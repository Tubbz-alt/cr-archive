<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/cpu/x86/jvmciCodeInstaller_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2013, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 #include &quot;precompiled.hpp&quot;
 25 #include &quot;compiler/disassembler.hpp&quot;
 26 #include &quot;oops/oop.inline.hpp&quot;
 27 #include &quot;runtime/handles.inline.hpp&quot;
 28 #include &quot;runtime/javaCalls.hpp&quot;
 29 #include &quot;runtime/sharedRuntime.hpp&quot;
 30 #include &quot;jvmci/jvmci.hpp&quot;
 31 #include &quot;jvmci/jvmciEnv.hpp&quot;
 32 #include &quot;jvmci/jvmciCodeInstaller.hpp&quot;
 33 #include &quot;jvmci/jvmciJavaClasses.hpp&quot;
 34 #include &quot;jvmci/jvmciCompilerToVM.hpp&quot;
 35 #include &quot;jvmci/jvmciRuntime.hpp&quot;
 36 #include &quot;asm/register.hpp&quot;
 37 #include &quot;classfile/vmSymbols.hpp&quot;
 38 #include &quot;code/vmreg.hpp&quot;
 39 #include &quot;vmreg_x86.inline.hpp&quot;
 40 
 41 jint CodeInstaller::pd_next_offset(NativeInstruction* inst, jint pc_offset, JVMCIObject method, JVMCI_TRAPS) {
 42   if (inst-&gt;is_call() || inst-&gt;is_jump()) {
 43     assert(NativeCall::instruction_size == (int)NativeJump::instruction_size, &quot;unexpected size&quot;);
 44     return (pc_offset + NativeCall::instruction_size);
 45   } else if (inst-&gt;is_mov_literal64()) {
 46     // mov+call instruction pair
 47     jint offset = pc_offset + NativeMovConstReg::instruction_size;
 48     u_char* call = (u_char*) (_instructions-&gt;start() + offset);
 49     if (call[0] == Assembler::REX_B) {
 50       offset += 1; /* prefix byte for extended register R8-R15 */
 51       call++;
 52     }
 53     assert(call[0] == 0xFF, &quot;expected call&quot;);
 54     offset += 2; /* opcode byte + modrm byte */
 55     return (offset);
 56   } else if (inst-&gt;is_call_reg()) {
 57     // the inlined vtable stub contains a &quot;call register&quot; instruction
 58     assert(method.is_non_null(), &quot;only valid for virtual calls&quot;);
 59     return (pc_offset + ((NativeCallReg *) inst)-&gt;next_instruction_offset());
 60   } else if (inst-&gt;is_cond_jump()) {
 61     address pc = (address) (inst);
 62     return pc_offset + (jint) (Assembler::locate_next_instruction(pc) - pc);
 63   } else {
 64     JVMCI_ERROR_0(&quot;unsupported type of instruction for call site&quot;);
 65   }
 66 }
 67 
 68 void CodeInstaller::pd_patch_OopConstant(int pc_offset, JVMCIObject constant, JVMCI_TRAPS) {
 69   address pc = _instructions-&gt;start() + pc_offset;
 70   Handle obj = jvmci_env()-&gt;asConstant(constant, JVMCI_CHECK);
 71   Thread* THREAD = Thread::current();
 72   jobject value = JNIHandles::make_local(obj());
 73   if (jvmci_env()-&gt;get_HotSpotObjectConstantImpl_compressed(constant)) {
 74 #ifdef _LP64
 75     address operand = Assembler::locate_operand(pc, Assembler::narrow_oop_operand);
 76     int oop_index = _oop_recorder-&gt;find_index(value);
 77     _instructions-&gt;relocate(pc, oop_Relocation::spec(oop_index), Assembler::narrow_oop_operand);
 78     JVMCI_event_3(&quot;relocating (narrow oop constant) at &quot; PTR_FORMAT &quot;/&quot; PTR_FORMAT, p2i(pc), p2i(operand));
 79 #else
 80     JVMCI_ERROR(&quot;compressed oop on 32bit&quot;);
 81 #endif
 82   } else {
 83     address operand = Assembler::locate_operand(pc, Assembler::imm_operand);
 84     *((jobject*) operand) = value;
 85     _instructions-&gt;relocate(pc, oop_Relocation::spec_for_immediate(), Assembler::imm_operand);
 86     JVMCI_event_3(&quot;relocating (oop constant) at &quot; PTR_FORMAT &quot;/&quot; PTR_FORMAT, p2i(pc), p2i(operand));
 87   }
 88 }
 89 
 90 void CodeInstaller::pd_patch_MetaspaceConstant(int pc_offset, JVMCIObject constant, JVMCI_TRAPS) {
 91   address pc = _instructions-&gt;start() + pc_offset;
 92   if (jvmci_env()-&gt;get_HotSpotMetaspaceConstantImpl_compressed(constant)) {
 93 #ifdef _LP64
 94     address operand = Assembler::locate_operand(pc, Assembler::narrow_oop_operand);
 95     *((narrowKlass*) operand) = record_narrow_metadata_reference(_instructions, operand, constant, JVMCI_CHECK);
 96     JVMCI_event_3(&quot;relocating (narrow metaspace constant) at &quot; PTR_FORMAT &quot;/&quot; PTR_FORMAT, p2i(pc), p2i(operand));
 97 #else
 98     JVMCI_ERROR(&quot;compressed Klass* on 32bit&quot;);
 99 #endif
100   } else {
101     address operand = Assembler::locate_operand(pc, Assembler::imm_operand);
102     *((void**) operand) = record_metadata_reference(_instructions, operand, constant, JVMCI_CHECK);
103     JVMCI_event_3(&quot;relocating (metaspace constant) at &quot; PTR_FORMAT &quot;/&quot; PTR_FORMAT, p2i(pc), p2i(operand));
104   }
105 }
106 
107 void CodeInstaller::pd_patch_DataSectionReference(int pc_offset, int data_offset, JVMCI_TRAPS) {
108   address pc = _instructions-&gt;start() + pc_offset;
109 
110   address operand = Assembler::locate_operand(pc, Assembler::disp32_operand);
111   address next_instruction = Assembler::locate_next_instruction(pc);
112   address dest = _constants-&gt;start() + data_offset;
113 
114   long disp = dest - next_instruction;
115   assert(disp == (jint) disp, &quot;disp doesn&#39;t fit in 32 bits&quot;);
116   *((jint*) operand) = (jint) disp;
117 
118   _instructions-&gt;relocate(pc, section_word_Relocation::spec((address) dest, CodeBuffer::SECT_CONSTS), Assembler::disp32_operand);
119   JVMCI_event_3(&quot;relocating at &quot; PTR_FORMAT &quot;/&quot; PTR_FORMAT &quot; with destination at &quot; PTR_FORMAT &quot; (%d)&quot;, p2i(pc), p2i(operand), p2i(dest), data_offset);
120 }
121 
122 void CodeInstaller::pd_relocate_ForeignCall(NativeInstruction* inst, jlong foreign_call_destination, JVMCI_TRAPS) {
123   address pc = (address) inst;
124   if (inst-&gt;is_call()) {
125     // NOTE: for call without a mov, the offset must fit a 32-bit immediate
126     //       see also CompilerToVM.getMaxCallTargetOffset()
127     NativeCall* call = nativeCall_at(pc);
128     call-&gt;set_destination((address) foreign_call_destination);
129     _instructions-&gt;relocate(call-&gt;instruction_address(), runtime_call_Relocation::spec(), Assembler::call32_operand);
130   } else if (inst-&gt;is_mov_literal64()) {
131     NativeMovConstReg* mov = nativeMovConstReg_at(pc);
132     mov-&gt;set_data((intptr_t) foreign_call_destination);
133     _instructions-&gt;relocate(mov-&gt;instruction_address(), runtime_call_Relocation::spec(), Assembler::imm_operand);
134   } else if (inst-&gt;is_jump()) {
135     NativeJump* jump = nativeJump_at(pc);
136     jump-&gt;set_jump_destination((address) foreign_call_destination);
137     _instructions-&gt;relocate(jump-&gt;instruction_address(), runtime_call_Relocation::spec(), Assembler::call32_operand);
138   } else if (inst-&gt;is_cond_jump()) {
139     address old_dest = nativeGeneralJump_at(pc)-&gt;jump_destination();
140     address disp = Assembler::locate_operand(pc, Assembler::call32_operand);
141     *(jint*) disp += ((address) foreign_call_destination) - old_dest;
142     _instructions-&gt;relocate(pc, runtime_call_Relocation::spec(), Assembler::call32_operand);
143   } else {
144     JVMCI_ERROR(&quot;unsupported relocation for foreign call&quot;);
145   }
146 
147   JVMCI_event_3(&quot;relocating (foreign call)  at &quot; PTR_FORMAT, p2i(inst));
148 }
149 
150 void CodeInstaller::pd_relocate_JavaMethod(CodeBuffer &amp;, JVMCIObject hotspot_method, jint pc_offset, JVMCI_TRAPS) {
151 #ifdef ASSERT
152   Method* method = NULL;
153   // we need to check, this might also be an unresolved method
154   if (JVMCIENV-&gt;isa_HotSpotResolvedJavaMethodImpl(hotspot_method)) {
155     method = JVMCIENV-&gt;asMethod(hotspot_method);
156   }
157 #endif
158   switch (_next_call_type) {
159     case INLINE_INVOKE:
160       break;
161     case INVOKEVIRTUAL:
162     case INVOKEINTERFACE: {
163       assert(method == NULL || !method-&gt;is_static(), &quot;cannot call static method with invokeinterface&quot;);
164 
165       NativeCall* call = nativeCall_at(_instructions-&gt;start() + pc_offset);
166       call-&gt;set_destination(SharedRuntime::get_resolve_virtual_call_stub());
167       _instructions-&gt;relocate(call-&gt;instruction_address(),
168                                              virtual_call_Relocation::spec(_invoke_mark_pc),
169                                              Assembler::call32_operand);
170       break;
171     }
172     case INVOKESTATIC: {
173       assert(method == NULL || method-&gt;is_static(), &quot;cannot call non-static method with invokestatic&quot;);
174 
175       NativeCall* call = nativeCall_at(_instructions-&gt;start() + pc_offset);
176       call-&gt;set_destination(SharedRuntime::get_resolve_static_call_stub());
177       _instructions-&gt;relocate(call-&gt;instruction_address(),
178                                              relocInfo::static_call_type, Assembler::call32_operand);
179       break;
180     }
181     case INVOKESPECIAL: {
182       assert(method == NULL || !method-&gt;is_static(), &quot;cannot call static method with invokespecial&quot;);
183       NativeCall* call = nativeCall_at(_instructions-&gt;start() + pc_offset);
184       call-&gt;set_destination(SharedRuntime::get_resolve_opt_virtual_call_stub());
185       _instructions-&gt;relocate(call-&gt;instruction_address(),
186                               relocInfo::opt_virtual_call_type, Assembler::call32_operand);
187       break;
188     }
189     default:
190       JVMCI_ERROR(&quot;invalid _next_call_type value&quot;);
191       break;
192   }
193 }
194 
195 void CodeInstaller::pd_relocate_poll(address pc, jint mark, JVMCI_TRAPS) {
196   switch (mark) {
197     case POLL_NEAR:
198     case POLL_FAR:
199       // This is a load from a register so there is no relocatable operand.
200       // We just have to ensure that the format is not disp32_operand
201       // so that poll_Relocation::fix_relocation_after_move does the right
202       // thing (i.e. ignores this relocation record)
203       _instructions-&gt;relocate(pc, relocInfo::poll_type, Assembler::imm_operand);
204       break;
205     case POLL_RETURN_NEAR:
206     case POLL_RETURN_FAR:
207       // see comment above for POLL_FAR
208       _instructions-&gt;relocate(pc, relocInfo::poll_return_type, Assembler::imm_operand);
209       break;
210     default:
211       JVMCI_ERROR(&quot;invalid mark value: %d&quot;, mark);
212       break;
213   }
214 }
215 
216 // convert JVMCI register indices (as used in oop maps) to HotSpot registers
217 VMReg CodeInstaller::get_hotspot_reg(jint jvmci_reg, JVMCI_TRAPS) {
218   if (jvmci_reg &lt; RegisterImpl::number_of_registers) {
219     return as_Register(jvmci_reg)-&gt;as_VMReg();
220   } else {
221     jint floatRegisterNumber = jvmci_reg - RegisterImpl::number_of_registers;
222     if (floatRegisterNumber &lt; XMMRegisterImpl::number_of_registers) {
223       return as_XMMRegister(floatRegisterNumber)-&gt;as_VMReg();
224     }
225     JVMCI_ERROR_NULL(&quot;invalid register number: %d&quot;, jvmci_reg);
226   }
227 }
228 
229 bool CodeInstaller::is_general_purpose_reg(VMReg hotspotRegister) {
230   return !(hotspotRegister-&gt;is_FloatRegister() || hotspotRegister-&gt;is_XMMRegister());
231 }
    </pre>
  </body>
</html>