<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/AssemblyHelpers.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="../interpreter/VMEntryRecord.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="AssemblyHelpers.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/AssemblyHelpers.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  83     loadDouble(TrustedImmPtr(&amp;NaN), fpr);
  84     notNaN.link(this);
  85 }
  86 
  87 #if ENABLE(SAMPLING_FLAGS)
  88 void AssemblyHelpers::setSamplingFlag(int32_t flag)
  89 {
  90     ASSERT(flag &gt;= 1);
  91     ASSERT(flag &lt;= 32);
  92     or32(TrustedImm32(1u &lt;&lt; (flag - 1)), AbsoluteAddress(SamplingFlags::addressOfFlags()));
  93 }
  94 
  95 void AssemblyHelpers::clearSamplingFlag(int32_t flag)
  96 {
  97     ASSERT(flag &gt;= 1);
  98     ASSERT(flag &lt;= 32);
  99     and32(TrustedImm32(~(1u &lt;&lt; (flag - 1))), AbsoluteAddress(SamplingFlags::addressOfFlags()));
 100 }
 101 #endif
 102 
<span class="line-modified"> 103 #if !ASSERT_DISABLED</span>
 104 #if USE(JSVALUE64)
 105 void AssemblyHelpers::jitAssertIsInt32(GPRReg gpr)
 106 {
 107 #if CPU(X86_64) || CPU(ARM64)
 108     Jump checkInt32 = branch64(BelowOrEqual, gpr, TrustedImm64(static_cast&lt;uintptr_t&gt;(0xFFFFFFFFu)));
 109     abortWithReason(AHIsNotInt32);
 110     checkInt32.link(this);
 111 #else
 112     UNUSED_PARAM(gpr);
 113 #endif
 114 }
 115 
 116 void AssemblyHelpers::jitAssertIsJSInt32(GPRReg gpr)
 117 {
<span class="line-modified"> 118     Jump checkJSInt32 = branch64(AboveOrEqual, gpr, GPRInfo::tagTypeNumberRegister);</span>
 119     abortWithReason(AHIsNotJSInt32);
 120     checkJSInt32.link(this);
 121 }
 122 
 123 void AssemblyHelpers::jitAssertIsJSNumber(GPRReg gpr)
 124 {
<span class="line-modified"> 125     Jump checkJSNumber = branchTest64(MacroAssembler::NonZero, gpr, GPRInfo::tagTypeNumberRegister);</span>
 126     abortWithReason(AHIsNotJSNumber);
 127     checkJSNumber.link(this);
 128 }
 129 
 130 void AssemblyHelpers::jitAssertIsJSDouble(GPRReg gpr)
 131 {
<span class="line-modified"> 132     Jump checkJSInt32 = branch64(AboveOrEqual, gpr, GPRInfo::tagTypeNumberRegister);</span>
<span class="line-modified"> 133     Jump checkJSNumber = branchTest64(MacroAssembler::NonZero, gpr, GPRInfo::tagTypeNumberRegister);</span>
 134     checkJSInt32.link(this);
 135     abortWithReason(AHIsNotJSDouble);
 136     checkJSNumber.link(this);
 137 }
 138 
 139 void AssemblyHelpers::jitAssertIsCell(GPRReg gpr)
 140 {
<span class="line-modified"> 141     Jump checkCell = branchTest64(MacroAssembler::Zero, gpr, GPRInfo::tagMaskRegister);</span>
 142     abortWithReason(AHIsNotCell);
 143     checkCell.link(this);
 144 }
 145 
 146 void AssemblyHelpers::jitAssertTagsInPlace()
 147 {
<span class="line-modified"> 148     Jump ok = branch64(Equal, GPRInfo::tagTypeNumberRegister, TrustedImm64(TagTypeNumber));</span>
<span class="line-modified"> 149     abortWithReason(AHTagTypeNumberNotInPlace);</span>
 150     breakpoint();
 151     ok.link(this);
 152 
<span class="line-modified"> 153     ok = branch64(Equal, GPRInfo::tagMaskRegister, TrustedImm64(TagMask));</span>
<span class="line-modified"> 154     abortWithReason(AHTagMaskNotInPlace);</span>
 155     ok.link(this);
 156 }
 157 #elif USE(JSVALUE32_64)
 158 void AssemblyHelpers::jitAssertIsInt32(GPRReg gpr)
 159 {
 160     UNUSED_PARAM(gpr);
 161 }
 162 
 163 void AssemblyHelpers::jitAssertIsJSInt32(GPRReg gpr)
 164 {
 165     Jump checkJSInt32 = branch32(Equal, gpr, TrustedImm32(JSValue::Int32Tag));
 166     abortWithReason(AHIsNotJSInt32);
 167     checkJSInt32.link(this);
 168 }
 169 
 170 void AssemblyHelpers::jitAssertIsJSNumber(GPRReg gpr)
 171 {
 172     Jump checkJSInt32 = branch32(Equal, gpr, TrustedImm32(JSValue::Int32Tag));
 173     Jump checkJSDouble = branch32(Below, gpr, TrustedImm32(JSValue::LowestTag));
 174     abortWithReason(AHIsNotJSNumber);
</pre>
<hr />
<pre>
 194 {
 195 }
 196 #endif // USE(JSVALUE32_64)
 197 
 198 void AssemblyHelpers::jitAssertHasValidCallFrame()
 199 {
 200     Jump checkCFR = branchTestPtr(Zero, GPRInfo::callFrameRegister, TrustedImm32(7));
 201     abortWithReason(AHCallFrameMisaligned);
 202     checkCFR.link(this);
 203 }
 204 
 205 void AssemblyHelpers::jitAssertIsNull(GPRReg gpr)
 206 {
 207     Jump checkNull = branchTestPtr(Zero, gpr);
 208     abortWithReason(AHIsNotNull);
 209     checkNull.link(this);
 210 }
 211 
 212 void AssemblyHelpers::jitAssertArgumentCountSane()
 213 {
<span class="line-modified"> 214     Jump ok = branch32(Below, payloadFor(CallFrameSlot::argumentCount), TrustedImm32(10000000));</span>
 215     abortWithReason(AHInsaneArgumentCount);
 216     ok.link(this);
 217 }
 218 
<span class="line-modified"> 219 #endif // !ASSERT_DISABLED</span>
 220 
 221 void AssemblyHelpers::jitReleaseAssertNoException(VM&amp; vm)
 222 {
 223     Jump noException;
 224 #if USE(JSVALUE64)
 225     noException = branchTest64(Zero, AbsoluteAddress(vm.addressOfException()));
 226 #elif USE(JSVALUE32_64)
 227     noException = branch32(Equal, AbsoluteAddress(vm.addressOfException()), TrustedImm32(0));
 228 #endif
 229     abortWithReason(JITUncoughtExceptionAfterCall);
 230     noException.link(this);
 231 }
 232 
 233 void AssemblyHelpers::callExceptionFuzz(VM&amp; vm)
 234 {
 235     if (!Options::useExceptionFuzz())
 236         return;
 237 
 238     EncodedJSValue* buffer = vm.exceptionFuzzingBuffer(sizeof(EncodedJSValue) * (GPRInfo::numberOfRegisters + FPRInfo::numberOfRegisters));
 239 
 240     for (unsigned i = 0; i &lt; GPRInfo::numberOfRegisters; ++i) {
 241 #if USE(JSVALUE64)
 242         store64(GPRInfo::toRegister(i), buffer + i);
 243 #else
 244         store32(GPRInfo::toRegister(i), buffer + i);
 245 #endif
 246     }
 247     for (unsigned i = 0; i &lt; FPRInfo::numberOfRegisters; ++i) {
 248         move(TrustedImmPtr(buffer + GPRInfo::numberOfRegisters + i), GPRInfo::regT0);
 249         storeDouble(FPRInfo::toRegister(i), Address(GPRInfo::regT0));
 250     }
 251 
 252     // Set up one argument.
<span class="line-removed"> 253 #if CPU(X86)</span>
<span class="line-removed"> 254     poke(GPRInfo::callFrameRegister, 0);</span>
<span class="line-removed"> 255 #else</span>
 256     move(GPRInfo::callFrameRegister, GPRInfo::argumentGPR0);
<span class="line-removed"> 257 #endif</span>
 258     move(TrustedImmPtr(tagCFunctionPtr&lt;OperationPtrTag&gt;(operationExceptionFuzz)), GPRInfo::nonPreservedNonReturnGPR);

 259     call(GPRInfo::nonPreservedNonReturnGPR, OperationPtrTag);
 260 
 261     for (unsigned i = 0; i &lt; FPRInfo::numberOfRegisters; ++i) {
 262         move(TrustedImmPtr(buffer + GPRInfo::numberOfRegisters + i), GPRInfo::regT0);
 263         loadDouble(Address(GPRInfo::regT0), FPRInfo::toRegister(i));
 264     }
 265     for (unsigned i = 0; i &lt; GPRInfo::numberOfRegisters; ++i) {
 266 #if USE(JSVALUE64)
 267         load64(buffer + i, GPRInfo::toRegister(i));
 268 #else
 269         load32(buffer + i, GPRInfo::toRegister(i));
 270 #endif
 271     }
 272 }
 273 
 274 AssemblyHelpers::Jump AssemblyHelpers::emitJumpIfException(VM&amp; vm)
 275 {
 276     return emitExceptionCheck(vm, NormalExceptionCheck);
 277 }
 278 
</pre>
<hr />
<pre>
 301 
 302 AssemblyHelpers::Jump AssemblyHelpers::emitNonPatchableExceptionCheck(VM&amp; vm)
 303 {
 304     callExceptionFuzz(vm);
 305 
 306     Jump result;
 307 #if USE(JSVALUE64)
 308     result = branchTest64(NonZero, AbsoluteAddress(vm.addressOfException()));
 309 #elif USE(JSVALUE32_64)
 310     result = branch32(NotEqual, AbsoluteAddress(vm.addressOfException()), TrustedImm32(0));
 311 #endif
 312 
 313     return result;
 314 }
 315 
 316 void AssemblyHelpers::emitStoreStructureWithTypeInfo(AssemblyHelpers&amp; jit, TrustedImmPtr structure, RegisterID dest)
 317 {
 318     const Structure* structurePtr = reinterpret_cast&lt;const Structure*&gt;(structure.m_value);
 319 #if USE(JSVALUE64)
 320     jit.store64(TrustedImm64(structurePtr-&gt;idBlob()), MacroAssembler::Address(dest, JSCell::structureIDOffset()));
<span class="line-modified"> 321     if (!ASSERT_DISABLED) {</span>
 322         Jump correctStructure = jit.branch32(Equal, MacroAssembler::Address(dest, JSCell::structureIDOffset()), TrustedImm32(structurePtr-&gt;id()));
 323         jit.abortWithReason(AHStructureIDIsValid);
 324         correctStructure.link(&amp;jit);
 325 
 326         Jump correctIndexingType = jit.branch8(Equal, MacroAssembler::Address(dest, JSCell::indexingTypeAndMiscOffset()), TrustedImm32(structurePtr-&gt;indexingModeIncludingHistory()));
 327         jit.abortWithReason(AHIndexingTypeIsValid);
 328         correctIndexingType.link(&amp;jit);
 329 
 330         Jump correctType = jit.branch8(Equal, MacroAssembler::Address(dest, JSCell::typeInfoTypeOffset()), TrustedImm32(structurePtr-&gt;typeInfo().type()));
 331         jit.abortWithReason(AHTypeInfoIsValid);
 332         correctType.link(&amp;jit);
 333 
 334         Jump correctFlags = jit.branch8(Equal, MacroAssembler::Address(dest, JSCell::typeInfoFlagsOffset()), TrustedImm32(structurePtr-&gt;typeInfo().inlineTypeFlags()));
 335         jit.abortWithReason(AHTypeInfoInlineTypeFlagsAreValid);
 336         correctFlags.link(&amp;jit);
 337     }
 338 #else
 339     // Do a 32-bit wide store to initialize the cell&#39;s fields.
 340     jit.store32(TrustedImm32(structurePtr-&gt;objectInitializationBlob()), MacroAssembler::Address(dest, JSCell::indexingTypeAndMiscOffset()));
 341     jit.storePtr(structure, MacroAssembler::Address(dest, JSCell::structureIDOffset()));
</pre>
<hr />
<pre>
 433     // x ^= y ^ (y &gt;&gt; 26);
 434     jit.move(scratch1, scratch2);
 435     jit.rshift64(AssemblyHelpers::TrustedImm32(26), scratch2);
 436     jit.xor64(scratch1, scratch2);
 437     jit.xor64(scratch2, scratch0);
 438 
 439     // m_high = x;
 440     storeToHigh(scratch0);
 441 
 442     // return x + y;
 443     jit.add64(scratch1, scratch0);
 444 
 445     // Extract random 53bit. [0, 53] bit is safe integer number ranges in double representation.
 446     jit.move(AssemblyHelpers::TrustedImm64((1ULL &lt;&lt; 53) - 1), scratch1);
 447     jit.and64(scratch1, scratch0);
 448     // Now, scratch0 is always in range of int64_t. Safe to convert it to double with cvtsi2sdq.
 449     jit.convertInt64ToDouble(scratch0, result);
 450 
 451     // Convert `(53bit double integer value) / (1 &lt;&lt; 53)` to `(53bit double integer value) * (1.0 / (1 &lt;&lt; 53))`.
 452     // In latter case, `1.0 / (1 &lt;&lt; 53)` will become a double value represented as (mantissa = 0 &amp; exp = 970, it means 1e-(2**54)).
<span class="line-modified"> 453     static const double scale = 1.0 / (1ULL &lt;&lt; 53);</span>
 454 
 455     // Multiplying 1e-(2**54) with the double integer does not change anything of the mantissa part of the double integer.
 456     // It just reduces the exp part of the given 53bit double integer.
 457     // (Except for 0.0. This is specially handled and in this case, exp just becomes 0.)
 458     // Now we get 53bit precision random double value in [0, 1).
 459     jit.move(AssemblyHelpers::TrustedImmPtr(&amp;scale), scratch1);
 460     jit.mulDouble(AssemblyHelpers::Address(scratch1), result);
 461 }
 462 
 463 void AssemblyHelpers::emitRandomThunk(JSGlobalObject* globalObject, GPRReg scratch0, GPRReg scratch1, GPRReg scratch2, FPRReg result)
 464 {
 465     void* lowAddress = reinterpret_cast&lt;uint8_t*&gt;(globalObject) + JSGlobalObject::weakRandomOffset() + WeakRandom::lowOffset();
 466     void* highAddress = reinterpret_cast&lt;uint8_t*&gt;(globalObject) + JSGlobalObject::weakRandomOffset() + WeakRandom::highOffset();
 467 
 468     auto loadFromHigh = [&amp;](GPRReg high) {
 469         load64(highAddress, high);
 470     };
 471     auto storeToHigh = [&amp;](GPRReg high) {
 472         store64(high, highAddress);
 473     };
</pre>
<hr />
<pre>
 611         if (dontRestoreRegisters.get(entry.reg()))
 612             continue;
 613         if (entry.reg().isGPR()) {
 614             if (i != scratchGPREntryIndex)
 615                 loadPtr(Address(scratch, entry.offset()), entry.reg().gpr());
 616         } else
 617             loadDouble(Address(scratch, entry.offset()), entry.reg().fpr());
 618     }
 619 
 620     // Restore the callee save value of the scratch.
 621     RegisterAtOffset entry = allCalleeSaves-&gt;at(scratchGPREntryIndex);
 622     ASSERT(!dontRestoreRegisters.get(entry.reg()));
 623     ASSERT(entry.reg().isGPR());
 624     ASSERT(scratch == entry.reg().gpr());
 625     loadPtr(Address(scratch, entry.offset()), scratch);
 626 #else
 627     UNUSED_PARAM(topEntryFrame);
 628 #endif
 629 }
 630 
<span class="line-modified"> 631 void AssemblyHelpers::emitDumbVirtualCall(VM&amp; vm, CallLinkInfo* info)</span>
 632 {
 633     move(TrustedImmPtr(info), GPRInfo::regT2);

 634     Call call = nearCall();
 635     addLinkTask(
 636         [=, &amp;vm] (LinkBuffer&amp; linkBuffer) {
 637             MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; virtualThunk = virtualThunkFor(vm, *info);
<span class="line-modified"> 638             info-&gt;setSlowStub(createJITStubRoutine(virtualThunk, vm, nullptr, true));</span>
 639             linkBuffer.link(call, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(virtualThunk.code()));
 640         });
 641 }
 642 
 643 #if USE(JSVALUE64)
 644 void AssemblyHelpers::wangsInt64Hash(GPRReg inputAndResult, GPRReg scratch)
 645 {
 646     GPRReg input = inputAndResult;
 647     // key += ~(key &lt;&lt; 32);
 648     move(input, scratch);
 649     lshift64(TrustedImm32(32), scratch);
 650     not64(scratch);
 651     add64(scratch, input);
 652     // key ^= (key &gt;&gt; 22);
 653     move(input, scratch);
 654     urshift64(TrustedImm32(22), scratch);
 655     xor64(scratch, input);
 656     // key += ~(key &lt;&lt; 13);
 657     move(input, scratch);
 658     lshift64(TrustedImm32(13), scratch);
</pre>
<hr />
<pre>
 738 
 739     notCell.link(this);
 740     auto notInt32 = branchIfNotInt32(value);
 741     compare32(invert ? Equal : NotEqual, value.payloadGPR(), TrustedImm32(0), result);
 742     done.append(jump());
 743 
 744     notInt32.link(this);
 745     auto notDouble = branchIfNotDoubleKnownNotInt32(value);
 746 #if USE(JSVALUE64)
 747     unboxDouble(value.gpr(), result, valueAsFPR);
 748 #else
 749     unboxDouble(value, valueAsFPR, tempFPR);
 750 #endif
 751     move(invert ? TrustedImm32(1) : TrustedImm32(0), result);
 752     done.append(branchDoubleZeroOrNaN(valueAsFPR, tempFPR));
 753     move(invert ? TrustedImm32(0) : TrustedImm32(1), result);
 754     done.append(jump());
 755 
 756     notDouble.link(this);
 757 #if USE(JSVALUE64)
<span class="line-modified"> 758     static_assert(static_cast&lt;int32_t&gt;(ValueTrue) == ValueTrue, &quot;&quot;);</span>
<span class="line-removed"> 759     compare64(invert ? NotEqual : Equal, value.gpr(), TrustedImm32(ValueTrue), result);</span>
 760 #else
 761     move(invert ? TrustedImm32(1) : TrustedImm32(0), result);
 762     done.append(branchIfNotBoolean(value, InvalidGPRReg));
 763     compare32(invert ? Equal : NotEqual, value.payloadGPR(), TrustedImm32(0), result);
 764 #endif
 765 
 766     done.link(this);
 767 }
 768 
 769 AssemblyHelpers::JumpList AssemblyHelpers::branchIfValue(VM&amp; vm, JSValueRegs value, GPRReg scratch, GPRReg scratchIfShouldCheckMasqueradesAsUndefined, FPRReg valueAsFPR, FPRReg tempFPR, bool shouldCheckMasqueradesAsUndefined, JSGlobalObject* globalObject, bool invert)
 770 {
 771     // Implements the following control flow structure:
 772     // if (value is cell) {
 773     //     if (value is string or value is BigInt)
 774     //         result = !!value-&gt;length
 775     //     else {
 776     //         do evil things for masquerades-as-undefined
 777     //         result = true
 778     //     }
 779     // } else if (value is int32) {
</pre>
<hr />
<pre>
 915         store64(GPRInfo::toRegister(i), buffer + i);
 916 #else
 917         store32(GPRInfo::toRegister(i), buffer + i);
 918 #endif
 919     }
 920 
 921     for (unsigned i = 0; i &lt; FPRInfo::numberOfRegisters; ++i) {
 922         move(TrustedImmPtr(buffer + GPRInfo::numberOfRegisters + i), GPRInfo::regT0);
 923         storeDouble(FPRInfo::toRegister(i), GPRInfo::regT0);
 924     }
 925 
 926     // Tell GC mark phase how much of the scratch buffer is active during call.
 927     move(TrustedImmPtr(scratchBuffer-&gt;addressOfActiveLength()), GPRInfo::regT0);
 928     storePtr(TrustedImmPtr(scratchSize), GPRInfo::regT0);
 929 
 930 #if CPU(X86_64) || CPU(ARM_THUMB2) || CPU(ARM64) || CPU(MIPS)
 931     move(TrustedImmPtr(buffer), GPRInfo::argumentGPR2);
 932     move(TrustedImmPtr(argument), GPRInfo::argumentGPR1);
 933     move(GPRInfo::callFrameRegister, GPRInfo::argumentGPR0);
 934     GPRReg scratch = selectScratchGPR(GPRInfo::argumentGPR0, GPRInfo::argumentGPR1, GPRInfo::argumentGPR2);
<span class="line-removed"> 935 #elif CPU(X86)</span>
<span class="line-removed"> 936     poke(GPRInfo::callFrameRegister, 0);</span>
<span class="line-removed"> 937     poke(TrustedImmPtr(argument), 1);</span>
<span class="line-removed"> 938     poke(TrustedImmPtr(buffer), 2);</span>
<span class="line-removed"> 939     GPRReg scratch = GPRInfo::regT0;</span>
 940 #else
 941 #error &quot;JIT not supported on this platform.&quot;
 942 #endif

 943     move(TrustedImmPtr(tagCFunctionPtr&lt;OperationPtrTag&gt;(function)), scratch);
 944     call(scratch, OperationPtrTag);
 945 
 946     move(TrustedImmPtr(scratchBuffer-&gt;addressOfActiveLength()), GPRInfo::regT0);
 947     storePtr(TrustedImmPtr(nullptr), GPRInfo::regT0);
 948 
 949     for (unsigned i = 0; i &lt; FPRInfo::numberOfRegisters; ++i) {
 950         move(TrustedImmPtr(buffer + GPRInfo::numberOfRegisters + i), GPRInfo::regT0);
 951         loadDouble(GPRInfo::regT0, FPRInfo::toRegister(i));
 952     }
 953     for (unsigned i = 0; i &lt; GPRInfo::numberOfRegisters; ++i) {
 954 #if USE(JSVALUE64)
 955         load64(buffer + i, GPRInfo::toRegister(i));
 956 #else
 957         load32(buffer + i, GPRInfo::toRegister(i));
 958 #endif
 959     }
 960 }
 961 
 962 void AssemblyHelpers::copyCalleeSavesToEntryFrameCalleeSavesBufferImpl(GPRReg calleeSavesBuffer)
</pre>
<hr />
<pre>
 978             storeDouble(entry.reg().fpr(), Address(calleeSavesBuffer, entry.offset()));
 979     }
 980 #else
 981     UNUSED_PARAM(calleeSavesBuffer);
 982 #endif
 983 }
 984 
 985 void AssemblyHelpers::sanitizeStackInline(VM&amp; vm, GPRReg scratch)
 986 {
 987     loadPtr(vm.addressOfLastStackTop(), scratch);
 988     Jump done = branchPtr(BelowOrEqual, stackPointerRegister, scratch);
 989     Label loop = label();
 990     storePtr(TrustedImmPtr(nullptr), scratch);
 991     addPtr(TrustedImmPtr(sizeof(void*)), scratch);
 992     branchPtr(Above, stackPointerRegister, scratch).linkTo(loop, this);
 993     done.link(this);
 994     move(stackPointerRegister, scratch);
 995     storePtr(scratch, vm.addressOfLastStackTop());
 996 }
 997 
<span class="line-removed"> 998 void AssemblyHelpers::emitPreparePreciseIndexMask32(GPRReg index, GPRReg length, GPRReg result)</span>
<span class="line-removed"> 999 {</span>
<span class="line-removed">1000     if (length == result) {</span>
<span class="line-removed">1001         negPtr(length);</span>
<span class="line-removed">1002         addPtr(index, length);</span>
<span class="line-removed">1003     } else {</span>
<span class="line-removed">1004         move(index, result);</span>
<span class="line-removed">1005         subPtr(length, result);</span>
<span class="line-removed">1006     }</span>
<span class="line-removed">1007     rshiftPtr(TrustedImm32(preciseIndexMaskShift&lt;void*&gt;()), result);</span>
<span class="line-removed">1008 }</span>
<span class="line-removed">1009 </span>
1010 } // namespace JSC
1011 
1012 #endif // ENABLE(JIT)
1013 
</pre>
</td>
<td>
<hr />
<pre>
  83     loadDouble(TrustedImmPtr(&amp;NaN), fpr);
  84     notNaN.link(this);
  85 }
  86 
  87 #if ENABLE(SAMPLING_FLAGS)
  88 void AssemblyHelpers::setSamplingFlag(int32_t flag)
  89 {
  90     ASSERT(flag &gt;= 1);
  91     ASSERT(flag &lt;= 32);
  92     or32(TrustedImm32(1u &lt;&lt; (flag - 1)), AbsoluteAddress(SamplingFlags::addressOfFlags()));
  93 }
  94 
  95 void AssemblyHelpers::clearSamplingFlag(int32_t flag)
  96 {
  97     ASSERT(flag &gt;= 1);
  98     ASSERT(flag &lt;= 32);
  99     and32(TrustedImm32(~(1u &lt;&lt; (flag - 1))), AbsoluteAddress(SamplingFlags::addressOfFlags()));
 100 }
 101 #endif
 102 
<span class="line-modified"> 103 #if ASSERT_ENABLED</span>
 104 #if USE(JSVALUE64)
 105 void AssemblyHelpers::jitAssertIsInt32(GPRReg gpr)
 106 {
 107 #if CPU(X86_64) || CPU(ARM64)
 108     Jump checkInt32 = branch64(BelowOrEqual, gpr, TrustedImm64(static_cast&lt;uintptr_t&gt;(0xFFFFFFFFu)));
 109     abortWithReason(AHIsNotInt32);
 110     checkInt32.link(this);
 111 #else
 112     UNUSED_PARAM(gpr);
 113 #endif
 114 }
 115 
 116 void AssemblyHelpers::jitAssertIsJSInt32(GPRReg gpr)
 117 {
<span class="line-modified"> 118     Jump checkJSInt32 = branch64(AboveOrEqual, gpr, GPRInfo::numberTagRegister);</span>
 119     abortWithReason(AHIsNotJSInt32);
 120     checkJSInt32.link(this);
 121 }
 122 
 123 void AssemblyHelpers::jitAssertIsJSNumber(GPRReg gpr)
 124 {
<span class="line-modified"> 125     Jump checkJSNumber = branchTest64(MacroAssembler::NonZero, gpr, GPRInfo::numberTagRegister);</span>
 126     abortWithReason(AHIsNotJSNumber);
 127     checkJSNumber.link(this);
 128 }
 129 
 130 void AssemblyHelpers::jitAssertIsJSDouble(GPRReg gpr)
 131 {
<span class="line-modified"> 132     Jump checkJSInt32 = branch64(AboveOrEqual, gpr, GPRInfo::numberTagRegister);</span>
<span class="line-modified"> 133     Jump checkJSNumber = branchTest64(MacroAssembler::NonZero, gpr, GPRInfo::numberTagRegister);</span>
 134     checkJSInt32.link(this);
 135     abortWithReason(AHIsNotJSDouble);
 136     checkJSNumber.link(this);
 137 }
 138 
 139 void AssemblyHelpers::jitAssertIsCell(GPRReg gpr)
 140 {
<span class="line-modified"> 141     Jump checkCell = branchTest64(MacroAssembler::Zero, gpr, GPRInfo::notCellMaskRegister);</span>
 142     abortWithReason(AHIsNotCell);
 143     checkCell.link(this);
 144 }
 145 
 146 void AssemblyHelpers::jitAssertTagsInPlace()
 147 {
<span class="line-modified"> 148     Jump ok = branch64(Equal, GPRInfo::numberTagRegister, TrustedImm64(JSValue::NumberTag));</span>
<span class="line-modified"> 149     abortWithReason(AHNumberTagNotInPlace);</span>
 150     breakpoint();
 151     ok.link(this);
 152 
<span class="line-modified"> 153     ok = branch64(Equal, GPRInfo::notCellMaskRegister, TrustedImm64(JSValue::NotCellMask));</span>
<span class="line-modified"> 154     abortWithReason(AHNotCellMaskNotInPlace);</span>
 155     ok.link(this);
 156 }
 157 #elif USE(JSVALUE32_64)
 158 void AssemblyHelpers::jitAssertIsInt32(GPRReg gpr)
 159 {
 160     UNUSED_PARAM(gpr);
 161 }
 162 
 163 void AssemblyHelpers::jitAssertIsJSInt32(GPRReg gpr)
 164 {
 165     Jump checkJSInt32 = branch32(Equal, gpr, TrustedImm32(JSValue::Int32Tag));
 166     abortWithReason(AHIsNotJSInt32);
 167     checkJSInt32.link(this);
 168 }
 169 
 170 void AssemblyHelpers::jitAssertIsJSNumber(GPRReg gpr)
 171 {
 172     Jump checkJSInt32 = branch32(Equal, gpr, TrustedImm32(JSValue::Int32Tag));
 173     Jump checkJSDouble = branch32(Below, gpr, TrustedImm32(JSValue::LowestTag));
 174     abortWithReason(AHIsNotJSNumber);
</pre>
<hr />
<pre>
 194 {
 195 }
 196 #endif // USE(JSVALUE32_64)
 197 
 198 void AssemblyHelpers::jitAssertHasValidCallFrame()
 199 {
 200     Jump checkCFR = branchTestPtr(Zero, GPRInfo::callFrameRegister, TrustedImm32(7));
 201     abortWithReason(AHCallFrameMisaligned);
 202     checkCFR.link(this);
 203 }
 204 
 205 void AssemblyHelpers::jitAssertIsNull(GPRReg gpr)
 206 {
 207     Jump checkNull = branchTestPtr(Zero, gpr);
 208     abortWithReason(AHIsNotNull);
 209     checkNull.link(this);
 210 }
 211 
 212 void AssemblyHelpers::jitAssertArgumentCountSane()
 213 {
<span class="line-modified"> 214     Jump ok = branch32(Below, payloadFor(CallFrameSlot::argumentCountIncludingThis), TrustedImm32(10000000));</span>
 215     abortWithReason(AHInsaneArgumentCount);
 216     ok.link(this);
 217 }
 218 
<span class="line-modified"> 219 #endif // ASSERT_ENABLED</span>
 220 
 221 void AssemblyHelpers::jitReleaseAssertNoException(VM&amp; vm)
 222 {
 223     Jump noException;
 224 #if USE(JSVALUE64)
 225     noException = branchTest64(Zero, AbsoluteAddress(vm.addressOfException()));
 226 #elif USE(JSVALUE32_64)
 227     noException = branch32(Equal, AbsoluteAddress(vm.addressOfException()), TrustedImm32(0));
 228 #endif
 229     abortWithReason(JITUncoughtExceptionAfterCall);
 230     noException.link(this);
 231 }
 232 
 233 void AssemblyHelpers::callExceptionFuzz(VM&amp; vm)
 234 {
 235     if (!Options::useExceptionFuzz())
 236         return;
 237 
 238     EncodedJSValue* buffer = vm.exceptionFuzzingBuffer(sizeof(EncodedJSValue) * (GPRInfo::numberOfRegisters + FPRInfo::numberOfRegisters));
 239 
 240     for (unsigned i = 0; i &lt; GPRInfo::numberOfRegisters; ++i) {
 241 #if USE(JSVALUE64)
 242         store64(GPRInfo::toRegister(i), buffer + i);
 243 #else
 244         store32(GPRInfo::toRegister(i), buffer + i);
 245 #endif
 246     }
 247     for (unsigned i = 0; i &lt; FPRInfo::numberOfRegisters; ++i) {
 248         move(TrustedImmPtr(buffer + GPRInfo::numberOfRegisters + i), GPRInfo::regT0);
 249         storeDouble(FPRInfo::toRegister(i), Address(GPRInfo::regT0));
 250     }
 251 
 252     // Set up one argument.



 253     move(GPRInfo::callFrameRegister, GPRInfo::argumentGPR0);

 254     move(TrustedImmPtr(tagCFunctionPtr&lt;OperationPtrTag&gt;(operationExceptionFuzz)), GPRInfo::nonPreservedNonReturnGPR);
<span class="line-added"> 255     prepareCallOperation(vm);</span>
 256     call(GPRInfo::nonPreservedNonReturnGPR, OperationPtrTag);
 257 
 258     for (unsigned i = 0; i &lt; FPRInfo::numberOfRegisters; ++i) {
 259         move(TrustedImmPtr(buffer + GPRInfo::numberOfRegisters + i), GPRInfo::regT0);
 260         loadDouble(Address(GPRInfo::regT0), FPRInfo::toRegister(i));
 261     }
 262     for (unsigned i = 0; i &lt; GPRInfo::numberOfRegisters; ++i) {
 263 #if USE(JSVALUE64)
 264         load64(buffer + i, GPRInfo::toRegister(i));
 265 #else
 266         load32(buffer + i, GPRInfo::toRegister(i));
 267 #endif
 268     }
 269 }
 270 
 271 AssemblyHelpers::Jump AssemblyHelpers::emitJumpIfException(VM&amp; vm)
 272 {
 273     return emitExceptionCheck(vm, NormalExceptionCheck);
 274 }
 275 
</pre>
<hr />
<pre>
 298 
 299 AssemblyHelpers::Jump AssemblyHelpers::emitNonPatchableExceptionCheck(VM&amp; vm)
 300 {
 301     callExceptionFuzz(vm);
 302 
 303     Jump result;
 304 #if USE(JSVALUE64)
 305     result = branchTest64(NonZero, AbsoluteAddress(vm.addressOfException()));
 306 #elif USE(JSVALUE32_64)
 307     result = branch32(NotEqual, AbsoluteAddress(vm.addressOfException()), TrustedImm32(0));
 308 #endif
 309 
 310     return result;
 311 }
 312 
 313 void AssemblyHelpers::emitStoreStructureWithTypeInfo(AssemblyHelpers&amp; jit, TrustedImmPtr structure, RegisterID dest)
 314 {
 315     const Structure* structurePtr = reinterpret_cast&lt;const Structure*&gt;(structure.m_value);
 316 #if USE(JSVALUE64)
 317     jit.store64(TrustedImm64(structurePtr-&gt;idBlob()), MacroAssembler::Address(dest, JSCell::structureIDOffset()));
<span class="line-modified"> 318     if (ASSERT_ENABLED) {</span>
 319         Jump correctStructure = jit.branch32(Equal, MacroAssembler::Address(dest, JSCell::structureIDOffset()), TrustedImm32(structurePtr-&gt;id()));
 320         jit.abortWithReason(AHStructureIDIsValid);
 321         correctStructure.link(&amp;jit);
 322 
 323         Jump correctIndexingType = jit.branch8(Equal, MacroAssembler::Address(dest, JSCell::indexingTypeAndMiscOffset()), TrustedImm32(structurePtr-&gt;indexingModeIncludingHistory()));
 324         jit.abortWithReason(AHIndexingTypeIsValid);
 325         correctIndexingType.link(&amp;jit);
 326 
 327         Jump correctType = jit.branch8(Equal, MacroAssembler::Address(dest, JSCell::typeInfoTypeOffset()), TrustedImm32(structurePtr-&gt;typeInfo().type()));
 328         jit.abortWithReason(AHTypeInfoIsValid);
 329         correctType.link(&amp;jit);
 330 
 331         Jump correctFlags = jit.branch8(Equal, MacroAssembler::Address(dest, JSCell::typeInfoFlagsOffset()), TrustedImm32(structurePtr-&gt;typeInfo().inlineTypeFlags()));
 332         jit.abortWithReason(AHTypeInfoInlineTypeFlagsAreValid);
 333         correctFlags.link(&amp;jit);
 334     }
 335 #else
 336     // Do a 32-bit wide store to initialize the cell&#39;s fields.
 337     jit.store32(TrustedImm32(structurePtr-&gt;objectInitializationBlob()), MacroAssembler::Address(dest, JSCell::indexingTypeAndMiscOffset()));
 338     jit.storePtr(structure, MacroAssembler::Address(dest, JSCell::structureIDOffset()));
</pre>
<hr />
<pre>
 430     // x ^= y ^ (y &gt;&gt; 26);
 431     jit.move(scratch1, scratch2);
 432     jit.rshift64(AssemblyHelpers::TrustedImm32(26), scratch2);
 433     jit.xor64(scratch1, scratch2);
 434     jit.xor64(scratch2, scratch0);
 435 
 436     // m_high = x;
 437     storeToHigh(scratch0);
 438 
 439     // return x + y;
 440     jit.add64(scratch1, scratch0);
 441 
 442     // Extract random 53bit. [0, 53] bit is safe integer number ranges in double representation.
 443     jit.move(AssemblyHelpers::TrustedImm64((1ULL &lt;&lt; 53) - 1), scratch1);
 444     jit.and64(scratch1, scratch0);
 445     // Now, scratch0 is always in range of int64_t. Safe to convert it to double with cvtsi2sdq.
 446     jit.convertInt64ToDouble(scratch0, result);
 447 
 448     // Convert `(53bit double integer value) / (1 &lt;&lt; 53)` to `(53bit double integer value) * (1.0 / (1 &lt;&lt; 53))`.
 449     // In latter case, `1.0 / (1 &lt;&lt; 53)` will become a double value represented as (mantissa = 0 &amp; exp = 970, it means 1e-(2**54)).
<span class="line-modified"> 450     static constexpr double scale = 1.0 / (1ULL &lt;&lt; 53);</span>
 451 
 452     // Multiplying 1e-(2**54) with the double integer does not change anything of the mantissa part of the double integer.
 453     // It just reduces the exp part of the given 53bit double integer.
 454     // (Except for 0.0. This is specially handled and in this case, exp just becomes 0.)
 455     // Now we get 53bit precision random double value in [0, 1).
 456     jit.move(AssemblyHelpers::TrustedImmPtr(&amp;scale), scratch1);
 457     jit.mulDouble(AssemblyHelpers::Address(scratch1), result);
 458 }
 459 
 460 void AssemblyHelpers::emitRandomThunk(JSGlobalObject* globalObject, GPRReg scratch0, GPRReg scratch1, GPRReg scratch2, FPRReg result)
 461 {
 462     void* lowAddress = reinterpret_cast&lt;uint8_t*&gt;(globalObject) + JSGlobalObject::weakRandomOffset() + WeakRandom::lowOffset();
 463     void* highAddress = reinterpret_cast&lt;uint8_t*&gt;(globalObject) + JSGlobalObject::weakRandomOffset() + WeakRandom::highOffset();
 464 
 465     auto loadFromHigh = [&amp;](GPRReg high) {
 466         load64(highAddress, high);
 467     };
 468     auto storeToHigh = [&amp;](GPRReg high) {
 469         store64(high, highAddress);
 470     };
</pre>
<hr />
<pre>
 608         if (dontRestoreRegisters.get(entry.reg()))
 609             continue;
 610         if (entry.reg().isGPR()) {
 611             if (i != scratchGPREntryIndex)
 612                 loadPtr(Address(scratch, entry.offset()), entry.reg().gpr());
 613         } else
 614             loadDouble(Address(scratch, entry.offset()), entry.reg().fpr());
 615     }
 616 
 617     // Restore the callee save value of the scratch.
 618     RegisterAtOffset entry = allCalleeSaves-&gt;at(scratchGPREntryIndex);
 619     ASSERT(!dontRestoreRegisters.get(entry.reg()));
 620     ASSERT(entry.reg().isGPR());
 621     ASSERT(scratch == entry.reg().gpr());
 622     loadPtr(Address(scratch, entry.offset()), scratch);
 623 #else
 624     UNUSED_PARAM(topEntryFrame);
 625 #endif
 626 }
 627 
<span class="line-modified"> 628 void AssemblyHelpers::emitDumbVirtualCall(VM&amp; vm, JSGlobalObject* globalObject, CallLinkInfo* info)</span>
 629 {
 630     move(TrustedImmPtr(info), GPRInfo::regT2);
<span class="line-added"> 631     move(TrustedImmPtr(globalObject), GPRInfo::regT3);</span>
 632     Call call = nearCall();
 633     addLinkTask(
 634         [=, &amp;vm] (LinkBuffer&amp; linkBuffer) {
 635             MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; virtualThunk = virtualThunkFor(vm, *info);
<span class="line-modified"> 636             info-&gt;setSlowStub(GCAwareJITStubRoutine::create(virtualThunk, vm));</span>
 637             linkBuffer.link(call, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(virtualThunk.code()));
 638         });
 639 }
 640 
 641 #if USE(JSVALUE64)
 642 void AssemblyHelpers::wangsInt64Hash(GPRReg inputAndResult, GPRReg scratch)
 643 {
 644     GPRReg input = inputAndResult;
 645     // key += ~(key &lt;&lt; 32);
 646     move(input, scratch);
 647     lshift64(TrustedImm32(32), scratch);
 648     not64(scratch);
 649     add64(scratch, input);
 650     // key ^= (key &gt;&gt; 22);
 651     move(input, scratch);
 652     urshift64(TrustedImm32(22), scratch);
 653     xor64(scratch, input);
 654     // key += ~(key &lt;&lt; 13);
 655     move(input, scratch);
 656     lshift64(TrustedImm32(13), scratch);
</pre>
<hr />
<pre>
 736 
 737     notCell.link(this);
 738     auto notInt32 = branchIfNotInt32(value);
 739     compare32(invert ? Equal : NotEqual, value.payloadGPR(), TrustedImm32(0), result);
 740     done.append(jump());
 741 
 742     notInt32.link(this);
 743     auto notDouble = branchIfNotDoubleKnownNotInt32(value);
 744 #if USE(JSVALUE64)
 745     unboxDouble(value.gpr(), result, valueAsFPR);
 746 #else
 747     unboxDouble(value, valueAsFPR, tempFPR);
 748 #endif
 749     move(invert ? TrustedImm32(1) : TrustedImm32(0), result);
 750     done.append(branchDoubleZeroOrNaN(valueAsFPR, tempFPR));
 751     move(invert ? TrustedImm32(0) : TrustedImm32(1), result);
 752     done.append(jump());
 753 
 754     notDouble.link(this);
 755 #if USE(JSVALUE64)
<span class="line-modified"> 756     compare64(invert ? NotEqual : Equal, value.gpr(), TrustedImm32(JSValue::ValueTrue), result);</span>

 757 #else
 758     move(invert ? TrustedImm32(1) : TrustedImm32(0), result);
 759     done.append(branchIfNotBoolean(value, InvalidGPRReg));
 760     compare32(invert ? Equal : NotEqual, value.payloadGPR(), TrustedImm32(0), result);
 761 #endif
 762 
 763     done.link(this);
 764 }
 765 
 766 AssemblyHelpers::JumpList AssemblyHelpers::branchIfValue(VM&amp; vm, JSValueRegs value, GPRReg scratch, GPRReg scratchIfShouldCheckMasqueradesAsUndefined, FPRReg valueAsFPR, FPRReg tempFPR, bool shouldCheckMasqueradesAsUndefined, JSGlobalObject* globalObject, bool invert)
 767 {
 768     // Implements the following control flow structure:
 769     // if (value is cell) {
 770     //     if (value is string or value is BigInt)
 771     //         result = !!value-&gt;length
 772     //     else {
 773     //         do evil things for masquerades-as-undefined
 774     //         result = true
 775     //     }
 776     // } else if (value is int32) {
</pre>
<hr />
<pre>
 912         store64(GPRInfo::toRegister(i), buffer + i);
 913 #else
 914         store32(GPRInfo::toRegister(i), buffer + i);
 915 #endif
 916     }
 917 
 918     for (unsigned i = 0; i &lt; FPRInfo::numberOfRegisters; ++i) {
 919         move(TrustedImmPtr(buffer + GPRInfo::numberOfRegisters + i), GPRInfo::regT0);
 920         storeDouble(FPRInfo::toRegister(i), GPRInfo::regT0);
 921     }
 922 
 923     // Tell GC mark phase how much of the scratch buffer is active during call.
 924     move(TrustedImmPtr(scratchBuffer-&gt;addressOfActiveLength()), GPRInfo::regT0);
 925     storePtr(TrustedImmPtr(scratchSize), GPRInfo::regT0);
 926 
 927 #if CPU(X86_64) || CPU(ARM_THUMB2) || CPU(ARM64) || CPU(MIPS)
 928     move(TrustedImmPtr(buffer), GPRInfo::argumentGPR2);
 929     move(TrustedImmPtr(argument), GPRInfo::argumentGPR1);
 930     move(GPRInfo::callFrameRegister, GPRInfo::argumentGPR0);
 931     GPRReg scratch = selectScratchGPR(GPRInfo::argumentGPR0, GPRInfo::argumentGPR1, GPRInfo::argumentGPR2);





 932 #else
 933 #error &quot;JIT not supported on this platform.&quot;
 934 #endif
<span class="line-added"> 935     prepareCallOperation(vm);</span>
 936     move(TrustedImmPtr(tagCFunctionPtr&lt;OperationPtrTag&gt;(function)), scratch);
 937     call(scratch, OperationPtrTag);
 938 
 939     move(TrustedImmPtr(scratchBuffer-&gt;addressOfActiveLength()), GPRInfo::regT0);
 940     storePtr(TrustedImmPtr(nullptr), GPRInfo::regT0);
 941 
 942     for (unsigned i = 0; i &lt; FPRInfo::numberOfRegisters; ++i) {
 943         move(TrustedImmPtr(buffer + GPRInfo::numberOfRegisters + i), GPRInfo::regT0);
 944         loadDouble(GPRInfo::regT0, FPRInfo::toRegister(i));
 945     }
 946     for (unsigned i = 0; i &lt; GPRInfo::numberOfRegisters; ++i) {
 947 #if USE(JSVALUE64)
 948         load64(buffer + i, GPRInfo::toRegister(i));
 949 #else
 950         load32(buffer + i, GPRInfo::toRegister(i));
 951 #endif
 952     }
 953 }
 954 
 955 void AssemblyHelpers::copyCalleeSavesToEntryFrameCalleeSavesBufferImpl(GPRReg calleeSavesBuffer)
</pre>
<hr />
<pre>
 971             storeDouble(entry.reg().fpr(), Address(calleeSavesBuffer, entry.offset()));
 972     }
 973 #else
 974     UNUSED_PARAM(calleeSavesBuffer);
 975 #endif
 976 }
 977 
 978 void AssemblyHelpers::sanitizeStackInline(VM&amp; vm, GPRReg scratch)
 979 {
 980     loadPtr(vm.addressOfLastStackTop(), scratch);
 981     Jump done = branchPtr(BelowOrEqual, stackPointerRegister, scratch);
 982     Label loop = label();
 983     storePtr(TrustedImmPtr(nullptr), scratch);
 984     addPtr(TrustedImmPtr(sizeof(void*)), scratch);
 985     branchPtr(Above, stackPointerRegister, scratch).linkTo(loop, this);
 986     done.link(this);
 987     move(stackPointerRegister, scratch);
 988     storePtr(scratch, vm.addressOfLastStackTop());
 989 }
 990 












 991 } // namespace JSC
 992 
 993 #endif // ENABLE(JIT)
 994 
</pre>
</td>
</tr>
</table>
<center><a href="../interpreter/VMEntryRecord.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="AssemblyHelpers.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>