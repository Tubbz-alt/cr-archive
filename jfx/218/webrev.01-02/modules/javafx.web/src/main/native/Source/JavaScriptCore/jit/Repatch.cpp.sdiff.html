<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/Repatch.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="RegisterSet.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="Repatch.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/Repatch.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (C) 2011-2019 Apple Inc. All rights reserved.</span>
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;Repatch.h&quot;
  28 
  29 #if ENABLE(JIT)
  30 
  31 #include &quot;BinarySwitch.h&quot;
  32 #include &quot;CCallHelpers.h&quot;

  33 #include &quot;CallFrameShuffler.h&quot;
  34 #include &quot;DFGOperations.h&quot;
  35 #include &quot;DFGSpeculativeJIT.h&quot;
  36 #include &quot;DOMJITGetterSetter.h&quot;
  37 #include &quot;DirectArguments.h&quot;
  38 #include &quot;ExecutableBaseInlines.h&quot;
  39 #include &quot;FTLThunks.h&quot;
  40 #include &quot;FullCodeOrigin.h&quot;
  41 #include &quot;FunctionCodeBlock.h&quot;
  42 #include &quot;GCAwareJITStubRoutine.h&quot;
  43 #include &quot;GetterSetter.h&quot;
  44 #include &quot;GetterSetterAccessCase.h&quot;
  45 #include &quot;ICStats.h&quot;
  46 #include &quot;InlineAccess.h&quot;
  47 #include &quot;InstanceOfAccessCase.h&quot;
  48 #include &quot;IntrinsicGetterAccessCase.h&quot;
  49 #include &quot;JIT.h&quot;
  50 #include &quot;JITInlines.h&quot;
  51 #include &quot;JSCInlines.h&quot;
  52 #include &quot;JSModuleNamespaceObject.h&quot;
  53 #include &quot;JSWebAssembly.h&quot;
  54 #include &quot;JSWebAssemblyModule.h&quot;
  55 #include &quot;LinkBuffer.h&quot;
  56 #include &quot;ModuleNamespaceAccessCase.h&quot;
  57 #include &quot;PolymorphicAccess.h&quot;
  58 #include &quot;ScopedArguments.h&quot;
  59 #include &quot;ScratchRegisterAllocator.h&quot;
  60 #include &quot;StackAlignment.h&quot;
  61 #include &quot;StructureRareDataInlines.h&quot;
  62 #include &quot;StructureStubClearingWatchpoint.h&quot;
  63 #include &quot;StructureStubInfo.h&quot;
  64 #include &quot;SuperSampler.h&quot;
  65 #include &quot;ThunkGenerators.h&quot;
  66 #include &quot;WebAssemblyFunction.h&quot;
<span class="line-removed">  67 #include &quot;WebAssemblyToJSCallee.h&quot;</span>
  68 #include &lt;wtf/CommaPrinter.h&gt;
  69 #include &lt;wtf/ListDump.h&gt;
  70 #include &lt;wtf/StringPrintStream.h&gt;
  71 
  72 namespace JSC {
  73 
  74 static FunctionPtr&lt;CFunctionPtrTag&gt; readPutICCallTarget(CodeBlock* codeBlock, CodeLocationCall&lt;JSInternalPtrTag&gt; call)
  75 {
  76     FunctionPtr&lt;OperationPtrTag&gt; target = MacroAssembler::readCallTarget&lt;OperationPtrTag&gt;(call);
  77 #if ENABLE(FTL_JIT)
  78     if (codeBlock-&gt;jitType() == JITType::FTLJIT) {
  79         MacroAssemblerCodePtr&lt;JITThunkPtrTag&gt; thunk = MacroAssemblerCodePtr&lt;OperationPtrTag&gt;::createFromExecutableAddress(target.executableAddress()).retagged&lt;JITThunkPtrTag&gt;();
  80         return codeBlock-&gt;vm().ftlThunks-&gt;keyForSlowPathCallThunk(thunk).callTarget().retagged&lt;CFunctionPtrTag&gt;();
  81     }
  82 #else
  83     UNUSED_PARAM(codeBlock);
  84 #endif // ENABLE(FTL_JIT)
  85     return target.retagged&lt;CFunctionPtrTag&gt;();
  86 }
  87 
  88 void ftlThunkAwareRepatchCall(CodeBlock* codeBlock, CodeLocationCall&lt;JSInternalPtrTag&gt; call, FunctionPtr&lt;CFunctionPtrTag&gt; newCalleeFunction)
  89 {
  90 #if ENABLE(FTL_JIT)
  91     if (codeBlock-&gt;jitType() == JITType::FTLJIT) {
  92         VM&amp; vm = codeBlock-&gt;vm();
  93         FTL::Thunks&amp; thunks = *vm.ftlThunks;
  94         FunctionPtr&lt;OperationPtrTag&gt; target = MacroAssembler::readCallTarget&lt;OperationPtrTag&gt;(call);
  95         auto slowPathThunk = MacroAssemblerCodePtr&lt;JITThunkPtrTag&gt;::createFromExecutableAddress(target.retaggedExecutableAddress&lt;JITThunkPtrTag&gt;());
  96         FTL::SlowPathCallKey key = thunks.keyForSlowPathCallThunk(slowPathThunk);
  97         key = key.withCallTarget(newCalleeFunction);
<span class="line-modified">  98         MacroAssembler::repatchCall(call, FunctionPtr&lt;OperationPtrTag&gt;(thunks.getSlowPathCallThunk(key).retaggedCode&lt;OperationPtrTag&gt;()));</span>
  99         return;
 100     }
 101 #else // ENABLE(FTL_JIT)
 102     UNUSED_PARAM(codeBlock);
 103 #endif // ENABLE(FTL_JIT)
 104     MacroAssembler::repatchCall(call, newCalleeFunction.retagged&lt;OperationPtrTag&gt;());
 105 }
 106 
 107 enum InlineCacheAction {
 108     GiveUpOnCache,
 109     RetryCacheLater,
 110     AttemptToCache
 111 };
 112 
 113 static InlineCacheAction actionForCell(VM&amp; vm, JSCell* cell)
 114 {
 115     Structure* structure = cell-&gt;structure(vm);
 116 
 117     TypeInfo typeInfo = structure-&gt;typeInfo();
 118     if (typeInfo.prohibitsPropertyCaching())
 119         return GiveUpOnCache;
 120 
 121     if (structure-&gt;isUncacheableDictionary()) {
 122         if (structure-&gt;hasBeenFlattenedBefore())
 123             return GiveUpOnCache;
 124         // Flattening could have changed the offset, so return early for another try.
 125         asObject(cell)-&gt;flattenDictionaryObject(vm);
 126         return RetryCacheLater;
 127     }
 128 
 129     if (!structure-&gt;propertyAccessesAreCacheable())
 130         return GiveUpOnCache;
 131 
 132     return AttemptToCache;
 133 }
 134 
<span class="line-modified"> 135 static bool forceICFailure(ExecState*)</span>
 136 {
 137     return Options::forceICFailure();
 138 }
 139 
 140 ALWAYS_INLINE static void fireWatchpointsAndClearStubIfNeeded(VM&amp; vm, StructureStubInfo&amp; stubInfo, CodeBlock* codeBlock, AccessGenerationResult&amp; result)
 141 {
 142     if (result.shouldResetStubAndFireWatchpoints()) {
 143         result.fireWatchpoints(vm);
 144         stubInfo.reset(codeBlock);
 145     }
 146 }
 147 
<span class="line-modified"> 148 inline FunctionPtr&lt;CFunctionPtrTag&gt; appropriateOptimizingGetByIdFunction(GetByIDKind kind)</span>
 149 {
 150     switch (kind) {
<span class="line-modified"> 151     case GetByIDKind::Normal:</span>
 152         return operationGetByIdOptimize;
<span class="line-modified"> 153     case GetByIDKind::WithThis:</span>
 154         return operationGetByIdWithThisOptimize;
<span class="line-modified"> 155     case GetByIDKind::Try:</span>
 156         return operationTryGetByIdOptimize;
<span class="line-modified"> 157     case GetByIDKind::Direct:</span>
 158         return operationGetByIdDirectOptimize;


 159     }
<span class="line-modified"> 160     ASSERT_NOT_REACHED();</span>
<span class="line-removed"> 161     return operationGetById;</span>
 162 }
 163 
<span class="line-modified"> 164 inline FunctionPtr&lt;CFunctionPtrTag&gt; appropriateGetByIdFunction(GetByIDKind kind)</span>
 165 {
 166     switch (kind) {
<span class="line-modified"> 167     case GetByIDKind::Normal:</span>
 168         return operationGetById;
<span class="line-modified"> 169     case GetByIDKind::WithThis:</span>
 170         return operationGetByIdWithThis;
<span class="line-modified"> 171     case GetByIDKind::Try:</span>
 172         return operationTryGetById;
<span class="line-modified"> 173     case GetByIDKind::Direct:</span>
 174         return operationGetByIdDirect;


 175     }
<span class="line-modified"> 176     ASSERT_NOT_REACHED();</span>
<span class="line-removed"> 177     return operationGetById;</span>
 178 }
 179 
<span class="line-modified"> 180 static InlineCacheAction tryCacheGetByID(ExecState* exec, JSValue baseValue, const Identifier&amp; propertyName, const PropertySlot&amp; slot, StructureStubInfo&amp; stubInfo, GetByIDKind kind)</span>
 181 {
<span class="line-modified"> 182     VM&amp; vm = exec-&gt;vm();</span>
 183     AccessGenerationResult result;
 184 
 185     {
<span class="line-modified"> 186         GCSafeConcurrentJSLocker locker(exec-&gt;codeBlock()-&gt;m_lock, exec-&gt;vm().heap);</span>
 187 
<span class="line-modified"> 188         if (forceICFailure(exec))</span>
 189             return GiveUpOnCache;
 190 
 191         // FIXME: Cache property access for immediates.
 192         if (!baseValue.isCell())
 193             return GiveUpOnCache;
 194         JSCell* baseCell = baseValue.asCell();
 195 
<span class="line-removed"> 196         CodeBlock* codeBlock = exec-&gt;codeBlock();</span>
<span class="line-removed"> 197 </span>
 198         std::unique_ptr&lt;AccessCase&gt; newCase;
 199 
 200         if (propertyName == vm.propertyNames-&gt;length) {
 201             if (isJSArray(baseCell)) {
<span class="line-modified"> 202                 if (stubInfo.cacheType == CacheType::Unset</span>
 203                     &amp;&amp; slot.slotBase() == baseCell
 204                     &amp;&amp; InlineAccess::isCacheableArrayLength(stubInfo, jsCast&lt;JSArray*&gt;(baseCell))) {
 205 
 206                     bool generatedCodeInline = InlineAccess::generateArrayLength(stubInfo, jsCast&lt;JSArray*&gt;(baseCell));
 207                     if (generatedCodeInline) {
<span class="line-modified"> 208                         ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), appropriateOptimizingGetByIdFunction(kind));</span>
 209                         stubInfo.initArrayLength();
 210                         return RetryCacheLater;
 211                     }
 212                 }
 213 
<span class="line-modified"> 214                 newCase = AccessCase::create(vm, codeBlock, AccessCase::ArrayLength);</span>
 215             } else if (isJSString(baseCell)) {
<span class="line-modified"> 216                 if (stubInfo.cacheType == CacheType::Unset &amp;&amp; InlineAccess::isCacheableStringLength(stubInfo)) {</span>
 217                     bool generatedCodeInline = InlineAccess::generateStringLength(stubInfo);
 218                     if (generatedCodeInline) {
<span class="line-modified"> 219                         ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), appropriateOptimizingGetByIdFunction(kind));</span>
 220                         stubInfo.initStringLength();
 221                         return RetryCacheLater;
 222                     }
 223                 }
 224 
<span class="line-modified"> 225                 newCase = AccessCase::create(vm, codeBlock, AccessCase::StringLength);</span>
<span class="line-modified"> 226             }</span>
<span class="line-removed"> 227             else if (DirectArguments* arguments = jsDynamicCast&lt;DirectArguments*&gt;(vm, baseCell)) {</span>
 228                 // If there were overrides, then we can handle this as a normal property load! Guarding
 229                 // this with such a check enables us to add an IC case for that load if needed.
 230                 if (!arguments-&gt;overrodeThings())
<span class="line-modified"> 231                     newCase = AccessCase::create(vm, codeBlock, AccessCase::DirectArgumentsLength);</span>
 232             } else if (ScopedArguments* arguments = jsDynamicCast&lt;ScopedArguments*&gt;(vm, baseCell)) {
 233                 // Ditto.
 234                 if (!arguments-&gt;overrodeThings())
<span class="line-modified"> 235                     newCase = AccessCase::create(vm, codeBlock, AccessCase::ScopedArgumentsLength);</span>
 236             }
 237         }
 238 
 239         if (!propertyName.isSymbol() &amp;&amp; baseCell-&gt;inherits&lt;JSModuleNamespaceObject&gt;(vm) &amp;&amp; !slot.isUnset()) {
 240             if (auto moduleNamespaceSlot = slot.moduleNamespaceSlot())
<span class="line-modified"> 241                 newCase = ModuleNamespaceAccessCase::create(vm, codeBlock, jsCast&lt;JSModuleNamespaceObject*&gt;(baseCell), moduleNamespaceSlot-&gt;environment, ScopeOffset(moduleNamespaceSlot-&gt;scopeOffset));</span>
 242         }
 243 
 244         if (!newCase) {
 245             if (!slot.isCacheable() &amp;&amp; !slot.isUnset())
 246                 return GiveUpOnCache;
 247 
 248             ObjectPropertyConditionSet conditionSet;
 249             Structure* structure = baseCell-&gt;structure(vm);
 250 
 251             bool loadTargetFromProxy = false;
 252             if (baseCell-&gt;type() == PureForwardingProxyType) {
 253                 baseValue = jsCast&lt;JSProxy*&gt;(baseCell)-&gt;target();
 254                 baseCell = baseValue.asCell();
 255                 structure = baseCell-&gt;structure(vm);
 256                 loadTargetFromProxy = true;
 257             }
 258 
 259             InlineCacheAction action = actionForCell(vm, baseCell);
 260             if (action != AttemptToCache)
 261                 return action;
 262 
 263             // Optimize self access.
<span class="line-modified"> 264             if (stubInfo.cacheType == CacheType::Unset</span>
 265                 &amp;&amp; slot.isCacheableValue()
 266                 &amp;&amp; slot.slotBase() == baseValue
 267                 &amp;&amp; !slot.watchpointSet()
 268                 &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()
 269                 &amp;&amp; !loadTargetFromProxy) {
 270 
 271                 bool generatedCodeInline = InlineAccess::generateSelfPropertyAccess(stubInfo, structure, slot.cachedOffset());
 272                 if (generatedCodeInline) {
<span class="line-modified"> 273                     LOG_IC((ICEvent::GetByIdSelfPatch, structure-&gt;classInfo(), propertyName, slot.slotBase() == baseValue));</span>
 274                     structure-&gt;startWatchingPropertyForReplacements(vm, slot.cachedOffset());
<span class="line-modified"> 275                     ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), appropriateOptimizingGetByIdFunction(kind));</span>
<span class="line-modified"> 276                     stubInfo.initGetByIdSelf(codeBlock, structure, slot.cachedOffset());</span>
 277                     return RetryCacheLater;
 278                 }
 279             }
 280 
 281             std::unique_ptr&lt;PolyProtoAccessChain&gt; prototypeAccessChain;
 282 
 283             PropertyOffset offset = slot.isUnset() ? invalidOffset : slot.cachedOffset();
 284 









 285             if (slot.isUnset() || slot.slotBase() != baseValue) {
 286                 if (structure-&gt;typeInfo().prohibitsPropertyCaching())
 287                     return GiveUpOnCache;
 288 
 289                 if (structure-&gt;isDictionary()) {
 290                     if (structure-&gt;hasBeenFlattenedBefore())
 291                         return GiveUpOnCache;
 292                     structure-&gt;flattenDictionaryStructure(vm, jsCast&lt;JSObject*&gt;(baseCell));

 293                 }
 294 
 295                 if (slot.isUnset() &amp;&amp; structure-&gt;typeInfo().getOwnPropertySlotIsImpureForPropertyAbsence())
 296                     return GiveUpOnCache;
 297 
<span class="line-modified"> 298                 // If a kind is GetByIDKind::Direct, we do not need to investigate prototype chains further.</span>
 299                 // Cacheability just depends on the head structure.
<span class="line-modified"> 300                 if (kind != GetByIDKind::Direct) {</span>
<span class="line-modified"> 301                     bool usesPolyProto;</span>
<span class="line-modified"> 302                     prototypeAccessChain = PolyProtoAccessChain::create(exec-&gt;lexicalGlobalObject(), baseCell, slot, usesPolyProto);</span>
<span class="line-removed"> 303                     if (!prototypeAccessChain) {</span>
<span class="line-removed"> 304                         // It&#39;s invalid to access this prototype property.</span>
 305                         return GiveUpOnCache;




 306                     }
 307 
<span class="line-modified"> 308                     if (!usesPolyProto) {</span>





 309                         // We use ObjectPropertyConditionSet instead for faster accesses.
 310                         prototypeAccessChain = nullptr;
 311 
 312                         // FIXME: Maybe this `if` should be inside generateConditionsForPropertyBlah.
 313                         // https://bugs.webkit.org/show_bug.cgi?id=185215
 314                         if (slot.isUnset()) {
 315                             conditionSet = generateConditionsForPropertyMiss(
<span class="line-modified"> 316                                 vm, codeBlock, exec, structure, propertyName.impl());</span>
 317                         } else if (!slot.isCacheableCustom()) {
 318                             conditionSet = generateConditionsForPrototypePropertyHit(
<span class="line-modified"> 319                                 vm, codeBlock, exec, structure, slot.slotBase(),</span>
<span class="line-modified"> 320                                 propertyName.impl());</span>

 321                         } else {
 322                             conditionSet = generateConditionsForPrototypePropertyHitCustom(
<span class="line-modified"> 323                                 vm, codeBlock, exec, structure, slot.slotBase(),</span>
<span class="line-modified"> 324                                 propertyName.impl());</span>
 325                         }
 326 
 327                         if (!conditionSet.isValid())
 328                             return GiveUpOnCache;
 329                     }
 330                 }
<span class="line-removed"> 331 </span>
<span class="line-removed"> 332                 offset = slot.isUnset() ? invalidOffset : slot.cachedOffset();</span>
 333             }
 334 
 335             JSFunction* getter = nullptr;
 336             if (slot.isCacheableGetter())
 337                 getter = jsDynamicCast&lt;JSFunction*&gt;(vm, slot.getterSetter()-&gt;getter());
 338 
 339             Optional&lt;DOMAttributeAnnotation&gt; domAttribute;
 340             if (slot.isCacheableCustom() &amp;&amp; slot.domAttribute())
 341                 domAttribute = slot.domAttribute();
 342 
<span class="line-modified"> 343             if (kind == GetByIDKind::Try) {</span>
 344                 AccessCase::AccessType type;
 345                 if (slot.isCacheableValue())
 346                     type = AccessCase::Load;
 347                 else if (slot.isUnset())
 348                     type = AccessCase::Miss;
 349                 else if (slot.isCacheableGetter())
 350                     type = AccessCase::GetGetter;
 351                 else
 352                     RELEASE_ASSERT_NOT_REACHED();
 353 
<span class="line-modified"> 354                 newCase = ProxyableAccessCase::create(vm, codeBlock, type, offset, structure, conditionSet, loadTargetFromProxy, slot.watchpointSet(), WTFMove(prototypeAccessChain));</span>
 355             } else if (!loadTargetFromProxy &amp;&amp; getter &amp;&amp; IntrinsicGetterAccessCase::canEmitIntrinsicGetter(getter, structure))
<span class="line-modified"> 356                 newCase = IntrinsicGetterAccessCase::create(vm, codeBlock, slot.cachedOffset(), structure, conditionSet, getter, WTFMove(prototypeAccessChain));</span>
 357             else {
 358                 if (slot.isCacheableValue() || slot.isUnset()) {
 359                     newCase = ProxyableAccessCase::create(vm, codeBlock, slot.isUnset() ? AccessCase::Miss : AccessCase::Load,
<span class="line-modified"> 360                         offset, structure, conditionSet, loadTargetFromProxy, slot.watchpointSet(), WTFMove(prototypeAccessChain));</span>
 361                 } else {
 362                     AccessCase::AccessType type;
 363                     if (slot.isCacheableGetter())
 364                         type = AccessCase::Getter;
 365                     else if (slot.attributes() &amp; PropertyAttribute::CustomAccessor)
 366                         type = AccessCase::CustomAccessorGetter;
 367                     else
 368                         type = AccessCase::CustomValueGetter;
 369 
<span class="line-modified"> 370                     if (kind == GetByIDKind::WithThis &amp;&amp; type == AccessCase::CustomAccessorGetter &amp;&amp; domAttribute)</span>
 371                         return GiveUpOnCache;
 372 
 373                     newCase = GetterSetterAccessCase::create(
<span class="line-modified"> 374                         vm, codeBlock, type, offset, structure, conditionSet, loadTargetFromProxy,</span>
 375                         slot.watchpointSet(), slot.isCacheableCustom() ? slot.customGetter() : nullptr,
 376                         slot.isCacheableCustom() &amp;&amp; slot.slotBase() != baseValue ? slot.slotBase() : nullptr,
 377                         domAttribute, WTFMove(prototypeAccessChain));
 378                 }
 379             }
 380         }
 381 
<span class="line-modified"> 382         LOG_IC((ICEvent::GetByIdAddAccessCase, baseValue.classInfoOrNull(vm), propertyName, slot.slotBase() == baseValue));</span>
 383 
 384         result = stubInfo.addAccessCase(locker, codeBlock, propertyName, WTFMove(newCase));
 385 
 386         if (result.generatedSomeCode()) {
<span class="line-modified"> 387             LOG_IC((ICEvent::GetByIdReplaceWithJump, baseValue.classInfoOrNull(vm), propertyName, slot.slotBase() == baseValue));</span>
 388 
 389             RELEASE_ASSERT(result.code());
 390             InlineAccess::rewireStubAsJump(stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));
 391         }
 392     }
 393 
<span class="line-modified"> 394     fireWatchpointsAndClearStubIfNeeded(vm, stubInfo, exec-&gt;codeBlock(), result);</span>
 395 
 396     return result.shouldGiveUpNow() ? GiveUpOnCache : RetryCacheLater;
 397 }
 398 
<span class="line-modified"> 399 void repatchGetByID(ExecState* exec, JSValue baseValue, const Identifier&amp; propertyName, const PropertySlot&amp; slot, StructureStubInfo&amp; stubInfo, GetByIDKind kind)</span>
 400 {
 401     SuperSamplerScope superSamplerScope(false);
 402 
<span class="line-modified"> 403     if (tryCacheGetByID(exec, baseValue, propertyName, slot, stubInfo, kind) == GiveUpOnCache) {</span>
<span class="line-modified"> 404         CodeBlock* codeBlock = exec-&gt;codeBlock();</span>
<span class="line-modified"> 405         ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), appropriateGetByIdFunction(kind));</span>





















































































 406     }









 407 }
 408 
<span class="line-modified"> 409 static V_JITOperation_ESsiJJI appropriateGenericPutByIdFunction(const PutPropertySlot &amp;slot, PutKind putKind)</span>
 410 {
 411     if (slot.isStrictMode()) {
 412         if (putKind == Direct)
 413             return operationPutByIdDirectStrict;
 414         return operationPutByIdStrict;
 415     }
 416     if (putKind == Direct)
 417         return operationPutByIdDirectNonStrict;
 418     return operationPutByIdNonStrict;
 419 }
 420 
<span class="line-modified"> 421 static V_JITOperation_ESsiJJI appropriateOptimizingPutByIdFunction(const PutPropertySlot &amp;slot, PutKind putKind)</span>
 422 {
 423     if (slot.isStrictMode()) {
 424         if (putKind == Direct)
 425             return operationPutByIdDirectStrictOptimize;
 426         return operationPutByIdStrictOptimize;
 427     }
 428     if (putKind == Direct)
 429         return operationPutByIdDirectNonStrictOptimize;
 430     return operationPutByIdNonStrictOptimize;
 431 }
 432 
<span class="line-modified"> 433 static InlineCacheAction tryCachePutByID(ExecState* exec, JSValue baseValue, Structure* structure, const Identifier&amp; ident, const PutPropertySlot&amp; slot, StructureStubInfo&amp; stubInfo, PutKind putKind)</span>
 434 {
<span class="line-modified"> 435     VM&amp; vm = exec-&gt;vm();</span>
 436     AccessGenerationResult result;
 437     {
<span class="line-modified"> 438         GCSafeConcurrentJSLocker locker(exec-&gt;codeBlock()-&gt;m_lock, exec-&gt;vm().heap);</span>
 439 
<span class="line-modified"> 440         if (forceICFailure(exec))</span>
 441             return GiveUpOnCache;
 442 
<span class="line-removed"> 443         CodeBlock* codeBlock = exec-&gt;codeBlock();</span>
<span class="line-removed"> 444 </span>
 445         if (!baseValue.isCell())
 446             return GiveUpOnCache;
 447 
 448         if (!slot.isCacheablePut() &amp;&amp; !slot.isCacheableCustom() &amp;&amp; !slot.isCacheableSetter())
 449             return GiveUpOnCache;
 450 
 451         // FIXME: We should try to do something smarter here...
<span class="line-modified"> 452         if (isCopyOnWrite(structure-&gt;indexingMode()))</span>
 453             return GiveUpOnCache;
 454         // We can&#39;t end up storing to a CoW on the prototype since it shouldn&#39;t own properties.
 455         ASSERT(!isCopyOnWrite(slot.base()-&gt;indexingMode()));
 456 
<span class="line-modified"> 457         if (!structure-&gt;propertyAccessesAreCacheable())</span>
 458             return GiveUpOnCache;
 459 
 460         std::unique_ptr&lt;AccessCase&gt; newCase;
 461         JSCell* baseCell = baseValue.asCell();
 462 
 463         if (slot.base() == baseValue &amp;&amp; slot.isCacheablePut()) {
 464             if (slot.type() == PutPropertySlot::ExistingProperty) {
 465                 // This assert helps catch bugs if we accidentally forget to disable caching
 466                 // when we transition then store to an existing property. This is common among
 467                 // paths that reify lazy properties. If we reify a lazy property and forget
 468                 // to disable caching, we may come down this path. The Replace IC does not
 469                 // know how to model these types of structure transitions (or any structure
 470                 // transition for that matter).
<span class="line-modified"> 471                 RELEASE_ASSERT(baseValue.asCell()-&gt;structure(vm) == structure);</span>
 472 
<span class="line-modified"> 473                 structure-&gt;didCachePropertyReplacement(vm, slot.cachedOffset());</span>
 474 
<span class="line-modified"> 475                 if (stubInfo.cacheType == CacheType::Unset</span>
 476                     &amp;&amp; InlineAccess::canGenerateSelfPropertyReplace(stubInfo, slot.cachedOffset())
<span class="line-modified"> 477                     &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()) {</span>
 478 
<span class="line-modified"> 479                     bool generatedCodeInline = InlineAccess::generateSelfPropertyReplace(stubInfo, structure, slot.cachedOffset());</span>
 480                     if (generatedCodeInline) {
<span class="line-modified"> 481                         LOG_IC((ICEvent::PutByIdSelfPatch, structure-&gt;classInfo(), ident, slot.base() == baseValue));</span>
<span class="line-modified"> 482                         ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), appropriateOptimizingPutByIdFunction(slot, putKind));</span>
<span class="line-modified"> 483                         stubInfo.initPutByIdReplace(codeBlock, structure, slot.cachedOffset());</span>
 484                         return RetryCacheLater;
 485                     }
 486                 }
 487 
<span class="line-modified"> 488                 newCase = AccessCase::create(vm, codeBlock, AccessCase::Replace, slot.cachedOffset(), structure);</span>
 489             } else {
 490                 ASSERT(slot.type() == PutPropertySlot::NewProperty);
 491 
<span class="line-modified"> 492                 if (!structure-&gt;isObject())</span>
 493                     return GiveUpOnCache;
 494 
<span class="line-modified"> 495                 if (structure-&gt;isDictionary()) {</span>
<span class="line-modified"> 496                     if (structure-&gt;hasBeenFlattenedBefore())</span>
<span class="line-modified"> 497                         return GiveUpOnCache;</span>
<span class="line-modified"> 498                     structure-&gt;flattenDictionaryStructure(vm, jsCast&lt;JSObject*&gt;(baseValue));</span>
<span class="line-removed"> 499                 }</span>
 500 
 501                 PropertyOffset offset;
<span class="line-modified"> 502                 Structure* newStructure =</span>
<span class="line-removed"> 503                     Structure::addPropertyTransitionToExistingStructureConcurrently(</span>
<span class="line-removed"> 504                         structure, ident.impl(), 0, offset);</span>
 505                 if (!newStructure || !newStructure-&gt;propertyAccessesAreCacheable())
 506                     return GiveUpOnCache;
 507 
<span class="line-modified"> 508                 ASSERT(newStructure-&gt;previousID() == structure);</span>








 509                 ASSERT(!newStructure-&gt;isDictionary());
 510                 ASSERT(newStructure-&gt;isObject());
 511 
 512                 std::unique_ptr&lt;PolyProtoAccessChain&gt; prototypeAccessChain;
 513                 ObjectPropertyConditionSet conditionSet;
 514                 if (putKind == NotDirect) {
<span class="line-modified"> 515                     bool usesPolyProto;</span>
<span class="line-modified"> 516                     prototypeAccessChain = PolyProtoAccessChain::create(exec-&gt;lexicalGlobalObject(), baseCell, nullptr, usesPolyProto);</span>
<span class="line-removed"> 517                     if (!prototypeAccessChain) {</span>
<span class="line-removed"> 518                         // It&#39;s invalid to access this prototype property.</span>
 519                         return GiveUpOnCache;
<span class="line-removed"> 520                     }</span>
 521 
<span class="line-modified"> 522                     if (!usesPolyProto) {</span>




 523                         prototypeAccessChain = nullptr;
<span class="line-modified"> 524                         conditionSet =</span>
<span class="line-modified"> 525                             generateConditionsForPropertySetterMiss(</span>
<span class="line-removed"> 526                                 vm, codeBlock, exec, newStructure, ident.impl());</span>
 527                         if (!conditionSet.isValid())
 528                             return GiveUpOnCache;
 529                     }
<span class="line-removed"> 530 </span>
 531                 }
 532 
<span class="line-modified"> 533                 newCase = AccessCase::create(vm, codeBlock, offset, structure, newStructure, conditionSet, WTFMove(prototypeAccessChain));</span>
 534             }
 535         } else if (slot.isCacheableCustom() || slot.isCacheableSetter()) {
 536             if (slot.isCacheableCustom()) {
 537                 ObjectPropertyConditionSet conditionSet;
 538                 std::unique_ptr&lt;PolyProtoAccessChain&gt; prototypeAccessChain;
 539 
<span class="line-modified"> 540                 if (slot.base() != baseValue) {</span>
<span class="line-modified"> 541                     bool usesPolyProto;</span>
<span class="line-modified"> 542                     prototypeAccessChain = PolyProtoAccessChain::create(exec-&gt;lexicalGlobalObject(), baseCell, slot.base(), usesPolyProto);</span>
<span class="line-modified"> 543                     if (!prototypeAccessChain) {</span>
<span class="line-modified"> 544                         // It&#39;s invalid to access this prototype property.</span>
<span class="line-modified"> 545                         return GiveUpOnCache;</span>
<span class="line-removed"> 546                     }</span>
 547 
<span class="line-modified"> 548                     if (!usesPolyProto) {</span>





 549                         prototypeAccessChain = nullptr;
<span class="line-modified"> 550                         conditionSet =</span>
<span class="line-modified"> 551                             generateConditionsForPrototypePropertyHitCustom(</span>
<span class="line-removed"> 552                                 vm, codeBlock, exec, structure, slot.base(), ident.impl());</span>
 553                         if (!conditionSet.isValid())
 554                             return GiveUpOnCache;
 555                     }
 556                 }
 557 
 558                 newCase = GetterSetterAccessCase::create(
<span class="line-modified"> 559                     vm, codeBlock, slot.isCustomAccessor() ? AccessCase::CustomAccessorSetter : AccessCase::CustomValueSetter, structure, invalidOffset,</span>
<span class="line-modified"> 560                     conditionSet, WTFMove(prototypeAccessChain), slot.customSetter(), slot.base() != baseValue ? slot.base() : nullptr);</span>
 561             } else {
 562                 ObjectPropertyConditionSet conditionSet;
 563                 std::unique_ptr&lt;PolyProtoAccessChain&gt; prototypeAccessChain;
 564                 PropertyOffset offset = slot.cachedOffset();
 565 
 566                 if (slot.base() != baseValue) {
<span class="line-modified"> 567                     bool usesPolyProto;</span>
<span class="line-modified"> 568                     prototypeAccessChain = PolyProtoAccessChain::create(exec-&gt;lexicalGlobalObject(), baseCell, slot.base(), usesPolyProto);</span>
<span class="line-removed"> 569                     if (!prototypeAccessChain) {</span>
<span class="line-removed"> 570                         // It&#39;s invalid to access this prototype property.</span>
 571                         return GiveUpOnCache;
<span class="line-modified"> 572                     }</span>

 573 
<span class="line-modified"> 574                     if (!usesPolyProto) {</span>





 575                         prototypeAccessChain = nullptr;
<span class="line-modified"> 576                         conditionSet =</span>
<span class="line-modified"> 577                             generateConditionsForPrototypePropertyHit(</span>
<span class="line-removed"> 578                                 vm, codeBlock, exec, structure, slot.base(), ident.impl());</span>
 579                         if (!conditionSet.isValid())
 580                             return GiveUpOnCache;
 581 
 582                         if (!(conditionSet.slotBaseCondition().attributes() &amp; PropertyAttribute::Accessor))
 583                             return GiveUpOnCache;
 584 
 585                         offset = conditionSet.slotBaseCondition().offset();
 586                     }
<span class="line-removed"> 587 </span>
 588                 }
 589 
 590                 newCase = GetterSetterAccessCase::create(
<span class="line-modified"> 591                     vm, codeBlock, AccessCase::Setter, structure, offset, conditionSet, WTFMove(prototypeAccessChain));</span>
 592             }
 593         }
 594 
<span class="line-modified"> 595         LOG_IC((ICEvent::PutByIdAddAccessCase, structure-&gt;classInfo(), ident, slot.base() == baseValue));</span>
 596 
 597         result = stubInfo.addAccessCase(locker, codeBlock, ident, WTFMove(newCase));
 598 
 599         if (result.generatedSomeCode()) {
<span class="line-modified"> 600             LOG_IC((ICEvent::PutByIdReplaceWithJump, structure-&gt;classInfo(), ident, slot.base() == baseValue));</span>
 601 
 602             RELEASE_ASSERT(result.code());
 603 
 604             InlineAccess::rewireStubAsJump(stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));
 605         }
 606     }
 607 
<span class="line-modified"> 608     fireWatchpointsAndClearStubIfNeeded(vm, stubInfo, exec-&gt;codeBlock(), result);</span>
 609 
 610     return result.shouldGiveUpNow() ? GiveUpOnCache : RetryCacheLater;
 611 }
 612 
<span class="line-modified"> 613 void repatchPutByID(ExecState* exec, JSValue baseValue, Structure* structure, const Identifier&amp; propertyName, const PutPropertySlot&amp; slot, StructureStubInfo&amp; stubInfo, PutKind putKind)</span>
 614 {
 615     SuperSamplerScope superSamplerScope(false);
 616 
<span class="line-modified"> 617     if (tryCachePutByID(exec, baseValue, structure, propertyName, slot, stubInfo, putKind) == GiveUpOnCache) {</span>
<span class="line-modified"> 618         CodeBlock* codeBlock = exec-&gt;codeBlock();</span>
<span class="line-removed"> 619         ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), appropriateGenericPutByIdFunction(slot, putKind));</span>
<span class="line-removed"> 620     }</span>
 621 }
 622 
 623 static InlineCacheAction tryCacheInByID(
<span class="line-modified"> 624     ExecState* exec, JSObject* base, const Identifier&amp; ident,</span>
 625     bool wasFound, const PropertySlot&amp; slot, StructureStubInfo&amp; stubInfo)
 626 {
<span class="line-modified"> 627     VM&amp; vm = exec-&gt;vm();</span>
 628     AccessGenerationResult result;
 629 
 630     {
<span class="line-modified"> 631         GCSafeConcurrentJSLocker locker(exec-&gt;codeBlock()-&gt;m_lock, vm.heap);</span>
<span class="line-modified"> 632         if (forceICFailure(exec))</span>
 633             return GiveUpOnCache;
 634 
 635         if (!base-&gt;structure(vm)-&gt;propertyAccessesAreCacheable() || (!wasFound &amp;&amp; !base-&gt;structure(vm)-&gt;propertyAccessesAreCacheableForAbsence()))
 636             return GiveUpOnCache;
 637 
 638         if (wasFound) {
 639             if (!slot.isCacheable())
 640                 return GiveUpOnCache;
 641         }
 642 
<span class="line-removed"> 643         CodeBlock* codeBlock = exec-&gt;codeBlock();</span>
 644         Structure* structure = base-&gt;structure(vm);
 645 
 646         std::unique_ptr&lt;PolyProtoAccessChain&gt; prototypeAccessChain;
 647         ObjectPropertyConditionSet conditionSet;
 648         if (wasFound) {
 649             InlineCacheAction action = actionForCell(vm, base);
 650             if (action != AttemptToCache)
 651                 return action;
 652 
 653             // Optimize self access.
<span class="line-modified"> 654             if (stubInfo.cacheType == CacheType::Unset</span>
 655                 &amp;&amp; slot.isCacheableValue()
 656                 &amp;&amp; slot.slotBase() == base
 657                 &amp;&amp; !slot.watchpointSet()
 658                 &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()) {
 659                 bool generatedCodeInline = InlineAccess::generateSelfInAccess(stubInfo, structure);
 660                 if (generatedCodeInline) {
 661                     LOG_IC((ICEvent::InByIdSelfPatch, structure-&gt;classInfo(), ident, slot.slotBase() == base));
 662                     structure-&gt;startWatchingPropertyForReplacements(vm, slot.cachedOffset());
<span class="line-modified"> 663                     ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), operationInByIdOptimize);</span>
 664                     stubInfo.initInByIdSelf(codeBlock, structure, slot.cachedOffset());
 665                     return RetryCacheLater;
 666                 }
 667             }
 668 
 669             if (slot.slotBase() != base) {
<span class="line-modified"> 670                 bool usesPolyProto;</span>
<span class="line-modified"> 671                 prototypeAccessChain = PolyProtoAccessChain::create(exec-&gt;lexicalGlobalObject(), base, slot, usesPolyProto);</span>
<span class="line-removed"> 672                 if (!prototypeAccessChain) {</span>
<span class="line-removed"> 673                     // It&#39;s invalid to access this prototype property.</span>
 674                     return GiveUpOnCache;
<span class="line-modified"> 675                 }</span>
<span class="line-modified"> 676                 if (!usesPolyProto) {</span>







 677                     prototypeAccessChain = nullptr;
 678                     conditionSet = generateConditionsForPrototypePropertyHit(
<span class="line-modified"> 679                         vm, codeBlock, exec, structure, slot.slotBase(), ident.impl());</span>



 680                 }
 681             }
 682         } else {
<span class="line-modified"> 683             bool usesPolyProto;</span>
<span class="line-modified"> 684             prototypeAccessChain = PolyProtoAccessChain::create(exec-&gt;lexicalGlobalObject(), base, slot, usesPolyProto);</span>
<span class="line-removed"> 685             if (!prototypeAccessChain) {</span>
<span class="line-removed"> 686                 // It&#39;s invalid to access this prototype property.</span>
 687                 return GiveUpOnCache;
<span class="line-removed"> 688             }</span>
 689 
<span class="line-modified"> 690             if (!usesPolyProto) {</span>




 691                 prototypeAccessChain = nullptr;
 692                 conditionSet = generateConditionsForPropertyMiss(
<span class="line-modified"> 693                     vm, codeBlock, exec, structure, ident.impl());</span>


 694             }
 695         }
<span class="line-removed"> 696         if (!conditionSet.isValid())</span>
<span class="line-removed"> 697             return GiveUpOnCache;</span>
 698 
 699         LOG_IC((ICEvent::InAddAccessCase, structure-&gt;classInfo(), ident, slot.slotBase() == base));
 700 
 701         std::unique_ptr&lt;AccessCase&gt; newCase = AccessCase::create(
<span class="line-modified"> 702             vm, codeBlock, wasFound ? AccessCase::InHit : AccessCase::InMiss, wasFound ? slot.cachedOffset() : invalidOffset, structure, conditionSet, WTFMove(prototypeAccessChain));</span>
 703 
 704         result = stubInfo.addAccessCase(locker, codeBlock, ident, WTFMove(newCase));
 705 
 706         if (result.generatedSomeCode()) {
 707             LOG_IC((ICEvent::InReplaceWithJump, structure-&gt;classInfo(), ident, slot.slotBase() == base));
 708 
 709             RELEASE_ASSERT(result.code());
 710             InlineAccess::rewireStubAsJump(stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));
 711         }
 712     }
 713 
<span class="line-modified"> 714     fireWatchpointsAndClearStubIfNeeded(vm, stubInfo, exec-&gt;codeBlock(), result);</span>
 715 
 716     return result.shouldGiveUpNow() ? GiveUpOnCache : RetryCacheLater;
 717 }
 718 
<span class="line-modified"> 719 void repatchInByID(ExecState* exec, JSObject* baseObject, const Identifier&amp; propertyName, bool wasFound, const PropertySlot&amp; slot, StructureStubInfo&amp; stubInfo)</span>
 720 {
 721     SuperSamplerScope superSamplerScope(false);
 722 
<span class="line-modified"> 723     if (tryCacheInByID(exec, baseObject, propertyName, wasFound, slot, stubInfo) == GiveUpOnCache) {</span>
<span class="line-modified"> 724         CodeBlock* codeBlock = exec-&gt;codeBlock();</span>
<span class="line-removed"> 725         ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), operationInById);</span>
<span class="line-removed"> 726     }</span>
 727 }
 728 
 729 static InlineCacheAction tryCacheInstanceOf(
<span class="line-modified"> 730     ExecState* exec, JSValue valueValue, JSValue prototypeValue, StructureStubInfo&amp; stubInfo,</span>
 731     bool wasFound)
 732 {
<span class="line-modified"> 733     VM&amp; vm = exec-&gt;vm();</span>
<span class="line-removed"> 734     CodeBlock* codeBlock = exec-&gt;codeBlock();</span>
 735     AccessGenerationResult result;
 736 
 737     RELEASE_ASSERT(valueValue.isCell()); // shouldConsiderCaching rejects non-cells.
 738 
<span class="line-modified"> 739     if (forceICFailure(exec))</span>
 740         return GiveUpOnCache;
 741 
 742     {
 743         GCSafeConcurrentJSLocker locker(codeBlock-&gt;m_lock, vm.heap);
 744 
 745         JSCell* value = valueValue.asCell();
 746         Structure* structure = value-&gt;structure(vm);
 747         std::unique_ptr&lt;AccessCase&gt; newCase;
 748         JSObject* prototype = jsDynamicCast&lt;JSObject*&gt;(vm, prototypeValue);
 749         if (prototype) {
 750             if (!jsDynamicCast&lt;JSObject*&gt;(vm, value)) {
 751                 newCase = InstanceOfAccessCase::create(
 752                     vm, codeBlock, AccessCase::InstanceOfMiss, structure, ObjectPropertyConditionSet(),
 753                     prototype);
 754             } else if (structure-&gt;prototypeQueriesAreCacheable()) {
 755                 // FIXME: Teach this to do poly proto.
 756                 // https://bugs.webkit.org/show_bug.cgi?id=185663
<span class="line-modified"> 757 </span>
 758                 ObjectPropertyConditionSet conditionSet = generateConditionsForInstanceOf(
<span class="line-modified"> 759                     vm, codeBlock, exec, structure, prototype, wasFound);</span>
 760 
 761                 if (conditionSet.isValid()) {
 762                     newCase = InstanceOfAccessCase::create(
 763                         vm, codeBlock,
 764                         wasFound ? AccessCase::InstanceOfHit : AccessCase::InstanceOfMiss,
 765                         structure, conditionSet, prototype);
 766                 }
 767             }
 768         }
 769 
 770         if (!newCase)
<span class="line-modified"> 771             newCase = AccessCase::create(vm, codeBlock, AccessCase::InstanceOfGeneric);</span>
 772 
 773         LOG_IC((ICEvent::InstanceOfAddAccessCase, structure-&gt;classInfo(), Identifier()));
 774 
<span class="line-modified"> 775         result = stubInfo.addAccessCase(locker, codeBlock, Identifier(), WTFMove(newCase));</span>
 776 
 777         if (result.generatedSomeCode()) {
 778             LOG_IC((ICEvent::InstanceOfReplaceWithJump, structure-&gt;classInfo(), Identifier()));
 779 
 780             RELEASE_ASSERT(result.code());
 781 
 782             MacroAssembler::repatchJump(
 783                 stubInfo.patchableJump(),
 784                 CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));
 785         }
 786     }
 787 
 788     fireWatchpointsAndClearStubIfNeeded(vm, stubInfo, codeBlock, result);
 789 
 790     return result.shouldGiveUpNow() ? GiveUpOnCache : RetryCacheLater;
 791 }
 792 
 793 void repatchInstanceOf(
<span class="line-modified"> 794     ExecState* exec, JSValue valueValue, JSValue prototypeValue, StructureStubInfo&amp; stubInfo,</span>
 795     bool wasFound)
 796 {
 797     SuperSamplerScope superSamplerScope(false);
<span class="line-modified"> 798     if (tryCacheInstanceOf(exec, valueValue, prototypeValue, stubInfo, wasFound) == GiveUpOnCache)</span>
<span class="line-modified"> 799         ftlThunkAwareRepatchCall(exec-&gt;codeBlock(), stubInfo.slowPathCallLocation(), operationInstanceOfGeneric);</span>
 800 }
 801 
 802 static void linkSlowFor(VM&amp;, CallLinkInfo&amp; callLinkInfo, MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; codeRef)
 803 {
 804     MacroAssembler::repatchNearCall(callLinkInfo.callReturnLocation(), CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(codeRef.code()));
 805 }
 806 
 807 static void linkSlowFor(VM&amp; vm, CallLinkInfo&amp; callLinkInfo, ThunkGenerator generator)
 808 {
 809     linkSlowFor(vm, callLinkInfo, vm.getCTIStub(generator).retagged&lt;JITStubRoutinePtrTag&gt;());
 810 }
 811 
 812 static void linkSlowFor(VM&amp; vm, CallLinkInfo&amp; callLinkInfo)
 813 {
 814     MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; virtualThunk = virtualThunkFor(vm, callLinkInfo);
 815     linkSlowFor(vm, callLinkInfo, virtualThunk);
<span class="line-modified"> 816     callLinkInfo.setSlowStub(createJITStubRoutine(virtualThunk, vm, nullptr, true));</span>
 817 }
 818 
 819 static JSCell* webAssemblyOwner(JSCell* callee)
 820 {
 821 #if ENABLE(WEBASSEMBLY)
 822     // Each WebAssembly.Instance shares the stubs from their WebAssembly.Module, which are therefore the appropriate owner.
<span class="line-modified"> 823     return jsCast&lt;WebAssemblyToJSCallee*&gt;(callee)-&gt;module();</span>
 824 #else
 825     UNUSED_PARAM(callee);
 826     RELEASE_ASSERT_NOT_REACHED();
 827     return nullptr;
 828 #endif // ENABLE(WEBASSEMBLY)
 829 }
 830 
 831 void linkFor(
<span class="line-modified"> 832     ExecState* exec, CallLinkInfo&amp; callLinkInfo, CodeBlock* calleeCodeBlock,</span>
 833     JSObject* callee, MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr)
 834 {
 835     ASSERT(!callLinkInfo.stub());
 836 
<span class="line-modified"> 837     CallFrame* callerFrame = exec-&gt;callerFrame();</span>
 838     // Our caller must have a cell for a callee. When calling
 839     // this from Wasm, we ensure the callee is a cell.
 840     ASSERT(callerFrame-&gt;callee().isCell());
 841 
<span class="line-removed"> 842     VM&amp; vm = callerFrame-&gt;vm();</span>
 843     CodeBlock* callerCodeBlock = callerFrame-&gt;codeBlock();
 844 
 845     // WebAssembly -&gt; JS stubs don&#39;t have a valid CodeBlock.
<span class="line-modified"> 846     JSCell* owner = isWebAssemblyToJSCallee(callerFrame-&gt;callee().asCell()) ? webAssemblyOwner(callerFrame-&gt;callee().asCell()) : callerCodeBlock;</span>
 847     ASSERT(owner);
 848 
 849     ASSERT(!callLinkInfo.isLinked());
 850     callLinkInfo.setCallee(vm, owner, callee);
 851     MacroAssembler::repatchPointer(callLinkInfo.hotPathBegin(), callee);
 852     callLinkInfo.setLastSeenCallee(vm, owner, callee);
 853     if (shouldDumpDisassemblyFor(callerCodeBlock))
 854         dataLog(&quot;Linking call in &quot;, FullCodeOrigin(callerCodeBlock, callLinkInfo.codeOrigin()), &quot; to &quot;, pointerDump(calleeCodeBlock), &quot;, entrypoint at &quot;, codePtr, &quot;\n&quot;);
 855 
 856     MacroAssembler::repatchNearCall(callLinkInfo.hotPathOther(), CodeLocationLabel&lt;JSEntryPtrTag&gt;(codePtr));
 857 
 858     if (calleeCodeBlock)
 859         calleeCodeBlock-&gt;linkIncomingCall(callerFrame, &amp;callLinkInfo);
 860 
 861     if (callLinkInfo.specializationKind() == CodeForCall &amp;&amp; callLinkInfo.allowStubs()) {
 862         linkSlowFor(vm, callLinkInfo, linkPolymorphicCallThunkGenerator);
 863         return;
 864     }
 865 
 866     linkSlowFor(vm, callLinkInfo);
 867 }
 868 
 869 void linkDirectFor(
<span class="line-modified"> 870     ExecState* exec, CallLinkInfo&amp; callLinkInfo, CodeBlock* calleeCodeBlock,</span>
 871     MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr)
 872 {
 873     ASSERT(!callLinkInfo.stub());
 874 
<span class="line-modified"> 875     CodeBlock* callerCodeBlock = exec-&gt;codeBlock();</span>
 876 
 877     VM&amp; vm = callerCodeBlock-&gt;vm();
 878 
 879     ASSERT(!callLinkInfo.isLinked());
 880     callLinkInfo.setCodeBlock(vm, callerCodeBlock, jsCast&lt;FunctionCodeBlock*&gt;(calleeCodeBlock));
 881     if (shouldDumpDisassemblyFor(callerCodeBlock))
 882         dataLog(&quot;Linking call in &quot;, FullCodeOrigin(callerCodeBlock, callLinkInfo.codeOrigin()), &quot; to &quot;, pointerDump(calleeCodeBlock), &quot;, entrypoint at &quot;, codePtr, &quot;\n&quot;);
 883 
 884     if (callLinkInfo.callType() == CallLinkInfo::DirectTailCall)
 885         MacroAssembler::repatchJumpToNop(callLinkInfo.patchableJump());
 886     MacroAssembler::repatchNearCall(callLinkInfo.hotPathOther(), CodeLocationLabel&lt;JSEntryPtrTag&gt;(codePtr));
 887 
 888     if (calleeCodeBlock)
<span class="line-modified"> 889         calleeCodeBlock-&gt;linkIncomingCall(exec, &amp;callLinkInfo);</span>
 890 }
 891 
<span class="line-modified"> 892 void linkSlowFor(</span>
<span class="line-removed"> 893     ExecState* exec, CallLinkInfo&amp; callLinkInfo)</span>
 894 {
<span class="line-modified"> 895     CodeBlock* callerCodeBlock = exec-&gt;callerFrame()-&gt;codeBlock();</span>
 896     VM&amp; vm = callerCodeBlock-&gt;vm();
 897 
 898     linkSlowFor(vm, callLinkInfo);
 899 }
 900 
 901 static void revertCall(VM&amp; vm, CallLinkInfo&amp; callLinkInfo, MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; codeRef)
 902 {
 903     if (callLinkInfo.isDirect()) {
 904         callLinkInfo.clearCodeBlock();
 905         if (!callLinkInfo.clearedByJettison()) {
 906             if (callLinkInfo.callType() == CallLinkInfo::DirectTailCall)
 907                 MacroAssembler::repatchJump(callLinkInfo.patchableJump(), callLinkInfo.slowPathStart());
 908             else
 909                 MacroAssembler::repatchNearCall(callLinkInfo.hotPathOther(), callLinkInfo.slowPathStart());
 910         }
 911     } else {
 912         if (!callLinkInfo.clearedByJettison()) {
 913             MacroAssembler::revertJumpReplacementToBranchPtrWithPatch(
 914                 MacroAssembler::startOfBranchPtrWithPatchOnRegister(callLinkInfo.hotPathBegin()),
 915                 callLinkInfo.calleeGPR(), 0);
 916             linkSlowFor(vm, callLinkInfo, codeRef);
 917             MacroAssembler::repatchPointer(callLinkInfo.hotPathBegin(), nullptr);
 918         }
 919         callLinkInfo.clearCallee();
 920     }
 921     callLinkInfo.clearSeen();
 922     callLinkInfo.clearStub();
 923     callLinkInfo.clearSlowStub();
 924     if (callLinkInfo.isOnList())
 925         callLinkInfo.remove();
 926 }
 927 
 928 void unlinkFor(VM&amp; vm, CallLinkInfo&amp; callLinkInfo)
 929 {
<span class="line-modified"> 930     if (Options::dumpDisassembly())</span>
<span class="line-removed"> 931         dataLog(&quot;Unlinking call at &quot;, callLinkInfo.hotPathOther(), &quot;\n&quot;);</span>
 932 
 933     revertCall(vm, callLinkInfo, vm.getCTIStub(linkCallThunkGenerator).retagged&lt;JITStubRoutinePtrTag&gt;());
 934 }
 935 
<span class="line-modified"> 936 static void linkVirtualFor(ExecState* exec, CallLinkInfo&amp; callLinkInfo)</span>
 937 {
<span class="line-modified"> 938     CallFrame* callerFrame = exec-&gt;callerFrame();</span>
<span class="line-removed"> 939     VM&amp; vm = callerFrame-&gt;vm();</span>
 940     CodeBlock* callerCodeBlock = callerFrame-&gt;codeBlock();
 941 
<span class="line-modified"> 942     if (shouldDumpDisassemblyFor(callerCodeBlock))</span>
<span class="line-modified"> 943         dataLog(&quot;Linking virtual call at &quot;, FullCodeOrigin(callerCodeBlock, callerFrame-&gt;codeOrigin()), &quot;\n&quot;);</span>
 944 
 945     MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; virtualThunk = virtualThunkFor(vm, callLinkInfo);
 946     revertCall(vm, callLinkInfo, virtualThunk);
<span class="line-modified"> 947     callLinkInfo.setSlowStub(createJITStubRoutine(virtualThunk, vm, nullptr, true));</span>
 948     callLinkInfo.setClearedByVirtual();
 949 }
 950 
 951 namespace {
 952 struct CallToCodePtr {
 953     CCallHelpers::Call call;
 954     MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr;
 955 };
 956 } // annonymous namespace
 957 
<span class="line-modified"> 958 void linkPolymorphicCall(</span>
<span class="line-removed"> 959     ExecState* exec, CallLinkInfo&amp; callLinkInfo, CallVariant newVariant)</span>
 960 {
 961     RELEASE_ASSERT(callLinkInfo.allowStubs());
 962 
<span class="line-modified"> 963     CallFrame* callerFrame = exec-&gt;callerFrame();</span>
<span class="line-modified"> 964     VM&amp; vm = callerFrame-&gt;vm();</span>
 965 
 966     // During execution of linkPolymorphicCall, we strongly assume that we never do GC.
 967     // GC jettisons CodeBlocks, changes CallLinkInfo etc. and breaks assumption done before and after this call.
 968     DeferGCForAWhile deferGCForAWhile(vm.heap);
 969 
 970     if (!newVariant) {
<span class="line-modified"> 971         linkVirtualFor(exec, callLinkInfo);</span>
 972         return;
 973     }
 974 
 975     // Our caller must be have a cell for a callee. When calling
 976     // this from Wasm, we ensure the callee is a cell.
 977     ASSERT(callerFrame-&gt;callee().isCell());
 978 
 979     CodeBlock* callerCodeBlock = callerFrame-&gt;codeBlock();
<span class="line-modified"> 980     bool isWebAssembly = isWebAssemblyToJSCallee(callerFrame-&gt;callee().asCell());</span>
 981 
 982     // WebAssembly -&gt; JS stubs don&#39;t have a valid CodeBlock.
 983     JSCell* owner = isWebAssembly ? webAssemblyOwner(callerFrame-&gt;callee().asCell()) : callerCodeBlock;
 984     ASSERT(owner);
 985 
 986     CallVariantList list;
 987     if (PolymorphicCallStubRoutine* stub = callLinkInfo.stub())
 988         list = stub-&gt;variants();
 989     else if (JSObject* oldCallee = callLinkInfo.callee())
 990         list = CallVariantList { CallVariant(oldCallee) };
 991 
 992     list = variantListWithVariant(list, newVariant);
 993 
 994     // If there are any closure calls then it makes sense to treat all of them as closure calls.
 995     // This makes switching on callee cheaper. It also produces profiling that&#39;s easier on the DFG;
 996     // the DFG doesn&#39;t really want to deal with a combination of closure and non-closure callees.
 997     bool isClosureCall = false;
 998     for (CallVariant variant : list)  {
 999         if (variant.isClosureCall()) {
1000             list = despecifiedVariantList(list);
1001             isClosureCall = true;
1002             break;
1003         }
1004     }
1005 
1006     if (isClosureCall)
1007         callLinkInfo.setHasSeenClosure();
1008 
1009     Vector&lt;PolymorphicCallCase&gt; callCases;
1010     Vector&lt;int64_t&gt; caseValues;
1011 
1012     // Figure out what our cases are.
1013     for (CallVariant variant : list) {
1014         CodeBlock* codeBlock = nullptr;
1015         if (variant.executable() &amp;&amp; !variant.executable()-&gt;isHostFunction()) {
1016             ExecutableBase* executable = variant.executable();
1017             codeBlock = jsCast&lt;FunctionExecutable*&gt;(executable)-&gt;codeBlockForCall();
1018             // If we cannot handle a callee, either because we don&#39;t have a CodeBlock or because arity mismatch,
1019             // assume that it&#39;s better for this whole thing to be a virtual call.
<span class="line-modified">1020             if (!codeBlock || exec-&gt;argumentCountIncludingThis() &lt; static_cast&lt;size_t&gt;(codeBlock-&gt;numParameters()) || callLinkInfo.isVarargs()) {</span>
<span class="line-modified">1021                 linkVirtualFor(exec, callLinkInfo);</span>
1022                 return;
1023             }
1024         }
1025 
1026         int64_t newCaseValue = 0;
1027         if (isClosureCall) {
1028             newCaseValue = bitwise_cast&lt;intptr_t&gt;(variant.executable());
1029             // FIXME: We could add a fast path for InternalFunction with closure call.
1030             // https://bugs.webkit.org/show_bug.cgi?id=179311
1031             if (!newCaseValue)
1032                 continue;
1033         } else {
1034             if (auto* function = variant.function())
1035                 newCaseValue = bitwise_cast&lt;intptr_t&gt;(function);
1036             else
1037                 newCaseValue = bitwise_cast&lt;intptr_t&gt;(variant.internalFunction());
1038         }
1039 
<span class="line-modified">1040         if (!ASSERT_DISABLED) {</span>
1041             if (caseValues.contains(newCaseValue)) {
1042                 dataLog(&quot;ERROR: Attempt to add duplicate case value.\n&quot;);
1043                 dataLog(&quot;Existing case values: &quot;);
1044                 CommaPrinter comma;
1045                 for (auto&amp; value : caseValues)
1046                     dataLog(comma, value);
1047                 dataLog(&quot;\n&quot;);
1048                 dataLog(&quot;Attempting to add: &quot;, newCaseValue, &quot;\n&quot;);
1049                 dataLog(&quot;Variant list: &quot;, listDump(callCases), &quot;\n&quot;);
1050                 RELEASE_ASSERT_NOT_REACHED();
1051             }
1052         }
1053 
1054         callCases.append(PolymorphicCallCase(variant, codeBlock));
1055         caseValues.append(newCaseValue);
1056     }
1057     ASSERT(callCases.size() == caseValues.size());
1058 
1059     // If we are over the limit, just use a normal virtual call.
1060     unsigned maxPolymorphicCallVariantListSize;
1061     if (isWebAssembly)
1062         maxPolymorphicCallVariantListSize = Options::maxPolymorphicCallVariantListSizeForWebAssemblyToJS();
1063     else if (callerCodeBlock-&gt;jitType() == JITCode::topTierJIT())
1064         maxPolymorphicCallVariantListSize = Options::maxPolymorphicCallVariantListSizeForTopTier();
1065     else
1066         maxPolymorphicCallVariantListSize = Options::maxPolymorphicCallVariantListSize();
1067 
1068     // We use list.size() instead of callCases.size() because we respect CallVariant size for now.
1069     if (list.size() &gt; maxPolymorphicCallVariantListSize) {
<span class="line-modified">1070         linkVirtualFor(exec, callLinkInfo);</span>
1071         return;
1072     }
1073 
1074     Vector&lt;CallToCodePtr&gt; calls(callCases.size());
1075     UniqueArray&lt;uint32_t&gt; fastCounts;
1076 
1077     if (!isWebAssembly &amp;&amp; callerCodeBlock-&gt;jitType() != JITCode::topTierJIT()) {
1078         fastCounts = makeUniqueArray&lt;uint32_t&gt;(callCases.size());
1079         memset(fastCounts.get(), 0, callCases.size() * sizeof(uint32_t));
1080     }
1081 
1082     GPRReg calleeGPR = callLinkInfo.calleeGPR();
1083 
1084     CCallHelpers stubJit(callerCodeBlock);
1085 
1086     std::unique_ptr&lt;CallFrameShuffler&gt; frameShuffler;
1087     if (callLinkInfo.frameShuffleData()) {
1088         ASSERT(callLinkInfo.isTailCall());
1089         frameShuffler = makeUnique&lt;CallFrameShuffler&gt;(stubJit, *callLinkInfo.frameShuffleData());
1090 #if USE(JSVALUE32_64)
</pre>
<hr />
<pre>
1116     if (!frameShuffler &amp;&amp; callLinkInfo.isTailCall()) {
1117         // We strongly assume that calleeGPR is not a callee save register in the slow path.
1118         ASSERT(!callerCodeBlock-&gt;calleeSaveRegisters()-&gt;find(calleeGPR));
1119         stubJit.emitRestoreCalleeSaves();
1120     }
1121 
1122     CCallHelpers::JumpList slowPath;
1123     if (isClosureCall) {
1124         // Verify that we have a function and stash the executable in scratchGPR.
1125 #if USE(JSVALUE64)
1126         if (callLinkInfo.isTailCall())
1127             slowPath.append(stubJit.branchIfNotCell(calleeGPR, DoNotHaveTagRegisters));
1128         else
1129             slowPath.append(stubJit.branchIfNotCell(calleeGPR));
1130 #else
1131         // We would have already checked that the callee is a cell.
1132 #endif
1133         // FIXME: We could add a fast path for InternalFunction with closure call.
1134         slowPath.append(stubJit.branchIfNotFunction(calleeGPR));
1135 
<span class="line-modified">1136         stubJit.loadPtr(</span>
<span class="line-modified">1137             CCallHelpers::Address(calleeGPR, JSFunction::offsetOfExecutable()),</span>
<span class="line-modified">1138             comparisonValueGPR);</span>

1139     }
1140 
1141     BinarySwitch binarySwitch(comparisonValueGPR, caseValues, BinarySwitch::IntPtr);
1142     CCallHelpers::JumpList done;
1143     while (binarySwitch.advance(stubJit)) {
1144         size_t caseIndex = binarySwitch.caseIndex();
1145 
1146         CallVariant variant = callCases[caseIndex].variant();
1147 
1148         MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr;
1149         if (variant.executable()) {
1150             ASSERT(variant.executable()-&gt;hasJITCodeForCall());
1151 
1152             codePtr = jsToWasmICCodePtr(vm, callLinkInfo.specializationKind(), variant.function());
1153             if (!codePtr)
1154                 codePtr = variant.executable()-&gt;generatedJITCodeForCall()-&gt;addressForCall(ArityCheckNotRequired);
1155         } else {
1156             ASSERT(variant.internalFunction());
1157             codePtr = vm.getCTIInternalFunctionTrampolineFor(CodeForCall);
1158         }
</pre>
<hr />
<pre>
1176 
1177     slowPath.link(&amp;stubJit);
1178     binarySwitch.fallThrough().link(&amp;stubJit);
1179 
1180     if (frameShuffler) {
1181         frameShuffler-&gt;releaseGPR(calleeGPR);
1182         frameShuffler-&gt;releaseGPR(comparisonValueGPR);
1183         frameShuffler-&gt;releaseGPR(fastCountsBaseGPR);
1184 #if USE(JSVALUE32_64)
1185         frameShuffler-&gt;setCalleeJSValueRegs(JSValueRegs(GPRInfo::regT1, GPRInfo::regT0));
1186 #else
1187         frameShuffler-&gt;setCalleeJSValueRegs(JSValueRegs(GPRInfo::regT0));
1188 #endif
1189         frameShuffler-&gt;prepareForSlowPath();
1190     } else {
1191         stubJit.move(calleeGPR, GPRInfo::regT0);
1192 #if USE(JSVALUE32_64)
1193         stubJit.move(CCallHelpers::TrustedImm32(JSValue::CellTag), GPRInfo::regT1);
1194 #endif
1195     }

1196     stubJit.move(CCallHelpers::TrustedImmPtr(&amp;callLinkInfo), GPRInfo::regT2);
1197     stubJit.move(CCallHelpers::TrustedImmPtr(callLinkInfo.callReturnLocation().untaggedExecutableAddress()), GPRInfo::regT4);
1198 
1199     stubJit.restoreReturnAddressBeforeReturn(GPRInfo::regT4);
1200     AssemblyHelpers::Jump slow = stubJit.jump();
1201 
1202     LinkBuffer patchBuffer(stubJit, owner, JITCompilationCanFail);
1203     if (patchBuffer.didFailToAllocate()) {
<span class="line-modified">1204         linkVirtualFor(exec, callLinkInfo);</span>
1205         return;
1206     }
1207 
1208     RELEASE_ASSERT(callCases.size() == calls.size());
1209     for (CallToCodePtr callToCodePtr : calls) {
1210 #if CPU(ARM_THUMB2)
1211         // Tail call special-casing ensures proper linking on ARM Thumb2, where a tail call jumps to an address
1212         // with a non-decorated bottom bit but a normal call calls an address with a decorated bottom bit.
1213         bool isTailCall = callToCodePtr.call.isFlagSet(CCallHelpers::Call::Tail);
1214         void* target = isTailCall ? callToCodePtr.codePtr.dataLocation() : callToCodePtr.codePtr.executableAddress();
1215         patchBuffer.link(callToCodePtr.call, FunctionPtr&lt;JSEntryPtrTag&gt;(MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt;::createFromExecutableAddress(target)));
1216 #else
1217         patchBuffer.link(callToCodePtr.call, FunctionPtr&lt;JSEntryPtrTag&gt;(callToCodePtr.codePtr));
1218 #endif
1219     }
1220     if (isWebAssembly || JITCode::isOptimizingJIT(callerCodeBlock-&gt;jitType()))
1221         patchBuffer.link(done, callLinkInfo.callReturnLocation().labelAtOffset(0));
1222     else
1223         patchBuffer.link(done, callLinkInfo.hotPathOther().labelAtOffset(0));
1224     patchBuffer.link(slow, CodeLocationLabel&lt;JITThunkPtrTag&gt;(vm.getCTIStub(linkPolymorphicCallThunkGenerator).code()));
1225 
1226     auto stubRoutine = adoptRef(*new PolymorphicCallStubRoutine(
1227         FINALIZE_CODE_FOR(
1228             callerCodeBlock, patchBuffer, JITStubRoutinePtrTag,
1229             &quot;Polymorphic call stub for %s, return point %p, targets %s&quot;,
1230                 isWebAssembly ? &quot;WebAssembly&quot; : toCString(*callerCodeBlock).data(), callLinkInfo.callReturnLocation().labelAtOffset(0).executableAddress(),
1231                 toCString(listDump(callCases)).data()),
<span class="line-modified">1232         vm, owner, exec-&gt;callerFrame(), callLinkInfo, callCases,</span>
1233         WTFMove(fastCounts)));
1234 
1235     MacroAssembler::replaceWithJump(
1236         MacroAssembler::startOfBranchPtrWithPatchOnRegister(callLinkInfo.hotPathBegin()),
1237         CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(stubRoutine-&gt;code().code()));
1238     // The original slow path is unreachable on 64-bits, but still
1239     // reachable on 32-bits since a non-cell callee will always
1240     // trigger the slow path
1241     linkSlowFor(vm, callLinkInfo);
1242 
1243     // If there had been a previous stub routine, that one will die as soon as the GC runs and sees
1244     // that it&#39;s no longer on stack.
1245     callLinkInfo.setStub(WTFMove(stubRoutine));
1246 
1247     // The call link info no longer has a call cache apart from the jump to the polymorphic call
1248     // stub.
1249     if (callLinkInfo.isOnList())
1250         callLinkInfo.remove();
1251 }
1252 
<span class="line-modified">1253 void resetGetByID(CodeBlock* codeBlock, StructureStubInfo&amp; stubInfo, GetByIDKind kind)</span>
1254 {
<span class="line-modified">1255     ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), appropriateOptimizingGetByIdFunction(kind));</span>
<span class="line-modified">1256     InlineAccess::rewireStubAsJump(stubInfo, stubInfo.slowPathStartLocation());</span>
1257 }
1258 
1259 void resetPutByID(CodeBlock* codeBlock, StructureStubInfo&amp; stubInfo)
1260 {
<span class="line-modified">1261     V_JITOperation_ESsiJJI unoptimizedFunction = reinterpret_cast&lt;V_JITOperation_ESsiJJI&gt;(readPutICCallTarget(codeBlock, stubInfo.slowPathCallLocation()).executableAddress());</span>
<span class="line-modified">1262     V_JITOperation_ESsiJJI optimizedFunction;</span>
1263     if (unoptimizedFunction == operationPutByIdStrict || unoptimizedFunction == operationPutByIdStrictOptimize)
1264         optimizedFunction = operationPutByIdStrictOptimize;
1265     else if (unoptimizedFunction == operationPutByIdNonStrict || unoptimizedFunction == operationPutByIdNonStrictOptimize)
1266         optimizedFunction = operationPutByIdNonStrictOptimize;
1267     else if (unoptimizedFunction == operationPutByIdDirectStrict || unoptimizedFunction == operationPutByIdDirectStrictOptimize)
1268         optimizedFunction = operationPutByIdDirectStrictOptimize;
1269     else {
1270         ASSERT(unoptimizedFunction == operationPutByIdDirectNonStrict || unoptimizedFunction == operationPutByIdDirectNonStrictOptimize);
1271         optimizedFunction = operationPutByIdDirectNonStrictOptimize;
1272     }
1273 
<span class="line-modified">1274     ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), optimizedFunction);</span>
<span class="line-modified">1275     InlineAccess::rewireStubAsJump(stubInfo, stubInfo.slowPathStartLocation());</span>
1276 }
1277 
1278 static void resetPatchableJump(StructureStubInfo&amp; stubInfo)
1279 {
<span class="line-modified">1280     MacroAssembler::repatchJump(stubInfo.patchableJump(), stubInfo.slowPathStartLocation());</span>
1281 }
1282 
1283 void resetInByID(CodeBlock* codeBlock, StructureStubInfo&amp; stubInfo)
1284 {
<span class="line-modified">1285     ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), operationInByIdOptimize);</span>
<span class="line-modified">1286     InlineAccess::rewireStubAsJump(stubInfo, stubInfo.slowPathStartLocation());</span>
1287 }
1288 
1289 void resetInstanceOf(StructureStubInfo&amp; stubInfo)
1290 {
1291     resetPatchableJump(stubInfo);
1292 }
1293 
1294 MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; jsToWasmICCodePtr(VM&amp; vm, CodeSpecializationKind kind, JSObject* callee)
1295 {
1296 #if ENABLE(WEBASSEMBLY)
1297     if (!callee)
1298         return nullptr;
1299     if (kind != CodeForCall)
1300         return nullptr;
1301     if (auto* wasmFunction = jsDynamicCast&lt;WebAssemblyFunction*&gt;(vm, callee))
1302         return wasmFunction-&gt;jsCallEntrypoint();
1303 #else
1304     UNUSED_PARAM(vm);
1305     UNUSED_PARAM(kind);
1306     UNUSED_PARAM(callee);
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (C) 2011-2020 Apple Inc. All rights reserved.</span>
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;Repatch.h&quot;
  28 
  29 #if ENABLE(JIT)
  30 
  31 #include &quot;BinarySwitch.h&quot;
  32 #include &quot;CCallHelpers.h&quot;
<span class="line-added">  33 #include &quot;CacheableIdentifierInlines.h&quot;</span>
  34 #include &quot;CallFrameShuffler.h&quot;
  35 #include &quot;DFGOperations.h&quot;
  36 #include &quot;DFGSpeculativeJIT.h&quot;
  37 #include &quot;DOMJITGetterSetter.h&quot;
  38 #include &quot;DirectArguments.h&quot;
  39 #include &quot;ExecutableBaseInlines.h&quot;
  40 #include &quot;FTLThunks.h&quot;
  41 #include &quot;FullCodeOrigin.h&quot;
  42 #include &quot;FunctionCodeBlock.h&quot;
  43 #include &quot;GCAwareJITStubRoutine.h&quot;
  44 #include &quot;GetterSetter.h&quot;
  45 #include &quot;GetterSetterAccessCase.h&quot;
  46 #include &quot;ICStats.h&quot;
  47 #include &quot;InlineAccess.h&quot;
  48 #include &quot;InstanceOfAccessCase.h&quot;
  49 #include &quot;IntrinsicGetterAccessCase.h&quot;
  50 #include &quot;JIT.h&quot;
  51 #include &quot;JITInlines.h&quot;
  52 #include &quot;JSCInlines.h&quot;
  53 #include &quot;JSModuleNamespaceObject.h&quot;
  54 #include &quot;JSWebAssembly.h&quot;
  55 #include &quot;JSWebAssemblyModule.h&quot;
  56 #include &quot;LinkBuffer.h&quot;
  57 #include &quot;ModuleNamespaceAccessCase.h&quot;
  58 #include &quot;PolymorphicAccess.h&quot;
  59 #include &quot;ScopedArguments.h&quot;
  60 #include &quot;ScratchRegisterAllocator.h&quot;
  61 #include &quot;StackAlignment.h&quot;
  62 #include &quot;StructureRareDataInlines.h&quot;
  63 #include &quot;StructureStubClearingWatchpoint.h&quot;
  64 #include &quot;StructureStubInfo.h&quot;
  65 #include &quot;SuperSampler.h&quot;
  66 #include &quot;ThunkGenerators.h&quot;
  67 #include &quot;WebAssemblyFunction.h&quot;

  68 #include &lt;wtf/CommaPrinter.h&gt;
  69 #include &lt;wtf/ListDump.h&gt;
  70 #include &lt;wtf/StringPrintStream.h&gt;
  71 
  72 namespace JSC {
  73 
  74 static FunctionPtr&lt;CFunctionPtrTag&gt; readPutICCallTarget(CodeBlock* codeBlock, CodeLocationCall&lt;JSInternalPtrTag&gt; call)
  75 {
  76     FunctionPtr&lt;OperationPtrTag&gt; target = MacroAssembler::readCallTarget&lt;OperationPtrTag&gt;(call);
  77 #if ENABLE(FTL_JIT)
  78     if (codeBlock-&gt;jitType() == JITType::FTLJIT) {
  79         MacroAssemblerCodePtr&lt;JITThunkPtrTag&gt; thunk = MacroAssemblerCodePtr&lt;OperationPtrTag&gt;::createFromExecutableAddress(target.executableAddress()).retagged&lt;JITThunkPtrTag&gt;();
  80         return codeBlock-&gt;vm().ftlThunks-&gt;keyForSlowPathCallThunk(thunk).callTarget().retagged&lt;CFunctionPtrTag&gt;();
  81     }
  82 #else
  83     UNUSED_PARAM(codeBlock);
  84 #endif // ENABLE(FTL_JIT)
  85     return target.retagged&lt;CFunctionPtrTag&gt;();
  86 }
  87 
  88 void ftlThunkAwareRepatchCall(CodeBlock* codeBlock, CodeLocationCall&lt;JSInternalPtrTag&gt; call, FunctionPtr&lt;CFunctionPtrTag&gt; newCalleeFunction)
  89 {
  90 #if ENABLE(FTL_JIT)
  91     if (codeBlock-&gt;jitType() == JITType::FTLJIT) {
  92         VM&amp; vm = codeBlock-&gt;vm();
  93         FTL::Thunks&amp; thunks = *vm.ftlThunks;
  94         FunctionPtr&lt;OperationPtrTag&gt; target = MacroAssembler::readCallTarget&lt;OperationPtrTag&gt;(call);
  95         auto slowPathThunk = MacroAssemblerCodePtr&lt;JITThunkPtrTag&gt;::createFromExecutableAddress(target.retaggedExecutableAddress&lt;JITThunkPtrTag&gt;());
  96         FTL::SlowPathCallKey key = thunks.keyForSlowPathCallThunk(slowPathThunk);
  97         key = key.withCallTarget(newCalleeFunction);
<span class="line-modified">  98         MacroAssembler::repatchCall(call, FunctionPtr&lt;OperationPtrTag&gt;(thunks.getSlowPathCallThunk(vm, key).retaggedCode&lt;OperationPtrTag&gt;()));</span>
  99         return;
 100     }
 101 #else // ENABLE(FTL_JIT)
 102     UNUSED_PARAM(codeBlock);
 103 #endif // ENABLE(FTL_JIT)
 104     MacroAssembler::repatchCall(call, newCalleeFunction.retagged&lt;OperationPtrTag&gt;());
 105 }
 106 
 107 enum InlineCacheAction {
 108     GiveUpOnCache,
 109     RetryCacheLater,
 110     AttemptToCache
 111 };
 112 
 113 static InlineCacheAction actionForCell(VM&amp; vm, JSCell* cell)
 114 {
 115     Structure* structure = cell-&gt;structure(vm);
 116 
 117     TypeInfo typeInfo = structure-&gt;typeInfo();
 118     if (typeInfo.prohibitsPropertyCaching())
 119         return GiveUpOnCache;
 120 
 121     if (structure-&gt;isUncacheableDictionary()) {
 122         if (structure-&gt;hasBeenFlattenedBefore())
 123             return GiveUpOnCache;
 124         // Flattening could have changed the offset, so return early for another try.
 125         asObject(cell)-&gt;flattenDictionaryObject(vm);
 126         return RetryCacheLater;
 127     }
 128 
 129     if (!structure-&gt;propertyAccessesAreCacheable())
 130         return GiveUpOnCache;
 131 
 132     return AttemptToCache;
 133 }
 134 
<span class="line-modified"> 135 static bool forceICFailure(JSGlobalObject*)</span>
 136 {
 137     return Options::forceICFailure();
 138 }
 139 
 140 ALWAYS_INLINE static void fireWatchpointsAndClearStubIfNeeded(VM&amp; vm, StructureStubInfo&amp; stubInfo, CodeBlock* codeBlock, AccessGenerationResult&amp; result)
 141 {
 142     if (result.shouldResetStubAndFireWatchpoints()) {
 143         result.fireWatchpoints(vm);
 144         stubInfo.reset(codeBlock);
 145     }
 146 }
 147 
<span class="line-modified"> 148 inline FunctionPtr&lt;CFunctionPtrTag&gt; appropriateOptimizingGetByFunction(GetByKind kind)</span>
 149 {
 150     switch (kind) {
<span class="line-modified"> 151     case GetByKind::Normal:</span>
 152         return operationGetByIdOptimize;
<span class="line-modified"> 153     case GetByKind::WithThis:</span>
 154         return operationGetByIdWithThisOptimize;
<span class="line-modified"> 155     case GetByKind::Try:</span>
 156         return operationTryGetByIdOptimize;
<span class="line-modified"> 157     case GetByKind::Direct:</span>
 158         return operationGetByIdDirectOptimize;
<span class="line-added"> 159     case GetByKind::NormalByVal:</span>
<span class="line-added"> 160         return operationGetByValOptimize;</span>
 161     }
<span class="line-modified"> 162     RELEASE_ASSERT_NOT_REACHED();</span>

 163 }
 164 
<span class="line-modified"> 165 inline FunctionPtr&lt;CFunctionPtrTag&gt; appropriateGetByFunction(GetByKind kind)</span>
 166 {
 167     switch (kind) {
<span class="line-modified"> 168     case GetByKind::Normal:</span>
 169         return operationGetById;
<span class="line-modified"> 170     case GetByKind::WithThis:</span>
 171         return operationGetByIdWithThis;
<span class="line-modified"> 172     case GetByKind::Try:</span>
 173         return operationTryGetById;
<span class="line-modified"> 174     case GetByKind::Direct:</span>
 175         return operationGetByIdDirect;
<span class="line-added"> 176     case GetByKind::NormalByVal:</span>
<span class="line-added"> 177         return operationGetByValGeneric;</span>
 178     }
<span class="line-modified"> 179     RELEASE_ASSERT_NOT_REACHED();</span>

 180 }
 181 
<span class="line-modified"> 182 static InlineCacheAction tryCacheGetBy(JSGlobalObject* globalObject, CodeBlock* codeBlock, JSValue baseValue, CacheableIdentifier propertyName, const PropertySlot&amp; slot, StructureStubInfo&amp; stubInfo, GetByKind kind)</span>
 183 {
<span class="line-modified"> 184     VM&amp; vm = globalObject-&gt;vm();</span>
 185     AccessGenerationResult result;
 186 
 187     {
<span class="line-modified"> 188         GCSafeConcurrentJSLocker locker(codeBlock-&gt;m_lock, globalObject-&gt;vm().heap);</span>
 189 
<span class="line-modified"> 190         if (forceICFailure(globalObject))</span>
 191             return GiveUpOnCache;
 192 
 193         // FIXME: Cache property access for immediates.
 194         if (!baseValue.isCell())
 195             return GiveUpOnCache;
 196         JSCell* baseCell = baseValue.asCell();
 197 


 198         std::unique_ptr&lt;AccessCase&gt; newCase;
 199 
 200         if (propertyName == vm.propertyNames-&gt;length) {
 201             if (isJSArray(baseCell)) {
<span class="line-modified"> 202                 if (stubInfo.cacheType() == CacheType::Unset</span>
 203                     &amp;&amp; slot.slotBase() == baseCell
 204                     &amp;&amp; InlineAccess::isCacheableArrayLength(stubInfo, jsCast&lt;JSArray*&gt;(baseCell))) {
 205 
 206                     bool generatedCodeInline = InlineAccess::generateArrayLength(stubInfo, jsCast&lt;JSArray*&gt;(baseCell));
 207                     if (generatedCodeInline) {
<span class="line-modified"> 208                         ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation, appropriateOptimizingGetByFunction(kind));</span>
 209                         stubInfo.initArrayLength();
 210                         return RetryCacheLater;
 211                     }
 212                 }
 213 
<span class="line-modified"> 214                 newCase = AccessCase::create(vm, codeBlock, AccessCase::ArrayLength, propertyName);</span>
 215             } else if (isJSString(baseCell)) {
<span class="line-modified"> 216                 if (stubInfo.cacheType() == CacheType::Unset &amp;&amp; InlineAccess::isCacheableStringLength(stubInfo)) {</span>
 217                     bool generatedCodeInline = InlineAccess::generateStringLength(stubInfo);
 218                     if (generatedCodeInline) {
<span class="line-modified"> 219                         ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation, appropriateOptimizingGetByFunction(kind));</span>
 220                         stubInfo.initStringLength();
 221                         return RetryCacheLater;
 222                     }
 223                 }
 224 
<span class="line-modified"> 225                 newCase = AccessCase::create(vm, codeBlock, AccessCase::StringLength, propertyName);</span>
<span class="line-modified"> 226             } else if (DirectArguments* arguments = jsDynamicCast&lt;DirectArguments*&gt;(vm, baseCell)) {</span>

 227                 // If there were overrides, then we can handle this as a normal property load! Guarding
 228                 // this with such a check enables us to add an IC case for that load if needed.
 229                 if (!arguments-&gt;overrodeThings())
<span class="line-modified"> 230                     newCase = AccessCase::create(vm, codeBlock, AccessCase::DirectArgumentsLength, propertyName);</span>
 231             } else if (ScopedArguments* arguments = jsDynamicCast&lt;ScopedArguments*&gt;(vm, baseCell)) {
 232                 // Ditto.
 233                 if (!arguments-&gt;overrodeThings())
<span class="line-modified"> 234                     newCase = AccessCase::create(vm, codeBlock, AccessCase::ScopedArgumentsLength, propertyName);</span>
 235             }
 236         }
 237 
 238         if (!propertyName.isSymbol() &amp;&amp; baseCell-&gt;inherits&lt;JSModuleNamespaceObject&gt;(vm) &amp;&amp; !slot.isUnset()) {
 239             if (auto moduleNamespaceSlot = slot.moduleNamespaceSlot())
<span class="line-modified"> 240                 newCase = ModuleNamespaceAccessCase::create(vm, codeBlock, propertyName, jsCast&lt;JSModuleNamespaceObject*&gt;(baseCell), moduleNamespaceSlot-&gt;environment, ScopeOffset(moduleNamespaceSlot-&gt;scopeOffset));</span>
 241         }
 242 
 243         if (!newCase) {
 244             if (!slot.isCacheable() &amp;&amp; !slot.isUnset())
 245                 return GiveUpOnCache;
 246 
 247             ObjectPropertyConditionSet conditionSet;
 248             Structure* structure = baseCell-&gt;structure(vm);
 249 
 250             bool loadTargetFromProxy = false;
 251             if (baseCell-&gt;type() == PureForwardingProxyType) {
 252                 baseValue = jsCast&lt;JSProxy*&gt;(baseCell)-&gt;target();
 253                 baseCell = baseValue.asCell();
 254                 structure = baseCell-&gt;structure(vm);
 255                 loadTargetFromProxy = true;
 256             }
 257 
 258             InlineCacheAction action = actionForCell(vm, baseCell);
 259             if (action != AttemptToCache)
 260                 return action;
 261 
 262             // Optimize self access.
<span class="line-modified"> 263             if (stubInfo.cacheType() == CacheType::Unset</span>
 264                 &amp;&amp; slot.isCacheableValue()
 265                 &amp;&amp; slot.slotBase() == baseValue
 266                 &amp;&amp; !slot.watchpointSet()
 267                 &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()
 268                 &amp;&amp; !loadTargetFromProxy) {
 269 
 270                 bool generatedCodeInline = InlineAccess::generateSelfPropertyAccess(stubInfo, structure, slot.cachedOffset());
 271                 if (generatedCodeInline) {
<span class="line-modified"> 272                     LOG_IC((ICEvent::GetBySelfPatch, structure-&gt;classInfo(), Identifier::fromUid(vm, propertyName.uid()), slot.slotBase() == baseValue));</span>
 273                     structure-&gt;startWatchingPropertyForReplacements(vm, slot.cachedOffset());
<span class="line-modified"> 274                     ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation, appropriateOptimizingGetByFunction(kind));</span>
<span class="line-modified"> 275                     stubInfo.initGetByIdSelf(codeBlock, structure, slot.cachedOffset(), propertyName);</span>
 276                     return RetryCacheLater;
 277                 }
 278             }
 279 
 280             std::unique_ptr&lt;PolyProtoAccessChain&gt; prototypeAccessChain;
 281 
 282             PropertyOffset offset = slot.isUnset() ? invalidOffset : slot.cachedOffset();
 283 
<span class="line-added"> 284             if (slot.isCustom() &amp;&amp; slot.slotBase() == baseValue) {</span>
<span class="line-added"> 285                 // To cache self customs, we must disallow dictionaries because we</span>
<span class="line-added"> 286                 // need to be informed if the custom goes away since we cache the</span>
<span class="line-added"> 287                 // constant function pointer.</span>
<span class="line-added"> 288 </span>
<span class="line-added"> 289                 if (!prepareChainForCaching(globalObject, slot.slotBase(), slot.slotBase()))</span>
<span class="line-added"> 290                     return GiveUpOnCache;</span>
<span class="line-added"> 291             }</span>
<span class="line-added"> 292 </span>
 293             if (slot.isUnset() || slot.slotBase() != baseValue) {
 294                 if (structure-&gt;typeInfo().prohibitsPropertyCaching())
 295                     return GiveUpOnCache;
 296 
 297                 if (structure-&gt;isDictionary()) {
 298                     if (structure-&gt;hasBeenFlattenedBefore())
 299                         return GiveUpOnCache;
 300                     structure-&gt;flattenDictionaryStructure(vm, jsCast&lt;JSObject*&gt;(baseCell));
<span class="line-added"> 301                     return RetryCacheLater; // We may have changed property offsets.</span>
 302                 }
 303 
 304                 if (slot.isUnset() &amp;&amp; structure-&gt;typeInfo().getOwnPropertySlotIsImpureForPropertyAbsence())
 305                     return GiveUpOnCache;
 306 
<span class="line-modified"> 307                 // If a kind is GetByKind::Direct, we do not need to investigate prototype chains further.</span>
 308                 // Cacheability just depends on the head structure.
<span class="line-modified"> 309                 if (kind != GetByKind::Direct) {</span>
<span class="line-modified"> 310                     auto cacheStatus = prepareChainForCaching(globalObject, baseCell, slot);</span>
<span class="line-modified"> 311                     if (!cacheStatus)</span>


 312                         return GiveUpOnCache;
<span class="line-added"> 313 </span>
<span class="line-added"> 314                     if (cacheStatus-&gt;flattenedDictionary) {</span>
<span class="line-added"> 315                         // Property offsets may have changed due to flattening. We&#39;ll cache later.</span>
<span class="line-added"> 316                         return RetryCacheLater;</span>
 317                     }
 318 
<span class="line-modified"> 319                     if (cacheStatus-&gt;usesPolyProto) {</span>
<span class="line-added"> 320                         prototypeAccessChain = PolyProtoAccessChain::create(globalObject, baseCell, slot);</span>
<span class="line-added"> 321                         if (!prototypeAccessChain)</span>
<span class="line-added"> 322                             return GiveUpOnCache;</span>
<span class="line-added"> 323                         RELEASE_ASSERT(slot.isCacheableCustom() || prototypeAccessChain-&gt;slotBaseStructure(vm, structure)-&gt;get(vm, propertyName.uid()) == offset);</span>
<span class="line-added"> 324                     } else {</span>
 325                         // We use ObjectPropertyConditionSet instead for faster accesses.
 326                         prototypeAccessChain = nullptr;
 327 
 328                         // FIXME: Maybe this `if` should be inside generateConditionsForPropertyBlah.
 329                         // https://bugs.webkit.org/show_bug.cgi?id=185215
 330                         if (slot.isUnset()) {
 331                             conditionSet = generateConditionsForPropertyMiss(
<span class="line-modified"> 332                                 vm, codeBlock, globalObject, structure, propertyName.uid());</span>
 333                         } else if (!slot.isCacheableCustom()) {
 334                             conditionSet = generateConditionsForPrototypePropertyHit(
<span class="line-modified"> 335                                 vm, codeBlock, globalObject, structure, slot.slotBase(),</span>
<span class="line-modified"> 336                                 propertyName.uid());</span>
<span class="line-added"> 337                             RELEASE_ASSERT(!conditionSet.isValid() || conditionSet.slotBaseCondition().offset() == offset);</span>
 338                         } else {
 339                             conditionSet = generateConditionsForPrototypePropertyHitCustom(
<span class="line-modified"> 340                                 vm, codeBlock, globalObject, structure, slot.slotBase(),</span>
<span class="line-modified"> 341                                 propertyName.uid(), slot.attributes());</span>
 342                         }
 343 
 344                         if (!conditionSet.isValid())
 345                             return GiveUpOnCache;
 346                     }
 347                 }


 348             }
 349 
 350             JSFunction* getter = nullptr;
 351             if (slot.isCacheableGetter())
 352                 getter = jsDynamicCast&lt;JSFunction*&gt;(vm, slot.getterSetter()-&gt;getter());
 353 
 354             Optional&lt;DOMAttributeAnnotation&gt; domAttribute;
 355             if (slot.isCacheableCustom() &amp;&amp; slot.domAttribute())
 356                 domAttribute = slot.domAttribute();
 357 
<span class="line-modified"> 358             if (kind == GetByKind::Try) {</span>
 359                 AccessCase::AccessType type;
 360                 if (slot.isCacheableValue())
 361                     type = AccessCase::Load;
 362                 else if (slot.isUnset())
 363                     type = AccessCase::Miss;
 364                 else if (slot.isCacheableGetter())
 365                     type = AccessCase::GetGetter;
 366                 else
 367                     RELEASE_ASSERT_NOT_REACHED();
 368 
<span class="line-modified"> 369                 newCase = ProxyableAccessCase::create(vm, codeBlock, type, propertyName, offset, structure, conditionSet, loadTargetFromProxy, slot.watchpointSet(), WTFMove(prototypeAccessChain));</span>
 370             } else if (!loadTargetFromProxy &amp;&amp; getter &amp;&amp; IntrinsicGetterAccessCase::canEmitIntrinsicGetter(getter, structure))
<span class="line-modified"> 371                 newCase = IntrinsicGetterAccessCase::create(vm, codeBlock, propertyName, slot.cachedOffset(), structure, conditionSet, getter, WTFMove(prototypeAccessChain));</span>
 372             else {
 373                 if (slot.isCacheableValue() || slot.isUnset()) {
 374                     newCase = ProxyableAccessCase::create(vm, codeBlock, slot.isUnset() ? AccessCase::Miss : AccessCase::Load,
<span class="line-modified"> 375                         propertyName, offset, structure, conditionSet, loadTargetFromProxy, slot.watchpointSet(), WTFMove(prototypeAccessChain));</span>
 376                 } else {
 377                     AccessCase::AccessType type;
 378                     if (slot.isCacheableGetter())
 379                         type = AccessCase::Getter;
 380                     else if (slot.attributes() &amp; PropertyAttribute::CustomAccessor)
 381                         type = AccessCase::CustomAccessorGetter;
 382                     else
 383                         type = AccessCase::CustomValueGetter;
 384 
<span class="line-modified"> 385                     if (kind == GetByKind::WithThis &amp;&amp; type == AccessCase::CustomAccessorGetter &amp;&amp; domAttribute)</span>
 386                         return GiveUpOnCache;
 387 
 388                     newCase = GetterSetterAccessCase::create(
<span class="line-modified"> 389                         vm, codeBlock, type, propertyName, offset, structure, conditionSet, loadTargetFromProxy,</span>
 390                         slot.watchpointSet(), slot.isCacheableCustom() ? slot.customGetter() : nullptr,
 391                         slot.isCacheableCustom() &amp;&amp; slot.slotBase() != baseValue ? slot.slotBase() : nullptr,
 392                         domAttribute, WTFMove(prototypeAccessChain));
 393                 }
 394             }
 395         }
 396 
<span class="line-modified"> 397         LOG_IC((ICEvent::GetByAddAccessCase, baseValue.classInfoOrNull(vm), Identifier::fromUid(vm, propertyName.uid()), slot.slotBase() == baseValue));</span>
 398 
 399         result = stubInfo.addAccessCase(locker, codeBlock, propertyName, WTFMove(newCase));
 400 
 401         if (result.generatedSomeCode()) {
<span class="line-modified"> 402             LOG_IC((ICEvent::GetByReplaceWithJump, baseValue.classInfoOrNull(vm), Identifier::fromUid(vm, propertyName.uid()), slot.slotBase() == baseValue));</span>
 403 
 404             RELEASE_ASSERT(result.code());
 405             InlineAccess::rewireStubAsJump(stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));
 406         }
 407     }
 408 
<span class="line-modified"> 409     fireWatchpointsAndClearStubIfNeeded(vm, stubInfo, codeBlock, result);</span>
 410 
 411     return result.shouldGiveUpNow() ? GiveUpOnCache : RetryCacheLater;
 412 }
 413 
<span class="line-modified"> 414 void repatchGetBy(JSGlobalObject* globalObject, CodeBlock* codeBlock, JSValue baseValue, CacheableIdentifier propertyName, const PropertySlot&amp; slot, StructureStubInfo&amp; stubInfo, GetByKind kind)</span>
 415 {
 416     SuperSamplerScope superSamplerScope(false);
 417 
<span class="line-modified"> 418     if (tryCacheGetBy(globalObject, codeBlock, baseValue, propertyName, slot, stubInfo, kind) == GiveUpOnCache)</span>
<span class="line-modified"> 419         ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation, appropriateGetByFunction(kind));</span>
<span class="line-modified"> 420 }</span>
<span class="line-added"> 421 </span>
<span class="line-added"> 422 </span>
<span class="line-added"> 423 static InlineCacheAction tryCacheArrayGetByVal(JSGlobalObject* globalObject, CodeBlock* codeBlock, JSValue baseValue, JSValue index, StructureStubInfo&amp; stubInfo)</span>
<span class="line-added"> 424 {</span>
<span class="line-added"> 425     if (!baseValue.isCell())</span>
<span class="line-added"> 426         return GiveUpOnCache;</span>
<span class="line-added"> 427 </span>
<span class="line-added"> 428     if (!index.isInt32())</span>
<span class="line-added"> 429         return RetryCacheLater;</span>
<span class="line-added"> 430 </span>
<span class="line-added"> 431     VM&amp; vm = globalObject-&gt;vm();</span>
<span class="line-added"> 432     AccessGenerationResult result;</span>
<span class="line-added"> 433 </span>
<span class="line-added"> 434     {</span>
<span class="line-added"> 435         GCSafeConcurrentJSLocker locker(codeBlock-&gt;m_lock, globalObject-&gt;vm().heap);</span>
<span class="line-added"> 436 </span>
<span class="line-added"> 437         JSCell* base = baseValue.asCell();</span>
<span class="line-added"> 438 </span>
<span class="line-added"> 439         AccessCase::AccessType accessType;</span>
<span class="line-added"> 440         if (base-&gt;type() == DirectArgumentsType)</span>
<span class="line-added"> 441             accessType = AccessCase::IndexedDirectArgumentsLoad;</span>
<span class="line-added"> 442         else if (base-&gt;type() == ScopedArgumentsType)</span>
<span class="line-added"> 443             accessType = AccessCase::IndexedScopedArgumentsLoad;</span>
<span class="line-added"> 444         else if (base-&gt;type() == StringType)</span>
<span class="line-added"> 445             accessType = AccessCase::IndexedStringLoad;</span>
<span class="line-added"> 446         else if (isTypedView(base-&gt;classInfo(vm)-&gt;typedArrayStorageType)) {</span>
<span class="line-added"> 447             switch (base-&gt;classInfo(vm)-&gt;typedArrayStorageType) {</span>
<span class="line-added"> 448             case TypeInt8:</span>
<span class="line-added"> 449                 accessType = AccessCase::IndexedTypedArrayInt8Load;</span>
<span class="line-added"> 450                 break;</span>
<span class="line-added"> 451             case TypeUint8:</span>
<span class="line-added"> 452                 accessType = AccessCase::IndexedTypedArrayUint8Load;</span>
<span class="line-added"> 453                 break;</span>
<span class="line-added"> 454             case TypeUint8Clamped:</span>
<span class="line-added"> 455                 accessType = AccessCase::IndexedTypedArrayUint8ClampedLoad;</span>
<span class="line-added"> 456                 break;</span>
<span class="line-added"> 457             case TypeInt16:</span>
<span class="line-added"> 458                 accessType = AccessCase::IndexedTypedArrayInt16Load;</span>
<span class="line-added"> 459                 break;</span>
<span class="line-added"> 460             case TypeUint16:</span>
<span class="line-added"> 461                 accessType = AccessCase::IndexedTypedArrayUint16Load;</span>
<span class="line-added"> 462                 break;</span>
<span class="line-added"> 463             case TypeInt32:</span>
<span class="line-added"> 464                 accessType = AccessCase::IndexedTypedArrayInt32Load;</span>
<span class="line-added"> 465                 break;</span>
<span class="line-added"> 466             case TypeUint32:</span>
<span class="line-added"> 467                 accessType = AccessCase::IndexedTypedArrayUint32Load;</span>
<span class="line-added"> 468                 break;</span>
<span class="line-added"> 469             case TypeFloat32:</span>
<span class="line-added"> 470                 accessType = AccessCase::IndexedTypedArrayFloat32Load;</span>
<span class="line-added"> 471                 break;</span>
<span class="line-added"> 472             case TypeFloat64:</span>
<span class="line-added"> 473                 accessType = AccessCase::IndexedTypedArrayFloat64Load;</span>
<span class="line-added"> 474                 break;</span>
<span class="line-added"> 475             default:</span>
<span class="line-added"> 476                 RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-added"> 477             }</span>
<span class="line-added"> 478         } else {</span>
<span class="line-added"> 479             IndexingType indexingShape = base-&gt;indexingType() &amp; IndexingShapeMask;</span>
<span class="line-added"> 480             switch (indexingShape) {</span>
<span class="line-added"> 481             case Int32Shape:</span>
<span class="line-added"> 482                 accessType = AccessCase::IndexedInt32Load;</span>
<span class="line-added"> 483                 break;</span>
<span class="line-added"> 484             case DoubleShape:</span>
<span class="line-added"> 485                 accessType = AccessCase::IndexedDoubleLoad;</span>
<span class="line-added"> 486                 break;</span>
<span class="line-added"> 487             case ContiguousShape:</span>
<span class="line-added"> 488                 accessType = AccessCase::IndexedContiguousLoad;</span>
<span class="line-added"> 489                 break;</span>
<span class="line-added"> 490             case ArrayStorageShape:</span>
<span class="line-added"> 491                 accessType = AccessCase::IndexedArrayStorageLoad;</span>
<span class="line-added"> 492                 break;</span>
<span class="line-added"> 493             default:</span>
<span class="line-added"> 494                 return GiveUpOnCache;</span>
<span class="line-added"> 495             }</span>
<span class="line-added"> 496         }</span>
<span class="line-added"> 497 </span>
<span class="line-added"> 498         result = stubInfo.addAccessCase(locker, codeBlock, nullptr, AccessCase::create(vm, codeBlock, accessType, nullptr));</span>
<span class="line-added"> 499 </span>
<span class="line-added"> 500         if (result.generatedSomeCode()) {</span>
<span class="line-added"> 501             LOG_IC((ICEvent::GetByReplaceWithJump, baseValue.classInfoOrNull(vm), Identifier()));</span>
<span class="line-added"> 502 </span>
<span class="line-added"> 503             RELEASE_ASSERT(result.code());</span>
<span class="line-added"> 504             InlineAccess::rewireStubAsJump(stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));</span>
<span class="line-added"> 505         }</span>
 506     }
<span class="line-added"> 507 </span>
<span class="line-added"> 508     fireWatchpointsAndClearStubIfNeeded(vm, stubInfo, codeBlock, result);</span>
<span class="line-added"> 509     return result.shouldGiveUpNow() ? GiveUpOnCache : RetryCacheLater;</span>
<span class="line-added"> 510 }</span>
<span class="line-added"> 511 </span>
<span class="line-added"> 512 void repatchArrayGetByVal(JSGlobalObject* globalObject, CodeBlock* codeBlock, JSValue base, JSValue index, StructureStubInfo&amp; stubInfo)</span>
<span class="line-added"> 513 {</span>
<span class="line-added"> 514     if (tryCacheArrayGetByVal(globalObject, codeBlock, base, index, stubInfo) == GiveUpOnCache)</span>
<span class="line-added"> 515         ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation, operationGetByValGeneric);</span>
 516 }
 517 
<span class="line-modified"> 518 static V_JITOperation_GSsiJJI appropriateGenericPutByIdFunction(const PutPropertySlot &amp;slot, PutKind putKind)</span>
 519 {
 520     if (slot.isStrictMode()) {
 521         if (putKind == Direct)
 522             return operationPutByIdDirectStrict;
 523         return operationPutByIdStrict;
 524     }
 525     if (putKind == Direct)
 526         return operationPutByIdDirectNonStrict;
 527     return operationPutByIdNonStrict;
 528 }
 529 
<span class="line-modified"> 530 static V_JITOperation_GSsiJJI appropriateOptimizingPutByIdFunction(const PutPropertySlot &amp;slot, PutKind putKind)</span>
 531 {
 532     if (slot.isStrictMode()) {
 533         if (putKind == Direct)
 534             return operationPutByIdDirectStrictOptimize;
 535         return operationPutByIdStrictOptimize;
 536     }
 537     if (putKind == Direct)
 538         return operationPutByIdDirectNonStrictOptimize;
 539     return operationPutByIdNonStrictOptimize;
 540 }
 541 
<span class="line-modified"> 542 static InlineCacheAction tryCachePutByID(JSGlobalObject* globalObject, CodeBlock* codeBlock, JSValue baseValue, Structure* oldStructure, const Identifier&amp; ident, const PutPropertySlot&amp; slot, StructureStubInfo&amp; stubInfo, PutKind putKind)</span>
 543 {
<span class="line-modified"> 544     VM&amp; vm = globalObject-&gt;vm();</span>
 545     AccessGenerationResult result;
 546     {
<span class="line-modified"> 547         GCSafeConcurrentJSLocker locker(codeBlock-&gt;m_lock, globalObject-&gt;vm().heap);</span>
 548 
<span class="line-modified"> 549         if (forceICFailure(globalObject))</span>
 550             return GiveUpOnCache;
 551 


 552         if (!baseValue.isCell())
 553             return GiveUpOnCache;
 554 
 555         if (!slot.isCacheablePut() &amp;&amp; !slot.isCacheableCustom() &amp;&amp; !slot.isCacheableSetter())
 556             return GiveUpOnCache;
 557 
 558         // FIXME: We should try to do something smarter here...
<span class="line-modified"> 559         if (isCopyOnWrite(oldStructure-&gt;indexingMode()))</span>
 560             return GiveUpOnCache;
 561         // We can&#39;t end up storing to a CoW on the prototype since it shouldn&#39;t own properties.
 562         ASSERT(!isCopyOnWrite(slot.base()-&gt;indexingMode()));
 563 
<span class="line-modified"> 564         if (!oldStructure-&gt;propertyAccessesAreCacheable())</span>
 565             return GiveUpOnCache;
 566 
 567         std::unique_ptr&lt;AccessCase&gt; newCase;
 568         JSCell* baseCell = baseValue.asCell();
 569 
 570         if (slot.base() == baseValue &amp;&amp; slot.isCacheablePut()) {
 571             if (slot.type() == PutPropertySlot::ExistingProperty) {
 572                 // This assert helps catch bugs if we accidentally forget to disable caching
 573                 // when we transition then store to an existing property. This is common among
 574                 // paths that reify lazy properties. If we reify a lazy property and forget
 575                 // to disable caching, we may come down this path. The Replace IC does not
 576                 // know how to model these types of structure transitions (or any structure
 577                 // transition for that matter).
<span class="line-modified"> 578                 RELEASE_ASSERT(baseValue.asCell()-&gt;structure(vm) == oldStructure);</span>
 579 
<span class="line-modified"> 580                 oldStructure-&gt;didCachePropertyReplacement(vm, slot.cachedOffset());</span>
 581 
<span class="line-modified"> 582                 if (stubInfo.cacheType() == CacheType::Unset</span>
 583                     &amp;&amp; InlineAccess::canGenerateSelfPropertyReplace(stubInfo, slot.cachedOffset())
<span class="line-modified"> 584                     &amp;&amp; !oldStructure-&gt;needImpurePropertyWatchpoint()) {</span>
 585 
<span class="line-modified"> 586                     bool generatedCodeInline = InlineAccess::generateSelfPropertyReplace(stubInfo, oldStructure, slot.cachedOffset());</span>
 587                     if (generatedCodeInline) {
<span class="line-modified"> 588                         LOG_IC((ICEvent::PutByIdSelfPatch, oldStructure-&gt;classInfo(), ident, slot.base() == baseValue));</span>
<span class="line-modified"> 589                         ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation, appropriateOptimizingPutByIdFunction(slot, putKind));</span>
<span class="line-modified"> 590                         stubInfo.initPutByIdReplace(codeBlock, oldStructure, slot.cachedOffset());</span>
 591                         return RetryCacheLater;
 592                     }
 593                 }
 594 
<span class="line-modified"> 595                 newCase = AccessCase::create(vm, codeBlock, AccessCase::Replace, ident, slot.cachedOffset(), oldStructure);</span>
 596             } else {
 597                 ASSERT(slot.type() == PutPropertySlot::NewProperty);
 598 
<span class="line-modified"> 599                 if (!oldStructure-&gt;isObject())</span>
 600                     return GiveUpOnCache;
 601 
<span class="line-modified"> 602                 // If the old structure is dictionary, it means that this is one-on-one between an object and a structure.</span>
<span class="line-modified"> 603                 // If this is NewProperty operation, generating IC for this does not offer any benefit because this transition never happens again.</span>
<span class="line-modified"> 604                 if (oldStructure-&gt;isDictionary())</span>
<span class="line-modified"> 605                     return RetryCacheLater;</span>

 606 
 607                 PropertyOffset offset;
<span class="line-modified"> 608                 Structure* newStructure = Structure::addPropertyTransitionToExistingStructureConcurrently(oldStructure, ident.impl(), static_cast&lt;unsigned&gt;(PropertyAttribute::None), offset);</span>


 609                 if (!newStructure || !newStructure-&gt;propertyAccessesAreCacheable())
 610                     return GiveUpOnCache;
 611 
<span class="line-modified"> 612                 // If JSObject::put is overridden by UserObject, UserObject::put performs side-effect on JSObject::put, and it neglects to mark the PutPropertySlot as non-cachaeble,</span>
<span class="line-added"> 613                 // then arbitrary structure transitions can happen during the put operation, and this generates wrong transition information here as if oldStructure -&gt; newStructure.</span>
<span class="line-added"> 614                 // In reality, the transition is oldStructure -&gt; something unknown structures -&gt; baseValue&#39;s structure.</span>
<span class="line-added"> 615                 // To guard against the embedder&#39;s potentially incorrect UserObject::put implementation, we should check for this condition and if found, and give up on caching the put.</span>
<span class="line-added"> 616                 ASSERT(baseValue.asCell()-&gt;structure(vm) == newStructure);</span>
<span class="line-added"> 617                 if (baseValue.asCell()-&gt;structure(vm) != newStructure)</span>
<span class="line-added"> 618                     return GiveUpOnCache;</span>
<span class="line-added"> 619 </span>
<span class="line-added"> 620                 ASSERT(newStructure-&gt;previousID() == oldStructure);</span>
 621                 ASSERT(!newStructure-&gt;isDictionary());
 622                 ASSERT(newStructure-&gt;isObject());
 623 
 624                 std::unique_ptr&lt;PolyProtoAccessChain&gt; prototypeAccessChain;
 625                 ObjectPropertyConditionSet conditionSet;
 626                 if (putKind == NotDirect) {
<span class="line-modified"> 627                     auto cacheStatus = prepareChainForCaching(globalObject, baseCell, nullptr);</span>
<span class="line-modified"> 628                     if (!cacheStatus)</span>


 629                         return GiveUpOnCache;

 630 
<span class="line-modified"> 631                     if (cacheStatus-&gt;usesPolyProto) {</span>
<span class="line-added"> 632                         prototypeAccessChain = PolyProtoAccessChain::create(globalObject, baseCell, nullptr);</span>
<span class="line-added"> 633                         if (!prototypeAccessChain)</span>
<span class="line-added"> 634                             return GiveUpOnCache;</span>
<span class="line-added"> 635                     } else {</span>
 636                         prototypeAccessChain = nullptr;
<span class="line-modified"> 637                         conditionSet = generateConditionsForPropertySetterMiss(</span>
<span class="line-modified"> 638                             vm, codeBlock, globalObject, newStructure, ident.impl());</span>

 639                         if (!conditionSet.isValid())
 640                             return GiveUpOnCache;
 641                     }

 642                 }
 643 
<span class="line-modified"> 644                 newCase = AccessCase::create(vm, codeBlock, ident, offset, oldStructure, newStructure, conditionSet, WTFMove(prototypeAccessChain));</span>
 645             }
 646         } else if (slot.isCacheableCustom() || slot.isCacheableSetter()) {
 647             if (slot.isCacheableCustom()) {
 648                 ObjectPropertyConditionSet conditionSet;
 649                 std::unique_ptr&lt;PolyProtoAccessChain&gt; prototypeAccessChain;
 650 
<span class="line-modified"> 651                 // We need to do this even if we&#39;re a self custom, since we must disallow dictionaries</span>
<span class="line-modified"> 652                 // because we need to be informed if the custom goes away since we cache the constant</span>
<span class="line-modified"> 653                 // function pointer.</span>
<span class="line-modified"> 654                 auto cacheStatus = prepareChainForCaching(globalObject, baseCell, slot.base());</span>
<span class="line-modified"> 655                 if (!cacheStatus)</span>
<span class="line-modified"> 656                     return GiveUpOnCache;</span>

 657 
<span class="line-modified"> 658                 if (slot.base() != baseValue) {</span>
<span class="line-added"> 659                     if (cacheStatus-&gt;usesPolyProto) {</span>
<span class="line-added"> 660                         prototypeAccessChain = PolyProtoAccessChain::create(globalObject, baseCell, slot.base());</span>
<span class="line-added"> 661                         if (!prototypeAccessChain)</span>
<span class="line-added"> 662                             return GiveUpOnCache;</span>
<span class="line-added"> 663                     } else {</span>
 664                         prototypeAccessChain = nullptr;
<span class="line-modified"> 665                         conditionSet = generateConditionsForPrototypePropertyHitCustom(</span>
<span class="line-modified"> 666                             vm, codeBlock, globalObject, oldStructure, slot.base(), ident.impl(), static_cast&lt;unsigned&gt;(PropertyAttribute::None));</span>

 667                         if (!conditionSet.isValid())
 668                             return GiveUpOnCache;
 669                     }
 670                 }
 671 
 672                 newCase = GetterSetterAccessCase::create(
<span class="line-modified"> 673                     vm, codeBlock, slot.isCustomAccessor() ? AccessCase::CustomAccessorSetter : AccessCase::CustomValueSetter, oldStructure, ident,</span>
<span class="line-modified"> 674                     invalidOffset, conditionSet, WTFMove(prototypeAccessChain), slot.customSetter(), slot.base() != baseValue ? slot.base() : nullptr);</span>
 675             } else {
 676                 ObjectPropertyConditionSet conditionSet;
 677                 std::unique_ptr&lt;PolyProtoAccessChain&gt; prototypeAccessChain;
 678                 PropertyOffset offset = slot.cachedOffset();
 679 
 680                 if (slot.base() != baseValue) {
<span class="line-modified"> 681                     auto cacheStatus = prepareChainForCaching(globalObject, baseCell, slot.base());</span>
<span class="line-modified"> 682                     if (!cacheStatus)</span>


 683                         return GiveUpOnCache;
<span class="line-modified"> 684                     if (cacheStatus-&gt;flattenedDictionary)</span>
<span class="line-added"> 685                         return RetryCacheLater;</span>
 686 
<span class="line-modified"> 687                     if (cacheStatus-&gt;usesPolyProto) {</span>
<span class="line-added"> 688                         prototypeAccessChain = PolyProtoAccessChain::create(globalObject, baseCell, slot.base());</span>
<span class="line-added"> 689                         if (!prototypeAccessChain)</span>
<span class="line-added"> 690                             return GiveUpOnCache;</span>
<span class="line-added"> 691                         offset = prototypeAccessChain-&gt;slotBaseStructure(vm, baseCell-&gt;structure(vm))-&gt;get(vm, ident.impl());</span>
<span class="line-added"> 692                     } else {</span>
 693                         prototypeAccessChain = nullptr;
<span class="line-modified"> 694                         conditionSet = generateConditionsForPrototypePropertyHit(</span>
<span class="line-modified"> 695                             vm, codeBlock, globalObject, oldStructure, slot.base(), ident.impl());</span>

 696                         if (!conditionSet.isValid())
 697                             return GiveUpOnCache;
 698 
 699                         if (!(conditionSet.slotBaseCondition().attributes() &amp; PropertyAttribute::Accessor))
 700                             return GiveUpOnCache;
 701 
 702                         offset = conditionSet.slotBaseCondition().offset();
 703                     }

 704                 }
 705 
 706                 newCase = GetterSetterAccessCase::create(
<span class="line-modified"> 707                     vm, codeBlock, AccessCase::Setter, oldStructure, ident, offset, conditionSet, WTFMove(prototypeAccessChain));</span>
 708             }
 709         }
 710 
<span class="line-modified"> 711         LOG_IC((ICEvent::PutByIdAddAccessCase, oldStructure-&gt;classInfo(), ident, slot.base() == baseValue));</span>
 712 
 713         result = stubInfo.addAccessCase(locker, codeBlock, ident, WTFMove(newCase));
 714 
 715         if (result.generatedSomeCode()) {
<span class="line-modified"> 716             LOG_IC((ICEvent::PutByIdReplaceWithJump, oldStructure-&gt;classInfo(), ident, slot.base() == baseValue));</span>
 717 
 718             RELEASE_ASSERT(result.code());
 719 
 720             InlineAccess::rewireStubAsJump(stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));
 721         }
 722     }
 723 
<span class="line-modified"> 724     fireWatchpointsAndClearStubIfNeeded(vm, stubInfo, codeBlock, result);</span>
 725 
 726     return result.shouldGiveUpNow() ? GiveUpOnCache : RetryCacheLater;
 727 }
 728 
<span class="line-modified"> 729 void repatchPutByID(JSGlobalObject* globalObject, CodeBlock* codeBlock, JSValue baseValue, Structure* oldStructure, const Identifier&amp; propertyName, const PutPropertySlot&amp; slot, StructureStubInfo&amp; stubInfo, PutKind putKind)</span>
 730 {
 731     SuperSamplerScope superSamplerScope(false);
 732 
<span class="line-modified"> 733     if (tryCachePutByID(globalObject, codeBlock, baseValue, oldStructure, propertyName, slot, stubInfo, putKind) == GiveUpOnCache)</span>
<span class="line-modified"> 734         ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation, appropriateGenericPutByIdFunction(slot, putKind));</span>


 735 }
 736 
 737 static InlineCacheAction tryCacheInByID(
<span class="line-modified"> 738     JSGlobalObject* globalObject, CodeBlock* codeBlock, JSObject* base, const Identifier&amp; ident,</span>
 739     bool wasFound, const PropertySlot&amp; slot, StructureStubInfo&amp; stubInfo)
 740 {
<span class="line-modified"> 741     VM&amp; vm = globalObject-&gt;vm();</span>
 742     AccessGenerationResult result;
 743 
 744     {
<span class="line-modified"> 745         GCSafeConcurrentJSLocker locker(codeBlock-&gt;m_lock, vm.heap);</span>
<span class="line-modified"> 746         if (forceICFailure(globalObject))</span>
 747             return GiveUpOnCache;
 748 
 749         if (!base-&gt;structure(vm)-&gt;propertyAccessesAreCacheable() || (!wasFound &amp;&amp; !base-&gt;structure(vm)-&gt;propertyAccessesAreCacheableForAbsence()))
 750             return GiveUpOnCache;
 751 
 752         if (wasFound) {
 753             if (!slot.isCacheable())
 754                 return GiveUpOnCache;
 755         }
 756 

 757         Structure* structure = base-&gt;structure(vm);
 758 
 759         std::unique_ptr&lt;PolyProtoAccessChain&gt; prototypeAccessChain;
 760         ObjectPropertyConditionSet conditionSet;
 761         if (wasFound) {
 762             InlineCacheAction action = actionForCell(vm, base);
 763             if (action != AttemptToCache)
 764                 return action;
 765 
 766             // Optimize self access.
<span class="line-modified"> 767             if (stubInfo.cacheType() == CacheType::Unset</span>
 768                 &amp;&amp; slot.isCacheableValue()
 769                 &amp;&amp; slot.slotBase() == base
 770                 &amp;&amp; !slot.watchpointSet()
 771                 &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()) {
 772                 bool generatedCodeInline = InlineAccess::generateSelfInAccess(stubInfo, structure);
 773                 if (generatedCodeInline) {
 774                     LOG_IC((ICEvent::InByIdSelfPatch, structure-&gt;classInfo(), ident, slot.slotBase() == base));
 775                     structure-&gt;startWatchingPropertyForReplacements(vm, slot.cachedOffset());
<span class="line-modified"> 776                     ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation, operationInByIdOptimize);</span>
 777                     stubInfo.initInByIdSelf(codeBlock, structure, slot.cachedOffset());
 778                     return RetryCacheLater;
 779                 }
 780             }
 781 
 782             if (slot.slotBase() != base) {
<span class="line-modified"> 783                 auto cacheStatus = prepareChainForCaching(globalObject, base, slot);</span>
<span class="line-modified"> 784                 if (!cacheStatus)</span>


 785                     return GiveUpOnCache;
<span class="line-modified"> 786                 if (cacheStatus-&gt;flattenedDictionary)</span>
<span class="line-modified"> 787                     return RetryCacheLater;</span>
<span class="line-added"> 788 </span>
<span class="line-added"> 789                 if (cacheStatus-&gt;usesPolyProto) {</span>
<span class="line-added"> 790                     prototypeAccessChain = PolyProtoAccessChain::create(globalObject, base, slot);</span>
<span class="line-added"> 791                     if (!prototypeAccessChain)</span>
<span class="line-added"> 792                         return GiveUpOnCache;</span>
<span class="line-added"> 793                     RELEASE_ASSERT(slot.isCacheableCustom() || prototypeAccessChain-&gt;slotBaseStructure(vm, structure)-&gt;get(vm, ident.impl()) == slot.cachedOffset());</span>
<span class="line-added"> 794                 } else {</span>
 795                     prototypeAccessChain = nullptr;
 796                     conditionSet = generateConditionsForPrototypePropertyHit(
<span class="line-modified"> 797                         vm, codeBlock, globalObject, structure, slot.slotBase(), ident.impl());</span>
<span class="line-added"> 798                     if (!conditionSet.isValid())</span>
<span class="line-added"> 799                         return GiveUpOnCache;</span>
<span class="line-added"> 800                     RELEASE_ASSERT(slot.isCacheableCustom() || conditionSet.slotBaseCondition().offset() == slot.cachedOffset());</span>
 801                 }
 802             }
 803         } else {
<span class="line-modified"> 804             auto cacheStatus = prepareChainForCaching(globalObject, base, nullptr);</span>
<span class="line-modified"> 805             if (!cacheStatus)</span>


 806                 return GiveUpOnCache;

 807 
<span class="line-modified"> 808             if (cacheStatus-&gt;usesPolyProto) {</span>
<span class="line-added"> 809                 prototypeAccessChain = PolyProtoAccessChain::create(globalObject, base, slot);</span>
<span class="line-added"> 810                 if (!prototypeAccessChain)</span>
<span class="line-added"> 811                     return GiveUpOnCache;</span>
<span class="line-added"> 812             } else {</span>
 813                 prototypeAccessChain = nullptr;
 814                 conditionSet = generateConditionsForPropertyMiss(
<span class="line-modified"> 815                     vm, codeBlock, globalObject, structure, ident.impl());</span>
<span class="line-added"> 816                 if (!conditionSet.isValid())</span>
<span class="line-added"> 817                     return GiveUpOnCache;</span>
 818             }
 819         }


 820 
 821         LOG_IC((ICEvent::InAddAccessCase, structure-&gt;classInfo(), ident, slot.slotBase() == base));
 822 
 823         std::unique_ptr&lt;AccessCase&gt; newCase = AccessCase::create(
<span class="line-modified"> 824             vm, codeBlock, wasFound ? AccessCase::InHit : AccessCase::InMiss, ident, wasFound ? slot.cachedOffset() : invalidOffset, structure, conditionSet, WTFMove(prototypeAccessChain));</span>
 825 
 826         result = stubInfo.addAccessCase(locker, codeBlock, ident, WTFMove(newCase));
 827 
 828         if (result.generatedSomeCode()) {
 829             LOG_IC((ICEvent::InReplaceWithJump, structure-&gt;classInfo(), ident, slot.slotBase() == base));
 830 
 831             RELEASE_ASSERT(result.code());
 832             InlineAccess::rewireStubAsJump(stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));
 833         }
 834     }
 835 
<span class="line-modified"> 836     fireWatchpointsAndClearStubIfNeeded(vm, stubInfo, codeBlock, result);</span>
 837 
 838     return result.shouldGiveUpNow() ? GiveUpOnCache : RetryCacheLater;
 839 }
 840 
<span class="line-modified"> 841 void repatchInByID(JSGlobalObject* globalObject, CodeBlock* codeBlock, JSObject* baseObject, const Identifier&amp; propertyName, bool wasFound, const PropertySlot&amp; slot, StructureStubInfo&amp; stubInfo)</span>
 842 {
 843     SuperSamplerScope superSamplerScope(false);
 844 
<span class="line-modified"> 845     if (tryCacheInByID(globalObject, codeBlock, baseObject, propertyName, wasFound, slot, stubInfo) == GiveUpOnCache)</span>
<span class="line-modified"> 846         ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation, operationInById);</span>


 847 }
 848 
 849 static InlineCacheAction tryCacheInstanceOf(
<span class="line-modified"> 850     JSGlobalObject* globalObject, CodeBlock* codeBlock, JSValue valueValue, JSValue prototypeValue, StructureStubInfo&amp; stubInfo,</span>
 851     bool wasFound)
 852 {
<span class="line-modified"> 853     VM&amp; vm = globalObject-&gt;vm();</span>

 854     AccessGenerationResult result;
 855 
 856     RELEASE_ASSERT(valueValue.isCell()); // shouldConsiderCaching rejects non-cells.
 857 
<span class="line-modified"> 858     if (forceICFailure(globalObject))</span>
 859         return GiveUpOnCache;
 860 
 861     {
 862         GCSafeConcurrentJSLocker locker(codeBlock-&gt;m_lock, vm.heap);
 863 
 864         JSCell* value = valueValue.asCell();
 865         Structure* structure = value-&gt;structure(vm);
 866         std::unique_ptr&lt;AccessCase&gt; newCase;
 867         JSObject* prototype = jsDynamicCast&lt;JSObject*&gt;(vm, prototypeValue);
 868         if (prototype) {
 869             if (!jsDynamicCast&lt;JSObject*&gt;(vm, value)) {
 870                 newCase = InstanceOfAccessCase::create(
 871                     vm, codeBlock, AccessCase::InstanceOfMiss, structure, ObjectPropertyConditionSet(),
 872                     prototype);
 873             } else if (structure-&gt;prototypeQueriesAreCacheable()) {
 874                 // FIXME: Teach this to do poly proto.
 875                 // https://bugs.webkit.org/show_bug.cgi?id=185663
<span class="line-modified"> 876                 prepareChainForCaching(globalObject, value, wasFound ? prototype : nullptr);</span>
 877                 ObjectPropertyConditionSet conditionSet = generateConditionsForInstanceOf(
<span class="line-modified"> 878                     vm, codeBlock, globalObject, structure, prototype, wasFound);</span>
 879 
 880                 if (conditionSet.isValid()) {
 881                     newCase = InstanceOfAccessCase::create(
 882                         vm, codeBlock,
 883                         wasFound ? AccessCase::InstanceOfHit : AccessCase::InstanceOfMiss,
 884                         structure, conditionSet, prototype);
 885                 }
 886             }
 887         }
 888 
 889         if (!newCase)
<span class="line-modified"> 890             newCase = AccessCase::create(vm, codeBlock, AccessCase::InstanceOfGeneric, Identifier());</span>
 891 
 892         LOG_IC((ICEvent::InstanceOfAddAccessCase, structure-&gt;classInfo(), Identifier()));
 893 
<span class="line-modified"> 894         result = stubInfo.addAccessCase(locker, codeBlock, nullptr, WTFMove(newCase));</span>
 895 
 896         if (result.generatedSomeCode()) {
 897             LOG_IC((ICEvent::InstanceOfReplaceWithJump, structure-&gt;classInfo(), Identifier()));
 898 
 899             RELEASE_ASSERT(result.code());
 900 
 901             MacroAssembler::repatchJump(
 902                 stubInfo.patchableJump(),
 903                 CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));
 904         }
 905     }
 906 
 907     fireWatchpointsAndClearStubIfNeeded(vm, stubInfo, codeBlock, result);
 908 
 909     return result.shouldGiveUpNow() ? GiveUpOnCache : RetryCacheLater;
 910 }
 911 
 912 void repatchInstanceOf(
<span class="line-modified"> 913     JSGlobalObject* globalObject, CodeBlock* codeBlock, JSValue valueValue, JSValue prototypeValue, StructureStubInfo&amp; stubInfo,</span>
 914     bool wasFound)
 915 {
 916     SuperSamplerScope superSamplerScope(false);
<span class="line-modified"> 917     if (tryCacheInstanceOf(globalObject, codeBlock, valueValue, prototypeValue, stubInfo, wasFound) == GiveUpOnCache)</span>
<span class="line-modified"> 918         ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation, operationInstanceOfGeneric);</span>
 919 }
 920 
 921 static void linkSlowFor(VM&amp;, CallLinkInfo&amp; callLinkInfo, MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; codeRef)
 922 {
 923     MacroAssembler::repatchNearCall(callLinkInfo.callReturnLocation(), CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(codeRef.code()));
 924 }
 925 
 926 static void linkSlowFor(VM&amp; vm, CallLinkInfo&amp; callLinkInfo, ThunkGenerator generator)
 927 {
 928     linkSlowFor(vm, callLinkInfo, vm.getCTIStub(generator).retagged&lt;JITStubRoutinePtrTag&gt;());
 929 }
 930 
 931 static void linkSlowFor(VM&amp; vm, CallLinkInfo&amp; callLinkInfo)
 932 {
 933     MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; virtualThunk = virtualThunkFor(vm, callLinkInfo);
 934     linkSlowFor(vm, callLinkInfo, virtualThunk);
<span class="line-modified"> 935     callLinkInfo.setSlowStub(GCAwareJITStubRoutine::create(virtualThunk, vm));</span>
 936 }
 937 
 938 static JSCell* webAssemblyOwner(JSCell* callee)
 939 {
 940 #if ENABLE(WEBASSEMBLY)
 941     // Each WebAssembly.Instance shares the stubs from their WebAssembly.Module, which are therefore the appropriate owner.
<span class="line-modified"> 942     return jsCast&lt;JSWebAssemblyModule*&gt;(callee);</span>
 943 #else
 944     UNUSED_PARAM(callee);
 945     RELEASE_ASSERT_NOT_REACHED();
 946     return nullptr;
 947 #endif // ENABLE(WEBASSEMBLY)
 948 }
 949 
 950 void linkFor(
<span class="line-modified"> 951     VM&amp; vm, CallFrame* callFrame, CallLinkInfo&amp; callLinkInfo, CodeBlock* calleeCodeBlock,</span>
 952     JSObject* callee, MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr)
 953 {
 954     ASSERT(!callLinkInfo.stub());
 955 
<span class="line-modified"> 956     CallFrame* callerFrame = callFrame-&gt;callerFrame();</span>
 957     // Our caller must have a cell for a callee. When calling
 958     // this from Wasm, we ensure the callee is a cell.
 959     ASSERT(callerFrame-&gt;callee().isCell());
 960 

 961     CodeBlock* callerCodeBlock = callerFrame-&gt;codeBlock();
 962 
 963     // WebAssembly -&gt; JS stubs don&#39;t have a valid CodeBlock.
<span class="line-modified"> 964     JSCell* owner = isWebAssemblyModule(callerFrame-&gt;callee().asCell()) ? webAssemblyOwner(callerFrame-&gt;callee().asCell()) : callerCodeBlock;</span>
 965     ASSERT(owner);
 966 
 967     ASSERT(!callLinkInfo.isLinked());
 968     callLinkInfo.setCallee(vm, owner, callee);
 969     MacroAssembler::repatchPointer(callLinkInfo.hotPathBegin(), callee);
 970     callLinkInfo.setLastSeenCallee(vm, owner, callee);
 971     if (shouldDumpDisassemblyFor(callerCodeBlock))
 972         dataLog(&quot;Linking call in &quot;, FullCodeOrigin(callerCodeBlock, callLinkInfo.codeOrigin()), &quot; to &quot;, pointerDump(calleeCodeBlock), &quot;, entrypoint at &quot;, codePtr, &quot;\n&quot;);
 973 
 974     MacroAssembler::repatchNearCall(callLinkInfo.hotPathOther(), CodeLocationLabel&lt;JSEntryPtrTag&gt;(codePtr));
 975 
 976     if (calleeCodeBlock)
 977         calleeCodeBlock-&gt;linkIncomingCall(callerFrame, &amp;callLinkInfo);
 978 
 979     if (callLinkInfo.specializationKind() == CodeForCall &amp;&amp; callLinkInfo.allowStubs()) {
 980         linkSlowFor(vm, callLinkInfo, linkPolymorphicCallThunkGenerator);
 981         return;
 982     }
 983 
 984     linkSlowFor(vm, callLinkInfo);
 985 }
 986 
 987 void linkDirectFor(
<span class="line-modified"> 988     CallFrame* callFrame, CallLinkInfo&amp; callLinkInfo, CodeBlock* calleeCodeBlock,</span>
 989     MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr)
 990 {
 991     ASSERT(!callLinkInfo.stub());
 992 
<span class="line-modified"> 993     CodeBlock* callerCodeBlock = callFrame-&gt;codeBlock();</span>
 994 
 995     VM&amp; vm = callerCodeBlock-&gt;vm();
 996 
 997     ASSERT(!callLinkInfo.isLinked());
 998     callLinkInfo.setCodeBlock(vm, callerCodeBlock, jsCast&lt;FunctionCodeBlock*&gt;(calleeCodeBlock));
 999     if (shouldDumpDisassemblyFor(callerCodeBlock))
1000         dataLog(&quot;Linking call in &quot;, FullCodeOrigin(callerCodeBlock, callLinkInfo.codeOrigin()), &quot; to &quot;, pointerDump(calleeCodeBlock), &quot;, entrypoint at &quot;, codePtr, &quot;\n&quot;);
1001 
1002     if (callLinkInfo.callType() == CallLinkInfo::DirectTailCall)
1003         MacroAssembler::repatchJumpToNop(callLinkInfo.patchableJump());
1004     MacroAssembler::repatchNearCall(callLinkInfo.hotPathOther(), CodeLocationLabel&lt;JSEntryPtrTag&gt;(codePtr));
1005 
1006     if (calleeCodeBlock)
<span class="line-modified">1007         calleeCodeBlock-&gt;linkIncomingCall(callFrame, &amp;callLinkInfo);</span>
1008 }
1009 
<span class="line-modified">1010 void linkSlowFor(CallFrame* callFrame, CallLinkInfo&amp; callLinkInfo)</span>

1011 {
<span class="line-modified">1012     CodeBlock* callerCodeBlock = callFrame-&gt;callerFrame()-&gt;codeBlock();</span>
1013     VM&amp; vm = callerCodeBlock-&gt;vm();
1014 
1015     linkSlowFor(vm, callLinkInfo);
1016 }
1017 
1018 static void revertCall(VM&amp; vm, CallLinkInfo&amp; callLinkInfo, MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; codeRef)
1019 {
1020     if (callLinkInfo.isDirect()) {
1021         callLinkInfo.clearCodeBlock();
1022         if (!callLinkInfo.clearedByJettison()) {
1023             if (callLinkInfo.callType() == CallLinkInfo::DirectTailCall)
1024                 MacroAssembler::repatchJump(callLinkInfo.patchableJump(), callLinkInfo.slowPathStart());
1025             else
1026                 MacroAssembler::repatchNearCall(callLinkInfo.hotPathOther(), callLinkInfo.slowPathStart());
1027         }
1028     } else {
1029         if (!callLinkInfo.clearedByJettison()) {
1030             MacroAssembler::revertJumpReplacementToBranchPtrWithPatch(
1031                 MacroAssembler::startOfBranchPtrWithPatchOnRegister(callLinkInfo.hotPathBegin()),
1032                 callLinkInfo.calleeGPR(), 0);
1033             linkSlowFor(vm, callLinkInfo, codeRef);
1034             MacroAssembler::repatchPointer(callLinkInfo.hotPathBegin(), nullptr);
1035         }
1036         callLinkInfo.clearCallee();
1037     }
1038     callLinkInfo.clearSeen();
1039     callLinkInfo.clearStub();
1040     callLinkInfo.clearSlowStub();
1041     if (callLinkInfo.isOnList())
1042         callLinkInfo.remove();
1043 }
1044 
1045 void unlinkFor(VM&amp; vm, CallLinkInfo&amp; callLinkInfo)
1046 {
<span class="line-modified">1047     dataLogLnIf(Options::dumpDisassembly(), &quot;Unlinking call at &quot;, callLinkInfo.hotPathOther());</span>

1048 
1049     revertCall(vm, callLinkInfo, vm.getCTIStub(linkCallThunkGenerator).retagged&lt;JITStubRoutinePtrTag&gt;());
1050 }
1051 
<span class="line-modified">1052 static void linkVirtualFor(VM&amp; vm, CallFrame* callFrame, CallLinkInfo&amp; callLinkInfo)</span>
1053 {
<span class="line-modified">1054     CallFrame* callerFrame = callFrame-&gt;callerFrame();</span>

1055     CodeBlock* callerCodeBlock = callerFrame-&gt;codeBlock();
1056 
<span class="line-modified">1057     dataLogLnIf(shouldDumpDisassemblyFor(callerCodeBlock),</span>
<span class="line-modified">1058         &quot;Linking virtual call at &quot;, FullCodeOrigin(callerCodeBlock, callerFrame-&gt;codeOrigin()));</span>
1059 
1060     MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; virtualThunk = virtualThunkFor(vm, callLinkInfo);
1061     revertCall(vm, callLinkInfo, virtualThunk);
<span class="line-modified">1062     callLinkInfo.setSlowStub(GCAwareJITStubRoutine::create(virtualThunk, vm));</span>
1063     callLinkInfo.setClearedByVirtual();
1064 }
1065 
1066 namespace {
1067 struct CallToCodePtr {
1068     CCallHelpers::Call call;
1069     MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr;
1070 };
1071 } // annonymous namespace
1072 
<span class="line-modified">1073 void linkPolymorphicCall(JSGlobalObject* globalObject, CallFrame* callFrame, CallLinkInfo&amp; callLinkInfo, CallVariant newVariant)</span>

1074 {
1075     RELEASE_ASSERT(callLinkInfo.allowStubs());
1076 
<span class="line-modified">1077     CallFrame* callerFrame = callFrame-&gt;callerFrame();</span>
<span class="line-modified">1078     VM&amp; vm = globalObject-&gt;vm();</span>
1079 
1080     // During execution of linkPolymorphicCall, we strongly assume that we never do GC.
1081     // GC jettisons CodeBlocks, changes CallLinkInfo etc. and breaks assumption done before and after this call.
1082     DeferGCForAWhile deferGCForAWhile(vm.heap);
1083 
1084     if (!newVariant) {
<span class="line-modified">1085         linkVirtualFor(vm, callFrame, callLinkInfo);</span>
1086         return;
1087     }
1088 
1089     // Our caller must be have a cell for a callee. When calling
1090     // this from Wasm, we ensure the callee is a cell.
1091     ASSERT(callerFrame-&gt;callee().isCell());
1092 
1093     CodeBlock* callerCodeBlock = callerFrame-&gt;codeBlock();
<span class="line-modified">1094     bool isWebAssembly = isWebAssemblyModule(callerFrame-&gt;callee().asCell());</span>
1095 
1096     // WebAssembly -&gt; JS stubs don&#39;t have a valid CodeBlock.
1097     JSCell* owner = isWebAssembly ? webAssemblyOwner(callerFrame-&gt;callee().asCell()) : callerCodeBlock;
1098     ASSERT(owner);
1099 
1100     CallVariantList list;
1101     if (PolymorphicCallStubRoutine* stub = callLinkInfo.stub())
1102         list = stub-&gt;variants();
1103     else if (JSObject* oldCallee = callLinkInfo.callee())
1104         list = CallVariantList { CallVariant(oldCallee) };
1105 
1106     list = variantListWithVariant(list, newVariant);
1107 
1108     // If there are any closure calls then it makes sense to treat all of them as closure calls.
1109     // This makes switching on callee cheaper. It also produces profiling that&#39;s easier on the DFG;
1110     // the DFG doesn&#39;t really want to deal with a combination of closure and non-closure callees.
1111     bool isClosureCall = false;
1112     for (CallVariant variant : list)  {
1113         if (variant.isClosureCall()) {
1114             list = despecifiedVariantList(list);
1115             isClosureCall = true;
1116             break;
1117         }
1118     }
1119 
1120     if (isClosureCall)
1121         callLinkInfo.setHasSeenClosure();
1122 
1123     Vector&lt;PolymorphicCallCase&gt; callCases;
1124     Vector&lt;int64_t&gt; caseValues;
1125 
1126     // Figure out what our cases are.
1127     for (CallVariant variant : list) {
1128         CodeBlock* codeBlock = nullptr;
1129         if (variant.executable() &amp;&amp; !variant.executable()-&gt;isHostFunction()) {
1130             ExecutableBase* executable = variant.executable();
1131             codeBlock = jsCast&lt;FunctionExecutable*&gt;(executable)-&gt;codeBlockForCall();
1132             // If we cannot handle a callee, either because we don&#39;t have a CodeBlock or because arity mismatch,
1133             // assume that it&#39;s better for this whole thing to be a virtual call.
<span class="line-modified">1134             if (!codeBlock || callFrame-&gt;argumentCountIncludingThis() &lt; static_cast&lt;size_t&gt;(codeBlock-&gt;numParameters()) || callLinkInfo.isVarargs()) {</span>
<span class="line-modified">1135                 linkVirtualFor(vm, callFrame, callLinkInfo);</span>
1136                 return;
1137             }
1138         }
1139 
1140         int64_t newCaseValue = 0;
1141         if (isClosureCall) {
1142             newCaseValue = bitwise_cast&lt;intptr_t&gt;(variant.executable());
1143             // FIXME: We could add a fast path for InternalFunction with closure call.
1144             // https://bugs.webkit.org/show_bug.cgi?id=179311
1145             if (!newCaseValue)
1146                 continue;
1147         } else {
1148             if (auto* function = variant.function())
1149                 newCaseValue = bitwise_cast&lt;intptr_t&gt;(function);
1150             else
1151                 newCaseValue = bitwise_cast&lt;intptr_t&gt;(variant.internalFunction());
1152         }
1153 
<span class="line-modified">1154         if (ASSERT_ENABLED) {</span>
1155             if (caseValues.contains(newCaseValue)) {
1156                 dataLog(&quot;ERROR: Attempt to add duplicate case value.\n&quot;);
1157                 dataLog(&quot;Existing case values: &quot;);
1158                 CommaPrinter comma;
1159                 for (auto&amp; value : caseValues)
1160                     dataLog(comma, value);
1161                 dataLog(&quot;\n&quot;);
1162                 dataLog(&quot;Attempting to add: &quot;, newCaseValue, &quot;\n&quot;);
1163                 dataLog(&quot;Variant list: &quot;, listDump(callCases), &quot;\n&quot;);
1164                 RELEASE_ASSERT_NOT_REACHED();
1165             }
1166         }
1167 
1168         callCases.append(PolymorphicCallCase(variant, codeBlock));
1169         caseValues.append(newCaseValue);
1170     }
1171     ASSERT(callCases.size() == caseValues.size());
1172 
1173     // If we are over the limit, just use a normal virtual call.
1174     unsigned maxPolymorphicCallVariantListSize;
1175     if (isWebAssembly)
1176         maxPolymorphicCallVariantListSize = Options::maxPolymorphicCallVariantListSizeForWebAssemblyToJS();
1177     else if (callerCodeBlock-&gt;jitType() == JITCode::topTierJIT())
1178         maxPolymorphicCallVariantListSize = Options::maxPolymorphicCallVariantListSizeForTopTier();
1179     else
1180         maxPolymorphicCallVariantListSize = Options::maxPolymorphicCallVariantListSize();
1181 
1182     // We use list.size() instead of callCases.size() because we respect CallVariant size for now.
1183     if (list.size() &gt; maxPolymorphicCallVariantListSize) {
<span class="line-modified">1184         linkVirtualFor(vm, callFrame, callLinkInfo);</span>
1185         return;
1186     }
1187 
1188     Vector&lt;CallToCodePtr&gt; calls(callCases.size());
1189     UniqueArray&lt;uint32_t&gt; fastCounts;
1190 
1191     if (!isWebAssembly &amp;&amp; callerCodeBlock-&gt;jitType() != JITCode::topTierJIT()) {
1192         fastCounts = makeUniqueArray&lt;uint32_t&gt;(callCases.size());
1193         memset(fastCounts.get(), 0, callCases.size() * sizeof(uint32_t));
1194     }
1195 
1196     GPRReg calleeGPR = callLinkInfo.calleeGPR();
1197 
1198     CCallHelpers stubJit(callerCodeBlock);
1199 
1200     std::unique_ptr&lt;CallFrameShuffler&gt; frameShuffler;
1201     if (callLinkInfo.frameShuffleData()) {
1202         ASSERT(callLinkInfo.isTailCall());
1203         frameShuffler = makeUnique&lt;CallFrameShuffler&gt;(stubJit, *callLinkInfo.frameShuffleData());
1204 #if USE(JSVALUE32_64)
</pre>
<hr />
<pre>
1230     if (!frameShuffler &amp;&amp; callLinkInfo.isTailCall()) {
1231         // We strongly assume that calleeGPR is not a callee save register in the slow path.
1232         ASSERT(!callerCodeBlock-&gt;calleeSaveRegisters()-&gt;find(calleeGPR));
1233         stubJit.emitRestoreCalleeSaves();
1234     }
1235 
1236     CCallHelpers::JumpList slowPath;
1237     if (isClosureCall) {
1238         // Verify that we have a function and stash the executable in scratchGPR.
1239 #if USE(JSVALUE64)
1240         if (callLinkInfo.isTailCall())
1241             slowPath.append(stubJit.branchIfNotCell(calleeGPR, DoNotHaveTagRegisters));
1242         else
1243             slowPath.append(stubJit.branchIfNotCell(calleeGPR));
1244 #else
1245         // We would have already checked that the callee is a cell.
1246 #endif
1247         // FIXME: We could add a fast path for InternalFunction with closure call.
1248         slowPath.append(stubJit.branchIfNotFunction(calleeGPR));
1249 
<span class="line-modified">1250         stubJit.loadPtr(CCallHelpers::Address(calleeGPR, JSFunction::offsetOfExecutableOrRareData()), comparisonValueGPR);</span>
<span class="line-modified">1251         auto hasExecutable = stubJit.branchTestPtr(CCallHelpers::Zero, comparisonValueGPR, CCallHelpers::TrustedImm32(JSFunction::rareDataTag));</span>
<span class="line-modified">1252         stubJit.loadPtr(CCallHelpers::Address(comparisonValueGPR, FunctionRareData::offsetOfExecutable() - JSFunction::rareDataTag), comparisonValueGPR);</span>
<span class="line-added">1253         hasExecutable.link(&amp;stubJit);</span>
1254     }
1255 
1256     BinarySwitch binarySwitch(comparisonValueGPR, caseValues, BinarySwitch::IntPtr);
1257     CCallHelpers::JumpList done;
1258     while (binarySwitch.advance(stubJit)) {
1259         size_t caseIndex = binarySwitch.caseIndex();
1260 
1261         CallVariant variant = callCases[caseIndex].variant();
1262 
1263         MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr;
1264         if (variant.executable()) {
1265             ASSERT(variant.executable()-&gt;hasJITCodeForCall());
1266 
1267             codePtr = jsToWasmICCodePtr(vm, callLinkInfo.specializationKind(), variant.function());
1268             if (!codePtr)
1269                 codePtr = variant.executable()-&gt;generatedJITCodeForCall()-&gt;addressForCall(ArityCheckNotRequired);
1270         } else {
1271             ASSERT(variant.internalFunction());
1272             codePtr = vm.getCTIInternalFunctionTrampolineFor(CodeForCall);
1273         }
</pre>
<hr />
<pre>
1291 
1292     slowPath.link(&amp;stubJit);
1293     binarySwitch.fallThrough().link(&amp;stubJit);
1294 
1295     if (frameShuffler) {
1296         frameShuffler-&gt;releaseGPR(calleeGPR);
1297         frameShuffler-&gt;releaseGPR(comparisonValueGPR);
1298         frameShuffler-&gt;releaseGPR(fastCountsBaseGPR);
1299 #if USE(JSVALUE32_64)
1300         frameShuffler-&gt;setCalleeJSValueRegs(JSValueRegs(GPRInfo::regT1, GPRInfo::regT0));
1301 #else
1302         frameShuffler-&gt;setCalleeJSValueRegs(JSValueRegs(GPRInfo::regT0));
1303 #endif
1304         frameShuffler-&gt;prepareForSlowPath();
1305     } else {
1306         stubJit.move(calleeGPR, GPRInfo::regT0);
1307 #if USE(JSVALUE32_64)
1308         stubJit.move(CCallHelpers::TrustedImm32(JSValue::CellTag), GPRInfo::regT1);
1309 #endif
1310     }
<span class="line-added">1311     stubJit.move(CCallHelpers::TrustedImmPtr(globalObject), GPRInfo::regT3);</span>
1312     stubJit.move(CCallHelpers::TrustedImmPtr(&amp;callLinkInfo), GPRInfo::regT2);
1313     stubJit.move(CCallHelpers::TrustedImmPtr(callLinkInfo.callReturnLocation().untaggedExecutableAddress()), GPRInfo::regT4);
1314 
1315     stubJit.restoreReturnAddressBeforeReturn(GPRInfo::regT4);
1316     AssemblyHelpers::Jump slow = stubJit.jump();
1317 
1318     LinkBuffer patchBuffer(stubJit, owner, JITCompilationCanFail);
1319     if (patchBuffer.didFailToAllocate()) {
<span class="line-modified">1320         linkVirtualFor(vm, callFrame, callLinkInfo);</span>
1321         return;
1322     }
1323 
1324     RELEASE_ASSERT(callCases.size() == calls.size());
1325     for (CallToCodePtr callToCodePtr : calls) {
1326 #if CPU(ARM_THUMB2)
1327         // Tail call special-casing ensures proper linking on ARM Thumb2, where a tail call jumps to an address
1328         // with a non-decorated bottom bit but a normal call calls an address with a decorated bottom bit.
1329         bool isTailCall = callToCodePtr.call.isFlagSet(CCallHelpers::Call::Tail);
1330         void* target = isTailCall ? callToCodePtr.codePtr.dataLocation() : callToCodePtr.codePtr.executableAddress();
1331         patchBuffer.link(callToCodePtr.call, FunctionPtr&lt;JSEntryPtrTag&gt;(MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt;::createFromExecutableAddress(target)));
1332 #else
1333         patchBuffer.link(callToCodePtr.call, FunctionPtr&lt;JSEntryPtrTag&gt;(callToCodePtr.codePtr));
1334 #endif
1335     }
1336     if (isWebAssembly || JITCode::isOptimizingJIT(callerCodeBlock-&gt;jitType()))
1337         patchBuffer.link(done, callLinkInfo.callReturnLocation().labelAtOffset(0));
1338     else
1339         patchBuffer.link(done, callLinkInfo.hotPathOther().labelAtOffset(0));
1340     patchBuffer.link(slow, CodeLocationLabel&lt;JITThunkPtrTag&gt;(vm.getCTIStub(linkPolymorphicCallThunkGenerator).code()));
1341 
1342     auto stubRoutine = adoptRef(*new PolymorphicCallStubRoutine(
1343         FINALIZE_CODE_FOR(
1344             callerCodeBlock, patchBuffer, JITStubRoutinePtrTag,
1345             &quot;Polymorphic call stub for %s, return point %p, targets %s&quot;,
1346                 isWebAssembly ? &quot;WebAssembly&quot; : toCString(*callerCodeBlock).data(), callLinkInfo.callReturnLocation().labelAtOffset(0).executableAddress(),
1347                 toCString(listDump(callCases)).data()),
<span class="line-modified">1348         vm, owner, callFrame-&gt;callerFrame(), callLinkInfo, callCases,</span>
1349         WTFMove(fastCounts)));
1350 
1351     MacroAssembler::replaceWithJump(
1352         MacroAssembler::startOfBranchPtrWithPatchOnRegister(callLinkInfo.hotPathBegin()),
1353         CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(stubRoutine-&gt;code().code()));
1354     // The original slow path is unreachable on 64-bits, but still
1355     // reachable on 32-bits since a non-cell callee will always
1356     // trigger the slow path
1357     linkSlowFor(vm, callLinkInfo);
1358 
1359     // If there had been a previous stub routine, that one will die as soon as the GC runs and sees
1360     // that it&#39;s no longer on stack.
1361     callLinkInfo.setStub(WTFMove(stubRoutine));
1362 
1363     // The call link info no longer has a call cache apart from the jump to the polymorphic call
1364     // stub.
1365     if (callLinkInfo.isOnList())
1366         callLinkInfo.remove();
1367 }
1368 
<span class="line-modified">1369 void resetGetBy(CodeBlock* codeBlock, StructureStubInfo&amp; stubInfo, GetByKind kind)</span>
1370 {
<span class="line-modified">1371     ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation, appropriateOptimizingGetByFunction(kind));</span>
<span class="line-modified">1372     InlineAccess::rewireStubAsJump(stubInfo, stubInfo.slowPathStartLocation);</span>
1373 }
1374 
1375 void resetPutByID(CodeBlock* codeBlock, StructureStubInfo&amp; stubInfo)
1376 {
<span class="line-modified">1377     V_JITOperation_GSsiJJI unoptimizedFunction = reinterpret_cast&lt;V_JITOperation_GSsiJJI&gt;(readPutICCallTarget(codeBlock, stubInfo.slowPathCallLocation).executableAddress());</span>
<span class="line-modified">1378     V_JITOperation_GSsiJJI optimizedFunction;</span>
1379     if (unoptimizedFunction == operationPutByIdStrict || unoptimizedFunction == operationPutByIdStrictOptimize)
1380         optimizedFunction = operationPutByIdStrictOptimize;
1381     else if (unoptimizedFunction == operationPutByIdNonStrict || unoptimizedFunction == operationPutByIdNonStrictOptimize)
1382         optimizedFunction = operationPutByIdNonStrictOptimize;
1383     else if (unoptimizedFunction == operationPutByIdDirectStrict || unoptimizedFunction == operationPutByIdDirectStrictOptimize)
1384         optimizedFunction = operationPutByIdDirectStrictOptimize;
1385     else {
1386         ASSERT(unoptimizedFunction == operationPutByIdDirectNonStrict || unoptimizedFunction == operationPutByIdDirectNonStrictOptimize);
1387         optimizedFunction = operationPutByIdDirectNonStrictOptimize;
1388     }
1389 
<span class="line-modified">1390     ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation, optimizedFunction);</span>
<span class="line-modified">1391     InlineAccess::rewireStubAsJump(stubInfo, stubInfo.slowPathStartLocation);</span>
1392 }
1393 
1394 static void resetPatchableJump(StructureStubInfo&amp; stubInfo)
1395 {
<span class="line-modified">1396     MacroAssembler::repatchJump(stubInfo.patchableJump(), stubInfo.slowPathStartLocation);</span>
1397 }
1398 
1399 void resetInByID(CodeBlock* codeBlock, StructureStubInfo&amp; stubInfo)
1400 {
<span class="line-modified">1401     ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation, operationInByIdOptimize);</span>
<span class="line-modified">1402     InlineAccess::rewireStubAsJump(stubInfo, stubInfo.slowPathStartLocation);</span>
1403 }
1404 
1405 void resetInstanceOf(StructureStubInfo&amp; stubInfo)
1406 {
1407     resetPatchableJump(stubInfo);
1408 }
1409 
1410 MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; jsToWasmICCodePtr(VM&amp; vm, CodeSpecializationKind kind, JSObject* callee)
1411 {
1412 #if ENABLE(WEBASSEMBLY)
1413     if (!callee)
1414         return nullptr;
1415     if (kind != CodeForCall)
1416         return nullptr;
1417     if (auto* wasmFunction = jsDynamicCast&lt;WebAssemblyFunction*&gt;(vm, callee))
1418         return wasmFunction-&gt;jsCallEntrypoint();
1419 #else
1420     UNUSED_PARAM(vm);
1421     UNUSED_PARAM(kind);
1422     UNUSED_PARAM(callee);
</pre>
</td>
</tr>
</table>
<center><a href="RegisterSet.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="Repatch.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>