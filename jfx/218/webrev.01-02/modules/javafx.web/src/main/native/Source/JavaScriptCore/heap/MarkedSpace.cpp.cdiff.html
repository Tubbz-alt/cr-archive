<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/MarkedSpace.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="MarkedBlockInlines.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="MarkedSpace.h.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/MarkedSpace.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 25,10 ***</span>
<span class="line-new-header">--- 25,11 ---</span>
  #include &quot;FunctionCodeBlock.h&quot;
  #include &quot;IncrementalSweeper.h&quot;
  #include &quot;JSObject.h&quot;
  #include &quot;JSCInlines.h&quot;
  #include &quot;MarkedBlockInlines.h&quot;
<span class="line-added">+ #include &quot;MarkedSpaceInlines.h&quot;</span>
  #include &lt;wtf/ListDump.h&gt;
  
  namespace JSC {
  
  std::array&lt;size_t, MarkedSpace::numSizeClasses&gt; MarkedSpace::s_sizeClassForSizeStep;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 42,19 ***</span>
      std::call_once(
          once,
          [] {
              result = new Vector&lt;size_t&gt;();
  
<span class="line-modified">!             if (Options::dumpSizeClasses()) {</span>
                  dataLog(&quot;Block size: &quot;, MarkedBlock::blockSize, &quot;\n&quot;);
                  dataLog(&quot;Footer size: &quot;, sizeof(MarkedBlock::Footer), &quot;\n&quot;);
              }
  
              auto add = [&amp;] (size_t sizeClass) {
                  sizeClass = WTF::roundUpToMultipleOf&lt;MarkedBlock::atomSize&gt;(sizeClass);
<span class="line-modified">!                 if (Options::dumpSizeClasses())</span>
<span class="line-removed">-                     dataLog(&quot;Adding JSC MarkedSpace size class: &quot;, sizeClass, &quot;\n&quot;);</span>
                  // Perform some validation as we go.
                  RELEASE_ASSERT(!(sizeClass % MarkedSpace::sizeStep));
                  if (result-&gt;isEmpty())
                      RELEASE_ASSERT(sizeClass == MarkedSpace::sizeStep);
                  result-&gt;append(sizeClass);
<span class="line-new-header">--- 43,18 ---</span>
      std::call_once(
          once,
          [] {
              result = new Vector&lt;size_t&gt;();
  
<span class="line-modified">!             if (UNLIKELY(Options::dumpSizeClasses())) {</span>
                  dataLog(&quot;Block size: &quot;, MarkedBlock::blockSize, &quot;\n&quot;);
                  dataLog(&quot;Footer size: &quot;, sizeof(MarkedBlock::Footer), &quot;\n&quot;);
              }
  
              auto add = [&amp;] (size_t sizeClass) {
                  sizeClass = WTF::roundUpToMultipleOf&lt;MarkedBlock::atomSize&gt;(sizeClass);
<span class="line-modified">!                 dataLogLnIf(Options::dumpSizeClasses(), &quot;Adding JSC MarkedSpace size class: &quot;, sizeClass);</span>
                  // Perform some validation as we go.
                  RELEASE_ASSERT(!(sizeClass % MarkedSpace::sizeStep));
                  if (result-&gt;isEmpty())
                      RELEASE_ASSERT(sizeClass == MarkedSpace::sizeStep);
                  result-&gt;append(sizeClass);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 70,89 ***</span>
  
              // We want to make sure that the remaining size classes minimize internal fragmentation (i.e.
              // the wasted space at the tail end of a MarkedBlock) while proceeding roughly in an exponential
              // way starting at just above the precise size classes to four cells per block.
  
<span class="line-modified">!             if (Options::dumpSizeClasses())</span>
<span class="line-removed">-                 dataLog(&quot;    Marked block payload size: &quot;, static_cast&lt;size_t&gt;(MarkedSpace::blockPayload), &quot;\n&quot;);</span>
  
              for (unsigned i = 0; ; ++i) {
                  double approximateSize = MarkedSpace::preciseCutoff * pow(Options::sizeClassProgression(), i);
<span class="line-modified">! </span>
<span class="line-removed">-                 if (Options::dumpSizeClasses())</span>
<span class="line-removed">-                     dataLog(&quot;    Next size class as a double: &quot;, approximateSize, &quot;\n&quot;);</span>
  
                  size_t approximateSizeInBytes = static_cast&lt;size_t&gt;(approximateSize);
<span class="line-modified">! </span>
<span class="line-removed">-                 if (Options::dumpSizeClasses())</span>
<span class="line-removed">-                     dataLog(&quot;    Next size class as bytes: &quot;, approximateSizeInBytes, &quot;\n&quot;);</span>
  
                  // Make sure that the computer did the math correctly.
                  RELEASE_ASSERT(approximateSizeInBytes &gt;= MarkedSpace::preciseCutoff);
  
                  if (approximateSizeInBytes &gt; MarkedSpace::largeCutoff)
                      break;
  
                  size_t sizeClass =
                      WTF::roundUpToMultipleOf&lt;MarkedSpace::sizeStep&gt;(approximateSizeInBytes);
<span class="line-modified">! </span>
<span class="line-removed">-                 if (Options::dumpSizeClasses())</span>
<span class="line-removed">-                     dataLog(&quot;    Size class: &quot;, sizeClass, &quot;\n&quot;);</span>
  
                  // Optimize the size class so that there isn&#39;t any slop at the end of the block&#39;s
                  // payload.
                  unsigned cellsPerBlock = MarkedSpace::blockPayload / sizeClass;
                  size_t possiblyBetterSizeClass = (MarkedSpace::blockPayload / cellsPerBlock) &amp; ~(MarkedSpace::sizeStep - 1);
<span class="line-modified">! </span>
<span class="line-removed">-                 if (Options::dumpSizeClasses())</span>
<span class="line-removed">-                     dataLog(&quot;    Possibly better size class: &quot;, possiblyBetterSizeClass, &quot;\n&quot;);</span>
  
                  // The size class we just came up with is better than the other one if it reduces
                  // total wastage assuming we only allocate cells of that size.
                  size_t originalWastage = MarkedSpace::blockPayload - cellsPerBlock * sizeClass;
                  size_t newWastage = (possiblyBetterSizeClass - sizeClass) * cellsPerBlock;
<span class="line-modified">! </span>
<span class="line-removed">-                 if (Options::dumpSizeClasses())</span>
<span class="line-removed">-                     dataLog(&quot;    Original wastage: &quot;, originalWastage, &quot;, new wastage: &quot;, newWastage, &quot;\n&quot;);</span>
  
                  size_t betterSizeClass;
                  if (newWastage &gt; originalWastage)
                      betterSizeClass = sizeClass;
                  else
                      betterSizeClass = possiblyBetterSizeClass;
  
<span class="line-modified">!                 if (Options::dumpSizeClasses())</span>
<span class="line-removed">-                     dataLog(&quot;    Choosing size class: &quot;, betterSizeClass, &quot;\n&quot;);</span>
  
                  if (betterSizeClass == result-&gt;last()) {
                      // Defense for when expStep is small.
                      continue;
                  }
  
                  // This is usually how we get out of the loop.
                  if (betterSizeClass &gt; MarkedSpace::largeCutoff
<span class="line-modified">!                     || betterSizeClass &gt; Options::largeAllocationCutoff())</span>
                      break;
  
                  add(betterSizeClass);
              }
  
              // Manually inject size classes for objects we know will be allocated in high volume.
              // FIXME: All of these things should have IsoSubspaces.
              // https://bugs.webkit.org/show_bug.cgi?id=179876
<span class="line-modified">!             add(sizeof(UnlinkedFunctionCodeBlock));</span>
<span class="line-removed">-             add(sizeof(JSString));</span>
  
              {
                  // Sort and deduplicate.
                  std::sort(result-&gt;begin(), result-&gt;end());
                  auto it = std::unique(result-&gt;begin(), result-&gt;end());
                  result-&gt;shrinkCapacity(it - result-&gt;begin());
              }
  
<span class="line-modified">!             if (Options::dumpSizeClasses())</span>
<span class="line-removed">-                 dataLog(&quot;JSC Heap MarkedSpace size class dump: &quot;, listDump(*result), &quot;\n&quot;);</span>
  
              // We have an optimiation in MarkedSpace::optimalSizeFor() that assumes things about
              // the size class table. This checks our results against that function&#39;s assumptions.
              for (size_t size = MarkedSpace::sizeStep, i = 0; size &lt;= MarkedSpace::preciseCutoff; size += MarkedSpace::sizeStep, i++)
                  RELEASE_ASSERT(result-&gt;at(i) == size);
<span class="line-new-header">--- 70,75 ---</span>
  
              // We want to make sure that the remaining size classes minimize internal fragmentation (i.e.
              // the wasted space at the tail end of a MarkedBlock) while proceeding roughly in an exponential
              // way starting at just above the precise size classes to four cells per block.
  
<span class="line-modified">!             dataLogLnIf(Options::dumpSizeClasses(), &quot;    Marked block payload size: &quot;, static_cast&lt;size_t&gt;(MarkedSpace::blockPayload));</span>
  
              for (unsigned i = 0; ; ++i) {
                  double approximateSize = MarkedSpace::preciseCutoff * pow(Options::sizeClassProgression(), i);
<span class="line-modified">!                 dataLogLnIf(Options::dumpSizeClasses(), &quot;    Next size class as a double: &quot;, approximateSize);</span>
  
                  size_t approximateSizeInBytes = static_cast&lt;size_t&gt;(approximateSize);
<span class="line-modified">!                 dataLogLnIf(Options::dumpSizeClasses(), &quot;    Next size class as bytes: &quot;, approximateSizeInBytes);</span>
  
                  // Make sure that the computer did the math correctly.
                  RELEASE_ASSERT(approximateSizeInBytes &gt;= MarkedSpace::preciseCutoff);
  
                  if (approximateSizeInBytes &gt; MarkedSpace::largeCutoff)
                      break;
  
                  size_t sizeClass =
                      WTF::roundUpToMultipleOf&lt;MarkedSpace::sizeStep&gt;(approximateSizeInBytes);
<span class="line-modified">!                 dataLogLnIf(Options::dumpSizeClasses(), &quot;    Size class: &quot;, sizeClass);</span>
  
                  // Optimize the size class so that there isn&#39;t any slop at the end of the block&#39;s
                  // payload.
                  unsigned cellsPerBlock = MarkedSpace::blockPayload / sizeClass;
                  size_t possiblyBetterSizeClass = (MarkedSpace::blockPayload / cellsPerBlock) &amp; ~(MarkedSpace::sizeStep - 1);
<span class="line-modified">!                 dataLogLnIf(Options::dumpSizeClasses(), &quot;    Possibly better size class: &quot;, possiblyBetterSizeClass);</span>
  
                  // The size class we just came up with is better than the other one if it reduces
                  // total wastage assuming we only allocate cells of that size.
                  size_t originalWastage = MarkedSpace::blockPayload - cellsPerBlock * sizeClass;
                  size_t newWastage = (possiblyBetterSizeClass - sizeClass) * cellsPerBlock;
<span class="line-modified">!                 dataLogLnIf(Options::dumpSizeClasses(), &quot;    Original wastage: &quot;, originalWastage, &quot;, new wastage: &quot;, newWastage);</span>
  
                  size_t betterSizeClass;
                  if (newWastage &gt; originalWastage)
                      betterSizeClass = sizeClass;
                  else
                      betterSizeClass = possiblyBetterSizeClass;
  
<span class="line-modified">!                 dataLogLnIf(Options::dumpSizeClasses(), &quot;    Choosing size class: &quot;, betterSizeClass);</span>
  
                  if (betterSizeClass == result-&gt;last()) {
                      // Defense for when expStep is small.
                      continue;
                  }
  
                  // This is usually how we get out of the loop.
                  if (betterSizeClass &gt; MarkedSpace::largeCutoff
<span class="line-modified">!                     || betterSizeClass &gt; Options::preciseAllocationCutoff())</span>
                      break;
  
                  add(betterSizeClass);
              }
  
              // Manually inject size classes for objects we know will be allocated in high volume.
              // FIXME: All of these things should have IsoSubspaces.
              // https://bugs.webkit.org/show_bug.cgi?id=179876
<span class="line-modified">!             add(256);</span>
  
              {
                  // Sort and deduplicate.
                  std::sort(result-&gt;begin(), result-&gt;end());
                  auto it = std::unique(result-&gt;begin(), result-&gt;end());
                  result-&gt;shrinkCapacity(it - result-&gt;begin());
              }
  
<span class="line-modified">!             dataLogLnIf(Options::dumpSizeClasses(), &quot;JSC Heap MarkedSpace size class dump: &quot;, listDump(*result));</span>
  
              // We have an optimiation in MarkedSpace::optimalSizeFor() that assumes things about
              // the size class table. This checks our results against that function&#39;s assumptions.
              for (size_t size = MarkedSpace::sizeStep, i = 0; size &lt;= MarkedSpace::preciseCutoff; size += MarkedSpace::sizeStep, i++)
                  RELEASE_ASSERT(result-&gt;at(i) == size);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 194,12 ***</span>
                  });
          });
  }
  
  MarkedSpace::MarkedSpace(Heap* heap)
<span class="line-removed">-     : m_heap(heap)</span>
  {
      initializeSizeClassForStepSize();
  }
  
  MarkedSpace::~MarkedSpace()
  {
<span class="line-new-header">--- 180,12 ---</span>
                  });
          });
  }
  
  MarkedSpace::MarkedSpace(Heap* heap)
  {
<span class="line-added">+     ASSERT_UNUSED(heap, heap == &amp;this-&gt;heap());</span>
      initializeSizeClassForStepSize();
  }
  
  MarkedSpace::~MarkedSpace()
  {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 210,79 ***</span>
  {
      forEachBlock(
          [&amp;] (MarkedBlock::Handle* block) {
              freeBlock(block);
          });
<span class="line-modified">!     for (LargeAllocation* allocation : m_largeAllocations)</span>
          allocation-&gt;destroy();
  }
  
  void MarkedSpace::lastChanceToFinalize()
  {
      forEachDirectory(
          [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
              directory.lastChanceToFinalize();
              return IterationStatus::Continue;
          });
<span class="line-modified">!     for (LargeAllocation* allocation : m_largeAllocations)</span>
          allocation-&gt;lastChanceToFinalize();
  }
  
<span class="line-modified">! void MarkedSpace::sweep()</span>
  {
<span class="line-modified">!     m_heap-&gt;sweeper().stopSweeping();</span>
      forEachDirectory(
          [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
              directory.sweep();
              return IterationStatus::Continue;
          });
  }
  
<span class="line-modified">! void MarkedSpace::sweepLargeAllocations()</span>
  {
<span class="line-modified">!     RELEASE_ASSERT(m_largeAllocationsNurseryOffset == m_largeAllocations.size());</span>
<span class="line-modified">!     unsigned srcIndex = m_largeAllocationsNurseryOffsetForSweep;</span>
      unsigned dstIndex = srcIndex;
<span class="line-modified">!     while (srcIndex &lt; m_largeAllocations.size()) {</span>
<span class="line-modified">!         LargeAllocation* allocation = m_largeAllocations[srcIndex++];</span>
          allocation-&gt;sweep();
          if (allocation-&gt;isEmpty()) {
<span class="line-modified">!             m_capacity -= allocation-&gt;cellSize();</span>
<span class="line-modified">!             allocation-&gt;destroy();</span>
              continue;
          }
          allocation-&gt;setIndexInSpace(dstIndex);
<span class="line-modified">!         m_largeAllocations[dstIndex++] = allocation;</span>
      }
<span class="line-modified">!     m_largeAllocations.shrink(dstIndex);</span>
<span class="line-modified">!     m_largeAllocationsNurseryOffset = m_largeAllocations.size();</span>
  }
  
  void MarkedSpace::prepareForAllocation()
  {
<span class="line-modified">!     ASSERT(!Thread::mayBeGCThread() || m_heap-&gt;worldIsStopped());</span>
      for (Subspace* subspace : m_subspaces)
          subspace-&gt;prepareForAllocation();
  
      m_activeWeakSets.takeFrom(m_newActiveWeakSets);
  
<span class="line-modified">!     if (m_heap-&gt;collectionScope() == CollectionScope::Eden)</span>
<span class="line-modified">!         m_largeAllocationsNurseryOffsetForSweep = m_largeAllocationsNurseryOffset;</span>
      else
<span class="line-modified">!         m_largeAllocationsNurseryOffsetForSweep = 0;</span>
<span class="line-modified">!     m_largeAllocationsNurseryOffset = m_largeAllocations.size();</span>
  }
  
  void MarkedSpace::visitWeakSets(SlotVisitor&amp; visitor)
  {
      auto visit = [&amp;] (WeakSet* weakSet) {
          weakSet-&gt;visit(visitor);
      };
  
      m_newActiveWeakSets.forEach(visit);
  
<span class="line-modified">!     if (m_heap-&gt;collectionScope() == CollectionScope::Full)</span>
          m_activeWeakSets.forEach(visit);
  }
  
  void MarkedSpace::reapWeakSets()
  {
<span class="line-new-header">--- 196,98 ---</span>
  {
      forEachBlock(
          [&amp;] (MarkedBlock::Handle* block) {
              freeBlock(block);
          });
<span class="line-modified">!     for (PreciseAllocation* allocation : m_preciseAllocations)</span>
          allocation-&gt;destroy();
<span class="line-added">+     forEachSubspace([&amp;](Subspace&amp; subspace) {</span>
<span class="line-added">+         if (subspace.isIsoSubspace())</span>
<span class="line-added">+             static_cast&lt;IsoSubspace&amp;&gt;(subspace).destroyLowerTierFreeList();</span>
<span class="line-added">+         return IterationStatus::Continue;</span>
<span class="line-added">+     });</span>
  }
  
  void MarkedSpace::lastChanceToFinalize()
  {
      forEachDirectory(
          [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
              directory.lastChanceToFinalize();
              return IterationStatus::Continue;
          });
<span class="line-modified">!     for (PreciseAllocation* allocation : m_preciseAllocations)</span>
          allocation-&gt;lastChanceToFinalize();
<span class="line-added">+     // We do not call lastChanceToFinalize for lower-tier swept cells since we need nothing to do.</span>
  }
  
<span class="line-modified">! void MarkedSpace::sweepBlocks()</span>
  {
<span class="line-modified">!     heap().sweeper().stopSweeping();</span>
      forEachDirectory(
          [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
              directory.sweep();
              return IterationStatus::Continue;
          });
  }
  
<span class="line-modified">! void MarkedSpace::sweepPreciseAllocations()</span>
  {
<span class="line-modified">!     RELEASE_ASSERT(m_preciseAllocationsNurseryOffset == m_preciseAllocations.size());</span>
<span class="line-modified">!     unsigned srcIndex = m_preciseAllocationsNurseryOffsetForSweep;</span>
      unsigned dstIndex = srcIndex;
<span class="line-modified">!     while (srcIndex &lt; m_preciseAllocations.size()) {</span>
<span class="line-modified">!         PreciseAllocation* allocation = m_preciseAllocations[srcIndex++];</span>
          allocation-&gt;sweep();
          if (allocation-&gt;isEmpty()) {
<span class="line-modified">!             if (auto* set = preciseAllocationSet())</span>
<span class="line-modified">!                 set-&gt;remove(allocation-&gt;cell());</span>
<span class="line-added">+             if (allocation-&gt;isLowerTier())</span>
<span class="line-added">+                 static_cast&lt;IsoSubspace*&gt;(allocation-&gt;subspace())-&gt;sweepLowerTierCell(allocation);</span>
<span class="line-added">+             else {</span>
<span class="line-added">+                 m_capacity -= allocation-&gt;cellSize();</span>
<span class="line-added">+                 allocation-&gt;destroy();</span>
<span class="line-added">+             }</span>
              continue;
          }
          allocation-&gt;setIndexInSpace(dstIndex);
<span class="line-modified">!         m_preciseAllocations[dstIndex++] = allocation;</span>
      }
<span class="line-modified">!     m_preciseAllocations.shrink(dstIndex);</span>
<span class="line-modified">!     m_preciseAllocationsNurseryOffset = m_preciseAllocations.size();</span>
  }
  
  void MarkedSpace::prepareForAllocation()
  {
<span class="line-modified">!     ASSERT(!Thread::mayBeGCThread() || heap().worldIsStopped());</span>
      for (Subspace* subspace : m_subspaces)
          subspace-&gt;prepareForAllocation();
  
      m_activeWeakSets.takeFrom(m_newActiveWeakSets);
  
<span class="line-modified">!     if (heap().collectionScope() == CollectionScope::Eden)</span>
<span class="line-modified">!         m_preciseAllocationsNurseryOffsetForSweep = m_preciseAllocationsNurseryOffset;</span>
      else
<span class="line-modified">!         m_preciseAllocationsNurseryOffsetForSweep = 0;</span>
<span class="line-modified">!     m_preciseAllocationsNurseryOffset = m_preciseAllocations.size();</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ void MarkedSpace::enablePreciseAllocationTracking()</span>
<span class="line-added">+ {</span>
<span class="line-added">+     m_preciseAllocationSet = makeUnique&lt;HashSet&lt;HeapCell*&gt;&gt;();</span>
<span class="line-added">+     for (auto* allocation : m_preciseAllocations)</span>
<span class="line-added">+         m_preciseAllocationSet-&gt;add(allocation-&gt;cell());</span>
  }
  
  void MarkedSpace::visitWeakSets(SlotVisitor&amp; visitor)
  {
      auto visit = [&amp;] (WeakSet* weakSet) {
          weakSet-&gt;visit(visitor);
      };
  
      m_newActiveWeakSets.forEach(visit);
  
<span class="line-modified">!     if (heap().collectionScope() == CollectionScope::Full)</span>
          m_activeWeakSets.forEach(visit);
  }
  
  void MarkedSpace::reapWeakSets()
  {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 290,11 ***</span>
          weakSet-&gt;reap();
      };
  
      m_newActiveWeakSets.forEach(visit);
  
<span class="line-modified">!     if (m_heap-&gt;collectionScope() == CollectionScope::Full)</span>
          m_activeWeakSets.forEach(visit);
  }
  
  void MarkedSpace::stopAllocating()
  {
<span class="line-new-header">--- 295,11 ---</span>
          weakSet-&gt;reap();
      };
  
      m_newActiveWeakSets.forEach(visit);
  
<span class="line-modified">!     if (heap().collectionScope() == CollectionScope::Full)</span>
          m_activeWeakSets.forEach(visit);
  }
  
  void MarkedSpace::stopAllocating()
  {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 316,44 ***</span>
          });
  }
  
  void MarkedSpace::prepareForConservativeScan()
  {
<span class="line-modified">!     m_largeAllocationsForThisCollectionBegin = m_largeAllocations.begin() + m_largeAllocationsOffsetForThisCollection;</span>
<span class="line-modified">!     m_largeAllocationsForThisCollectionSize = m_largeAllocations.size() - m_largeAllocationsOffsetForThisCollection;</span>
<span class="line-modified">!     m_largeAllocationsForThisCollectionEnd = m_largeAllocations.end();</span>
<span class="line-modified">!     RELEASE_ASSERT(m_largeAllocationsForThisCollectionEnd == m_largeAllocationsForThisCollectionBegin + m_largeAllocationsForThisCollectionSize);</span>
  
      std::sort(
<span class="line-modified">!         m_largeAllocationsForThisCollectionBegin, m_largeAllocationsForThisCollectionEnd,</span>
<span class="line-modified">!         [&amp;] (LargeAllocation* a, LargeAllocation* b) {</span>
              return a &lt; b;
          });
<span class="line-modified">!     unsigned index = m_largeAllocationsOffsetForThisCollection;</span>
<span class="line-modified">!     for (auto* start = m_largeAllocationsForThisCollectionBegin; start != m_largeAllocationsForThisCollectionEnd; ++start, ++index) {</span>
          (*start)-&gt;setIndexInSpace(index);
<span class="line-modified">!         ASSERT(m_largeAllocations[index] == *start);</span>
<span class="line-modified">!         ASSERT(m_largeAllocations[index]-&gt;indexInSpace() == index);</span>
      }
  }
  
  void MarkedSpace::prepareForMarking()
  {
<span class="line-modified">!     if (m_heap-&gt;collectionScope() == CollectionScope::Eden)</span>
<span class="line-modified">!         m_largeAllocationsOffsetForThisCollection = m_largeAllocationsNurseryOffset;</span>
      else
<span class="line-modified">!         m_largeAllocationsOffsetForThisCollection = 0;</span>
  }
  
  void MarkedSpace::resumeAllocating()
  {
      forEachDirectory(
          [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
              directory.resumeAllocating();
              return IterationStatus::Continue;
          });
<span class="line-modified">!     // Nothing to do for LargeAllocations.</span>
  }
  
  bool MarkedSpace::isPagedOut(MonotonicTime deadline)
  {
      bool result = false;
<span class="line-new-header">--- 321,44 ---</span>
          });
  }
  
  void MarkedSpace::prepareForConservativeScan()
  {
<span class="line-modified">!     m_preciseAllocationsForThisCollectionBegin = m_preciseAllocations.begin() + m_preciseAllocationsOffsetForThisCollection;</span>
<span class="line-modified">!     m_preciseAllocationsForThisCollectionSize = m_preciseAllocations.size() - m_preciseAllocationsOffsetForThisCollection;</span>
<span class="line-modified">!     m_preciseAllocationsForThisCollectionEnd = m_preciseAllocations.end();</span>
<span class="line-modified">!     RELEASE_ASSERT(m_preciseAllocationsForThisCollectionEnd == m_preciseAllocationsForThisCollectionBegin + m_preciseAllocationsForThisCollectionSize);</span>
  
      std::sort(
<span class="line-modified">!         m_preciseAllocationsForThisCollectionBegin, m_preciseAllocationsForThisCollectionEnd,</span>
<span class="line-modified">!         [&amp;] (PreciseAllocation* a, PreciseAllocation* b) {</span>
              return a &lt; b;
          });
<span class="line-modified">!     unsigned index = m_preciseAllocationsOffsetForThisCollection;</span>
<span class="line-modified">!     for (auto* start = m_preciseAllocationsForThisCollectionBegin; start != m_preciseAllocationsForThisCollectionEnd; ++start, ++index) {</span>
          (*start)-&gt;setIndexInSpace(index);
<span class="line-modified">!         ASSERT(m_preciseAllocations[index] == *start);</span>
<span class="line-modified">!         ASSERT(m_preciseAllocations[index]-&gt;indexInSpace() == index);</span>
      }
  }
  
  void MarkedSpace::prepareForMarking()
  {
<span class="line-modified">!     if (heap().collectionScope() == CollectionScope::Eden)</span>
<span class="line-modified">!         m_preciseAllocationsOffsetForThisCollection = m_preciseAllocationsNurseryOffset;</span>
      else
<span class="line-modified">!         m_preciseAllocationsOffsetForThisCollection = 0;</span>
  }
  
  void MarkedSpace::resumeAllocating()
  {
      forEachDirectory(
          [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
              directory.resumeAllocating();
              return IterationStatus::Continue;
          });
<span class="line-modified">!     // Nothing to do for PreciseAllocations.</span>
  }
  
  bool MarkedSpace::isPagedOut(MonotonicTime deadline)
  {
      bool result = false;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 363,11 ***</span>
                  result = true;
                  return IterationStatus::Done;
              }
              return IterationStatus::Continue;
          });
<span class="line-modified">!     // FIXME: Consider taking LargeAllocations into account here.</span>
      return result;
  }
  
  void MarkedSpace::freeBlock(MarkedBlock::Handle* block)
  {
<span class="line-new-header">--- 368,11 ---</span>
                  result = true;
                  return IterationStatus::Done;
              }
              return IterationStatus::Continue;
          });
<span class="line-modified">!     // FIXME: Consider taking PreciseAllocations into account here.</span>
      return result;
  }
  
  void MarkedSpace::freeBlock(MarkedBlock::Handle* block)
  {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 396,11 ***</span>
          });
  }
  
  void MarkedSpace::beginMarking()
  {
<span class="line-modified">!     if (m_heap-&gt;collectionScope() == CollectionScope::Full) {</span>
          forEachDirectory(
              [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
                  directory.beginMarkingForFullCollection();
                  return IterationStatus::Continue;
              });
<span class="line-new-header">--- 401,11 ---</span>
          });
  }
  
  void MarkedSpace::beginMarking()
  {
<span class="line-modified">!     if (heap().collectionScope() == CollectionScope::Full) {</span>
          forEachDirectory(
              [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
                  directory.beginMarkingForFullCollection();
                  return IterationStatus::Continue;
              });
</pre>
<hr />
<pre>
<span class="line-old-header">*** 412,15 ***</span>
                  });
          }
  
          m_markingVersion = nextVersion(m_markingVersion);
  
<span class="line-modified">!         for (LargeAllocation* allocation : m_largeAllocations)</span>
              allocation-&gt;flip();
      }
  
<span class="line-modified">!     if (!ASSERT_DISABLED) {</span>
          forEachBlock(
              [&amp;] (MarkedBlock::Handle* block) {
                  if (block-&gt;areMarksStale())
                      return;
                  ASSERT(!block-&gt;isFreeListed());
<span class="line-new-header">--- 417,15 ---</span>
                  });
          }
  
          m_markingVersion = nextVersion(m_markingVersion);
  
<span class="line-modified">!         for (PreciseAllocation* allocation : m_preciseAllocations)</span>
              allocation-&gt;flip();
      }
  
<span class="line-modified">!     if (ASSERT_ENABLED) {</span>
          forEachBlock(
              [&amp;] (MarkedBlock::Handle* block) {
                  if (block-&gt;areMarksStale())
                      return;
                  ASSERT(!block-&gt;isFreeListed());
</pre>
<hr />
<pre>
<span class="line-old-header">*** 439,15 ***</span>
              });
      }
  
      m_newlyAllocatedVersion = nextVersion(m_newlyAllocatedVersion);
  
<span class="line-modified">!     for (unsigned i = m_largeAllocationsOffsetForThisCollection; i &lt; m_largeAllocations.size(); ++i)</span>
<span class="line-modified">!         m_largeAllocations[i]-&gt;clearNewlyAllocated();</span>
  
<span class="line-modified">!     if (!ASSERT_DISABLED) {</span>
<span class="line-modified">!         for (LargeAllocation* allocation : m_largeAllocations)</span>
              ASSERT_UNUSED(allocation, !allocation-&gt;isNewlyAllocated());
      }
  
      forEachDirectory(
          [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
<span class="line-new-header">--- 444,15 ---</span>
              });
      }
  
      m_newlyAllocatedVersion = nextVersion(m_newlyAllocatedVersion);
  
<span class="line-modified">!     for (unsigned i = m_preciseAllocationsOffsetForThisCollection; i &lt; m_preciseAllocations.size(); ++i)</span>
<span class="line-modified">!         m_preciseAllocations[i]-&gt;clearNewlyAllocated();</span>
  
<span class="line-modified">!     if (ASSERT_ENABLED) {</span>
<span class="line-modified">!         for (PreciseAllocation* allocation : m_preciseAllocations)</span>
              ASSERT_UNUSED(allocation, !allocation-&gt;isNewlyAllocated());
      }
  
      forEachDirectory(
          [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 477,11 ***</span>
      size_t result = 0;
      forEachBlock(
          [&amp;] (MarkedBlock::Handle* block) {
              result += block-&gt;markCount();
          });
<span class="line-modified">!     for (LargeAllocation* allocation : m_largeAllocations) {</span>
          if (allocation-&gt;isMarked())
              result++;
      }
      return result;
  }
<span class="line-new-header">--- 482,11 ---</span>
      size_t result = 0;
      forEachBlock(
          [&amp;] (MarkedBlock::Handle* block) {
              result += block-&gt;markCount();
          });
<span class="line-modified">!     for (PreciseAllocation* allocation : m_preciseAllocations) {</span>
          if (allocation-&gt;isMarked())
              result++;
      }
      return result;
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 491,11 ***</span>
      size_t result = 0;
      forEachBlock(
          [&amp;] (MarkedBlock::Handle* block) {
              result += block-&gt;markCount() * block-&gt;cellSize();
          });
<span class="line-modified">!     for (LargeAllocation* allocation : m_largeAllocations) {</span>
          if (allocation-&gt;isMarked())
              result += allocation-&gt;cellSize();
      }
      return result;
  }
<span class="line-new-header">--- 496,11 ---</span>
      size_t result = 0;
      forEachBlock(
          [&amp;] (MarkedBlock::Handle* block) {
              result += block-&gt;markCount() * block-&gt;cellSize();
          });
<span class="line-modified">!     for (PreciseAllocation* allocation : m_preciseAllocations) {</span>
          if (allocation-&gt;isMarked())
              result += allocation-&gt;cellSize();
      }
      return result;
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 531,11 ***</span>
      }
  }
  
  void MarkedSpace::snapshotUnswept()
  {
<span class="line-modified">!     if (m_heap-&gt;collectionScope() == CollectionScope::Eden) {</span>
          forEachDirectory(
              [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
                  directory.snapshotUnsweptForEdenCollection();
                  return IterationStatus::Continue;
              });
<span class="line-new-header">--- 536,11 ---</span>
      }
  }
  
  void MarkedSpace::snapshotUnswept()
  {
<span class="line-modified">!     if (heap().collectionScope() == CollectionScope::Eden) {</span>
          forEachDirectory(
              [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
                  directory.snapshotUnsweptForEdenCollection();
                  return IterationStatus::Continue;
              });
</pre>
<hr />
<pre>
<span class="line-old-header">*** 548,11 ***</span>
      }
  }
  
  void MarkedSpace::assertNoUnswept()
  {
<span class="line-modified">!     if (ASSERT_DISABLED)</span>
          return;
      forEachDirectory(
          [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
              directory.assertNoUnswept();
              return IterationStatus::Continue;
<span class="line-new-header">--- 553,11 ---</span>
      }
  }
  
  void MarkedSpace::assertNoUnswept()
  {
<span class="line-modified">!     if (!ASSERT_ENABLED)</span>
          return;
      forEachDirectory(
          [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
              directory.assertNoUnswept();
              return IterationStatus::Continue;
</pre>
<center><a href="MarkedBlockInlines.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="MarkedSpace.h.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>