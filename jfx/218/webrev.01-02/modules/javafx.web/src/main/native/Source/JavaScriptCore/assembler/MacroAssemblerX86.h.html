<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerX86.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2008-2019 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #if ENABLE(ASSEMBLER) &amp;&amp; CPU(X86)
 29 
 30 #include &quot;MacroAssemblerX86Common.h&quot;
 31 
 32 namespace JSC {
 33 
 34 class MacroAssemblerX86 : public MacroAssemblerX86Common {
 35 public:
 36     static constexpr unsigned numGPRs = 8;
 37     static constexpr unsigned numFPRs = 8;
 38 
 39     static constexpr Scale ScalePtr = TimesFour;
 40 
 41     using MacroAssemblerX86Common::add32;
 42     using MacroAssemblerX86Common::and32;
 43     using MacroAssemblerX86Common::branchAdd32;
 44     using MacroAssemblerX86Common::branchSub32;
 45     using MacroAssemblerX86Common::sub32;
 46     using MacroAssemblerX86Common::or32;
 47     using MacroAssemblerX86Common::load32;
 48     using MacroAssemblerX86Common::load8;
 49     using MacroAssemblerX86Common::store32;
 50     using MacroAssemblerX86Common::store8;
 51     using MacroAssemblerX86Common::branch32;
 52     using MacroAssemblerX86Common::call;
 53     using MacroAssemblerX86Common::jump;
 54     using MacroAssemblerX86Common::farJump;
 55     using MacroAssemblerX86Common::addDouble;
 56     using MacroAssemblerX86Common::loadDouble;
 57     using MacroAssemblerX86Common::storeDouble;
 58     using MacroAssemblerX86Common::convertInt32ToDouble;
 59     using MacroAssemblerX86Common::branch8;
 60     using MacroAssemblerX86Common::branchTest8;
 61 
 62     void add32(TrustedImm32 imm, RegisterID src, RegisterID dest)
 63     {
 64         m_assembler.leal_mr(imm.m_value, src, dest);
 65     }
 66 
 67     void add32(TrustedImm32 imm, AbsoluteAddress address)
 68     {
 69         m_assembler.addl_im(imm.m_value, address.m_ptr);
 70     }
 71 
 72     void add32(AbsoluteAddress address, RegisterID dest)
 73     {
 74         m_assembler.addl_mr(address.m_ptr, dest);
 75     }
 76 
 77     void add64(TrustedImm32 imm, AbsoluteAddress address)
 78     {
 79         m_assembler.addl_im(imm.m_value, address.m_ptr);
 80         m_assembler.adcl_im(imm.m_value &gt;&gt; 31, reinterpret_cast&lt;const char*&gt;(address.m_ptr) + sizeof(int32_t));
 81     }
 82 
 83     void getEffectiveAddress(BaseIndex address, RegisterID dest)
 84     {
 85         return x86Lea32(address, dest);
 86     }
 87 
 88     void and32(TrustedImm32 imm, AbsoluteAddress address)
 89     {
 90         m_assembler.andl_im(imm.m_value, address.m_ptr);
 91     }
 92 
 93     void or32(TrustedImm32 imm, AbsoluteAddress address)
 94     {
 95         m_assembler.orl_im(imm.m_value, address.m_ptr);
 96     }
 97 
 98     void or32(RegisterID reg, AbsoluteAddress address)
 99     {
100         m_assembler.orl_rm(reg, address.m_ptr);
101     }
102 
103     void or16(TrustedImm32 imm, AbsoluteAddress address)
104     {
105         m_assembler.orw_im(imm.m_value, address.m_ptr);
106     }
107 
108     void sub32(TrustedImm32 imm, AbsoluteAddress address)
109     {
110         m_assembler.subl_im(imm.m_value, address.m_ptr);
111     }
112 
113     void load32(const void* address, RegisterID dest)
114     {
115         m_assembler.movl_mr(address, dest);
116     }
117 
118     void load8(const void* address, RegisterID dest)
119     {
120         m_assembler.movzbl_mr(address, dest);
121     }
122 
123     void abortWithReason(AbortReason reason)
124     {
125         move(TrustedImm32(reason), X86Registers::eax);
126         breakpoint();
127     }
128 
129     void abortWithReason(AbortReason reason, intptr_t misc)
130     {
131         move(TrustedImm32(misc), X86Registers::edx);
132         abortWithReason(reason);
133     }
134 
135     ConvertibleLoadLabel convertibleLoadPtr(Address address, RegisterID dest)
136     {
137         ConvertibleLoadLabel result = ConvertibleLoadLabel(this);
138         m_assembler.movl_mr(address.offset, address.base, dest);
139         return result;
140     }
141 
142     void addDouble(AbsoluteAddress address, FPRegisterID dest)
143     {
144         m_assembler.addsd_mr(address.m_ptr, dest);
145     }
146 
147     void storeDouble(FPRegisterID src, TrustedImmPtr address)
148     {
149         ASSERT(address.m_value);
150         m_assembler.movsd_rm(src, address.asPtr());
151     }
152 
153     void convertInt32ToDouble(AbsoluteAddress src, FPRegisterID dest)
154     {
155         m_assembler.cvtsi2sd_mr(src.m_ptr, dest);
156     }
157 
158     void store32(TrustedImm32 imm, void* address)
159     {
160         m_assembler.movl_i32m(imm.m_value, address);
161     }
162 
163     void store32(RegisterID src, void* address)
164     {
165         m_assembler.movl_rm(src, address);
166     }
167 
168     void store8(RegisterID src, void* address)
169     {
170         m_assembler.movb_rm(src, address);
171     }
172 
173     void store8(TrustedImm32 imm, void* address)
174     {
175         TrustedImm32 imm8(static_cast&lt;int8_t&gt;(imm.m_value));
176         m_assembler.movb_i8m(imm8.m_value, address);
177     }
178 
179     void moveDoubleToInts(FPRegisterID src, RegisterID dest1, RegisterID dest2)
180     {
181         m_assembler.pextrw_irr(3, src, dest1);
182         m_assembler.pextrw_irr(2, src, dest2);
183         lshift32(TrustedImm32(16), dest1);
184         or32(dest1, dest2);
185         moveFloatTo32(src, dest1);
186     }
187 
188     void moveIntsToDouble(RegisterID src1, RegisterID src2, FPRegisterID dest, FPRegisterID scratch)
189     {
190         move32ToFloat(src1, dest);
191         move32ToFloat(src2, scratch);
192         lshiftPacked(TrustedImm32(32), scratch);
193         orPacked(scratch, dest);
194     }
195 
196     Jump branchAdd32(ResultCondition cond, TrustedImm32 imm, AbsoluteAddress dest)
197     {
198         m_assembler.addl_im(imm.m_value, dest.m_ptr);
199         return Jump(m_assembler.jCC(x86Condition(cond)));
200     }
201 
202     Jump branchSub32(ResultCondition cond, TrustedImm32 imm, AbsoluteAddress dest)
203     {
204         m_assembler.subl_im(imm.m_value, dest.m_ptr);
205         return Jump(m_assembler.jCC(x86Condition(cond)));
206     }
207 
208     Jump branch32(RelationalCondition cond, AbsoluteAddress left, RegisterID right)
209     {
210         m_assembler.cmpl_rm(right, left.m_ptr);
211         return Jump(m_assembler.jCC(x86Condition(cond)));
212     }
213 
214     Jump branch32(RelationalCondition cond, AbsoluteAddress left, TrustedImm32 right)
215     {
216         m_assembler.cmpl_im(right.m_value, left.m_ptr);
217         return Jump(m_assembler.jCC(x86Condition(cond)));
218     }
219 
220     Call call(PtrTag)
221     {
222         return Call(m_assembler.call(), Call::Linkable);
223     }
224 
225     ALWAYS_INLINE Call call(RegisterID callTag) { return UNUSED_PARAM(callTag), call(NoPtrTag); }
226 
227     // Address is a memory location containing the address to jump to
228     void farJump(AbsoluteAddress address, PtrTag)
229     {
230         m_assembler.jmp_m(address.m_ptr);
231     }
232 
233     ALWAYS_INLINE void farJump(AbsoluteAddress address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }
234 
235     DataLabelPtr moveWithPatch(TrustedImmPtr initialValue, RegisterID dest)
236     {
237         padBeforePatch();
238         m_assembler.movl_i32r(initialValue.asIntptr(), dest);
239         return DataLabelPtr(this);
240     }
241 
242     Jump branch8(RelationalCondition cond, AbsoluteAddress left, TrustedImm32 right)
243     {
244         TrustedImm32 right8(static_cast&lt;int8_t&gt;(right.m_value));
245         m_assembler.cmpb_im(right8.m_value, left.m_ptr);
246         return Jump(m_assembler.jCC(x86Condition(cond)));
247     }
248 
249     Jump branchTest8(ResultCondition cond, AbsoluteAddress address, TrustedImm32 mask = TrustedImm32(-1))
250     {
251         TrustedImm32 mask8(static_cast&lt;int8_t&gt;(mask.m_value));
252         if (mask8.m_value == -1)
253             m_assembler.cmpb_im(0, address.m_ptr);
254         else
255             m_assembler.testb_im(mask8.m_value, address.m_ptr);
256         return Jump(m_assembler.jCC(x86Condition(cond)));
257     }
258 
259     Jump branchPtrWithPatch(RelationalCondition cond, RegisterID left, DataLabelPtr&amp; dataLabel, TrustedImmPtr initialRightValue = TrustedImmPtr(nullptr))
260     {
261         padBeforePatch();
262         m_assembler.cmpl_ir_force32(initialRightValue.asIntptr(), left);
263         dataLabel = DataLabelPtr(this);
264         return Jump(m_assembler.jCC(x86Condition(cond)));
265     }
266 
267     Jump branchPtrWithPatch(RelationalCondition cond, Address left, DataLabelPtr&amp; dataLabel, TrustedImmPtr initialRightValue = TrustedImmPtr(nullptr))
268     {
269         padBeforePatch();
270         m_assembler.cmpl_im_force32(initialRightValue.asIntptr(), left.offset, left.base);
271         dataLabel = DataLabelPtr(this);
272         return Jump(m_assembler.jCC(x86Condition(cond)));
273     }
274 
275     Jump branch32WithPatch(RelationalCondition cond, Address left, DataLabel32&amp; dataLabel, TrustedImm32 initialRightValue = TrustedImm32(0))
276     {
277         padBeforePatch();
278         m_assembler.cmpl_im_force32(initialRightValue.m_value, left.offset, left.base);
279         dataLabel = DataLabel32(this);
280         return Jump(m_assembler.jCC(x86Condition(cond)));
281     }
282 
283     DataLabelPtr storePtrWithPatch(TrustedImmPtr initialValue, ImplicitAddress address)
284     {
285         padBeforePatch();
286         m_assembler.movl_i32m(initialValue.asIntptr(), address.offset, address.base);
287         return DataLabelPtr(this);
288     }
289 
290     static bool supportsFloatingPoint() { return true; }
291     static bool supportsFloatingPointTruncate() { return true; }
292     static bool supportsFloatingPointSqrt() { return true; }
293     static bool supportsFloatingPointAbs() { return true; }
294 
295     template&lt;PtrTag resultTag, PtrTag locationTag&gt;
296     static FunctionPtr&lt;resultTag&gt; readCallTarget(CodeLocationCall&lt;locationTag&gt; call)
297     {
298         intptr_t offset = WTF::unalignedLoad&lt;int32_t&gt;(bitwise_cast&lt;int32_t*&gt;(call.dataLocation()) - 1);
299         return FunctionPtr&lt;resultTag&gt;(reinterpret_cast&lt;void*&gt;(reinterpret_cast&lt;uintptr_t&gt;(call.dataLocation()) + offset));
300     }
301 
302     static bool canJumpReplacePatchableBranchPtrWithPatch() { return true; }
303     static bool canJumpReplacePatchableBranch32WithPatch() { return true; }
304 
305     template&lt;PtrTag tag&gt;
306     static CodeLocationLabel&lt;tag&gt; startOfBranchPtrWithPatchOnRegister(CodeLocationDataLabelPtr&lt;tag&gt; label)
307     {
308         const int opcodeBytes = 1;
309         const int modRMBytes = 1;
310         const int immediateBytes = 4;
311         const int totalBytes = opcodeBytes + modRMBytes + immediateBytes;
312         ASSERT(totalBytes &gt;= maxJumpReplacementSize());
313         return label.labelAtOffset(-totalBytes);
314     }
315 
316     template&lt;PtrTag tag&gt;
317     static CodeLocationLabel&lt;tag&gt; startOfPatchableBranchPtrWithPatchOnAddress(CodeLocationDataLabelPtr&lt;tag&gt; label)
318     {
319         const int opcodeBytes = 1;
320         const int modRMBytes = 1;
321         const int offsetBytes = 0;
322         const int immediateBytes = 4;
323         const int totalBytes = opcodeBytes + modRMBytes + offsetBytes + immediateBytes;
324         ASSERT(totalBytes &gt;= maxJumpReplacementSize());
325         return label.labelAtOffset(-totalBytes);
326     }
327 
328     template&lt;PtrTag tag&gt;
329     static CodeLocationLabel&lt;tag&gt; startOfPatchableBranch32WithPatchOnAddress(CodeLocationDataLabel32&lt;tag&gt; label)
330     {
331         const int opcodeBytes = 1;
332         const int modRMBytes = 1;
333         const int offsetBytes = 0;
334         const int immediateBytes = 4;
335         const int totalBytes = opcodeBytes + modRMBytes + offsetBytes + immediateBytes;
336         ASSERT(totalBytes &gt;= maxJumpReplacementSize());
337         return label.labelAtOffset(-totalBytes);
338     }
339 
340     template&lt;PtrTag tag&gt;
341     static void revertJumpReplacementToBranchPtrWithPatch(CodeLocationLabel&lt;tag&gt; instructionStart, RegisterID reg, void* initialValue)
342     {
343         X86Assembler::revertJumpTo_cmpl_ir_force32(instructionStart.executableAddress(), reinterpret_cast&lt;intptr_t&gt;(initialValue), reg);
344     }
345 
346     template&lt;PtrTag tag&gt;
347     static void revertJumpReplacementToPatchableBranchPtrWithPatch(CodeLocationLabel&lt;tag&gt; instructionStart, Address address, void* initialValue)
348     {
349         ASSERT(!address.offset);
350         X86Assembler::revertJumpTo_cmpl_im_force32(instructionStart.executableAddress(), reinterpret_cast&lt;intptr_t&gt;(initialValue), 0, address.base);
351     }
352 
353     template&lt;PtrTag tag&gt;
354     static void revertJumpReplacementToPatchableBranch32WithPatch(CodeLocationLabel&lt;tag&gt; instructionStart, Address address, int32_t initialValue)
355     {
356         ASSERT(!address.offset);
357         X86Assembler::revertJumpTo_cmpl_im_force32(instructionStart.executableAddress(), initialValue, 0, address.base);
358     }
359 
360     template&lt;PtrTag callTag, PtrTag destTag&gt;
361     static void repatchCall(CodeLocationCall&lt;callTag&gt; call, CodeLocationLabel&lt;destTag&gt; destination)
362     {
363         X86Assembler::relinkCall(call.dataLocation(), destination.executableAddress());
364     }
365 
366     template&lt;PtrTag callTag, PtrTag destTag&gt;
367     static void repatchCall(CodeLocationCall&lt;callTag&gt; call, FunctionPtr&lt;destTag&gt; destination)
368     {
369         X86Assembler::relinkCall(call.dataLocation(), destination.executableAddress());
370     }
371 
372 private:
373     friend class LinkBuffer;
374 
375     template&lt;PtrTag tag&gt;
376     static void linkCall(void* code, Call call, FunctionPtr&lt;tag&gt; function)
377     {
378         if (call.isFlagSet(Call::Tail))
379             X86Assembler::linkJump(code, call.m_label, function.executableAddress());
380         else
381             X86Assembler::linkCall(code, call.m_label, function.executableAddress());
382     }
383 };
384 
385 } // namespace JSC
386 
387 #endif // ENABLE(ASSEMBLER)
    </pre>
  </body>
</html>