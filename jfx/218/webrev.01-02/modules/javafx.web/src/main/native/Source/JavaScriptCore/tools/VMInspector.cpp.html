<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/JavaScriptCore/tools/VMInspector.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2017-2019 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;VMInspector.h&quot;
 28 
 29 #include &quot;CodeBlock.h&quot;
 30 #include &quot;CodeBlockSet.h&quot;
 31 #include &quot;HeapInlines.h&quot;
 32 #include &quot;HeapIterationScope.h&quot;
 33 #include &quot;JSCInlines.h&quot;
 34 #include &quot;MachineContext.h&quot;
 35 #include &quot;MarkedSpaceInlines.h&quot;
 36 #include &quot;StackVisitor.h&quot;
 37 #include &lt;mutex&gt;
 38 #include &lt;wtf/Expected.h&gt;
 39 
 40 #if !OS(WINDOWS)
 41 #include &lt;unistd.h&gt;
 42 #endif
 43 
 44 namespace JSC {
 45 
 46 VMInspector&amp; VMInspector::instance()
 47 {
 48     static VMInspector* manager;
 49     static std::once_flag once;
 50     std::call_once(once, [] {
 51         manager = new VMInspector();
 52     });
 53     return *manager;
 54 }
 55 
 56 void VMInspector::add(VM* vm)
 57 {
 58     auto locker = holdLock(m_lock);
 59     m_vmList.append(vm);
 60 }
 61 
 62 void VMInspector::remove(VM* vm)
 63 {
 64     auto locker = holdLock(m_lock);
 65     m_vmList.remove(vm);
 66 }
 67 
 68 auto VMInspector::lock(Seconds timeout) -&gt; Expected&lt;Locker, Error&gt;
 69 {
 70     // This function may be called from a signal handler (e.g. via visit()). Hence,
 71     // it should only use APIs that are safe to call from signal handlers. This is
 72     // why we use unistd.h&#39;s sleep() instead of its alternatives.
 73 
 74     // We&#39;ll be doing sleep(1) between tries below. Hence, sleepPerRetry is 1.
 75     unsigned maxRetries = (timeout &lt; Seconds::infinity()) ? timeout.value() : UINT_MAX;
 76 
 77     Expected&lt;Locker, Error&gt; locker = Locker::tryLock(m_lock);
 78     unsigned tryCount = 0;
 79     while (!locker &amp;&amp; tryCount &lt; maxRetries) {
 80         // We want the version of sleep from unistd.h. Cast to disambiguate.
 81 #if !OS(WINDOWS)
 82         (static_cast&lt;unsigned (*)(unsigned)&gt;(sleep))(1);
 83 #endif
 84         locker = Locker::tryLock(m_lock);
 85     }
 86 
 87     if (!locker)
 88         return makeUnexpected(Error::TimedOut);
 89     return locker;
 90 }
 91 
 92 #if ENABLE(JIT)
 93 static bool ensureIsSafeToLock(Lock&amp; lock)
 94 {
 95     unsigned maxRetries = 2;
 96     unsigned tryCount = 0;
 97     while (tryCount &lt;= maxRetries) {
 98         bool success = lock.tryLock();
 99         if (success) {
100             lock.unlock();
101             return true;
102         }
103         tryCount++;
104     }
105     return false;
106 };
107 #endif // ENABLE(JIT)
108 
109 void VMInspector::forEachVM(Function&lt;FunctorStatus(VM&amp;)&gt;&amp;&amp; func)
110 {
111     VMInspector&amp; inspector = instance();
112     Locker lock(inspector.getLock());
113     inspector.iterate(func);
114 }
115 
116 auto VMInspector::isValidExecutableMemory(const VMInspector::Locker&amp;, void* machinePC) -&gt; Expected&lt;bool, Error&gt;
117 {
118 #if ENABLE(JIT)
119     bool found = false;
120     bool hasTimeout = false;
121     iterate([&amp;] (VM&amp;) -&gt; FunctorStatus {
122         auto&amp; allocator = ExecutableAllocator::singleton();
123         auto&amp; lock = allocator.getLock();
124 
125         bool isSafeToLock = ensureIsSafeToLock(lock);
126         if (!isSafeToLock) {
127             hasTimeout = true;
128             return FunctorStatus::Continue; // Skip this VM.
129         }
130 
131         LockHolder executableAllocatorLocker(lock);
132         if (allocator.isValidExecutableMemory(executableAllocatorLocker, machinePC)) {
133             found = true;
134             return FunctorStatus::Done;
135         }
136         return FunctorStatus::Continue;
137     });
138 
139     if (!found &amp;&amp; hasTimeout)
140         return makeUnexpected(Error::TimedOut);
141     return found;
142 #else
143     UNUSED_PARAM(machinePC);
144     return false;
145 #endif
146 }
147 
148 auto VMInspector::codeBlockForMachinePC(const VMInspector::Locker&amp;, void* machinePC) -&gt; Expected&lt;CodeBlock*, Error&gt;
149 {
150 #if ENABLE(JIT)
151     CodeBlock* codeBlock = nullptr;
152     bool hasTimeout = false;
153     iterate([&amp;] (VM&amp; vm) {
154         if (!vm.currentThreadIsHoldingAPILock())
155             return FunctorStatus::Continue;
156 
157         // It is safe to call Heap::forEachCodeBlockIgnoringJITPlans here because:
158         // 1. CodeBlocks are added to the CodeBlockSet from the main thread before
159         //    they are handed to the JIT plans. Those codeBlocks will have a null jitCode,
160         //    but we check for that in our lambda functor.
161         // 2. We will acquire the CodeBlockSet lock before iterating.
162         //    This ensures that a CodeBlock won&#39;t be GCed while we&#39;re iterating.
163         // 3. We do a tryLock on the CodeBlockSet&#39;s lock first to ensure that it is
164         //    safe for the current thread to lock it before calling
165         //    Heap::forEachCodeBlockIgnoringJITPlans(). Hence, there&#39;s no risk of
166         //    re-entering the lock and deadlocking on it.
167 
168         auto&amp; codeBlockSetLock = vm.heap.codeBlockSet().getLock();
169         bool isSafeToLock = ensureIsSafeToLock(codeBlockSetLock);
170         if (!isSafeToLock) {
171             hasTimeout = true;
172             return FunctorStatus::Continue; // Skip this VM.
173         }
174 
175         auto locker = holdLock(codeBlockSetLock);
176         vm.heap.forEachCodeBlockIgnoringJITPlans(locker, [&amp;] (CodeBlock* cb) {
177             JITCode* jitCode = cb-&gt;jitCode().get();
178             if (!jitCode) {
179                 // If the codeBlock is a replacement codeBlock which is in the process of being
180                 // compiled, its jitCode will be null, and we can disregard it as a match for
181                 // the machinePC we&#39;re searching for.
182                 return;
183             }
184 
185             if (!JITCode::isJIT(jitCode-&gt;jitType()))
186                 return;
187 
188             if (jitCode-&gt;contains(machinePC)) {
189                 codeBlock = cb;
190                 return;
191             }
192         });
193         if (codeBlock)
194             return FunctorStatus::Done;
195         return FunctorStatus::Continue;
196     });
197 
198     if (!codeBlock &amp;&amp; hasTimeout)
199         return makeUnexpected(Error::TimedOut);
200     return codeBlock;
201 #else
202     UNUSED_PARAM(machinePC);
203     return nullptr;
204 #endif
205 }
206 
207 bool VMInspector::currentThreadOwnsJSLock(JSGlobalObject* globalObject)
208 {
209     return globalObject-&gt;vm().currentThreadIsHoldingAPILock();
210 }
211 
212 static bool ensureCurrentThreadOwnsJSLock(JSGlobalObject* globalObject)
213 {
214     if (VMInspector::currentThreadOwnsJSLock(globalObject))
215         return true;
216     dataLog(&quot;ERROR: current thread does not own the JSLock\n&quot;);
217     return false;
218 }
219 
220 void VMInspector::gc(JSGlobalObject* globalObject)
221 {
222     VM&amp; vm = globalObject-&gt;vm();
223     if (!ensureCurrentThreadOwnsJSLock(globalObject))
224         return;
225     vm.heap.collectNow(Sync, CollectionScope::Full);
226 }
227 
228 void VMInspector::edenGC(JSGlobalObject* globalObject)
229 {
230     VM&amp; vm = globalObject-&gt;vm();
231     if (!ensureCurrentThreadOwnsJSLock(globalObject))
232         return;
233     vm.heap.collectSync(CollectionScope::Eden);
234 }
235 
236 bool VMInspector::isInHeap(Heap* heap, void* ptr)
237 {
238     MarkedBlock* candidate = MarkedBlock::blockFor(ptr);
239     if (heap-&gt;objectSpace().blocks().set().contains(candidate))
240         return true;
241     for (PreciseAllocation* allocation : heap-&gt;objectSpace().preciseAllocations()) {
242         if (allocation-&gt;contains(ptr))
243             return true;
244     }
245     return false;
246 }
247 
248 struct CellAddressCheckFunctor : MarkedBlock::CountFunctor {
249     CellAddressCheckFunctor(JSCell* candidate)
250         : candidate(candidate)
251     {
252     }
253 
254     IterationStatus operator()(HeapCell* cell, HeapCell::Kind) const
255     {
256         if (cell == candidate) {
257             found = true;
258             return IterationStatus::Done;
259         }
260         return IterationStatus::Continue;
261     }
262 
263     JSCell* candidate;
264     mutable bool found { false };
265 };
266 
267 bool VMInspector::isValidCell(Heap* heap, JSCell* candidate)
268 {
269     HeapIterationScope iterationScope(*heap);
270     CellAddressCheckFunctor functor(candidate);
271     heap-&gt;objectSpace().forEachLiveCell(iterationScope, functor);
272     return functor.found;
273 }
274 
275 bool VMInspector::isValidCodeBlock(JSGlobalObject* globalObject, CodeBlock* candidate)
276 {
277     if (!ensureCurrentThreadOwnsJSLock(globalObject))
278         return false;
279 
280     struct CodeBlockValidationFunctor {
281         CodeBlockValidationFunctor(CodeBlock* candidate)
282             : candidate(candidate)
283         {
284         }
285 
286         void operator()(CodeBlock* codeBlock) const
287         {
288             if (codeBlock == candidate)
289                 found = true;
290         }
291 
292         CodeBlock* candidate;
293         mutable bool found { false };
294     };
295 
296     VM&amp; vm = globalObject-&gt;vm();
297     CodeBlockValidationFunctor functor(candidate);
298     vm.heap.forEachCodeBlock(functor);
299     return functor.found;
300 }
301 
302 CodeBlock* VMInspector::codeBlockForFrame(JSGlobalObject* globalObject, CallFrame* topCallFrame, unsigned frameNumber)
303 {
304     VM&amp; vm = globalObject-&gt;vm();
305     if (!ensureCurrentThreadOwnsJSLock(globalObject))
306         return nullptr;
307 
308     if (!topCallFrame)
309         return nullptr;
310 
311     struct FetchCodeBlockFunctor {
312     public:
313         FetchCodeBlockFunctor(unsigned targetFrameNumber)
314             : targetFrame(targetFrameNumber)
315         {
316         }
317 
318         StackVisitor::Status operator()(StackVisitor&amp; visitor) const
319         {
320             auto currentFrame = nextFrame++;
321             if (currentFrame == targetFrame) {
322                 codeBlock = visitor-&gt;codeBlock();
323                 return StackVisitor::Done;
324             }
325             return StackVisitor::Continue;
326         }
327 
328         unsigned targetFrame;
329         mutable unsigned nextFrame { 0 };
330         mutable CodeBlock* codeBlock { nullptr };
331     };
332 
333     FetchCodeBlockFunctor functor(frameNumber);
334     topCallFrame-&gt;iterate(vm, functor);
335     return functor.codeBlock;
336 }
337 
338 class DumpFrameFunctor {
339 public:
340     enum Action {
341         DumpOne,
342         DumpAll
343     };
344 
345     DumpFrameFunctor(Action action, unsigned framesToSkip)
346         : m_action(action)
347         , m_framesToSkip(framesToSkip)
348     {
349     }
350 
351     StackVisitor::Status operator()(StackVisitor&amp; visitor) const
352     {
353         m_currentFrame++;
354         if (m_currentFrame &gt; m_framesToSkip) {
355             visitor-&gt;dump(WTF::dataFile(), Indenter(2), [&amp;] (PrintStream&amp; out) {
356                 out.print(&quot;[&quot;, (m_currentFrame - m_framesToSkip - 1), &quot;] &quot;);
357             });
358         }
359         if (m_action == DumpOne &amp;&amp; m_currentFrame &gt; m_framesToSkip)
360             return StackVisitor::Done;
361         return StackVisitor::Continue;
362     }
363 
364 private:
365     Action m_action;
366     unsigned m_framesToSkip;
367     mutable unsigned m_currentFrame { 0 };
368 };
369 
370 void VMInspector::dumpCallFrame(JSGlobalObject* globalObject, CallFrame* callFrame, unsigned framesToSkip)
371 {
372     if (!ensureCurrentThreadOwnsJSLock(globalObject))
373         return;
374     DumpFrameFunctor functor(DumpFrameFunctor::DumpOne, framesToSkip);
375     callFrame-&gt;iterate(globalObject-&gt;vm(), functor);
376 }
377 
378 void VMInspector::dumpRegisters(CallFrame* callFrame)
379 {
380     CodeBlock* codeBlock = callFrame-&gt;codeBlock();
381     if (!codeBlock) {
382         dataLog(&quot;Dumping host frame registers not supported.\n&quot;);
383         return;
384     }
385     VM&amp; vm = codeBlock-&gt;vm();
386     auto valueAsString = [&amp;] (JSValue v) -&gt; CString {
387         if (!v.isCell() || VMInspector::isValidCell(&amp;vm.heap, reinterpret_cast&lt;JSCell*&gt;(JSValue::encode(v))))
388             return toCString(v);
389         return &quot;&quot;;
390     };
391 
392     dataLogF(&quot;Register frame: \n\n&quot;);
393     dataLogF(&quot;-----------------------------------------------------------------------------\n&quot;);
394     dataLogF(&quot;            use            |   address  |                value               \n&quot;);
395     dataLogF(&quot;-----------------------------------------------------------------------------\n&quot;);
396 
397     const Register* it;
398     const Register* end;
399 
400     it = callFrame-&gt;registers() + (CallFrameSlot::thisArgument + callFrame-&gt;argumentCount());
401     end = callFrame-&gt;registers() + (CallFrameSlot::thisArgument - 1);
402     while (it &gt; end) {
403         JSValue v = it-&gt;jsValue();
404         int registerNumber = it - callFrame-&gt;registers();
405         String name = codeBlock-&gt;nameForRegister(VirtualRegister(registerNumber));
406         dataLogF(&quot;[r% 3d %14s]      | %10p | 0x%-16llx %s\n&quot;, registerNumber, name.ascii().data(), it, (long long)JSValue::encode(v), valueAsString(v).data());
407         --it;
408     }
409 
410     dataLogF(&quot;-----------------------------------------------------------------------------\n&quot;);
411     dataLogF(&quot;[ArgumentCount]            | %10p | %lu \n&quot;, it, (unsigned long) callFrame-&gt;argumentCount());
412 
413     callFrame-&gt;iterate(vm, [&amp;] (StackVisitor&amp; visitor) {
414         if (visitor-&gt;callFrame() == callFrame) {
415             unsigned line = 0;
416             unsigned unusedColumn = 0;
417             visitor-&gt;computeLineAndColumn(line, unusedColumn);
418             dataLogF(&quot;[ReturnVPC]                | %10p | %d (line %d)\n&quot;, it, visitor-&gt;bytecodeIndex().offset(), line);
419             return StackVisitor::Done;
420         }
421         return StackVisitor::Continue;
422     });
423 
424     --it;
425     dataLogF(&quot;[Callee]                   | %10p | 0x%-16llx %s\n&quot;, it, (long long)callFrame-&gt;callee().rawPtr(), valueAsString(it-&gt;jsValue()).data());
426     --it;
427     dataLogF(&quot;[CodeBlock]                | %10p | 0x%-16llx &quot;, it, (long long)codeBlock);
428     dataLogLn(codeBlock);
429     --it;
430 #if ENABLE(JIT)
431     AbstractPC pc = callFrame-&gt;abstractReturnPC(vm);
432     if (pc.hasJITReturnAddress())
433         dataLogF(&quot;[ReturnPC]                 | %10p | %p \n&quot;, it, pc.jitReturnAddress().value());
434     --it;
435 #endif
436     dataLogF(&quot;[CallerFrame]              | %10p | %p \n&quot;, it, callFrame-&gt;callerFrame());
437     --it;
438     dataLogF(&quot;-----------------------------------------------------------------------------\n&quot;);
439 
440     size_t numberOfCalleeSaveSlots = codeBlock-&gt;calleeSaveSpaceAsVirtualRegisters();
441     const Register* endOfCalleeSaves = it - numberOfCalleeSaveSlots;
442 
443     end = it - codeBlock-&gt;numVars();
444     if (it != end) {
445         do {
446             JSValue v = it-&gt;jsValue();
447             int registerNumber = it - callFrame-&gt;registers();
448             String name = (it &gt; endOfCalleeSaves)
449                 ? &quot;CalleeSaveReg&quot;
450                 : codeBlock-&gt;nameForRegister(VirtualRegister(registerNumber));
451             dataLogF(&quot;[r% 3d %14s]      | %10p | 0x%-16llx %s\n&quot;, registerNumber, name.ascii().data(), it, (long long)JSValue::encode(v), valueAsString(v).data());
452             --it;
453         } while (it != end);
454     }
455     dataLogF(&quot;-----------------------------------------------------------------------------\n&quot;);
456 
457     end = it - codeBlock-&gt;numCalleeLocals() + codeBlock-&gt;numVars();
458     if (it != end) {
459         do {
460             JSValue v = (*it).jsValue();
461             int registerNumber = it - callFrame-&gt;registers();
462             dataLogF(&quot;[r% 3d]                     | %10p | 0x%-16llx %s\n&quot;, registerNumber, it, (long long)JSValue::encode(v), valueAsString(v).data());
463             --it;
464         } while (it != end);
465     }
466     dataLogF(&quot;-----------------------------------------------------------------------------\n&quot;);
467 }
468 
469 void VMInspector::dumpStack(JSGlobalObject* globalObject, CallFrame* topCallFrame, unsigned framesToSkip)
470 {
471     if (!ensureCurrentThreadOwnsJSLock(globalObject))
472         return;
473     if (!topCallFrame)
474         return;
475     DumpFrameFunctor functor(DumpFrameFunctor::DumpAll, framesToSkip);
476     topCallFrame-&gt;iterate(globalObject-&gt;vm(), functor);
477 }
478 
479 void VMInspector::dumpValue(JSValue value)
480 {
481     dataLogLn(value);
482 }
483 
484 void VMInspector::dumpCellMemory(JSCell* cell)
485 {
486     dumpCellMemoryToStream(cell, WTF::dataFile());
487 }
488 
489 class IndentationScope {
490 public:
491     IndentationScope(unsigned&amp; indentation)
492         : m_indentation(indentation)
493     {
494         ++m_indentation;
495     }
496 
497     ~IndentationScope()
498     {
499         --m_indentation;
500     }
501 
502 private:
503     unsigned&amp; m_indentation;
504 };
505 
506 void VMInspector::dumpCellMemoryToStream(JSCell* cell, PrintStream&amp; out)
507 {
508     VM&amp; vm = cell-&gt;vm();
509     StructureID structureID = cell-&gt;structureID();
510     Structure* structure = cell-&gt;structure(vm);
511     IndexingType indexingTypeAndMisc = cell-&gt;indexingTypeAndMisc();
512     IndexingType indexingType = structure-&gt;indexingType();
513     IndexingType indexingMode = structure-&gt;indexingMode();
514     JSType type = cell-&gt;type();
515     TypeInfo::InlineTypeFlags inlineTypeFlags = cell-&gt;inlineTypeFlags();
516     CellState cellState = cell-&gt;cellState();
517     size_t cellSize = cell-&gt;cellSize();
518     size_t slotCount = cellSize / sizeof(EncodedJSValue);
519 
520     EncodedJSValue* slots = bitwise_cast&lt;EncodedJSValue*&gt;(cell);
521     unsigned indentation = 0;
522 
523     auto indent = [&amp;] {
524         for (unsigned i = 0 ; i &lt; indentation; ++i)
525             out.print(&quot;  &quot;);
526     };
527 
528 #define INDENT indent(),
529 
530     auto dumpSlot = [&amp;] (EncodedJSValue* slots, unsigned index, const char* label = nullptr) {
531         out.print(&quot;[&quot;, index, &quot;] &quot;, format(&quot;%p : 0x%016&quot; PRIx64, &amp;slots[index], slots[index]));
532         if (label)
533             out.print(&quot; &quot;, label);
534         out.print(&quot;\n&quot;);
535     };
536 
537     out.printf(&quot;&lt;%p, %s&gt;\n&quot;, cell, cell-&gt;className(vm));
538     IndentationScope scope(indentation);
539 
540     INDENT dumpSlot(slots, 0, &quot;header&quot;);
541     {
542         IndentationScope scope(indentation);
543         INDENT out.println(&quot;structureID &quot;, format(&quot;%d 0x%&quot; PRIx32, structureID, structureID), &quot; structure &quot;, RawPointer(structure));
544         INDENT out.println(&quot;indexingTypeAndMisc &quot;, format(&quot;%d 0x%&quot; PRIx8, indexingTypeAndMisc, indexingTypeAndMisc), &quot; &quot;, IndexingTypeDump(indexingMode));
545         INDENT out.println(&quot;type &quot;, format(&quot;%d 0x%&quot; PRIx8, type, type));
546         INDENT out.println(&quot;flags &quot;, format(&quot;%d 0x%&quot; PRIx8, inlineTypeFlags, inlineTypeFlags));
547         INDENT out.println(&quot;cellState &quot;, format(&quot;%d&quot;, cellState));
548     }
549 
550     unsigned slotIndex = 1;
551     if (cell-&gt;isObject()) {
552         JSObject* obj = static_cast&lt;JSObject*&gt;(const_cast&lt;JSCell*&gt;(cell));
553         Butterfly* butterfly = obj-&gt;butterfly();
554         size_t butterflySize = obj-&gt;butterflyTotalSize();
555 
556         INDENT dumpSlot(slots, slotIndex, &quot;butterfly&quot;);
557         slotIndex++;
558 
559         if (butterfly) {
560             IndentationScope scope(indentation);
561 
562             bool hasIndexingHeader = structure-&gt;hasIndexingHeader(cell);
563             bool hasAnyArrayStorage = JSC::hasAnyArrayStorage(indexingType);
564 
565             size_t preCapacity = obj-&gt;butterflyPreCapacity();
566             size_t propertyCapacity = structure-&gt;outOfLineCapacity();
567 
568             void* base = hasIndexingHeader
569                 ? butterfly-&gt;base(preCapacity, propertyCapacity)
570                 : butterfly-&gt;base(structure);
571 
572             unsigned publicLength = butterfly-&gt;publicLength();
573             unsigned vectorLength = butterfly-&gt;vectorLength();
574             size_t butterflyCellSize = MarkedSpace::optimalSizeFor(butterflySize);
575 
576             size_t endOfIndexedPropertiesIndex = butterflySize / sizeof(EncodedJSValue);
577             size_t endOfButterflyIndex = butterflyCellSize / sizeof(EncodedJSValue);
578 
579             INDENT out.println(&quot;base &quot;, RawPointer(base));
580             INDENT out.println(&quot;hasIndexingHeader &quot;, (hasIndexingHeader ? &quot;YES&quot; : &quot;NO&quot;), &quot; hasAnyArrayStorage &quot;, (hasAnyArrayStorage ? &quot;YES&quot; : &quot;NO&quot;));
581             if (hasIndexingHeader) {
582                 INDENT out.print(&quot;publicLength &quot;, publicLength, &quot; vectorLength &quot;, vectorLength);
583                 if (hasAnyArrayStorage)
584                     out.print(&quot; indexBias &quot;, butterfly-&gt;arrayStorage()-&gt;m_indexBias);
585                 out.print(&quot;\n&quot;);
586             }
587             INDENT out.println(&quot;preCapacity &quot;, preCapacity, &quot; propertyCapacity &quot;, propertyCapacity);
588 
589             unsigned index = 0;
590             EncodedJSValue* slots = reinterpret_cast&lt;EncodedJSValue*&gt;(base);
591 
592             auto asVoidPtr = [] (void* p) {
593                 return p;
594             };
595 
596             auto dumpSectionHeader = [&amp;] (const char* name) {
597                 out.println(&quot;&lt;--- &quot;, name);
598             };
599 
600             auto dumpSection = [&amp;] (unsigned startIndex, unsigned endIndex, const char* name) -&gt; unsigned {
601                 for (unsigned index = startIndex; index &lt; endIndex; ++index) {
602                     if (name &amp;&amp; index == startIndex)
603                         INDENT dumpSectionHeader(name);
604                     INDENT dumpSlot(slots, index);
605                 }
606                 return endIndex;
607             };
608 
609             {
610                 IndentationScope scope(indentation);
611 
612                 index = dumpSection(index, preCapacity, &quot;preCapacity&quot;);
613                 index = dumpSection(index, preCapacity + propertyCapacity, &quot;propertyCapacity&quot;);
614 
615                 if (hasIndexingHeader)
616                     index = dumpSection(index, index + 1, &quot;indexingHeader&quot;);
617 
618                 INDENT dumpSectionHeader(&quot;butterfly&quot;);
619                 if (hasAnyArrayStorage) {
620                     RELEASE_ASSERT(asVoidPtr(butterfly-&gt;arrayStorage()) == asVoidPtr(&amp;slots[index]));
621                     RELEASE_ASSERT(ArrayStorage::vectorOffset() == 2 * sizeof(EncodedJSValue));
622                     index = dumpSection(index, index + 2, &quot;arrayStorage&quot;);
623                 }
624 
625                 index = dumpSection(index, endOfIndexedPropertiesIndex, &quot;indexedProperties&quot;);
626                 index = dumpSection(index, endOfButterflyIndex, &quot;unallocated capacity&quot;);
627             }
628         }
629     }
630 
631     for (; slotIndex &lt; slotCount; ++slotIndex)
632         INDENT dumpSlot(slots, slotIndex);
633 
634 #undef INDENT
635 }
636 
637 void VMInspector::dumpSubspaceHashes(VM* vm)
638 {
639     unsigned count = 0;
640     vm-&gt;heap.objectSpace().forEachSubspace([&amp;] (const Subspace&amp; subspace) -&gt; IterationStatus {
641         const char* name = subspace.name();
642         unsigned hash = StringHasher::computeHash(name);
643         void* hashAsPtr = reinterpret_cast&lt;void*&gt;(static_cast&lt;uintptr_t&gt;(hash));
644         dataLogLn(&quot;    [&quot;, count++, &quot;] &quot;, name, &quot; Hash:&quot;, RawPointer(hashAsPtr));
645         return IterationStatus::Continue;
646     });
647     dataLogLn();
648 }
649 
650 } // namespace JSC
    </pre>
  </body>
</html>