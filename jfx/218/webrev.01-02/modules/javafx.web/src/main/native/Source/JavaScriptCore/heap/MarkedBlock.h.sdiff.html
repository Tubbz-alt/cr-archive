<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/MarkedBlock.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="MarkedBlock.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="MarkedBlockInlines.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/MarkedBlock.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  9  *  version 2 of the License, or (at your option) any later version.
 10  *
 11  *  This library is distributed in the hope that it will be useful,
 12  *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 13  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 14  *  Lesser General Public License for more details.
 15  *
 16  *  You should have received a copy of the GNU Lesser General Public
 17  *  License along with this library; if not, write to the Free Software
 18  *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
 19  *
 20  */
 21 
 22 #pragma once
 23 
 24 #include &quot;CellAttributes.h&quot;
 25 #include &quot;DestructionMode.h&quot;
 26 #include &quot;HeapCell.h&quot;
 27 #include &quot;IterationStatus.h&quot;
 28 #include &quot;WeakSet.h&quot;

 29 #include &lt;wtf/Atomics.h&gt;
 30 #include &lt;wtf/Bitmap.h&gt;
<span class="line-removed"> 31 #include &lt;wtf/HashFunctions.h&gt;</span>
 32 #include &lt;wtf/CountingLock.h&gt;


 33 #include &lt;wtf/StdLibExtras.h&gt;
 34 
 35 namespace JSC {
 36 
 37 class AlignedMemoryAllocator;
 38 class FreeList;
 39 class Heap;
 40 class JSCell;
 41 class BlockDirectory;
 42 class MarkedSpace;
 43 class SlotVisitor;
 44 class Subspace;
 45 
 46 typedef uint32_t HeapVersion;
 47 
 48 // A marked block is a page-aligned container for heap-allocated objects.
 49 // Objects are allocated within cells of the marked block. For a given
 50 // marked block, all cells have the same size. Objects smaller than the
 51 // cell size may be allocated in the marked block, in which case the
 52 // allocation suffers from internal fragmentation: wasted space whose
 53 // size is equal to the difference between the cell size and the object
 54 // size.
<span class="line-modified"> 55 </span>

 56 class MarkedBlock {
 57     WTF_MAKE_NONCOPYABLE(MarkedBlock);

 58     friend class LLIntOffsetsExtractor;
 59     friend struct VerifyMarked;
 60 
 61 public:
 62     class Footer;
 63     class Handle;
 64 private:
 65     friend class Footer;
 66     friend class Handle;
 67 public:
 68     static constexpr size_t atomSize = 16; // bytes
 69 
 70     // Block size must be at least as large as the system page size.
<span class="line-modified"> 71 #if CPU(PPC64) || CPU(PPC64LE) || CPU(PPC) || CPU(UNKNOWN)</span>
<span class="line-removed"> 72     static constexpr size_t blockSize = 64 * KB;</span>
<span class="line-removed"> 73 #else</span>
<span class="line-removed"> 74     static constexpr size_t blockSize = 16 * KB;</span>
<span class="line-removed"> 75 #endif</span>
 76 
 77     static constexpr size_t blockMask = ~(blockSize - 1); // blockSize must be a power of two.
 78 
 79     static constexpr size_t atomsPerBlock = blockSize / atomSize;
 80 



 81     static_assert(!(MarkedBlock::atomSize &amp; (MarkedBlock::atomSize - 1)), &quot;MarkedBlock::atomSize must be a power of two.&quot;);
 82     static_assert(!(MarkedBlock::blockSize &amp; (MarkedBlock::blockSize - 1)), &quot;MarkedBlock::blockSize must be a power of two.&quot;);
 83 
 84     struct VoidFunctor {
 85         typedef void ReturnType;
 86         void returnValue() { }
 87     };
 88 
 89     class CountFunctor {
 90     public:
 91         typedef size_t ReturnType;
 92 
 93         CountFunctor() : m_count(0) { }
 94         void count(size_t count) const { m_count += count; }
 95         ReturnType returnValue() const { return m_count; }
 96 
 97     private:
 98         // FIXME: This is mutable because we&#39;re using a functor rather than C++ lambdas.
 99         // https://bugs.webkit.org/show_bug.cgi?id=159644
100         mutable ReturnType m_count;
101     };
102 
103     class Handle {
104         WTF_MAKE_NONCOPYABLE(Handle);
<span class="line-modified">105         WTF_MAKE_FAST_ALLOCATED;</span>
106         friend class LLIntOffsetsExtractor;
107         friend class MarkedBlock;
108         friend struct VerifyMarked;
109     public:
110 
111         ~Handle();
112 
113         MarkedBlock&amp; block();
114         MarkedBlock::Footer&amp; blockFooter();
115 
116         void* cellAlign(void*);
117 
118         bool isEmpty();
119 
120         void lastChanceToFinalize();
121 
122         BlockDirectory* directory() const;
123         Subspace* subspace() const;
124         AlignedMemoryAllocator* alignedMemoryAllocator() const;
125         Heap* heap() const;
</pre>
<hr />
<pre>
174         bool isLive(HeapVersion markingVersion, HeapVersion newlyAllocatedVersion, bool isMarking, const HeapCell*);
175         inline bool isLiveCell(HeapVersion markingVersion, HeapVersion newlyAllocatedVersion, bool isMarking, const void*);
176 
177         bool isLive(const HeapCell*);
178         bool isLiveCell(const void*);
179 
180         bool isFreeListedCell(const void* target) const;
181 
182         template &lt;typename Functor&gt; IterationStatus forEachCell(const Functor&amp;);
183         template &lt;typename Functor&gt; inline IterationStatus forEachLiveCell(const Functor&amp;);
184         template &lt;typename Functor&gt; inline IterationStatus forEachDeadCell(const Functor&amp;);
185         template &lt;typename Functor&gt; inline IterationStatus forEachMarkedCell(const Functor&amp;);
186 
187         JS_EXPORT_PRIVATE bool areMarksStale();
188         bool areMarksStaleForSweep();
189 
190         void assertMarksNotStale();
191 
192         bool isFreeListed() const { return m_isFreeListed; }
193 
<span class="line-modified">194         size_t index() const { return m_index; }</span>
195 
196         void removeFromDirectory();
197 
<span class="line-modified">198         void didAddToDirectory(BlockDirectory*, size_t index);</span>
199         void didRemoveFromDirectory();
200 
201         void* start() const { return &amp;m_block-&gt;atoms()[0]; }
202         void* end() const { return &amp;m_block-&gt;atoms()[m_endAtom]; }
203         bool contains(void* p) const { return start() &lt;= p &amp;&amp; p &lt; end(); }
204 
205         void dumpState(PrintStream&amp;);
206 
207     private:
208         Handle(Heap&amp;, AlignedMemoryAllocator*, void*);
209 
210         enum SweepDestructionMode { BlockHasNoDestructors, BlockHasDestructors, BlockHasDestructorsAndCollectorIsRunning };
211         enum ScribbleMode { DontScribble, Scribble };
212         enum EmptyMode { IsEmpty, NotEmpty };
213         enum NewlyAllocatedMode { HasNewlyAllocated, DoesNotHaveNewlyAllocated };
214         enum MarksMode { MarksStale, MarksNotStale };
215 
216         SweepDestructionMode sweepDestructionMode();
217         EmptyMode emptyMode();
218         ScribbleMode scribbleMode();
219         NewlyAllocatedMode newlyAllocatedMode();
220         MarksMode marksMode();
221 
222         template&lt;bool, EmptyMode, SweepMode, SweepDestructionMode, ScribbleMode, NewlyAllocatedMode, MarksMode, typename DestroyFunc&gt;
223         void specializedSweep(FreeList*, EmptyMode, SweepMode, SweepDestructionMode, ScribbleMode, NewlyAllocatedMode, MarksMode, const DestroyFunc&amp;);
224 
225         void setIsFreeListed();
226 
<span class="line-modified">227         MarkedBlock::Handle* m_prev { nullptr };</span>
<span class="line-modified">228         MarkedBlock::Handle* m_next { nullptr };</span>
<span class="line-removed">229 </span>
<span class="line-removed">230         size_t m_atomsPerCell { std::numeric_limits&lt;size_t&gt;::max() };</span>
<span class="line-removed">231         size_t m_endAtom { std::numeric_limits&lt;size_t&gt;::max() }; // This is a fuzzy end. Always test for &lt; m_endAtom.</span>
232 
233         CellAttributes m_attributes;
234         bool m_isFreeListed { false };

235 
236         AlignedMemoryAllocator* m_alignedMemoryAllocator { nullptr };
237         BlockDirectory* m_directory { nullptr };
<span class="line-removed">238         size_t m_index { std::numeric_limits&lt;size_t&gt;::max() };</span>
239         WeakSet m_weakSet;
240 
241         MarkedBlock* m_block { nullptr };
242     };
243 
244 private:
245     static constexpr size_t atomAlignmentMask = atomSize - 1;
246 
247     typedef char Atom[atomSize];
248 
249 public:
250     class Footer {
251     public:
252         Footer(VM&amp;, Handle&amp;);
253         ~Footer();
254 
255     private:
256         friend class LLIntOffsetsExtractor;
257         friend class MarkedBlock;
258 
</pre>
<hr />
<pre>
291         //     m_biasedMarkCount != m_markCountBias
292         int16_t m_markCountBias;
293 
294         HeapVersion m_markingVersion;
295         HeapVersion m_newlyAllocatedVersion;
296 
297         Bitmap&lt;atomsPerBlock&gt; m_marks;
298         Bitmap&lt;atomsPerBlock&gt; m_newlyAllocated;
299     };
300 
301 private:
302     Footer&amp; footer();
303     const Footer&amp; footer() const;
304 
305 public:
306     static constexpr size_t endAtom = (blockSize - sizeof(Footer)) / atomSize;
307     static constexpr size_t payloadSize = endAtom * atomSize;
308     static constexpr size_t footerSize = blockSize - payloadSize;
309 
310     static_assert(payloadSize == ((blockSize - sizeof(MarkedBlock::Footer)) &amp; ~(atomSize - 1)), &quot;Payload size computed the alternate way should give the same result&quot;);
<span class="line-removed">311     // Some of JSCell types assume that the last JSCell in a MarkedBlock has a subsequent memory region (Footer) that can still safely accessed.</span>
<span class="line-removed">312     // For example, JSRopeString assumes that it can safely access up to 2 bytes beyond the JSRopeString cell.</span>
<span class="line-removed">313     static_assert(sizeof(Footer) &gt;= sizeof(uint16_t));</span>
314 
315     static MarkedBlock::Handle* tryCreate(Heap&amp;, AlignedMemoryAllocator*);
316 
317     Handle&amp; handle();
318     const Handle&amp; handle() const;
319 
320     VM&amp; vm() const;
321     inline Heap* heap() const;
322     inline MarkedSpace* space() const;
323 
324     static bool isAtomAligned(const void*);
325     static MarkedBlock* blockFor(const void*);
<span class="line-modified">326     size_t atomNumber(const void*);</span>

327 
328     size_t markCount();
329 
330     bool isMarked(const void*);
331     bool isMarked(HeapVersion markingVersion, const void*);
332     bool isMarked(const void*, Dependency);
333     bool testAndSetMarked(const void*, Dependency);
334 
335     bool isAtom(const void*);
336     void clearMarked(const void*);
337 
338     bool isNewlyAllocated(const void*);
339     void setNewlyAllocated(const void*);
340     void clearNewlyAllocated(const void*);
341     const Bitmap&lt;atomsPerBlock&gt;&amp; newlyAllocated() const;
342 
343     HeapVersion newlyAllocatedVersion() const { return footer().m_newlyAllocatedVersion; }
344 
345     inline bool isNewlyAllocatedStale() const;
346 
347     inline bool hasAnyNewlyAllocated();
348     void resetAllocated();
349 
350     size_t cellSize();
351     const CellAttributes&amp; attributes() const;
352 
353     bool hasAnyMarked() const;
354     void noteMarked();
<span class="line-modified">355 #if ASSERT_DISABLED</span>
<span class="line-removed">356     void assertValidCell(VM&amp;, HeapCell*) const { }</span>
<span class="line-removed">357 #else</span>
358     void assertValidCell(VM&amp;, HeapCell*) const;


359 #endif
360 
361     WeakSet&amp; weakSet();
362 
363     JS_EXPORT_PRIVATE bool areMarksStale();
364     bool areMarksStale(HeapVersion markingVersion);
365 
366     Dependency aboutToMark(HeapVersion markingVersion);
367 
<span class="line-modified">368 #if ASSERT_DISABLED</span>
<span class="line-removed">369     void assertMarksNotStale() { }</span>
<span class="line-removed">370 #else</span>
371     JS_EXPORT_PRIVATE void assertMarksNotStale();


372 #endif
373 
374     void resetMarks();
375 
376     bool isMarkedRaw(const void* p);
377     HeapVersion markingVersion() const { return footer().m_markingVersion; }
378 
379     const Bitmap&lt;atomsPerBlock&gt;&amp; marks() const;
380 
381     CountingLock&amp; lock() { return footer().m_lock; }
382 
383     Subspace* subspace() const { return footer().m_subspace; }
384 
385     void populatePage() const
386     {
387         *bitwise_cast&lt;volatile uint8_t*&gt;(&amp;footer());
388     }
389 
390     static constexpr size_t offsetOfFooter = endAtom * atomSize;
391 
</pre>
<hr />
<pre>
536 inline DestructionMode MarkedBlock::Handle::destruction() const
537 {
538     return m_attributes.destruction;
539 }
540 
541 inline HeapCell::Kind MarkedBlock::Handle::cellKind() const
542 {
543     return m_attributes.cellKind;
544 }
545 
546 inline size_t MarkedBlock::Handle::markCount()
547 {
548     return m_block-&gt;markCount();
549 }
550 
551 inline size_t MarkedBlock::Handle::size()
552 {
553     return markCount() * cellSize();
554 }
555 
<span class="line-modified">556 inline size_t MarkedBlock::atomNumber(const void* p)</span>
557 {


558     return (reinterpret_cast&lt;uintptr_t&gt;(p) - reinterpret_cast&lt;uintptr_t&gt;(this)) / atomSize;
559 }
560 







561 inline bool MarkedBlock::areMarksStale(HeapVersion markingVersion)
562 {
563     return markingVersion != footer().m_markingVersion;
564 }
565 
566 inline Dependency MarkedBlock::aboutToMark(HeapVersion markingVersion)
567 {
568     HeapVersion version = footer().m_markingVersion;
569     if (UNLIKELY(version != markingVersion))
570         aboutToMarkSlow(markingVersion);
571     return Dependency::fence(version);
572 }
573 
574 inline void MarkedBlock::Handle::assertMarksNotStale()
575 {
576     block().assertMarksNotStale();
577 }
578 
579 inline bool MarkedBlock::isMarkedRaw(const void* p)
580 {
</pre>
<hr />
<pre>
612 }
613 
614 inline void MarkedBlock::setNewlyAllocated(const void* p)
615 {
616     footer().m_newlyAllocated.set(atomNumber(p));
617 }
618 
619 inline void MarkedBlock::clearNewlyAllocated(const void* p)
620 {
621     footer().m_newlyAllocated.clear(atomNumber(p));
622 }
623 
624 inline const Bitmap&lt;MarkedBlock::atomsPerBlock&gt;&amp; MarkedBlock::newlyAllocated() const
625 {
626     return footer().m_newlyAllocated;
627 }
628 
629 inline bool MarkedBlock::isAtom(const void* p)
630 {
631     ASSERT(MarkedBlock::isAtomAligned(p));
<span class="line-modified">632     size_t atomNumber = this-&gt;atomNumber(p);</span>
633     if (atomNumber % handle().m_atomsPerCell) // Filters pointers into cell middles.
634         return false;
635     if (atomNumber &gt;= handle().m_endAtom) // Filters pointers into invalid cells out of the range.
636         return false;
637     return true;
638 }
639 
640 template &lt;typename Functor&gt;
641 inline IterationStatus MarkedBlock::Handle::forEachCell(const Functor&amp; functor)
642 {
643     HeapCell::Kind kind = m_attributes.cellKind;
644     for (size_t i = 0; i &lt; m_endAtom; i += m_atomsPerCell) {
645         HeapCell* cell = reinterpret_cast_ptr&lt;HeapCell*&gt;(&amp;m_block-&gt;atoms()[i]);
<span class="line-modified">646         if (functor(cell, kind) == IterationStatus::Done)</span>
647             return IterationStatus::Done;
648     }
649     return IterationStatus::Continue;
650 }
651 
652 inline bool MarkedBlock::hasAnyMarked() const
653 {
654     return footer().m_biasedMarkCount != footer().m_markCountBias;
655 }
656 
657 inline void MarkedBlock::noteMarked()
658 {
659     // This is racy by design. We don&#39;t want to pay the price of an atomic increment!
660     int16_t biasedMarkCount = footer().m_biasedMarkCount;
661     ++biasedMarkCount;
662     footer().m_biasedMarkCount = biasedMarkCount;
663     if (UNLIKELY(!biasedMarkCount))
664         noteMarkedSlow();
665 }
666 
</pre>
</td>
<td>
<hr />
<pre>
  9  *  version 2 of the License, or (at your option) any later version.
 10  *
 11  *  This library is distributed in the hope that it will be useful,
 12  *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 13  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 14  *  Lesser General Public License for more details.
 15  *
 16  *  You should have received a copy of the GNU Lesser General Public
 17  *  License along with this library; if not, write to the Free Software
 18  *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
 19  *
 20  */
 21 
 22 #pragma once
 23 
 24 #include &quot;CellAttributes.h&quot;
 25 #include &quot;DestructionMode.h&quot;
 26 #include &quot;HeapCell.h&quot;
 27 #include &quot;IterationStatus.h&quot;
 28 #include &quot;WeakSet.h&quot;
<span class="line-added"> 29 #include &lt;algorithm&gt;</span>
 30 #include &lt;wtf/Atomics.h&gt;
 31 #include &lt;wtf/Bitmap.h&gt;

 32 #include &lt;wtf/CountingLock.h&gt;
<span class="line-added"> 33 #include &lt;wtf/HashFunctions.h&gt;</span>
<span class="line-added"> 34 #include &lt;wtf/PageBlock.h&gt;</span>
 35 #include &lt;wtf/StdLibExtras.h&gt;
 36 
 37 namespace JSC {
 38 
 39 class AlignedMemoryAllocator;
 40 class FreeList;
 41 class Heap;
 42 class JSCell;
 43 class BlockDirectory;
 44 class MarkedSpace;
 45 class SlotVisitor;
 46 class Subspace;
 47 
 48 typedef uint32_t HeapVersion;
 49 
 50 // A marked block is a page-aligned container for heap-allocated objects.
 51 // Objects are allocated within cells of the marked block. For a given
 52 // marked block, all cells have the same size. Objects smaller than the
 53 // cell size may be allocated in the marked block, in which case the
 54 // allocation suffers from internal fragmentation: wasted space whose
 55 // size is equal to the difference between the cell size and the object
 56 // size.
<span class="line-modified"> 57 DECLARE_ALLOCATOR_WITH_HEAP_IDENTIFIER(MarkedBlock);</span>
<span class="line-added"> 58 DECLARE_ALLOCATOR_WITH_HEAP_IDENTIFIER(MarkedBlockHandle);</span>
 59 class MarkedBlock {
 60     WTF_MAKE_NONCOPYABLE(MarkedBlock);
<span class="line-added"> 61     WTF_MAKE_STRUCT_FAST_ALLOCATED_WITH_HEAP_IDENTIFIER(MarkedBlock);</span>
 62     friend class LLIntOffsetsExtractor;
 63     friend struct VerifyMarked;
 64 
 65 public:
 66     class Footer;
 67     class Handle;
 68 private:
 69     friend class Footer;
 70     friend class Handle;
 71 public:
 72     static constexpr size_t atomSize = 16; // bytes
 73 
 74     // Block size must be at least as large as the system page size.
<span class="line-modified"> 75     static constexpr size_t blockSize = std::max(16 * KB, CeilingOnPageSize);</span>




 76 
 77     static constexpr size_t blockMask = ~(blockSize - 1); // blockSize must be a power of two.
 78 
 79     static constexpr size_t atomsPerBlock = blockSize / atomSize;
 80 
<span class="line-added"> 81     static constexpr size_t maxNumberOfLowerTierCells = 8;</span>
<span class="line-added"> 82     static_assert(maxNumberOfLowerTierCells &lt;= 256);</span>
<span class="line-added"> 83 </span>
 84     static_assert(!(MarkedBlock::atomSize &amp; (MarkedBlock::atomSize - 1)), &quot;MarkedBlock::atomSize must be a power of two.&quot;);
 85     static_assert(!(MarkedBlock::blockSize &amp; (MarkedBlock::blockSize - 1)), &quot;MarkedBlock::blockSize must be a power of two.&quot;);
 86 
 87     struct VoidFunctor {
 88         typedef void ReturnType;
 89         void returnValue() { }
 90     };
 91 
 92     class CountFunctor {
 93     public:
 94         typedef size_t ReturnType;
 95 
 96         CountFunctor() : m_count(0) { }
 97         void count(size_t count) const { m_count += count; }
 98         ReturnType returnValue() const { return m_count; }
 99 
100     private:
101         // FIXME: This is mutable because we&#39;re using a functor rather than C++ lambdas.
102         // https://bugs.webkit.org/show_bug.cgi?id=159644
103         mutable ReturnType m_count;
104     };
105 
106     class Handle {
107         WTF_MAKE_NONCOPYABLE(Handle);
<span class="line-modified">108         WTF_MAKE_STRUCT_FAST_ALLOCATED_WITH_HEAP_IDENTIFIER(MarkedBlockHandle);</span>
109         friend class LLIntOffsetsExtractor;
110         friend class MarkedBlock;
111         friend struct VerifyMarked;
112     public:
113 
114         ~Handle();
115 
116         MarkedBlock&amp; block();
117         MarkedBlock::Footer&amp; blockFooter();
118 
119         void* cellAlign(void*);
120 
121         bool isEmpty();
122 
123         void lastChanceToFinalize();
124 
125         BlockDirectory* directory() const;
126         Subspace* subspace() const;
127         AlignedMemoryAllocator* alignedMemoryAllocator() const;
128         Heap* heap() const;
</pre>
<hr />
<pre>
177         bool isLive(HeapVersion markingVersion, HeapVersion newlyAllocatedVersion, bool isMarking, const HeapCell*);
178         inline bool isLiveCell(HeapVersion markingVersion, HeapVersion newlyAllocatedVersion, bool isMarking, const void*);
179 
180         bool isLive(const HeapCell*);
181         bool isLiveCell(const void*);
182 
183         bool isFreeListedCell(const void* target) const;
184 
185         template &lt;typename Functor&gt; IterationStatus forEachCell(const Functor&amp;);
186         template &lt;typename Functor&gt; inline IterationStatus forEachLiveCell(const Functor&amp;);
187         template &lt;typename Functor&gt; inline IterationStatus forEachDeadCell(const Functor&amp;);
188         template &lt;typename Functor&gt; inline IterationStatus forEachMarkedCell(const Functor&amp;);
189 
190         JS_EXPORT_PRIVATE bool areMarksStale();
191         bool areMarksStaleForSweep();
192 
193         void assertMarksNotStale();
194 
195         bool isFreeListed() const { return m_isFreeListed; }
196 
<span class="line-modified">197         unsigned index() const { return m_index; }</span>
198 
199         void removeFromDirectory();
200 
<span class="line-modified">201         void didAddToDirectory(BlockDirectory*, unsigned index);</span>
202         void didRemoveFromDirectory();
203 
204         void* start() const { return &amp;m_block-&gt;atoms()[0]; }
205         void* end() const { return &amp;m_block-&gt;atoms()[m_endAtom]; }
206         bool contains(void* p) const { return start() &lt;= p &amp;&amp; p &lt; end(); }
207 
208         void dumpState(PrintStream&amp;);
209 
210     private:
211         Handle(Heap&amp;, AlignedMemoryAllocator*, void*);
212 
213         enum SweepDestructionMode { BlockHasNoDestructors, BlockHasDestructors, BlockHasDestructorsAndCollectorIsRunning };
214         enum ScribbleMode { DontScribble, Scribble };
215         enum EmptyMode { IsEmpty, NotEmpty };
216         enum NewlyAllocatedMode { HasNewlyAllocated, DoesNotHaveNewlyAllocated };
217         enum MarksMode { MarksStale, MarksNotStale };
218 
219         SweepDestructionMode sweepDestructionMode();
220         EmptyMode emptyMode();
221         ScribbleMode scribbleMode();
222         NewlyAllocatedMode newlyAllocatedMode();
223         MarksMode marksMode();
224 
225         template&lt;bool, EmptyMode, SweepMode, SweepDestructionMode, ScribbleMode, NewlyAllocatedMode, MarksMode, typename DestroyFunc&gt;
226         void specializedSweep(FreeList*, EmptyMode, SweepMode, SweepDestructionMode, ScribbleMode, NewlyAllocatedMode, MarksMode, const DestroyFunc&amp;);
227 
228         void setIsFreeListed();
229 
<span class="line-modified">230         unsigned m_atomsPerCell { std::numeric_limits&lt;unsigned&gt;::max() };</span>
<span class="line-modified">231         unsigned m_endAtom { std::numeric_limits&lt;unsigned&gt;::max() }; // This is a fuzzy end. Always test for &lt; m_endAtom.</span>



232 
233         CellAttributes m_attributes;
234         bool m_isFreeListed { false };
<span class="line-added">235         unsigned m_index { std::numeric_limits&lt;unsigned&gt;::max() };</span>
236 
237         AlignedMemoryAllocator* m_alignedMemoryAllocator { nullptr };
238         BlockDirectory* m_directory { nullptr };

239         WeakSet m_weakSet;
240 
241         MarkedBlock* m_block { nullptr };
242     };
243 
244 private:
245     static constexpr size_t atomAlignmentMask = atomSize - 1;
246 
247     typedef char Atom[atomSize];
248 
249 public:
250     class Footer {
251     public:
252         Footer(VM&amp;, Handle&amp;);
253         ~Footer();
254 
255     private:
256         friend class LLIntOffsetsExtractor;
257         friend class MarkedBlock;
258 
</pre>
<hr />
<pre>
291         //     m_biasedMarkCount != m_markCountBias
292         int16_t m_markCountBias;
293 
294         HeapVersion m_markingVersion;
295         HeapVersion m_newlyAllocatedVersion;
296 
297         Bitmap&lt;atomsPerBlock&gt; m_marks;
298         Bitmap&lt;atomsPerBlock&gt; m_newlyAllocated;
299     };
300 
301 private:
302     Footer&amp; footer();
303     const Footer&amp; footer() const;
304 
305 public:
306     static constexpr size_t endAtom = (blockSize - sizeof(Footer)) / atomSize;
307     static constexpr size_t payloadSize = endAtom * atomSize;
308     static constexpr size_t footerSize = blockSize - payloadSize;
309 
310     static_assert(payloadSize == ((blockSize - sizeof(MarkedBlock::Footer)) &amp; ~(atomSize - 1)), &quot;Payload size computed the alternate way should give the same result&quot;);



311 
312     static MarkedBlock::Handle* tryCreate(Heap&amp;, AlignedMemoryAllocator*);
313 
314     Handle&amp; handle();
315     const Handle&amp; handle() const;
316 
317     VM&amp; vm() const;
318     inline Heap* heap() const;
319     inline MarkedSpace* space() const;
320 
321     static bool isAtomAligned(const void*);
322     static MarkedBlock* blockFor(const void*);
<span class="line-modified">323     unsigned atomNumber(const void*);</span>
<span class="line-added">324     size_t candidateAtomNumber(const void*);</span>
325 
326     size_t markCount();
327 
328     bool isMarked(const void*);
329     bool isMarked(HeapVersion markingVersion, const void*);
330     bool isMarked(const void*, Dependency);
331     bool testAndSetMarked(const void*, Dependency);
332 
333     bool isAtom(const void*);
334     void clearMarked(const void*);
335 
336     bool isNewlyAllocated(const void*);
337     void setNewlyAllocated(const void*);
338     void clearNewlyAllocated(const void*);
339     const Bitmap&lt;atomsPerBlock&gt;&amp; newlyAllocated() const;
340 
341     HeapVersion newlyAllocatedVersion() const { return footer().m_newlyAllocatedVersion; }
342 
343     inline bool isNewlyAllocatedStale() const;
344 
345     inline bool hasAnyNewlyAllocated();
346     void resetAllocated();
347 
348     size_t cellSize();
349     const CellAttributes&amp; attributes() const;
350 
351     bool hasAnyMarked() const;
352     void noteMarked();
<span class="line-modified">353 #if ASSERT_ENABLED</span>


354     void assertValidCell(VM&amp;, HeapCell*) const;
<span class="line-added">355 #else</span>
<span class="line-added">356     void assertValidCell(VM&amp;, HeapCell*) const { }</span>
357 #endif
358 
359     WeakSet&amp; weakSet();
360 
361     JS_EXPORT_PRIVATE bool areMarksStale();
362     bool areMarksStale(HeapVersion markingVersion);
363 
364     Dependency aboutToMark(HeapVersion markingVersion);
365 
<span class="line-modified">366 #if ASSERT_ENABLED</span>


367     JS_EXPORT_PRIVATE void assertMarksNotStale();
<span class="line-added">368 #else</span>
<span class="line-added">369     void assertMarksNotStale() { }</span>
370 #endif
371 
372     void resetMarks();
373 
374     bool isMarkedRaw(const void* p);
375     HeapVersion markingVersion() const { return footer().m_markingVersion; }
376 
377     const Bitmap&lt;atomsPerBlock&gt;&amp; marks() const;
378 
379     CountingLock&amp; lock() { return footer().m_lock; }
380 
381     Subspace* subspace() const { return footer().m_subspace; }
382 
383     void populatePage() const
384     {
385         *bitwise_cast&lt;volatile uint8_t*&gt;(&amp;footer());
386     }
387 
388     static constexpr size_t offsetOfFooter = endAtom * atomSize;
389 
</pre>
<hr />
<pre>
534 inline DestructionMode MarkedBlock::Handle::destruction() const
535 {
536     return m_attributes.destruction;
537 }
538 
539 inline HeapCell::Kind MarkedBlock::Handle::cellKind() const
540 {
541     return m_attributes.cellKind;
542 }
543 
544 inline size_t MarkedBlock::Handle::markCount()
545 {
546     return m_block-&gt;markCount();
547 }
548 
549 inline size_t MarkedBlock::Handle::size()
550 {
551     return markCount() * cellSize();
552 }
553 
<span class="line-modified">554 inline size_t MarkedBlock::candidateAtomNumber(const void* p)</span>
555 {
<span class="line-added">556     // This function must return size_t instead of unsigned since pointer |p| is not guaranteed that this is within MarkedBlock.</span>
<span class="line-added">557     // See MarkedBlock::isAtom which can accept out-of-bound pointers.</span>
558     return (reinterpret_cast&lt;uintptr_t&gt;(p) - reinterpret_cast&lt;uintptr_t&gt;(this)) / atomSize;
559 }
560 
<span class="line-added">561 inline unsigned MarkedBlock::atomNumber(const void* p)</span>
<span class="line-added">562 {</span>
<span class="line-added">563     size_t atomNumber = candidateAtomNumber(p);</span>
<span class="line-added">564     ASSERT(atomNumber &lt; handle().m_endAtom);</span>
<span class="line-added">565     return atomNumber;</span>
<span class="line-added">566 }</span>
<span class="line-added">567 </span>
568 inline bool MarkedBlock::areMarksStale(HeapVersion markingVersion)
569 {
570     return markingVersion != footer().m_markingVersion;
571 }
572 
573 inline Dependency MarkedBlock::aboutToMark(HeapVersion markingVersion)
574 {
575     HeapVersion version = footer().m_markingVersion;
576     if (UNLIKELY(version != markingVersion))
577         aboutToMarkSlow(markingVersion);
578     return Dependency::fence(version);
579 }
580 
581 inline void MarkedBlock::Handle::assertMarksNotStale()
582 {
583     block().assertMarksNotStale();
584 }
585 
586 inline bool MarkedBlock::isMarkedRaw(const void* p)
587 {
</pre>
<hr />
<pre>
619 }
620 
621 inline void MarkedBlock::setNewlyAllocated(const void* p)
622 {
623     footer().m_newlyAllocated.set(atomNumber(p));
624 }
625 
626 inline void MarkedBlock::clearNewlyAllocated(const void* p)
627 {
628     footer().m_newlyAllocated.clear(atomNumber(p));
629 }
630 
631 inline const Bitmap&lt;MarkedBlock::atomsPerBlock&gt;&amp; MarkedBlock::newlyAllocated() const
632 {
633     return footer().m_newlyAllocated;
634 }
635 
636 inline bool MarkedBlock::isAtom(const void* p)
637 {
638     ASSERT(MarkedBlock::isAtomAligned(p));
<span class="line-modified">639     size_t atomNumber = candidateAtomNumber(p);</span>
640     if (atomNumber % handle().m_atomsPerCell) // Filters pointers into cell middles.
641         return false;
642     if (atomNumber &gt;= handle().m_endAtom) // Filters pointers into invalid cells out of the range.
643         return false;
644     return true;
645 }
646 
647 template &lt;typename Functor&gt;
648 inline IterationStatus MarkedBlock::Handle::forEachCell(const Functor&amp; functor)
649 {
650     HeapCell::Kind kind = m_attributes.cellKind;
651     for (size_t i = 0; i &lt; m_endAtom; i += m_atomsPerCell) {
652         HeapCell* cell = reinterpret_cast_ptr&lt;HeapCell*&gt;(&amp;m_block-&gt;atoms()[i]);
<span class="line-modified">653         if (functor(i, cell, kind) == IterationStatus::Done)</span>
654             return IterationStatus::Done;
655     }
656     return IterationStatus::Continue;
657 }
658 
659 inline bool MarkedBlock::hasAnyMarked() const
660 {
661     return footer().m_biasedMarkCount != footer().m_markCountBias;
662 }
663 
664 inline void MarkedBlock::noteMarked()
665 {
666     // This is racy by design. We don&#39;t want to pay the price of an atomic increment!
667     int16_t biasedMarkCount = footer().m_biasedMarkCount;
668     ++biasedMarkCount;
669     footer().m_biasedMarkCount = biasedMarkCount;
670     if (UNLIKELY(!biasedMarkCount))
671         noteMarkedSlow();
672 }
673 
</pre>
</td>
</tr>
</table>
<center><a href="MarkedBlock.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="MarkedBlockInlines.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>