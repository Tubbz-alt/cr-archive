diff a/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediastream/MediaStreamTrack.cpp b/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediastream/MediaStreamTrack.cpp
--- a/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediastream/MediaStreamTrack.cpp
+++ b/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediastream/MediaStreamTrack.cpp
@@ -31,14 +31,19 @@
 #if ENABLE(MEDIA_STREAM)
 
 #include "Document.h"
 #include "Event.h"
 #include "EventNames.h"
+#include "Frame.h"
+#include "FrameLoader.h"
+#include "JSDOMPromiseDeferred.h"
 #include "JSOverconstrainedError.h"
+#include "Logging.h"
 #include "MediaConstraints.h"
 #include "MediaStream.h"
 #include "MediaStreamPrivate.h"
+#include "NetworkingContext.h"
 #include "NotImplemented.h"
 #include "OverconstrainedError.h"
 #include "Page.h"
 #include "RealtimeMediaSourceCenter.h"
 #include "ScriptExecutionContext.h"
@@ -58,21 +63,22 @@
 
 WTF_MAKE_ISO_ALLOCATED_IMPL(MediaStreamTrack);
 
 Ref<MediaStreamTrack> MediaStreamTrack::create(ScriptExecutionContext& context, Ref<MediaStreamTrackPrivate>&& privateTrack)
 {
-    return adoptRef(*new MediaStreamTrack(context, WTFMove(privateTrack)));
+    auto track = adoptRef(*new MediaStreamTrack(context, WTFMove(privateTrack)));
+    track->suspendIfNeeded();
+    return track;
 }
 
 MediaStreamTrack::MediaStreamTrack(ScriptExecutionContext& context, Ref<MediaStreamTrackPrivate>&& privateTrack)
     : ActiveDOMObject(&context)
     , m_private(WTFMove(privateTrack))
-    , m_taskQueue(context)
     , m_isCaptureTrack(m_private->isCaptureTrack())
+    , m_mediaSession(PlatformMediaSession::create(*this))
 {
     ALWAYS_LOG(LOGIDENTIFIER);
-    suspendIfNeeded();
 
     m_private->addObserver(*this);
 
     if (!isCaptureTrack())
         return;
@@ -80,13 +86,10 @@
     allCaptureTracks().add(this);
 
     if (auto document = this->document()) {
         if (document->page() && document->page()->mutedState())
             setMuted(true);
-#if !PLATFORM(IOS_FAMILY)
-        document->addAudioProducer(*this);
-#endif
     }
 }
 
 MediaStreamTrack::~MediaStreamTrack()
 {
@@ -94,15 +97,10 @@
 
     if (!isCaptureTrack())
         return;
 
     allCaptureTracks().remove(this);
-
-#if !PLATFORM(IOS_FAMILY)
-    if (auto document = this->document())
-        document->removeAudioProducer(*this);
-#endif
 }
 
 const AtomString& MediaStreamTrack::kind() const
 {
     static NeverDestroyed<AtomString> audioKind("audio", AtomString::ConstructFromLiteral);
@@ -195,15 +193,15 @@
 {
     bool trackMuted = false;
     switch (source().deviceType()) {
     case CaptureDevice::DeviceType::Microphone:
     case CaptureDevice::DeviceType::Camera:
-        trackMuted = state & AudioAndVideoCaptureIsMuted;
+        trackMuted = state & MediaProducer::AudioAndVideoCaptureIsMuted;
         break;
     case CaptureDevice::DeviceType::Screen:
     case CaptureDevice::DeviceType::Window:
-        trackMuted = state & ScreenCaptureIsMuted;
+        trackMuted = state & MediaProducer::ScreenCaptureIsMuted;
         break;
     case CaptureDevice::DeviceType::Unknown:
         ASSERT_NOT_REACHED();
         break;
     }
@@ -321,22 +319,23 @@
 }
 
 static Vector<String> capabilityStringVector(const Vector<RealtimeMediaSourceSettings::VideoFacingMode>& modes)
 {
     Vector<String> result;
-    result.reserveCapacity(modes.size());
+    result.reserveInitialCapacity(modes.size());
     for (auto& mode : modes)
         result.uncheckedAppend(RealtimeMediaSourceSettings::facingMode(mode));
     return result;
 }
 
 static Vector<bool> capabilityBooleanVector(RealtimeMediaSourceCapabilities::EchoCancellation cancellation)
 {
     Vector<bool> result;
-    result.reserveCapacity(2);
+    result.reserveInitialCapacity(2);
     result.uncheckedAppend(true);
-    result.uncheckedAppend(cancellation == RealtimeMediaSourceCapabilities::EchoCancellation::ReadWrite);
+    if (cancellation == RealtimeMediaSourceCapabilities::EchoCancellation::ReadWrite)
+        result.uncheckedAppend(false);
     return result;
 }
 
 MediaStreamTrack::TrackCapabilities MediaStreamTrack::getCapabilities() const
 {
@@ -377,14 +376,14 @@
     return createMediaConstraints(constraints.value());
 }
 
 void MediaStreamTrack::applyConstraints(const Optional<MediaTrackConstraints>& constraints, DOMPromiseDeferred<void>&& promise)
 {
-    m_promise = WTFMove(promise);
+    m_promise = WTF::makeUnique<DOMPromiseDeferred<void>>(WTFMove(promise));
 
-    auto completionHandler = [this, weakThis = makeWeakPtr(*this), constraints](auto&& error) mutable {
-        if (!weakThis || !m_promise)
+    auto completionHandler = [this, protectedThis = makeRef(*this), constraints](auto&& error) mutable {
+        if (!m_promise)
             return;
         if (error) {
             m_promise->rejectType<IDLInterface<OverconstrainedError>>(OverconstrainedError::create(WTFMove(error->badConstraint), WTFMove(error->message)));
             return;
         }
@@ -402,30 +401,18 @@
 void MediaStreamTrack::removeObserver(Observer& observer)
 {
     m_observers.removeFirst(&observer);
 }
 
-void MediaStreamTrack::pageMutedStateDidChange()
-{
-    if (m_ended || !isCaptureTrack())
-        return;
-
-    Document* document = this->document();
-    if (!document || !document->page())
-        return;
-
-    setMuted(document->page()->mutedState());
-}
-
 MediaProducer::MediaStateFlags MediaStreamTrack::mediaState() const
 {
     if (m_ended || !isCaptureTrack())
-        return IsNotPlaying;
+        return MediaProducer::IsNotPlaying;
 
-    Document* document = this->document();
+    auto* document = this->document();
     if (!document || !document->page())
-        return IsNotPlaying;
+        return MediaProducer::IsNotPlaying;
 
     return sourceCaptureState(source());
 }
 
 MediaProducer::MediaStateFlags sourceCaptureState(RealtimeMediaSource& source)
@@ -461,37 +448,41 @@
     }
 
     return MediaProducer::IsNotPlaying;
 }
 
-#if PLATFORM(IOS_FAMILY)
-MediaProducer::MediaStateFlags MediaStreamTrack::captureState()
+MediaProducer::MediaStateFlags MediaStreamTrack::captureState(Document& document)
 {
     MediaProducer::MediaStateFlags state = MediaProducer::IsNotPlaying;
-    if (auto* source = RealtimeMediaSourceCenter::singleton().audioCaptureFactory().activeSource())
-        state |= sourceCaptureState(*source);
-    if (auto* source = RealtimeMediaSourceCenter::singleton().videoCaptureFactory().activeSource())
-        state |= sourceCaptureState(*source);
+    for (auto* captureTrack : allCaptureTracks()) {
+        if (captureTrack->document() != &document || captureTrack->ended())
+            continue;
+        state |= sourceCaptureState(captureTrack->source());
+    }
     return state;
 }
 
-void MediaStreamTrack::muteCapture()
+void MediaStreamTrack::updateCaptureAccordingToMutedState(Document& document)
 {
-    if (auto* source = RealtimeMediaSourceCenter::singleton().audioCaptureFactory().activeSource())
-        source->setMuted(true);
-    if (auto* source = RealtimeMediaSourceCenter::singleton().videoCaptureFactory().activeSource())
-        source->setMuted(true);
+    for (auto* captureTrack : allCaptureTracks()) {
+        if (captureTrack->document() != &document || captureTrack->ended())
+            continue;
+        captureTrack->setMuted(document.page()->mutedState());
+    }
 }
-#endif
 
 void MediaStreamTrack::endCapture(Document& document)
 {
+    bool didEndCapture = false;
     for (auto* captureTrack : allCaptureTracks()) {
         if (captureTrack->document() != &document)
             continue;
         captureTrack->stopTrack(MediaStreamTrack::StopMode::PostEvent);
+        didEndCapture = true;
     }
+    if (didEndCapture)
+        document.updateIsPlayingMedia();
 }
 
 void MediaStreamTrack::trackStarted(MediaStreamTrackPrivate&)
 {
     configureTrackRendering();
@@ -521,17 +512,15 @@
     configureTrackRendering();
 }
 
 void MediaStreamTrack::trackMutedChanged(MediaStreamTrackPrivate&)
 {
-    if (scriptExecutionContext()->activeDOMObjectsAreSuspended() || scriptExecutionContext()->activeDOMObjectsAreStopped() || m_ended)
+    if (scriptExecutionContext()->activeDOMObjectsAreStopped() || m_ended)
         return;
 
-    m_eventTaskQueue.enqueueTask([this, muted = this->muted()] {
-        AtomString eventType = muted ? eventNames().muteEvent : eventNames().unmuteEvent;
-        dispatchEvent(Event::create(eventType, Event::CanBubble::No, Event::IsCancelable::No));
-    });
+    AtomString eventType = muted() ? eventNames().muteEvent : eventNames().unmuteEvent;
+    queueTaskToDispatchEvent(*this, TaskSource::Networking, Event::create(eventType, Event::CanBubble::No, Event::IsCancelable::No));
 
     configureTrackRendering();
 }
 
 void MediaStreamTrack::trackSettingsChanged(MediaStreamTrackPrivate&)
@@ -544,38 +533,42 @@
     configureTrackRendering();
 }
 
 void MediaStreamTrack::configureTrackRendering()
 {
-    m_taskQueue.enqueueTask([this] {
-        if (auto document = this->document())
-            document->updateIsPlayingMedia();
-    });
+    if (m_mediaSession && m_private->type() == RealtimeMediaSource::Type::Audio)
+        m_mediaSession->canProduceAudioChanged();
+
+    if (auto document = this->document())
+        document->updateIsPlayingMedia();
 
     // 4.3.1
     // ... media from the source only flows when a MediaStreamTrack object is both unmuted and enabled
 }
 
-void MediaStreamTrack::stop()
-{
-    stopTrack();
-    m_taskQueue.close();
-}
-
 const char* MediaStreamTrack::activeDOMObjectName() const
 {
     return "MediaStreamTrack";
 }
 
-bool MediaStreamTrack::canSuspendForDocumentSuspension() const
+void MediaStreamTrack::suspend(ReasonForSuspension reason)
 {
-    return !hasPendingActivity();
+    if (reason != ReasonForSuspension::BackForwardCache)
+        return;
+
+    // We only end capture tracks, other tracks (capture canvas, remote tracks) can still continue working.
+    if (m_ended || !isCaptureTrack())
+        return;
+
+    stopTrack();
+
+    queueTaskToDispatchEvent(*this, TaskSource::Networking, Event::create(eventNames().endedEvent, Event::CanBubble::No, Event::IsCancelable::No));
 }
 
 bool MediaStreamTrack::hasPendingActivity() const
 {
-    return !m_ended;
+    return !m_ended || ActiveDOMObject::hasPendingActivity();
 }
 
 AudioSourceProvider* MediaStreamTrack::audioSourceProvider()
 {
     return m_private->audioSourceProvider();
@@ -584,10 +577,59 @@
 Document* MediaStreamTrack::document() const
 {
     return downcast<Document>(scriptExecutionContext());
 }
 
+PlatformMediaSession::MediaType MediaStreamTrack::mediaType() const
+{
+    return (isCaptureTrack() && canProduceAudio()) ? PlatformMediaSession::MediaStreamCapturingAudio : PlatformMediaSession::None;
+}
+
+PlatformMediaSession::MediaType MediaStreamTrack::presentationType() const
+{
+    return mediaType();
+}
+
+PlatformMediaSession::CharacteristicsFlags MediaStreamTrack::characteristics() const
+{
+    if (!m_private->isActive())
+        return PlatformMediaSession::HasNothing;
+
+    return m_private->type() == RealtimeMediaSource::Type::Audio ? PlatformMediaSession::HasAudio : PlatformMediaSession::HasVideo;
+}
+
+void MediaStreamTrack::mayResumePlayback(bool)
+{
+    // FIXME: should a media stream track pay attention to this directly, or only when attached to a media element?
+}
+
+void MediaStreamTrack::suspendPlayback()
+{
+    // FIXME: should a media stream track pay attention to this directly, or only when attached to a media element?
+}
+
+String MediaStreamTrack::sourceApplicationIdentifier() const
+{
+    auto* document = this->document();
+    if (document && document->frame()) {
+        if (auto* networkingContext = document->frame()->loader().networkingContext())
+            return networkingContext->sourceApplicationIdentifier();
+    }
+
+    return emptyString();
+}
+
+bool MediaStreamTrack::canProduceAudio() const
+{
+    return m_private->type() == RealtimeMediaSource::Type::Audio && !ended() && !muted();
+}
+
+bool MediaStreamTrack::processingUserGestureForMedia() const
+{
+    return document() ? document()->processingUserGestureForMedia() : false;
+}
+
 #if !RELEASE_LOG_DISABLED
 WTFLogChannel& MediaStreamTrack::logChannel() const
 {
     return LogWebRTC;
 }
