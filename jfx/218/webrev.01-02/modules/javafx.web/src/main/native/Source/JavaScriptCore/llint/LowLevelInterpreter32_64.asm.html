<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter32_64.asm</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 # Copyright (C) 2011-2019 Apple Inc. All rights reserved.
   2 #
   3 # Redistribution and use in source and binary forms, with or without
   4 # modification, are permitted provided that the following conditions
   5 # are met:
   6 # 1. Redistributions of source code must retain the above copyright
   7 #    notice, this list of conditions and the following disclaimer.
   8 # 2. Redistributions in binary form must reproduce the above copyright
   9 #    notice, this list of conditions and the following disclaimer in the
  10 #    documentation and/or other materials provided with the distribution.
  11 #
  12 # THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
  13 # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
  14 # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  15 # PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
  16 # BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  17 # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  18 # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
  19 # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
  20 # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
  21 # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
  22 # THE POSSIBILITY OF SUCH DAMAGE.
  23 
  24 
  25 # Utilities
  26 # FIXME:  Merge &quot;getOperand&quot; macros on 32 and 64 bits LLInt
  27 # https://bugs.webkit.org/show_bug.cgi?id=206342
  28 
  29 macro getuOperandNarrow(opcodeStruct, fieldName, dst)
  30     loadb constexpr %opcodeStruct%_%fieldName%_index + OpcodeIDNarrowSize[PB, PC, 1], dst
  31 end
  32 
  33 macro getOperandNarrow(opcodeStruct, fieldName, dst)
  34     loadbsi constexpr %opcodeStruct%_%fieldName%_index + OpcodeIDNarrowSize[PB, PC, 1], dst
  35 end
  36 
  37 macro getuOperandWide16(opcodeStruct, fieldName, dst)
  38     loadh constexpr %opcodeStruct%_%fieldName%_index * 2 + OpcodeIDWide16Size[PB, PC, 1], dst
  39 end
  40 
  41 macro getOperandWide16(opcodeStruct, fieldName, dst)
  42     loadhsi constexpr %opcodeStruct%_%fieldName%_index * 2 + OpcodeIDWide16Size[PB, PC, 1], dst
  43 end
  44 
  45 macro getuOperandWide32(opcodeStruct, fieldName, dst)
  46     loadi constexpr %opcodeStruct%_%fieldName%_index * 4 + OpcodeIDWide32Size[PB, PC, 1], dst
  47 end
  48 
  49 macro getOperandWide32(opcodeStruct, fieldName, dst)
  50     loadis constexpr %opcodeStruct%_%fieldName%_index * 4 + OpcodeIDWide32Size[PB, PC, 1], dst
  51 end
  52 
  53 macro makeReturn(get, dispatch, fn)
  54     fn(macro(tag, payload)
  55         move tag, t5
  56         move payload, t3
  57         get(m_dst, t2)
  58         storei t5, TagOffset[cfr, t2, 8]
  59         storei t3, PayloadOffset[cfr, t2, 8]
  60         dispatch()
  61     end)
  62 end
  63 
  64 macro makeReturnProfiled(opcodeStruct, get, metadata, dispatch, fn)
  65     fn(macro (tag, payload)
  66         move tag, t1
  67         move payload, t0
  68 
  69         metadata(t5, t2)
  70         valueProfile(opcodeStruct, t5, t1, t0)
  71         get(m_dst, t2)
  72         storei t1, TagOffset[cfr, t2, 8]
  73         storei t0, PayloadOffset[cfr, t2, 8]
  74         dispatch()
  75     end)
  76 end
  77 
  78 
  79 # After calling, calling bytecode is claiming input registers are not used.
  80 macro dispatchAfterCall(size, opcodeStruct, dispatch)
  81     loadi ArgumentCountIncludingThis + TagOffset[cfr], PC
  82     loadp CodeBlock[cfr], PB
  83     loadp CodeBlock::m_instructionsRawPointer[PB], PB
  84     get(size, opcodeStruct, m_dst, t3)
  85     storei r1, TagOffset[cfr, t3, 8]
  86     storei r0, PayloadOffset[cfr, t3, 8]
  87     metadata(size, opcodeStruct, t2, t3)
  88     valueProfile(opcodeStruct, t2, r1, r0)
  89     dispatch()
  90 end
  91 
  92 macro cCall2(function)
  93     if ARMv7 or MIPS
  94         call function
  95     elsif X86 or X86_WIN
  96         subp 8, sp
  97         push a1
  98         push a0
  99         call function
 100         addp 16, sp
 101     elsif C_LOOP or C_LOOP_WIN
 102         cloopCallSlowPath function, a0, a1
 103     else
 104         error
 105     end
 106 end
 107 
 108 macro cCall2Void(function)
 109     if C_LOOP or C_LOOP_WIN
 110         cloopCallSlowPathVoid function, a0, a1
 111     else
 112         cCall2(function)
 113     end
 114 end
 115 
 116 macro cCall4(function)
 117     if ARMv7 or MIPS
 118         call function
 119     elsif X86 or X86_WIN
 120         push a3
 121         push a2
 122         push a1
 123         push a0
 124         call function
 125         addp 16, sp
 126     elsif C_LOOP or C_LOOP_WIN
 127         error
 128     else
 129         error
 130     end
 131 end
 132 
 133 macro prepareStateForCCall()
 134     addp PB, PC
 135 end
 136 
 137 macro restoreStateAfterCCall()
 138     move r0, PC
 139     subp PB, PC
 140 end
 141 
 142 macro callSlowPath(slowPath)
 143     prepareStateForCCall()
 144     move cfr, a0
 145     move PC, a1
 146     cCall2(slowPath)
 147     restoreStateAfterCCall()
 148 end
 149 
 150 macro doVMEntry(makeCall)
 151     functionPrologue()
 152     pushCalleeSaves()
 153 
 154     # x86 needs to load arguments from the stack
 155     if X86 or X86_WIN
 156         loadp 16[cfr], a2
 157         loadp 12[cfr], a1
 158         loadp 8[cfr], a0
 159     end
 160 
 161     const entry = a0
 162     const vm = a1
 163     const protoCallFrame = a2
 164 
 165     # We are using t3, t4 and t5 as temporaries through the function.
 166     # Since we have the guarantee that tX != aY when X != Y, we are safe from
 167     # aliasing problems with our arguments.
 168 
 169     if ARMv7
 170         vmEntryRecord(cfr, t3)
 171         move t3, sp
 172     else
 173         vmEntryRecord(cfr, sp)
 174     end
 175 
 176     storep vm, VMEntryRecord::m_vm[sp]
 177     loadp VM::topCallFrame[vm], t4
 178     storep t4, VMEntryRecord::m_prevTopCallFrame[sp]
 179     loadp VM::topEntryFrame[vm], t4
 180     storep t4, VMEntryRecord::m_prevTopEntryFrame[sp]
 181     loadp ProtoCallFrame::calleeValue[protoCallFrame], t4
 182     storep t4, VMEntryRecord::m_callee[sp]
 183 
 184     # Align stack pointer
 185     if X86_WIN or MIPS
 186         addp CallFrameAlignSlots * SlotSize, sp, t3
 187         andp ~StackAlignmentMask, t3
 188         subp t3, CallFrameAlignSlots * SlotSize, sp
 189     elsif ARMv7
 190         addp CallFrameAlignSlots * SlotSize, sp, t3
 191         clrbp t3, StackAlignmentMask, t3
 192         subp t3, CallFrameAlignSlots * SlotSize, t3
 193         move t3, sp
 194     end
 195 
 196     loadi ProtoCallFrame::paddedArgCount[protoCallFrame], t4
 197     addp CallFrameHeaderSlots, t4, t4
 198     lshiftp 3, t4
 199     subp sp, t4, t3
 200     bpa t3, sp, .throwStackOverflow
 201 
 202     # Ensure that we have enough additional stack capacity for the incoming args,
 203     # and the frame for the JS code we&#39;re executing. We need to do this check
 204     # before we start copying the args from the protoCallFrame below.
 205     if C_LOOP or C_LOOP_WIN
 206         bpaeq t3, VM::m_cloopStackLimit[vm], .stackHeightOK
 207         move entry, t4
 208         move vm, t5
 209         cloopCallSlowPath _llint_stack_check_at_vm_entry, vm, t3
 210         bpeq t0, 0, .stackCheckFailed
 211         move t4, entry
 212         move t5, vm
 213         jmp .stackHeightOK
 214 
 215 .stackCheckFailed:
 216         move t4, entry
 217         move t5, vm
 218         jmp .throwStackOverflow
 219     else
 220         bpb t3, VM::m_softStackLimit[vm], .throwStackOverflow
 221     end
 222 
 223 .stackHeightOK:
 224     move t3, sp
 225     move (constexpr ProtoCallFrame::numberOfRegisters), t3
 226 
 227 .copyHeaderLoop:
 228     subi 1, t3
 229     loadi TagOffset[protoCallFrame, t3, 8], t5
 230     storei t5, TagOffset + CodeBlock[sp, t3, 8]
 231     loadi PayloadOffset[protoCallFrame, t3, 8], t5
 232     storei t5, PayloadOffset + CodeBlock[sp, t3, 8]
 233     btinz t3, .copyHeaderLoop
 234 
 235     loadi PayloadOffset + ProtoCallFrame::argCountAndCodeOriginValue[protoCallFrame], t4
 236     subi 1, t4
 237     loadi ProtoCallFrame::paddedArgCount[protoCallFrame], t5
 238     subi 1, t5
 239 
 240     bieq t4, t5, .copyArgs
 241 .fillExtraArgsLoop:
 242     subi 1, t5
 243     storei UndefinedTag, ThisArgumentOffset + 8 + TagOffset[sp, t5, 8]
 244     storei 0, ThisArgumentOffset + 8 + PayloadOffset[sp, t5, 8]
 245     bineq t4, t5, .fillExtraArgsLoop
 246 
 247 .copyArgs:
 248     loadp ProtoCallFrame::args[protoCallFrame], t3
 249 
 250 .copyArgsLoop:
 251     btiz t4, .copyArgsDone
 252     subi 1, t4
 253     loadi TagOffset[t3, t4, 8], t5
 254     storei t5, ThisArgumentOffset + 8 + TagOffset[sp, t4, 8]
 255     loadi PayloadOffset[t3, t4, 8], t5
 256     storei t5, ThisArgumentOffset + 8 + PayloadOffset[sp, t4, 8]
 257     jmp .copyArgsLoop
 258 
 259 .copyArgsDone:
 260     storep sp, VM::topCallFrame[vm]
 261     storep cfr, VM::topEntryFrame[vm]
 262 
 263     makeCall(entry, protoCallFrame, t3, t4)
 264 
 265     if ARMv7
 266         vmEntryRecord(cfr, t3)
 267         move t3, sp
 268     else
 269         vmEntryRecord(cfr, sp)
 270     end
 271 
 272     loadp VMEntryRecord::m_vm[sp], t5
 273     loadp VMEntryRecord::m_prevTopCallFrame[sp], t4
 274     storep t4, VM::topCallFrame[t5]
 275     loadp VMEntryRecord::m_prevTopEntryFrame[sp], t4
 276     storep t4, VM::topEntryFrame[t5]
 277 
 278     if ARMv7
 279         subp cfr, CalleeRegisterSaveSize, t5
 280         move t5, sp
 281     else
 282         subp cfr, CalleeRegisterSaveSize, sp
 283     end
 284 
 285     popCalleeSaves()
 286     functionEpilogue()
 287     ret
 288 
 289 .throwStackOverflow:
 290     subp 8, sp # Align stack for cCall2() to make a call.
 291     move vm, a0
 292     move protoCallFrame, a1
 293     cCall2(_llint_throw_stack_overflow_error)
 294 
 295     if ARMv7
 296         vmEntryRecord(cfr, t3)
 297         move t3, sp
 298     else
 299         vmEntryRecord(cfr, sp)
 300     end
 301 
 302     loadp VMEntryRecord::m_vm[sp], t5
 303     loadp VMEntryRecord::m_prevTopCallFrame[sp], t4
 304     storep t4, VM::topCallFrame[t5]
 305     loadp VMEntryRecord::m_prevTopEntryFrame[sp], t4
 306     storep t4, VM::topEntryFrame[t5]
 307 
 308     if ARMv7
 309         subp cfr, CalleeRegisterSaveSize, t5
 310         move t5, sp
 311     else
 312         subp cfr, CalleeRegisterSaveSize, sp
 313     end
 314 
 315     popCalleeSaves()
 316     functionEpilogue()
 317     ret
 318 end
 319 
 320 # a0, a2, t3, t4
 321 macro makeJavaScriptCall(entry, protoCallFrame, temp1, temp2)
 322     addp CallerFrameAndPCSize, sp
 323     checkStackPointerAlignment(temp1, 0xbad0dc02)
 324     if C_LOOP or C_LOOP_WIN
 325         cloopCallJSFunction entry
 326     else
 327         call entry
 328     end
 329     checkStackPointerAlignment(temp1, 0xbad0dc03)
 330     subp CallerFrameAndPCSize, sp
 331 end
 332 
 333 # a0, a2, t3, t4
 334 macro makeHostFunctionCall(entry, protoCallFrame, temp1, temp2)
 335     move entry, temp1
 336     storep cfr, [sp]
 337     if C_LOOP or C_LOOP_WIN
 338         loadp ProtoCallFrame::globalObject[protoCallFrame], a0
 339         move sp, a1
 340         storep lr, PtrSize[sp]
 341         cloopCallNative temp1
 342     elsif X86 or X86_WIN
 343         # Put callee frame pointer on stack as arg1, also put it in ecx for &quot;fastcall&quot; targets
 344         move 0, temp2
 345         move temp2, 4[sp] # put 0 in ReturnPC
 346         move sp, a1 # a1 is edx
 347         loadp ProtoCallFrame::globalObject[protoCallFrame], a0
 348         push a1
 349         push a0
 350         call temp1
 351         addp 8, sp
 352     elsif MIPS
 353         move sp, a1
 354         # We need to allocate stack space for 16 bytes (8-byte aligned)
 355         # for 4 arguments, since callee can use this space.
 356         subp 16, sp
 357         loadp ProtoCallFrame::globalObject[protoCallFrame], a0
 358         call temp1
 359         addp 16, sp
 360     else
 361         loadp ProtoCallFrame::globalObject[protoCallFrame], a0
 362         move sp, a1
 363         call temp1
 364     end
 365 end
 366 
 367 op(handleUncaughtException, macro()
 368     loadp Callee + PayloadOffset[cfr], t3
 369     convertCalleeToVM(t3)
 370     restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(t3, t0)
 371     storep 0, VM::callFrameForCatch[t3]
 372 
 373     loadp VM::topEntryFrame[t3], cfr
 374     if ARMv7
 375         vmEntryRecord(cfr, t3)
 376         move t3, sp
 377     else
 378         vmEntryRecord(cfr, sp)
 379     end
 380 
 381     loadp VMEntryRecord::m_vm[sp], t3
 382     loadp VMEntryRecord::m_prevTopCallFrame[sp], t5
 383     storep t5, VM::topCallFrame[t3]
 384     loadp VMEntryRecord::m_prevTopEntryFrame[sp], t5
 385     storep t5, VM::topEntryFrame[t3]
 386 
 387     if ARMv7
 388         subp cfr, CalleeRegisterSaveSize, t3
 389         move t3, sp
 390     else
 391         subp cfr, CalleeRegisterSaveSize, sp
 392     end
 393 
 394     popCalleeSaves()
 395     functionEpilogue()
 396     ret
 397 end)
 398 
 399 macro doReturnFromHostFunction(extraStackSpace)
 400     functionEpilogue(extraStackSpace)
 401     ret
 402 end
 403 
 404 # Debugging operation if you&#39;d like to print an operand in the instruction stream. fromWhere
 405 # should be an immediate integer - any integer you like; use it to identify the place you&#39;re
 406 # debugging from. operand should likewise be an immediate, and should identify the operand
 407 # in the instruction stream you&#39;d like to print out.
 408 macro traceOperand(fromWhere, operand)
 409     prepareStateForCCall()
 410     move fromWhere, a2
 411     move operand, a3
 412     move cfr, a0
 413     move PC, a1
 414     cCall4(_llint_trace_operand)
 415     restoreStateAfterCCall()
 416     move r1, cfr
 417 end
 418 
 419 # Debugging operation if you&#39;d like to print the value of an operand in the instruction
 420 # stream. Same as traceOperand(), but assumes that the operand is a register, and prints its
 421 # value.
 422 macro traceValue(fromWhere, operand)
 423     prepareStateForCCall()
 424     move fromWhere, a2
 425     move operand, a3
 426     move cfr, a0
 427     move PC, a1
 428     cCall4(_llint_trace_value)
 429     restoreStateAfterCCall()
 430     move r1, cfr
 431 end
 432 
 433 # Call a slowPath for call opcodes.
 434 macro callCallSlowPath(slowPath, action)
 435     storep PC, ArgumentCountIncludingThis + TagOffset[cfr]
 436     prepareStateForCCall()
 437     move cfr, a0
 438     move PC, a1
 439     cCall2(slowPath)
 440     action(r0, r1)
 441 end
 442 
 443 macro callTrapHandler(throwHandler)
 444     storei PC, ArgumentCountIncludingThis + TagOffset[cfr]
 445     prepareStateForCCall()
 446     move cfr, a0
 447     move PC, a1
 448     cCall2(_llint_slow_path_handle_traps)
 449     btpnz r0, throwHandler
 450     loadi ArgumentCountIncludingThis + TagOffset[cfr], PC
 451 end
 452 
 453 macro checkSwitchToJITForLoop()
 454     checkSwitchToJIT(
 455         1,
 456         macro ()
 457             storei PC, ArgumentCountIncludingThis + TagOffset[cfr]
 458             prepareStateForCCall()
 459             move cfr, a0
 460             move PC, a1
 461             cCall2(_llint_loop_osr)
 462             btpz r0, .recover
 463             move r1, sp
 464             jmp r0
 465         .recover:
 466             loadi ArgumentCountIncludingThis + TagOffset[cfr], PC
 467         end)
 468 end
 469 
 470 macro loadVariable(get, fieldName, indexReg, tagReg, payloadReg)
 471     get(fieldName, indexReg)
 472     loadi TagOffset[cfr, indexReg, 8], tagReg
 473     loadi PayloadOffset[cfr, indexReg, 8], payloadReg
 474 end
 475 
 476 # Index, tag, and payload must be different registers. Index is not
 477 # changed.
 478 macro loadConstant(size, index, tag, payload)
 479     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)
 480         loadp CodeBlock[cfr], payload
 481         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[payload], payload
 482         subp FirstConstantRegisterIndex, index
 483         loadp TagOffset[payload, index, 8], tag
 484         loadp PayloadOffset[payload, index, 8], payload
 485     end)
 486 end
 487 
 488 # Index, tag, and payload must be different registers. Index is not
 489 # changed.
 490 macro loadConstantOrVariable(size, index, tag, payload)
 491     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)
 492         bigteq index, FirstConstantRegisterIndex, .constant
 493         loadi TagOffset[cfr, index, 8], tag
 494         loadi PayloadOffset[cfr, index, 8], payload
 495         jmp .done
 496     .constant:
 497         loadConstant(size, index, tag, payload)
 498     .done:
 499     end)
 500 end
 501 
 502 macro loadConstantOrVariableTag(size, index, tag)
 503     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)
 504         bigteq index, FirstConstantRegisterIndex, .constant
 505         loadi TagOffset[cfr, index, 8], tag
 506         jmp .done
 507     .constant:
 508         loadp CodeBlock[cfr], tag
 509         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[tag], tag
 510         subi FirstConstantRegisterIndex, index
 511         loadp TagOffset[tag, index, 8], tag
 512     .done:
 513     end)
 514 end
 515 
 516 # Index and payload may be the same register. Index may be clobbered.
 517 macro loadConstantOrVariable2Reg(size, index, tag, payload)
 518     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)
 519         bigteq index, FirstConstantRegisterIndex, .constant
 520         loadi TagOffset[cfr, index, 8], tag
 521         loadi PayloadOffset[cfr, index, 8], payload
 522         jmp .done
 523     .constant:
 524         loadp CodeBlock[cfr], tag
 525         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[tag], tag
 526         subi FirstConstantRegisterIndex, index
 527         lshifti 3, index
 528         addp index, tag
 529         loadp PayloadOffset[tag], payload
 530         loadp TagOffset[tag], tag
 531     .done:
 532     end)
 533 end
 534 
 535 macro loadConstantOrVariablePayloadTagCustom(size, index, tagCheck, payload)
 536     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)
 537         bigteq index, FirstConstantRegisterIndex, .constant
 538         tagCheck(TagOffset[cfr, index, 8])
 539         loadi PayloadOffset[cfr, index, 8], payload
 540         jmp .done
 541     .constant:
 542         loadp CodeBlock[cfr], payload
 543         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[payload], payload
 544         subp FirstConstantRegisterIndex, index
 545         tagCheck(TagOffset[payload, index, 8])
 546         loadp PayloadOffset[payload, index, 8], payload
 547     .done:
 548     end)
 549 end
 550 
 551 # Index and payload must be different registers. Index is not mutated. Use
 552 # this if you know what the tag of the variable should be. Doing the tag
 553 # test as part of loading the variable reduces register use, but may not
 554 # be faster than doing loadConstantOrVariable followed by a branch on the
 555 # tag.
 556 macro loadConstantOrVariablePayload(size, index, expectedTag, payload, slow)
 557     loadConstantOrVariablePayloadTagCustom(
 558         size,
 559         index,
 560         macro (actualTag) bineq actualTag, expectedTag, slow end,
 561         payload)
 562 end
 563 
 564 macro loadConstantOrVariablePayloadUnchecked(size, index, payload)
 565     loadConstantOrVariablePayloadTagCustom(
 566         size,
 567         index,
 568         macro (actualTag) end,
 569         payload)
 570 end
 571 
 572 macro writeBarrierOnCellWithReload(cell, reloadAfterSlowPath)
 573     skipIfIsRememberedOrInEden(
 574         cell,
 575         macro()
 576             push PB, PC
 577             # We make two extra slots because cCall2 will poke.
 578             subp 8, sp
 579             move cell, a1 # cell can be a0
 580             move cfr, a0
 581             cCall2Void(_llint_write_barrier_slow)
 582             addp 8, sp
 583             pop PC, PB
 584             reloadAfterSlowPath()
 585         end)
 586 end
 587 
 588 macro writeBarrierOnOperand(size, get, cellFieldName)
 589     get(cellFieldName, t1)
 590     loadConstantOrVariablePayload(size, t1, CellTag, t2, .writeBarrierDone)
 591     writeBarrierOnCellWithReload(t2, macro() end)
 592 .writeBarrierDone:
 593 end
 594 
 595 macro writeBarrierOnOperands(size, get, cellFieldName, valueFieldName)
 596     get(valueFieldName, t1)
 597     loadConstantOrVariableTag(size, t1, t0)
 598     bineq t0, CellTag, .writeBarrierDone
 599 
 600     writeBarrierOnOperand(size, get, cellFieldName)
 601 .writeBarrierDone:
 602 end
 603 
 604 macro writeBarrierOnGlobal(size, get, valueFieldName, loadMacro)
 605     get(valueFieldName, t1)
 606     loadConstantOrVariableTag(size, t1, t0)
 607     bineq t0, CellTag, .writeBarrierDone
 608 
 609     loadMacro(t3)
 610 
 611     writeBarrierOnCellWithReload(t3, macro() end)
 612 .writeBarrierDone:
 613 end
 614 
 615 macro writeBarrierOnGlobalObject(size, get, valueFieldName)
 616     writeBarrierOnGlobal(size, get, valueFieldName,
 617         macro(registerToStoreGlobal)
 618             loadp CodeBlock[cfr], registerToStoreGlobal
 619             loadp CodeBlock::m_globalObject[registerToStoreGlobal], registerToStoreGlobal
 620         end)
 621 end
 622 
 623 macro writeBarrierOnGlobalLexicalEnvironment(size, get, valueFieldName)
 624     writeBarrierOnGlobal(size, get, valueFieldName,
 625         macro(registerToStoreGlobal)
 626             loadp CodeBlock[cfr], registerToStoreGlobal
 627             loadp CodeBlock::m_globalObject[registerToStoreGlobal], registerToStoreGlobal
 628             loadp JSGlobalObject::m_globalLexicalEnvironment[registerToStoreGlobal], registerToStoreGlobal
 629         end)
 630 end
 631 
 632 macro valueProfile(opcodeStruct, metadata, tag, payload)
 633     storei tag, %opcodeStruct%::Metadata::m_profile.m_buckets + TagOffset[metadata]
 634     storei payload, %opcodeStruct%::Metadata::m_profile.m_buckets + PayloadOffset[metadata]
 635 end
 636 
 637 
 638 # Entrypoints into the interpreter
 639 
 640 # Expects that CodeBlock is in t1, which is what prologue() leaves behind.
 641 macro functionArityCheck(doneLabel, slowPath)
 642     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t0
 643     biaeq t0, CodeBlock::m_numParameters[t1], doneLabel
 644     prepareStateForCCall()
 645     move cfr, a0
 646     move PC, a1
 647     cCall2(slowPath)   # This slowPath has a simple protocol: t0 = 0 =&gt; no error, t0 != 0 =&gt; error
 648     btiz r0, .noError
 649 
 650     # We&#39;re throwing before the frame is fully set up. This frame will be
 651     # ignored by the unwinder. So, let&#39;s restore the callee saves before we
 652     # start unwinding. We need to do this before we change the cfr.
 653     restoreCalleeSavesUsedByLLInt()
 654 
 655     move r1, cfr   # r1 contains caller frame
 656     jmp _llint_throw_from_slow_path_trampoline
 657 
 658 .noError:
 659     move r1, t1 # r1 contains slotsToAdd.
 660     btiz t1, .continue
 661     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t2
 662     addi CallFrameHeaderSlots, t2
 663 
 664     // Check if there are some unaligned slots we can use
 665     move t1, t3
 666     andi StackAlignmentSlots - 1, t3
 667     btiz t3, .noExtraSlot
 668 .fillExtraSlots:
 669     move 0, t0
 670     storei t0, PayloadOffset[cfr, t2, 8]
 671     move UndefinedTag, t0
 672     storei t0, TagOffset[cfr, t2, 8]
 673     addi 1, t2
 674     bsubinz 1, t3, .fillExtraSlots
 675     andi ~(StackAlignmentSlots - 1), t1
 676     btiz t1, .continue
 677 
 678 .noExtraSlot:
 679     // Move frame up t1 slots
 680     negi t1
 681     move cfr, t3
 682     subp CalleeSaveSpaceAsVirtualRegisters * SlotSize, t3
 683     addi CalleeSaveSpaceAsVirtualRegisters, t2
 684     move t1, t0
 685     lshiftp 3, t0
 686     addp t0, cfr
 687     addp t0, sp
 688 .copyLoop:
 689     loadi PayloadOffset[t3], t0
 690     storei t0, PayloadOffset[t3, t1, 8]
 691     loadi TagOffset[t3], t0
 692     storei t0, TagOffset[t3, t1, 8]
 693     addp 8, t3
 694     bsubinz 1, t2, .copyLoop
 695 
 696     // Fill new slots with JSUndefined
 697     move t1, t2
 698 .fillLoop:
 699     move 0, t0
 700     storei t0, PayloadOffset[t3, t1, 8]
 701     move UndefinedTag, t0
 702     storei t0, TagOffset[t3, t1, 8]
 703     addp 8, t3
 704     baddinz 1, t2, .fillLoop
 705 
 706 .continue:
 707     # Reload CodeBlock and PC, since the slow_path clobbered it.
 708     loadp CodeBlock[cfr], t1
 709     loadp CodeBlock::m_instructionsRawPointer[t1], PB
 710     move 0, PC
 711     jmp doneLabel
 712 end
 713 
 714 # Instruction implementations
 715 
 716 _llint_op_enter:
 717     traceExecution()
 718     checkStackPointerAlignment(t2, 0xdead00e1)
 719     loadp CodeBlock[cfr], t2                // t2&lt;CodeBlock&gt; = cfr.CodeBlock
 720     loadi CodeBlock::m_numVars[t2], t2      // t2&lt;size_t&gt; = t2&lt;CodeBlock&gt;.m_numVars
 721     subi CalleeSaveSpaceAsVirtualRegisters, t2
 722     move cfr, t3
 723     subp CalleeSaveSpaceAsVirtualRegisters * SlotSize, t3
 724     btiz t2, .opEnterDone
 725     move UndefinedTag, t0
 726     move 0, t1
 727     negi t2
 728 .opEnterLoop:
 729     storei t0, TagOffset[t3, t2, 8]
 730     storei t1, PayloadOffset[t3, t2, 8]
 731     addi 1, t2
 732     btinz t2, .opEnterLoop
 733 .opEnterDone:
 734     callSlowPath(_slow_path_enter)
 735     dispatchOp(narrow, op_enter)
 736 
 737 
 738 llintOpWithProfile(op_get_argument, OpGetArgument, macro (size, get, dispatch, return)
 739     get(m_index, t2)
 740     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t0
 741     bilteq t0, t2, .opGetArgumentOutOfBounds
 742     loadi ThisArgumentOffset + TagOffset[cfr, t2, 8], t0
 743     loadi ThisArgumentOffset + PayloadOffset[cfr, t2, 8], t3
 744     return (t0, t3)
 745 
 746 .opGetArgumentOutOfBounds:
 747     return (UndefinedTag, 0)
 748 end)
 749 
 750 
 751 llintOpWithReturn(op_argument_count, OpArgumentCount, macro (size, get, dispatch, return)
 752     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t0
 753     subi 1, t0
 754     return(Int32Tag, t0)
 755 end)
 756 
 757 
 758 llintOpWithReturn(op_get_scope, OpGetScope, macro (size, get, dispatch, return)
 759     loadi Callee + PayloadOffset[cfr], t0
 760     loadp JSCallee::m_scope[t0], t0
 761     return (CellTag, t0)
 762 end)
 763 
 764 
 765 llintOpWithMetadata(op_to_this, OpToThis, macro (size, get, dispatch, metadata, return)
 766     get(m_srcDst, t0)
 767     bineq TagOffset[cfr, t0, 8], CellTag, .opToThisSlow
 768     loadi PayloadOffset[cfr, t0, 8], t0
 769     bbneq JSCell::m_type[t0], FinalObjectType, .opToThisSlow
 770     metadata(t2, t3)
 771     loadi OpToThis::Metadata::m_cachedStructureID[t2], t2
 772     bineq JSCell::m_structureID[t0], t2, .opToThisSlow
 773     dispatch()
 774 
 775 .opToThisSlow:
 776     callSlowPath(_slow_path_to_this)
 777     dispatch()
 778 end)
 779 
 780 
 781 llintOp(op_check_tdz, OpCheckTdz, macro (size, get, dispatch)
 782     get(m_targetVirtualRegister, t0)
 783     loadConstantOrVariableTag(size, t0, t1)
 784     bineq t1, EmptyValueTag, .opNotTDZ
 785     callSlowPath(_slow_path_throw_tdz_error)
 786 
 787 .opNotTDZ:
 788     dispatch()
 789 end)
 790 
 791 
 792 llintOpWithReturn(op_mov, OpMov, macro (size, get, dispatch, return)
 793     get(m_src, t1)
 794     loadConstantOrVariable(size, t1, t2, t3)
 795     return(t2, t3)
 796 end)
 797 
 798 
 799 llintOpWithReturn(op_not, OpNot, macro (size, get, dispatch, return)
 800     get(m_operand, t0)
 801     loadConstantOrVariable(size, t0, t2, t3)
 802     bineq t2, BooleanTag, .opNotSlow
 803     xori 1, t3
 804     return(t2, t3)
 805 
 806 .opNotSlow:
 807     callSlowPath(_slow_path_not)
 808     dispatch()
 809 end)
 810 
 811 
 812 macro equalityComparisonOp(opcodeName, opcodeStruct, integerComparison)
 813     llintOpWithReturn(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
 814         get(m_rhs, t2)
 815         get(m_lhs, t0)
 816         loadConstantOrVariable(size, t2, t3, t1)
 817         loadConstantOrVariable2Reg(size, t0, t2, t0)
 818         bineq t2, t3, .opEqSlow
 819         bieq t2, CellTag, .opEqSlow
 820         bib t2, LowestTag, .opEqSlow
 821         integerComparison(t0, t1, t0)
 822         return(BooleanTag, t0)
 823 
 824     .opEqSlow:
 825         callSlowPath(_slow_path_%opcodeName%)
 826         dispatch()
 827     end)
 828 end
 829 
 830 
 831 macro equalityJumpOp(opcodeName, opcodeStruct, integerComparison)
 832     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
 833         get(m_rhs, t2)
 834         get(m_lhs, t0)
 835         loadConstantOrVariable(size, t2, t3, t1)
 836         loadConstantOrVariable2Reg(size, t0, t2, t0)
 837         bineq t2, t3, .slow
 838         bieq t2, CellTag, .slow
 839         bib t2, LowestTag, .slow
 840         integerComparison(t0, t1, .jumpTarget)
 841         dispatch()
 842 
 843     .jumpTarget:
 844         jump(m_targetLabel)
 845 
 846     .slow:
 847         callSlowPath(_llint_slow_path_%opcodeName%)
 848         nextInstruction()
 849     end)
 850 end
 851 
 852 
 853 macro equalNullComparisonOp(opcodeName, opcodeStruct, fn)
 854     llintOpWithReturn(opcodeName, opcodeStruct, macro (size, get, dispatch, return)
 855         get(m_operand, t0)
 856         assertNotConstant(size, t0)
 857         loadi TagOffset[cfr, t0, 8], t1
 858         loadi PayloadOffset[cfr, t0, 8], t0
 859         bineq t1, CellTag, .opEqNullImmediate
 860         btbnz JSCell::m_flags[t0], MasqueradesAsUndefined, .opEqNullMasqueradesAsUndefined
 861         move 0, t1
 862         jmp .opEqNullNotImmediate
 863     .opEqNullMasqueradesAsUndefined:
 864         loadi JSCell::m_structureID[t0], t1
 865         loadp CodeBlock[cfr], t0
 866         loadp CodeBlock::m_globalObject[t0], t0
 867         cpeq Structure::m_globalObject[t1], t0, t1
 868         jmp .opEqNullNotImmediate
 869     .opEqNullImmediate:
 870         cieq t1, NullTag, t2
 871         cieq t1, UndefinedTag, t1
 872         ori t2, t1
 873     .opEqNullNotImmediate:
 874         fn(t1)
 875         return(BooleanTag, t1)
 876     end)
 877 end
 878 
 879 equalNullComparisonOp(op_eq_null, OpEqNull, macro (value) end)
 880 
 881 equalNullComparisonOp(op_neq_null, OpNeqNull,
 882     macro (value) xori 1, value end)
 883 
 884 
 885 llintOpWithReturn(op_is_undefined_or_null, OpIsUndefinedOrNull, macro (size, get, dispatch, return)
 886     get(m_operand, t0)
 887     loadConstantOrVariableTag(size, t0, t1)
 888     ori 1, t1
 889     cieq t1, NullTag, t1
 890     return(BooleanTag, t1)
 891 end)
 892 
 893 
 894 macro strictEqOp(opcodeName, opcodeStruct, equalityOperation)
 895     llintOpWithReturn(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
 896         get(m_rhs, t2)
 897         get(m_lhs, t0)
 898         loadConstantOrVariable(size, t2, t3, t1)
 899         loadConstantOrVariable2Reg(size, t0, t2, t0)
 900         bineq t2, t3, .slow
 901         bib t2, LowestTag, .slow
 902         bineq t2, CellTag, .notStringOrSymbol
 903         bbaeq JSCell::m_type[t0], ObjectType, .notStringOrSymbol
 904         bbb JSCell::m_type[t1], ObjectType, .slow
 905     .notStringOrSymbol:
 906         equalityOperation(t0, t1, t0)
 907         return(BooleanTag, t0)
 908 
 909     .slow:
 910         callSlowPath(_slow_path_%opcodeName%)
 911         dispatch()
 912     end)
 913 end
 914 
 915 
 916 macro strictEqualityJumpOp(opcodeName, opcodeStruct, equalityOperation)
 917     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
 918         get(m_rhs, t2)
 919         get(m_lhs, t0)
 920         loadConstantOrVariable(size, t2, t3, t1)
 921         loadConstantOrVariable2Reg(size, t0, t2, t0)
 922         bineq t2, t3, .slow
 923         bib t2, LowestTag, .slow
 924         bineq t2, CellTag, .notStringOrSymbol
 925         bbaeq JSCell::m_type[t0], ObjectType, .notStringOrSymbol
 926         bbb JSCell::m_type[t1], ObjectType, .slow
 927     .notStringOrSymbol:
 928         equalityOperation(t0, t1, .jumpTarget)
 929         dispatch()
 930 
 931     .jumpTarget:
 932         jump(m_targetLabel)
 933 
 934     .slow:
 935         callSlowPath(_llint_slow_path_%opcodeName%)
 936         nextInstruction()
 937     end)
 938 end
 939 
 940 
 941 strictEqOp(stricteq, OpStricteq,
 942     macro (left, right, result) cieq left, right, result end)
 943 
 944 
 945 strictEqOp(nstricteq, OpNstricteq,
 946     macro (left, right, result) cineq left, right, result end)
 947 
 948 
 949 strictEqualityJumpOp(jstricteq, OpJstricteq,
 950     macro (left, right, target) bieq left, right, target end)
 951 
 952 
 953 strictEqualityJumpOp(jnstricteq, OpJnstricteq,
 954     macro (left, right, target) bineq left, right, target end)
 955 
 956 
 957 macro preOp(opcodeName, opcodeStruct, integerOperation)
 958     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)
 959         macro updateArithProfile(type)
 960             orh type, %opcodeStruct%::Metadata::m_arithProfile + UnaryArithProfile::m_bits[t1]
 961         end
 962 
 963         metadata(t1, t2)
 964         get(m_srcDst, t0)
 965         bineq TagOffset[cfr, t0, 8], Int32Tag, .slow
 966         loadi PayloadOffset[cfr, t0, 8], t2
 967         # Metadata in t1, srcDst in t2
 968         integerOperation(t2, .slow)
 969         storei t2, PayloadOffset[cfr, t0, 8]
 970         updateArithProfile(ArithProfileInt)
 971         dispatch()
 972 
 973     .slow:
 974         callSlowPath(_slow_path_%opcodeName%)
 975         dispatch()
 976     end)
 977 end
 978 
 979 
 980 llintOpWithProfile(op_to_number, OpToNumber, macro (size, get, dispatch, return)
 981     get(m_operand, t0)
 982     loadConstantOrVariable(size, t0, t2, t3)
 983     bieq t2, Int32Tag, .opToNumberIsInt
 984     biaeq t2, LowestTag, .opToNumberSlow
 985 .opToNumberIsInt:
 986     return(t2, t3)
 987 
 988 .opToNumberSlow:
 989     callSlowPath(_slow_path_to_number)
 990     dispatch()
 991 end)
 992 
 993 llintOpWithProfile(op_to_numeric, OpToNumeric, macro (size, get, dispatch, return)
 994     get(m_operand, t0)
 995     loadConstantOrVariable(size, t0, t2, t3)
 996     bieq t2, Int32Tag, .opToNumericIsInt
 997     biaeq t2, LowestTag, .opToNumericSlow
 998 .opToNumericIsInt:
 999     return(t2, t3)
1000 
1001 .opToNumericSlow:
1002     callSlowPath(_slow_path_to_numeric)
1003     dispatch()
1004 end)
1005 
1006 
1007 llintOpWithReturn(op_to_string, OpToString, macro (size, get, dispatch, return)
1008     get(m_operand, t0)
1009     loadConstantOrVariable(size, t0, t2, t3)
1010     bineq t2, CellTag, .opToStringSlow
1011     bbneq JSCell::m_type[t3], StringType, .opToStringSlow
1012 .opToStringIsString:
1013     return(t2, t3)
1014 
1015 .opToStringSlow:
1016     callSlowPath(_slow_path_to_string)
1017     dispatch()
1018 end)
1019 
1020 
1021 llintOpWithProfile(op_to_object, OpToObject, macro (size, get, dispatch, return)
1022     get(m_operand, t0)
1023     loadConstantOrVariable(size, t0, t2, t3)
1024     bineq t2, CellTag, .opToObjectSlow
1025     bbb JSCell::m_type[t3], ObjectType, .opToObjectSlow
1026     return(t2, t3)
1027 
1028 .opToObjectSlow:
1029     callSlowPath(_slow_path_to_object)
1030     dispatch()
1031 end)
1032 
1033 
1034 llintOpWithMetadata(op_negate, OpNegate, macro (size, get, dispatch, metadata, return)
1035 
1036     macro updateArithProfile(type)
1037         orh type, OpNegate::Metadata::m_arithProfile + UnaryArithProfile::m_bits[t5]
1038     end
1039 
1040     metadata(t5, t0)
1041     get(m_operand, t0)
1042     loadConstantOrVariable(size, t0, t1, t2)
1043     bineq t1, Int32Tag, .opNegateSrcNotInt
1044     btiz t2, 0x7fffffff, .opNegateSlow
1045     negi t2
1046     updateArithProfile(ArithProfileInt)
1047     return (Int32Tag, t2)
1048 .opNegateSrcNotInt:
1049     bia t1, LowestTag, .opNegateSlow
1050     xori 0x80000000, t1
1051     updateArithProfile(ArithProfileNumber)
1052     return(t1, t2)
1053 
1054 .opNegateSlow:
1055     callSlowPath(_slow_path_negate)
1056     dispatch()
1057 end)
1058 
1059 
1060 macro binaryOpCustomStore(opcodeName, opcodeStruct, integerOperationAndStore, doubleOperation)
1061     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)
1062         macro arithProfile(type)
1063             orh type, %opcodeStruct%::Metadata::m_arithProfile + BinaryArithProfile::m_bits[t5]
1064         end
1065 
1066         metadata(t5, t2)
1067         get(m_rhs, t2)
1068         get(m_lhs, t0)
1069         loadConstantOrVariable(size, t2, t3, t1)
1070         loadConstantOrVariable2Reg(size, t0, t2, t0)
1071         bineq t2, Int32Tag, .op1NotInt
1072         bineq t3, Int32Tag, .op2NotInt
1073         arithProfile(ArithProfileIntInt)
1074         get(m_dst, t2)
1075         integerOperationAndStore(t3, t1, t0, .slow, t2)
1076         dispatch()
1077 
1078     .op1NotInt:
1079         # First operand is definitely not an int, the second operand could be anything.
1080         bia t2, LowestTag, .slow
1081         bib t3, LowestTag, .op1NotIntOp2Double
1082         bineq t3, Int32Tag, .slow
1083         arithProfile(ArithProfileNumberInt)
1084         ci2ds t1, ft1
1085         jmp .op1NotIntReady
1086     .op1NotIntOp2Double:
1087         fii2d t1, t3, ft1
1088         arithProfile(ArithProfileNumberNumber)
1089     .op1NotIntReady:
1090         get(m_dst, t1)
1091         fii2d t0, t2, ft0
1092         doubleOperation(ft1, ft0)
1093         stored ft0, [cfr, t1, 8]
1094         dispatch()
1095 
1096     .op2NotInt:
1097         # First operand is definitely an int, the second operand is definitely not.
1098         get(m_dst, t2)
1099         bia t3, LowestTag, .slow
1100         arithProfile(ArithProfileIntNumber)
1101         ci2ds t0, ft0
1102         fii2d t1, t3, ft1
1103         doubleOperation(ft1, ft0)
1104         stored ft0, [cfr, t2, 8]
1105         dispatch()
1106 
1107     .slow:
1108         callSlowPath(_slow_path_%opcodeName%)
1109         dispatch()
1110     end)
1111 end
1112 
1113 macro binaryOp(opcodeName, opcodeStruct, integerOperation, doubleOperation)
1114     binaryOpCustomStore(opcodeName, opcodeStruct,
1115         macro (int32Tag, left, right, slow, index)
1116             integerOperation(left, right, slow)
1117             storei int32Tag, TagOffset[cfr, index, 8]
1118             storei right, PayloadOffset[cfr, index, 8]
1119         end,
1120         doubleOperation)
1121 end
1122 
1123 binaryOp(add, OpAdd,
1124     macro (left, right, slow) baddio left, right, slow end,
1125     macro (left, right) addd left, right end)
1126 
1127 
1128 binaryOpCustomStore(mul, OpMul,
1129     macro (int32Tag, left, right, slow, index)
1130         const scratch = int32Tag   # We know that we can reuse the int32Tag register since it has a constant.
1131         move right, scratch
1132         bmulio left, scratch, slow
1133         btinz scratch, .done
1134         bilt left, 0, slow
1135         bilt right, 0, slow
1136     .done:
1137         storei Int32Tag, TagOffset[cfr, index, 8]
1138         storei scratch, PayloadOffset[cfr, index, 8]
1139     end,
1140     macro (left, right) muld left, right end)
1141 
1142 
1143 binaryOp(sub, OpSub,
1144     macro (left, right, slow) bsubio left, right, slow end,
1145     macro (left, right) subd left, right end)
1146 
1147 
1148 binaryOpCustomStore(div, OpDiv,
1149     macro (int32Tag, left, right, slow, index)
1150         ci2ds left, ft0
1151         ci2ds right, ft1
1152         divd ft0, ft1
1153         bcd2i ft1, right, .notInt
1154         storei int32Tag, TagOffset[cfr, index, 8]
1155         storei right, PayloadOffset[cfr, index, 8]
1156         jmp .done
1157     .notInt:
1158         stored ft1, [cfr, index, 8]
1159     .done:
1160     end,
1161     macro (left, right) divd left, right end)
1162 
1163 
1164 llintOpWithReturn(op_unsigned, OpUnsigned, macro (size, get, dispatch, return)
1165     get(m_operand, t1)
1166     loadConstantOrVariablePayload(size, t1, Int32Tag, t2, .opUnsignedSlow)
1167     bilt t2, 0, .opUnsignedSlow
1168     return (Int32Tag, t2)
1169 .opUnsignedSlow:
1170     callSlowPath(_slow_path_unsigned)
1171     dispatch()
1172 end)
1173 
1174 
1175 macro commonBitOp(opKind, opcodeName, opcodeStruct, operation)
1176     opKind(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
1177         get(m_rhs, t2)
1178         get(m_lhs, t0)
1179         loadConstantOrVariable(size, t2, t3, t1)
1180         loadConstantOrVariable2Reg(size, t0, t2, t0)
1181         bineq t3, Int32Tag, .slow
1182         bineq t2, Int32Tag, .slow
1183         operation(t1, t0)
1184         return (t3, t0)
1185 
1186     .slow:
1187         callSlowPath(_slow_path_%opcodeName%)
1188         dispatch()
1189     end)
1190 end
1191 
1192 macro bitOp(opcodeName, opcodeStruct, operation)
1193     commonBitOp(llintOpWithReturn, opcodeName, opcodeStruct, operation)
1194 end
1195 
1196 macro bitOpProfiled(opcodeName, opcodeStruct, operation)
1197     commonBitOp(llintOpWithProfile, opcodeName, opcodeStruct, operation)
1198 end
1199 
1200 
1201 bitOpProfiled(lshift, OpLshift,
1202     macro (left, right) lshifti left, right end)
1203 
1204 
1205 bitOp(rshift, OpRshift,
1206     macro (left, right) rshifti left, right end)
1207 
1208 
1209 bitOp(urshift, OpUrshift,
1210     macro (left, right) urshifti left, right end)
1211 
1212 bitOpProfiled(bitxor, OpBitxor,
1213     macro (left, right) xori left, right end)
1214 
1215 bitOpProfiled(bitand, OpBitand,
1216     macro (left, right) andi left, right end)
1217 
1218 bitOpProfiled(bitor, OpBitor,
1219     macro (left, right) ori left, right end)
1220 
1221 llintOpWithProfile(op_bitnot, OpBitnot, macro (size, get, dispatch, return)
1222     get(m_operand, t0)
1223     loadConstantOrVariable(size, t0, t2, t3)
1224     bineq t2, Int32Tag, .opBitNotSlow
1225     noti t3
1226     return (Int32Tag, t3)
1227 
1228  .opBitNotSlow:
1229     callSlowPath(_slow_path_bitnot)
1230     dispatch()
1231 end)
1232 
1233 llintOp(op_overrides_has_instance, OpOverridesHasInstance, macro (size, get, dispatch)
1234     get(m_dst, t3)
1235     storei BooleanTag, TagOffset[cfr, t3, 8]
1236 
1237     # First check if hasInstanceValue is the one on Function.prototype[Symbol.hasInstance]
1238     get(m_hasInstanceValue, t0)
1239     loadConstantOrVariablePayload(size, t0, CellTag, t2, .opOverrideshasInstanceValueNotCell)
1240     loadConstantOrVariable(size, t0, t1, t2)
1241     bineq t1, CellTag, .opOverrideshasInstanceValueNotCell
1242 
1243     # We don&#39;t need hasInstanceValue&#39;s tag register anymore.
1244     loadp CodeBlock[cfr], t1
1245     loadp CodeBlock::m_globalObject[t1], t1
1246     loadp JSGlobalObject::m_functionProtoHasInstanceSymbolFunction[t1], t1
1247     bineq t1, t2, .opOverrideshasInstanceValueNotDefault
1248 
1249     # We know the constructor is a cell.
1250     get(m_constructor, t0)
1251     loadConstantOrVariablePayloadUnchecked(size, t0, t1)
1252     tbz JSCell::m_flags[t1], ImplementsDefaultHasInstance, t0
1253     storei t0, PayloadOffset[cfr, t3, 8]
1254     dispatch()
1255 
1256 .opOverrideshasInstanceValueNotCell:
1257 .opOverrideshasInstanceValueNotDefault:
1258     storei 1, PayloadOffset[cfr, t3, 8]
1259     dispatch()
1260 end)
1261 
1262 
1263 llintOpWithReturn(op_is_empty, OpIsEmpty, macro (size, get, dispatch, return)
1264     get(m_operand, t1)
1265     loadConstantOrVariable(size, t1, t2, t3)
1266     cieq t2, EmptyValueTag, t3
1267     return(BooleanTag, t3)
1268 end)
1269 
1270 
1271 llintOpWithReturn(op_is_undefined, OpIsUndefined, macro (size, get, dispatch, return)
1272     get(m_operand, t1)
1273     loadConstantOrVariable(size, t1, t2, t3)
1274     bieq t2, CellTag, .opIsUndefinedCell
1275     cieq t2, UndefinedTag, t3
1276     return(BooleanTag, t3)
1277 .opIsUndefinedCell:
1278     btbnz JSCell::m_flags[t3], MasqueradesAsUndefined, .opIsUndefinedMasqueradesAsUndefined
1279     return(BooleanTag, 0)
1280 .opIsUndefinedMasqueradesAsUndefined:
1281     loadi JSCell::m_structureID[t3], t1
1282     loadp CodeBlock[cfr], t3
1283     loadp CodeBlock::m_globalObject[t3], t3
1284     cpeq Structure::m_globalObject[t1], t3, t1
1285     return(BooleanTag, t1)
1286 end)
1287 
1288 
1289 llintOpWithReturn(op_is_boolean, OpIsBoolean, macro (size, get, dispatch, return)
1290     get(m_operand, t1)
1291     loadConstantOrVariableTag(size, t1, t0)
1292     cieq t0, BooleanTag, t0
1293     return(BooleanTag, t0)
1294 end)
1295 
1296 
1297 llintOpWithReturn(op_is_number, OpIsNumber, macro (size, get, dispatch, return)
1298     get(m_operand, t1)
1299     loadConstantOrVariableTag(size, t1, t0)
1300     addi 1, t0
1301     cib t0, LowestTag + 1, t1
1302     return(BooleanTag, t1)
1303 end)
1304 
1305 
1306 llintOpWithReturn(op_is_cell_with_type, OpIsCellWithType, macro (size, get, dispatch, return)
1307     get(m_operand, t1)
1308     loadConstantOrVariable(size, t1, t0, t3)
1309     bineq t0, CellTag, .notCellCase
1310     getu(size, OpIsCellWithType, m_type, t0)
1311     cbeq JSCell::m_type[t3], t0, t1
1312     return(BooleanTag, t1)
1313 .notCellCase:
1314     return(BooleanTag, 0)
1315 end)
1316 
1317 
1318 llintOpWithReturn(op_is_object, OpIsObject, macro (size, get, dispatch, return)
1319     get(m_operand, t1)
1320     loadConstantOrVariable(size, t1, t0, t3)
1321     bineq t0, CellTag, .opIsObjectNotCell
1322     cbaeq JSCell::m_type[t3], ObjectType, t1
1323     return(BooleanTag, t1)
1324 .opIsObjectNotCell:
1325     return(BooleanTag, 0)
1326 end)
1327 
1328 
1329 macro loadPropertyAtVariableOffsetKnownNotInline(propertyOffset, objectAndStorage, tag, payload)
1330     assert(macro (ok) bigteq propertyOffset, firstOutOfLineOffset, ok end)
1331     negi propertyOffset
1332     loadp JSObject::m_butterfly[objectAndStorage], objectAndStorage
1333     loadi TagOffset + (firstOutOfLineOffset - 2) * 8[objectAndStorage, propertyOffset, 8], tag
1334     loadi PayloadOffset + (firstOutOfLineOffset - 2) * 8[objectAndStorage, propertyOffset, 8], payload
1335 end
1336 
1337 macro loadPropertyAtVariableOffset(propertyOffset, objectAndStorage, tag, payload)
1338     bilt propertyOffset, firstOutOfLineOffset, .isInline
1339     loadp JSObject::m_butterfly[objectAndStorage], objectAndStorage
1340     negi propertyOffset
1341     jmp .ready
1342 .isInline:
1343     addp sizeof JSObject - (firstOutOfLineOffset - 2) * 8, objectAndStorage
1344 .ready:
1345     loadi TagOffset + (firstOutOfLineOffset - 2) * 8[objectAndStorage, propertyOffset, 8], tag
1346     loadi PayloadOffset + (firstOutOfLineOffset - 2) * 8[objectAndStorage, propertyOffset, 8], payload
1347 end
1348 
1349 macro storePropertyAtVariableOffset(propertyOffsetAsInt, objectAndStorage, tag, payload)
1350     bilt propertyOffsetAsInt, firstOutOfLineOffset, .isInline
1351     loadp JSObject::m_butterfly[objectAndStorage], objectAndStorage
1352     negi propertyOffsetAsInt
1353     jmp .ready
1354 .isInline:
1355     addp sizeof JSObject - (firstOutOfLineOffset - 2) * 8, objectAndStorage
1356 .ready:
1357     storei tag, TagOffset + (firstOutOfLineOffset - 2) * 8[objectAndStorage, propertyOffsetAsInt, 8]
1358     storei payload, PayloadOffset + (firstOutOfLineOffset - 2) * 8[objectAndStorage, propertyOffsetAsInt, 8]
1359 end
1360 
1361 
1362 # We only do monomorphic get_by_id caching for now, and we do not modify the
1363 # opcode for own properties. We also allow for the cache to change anytime it fails,
1364 # since ping-ponging is free. At best we get lucky and the get_by_id will continue
1365 # to take fast path on the new cache. At worst we take slow path, which is what
1366 # we would have been doing anyway. For prototype/unset properties, we will attempt to
1367 # convert opcode into a get_by_id_proto_load/get_by_id_unset, respectively, after an
1368 # execution counter hits zero.
1369 
1370 llintOpWithMetadata(op_get_by_id_direct, OpGetByIdDirect, macro (size, get, dispatch, metadata, return)
1371     metadata(t5, t0)
1372     get(m_base, t0)
1373     loadi OpGetByIdDirect::Metadata::m_structureID[t5], t1
1374     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdDirectSlow)
1375     loadi OpGetByIdDirect::Metadata::m_offset[t5], t2
1376     bineq JSCell::m_structureID[t3], t1, .opGetByIdDirectSlow
1377     loadPropertyAtVariableOffset(t2, t3, t0, t1)
1378     valueProfile(OpGetByIdDirect, t5, t0, t1)
1379     return(t0, t1)
1380 
1381 .opGetByIdDirectSlow:
1382     callSlowPath(_llint_slow_path_get_by_id_direct)
1383     dispatch()
1384 end)
1385 
1386 
1387 llintOpWithMetadata(op_get_by_id, OpGetById, macro (size, get, dispatch, metadata, return)
1388     metadata(t5, t0)
1389     loadb OpGetById::Metadata::m_modeMetadata.mode[t5], t1
1390     get(m_base, t0)
1391 
1392 .opGetByIdProtoLoad:
1393     bbneq t1, constexpr GetByIdMode::ProtoLoad, .opGetByIdArrayLength
1394     loadi OpGetById::Metadata::m_modeMetadata.protoLoadMode.structureID[t5], t1
1395     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1396     loadis OpGetById::Metadata::m_modeMetadata.protoLoadMode.cachedOffset[t5], t2
1397     bineq JSCell::m_structureID[t3], t1, .opGetByIdSlow
1398     loadp OpGetById::Metadata::m_modeMetadata.protoLoadMode.cachedSlot[t5], t3
1399     loadPropertyAtVariableOffset(t2, t3, t0, t1)
1400     valueProfile(OpGetById, t5, t0, t1)
1401     return(t0, t1)
1402 
1403 .opGetByIdArrayLength:
1404     bbneq t1, constexpr GetByIdMode::ArrayLength, .opGetByIdUnset
1405     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1406     move t3, t2
1407     arrayProfile(OpGetById::Metadata::m_modeMetadata.arrayLengthMode.arrayProfile, t2, t5, t0)
1408     btiz t2, IsArray, .opGetByIdSlow
1409     btiz t2, IndexingShapeMask, .opGetByIdSlow
1410     loadp JSObject::m_butterfly[t3], t0
1411     loadi -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], t0
1412     bilt t0, 0, .opGetByIdSlow
1413     valueProfile(OpGetById, t5, Int32Tag, t0)
1414     return(Int32Tag, t0)
1415 
1416 .opGetByIdUnset:
1417     bbneq t1, constexpr GetByIdMode::Unset, .opGetByIdDefault
1418     loadi OpGetById::Metadata::m_modeMetadata.unsetMode.structureID[t5], t1
1419     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1420     bineq JSCell::m_structureID[t3], t1, .opGetByIdSlow
1421     valueProfile(OpGetById, t5, UndefinedTag, 0)
1422     return(UndefinedTag, 0)
1423 
1424 .opGetByIdDefault:
1425     loadi OpGetById::Metadata::m_modeMetadata.defaultMode.structureID[t5], t1
1426     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1427     loadis OpGetById::Metadata::m_modeMetadata.defaultMode.cachedOffset[t5], t2
1428     bineq JSCell::m_structureID[t3], t1, .opGetByIdSlow
1429     loadPropertyAtVariableOffset(t2, t3, t0, t1)
1430     valueProfile(OpGetById, t5, t0, t1)
1431     return(t0, t1)
1432 
1433 .opGetByIdSlow:
1434     callSlowPath(_llint_slow_path_get_by_id)
1435     dispatch()
1436 
1437 .osrReturnPoint:
1438     getterSetterOSRExitReturnPoint(op_get_by_id, size)
1439     metadata(t2, t3)
1440     valueProfile(OpGetById, t2, r1, r0)
1441     return(r1, r0)
1442 
1443 end)
1444 
1445 
1446 llintOpWithMetadata(op_put_by_id, OpPutById, macro (size, get, dispatch, metadata, return)
1447     writeBarrierOnOperands(size, get, m_base, m_value)
1448     metadata(t5, t3)
1449     get(m_base, t3)
1450     loadConstantOrVariablePayload(size, t3, CellTag, t0, .opPutByIdSlow)
1451     loadi JSCell::m_structureID[t0], t2
1452     bineq t2, OpPutById::Metadata::m_oldStructureID[t5], .opPutByIdSlow
1453 
1454     # At this point, we have:
1455     # t5 -&gt; metadata
1456     # t2 -&gt; currentStructureID
1457     # t0 -&gt; object base
1458     # We will lose currentStructureID in the shenanigans below.
1459 
1460     loadi OpPutById::Metadata::m_newStructureID[t5], t1
1461 
1462     btiz t1, .opPutByIdNotTransition
1463 
1464     # This is the transition case. t1 holds the new Structure*. If we have a chain, we need to
1465     # check it. t0 is the base. We may clobber t1 to use it as scratch.
1466     loadp OpPutById::Metadata::m_structureChain[t5], t3
1467     btpz t3, .opPutByIdTransitionDirect
1468 
1469     loadi OpPutById::Metadata::m_oldStructureID[t5], t2 # Need old structure again.
1470     loadp StructureChain::m_vector[t3], t3
1471     assert(macro (ok) btpnz t3, ok end)
1472 
1473     loadp Structure::m_prototype[t2], t2
1474     btpz t2, .opPutByIdTransitionChainDone
1475 .opPutByIdTransitionChainLoop:
1476     loadp [t3], t1
1477     bineq t1, JSCell::m_structureID[t2], .opPutByIdSlow
1478     addp 4, t3
1479     loadp Structure::m_prototype[t1], t2
1480     btpnz t2, .opPutByIdTransitionChainLoop
1481 
1482 .opPutByIdTransitionChainDone:
1483     loadi OpPutById::Metadata::m_newStructureID[t5], t1
1484 
1485 .opPutByIdTransitionDirect:
1486     storei t1, JSCell::m_structureID[t0]
1487     get(m_value, t1)
1488     loadConstantOrVariable(size, t1, t2, t3)
1489     loadi OpPutById::Metadata::m_offset[t5], t1
1490     storePropertyAtVariableOffset(t1, t0, t2, t3)
1491     writeBarrierOnOperand(size, get, m_base)
1492     dispatch()
1493 
1494 .opPutByIdNotTransition:
1495     # The only thing live right now is t0, which holds the base.
1496     get(m_value, t1)
1497     loadConstantOrVariable(size, t1, t2, t3)
1498     loadi OpPutById::Metadata::m_offset[t5], t1
1499     storePropertyAtVariableOffset(t1, t0, t2, t3)
1500     dispatch()
1501 
1502 .opPutByIdSlow:
1503     callSlowPath(_llint_slow_path_put_by_id)
1504     dispatch()
1505 
1506 .osrReturnPoint:
1507     getterSetterOSRExitReturnPoint(op_put_by_id, size)
1508     dispatch()
1509 
1510 end)
1511 
1512 
1513 llintOpWithMetadata(op_get_by_val, OpGetByVal, macro (size, get, dispatch, metadata, return)
1514     metadata(t5, t2)
1515     get(m_base, t2)
1516     loadConstantOrVariablePayload(size, t2, CellTag, t0, .opGetByValSlow)
1517     move t0, t2
1518     arrayProfile(OpGetByVal::Metadata::m_arrayProfile, t2, t5, t1)
1519     get(m_property, t3)
1520     loadConstantOrVariablePayload(size, t3, Int32Tag, t1, .opGetByValSlow)
1521     loadp JSObject::m_butterfly[t0], t3
1522     andi IndexingShapeMask, t2
1523     bieq t2, Int32Shape, .opGetByValIsContiguous
1524     bineq t2, ContiguousShape, .opGetByValNotContiguous
1525 
1526 .opGetByValIsContiguous:
1527     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t3], .opGetByValSlow
1528     loadi TagOffset[t3, t1, 8], t2
1529     loadi PayloadOffset[t3, t1, 8], t1
1530     jmp .opGetByValDone
1531 
1532 .opGetByValNotContiguous:
1533     bineq t2, DoubleShape, .opGetByValNotDouble
1534     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t3], .opGetByValSlow
1535     loadd [t3, t1, 8], ft0
1536     bdnequn ft0, ft0, .opGetByValSlow
1537     # FIXME: This could be massively optimized.
1538     fd2ii ft0, t1, t2
1539     get(m_dst, t0)
1540     jmp .opGetByValNotEmpty
1541 
1542 .opGetByValNotDouble:
1543     subi ArrayStorageShape, t2
1544     bia t2, SlowPutArrayStorageShape - ArrayStorageShape, .opGetByValSlow
1545     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t3], .opGetByValSlow
1546     loadi ArrayStorage::m_vector + TagOffset[t3, t1, 8], t2
1547     loadi ArrayStorage::m_vector + PayloadOffset[t3, t1, 8], t1
1548 
1549 .opGetByValDone:
1550     get(m_dst, t0)
1551     bieq t2, EmptyValueTag, .opGetByValSlow
1552 .opGetByValNotEmpty:
1553     storei t2, TagOffset[cfr, t0, 8]
1554     storei t1, PayloadOffset[cfr, t0, 8]
1555     valueProfile(OpGetByVal, t5, t2, t1)
1556     dispatch()
1557 
1558 .opGetByValSlow:
1559     callSlowPath(_llint_slow_path_get_by_val)
1560     dispatch()
1561 
1562 .osrReturnPoint:
1563     getterSetterOSRExitReturnPoint(op_get_by_val, size)
1564     metadata(t2, t3)
1565     valueProfile(OpGetByVal, t2, r1, r0)
1566     return(r1, r0)
1567 
1568 end)
1569 
1570 
1571 macro putByValOp(opcodeName, opcodeStruct, osrExitPoint)
1572     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)
1573         macro contiguousPutByVal(storeCallback)
1574             biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], .outOfBounds
1575         .storeResult:
1576             get(m_value, t2)
1577             storeCallback(t2, t1, t0, t3)
1578             dispatch()
1579 
1580         .outOfBounds:
1581             biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t0], .opPutByValOutOfBounds
1582             storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_mayStoreToHole[t5]
1583             addi 1, t3, t2
1584             storei t2, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0]
1585             jmp .storeResult
1586         end
1587 
1588         writeBarrierOnOperands(size, get, m_base, m_value)
1589         metadata(t5, t0)
1590         get(m_base, t0)
1591         loadConstantOrVariablePayload(size, t0, CellTag, t1, .opPutByValSlow)
1592         move t1, t2
1593         arrayProfile(%opcodeStruct%::Metadata::m_arrayProfile, t2, t5, t0)
1594         get(m_property, t0)
1595         loadConstantOrVariablePayload(size, t0, Int32Tag, t3, .opPutByValSlow)
1596         loadp JSObject::m_butterfly[t1], t0
1597         btinz t2, CopyOnWrite, .opPutByValSlow
1598         andi IndexingShapeMask, t2
1599         bineq t2, Int32Shape, .opPutByValNotInt32
1600         contiguousPutByVal(
1601             macro (operand, scratch, base, index)
1602                 loadConstantOrVariablePayload(size, operand, Int32Tag, scratch, .opPutByValSlow)
1603                 storei Int32Tag, TagOffset[base, index, 8]
1604                 storei scratch, PayloadOffset[base, index, 8]
1605             end)
1606 
1607     .opPutByValNotInt32:
1608         bineq t2, DoubleShape, .opPutByValNotDouble
1609         contiguousPutByVal(
1610             macro (operand, scratch, base, index)
1611                 const tag = scratch
1612                 const payload = operand
1613                 loadConstantOrVariable2Reg(size, operand, tag, payload)
1614                 bineq tag, Int32Tag, .notInt
1615                 ci2ds payload, ft0
1616                 jmp .ready
1617             .notInt:
1618                 fii2d payload, tag, ft0
1619                 bdnequn ft0, ft0, .opPutByValSlow
1620             .ready:
1621                 stored ft0, [base, index, 8]
1622             end)
1623 
1624     .opPutByValNotDouble:
1625         bineq t2, ContiguousShape, .opPutByValNotContiguous
1626         contiguousPutByVal(
1627             macro (operand, scratch, base, index)
1628                 const tag = scratch
1629                 const payload = operand
1630                 loadConstantOrVariable2Reg(size, operand, tag, payload)
1631                 storei tag, TagOffset[base, index, 8]
1632                 storei payload, PayloadOffset[base, index, 8]
1633             end)
1634 
1635     .opPutByValNotContiguous:
1636         bineq t2, ArrayStorageShape, .opPutByValSlow
1637         biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t0], .opPutByValOutOfBounds
1638         bieq ArrayStorage::m_vector + TagOffset[t0, t3, 8], EmptyValueTag, .opPutByValArrayStorageEmpty
1639     .opPutByValArrayStorageStoreResult:
1640         get(m_value, t2)
1641         loadConstantOrVariable2Reg(size, t2, t1, t2)
1642         storei t1, ArrayStorage::m_vector + TagOffset[t0, t3, 8]
1643         storei t2, ArrayStorage::m_vector + PayloadOffset[t0, t3, 8]
1644         dispatch()
1645 
1646     .opPutByValArrayStorageEmpty:
1647         storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_mayStoreToHole[t5]
1648         addi 1, ArrayStorage::m_numValuesInVector[t0]
1649         bib t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], .opPutByValArrayStorageStoreResult
1650         addi 1, t3, t1
1651         storei t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0]
1652         jmp .opPutByValArrayStorageStoreResult
1653 
1654     .opPutByValOutOfBounds:
1655         storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_outOfBounds[t5]
1656     .opPutByValSlow:
1657         callSlowPath(_llint_slow_path_%opcodeName%)
1658         dispatch()
1659 
1660     .osrExitPoint:
1661         osrExitPoint(size, dispatch)
1662     end)
1663 end
1664 
1665 
1666 putByValOp(put_by_val, OpPutByVal, macro (size, dispatch)
1667 .osrReturnPoint:
1668     getterSetterOSRExitReturnPoint(op_put_by_val, size)
1669     dispatch()
1670 end)
1671 
1672 putByValOp(put_by_val_direct, OpPutByValDirect, macro (a, b) end)
1673 
1674 
1675 macro llintJumpTrueOrFalseOp(opcodeName, opcodeStruct, conditionOp)
1676     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1677         get(m_condition, t1)
1678         loadConstantOrVariablePayload(size, t1, BooleanTag, t0, .slow)
1679         conditionOp(t0, .target)
1680         dispatch()
1681 
1682     .target:
1683         jump(m_targetLabel)
1684 
1685     .slow:
1686         callSlowPath(_llint_slow_path_%opcodeName%)
1687         nextInstruction()
1688     end)
1689 end
1690 
1691 
1692 macro equalNullJumpOp(opcodeName, opcodeStruct, cellHandler, immediateHandler)
1693     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1694         get(m_value, t0)
1695         assertNotConstant(size, t0)
1696         loadi TagOffset[cfr, t0, 8], t1
1697         loadi PayloadOffset[cfr, t0, 8], t0
1698         bineq t1, CellTag, .immediate
1699         loadi JSCell::m_structureID[t0], t2
1700         cellHandler(t2, JSCell::m_flags[t0], .target)
1701         dispatch()
1702 
1703     .target:
1704         jump(m_targetLabel)
1705 
1706     .immediate:
1707         ori 1, t1
1708         immediateHandler(t1, .target)
1709         dispatch()
1710     end)
1711 end
1712 
1713 equalNullJumpOp(jeq_null, OpJeqNull,
1714     macro (structure, value, target)
1715         btbz value, MasqueradesAsUndefined, .opJeqNullNotMasqueradesAsUndefined
1716         loadp CodeBlock[cfr], t0
1717         loadp CodeBlock::m_globalObject[t0], t0
1718         bpeq Structure::m_globalObject[structure], t0, target
1719     .opJeqNullNotMasqueradesAsUndefined:
1720     end,
1721     macro (value, target) bieq value, NullTag, target end)
1722     
1723 
1724 equalNullJumpOp(jneq_null, OpJneqNull,
1725     macro (structure, value, target)
1726         btbz value, MasqueradesAsUndefined, target
1727         loadp CodeBlock[cfr], t0
1728         loadp CodeBlock::m_globalObject[t0], t0
1729         bpneq Structure::m_globalObject[structure], t0, target
1730     end,
1731     macro (value, target) bineq value, NullTag, target end)
1732 
1733 macro undefinedOrNullJumpOp(opcodeName, opcodeStruct, fn)
1734     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1735         get(m_value, t1)
1736         loadConstantOrVariableTag(size, t1, t0)
1737         ori 1, t0
1738         fn(t0, .target)
1739         dispatch()
1740 
1741     .target:
1742         jump(m_targetLabel)
1743     end)
1744 end
1745 
1746 undefinedOrNullJumpOp(jundefined_or_null, OpJundefinedOrNull,
1747     macro (value, target) bieq value, NullTag, target end)
1748 
1749 undefinedOrNullJumpOp(jnundefined_or_null, OpJnundefinedOrNull,
1750     macro (value, target) bineq value, NullTag, target end)
1751 
1752 llintOpWithMetadata(op_jneq_ptr, OpJneqPtr, macro (size, get, dispatch, metadata, return)
1753     get(m_value, t0)
1754     get(m_specialPointer, t1)
1755     loadConstant(size, t1, t3, t2)
1756     bineq TagOffset[cfr, t0, 8], CellTag, .opJneqPtrBranch
1757     bpeq PayloadOffset[cfr, t0, 8], t2, .opJneqPtrFallThrough
1758 .opJneqPtrBranch:
1759     metadata(t5, t2)
1760     storeb 1, OpJneqPtr::Metadata::m_hasJumped[t5]
1761     get(m_targetLabel, t0)
1762     jumpImpl(dispatchIndirect, t0)
1763 .opJneqPtrFallThrough:
1764     dispatch()
1765 end)
1766 
1767 
1768 macro compareUnsignedJumpOp(opcodeName, opcodeStruct, integerCompare)
1769     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1770         get(m_lhs, t2)
1771         get(m_rhs, t3)
1772         loadConstantOrVariable(size, t2, t0, t1)
1773         loadConstantOrVariable2Reg(size, t3, t2, t3)
1774         integerCompare(t1, t3, .jumpTarget)
1775         dispatch()
1776 
1777     .jumpTarget:
1778         jump(m_targetLabel)
1779     end)
1780 end
1781 
1782 
1783 macro compareUnsignedOp(opcodeName, opcodeStruct, integerCompareAndSet)
1784     llintOpWithReturn(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
1785         get(m_rhs, t2)
1786         get(m_lhs, t0)
1787         loadConstantOrVariable(size, t2, t3, t1)
1788         loadConstantOrVariable2Reg(size, t0, t2, t0)
1789         integerCompareAndSet(t0, t1, t0)
1790         return(BooleanTag, t0)
1791     end)
1792 end
1793 
1794 
1795 macro compareJumpOp(opcodeName, opcodeStruct, integerCompare, doubleCompare)
1796     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1797         get(m_lhs, t2)
1798         get(m_rhs, t3)
1799         loadConstantOrVariable(size, t2, t0, t1)
1800         loadConstantOrVariable2Reg(size, t3, t2, t3)
1801         bineq t0, Int32Tag, .op1NotInt
1802         bineq t2, Int32Tag, .op2NotInt
1803         integerCompare(t1, t3, .jumpTarget)
1804         dispatch()
1805 
1806     .op1NotInt:
1807         bia t0, LowestTag, .slow
1808         bib t2, LowestTag, .op1NotIntOp2Double
1809         bineq t2, Int32Tag, .slow
1810         ci2ds t3, ft1
1811         jmp .op1NotIntReady
1812     .op1NotIntOp2Double:
1813         fii2d t3, t2, ft1
1814     .op1NotIntReady:
1815         fii2d t1, t0, ft0
1816         doubleCompare(ft0, ft1, .jumpTarget)
1817         dispatch()
1818 
1819     .op2NotInt:
1820         ci2ds t1, ft0
1821         bia t2, LowestTag, .slow
1822         fii2d t3, t2, ft1
1823         doubleCompare(ft0, ft1, .jumpTarget)
1824         dispatch()
1825 
1826     .jumpTarget:
1827         jump(m_targetLabel)
1828 
1829     .slow:
1830         callSlowPath(_llint_slow_path_%opcodeName%)
1831         nextInstruction()
1832     end)
1833 end
1834 
1835 
1836 llintOpWithJump(op_switch_imm, OpSwitchImm, macro (size, get, jump, dispatch)
1837     get(m_scrutinee, t2)
1838     getu(size, OpSwitchImm, m_tableIndex, t3)
1839     loadConstantOrVariable(size, t2, t1, t0)
1840     loadp CodeBlock[cfr], t2
1841     loadp CodeBlock::m_rareData[t2], t2
1842     muli sizeof SimpleJumpTable, t3
1843     loadp CodeBlock::RareData::m_switchJumpTables + VectorBufferOffset[t2], t2
1844     addp t3, t2
1845     bineq t1, Int32Tag, .opSwitchImmNotInt
1846     subi SimpleJumpTable::min[t2], t0
1847     biaeq t0, SimpleJumpTable::branchOffsets + VectorSizeOffset[t2], .opSwitchImmFallThrough
1848     loadp SimpleJumpTable::branchOffsets + VectorBufferOffset[t2], t3
1849     loadi [t3, t0, 4], t1
1850     btiz t1, .opSwitchImmFallThrough
1851     dispatchIndirect(t1)
1852 
1853 .opSwitchImmNotInt:
1854     bib t1, LowestTag, .opSwitchImmSlow  # Go to slow path if it&#39;s a double.
1855 .opSwitchImmFallThrough:
1856     jump(m_defaultOffset)
1857 
1858 .opSwitchImmSlow:
1859     callSlowPath(_llint_slow_path_switch_imm)
1860     nextInstruction()
1861 end)
1862 
1863 
1864 llintOpWithJump(op_switch_char, OpSwitchChar, macro (size, get, jump, dispatch)
1865     get(m_scrutinee, t2)
1866     getu(size, OpSwitchChar, m_tableIndex, t3)
1867     loadConstantOrVariable(size, t2, t1, t0)
1868     loadp CodeBlock[cfr], t2
1869     loadp CodeBlock::m_rareData[t2], t2
1870     muli sizeof SimpleJumpTable, t3
1871     loadp CodeBlock::RareData::m_switchJumpTables + VectorBufferOffset[t2], t2
1872     addp t3, t2
1873     bineq t1, CellTag, .opSwitchCharFallThrough
1874     bbneq JSCell::m_type[t0], StringType, .opSwitchCharFallThrough
1875     loadp JSString::m_fiber[t0], t1
1876     btpnz t1, isRopeInPointer, .opSwitchOnRope
1877     bineq StringImpl::m_length[t1], 1, .opSwitchCharFallThrough
1878     loadp StringImpl::m_data8[t1], t0
1879     btinz StringImpl::m_hashAndFlags[t1], HashFlags8BitBuffer, .opSwitchChar8Bit
1880     loadh [t0], t0
1881     jmp .opSwitchCharReady
1882 .opSwitchChar8Bit:
1883     loadb [t0], t0
1884 .opSwitchCharReady:
1885     subi SimpleJumpTable::min[t2], t0
1886     biaeq t0, SimpleJumpTable::branchOffsets + VectorSizeOffset[t2], .opSwitchCharFallThrough
1887     loadp SimpleJumpTable::branchOffsets + VectorBufferOffset[t2], t2
1888     loadi [t2, t0, 4], t1
1889     btiz t1, .opSwitchCharFallThrough
1890     dispatchIndirect(t1)
1891 
1892 .opSwitchCharFallThrough:
1893     jump(m_defaultOffset)
1894 
1895 .opSwitchOnRope:
1896     bineq JSRopeString::m_compactFibers + JSRopeString::CompactFibers::m_length[t0], 1, .opSwitchCharFallThrough
1897 
1898 .opSwitchOnRopeChar:
1899     callSlowPath(_llint_slow_path_switch_char)
1900     nextInstruction()
1901 end)
1902 
1903 
1904 macro arrayProfileForCall(opcodeStruct, getu)
1905     getu(m_argv, t3)
1906     negi t3
1907     bineq ThisArgumentOffset + TagOffset[cfr, t3, 8], CellTag, .done
1908     loadi ThisArgumentOffset + PayloadOffset[cfr, t3, 8], t0
1909     loadi JSCell::m_structureID[t0], t0
1910     storei t0, %opcodeStruct%::Metadata::m_callLinkInfo.m_arrayProfile.m_lastSeenStructureID[t5]
1911 .done:
1912 end
1913 
1914 macro commonCallOp(opcodeName, slowPath, opcodeStruct, prepareCall, prologue)
1915     llintOpWithMetadata(opcodeName, opcodeStruct, macro (size, get, dispatch, metadata, return)
1916         metadata(t5, t0)
1917 
1918         prologue(macro (fieldName, dst)
1919             getu(size, opcodeStruct, fieldName, dst)
1920         end, metadata)
1921 
1922         get(m_callee, t0)
1923         loadp %opcodeStruct%::Metadata::m_callLinkInfo.m_calleeOrLastSeenCalleeWithLinkBit[t5], t2
1924         loadConstantOrVariablePayload(size, t0, CellTag, t3, .opCallSlow)
1925         bineq t3, t2, .opCallSlow
1926         getu(size, opcodeStruct, m_argv, t3)
1927         lshifti 3, t3
1928         negi t3
1929         addp cfr, t3  # t3 contains the new value of cfr
1930         storei t2, Callee + PayloadOffset[t3]
1931         getu(size, opcodeStruct, m_argc, t2)
1932         storei PC, ArgumentCountIncludingThis + TagOffset[cfr]
1933         storei t2, ArgumentCountIncludingThis + PayloadOffset[t3]
1934         storei CellTag, Callee + TagOffset[t3]
1935         move t3, sp
1936         prepareCall(%opcodeStruct%::Metadata::m_callLinkInfo.m_machineCodeTarget[t5], t2, t3, t4, JSEntryPtrTag)
1937         callTargetFunction(opcodeName, size, opcodeStruct, dispatch, %opcodeStruct%::Metadata::m_callLinkInfo.m_machineCodeTarget[t5], JSEntryPtrTag)
1938 
1939     .opCallSlow:
1940         slowPathForCall(opcodeName, size, opcodeStruct, dispatch, slowPath, prepareCall)
1941     end)
1942 end
1943 
1944 llintOp(op_ret, OpRet, macro (size, get, dispatch)
1945     checkSwitchToJITForEpilogue()
1946     get(m_value, t2)
1947     loadConstantOrVariable(size, t2, t1, t0)
1948     doReturn()
1949 end)
1950 
1951 
1952 llintOpWithReturn(op_to_primitive, OpToPrimitive, macro (size, get, dispatch, return)
1953     get(m_src, t2)
1954     loadConstantOrVariable(size, t2, t1, t0)
1955     bineq t1, CellTag, .opToPrimitiveIsImm
1956     bbaeq JSCell::m_type[t0], ObjectType, .opToPrimitiveSlowCase
1957 .opToPrimitiveIsImm:
1958     return(t1, t0)
1959 
1960 .opToPrimitiveSlowCase:
1961     callSlowPath(_slow_path_to_primitive)
1962     dispatch()
1963 end)
1964 
1965 
1966 llintOpWithReturn(op_to_property_key, OpToPropertyKey, macro (size, get, dispatch, return)
1967     get(m_src, t2)
1968     loadConstantOrVariable(size, t2, t1, t0)
1969     bineq t1, CellTag, .opToPropertyKeySlow
1970     bbeq JSCell::m_type[t0], SymbolType, .done
1971     bbneq JSCell::m_type[t0], StringType, .opToPropertyKeySlow
1972 
1973 .done:
1974     return(t1, t0)
1975 
1976 .opToPropertyKeySlow:
1977     callSlowPath(_slow_path_to_property_key)
1978     dispatch()
1979 end)
1980 
1981 
1982 commonOp(llint_op_catch, macro() end, macro (size)
1983     # This is where we end up from the JIT&#39;s throw trampoline (because the
1984     # machine code return address will be set to _llint_op_catch), and from
1985     # the interpreter&#39;s throw trampoline (see _llint_throw_trampoline).
1986     # The throwing code must have known that we were throwing to the interpreter,
1987     # and have set VM::targetInterpreterPCForThrow.
1988     loadp Callee + PayloadOffset[cfr], t3
1989     convertCalleeToVM(t3)
1990     restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(t3, t0)
1991     loadp VM::callFrameForCatch[t3], cfr
1992     storep 0, VM::callFrameForCatch[t3]
1993     restoreStackPointerAfterCall()
1994 
1995     # restore metadataTable since we don&#39;t restore callee saves for CLoop during unwinding
1996     loadp CodeBlock[cfr], t1
1997     loadp CodeBlock::m_metadata[t1], metadataTable
1998     loadp CodeBlock::m_instructionsRawPointer[t1], PB
1999 
2000     loadp VM::targetInterpreterPCForThrow[t3], PC
2001     subp PB, PC
2002 
2003     callSlowPath(_llint_slow_path_check_if_exception_is_uncatchable_and_notify_profiler)
2004     bpeq r1, 0, .isCatchableException
2005     jmp _llint_throw_from_slow_path_trampoline
2006 
2007 .isCatchableException:
2008     loadp CodeBlock[cfr], t3
2009     loadp CodeBlock::m_vm[t3], t3
2010 
2011     loadp VM::m_exception[t3], t0
2012     storep 0, VM::m_exception[t3]
2013     get(size, OpCatch, m_exception, t2)
2014     storei t0, PayloadOffset[cfr, t2, 8]
2015     storei CellTag, TagOffset[cfr, t2, 8]
2016 
2017     loadi Exception::m_value + TagOffset[t0], t1
2018     loadi Exception::m_value + PayloadOffset[t0], t0
2019     get(size, OpCatch, m_thrownValue, t2)
2020     storei t0, PayloadOffset[cfr, t2, 8]
2021     storei t1, TagOffset[cfr, t2, 8]
2022 
2023     traceExecution()  # This needs to be here because we don&#39;t want to clobber t0, t1, t2, t3 above.
2024 
2025     callSlowPath(_llint_slow_path_profile_catch)
2026 
2027     dispatchOp(size, op_catch)
2028 end)
2029 
2030 llintOp(op_end, OpEnd, macro (size, get, dispatch)
2031     checkSwitchToJITForEpilogue()
2032     get(m_value, t0)
2033     assertNotConstant(size, t0)
2034     loadi TagOffset[cfr, t0, 8], t1
2035     loadi PayloadOffset[cfr, t0, 8], t0
2036     doReturn()
2037 end)
2038 
2039 
2040 op(llint_throw_from_slow_path_trampoline, macro()
2041     loadp Callee[cfr], t1
2042     convertCalleeToVM(t1)
2043     copyCalleeSavesToVMEntryFrameCalleeSavesBuffer(t1, t2)
2044 
2045     callSlowPath(_llint_slow_path_handle_exception)
2046 
2047     # When throwing from the interpreter (i.e. throwing from LLIntSlowPaths), so
2048     # the throw target is not necessarily interpreted code, we come to here.
2049     # This essentially emulates the JIT&#39;s throwing protocol.
2050     loadp Callee[cfr], t1
2051     convertCalleeToVM(t1)
2052     jmp VM::targetMachinePCForThrow[t1]
2053 end)
2054 
2055 
2056 op(llint_throw_during_call_trampoline, macro()
2057     preserveReturnAddressAfterCall(t2)
2058     jmp _llint_throw_from_slow_path_trampoline
2059 end)
2060 
2061 
2062 macro nativeCallTrampoline(executableOffsetToFunction)
2063     functionPrologue()
2064     storep 0, CodeBlock[cfr]
2065 
2066     if X86 or X86_WIN
2067         subp 8, sp # align stack pointer
2068         storep cfr, [sp]
2069     elsif MIPS
2070         # calling convention says to save stack space for 4 first registers in
2071         # all cases. To match our 16-byte alignment, that means we need to
2072         # take 24 bytes
2073         subp 24, sp
2074     else
2075         subp 8, sp # align stack pointer
2076     end
2077 
2078     loadp Callee + PayloadOffset[cfr], a0
2079     loadp JSFunction::m_executableOrRareData[a0], a2
2080     btpz a2, (constexpr JSFunction::rareDataTag), .isExecutable
2081     loadp (FunctionRareData::m_executable - (constexpr JSFunction::rareDataTag))[a2], a2
2082 .isExecutable:
2083     loadp JSFunction::m_scope[a0], a0
2084     loadp JSGlobalObject::m_vm[a0], a1
2085     storep cfr, VM::topCallFrame[a1]
2086     move cfr, a1
2087 
2088     checkStackPointerAlignment(t3, 0xdead0001)
2089     if C_LOOP or C_LOOP_WIN
2090         cloopCallNative executableOffsetToFunction[a2]
2091     else
2092         call executableOffsetToFunction[a2]
2093     end
2094 
2095     loadp Callee + PayloadOffset[cfr], t3
2096     loadp JSFunction::m_scope[t3], t3
2097     loadp JSGlobalObject::m_vm[t3], t3
2098 
2099     if MIPS
2100         addp 24, sp
2101     else
2102         addp 8, sp
2103     end
2104 
2105     btpnz VM::m_exception[t3], .handleException
2106 
2107     functionEpilogue()
2108     ret
2109 
2110 .handleException:
2111     if X86 or X86_WIN
2112         subp 8, sp # align stack pointer
2113     end
2114     storep cfr, VM::topCallFrame[t3]
2115     jmp _llint_throw_from_slow_path_trampoline
2116 end
2117 
2118 
2119 macro internalFunctionCallTrampoline(offsetOfFunction)
2120     functionPrologue()
2121     storep 0, CodeBlock[cfr]
2122 
2123     // Callee is still in t1 for code below
2124     if X86 or X86_WIN
2125         subp 8, sp # align stack pointer
2126         storep cfr, [sp]
2127     else
2128         subp 8, sp # align stack pointer
2129     end
2130 
2131     loadp Callee + PayloadOffset[cfr], a2
2132     loadp InternalFunction::m_globalObject[a2], a0
2133     loadp JSGlobalObject::m_vm[a0], a1
2134     storep cfr, VM::topCallFrame[a1]
2135     move cfr, a1
2136 
2137     checkStackPointerAlignment(t3, 0xdead0001)
2138     if C_LOOP or C_LOOP_WIN
2139         cloopCallNative offsetOfFunction[a2]
2140     else
2141         call offsetOfFunction[a2]
2142     end
2143 
2144     loadp Callee + PayloadOffset[cfr], t3
2145     loadp InternalFunction::m_globalObject[t3], t3
2146     loadp JSGlobalObject::m_vm[t3], t3
2147 
2148     addp 8, sp
2149 
2150     btpnz VM::m_exception[t3], .handleException
2151 
2152     functionEpilogue()
2153     ret
2154 
2155 .handleException:
2156     if X86 or X86_WIN
2157         subp 8, sp # align stack pointer
2158     end
2159     storep cfr, VM::topCallFrame[t3]
2160     jmp _llint_throw_from_slow_path_trampoline
2161 end
2162 
2163 
2164 macro varInjectionCheck(slowPath)
2165     loadp CodeBlock[cfr], t0
2166     loadp CodeBlock::m_globalObject[t0], t0
2167     loadp JSGlobalObject::m_varInjectionWatchpoint[t0], t0
2168     bbeq WatchpointSet::m_state[t0], IsInvalidated, slowPath
2169 end
2170 
2171 
2172 llintOpWithMetadata(op_resolve_scope, OpResolveScope, macro (size, get, dispatch, metadata, return)
2173 
2174     macro getConstantScope(dst)
2175         loadp OpResolveScope::Metadata::m_constantScope[t5], dst
2176     end
2177 
2178     macro returnConstantScope()
2179         getConstantScope(t0)
2180         return(CellTag, t0)
2181     end
2182 
2183     macro globalLexicalBindingEpochCheck(slowPath, globalObject, scratch)
2184         loadi OpResolveScope::Metadata::m_globalLexicalBindingEpoch[t5], scratch
2185         bineq JSGlobalObject::m_globalLexicalBindingEpoch[globalObject], scratch, slowPath
2186     end
2187 
2188     macro resolveScope()
2189         loadi OpResolveScope::Metadata::m_localScopeDepth[t5], t2
2190         get(m_scope, t0)
2191         loadp PayloadOffset[cfr, t0, 8], t0
2192         btiz t2, .resolveScopeLoopEnd
2193 
2194     .resolveScopeLoop:
2195         loadp JSScope::m_next[t0], t0
2196         subi 1, t2
2197         btinz t2, .resolveScopeLoop
2198 
2199     .resolveScopeLoopEnd:
2200         return(CellTag, t0)
2201     end
2202 
2203     metadata(t5, t0)
2204     loadi OpResolveScope::Metadata::m_resolveType[t5], t0
2205 
2206 #rGlobalProperty:
2207     bineq t0, GlobalProperty, .rGlobalVar
2208     getConstantScope(t0)
2209     globalLexicalBindingEpochCheck(.rDynamic, t0, t2)
2210     return(CellTag, t0)
2211 
2212 .rGlobalVar:
2213     bineq t0, GlobalVar, .rGlobalLexicalVar
2214     returnConstantScope()
2215 
2216 .rGlobalLexicalVar:
2217     bineq t0, GlobalLexicalVar, .rClosureVar
2218     returnConstantScope()
2219 
2220 .rClosureVar:
2221     bineq t0, ClosureVar, .rModuleVar
2222     resolveScope()
2223 
2224 .rModuleVar:
2225     bineq t0, ModuleVar, .rGlobalPropertyWithVarInjectionChecks
2226     returnConstantScope()
2227 
2228 .rGlobalPropertyWithVarInjectionChecks:
2229     bineq t0, GlobalPropertyWithVarInjectionChecks, .rGlobalVarWithVarInjectionChecks
2230     varInjectionCheck(.rDynamic)
2231     getConstantScope(t0)
2232     globalLexicalBindingEpochCheck(.rDynamic, t0, t2)
2233     return(CellTag, t0)
2234 
2235 .rGlobalVarWithVarInjectionChecks:
2236     bineq t0, GlobalVarWithVarInjectionChecks, .rGlobalLexicalVarWithVarInjectionChecks
2237     varInjectionCheck(.rDynamic)
2238     returnConstantScope()
2239 
2240 .rGlobalLexicalVarWithVarInjectionChecks:
2241     bineq t0, GlobalLexicalVarWithVarInjectionChecks, .rClosureVarWithVarInjectionChecks
2242     varInjectionCheck(.rDynamic)
2243     returnConstantScope()
2244 
2245 .rClosureVarWithVarInjectionChecks:
2246     bineq t0, ClosureVarWithVarInjectionChecks, .rDynamic
2247     varInjectionCheck(.rDynamic)
2248     resolveScope()
2249 
2250 .rDynamic:
2251     callSlowPath(_slow_path_resolve_scope)
2252     dispatch()
2253 end)
2254 
2255 
2256 macro loadWithStructureCheck(opcodeStruct, get, operand, slowPath)
2257     get(m_scope, t0)
2258     loadp PayloadOffset[cfr, t0, 8], t0
2259     loadp %opcodeStruct%::Metadata::m_structure[t5], t1
2260     bineq JSCell::m_structureID[t0], t1, slowPath
2261 end
2262 
2263 
2264 llintOpWithMetadata(op_get_from_scope, OpGetFromScope, macro (size, get, dispatch, metadata, return)
2265     macro getProperty()
2266         loadp OpGetFromScope::Metadata::m_operand[t5], t3
2267         loadPropertyAtVariableOffset(t3, t0, t1, t2)
2268         valueProfile(OpGetFromScope, t5, t1, t2)
2269         return(t1, t2)
2270     end
2271 
2272     macro getGlobalVar(tdzCheckIfNecessary)
2273         loadp OpGetFromScope::Metadata::m_operand[t5], t0
2274         loadp TagOffset[t0], t1
2275         loadp PayloadOffset[t0], t2
2276         tdzCheckIfNecessary(t1)
2277         valueProfile(OpGetFromScope, t5, t1, t2)
2278         return(t1, t2)
2279     end
2280 
2281     macro getClosureVar()
2282         loadp OpGetFromScope::Metadata::m_operand[t5], t3
2283         loadp JSLexicalEnvironment_variables + TagOffset[t0, t3, 8], t1
2284         loadp JSLexicalEnvironment_variables + PayloadOffset[t0, t3, 8], t2
2285         valueProfile(OpGetFromScope, t5, t1, t2)
2286         return(t1, t2)
2287     end
2288 
2289     metadata(t5, t0)
2290     loadi OpGetFromScope::Metadata::m_getPutInfo + GetPutInfo::m_operand[t5], t0
2291     andi ResolveTypeMask, t0
2292 
2293 #gGlobalProperty:
2294     bineq t0, GlobalProperty, .gGlobalVar
2295     loadWithStructureCheck(OpGetFromScope, get, scope, .gDynamic)
2296     getProperty()
2297 
2298 .gGlobalVar:
2299     bineq t0, GlobalVar, .gGlobalLexicalVar
2300     getGlobalVar(macro(t) end)
2301 
2302 .gGlobalLexicalVar:
2303     bineq t0, GlobalLexicalVar, .gClosureVar
2304     getGlobalVar(
2305         macro(tag)
2306             bieq tag, EmptyValueTag, .gDynamic
2307         end)
2308 
2309 .gClosureVar:
2310     bineq t0, ClosureVar, .gGlobalPropertyWithVarInjectionChecks
2311     loadVariable(get, m_scope, t2, t1, t0)
2312     getClosureVar()
2313 
2314 .gGlobalPropertyWithVarInjectionChecks:
2315     bineq t0, GlobalPropertyWithVarInjectionChecks, .gGlobalVarWithVarInjectionChecks
2316     loadWithStructureCheck(OpGetFromScope, get, scope, .gDynamic)
2317     getProperty()
2318 
2319 .gGlobalVarWithVarInjectionChecks:
2320     bineq t0, GlobalVarWithVarInjectionChecks, .gGlobalLexicalVarWithVarInjectionChecks
2321     varInjectionCheck(.gDynamic)
2322     getGlobalVar(macro(t) end)
2323 
2324 .gGlobalLexicalVarWithVarInjectionChecks:
2325     bineq t0, GlobalLexicalVarWithVarInjectionChecks, .gClosureVarWithVarInjectionChecks
2326     varInjectionCheck(.gDynamic)
2327     getGlobalVar(
2328         macro(tag)
2329             bieq tag, EmptyValueTag, .gDynamic
2330         end)
2331 
2332 .gClosureVarWithVarInjectionChecks:
2333     bineq t0, ClosureVarWithVarInjectionChecks, .gDynamic
2334     varInjectionCheck(.gDynamic)
2335     loadVariable(get, m_scope, t2, t1, t0)
2336     getClosureVar()
2337 
2338 .gDynamic:
2339     callSlowPath(_llint_slow_path_get_from_scope)
2340     dispatch()
2341 end)
2342 
2343 
2344 llintOpWithMetadata(op_put_to_scope, OpPutToScope, macro (size, get, dispatch, metadata, return)
2345     macro putProperty()
2346         get(m_value, t1)
2347         loadConstantOrVariable(size, t1, t2, t3)
2348         loadp OpPutToScope::Metadata::m_operand[t5], t1
2349         storePropertyAtVariableOffset(t1, t0, t2, t3)
2350     end
2351 
2352     macro putGlobalVariable()
2353         get(m_value, t0)
2354         loadConstantOrVariable(size, t0, t1, t2)
2355         loadp OpPutToScope::Metadata::m_watchpointSet[t5], t3
2356         btpz t3, .noVariableWatchpointSet
2357         notifyWrite(t3, .pDynamic)
2358     .noVariableWatchpointSet:
2359         loadp OpPutToScope::Metadata::m_operand[t5], t0
2360         storei t1, TagOffset[t0]
2361         storei t2, PayloadOffset[t0]
2362     end
2363 
2364     macro putClosureVar()
2365         get(m_value, t1)
2366         loadConstantOrVariable(size, t1, t2, t3)
2367         loadp OpPutToScope::Metadata::m_operand[t5], t1
2368         storei t2, JSLexicalEnvironment_variables + TagOffset[t0, t1, 8]
2369         storei t3, JSLexicalEnvironment_variables + PayloadOffset[t0, t1, 8]
2370     end
2371 
2372     macro putLocalClosureVar()
2373         get(m_value, t1)
2374         loadConstantOrVariable(size, t1, t2, t3)
2375         loadp OpPutToScope::Metadata::m_watchpointSet[t5], t1
2376         btpz t1, .noVariableWatchpointSet
2377         notifyWrite(t1, .pDynamic)
2378     .noVariableWatchpointSet:
2379         loadp OpPutToScope::Metadata::m_operand[t5], t1
2380         storei t2, JSLexicalEnvironment_variables + TagOffset[t0, t1, 8]
2381         storei t3, JSLexicalEnvironment_variables + PayloadOffset[t0, t1, 8]
2382     end
2383 
2384     macro checkTDZInGlobalPutToScopeIfNecessary()
2385         loadi OpPutToScope::Metadata::m_getPutInfo + GetPutInfo::m_operand[t5], t0
2386         andi InitializationModeMask, t0
2387         rshifti InitializationModeShift, t0
2388         bineq t0, NotInitialization, .noNeedForTDZCheck
2389         loadp OpPutToScope::Metadata::m_operand[t5], t0
2390         loadi TagOffset[t0], t0
2391         bieq t0, EmptyValueTag, .pDynamic
2392     .noNeedForTDZCheck:
2393     end
2394 
2395     metadata(t5, t0)
2396     loadi OpPutToScope::Metadata::m_getPutInfo + GetPutInfo::m_operand[t5], t0
2397     andi ResolveTypeMask, t0
2398 
2399 #pLocalClosureVar:
2400     bineq t0, LocalClosureVar, .pGlobalProperty
2401     loadVariable(get, m_scope, t2, t1, t0)
2402     putLocalClosureVar()
2403     writeBarrierOnOperands(size, get, m_scope, m_value)
2404     dispatch()
2405 
2406 .pGlobalProperty:
2407     bineq t0, GlobalProperty, .pGlobalVar
2408     loadWithStructureCheck(OpPutToScope, get, scope, .pDynamic)
2409     putProperty()
2410     writeBarrierOnOperands(size, get, m_scope, m_value)
2411     dispatch()
2412 
2413 .pGlobalVar:
2414     bineq t0, GlobalVar, .pGlobalLexicalVar
2415     putGlobalVariable()
2416     writeBarrierOnGlobalObject(size, get, m_value)
2417     dispatch()
2418 
2419 .pGlobalLexicalVar:
2420     bineq t0, GlobalLexicalVar, .pClosureVar
2421     checkTDZInGlobalPutToScopeIfNecessary()
2422     putGlobalVariable()
2423     writeBarrierOnGlobalLexicalEnvironment(size, get, m_value)
2424     dispatch()
2425 
2426 .pClosureVar:
2427     bineq t0, ClosureVar, .pGlobalPropertyWithVarInjectionChecks
2428     loadVariable(get, m_scope, t2, t1, t0)
2429     putClosureVar()
2430     writeBarrierOnOperands(size, get, m_scope, m_value)
2431     dispatch()
2432 
2433 .pGlobalPropertyWithVarInjectionChecks:
2434     bineq t0, GlobalPropertyWithVarInjectionChecks, .pGlobalVarWithVarInjectionChecks
2435     loadWithStructureCheck(OpPutToScope, get, scope, .pDynamic)
2436     putProperty()
2437     writeBarrierOnOperands(size, get, m_scope, m_value)
2438     dispatch()
2439 
2440 .pGlobalVarWithVarInjectionChecks:
2441     bineq t0, GlobalVarWithVarInjectionChecks, .pGlobalLexicalVarWithVarInjectionChecks
2442     varInjectionCheck(.pDynamic)
2443     putGlobalVariable()
2444     writeBarrierOnGlobalObject(size, get, m_value)
2445     dispatch()
2446 
2447 .pGlobalLexicalVarWithVarInjectionChecks:
2448     bineq t0, GlobalLexicalVarWithVarInjectionChecks, .pClosureVarWithVarInjectionChecks
2449     varInjectionCheck(.pDynamic)
2450     checkTDZInGlobalPutToScopeIfNecessary()
2451     putGlobalVariable()
2452     writeBarrierOnGlobalLexicalEnvironment(size, get, m_value)
2453     dispatch()
2454 
2455 .pClosureVarWithVarInjectionChecks:
2456     bineq t0, ClosureVarWithVarInjectionChecks, .pModuleVar
2457     varInjectionCheck(.pDynamic)
2458     loadVariable(get, m_scope, t2, t1, t0)
2459     putClosureVar()
2460     writeBarrierOnOperands(size, get, m_scope, m_value)
2461     dispatch()
2462 
2463 .pModuleVar:
2464     bineq t0, ModuleVar, .pDynamic
2465     callSlowPath(_slow_path_throw_strict_mode_readonly_property_write_error)
2466     dispatch()
2467 
2468 .pDynamic:
2469     callSlowPath(_llint_slow_path_put_to_scope)
2470     dispatch()
2471 end)
2472 
2473 
2474 llintOpWithProfile(op_get_from_arguments, OpGetFromArguments, macro (size, get, dispatch, return)
2475     get(m_arguments, t0)
2476     loadi PayloadOffset[cfr, t0, 8], t0
2477     getu(size, OpGetFromArguments, m_index, t1)
2478     loadi DirectArguments_storage + TagOffset[t0, t1, 8], t2
2479     loadi DirectArguments_storage + PayloadOffset[t0, t1, 8], t3
2480     return(t2, t3)
2481 end)
2482 
2483 
2484 llintOp(op_put_to_arguments, OpPutToArguments, macro (size, get, dispatch)
2485     writeBarrierOnOperands(size, get, m_arguments, m_value)
2486     get(m_arguments, t0)
2487     loadi PayloadOffset[cfr, t0, 8], t0
2488     get(m_value, t1)
2489     loadConstantOrVariable(size, t1, t2, t3)
2490     getu(size, OpPutToArguments, m_index, t1)
2491     storei t2, DirectArguments_storage + TagOffset[t0, t1, 8]
2492     storei t3, DirectArguments_storage + PayloadOffset[t0, t1, 8]
2493     dispatch()
2494 end)
2495 
2496 
2497 llintOpWithReturn(op_get_parent_scope, OpGetParentScope, macro (size, get, dispatch, return)
2498     get(m_scope, t0)
2499     loadp PayloadOffset[cfr, t0, 8], t0
2500     loadp JSScope::m_next[t0], t0
2501     return(CellTag, t0)
2502 end)
2503 
2504 
2505 llintOpWithMetadata(op_profile_type, OpProfileType, macro (size, get, dispatch, metadata, return)
2506     loadp CodeBlock[cfr], t1
2507     loadp CodeBlock::m_vm[t1], t1
2508     # t1 is holding the pointer to the typeProfilerLog.
2509     loadp VM::m_typeProfilerLog[t1], t1
2510 
2511     # t0 is holding the payload, t5 is holding the tag.
2512     get(m_targetVirtualRegister, t2)
2513     loadConstantOrVariable(size, t2, t5, t0)
2514 
2515     bieq t5, EmptyValueTag, .opProfileTypeDone
2516 
2517     metadata(t3, t2)
2518     # t2 is holding the pointer to the current log entry.
2519     loadp TypeProfilerLog::m_currentLogEntryPtr[t1], t2
2520 
2521     # Store the JSValue onto the log entry.
2522     storei t5, TypeProfilerLog::LogEntry::value + TagOffset[t2]
2523     storei t0, TypeProfilerLog::LogEntry::value + PayloadOffset[t2]
2524 
2525     # Store the TypeLocation onto the log entry.
2526     loadp OpProfileType::Metadata::m_typeLocation[t3], t3
2527     storep t3, TypeProfilerLog::LogEntry::location[t2]
2528 
2529     bieq t5, CellTag, .opProfileTypeIsCell
2530     storei 0, TypeProfilerLog::LogEntry::structureID[t2]
2531     jmp .opProfileTypeSkipIsCell
2532 .opProfileTypeIsCell:
2533     loadi JSCell::m_structureID[t0], t3
2534     storei t3, TypeProfilerLog::LogEntry::structureID[t2]
2535 .opProfileTypeSkipIsCell:
2536     
2537     # Increment the current log entry.
2538     addp sizeof TypeProfilerLog::LogEntry, t2
2539     storep t2, TypeProfilerLog::m_currentLogEntryPtr[t1]
2540 
2541     loadp TypeProfilerLog::m_logEndPtr[t1], t1
2542     bpneq t2, t1, .opProfileTypeDone
2543     callSlowPath(_slow_path_profile_type_clear_log)
2544 
2545 .opProfileTypeDone:
2546     dispatch()
2547 end)
2548 
2549 
2550 llintOpWithMetadata(op_profile_control_flow, OpProfileControlFlow, macro (size, get, dispatch, metadata, return)
2551     metadata(t5, t0)
2552     loadp OpProfileControlFlow::Metadata::m_basicBlockLocation[t5], t0
2553     loadi BasicBlockLocation::m_executionCount[t0], t1
2554     baddio 1, t1, .done
2555     storei t1, BasicBlockLocation::m_executionCount[t0]
2556 .done:
2557     dispatch()
2558 end)
2559 
2560 
2561 llintOpWithReturn(op_get_rest_length, OpGetRestLength, macro (size, get, dispatch, return)
2562     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t0
2563     subi 1, t0
2564     getu(size, OpGetRestLength, m_numParametersToSkip, t1)
2565     bilteq t0, t1, .storeZero
2566     subi t1, t0
2567     jmp .finish
2568 .storeZero:
2569     move 0, t0
2570 .finish:
2571     return(Int32Tag, t0)
2572 end)
2573 
2574 
2575 llintOpWithProfile(op_get_internal_field, OpGetInternalField, macro (size, get, dispatch, return)
2576     get(m_base, t0)
2577     loadi PayloadOffset[cfr, t0, 8], t0
2578     getu(size, OpGetInternalField, m_index, t1)
2579     loadi JSInternalFieldObjectImpl_internalFields + TagOffset[t0, t1, SlotSize], t2
2580     loadi JSInternalFieldObjectImpl_internalFields + PayloadOffset[t0, t1, SlotSize], t3
2581     return(t2, t3)
2582 end)
2583 
2584 llintOp(op_put_internal_field, OpPutInternalField, macro (size, get, dispatch)
2585     get(m_base, t0)
2586     loadi PayloadOffset[cfr, t0, 8], t0
2587     get(m_value, t1)
2588     loadConstantOrVariable(size, t1, t2, t3)
2589     getu(size, OpPutInternalField, m_index, t1)
2590     storei t2, JSInternalFieldObjectImpl_internalFields + TagOffset[t0, t1, SlotSize]
2591     storei t3, JSInternalFieldObjectImpl_internalFields + PayloadOffset[t0, t1, SlotSize]
2592     writeBarrierOnOperand(size, get, m_base)
2593     dispatch()
2594 end)
2595 
2596 
2597 llintOp(op_log_shadow_chicken_prologue, OpLogShadowChickenPrologue, macro (size, get, dispatch)
2598     acquireShadowChickenPacket(.opLogShadowChickenPrologueSlow)
2599     storep cfr, ShadowChicken::Packet::frame[t0]
2600     loadp CallerFrame[cfr], t1
2601     storep t1, ShadowChicken::Packet::callerFrame[t0]
2602     loadp Callee + PayloadOffset[cfr], t1
2603     storep t1, ShadowChicken::Packet::callee[t0]
2604     get(m_scope, t1)
2605     loadi PayloadOffset[cfr, t1, 8], t1
2606     storep t1, ShadowChicken::Packet::scope[t0]
2607     dispatch()
2608 .opLogShadowChickenPrologueSlow:
2609     callSlowPath(_llint_slow_path_log_shadow_chicken_prologue)
2610     dispatch()
2611 end)
2612 
2613 
2614 llintOp(op_log_shadow_chicken_tail, OpLogShadowChickenTail, macro (size, get, dispatch)
2615     acquireShadowChickenPacket(.opLogShadowChickenTailSlow)
2616     storep cfr, ShadowChicken::Packet::frame[t0]
2617     storep ShadowChickenTailMarker, ShadowChicken::Packet::callee[t0]
2618     loadVariable(get, m_thisValue, t3, t2, t1)
2619     storei t2, TagOffset + ShadowChicken::Packet::thisValue[t0]
2620     storei t1, PayloadOffset + ShadowChicken::Packet::thisValue[t0]
2621     get(m_scope, t1)
2622     loadi PayloadOffset[cfr, t1, 8], t1
2623     storep t1, ShadowChicken::Packet::scope[t0]
2624     loadp CodeBlock[cfr], t1
2625     storep t1, ShadowChicken::Packet::codeBlock[t0]
2626     storei PC, ShadowChicken::Packet::callSiteIndex[t0]
2627     dispatch()
2628 .opLogShadowChickenTailSlow:
2629     callSlowPath(_llint_slow_path_log_shadow_chicken_tail)
2630     dispatch()
2631 end)
    </pre>
  </body>
</html>