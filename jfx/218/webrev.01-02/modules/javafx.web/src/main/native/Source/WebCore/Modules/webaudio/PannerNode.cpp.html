<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/PannerNode.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2010, Google Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1.  Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2.  Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 15  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 16  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
 17  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 18  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 19  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 20  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 21  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 22  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 23  */
 24 
 25 #include &quot;config.h&quot;
 26 #include &quot;PannerNode.h&quot;
 27 
 28 #if ENABLE(WEB_AUDIO)
 29 
 30 #include &quot;AudioBufferSourceNode.h&quot;
 31 #include &quot;AudioBus.h&quot;
 32 #include &quot;AudioContext.h&quot;
 33 #include &quot;AudioNodeInput.h&quot;
 34 #include &quot;AudioNodeOutput.h&quot;
 35 #include &quot;HRTFDatabaseLoader.h&quot;
 36 #include &quot;HRTFPanner.h&quot;
 37 #include &quot;ScriptExecutionContext.h&quot;
 38 #include &lt;wtf/IsoMallocInlines.h&gt;
 39 #include &lt;wtf/MathExtras.h&gt;
 40 
 41 namespace WebCore {
 42 
 43 WTF_MAKE_ISO_ALLOCATED_IMPL(PannerNode);
 44 
 45 static void fixNANs(double &amp;x)
 46 {
 47     if (std::isnan(x) || std::isinf(x))
 48         x = 0.0;
 49 }
 50 
 51 PannerNode::PannerNode(AudioContext&amp; context, float sampleRate)
 52     : AudioNode(context, sampleRate)
 53     , m_panningModel(PanningModelType::HRTF)
 54     , m_lastGain(-1.0)
 55     , m_connectionCount(0)
 56 {
 57     setNodeType(NodeTypePanner);
 58 
 59     // Load the HRTF database asynchronously so we don&#39;t block the Javascript thread while creating the HRTF database.
 60     m_hrtfDatabaseLoader = HRTFDatabaseLoader::createAndLoadAsynchronouslyIfNecessary(context.sampleRate());
 61 
 62     addInput(makeUnique&lt;AudioNodeInput&gt;(this));
 63     addOutput(makeUnique&lt;AudioNodeOutput&gt;(this, 2));
 64 
 65     // Node-specific default mixing rules.
 66     m_channelCount = 2;
 67     m_channelCountMode = ClampedMax;
 68     m_channelInterpretation = AudioBus::Speakers;
 69 
 70     m_distanceGain = AudioParam::create(context, &quot;distanceGain&quot;, 1.0, 0.0, 1.0);
 71     m_coneGain = AudioParam::create(context, &quot;coneGain&quot;, 1.0, 0.0, 1.0);
 72 
 73     m_position = FloatPoint3D(0, 0, 0);
 74     m_orientation = FloatPoint3D(1, 0, 0);
 75     m_velocity = FloatPoint3D(0, 0, 0);
 76 
 77     initialize();
 78 }
 79 
 80 PannerNode::~PannerNode()
 81 {
 82     uninitialize();
 83 }
 84 
 85 void PannerNode::pullInputs(size_t framesToProcess)
 86 {
 87     // We override pullInputs(), so we can detect new AudioSourceNodes which have connected to us when new connections are made.
 88     // These AudioSourceNodes need to be made aware of our existence in order to handle doppler shift pitch changes.
 89     if (m_connectionCount != context().connectionCount()) {
 90         m_connectionCount = context().connectionCount();
 91 
 92         // Recursively go through all nodes connected to us.
 93         HashSet&lt;AudioNode*&gt; visitedNodes;
 94         notifyAudioSourcesConnectedToNode(this, visitedNodes);
 95     }
 96 
 97     AudioNode::pullInputs(framesToProcess);
 98 }
 99 
100 void PannerNode::process(size_t framesToProcess)
101 {
102     AudioBus* destination = output(0)-&gt;bus();
103 
104     if (!isInitialized() || !input(0)-&gt;isConnected() || !m_panner.get()) {
105         destination-&gt;zero();
106         return;
107     }
108 
109     AudioBus* source = input(0)-&gt;bus();
110     if (!source) {
111         destination-&gt;zero();
112         return;
113     }
114 
115     // HRTFDatabase should be loaded before proceeding for offline audio context when panningModel() is &quot;HRTF&quot;.
116     if (panningModel() == PanningModelType::HRTF &amp;&amp; !m_hrtfDatabaseLoader-&gt;isLoaded()) {
117         if (context().isOfflineContext())
118             m_hrtfDatabaseLoader-&gt;waitForLoaderThreadCompletion();
119         else {
120             destination-&gt;zero();
121             return;
122         }
123     }
124 
125     // The audio thread can&#39;t block on this lock, so we use std::try_to_lock instead.
126     std::unique_lock&lt;Lock&gt; lock(m_pannerMutex, std::try_to_lock);
127     if (!lock.owns_lock()) {
128         // Too bad - The try_lock() failed. We must be in the middle of changing the panner.
129         destination-&gt;zero();
130         return;
131     }
132 
133     // Apply the panning effect.
134     double azimuth;
135     double elevation;
136     getAzimuthElevation(&amp;azimuth, &amp;elevation);
137     m_panner-&gt;pan(azimuth, elevation, source, destination, framesToProcess);
138 
139     // Get the distance and cone gain.
140     double totalGain = distanceConeGain();
141 
142     // Snap to desired gain at the beginning.
143     if (m_lastGain == -1.0)
144         m_lastGain = totalGain;
145 
146     // Apply gain in-place with de-zippering.
147     destination-&gt;copyWithGainFrom(*destination, &amp;m_lastGain, totalGain);
148 }
149 
150 void PannerNode::reset()
151 {
152     m_lastGain = -1.0; // force to snap to initial gain
153     if (m_panner.get())
154         m_panner-&gt;reset();
155 }
156 
157 void PannerNode::initialize()
158 {
159     if (isInitialized())
160         return;
161 
162     m_panner = Panner::create(m_panningModel, sampleRate(), m_hrtfDatabaseLoader.get());
163 
164     AudioNode::initialize();
165 }
166 
167 void PannerNode::uninitialize()
168 {
169     if (!isInitialized())
170         return;
171 
172     m_panner = nullptr;
173     AudioNode::uninitialize();
174 }
175 
176 AudioListener* PannerNode::listener()
177 {
178     return context().listener();
179 }
180 
181 void PannerNode::setPanningModel(PanningModelType model)
182 {
183     if (!m_panner.get() || model != m_panningModel) {
184         // This synchronizes with process().
185         std::lock_guard&lt;Lock&gt; lock(m_pannerMutex);
186 
187         m_panner = Panner::create(model, sampleRate(), m_hrtfDatabaseLoader.get());
188         m_panningModel = model;
189     }
190 }
191 
192 DistanceModelType PannerNode::distanceModel() const
193 {
194     return const_cast&lt;PannerNode*&gt;(this)-&gt;m_distanceEffect.model();
195 }
196 
197 void PannerNode::setDistanceModel(DistanceModelType model)
198 {
199     m_distanceEffect.setModel(model, true);
200 }
201 
202 void PannerNode::getAzimuthElevation(double* outAzimuth, double* outElevation)
203 {
204     // FIXME: we should cache azimuth and elevation (if possible), so we only re-calculate if a change has been made.
205 
206     double azimuth = 0.0;
207 
208     // Calculate the source-listener vector
209     FloatPoint3D listenerPosition = listener()-&gt;position();
210     FloatPoint3D sourceListener = m_position - listenerPosition;
211 
212     if (sourceListener.isZero()) {
213         // degenerate case if source and listener are at the same point
214         *outAzimuth = 0.0;
215         *outElevation = 0.0;
216         return;
217     }
218 
219     sourceListener.normalize();
220 
221     // Align axes
222     FloatPoint3D listenerFront = listener()-&gt;orientation();
223     FloatPoint3D listenerUp = listener()-&gt;upVector();
224     FloatPoint3D listenerRight = listenerFront.cross(listenerUp);
225     listenerRight.normalize();
226 
227     FloatPoint3D listenerFrontNorm = listenerFront;
228     listenerFrontNorm.normalize();
229 
230     FloatPoint3D up = listenerRight.cross(listenerFrontNorm);
231 
232     float upProjection = sourceListener.dot(up);
233 
234     FloatPoint3D projectedSource = sourceListener - upProjection * up;
235     projectedSource.normalize();
236 
237     azimuth = 180.0 * acos(projectedSource.dot(listenerRight)) / piDouble;
238     fixNANs(azimuth); // avoid illegal values
239 
240     // Source  in front or behind the listener
241     double frontBack = projectedSource.dot(listenerFrontNorm);
242     if (frontBack &lt; 0.0)
243         azimuth = 360.0 - azimuth;
244 
245     // Make azimuth relative to &quot;front&quot; and not &quot;right&quot; listener vector
246     if ((azimuth &gt;= 0.0) &amp;&amp; (azimuth &lt;= 270.0))
247         azimuth = 90.0 - azimuth;
248     else
249         azimuth = 450.0 - azimuth;
250 
251     // Elevation
252     double elevation = 90.0 - 180.0 * acos(sourceListener.dot(up)) / piDouble;
253     fixNANs(elevation); // avoid illegal values
254 
255     if (elevation &gt; 90.0)
256         elevation = 180.0 - elevation;
257     else if (elevation &lt; -90.0)
258         elevation = -180.0 - elevation;
259 
260     if (outAzimuth)
261         *outAzimuth = azimuth;
262     if (outElevation)
263         *outElevation = elevation;
264 }
265 
266 float PannerNode::dopplerRate()
267 {
268     double dopplerShift = 1.0;
269 
270     // FIXME: optimize for case when neither source nor listener has changed...
271     double dopplerFactor = listener()-&gt;dopplerFactor();
272 
273     if (dopplerFactor &gt; 0.0) {
274         double speedOfSound = listener()-&gt;speedOfSound();
275 
276         const FloatPoint3D &amp;sourceVelocity = m_velocity;
277         const FloatPoint3D &amp;listenerVelocity = listener()-&gt;velocity();
278 
279         // Don&#39;t bother if both source and listener have no velocity
280         bool sourceHasVelocity = !sourceVelocity.isZero();
281         bool listenerHasVelocity = !listenerVelocity.isZero();
282 
283         if (sourceHasVelocity || listenerHasVelocity) {
284             // Calculate the source to listener vector
285             FloatPoint3D listenerPosition = listener()-&gt;position();
286             FloatPoint3D sourceToListener = m_position - listenerPosition;
287 
288             double sourceListenerMagnitude = sourceToListener.length();
289 
290             double listenerProjection = sourceToListener.dot(listenerVelocity) / sourceListenerMagnitude;
291             double sourceProjection = sourceToListener.dot(sourceVelocity) / sourceListenerMagnitude;
292 
293             listenerProjection = -listenerProjection;
294             sourceProjection = -sourceProjection;
295 
296             double scaledSpeedOfSound = speedOfSound / dopplerFactor;
297             listenerProjection = std::min(listenerProjection, scaledSpeedOfSound);
298             sourceProjection = std::min(sourceProjection, scaledSpeedOfSound);
299 
300             dopplerShift = ((speedOfSound - dopplerFactor * listenerProjection) / (speedOfSound - dopplerFactor * sourceProjection));
301             fixNANs(dopplerShift); // avoid illegal values
302 
303             // Limit the pitch shifting to 4 octaves up and 3 octaves down.
304             if (dopplerShift &gt; 16.0)
305                 dopplerShift = 16.0;
306             else if (dopplerShift &lt; 0.125)
307                 dopplerShift = 0.125;
308         }
309     }
310 
311     return static_cast&lt;float&gt;(dopplerShift);
312 }
313 
314 float PannerNode::distanceConeGain()
315 {
316     FloatPoint3D listenerPosition = listener()-&gt;position();
317 
318     double listenerDistance = m_position.distanceTo(listenerPosition);
319     double distanceGain = m_distanceEffect.gain(listenerDistance);
320 
321     m_distanceGain-&gt;setValue(static_cast&lt;float&gt;(distanceGain));
322 
323     // FIXME: could optimize by caching coneGain
324     double coneGain = m_coneEffect.gain(m_position, m_orientation, listenerPosition);
325 
326     m_coneGain-&gt;setValue(static_cast&lt;float&gt;(coneGain));
327 
328     return float(distanceGain * coneGain);
329 }
330 
331 void PannerNode::notifyAudioSourcesConnectedToNode(AudioNode* node, HashSet&lt;AudioNode*&gt;&amp; visitedNodes)
332 {
333     ASSERT(node);
334     if (!node)
335         return;
336 
337     // First check if this node is an AudioBufferSourceNode. If so, let it know about us so that doppler shift pitch can be taken into account.
338     if (node-&gt;nodeType() == NodeTypeAudioBufferSource) {
339         AudioBufferSourceNode* bufferSourceNode = reinterpret_cast&lt;AudioBufferSourceNode*&gt;(node);
340         bufferSourceNode-&gt;setPannerNode(this);
341     } else {
342         // Go through all inputs to this node.
343         for (unsigned i = 0; i &lt; node-&gt;numberOfInputs(); ++i) {
344             AudioNodeInput* input = node-&gt;input(i);
345 
346             // For each input, go through all of its connections, looking for AudioBufferSourceNodes.
347             for (unsigned j = 0; j &lt; input-&gt;numberOfRenderingConnections(); ++j) {
348                 AudioNodeOutput* connectedOutput = input-&gt;renderingOutput(j);
349                 AudioNode* connectedNode = connectedOutput-&gt;node();
350                 if (visitedNodes.contains(connectedNode))
351                     continue;
352 
353                 visitedNodes.add(connectedNode);
354                 notifyAudioSourcesConnectedToNode(connectedNode, visitedNodes);
355             }
356         }
357     }
358 }
359 
360 } // namespace WebCore
361 
362 #endif // ENABLE(WEB_AUDIO)
    </pre>
  </body>
</html>