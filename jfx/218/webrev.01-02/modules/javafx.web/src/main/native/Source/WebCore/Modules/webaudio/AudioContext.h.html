<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.h</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2010 Google Inc. All rights reserved.
  3  * Copyright (C) 2016-2019 Apple Inc. All rights reserved.
  4  *
  5  * Redistribution and use in source and binary forms, with or without
  6  * modification, are permitted provided that the following conditions
  7  * are met:
  8  * 1.  Redistributions of source code must retain the above copyright
  9  *    notice, this list of conditions and the following disclaimer.
 10  * 2.  Redistributions in binary form must reproduce the above copyright
 11  *    notice, this list of conditions and the following disclaimer in the
 12  *    documentation and/or other materials provided with the distribution.
 13  *
 14  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
 15  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 16  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 17  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
 18  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 19  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 20  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 21  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 23  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #include &quot;ActiveDOMObject.h&quot;
 29 #include &quot;AsyncAudioDecoder.h&quot;
 30 #include &quot;AudioBus.h&quot;
 31 #include &quot;AudioDestinationNode.h&quot;
 32 #include &quot;EventTarget.h&quot;
 33 #include &quot;MediaCanStartListener.h&quot;
 34 #include &quot;MediaProducer.h&quot;
 35 #include &quot;PlatformMediaSession.h&quot;
 36 #include &quot;ScriptExecutionContext.h&quot;
 37 #include &quot;VisibilityChangeClient.h&quot;
 38 #include &lt;JavaScriptCore/ConsoleTypes.h&gt;
 39 #include &lt;JavaScriptCore/Float32Array.h&gt;
 40 #include &lt;atomic&gt;
 41 #include &lt;wtf/HashSet.h&gt;
 42 #include &lt;wtf/LoggerHelper.h&gt;
 43 #include &lt;wtf/MainThread.h&gt;
 44 #include &lt;wtf/RefPtr.h&gt;
 45 #include &lt;wtf/ThreadSafeRefCounted.h&gt;
 46 #include &lt;wtf/Threading.h&gt;
 47 #include &lt;wtf/UniqueRef.h&gt;
 48 #include &lt;wtf/Vector.h&gt;
 49 #include &lt;wtf/text/AtomStringHash.h&gt;
 50 
 51 namespace WebCore {
 52 
 53 class AnalyserNode;
 54 class AudioBuffer;
 55 class AudioBufferCallback;
 56 class AudioBufferSourceNode;
 57 class AudioListener;
 58 class AudioSummingJunction;
 59 class BiquadFilterNode;
 60 class ChannelMergerNode;
 61 class ChannelSplitterNode;
 62 class ConvolverNode;
 63 class DelayNode;
 64 class Document;
 65 class DynamicsCompressorNode;
 66 class GainNode;
 67 class HTMLMediaElement;
 68 class MainThreadGenericEventQueue;
 69 class MediaElementAudioSourceNode;
 70 class MediaStream;
 71 class MediaStreamAudioDestinationNode;
 72 class MediaStreamAudioSourceNode;
 73 class OscillatorNode;
 74 class PannerNode;
 75 class PeriodicWave;
 76 class ScriptProcessorNode;
 77 class SecurityOrigin;
 78 class WaveShaperNode;
 79 
 80 template&lt;typename IDLType&gt; class DOMPromiseDeferred;
 81 
 82 // AudioContext is the cornerstone of the web audio API and all AudioNodes are created from it.
 83 // For thread safety between the audio thread and the main thread, it has a rendering graph locking mechanism.
 84 
 85 class AudioContext
 86     : public ActiveDOMObject
 87     , public ThreadSafeRefCounted&lt;AudioContext&gt;
 88     , public EventTargetWithInlineData
 89     , public MediaCanStartListener
 90     , public MediaProducer
 91     , private PlatformMediaSessionClient
 92     , private VisibilityChangeClient
 93 #if !RELEASE_LOG_DISABLED
 94     , private LoggerHelper
 95 #endif
 96 {
 97     WTF_MAKE_ISO_ALLOCATED(AudioContext);
 98 public:
 99     // Create an AudioContext for rendering to the audio hardware.
100     static RefPtr&lt;AudioContext&gt; create(Document&amp;);
101 
102     virtual ~AudioContext();
103 
104     bool isInitialized() const;
105 
106     bool isOfflineContext() const { return m_isOfflineContext; }
107 
108     Document* document() const; // ASSERTs if document no longer exists.
109 
110     Document* hostingDocument() const final;
111 
112     AudioDestinationNode* destination() { return m_destinationNode.get(); }
113     size_t currentSampleFrame() const { return m_destinationNode ? m_destinationNode-&gt;currentSampleFrame() : 0; }
114     double currentTime() const { return m_destinationNode ? m_destinationNode-&gt;currentTime() : 0.; }
115     float sampleRate() const { return m_destinationNode ? m_destinationNode-&gt;sampleRate() : 0.f; }
116     unsigned long activeSourceCount() const { return static_cast&lt;unsigned long&gt;(m_activeSourceCount); }
117 
118     void incrementActiveSourceCount();
119     void decrementActiveSourceCount();
120 
121     ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; createBuffer(unsigned numberOfChannels, size_t numberOfFrames, float sampleRate);
122     ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; createBuffer(ArrayBuffer&amp;, bool mixToMono);
123 
124     // Asynchronous audio file data decoding.
125     void decodeAudioData(Ref&lt;ArrayBuffer&gt;&amp;&amp;, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp;, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp;);
126 
127     AudioListener* listener() { return m_listener.get(); }
128 
129     void suspendRendering(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
130     void resumeRendering(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
131     void close(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
132 
133     enum class State { Suspended, Running, Interrupted, Closed };
134     State state() const;
135     bool isClosed() const { return m_state == State::Closed; }
136 
137     bool wouldTaintOrigin(const URL&amp;) const;
138 
139     // The AudioNode create methods are called on the main thread (from JavaScript).
140     ExceptionOr&lt;Ref&lt;AudioBufferSourceNode&gt;&gt; createBufferSource();
141 #if ENABLE(VIDEO)
142     ExceptionOr&lt;Ref&lt;MediaElementAudioSourceNode&gt;&gt; createMediaElementSource(HTMLMediaElement&amp;);
143 #endif
144 #if ENABLE(MEDIA_STREAM)
145     ExceptionOr&lt;Ref&lt;MediaStreamAudioSourceNode&gt;&gt; createMediaStreamSource(MediaStream&amp;);
146     ExceptionOr&lt;Ref&lt;MediaStreamAudioDestinationNode&gt;&gt; createMediaStreamDestination();
147 #endif
148     ExceptionOr&lt;Ref&lt;GainNode&gt;&gt; createGain();
149     ExceptionOr&lt;Ref&lt;BiquadFilterNode&gt;&gt; createBiquadFilter();
150     ExceptionOr&lt;Ref&lt;WaveShaperNode&gt;&gt; createWaveShaper();
151     ExceptionOr&lt;Ref&lt;DelayNode&gt;&gt; createDelay(double maxDelayTime);
152     ExceptionOr&lt;Ref&lt;PannerNode&gt;&gt; createPanner();
153     ExceptionOr&lt;Ref&lt;ConvolverNode&gt;&gt; createConvolver();
154     ExceptionOr&lt;Ref&lt;DynamicsCompressorNode&gt;&gt; createDynamicsCompressor();
155     ExceptionOr&lt;Ref&lt;AnalyserNode&gt;&gt; createAnalyser();
156     ExceptionOr&lt;Ref&lt;ScriptProcessorNode&gt;&gt; createScriptProcessor(size_t bufferSize, size_t numberOfInputChannels, size_t numberOfOutputChannels);
157     ExceptionOr&lt;Ref&lt;ChannelSplitterNode&gt;&gt; createChannelSplitter(size_t numberOfOutputs);
158     ExceptionOr&lt;Ref&lt;ChannelMergerNode&gt;&gt; createChannelMerger(size_t numberOfInputs);
159     ExceptionOr&lt;Ref&lt;OscillatorNode&gt;&gt; createOscillator();
160     ExceptionOr&lt;Ref&lt;PeriodicWave&gt;&gt; createPeriodicWave(Float32Array&amp; real, Float32Array&amp; imaginary);
161 
162     // When a source node has no more processing to do (has finished playing), then it tells the context to dereference it.
163     void notifyNodeFinishedProcessing(AudioNode*);
164 
165     // Called at the start of each render quantum.
166     void handlePreRenderTasks();
167 
168     // Called at the end of each render quantum.
169     void handlePostRenderTasks();
170 
171     // Called periodically at the end of each render quantum to dereference finished source nodes.
172     void derefFinishedSourceNodes();
173 
174     // We schedule deletion of all marked nodes at the end of each realtime render quantum.
175     void markForDeletion(AudioNode&amp;);
176     void deleteMarkedNodes();
177 
178     // AudioContext can pull node(s) at the end of each render quantum even when they are not connected to any downstream nodes.
179     // These two methods are called by the nodes who want to add/remove themselves into/from the automatic pull lists.
180     void addAutomaticPullNode(AudioNode&amp;);
181     void removeAutomaticPullNode(AudioNode&amp;);
182 
183     // Called right before handlePostRenderTasks() to handle nodes which need to be pulled even when they are not connected to anything.
184     void processAutomaticPullNodes(size_t framesToProcess);
185 
186     // Keeps track of the number of connections made.
187     void incrementConnectionCount()
188     {
189         ASSERT(isMainThread());
190         m_connectionCount++;
191     }
192 
193     unsigned connectionCount() const { return m_connectionCount; }
194 
195     //
196     // Thread Safety and Graph Locking:
197     //
198 
199     void setAudioThread(Thread&amp; thread) { m_audioThread = &amp;thread; } // FIXME: check either not initialized or the same
200     Thread* audioThread() const { return m_audioThread; }
201     bool isAudioThread() const;
202 
203     // Returns true only after the audio thread has been started and then shutdown.
204     bool isAudioThreadFinished() { return m_isAudioThreadFinished; }
205 
206     // mustReleaseLock is set to true if we acquired the lock in this method call and caller must unlock(), false if it was previously acquired.
207     void lock(bool&amp; mustReleaseLock);
208 
209     // Returns true if we own the lock.
210     // mustReleaseLock is set to true if we acquired the lock in this method call and caller must unlock(), false if it was previously acquired.
211     bool tryLock(bool&amp; mustReleaseLock);
212 
213     void unlock();
214 
215     // Returns true if this thread owns the context&#39;s lock.
216     bool isGraphOwner() const;
217 
218     // Returns the maximum number of channels we can support.
219     static unsigned maxNumberOfChannels() { return MaxNumberOfChannels; }
220 
221     class AutoLocker {
222     public:
223         explicit AutoLocker(AudioContext&amp; context)
224             : m_context(context)
225         {
226             m_context.lock(m_mustReleaseLock);
227         }
228 
229         ~AutoLocker()
230         {
231             if (m_mustReleaseLock)
232                 m_context.unlock();
233         }
234 
235     private:
236         AudioContext&amp; m_context;
237         bool m_mustReleaseLock;
238     };
239 
240     // In AudioNode::deref() a tryLock() is used for calling finishDeref(), but if it fails keep track here.
241     void addDeferredFinishDeref(AudioNode*);
242 
243     // In the audio thread at the start of each render cycle, we&#39;ll call handleDeferredFinishDerefs().
244     void handleDeferredFinishDerefs();
245 
246     // Only accessed when the graph lock is held.
247     void markSummingJunctionDirty(AudioSummingJunction*);
248     void markAudioNodeOutputDirty(AudioNodeOutput*);
249 
250     // Must be called on main thread.
251     void removeMarkedSummingJunction(AudioSummingJunction*);
252 
253     // EventTarget
254     EventTargetInterface eventTargetInterface() const final { return AudioContextEventTargetInterfaceType; }
255 
256     // Reconcile ref/deref which are defined both in ThreadSafeRefCounted and EventTarget.
257     using ThreadSafeRefCounted::ref;
258     using ThreadSafeRefCounted::deref;
259 
260     void startRendering();
261     void finishedRendering(bool didRendering);
262 
263     static unsigned s_hardwareContextCount;
264 
265     // Restrictions to change default behaviors.
266     enum BehaviorRestrictionFlags {
267         NoRestrictions = 0,
268         RequireUserGestureForAudioStartRestriction = 1 &lt;&lt; 0,
269         RequirePageConsentForAudioStartRestriction = 1 &lt;&lt; 1,
270     };
271     typedef unsigned BehaviorRestrictions;
272 
273     BehaviorRestrictions behaviorRestrictions() const { return m_restrictions; }
274     void addBehaviorRestriction(BehaviorRestrictions restriction) { m_restrictions |= restriction; }
275     void removeBehaviorRestriction(BehaviorRestrictions restriction) { m_restrictions &amp;= ~restriction; }
276 
277     void isPlayingAudioDidChange();
278 
279     void nodeWillBeginPlayback();
280 
281 #if !RELEASE_LOG_DISABLED
282     const Logger&amp; logger() const final { return m_logger.get(); }
283     const void* logIdentifier() const final { return m_logIdentifier; }
284     WTFLogChannel&amp; logChannel() const final;
285     const void* nextAudioNodeLogIdentifier() { return childLogIdentifier(++m_nextAudioNodeIdentifier); }
286     const void* nextAudioParameterLogIdentifier() { return childLogIdentifier(++m_nextAudioParameterIdentifier); }
287 #endif
288 
289     void postTask(WTF::Function&lt;void()&gt;&amp;&amp;);
290     bool isStopped() const { return m_isStopScheduled; }
291     const SecurityOrigin* origin() const;
292     void addConsoleMessage(MessageSource, MessageLevel, const String&amp; message);
293 
294     // EventTarget
295     ScriptExecutionContext* scriptExecutionContext() const final;
296 
297 protected:
298     explicit AudioContext(Document&amp;);
299     AudioContext(Document&amp;, AudioBuffer* renderTarget);
300 
301     static bool isSampleRateRangeGood(float sampleRate);
302     void clearPendingActivity();
303     void makePendingActivity();
304 
305 private:
306     void constructCommon();
307 
308     void lazyInitialize();
309     void uninitialize();
310 
311     bool willBeginPlayback();
312     bool willPausePlayback();
313 
314     bool userGestureRequiredForAudioStart() const { return !isOfflineContext() &amp;&amp; m_restrictions &amp; RequireUserGestureForAudioStartRestriction; }
315     bool pageConsentRequiredForAudioStart() const { return !isOfflineContext() &amp;&amp; m_restrictions &amp; RequirePageConsentForAudioStartRestriction; }
316 
317     void setState(State);
318 
319     void clear();
320 
321     void scheduleNodeDeletion();
322 
323     void mediaCanStart(Document&amp;) override;
324 
325     // EventTarget
326     void dispatchEvent(Event&amp;) final;
327 
328     // MediaProducer
329     MediaProducer::MediaStateFlags mediaState() const override;
330     void pageMutedStateDidChange() override;
331 
332     // The context itself keeps a reference to all source nodes.  The source nodes, then reference all nodes they&#39;re connected to.
333     // In turn, these nodes reference all nodes they&#39;re connected to.  All nodes are ultimately connected to the AudioDestinationNode.
334     // When the context dereferences a source node, it will be deactivated from the rendering graph along with all other nodes it is
335     // uniquely connected to.  See the AudioNode::ref() and AudioNode::deref() methods for more details.
336     void refNode(AudioNode&amp;);
337     void derefNode(AudioNode&amp;);
338 
339     // ActiveDOMObject API.
340     void suspend(ReasonForSuspension) final;
341     void resume() final;
342     void stop() override;
343     const char* activeDOMObjectName() const override;
344 
345     // When the context goes away, there might still be some sources which haven&#39;t finished playing.
346     // Make sure to dereference them here.
347     void derefUnfinishedSourceNodes();
348 
349     // PlatformMediaSessionClient
350     PlatformMediaSession::MediaType mediaType() const override { return PlatformMediaSession::WebAudio; }
351     PlatformMediaSession::MediaType presentationType() const override { return PlatformMediaSession::WebAudio; }
352     PlatformMediaSession::CharacteristicsFlags characteristics() const override { return m_state == State::Running ? PlatformMediaSession::HasAudio : PlatformMediaSession::HasNothing; }
353     void mayResumePlayback(bool shouldResume) override;
354     void suspendPlayback() override;
355     bool canReceiveRemoteControlCommands() const override { return false; }
356     void didReceiveRemoteControlCommand(PlatformMediaSession::RemoteControlCommandType, const PlatformMediaSession::RemoteCommandArgument*) override { }
357     bool supportsSeeking() const override { return false; }
358     bool shouldOverrideBackgroundPlaybackRestriction(PlatformMediaSession::InterruptionType) const override { return false; }
359     String sourceApplicationIdentifier() const override;
360     bool canProduceAudio() const final { return true; }
361     bool isSuspended() const final;
362     bool processingUserGestureForMedia() const final;
363 
364     void visibilityStateChanged() final;
365 
366     // EventTarget
367     void refEventTarget() override { ref(); }
368     void derefEventTarget() override { deref(); }
369 
370     void handleDirtyAudioSummingJunctions();
371     void handleDirtyAudioNodeOutputs();
372 
373     void addReaction(State, DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
374     void updateAutomaticPullNodes();
375 
376 #if !RELEASE_LOG_DISABLED
377     const char* logClassName() const final { return &quot;AudioContext&quot;; }
378 
379     Ref&lt;Logger&gt; m_logger;
380     const void* m_logIdentifier;
381     uint64_t m_nextAudioNodeIdentifier { 0 };
382     uint64_t m_nextAudioParameterIdentifier { 0 };
383 #endif
384 
385     // Only accessed in the audio thread.
386     Vector&lt;AudioNode*&gt; m_finishedNodes;
387 
388     // We don&#39;t use RefPtr&lt;AudioNode&gt; here because AudioNode has a more complex ref() / deref() implementation
389     // with an optional argument for refType.  We need to use the special refType: RefTypeConnection
390     // Either accessed when the graph lock is held, or on the main thread when the audio thread has finished.
391     Vector&lt;AudioNode*&gt; m_referencedNodes;
392 
393     // Accumulate nodes which need to be deleted here.
394     // This is copied to m_nodesToDelete at the end of a render cycle in handlePostRenderTasks(), where we&#39;re assured of a stable graph
395     // state which will have no references to any of the nodes in m_nodesToDelete once the context lock is released
396     // (when handlePostRenderTasks() has completed).
397     Vector&lt;AudioNode*&gt; m_nodesMarkedForDeletion;
398 
399     // They will be scheduled for deletion (on the main thread) at the end of a render cycle (in realtime thread).
400     Vector&lt;AudioNode*&gt; m_nodesToDelete;
401 
402     bool m_isDeletionScheduled { false };
403     bool m_isStopScheduled { false };
404     bool m_isInitialized { false };
405     bool m_isAudioThreadFinished { false };
406     bool m_automaticPullNodesNeedUpdating { false };
407     bool m_isOfflineContext { false };
408 
409     // Only accessed when the graph lock is held.
410     HashSet&lt;AudioSummingJunction*&gt; m_dirtySummingJunctions;
411     HashSet&lt;AudioNodeOutput*&gt; m_dirtyAudioNodeOutputs;
412 
413     // For the sake of thread safety, we maintain a seperate Vector of automatic pull nodes for rendering in m_renderingAutomaticPullNodes.
414     // It will be copied from m_automaticPullNodes by updateAutomaticPullNodes() at the very start or end of the rendering quantum.
415     HashSet&lt;AudioNode*&gt; m_automaticPullNodes;
416     Vector&lt;AudioNode*&gt; m_renderingAutomaticPullNodes;
417     // Only accessed in the audio thread.
418     Vector&lt;AudioNode*&gt; m_deferredFinishDerefList;
419     Vector&lt;Vector&lt;DOMPromiseDeferred&lt;void&gt;&gt;&gt; m_stateReactions;
420 
421     std::unique_ptr&lt;PlatformMediaSession&gt; m_mediaSession;
422     UniqueRef&lt;MainThreadGenericEventQueue&gt; m_eventQueue;
423 
424     RefPtr&lt;AudioBuffer&gt; m_renderTarget;
425     RefPtr&lt;AudioDestinationNode&gt; m_destinationNode;
426     RefPtr&lt;AudioListener&gt; m_listener;
427 
428     unsigned m_connectionCount { 0 };
429 
430     // Graph locking.
431     Lock m_contextGraphMutex;
432     // FIXME: Using volatile seems incorrect.
433     // https://bugs.webkit.org/show_bug.cgi?id=180332
434     Thread* volatile m_audioThread { nullptr };
435     Thread* volatile m_graphOwnerThread { nullptr }; // if the lock is held then this is the thread which owns it, otherwise == nullptr.
436 
437     std::unique_ptr&lt;AsyncAudioDecoder&gt; m_audioDecoder;
438 
439     // This is considering 32 is large enough for multiple channels audio.
440     // It is somewhat arbitrary and could be increased if necessary.
441     enum { MaxNumberOfChannels = 32 };
442 
443     // Number of AudioBufferSourceNodes that are active (playing).
444     std::atomic&lt;int&gt; m_activeSourceCount { 0 };
445 
446     BehaviorRestrictions m_restrictions { NoRestrictions };
447 
448     State m_state { State::Suspended };
449     RefPtr&lt;PendingActivity&lt;AudioContext&gt;&gt; m_pendingActivity;
450 };
451 
452 // FIXME: Find out why these ==/!= functions are needed and remove them if possible.
453 
454 inline bool operator==(const AudioContext&amp; lhs, const AudioContext&amp; rhs)
455 {
456     return &amp;lhs == &amp;rhs;
457 }
458 
459 inline bool operator!=(const AudioContext&amp; lhs, const AudioContext&amp; rhs)
460 {
461     return &amp;lhs != &amp;rhs;
462 }
463 
464 inline AudioContext::State AudioContext::state() const
465 {
466     return m_state;
467 }
468 
469 } // WebCore
    </pre>
  </body>
</html>