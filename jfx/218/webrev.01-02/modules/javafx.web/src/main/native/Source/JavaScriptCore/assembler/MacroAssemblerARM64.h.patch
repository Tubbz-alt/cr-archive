diff a/modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerARM64.h b/modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerARM64.h
--- a/modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerARM64.h
+++ b/modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerARM64.h
@@ -1,7 +1,7 @@
 /*
- * Copyright (C) 2012-2018 Apple Inc. All rights reserved.
+ * Copyright (C) 2012-2019 Apple Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions
  * are met:
  * 1. Redistributions of source code must retain the above copyright
@@ -33,15 +33,16 @@
 #include <wtf/Optional.h>
 
 namespace JSC {
 
 using Assembler = TARGET_ASSEMBLER;
+class Reg;
 
 class MacroAssemblerARM64 : public AbstractMacroAssembler<Assembler> {
 public:
-    static const unsigned numGPRs = 32;
-    static const unsigned numFPRs = 32;
+    static constexpr unsigned numGPRs = 32;
+    static constexpr unsigned numFPRs = 32;
 
     static constexpr RegisterID dataTempRegister = ARM64Registers::ip0;
     static constexpr RegisterID memoryTempRegister = ARM64Registers::ip1;
 
     RegisterID scratchRegister()
@@ -49,15 +50,15 @@
         RELEASE_ASSERT(m_allowScratchRegister);
         return getCachedDataTempRegisterIDAndInvalidate();
     }
 
 protected:
-    static const ARM64Registers::FPRegisterID fpTempRegister = ARM64Registers::q31;
-    static const Assembler::SetFlags S = Assembler::S;
-    static const int64_t maskHalfWord0 = 0xffffl;
-    static const int64_t maskHalfWord1 = 0xffff0000l;
-    static const int64_t maskUpperWord = 0xffffffff00000000l;
+    static constexpr ARM64Registers::FPRegisterID fpTempRegister = ARM64Registers::q31;
+    static constexpr Assembler::SetFlags S = Assembler::S;
+    static constexpr int64_t maskHalfWord0 = 0xffffl;
+    static constexpr int64_t maskHalfWord1 = 0xffff0000l;
+    static constexpr int64_t maskUpperWord = 0xffffffff00000000l;
 
     static constexpr size_t INSTRUCTION_SIZE = 4;
 
     // N instructions to load the pointer + 1 call instruction.
     static constexpr ptrdiff_t REPATCH_OFFSET_CALL_TO_POINTER = -((Assembler::MAX_POINTER_BITS / 16 + 1) * INSTRUCTION_SIZE);
@@ -73,22 +74,22 @@
     typedef Assembler::LinkRecord LinkRecord;
     typedef Assembler::JumpType JumpType;
     typedef Assembler::JumpLinkType JumpLinkType;
     typedef Assembler::Condition Condition;
 
-    static const Assembler::Condition DefaultCondition = Assembler::ConditionInvalid;
-    static const Assembler::JumpType DefaultJump = Assembler::JumpNoConditionFixedSize;
+    static constexpr Assembler::Condition DefaultCondition = Assembler::ConditionInvalid;
+    static constexpr Assembler::JumpType DefaultJump = Assembler::JumpNoConditionFixedSize;
 
     Vector<LinkRecord, 0, UnsafeVectorOverflow>& jumpsToLink() { return m_assembler.jumpsToLink(); }
     static bool canCompact(JumpType jumpType) { return Assembler::canCompact(jumpType); }
     static JumpLinkType computeJumpType(JumpType jumpType, const uint8_t* from, const uint8_t* to) { return Assembler::computeJumpType(jumpType, from, to); }
     static JumpLinkType computeJumpType(LinkRecord& record, const uint8_t* from, const uint8_t* to) { return Assembler::computeJumpType(record, from, to); }
     static int jumpSizeDelta(JumpType jumpType, JumpLinkType jumpLinkType) { return Assembler::jumpSizeDelta(jumpType, jumpLinkType); }
-    template <typename CopyFunction>
-    static void link(LinkRecord& record, uint8_t* from, const uint8_t* fromInstruction, uint8_t* to, CopyFunction copy) { return Assembler::link(record, from, fromInstruction, to, copy); }
+    template <Assembler::CopyFunction copy>
+    static void link(LinkRecord& record, uint8_t* from, const uint8_t* fromInstruction, uint8_t* to) { return Assembler::link<copy>(record, from, fromInstruction, to); }
 
-    static const Scale ScalePtr = TimesEight;
+    static constexpr Scale ScalePtr = TimesEight;
 
     static bool isCompactPtrAlignedAddressOffset(ptrdiff_t value)
     {
         // This is the largest 32-bit access allowed, aligned to 64-bit boundary.
         return !(value & ~0x3ff8);
@@ -135,13 +136,13 @@
         DoubleGreaterThanOrEqualOrUnordered = Assembler::ConditionHS,
         DoubleLessThanOrUnordered = Assembler::ConditionLT,
         DoubleLessThanOrEqualOrUnordered = Assembler::ConditionLE,
     };
 
-    static const RegisterID stackPointerRegister = ARM64Registers::sp;
-    static const RegisterID framePointerRegister = ARM64Registers::fp;
-    static const RegisterID linkRegister = ARM64Registers::lr;
+    static constexpr RegisterID stackPointerRegister = ARM64Registers::sp;
+    static constexpr RegisterID framePointerRegister = ARM64Registers::fp;
+    static constexpr RegisterID linkRegister = ARM64Registers::lr;
 
     // FIXME: Get reasonable implementations for these
     static bool shouldBlindForSpecificArch(uint32_t value) { return value >= 0x00ffffff; }
     static bool shouldBlindForSpecificArch(uint64_t value) { return value >= 0x00ffffff; }
 
@@ -612,10 +613,24 @@
     void neg64(RegisterID src, RegisterID dest)
     {
         m_assembler.neg<64>(dest, src);
     }
 
+    void or16(TrustedImm32 imm, AbsoluteAddress address)
+    {
+        LogicalImmediate logicalImm = LogicalImmediate::create32(imm.m_value);
+        if (logicalImm.isValid()) {
+            load16(address.m_ptr, getCachedDataTempRegisterIDAndInvalidate());
+            m_assembler.orr<32>(dataTempRegister, dataTempRegister, logicalImm);
+            store16(dataTempRegister, address.m_ptr);
+        } else {
+            load16(address.m_ptr, getCachedMemoryTempRegisterIDAndInvalidate());
+            or32(imm, memoryTempRegister, getCachedDataTempRegisterIDAndInvalidate());
+            store16(dataTempRegister, address.m_ptr);
+        }
+    }
+
     void or32(RegisterID src, RegisterID dest)
     {
         or32(dest, src, dest);
     }
 
@@ -1235,10 +1250,15 @@
         m_assembler.ldrh(dest, memoryTempRegister, address.base, Assembler::UXTX, 1);
         if (dest == memoryTempRegister)
             cachedMemoryTempRegister().invalidate();
     }
 
+    void load16(const void* address, RegisterID dest)
+    {
+        load<16>(address, dest);
+    }
+
     void load16Unaligned(ImplicitAddress address, RegisterID dest)
     {
         load16(address, dest);
     }
 
@@ -1543,10 +1563,26 @@
         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
         m_assembler.add<64>(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
         m_assembler.strh(src, address.base, memoryTempRegister);
     }
 
+    void store16(RegisterID src, const void* address)
+    {
+        store<16>(src, address);
+    }
+
+    void store16(TrustedImm32 imm, const void* address)
+    {
+        if (!imm.m_value) {
+            store16(ARM64Registers::zr, address);
+            return;
+        }
+
+        moveToCachedReg(imm, dataMemoryTempRegister());
+        store16(dataTempRegister, address);
+    }
+
     void storeZero16(ImplicitAddress address)
     {
         store16(ARM64Registers::zr, address);
     }
 
@@ -3207,10 +3243,17 @@
 
     ALWAYS_INLINE Call call(RegisterID callTag) { return UNUSED_PARAM(callTag), call(NoPtrTag); }
     ALWAYS_INLINE Call call(RegisterID target, RegisterID callTag) { return UNUSED_PARAM(callTag), call(target, NoPtrTag); }
     ALWAYS_INLINE Call call(Address address, RegisterID callTag) { return UNUSED_PARAM(callTag), call(address, NoPtrTag); }
 
+    ALWAYS_INLINE void callOperation(const FunctionPtr<OperationPtrTag> operation)
+    {
+        auto tmp = getCachedDataTempRegisterIDAndInvalidate();
+        move(TrustedImmPtr(operation.executableAddress()), tmp);
+        call(tmp, OperationPtrTag);
+    }
+
     ALWAYS_INLINE Jump jump()
     {
         AssemblerLabel label = m_assembler.label();
         m_assembler.b();
         return Jump(label, m_makeJumpPatchable ? Assembler::JumpNoConditionFixedSize : Assembler::JumpNoCondition);
@@ -3245,10 +3288,11 @@
     ALWAYS_INLINE void farJump(BaseIndex address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }
     ALWAYS_INLINE void farJump(AbsoluteAddress address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }
 
     ALWAYS_INLINE Call nearCall()
     {
+        invalidateAllTempRegisters();
         m_assembler.bl();
         return Call(m_assembler.label(), Call::LinkableNear);
     }
 
     ALWAYS_INLINE Call nearTailCall()
@@ -3258,10 +3302,11 @@
         return Call(label, Call::LinkableNearTail);
     }
 
     ALWAYS_INLINE Call threadSafePatchableNearCall()
     {
+        invalidateAllTempRegisters();
         m_assembler.bl();
         return Call(m_assembler.label(), Call::LinkableNear);
     }
 
     ALWAYS_INLINE void ret()
@@ -4171,34 +4216,40 @@
             if (dest == memoryTempRegister)
                 cachedMemoryTempRegister().invalidate();
 
             if (isInt<32>(addressDelta)) {
                 if (Assembler::canEncodeSImmOffset(addressDelta)) {
-                    m_assembler.ldur<datasize>(dest,  memoryTempRegister, addressDelta);
+                    loadUnscaledImmediate<datasize>(dest, memoryTempRegister, addressDelta);
                     return;
                 }
 
                 if (Assembler::canEncodePImmOffset<datasize>(addressDelta)) {
-                    m_assembler.ldr<datasize>(dest,  memoryTempRegister, addressDelta);
+                    loadUnsignedImmediate<datasize>(dest, memoryTempRegister, addressDelta);
                     return;
                 }
             }
 
             if ((addressAsInt & (~maskHalfWord0)) == (currentRegisterContents & (~maskHalfWord0))) {
                 m_assembler.movk<64>(memoryTempRegister, addressAsInt & maskHalfWord0, 0);
                 cachedMemoryTempRegister().setValue(reinterpret_cast<intptr_t>(address));
-                m_assembler.ldr<datasize>(dest, memoryTempRegister, ARM64Registers::zr);
+                if constexpr (datasize == 16)
+                    m_assembler.ldrh(dest, memoryTempRegister, ARM64Registers::zr);
+                else
+                    m_assembler.ldr<datasize>(dest, memoryTempRegister, ARM64Registers::zr);
                 return;
             }
         }
 
         move(TrustedImmPtr(address), memoryTempRegister);
         if (dest == memoryTempRegister)
             cachedMemoryTempRegister().invalidate();
         else
             cachedMemoryTempRegister().setValue(reinterpret_cast<intptr_t>(address));
-        m_assembler.ldr<datasize>(dest, memoryTempRegister, ARM64Registers::zr);
+        if constexpr (datasize == 16)
+            m_assembler.ldrh(dest, memoryTempRegister, ARM64Registers::zr);
+        else
+            m_assembler.ldr<datasize>(dest, memoryTempRegister, ARM64Registers::zr);
     }
 
     template<int datasize>
     ALWAYS_INLINE void store(RegisterID src, const void* address)
     {
@@ -4208,31 +4259,37 @@
             intptr_t addressAsInt = reinterpret_cast<intptr_t>(address);
             intptr_t addressDelta = addressAsInt - currentRegisterContents;
 
             if (isInt<32>(addressDelta)) {
                 if (Assembler::canEncodeSImmOffset(addressDelta)) {
-                    m_assembler.stur<datasize>(src, memoryTempRegister, addressDelta);
+                    storeUnscaledImmediate<datasize>(src, memoryTempRegister, addressDelta);
                     return;
                 }
 
                 if (Assembler::canEncodePImmOffset<datasize>(addressDelta)) {
-                    m_assembler.str<datasize>(src, memoryTempRegister, addressDelta);
+                    storeUnsignedImmediate<datasize>(src, memoryTempRegister, addressDelta);
                     return;
                 }
             }
 
             if ((addressAsInt & (~maskHalfWord0)) == (currentRegisterContents & (~maskHalfWord0))) {
                 m_assembler.movk<64>(memoryTempRegister, addressAsInt & maskHalfWord0, 0);
                 cachedMemoryTempRegister().setValue(reinterpret_cast<intptr_t>(address));
-                m_assembler.str<datasize>(src, memoryTempRegister, ARM64Registers::zr);
+                if constexpr (datasize == 16)
+                    m_assembler.strh(src, memoryTempRegister, ARM64Registers::zr);
+                else
+                    m_assembler.str<datasize>(src, memoryTempRegister, ARM64Registers::zr);
                 return;
             }
         }
 
         move(TrustedImmPtr(address), memoryTempRegister);
         cachedMemoryTempRegister().setValue(reinterpret_cast<intptr_t>(address));
-        m_assembler.str<datasize>(src, memoryTempRegister, ARM64Registers::zr);
+        if constexpr (datasize == 16)
+            m_assembler.strh(src, memoryTempRegister, ARM64Registers::zr);
+        else
+            m_assembler.str<datasize>(src, memoryTempRegister, ARM64Registers::zr);
     }
 
     template <int dataSize>
     ALWAYS_INLINE bool tryMoveUsingCacheRegisterContents(intptr_t immediate, CachedTempRegister& dest)
     {
