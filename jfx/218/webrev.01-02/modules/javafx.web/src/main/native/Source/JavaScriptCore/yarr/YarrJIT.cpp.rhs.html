<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/yarr/YarrJIT.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
   2  * Copyright (C) 2009-2018 Apple Inc. All rights reserved.
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;YarrJIT.h&quot;
  28 
  29 #include &lt;wtf/ASCIICType.h&gt;
  30 #include &quot;LinkBuffer.h&quot;
  31 #include &quot;Options.h&quot;
  32 #include &quot;VM.h&quot;
  33 #include &quot;Yarr.h&quot;
  34 #include &quot;YarrCanonicalize.h&quot;
  35 #include &quot;YarrDisassembler.h&quot;
  36 
  37 #if ENABLE(YARR_JIT)
  38 
  39 namespace JSC { namespace Yarr {
  40 
  41 template&lt;YarrJITCompileMode compileMode&gt;
  42 class YarrGenerator : public YarrJITInfo, private MacroAssembler {
  43 
  44 #if CPU(ARM_THUMB2)
  45     static const RegisterID input = ARMRegisters::r0;
  46     static const RegisterID index = ARMRegisters::r1;
  47     static const RegisterID length = ARMRegisters::r2;
  48     static const RegisterID output = ARMRegisters::r3;
  49 
  50     static const RegisterID regT0 = ARMRegisters::r4;
  51     static const RegisterID regT1 = ARMRegisters::r5;
  52     static const RegisterID initialStart = ARMRegisters::r8;
  53 
  54     static const RegisterID returnRegister = ARMRegisters::r0;
  55     static const RegisterID returnRegister2 = ARMRegisters::r1;
  56 
<a name="1" id="anc1"></a>
  57 #elif CPU(ARM64)
  58     // Argument registers
  59     static const RegisterID input = ARM64Registers::x0;
  60     static const RegisterID index = ARM64Registers::x1;
  61     static const RegisterID length = ARM64Registers::x2;
  62     static const RegisterID output = ARM64Registers::x3;
  63     static const RegisterID freelistRegister = ARM64Registers::x4;
<a name="2" id="anc2"></a><span class="line-modified">  64     static const RegisterID freelistSizeRegister = ARM64Registers::x5; // Only used during initialization.</span>
  65 
  66     // Scratch registers
  67     static const RegisterID regT0 = ARM64Registers::x6;
  68     static const RegisterID regT1 = ARM64Registers::x7;
  69     static const RegisterID regT2 = ARM64Registers::x8;
  70     static const RegisterID remainingMatchCount = ARM64Registers::x9;
  71     static const RegisterID regUnicodeInputAndTrail = ARM64Registers::x10;
<a name="3" id="anc3"></a><span class="line-added">  72     static const RegisterID unicodeTemp = ARM64Registers::x5;</span>
  73     static const RegisterID initialStart = ARM64Registers::x11;
  74     static const RegisterID supplementaryPlanesBase = ARM64Registers::x12;
  75     static const RegisterID leadingSurrogateTag = ARM64Registers::x13;
  76     static const RegisterID trailingSurrogateTag = ARM64Registers::x14;
  77     static const RegisterID endOfStringAddress = ARM64Registers::x15;
  78 
  79     static const RegisterID returnRegister = ARM64Registers::x0;
  80     static const RegisterID returnRegister2 = ARM64Registers::x1;
  81 
  82     const TrustedImm32 surrogateTagMask = TrustedImm32(0xfffffc00);
<a name="4" id="anc4"></a>
  83 #define JIT_UNICODE_EXPRESSIONS
  84 #elif CPU(MIPS)
  85     static const RegisterID input = MIPSRegisters::a0;
  86     static const RegisterID index = MIPSRegisters::a1;
  87     static const RegisterID length = MIPSRegisters::a2;
  88     static const RegisterID output = MIPSRegisters::a3;
  89 
  90     static const RegisterID regT0 = MIPSRegisters::t4;
  91     static const RegisterID regT1 = MIPSRegisters::t5;
  92     static const RegisterID initialStart = MIPSRegisters::t6;
  93 
  94     static const RegisterID returnRegister = MIPSRegisters::v0;
  95     static const RegisterID returnRegister2 = MIPSRegisters::v1;
  96 
<a name="5" id="anc5"></a>











  97 #elif CPU(X86_64)
  98 #if !OS(WINDOWS)
  99     // Argument registers
 100     static const RegisterID input = X86Registers::edi;
 101     static const RegisterID index = X86Registers::esi;
 102     static const RegisterID length = X86Registers::edx;
 103     static const RegisterID output = X86Registers::ecx;
 104     static const RegisterID freelistRegister = X86Registers::r8;
 105     static const RegisterID freelistSizeRegister = X86Registers::r9; // Only used during initialization.
 106 #else
 107     // If the return value doesn&#39;t fit in 64bits, its destination is pointed by rcx and the parameters are shifted.
 108     // http://msdn.microsoft.com/en-us/library/7572ztz4.aspx
 109     COMPILE_ASSERT(sizeof(MatchResult) &gt; sizeof(void*), MatchResult_does_not_fit_in_64bits);
 110     static const RegisterID input = X86Registers::edx;
 111     static const RegisterID index = X86Registers::r8;
 112     static const RegisterID length = X86Registers::r9;
 113     static const RegisterID output = X86Registers::r10;
 114 #endif
 115 
 116     // Scratch registers
 117     static const RegisterID regT0 = X86Registers::eax;
 118 #if !OS(WINDOWS)
 119     static const RegisterID regT1 = X86Registers::r9;
 120     static const RegisterID regT2 = X86Registers::r10;
 121 #else
 122     static const RegisterID regT1 = X86Registers::ecx;
 123     static const RegisterID regT2 = X86Registers::edi;
 124 #endif
 125 
 126     static const RegisterID initialStart = X86Registers::ebx;
 127 #if !OS(WINDOWS)
 128     static const RegisterID remainingMatchCount = X86Registers::r12;
 129 #else
 130     static const RegisterID remainingMatchCount = X86Registers::esi;
 131 #endif
 132     static const RegisterID regUnicodeInputAndTrail = X86Registers::r13;
<a name="6" id="anc6"></a><span class="line-modified"> 133     static const RegisterID unicodeTemp = X86Registers::r14;</span>
 134     static const RegisterID endOfStringAddress = X86Registers::r15;
 135 
 136     static const RegisterID returnRegister = X86Registers::eax;
 137     static const RegisterID returnRegister2 = X86Registers::edx;
 138 
 139     const TrustedImm32 supplementaryPlanesBase = TrustedImm32(0x10000);
<a name="7" id="anc7"></a><span class="line-added"> 140     const TrustedImm32 leadingSurrogateTag = TrustedImm32(0xd800);</span>
 141     const TrustedImm32 trailingSurrogateTag = TrustedImm32(0xdc00);
 142     const TrustedImm32 surrogateTagMask = TrustedImm32(0xfffffc00);
<a name="8" id="anc8"></a>
 143 #define JIT_UNICODE_EXPRESSIONS
 144 #endif
 145 
 146 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
 147     struct ParenContextSizes {
 148         size_t m_numSubpatterns;
 149         size_t m_frameSlots;
 150 
 151         ParenContextSizes(size_t numSubpatterns, size_t frameSlots)
 152             : m_numSubpatterns(numSubpatterns)
 153             , m_frameSlots(frameSlots)
 154         {
 155         }
 156 
 157         size_t numSubpatterns() { return m_numSubpatterns; }
 158 
 159         size_t frameSlots() { return m_frameSlots; }
 160     };
 161 
 162     struct ParenContext {
 163         struct ParenContext* next;
 164         uint32_t begin;
 165         uint32_t matchAmount;
 166         uintptr_t returnAddress;
 167         struct Subpatterns {
 168             unsigned start;
 169             unsigned end;
 170         } subpatterns[0];
 171         uintptr_t frameSlots[0];
 172 
 173         static size_t sizeFor(ParenContextSizes&amp; parenContextSizes)
 174         {
 175             return sizeof(ParenContext) + sizeof(Subpatterns) * parenContextSizes.numSubpatterns() + sizeof(uintptr_t) * parenContextSizes.frameSlots();
 176         }
 177 
 178         static ptrdiff_t nextOffset()
 179         {
 180             return offsetof(ParenContext, next);
 181         }
 182 
 183         static ptrdiff_t beginOffset()
 184         {
 185             return offsetof(ParenContext, begin);
 186         }
 187 
 188         static ptrdiff_t matchAmountOffset()
 189         {
 190             return offsetof(ParenContext, matchAmount);
 191         }
 192 
 193         static ptrdiff_t returnAddressOffset()
 194         {
 195             return offsetof(ParenContext, returnAddress);
 196         }
 197 
 198         static ptrdiff_t subpatternOffset(size_t subpattern)
 199         {
 200             return offsetof(ParenContext, subpatterns) + (subpattern - 1) * sizeof(Subpatterns);
 201         }
 202 
 203         static ptrdiff_t savedFrameOffset(ParenContextSizes&amp; parenContextSizes)
 204         {
 205             return offsetof(ParenContext, subpatterns) + (parenContextSizes.numSubpatterns()) * sizeof(Subpatterns);
 206         }
 207     };
 208 
 209     void initParenContextFreeList()
 210     {
 211         RegisterID parenContextPointer = regT0;
 212         RegisterID nextParenContextPointer = regT2;
 213 
 214         size_t parenContextSize = ParenContext::sizeFor(m_parenContextSizes);
 215 
 216         parenContextSize = WTF::roundUpToMultipleOf&lt;sizeof(uintptr_t)&gt;(parenContextSize);
 217 
 218         if (parenContextSize &gt; VM::patternContextBufferSize) {
 219             m_failureReason = JITFailureReason::ParenthesisNestedTooDeep;
 220             return;
 221         }
 222 
 223         Jump emptyFreeList = branchTestPtr(Zero, freelistRegister);
 224         move(freelistRegister, parenContextPointer);
 225         addPtr(TrustedImm32(parenContextSize), freelistRegister, nextParenContextPointer);
 226         addPtr(freelistRegister, freelistSizeRegister);
 227         subPtr(TrustedImm32(parenContextSize), freelistSizeRegister);
 228 
 229         Label loopTop(this);
 230         Jump initDone = branchPtr(Above, nextParenContextPointer, freelistSizeRegister);
 231         storePtr(nextParenContextPointer, Address(parenContextPointer, ParenContext::nextOffset()));
 232         move(nextParenContextPointer, parenContextPointer);
 233         addPtr(TrustedImm32(parenContextSize), parenContextPointer, nextParenContextPointer);
 234         jump(loopTop);
 235 
 236         initDone.link(this);
 237         storePtr(TrustedImmPtr(nullptr), Address(parenContextPointer, ParenContext::nextOffset()));
 238         emptyFreeList.link(this);
 239     }
 240 
 241     void allocateParenContext(RegisterID result)
 242     {
 243         m_abortExecution.append(branchTestPtr(Zero, freelistRegister));
 244         sub32(TrustedImm32(1), remainingMatchCount);
 245         m_hitMatchLimit.append(branchTestPtr(Zero, remainingMatchCount));
 246         move(freelistRegister, result);
 247         loadPtr(Address(freelistRegister, ParenContext::nextOffset()), freelistRegister);
 248     }
 249 
 250     void freeParenContext(RegisterID headPtrRegister, RegisterID newHeadPtrRegister)
 251     {
 252         loadPtr(Address(headPtrRegister, ParenContext::nextOffset()), newHeadPtrRegister);
 253         storePtr(freelistRegister, Address(headPtrRegister, ParenContext::nextOffset()));
 254         move(headPtrRegister, freelistRegister);
 255     }
 256 
 257     void saveParenContext(RegisterID parenContextReg, RegisterID tempReg, unsigned firstSubpattern, unsigned lastSubpattern, unsigned subpatternBaseFrameLocation)
 258     {
 259         store32(index, Address(parenContextReg, ParenContext::beginOffset()));
 260         loadFromFrame(subpatternBaseFrameLocation + BackTrackInfoParentheses::matchAmountIndex(), tempReg);
 261         store32(tempReg, Address(parenContextReg, ParenContext::matchAmountOffset()));
 262         loadFromFrame(subpatternBaseFrameLocation + BackTrackInfoParentheses::returnAddressIndex(), tempReg);
 263         storePtr(tempReg, Address(parenContextReg, ParenContext::returnAddressOffset()));
 264         if (compileMode == IncludeSubpatterns) {
 265             for (unsigned subpattern = firstSubpattern; subpattern &lt;= lastSubpattern; subpattern++) {
 266                 loadPtr(Address(output, (subpattern &lt;&lt; 1) * sizeof(unsigned)), tempReg);
 267                 storePtr(tempReg, Address(parenContextReg, ParenContext::subpatternOffset(subpattern)));
 268                 clearSubpatternStart(subpattern);
 269             }
 270         }
 271         subpatternBaseFrameLocation += YarrStackSpaceForBackTrackInfoParentheses;
 272         for (unsigned frameLocation = subpatternBaseFrameLocation; frameLocation &lt; m_parenContextSizes.frameSlots(); frameLocation++) {
 273             loadFromFrame(frameLocation, tempReg);
 274             storePtr(tempReg, Address(parenContextReg, ParenContext::savedFrameOffset(m_parenContextSizes) + frameLocation * sizeof(uintptr_t)));
 275         }
 276     }
 277 
 278     void restoreParenContext(RegisterID parenContextReg, RegisterID tempReg, unsigned firstSubpattern, unsigned lastSubpattern, unsigned subpatternBaseFrameLocation)
 279     {
 280         load32(Address(parenContextReg, ParenContext::beginOffset()), index);
 281         storeToFrame(index, subpatternBaseFrameLocation + BackTrackInfoParentheses::beginIndex());
 282         load32(Address(parenContextReg, ParenContext::matchAmountOffset()), tempReg);
 283         storeToFrame(tempReg, subpatternBaseFrameLocation + BackTrackInfoParentheses::matchAmountIndex());
 284         loadPtr(Address(parenContextReg, ParenContext::returnAddressOffset()), tempReg);
 285         storeToFrame(tempReg, subpatternBaseFrameLocation + BackTrackInfoParentheses::returnAddressIndex());
 286         if (compileMode == IncludeSubpatterns) {
 287             for (unsigned subpattern = firstSubpattern; subpattern &lt;= lastSubpattern; subpattern++) {
 288                 loadPtr(Address(parenContextReg, ParenContext::subpatternOffset(subpattern)), tempReg);
 289                 storePtr(tempReg, Address(output, (subpattern &lt;&lt; 1) * sizeof(unsigned)));
 290             }
 291         }
 292         subpatternBaseFrameLocation += YarrStackSpaceForBackTrackInfoParentheses;
 293         for (unsigned frameLocation = subpatternBaseFrameLocation; frameLocation &lt; m_parenContextSizes.frameSlots(); frameLocation++) {
 294             loadPtr(Address(parenContextReg, ParenContext::savedFrameOffset(m_parenContextSizes) + frameLocation * sizeof(uintptr_t)), tempReg);
 295             storeToFrame(tempReg, frameLocation);
 296         }
 297     }
 298 #endif
 299 
 300     void optimizeAlternative(PatternAlternative* alternative)
 301     {
 302         if (!alternative-&gt;m_terms.size())
 303             return;
 304 
 305         for (unsigned i = 0; i &lt; alternative-&gt;m_terms.size() - 1; ++i) {
 306             PatternTerm&amp; term = alternative-&gt;m_terms[i];
 307             PatternTerm&amp; nextTerm = alternative-&gt;m_terms[i + 1];
 308 
 309             // We can move BMP only character classes after fixed character terms.
 310             if ((term.type == PatternTerm::TypeCharacterClass)
 311                 &amp;&amp; (term.quantityType == QuantifierFixedCount)
 312                 &amp;&amp; (!m_decodeSurrogatePairs || (term.characterClass-&gt;hasOneCharacterSize() &amp;&amp; !term.m_invert))
 313                 &amp;&amp; (nextTerm.type == PatternTerm::TypePatternCharacter)
 314                 &amp;&amp; (nextTerm.quantityType == QuantifierFixedCount)) {
 315                 PatternTerm termCopy = term;
 316                 alternative-&gt;m_terms[i] = nextTerm;
 317                 alternative-&gt;m_terms[i + 1] = termCopy;
 318             }
 319         }
 320     }
 321 
 322     void matchCharacterClassRange(RegisterID character, JumpList&amp; failures, JumpList&amp; matchDest, const CharacterRange* ranges, unsigned count, unsigned* matchIndex, const UChar32* matches, unsigned matchCount)
 323     {
 324         do {
 325             // pick which range we&#39;re going to generate
 326             int which = count &gt;&gt; 1;
 327             char lo = ranges[which].begin;
 328             char hi = ranges[which].end;
 329 
 330             // check if there are any ranges or matches below lo.  If not, just jl to failure -
 331             // if there is anything else to check, check that first, if it falls through jmp to failure.
 332             if ((*matchIndex &lt; matchCount) &amp;&amp; (matches[*matchIndex] &lt; lo)) {
 333                 Jump loOrAbove = branch32(GreaterThanOrEqual, character, Imm32((unsigned short)lo));
 334 
 335                 // generate code for all ranges before this one
 336                 if (which)
 337                     matchCharacterClassRange(character, failures, matchDest, ranges, which, matchIndex, matches, matchCount);
 338 
 339                 while ((*matchIndex &lt; matchCount) &amp;&amp; (matches[*matchIndex] &lt; lo)) {
 340                     matchDest.append(branch32(Equal, character, Imm32((unsigned short)matches[*matchIndex])));
 341                     ++*matchIndex;
 342                 }
 343                 failures.append(jump());
 344 
 345                 loOrAbove.link(this);
 346             } else if (which) {
 347                 Jump loOrAbove = branch32(GreaterThanOrEqual, character, Imm32((unsigned short)lo));
 348 
 349                 matchCharacterClassRange(character, failures, matchDest, ranges, which, matchIndex, matches, matchCount);
 350                 failures.append(jump());
 351 
 352                 loOrAbove.link(this);
 353             } else
 354                 failures.append(branch32(LessThan, character, Imm32((unsigned short)lo)));
 355 
 356             while ((*matchIndex &lt; matchCount) &amp;&amp; (matches[*matchIndex] &lt;= hi))
 357                 ++*matchIndex;
 358 
 359             matchDest.append(branch32(LessThanOrEqual, character, Imm32((unsigned short)hi)));
 360             // fall through to here, the value is above hi.
 361 
 362             // shuffle along &amp; loop around if there are any more matches to handle.
 363             unsigned next = which + 1;
 364             ranges += next;
 365             count -= next;
 366         } while (count);
 367     }
 368 
 369     void matchCharacterClass(RegisterID character, JumpList&amp; matchDest, const CharacterClass* charClass)
 370     {
 371         if (charClass-&gt;m_table &amp;&amp; !m_decodeSurrogatePairs) {
 372             ExtendedAddress tableEntry(character, reinterpret_cast&lt;intptr_t&gt;(charClass-&gt;m_table));
 373             matchDest.append(branchTest8(charClass-&gt;m_tableInverted ? Zero : NonZero, tableEntry));
 374             return;
 375         }
 376 
 377         JumpList unicodeFail;
 378         if (charClass-&gt;m_matchesUnicode.size() || charClass-&gt;m_rangesUnicode.size()) {
 379             JumpList isAscii;
 380             if (charClass-&gt;m_matches.size() || charClass-&gt;m_ranges.size())
 381                 isAscii.append(branch32(LessThanOrEqual, character, TrustedImm32(0x7f)));
 382 
 383             if (charClass-&gt;m_matchesUnicode.size()) {
 384                 for (unsigned i = 0; i &lt; charClass-&gt;m_matchesUnicode.size(); ++i) {
 385                     UChar32 ch = charClass-&gt;m_matchesUnicode[i];
 386                     matchDest.append(branch32(Equal, character, Imm32(ch)));
 387                 }
 388             }
 389 
 390             if (charClass-&gt;m_rangesUnicode.size()) {
 391                 for (unsigned i = 0; i &lt; charClass-&gt;m_rangesUnicode.size(); ++i) {
 392                     UChar32 lo = charClass-&gt;m_rangesUnicode[i].begin;
 393                     UChar32 hi = charClass-&gt;m_rangesUnicode[i].end;
 394 
 395                     Jump below = branch32(LessThan, character, Imm32(lo));
 396                     matchDest.append(branch32(LessThanOrEqual, character, Imm32(hi)));
 397                     below.link(this);
 398                 }
 399             }
 400 
 401             if (charClass-&gt;m_matches.size() || charClass-&gt;m_ranges.size())
 402                 unicodeFail = jump();
 403             isAscii.link(this);
 404         }
 405 
 406         if (charClass-&gt;m_ranges.size()) {
 407             unsigned matchIndex = 0;
 408             JumpList failures;
 409             matchCharacterClassRange(character, failures, matchDest, charClass-&gt;m_ranges.begin(), charClass-&gt;m_ranges.size(), &amp;matchIndex, charClass-&gt;m_matches.begin(), charClass-&gt;m_matches.size());
 410             while (matchIndex &lt; charClass-&gt;m_matches.size())
 411                 matchDest.append(branch32(Equal, character, Imm32((unsigned short)charClass-&gt;m_matches[matchIndex++])));
 412 
 413             failures.link(this);
 414         } else if (charClass-&gt;m_matches.size()) {
 415             // optimization: gather &#39;a&#39;,&#39;A&#39; etc back together, can mask &amp; test once.
 416             Vector&lt;char&gt; matchesAZaz;
 417 
 418             for (unsigned i = 0; i &lt; charClass-&gt;m_matches.size(); ++i) {
 419                 char ch = charClass-&gt;m_matches[i];
 420                 if (m_pattern.ignoreCase()) {
 421                     if (isASCIILower(ch)) {
 422                         matchesAZaz.append(ch);
 423                         continue;
 424                     }
 425                     if (isASCIIUpper(ch))
 426                         continue;
 427                 }
 428                 matchDest.append(branch32(Equal, character, Imm32((unsigned short)ch)));
 429             }
 430 
 431             if (unsigned countAZaz = matchesAZaz.size()) {
 432                 or32(TrustedImm32(32), character);
 433                 for (unsigned i = 0; i &lt; countAZaz; ++i)
 434                     matchDest.append(branch32(Equal, character, TrustedImm32(matchesAZaz[i])));
 435             }
 436         }
 437 
 438         if (charClass-&gt;m_matchesUnicode.size() || charClass-&gt;m_rangesUnicode.size())
 439             unicodeFail.link(this);
 440     }
 441 
 442 #ifdef JIT_UNICODE_EXPRESSIONS
 443     void advanceIndexAfterCharacterClassTermMatch(const PatternTerm* term, JumpList&amp; failuresAfterIncrementingIndex, const RegisterID character)
 444     {
 445         ASSERT(term-&gt;type == PatternTerm::TypeCharacterClass);
 446 
 447         if (term-&gt;isFixedWidthCharacterClass())
 448             add32(TrustedImm32(term-&gt;characterClass-&gt;hasNonBMPCharacters() ? 2 : 1), index);
 449         else {
 450             add32(TrustedImm32(1), index);
 451             Jump isBMPChar = branch32(LessThan, character, supplementaryPlanesBase);
 452             failuresAfterIncrementingIndex.append(atEndOfInput());
 453             add32(TrustedImm32(1), index);
 454             isBMPChar.link(this);
 455         }
 456     }
 457 #endif
 458 
 459     // Jumps if input not available; will have (incorrectly) incremented already!
 460     Jump jumpIfNoAvailableInput(unsigned countToCheck = 0)
 461     {
 462         if (countToCheck)
 463             add32(Imm32(countToCheck), index);
 464         return branch32(Above, index, length);
 465     }
 466 
 467     Jump jumpIfAvailableInput(unsigned countToCheck)
 468     {
 469         add32(Imm32(countToCheck), index);
 470         return branch32(BelowOrEqual, index, length);
 471     }
 472 
 473     Jump checkNotEnoughInput(RegisterID additionalAmount)
 474     {
 475         add32(index, additionalAmount);
 476         return branch32(Above, additionalAmount, length);
 477     }
 478 
 479     Jump checkInput()
 480     {
 481         return branch32(BelowOrEqual, index, length);
 482     }
 483 
 484     Jump atEndOfInput()
 485     {
 486         return branch32(Equal, index, length);
 487     }
 488 
 489     Jump notAtEndOfInput()
 490     {
 491         return branch32(NotEqual, index, length);
 492     }
 493 
 494     BaseIndex negativeOffsetIndexedAddress(Checked&lt;unsigned&gt; negativeCharacterOffset, RegisterID tempReg, RegisterID indexReg = index)
 495     {
 496         RegisterID base = input;
 497 
 498         // BaseIndex() addressing can take a int32_t offset. Given that we can have a regular
 499         // expression that has unsigned character offsets, BaseIndex&#39;s signed offset is insufficient
 500         // for addressing in extreme cases where we might underflow. Therefore we check to see if
 501         // negativeCharacterOffset will underflow directly or after converting for 16 bit characters.
 502         // If so, we do our own address calculating by adjusting the base, using the result register
 503         // as a temp address register.
 504         unsigned maximumNegativeOffsetForCharacterSize = m_charSize == Char8 ? 0x7fffffff : 0x3fffffff;
 505         unsigned offsetAdjustAmount = 0x40000000;
 506         if (negativeCharacterOffset.unsafeGet() &gt; maximumNegativeOffsetForCharacterSize) {
 507             base = tempReg;
 508             move(input, base);
 509             while (negativeCharacterOffset.unsafeGet() &gt; maximumNegativeOffsetForCharacterSize) {
 510                 subPtr(TrustedImm32(offsetAdjustAmount), base);
 511                 if (m_charSize != Char8)
 512                     subPtr(TrustedImm32(offsetAdjustAmount), base);
 513                 negativeCharacterOffset -= offsetAdjustAmount;
 514             }
 515         }
 516 
 517         Checked&lt;int32_t&gt; characterOffset(-static_cast&lt;int32_t&gt;(negativeCharacterOffset.unsafeGet()));
 518 
 519         if (m_charSize == Char8)
 520             return BaseIndex(input, indexReg, TimesOne, (characterOffset * static_cast&lt;int32_t&gt;(sizeof(char))).unsafeGet());
 521 
 522         return BaseIndex(input, indexReg, TimesTwo, (characterOffset * static_cast&lt;int32_t&gt;(sizeof(UChar))).unsafeGet());
 523     }
 524 
 525 #ifdef JIT_UNICODE_EXPRESSIONS
 526     void tryReadUnicodeCharImpl(RegisterID resultReg)
 527     {
 528         ASSERT(m_charSize == Char16);
 529 
 530         JumpList notUnicode;
 531 
 532         load16Unaligned(regUnicodeInputAndTrail, resultReg);
<a name="9" id="anc9"></a><span class="line-modified"> 533 </span>
<span class="line-modified"> 534         // Is the character a leading surrogate?</span>
<span class="line-added"> 535         and32(surrogateTagMask, resultReg, unicodeTemp);</span>
<span class="line-added"> 536         notUnicode.append(branch32(NotEqual, unicodeTemp, leadingSurrogateTag));</span>
<span class="line-added"> 537 </span>
<span class="line-added"> 538         // Is the input long enough to read a trailing surrogate?</span>
 539         addPtr(TrustedImm32(2), regUnicodeInputAndTrail);
 540         notUnicode.append(branchPtr(AboveOrEqual, regUnicodeInputAndTrail, endOfStringAddress));
<a name="10" id="anc10"></a><span class="line-added"> 541 </span>
<span class="line-added"> 542         // Is the character a trailing surrogate?</span>
 543         load16Unaligned(Address(regUnicodeInputAndTrail), regUnicodeInputAndTrail);
<a name="11" id="anc11"></a><span class="line-modified"> 544         and32(surrogateTagMask, regUnicodeInputAndTrail, unicodeTemp);</span>
<span class="line-modified"> 545         notUnicode.append(branch32(NotEqual, unicodeTemp, trailingSurrogateTag));</span>
<span class="line-modified"> 546 </span>
<span class="line-modified"> 547         // Combine leading and trailing surrogates to produce a code point.</span>
 548         lshift32(TrustedImm32(10), resultReg);
<a name="12" id="anc12"></a><span class="line-modified"> 549         getEffectiveAddress(BaseIndex(resultReg, regUnicodeInputAndTrail, TimesOne, -U16_SURROGATE_OFFSET), resultReg);</span>

 550         notUnicode.link(this);
 551     }
 552 
 553     void tryReadUnicodeChar(BaseIndex address, RegisterID resultReg)
 554     {
 555         ASSERT(m_charSize == Char16);
 556 
 557         getEffectiveAddress(address, regUnicodeInputAndTrail);
 558 
 559         if (resultReg == regT0)
 560             m_tryReadUnicodeCharacterCalls.append(nearCall());
 561         else
 562             tryReadUnicodeCharImpl(resultReg);
 563     }
 564 #endif
 565 
<a name="13" id="anc13"></a>









 566     void readCharacter(Checked&lt;unsigned&gt; negativeCharacterOffset, RegisterID resultReg, RegisterID indexReg = index)
 567     {
 568         BaseIndex address = negativeOffsetIndexedAddress(negativeCharacterOffset, resultReg, indexReg);
 569 
 570         if (m_charSize == Char8)
 571             load8(address, resultReg);
 572 #ifdef JIT_UNICODE_EXPRESSIONS
 573         else if (m_decodeSurrogatePairs)
 574             tryReadUnicodeChar(address, resultReg);
 575 #endif
 576         else
 577             load16Unaligned(address, resultReg);
 578     }
 579 
 580     Jump jumpIfCharNotEquals(UChar32 ch, Checked&lt;unsigned&gt; negativeCharacterOffset, RegisterID character)
 581     {
 582         readCharacter(negativeCharacterOffset, character);
 583 
 584         // For case-insesitive compares, non-ascii characters that have different
 585         // upper &amp; lower case representations are converted to a character class.
 586         ASSERT(!m_pattern.ignoreCase() || isASCIIAlpha(ch) || isCanonicallyUnique(ch, m_canonicalMode));
 587         if (m_pattern.ignoreCase() &amp;&amp; isASCIIAlpha(ch)) {
 588             or32(TrustedImm32(0x20), character);
 589             ch |= 0x20;
 590         }
 591 
 592         return branch32(NotEqual, character, Imm32(ch));
 593     }
 594 
 595     void storeToFrame(RegisterID reg, unsigned frameLocation)
 596     {
 597         poke(reg, frameLocation);
 598     }
 599 
 600     void storeToFrame(TrustedImm32 imm, unsigned frameLocation)
 601     {
 602         poke(imm, frameLocation);
 603     }
 604 
 605 #if CPU(ARM64) || CPU(X86_64)
 606     void storeToFrame(TrustedImmPtr imm, unsigned frameLocation)
 607     {
 608         poke(imm, frameLocation);
 609     }
 610 #endif
 611 
 612     DataLabelPtr storeToFrameWithPatch(unsigned frameLocation)
 613     {
 614         return storePtrWithPatch(TrustedImmPtr(nullptr), Address(stackPointerRegister, frameLocation * sizeof(void*)));
 615     }
 616 
 617     void loadFromFrame(unsigned frameLocation, RegisterID reg)
 618     {
 619         peek(reg, frameLocation);
 620     }
 621 
 622     void loadFromFrameAndJump(unsigned frameLocation)
 623     {
 624         farJump(Address(stackPointerRegister, frameLocation * sizeof(void*)), YarrBacktrackPtrTag);
 625     }
 626 
 627     unsigned alignCallFrameSizeInBytes(unsigned callFrameSize)
 628     {
 629         if (!callFrameSize)
 630             return 0;
 631 
 632         callFrameSize *= sizeof(void*);
 633         if (callFrameSize / sizeof(void*) != m_pattern.m_body-&gt;m_callFrameSize)
 634             CRASH();
 635         callFrameSize = (callFrameSize + 0x3f) &amp; ~0x3f;
 636         return callFrameSize;
 637     }
 638     void initCallFrame()
 639     {
 640         unsigned callFrameSizeInBytes = alignCallFrameSizeInBytes(m_pattern.m_body-&gt;m_callFrameSize);
<a name="14" id="anc14"></a><span class="line-modified"> 641         if (callFrameSizeInBytes)</span>
<span class="line-modified"> 642             subPtr(Imm32(callFrameSizeInBytes), stackPointerRegister);</span>























 643     }
 644     void removeCallFrame()
 645     {
 646         unsigned callFrameSizeInBytes = alignCallFrameSizeInBytes(m_pattern.m_body-&gt;m_callFrameSize);
 647         if (callFrameSizeInBytes)
 648             addPtr(Imm32(callFrameSizeInBytes), stackPointerRegister);
 649     }
 650 
 651     void generateFailReturn()
 652     {
 653         move(TrustedImmPtr((void*)WTF::notFound), returnRegister);
 654         move(TrustedImm32(0), returnRegister2);
 655         generateReturn();
 656     }
 657 
 658     void generateJITFailReturn()
 659     {
 660         if (m_abortExecution.empty() &amp;&amp; m_hitMatchLimit.empty())
 661             return;
 662 
 663         JumpList finishExiting;
 664         if (!m_abortExecution.empty()) {
 665             m_abortExecution.link(this);
 666             move(TrustedImmPtr((void*)static_cast&lt;size_t&gt;(-2)), returnRegister);
 667             finishExiting.append(jump());
 668         }
 669 
 670         if (!m_hitMatchLimit.empty()) {
 671             m_hitMatchLimit.link(this);
 672             move(TrustedImmPtr((void*)static_cast&lt;size_t&gt;(-1)), returnRegister);
 673         }
 674 
 675         finishExiting.link(this);
 676         removeCallFrame();
 677         move(TrustedImm32(0), returnRegister2);
 678         generateReturn();
 679     }
 680 
 681     // Used to record subpatterns, should only be called if compileMode is IncludeSubpatterns.
 682     void setSubpatternStart(RegisterID reg, unsigned subpattern)
 683     {
 684         ASSERT(subpattern);
 685         // FIXME: should be able to ASSERT(compileMode == IncludeSubpatterns), but then this function is conditionally NORETURN. :-(
 686         store32(reg, Address(output, (subpattern &lt;&lt; 1) * sizeof(int)));
 687     }
 688     void setSubpatternEnd(RegisterID reg, unsigned subpattern)
 689     {
 690         ASSERT(subpattern);
 691         // FIXME: should be able to ASSERT(compileMode == IncludeSubpatterns), but then this function is conditionally NORETURN. :-(
 692         store32(reg, Address(output, ((subpattern &lt;&lt; 1) + 1) * sizeof(int)));
 693     }
 694     void clearSubpatternStart(unsigned subpattern)
 695     {
 696         ASSERT(subpattern);
 697         // FIXME: should be able to ASSERT(compileMode == IncludeSubpatterns), but then this function is conditionally NORETURN. :-(
 698         store32(TrustedImm32(-1), Address(output, (subpattern &lt;&lt; 1) * sizeof(int)));
 699     }
 700 
 701     void clearMatches(unsigned subpattern, unsigned lastSubpattern)
 702     {
 703         for (; subpattern &lt;= lastSubpattern; subpattern++)
 704             clearSubpatternStart(subpattern);
 705     }
 706 
 707     // We use one of three different strategies to track the start of the current match,
 708     // while matching.
 709     // 1) If the pattern has a fixed size, do nothing! - we calculate the value lazily
 710     //    at the end of matching. This is irrespective of compileMode, and in this case
 711     //    these methods should never be called.
 712     // 2) If we&#39;re compiling IncludeSubpatterns, &#39;output&#39; contains a pointer to an output
 713     //    vector, store the match start in the output vector.
 714     // 3) If we&#39;re compiling MatchOnly, &#39;output&#39; is unused, store the match start directly
 715     //    in this register.
 716     void setMatchStart(RegisterID reg)
 717     {
 718         ASSERT(!m_pattern.m_body-&gt;m_hasFixedSize);
 719         if (compileMode == IncludeSubpatterns)
 720             store32(reg, output);
 721         else
 722             move(reg, output);
 723     }
 724     void getMatchStart(RegisterID reg)
 725     {
 726         ASSERT(!m_pattern.m_body-&gt;m_hasFixedSize);
 727         if (compileMode == IncludeSubpatterns)
 728             load32(output, reg);
 729         else
 730             move(output, reg);
 731     }
 732 
 733     enum YarrOpCode : uint8_t {
 734         // These nodes wrap body alternatives - those in the main disjunction,
 735         // rather than subpatterns or assertions. These are chained together in
 736         // a doubly linked list, with a &#39;begin&#39; node for the first alternative,
 737         // a &#39;next&#39; node for each subsequent alternative, and an &#39;end&#39; node at
 738         // the end. In the case of repeating alternatives, the &#39;end&#39; node also
 739         // has a reference back to &#39;begin&#39;.
 740         OpBodyAlternativeBegin,
 741         OpBodyAlternativeNext,
 742         OpBodyAlternativeEnd,
 743         // Similar to the body alternatives, but used for subpatterns with two
 744         // or more alternatives.
 745         OpNestedAlternativeBegin,
 746         OpNestedAlternativeNext,
 747         OpNestedAlternativeEnd,
 748         // Used for alternatives in subpatterns where there is only a single
 749         // alternative (backtracking is easier in these cases), or for alternatives
 750         // which never need to be backtracked (those in parenthetical assertions,
 751         // terminal subpatterns).
 752         OpSimpleNestedAlternativeBegin,
 753         OpSimpleNestedAlternativeNext,
 754         OpSimpleNestedAlternativeEnd,
 755         // Used to wrap &#39;Once&#39; subpattern matches (quantityMaxCount == 1).
 756         OpParenthesesSubpatternOnceBegin,
 757         OpParenthesesSubpatternOnceEnd,
 758         // Used to wrap &#39;Terminal&#39; subpattern matches (at the end of the regexp).
 759         OpParenthesesSubpatternTerminalBegin,
 760         OpParenthesesSubpatternTerminalEnd,
 761         // Used to wrap generic captured matches
 762         OpParenthesesSubpatternBegin,
 763         OpParenthesesSubpatternEnd,
 764         // Used to wrap parenthetical assertions.
 765         OpParentheticalAssertionBegin,
 766         OpParentheticalAssertionEnd,
 767         // Wraps all simple terms (pattern characters, character classes).
 768         OpTerm,
 769         // Where an expression contains only &#39;once through&#39; body alternatives
 770         // and no repeating ones, this op is used to return match failure.
 771         OpMatchFailed
 772     };
 773 
 774     // This structure is used to hold the compiled opcode information,
 775     // including reference back to the original PatternTerm/PatternAlternatives,
 776     // and JIT compilation data structures.
 777     struct YarrOp {
 778         explicit YarrOp(PatternTerm* term)
 779             : m_term(term)
 780             , m_op(OpTerm)
 781             , m_isDeadCode(false)
 782         {
 783         }
 784 
 785         explicit YarrOp(YarrOpCode op)
 786             : m_op(op)
 787             , m_isDeadCode(false)
 788         {
 789         }
 790 
 791         // For alternatives, this holds the PatternAlternative and doubly linked
 792         // references to this alternative&#39;s siblings. In the case of the
 793         // OpBodyAlternativeEnd node at the end of a section of repeating nodes,
 794         // m_nextOp will reference the OpBodyAlternativeBegin node of the first
 795         // repeating alternative.
 796         PatternAlternative* m_alternative;
 797         size_t m_previousOp;
 798         size_t m_nextOp;
 799 
 800         // The operation, as a YarrOpCode, and also a reference to the PatternTerm.
 801         PatternTerm* m_term;
 802         YarrOpCode m_op;
 803 
 804         // Used to record a set of Jumps out of the generated code, typically
 805         // used for jumps out to backtracking code, and a single reentry back
 806         // into the code for a node (likely where a backtrack will trigger
 807         // rematching).
 808         Label m_reentry;
 809         JumpList m_jumps;
 810 
 811         // Used for backtracking when the prior alternative did not consume any
 812         // characters but matched.
 813         Jump m_zeroLengthMatch;
 814 
 815         // This flag is used to null out the second pattern character, when
 816         // two are fused to match a pair together.
 817         bool m_isDeadCode;
 818 
 819         // Currently used in the case of some of the more complex management of
 820         // &#39;m_checkedOffset&#39;, to cache the offset used in this alternative, to avoid
 821         // recalculating it.
 822         Checked&lt;unsigned&gt; m_checkAdjust;
 823 
 824         // Used by OpNestedAlternativeNext/End to hold the pointer to the
 825         // value that will be pushed into the pattern&#39;s frame to return to,
 826         // upon backtracking back into the disjunction.
 827         DataLabelPtr m_returnAddress;
 828     };
 829 
 830     // BacktrackingState
 831     // This class encapsulates information about the state of code generation
 832     // whilst generating the code for backtracking, when a term fails to match.
 833     // Upon entry to code generation of the backtracking code for a given node,
 834     // the Backtracking state will hold references to all control flow sources
 835     // that are outputs in need of further backtracking from the prior node
 836     // generated (which is the subsequent operation in the regular expression,
 837     // and in the m_ops Vector, since we generated backtracking backwards).
 838     // These references to control flow take the form of:
 839     //  - A jump list of jumps, to be linked to code that will backtrack them
 840     //    further.
 841     //  - A set of DataLabelPtr values, to be populated with values to be
 842     //    treated effectively as return addresses backtracking into complex
 843     //    subpatterns.
 844     //  - A flag indicating that the current sequence of generated code up to
 845     //    this point requires backtracking.
 846     class BacktrackingState {
 847     public:
 848         BacktrackingState()
 849             : m_pendingFallthrough(false)
 850         {
 851         }
 852 
 853         // Add a jump or jumps, a return address, or set the flag indicating
 854         // that the current &#39;fallthrough&#39; control flow requires backtracking.
 855         void append(const Jump&amp; jump)
 856         {
 857             m_laterFailures.append(jump);
 858         }
 859         void append(JumpList&amp; jumpList)
 860         {
 861             m_laterFailures.append(jumpList);
 862         }
 863         void append(const DataLabelPtr&amp; returnAddress)
 864         {
 865             m_pendingReturns.append(returnAddress);
 866         }
 867         void fallthrough()
 868         {
 869             ASSERT(!m_pendingFallthrough);
 870             m_pendingFallthrough = true;
 871         }
 872 
 873         // These methods clear the backtracking state, either linking to the
 874         // current location, a provided label, or copying the backtracking out
 875         // to a JumpList. All actions may require code generation to take place,
 876         // and as such are passed a pointer to the assembler.
 877         void link(MacroAssembler* assembler)
 878         {
 879             if (m_pendingReturns.size()) {
 880                 Label here(assembler);
 881                 for (unsigned i = 0; i &lt; m_pendingReturns.size(); ++i)
 882                     m_backtrackRecords.append(ReturnAddressRecord(m_pendingReturns[i], here));
 883                 m_pendingReturns.clear();
 884             }
 885             m_laterFailures.link(assembler);
 886             m_laterFailures.clear();
 887             m_pendingFallthrough = false;
 888         }
 889         void linkTo(Label label, MacroAssembler* assembler)
 890         {
 891             if (m_pendingReturns.size()) {
 892                 for (unsigned i = 0; i &lt; m_pendingReturns.size(); ++i)
 893                     m_backtrackRecords.append(ReturnAddressRecord(m_pendingReturns[i], label));
 894                 m_pendingReturns.clear();
 895             }
 896             if (m_pendingFallthrough)
 897                 assembler-&gt;jump(label);
 898             m_laterFailures.linkTo(label, assembler);
 899             m_laterFailures.clear();
 900             m_pendingFallthrough = false;
 901         }
 902         void takeBacktracksToJumpList(JumpList&amp; jumpList, MacroAssembler* assembler)
 903         {
 904             if (m_pendingReturns.size()) {
 905                 Label here(assembler);
 906                 for (unsigned i = 0; i &lt; m_pendingReturns.size(); ++i)
 907                     m_backtrackRecords.append(ReturnAddressRecord(m_pendingReturns[i], here));
 908                 m_pendingReturns.clear();
 909                 m_pendingFallthrough = true;
 910             }
 911             if (m_pendingFallthrough)
 912                 jumpList.append(assembler-&gt;jump());
 913             jumpList.append(m_laterFailures);
 914             m_laterFailures.clear();
 915             m_pendingFallthrough = false;
 916         }
 917 
 918         bool isEmpty()
 919         {
 920             return m_laterFailures.empty() &amp;&amp; m_pendingReturns.isEmpty() &amp;&amp; !m_pendingFallthrough;
 921         }
 922 
 923         // Called at the end of code generation to link all return addresses.
 924         void linkDataLabels(LinkBuffer&amp; linkBuffer)
 925         {
 926             ASSERT(isEmpty());
 927             for (unsigned i = 0; i &lt; m_backtrackRecords.size(); ++i)
 928                 linkBuffer.patch(m_backtrackRecords[i].m_dataLabel, linkBuffer.locationOf&lt;YarrBacktrackPtrTag&gt;(m_backtrackRecords[i].m_backtrackLocation));
 929         }
 930 
 931     private:
 932         struct ReturnAddressRecord {
 933             ReturnAddressRecord(DataLabelPtr dataLabel, Label backtrackLocation)
 934                 : m_dataLabel(dataLabel)
 935                 , m_backtrackLocation(backtrackLocation)
 936             {
 937             }
 938 
 939             DataLabelPtr m_dataLabel;
 940             Label m_backtrackLocation;
 941         };
 942 
 943         JumpList m_laterFailures;
 944         bool m_pendingFallthrough;
 945         Vector&lt;DataLabelPtr, 4&gt; m_pendingReturns;
 946         Vector&lt;ReturnAddressRecord, 4&gt; m_backtrackRecords;
 947     };
 948 
 949     // Generation methods:
 950     // ===================
 951 
 952     // This method provides a default implementation of backtracking common
 953     // to many terms; terms commonly jump out of the forwards  matching path
 954     // on any failed conditions, and add these jumps to the m_jumps list. If
 955     // no special handling is required we can often just backtrack to m_jumps.
 956     void backtrackTermDefault(size_t opIndex)
 957     {
 958         YarrOp&amp; op = m_ops[opIndex];
 959         m_backtrackingState.append(op.m_jumps);
 960     }
 961 
 962     void generateAssertionBOL(size_t opIndex)
 963     {
 964         YarrOp&amp; op = m_ops[opIndex];
 965         PatternTerm* term = op.m_term;
 966 
 967         if (m_pattern.multiline()) {
 968             const RegisterID character = regT0;
 969 
 970             JumpList matchDest;
 971             if (!term-&gt;inputPosition)
 972                 matchDest.append(branch32(Equal, index, Imm32(m_checkedOffset.unsafeGet())));
 973 
 974             readCharacter(m_checkedOffset - term-&gt;inputPosition + 1, character);
 975             matchCharacterClass(character, matchDest, m_pattern.newlineCharacterClass());
 976             op.m_jumps.append(jump());
 977 
 978             matchDest.link(this);
 979         } else {
 980             // Erk, really should poison out these alternatives early. :-/
 981             if (term-&gt;inputPosition)
 982                 op.m_jumps.append(jump());
 983             else
 984                 op.m_jumps.append(branch32(NotEqual, index, Imm32(m_checkedOffset.unsafeGet())));
 985         }
 986     }
 987     void backtrackAssertionBOL(size_t opIndex)
 988     {
 989         backtrackTermDefault(opIndex);
 990     }
 991 
 992     void generateAssertionEOL(size_t opIndex)
 993     {
 994         YarrOp&amp; op = m_ops[opIndex];
 995         PatternTerm* term = op.m_term;
 996 
 997         if (m_pattern.multiline()) {
 998             const RegisterID character = regT0;
 999 
1000             JumpList matchDest;
1001             if (term-&gt;inputPosition == m_checkedOffset.unsafeGet())
1002                 matchDest.append(atEndOfInput());
1003 
1004             readCharacter(m_checkedOffset - term-&gt;inputPosition, character);
1005             matchCharacterClass(character, matchDest, m_pattern.newlineCharacterClass());
1006             op.m_jumps.append(jump());
1007 
1008             matchDest.link(this);
1009         } else {
1010             if (term-&gt;inputPosition == m_checkedOffset.unsafeGet())
1011                 op.m_jumps.append(notAtEndOfInput());
1012             // Erk, really should poison out these alternatives early. :-/
1013             else
1014                 op.m_jumps.append(jump());
1015         }
1016     }
1017     void backtrackAssertionEOL(size_t opIndex)
1018     {
1019         backtrackTermDefault(opIndex);
1020     }
1021 
1022     // Also falls though on nextIsNotWordChar.
1023     void matchAssertionWordchar(size_t opIndex, JumpList&amp; nextIsWordChar, JumpList&amp; nextIsNotWordChar)
1024     {
1025         YarrOp&amp; op = m_ops[opIndex];
1026         PatternTerm* term = op.m_term;
1027 
1028         const RegisterID character = regT0;
1029 
1030         if (term-&gt;inputPosition == m_checkedOffset.unsafeGet())
1031             nextIsNotWordChar.append(atEndOfInput());
1032 
1033         readCharacter(m_checkedOffset - term-&gt;inputPosition, character);
1034 
1035         CharacterClass* wordcharCharacterClass;
1036 
1037         if (m_unicodeIgnoreCase)
1038             wordcharCharacterClass = m_pattern.wordUnicodeIgnoreCaseCharCharacterClass();
1039         else
1040             wordcharCharacterClass = m_pattern.wordcharCharacterClass();
1041 
1042         matchCharacterClass(character, nextIsWordChar, wordcharCharacterClass);
1043     }
1044 
1045     void generateAssertionWordBoundary(size_t opIndex)
1046     {
1047         YarrOp&amp; op = m_ops[opIndex];
1048         PatternTerm* term = op.m_term;
1049 
1050         const RegisterID character = regT0;
1051 
1052         Jump atBegin;
1053         JumpList matchDest;
1054         if (!term-&gt;inputPosition)
1055             atBegin = branch32(Equal, index, Imm32(m_checkedOffset.unsafeGet()));
1056         readCharacter(m_checkedOffset - term-&gt;inputPosition + 1, character);
1057 
1058         CharacterClass* wordcharCharacterClass;
1059 
1060         if (m_unicodeIgnoreCase)
1061             wordcharCharacterClass = m_pattern.wordUnicodeIgnoreCaseCharCharacterClass();
1062         else
1063             wordcharCharacterClass = m_pattern.wordcharCharacterClass();
1064 
1065         matchCharacterClass(character, matchDest, wordcharCharacterClass);
1066         if (!term-&gt;inputPosition)
1067             atBegin.link(this);
1068 
1069         // We fall through to here if the last character was not a wordchar.
1070         JumpList nonWordCharThenWordChar;
1071         JumpList nonWordCharThenNonWordChar;
1072         if (term-&gt;invert()) {
1073             matchAssertionWordchar(opIndex, nonWordCharThenNonWordChar, nonWordCharThenWordChar);
1074             nonWordCharThenWordChar.append(jump());
1075         } else {
1076             matchAssertionWordchar(opIndex, nonWordCharThenWordChar, nonWordCharThenNonWordChar);
1077             nonWordCharThenNonWordChar.append(jump());
1078         }
1079         op.m_jumps.append(nonWordCharThenNonWordChar);
1080 
1081         // We jump here if the last character was a wordchar.
1082         matchDest.link(this);
1083         JumpList wordCharThenWordChar;
1084         JumpList wordCharThenNonWordChar;
1085         if (term-&gt;invert()) {
1086             matchAssertionWordchar(opIndex, wordCharThenNonWordChar, wordCharThenWordChar);
1087             wordCharThenWordChar.append(jump());
1088         } else {
1089             matchAssertionWordchar(opIndex, wordCharThenWordChar, wordCharThenNonWordChar);
1090             // This can fall-though!
1091         }
1092 
1093         op.m_jumps.append(wordCharThenWordChar);
1094 
1095         nonWordCharThenWordChar.link(this);
1096         wordCharThenNonWordChar.link(this);
1097     }
1098     void backtrackAssertionWordBoundary(size_t opIndex)
1099     {
1100         backtrackTermDefault(opIndex);
1101     }
1102 
1103 #if ENABLE(YARR_JIT_BACKREFERENCES)
1104     void matchBackreference(size_t opIndex, JumpList&amp; characterMatchFails, RegisterID character, RegisterID patternIndex, RegisterID patternCharacter)
1105     {
1106         YarrOp&amp; op = m_ops[opIndex];
1107         PatternTerm* term = op.m_term;
1108         unsigned subpatternId = term-&gt;backReferenceSubpatternId;
1109 
1110         Label loop(this);
1111 
<a name="15" id="anc15"></a><span class="line-modified">1112         readCharacter(0, patternCharacter, patternIndex);</span>
<span class="line-modified">1113         readCharacter(m_checkedOffset - term-&gt;inputPosition, character);</span>
1114 
1115         if (!m_pattern.ignoreCase())
1116             characterMatchFails.append(branch32(NotEqual, character, patternCharacter));
1117         else {
1118             Jump charactersMatch = branch32(Equal, character, patternCharacter);
1119             ExtendedAddress characterTableEntry(character, reinterpret_cast&lt;intptr_t&gt;(&amp;canonicalTableLChar));
1120             load16(characterTableEntry, character);
1121             ExtendedAddress patternTableEntry(patternCharacter, reinterpret_cast&lt;intptr_t&gt;(&amp;canonicalTableLChar));
1122             load16(patternTableEntry, patternCharacter);
1123             characterMatchFails.append(branch32(NotEqual, character, patternCharacter));
1124             charactersMatch.link(this);
1125         }
1126 
<a name="16" id="anc16"></a>
1127         add32(TrustedImm32(1), index);
1128         add32(TrustedImm32(1), patternIndex);
1129 
<a name="17" id="anc17"></a><span class="line-added">1130         if (m_decodeSurrogatePairs) {</span>
<span class="line-added">1131             Jump isBMPChar = branch32(LessThan, character, supplementaryPlanesBase);</span>
<span class="line-added">1132             add32(TrustedImm32(1), index);</span>
<span class="line-added">1133             add32(TrustedImm32(1), patternIndex);</span>
<span class="line-added">1134             isBMPChar.link(this);</span>
<span class="line-added">1135         }</span>
<span class="line-added">1136 </span>
1137         branch32(NotEqual, patternIndex, Address(output, ((subpatternId &lt;&lt; 1) + 1) * sizeof(int))).linkTo(loop, this);
1138     }
1139 
1140     void generateBackReference(size_t opIndex)
1141     {
1142         YarrOp&amp; op = m_ops[opIndex];
1143         PatternTerm* term = op.m_term;
1144 
1145         if (m_pattern.ignoreCase() &amp;&amp; m_charSize != Char8) {
1146             m_failureReason = JITFailureReason::BackReference;
1147             return;
1148         }
1149 
1150         unsigned subpatternId = term-&gt;backReferenceSubpatternId;
1151         unsigned parenthesesFrameLocation = term-&gt;frameLocation;
1152 
1153         const RegisterID characterOrTemp = regT0;
1154         const RegisterID patternIndex = regT1;
1155         const RegisterID patternTemp = regT2;
1156 
1157         storeToFrame(index, parenthesesFrameLocation + BackTrackInfoBackReference::beginIndex());
1158         if (term-&gt;quantityType != QuantifierFixedCount || term-&gt;quantityMaxCount != 1)
1159             storeToFrame(TrustedImm32(0), parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex());
1160 
1161         JumpList matches;
1162 
1163         if (term-&gt;quantityType != QuantifierNonGreedy) {
1164             load32(Address(output, (subpatternId &lt;&lt; 1) * sizeof(int)), patternIndex);
1165             load32(Address(output, ((subpatternId &lt;&lt; 1) + 1) * sizeof(int)), patternTemp);
1166 
1167             // An empty match is successful without consuming characters
1168             if (term-&gt;quantityType != QuantifierFixedCount || term-&gt;quantityMaxCount != 1) {
1169                 matches.append(branch32(Equal, TrustedImm32(-1), patternIndex));
1170                 matches.append(branch32(Equal, patternIndex, patternTemp));
1171             } else {
1172                 Jump zeroLengthMatch = branch32(Equal, TrustedImm32(-1), patternIndex);
1173                 Jump tryNonZeroMatch = branch32(NotEqual, patternIndex, patternTemp);
1174                 zeroLengthMatch.link(this);
1175                 storeToFrame(TrustedImm32(1), parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex());
1176                 matches.append(jump());
1177                 tryNonZeroMatch.link(this);
1178             }
1179         }
1180 
1181         switch (term-&gt;quantityType) {
1182         case QuantifierFixedCount: {
1183             Label outerLoop(this);
1184 
1185             // PatternTemp should contain pattern end index at this point
1186             sub32(patternIndex, patternTemp);
1187             op.m_jumps.append(checkNotEnoughInput(patternTemp));
1188 
1189             matchBackreference(opIndex, op.m_jumps, characterOrTemp, patternIndex, patternTemp);
1190 
1191             if (term-&gt;quantityMaxCount != 1) {
1192                 loadFromFrame(parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex(), characterOrTemp);
1193                 add32(TrustedImm32(1), characterOrTemp);
1194                 storeToFrame(characterOrTemp, parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex());
1195                 matches.append(branch32(Equal, Imm32(term-&gt;quantityMaxCount.unsafeGet()), characterOrTemp));
1196                 load32(Address(output, (subpatternId &lt;&lt; 1) * sizeof(int)), patternIndex);
1197                 load32(Address(output, ((subpatternId &lt;&lt; 1) + 1) * sizeof(int)), patternTemp);
1198                 jump(outerLoop);
1199             }
1200             matches.link(this);
1201             break;
1202         }
1203 
1204         case QuantifierGreedy: {
1205             JumpList incompleteMatches;
1206 
1207             Label outerLoop(this);
1208 
1209             // PatternTemp should contain pattern end index at this point
1210             sub32(patternIndex, patternTemp);
1211             matches.append(checkNotEnoughInput(patternTemp));
1212 
1213             matchBackreference(opIndex, incompleteMatches, characterOrTemp, patternIndex, patternTemp);
1214 
1215             loadFromFrame(parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex(), characterOrTemp);
1216             add32(TrustedImm32(1), characterOrTemp);
1217             storeToFrame(characterOrTemp, parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex());
1218             if (term-&gt;quantityMaxCount != quantifyInfinite)
1219                 matches.append(branch32(Equal, Imm32(term-&gt;quantityMaxCount.unsafeGet()), characterOrTemp));
1220             load32(Address(output, (subpatternId &lt;&lt; 1) * sizeof(int)), patternIndex);
1221             load32(Address(output, ((subpatternId &lt;&lt; 1) + 1) * sizeof(int)), patternTemp);
1222 
1223             // Store current index in frame for restoring after a partial match
1224             storeToFrame(index, parenthesesFrameLocation + BackTrackInfoBackReference::beginIndex());
1225             jump(outerLoop);
1226 
1227             incompleteMatches.link(this);
1228             loadFromFrame(parenthesesFrameLocation + BackTrackInfoBackReference::beginIndex(), index);
1229 
1230             matches.link(this);
1231             op.m_reentry = label();
1232             break;
1233         }
1234 
1235         case QuantifierNonGreedy: {
1236             JumpList incompleteMatches;
1237 
1238             matches.append(jump());
1239 
1240             op.m_reentry = label();
1241 
1242             load32(Address(output, (subpatternId &lt;&lt; 1) * sizeof(int)), patternIndex);
1243             load32(Address(output, ((subpatternId &lt;&lt; 1) + 1) * sizeof(int)), patternTemp);
1244 
1245             // An empty match is successful without consuming characters
1246             Jump zeroLengthMatch = branch32(Equal, TrustedImm32(-1), patternIndex);
1247             Jump tryNonZeroMatch = branch32(NotEqual, patternIndex, patternTemp);
1248             zeroLengthMatch.link(this);
1249             storeToFrame(TrustedImm32(1), parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex());
1250             matches.append(jump());
1251             tryNonZeroMatch.link(this);
1252 
1253             // Check if we have input remaining to match
1254             sub32(patternIndex, patternTemp);
1255             matches.append(checkNotEnoughInput(patternTemp));
1256 
1257             storeToFrame(index, parenthesesFrameLocation + BackTrackInfoBackReference::beginIndex());
1258 
1259             matchBackreference(opIndex, incompleteMatches, characterOrTemp, patternIndex, patternTemp);
1260 
1261             matches.append(jump());
1262 
1263             incompleteMatches.link(this);
1264             loadFromFrame(parenthesesFrameLocation + BackTrackInfoBackReference::beginIndex(), index);
1265 
1266             matches.link(this);
1267             break;
1268         }
1269         }
1270     }
1271     void backtrackBackReference(size_t opIndex)
1272     {
1273         YarrOp&amp; op = m_ops[opIndex];
1274         PatternTerm* term = op.m_term;
1275 
1276         unsigned subpatternId = term-&gt;backReferenceSubpatternId;
1277 
1278         m_backtrackingState.link(this);
1279         op.m_jumps.link(this);
1280 
1281         JumpList failures;
1282 
1283         unsigned parenthesesFrameLocation = term-&gt;frameLocation;
1284         switch (term-&gt;quantityType) {
1285         case QuantifierFixedCount:
1286             loadFromFrame(parenthesesFrameLocation + BackTrackInfoBackReference::beginIndex(), index);
1287             break;
1288 
1289         case QuantifierGreedy: {
1290             const RegisterID matchAmount = regT0;
1291             const RegisterID patternStartIndex = regT1;
1292             const RegisterID patternEndIndexOrLen = regT2;
1293 
1294             loadFromFrame(parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex(), matchAmount);
1295             failures.append(branchTest32(Zero, matchAmount));
1296 
1297             load32(Address(output, (subpatternId &lt;&lt; 1) * sizeof(int)), patternStartIndex);
1298             load32(Address(output, ((subpatternId &lt;&lt; 1) + 1) * sizeof(int)), patternEndIndexOrLen);
1299             sub32(patternStartIndex, patternEndIndexOrLen);
1300             sub32(patternEndIndexOrLen, index);
1301 
1302             sub32(TrustedImm32(1), matchAmount);
1303             storeToFrame(matchAmount, parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex());
1304             jump(op.m_reentry);
1305             break;
1306         }
1307 
1308         case QuantifierNonGreedy: {
1309             const RegisterID matchAmount = regT0;
1310 
1311             failures.append(atEndOfInput());
1312             loadFromFrame(parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex(), matchAmount);
1313             if (term-&gt;quantityMaxCount != quantifyInfinite)
1314                 failures.append(branch32(AboveOrEqual, Imm32(term-&gt;quantityMaxCount.unsafeGet()), matchAmount));
1315             add32(TrustedImm32(1), matchAmount);
1316             storeToFrame(matchAmount, parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex());
1317             jump(op.m_reentry);
1318             break;
1319         }
1320         }
1321         failures.link(this);
1322         m_backtrackingState.fallthrough();
1323     }
1324 #endif
1325 
1326     void generatePatternCharacterOnce(size_t opIndex)
1327     {
1328         YarrOp&amp; op = m_ops[opIndex];
1329 
1330         if (op.m_isDeadCode)
1331             return;
1332 
1333         // m_ops always ends with a OpBodyAlternativeEnd or OpMatchFailed
1334         // node, so there must always be at least one more node.
1335         ASSERT(opIndex + 1 &lt; m_ops.size());
1336         YarrOp* nextOp = &amp;m_ops[opIndex + 1];
1337 
1338         PatternTerm* term = op.m_term;
1339         UChar32 ch = term-&gt;patternCharacter;
1340 
1341         if (!isLatin1(ch) &amp;&amp; (m_charSize == Char8)) {
1342             // Have a 16 bit pattern character and an 8 bit string - short circuit
1343             op.m_jumps.append(jump());
1344             return;
1345         }
1346 
1347         const RegisterID character = regT0;
1348 #if CPU(X86_64) || CPU(ARM64)
1349         unsigned maxCharactersAtOnce = m_charSize == Char8 ? 8 : 4;
1350 #else
1351         unsigned maxCharactersAtOnce = m_charSize == Char8 ? 4 : 2;
1352 #endif
1353         uint64_t ignoreCaseMask = 0;
1354 #if CPU(BIG_ENDIAN)
1355         uint64_t allCharacters = ch &lt;&lt; (m_charSize == Char8 ? 24 : 16);
1356 #else
1357         uint64_t allCharacters = ch;
1358 #endif
1359         unsigned numberCharacters;
1360         unsigned startTermPosition = term-&gt;inputPosition;
1361 
1362         // For case-insesitive compares, non-ascii characters that have different
1363         // upper &amp; lower case representations are converted to a character class.
1364         ASSERT(!m_pattern.ignoreCase() || isASCIIAlpha(ch) || isCanonicallyUnique(ch, m_canonicalMode));
1365 
1366         if (m_pattern.ignoreCase() &amp;&amp; isASCIIAlpha(ch)) {
1367 #if CPU(BIG_ENDIAN)
1368             ignoreCaseMask |= 32 &lt;&lt; (m_charSize == Char8 ? 24 : 16);
1369 #else
1370             ignoreCaseMask |= 32;
1371 #endif
1372         }
1373 
1374         for (numberCharacters = 1; numberCharacters &lt; maxCharactersAtOnce &amp;&amp; nextOp-&gt;m_op == OpTerm; ++numberCharacters, nextOp = &amp;m_ops[opIndex + numberCharacters]) {
1375             PatternTerm* nextTerm = nextOp-&gt;m_term;
1376 
1377             // YarrJIT handles decoded surrogate pair as one character if unicode flag is enabled.
1378             // Note that the numberCharacters become 1 while the width of the pattern character becomes 32bit in this case.
1379             if (nextTerm-&gt;type != PatternTerm::TypePatternCharacter
1380                 || nextTerm-&gt;quantityType != QuantifierFixedCount
1381                 || nextTerm-&gt;quantityMaxCount != 1
1382                 || nextTerm-&gt;inputPosition != (startTermPosition + numberCharacters)
1383                 || (U16_LENGTH(nextTerm-&gt;patternCharacter) != 1 &amp;&amp; m_decodeSurrogatePairs))
1384                 break;
1385 
1386             nextOp-&gt;m_isDeadCode = true;
1387 
1388 #if CPU(BIG_ENDIAN)
1389             int shiftAmount = (m_charSize == Char8 ? 24 : 16) - ((m_charSize == Char8 ? 8 : 16) * numberCharacters);
1390 #else
1391             int shiftAmount = (m_charSize == Char8 ? 8 : 16) * numberCharacters;
1392 #endif
1393 
1394             UChar32 currentCharacter = nextTerm-&gt;patternCharacter;
1395 
1396             if (!isLatin1(currentCharacter) &amp;&amp; (m_charSize == Char8)) {
1397                 // Have a 16 bit pattern character and an 8 bit string - short circuit
1398                 op.m_jumps.append(jump());
1399                 return;
1400             }
1401 
1402             // For case-insesitive compares, non-ascii characters that have different
1403             // upper &amp; lower case representations are converted to a character class.
1404             ASSERT(!m_pattern.ignoreCase() || isASCIIAlpha(currentCharacter) || isCanonicallyUnique(currentCharacter, m_canonicalMode));
1405 
1406             allCharacters |= (static_cast&lt;uint64_t&gt;(currentCharacter) &lt;&lt; shiftAmount);
1407 
1408             if ((m_pattern.ignoreCase()) &amp;&amp; (isASCIIAlpha(currentCharacter)))
1409                 ignoreCaseMask |= 32ULL &lt;&lt; shiftAmount;
1410         }
1411 
1412         if (m_decodeSurrogatePairs)
1413             op.m_jumps.append(jumpIfNoAvailableInput());
1414 
1415         if (m_charSize == Char8) {
1416             auto check1 = [&amp;] (Checked&lt;unsigned&gt; offset, UChar32 characters) {
1417                 op.m_jumps.append(jumpIfCharNotEquals(characters, offset, character));
1418             };
1419 
1420             auto check2 = [&amp;] (Checked&lt;unsigned&gt; offset, uint16_t characters, uint16_t mask) {
1421                 load16Unaligned(negativeOffsetIndexedAddress(offset, character), character);
1422                 if (mask)
1423                     or32(Imm32(mask), character);
1424                 op.m_jumps.append(branch32(NotEqual, character, Imm32(characters | mask)));
1425             };
1426 
1427             auto check4 = [&amp;] (Checked&lt;unsigned&gt; offset, unsigned characters, unsigned mask) {
1428                 if (mask) {
1429                     load32WithUnalignedHalfWords(negativeOffsetIndexedAddress(offset, character), character);
1430                     if (mask)
1431                         or32(Imm32(mask), character);
1432                     op.m_jumps.append(branch32(NotEqual, character, Imm32(characters | mask)));
1433                     return;
1434                 }
1435                 op.m_jumps.append(branch32WithUnalignedHalfWords(NotEqual, negativeOffsetIndexedAddress(offset, character), TrustedImm32(characters)));
1436             };
1437 
1438 #if CPU(X86_64) || CPU(ARM64)
1439             auto check8 = [&amp;] (Checked&lt;unsigned&gt; offset, uint64_t characters, uint64_t mask) {
1440                 load64(negativeOffsetIndexedAddress(offset, character), character);
1441                 if (mask)
1442                     or64(TrustedImm64(mask), character);
1443                 op.m_jumps.append(branch64(NotEqual, character, TrustedImm64(characters | mask)));
1444             };
1445 #endif
1446 
1447             switch (numberCharacters) {
1448             case 1:
1449                 // Use 32bit width of allCharacters since Yarr counts surrogate pairs as one character with unicode flag.
1450                 check1(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff);
1451                 return;
1452             case 2: {
1453                 check2(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffff, ignoreCaseMask &amp; 0xffff);
1454                 return;
1455             }
1456             case 3: {
1457                 check2(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffff, ignoreCaseMask &amp; 0xffff);
1458                 check1(m_checkedOffset - startTermPosition - 2, (allCharacters &gt;&gt; 16) &amp; 0xff);
1459                 return;
1460             }
1461             case 4: {
1462                 check4(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff, ignoreCaseMask &amp; 0xffffffff);
1463                 return;
1464             }
1465 #if CPU(X86_64) || CPU(ARM64)
1466             case 5: {
1467                 check4(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff, ignoreCaseMask &amp; 0xffffffff);
1468                 check1(m_checkedOffset - startTermPosition - 4, (allCharacters &gt;&gt; 32) &amp; 0xff);
1469                 return;
1470             }
1471             case 6: {
1472                 check4(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff, ignoreCaseMask &amp; 0xffffffff);
1473                 check2(m_checkedOffset - startTermPosition - 4, (allCharacters &gt;&gt; 32) &amp; 0xffff, (ignoreCaseMask &gt;&gt; 32) &amp; 0xffff);
1474                 return;
1475             }
1476             case 7: {
1477                 check4(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff, ignoreCaseMask &amp; 0xffffffff);
1478                 check2(m_checkedOffset - startTermPosition - 4, (allCharacters &gt;&gt; 32) &amp; 0xffff, (ignoreCaseMask &gt;&gt; 32) &amp; 0xffff);
1479                 check1(m_checkedOffset - startTermPosition - 6, (allCharacters &gt;&gt; 48) &amp; 0xff);
1480                 return;
1481             }
1482             case 8: {
1483                 check8(m_checkedOffset - startTermPosition, allCharacters, ignoreCaseMask);
1484                 return;
1485             }
1486 #endif
1487             }
1488         } else {
1489             auto check1 = [&amp;] (Checked&lt;unsigned&gt; offset, UChar32 characters) {
1490                 op.m_jumps.append(jumpIfCharNotEquals(characters, offset, character));
1491             };
1492 
1493             auto check2 = [&amp;] (Checked&lt;unsigned&gt; offset, unsigned characters, unsigned mask) {
1494                 if (mask) {
1495                     load32WithUnalignedHalfWords(negativeOffsetIndexedAddress(offset, character), character);
1496                     if (mask)
1497                         or32(Imm32(mask), character);
1498                     op.m_jumps.append(branch32(NotEqual, character, Imm32(characters | mask)));
1499                     return;
1500                 }
1501                 op.m_jumps.append(branch32WithUnalignedHalfWords(NotEqual, negativeOffsetIndexedAddress(offset, character), TrustedImm32(characters)));
1502             };
1503 
1504 #if CPU(X86_64) || CPU(ARM64)
1505             auto check4 = [&amp;] (Checked&lt;unsigned&gt; offset, uint64_t characters, uint64_t mask) {
1506                 load64(negativeOffsetIndexedAddress(offset, character), character);
1507                 if (mask)
1508                     or64(TrustedImm64(mask), character);
1509                 op.m_jumps.append(branch64(NotEqual, character, TrustedImm64(characters | mask)));
1510             };
1511 #endif
1512 
1513             switch (numberCharacters) {
1514             case 1:
1515                 // Use 32bit width of allCharacters since Yarr counts surrogate pairs as one character with unicode flag.
1516                 check1(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff);
1517                 return;
1518             case 2:
1519                 check2(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff, ignoreCaseMask &amp; 0xffffffff);
1520                 return;
1521 #if CPU(X86_64) || CPU(ARM64)
1522             case 3:
1523                 check2(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff, ignoreCaseMask &amp; 0xffffffff);
1524                 check1(m_checkedOffset - startTermPosition - 2, (allCharacters &gt;&gt; 32) &amp; 0xffff);
1525                 return;
1526             case 4:
1527                 check4(m_checkedOffset - startTermPosition, allCharacters, ignoreCaseMask);
1528                 return;
1529 #endif
1530             }
1531         }
1532     }
1533     void backtrackPatternCharacterOnce(size_t opIndex)
1534     {
1535         backtrackTermDefault(opIndex);
1536     }
1537 
1538     void generatePatternCharacterFixed(size_t opIndex)
1539     {
1540         YarrOp&amp; op = m_ops[opIndex];
1541         PatternTerm* term = op.m_term;
1542         UChar32 ch = term-&gt;patternCharacter;
1543 
1544         const RegisterID character = regT0;
1545         const RegisterID countRegister = regT1;
1546 
1547         if (m_decodeSurrogatePairs)
1548             op.m_jumps.append(jumpIfNoAvailableInput());
1549 
1550         move(index, countRegister);
1551         Checked&lt;unsigned&gt; scaledMaxCount = term-&gt;quantityMaxCount;
1552         scaledMaxCount *= U_IS_BMP(ch) ? 1 : 2;
1553         sub32(Imm32(scaledMaxCount.unsafeGet()), countRegister);
1554 
1555         Label loop(this);
1556         readCharacter(m_checkedOffset - term-&gt;inputPosition - scaledMaxCount, character, countRegister);
1557         // For case-insesitive compares, non-ascii characters that have different
1558         // upper &amp; lower case representations are converted to a character class.
1559         ASSERT(!m_pattern.ignoreCase() || isASCIIAlpha(ch) || isCanonicallyUnique(ch, m_canonicalMode));
1560         if (m_pattern.ignoreCase() &amp;&amp; isASCIIAlpha(ch)) {
1561             or32(TrustedImm32(0x20), character);
1562             ch |= 0x20;
1563         }
1564 
1565         op.m_jumps.append(branch32(NotEqual, character, Imm32(ch)));
1566 #ifdef JIT_UNICODE_EXPRESSIONS
1567         if (m_decodeSurrogatePairs &amp;&amp; !U_IS_BMP(ch))
1568             add32(TrustedImm32(2), countRegister);
1569         else
1570 #endif
1571             add32(TrustedImm32(1), countRegister);
1572         branch32(NotEqual, countRegister, index).linkTo(loop, this);
1573     }
1574     void backtrackPatternCharacterFixed(size_t opIndex)
1575     {
1576         backtrackTermDefault(opIndex);
1577     }
1578 
1579     void generatePatternCharacterGreedy(size_t opIndex)
1580     {
1581         YarrOp&amp; op = m_ops[opIndex];
1582         PatternTerm* term = op.m_term;
1583         UChar32 ch = term-&gt;patternCharacter;
1584 
1585         const RegisterID character = regT0;
1586         const RegisterID countRegister = regT1;
1587 
1588         move(TrustedImm32(0), countRegister);
1589 
1590         // Unless have a 16 bit pattern character and an 8 bit string - short circuit
1591         if (!(!isLatin1(ch) &amp;&amp; (m_charSize == Char8))) {
1592             JumpList failures;
1593             Label loop(this);
1594             failures.append(atEndOfInput());
1595             failures.append(jumpIfCharNotEquals(ch, m_checkedOffset - term-&gt;inputPosition, character));
1596 
1597             add32(TrustedImm32(1), index);
1598 #ifdef JIT_UNICODE_EXPRESSIONS
1599             if (m_decodeSurrogatePairs &amp;&amp; !U_IS_BMP(ch)) {
1600                 Jump surrogatePairOk = notAtEndOfInput();
1601                 sub32(TrustedImm32(1), index);
1602                 failures.append(jump());
1603                 surrogatePairOk.link(this);
1604                 add32(TrustedImm32(1), index);
1605             }
1606 #endif
1607             add32(TrustedImm32(1), countRegister);
1608 
1609             if (term-&gt;quantityMaxCount == quantifyInfinite)
1610                 jump(loop);
1611             else
1612                 branch32(NotEqual, countRegister, Imm32(term-&gt;quantityMaxCount.unsafeGet())).linkTo(loop, this);
1613 
1614             failures.link(this);
1615         }
1616         op.m_reentry = label();
1617 
1618         storeToFrame(countRegister, term-&gt;frameLocation + BackTrackInfoPatternCharacter::matchAmountIndex());
1619     }
1620     void backtrackPatternCharacterGreedy(size_t opIndex)
1621     {
1622         YarrOp&amp; op = m_ops[opIndex];
1623         PatternTerm* term = op.m_term;
1624 
1625         const RegisterID countRegister = regT1;
1626 
1627         m_backtrackingState.link(this);
1628 
1629         loadFromFrame(term-&gt;frameLocation + BackTrackInfoPatternCharacter::matchAmountIndex(), countRegister);
1630         m_backtrackingState.append(branchTest32(Zero, countRegister));
1631         sub32(TrustedImm32(1), countRegister);
1632         if (!m_decodeSurrogatePairs || U_IS_BMP(term-&gt;patternCharacter))
1633             sub32(TrustedImm32(1), index);
1634         else
1635             sub32(TrustedImm32(2), index);
1636         jump(op.m_reentry);
1637     }
1638 
1639     void generatePatternCharacterNonGreedy(size_t opIndex)
1640     {
1641         YarrOp&amp; op = m_ops[opIndex];
1642         PatternTerm* term = op.m_term;
1643 
1644         const RegisterID countRegister = regT1;
1645 
1646         move(TrustedImm32(0), countRegister);
1647         op.m_reentry = label();
1648         storeToFrame(countRegister, term-&gt;frameLocation + BackTrackInfoPatternCharacter::matchAmountIndex());
1649     }
1650     void backtrackPatternCharacterNonGreedy(size_t opIndex)
1651     {
1652         YarrOp&amp; op = m_ops[opIndex];
1653         PatternTerm* term = op.m_term;
1654         UChar32 ch = term-&gt;patternCharacter;
1655 
1656         const RegisterID character = regT0;
1657         const RegisterID countRegister = regT1;
1658 
1659         m_backtrackingState.link(this);
1660 
1661         loadFromFrame(term-&gt;frameLocation + BackTrackInfoPatternCharacter::matchAmountIndex(), countRegister);
1662 
1663         // Unless have a 16 bit pattern character and an 8 bit string - short circuit
1664         if (!(!isLatin1(ch) &amp;&amp; (m_charSize == Char8))) {
1665             JumpList nonGreedyFailures;
1666             nonGreedyFailures.append(atEndOfInput());
1667             if (term-&gt;quantityMaxCount != quantifyInfinite)
1668                 nonGreedyFailures.append(branch32(Equal, countRegister, Imm32(term-&gt;quantityMaxCount.unsafeGet())));
1669             nonGreedyFailures.append(jumpIfCharNotEquals(ch, m_checkedOffset - term-&gt;inputPosition, character));
1670 
1671             add32(TrustedImm32(1), index);
1672 #ifdef JIT_UNICODE_EXPRESSIONS
1673             if (m_decodeSurrogatePairs &amp;&amp; !U_IS_BMP(ch)) {
1674                 Jump surrogatePairOk = notAtEndOfInput();
1675                 sub32(TrustedImm32(1), index);
1676                 nonGreedyFailures.append(jump());
1677                 surrogatePairOk.link(this);
1678                 add32(TrustedImm32(1), index);
1679             }
1680 #endif
1681             add32(TrustedImm32(1), countRegister);
1682 
1683             jump(op.m_reentry);
1684             nonGreedyFailures.link(this);
1685         }
1686 
1687         if (m_decodeSurrogatePairs &amp;&amp; !U_IS_BMP(ch)) {
1688             // subtract countRegister*2 for non-BMP characters
1689             lshift32(TrustedImm32(1), countRegister);
1690         }
1691 
1692         sub32(countRegister, index);
1693         m_backtrackingState.fallthrough();
1694     }
1695 
1696     void generateCharacterClassOnce(size_t opIndex)
1697     {
1698         YarrOp&amp; op = m_ops[opIndex];
1699         PatternTerm* term = op.m_term;
1700 
1701         const RegisterID character = regT0;
1702 
1703         if (m_decodeSurrogatePairs) {
1704             op.m_jumps.append(jumpIfNoAvailableInput());
1705             storeToFrame(index, term-&gt;frameLocation + BackTrackInfoCharacterClass::beginIndex());
1706         }
1707 
1708         JumpList matchDest;
1709         readCharacter(m_checkedOffset - term-&gt;inputPosition, character);
1710         // If we are matching the &quot;any character&quot; builtin class we only need to read the
1711         // character and don&#39;t need to match as it will always succeed.
1712         if (term-&gt;invert() || !term-&gt;characterClass-&gt;m_anyCharacter) {
1713             matchCharacterClass(character, matchDest, term-&gt;characterClass);
1714 
1715             if (term-&gt;invert())
1716                 op.m_jumps.append(matchDest);
1717             else {
1718                 op.m_jumps.append(jump());
1719                 matchDest.link(this);
1720             }
1721         }
1722 #ifdef JIT_UNICODE_EXPRESSIONS
1723         if (m_decodeSurrogatePairs &amp;&amp; (!term-&gt;characterClass-&gt;hasOneCharacterSize() || term-&gt;invert())) {
1724             Jump isBMPChar = branch32(LessThan, character, supplementaryPlanesBase);
1725             op.m_jumps.append(atEndOfInput());
1726             add32(TrustedImm32(1), index);
1727             isBMPChar.link(this);
1728         }
1729 #endif
1730     }
1731     void backtrackCharacterClassOnce(size_t opIndex)
1732     {
1733 #ifdef JIT_UNICODE_EXPRESSIONS
1734         if (m_decodeSurrogatePairs) {
1735             YarrOp&amp; op = m_ops[opIndex];
1736             PatternTerm* term = op.m_term;
1737 
1738             m_backtrackingState.link(this);
1739             loadFromFrame(term-&gt;frameLocation + BackTrackInfoCharacterClass::beginIndex(), index);
1740             m_backtrackingState.fallthrough();
1741         }
1742 #endif
1743         backtrackTermDefault(opIndex);
1744     }
1745 
1746     void generateCharacterClassFixed(size_t opIndex)
1747     {
1748         YarrOp&amp; op = m_ops[opIndex];
1749         PatternTerm* term = op.m_term;
1750 
1751         const RegisterID character = regT0;
1752         const RegisterID countRegister = regT1;
1753 
1754         if (m_decodeSurrogatePairs)
1755             op.m_jumps.append(jumpIfNoAvailableInput());
1756 
1757         move(index, countRegister);
1758 
1759         Checked&lt;unsigned&gt; scaledMaxCount = term-&gt;quantityMaxCount;
1760 
1761 #ifdef JIT_UNICODE_EXPRESSIONS
1762         if (m_decodeSurrogatePairs &amp;&amp; term-&gt;characterClass-&gt;hasOnlyNonBMPCharacters() &amp;&amp; !term-&gt;invert())
1763             scaledMaxCount *= 2;
1764 #endif
1765         sub32(Imm32(scaledMaxCount.unsafeGet()), countRegister);
1766 
1767         Label loop(this);
1768         JumpList matchDest;
1769         readCharacter(m_checkedOffset - term-&gt;inputPosition - scaledMaxCount, character, countRegister);
1770         // If we are matching the &quot;any character&quot; builtin class we only need to read the
1771         // character and don&#39;t need to match as it will always succeed.
1772         if (term-&gt;invert() || !term-&gt;characterClass-&gt;m_anyCharacter) {
1773             matchCharacterClass(character, matchDest, term-&gt;characterClass);
1774 
1775             if (term-&gt;invert())
1776                 op.m_jumps.append(matchDest);
1777             else {
1778                 op.m_jumps.append(jump());
1779                 matchDest.link(this);
1780             }
1781         }
1782 
1783 #ifdef JIT_UNICODE_EXPRESSIONS
1784         if (m_decodeSurrogatePairs) {
1785             if (term-&gt;isFixedWidthCharacterClass())
1786                 add32(TrustedImm32(term-&gt;characterClass-&gt;hasNonBMPCharacters() ? 2 : 1), countRegister);
1787             else {
1788                 add32(TrustedImm32(1), countRegister);
1789                 Jump isBMPChar = branch32(LessThan, character, supplementaryPlanesBase);
1790                 op.m_jumps.append(atEndOfInput());
1791                 add32(TrustedImm32(1), countRegister);
1792                 add32(TrustedImm32(1), index);
1793                 isBMPChar.link(this);
1794             }
1795         } else
1796 #endif
1797             add32(TrustedImm32(1), countRegister);
1798         branch32(NotEqual, countRegister, index).linkTo(loop, this);
1799     }
1800     void backtrackCharacterClassFixed(size_t opIndex)
1801     {
1802         backtrackTermDefault(opIndex);
1803     }
1804 
1805     void generateCharacterClassGreedy(size_t opIndex)
1806     {
1807         YarrOp&amp; op = m_ops[opIndex];
1808         PatternTerm* term = op.m_term;
1809 
1810         const RegisterID character = regT0;
1811         const RegisterID countRegister = regT1;
1812 
1813         if (m_decodeSurrogatePairs &amp;&amp; (!term-&gt;characterClass-&gt;hasOneCharacterSize() || term-&gt;invert()))
1814             storeToFrame(index, term-&gt;frameLocation + BackTrackInfoCharacterClass::beginIndex());
1815         move(TrustedImm32(0), countRegister);
1816 
1817         JumpList failures;
1818         JumpList failuresDecrementIndex;
1819         Label loop(this);
1820 #ifdef JIT_UNICODE_EXPRESSIONS
1821         if (term-&gt;isFixedWidthCharacterClass() &amp;&amp; term-&gt;characterClass-&gt;hasNonBMPCharacters()) {
1822             move(TrustedImm32(1), character);
1823             failures.append(checkNotEnoughInput(character));
1824         } else
1825 #endif
1826             failures.append(atEndOfInput());
1827 
1828         if (term-&gt;invert()) {
1829             readCharacter(m_checkedOffset - term-&gt;inputPosition, character);
1830             matchCharacterClass(character, failures, term-&gt;characterClass);
1831         } else {
1832             JumpList matchDest;
1833             readCharacter(m_checkedOffset - term-&gt;inputPosition, character);
1834             // If we are matching the &quot;any character&quot; builtin class for non-unicode patterns,
1835             // we only need to read the character and don&#39;t need to match as it will always succeed.
1836             if (!term-&gt;characterClass-&gt;m_anyCharacter) {
1837                 matchCharacterClass(character, matchDest, term-&gt;characterClass);
1838                 failures.append(jump());
1839             }
1840             matchDest.link(this);
1841         }
1842 
1843 #ifdef JIT_UNICODE_EXPRESSIONS
1844         if (m_decodeSurrogatePairs)
1845             advanceIndexAfterCharacterClassTermMatch(term, failuresDecrementIndex, character);
1846         else
1847 #endif
1848             add32(TrustedImm32(1), index);
1849         add32(TrustedImm32(1), countRegister);
1850 
1851         if (term-&gt;quantityMaxCount != quantifyInfinite) {
1852             branch32(NotEqual, countRegister, Imm32(term-&gt;quantityMaxCount.unsafeGet())).linkTo(loop, this);
1853             failures.append(jump());
1854         } else
1855             jump(loop);
1856 
1857         if (!failuresDecrementIndex.empty()) {
1858             failuresDecrementIndex.link(this);
1859             sub32(TrustedImm32(1), index);
1860         }
1861 
1862         failures.link(this);
1863         op.m_reentry = label();
1864 
1865         storeToFrame(countRegister, term-&gt;frameLocation + BackTrackInfoCharacterClass::matchAmountIndex());
1866     }
1867     void backtrackCharacterClassGreedy(size_t opIndex)
1868     {
1869         YarrOp&amp; op = m_ops[opIndex];
1870         PatternTerm* term = op.m_term;
1871 
1872         const RegisterID countRegister = regT1;
1873 
1874         m_backtrackingState.link(this);
1875 
1876         loadFromFrame(term-&gt;frameLocation + BackTrackInfoCharacterClass::matchAmountIndex(), countRegister);
1877         m_backtrackingState.append(branchTest32(Zero, countRegister));
1878         sub32(TrustedImm32(1), countRegister);
1879         storeToFrame(countRegister, term-&gt;frameLocation + BackTrackInfoCharacterClass::matchAmountIndex());
1880 
1881         if (!m_decodeSurrogatePairs)
1882             sub32(TrustedImm32(1), index);
1883         else if (term-&gt;isFixedWidthCharacterClass())
1884             sub32(TrustedImm32(term-&gt;characterClass-&gt;hasNonBMPCharacters() ? 2 : 1), index);
1885         else {
1886             // Rematch one less
1887             const RegisterID character = regT0;
1888 
1889             loadFromFrame(term-&gt;frameLocation + BackTrackInfoCharacterClass::beginIndex(), index);
1890 
1891             Label rematchLoop(this);
1892             Jump doneRematching = branchTest32(Zero, countRegister);
1893 
1894             readCharacter(m_checkedOffset - term-&gt;inputPosition, character);
1895 
1896             sub32(TrustedImm32(1), countRegister);
1897             add32(TrustedImm32(1), index);
1898 
1899 #ifdef JIT_UNICODE_EXPRESSIONS
1900             Jump isBMPChar = branch32(LessThan, character, supplementaryPlanesBase);
1901             add32(TrustedImm32(1), index);
1902             isBMPChar.link(this);
1903 #endif
1904 
1905             jump(rematchLoop);
1906             doneRematching.link(this);
1907 
1908             loadFromFrame(term-&gt;frameLocation + BackTrackInfoCharacterClass::matchAmountIndex(), countRegister);
1909         }
1910         jump(op.m_reentry);
1911     }
1912 
1913     void generateCharacterClassNonGreedy(size_t opIndex)
1914     {
1915         YarrOp&amp; op = m_ops[opIndex];
1916         PatternTerm* term = op.m_term;
1917 
1918         const RegisterID countRegister = regT1;
1919 
1920         move(TrustedImm32(0), countRegister);
1921         op.m_reentry = label();
1922 
1923 #ifdef JIT_UNICODE_EXPRESSIONS
1924         if (m_decodeSurrogatePairs) {
1925             if (!term-&gt;characterClass-&gt;hasOneCharacterSize() || term-&gt;invert())
1926                 storeToFrame(index, term-&gt;frameLocation + BackTrackInfoCharacterClass::beginIndex());
1927         }
1928 #endif
1929 
1930         storeToFrame(countRegister, term-&gt;frameLocation + BackTrackInfoCharacterClass::matchAmountIndex());
1931     }
1932 
1933     void backtrackCharacterClassNonGreedy(size_t opIndex)
1934     {
1935         YarrOp&amp; op = m_ops[opIndex];
1936         PatternTerm* term = op.m_term;
1937 
1938         const RegisterID character = regT0;
1939         const RegisterID countRegister = regT1;
1940 
1941         JumpList nonGreedyFailures;
1942         JumpList nonGreedyFailuresDecrementIndex;
1943 
1944         m_backtrackingState.link(this);
1945 
1946 #ifdef JIT_UNICODE_EXPRESSIONS
1947         if (m_decodeSurrogatePairs) {
1948             if (!term-&gt;characterClass-&gt;hasOneCharacterSize() || term-&gt;invert())
1949                 loadFromFrame(term-&gt;frameLocation + BackTrackInfoCharacterClass::beginIndex(), index);
1950         }
1951 #endif
1952 
1953         loadFromFrame(term-&gt;frameLocation + BackTrackInfoCharacterClass::matchAmountIndex(), countRegister);
1954 
1955         nonGreedyFailures.append(atEndOfInput());
1956         nonGreedyFailures.append(branch32(Equal, countRegister, Imm32(term-&gt;quantityMaxCount.unsafeGet())));
1957 
1958         JumpList matchDest;
1959         readCharacter(m_checkedOffset - term-&gt;inputPosition, character);
1960         // If we are matching the &quot;any character&quot; builtin class for non-unicode patterns,
1961         // we only need to read the character and don&#39;t need to match as it will always succeed.
1962         if (term-&gt;invert() || !term-&gt;characterClass-&gt;m_anyCharacter) {
1963             matchCharacterClass(character, matchDest, term-&gt;characterClass);
1964 
1965             if (term-&gt;invert())
1966                 nonGreedyFailures.append(matchDest);
1967             else {
1968                 nonGreedyFailures.append(jump());
1969                 matchDest.link(this);
1970             }
1971         }
1972 
1973 #ifdef JIT_UNICODE_EXPRESSIONS
1974         if (m_decodeSurrogatePairs)
1975             advanceIndexAfterCharacterClassTermMatch(term, nonGreedyFailuresDecrementIndex, character);
1976         else
1977 #endif
1978             add32(TrustedImm32(1), index);
1979         add32(TrustedImm32(1), countRegister);
1980 
1981         jump(op.m_reentry);
1982 
1983         if (!nonGreedyFailuresDecrementIndex.empty()) {
1984             nonGreedyFailuresDecrementIndex.link(this);
1985             breakpoint();
1986         }
1987         nonGreedyFailures.link(this);
1988         sub32(countRegister, index);
1989         m_backtrackingState.fallthrough();
1990     }
1991 
1992     void generateDotStarEnclosure(size_t opIndex)
1993     {
1994         YarrOp&amp; op = m_ops[opIndex];
1995         PatternTerm* term = op.m_term;
1996 
1997         const RegisterID character = regT0;
1998         const RegisterID matchPos = regT1;
<a name="18" id="anc18"></a>



1999         JumpList foundBeginningNewLine;
2000         JumpList saveStartIndex;
2001         JumpList foundEndingNewLine;
2002 
2003         if (m_pattern.dotAll()) {
2004             move(TrustedImm32(0), matchPos);
2005             setMatchStart(matchPos);
2006             move(length, index);
2007             return;
2008         }
2009 
2010         ASSERT(!m_pattern.m_body-&gt;m_hasFixedSize);
2011         getMatchStart(matchPos);
2012 
<a name="19" id="anc19"></a>


2013         saveStartIndex.append(branch32(BelowOrEqual, matchPos, initialStart));
2014         Label findBOLLoop(this);
2015         sub32(TrustedImm32(1), matchPos);
2016         if (m_charSize == Char8)
2017             load8(BaseIndex(input, matchPos, TimesOne, 0), character);
2018         else
2019             load16(BaseIndex(input, matchPos, TimesTwo, 0), character);
2020         matchCharacterClass(character, foundBeginningNewLine, m_pattern.newlineCharacterClass());
2021 
<a name="20" id="anc20"></a>


2022         branch32(Above, matchPos, initialStart).linkTo(findBOLLoop, this);
2023         saveStartIndex.append(jump());
2024 
2025         foundBeginningNewLine.link(this);
2026         add32(TrustedImm32(1), matchPos); // Advance past newline
2027         saveStartIndex.link(this);
2028 
2029         if (!m_pattern.multiline() &amp;&amp; term-&gt;anchors.bolAnchor)
2030             op.m_jumps.append(branchTest32(NonZero, matchPos));
2031 
2032         ASSERT(!m_pattern.m_body-&gt;m_hasFixedSize);
2033         setMatchStart(matchPos);
2034 
2035         move(index, matchPos);
2036 
2037         Label findEOLLoop(this);
2038         foundEndingNewLine.append(branch32(Equal, matchPos, length));
2039         if (m_charSize == Char8)
2040             load8(BaseIndex(input, matchPos, TimesOne, 0), character);
2041         else
2042             load16(BaseIndex(input, matchPos, TimesTwo, 0), character);
2043         matchCharacterClass(character, foundEndingNewLine, m_pattern.newlineCharacterClass());
2044         add32(TrustedImm32(1), matchPos);
2045         jump(findEOLLoop);
2046 
2047         foundEndingNewLine.link(this);
2048 
2049         if (!m_pattern.multiline() &amp;&amp; term-&gt;anchors.eolAnchor)
2050             op.m_jumps.append(branch32(NotEqual, matchPos, length));
2051 
2052         move(matchPos, index);
2053     }
2054 
2055     void backtrackDotStarEnclosure(size_t opIndex)
2056     {
2057         backtrackTermDefault(opIndex);
2058     }
2059 
2060     // Code generation/backtracking for simple terms
2061     // (pattern characters, character classes, and assertions).
2062     // These methods farm out work to the set of functions above.
2063     void generateTerm(size_t opIndex)
2064     {
2065         YarrOp&amp; op = m_ops[opIndex];
2066         PatternTerm* term = op.m_term;
2067 
2068         switch (term-&gt;type) {
2069         case PatternTerm::TypePatternCharacter:
2070             switch (term-&gt;quantityType) {
2071             case QuantifierFixedCount:
2072                 if (term-&gt;quantityMaxCount == 1)
2073                     generatePatternCharacterOnce(opIndex);
2074                 else
2075                     generatePatternCharacterFixed(opIndex);
2076                 break;
2077             case QuantifierGreedy:
2078                 generatePatternCharacterGreedy(opIndex);
2079                 break;
2080             case QuantifierNonGreedy:
2081                 generatePatternCharacterNonGreedy(opIndex);
2082                 break;
2083             }
2084             break;
2085 
2086         case PatternTerm::TypeCharacterClass:
2087             switch (term-&gt;quantityType) {
2088             case QuantifierFixedCount:
2089                 if (term-&gt;quantityMaxCount == 1)
2090                     generateCharacterClassOnce(opIndex);
2091                 else
2092                     generateCharacterClassFixed(opIndex);
2093                 break;
2094             case QuantifierGreedy:
2095                 generateCharacterClassGreedy(opIndex);
2096                 break;
2097             case QuantifierNonGreedy:
2098                 generateCharacterClassNonGreedy(opIndex);
2099                 break;
2100             }
2101             break;
2102 
2103         case PatternTerm::TypeAssertionBOL:
2104             generateAssertionBOL(opIndex);
2105             break;
2106 
2107         case PatternTerm::TypeAssertionEOL:
2108             generateAssertionEOL(opIndex);
2109             break;
2110 
2111         case PatternTerm::TypeAssertionWordBoundary:
2112             generateAssertionWordBoundary(opIndex);
2113             break;
2114 
2115         case PatternTerm::TypeForwardReference:
2116             m_failureReason = JITFailureReason::ForwardReference;
2117             break;
2118 
2119         case PatternTerm::TypeParenthesesSubpattern:
2120         case PatternTerm::TypeParentheticalAssertion:
2121             RELEASE_ASSERT_NOT_REACHED();
2122 
2123         case PatternTerm::TypeBackReference:
2124 #if ENABLE(YARR_JIT_BACKREFERENCES)
2125             generateBackReference(opIndex);
2126 #else
2127             m_failureReason = JITFailureReason::BackReference;
2128 #endif
2129             break;
2130         case PatternTerm::TypeDotStarEnclosure:
2131             generateDotStarEnclosure(opIndex);
2132             break;
2133         }
2134     }
2135     void backtrackTerm(size_t opIndex)
2136     {
2137         YarrOp&amp; op = m_ops[opIndex];
2138         PatternTerm* term = op.m_term;
2139 
2140         switch (term-&gt;type) {
2141         case PatternTerm::TypePatternCharacter:
2142             switch (term-&gt;quantityType) {
2143             case QuantifierFixedCount:
2144                 if (term-&gt;quantityMaxCount == 1)
2145                     backtrackPatternCharacterOnce(opIndex);
2146                 else
2147                     backtrackPatternCharacterFixed(opIndex);
2148                 break;
2149             case QuantifierGreedy:
2150                 backtrackPatternCharacterGreedy(opIndex);
2151                 break;
2152             case QuantifierNonGreedy:
2153                 backtrackPatternCharacterNonGreedy(opIndex);
2154                 break;
2155             }
2156             break;
2157 
2158         case PatternTerm::TypeCharacterClass:
2159             switch (term-&gt;quantityType) {
2160             case QuantifierFixedCount:
2161                 if (term-&gt;quantityMaxCount == 1)
2162                     backtrackCharacterClassOnce(opIndex);
2163                 else
2164                     backtrackCharacterClassFixed(opIndex);
2165                 break;
2166             case QuantifierGreedy:
2167                 backtrackCharacterClassGreedy(opIndex);
2168                 break;
2169             case QuantifierNonGreedy:
2170                 backtrackCharacterClassNonGreedy(opIndex);
2171                 break;
2172             }
2173             break;
2174 
2175         case PatternTerm::TypeAssertionBOL:
2176             backtrackAssertionBOL(opIndex);
2177             break;
2178 
2179         case PatternTerm::TypeAssertionEOL:
2180             backtrackAssertionEOL(opIndex);
2181             break;
2182 
2183         case PatternTerm::TypeAssertionWordBoundary:
2184             backtrackAssertionWordBoundary(opIndex);
2185             break;
2186 
2187         case PatternTerm::TypeForwardReference:
2188             m_failureReason = JITFailureReason::ForwardReference;
2189             break;
2190 
2191         case PatternTerm::TypeParenthesesSubpattern:
2192         case PatternTerm::TypeParentheticalAssertion:
2193             RELEASE_ASSERT_NOT_REACHED();
2194 
2195         case PatternTerm::TypeBackReference:
2196 #if ENABLE(YARR_JIT_BACKREFERENCES)
2197             backtrackBackReference(opIndex);
2198 #else
2199             m_failureReason = JITFailureReason::BackReference;
2200 #endif
2201             break;
2202 
2203         case PatternTerm::TypeDotStarEnclosure:
2204             backtrackDotStarEnclosure(opIndex);
2205             break;
2206         }
2207     }
2208 
2209     void generate()
2210     {
2211         // Forwards generate the matching code.
2212         ASSERT(m_ops.size());
2213         size_t opIndex = 0;
2214 
2215         do {
2216             if (m_disassembler)
2217                 m_disassembler-&gt;setForGenerate(opIndex, label());
2218 
2219             YarrOp&amp; op = m_ops[opIndex];
2220             switch (op.m_op) {
2221 
2222             case OpTerm:
2223                 generateTerm(opIndex);
2224                 break;
2225 
2226             // OpBodyAlternativeBegin/Next/End
2227             //
2228             // These nodes wrap the set of alternatives in the body of the regular expression.
2229             // There may be either one or two chains of OpBodyAlternative nodes, one representing
2230             // the &#39;once through&#39; sequence of alternatives (if any exist), and one representing
2231             // the repeating alternatives (again, if any exist).
2232             //
2233             // Upon normal entry to the Begin alternative, we will check that input is available.
2234             // Reentry to the Begin alternative will take place after the check has taken place,
2235             // and will assume that the input position has already been progressed as appropriate.
2236             //
2237             // Entry to subsequent Next/End alternatives occurs when the prior alternative has
2238             // successfully completed a match - return a success state from JIT code.
2239             //
2240             // Next alternatives allow for reentry optimized to suit backtracking from its
2241             // preceding alternative. It expects the input position to still be set to a position
2242             // appropriate to its predecessor, and it will only perform an input check if the
2243             // predecessor had a minimum size less than its own.
2244             //
2245             // In the case &#39;once through&#39; expressions, the End node will also have a reentry
2246             // point to jump to when the last alternative fails. Again, this expects the input
2247             // position to still reflect that expected by the prior alternative.
2248             case OpBodyAlternativeBegin: {
2249                 PatternAlternative* alternative = op.m_alternative;
2250 
2251                 // Upon entry at the head of the set of alternatives, check if input is available
2252                 // to run the first alternative. (This progresses the input position).
2253                 op.m_jumps.append(jumpIfNoAvailableInput(alternative-&gt;m_minimumSize));
2254                 // We will reenter after the check, and assume the input position to have been
2255                 // set as appropriate to this alternative.
2256                 op.m_reentry = label();
2257 
2258                 m_checkedOffset += alternative-&gt;m_minimumSize;
2259                 break;
2260             }
2261             case OpBodyAlternativeNext:
2262             case OpBodyAlternativeEnd: {
2263                 PatternAlternative* priorAlternative = m_ops[op.m_previousOp].m_alternative;
2264                 PatternAlternative* alternative = op.m_alternative;
2265 
2266                 // If we get here, the prior alternative matched - return success.
2267 
2268                 // Adjust the stack pointer to remove the pattern&#39;s frame.
2269                 removeCallFrame();
2270 
2271                 // Load appropriate values into the return register and the first output
2272                 // slot, and return. In the case of pattern with a fixed size, we will
2273                 // not have yet set the value in the first
2274                 ASSERT(index != returnRegister);
2275                 if (m_pattern.m_body-&gt;m_hasFixedSize) {
2276                     move(index, returnRegister);
2277                     if (priorAlternative-&gt;m_minimumSize)
2278                         sub32(Imm32(priorAlternative-&gt;m_minimumSize), returnRegister);
2279                     if (compileMode == IncludeSubpatterns)
2280                         store32(returnRegister, output);
2281                 } else
2282                     getMatchStart(returnRegister);
2283                 if (compileMode == IncludeSubpatterns)
2284                     store32(index, Address(output, 4));
2285                 move(index, returnRegister2);
2286 
2287                 generateReturn();
2288 
2289                 // This is the divide between the tail of the prior alternative, above, and
2290                 // the head of the subsequent alternative, below.
2291 
2292                 if (op.m_op == OpBodyAlternativeNext) {
2293                     // This is the reentry point for the Next alternative. We expect any code
2294                     // that jumps here to do so with the input position matching that of the
2295                     // PRIOR alteranative, and we will only check input availability if we
2296                     // need to progress it forwards.
2297                     op.m_reentry = label();
2298                     if (alternative-&gt;m_minimumSize &gt; priorAlternative-&gt;m_minimumSize) {
2299                         add32(Imm32(alternative-&gt;m_minimumSize - priorAlternative-&gt;m_minimumSize), index);
2300                         op.m_jumps.append(jumpIfNoAvailableInput());
2301                     } else if (priorAlternative-&gt;m_minimumSize &gt; alternative-&gt;m_minimumSize)
2302                         sub32(Imm32(priorAlternative-&gt;m_minimumSize - alternative-&gt;m_minimumSize), index);
2303                 } else if (op.m_nextOp == notFound) {
2304                     // This is the reentry point for the End of &#39;once through&#39; alternatives,
2305                     // jumped to when the last alternative fails to match.
2306                     op.m_reentry = label();
2307                     sub32(Imm32(priorAlternative-&gt;m_minimumSize), index);
2308                 }
2309 
2310                 if (op.m_op == OpBodyAlternativeNext)
2311                     m_checkedOffset += alternative-&gt;m_minimumSize;
2312                 m_checkedOffset -= priorAlternative-&gt;m_minimumSize;
2313                 break;
2314             }
2315 
2316             // OpSimpleNestedAlternativeBegin/Next/End
2317             // OpNestedAlternativeBegin/Next/End
2318             //
2319             // These nodes are used to handle sets of alternatives that are nested within
2320             // subpatterns and parenthetical assertions. The &#39;simple&#39; forms are used where
2321             // we do not need to be able to backtrack back into any alternative other than
2322             // the last, the normal forms allow backtracking into any alternative.
2323             //
2324             // Each Begin/Next node is responsible for planting an input check to ensure
2325             // sufficient input is available on entry. Next nodes additionally need to
2326             // jump to the end - Next nodes use the End node&#39;s m_jumps list to hold this
2327             // set of jumps.
2328             //
2329             // In the non-simple forms, successful alternative matches must store a
2330             // &#39;return address&#39; using a DataLabelPtr, used to store the address to jump
2331             // to when backtracking, to get to the code for the appropriate alternative.
2332             case OpSimpleNestedAlternativeBegin:
2333             case OpNestedAlternativeBegin: {
2334                 PatternTerm* term = op.m_term;
2335                 PatternAlternative* alternative = op.m_alternative;
2336                 PatternDisjunction* disjunction = term-&gt;parentheses.disjunction;
2337 
2338                 // Calculate how much input we need to check for, and if non-zero check.
2339                 op.m_checkAdjust = Checked&lt;unsigned&gt;(alternative-&gt;m_minimumSize);
2340                 if ((term-&gt;quantityType == QuantifierFixedCount) &amp;&amp; (term-&gt;type != PatternTerm::TypeParentheticalAssertion))
2341                     op.m_checkAdjust -= disjunction-&gt;m_minimumSize;
2342                 if (op.m_checkAdjust)
2343                     op.m_jumps.append(jumpIfNoAvailableInput(op.m_checkAdjust.unsafeGet()));
2344 
2345                 m_checkedOffset += op.m_checkAdjust;
2346                 break;
2347             }
2348             case OpSimpleNestedAlternativeNext:
2349             case OpNestedAlternativeNext: {
2350                 PatternTerm* term = op.m_term;
2351                 PatternAlternative* alternative = op.m_alternative;
2352                 PatternDisjunction* disjunction = term-&gt;parentheses.disjunction;
2353 
2354                 // In the non-simple case, store a &#39;return address&#39; so we can backtrack correctly.
2355                 if (op.m_op == OpNestedAlternativeNext) {
2356                     unsigned parenthesesFrameLocation = term-&gt;frameLocation;
2357                     op.m_returnAddress = storeToFrameWithPatch(parenthesesFrameLocation + BackTrackInfoParentheses::returnAddressIndex());
2358                 }
2359 
2360                 if (term-&gt;quantityType != QuantifierFixedCount &amp;&amp; !m_ops[op.m_previousOp].m_alternative-&gt;m_minimumSize) {
2361                     // If the previous alternative matched without consuming characters then
2362                     // backtrack to try to match while consumming some input.
2363                     op.m_zeroLengthMatch = branch32(Equal, index, Address(stackPointerRegister, term-&gt;frameLocation * sizeof(void*)));
2364                 }
2365 
2366                 // If we reach here then the last alternative has matched - jump to the
2367                 // End node, to skip over any further alternatives.
2368                 //
2369                 // FIXME: this is logically O(N^2) (though N can be expected to be very
2370                 // small). We could avoid this either by adding an extra jump to the JIT
2371                 // data structures, or by making backtracking code that jumps to Next
2372                 // alternatives are responsible for checking that input is available (if
2373                 // we didn&#39;t need to plant the input checks, then m_jumps would be free).
2374                 YarrOp* endOp = &amp;m_ops[op.m_nextOp];
2375                 while (endOp-&gt;m_nextOp != notFound) {
2376                     ASSERT(endOp-&gt;m_op == OpSimpleNestedAlternativeNext || endOp-&gt;m_op == OpNestedAlternativeNext);
2377                     endOp = &amp;m_ops[endOp-&gt;m_nextOp];
2378                 }
2379                 ASSERT(endOp-&gt;m_op == OpSimpleNestedAlternativeEnd || endOp-&gt;m_op == OpNestedAlternativeEnd);
2380                 endOp-&gt;m_jumps.append(jump());
2381 
2382                 // This is the entry point for the next alternative.
2383                 op.m_reentry = label();
2384 
2385                 // Calculate how much input we need to check for, and if non-zero check.
2386                 op.m_checkAdjust = alternative-&gt;m_minimumSize;
2387                 if ((term-&gt;quantityType == QuantifierFixedCount) &amp;&amp; (term-&gt;type != PatternTerm::TypeParentheticalAssertion))
2388                     op.m_checkAdjust -= disjunction-&gt;m_minimumSize;
2389                 if (op.m_checkAdjust)
2390                     op.m_jumps.append(jumpIfNoAvailableInput(op.m_checkAdjust.unsafeGet()));
2391 
2392                 YarrOp&amp; lastOp = m_ops[op.m_previousOp];
2393                 m_checkedOffset -= lastOp.m_checkAdjust;
2394                 m_checkedOffset += op.m_checkAdjust;
2395                 break;
2396             }
2397             case OpSimpleNestedAlternativeEnd:
2398             case OpNestedAlternativeEnd: {
2399                 PatternTerm* term = op.m_term;
2400 
2401                 // In the non-simple case, store a &#39;return address&#39; so we can backtrack correctly.
2402                 if (op.m_op == OpNestedAlternativeEnd) {
2403                     unsigned parenthesesFrameLocation = term-&gt;frameLocation;
2404                     op.m_returnAddress = storeToFrameWithPatch(parenthesesFrameLocation + BackTrackInfoParentheses::returnAddressIndex());
2405                 }
2406 
2407                 if (term-&gt;quantityType != QuantifierFixedCount &amp;&amp; !m_ops[op.m_previousOp].m_alternative-&gt;m_minimumSize) {
2408                     // If the previous alternative matched without consuming characters then
2409                     // backtrack to try to match while consumming some input.
2410                     op.m_zeroLengthMatch = branch32(Equal, index, Address(stackPointerRegister, term-&gt;frameLocation * sizeof(void*)));
2411                 }
2412 
2413                 // If this set of alternatives contains more than one alternative,
2414                 // then the Next nodes will have planted jumps to the End, and added
2415                 // them to this node&#39;s m_jumps list.
2416                 op.m_jumps.link(this);
2417                 op.m_jumps.clear();
2418 
2419                 YarrOp&amp; lastOp = m_ops[op.m_previousOp];
2420                 m_checkedOffset -= lastOp.m_checkAdjust;
2421                 break;
2422             }
2423 
2424             // OpParenthesesSubpatternOnceBegin/End
2425             //
2426             // These nodes support (optionally) capturing subpatterns, that have a
2427             // quantity count of 1 (this covers fixed once, and ?/?? quantifiers).
2428             case OpParenthesesSubpatternOnceBegin: {
2429                 PatternTerm* term = op.m_term;
2430                 unsigned parenthesesFrameLocation = term-&gt;frameLocation;
2431                 const RegisterID indexTemporary = regT0;
2432                 ASSERT(term-&gt;quantityMaxCount == 1);
2433 
2434                 // Upon entry to a Greedy quantified set of parenthese store the index.
2435                 // We&#39;ll use this for two purposes:
2436                 //  - To indicate which iteration we are on of mathing the remainder of
2437                 //    the expression after the parentheses - the first, including the
2438                 //    match within the parentheses, or the second having skipped over them.
2439                 //  - To check for empty matches, which must be rejected.
2440                 //
2441                 // At the head of a NonGreedy set of parentheses we&#39;ll immediately set the
2442                 // value on the stack to -1 (indicating a match skipping the subpattern),
2443                 // and plant a jump to the end. We&#39;ll also plant a label to backtrack to
2444                 // to reenter the subpattern later, with a store to set up index on the
2445                 // second iteration.
2446                 //
2447                 // FIXME: for capturing parens, could use the index in the capture array?
2448                 if (term-&gt;quantityType == QuantifierGreedy)
2449                     storeToFrame(index, parenthesesFrameLocation + BackTrackInfoParenthesesOnce::beginIndex());
2450                 else if (term-&gt;quantityType == QuantifierNonGreedy) {
2451                     storeToFrame(TrustedImm32(-1), parenthesesFrameLocation + BackTrackInfoParenthesesOnce::beginIndex());
2452                     op.m_jumps.append(jump());
2453                     op.m_reentry = label();
2454                     storeToFrame(index, parenthesesFrameLocation + BackTrackInfoParenthesesOnce::beginIndex());
2455                 }
2456 
2457                 // If the parenthese are capturing, store the starting index value to the
2458                 // captures array, offsetting as necessary.
2459                 //
2460                 // FIXME: could avoid offsetting this value in JIT code, apply
2461                 // offsets only afterwards, at the point the results array is
2462                 // being accessed.
2463                 if (term-&gt;capture() &amp;&amp; compileMode == IncludeSubpatterns) {
2464                     unsigned inputOffset = (m_checkedOffset - term-&gt;inputPosition).unsafeGet();
2465                     if (term-&gt;quantityType == QuantifierFixedCount)
2466                         inputOffset += term-&gt;parentheses.disjunction-&gt;m_minimumSize;
2467                     if (inputOffset) {
2468                         move(index, indexTemporary);
2469                         sub32(Imm32(inputOffset), indexTemporary);
2470                         setSubpatternStart(indexTemporary, term-&gt;parentheses.subpatternId);
2471                     } else
2472                         setSubpatternStart(index, term-&gt;parentheses.subpatternId);
2473                 }
2474                 break;
2475             }
2476             case OpParenthesesSubpatternOnceEnd: {
2477                 PatternTerm* term = op.m_term;
2478                 const RegisterID indexTemporary = regT0;
2479                 ASSERT(term-&gt;quantityMaxCount == 1);
2480 
2481                 // If the nested alternative matched without consuming any characters, punt this back to the interpreter.
2482                 // FIXME: &lt;https://bugs.webkit.org/show_bug.cgi?id=200786&gt; Add ability for the YARR JIT to properly
2483                 // handle nested expressions that can match without consuming characters
2484                 if (term-&gt;quantityType != QuantifierFixedCount &amp;&amp; !term-&gt;parentheses.disjunction-&gt;m_minimumSize)
2485                     m_abortExecution.append(branch32(Equal, index, Address(stackPointerRegister, term-&gt;frameLocation * sizeof(void*))));
2486 
2487                 // If the parenthese are capturing, store the ending index value to the
2488                 // captures array, offsetting as necessary.
2489                 //
2490                 // FIXME: could avoid offsetting this value in JIT code, apply
2491                 // offsets only afterwards, at the point the results array is
2492                 // being accessed.
2493                 if (term-&gt;capture() &amp;&amp; compileMode == IncludeSubpatterns) {
2494                     unsigned inputOffset = (m_checkedOffset - term-&gt;inputPosition).unsafeGet();
2495                     if (inputOffset) {
2496                         move(index, indexTemporary);
2497                         sub32(Imm32(inputOffset), indexTemporary);
2498                         setSubpatternEnd(indexTemporary, term-&gt;parentheses.subpatternId);
2499                     } else
2500                         setSubpatternEnd(index, term-&gt;parentheses.subpatternId);
2501                 }
2502 
2503                 // If the parentheses are quantified Greedy then add a label to jump back
2504                 // to if we get a failed match from after the parentheses. For NonGreedy
2505                 // parentheses, link the jump from before the subpattern to here.
2506                 if (term-&gt;quantityType == QuantifierGreedy)
2507                     op.m_reentry = label();
2508                 else if (term-&gt;quantityType == QuantifierNonGreedy) {
2509                     YarrOp&amp; beginOp = m_ops[op.m_previousOp];
2510                     beginOp.m_jumps.link(this);
2511                 }
2512                 break;
2513             }
2514 
2515             // OpParenthesesSubpatternTerminalBegin/End
2516             case OpParenthesesSubpatternTerminalBegin: {
2517                 PatternTerm* term = op.m_term;
2518                 ASSERT(term-&gt;quantityType == QuantifierGreedy);
2519                 ASSERT(term-&gt;quantityMaxCount == quantifyInfinite);
2520                 ASSERT(!term-&gt;capture());
2521 
2522                 // Upon entry set a label to loop back to.
2523                 op.m_reentry = label();
2524 
2525                 // Store the start index of the current match; we need to reject zero
2526                 // length matches.
2527                 storeToFrame(index, term-&gt;frameLocation + BackTrackInfoParenthesesTerminal::beginIndex());
2528                 break;
2529             }
2530             case OpParenthesesSubpatternTerminalEnd: {
2531                 YarrOp&amp; beginOp = m_ops[op.m_previousOp];
2532                 PatternTerm* term = op.m_term;
2533 
2534                 // If the nested alternative matched without consuming any characters, punt this back to the interpreter.
2535                 // FIXME: &lt;https://bugs.webkit.org/show_bug.cgi?id=200786&gt; Add ability for the YARR JIT to properly
2536                 // handle nested expressions that can match without consuming characters
2537                 if (term-&gt;quantityType != QuantifierFixedCount &amp;&amp; !term-&gt;parentheses.disjunction-&gt;m_minimumSize)
2538                     m_abortExecution.append(branch32(Equal, index, Address(stackPointerRegister, term-&gt;frameLocation * sizeof(void*))));
2539 
2540                 // We know that the match is non-zero, we can accept it and
2541                 // loop back up to the head of the subpattern.
2542                 jump(beginOp.m_reentry);
2543 
2544                 // This is the entry point to jump to when we stop matching - we will
2545                 // do so once the subpattern cannot match any more.
2546                 op.m_reentry = label();
2547                 break;
2548             }
2549 
2550             // OpParenthesesSubpatternBegin/End
2551             //
2552             // These nodes support generic subpatterns.
2553             case OpParenthesesSubpatternBegin: {
2554 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
2555                 PatternTerm* term = op.m_term;
2556                 unsigned parenthesesFrameLocation = term-&gt;frameLocation;
2557 
2558                 // Upon entry to a Greedy quantified set of parenthese store the index.
2559                 // We&#39;ll use this for two purposes:
2560                 //  - To indicate which iteration we are on of mathing the remainder of
2561                 //    the expression after the parentheses - the first, including the
2562                 //    match within the parentheses, or the second having skipped over them.
2563                 //  - To check for empty matches, which must be rejected.
2564                 //
2565                 // At the head of a NonGreedy set of parentheses we&#39;ll immediately set &#39;begin&#39;
2566                 // in the backtrack info to -1 (indicating a match skipping the subpattern),
2567                 // and plant a jump to the end. We&#39;ll also plant a label to backtrack to
2568                 // to reenter the subpattern later, with a store to set &#39;begin&#39; to current index
2569                 // on the second iteration.
2570                 //
2571                 // FIXME: for capturing parens, could use the index in the capture array?
2572                 if (term-&gt;quantityType == QuantifierGreedy || term-&gt;quantityType == QuantifierNonGreedy) {
2573                     storeToFrame(TrustedImm32(0), parenthesesFrameLocation + BackTrackInfoParentheses::matchAmountIndex());
2574                     storeToFrame(TrustedImmPtr(nullptr), parenthesesFrameLocation + BackTrackInfoParentheses::parenContextHeadIndex());
2575 
2576                     if (term-&gt;quantityType == QuantifierNonGreedy) {
2577                         storeToFrame(TrustedImm32(-1), parenthesesFrameLocation + BackTrackInfoParentheses::beginIndex());
2578                         op.m_jumps.append(jump());
2579                     }
2580 
2581                     op.m_reentry = label();
2582                     RegisterID currParenContextReg = regT0;
2583                     RegisterID newParenContextReg = regT1;
2584 
2585                     loadFromFrame(parenthesesFrameLocation + BackTrackInfoParentheses::parenContextHeadIndex(), currParenContextReg);
2586                     allocateParenContext(newParenContextReg);
2587                     storePtr(currParenContextReg, newParenContextReg);
2588                     storeToFrame(newParenContextReg, parenthesesFrameLocation + BackTrackInfoParentheses::parenContextHeadIndex());
2589                     saveParenContext(newParenContextReg, regT2, term-&gt;parentheses.subpatternId, term-&gt;parentheses.lastSubpatternId, parenthesesFrameLocation);
2590                     storeToFrame(index, parenthesesFrameLocation + BackTrackInfoParentheses::beginIndex());
2591                 }
2592 
2593                 // If the parenthese are capturing, store the starting index value to the
2594                 // captures array, offsetting as necessary.
2595                 //
2596                 // FIXME: could avoid offsetting this value in JIT code, apply
2597                 // offsets only afterwards, at the point the results array is
2598                 // being accessed.
2599                 if (term-&gt;capture() &amp;&amp; compileMode == IncludeSubpatterns) {
2600                     const RegisterID indexTemporary = regT0;
2601                     unsigned inputOffset = (m_checkedOffset - term-&gt;inputPosition).unsafeGet();
2602                     if (term-&gt;quantityType == QuantifierFixedCount)
2603                         inputOffset += term-&gt;parentheses.disjunction-&gt;m_minimumSize;
2604                     if (inputOffset) {
2605                         move(index, indexTemporary);
2606                         sub32(Imm32(inputOffset), indexTemporary);
2607                         setSubpatternStart(indexTemporary, term-&gt;parentheses.subpatternId);
2608                     } else
2609                         setSubpatternStart(index, term-&gt;parentheses.subpatternId);
2610                 }
2611 #else // !YARR_JIT_ALL_PARENS_EXPRESSIONS
2612                 RELEASE_ASSERT_NOT_REACHED();
2613 #endif
2614                 break;
2615             }
2616             case OpParenthesesSubpatternEnd: {
2617 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
2618                 PatternTerm* term = op.m_term;
2619                 unsigned parenthesesFrameLocation = term-&gt;frameLocation;
2620 
2621                 // If the nested alternative matched without consuming any characters, punt this back to the interpreter.
2622                 // FIXME: &lt;https://bugs.webkit.org/show_bug.cgi?id=200786&gt; Add ability for the YARR JIT to properly
2623                 // handle nested expressions that can match without consuming characters
2624                 if (term-&gt;quantityType != QuantifierFixedCount &amp;&amp; !term-&gt;parentheses.disjunction-&gt;m_minimumSize)
2625                     m_abortExecution.append(branch32(Equal, index, Address(stackPointerRegister, parenthesesFrameLocation * sizeof(void*))));
2626 
2627                 const RegisterID countTemporary = regT1;
2628 
2629                 YarrOp&amp; beginOp = m_ops[op.m_previousOp];
2630                 loadFromFrame(parenthesesFrameLocation + BackTrackInfoParentheses::matchAmountIndex(), countTemporary);
2631                 add32(TrustedImm32(1), countTemporary);
2632                 storeToFrame(countTemporary, parenthesesFrameLocation + BackTrackInfoParentheses::matchAmountIndex());
2633 
2634                 // If the parenthese are capturing, store the ending index value to the
2635                 // captures array, offsetting as necessary.
2636                 //
2637                 // FIXME: could avoid offsetting this value in JIT code, apply
2638                 // offsets only afterwards, at the point the results array is
2639                 // being accessed.
2640                 if (term-&gt;capture() &amp;&amp; compileMode == IncludeSubpatterns) {
2641                     const RegisterID indexTemporary = regT0;
2642 
2643                     unsigned inputOffset = (m_checkedOffset - term-&gt;inputPosition).unsafeGet();
2644                     if (inputOffset) {
2645                         move(index, indexTemporary);
2646                         sub32(Imm32(inputOffset), indexTemporary);
2647                         setSubpatternEnd(indexTemporary, term-&gt;parentheses.subpatternId);
2648                     } else
2649                         setSubpatternEnd(index, term-&gt;parentheses.subpatternId);
2650                 }
2651 
2652                 // If the parentheses are quantified Greedy then add a label to jump back
2653                 // to if we get a failed match from after the parentheses. For NonGreedy
2654                 // parentheses, link the jump from before the subpattern to here.
2655                 if (term-&gt;quantityType == QuantifierGreedy) {
2656                     if (term-&gt;quantityMaxCount != quantifyInfinite)
2657                         branch32(Below, countTemporary, Imm32(term-&gt;quantityMaxCount.unsafeGet())).linkTo(beginOp.m_reentry, this);
2658                     else
2659                         jump(beginOp.m_reentry);
2660 
2661                     op.m_reentry = label();
2662                 } else if (term-&gt;quantityType == QuantifierNonGreedy) {
2663                     YarrOp&amp; beginOp = m_ops[op.m_previousOp];
2664                     beginOp.m_jumps.link(this);
2665                     op.m_reentry = label();
2666                 }
2667 #else // !YARR_JIT_ALL_PARENS_EXPRESSIONS
2668                 RELEASE_ASSERT_NOT_REACHED();
2669 #endif
2670                 break;
2671             }
2672 
2673             // OpParentheticalAssertionBegin/End
2674             case OpParentheticalAssertionBegin: {
2675                 PatternTerm* term = op.m_term;
2676 
2677                 // Store the current index - assertions should not update index, so
2678                 // we will need to restore it upon a successful match.
2679                 unsigned parenthesesFrameLocation = term-&gt;frameLocation;
2680                 storeToFrame(index, parenthesesFrameLocation + BackTrackInfoParentheticalAssertion::beginIndex());
2681 
2682                 // Check
2683                 op.m_checkAdjust = m_checkedOffset - term-&gt;inputPosition;
2684                 if (op.m_checkAdjust)
2685                     sub32(Imm32(op.m_checkAdjust.unsafeGet()), index);
2686 
2687                 m_checkedOffset -= op.m_checkAdjust;
2688                 break;
2689             }
2690             case OpParentheticalAssertionEnd: {
2691                 PatternTerm* term = op.m_term;
2692 
2693                 // Restore the input index value.
2694                 unsigned parenthesesFrameLocation = term-&gt;frameLocation;
2695                 loadFromFrame(parenthesesFrameLocation + BackTrackInfoParentheticalAssertion::beginIndex(), index);
2696 
2697                 // If inverted, a successful match of the assertion must be treated
2698                 // as a failure, so jump to backtracking.
2699                 if (term-&gt;invert()) {
2700                     op.m_jumps.append(jump());
2701                     op.m_reentry = label();
2702                 }
2703 
2704                 YarrOp&amp; lastOp = m_ops[op.m_previousOp];
2705                 m_checkedOffset += lastOp.m_checkAdjust;
2706                 break;
2707             }
2708 
2709             case OpMatchFailed:
2710                 removeCallFrame();
2711                 generateFailReturn();
2712                 break;
2713             }
2714 
2715             ++opIndex;
2716         } while (opIndex &lt; m_ops.size());
2717     }
2718 
2719     void backtrack()
2720     {
2721         // Backwards generate the backtracking code.
2722         size_t opIndex = m_ops.size();
2723         ASSERT(opIndex);
2724 
2725         do {
2726             --opIndex;
2727 
2728             if (m_disassembler)
2729                 m_disassembler-&gt;setForBacktrack(opIndex, label());
2730 
2731             YarrOp&amp; op = m_ops[opIndex];
2732             switch (op.m_op) {
2733 
2734             case OpTerm:
2735                 backtrackTerm(opIndex);
2736                 break;
2737 
2738             // OpBodyAlternativeBegin/Next/End
2739             //
2740             // For each Begin/Next node representing an alternative, we need to decide what to do
2741             // in two circumstances:
2742             //  - If we backtrack back into this node, from within the alternative.
2743             //  - If the input check at the head of the alternative fails (if this exists).
2744             //
2745             // We treat these two cases differently since in the former case we have slightly
2746             // more information - since we are backtracking out of a prior alternative we know
2747             // that at least enough input was available to run it. For example, given the regular
2748             // expression /a|b/, if we backtrack out of the first alternative (a failed pattern
2749             // character match of &#39;a&#39;), then we need not perform an additional input availability
2750             // check before running the second alternative.
2751             //
2752             // Backtracking required differs for the last alternative, which in the case of the
2753             // repeating set of alternatives must loop. The code generated for the last alternative
2754             // will also be used to handle all input check failures from any prior alternatives -
2755             // these require similar functionality, in seeking the next available alternative for
2756             // which there is sufficient input.
2757             //
2758             // Since backtracking of all other alternatives simply requires us to link backtracks
2759             // to the reentry point for the subsequent alternative, we will only be generating any
2760             // code when backtracking the last alternative.
2761             case OpBodyAlternativeBegin:
2762             case OpBodyAlternativeNext: {
2763                 PatternAlternative* alternative = op.m_alternative;
2764 
2765                 if (op.m_op == OpBodyAlternativeNext) {
2766                     PatternAlternative* priorAlternative = m_ops[op.m_previousOp].m_alternative;
2767                     m_checkedOffset += priorAlternative-&gt;m_minimumSize;
2768                 }
2769                 m_checkedOffset -= alternative-&gt;m_minimumSize;
2770 
2771                 // Is this the last alternative? If not, then if we backtrack to this point we just
2772                 // need to jump to try to match the next alternative.
2773                 if (m_ops[op.m_nextOp].m_op != OpBodyAlternativeEnd) {
2774                     m_backtrackingState.linkTo(m_ops[op.m_nextOp].m_reentry, this);
2775                     break;
2776                 }
2777                 YarrOp&amp; endOp = m_ops[op.m_nextOp];
2778 
2779                 YarrOp* beginOp = &amp;op;
2780                 while (beginOp-&gt;m_op != OpBodyAlternativeBegin) {
2781                     ASSERT(beginOp-&gt;m_op == OpBodyAlternativeNext);
2782                     beginOp = &amp;m_ops[beginOp-&gt;m_previousOp];
2783                 }
2784 
2785                 bool onceThrough = endOp.m_nextOp == notFound;
2786 
2787                 JumpList lastStickyAlternativeFailures;
2788 
2789                 // First, generate code to handle cases where we backtrack out of an attempted match
2790                 // of the last alternative. If this is a &#39;once through&#39; set of alternatives then we
2791                 // have nothing to do - link this straight through to the End.
2792                 if (onceThrough)
2793                     m_backtrackingState.linkTo(endOp.m_reentry, this);
2794                 else {
2795                     // If we don&#39;t need to move the input poistion, and the pattern has a fixed size
2796                     // (in which case we omit the store of the start index until the pattern has matched)
2797                     // then we can just link the backtrack out of the last alternative straight to the
2798                     // head of the first alternative.
2799                     if (m_pattern.m_body-&gt;m_hasFixedSize
2800                         &amp;&amp; (alternative-&gt;m_minimumSize &gt; beginOp-&gt;m_alternative-&gt;m_minimumSize)
2801                         &amp;&amp; (alternative-&gt;m_minimumSize - beginOp-&gt;m_alternative-&gt;m_minimumSize == 1))
2802                         m_backtrackingState.linkTo(beginOp-&gt;m_reentry, this);
2803                     else if (m_pattern.sticky() &amp;&amp; m_ops[op.m_nextOp].m_op == OpBodyAlternativeEnd) {
2804                         // It is a sticky pattern and the last alternative failed, jump to the end.
2805                         m_backtrackingState.takeBacktracksToJumpList(lastStickyAlternativeFailures, this);
2806                     } else {
2807                         // We need to generate a trampoline of code to execute before looping back
2808                         // around to the first alternative.
2809                         m_backtrackingState.link(this);
2810 
2811                         // No need to advance and retry for a sticky pattern.
2812                         if (!m_pattern.sticky()) {
2813                             // If the pattern size is not fixed, then store the start index for use if we match.
2814                             if (!m_pattern.m_body-&gt;m_hasFixedSize) {
2815                                 if (alternative-&gt;m_minimumSize == 1)
2816                                     setMatchStart(index);
2817                                 else {
2818                                     move(index, regT0);
2819                                     if (alternative-&gt;m_minimumSize)
2820                                         sub32(Imm32(alternative-&gt;m_minimumSize - 1), regT0);
2821                                     else
2822                                         add32(TrustedImm32(1), regT0);
2823                                     setMatchStart(regT0);
2824                                 }
2825                             }
2826 
2827                             // Generate code to loop. Check whether the last alternative is longer than the
2828                             // first (e.g. /a|xy/ or /a|xyz/).
2829                             if (alternative-&gt;m_minimumSize &gt; beginOp-&gt;m_alternative-&gt;m_minimumSize) {
2830                                 // We want to loop, and increment input position. If the delta is 1, it is
2831                                 // already correctly incremented, if more than one then decrement as appropriate.
2832                                 unsigned delta = alternative-&gt;m_minimumSize - beginOp-&gt;m_alternative-&gt;m_minimumSize;
2833                                 ASSERT(delta);
2834                                 if (delta != 1)
2835                                     sub32(Imm32(delta - 1), index);
2836                                 jump(beginOp-&gt;m_reentry);
2837                             } else {
2838                                 // If the first alternative has minimum size 0xFFFFFFFFu, then there cannot
2839                                 // be sufficent input available to handle this, so just fall through.
2840                                 unsigned delta = beginOp-&gt;m_alternative-&gt;m_minimumSize - alternative-&gt;m_minimumSize;
2841                                 if (delta != 0xFFFFFFFFu) {
2842                                     // We need to check input because we are incrementing the input.
2843                                     add32(Imm32(delta + 1), index);
2844                                     checkInput().linkTo(beginOp-&gt;m_reentry, this);
2845                                 }
2846                             }
2847                         }
2848                     }
2849                 }
2850 
2851                 // We can reach this point in the code in two ways:
2852                 //  - Fallthrough from the code above (a repeating alternative backtracked out of its
2853                 //    last alternative, and did not have sufficent input to run the first).
2854                 //  - We will loop back up to the following label when a repeating alternative loops,
2855                 //    following a failed input check.
2856                 //
2857                 // Either way, we have just failed the input check for the first alternative.
2858                 Label firstInputCheckFailed(this);
2859 
2860                 // Generate code to handle input check failures from alternatives except the last.
2861                 // prevOp is the alternative we&#39;re handling a bail out from (initially Begin), and
2862                 // nextOp is the alternative we will be attempting to reenter into.
2863                 //
2864                 // We will link input check failures from the forwards matching path back to the code
2865                 // that can handle them.
2866                 YarrOp* prevOp = beginOp;
2867                 YarrOp* nextOp = &amp;m_ops[beginOp-&gt;m_nextOp];
2868                 while (nextOp-&gt;m_op != OpBodyAlternativeEnd) {
2869                     prevOp-&gt;m_jumps.link(this);
2870 
2871                     // We only get here if an input check fails, it is only worth checking again
2872                     // if the next alternative has a minimum size less than the last.
2873                     if (prevOp-&gt;m_alternative-&gt;m_minimumSize &gt; nextOp-&gt;m_alternative-&gt;m_minimumSize) {
2874                         // FIXME: if we added an extra label to YarrOp, we could avoid needing to
2875                         // subtract delta back out, and reduce this code. Should performance test
2876                         // the benefit of this.
2877                         unsigned delta = prevOp-&gt;m_alternative-&gt;m_minimumSize - nextOp-&gt;m_alternative-&gt;m_minimumSize;
2878                         sub32(Imm32(delta), index);
2879                         Jump fail = jumpIfNoAvailableInput();
2880                         add32(Imm32(delta), index);
2881                         jump(nextOp-&gt;m_reentry);
2882                         fail.link(this);
2883                     } else if (prevOp-&gt;m_alternative-&gt;m_minimumSize &lt; nextOp-&gt;m_alternative-&gt;m_minimumSize)
2884                         add32(Imm32(nextOp-&gt;m_alternative-&gt;m_minimumSize - prevOp-&gt;m_alternative-&gt;m_minimumSize), index);
2885                     prevOp = nextOp;
2886                     nextOp = &amp;m_ops[nextOp-&gt;m_nextOp];
2887                 }
2888 
2889                 // We fall through to here if there is insufficient input to run the last alternative.
2890 
2891                 // If there is insufficient input to run the last alternative, then for &#39;once through&#39;
2892                 // alternatives we are done - just jump back up into the forwards matching path at the End.
2893                 if (onceThrough) {
2894                     op.m_jumps.linkTo(endOp.m_reentry, this);
2895                     jump(endOp.m_reentry);
2896                     break;
2897                 }
2898 
2899                 // For repeating alternatives, link any input check failure from the last alternative to
2900                 // this point.
2901                 op.m_jumps.link(this);
2902 
2903                 bool needsToUpdateMatchStart = !m_pattern.m_body-&gt;m_hasFixedSize;
2904 
2905                 // Check for cases where input position is already incremented by 1 for the last
2906                 // alternative (this is particularly useful where the minimum size of the body
2907                 // disjunction is 0, e.g. /a*|b/).
2908                 if (needsToUpdateMatchStart &amp;&amp; alternative-&gt;m_minimumSize == 1) {
2909                     // index is already incremented by 1, so just store it now!
2910                     setMatchStart(index);
2911                     needsToUpdateMatchStart = false;
2912                 }
2913 
2914                 if (!m_pattern.sticky()) {
2915                     // Check whether there is sufficient input to loop. Increment the input position by
2916                     // one, and check. Also add in the minimum disjunction size before checking - there
2917                     // is no point in looping if we&#39;re just going to fail all the input checks around
2918                     // the next iteration.
2919                     ASSERT(alternative-&gt;m_minimumSize &gt;= m_pattern.m_body-&gt;m_minimumSize);
2920                     if (alternative-&gt;m_minimumSize == m_pattern.m_body-&gt;m_minimumSize) {
2921                         // If the last alternative had the same minimum size as the disjunction,
2922                         // just simply increment input pos by 1, no adjustment based on minimum size.
2923                         add32(TrustedImm32(1), index);
2924                     } else {
2925                         // If the minumum for the last alternative was one greater than than that
2926                         // for the disjunction, we&#39;re already progressed by 1, nothing to do!
2927                         unsigned delta = (alternative-&gt;m_minimumSize - m_pattern.m_body-&gt;m_minimumSize) - 1;
2928                         if (delta)
2929                             sub32(Imm32(delta), index);
2930                     }
2931                     Jump matchFailed = jumpIfNoAvailableInput();
2932 
2933                     if (needsToUpdateMatchStart) {
2934                         if (!m_pattern.m_body-&gt;m_minimumSize)
2935                             setMatchStart(index);
2936                         else {
2937                             move(index, regT0);
2938                             sub32(Imm32(m_pattern.m_body-&gt;m_minimumSize), regT0);
2939                             setMatchStart(regT0);
2940                         }
2941                     }
2942 
2943                     // Calculate how much more input the first alternative requires than the minimum
2944                     // for the body as a whole. If no more is needed then we dont need an additional
2945                     // input check here - jump straight back up to the start of the first alternative.
2946                     if (beginOp-&gt;m_alternative-&gt;m_minimumSize == m_pattern.m_body-&gt;m_minimumSize)
2947                         jump(beginOp-&gt;m_reentry);
2948                     else {
2949                         if (beginOp-&gt;m_alternative-&gt;m_minimumSize &gt; m_pattern.m_body-&gt;m_minimumSize)
2950                             add32(Imm32(beginOp-&gt;m_alternative-&gt;m_minimumSize - m_pattern.m_body-&gt;m_minimumSize), index);
2951                         else
2952                             sub32(Imm32(m_pattern.m_body-&gt;m_minimumSize - beginOp-&gt;m_alternative-&gt;m_minimumSize), index);
2953                         checkInput().linkTo(beginOp-&gt;m_reentry, this);
2954                         jump(firstInputCheckFailed);
2955                     }
2956 
2957                     // We jump to here if we iterate to the point that there is insufficient input to
2958                     // run any matches, and need to return a failure state from JIT code.
2959                     matchFailed.link(this);
2960                 }
2961 
2962                 lastStickyAlternativeFailures.link(this);
2963                 removeCallFrame();
2964                 generateFailReturn();
2965                 break;
2966             }
2967             case OpBodyAlternativeEnd: {
2968                 // We should never backtrack back into a body disjunction.
2969                 ASSERT(m_backtrackingState.isEmpty());
2970 
2971                 PatternAlternative* priorAlternative = m_ops[op.m_previousOp].m_alternative;
2972                 m_checkedOffset += priorAlternative-&gt;m_minimumSize;
2973                 break;
2974             }
2975 
2976             // OpSimpleNestedAlternativeBegin/Next/End
2977             // OpNestedAlternativeBegin/Next/End
2978             //
2979             // Generate code for when we backtrack back out of an alternative into
2980             // a Begin or Next node, or when the entry input count check fails. If
2981             // there are more alternatives we need to jump to the next alternative,
2982             // if not we backtrack back out of the current set of parentheses.
2983             //
2984             // In the case of non-simple nested assertions we need to also link the
2985             // &#39;return address&#39; appropriately to backtrack back out into the correct
2986             // alternative.
2987             case OpSimpleNestedAlternativeBegin:
2988             case OpSimpleNestedAlternativeNext:
2989             case OpNestedAlternativeBegin:
2990             case OpNestedAlternativeNext: {
2991                 YarrOp&amp; nextOp = m_ops[op.m_nextOp];
2992                 bool isBegin = op.m_previousOp == notFound;
2993                 bool isLastAlternative = nextOp.m_nextOp == notFound;
2994                 ASSERT(isBegin == (op.m_op == OpSimpleNestedAlternativeBegin || op.m_op == OpNestedAlternativeBegin));
2995                 ASSERT(isLastAlternative == (nextOp.m_op == OpSimpleNestedAlternativeEnd || nextOp.m_op == OpNestedAlternativeEnd));
2996 
2997                 // Treat an input check failure the same as a failed match.
2998                 m_backtrackingState.append(op.m_jumps);
2999 
3000                 // Set the backtracks to jump to the appropriate place. We may need
3001                 // to link the backtracks in one of three different way depending on
3002                 // the type of alternative we are dealing with:
3003                 //  - A single alternative, with no simplings.
3004                 //  - The last alternative of a set of two or more.
3005                 //  - An alternative other than the last of a set of two or more.
3006                 //
3007                 // In the case of a single alternative on its own, we don&#39;t need to
3008                 // jump anywhere - if the alternative fails to match we can just
3009                 // continue to backtrack out of the parentheses without jumping.
3010                 //
3011                 // In the case of the last alternative in a set of more than one, we
3012                 // need to jump to return back out to the beginning. We&#39;ll do so by
3013                 // adding a jump to the End node&#39;s m_jumps list, and linking this
3014                 // when we come to generate the Begin node. For alternatives other
3015                 // than the last, we need to jump to the next alternative.
3016                 //
3017                 // If the alternative had adjusted the input position we must link
3018                 // backtracking to here, correct, and then jump on. If not we can
3019                 // link the backtracks directly to their destination.
3020                 if (op.m_checkAdjust) {
3021                     // Handle the cases where we need to link the backtracks here.
3022                     m_backtrackingState.link(this);
3023                     sub32(Imm32(op.m_checkAdjust.unsafeGet()), index);
3024                     if (!isLastAlternative) {
3025                         // An alternative that is not the last should jump to its successor.
3026                         jump(nextOp.m_reentry);
3027                     } else if (!isBegin) {
3028                         // The last of more than one alternatives must jump back to the beginning.
3029                         nextOp.m_jumps.append(jump());
3030                     } else {
3031                         // A single alternative on its own can fall through.
3032                         m_backtrackingState.fallthrough();
3033                     }
3034                 } else {
3035                     // Handle the cases where we can link the backtracks directly to their destinations.
3036                     if (!isLastAlternative) {
3037                         // An alternative that is not the last should jump to its successor.
3038                         m_backtrackingState.linkTo(nextOp.m_reentry, this);
3039                     } else if (!isBegin) {
3040                         // The last of more than one alternatives must jump back to the beginning.
3041                         m_backtrackingState.takeBacktracksToJumpList(nextOp.m_jumps, this);
3042                     }
3043                     // In the case of a single alternative on its own do nothing - it can fall through.
3044                 }
3045 
3046                 // If there is a backtrack jump from a zero length match link it here.
3047                 if (op.m_zeroLengthMatch.isSet())
3048                     m_backtrackingState.append(op.m_zeroLengthMatch);
3049 
3050                 // At this point we&#39;ve handled the backtracking back into this node.
3051                 // Now link any backtracks that need to jump to here.
3052 
3053                 // For non-simple alternatives, link the alternative&#39;s &#39;return address&#39;
3054                 // so that we backtrack back out into the previous alternative.
3055                 if (op.m_op == OpNestedAlternativeNext)
3056                     m_backtrackingState.append(op.m_returnAddress);
3057 
3058                 // If there is more than one alternative, then the last alternative will
3059                 // have planted a jump to be linked to the end. This jump was added to the
3060                 // End node&#39;s m_jumps list. If we are back at the beginning, link it here.
3061                 if (isBegin) {
3062                     YarrOp* endOp = &amp;m_ops[op.m_nextOp];
3063                     while (endOp-&gt;m_nextOp != notFound) {
3064                         ASSERT(endOp-&gt;m_op == OpSimpleNestedAlternativeNext || endOp-&gt;m_op == OpNestedAlternativeNext);
3065                         endOp = &amp;m_ops[endOp-&gt;m_nextOp];
3066                     }
3067                     ASSERT(endOp-&gt;m_op == OpSimpleNestedAlternativeEnd || endOp-&gt;m_op == OpNestedAlternativeEnd);
3068                     m_backtrackingState.append(endOp-&gt;m_jumps);
3069                 }
3070 
3071                 if (!isBegin) {
3072                     YarrOp&amp; lastOp = m_ops[op.m_previousOp];
3073                     m_checkedOffset += lastOp.m_checkAdjust;
3074                 }
3075                 m_checkedOffset -= op.m_checkAdjust;
3076                 break;
3077             }
3078             case OpSimpleNestedAlternativeEnd:
3079             case OpNestedAlternativeEnd: {
3080                 PatternTerm* term = op.m_term;
3081 
3082                 // If there is a backtrack jump from a zero length match link it here.
3083                 if (op.m_zeroLengthMatch.isSet())
3084                     m_backtrackingState.append(op.m_zeroLengthMatch);
3085 
3086                 // If we backtrack into the end of a simple subpattern do nothing;
3087                 // just continue through into the last alternative. If we backtrack
3088                 // into the end of a non-simple set of alterntives we need to jump
3089                 // to the backtracking return address set up during generation.
3090                 if (op.m_op == OpNestedAlternativeEnd) {
3091                     m_backtrackingState.link(this);
3092 
3093                     // Plant a jump to the return address.
3094                     unsigned parenthesesFrameLocation = term-&gt;frameLocation;
3095                     loadFromFrameAndJump(parenthesesFrameLocation + BackTrackInfoParentheses::returnAddressIndex());
3096 
3097                     // Link the DataLabelPtr associated with the end of the last
3098                     // alternative to this point.
3099                     m_backtrackingState.append(op.m_returnAddress);
3100                 }
3101 
3102                 YarrOp&amp; lastOp = m_ops[op.m_previousOp];
3103                 m_checkedOffset += lastOp.m_checkAdjust;
3104                 break;
3105             }
3106 
3107             // OpParenthesesSubpatternOnceBegin/End
3108             //
3109             // When we are backtracking back out of a capturing subpattern we need
3110             // to clear the start index in the matches output array, to record that
3111             // this subpattern has not been captured.
3112             //
3113             // When backtracking back out of a Greedy quantified subpattern we need
3114             // to catch this, and try running the remainder of the alternative after
3115             // the subpattern again, skipping the parentheses.
3116             //
3117             // Upon backtracking back into a quantified set of parentheses we need to
3118             // check whether we were currently skipping the subpattern. If not, we
3119             // can backtrack into them, if we were we need to either backtrack back
3120             // out of the start of the parentheses, or jump back to the forwards
3121             // matching start, depending of whether the match is Greedy or NonGreedy.
3122             case OpParenthesesSubpatternOnceBegin: {
3123                 PatternTerm* term = op.m_term;
3124                 ASSERT(term-&gt;quantityMaxCount == 1);
3125 
3126                 // We only need to backtrack to this point if capturing or greedy.
3127                 if ((term-&gt;capture() &amp;&amp; compileMode == IncludeSubpatterns) || term-&gt;quantityType == QuantifierGreedy) {
3128                     m_backtrackingState.link(this);
3129 
3130                     // If capturing, clear the capture (we only need to reset start).
3131                     if (term-&gt;capture() &amp;&amp; compileMode == IncludeSubpatterns)
3132                         clearSubpatternStart(term-&gt;parentheses.subpatternId);
3133 
3134                     // If Greedy, jump to the end.
3135                     if (term-&gt;quantityType == QuantifierGreedy) {
3136                         // Clear the flag in the stackframe indicating we ran through the subpattern.
3137                         unsigned parenthesesFrameLocation = term-&gt;frameLocation;
3138                         storeToFrame(TrustedImm32(-1), parenthesesFrameLocation + BackTrackInfoParenthesesOnce::beginIndex());
3139                         // Jump to after the parentheses, skipping the subpattern.
3140                         jump(m_ops[op.m_nextOp].m_reentry);
3141                         // A backtrack from after the parentheses, when skipping the subpattern,
3142                         // will jump back to here.
3143                         op.m_jumps.link(this);
3144                     }
3145 
3146                     m_backtrackingState.fallthrough();
3147                 }
3148                 break;
3149             }
3150             case OpParenthesesSubpatternOnceEnd: {
3151                 PatternTerm* term = op.m_term;
3152 
3153                 if (term-&gt;quantityType != QuantifierFixedCount) {
3154                     m_backtrackingState.link(this);
3155 
3156                     // Check whether we should backtrack back into the parentheses, or if we
3157                     // are currently in a state where we had skipped over the subpattern
3158                     // (in which case the flag value on the stack will be -1).
3159                     unsigned parenthesesFrameLocation = term-&gt;frameLocation;
3160                     Jump hadSkipped = branch32(Equal, Address(stackPointerRegister, (parenthesesFrameLocation + BackTrackInfoParenthesesOnce::beginIndex()) * sizeof(void*)), TrustedImm32(-1));
3161 
3162                     if (term-&gt;quantityType == QuantifierGreedy) {
3163                         // For Greedy parentheses, we skip after having already tried going
3164                         // through the subpattern, so if we get here we&#39;re done.
3165                         YarrOp&amp; beginOp = m_ops[op.m_previousOp];
3166                         beginOp.m_jumps.append(hadSkipped);
3167                     } else {
3168                         // For NonGreedy parentheses, we try skipping the subpattern first,
3169                         // so if we get here we need to try running through the subpattern
3170                         // next. Jump back to the start of the parentheses in the forwards
3171                         // matching path.
3172                         ASSERT(term-&gt;quantityType == QuantifierNonGreedy);
3173                         YarrOp&amp; beginOp = m_ops[op.m_previousOp];
3174                         hadSkipped.linkTo(beginOp.m_reentry, this);
3175                     }
3176 
3177                     m_backtrackingState.fallthrough();
3178                 }
3179 
3180                 m_backtrackingState.append(op.m_jumps);
3181                 break;
3182             }
3183 
3184             // OpParenthesesSubpatternTerminalBegin/End
3185             //
3186             // Terminal subpatterns will always match - there is nothing after them to
3187             // force a backtrack, and they have a minimum count of 0, and as such will
3188             // always produce an acceptable result.
3189             case OpParenthesesSubpatternTerminalBegin: {
3190                 // We will backtrack to this point once the subpattern cannot match any
3191                 // more. Since no match is accepted as a successful match (we are Greedy
3192                 // quantified with a minimum of zero) jump back to the forwards matching
3193                 // path at the end.
3194                 YarrOp&amp; endOp = m_ops[op.m_nextOp];
3195                 m_backtrackingState.linkTo(endOp.m_reentry, this);
3196                 break;
3197             }
3198             case OpParenthesesSubpatternTerminalEnd:
3199                 // We should never be backtracking to here (hence the &#39;terminal&#39; in the name).
3200                 ASSERT(m_backtrackingState.isEmpty());
3201                 m_backtrackingState.append(op.m_jumps);
3202                 break;
3203 
3204             // OpParenthesesSubpatternBegin/End
3205             //
3206             // When we are backtracking back out of a capturing subpattern we need
3207             // to clear the start index in the matches output array, to record that
3208             // this subpattern has not been captured.
3209             //
3210             // When backtracking back out of a Greedy quantified subpattern we need
3211             // to catch this, and try running the remainder of the alternative after
3212             // the subpattern again, skipping the parentheses.
3213             //
3214             // Upon backtracking back into a quantified set of parentheses we need to
3215             // check whether we were currently skipping the subpattern. If not, we
3216             // can backtrack into them, if we were we need to either backtrack back
3217             // out of the start of the parentheses, or jump back to the forwards
3218             // matching start, depending of whether the match is Greedy or NonGreedy.
3219             case OpParenthesesSubpatternBegin: {
3220 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3221                 PatternTerm* term = op.m_term;
3222                 unsigned parenthesesFrameLocation = term-&gt;frameLocation;
3223 
3224                 if (term-&gt;quantityType != QuantifierFixedCount) {
3225                     m_backtrackingState.link(this);
3226 
3227                     RegisterID currParenContextReg = regT0;
3228                     RegisterID newParenContextReg = regT1;
3229 
3230                     loadFromFrame(parenthesesFrameLocation + BackTrackInfoParentheses::parenContextHeadIndex(), currParenContextReg);
3231 
3232                     restoreParenContext(currParenContextReg, regT2, term-&gt;parentheses.subpatternId, term-&gt;parentheses.lastSubpatternId, parenthesesFrameLocation);
3233 
3234                     freeParenContext(currParenContextReg, newParenContextReg);
3235                     storeToFrame(newParenContextReg, parenthesesFrameLocation + BackTrackInfoParentheses::parenContextHeadIndex());
3236 
3237                     const RegisterID countTemporary = regT0;
3238                     loadFromFrame(parenthesesFrameLocation + BackTrackInfoParentheses::matchAmountIndex(), countTemporary);
3239                     Jump zeroLengthMatch = branchTest32(Zero, countTemporary);
3240 
3241                     sub32(TrustedImm32(1), countTemporary);
3242                     storeToFrame(countTemporary, parenthesesFrameLocation + BackTrackInfoParentheses::matchAmountIndex());
3243 
3244                     jump(m_ops[op.m_nextOp].m_reentry);
3245 
3246                     zeroLengthMatch.link(this);
3247 
3248                     // Clear the flag in the stackframe indicating we didn&#39;t run through the subpattern.
3249                     storeToFrame(TrustedImm32(-1), parenthesesFrameLocation + BackTrackInfoParentheses::beginIndex());
3250 
3251                     if (term-&gt;quantityType == QuantifierGreedy)
3252                         jump(m_ops[op.m_nextOp].m_reentry);
3253 
3254                     // If Greedy, jump to the end.
3255                     if (term-&gt;quantityType == QuantifierGreedy) {
3256                         // A backtrack from after the parentheses, when skipping the subpattern,
3257                         // will jump back to here.
3258                         op.m_jumps.link(this);
3259                     }
3260 
3261                     m_backtrackingState.fallthrough();
3262                 }
3263 #else // !YARR_JIT_ALL_PARENS_EXPRESSIONS
3264                 RELEASE_ASSERT_NOT_REACHED();
3265 #endif
3266                 break;
3267             }
3268             case OpParenthesesSubpatternEnd: {
3269 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3270                 PatternTerm* term = op.m_term;
3271 
3272                 if (term-&gt;quantityType != QuantifierFixedCount) {
3273                     m_backtrackingState.link(this);
3274 
3275                     unsigned parenthesesFrameLocation = term-&gt;frameLocation;
3276 
3277                     if (term-&gt;quantityType == QuantifierGreedy) {
3278                         // Check whether we should backtrack back into the parentheses, or if we
3279                         // are currently in a state where we had skipped over the subpattern
3280                         // (in which case the flag value on the stack will be -1).
3281                         Jump hadSkipped = branch32(Equal, Address(stackPointerRegister, (parenthesesFrameLocation  + BackTrackInfoParentheses::beginIndex()) * sizeof(void*)), TrustedImm32(-1));
3282 
3283                         // For Greedy parentheses, we skip after having already tried going
3284                         // through the subpattern, so if we get here we&#39;re done.
3285                         YarrOp&amp; beginOp = m_ops[op.m_previousOp];
3286                         beginOp.m_jumps.append(hadSkipped);
3287                     } else {
3288                         // For NonGreedy parentheses, we try skipping the subpattern first,
3289                         // so if we get here we need to try running through the subpattern
3290                         // next. Jump back to the start of the parentheses in the forwards
3291                         // matching path.
3292                         ASSERT(term-&gt;quantityType == QuantifierNonGreedy);
3293 
3294                         const RegisterID beginTemporary = regT0;
3295                         const RegisterID countTemporary = regT1;
3296 
3297                         YarrOp&amp; beginOp = m_ops[op.m_previousOp];
3298 
3299                         loadFromFrame(parenthesesFrameLocation + BackTrackInfoParentheses::beginIndex(), beginTemporary);
3300                         branch32(Equal, beginTemporary, TrustedImm32(-1)).linkTo(beginOp.m_reentry, this);
3301 
3302                         JumpList exceededMatchLimit;
3303 
3304                         if (term-&gt;quantityMaxCount != quantifyInfinite) {
3305                             loadFromFrame(parenthesesFrameLocation + BackTrackInfoParentheses::matchAmountIndex(), countTemporary);
3306                             exceededMatchLimit.append(branch32(AboveOrEqual, countTemporary, Imm32(term-&gt;quantityMaxCount.unsafeGet())));
3307                         }
3308 
3309                         branch32(Above, index, beginTemporary).linkTo(beginOp.m_reentry, this);
3310 
3311                         exceededMatchLimit.link(this);
3312                     }
3313 
3314                     m_backtrackingState.fallthrough();
3315                 }
3316 
3317                 m_backtrackingState.append(op.m_jumps);
3318 #else // !YARR_JIT_ALL_PARENS_EXPRESSIONS
3319                 RELEASE_ASSERT_NOT_REACHED();
3320 #endif
3321                 break;
3322             }
3323 
3324             // OpParentheticalAssertionBegin/End
3325             case OpParentheticalAssertionBegin: {
3326                 PatternTerm* term = op.m_term;
3327                 YarrOp&amp; endOp = m_ops[op.m_nextOp];
3328 
3329                 // We need to handle the backtracks upon backtracking back out
3330                 // of a parenthetical assertion if either we need to correct
3331                 // the input index, or the assertion was inverted.
3332                 if (op.m_checkAdjust || term-&gt;invert()) {
3333                      m_backtrackingState.link(this);
3334 
3335                     if (op.m_checkAdjust)
3336                         add32(Imm32(op.m_checkAdjust.unsafeGet()), index);
3337 
3338                     // In an inverted assertion failure to match the subpattern
3339                     // is treated as a successful match - jump to the end of the
3340                     // subpattern. We already have adjusted the input position
3341                     // back to that before the assertion, which is correct.
3342                     if (term-&gt;invert())
3343                         jump(endOp.m_reentry);
3344 
3345                     m_backtrackingState.fallthrough();
3346                 }
3347 
3348                 // The End node&#39;s jump list will contain any backtracks into
3349                 // the end of the assertion. Also, if inverted, we will have
3350                 // added the failure caused by a successful match to this.
3351                 m_backtrackingState.append(endOp.m_jumps);
3352 
3353                 m_checkedOffset += op.m_checkAdjust;
3354                 break;
3355             }
3356             case OpParentheticalAssertionEnd: {
3357                 // FIXME: We should really be clearing any nested subpattern
3358                 // matches on bailing out from after the pattern. Firefox has
3359                 // this bug too (presumably because they use YARR!)
3360 
3361                 // Never backtrack into an assertion; later failures bail to before the begin.
3362                 m_backtrackingState.takeBacktracksToJumpList(op.m_jumps, this);
3363 
3364                 YarrOp&amp; lastOp = m_ops[op.m_previousOp];
3365                 m_checkedOffset -= lastOp.m_checkAdjust;
3366                 break;
3367             }
3368 
3369             case OpMatchFailed:
3370                 break;
3371             }
3372 
3373         } while (opIndex);
3374     }
3375 
3376     // Compilation methods:
3377     // ====================
3378 
3379     // opCompileParenthesesSubpattern
3380     // Emits ops for a subpattern (set of parentheses). These consist
3381     // of a set of alternatives wrapped in an outer set of nodes for
3382     // the parentheses.
3383     // Supported types of parentheses are &#39;Once&#39; (quantityMaxCount == 1),
3384     // &#39;Terminal&#39; (non-capturing parentheses quantified as greedy
3385     // and infinite), and 0 based greedy / non-greedy quantified parentheses.
3386     // Alternatives will use the &#39;Simple&#39; set of ops if either the
3387     // subpattern is terminal (in which case we will never need to
3388     // backtrack), or if the subpattern only contains one alternative.
3389     void opCompileParenthesesSubpattern(PatternTerm* term)
3390     {
3391         YarrOpCode parenthesesBeginOpCode;
3392         YarrOpCode parenthesesEndOpCode;
3393         YarrOpCode alternativeBeginOpCode = OpSimpleNestedAlternativeBegin;
3394         YarrOpCode alternativeNextOpCode = OpSimpleNestedAlternativeNext;
3395         YarrOpCode alternativeEndOpCode = OpSimpleNestedAlternativeEnd;
3396 
3397         if (UNLIKELY(!m_vm-&gt;isSafeToRecurse())) {
3398             m_failureReason = JITFailureReason::ParenthesisNestedTooDeep;
3399             return;
3400         }
3401 
3402         // We can currently only compile quantity 1 subpatterns that are
3403         // not copies. We generate a copy in the case of a range quantifier,
3404         // e.g. /(?:x){3,9}/, or /(?:x)+/ (These are effectively expanded to
3405         // /(?:x){3,3}(?:x){0,6}/ and /(?:x)(?:x)*/ repectively). The problem
3406         // comes where the subpattern is capturing, in which case we would
3407         // need to restore the capture from the first subpattern upon a
3408         // failure in the second.
3409         if (term-&gt;quantityMinCount &amp;&amp; term-&gt;quantityMinCount != term-&gt;quantityMaxCount) {
3410             m_failureReason = JITFailureReason::VariableCountedParenthesisWithNonZeroMinimum;
3411             return;
3412         }
3413 
3414         if (term-&gt;quantityMaxCount == 1 &amp;&amp; !term-&gt;parentheses.isCopy) {
3415             // Select the &#39;Once&#39; nodes.
3416             parenthesesBeginOpCode = OpParenthesesSubpatternOnceBegin;
3417             parenthesesEndOpCode = OpParenthesesSubpatternOnceEnd;
3418 
3419             // If there is more than one alternative we cannot use the &#39;simple&#39; nodes.
3420             if (term-&gt;parentheses.disjunction-&gt;m_alternatives.size() != 1) {
3421                 alternativeBeginOpCode = OpNestedAlternativeBegin;
3422                 alternativeNextOpCode = OpNestedAlternativeNext;
3423                 alternativeEndOpCode = OpNestedAlternativeEnd;
3424             }
3425         } else if (term-&gt;parentheses.isTerminal) {
3426             // Select the &#39;Terminal&#39; nodes.
3427             parenthesesBeginOpCode = OpParenthesesSubpatternTerminalBegin;
3428             parenthesesEndOpCode = OpParenthesesSubpatternTerminalEnd;
3429         } else {
3430 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3431             // We only handle generic parenthesis with non-fixed counts.
3432             if (term-&gt;quantityType == QuantifierFixedCount) {
3433                 // This subpattern is not supported by the JIT.
3434                 m_failureReason = JITFailureReason::FixedCountParenthesizedSubpattern;
3435                 return;
3436             }
3437 
3438             m_containsNestedSubpatterns = true;
3439 
3440             // Select the &#39;Generic&#39; nodes.
3441             parenthesesBeginOpCode = OpParenthesesSubpatternBegin;
3442             parenthesesEndOpCode = OpParenthesesSubpatternEnd;
3443 
3444             // If there is more than one alternative we cannot use the &#39;simple&#39; nodes.
3445             if (term-&gt;parentheses.disjunction-&gt;m_alternatives.size() != 1) {
3446                 alternativeBeginOpCode = OpNestedAlternativeBegin;
3447                 alternativeNextOpCode = OpNestedAlternativeNext;
3448                 alternativeEndOpCode = OpNestedAlternativeEnd;
3449             }
3450 #else
3451             // This subpattern is not supported by the JIT.
3452             m_failureReason = JITFailureReason::ParenthesizedSubpattern;
3453             return;
3454 #endif
3455         }
3456 
3457         size_t parenBegin = m_ops.size();
3458         m_ops.append(parenthesesBeginOpCode);
3459 
3460         m_ops.append(alternativeBeginOpCode);
3461         m_ops.last().m_previousOp = notFound;
3462         m_ops.last().m_term = term;
3463         Vector&lt;std::unique_ptr&lt;PatternAlternative&gt;&gt;&amp; alternatives = term-&gt;parentheses.disjunction-&gt;m_alternatives;
3464         for (unsigned i = 0; i &lt; alternatives.size(); ++i) {
3465             size_t lastOpIndex = m_ops.size() - 1;
3466 
3467             PatternAlternative* nestedAlternative = alternatives[i].get();
3468             opCompileAlternative(nestedAlternative);
3469 
3470             size_t thisOpIndex = m_ops.size();
3471             m_ops.append(YarrOp(alternativeNextOpCode));
3472 
3473             YarrOp&amp; lastOp = m_ops[lastOpIndex];
3474             YarrOp&amp; thisOp = m_ops[thisOpIndex];
3475 
3476             lastOp.m_alternative = nestedAlternative;
3477             lastOp.m_nextOp = thisOpIndex;
3478             thisOp.m_previousOp = lastOpIndex;
3479             thisOp.m_term = term;
3480         }
3481         YarrOp&amp; lastOp = m_ops.last();
3482         ASSERT(lastOp.m_op == alternativeNextOpCode);
3483         lastOp.m_op = alternativeEndOpCode;
3484         lastOp.m_alternative = 0;
3485         lastOp.m_nextOp = notFound;
3486 
3487         size_t parenEnd = m_ops.size();
3488         m_ops.append(parenthesesEndOpCode);
3489 
3490         m_ops[parenBegin].m_term = term;
3491         m_ops[parenBegin].m_previousOp = notFound;
3492         m_ops[parenBegin].m_nextOp = parenEnd;
3493         m_ops[parenEnd].m_term = term;
3494         m_ops[parenEnd].m_previousOp = parenBegin;
3495         m_ops[parenEnd].m_nextOp = notFound;
3496     }
3497 
3498     // opCompileParentheticalAssertion
3499     // Emits ops for a parenthetical assertion. These consist of an
3500     // OpSimpleNestedAlternativeBegin/Next/End set of nodes wrapping
3501     // the alternatives, with these wrapped by an outer pair of
3502     // OpParentheticalAssertionBegin/End nodes.
3503     // We can always use the OpSimpleNestedAlternative nodes in the
3504     // case of parenthetical assertions since these only ever match
3505     // once, and will never backtrack back into the assertion.
3506     void opCompileParentheticalAssertion(PatternTerm* term)
3507     {
3508         if (UNLIKELY(!m_vm-&gt;isSafeToRecurse())) {
3509             m_failureReason = JITFailureReason::ParenthesisNestedTooDeep;
3510             return;
3511         }
3512 
3513         size_t parenBegin = m_ops.size();
3514         m_ops.append(OpParentheticalAssertionBegin);
3515 
3516         m_ops.append(OpSimpleNestedAlternativeBegin);
3517         m_ops.last().m_previousOp = notFound;
3518         m_ops.last().m_term = term;
3519         Vector&lt;std::unique_ptr&lt;PatternAlternative&gt;&gt;&amp; alternatives =  term-&gt;parentheses.disjunction-&gt;m_alternatives;
3520         for (unsigned i = 0; i &lt; alternatives.size(); ++i) {
3521             size_t lastOpIndex = m_ops.size() - 1;
3522 
3523             PatternAlternative* nestedAlternative = alternatives[i].get();
3524             opCompileAlternative(nestedAlternative);
3525 
3526             size_t thisOpIndex = m_ops.size();
3527             m_ops.append(YarrOp(OpSimpleNestedAlternativeNext));
3528 
3529             YarrOp&amp; lastOp = m_ops[lastOpIndex];
3530             YarrOp&amp; thisOp = m_ops[thisOpIndex];
3531 
3532             lastOp.m_alternative = nestedAlternative;
3533             lastOp.m_nextOp = thisOpIndex;
3534             thisOp.m_previousOp = lastOpIndex;
3535             thisOp.m_term = term;
3536         }
3537         YarrOp&amp; lastOp = m_ops.last();
3538         ASSERT(lastOp.m_op == OpSimpleNestedAlternativeNext);
3539         lastOp.m_op = OpSimpleNestedAlternativeEnd;
3540         lastOp.m_alternative = 0;
3541         lastOp.m_nextOp = notFound;
3542 
3543         size_t parenEnd = m_ops.size();
3544         m_ops.append(OpParentheticalAssertionEnd);
3545 
3546         m_ops[parenBegin].m_term = term;
3547         m_ops[parenBegin].m_previousOp = notFound;
3548         m_ops[parenBegin].m_nextOp = parenEnd;
3549         m_ops[parenEnd].m_term = term;
3550         m_ops[parenEnd].m_previousOp = parenBegin;
3551         m_ops[parenEnd].m_nextOp = notFound;
3552     }
3553 
3554     // opCompileAlternative
3555     // Called to emit nodes for all terms in an alternative.
3556     void opCompileAlternative(PatternAlternative* alternative)
3557     {
3558         optimizeAlternative(alternative);
3559 
3560         for (unsigned i = 0; i &lt; alternative-&gt;m_terms.size(); ++i) {
3561             PatternTerm* term = &amp;alternative-&gt;m_terms[i];
3562 
3563             switch (term-&gt;type) {
3564             case PatternTerm::TypeParenthesesSubpattern:
3565                 opCompileParenthesesSubpattern(term);
3566                 break;
3567 
3568             case PatternTerm::TypeParentheticalAssertion:
3569                 opCompileParentheticalAssertion(term);
3570                 break;
3571 
3572             default:
3573                 m_ops.append(term);
3574             }
3575         }
3576     }
3577 
3578     // opCompileBody
3579     // This method compiles the body disjunction of the regular expression.
3580     // The body consists of two sets of alternatives - zero or more &#39;once
3581     // through&#39; (BOL anchored) alternatives, followed by zero or more
3582     // repeated alternatives.
3583     // For each of these two sets of alteratives, if not empty they will be
3584     // wrapped in a set of OpBodyAlternativeBegin/Next/End nodes (with the
3585     // &#39;begin&#39; node referencing the first alternative, and &#39;next&#39; nodes
3586     // referencing any further alternatives. The begin/next/end nodes are
3587     // linked together in a doubly linked list. In the case of repeating
3588     // alternatives, the end node is also linked back to the beginning.
3589     // If no repeating alternatives exist, then a OpMatchFailed node exists
3590     // to return the failing result.
3591     void opCompileBody(PatternDisjunction* disjunction)
3592     {
3593         if (UNLIKELY(!m_vm-&gt;isSafeToRecurse())) {
3594             m_failureReason = JITFailureReason::ParenthesisNestedTooDeep;
3595             return;
3596         }
3597 
3598         Vector&lt;std::unique_ptr&lt;PatternAlternative&gt;&gt;&amp; alternatives = disjunction-&gt;m_alternatives;
3599         size_t currentAlternativeIndex = 0;
3600 
3601         // Emit the &#39;once through&#39; alternatives.
3602         if (alternatives.size() &amp;&amp; alternatives[0]-&gt;onceThrough()) {
3603             m_ops.append(YarrOp(OpBodyAlternativeBegin));
3604             m_ops.last().m_previousOp = notFound;
3605 
3606             do {
3607                 size_t lastOpIndex = m_ops.size() - 1;
3608                 PatternAlternative* alternative = alternatives[currentAlternativeIndex].get();
3609                 opCompileAlternative(alternative);
3610 
3611                 size_t thisOpIndex = m_ops.size();
3612                 m_ops.append(YarrOp(OpBodyAlternativeNext));
3613 
3614                 YarrOp&amp; lastOp = m_ops[lastOpIndex];
3615                 YarrOp&amp; thisOp = m_ops[thisOpIndex];
3616 
3617                 lastOp.m_alternative = alternative;
3618                 lastOp.m_nextOp = thisOpIndex;
3619                 thisOp.m_previousOp = lastOpIndex;
3620 
3621                 ++currentAlternativeIndex;
3622             } while (currentAlternativeIndex &lt; alternatives.size() &amp;&amp; alternatives[currentAlternativeIndex]-&gt;onceThrough());
3623 
3624             YarrOp&amp; lastOp = m_ops.last();
3625 
3626             ASSERT(lastOp.m_op == OpBodyAlternativeNext);
3627             lastOp.m_op = OpBodyAlternativeEnd;
3628             lastOp.m_alternative = 0;
3629             lastOp.m_nextOp = notFound;
3630         }
3631 
3632         if (currentAlternativeIndex == alternatives.size()) {
3633             m_ops.append(YarrOp(OpMatchFailed));
3634             return;
3635         }
3636 
3637         // Emit the repeated alternatives.
3638         size_t repeatLoop = m_ops.size();
3639         m_ops.append(YarrOp(OpBodyAlternativeBegin));
3640         m_ops.last().m_previousOp = notFound;
3641         do {
3642             size_t lastOpIndex = m_ops.size() - 1;
3643             PatternAlternative* alternative = alternatives[currentAlternativeIndex].get();
3644             ASSERT(!alternative-&gt;onceThrough());
3645             opCompileAlternative(alternative);
3646 
3647             size_t thisOpIndex = m_ops.size();
3648             m_ops.append(YarrOp(OpBodyAlternativeNext));
3649 
3650             YarrOp&amp; lastOp = m_ops[lastOpIndex];
3651             YarrOp&amp; thisOp = m_ops[thisOpIndex];
3652 
3653             lastOp.m_alternative = alternative;
3654             lastOp.m_nextOp = thisOpIndex;
3655             thisOp.m_previousOp = lastOpIndex;
3656 
3657             ++currentAlternativeIndex;
3658         } while (currentAlternativeIndex &lt; alternatives.size());
3659         YarrOp&amp; lastOp = m_ops.last();
3660         ASSERT(lastOp.m_op == OpBodyAlternativeNext);
3661         lastOp.m_op = OpBodyAlternativeEnd;
3662         lastOp.m_alternative = 0;
3663         lastOp.m_nextOp = repeatLoop;
3664     }
3665 
3666     void generateTryReadUnicodeCharacterHelper()
3667     {
3668 #ifdef JIT_UNICODE_EXPRESSIONS
3669         if (m_tryReadUnicodeCharacterCalls.isEmpty())
3670             return;
3671 
3672         ASSERT(m_decodeSurrogatePairs);
3673 
3674         m_tryReadUnicodeCharacterEntry = label();
3675 
3676         tagReturnAddress();
3677 
3678         tryReadUnicodeCharImpl(regT0);
3679 
3680         ret();
3681 #endif
3682     }
3683 
3684     void generateEnter()
3685     {
3686 #if CPU(X86_64)
3687         push(X86Registers::ebp);
3688         move(stackPointerRegister, X86Registers::ebp);
3689 
3690         if (m_pattern.m_saveInitialStartValue)
3691             push(X86Registers::ebx);
3692 
3693 #if OS(WINDOWS)
3694         push(X86Registers::edi);
3695 #endif
3696 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3697         if (m_containsNestedSubpatterns) {
3698 #if OS(WINDOWS)
3699             push(X86Registers::esi);
3700 #endif
3701             push(X86Registers::r12);
3702         }
3703 #endif
3704 
3705         if (m_decodeSurrogatePairs) {
3706             push(X86Registers::r13);
3707             push(X86Registers::r14);
3708             push(X86Registers::r15);
<a name="21" id="anc21"></a>

3709         }
3710         // The ABI doesn&#39;t guarantee the upper bits are zero on unsigned arguments, so clear them ourselves.
3711         zeroExtend32ToPtr(index, index);
3712         zeroExtend32ToPtr(length, length);
3713 #if OS(WINDOWS)
3714         if (compileMode == IncludeSubpatterns)
3715             loadPtr(Address(X86Registers::ebp, 6 * sizeof(void*)), output);
3716         // rcx is the pointer to the allocated space for result in x64 Windows.
3717         push(X86Registers::ecx);
3718 #endif
<a name="22" id="anc22"></a>

















3719 #elif CPU(ARM64)
3720         tagReturnAddress();
3721         if (m_decodeSurrogatePairs) {
3722             pushPair(framePointerRegister, linkRegister);
3723             move(TrustedImm32(0x10000), supplementaryPlanesBase);
3724             move(TrustedImm32(0xd800), leadingSurrogateTag);
3725             move(TrustedImm32(0xdc00), trailingSurrogateTag);
3726         }
3727 
3728         // The ABI doesn&#39;t guarantee the upper bits are zero on unsigned arguments, so clear them ourselves.
3729         zeroExtend32ToPtr(index, index);
3730         zeroExtend32ToPtr(length, length);
3731 #elif CPU(ARM_THUMB2)
3732         push(ARMRegisters::r4);
3733         push(ARMRegisters::r5);
3734         push(ARMRegisters::r6);
3735         push(ARMRegisters::r8);
3736 #elif CPU(MIPS)
3737         // Do nothing.
3738 #endif
3739 
3740         store8(TrustedImm32(1), &amp;m_vm-&gt;isExecutingInRegExpJIT);
3741     }
3742 
3743     void generateReturn()
3744     {
3745         store8(TrustedImm32(0), &amp;m_vm-&gt;isExecutingInRegExpJIT);
3746 
3747 #if CPU(X86_64)
3748 #if OS(WINDOWS)
3749         // Store the return value in the allocated space pointed by rcx.
3750         pop(X86Registers::ecx);
3751         store64(returnRegister, Address(X86Registers::ecx));
3752         store64(returnRegister2, Address(X86Registers::ecx, sizeof(void*)));
3753         move(X86Registers::ecx, returnRegister);
3754 #endif
3755         if (m_decodeSurrogatePairs) {
3756             pop(X86Registers::r15);
3757             pop(X86Registers::r14);
3758             pop(X86Registers::r13);
3759         }
3760 
3761 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3762         if (m_containsNestedSubpatterns) {
3763             pop(X86Registers::r12);
3764 #if OS(WINDOWS)
3765             pop(X86Registers::esi);
3766 #endif
3767         }
3768 #endif
3769 #if OS(WINDOWS)
3770         pop(X86Registers::edi);
3771 #endif
3772 
3773         if (m_pattern.m_saveInitialStartValue)
3774             pop(X86Registers::ebx);
3775         pop(X86Registers::ebp);
<a name="23" id="anc23"></a>




3776 #elif CPU(ARM64)
3777         if (m_decodeSurrogatePairs)
3778             popPair(framePointerRegister, linkRegister);
3779 #elif CPU(ARM_THUMB2)
3780         pop(ARMRegisters::r8);
3781         pop(ARMRegisters::r6);
3782         pop(ARMRegisters::r5);
3783         pop(ARMRegisters::r4);
3784 #elif CPU(MIPS)
3785         // Do nothing
3786 #endif
3787         ret();
3788     }
3789 
3790 public:
3791     YarrGenerator(VM* vm, YarrPattern&amp; pattern, String&amp; patternString, YarrCodeBlock&amp; codeBlock, YarrCharSize charSize)
3792         : m_vm(vm)
3793         , m_pattern(pattern)
3794         , m_patternString(patternString)
3795         , m_codeBlock(codeBlock)
3796         , m_charSize(charSize)
3797         , m_decodeSurrogatePairs(m_charSize == Char16 &amp;&amp; m_pattern.unicode())
3798         , m_unicodeIgnoreCase(m_pattern.unicode() &amp;&amp; m_pattern.ignoreCase())
3799         , m_fixedSizedAlternative(false)
3800         , m_canonicalMode(m_pattern.unicode() ? CanonicalMode::Unicode : CanonicalMode::UCS2)
3801 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3802         , m_containsNestedSubpatterns(false)
3803         , m_parenContextSizes(compileMode == IncludeSubpatterns ? m_pattern.m_numSubpatterns : 0, m_pattern.m_body-&gt;m_callFrameSize)
3804 #endif
3805     {
3806     }
3807 
3808     void compile()
3809     {
3810         YarrCodeBlock&amp; codeBlock = m_codeBlock;
3811 
3812 #ifndef JIT_UNICODE_EXPRESSIONS
3813         if (m_decodeSurrogatePairs) {
3814             codeBlock.setFallBackWithFailureReason(JITFailureReason::DecodeSurrogatePair);
3815             return;
3816         }
3817 #endif
3818 
3819         if (m_pattern.m_containsBackreferences
3820 #if ENABLE(YARR_JIT_BACKREFERENCES)
3821             &amp;&amp; (compileMode == MatchOnly || (m_pattern.ignoreCase() &amp;&amp; m_charSize != Char8))
3822 #endif
3823             ) {
3824                 codeBlock.setFallBackWithFailureReason(JITFailureReason::BackReference);
3825                 return;
3826         }
3827 
3828         // We need to compile before generating code since we set flags based on compilation that
3829         // are used during generation.
3830         opCompileBody(m_pattern.m_body);
3831 
3832         if (m_failureReason) {
3833             codeBlock.setFallBackWithFailureReason(*m_failureReason);
3834             return;
3835         }
3836 
3837         if (UNLIKELY(Options::dumpDisassembly() || Options::dumpRegExpDisassembly()))
3838             m_disassembler = makeUnique&lt;YarrDisassembler&gt;(this);
3839 
3840         if (m_disassembler)
3841             m_disassembler-&gt;setStartOfCode(label());
3842 
3843 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3844         if (m_containsNestedSubpatterns)
3845             codeBlock.setUsesPatternContextBuffer();
3846 #endif
3847 
3848         generateEnter();
3849 
3850         Jump hasInput = checkInput();
3851         generateFailReturn();
3852         hasInput.link(this);
3853 
3854 #ifdef JIT_UNICODE_EXPRESSIONS
3855         if (m_decodeSurrogatePairs)
3856             getEffectiveAddress(BaseIndex(input, length, TimesTwo), endOfStringAddress);
3857 #endif
3858 
3859 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3860         if (m_containsNestedSubpatterns)
3861             move(TrustedImm32(matchLimit), remainingMatchCount);
3862 #endif
3863 
3864         if (compileMode == IncludeSubpatterns) {
3865             for (unsigned i = 0; i &lt; m_pattern.m_numSubpatterns + 1; ++i)
3866                 store32(TrustedImm32(-1), Address(output, (i &lt;&lt; 1) * sizeof(int)));
3867         }
3868 
3869         if (!m_pattern.m_body-&gt;m_hasFixedSize)
3870             setMatchStart(index);
3871 
3872         initCallFrame();
3873 
3874 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3875         if (m_containsNestedSubpatterns) {
3876             initParenContextFreeList();
3877             if (m_failureReason) {
3878                 codeBlock.setFallBackWithFailureReason(*m_failureReason);
3879                 return;
3880             }
3881         }
3882 #endif
3883 
<a name="24" id="anc24"></a><span class="line-modified">3884         if (m_pattern.m_saveInitialStartValue)</span>

3885             move(index, initialStart);
<a name="25" id="anc25"></a>



3886 
3887         generate();
3888         if (m_disassembler)
3889             m_disassembler-&gt;setEndOfGenerate(label());
3890         backtrack();
3891         if (m_disassembler)
3892             m_disassembler-&gt;setEndOfBacktrack(label());
3893 
3894         generateTryReadUnicodeCharacterHelper();
3895 
3896         generateJITFailReturn();
3897 
3898         if (m_disassembler)
3899             m_disassembler-&gt;setEndOfCode(label());
3900 
3901         LinkBuffer linkBuffer(*this, REGEXP_CODE_ID, JITCompilationCanFail);
3902         if (linkBuffer.didFailToAllocate()) {
3903             codeBlock.setFallBackWithFailureReason(JITFailureReason::ExecutableMemoryAllocationFailure);
3904             return;
3905         }
3906 
3907         if (!m_tryReadUnicodeCharacterCalls.isEmpty()) {
3908             CodeLocationLabel&lt;NoPtrTag&gt; tryReadUnicodeCharacterHelper = linkBuffer.locationOf&lt;NoPtrTag&gt;(m_tryReadUnicodeCharacterEntry);
3909 
3910             for (auto call : m_tryReadUnicodeCharacterCalls)
3911                 linkBuffer.link(call, tryReadUnicodeCharacterHelper);
3912         }
3913 
3914         m_backtrackingState.linkDataLabels(linkBuffer);
3915 
3916         if (m_disassembler)
3917             m_disassembler-&gt;dump(linkBuffer);
3918 
3919         if (compileMode == MatchOnly) {
3920             if (m_charSize == Char8)
3921                 codeBlock.set8BitCodeMatchOnly(FINALIZE_REGEXP_CODE(linkBuffer, YarrMatchOnly8BitPtrTag, &quot;Match-only 8-bit regular expression&quot;));
3922             else
3923                 codeBlock.set16BitCodeMatchOnly(FINALIZE_REGEXP_CODE(linkBuffer, YarrMatchOnly16BitPtrTag, &quot;Match-only 16-bit regular expression&quot;));
3924         } else {
3925             if (m_charSize == Char8)
3926                 codeBlock.set8BitCode(FINALIZE_REGEXP_CODE(linkBuffer, Yarr8BitPtrTag, &quot;8-bit regular expression&quot;));
3927             else
3928                 codeBlock.set16BitCode(FINALIZE_REGEXP_CODE(linkBuffer, Yarr16BitPtrTag, &quot;16-bit regular expression&quot;));
3929         }
3930         if (m_failureReason)
3931             codeBlock.setFallBackWithFailureReason(*m_failureReason);
3932     }
3933 
3934     const char* variant() override
3935     {
3936         if (compileMode == MatchOnly) {
3937             if (m_charSize == Char8)
3938                 return &quot;Match-only 8-bit regular expression&quot;;
3939 
3940             return &quot;Match-only 16-bit regular expression&quot;;
3941         }
3942 
3943         if (m_charSize == Char8)
3944             return &quot;8-bit regular expression&quot;;
3945 
3946         return &quot;16-bit regular expression&quot;;
3947     }
3948 
3949     unsigned opCount() override
3950     {
3951         return m_ops.size();
3952     }
3953 
3954     void dumpPatternString(PrintStream&amp; out) override
3955     {
3956         m_pattern.dumpPatternString(out, m_patternString);
3957     }
3958 
3959     int dumpFor(PrintStream&amp; out, unsigned opIndex) override
3960     {
3961         if (opIndex &gt;= opCount())
3962             return 0;
3963 
3964         out.printf(&quot;%4d:&quot;, opIndex);
3965 
3966         YarrOp&amp; op = m_ops[opIndex];
3967         PatternTerm* term = op.m_term;
3968         switch (op.m_op) {
3969         case OpTerm: {
3970             out.print(&quot;OpTerm &quot;);
3971             switch (term-&gt;type) {
3972             case PatternTerm::TypeAssertionBOL:
3973                 out.print(&quot;Assert BOL&quot;);
3974                 break;
3975 
3976             case PatternTerm::TypeAssertionEOL:
3977                 out.print(&quot;Assert EOL&quot;);
3978                 break;
3979 
3980             case PatternTerm::TypeBackReference:
3981                 out.printf(&quot;BackReference pattern #%u&quot;, term-&gt;backReferenceSubpatternId);
3982                 term-&gt;dumpQuantifier(out);
3983                 break;
3984 
3985             case PatternTerm::TypePatternCharacter:
3986                 out.print(&quot;TypePatternCharacter &quot;);
3987                 dumpUChar32(out, term-&gt;patternCharacter);
3988                 if (m_pattern.ignoreCase())
3989                     out.print(&quot; ignore case&quot;);
3990 
3991                 term-&gt;dumpQuantifier(out);
3992                 break;
3993 
3994             case PatternTerm::TypeCharacterClass:
3995                 out.print(&quot;TypePatternCharacterClass &quot;);
3996                 if (term-&gt;invert())
3997                     out.print(&quot;not &quot;);
3998                 dumpCharacterClass(out, &amp;m_pattern, term-&gt;characterClass);
3999                 term-&gt;dumpQuantifier(out);
4000                 break;
4001 
4002             case PatternTerm::TypeAssertionWordBoundary:
4003                 out.printf(&quot;%sword boundary&quot;, term-&gt;invert() ? &quot;non-&quot; : &quot;&quot;);
4004                 break;
4005 
4006             case PatternTerm::TypeDotStarEnclosure:
4007                 out.print(&quot;.* enclosure&quot;);
4008                 break;
4009 
4010             case PatternTerm::TypeForwardReference:
4011                 out.print(&quot;TypeForwardReference &lt;not handled&gt;&quot;);
4012                 break;
4013 
4014             case PatternTerm::TypeParenthesesSubpattern:
4015             case PatternTerm::TypeParentheticalAssertion:
4016                 RELEASE_ASSERT_NOT_REACHED();
4017                 break;
4018             }
4019 
4020             if (op.m_isDeadCode)
4021                 out.print(&quot; already handled&quot;);
4022             out.print(&quot;\n&quot;);
4023             return(0);
4024         }
4025 
4026         case OpBodyAlternativeBegin:
4027             out.printf(&quot;OpBodyAlternativeBegin minimum size %u\n&quot;, op.m_alternative-&gt;m_minimumSize);
4028             return(0);
4029 
4030         case OpBodyAlternativeNext:
4031             out.printf(&quot;OpBodyAlternativeNext minimum size %u\n&quot;, op.m_alternative-&gt;m_minimumSize);
4032             return(0);
4033 
4034         case OpBodyAlternativeEnd:
4035             out.print(&quot;OpBodyAlternativeEnd\n&quot;);
4036             return(0);
4037 
4038         case OpSimpleNestedAlternativeBegin:
4039             out.printf(&quot;OpSimpleNestedAlternativeBegin minimum size %u\n&quot;, op.m_alternative-&gt;m_minimumSize);
4040             return(1);
4041 
4042         case OpNestedAlternativeBegin:
4043             out.printf(&quot;OpNestedAlternativeBegin minimum size %u\n&quot;, op.m_alternative-&gt;m_minimumSize);
4044             return(1);
4045 
4046         case OpSimpleNestedAlternativeNext:
4047             out.printf(&quot;OpSimpleNestedAlternativeNext minimum size %u\n&quot;, op.m_alternative-&gt;m_minimumSize);
4048             return(0);
4049 
4050         case OpNestedAlternativeNext:
4051             out.printf(&quot;OpNestedAlternativeNext minimum size %u\n&quot;, op.m_alternative-&gt;m_minimumSize);
4052             return(0);
4053 
4054         case OpSimpleNestedAlternativeEnd:
4055             out.print(&quot;OpSimpleNestedAlternativeEnd&quot;);
4056             term-&gt;dumpQuantifier(out);
4057             out.print(&quot;\n&quot;);
4058             return(-1);
4059 
4060         case OpNestedAlternativeEnd:
4061             out.print(&quot;OpNestedAlternativeEnd&quot;);
4062             term-&gt;dumpQuantifier(out);
4063             out.print(&quot;\n&quot;);
4064             return(-1);
4065 
4066         case OpParenthesesSubpatternOnceBegin:
4067             out.print(&quot;OpParenthesesSubpatternOnceBegin &quot;);
4068             if (term-&gt;capture())
4069                 out.printf(&quot;capturing pattern #%u&quot;, term-&gt;parentheses.subpatternId);
4070             else
4071                 out.print(&quot;non-capturing&quot;);
4072             term-&gt;dumpQuantifier(out);
4073             out.print(&quot;\n&quot;);
4074             return(0);
4075 
4076         case OpParenthesesSubpatternOnceEnd:
4077             out.print(&quot;OpParenthesesSubpatternOnceEnd &quot;);
4078             if (term-&gt;capture())
4079                 out.printf(&quot;capturing pattern #%u&quot;, term-&gt;parentheses.subpatternId);
4080             else
4081                 out.print(&quot;non-capturing&quot;);
4082             term-&gt;dumpQuantifier(out);
4083             out.print(&quot;\n&quot;);
4084             return(0);
4085 
4086         case OpParenthesesSubpatternTerminalBegin:
4087             out.print(&quot;OpParenthesesSubpatternTerminalBegin &quot;);
4088             if (term-&gt;capture())
4089                 out.printf(&quot;capturing pattern #%u\n&quot;, term-&gt;parentheses.subpatternId);
4090             else
4091                 out.print(&quot;non-capturing\n&quot;);
4092             return(0);
4093 
4094         case OpParenthesesSubpatternTerminalEnd:
4095             out.print(&quot;OpParenthesesSubpatternTerminalEnd &quot;);
4096             if (term-&gt;capture())
4097                 out.printf(&quot;capturing pattern #%u\n&quot;, term-&gt;parentheses.subpatternId);
4098             else
4099                 out.print(&quot;non-capturing\n&quot;);
4100             return(0);
4101 
4102         case OpParenthesesSubpatternBegin:
4103             out.print(&quot;OpParenthesesSubpatternBegin &quot;);
4104             if (term-&gt;capture())
4105                 out.printf(&quot;capturing pattern #%u&quot;, term-&gt;parentheses.subpatternId);
4106             else
4107                 out.print(&quot;non-capturing&quot;);
4108             term-&gt;dumpQuantifier(out);
4109             out.print(&quot;\n&quot;);
4110             return(0);
4111 
4112         case OpParenthesesSubpatternEnd:
4113             out.print(&quot;OpParenthesesSubpatternEnd &quot;);
4114             if (term-&gt;capture())
4115                 out.printf(&quot;capturing pattern #%u&quot;, term-&gt;parentheses.subpatternId);
4116             else
4117                 out.print(&quot;non-capturing&quot;);
4118             term-&gt;dumpQuantifier(out);
4119             out.print(&quot;\n&quot;);
4120             return(0);
4121 
4122         case OpParentheticalAssertionBegin:
4123             out.printf(&quot;OpParentheticalAssertionBegin%s\n&quot;, term-&gt;invert() ? &quot; inverted&quot; : &quot;&quot;);
4124             return(0);
4125 
4126         case OpParentheticalAssertionEnd:
4127             out.printf(&quot;OpParentheticalAssertionEnd%s\n&quot;, term-&gt;invert() ? &quot; inverted&quot; : &quot;&quot;);
4128             return(0);
4129 
4130         case OpMatchFailed:
4131             out.print(&quot;OpMatchFailed\n&quot;);
4132             return(0);
4133         }
4134 
4135         return(0);
4136     }
4137 
4138 private:
4139     VM* m_vm;
4140 
4141     YarrPattern&amp; m_pattern;
4142     String&amp; m_patternString;
4143 
4144     YarrCodeBlock&amp; m_codeBlock;
4145     YarrCharSize m_charSize;
4146 
4147     // Used to detect regular expression constructs that are not currently
4148     // supported in the JIT; fall back to the interpreter when this is detected.
4149     Optional&lt;JITFailureReason&gt; m_failureReason;
4150 
4151     bool m_decodeSurrogatePairs;
4152     bool m_unicodeIgnoreCase;
4153     bool m_fixedSizedAlternative;
4154     CanonicalMode m_canonicalMode;
4155 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
4156     bool m_containsNestedSubpatterns;
4157     ParenContextSizes m_parenContextSizes;
4158 #endif
4159     JumpList m_abortExecution;
4160     JumpList m_hitMatchLimit;
4161     Vector&lt;Call&gt; m_tryReadUnicodeCharacterCalls;
4162     Label m_tryReadUnicodeCharacterEntry;
4163 
4164     // The regular expression expressed as a linear sequence of operations.
4165     Vector&lt;YarrOp, 128&gt; m_ops;
4166 
4167     // This records the current input offset being applied due to the current
4168     // set of alternatives we are nested within. E.g. when matching the
4169     // character &#39;b&#39; within the regular expression /abc/, we will know that
4170     // the minimum size for the alternative is 3, checked upon entry to the
4171     // alternative, and that &#39;b&#39; is at offset 1 from the start, and as such
4172     // when matching &#39;b&#39; we need to apply an offset of -2 to the load.
4173     //
4174     // FIXME: This should go away. Rather than tracking this value throughout
4175     // code generation, we should gather this information up front &amp; store it
4176     // on the YarrOp structure.
4177     Checked&lt;unsigned&gt; m_checkedOffset;
4178 
4179     // This class records state whilst generating the backtracking path of code.
4180     BacktrackingState m_backtrackingState;
4181 
4182     std::unique_ptr&lt;YarrDisassembler&gt; m_disassembler;
4183 };
4184 
4185 static void dumpCompileFailure(JITFailureReason failure)
4186 {
4187     switch (failure) {
4188     case JITFailureReason::DecodeSurrogatePair:
4189         dataLog(&quot;Can&#39;t JIT a pattern decoding surrogate pairs\n&quot;);
4190         break;
4191     case JITFailureReason::BackReference:
4192         dataLog(&quot;Can&#39;t JIT some patterns containing back references\n&quot;);
4193         break;
4194     case JITFailureReason::ForwardReference:
4195         dataLog(&quot;Can&#39;t JIT a pattern containing forward references\n&quot;);
4196         break;
4197     case JITFailureReason::VariableCountedParenthesisWithNonZeroMinimum:
4198         dataLog(&quot;Can&#39;t JIT a pattern containing a variable counted parenthesis with a non-zero minimum\n&quot;);
4199         break;
4200     case JITFailureReason::ParenthesizedSubpattern:
4201         dataLog(&quot;Can&#39;t JIT a pattern containing parenthesized subpatterns\n&quot;);
4202         break;
4203     case JITFailureReason::FixedCountParenthesizedSubpattern:
4204         dataLog(&quot;Can&#39;t JIT a pattern containing fixed count parenthesized subpatterns\n&quot;);
4205         break;
4206     case JITFailureReason::ParenthesisNestedTooDeep:
4207         dataLog(&quot;Can&#39;t JIT pattern due to parentheses nested too deeply\n&quot;);
4208         break;
4209     case JITFailureReason::ExecutableMemoryAllocationFailure:
4210         dataLog(&quot;Can&#39;t JIT because of failure of allocation of executable memory\n&quot;);
4211         break;
4212     }
4213 }
4214 
4215 void jitCompile(YarrPattern&amp; pattern, String&amp; patternString, YarrCharSize charSize, VM* vm, YarrCodeBlock&amp; codeBlock, YarrJITCompileMode mode)
4216 {
4217     if (mode == MatchOnly)
4218         YarrGenerator&lt;MatchOnly&gt;(vm, pattern, patternString, codeBlock, charSize).compile();
4219     else
4220         YarrGenerator&lt;IncludeSubpatterns&gt;(vm, pattern, patternString, codeBlock, charSize).compile();
4221 
4222     if (auto failureReason = codeBlock.failureReason()) {
<a name="26" id="anc26"></a><span class="line-modified">4223         if (UNLIKELY(Options::dumpCompiledRegExpPatterns())) {</span>
4224             pattern.dumpPatternString(WTF::dataFile(), patternString);
4225             dataLog(&quot; : &quot;);
4226             dumpCompileFailure(*failureReason);
4227         }
4228     }
4229 }
4230 
4231 }}
4232 
4233 #endif
<a name="27" id="anc27"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="27" type="hidden" />
</body>
</html>