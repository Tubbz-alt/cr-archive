<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (C) 2010 Google Inc. All rights reserved.
   3  * Copyright (C) 2016 Apple Inc. All rights reserved.
   4  *
   5  * Redistribution and use in source and binary forms, with or without
   6  * modification, are permitted provided that the following conditions
   7  * are met:
   8  * 1.  Redistributions of source code must retain the above copyright
   9  *    notice, this list of conditions and the following disclaimer.
  10  * 2.  Redistributions in binary form must reproduce the above copyright
  11  *    notice, this list of conditions and the following disclaimer in the
  12  *    documentation and/or other materials provided with the distribution.
  13  *
  14  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
  15  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
  16  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
  17  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
  18  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
  19  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
  20  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
  21  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
  23  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 
  28 #if ENABLE(WEB_AUDIO)
  29 
  30 #include &quot;AudioContext.h&quot;
  31 
  32 #include &quot;AnalyserNode.h&quot;
  33 #include &quot;AsyncAudioDecoder.h&quot;
  34 #include &quot;AudioBuffer.h&quot;
  35 #include &quot;AudioBufferCallback.h&quot;
  36 #include &quot;AudioBufferSourceNode.h&quot;
  37 #include &quot;AudioListener.h&quot;
  38 #include &quot;AudioNodeInput.h&quot;
  39 #include &quot;AudioNodeOutput.h&quot;
  40 #include &quot;AudioSession.h&quot;
  41 #include &quot;BiquadFilterNode.h&quot;
  42 #include &quot;ChannelMergerNode.h&quot;
  43 #include &quot;ChannelSplitterNode.h&quot;
  44 #include &quot;ConvolverNode.h&quot;
  45 #include &quot;DefaultAudioDestinationNode.h&quot;
  46 #include &quot;DelayNode.h&quot;
  47 #include &quot;Document.h&quot;
  48 #include &quot;DynamicsCompressorNode.h&quot;
  49 #include &quot;EventNames.h&quot;
  50 #include &quot;FFTFrame.h&quot;
  51 #include &quot;Frame.h&quot;
  52 #include &quot;FrameLoader.h&quot;
  53 #include &quot;GainNode.h&quot;
  54 #include &quot;GenericEventQueue.h&quot;
  55 #include &quot;HRTFDatabaseLoader.h&quot;
  56 #include &quot;HRTFPanner.h&quot;
  57 #include &quot;JSDOMPromiseDeferred.h&quot;
  58 #include &quot;Logging.h&quot;
  59 #include &quot;NetworkingContext.h&quot;
  60 #include &quot;OfflineAudioCompletionEvent.h&quot;
  61 #include &quot;OfflineAudioDestinationNode.h&quot;
  62 #include &quot;OscillatorNode.h&quot;
  63 #include &quot;Page.h&quot;
  64 #include &quot;PannerNode.h&quot;
  65 #include &quot;PeriodicWave.h&quot;
  66 #include &quot;ScriptController.h&quot;
  67 #include &quot;ScriptProcessorNode.h&quot;
  68 #include &quot;WaveShaperNode.h&quot;
  69 #include &lt;JavaScriptCore/ScriptCallStack.h&gt;
  70 
  71 #if ENABLE(MEDIA_STREAM)
  72 #include &quot;MediaStream.h&quot;
  73 #include &quot;MediaStreamAudioDestinationNode.h&quot;
  74 #include &quot;MediaStreamAudioSource.h&quot;
  75 #include &quot;MediaStreamAudioSourceNode.h&quot;
  76 #endif
  77 
  78 #if ENABLE(VIDEO)
  79 #include &quot;HTMLMediaElement.h&quot;
  80 #include &quot;MediaElementAudioSourceNode.h&quot;
  81 #endif
  82 
  83 #if DEBUG_AUDIONODE_REFERENCES
  84 #include &lt;stdio.h&gt;
  85 #endif
  86 
  87 #if USE(GSTREAMER)
  88 #include &quot;GStreamerCommon.h&quot;
  89 #endif
  90 
  91 #if PLATFORM(IOS_FAMILY)
  92 #include &quot;ScriptController.h&quot;
  93 #include &quot;Settings.h&quot;
  94 #endif
  95 
  96 #include &lt;JavaScriptCore/ArrayBuffer.h&gt;
  97 #include &lt;wtf/Atomics.h&gt;
  98 #include &lt;wtf/IsoMallocInlines.h&gt;
  99 #include &lt;wtf/MainThread.h&gt;
 100 #include &lt;wtf/Ref.h&gt;
 101 #include &lt;wtf/RefCounted.h&gt;
 102 #include &lt;wtf/Scope.h&gt;
 103 #include &lt;wtf/text/WTFString.h&gt;
 104 
 105 const unsigned MaxPeriodicWaveLength = 4096;
 106 
 107 namespace WebCore {
 108 
 109 WTF_MAKE_ISO_ALLOCATED_IMPL(AudioContext);
 110 
 111 #define RELEASE_LOG_IF_ALLOWED(fmt, ...) RELEASE_LOG_IF(document() &amp;&amp; document()-&gt;page() &amp;&amp; document()-&gt;page()-&gt;isAlwaysOnLoggingAllowed(), Media, &quot;%p - AudioContext::&quot; fmt, this, ##__VA_ARGS__)
 112 
 113 bool AudioContext::isSampleRateRangeGood(float sampleRate)
 114 {
 115     // FIXME: It would be nice if the minimum sample-rate could be less than 44.1KHz,
 116     // but that will require some fixes in HRTFPanner::fftSizeForSampleRate(), and some testing there.
 117     return sampleRate &gt;= 44100 &amp;&amp; sampleRate &lt;= 96000;
 118 }
 119 
 120 // Don&#39;t allow more than this number of simultaneous AudioContexts talking to hardware.
 121 const unsigned MaxHardwareContexts = 4;
 122 unsigned AudioContext::s_hardwareContextCount = 0;
 123 
 124 RefPtr&lt;AudioContext&gt; AudioContext::create(Document&amp; document)
 125 {
 126     ASSERT(isMainThread());
 127     if (s_hardwareContextCount &gt;= MaxHardwareContexts)
 128         return nullptr;
 129 
 130     RefPtr&lt;AudioContext&gt; audioContext(adoptRef(new AudioContext(document)));
 131     audioContext-&gt;suspendIfNeeded();
 132     return audioContext;
 133 }
 134 
 135 // Constructor for rendering to the audio hardware.
 136 AudioContext::AudioContext(Document&amp; document)
 137     : ActiveDOMObject(document)
 138 #if !RELEASE_LOG_DISABLED
 139     , m_logger(document.logger())
 140     , m_logIdentifier(uniqueLogIdentifier())
 141 #endif
 142     , m_mediaSession(PlatformMediaSession::create(*this))
 143     , m_eventQueue(MainThreadGenericEventQueue::create(*this))
 144 {
 145     // According to spec AudioContext must die only after page navigate.
 146     // Lets mark it as ActiveDOMObject with pending activity and unmark it in clear method.
 147     makePendingActivity();
 148 
 149     constructCommon();
 150 
 151     m_destinationNode = DefaultAudioDestinationNode::create(*this);
 152 
 153     // Initialize the destination node&#39;s muted state to match the page&#39;s current muted state.
 154     pageMutedStateDidChange();
 155 
 156     document.addAudioProducer(*this);
 157     document.registerForVisibilityStateChangedCallbacks(*this);
 158 }
 159 
 160 // Constructor for offline (non-realtime) rendering.
 161 AudioContext::AudioContext(Document&amp; document, AudioBuffer* renderTarget)
 162     : ActiveDOMObject(document)
 163 #if !RELEASE_LOG_DISABLED
 164     , m_logger(document.logger())
 165     , m_logIdentifier(uniqueLogIdentifier())
 166 #endif
 167     , m_isOfflineContext(true)
 168     , m_mediaSession(PlatformMediaSession::create(*this))
 169     , m_eventQueue(MainThreadGenericEventQueue::create(*this))
 170     , m_renderTarget(renderTarget)
 171 {
 172     constructCommon();
 173 
 174     // Create a new destination for offline rendering.
 175     m_destinationNode = OfflineAudioDestinationNode::create(*this, m_renderTarget.get());
 176 }
 177 
 178 void AudioContext::constructCommon()
 179 {
 180     FFTFrame::initialize();
 181 
 182     m_listener = AudioListener::create();
 183 
 184     ASSERT(document());
 185     if (document()-&gt;audioPlaybackRequiresUserGesture())
 186         addBehaviorRestriction(RequireUserGestureForAudioStartRestriction);
 187     else
 188         m_restrictions = NoRestrictions;
 189 
 190 #if PLATFORM(COCOA)
 191     addBehaviorRestriction(RequirePageConsentForAudioStartRestriction);
 192 #endif
 193 }
 194 
 195 AudioContext::~AudioContext()
 196 {
 197 #if DEBUG_AUDIONODE_REFERENCES
 198     fprintf(stderr, &quot;%p: AudioContext::~AudioContext()\n&quot;, this);
 199 #endif
 200     ASSERT(!m_isInitialized);
 201     ASSERT(m_isStopScheduled);
 202     ASSERT(m_nodesToDelete.isEmpty());
 203     ASSERT(m_referencedNodes.isEmpty());
 204     ASSERT(m_finishedNodes.isEmpty()); // FIXME (bug 105870): This assertion fails on tests sometimes.
 205     ASSERT(m_automaticPullNodes.isEmpty());
 206     if (m_automaticPullNodesNeedUpdating)
 207         m_renderingAutomaticPullNodes.resize(m_automaticPullNodes.size());
 208     ASSERT(m_renderingAutomaticPullNodes.isEmpty());
 209     // FIXME: Can we assert that m_deferredFinishDerefList is empty?
 210 
 211     if (!isOfflineContext() &amp;&amp; scriptExecutionContext()) {
 212         document()-&gt;removeAudioProducer(*this);
 213         document()-&gt;unregisterForVisibilityStateChangedCallbacks(*this);
 214     }
 215 }
 216 
 217 void AudioContext::lazyInitialize()
 218 {
 219     ASSERT(!m_isStopScheduled);
 220 
 221     if (m_isInitialized)
 222         return;
 223 
 224     // Don&#39;t allow the context to initialize a second time after it&#39;s already been explicitly uninitialized.
 225     ASSERT(!m_isAudioThreadFinished);
 226     if (m_isAudioThreadFinished)
 227         return;
 228 
 229     if (m_destinationNode) {
 230         m_destinationNode-&gt;initialize();
 231 
 232         if (!isOfflineContext()) {
 233             // This starts the audio thread. The destination node&#39;s provideInput() method will now be called repeatedly to render audio.
 234             // Each time provideInput() is called, a portion of the audio stream is rendered. Let&#39;s call this time period a &quot;render quantum&quot;.
 235             // NOTE: for now default AudioContext does not need an explicit startRendering() call from JavaScript.
 236             // We may want to consider requiring it for symmetry with OfflineAudioContext.
 237             startRendering();
 238             ++s_hardwareContextCount;
 239         }
 240     }
 241     m_isInitialized = true;
 242 }
 243 
 244 void AudioContext::clear()
 245 {
 246     Ref&lt;AudioContext&gt; protectedThis(*this);
 247 
 248     // We have to release our reference to the destination node before the context will ever be deleted since the destination node holds a reference to the context.
 249     if (m_destinationNode)
 250         m_destinationNode = nullptr;
 251 
 252     // Audio thread is dead. Nobody will schedule node deletion action. Let&#39;s do it ourselves.
 253     do {
 254         deleteMarkedNodes();
 255         m_nodesToDelete.appendVector(m_nodesMarkedForDeletion);
 256         m_nodesMarkedForDeletion.clear();
 257     } while (m_nodesToDelete.size());
 258 
 259     clearPendingActivity();
 260 }
 261 
 262 void AudioContext::uninitialize()
 263 {
 264     ALWAYS_LOG(LOGIDENTIFIER);
 265 
 266     ASSERT(isMainThread());
 267 
 268     if (!m_isInitialized)
 269         return;
 270 
 271     // This stops the audio thread and all audio rendering.
 272     if (m_destinationNode)
 273         m_destinationNode-&gt;uninitialize();
 274 
 275     // Don&#39;t allow the context to initialize a second time after it&#39;s already been explicitly uninitialized.
 276     m_isAudioThreadFinished = true;
 277 
 278     if (!isOfflineContext()) {
 279         ASSERT(s_hardwareContextCount);
 280         --s_hardwareContextCount;
 281 
 282         // Offline contexts move to &#39;Closed&#39; state when dispatching the completion event.
 283         setState(State::Closed);
 284     }
 285 
 286     // Get rid of the sources which may still be playing.
 287     derefUnfinishedSourceNodes();
 288 
 289     m_isInitialized = false;
 290 }
 291 
 292 bool AudioContext::isInitialized() const
 293 {
 294     return m_isInitialized;
 295 }
 296 
 297 void AudioContext::addReaction(State state, DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
 298 {
 299     size_t stateIndex = static_cast&lt;size_t&gt;(state);
 300     if (stateIndex &gt;= m_stateReactions.size())
 301         m_stateReactions.grow(stateIndex + 1);
 302 
 303     m_stateReactions[stateIndex].append(WTFMove(promise));
 304 }
 305 
 306 void AudioContext::setState(State state)
 307 {
 308     if (m_state == state)
 309         return;
 310 
 311     m_state = state;
 312     m_eventQueue-&gt;enqueueEvent(Event::create(eventNames().statechangeEvent, Event::CanBubble::Yes, Event::IsCancelable::No));
 313 
 314     size_t stateIndex = static_cast&lt;size_t&gt;(state);
 315     if (stateIndex &gt;= m_stateReactions.size())
 316         return;
 317 
 318     Vector&lt;DOMPromiseDeferred&lt;void&gt;&gt; reactions;
 319     m_stateReactions[stateIndex].swap(reactions);
 320 
 321     for (auto&amp; promise : reactions)
 322         promise.resolve();
 323 }
 324 
 325 void AudioContext::stop()
 326 {
 327     ALWAYS_LOG(LOGIDENTIFIER);
 328 
 329     ASSERT(isMainThread());
 330 
 331     // Usually ScriptExecutionContext calls stop twice.
 332     if (m_isStopScheduled)
 333         return;
 334     m_isStopScheduled = true;
 335 
 336     ASSERT(document());
 337     document()-&gt;updateIsPlayingMedia();
 338 
 339     uninitialize();
 340     clear();
 341 }
 342 
 343 void AudioContext::suspend(ReasonForSuspension)
 344 {
 345     if (state() == State::Running) {
 346         m_mediaSession-&gt;beginInterruption(PlatformMediaSession::PlaybackSuspended);
 347         document()-&gt;updateIsPlayingMedia();
 348     }
 349 }
 350 
 351 void AudioContext::resume()
 352 {
 353     if (state() == State::Interrupted) {
 354         m_mediaSession-&gt;endInterruption(PlatformMediaSession::MayResumePlaying);
 355         document()-&gt;updateIsPlayingMedia();
 356     }
 357 }
 358 
 359 const char* AudioContext::activeDOMObjectName() const
 360 {
 361     return &quot;AudioContext&quot;;
 362 }
 363 
 364 Document* AudioContext::document() const
 365 {
 366     return downcast&lt;Document&gt;(m_scriptExecutionContext);
 367 }
 368 
 369 Document* AudioContext::hostingDocument() const
 370 {
 371     return downcast&lt;Document&gt;(m_scriptExecutionContext);
 372 }
 373 
 374 String AudioContext::sourceApplicationIdentifier() const
 375 {
 376     Document* document = this-&gt;document();
 377     if (Frame* frame = document ? document-&gt;frame() : nullptr) {
 378         if (NetworkingContext* networkingContext = frame-&gt;loader().networkingContext())
 379             return networkingContext-&gt;sourceApplicationIdentifier();
 380     }
 381     return emptyString();
 382 }
 383 
 384 bool AudioContext::processingUserGestureForMedia() const
 385 {
 386     return document() ? document()-&gt;processingUserGestureForMedia() : false;
 387 }
 388 
 389 bool AudioContext::isSuspended() const
 390 {
 391     return !document() || document()-&gt;activeDOMObjectsAreSuspended() || document()-&gt;activeDOMObjectsAreStopped();
 392 }
 393 
 394 void AudioContext::visibilityStateChanged()
 395 {
 396     // Do not suspend if audio is audible.
 397     if (!document() || mediaState() == MediaProducer::IsPlayingAudio || m_isStopScheduled)
 398         return;
 399 
 400     if (document()-&gt;hidden()) {
 401         if (state() == State::Running) {
 402             RELEASE_LOG_IF_ALLOWED(&quot;visibilityStateChanged() Suspending playback after going to the background&quot;);
 403             m_mediaSession-&gt;beginInterruption(PlatformMediaSession::EnteringBackground);
 404         }
 405     } else {
 406         if (state() == State::Interrupted) {
 407             RELEASE_LOG_IF_ALLOWED(&quot;visibilityStateChanged() Resuming playback after entering foreground&quot;);
 408             m_mediaSession-&gt;endInterruption(PlatformMediaSession::MayResumePlaying);
 409         }
 410     }
 411 }
 412 
 413 bool AudioContext::wouldTaintOrigin(const URL&amp; url) const
 414 {
 415     if (url.protocolIsData())
 416         return false;
 417 
 418     if (auto* document = this-&gt;document())
 419         return !document-&gt;securityOrigin().canRequest(url);
 420 
 421     return false;
 422 }
 423 
 424 ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; AudioContext::createBuffer(unsigned numberOfChannels, size_t numberOfFrames, float sampleRate)
 425 {
 426     auto audioBuffer = AudioBuffer::create(numberOfChannels, numberOfFrames, sampleRate);
 427     if (!audioBuffer)
 428         return Exception { NotSupportedError };
 429     return audioBuffer.releaseNonNull();
 430 }
 431 
 432 ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; AudioContext::createBuffer(ArrayBuffer&amp; arrayBuffer, bool mixToMono)
 433 {
 434     auto audioBuffer = AudioBuffer::createFromAudioFileData(arrayBuffer.data(), arrayBuffer.byteLength(), mixToMono, sampleRate());
 435     if (!audioBuffer)
 436         return Exception { SyntaxError };
 437     return audioBuffer.releaseNonNull();
 438 }
 439 
 440 void AudioContext::decodeAudioData(Ref&lt;ArrayBuffer&gt;&amp;&amp; audioData, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp; successCallback, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp; errorCallback)
 441 {
 442     if (!m_audioDecoder)
 443         m_audioDecoder = makeUnique&lt;AsyncAudioDecoder&gt;();
 444     m_audioDecoder-&gt;decodeAsync(WTFMove(audioData), sampleRate(), WTFMove(successCallback), WTFMove(errorCallback));
 445 }
 446 
 447 ExceptionOr&lt;Ref&lt;AudioBufferSourceNode&gt;&gt; AudioContext::createBufferSource()
 448 {
 449     ALWAYS_LOG(LOGIDENTIFIER);
 450 
 451     ASSERT(isMainThread());
 452 
 453     if (m_isStopScheduled)
 454         return Exception { InvalidStateError };
 455 
 456     lazyInitialize();
 457     Ref&lt;AudioBufferSourceNode&gt; node = AudioBufferSourceNode::create(*this, sampleRate());
 458 
 459     // Because this is an AudioScheduledSourceNode, the context keeps a reference until it has finished playing.
 460     // When this happens, AudioScheduledSourceNode::finish() calls AudioContext::notifyNodeFinishedProcessing().
 461     refNode(node);
 462 
 463     return node;
 464 }
 465 
 466 #if ENABLE(VIDEO)
 467 
 468 ExceptionOr&lt;Ref&lt;MediaElementAudioSourceNode&gt;&gt; AudioContext::createMediaElementSource(HTMLMediaElement&amp; mediaElement)
 469 {
 470     ALWAYS_LOG(LOGIDENTIFIER);
 471 
 472     ASSERT(isMainThread());
 473 
 474     if (m_isStopScheduled || mediaElement.audioSourceNode())
 475         return Exception { InvalidStateError };
 476 
 477     lazyInitialize();
 478 
 479     auto node = MediaElementAudioSourceNode::create(*this, mediaElement);
 480 
 481     mediaElement.setAudioSourceNode(node.ptr());
 482 
 483     refNode(node.get()); // context keeps reference until node is disconnected
 484     return node;
 485 }
 486 
 487 #endif
 488 
 489 #if ENABLE(MEDIA_STREAM)
 490 
 491 ExceptionOr&lt;Ref&lt;MediaStreamAudioSourceNode&gt;&gt; AudioContext::createMediaStreamSource(MediaStream&amp; mediaStream)
 492 {
 493     ALWAYS_LOG(LOGIDENTIFIER);
 494 
 495     ASSERT(isMainThread());
 496 
 497     if (m_isStopScheduled)
 498         return Exception { InvalidStateError };
 499 
 500     auto audioTracks = mediaStream.getAudioTracks();
 501     if (audioTracks.isEmpty())
 502         return Exception { InvalidStateError };
 503 
 504     MediaStreamTrack* providerTrack = nullptr;
 505     for (auto&amp; track : audioTracks) {
 506         if (track-&gt;audioSourceProvider()) {
 507             providerTrack = track.get();
 508             break;
 509         }
 510     }
 511     if (!providerTrack)
 512         return Exception { InvalidStateError };
 513 
 514     lazyInitialize();
 515 
 516     auto node = MediaStreamAudioSourceNode::create(*this, mediaStream, *providerTrack);
 517     node-&gt;setFormat(2, sampleRate());
 518 
 519     refNode(node); // context keeps reference until node is disconnected
 520     return node;
 521 }
 522 
 523 ExceptionOr&lt;Ref&lt;MediaStreamAudioDestinationNode&gt;&gt; AudioContext::createMediaStreamDestination()
 524 {
 525     if (m_isStopScheduled)
 526         return Exception { InvalidStateError };
 527 
 528     // FIXME: Add support for an optional argument which specifies the number of channels.
 529     // FIXME: The default should probably be stereo instead of mono.
 530     return MediaStreamAudioDestinationNode::create(*this, 1);
 531 }
 532 
 533 #endif
 534 
 535 ExceptionOr&lt;Ref&lt;ScriptProcessorNode&gt;&gt; AudioContext::createScriptProcessor(size_t bufferSize, size_t numberOfInputChannels, size_t numberOfOutputChannels)
 536 {
 537     ALWAYS_LOG(LOGIDENTIFIER);
 538 
 539     ASSERT(isMainThread());
 540 
 541     if (m_isStopScheduled)
 542         return Exception { InvalidStateError };
 543 
 544     lazyInitialize();
 545 
 546     // W3C Editor&#39;s Draft 06 June 2017
 547     //  https://webaudio.github.io/web-audio-api/#widl-BaseAudioContext-createScriptProcessor-ScriptProcessorNode-unsigned-long-bufferSize-unsigned-long-numberOfInputChannels-unsigned-long-numberOfOutputChannels
 548 
 549     // The bufferSize parameter determines the buffer size in units of sample-frames. If it&#39;s not passed in,
 550     // or if the value is 0, then the implementation will choose the best buffer size for the given environment,
 551     // which will be constant power of 2 throughout the lifetime of the node. ... If the value of this parameter
 552     // is not one of the allowed power-of-2 values listed above, an IndexSizeError must be thrown.
 553     switch (bufferSize) {
 554     case 0:
 555 #if USE(AUDIO_SESSION)
 556         // Pick a value between 256 (2^8) and 16384 (2^14), based on the buffer size of the current AudioSession:
 557         bufferSize = 1 &lt;&lt; std::max&lt;size_t&gt;(8, std::min&lt;size_t&gt;(14, std::log2(AudioSession::sharedSession().bufferSize())));
 558 #else
 559         bufferSize = 2048;
 560 #endif
 561         break;
 562     case 256:
 563     case 512:
 564     case 1024:
 565     case 2048:
 566     case 4096:
 567     case 8192:
 568     case 16384:
 569         break;
 570     default:
 571         return Exception { IndexSizeError };
 572     }
 573 
 574     // An IndexSizeError exception must be thrown if bufferSize or numberOfInputChannels or numberOfOutputChannels
 575     // are outside the valid range. It is invalid for both numberOfInputChannels and numberOfOutputChannels to be zero.
 576     // In this case an IndexSizeError must be thrown.
 577 
 578     if (!numberOfInputChannels &amp;&amp; !numberOfOutputChannels)
 579         return Exception { NotSupportedError };
 580 
 581     // This parameter [numberOfInputChannels] determines the number of channels for this node&#39;s input. Values of
 582     // up to 32 must be supported. A NotSupportedError must be thrown if the number of channels is not supported.
 583 
 584     if (numberOfInputChannels &gt; maxNumberOfChannels())
 585         return Exception { NotSupportedError };
 586 
 587     // This parameter [numberOfOutputChannels] determines the number of channels for this node&#39;s output. Values of
 588     // up to 32 must be supported. A NotSupportedError must be thrown if the number of channels is not supported.
 589 
 590     if (numberOfOutputChannels &gt; maxNumberOfChannels())
 591         return Exception { NotSupportedError };
 592 
 593     auto node = ScriptProcessorNode::create(*this, sampleRate(), bufferSize, numberOfInputChannels, numberOfOutputChannels);
 594 
 595     refNode(node); // context keeps reference until we stop making javascript rendering callbacks
 596     return node;
 597 }
 598 
 599 ExceptionOr&lt;Ref&lt;BiquadFilterNode&gt;&gt; AudioContext::createBiquadFilter()
 600 {
 601     ALWAYS_LOG(LOGIDENTIFIER);
 602 
 603     ASSERT(isMainThread());
 604     if (m_isStopScheduled)
 605         return Exception { InvalidStateError };
 606 
 607     lazyInitialize();
 608 
 609     return BiquadFilterNode::create(*this, sampleRate());
 610 }
 611 
 612 ExceptionOr&lt;Ref&lt;WaveShaperNode&gt;&gt; AudioContext::createWaveShaper()
 613 {
 614     ALWAYS_LOG(LOGIDENTIFIER);
 615 
 616     ASSERT(isMainThread());
 617     if (m_isStopScheduled)
 618         return Exception { InvalidStateError };
 619 
 620     lazyInitialize();
 621     return WaveShaperNode::create(*this);
 622 }
 623 
 624 ExceptionOr&lt;Ref&lt;PannerNode&gt;&gt; AudioContext::createPanner()
 625 {
 626     ALWAYS_LOG(LOGIDENTIFIER);
 627 
 628     ASSERT(isMainThread());
 629     if (m_isStopScheduled)
 630         return Exception { InvalidStateError };
 631 
 632     lazyInitialize();
 633     return PannerNode::create(*this, sampleRate());
 634 }
 635 
 636 ExceptionOr&lt;Ref&lt;ConvolverNode&gt;&gt; AudioContext::createConvolver()
 637 {
 638     ALWAYS_LOG(LOGIDENTIFIER);
 639 
 640     ASSERT(isMainThread());
 641     if (m_isStopScheduled)
 642         return Exception { InvalidStateError };
 643 
 644     lazyInitialize();
 645     return ConvolverNode::create(*this, sampleRate());
 646 }
 647 
 648 ExceptionOr&lt;Ref&lt;DynamicsCompressorNode&gt;&gt; AudioContext::createDynamicsCompressor()
 649 {
 650     ALWAYS_LOG(LOGIDENTIFIER);
 651 
 652     ASSERT(isMainThread());
 653     if (m_isStopScheduled)
 654         return Exception { InvalidStateError };
 655 
 656     lazyInitialize();
 657     return DynamicsCompressorNode::create(*this, sampleRate());
 658 }
 659 
 660 ExceptionOr&lt;Ref&lt;AnalyserNode&gt;&gt; AudioContext::createAnalyser()
 661 {
 662     ALWAYS_LOG(LOGIDENTIFIER);
 663 
 664     ASSERT(isMainThread());
 665     if (m_isStopScheduled)
 666         return Exception { InvalidStateError };
 667 
 668     lazyInitialize();
 669     return AnalyserNode::create(*this, sampleRate());
 670 }
 671 
 672 ExceptionOr&lt;Ref&lt;GainNode&gt;&gt; AudioContext::createGain()
 673 {
 674     ALWAYS_LOG(LOGIDENTIFIER);
 675 
 676     ASSERT(isMainThread());
 677     if (m_isStopScheduled)
 678         return Exception { InvalidStateError };
 679 
 680     lazyInitialize();
 681     return GainNode::create(*this, sampleRate());
 682 }
 683 
 684 ExceptionOr&lt;Ref&lt;DelayNode&gt;&gt; AudioContext::createDelay(double maxDelayTime)
 685 {
 686     ALWAYS_LOG(LOGIDENTIFIER);
 687 
 688     ASSERT(isMainThread());
 689     if (m_isStopScheduled)
 690         return Exception { InvalidStateError };
 691 
 692     lazyInitialize();
 693     return DelayNode::create(*this, sampleRate(), maxDelayTime);
 694 }
 695 
 696 ExceptionOr&lt;Ref&lt;ChannelSplitterNode&gt;&gt; AudioContext::createChannelSplitter(size_t numberOfOutputs)
 697 {
 698     ALWAYS_LOG(LOGIDENTIFIER);
 699 
 700     ASSERT(isMainThread());
 701     if (m_isStopScheduled)
 702         return Exception { InvalidStateError };
 703 
 704     lazyInitialize();
 705     auto node = ChannelSplitterNode::create(*this, sampleRate(), numberOfOutputs);
 706     if (!node)
 707         return Exception { IndexSizeError };
 708     return node.releaseNonNull();
 709 }
 710 
 711 ExceptionOr&lt;Ref&lt;ChannelMergerNode&gt;&gt; AudioContext::createChannelMerger(size_t numberOfInputs)
 712 {
 713     ALWAYS_LOG(LOGIDENTIFIER);
 714 
 715     ASSERT(isMainThread());
 716     if (m_isStopScheduled)
 717         return Exception { InvalidStateError };
 718 
 719     lazyInitialize();
 720     auto node = ChannelMergerNode::create(*this, sampleRate(), numberOfInputs);
 721     if (!node)
 722         return Exception { IndexSizeError };
 723     return node.releaseNonNull();
 724 }
 725 
 726 ExceptionOr&lt;Ref&lt;OscillatorNode&gt;&gt; AudioContext::createOscillator()
 727 {
 728     ALWAYS_LOG(LOGIDENTIFIER);
 729 
 730     ASSERT(isMainThread());
 731     if (m_isStopScheduled)
 732         return Exception { InvalidStateError };
 733 
 734     lazyInitialize();
 735 
 736     Ref&lt;OscillatorNode&gt; node = OscillatorNode::create(*this, sampleRate());
 737 
 738     // Because this is an AudioScheduledSourceNode, the context keeps a reference until it has finished playing.
 739     // When this happens, AudioScheduledSourceNode::finish() calls AudioContext::notifyNodeFinishedProcessing().
 740     refNode(node);
 741 
 742     return node;
 743 }
 744 
 745 ExceptionOr&lt;Ref&lt;PeriodicWave&gt;&gt; AudioContext::createPeriodicWave(Float32Array&amp; real, Float32Array&amp; imaginary)
 746 {
 747     ALWAYS_LOG(LOGIDENTIFIER);
 748 
 749     ASSERT(isMainThread());
 750     if (m_isStopScheduled)
 751         return Exception { InvalidStateError };
 752 
 753     if (real.length() != imaginary.length() || (real.length() &gt; MaxPeriodicWaveLength) || !real.length())
 754         return Exception { IndexSizeError };
 755     lazyInitialize();
 756     return PeriodicWave::create(sampleRate(), real, imaginary);
 757 }
 758 
 759 void AudioContext::notifyNodeFinishedProcessing(AudioNode* node)
 760 {
 761     ASSERT(isAudioThread());
 762     m_finishedNodes.append(node);
 763 }
 764 
 765 void AudioContext::derefFinishedSourceNodes()
 766 {
 767     ASSERT(isGraphOwner());
 768     ASSERT(isAudioThread() || isAudioThreadFinished());
 769     for (auto&amp; node : m_finishedNodes)
 770         derefNode(*node);
 771 
 772     m_finishedNodes.clear();
 773 }
 774 
 775 void AudioContext::refNode(AudioNode&amp; node)
 776 {
 777     ASSERT(isMainThread());
 778     AutoLocker locker(*this);
 779 
 780     node.ref(AudioNode::RefTypeConnection);
 781     m_referencedNodes.append(&amp;node);
 782 }
 783 
 784 void AudioContext::derefNode(AudioNode&amp; node)
 785 {
 786     ASSERT(isGraphOwner());
 787 
 788     node.deref(AudioNode::RefTypeConnection);
 789 
 790     ASSERT(m_referencedNodes.contains(&amp;node));
 791     m_referencedNodes.removeFirst(&amp;node);
 792 }
 793 
 794 void AudioContext::derefUnfinishedSourceNodes()
 795 {
 796     ASSERT(isMainThread() &amp;&amp; isAudioThreadFinished());
 797     for (auto&amp; node : m_referencedNodes)
 798         node-&gt;deref(AudioNode::RefTypeConnection);
 799 
 800     m_referencedNodes.clear();
 801 }
 802 
 803 void AudioContext::lock(bool&amp; mustReleaseLock)
 804 {
 805     // Don&#39;t allow regular lock in real-time audio thread.
 806     ASSERT(isMainThread());
 807 
 808     Thread&amp; thisThread = Thread::current();
 809 
 810     if (&amp;thisThread == m_graphOwnerThread) {
 811         // We already have the lock.
 812         mustReleaseLock = false;
 813     } else {
 814         // Acquire the lock.
 815         m_contextGraphMutex.lock();
 816         m_graphOwnerThread = &amp;thisThread;
 817         mustReleaseLock = true;
 818     }
 819 }
 820 
 821 bool AudioContext::tryLock(bool&amp; mustReleaseLock)
 822 {
 823     Thread&amp; thisThread = Thread::current();
 824     bool isAudioThread = &amp;thisThread == audioThread();
 825 
 826     // Try to catch cases of using try lock on main thread - it should use regular lock.
 827     ASSERT(isAudioThread || isAudioThreadFinished());
 828 
 829     if (!isAudioThread) {
 830         // In release build treat tryLock() as lock() (since above ASSERT(isAudioThread) never fires) - this is the best we can do.
 831         lock(mustReleaseLock);
 832         return true;
 833     }
 834 
 835     bool hasLock;
 836 
 837     if (&amp;thisThread == m_graphOwnerThread) {
 838         // Thread already has the lock.
 839         hasLock = true;
 840         mustReleaseLock = false;
 841     } else {
 842         // Don&#39;t already have the lock - try to acquire it.
 843         hasLock = m_contextGraphMutex.tryLock();
 844 
 845         if (hasLock)
 846             m_graphOwnerThread = &amp;thisThread;
 847 
 848         mustReleaseLock = hasLock;
 849     }
 850 
 851     return hasLock;
 852 }
 853 
 854 void AudioContext::unlock()
 855 {
 856     ASSERT(m_graphOwnerThread == &amp;Thread::current());
 857 
 858     m_graphOwnerThread = nullptr;
 859     m_contextGraphMutex.unlock();
 860 }
 861 
 862 bool AudioContext::isAudioThread() const
 863 {
 864     return m_audioThread == &amp;Thread::current();
 865 }
 866 
 867 bool AudioContext::isGraphOwner() const
 868 {
 869     return m_graphOwnerThread == &amp;Thread::current();
 870 }
 871 
 872 void AudioContext::addDeferredFinishDeref(AudioNode* node)
 873 {
 874     ASSERT(isAudioThread());
 875     m_deferredFinishDerefList.append(node);
 876 }
 877 
 878 void AudioContext::handlePreRenderTasks()
 879 {
 880     ASSERT(isAudioThread());
 881 
 882     // At the beginning of every render quantum, try to update the internal rendering graph state (from main thread changes).
 883     // It&#39;s OK if the tryLock() fails, we&#39;ll just take slightly longer to pick up the changes.
 884     bool mustReleaseLock;
 885     if (tryLock(mustReleaseLock)) {
 886         // Fixup the state of any dirty AudioSummingJunctions and AudioNodeOutputs.
 887         handleDirtyAudioSummingJunctions();
 888         handleDirtyAudioNodeOutputs();
 889 
 890         updateAutomaticPullNodes();
 891 
 892         if (mustReleaseLock)
 893             unlock();
 894     }
 895 }
 896 
 897 void AudioContext::handlePostRenderTasks()
 898 {
 899     ASSERT(isAudioThread());
 900 
 901     // Must use a tryLock() here too. Don&#39;t worry, the lock will very rarely be contended and this method is called frequently.
 902     // The worst that can happen is that there will be some nodes which will take slightly longer than usual to be deleted or removed
 903     // from the render graph (in which case they&#39;ll render silence).
 904     bool mustReleaseLock;
 905     if (tryLock(mustReleaseLock)) {
 906         // Take care of finishing any derefs where the tryLock() failed previously.
 907         handleDeferredFinishDerefs();
 908 
 909         // Dynamically clean up nodes which are no longer needed.
 910         derefFinishedSourceNodes();
 911 
 912         // Don&#39;t delete in the real-time thread. Let the main thread do it.
 913         // Ref-counted objects held by certain AudioNodes may not be thread-safe.
 914         scheduleNodeDeletion();
 915 
 916         // Fixup the state of any dirty AudioSummingJunctions and AudioNodeOutputs.
 917         handleDirtyAudioSummingJunctions();
 918         handleDirtyAudioNodeOutputs();
 919 
 920         updateAutomaticPullNodes();
 921 
 922         if (mustReleaseLock)
 923             unlock();
 924     }
 925 }
 926 
 927 void AudioContext::handleDeferredFinishDerefs()
 928 {
 929     ASSERT(isAudioThread() &amp;&amp; isGraphOwner());
 930     for (auto&amp; node : m_deferredFinishDerefList)
 931         node-&gt;finishDeref(AudioNode::RefTypeConnection);
 932 
 933     m_deferredFinishDerefList.clear();
 934 }
 935 
 936 void AudioContext::markForDeletion(AudioNode&amp; node)
 937 {
 938     ASSERT(isGraphOwner());
 939 
 940     if (isAudioThreadFinished())
 941         m_nodesToDelete.append(&amp;node);
 942     else
 943         m_nodesMarkedForDeletion.append(&amp;node);
 944 
 945     // This is probably the best time for us to remove the node from automatic pull list,
 946     // since all connections are gone and we hold the graph lock. Then when handlePostRenderTasks()
 947     // gets a chance to schedule the deletion work, updateAutomaticPullNodes() also gets a chance to
 948     // modify m_renderingAutomaticPullNodes.
 949     removeAutomaticPullNode(node);
 950 }
 951 
 952 void AudioContext::scheduleNodeDeletion()
 953 {
 954     bool isGood = m_isInitialized &amp;&amp; isGraphOwner();
 955     ASSERT(isGood);
 956     if (!isGood)
 957         return;
 958 
 959     // Make sure to call deleteMarkedNodes() on main thread.
 960     if (m_nodesMarkedForDeletion.size() &amp;&amp; !m_isDeletionScheduled) {
 961         m_nodesToDelete.appendVector(m_nodesMarkedForDeletion);
 962         m_nodesMarkedForDeletion.clear();
 963 
 964         m_isDeletionScheduled = true;
 965 
 966         callOnMainThread([protectedThis = makeRef(*this)]() mutable {
 967             protectedThis-&gt;deleteMarkedNodes();
 968         });
 969     }
 970 }
 971 
 972 void AudioContext::deleteMarkedNodes()
 973 {
 974     ASSERT(isMainThread());
 975 
 976     // Protect this object from being deleted before we release the mutex locked by AutoLocker.
 977     Ref&lt;AudioContext&gt; protectedThis(*this);
 978     {
 979         AutoLocker locker(*this);
 980 
 981         while (m_nodesToDelete.size()) {
 982             AudioNode* node = m_nodesToDelete.takeLast();
 983 
 984             // Before deleting the node, clear out any AudioNodeInputs from m_dirtySummingJunctions.
 985             unsigned numberOfInputs = node-&gt;numberOfInputs();
 986             for (unsigned i = 0; i &lt; numberOfInputs; ++i)
 987                 m_dirtySummingJunctions.remove(node-&gt;input(i));
 988 
 989             // Before deleting the node, clear out any AudioNodeOutputs from m_dirtyAudioNodeOutputs.
 990             unsigned numberOfOutputs = node-&gt;numberOfOutputs();
 991             for (unsigned i = 0; i &lt; numberOfOutputs; ++i)
 992                 m_dirtyAudioNodeOutputs.remove(node-&gt;output(i));
 993 
 994             // Finally, delete it.
 995             delete node;
 996         }
 997         m_isDeletionScheduled = false;
 998     }
 999 }
1000 
1001 void AudioContext::markSummingJunctionDirty(AudioSummingJunction* summingJunction)
1002 {
1003     ASSERT(isGraphOwner());
1004     m_dirtySummingJunctions.add(summingJunction);
1005 }
1006 
1007 void AudioContext::removeMarkedSummingJunction(AudioSummingJunction* summingJunction)
1008 {
1009     ASSERT(isMainThread());
1010     AutoLocker locker(*this);
1011     m_dirtySummingJunctions.remove(summingJunction);
1012 }
1013 
1014 void AudioContext::markAudioNodeOutputDirty(AudioNodeOutput* output)
1015 {
1016     ASSERT(isGraphOwner());
1017     m_dirtyAudioNodeOutputs.add(output);
1018 }
1019 
1020 void AudioContext::handleDirtyAudioSummingJunctions()
1021 {
1022     ASSERT(isGraphOwner());
1023 
1024     for (auto&amp; junction : m_dirtySummingJunctions)
1025         junction-&gt;updateRenderingState();
1026 
1027     m_dirtySummingJunctions.clear();
1028 }
1029 
1030 void AudioContext::handleDirtyAudioNodeOutputs()
1031 {
1032     ASSERT(isGraphOwner());
1033 
1034     for (auto&amp; output : m_dirtyAudioNodeOutputs)
1035         output-&gt;updateRenderingState();
1036 
1037     m_dirtyAudioNodeOutputs.clear();
1038 }
1039 
1040 void AudioContext::addAutomaticPullNode(AudioNode&amp; node)
1041 {
1042     ASSERT(isGraphOwner());
1043 
1044     if (m_automaticPullNodes.add(&amp;node).isNewEntry)
1045         m_automaticPullNodesNeedUpdating = true;
1046 }
1047 
1048 void AudioContext::removeAutomaticPullNode(AudioNode&amp; node)
1049 {
1050     ASSERT(isGraphOwner());
1051 
1052     if (m_automaticPullNodes.remove(&amp;node))
1053         m_automaticPullNodesNeedUpdating = true;
1054 }
1055 
1056 void AudioContext::updateAutomaticPullNodes()
1057 {
1058     ASSERT(isGraphOwner());
1059 
1060     if (m_automaticPullNodesNeedUpdating) {
1061         // Copy from m_automaticPullNodes to m_renderingAutomaticPullNodes.
1062         m_renderingAutomaticPullNodes.resize(m_automaticPullNodes.size());
1063 
1064         unsigned i = 0;
1065         for (auto&amp; output : m_automaticPullNodes)
1066             m_renderingAutomaticPullNodes[i++] = output;
1067 
1068         m_automaticPullNodesNeedUpdating = false;
1069     }
1070 }
1071 
1072 void AudioContext::processAutomaticPullNodes(size_t framesToProcess)
1073 {
1074     ASSERT(isAudioThread());
1075 
1076     for (auto&amp; node : m_renderingAutomaticPullNodes)
1077         node-&gt;processIfNecessary(framesToProcess);
1078 }
1079 
1080 ScriptExecutionContext* AudioContext::scriptExecutionContext() const
1081 {
1082     return ActiveDOMObject::scriptExecutionContext();
1083 }
1084 
1085 void AudioContext::nodeWillBeginPlayback()
1086 {
1087     // Called by scheduled AudioNodes when clients schedule their start times.
1088     // Prior to the introduction of suspend(), resume(), and stop(), starting
1089     // a scheduled AudioNode would remove the user-gesture restriction, if present,
1090     // and would thus unmute the context. Now that AudioContext stays in the
1091     // &quot;suspended&quot; state if a user-gesture restriction is present, starting a
1092     // schedule AudioNode should set the state to &quot;running&quot;, but only if the
1093     // user-gesture restriction is set.
1094     if (userGestureRequiredForAudioStart())
1095         startRendering();
1096 }
1097 
1098 bool AudioContext::willBeginPlayback()
1099 {
1100     if (!document())
1101         return false;
1102 
1103     if (userGestureRequiredForAudioStart()) {
1104         if (!processingUserGestureForMedia() &amp;&amp; !document()-&gt;isCapturing()) {
1105             ALWAYS_LOG(LOGIDENTIFIER, &quot;returning false, not processing user gesture or capturing&quot;);
1106             return false;
1107         }
1108         removeBehaviorRestriction(AudioContext::RequireUserGestureForAudioStartRestriction);
1109     }
1110 
1111     if (pageConsentRequiredForAudioStart()) {
1112         Page* page = document()-&gt;page();
1113         if (page &amp;&amp; !page-&gt;canStartMedia()) {
1114             document()-&gt;addMediaCanStartListener(*this);
1115             ALWAYS_LOG(LOGIDENTIFIER, &quot;returning false, page doesn&#39;t allow media to start&quot;);
1116             return false;
1117         }
1118         removeBehaviorRestriction(AudioContext::RequirePageConsentForAudioStartRestriction);
1119     }
1120 
1121     auto willBegin = m_mediaSession-&gt;clientWillBeginPlayback();
1122     ALWAYS_LOG(LOGIDENTIFIER, &quot;returning &quot;, willBegin);
1123 
1124     return willBegin;
1125 }
1126 
1127 bool AudioContext::willPausePlayback()
1128 {
1129     if (!document())
1130         return false;
1131 
1132     if (userGestureRequiredForAudioStart()) {
1133         if (!processingUserGestureForMedia())
1134             return false;
1135         removeBehaviorRestriction(AudioContext::RequireUserGestureForAudioStartRestriction);
1136     }
1137 
1138     if (pageConsentRequiredForAudioStart()) {
1139         Page* page = document()-&gt;page();
1140         if (page &amp;&amp; !page-&gt;canStartMedia()) {
1141             document()-&gt;addMediaCanStartListener(*this);
1142             return false;
1143         }
1144         removeBehaviorRestriction(AudioContext::RequirePageConsentForAudioStartRestriction);
1145     }
1146 
1147     return m_mediaSession-&gt;clientWillPausePlayback();
1148 }
1149 
1150 void AudioContext::startRendering()
1151 {
1152     ALWAYS_LOG(LOGIDENTIFIER);
1153     if (m_isStopScheduled || !willBeginPlayback())
1154         return;
1155 
1156     makePendingActivity();
1157 
1158     destination()-&gt;startRendering();
1159     setState(State::Running);
1160 }
1161 
1162 void AudioContext::mediaCanStart(Document&amp; document)
1163 {
1164     ASSERT_UNUSED(document, &amp;document == this-&gt;document());
1165     removeBehaviorRestriction(AudioContext::RequirePageConsentForAudioStartRestriction);
1166     mayResumePlayback(true);
1167 }
1168 
1169 MediaProducer::MediaStateFlags AudioContext::mediaState() const
1170 {
1171     if (!m_isStopScheduled &amp;&amp; m_destinationNode &amp;&amp; m_destinationNode-&gt;isPlayingAudio())
1172         return MediaProducer::IsPlayingAudio;
1173 
1174     return MediaProducer::IsNotPlaying;
1175 }
1176 
1177 void AudioContext::pageMutedStateDidChange()
1178 {
1179     if (m_destinationNode &amp;&amp; document() &amp;&amp; document()-&gt;page())
1180         m_destinationNode-&gt;setMuted(document()-&gt;page()-&gt;isAudioMuted());
1181 }
1182 
1183 void AudioContext::isPlayingAudioDidChange()
1184 {
1185     // Make sure to call Document::updateIsPlayingMedia() on the main thread, since
1186     // we could be on the audio I/O thread here and the call into WebCore could block.
1187     callOnMainThread([protectedThis = makeRef(*this)] {
1188         if (protectedThis-&gt;document())
1189             protectedThis-&gt;document()-&gt;updateIsPlayingMedia();
1190     });
1191 }
1192 
1193 void AudioContext::finishedRendering(bool didRendering)
1194 {
1195     ASSERT(isOfflineContext());
1196     ASSERT(isMainThread());
1197     if (!isMainThread())
1198         return;
1199 
1200     auto clearPendingActivityIfExitEarly = WTF::makeScopeExit([this] {
1201         clearPendingActivity();
1202     });
1203 
1204 
1205     ALWAYS_LOG(LOGIDENTIFIER);
1206 
1207     if (!didRendering)
1208         return;
1209 
1210     AudioBuffer* renderedBuffer = m_renderTarget.get();
1211     setState(State::Closed);
1212 
1213     ASSERT(renderedBuffer);
1214     if (!renderedBuffer)
1215         return;
1216 
1217     // Avoid firing the event if the document has already gone away.
1218     if (m_isStopScheduled)
1219         return;
1220 
1221     clearPendingActivityIfExitEarly.release();
1222     m_eventQueue-&gt;enqueueEvent(OfflineAudioCompletionEvent::create(renderedBuffer));
1223 }
1224 
1225 void AudioContext::dispatchEvent(Event&amp; event)
1226 {
1227     EventTarget::dispatchEvent(event);
1228     if (event.eventInterface() == OfflineAudioCompletionEventInterfaceType)
1229         clearPendingActivity();
1230 }
1231 
1232 void AudioContext::incrementActiveSourceCount()
1233 {
1234     ++m_activeSourceCount;
1235 }
1236 
1237 void AudioContext::decrementActiveSourceCount()
1238 {
1239     --m_activeSourceCount;
1240 }
1241 
1242 void AudioContext::suspendRendering(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
1243 {
1244     if (isOfflineContext() || m_isStopScheduled) {
1245         promise.reject(InvalidStateError);
1246         return;
1247     }
1248 
1249     if (m_state == State::Suspended) {
1250         promise.resolve();
1251         return;
1252     }
1253 
1254     if (m_state == State::Closed || m_state == State::Interrupted || !m_destinationNode) {
1255         promise.reject();
1256         return;
1257     }
1258 
1259     addReaction(State::Suspended, WTFMove(promise));
1260 
1261     if (!willPausePlayback())
1262         return;
1263 
1264     lazyInitialize();
1265 
1266     m_destinationNode-&gt;suspend([this, protectedThis = makeRef(*this)] {
1267         setState(State::Suspended);
1268     });
1269 }
1270 
1271 void AudioContext::resumeRendering(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
1272 {
1273     if (isOfflineContext() || m_isStopScheduled) {
1274         promise.reject(InvalidStateError);
1275         return;
1276     }
1277 
1278     if (m_state == State::Running) {
1279         promise.resolve();
1280         return;
1281     }
1282 
1283     if (m_state == State::Closed || !m_destinationNode) {
1284         promise.reject();
1285         return;
1286     }
1287 
1288     addReaction(State::Running, WTFMove(promise));
1289 
1290     if (!willBeginPlayback())
1291         return;
1292 
1293     lazyInitialize();
1294 
1295     m_destinationNode-&gt;resume([this, protectedThis = makeRef(*this)] {
1296         setState(State::Running);
1297     });
1298 }
1299 
1300 void AudioContext::close(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
1301 {
1302     if (isOfflineContext() || m_isStopScheduled) {
1303         promise.reject(InvalidStateError);
1304         return;
1305     }
1306 
1307     if (m_state == State::Closed || !m_destinationNode) {
1308         promise.resolve();
1309         return;
1310     }
1311 
1312     addReaction(State::Closed, WTFMove(promise));
1313 
1314     lazyInitialize();
1315 
1316     m_destinationNode-&gt;close([this, protectedThis = makeRef(*this)] {
1317         setState(State::Closed);
1318         uninitialize();
1319     });
1320 }
1321 
1322 
1323 void AudioContext::suspendPlayback()
1324 {
1325     if (!m_destinationNode || m_state == State::Closed)
1326         return;
1327 
1328     if (m_state == State::Suspended) {
1329         if (m_mediaSession-&gt;state() == PlatformMediaSession::Interrupted)
1330             setState(State::Interrupted);
1331         return;
1332     }
1333 
1334     lazyInitialize();
1335 
1336     m_destinationNode-&gt;suspend([this, protectedThis = makeRef(*this)] {
1337         bool interrupted = m_mediaSession-&gt;state() == PlatformMediaSession::Interrupted;
1338         setState(interrupted ? State::Interrupted : State::Suspended);
1339     });
1340 }
1341 
1342 void AudioContext::mayResumePlayback(bool shouldResume)
1343 {
1344     if (!m_destinationNode || m_state == State::Closed || m_state == State::Running)
1345         return;
1346 
1347     if (!shouldResume) {
1348         setState(State::Suspended);
1349         return;
1350     }
1351 
1352     if (!willBeginPlayback())
1353         return;
1354 
1355     lazyInitialize();
1356 
1357     m_destinationNode-&gt;resume([this, protectedThis = makeRef(*this)] {
1358         setState(State::Running);
1359     });
1360 }
1361 
1362 void AudioContext::postTask(WTF::Function&lt;void()&gt;&amp;&amp; task)
1363 {
1364     if (m_isStopScheduled)
1365         return;
1366 
1367     m_scriptExecutionContext-&gt;postTask(WTFMove(task));
1368 }
1369 
1370 const SecurityOrigin* AudioContext::origin() const
1371 {
1372     return m_scriptExecutionContext ? m_scriptExecutionContext-&gt;securityOrigin() : nullptr;
1373 }
1374 
1375 void AudioContext::addConsoleMessage(MessageSource source, MessageLevel level, const String&amp; message)
1376 {
1377     if (m_scriptExecutionContext)
1378         m_scriptExecutionContext-&gt;addConsoleMessage(source, level, message);
1379 }
1380 
1381 void AudioContext::clearPendingActivity()
1382 {
1383     if (!m_pendingActivity)
1384         return;
1385     m_pendingActivity = nullptr;
1386     // FIXME: Remove this specific deref() and ref() call in makePendingActivity().
1387     deref();
1388 }
1389 
1390 void AudioContext::makePendingActivity()
1391 {
1392     if (m_pendingActivity)
1393         return;
1394     m_pendingActivity = ActiveDOMObject::makePendingActivity(*this);
1395     ref();
1396 }
1397 
1398 #if !RELEASE_LOG_DISABLED
1399 WTFLogChannel&amp; AudioContext::logChannel() const
1400 {
1401     return LogMedia;
1402 }
1403 #endif
1404 
1405 } // namespace WebCore
1406 
1407 #endif // ENABLE(WEB_AUDIO)
    </pre>
  </body>
</html>