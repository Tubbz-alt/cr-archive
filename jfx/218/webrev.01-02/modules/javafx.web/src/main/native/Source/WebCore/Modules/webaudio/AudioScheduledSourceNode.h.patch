diff a/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioScheduledSourceNode.h b/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioScheduledSourceNode.h
--- a/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioScheduledSourceNode.h
+++ b/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioScheduledSourceNode.h
@@ -26,15 +26,16 @@
  * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
 
 #pragma once
 
+#include "ActiveDOMObject.h"
 #include "AudioNode.h"
 
 namespace WebCore {
 
-class AudioScheduledSourceNode : public AudioNode {
+class AudioScheduledSourceNode : public AudioNode, public ActiveDOMObject {
     WTF_MAKE_ISO_ALLOCATED(AudioScheduledSourceNode);
 public:
     // These are the possible states an AudioScheduledSourceNode can be in:
     //
     // UNSCHEDULED_STATE - Initial playback state. Created, but not yet scheduled.
@@ -52,12 +53,14 @@
         FINISHED_STATE = 3
     };
 
     AudioScheduledSourceNode(AudioContext&, float sampleRate);
 
-    ExceptionOr<void> start(double when);
-    ExceptionOr<void> stop(double when);
+    ExceptionOr<void> startLater(double when);
+    ExceptionOr<void> stopLater(double when);
+
+    void didBecomeMarkedForDeletion() override;
 
     unsigned short playbackState() const { return static_cast<unsigned short>(m_playbackState); }
     bool isPlayingOrScheduled() const { return m_playbackState == PLAYING_STATE || m_playbackState == SCHEDULED_STATE; }
     bool hasFinished() const { return m_playbackState == FINISHED_STATE; }
 
@@ -73,24 +76,18 @@
     // Called when we have no more sound to play or the noteOff() time has been reached.
     virtual void finish();
 
     PlaybackState m_playbackState { UNSCHEDULED_STATE };
 
+    RefPtr<PendingActivity<AudioScheduledSourceNode>> m_pendingActivity;
     // m_startTime is the time to start playing based on the context's timeline (0 or a time less than the context's current time means "now").
     double m_startTime { 0 }; // in seconds
 
     // m_endTime is the time to stop playing based on the context's timeline (0 or a time less than the context's current time means "now").
     // If it hasn't been set explicitly, then the sound will not stop playing (if looping) or will stop when the end of the AudioBuffer
     // has been reached.
     double m_endTime; // in seconds
 
-    bool m_hasEndedListener { false };
-
     static const double UnknownTime;
-
-private:
-    bool addEventListener(const AtomString& eventType, Ref<EventListener>&&, const AddEventListenerOptions&) override;
-    bool removeEventListener(const AtomString& eventType, EventListener&, const ListenerOptions&) override;
-    void removeAllEventListeners() override;
 };
 
 } // namespace WebCore
