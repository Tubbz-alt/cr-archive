<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JITInlines.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2008-2019 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #if ENABLE(JIT)
<a name="1" id="anc1"></a>
 29 #include &quot;JSCInlines.h&quot;
 30 
 31 namespace JSC {
 32 
<a name="2" id="anc2"></a><span class="line-removed"> 33 inline MacroAssembler::JumpList JIT::emitDoubleGetByVal(const Instruction* instruction, PatchableJump&amp; badType)</span>
<span class="line-removed"> 34 {</span>
<span class="line-removed"> 35 #if USE(JSVALUE64)</span>
<span class="line-removed"> 36     JSValueRegs result = JSValueRegs(regT0);</span>
<span class="line-removed"> 37 #else</span>
<span class="line-removed"> 38     JSValueRegs result = JSValueRegs(regT1, regT0);</span>
<span class="line-removed"> 39 #endif</span>
<span class="line-removed"> 40     JumpList slowCases = emitDoubleLoad(instruction, badType);</span>
<span class="line-removed"> 41     boxDouble(fpRegT0, result);</span>
<span class="line-removed"> 42     return slowCases;</span>
<span class="line-removed"> 43 }</span>
<span class="line-removed"> 44 </span>
 45 ALWAYS_INLINE MacroAssembler::JumpList JIT::emitLoadForArrayMode(const Instruction* currentInstruction, JITArrayMode arrayMode, PatchableJump&amp; badType)
 46 {
 47     switch (arrayMode) {
 48     case JITInt32:
 49         return emitInt32Load(currentInstruction, badType);
 50     case JITDouble:
 51         return emitDoubleLoad(currentInstruction, badType);
 52     case JITContiguous:
 53         return emitContiguousLoad(currentInstruction, badType);
 54     case JITArrayStorage:
 55         return emitArrayStorageLoad(currentInstruction, badType);
 56     default:
 57         break;
 58     }
 59     RELEASE_ASSERT_NOT_REACHED();
 60     return MacroAssembler::JumpList();
 61 }
 62 
<a name="3" id="anc3"></a><span class="line-modified"> 63 inline MacroAssembler::JumpList JIT::emitContiguousGetByVal(const Instruction* instruction, PatchableJump&amp; badType, IndexingType expectedShape)</span>
 64 {
<a name="4" id="anc4"></a><span class="line-modified"> 65     return emitContiguousLoad(instruction, badType, expectedShape);</span>
 66 }
 67 
<a name="5" id="anc5"></a><span class="line-modified"> 68 inline MacroAssembler::JumpList JIT::emitArrayStorageGetByVal(const Instruction* instruction, PatchableJump&amp; badType)</span>
 69 {
<a name="6" id="anc6"></a><span class="line-modified"> 70     return emitArrayStorageLoad(instruction, badType);</span>
<span class="line-removed"> 71 }</span>
<span class="line-removed"> 72 </span>
<span class="line-removed"> 73 ALWAYS_INLINE bool JIT::isOperandConstantDouble(int src)</span>
<span class="line-removed"> 74 {</span>
<span class="line-removed"> 75     return m_codeBlock-&gt;isConstantRegisterIndex(src) &amp;&amp; getConstantOperand(src).isDouble();</span>
<span class="line-removed"> 76 }</span>
<span class="line-removed"> 77 </span>
<span class="line-removed"> 78 ALWAYS_INLINE JSValue JIT::getConstantOperand(int src)</span>
<span class="line-removed"> 79 {</span>
<span class="line-removed"> 80     ASSERT(m_codeBlock-&gt;isConstantRegisterIndex(src));</span>
 81     return m_codeBlock-&gt;getConstant(src);
 82 }
 83 
<a name="7" id="anc7"></a><span class="line-modified"> 84 ALWAYS_INLINE void JIT::emitPutIntToCallFrameHeader(RegisterID from, int entry)</span>
 85 {
<a name="8" id="anc8"></a>
 86 #if USE(JSVALUE32_64)
 87     store32(TrustedImm32(JSValue::Int32Tag), tagFor(entry));
 88     store32(from, payloadFor(entry));
 89 #else
 90     store64(from, addressFor(entry));
 91 #endif
 92 }
 93 
 94 ALWAYS_INLINE void JIT::emitLoadCharacterString(RegisterID src, RegisterID dst, JumpList&amp; failures)
 95 {
 96     failures.append(branchIfNotString(src));
 97     loadPtr(MacroAssembler::Address(src, JSString::offsetOfValue()), dst);
 98     failures.append(branchIfRopeStringImpl(dst));
 99     failures.append(branch32(NotEqual, MacroAssembler::Address(dst, StringImpl::lengthMemoryOffset()), TrustedImm32(1)));
<a name="9" id="anc9"></a><span class="line-modified">100     loadPtr(MacroAssembler::Address(dst, StringImpl::flagsOffset()), regT1);</span>
<span class="line-modified">101     loadPtr(MacroAssembler::Address(dst, StringImpl::dataOffset()), dst);</span>
<span class="line-modified">102 </span>
<span class="line-modified">103     JumpList is16Bit;</span>
<span class="line-modified">104     JumpList cont8Bit;</span>
<span class="line-removed">105     is16Bit.append(branchTest32(Zero, regT1, TrustedImm32(StringImpl::flagIs8Bit())));</span>
<span class="line-removed">106     load8(MacroAssembler::Address(dst, 0), dst);</span>
<span class="line-removed">107     cont8Bit.append(jump());</span>
108     is16Bit.link(this);
<a name="10" id="anc10"></a><span class="line-modified">109     load16(MacroAssembler::Address(dst, 0), dst);</span>
<span class="line-modified">110     cont8Bit.link(this);</span>
111 }
112 
113 ALWAYS_INLINE JIT::Call JIT::emitNakedCall(CodePtr&lt;NoPtrTag&gt; target)
114 {
<a name="11" id="anc11"></a><span class="line-modified">115     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
116     Call nakedCall = nearCall();
<a name="12" id="anc12"></a><span class="line-modified">117     m_calls.append(CallRecord(nakedCall, m_bytecodeOffset, FunctionPtr&lt;OperationPtrTag&gt;(target.retagged&lt;OperationPtrTag&gt;())));</span>
118     return nakedCall;
119 }
120 
121 ALWAYS_INLINE JIT::Call JIT::emitNakedTailCall(CodePtr&lt;NoPtrTag&gt; target)
122 {
<a name="13" id="anc13"></a><span class="line-modified">123     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
124     Call nakedCall = nearTailCall();
<a name="14" id="anc14"></a><span class="line-modified">125     m_calls.append(CallRecord(nakedCall, m_bytecodeOffset, FunctionPtr&lt;OperationPtrTag&gt;(target.retagged&lt;OperationPtrTag&gt;())));</span>
126     return nakedCall;
127 }
128 
129 ALWAYS_INLINE void JIT::updateTopCallFrame()
130 {
<a name="15" id="anc15"></a><span class="line-modified">131     ASSERT(static_cast&lt;int&gt;(m_bytecodeOffset) &gt;= 0);</span>
<span class="line-modified">132 #if USE(JSVALUE32_64)</span>
<span class="line-removed">133     const Instruction* instruction = m_codeBlock-&gt;instructions().at(m_bytecodeOffset).ptr();</span>
<span class="line-removed">134     uint32_t locationBits = CallSiteIndex(instruction).bits();</span>
<span class="line-removed">135 #else</span>
<span class="line-removed">136     uint32_t locationBits = CallSiteIndex(m_bytecodeOffset).bits();</span>
<span class="line-removed">137 #endif</span>
<span class="line-removed">138     store32(TrustedImm32(locationBits), tagFor(CallFrameSlot::argumentCount));</span>
139 
140     // FIXME: It&#39;s not clear that this is needed. JITOperations tend to update the top call frame on
141     // the C++ side.
142     // https://bugs.webkit.org/show_bug.cgi?id=155693
143     storePtr(callFrameRegister, &amp;m_vm-&gt;topCallFrame);
144 }
145 
146 ALWAYS_INLINE MacroAssembler::Call JIT::appendCallWithExceptionCheck(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
147 {
148     updateTopCallFrame();
149     MacroAssembler::Call call = appendCall(function);
150     exceptionCheck();
151     return call;
152 }
153 
154 #if OS(WINDOWS) &amp;&amp; CPU(X86_64)
155 ALWAYS_INLINE MacroAssembler::Call JIT::appendCallWithExceptionCheckAndSlowPathReturnType(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
156 {
157     updateTopCallFrame();
158     MacroAssembler::Call call = appendCallWithSlowPathReturnType(function);
159     exceptionCheck();
160     return call;
161 }
162 #endif
163 
164 ALWAYS_INLINE MacroAssembler::Call JIT::appendCallWithCallFrameRollbackOnException(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
165 {
166     updateTopCallFrame(); // The callee is responsible for setting topCallFrame to their caller
167     MacroAssembler::Call call = appendCall(function);
168     exceptionCheckWithCallFrameRollback();
169     return call;
170 }
171 
<a name="16" id="anc16"></a><span class="line-modified">172 ALWAYS_INLINE MacroAssembler::Call JIT::appendCallWithExceptionCheckSetJSValueResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, int dst)</span>
173 {
174     MacroAssembler::Call call = appendCallWithExceptionCheck(function);
175 #if USE(JSVALUE64)
176     emitPutVirtualRegister(dst, returnValueGPR);
177 #else
178     emitStore(dst, returnValueGPR2, returnValueGPR);
179 #endif
180     return call;
181 }
182 
183 template&lt;typename Metadata&gt;
<a name="17" id="anc17"></a><span class="line-modified">184 ALWAYS_INLINE MacroAssembler::Call JIT::appendCallWithExceptionCheckSetJSValueResultWithProfile(Metadata&amp; metadata, const FunctionPtr&lt;CFunctionPtrTag&gt; function, int dst)</span>
185 {
186     MacroAssembler::Call call = appendCallWithExceptionCheck(function);
187     emitValueProfilingSite(metadata);
188 #if USE(JSVALUE64)
189     emitPutVirtualRegister(dst, returnValueGPR);
190 #else
191     emitStore(dst, returnValueGPR2, returnValueGPR);
192 #endif
193     return call;
194 }
195 
<a name="18" id="anc18"></a><span class="line-modified">196 ALWAYS_INLINE void JIT::linkSlowCaseIfNotJSCell(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter, int vReg)</span>
197 {
<a name="19" id="anc19"></a><span class="line-modified">198     if (!m_codeBlock-&gt;isKnownNotImmediate(vReg))</span>
199         linkSlowCase(iter);
200 }
201 
<a name="20" id="anc20"></a><span class="line-modified">202 ALWAYS_INLINE void JIT::linkAllSlowCasesForBytecodeOffset(Vector&lt;SlowCaseEntry&gt;&amp; slowCases, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter, unsigned bytecodeOffset)</span>
203 {
<a name="21" id="anc21"></a><span class="line-modified">204     while (iter != slowCases.end() &amp;&amp; iter-&gt;to == bytecodeOffset)</span>
205         linkSlowCase(iter);
206 }
207 
<a name="22" id="anc22"></a>






208 ALWAYS_INLINE void JIT::addSlowCase(Jump jump)
209 {
<a name="23" id="anc23"></a><span class="line-modified">210     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
211 
<a name="24" id="anc24"></a><span class="line-modified">212     m_slowCases.append(SlowCaseEntry(jump, m_bytecodeOffset));</span>
213 }
214 
215 ALWAYS_INLINE void JIT::addSlowCase(const JumpList&amp; jumpList)
216 {
<a name="25" id="anc25"></a><span class="line-modified">217     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
218 
219     for (const Jump&amp; jump : jumpList.jumps())
<a name="26" id="anc26"></a><span class="line-modified">220         m_slowCases.append(SlowCaseEntry(jump, m_bytecodeOffset));</span>
221 }
222 
223 ALWAYS_INLINE void JIT::addSlowCase()
224 {
<a name="27" id="anc27"></a><span class="line-modified">225     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
226 
227     Jump emptyJump; // Doing it this way to make Windows happy.
<a name="28" id="anc28"></a><span class="line-modified">228     m_slowCases.append(SlowCaseEntry(emptyJump, m_bytecodeOffset));</span>
229 }
230 
231 ALWAYS_INLINE void JIT::addJump(Jump jump, int relativeOffset)
232 {
<a name="29" id="anc29"></a><span class="line-modified">233     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
234 
<a name="30" id="anc30"></a><span class="line-modified">235     m_jmpTable.append(JumpTable(jump, m_bytecodeOffset + relativeOffset));</span>
236 }
237 
238 ALWAYS_INLINE void JIT::addJump(const JumpList&amp; jumpList, int relativeOffset)
239 {
<a name="31" id="anc31"></a><span class="line-modified">240     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
241 
242     for (auto&amp; jump : jumpList.jumps())
243         addJump(jump, relativeOffset);
244 }
245 
246 ALWAYS_INLINE void JIT::emitJumpSlowToHot(Jump jump, int relativeOffset)
247 {
<a name="32" id="anc32"></a><span class="line-modified">248     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
249 
<a name="33" id="anc33"></a><span class="line-modified">250     jump.linkTo(m_labels[m_bytecodeOffset + relativeOffset], this);</span>
251 }
252 
253 #if ENABLE(SAMPLING_FLAGS)
254 ALWAYS_INLINE void JIT::setSamplingFlag(int32_t flag)
255 {
256     ASSERT(flag &gt;= 1);
257     ASSERT(flag &lt;= 32);
258     or32(TrustedImm32(1u &lt;&lt; (flag - 1)), AbsoluteAddress(SamplingFlags::addressOfFlags()));
259 }
260 
261 ALWAYS_INLINE void JIT::clearSamplingFlag(int32_t flag)
262 {
263     ASSERT(flag &gt;= 1);
264     ASSERT(flag &lt;= 32);
265     and32(TrustedImm32(~(1u &lt;&lt; (flag - 1))), AbsoluteAddress(SamplingFlags::addressOfFlags()));
266 }
267 #endif
268 
269 #if ENABLE(SAMPLING_COUNTERS)
270 ALWAYS_INLINE void JIT::emitCount(AbstractSamplingCounter&amp; counter, int32_t count)
271 {
272     add64(TrustedImm32(count), AbsoluteAddress(counter.addressOfCounter()));
273 }
274 #endif
275 
276 #if ENABLE(OPCODE_SAMPLING)
277 #if CPU(X86_64)
278 ALWAYS_INLINE void JIT::sampleInstruction(const Instruction* instruction, bool inHostFunction)
279 {
280     move(TrustedImmPtr(m_interpreter-&gt;sampler()-&gt;sampleSlot()), X86Registers::ecx);
281     storePtr(TrustedImmPtr(m_interpreter-&gt;sampler()-&gt;encodeSample(instruction, inHostFunction)), X86Registers::ecx);
282 }
283 #else
284 ALWAYS_INLINE void JIT::sampleInstruction(const Instruction* instruction, bool inHostFunction)
285 {
286     storePtr(TrustedImmPtr(m_interpreter-&gt;sampler()-&gt;encodeSample(instruction, inHostFunction)), m_interpreter-&gt;sampler()-&gt;sampleSlot());
287 }
288 #endif
289 #endif
290 
291 #if ENABLE(CODEBLOCK_SAMPLING)
292 #if CPU(X86_64)
293 ALWAYS_INLINE void JIT::sampleCodeBlock(CodeBlock* codeBlock)
294 {
295     move(TrustedImmPtr(m_interpreter-&gt;sampler()-&gt;codeBlockSlot()), X86Registers::ecx);
296     storePtr(TrustedImmPtr(codeBlock), X86Registers::ecx);
297 }
298 #else
299 ALWAYS_INLINE void JIT::sampleCodeBlock(CodeBlock* codeBlock)
300 {
301     storePtr(TrustedImmPtr(codeBlock), m_interpreter-&gt;sampler()-&gt;codeBlockSlot());
302 }
303 #endif
304 #endif
305 
<a name="34" id="anc34"></a><span class="line-modified">306 ALWAYS_INLINE bool JIT::isOperandConstantChar(int src)</span>
307 {
<a name="35" id="anc35"></a><span class="line-modified">308     return m_codeBlock-&gt;isConstantRegisterIndex(src) &amp;&amp; getConstantOperand(src).isString() &amp;&amp; asString(getConstantOperand(src).asCell())-&gt;length() == 1;</span>
309 }
310 
311 inline void JIT::emitValueProfilingSite(ValueProfile&amp; valueProfile)
312 {
313     ASSERT(shouldEmitProfiling());
314 
315     const RegisterID value = regT0;
316 #if USE(JSVALUE32_64)
317     const RegisterID valueTag = regT1;
318 #endif
319 
320     // We&#39;re in a simple configuration: only one bucket, so we can just do a direct
321     // store.
322 #if USE(JSVALUE64)
323     store64(value, valueProfile.m_buckets);
324 #else
325     EncodedValueDescriptor* descriptor = bitwise_cast&lt;EncodedValueDescriptor*&gt;(valueProfile.m_buckets);
326     store32(value, &amp;descriptor-&gt;asBits.payload);
327     store32(valueTag, &amp;descriptor-&gt;asBits.tag);
328 #endif
329 }
330 
331 template&lt;typename Op&gt;
332 inline std::enable_if_t&lt;std::is_same&lt;decltype(Op::Metadata::m_profile), ValueProfile&gt;::value, void&gt; JIT::emitValueProfilingSiteIfProfiledOpcode(Op bytecode)
333 {
334     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
335 }
336 
337 inline void JIT::emitValueProfilingSiteIfProfiledOpcode(...) { }
338 
339 template&lt;typename Metadata&gt;
340 inline void JIT::emitValueProfilingSite(Metadata&amp; metadata)
341 {
342     if (!shouldEmitProfiling())
343         return;
344     emitValueProfilingSite(metadata.m_profile);
345 }
346 
347 inline void JIT::emitArrayProfilingSiteWithCell(RegisterID cell, RegisterID indexingType, ArrayProfile* arrayProfile)
348 {
349     if (shouldEmitProfiling()) {
350         load32(MacroAssembler::Address(cell, JSCell::structureIDOffset()), indexingType);
351         store32(indexingType, arrayProfile-&gt;addressOfLastSeenStructureID());
352     }
353 
354     load8(Address(cell, JSCell::indexingTypeAndMiscOffset()), indexingType);
355 }
356 
357 inline void JIT::emitArrayProfileStoreToHoleSpecialCase(ArrayProfile* arrayProfile)
358 {
359     store8(TrustedImm32(1), arrayProfile-&gt;addressOfMayStoreToHole());
360 }
361 
362 inline void JIT::emitArrayProfileOutOfBoundsSpecialCase(ArrayProfile* arrayProfile)
363 {
364     store8(TrustedImm32(1), arrayProfile-&gt;addressOfOutOfBounds());
365 }
366 
367 inline JITArrayMode JIT::chooseArrayMode(ArrayProfile* profile)
368 {
369     auto arrayProfileSaw = [] (ArrayModes arrayModes, IndexingType capability) {
370         return arrayModesIncludeIgnoringTypedArrays(arrayModes, capability);
371     };
372 
373     ConcurrentJSLocker locker(m_codeBlock-&gt;m_lock);
374     profile-&gt;computeUpdatedPrediction(locker, m_codeBlock);
375     ArrayModes arrayModes = profile-&gt;observedArrayModes(locker);
376     if (arrayProfileSaw(arrayModes, DoubleShape))
377         return JITDouble;
378     if (arrayProfileSaw(arrayModes, Int32Shape))
379         return JITInt32;
380     if (arrayProfileSaw(arrayModes, ArrayStorageShape))
381         return JITArrayStorage;
382     return JITContiguous;
383 }
384 
<a name="36" id="anc36"></a><span class="line-modified">385 ALWAYS_INLINE int32_t JIT::getOperandConstantInt(int src)</span>
386 {
387     return getConstantOperand(src).asInt32();
388 }
389 
<a name="37" id="anc37"></a><span class="line-modified">390 ALWAYS_INLINE double JIT::getOperandConstantDouble(int src)</span>
391 {
392     return getConstantOperand(src).asDouble();
393 }
394 
<a name="38" id="anc38"></a><span class="line-modified">395 ALWAYS_INLINE void JIT::emitInitRegister(int dst)</span>
396 {
397     storeTrustedValue(jsUndefined(), addressFor(dst));
398 }
399 
400 #if USE(JSVALUE32_64)
401 
<a name="39" id="anc39"></a><span class="line-modified">402 inline void JIT::emitLoadTag(int index, RegisterID tag)</span>
403 {
<a name="40" id="anc40"></a><span class="line-modified">404     if (m_codeBlock-&gt;isConstantRegisterIndex(index)) {</span>
<span class="line-modified">405         move(Imm32(getConstantOperand(index).tag()), tag);</span>









406         return;
407     }
408 
<a name="41" id="anc41"></a><span class="line-modified">409     load32(tagFor(index), tag);</span>
410 }
411 
<a name="42" id="anc42"></a><span class="line-modified">412 inline void JIT::emitLoadPayload(int index, RegisterID payload)</span>
413 {
<a name="43" id="anc43"></a><span class="line-modified">414     if (m_codeBlock-&gt;isConstantRegisterIndex(index)) {</span>
<span class="line-modified">415         move(Imm32(getConstantOperand(index).payload()), payload);</span>
416         return;
417     }
418 
<a name="44" id="anc44"></a><span class="line-modified">419     load32(payloadFor(index), payload);</span>
420 }
421 
422 inline void JIT::emitLoad(const JSValue&amp; v, RegisterID tag, RegisterID payload)
423 {
424     move(Imm32(v.payload()), payload);
425     move(Imm32(v.tag()), tag);
426 }
427 
<a name="45" id="anc45"></a><span class="line-modified">428 ALWAYS_INLINE void JIT::emitGetVirtualRegister(int src, JSValueRegs dst)</span>
429 {
430     emitLoad(src, dst.tagGPR(), dst.payloadGPR());
431 }
432 
<a name="46" id="anc46"></a><span class="line-modified">433 ALWAYS_INLINE void JIT::emitPutVirtualRegister(int dst, JSValueRegs from)</span>
434 {
435     emitStore(dst, from.tagGPR(), from.payloadGPR());
436 }
437 
<a name="47" id="anc47"></a><span class="line-modified">438 inline void JIT::emitLoad(int index, RegisterID tag, RegisterID payload, RegisterID base)</span>
439 {
440     RELEASE_ASSERT(tag != payload);
441 
442     if (base == callFrameRegister) {
443         RELEASE_ASSERT(payload != base);
<a name="48" id="anc48"></a><span class="line-modified">444         emitLoadPayload(index, payload);</span>
<span class="line-modified">445         emitLoadTag(index, tag);</span>
446         return;
447     }
448 
<a name="49" id="anc49"></a><span class="line-removed">449     VirtualRegister target { index };</span>
450     if (payload == base) { // avoid stomping base
<a name="50" id="anc50"></a><span class="line-modified">451         load32(tagFor(target, base), tag);</span>
<span class="line-modified">452         load32(payloadFor(target, base), payload);</span>
453         return;
454     }
455 
<a name="51" id="anc51"></a><span class="line-modified">456     load32(payloadFor(target, base), payload);</span>
<span class="line-modified">457     load32(tagFor(target, base), tag);</span>
<span class="line-removed">458 }</span>
<span class="line-removed">459 </span>
<span class="line-removed">460 inline void JIT::emitLoad2(int index1, RegisterID tag1, RegisterID payload1, int index2, RegisterID tag2, RegisterID payload2)</span>
<span class="line-removed">461 {</span>
<span class="line-removed">462     emitLoad(index2, tag2, payload2);</span>
<span class="line-removed">463     emitLoad(index1, tag1, payload1);</span>
<span class="line-removed">464 }</span>
<span class="line-removed">465 </span>
<span class="line-removed">466 inline void JIT::emitLoadDouble(int index, FPRegisterID value)</span>
<span class="line-removed">467 {</span>
<span class="line-removed">468     if (m_codeBlock-&gt;isConstantRegisterIndex(index)) {</span>
<span class="line-removed">469         WriteBarrier&lt;Unknown&gt;&amp; inConstantPool = m_codeBlock-&gt;constantRegister(index);</span>
<span class="line-removed">470         loadDouble(TrustedImmPtr(&amp;inConstantPool), value);</span>
<span class="line-removed">471     } else</span>
<span class="line-removed">472         loadDouble(addressFor(index), value);</span>
473 }
474 
<a name="52" id="anc52"></a><span class="line-modified">475 inline void JIT::emitLoadInt32ToDouble(int index, FPRegisterID value)</span>
476 {
<a name="53" id="anc53"></a><span class="line-modified">477     if (m_codeBlock-&gt;isConstantRegisterIndex(index)) {</span>
<span class="line-modified">478         WriteBarrier&lt;Unknown&gt;&amp; inConstantPool = m_codeBlock-&gt;constantRegister(index);</span>
<span class="line-removed">479         char* bytePointer = reinterpret_cast&lt;char*&gt;(&amp;inConstantPool);</span>
<span class="line-removed">480         convertInt32ToDouble(AbsoluteAddress(bytePointer + OBJECT_OFFSETOF(JSValue, u.asBits.payload)), value);</span>
<span class="line-removed">481     } else</span>
<span class="line-removed">482         convertInt32ToDouble(payloadFor(index), value);</span>
483 }
484 
<a name="54" id="anc54"></a><span class="line-modified">485 inline void JIT::emitStore(int index, RegisterID tag, RegisterID payload, RegisterID base)</span>
486 {
<a name="55" id="anc55"></a><span class="line-modified">487     VirtualRegister target { index };</span>
<span class="line-modified">488     store32(payload, payloadFor(target, base));</span>
<span class="line-removed">489     store32(tag, tagFor(target, base));</span>
490 }
491 
<a name="56" id="anc56"></a><span class="line-modified">492 inline void JIT::emitStoreInt32(int index, RegisterID payload, bool indexIsInt32)</span>
493 {
<a name="57" id="anc57"></a><span class="line-modified">494     store32(payload, payloadFor(index));</span>
495     if (!indexIsInt32)
<a name="58" id="anc58"></a><span class="line-modified">496         store32(TrustedImm32(JSValue::Int32Tag), tagFor(index));</span>
497 }
498 
<a name="59" id="anc59"></a><span class="line-modified">499 inline void JIT::emitStoreInt32(int index, TrustedImm32 payload, bool indexIsInt32)</span>
500 {
<a name="60" id="anc60"></a><span class="line-modified">501     store32(payload, payloadFor(index));</span>
502     if (!indexIsInt32)
<a name="61" id="anc61"></a><span class="line-modified">503         store32(TrustedImm32(JSValue::Int32Tag), tagFor(index));</span>
504 }
505 
<a name="62" id="anc62"></a><span class="line-modified">506 inline void JIT::emitStoreCell(int index, RegisterID payload, bool indexIsCell)</span>
507 {
<a name="63" id="anc63"></a><span class="line-modified">508     store32(payload, payloadFor(index));</span>
509     if (!indexIsCell)
<a name="64" id="anc64"></a><span class="line-modified">510         store32(TrustedImm32(JSValue::CellTag), tagFor(index));</span>
511 }
512 
<a name="65" id="anc65"></a><span class="line-modified">513 inline void JIT::emitStoreBool(int index, RegisterID payload, bool indexIsBool)</span>
514 {
<a name="66" id="anc66"></a><span class="line-modified">515     store32(payload, payloadFor(index));</span>
516     if (!indexIsBool)
<a name="67" id="anc67"></a><span class="line-modified">517         store32(TrustedImm32(JSValue::BooleanTag), tagFor(index));</span>
518 }
519 
<a name="68" id="anc68"></a><span class="line-modified">520 inline void JIT::emitStoreDouble(int index, FPRegisterID value)</span>
521 {
<a name="69" id="anc69"></a><span class="line-modified">522     storeDouble(value, addressFor(index));</span>
523 }
524 
<a name="70" id="anc70"></a><span class="line-modified">525 inline void JIT::emitStore(int index, const JSValue constant, RegisterID base)</span>
526 {
<a name="71" id="anc71"></a><span class="line-modified">527     VirtualRegister target { index };</span>
<span class="line-modified">528     store32(Imm32(constant.payload()), payloadFor(target, base));</span>
<span class="line-removed">529     store32(Imm32(constant.tag()), tagFor(target, base));</span>
530 }
531 
<a name="72" id="anc72"></a><span class="line-modified">532 inline void JIT::emitJumpSlowCaseIfNotJSCell(int virtualRegisterIndex)</span>
533 {
<a name="73" id="anc73"></a><span class="line-modified">534     if (!m_codeBlock-&gt;isKnownNotImmediate(virtualRegisterIndex)) {</span>
<span class="line-modified">535         if (m_codeBlock-&gt;isConstantRegisterIndex(virtualRegisterIndex))</span>
536             addSlowCase(jump());
537         else
<a name="74" id="anc74"></a><span class="line-modified">538             addSlowCase(emitJumpIfNotJSCell(virtualRegisterIndex));</span>
539     }
540 }
541 
<a name="75" id="anc75"></a><span class="line-modified">542 inline void JIT::emitJumpSlowCaseIfNotJSCell(int virtualRegisterIndex, RegisterID tag)</span>
543 {
<a name="76" id="anc76"></a><span class="line-modified">544     if (!m_codeBlock-&gt;isKnownNotImmediate(virtualRegisterIndex)) {</span>
<span class="line-modified">545         if (m_codeBlock-&gt;isConstantRegisterIndex(virtualRegisterIndex))</span>
546             addSlowCase(jump());
547         else
548             addSlowCase(branchIfNotCell(tag));
549     }
550 }
551 
<a name="77" id="anc77"></a><span class="line-modified">552 ALWAYS_INLINE bool JIT::isOperandConstantInt(int src)</span>
553 {
<a name="78" id="anc78"></a><span class="line-modified">554     return m_codeBlock-&gt;isConstantRegisterIndex(src) &amp;&amp; getConstantOperand(src).isInt32();</span>
555 }
556 
<a name="79" id="anc79"></a><span class="line-modified">557 ALWAYS_INLINE bool JIT::getOperandConstantInt(int op1, int op2, int&amp; op, int32_t&amp; constant)</span>
558 {
559     if (isOperandConstantInt(op1)) {
560         constant = getConstantOperand(op1).asInt32();
561         op = op2;
562         return true;
563     }
564 
565     if (isOperandConstantInt(op2)) {
566         constant = getConstantOperand(op2).asInt32();
567         op = op1;
568         return true;
569     }
570 
571     return false;
572 }
573 
574 #else // USE(JSVALUE32_64)
575 
576 // get arg puts an arg from the SF register array into a h/w register
<a name="80" id="anc80"></a><span class="line-modified">577 ALWAYS_INLINE void JIT::emitGetVirtualRegister(int src, RegisterID dst)</span>
578 {
<a name="81" id="anc81"></a><span class="line-modified">579     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
580 
<a name="82" id="anc82"></a><span class="line-modified">581     if (m_codeBlock-&gt;isConstantRegisterIndex(src)) {</span>
582         JSValue value = m_codeBlock-&gt;getConstant(src);
583         if (!value.isNumber())
584             move(TrustedImm64(JSValue::encode(value)), dst);
585         else
586             move(Imm64(JSValue::encode(value)), dst);
587         return;
588     }
589 
590     load64(addressFor(src), dst);
591 }
592 
<a name="83" id="anc83"></a><span class="line-modified">593 ALWAYS_INLINE void JIT::emitGetVirtualRegister(int src, JSValueRegs dst)</span>
594 {
595     emitGetVirtualRegister(src, dst.payloadGPR());
596 }
597 
<a name="84" id="anc84"></a><span class="line-modified">598 ALWAYS_INLINE void JIT::emitGetVirtualRegister(VirtualRegister src, RegisterID dst)</span>
<span class="line-removed">599 {</span>
<span class="line-removed">600     emitGetVirtualRegister(src.offset(), dst);</span>
<span class="line-removed">601 }</span>
<span class="line-removed">602 </span>
<span class="line-removed">603 ALWAYS_INLINE void JIT::emitGetVirtualRegisters(int src1, RegisterID dst1, int src2, RegisterID dst2)</span>
604 {
605     emitGetVirtualRegister(src1, dst1);
606     emitGetVirtualRegister(src2, dst2);
607 }
608 
<a name="85" id="anc85"></a><span class="line-modified">609 ALWAYS_INLINE void JIT::emitGetVirtualRegisters(VirtualRegister src1, RegisterID dst1, VirtualRegister src2, RegisterID dst2)</span>
<span class="line-removed">610 {</span>
<span class="line-removed">611     emitGetVirtualRegisters(src1.offset(), dst1, src2.offset(), dst2);</span>
<span class="line-removed">612 }</span>
<span class="line-removed">613 </span>
<span class="line-removed">614 ALWAYS_INLINE bool JIT::isOperandConstantInt(int src)</span>
615 {
<a name="86" id="anc86"></a><span class="line-modified">616     return m_codeBlock-&gt;isConstantRegisterIndex(src) &amp;&amp; getConstantOperand(src).isInt32();</span>
617 }
618 
<a name="87" id="anc87"></a><span class="line-modified">619 ALWAYS_INLINE void JIT::emitPutVirtualRegister(int dst, RegisterID from)</span>
620 {
621     store64(from, addressFor(dst));
622 }
623 
<a name="88" id="anc88"></a><span class="line-modified">624 ALWAYS_INLINE void JIT::emitPutVirtualRegister(int dst, JSValueRegs from)</span>
625 {
626     emitPutVirtualRegister(dst, from.payloadGPR());
627 }
628 
<a name="89" id="anc89"></a><span class="line-removed">629 ALWAYS_INLINE void JIT::emitPutVirtualRegister(VirtualRegister dst, RegisterID from)</span>
<span class="line-removed">630 {</span>
<span class="line-removed">631     emitPutVirtualRegister(dst.offset(), from);</span>
<span class="line-removed">632 }</span>
<span class="line-removed">633 </span>
634 ALWAYS_INLINE JIT::Jump JIT::emitJumpIfBothJSCells(RegisterID reg1, RegisterID reg2, RegisterID scratch)
635 {
636     move(reg1, scratch);
637     or64(reg2, scratch);
638     return branchIfCell(scratch);
639 }
640 
641 ALWAYS_INLINE void JIT::emitJumpSlowCaseIfJSCell(RegisterID reg)
642 {
643     addSlowCase(branchIfCell(reg));
644 }
645 
646 ALWAYS_INLINE void JIT::emitJumpSlowCaseIfNotJSCell(RegisterID reg)
647 {
648     addSlowCase(branchIfNotCell(reg));
649 }
650 
<a name="90" id="anc90"></a><span class="line-modified">651 ALWAYS_INLINE void JIT::emitJumpSlowCaseIfNotJSCell(RegisterID reg, int vReg)</span>
652 {
653     if (!m_codeBlock-&gt;isKnownNotImmediate(vReg))
654         emitJumpSlowCaseIfNotJSCell(reg);
655 }
656 
<a name="91" id="anc91"></a><span class="line-removed">657 inline void JIT::emitLoadDouble(int index, FPRegisterID value)</span>
<span class="line-removed">658 {</span>
<span class="line-removed">659     if (m_codeBlock-&gt;isConstantRegisterIndex(index)) {</span>
<span class="line-removed">660         WriteBarrier&lt;Unknown&gt;&amp; inConstantPool = m_codeBlock-&gt;constantRegister(index);</span>
<span class="line-removed">661         loadDouble(TrustedImmPtr(&amp;inConstantPool), value);</span>
<span class="line-removed">662     } else</span>
<span class="line-removed">663         loadDouble(addressFor(index), value);</span>
<span class="line-removed">664 }</span>
<span class="line-removed">665 </span>
<span class="line-removed">666 inline void JIT::emitLoadInt32ToDouble(int index, FPRegisterID value)</span>
<span class="line-removed">667 {</span>
<span class="line-removed">668     if (m_codeBlock-&gt;isConstantRegisterIndex(index)) {</span>
<span class="line-removed">669         ASSERT(isOperandConstantInt(index));</span>
<span class="line-removed">670         convertInt32ToDouble(Imm32(getConstantOperand(index).asInt32()), value);</span>
<span class="line-removed">671     } else</span>
<span class="line-removed">672         convertInt32ToDouble(addressFor(index), value);</span>
<span class="line-removed">673 }</span>
<span class="line-removed">674 </span>
675 ALWAYS_INLINE JIT::PatchableJump JIT::emitPatchableJumpIfNotInt(RegisterID reg)
676 {
<a name="92" id="anc92"></a><span class="line-modified">677     return patchableBranch64(Below, reg, tagTypeNumberRegister);</span>
678 }
679 
680 ALWAYS_INLINE JIT::Jump JIT::emitJumpIfNotInt(RegisterID reg1, RegisterID reg2, RegisterID scratch)
681 {
682     move(reg1, scratch);
683     and64(reg2, scratch);
684     return branchIfNotInt32(scratch);
685 }
686 
687 ALWAYS_INLINE void JIT::emitJumpSlowCaseIfNotInt(RegisterID reg)
688 {
689     addSlowCase(branchIfNotInt32(reg));
690 }
691 
692 ALWAYS_INLINE void JIT::emitJumpSlowCaseIfNotInt(RegisterID reg1, RegisterID reg2, RegisterID scratch)
693 {
694     addSlowCase(emitJumpIfNotInt(reg1, reg2, scratch));
695 }
696 
697 ALWAYS_INLINE void JIT::emitJumpSlowCaseIfNotNumber(RegisterID reg)
698 {
699     addSlowCase(branchIfNotNumber(reg));
700 }
701 
702 #endif // USE(JSVALUE32_64)
703 
704 ALWAYS_INLINE int JIT::jumpTarget(const Instruction* instruction, int target)
705 {
706     if (target)
707         return target;
708     return m_codeBlock-&gt;outOfLineJumpOffset(instruction);
709 }
710 
711 ALWAYS_INLINE GetPutInfo JIT::copiedGetPutInfo(OpPutToScope bytecode)
712 {
713     unsigned key = bytecode.m_metadataID + 1; // HashMap doesn&#39;t like 0 as a key
714     auto iterator = m_copiedGetPutInfos.find(key);
715     if (iterator != m_copiedGetPutInfos.end())
716         return GetPutInfo(iterator-&gt;value);
717     GetPutInfo getPutInfo = bytecode.metadata(m_codeBlock).m_getPutInfo;
718     m_copiedGetPutInfos.add(key, getPutInfo.operand());
719     return getPutInfo;
720 }
721 
722 template&lt;typename BinaryOp&gt;
<a name="93" id="anc93"></a><span class="line-modified">723 ALWAYS_INLINE ArithProfile JIT::copiedArithProfile(BinaryOp bytecode)</span>
724 {
<a name="94" id="anc94"></a><span class="line-modified">725     uint64_t key = static_cast&lt;uint64_t&gt;(BinaryOp::opcodeID) &lt;&lt; 32 | static_cast&lt;uint64_t&gt;(bytecode.m_metadataID);</span>
726     auto iterator = m_copiedArithProfiles.find(key);
727     if (iterator != m_copiedArithProfiles.end())
728         return iterator-&gt;value;
<a name="95" id="anc95"></a><span class="line-modified">729     ArithProfile arithProfile = bytecode.metadata(m_codeBlock).m_arithProfile;</span>
730     m_copiedArithProfiles.add(key, arithProfile);
731     return arithProfile;
732 }
733 
734 } // namespace JSC
735 
736 #endif // ENABLE(JIT)
<a name="96" id="anc96"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="96" type="hidden" />
</body>
</html>