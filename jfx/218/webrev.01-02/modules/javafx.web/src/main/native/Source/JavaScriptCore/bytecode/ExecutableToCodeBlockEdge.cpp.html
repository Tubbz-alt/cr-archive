<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/JavaScriptCore/bytecode/ExecutableToCodeBlockEdge.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2018 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;ExecutableToCodeBlockEdge.h&quot;
 28 
 29 #include &quot;CodeBlock.h&quot;
 30 #include &quot;IsoCellSetInlines.h&quot;
 31 #include &quot;JSObjectInlines.h&quot;
 32 #include &quot;StructureInlines.h&quot;
 33 
 34 namespace JSC {
 35 
 36 const ClassInfo ExecutableToCodeBlockEdge::s_info = { &quot;ExecutableToCodeBlockEdge&quot;, nullptr, nullptr, nullptr, CREATE_METHOD_TABLE(ExecutableToCodeBlockEdge) };
 37 
 38 Structure* ExecutableToCodeBlockEdge::createStructure(VM&amp; vm, JSGlobalObject* globalObject, JSValue prototype)
 39 {
 40     return Structure::create(vm, globalObject, prototype, TypeInfo(CellType, StructureFlags), info());
 41 }
 42 
 43 ExecutableToCodeBlockEdge* ExecutableToCodeBlockEdge::create(VM&amp; vm, CodeBlock* codeBlock)
 44 {
 45     ExecutableToCodeBlockEdge* result = new (NotNull, allocateCell&lt;ExecutableToCodeBlockEdge&gt;(vm.heap)) ExecutableToCodeBlockEdge(vm, codeBlock);
 46     result-&gt;finishCreation(vm);
 47     return result;
 48 }
 49 
 50 void ExecutableToCodeBlockEdge::finishCreation(VM&amp; vm)
 51 {
 52     Base::finishCreation(vm);
 53     ASSERT(!isActive());
 54 }
 55 
 56 void ExecutableToCodeBlockEdge::visitChildren(JSCell* cell, SlotVisitor&amp; visitor)
 57 {
 58     VM&amp; vm = visitor.vm();
 59     ExecutableToCodeBlockEdge* edge = jsCast&lt;ExecutableToCodeBlockEdge*&gt;(cell);
 60     ASSERT_GC_OBJECT_INHERITS(cell, info());
 61     Base::visitChildren(cell, visitor);
 62 
 63     CodeBlock* codeBlock = edge-&gt;m_codeBlock.get();
 64 
 65     // It&#39;s possible for someone to hold a pointer to the edge after the edge has cleared its weak
 66     // reference to the codeBlock. In a conservative GC like ours, that could happen at random for
 67     // no good reason and it&#39;s Totally OK (TM). See finalizeUnconditionally() for where we clear
 68     // m_codeBlock.
 69     if (!codeBlock)
 70         return;
 71 
 72     if (!edge-&gt;isActive()) {
 73         visitor.appendUnbarriered(codeBlock);
 74         return;
 75     }
 76 
 77     ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
 78 
 79     if (codeBlock-&gt;shouldVisitStrongly(locker))
 80         visitor.appendUnbarriered(codeBlock);
 81 
 82     if (!vm.heap.isMarked(codeBlock))
 83         vm.executableToCodeBlockEdgesWithFinalizers.add(edge);
 84 
 85     if (JITCode::isOptimizingJIT(codeBlock-&gt;jitType())) {
 86         // If we jettison ourselves we&#39;ll install our alternative, so make sure that it
 87         // survives GC even if we don&#39;t.
 88         visitor.append(codeBlock-&gt;m_alternative);
 89     }
 90 
 91     // NOTE: There are two sides to this constraint, with different requirements for correctness.
 92     // Because everything is ultimately protected with weak references and jettisoning, it&#39;s
 93     // always &quot;OK&quot; to claim that something is dead prematurely and it&#39;s &quot;OK&quot; to keep things alive.
 94     // But both choices could lead to bad perf - either recomp cycles or leaks.
 95     //
 96     // Determining CodeBlock liveness: This part is the most consequential. We want to keep the
 97     // output constraint active so long as we think that we may yet prove that the CodeBlock is
 98     // live but we haven&#39;t done it yet.
 99     //
100     // Marking Structures if profitable: It&#39;s important that we do a pass of this. Logically, this
101     // seems like it is a constraint of CodeBlock. But we have always first run this as a result
102     // of the edge being marked even before we determine the liveness of the CodeBlock. This
103     // allows a CodeBlock to mark itself by first proving that all of the Structures it weakly
104     // depends on could be strongly marked. (This part is also called propagateTransitions.)
105     //
106     // As a weird caveat, we only fixpoint the constraints so long as the CodeBlock is not live.
107     // This means that we may overlook structure marking opportunities created by other marking
108     // that happens after the CodeBlock is marked. This was an accidental policy decision from a
109     // long time ago, but it is probably OK, since it&#39;s only worthwhile to keep fixpointing the
110     // structure marking if we still have unmarked structures after the first round. We almost
111     // never will because we will mark-if-profitable based on the owning global object being
112     // already marked. We mark it just in case that hadn&#39;t happened yet. And if the CodeBlock is
113     // not yet marked because it weakly depends on a structure that we did not yet mark, then we
114     // will keep fixpointing until the end.
115     visitor.appendUnbarriered(codeBlock-&gt;globalObject());
116     vm.executableToCodeBlockEdgesWithConstraints.add(edge);
117     edge-&gt;runConstraint(locker, vm, visitor);
118 }
119 
120 void ExecutableToCodeBlockEdge::visitOutputConstraints(JSCell* cell, SlotVisitor&amp; visitor)
121 {
122     VM&amp; vm = visitor.vm();
123     ExecutableToCodeBlockEdge* edge = jsCast&lt;ExecutableToCodeBlockEdge*&gt;(cell);
124 
125     edge-&gt;runConstraint(NoLockingNecessary, vm, visitor);
126 }
127 
128 void ExecutableToCodeBlockEdge::finalizeUnconditionally(VM&amp; vm)
129 {
130     CodeBlock* codeBlock = m_codeBlock.get();
131 
132     if (!vm.heap.isMarked(codeBlock)) {
133         if (codeBlock-&gt;shouldJettisonDueToWeakReference(vm))
134             codeBlock-&gt;jettison(Profiler::JettisonDueToWeakReference);
135         else
136             codeBlock-&gt;jettison(Profiler::JettisonDueToOldAge);
137         m_codeBlock.clear();
138     }
139 
140     vm.executableToCodeBlockEdgesWithFinalizers.remove(this);
141     vm.executableToCodeBlockEdgesWithConstraints.remove(this);
142 }
143 
144 inline void ExecutableToCodeBlockEdge::activate()
145 {
146     setPerCellBit(true);
147 }
148 
149 inline void ExecutableToCodeBlockEdge::deactivate()
150 {
151     setPerCellBit(false);
152 }
153 
154 inline bool ExecutableToCodeBlockEdge::isActive() const
155 {
156     return perCellBit();
157 }
158 
159 CodeBlock* ExecutableToCodeBlockEdge::deactivateAndUnwrap(ExecutableToCodeBlockEdge* edge)
160 {
161     if (!edge)
162         return nullptr;
163     edge-&gt;deactivate();
164     return edge-&gt;codeBlock();
165 }
166 
167 ExecutableToCodeBlockEdge* ExecutableToCodeBlockEdge::wrap(CodeBlock* codeBlock)
168 {
169     if (!codeBlock)
170         return nullptr;
171     return codeBlock-&gt;ownerEdge();
172 }
173 
174 ExecutableToCodeBlockEdge* ExecutableToCodeBlockEdge::wrapAndActivate(CodeBlock* codeBlock)
175 {
176     if (!codeBlock)
177         return nullptr;
178     ExecutableToCodeBlockEdge* result = codeBlock-&gt;ownerEdge();
179     result-&gt;activate();
180     return result;
181 }
182 
183 ExecutableToCodeBlockEdge::ExecutableToCodeBlockEdge(VM&amp; vm, CodeBlock* codeBlock)
184     : Base(vm, vm.executableToCodeBlockEdgeStructure.get())
185     , m_codeBlock(vm, this, codeBlock)
186 {
187 }
188 
189 void ExecutableToCodeBlockEdge::runConstraint(const ConcurrentJSLocker&amp; locker, VM&amp; vm, SlotVisitor&amp; visitor)
190 {
191     CodeBlock* codeBlock = m_codeBlock.get();
192 
193     codeBlock-&gt;propagateTransitions(locker, visitor);
194     codeBlock-&gt;determineLiveness(locker, visitor);
195 
196     if (vm.heap.isMarked(codeBlock))
197         vm.executableToCodeBlockEdgesWithConstraints.remove(this);
198 }
199 
200 } // namespace JSC
201 
    </pre>
  </body>
</html>