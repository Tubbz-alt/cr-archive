<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/WTF/wtf/FastMalloc.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2005, 2007, Google Inc. All rights reserved.
  3  * Copyright (C) 2005-2018 Apple Inc. All rights reserved.
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &lt;wtf/FastMalloc.h&gt;
 28 
 29 #include &lt;limits&gt;
 30 #include &lt;string.h&gt;
 31 #include &lt;wtf/CheckedArithmetic.h&gt;
 32 #include &lt;wtf/DataLog.h&gt;
 33 
 34 #if OS(WINDOWS)
 35 #include &lt;windows.h&gt;
 36 #else
 37 #include &lt;pthread.h&gt;
 38 #if HAVE(RESOURCE_H)
 39 #include &lt;sys/resource.h&gt;
 40 #endif // HAVE(RESOURCE_H)
 41 #endif
 42 
 43 #if OS(DARWIN)
 44 #include &lt;mach/mach_init.h&gt;
 45 #include &lt;malloc/malloc.h&gt;
 46 #endif
 47 
 48 #if ENABLE(MALLOC_HEAP_BREAKDOWN)
 49 #include &lt;wtf/Atomics.h&gt;
 50 #include &lt;wtf/HashMap.h&gt;
 51 #include &lt;wtf/Lock.h&gt;
 52 #include &lt;wtf/NeverDestroyed.h&gt;
 53 #include &lt;wtf/SetForScope.h&gt;
 54 #include &lt;wtf/StackShot.h&gt;
 55 
 56 #if PLATFORM(COCOA)
 57 #include &lt;notify.h&gt;
 58 #endif
 59 
 60 #endif
 61 
 62 namespace WTF {
 63 
 64 #if !defined(NDEBUG)
 65 namespace {
 66 // We do not use std::numeric_limits&lt;size_t&gt;::max() here due to the edge case in VC++.
 67 // https://bugs.webkit.org/show_bug.cgi?id=173720
 68 static size_t maxSingleAllocationSize = SIZE_MAX;
 69 };
 70 
 71 void fastSetMaxSingleAllocationSize(size_t size)
 72 {
 73     maxSingleAllocationSize = size;
 74 }
 75 
 76 #define ASSERT_IS_WITHIN_LIMIT(size) do { \
 77         size_t size__ = (size); \
 78         ASSERT_WITH_MESSAGE((size__) &lt;= maxSingleAllocationSize, &quot;Requested size (%zu) exceeds max single allocation size set for testing (%zu)&quot;, (size__), maxSingleAllocationSize); \
 79     } while (false)
 80 
 81 #define FAIL_IF_EXCEEDS_LIMIT(size) do { \
 82         if (UNLIKELY((size) &gt; maxSingleAllocationSize)) \
 83             return nullptr; \
 84     } while (false)
 85 
 86 #else // !defined(NDEBUG)
 87 
 88 #define ASSERT_IS_WITHIN_LIMIT(size)
 89 #define FAIL_IF_EXCEEDS_LIMIT(size)
 90 
 91 #endif // !defined(NDEBUG)
 92 
 93 void* fastZeroedMalloc(size_t n)
 94 {
 95     void* result = fastMalloc(n);
 96     memset(result, 0, n);
 97     return result;
 98 }
 99 
100 char* fastStrDup(const char* src)
101 {
102     size_t len = strlen(src) + 1;
103     char* dup = static_cast&lt;char*&gt;(fastMalloc(len));
104     memcpy(dup, src, len);
105     return dup;
106 }
107 
108 TryMallocReturnValue tryFastZeroedMalloc(size_t n)
109 {
110     void* result;
111     if (!tryFastMalloc(n).getValue(result))
112         return 0;
113     memset(result, 0, n);
114     return result;
115 }
116 
117 } // namespace WTF
118 
119 #if defined(USE_SYSTEM_MALLOC) &amp;&amp; USE_SYSTEM_MALLOC
120 
121 #include &lt;wtf/OSAllocator.h&gt;
122 
123 #if OS(WINDOWS)
124 #include &lt;malloc.h&gt;
125 #endif
126 
127 namespace WTF {
128 
129 bool isFastMallocEnabled()
130 {
131     return false;
132 }
133 
134 size_t fastMallocGoodSize(size_t bytes)
135 {
136 #if OS(DARWIN)
137     return malloc_good_size(bytes);
138 #else
139     return bytes;
140 #endif
141 }
142 
143 #if OS(WINDOWS)
144 
145 void* fastAlignedMalloc(size_t alignment, size_t size)
146 {
147     ASSERT_IS_WITHIN_LIMIT(size);
148     void* p = _aligned_malloc(size, alignment);
149     if (UNLIKELY(!p))
150         CRASH();
151     return p;
152 }
153 
154 void* tryFastAlignedMalloc(size_t alignment, size_t size)
155 {
156     FAIL_IF_EXCEEDS_LIMIT(size);
157     return _aligned_malloc(size, alignment);
158 }
159 
160 void fastAlignedFree(void* p)
161 {
162     _aligned_free(p);
163 }
164 
165 #else
166 
167 void* fastAlignedMalloc(size_t alignment, size_t size)
168 {
169     ASSERT_IS_WITHIN_LIMIT(size);
170     void* p = nullptr;
171     posix_memalign(&amp;p, alignment, size);
172     if (UNLIKELY(!p))
173         CRASH();
174     return p;
175 }
176 
177 void* tryFastAlignedMalloc(size_t alignment, size_t size)
178 {
179     FAIL_IF_EXCEEDS_LIMIT(size);
180     void* p = nullptr;
181     posix_memalign(&amp;p, alignment, size);
182     return p;
183 }
184 
185 void fastAlignedFree(void* p)
186 {
187     free(p);
188 }
189 
190 #endif // OS(WINDOWS)
191 
192 TryMallocReturnValue tryFastMalloc(size_t n)
193 {
194     FAIL_IF_EXCEEDS_LIMIT(n);
195     return malloc(n);
196 }
197 
198 void* fastMalloc(size_t n)
199 {
200     ASSERT_IS_WITHIN_LIMIT(n);
201     void* result = malloc(n);
202     if (!result)
203         CRASH();
204 
205     return result;
206 }
207 
208 TryMallocReturnValue tryFastCalloc(size_t n_elements, size_t element_size)
209 {
210     FAIL_IF_EXCEEDS_LIMIT(n_elements * element_size);
211     return calloc(n_elements, element_size);
212 }
213 
214 void* fastCalloc(size_t n_elements, size_t element_size)
215 {
216     ASSERT_IS_WITHIN_LIMIT(n_elements * element_size);
217     void* result = calloc(n_elements, element_size);
218     if (!result)
219         CRASH();
220 
221     return result;
222 }
223 
224 void fastFree(void* p)
225 {
226     free(p);
227 }
228 
229 void* fastRealloc(void* p, size_t n)
230 {
231     ASSERT_IS_WITHIN_LIMIT(n);
232     void* result = realloc(p, n);
233     if (!result)
234         CRASH();
235     return result;
236 }
237 
238 TryMallocReturnValue tryFastRealloc(void* p, size_t n)
239 {
240     FAIL_IF_EXCEEDS_LIMIT(n);
241     return realloc(p, n);
242 }
243 
244 void releaseFastMallocFreeMemory() { }
245 void releaseFastMallocFreeMemoryForThisThread() { }
246 
247 FastMallocStatistics fastMallocStatistics()
248 {
249     FastMallocStatistics statistics = { 0, 0, 0 };
250     return statistics;
251 }
252 
253 size_t fastMallocSize(const void* p)
254 {
255 #if OS(DARWIN)
256     return malloc_size(p);
257 #elif OS(WINDOWS)
258     return _msize(const_cast&lt;void*&gt;(p));
259 #else
260     UNUSED_PARAM(p);
261     return 1;
262 #endif
263 }
264 
265 void fastCommitAlignedMemory(void* ptr, size_t size)
266 {
267     OSAllocator::commit(ptr, size, true, false);
268 }
269 
270 void fastDecommitAlignedMemory(void* ptr, size_t size)
271 {
272     OSAllocator::decommit(ptr, size);
273 }
274 
275 void fastEnableMiniMode() { }
276 
277 void fastMallocDumpMallocStats() { }
278 
279 } // namespace WTF
280 
281 #else // defined(USE_SYSTEM_MALLOC) &amp;&amp; USE_SYSTEM_MALLOC
282 
283 #include &lt;bmalloc/bmalloc.h&gt;
284 
285 namespace WTF {
286 
287 #define TRACK_MALLOC_CALLSTACK 0
288 
289 #if ENABLE(MALLOC_HEAP_BREAKDOWN) &amp;&amp; TRACK_MALLOC_CALLSTACK
290 
291 static ThreadSpecificKey avoidRecordingCountKey { InvalidThreadSpecificKey };
292 class AvoidRecordingScope {
293 public:
294     AvoidRecordingScope();
295     ~AvoidRecordingScope();
296 
297     static uintptr_t avoidRecordingCount()
298     {
299         return bitwise_cast&lt;uintptr_t&gt;(threadSpecificGet(avoidRecordingCountKey));
300     }
301 };
302 
303 AvoidRecordingScope::AvoidRecordingScope()
304 {
305     static std::once_flag onceKey;
306     std::call_once(onceKey, [] {
307         // The value stored in TLS is initially 0.
308         threadSpecificKeyCreate(&amp;avoidRecordingCountKey, [](void*) { });
309     });
310     threadSpecificSet(avoidRecordingCountKey, bitwise_cast&lt;void*&gt;(avoidRecordingCount() + 1));
311 }
312 
313 AvoidRecordingScope::~AvoidRecordingScope()
314 {
315     threadSpecificSet(avoidRecordingCountKey, bitwise_cast&lt;void*&gt;(avoidRecordingCount() - 1));
316 }
317 
318 class MallocCallTracker {
319 public:
320     MallocCallTracker();
321 
322     void recordMalloc(void*, size_t);
323     void recordRealloc(void* oldAddress, void* newAddress, size_t);
324     void recordFree(void*);
325 
326     void dumpStats();
327 
328     static MallocCallTracker&amp; singleton();
329 
330 private:
331     struct MallocSiteData {
332         StackShot stack;
333         size_t size;
334 
335         MallocSiteData(size_t stackSize, size_t allocationSize)
336             : stack(stackSize)
337             , size(allocationSize)
338         {
339         }
340     };
341 
342     HashMap&lt;void*, std::unique_ptr&lt;MallocSiteData&gt;&gt; m_addressMallocSiteData;
343     Lock m_mutex;
344 };
345 
346 MallocCallTracker&amp; MallocCallTracker::singleton()
347 {
348     AvoidRecordingScope avoidRecording;
349     static NeverDestroyed&lt;MallocCallTracker&gt; tracker;
350     return tracker;
351 }
352 
353 
354 MallocCallTracker::MallocCallTracker()
355 {
356     int token;
357     notify_register_dispatch(&quot;com.apple.WebKit.dumpUntrackedMallocs&quot;, &amp;token, dispatch_get_main_queue(), ^(int) {
358         MallocCallTracker::singleton().dumpStats();
359     });
360 }
361 
362 void MallocCallTracker::recordMalloc(void* address, size_t allocationSize)
363 {
364     AvoidRecordingScope avoidRecording;
365 
366     // Intentionally using std::make_unique not to use FastMalloc for data structure tracking FastMalloc.
367     const size_t stackSize = 10;
368     auto siteData = std::make_unique&lt;MallocSiteData&gt;(stackSize, allocationSize);
369 
370     auto locker = holdLock(m_mutex);
371     auto addResult = m_addressMallocSiteData.add(address, WTFMove(siteData));
372     UNUSED_PARAM(addResult);
373 }
374 
375 void MallocCallTracker::recordRealloc(void* oldAddress, void* newAddress, size_t newSize)
376 {
377     AvoidRecordingScope avoidRecording;
378 
379     auto locker = holdLock(m_mutex);
380 
381     auto it = m_addressMallocSiteData.find(oldAddress);
382     if (it == m_addressMallocSiteData.end()) {
383         ASSERT_NOT_REACHED();
384         return;
385     }
386 
387     it-&gt;value-&gt;size = newSize;
388     if (oldAddress != newAddress) {
389         auto value = WTFMove(it-&gt;value);
390         m_addressMallocSiteData.remove(it);
391         auto addResult = m_addressMallocSiteData.add(newAddress, WTFMove(value));
392         ASSERT_UNUSED(addResult, addResult.isNewEntry);
393     }
394 }
395 
396 void MallocCallTracker::recordFree(void* address)
397 {
398     AvoidRecordingScope avoidRecording;
399 
400     auto locker = holdLock(m_mutex);
401     bool removed = m_addressMallocSiteData.remove(address);
402     UNUSED_PARAM(removed);
403 }
404 
405 void MallocCallTracker::dumpStats()
406 {
407     AvoidRecordingScope avoidRecording;
408 
409     {
410         auto locker = holdLock(m_mutex);
411 
412         // Build a hash of stack to address vector
413         struct MallocSiteTotals {
414             Vector&lt;MallocSiteData*&gt; siteData;
415             size_t count { 0 };
416             size_t totalSize { 0 };
417         };
418 
419         size_t totalUntrackedSize = 0;
420         size_t totalUntrackedCount = 0;
421 
422         HashMap&lt;unsigned, std::unique_ptr&lt;MallocSiteTotals&gt;&gt; callSiteToMallocData;
423         for (const auto&amp; it : m_addressMallocSiteData) {
424             auto result = callSiteToMallocData.ensure(it.value-&gt;stack.hash(), [] () {
425                 // Intentionally using std::make_unique not to use FastMalloc for data structure tracking FastMalloc.
426                 return std::make_unique&lt;MallocSiteTotals&gt;();
427             });
428             auto&amp; siteTotal = result.iterator-&gt;value;
429             siteTotal-&gt;siteData.append(it.value.get());
430             ++siteTotal-&gt;count;
431             siteTotal-&gt;totalSize += it.value-&gt;size;
432             totalUntrackedSize += it.value-&gt;size;
433             ++totalUntrackedCount;
434         }
435 
436         Vector&lt;unsigned&gt; stackHashes;
437         auto stackKeys = callSiteToMallocData.keys();
438         for (auto key : stackKeys)
439             stackHashes.append(key);
440 
441         // Sort by reverse total size.
442         std::sort(stackHashes.begin(), stackHashes.end(), [&amp;] (unsigned a, unsigned b) {
443             const auto&amp; aSiteTotals = callSiteToMallocData.get(a);
444             const auto&amp; bSiteTotals = callSiteToMallocData.get(b);
445 
446             return aSiteTotals-&gt;totalSize &gt; bSiteTotals-&gt;totalSize;
447         });
448 
449         WTFLogAlways(&quot;Total untracked bytes: %lu (%lu allocations)\n&quot;, totalUntrackedSize, totalUntrackedCount);
450 
451         const size_t numStacksToDump = 100;
452         for (size_t i = 0; i &lt; std::min(numStacksToDump, stackHashes.size()); ++i) {
453             const auto&amp; mallocDataForStack = callSiteToMallocData.get(stackHashes[i]);
454 
455             WTFLogAlways(&quot;Total allocation size: %lu (%lu allocations)\n&quot;, mallocDataForStack-&gt;totalSize, mallocDataForStack-&gt;count);
456             // FIXME: Add a way to remove some entries in StackShot in a programable way.
457             // https://bugs.webkit.org/show_bug.cgi?id=205701
458             const size_t framesToSkip = 6;
459             WTFPrintBacktrace(mallocDataForStack-&gt;siteData[0]-&gt;stack.array() + framesToSkip, mallocDataForStack-&gt;siteData[0]-&gt;stack.size() - framesToSkip);
460             WTFLogAlways(&quot;\n&quot;);
461         }
462     }
463 }
464 void fastMallocDumpMallocStats()
465 {
466     MallocCallTracker::singleton().dumpStats();
467 }
468 #else
469 void fastMallocDumpMallocStats()
470 {
471 }
472 #endif
473 
474 
475 bool isFastMallocEnabled()
476 {
477     return bmalloc::api::isEnabled();
478 }
479 
480 void* fastMalloc(size_t size)
481 {
482     ASSERT_IS_WITHIN_LIMIT(size);
483     void* result = bmalloc::api::malloc(size);
484 #if ENABLE(MALLOC_HEAP_BREAKDOWN) &amp;&amp; TRACK_MALLOC_CALLSTACK
485     if (!AvoidRecordingScope::avoidRecordingCount())
486         MallocCallTracker::singleton().recordMalloc(result, size);
487 #endif
488     return result;
489 }
490 
491 void* fastCalloc(size_t numElements, size_t elementSize)
492 {
493     ASSERT_IS_WITHIN_LIMIT(numElements * elementSize);
494     Checked&lt;size_t&gt; checkedSize = elementSize;
495     checkedSize *= numElements;
496     void* result = fastZeroedMalloc(checkedSize.unsafeGet());
497     if (!result)
498         CRASH();
499     return result;
500 }
501 
502 void* fastRealloc(void* object, size_t size)
503 {
504     ASSERT_IS_WITHIN_LIMIT(size);
505     void* result = bmalloc::api::realloc(object, size);
506 #if ENABLE(MALLOC_HEAP_BREAKDOWN) &amp;&amp; TRACK_MALLOC_CALLSTACK
507     if (!AvoidRecordingScope::avoidRecordingCount())
508         MallocCallTracker::singleton().recordRealloc(object, result, size);
509 #endif
510     return result;
511 }
512 
513 void fastFree(void* object)
514 {
515     bmalloc::api::free(object);
516 #if ENABLE(MALLOC_HEAP_BREAKDOWN) &amp;&amp; TRACK_MALLOC_CALLSTACK
517     if (!AvoidRecordingScope::avoidRecordingCount())
518         MallocCallTracker::singleton().recordFree(object);
519 #endif
520 }
521 
522 size_t fastMallocSize(const void*)
523 {
524     // FIXME: This is incorrect; best fix is probably to remove this function.
525     // Caller currently are all using this for assertion, not to actually check
526     // the size of the allocation, so maybe we can come up with something for that.
527     return 1;
528 }
529 
530 size_t fastMallocGoodSize(size_t size)
531 {
532     return size;
533 }
534 
535 void* fastAlignedMalloc(size_t alignment, size_t size)
536 {
537     ASSERT_IS_WITHIN_LIMIT(size);
538     void* result = bmalloc::api::memalign(alignment, size);
539 #if ENABLE(MALLOC_HEAP_BREAKDOWN) &amp;&amp; TRACK_MALLOC_CALLSTACK
540     if (!AvoidRecordingScope::avoidRecordingCount())
541         MallocCallTracker::singleton().recordMalloc(result, size);
542 #endif
543     return result;
544 }
545 
546 void* tryFastAlignedMalloc(size_t alignment, size_t size)
547 {
548     FAIL_IF_EXCEEDS_LIMIT(size);
549     void* result = bmalloc::api::tryMemalign(alignment, size);
550 #if ENABLE(MALLOC_HEAP_BREAKDOWN) &amp;&amp; TRACK_MALLOC_CALLSTACK
551     if (!AvoidRecordingScope::avoidRecordingCount())
552         MallocCallTracker::singleton().recordMalloc(result, size);
553 #endif
554     return result;
555 }
556 
557 void fastAlignedFree(void* p)
558 {
559     bmalloc::api::free(p);
560 }
561 
562 TryMallocReturnValue tryFastMalloc(size_t size)
563 {
564     FAIL_IF_EXCEEDS_LIMIT(size);
565     return bmalloc::api::tryMalloc(size);
566 }
567 
568 TryMallocReturnValue tryFastCalloc(size_t numElements, size_t elementSize)
569 {
570     FAIL_IF_EXCEEDS_LIMIT(numElements * elementSize);
571     Checked&lt;size_t, RecordOverflow&gt; checkedSize = elementSize;
572     checkedSize *= numElements;
573     if (checkedSize.hasOverflowed())
574         return nullptr;
575     return tryFastZeroedMalloc(checkedSize.unsafeGet());
576 }
577 
578 TryMallocReturnValue tryFastRealloc(void* object, size_t newSize)
579 {
580     FAIL_IF_EXCEEDS_LIMIT(newSize);
581     return bmalloc::api::tryRealloc(object, newSize);
582 }
583 
584 void releaseFastMallocFreeMemoryForThisThread()
585 {
586     bmalloc::api::scavengeThisThread();
587 }
588 
589 void releaseFastMallocFreeMemory()
590 {
591     bmalloc::api::scavenge();
592 }
593 
594 FastMallocStatistics fastMallocStatistics()
595 {
596 
597     // FIXME: Can bmalloc itself report the stats instead of relying on the OS?
598     FastMallocStatistics statistics;
599     statistics.freeListBytes = 0;
600     statistics.reservedVMBytes = 0;
601 
602 #if OS(WINDOWS)
603     PROCESS_MEMORY_COUNTERS resourceUsage;
604     GetProcessMemoryInfo(GetCurrentProcess(), &amp;resourceUsage, sizeof(resourceUsage));
605     statistics.committedVMBytes = resourceUsage.PeakWorkingSetSize;
606 #elif HAVE(RESOURCE_H)
607     struct rusage resourceUsage;
608     getrusage(RUSAGE_SELF, &amp;resourceUsage);
609 
610 #if OS(DARWIN)
611     statistics.committedVMBytes = resourceUsage.ru_maxrss;
612 #else
613     statistics.committedVMBytes = resourceUsage.ru_maxrss * 1024;
614 #endif // OS(DARWIN)
615 
616 #endif // OS(WINDOWS)
617     return statistics;
618 }
619 
620 void fastCommitAlignedMemory(void* ptr, size_t size)
621 {
622     bmalloc::api::commitAlignedPhysical(ptr, size);
623 }
624 
625 void fastDecommitAlignedMemory(void* ptr, size_t size)
626 {
627     bmalloc::api::decommitAlignedPhysical(ptr, size);
628 }
629 
630 void fastEnableMiniMode()
631 {
632     bmalloc::api::enableMiniMode();
633 }
634 
635 } // namespace WTF
636 
637 #endif // defined(USE_SYSTEM_MALLOC) &amp;&amp; USE_SYSTEM_MALLOC
    </pre>
  </body>
</html>