<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="AudioBufferSourceNode.idl.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="AudioContext.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 123 
 124 RefPtr&lt;AudioContext&gt; AudioContext::create(Document&amp; document)
 125 {
 126     ASSERT(isMainThread());
 127     if (s_hardwareContextCount &gt;= MaxHardwareContexts)
 128         return nullptr;
 129 
 130     RefPtr&lt;AudioContext&gt; audioContext(adoptRef(new AudioContext(document)));
 131     audioContext-&gt;suspendIfNeeded();
 132     return audioContext;
 133 }
 134 
 135 // Constructor for rendering to the audio hardware.
 136 AudioContext::AudioContext(Document&amp; document)
 137     : ActiveDOMObject(document)
 138 #if !RELEASE_LOG_DISABLED
 139     , m_logger(document.logger())
 140     , m_logIdentifier(uniqueLogIdentifier())
 141 #endif
 142     , m_mediaSession(PlatformMediaSession::create(*this))
<span class="line-modified"> 143     , m_eventQueue(makeUnique&lt;GenericEventQueue&gt;(*this))</span>
 144 {
 145     // According to spec AudioContext must die only after page navigate.
 146     // Lets mark it as ActiveDOMObject with pending activity and unmark it in clear method.
 147     makePendingActivity();
 148 
 149     constructCommon();
 150 
 151     m_destinationNode = DefaultAudioDestinationNode::create(*this);
 152 
 153     // Initialize the destination node&#39;s muted state to match the page&#39;s current muted state.
 154     pageMutedStateDidChange();
 155 
 156     document.addAudioProducer(*this);
 157     document.registerForVisibilityStateChangedCallbacks(*this);
 158 }
 159 
 160 // Constructor for offline (non-realtime) rendering.
<span class="line-modified"> 161 AudioContext::AudioContext(Document&amp; document, unsigned numberOfChannels, size_t numberOfFrames, float sampleRate)</span>
 162     : ActiveDOMObject(document)
 163 #if !RELEASE_LOG_DISABLED
 164     , m_logger(document.logger())
 165     , m_logIdentifier(uniqueLogIdentifier())
 166 #endif
 167     , m_isOfflineContext(true)
 168     , m_mediaSession(PlatformMediaSession::create(*this))
<span class="line-modified"> 169     , m_eventQueue(makeUnique&lt;GenericEventQueue&gt;(*this))</span>

 170 {
 171     constructCommon();
 172 
 173     // Create a new destination for offline rendering.
<span class="line-removed"> 174     m_renderTarget = AudioBuffer::create(numberOfChannels, numberOfFrames, sampleRate);</span>
 175     m_destinationNode = OfflineAudioDestinationNode::create(*this, m_renderTarget.get());
 176 }
 177 
 178 void AudioContext::constructCommon()
 179 {
 180     FFTFrame::initialize();
 181 
 182     m_listener = AudioListener::create();
 183 
 184     ASSERT(document());
 185     if (document()-&gt;audioPlaybackRequiresUserGesture())
 186         addBehaviorRestriction(RequireUserGestureForAudioStartRestriction);
 187     else
 188         m_restrictions = NoRestrictions;
 189 
 190 #if PLATFORM(COCOA)
 191     addBehaviorRestriction(RequirePageConsentForAudioStartRestriction);
 192 #endif
 193 }
 194 
</pre>
<hr />
<pre>
 319     m_stateReactions[stateIndex].swap(reactions);
 320 
 321     for (auto&amp; promise : reactions)
 322         promise.resolve();
 323 }
 324 
 325 void AudioContext::stop()
 326 {
 327     ALWAYS_LOG(LOGIDENTIFIER);
 328 
 329     ASSERT(isMainThread());
 330 
 331     // Usually ScriptExecutionContext calls stop twice.
 332     if (m_isStopScheduled)
 333         return;
 334     m_isStopScheduled = true;
 335 
 336     ASSERT(document());
 337     document()-&gt;updateIsPlayingMedia();
 338 
<span class="line-removed"> 339     m_eventQueue-&gt;close();</span>
<span class="line-removed"> 340 </span>
 341     uninitialize();
 342     clear();
 343 }
 344 
<span class="line-modified"> 345 bool AudioContext::canSuspendForDocumentSuspension() const</span>








 346 {
<span class="line-modified"> 347     // FIXME: We should be able to suspend while rendering as well with some more code.</span>
<span class="line-modified"> 348     return m_state == State::Suspended || m_state == State::Closed;</span>


 349 }
 350 
 351 const char* AudioContext::activeDOMObjectName() const
 352 {
 353     return &quot;AudioContext&quot;;
 354 }
 355 
 356 Document* AudioContext::document() const
 357 {
 358     return downcast&lt;Document&gt;(m_scriptExecutionContext);
 359 }
 360 
 361 Document* AudioContext::hostingDocument() const
 362 {
 363     return downcast&lt;Document&gt;(m_scriptExecutionContext);
 364 }
 365 
 366 String AudioContext::sourceApplicationIdentifier() const
 367 {
 368     Document* document = this-&gt;document();
</pre>
<hr />
<pre>
1214     m_eventQueue-&gt;enqueueEvent(OfflineAudioCompletionEvent::create(renderedBuffer));
1215 }
1216 
1217 void AudioContext::dispatchEvent(Event&amp; event)
1218 {
1219     EventTarget::dispatchEvent(event);
1220     if (event.eventInterface() == OfflineAudioCompletionEventInterfaceType)
1221         clearPendingActivity();
1222 }
1223 
1224 void AudioContext::incrementActiveSourceCount()
1225 {
1226     ++m_activeSourceCount;
1227 }
1228 
1229 void AudioContext::decrementActiveSourceCount()
1230 {
1231     --m_activeSourceCount;
1232 }
1233 
<span class="line-modified">1234 void AudioContext::suspend(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)</span>
1235 {
1236     if (isOfflineContext() || m_isStopScheduled) {
1237         promise.reject(InvalidStateError);
1238         return;
1239     }
1240 
1241     if (m_state == State::Suspended) {
1242         promise.resolve();
1243         return;
1244     }
1245 
1246     if (m_state == State::Closed || m_state == State::Interrupted || !m_destinationNode) {
1247         promise.reject();
1248         return;
1249     }
1250 
1251     addReaction(State::Suspended, WTFMove(promise));
1252 
1253     if (!willPausePlayback())
1254         return;
1255 
1256     lazyInitialize();
1257 
1258     m_destinationNode-&gt;suspend([this, protectedThis = makeRef(*this)] {
1259         setState(State::Suspended);
1260     });
1261 }
1262 
<span class="line-modified">1263 void AudioContext::resume(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)</span>
1264 {
1265     if (isOfflineContext() || m_isStopScheduled) {
1266         promise.reject(InvalidStateError);
1267         return;
1268     }
1269 
1270     if (m_state == State::Running) {
1271         promise.resolve();
1272         return;
1273     }
1274 
1275     if (m_state == State::Closed || !m_destinationNode) {
1276         promise.reject();
1277         return;
1278     }
1279 
1280     addReaction(State::Running, WTFMove(promise));
1281 
1282     if (!willBeginPlayback())
1283         return;
</pre>
</td>
<td>
<hr />
<pre>
 123 
 124 RefPtr&lt;AudioContext&gt; AudioContext::create(Document&amp; document)
 125 {
 126     ASSERT(isMainThread());
 127     if (s_hardwareContextCount &gt;= MaxHardwareContexts)
 128         return nullptr;
 129 
 130     RefPtr&lt;AudioContext&gt; audioContext(adoptRef(new AudioContext(document)));
 131     audioContext-&gt;suspendIfNeeded();
 132     return audioContext;
 133 }
 134 
 135 // Constructor for rendering to the audio hardware.
 136 AudioContext::AudioContext(Document&amp; document)
 137     : ActiveDOMObject(document)
 138 #if !RELEASE_LOG_DISABLED
 139     , m_logger(document.logger())
 140     , m_logIdentifier(uniqueLogIdentifier())
 141 #endif
 142     , m_mediaSession(PlatformMediaSession::create(*this))
<span class="line-modified"> 143     , m_eventQueue(MainThreadGenericEventQueue::create(*this))</span>
 144 {
 145     // According to spec AudioContext must die only after page navigate.
 146     // Lets mark it as ActiveDOMObject with pending activity and unmark it in clear method.
 147     makePendingActivity();
 148 
 149     constructCommon();
 150 
 151     m_destinationNode = DefaultAudioDestinationNode::create(*this);
 152 
 153     // Initialize the destination node&#39;s muted state to match the page&#39;s current muted state.
 154     pageMutedStateDidChange();
 155 
 156     document.addAudioProducer(*this);
 157     document.registerForVisibilityStateChangedCallbacks(*this);
 158 }
 159 
 160 // Constructor for offline (non-realtime) rendering.
<span class="line-modified"> 161 AudioContext::AudioContext(Document&amp; document, AudioBuffer* renderTarget)</span>
 162     : ActiveDOMObject(document)
 163 #if !RELEASE_LOG_DISABLED
 164     , m_logger(document.logger())
 165     , m_logIdentifier(uniqueLogIdentifier())
 166 #endif
 167     , m_isOfflineContext(true)
 168     , m_mediaSession(PlatformMediaSession::create(*this))
<span class="line-modified"> 169     , m_eventQueue(MainThreadGenericEventQueue::create(*this))</span>
<span class="line-added"> 170     , m_renderTarget(renderTarget)</span>
 171 {
 172     constructCommon();
 173 
 174     // Create a new destination for offline rendering.

 175     m_destinationNode = OfflineAudioDestinationNode::create(*this, m_renderTarget.get());
 176 }
 177 
 178 void AudioContext::constructCommon()
 179 {
 180     FFTFrame::initialize();
 181 
 182     m_listener = AudioListener::create();
 183 
 184     ASSERT(document());
 185     if (document()-&gt;audioPlaybackRequiresUserGesture())
 186         addBehaviorRestriction(RequireUserGestureForAudioStartRestriction);
 187     else
 188         m_restrictions = NoRestrictions;
 189 
 190 #if PLATFORM(COCOA)
 191     addBehaviorRestriction(RequirePageConsentForAudioStartRestriction);
 192 #endif
 193 }
 194 
</pre>
<hr />
<pre>
 319     m_stateReactions[stateIndex].swap(reactions);
 320 
 321     for (auto&amp; promise : reactions)
 322         promise.resolve();
 323 }
 324 
 325 void AudioContext::stop()
 326 {
 327     ALWAYS_LOG(LOGIDENTIFIER);
 328 
 329     ASSERT(isMainThread());
 330 
 331     // Usually ScriptExecutionContext calls stop twice.
 332     if (m_isStopScheduled)
 333         return;
 334     m_isStopScheduled = true;
 335 
 336     ASSERT(document());
 337     document()-&gt;updateIsPlayingMedia();
 338 


 339     uninitialize();
 340     clear();
 341 }
 342 
<span class="line-modified"> 343 void AudioContext::suspend(ReasonForSuspension)</span>
<span class="line-added"> 344 {</span>
<span class="line-added"> 345     if (state() == State::Running) {</span>
<span class="line-added"> 346         m_mediaSession-&gt;beginInterruption(PlatformMediaSession::PlaybackSuspended);</span>
<span class="line-added"> 347         document()-&gt;updateIsPlayingMedia();</span>
<span class="line-added"> 348     }</span>
<span class="line-added"> 349 }</span>
<span class="line-added"> 350 </span>
<span class="line-added"> 351 void AudioContext::resume()</span>
 352 {
<span class="line-modified"> 353     if (state() == State::Interrupted) {</span>
<span class="line-modified"> 354         m_mediaSession-&gt;endInterruption(PlatformMediaSession::MayResumePlaying);</span>
<span class="line-added"> 355         document()-&gt;updateIsPlayingMedia();</span>
<span class="line-added"> 356     }</span>
 357 }
 358 
 359 const char* AudioContext::activeDOMObjectName() const
 360 {
 361     return &quot;AudioContext&quot;;
 362 }
 363 
 364 Document* AudioContext::document() const
 365 {
 366     return downcast&lt;Document&gt;(m_scriptExecutionContext);
 367 }
 368 
 369 Document* AudioContext::hostingDocument() const
 370 {
 371     return downcast&lt;Document&gt;(m_scriptExecutionContext);
 372 }
 373 
 374 String AudioContext::sourceApplicationIdentifier() const
 375 {
 376     Document* document = this-&gt;document();
</pre>
<hr />
<pre>
1222     m_eventQueue-&gt;enqueueEvent(OfflineAudioCompletionEvent::create(renderedBuffer));
1223 }
1224 
1225 void AudioContext::dispatchEvent(Event&amp; event)
1226 {
1227     EventTarget::dispatchEvent(event);
1228     if (event.eventInterface() == OfflineAudioCompletionEventInterfaceType)
1229         clearPendingActivity();
1230 }
1231 
1232 void AudioContext::incrementActiveSourceCount()
1233 {
1234     ++m_activeSourceCount;
1235 }
1236 
1237 void AudioContext::decrementActiveSourceCount()
1238 {
1239     --m_activeSourceCount;
1240 }
1241 
<span class="line-modified">1242 void AudioContext::suspendRendering(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)</span>
1243 {
1244     if (isOfflineContext() || m_isStopScheduled) {
1245         promise.reject(InvalidStateError);
1246         return;
1247     }
1248 
1249     if (m_state == State::Suspended) {
1250         promise.resolve();
1251         return;
1252     }
1253 
1254     if (m_state == State::Closed || m_state == State::Interrupted || !m_destinationNode) {
1255         promise.reject();
1256         return;
1257     }
1258 
1259     addReaction(State::Suspended, WTFMove(promise));
1260 
1261     if (!willPausePlayback())
1262         return;
1263 
1264     lazyInitialize();
1265 
1266     m_destinationNode-&gt;suspend([this, protectedThis = makeRef(*this)] {
1267         setState(State::Suspended);
1268     });
1269 }
1270 
<span class="line-modified">1271 void AudioContext::resumeRendering(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)</span>
1272 {
1273     if (isOfflineContext() || m_isStopScheduled) {
1274         promise.reject(InvalidStateError);
1275         return;
1276     }
1277 
1278     if (m_state == State::Running) {
1279         promise.resolve();
1280         return;
1281     }
1282 
1283     if (m_state == State::Closed || !m_destinationNode) {
1284         promise.reject();
1285         return;
1286     }
1287 
1288     addReaction(State::Running, WTFMove(promise));
1289 
1290     if (!willBeginPlayback())
1291         return;
</pre>
</td>
</tr>
</table>
<center><a href="AudioBufferSourceNode.idl.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="AudioContext.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>