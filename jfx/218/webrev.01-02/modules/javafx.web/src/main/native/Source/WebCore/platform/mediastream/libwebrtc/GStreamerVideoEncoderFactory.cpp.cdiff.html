<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoEncoderFactory.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="GStreamerVideoDecoderFactory.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../index.html" target="_top">index</a> <a href="LibWebRTCAudioModule.h.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoEncoderFactory.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 71,23 ***</span>
          : m_firstFramePts(GST_CLOCK_TIME_NONE)
          , m_restrictionCaps(adoptGRef(gst_caps_new_empty_simple(&quot;video/x-raw&quot;)))
      {
      }
  
<span class="line-modified">!     int SetRates(uint32_t newBitrate, uint32_t frameRate) override</span>
      {
<span class="line-modified">!         GST_INFO_OBJECT(m_pipeline.get(), &quot;New bitrate: %d - framerate is %d&quot;,</span>
<span class="line-modified">!             newBitrate, frameRate);</span>
  
          auto caps = adoptGRef(gst_caps_copy(m_restrictionCaps.get()));
  
          SetRestrictionCaps(WTFMove(caps));
  
          if (m_encoder)
<span class="line-modified">!             g_object_set(m_encoder, &quot;bitrate&quot;, newBitrate, nullptr);</span>
<span class="line-removed">- </span>
<span class="line-removed">-         return WEBRTC_VIDEO_CODEC_OK;</span>
      }
  
      GstElement* pipeline()
      {
          return m_pipeline.get();
<span class="line-new-header">--- 71,21 ---</span>
          : m_firstFramePts(GST_CLOCK_TIME_NONE)
          , m_restrictionCaps(adoptGRef(gst_caps_new_empty_simple(&quot;video/x-raw&quot;)))
      {
      }
  
<span class="line-modified">!     void SetRates(const webrtc::VideoEncoder::RateControlParameters&amp; parameters) override</span>
      {
<span class="line-modified">!         GST_INFO_OBJECT(m_pipeline.get(), &quot;New bitrate: %d - framerate is %f&quot;,</span>
<span class="line-modified">!             parameters.bitrate.get_sum_bps(), parameters.framerate_fps);</span>
  
          auto caps = adoptGRef(gst_caps_copy(m_restrictionCaps.get()));
  
          SetRestrictionCaps(WTFMove(caps));
  
          if (m_encoder)
<span class="line-modified">!             g_object_set(m_encoder, &quot;bitrate&quot;, parameters.bitrate.get_sum_bps(), nullptr);</span>
      }
  
      GstElement* pipeline()
      {
          return m_pipeline.get();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 111,17 ***</span>
              GST_ERROR(&quot;Simulcast not supported.&quot;);
  
              return WEBRTC_VIDEO_CODEC_ERR_SIMULCAST_PARAMETERS_NOT_SUPPORTED;
          }
  
<span class="line-modified">!         m_encodedFrame._size = codecSettings-&gt;width * codecSettings-&gt;height * 3;</span>
<span class="line-modified">!         m_encodedFrame._buffer = new uint8_t[m_encodedFrame._size];</span>
<span class="line-modified">!         m_encodedImageBuffer.reset(m_encodedFrame._buffer);</span>
          m_encodedFrame._completeFrame = true;
          m_encodedFrame._encodedWidth = 0;
          m_encodedFrame._encodedHeight = 0;
<span class="line-removed">-         m_encodedFrame._length = 0;</span>
  
          m_pipeline = makeElement(&quot;pipeline&quot;);
  
          connectSimpleBusMessageCallback(m_pipeline.get());
          auto encoder = createEncoder();
<span class="line-new-header">--- 109,16 ---</span>
              GST_ERROR(&quot;Simulcast not supported.&quot;);
  
              return WEBRTC_VIDEO_CODEC_ERR_SIMULCAST_PARAMETERS_NOT_SUPPORTED;
          }
  
<span class="line-modified">!         auto size = codecSettings-&gt;width * codecSettings-&gt;height * 3;</span>
<span class="line-modified">!         m_encodedFrame.set_buffer(new uint8_t[size], size);</span>
<span class="line-modified">!         m_encodedImageBuffer.reset(m_encodedFrame.data());</span>
          m_encodedFrame._completeFrame = true;
          m_encodedFrame._encodedWidth = 0;
          m_encodedFrame._encodedHeight = 0;
  
          m_pipeline = makeElement(&quot;pipeline&quot;);
  
          connectSimpleBusMessageCallback(m_pipeline.get());
          auto encoder = createEncoder();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 151,25 ***</span>
          gst_element_set_state(m_pipeline.get(), GST_STATE_PLAYING);
  
          return WEBRTC_VIDEO_CODEC_OK;
      }
  
<span class="line-removed">-     bool SupportsNativeHandle() const final</span>
<span class="line-removed">-     {</span>
<span class="line-removed">-         return true;</span>
<span class="line-removed">-     }</span>
<span class="line-removed">- </span>
      int32_t RegisterEncodeCompleteCallback(webrtc::EncodedImageCallback* callback) final
      {
          m_imageReadyCb = callback;
  
          return WEBRTC_VIDEO_CODEC_OK;
      }
  
      int32_t Release() final
      {
<span class="line-modified">!         m_encodedFrame._buffer = nullptr;</span>
          m_encodedImageBuffer.reset();
          if (m_pipeline) {
              GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
              gst_bus_set_sync_handler(bus.get(), nullptr, nullptr, nullptr);
  
<span class="line-new-header">--- 148,20 ---</span>
          gst_element_set_state(m_pipeline.get(), GST_STATE_PLAYING);
  
          return WEBRTC_VIDEO_CODEC_OK;
      }
  
      int32_t RegisterEncodeCompleteCallback(webrtc::EncodedImageCallback* callback) final
      {
          m_imageReadyCb = callback;
  
          return WEBRTC_VIDEO_CODEC_OK;
      }
  
      int32_t Release() final
      {
<span class="line-modified">!         m_encodedFrame.set_buffer(nullptr, 0);</span>
          m_encodedImageBuffer.reset();
          if (m_pipeline) {
              GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
              gst_bus_set_sync_handler(bus.get(), nullptr, nullptr, nullptr);
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 194,13 ***</span>
          default:
              return WEBRTC_VIDEO_CODEC_ERROR;
          }
      }
  
      int32_t Encode(const webrtc::VideoFrame&amp; frame,
<span class="line-modified">!         const webrtc::CodecSpecificInfo*,</span>
<span class="line-removed">-         const std::vector&lt;webrtc::FrameType&gt;* frameTypes) final</span>
      {
          int32_t res;
  
          if (!m_imageReadyCb) {
              GST_INFO_OBJECT(m_pipeline.get(), &quot;No encoded callback set yet!&quot;);
<span class="line-new-header">--- 186,22 ---</span>
          default:
              return WEBRTC_VIDEO_CODEC_ERROR;
          }
      }
  
<span class="line-added">+     VideoEncoder::EncoderInfo GetEncoderInfo() const {</span>
<span class="line-added">+         EncoderInfo info;</span>
<span class="line-added">+         info.supports_native_handle = false;</span>
<span class="line-added">+         info.implementation_name = &quot;GStreamer&quot;;</span>
<span class="line-added">+         info.has_trusted_rate_controller = true;</span>
<span class="line-added">+         info.is_hardware_accelerated = true;</span>
<span class="line-added">+         info.has_internal_source = false;</span>
<span class="line-added">+         return info;</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
      int32_t Encode(const webrtc::VideoFrame&amp; frame,
<span class="line-modified">!         const std::vector&lt;webrtc::VideoFrameType&gt;* frameTypes) final</span>
      {
          int32_t res;
  
          if (!m_imageReadyCb) {
              GST_INFO_OBJECT(m_pipeline.get(), &quot;No encoded callback set yet!&quot;);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 222,11 ***</span>
              auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
              gst_pad_set_offset(pad.get(), -m_firstFramePts);
          }
  
          for (auto frame_type : *frameTypes) {
<span class="line-modified">!             if (frame_type == webrtc::kVideoFrameKey) {</span>
                  auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
                  auto forceKeyUnit = gst_video_event_new_downstream_force_key_unit(GST_CLOCK_TIME_NONE,
                      GST_CLOCK_TIME_NONE, GST_CLOCK_TIME_NONE, FALSE, 1);
                  GST_INFO_OBJECT(m_pipeline.get(), &quot;Requesting KEYFRAME!&quot;);
  
<span class="line-new-header">--- 223,11 ---</span>
              auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
              gst_pad_set_offset(pad.get(), -m_firstFramePts);
          }
  
          for (auto frame_type : *frameTypes) {
<span class="line-modified">!             if (frame_type == webrtc::VideoFrameType::kVideoFrameKey) {</span>
                  auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
                  auto forceKeyUnit = gst_video_event_new_downstream_force_key_unit(GST_CLOCK_TIME_NONE,
                      GST_CLOCK_TIME_NONE, GST_CLOCK_TIME_NONE, FALSE, 1);
                  GST_INFO_OBJECT(m_pipeline.get(), &quot;Requesting KEYFRAME!&quot;);
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 251,19 ***</span>
          auto encodedCaps = gst_sample_get_caps(encodedSample.get());
  
          webrtc::RTPFragmentationHeader fragmentationInfo;
  
          Fragmentize(&amp;m_encodedFrame, &amp;m_encodedImageBuffer, &amp;m_encodedImageBufferSize, encodedBuffer, &amp;fragmentationInfo);
<span class="line-modified">!         if (!m_encodedFrame._size)</span>
              return WEBRTC_VIDEO_CODEC_OK;
  
          gst_structure_get(gst_caps_get_structure(encodedCaps, 0),
              &quot;width&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedWidth,
              &quot;height&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedHeight,
              nullptr);
  
<span class="line-modified">!         m_encodedFrame._frameType = GST_BUFFER_FLAG_IS_SET(encodedBuffer, GST_BUFFER_FLAG_DELTA_UNIT) ? webrtc::kVideoFrameDelta : webrtc::kVideoFrameKey;</span>
          m_encodedFrame._completeFrame = true;
          m_encodedFrame.capture_time_ms_ = frame.render_time_ms();
          m_encodedFrame.SetTimestamp(frame.timestamp());
  
          GST_LOG_OBJECT(m_pipeline.get(), &quot;Got buffer capture_time_ms: %&quot; G_GINT64_FORMAT  &quot; _timestamp: %u&quot;,
<span class="line-new-header">--- 252,19 ---</span>
          auto encodedCaps = gst_sample_get_caps(encodedSample.get());
  
          webrtc::RTPFragmentationHeader fragmentationInfo;
  
          Fragmentize(&amp;m_encodedFrame, &amp;m_encodedImageBuffer, &amp;m_encodedImageBufferSize, encodedBuffer, &amp;fragmentationInfo);
<span class="line-modified">!         if (!m_encodedFrame.size())</span>
              return WEBRTC_VIDEO_CODEC_OK;
  
          gst_structure_get(gst_caps_get_structure(encodedCaps, 0),
              &quot;width&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedWidth,
              &quot;height&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedHeight,
              nullptr);
  
<span class="line-modified">!         m_encodedFrame._frameType = GST_BUFFER_FLAG_IS_SET(encodedBuffer, GST_BUFFER_FLAG_DELTA_UNIT) ? webrtc::VideoFrameType::kVideoFrameDelta : webrtc::VideoFrameType::kVideoFrameKey;</span>
          m_encodedFrame._completeFrame = true;
          m_encodedFrame.capture_time_ms_ = frame.render_time_ms();
          m_encodedFrame.SetTimestamp(frame.timestamp());
  
          GST_LOG_OBJECT(m_pipeline.get(), &quot;Got buffer capture_time_ms: %&quot; G_GINT64_FORMAT  &quot; _timestamp: %u&quot;,
</pre>
<hr />
<pre>
<span class="line-old-header">*** 323,35 ***</span>
          size_t* bufferSize, GstBuffer* buffer, webrtc::RTPFragmentationHeader* fragmentationInfo)
      {
          auto map = GstMappedBuffer::create(buffer, GST_MAP_READ);
  
          if (*bufferSize &lt; map-&gt;size()) {
<span class="line-modified">!             encodedImage-&gt;_size = map-&gt;size();</span>
<span class="line-modified">!             encodedImage-&gt;_buffer = new uint8_t[encodedImage-&gt;_size];</span>
<span class="line-modified">!             encodedImageBuffer-&gt;reset(encodedImage-&gt;_buffer);</span>
              *bufferSize = map-&gt;size();
          }
  
<span class="line-modified">!         memcpy(encodedImage-&gt;_buffer, map-&gt;data(), map-&gt;size());</span>
<span class="line-modified">!         encodedImage-&gt;_length = map-&gt;size();</span>
<span class="line-removed">-         encodedImage-&gt;_size = map-&gt;size();</span>
  
          fragmentationInfo-&gt;VerifyAndAllocateFragmentationHeader(1);
          fragmentationInfo-&gt;fragmentationOffset[0] = 0;
          fragmentationInfo-&gt;fragmentationLength[0] = map-&gt;size();
<span class="line-removed">-         fragmentationInfo-&gt;fragmentationPlType[0] = 0;</span>
<span class="line-removed">-         fragmentationInfo-&gt;fragmentationTimeDiff[0] = 0;</span>
<span class="line-removed">-     }</span>
<span class="line-removed">- </span>
<span class="line-removed">-     const char* ImplementationName() const</span>
<span class="line-removed">-     {</span>
<span class="line-removed">-         GRefPtr&lt;GstElement&gt; encoderImplementation;</span>
<span class="line-removed">-         g_return_val_if_fail(m_encoder, nullptr);</span>
<span class="line-removed">- </span>
<span class="line-removed">-         g_object_get(m_encoder, &quot;encoder&quot;, &amp;encoderImplementation.outPtr(), nullptr);</span>
<span class="line-removed">- </span>
<span class="line-removed">-         return GST_OBJECT_NAME(gst_element_get_factory(encoderImplementation.get()));</span>
      }
  
      virtual const gchar* Name() = 0;
      virtual int KeyframeInterval(const webrtc::VideoCodec* codecSettings) = 0;
  
<span class="line-new-header">--- 324,22 ---</span>
          size_t* bufferSize, GstBuffer* buffer, webrtc::RTPFragmentationHeader* fragmentationInfo)
      {
          auto map = GstMappedBuffer::create(buffer, GST_MAP_READ);
  
          if (*bufferSize &lt; map-&gt;size()) {
<span class="line-modified">!             encodedImage-&gt;set_size(map-&gt;size());</span>
<span class="line-modified">!             encodedImage-&gt;set_buffer(new uint8_t[map-&gt;size()], map-&gt;size());</span>
<span class="line-modified">!             encodedImageBuffer-&gt;reset(encodedImage-&gt;data());</span>
              *bufferSize = map-&gt;size();
          }
  
<span class="line-modified">!         memcpy(encodedImage-&gt;data(), map-&gt;data(), map-&gt;size());</span>
<span class="line-modified">!         encodedImage-&gt;set_size(map-&gt;size());</span>
  
          fragmentationInfo-&gt;VerifyAndAllocateFragmentationHeader(1);
          fragmentationInfo-&gt;fragmentationOffset[0] = 0;
          fragmentationInfo-&gt;fragmentationLength[0] = map-&gt;size();
      }
  
      virtual const gchar* Name() = 0;
      virtual int KeyframeInterval(const webrtc::VideoCodec* codecSettings) = 0;
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 424,34 ***</span>
              requiredSize += nalu.size + sizeof(startCode);
              nals.push_back(nalu);
              offset = nalu.offset + nalu.size;
          }
  
<span class="line-modified">!         if (encodedImage-&gt;_size &lt; requiredSize) {</span>
<span class="line-modified">!             encodedImage-&gt;_size = requiredSize;</span>
<span class="line-modified">!             encodedImage-&gt;_buffer = new uint8_t[encodedImage-&gt;_size];</span>
<span class="line-modified">!             encodedImageBuffer-&gt;reset(encodedImage-&gt;_buffer);</span>
              *bufferSize = map-&gt;size();
          }
  
          // Iterate nal units and fill the Fragmentation info.
          fragmentationHeader-&gt;VerifyAndAllocateFragmentationHeader(nals.size());
          size_t fragmentIndex = 0;
<span class="line-modified">!         encodedImage-&gt;_length = 0;</span>
          for (std::vector&lt;GstH264NalUnit&gt;::iterator nal = nals.begin(); nal != nals.end(); ++nal, fragmentIndex++) {
  
              ASSERT(map-&gt;data()[nal-&gt;sc_offset + 0] == startCode[0]);
              ASSERT(map-&gt;data()[nal-&gt;sc_offset + 1] == startCode[1]);
              ASSERT(map-&gt;data()[nal-&gt;sc_offset + 2] == startCode[2]);
              ASSERT(map-&gt;data()[nal-&gt;sc_offset + 3] == startCode[3]);
  
              fragmentationHeader-&gt;fragmentationOffset[fragmentIndex] = nal-&gt;offset;
              fragmentationHeader-&gt;fragmentationLength[fragmentIndex] = nal-&gt;size;
  
<span class="line-modified">!             memcpy(encodedImage-&gt;_buffer + encodedImage-&gt;_length, &amp;map-&gt;data()[nal-&gt;sc_offset],</span>
                  sizeof(startCode) + nal-&gt;size);
<span class="line-modified">!             encodedImage-&gt;_length += nal-&gt;size + sizeof(startCode);</span>
          }
      }
  
      webrtc::SdpVideoFormat ConfigureSupportedCodec(GstElement*) final
      {
<span class="line-new-header">--- 412,34 ---</span>
              requiredSize += nalu.size + sizeof(startCode);
              nals.push_back(nalu);
              offset = nalu.offset + nalu.size;
          }
  
<span class="line-modified">!         if (encodedImage-&gt;size() &lt; requiredSize) {</span>
<span class="line-modified">!             encodedImage-&gt;set_size(requiredSize);</span>
<span class="line-modified">!             encodedImage-&gt;set_buffer(new uint8_t[requiredSize], requiredSize);</span>
<span class="line-modified">!             encodedImageBuffer-&gt;reset(encodedImage-&gt;data());</span>
              *bufferSize = map-&gt;size();
          }
  
          // Iterate nal units and fill the Fragmentation info.
          fragmentationHeader-&gt;VerifyAndAllocateFragmentationHeader(nals.size());
          size_t fragmentIndex = 0;
<span class="line-modified">!         encodedImage-&gt;set_size(0);</span>
          for (std::vector&lt;GstH264NalUnit&gt;::iterator nal = nals.begin(); nal != nals.end(); ++nal, fragmentIndex++) {
  
              ASSERT(map-&gt;data()[nal-&gt;sc_offset + 0] == startCode[0]);
              ASSERT(map-&gt;data()[nal-&gt;sc_offset + 1] == startCode[1]);
              ASSERT(map-&gt;data()[nal-&gt;sc_offset + 2] == startCode[2]);
              ASSERT(map-&gt;data()[nal-&gt;sc_offset + 3] == startCode[3]);
  
              fragmentationHeader-&gt;fragmentationOffset[fragmentIndex] = nal-&gt;offset;
              fragmentationHeader-&gt;fragmentationLength[fragmentIndex] = nal-&gt;size;
  
<span class="line-modified">!             memcpy(encodedImage-&gt;data() + encodedImage-&gt;size(), &amp;map-&gt;data()[nal-&gt;sc_offset],</span>
                  sizeof(startCode) + nal-&gt;size);
<span class="line-modified">!             encodedImage-&gt;set_size(nal-&gt;size + sizeof(startCode));</span>
          }
      }
  
      webrtc::SdpVideoFormat ConfigureSupportedCodec(GstElement*) final
      {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 468,11 ***</span>
      webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecH264; }
  
      void PopulateCodecSpecific(webrtc::CodecSpecificInfo* codecSpecificInfos, GstBuffer*) final
      {
          codecSpecificInfos-&gt;codecType = CodecType();
<span class="line-removed">-         codecSpecificInfos-&gt;codec_name = ImplementationName();</span>
          webrtc::CodecSpecificInfoH264* h264Info = &amp;(codecSpecificInfos-&gt;codecSpecific.H264);
          h264Info-&gt;packetization_mode = packetizationMode;
      }
  
      webrtc::H264PacketizationMode packetizationMode;
<span class="line-new-header">--- 456,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 492,11 ***</span>
      }
  
      void PopulateCodecSpecific(webrtc::CodecSpecificInfo* codecSpecificInfos, GstBuffer* buffer) final
      {
          codecSpecificInfos-&gt;codecType = webrtc::kVideoCodecVP8;
<span class="line-removed">-         codecSpecificInfos-&gt;codec_name = ImplementationName();</span>
          webrtc::CodecSpecificInfoVP8* vp8Info = &amp;(codecSpecificInfos-&gt;codecSpecific.VP8);
          vp8Info-&gt;temporalIdx = 0;
  
          vp8Info-&gt;keyIdx = webrtc::kNoKeyIdx;
          vp8Info-&gt;nonReference = GST_BUFFER_FLAG_IS_SET(buffer, GST_BUFFER_FLAG_DELTA_UNIT);
<span class="line-new-header">--- 479,10 ---</span>
</pre>
<center><a href="GStreamerVideoDecoderFactory.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../index.html" target="_top">index</a> <a href="LibWebRTCAudioModule.h.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>