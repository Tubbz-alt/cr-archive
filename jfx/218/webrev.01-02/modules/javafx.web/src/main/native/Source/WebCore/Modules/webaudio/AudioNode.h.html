<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioNode.h</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2010, Google Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1.  Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2.  Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 15  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 16  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
 17  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 18  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 19  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 20  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 21  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 22  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 23  */
 24 
 25 #pragma once
 26 
 27 #include &quot;AudioBus.h&quot;
 28 #include &quot;EventTarget.h&quot;
 29 #include &quot;ExceptionOr.h&quot;
 30 #include &lt;wtf/Forward.h&gt;
 31 #include &lt;wtf/LoggerHelper.h&gt;
 32 
 33 #define DEBUG_AUDIONODE_REFERENCES 0
 34 
 35 namespace WebCore {
 36 
 37 class AudioContext;
 38 class AudioNodeInput;
 39 class AudioNodeOutput;
 40 class AudioParam;
 41 
 42 // An AudioNode is the basic building block for handling audio within an AudioContext.
 43 // It may be an audio source, an intermediate processing module, or an audio destination.
 44 // Each AudioNode can have inputs and/or outputs. An AudioSourceNode has no inputs and a single output.
 45 // An AudioDestinationNode has one input and no outputs and represents the final destination to the audio hardware.
 46 // Most processing nodes such as filters will have one input and one output, although multiple inputs and outputs are possible.
 47 
 48 class AudioNode
 49     : public EventTargetWithInlineData
 50 #if !RELEASE_LOG_DISABLED
 51     , private LoggerHelper
 52 #endif
 53 {
 54     WTF_MAKE_NONCOPYABLE(AudioNode);
 55     WTF_MAKE_ISO_ALLOCATED(AudioNode);
 56 public:
 57     enum { ProcessingSizeInFrames = 128 };
 58 
 59     AudioNode(AudioContext&amp;, float sampleRate);
 60     virtual ~AudioNode();
 61 
 62     AudioContext&amp; context() { return m_context.get(); }
 63     const AudioContext&amp; context() const { return m_context.get(); }
 64 
 65     enum NodeType {
 66         NodeTypeUnknown,
 67         NodeTypeDestination,
 68         NodeTypeOscillator,
 69         NodeTypeAudioBufferSource,
 70         NodeTypeMediaElementAudioSource,
 71         NodeTypeMediaStreamAudioDestination,
 72         NodeTypeMediaStreamAudioSource,
 73         NodeTypeJavaScript,
 74         NodeTypeBiquadFilter,
 75         NodeTypePanner,
 76         NodeTypeConvolver,
 77         NodeTypeDelay,
 78         NodeTypeGain,
 79         NodeTypeChannelSplitter,
 80         NodeTypeChannelMerger,
 81         NodeTypeAnalyser,
 82         NodeTypeDynamicsCompressor,
 83         NodeTypeWaveShaper,
 84         NodeTypeBasicInspector,
 85         NodeTypeEnd
 86     };
 87 
 88     enum ChannelCountMode {
 89         Max,
 90         ClampedMax,
 91         Explicit
 92     };
 93 
 94     NodeType nodeType() const { return m_nodeType; }
 95     void setNodeType(NodeType);
 96 
 97     // We handle our own ref-counting because of the threading issues and subtle nature of
 98     // how AudioNodes can continue processing (playing one-shot sound) after there are no more
 99     // JavaScript references to the object.
100     enum RefType { RefTypeNormal, RefTypeConnection };
101 
102     // Can be called from main thread or context&#39;s audio thread.
103     void ref(RefType refType = RefTypeNormal);
104     void deref(RefType refType = RefTypeNormal);
105 
106     // Can be called from main thread or context&#39;s audio thread.  It must be called while the context&#39;s graph lock is held.
107     void finishDeref(RefType refType);
108     virtual void didBecomeMarkedForDeletion() { }
109 
110     // The AudioNodeInput(s) (if any) will already have their input data available when process() is called.
111     // Subclasses will take this input data and put the results in the AudioBus(s) of its AudioNodeOutput(s) (if any).
112     // Called from context&#39;s audio thread.
113     virtual void process(size_t framesToProcess) = 0;
114 
115     // Resets DSP processing state (clears delay lines, filter memory, etc.)
116     // Called from context&#39;s audio thread.
117     virtual void reset() = 0;
118 
119     // No significant resources should be allocated until initialize() is called.
120     // Processing may not occur until a node is initialized.
121     virtual void initialize();
122     virtual void uninitialize();
123 
124     bool isInitialized() const { return m_isInitialized; }
125     void lazyInitialize();
126 
127     unsigned numberOfInputs() const { return m_inputs.size(); }
128     unsigned numberOfOutputs() const { return m_outputs.size(); }
129 
130     AudioNodeInput* input(unsigned);
131     AudioNodeOutput* output(unsigned);
132 
133     // Called from main thread by corresponding JavaScript methods.
134     virtual ExceptionOr&lt;void&gt; connect(AudioNode&amp;, unsigned outputIndex, unsigned inputIndex);
135     ExceptionOr&lt;void&gt; connect(AudioParam&amp;, unsigned outputIndex);
136     virtual ExceptionOr&lt;void&gt; disconnect(unsigned outputIndex);
137 
138     virtual float sampleRate() const { return m_sampleRate; }
139 
140     // processIfNecessary() is called by our output(s) when the rendering graph needs this AudioNode to process.
141     // This method ensures that the AudioNode will only process once per rendering time quantum even if it&#39;s called repeatedly.
142     // This handles the case of &quot;fanout&quot; where an output is connected to multiple AudioNode inputs.
143     // Called from context&#39;s audio thread.
144     void processIfNecessary(size_t framesToProcess);
145 
146     // Called when a new connection has been made to one of our inputs or the connection number of channels has changed.
147     // This potentially gives us enough information to perform a lazy initialization or, if necessary, a re-initialization.
148     // Called from main thread.
149     virtual void checkNumberOfChannelsForInput(AudioNodeInput*);
150 
151 #if DEBUG_AUDIONODE_REFERENCES
152     static void printNodeCounts();
153 #endif
154 
155     bool isMarkedForDeletion() const { return m_isMarkedForDeletion; }
156 
157     // tailTime() is the length of time (not counting latency time) where non-zero output may occur after continuous silent input.
158     virtual double tailTime() const = 0;
159     // latencyTime() is the length of time it takes for non-zero output to appear after non-zero input is provided. This only applies to
160     // processing delay which is an artifact of the processing algorithm chosen and is *not* part of the intrinsic desired effect. For
161     // example, a &quot;delay&quot; effect is expected to delay the signal, and thus would not be considered latency.
162     virtual double latencyTime() const = 0;
163 
164     // propagatesSilence() should return true if the node will generate silent output when given silent input. By default, AudioNode
165     // will take tailTime() and latencyTime() into account when determining whether the node will propagate silence.
166     virtual bool propagatesSilence() const;
167     bool inputsAreSilent();
168     void silenceOutputs();
169 
170     void enableOutputsIfNecessary();
171     void disableOutputsIfNecessary();
172 
173     unsigned channelCount();
174     virtual ExceptionOr&lt;void&gt; setChannelCount(unsigned);
175 
176     String channelCountMode();
177     ExceptionOr&lt;void&gt; setChannelCountMode(const String&amp;);
178 
179     String channelInterpretation();
180     ExceptionOr&lt;void&gt; setChannelInterpretation(const String&amp;);
181 
182     ChannelCountMode internalChannelCountMode() const { return m_channelCountMode; }
183     AudioBus::ChannelInterpretation internalChannelInterpretation() const { return m_channelInterpretation; }
184 
185 protected:
186     // Inputs and outputs must be created before the AudioNode is initialized.
187     void addInput(std::unique_ptr&lt;AudioNodeInput&gt;);
188     void addOutput(std::unique_ptr&lt;AudioNodeOutput&gt;);
189 
190     // Called by processIfNecessary() to cause all parts of the rendering graph connected to us to process.
191     // Each rendering quantum, the audio data for each of the AudioNode&#39;s inputs will be available after this method is called.
192     // Called from context&#39;s audio thread.
193     virtual void pullInputs(size_t framesToProcess);
194 
195     // Force all inputs to take any channel interpretation changes into account.
196     void updateChannelsForInputs();
197 
198 #if !RELEASE_LOG_DISABLED
199     const Logger&amp; logger() const final { return m_logger.get(); }
200     const void* logIdentifier() const final { return m_logIdentifier; }
201     const char* logClassName() const final { return &quot;AudioNode&quot;; }
202     WTFLogChannel&amp; logChannel() const final;
203 #endif
204 
205 private:
206     // EventTarget
207     EventTargetInterface eventTargetInterface() const override;
208     ScriptExecutionContext* scriptExecutionContext() const final;
209 
210     volatile bool m_isInitialized;
211     NodeType m_nodeType;
212     Ref&lt;AudioContext&gt; m_context;
213     float m_sampleRate;
214     Vector&lt;std::unique_ptr&lt;AudioNodeInput&gt;&gt; m_inputs;
215     Vector&lt;std::unique_ptr&lt;AudioNodeOutput&gt;&gt; m_outputs;
216 
217     double m_lastProcessingTime;
218     double m_lastNonSilentTime;
219 
220     // Ref-counting
221     std::atomic&lt;int&gt; m_normalRefCount;
222     std::atomic&lt;int&gt; m_connectionRefCount;
223 
224     bool m_isMarkedForDeletion;
225     bool m_isDisabled;
226 
227 #if DEBUG_AUDIONODE_REFERENCES
228     static bool s_isNodeCountInitialized;
229     static int s_nodeCount[NodeTypeEnd];
230 #endif
231 
232     void refEventTarget() override { ref(); }
233     void derefEventTarget() override { deref(); }
234 
235 #if !RELEASE_LOG_DISABLED
236     mutable Ref&lt;const Logger&gt; m_logger;
237     const void* m_logIdentifier;
238 #endif
239 
240 protected:
241     unsigned m_channelCount;
242     ChannelCountMode m_channelCountMode;
243     AudioBus::ChannelInterpretation m_channelInterpretation;
244 };
245 
246 String convertEnumerationToString(AudioNode::NodeType);
247 
248 } // namespace WebCore
249 
250 namespace WTF {
251 
252 template&lt;&gt; struct LogArgument&lt;WebCore::AudioNode::NodeType&gt; {
253     static String toString(WebCore::AudioNode::NodeType type) { return convertEnumerationToString(type); }
254 };
255 
256 } // namespace WTF
    </pre>
  </body>
</html>