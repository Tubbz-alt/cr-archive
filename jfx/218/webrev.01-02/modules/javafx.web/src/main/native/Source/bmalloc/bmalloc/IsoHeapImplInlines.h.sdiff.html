<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/IsoHeapImplInlines.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="IsoHeapImpl.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="IsoHeapInlines.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/IsoHeapImplInlines.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #include &quot;IsoHeapImpl.h&quot;
 29 #include &quot;IsoTLSDeallocatorEntry.h&quot;
 30 #include &quot;IsoSharedHeapInlines.h&quot;
 31 #include &quot;IsoSharedPageInlines.h&quot;
 32 
 33 namespace bmalloc {
 34 
 35 template&lt;typename Config&gt;
 36 IsoHeapImpl&lt;Config&gt;::IsoHeapImpl()
<span class="line-modified"> 37     : lock(PerProcess&lt;IsoTLSDeallocatorEntry&lt;Config&gt;&gt;::get()-&gt;lock)</span>
 38     , m_inlineDirectory(*this)
 39     , m_allocator(*this)
 40 {
<span class="line-removed"> 41     addToAllIsoHeaps();</span>
 42 }
 43 
 44 template&lt;typename Config&gt;
<span class="line-modified"> 45 EligibilityResult&lt;Config&gt; IsoHeapImpl&lt;Config&gt;::takeFirstEligible()</span>
 46 {
 47     if (m_isInlineDirectoryEligibleOrDecommitted) {
<span class="line-modified"> 48         EligibilityResult&lt;Config&gt; result = m_inlineDirectory.takeFirstEligible();</span>
 49         if (result.kind == EligibilityKind::Full)
 50             m_isInlineDirectoryEligibleOrDecommitted = false;
 51         else
 52             return result;
 53     }
 54 
<span class="line-modified"> 55     if (!m_firstEligibleOrDecommitedDirectory) {</span>
<span class="line-modified"> 56         // If nothing is eligible, it can only be because we have no directories. It wouldn&#39;t be the end</span>
<span class="line-modified"> 57         // of the world if we broke this invariant. It would only mean that didBecomeEligibleOrDecommited() would need</span>
<span class="line-modified"> 58         // a null check.</span>
<span class="line-modified"> 59         RELEASE_BASSERT(!m_headDirectory);</span>
<span class="line-modified"> 60         RELEASE_BASSERT(!m_tailDirectory);</span>
<span class="line-modified"> 61     }</span>
<span class="line-modified"> 62 </span>
<span class="line-modified"> 63     for (; m_firstEligibleOrDecommitedDirectory; m_firstEligibleOrDecommitedDirectory = m_firstEligibleOrDecommitedDirectory-&gt;next) {</span>
<span class="line-modified"> 64         EligibilityResult&lt;Config&gt; result = m_firstEligibleOrDecommitedDirectory-&gt;payload.takeFirstEligible();</span>
<span class="line-modified"> 65         if (result.kind != EligibilityKind::Full) {</span>
<span class="line-modified"> 66             m_directoryHighWatermark = std::max(m_directoryHighWatermark, m_firstEligibleOrDecommitedDirectory-&gt;index());</span>
<span class="line-modified"> 67             return result;</span>










 68         }
 69     }
 70 
 71     auto* newDirectory = new IsoDirectoryPage&lt;Config&gt;(*this, m_nextDirectoryPageIndex++);
<span class="line-modified"> 72     if (m_headDirectory) {</span>
 73         m_tailDirectory-&gt;next = newDirectory;
 74         m_tailDirectory = newDirectory;
 75     } else {
<span class="line-modified"> 76         RELEASE_BASSERT(!m_tailDirectory);</span>
 77         m_headDirectory = newDirectory;
 78         m_tailDirectory = newDirectory;
 79     }
 80     m_directoryHighWatermark = newDirectory-&gt;index();
 81     m_firstEligibleOrDecommitedDirectory = newDirectory;
<span class="line-modified"> 82     EligibilityResult&lt;Config&gt; result = newDirectory-&gt;payload.takeFirstEligible();</span>
 83     RELEASE_BASSERT(result.kind != EligibilityKind::Full);
 84     return result;
 85 }
 86 
 87 template&lt;typename Config&gt;
<span class="line-modified"> 88 void IsoHeapImpl&lt;Config&gt;::didBecomeEligibleOrDecommited(IsoDirectory&lt;Config, numPagesInInlineDirectory&gt;* directory)</span>
 89 {
 90     RELEASE_BASSERT(directory == &amp;m_inlineDirectory);
 91     m_isInlineDirectoryEligibleOrDecommitted = true;
 92 }
 93 
 94 template&lt;typename Config&gt;
<span class="line-modified"> 95 void IsoHeapImpl&lt;Config&gt;::didBecomeEligibleOrDecommited(IsoDirectory&lt;Config, IsoDirectoryPage&lt;Config&gt;::numPages&gt;* directory)</span>
 96 {
 97     RELEASE_BASSERT(m_firstEligibleOrDecommitedDirectory);
 98     auto* directoryPage = IsoDirectoryPage&lt;Config&gt;::pageFor(directory);
 99     if (directoryPage-&gt;index() &lt; m_firstEligibleOrDecommitedDirectory-&gt;index())
100         m_firstEligibleOrDecommitedDirectory = directoryPage;
101 }
102 
103 template&lt;typename Config&gt;
104 void IsoHeapImpl&lt;Config&gt;::scavenge(Vector&lt;DeferredDecommit&gt;&amp; decommits)
105 {
<span class="line-modified">106     std::lock_guard&lt;Mutex&gt; locker(this-&gt;lock);</span>
107     forEachDirectory(

108         [&amp;] (auto&amp; directory) {
<span class="line-modified">109             directory.scavenge(decommits);</span>
110         });
111     m_directoryHighWatermark = 0;
112 }
113 

114 template&lt;typename Config&gt;
<span class="line-modified">115 size_t IsoHeapImpl&lt;Config&gt;::freeableMemory()</span>













116 {
117     return m_freeableMemory;
118 }
119 
120 template&lt;typename Config&gt;
121 unsigned IsoHeapImpl&lt;Config&gt;::allocatorOffset()
122 {
<span class="line-modified">123     return m_allocator.offset();</span>
124 }
125 
126 template&lt;typename Config&gt;
127 unsigned IsoHeapImpl&lt;Config&gt;::deallocatorOffset()
128 {
<span class="line-modified">129     return PerProcess&lt;IsoTLSDeallocatorEntry&lt;Config&gt;&gt;::get()-&gt;offset();</span>
130 }
131 
132 template&lt;typename Config&gt;
133 unsigned IsoHeapImpl&lt;Config&gt;::numLiveObjects()
134 {

135     unsigned result = 0;
136     forEachLiveObject(

137         [&amp;] (void*) {
138             result++;
139         });
140     return result;
141 }
142 
143 template&lt;typename Config&gt;
144 unsigned IsoHeapImpl&lt;Config&gt;::numCommittedPages()
145 {

146     unsigned result = 0;
147     forEachCommittedPage(

148         [&amp;] (IsoPage&lt;Config&gt;&amp;) {
149             result++;
150         });
151     return result;
152 }
153 
154 template&lt;typename Config&gt;
155 template&lt;typename Func&gt;
<span class="line-modified">156 void IsoHeapImpl&lt;Config&gt;::forEachDirectory(const Func&amp; func)</span>
157 {
158     func(m_inlineDirectory);
<span class="line-modified">159     for (IsoDirectoryPage&lt;Config&gt;* page = m_headDirectory; page; page = page-&gt;next)</span>
160         func(page-&gt;payload);
161 }
162 
163 template&lt;typename Config&gt;
164 template&lt;typename Func&gt;
<span class="line-modified">165 void IsoHeapImpl&lt;Config&gt;::forEachCommittedPage(const Func&amp; func)</span>
166 {
167     forEachDirectory(

168         [&amp;] (auto&amp; directory) {
<span class="line-modified">169             directory.forEachCommittedPage(func);</span>
170         });
171 }
172 
173 template&lt;typename Config&gt;
174 template&lt;typename Func&gt;
<span class="line-modified">175 void IsoHeapImpl&lt;Config&gt;::forEachLiveObject(const Func&amp; func)</span>
176 {
177     forEachCommittedPage(

178         [&amp;] (IsoPage&lt;Config&gt;&amp; page) {
<span class="line-modified">179             page.forEachLiveObject(func);</span>
180         });
181     for (unsigned index = 0; index &lt; maxAllocationFromShared; ++index) {
<span class="line-modified">182         void* pointer = m_sharedCells[index];</span>
183         if (pointer &amp;&amp; !(m_availableShared &amp; (1U &lt;&lt; index)))
184             func(pointer);
185     }
186 }
187 
<span class="line-modified">188 template&lt;typename Config&gt;</span>
<span class="line-removed">189 size_t IsoHeapImpl&lt;Config&gt;::footprint()</span>
190 {
191 #if ENABLE_PHYSICAL_PAGE_MAP
192     RELEASE_BASSERT(m_footprint == m_physicalPageMap.footprint());
193 #endif
194     return m_footprint;
195 }
196 
<span class="line-modified">197 template&lt;typename Config&gt;</span>
<span class="line-removed">198 void IsoHeapImpl&lt;Config&gt;::didCommit(void* ptr, size_t bytes)</span>
199 {
200     BUNUSED_PARAM(ptr);
201     m_footprint += bytes;
202 #if ENABLE_PHYSICAL_PAGE_MAP
203     m_physicalPageMap.commit(ptr, bytes);
204 #endif
205 }
206 
<span class="line-modified">207 template&lt;typename Config&gt;</span>
<span class="line-removed">208 void IsoHeapImpl&lt;Config&gt;::didDecommit(void* ptr, size_t bytes)</span>
209 {
210     BUNUSED_PARAM(ptr);
211     m_footprint -= bytes;
212 #if ENABLE_PHYSICAL_PAGE_MAP
213     m_physicalPageMap.decommit(ptr, bytes);
214 #endif
215 }
216 
<span class="line-modified">217 template&lt;typename Config&gt;</span>
<span class="line-removed">218 void IsoHeapImpl&lt;Config&gt;::isNowFreeable(void* ptr, size_t bytes)</span>
219 {
220     BUNUSED_PARAM(ptr);
221     m_freeableMemory += bytes;
222 }
223 
<span class="line-modified">224 template&lt;typename Config&gt;</span>
<span class="line-removed">225 void IsoHeapImpl&lt;Config&gt;::isNoLongerFreeable(void* ptr, size_t bytes)</span>
226 {
227     BUNUSED_PARAM(ptr);
228     m_freeableMemory -= bytes;
229 }
230 
231 template&lt;typename Config&gt;
232 AllocationMode IsoHeapImpl&lt;Config&gt;::updateAllocationMode()
233 {
234     auto getNewAllocationMode = [&amp;] {
235         // Exhaust shared free cells, which means we should start activating the fast allocation mode for this type.
236         if (!m_availableShared) {
237             m_lastSlowPathTime = std::chrono::steady_clock::now();
238             return AllocationMode::Fast;
239         }
240 
241         switch (m_allocationMode) {
242         case AllocationMode::Shared:
243             // Currently in the shared allocation mode. Until we exhaust shared free cells, continue using the shared allocation mode.
244             // But if we allocate so many shared cells within very short period, we should use the fast allocation mode instead.
245             // This avoids the following pathological case.
</pre>
<hr />
<pre>
263             }
264 
265             m_numberOfAllocationsFromSharedInOneCycle = 0;
266             m_lastSlowPathTime = now;
267             return AllocationMode::Shared;
268         }
269 
270         case AllocationMode::Init:
271             m_lastSlowPathTime = std::chrono::steady_clock::now();
272             return AllocationMode::Shared;
273         }
274 
275         return AllocationMode::Shared;
276     };
277     AllocationMode allocationMode = getNewAllocationMode();
278     m_allocationMode = allocationMode;
279     return allocationMode;
280 }
281 
282 template&lt;typename Config&gt;
<span class="line-modified">283 void* IsoHeapImpl&lt;Config&gt;::allocateFromShared(const std::lock_guard&lt;Mutex&gt;&amp;, bool abortOnFailure)</span>
284 {
285     static constexpr bool verbose = false;
286 
287     unsigned indexPlusOne = __builtin_ffs(m_availableShared);
288     BASSERT(indexPlusOne);
289     unsigned index = indexPlusOne - 1;
<span class="line-modified">290     void* result = m_sharedCells[index];</span>
291     if (result) {
292         if (verbose)
293             fprintf(stderr, &quot;%p: allocated %p from shared again of size %u\n&quot;, this, result, Config::objectSize);
294     } else {
295         constexpr unsigned objectSizeWithHeapImplPointer = Config::objectSize + sizeof(uint8_t);
296         result = IsoSharedHeap::get()-&gt;allocateNew&lt;objectSizeWithHeapImplPointer&gt;(abortOnFailure);
297         if (!result)
298             return nullptr;
299         if (verbose)
300             fprintf(stderr, &quot;%p: allocated %p from shared of size %u\n&quot;, this, result, Config::objectSize);
301         BASSERT(index &lt; IsoHeapImplBase::maxAllocationFromShared);
302         *indexSlotFor&lt;Config&gt;(result) = index;
<span class="line-modified">303         m_sharedCells[index] = result;</span>
304     }
305     BASSERT(result);
306     m_availableShared &amp;= ~(1U &lt;&lt; index);
307     ++m_numberOfAllocationsFromSharedInOneCycle;
308     return result;
309 }
310 
311 } // namespace bmalloc
312 
</pre>
</td>
<td>
<hr />
<pre>
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #include &quot;IsoHeapImpl.h&quot;
 29 #include &quot;IsoTLSDeallocatorEntry.h&quot;
 30 #include &quot;IsoSharedHeapInlines.h&quot;
 31 #include &quot;IsoSharedPageInlines.h&quot;
 32 
 33 namespace bmalloc {
 34 
 35 template&lt;typename Config&gt;
 36 IsoHeapImpl&lt;Config&gt;::IsoHeapImpl()
<span class="line-modified"> 37     : IsoHeapImplBase((*PerProcess&lt;IsoTLSEntryHolder&lt;IsoTLSDeallocatorEntry&lt;Config&gt;&gt;&gt;::get())-&gt;lock)</span>
 38     , m_inlineDirectory(*this)
 39     , m_allocator(*this)
 40 {

 41 }
 42 
 43 template&lt;typename Config&gt;
<span class="line-modified"> 44 EligibilityResult&lt;Config&gt; IsoHeapImpl&lt;Config&gt;::takeFirstEligible(const LockHolder&amp; locker)</span>
 45 {
 46     if (m_isInlineDirectoryEligibleOrDecommitted) {
<span class="line-modified"> 47         EligibilityResult&lt;Config&gt; result = m_inlineDirectory.takeFirstEligible(locker);</span>
 48         if (result.kind == EligibilityKind::Full)
 49             m_isInlineDirectoryEligibleOrDecommitted = false;
 50         else
 51             return result;
 52     }
 53 
<span class="line-modified"> 54     {</span>
<span class="line-modified"> 55         auto* cursor = m_firstEligibleOrDecommitedDirectory.get();</span>
<span class="line-modified"> 56         if (!cursor) {</span>
<span class="line-modified"> 57             // If nothing is eligible, it can only be because we have no directories. It wouldn&#39;t be the end</span>
<span class="line-modified"> 58             // of the world if we broke this invariant. It would only mean that didBecomeEligibleOrDecommited() would need</span>
<span class="line-modified"> 59             // a null check.</span>
<span class="line-modified"> 60             RELEASE_BASSERT(!m_headDirectory.get());</span>
<span class="line-modified"> 61             RELEASE_BASSERT(!m_tailDirectory.get());</span>
<span class="line-modified"> 62         } else {</span>
<span class="line-modified"> 63             auto* originalCursor = cursor;</span>
<span class="line-modified"> 64             BUNUSED(originalCursor);</span>
<span class="line-modified"> 65             for (; cursor; cursor = cursor-&gt;next) {</span>
<span class="line-modified"> 66                 EligibilityResult&lt;Config&gt; result = cursor-&gt;payload.takeFirstEligible(locker);</span>
<span class="line-added"> 67                 // While iterating, m_firstEligibleOrDecommitedDirectory is never changed. We are holding a lock,</span>
<span class="line-added"> 68                 // and IsoDirectory::takeFirstEligible must not populate a new eligibile / decommitted pages.</span>
<span class="line-added"> 69                 BASSERT(m_firstEligibleOrDecommitedDirectory.get() == originalCursor);</span>
<span class="line-added"> 70                 if (result.kind != EligibilityKind::Full) {</span>
<span class="line-added"> 71                     m_directoryHighWatermark = std::max(m_directoryHighWatermark, cursor-&gt;index());</span>
<span class="line-added"> 72                     m_firstEligibleOrDecommitedDirectory = cursor;</span>
<span class="line-added"> 73                     return result;</span>
<span class="line-added"> 74                 }</span>
<span class="line-added"> 75             }</span>
<span class="line-added"> 76             m_firstEligibleOrDecommitedDirectory = nullptr;</span>
 77         }
 78     }
 79 
 80     auto* newDirectory = new IsoDirectoryPage&lt;Config&gt;(*this, m_nextDirectoryPageIndex++);
<span class="line-modified"> 81     if (m_headDirectory.get()) {</span>
 82         m_tailDirectory-&gt;next = newDirectory;
 83         m_tailDirectory = newDirectory;
 84     } else {
<span class="line-modified"> 85         RELEASE_BASSERT(!m_tailDirectory.get());</span>
 86         m_headDirectory = newDirectory;
 87         m_tailDirectory = newDirectory;
 88     }
 89     m_directoryHighWatermark = newDirectory-&gt;index();
 90     m_firstEligibleOrDecommitedDirectory = newDirectory;
<span class="line-modified"> 91     EligibilityResult&lt;Config&gt; result = newDirectory-&gt;payload.takeFirstEligible(locker);</span>
 92     RELEASE_BASSERT(result.kind != EligibilityKind::Full);
 93     return result;
 94 }
 95 
 96 template&lt;typename Config&gt;
<span class="line-modified"> 97 void IsoHeapImpl&lt;Config&gt;::didBecomeEligibleOrDecommited(const LockHolder&amp;, IsoDirectory&lt;Config, numPagesInInlineDirectory&gt;* directory)</span>
 98 {
 99     RELEASE_BASSERT(directory == &amp;m_inlineDirectory);
100     m_isInlineDirectoryEligibleOrDecommitted = true;
101 }
102 
103 template&lt;typename Config&gt;
<span class="line-modified">104 void IsoHeapImpl&lt;Config&gt;::didBecomeEligibleOrDecommited(const LockHolder&amp;, IsoDirectory&lt;Config, IsoDirectoryPage&lt;Config&gt;::numPages&gt;* directory)</span>
105 {
106     RELEASE_BASSERT(m_firstEligibleOrDecommitedDirectory);
107     auto* directoryPage = IsoDirectoryPage&lt;Config&gt;::pageFor(directory);
108     if (directoryPage-&gt;index() &lt; m_firstEligibleOrDecommitedDirectory-&gt;index())
109         m_firstEligibleOrDecommitedDirectory = directoryPage;
110 }
111 
112 template&lt;typename Config&gt;
113 void IsoHeapImpl&lt;Config&gt;::scavenge(Vector&lt;DeferredDecommit&gt;&amp; decommits)
114 {
<span class="line-modified">115     LockHolder locker(this-&gt;lock);</span>
116     forEachDirectory(
<span class="line-added">117         locker,</span>
118         [&amp;] (auto&amp; directory) {
<span class="line-modified">119             directory.scavenge(locker, decommits);</span>
120         });
121     m_directoryHighWatermark = 0;
122 }
123 
<span class="line-added">124 #if BUSE(PARTIAL_SCAVENGE)</span>
125 template&lt;typename Config&gt;
<span class="line-modified">126 void IsoHeapImpl&lt;Config&gt;::scavengeToHighWatermark(Vector&lt;DeferredDecommit&gt;&amp; decommits)</span>
<span class="line-added">127 {</span>
<span class="line-added">128     LockHolder locker(this-&gt;lock);</span>
<span class="line-added">129     if (!m_directoryHighWatermark)</span>
<span class="line-added">130         m_inlineDirectory.scavengeToHighWatermark(locker, decommits);</span>
<span class="line-added">131     for (IsoDirectoryPage&lt;Config&gt;* page = m_headDirectory.get(); page; page = page-&gt;next) {</span>
<span class="line-added">132         if (page-&gt;index() &gt;= m_directoryHighWatermark)</span>
<span class="line-added">133             page-&gt;payload.scavengeToHighWatermark(locker, decommits);</span>
<span class="line-added">134     }</span>
<span class="line-added">135     m_directoryHighWatermark = 0;</span>
<span class="line-added">136 }</span>
<span class="line-added">137 #endif</span>
<span class="line-added">138 </span>
<span class="line-added">139 inline size_t IsoHeapImplBase::freeableMemory()</span>
140 {
141     return m_freeableMemory;
142 }
143 
144 template&lt;typename Config&gt;
145 unsigned IsoHeapImpl&lt;Config&gt;::allocatorOffset()
146 {
<span class="line-modified">147     return m_allocator-&gt;offset();</span>
148 }
149 
150 template&lt;typename Config&gt;
151 unsigned IsoHeapImpl&lt;Config&gt;::deallocatorOffset()
152 {
<span class="line-modified">153     return (*PerProcess&lt;IsoTLSEntryHolder&lt;IsoTLSDeallocatorEntry&lt;Config&gt;&gt;&gt;::get())-&gt;offset();</span>
154 }
155 
156 template&lt;typename Config&gt;
157 unsigned IsoHeapImpl&lt;Config&gt;::numLiveObjects()
158 {
<span class="line-added">159     LockHolder locker(this-&gt;lock);</span>
160     unsigned result = 0;
161     forEachLiveObject(
<span class="line-added">162         locker,</span>
163         [&amp;] (void*) {
164             result++;
165         });
166     return result;
167 }
168 
169 template&lt;typename Config&gt;
170 unsigned IsoHeapImpl&lt;Config&gt;::numCommittedPages()
171 {
<span class="line-added">172     LockHolder locker(this-&gt;lock);</span>
173     unsigned result = 0;
174     forEachCommittedPage(
<span class="line-added">175         locker,</span>
176         [&amp;] (IsoPage&lt;Config&gt;&amp;) {
177             result++;
178         });
179     return result;
180 }
181 
182 template&lt;typename Config&gt;
183 template&lt;typename Func&gt;
<span class="line-modified">184 void IsoHeapImpl&lt;Config&gt;::forEachDirectory(const LockHolder&amp;, const Func&amp; func)</span>
185 {
186     func(m_inlineDirectory);
<span class="line-modified">187     for (IsoDirectoryPage&lt;Config&gt;* page = m_headDirectory.get(); page; page = page-&gt;next)</span>
188         func(page-&gt;payload);
189 }
190 
191 template&lt;typename Config&gt;
192 template&lt;typename Func&gt;
<span class="line-modified">193 void IsoHeapImpl&lt;Config&gt;::forEachCommittedPage(const LockHolder&amp; locker, const Func&amp; func)</span>
194 {
195     forEachDirectory(
<span class="line-added">196         locker,</span>
197         [&amp;] (auto&amp; directory) {
<span class="line-modified">198             directory.forEachCommittedPage(locker, func);</span>
199         });
200 }
201 
202 template&lt;typename Config&gt;
203 template&lt;typename Func&gt;
<span class="line-modified">204 void IsoHeapImpl&lt;Config&gt;::forEachLiveObject(const LockHolder&amp; locker, const Func&amp; func)</span>
205 {
206     forEachCommittedPage(
<span class="line-added">207         locker,</span>
208         [&amp;] (IsoPage&lt;Config&gt;&amp; page) {
<span class="line-modified">209             page.forEachLiveObject(locker, func);</span>
210         });
211     for (unsigned index = 0; index &lt; maxAllocationFromShared; ++index) {
<span class="line-modified">212         void* pointer = m_sharedCells[index].get();</span>
213         if (pointer &amp;&amp; !(m_availableShared &amp; (1U &lt;&lt; index)))
214             func(pointer);
215     }
216 }
217 
<span class="line-modified">218 inline size_t IsoHeapImplBase::footprint()</span>

219 {
220 #if ENABLE_PHYSICAL_PAGE_MAP
221     RELEASE_BASSERT(m_footprint == m_physicalPageMap.footprint());
222 #endif
223     return m_footprint;
224 }
225 
<span class="line-modified">226 inline void IsoHeapImplBase::didCommit(void* ptr, size_t bytes)</span>

227 {
228     BUNUSED_PARAM(ptr);
229     m_footprint += bytes;
230 #if ENABLE_PHYSICAL_PAGE_MAP
231     m_physicalPageMap.commit(ptr, bytes);
232 #endif
233 }
234 
<span class="line-modified">235 inline void IsoHeapImplBase::didDecommit(void* ptr, size_t bytes)</span>

236 {
237     BUNUSED_PARAM(ptr);
238     m_footprint -= bytes;
239 #if ENABLE_PHYSICAL_PAGE_MAP
240     m_physicalPageMap.decommit(ptr, bytes);
241 #endif
242 }
243 
<span class="line-modified">244 inline void IsoHeapImplBase::isNowFreeable(void* ptr, size_t bytes)</span>

245 {
246     BUNUSED_PARAM(ptr);
247     m_freeableMemory += bytes;
248 }
249 
<span class="line-modified">250 inline void IsoHeapImplBase::isNoLongerFreeable(void* ptr, size_t bytes)</span>

251 {
252     BUNUSED_PARAM(ptr);
253     m_freeableMemory -= bytes;
254 }
255 
256 template&lt;typename Config&gt;
257 AllocationMode IsoHeapImpl&lt;Config&gt;::updateAllocationMode()
258 {
259     auto getNewAllocationMode = [&amp;] {
260         // Exhaust shared free cells, which means we should start activating the fast allocation mode for this type.
261         if (!m_availableShared) {
262             m_lastSlowPathTime = std::chrono::steady_clock::now();
263             return AllocationMode::Fast;
264         }
265 
266         switch (m_allocationMode) {
267         case AllocationMode::Shared:
268             // Currently in the shared allocation mode. Until we exhaust shared free cells, continue using the shared allocation mode.
269             // But if we allocate so many shared cells within very short period, we should use the fast allocation mode instead.
270             // This avoids the following pathological case.
</pre>
<hr />
<pre>
288             }
289 
290             m_numberOfAllocationsFromSharedInOneCycle = 0;
291             m_lastSlowPathTime = now;
292             return AllocationMode::Shared;
293         }
294 
295         case AllocationMode::Init:
296             m_lastSlowPathTime = std::chrono::steady_clock::now();
297             return AllocationMode::Shared;
298         }
299 
300         return AllocationMode::Shared;
301     };
302     AllocationMode allocationMode = getNewAllocationMode();
303     m_allocationMode = allocationMode;
304     return allocationMode;
305 }
306 
307 template&lt;typename Config&gt;
<span class="line-modified">308 void* IsoHeapImpl&lt;Config&gt;::allocateFromShared(const LockHolder&amp;, bool abortOnFailure)</span>
309 {
310     static constexpr bool verbose = false;
311 
312     unsigned indexPlusOne = __builtin_ffs(m_availableShared);
313     BASSERT(indexPlusOne);
314     unsigned index = indexPlusOne - 1;
<span class="line-modified">315     void* result = m_sharedCells[index].get();</span>
316     if (result) {
317         if (verbose)
318             fprintf(stderr, &quot;%p: allocated %p from shared again of size %u\n&quot;, this, result, Config::objectSize);
319     } else {
320         constexpr unsigned objectSizeWithHeapImplPointer = Config::objectSize + sizeof(uint8_t);
321         result = IsoSharedHeap::get()-&gt;allocateNew&lt;objectSizeWithHeapImplPointer&gt;(abortOnFailure);
322         if (!result)
323             return nullptr;
324         if (verbose)
325             fprintf(stderr, &quot;%p: allocated %p from shared of size %u\n&quot;, this, result, Config::objectSize);
326         BASSERT(index &lt; IsoHeapImplBase::maxAllocationFromShared);
327         *indexSlotFor&lt;Config&gt;(result) = index;
<span class="line-modified">328         m_sharedCells[index] = bitwise_cast&lt;uint8_t*&gt;(result);</span>
329     }
330     BASSERT(result);
331     m_availableShared &amp;= ~(1U &lt;&lt; index);
332     ++m_numberOfAllocationsFromSharedInOneCycle;
333     return result;
334 }
335 
336 } // namespace bmalloc
337 
</pre>
</td>
</tr>
</table>
<center><a href="IsoHeapImpl.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="IsoHeapInlines.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>