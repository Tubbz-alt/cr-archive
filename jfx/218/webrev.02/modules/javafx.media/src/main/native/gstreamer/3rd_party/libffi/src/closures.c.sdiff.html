<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.media/src/main/native/gstreamer/3rd_party/libffi/src/closures.c</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="../include/ffitarget.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="dlmalloc.c.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.media/src/main/native/gstreamer/3rd_party/libffi/src/closures.c</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /* -----------------------------------------------------------------------
<span class="line-modified">   2    closures.c - Copyright (c) 2007, 2009, 2010  Red Hat, Inc.</span>

   3                 Copyright (C) 2007, 2009, 2010 Free Software Foundation, Inc
   4                 Copyright (c) 2011 Plausible Labs Cooperative, Inc.
   5 
   6    Code to allocate and deallocate memory for closures.
   7 
   8    Permission is hereby granted, free of charge, to any person obtaining
   9    a copy of this software and associated documentation files (the
  10    ``Software&#39;&#39;), to deal in the Software without restriction, including
  11    without limitation the rights to use, copy, modify, merge, publish,
  12    distribute, sublicense, and/or sell copies of the Software, and to
  13    permit persons to whom the Software is furnished to do so, subject to
  14    the following conditions:
  15 
  16    The above copyright notice and this permission notice shall be included
  17    in all copies or substantial portions of the Software.
  18 
  19    THE SOFTWARE IS PROVIDED ``AS IS&#39;&#39;, WITHOUT WARRANTY OF ANY KIND,
  20    EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
  21    MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
  22    NONINFRINGEMENT.  IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
  23    HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
  24    WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
  25    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
  26    DEALINGS IN THE SOFTWARE.
  27    ----------------------------------------------------------------------- */
  28 
  29 #if defined __linux__ &amp;&amp; !defined _GNU_SOURCE
  30 #define _GNU_SOURCE 1
  31 #endif
  32 

  33 #include &lt;ffi.h&gt;
  34 #include &lt;ffi_common.h&gt;
  35 












































































  36 #if !FFI_MMAP_EXEC_WRIT &amp;&amp; !FFI_EXEC_TRAMPOLINE_TABLE
<span class="line-modified">  37 # if __gnu_linux__ &amp;&amp; !defined(__ANDROID__)</span>
  38 /* This macro indicates it may be forbidden to map anonymous memory
  39    with both write and execute permission.  Code compiled when this
  40    option is defined will attempt to map such pages once, but if it
  41    fails, it falls back to creating a temporary file in a writable and
  42    executable filesystem and mapping pages from it into separate
  43    locations in the virtual memory space, one location writable and
  44    another executable.  */
  45 #  define FFI_MMAP_EXEC_WRIT 1
  46 #  define HAVE_MNTENT 1
  47 # endif
<span class="line-modified">  48 # if defined(X86_WIN32) || defined(X86_WIN64) || defined(__OS2__)</span>
  49 /* Windows systems may have Data Execution Protection (DEP) enabled,
  50    which requires the use of VirtualMalloc/VirtualFree to alloc/free
  51    executable memory. */
  52 #  define FFI_MMAP_EXEC_WRIT 1
  53 # endif
  54 #endif
  55 
  56 #if FFI_MMAP_EXEC_WRIT &amp;&amp; !defined FFI_MMAP_EXEC_SELINUX
<span class="line-modified">  57 # ifdef __linux__</span>
  58 /* When defined to 1 check for SELinux and if SELinux is active,
  59    don&#39;t attempt PROT_EXEC|PROT_WRITE mapping at all, as that
  60    might cause audit messages.  */
  61 #  define FFI_MMAP_EXEC_SELINUX 1
  62 # endif
  63 #endif
  64 
  65 #if FFI_CLOSURES
  66 
<span class="line-modified">  67 # if FFI_EXEC_TRAMPOLINE_TABLE</span>













































































































































































































  68 
  69 // Per-target implementation; It&#39;s unclear what can reasonable be shared between two OS/architecture implementations.
  70 
<span class="line-modified">  71 # elif FFI_MMAP_EXEC_WRIT /* !FFI_EXEC_TRAMPOLINE_TABLE */</span>
  72 
  73 #define USE_LOCKS 1
  74 #define USE_DL_PREFIX 1
  75 #ifdef __GNUC__
  76 #ifndef USE_BUILTIN_FFS
  77 #define USE_BUILTIN_FFS 1
  78 #endif
  79 #endif
  80 
  81 /* We need to use mmap, not sbrk.  */
  82 #define HAVE_MORECORE 0
  83 
  84 /* We could, in theory, support mremap, but it wouldn&#39;t buy us anything.  */
  85 #define HAVE_MREMAP 0
  86 
  87 /* We have no use for this, so save some code and data.  */
  88 #define NO_MALLINFO 1
  89 
  90 /* We need all allocations to be in regular segments, otherwise we
  91    lose track of the corresponding code address.  */
  92 #define DEFAULT_MMAP_THRESHOLD MAX_SIZE_T
  93 
  94 /* Don&#39;t allocate more than a page unless needed.  */
  95 #define DEFAULT_GRANULARITY ((size_t)malloc_getpagesize)
  96 
<span class="line-removed">  97 #if FFI_CLOSURE_TEST</span>
<span class="line-removed">  98 /* Don&#39;t release single pages, to avoid a worst-case scenario of</span>
<span class="line-removed">  99    continuously allocating and releasing single pages, but release</span>
<span class="line-removed"> 100    pairs of pages, which should do just as well given that allocations</span>
<span class="line-removed"> 101    are likely to be small.  */</span>
<span class="line-removed"> 102 #define DEFAULT_TRIM_THRESHOLD ((size_t)malloc_getpagesize)</span>
<span class="line-removed"> 103 #endif</span>
<span class="line-removed"> 104 </span>
 105 #include &lt;sys/types.h&gt;
 106 #include &lt;sys/stat.h&gt;
 107 #include &lt;fcntl.h&gt;
 108 #include &lt;errno.h&gt;
 109 #ifndef _MSC_VER
 110 #include &lt;unistd.h&gt;
 111 #endif
 112 #include &lt;string.h&gt;
 113 #include &lt;stdio.h&gt;
<span class="line-modified"> 114 #if !defined(X86_WIN32) &amp;&amp; !defined(X86_WIN64)</span>
 115 #ifdef HAVE_MNTENT
 116 #include &lt;mntent.h&gt;
 117 #endif /* HAVE_MNTENT */
 118 #include &lt;sys/param.h&gt;
 119 #include &lt;pthread.h&gt;
 120 
 121 /* We don&#39;t want sys/mman.h to be included after we redefine mmap and
 122    dlmunmap.  */
 123 #include &lt;sys/mman.h&gt;
 124 #define LACKS_SYS_MMAN_H 1
 125 
 126 #if FFI_MMAP_EXEC_SELINUX
 127 #include &lt;sys/statfs.h&gt;
 128 #include &lt;stdlib.h&gt;
 129 
 130 static int selinux_enabled = -1;
 131 
 132 static int
 133 selinux_enabled_check (void)
 134 {
</pre>
<hr />
<pre>
 220 #define is_emutramp_enabled() 0
 221 #endif /* FFI_MMAP_EXEC_EMUTRAMP_PAX */
 222 
 223 /* Declare all functions defined in dlmalloc.c as static.  */
 224 static void *dlmalloc(size_t);
 225 static void dlfree(void*);
 226 static void *dlcalloc(size_t, size_t) MAYBE_UNUSED;
 227 static void *dlrealloc(void *, size_t) MAYBE_UNUSED;
 228 static void *dlmemalign(size_t, size_t) MAYBE_UNUSED;
 229 static void *dlvalloc(size_t) MAYBE_UNUSED;
 230 static int dlmallopt(int, int) MAYBE_UNUSED;
 231 static size_t dlmalloc_footprint(void) MAYBE_UNUSED;
 232 static size_t dlmalloc_max_footprint(void) MAYBE_UNUSED;
 233 static void** dlindependent_calloc(size_t, size_t, void**) MAYBE_UNUSED;
 234 static void** dlindependent_comalloc(size_t, size_t*, void**) MAYBE_UNUSED;
 235 static void *dlpvalloc(size_t) MAYBE_UNUSED;
 236 static int dlmalloc_trim(size_t) MAYBE_UNUSED;
 237 static size_t dlmalloc_usable_size(void*) MAYBE_UNUSED;
 238 static void dlmalloc_stats(void) MAYBE_UNUSED;
 239 
<span class="line-modified"> 240 #if !(defined(X86_WIN32) || defined(X86_WIN64) || defined(__OS2__)) || defined (__CYGWIN__) || defined(__INTERIX)</span>
 241 /* Use these for mmap and munmap within dlmalloc.c.  */
 242 static void *dlmmap(void *, size_t, int, int, int, off_t);
 243 static int dlmunmap(void *, size_t);
 244 #endif /* !(defined(X86_WIN32) || defined(X86_WIN64) || defined(__OS2__)) || defined (__CYGWIN__) || defined(__INTERIX) */
 245 
 246 #define mmap dlmmap
 247 #define munmap dlmunmap
 248 
 249 #include &quot;dlmalloc.c&quot;
 250 
 251 #undef mmap
 252 #undef munmap
 253 
<span class="line-modified"> 254 #if !(defined(X86_WIN32) || defined(X86_WIN64) || defined(__OS2__)) || defined (__CYGWIN__) || defined(__INTERIX)</span>
 255 
 256 /* A mutex used to synchronize access to *exec* variables in this file.  */
 257 static pthread_mutex_t open_temp_exec_file_mutex = PTHREAD_MUTEX_INITIALIZER;
 258 
 259 /* A file descriptor of a temporary file from which we&#39;ll map
 260    executable pages.  */
 261 static int execfd = -1;
 262 
 263 /* The amount of space already allocated from the temporary file.  */
 264 static size_t execsize = 0;
 265 
 266 /* Open a temporary file name, and immediately unlink it.  */
 267 static int
 268 open_temp_exec_file_name (char *name, int flags)
 269 {
 270   int fd;
 271 
 272 #ifdef HAVE_MKOSTEMP
 273   fd = mkostemp (name, flags);
 274 #else
</pre>
<hr />
<pre>
 291 #ifdef O_TMPFILE
 292   int fd;
 293 #endif
 294 
 295 #ifdef O_CLOEXEC
 296   flags = O_CLOEXEC;
 297 #else
 298   flags = 0;
 299 #endif
 300 
 301 #ifdef O_TMPFILE
 302   fd = open (dir, flags | O_RDWR | O_EXCL | O_TMPFILE, 0700);
 303   /* If the running system does not support the O_TMPFILE flag then retry without it. */
 304   if (fd != -1 || (errno != EINVAL &amp;&amp; errno != EISDIR &amp;&amp; errno != EOPNOTSUPP)) {
 305     return fd;
 306   } else {
 307     errno = 0;
 308   }
 309 #endif
 310 
<span class="line-modified"> 311   lendir = strlen (dir);</span>
 312   tempname = __builtin_alloca (lendir + sizeof (suffix));
 313 
 314   if (!tempname)
 315     return -1;
 316 
 317   memcpy (tempname, dir, lendir);
 318   memcpy (tempname + lendir, suffix, sizeof (suffix));
 319 
 320   return open_temp_exec_file_name (tempname, flags);
 321 }
 322 
 323 /* Open a temporary file in the directory in the named environment
 324    variable.  */
 325 static int
 326 open_temp_exec_file_env (const char *envvar)
 327 {
 328   const char *value = getenv (envvar);
 329 
 330   if (!value)
 331     return -1;
</pre>
<hr />
<pre>
 432 {
 433   int fd;
 434 
 435   do
 436     {
 437       fd = open_temp_exec_file_opts[open_temp_exec_file_opts_idx].func
 438     (open_temp_exec_file_opts[open_temp_exec_file_opts_idx].arg);
 439 
 440       if (!open_temp_exec_file_opts[open_temp_exec_file_opts_idx].repeat
 441       || fd == -1)
 442     {
 443       if (open_temp_exec_file_opts_next ())
 444         break;
 445     }
 446     }
 447   while (fd == -1);
 448 
 449   return fd;
 450 }
 451 






























 452 /* Map in a chunk of memory from the temporary exec file into separate
 453    locations in the virtual memory address space, one writable and one
 454    executable.  Returns the address of the writable portion, after
 455    storing an offset to the corresponding executable portion at the
 456    last word of the requested chunk.  */
 457 static void *
 458 dlmmap_locked (void *start, size_t length, int prot, int flags, off_t offset)
 459 {
 460   void *ptr;
 461 
 462   if (execfd == -1)
 463     {
 464       open_temp_exec_file_opts_idx = 0;
 465     retry_open:
 466       execfd = open_temp_exec_file ();
 467       if (execfd == -1)
 468     return MFAIL;
 469     }
 470 
 471   offset = execsize;
 472 
<span class="line-modified"> 473   if (ftruncate (execfd, offset + length))</span>
 474     return MFAIL;
 475 
 476   flags &amp;= ~(MAP_PRIVATE | MAP_ANONYMOUS);
 477   flags |= MAP_SHARED;
 478 
 479   ptr = mmap (NULL, length, (prot &amp; ~PROT_WRITE) | PROT_EXEC,
 480           flags, execfd, offset);
 481   if (ptr == MFAIL)
 482     {
 483       if (!offset)
 484     {
 485       close (execfd);
 486       goto retry_open;
 487     }
<span class="line-modified"> 488       ftruncate (execfd, offset);</span>






 489       return MFAIL;
 490     }
 491   else if (!offset
 492        &amp;&amp; open_temp_exec_file_opts[open_temp_exec_file_opts_idx].repeat)
 493     open_temp_exec_file_opts_next ();
 494 
 495   start = mmap (start, length, prot, flags, execfd, offset);
 496 
 497   if (start == MFAIL)
 498     {
 499       munmap (ptr, length);
<span class="line-modified"> 500       ftruncate (execfd, offset);</span>





 501       return start;
 502     }
 503 
 504   mmap_exec_offset ((char *)start, length) = (char*)ptr - (char*)start;
 505 
 506   execsize += length;
 507 
 508   return start;
 509 }
 510 
 511 /* Map in a writable and executable chunk of memory if possible.
 512    Failing that, fall back to dlmmap_locked.  */
 513 static void *
 514 dlmmap (void *start, size_t length, int prot,
 515     int flags, int fd, off_t offset)
 516 {
 517   void *ptr;
 518 
 519   assert (start == NULL &amp;&amp; length % malloc_getpagesize == 0
 520       &amp;&amp; prot == (PROT_READ | PROT_WRITE)
 521       &amp;&amp; flags == (MAP_PRIVATE | MAP_ANONYMOUS)
 522       &amp;&amp; fd == -1 &amp;&amp; offset == 0);
 523 
<span class="line-removed"> 524 #if FFI_CLOSURE_TEST</span>
<span class="line-removed"> 525   printf (&quot;mapping in %zi\n&quot;, length);</span>
<span class="line-removed"> 526 #endif</span>
<span class="line-removed"> 527 </span>
 528   if (execfd == -1 &amp;&amp; is_emutramp_enabled ())
 529     {
 530       ptr = mmap (start, length, prot &amp; ~PROT_EXEC, flags, fd, offset);
 531       return ptr;
 532     }
 533 
 534   if (execfd == -1 &amp;&amp; !is_selinux_enabled ())
 535     {
 536       ptr = mmap (start, length, prot | PROT_EXEC, flags, fd, offset);
 537 
 538       if (ptr != MFAIL || (errno != EPERM &amp;&amp; errno != EACCES))
 539     /* Cool, no need to mess with separate segments.  */
 540     return ptr;
 541 
 542       /* If MREMAP_DUP is ever introduced and implemented, try mmap
 543      with ((prot &amp; ~PROT_WRITE) | PROT_EXEC) and mremap with
 544      MREMAP_DUP and prot at this point.  */
 545     }
 546 
 547   if (execsize == 0 || execfd == -1)
</pre>
<hr />
<pre>
 553       return ptr;
 554     }
 555 
 556   return dlmmap_locked (start, length, prot, flags, offset);
 557 }
 558 
 559 /* Release memory at the given address, as well as the corresponding
 560    executable page if it&#39;s separate.  */
 561 static int
 562 dlmunmap (void *start, size_t length)
 563 {
 564   /* We don&#39;t bother decreasing execsize or truncating the file, since
 565      we can&#39;t quite tell whether we&#39;re unmapping the end of the file.
 566      We don&#39;t expect frequent deallocation anyway.  If we did, we
 567      could locate pages in the file by writing to the pages being
 568      deallocated and checking that the file contents change.
 569      Yuck.  */
 570   msegmentptr seg = segment_holding (gm, start);
 571   void *code;
 572 
<span class="line-removed"> 573 #if FFI_CLOSURE_TEST</span>
<span class="line-removed"> 574   printf (&quot;unmapping %zi\n&quot;, length);</span>
<span class="line-removed"> 575 #endif</span>
<span class="line-removed"> 576 </span>
 577   if (seg &amp;&amp; (code = add_segment_exec_offset (start, seg)) != start)
 578     {
 579       int ret = munmap (code, length);
 580       if (ret)
 581     return ret;
 582     }
 583 
 584   return munmap (start, length);
 585 }
 586 
 587 #if FFI_CLOSURE_FREE_CODE
 588 /* Return segment holding given code address.  */
 589 static msegmentptr
 590 segment_holding_code (mstate m, char* addr)
 591 {
 592   msegmentptr sp = &amp;m-&gt;seg;
 593   for (;;) {
 594     if (addr &gt;= add_segment_exec_offset (sp-&gt;base, sp)
 595     &amp;&amp; addr &lt; add_segment_exec_offset (sp-&gt;base, sp) + sp-&gt;size)
 596       return sp;
 597     if ((sp = sp-&gt;next) == 0)
 598       return 0;
 599   }
 600 }
 601 #endif
 602 
<span class="line-modified"> 603 #endif /* !(defined(X86_WIN32) || defined(X86_WIN64) || defined(__OS2__)) || defined (__CYGWIN__) || defined(__INTERIX) */</span>
 604 
 605 /* Allocate a chunk of memory with the given size.  Returns a pointer
 606    to the writable address, and sets *CODE to the executable
 607    corresponding virtual address.  */
 608 void *
 609 ffi_closure_alloc (size_t size, void **code)
 610 {
 611   void *ptr;
 612 
 613   if (!code)
 614     return NULL;
 615 
 616   ptr = dlmalloc (size);
 617 
 618   if (ptr)
 619     {
 620       msegmentptr seg = segment_holding (gm, ptr);
 621 #ifdef GSTREAMER_LITE
 622       if (seg == NULL)
 623         return NULL;
 624 #endif // GSTREAMER_LITE
 625 
 626       *code = add_segment_exec_offset (ptr, seg);
 627     }
 628 
 629   return ptr;
 630 }
 631 














 632 /* Release a chunk of memory allocated with ffi_closure_alloc.  If
 633    FFI_CLOSURE_FREE_CODE is nonzero, the given address can be the
 634    writable or the executable address given.  Otherwise, only the
 635    writable address can be provided here.  */
 636 void
 637 ffi_closure_free (void *ptr)
 638 {
 639 #if FFI_CLOSURE_FREE_CODE
 640   msegmentptr seg = segment_holding_code (gm, ptr);
 641 
 642   if (seg)
 643     ptr = sub_segment_exec_offset (ptr, seg);
 644 #endif
 645 
 646   dlfree (ptr);
 647 }
 648 
<span class="line-removed"> 649 </span>
<span class="line-removed"> 650 #if FFI_CLOSURE_TEST</span>
<span class="line-removed"> 651 /* Do some internal sanity testing to make sure allocation and</span>
<span class="line-removed"> 652    deallocation of pages are working as intended.  */</span>
<span class="line-removed"> 653 int main ()</span>
<span class="line-removed"> 654 {</span>
<span class="line-removed"> 655   void *p[3];</span>
<span class="line-removed"> 656 #define GET(idx, len) do { p[idx] = dlmalloc (len); printf (&quot;allocated %zi for p[%i]\n&quot;, (len), (idx)); } while (0)</span>
<span class="line-removed"> 657 #define PUT(idx) do { printf (&quot;freeing p[%i]\n&quot;, (idx)); dlfree (p[idx]); } while (0)</span>
<span class="line-removed"> 658   GET (0, malloc_getpagesize / 2);</span>
<span class="line-removed"> 659   GET (1, 2 * malloc_getpagesize - 64 * sizeof (void*));</span>
<span class="line-removed"> 660   PUT (1);</span>
<span class="line-removed"> 661   GET (1, 2 * malloc_getpagesize);</span>
<span class="line-removed"> 662   GET (2, malloc_getpagesize / 2);</span>
<span class="line-removed"> 663   PUT (1);</span>
<span class="line-removed"> 664   PUT (0);</span>
<span class="line-removed"> 665   PUT (2);</span>
<span class="line-removed"> 666   return 0;</span>
<span class="line-removed"> 667 }</span>
<span class="line-removed"> 668 #endif /* FFI_CLOSURE_TEST */</span>
 669 # else /* ! FFI_MMAP_EXEC_WRIT */
 670 
 671 /* On many systems, memory returned by malloc is writable and
 672    executable, so just use it.  */
 673 
 674 #include &lt;stdlib.h&gt;
 675 
 676 void *
 677 ffi_closure_alloc (size_t size, void **code)
 678 {
 679   if (!code)
 680     return NULL;
 681 
 682   return *code = malloc (size);
 683 }
 684 
 685 void
 686 ffi_closure_free (void *ptr)
 687 {
 688   free (ptr);
 689 }
 690 






 691 # endif /* ! FFI_MMAP_EXEC_WRIT */
 692 #endif /* FFI_CLOSURES */


</pre>
</td>
<td>
<hr />
<pre>
   1 /* -----------------------------------------------------------------------
<span class="line-modified">   2    closures.c - Copyright (c) 2019 Anthony Green</span>
<span class="line-added">   3                 Copyright (c) 2007, 2009, 2010 Red Hat, Inc.</span>
   4                 Copyright (C) 2007, 2009, 2010 Free Software Foundation, Inc
   5                 Copyright (c) 2011 Plausible Labs Cooperative, Inc.
   6 
   7    Code to allocate and deallocate memory for closures.
   8 
   9    Permission is hereby granted, free of charge, to any person obtaining
  10    a copy of this software and associated documentation files (the
  11    ``Software&#39;&#39;), to deal in the Software without restriction, including
  12    without limitation the rights to use, copy, modify, merge, publish,
  13    distribute, sublicense, and/or sell copies of the Software, and to
  14    permit persons to whom the Software is furnished to do so, subject to
  15    the following conditions:
  16 
  17    The above copyright notice and this permission notice shall be included
  18    in all copies or substantial portions of the Software.
  19 
  20    THE SOFTWARE IS PROVIDED ``AS IS&#39;&#39;, WITHOUT WARRANTY OF ANY KIND,
  21    EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
  22    MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
  23    NONINFRINGEMENT.  IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
  24    HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
  25    WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
  26    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
  27    DEALINGS IN THE SOFTWARE.
  28    ----------------------------------------------------------------------- */
  29 
  30 #if defined __linux__ &amp;&amp; !defined _GNU_SOURCE
  31 #define _GNU_SOURCE 1
  32 #endif
  33 
<span class="line-added">  34 #include &lt;fficonfig.h&gt;</span>
  35 #include &lt;ffi.h&gt;
  36 #include &lt;ffi_common.h&gt;
  37 
<span class="line-added">  38 #ifdef __NetBSD__</span>
<span class="line-added">  39 #include &lt;sys/param.h&gt;</span>
<span class="line-added">  40 #endif</span>
<span class="line-added">  41 </span>
<span class="line-added">  42 #if __NetBSD_Version__ - 0 &gt;= 799007200</span>
<span class="line-added">  43 /* NetBSD with PROT_MPROTECT */</span>
<span class="line-added">  44 #include &lt;sys/mman.h&gt;</span>
<span class="line-added">  45 </span>
<span class="line-added">  46 #include &lt;stddef.h&gt;</span>
<span class="line-added">  47 #include &lt;unistd.h&gt;</span>
<span class="line-added">  48 </span>
<span class="line-added">  49 static const size_t overhead =</span>
<span class="line-added">  50   (sizeof(max_align_t) &gt; sizeof(void *) + sizeof(size_t)) ?</span>
<span class="line-added">  51     sizeof(max_align_t)</span>
<span class="line-added">  52     : sizeof(void *) + sizeof(size_t);</span>
<span class="line-added">  53 </span>
<span class="line-added">  54 #define ADD_TO_POINTER(p, d) ((void *)((uintptr_t)(p) + (d)))</span>
<span class="line-added">  55 </span>
<span class="line-added">  56 void *</span>
<span class="line-added">  57 ffi_closure_alloc (size_t size, void **code)</span>
<span class="line-added">  58 {</span>
<span class="line-added">  59   static size_t page_size;</span>
<span class="line-added">  60   size_t rounded_size;</span>
<span class="line-added">  61   void *codeseg, *dataseg;</span>
<span class="line-added">  62   int prot;</span>
<span class="line-added">  63 </span>
<span class="line-added">  64   /* Expect that PAX mprotect is active and a separate code mapping is necessary. */</span>
<span class="line-added">  65   if (!code)</span>
<span class="line-added">  66     return NULL;</span>
<span class="line-added">  67 </span>
<span class="line-added">  68   /* Obtain system page size. */</span>
<span class="line-added">  69   if (!page_size)</span>
<span class="line-added">  70     page_size = sysconf(_SC_PAGESIZE);</span>
<span class="line-added">  71 </span>
<span class="line-added">  72   /* Round allocation size up to the next page, keeping in mind the size field and pointer to code map. */</span>
<span class="line-added">  73   rounded_size = (size + overhead + page_size - 1) &amp; ~(page_size - 1);</span>
<span class="line-added">  74 </span>
<span class="line-added">  75   /* Primary mapping is RW, but request permission to switch to PROT_EXEC later. */</span>
<span class="line-added">  76   prot = PROT_READ | PROT_WRITE | PROT_MPROTECT(PROT_EXEC);</span>
<span class="line-added">  77   dataseg = mmap(NULL, rounded_size, prot, MAP_ANON | MAP_PRIVATE, -1, 0);</span>
<span class="line-added">  78   if (dataseg == MAP_FAILED)</span>
<span class="line-added">  79     return NULL;</span>
<span class="line-added">  80 </span>
<span class="line-added">  81   /* Create secondary mapping and switch it to RX. */</span>
<span class="line-added">  82   codeseg = mremap(dataseg, rounded_size, NULL, rounded_size, MAP_REMAPDUP);</span>
<span class="line-added">  83   if (codeseg == MAP_FAILED) {</span>
<span class="line-added">  84     munmap(dataseg, rounded_size);</span>
<span class="line-added">  85     return NULL;</span>
<span class="line-added">  86   }</span>
<span class="line-added">  87   if (mprotect(codeseg, rounded_size, PROT_READ | PROT_EXEC) == -1) {</span>
<span class="line-added">  88     munmap(codeseg, rounded_size);</span>
<span class="line-added">  89     munmap(dataseg, rounded_size);</span>
<span class="line-added">  90     return NULL;</span>
<span class="line-added">  91   }</span>
<span class="line-added">  92 </span>
<span class="line-added">  93   /* Remember allocation size and location of the secondary mapping for ffi_closure_free. */</span>
<span class="line-added">  94   memcpy(dataseg, &amp;rounded_size, sizeof(rounded_size));</span>
<span class="line-added">  95   memcpy(ADD_TO_POINTER(dataseg, sizeof(size_t)), &amp;codeseg, sizeof(void *));</span>
<span class="line-added">  96   *code = ADD_TO_POINTER(codeseg, overhead);</span>
<span class="line-added">  97   return ADD_TO_POINTER(dataseg, overhead);</span>
<span class="line-added">  98 }</span>
<span class="line-added">  99 </span>
<span class="line-added"> 100 void</span>
<span class="line-added"> 101 ffi_closure_free (void *ptr)</span>
<span class="line-added"> 102 {</span>
<span class="line-added"> 103   void *codeseg, *dataseg;</span>
<span class="line-added"> 104   size_t rounded_size;</span>
<span class="line-added"> 105 </span>
<span class="line-added"> 106   dataseg = ADD_TO_POINTER(ptr, -overhead);</span>
<span class="line-added"> 107   memcpy(&amp;rounded_size, dataseg, sizeof(rounded_size));</span>
<span class="line-added"> 108   memcpy(&amp;codeseg, ADD_TO_POINTER(dataseg, sizeof(size_t)), sizeof(void *));</span>
<span class="line-added"> 109   munmap(dataseg, rounded_size);</span>
<span class="line-added"> 110   munmap(codeseg, rounded_size);</span>
<span class="line-added"> 111 }</span>
<span class="line-added"> 112 #else /* !NetBSD with PROT_MPROTECT */</span>
<span class="line-added"> 113 </span>
 114 #if !FFI_MMAP_EXEC_WRIT &amp;&amp; !FFI_EXEC_TRAMPOLINE_TABLE
<span class="line-modified"> 115 # if __linux__ &amp;&amp; !defined(__ANDROID__)</span>
 116 /* This macro indicates it may be forbidden to map anonymous memory
 117    with both write and execute permission.  Code compiled when this
 118    option is defined will attempt to map such pages once, but if it
 119    fails, it falls back to creating a temporary file in a writable and
 120    executable filesystem and mapping pages from it into separate
 121    locations in the virtual memory space, one location writable and
 122    another executable.  */
 123 #  define FFI_MMAP_EXEC_WRIT 1
 124 #  define HAVE_MNTENT 1
 125 # endif
<span class="line-modified"> 126 # if defined(X86_WIN32) || defined(X86_WIN64) || defined(_M_ARM64) || defined(__OS2__)</span>
 127 /* Windows systems may have Data Execution Protection (DEP) enabled,
 128    which requires the use of VirtualMalloc/VirtualFree to alloc/free
 129    executable memory. */
 130 #  define FFI_MMAP_EXEC_WRIT 1
 131 # endif
 132 #endif
 133 
 134 #if FFI_MMAP_EXEC_WRIT &amp;&amp; !defined FFI_MMAP_EXEC_SELINUX
<span class="line-modified"> 135 # if defined(__linux__) &amp;&amp; !defined(__ANDROID__)</span>
 136 /* When defined to 1 check for SELinux and if SELinux is active,
 137    don&#39;t attempt PROT_EXEC|PROT_WRITE mapping at all, as that
 138    might cause audit messages.  */
 139 #  define FFI_MMAP_EXEC_SELINUX 1
 140 # endif
 141 #endif
 142 
 143 #if FFI_CLOSURES
 144 
<span class="line-modified"> 145 #if FFI_EXEC_TRAMPOLINE_TABLE</span>
<span class="line-added"> 146 </span>
<span class="line-added"> 147 #ifdef __MACH__</span>
<span class="line-added"> 148 </span>
<span class="line-added"> 149 #include &lt;mach/mach.h&gt;</span>
<span class="line-added"> 150 #include &lt;pthread.h&gt;</span>
<span class="line-added"> 151 #include &lt;stdio.h&gt;</span>
<span class="line-added"> 152 #include &lt;stdlib.h&gt;</span>
<span class="line-added"> 153 </span>
<span class="line-added"> 154 extern void *ffi_closure_trampoline_table_page;</span>
<span class="line-added"> 155 </span>
<span class="line-added"> 156 typedef struct ffi_trampoline_table ffi_trampoline_table;</span>
<span class="line-added"> 157 typedef struct ffi_trampoline_table_entry ffi_trampoline_table_entry;</span>
<span class="line-added"> 158 </span>
<span class="line-added"> 159 struct ffi_trampoline_table</span>
<span class="line-added"> 160 {</span>
<span class="line-added"> 161   /* contiguous writable and executable pages */</span>
<span class="line-added"> 162   vm_address_t config_page;</span>
<span class="line-added"> 163   vm_address_t trampoline_page;</span>
<span class="line-added"> 164 </span>
<span class="line-added"> 165   /* free list tracking */</span>
<span class="line-added"> 166   uint16_t free_count;</span>
<span class="line-added"> 167   ffi_trampoline_table_entry *free_list;</span>
<span class="line-added"> 168   ffi_trampoline_table_entry *free_list_pool;</span>
<span class="line-added"> 169 </span>
<span class="line-added"> 170   ffi_trampoline_table *prev;</span>
<span class="line-added"> 171   ffi_trampoline_table *next;</span>
<span class="line-added"> 172 };</span>
<span class="line-added"> 173 </span>
<span class="line-added"> 174 struct ffi_trampoline_table_entry</span>
<span class="line-added"> 175 {</span>
<span class="line-added"> 176   void *(*trampoline) (void);</span>
<span class="line-added"> 177   ffi_trampoline_table_entry *next;</span>
<span class="line-added"> 178 };</span>
<span class="line-added"> 179 </span>
<span class="line-added"> 180 /* Total number of trampolines that fit in one trampoline table */</span>
<span class="line-added"> 181 #define FFI_TRAMPOLINE_COUNT (PAGE_MAX_SIZE / FFI_TRAMPOLINE_SIZE)</span>
<span class="line-added"> 182 </span>
<span class="line-added"> 183 static pthread_mutex_t ffi_trampoline_lock = PTHREAD_MUTEX_INITIALIZER;</span>
<span class="line-added"> 184 static ffi_trampoline_table *ffi_trampoline_tables = NULL;</span>
<span class="line-added"> 185 </span>
<span class="line-added"> 186 static ffi_trampoline_table *</span>
<span class="line-added"> 187 ffi_trampoline_table_alloc (void)</span>
<span class="line-added"> 188 {</span>
<span class="line-added"> 189   ffi_trampoline_table *table;</span>
<span class="line-added"> 190   vm_address_t config_page;</span>
<span class="line-added"> 191   vm_address_t trampoline_page;</span>
<span class="line-added"> 192   vm_address_t trampoline_page_template;</span>
<span class="line-added"> 193   vm_prot_t cur_prot;</span>
<span class="line-added"> 194   vm_prot_t max_prot;</span>
<span class="line-added"> 195   kern_return_t kt;</span>
<span class="line-added"> 196   uint16_t i;</span>
<span class="line-added"> 197 </span>
<span class="line-added"> 198   /* Allocate two pages -- a config page and a placeholder page */</span>
<span class="line-added"> 199   config_page = 0x0;</span>
<span class="line-added"> 200   kt = vm_allocate (mach_task_self (), &amp;config_page, PAGE_MAX_SIZE * 2,</span>
<span class="line-added"> 201             VM_FLAGS_ANYWHERE);</span>
<span class="line-added"> 202   if (kt != KERN_SUCCESS)</span>
<span class="line-added"> 203     return NULL;</span>
<span class="line-added"> 204 </span>
<span class="line-added"> 205   /* Remap the trampoline table on top of the placeholder page */</span>
<span class="line-added"> 206   trampoline_page = config_page + PAGE_MAX_SIZE;</span>
<span class="line-added"> 207   trampoline_page_template = (vm_address_t)&amp;ffi_closure_trampoline_table_page;</span>
<span class="line-added"> 208 #ifdef __arm__</span>
<span class="line-added"> 209   /* ffi_closure_trampoline_table_page can be thumb-biased on some ARM archs */</span>
<span class="line-added"> 210   trampoline_page_template &amp;= ~1UL;</span>
<span class="line-added"> 211 #endif</span>
<span class="line-added"> 212   kt = vm_remap (mach_task_self (), &amp;trampoline_page, PAGE_MAX_SIZE, 0x0,</span>
<span class="line-added"> 213          VM_FLAGS_OVERWRITE, mach_task_self (), trampoline_page_template,</span>
<span class="line-added"> 214          FALSE, &amp;cur_prot, &amp;max_prot, VM_INHERIT_SHARE);</span>
<span class="line-added"> 215   if (kt != KERN_SUCCESS)</span>
<span class="line-added"> 216     {</span>
<span class="line-added"> 217       vm_deallocate (mach_task_self (), config_page, PAGE_MAX_SIZE * 2);</span>
<span class="line-added"> 218       return NULL;</span>
<span class="line-added"> 219     }</span>
<span class="line-added"> 220 </span>
<span class="line-added"> 221   /* We have valid trampoline and config pages */</span>
<span class="line-added"> 222   table = calloc (1, sizeof (ffi_trampoline_table));</span>
<span class="line-added"> 223   table-&gt;free_count = FFI_TRAMPOLINE_COUNT;</span>
<span class="line-added"> 224   table-&gt;config_page = config_page;</span>
<span class="line-added"> 225   table-&gt;trampoline_page = trampoline_page;</span>
<span class="line-added"> 226 </span>
<span class="line-added"> 227   /* Create and initialize the free list */</span>
<span class="line-added"> 228   table-&gt;free_list_pool =</span>
<span class="line-added"> 229     calloc (FFI_TRAMPOLINE_COUNT, sizeof (ffi_trampoline_table_entry));</span>
<span class="line-added"> 230 </span>
<span class="line-added"> 231   for (i = 0; i &lt; table-&gt;free_count; i++)</span>
<span class="line-added"> 232     {</span>
<span class="line-added"> 233       ffi_trampoline_table_entry *entry = &amp;table-&gt;free_list_pool[i];</span>
<span class="line-added"> 234       entry-&gt;trampoline =</span>
<span class="line-added"> 235     (void *) (table-&gt;trampoline_page + (i * FFI_TRAMPOLINE_SIZE));</span>
<span class="line-added"> 236 </span>
<span class="line-added"> 237       if (i &lt; table-&gt;free_count - 1)</span>
<span class="line-added"> 238     entry-&gt;next = &amp;table-&gt;free_list_pool[i + 1];</span>
<span class="line-added"> 239     }</span>
<span class="line-added"> 240 </span>
<span class="line-added"> 241   table-&gt;free_list = table-&gt;free_list_pool;</span>
<span class="line-added"> 242 </span>
<span class="line-added"> 243   return table;</span>
<span class="line-added"> 244 }</span>
<span class="line-added"> 245 </span>
<span class="line-added"> 246 static void</span>
<span class="line-added"> 247 ffi_trampoline_table_free (ffi_trampoline_table *table)</span>
<span class="line-added"> 248 {</span>
<span class="line-added"> 249   /* Remove from the list */</span>
<span class="line-added"> 250   if (table-&gt;prev != NULL)</span>
<span class="line-added"> 251     table-&gt;prev-&gt;next = table-&gt;next;</span>
<span class="line-added"> 252 </span>
<span class="line-added"> 253   if (table-&gt;next != NULL)</span>
<span class="line-added"> 254     table-&gt;next-&gt;prev = table-&gt;prev;</span>
<span class="line-added"> 255 </span>
<span class="line-added"> 256   /* Deallocate pages */</span>
<span class="line-added"> 257   vm_deallocate (mach_task_self (), table-&gt;config_page, PAGE_MAX_SIZE * 2);</span>
<span class="line-added"> 258 </span>
<span class="line-added"> 259   /* Deallocate free list */</span>
<span class="line-added"> 260   free (table-&gt;free_list_pool);</span>
<span class="line-added"> 261   free (table);</span>
<span class="line-added"> 262 }</span>
<span class="line-added"> 263 </span>
<span class="line-added"> 264 void *</span>
<span class="line-added"> 265 ffi_closure_alloc (size_t size, void **code)</span>
<span class="line-added"> 266 {</span>
<span class="line-added"> 267   /* Create the closure */</span>
<span class="line-added"> 268   ffi_closure *closure = malloc (size);</span>
<span class="line-added"> 269   if (closure == NULL)</span>
<span class="line-added"> 270     return NULL;</span>
<span class="line-added"> 271 </span>
<span class="line-added"> 272   pthread_mutex_lock (&amp;ffi_trampoline_lock);</span>
<span class="line-added"> 273 </span>
<span class="line-added"> 274   /* Check for an active trampoline table with available entries. */</span>
<span class="line-added"> 275   ffi_trampoline_table *table = ffi_trampoline_tables;</span>
<span class="line-added"> 276   if (table == NULL || table-&gt;free_list == NULL)</span>
<span class="line-added"> 277     {</span>
<span class="line-added"> 278       table = ffi_trampoline_table_alloc ();</span>
<span class="line-added"> 279       if (table == NULL)</span>
<span class="line-added"> 280     {</span>
<span class="line-added"> 281       pthread_mutex_unlock (&amp;ffi_trampoline_lock);</span>
<span class="line-added"> 282       free (closure);</span>
<span class="line-added"> 283       return NULL;</span>
<span class="line-added"> 284     }</span>
<span class="line-added"> 285 </span>
<span class="line-added"> 286       /* Insert the new table at the top of the list */</span>
<span class="line-added"> 287       table-&gt;next = ffi_trampoline_tables;</span>
<span class="line-added"> 288       if (table-&gt;next != NULL)</span>
<span class="line-added"> 289     table-&gt;next-&gt;prev = table;</span>
<span class="line-added"> 290 </span>
<span class="line-added"> 291       ffi_trampoline_tables = table;</span>
<span class="line-added"> 292     }</span>
<span class="line-added"> 293 </span>
<span class="line-added"> 294   /* Claim the free entry */</span>
<span class="line-added"> 295   ffi_trampoline_table_entry *entry = ffi_trampoline_tables-&gt;free_list;</span>
<span class="line-added"> 296   ffi_trampoline_tables-&gt;free_list = entry-&gt;next;</span>
<span class="line-added"> 297   ffi_trampoline_tables-&gt;free_count--;</span>
<span class="line-added"> 298   entry-&gt;next = NULL;</span>
<span class="line-added"> 299 </span>
<span class="line-added"> 300   pthread_mutex_unlock (&amp;ffi_trampoline_lock);</span>
<span class="line-added"> 301 </span>
<span class="line-added"> 302   /* Initialize the return values */</span>
<span class="line-added"> 303   *code = entry-&gt;trampoline;</span>
<span class="line-added"> 304   closure-&gt;trampoline_table = table;</span>
<span class="line-added"> 305   closure-&gt;trampoline_table_entry = entry;</span>
<span class="line-added"> 306 </span>
<span class="line-added"> 307   return closure;</span>
<span class="line-added"> 308 }</span>
<span class="line-added"> 309 </span>
<span class="line-added"> 310 void</span>
<span class="line-added"> 311 ffi_closure_free (void *ptr)</span>
<span class="line-added"> 312 {</span>
<span class="line-added"> 313   ffi_closure *closure = ptr;</span>
<span class="line-added"> 314 </span>
<span class="line-added"> 315   pthread_mutex_lock (&amp;ffi_trampoline_lock);</span>
<span class="line-added"> 316 </span>
<span class="line-added"> 317   /* Fetch the table and entry references */</span>
<span class="line-added"> 318   ffi_trampoline_table *table = closure-&gt;trampoline_table;</span>
<span class="line-added"> 319   ffi_trampoline_table_entry *entry = closure-&gt;trampoline_table_entry;</span>
<span class="line-added"> 320 </span>
<span class="line-added"> 321   /* Return the entry to the free list */</span>
<span class="line-added"> 322   entry-&gt;next = table-&gt;free_list;</span>
<span class="line-added"> 323   table-&gt;free_list = entry;</span>
<span class="line-added"> 324   table-&gt;free_count++;</span>
<span class="line-added"> 325 </span>
<span class="line-added"> 326   /* If all trampolines within this table are free, and at least one other table exists, deallocate</span>
<span class="line-added"> 327    * the table */</span>
<span class="line-added"> 328   if (table-&gt;free_count == FFI_TRAMPOLINE_COUNT</span>
<span class="line-added"> 329       &amp;&amp; ffi_trampoline_tables != table)</span>
<span class="line-added"> 330     {</span>
<span class="line-added"> 331       ffi_trampoline_table_free (table);</span>
<span class="line-added"> 332     }</span>
<span class="line-added"> 333   else if (ffi_trampoline_tables != table)</span>
<span class="line-added"> 334     {</span>
<span class="line-added"> 335       /* Otherwise, bump this table to the top of the list */</span>
<span class="line-added"> 336       table-&gt;prev = NULL;</span>
<span class="line-added"> 337       table-&gt;next = ffi_trampoline_tables;</span>
<span class="line-added"> 338       if (ffi_trampoline_tables != NULL)</span>
<span class="line-added"> 339     ffi_trampoline_tables-&gt;prev = table;</span>
<span class="line-added"> 340 </span>
<span class="line-added"> 341       ffi_trampoline_tables = table;</span>
<span class="line-added"> 342     }</span>
<span class="line-added"> 343 </span>
<span class="line-added"> 344   pthread_mutex_unlock (&amp;ffi_trampoline_lock);</span>
<span class="line-added"> 345 </span>
<span class="line-added"> 346   /* Free the closure */</span>
<span class="line-added"> 347   free (closure);</span>
<span class="line-added"> 348 }</span>
<span class="line-added"> 349 </span>
<span class="line-added"> 350 #endif</span>
 351 
 352 // Per-target implementation; It&#39;s unclear what can reasonable be shared between two OS/architecture implementations.
 353 
<span class="line-modified"> 354 #elif FFI_MMAP_EXEC_WRIT /* !FFI_EXEC_TRAMPOLINE_TABLE */</span>
 355 
 356 #define USE_LOCKS 1
 357 #define USE_DL_PREFIX 1
 358 #ifdef __GNUC__
 359 #ifndef USE_BUILTIN_FFS
 360 #define USE_BUILTIN_FFS 1
 361 #endif
 362 #endif
 363 
 364 /* We need to use mmap, not sbrk.  */
 365 #define HAVE_MORECORE 0
 366 
 367 /* We could, in theory, support mremap, but it wouldn&#39;t buy us anything.  */
 368 #define HAVE_MREMAP 0
 369 
 370 /* We have no use for this, so save some code and data.  */
 371 #define NO_MALLINFO 1
 372 
 373 /* We need all allocations to be in regular segments, otherwise we
 374    lose track of the corresponding code address.  */
 375 #define DEFAULT_MMAP_THRESHOLD MAX_SIZE_T
 376 
 377 /* Don&#39;t allocate more than a page unless needed.  */
 378 #define DEFAULT_GRANULARITY ((size_t)malloc_getpagesize)
 379 








 380 #include &lt;sys/types.h&gt;
 381 #include &lt;sys/stat.h&gt;
 382 #include &lt;fcntl.h&gt;
 383 #include &lt;errno.h&gt;
 384 #ifndef _MSC_VER
 385 #include &lt;unistd.h&gt;
 386 #endif
 387 #include &lt;string.h&gt;
 388 #include &lt;stdio.h&gt;
<span class="line-modified"> 389 #if !defined(X86_WIN32) &amp;&amp; !defined(X86_WIN64) &amp;&amp; !defined(_M_ARM64)</span>
 390 #ifdef HAVE_MNTENT
 391 #include &lt;mntent.h&gt;
 392 #endif /* HAVE_MNTENT */
 393 #include &lt;sys/param.h&gt;
 394 #include &lt;pthread.h&gt;
 395 
 396 /* We don&#39;t want sys/mman.h to be included after we redefine mmap and
 397    dlmunmap.  */
 398 #include &lt;sys/mman.h&gt;
 399 #define LACKS_SYS_MMAN_H 1
 400 
 401 #if FFI_MMAP_EXEC_SELINUX
 402 #include &lt;sys/statfs.h&gt;
 403 #include &lt;stdlib.h&gt;
 404 
 405 static int selinux_enabled = -1;
 406 
 407 static int
 408 selinux_enabled_check (void)
 409 {
</pre>
<hr />
<pre>
 495 #define is_emutramp_enabled() 0
 496 #endif /* FFI_MMAP_EXEC_EMUTRAMP_PAX */
 497 
 498 /* Declare all functions defined in dlmalloc.c as static.  */
 499 static void *dlmalloc(size_t);
 500 static void dlfree(void*);
 501 static void *dlcalloc(size_t, size_t) MAYBE_UNUSED;
 502 static void *dlrealloc(void *, size_t) MAYBE_UNUSED;
 503 static void *dlmemalign(size_t, size_t) MAYBE_UNUSED;
 504 static void *dlvalloc(size_t) MAYBE_UNUSED;
 505 static int dlmallopt(int, int) MAYBE_UNUSED;
 506 static size_t dlmalloc_footprint(void) MAYBE_UNUSED;
 507 static size_t dlmalloc_max_footprint(void) MAYBE_UNUSED;
 508 static void** dlindependent_calloc(size_t, size_t, void**) MAYBE_UNUSED;
 509 static void** dlindependent_comalloc(size_t, size_t*, void**) MAYBE_UNUSED;
 510 static void *dlpvalloc(size_t) MAYBE_UNUSED;
 511 static int dlmalloc_trim(size_t) MAYBE_UNUSED;
 512 static size_t dlmalloc_usable_size(void*) MAYBE_UNUSED;
 513 static void dlmalloc_stats(void) MAYBE_UNUSED;
 514 
<span class="line-modified"> 515 #if !(defined(X86_WIN32) || defined(X86_WIN64) || defined(_M_ARM64) || defined(__OS2__)) || defined (__CYGWIN__) || defined(__INTERIX)</span>
 516 /* Use these for mmap and munmap within dlmalloc.c.  */
 517 static void *dlmmap(void *, size_t, int, int, int, off_t);
 518 static int dlmunmap(void *, size_t);
 519 #endif /* !(defined(X86_WIN32) || defined(X86_WIN64) || defined(__OS2__)) || defined (__CYGWIN__) || defined(__INTERIX) */
 520 
 521 #define mmap dlmmap
 522 #define munmap dlmunmap
 523 
 524 #include &quot;dlmalloc.c&quot;
 525 
 526 #undef mmap
 527 #undef munmap
 528 
<span class="line-modified"> 529 #if !(defined(X86_WIN32) || defined(X86_WIN64) || defined(_M_ARM64) || defined(__OS2__)) || defined (__CYGWIN__) || defined(__INTERIX)</span>
 530 
 531 /* A mutex used to synchronize access to *exec* variables in this file.  */
 532 static pthread_mutex_t open_temp_exec_file_mutex = PTHREAD_MUTEX_INITIALIZER;
 533 
 534 /* A file descriptor of a temporary file from which we&#39;ll map
 535    executable pages.  */
 536 static int execfd = -1;
 537 
 538 /* The amount of space already allocated from the temporary file.  */
 539 static size_t execsize = 0;
 540 
 541 /* Open a temporary file name, and immediately unlink it.  */
 542 static int
 543 open_temp_exec_file_name (char *name, int flags)
 544 {
 545   int fd;
 546 
 547 #ifdef HAVE_MKOSTEMP
 548   fd = mkostemp (name, flags);
 549 #else
</pre>
<hr />
<pre>
 566 #ifdef O_TMPFILE
 567   int fd;
 568 #endif
 569 
 570 #ifdef O_CLOEXEC
 571   flags = O_CLOEXEC;
 572 #else
 573   flags = 0;
 574 #endif
 575 
 576 #ifdef O_TMPFILE
 577   fd = open (dir, flags | O_RDWR | O_EXCL | O_TMPFILE, 0700);
 578   /* If the running system does not support the O_TMPFILE flag then retry without it. */
 579   if (fd != -1 || (errno != EINVAL &amp;&amp; errno != EISDIR &amp;&amp; errno != EOPNOTSUPP)) {
 580     return fd;
 581   } else {
 582     errno = 0;
 583   }
 584 #endif
 585 
<span class="line-modified"> 586   lendir = (int) strlen (dir);</span>
 587   tempname = __builtin_alloca (lendir + sizeof (suffix));
 588 
 589   if (!tempname)
 590     return -1;
 591 
 592   memcpy (tempname, dir, lendir);
 593   memcpy (tempname + lendir, suffix, sizeof (suffix));
 594 
 595   return open_temp_exec_file_name (tempname, flags);
 596 }
 597 
 598 /* Open a temporary file in the directory in the named environment
 599    variable.  */
 600 static int
 601 open_temp_exec_file_env (const char *envvar)
 602 {
 603   const char *value = getenv (envvar);
 604 
 605   if (!value)
 606     return -1;
</pre>
<hr />
<pre>
 707 {
 708   int fd;
 709 
 710   do
 711     {
 712       fd = open_temp_exec_file_opts[open_temp_exec_file_opts_idx].func
 713     (open_temp_exec_file_opts[open_temp_exec_file_opts_idx].arg);
 714 
 715       if (!open_temp_exec_file_opts[open_temp_exec_file_opts_idx].repeat
 716       || fd == -1)
 717     {
 718       if (open_temp_exec_file_opts_next ())
 719         break;
 720     }
 721     }
 722   while (fd == -1);
 723 
 724   return fd;
 725 }
 726 
<span class="line-added"> 727 /* We need to allocate space in a file that will be backing a writable</span>
<span class="line-added"> 728    mapping.  Several problems exist with the usual approaches:</span>
<span class="line-added"> 729    - fallocate() is Linux-only</span>
<span class="line-added"> 730    - posix_fallocate() is not available on all platforms</span>
<span class="line-added"> 731    - ftruncate() does not allocate space on filesystems with sparse files</span>
<span class="line-added"> 732    Failure to allocate the space will cause SIGBUS to be thrown when</span>
<span class="line-added"> 733    the mapping is subsequently written to.  */</span>
<span class="line-added"> 734 static int</span>
<span class="line-added"> 735 allocate_space (int fd, off_t offset, off_t len)</span>
<span class="line-added"> 736 {</span>
<span class="line-added"> 737   static size_t page_size;</span>
<span class="line-added"> 738 </span>
<span class="line-added"> 739   /* Obtain system page size. */</span>
<span class="line-added"> 740   if (!page_size)</span>
<span class="line-added"> 741     page_size = sysconf(_SC_PAGESIZE);</span>
<span class="line-added"> 742 </span>
<span class="line-added"> 743   unsigned char buf[page_size];</span>
<span class="line-added"> 744   memset (buf, 0, page_size);</span>
<span class="line-added"> 745 </span>
<span class="line-added"> 746   while (len &gt; 0)</span>
<span class="line-added"> 747     {</span>
<span class="line-added"> 748       off_t to_write = (len &lt; page_size) ? len : page_size;</span>
<span class="line-added"> 749       if (write (fd, buf, to_write) &lt; to_write)</span>
<span class="line-added"> 750         return -1;</span>
<span class="line-added"> 751       len -= to_write;</span>
<span class="line-added"> 752     }</span>
<span class="line-added"> 753 </span>
<span class="line-added"> 754   return 0;</span>
<span class="line-added"> 755 }</span>
<span class="line-added"> 756 </span>
 757 /* Map in a chunk of memory from the temporary exec file into separate
 758    locations in the virtual memory address space, one writable and one
 759    executable.  Returns the address of the writable portion, after
 760    storing an offset to the corresponding executable portion at the
 761    last word of the requested chunk.  */
 762 static void *
 763 dlmmap_locked (void *start, size_t length, int prot, int flags, off_t offset)
 764 {
 765   void *ptr;
 766 
 767   if (execfd == -1)
 768     {
 769       open_temp_exec_file_opts_idx = 0;
 770     retry_open:
 771       execfd = open_temp_exec_file ();
 772       if (execfd == -1)
 773     return MFAIL;
 774     }
 775 
 776   offset = execsize;
 777 
<span class="line-modified"> 778   if (allocate_space (execfd, offset, length))</span>
 779     return MFAIL;
 780 
 781   flags &amp;= ~(MAP_PRIVATE | MAP_ANONYMOUS);
 782   flags |= MAP_SHARED;
 783 
 784   ptr = mmap (NULL, length, (prot &amp; ~PROT_WRITE) | PROT_EXEC,
 785           flags, execfd, offset);
 786   if (ptr == MFAIL)
 787     {
 788       if (!offset)
 789     {
 790       close (execfd);
 791       goto retry_open;
 792     }
<span class="line-modified"> 793       if (ftruncate (execfd, offset) != 0)</span>
<span class="line-added"> 794       {</span>
<span class="line-added"> 795         /* Fixme : Error logs can be added here. Returning an error for</span>
<span class="line-added"> 796          * ftruncte() will not add any advantage as it is being</span>
<span class="line-added"> 797          * validating in the error case. */</span>
<span class="line-added"> 798       }</span>
<span class="line-added"> 799 </span>
 800       return MFAIL;
 801     }
 802   else if (!offset
 803        &amp;&amp; open_temp_exec_file_opts[open_temp_exec_file_opts_idx].repeat)
 804     open_temp_exec_file_opts_next ();
 805 
 806   start = mmap (start, length, prot, flags, execfd, offset);
 807 
 808   if (start == MFAIL)
 809     {
 810       munmap (ptr, length);
<span class="line-modified"> 811       if (ftruncate (execfd, offset) != 0)</span>
<span class="line-added"> 812       {</span>
<span class="line-added"> 813         /* Fixme : Error logs can be added here. Returning an error for</span>
<span class="line-added"> 814          * ftruncte() will not add any advantage as it is being</span>
<span class="line-added"> 815          * validating in the error case. */</span>
<span class="line-added"> 816       }</span>
 817       return start;
 818     }
 819 
 820   mmap_exec_offset ((char *)start, length) = (char*)ptr - (char*)start;
 821 
 822   execsize += length;
 823 
 824   return start;
 825 }
 826 
 827 /* Map in a writable and executable chunk of memory if possible.
 828    Failing that, fall back to dlmmap_locked.  */
 829 static void *
 830 dlmmap (void *start, size_t length, int prot,
 831     int flags, int fd, off_t offset)
 832 {
 833   void *ptr;
 834 
 835   assert (start == NULL &amp;&amp; length % malloc_getpagesize == 0
 836       &amp;&amp; prot == (PROT_READ | PROT_WRITE)
 837       &amp;&amp; flags == (MAP_PRIVATE | MAP_ANONYMOUS)
 838       &amp;&amp; fd == -1 &amp;&amp; offset == 0);
 839 




 840   if (execfd == -1 &amp;&amp; is_emutramp_enabled ())
 841     {
 842       ptr = mmap (start, length, prot &amp; ~PROT_EXEC, flags, fd, offset);
 843       return ptr;
 844     }
 845 
 846   if (execfd == -1 &amp;&amp; !is_selinux_enabled ())
 847     {
 848       ptr = mmap (start, length, prot | PROT_EXEC, flags, fd, offset);
 849 
 850       if (ptr != MFAIL || (errno != EPERM &amp;&amp; errno != EACCES))
 851     /* Cool, no need to mess with separate segments.  */
 852     return ptr;
 853 
 854       /* If MREMAP_DUP is ever introduced and implemented, try mmap
 855      with ((prot &amp; ~PROT_WRITE) | PROT_EXEC) and mremap with
 856      MREMAP_DUP and prot at this point.  */
 857     }
 858 
 859   if (execsize == 0 || execfd == -1)
</pre>
<hr />
<pre>
 865       return ptr;
 866     }
 867 
 868   return dlmmap_locked (start, length, prot, flags, offset);
 869 }
 870 
 871 /* Release memory at the given address, as well as the corresponding
 872    executable page if it&#39;s separate.  */
 873 static int
 874 dlmunmap (void *start, size_t length)
 875 {
 876   /* We don&#39;t bother decreasing execsize or truncating the file, since
 877      we can&#39;t quite tell whether we&#39;re unmapping the end of the file.
 878      We don&#39;t expect frequent deallocation anyway.  If we did, we
 879      could locate pages in the file by writing to the pages being
 880      deallocated and checking that the file contents change.
 881      Yuck.  */
 882   msegmentptr seg = segment_holding (gm, start);
 883   void *code;
 884 




 885   if (seg &amp;&amp; (code = add_segment_exec_offset (start, seg)) != start)
 886     {
 887       int ret = munmap (code, length);
 888       if (ret)
 889     return ret;
 890     }
 891 
 892   return munmap (start, length);
 893 }
 894 
 895 #if FFI_CLOSURE_FREE_CODE
 896 /* Return segment holding given code address.  */
 897 static msegmentptr
 898 segment_holding_code (mstate m, char* addr)
 899 {
 900   msegmentptr sp = &amp;m-&gt;seg;
 901   for (;;) {
 902     if (addr &gt;= add_segment_exec_offset (sp-&gt;base, sp)
 903     &amp;&amp; addr &lt; add_segment_exec_offset (sp-&gt;base, sp) + sp-&gt;size)
 904       return sp;
 905     if ((sp = sp-&gt;next) == 0)
 906       return 0;
 907   }
 908 }
 909 #endif
 910 
<span class="line-modified"> 911 #endif /* !(defined(X86_WIN32) || defined(X86_WIN64) || defined(_M_ARM64) || defined(__OS2__)) || defined (__CYGWIN__) || defined(__INTERIX) */</span>
 912 
 913 /* Allocate a chunk of memory with the given size.  Returns a pointer
 914    to the writable address, and sets *CODE to the executable
 915    corresponding virtual address.  */
 916 void *
 917 ffi_closure_alloc (size_t size, void **code)
 918 {
 919   void *ptr;
 920 
 921   if (!code)
 922     return NULL;
 923 
 924   ptr = dlmalloc (size);
 925 
 926   if (ptr)
 927     {
 928       msegmentptr seg = segment_holding (gm, ptr);
 929 #ifdef GSTREAMER_LITE
 930       if (seg == NULL)
 931         return NULL;
 932 #endif // GSTREAMER_LITE
 933 
 934       *code = add_segment_exec_offset (ptr, seg);
 935     }
 936 
 937   return ptr;
 938 }
 939 
<span class="line-added"> 940 void *</span>
<span class="line-added"> 941 ffi_data_to_code_pointer (void *data)</span>
<span class="line-added"> 942 {</span>
<span class="line-added"> 943   msegmentptr seg = segment_holding (gm, data);</span>
<span class="line-added"> 944   /* We expect closures to be allocated with ffi_closure_alloc(), in</span>
<span class="line-added"> 945      which case seg will be non-NULL.  However, some users take on the</span>
<span class="line-added"> 946      burden of managing this memory themselves, in which case this</span>
<span class="line-added"> 947      we&#39;ll just return data. */</span>
<span class="line-added"> 948   if (seg)</span>
<span class="line-added"> 949     return add_segment_exec_offset (data, seg);</span>
<span class="line-added"> 950   else</span>
<span class="line-added"> 951     return data;</span>
<span class="line-added"> 952 }</span>
<span class="line-added"> 953 </span>
 954 /* Release a chunk of memory allocated with ffi_closure_alloc.  If
 955    FFI_CLOSURE_FREE_CODE is nonzero, the given address can be the
 956    writable or the executable address given.  Otherwise, only the
 957    writable address can be provided here.  */
 958 void
 959 ffi_closure_free (void *ptr)
 960 {
 961 #if FFI_CLOSURE_FREE_CODE
 962   msegmentptr seg = segment_holding_code (gm, ptr);
 963 
 964   if (seg)
 965     ptr = sub_segment_exec_offset (ptr, seg);
 966 #endif
 967 
 968   dlfree (ptr);
 969 }
 970 




















 971 # else /* ! FFI_MMAP_EXEC_WRIT */
 972 
 973 /* On many systems, memory returned by malloc is writable and
 974    executable, so just use it.  */
 975 
 976 #include &lt;stdlib.h&gt;
 977 
 978 void *
 979 ffi_closure_alloc (size_t size, void **code)
 980 {
 981   if (!code)
 982     return NULL;
 983 
 984   return *code = malloc (size);
 985 }
 986 
 987 void
 988 ffi_closure_free (void *ptr)
 989 {
 990   free (ptr);
 991 }
 992 
<span class="line-added"> 993 void *</span>
<span class="line-added"> 994 ffi_data_to_code_pointer (void *data)</span>
<span class="line-added"> 995 {</span>
<span class="line-added"> 996   return data;</span>
<span class="line-added"> 997 }</span>
<span class="line-added"> 998 </span>
 999 # endif /* ! FFI_MMAP_EXEC_WRIT */
1000 #endif /* FFI_CLOSURES */
<span class="line-added">1001 </span>
<span class="line-added">1002 #endif /* NetBSD with PROT_MPROTECT */</span>
</pre>
</td>
</tr>
</table>
<center><a href="../include/ffitarget.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="dlmalloc.c.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>