<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/HeapInlines.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="HeapCellInlines.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="HeapSnapshot.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/HeapInlines.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 53 inline Heap* Heap::heap(const JSValue v)
 54 {
 55     if (!v.isCell())
 56         return nullptr;
 57     return heap(v.asCell());
 58 }
 59 
 60 inline bool Heap::hasHeapAccess() const
 61 {
 62     return m_worldState.load() &amp; hasAccessBit;
 63 }
 64 
 65 inline bool Heap::worldIsStopped() const
 66 {
 67     return m_worldIsStopped;
 68 }
 69 
 70 ALWAYS_INLINE bool Heap::isMarked(const void* rawCell)
 71 {
 72     HeapCell* cell = bitwise_cast&lt;HeapCell*&gt;(rawCell);
<span class="line-modified"> 73     if (cell-&gt;isLargeAllocation())</span>
<span class="line-modified"> 74         return cell-&gt;largeAllocation().isMarked();</span>
 75     MarkedBlock&amp; block = cell-&gt;markedBlock();
 76     return block.isMarked(m_objectSpace.markingVersion(), cell);
 77 }
 78 
 79 ALWAYS_INLINE bool Heap::testAndSetMarked(HeapVersion markingVersion, const void* rawCell)
 80 {
 81     HeapCell* cell = bitwise_cast&lt;HeapCell*&gt;(rawCell);
<span class="line-modified"> 82     if (cell-&gt;isLargeAllocation())</span>
<span class="line-modified"> 83         return cell-&gt;largeAllocation().testAndSetMarked();</span>
 84     MarkedBlock&amp; block = cell-&gt;markedBlock();
 85     Dependency dependency = block.aboutToMark(markingVersion);
 86     return block.testAndSetMarked(cell, dependency);
 87 }
 88 
 89 ALWAYS_INLINE size_t Heap::cellSize(const void* rawCell)
 90 {
 91     return bitwise_cast&lt;HeapCell*&gt;(rawCell)-&gt;cellSize();
 92 }
 93 
 94 inline void Heap::writeBarrier(const JSCell* from, JSValue to)
 95 {
 96 #if ENABLE(WRITE_BARRIER_PROFILING)
 97     WriteBarrierCounters::countWriteBarrier();
 98 #endif
 99     if (!to.isCell())
100         return;
101     writeBarrier(from, to.asCell());
102 }
103 
</pre>
<hr />
<pre>
171 }
172 #endif
173 
174 inline void Heap::incrementDeferralDepth()
175 {
176     ASSERT(!Thread::mayBeGCThread() || m_worldIsStopped);
177     m_deferralDepth++;
178 }
179 
180 inline void Heap::decrementDeferralDepth()
181 {
182     ASSERT(!Thread::mayBeGCThread() || m_worldIsStopped);
183     m_deferralDepth--;
184 }
185 
186 inline void Heap::decrementDeferralDepthAndGCIfNeeded()
187 {
188     ASSERT(!Thread::mayBeGCThread() || m_worldIsStopped);
189     m_deferralDepth--;
190 
<span class="line-modified">191     if (UNLIKELY(m_didDeferGCWork)) {</span>
192         decrementDeferralDepthAndGCIfNeededSlow();
193 
194         // Here are the possible relationships between m_deferralDepth and m_didDeferGCWork.
195         // Note that prior to the call to decrementDeferralDepthAndGCIfNeededSlow,
196         // m_didDeferGCWork had to have been true. Now it can be either false or true. There is
197         // nothing we can reliably assert.
198         //
199         // Possible arrangements of m_didDeferGCWork and !!m_deferralDepth:
200         //
201         // Both false: We popped out of all DeferGCs and we did whatever work was deferred.
202         //
203         // Only m_didDeferGCWork is true: We stopped for GC and the GC did DeferGC. This is
204         // possible because of how we handle the baseline JIT&#39;s worklist. It&#39;s also perfectly
205         // safe because it only protects reportExtraMemory. We can just ignore this.
206         //
207         // Only !!m_deferralDepth is true: m_didDeferGCWork had been set spuriously. It is only
208         // cleared by decrementDeferralDepthAndGCIfNeededSlow(). So, if we had deferred work but
209         // then decrementDeferralDepth()&#39;d, then we might have the bit set even if we GC&#39;d since
210         // then.
211         //
</pre>
</td>
<td>
<hr />
<pre>
 53 inline Heap* Heap::heap(const JSValue v)
 54 {
 55     if (!v.isCell())
 56         return nullptr;
 57     return heap(v.asCell());
 58 }
 59 
 60 inline bool Heap::hasHeapAccess() const
 61 {
 62     return m_worldState.load() &amp; hasAccessBit;
 63 }
 64 
 65 inline bool Heap::worldIsStopped() const
 66 {
 67     return m_worldIsStopped;
 68 }
 69 
 70 ALWAYS_INLINE bool Heap::isMarked(const void* rawCell)
 71 {
 72     HeapCell* cell = bitwise_cast&lt;HeapCell*&gt;(rawCell);
<span class="line-modified"> 73     if (cell-&gt;isPreciseAllocation())</span>
<span class="line-modified"> 74         return cell-&gt;preciseAllocation().isMarked();</span>
 75     MarkedBlock&amp; block = cell-&gt;markedBlock();
 76     return block.isMarked(m_objectSpace.markingVersion(), cell);
 77 }
 78 
 79 ALWAYS_INLINE bool Heap::testAndSetMarked(HeapVersion markingVersion, const void* rawCell)
 80 {
 81     HeapCell* cell = bitwise_cast&lt;HeapCell*&gt;(rawCell);
<span class="line-modified"> 82     if (cell-&gt;isPreciseAllocation())</span>
<span class="line-modified"> 83         return cell-&gt;preciseAllocation().testAndSetMarked();</span>
 84     MarkedBlock&amp; block = cell-&gt;markedBlock();
 85     Dependency dependency = block.aboutToMark(markingVersion);
 86     return block.testAndSetMarked(cell, dependency);
 87 }
 88 
 89 ALWAYS_INLINE size_t Heap::cellSize(const void* rawCell)
 90 {
 91     return bitwise_cast&lt;HeapCell*&gt;(rawCell)-&gt;cellSize();
 92 }
 93 
 94 inline void Heap::writeBarrier(const JSCell* from, JSValue to)
 95 {
 96 #if ENABLE(WRITE_BARRIER_PROFILING)
 97     WriteBarrierCounters::countWriteBarrier();
 98 #endif
 99     if (!to.isCell())
100         return;
101     writeBarrier(from, to.asCell());
102 }
103 
</pre>
<hr />
<pre>
171 }
172 #endif
173 
174 inline void Heap::incrementDeferralDepth()
175 {
176     ASSERT(!Thread::mayBeGCThread() || m_worldIsStopped);
177     m_deferralDepth++;
178 }
179 
180 inline void Heap::decrementDeferralDepth()
181 {
182     ASSERT(!Thread::mayBeGCThread() || m_worldIsStopped);
183     m_deferralDepth--;
184 }
185 
186 inline void Heap::decrementDeferralDepthAndGCIfNeeded()
187 {
188     ASSERT(!Thread::mayBeGCThread() || m_worldIsStopped);
189     m_deferralDepth--;
190 
<span class="line-modified">191     if (UNLIKELY(m_didDeferGCWork) || Options::forceDidDeferGCWork()) {</span>
192         decrementDeferralDepthAndGCIfNeededSlow();
193 
194         // Here are the possible relationships between m_deferralDepth and m_didDeferGCWork.
195         // Note that prior to the call to decrementDeferralDepthAndGCIfNeededSlow,
196         // m_didDeferGCWork had to have been true. Now it can be either false or true. There is
197         // nothing we can reliably assert.
198         //
199         // Possible arrangements of m_didDeferGCWork and !!m_deferralDepth:
200         //
201         // Both false: We popped out of all DeferGCs and we did whatever work was deferred.
202         //
203         // Only m_didDeferGCWork is true: We stopped for GC and the GC did DeferGC. This is
204         // possible because of how we handle the baseline JIT&#39;s worklist. It&#39;s also perfectly
205         // safe because it only protects reportExtraMemory. We can just ignore this.
206         //
207         // Only !!m_deferralDepth is true: m_didDeferGCWork had been set spuriously. It is only
208         // cleared by decrementDeferralDepthAndGCIfNeededSlow(). So, if we had deferred work but
209         // then decrementDeferralDepth()&#39;d, then we might have the bit set even if we GC&#39;d since
210         // then.
211         //
</pre>
</td>
</tr>
</table>
<center><a href="HeapCellInlines.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="HeapSnapshot.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>