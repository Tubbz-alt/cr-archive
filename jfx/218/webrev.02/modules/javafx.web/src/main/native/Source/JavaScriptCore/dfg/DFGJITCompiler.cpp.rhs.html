<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGJITCompiler.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2011-2019 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;DFGJITCompiler.h&quot;
 28 
 29 #if ENABLE(DFG_JIT)
 30 
 31 #include &quot;CodeBlock.h&quot;
 32 #include &quot;DFGFailedFinalizer.h&quot;
 33 #include &quot;DFGInlineCacheWrapperInlines.h&quot;
 34 #include &quot;DFGJITCode.h&quot;
 35 #include &quot;DFGJITFinalizer.h&quot;
 36 #include &quot;DFGOSRExit.h&quot;
 37 #include &quot;DFGOperations.h&quot;
 38 #include &quot;DFGRegisterBank.h&quot;
 39 #include &quot;DFGSlowPathGenerator.h&quot;
 40 #include &quot;DFGSpeculativeJIT.h&quot;
 41 #include &quot;DFGThunks.h&quot;
 42 #include &quot;JSCInlines.h&quot;
 43 #include &quot;JSCJSValueInlines.h&quot;
 44 #include &quot;LinkBuffer.h&quot;
 45 #include &quot;MaxFrameExtentForSlowPathCall.h&quot;
 46 #include &quot;StructureStubInfo.h&quot;
 47 #include &quot;ThunkGenerators.h&quot;
 48 #include &quot;VM.h&quot;
 49 
 50 namespace JSC { namespace DFG {
 51 
 52 JITCompiler::JITCompiler(Graph&amp; dfg)
 53     : CCallHelpers(dfg.m_codeBlock)
 54     , m_graph(dfg)
 55     , m_jitCode(adoptRef(new JITCode()))
 56     , m_blockHeads(dfg.numBlocks())
 57     , m_pcToCodeOriginMapBuilder(dfg.m_vm)
 58 {
 59     if (UNLIKELY(shouldDumpDisassembly() || m_graph.m_vm.m_perBytecodeProfiler))
 60         m_disassembler = makeUnique&lt;Disassembler&gt;(dfg);
 61 #if ENABLE(FTL_JIT)
 62     m_jitCode-&gt;tierUpInLoopHierarchy = WTFMove(m_graph.m_plan.tierUpInLoopHierarchy());
<a name="1" id="anc1"></a><span class="line-modified"> 63     for (BytecodeIndex tierUpBytecode : m_graph.m_plan.tierUpAndOSREnterBytecodes())</span>
 64         m_jitCode-&gt;tierUpEntryTriggers.add(tierUpBytecode, JITCode::TriggerReason::DontTrigger);
 65 #endif
 66 }
 67 
 68 JITCompiler::~JITCompiler()
 69 {
 70 }
 71 
 72 void JITCompiler::linkOSRExits()
 73 {
 74     ASSERT(m_jitCode-&gt;osrExit.size() == m_exitCompilationInfo.size());
 75     if (UNLIKELY(m_graph.compilation())) {
 76         for (unsigned i = 0; i &lt; m_jitCode-&gt;osrExit.size(); ++i) {
 77             OSRExitCompilationInfo&amp; info = m_exitCompilationInfo[i];
 78             Vector&lt;Label&gt; labels;
 79             if (!info.m_failureJumps.empty()) {
 80                 for (unsigned j = 0; j &lt; info.m_failureJumps.jumps().size(); ++j)
 81                     labels.append(info.m_failureJumps.jumps()[j].label());
 82             } else
 83                 labels.append(info.m_replacementSource);
 84             m_exitSiteLabels.append(labels);
 85         }
 86     }
 87 
<a name="2" id="anc2"></a>

 88     for (unsigned i = 0; i &lt; m_jitCode-&gt;osrExit.size(); ++i) {
 89         OSRExitCompilationInfo&amp; info = m_exitCompilationInfo[i];
 90         JumpList&amp; failureJumps = info.m_failureJumps;
 91         if (!failureJumps.empty())
 92             failureJumps.link(this);
 93         else
 94             info.m_replacementDestination = label();
 95 
 96         jitAssertHasValidCallFrame();
 97         store32(TrustedImm32(i), &amp;vm().osrExitIndex);
<a name="3" id="anc3"></a><span class="line-modified"> 98         info.m_patchableJump = patchableJump();</span>






 99     }
100 }
101 
102 void JITCompiler::compileEntry()
103 {
104     // This code currently matches the old JIT. In the function header we need to
105     // save return address and call frame via the prologue and perform a fast stack check.
106     // FIXME: https://bugs.webkit.org/show_bug.cgi?id=56292
107     // We&#39;ll need to convert the remaining cti_ style calls (specifically the stack
108     // check) which will be dependent on stack layout. (We&#39;d need to account for this in
109     // both normal return code and when jumping to an exception handler).
110     emitFunctionPrologue();
111     emitPutToCallFrameHeader(m_codeBlock, CallFrameSlot::codeBlock);
112 }
113 
114 void JITCompiler::compileSetupRegistersForEntry()
115 {
116     emitSaveCalleeSaves();
117     emitMaterializeTagCheckRegisters();
118 }
119 
120 void JITCompiler::compileEntryExecutionFlag()
121 {
122 #if ENABLE(FTL_JIT)
123     if (m_graph.m_plan.canTierUpAndOSREnter())
124         store8(TrustedImm32(0), &amp;m_jitCode-&gt;neverExecutedEntry);
125 #endif // ENABLE(FTL_JIT)
126 }
127 
128 void JITCompiler::compileBody()
129 {
130     // We generate the speculative code path, followed by OSR exit code to return
131     // to the old JIT code if speculations fail.
132 
133     bool compiledSpeculative = m_speculative-&gt;compile();
134     ASSERT_UNUSED(compiledSpeculative, compiledSpeculative);
135 }
136 
137 void JITCompiler::compileExceptionHandlers()
138 {
139     if (!m_exceptionChecksWithCallFrameRollback.empty()) {
140         m_exceptionChecksWithCallFrameRollback.link(this);
141 
142         copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm().topEntryFrame);
143 
<a name="4" id="anc4"></a><span class="line-modified">144         // operationLookupExceptionHandlerFromCallerFrame is passed one argument, the VM*.</span>
145         move(TrustedImmPtr(&amp;vm()), GPRInfo::argumentGPR0);
<a name="5" id="anc5"></a><span class="line-modified">146         prepareCallOperation(vm());</span>
147         addPtr(TrustedImm32(m_graph.stackPointerOffset() * sizeof(Register)), GPRInfo::callFrameRegister, stackPointerRegister);
148 
<a name="6" id="anc6"></a><span class="line-modified">149         m_calls.append(CallLinkRecord(call(OperationPtrTag), FunctionPtr&lt;OperationPtrTag&gt;(operationLookupExceptionHandlerFromCallerFrame)));</span>





150 
151         jumpToExceptionHandler(vm());
152     }
153 
154     if (!m_exceptionChecks.empty()) {
155         m_exceptionChecks.link(this);
156 
157         copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm().topEntryFrame);
158 
<a name="7" id="anc7"></a><span class="line-modified">159         // operationLookupExceptionHandler is passed one argument, the VM*.</span>
160         move(TrustedImmPtr(&amp;vm()), GPRInfo::argumentGPR0);
<a name="8" id="anc8"></a><span class="line-modified">161         prepareCallOperation(vm());</span>
162 
<a name="9" id="anc9"></a><span class="line-modified">163         m_calls.append(CallLinkRecord(call(OperationPtrTag), FunctionPtr&lt;OperationPtrTag&gt;(operationLookupExceptionHandler)));</span>





164 
165         jumpToExceptionHandler(vm());
166     }
167 }
168 
169 void JITCompiler::link(LinkBuffer&amp; linkBuffer)
170 {
171     // Link the code, populate data in CodeBlock data structures.
172     m_jitCode-&gt;common.frameRegisterCount = m_graph.frameRegisterCount();
173     m_jitCode-&gt;common.requiredRegisterCountForExit = m_graph.requiredRegisterCountForExit();
174 
175     if (!m_graph.m_plan.inlineCallFrames()-&gt;isEmpty())
176         m_jitCode-&gt;common.inlineCallFrames = m_graph.m_plan.inlineCallFrames();
177 
178 #if USE(JSVALUE32_64)
179     m_jitCode-&gt;common.doubleConstants = WTFMove(m_graph.m_doubleConstants);
180 #endif
181 
182     m_graph.registerFrozenValues();
183 
184     BitVector usedJumpTables;
185     for (Bag&lt;SwitchData&gt;::iterator iter = m_graph.m_switchData.begin(); !!iter; ++iter) {
186         SwitchData&amp; data = **iter;
187         if (!data.didUseJumpTable)
188             continue;
189 
190         if (data.kind == SwitchString)
191             continue;
192 
193         RELEASE_ASSERT(data.kind == SwitchImm || data.kind == SwitchChar);
194 
195         usedJumpTables.set(data.switchTableIndex);
196         SimpleJumpTable&amp; table = m_codeBlock-&gt;switchJumpTable(data.switchTableIndex);
197         table.ctiDefault = linkBuffer.locationOf&lt;JSSwitchPtrTag&gt;(m_blockHeads[data.fallThrough.block-&gt;index]);
198         table.ctiOffsets.grow(table.branchOffsets.size());
199         for (unsigned j = table.ctiOffsets.size(); j--;)
200             table.ctiOffsets[j] = table.ctiDefault;
201         for (unsigned j = data.cases.size(); j--;) {
202             SwitchCase&amp; myCase = data.cases[j];
203             table.ctiOffsets[myCase.value.switchLookupValue(data.kind) - table.min] =
204                 linkBuffer.locationOf&lt;JSSwitchPtrTag&gt;(m_blockHeads[myCase.target.block-&gt;index]);
205         }
206     }
207 
208     for (unsigned i = m_codeBlock-&gt;numberOfSwitchJumpTables(); i--;) {
209         if (usedJumpTables.get(i))
210             continue;
211 
212         m_codeBlock-&gt;switchJumpTable(i).clear();
213     }
214 
215     // NOTE: we cannot clear string switch tables because (1) we&#39;re running concurrently
216     // and we cannot deref StringImpl&#39;s and (2) it would be weird to deref those
217     // StringImpl&#39;s since we refer to them.
218     for (Bag&lt;SwitchData&gt;::iterator switchDataIter = m_graph.m_switchData.begin(); !!switchDataIter; ++switchDataIter) {
219         SwitchData&amp; data = **switchDataIter;
220         if (!data.didUseJumpTable)
221             continue;
222 
223         if (data.kind != SwitchString)
224             continue;
225 
226         StringJumpTable&amp; table = m_codeBlock-&gt;stringSwitchJumpTable(data.switchTableIndex);
227 
228         table.ctiDefault = linkBuffer.locationOf&lt;JSSwitchPtrTag&gt;(m_blockHeads[data.fallThrough.block-&gt;index]);
229         StringJumpTable::StringOffsetTable::iterator iter;
230         StringJumpTable::StringOffsetTable::iterator end = table.offsetTable.end();
231         for (iter = table.offsetTable.begin(); iter != end; ++iter)
232             iter-&gt;value.ctiOffset = table.ctiDefault;
233         for (unsigned j = data.cases.size(); j--;) {
234             SwitchCase&amp; myCase = data.cases[j];
235             iter = table.offsetTable.find(myCase.value.stringImpl());
236             RELEASE_ASSERT(iter != end);
237             iter-&gt;value.ctiOffset = linkBuffer.locationOf&lt;JSSwitchPtrTag&gt;(m_blockHeads[myCase.target.block-&gt;index]);
238         }
239     }
240 
241     // Link all calls out from the JIT code to their respective functions.
242     for (unsigned i = 0; i &lt; m_calls.size(); ++i)
243         linkBuffer.link(m_calls[i].m_call, m_calls[i].m_function);
244 
245     finalizeInlineCaches(m_getByIds, linkBuffer);
246     finalizeInlineCaches(m_getByIdsWithThis, linkBuffer);
<a name="10" id="anc10"></a><span class="line-added">247     finalizeInlineCaches(m_getByVals, linkBuffer);</span>
248     finalizeInlineCaches(m_putByIds, linkBuffer);
249     finalizeInlineCaches(m_inByIds, linkBuffer);
250     finalizeInlineCaches(m_instanceOfs, linkBuffer);
251 
252     auto linkCallThunk = FunctionPtr&lt;NoPtrTag&gt;(vm().getCTIStub(linkCallThunkGenerator).retaggedCode&lt;NoPtrTag&gt;());
253     for (auto&amp; record : m_jsCalls) {
254         CallLinkInfo&amp; info = *record.info;
255         linkBuffer.link(record.slowCall, linkCallThunk);
256         info.setCallLocations(
257             CodeLocationLabel&lt;JSInternalPtrTag&gt;(linkBuffer.locationOfNearCall&lt;JSInternalPtrTag&gt;(record.slowCall)),
258             CodeLocationLabel&lt;JSInternalPtrTag&gt;(linkBuffer.locationOf&lt;JSInternalPtrTag&gt;(record.targetToCheck)),
259             linkBuffer.locationOfNearCall&lt;JSInternalPtrTag&gt;(record.fastCall));
260     }
261 
262     for (JSDirectCallRecord&amp; record : m_jsDirectCalls) {
263         CallLinkInfo&amp; info = *record.info;
264         linkBuffer.link(record.call, linkBuffer.locationOf&lt;NoPtrTag&gt;(record.slowPath));
265         info.setCallLocations(
266             CodeLocationLabel&lt;JSInternalPtrTag&gt;(),
267             linkBuffer.locationOf&lt;JSInternalPtrTag&gt;(record.slowPath),
268             linkBuffer.locationOfNearCall&lt;JSInternalPtrTag&gt;(record.call));
269     }
270 
271     for (JSDirectTailCallRecord&amp; record : m_jsDirectTailCalls) {
272         CallLinkInfo&amp; info = *record.info;
273         info.setCallLocations(
274             linkBuffer.locationOf&lt;JSInternalPtrTag&gt;(record.patchableJump),
275             linkBuffer.locationOf&lt;JSInternalPtrTag&gt;(record.slowPath),
276             linkBuffer.locationOfNearCall&lt;JSInternalPtrTag&gt;(record.call));
277     }
278 
279     MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; osrExitThunk = vm().getCTIStub(osrExitGenerationThunkGenerator);
280     auto target = CodeLocationLabel&lt;JITThunkPtrTag&gt;(osrExitThunk.code());
281     for (unsigned i = 0; i &lt; m_jitCode-&gt;osrExit.size(); ++i) {
282         OSRExitCompilationInfo&amp; info = m_exitCompilationInfo[i];
283         if (!Options::useProbeOSRExit()) {
284             linkBuffer.link(info.m_patchableJump.m_jump, target);
285             OSRExit&amp; exit = m_jitCode-&gt;osrExit[i];
286             exit.m_patchableJumpLocation = linkBuffer.locationOf&lt;JSInternalPtrTag&gt;(info.m_patchableJump);
287         }
288         if (info.m_replacementSource.isSet()) {
289             m_jitCode-&gt;common.jumpReplacements.append(JumpReplacement(
290                 linkBuffer.locationOf&lt;JSInternalPtrTag&gt;(info.m_replacementSource),
291                 linkBuffer.locationOf&lt;OSRExitPtrTag&gt;(info.m_replacementDestination)));
292         }
293     }
294 
295     if (UNLIKELY(m_graph.compilation())) {
296         ASSERT(m_exitSiteLabels.size() == m_jitCode-&gt;osrExit.size());
297         for (unsigned i = 0; i &lt; m_exitSiteLabels.size(); ++i) {
298             Vector&lt;Label&gt;&amp; labels = m_exitSiteLabels[i];
299             Vector&lt;MacroAssemblerCodePtr&lt;JSInternalPtrTag&gt;&gt; addresses;
300             for (unsigned j = 0; j &lt; labels.size(); ++j)
301                 addresses.append(linkBuffer.locationOf&lt;JSInternalPtrTag&gt;(labels[j]));
302             m_graph.compilation()-&gt;addOSRExitSite(addresses);
303         }
304     } else
305         ASSERT(!m_exitSiteLabels.size());
306 
307     m_jitCode-&gt;common.compilation = m_graph.compilation();
308 
309     // Link new DFG exception handlers and remove baseline JIT handlers.
310     m_codeBlock-&gt;clearExceptionHandlers();
311     for (unsigned  i = 0; i &lt; m_exceptionHandlerOSRExitCallSites.size(); i++) {
312         OSRExitCompilationInfo&amp; info = m_exceptionHandlerOSRExitCallSites[i].exitInfo;
313         if (info.m_replacementDestination.isSet()) {
314             // If this is is *not* set, it means that we already jumped to the OSR exit in pure generated control flow.
315             // i.e, we explicitly emitted an exceptionCheck that we know will be caught in this machine frame.
316             // If this *is set*, it means we will be landing at this code location from genericUnwind from an
317             // exception thrown in a child call frame.
318             CodeLocationLabel&lt;ExceptionHandlerPtrTag&gt; catchLabel = linkBuffer.locationOf&lt;ExceptionHandlerPtrTag&gt;(info.m_replacementDestination);
319             HandlerInfo newExceptionHandler = m_exceptionHandlerOSRExitCallSites[i].baselineExceptionHandler;
320             CallSiteIndex callSite = m_exceptionHandlerOSRExitCallSites[i].callSiteIndex;
321             newExceptionHandler.start = callSite.bits();
322             newExceptionHandler.end = callSite.bits() + 1;
323             newExceptionHandler.nativeCode = catchLabel;
324             m_codeBlock-&gt;appendExceptionHandler(newExceptionHandler);
325         }
326     }
327 
328     if (m_pcToCodeOriginMapBuilder.didBuildMapping())
329         m_codeBlock-&gt;setPCToCodeOriginMap(makeUnique&lt;PCToCodeOriginMap&gt;(WTFMove(m_pcToCodeOriginMapBuilder), linkBuffer));
330 }
331 
332 static void emitStackOverflowCheck(JITCompiler&amp; jit, MacroAssembler::JumpList&amp; stackOverflow)
333 {
334     int frameTopOffset = virtualRegisterForLocal(jit.graph().requiredRegisterCountForExecutionAndExit() - 1).offset() * sizeof(Register);
335     unsigned maxFrameSize = -frameTopOffset;
336 
337     jit.addPtr(MacroAssembler::TrustedImm32(frameTopOffset), GPRInfo::callFrameRegister, GPRInfo::regT1);
338     if (UNLIKELY(maxFrameSize &gt; Options::reservedZoneSize()))
339         stackOverflow.append(jit.branchPtr(MacroAssembler::Above, GPRInfo::regT1, GPRInfo::callFrameRegister));
340     stackOverflow.append(jit.branchPtr(MacroAssembler::Above, MacroAssembler::AbsoluteAddress(jit.vm().addressOfSoftStackLimit()), GPRInfo::regT1));
341 }
342 
343 void JITCompiler::compile()
344 {
345     makeCatchOSREntryBuffer();
346 
347     setStartOfCode();
348     compileEntry();
349     m_speculative = makeUnique&lt;SpeculativeJIT&gt;(*this);
350 
351     // Plant a check that sufficient space is available in the JSStack.
352     JumpList stackOverflow;
353     emitStackOverflowCheck(*this, stackOverflow);
354 
355     addPtr(TrustedImm32(-(m_graph.frameRegisterCount() * sizeof(Register))), GPRInfo::callFrameRegister, stackPointerRegister);
<a name="11" id="anc11"></a>

356     checkStackPointerAlignment();
357     compileSetupRegistersForEntry();
358     compileEntryExecutionFlag();
359     compileBody();
360     setEndOfMainPath();
361 
362     // === Footer code generation ===
363     //
364     // Generate the stack overflow handling; if the stack check in the entry head fails,
365     // we need to call out to a helper function to throw the StackOverflowError.
366     stackOverflow.link(this);
367 
<a name="12" id="anc12"></a><span class="line-modified">368     emitStoreCodeOrigin(CodeOrigin(BytecodeIndex(0)));</span>
369 
370     if (maxFrameExtentForSlowPathCall)
371         addPtr(TrustedImm32(-static_cast&lt;int32_t&gt;(maxFrameExtentForSlowPathCall)), stackPointerRegister);
372 
373     m_speculative-&gt;callOperationWithCallFrameRollbackOnException(operationThrowStackOverflowError, m_codeBlock);
374 
375     // Generate slow path code.
376     m_speculative-&gt;runSlowPathGenerators(m_pcToCodeOriginMapBuilder);
377     m_pcToCodeOriginMapBuilder.appendItem(labelIgnoringWatchpoints(), PCToCodeOriginMapBuilder::defaultCodeOrigin());
378 
379     compileExceptionHandlers();
380     linkOSRExits();
381 
382     // Create OSR entry trampolines if necessary.
383     m_speculative-&gt;createOSREntries();
384     setEndOfCode();
385 
386     auto linkBuffer = makeUnique&lt;LinkBuffer&gt;(*this, m_codeBlock, JITCompilationCanFail);
387     if (linkBuffer-&gt;didFailToAllocate()) {
388         m_graph.m_plan.setFinalizer(makeUnique&lt;FailedFinalizer&gt;(m_graph.m_plan));
389         return;
390     }
391 
392     link(*linkBuffer);
393     m_speculative-&gt;linkOSREntries(*linkBuffer);
394 
<a name="13" id="anc13"></a>


395     disassemble(*linkBuffer);
396 
397     m_graph.m_plan.setFinalizer(makeUnique&lt;JITFinalizer&gt;(
398         m_graph.m_plan, m_jitCode.releaseNonNull(), WTFMove(linkBuffer)));
399 }
400 
401 void JITCompiler::compileFunction()
402 {
403     makeCatchOSREntryBuffer();
404 
405     setStartOfCode();
406     Label entryLabel(this);
407     compileEntry();
408 
409     // === Function header code generation ===
410     // This is the main entry point, without performing an arity check.
411     // If we needed to perform an arity check we will already have moved the return address,
412     // so enter after this.
413     Label fromArityCheck(this);
414     // Plant a check that sufficient space is available in the JSStack.
415     JumpList stackOverflow;
416     emitStackOverflowCheck(*this, stackOverflow);
417 
418     // Move the stack pointer down to accommodate locals
419     addPtr(TrustedImm32(-(m_graph.frameRegisterCount() * sizeof(Register))), GPRInfo::callFrameRegister, stackPointerRegister);
<a name="14" id="anc14"></a>

420     checkStackPointerAlignment();
421 
422     compileSetupRegistersForEntry();
423     compileEntryExecutionFlag();
424 
425     // === Function body code generation ===
426     m_speculative = makeUnique&lt;SpeculativeJIT&gt;(*this);
427     compileBody();
428     setEndOfMainPath();
429 
430     // === Function footer code generation ===
431     //
432     // Generate code to perform the stack overflow handling (if the stack check in
433     // the function header fails), and generate the entry point with arity check.
434     //
435     // Generate the stack overflow handling; if the stack check in the function head fails,
436     // we need to call out to a helper function to throw the StackOverflowError.
437     stackOverflow.link(this);
438 
<a name="15" id="anc15"></a><span class="line-modified">439     emitStoreCodeOrigin(CodeOrigin(BytecodeIndex(0)));</span>
440 
441     if (maxFrameExtentForSlowPathCall)
442         addPtr(TrustedImm32(-static_cast&lt;int32_t&gt;(maxFrameExtentForSlowPathCall)), stackPointerRegister);
443 
444     m_speculative-&gt;callOperationWithCallFrameRollbackOnException(operationThrowStackOverflowError, m_codeBlock);
445 
446     // The fast entry point into a function does not check the correct number of arguments
447     // have been passed to the call (we only use the fast entry point where we can statically
448     // determine the correct number of arguments have been passed, or have already checked).
449     // In cases where an arity check is necessary, we enter here.
450     // FIXME: change this from a cti call to a DFG style operation (normal C calling conventions).
451     Call callArityFixup;
452     Label arityCheck;
453     bool requiresArityFixup = m_codeBlock-&gt;numParameters() != 1;
454     if (requiresArityFixup) {
455         arityCheck = label();
456         compileEntry();
457 
<a name="16" id="anc16"></a><span class="line-modified">458         load32(AssemblyHelpers::payloadFor((VirtualRegister)CallFrameSlot::argumentCountIncludingThis), GPRInfo::regT1);</span>
459         branch32(AboveOrEqual, GPRInfo::regT1, TrustedImm32(m_codeBlock-&gt;numParameters())).linkTo(fromArityCheck, this);
<a name="17" id="anc17"></a><span class="line-modified">460         emitStoreCodeOrigin(CodeOrigin(BytecodeIndex(0)));</span>
461         if (maxFrameExtentForSlowPathCall)
462             addPtr(TrustedImm32(-static_cast&lt;int32_t&gt;(maxFrameExtentForSlowPathCall)), stackPointerRegister);
<a name="18" id="anc18"></a><span class="line-modified">463         m_speculative-&gt;callOperationWithCallFrameRollbackOnException(m_codeBlock-&gt;isConstructor() ? operationConstructArityCheck : operationCallArityCheck, GPRInfo::regT0, m_codeBlock-&gt;globalObject());</span>
464         if (maxFrameExtentForSlowPathCall)
465             addPtr(TrustedImm32(maxFrameExtentForSlowPathCall), stackPointerRegister);
466         branchTest32(Zero, GPRInfo::returnValueGPR).linkTo(fromArityCheck, this);
<a name="19" id="anc19"></a><span class="line-modified">467         emitStoreCodeOrigin(CodeOrigin(BytecodeIndex(0)));</span>
468         move(GPRInfo::returnValueGPR, GPRInfo::argumentGPR0);
469         callArityFixup = nearCall();
470         jump(fromArityCheck);
471     } else
472         arityCheck = entryLabel;
473 
474     // Generate slow path code.
475     m_speculative-&gt;runSlowPathGenerators(m_pcToCodeOriginMapBuilder);
476     m_pcToCodeOriginMapBuilder.appendItem(labelIgnoringWatchpoints(), PCToCodeOriginMapBuilder::defaultCodeOrigin());
477 
478     compileExceptionHandlers();
479     linkOSRExits();
480 
481     // Create OSR entry trampolines if necessary.
482     m_speculative-&gt;createOSREntries();
483     setEndOfCode();
484 
485     // === Link ===
486     auto linkBuffer = makeUnique&lt;LinkBuffer&gt;(*this, m_codeBlock, JITCompilationCanFail);
487     if (linkBuffer-&gt;didFailToAllocate()) {
488         m_graph.m_plan.setFinalizer(makeUnique&lt;FailedFinalizer&gt;(m_graph.m_plan));
489         return;
490     }
491     link(*linkBuffer);
492     m_speculative-&gt;linkOSREntries(*linkBuffer);
493 
<a name="20" id="anc20"></a>


494     if (requiresArityFixup)
495         linkBuffer-&gt;link(callArityFixup, FunctionPtr&lt;JITThunkPtrTag&gt;(vm().getCTIStub(arityFixupGenerator).code()));
496 
497     disassemble(*linkBuffer);
498 
499     MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; withArityCheck = linkBuffer-&gt;locationOf&lt;JSEntryPtrTag&gt;(arityCheck);
500 
501     m_graph.m_plan.setFinalizer(makeUnique&lt;JITFinalizer&gt;(
502         m_graph.m_plan, m_jitCode.releaseNonNull(), WTFMove(linkBuffer), withArityCheck));
503 }
504 
505 void JITCompiler::disassemble(LinkBuffer&amp; linkBuffer)
506 {
507     if (shouldDumpDisassembly()) {
508         m_disassembler-&gt;dump(linkBuffer);
509         linkBuffer.didAlreadyDisassemble();
510     }
511 
512     if (UNLIKELY(m_graph.m_plan.compilation()))
513         m_disassembler-&gt;reportToProfiler(m_graph.m_plan.compilation(), linkBuffer);
514 }
515 
516 #if USE(JSVALUE32_64)
517 void* JITCompiler::addressOfDoubleConstant(Node* node)
518 {
519     double value = node-&gt;asNumber();
520     int64_t valueBits = bitwise_cast&lt;int64_t&gt;(value);
521     auto it = m_graph.m_doubleConstantsMap.find(valueBits);
522     if (it != m_graph.m_doubleConstantsMap.end())
523         return it-&gt;second;
524 
525     if (!m_graph.m_doubleConstants)
526         m_graph.m_doubleConstants = makeUnique&lt;Bag&lt;double&gt;&gt;();
527 
528     double* addressInConstantPool = m_graph.m_doubleConstants-&gt;add();
529     *addressInConstantPool = value;
530     m_graph.m_doubleConstantsMap[valueBits] = addressInConstantPool;
531     return addressInConstantPool;
532 }
533 #endif
534 
535 void JITCompiler::noticeCatchEntrypoint(BasicBlock&amp; basicBlock, JITCompiler::Label blockHead, LinkBuffer&amp; linkBuffer, Vector&lt;FlushFormat&gt;&amp;&amp; argumentFormats)
536 {
537     RELEASE_ASSERT(basicBlock.isCatchEntrypoint);
538     RELEASE_ASSERT(basicBlock.intersectionOfCFAHasVisited); // An entrypoint is reachable by definition.
539     m_jitCode-&gt;common.appendCatchEntrypoint(basicBlock.bytecodeBegin, linkBuffer.locationOf&lt;ExceptionHandlerPtrTag&gt;(blockHead), WTFMove(argumentFormats));
540 }
541 
542 void JITCompiler::noticeOSREntry(BasicBlock&amp; basicBlock, JITCompiler::Label blockHead, LinkBuffer&amp; linkBuffer)
543 {
544     RELEASE_ASSERT(!basicBlock.isCatchEntrypoint);
545 
546     // OSR entry is not allowed into blocks deemed unreachable by control flow analysis.
547     if (!basicBlock.intersectionOfCFAHasVisited)
548         return;
549 
550     OSREntryData* entry = m_jitCode-&gt;appendOSREntryData(basicBlock.bytecodeBegin, linkBuffer.locationOf&lt;OSREntryPtrTag&gt;(blockHead));
551 
552     entry-&gt;m_expectedValues = basicBlock.intersectionOfPastValuesAtHead;
553 
554     // Fix the expected values: in our protocol, a dead variable will have an expected
555     // value of (None, []). But the old JIT may stash some values there. So we really
556     // need (Top, TOP).
557     for (size_t argument = 0; argument &lt; basicBlock.variablesAtHead.numberOfArguments(); ++argument) {
558         Node* node = basicBlock.variablesAtHead.argument(argument);
559         if (!node || !node-&gt;shouldGenerate())
560             entry-&gt;m_expectedValues.argument(argument).makeBytecodeTop();
561     }
562     for (size_t local = 0; local &lt; basicBlock.variablesAtHead.numberOfLocals(); ++local) {
563         Node* node = basicBlock.variablesAtHead.local(local);
564         if (!node || !node-&gt;shouldGenerate())
565             entry-&gt;m_expectedValues.local(local).makeBytecodeTop();
566         else {
567             VariableAccessData* variable = node-&gt;variableAccessData();
568             entry-&gt;m_machineStackUsed.set(variable-&gt;machineLocal().toLocal());
569 
570             switch (variable-&gt;flushFormat()) {
571             case FlushedDouble:
572                 entry-&gt;m_localsForcedDouble.set(local);
573                 break;
574             case FlushedInt52:
575                 entry-&gt;m_localsForcedAnyInt.set(local);
576                 break;
577             default:
578                 break;
579             }
580 
<a name="21" id="anc21"></a><span class="line-modified">581             ASSERT(!variable-&gt;operand().isTmp());</span>
<span class="line-added">582             if (variable-&gt;operand().virtualRegister() != variable-&gt;machineLocal()) {</span>
583                 entry-&gt;m_reshufflings.append(
584                     OSREntryReshuffling(
<a name="22" id="anc22"></a><span class="line-modified">585                         variable-&gt;operand().virtualRegister().offset(), variable-&gt;machineLocal().offset()));</span>
586             }
587         }
588     }
589 
590     entry-&gt;m_reshufflings.shrinkToFit();
591 }
592 
593 void JITCompiler::appendExceptionHandlingOSRExit(ExitKind kind, unsigned eventStreamIndex, CodeOrigin opCatchOrigin, HandlerInfo* exceptionHandler, CallSiteIndex callSite, MacroAssembler::JumpList jumpsToFail)
594 {
595     OSRExit exit(kind, JSValueRegs(), MethodOfGettingAValueProfile(), m_speculative.get(), eventStreamIndex);
596     exit.m_codeOrigin = opCatchOrigin;
597     exit.m_exceptionHandlerCallSiteIndex = callSite;
598     OSRExitCompilationInfo&amp; exitInfo = appendExitInfo(jumpsToFail);
599     jitCode()-&gt;appendOSRExit(exit);
600     m_exceptionHandlerOSRExitCallSites.append(ExceptionHandlingOSRExitInfo { exitInfo, *exceptionHandler, callSite });
601 }
602 
603 void JITCompiler::exceptionCheck()
604 {
605     // It&#39;s important that we use origin.forExit here. Consider if we hoist string
606     // addition outside a loop, and that we exit at the point of that concatenation
607     // from an out of memory exception.
608     // If the original loop had a try/catch around string concatenation, if we &quot;catch&quot;
609     // that exception inside the loop, then the loops induction variable will be undefined
610     // in the OSR exit value recovery. It&#39;s more defensible for the string concatenation,
611     // then, to not be caught by the for loops&#39; try/catch.
612     // Here is the program I&#39;m speaking about:
613     //
614     // &gt;&gt;&gt;&gt; lets presume &quot;c = a + b&quot; gets hoisted here.
615     // for (var i = 0; i &lt; length; i++) {
616     //     try {
617     //         c = a + b
618     //     } catch(e) {
619     //         If we threw an out of memory error, and we cought the exception
620     //         right here, then &quot;i&quot; would almost certainly be undefined, which
621     //         would make no sense.
622     //         ...
623     //     }
624     // }
625     CodeOrigin opCatchOrigin;
626     HandlerInfo* exceptionHandler;
627     bool willCatchException = m_graph.willCatchExceptionInMachineFrame(m_speculative-&gt;m_currentNode-&gt;origin.forExit, opCatchOrigin, exceptionHandler);
628     if (willCatchException) {
629         unsigned streamIndex = m_speculative-&gt;m_outOfLineStreamIndex ? *m_speculative-&gt;m_outOfLineStreamIndex : m_speculative-&gt;m_stream-&gt;size();
630         MacroAssembler::Jump hadException = emitNonPatchableExceptionCheck(vm());
631         // We assume here that this is called after callOpeartion()/appendCall() is called.
632         appendExceptionHandlingOSRExit(ExceptionCheck, streamIndex, opCatchOrigin, exceptionHandler, m_jitCode-&gt;common.lastCallSite(), hadException);
633     } else
634         m_exceptionChecks.append(emitExceptionCheck(vm()));
635 }
636 
637 CallSiteIndex JITCompiler::recordCallSiteAndGenerateExceptionHandlingOSRExitIfNeeded(const CodeOrigin&amp; callSiteCodeOrigin, unsigned eventStreamIndex)
638 {
639     CodeOrigin opCatchOrigin;
640     HandlerInfo* exceptionHandler;
641     bool willCatchException = m_graph.willCatchExceptionInMachineFrame(callSiteCodeOrigin, opCatchOrigin, exceptionHandler);
642     CallSiteIndex callSite = addCallSite(callSiteCodeOrigin);
643     if (willCatchException)
644         appendExceptionHandlingOSRExit(GenericUnwind, eventStreamIndex, opCatchOrigin, exceptionHandler, callSite);
645     return callSite;
646 }
647 
648 void JITCompiler::setEndOfMainPath()
649 {
650     m_pcToCodeOriginMapBuilder.appendItem(labelIgnoringWatchpoints(), m_speculative-&gt;m_origin.semantic);
651     if (LIKELY(!m_disassembler))
652         return;
653     m_disassembler-&gt;setEndOfMainPath(labelIgnoringWatchpoints());
654 }
655 
656 void JITCompiler::setEndOfCode()
657 {
658     m_pcToCodeOriginMapBuilder.appendItem(labelIgnoringWatchpoints(), PCToCodeOriginMapBuilder::defaultCodeOrigin());
659     if (LIKELY(!m_disassembler))
660         return;
661     m_disassembler-&gt;setEndOfCode(labelIgnoringWatchpoints());
662 }
663 
664 void JITCompiler::makeCatchOSREntryBuffer()
665 {
666     if (m_graph.m_maxLocalsForCatchOSREntry) {
667         uint32_t numberOfLiveLocals = std::max(*m_graph.m_maxLocalsForCatchOSREntry, 1u); // Make sure we always allocate a non-null catchOSREntryBuffer.
668         m_jitCode-&gt;common.catchOSREntryBuffer = vm().scratchBufferForSize(sizeof(JSValue) * numberOfLiveLocals);
669     }
670 }
671 
672 } } // namespace JSC::DFG
673 
674 #endif // ENABLE(DFG_JIT)
<a name="23" id="anc23"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="23" type="hidden" />
</body>
</html>