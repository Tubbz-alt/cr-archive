<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/Heap.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2014-2019 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #ifndef Heap_h
 27 #define Heap_h
 28 
 29 #include &quot;BumpRange.h&quot;
 30 #include &quot;Chunk.h&quot;
 31 #include &quot;FailureAction.h&quot;
 32 #include &quot;HeapKind.h&quot;
 33 #include &quot;LargeMap.h&quot;
 34 #include &quot;List.h&quot;
 35 #include &quot;Map.h&quot;
 36 #include &quot;Mutex.h&quot;
 37 #include &quot;Object.h&quot;
 38 #include &quot;PerHeapKind.h&quot;
 39 #include &quot;PerProcess.h&quot;
 40 #include &quot;PhysicalPageMap.h&quot;
 41 #include &quot;SmallLine.h&quot;
 42 #include &quot;SmallPage.h&quot;
 43 #include &lt;array&gt;
 44 #include &lt;condition_variable&gt;
 45 #include &lt;mutex&gt;
 46 #include &lt;vector&gt;
 47 
 48 namespace bmalloc {
 49 
 50 class BulkDecommit;
 51 class BumpAllocator;
 52 class DebugHeap;
 53 class HeapConstants;
 54 class Scavenger;
 55 
 56 class Heap {
 57 public:
 58     Heap(HeapKind, LockHolder&amp;);
 59 
 60     static Mutex&amp; mutex() { return PerProcess&lt;PerHeapKind&lt;Heap&gt;&gt;::mutex(); }
 61 
 62     HeapKind kind() const { return m_kind; }
 63 
 64     void allocateSmallBumpRanges(UniqueLockHolder&amp;, size_t sizeClass,
 65         BumpAllocator&amp;, BumpRangeCache&amp;, LineCache&amp;, FailureAction);
 66     void derefSmallLine(UniqueLockHolder&amp;, Object, LineCache&amp;);
 67     void deallocateLineCache(UniqueLockHolder&amp;, LineCache&amp;);
 68 
 69     void* allocateLarge(UniqueLockHolder&amp;, size_t alignment, size_t, FailureAction);
 70     void deallocateLarge(UniqueLockHolder&amp;, void*);
 71 
 72     bool isLarge(UniqueLockHolder&amp;, void*);
 73     size_t largeSize(UniqueLockHolder&amp;, void*);
 74     void shrinkLarge(UniqueLockHolder&amp;, const Range&amp;, size_t);
 75 
 76 #if BUSE(PARTIAL_SCAVENGE)
 77     void scavengeToHighWatermark(const LockHolder&amp;, BulkDecommit&amp;);
 78     void scavenge(const LockHolder&amp;, BulkDecommit&amp;);
 79 #else
 80     void scavenge(const LockHolder&amp;, BulkDecommit&amp;, size_t&amp; deferredDecommits);
 81 #endif
 82     void scavenge(const LockHolder&amp;, BulkDecommit&amp;, size_t&amp; freed, size_t goal);
 83 
 84     size_t freeableMemory(const LockHolder&amp;);
 85     size_t footprint();
 86 
 87     void externalDecommit(void* ptr, size_t);
 88     void externalDecommit(UniqueLockHolder&amp;, void* ptr, size_t);
 89     void externalCommit(void* ptr, size_t);
 90     void externalCommit(UniqueLockHolder&amp;, void* ptr, size_t);
 91 
 92     void markAllLargeAsEligibile(const LockHolder&amp;);
 93 
 94 private:
 95     void decommitLargeRange(const LockHolder&amp;, LargeRange&amp;, BulkDecommit&amp;);
 96 
 97     struct LargeObjectHash {
 98         static unsigned hash(void* key)
 99         {
100             return static_cast&lt;unsigned&gt;(
101                 reinterpret_cast&lt;uintptr_t&gt;(key) / smallMax);
102         }
103     };
104 
105     ~Heap() = delete;
106 
107     bool usingGigacage();
108     void* gigacageBasePtr(); // May crash if !usingGigacage().
109     size_t gigacageSize();
110 
111     void allocateSmallBumpRangesByMetadata(UniqueLockHolder&amp;,
112         size_t sizeClass, BumpAllocator&amp;, BumpRangeCache&amp;, LineCache&amp;, FailureAction);
113     void allocateSmallBumpRangesByObject(UniqueLockHolder&amp;,
114         size_t sizeClass, BumpAllocator&amp;, BumpRangeCache&amp;, LineCache&amp;, FailureAction);
115 
116     SmallPage* allocateSmallPage(UniqueLockHolder&amp;, size_t sizeClass, LineCache&amp;, FailureAction);
117     void deallocateSmallLine(UniqueLockHolder&amp;, Object, LineCache&amp;);
118 
119     void allocateSmallChunk(UniqueLockHolder&amp;, size_t pageClass, FailureAction);
120     void deallocateSmallChunk(Chunk*, size_t pageClass);
121 
122     LargeRange tryAllocateLargeChunk(size_t alignment, size_t);
123     LargeRange splitAndAllocate(UniqueLockHolder&amp;, LargeRange&amp;, size_t alignment, size_t);
124 
125     HeapKind m_kind;
126     HeapConstants&amp; m_constants;
127 
128     bool m_hasPendingDecommits { false };
129     std::condition_variable_any m_condition;
130 
131     LineCache m_lineCache;
132     std::array&lt;List&lt;Chunk&gt;, pageClassCount&gt; m_freePages;
133     std::array&lt;List&lt;Chunk&gt;, pageClassCount&gt; m_chunkCache;
134 
135     Map&lt;void*, size_t, LargeObjectHash&gt; m_largeAllocated;
136     LargeMap m_largeFree;
137 
138     Map&lt;Chunk*, ObjectType, ChunkHash&gt; m_objectTypes;
139 
140     Scavenger* m_scavenger { nullptr };
141 
142     size_t m_footprint { 0 };
143     size_t m_freeableMemory { 0 };
144 
145 #if ENABLE_PHYSICAL_PAGE_MAP
146     PhysicalPageMap m_physicalPageMap;
147 #endif
148 
149 #if BUSE(PARTIAL_SCAVENGE)
150     void* m_highWatermark { nullptr };
151 #endif
152 };
153 
154 inline void Heap::allocateSmallBumpRanges(
155     UniqueLockHolder&amp; lock, size_t sizeClass,
156     BumpAllocator&amp; allocator, BumpRangeCache&amp; rangeCache,
157     LineCache&amp; lineCache, FailureAction action)
158 {
159     if (sizeClass &lt; bmalloc::sizeClass(smallLineSize))
160         return allocateSmallBumpRangesByMetadata(lock, sizeClass, allocator, rangeCache, lineCache, action);
161     return allocateSmallBumpRangesByObject(lock, sizeClass, allocator, rangeCache, lineCache, action);
162 }
163 
164 inline void Heap::derefSmallLine(UniqueLockHolder&amp; lock, Object object, LineCache&amp; lineCache)
165 {
166     if (!object.line()-&gt;deref(lock))
167         return;
168     deallocateSmallLine(lock, object, lineCache);
169 }
170 
171 } // namespace bmalloc
172 
173 #endif // Heap_h
    </pre>
  </body>
</html>