<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter.asm</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="LLIntThunks.h.udiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="LowLevelInterpreter.cpp.udiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter.asm</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -1,6 +1,6 @@</span>
<span class="udiff-line-modified-removed">- # Copyrsght (C) 2011-2019 Apple Inc. All rights reserved.</span>
<span class="udiff-line-modified-added">+ # Copyright (C) 2011-2019 Apple Inc. All rights reserved.</span>
  #
  # Redistribution and use in source and binary forms, with or without
  # modification, are permitted provided that the following conditions
  # are met:
  # 1. Redistributions of source code must retain the above copyright
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -72,12 +72,10 @@</span>
  #  registers on all architectures.
  #
  #  - lr is defined on non-X86 architectures (ARM64, ARM64E, ARMv7, MIPS and CLOOP)
  #  and holds the return PC
  #
<span class="udiff-line-removed">- #  - pc holds the (native) program counter on 32-bits ARM architectures (ARMv7)</span>
<span class="udiff-line-removed">- #</span>
  #  - t0, t1, t2, t3, t4, and optionally t5, t6, and t7 are temporary registers that can get trashed on
  #  calls, and are pairwise distinct registers. t4 holds the JS program counter, so use
  #  with caution in opcodes (actually, don&#39;t use it in opcodes at all, except as PC).
  #
  #  - r0 and r1 are the platform&#39;s customary return registers, and thus are
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -104,13 +102,13 @@</span>
  #  can be return registers.
  #
  #  - t4 and t5 are never argument registers, t3 can only be a3, t1 can only be
  #  a1; but t0 and t2 can be either a0 or a2.
  #
<span class="udiff-line-modified-removed">- #  - On 64 bits, there are callee-save registers named csr0, csr1, ... csrN.</span>
<span class="udiff-line-modified-added">+ #  - There are callee-save registers named csr0, csr1, ... csrN.</span>
  #  The last three csr registers are used used to store the PC base and
<span class="udiff-line-modified-removed">- #  two special tag values. Don&#39;t use them for anything else.</span>
<span class="udiff-line-modified-added">+ #  two special tag values (on 64-bits only). Don&#39;t use them for anything else.</span>
  #
  # Additional platform-specific details (you shouldn&#39;t rely on this remaining
  # true):
  #
  #  - For consistency with the baseline JIT, t0 is always r0 (and t1 is always
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -163,10 +161,11 @@</span>
      const CallFrameAlignSlots = 1
  end
  
  const JSLexicalEnvironment_variables = (sizeof JSLexicalEnvironment + SlotSize - 1) &amp; ~(SlotSize - 1)
  const DirectArguments_storage = (sizeof DirectArguments + SlotSize - 1) &amp; ~(SlotSize - 1)
<span class="udiff-line-added">+ const JSInternalFieldObjectImpl_internalFields = JSInternalFieldObjectImpl::m_internalFields</span>
  
  const StackAlignment = constexpr (stackAlignmentBytes())
  const StackAlignmentSlots = constexpr (stackAlignmentRegisters())
  const StackAlignmentMask = StackAlignment - 1
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -174,30 +173,31 @@</span>
  
  const CallerFrame = 0
  const ReturnPC = CallerFrame + MachineRegisterSize
  const CodeBlock = ReturnPC + MachineRegisterSize
  const Callee = CodeBlock + SlotSize
<span class="udiff-line-modified-removed">- const ArgumentCount = Callee + SlotSize</span>
<span class="udiff-line-modified-removed">- const ThisArgumentOffset = ArgumentCount + SlotSize</span>
<span class="udiff-line-modified-added">+ const ArgumentCountIncludingThis = Callee + SlotSize</span>
<span class="udiff-line-modified-added">+ const ThisArgumentOffset = ArgumentCountIncludingThis + SlotSize</span>
  const FirstArgumentOffset = ThisArgumentOffset + SlotSize
  const CallFrameHeaderSize = ThisArgumentOffset
  
  const MetadataOffsetTable16Offset = 0
  const MetadataOffsetTable32Offset = constexpr UnlinkedMetadataTable::s_offset16TableSize
<span class="udiff-line-added">+ const NumberOfJSOpcodeIDs = constexpr numOpcodeIDs</span>
  
  # Some value representation constants.
  if JSVALUE64
<span class="udiff-line-modified-removed">-     const TagBitTypeOther = constexpr TagBitTypeOther</span>
<span class="udiff-line-modified-removed">-     const TagBitBool      = constexpr TagBitBool</span>
<span class="udiff-line-modified-removed">-     const TagBitUndefined = constexpr TagBitUndefined</span>
<span class="udiff-line-modified-removed">-     const ValueEmpty      = constexpr ValueEmpty</span>
<span class="udiff-line-modified-removed">-     const ValueFalse      = constexpr ValueFalse</span>
<span class="udiff-line-modified-removed">-     const ValueTrue       = constexpr ValueTrue</span>
<span class="udiff-line-modified-removed">-     const ValueUndefined  = constexpr ValueUndefined</span>
<span class="udiff-line-modified-removed">-     const ValueNull       = constexpr ValueNull</span>
<span class="udiff-line-modified-removed">-     const TagTypeNumber   = constexpr TagTypeNumber</span>
<span class="udiff-line-modified-removed">-     const TagMask         = constexpr TagMask</span>
<span class="udiff-line-modified-added">+     const TagOther        = constexpr JSValue::OtherTag</span>
<span class="udiff-line-modified-added">+     const TagBool         = constexpr JSValue::BoolTag</span>
<span class="udiff-line-modified-added">+     const TagUndefined    = constexpr JSValue::UndefinedTag</span>
<span class="udiff-line-modified-added">+     const ValueEmpty      = constexpr JSValue::ValueEmpty</span>
<span class="udiff-line-modified-added">+     const ValueFalse      = constexpr JSValue::ValueFalse</span>
<span class="udiff-line-modified-added">+     const ValueTrue       = constexpr JSValue::ValueTrue</span>
<span class="udiff-line-modified-added">+     const ValueUndefined  = constexpr JSValue::ValueUndefined</span>
<span class="udiff-line-modified-added">+     const ValueNull       = constexpr JSValue::ValueNull</span>
<span class="udiff-line-modified-added">+     const TagNumber       = constexpr JSValue::NumberTag</span>
<span class="udiff-line-modified-added">+     const NotCellMask     = constexpr JSValue::NotCellMask</span>
  else
      const Int32Tag = constexpr JSValue::Int32Tag
      const BooleanTag = constexpr JSValue::BooleanTag
      const NullTag = constexpr JSValue::NullTag
      const UndefinedTag = constexpr JSValue::UndefinedTag
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -210,12 +210,10 @@</span>
  if JSVALUE64
      const NumberOfStructureIDEntropyBits = constexpr StructureIDTable::s_numberOfEntropyBits
      const StructureEntropyBitsShift = constexpr StructureIDTable::s_entropyBitsShiftForStructurePointer
  end
  
<span class="udiff-line-removed">- const CallOpCodeSize = constexpr op_call_length</span>
<span class="udiff-line-removed">- </span>
  const maxFrameExtentForSlowPathCall = constexpr maxFrameExtentForSlowPathCall
  
  if X86_64 or X86_64_WIN or ARM64 or ARM64E
      const CalleeSaveSpaceAsVirtualRegisters = 4
  elsif C_LOOP or C_LOOP_WIN
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -237,93 +235,132 @@</span>
  const IsInvalidated = constexpr IsInvalidated
  
  # ShadowChicken data
  const ShadowChickenTailMarker = constexpr ShadowChicken::Packet::tailMarkerValue
  
<span class="udiff-line-modified-removed">- # ArithProfile data</span>
<span class="udiff-line-modified-removed">- const ArithProfileInt = constexpr (ArithProfile::observedUnaryInt().bits())</span>
<span class="udiff-line-modified-removed">- const ArithProfileNumber = constexpr (ArithProfile::observedUnaryNumber().bits())</span>
<span class="udiff-line-modified-removed">- const ArithProfileIntInt = constexpr (ArithProfile::observedBinaryIntInt().bits())</span>
<span class="udiff-line-modified-removed">- const ArithProfileNumberInt = constexpr (ArithProfile::observedBinaryNumberInt().bits())</span>
<span class="udiff-line-modified-removed">- const ArithProfileIntNumber = constexpr (ArithProfile::observedBinaryIntNumber().bits())</span>
<span class="udiff-line-modified-removed">- const ArithProfileNumberNumber = constexpr (ArithProfile::observedBinaryNumberNumber().bits())</span>
<span class="udiff-line-modified-added">+ # UnaryArithProfile data</span>
<span class="udiff-line-modified-added">+ const ArithProfileInt = constexpr (UnaryArithProfile::observedIntBits())</span>
<span class="udiff-line-modified-added">+ const ArithProfileNumber = constexpr (UnaryArithProfile::observedNumberBits())</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+ # BinaryArithProfile data</span>
<span class="udiff-line-modified-added">+ const ArithProfileIntInt = constexpr (BinaryArithProfile::observedIntIntBits())</span>
<span class="udiff-line-modified-added">+ const ArithProfileNumberInt = constexpr (BinaryArithProfile::observedNumberIntBits())</span>
<span class="udiff-line-added">+ const ArithProfileIntNumber = constexpr (BinaryArithProfile::observedIntNumberBits())</span>
<span class="udiff-line-added">+ const ArithProfileNumberNumber = constexpr (BinaryArithProfile::observedNumberNumberBits())</span>
  
  # Pointer Tags
  const BytecodePtrTag = constexpr BytecodePtrTag
  const JSEntryPtrTag = constexpr JSEntryPtrTag
  const ExceptionHandlerPtrTag = constexpr ExceptionHandlerPtrTag
  const NoPtrTag = constexpr NoPtrTag
  const SlowPathPtrTag = constexpr SlowPathPtrTag
  
  # Some register conventions.
<span class="udiff-line-added">+ # - We use a pair of registers to represent the PC: one register for the</span>
<span class="udiff-line-added">+ #   base of the bytecodes, and one register for the index.</span>
<span class="udiff-line-added">+ # - The PC base (or PB for short) must be stored in a callee-save register.</span>
<span class="udiff-line-added">+ # - C calls are still given the Instruction* rather than the PC index.</span>
<span class="udiff-line-added">+ #   This requires an add before the call, and a sub after.</span>
  if JSVALUE64
<span class="udiff-line-removed">-     # - Use a pair of registers to represent the PC: one register for the</span>
<span class="udiff-line-removed">-     #   base of the bytecodes, and one register for the index.</span>
<span class="udiff-line-removed">-     # - The PC base (or PB for short) must be stored in a callee-save register.</span>
<span class="udiff-line-removed">-     # - C calls are still given the Instruction* rather than the PC index.</span>
<span class="udiff-line-removed">-     #   This requires an add before the call, and a sub after.</span>
      const PC = t4 # When changing this, make sure LLIntPC is up to date in LLIntPCRanges.h
      if ARM64 or ARM64E
          const metadataTable = csr6
          const PB = csr7
<span class="udiff-line-modified-removed">-         const tagTypeNumber = csr8</span>
<span class="udiff-line-modified-removed">-         const tagMask = csr9</span>
<span class="udiff-line-modified-added">+         const numberTag = csr8</span>
<span class="udiff-line-modified-added">+         const notCellMask = csr9</span>
      elsif X86_64
          const metadataTable = csr1
          const PB = csr2
<span class="udiff-line-modified-removed">-         const tagTypeNumber = csr3</span>
<span class="udiff-line-modified-removed">-         const tagMask = csr4</span>
<span class="udiff-line-modified-added">+         const numberTag = csr3</span>
<span class="udiff-line-modified-added">+         const notCellMask = csr4</span>
      elsif X86_64_WIN
          const metadataTable = csr3
          const PB = csr4
<span class="udiff-line-modified-removed">-         const tagTypeNumber = csr5</span>
<span class="udiff-line-modified-removed">-         const tagMask = csr6</span>
<span class="udiff-line-modified-added">+         const numberTag = csr5</span>
<span class="udiff-line-modified-added">+         const notCellMask = csr6</span>
      elsif C_LOOP or C_LOOP_WIN
          const PB = csr0
<span class="udiff-line-modified-removed">-         const tagTypeNumber = csr1</span>
<span class="udiff-line-modified-removed">-         const tagMask = csr2</span>
<span class="udiff-line-modified-added">+         const numberTag = csr1</span>
<span class="udiff-line-modified-added">+         const notCellMask = csr2</span>
          const metadataTable = csr3
      end
  
  else
      const PC = t4 # When changing this, make sure LLIntPC is up to date in LLIntPCRanges.h
      if C_LOOP or C_LOOP_WIN
<span class="udiff-line-added">+         const PB = csr0</span>
          const metadataTable = csr3
      elsif ARMv7
          const metadataTable = csr0
<span class="udiff-line-added">+         const PB = csr1</span>
      elsif MIPS
          const metadataTable = csr0
<span class="udiff-line-added">+         const PB = csr1</span>
      else
          error
      end
  end
  
<span class="udiff-line-added">+ if GIGACAGE_ENABLED</span>
<span class="udiff-line-added">+     const GigacagePrimitiveBasePtrOffset = constexpr Gigacage::offsetOfPrimitiveGigacageBasePtr</span>
<span class="udiff-line-added">+     const GigacageJSValueBasePtrOffset = constexpr Gigacage::offsetOfJSValueGigacageBasePtr</span>
<span class="udiff-line-added">+ end</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ # Opcode offsets</span>
<span class="udiff-line-added">+ const OpcodeIDNarrowSize = 1 # OpcodeID</span>
<span class="udiff-line-added">+ const OpcodeIDWide16Size = 2 # Wide16 Prefix + OpcodeID</span>
<span class="udiff-line-added">+ const OpcodeIDWide32Size = 2 # Wide32 Prefix + OpcodeID</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ macro nextInstruction()</span>
<span class="udiff-line-added">+     loadb [PB, PC, 1], t0</span>
<span class="udiff-line-added">+     leap _g_opcodeMap, t1</span>
<span class="udiff-line-added">+     jmp [t1, t0, PtrSize], BytecodePtrTag</span>
<span class="udiff-line-added">+ end</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ macro nextInstructionWide16()</span>
<span class="udiff-line-added">+     loadb OpcodeIDNarrowSize[PB, PC, 1], t0</span>
<span class="udiff-line-added">+     leap _g_opcodeMapWide16, t1</span>
<span class="udiff-line-added">+     jmp [t1, t0, PtrSize], BytecodePtrTag</span>
<span class="udiff-line-added">+ end</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ macro nextInstructionWide32()</span>
<span class="udiff-line-added">+     loadb OpcodeIDNarrowSize[PB, PC, 1], t0</span>
<span class="udiff-line-added">+     leap _g_opcodeMapWide32, t1</span>
<span class="udiff-line-added">+     jmp [t1, t0, PtrSize], BytecodePtrTag</span>
<span class="udiff-line-added">+ end</span>
<span class="udiff-line-added">+ </span>
  macro dispatch(advanceReg)
      addp advanceReg, PC
      nextInstruction()
  end
  
  macro dispatchIndirect(offsetReg)
      dispatch(offsetReg)
  end
  
<span class="udiff-line-modified-removed">- macro dispatchOp(size, opcodeName)</span>
<span class="udiff-line-modified-added">+ macro genericDispatchOp(dispatch, size, opcodeName)</span>
      macro dispatchNarrow()
<span class="udiff-line-modified-removed">-         dispatch(constexpr %opcodeName%_length)</span>
<span class="udiff-line-modified-added">+         dispatch((constexpr %opcodeName%_length - 1) * 1 + OpcodeIDNarrowSize)</span>
      end
  
      macro dispatchWide16()
<span class="udiff-line-modified-removed">-         dispatch(constexpr %opcodeName%_length * 2 + 1)</span>
<span class="udiff-line-modified-added">+         dispatch((constexpr %opcodeName%_length - 1) * 2 + OpcodeIDWide16Size)</span>
      end
  
      macro dispatchWide32()
<span class="udiff-line-modified-removed">-         dispatch(constexpr %opcodeName%_length * 4 + 1)</span>
<span class="udiff-line-modified-added">+         dispatch((constexpr %opcodeName%_length - 1) * 4 + OpcodeIDWide32Size)</span>
      end
  
      size(dispatchNarrow, dispatchWide16, dispatchWide32, macro (dispatch) dispatch() end)
  end
  
<span class="udiff-line-added">+ macro dispatchOp(size, opcodeName)</span>
<span class="udiff-line-added">+     genericDispatchOp(dispatch, size, opcodeName)</span>
<span class="udiff-line-added">+ end</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ </span>
  macro getu(size, opcodeStruct, fieldName, dst)
      size(getuOperandNarrow, getuOperandWide16, getuOperandWide32, macro (getu)
          getu(opcodeStruct, fieldName, dst)
      end)
  end
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -355,11 +392,11 @@</span>
      muli sizeof %opcode%::Metadata, scratch # scratch *= sizeof(Op::Metadata)
      addi scratch, dst # offset += scratch
      addp metadataTable, dst # return &amp;metadataTable[offset]
  end
  
<span class="udiff-line-modified-removed">- macro jumpImpl(targetOffsetReg)</span>
<span class="udiff-line-modified-added">+ macro jumpImpl(dispatchIndirect, targetOffsetReg)</span>
      btiz targetOffsetReg, .outOfLineJumpTarget
      dispatchIndirect(targetOffsetReg)
  .outOfLineJumpTarget:
      callSlowPath(_llint_slow_path_out_of_line_jump_target)
      nextInstruction()
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -367,24 +404,36 @@</span>
  
  macro commonOp(label, prologue, fn)
  _%label%:
      prologue()
      fn(narrow)
<span class="udiff-line-added">+     if ASSERT_ENABLED</span>
<span class="udiff-line-added">+         break</span>
<span class="udiff-line-added">+         break</span>
<span class="udiff-line-added">+     end</span>
  
  # FIXME: We cannot enable wide16 bytecode in Windows CLoop. With MSVC, as CLoop::execute gets larger code
  # size, CLoop::execute gets higher stack height requirement. This makes CLoop::execute takes 160KB stack
  # per call, causes stack overflow error easily. For now, we disable wide16 optimization for Windows CLoop.
  # https://bugs.webkit.org/show_bug.cgi?id=198283
  if not C_LOOP_WIN
  _%label%_wide16:
      prologue()
      fn(wide16)
<span class="udiff-line-added">+     if ASSERT_ENABLED</span>
<span class="udiff-line-added">+         break</span>
<span class="udiff-line-added">+         break</span>
<span class="udiff-line-added">+     end</span>
  end
  
  _%label%_wide32:
      prologue()
      fn(wide32)
<span class="udiff-line-added">+     if ASSERT_ENABLED</span>
<span class="udiff-line-added">+         break</span>
<span class="udiff-line-added">+         break</span>
<span class="udiff-line-added">+     end</span>
  end
  
  macro op(l, fn)
      commonOp(l, macro () end, macro (size)
          size(fn, macro() end, macro() end, macro(gen) gen() end)
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -424,11 +473,11 @@</span>
  
  macro llintOpWithJump(opcodeName, opcodeStruct, impl)
      llintOpWithMetadata(opcodeName, opcodeStruct, macro(size, get, dispatch, metadata, return)
          macro jump(fieldName)
              get(fieldName, t0)
<span class="udiff-line-modified-removed">-             jumpImpl(t0)</span>
<span class="udiff-line-modified-added">+             jumpImpl(dispatchIndirect, t0)</span>
          end
  
          impl(size, get, jump, dispatch)
      end)
  end
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -502,11 +551,11 @@</span>
  const EvalCode = constexpr EvalCode
  const FunctionCode = constexpr FunctionCode
  const ModuleCode = constexpr ModuleCode
  
  # The interpreter steals the tag word of the argument count.
<span class="udiff-line-modified-removed">- const LLIntReturnPC = ArgumentCount + TagOffset</span>
<span class="udiff-line-modified-added">+ const LLIntReturnPC = ArgumentCountIncludingThis + TagOffset</span>
  
  # String flags.
  const isRopeInPointer = constexpr JSString::isRopeInPointer
  const HashFlags8BitBuffer = constexpr StringImpl::s_hashFlag8BitBuffer
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -531,10 +580,12 @@</span>
  const NotInitialization = constexpr InitializationMode::NotInitialization
  
  const MarkedBlockSize = constexpr MarkedBlock::blockSize
  const MarkedBlockMask = ~(MarkedBlockSize - 1)
  const MarkedBlockFooterOffset = constexpr MarkedBlock::offsetOfFooter
<span class="udiff-line-added">+ const PreciseAllocationHeaderSize = constexpr (PreciseAllocation::headerSize())</span>
<span class="udiff-line-added">+ const PreciseAllocationVMOffset = (PreciseAllocation::m_weakSet + WeakSet::m_vm - PreciseAllocationHeaderSize)</span>
  
  const BlackThreshold = constexpr blackThreshold
  
  const VectorBufferOffset = Vector::m_buffer
  const VectorSizeOffset = Vector::m_size
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -554,10 +605,18 @@</span>
          crash()
      .ok:
      end
  end
  
<span class="udiff-line-added">+ macro assert_with(assertion, crash)</span>
<span class="udiff-line-added">+     if ASSERT_ENABLED</span>
<span class="udiff-line-added">+         assertion(.ok)</span>
<span class="udiff-line-added">+         crash()</span>
<span class="udiff-line-added">+     .ok:</span>
<span class="udiff-line-added">+     end</span>
<span class="udiff-line-added">+ end</span>
<span class="udiff-line-added">+ </span>
  # The probe macro can be used to insert some debugging code without perturbing scalar
  # registers. Presently, the probe macro only preserves scalar registers. Hence, the
  # C probe callback function should not trash floating point registers.
  #
  # The macro you pass to probe() can pass whatever registers you like to your probe
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -567,11 +626,11 @@</span>
  #
  # Here&#39;s an example of how it&#39;s used:
  #
  #     probe(
  #         macro()
<span class="udiff-line-modified-removed">- #             move cfr, a0 # pass the ExecState* as arg0.</span>
<span class="udiff-line-modified-added">+ #             move cfr, a0 # pass the CallFrame* as arg0.</span>
  #             move t0, a1 # pass the value of register t0 as arg1.
  #             call _cProbeCallbackFunction # to do whatever you want.
  #         end
  #     )
  #
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -591,11 +650,11 @@</span>
              push csr2, csr3
              push csr4, csr5
              push csr6, csr7
              push csr8, csr9
          elsif ARMv7
<span class="udiff-line-modified-removed">-             push csr0</span>
<span class="udiff-line-modified-added">+             push csr0, csr1</span>
          end
  
          action()
  
          # restore all the registers we saved previously.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -604,11 +663,11 @@</span>
              pop csr7, csr6
              pop csr5, csr4
              pop csr3, csr2
              pop csr1, csr0
          elsif ARMv7
<span class="udiff-line-modified-removed">-             pop csr0</span>
<span class="udiff-line-modified-added">+             pop csr1, csr0</span>
          end
          pop t5, t4
          pop t3, t2
          pop t1, t0
          pop a3, a2
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -647,11 +706,11 @@</span>
  if C_LOOP or C_LOOP_WIN or ARM64 or ARM64E or X86_64 or X86_64_WIN
      const CalleeSaveRegisterCount = 0
  elsif ARMv7
      const CalleeSaveRegisterCount = 7
  elsif MIPS
<span class="udiff-line-modified-removed">-     const CalleeSaveRegisterCount = 2</span>
<span class="udiff-line-modified-added">+     const CalleeSaveRegisterCount = 3</span>
  elsif X86 or X86_WIN
      const CalleeSaveRegisterCount = 3
  end
  
  const CalleeRegisterSaveSize = CalleeSaveRegisterCount * MachineRegisterSize
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -663,13 +722,14 @@</span>
  macro pushCalleeSaves()
      if C_LOOP or C_LOOP_WIN or ARM64 or ARM64E or X86_64 or X86_64_WIN
      elsif ARMv7
          emit &quot;push {r4-r6, r8-r11}&quot;
      elsif MIPS
<span class="udiff-line-modified-removed">-         emit &quot;addiu $sp, $sp, -8&quot;</span>
<span class="udiff-line-modified-added">+         emit &quot;addiu $sp, $sp, -12&quot;</span>
          emit &quot;sw $s0, 0($sp)&quot; # csr0/metaData
<span class="udiff-line-modified-removed">-         emit &quot;sw $s4, 4($sp)&quot;</span>
<span class="udiff-line-modified-added">+         emit &quot;sw $s1, 4($sp)&quot; # csr1/PB</span>
<span class="udiff-line-added">+         emit &quot;sw $s4, 8($sp)&quot;</span>
          # save $gp to $s4 so that we can restore it after a function call
          emit &quot;move $s4, $gp&quot;
      elsif X86
          emit &quot;push %esi&quot;
          emit &quot;push %edi&quot;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -685,12 +745,13 @@</span>
      if C_LOOP or C_LOOP_WIN or ARM64 or ARM64E or X86_64 or X86_64_WIN
      elsif ARMv7
          emit &quot;pop {r4-r6, r8-r11}&quot;
      elsif MIPS
          emit &quot;lw $s0, 0($sp)&quot;
<span class="udiff-line-modified-removed">-         emit &quot;lw $s4, 4($sp)&quot;</span>
<span class="udiff-line-modified-removed">-         emit &quot;addiu $sp, $sp, 8&quot;</span>
<span class="udiff-line-modified-added">+         emit &quot;lw $s1, 4($sp)&quot;</span>
<span class="udiff-line-modified-added">+         emit &quot;lw $s4, 8($sp)&quot;</span>
<span class="udiff-line-added">+         emit &quot;addiu $sp, $sp, 12&quot;</span>
      elsif X86
          emit &quot;pop %ebx&quot;
          emit &quot;pop %edi&quot;
          emit &quot;pop %esi&quot;
      elsif X86_WIN
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -728,12 +789,24 @@</span>
  
  macro preserveCalleeSavesUsedByLLInt()
      subp CalleeSaveSpaceStackAligned, sp
      if C_LOOP or C_LOOP_WIN
          storep metadataTable, -PtrSize[cfr]
<span class="udiff-line-modified-removed">-     elsif ARMv7 or MIPS</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-added">+     # Next ARMv7 and MIPS differ in how we store metadataTable and PB,</span>
<span class="udiff-line-added">+     # because this codes needs to be in sync with how registers are</span>
<span class="udiff-line-added">+     # restored in Baseline JIT (specifically in emitRestoreCalleeSavesFor).</span>
<span class="udiff-line-added">+     # emitRestoreCalleeSavesFor restores registers in order instead of by name.</span>
<span class="udiff-line-added">+     # However, ARMv7 and MIPS differ in the order in which registers are assigned</span>
<span class="udiff-line-added">+     # to metadataTable and PB, therefore they can also not have the same saving</span>
<span class="udiff-line-added">+     # order.</span>
<span class="udiff-line-added">+     elsif ARMv7</span>
          storep metadataTable, -4[cfr]
<span class="udiff-line-added">+         storep PB, -8[cfr]</span>
<span class="udiff-line-added">+     elsif MIPS</span>
<span class="udiff-line-added">+         storep PB, -4[cfr]</span>
<span class="udiff-line-added">+         storep metadataTable, -8[cfr]</span>
      elsif ARM64 or ARM64E
          emit &quot;stp x27, x28, [x29, #-16]&quot;
          emit &quot;stp x25, x26, [x29, #-32]&quot;
      elsif X86
      elsif X86_WIN
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -751,12 +824,18 @@</span>
  end
  
  macro restoreCalleeSavesUsedByLLInt()
      if C_LOOP or C_LOOP_WIN
          loadp -PtrSize[cfr], metadataTable
<span class="udiff-line-modified-removed">-     elsif ARMv7 or MIPS</span>
<span class="udiff-line-modified-added">+     # To understand why ARMv7 and MIPS differ in restore order,</span>
<span class="udiff-line-added">+     # see comment in preserveCalleeSavesUsedByLLInt</span>
<span class="udiff-line-added">+     elsif ARMv7</span>
          loadp -4[cfr], metadataTable
<span class="udiff-line-added">+         loadp -8[cfr], PB</span>
<span class="udiff-line-added">+     elsif MIPS</span>
<span class="udiff-line-added">+         loadp -4[cfr], PB</span>
<span class="udiff-line-added">+         loadp -8[cfr], metadataTable</span>
      elsif ARM64 or ARM64E
          emit &quot;ldp x25, x26, [x29, #-32]&quot;
          emit &quot;ldp x27, x28, [x29, #-16]&quot;
      elsif X86
      elsif X86_WIN
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -771,54 +850,61 @@</span>
          loadp -16[cfr], csr5
          loadp -8[cfr], csr6
      end
  end
  
<span class="udiff-line-modified-removed">- macro copyCalleeSavesToVMEntryFrameCalleeSavesBuffer(vm, temp)</span>
<span class="udiff-line-modified-added">+ macro copyCalleeSavesToEntryFrameCalleeSavesBuffer(entryFrame)</span>
      if ARM64 or ARM64E or X86_64 or X86_64_WIN or ARMv7 or MIPS
<span class="udiff-line-modified-removed">-         loadp VM::topEntryFrame[vm], temp</span>
<span class="udiff-line-modified-removed">-         vmEntryRecord(temp, temp)</span>
<span class="udiff-line-removed">-         leap VMEntryRecord::calleeSaveRegistersBuffer[temp], temp</span>
<span class="udiff-line-modified-added">+         vmEntryRecord(entryFrame, entryFrame)</span>
<span class="udiff-line-modified-added">+         leap VMEntryRecord::calleeSaveRegistersBuffer[entryFrame], entryFrame</span>
          if ARM64 or ARM64E
<span class="udiff-line-modified-removed">-             storeq csr0, [temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr1, 8[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr2, 16[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr3, 24[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr4, 32[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr5, 40[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr6, 48[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr7, 56[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr8, 64[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr9, 72[temp]</span>
<span class="udiff-line-modified-removed">-             stored csfr0, 80[temp]</span>
<span class="udiff-line-modified-removed">-             stored csfr1, 88[temp]</span>
<span class="udiff-line-modified-removed">-             stored csfr2, 96[temp]</span>
<span class="udiff-line-modified-removed">-             stored csfr3, 104[temp]</span>
<span class="udiff-line-modified-removed">-             stored csfr4, 112[temp]</span>
<span class="udiff-line-modified-removed">-             stored csfr5, 120[temp]</span>
<span class="udiff-line-modified-removed">-             stored csfr6, 128[temp]</span>
<span class="udiff-line-modified-removed">-             stored csfr7, 136[temp]</span>
<span class="udiff-line-modified-added">+             storeq csr0, [entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr1, 8[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr2, 16[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr3, 24[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr4, 32[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr5, 40[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr6, 48[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr7, 56[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr8, 64[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr9, 72[entryFrame]</span>
<span class="udiff-line-modified-added">+             stored csfr0, 80[entryFrame]</span>
<span class="udiff-line-modified-added">+             stored csfr1, 88[entryFrame]</span>
<span class="udiff-line-modified-added">+             stored csfr2, 96[entryFrame]</span>
<span class="udiff-line-modified-added">+             stored csfr3, 104[entryFrame]</span>
<span class="udiff-line-modified-added">+             stored csfr4, 112[entryFrame]</span>
<span class="udiff-line-modified-added">+             stored csfr5, 120[entryFrame]</span>
<span class="udiff-line-modified-added">+             stored csfr6, 128[entryFrame]</span>
<span class="udiff-line-modified-added">+             stored csfr7, 136[entryFrame]</span>
          elsif X86_64
<span class="udiff-line-modified-removed">-             storeq csr0, [temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr1, 8[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr2, 16[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr3, 24[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr4, 32[temp]</span>
<span class="udiff-line-modified-added">+             storeq csr0, [entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr1, 8[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr2, 16[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr3, 24[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr4, 32[entryFrame]</span>
          elsif X86_64_WIN
<span class="udiff-line-modified-removed">-             storeq csr0, [temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr1, 8[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr2, 16[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr3, 24[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr4, 32[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr5, 40[temp]</span>
<span class="udiff-line-modified-removed">-             storeq csr6, 48[temp]</span>
<span class="udiff-line-modified-added">+             storeq csr0, [entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr1, 8[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr2, 16[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr3, 24[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr4, 32[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr5, 40[entryFrame]</span>
<span class="udiff-line-modified-added">+             storeq csr6, 48[entryFrame]</span>
          elsif ARMv7 or MIPS
<span class="udiff-line-modified-removed">-             storep csr0, [temp]</span>
<span class="udiff-line-modified-added">+             storep csr0, [entryFrame]</span>
<span class="udiff-line-added">+             storep csr1, 4[entryFrame]</span>
          end
      end
  end
  
<span class="udiff-line-added">+ macro copyCalleeSavesToVMEntryFrameCalleeSavesBuffer(vm, temp)</span>
<span class="udiff-line-added">+     if ARM64 or ARM64E or X86_64 or X86_64_WIN or ARMv7 or MIPS</span>
<span class="udiff-line-added">+         loadp VM::topEntryFrame[vm], temp</span>
<span class="udiff-line-added">+         copyCalleeSavesToEntryFrameCalleeSavesBuffer(temp)</span>
<span class="udiff-line-added">+     end</span>
<span class="udiff-line-added">+ end</span>
<span class="udiff-line-added">+ </span>
  macro restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(vm, temp)
      if ARM64 or ARM64E or X86_64 or X86_64_WIN or ARMv7 or MIPS
          loadp VM::topEntryFrame[vm], temp
          vmEntryRecord(temp, temp)
          leap VMEntryRecord::calleeSaveRegistersBuffer[temp], temp
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -855,10 +941,11 @@</span>
              loadq 32[temp], csr4
              loadq 40[temp], csr5
              loadq 48[temp], csr6
          elsif ARMv7 or MIPS
              loadp [temp], csr0
<span class="udiff-line-added">+             loadp 4[temp], csr1</span>
          end
      end
  end
  
  macro preserveReturnAddressAfterCall(destinationRegister)
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -921,16 +1008,48 @@</span>
      if TRACING
          callSlowPath(_llint_trace)
      end
  end
  
<span class="udiff-line-modified-removed">- macro callTargetFunction(size, opcodeStruct, dispatch, callee, callPtrTag)</span>
<span class="udiff-line-modified-added">+ macro defineOSRExitReturnLabel(opcodeName, size)</span>
<span class="udiff-line-added">+     macro defineNarrow()</span>
<span class="udiff-line-added">+         if not C_LOOP_WIN</span>
<span class="udiff-line-added">+             _%opcodeName%_return_location:</span>
<span class="udiff-line-added">+         end</span>
<span class="udiff-line-added">+     end</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     macro defineWide16()</span>
<span class="udiff-line-added">+         if not C_LOOP_WIN</span>
<span class="udiff-line-added">+             _%opcodeName%_return_location_wide16:</span>
<span class="udiff-line-added">+         end</span>
<span class="udiff-line-added">+     end</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     macro defineWide32()</span>
<span class="udiff-line-added">+         if not C_LOOP_WIN</span>
<span class="udiff-line-added">+             _%opcodeName%_return_location_wide32:</span>
<span class="udiff-line-added">+         end</span>
<span class="udiff-line-added">+     end</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     size(defineNarrow, defineWide16, defineWide32, macro (f) f() end)</span>
<span class="udiff-line-added">+ end</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ macro callTargetFunction(opcodeName, size, opcodeStruct, dispatch, callee, callPtrTag)</span>
      if C_LOOP or C_LOOP_WIN
          cloopCallJSFunction callee
      else
          call callee, callPtrTag
      end
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     if ARMv7 or MIPS</span>
<span class="udiff-line-added">+         # It is required in ARMv7 and MIPs because global label definitions</span>
<span class="udiff-line-added">+         # for those architectures generates a set of instructions</span>
<span class="udiff-line-added">+         # that can clobber LLInt execution, resulting in unexpected</span>
<span class="udiff-line-added">+         # crashes.</span>
<span class="udiff-line-added">+         restoreStackPointerAfterCall()</span>
<span class="udiff-line-added">+         dispatchAfterCall(size, opcodeStruct, dispatch)</span>
<span class="udiff-line-added">+     end</span>
<span class="udiff-line-added">+     defineOSRExitReturnLabel(opcodeName, size)</span>
      restoreStackPointerAfterCall()
      dispatchAfterCall(size, opcodeStruct, dispatch)
  end
  
  macro prepareForRegularCall(callee, temp1, temp2, temp3, callPtrTag)
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -939,11 +1058,11 @@</span>
  
  # sp points to the new frame
  macro prepareForTailCall(callee, temp1, temp2, temp3, callPtrTag)
      restoreCalleeSavesUsedByLLInt()
  
<span class="udiff-line-modified-removed">-     loadi PayloadOffset + ArgumentCount[cfr], temp2</span>
<span class="udiff-line-modified-added">+     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], temp2</span>
      loadp CodeBlock[cfr], temp1
      loadi CodeBlock::m_numParameters[temp1], temp1
      bilteq temp1, temp2, .noArityFixup
      move temp1, temp2
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -954,11 +1073,11 @@</span>
      andi ~StackAlignmentMask, temp2
  
      move cfr, temp1
      addp temp2, temp1
  
<span class="udiff-line-modified-removed">-     loadi PayloadOffset + ArgumentCount[sp], temp2</span>
<span class="udiff-line-modified-added">+     loadi PayloadOffset + ArgumentCountIncludingThis[sp], temp2</span>
      # We assume &lt; 2^28 arguments
      muli SlotSize, temp2
      addi StackAlignment - 1 + CallFrameHeaderSize, temp2
      andi ~StackAlignmentMask, temp2
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -996,23 +1115,32 @@</span>
  
      move temp1, sp
      jmp callee, callPtrTag
  end
  
<span class="udiff-line-modified-removed">- macro slowPathForCall(size, opcodeStruct, dispatch, slowPath, prepareCall)</span>
<span class="udiff-line-modified-added">+ macro slowPathForCall(opcodeName, size, opcodeStruct, dispatch, slowPath, prepareCall)</span>
      callCallSlowPath(
          slowPath,
          # Those are r0 and r1
          macro (callee, calleeFramePtr)
              btpz calleeFramePtr, .dontUpdateSP
              move calleeFramePtr, sp
              prepareCall(callee, t2, t3, t4, SlowPathPtrTag)
          .dontUpdateSP:
<span class="udiff-line-modified-removed">-             callTargetFunction(size, opcodeStruct, dispatch, callee, SlowPathPtrTag)</span>
<span class="udiff-line-modified-added">+             callTargetFunction(%opcodeName%_slow, size, opcodeStruct, dispatch, callee, SlowPathPtrTag)</span>
          end)
  end
  
<span class="udiff-line-added">+ macro getterSetterOSRExitReturnPoint(opName, size)</span>
<span class="udiff-line-added">+     crash() # We don&#39;t reach this in straight line code. We only reach it via returning to the code below when reconstructing stack frames during OSR exit.</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     defineOSRExitReturnLabel(opName, size)</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     restoreStackPointerAfterCall()</span>
<span class="udiff-line-added">+     loadi LLIntReturnPC[cfr], PC</span>
<span class="udiff-line-added">+ end</span>
<span class="udiff-line-added">+ </span>
  macro arrayProfile(offset, cellAndIndexingType, metadata, scratch)
      const cell = cellAndIndexingType
      const indexingType = cellAndIndexingType 
      loadi JSCell::m_structureID[cell], scratch
      storei scratch, offset + ArrayProfile::m_lastSeenStructureID[metadata]
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1055,22 +1183,28 @@</span>
      if JSVALUE64
          loadp Callee[cfr], targetRegister
      else
          loadp Callee + PayloadOffset[cfr], targetRegister
      end
<span class="udiff-line-modified-removed">-     loadp JSFunction::m_executable[targetRegister], targetRegister</span>
<span class="udiff-line-modified-added">+     loadp JSFunction::m_executableOrRareData[targetRegister], targetRegister</span>
<span class="udiff-line-added">+     btpz targetRegister, (constexpr JSFunction::rareDataTag), .isExecutable</span>
<span class="udiff-line-added">+     loadp (FunctionRareData::m_executable - (constexpr JSFunction::rareDataTag))[targetRegister], targetRegister</span>
<span class="udiff-line-added">+ .isExecutable:</span>
      loadp FunctionExecutable::m_codeBlockForCall[targetRegister], targetRegister
      loadp ExecutableToCodeBlockEdge::m_codeBlock[targetRegister], targetRegister
  end
  
  macro functionForConstructCodeBlockGetter(targetRegister)
      if JSVALUE64
          loadp Callee[cfr], targetRegister
      else
          loadp Callee + PayloadOffset[cfr], targetRegister
      end
<span class="udiff-line-modified-removed">-     loadp JSFunction::m_executable[targetRegister], targetRegister</span>
<span class="udiff-line-modified-added">+     loadp JSFunction::m_executableOrRareData[targetRegister], targetRegister</span>
<span class="udiff-line-added">+     btpz targetRegister, (constexpr JSFunction::rareDataTag), .isExecutable</span>
<span class="udiff-line-added">+     loadp (FunctionRareData::m_executable - (constexpr JSFunction::rareDataTag))[targetRegister], targetRegister</span>
<span class="udiff-line-added">+ .isExecutable:</span>
      loadp FunctionExecutable::m_codeBlockForConstruct[targetRegister], targetRegister
      loadp ExecutableToCodeBlockEdge::m_codeBlock[targetRegister], targetRegister
  end
  
  macro notFunctionCodeBlockGetter(targetRegister)
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1083,10 +1217,20 @@</span>
  
  macro notFunctionCodeBlockSetter(sourceRegister)
      # Nothing to do!
  end
  
<span class="udiff-line-added">+ macro convertCalleeToVM(callee)</span>
<span class="udiff-line-added">+     btpnz callee, (constexpr PreciseAllocation::halfAlignment), .preciseAllocation</span>
<span class="udiff-line-added">+     andp MarkedBlockMask, callee</span>
<span class="udiff-line-added">+     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[callee], callee</span>
<span class="udiff-line-added">+     jmp .done</span>
<span class="udiff-line-added">+ .preciseAllocation:</span>
<span class="udiff-line-added">+     loadp PreciseAllocationVMOffset[callee], callee</span>
<span class="udiff-line-added">+ .done:</span>
<span class="udiff-line-added">+ end</span>
<span class="udiff-line-added">+ </span>
  # Do the bare minimum required to execute code. Sets up the PC, leave the CodeBlock*
  # in t1. May also trigger prologue entry OSR.
  macro prologue(codeBlockGetter, codeBlockSetter, osrSlowPath, traceSlowPath)
      # Set up the call frame and check if we should OSR.
      tagReturnAddress sp
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1096,10 +1240,11 @@</span>
          subp maxFrameExtentForSlowPathCall, sp
          callSlowPath(traceSlowPath)
          addp maxFrameExtentForSlowPathCall, sp
      end
      codeBlockGetter(t1)
<span class="udiff-line-added">+     codeBlockSetter(t1)</span>
      if not (C_LOOP or C_LOOP_WIN)
          baddis 5, CodeBlock::m_llintExecuteCounter + BaselineExecutionCounter::m_counter[t1], .continue
          if JSVALUE64
              move cfr, a0
              move PC, a1
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1125,25 +1270,19 @@</span>
          else
              pop cfr
          end
          jmp r0, JSEntryPtrTag
      .recover:
<span class="udiff-line-modified-removed">-         codeBlockGetter(t1)</span>
<span class="udiff-line-modified-added">+         notFunctionCodeBlockGetter(t1)</span>
      .continue:
      end
  
<span class="udiff-line-removed">-     codeBlockSetter(t1)</span>
<span class="udiff-line-removed">- </span>
      preserveCalleeSavesUsedByLLInt()
  
      # Set up the PC.
<span class="udiff-line-modified-removed">-     if JSVALUE64</span>
<span class="udiff-line-modified-removed">-         loadp CodeBlock::m_instructionsRawPointer[t1], PB</span>
<span class="udiff-line-removed">-         move 0, PC</span>
<span class="udiff-line-removed">-     else</span>
<span class="udiff-line-removed">-         loadp CodeBlock::m_instructionsRawPointer[t1], PC</span>
<span class="udiff-line-removed">-     end</span>
<span class="udiff-line-modified-added">+     loadp CodeBlock::m_instructionsRawPointer[t1], PB</span>
<span class="udiff-line-modified-added">+     move 0, PC</span>
  
      # Get new sp in t0 and check stack height.
      getFrameRegisterSizeForCodeBlock(t1, t0)
      subp cfr, t0, t0
      bpa t0, cfr, .needStackCheck
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1170,11 +1309,11 @@</span>
      jmp _llint_throw_from_slow_path_trampoline
  
  .stackHeightOKGetCodeBlock:
      # Stack check slow path returned that the stack was ok.
      # Since they were clobbered, need to get CodeBlock and new sp
<span class="udiff-line-modified-removed">-     codeBlockGetter(t1)</span>
<span class="udiff-line-modified-added">+     notFunctionCodeBlockGetter(t1)</span>
      getFrameRegisterSizeForCodeBlock(t1, t0)
      subp cfr, t0, t0
  
  .stackHeightOK:
      if X86_64 or ARM64
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1192,12 +1331,12 @@</span>
      end
  
      loadp CodeBlock::m_metadata[t1], metadataTable
  
      if JSVALUE64
<span class="udiff-line-modified-removed">-         move TagTypeNumber, tagTypeNumber</span>
<span class="udiff-line-modified-removed">-         addq TagBitTypeOther, tagTypeNumber, tagMask</span>
<span class="udiff-line-modified-added">+         move TagNumber, numberTag</span>
<span class="udiff-line-modified-added">+         addq TagOther, numberTag, notCellMask</span>
      end
  end
  
  # Expects that CodeBlock is in t1, which is what prologue() leaves behind.
  # Must call dispatch(0) after calling this.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1277,26 +1416,30 @@</span>
          # We need three non-aliased caller-save registers. We are guaranteed
          # this for a0, a1 and a2 on all architectures.
          if X86 or X86_WIN
              loadp 4[sp], a0
          end
<span class="udiff-line-modified-removed">-         const vm = a0</span>
<span class="udiff-line-modified-added">+         const vmOrStartSP = a0</span>
          const address = a1
          const zeroValue = a2
      
<span class="udiff-line-modified-removed">-         loadp VM::m_lastStackTop[vm], address</span>
<span class="udiff-line-modified-added">+         loadp VM::m_lastStackTop[vmOrStartSP], address</span>
<span class="udiff-line-added">+         move sp, zeroValue</span>
<span class="udiff-line-added">+         storep zeroValue, VM::m_lastStackTop[vmOrStartSP]</span>
<span class="udiff-line-added">+         move sp, vmOrStartSP</span>
<span class="udiff-line-added">+ </span>
          bpbeq sp, address, .zeroFillDone
<span class="udiff-line-modified-removed">-     </span>
<span class="udiff-line-modified-added">+         move address, sp</span>
<span class="udiff-line-added">+ </span>
          move 0, zeroValue
      .zeroFillLoop:
          storep zeroValue, [address]
          addp PtrSize, address
<span class="udiff-line-modified-removed">-         bpa sp, address, .zeroFillLoop</span>
<span class="udiff-line-modified-added">+         bpa vmOrStartSP, address, .zeroFillLoop</span>
  
      .zeroFillDone:
<span class="udiff-line-modified-removed">-         move sp, address</span>
<span class="udiff-line-removed">-         storep address, VM::m_lastStackTop[vm]</span>
<span class="udiff-line-modified-added">+         move vmOrStartSP, sp</span>
          ret
      
      # VMEntryRecord* vmEntryRecord(const EntryFrame* entryFrame)
      global _vmEntryRecord
      _vmEntryRecord:
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1312,111 +1455,124 @@</span>
  if C_LOOP or C_LOOP_WIN
      # Dummy entry point the C Loop uses to initialize.
      _llint_entry:
          crash()
  else
<span class="udiff-line-modified-removed">-     macro initPCRelative(pcBase)</span>
<span class="udiff-line-modified-added">+     macro initPCRelative(kind, pcBase)</span>
          if X86_64 or X86_64_WIN or X86 or X86_WIN
<span class="udiff-line-modified-removed">-             call _relativePCBase</span>
<span class="udiff-line-modified-removed">-         _relativePCBase:</span>
<span class="udiff-line-modified-added">+             call _%kind%_relativePCBase</span>
<span class="udiff-line-modified-added">+         _%kind%_relativePCBase:</span>
              pop pcBase
          elsif ARM64 or ARM64E
          elsif ARMv7
<span class="udiff-line-modified-removed">-         _relativePCBase:</span>
<span class="udiff-line-modified-added">+         _%kind%_relativePCBase:</span>
              move pc, pcBase
              subp 3, pcBase   # Need to back up the PC and set the Thumb2 bit
          elsif MIPS
<span class="udiff-line-modified-removed">-             la _relativePCBase, pcBase</span>
<span class="udiff-line-modified-added">+             la _%kind%_relativePCBase, pcBase</span>
              setcallreg pcBase # needed to set $t9 to the right value for the .cpload created by the label.
<span class="udiff-line-modified-removed">-         _relativePCBase:</span>
<span class="udiff-line-modified-added">+         _%kind%_relativePCBase:</span>
          end
<span class="udiff-line-modified-removed">- end</span>
<span class="udiff-line-modified-added">+     end</span>
  
<span class="udiff-line-modified-removed">- # The PC base is in t3, as this is what _llint_entry leaves behind through</span>
<span class="udiff-line-modified-removed">- # initPCRelative(t3)</span>
<span class="udiff-line-modified-removed">- macro setEntryAddress(index, label)</span>
<span class="udiff-line-modified-removed">-     setEntryAddressCommon(index, label, a0)</span>
<span class="udiff-line-modified-removed">- end</span>
<span class="udiff-line-modified-added">+     # The PC base is in t3, as this is what _llint_entry leaves behind through</span>
<span class="udiff-line-modified-added">+     # initPCRelative(t3)</span>
<span class="udiff-line-modified-added">+     macro setEntryAddressCommon(kind, index, label, map)</span>
<span class="udiff-line-modified-added">+         if X86_64</span>
<span class="udiff-line-modified-added">+             leap (label - _%kind%_relativePCBase)[t3], t4</span>
<span class="udiff-line-added">+             move index, t5</span>
<span class="udiff-line-added">+             storep t4, [map, t5, 8]</span>
<span class="udiff-line-added">+         elsif X86_64_WIN</span>
<span class="udiff-line-added">+             leap (label - _%kind%_relativePCBase)[t3], t4</span>
<span class="udiff-line-added">+             move index, t0</span>
<span class="udiff-line-added">+             storep t4, [map, t0, 8]</span>
<span class="udiff-line-added">+         elsif X86 or X86_WIN</span>
<span class="udiff-line-added">+             leap (label - _%kind%_relativePCBase)[t3], t4</span>
<span class="udiff-line-added">+             move index, t5</span>
<span class="udiff-line-added">+             storep t4, [map, t5, 4]</span>
<span class="udiff-line-added">+         elsif ARM64 or ARM64E</span>
<span class="udiff-line-added">+             pcrtoaddr label, t3</span>
<span class="udiff-line-added">+             move index, t4</span>
<span class="udiff-line-added">+             storep t3, [map, t4, PtrSize]</span>
<span class="udiff-line-added">+         elsif ARMv7</span>
<span class="udiff-line-added">+             mvlbl (label - _%kind%_relativePCBase), t4</span>
<span class="udiff-line-added">+             addp t4, t3, t4</span>
<span class="udiff-line-added">+             move index, t5</span>
<span class="udiff-line-added">+             storep t4, [map, t5, 4]</span>
<span class="udiff-line-added">+         elsif MIPS</span>
<span class="udiff-line-added">+             la label, t4</span>
<span class="udiff-line-added">+             la _%kind%_relativePCBase, t3</span>
<span class="udiff-line-added">+             subp t3, t4</span>
<span class="udiff-line-added">+             addp t4, t3, t4</span>
<span class="udiff-line-added">+             move index, t5</span>
<span class="udiff-line-added">+             storep t4, [map, t5, 4]</span>
<span class="udiff-line-added">+         end</span>
<span class="udiff-line-added">+     end</span>
  
<span class="udiff-line-removed">- macro setEntryAddressWide16(index, label)</span>
<span class="udiff-line-removed">-      setEntryAddressCommon(index, label, a1)</span>
<span class="udiff-line-removed">- end</span>
  
<span class="udiff-line-removed">- macro setEntryAddressWide32(index, label)</span>
<span class="udiff-line-removed">-      setEntryAddressCommon(index, label, a2)</span>
<span class="udiff-line-removed">- end</span>
  
<span class="udiff-line-modified-removed">- macro setEntryAddressCommon(index, label, map)</span>
<span class="udiff-line-modified-removed">-     if X86_64</span>
<span class="udiff-line-modified-removed">-         leap (label - _relativePCBase)[t3], t4</span>
<span class="udiff-line-modified-removed">-         move index, t5</span>
<span class="udiff-line-removed">-         storep t4, [map, t5, 8]</span>
<span class="udiff-line-removed">-     elsif X86_64_WIN</span>
<span class="udiff-line-removed">-         leap (label - _relativePCBase)[t3], t4</span>
<span class="udiff-line-removed">-         move index, t0</span>
<span class="udiff-line-removed">-         storep t4, [map, t0, 8]</span>
<span class="udiff-line-removed">-     elsif X86 or X86_WIN</span>
<span class="udiff-line-removed">-         leap (label - _relativePCBase)[t3], t4</span>
<span class="udiff-line-removed">-         move index, t5</span>
<span class="udiff-line-removed">-         storep t4, [map, t5, 4]</span>
<span class="udiff-line-removed">-     elsif ARM64 or ARM64E</span>
<span class="udiff-line-removed">-         pcrtoaddr label, t3</span>
<span class="udiff-line-removed">-         move index, t4</span>
<span class="udiff-line-removed">-         storep t3, [map, t4, PtrSize]</span>
<span class="udiff-line-removed">-     elsif ARMv7</span>
<span class="udiff-line-removed">-         mvlbl (label - _relativePCBase), t4</span>
<span class="udiff-line-removed">-         addp t4, t3, t4</span>
<span class="udiff-line-removed">-         move index, t5</span>
<span class="udiff-line-removed">-         storep t4, [map, t5, 4]</span>
<span class="udiff-line-removed">-     elsif MIPS</span>
<span class="udiff-line-removed">-         la label, t4</span>
<span class="udiff-line-removed">-         la _relativePCBase, t3</span>
<span class="udiff-line-removed">-         subp t3, t4</span>
<span class="udiff-line-removed">-         addp t4, t3, t4</span>
<span class="udiff-line-removed">-         move index, t5</span>
<span class="udiff-line-removed">-         storep t4, [map, t5, 4]</span>
<span class="udiff-line-removed">-     end</span>
<span class="udiff-line-removed">- end</span>
<span class="udiff-line-modified-added">+     macro includeEntriesAtOffset(kind, fn)</span>
<span class="udiff-line-modified-added">+         macro setEntryAddress(index, label)</span>
<span class="udiff-line-modified-added">+             setEntryAddressCommon(kind, index, label, a0)</span>
<span class="udiff-line-modified-added">+         end</span>
  
<span class="udiff-line-modified-removed">- global _llint_entry</span>
<span class="udiff-line-modified-removed">- # Entry point for the llint to initialize.</span>
<span class="udiff-line-modified-removed">- _llint_entry:</span>
<span class="udiff-line-modified-removed">-     functionPrologue()</span>
<span class="udiff-line-modified-removed">-     pushCalleeSaves()</span>
<span class="udiff-line-modified-removed">-     if X86 or X86_WIN</span>
<span class="udiff-line-modified-removed">-         loadp 20[sp], a0</span>
<span class="udiff-line-modified-removed">-         loadp 24[sp], a1</span>
<span class="udiff-line-modified-removed">-         loadp 28[sp], a2</span>
<span class="udiff-line-modified-added">+         macro setEntryAddressWide16(index, label)</span>
<span class="udiff-line-modified-added">+              setEntryAddressCommon(kind, index, label, a1)</span>
<span class="udiff-line-modified-added">+         end</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+         macro setEntryAddressWide32(index, label)</span>
<span class="udiff-line-modified-added">+              setEntryAddressCommon(kind, index, label, a2)</span>
<span class="udiff-line-modified-added">+         end</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+         fn()</span>
      end
  
<span class="udiff-line-removed">-     initPCRelative(t3)</span>
  
<span class="udiff-line-modified-removed">-     # Include generated bytecode initialization file.</span>
<span class="udiff-line-modified-removed">-     include InitBytecodes</span>
<span class="udiff-line-modified-added">+ macro entry(kind, initialize)</span>
<span class="udiff-line-modified-added">+     global _%kind%_entry</span>
<span class="udiff-line-added">+     _%kind%_entry:</span>
<span class="udiff-line-added">+         functionPrologue()</span>
<span class="udiff-line-added">+         pushCalleeSaves()</span>
<span class="udiff-line-added">+         if X86 or X86_WIN</span>
<span class="udiff-line-added">+             loadp 20[sp], a0</span>
<span class="udiff-line-added">+             loadp 24[sp], a1</span>
<span class="udiff-line-added">+             loadp 28[sp], a2</span>
<span class="udiff-line-added">+         end</span>
  
<span class="udiff-line-modified-removed">-     popCalleeSaves()</span>
<span class="udiff-line-modified-removed">-     functionEpilogue()</span>
<span class="udiff-line-modified-removed">-     ret</span>
<span class="udiff-line-modified-added">+         initPCRelative(kind, t3)</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+         # Include generated bytecode initialization file.</span>
<span class="udiff-line-added">+         includeEntriesAtOffset(kind, initialize)</span>
<span class="udiff-line-added">+         popCalleeSaves()</span>
<span class="udiff-line-added">+         functionEpilogue()</span>
<span class="udiff-line-added">+         ret</span>
  end
  
<span class="udiff-line-added">+ # Entry point for the llint to initialize.</span>
<span class="udiff-line-added">+ entry(llint, macro()</span>
<span class="udiff-line-added">+     include InitBytecodes</span>
<span class="udiff-line-added">+ end)</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ end // not (C_LOOP or C_LOOP_WIN)</span>
<span class="udiff-line-added">+ </span>
  _llint_op_wide16:
      nextInstructionWide16()
  
  _llint_op_wide32:
      nextInstructionWide32()
  
  macro noWide(label)
<span class="udiff-line-modified-removed">- _llint_%label%_wide16:</span>
<span class="udiff-line-modified-added">+ _%label%_wide16:</span>
      crash()
  
<span class="udiff-line-modified-removed">- _llint_%label%_wide32:</span>
<span class="udiff-line-modified-added">+ _%label%_wide32:</span>
      crash()
  end
  
<span class="udiff-line-modified-removed">- noWide(op_wide16)</span>
<span class="udiff-line-modified-removed">- noWide(op_wide32)</span>
<span class="udiff-line-modified-removed">- noWide(op_enter)</span>
<span class="udiff-line-modified-added">+ noWide(llint_op_wide16)</span>
<span class="udiff-line-modified-added">+ noWide(llint_op_wide32)</span>
<span class="udiff-line-modified-added">+ noWide(llint_op_enter)</span>
  
  op(llint_program_prologue, macro ()
      prologue(notFunctionCodeBlockGetter, notFunctionCodeBlockSetter, _llint_entry_osr, _llint_trace_prologue)
      dispatch(0)
  end)
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1481,15 +1637,19 @@</span>
          dispatch()
      end)
  end
  
  slowPathOp(create_cloned_arguments)
<span class="udiff-line-added">+ slowPathOp(create_arguments_butterfly)</span>
  slowPathOp(create_direct_arguments)
  slowPathOp(create_lexical_environment)
  slowPathOp(create_rest)
  slowPathOp(create_scoped_arguments)
  slowPathOp(create_this)
<span class="udiff-line-added">+ slowPathOp(create_promise)</span>
<span class="udiff-line-added">+ slowPathOp(create_generator)</span>
<span class="udiff-line-added">+ slowPathOp(create_async_generator)</span>
  slowPathOp(define_accessor_property)
  slowPathOp(define_data_property)
  slowPathOp(enumerator_generic_pname)
  slowPathOp(enumerator_structure_pname)
  slowPathOp(get_by_id_with_this)
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1520,10 +1680,12 @@</span>
  slowPathOp(strcat)
  slowPathOp(throw_static_error)
  slowPathOp(to_index_string)
  slowPathOp(typeof)
  slowPathOp(unreachable)
<span class="udiff-line-added">+ slowPathOp(new_promise)</span>
<span class="udiff-line-added">+ slowPathOp(new_generator)</span>
  
  macro llintSlowPathOp(opcodeName)
      llintOp(op_%opcodeName%, unused, macro (unused, unused, dispatch)
          callSlowPath(_llint_slow_path_%opcodeName%)
          dispatch()
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1663,26 +1825,32 @@</span>
  
  
  preOp(inc, OpInc,
      macro (value, slow) baddio 1, value, slow end)
  
<span class="udiff-line-removed">- </span>
  preOp(dec, OpDec,
      macro (value, slow) bsubio 1, value, slow end)
  
  
  llintOp(op_loop_hint, OpLoopHint, macro (unused, unused, dispatch)
<span class="udiff-line-modified-removed">-     # CheckTraps.</span>
<span class="udiff-line-modified-added">+     checkSwitchToJITForLoop()</span>
<span class="udiff-line-added">+     dispatch()</span>
<span class="udiff-line-added">+ end)</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ llintOp(op_check_traps, OpCheckTraps, macro (unused, unused, dispatch)</span>
      loadp CodeBlock[cfr], t1
      loadp CodeBlock::m_vm[t1], t1
<span class="udiff-line-modified-removed">-     btbnz VM::m_traps + VMTraps::m_needTrapHandling[t1], .handleTraps</span>
<span class="udiff-line-modified-added">+     loadb VM::m_traps+VMTraps::m_needTrapHandling[t1], t0</span>
<span class="udiff-line-added">+     btpnz t0, .handleTraps</span>
  .afterHandlingTraps:
<span class="udiff-line-removed">-     checkSwitchToJITForLoop()</span>
      dispatch()
  .handleTraps:
<span class="udiff-line-modified-removed">-     callTrapHandler(_llint_throw_from_slow_path_trampoline)</span>
<span class="udiff-line-modified-added">+     callTrapHandler(.throwHandler)</span>
      jmp .afterHandlingTraps
<span class="udiff-line-added">+ .throwHandler:</span>
<span class="udiff-line-added">+     jmp _llint_throw_from_slow_path_trampoline</span>
  end)
  
  
  # Returns the packet pointer in t0.
  macro acquireShadowChickenPacket(slow)
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1721,11 +1889,19 @@</span>
  
  
  callOp(construct, OpConstruct, prepareForRegularCall, macro (getu, metadata) end)
  
  
<span class="udiff-line-modified-removed">- macro doCallVarargs(size, opcodeStruct, dispatch, frameSlowPath, slowPath, prepareCall)</span>
<span class="udiff-line-modified-added">+ macro branchIfException(exceptionTarget)</span>
<span class="udiff-line-added">+     loadp CodeBlock[cfr], t3</span>
<span class="udiff-line-added">+     loadp CodeBlock::m_vm[t3], t3</span>
<span class="udiff-line-added">+     btpz VM::m_exception[t3], .noException</span>
<span class="udiff-line-added">+     jmp exceptionTarget</span>
<span class="udiff-line-added">+ .noException:</span>
<span class="udiff-line-added">+ end</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ macro doCallVarargs(opcodeName, size, opcodeStruct, dispatch, frameSlowPath, slowPath, prepareCall)</span>
      callSlowPath(frameSlowPath)
      branchIfException(_llint_throw_from_slow_path_trampoline)
      # calleeFrame in r1
      if JSVALUE64
          move r1, sp
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1736,36 +1912,36 @@</span>
              move t2, sp
          else
              subp r1, CallerFrameAndPCSize, sp
          end
      end
<span class="udiff-line-modified-removed">-     slowPathForCall(size, opcodeStruct, dispatch, slowPath, prepareCall)</span>
<span class="udiff-line-modified-added">+     slowPathForCall(opcodeName, size, opcodeStruct, dispatch, slowPath, prepareCall)</span>
  end
  
  
  llintOp(op_call_varargs, OpCallVarargs, macro (size, get, dispatch)
<span class="udiff-line-modified-removed">-     doCallVarargs(size, OpCallVarargs, dispatch, _llint_slow_path_size_frame_for_varargs, _llint_slow_path_call_varargs, prepareForRegularCall)</span>
<span class="udiff-line-modified-added">+     doCallVarargs(op_call_varargs, size, OpCallVarargs, dispatch, _llint_slow_path_size_frame_for_varargs, _llint_slow_path_call_varargs, prepareForRegularCall)</span>
  end)
  
  llintOp(op_tail_call_varargs, OpTailCallVarargs, macro (size, get, dispatch)
      checkSwitchToJITForEpilogue()
      # We lie and perform the tail call instead of preparing it since we can&#39;t
      # prepare the frame for a call opcode
<span class="udiff-line-modified-removed">-     doCallVarargs(size, OpTailCallVarargs, dispatch, _llint_slow_path_size_frame_for_varargs, _llint_slow_path_tail_call_varargs, prepareForTailCall)</span>
<span class="udiff-line-modified-added">+     doCallVarargs(op_tail_call_varargs, size, OpTailCallVarargs, dispatch, _llint_slow_path_size_frame_for_varargs, _llint_slow_path_tail_call_varargs, prepareForTailCall)</span>
  end)
  
  
  llintOp(op_tail_call_forward_arguments, OpTailCallForwardArguments, macro (size, get, dispatch)
      checkSwitchToJITForEpilogue()
      # We lie and perform the tail call instead of preparing it since we can&#39;t
      # prepare the frame for a call opcode
<span class="udiff-line-modified-removed">-     doCallVarargs(size, OpTailCallForwardArguments, dispatch, _llint_slow_path_size_frame_for_forward_arguments, _llint_slow_path_tail_call_forward_arguments, prepareForTailCall)</span>
<span class="udiff-line-modified-added">+     doCallVarargs(op_tail_call_forward_arguments, size, OpTailCallForwardArguments, dispatch, _llint_slow_path_size_frame_for_forward_arguments, _llint_slow_path_tail_call_forward_arguments, prepareForTailCall)</span>
  end)
  
  
  llintOp(op_construct_varargs, OpConstructVarargs, macro (size, get, dispatch)
<span class="udiff-line-modified-removed">-     doCallVarargs(size, OpConstructVarargs, dispatch, _llint_slow_path_size_frame_for_varargs, _llint_slow_path_construct_varargs, prepareForRegularCall)</span>
<span class="udiff-line-modified-added">+     doCallVarargs(op_construct_varargs, size, OpConstructVarargs, dispatch, _llint_slow_path_size_frame_for_varargs, _llint_slow_path_construct_varargs, prepareForRegularCall)</span>
  end)
  
  
  # Eval is executed in one of two modes:
  #
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1800,26 +1976,29 @@</span>
  # and a PC to call, and that PC may be a dummy thunk that just
  # returns the JS value that the eval returned.
  
  _llint_op_call_eval:
      slowPathForCall(
<span class="udiff-line-added">+         op_call_eval_narrow,</span>
          narrow,
          OpCallEval,
          macro () dispatchOp(narrow, op_call_eval) end,
          _llint_slow_path_call_eval,
          prepareForRegularCall)
  
  _llint_op_call_eval_wide16:
      slowPathForCall(
<span class="udiff-line-added">+         op_call_eval_wide16,</span>
          wide16,
          OpCallEval,
          macro () dispatchOp(wide16, op_call_eval) end,
          _llint_slow_path_call_eval_wide16,
          prepareForRegularCall)
  
  _llint_op_call_eval_wide32:
      slowPathForCall(
<span class="udiff-line-added">+         op_call_eval_wide32,</span>
          wide32,
          OpCallEval,
          macro () dispatchOp(wide32, op_call_eval) end,
          _llint_slow_path_call_eval_wide32,
          prepareForRegularCall)
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1875,10 +2054,57 @@</span>
  op(llint_internal_function_construct_trampoline, macro ()
      internalFunctionCallTrampoline(InternalFunction::m_functionForConstruct)
  end)
  
  
<span class="udiff-line-added">+ op(checkpoint_osr_exit_from_inlined_call_trampoline, macro ()</span>
<span class="udiff-line-added">+     if (JSVALUE64 and not (C_LOOP or C_LOOP_WIN)) or ARMv7 or MIPS</span>
<span class="udiff-line-added">+         restoreStackPointerAfterCall()</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         # Make sure we move r0 to a1 first since r0 might be the same as a0, for instance, on arm.</span>
<span class="udiff-line-added">+         if ARMv7 or MIPS</span>
<span class="udiff-line-added">+             # Given _slow_path_checkpoint_osr_exit_from_inlined_call has</span>
<span class="udiff-line-added">+             # parameters as CallFrame* and EncodedJSValue,</span>
<span class="udiff-line-added">+             # we need to store call result on a2, a3 and call frame on a0,</span>
<span class="udiff-line-added">+             # leaving a1 as dummy value.</span>
<span class="udiff-line-added">+             move r1, a3</span>
<span class="udiff-line-added">+             move r0, a2</span>
<span class="udiff-line-added">+             move cfr, a0</span>
<span class="udiff-line-added">+             # We don&#39;t call saveStateForCCall() because we are going to use the bytecodeIndex from our side state.</span>
<span class="udiff-line-added">+             cCall4(_slow_path_checkpoint_osr_exit_from_inlined_call)</span>
<span class="udiff-line-added">+         else</span>
<span class="udiff-line-added">+             move r0, a1</span>
<span class="udiff-line-added">+             move cfr, a0</span>
<span class="udiff-line-added">+             # We don&#39;t call saveStateForCCall() because we are going to use the bytecodeIndex from our side state.</span>
<span class="udiff-line-added">+             cCall2(_slow_path_checkpoint_osr_exit_from_inlined_call)</span>
<span class="udiff-line-added">+         end</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         restoreStateAfterCCall()</span>
<span class="udiff-line-added">+         branchIfException(_llint_throw_from_slow_path_trampoline)</span>
<span class="udiff-line-added">+         jmp r1, JSEntryPtrTag</span>
<span class="udiff-line-added">+     else</span>
<span class="udiff-line-added">+         notSupported()</span>
<span class="udiff-line-added">+     end</span>
<span class="udiff-line-added">+ end)</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ op(checkpoint_osr_exit_trampoline, macro ()</span>
<span class="udiff-line-added">+     # FIXME: We can probably dispatch to the checkpoint handler directly but this was easier</span>
<span class="udiff-line-added">+     # and probably doesn&#39;t matter for performance.</span>
<span class="udiff-line-added">+     if (JSVALUE64 and not (C_LOOP or C_LOOP_WIN)) or ARMv7 or MIPS</span>
<span class="udiff-line-added">+         restoreStackPointerAfterCall()</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         move cfr, a0</span>
<span class="udiff-line-added">+         # We don&#39;t call saveStateForCCall() because we are going to use the bytecodeIndex from our side state.</span>
<span class="udiff-line-added">+         cCall2(_slow_path_checkpoint_osr_exit)</span>
<span class="udiff-line-added">+         restoreStateAfterCCall()</span>
<span class="udiff-line-added">+         branchIfException(_llint_throw_from_slow_path_trampoline)</span>
<span class="udiff-line-added">+         jmp r1, JSEntryPtrTag</span>
<span class="udiff-line-added">+     else</span>
<span class="udiff-line-added">+         notSupported()</span>
<span class="udiff-line-added">+     end</span>
<span class="udiff-line-added">+ end)</span>
<span class="udiff-line-added">+ </span>
  # Lastly, make sure that we can link even though we don&#39;t support all opcodes.
  # These opcodes should never arise when using LLInt or either JIT. We assert
  # as much.
  
  macro notSupported()
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1892,5 +2118,33 @@</span>
          # instruction on all architectures we&#39;re interested in. (Break is int3
          # on Intel, which is 1 byte, and bkpt on ARMv7, which is 2 bytes.)
          break
      end
  end
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ // FIXME: We should not need the X86_64_WIN condition here, since WEBASSEMBLY should already be false on Windows</span>
<span class="udiff-line-added">+ // https://bugs.webkit.org/show_bug.cgi?id=203716</span>
<span class="udiff-line-added">+ if WEBASSEMBLY and not X86_64_WIN</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ entry(wasm, macro()</span>
<span class="udiff-line-added">+     include InitWasm</span>
<span class="udiff-line-added">+ end)</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ macro wasmScope()</span>
<span class="udiff-line-added">+     # Wrap the script in a macro since it overwrites some of the LLInt macros,</span>
<span class="udiff-line-added">+     # but we don&#39;t want to interfere with the LLInt opcodes</span>
<span class="udiff-line-added">+     include WebAssembly</span>
<span class="udiff-line-added">+ end</span>
<span class="udiff-line-added">+ wasmScope()</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ else</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ # These need to be defined even when WebAssembly is disabled</span>
<span class="udiff-line-added">+ op(wasm_function_prologue, macro ()</span>
<span class="udiff-line-added">+     crash()</span>
<span class="udiff-line-added">+ end)</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ op(wasm_function_prologue_no_tls, macro ()</span>
<span class="udiff-line-added">+     crash()</span>
<span class="udiff-line-added">+ end)</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ end</span>
</pre>
<center><a href="LLIntThunks.h.udiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="LowLevelInterpreter.cpp.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>