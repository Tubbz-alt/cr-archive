<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/wasm/WasmAirIRGenerator.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="../tools/VMInspector.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="WasmAirIRGenerator.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/wasm/WasmAirIRGenerator.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;WasmAirIRGenerator.h&quot;
  28 
  29 #if ENABLE(WEBASSEMBLY)
  30 
  31 #include &quot;AirCode.h&quot;
  32 #include &quot;AirGenerate.h&quot;

  33 #include &quot;AirOpcodeUtils.h&quot;
  34 #include &quot;AirValidate.h&quot;
  35 #include &quot;AllowMacroScratchRegisterUsageIf.h&quot;
  36 #include &quot;B3CCallValue.h&quot;
  37 #include &quot;B3CheckSpecial.h&quot;
  38 #include &quot;B3CheckValue.h&quot;
  39 #include &quot;B3PatchpointSpecial.h&quot;
  40 #include &quot;B3Procedure.h&quot;
  41 #include &quot;B3ProcedureInlines.h&quot;
  42 #include &quot;BinarySwitch.h&quot;
  43 #include &quot;DisallowMacroScratchRegisterUsage.h&quot;
  44 #include &quot;JSCInlines.h&quot;
  45 #include &quot;JSWebAssemblyInstance.h&quot;
  46 #include &quot;ScratchRegisterAllocator.h&quot;
  47 #include &quot;VirtualRegister.h&quot;
  48 #include &quot;WasmCallingConvention.h&quot;
  49 #include &quot;WasmContextInlines.h&quot;
  50 #include &quot;WasmExceptionType.h&quot;
  51 #include &quot;WasmFunctionParser.h&quot;
  52 #include &quot;WasmInstance.h&quot;
  53 #include &quot;WasmMemory.h&quot;
  54 #include &quot;WasmOMGPlan.h&quot;
  55 #include &quot;WasmOSREntryData.h&quot;
  56 #include &quot;WasmOpcodeOrigin.h&quot;
  57 #include &quot;WasmOperations.h&quot;
  58 #include &quot;WasmSignatureInlines.h&quot;
  59 #include &quot;WasmThunks.h&quot;
  60 #include &lt;limits&gt;
  61 #include &lt;wtf/Box.h&gt;
  62 #include &lt;wtf/Optional.h&gt;
  63 #include &lt;wtf/StdLibExtras.h&gt;
  64 
  65 namespace JSC { namespace Wasm {
  66 
  67 using namespace B3::Air;
  68 
  69 struct ConstrainedTmp {

  70     ConstrainedTmp(Tmp tmp)
  71         : ConstrainedTmp(tmp, tmp.isReg() ? B3::ValueRep::reg(tmp.reg()) : B3::ValueRep::SomeRegister)
  72     { }
  73 
  74     ConstrainedTmp(Tmp tmp, B3::ValueRep rep)
  75         : tmp(tmp)
  76         , rep(rep)
  77     {
  78     }
  79 


  80     Tmp tmp;
  81     B3::ValueRep rep;
  82 };
  83 
  84 class TypedTmp {
  85 public:
  86     constexpr TypedTmp()
  87         : m_tmp()
  88         , m_type(Type::Void)
  89     { }
  90 
  91     TypedTmp(Tmp tmp, Type type)
  92         : m_tmp(tmp)
  93         , m_type(type)
  94     { }
  95 
  96     TypedTmp(const TypedTmp&amp;) = default;
  97     TypedTmp(TypedTmp&amp;&amp;) = default;
  98     TypedTmp&amp; operator=(TypedTmp&amp;&amp;) = default;
  99     TypedTmp&amp; operator=(const TypedTmp&amp;) = default;
 100 
 101     bool operator==(const TypedTmp&amp; other) const
 102     {
 103         return m_tmp == other.m_tmp &amp;&amp; m_type == other.m_type;
 104     }
 105     bool operator!=(const TypedTmp&amp; other) const
 106     {
 107         return !(*this == other);
 108     }
 109 
 110     explicit operator bool() const { return !!tmp(); }
 111 
 112     operator Tmp() const { return tmp(); }
 113     operator Arg() const { return Arg(tmp()); }
 114     Tmp tmp() const { return m_tmp; }
 115     Type type() const { return m_type; }
 116 





 117 private:
 118 
 119     Tmp m_tmp;
 120     Type m_type;
 121 };
 122 
 123 class AirIRGenerator {
 124 public:



 125     struct ControlData {
<span class="line-modified"> 126         ControlData(B3::Origin origin, Type returnType, TypedTmp resultTmp, BlockType type, BasicBlock* continuation, BasicBlock* special = nullptr)</span>
<span class="line-modified"> 127             : blockType(type)</span>
 128             , continuation(continuation)
 129             , special(special)
<span class="line-modified"> 130             , returnType(returnType)</span>

 131         {
<span class="line-modified"> 132             UNUSED_PARAM(origin); // FIXME: Use origin.</span>
<span class="line-removed"> 133             if (resultTmp) {</span>
<span class="line-removed"> 134                 ASSERT(returnType != Type::Void);</span>
<span class="line-removed"> 135                 result.append(resultTmp);</span>
<span class="line-removed"> 136             } else</span>
<span class="line-removed"> 137                 ASSERT(returnType == Type::Void);</span>
 138         }
 139 
 140         ControlData()
 141         {
 142         }
 143 



 144         void dump(PrintStream&amp; out) const
 145         {
<span class="line-modified"> 146             switch (type()) {</span>
 147             case BlockType::If:
 148                 out.print(&quot;If:       &quot;);
 149                 break;
 150             case BlockType::Block:
 151                 out.print(&quot;Block:    &quot;);
 152                 break;
 153             case BlockType::Loop:
 154                 out.print(&quot;Loop:     &quot;);
 155                 break;
 156             case BlockType::TopLevel:
 157                 out.print(&quot;TopLevel: &quot;);
 158                 break;
 159             }
 160             out.print(&quot;Continuation: &quot;, *continuation, &quot;, Special: &quot;);
 161             if (special)
 162                 out.print(*special);
 163             else
 164                 out.print(&quot;None&quot;);
<span class="line-removed"> 165         }</span>
<span class="line-removed"> 166 </span>
<span class="line-removed"> 167         BlockType type() const { return blockType; }</span>
 168 
<span class="line-modified"> 169         Type signature() const { return returnType; }</span>





 170 
<span class="line-modified"> 171         bool hasNonVoidSignature() const { return result.size(); }</span>

 172 
 173         BasicBlock* targetBlockForBranch()
 174         {
<span class="line-modified"> 175             if (type() == BlockType::Loop)</span>
 176                 return special;
 177             return continuation;
 178         }
 179 
 180         void convertIfToBlock()
 181         {
<span class="line-modified"> 182             ASSERT(type() == BlockType::If);</span>
<span class="line-modified"> 183             blockType = BlockType::Block;</span>
 184             special = nullptr;
 185         }
 186 
<span class="line-modified"> 187         using ResultList = Vector&lt;TypedTmp, 1&gt;;</span>





 188 
<span class="line-modified"> 189         ResultList resultForBranch() const</span>
 190         {
<span class="line-modified"> 191             if (type() == BlockType::Loop)</span>
<span class="line-modified"> 192                 return ResultList();</span>
<span class="line-modified"> 193             return result;</span>

 194         }
 195 
 196     private:
 197         friend class AirIRGenerator;
<span class="line-modified"> 198         BlockType blockType;</span>
 199         BasicBlock* continuation;
 200         BasicBlock* special;
<span class="line-modified"> 201         ResultList result;</span>
<span class="line-modified"> 202         Type returnType;</span>
 203     };
 204 
<span class="line-removed"> 205     using ExpressionType = TypedTmp;</span>
 206     using ControlType = ControlData;
<span class="line-removed"> 207     using ExpressionList = Vector&lt;ExpressionType, 1&gt;;</span>
<span class="line-removed"> 208     using Stack = ExpressionList;</span>
<span class="line-removed"> 209     using ResultList = ControlData::ResultList;</span>
<span class="line-removed"> 210     using ControlEntry = FunctionParser&lt;AirIRGenerator&gt;::ControlEntry;</span>
 211 
<span class="line-modified"> 212     static ExpressionType emptyExpression() { return { }; };</span>
<span class="line-modified"> 213     Stack createStack() { return Stack(); }</span>


 214 
 215     using ErrorType = String;
 216     using UnexpectedResult = Unexpected&lt;ErrorType&gt;;
 217     using Result = Expected&lt;std::unique_ptr&lt;InternalFunction&gt;, ErrorType&gt;;
 218     using PartialResult = Expected&lt;void, ErrorType&gt;;
 219 




 220     template &lt;typename ...Args&gt;
 221     NEVER_INLINE UnexpectedResult WARN_UNUSED_RETURN fail(Args... args) const
 222     {
 223         using namespace FailureHelper; // See ADL comment in WasmParser.h.
 224         return UnexpectedResult(makeString(&quot;WebAssembly.Module failed compiling: &quot;_s, makeString(args)...));
 225     }
 226 
 227 #define WASM_COMPILE_FAIL_IF(condition, ...) do { \
 228         if (UNLIKELY(condition))                  \
 229             return fail(__VA_ARGS__);             \
 230     } while (0)
 231 
<span class="line-modified"> 232     AirIRGenerator(const ModuleInformation&amp;, B3::Procedure&amp;, InternalFunction*, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp;, MemoryMode, unsigned functionIndex, TierUpCount*, ThrowWasmException, const Signature&amp;);</span>
 233 
 234     PartialResult WARN_UNUSED_RETURN addArguments(const Signature&amp;);
 235     PartialResult WARN_UNUSED_RETURN addLocal(Type, uint32_t);
 236     ExpressionType addConstant(Type, uint64_t);
 237     ExpressionType addConstant(BasicBlock*, Type, uint64_t);

 238 
 239     // References
<span class="line-modified"> 240     PartialResult WARN_UNUSED_RETURN addRefIsNull(ExpressionType&amp; value, ExpressionType&amp; result);</span>
 241     PartialResult WARN_UNUSED_RETURN addRefFunc(uint32_t index, ExpressionType&amp; result);
 242 
 243     // Tables
<span class="line-modified"> 244     PartialResult WARN_UNUSED_RETURN addTableGet(unsigned, ExpressionType&amp; index, ExpressionType&amp; result);</span>
<span class="line-modified"> 245     PartialResult WARN_UNUSED_RETURN addTableSet(unsigned, ExpressionType&amp; index, ExpressionType&amp; value);</span>
 246     PartialResult WARN_UNUSED_RETURN addTableSize(unsigned, ExpressionType&amp; result);
<span class="line-modified"> 247     PartialResult WARN_UNUSED_RETURN addTableGrow(unsigned, ExpressionType&amp; fill, ExpressionType&amp; delta, ExpressionType&amp; result);</span>
<span class="line-modified"> 248     PartialResult WARN_UNUSED_RETURN addTableFill(unsigned, ExpressionType&amp; offset, ExpressionType&amp; fill, ExpressionType&amp; count);</span>
 249 
 250     // Locals
 251     PartialResult WARN_UNUSED_RETURN getLocal(uint32_t index, ExpressionType&amp; result);
 252     PartialResult WARN_UNUSED_RETURN setLocal(uint32_t index, ExpressionType value);
 253 
 254     // Globals
 255     PartialResult WARN_UNUSED_RETURN getGlobal(uint32_t index, ExpressionType&amp; result);
 256     PartialResult WARN_UNUSED_RETURN setGlobal(uint32_t index, ExpressionType value);
 257 
 258     // Memory
 259     PartialResult WARN_UNUSED_RETURN load(LoadOpType, ExpressionType pointer, ExpressionType&amp; result, uint32_t offset);
 260     PartialResult WARN_UNUSED_RETURN store(StoreOpType, ExpressionType pointer, ExpressionType value, uint32_t offset);
 261     PartialResult WARN_UNUSED_RETURN addGrowMemory(ExpressionType delta, ExpressionType&amp; result);
 262     PartialResult WARN_UNUSED_RETURN addCurrentMemory(ExpressionType&amp; result);
 263 
 264     // Basic operators
 265     template&lt;OpType&gt;
 266     PartialResult WARN_UNUSED_RETURN addOp(ExpressionType arg, ExpressionType&amp; result);
 267     template&lt;OpType&gt;
 268     PartialResult WARN_UNUSED_RETURN addOp(ExpressionType left, ExpressionType right, ExpressionType&amp; result);
 269     PartialResult WARN_UNUSED_RETURN addSelect(ExpressionType condition, ExpressionType nonZero, ExpressionType zero, ExpressionType&amp; result);
 270 
 271     // Control flow
<span class="line-modified"> 272     ControlData WARN_UNUSED_RETURN addTopLevel(Type signature);</span>
<span class="line-modified"> 273     ControlData WARN_UNUSED_RETURN addBlock(Type signature);</span>
<span class="line-modified"> 274     ControlData WARN_UNUSED_RETURN addLoop(Type signature, const Stack&amp;, uint32_t loopIndex);</span>
<span class="line-modified"> 275     PartialResult WARN_UNUSED_RETURN addIf(ExpressionType condition, Type signature, ControlData&amp; result);</span>
 276     PartialResult WARN_UNUSED_RETURN addElse(ControlData&amp;, const Stack&amp;);
 277     PartialResult WARN_UNUSED_RETURN addElseToUnreachable(ControlData&amp;);
 278 
<span class="line-modified"> 279     PartialResult WARN_UNUSED_RETURN addReturn(const ControlData&amp;, const ExpressionList&amp; returnValues);</span>
 280     PartialResult WARN_UNUSED_RETURN addBranch(ControlData&amp;, ExpressionType condition, const Stack&amp; returnValues);
 281     PartialResult WARN_UNUSED_RETURN addSwitch(ExpressionType condition, const Vector&lt;ControlData*&gt;&amp; targets, ControlData&amp; defaultTargets, const Stack&amp; expressionStack);
 282     PartialResult WARN_UNUSED_RETURN endBlock(ControlEntry&amp;, Stack&amp; expressionStack);
<span class="line-modified"> 283     PartialResult WARN_UNUSED_RETURN addEndToUnreachable(ControlEntry&amp;);</span>


 284 
 285     // Calls
<span class="line-modified"> 286     PartialResult WARN_UNUSED_RETURN addCall(uint32_t calleeIndex, const Signature&amp;, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result);</span>
<span class="line-modified"> 287     PartialResult WARN_UNUSED_RETURN addCallIndirect(unsigned tableIndex, const Signature&amp;, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result);</span>
 288     PartialResult WARN_UNUSED_RETURN addUnreachable();

 289 
 290     PartialResult addShift(Type, B3::Air::Opcode, ExpressionType value, ExpressionType shift, ExpressionType&amp; result);
 291     PartialResult addIntegerSub(B3::Air::Opcode, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 292     PartialResult addFloatingPointAbs(B3::Air::Opcode, ExpressionType value, ExpressionType&amp; result);
 293     PartialResult addFloatingPointBinOp(Type, B3::Air::Opcode, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 294 
<span class="line-modified"> 295     void dump(const Vector&lt;ControlEntry&gt;&amp; controlStack, const Stack* expressionStack);</span>
 296     void setParser(FunctionParser&lt;AirIRGenerator&gt;* parser) { m_parser = parser; };
<span class="line-modified"> 297 </span>
<span class="line-modified"> 298     static Vector&lt;Tmp&gt; toTmpVector(const Vector&lt;TypedTmp&gt;&amp; vector)</span>
<span class="line-removed"> 299     {</span>
<span class="line-removed"> 300         Vector&lt;Tmp&gt; result;</span>
<span class="line-removed"> 301         for (const auto&amp; item : vector)</span>
<span class="line-removed"> 302             result.append(item.tmp());</span>
<span class="line-removed"> 303         return result;</span>
<span class="line-removed"> 304     }</span>
<span class="line-removed"> 305 </span>
<span class="line-removed"> 306     ALWAYS_INLINE void didKill(const ExpressionType&amp; typedTmp)</span>
<span class="line-removed"> 307     {</span>
<span class="line-removed"> 308         Tmp tmp = typedTmp.tmp();</span>
<span class="line-removed"> 309         if (!tmp)</span>
<span class="line-removed"> 310             return;</span>
<span class="line-removed"> 311         if (tmp.isGP())</span>
<span class="line-removed"> 312             m_freeGPs.append(tmp);</span>
<span class="line-removed"> 313         else</span>
<span class="line-removed"> 314             m_freeFPs.append(tmp);</span>
<span class="line-removed"> 315     }</span>
 316 
 317     const Bag&lt;B3::PatchpointValue*&gt;&amp; patchpoints() const
 318     {
 319         return m_patchpoints;
 320     }
 321 
 322 private:

 323     ALWAYS_INLINE void validateInst(Inst&amp; inst)
 324     {
<span class="line-modified"> 325         if (!ASSERT_DISABLED) {</span>
 326             if (!inst.isValidForm()) {
<span class="line-modified"> 327                 dataLogLn(inst);</span>



 328                 CRASH();
 329             }
 330         }
 331     }
 332 
 333     static Arg extractArg(const TypedTmp&amp; tmp) { return tmp.tmp(); }
 334     static Arg extractArg(const Tmp&amp; tmp) { return Arg(tmp); }
 335     static Arg extractArg(const Arg&amp; arg) { return arg; }
 336 
 337     template&lt;typename... Arguments&gt;
 338     void append(BasicBlock* block, Kind kind, Arguments&amp;&amp;... arguments)
 339     {
 340         // FIXME: Find a way to use origin here.
 341         auto&amp; inst = block-&gt;append(kind, nullptr, extractArg(arguments)...);
 342         validateInst(inst);
 343     }
 344 
 345     template&lt;typename... Arguments&gt;
 346     void append(Kind kind, Arguments&amp;&amp;... arguments)
 347     {
</pre>
<hr />
<pre>
 383         switch (type) {
 384         case Type::I32:
 385             return g32();
 386         case Type::I64:
 387             return g64();
 388         case Type::Funcref:
 389             return gFuncref();
 390         case Type::Anyref:
 391             return gAnyref();
 392         case Type::F32:
 393             return f32();
 394         case Type::F64:
 395             return f64();
 396         case Type::Void:
 397             return { };
 398         default:
 399             RELEASE_ASSERT_NOT_REACHED();
 400         }
 401     }
 402 








 403     B3::PatchpointValue* addPatchpoint(B3::Type type)
 404     {
 405         auto* result = m_proc.add&lt;B3::PatchpointValue&gt;(type, B3::Origin());
 406         if (UNLIKELY(shouldDumpIRAtEachPhase(B3::AirMode)))
 407             m_patchpoints.add(result);
 408         return result;
 409     }
 410 
 411     template &lt;typename ...Args&gt;
 412     void emitPatchpoint(B3::PatchpointValue* patch, Tmp result, Args... theArgs)
 413     {
 414         emitPatchpoint(m_currentBlock, patch, result, std::forward&lt;Args&gt;(theArgs)...);
 415     }
 416 
 417     template &lt;typename ...Args&gt;
 418     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, Tmp result, Args... theArgs)
 419     {
<span class="line-modified"> 420         emitPatchpoint(basicBlock, patch, result, Vector&lt;ConstrainedTmp, sizeof...(Args)&gt;::from(theArgs...));</span>
 421     }
 422 
 423     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, Tmp result)
 424     {
<span class="line-modified"> 425         emitPatchpoint(basicBlock, patch, result, Vector&lt;ConstrainedTmp&gt;());</span>
 426     }
 427 
<span class="line-modified"> 428     template &lt;size_t inlineSize&gt;</span>
<span class="line-modified"> 429     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, Tmp result, Vector&lt;ConstrainedTmp, inlineSize&gt;&amp;&amp; args)</span>
 430     {
 431         if (!m_patchpointSpecial)
 432             m_patchpointSpecial = static_cast&lt;B3::PatchpointSpecial*&gt;(m_code.addSpecial(makeUnique&lt;B3::PatchpointSpecial&gt;()));
 433 







 434         Inst inst(Patch, patch, Arg::special(m_patchpointSpecial));
<span class="line-modified"> 435         Inst resultMov;</span>
<span class="line-modified"> 436         if (result) {</span>
<span class="line-modified"> 437             ASSERT(patch-&gt;type() != B3::Void);</span>
<span class="line-modified"> 438             switch (patch-&gt;resultConstraints[0].kind()) {</span>
<span class="line-modified"> 439             case B3::ValueRep::Register:</span>
<span class="line-modified"> 440                 inst.args.append(Tmp(patch-&gt;resultConstraints[0].reg()));</span>
<span class="line-modified"> 441                 resultMov = Inst(result.isGP() ? Move : MoveDouble, nullptr, Tmp(patch-&gt;resultConstraints[0].reg()), result);</span>
<span class="line-modified"> 442                 break;</span>
<span class="line-modified"> 443             case B3::ValueRep::SomeRegister:</span>
<span class="line-modified"> 444                 inst.args.append(result);</span>
<span class="line-modified"> 445                 break;</span>
<span class="line-modified"> 446             default:</span>
<span class="line-modified"> 447                 RELEASE_ASSERT_NOT_REACHED();</span>













 448             }
<span class="line-modified"> 449         } else</span>
<span class="line-modified"> 450             ASSERT(patch-&gt;type() == B3::Void);</span>
 451 
<span class="line-modified"> 452         for (ConstrainedTmp&amp; tmp : args) {</span>

 453             // FIXME: This is less than ideal to create dummy values just to satisfy Air&#39;s
 454             // validation. We should abstrcat Patch enough so ValueRep&#39;s don&#39;t need to be
 455             // backed by Values.
 456             // https://bugs.webkit.org/show_bug.cgi?id=194040
 457             B3::Value* dummyValue = m_proc.addConstant(B3::Origin(), tmp.tmp.isGP() ? B3::Int64 : B3::Double, 0);
 458             patch-&gt;append(dummyValue, tmp.rep);
 459             switch (tmp.rep.kind()) {
 460             case B3::ValueRep::ColdAny: // B3::Value propagates ColdAny information and later Air will allocate appropriate stack.
 461             case B3::ValueRep::SomeRegister:
 462                 inst.args.append(tmp.tmp);
 463                 break;
 464             case B3::ValueRep::Register:
 465                 patch-&gt;earlyClobbered().clear(tmp.rep.reg());
 466                 append(basicBlock, tmp.tmp.isGP() ? Move : MoveDouble, tmp.tmp, tmp.rep.reg());
 467                 inst.args.append(Tmp(tmp.rep.reg()));
 468                 break;
 469             case B3::ValueRep::StackArgument: {
<span class="line-modified"> 470                 auto arg = Arg::callArg(tmp.rep.offsetFromSP());</span>

 471                 append(basicBlock, tmp.tmp.isGP() ? Move : MoveDouble, tmp.tmp, arg);

 472                 inst.args.append(arg);
 473                 break;
 474             }
 475             default:
 476                 RELEASE_ASSERT_NOT_REACHED();
 477             }
 478         }
 479 
<span class="line-modified"> 480         if (patch-&gt;resultConstraints[0].isReg())</span>
<span class="line-modified"> 481             patch-&gt;lateClobbered().clear(patch-&gt;resultConstraints[0].reg());</span>


 482         for (unsigned i = patch-&gt;numGPScratchRegisters; i--;)
 483             inst.args.append(g64().tmp());
 484         for (unsigned i = patch-&gt;numFPScratchRegisters; i--;)
 485             inst.args.append(f64().tmp());
 486 
 487         validateInst(inst);
 488         basicBlock-&gt;append(WTFMove(inst));
<span class="line-modified"> 489         if (resultMov) {</span>
<span class="line-modified"> 490             validateInst(resultMov);</span>
<span class="line-modified"> 491             basicBlock-&gt;append(WTFMove(resultMov));</span>
 492         }
 493     }
 494 
 495     template &lt;typename Branch, typename Generator&gt;
 496     void emitCheck(const Branch&amp; makeBranch, const Generator&amp; generator)
 497     {
 498         // We fail along the truthy edge of &#39;branch&#39;.
 499         Inst branch = makeBranch();
 500 
 501         // FIXME: Make a hashmap of these.
 502         B3::CheckSpecial::Key key(branch);
 503         B3::CheckSpecial* special = static_cast&lt;B3::CheckSpecial*&gt;(m_code.addSpecial(makeUnique&lt;B3::CheckSpecial&gt;(key)));
 504 
 505         // FIXME: Remove the need for dummy values
 506         // https://bugs.webkit.org/show_bug.cgi?id=194040
 507         B3::Value* dummyPredicate = m_proc.addConstant(B3::Origin(), B3::Int32, 42);
 508         B3::CheckValue* checkValue = m_proc.add&lt;B3::CheckValue&gt;(B3::Check, B3::Origin(), dummyPredicate);
 509         checkValue-&gt;setGenerator(generator);
 510 
 511         Inst inst(Patch, checkValue, Arg::special(special));
</pre>
<hr />
<pre>
 574     static B3::Air::Opcode moveOpForValueType(Type type)
 575     {
 576         switch (type) {
 577         case Type::I32:
 578             return Move32;
 579         case Type::I64:
 580         case Type::Anyref:
 581         case Type::Funcref:
 582             return Move;
 583         case Type::F32:
 584             return MoveFloat;
 585         case Type::F64:
 586             return MoveDouble;
 587         default:
 588             RELEASE_ASSERT_NOT_REACHED();
 589         }
 590     }
 591 
 592     void emitThrowException(CCallHelpers&amp;, ExceptionType);
 593 
<span class="line-modified"> 594     void emitEntryTierUpCheck(int32_t incrementCount, B3::Origin);</span>
<span class="line-modified"> 595     void emitLoopTierUpCheck(int32_t incrementCount, const Stack&amp;, uint32_t, uint32_t, B3::Origin);</span>
 596 
 597     void emitWriteBarrierForJSWrapper();
 598     ExpressionType emitCheckAndPreparePointer(ExpressionType pointer, uint32_t offset, uint32_t sizeOfOp);
 599     ExpressionType emitLoadOp(LoadOpType, ExpressionType pointer, uint32_t offset);
 600     void emitStoreOp(StoreOpType, ExpressionType pointer, ExpressionType value, uint32_t offset);
 601 
<span class="line-modified"> 602     void unify(const ExpressionType&amp; dst, const ExpressionType&amp; source);</span>
 603     void unifyValuesWithBlock(const Stack&amp; resultStack, const ResultList&amp; stack);
 604 
 605     template &lt;typename IntType&gt;
 606     void emitChecksForModOrDiv(bool isSignedDiv, ExpressionType left, ExpressionType right);
 607 
 608     template &lt;typename IntType&gt;
 609     void emitModOrDiv(bool isDiv, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 610 
 611     enum class MinOrMax { Min, Max };
 612 
 613     PartialResult addFloatingPointMinOrMax(Type, MinOrMax, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 614 
 615     int32_t WARN_UNUSED_RETURN fixupPointerPlusOffset(ExpressionType&amp;, uint32_t);
 616 
 617     void restoreWasmContextInstance(BasicBlock*, TypedTmp);
 618     enum class RestoreCachedStackLimit { No, Yes };
 619     void restoreWebAssemblyGlobalState(RestoreCachedStackLimit, const MemoryInformation&amp;, TypedTmp instance, BasicBlock*);
 620 
 621     B3::Origin origin();
 622 
</pre>
<hr />
<pre>
 631     const ModuleInformation&amp; m_info;
 632     const MemoryMode m_mode { MemoryMode::BoundsChecking };
 633     const unsigned m_functionIndex { UINT_MAX };
 634     TierUpCount* m_tierUp { nullptr };
 635 
 636     B3::Procedure&amp; m_proc;
 637     Code&amp; m_code;
 638     Vector&lt;uint32_t&gt; m_outerLoops;
 639     BasicBlock* m_currentBlock { nullptr };
 640     BasicBlock* m_rootBlock { nullptr };
 641     Vector&lt;TypedTmp&gt; m_locals;
 642     Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; m_unlinkedWasmToWasmCalls; // List each call site and the function index whose address it should be patched with.
 643     GPRReg m_memoryBaseGPR { InvalidGPRReg };
 644     GPRReg m_memorySizeGPR { InvalidGPRReg };
 645     GPRReg m_wasmContextInstanceGPR { InvalidGPRReg };
 646     bool m_makesCalls { false };
 647 
 648     Vector&lt;Tmp, 8&gt; m_freeGPs;
 649     Vector&lt;Tmp, 8&gt; m_freeFPs;
 650 

 651     // This is only filled if we are dumping IR.
 652     Bag&lt;B3::PatchpointValue*&gt; m_patchpoints;
 653 
 654     TypedTmp m_instanceValue; // Always use the accessor below to ensure the instance value is materialized when used.
 655     bool m_usesInstanceValue { false };
 656     TypedTmp instanceValue()
 657     {
 658         m_usesInstanceValue = true;
 659         return m_instanceValue;
 660     }
 661 
 662     uint32_t m_maxNumJSCallArguments { 0 };
 663     unsigned m_numImportFunctions;
 664 
 665     B3::PatchpointSpecial* m_patchpointSpecial { nullptr };
 666 };
 667 
 668 // Memory accesses in WebAssembly have unsigned 32-bit offsets, whereas they have signed 32-bit offsets in B3.
 669 int32_t AirIRGenerator::fixupPointerPlusOffset(ExpressionType&amp; ptr, uint32_t offset)
 670 {
</pre>
<hr />
<pre>
 691         });
 692         emitPatchpoint(block, patchpoint, Tmp(), instance);
 693         return;
 694     }
 695 
 696     // FIXME: Because WasmToWasm call clobbers wasmContextInstance register and does not restore it, we need to restore it in the caller side.
 697     // This prevents us from using ArgumentReg to this (logically) immutable pinned register.
 698     auto* patchpoint = addPatchpoint(B3::Void);
 699     B3::Effects effects = B3::Effects::none();
 700     effects.writesPinned = true;
 701     effects.reads = B3::HeapRange::top();
 702     patchpoint-&gt;effects = effects;
 703     patchpoint-&gt;clobberLate(RegisterSet(m_wasmContextInstanceGPR));
 704     GPRReg wasmContextInstanceGPR = m_wasmContextInstanceGPR;
 705     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; param) {
 706         jit.move(param[0].gpr(), wasmContextInstanceGPR);
 707     });
 708     emitPatchpoint(block, patchpoint, Tmp(), instance);
 709 }
 710 
<span class="line-modified"> 711 AirIRGenerator::AirIRGenerator(const ModuleInformation&amp; info, B3::Procedure&amp; procedure, InternalFunction* compilation, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; unlinkedWasmToWasmCalls, MemoryMode mode, unsigned functionIndex, TierUpCount* tierUp, ThrowWasmException throwWasmException, const Signature&amp; signature)</span>
 712     : m_info(info)
 713     , m_mode(mode)
 714     , m_functionIndex(functionIndex)
 715     , m_tierUp(tierUp)
 716     , m_proc(procedure)
 717     , m_code(m_proc.code())
 718     , m_unlinkedWasmToWasmCalls(unlinkedWasmToWasmCalls)
 719     , m_numImportFunctions(info.importFunctionCount())
 720 {
 721     m_currentBlock = m_code.addBlock();
 722     m_rootBlock = m_currentBlock;
 723 
 724     // FIXME we don&#39;t really need to pin registers here if there&#39;s no memory. It makes wasm -&gt; wasm thunks simpler for now. https://bugs.webkit.org/show_bug.cgi?id=166623
 725     const PinnedRegisterInfo&amp; pinnedRegs = PinnedRegisterInfo::get();
 726 
 727     m_memoryBaseGPR = pinnedRegs.baseMemoryPointer;
 728     m_code.pinRegister(m_memoryBaseGPR);
 729 
 730     m_wasmContextInstanceGPR = pinnedRegs.wasmContextInstancePointer;
 731     if (!Context::useFastTLS())
 732         m_code.pinRegister(m_wasmContextInstanceGPR);
 733 
 734     if (mode != MemoryMode::Signaling) {
 735         m_memorySizeGPR = pinnedRegs.sizeRegister;
 736         m_code.pinRegister(m_memorySizeGPR);
 737     }
 738 
<span class="line-removed"> 739     if (throwWasmException)</span>
<span class="line-removed"> 740         Thunks::singleton().setThrowWasmException(throwWasmException);</span>
<span class="line-removed"> 741 </span>
 742     if (info.memory) {
 743         switch (m_mode) {
 744         case MemoryMode::BoundsChecking:
 745             break;
 746         case MemoryMode::Signaling:
 747             // Most memory accesses in signaling mode don&#39;t do an explicit
 748             // exception check because they can rely on fault handling to detect
 749             // out-of-bounds accesses. FaultSignalHandler nonetheless needs the
 750             // thunk to exist so that it can jump to that thunk.
 751             if (UNLIKELY(!Thunks::singleton().stub(throwExceptionFromWasmThunkGenerator)))
 752                 CRASH();
 753             break;
 754         }
 755     }
 756 
 757     m_code.setNumEntrypoints(1);
 758 
<span class="line-modified"> 759     GPRReg contextInstance = Context::useFastTLS() ? wasmCallingConventionAir().prologueScratch(1) : m_wasmContextInstanceGPR;</span>
 760 
 761     Ref&lt;B3::Air::PrologueGenerator&gt; prologueGenerator = createSharedTask&lt;B3::Air::PrologueGeneratorFunction&gt;([=] (CCallHelpers&amp; jit, B3::Air::Code&amp; code) {
 762         AllowMacroScratchRegisterUsage allowScratch(jit);
 763         code.emitDefaultPrologue(jit);
 764 
 765         {
<span class="line-modified"> 766             GPRReg calleeGPR = wasmCallingConventionAir().prologueScratch(0);</span>
 767             auto moveLocation = jit.moveWithPatch(MacroAssembler::TrustedImmPtr(nullptr), calleeGPR);
 768             jit.addLinkTask([compilation, moveLocation] (LinkBuffer&amp; linkBuffer) {
 769                 compilation-&gt;calleeMoveLocation = linkBuffer.locationOf&lt;WasmEntryPtrTag&gt;(moveLocation);
 770             });
 771             jit.emitPutToCallFrameHeader(calleeGPR, CallFrameSlot::callee);
 772             jit.emitPutToCallFrameHeader(nullptr, CallFrameSlot::codeBlock);
 773         }
 774 
 775         {
 776             const Checked&lt;int32_t&gt; wasmFrameSize = m_code.frameSize();
 777             const unsigned minimumParentCheckSize = WTF::roundUpToMultipleOf(stackAlignmentBytes(), 1024);
 778             const unsigned extraFrameSize = WTF::roundUpToMultipleOf(stackAlignmentBytes(), std::max&lt;uint32_t&gt;(
 779                 // This allows us to elide stack checks for functions that are terminal nodes in the call
 780                 // tree, (e.g they don&#39;t make any calls) and have a small enough frame size. This works by
 781                 // having any such terminal node have its parent caller include some extra size in its
 782                 // own check for it. The goal here is twofold:
 783                 // 1. Emit less code.
 784                 // 2. Try to speed things up by skipping stack checks.
 785                 minimumParentCheckSize,
 786                 // This allows us to elide stack checks in the Wasm -&gt; Embedder call IC stub. Since these will
 787                 // spill all arguments to the stack, we ensure that a stack check here covers the
 788                 // stack that such a stub would use.
<span class="line-modified"> 789                 (Checked&lt;uint32_t&gt;(m_maxNumJSCallArguments) * sizeof(Register) + jscCallingConvention().headerSizeInBytes()).unsafeGet()</span>
 790             ));
 791             const int32_t checkSize = m_makesCalls ? (wasmFrameSize + extraFrameSize).unsafeGet() : wasmFrameSize.unsafeGet();
 792             bool needUnderflowCheck = static_cast&lt;unsigned&gt;(checkSize) &gt; Options::reservedZoneSize();
 793             bool needsOverflowCheck = m_makesCalls || wasmFrameSize &gt;= minimumParentCheckSize || needUnderflowCheck;
 794 
 795             // This allows leaf functions to not do stack checks if their frame size is within
 796             // certain limits since their caller would have already done the check.
 797             if (needsOverflowCheck) {
<span class="line-modified"> 798                 GPRReg scratch = wasmCallingConventionAir().prologueScratch(0);</span>
 799 
 800                 if (Context::useFastTLS())
 801                     jit.loadWasmContextInstance(contextInstance);
 802 
 803                 jit.addPtr(CCallHelpers::TrustedImm32(-checkSize), GPRInfo::callFrameRegister, scratch);
 804                 MacroAssembler::JumpList overflow;
 805                 if (UNLIKELY(needUnderflowCheck))
 806                     overflow.append(jit.branchPtr(CCallHelpers::Above, scratch, GPRInfo::callFrameRegister));
 807                 overflow.append(jit.branchPtr(CCallHelpers::Below, scratch, CCallHelpers::Address(contextInstance, Instance::offsetOfCachedStackLimit())));
 808                 jit.addLinkTask([overflow] (LinkBuffer&amp; linkBuffer) {
 809                     linkBuffer.link(overflow, CodeLocationLabel&lt;JITThunkPtrTag&gt;(Thunks::singleton().stub(throwStackOverflowFromWasmThunkGenerator).code()));
 810                 });
 811             } else if (m_usesInstanceValue &amp;&amp; Context::useFastTLS()) {
 812                 // No overflow check is needed, but the instance values still needs to be correct.
 813                 jit.loadWasmContextInstance(contextInstance);
 814             }
 815         }
 816     });
 817 
 818     m_code.setPrologueForEntrypoint(0, WTFMove(prologueGenerator));
 819 
 820     if (Context::useFastTLS()) {
 821         m_instanceValue = g64();
 822         // FIXME: Would be nice to only do this if we use instance value.
 823         append(Move, Tmp(contextInstance), m_instanceValue);
 824     } else
 825         m_instanceValue = { Tmp(contextInstance), Type::I64 };
 826 
 827     ASSERT(!m_locals.size());
 828     m_locals.grow(signature.argumentCount());
 829     for (unsigned i = 0; i &lt; signature.argumentCount(); ++i) {
 830         Type type = signature.argument(i);
 831         m_locals[i] = tmpForType(type);
 832     }
 833 
<span class="line-modified"> 834     wasmCallingConventionAir().loadArguments(signature, [&amp;] (const Arg&amp; arg, unsigned i) {</span>




 835         switch (signature.argument(i)) {
 836         case Type::I32:
 837             append(Move32, arg, m_locals[i]);
 838             break;
 839         case Type::I64:
 840         case Type::Anyref:
 841         case Type::Funcref:
 842             append(Move, arg, m_locals[i]);
 843             break;
 844         case Type::F32:
 845             append(MoveFloat, arg, m_locals[i]);
 846             break;
 847         case Type::F64:
 848             append(MoveDouble, arg, m_locals[i]);
 849             break;
 850         default:
 851             RELEASE_ASSERT_NOT_REACHED();
 852         }
<span class="line-modified"> 853     });</span>
 854 
<span class="line-modified"> 855     emitEntryTierUpCheck(TierUpCount::functionEntryIncrement(), B3::Origin());</span>

















 856 }
 857 
 858 void AirIRGenerator::restoreWebAssemblyGlobalState(RestoreCachedStackLimit restoreCachedStackLimit, const MemoryInformation&amp; memory, TypedTmp instance, BasicBlock* block)
 859 {
 860     restoreWasmContextInstance(block, instance);
 861 
 862     if (restoreCachedStackLimit == RestoreCachedStackLimit::Yes) {
 863         // The Instance caches the stack limit, but also knows where its canonical location is.
 864         static_assert(sizeof(decltype(static_cast&lt;Instance*&gt;(nullptr)-&gt;cachedStackLimit())) == sizeof(uint64_t), &quot;&quot;);
 865 
 866         RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfPointerToActualStackLimit(), B3::Width64));
 867         RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfCachedStackLimit(), B3::Width64));
 868         auto temp = g64();
 869         append(block, Move, Arg::addr(instanceValue(), Instance::offsetOfPointerToActualStackLimit()), temp);
 870         append(block, Move, Arg::addr(temp), temp);
 871         append(block, Move, temp, Arg::addr(instanceValue(), Instance::offsetOfCachedStackLimit()));
 872     }
 873 
 874     if (!!memory) {
 875         const PinnedRegisterInfo* pinnedRegs = &amp;PinnedRegisterInfo::get();
</pre>
<hr />
<pre>
 960     case Type::I64:
 961     case Type::Anyref:
 962     case Type::Funcref:
 963         append(block, Move, Arg::bigImm(value), result);
 964         break;
 965     case Type::F32:
 966     case Type::F64: {
 967         auto tmp = g64();
 968         append(block, Move, Arg::bigImm(value), tmp);
 969         append(block, type == Type::F32 ? Move32ToFloat : Move64ToDouble, tmp, result);
 970         break;
 971     }
 972 
 973     default:
 974         RELEASE_ASSERT_NOT_REACHED();
 975     }
 976 
 977     return result;
 978 }
 979 






 980 auto AirIRGenerator::addArguments(const Signature&amp; signature) -&gt; PartialResult
 981 {
 982     RELEASE_ASSERT(m_locals.size() == signature.argumentCount()); // We handle arguments in the prologue
 983     return { };
 984 }
 985 
<span class="line-modified"> 986 auto AirIRGenerator::addRefIsNull(ExpressionType&amp; value, ExpressionType&amp; result) -&gt; PartialResult</span>
 987 {
 988     ASSERT(value.tmp());
 989     result = tmpForType(Type::I32);
 990     auto tmp = g64();
 991 
 992     append(Move, Arg::bigImm(JSValue::encode(jsNull())), tmp);
 993     append(Compare64, Arg::relCond(MacroAssembler::Equal), value, tmp, result);
 994 
 995     return { };
 996 }
 997 
 998 auto AirIRGenerator::addRefFunc(uint32_t index, ExpressionType&amp; result) -&gt; PartialResult
 999 {
1000     // FIXME: Emit this inline &lt;https://bugs.webkit.org/show_bug.cgi?id=198506&gt;.
1001     result = tmpForType(Type::Funcref);
<span class="line-modified">1002     emitCCall(&amp;doWasmRefFunc, result, instanceValue(), addConstant(Type::I32, index));</span>
1003 
1004     return { };
1005 }
1006 
<span class="line-modified">1007 auto AirIRGenerator::addTableGet(unsigned tableIndex, ExpressionType&amp; index, ExpressionType&amp; result) -&gt; PartialResult</span>
1008 {
1009     // FIXME: Emit this inline &lt;https://bugs.webkit.org/show_bug.cgi?id=198506&gt;.
1010     ASSERT(index.tmp());
1011     ASSERT(index.type() == Type::I32);
1012     result = tmpForType(m_info.tables[tableIndex].wasmType());
1013 
<span class="line-modified">1014     emitCCall(&amp;getWasmTableElement, result, instanceValue(), addConstant(Type::I32, tableIndex), index);</span>
1015     emitCheck([&amp;] {
1016         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::Zero), result, result);
1017     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1018         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTableAccess);
1019     });
1020 
1021     return { };
1022 }
1023 
<span class="line-modified">1024 auto AirIRGenerator::addTableSet(unsigned tableIndex, ExpressionType&amp; index, ExpressionType&amp; value) -&gt; PartialResult</span>
1025 {
1026     // FIXME: Emit this inline &lt;https://bugs.webkit.org/show_bug.cgi?id=198506&gt;.
1027     ASSERT(index.tmp());
1028     ASSERT(index.type() == Type::I32);
1029     ASSERT(value.tmp());
1030 
1031     auto shouldThrow = g32();
<span class="line-modified">1032     emitCCall(&amp;setWasmTableElement, shouldThrow, instanceValue(), addConstant(Type::I32, tableIndex), index, value);</span>
1033 
1034     emitCheck([&amp;] {
1035         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::Zero), shouldThrow, shouldThrow);
1036     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1037         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTableAccess);
1038     });
1039 
1040     return { };
1041 }
1042 
1043 auto AirIRGenerator::addTableSize(unsigned tableIndex, ExpressionType&amp; result) -&gt; PartialResult
1044 {
1045     // FIXME: Emit this inline &lt;https://bugs.webkit.org/show_bug.cgi?id=198506&gt;.
1046     result = tmpForType(Type::I32);
1047 
<span class="line-modified">1048     int32_t (*doSize)(Instance*, unsigned) = [] (Instance* instance, unsigned tableIndex) -&gt; int32_t {</span>
<span class="line-removed">1049         return instance-&gt;table(tableIndex)-&gt;length();</span>
<span class="line-removed">1050     };</span>
<span class="line-removed">1051 </span>
<span class="line-removed">1052     emitCCall(doSize, result, instanceValue(), addConstant(Type::I32, tableIndex));</span>
1053 
1054     return { };
1055 }
1056 
<span class="line-modified">1057 auto AirIRGenerator::addTableGrow(unsigned tableIndex, ExpressionType&amp; fill, ExpressionType&amp; delta, ExpressionType&amp; result) -&gt; PartialResult</span>
1058 {
1059     ASSERT(fill.tmp());
1060     ASSERT(isSubtype(fill.type(), m_info.tables[tableIndex].wasmType()));
1061     ASSERT(delta.tmp());
1062     ASSERT(delta.type() == Type::I32);
1063     result = tmpForType(Type::I32);
1064 
<span class="line-modified">1065     emitCCall(&amp;doWasmTableGrow, result, instanceValue(), addConstant(Type::I32, tableIndex), fill, delta);</span>
1066 
1067     return { };
1068 }
1069 
<span class="line-modified">1070 auto AirIRGenerator::addTableFill(unsigned tableIndex, ExpressionType&amp; offset, ExpressionType&amp; fill, ExpressionType&amp; count) -&gt; PartialResult</span>
1071 {
1072     ASSERT(fill.tmp());
1073     ASSERT(isSubtype(fill.type(), m_info.tables[tableIndex].wasmType()));
1074     ASSERT(offset.tmp());
1075     ASSERT(offset.type() == Type::I32);
1076     ASSERT(count.tmp());
1077     ASSERT(count.type() == Type::I32);
1078 
1079     auto result = tmpForType(Type::I32);
<span class="line-modified">1080     emitCCall(&amp;doWasmTableFill, result, instanceValue(), addConstant(Type::I32, tableIndex), offset, fill, count);</span>
1081 
1082     emitCheck([&amp;] {
1083         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::Zero), result, result);
1084     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1085         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTableAccess);
1086     });
1087 
1088     return { };
1089 }
1090 
1091 auto AirIRGenerator::getLocal(uint32_t index, ExpressionType&amp; result) -&gt; PartialResult
1092 {
1093     ASSERT(m_locals[index].tmp());
1094     result = tmpForType(m_locals[index].type());
1095     append(moveOpForValueType(m_locals[index].type()), m_locals[index].tmp(), result);
1096     return { };
1097 }
1098 
1099 auto AirIRGenerator::addUnreachable() -&gt; PartialResult
1100 {
1101     B3::PatchpointValue* unreachable = addPatchpoint(B3::Void);
1102     unreachable-&gt;setGenerator([this] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1103         this-&gt;emitThrowException(jit, ExceptionType::Unreachable);
1104     });
1105     unreachable-&gt;effects.terminal = true;
1106     emitPatchpoint(unreachable, Tmp());
1107     return { };
1108 }
1109 
1110 auto AirIRGenerator::addGrowMemory(ExpressionType delta, ExpressionType&amp; result) -&gt; PartialResult
1111 {
<span class="line-removed">1112     int32_t (*growMemory)(void*, Instance*, int32_t) = [] (void* callFrame, Instance* instance, int32_t delta) -&gt; int32_t {</span>
<span class="line-removed">1113         instance-&gt;storeTopCallFrame(callFrame);</span>
<span class="line-removed">1114 </span>
<span class="line-removed">1115         if (delta &lt; 0)</span>
<span class="line-removed">1116             return -1;</span>
<span class="line-removed">1117 </span>
<span class="line-removed">1118         auto grown = instance-&gt;memory()-&gt;grow(PageCount(delta));</span>
<span class="line-removed">1119         if (!grown) {</span>
<span class="line-removed">1120             switch (grown.error()) {</span>
<span class="line-removed">1121             case Memory::GrowFailReason::InvalidDelta:</span>
<span class="line-removed">1122             case Memory::GrowFailReason::InvalidGrowSize:</span>
<span class="line-removed">1123             case Memory::GrowFailReason::WouldExceedMaximum:</span>
<span class="line-removed">1124             case Memory::GrowFailReason::OutOfMemory:</span>
<span class="line-removed">1125                 return -1;</span>
<span class="line-removed">1126             }</span>
<span class="line-removed">1127             RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-removed">1128         }</span>
<span class="line-removed">1129 </span>
<span class="line-removed">1130         return grown.value().pageCount();</span>
<span class="line-removed">1131     };</span>
<span class="line-removed">1132 </span>
1133     result = g32();
<span class="line-modified">1134     emitCCall(growMemory, result, TypedTmp { Tmp(GPRInfo::callFrameRegister), Type::I64 }, instanceValue(), delta);</span>
1135     restoreWebAssemblyGlobalState(RestoreCachedStackLimit::No, m_info.memory, instanceValue(), m_currentBlock);
1136 
1137     return { };
1138 }
1139 
1140 auto AirIRGenerator::addCurrentMemory(ExpressionType&amp; result) -&gt; PartialResult
1141 {
1142     static_assert(sizeof(decltype(static_cast&lt;Memory*&gt;(nullptr)-&gt;size())) == sizeof(uint64_t), &quot;codegen relies on this size&quot;);
1143 
1144     auto temp1 = g64();
1145     auto temp2 = g64();
1146 
1147     RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfCachedMemorySize(), B3::Width64));
1148     append(Move, Arg::addr(instanceValue(), Instance::offsetOfCachedMemorySize()), temp1);
1149     constexpr uint32_t shiftValue = 16;
1150     static_assert(PageCount::pageSize == 1ull &lt;&lt; shiftValue, &quot;This must hold for the code below to be correct.&quot;);
1151     append(Move, Arg::imm(16), temp2);
1152     addShift(Type::I32, Urshift64, temp1, temp2, result);
1153     append(Move32, result, result);
1154 
1155     return { };
1156 }
1157 
1158 auto AirIRGenerator::setLocal(uint32_t index, ExpressionType value) -&gt; PartialResult
1159 {
1160     ASSERT(m_locals[index].tmp());
1161     append(moveOpForValueType(m_locals[index].type()), value, m_locals[index].tmp());
1162     return { };
1163 }
1164 
1165 auto AirIRGenerator::getGlobal(uint32_t index, ExpressionType&amp; result) -&gt; PartialResult
1166 {
<span class="line-modified">1167     Type type = m_info.globals[index].type;</span>

1168 
1169     result = tmpForType(type);
1170 
1171     auto temp = g64();
1172 
1173     RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfGlobals(), B3::Width64));
1174     append(Move, Arg::addr(instanceValue(), Instance::offsetOfGlobals()), temp);
1175 
1176     int32_t offset = safeCast&lt;int32_t&gt;(index * sizeof(Register));
<span class="line-modified">1177     if (Arg::isValidAddrForm(offset, B3::widthForType(toB3Type(type))))</span>
<span class="line-modified">1178         append(moveOpForValueType(type), Arg::addr(temp, offset), result);</span>
<span class="line-modified">1179     else {</span>
<span class="line-modified">1180         auto temp2 = g64();</span>
<span class="line-modified">1181         append(Move, Arg::bigImm(offset), temp2);</span>
<span class="line-modified">1182         append(Add64, temp2, temp, temp);</span>















1183         append(moveOpForValueType(type), Arg::addr(temp), result);

1184     }
1185     return { };
1186 }
1187 
1188 auto AirIRGenerator::setGlobal(uint32_t index, ExpressionType value) -&gt; PartialResult
1189 {
1190     auto temp = g64();
1191 
1192     RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfGlobals(), B3::Width64));
1193     append(Move, Arg::addr(instanceValue(), Instance::offsetOfGlobals()), temp);
1194 
<span class="line-modified">1195     Type type = m_info.globals[index].type;</span>

1196 
1197     int32_t offset = safeCast&lt;int32_t&gt;(index * sizeof(Register));
<span class="line-modified">1198     if (Arg::isValidAddrForm(offset, B3::widthForType(toB3Type(type))))</span>
<span class="line-modified">1199         append(moveOpForValueType(type), value, Arg::addr(temp, offset));</span>
<span class="line-modified">1200     else {</span>
<span class="line-modified">1201         auto temp2 = g64();</span>
<span class="line-modified">1202         append(Move, Arg::bigImm(offset), temp2);</span>
<span class="line-modified">1203         append(Add64, temp2, temp, temp);</span>

















1204         append(moveOpForValueType(type), value, Arg::addr(temp));
<span class="line-modified">1205     }</span>





































1206 
<span class="line-modified">1207     if (isSubtype(type, Anyref))</span>
<span class="line-modified">1208         emitWriteBarrierForJSWrapper();</span>





1209 
1210     return { };
1211 }
1212 
1213 inline void AirIRGenerator::emitWriteBarrierForJSWrapper()
1214 {
1215     auto cell = g64();
1216     auto vm = g64();
1217     auto cellState = g32();
1218     auto threshold = g32();
1219 
1220     BasicBlock* fenceCheckPath = m_code.addBlock();
1221     BasicBlock* fencePath = m_code.addBlock();
1222     BasicBlock* doSlowPath = m_code.addBlock();
1223     BasicBlock* continuation = m_code.addBlock();
1224 
1225     append(Move, Arg::addr(instanceValue(), Instance::offsetOfOwner()), cell);
1226     append(Move, Arg::addr(cell, JSWebAssemblyInstance::offsetOfVM()), vm);
1227     append(Load8, Arg::addr(cell, JSCell::cellStateOffset()), cellState);
1228     append(Move32, Arg::addr(vm, VM::offsetOfHeapBarrierThreshold()), threshold);
</pre>
<hr />
<pre>
1230     append(Branch32, Arg::relCond(MacroAssembler::Above), cellState, threshold);
1231     m_currentBlock-&gt;setSuccessors(continuation, fenceCheckPath);
1232     m_currentBlock = fenceCheckPath;
1233 
1234     append(Load8, Arg::addr(vm, VM::offsetOfHeapMutatorShouldBeFenced()), threshold);
1235     append(BranchTest32, Arg::resCond(MacroAssembler::Zero), threshold, threshold);
1236     m_currentBlock-&gt;setSuccessors(doSlowPath, fencePath);
1237     m_currentBlock = fencePath;
1238 
1239     auto* doFence = addPatchpoint(B3::Void);
1240     doFence-&gt;setGenerator([] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1241         jit.memoryFence();
1242     });
1243     emitPatchpoint(doFence, Tmp());
1244 
1245     append(Load8, Arg::addr(cell, JSCell::cellStateOffset()), cellState);
1246     append(Branch32, Arg::relCond(MacroAssembler::Above), cellState, Arg::imm(blackThreshold));
1247     m_currentBlock-&gt;setSuccessors(continuation, doSlowPath);
1248     m_currentBlock = doSlowPath;
1249 
<span class="line-modified">1250     void (*writeBarrier)(JSWebAssemblyInstance*, VM*) = [] (JSWebAssemblyInstance* cell, VM* vm) -&gt; void {</span>
<span class="line-removed">1251         ASSERT(cell);</span>
<span class="line-removed">1252         ASSERT(vm);</span>
<span class="line-removed">1253         vm-&gt;heap.writeBarrierSlowPath(cell);</span>
<span class="line-removed">1254     };</span>
<span class="line-removed">1255     emitCCall(writeBarrier, TypedTmp(), cell, vm);</span>
1256     append(Jump);
1257     m_currentBlock-&gt;setSuccessors(continuation);
1258     m_currentBlock = continuation;
1259 }
1260 
1261 inline AirIRGenerator::ExpressionType AirIRGenerator::emitCheckAndPreparePointer(ExpressionType pointer, uint32_t offset, uint32_t sizeOfOperation)
1262 {
1263     ASSERT(m_memoryBaseGPR);
1264 
1265     auto result = g64();
1266     append(Move32, pointer, result);
1267 
1268     switch (m_mode) {
1269     case MemoryMode::BoundsChecking: {
1270         // We&#39;re not using signal handling at all, we must therefore check that no memory access exceeds the current memory size.
1271         ASSERT(m_memorySizeGPR);
1272         ASSERT(sizeOfOperation + offset &gt; offset);
1273         auto temp = g64();
1274         append(Move, Arg::bigImm(static_cast&lt;uint64_t&gt;(sizeOfOperation) + offset - 1), temp);
1275         append(Add64, result, temp);
</pre>
<hr />
<pre>
1586 {
1587     ASSERT(nonZero.type() == zero.type());
1588     result = tmpForType(nonZero.type());
1589     append(moveOpForValueType(nonZero.type()), nonZero, result);
1590 
1591     BasicBlock* isZero = m_code.addBlock();
1592     BasicBlock* continuation = m_code.addBlock();
1593 
1594     append(BranchTest32, Arg::resCond(MacroAssembler::Zero), condition, condition);
1595     m_currentBlock-&gt;setSuccessors(isZero, continuation);
1596 
1597     append(isZero, moveOpForValueType(zero.type()), zero, result);
1598     append(isZero, Jump);
1599     isZero-&gt;setSuccessors(continuation);
1600 
1601     m_currentBlock = continuation;
1602 
1603     return { };
1604 }
1605 
<span class="line-modified">1606 void AirIRGenerator::emitEntryTierUpCheck(int32_t incrementCount, B3::Origin origin)</span>
1607 {
<span class="line-removed">1608     UNUSED_PARAM(origin);</span>
<span class="line-removed">1609 </span>
1610     if (!m_tierUp)
1611         return;
1612 
1613     auto countdownPtr = g64();
1614 
1615     append(Move, Arg::bigImm(reinterpret_cast&lt;uint64_t&gt;(&amp;m_tierUp-&gt;m_counter)), countdownPtr);
1616 
1617     auto* patch = addPatchpoint(B3::Void);
1618     B3::Effects effects = B3::Effects::none();
1619     effects.reads = B3::HeapRange::top();
1620     effects.writes = B3::HeapRange::top();
1621     patch-&gt;effects = effects;
1622     patch-&gt;clobber(RegisterSet::macroScratchRegisters());
1623 
1624     patch-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
1625         AllowMacroScratchRegisterUsage allowScratch(jit);
1626 
<span class="line-modified">1627         CCallHelpers::Jump tierUp = jit.branchAdd32(CCallHelpers::PositiveOrZero, CCallHelpers::TrustedImm32(incrementCount), CCallHelpers::Address(params[0].gpr()));</span>
1628         CCallHelpers::Label tierUpResume = jit.label();
1629 
1630         params.addLatePath([=] (CCallHelpers&amp; jit) {
1631             tierUp.link(&amp;jit);
1632 
1633             const unsigned extraPaddingBytes = 0;
1634             RegisterSet registersToSpill = { };
1635             registersToSpill.add(GPRInfo::argumentGPR1);
1636             unsigned numberOfStackBytesUsedForRegisterPreservation = ScratchRegisterAllocator::preserveRegistersToStackForCall(jit, registersToSpill, extraPaddingBytes);
1637 
1638             jit.move(MacroAssembler::TrustedImm32(m_functionIndex), GPRInfo::argumentGPR1);
1639             MacroAssembler::Call call = jit.nearCall();
1640 
1641             ScratchRegisterAllocator::restoreRegistersFromStackForCall(jit, registersToSpill, RegisterSet(), numberOfStackBytesUsedForRegisterPreservation, extraPaddingBytes);
1642             jit.jump(tierUpResume);
1643 
1644             jit.addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
1645                 MacroAssembler::repatchNearCall(linkBuffer.locationOfNearCall&lt;NoPtrTag&gt;(call), CodeLocationLabel&lt;JITThunkPtrTag&gt;(Thunks::singleton().stub(triggerOMGEntryTierUpThunkGenerator).code()));
1646             });
1647         });
1648     });
1649 
1650     emitPatchpoint(patch, Tmp(), countdownPtr);
1651 }
1652 
<span class="line-modified">1653 void AirIRGenerator::emitLoopTierUpCheck(int32_t incrementCount, const Stack&amp; expressionStack, uint32_t loopIndex, uint32_t outerLoopIndex, B3::Origin origin)</span>
1654 {
<span class="line-modified">1655     UNUSED_PARAM(origin);</span>

1656 
1657     if (!m_tierUp)
1658         return;
1659 
1660     ASSERT(m_tierUp-&gt;osrEntryTriggers().size() == loopIndex);
1661     m_tierUp-&gt;osrEntryTriggers().append(TierUpCount::TriggerReason::DontTrigger);
1662     m_tierUp-&gt;outerLoops().append(outerLoopIndex);
1663 
1664     auto countdownPtr = g64();
1665 
1666     append(Move, Arg::bigImm(reinterpret_cast&lt;uint64_t&gt;(&amp;m_tierUp-&gt;m_counter)), countdownPtr);
1667 
1668     auto* patch = addPatchpoint(B3::Void);
1669     B3::Effects effects = B3::Effects::none();
1670     effects.reads = B3::HeapRange::top();
1671     effects.writes = B3::HeapRange::top();
1672     effects.exitsSideways = true;
1673     patch-&gt;effects = effects;
1674 
1675     patch-&gt;clobber(RegisterSet::macroScratchRegisters());
1676     RegisterSet clobberLate;
1677     clobberLate.add(GPRInfo::argumentGPR0);
1678     patch-&gt;clobberLate(clobberLate);
1679 
1680     Vector&lt;ConstrainedTmp&gt; patchArgs;
1681     patchArgs.append(countdownPtr);
1682 
<span class="line-modified">1683     Vector&lt;B3::Type&gt; types;</span>
<span class="line-removed">1684     for (auto&amp; local : m_locals) {</span>
1685         patchArgs.append(ConstrainedTmp(local, B3::ValueRep::ColdAny));
<span class="line-modified">1686         types.append(toB3Type(local.type()));</span>
<span class="line-modified">1687     }</span>
<span class="line-modified">1688     for (auto&amp; expression : expressionStack) {</span>
<span class="line-modified">1689         patchArgs.append(ConstrainedTmp(expression, B3::ValueRep::ColdAny));</span>
<span class="line-removed">1690         types.append(toB3Type(expression.type()));</span>
1691     }


1692 
1693     TierUpCount::TriggerReason* forceEntryTrigger = &amp;(m_tierUp-&gt;osrEntryTriggers().last());
1694     static_assert(!static_cast&lt;uint8_t&gt;(TierUpCount::TriggerReason::DontTrigger), &quot;the JIT code assumes non-zero means &#39;enter&#39;&quot;);
1695     static_assert(sizeof(TierUpCount::TriggerReason) == 1, &quot;branchTest8 assumes this size&quot;);
1696     patch-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
1697         AllowMacroScratchRegisterUsage allowScratch(jit);
1698         CCallHelpers::Jump forceOSREntry = jit.branchTest8(CCallHelpers::NonZero, CCallHelpers::AbsoluteAddress(forceEntryTrigger));
<span class="line-modified">1699         CCallHelpers::Jump tierUp = jit.branchAdd32(CCallHelpers::PositiveOrZero, CCallHelpers::TrustedImm32(incrementCount), CCallHelpers::Address(params[0].gpr()));</span>
1700         MacroAssembler::Label tierUpResume = jit.label();
1701 
1702         OSREntryData&amp; osrEntryData = m_tierUp-&gt;addOSREntryData(m_functionIndex, loopIndex);
<span class="line-modified">1703         for (unsigned index = 0; index &lt; types.size(); ++index)</span>
<span class="line-modified">1704             osrEntryData.values().constructAndAppend(params[index + 1], types[index]);</span>

1705         OSREntryData* osrEntryDataPtr = &amp;osrEntryData;
1706 
1707         params.addLatePath([=] (CCallHelpers&amp; jit) {
1708             AllowMacroScratchRegisterUsage allowScratch(jit);
1709             forceOSREntry.link(&amp;jit);
1710             tierUp.link(&amp;jit);
1711 
<span class="line-modified">1712             jit.probe(triggerOSREntryNow, osrEntryDataPtr);</span>
1713             jit.branchTestPtr(CCallHelpers::Zero, GPRInfo::argumentGPR0).linkTo(tierUpResume, &amp;jit);
1714             jit.farJump(GPRInfo::argumentGPR1, WasmEntryPtrTag);
1715         });
1716     });
1717 
<span class="line-modified">1718     emitPatchpoint(patch, Tmp(), WTFMove(patchArgs));</span>
1719 }
1720 
<span class="line-modified">1721 AirIRGenerator::ControlData AirIRGenerator::addLoop(Type signature, const Stack&amp; expressionStack, uint32_t loopIndex)</span>





1722 {
1723     BasicBlock* body = m_code.addBlock();
1724     BasicBlock* continuation = m_code.addBlock();
1725 







1726     append(Jump);
1727     m_currentBlock-&gt;setSuccessors(body);
1728 
<span class="line-removed">1729     uint32_t outerLoopIndex = this-&gt;outerLoopIndex();</span>
<span class="line-removed">1730     m_outerLoops.append(loopIndex);</span>
1731     m_currentBlock = body;
<span class="line-modified">1732     emitLoopTierUpCheck(TierUpCount::loopIncrement(), expressionStack, loopIndex, outerLoopIndex, origin());</span>
<span class="line-removed">1733 </span>
<span class="line-removed">1734     return ControlData(origin(), signature, tmpForType(signature), BlockType::Loop, continuation, body);</span>
<span class="line-removed">1735 }</span>
1736 
<span class="line-modified">1737 AirIRGenerator::ControlData AirIRGenerator::addTopLevel(Type signature)</span>
<span class="line-removed">1738 {</span>
<span class="line-removed">1739     return ControlData(B3::Origin(), signature, tmpForType(signature), BlockType::TopLevel, m_code.addBlock());</span>
1740 }
1741 
<span class="line-modified">1742 AirIRGenerator::ControlData AirIRGenerator::addBlock(Type signature)</span>
1743 {
<span class="line-modified">1744     return ControlData(origin(), signature, tmpForType(signature), BlockType::Block, m_code.addBlock());</span>


1745 }
1746 
<span class="line-modified">1747 auto AirIRGenerator::addIf(ExpressionType condition, Type signature, ControlType&amp; result) -&gt; PartialResult</span>
1748 {
1749     BasicBlock* taken = m_code.addBlock();
1750     BasicBlock* notTaken = m_code.addBlock();
1751     BasicBlock* continuation = m_code.addBlock();
1752 
1753     // Wasm bools are i32.
1754     append(BranchTest32, Arg::resCond(MacroAssembler::NonZero), condition, condition);
1755     m_currentBlock-&gt;setSuccessors(taken, notTaken);
1756 
1757     m_currentBlock = taken;
<span class="line-modified">1758     result = ControlData(origin(), signature, tmpForType(signature), BlockType::If, continuation, notTaken);</span>

1759     return { };
1760 }
1761 
1762 auto AirIRGenerator::addElse(ControlData&amp; data, const Stack&amp; currentStack) -&gt; PartialResult
1763 {
<span class="line-modified">1764     unifyValuesWithBlock(currentStack, data.result);</span>
1765     append(Jump);
1766     m_currentBlock-&gt;setSuccessors(data.continuation);
1767     return addElseToUnreachable(data);
1768 }
1769 
1770 auto AirIRGenerator::addElseToUnreachable(ControlData&amp; data) -&gt; PartialResult
1771 {
<span class="line-modified">1772     ASSERT(data.type() == BlockType::If);</span>
1773     m_currentBlock = data.special;
1774     data.convertIfToBlock();
1775     return { };
1776 }
1777 
<span class="line-modified">1778 auto AirIRGenerator::addReturn(const ControlData&amp; data, const ExpressionList&amp; returnValues) -&gt; PartialResult</span>
1779 {
<span class="line-modified">1780     ASSERT(returnValues.size() &lt;= 1);</span>
<span class="line-modified">1781     if (returnValues.size()) {</span>
<span class="line-removed">1782         Tmp returnValueGPR = Tmp(GPRInfo::returnValueGPR);</span>
<span class="line-removed">1783         Tmp returnValueFPR = Tmp(FPRInfo::returnValueFPR);</span>
<span class="line-removed">1784         switch (data.signature()) {</span>
<span class="line-removed">1785         case Type::I32:</span>
<span class="line-removed">1786             append(Move32, returnValues[0], returnValueGPR);</span>
<span class="line-removed">1787             append(Ret32, returnValueGPR);</span>
<span class="line-removed">1788             break;</span>
<span class="line-removed">1789         case Type::I64:</span>
<span class="line-removed">1790         case Type::Anyref:</span>
<span class="line-removed">1791         case Type::Funcref:</span>
<span class="line-removed">1792             append(Move, returnValues[0], returnValueGPR);</span>
<span class="line-removed">1793             append(Ret64, returnValueGPR);</span>
<span class="line-removed">1794             break;</span>
<span class="line-removed">1795         case Type::F32:</span>
<span class="line-removed">1796             append(MoveFloat, returnValues[0], returnValueFPR);</span>
<span class="line-removed">1797             append(RetFloat, returnValueFPR);</span>
<span class="line-removed">1798             break;</span>
<span class="line-removed">1799         case Type::F64:</span>
<span class="line-removed">1800             append(MoveDouble, returnValues[0], returnValueFPR);</span>
<span class="line-removed">1801             append(RetFloat, returnValueFPR);</span>
<span class="line-removed">1802             break;</span>
<span class="line-removed">1803         default:</span>
<span class="line-removed">1804             RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-removed">1805         }</span>
<span class="line-removed">1806     } else</span>
1807         append(RetVoid);


































1808     return { };
1809 }
1810 
1811 // NOTE: All branches in Wasm are on 32-bit ints
1812 
1813 auto AirIRGenerator::addBranch(ControlData&amp; data, ExpressionType condition, const Stack&amp; returnValues) -&gt; PartialResult
1814 {
<span class="line-modified">1815     unifyValuesWithBlock(returnValues, data.resultForBranch());</span>
1816 
1817     BasicBlock* target = data.targetBlockForBranch();
1818     if (condition) {
1819         BasicBlock* continuation = m_code.addBlock();
1820         append(BranchTest32, Arg::resCond(MacroAssembler::NonZero), condition, condition);
1821         m_currentBlock-&gt;setSuccessors(target, continuation);
1822         m_currentBlock = continuation;
1823     } else {
1824         append(Jump);
1825         m_currentBlock-&gt;setSuccessors(target);
1826     }
1827 
1828     return { };
1829 }
1830 
1831 auto AirIRGenerator::addSwitch(ExpressionType condition, const Vector&lt;ControlData*&gt;&amp; targets, ControlData&amp; defaultTarget, const Stack&amp; expressionStack) -&gt; PartialResult
1832 {
1833     auto&amp; successors = m_currentBlock-&gt;successors();
1834     ASSERT(successors.isEmpty());
1835     for (const auto&amp; target : targets) {
<span class="line-modified">1836         unifyValuesWithBlock(expressionStack, target-&gt;resultForBranch());</span>
1837         successors.append(target-&gt;targetBlockForBranch());
1838     }
<span class="line-modified">1839     unifyValuesWithBlock(expressionStack, defaultTarget.resultForBranch());</span>
1840     successors.append(defaultTarget.targetBlockForBranch());
1841 
1842     ASSERT(condition.type() == Type::I32);
1843 
1844     // FIXME: We should consider dynamically switching between a jump table
1845     // and a binary switch depending on the number of successors.
1846     // https://bugs.webkit.org/show_bug.cgi?id=194477
1847 
1848     size_t numTargets = targets.size();
1849 
1850     auto* patchpoint = addPatchpoint(B3::Void);
1851     patchpoint-&gt;effects = B3::Effects::none();
1852     patchpoint-&gt;effects.terminal = true;
1853     patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
1854 
1855     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
1856         AllowMacroScratchRegisterUsage allowScratch(jit);
1857 
1858         Vector&lt;int64_t&gt; cases;
1859         cases.reserveInitialCapacity(numTargets);
</pre>
<hr />
<pre>
1878 
1879         Vector&lt;Box&lt;CCallHelpers::Label&gt;&gt; successorLabels = params.successorLabels();
1880         ASSERT(successorLabels.size() == caseJumps.size() + 1);
1881 
1882         params.addLatePath([=, caseJumps = WTFMove(caseJumps), successorLabels = WTFMove(successorLabels)] (CCallHelpers&amp; jit) {
1883             for (size_t i = 0; i &lt; numTargets; ++i)
1884                 caseJumps[i].linkTo(*successorLabels[i], &amp;jit);
1885             fallThrough.linkTo(*successorLabels[numTargets], &amp;jit);
1886         });
1887     });
1888 
1889     emitPatchpoint(patchpoint, TypedTmp(), condition);
1890 
1891     return { };
1892 }
1893 
1894 auto AirIRGenerator::endBlock(ControlEntry&amp; entry, Stack&amp; expressionStack) -&gt; PartialResult
1895 {
1896     ControlData&amp; data = entry.controlData;
1897 
<span class="line-modified">1898     unifyValuesWithBlock(expressionStack, data.result);</span>

1899     append(Jump);
1900     m_currentBlock-&gt;setSuccessors(data.continuation);
1901 
<span class="line-modified">1902     return addEndToUnreachable(entry);</span>
1903 }
1904 
1905 
<span class="line-modified">1906 auto AirIRGenerator::addEndToUnreachable(ControlEntry&amp; entry) -&gt; PartialResult</span>
1907 {
1908     ControlData&amp; data = entry.controlData;
1909     m_currentBlock = data.continuation;
1910 
<span class="line-modified">1911     if (data.type() == BlockType::If) {</span>
1912         append(data.special, Jump);
1913         data.special-&gt;setSuccessors(m_currentBlock);
1914     }
1915 
<span class="line-modified">1916     if (data.type() == BlockType::Loop)</span>
1917         m_outerLoops.removeLast();
<span class="line-modified">1918 </span>
<span class="line-modified">1919     for (const auto&amp; result : data.result)</span>
<span class="line-modified">1920         entry.enclosedExpressionStack.append(result);</span>









1921 
1922     // TopLevel does not have any code after this so we need to make sure we emit a return here.
<span class="line-modified">1923     if (data.type() == BlockType::TopLevel)</span>
1924         return addReturn(data, entry.enclosedExpressionStack);
1925 
1926     return { };
1927 }
1928 
<span class="line-modified">1929 auto AirIRGenerator::addCall(uint32_t functionIndex, const Signature&amp; signature, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result) -&gt; PartialResult</span>

























1930 {
1931     ASSERT(signature.argumentCount() == args.size());
1932 
1933     m_makesCalls = true;
1934 
<span class="line-modified">1935     Type returnType = signature.returnType();</span>
<span class="line-modified">1936     if (returnType != Type::Void)</span>
<span class="line-removed">1937         result = tmpForType(returnType);</span>
1938 
1939     Vector&lt;UnlinkedWasmToWasmCall&gt;* unlinkedWasmToWasmCalls = &amp;m_unlinkedWasmToWasmCalls;
1940 
1941     if (m_info.isImportedFunctionFromFunctionIndexSpace(functionIndex)) {
1942         m_maxNumJSCallArguments = std::max(m_maxNumJSCallArguments, static_cast&lt;uint32_t&gt;(args.size()));
1943 
1944         auto currentInstance = g64();
1945         append(Move, instanceValue(), currentInstance);
1946 
1947         auto targetInstance = g64();
1948 
1949         // FIXME: We should have better isel here.
1950         // https://bugs.webkit.org/show_bug.cgi?id=193999
1951         append(Move, Arg::bigImm(Instance::offsetOfTargetInstance(functionIndex)), targetInstance);
1952         append(Add64, instanceValue(), targetInstance);
1953         append(Move, Arg::addr(targetInstance), targetInstance);
1954 
1955         BasicBlock* isWasmBlock = m_code.addBlock();
1956         BasicBlock* isEmbedderBlock = m_code.addBlock();
1957         BasicBlock* continuation = m_code.addBlock();
1958 
1959         append(BranchTest64, Arg::resCond(MacroAssembler::NonZero), targetInstance, targetInstance);
1960         m_currentBlock-&gt;setSuccessors(isWasmBlock, isEmbedderBlock);
1961 
1962         {
<span class="line-modified">1963             auto* patchpoint = addPatchpoint(toB3Type(returnType));</span>
<span class="line-removed">1964             patchpoint-&gt;effects.writesPinned = true;</span>
<span class="line-removed">1965             patchpoint-&gt;effects.readsPinned = true;</span>
1966             // We need to clobber all potential pinned registers since we might be leaving the instance.
1967             // We pessimistically assume we could be calling to something that is bounds checking.
1968             // FIXME: We shouldn&#39;t have to do this: https://bugs.webkit.org/show_bug.cgi?id=172181
1969             patchpoint-&gt;clobberLate(PinnedRegisterInfo::get().toSave(MemoryMode::BoundsChecking));
1970 
<span class="line-removed">1971             Vector&lt;ConstrainedTmp&gt; patchArgs;</span>
<span class="line-removed">1972             wasmCallingConventionAir().setupCall(m_code, returnType, patchpoint, toTmpVector(args), [&amp;] (Tmp tmp, B3::ValueRep rep) {</span>
<span class="line-removed">1973                 patchArgs.append({ tmp, rep });</span>
<span class="line-removed">1974             });</span>
<span class="line-removed">1975 </span>
1976             patchpoint-&gt;setGenerator([unlinkedWasmToWasmCalls, functionIndex] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1977                 AllowMacroScratchRegisterUsage allowScratch(jit);
1978                 CCallHelpers::Call call = jit.threadSafePatchableNearCall();
1979                 jit.addLinkTask([unlinkedWasmToWasmCalls, call, functionIndex] (LinkBuffer&amp; linkBuffer) {
1980                     unlinkedWasmToWasmCalls-&gt;append({ linkBuffer.locationOfNearCall&lt;WasmEntryPtrTag&gt;(call), functionIndex });
1981                 });
1982             });
1983 
<span class="line-removed">1984             emitPatchpoint(isWasmBlock, patchpoint, result, WTFMove(patchArgs));</span>
1985             append(isWasmBlock, Jump);
1986             isWasmBlock-&gt;setSuccessors(continuation);
1987         }
1988 
1989         {
1990             auto jumpDestination = g64();
1991             append(isEmbedderBlock, Move, Arg::bigImm(Instance::offsetOfWasmToEmbedderStub(functionIndex)), jumpDestination);
1992             append(isEmbedderBlock, Add64, instanceValue(), jumpDestination);
1993             append(isEmbedderBlock, Move, Arg::addr(jumpDestination), jumpDestination);
1994 
<span class="line-modified">1995             auto* patchpoint = addPatchpoint(toB3Type(returnType));</span>
<span class="line-modified">1996             patchpoint-&gt;effects.writesPinned = true;</span>
<span class="line-modified">1997             patchpoint-&gt;effects.readsPinned = true;</span>
1998             // We need to clobber all potential pinned registers since we might be leaving the instance.
1999             // We pessimistically assume we could be calling to something that is bounds checking.
2000             // FIXME: We shouldn&#39;t have to do this: https://bugs.webkit.org/show_bug.cgi?id=172181
2001             patchpoint-&gt;clobberLate(PinnedRegisterInfo::get().toSave(MemoryMode::BoundsChecking));
<span class="line-modified">2002 </span>
<span class="line-removed">2003             Vector&lt;ConstrainedTmp&gt; patchArgs;</span>
<span class="line-removed">2004             patchArgs.append(jumpDestination);</span>
<span class="line-removed">2005 </span>
<span class="line-removed">2006             wasmCallingConventionAir().setupCall(m_code, returnType, patchpoint, toTmpVector(args), [&amp;] (Tmp tmp, B3::ValueRep rep) {</span>
<span class="line-removed">2007                 patchArgs.append({ tmp, rep });</span>
<span class="line-removed">2008             });</span>
<span class="line-removed">2009 </span>
<span class="line-removed">2010             patchpoint-&gt;setGenerator([returnType] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {</span>
2011                 AllowMacroScratchRegisterUsage allowScratch(jit);
<span class="line-modified">2012                 jit.call(params[returnType == Void ? 0 : 1].gpr(), WasmEntryPtrTag);</span>
2013             });
2014 
<span class="line-removed">2015             emitPatchpoint(isEmbedderBlock, patchpoint, result, WTFMove(patchArgs));</span>
2016             append(isEmbedderBlock, Jump);
2017             isEmbedderBlock-&gt;setSuccessors(continuation);
2018         }
2019 
2020         m_currentBlock = continuation;
2021         // The call could have been to another WebAssembly instance, and / or could have modified our Memory.
2022         restoreWebAssemblyGlobalState(RestoreCachedStackLimit::Yes, m_info.memory, currentInstance, continuation);
2023     } else {
<span class="line-modified">2024         auto* patchpoint = addPatchpoint(toB3Type(returnType));</span>
<span class="line-modified">2025         patchpoint-&gt;effects.writesPinned = true;</span>
<span class="line-modified">2026         patchpoint-&gt;effects.readsPinned = true;</span>
<span class="line-modified">2027 </span>
<span class="line-removed">2028         Vector&lt;ConstrainedTmp&gt; patchArgs;</span>
<span class="line-removed">2029         wasmCallingConventionAir().setupCall(m_code, returnType, patchpoint, toTmpVector(args), [&amp;] (Tmp tmp, B3::ValueRep rep) {</span>
<span class="line-removed">2030             patchArgs.append({ tmp, rep });</span>
<span class="line-removed">2031         });</span>
<span class="line-removed">2032 </span>
2033         patchpoint-&gt;setGenerator([unlinkedWasmToWasmCalls, functionIndex] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2034             AllowMacroScratchRegisterUsage allowScratch(jit);
2035             CCallHelpers::Call call = jit.threadSafePatchableNearCall();
2036             jit.addLinkTask([unlinkedWasmToWasmCalls, call, functionIndex] (LinkBuffer&amp; linkBuffer) {
2037                 unlinkedWasmToWasmCalls-&gt;append({ linkBuffer.locationOfNearCall&lt;WasmEntryPtrTag&gt;(call), functionIndex });
2038             });
2039         });
<span class="line-removed">2040 </span>
<span class="line-removed">2041         emitPatchpoint(m_currentBlock, patchpoint, result, WTFMove(patchArgs));</span>
2042     }
2043 
2044     return { };
2045 }
2046 
<span class="line-modified">2047 auto AirIRGenerator::addCallIndirect(unsigned tableIndex, const Signature&amp; signature, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result) -&gt; PartialResult</span>
2048 {
2049     ExpressionType calleeIndex = args.takeLast();
2050     ASSERT(signature.argumentCount() == args.size());
2051     ASSERT(m_info.tableCount() &gt; tableIndex);
2052     ASSERT(m_info.tables[tableIndex].type() == TableElementType::Funcref);
2053 
2054     m_makesCalls = true;
2055     // Note: call indirect can call either WebAssemblyFunction or WebAssemblyWrapperFunction. Because
2056     // WebAssemblyWrapperFunction is like calling into the embedder, we conservatively assume all call indirects
2057     // can be to the embedder for our stack check calculation.
2058     m_maxNumJSCallArguments = std::max(m_maxNumJSCallArguments, static_cast&lt;uint32_t&gt;(args.size()));
2059 
2060     auto currentInstance = g64();
2061     append(Move, instanceValue(), currentInstance);
2062 
2063     ExpressionType callableFunctionBuffer = g64();
2064     ExpressionType instancesBuffer = g64();
2065     ExpressionType callableFunctionBufferLength = g64();
2066     {
2067         RELEASE_ASSERT(Arg::isValidAddrForm(FuncRefTable::offsetOfFunctions(), B3::Width64));
</pre>
<hr />
<pre>
2156             // FIXME: We should support more than one memory size register
2157             //   see: https://bugs.webkit.org/show_bug.cgi?id=162952
2158             ASSERT(pinnedRegs.sizeRegister != newContextInstance);
2159             GPRReg scratchOrSize = Gigacage::isEnabled(Gigacage::Primitive) ? params.gpScratch(0) : pinnedRegs.sizeRegister;
2160 
2161             jit.loadPtr(CCallHelpers::Address(newContextInstance, Instance::offsetOfCachedMemorySize()), pinnedRegs.sizeRegister); // Memory size.
2162             jit.loadPtr(CCallHelpers::Address(newContextInstance, Instance::offsetOfCachedMemory()), baseMemory); // Memory::void*.
2163 
2164             jit.cageConditionally(Gigacage::Primitive, baseMemory, pinnedRegs.sizeRegister, scratchOrSize);
2165         });
2166 
2167         emitPatchpoint(doContextSwitch, patchpoint, Tmp(), newContextInstance, instanceValue());
2168         append(doContextSwitch, Jump);
2169         doContextSwitch-&gt;setSuccessors(continuation);
2170 
2171         m_currentBlock = continuation;
2172     }
2173 
2174     append(Move, Arg::addr(calleeCode), calleeCode);
2175 
<span class="line-modified">2176     Type returnType = signature.returnType();</span>
<span class="line-modified">2177     if (returnType != Type::Void)</span>
<span class="line-modified">2178         result = tmpForType(returnType);</span>




2179 
<span class="line-removed">2180     auto* patch = addPatchpoint(toB3Type(returnType));</span>
<span class="line-removed">2181     patch-&gt;effects.writesPinned = true;</span>
<span class="line-removed">2182     patch-&gt;effects.readsPinned = true;</span>
2183     // We need to clobber all potential pinned registers since we might be leaving the instance.
2184     // We pessimistically assume we&#39;re always calling something that is bounds checking so
2185     // because the wasm-&gt;wasm thunk unconditionally overrides the size registers.
2186     // FIXME: We should not have to do this, but the wasm-&gt;wasm stub assumes it can
2187     // use all the pinned registers as scratch: https://bugs.webkit.org/show_bug.cgi?id=172181
<span class="line-removed">2188     patch-&gt;clobberLate(PinnedRegisterInfo::get().toSave(MemoryMode::BoundsChecking));</span>
2189 
<span class="line-modified">2190     Vector&lt;ConstrainedTmp&gt; emitArgs;</span>
<span class="line-modified">2191     emitArgs.append(calleeCode);</span>
<span class="line-modified">2192     wasmCallingConventionAir().setupCall(m_code, returnType, patch, toTmpVector(args), [&amp;] (Tmp tmp, B3::ValueRep rep) {</span>
<span class="line-removed">2193         emitArgs.append({ tmp, rep });</span>
<span class="line-removed">2194     });</span>
<span class="line-removed">2195     patch-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {</span>
2196         AllowMacroScratchRegisterUsage allowScratch(jit);
<span class="line-modified">2197         jit.call(params[returnType == Void ? 0 : 1].gpr(), WasmEntryPtrTag);</span>
2198     });
2199 
<span class="line-removed">2200     emitPatchpoint(m_currentBlock, patch, result, WTFMove(emitArgs));</span>
<span class="line-removed">2201 </span>
2202     // The call could have been to another WebAssembly instance, and / or could have modified our Memory.
2203     restoreWebAssemblyGlobalState(RestoreCachedStackLimit::Yes, m_info.memory, currentInstance, m_currentBlock);
2204 
2205     return { };
2206 }
2207 
<span class="line-modified">2208 void AirIRGenerator::unify(const ExpressionType&amp; dst, const ExpressionType&amp; source)</span>
2209 {
2210     ASSERT(isSubtype(source.type(), dst.type()));
2211     append(moveOpForValueType(dst.type()), source, dst);
2212 }
2213 
2214 void AirIRGenerator::unifyValuesWithBlock(const Stack&amp; resultStack, const ResultList&amp; result)
2215 {
2216     ASSERT(result.size() &lt;= resultStack.size());
2217 
2218     for (size_t i = 0; i &lt; result.size(); ++i)
2219         unify(result[result.size() - 1 - i], resultStack[resultStack.size() - 1 - i]);
2220 }
2221 
<span class="line-modified">2222 void AirIRGenerator::dump(const Vector&lt;ControlEntry&gt;&amp;, const Stack*)</span>







2223 {












2224 }
2225 
2226 auto AirIRGenerator::origin() -&gt; B3::Origin
2227 {
2228     // FIXME: We should implement a way to give Inst&#39;s an origin.
2229     return B3::Origin();
2230 }
2231 
<span class="line-modified">2232 Expected&lt;std::unique_ptr&lt;InternalFunction&gt;, String&gt; parseAndCompileAir(CompilationContext&amp; compilationContext, const uint8_t* functionStart, size_t functionLength, const Signature&amp; signature, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; unlinkedWasmToWasmCalls, const ModuleInformation&amp; info, MemoryMode mode, uint32_t functionIndex, TierUpCount* tierUp, ThrowWasmException throwWasmException)</span>
2233 {
2234     auto result = makeUnique&lt;InternalFunction&gt;();
2235 
2236     compilationContext.embedderEntrypointJIT = makeUnique&lt;CCallHelpers&gt;();
2237     compilationContext.wasmEntrypointJIT = makeUnique&lt;CCallHelpers&gt;();
2238 
2239     B3::Procedure procedure;
2240     Code&amp; code = procedure.code();
2241 
2242     procedure.setOriginPrinter([] (PrintStream&amp; out, B3::Origin origin) {
2243         if (origin.data())
2244             out.print(&quot;Wasm: &quot;, bitwise_cast&lt;OpcodeOrigin&gt;(origin));
2245     });
2246 
2247     // This means we cannot use either StackmapGenerationParams::usedRegisters() or
2248     // StackmapGenerationParams::unavailableRegisters(). In exchange for this concession, we
2249     // don&#39;t strictly need to run Air::reportUsedRegisters(), which saves a bit of CPU time at
2250     // optLevel=1.
2251     procedure.setNeedsUsedRegisters(false);
2252 
2253     procedure.setOptLevel(Options::webAssemblyBBQAirOptimizationLevel());
2254 
<span class="line-modified">2255     AirIRGenerator irGenerator(info, procedure, result.get(), unlinkedWasmToWasmCalls, mode, functionIndex, tierUp, throwWasmException, signature);</span>
<span class="line-modified">2256     FunctionParser&lt;AirIRGenerator&gt; parser(irGenerator, functionStart, functionLength, signature, info);</span>
2257     WASM_FAIL_IF_HELPER_FAILS(parser.parse());
2258 
2259 
2260     for (BasicBlock* block : code) {
2261         for (size_t i = 0; i &lt; block-&gt;numSuccessors(); ++i)
2262             block-&gt;successorBlock(i)-&gt;addPredecessor(block);
2263     }
2264 
2265     {
2266         if (UNLIKELY(shouldDumpIRAtEachPhase(B3::AirMode))) {
2267             dataLogLn(&quot;Generated patchpoints&quot;);
2268             for (B3::PatchpointValue** patch : irGenerator.patchpoints())
2269                 dataLogLn(deepDump(procedure, *patch));
2270         }
2271 
2272         B3::Air::prepareForGeneration(code);
2273         B3::Air::generate(code, *compilationContext.wasmEntrypointJIT);
2274         compilationContext.wasmEntrypointByproducts = procedure.releaseByproducts();
2275         result-&gt;entrypoint.calleeSaveRegisters = code.calleeSaveRegisterAtOffsetList();
2276     }
</pre>
<hr />
<pre>
2327         B3::Air::Opcode div;
2328         switch (sizeof(IntType)) {
2329         case 4:
2330             div = isSigned ? Div32 : UDiv32;
2331             break;
2332         case 8:
2333             div = isSigned ? Div64 : UDiv64;
2334             break;
2335         }
2336 
2337         append(div, lhs, rhs, result);
2338 
2339         if (!isDiv) {
2340             append(sizeof(IntType) == 4 ? Mul32 : Mul64, result, rhs, result);
2341             append(sizeof(IntType) == 4 ? Sub32 : Sub64, lhs, result, result);
2342         }
2343 
2344         return;
2345     }
2346 
<span class="line-modified">2347 #if CPU(X86) || CPU(X86_64)</span>
2348     Tmp eax(X86Registers::eax);
2349     Tmp edx(X86Registers::edx);
2350 
2351     if (isSigned) {
2352         B3::Air::Opcode convertToDoubleWord;
2353         B3::Air::Opcode div;
2354         switch (sizeof(IntType)) {
2355         case 4:
2356             convertToDoubleWord = X86ConvertToDoubleWord32;
2357             div = X86Div32;
2358             break;
2359         case 8:
2360             convertToDoubleWord = X86ConvertToQuadWord64;
2361             div = X86Div64;
2362             break;
2363         default:
2364             RELEASE_ASSERT_NOT_REACHED();
2365         }
2366 
2367         // We implement &quot;res = Div&lt;Chill&gt;/Mod&lt;Chill&gt;(num, den)&quot; as follows:
</pre>
<hr />
<pre>
2519     return { };
2520 }
2521 
2522 template&lt;&gt;
2523 auto AirIRGenerator::addOp&lt;OpType::I32Popcnt&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2524 {
2525     result = g32();
2526 
2527 #if CPU(X86_64)
2528     if (MacroAssembler::supportsCountPopulation()) {
2529         auto* patchpoint = addPatchpoint(B3::Int32);
2530         patchpoint-&gt;effects = B3::Effects::none();
2531         patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2532             jit.countPopulation32(params[1].gpr(), params[0].gpr());
2533         });
2534         emitPatchpoint(patchpoint, result, arg);
2535         return { };
2536     }
2537 #endif
2538 
<span class="line-modified">2539     uint32_t (*popcount)(int32_t) = [] (int32_t value) -&gt; uint32_t { return __builtin_popcount(value); };</span>
<span class="line-removed">2540     emitCCall(popcount, result, arg);</span>
2541     return { };
2542 }
2543 
2544 template&lt;&gt;
2545 auto AirIRGenerator::addOp&lt;OpType::I64Popcnt&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2546 {
2547     result = g64();
2548 
2549 #if CPU(X86_64)
2550     if (MacroAssembler::supportsCountPopulation()) {
2551         auto* patchpoint = addPatchpoint(B3::Int64);
2552         patchpoint-&gt;effects = B3::Effects::none();
2553         patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2554             jit.countPopulation64(params[1].gpr(), params[0].gpr());
2555         });
2556         emitPatchpoint(patchpoint, result, arg);
2557         return { };
2558     }
2559 #endif
2560 
<span class="line-modified">2561     uint64_t (*popcount)(int64_t) = [] (int64_t value) -&gt; uint64_t { return __builtin_popcountll(value); };</span>
<span class="line-removed">2562     emitCCall(popcount, result, arg);</span>
2563     return { };
2564 }
2565 
2566 template&lt;&gt;
2567 auto AirIRGenerator::addOp&lt;F64ConvertUI64&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2568 {
2569     auto* patchpoint = addPatchpoint(B3::Double);
2570     patchpoint-&gt;effects = B3::Effects::none();
2571     if (isX86())
2572         patchpoint-&gt;numGPScratchRegisters = 1;
2573     patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
2574     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2575         AllowMacroScratchRegisterUsage allowScratch(jit);
2576 #if CPU(X86_64)
2577         jit.convertUInt64ToDouble(params[1].gpr(), params[0].fpr(), params.gpScratch(0));
2578 #else
2579         jit.convertUInt64ToDouble(params[1].gpr(), params[0].fpr());
2580 #endif
2581     });
2582     result = f64();
</pre>
<hr />
<pre>
2826     auto* patchpoint = addPatchpoint(B3::Int64);
2827     patchpoint-&gt;effects = B3::Effects::none();
2828     patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
2829     args.append(arg);
2830     if (isX86()) {
2831         args.append(signBitConstant);
2832         patchpoint-&gt;numFPScratchRegisters = 1;
2833     }
2834     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2835         AllowMacroScratchRegisterUsage allowScratch(jit);
2836         FPRReg scratch = InvalidFPRReg;
2837         FPRReg constant = InvalidFPRReg;
2838         if (isX86()) {
2839             scratch = params.fpScratch(0);
2840             constant = params[2].fpr();
2841         }
2842         jit.truncateDoubleToUint64(params[1].fpr(), params[0].gpr(), scratch, constant);
2843     });
2844 
2845     result = g64();
<span class="line-modified">2846     emitPatchpoint(m_currentBlock, patchpoint, result, WTFMove(args));</span>
2847     return { };
2848 }
2849 
2850 template&lt;&gt;
2851 auto AirIRGenerator::addOp&lt;OpType::I64TruncSF32&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2852 {
2853     auto max = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(-static_cast&lt;float&gt;(std::numeric_limits&lt;int64_t&gt;::min())));
2854     auto min = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(static_cast&lt;float&gt;(std::numeric_limits&lt;int64_t&gt;::min())));
2855 
2856     auto temp1 = g32();
2857     auto temp2 = g32();
2858     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleLessThanOrUnordered), arg, min, temp1);
2859     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleGreaterThanOrEqualOrUnordered), arg, max, temp2);
2860     append(Or32, temp1, temp2);
2861 
2862     emitCheck([&amp;] {
2863         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::NonZero), temp2, temp2);
2864     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2865         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTrunc);
2866     });
</pre>
<hr />
<pre>
2883 
2884     auto temp1 = g32();
2885     auto temp2 = g32();
2886     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleLessThanOrEqualOrUnordered), arg, min, temp1);
2887     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleGreaterThanOrEqualOrUnordered), arg, max, temp2);
2888     append(Or32, temp1, temp2);
2889 
2890     emitCheck([&amp;] {
2891         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::NonZero), temp2, temp2);
2892     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2893         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTrunc);
2894     });
2895 
2896     TypedTmp signBitConstant;
2897     if (isX86())
2898         signBitConstant = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(static_cast&lt;float&gt;(std::numeric_limits&lt;uint64_t&gt;::max() - std::numeric_limits&lt;int64_t&gt;::max())));
2899 
2900     auto* patchpoint = addPatchpoint(B3::Int64);
2901     patchpoint-&gt;effects = B3::Effects::none();
2902     patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
<span class="line-modified">2903     Vector&lt;ConstrainedTmp&gt; args;</span>
2904     args.append(arg);
2905     if (isX86()) {
2906         args.append(signBitConstant);
2907         patchpoint-&gt;numFPScratchRegisters = 1;
2908     }
2909     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2910         AllowMacroScratchRegisterUsage allowScratch(jit);
2911         FPRReg scratch = InvalidFPRReg;
2912         FPRReg constant = InvalidFPRReg;
2913         if (isX86()) {
2914             scratch = params.fpScratch(0);
2915             constant = params[2].fpr();
2916         }
2917         jit.truncateFloatToUint64(params[1].fpr(), params[0].gpr(), scratch, constant);
2918     });
2919 
2920     result = g64();
<span class="line-modified">2921     emitPatchpoint(m_currentBlock, patchpoint, result, WTFMove(args));</span>
2922 
2923     return { };
2924 }
2925 
2926 auto AirIRGenerator::addShift(Type type, B3::Air::Opcode op, ExpressionType value, ExpressionType shift, ExpressionType&amp; result) -&gt; PartialResult
2927 {
2928     ASSERT(type == Type::I64 || type == Type::I32);
2929     result = tmpForType(type);
2930 
2931     if (isValidForm(op, Arg::Tmp, Arg::Tmp, Arg::Tmp)) {
2932         append(op, value, shift, result);
2933         return { };
2934     }
2935 
2936 #if CPU(X86_64)
2937     Tmp ecx = Tmp(X86Registers::ecx);
2938     append(Move, value, result);
2939     append(Move, shift, ecx);
2940     append(op, ecx, result);
2941 #else
</pre>
</td>
<td>
<hr />
<pre>
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;WasmAirIRGenerator.h&quot;
  28 
  29 #if ENABLE(WEBASSEMBLY)
  30 
  31 #include &quot;AirCode.h&quot;
  32 #include &quot;AirGenerate.h&quot;
<span class="line-added">  33 #include &quot;AirHelpers.h&quot;</span>
  34 #include &quot;AirOpcodeUtils.h&quot;
  35 #include &quot;AirValidate.h&quot;
  36 #include &quot;AllowMacroScratchRegisterUsageIf.h&quot;
  37 #include &quot;B3CCallValue.h&quot;
  38 #include &quot;B3CheckSpecial.h&quot;
  39 #include &quot;B3CheckValue.h&quot;
  40 #include &quot;B3PatchpointSpecial.h&quot;
  41 #include &quot;B3Procedure.h&quot;
  42 #include &quot;B3ProcedureInlines.h&quot;
  43 #include &quot;BinarySwitch.h&quot;
  44 #include &quot;DisallowMacroScratchRegisterUsage.h&quot;
  45 #include &quot;JSCInlines.h&quot;
  46 #include &quot;JSWebAssemblyInstance.h&quot;
  47 #include &quot;ScratchRegisterAllocator.h&quot;
  48 #include &quot;VirtualRegister.h&quot;
  49 #include &quot;WasmCallingConvention.h&quot;
  50 #include &quot;WasmContextInlines.h&quot;
  51 #include &quot;WasmExceptionType.h&quot;
  52 #include &quot;WasmFunctionParser.h&quot;
  53 #include &quot;WasmInstance.h&quot;
  54 #include &quot;WasmMemory.h&quot;
  55 #include &quot;WasmOMGPlan.h&quot;
  56 #include &quot;WasmOSREntryData.h&quot;
  57 #include &quot;WasmOpcodeOrigin.h&quot;
  58 #include &quot;WasmOperations.h&quot;
  59 #include &quot;WasmSignatureInlines.h&quot;
  60 #include &quot;WasmThunks.h&quot;
  61 #include &lt;limits&gt;
  62 #include &lt;wtf/Box.h&gt;
  63 #include &lt;wtf/Optional.h&gt;
  64 #include &lt;wtf/StdLibExtras.h&gt;
  65 
  66 namespace JSC { namespace Wasm {
  67 
  68 using namespace B3::Air;
  69 
  70 struct ConstrainedTmp {
<span class="line-added">  71     ConstrainedTmp() = default;</span>
  72     ConstrainedTmp(Tmp tmp)
  73         : ConstrainedTmp(tmp, tmp.isReg() ? B3::ValueRep::reg(tmp.reg()) : B3::ValueRep::SomeRegister)
  74     { }
  75 
  76     ConstrainedTmp(Tmp tmp, B3::ValueRep rep)
  77         : tmp(tmp)
  78         , rep(rep)
  79     {
  80     }
  81 
<span class="line-added">  82     explicit operator bool() const { return !!tmp; }</span>
<span class="line-added">  83 </span>
  84     Tmp tmp;
  85     B3::ValueRep rep;
  86 };
  87 
  88 class TypedTmp {
  89 public:
  90     constexpr TypedTmp()
  91         : m_tmp()
  92         , m_type(Type::Void)
  93     { }
  94 
  95     TypedTmp(Tmp tmp, Type type)
  96         : m_tmp(tmp)
  97         , m_type(type)
  98     { }
  99 
 100     TypedTmp(const TypedTmp&amp;) = default;
 101     TypedTmp(TypedTmp&amp;&amp;) = default;
 102     TypedTmp&amp; operator=(TypedTmp&amp;&amp;) = default;
 103     TypedTmp&amp; operator=(const TypedTmp&amp;) = default;
 104 
 105     bool operator==(const TypedTmp&amp; other) const
 106     {
 107         return m_tmp == other.m_tmp &amp;&amp; m_type == other.m_type;
 108     }
 109     bool operator!=(const TypedTmp&amp; other) const
 110     {
 111         return !(*this == other);
 112     }
 113 
 114     explicit operator bool() const { return !!tmp(); }
 115 
 116     operator Tmp() const { return tmp(); }
 117     operator Arg() const { return Arg(tmp()); }
 118     Tmp tmp() const { return m_tmp; }
 119     Type type() const { return m_type; }
 120 
<span class="line-added"> 121     void dump(PrintStream&amp; out) const</span>
<span class="line-added"> 122     {</span>
<span class="line-added"> 123         out.print(&quot;(&quot;, m_tmp, &quot;, &quot;, m_type, &quot;)&quot;);</span>
<span class="line-added"> 124     }</span>
<span class="line-added"> 125 </span>
 126 private:
 127 
 128     Tmp m_tmp;
 129     Type m_type;
 130 };
 131 
 132 class AirIRGenerator {
 133 public:
<span class="line-added"> 134     using ExpressionType = TypedTmp;</span>
<span class="line-added"> 135     using ResultList = Vector&lt;ExpressionType, 8&gt;;</span>
<span class="line-added"> 136 </span>
 137     struct ControlData {
<span class="line-modified"> 138         ControlData(B3::Origin origin, BlockSignature result, ResultList resultTmps, BlockType type, BasicBlock* continuation, BasicBlock* special = nullptr)</span>
<span class="line-modified"> 139             : controlBlockType(type)</span>
 140             , continuation(continuation)
 141             , special(special)
<span class="line-modified"> 142             , results(resultTmps)</span>
<span class="line-added"> 143             , returnType(result)</span>
 144         {
<span class="line-modified"> 145             UNUSED_PARAM(origin);</span>





 146         }
 147 
 148         ControlData()
 149         {
 150         }
 151 
<span class="line-added"> 152         static bool isIf(const ControlData&amp; control) { return control.blockType() == BlockType::If; }</span>
<span class="line-added"> 153         static bool isTopLevel(const ControlData&amp; control) { return control.blockType() == BlockType::TopLevel; }</span>
<span class="line-added"> 154 </span>
 155         void dump(PrintStream&amp; out) const
 156         {
<span class="line-modified"> 157             switch (blockType()) {</span>
 158             case BlockType::If:
 159                 out.print(&quot;If:       &quot;);
 160                 break;
 161             case BlockType::Block:
 162                 out.print(&quot;Block:    &quot;);
 163                 break;
 164             case BlockType::Loop:
 165                 out.print(&quot;Loop:     &quot;);
 166                 break;
 167             case BlockType::TopLevel:
 168                 out.print(&quot;TopLevel: &quot;);
 169                 break;
 170             }
 171             out.print(&quot;Continuation: &quot;, *continuation, &quot;, Special: &quot;);
 172             if (special)
 173                 out.print(*special);
 174             else
 175                 out.print(&quot;None&quot;);



 176 
<span class="line-modified"> 177             CommaPrinter comma(&quot;, &quot;, &quot; Result Tmps: [&quot;);</span>
<span class="line-added"> 178             for (const auto&amp; tmp : results)</span>
<span class="line-added"> 179                 out.print(comma, tmp);</span>
<span class="line-added"> 180             if (comma.didPrint())</span>
<span class="line-added"> 181                 out.print(&quot;]&quot;);</span>
<span class="line-added"> 182         }</span>
 183 
<span class="line-modified"> 184         BlockType blockType() const { return controlBlockType; }</span>
<span class="line-added"> 185         BlockSignature signature() const { return returnType; }</span>
 186 
 187         BasicBlock* targetBlockForBranch()
 188         {
<span class="line-modified"> 189             if (blockType() == BlockType::Loop)</span>
 190                 return special;
 191             return continuation;
 192         }
 193 
 194         void convertIfToBlock()
 195         {
<span class="line-modified"> 196             ASSERT(blockType() == BlockType::If);</span>
<span class="line-modified"> 197             controlBlockType = BlockType::Block;</span>
 198             special = nullptr;
 199         }
 200 
<span class="line-modified"> 201         SignatureArgCount branchTargetArity() const</span>
<span class="line-added"> 202         {</span>
<span class="line-added"> 203             if (blockType() == BlockType::Loop)</span>
<span class="line-added"> 204                 return returnType-&gt;argumentCount();</span>
<span class="line-added"> 205             return returnType-&gt;returnCount();</span>
<span class="line-added"> 206         }</span>
 207 
<span class="line-modified"> 208         Type branchTargetType(unsigned i) const</span>
 209         {
<span class="line-modified"> 210             ASSERT(i &lt; branchTargetArity());</span>
<span class="line-modified"> 211             if (blockType() == BlockType::Loop)</span>
<span class="line-modified"> 212                 return returnType-&gt;argument(i);</span>
<span class="line-added"> 213             return returnType-&gt;returnType(i);</span>
 214         }
 215 
 216     private:
 217         friend class AirIRGenerator;
<span class="line-modified"> 218         BlockType controlBlockType;</span>
 219         BasicBlock* continuation;
 220         BasicBlock* special;
<span class="line-modified"> 221         ResultList results;</span>
<span class="line-modified"> 222         BlockSignature returnType;</span>
 223     };
 224 

 225     using ControlType = ControlData;




 226 
<span class="line-modified"> 227     using ControlEntry = FunctionParser&lt;AirIRGenerator&gt;::ControlEntry;</span>
<span class="line-modified"> 228     using ControlStack = FunctionParser&lt;AirIRGenerator&gt;::ControlStack;</span>
<span class="line-added"> 229     using Stack = FunctionParser&lt;AirIRGenerator&gt;::Stack;</span>
<span class="line-added"> 230     using TypedExpression = FunctionParser&lt;AirIRGenerator&gt;::TypedExpression;</span>
 231 
 232     using ErrorType = String;
 233     using UnexpectedResult = Unexpected&lt;ErrorType&gt;;
 234     using Result = Expected&lt;std::unique_ptr&lt;InternalFunction&gt;, ErrorType&gt;;
 235     using PartialResult = Expected&lt;void, ErrorType&gt;;
 236 
<span class="line-added"> 237     static_assert(std::is_same_v&lt;ResultList, FunctionParser&lt;AirIRGenerator&gt;::ResultList&gt;);</span>
<span class="line-added"> 238 </span>
<span class="line-added"> 239     static ExpressionType emptyExpression() { return { }; };</span>
<span class="line-added"> 240 </span>
 241     template &lt;typename ...Args&gt;
 242     NEVER_INLINE UnexpectedResult WARN_UNUSED_RETURN fail(Args... args) const
 243     {
 244         using namespace FailureHelper; // See ADL comment in WasmParser.h.
 245         return UnexpectedResult(makeString(&quot;WebAssembly.Module failed compiling: &quot;_s, makeString(args)...));
 246     }
 247 
 248 #define WASM_COMPILE_FAIL_IF(condition, ...) do { \
 249         if (UNLIKELY(condition))                  \
 250             return fail(__VA_ARGS__);             \
 251     } while (0)
 252 
<span class="line-modified"> 253     AirIRGenerator(const ModuleInformation&amp;, B3::Procedure&amp;, InternalFunction*, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp;, MemoryMode, unsigned functionIndex, TierUpCount*, const Signature&amp;);</span>
 254 
 255     PartialResult WARN_UNUSED_RETURN addArguments(const Signature&amp;);
 256     PartialResult WARN_UNUSED_RETURN addLocal(Type, uint32_t);
 257     ExpressionType addConstant(Type, uint64_t);
 258     ExpressionType addConstant(BasicBlock*, Type, uint64_t);
<span class="line-added"> 259     ExpressionType addBottom(BasicBlock*, Type);</span>
 260 
 261     // References
<span class="line-modified"> 262     PartialResult WARN_UNUSED_RETURN addRefIsNull(ExpressionType value, ExpressionType&amp; result);</span>
 263     PartialResult WARN_UNUSED_RETURN addRefFunc(uint32_t index, ExpressionType&amp; result);
 264 
 265     // Tables
<span class="line-modified"> 266     PartialResult WARN_UNUSED_RETURN addTableGet(unsigned, ExpressionType index, ExpressionType&amp; result);</span>
<span class="line-modified"> 267     PartialResult WARN_UNUSED_RETURN addTableSet(unsigned, ExpressionType index, ExpressionType value);</span>
 268     PartialResult WARN_UNUSED_RETURN addTableSize(unsigned, ExpressionType&amp; result);
<span class="line-modified"> 269     PartialResult WARN_UNUSED_RETURN addTableGrow(unsigned, ExpressionType fill, ExpressionType delta, ExpressionType&amp; result);</span>
<span class="line-modified"> 270     PartialResult WARN_UNUSED_RETURN addTableFill(unsigned, ExpressionType offset, ExpressionType fill, ExpressionType count);</span>
 271 
 272     // Locals
 273     PartialResult WARN_UNUSED_RETURN getLocal(uint32_t index, ExpressionType&amp; result);
 274     PartialResult WARN_UNUSED_RETURN setLocal(uint32_t index, ExpressionType value);
 275 
 276     // Globals
 277     PartialResult WARN_UNUSED_RETURN getGlobal(uint32_t index, ExpressionType&amp; result);
 278     PartialResult WARN_UNUSED_RETURN setGlobal(uint32_t index, ExpressionType value);
 279 
 280     // Memory
 281     PartialResult WARN_UNUSED_RETURN load(LoadOpType, ExpressionType pointer, ExpressionType&amp; result, uint32_t offset);
 282     PartialResult WARN_UNUSED_RETURN store(StoreOpType, ExpressionType pointer, ExpressionType value, uint32_t offset);
 283     PartialResult WARN_UNUSED_RETURN addGrowMemory(ExpressionType delta, ExpressionType&amp; result);
 284     PartialResult WARN_UNUSED_RETURN addCurrentMemory(ExpressionType&amp; result);
 285 
 286     // Basic operators
 287     template&lt;OpType&gt;
 288     PartialResult WARN_UNUSED_RETURN addOp(ExpressionType arg, ExpressionType&amp; result);
 289     template&lt;OpType&gt;
 290     PartialResult WARN_UNUSED_RETURN addOp(ExpressionType left, ExpressionType right, ExpressionType&amp; result);
 291     PartialResult WARN_UNUSED_RETURN addSelect(ExpressionType condition, ExpressionType nonZero, ExpressionType zero, ExpressionType&amp; result);
 292 
 293     // Control flow
<span class="line-modified"> 294     ControlData WARN_UNUSED_RETURN addTopLevel(BlockSignature);</span>
<span class="line-modified"> 295     PartialResult WARN_UNUSED_RETURN addBlock(BlockSignature, Stack&amp; enclosingStack, ControlType&amp; newBlock, Stack&amp; newStack);</span>
<span class="line-modified"> 296     PartialResult WARN_UNUSED_RETURN addLoop(BlockSignature, Stack&amp; enclosingStack, ControlType&amp; block, Stack&amp; newStack, uint32_t loopIndex);</span>
<span class="line-modified"> 297     PartialResult WARN_UNUSED_RETURN addIf(ExpressionType condition, BlockSignature, Stack&amp; enclosingStack, ControlType&amp; result, Stack&amp; newStack);</span>
 298     PartialResult WARN_UNUSED_RETURN addElse(ControlData&amp;, const Stack&amp;);
 299     PartialResult WARN_UNUSED_RETURN addElseToUnreachable(ControlData&amp;);
 300 
<span class="line-modified"> 301     PartialResult WARN_UNUSED_RETURN addReturn(const ControlData&amp;, const Stack&amp; returnValues);</span>
 302     PartialResult WARN_UNUSED_RETURN addBranch(ControlData&amp;, ExpressionType condition, const Stack&amp; returnValues);
 303     PartialResult WARN_UNUSED_RETURN addSwitch(ExpressionType condition, const Vector&lt;ControlData*&gt;&amp; targets, ControlData&amp; defaultTargets, const Stack&amp; expressionStack);
 304     PartialResult WARN_UNUSED_RETURN endBlock(ControlEntry&amp;, Stack&amp; expressionStack);
<span class="line-modified"> 305     PartialResult WARN_UNUSED_RETURN addEndToUnreachable(ControlEntry&amp;, const Stack&amp; expressionStack = { });</span>
<span class="line-added"> 306 </span>
<span class="line-added"> 307     PartialResult WARN_UNUSED_RETURN endTopLevel(BlockSignature, const Stack&amp;) { return { }; }</span>
 308 
 309     // Calls
<span class="line-modified"> 310     PartialResult WARN_UNUSED_RETURN addCall(uint32_t calleeIndex, const Signature&amp;, Vector&lt;ExpressionType&gt;&amp; args, ResultList&amp; results);</span>
<span class="line-modified"> 311     PartialResult WARN_UNUSED_RETURN addCallIndirect(unsigned tableIndex, const Signature&amp;, Vector&lt;ExpressionType&gt;&amp; args, ResultList&amp; results);</span>
 312     PartialResult WARN_UNUSED_RETURN addUnreachable();
<span class="line-added"> 313     B3::PatchpointValue* WARN_UNUSED_RETURN emitCallPatchpoint(BasicBlock*, const Signature&amp;, const ResultList&amp; results, const Vector&lt;TypedTmp&gt;&amp; args, Vector&lt;ConstrainedTmp&gt;&amp;&amp; extraArgs = { });</span>
 314 
 315     PartialResult addShift(Type, B3::Air::Opcode, ExpressionType value, ExpressionType shift, ExpressionType&amp; result);
 316     PartialResult addIntegerSub(B3::Air::Opcode, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 317     PartialResult addFloatingPointAbs(B3::Air::Opcode, ExpressionType value, ExpressionType&amp; result);
 318     PartialResult addFloatingPointBinOp(Type, B3::Air::Opcode, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 319 
<span class="line-modified"> 320     void dump(const ControlStack&amp;, const Stack* expressionStack);</span>
 321     void setParser(FunctionParser&lt;AirIRGenerator&gt;* parser) { m_parser = parser; };
<span class="line-modified"> 322     void didFinishParsingLocals() { }</span>
<span class="line-modified"> 323     void didPopValueFromStack() { }</span>

















 324 
 325     const Bag&lt;B3::PatchpointValue*&gt;&amp; patchpoints() const
 326     {
 327         return m_patchpoints;
 328     }
 329 
 330 private:
<span class="line-added"> 331     B3::Type toB3ResultType(BlockSignature returnType);</span>
 332     ALWAYS_INLINE void validateInst(Inst&amp; inst)
 333     {
<span class="line-modified"> 334         if (ASSERT_ENABLED) {</span>
 335             if (!inst.isValidForm()) {
<span class="line-modified"> 336                 dataLogLn(&quot;Inst validation failed:&quot;);</span>
<span class="line-added"> 337                 dataLogLn(inst, &quot;\n&quot;);</span>
<span class="line-added"> 338                 if (inst.origin)</span>
<span class="line-added"> 339                     dataLogLn(deepDump(inst.origin), &quot;\n&quot;);</span>
 340                 CRASH();
 341             }
 342         }
 343     }
 344 
 345     static Arg extractArg(const TypedTmp&amp; tmp) { return tmp.tmp(); }
 346     static Arg extractArg(const Tmp&amp; tmp) { return Arg(tmp); }
 347     static Arg extractArg(const Arg&amp; arg) { return arg; }
 348 
 349     template&lt;typename... Arguments&gt;
 350     void append(BasicBlock* block, Kind kind, Arguments&amp;&amp;... arguments)
 351     {
 352         // FIXME: Find a way to use origin here.
 353         auto&amp; inst = block-&gt;append(kind, nullptr, extractArg(arguments)...);
 354         validateInst(inst);
 355     }
 356 
 357     template&lt;typename... Arguments&gt;
 358     void append(Kind kind, Arguments&amp;&amp;... arguments)
 359     {
</pre>
<hr />
<pre>
 395         switch (type) {
 396         case Type::I32:
 397             return g32();
 398         case Type::I64:
 399             return g64();
 400         case Type::Funcref:
 401             return gFuncref();
 402         case Type::Anyref:
 403             return gAnyref();
 404         case Type::F32:
 405             return f32();
 406         case Type::F64:
 407             return f64();
 408         case Type::Void:
 409             return { };
 410         default:
 411             RELEASE_ASSERT_NOT_REACHED();
 412         }
 413     }
 414 
<span class="line-added"> 415     ResultList tmpsForSignature(BlockSignature signature)</span>
<span class="line-added"> 416     {</span>
<span class="line-added"> 417         ResultList result(signature-&gt;returnCount());</span>
<span class="line-added"> 418         for (unsigned i = 0; i &lt; signature-&gt;returnCount(); ++i)</span>
<span class="line-added"> 419             result[i] = tmpForType(signature-&gt;returnType(i));</span>
<span class="line-added"> 420         return result;</span>
<span class="line-added"> 421     }</span>
<span class="line-added"> 422 </span>
 423     B3::PatchpointValue* addPatchpoint(B3::Type type)
 424     {
 425         auto* result = m_proc.add&lt;B3::PatchpointValue&gt;(type, B3::Origin());
 426         if (UNLIKELY(shouldDumpIRAtEachPhase(B3::AirMode)))
 427             m_patchpoints.add(result);
 428         return result;
 429     }
 430 
 431     template &lt;typename ...Args&gt;
 432     void emitPatchpoint(B3::PatchpointValue* patch, Tmp result, Args... theArgs)
 433     {
 434         emitPatchpoint(m_currentBlock, patch, result, std::forward&lt;Args&gt;(theArgs)...);
 435     }
 436 
 437     template &lt;typename ...Args&gt;
 438     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, Tmp result, Args... theArgs)
 439     {
<span class="line-modified"> 440         emitPatchpoint(basicBlock, patch, Vector&lt;Tmp, 8&gt; { result }, Vector&lt;ConstrainedTmp, sizeof...(Args)&gt;::from(theArgs...));</span>
 441     }
 442 
 443     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, Tmp result)
 444     {
<span class="line-modified"> 445         emitPatchpoint(basicBlock, patch, Vector&lt;Tmp, 8&gt; { result }, Vector&lt;ConstrainedTmp&gt;());</span>
 446     }
 447 
<span class="line-modified"> 448     template &lt;typename ResultTmpType, size_t inlineSize&gt;</span>
<span class="line-modified"> 449     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, const Vector&lt;ResultTmpType, 8&gt;&amp;  results, Vector&lt;ConstrainedTmp, inlineSize&gt;&amp;&amp; args)</span>
 450     {
 451         if (!m_patchpointSpecial)
 452             m_patchpointSpecial = static_cast&lt;B3::PatchpointSpecial*&gt;(m_code.addSpecial(makeUnique&lt;B3::PatchpointSpecial&gt;()));
 453 
<span class="line-added"> 454         auto toTmp = [&amp;] (ResultTmpType tmp) {</span>
<span class="line-added"> 455             if constexpr (std::is_same_v&lt;ResultTmpType, Tmp&gt;)</span>
<span class="line-added"> 456                 return tmp;</span>
<span class="line-added"> 457             else</span>
<span class="line-added"> 458                 return tmp.tmp();</span>
<span class="line-added"> 459         };</span>
<span class="line-added"> 460 </span>
 461         Inst inst(Patch, patch, Arg::special(m_patchpointSpecial));
<span class="line-modified"> 462         Vector&lt;Inst, 1&gt; resultMovs;</span>
<span class="line-modified"> 463         switch (patch-&gt;type().kind()) {</span>
<span class="line-modified"> 464         case B3::Void:</span>
<span class="line-modified"> 465             break;</span>
<span class="line-modified"> 466         default: {</span>
<span class="line-modified"> 467             ASSERT(results.size());</span>
<span class="line-modified"> 468             for (unsigned i = 0; i &lt; results.size(); ++i) {</span>
<span class="line-modified"> 469                 switch (patch-&gt;resultConstraints[i].kind()) {</span>
<span class="line-modified"> 470                 case B3::ValueRep::StackArgument: {</span>
<span class="line-modified"> 471                     Arg arg = Arg::callArg(patch-&gt;resultConstraints[i].offsetFromSP());</span>
<span class="line-modified"> 472                     inst.args.append(arg);</span>
<span class="line-modified"> 473                     resultMovs.append(Inst(B3::Air::moveForType(m_proc.typeAtOffset(patch-&gt;type(), i)), nullptr, arg, toTmp(results[i])));</span>
<span class="line-modified"> 474                     break;</span>
<span class="line-added"> 475                 }</span>
<span class="line-added"> 476                 case B3::ValueRep::Register: {</span>
<span class="line-added"> 477                     inst.args.append(Tmp(patch-&gt;resultConstraints[i].reg()));</span>
<span class="line-added"> 478                     resultMovs.append(Inst(B3::Air::relaxedMoveForType(m_proc.typeAtOffset(patch-&gt;type(), i)), nullptr, Tmp(patch-&gt;resultConstraints[i].reg()), toTmp(results[i])));</span>
<span class="line-added"> 479                     break;</span>
<span class="line-added"> 480                 }</span>
<span class="line-added"> 481                 case B3::ValueRep::SomeRegister: {</span>
<span class="line-added"> 482                     inst.args.append(toTmp(results[i]));</span>
<span class="line-added"> 483                     break;</span>
<span class="line-added"> 484                 }</span>
<span class="line-added"> 485                 default:</span>
<span class="line-added"> 486                     RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-added"> 487                 }</span>
 488             }
<span class="line-modified"> 489         }</span>
<span class="line-modified"> 490         }</span>
 491 
<span class="line-modified"> 492         for (unsigned i = 0; i &lt; args.size(); ++i) {</span>
<span class="line-added"> 493             ConstrainedTmp&amp; tmp = args[i];</span>
 494             // FIXME: This is less than ideal to create dummy values just to satisfy Air&#39;s
 495             // validation. We should abstrcat Patch enough so ValueRep&#39;s don&#39;t need to be
 496             // backed by Values.
 497             // https://bugs.webkit.org/show_bug.cgi?id=194040
 498             B3::Value* dummyValue = m_proc.addConstant(B3::Origin(), tmp.tmp.isGP() ? B3::Int64 : B3::Double, 0);
 499             patch-&gt;append(dummyValue, tmp.rep);
 500             switch (tmp.rep.kind()) {
 501             case B3::ValueRep::ColdAny: // B3::Value propagates ColdAny information and later Air will allocate appropriate stack.
 502             case B3::ValueRep::SomeRegister:
 503                 inst.args.append(tmp.tmp);
 504                 break;
 505             case B3::ValueRep::Register:
 506                 patch-&gt;earlyClobbered().clear(tmp.rep.reg());
 507                 append(basicBlock, tmp.tmp.isGP() ? Move : MoveDouble, tmp.tmp, tmp.rep.reg());
 508                 inst.args.append(Tmp(tmp.rep.reg()));
 509                 break;
 510             case B3::ValueRep::StackArgument: {
<span class="line-modified"> 511                 ASSERT(!patch-&gt;effects.terminal);</span>
<span class="line-added"> 512                 Arg arg = Arg::callArg(tmp.rep.offsetFromSP());</span>
 513                 append(basicBlock, tmp.tmp.isGP() ? Move : MoveDouble, tmp.tmp, arg);
<span class="line-added"> 514                 ASSERT(arg.canRepresent(patch-&gt;child(i)-&gt;type()));</span>
 515                 inst.args.append(arg);
 516                 break;
 517             }
 518             default:
 519                 RELEASE_ASSERT_NOT_REACHED();
 520             }
 521         }
 522 
<span class="line-modified"> 523         for (auto valueRep : patch-&gt;resultConstraints) {</span>
<span class="line-modified"> 524             if (valueRep.isReg())</span>
<span class="line-added"> 525                 patch-&gt;lateClobbered().clear(valueRep.reg());</span>
<span class="line-added"> 526         }</span>
 527         for (unsigned i = patch-&gt;numGPScratchRegisters; i--;)
 528             inst.args.append(g64().tmp());
 529         for (unsigned i = patch-&gt;numFPScratchRegisters; i--;)
 530             inst.args.append(f64().tmp());
 531 
 532         validateInst(inst);
 533         basicBlock-&gt;append(WTFMove(inst));
<span class="line-modified"> 534         for (Inst result : resultMovs) {</span>
<span class="line-modified"> 535             validateInst(result);</span>
<span class="line-modified"> 536             basicBlock-&gt;append(WTFMove(result));</span>
 537         }
 538     }
 539 
 540     template &lt;typename Branch, typename Generator&gt;
 541     void emitCheck(const Branch&amp; makeBranch, const Generator&amp; generator)
 542     {
 543         // We fail along the truthy edge of &#39;branch&#39;.
 544         Inst branch = makeBranch();
 545 
 546         // FIXME: Make a hashmap of these.
 547         B3::CheckSpecial::Key key(branch);
 548         B3::CheckSpecial* special = static_cast&lt;B3::CheckSpecial*&gt;(m_code.addSpecial(makeUnique&lt;B3::CheckSpecial&gt;(key)));
 549 
 550         // FIXME: Remove the need for dummy values
 551         // https://bugs.webkit.org/show_bug.cgi?id=194040
 552         B3::Value* dummyPredicate = m_proc.addConstant(B3::Origin(), B3::Int32, 42);
 553         B3::CheckValue* checkValue = m_proc.add&lt;B3::CheckValue&gt;(B3::Check, B3::Origin(), dummyPredicate);
 554         checkValue-&gt;setGenerator(generator);
 555 
 556         Inst inst(Patch, checkValue, Arg::special(special));
</pre>
<hr />
<pre>
 619     static B3::Air::Opcode moveOpForValueType(Type type)
 620     {
 621         switch (type) {
 622         case Type::I32:
 623             return Move32;
 624         case Type::I64:
 625         case Type::Anyref:
 626         case Type::Funcref:
 627             return Move;
 628         case Type::F32:
 629             return MoveFloat;
 630         case Type::F64:
 631             return MoveDouble;
 632         default:
 633             RELEASE_ASSERT_NOT_REACHED();
 634         }
 635     }
 636 
 637     void emitThrowException(CCallHelpers&amp;, ExceptionType);
 638 
<span class="line-modified"> 639     void emitEntryTierUpCheck();</span>
<span class="line-modified"> 640     void emitLoopTierUpCheck(uint32_t loopIndex, const Stack&amp; enclosingStack);</span>
 641 
 642     void emitWriteBarrierForJSWrapper();
 643     ExpressionType emitCheckAndPreparePointer(ExpressionType pointer, uint32_t offset, uint32_t sizeOfOp);
 644     ExpressionType emitLoadOp(LoadOpType, ExpressionType pointer, uint32_t offset);
 645     void emitStoreOp(StoreOpType, ExpressionType pointer, ExpressionType value, uint32_t offset);
 646 
<span class="line-modified"> 647     void unify(const ExpressionType dst, const ExpressionType source);</span>
 648     void unifyValuesWithBlock(const Stack&amp; resultStack, const ResultList&amp; stack);
 649 
 650     template &lt;typename IntType&gt;
 651     void emitChecksForModOrDiv(bool isSignedDiv, ExpressionType left, ExpressionType right);
 652 
 653     template &lt;typename IntType&gt;
 654     void emitModOrDiv(bool isDiv, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 655 
 656     enum class MinOrMax { Min, Max };
 657 
 658     PartialResult addFloatingPointMinOrMax(Type, MinOrMax, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 659 
 660     int32_t WARN_UNUSED_RETURN fixupPointerPlusOffset(ExpressionType&amp;, uint32_t);
 661 
 662     void restoreWasmContextInstance(BasicBlock*, TypedTmp);
 663     enum class RestoreCachedStackLimit { No, Yes };
 664     void restoreWebAssemblyGlobalState(RestoreCachedStackLimit, const MemoryInformation&amp;, TypedTmp instance, BasicBlock*);
 665 
 666     B3::Origin origin();
 667 
</pre>
<hr />
<pre>
 676     const ModuleInformation&amp; m_info;
 677     const MemoryMode m_mode { MemoryMode::BoundsChecking };
 678     const unsigned m_functionIndex { UINT_MAX };
 679     TierUpCount* m_tierUp { nullptr };
 680 
 681     B3::Procedure&amp; m_proc;
 682     Code&amp; m_code;
 683     Vector&lt;uint32_t&gt; m_outerLoops;
 684     BasicBlock* m_currentBlock { nullptr };
 685     BasicBlock* m_rootBlock { nullptr };
 686     Vector&lt;TypedTmp&gt; m_locals;
 687     Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; m_unlinkedWasmToWasmCalls; // List each call site and the function index whose address it should be patched with.
 688     GPRReg m_memoryBaseGPR { InvalidGPRReg };
 689     GPRReg m_memorySizeGPR { InvalidGPRReg };
 690     GPRReg m_wasmContextInstanceGPR { InvalidGPRReg };
 691     bool m_makesCalls { false };
 692 
 693     Vector&lt;Tmp, 8&gt; m_freeGPs;
 694     Vector&lt;Tmp, 8&gt; m_freeFPs;
 695 
<span class="line-added"> 696     HashMap&lt;BlockSignature, B3::Type&gt; m_tupleMap;</span>
 697     // This is only filled if we are dumping IR.
 698     Bag&lt;B3::PatchpointValue*&gt; m_patchpoints;
 699 
 700     TypedTmp m_instanceValue; // Always use the accessor below to ensure the instance value is materialized when used.
 701     bool m_usesInstanceValue { false };
 702     TypedTmp instanceValue()
 703     {
 704         m_usesInstanceValue = true;
 705         return m_instanceValue;
 706     }
 707 
 708     uint32_t m_maxNumJSCallArguments { 0 };
 709     unsigned m_numImportFunctions;
 710 
 711     B3::PatchpointSpecial* m_patchpointSpecial { nullptr };
 712 };
 713 
 714 // Memory accesses in WebAssembly have unsigned 32-bit offsets, whereas they have signed 32-bit offsets in B3.
 715 int32_t AirIRGenerator::fixupPointerPlusOffset(ExpressionType&amp; ptr, uint32_t offset)
 716 {
</pre>
<hr />
<pre>
 737         });
 738         emitPatchpoint(block, patchpoint, Tmp(), instance);
 739         return;
 740     }
 741 
 742     // FIXME: Because WasmToWasm call clobbers wasmContextInstance register and does not restore it, we need to restore it in the caller side.
 743     // This prevents us from using ArgumentReg to this (logically) immutable pinned register.
 744     auto* patchpoint = addPatchpoint(B3::Void);
 745     B3::Effects effects = B3::Effects::none();
 746     effects.writesPinned = true;
 747     effects.reads = B3::HeapRange::top();
 748     patchpoint-&gt;effects = effects;
 749     patchpoint-&gt;clobberLate(RegisterSet(m_wasmContextInstanceGPR));
 750     GPRReg wasmContextInstanceGPR = m_wasmContextInstanceGPR;
 751     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; param) {
 752         jit.move(param[0].gpr(), wasmContextInstanceGPR);
 753     });
 754     emitPatchpoint(block, patchpoint, Tmp(), instance);
 755 }
 756 
<span class="line-modified"> 757 AirIRGenerator::AirIRGenerator(const ModuleInformation&amp; info, B3::Procedure&amp; procedure, InternalFunction* compilation, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; unlinkedWasmToWasmCalls, MemoryMode mode, unsigned functionIndex, TierUpCount* tierUp, const Signature&amp; signature)</span>
 758     : m_info(info)
 759     , m_mode(mode)
 760     , m_functionIndex(functionIndex)
 761     , m_tierUp(tierUp)
 762     , m_proc(procedure)
 763     , m_code(m_proc.code())
 764     , m_unlinkedWasmToWasmCalls(unlinkedWasmToWasmCalls)
 765     , m_numImportFunctions(info.importFunctionCount())
 766 {
 767     m_currentBlock = m_code.addBlock();
 768     m_rootBlock = m_currentBlock;
 769 
 770     // FIXME we don&#39;t really need to pin registers here if there&#39;s no memory. It makes wasm -&gt; wasm thunks simpler for now. https://bugs.webkit.org/show_bug.cgi?id=166623
 771     const PinnedRegisterInfo&amp; pinnedRegs = PinnedRegisterInfo::get();
 772 
 773     m_memoryBaseGPR = pinnedRegs.baseMemoryPointer;
 774     m_code.pinRegister(m_memoryBaseGPR);
 775 
 776     m_wasmContextInstanceGPR = pinnedRegs.wasmContextInstancePointer;
 777     if (!Context::useFastTLS())
 778         m_code.pinRegister(m_wasmContextInstanceGPR);
 779 
 780     if (mode != MemoryMode::Signaling) {
 781         m_memorySizeGPR = pinnedRegs.sizeRegister;
 782         m_code.pinRegister(m_memorySizeGPR);
 783     }
 784 



 785     if (info.memory) {
 786         switch (m_mode) {
 787         case MemoryMode::BoundsChecking:
 788             break;
 789         case MemoryMode::Signaling:
 790             // Most memory accesses in signaling mode don&#39;t do an explicit
 791             // exception check because they can rely on fault handling to detect
 792             // out-of-bounds accesses. FaultSignalHandler nonetheless needs the
 793             // thunk to exist so that it can jump to that thunk.
 794             if (UNLIKELY(!Thunks::singleton().stub(throwExceptionFromWasmThunkGenerator)))
 795                 CRASH();
 796             break;
 797         }
 798     }
 799 
 800     m_code.setNumEntrypoints(1);
 801 
<span class="line-modified"> 802     GPRReg contextInstance = Context::useFastTLS() ? wasmCallingConvention().prologueScratchGPRs[1] : m_wasmContextInstanceGPR;</span>
 803 
 804     Ref&lt;B3::Air::PrologueGenerator&gt; prologueGenerator = createSharedTask&lt;B3::Air::PrologueGeneratorFunction&gt;([=] (CCallHelpers&amp; jit, B3::Air::Code&amp; code) {
 805         AllowMacroScratchRegisterUsage allowScratch(jit);
 806         code.emitDefaultPrologue(jit);
 807 
 808         {
<span class="line-modified"> 809             GPRReg calleeGPR = wasmCallingConvention().prologueScratchGPRs[0];</span>
 810             auto moveLocation = jit.moveWithPatch(MacroAssembler::TrustedImmPtr(nullptr), calleeGPR);
 811             jit.addLinkTask([compilation, moveLocation] (LinkBuffer&amp; linkBuffer) {
 812                 compilation-&gt;calleeMoveLocation = linkBuffer.locationOf&lt;WasmEntryPtrTag&gt;(moveLocation);
 813             });
 814             jit.emitPutToCallFrameHeader(calleeGPR, CallFrameSlot::callee);
 815             jit.emitPutToCallFrameHeader(nullptr, CallFrameSlot::codeBlock);
 816         }
 817 
 818         {
 819             const Checked&lt;int32_t&gt; wasmFrameSize = m_code.frameSize();
 820             const unsigned minimumParentCheckSize = WTF::roundUpToMultipleOf(stackAlignmentBytes(), 1024);
 821             const unsigned extraFrameSize = WTF::roundUpToMultipleOf(stackAlignmentBytes(), std::max&lt;uint32_t&gt;(
 822                 // This allows us to elide stack checks for functions that are terminal nodes in the call
 823                 // tree, (e.g they don&#39;t make any calls) and have a small enough frame size. This works by
 824                 // having any such terminal node have its parent caller include some extra size in its
 825                 // own check for it. The goal here is twofold:
 826                 // 1. Emit less code.
 827                 // 2. Try to speed things up by skipping stack checks.
 828                 minimumParentCheckSize,
 829                 // This allows us to elide stack checks in the Wasm -&gt; Embedder call IC stub. Since these will
 830                 // spill all arguments to the stack, we ensure that a stack check here covers the
 831                 // stack that such a stub would use.
<span class="line-modified"> 832                 (Checked&lt;uint32_t&gt;(m_maxNumJSCallArguments) * sizeof(Register) + jsCallingConvention().headerSizeInBytes).unsafeGet()</span>
 833             ));
 834             const int32_t checkSize = m_makesCalls ? (wasmFrameSize + extraFrameSize).unsafeGet() : wasmFrameSize.unsafeGet();
 835             bool needUnderflowCheck = static_cast&lt;unsigned&gt;(checkSize) &gt; Options::reservedZoneSize();
 836             bool needsOverflowCheck = m_makesCalls || wasmFrameSize &gt;= minimumParentCheckSize || needUnderflowCheck;
 837 
 838             // This allows leaf functions to not do stack checks if their frame size is within
 839             // certain limits since their caller would have already done the check.
 840             if (needsOverflowCheck) {
<span class="line-modified"> 841                 GPRReg scratch = wasmCallingConvention().prologueScratchGPRs[0];</span>
 842 
 843                 if (Context::useFastTLS())
 844                     jit.loadWasmContextInstance(contextInstance);
 845 
 846                 jit.addPtr(CCallHelpers::TrustedImm32(-checkSize), GPRInfo::callFrameRegister, scratch);
 847                 MacroAssembler::JumpList overflow;
 848                 if (UNLIKELY(needUnderflowCheck))
 849                     overflow.append(jit.branchPtr(CCallHelpers::Above, scratch, GPRInfo::callFrameRegister));
 850                 overflow.append(jit.branchPtr(CCallHelpers::Below, scratch, CCallHelpers::Address(contextInstance, Instance::offsetOfCachedStackLimit())));
 851                 jit.addLinkTask([overflow] (LinkBuffer&amp; linkBuffer) {
 852                     linkBuffer.link(overflow, CodeLocationLabel&lt;JITThunkPtrTag&gt;(Thunks::singleton().stub(throwStackOverflowFromWasmThunkGenerator).code()));
 853                 });
 854             } else if (m_usesInstanceValue &amp;&amp; Context::useFastTLS()) {
 855                 // No overflow check is needed, but the instance values still needs to be correct.
 856                 jit.loadWasmContextInstance(contextInstance);
 857             }
 858         }
 859     });
 860 
 861     m_code.setPrologueForEntrypoint(0, WTFMove(prologueGenerator));
 862 
 863     if (Context::useFastTLS()) {
 864         m_instanceValue = g64();
 865         // FIXME: Would be nice to only do this if we use instance value.
 866         append(Move, Tmp(contextInstance), m_instanceValue);
 867     } else
 868         m_instanceValue = { Tmp(contextInstance), Type::I64 };
 869 
 870     ASSERT(!m_locals.size());
 871     m_locals.grow(signature.argumentCount());
 872     for (unsigned i = 0; i &lt; signature.argumentCount(); ++i) {
 873         Type type = signature.argument(i);
 874         m_locals[i] = tmpForType(type);
 875     }
 876 
<span class="line-modified"> 877     CallInformation wasmCallInfo = wasmCallingConvention().callInformationFor(signature, CallRole::Callee);</span>
<span class="line-added"> 878 </span>
<span class="line-added"> 879     for (unsigned i = 0; i &lt; wasmCallInfo.params.size(); ++i) {</span>
<span class="line-added"> 880         B3::ValueRep location = wasmCallInfo.params[i];</span>
<span class="line-added"> 881         Arg arg = location.isReg() ? Arg(Tmp(location.reg())) : Arg::addr(Tmp(GPRInfo::callFrameRegister), location.offsetFromFP());</span>
 882         switch (signature.argument(i)) {
 883         case Type::I32:
 884             append(Move32, arg, m_locals[i]);
 885             break;
 886         case Type::I64:
 887         case Type::Anyref:
 888         case Type::Funcref:
 889             append(Move, arg, m_locals[i]);
 890             break;
 891         case Type::F32:
 892             append(MoveFloat, arg, m_locals[i]);
 893             break;
 894         case Type::F64:
 895             append(MoveDouble, arg, m_locals[i]);
 896             break;
 897         default:
 898             RELEASE_ASSERT_NOT_REACHED();
 899         }
<span class="line-modified"> 900     }</span>
 901 
<span class="line-modified"> 902     emitEntryTierUpCheck();</span>
<span class="line-added"> 903 }</span>
<span class="line-added"> 904 </span>
<span class="line-added"> 905 B3::Type AirIRGenerator::toB3ResultType(BlockSignature returnType)</span>
<span class="line-added"> 906 {</span>
<span class="line-added"> 907     if (returnType-&gt;returnsVoid())</span>
<span class="line-added"> 908         return B3::Void;</span>
<span class="line-added"> 909 </span>
<span class="line-added"> 910     if (returnType-&gt;returnCount() == 1)</span>
<span class="line-added"> 911         return toB3Type(returnType-&gt;returnType(0));</span>
<span class="line-added"> 912 </span>
<span class="line-added"> 913     auto result = m_tupleMap.ensure(returnType, [&amp;] {</span>
<span class="line-added"> 914         Vector&lt;B3::Type&gt; result;</span>
<span class="line-added"> 915         for (unsigned i = 0; i &lt; returnType-&gt;returnCount(); ++i)</span>
<span class="line-added"> 916             result.append(toB3Type(returnType-&gt;returnType(i)));</span>
<span class="line-added"> 917         return m_proc.addTuple(WTFMove(result));</span>
<span class="line-added"> 918     });</span>
<span class="line-added"> 919     return result.iterator-&gt;value;</span>
 920 }
 921 
 922 void AirIRGenerator::restoreWebAssemblyGlobalState(RestoreCachedStackLimit restoreCachedStackLimit, const MemoryInformation&amp; memory, TypedTmp instance, BasicBlock* block)
 923 {
 924     restoreWasmContextInstance(block, instance);
 925 
 926     if (restoreCachedStackLimit == RestoreCachedStackLimit::Yes) {
 927         // The Instance caches the stack limit, but also knows where its canonical location is.
 928         static_assert(sizeof(decltype(static_cast&lt;Instance*&gt;(nullptr)-&gt;cachedStackLimit())) == sizeof(uint64_t), &quot;&quot;);
 929 
 930         RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfPointerToActualStackLimit(), B3::Width64));
 931         RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfCachedStackLimit(), B3::Width64));
 932         auto temp = g64();
 933         append(block, Move, Arg::addr(instanceValue(), Instance::offsetOfPointerToActualStackLimit()), temp);
 934         append(block, Move, Arg::addr(temp), temp);
 935         append(block, Move, temp, Arg::addr(instanceValue(), Instance::offsetOfCachedStackLimit()));
 936     }
 937 
 938     if (!!memory) {
 939         const PinnedRegisterInfo* pinnedRegs = &amp;PinnedRegisterInfo::get();
</pre>
<hr />
<pre>
1024     case Type::I64:
1025     case Type::Anyref:
1026     case Type::Funcref:
1027         append(block, Move, Arg::bigImm(value), result);
1028         break;
1029     case Type::F32:
1030     case Type::F64: {
1031         auto tmp = g64();
1032         append(block, Move, Arg::bigImm(value), tmp);
1033         append(block, type == Type::F32 ? Move32ToFloat : Move64ToDouble, tmp, result);
1034         break;
1035     }
1036 
1037     default:
1038         RELEASE_ASSERT_NOT_REACHED();
1039     }
1040 
1041     return result;
1042 }
1043 
<span class="line-added">1044 auto AirIRGenerator::addBottom(BasicBlock* block, Type type) -&gt; ExpressionType</span>
<span class="line-added">1045 {</span>
<span class="line-added">1046     append(block, B3::Air::Oops);</span>
<span class="line-added">1047     return addConstant(type, 0);</span>
<span class="line-added">1048 }</span>
<span class="line-added">1049 </span>
1050 auto AirIRGenerator::addArguments(const Signature&amp; signature) -&gt; PartialResult
1051 {
1052     RELEASE_ASSERT(m_locals.size() == signature.argumentCount()); // We handle arguments in the prologue
1053     return { };
1054 }
1055 
<span class="line-modified">1056 auto AirIRGenerator::addRefIsNull(ExpressionType value, ExpressionType&amp; result) -&gt; PartialResult</span>
1057 {
1058     ASSERT(value.tmp());
1059     result = tmpForType(Type::I32);
1060     auto tmp = g64();
1061 
1062     append(Move, Arg::bigImm(JSValue::encode(jsNull())), tmp);
1063     append(Compare64, Arg::relCond(MacroAssembler::Equal), value, tmp, result);
1064 
1065     return { };
1066 }
1067 
1068 auto AirIRGenerator::addRefFunc(uint32_t index, ExpressionType&amp; result) -&gt; PartialResult
1069 {
1070     // FIXME: Emit this inline &lt;https://bugs.webkit.org/show_bug.cgi?id=198506&gt;.
1071     result = tmpForType(Type::Funcref);
<span class="line-modified">1072     emitCCall(&amp;operationWasmRefFunc, result, instanceValue(), addConstant(Type::I32, index));</span>
1073 
1074     return { };
1075 }
1076 
<span class="line-modified">1077 auto AirIRGenerator::addTableGet(unsigned tableIndex, ExpressionType index, ExpressionType&amp; result) -&gt; PartialResult</span>
1078 {
1079     // FIXME: Emit this inline &lt;https://bugs.webkit.org/show_bug.cgi?id=198506&gt;.
1080     ASSERT(index.tmp());
1081     ASSERT(index.type() == Type::I32);
1082     result = tmpForType(m_info.tables[tableIndex].wasmType());
1083 
<span class="line-modified">1084     emitCCall(&amp;operationGetWasmTableElement, result, instanceValue(), addConstant(Type::I32, tableIndex), index);</span>
1085     emitCheck([&amp;] {
1086         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::Zero), result, result);
1087     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1088         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTableAccess);
1089     });
1090 
1091     return { };
1092 }
1093 
<span class="line-modified">1094 auto AirIRGenerator::addTableSet(unsigned tableIndex, ExpressionType index, ExpressionType value) -&gt; PartialResult</span>
1095 {
1096     // FIXME: Emit this inline &lt;https://bugs.webkit.org/show_bug.cgi?id=198506&gt;.
1097     ASSERT(index.tmp());
1098     ASSERT(index.type() == Type::I32);
1099     ASSERT(value.tmp());
1100 
1101     auto shouldThrow = g32();
<span class="line-modified">1102     emitCCall(&amp;operationSetWasmTableElement, shouldThrow, instanceValue(), addConstant(Type::I32, tableIndex), index, value);</span>
1103 
1104     emitCheck([&amp;] {
1105         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::Zero), shouldThrow, shouldThrow);
1106     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1107         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTableAccess);
1108     });
1109 
1110     return { };
1111 }
1112 
1113 auto AirIRGenerator::addTableSize(unsigned tableIndex, ExpressionType&amp; result) -&gt; PartialResult
1114 {
1115     // FIXME: Emit this inline &lt;https://bugs.webkit.org/show_bug.cgi?id=198506&gt;.
1116     result = tmpForType(Type::I32);
1117 
<span class="line-modified">1118     emitCCall(&amp;operationGetWasmTableSize, result, instanceValue(), addConstant(Type::I32, tableIndex));</span>




1119 
1120     return { };
1121 }
1122 
<span class="line-modified">1123 auto AirIRGenerator::addTableGrow(unsigned tableIndex, ExpressionType fill, ExpressionType delta, ExpressionType&amp; result) -&gt; PartialResult</span>
1124 {
1125     ASSERT(fill.tmp());
1126     ASSERT(isSubtype(fill.type(), m_info.tables[tableIndex].wasmType()));
1127     ASSERT(delta.tmp());
1128     ASSERT(delta.type() == Type::I32);
1129     result = tmpForType(Type::I32);
1130 
<span class="line-modified">1131     emitCCall(&amp;operationWasmTableGrow, result, instanceValue(), addConstant(Type::I32, tableIndex), fill, delta);</span>
1132 
1133     return { };
1134 }
1135 
<span class="line-modified">1136 auto AirIRGenerator::addTableFill(unsigned tableIndex, ExpressionType offset, ExpressionType fill, ExpressionType count) -&gt; PartialResult</span>
1137 {
1138     ASSERT(fill.tmp());
1139     ASSERT(isSubtype(fill.type(), m_info.tables[tableIndex].wasmType()));
1140     ASSERT(offset.tmp());
1141     ASSERT(offset.type() == Type::I32);
1142     ASSERT(count.tmp());
1143     ASSERT(count.type() == Type::I32);
1144 
1145     auto result = tmpForType(Type::I32);
<span class="line-modified">1146     emitCCall(&amp;operationWasmTableFill, result, instanceValue(), addConstant(Type::I32, tableIndex), offset, fill, count);</span>
1147 
1148     emitCheck([&amp;] {
1149         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::Zero), result, result);
1150     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1151         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTableAccess);
1152     });
1153 
1154     return { };
1155 }
1156 
1157 auto AirIRGenerator::getLocal(uint32_t index, ExpressionType&amp; result) -&gt; PartialResult
1158 {
1159     ASSERT(m_locals[index].tmp());
1160     result = tmpForType(m_locals[index].type());
1161     append(moveOpForValueType(m_locals[index].type()), m_locals[index].tmp(), result);
1162     return { };
1163 }
1164 
1165 auto AirIRGenerator::addUnreachable() -&gt; PartialResult
1166 {
1167     B3::PatchpointValue* unreachable = addPatchpoint(B3::Void);
1168     unreachable-&gt;setGenerator([this] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1169         this-&gt;emitThrowException(jit, ExceptionType::Unreachable);
1170     });
1171     unreachable-&gt;effects.terminal = true;
1172     emitPatchpoint(unreachable, Tmp());
1173     return { };
1174 }
1175 
1176 auto AirIRGenerator::addGrowMemory(ExpressionType delta, ExpressionType&amp; result) -&gt; PartialResult
1177 {





















1178     result = g32();
<span class="line-modified">1179     emitCCall(&amp;operationGrowMemory, result, TypedTmp { Tmp(GPRInfo::callFrameRegister), Type::I64 }, instanceValue(), delta);</span>
1180     restoreWebAssemblyGlobalState(RestoreCachedStackLimit::No, m_info.memory, instanceValue(), m_currentBlock);
1181 
1182     return { };
1183 }
1184 
1185 auto AirIRGenerator::addCurrentMemory(ExpressionType&amp; result) -&gt; PartialResult
1186 {
1187     static_assert(sizeof(decltype(static_cast&lt;Memory*&gt;(nullptr)-&gt;size())) == sizeof(uint64_t), &quot;codegen relies on this size&quot;);
1188 
1189     auto temp1 = g64();
1190     auto temp2 = g64();
1191 
1192     RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfCachedMemorySize(), B3::Width64));
1193     append(Move, Arg::addr(instanceValue(), Instance::offsetOfCachedMemorySize()), temp1);
1194     constexpr uint32_t shiftValue = 16;
1195     static_assert(PageCount::pageSize == 1ull &lt;&lt; shiftValue, &quot;This must hold for the code below to be correct.&quot;);
1196     append(Move, Arg::imm(16), temp2);
1197     addShift(Type::I32, Urshift64, temp1, temp2, result);
1198     append(Move32, result, result);
1199 
1200     return { };
1201 }
1202 
1203 auto AirIRGenerator::setLocal(uint32_t index, ExpressionType value) -&gt; PartialResult
1204 {
1205     ASSERT(m_locals[index].tmp());
1206     append(moveOpForValueType(m_locals[index].type()), value, m_locals[index].tmp());
1207     return { };
1208 }
1209 
1210 auto AirIRGenerator::getGlobal(uint32_t index, ExpressionType&amp; result) -&gt; PartialResult
1211 {
<span class="line-modified">1212     const Wasm::GlobalInformation&amp; global = m_info.globals[index];</span>
<span class="line-added">1213     Type type = global.type;</span>
1214 
1215     result = tmpForType(type);
1216 
1217     auto temp = g64();
1218 
1219     RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfGlobals(), B3::Width64));
1220     append(Move, Arg::addr(instanceValue(), Instance::offsetOfGlobals()), temp);
1221 
1222     int32_t offset = safeCast&lt;int32_t&gt;(index * sizeof(Register));
<span class="line-modified">1223     switch (global.bindingMode) {</span>
<span class="line-modified">1224     case Wasm::GlobalInformation::BindingMode::EmbeddedInInstance:</span>
<span class="line-modified">1225         if (Arg::isValidAddrForm(offset, B3::widthForType(toB3Type(type))))</span>
<span class="line-modified">1226             append(moveOpForValueType(type), Arg::addr(temp, offset), result);</span>
<span class="line-modified">1227         else {</span>
<span class="line-modified">1228             auto temp2 = g64();</span>
<span class="line-added">1229             append(Move, Arg::bigImm(offset), temp2);</span>
<span class="line-added">1230             append(Add64, temp2, temp, temp);</span>
<span class="line-added">1231             append(moveOpForValueType(type), Arg::addr(temp), result);</span>
<span class="line-added">1232         }</span>
<span class="line-added">1233         break;</span>
<span class="line-added">1234     case Wasm::GlobalInformation::BindingMode::Portable:</span>
<span class="line-added">1235         ASSERT(global.mutability == Wasm::GlobalInformation::Mutability::Mutable);</span>
<span class="line-added">1236         if (Arg::isValidAddrForm(offset, B3::Width64))</span>
<span class="line-added">1237             append(Move, Arg::addr(temp, offset), temp);</span>
<span class="line-added">1238         else {</span>
<span class="line-added">1239             auto temp2 = g64();</span>
<span class="line-added">1240             append(Move, Arg::bigImm(offset), temp2);</span>
<span class="line-added">1241             append(Add64, temp2, temp, temp);</span>
<span class="line-added">1242             append(Move, Arg::addr(temp), temp);</span>
<span class="line-added">1243         }</span>
1244         append(moveOpForValueType(type), Arg::addr(temp), result);
<span class="line-added">1245         break;</span>
1246     }
1247     return { };
1248 }
1249 
1250 auto AirIRGenerator::setGlobal(uint32_t index, ExpressionType value) -&gt; PartialResult
1251 {
1252     auto temp = g64();
1253 
1254     RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfGlobals(), B3::Width64));
1255     append(Move, Arg::addr(instanceValue(), Instance::offsetOfGlobals()), temp);
1256 
<span class="line-modified">1257     const Wasm::GlobalInformation&amp; global = m_info.globals[index];</span>
<span class="line-added">1258     Type type = global.type;</span>
1259 
1260     int32_t offset = safeCast&lt;int32_t&gt;(index * sizeof(Register));
<span class="line-modified">1261     switch (global.bindingMode) {</span>
<span class="line-modified">1262     case Wasm::GlobalInformation::BindingMode::EmbeddedInInstance:</span>
<span class="line-modified">1263         if (Arg::isValidAddrForm(offset, B3::widthForType(toB3Type(type))))</span>
<span class="line-modified">1264             append(moveOpForValueType(type), value, Arg::addr(temp, offset));</span>
<span class="line-modified">1265         else {</span>
<span class="line-modified">1266             auto temp2 = g64();</span>
<span class="line-added">1267             append(Move, Arg::bigImm(offset), temp2);</span>
<span class="line-added">1268             append(Add64, temp2, temp, temp);</span>
<span class="line-added">1269             append(moveOpForValueType(type), value, Arg::addr(temp));</span>
<span class="line-added">1270         }</span>
<span class="line-added">1271         if (isSubtype(type, Anyref))</span>
<span class="line-added">1272             emitWriteBarrierForJSWrapper();</span>
<span class="line-added">1273         break;</span>
<span class="line-added">1274     case Wasm::GlobalInformation::BindingMode::Portable:</span>
<span class="line-added">1275         ASSERT(global.mutability == Wasm::GlobalInformation::Mutability::Mutable);</span>
<span class="line-added">1276         if (Arg::isValidAddrForm(offset, B3::Width64))</span>
<span class="line-added">1277             append(Move, Arg::addr(temp, offset), temp);</span>
<span class="line-added">1278         else {</span>
<span class="line-added">1279             auto temp2 = g64();</span>
<span class="line-added">1280             append(Move, Arg::bigImm(offset), temp2);</span>
<span class="line-added">1281             append(Add64, temp2, temp, temp);</span>
<span class="line-added">1282             append(Move, Arg::addr(temp), temp);</span>
<span class="line-added">1283         }</span>
1284         append(moveOpForValueType(type), value, Arg::addr(temp));
<span class="line-modified">1285         // We emit a write-barrier onto JSWebAssemblyGlobal, not JSWebAssemblyInstance.</span>
<span class="line-added">1286         if (isSubtype(type, Anyref)) {</span>
<span class="line-added">1287             auto cell = g64();</span>
<span class="line-added">1288             auto vm = g64();</span>
<span class="line-added">1289             auto cellState = g32();</span>
<span class="line-added">1290             auto threshold = g32();</span>
<span class="line-added">1291 </span>
<span class="line-added">1292             BasicBlock* fenceCheckPath = m_code.addBlock();</span>
<span class="line-added">1293             BasicBlock* fencePath = m_code.addBlock();</span>
<span class="line-added">1294             BasicBlock* doSlowPath = m_code.addBlock();</span>
<span class="line-added">1295             BasicBlock* continuation = m_code.addBlock();</span>
<span class="line-added">1296 </span>
<span class="line-added">1297             append(Move, Arg::addr(instanceValue(), Instance::offsetOfOwner()), cell);</span>
<span class="line-added">1298             append(Move, Arg::addr(cell, JSWebAssemblyInstance::offsetOfVM()), vm);</span>
<span class="line-added">1299 </span>
<span class="line-added">1300             append(Move, Arg::addr(temp, Wasm::Global::offsetOfOwner() - Wasm::Global::offsetOfValue()), cell);</span>
<span class="line-added">1301             append(Load8, Arg::addr(cell, JSCell::cellStateOffset()), cellState);</span>
<span class="line-added">1302             append(Move32, Arg::addr(vm, VM::offsetOfHeapBarrierThreshold()), threshold);</span>
<span class="line-added">1303 </span>
<span class="line-added">1304             append(Branch32, Arg::relCond(MacroAssembler::Above), cellState, threshold);</span>
<span class="line-added">1305             m_currentBlock-&gt;setSuccessors(continuation, fenceCheckPath);</span>
<span class="line-added">1306             m_currentBlock = fenceCheckPath;</span>
<span class="line-added">1307 </span>
<span class="line-added">1308             append(Load8, Arg::addr(vm, VM::offsetOfHeapMutatorShouldBeFenced()), threshold);</span>
<span class="line-added">1309             append(BranchTest32, Arg::resCond(MacroAssembler::Zero), threshold, threshold);</span>
<span class="line-added">1310             m_currentBlock-&gt;setSuccessors(doSlowPath, fencePath);</span>
<span class="line-added">1311             m_currentBlock = fencePath;</span>
<span class="line-added">1312 </span>
<span class="line-added">1313             auto* doFence = addPatchpoint(B3::Void);</span>
<span class="line-added">1314             doFence-&gt;setGenerator([] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {</span>
<span class="line-added">1315                 jit.memoryFence();</span>
<span class="line-added">1316             });</span>
<span class="line-added">1317             emitPatchpoint(doFence, Tmp());</span>
<span class="line-added">1318 </span>
<span class="line-added">1319             append(Load8, Arg::addr(cell, JSCell::cellStateOffset()), cellState);</span>
<span class="line-added">1320             append(Branch32, Arg::relCond(MacroAssembler::Above), cellState, Arg::imm(blackThreshold));</span>
<span class="line-added">1321             m_currentBlock-&gt;setSuccessors(continuation, doSlowPath);</span>
<span class="line-added">1322             m_currentBlock = doSlowPath;</span>
1323 
<span class="line-modified">1324             emitCCall(&amp;operationWasmWriteBarrierSlowPath, TypedTmp(), cell, vm);</span>
<span class="line-modified">1325             append(Jump);</span>
<span class="line-added">1326             m_currentBlock-&gt;setSuccessors(continuation);</span>
<span class="line-added">1327             m_currentBlock = continuation;</span>
<span class="line-added">1328         }</span>
<span class="line-added">1329         break;</span>
<span class="line-added">1330     }</span>
1331 
1332     return { };
1333 }
1334 
1335 inline void AirIRGenerator::emitWriteBarrierForJSWrapper()
1336 {
1337     auto cell = g64();
1338     auto vm = g64();
1339     auto cellState = g32();
1340     auto threshold = g32();
1341 
1342     BasicBlock* fenceCheckPath = m_code.addBlock();
1343     BasicBlock* fencePath = m_code.addBlock();
1344     BasicBlock* doSlowPath = m_code.addBlock();
1345     BasicBlock* continuation = m_code.addBlock();
1346 
1347     append(Move, Arg::addr(instanceValue(), Instance::offsetOfOwner()), cell);
1348     append(Move, Arg::addr(cell, JSWebAssemblyInstance::offsetOfVM()), vm);
1349     append(Load8, Arg::addr(cell, JSCell::cellStateOffset()), cellState);
1350     append(Move32, Arg::addr(vm, VM::offsetOfHeapBarrierThreshold()), threshold);
</pre>
<hr />
<pre>
1352     append(Branch32, Arg::relCond(MacroAssembler::Above), cellState, threshold);
1353     m_currentBlock-&gt;setSuccessors(continuation, fenceCheckPath);
1354     m_currentBlock = fenceCheckPath;
1355 
1356     append(Load8, Arg::addr(vm, VM::offsetOfHeapMutatorShouldBeFenced()), threshold);
1357     append(BranchTest32, Arg::resCond(MacroAssembler::Zero), threshold, threshold);
1358     m_currentBlock-&gt;setSuccessors(doSlowPath, fencePath);
1359     m_currentBlock = fencePath;
1360 
1361     auto* doFence = addPatchpoint(B3::Void);
1362     doFence-&gt;setGenerator([] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1363         jit.memoryFence();
1364     });
1365     emitPatchpoint(doFence, Tmp());
1366 
1367     append(Load8, Arg::addr(cell, JSCell::cellStateOffset()), cellState);
1368     append(Branch32, Arg::relCond(MacroAssembler::Above), cellState, Arg::imm(blackThreshold));
1369     m_currentBlock-&gt;setSuccessors(continuation, doSlowPath);
1370     m_currentBlock = doSlowPath;
1371 
<span class="line-modified">1372     emitCCall(&amp;operationWasmWriteBarrierSlowPath, TypedTmp(), cell, vm);</span>





1373     append(Jump);
1374     m_currentBlock-&gt;setSuccessors(continuation);
1375     m_currentBlock = continuation;
1376 }
1377 
1378 inline AirIRGenerator::ExpressionType AirIRGenerator::emitCheckAndPreparePointer(ExpressionType pointer, uint32_t offset, uint32_t sizeOfOperation)
1379 {
1380     ASSERT(m_memoryBaseGPR);
1381 
1382     auto result = g64();
1383     append(Move32, pointer, result);
1384 
1385     switch (m_mode) {
1386     case MemoryMode::BoundsChecking: {
1387         // We&#39;re not using signal handling at all, we must therefore check that no memory access exceeds the current memory size.
1388         ASSERT(m_memorySizeGPR);
1389         ASSERT(sizeOfOperation + offset &gt; offset);
1390         auto temp = g64();
1391         append(Move, Arg::bigImm(static_cast&lt;uint64_t&gt;(sizeOfOperation) + offset - 1), temp);
1392         append(Add64, result, temp);
</pre>
<hr />
<pre>
1703 {
1704     ASSERT(nonZero.type() == zero.type());
1705     result = tmpForType(nonZero.type());
1706     append(moveOpForValueType(nonZero.type()), nonZero, result);
1707 
1708     BasicBlock* isZero = m_code.addBlock();
1709     BasicBlock* continuation = m_code.addBlock();
1710 
1711     append(BranchTest32, Arg::resCond(MacroAssembler::Zero), condition, condition);
1712     m_currentBlock-&gt;setSuccessors(isZero, continuation);
1713 
1714     append(isZero, moveOpForValueType(zero.type()), zero, result);
1715     append(isZero, Jump);
1716     isZero-&gt;setSuccessors(continuation);
1717 
1718     m_currentBlock = continuation;
1719 
1720     return { };
1721 }
1722 
<span class="line-modified">1723 void AirIRGenerator::emitEntryTierUpCheck()</span>
1724 {


1725     if (!m_tierUp)
1726         return;
1727 
1728     auto countdownPtr = g64();
1729 
1730     append(Move, Arg::bigImm(reinterpret_cast&lt;uint64_t&gt;(&amp;m_tierUp-&gt;m_counter)), countdownPtr);
1731 
1732     auto* patch = addPatchpoint(B3::Void);
1733     B3::Effects effects = B3::Effects::none();
1734     effects.reads = B3::HeapRange::top();
1735     effects.writes = B3::HeapRange::top();
1736     patch-&gt;effects = effects;
1737     patch-&gt;clobber(RegisterSet::macroScratchRegisters());
1738 
1739     patch-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
1740         AllowMacroScratchRegisterUsage allowScratch(jit);
1741 
<span class="line-modified">1742         CCallHelpers::Jump tierUp = jit.branchAdd32(CCallHelpers::PositiveOrZero, CCallHelpers::TrustedImm32(TierUpCount::functionEntryIncrement()), CCallHelpers::Address(params[0].gpr()));</span>
1743         CCallHelpers::Label tierUpResume = jit.label();
1744 
1745         params.addLatePath([=] (CCallHelpers&amp; jit) {
1746             tierUp.link(&amp;jit);
1747 
1748             const unsigned extraPaddingBytes = 0;
1749             RegisterSet registersToSpill = { };
1750             registersToSpill.add(GPRInfo::argumentGPR1);
1751             unsigned numberOfStackBytesUsedForRegisterPreservation = ScratchRegisterAllocator::preserveRegistersToStackForCall(jit, registersToSpill, extraPaddingBytes);
1752 
1753             jit.move(MacroAssembler::TrustedImm32(m_functionIndex), GPRInfo::argumentGPR1);
1754             MacroAssembler::Call call = jit.nearCall();
1755 
1756             ScratchRegisterAllocator::restoreRegistersFromStackForCall(jit, registersToSpill, RegisterSet(), numberOfStackBytesUsedForRegisterPreservation, extraPaddingBytes);
1757             jit.jump(tierUpResume);
1758 
1759             jit.addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
1760                 MacroAssembler::repatchNearCall(linkBuffer.locationOfNearCall&lt;NoPtrTag&gt;(call), CodeLocationLabel&lt;JITThunkPtrTag&gt;(Thunks::singleton().stub(triggerOMGEntryTierUpThunkGenerator).code()));
1761             });
1762         });
1763     });
1764 
1765     emitPatchpoint(patch, Tmp(), countdownPtr);
1766 }
1767 
<span class="line-modified">1768 void AirIRGenerator::emitLoopTierUpCheck(uint32_t loopIndex, const Stack&amp; enclosingStack)</span>
1769 {
<span class="line-modified">1770     uint32_t outerLoopIndex = this-&gt;outerLoopIndex();</span>
<span class="line-added">1771     m_outerLoops.append(loopIndex);</span>
1772 
1773     if (!m_tierUp)
1774         return;
1775 
1776     ASSERT(m_tierUp-&gt;osrEntryTriggers().size() == loopIndex);
1777     m_tierUp-&gt;osrEntryTriggers().append(TierUpCount::TriggerReason::DontTrigger);
1778     m_tierUp-&gt;outerLoops().append(outerLoopIndex);
1779 
1780     auto countdownPtr = g64();
1781 
1782     append(Move, Arg::bigImm(reinterpret_cast&lt;uint64_t&gt;(&amp;m_tierUp-&gt;m_counter)), countdownPtr);
1783 
1784     auto* patch = addPatchpoint(B3::Void);
1785     B3::Effects effects = B3::Effects::none();
1786     effects.reads = B3::HeapRange::top();
1787     effects.writes = B3::HeapRange::top();
1788     effects.exitsSideways = true;
1789     patch-&gt;effects = effects;
1790 
1791     patch-&gt;clobber(RegisterSet::macroScratchRegisters());
1792     RegisterSet clobberLate;
1793     clobberLate.add(GPRInfo::argumentGPR0);
1794     patch-&gt;clobberLate(clobberLate);
1795 
1796     Vector&lt;ConstrainedTmp&gt; patchArgs;
1797     patchArgs.append(countdownPtr);
1798 
<span class="line-modified">1799     for (auto&amp; local : m_locals)</span>

1800         patchArgs.append(ConstrainedTmp(local, B3::ValueRep::ColdAny));
<span class="line-modified">1801     for (unsigned controlIndex = 0; controlIndex &lt; m_parser-&gt;controlStack().size(); ++controlIndex) {</span>
<span class="line-modified">1802         Stack&amp; expressionStack = m_parser-&gt;controlStack()[controlIndex].enclosedExpressionStack;</span>
<span class="line-modified">1803         for (TypedExpression value : expressionStack)</span>
<span class="line-modified">1804             patchArgs.append(ConstrainedTmp(value.value(), B3::ValueRep::ColdAny));</span>

1805     }
<span class="line-added">1806     for (TypedExpression value : enclosingStack)</span>
<span class="line-added">1807         patchArgs.append(ConstrainedTmp(value.value(), B3::ValueRep::ColdAny));</span>
1808 
1809     TierUpCount::TriggerReason* forceEntryTrigger = &amp;(m_tierUp-&gt;osrEntryTriggers().last());
1810     static_assert(!static_cast&lt;uint8_t&gt;(TierUpCount::TriggerReason::DontTrigger), &quot;the JIT code assumes non-zero means &#39;enter&#39;&quot;);
1811     static_assert(sizeof(TierUpCount::TriggerReason) == 1, &quot;branchTest8 assumes this size&quot;);
1812     patch-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
1813         AllowMacroScratchRegisterUsage allowScratch(jit);
1814         CCallHelpers::Jump forceOSREntry = jit.branchTest8(CCallHelpers::NonZero, CCallHelpers::AbsoluteAddress(forceEntryTrigger));
<span class="line-modified">1815         CCallHelpers::Jump tierUp = jit.branchAdd32(CCallHelpers::PositiveOrZero, CCallHelpers::TrustedImm32(TierUpCount::loopIncrement()), CCallHelpers::Address(params[0].gpr()));</span>
1816         MacroAssembler::Label tierUpResume = jit.label();
1817 
1818         OSREntryData&amp; osrEntryData = m_tierUp-&gt;addOSREntryData(m_functionIndex, loopIndex);
<span class="line-modified">1819         // First argument is the countdown location.</span>
<span class="line-modified">1820         for (unsigned index = 1; index &lt; params.value()-&gt;numChildren(); ++index)</span>
<span class="line-added">1821             osrEntryData.values().constructAndAppend(params[index], params.value()-&gt;child(index)-&gt;type());</span>
1822         OSREntryData* osrEntryDataPtr = &amp;osrEntryData;
1823 
1824         params.addLatePath([=] (CCallHelpers&amp; jit) {
1825             AllowMacroScratchRegisterUsage allowScratch(jit);
1826             forceOSREntry.link(&amp;jit);
1827             tierUp.link(&amp;jit);
1828 
<span class="line-modified">1829             jit.probe(operationWasmTriggerOSREntryNow, osrEntryDataPtr);</span>
1830             jit.branchTestPtr(CCallHelpers::Zero, GPRInfo::argumentGPR0).linkTo(tierUpResume, &amp;jit);
1831             jit.farJump(GPRInfo::argumentGPR1, WasmEntryPtrTag);
1832         });
1833     });
1834 
<span class="line-modified">1835     emitPatchpoint(m_currentBlock, patch, ResultList { }, WTFMove(patchArgs));</span>
1836 }
1837 
<span class="line-modified">1838 AirIRGenerator::ControlData AirIRGenerator::addTopLevel(BlockSignature signature)</span>
<span class="line-added">1839 {</span>
<span class="line-added">1840     return ControlData(B3::Origin(), signature, tmpsForSignature(signature), BlockType::TopLevel, m_code.addBlock());</span>
<span class="line-added">1841 }</span>
<span class="line-added">1842 </span>
<span class="line-added">1843 auto AirIRGenerator::addLoop(BlockSignature signature, Stack&amp; enclosingStack, ControlType&amp; block, Stack&amp; newStack, uint32_t loopIndex) -&gt; PartialResult</span>
1844 {
1845     BasicBlock* body = m_code.addBlock();
1846     BasicBlock* continuation = m_code.addBlock();
1847 
<span class="line-added">1848     splitStack(signature, enclosingStack, newStack);</span>
<span class="line-added">1849     ResultList results;</span>
<span class="line-added">1850     results.reserveInitialCapacity(newStack.size());</span>
<span class="line-added">1851     for (auto item : newStack)</span>
<span class="line-added">1852         results.uncheckedAppend(item);</span>
<span class="line-added">1853     block = ControlData(origin(), signature, WTFMove(results), BlockType::Loop, continuation, body);</span>
<span class="line-added">1854 </span>
1855     append(Jump);
1856     m_currentBlock-&gt;setSuccessors(body);
1857 


1858     m_currentBlock = body;
<span class="line-modified">1859     emitLoopTierUpCheck(loopIndex, enclosingStack);</span>



1860 
<span class="line-modified">1861     return { };</span>


1862 }
1863 
<span class="line-modified">1864 auto AirIRGenerator::addBlock(BlockSignature signature, Stack&amp; enclosingStack, ControlType&amp; newBlock, Stack&amp; newStack) -&gt; PartialResult</span>
1865 {
<span class="line-modified">1866     splitStack(signature, enclosingStack, newStack);</span>
<span class="line-added">1867     newBlock = ControlData(origin(), signature, tmpsForSignature(signature), BlockType::Block, m_code.addBlock());</span>
<span class="line-added">1868     return { };</span>
1869 }
1870 
<span class="line-modified">1871 auto AirIRGenerator::addIf(ExpressionType condition, BlockSignature signature, Stack&amp; enclosingStack, ControlType&amp; result, Stack&amp; newStack) -&gt; PartialResult</span>
1872 {
1873     BasicBlock* taken = m_code.addBlock();
1874     BasicBlock* notTaken = m_code.addBlock();
1875     BasicBlock* continuation = m_code.addBlock();
1876 
1877     // Wasm bools are i32.
1878     append(BranchTest32, Arg::resCond(MacroAssembler::NonZero), condition, condition);
1879     m_currentBlock-&gt;setSuccessors(taken, notTaken);
1880 
1881     m_currentBlock = taken;
<span class="line-modified">1882     splitStack(signature, enclosingStack, newStack);</span>
<span class="line-added">1883     result = ControlData(origin(), signature, tmpsForSignature(signature), BlockType::If, continuation, notTaken);</span>
1884     return { };
1885 }
1886 
1887 auto AirIRGenerator::addElse(ControlData&amp; data, const Stack&amp; currentStack) -&gt; PartialResult
1888 {
<span class="line-modified">1889     unifyValuesWithBlock(currentStack, data.results);</span>
1890     append(Jump);
1891     m_currentBlock-&gt;setSuccessors(data.continuation);
1892     return addElseToUnreachable(data);
1893 }
1894 
1895 auto AirIRGenerator::addElseToUnreachable(ControlData&amp; data) -&gt; PartialResult
1896 {
<span class="line-modified">1897     ASSERT(data.blockType() == BlockType::If);</span>
1898     m_currentBlock = data.special;
1899     data.convertIfToBlock();
1900     return { };
1901 }
1902 
<span class="line-modified">1903 auto AirIRGenerator::addReturn(const ControlData&amp; data, const Stack&amp; returnValues) -&gt; PartialResult</span>
1904 {
<span class="line-modified">1905     CallInformation wasmCallInfo = wasmCallingConvention().callInformationFor(*data.signature(), CallRole::Callee);</span>
<span class="line-modified">1906     if (!wasmCallInfo.results.size()) {</span>

























1907         append(RetVoid);
<span class="line-added">1908         return { };</span>
<span class="line-added">1909     }</span>
<span class="line-added">1910 </span>
<span class="line-added">1911     B3::PatchpointValue* patch = addPatchpoint(B3::Void);</span>
<span class="line-added">1912     patch-&gt;setGenerator([] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {</span>
<span class="line-added">1913         auto calleeSaves = params.code().calleeSaveRegisterAtOffsetList();</span>
<span class="line-added">1914 </span>
<span class="line-added">1915         for (RegisterAtOffset calleeSave : calleeSaves)</span>
<span class="line-added">1916             jit.load64ToReg(CCallHelpers::Address(GPRInfo::callFrameRegister, calleeSave.offset()), calleeSave.reg());</span>
<span class="line-added">1917 </span>
<span class="line-added">1918         jit.emitFunctionEpilogue();</span>
<span class="line-added">1919         jit.ret();</span>
<span class="line-added">1920     });</span>
<span class="line-added">1921     patch-&gt;effects.terminal = true;</span>
<span class="line-added">1922 </span>
<span class="line-added">1923     ASSERT(returnValues.size() &gt;= wasmCallInfo.results.size());</span>
<span class="line-added">1924     unsigned offset = returnValues.size() - wasmCallInfo.results.size();</span>
<span class="line-added">1925     Vector&lt;ConstrainedTmp, 8&gt; returnConstraints;</span>
<span class="line-added">1926     for (unsigned i = 0; i &lt; wasmCallInfo.results.size(); ++i) {</span>
<span class="line-added">1927         B3::ValueRep rep = wasmCallInfo.results[i];</span>
<span class="line-added">1928         TypedTmp tmp = returnValues[offset + i];</span>
<span class="line-added">1929 </span>
<span class="line-added">1930         if (rep.isStack()) {</span>
<span class="line-added">1931             append(moveForType(toB3Type(tmp.type())), tmp, Arg::addr(Tmp(GPRInfo::callFrameRegister), rep.offsetFromFP()));</span>
<span class="line-added">1932             continue;</span>
<span class="line-added">1933         }</span>
<span class="line-added">1934 </span>
<span class="line-added">1935         ASSERT(rep.isReg());</span>
<span class="line-added">1936         if (data.signature()-&gt;returnType(i) == I32)</span>
<span class="line-added">1937             append(Move32, tmp, tmp);</span>
<span class="line-added">1938         returnConstraints.append(ConstrainedTmp(tmp, wasmCallInfo.results[i]));</span>
<span class="line-added">1939     }</span>
<span class="line-added">1940 </span>
<span class="line-added">1941     emitPatchpoint(m_currentBlock, patch, ResultList { }, WTFMove(returnConstraints));</span>
1942     return { };
1943 }
1944 
1945 // NOTE: All branches in Wasm are on 32-bit ints
1946 
1947 auto AirIRGenerator::addBranch(ControlData&amp; data, ExpressionType condition, const Stack&amp; returnValues) -&gt; PartialResult
1948 {
<span class="line-modified">1949     unifyValuesWithBlock(returnValues, data.results);</span>
1950 
1951     BasicBlock* target = data.targetBlockForBranch();
1952     if (condition) {
1953         BasicBlock* continuation = m_code.addBlock();
1954         append(BranchTest32, Arg::resCond(MacroAssembler::NonZero), condition, condition);
1955         m_currentBlock-&gt;setSuccessors(target, continuation);
1956         m_currentBlock = continuation;
1957     } else {
1958         append(Jump);
1959         m_currentBlock-&gt;setSuccessors(target);
1960     }
1961 
1962     return { };
1963 }
1964 
1965 auto AirIRGenerator::addSwitch(ExpressionType condition, const Vector&lt;ControlData*&gt;&amp; targets, ControlData&amp; defaultTarget, const Stack&amp; expressionStack) -&gt; PartialResult
1966 {
1967     auto&amp; successors = m_currentBlock-&gt;successors();
1968     ASSERT(successors.isEmpty());
1969     for (const auto&amp; target : targets) {
<span class="line-modified">1970         unifyValuesWithBlock(expressionStack, target-&gt;results);</span>
1971         successors.append(target-&gt;targetBlockForBranch());
1972     }
<span class="line-modified">1973     unifyValuesWithBlock(expressionStack, defaultTarget.results);</span>
1974     successors.append(defaultTarget.targetBlockForBranch());
1975 
1976     ASSERT(condition.type() == Type::I32);
1977 
1978     // FIXME: We should consider dynamically switching between a jump table
1979     // and a binary switch depending on the number of successors.
1980     // https://bugs.webkit.org/show_bug.cgi?id=194477
1981 
1982     size_t numTargets = targets.size();
1983 
1984     auto* patchpoint = addPatchpoint(B3::Void);
1985     patchpoint-&gt;effects = B3::Effects::none();
1986     patchpoint-&gt;effects.terminal = true;
1987     patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
1988 
1989     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
1990         AllowMacroScratchRegisterUsage allowScratch(jit);
1991 
1992         Vector&lt;int64_t&gt; cases;
1993         cases.reserveInitialCapacity(numTargets);
</pre>
<hr />
<pre>
2012 
2013         Vector&lt;Box&lt;CCallHelpers::Label&gt;&gt; successorLabels = params.successorLabels();
2014         ASSERT(successorLabels.size() == caseJumps.size() + 1);
2015 
2016         params.addLatePath([=, caseJumps = WTFMove(caseJumps), successorLabels = WTFMove(successorLabels)] (CCallHelpers&amp; jit) {
2017             for (size_t i = 0; i &lt; numTargets; ++i)
2018                 caseJumps[i].linkTo(*successorLabels[i], &amp;jit);
2019             fallThrough.linkTo(*successorLabels[numTargets], &amp;jit);
2020         });
2021     });
2022 
2023     emitPatchpoint(patchpoint, TypedTmp(), condition);
2024 
2025     return { };
2026 }
2027 
2028 auto AirIRGenerator::endBlock(ControlEntry&amp; entry, Stack&amp; expressionStack) -&gt; PartialResult
2029 {
2030     ControlData&amp; data = entry.controlData;
2031 
<span class="line-modified">2032     if (data.blockType() != BlockType::Loop)</span>
<span class="line-added">2033         unifyValuesWithBlock(expressionStack, data.results);</span>
2034     append(Jump);
2035     m_currentBlock-&gt;setSuccessors(data.continuation);
2036 
<span class="line-modified">2037     return addEndToUnreachable(entry, expressionStack);</span>
2038 }
2039 
2040 
<span class="line-modified">2041 auto AirIRGenerator::addEndToUnreachable(ControlEntry&amp; entry, const Stack&amp; expressionStack) -&gt; PartialResult</span>
2042 {
2043     ControlData&amp; data = entry.controlData;
2044     m_currentBlock = data.continuation;
2045 
<span class="line-modified">2046     if (data.blockType() == BlockType::If) {</span>
2047         append(data.special, Jump);
2048         data.special-&gt;setSuccessors(m_currentBlock);
2049     }
2050 
<span class="line-modified">2051     if (data.blockType() == BlockType::Loop) {</span>
2052         m_outerLoops.removeLast();
<span class="line-modified">2053         for (unsigned i = 0; i &lt; data.signature()-&gt;returnCount(); ++i) {</span>
<span class="line-modified">2054             if (i &lt; expressionStack.size())</span>
<span class="line-modified">2055                 entry.enclosedExpressionStack.append(expressionStack[i]);</span>
<span class="line-added">2056             else {</span>
<span class="line-added">2057                 Type type = data.signature()-&gt;returnType(i);</span>
<span class="line-added">2058                 entry.enclosedExpressionStack.constructAndAppend(type, addBottom(m_currentBlock, type));</span>
<span class="line-added">2059             }</span>
<span class="line-added">2060         }</span>
<span class="line-added">2061     } else {</span>
<span class="line-added">2062         for (unsigned i = 0; i &lt; data.signature()-&gt;returnCount(); ++i)</span>
<span class="line-added">2063             entry.enclosedExpressionStack.constructAndAppend(data.signature()-&gt;returnType(i), data.results[i]);</span>
<span class="line-added">2064     }</span>
2065 
2066     // TopLevel does not have any code after this so we need to make sure we emit a return here.
<span class="line-modified">2067     if (data.blockType() == BlockType::TopLevel)</span>
2068         return addReturn(data, entry.enclosedExpressionStack);
2069 
2070     return { };
2071 }
2072 
<span class="line-modified">2073 B3::PatchpointValue* AirIRGenerator::emitCallPatchpoint(BasicBlock* block, const Signature&amp; signature, const ResultList&amp; results, const Vector&lt;TypedTmp&gt;&amp; args, Vector&lt;ConstrainedTmp&gt;&amp;&amp; patchArgs)</span>
<span class="line-added">2074 {</span>
<span class="line-added">2075     auto* patchpoint = addPatchpoint(toB3ResultType(&amp;signature));</span>
<span class="line-added">2076     patchpoint-&gt;effects.writesPinned = true;</span>
<span class="line-added">2077     patchpoint-&gt;effects.readsPinned = true;</span>
<span class="line-added">2078     patchpoint-&gt;clobberEarly(RegisterSet::macroScratchRegisters());</span>
<span class="line-added">2079     patchpoint-&gt;clobberLate(RegisterSet::volatileRegistersForJSCall());</span>
<span class="line-added">2080 </span>
<span class="line-added">2081     CallInformation locations = wasmCallingConvention().callInformationFor(signature);</span>
<span class="line-added">2082     m_code.requestCallArgAreaSizeInBytes(WTF::roundUpToMultipleOf(stackAlignmentBytes(), locations.headerAndArgumentStackSizeInBytes));</span>
<span class="line-added">2083 </span>
<span class="line-added">2084     size_t offset = patchArgs.size();</span>
<span class="line-added">2085     Checked&lt;size_t&gt; newSize = checkedSum&lt;size_t&gt;(patchArgs.size(), args.size());</span>
<span class="line-added">2086     RELEASE_ASSERT(!newSize.hasOverflowed());</span>
<span class="line-added">2087 </span>
<span class="line-added">2088     patchArgs.grow(newSize.unsafeGet());</span>
<span class="line-added">2089     for (unsigned i = 0; i &lt; args.size(); ++i)</span>
<span class="line-added">2090         patchArgs[i + offset] = ConstrainedTmp(args[i], locations.params[i]);</span>
<span class="line-added">2091 </span>
<span class="line-added">2092     if (patchpoint-&gt;type() != B3::Void)</span>
<span class="line-added">2093         patchpoint-&gt;resultConstraints = WTFMove(locations.results);</span>
<span class="line-added">2094     emitPatchpoint(block, patchpoint, results, WTFMove(patchArgs));</span>
<span class="line-added">2095     return patchpoint;</span>
<span class="line-added">2096 }</span>
<span class="line-added">2097 </span>
<span class="line-added">2098 auto AirIRGenerator::addCall(uint32_t functionIndex, const Signature&amp; signature, Vector&lt;ExpressionType&gt;&amp; args, ResultList&amp; results) -&gt; PartialResult</span>
2099 {
2100     ASSERT(signature.argumentCount() == args.size());
2101 
2102     m_makesCalls = true;
2103 
<span class="line-modified">2104     for (unsigned i = 0; i &lt; signature.returnCount(); ++i)</span>
<span class="line-modified">2105         results.append(tmpForType(signature.returnType(i)));</span>

2106 
2107     Vector&lt;UnlinkedWasmToWasmCall&gt;* unlinkedWasmToWasmCalls = &amp;m_unlinkedWasmToWasmCalls;
2108 
2109     if (m_info.isImportedFunctionFromFunctionIndexSpace(functionIndex)) {
2110         m_maxNumJSCallArguments = std::max(m_maxNumJSCallArguments, static_cast&lt;uint32_t&gt;(args.size()));
2111 
2112         auto currentInstance = g64();
2113         append(Move, instanceValue(), currentInstance);
2114 
2115         auto targetInstance = g64();
2116 
2117         // FIXME: We should have better isel here.
2118         // https://bugs.webkit.org/show_bug.cgi?id=193999
2119         append(Move, Arg::bigImm(Instance::offsetOfTargetInstance(functionIndex)), targetInstance);
2120         append(Add64, instanceValue(), targetInstance);
2121         append(Move, Arg::addr(targetInstance), targetInstance);
2122 
2123         BasicBlock* isWasmBlock = m_code.addBlock();
2124         BasicBlock* isEmbedderBlock = m_code.addBlock();
2125         BasicBlock* continuation = m_code.addBlock();
2126 
2127         append(BranchTest64, Arg::resCond(MacroAssembler::NonZero), targetInstance, targetInstance);
2128         m_currentBlock-&gt;setSuccessors(isWasmBlock, isEmbedderBlock);
2129 
2130         {
<span class="line-modified">2131             auto* patchpoint = emitCallPatchpoint(isWasmBlock, signature, results, args);</span>


2132             // We need to clobber all potential pinned registers since we might be leaving the instance.
2133             // We pessimistically assume we could be calling to something that is bounds checking.
2134             // FIXME: We shouldn&#39;t have to do this: https://bugs.webkit.org/show_bug.cgi?id=172181
2135             patchpoint-&gt;clobberLate(PinnedRegisterInfo::get().toSave(MemoryMode::BoundsChecking));
2136 





2137             patchpoint-&gt;setGenerator([unlinkedWasmToWasmCalls, functionIndex] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2138                 AllowMacroScratchRegisterUsage allowScratch(jit);
2139                 CCallHelpers::Call call = jit.threadSafePatchableNearCall();
2140                 jit.addLinkTask([unlinkedWasmToWasmCalls, call, functionIndex] (LinkBuffer&amp; linkBuffer) {
2141                     unlinkedWasmToWasmCalls-&gt;append({ linkBuffer.locationOfNearCall&lt;WasmEntryPtrTag&gt;(call), functionIndex });
2142                 });
2143             });
2144 

2145             append(isWasmBlock, Jump);
2146             isWasmBlock-&gt;setSuccessors(continuation);
2147         }
2148 
2149         {
2150             auto jumpDestination = g64();
2151             append(isEmbedderBlock, Move, Arg::bigImm(Instance::offsetOfWasmToEmbedderStub(functionIndex)), jumpDestination);
2152             append(isEmbedderBlock, Add64, instanceValue(), jumpDestination);
2153             append(isEmbedderBlock, Move, Arg::addr(jumpDestination), jumpDestination);
2154 
<span class="line-modified">2155             Vector&lt;ConstrainedTmp&gt; jumpArgs;</span>
<span class="line-modified">2156             jumpArgs.append({ jumpDestination, B3::ValueRep::SomeRegister });</span>
<span class="line-modified">2157             auto* patchpoint = emitCallPatchpoint(isEmbedderBlock, signature, results, args, WTFMove(jumpArgs));</span>
2158             // We need to clobber all potential pinned registers since we might be leaving the instance.
2159             // We pessimistically assume we could be calling to something that is bounds checking.
2160             // FIXME: We shouldn&#39;t have to do this: https://bugs.webkit.org/show_bug.cgi?id=172181
2161             patchpoint-&gt;clobberLate(PinnedRegisterInfo::get().toSave(MemoryMode::BoundsChecking));
<span class="line-modified">2162             patchpoint-&gt;setGenerator([] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {</span>








2163                 AllowMacroScratchRegisterUsage allowScratch(jit);
<span class="line-modified">2164                 jit.call(params[params.proc().resultCount(params.value()-&gt;type())].gpr(), WasmEntryPtrTag);</span>
2165             });
2166 

2167             append(isEmbedderBlock, Jump);
2168             isEmbedderBlock-&gt;setSuccessors(continuation);
2169         }
2170 
2171         m_currentBlock = continuation;
2172         // The call could have been to another WebAssembly instance, and / or could have modified our Memory.
2173         restoreWebAssemblyGlobalState(RestoreCachedStackLimit::Yes, m_info.memory, currentInstance, continuation);
2174     } else {
<span class="line-modified">2175         auto* patchpoint = emitCallPatchpoint(m_currentBlock, signature, results, args);</span>
<span class="line-modified">2176         // We need to clobber the size register since the LLInt always bounds checks</span>
<span class="line-modified">2177         if (m_mode == MemoryMode::Signaling)</span>
<span class="line-modified">2178             patchpoint-&gt;clobberLate(RegisterSet { PinnedRegisterInfo::get().sizeRegister });</span>





2179         patchpoint-&gt;setGenerator([unlinkedWasmToWasmCalls, functionIndex] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2180             AllowMacroScratchRegisterUsage allowScratch(jit);
2181             CCallHelpers::Call call = jit.threadSafePatchableNearCall();
2182             jit.addLinkTask([unlinkedWasmToWasmCalls, call, functionIndex] (LinkBuffer&amp; linkBuffer) {
2183                 unlinkedWasmToWasmCalls-&gt;append({ linkBuffer.locationOfNearCall&lt;WasmEntryPtrTag&gt;(call), functionIndex });
2184             });
2185         });


2186     }
2187 
2188     return { };
2189 }
2190 
<span class="line-modified">2191 auto AirIRGenerator::addCallIndirect(unsigned tableIndex, const Signature&amp; signature, Vector&lt;ExpressionType&gt;&amp; args, ResultList&amp; results) -&gt; PartialResult</span>
2192 {
2193     ExpressionType calleeIndex = args.takeLast();
2194     ASSERT(signature.argumentCount() == args.size());
2195     ASSERT(m_info.tableCount() &gt; tableIndex);
2196     ASSERT(m_info.tables[tableIndex].type() == TableElementType::Funcref);
2197 
2198     m_makesCalls = true;
2199     // Note: call indirect can call either WebAssemblyFunction or WebAssemblyWrapperFunction. Because
2200     // WebAssemblyWrapperFunction is like calling into the embedder, we conservatively assume all call indirects
2201     // can be to the embedder for our stack check calculation.
2202     m_maxNumJSCallArguments = std::max(m_maxNumJSCallArguments, static_cast&lt;uint32_t&gt;(args.size()));
2203 
2204     auto currentInstance = g64();
2205     append(Move, instanceValue(), currentInstance);
2206 
2207     ExpressionType callableFunctionBuffer = g64();
2208     ExpressionType instancesBuffer = g64();
2209     ExpressionType callableFunctionBufferLength = g64();
2210     {
2211         RELEASE_ASSERT(Arg::isValidAddrForm(FuncRefTable::offsetOfFunctions(), B3::Width64));
</pre>
<hr />
<pre>
2300             // FIXME: We should support more than one memory size register
2301             //   see: https://bugs.webkit.org/show_bug.cgi?id=162952
2302             ASSERT(pinnedRegs.sizeRegister != newContextInstance);
2303             GPRReg scratchOrSize = Gigacage::isEnabled(Gigacage::Primitive) ? params.gpScratch(0) : pinnedRegs.sizeRegister;
2304 
2305             jit.loadPtr(CCallHelpers::Address(newContextInstance, Instance::offsetOfCachedMemorySize()), pinnedRegs.sizeRegister); // Memory size.
2306             jit.loadPtr(CCallHelpers::Address(newContextInstance, Instance::offsetOfCachedMemory()), baseMemory); // Memory::void*.
2307 
2308             jit.cageConditionally(Gigacage::Primitive, baseMemory, pinnedRegs.sizeRegister, scratchOrSize);
2309         });
2310 
2311         emitPatchpoint(doContextSwitch, patchpoint, Tmp(), newContextInstance, instanceValue());
2312         append(doContextSwitch, Jump);
2313         doContextSwitch-&gt;setSuccessors(continuation);
2314 
2315         m_currentBlock = continuation;
2316     }
2317 
2318     append(Move, Arg::addr(calleeCode), calleeCode);
2319 
<span class="line-modified">2320     Vector&lt;ConstrainedTmp&gt; extraArgs;</span>
<span class="line-modified">2321     extraArgs.append(calleeCode);</span>
<span class="line-modified">2322 </span>
<span class="line-added">2323     for (unsigned i = 0; i &lt; signature.returnCount(); ++i)</span>
<span class="line-added">2324         results.append(tmpForType(signature.returnType(i)));</span>
<span class="line-added">2325 </span>
<span class="line-added">2326     auto* patchpoint = emitCallPatchpoint(m_currentBlock, signature, results, args, WTFMove(extraArgs));</span>
2327 



2328     // We need to clobber all potential pinned registers since we might be leaving the instance.
2329     // We pessimistically assume we&#39;re always calling something that is bounds checking so
2330     // because the wasm-&gt;wasm thunk unconditionally overrides the size registers.
2331     // FIXME: We should not have to do this, but the wasm-&gt;wasm stub assumes it can
2332     // use all the pinned registers as scratch: https://bugs.webkit.org/show_bug.cgi?id=172181

2333 
<span class="line-modified">2334     patchpoint-&gt;clobberLate(PinnedRegisterInfo::get().toSave(MemoryMode::BoundsChecking));</span>
<span class="line-modified">2335 </span>
<span class="line-modified">2336     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {</span>



2337         AllowMacroScratchRegisterUsage allowScratch(jit);
<span class="line-modified">2338         jit.call(params[params.proc().resultCount(params.value()-&gt;type())].gpr(), WasmEntryPtrTag);</span>
2339     });
2340 


2341     // The call could have been to another WebAssembly instance, and / or could have modified our Memory.
2342     restoreWebAssemblyGlobalState(RestoreCachedStackLimit::Yes, m_info.memory, currentInstance, m_currentBlock);
2343 
2344     return { };
2345 }
2346 
<span class="line-modified">2347 void AirIRGenerator::unify(const ExpressionType dst, const ExpressionType source)</span>
2348 {
2349     ASSERT(isSubtype(source.type(), dst.type()));
2350     append(moveOpForValueType(dst.type()), source, dst);
2351 }
2352 
2353 void AirIRGenerator::unifyValuesWithBlock(const Stack&amp; resultStack, const ResultList&amp; result)
2354 {
2355     ASSERT(result.size() &lt;= resultStack.size());
2356 
2357     for (size_t i = 0; i &lt; result.size(); ++i)
2358         unify(result[result.size() - 1 - i], resultStack[resultStack.size() - 1 - i]);
2359 }
2360 
<span class="line-modified">2361 static void dumpExpressionStack(const CommaPrinter&amp; comma, const AirIRGenerator::Stack&amp; expressionStack)</span>
<span class="line-added">2362 {</span>
<span class="line-added">2363     dataLog(comma, &quot;ExpressionStack:&quot;);</span>
<span class="line-added">2364     for (const auto&amp; expression : expressionStack)</span>
<span class="line-added">2365         dataLog(comma, expression.value());</span>
<span class="line-added">2366 }</span>
<span class="line-added">2367 </span>
<span class="line-added">2368 void AirIRGenerator::dump(const ControlStack&amp; controlStack, const Stack* stack)</span>
2369 {
<span class="line-added">2370     dataLogLn(&quot;Processing Graph:&quot;);</span>
<span class="line-added">2371     dataLog(m_code);</span>
<span class="line-added">2372     dataLogLn(&quot;With current block:&quot;, *m_currentBlock);</span>
<span class="line-added">2373     dataLogLn(&quot;Control stack:&quot;);</span>
<span class="line-added">2374     for (size_t i = controlStack.size(); i--;) {</span>
<span class="line-added">2375         dataLog(&quot;  &quot;, controlStack[i].controlData, &quot;: &quot;);</span>
<span class="line-added">2376         CommaPrinter comma(&quot;, &quot;, &quot;&quot;);</span>
<span class="line-added">2377         dumpExpressionStack(comma, *stack);</span>
<span class="line-added">2378         stack = &amp;controlStack[i].enclosedExpressionStack;</span>
<span class="line-added">2379         dataLogLn();</span>
<span class="line-added">2380     }</span>
<span class="line-added">2381     dataLogLn(&quot;\n&quot;);</span>
2382 }
2383 
2384 auto AirIRGenerator::origin() -&gt; B3::Origin
2385 {
2386     // FIXME: We should implement a way to give Inst&#39;s an origin.
2387     return B3::Origin();
2388 }
2389 
<span class="line-modified">2390 Expected&lt;std::unique_ptr&lt;InternalFunction&gt;, String&gt; parseAndCompileAir(CompilationContext&amp; compilationContext, const FunctionData&amp; function, const Signature&amp; signature, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; unlinkedWasmToWasmCalls, const ModuleInformation&amp; info, MemoryMode mode, uint32_t functionIndex, TierUpCount* tierUp)</span>
2391 {
2392     auto result = makeUnique&lt;InternalFunction&gt;();
2393 
2394     compilationContext.embedderEntrypointJIT = makeUnique&lt;CCallHelpers&gt;();
2395     compilationContext.wasmEntrypointJIT = makeUnique&lt;CCallHelpers&gt;();
2396 
2397     B3::Procedure procedure;
2398     Code&amp; code = procedure.code();
2399 
2400     procedure.setOriginPrinter([] (PrintStream&amp; out, B3::Origin origin) {
2401         if (origin.data())
2402             out.print(&quot;Wasm: &quot;, bitwise_cast&lt;OpcodeOrigin&gt;(origin));
2403     });
2404 
2405     // This means we cannot use either StackmapGenerationParams::usedRegisters() or
2406     // StackmapGenerationParams::unavailableRegisters(). In exchange for this concession, we
2407     // don&#39;t strictly need to run Air::reportUsedRegisters(), which saves a bit of CPU time at
2408     // optLevel=1.
2409     procedure.setNeedsUsedRegisters(false);
2410 
2411     procedure.setOptLevel(Options::webAssemblyBBQAirOptimizationLevel());
2412 
<span class="line-modified">2413     AirIRGenerator irGenerator(info, procedure, result.get(), unlinkedWasmToWasmCalls, mode, functionIndex, tierUp, signature);</span>
<span class="line-modified">2414     FunctionParser&lt;AirIRGenerator&gt; parser(irGenerator, function.data.data(), function.data.size(), signature, info);</span>
2415     WASM_FAIL_IF_HELPER_FAILS(parser.parse());
2416 
2417 
2418     for (BasicBlock* block : code) {
2419         for (size_t i = 0; i &lt; block-&gt;numSuccessors(); ++i)
2420             block-&gt;successorBlock(i)-&gt;addPredecessor(block);
2421     }
2422 
2423     {
2424         if (UNLIKELY(shouldDumpIRAtEachPhase(B3::AirMode))) {
2425             dataLogLn(&quot;Generated patchpoints&quot;);
2426             for (B3::PatchpointValue** patch : irGenerator.patchpoints())
2427                 dataLogLn(deepDump(procedure, *patch));
2428         }
2429 
2430         B3::Air::prepareForGeneration(code);
2431         B3::Air::generate(code, *compilationContext.wasmEntrypointJIT);
2432         compilationContext.wasmEntrypointByproducts = procedure.releaseByproducts();
2433         result-&gt;entrypoint.calleeSaveRegisters = code.calleeSaveRegisterAtOffsetList();
2434     }
</pre>
<hr />
<pre>
2485         B3::Air::Opcode div;
2486         switch (sizeof(IntType)) {
2487         case 4:
2488             div = isSigned ? Div32 : UDiv32;
2489             break;
2490         case 8:
2491             div = isSigned ? Div64 : UDiv64;
2492             break;
2493         }
2494 
2495         append(div, lhs, rhs, result);
2496 
2497         if (!isDiv) {
2498             append(sizeof(IntType) == 4 ? Mul32 : Mul64, result, rhs, result);
2499             append(sizeof(IntType) == 4 ? Sub32 : Sub64, lhs, result, result);
2500         }
2501 
2502         return;
2503     }
2504 
<span class="line-modified">2505 #if CPU(X86_64)</span>
2506     Tmp eax(X86Registers::eax);
2507     Tmp edx(X86Registers::edx);
2508 
2509     if (isSigned) {
2510         B3::Air::Opcode convertToDoubleWord;
2511         B3::Air::Opcode div;
2512         switch (sizeof(IntType)) {
2513         case 4:
2514             convertToDoubleWord = X86ConvertToDoubleWord32;
2515             div = X86Div32;
2516             break;
2517         case 8:
2518             convertToDoubleWord = X86ConvertToQuadWord64;
2519             div = X86Div64;
2520             break;
2521         default:
2522             RELEASE_ASSERT_NOT_REACHED();
2523         }
2524 
2525         // We implement &quot;res = Div&lt;Chill&gt;/Mod&lt;Chill&gt;(num, den)&quot; as follows:
</pre>
<hr />
<pre>
2677     return { };
2678 }
2679 
2680 template&lt;&gt;
2681 auto AirIRGenerator::addOp&lt;OpType::I32Popcnt&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2682 {
2683     result = g32();
2684 
2685 #if CPU(X86_64)
2686     if (MacroAssembler::supportsCountPopulation()) {
2687         auto* patchpoint = addPatchpoint(B3::Int32);
2688         patchpoint-&gt;effects = B3::Effects::none();
2689         patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2690             jit.countPopulation32(params[1].gpr(), params[0].gpr());
2691         });
2692         emitPatchpoint(patchpoint, result, arg);
2693         return { };
2694     }
2695 #endif
2696 
<span class="line-modified">2697     emitCCall(&amp;operationPopcount32, result, arg);</span>

2698     return { };
2699 }
2700 
2701 template&lt;&gt;
2702 auto AirIRGenerator::addOp&lt;OpType::I64Popcnt&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2703 {
2704     result = g64();
2705 
2706 #if CPU(X86_64)
2707     if (MacroAssembler::supportsCountPopulation()) {
2708         auto* patchpoint = addPatchpoint(B3::Int64);
2709         patchpoint-&gt;effects = B3::Effects::none();
2710         patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2711             jit.countPopulation64(params[1].gpr(), params[0].gpr());
2712         });
2713         emitPatchpoint(patchpoint, result, arg);
2714         return { };
2715     }
2716 #endif
2717 
<span class="line-modified">2718     emitCCall(&amp;operationPopcount64, result, arg);</span>

2719     return { };
2720 }
2721 
2722 template&lt;&gt;
2723 auto AirIRGenerator::addOp&lt;F64ConvertUI64&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2724 {
2725     auto* patchpoint = addPatchpoint(B3::Double);
2726     patchpoint-&gt;effects = B3::Effects::none();
2727     if (isX86())
2728         patchpoint-&gt;numGPScratchRegisters = 1;
2729     patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
2730     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2731         AllowMacroScratchRegisterUsage allowScratch(jit);
2732 #if CPU(X86_64)
2733         jit.convertUInt64ToDouble(params[1].gpr(), params[0].fpr(), params.gpScratch(0));
2734 #else
2735         jit.convertUInt64ToDouble(params[1].gpr(), params[0].fpr());
2736 #endif
2737     });
2738     result = f64();
</pre>
<hr />
<pre>
2982     auto* patchpoint = addPatchpoint(B3::Int64);
2983     patchpoint-&gt;effects = B3::Effects::none();
2984     patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
2985     args.append(arg);
2986     if (isX86()) {
2987         args.append(signBitConstant);
2988         patchpoint-&gt;numFPScratchRegisters = 1;
2989     }
2990     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2991         AllowMacroScratchRegisterUsage allowScratch(jit);
2992         FPRReg scratch = InvalidFPRReg;
2993         FPRReg constant = InvalidFPRReg;
2994         if (isX86()) {
2995             scratch = params.fpScratch(0);
2996             constant = params[2].fpr();
2997         }
2998         jit.truncateDoubleToUint64(params[1].fpr(), params[0].gpr(), scratch, constant);
2999     });
3000 
3001     result = g64();
<span class="line-modified">3002     emitPatchpoint(m_currentBlock, patchpoint, Vector&lt;TypedTmp, 8&gt; { result }, WTFMove(args));</span>
3003     return { };
3004 }
3005 
3006 template&lt;&gt;
3007 auto AirIRGenerator::addOp&lt;OpType::I64TruncSF32&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
3008 {
3009     auto max = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(-static_cast&lt;float&gt;(std::numeric_limits&lt;int64_t&gt;::min())));
3010     auto min = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(static_cast&lt;float&gt;(std::numeric_limits&lt;int64_t&gt;::min())));
3011 
3012     auto temp1 = g32();
3013     auto temp2 = g32();
3014     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleLessThanOrUnordered), arg, min, temp1);
3015     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleGreaterThanOrEqualOrUnordered), arg, max, temp2);
3016     append(Or32, temp1, temp2);
3017 
3018     emitCheck([&amp;] {
3019         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::NonZero), temp2, temp2);
3020     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
3021         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTrunc);
3022     });
</pre>
<hr />
<pre>
3039 
3040     auto temp1 = g32();
3041     auto temp2 = g32();
3042     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleLessThanOrEqualOrUnordered), arg, min, temp1);
3043     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleGreaterThanOrEqualOrUnordered), arg, max, temp2);
3044     append(Or32, temp1, temp2);
3045 
3046     emitCheck([&amp;] {
3047         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::NonZero), temp2, temp2);
3048     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
3049         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTrunc);
3050     });
3051 
3052     TypedTmp signBitConstant;
3053     if (isX86())
3054         signBitConstant = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(static_cast&lt;float&gt;(std::numeric_limits&lt;uint64_t&gt;::max() - std::numeric_limits&lt;int64_t&gt;::max())));
3055 
3056     auto* patchpoint = addPatchpoint(B3::Int64);
3057     patchpoint-&gt;effects = B3::Effects::none();
3058     patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
<span class="line-modified">3059     Vector&lt;ConstrainedTmp, 2&gt; args;</span>
3060     args.append(arg);
3061     if (isX86()) {
3062         args.append(signBitConstant);
3063         patchpoint-&gt;numFPScratchRegisters = 1;
3064     }
3065     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
3066         AllowMacroScratchRegisterUsage allowScratch(jit);
3067         FPRReg scratch = InvalidFPRReg;
3068         FPRReg constant = InvalidFPRReg;
3069         if (isX86()) {
3070             scratch = params.fpScratch(0);
3071             constant = params[2].fpr();
3072         }
3073         jit.truncateFloatToUint64(params[1].fpr(), params[0].gpr(), scratch, constant);
3074     });
3075 
3076     result = g64();
<span class="line-modified">3077     emitPatchpoint(m_currentBlock, patchpoint, Vector&lt;TypedTmp, 8&gt; { result }, WTFMove(args));</span>
3078 
3079     return { };
3080 }
3081 
3082 auto AirIRGenerator::addShift(Type type, B3::Air::Opcode op, ExpressionType value, ExpressionType shift, ExpressionType&amp; result) -&gt; PartialResult
3083 {
3084     ASSERT(type == Type::I64 || type == Type::I32);
3085     result = tmpForType(type);
3086 
3087     if (isValidForm(op, Arg::Tmp, Arg::Tmp, Arg::Tmp)) {
3088         append(op, value, shift, result);
3089         return { };
3090     }
3091 
3092 #if CPU(X86_64)
3093     Tmp ecx = Tmp(X86Registers::ecx);
3094     append(Move, value, result);
3095     append(Move, shift, ecx);
3096     append(op, ecx, result);
3097 #else
</pre>
</td>
</tr>
</table>
<center><a href="../tools/VMInspector.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="WasmAirIRGenerator.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>