diff a/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.h b/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.h
--- a/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.h
+++ b/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.h
@@ -28,11 +28,10 @@
 #include "ActiveDOMObject.h"
 #include "AsyncAudioDecoder.h"
 #include "AudioBus.h"
 #include "AudioDestinationNode.h"
 #include "EventTarget.h"
-#include "JSDOMPromiseDeferred.h"
 #include "MediaCanStartListener.h"
 #include "MediaProducer.h"
 #include "PlatformMediaSession.h"
 #include "ScriptExecutionContext.h"
 #include "VisibilityChangeClient.h"
@@ -43,10 +42,11 @@
 #include <wtf/LoggerHelper.h>
 #include <wtf/MainThread.h>
 #include <wtf/RefPtr.h>
 #include <wtf/ThreadSafeRefCounted.h>
 #include <wtf/Threading.h>
+#include <wtf/UniqueRef.h>
 #include <wtf/Vector.h>
 #include <wtf/text/AtomStringHash.h>
 
 namespace WebCore {
 
@@ -62,12 +62,12 @@
 class ConvolverNode;
 class DelayNode;
 class Document;
 class DynamicsCompressorNode;
 class GainNode;
-class GenericEventQueue;
 class HTMLMediaElement;
+class MainThreadGenericEventQueue;
 class MediaElementAudioSourceNode;
 class MediaStream;
 class MediaStreamAudioDestinationNode;
 class MediaStreamAudioSourceNode;
 class OscillatorNode;
@@ -75,10 +75,12 @@
 class PeriodicWave;
 class ScriptProcessorNode;
 class SecurityOrigin;
 class WaveShaperNode;
 
+template<typename IDLType> class DOMPromiseDeferred;
+
 // AudioContext is the cornerstone of the web audio API and all AudioNodes are created from it.
 // For thread safety between the audio thread and the main thread, it has a rendering graph locking mechanism.
 
 class AudioContext
     : public ActiveDOMObject
@@ -122,15 +124,12 @@
     // Asynchronous audio file data decoding.
     void decodeAudioData(Ref<ArrayBuffer>&&, RefPtr<AudioBufferCallback>&&, RefPtr<AudioBufferCallback>&&);
 
     AudioListener* listener() { return m_listener.get(); }
 
-    using ActiveDOMObject::suspend;
-    using ActiveDOMObject::resume;
-
-    void suspend(DOMPromiseDeferred<void>&&);
-    void resume(DOMPromiseDeferred<void>&&);
+    void suspendRendering(DOMPromiseDeferred<void>&&);
+    void resumeRendering(DOMPromiseDeferred<void>&&);
     void close(DOMPromiseDeferred<void>&&);
 
     enum class State { Suspended, Running, Interrupted, Closed };
     State state() const;
     bool isClosed() const { return m_state == State::Closed; }
@@ -290,13 +289,16 @@
     void postTask(WTF::Function<void()>&&);
     bool isStopped() const { return m_isStopScheduled; }
     const SecurityOrigin* origin() const;
     void addConsoleMessage(MessageSource, MessageLevel, const String& message);
 
+    // EventTarget
+    ScriptExecutionContext* scriptExecutionContext() const final;
+
 protected:
     explicit AudioContext(Document&);
-    AudioContext(Document&, unsigned numberOfChannels, size_t numberOfFrames, float sampleRate);
+    AudioContext(Document&, AudioBuffer* renderTarget);
 
     static bool isSampleRateRangeGood(float sampleRate);
     void clearPendingActivity();
     void makePendingActivity();
 
@@ -319,11 +321,10 @@
     void scheduleNodeDeletion();
 
     void mediaCanStart(Document&) override;
 
     // EventTarget
-    ScriptExecutionContext* scriptExecutionContext() const final;
     void dispatchEvent(Event&) final;
 
     // MediaProducer
     MediaProducer::MediaStateFlags mediaState() const override;
     void pageMutedStateDidChange() override;
@@ -334,12 +335,13 @@
     // uniquely connected to.  See the AudioNode::ref() and AudioNode::deref() methods for more details.
     void refNode(AudioNode&);
     void derefNode(AudioNode&);
 
     // ActiveDOMObject API.
+    void suspend(ReasonForSuspension) final;
+    void resume() final;
     void stop() override;
-    bool canSuspendForDocumentSuspension() const override;
     const char* activeDOMObjectName() const override;
 
     // When the context goes away, there might still be some sources which haven't finished playing.
     // Make sure to dereference them here.
     void derefUnfinishedSourceNodes();
@@ -415,11 +417,11 @@
     // Only accessed in the audio thread.
     Vector<AudioNode*> m_deferredFinishDerefList;
     Vector<Vector<DOMPromiseDeferred<void>>> m_stateReactions;
 
     std::unique_ptr<PlatformMediaSession> m_mediaSession;
-    std::unique_ptr<GenericEventQueue> m_eventQueue;
+    UniqueRef<MainThreadGenericEventQueue> m_eventQueue;
 
     RefPtr<AudioBuffer> m_renderTarget;
     RefPtr<AudioDestinationNode> m_destinationNode;
     RefPtr<AudioListener> m_listener;
 
