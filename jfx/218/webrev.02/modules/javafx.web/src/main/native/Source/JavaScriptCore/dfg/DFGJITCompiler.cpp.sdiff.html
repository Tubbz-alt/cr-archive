<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGJITCompiler.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="DFGJITCode.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGJITCompiler.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGJITCompiler.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 43 #include &quot;JSCJSValueInlines.h&quot;
 44 #include &quot;LinkBuffer.h&quot;
 45 #include &quot;MaxFrameExtentForSlowPathCall.h&quot;
 46 #include &quot;StructureStubInfo.h&quot;
 47 #include &quot;ThunkGenerators.h&quot;
 48 #include &quot;VM.h&quot;
 49 
 50 namespace JSC { namespace DFG {
 51 
 52 JITCompiler::JITCompiler(Graph&amp; dfg)
 53     : CCallHelpers(dfg.m_codeBlock)
 54     , m_graph(dfg)
 55     , m_jitCode(adoptRef(new JITCode()))
 56     , m_blockHeads(dfg.numBlocks())
 57     , m_pcToCodeOriginMapBuilder(dfg.m_vm)
 58 {
 59     if (UNLIKELY(shouldDumpDisassembly() || m_graph.m_vm.m_perBytecodeProfiler))
 60         m_disassembler = makeUnique&lt;Disassembler&gt;(dfg);
 61 #if ENABLE(FTL_JIT)
 62     m_jitCode-&gt;tierUpInLoopHierarchy = WTFMove(m_graph.m_plan.tierUpInLoopHierarchy());
<span class="line-modified"> 63     for (unsigned tierUpBytecode : m_graph.m_plan.tierUpAndOSREnterBytecodes())</span>
 64         m_jitCode-&gt;tierUpEntryTriggers.add(tierUpBytecode, JITCode::TriggerReason::DontTrigger);
 65 #endif
 66 }
 67 
 68 JITCompiler::~JITCompiler()
 69 {
 70 }
 71 
 72 void JITCompiler::linkOSRExits()
 73 {
 74     ASSERT(m_jitCode-&gt;osrExit.size() == m_exitCompilationInfo.size());
 75     if (UNLIKELY(m_graph.compilation())) {
 76         for (unsigned i = 0; i &lt; m_jitCode-&gt;osrExit.size(); ++i) {
 77             OSRExitCompilationInfo&amp; info = m_exitCompilationInfo[i];
 78             Vector&lt;Label&gt; labels;
 79             if (!info.m_failureJumps.empty()) {
 80                 for (unsigned j = 0; j &lt; info.m_failureJumps.jumps().size(); ++j)
 81                     labels.append(info.m_failureJumps.jumps()[j].label());
 82             } else
 83                 labels.append(info.m_replacementSource);
 84             m_exitSiteLabels.append(labels);
 85         }
 86     }
 87 
<span class="line-removed"> 88     MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; osrExitThunk = vm().getCTIStub(osrExitThunkGenerator);</span>
<span class="line-removed"> 89     auto osrExitThunkLabel = CodeLocationLabel&lt;JITThunkPtrTag&gt;(osrExitThunk.code());</span>
 90     for (unsigned i = 0; i &lt; m_jitCode-&gt;osrExit.size(); ++i) {
 91         OSRExitCompilationInfo&amp; info = m_exitCompilationInfo[i];
 92         JumpList&amp; failureJumps = info.m_failureJumps;
 93         if (!failureJumps.empty())
 94             failureJumps.link(this);
 95         else
 96             info.m_replacementDestination = label();
 97 
 98         jitAssertHasValidCallFrame();
 99         store32(TrustedImm32(i), &amp;vm().osrExitIndex);
<span class="line-modified">100         if (Options::useProbeOSRExit()) {</span>
<span class="line-removed">101             Jump target = jump();</span>
<span class="line-removed">102             addLinkTask([target, osrExitThunkLabel] (LinkBuffer&amp; linkBuffer) {</span>
<span class="line-removed">103                 linkBuffer.link(target, osrExitThunkLabel);</span>
<span class="line-removed">104             });</span>
<span class="line-removed">105         } else</span>
<span class="line-removed">106             info.m_patchableJump = patchableJump();</span>
107     }
108 }
109 
110 void JITCompiler::compileEntry()
111 {
112     // This code currently matches the old JIT. In the function header we need to
113     // save return address and call frame via the prologue and perform a fast stack check.
114     // FIXME: https://bugs.webkit.org/show_bug.cgi?id=56292
115     // We&#39;ll need to convert the remaining cti_ style calls (specifically the stack
116     // check) which will be dependent on stack layout. (We&#39;d need to account for this in
117     // both normal return code and when jumping to an exception handler).
118     emitFunctionPrologue();
119     emitPutToCallFrameHeader(m_codeBlock, CallFrameSlot::codeBlock);
120 }
121 
122 void JITCompiler::compileSetupRegistersForEntry()
123 {
124     emitSaveCalleeSaves();
125     emitMaterializeTagCheckRegisters();
126 }
</pre>
<hr />
<pre>
132         store8(TrustedImm32(0), &amp;m_jitCode-&gt;neverExecutedEntry);
133 #endif // ENABLE(FTL_JIT)
134 }
135 
136 void JITCompiler::compileBody()
137 {
138     // We generate the speculative code path, followed by OSR exit code to return
139     // to the old JIT code if speculations fail.
140 
141     bool compiledSpeculative = m_speculative-&gt;compile();
142     ASSERT_UNUSED(compiledSpeculative, compiledSpeculative);
143 }
144 
145 void JITCompiler::compileExceptionHandlers()
146 {
147     if (!m_exceptionChecksWithCallFrameRollback.empty()) {
148         m_exceptionChecksWithCallFrameRollback.link(this);
149 
150         copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm().topEntryFrame);
151 
<span class="line-modified">152         // lookupExceptionHandlerFromCallerFrame is passed two arguments, the VM and the exec (the CallFrame*).</span>
153         move(TrustedImmPtr(&amp;vm()), GPRInfo::argumentGPR0);
<span class="line-modified">154         move(GPRInfo::callFrameRegister, GPRInfo::argumentGPR1);</span>
155         addPtr(TrustedImm32(m_graph.stackPointerOffset() * sizeof(Register)), GPRInfo::callFrameRegister, stackPointerRegister);
156 
<span class="line-modified">157 #if CPU(X86)</span>
<span class="line-removed">158         // FIXME: should use the call abstraction, but this is currently in the SpeculativeJIT layer!</span>
<span class="line-removed">159         poke(GPRInfo::argumentGPR0);</span>
<span class="line-removed">160         poke(GPRInfo::argumentGPR1, 1);</span>
<span class="line-removed">161 #endif</span>
<span class="line-removed">162         m_calls.append(CallLinkRecord(call(OperationPtrTag), FunctionPtr&lt;OperationPtrTag&gt;(lookupExceptionHandlerFromCallerFrame)));</span>
163 
164         jumpToExceptionHandler(vm());
165     }
166 
167     if (!m_exceptionChecks.empty()) {
168         m_exceptionChecks.link(this);
169 
170         copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm().topEntryFrame);
171 
<span class="line-modified">172         // lookupExceptionHandler is passed two arguments, the VM and the exec (the CallFrame*).</span>
173         move(TrustedImmPtr(&amp;vm()), GPRInfo::argumentGPR0);
<span class="line-modified">174         move(GPRInfo::callFrameRegister, GPRInfo::argumentGPR1);</span>
175 
<span class="line-modified">176 #if CPU(X86)</span>
<span class="line-removed">177         // FIXME: should use the call abstraction, but this is currently in the SpeculativeJIT layer!</span>
<span class="line-removed">178         poke(GPRInfo::argumentGPR0);</span>
<span class="line-removed">179         poke(GPRInfo::argumentGPR1, 1);</span>
<span class="line-removed">180 #endif</span>
<span class="line-removed">181         m_calls.append(CallLinkRecord(call(OperationPtrTag), FunctionPtr&lt;OperationPtrTag&gt;(lookupExceptionHandler)));</span>
182 
183         jumpToExceptionHandler(vm());
184     }
185 }
186 
187 void JITCompiler::link(LinkBuffer&amp; linkBuffer)
188 {
189     // Link the code, populate data in CodeBlock data structures.
190     m_jitCode-&gt;common.frameRegisterCount = m_graph.frameRegisterCount();
191     m_jitCode-&gt;common.requiredRegisterCountForExit = m_graph.requiredRegisterCountForExit();
192 
193     if (!m_graph.m_plan.inlineCallFrames()-&gt;isEmpty())
194         m_jitCode-&gt;common.inlineCallFrames = m_graph.m_plan.inlineCallFrames();
195 
196 #if USE(JSVALUE32_64)
197     m_jitCode-&gt;common.doubleConstants = WTFMove(m_graph.m_doubleConstants);
198 #endif
199 
200     m_graph.registerFrozenValues();
201 
</pre>
<hr />
<pre>
245 
246         table.ctiDefault = linkBuffer.locationOf&lt;JSSwitchPtrTag&gt;(m_blockHeads[data.fallThrough.block-&gt;index]);
247         StringJumpTable::StringOffsetTable::iterator iter;
248         StringJumpTable::StringOffsetTable::iterator end = table.offsetTable.end();
249         for (iter = table.offsetTable.begin(); iter != end; ++iter)
250             iter-&gt;value.ctiOffset = table.ctiDefault;
251         for (unsigned j = data.cases.size(); j--;) {
252             SwitchCase&amp; myCase = data.cases[j];
253             iter = table.offsetTable.find(myCase.value.stringImpl());
254             RELEASE_ASSERT(iter != end);
255             iter-&gt;value.ctiOffset = linkBuffer.locationOf&lt;JSSwitchPtrTag&gt;(m_blockHeads[myCase.target.block-&gt;index]);
256         }
257     }
258 
259     // Link all calls out from the JIT code to their respective functions.
260     for (unsigned i = 0; i &lt; m_calls.size(); ++i)
261         linkBuffer.link(m_calls[i].m_call, m_calls[i].m_function);
262 
263     finalizeInlineCaches(m_getByIds, linkBuffer);
264     finalizeInlineCaches(m_getByIdsWithThis, linkBuffer);

265     finalizeInlineCaches(m_putByIds, linkBuffer);
266     finalizeInlineCaches(m_inByIds, linkBuffer);
267     finalizeInlineCaches(m_instanceOfs, linkBuffer);
268 
269     auto linkCallThunk = FunctionPtr&lt;NoPtrTag&gt;(vm().getCTIStub(linkCallThunkGenerator).retaggedCode&lt;NoPtrTag&gt;());
270     for (auto&amp; record : m_jsCalls) {
271         CallLinkInfo&amp; info = *record.info;
272         linkBuffer.link(record.slowCall, linkCallThunk);
273         info.setCallLocations(
274             CodeLocationLabel&lt;JSInternalPtrTag&gt;(linkBuffer.locationOfNearCall&lt;JSInternalPtrTag&gt;(record.slowCall)),
275             CodeLocationLabel&lt;JSInternalPtrTag&gt;(linkBuffer.locationOf&lt;JSInternalPtrTag&gt;(record.targetToCheck)),
276             linkBuffer.locationOfNearCall&lt;JSInternalPtrTag&gt;(record.fastCall));
277     }
278 
279     for (JSDirectCallRecord&amp; record : m_jsDirectCalls) {
280         CallLinkInfo&amp; info = *record.info;
281         linkBuffer.link(record.call, linkBuffer.locationOf&lt;NoPtrTag&gt;(record.slowPath));
282         info.setCallLocations(
283             CodeLocationLabel&lt;JSInternalPtrTag&gt;(),
284             linkBuffer.locationOf&lt;JSInternalPtrTag&gt;(record.slowPath),
</pre>
<hr />
<pre>
353 
354     jit.addPtr(MacroAssembler::TrustedImm32(frameTopOffset), GPRInfo::callFrameRegister, GPRInfo::regT1);
355     if (UNLIKELY(maxFrameSize &gt; Options::reservedZoneSize()))
356         stackOverflow.append(jit.branchPtr(MacroAssembler::Above, GPRInfo::regT1, GPRInfo::callFrameRegister));
357     stackOverflow.append(jit.branchPtr(MacroAssembler::Above, MacroAssembler::AbsoluteAddress(jit.vm().addressOfSoftStackLimit()), GPRInfo::regT1));
358 }
359 
360 void JITCompiler::compile()
361 {
362     makeCatchOSREntryBuffer();
363 
364     setStartOfCode();
365     compileEntry();
366     m_speculative = makeUnique&lt;SpeculativeJIT&gt;(*this);
367 
368     // Plant a check that sufficient space is available in the JSStack.
369     JumpList stackOverflow;
370     emitStackOverflowCheck(*this, stackOverflow);
371 
372     addPtr(TrustedImm32(-(m_graph.frameRegisterCount() * sizeof(Register))), GPRInfo::callFrameRegister, stackPointerRegister);
<span class="line-removed">373     if (Options::zeroStackFrame())</span>
<span class="line-removed">374         clearStackFrame(GPRInfo::callFrameRegister, stackPointerRegister, GPRInfo::regT0, m_graph.frameRegisterCount() * sizeof(Register));</span>
375     checkStackPointerAlignment();
376     compileSetupRegistersForEntry();
377     compileEntryExecutionFlag();
378     compileBody();
379     setEndOfMainPath();
380 
381     // === Footer code generation ===
382     //
383     // Generate the stack overflow handling; if the stack check in the entry head fails,
384     // we need to call out to a helper function to throw the StackOverflowError.
385     stackOverflow.link(this);
386 
<span class="line-modified">387     emitStoreCodeOrigin(CodeOrigin(0));</span>
388 
389     if (maxFrameExtentForSlowPathCall)
390         addPtr(TrustedImm32(-static_cast&lt;int32_t&gt;(maxFrameExtentForSlowPathCall)), stackPointerRegister);
391 
392     m_speculative-&gt;callOperationWithCallFrameRollbackOnException(operationThrowStackOverflowError, m_codeBlock);
393 
394     // Generate slow path code.
395     m_speculative-&gt;runSlowPathGenerators(m_pcToCodeOriginMapBuilder);
396     m_pcToCodeOriginMapBuilder.appendItem(labelIgnoringWatchpoints(), PCToCodeOriginMapBuilder::defaultCodeOrigin());
397 
398     compileExceptionHandlers();
399     linkOSRExits();
400 
401     // Create OSR entry trampolines if necessary.
402     m_speculative-&gt;createOSREntries();
403     setEndOfCode();
404 
405     auto linkBuffer = makeUnique&lt;LinkBuffer&gt;(*this, m_codeBlock, JITCompilationCanFail);
406     if (linkBuffer-&gt;didFailToAllocate()) {
407         m_graph.m_plan.setFinalizer(makeUnique&lt;FailedFinalizer&gt;(m_graph.m_plan));
408         return;
409     }
410 
411     link(*linkBuffer);
412     m_speculative-&gt;linkOSREntries(*linkBuffer);
413 
<span class="line-removed">414     m_jitCode-&gt;shrinkToFit();</span>
<span class="line-removed">415     codeBlock()-&gt;shrinkToFit(CodeBlock::LateShrink);</span>
<span class="line-removed">416 </span>
417     disassemble(*linkBuffer);
418 
419     m_graph.m_plan.setFinalizer(makeUnique&lt;JITFinalizer&gt;(
420         m_graph.m_plan, m_jitCode.releaseNonNull(), WTFMove(linkBuffer)));
421 }
422 
423 void JITCompiler::compileFunction()
424 {
425     makeCatchOSREntryBuffer();
426 
427     setStartOfCode();
428     Label entryLabel(this);
429     compileEntry();
430 
431     // === Function header code generation ===
432     // This is the main entry point, without performing an arity check.
433     // If we needed to perform an arity check we will already have moved the return address,
434     // so enter after this.
435     Label fromArityCheck(this);
436     // Plant a check that sufficient space is available in the JSStack.
437     JumpList stackOverflow;
438     emitStackOverflowCheck(*this, stackOverflow);
439 
440     // Move the stack pointer down to accommodate locals
441     addPtr(TrustedImm32(-(m_graph.frameRegisterCount() * sizeof(Register))), GPRInfo::callFrameRegister, stackPointerRegister);
<span class="line-removed">442     if (Options::zeroStackFrame())</span>
<span class="line-removed">443         clearStackFrame(GPRInfo::callFrameRegister, stackPointerRegister, GPRInfo::regT0, m_graph.frameRegisterCount() * sizeof(Register));</span>
444     checkStackPointerAlignment();
445 
446     compileSetupRegistersForEntry();
447     compileEntryExecutionFlag();
448 
449     // === Function body code generation ===
450     m_speculative = makeUnique&lt;SpeculativeJIT&gt;(*this);
451     compileBody();
452     setEndOfMainPath();
453 
454     // === Function footer code generation ===
455     //
456     // Generate code to perform the stack overflow handling (if the stack check in
457     // the function header fails), and generate the entry point with arity check.
458     //
459     // Generate the stack overflow handling; if the stack check in the function head fails,
460     // we need to call out to a helper function to throw the StackOverflowError.
461     stackOverflow.link(this);
462 
<span class="line-modified">463     emitStoreCodeOrigin(CodeOrigin(0));</span>
464 
465     if (maxFrameExtentForSlowPathCall)
466         addPtr(TrustedImm32(-static_cast&lt;int32_t&gt;(maxFrameExtentForSlowPathCall)), stackPointerRegister);
467 
468     m_speculative-&gt;callOperationWithCallFrameRollbackOnException(operationThrowStackOverflowError, m_codeBlock);
469 
470     // The fast entry point into a function does not check the correct number of arguments
471     // have been passed to the call (we only use the fast entry point where we can statically
472     // determine the correct number of arguments have been passed, or have already checked).
473     // In cases where an arity check is necessary, we enter here.
474     // FIXME: change this from a cti call to a DFG style operation (normal C calling conventions).
475     Call callArityFixup;
476     Label arityCheck;
477     bool requiresArityFixup = m_codeBlock-&gt;numParameters() != 1;
478     if (requiresArityFixup) {
479         arityCheck = label();
480         compileEntry();
481 
<span class="line-modified">482         load32(AssemblyHelpers::payloadFor((VirtualRegister)CallFrameSlot::argumentCount), GPRInfo::regT1);</span>
483         branch32(AboveOrEqual, GPRInfo::regT1, TrustedImm32(m_codeBlock-&gt;numParameters())).linkTo(fromArityCheck, this);
<span class="line-modified">484         emitStoreCodeOrigin(CodeOrigin(0));</span>
485         if (maxFrameExtentForSlowPathCall)
486             addPtr(TrustedImm32(-static_cast&lt;int32_t&gt;(maxFrameExtentForSlowPathCall)), stackPointerRegister);
<span class="line-modified">487         m_speculative-&gt;callOperationWithCallFrameRollbackOnException(m_codeBlock-&gt;isConstructor() ? operationConstructArityCheck : operationCallArityCheck, GPRInfo::regT0);</span>
488         if (maxFrameExtentForSlowPathCall)
489             addPtr(TrustedImm32(maxFrameExtentForSlowPathCall), stackPointerRegister);
490         branchTest32(Zero, GPRInfo::returnValueGPR).linkTo(fromArityCheck, this);
<span class="line-modified">491         emitStoreCodeOrigin(CodeOrigin(0));</span>
492         move(GPRInfo::returnValueGPR, GPRInfo::argumentGPR0);
493         callArityFixup = nearCall();
494         jump(fromArityCheck);
495     } else
496         arityCheck = entryLabel;
497 
498     // Generate slow path code.
499     m_speculative-&gt;runSlowPathGenerators(m_pcToCodeOriginMapBuilder);
500     m_pcToCodeOriginMapBuilder.appendItem(labelIgnoringWatchpoints(), PCToCodeOriginMapBuilder::defaultCodeOrigin());
501 
502     compileExceptionHandlers();
503     linkOSRExits();
504 
505     // Create OSR entry trampolines if necessary.
506     m_speculative-&gt;createOSREntries();
507     setEndOfCode();
508 
509     // === Link ===
510     auto linkBuffer = makeUnique&lt;LinkBuffer&gt;(*this, m_codeBlock, JITCompilationCanFail);
511     if (linkBuffer-&gt;didFailToAllocate()) {
512         m_graph.m_plan.setFinalizer(makeUnique&lt;FailedFinalizer&gt;(m_graph.m_plan));
513         return;
514     }
515     link(*linkBuffer);
516     m_speculative-&gt;linkOSREntries(*linkBuffer);
517 
<span class="line-removed">518     m_jitCode-&gt;shrinkToFit();</span>
<span class="line-removed">519     codeBlock()-&gt;shrinkToFit(CodeBlock::LateShrink);</span>
<span class="line-removed">520 </span>
521     if (requiresArityFixup)
522         linkBuffer-&gt;link(callArityFixup, FunctionPtr&lt;JITThunkPtrTag&gt;(vm().getCTIStub(arityFixupGenerator).code()));
523 
524     disassemble(*linkBuffer);
525 
526     MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; withArityCheck = linkBuffer-&gt;locationOf&lt;JSEntryPtrTag&gt;(arityCheck);
527 
528     m_graph.m_plan.setFinalizer(makeUnique&lt;JITFinalizer&gt;(
529         m_graph.m_plan, m_jitCode.releaseNonNull(), WTFMove(linkBuffer), withArityCheck));
530 }
531 
532 void JITCompiler::disassemble(LinkBuffer&amp; linkBuffer)
533 {
534     if (shouldDumpDisassembly()) {
535         m_disassembler-&gt;dump(linkBuffer);
536         linkBuffer.didAlreadyDisassemble();
537     }
538 
539     if (UNLIKELY(m_graph.m_plan.compilation()))
540         m_disassembler-&gt;reportToProfiler(m_graph.m_plan.compilation(), linkBuffer);
</pre>
<hr />
<pre>
588     }
589     for (size_t local = 0; local &lt; basicBlock.variablesAtHead.numberOfLocals(); ++local) {
590         Node* node = basicBlock.variablesAtHead.local(local);
591         if (!node || !node-&gt;shouldGenerate())
592             entry-&gt;m_expectedValues.local(local).makeBytecodeTop();
593         else {
594             VariableAccessData* variable = node-&gt;variableAccessData();
595             entry-&gt;m_machineStackUsed.set(variable-&gt;machineLocal().toLocal());
596 
597             switch (variable-&gt;flushFormat()) {
598             case FlushedDouble:
599                 entry-&gt;m_localsForcedDouble.set(local);
600                 break;
601             case FlushedInt52:
602                 entry-&gt;m_localsForcedAnyInt.set(local);
603                 break;
604             default:
605                 break;
606             }
607 
<span class="line-modified">608             if (variable-&gt;local() != variable-&gt;machineLocal()) {</span>

609                 entry-&gt;m_reshufflings.append(
610                     OSREntryReshuffling(
<span class="line-modified">611                         variable-&gt;local().offset(), variable-&gt;machineLocal().offset()));</span>
612             }
613         }
614     }
615 
616     entry-&gt;m_reshufflings.shrinkToFit();
617 }
618 
619 void JITCompiler::appendExceptionHandlingOSRExit(ExitKind kind, unsigned eventStreamIndex, CodeOrigin opCatchOrigin, HandlerInfo* exceptionHandler, CallSiteIndex callSite, MacroAssembler::JumpList jumpsToFail)
620 {
621     OSRExit exit(kind, JSValueRegs(), MethodOfGettingAValueProfile(), m_speculative.get(), eventStreamIndex);
622     exit.m_codeOrigin = opCatchOrigin;
623     exit.m_exceptionHandlerCallSiteIndex = callSite;
624     OSRExitCompilationInfo&amp; exitInfo = appendExitInfo(jumpsToFail);
625     jitCode()-&gt;appendOSRExit(exit);
626     m_exceptionHandlerOSRExitCallSites.append(ExceptionHandlingOSRExitInfo { exitInfo, *exceptionHandler, callSite });
627 }
628 
629 void JITCompiler::exceptionCheck()
630 {
631     // It&#39;s important that we use origin.forExit here. Consider if we hoist string
</pre>
</td>
<td>
<hr />
<pre>
 43 #include &quot;JSCJSValueInlines.h&quot;
 44 #include &quot;LinkBuffer.h&quot;
 45 #include &quot;MaxFrameExtentForSlowPathCall.h&quot;
 46 #include &quot;StructureStubInfo.h&quot;
 47 #include &quot;ThunkGenerators.h&quot;
 48 #include &quot;VM.h&quot;
 49 
 50 namespace JSC { namespace DFG {
 51 
 52 JITCompiler::JITCompiler(Graph&amp; dfg)
 53     : CCallHelpers(dfg.m_codeBlock)
 54     , m_graph(dfg)
 55     , m_jitCode(adoptRef(new JITCode()))
 56     , m_blockHeads(dfg.numBlocks())
 57     , m_pcToCodeOriginMapBuilder(dfg.m_vm)
 58 {
 59     if (UNLIKELY(shouldDumpDisassembly() || m_graph.m_vm.m_perBytecodeProfiler))
 60         m_disassembler = makeUnique&lt;Disassembler&gt;(dfg);
 61 #if ENABLE(FTL_JIT)
 62     m_jitCode-&gt;tierUpInLoopHierarchy = WTFMove(m_graph.m_plan.tierUpInLoopHierarchy());
<span class="line-modified"> 63     for (BytecodeIndex tierUpBytecode : m_graph.m_plan.tierUpAndOSREnterBytecodes())</span>
 64         m_jitCode-&gt;tierUpEntryTriggers.add(tierUpBytecode, JITCode::TriggerReason::DontTrigger);
 65 #endif
 66 }
 67 
 68 JITCompiler::~JITCompiler()
 69 {
 70 }
 71 
 72 void JITCompiler::linkOSRExits()
 73 {
 74     ASSERT(m_jitCode-&gt;osrExit.size() == m_exitCompilationInfo.size());
 75     if (UNLIKELY(m_graph.compilation())) {
 76         for (unsigned i = 0; i &lt; m_jitCode-&gt;osrExit.size(); ++i) {
 77             OSRExitCompilationInfo&amp; info = m_exitCompilationInfo[i];
 78             Vector&lt;Label&gt; labels;
 79             if (!info.m_failureJumps.empty()) {
 80                 for (unsigned j = 0; j &lt; info.m_failureJumps.jumps().size(); ++j)
 81                     labels.append(info.m_failureJumps.jumps()[j].label());
 82             } else
 83                 labels.append(info.m_replacementSource);
 84             m_exitSiteLabels.append(labels);
 85         }
 86     }
 87 


 88     for (unsigned i = 0; i &lt; m_jitCode-&gt;osrExit.size(); ++i) {
 89         OSRExitCompilationInfo&amp; info = m_exitCompilationInfo[i];
 90         JumpList&amp; failureJumps = info.m_failureJumps;
 91         if (!failureJumps.empty())
 92             failureJumps.link(this);
 93         else
 94             info.m_replacementDestination = label();
 95 
 96         jitAssertHasValidCallFrame();
 97         store32(TrustedImm32(i), &amp;vm().osrExitIndex);
<span class="line-modified"> 98         info.m_patchableJump = patchableJump();</span>






 99     }
100 }
101 
102 void JITCompiler::compileEntry()
103 {
104     // This code currently matches the old JIT. In the function header we need to
105     // save return address and call frame via the prologue and perform a fast stack check.
106     // FIXME: https://bugs.webkit.org/show_bug.cgi?id=56292
107     // We&#39;ll need to convert the remaining cti_ style calls (specifically the stack
108     // check) which will be dependent on stack layout. (We&#39;d need to account for this in
109     // both normal return code and when jumping to an exception handler).
110     emitFunctionPrologue();
111     emitPutToCallFrameHeader(m_codeBlock, CallFrameSlot::codeBlock);
112 }
113 
114 void JITCompiler::compileSetupRegistersForEntry()
115 {
116     emitSaveCalleeSaves();
117     emitMaterializeTagCheckRegisters();
118 }
</pre>
<hr />
<pre>
124         store8(TrustedImm32(0), &amp;m_jitCode-&gt;neverExecutedEntry);
125 #endif // ENABLE(FTL_JIT)
126 }
127 
128 void JITCompiler::compileBody()
129 {
130     // We generate the speculative code path, followed by OSR exit code to return
131     // to the old JIT code if speculations fail.
132 
133     bool compiledSpeculative = m_speculative-&gt;compile();
134     ASSERT_UNUSED(compiledSpeculative, compiledSpeculative);
135 }
136 
137 void JITCompiler::compileExceptionHandlers()
138 {
139     if (!m_exceptionChecksWithCallFrameRollback.empty()) {
140         m_exceptionChecksWithCallFrameRollback.link(this);
141 
142         copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm().topEntryFrame);
143 
<span class="line-modified">144         // operationLookupExceptionHandlerFromCallerFrame is passed one argument, the VM*.</span>
145         move(TrustedImmPtr(&amp;vm()), GPRInfo::argumentGPR0);
<span class="line-modified">146         prepareCallOperation(vm());</span>
147         addPtr(TrustedImm32(m_graph.stackPointerOffset() * sizeof(Register)), GPRInfo::callFrameRegister, stackPointerRegister);
148 
<span class="line-modified">149         m_calls.append(CallLinkRecord(call(OperationPtrTag), FunctionPtr&lt;OperationPtrTag&gt;(operationLookupExceptionHandlerFromCallerFrame)));</span>





150 
151         jumpToExceptionHandler(vm());
152     }
153 
154     if (!m_exceptionChecks.empty()) {
155         m_exceptionChecks.link(this);
156 
157         copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm().topEntryFrame);
158 
<span class="line-modified">159         // operationLookupExceptionHandler is passed one argument, the VM*.</span>
160         move(TrustedImmPtr(&amp;vm()), GPRInfo::argumentGPR0);
<span class="line-modified">161         prepareCallOperation(vm());</span>
162 
<span class="line-modified">163         m_calls.append(CallLinkRecord(call(OperationPtrTag), FunctionPtr&lt;OperationPtrTag&gt;(operationLookupExceptionHandler)));</span>





164 
165         jumpToExceptionHandler(vm());
166     }
167 }
168 
169 void JITCompiler::link(LinkBuffer&amp; linkBuffer)
170 {
171     // Link the code, populate data in CodeBlock data structures.
172     m_jitCode-&gt;common.frameRegisterCount = m_graph.frameRegisterCount();
173     m_jitCode-&gt;common.requiredRegisterCountForExit = m_graph.requiredRegisterCountForExit();
174 
175     if (!m_graph.m_plan.inlineCallFrames()-&gt;isEmpty())
176         m_jitCode-&gt;common.inlineCallFrames = m_graph.m_plan.inlineCallFrames();
177 
178 #if USE(JSVALUE32_64)
179     m_jitCode-&gt;common.doubleConstants = WTFMove(m_graph.m_doubleConstants);
180 #endif
181 
182     m_graph.registerFrozenValues();
183 
</pre>
<hr />
<pre>
227 
228         table.ctiDefault = linkBuffer.locationOf&lt;JSSwitchPtrTag&gt;(m_blockHeads[data.fallThrough.block-&gt;index]);
229         StringJumpTable::StringOffsetTable::iterator iter;
230         StringJumpTable::StringOffsetTable::iterator end = table.offsetTable.end();
231         for (iter = table.offsetTable.begin(); iter != end; ++iter)
232             iter-&gt;value.ctiOffset = table.ctiDefault;
233         for (unsigned j = data.cases.size(); j--;) {
234             SwitchCase&amp; myCase = data.cases[j];
235             iter = table.offsetTable.find(myCase.value.stringImpl());
236             RELEASE_ASSERT(iter != end);
237             iter-&gt;value.ctiOffset = linkBuffer.locationOf&lt;JSSwitchPtrTag&gt;(m_blockHeads[myCase.target.block-&gt;index]);
238         }
239     }
240 
241     // Link all calls out from the JIT code to their respective functions.
242     for (unsigned i = 0; i &lt; m_calls.size(); ++i)
243         linkBuffer.link(m_calls[i].m_call, m_calls[i].m_function);
244 
245     finalizeInlineCaches(m_getByIds, linkBuffer);
246     finalizeInlineCaches(m_getByIdsWithThis, linkBuffer);
<span class="line-added">247     finalizeInlineCaches(m_getByVals, linkBuffer);</span>
248     finalizeInlineCaches(m_putByIds, linkBuffer);
249     finalizeInlineCaches(m_inByIds, linkBuffer);
250     finalizeInlineCaches(m_instanceOfs, linkBuffer);
251 
252     auto linkCallThunk = FunctionPtr&lt;NoPtrTag&gt;(vm().getCTIStub(linkCallThunkGenerator).retaggedCode&lt;NoPtrTag&gt;());
253     for (auto&amp; record : m_jsCalls) {
254         CallLinkInfo&amp; info = *record.info;
255         linkBuffer.link(record.slowCall, linkCallThunk);
256         info.setCallLocations(
257             CodeLocationLabel&lt;JSInternalPtrTag&gt;(linkBuffer.locationOfNearCall&lt;JSInternalPtrTag&gt;(record.slowCall)),
258             CodeLocationLabel&lt;JSInternalPtrTag&gt;(linkBuffer.locationOf&lt;JSInternalPtrTag&gt;(record.targetToCheck)),
259             linkBuffer.locationOfNearCall&lt;JSInternalPtrTag&gt;(record.fastCall));
260     }
261 
262     for (JSDirectCallRecord&amp; record : m_jsDirectCalls) {
263         CallLinkInfo&amp; info = *record.info;
264         linkBuffer.link(record.call, linkBuffer.locationOf&lt;NoPtrTag&gt;(record.slowPath));
265         info.setCallLocations(
266             CodeLocationLabel&lt;JSInternalPtrTag&gt;(),
267             linkBuffer.locationOf&lt;JSInternalPtrTag&gt;(record.slowPath),
</pre>
<hr />
<pre>
336 
337     jit.addPtr(MacroAssembler::TrustedImm32(frameTopOffset), GPRInfo::callFrameRegister, GPRInfo::regT1);
338     if (UNLIKELY(maxFrameSize &gt; Options::reservedZoneSize()))
339         stackOverflow.append(jit.branchPtr(MacroAssembler::Above, GPRInfo::regT1, GPRInfo::callFrameRegister));
340     stackOverflow.append(jit.branchPtr(MacroAssembler::Above, MacroAssembler::AbsoluteAddress(jit.vm().addressOfSoftStackLimit()), GPRInfo::regT1));
341 }
342 
343 void JITCompiler::compile()
344 {
345     makeCatchOSREntryBuffer();
346 
347     setStartOfCode();
348     compileEntry();
349     m_speculative = makeUnique&lt;SpeculativeJIT&gt;(*this);
350 
351     // Plant a check that sufficient space is available in the JSStack.
352     JumpList stackOverflow;
353     emitStackOverflowCheck(*this, stackOverflow);
354 
355     addPtr(TrustedImm32(-(m_graph.frameRegisterCount() * sizeof(Register))), GPRInfo::callFrameRegister, stackPointerRegister);


356     checkStackPointerAlignment();
357     compileSetupRegistersForEntry();
358     compileEntryExecutionFlag();
359     compileBody();
360     setEndOfMainPath();
361 
362     // === Footer code generation ===
363     //
364     // Generate the stack overflow handling; if the stack check in the entry head fails,
365     // we need to call out to a helper function to throw the StackOverflowError.
366     stackOverflow.link(this);
367 
<span class="line-modified">368     emitStoreCodeOrigin(CodeOrigin(BytecodeIndex(0)));</span>
369 
370     if (maxFrameExtentForSlowPathCall)
371         addPtr(TrustedImm32(-static_cast&lt;int32_t&gt;(maxFrameExtentForSlowPathCall)), stackPointerRegister);
372 
373     m_speculative-&gt;callOperationWithCallFrameRollbackOnException(operationThrowStackOverflowError, m_codeBlock);
374 
375     // Generate slow path code.
376     m_speculative-&gt;runSlowPathGenerators(m_pcToCodeOriginMapBuilder);
377     m_pcToCodeOriginMapBuilder.appendItem(labelIgnoringWatchpoints(), PCToCodeOriginMapBuilder::defaultCodeOrigin());
378 
379     compileExceptionHandlers();
380     linkOSRExits();
381 
382     // Create OSR entry trampolines if necessary.
383     m_speculative-&gt;createOSREntries();
384     setEndOfCode();
385 
386     auto linkBuffer = makeUnique&lt;LinkBuffer&gt;(*this, m_codeBlock, JITCompilationCanFail);
387     if (linkBuffer-&gt;didFailToAllocate()) {
388         m_graph.m_plan.setFinalizer(makeUnique&lt;FailedFinalizer&gt;(m_graph.m_plan));
389         return;
390     }
391 
392     link(*linkBuffer);
393     m_speculative-&gt;linkOSREntries(*linkBuffer);
394 



395     disassemble(*linkBuffer);
396 
397     m_graph.m_plan.setFinalizer(makeUnique&lt;JITFinalizer&gt;(
398         m_graph.m_plan, m_jitCode.releaseNonNull(), WTFMove(linkBuffer)));
399 }
400 
401 void JITCompiler::compileFunction()
402 {
403     makeCatchOSREntryBuffer();
404 
405     setStartOfCode();
406     Label entryLabel(this);
407     compileEntry();
408 
409     // === Function header code generation ===
410     // This is the main entry point, without performing an arity check.
411     // If we needed to perform an arity check we will already have moved the return address,
412     // so enter after this.
413     Label fromArityCheck(this);
414     // Plant a check that sufficient space is available in the JSStack.
415     JumpList stackOverflow;
416     emitStackOverflowCheck(*this, stackOverflow);
417 
418     // Move the stack pointer down to accommodate locals
419     addPtr(TrustedImm32(-(m_graph.frameRegisterCount() * sizeof(Register))), GPRInfo::callFrameRegister, stackPointerRegister);


420     checkStackPointerAlignment();
421 
422     compileSetupRegistersForEntry();
423     compileEntryExecutionFlag();
424 
425     // === Function body code generation ===
426     m_speculative = makeUnique&lt;SpeculativeJIT&gt;(*this);
427     compileBody();
428     setEndOfMainPath();
429 
430     // === Function footer code generation ===
431     //
432     // Generate code to perform the stack overflow handling (if the stack check in
433     // the function header fails), and generate the entry point with arity check.
434     //
435     // Generate the stack overflow handling; if the stack check in the function head fails,
436     // we need to call out to a helper function to throw the StackOverflowError.
437     stackOverflow.link(this);
438 
<span class="line-modified">439     emitStoreCodeOrigin(CodeOrigin(BytecodeIndex(0)));</span>
440 
441     if (maxFrameExtentForSlowPathCall)
442         addPtr(TrustedImm32(-static_cast&lt;int32_t&gt;(maxFrameExtentForSlowPathCall)), stackPointerRegister);
443 
444     m_speculative-&gt;callOperationWithCallFrameRollbackOnException(operationThrowStackOverflowError, m_codeBlock);
445 
446     // The fast entry point into a function does not check the correct number of arguments
447     // have been passed to the call (we only use the fast entry point where we can statically
448     // determine the correct number of arguments have been passed, or have already checked).
449     // In cases where an arity check is necessary, we enter here.
450     // FIXME: change this from a cti call to a DFG style operation (normal C calling conventions).
451     Call callArityFixup;
452     Label arityCheck;
453     bool requiresArityFixup = m_codeBlock-&gt;numParameters() != 1;
454     if (requiresArityFixup) {
455         arityCheck = label();
456         compileEntry();
457 
<span class="line-modified">458         load32(AssemblyHelpers::payloadFor((VirtualRegister)CallFrameSlot::argumentCountIncludingThis), GPRInfo::regT1);</span>
459         branch32(AboveOrEqual, GPRInfo::regT1, TrustedImm32(m_codeBlock-&gt;numParameters())).linkTo(fromArityCheck, this);
<span class="line-modified">460         emitStoreCodeOrigin(CodeOrigin(BytecodeIndex(0)));</span>
461         if (maxFrameExtentForSlowPathCall)
462             addPtr(TrustedImm32(-static_cast&lt;int32_t&gt;(maxFrameExtentForSlowPathCall)), stackPointerRegister);
<span class="line-modified">463         m_speculative-&gt;callOperationWithCallFrameRollbackOnException(m_codeBlock-&gt;isConstructor() ? operationConstructArityCheck : operationCallArityCheck, GPRInfo::regT0, m_codeBlock-&gt;globalObject());</span>
464         if (maxFrameExtentForSlowPathCall)
465             addPtr(TrustedImm32(maxFrameExtentForSlowPathCall), stackPointerRegister);
466         branchTest32(Zero, GPRInfo::returnValueGPR).linkTo(fromArityCheck, this);
<span class="line-modified">467         emitStoreCodeOrigin(CodeOrigin(BytecodeIndex(0)));</span>
468         move(GPRInfo::returnValueGPR, GPRInfo::argumentGPR0);
469         callArityFixup = nearCall();
470         jump(fromArityCheck);
471     } else
472         arityCheck = entryLabel;
473 
474     // Generate slow path code.
475     m_speculative-&gt;runSlowPathGenerators(m_pcToCodeOriginMapBuilder);
476     m_pcToCodeOriginMapBuilder.appendItem(labelIgnoringWatchpoints(), PCToCodeOriginMapBuilder::defaultCodeOrigin());
477 
478     compileExceptionHandlers();
479     linkOSRExits();
480 
481     // Create OSR entry trampolines if necessary.
482     m_speculative-&gt;createOSREntries();
483     setEndOfCode();
484 
485     // === Link ===
486     auto linkBuffer = makeUnique&lt;LinkBuffer&gt;(*this, m_codeBlock, JITCompilationCanFail);
487     if (linkBuffer-&gt;didFailToAllocate()) {
488         m_graph.m_plan.setFinalizer(makeUnique&lt;FailedFinalizer&gt;(m_graph.m_plan));
489         return;
490     }
491     link(*linkBuffer);
492     m_speculative-&gt;linkOSREntries(*linkBuffer);
493 



494     if (requiresArityFixup)
495         linkBuffer-&gt;link(callArityFixup, FunctionPtr&lt;JITThunkPtrTag&gt;(vm().getCTIStub(arityFixupGenerator).code()));
496 
497     disassemble(*linkBuffer);
498 
499     MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; withArityCheck = linkBuffer-&gt;locationOf&lt;JSEntryPtrTag&gt;(arityCheck);
500 
501     m_graph.m_plan.setFinalizer(makeUnique&lt;JITFinalizer&gt;(
502         m_graph.m_plan, m_jitCode.releaseNonNull(), WTFMove(linkBuffer), withArityCheck));
503 }
504 
505 void JITCompiler::disassemble(LinkBuffer&amp; linkBuffer)
506 {
507     if (shouldDumpDisassembly()) {
508         m_disassembler-&gt;dump(linkBuffer);
509         linkBuffer.didAlreadyDisassemble();
510     }
511 
512     if (UNLIKELY(m_graph.m_plan.compilation()))
513         m_disassembler-&gt;reportToProfiler(m_graph.m_plan.compilation(), linkBuffer);
</pre>
<hr />
<pre>
561     }
562     for (size_t local = 0; local &lt; basicBlock.variablesAtHead.numberOfLocals(); ++local) {
563         Node* node = basicBlock.variablesAtHead.local(local);
564         if (!node || !node-&gt;shouldGenerate())
565             entry-&gt;m_expectedValues.local(local).makeBytecodeTop();
566         else {
567             VariableAccessData* variable = node-&gt;variableAccessData();
568             entry-&gt;m_machineStackUsed.set(variable-&gt;machineLocal().toLocal());
569 
570             switch (variable-&gt;flushFormat()) {
571             case FlushedDouble:
572                 entry-&gt;m_localsForcedDouble.set(local);
573                 break;
574             case FlushedInt52:
575                 entry-&gt;m_localsForcedAnyInt.set(local);
576                 break;
577             default:
578                 break;
579             }
580 
<span class="line-modified">581             ASSERT(!variable-&gt;operand().isTmp());</span>
<span class="line-added">582             if (variable-&gt;operand().virtualRegister() != variable-&gt;machineLocal()) {</span>
583                 entry-&gt;m_reshufflings.append(
584                     OSREntryReshuffling(
<span class="line-modified">585                         variable-&gt;operand().virtualRegister().offset(), variable-&gt;machineLocal().offset()));</span>
586             }
587         }
588     }
589 
590     entry-&gt;m_reshufflings.shrinkToFit();
591 }
592 
593 void JITCompiler::appendExceptionHandlingOSRExit(ExitKind kind, unsigned eventStreamIndex, CodeOrigin opCatchOrigin, HandlerInfo* exceptionHandler, CallSiteIndex callSite, MacroAssembler::JumpList jumpsToFail)
594 {
595     OSRExit exit(kind, JSValueRegs(), MethodOfGettingAValueProfile(), m_speculative.get(), eventStreamIndex);
596     exit.m_codeOrigin = opCatchOrigin;
597     exit.m_exceptionHandlerCallSiteIndex = callSite;
598     OSRExitCompilationInfo&amp; exitInfo = appendExitInfo(jumpsToFail);
599     jitCode()-&gt;appendOSRExit(exit);
600     m_exceptionHandlerOSRExitCallSites.append(ExceptionHandlingOSRExitInfo { exitInfo, *exceptionHandler, callSite });
601 }
602 
603 void JITCompiler::exceptionCheck()
604 {
605     // It&#39;s important that we use origin.forExit here. Consider if we hoist string
</pre>
</td>
</tr>
</table>
<center><a href="DFGJITCode.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGJITCompiler.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>