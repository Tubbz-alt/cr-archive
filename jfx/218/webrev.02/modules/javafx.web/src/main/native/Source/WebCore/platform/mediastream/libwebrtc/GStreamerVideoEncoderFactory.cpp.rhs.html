<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoEncoderFactory.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2018 Metrological Group B.V.
  3  * Copyright (C) 2018 Igalia S.L. All rights reserved.
  4  *
  5  * This library is free software; you can redistribute it and/or
  6  * modify it under the terms of the GNU Library General Public
  7  * License as published by the Free Software Foundation; either
  8  * version 2 of the License, or (at your option) any later version.
  9  *
 10  * This library is distributed in the hope that it will be useful,
 11  * but WITHOUT ANY WARRANTY; without even the implied warranty of
 12  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 13  * Library General Public License for more details.
 14  *
 15  * You should have received a copy of the GNU Library General Public License
 16  * aint with this library; see the file COPYING.LIB.  If not, write to
 17  * the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
 18  * Boston, MA 02110-1301, USA.
 19  */
 20 
 21 #include &quot;config.h&quot;
 22 
 23 #if ENABLE(VIDEO) &amp;&amp; ENABLE(MEDIA_STREAM) &amp;&amp; USE(LIBWEBRTC) &amp;&amp; USE(GSTREAMER)
 24 #include &quot;GStreamerVideoEncoderFactory.h&quot;
 25 
 26 #include &quot;GStreamerVideoEncoder.h&quot;
 27 #include &quot;GStreamerVideoFrameLibWebRTC.h&quot;
 28 #include &quot;webrtc/common_video/h264/h264_common.h&quot;
 29 #include &quot;webrtc/common_video/h264/profile_level_id.h&quot;
 30 #include &quot;webrtc/media/base/codec.h&quot;
 31 #include &quot;webrtc/modules/video_coding/codecs/h264/include/h264.h&quot;
 32 #include &quot;webrtc/modules/video_coding/codecs/vp8/include/vp8.h&quot;
 33 #include &quot;webrtc/modules/video_coding/codecs/vp8/libvpx_vp8_encoder.h&quot;
 34 #include &quot;webrtc/modules/video_coding/include/video_codec_interface.h&quot;
 35 #include &quot;webrtc/modules/video_coding/utility/simulcast_utility.h&quot;
 36 
 37 #include &lt;gst/app/gstappsink.h&gt;
 38 #include &lt;gst/app/gstappsrc.h&gt;
 39 #define GST_USE_UNSTABLE_API 1
 40 #include &lt;gst/codecparsers/gsth264parser.h&gt;
 41 #undef GST_USE_UNSTABLE_API
 42 #include &lt;gst/pbutils/encoding-profile.h&gt;
 43 #include &lt;gst/video/video.h&gt;
 44 #include &lt;wtf/Atomics.h&gt;
 45 #include &lt;wtf/HashMap.h&gt;
 46 #include &lt;wtf/Lock.h&gt;
 47 #include &lt;wtf/StdMap.h&gt;
 48 #include &lt;wtf/text/StringConcatenateNumbers.h&gt;
 49 
 50 // Required for unified builds
 51 #ifdef GST_CAT_DEFAULT
 52 #undef GST_CAT_DEFAULT
 53 #endif
 54 
 55 GST_DEBUG_CATEGORY(webkit_webrtcenc_debug);
 56 #define GST_CAT_DEFAULT webkit_webrtcenc_debug
 57 
 58 #define KBIT_TO_BIT 1024
 59 
 60 namespace WebCore {
 61 
 62 class GStreamerVideoEncoder : public webrtc::VideoEncoder {
 63     WTF_MAKE_FAST_ALLOCATED;
 64 public:
 65     GStreamerVideoEncoder(const webrtc::SdpVideoFormat&amp;)
 66         : m_firstFramePts(GST_CLOCK_TIME_NONE)
 67         , m_restrictionCaps(adoptGRef(gst_caps_new_empty_simple(&quot;video/x-raw&quot;)))
 68     {
 69     }
 70     GStreamerVideoEncoder()
 71         : m_firstFramePts(GST_CLOCK_TIME_NONE)
 72         , m_restrictionCaps(adoptGRef(gst_caps_new_empty_simple(&quot;video/x-raw&quot;)))
 73     {
 74     }
 75 
<a name="1" id="anc1"></a><span class="line-modified"> 76     void SetRates(const webrtc::VideoEncoder::RateControlParameters&amp; parameters) override</span>
 77     {
<a name="2" id="anc2"></a><span class="line-modified"> 78         GST_INFO_OBJECT(m_pipeline.get(), &quot;New bitrate: %d - framerate is %f&quot;,</span>
<span class="line-modified"> 79             parameters.bitrate.get_sum_bps(), parameters.framerate_fps);</span>
 80 
 81         auto caps = adoptGRef(gst_caps_copy(m_restrictionCaps.get()));
 82 
 83         SetRestrictionCaps(WTFMove(caps));
 84 
 85         if (m_encoder)
<a name="3" id="anc3"></a><span class="line-modified"> 86             g_object_set(m_encoder, &quot;bitrate&quot;, parameters.bitrate.get_sum_bps(), nullptr);</span>


 87     }
 88 
 89     GstElement* pipeline()
 90     {
 91         return m_pipeline.get();
 92     }
 93 
 94     GstElement* makeElement(const gchar* factoryName)
 95     {
 96         static Atomic&lt;uint32_t&gt; elementId;
 97         auto name = makeString(Name(), &quot;-enc-&quot;, factoryName, &quot;-&quot;, elementId.exchangeAdd(1));
 98         auto elem = gst_element_factory_make(factoryName, name.utf8().data());
 99 
100         return elem;
101     }
102 
103     int32_t InitEncode(const webrtc::VideoCodec* codecSettings, int32_t, size_t)
104     {
105         g_return_val_if_fail(codecSettings, WEBRTC_VIDEO_CODEC_ERR_PARAMETER);
106         g_return_val_if_fail(codecSettings-&gt;codecType == CodecType(), WEBRTC_VIDEO_CODEC_ERR_PARAMETER);
107 
108         if (webrtc::SimulcastUtility::NumberOfSimulcastStreams(*codecSettings) &gt; 1) {
109             GST_ERROR(&quot;Simulcast not supported.&quot;);
110 
111             return WEBRTC_VIDEO_CODEC_ERR_SIMULCAST_PARAMETERS_NOT_SUPPORTED;
112         }
113 
<a name="4" id="anc4"></a><span class="line-modified">114         auto size = codecSettings-&gt;width * codecSettings-&gt;height * 3;</span>
<span class="line-modified">115         m_encodedFrame.set_buffer(new uint8_t[size], size);</span>
<span class="line-modified">116         m_encodedImageBuffer.reset(m_encodedFrame.data());</span>
117         m_encodedFrame._completeFrame = true;
118         m_encodedFrame._encodedWidth = 0;
119         m_encodedFrame._encodedHeight = 0;
<a name="5" id="anc5"></a>
120 
121         m_pipeline = makeElement(&quot;pipeline&quot;);
122 
123         connectSimpleBusMessageCallback(m_pipeline.get());
124         auto encoder = createEncoder();
125         ASSERT(encoder);
126         m_encoder = encoder.get();
127 
128         g_object_set(m_encoder, &quot;keyframe-interval&quot;, KeyframeInterval(codecSettings), nullptr);
129 
130         m_src = makeElement(&quot;appsrc&quot;);
131         g_object_set(m_src, &quot;is-live&quot;, true, &quot;format&quot;, GST_FORMAT_TIME, nullptr);
132 
133         auto videoconvert = makeElement(&quot;videoconvert&quot;);
134         m_sink = makeElement(&quot;appsink&quot;);
135         g_object_set(m_sink, &quot;sync&quot;, FALSE, nullptr);
136 
137         m_capsFilter = makeElement(&quot;capsfilter&quot;);
138         if (m_restrictionCaps)
139             g_object_set(m_capsFilter, &quot;caps&quot;, m_restrictionCaps.get(), nullptr);
140 
141         gst_bin_add_many(GST_BIN(m_pipeline.get()), m_src, videoconvert, m_capsFilter, encoder.leakRef(), m_sink, nullptr);
142         if (!gst_element_link_many(m_src, videoconvert, m_capsFilter, m_encoder, m_sink, nullptr)) {
143             GST_DEBUG_BIN_TO_DOT_FILE_WITH_TS(GST_BIN(m_pipeline.get()), GST_DEBUG_GRAPH_SHOW_VERBOSE, &quot;webkit-webrtc-encoder.error&quot;);
144 
145             ASSERT_NOT_REACHED();
146         }
147 
148         gst_element_set_state(m_pipeline.get(), GST_STATE_PLAYING);
149 
150         return WEBRTC_VIDEO_CODEC_OK;
151     }
152 
<a name="6" id="anc6"></a>




153     int32_t RegisterEncodeCompleteCallback(webrtc::EncodedImageCallback* callback) final
154     {
155         m_imageReadyCb = callback;
156 
157         return WEBRTC_VIDEO_CODEC_OK;
158     }
159 
160     int32_t Release() final
161     {
<a name="7" id="anc7"></a><span class="line-modified">162         m_encodedFrame.set_buffer(nullptr, 0);</span>
163         m_encodedImageBuffer.reset();
164         if (m_pipeline) {
165             GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
166             gst_bus_set_sync_handler(bus.get(), nullptr, nullptr, nullptr);
167 
168             gst_element_set_state(m_pipeline.get(), GST_STATE_NULL);
169             m_src = nullptr;
170             m_encoder = nullptr;
171             m_capsFilter = nullptr;
172             m_sink = nullptr;
173             m_pipeline = nullptr;
174         }
175 
176         return WEBRTC_VIDEO_CODEC_OK;
177     }
178 
179     int32_t returnFromFlowReturn(GstFlowReturn flow)
180     {
181         switch (flow) {
182         case GST_FLOW_OK:
183             return WEBRTC_VIDEO_CODEC_OK;
184         case GST_FLOW_FLUSHING:
185             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
186         default:
187             return WEBRTC_VIDEO_CODEC_ERROR;
188         }
189     }
190 
<a name="8" id="anc8"></a><span class="line-added">191     VideoEncoder::EncoderInfo GetEncoderInfo() const {</span>
<span class="line-added">192         EncoderInfo info;</span>
<span class="line-added">193         info.supports_native_handle = false;</span>
<span class="line-added">194         info.implementation_name = &quot;GStreamer&quot;;</span>
<span class="line-added">195         info.has_trusted_rate_controller = true;</span>
<span class="line-added">196         info.is_hardware_accelerated = true;</span>
<span class="line-added">197         info.has_internal_source = false;</span>
<span class="line-added">198         return info;</span>
<span class="line-added">199     }</span>
<span class="line-added">200 </span>
201     int32_t Encode(const webrtc::VideoFrame&amp; frame,
<a name="9" id="anc9"></a><span class="line-modified">202         const std::vector&lt;webrtc::VideoFrameType&gt;* frameTypes) final</span>

203     {
204         int32_t res;
205 
206         if (!m_imageReadyCb) {
207             GST_INFO_OBJECT(m_pipeline.get(), &quot;No encoded callback set yet!&quot;);
208 
209             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
210         }
211 
212         if (!m_src) {
213             GST_INFO_OBJECT(m_pipeline.get(), &quot;No source set yet!&quot;);
214 
215             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
216         }
217 
218         auto sample = GStreamerSampleFromLibWebRTCVideoFrame(frame);
219         auto buffer = gst_sample_get_buffer(sample.get());
220 
221         if (!GST_CLOCK_TIME_IS_VALID(m_firstFramePts)) {
222             m_firstFramePts = GST_BUFFER_PTS(buffer);
223             auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
224             gst_pad_set_offset(pad.get(), -m_firstFramePts);
225         }
226 
227         for (auto frame_type : *frameTypes) {
<a name="10" id="anc10"></a><span class="line-modified">228             if (frame_type == webrtc::VideoFrameType::kVideoFrameKey) {</span>
229                 auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
230                 auto forceKeyUnit = gst_video_event_new_downstream_force_key_unit(GST_CLOCK_TIME_NONE,
231                     GST_CLOCK_TIME_NONE, GST_CLOCK_TIME_NONE, FALSE, 1);
232                 GST_INFO_OBJECT(m_pipeline.get(), &quot;Requesting KEYFRAME!&quot;);
233 
234                 if (!gst_pad_push_event(pad.get(), forceKeyUnit))
235                     GST_WARNING_OBJECT(pipeline(), &quot;Could not send ForceKeyUnit event&quot;);
236 
237                 break;
238             }
239         }
240 
241         res = returnFromFlowReturn(gst_app_src_push_sample(GST_APP_SRC(m_src), sample.get()));
242         if (res != WEBRTC_VIDEO_CODEC_OK)
243             return res;
244 
245         auto encodedSample = adoptGRef(gst_app_sink_try_pull_sample(GST_APP_SINK(m_sink), 5 * GST_SECOND));
246         if (!encodedSample) {
247             GST_ERROR(&quot;Didn&#39;t get any encodedSample&quot;);
248             return WEBRTC_VIDEO_CODEC_ERROR;
249         }
250 
251         auto encodedBuffer = gst_sample_get_buffer(encodedSample.get());
252         auto encodedCaps = gst_sample_get_caps(encodedSample.get());
253 
254         webrtc::RTPFragmentationHeader fragmentationInfo;
255 
256         Fragmentize(&amp;m_encodedFrame, &amp;m_encodedImageBuffer, &amp;m_encodedImageBufferSize, encodedBuffer, &amp;fragmentationInfo);
<a name="11" id="anc11"></a><span class="line-modified">257         if (!m_encodedFrame.size())</span>
258             return WEBRTC_VIDEO_CODEC_OK;
259 
260         gst_structure_get(gst_caps_get_structure(encodedCaps, 0),
261             &quot;width&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedWidth,
262             &quot;height&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedHeight,
263             nullptr);
264 
<a name="12" id="anc12"></a><span class="line-modified">265         m_encodedFrame._frameType = GST_BUFFER_FLAG_IS_SET(encodedBuffer, GST_BUFFER_FLAG_DELTA_UNIT) ? webrtc::VideoFrameType::kVideoFrameDelta : webrtc::VideoFrameType::kVideoFrameKey;</span>
266         m_encodedFrame._completeFrame = true;
267         m_encodedFrame.capture_time_ms_ = frame.render_time_ms();
268         m_encodedFrame.SetTimestamp(frame.timestamp());
269 
270         GST_LOG_OBJECT(m_pipeline.get(), &quot;Got buffer capture_time_ms: %&quot; G_GINT64_FORMAT  &quot; _timestamp: %u&quot;,
271             m_encodedFrame.capture_time_ms_, m_encodedFrame.Timestamp());
272 
273         webrtc::CodecSpecificInfo codecInfo;
274         PopulateCodecSpecific(&amp;codecInfo, encodedBuffer);
275         webrtc::EncodedImageCallback::Result result = m_imageReadyCb-&gt;OnEncodedImage(m_encodedFrame, &amp;codecInfo, &amp;fragmentationInfo);
276         if (result.error != webrtc::EncodedImageCallback::Result::OK)
277             GST_ERROR_OBJECT(m_pipeline.get(), &quot;Encode callback failed: %d&quot;, result.error);
278 
279         return WEBRTC_VIDEO_CODEC_OK;
280     }
281 
282     GRefPtr&lt;GstElement&gt; createEncoder(void)
283     {
284         GRefPtr&lt;GstElement&gt; encoder = nullptr;
285         GstElement* webrtcencoder = GST_ELEMENT(g_object_ref_sink(gst_element_factory_make(&quot;webrtcvideoencoder&quot;, NULL)));
286 
287         g_object_set(webrtcencoder, &quot;format&quot;, adoptGRef(gst_caps_from_string(Caps())).get(), NULL);
288         g_object_get(webrtcencoder, &quot;encoder&quot;, &amp;encoder.outPtr(), NULL);
289 
290         if (!encoder) {
291             GST_INFO(&quot;No encoder found for %s&quot;, Caps());
292 
293             return nullptr;
294         }
295 
296         return webrtcencoder;
297     }
298 
299     void AddCodecIfSupported(std::vector&lt;webrtc::SdpVideoFormat&gt;* supportedFormats)
300     {
301         GstElement* encoder;
302 
303         if (createEncoder().get() != nullptr) {
304             webrtc::SdpVideoFormat format = ConfigureSupportedCodec(encoder);
305 
306             supportedFormats-&gt;push_back(format);
307         }
308     }
309 
310     virtual const gchar* Caps()
311     {
312         return nullptr;
313     }
314 
315     virtual webrtc::VideoCodecType CodecType() = 0;
316     virtual webrtc::SdpVideoFormat ConfigureSupportedCodec(GstElement*)
317     {
318         return webrtc::SdpVideoFormat(Name());
319     }
320 
321     virtual void PopulateCodecSpecific(webrtc::CodecSpecificInfo*, GstBuffer*) = 0;
322 
323     virtual void Fragmentize(webrtc::EncodedImage* encodedImage, std::unique_ptr&lt;uint8_t[]&gt;* encodedImageBuffer,
324         size_t* bufferSize, GstBuffer* buffer, webrtc::RTPFragmentationHeader* fragmentationInfo)
325     {
326         auto map = GstMappedBuffer::create(buffer, GST_MAP_READ);
327 
328         if (*bufferSize &lt; map-&gt;size()) {
<a name="13" id="anc13"></a><span class="line-modified">329             encodedImage-&gt;set_size(map-&gt;size());</span>
<span class="line-modified">330             encodedImage-&gt;set_buffer(new uint8_t[map-&gt;size()], map-&gt;size());</span>
<span class="line-modified">331             encodedImageBuffer-&gt;reset(encodedImage-&gt;data());</span>
332             *bufferSize = map-&gt;size();
333         }
334 
<a name="14" id="anc14"></a><span class="line-modified">335         memcpy(encodedImage-&gt;data(), map-&gt;data(), map-&gt;size());</span>
<span class="line-modified">336         encodedImage-&gt;set_size(map-&gt;size());</span>

337 
338         fragmentationInfo-&gt;VerifyAndAllocateFragmentationHeader(1);
339         fragmentationInfo-&gt;fragmentationOffset[0] = 0;
340         fragmentationInfo-&gt;fragmentationLength[0] = map-&gt;size();
<a name="15" id="anc15"></a>











341     }
342 
343     virtual const gchar* Name() = 0;
344     virtual int KeyframeInterval(const webrtc::VideoCodec* codecSettings) = 0;
345 
346     void SetRestrictionCaps(GRefPtr&lt;GstCaps&gt; caps)
347     {
348         if (m_restrictionCaps)
349             g_object_set(m_capsFilter, &quot;caps&quot;, m_restrictionCaps.get(), nullptr);
350 
351         m_restrictionCaps = caps;
352     }
353 
354 private:
355     GRefPtr&lt;GstElement&gt; m_pipeline;
356     GstElement* m_src;
357     GstElement* m_encoder;
358     GstElement* m_capsFilter;
359 
360     webrtc::EncodedImageCallback* m_imageReadyCb;
361     GstClockTime m_firstFramePts;
362     GRefPtr&lt;GstCaps&gt; m_restrictionCaps;
363     webrtc::EncodedImage m_encodedFrame;
364     std::unique_ptr&lt;uint8_t[]&gt; m_encodedImageBuffer;
365     size_t m_encodedImageBufferSize;
366 
367     Lock m_bufferMapLock;
368     GstElement* m_sink;
369 };
370 
371 class GStreamerH264Encoder : public GStreamerVideoEncoder {
372 public:
373     GStreamerH264Encoder() { }
374 
375     GStreamerH264Encoder(const webrtc::SdpVideoFormat&amp; format)
376         : m_parser(gst_h264_nal_parser_new())
377         , packetizationMode(webrtc::H264PacketizationMode::NonInterleaved)
378     {
379         auto it = format.parameters.find(cricket::kH264FmtpPacketizationMode);
380 
381         if (it != format.parameters.end() &amp;&amp; it-&gt;second == &quot;1&quot;)
382             packetizationMode = webrtc::H264PacketizationMode::NonInterleaved;
383     }
384 
385     int KeyframeInterval(const webrtc::VideoCodec* codecSettings) final
386     {
387         return codecSettings-&gt;H264().keyFrameInterval;
388     }
389 
390     // FIXME - MT. safety!
391     void Fragmentize(webrtc::EncodedImage* encodedImage, std::unique_ptr&lt;uint8_t[]&gt;* encodedImageBuffer, size_t *bufferSize,
392         GstBuffer* gstbuffer, webrtc::RTPFragmentationHeader* fragmentationHeader) final
393     {
394         GstH264NalUnit nalu;
395         auto parserResult = GST_H264_PARSER_OK;
396 
397         gsize offset = 0;
398         size_t requiredSize = 0;
399 
400         std::vector&lt;GstH264NalUnit&gt; nals;
401 
402         const uint8_t startCode[4] = { 0, 0, 0, 1 };
403         auto map = GstMappedBuffer::create(gstbuffer, GST_MAP_READ);
404         while (parserResult == GST_H264_PARSER_OK) {
405             parserResult = gst_h264_parser_identify_nalu(m_parser, map-&gt;data(), offset, map-&gt;size(), &amp;nalu);
406 
407             nalu.sc_offset = offset;
408             nalu.offset = offset + sizeof(startCode);
409             if (parserResult != GST_H264_PARSER_OK &amp;&amp; parserResult != GST_H264_PARSER_NO_NAL_END)
410                 break;
411 
412             requiredSize += nalu.size + sizeof(startCode);
413             nals.push_back(nalu);
414             offset = nalu.offset + nalu.size;
415         }
416 
<a name="16" id="anc16"></a><span class="line-modified">417         if (encodedImage-&gt;size() &lt; requiredSize) {</span>
<span class="line-modified">418             encodedImage-&gt;set_size(requiredSize);</span>
<span class="line-modified">419             encodedImage-&gt;set_buffer(new uint8_t[requiredSize], requiredSize);</span>
<span class="line-modified">420             encodedImageBuffer-&gt;reset(encodedImage-&gt;data());</span>
421             *bufferSize = map-&gt;size();
422         }
423 
424         // Iterate nal units and fill the Fragmentation info.
425         fragmentationHeader-&gt;VerifyAndAllocateFragmentationHeader(nals.size());
426         size_t fragmentIndex = 0;
<a name="17" id="anc17"></a><span class="line-modified">427         encodedImage-&gt;set_size(0);</span>
428         for (std::vector&lt;GstH264NalUnit&gt;::iterator nal = nals.begin(); nal != nals.end(); ++nal, fragmentIndex++) {
429 
430             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 0] == startCode[0]);
431             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 1] == startCode[1]);
432             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 2] == startCode[2]);
433             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 3] == startCode[3]);
434 
435             fragmentationHeader-&gt;fragmentationOffset[fragmentIndex] = nal-&gt;offset;
436             fragmentationHeader-&gt;fragmentationLength[fragmentIndex] = nal-&gt;size;
437 
<a name="18" id="anc18"></a><span class="line-modified">438             memcpy(encodedImage-&gt;data() + encodedImage-&gt;size(), &amp;map-&gt;data()[nal-&gt;sc_offset],</span>
439                 sizeof(startCode) + nal-&gt;size);
<a name="19" id="anc19"></a><span class="line-modified">440             encodedImage-&gt;set_size(nal-&gt;size + sizeof(startCode));</span>
441         }
442     }
443 
444     webrtc::SdpVideoFormat ConfigureSupportedCodec(GstElement*) final
445     {
446         // TODO- Create from encoder src pad caps template
447         return webrtc::SdpVideoFormat(cricket::kH264CodecName,
448             { { cricket::kH264FmtpProfileLevelId, cricket::kH264ProfileLevelConstrainedBaseline },
449                 { cricket::kH264FmtpLevelAsymmetryAllowed, &quot;1&quot; },
450                 { cricket::kH264FmtpPacketizationMode, &quot;1&quot; } });
451     }
452 
453     const gchar* Caps() final { return &quot;video/x-h264&quot;; }
454     const gchar* Name() final { return cricket::kH264CodecName; }
455     GstH264NalParser* m_parser;
456     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecH264; }
457 
458     void PopulateCodecSpecific(webrtc::CodecSpecificInfo* codecSpecificInfos, GstBuffer*) final
459     {
460         codecSpecificInfos-&gt;codecType = CodecType();
<a name="20" id="anc20"></a>
461         webrtc::CodecSpecificInfoH264* h264Info = &amp;(codecSpecificInfos-&gt;codecSpecific.H264);
462         h264Info-&gt;packetization_mode = packetizationMode;
463     }
464 
465     webrtc::H264PacketizationMode packetizationMode;
466 };
467 
468 class GStreamerVP8Encoder : public GStreamerVideoEncoder {
469 public:
470     GStreamerVP8Encoder() { }
471     GStreamerVP8Encoder(const webrtc::SdpVideoFormat&amp;) { }
472     const gchar* Caps() final { return &quot;video/x-vp8&quot;; }
473     const gchar* Name() final { return cricket::kVp8CodecName; }
474     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecVP8; }
475 
476     int KeyframeInterval(const webrtc::VideoCodec* codecSettings) final
477     {
478         return codecSettings-&gt;VP8().keyFrameInterval;
479     }
480 
481     void PopulateCodecSpecific(webrtc::CodecSpecificInfo* codecSpecificInfos, GstBuffer* buffer) final
482     {
483         codecSpecificInfos-&gt;codecType = webrtc::kVideoCodecVP8;
<a name="21" id="anc21"></a>
484         webrtc::CodecSpecificInfoVP8* vp8Info = &amp;(codecSpecificInfos-&gt;codecSpecific.VP8);
485         vp8Info-&gt;temporalIdx = 0;
486 
487         vp8Info-&gt;keyIdx = webrtc::kNoKeyIdx;
488         vp8Info-&gt;nonReference = GST_BUFFER_FLAG_IS_SET(buffer, GST_BUFFER_FLAG_DELTA_UNIT);
489     }
490 };
491 
492 std::unique_ptr&lt;webrtc::VideoEncoder&gt; GStreamerVideoEncoderFactory::CreateVideoEncoder(const webrtc::SdpVideoFormat&amp; format)
493 {
494     if (format.name == cricket::kVp8CodecName) {
495         GRefPtr&lt;GstElement&gt; webrtcencoder = adoptGRef(GST_ELEMENT(g_object_ref_sink(gst_element_factory_make(&quot;webrtcvideoencoder&quot;, NULL))));
496         GRefPtr&lt;GstElement&gt; encoder = nullptr;
497 
498         g_object_set(webrtcencoder.get(), &quot;format&quot;, adoptGRef(gst_caps_from_string(&quot;video/x-vp8&quot;)).get(), NULL);
499         g_object_get(webrtcencoder.get(), &quot;encoder&quot;, &amp;encoder.outPtr(), NULL);
500 
501         if (encoder)
502             return makeUnique&lt;GStreamerVP8Encoder&gt;(format);
503 
504         GST_INFO(&quot;Using VP8 Encoder from LibWebRTC.&quot;);
505         return makeUniqueWithoutFastMallocCheck&lt;webrtc::LibvpxVp8Encoder&gt;();
506     }
507 
508     if (format.name == cricket::kH264CodecName)
509         return makeUnique&lt;GStreamerH264Encoder&gt;(format);
510 
511     return nullptr;
512 }
513 
514 GStreamerVideoEncoderFactory::GStreamerVideoEncoderFactory()
515 {
516     static std::once_flag debugRegisteredFlag;
517 
518     std::call_once(debugRegisteredFlag, [] {
519         GST_DEBUG_CATEGORY_INIT(webkit_webrtcenc_debug, &quot;webkitlibwebrtcvideoencoder&quot;, 0, &quot;WebKit WebRTC video encoder&quot;);
520         gst_element_register(nullptr, &quot;webrtcvideoencoder&quot;, GST_RANK_PRIMARY, GST_TYPE_WEBRTC_VIDEO_ENCODER);
521     });
522 }
523 
524 std::vector&lt;webrtc::SdpVideoFormat&gt; GStreamerVideoEncoderFactory::GetSupportedFormats() const
525 {
526     std::vector&lt;webrtc::SdpVideoFormat&gt; supportedCodecs;
527 
528     supportedCodecs.push_back(webrtc::SdpVideoFormat(cricket::kVp8CodecName));
529     GStreamerH264Encoder().AddCodecIfSupported(&amp;supportedCodecs);
530 
531     return supportedCodecs;
532 }
533 
534 } // namespace WebCore
535 #endif
<a name="22" id="anc22"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="22" type="hidden" />
</body>
</html>