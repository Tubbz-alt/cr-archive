<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/Heap.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  *  Copyright (C) 1999-2000 Harri Porten (porten@kde.org)
  3  *  Copyright (C) 2001 Peter Kelly (pmk@post.com)
  4  *  Copyright (C) 2003-2019 Apple Inc. All rights reserved.
  5  *
  6  *  This library is free software; you can redistribute it and/or
  7  *  modify it under the terms of the GNU Lesser General Public
  8  *  License as published by the Free Software Foundation; either
  9  *  version 2 of the License, or (at your option) any later version.
 10  *
 11  *  This library is distributed in the hope that it will be useful,
 12  *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 13  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 14  *  Lesser General Public License for more details.
 15  *
 16  *  You should have received a copy of the GNU Lesser General Public
 17  *  License along with this library; if not, write to the Free Software
 18  *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
 19  *
 20  */
 21 
 22 #pragma once
 23 
 24 #include &quot;ArrayBuffer.h&quot;
 25 #include &quot;CellState.h&quot;
 26 #include &quot;CollectionScope.h&quot;
 27 #include &quot;CollectorPhase.h&quot;
 28 #include &quot;DeleteAllCodeEffort.h&quot;
 29 #include &quot;GCConductor.h&quot;
 30 #include &quot;GCIncomingRefCountedSet.h&quot;
<a name="1" id="anc1"></a><span class="line-added"> 31 #include &quot;GCMemoryOperations.h&quot;</span>
 32 #include &quot;GCRequest.h&quot;
 33 #include &quot;HandleSet.h&quot;
 34 #include &quot;HeapFinalizerCallback.h&quot;
 35 #include &quot;HeapObserver.h&quot;
 36 #include &quot;MarkedBlock.h&quot;
 37 #include &quot;MarkedSpace.h&quot;
 38 #include &quot;MutatorState.h&quot;
 39 #include &quot;Options.h&quot;
 40 #include &quot;StructureIDTable.h&quot;
 41 #include &quot;Synchronousness.h&quot;
 42 #include &quot;WeakHandleOwner.h&quot;
 43 #include &lt;wtf/AutomaticThread.h&gt;
 44 #include &lt;wtf/ConcurrentPtrHashSet.h&gt;
 45 #include &lt;wtf/Deque.h&gt;
 46 #include &lt;wtf/HashCountedSet.h&gt;
 47 #include &lt;wtf/HashSet.h&gt;
 48 #include &lt;wtf/Markable.h&gt;
 49 #include &lt;wtf/ParallelHelperPool.h&gt;
 50 #include &lt;wtf/Threading.h&gt;
 51 
 52 namespace JSC {
 53 
 54 class CodeBlock;
 55 class CodeBlockSet;
 56 class CollectingScope;
 57 class ConservativeRoots;
 58 class GCDeferralContext;
 59 class EdenGCActivityCallback;
 60 class FullGCActivityCallback;
 61 class GCActivityCallback;
 62 class GCAwareJITStubRoutine;
 63 class Heap;
 64 class HeapProfiler;
 65 class HeapVerifier;
 66 class IncrementalSweeper;
 67 class JITStubRoutine;
 68 class JITStubRoutineSet;
 69 class JSCell;
 70 class JSImmutableButterfly;
 71 class JSValue;
 72 class LLIntOffsetsExtractor;
 73 class MachineThreads;
 74 class MarkStackArray;
 75 class MarkStackMergingConstraint;
 76 class BlockDirectory;
 77 class MarkedArgumentBuffer;
 78 class MarkingConstraint;
 79 class MarkingConstraintSet;
 80 class MutatorScheduler;
 81 class RunningScope;
 82 class SlotVisitor;
 83 class SpaceTimeMutatorScheduler;
 84 class StopIfNecessaryTimer;
 85 class SweepingScope;
 86 class VM;
 87 class WeakGCMapBase;
 88 struct CurrentThreadState;
 89 
 90 #ifdef JSC_GLIB_API_ENABLED
 91 class JSCGLibWrapperObject;
 92 #endif
 93 
 94 namespace DFG {
 95 class SpeculativeJIT;
 96 class Worklist;
 97 }
 98 
<a name="2" id="anc2"></a><span class="line-modified"> 99 #define ENABLE_DFG_DOES_GC_VALIDATION ASSERT_ENABLED</span>




100 constexpr bool validateDFGDoesGC = ENABLE_DFG_DOES_GC_VALIDATION;
101 
102 typedef HashCountedSet&lt;JSCell*&gt; ProtectCountSet;
103 typedef HashCountedSet&lt;const char*&gt; TypeCountSet;
104 
105 enum HeapType { SmallHeap, LargeHeap };
106 
107 class HeapUtil;
108 
109 class Heap {
110     WTF_MAKE_NONCOPYABLE(Heap);
111 public:
112     friend class JIT;
113     friend class DFG::SpeculativeJIT;
114     static Heap* heap(const JSValue); // 0 for immediate values
115     static Heap* heap(const HeapCell*);
116 
117     // This constant determines how many blocks we iterate between checks of our
118     // deadline when calling Heap::isPagedOut. Decreasing it will cause us to detect
119     // overstepping our deadline more quickly, while increasing it will cause
120     // our scan to run faster.
<a name="3" id="anc3"></a><span class="line-modified">121     static constexpr unsigned s_timeCheckResolution = 16;</span>
122 
123     bool isMarked(const void*);
124     static bool testAndSetMarked(HeapVersion, const void*);
125 
126     static size_t cellSize(const void*);
127 
128     void writeBarrier(const JSCell* from);
129     void writeBarrier(const JSCell* from, JSValue to);
130     void writeBarrier(const JSCell* from, JSCell* to);
131 
132     void writeBarrierWithoutFence(const JSCell* from);
133 
134     void mutatorFence();
135 
136     // Take this if you know that from-&gt;cellState() &lt; barrierThreshold.
137     JS_EXPORT_PRIVATE void writeBarrierSlowPath(const JSCell* from);
138 
139     Heap(VM&amp;, HeapType);
140     ~Heap();
141     void lastChanceToFinalize();
142     void releaseDelayedReleasedObjects();
143 
144     VM&amp; vm() const;
145 
146     MarkedSpace&amp; objectSpace() { return m_objectSpace; }
147     MachineThreads&amp; machineThreads() { return *m_machineThreads; }
148 
149     SlotVisitor&amp; collectorSlotVisitor() { return *m_collectorSlotVisitor; }
150 
151     JS_EXPORT_PRIVATE GCActivityCallback* fullActivityCallback();
152     JS_EXPORT_PRIVATE GCActivityCallback* edenActivityCallback();
153     JS_EXPORT_PRIVATE void setGarbageCollectionTimerEnabled(bool);
154 
155     JS_EXPORT_PRIVATE IncrementalSweeper&amp; sweeper();
156 
157     void addObserver(HeapObserver* observer) { m_observers.append(observer); }
158     void removeObserver(HeapObserver* observer) { m_observers.removeFirst(observer); }
159 
160     MutatorState mutatorState() const { return m_mutatorState; }
161     Optional&lt;CollectionScope&gt; collectionScope() const { return m_collectionScope; }
162     bool hasHeapAccess() const;
163     bool worldIsStopped() const;
164     bool worldIsRunning() const { return !worldIsStopped(); }
165 
166     // We&#39;re always busy on the collection threads. On the main thread, this returns true if we&#39;re
167     // helping heap.
168     JS_EXPORT_PRIVATE bool isCurrentThreadBusy();
169 
<a name="4" id="anc4"></a><span class="line-modified">170     typedef void (*CFinalizer)(JSCell*);</span>
<span class="line-modified">171     JS_EXPORT_PRIVATE void addFinalizer(JSCell*, CFinalizer);</span>
<span class="line-added">172     using LambdaFinalizer = WTF::Function&lt;void(JSCell*)&gt;;</span>
<span class="line-added">173     JS_EXPORT_PRIVATE void addFinalizer(JSCell*, LambdaFinalizer);</span>
174 
175     void notifyIsSafeToCollect();
176     bool isSafeToCollect() const { return m_isSafeToCollect; }
177 
178     bool isShuttingDown() const { return m_isShuttingDown; }
179 
180     JS_EXPORT_PRIVATE bool isAnalyzingHeap() const;
181 
182     JS_EXPORT_PRIVATE void sweepSynchronously();
183 
184     bool shouldCollectHeuristic();
185 
186     // Queue up a collection. Returns immediately. This will not queue a collection if a collection
187     // of equal or greater strength exists. Full collections are stronger than WTF::nullopt collections
188     // and WTF::nullopt collections are stronger than Eden collections. WTF::nullopt means that the GC can
189     // choose Eden or Full. This implies that if you request a GC while that GC is ongoing, nothing
190     // will happen.
191     JS_EXPORT_PRIVATE void collectAsync(GCRequest = GCRequest());
192 
193     // Queue up a collection and wait for it to complete. This won&#39;t return until you get your own
194     // complete collection. For example, if there was an ongoing asynchronous collection at the time
195     // you called this, then this would wait for that one to complete and then trigger your
196     // collection and then return. In weird cases, there could be multiple GC requests in the backlog
197     // and this will wait for that backlog before running its GC and returning.
198     JS_EXPORT_PRIVATE void collectSync(GCRequest = GCRequest());
199 
200     JS_EXPORT_PRIVATE void collect(Synchronousness, GCRequest = GCRequest());
201 
202     // Like collect(), but in the case of Async this will stopIfNecessary() and in the case of
203     // Sync this will sweep synchronously.
204     JS_EXPORT_PRIVATE void collectNow(Synchronousness, GCRequest = GCRequest());
205 
206     JS_EXPORT_PRIVATE void collectNowFullIfNotDoneRecently(Synchronousness);
207 
208     void collectIfNecessaryOrDefer(GCDeferralContext* = nullptr);
209 
210     void completeAllJITPlans();
211 
212     // Use this API to report non-GC memory referenced by GC objects. Be sure to
213     // call both of these functions: Calling only one may trigger catastropic
214     // memory growth.
215     void reportExtraMemoryAllocated(size_t);
216     JS_EXPORT_PRIVATE void reportExtraMemoryVisited(size_t);
217 
218 #if ENABLE(RESOURCE_USAGE)
219     // Use this API to report the subset of extra memory that lives outside this process.
220     JS_EXPORT_PRIVATE void reportExternalMemoryVisited(size_t);
221     size_t externalMemorySize() { return m_externalMemorySize; }
222 #endif
223 
224     // Use this API to report non-GC memory if you can&#39;t use the better API above.
225     void deprecatedReportExtraMemory(size_t);
226 
227     JS_EXPORT_PRIVATE void reportAbandonedObjectGraph();
228 
229     JS_EXPORT_PRIVATE void protect(JSValue);
230     JS_EXPORT_PRIVATE bool unprotect(JSValue); // True when the protect count drops to 0.
231 
232     JS_EXPORT_PRIVATE size_t extraMemorySize(); // Non-GC memory referenced by GC objects.
233     JS_EXPORT_PRIVATE size_t size();
234     JS_EXPORT_PRIVATE size_t capacity();
235     JS_EXPORT_PRIVATE size_t objectCount();
236     JS_EXPORT_PRIVATE size_t globalObjectCount();
237     JS_EXPORT_PRIVATE size_t protectedObjectCount();
238     JS_EXPORT_PRIVATE size_t protectedGlobalObjectCount();
239     JS_EXPORT_PRIVATE std::unique_ptr&lt;TypeCountSet&gt; protectedObjectTypeCounts();
240     JS_EXPORT_PRIVATE std::unique_ptr&lt;TypeCountSet&gt; objectTypeCounts();
241 
242     HashSet&lt;MarkedArgumentBuffer*&gt;&amp; markListSet();
243 
244     template&lt;typename Functor&gt; void forEachProtectedCell(const Functor&amp;);
245     template&lt;typename Functor&gt; void forEachCodeBlock(const Functor&amp;);
246     template&lt;typename Functor&gt; void forEachCodeBlockIgnoringJITPlans(const AbstractLocker&amp; codeBlockSetLocker, const Functor&amp;);
247 
248     HandleSet* handleSet() { return &amp;m_handleSet; }
249 
250     void willStartIterating();
251     void didFinishIterating();
252 
253     Seconds lastFullGCLength() const { return m_lastFullGCLength; }
254     Seconds lastEdenGCLength() const { return m_lastEdenGCLength; }
255     void increaseLastFullGCLength(Seconds amount) { m_lastFullGCLength += amount; }
256 
257     size_t sizeBeforeLastEdenCollection() const { return m_sizeBeforeLastEdenCollect; }
258     size_t sizeAfterLastEdenCollection() const { return m_sizeAfterLastEdenCollect; }
259     size_t sizeBeforeLastFullCollection() const { return m_sizeBeforeLastFullCollect; }
260     size_t sizeAfterLastFullCollection() const { return m_sizeAfterLastFullCollect; }
261 
262     void deleteAllCodeBlocks(DeleteAllCodeEffort);
263     void deleteAllUnlinkedCodeBlocks(DeleteAllCodeEffort);
264 
265     void didAllocate(size_t);
266     bool isPagedOut(MonotonicTime deadline);
267 
268     const JITStubRoutineSet&amp; jitStubRoutines() { return *m_jitStubRoutines; }
269 
270     void addReference(JSCell*, ArrayBuffer*);
271 
272     bool isDeferred() const { return !!m_deferralDepth; }
273 
274     StructureIDTable&amp; structureIDTable() { return m_structureIDTable; }
275 
276     CodeBlockSet&amp; codeBlockSet() { return *m_codeBlocks; }
277 
278 #if USE(FOUNDATION)
279     template&lt;typename T&gt; void releaseSoon(RetainPtr&lt;T&gt;&amp;&amp;);
280 #endif
281 #ifdef JSC_GLIB_API_ENABLED
282     void releaseSoon(std::unique_ptr&lt;JSCGLibWrapperObject&gt;&amp;&amp;);
283 #endif
284 
285     JS_EXPORT_PRIVATE void registerWeakGCMap(WeakGCMapBase* weakGCMap);
286     JS_EXPORT_PRIVATE void unregisterWeakGCMap(WeakGCMapBase* weakGCMap);
287 
288     void addLogicallyEmptyWeakBlock(WeakBlock*);
289 
290 #if ENABLE(RESOURCE_USAGE)
291     size_t blockBytesAllocated() const { return m_blockBytesAllocated; }
292 #endif
293 
294     void didAllocateBlock(size_t capacity);
295     void didFreeBlock(size_t capacity);
296 
297     bool mutatorShouldBeFenced() const { return m_mutatorShouldBeFenced; }
298     const bool* addressOfMutatorShouldBeFenced() const { return &amp;m_mutatorShouldBeFenced; }
299 
300     unsigned barrierThreshold() const { return m_barrierThreshold; }
301     const unsigned* addressOfBarrierThreshold() const { return &amp;m_barrierThreshold; }
302 
303 #if ENABLE(DFG_DOES_GC_VALIDATION)
304     bool expectDoesGC() const { return m_expectDoesGC; }
305     void setExpectDoesGC(bool value) { m_expectDoesGC = value; }
306     bool* addressOfExpectDoesGC() { return &amp;m_expectDoesGC; }
307 #else
308     bool expectDoesGC() const { UNREACHABLE_FOR_PLATFORM(); return true; }
309     void setExpectDoesGC(bool) { UNREACHABLE_FOR_PLATFORM(); }
310     bool* addressOfExpectDoesGC() { UNREACHABLE_FOR_PLATFORM(); return nullptr; }
311 #endif
312 
313     // If true, the GC believes that the mutator is currently messing with the heap. We call this
314     // &quot;having heap access&quot;. The GC may block if the mutator is in this state. If false, the GC may
315     // currently be doing things to the heap that make the heap unsafe to access for the mutator.
316     bool hasAccess() const;
317 
318     // If the mutator does not currently have heap access, this function will acquire it. If the GC
319     // is currently using the lack of heap access to do dangerous things to the heap then this
320     // function will block, waiting for the GC to finish. It&#39;s not valid to call this if the mutator
321     // already has heap access. The mutator is required to precisely track whether or not it has
322     // heap access.
323     //
324     // It&#39;s totally fine to acquireAccess() upon VM instantiation and keep it that way. This is how
325     // WebCore uses us. For most other clients, JSLock does acquireAccess()/releaseAccess() for you.
326     void acquireAccess();
327 
328     // Releases heap access. If the GC is blocking waiting to do bad things to the heap, it will be
329     // allowed to run now.
330     //
331     // Ordinarily, you should use the ReleaseHeapAccessScope to release and then reacquire heap
332     // access. You should do this anytime you&#39;re about do perform a blocking operation, like waiting
333     // on the ParkingLot.
334     void releaseAccess();
335 
336     // This is like a super optimized way of saying:
337     //
338     //     releaseAccess()
339     //     acquireAccess()
340     //
341     // The fast path is an inlined relaxed load and branch. The slow path will block the mutator if
342     // the GC wants to do bad things to the heap.
343     //
344     // All allocations logically call this. As an optimization to improve GC progress, you can call
345     // this anywhere that you can afford a load-branch and where an object allocation would have been
346     // safe.
347     //
348     // The GC will also push a stopIfNecessary() event onto the runloop of the thread that
349     // instantiated the VM whenever it wants the mutator to stop. This means that if you never block
350     // but instead use the runloop to wait for events, then you could safely run in a mode where the
351     // mutator has permanent heap access (like the DOM does). If you have good event handling
352     // discipline (i.e. you don&#39;t block the runloop) then you can be sure that stopIfNecessary() will
353     // already be called for you at the right times.
354     void stopIfNecessary();
355 
356     // This gives the conn to the collector.
357     void relinquishConn();
358 
359     bool mayNeedToStop();
360 
361     void performIncrement(size_t bytes);
362 
363     // This is a much stronger kind of stopping of the collector, and it may require waiting for a
364     // while. This is meant to be a legacy API for clients of collectAllGarbage that expect that there
365     // is no GC before or after that function call. After calling this, you are free to start GCs
366     // yourself but you can be sure that none are running.
367     //
368     // This both prevents new collections from being started asynchronously and waits for any
369     // outstanding collections to complete.
370     void preventCollection();
371     void allowCollection();
372 
373     uint64_t mutatorExecutionVersion() const { return m_mutatorExecutionVersion; }
374     uint64_t phaseVersion() const { return m_phaseVersion; }
375 
376     JS_EXPORT_PRIVATE void addMarkingConstraint(std::unique_ptr&lt;MarkingConstraint&gt;);
377 
378     size_t numOpaqueRoots() const { return m_opaqueRoots.size(); }
379 
380     HeapVerifier* verifier() const { return m_verifier.get(); }
381 
382     void addHeapFinalizerCallback(const HeapFinalizerCallback&amp;);
383     void removeHeapFinalizerCallback(const HeapFinalizerCallback&amp;);
384 
385     void runTaskInParallel(RefPtr&lt;SharedTask&lt;void(SlotVisitor&amp;)&gt;&gt;);
386 
387     template&lt;typename Func&gt;
388     void runFunctionInParallel(const Func&amp; func)
389     {
390         runTaskInParallel(createSharedTask&lt;void(SlotVisitor&amp;)&gt;(func));
391     }
392 
393     template&lt;typename Func&gt;
394     void forEachSlotVisitor(const Func&amp;);
395 
396     Seconds totalGCTime() const { return m_totalGCTime; }
397 
398     HashMap&lt;JSImmutableButterfly*, JSString*&gt; immutableButterflyToStringCache;
399 
400 private:
401     friend class AllocatingScope;
402     friend class CodeBlock;
403     friend class CollectingScope;
404     friend class DeferGC;
405     friend class DeferGCForAWhile;
406     friend class GCAwareJITStubRoutine;
407     friend class GCLogging;
408     friend class GCThread;
409     friend class HandleSet;
410     friend class HeapUtil;
411     friend class HeapVerifier;
412     friend class JITStubRoutine;
413     friend class LLIntOffsetsExtractor;
414     friend class MarkStackMergingConstraint;
415     friend class MarkedSpace;
416     friend class BlockDirectory;
417     friend class MarkedBlock;
418     friend class RunningScope;
419     friend class SlotVisitor;
420     friend class SpaceTimeMutatorScheduler;
421     friend class StochasticSpaceTimeMutatorScheduler;
422     friend class SweepingScope;
423     friend class IncrementalSweeper;
424     friend class VM;
425     friend class WeakSet;
426 
427     class HeapThread;
428     friend class HeapThread;
429 
<a name="5" id="anc5"></a><span class="line-modified">430     static constexpr size_t minExtraMemory = 256;</span>
<span class="line-added">431 </span>
<span class="line-added">432     class CFinalizerOwner : public WeakHandleOwner {</span>
<span class="line-added">433         void finalize(Handle&lt;Unknown&gt;, void* context) override;</span>
<span class="line-added">434     };</span>
435 
<a name="6" id="anc6"></a><span class="line-modified">436     class LambdaFinalizerOwner : public WeakHandleOwner {</span>
437         void finalize(Handle&lt;Unknown&gt;, void* context) override;
438     };
439 
440     JS_EXPORT_PRIVATE bool isValidAllocation(size_t);
441     JS_EXPORT_PRIVATE void reportExtraMemoryAllocatedSlowCase(size_t);
442     JS_EXPORT_PRIVATE void deprecatedReportExtraMemorySlowCase(size_t);
443 
444     bool shouldCollectInCollectorThread(const AbstractLocker&amp;);
445     void collectInCollectorThread();
446 
447     void checkConn(GCConductor);
448 
449     enum class RunCurrentPhaseResult {
450         Finished,
451         Continue,
452         NeedCurrentThreadState
453     };
454     RunCurrentPhaseResult runCurrentPhase(GCConductor, CurrentThreadState*);
455 
456     // Returns true if we should keep doing things.
457     bool runNotRunningPhase(GCConductor);
458     bool runBeginPhase(GCConductor);
459     bool runFixpointPhase(GCConductor);
460     bool runConcurrentPhase(GCConductor);
461     bool runReloopPhase(GCConductor);
462     bool runEndPhase(GCConductor);
463     bool changePhase(GCConductor, CollectorPhase);
464     bool finishChangingPhase(GCConductor);
465 
466     void collectInMutatorThread();
467 
468     void stopThePeriphery(GCConductor);
469     void resumeThePeriphery();
470 
471     // Returns true if the mutator is stopped, false if the mutator has the conn now.
472     bool stopTheMutator();
473     void resumeTheMutator();
474 
475     JS_EXPORT_PRIVATE void stopIfNecessarySlow();
476     bool stopIfNecessarySlow(unsigned extraStateBits);
477 
478     template&lt;typename Func&gt;
479     void waitForCollector(const Func&amp;);
480 
481     JS_EXPORT_PRIVATE void acquireAccessSlow();
482     JS_EXPORT_PRIVATE void releaseAccessSlow();
483 
484     bool handleGCDidJIT(unsigned);
485     void handleGCDidJIT();
486 
487     bool handleNeedFinalize(unsigned);
488     void handleNeedFinalize();
489 
490     bool relinquishConn(unsigned);
491     void finishRelinquishingConn();
492 
493     void setGCDidJIT();
494     void setNeedFinalize();
495     void waitWhileNeedFinalize();
496 
497     void setMutatorWaiting();
498     void clearMutatorWaiting();
499     void notifyThreadStopping(const AbstractLocker&amp;);
500 
501     typedef uint64_t Ticket;
502     Ticket requestCollection(GCRequest);
503     void waitForCollection(Ticket);
504 
505     void suspendCompilerThreads();
506     void willStartCollection();
507     void prepareForMarking();
508 
509     void gatherStackRoots(ConservativeRoots&amp;);
510     void gatherJSStackRoots(ConservativeRoots&amp;);
511     void gatherScratchBufferRoots(ConservativeRoots&amp;);
512     void beginMarking();
513     void visitCompilerWorklistWeakReferences();
514     void removeDeadCompilerWorklistEntries();
515     void updateObjectCounts();
516     void endMarking();
517 
518     void reapWeakHandles();
519     void pruneStaleEntriesFromWeakGCMaps();
520     void sweepArrayBuffers();
521     void snapshotUnswept();
522     void deleteSourceProviderCaches();
523     void notifyIncrementalSweeper();
524     void harvestWeakReferences();
525 
526     template&lt;typename CellType, typename CellSet&gt;
527     void finalizeMarkedUnconditionalFinalizers(CellSet&amp;);
528 
529     void finalizeUnconditionalFinalizers();
530 
531     void deleteUnmarkedCompiledCode();
532     JS_EXPORT_PRIVATE void addToRememberedSet(const JSCell*);
533     void updateAllocationLimits();
534     void didFinishCollection();
535     void resumeCompilerThreads();
536     void gatherExtraHeapData(HeapProfiler&amp;);
537     void removeDeadHeapSnapshotNodes(HeapProfiler&amp;);
538     void finalize();
539     void sweepInFinalize();
540 
541     void sweepAllLogicallyEmptyWeakBlocks();
542     bool sweepNextLogicallyEmptyWeakBlock();
543 
544     bool shouldDoFullCollection();
545 
546     void incrementDeferralDepth();
547     void decrementDeferralDepth();
548     void decrementDeferralDepthAndGCIfNeeded();
549     JS_EXPORT_PRIVATE void decrementDeferralDepthAndGCIfNeededSlow();
550 
551     size_t visitCount();
552     size_t bytesVisited();
553 
554     void forEachCodeBlockImpl(const ScopedLambda&lt;void(CodeBlock*)&gt;&amp;);
555     void forEachCodeBlockIgnoringJITPlansImpl(const AbstractLocker&amp; codeBlockSetLocker, const ScopedLambda&lt;void(CodeBlock*)&gt;&amp;);
556 
557     void setMutatorShouldBeFenced(bool value);
558 
559     void addCoreConstraints();
560 
561     enum class MemoryThresholdCallType {
562         Cached,
563         Direct
564     };
565 
566     bool overCriticalMemoryThreshold(MemoryThresholdCallType memoryThresholdCallType = MemoryThresholdCallType::Cached);
567 
568     template&lt;typename Func&gt;
569     void iterateExecutingAndCompilingCodeBlocks(const Func&amp;);
570 
571     template&lt;typename Func&gt;
572     void iterateExecutingAndCompilingCodeBlocksWithoutHoldingLocks(const Func&amp;);
573 
574     void assertMarkStacksEmpty();
575 
576     void setBonusVisitorTask(RefPtr&lt;SharedTask&lt;void(SlotVisitor&amp;)&gt;&gt;);
577 
578     void dumpHeapStatisticsAtVMDestruction();
579 
580     static bool useGenerationalGC();
581     static bool shouldSweepSynchronously();
582 
583     const HeapType m_heapType;
584     MutatorState m_mutatorState { MutatorState::Running };
585     const size_t m_ramSize;
586     const size_t m_minBytesPerCycle;
587     size_t m_sizeAfterLastCollect { 0 };
588     size_t m_sizeAfterLastFullCollect { 0 };
589     size_t m_sizeBeforeLastFullCollect { 0 };
590     size_t m_sizeAfterLastEdenCollect { 0 };
591     size_t m_sizeBeforeLastEdenCollect { 0 };
592 
593     size_t m_bytesAllocatedThisCycle { 0 };
594     size_t m_bytesAbandonedSinceLastFullCollect { 0 };
595     size_t m_maxEdenSize;
596     size_t m_maxEdenSizeWhenCritical;
597     size_t m_maxHeapSize;
598     size_t m_totalBytesVisited { 0 };
599     size_t m_totalBytesVisitedThisCycle { 0 };
600     double m_incrementBalance { 0 };
601 
602     bool m_shouldDoFullCollection { false };
603     Markable&lt;CollectionScope, EnumMarkableTraits&lt;CollectionScope&gt;&gt; m_collectionScope;
604     Markable&lt;CollectionScope, EnumMarkableTraits&lt;CollectionScope&gt;&gt; m_lastCollectionScope;
605     Lock m_raceMarkStackLock;
606 #if ENABLE(DFG_DOES_GC_VALIDATION)
607     bool m_expectDoesGC { true };
608 #endif
609 
610     StructureIDTable m_structureIDTable;
611     MarkedSpace m_objectSpace;
612     GCIncomingRefCountedSet&lt;ArrayBuffer&gt; m_arrayBuffers;
613     size_t m_extraMemorySize { 0 };
614     size_t m_deprecatedExtraMemorySize { 0 };
615 
616     HashSet&lt;const JSCell*&gt; m_copyingRememberedSet;
617 
618     ProtectCountSet m_protectedValues;
619     std::unique_ptr&lt;HashSet&lt;MarkedArgumentBuffer*&gt;&gt; m_markListSet;
620 
621     std::unique_ptr&lt;MachineThreads&gt; m_machineThreads;
622 
623     std::unique_ptr&lt;SlotVisitor&gt; m_collectorSlotVisitor;
624     std::unique_ptr&lt;SlotVisitor&gt; m_mutatorSlotVisitor;
625     std::unique_ptr&lt;MarkStackArray&gt; m_mutatorMarkStack;
626     std::unique_ptr&lt;MarkStackArray&gt; m_raceMarkStack;
627     std::unique_ptr&lt;MarkingConstraintSet&gt; m_constraintSet;
628 
629     // We pool the slot visitors used by parallel marking threads. It&#39;s useful to be able to
630     // enumerate over them, and it&#39;s useful to have them cache some small amount of memory from
631     // one GC to the next. GC marking threads claim these at the start of marking, and return
632     // them at the end.
633     Vector&lt;std::unique_ptr&lt;SlotVisitor&gt;&gt; m_parallelSlotVisitors;
634     Vector&lt;SlotVisitor*&gt; m_availableParallelSlotVisitors;
635 
636     HandleSet m_handleSet;
637     std::unique_ptr&lt;CodeBlockSet&gt; m_codeBlocks;
638     std::unique_ptr&lt;JITStubRoutineSet&gt; m_jitStubRoutines;
<a name="7" id="anc7"></a><span class="line-modified">639     CFinalizerOwner m_cFinalizerOwner;</span>
<span class="line-added">640     LambdaFinalizerOwner m_lambdaFinalizerOwner;</span>
641 
642     Lock m_parallelSlotVisitorLock;
643     bool m_isSafeToCollect { false };
644     bool m_isShuttingDown { false };
645     bool m_mutatorShouldBeFenced { Options::forceFencedBarrier() };
646 
647     unsigned m_barrierThreshold { Options::forceFencedBarrier() ? tautologicalThreshold : blackThreshold };
648 
649     VM&amp; m_vm;
650     Seconds m_lastFullGCLength { 10_ms };
651     Seconds m_lastEdenGCLength { 10_ms };
652 
653     Vector&lt;WeakBlock*&gt; m_logicallyEmptyWeakBlocks;
654     size_t m_indexOfNextLogicallyEmptyWeakBlockToSweep { WTF::notFound };
655 
656     RefPtr&lt;FullGCActivityCallback&gt; m_fullActivityCallback;
657     RefPtr&lt;GCActivityCallback&gt; m_edenActivityCallback;
658     Ref&lt;IncrementalSweeper&gt; m_sweeper;
659     Ref&lt;StopIfNecessaryTimer&gt; m_stopIfNecessaryTimer;
660 
661     Vector&lt;HeapObserver*&gt; m_observers;
662 
663     Vector&lt;HeapFinalizerCallback&gt; m_heapFinalizerCallbacks;
664 
665     std::unique_ptr&lt;HeapVerifier&gt; m_verifier;
666 
667 #if USE(FOUNDATION)
668     Vector&lt;RetainPtr&lt;CFTypeRef&gt;&gt; m_delayedReleaseObjects;
669     unsigned m_delayedReleaseRecursionCount { 0 };
670 #endif
671 #ifdef JSC_GLIB_API_ENABLED
672     Vector&lt;std::unique_ptr&lt;JSCGLibWrapperObject&gt;&gt; m_delayedReleaseObjects;
673     unsigned m_delayedReleaseRecursionCount { 0 };
674 #endif
675     unsigned m_deferralDepth { 0 };
676 
677     HashSet&lt;WeakGCMapBase*&gt; m_weakGCMaps;
678 
679     std::unique_ptr&lt;MarkStackArray&gt; m_sharedCollectorMarkStack;
680     std::unique_ptr&lt;MarkStackArray&gt; m_sharedMutatorMarkStack;
681     unsigned m_numberOfActiveParallelMarkers { 0 };
682     unsigned m_numberOfWaitingParallelMarkers { 0 };
683 
684     ConcurrentPtrHashSet m_opaqueRoots;
<a name="8" id="anc8"></a><span class="line-modified">685     static constexpr size_t s_blockFragmentLength = 32;</span>
686 
687     ParallelHelperClient m_helperClient;
688     RefPtr&lt;SharedTask&lt;void(SlotVisitor&amp;)&gt;&gt; m_bonusVisitorTask;
689 
690 #if ENABLE(RESOURCE_USAGE)
691     size_t m_blockBytesAllocated { 0 };
692     size_t m_externalMemorySize { 0 };
693 #endif
694 
695     std::unique_ptr&lt;MutatorScheduler&gt; m_scheduler;
696 
<a name="9" id="anc9"></a><span class="line-modified">697     static constexpr unsigned mutatorHasConnBit = 1u &lt;&lt; 0u; // Must also be protected by threadLock.</span>
<span class="line-modified">698     static constexpr unsigned stoppedBit = 1u &lt;&lt; 1u; // Only set when !hasAccessBit</span>
<span class="line-modified">699     static constexpr unsigned hasAccessBit = 1u &lt;&lt; 2u;</span>
<span class="line-modified">700     static constexpr unsigned gcDidJITBit = 1u &lt;&lt; 3u; // Set when the GC did some JITing, so on resume we need to cpuid.</span>
<span class="line-modified">701     static constexpr unsigned needFinalizeBit = 1u &lt;&lt; 4u;</span>
<span class="line-modified">702     static constexpr unsigned mutatorWaitingBit = 1u &lt;&lt; 5u; // Allows the mutator to use this as a condition variable.</span>
703     Atomic&lt;unsigned&gt; m_worldState;
704     bool m_worldIsStopped { false };
705     Lock m_visitRaceLock;
706     Lock m_markingMutex;
707     Condition m_markingConditionVariable;
708 
709     MonotonicTime m_beforeGC;
710     MonotonicTime m_afterGC;
711     MonotonicTime m_stopTime;
712 
713     Deque&lt;GCRequest&gt; m_requests;
714     GCRequest m_currentRequest;
715     Ticket m_lastServedTicket { 0 };
716     Ticket m_lastGrantedTicket { 0 };
717 
718     CollectorPhase m_lastPhase { CollectorPhase::NotRunning };
719     CollectorPhase m_currentPhase { CollectorPhase::NotRunning };
720     CollectorPhase m_nextPhase { CollectorPhase::NotRunning };
721     bool m_collectorThreadIsRunning { false };
722     bool m_threadShouldStop { false };
723     bool m_threadIsStopping { false };
724     bool m_mutatorDidRun { true };
725     bool m_didDeferGCWork { false };
726     bool m_shouldStopCollectingContinuously { false };
727 
728     uint64_t m_mutatorExecutionVersion { 0 };
729     uint64_t m_phaseVersion { 0 };
730     Box&lt;Lock&gt; m_threadLock;
731     Ref&lt;AutomaticThreadCondition&gt; m_threadCondition; // The mutator must not wait on this. It would cause a deadlock.
732     RefPtr&lt;AutomaticThread&gt; m_thread;
733 
734     RefPtr&lt;Thread&gt; m_collectContinuouslyThread { nullptr };
735 
736     MonotonicTime m_lastGCStartTime;
737     MonotonicTime m_lastGCEndTime;
738     MonotonicTime m_currentGCStartTime;
739     Seconds m_totalGCTime;
740 
741     uintptr_t m_barriersExecuted { 0 };
742 
743     CurrentThreadState* m_currentThreadState { nullptr };
744     Thread* m_currentThread { nullptr }; // It&#39;s OK if this becomes a dangling pointer.
745 
<a name="10" id="anc10"></a><span class="line-modified">746 #if USE(BMALLOC_MEMORY_FOOTPRINT_API)</span>
<span class="line-modified">747     unsigned m_percentAvailableMemoryCachedCallCount { 0 };</span>
<span class="line-modified">748     bool m_overCriticalMemoryThreshold { false };</span>
749 #endif
750 
751     bool m_parallelMarkersShouldExit { false };
752     Lock m_collectContinuouslyLock;
753     Condition m_collectContinuouslyCondition;
754 };
755 
756 } // namespace JSC
<a name="11" id="anc11"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="11" type="hidden" />
</body>
</html>