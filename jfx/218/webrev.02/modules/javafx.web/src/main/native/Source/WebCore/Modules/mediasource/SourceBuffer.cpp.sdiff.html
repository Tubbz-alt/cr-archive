<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/WebCore/Modules/mediasource/SourceBuffer.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="SampleMap.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="SourceBuffer.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/WebCore/Modules/mediasource/SourceBuffer.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  24  * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
  25  * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
  26  * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
  27  * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  28  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  29  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  30  */
  31 
  32 #include &quot;config.h&quot;
  33 #include &quot;SourceBuffer.h&quot;
  34 
  35 #if ENABLE(MEDIA_SOURCE)
  36 
  37 #include &quot;AudioTrackList.h&quot;
  38 #include &quot;BufferSource.h&quot;
  39 #include &quot;Event.h&quot;
  40 #include &quot;EventNames.h&quot;
  41 #include &quot;GenericEventQueue.h&quot;
  42 #include &quot;HTMLMediaElement.h&quot;
  43 #include &quot;InbandTextTrack.h&quot;

  44 #include &quot;Logging.h&quot;
  45 #include &quot;MediaDescription.h&quot;
  46 #include &quot;MediaSample.h&quot;
  47 #include &quot;MediaSource.h&quot;
  48 #include &quot;SampleMap.h&quot;
  49 #include &quot;SourceBufferList.h&quot;
  50 #include &quot;SourceBufferPrivate.h&quot;
  51 #include &quot;TextTrackList.h&quot;
  52 #include &quot;TimeRanges.h&quot;
  53 #include &quot;VideoTrackList.h&quot;
  54 #include &lt;JavaScriptCore/JSCInlines.h&gt;
  55 #include &lt;JavaScriptCore/JSLock.h&gt;
  56 #include &lt;JavaScriptCore/VM.h&gt;
  57 #include &lt;limits&gt;
  58 #include &lt;wtf/CheckedArithmetic.h&gt;
  59 #include &lt;wtf/IsoMallocInlines.h&gt;

  60 
  61 namespace WebCore {
  62 
  63 WTF_MAKE_ISO_ALLOCATED_IMPL(SourceBuffer);
  64 
  65 static const double ExponentialMovingAverageCoefficient = 0.1;
  66 









  67 struct SourceBuffer::TrackBuffer {
  68     MediaTime lastDecodeTimestamp;
  69     MediaTime greatestDecodeDuration;
  70     MediaTime lastFrameDuration;
  71     MediaTime highestPresentationTimestamp;
<span class="line-modified">  72     MediaTime lastEnqueuedPresentationTime;</span>
  73     MediaTime minimumEnqueuedPresentationTime;
  74     DecodeOrderSampleMap::KeyType lastEnqueuedDecodeKey;
<span class="line-modified">  75     MediaTime lastEnqueuedDecodeDuration;</span>
  76     MediaTime roundedTimestampOffset;
  77     uint32_t lastFrameTimescale { 0 };
  78     bool needRandomAccessFlag { true };
  79     bool enabled { false };
  80     bool needsReenqueueing { false };
  81     bool needsMinimumUpcomingPresentationTimeUpdating { false };
  82     SampleMap samples;
  83     DecodeOrderSampleMap::MapType decodeQueue;
  84     RefPtr&lt;MediaDescription&gt; description;
  85     PlatformTimeRanges buffered;
  86 
  87     TrackBuffer()
  88         : lastDecodeTimestamp(MediaTime::invalidTime())
  89         , greatestDecodeDuration(MediaTime::invalidTime())
  90         , lastFrameDuration(MediaTime::invalidTime())
  91         , highestPresentationTimestamp(MediaTime::invalidTime())
<span class="line-modified">  92         , lastEnqueuedPresentationTime(MediaTime::invalidTime())</span>
  93         , lastEnqueuedDecodeKey({MediaTime::invalidTime(), MediaTime::invalidTime()})
<span class="line-modified">  94         , lastEnqueuedDecodeDuration(MediaTime::invalidTime())</span>
  95     {
  96     }
  97 };
  98 
  99 Ref&lt;SourceBuffer&gt; SourceBuffer::create(Ref&lt;SourceBufferPrivate&gt;&amp;&amp; sourceBufferPrivate, MediaSource* source)
 100 {
 101     auto sourceBuffer = adoptRef(*new SourceBuffer(WTFMove(sourceBufferPrivate), source));
 102     sourceBuffer-&gt;suspendIfNeeded();
 103     return sourceBuffer;
 104 }
 105 
 106 SourceBuffer::SourceBuffer(Ref&lt;SourceBufferPrivate&gt;&amp;&amp; sourceBufferPrivate, MediaSource* source)
 107     : ActiveDOMObject(source-&gt;scriptExecutionContext())
 108     , m_private(WTFMove(sourceBufferPrivate))
 109     , m_source(source)
<span class="line-modified"> 110     , m_asyncEventQueue(*this)</span>
 111     , m_appendBufferTimer(*this, &amp;SourceBuffer::appendBufferTimerFired)
 112     , m_appendWindowStart(MediaTime::zeroTime())
 113     , m_appendWindowEnd(MediaTime::positiveInfiniteTime())
 114     , m_groupStartTimestamp(MediaTime::invalidTime())
 115     , m_groupEndTimestamp(MediaTime::zeroTime())
 116     , m_buffered(TimeRanges::create())
 117     , m_appendState(WaitingForSegment)
 118     , m_timeOfBufferingMonitor(MonotonicTime::now())
 119     , m_pendingRemoveStart(MediaTime::invalidTime())
 120     , m_pendingRemoveEnd(MediaTime::invalidTime())
 121     , m_removeTimer(*this, &amp;SourceBuffer::removeTimerFired)
 122 #if !RELEASE_LOG_DISABLED
 123     , m_logger(m_private-&gt;sourceBufferLogger())
 124     , m_logIdentifier(m_private-&gt;sourceBufferLogIdentifier())
 125 #endif
 126 {
 127     ASSERT(m_source);
 128     ALWAYS_LOG(LOGIDENTIFIER);
 129 
 130     m_private-&gt;setClient(this);
</pre>
<hr />
<pre>
 476     m_private-&gt;removedFromMediaSource();
 477     m_source = nullptr;
 478 }
 479 
 480 void SourceBuffer::seekToTime(const MediaTime&amp; time)
 481 {
 482     ALWAYS_LOG(LOGIDENTIFIER, time);
 483 
 484     for (auto&amp; trackBufferPair : m_trackBufferMap) {
 485         TrackBuffer&amp; trackBuffer = trackBufferPair.value;
 486         const AtomString&amp; trackID = trackBufferPair.key;
 487 
 488         trackBuffer.needsReenqueueing = true;
 489         reenqueueMediaForTime(trackBuffer, trackID, time);
 490     }
 491 }
 492 
 493 MediaTime SourceBuffer::sourceBufferPrivateFastSeekTimeForMediaTime(const MediaTime&amp; targetTime, const MediaTime&amp; negativeThreshold, const MediaTime&amp; positiveThreshold)
 494 {
 495     MediaTime seekTime = targetTime;
<span class="line-removed"> 496     MediaTime lowerBoundTime = targetTime - negativeThreshold;</span>
<span class="line-removed"> 497     MediaTime upperBoundTime = targetTime + positiveThreshold;</span>
 498 
 499     for (auto&amp; trackBuffer : m_trackBufferMap.values()) {
 500         // Find the sample which contains the target time time.
 501         auto futureSyncSampleIterator = trackBuffer.samples.decodeOrder().findSyncSampleAfterPresentationTime(targetTime, positiveThreshold);
 502         auto pastSyncSampleIterator = trackBuffer.samples.decodeOrder().findSyncSamplePriorToPresentationTime(targetTime, negativeThreshold);
 503         auto upperBound = trackBuffer.samples.decodeOrder().end();
 504         auto lowerBound = trackBuffer.samples.decodeOrder().rend();
 505 
 506         if (futureSyncSampleIterator == upperBound &amp;&amp; pastSyncSampleIterator == lowerBound)
 507             continue;
 508 
 509         MediaTime futureSeekTime = MediaTime::positiveInfiniteTime();
 510         if (futureSyncSampleIterator != upperBound) {
 511             RefPtr&lt;MediaSample&gt;&amp; sample = futureSyncSampleIterator-&gt;second;
 512             futureSeekTime = sample-&gt;presentationTime();
 513         }
 514 
 515         MediaTime pastSeekTime = MediaTime::negativeInfiniteTime();
 516         if (pastSyncSampleIterator != lowerBound) {
 517             RefPtr&lt;MediaSample&gt;&amp; sample = pastSyncSampleIterator-&gt;second;
 518             pastSeekTime = sample-&gt;presentationTime();
 519         }
 520 
 521         MediaTime trackSeekTime = abs(targetTime - futureSeekTime) &lt; abs(targetTime - pastSeekTime) ? futureSeekTime : pastSeekTime;
 522         if (abs(targetTime - trackSeekTime) &gt; abs(targetTime - seekTime))
 523             seekTime = trackSeekTime;
 524     }
 525 
 526     return seekTime;
 527 }
 528 
 529 bool SourceBuffer::hasPendingActivity() const
 530 {
<span class="line-modified"> 531     return m_source || m_asyncEventQueue.hasPendingEvents();</span>
<span class="line-removed"> 532 }</span>
<span class="line-removed"> 533 </span>
<span class="line-removed"> 534 void SourceBuffer::suspend(ReasonForSuspension reason)</span>
<span class="line-removed"> 535 {</span>
<span class="line-removed"> 536     switch (reason) {</span>
<span class="line-removed"> 537     case ReasonForSuspension::PageCache:</span>
<span class="line-removed"> 538     case ReasonForSuspension::PageWillBeSuspended:</span>
<span class="line-removed"> 539         m_asyncEventQueue.suspend();</span>
<span class="line-removed"> 540         break;</span>
<span class="line-removed"> 541     case ReasonForSuspension::JavaScriptDebuggerPaused:</span>
<span class="line-removed"> 542     case ReasonForSuspension::WillDeferLoading:</span>
<span class="line-removed"> 543         // Do nothing, we don&#39;t pause media playback in these cases.</span>
<span class="line-removed"> 544         break;</span>
<span class="line-removed"> 545     }</span>
<span class="line-removed"> 546 }</span>
<span class="line-removed"> 547 </span>
<span class="line-removed"> 548 void SourceBuffer::resume()</span>
<span class="line-removed"> 549 {</span>
<span class="line-removed"> 550     m_asyncEventQueue.resume();</span>
 551 }
 552 
 553 void SourceBuffer::stop()
 554 {
<span class="line-removed"> 555     m_asyncEventQueue.close();</span>
 556     m_appendBufferTimer.stop();
 557     m_removeTimer.stop();
 558 }
 559 
<span class="line-removed"> 560 bool SourceBuffer::canSuspendForDocumentSuspension() const</span>
<span class="line-removed"> 561 {</span>
<span class="line-removed"> 562     return !hasPendingActivity();</span>
<span class="line-removed"> 563 }</span>
<span class="line-removed"> 564 </span>
 565 const char* SourceBuffer::activeDOMObjectName() const
 566 {
 567     return &quot;SourceBuffer&quot;;
 568 }
 569 
 570 bool SourceBuffer::isRemoved() const
 571 {
 572     return !m_source;
 573 }
 574 
 575 void SourceBuffer::scheduleEvent(const AtomString&amp; eventName)
 576 {
 577     auto event = Event::create(eventName, Event::CanBubble::No, Event::IsCancelable::No);
 578     event-&gt;setTarget(this);
 579 
<span class="line-modified"> 580     m_asyncEventQueue.enqueueEvent(WTFMove(event));</span>
 581 }
 582 
 583 ExceptionOr&lt;void&gt; SourceBuffer::appendBufferInternal(const unsigned char* data, unsigned size)
 584 {
 585     // Section 3.2 appendBuffer()
 586     // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-SourceBuffer-appendBuffer-void-ArrayBufferView-data
 587 
 588     // Step 1 is enforced by the caller.
 589     // 2. Run the prepare append algorithm.
 590     // Section 3.5.4 Prepare AppendAlgorithm
 591 
 592     // 1. If the SourceBuffer has been removed from the sourceBuffers attribute of the parent media source
 593     // then throw an InvalidStateError exception and abort these steps.
 594     // 2. If the updating attribute equals true, then throw an InvalidStateError exception and abort these steps.
 595     if (isRemoved() || m_updating)
 596         return Exception { InvalidStateError };
 597 
 598     // 3. If the readyState attribute of the parent media source is in the &quot;ended&quot; state then run the following steps:
 599     // 3.1. Set the readyState attribute of the parent media source to &quot;open&quot;
 600     // 3.2. Queue a task to fire a simple event named sourceopen at the parent media source .
</pre>
<hr />
<pre>
 808             auto&amp; nextSample = *endIterator-&gt;second;
 809             if (nextSample.presentationTime() &gt; erasedEnd)
 810                 additionalErasedRanges.add(erasedEnd, nextSample.presentationTime());
 811         }
 812     }
 813     if (additionalErasedRanges.length())
 814         erasedRanges.unionWith(additionalErasedRanges);
 815 
 816 #if !RELEASE_LOG_DISABLED
 817     if (bytesRemoved &amp;&amp; willLog)
 818         logger.debug(buffer-&gt;logChannel(), logIdentifier, &quot;removed &quot;, bytesRemoved, &quot;, start = &quot;, earliestSample, &quot;, end = &quot;, latestSample);
 819 #endif
 820 
 821     return erasedRanges;
 822 }
 823 
 824 void SourceBuffer::removeCodedFrames(const MediaTime&amp; start, const MediaTime&amp; end)
 825 {
 826     DEBUG_LOG(LOGIDENTIFIER, &quot;start = &quot;, start, &quot;, end = &quot;, end);
 827 




 828     // 3.5.9 Coded Frame Removal Algorithm
 829     // https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#sourcebuffer-coded-frame-removal
 830 
 831     // 1. Let start be the starting presentation timestamp for the removal range.
<span class="line-removed"> 832     MediaTime durationMediaTime = m_source-&gt;duration();</span>
 833     MediaTime currentMediaTime = m_source-&gt;currentTime();
 834 
 835     // 2. Let end be the end presentation timestamp for the removal range.
 836     // 3. For each track buffer in this source buffer, run the following steps:
 837     for (auto&amp; trackBufferKeyValue : m_trackBufferMap) {
 838         TrackBuffer&amp; trackBuffer = trackBufferKeyValue.value;
 839         AtomString trackID = trackBufferKeyValue.key;
 840 
 841         // 3.1. Let remove end timestamp be the current value of duration
 842         // 3.2 If this track buffer has a random access point timestamp that is greater than or equal to end, then update
 843         // remove end timestamp to that random access point timestamp.
 844         // NOTE: Step 3.2 will be incorrect for any random access point timestamp whose decode time is later than the sample at end,
 845         // but whose presentation time is less than the sample at end. Skip this step until step 3.3 below.
 846 
 847         // NOTE: To handle MediaSamples which may be an amalgamation of multiple shorter samples, find samples whose presentation
 848         // interval straddles the start and end times, and divide them if possible:
 849         auto divideSampleIfPossibleAtPresentationTime = [&amp;] (const MediaTime&amp; time) {
 850             auto sampleIterator = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(time);
 851             if (sampleIterator == trackBuffer.samples.presentationOrder().end())
 852                 return;
</pre>
<hr />
<pre>
 869         if (removePresentationStart == removePresentationEnd)
 870             continue;
 871 
 872         // 3.3 Remove all media data, from this track buffer, that contain starting timestamps greater than or equal to
 873         // start and less than the remove end timestamp.
 874         // NOTE: frames must be removed in decode order, so that all dependant frames between the frame to be removed
 875         // and the next sync sample frame are removed. But we must start from the first sample in decode order, not
 876         // presentation order.
 877         auto minmaxDecodeTimeIterPair = std::minmax_element(removePresentationStart, removePresentationEnd, decodeTimeComparator);
 878         auto&amp; firstSample = *minmaxDecodeTimeIterPair.first-&gt;second;
 879         auto&amp; lastSample = *minmaxDecodeTimeIterPair.second-&gt;second;
 880         auto removeDecodeStart = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey({firstSample.decodeTime(), firstSample.presentationTime()});
 881         auto removeDecodeLast = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey({lastSample.decodeTime(), lastSample.presentationTime()});
 882         auto removeDecodeEnd = trackBuffer.samples.decodeOrder().findSyncSampleAfterDecodeIterator(removeDecodeLast);
 883 
 884         DecodeOrderSampleMap::MapType erasedSamples(removeDecodeStart, removeDecodeEnd);
 885         PlatformTimeRanges erasedRanges = removeSamplesFromTrackBuffer(erasedSamples, trackBuffer, this, &quot;removeCodedFrames&quot;);
 886 
 887         // Only force the TrackBuffer to re-enqueue if the removed ranges overlap with enqueued and possibly
 888         // not yet displayed samples.
<span class="line-modified"> 889         if (trackBuffer.lastEnqueuedPresentationTime.isValid() &amp;&amp; currentMediaTime &lt; trackBuffer.lastEnqueuedPresentationTime) {</span>
<span class="line-modified"> 890             PlatformTimeRanges possiblyEnqueuedRanges(currentMediaTime, trackBuffer.lastEnqueuedPresentationTime);</span>
 891             possiblyEnqueuedRanges.intersectWith(erasedRanges);
 892             if (possiblyEnqueuedRanges.length()) {
 893                 trackBuffer.needsReenqueueing = true;
 894                 DEBUG_LOG(LOGIDENTIFIER, &quot;the range in removeCodedFrames() includes already enqueued samples, reenqueueing from &quot;, currentMediaTime);
 895                 reenqueueMediaForTime(trackBuffer, trackID, currentMediaTime);
 896             }
 897         }
 898 
 899         erasedRanges.invert();
 900         trackBuffer.buffered.intersectWith(erasedRanges);
 901         setBufferedDirty(true);
 902 
 903         // 3.4 If this object is in activeSourceBuffers, the current playback position is greater than or equal to start
 904         // and less than the remove end timestamp, and HTMLMediaElement.readyState is greater than HAVE_METADATA, then set
 905         // the HTMLMediaElement.readyState attribute to HAVE_METADATA and stall playback.
<span class="line-modified"> 906         if (m_active &amp;&amp; currentMediaTime &gt;= start &amp;&amp; currentMediaTime &lt; end &amp;&amp; m_private-&gt;readyState() &gt; MediaPlayer::HaveMetadata)</span>
<span class="line-modified"> 907             m_private-&gt;setReadyState(MediaPlayer::HaveMetadata);</span>
 908     }
 909 
 910     updateBufferedFromTrackBuffers();
 911 
 912     // 4. If buffer full flag equals true and this object is ready to accept more bytes, then set the buffer full flag to false.
 913     // No-op
 914 
 915     LOG(Media, &quot;SourceBuffer::removeCodedFrames(%p) - buffered = %s&quot;, this, toString(m_buffered-&gt;ranges()).utf8().data());
 916 }
 917 
 918 void SourceBuffer::removeTimerFired()
 919 {
 920     if (isRemoved())
 921         return;
 922 
 923     ASSERT(m_updating);
 924     ASSERT(m_pendingRemoveStart.isValid());
 925     ASSERT(m_pendingRemoveStart &lt; m_pendingRemoveEnd);
 926 
 927     // Section 3.5.7 Range Removal
</pre>
<hr />
<pre>
1040     else
1041         DEBUG_LOG(LOGIDENTIFIER, &quot;evicted &quot;, initialBufferedSize - extraMemoryCost());
1042 #endif
1043 }
1044 
1045 size_t SourceBuffer::maximumBufferSize() const
1046 {
1047     if (isRemoved())
1048         return 0;
1049 
1050     auto* element = m_source-&gt;mediaElement();
1051     if (!element)
1052         return 0;
1053 
1054     return element-&gt;maximumSourceBufferSize(*this);
1055 }
1056 
1057 VideoTrackList&amp; SourceBuffer::videoTracks()
1058 {
1059     if (!m_videoTracks)
<span class="line-modified">1060         m_videoTracks = VideoTrackList::create(m_source-&gt;mediaElement(), scriptExecutionContext());</span>
1061     return *m_videoTracks;
1062 }
1063 
1064 AudioTrackList&amp; SourceBuffer::audioTracks()
1065 {
1066     if (!m_audioTracks)
<span class="line-modified">1067         m_audioTracks = AudioTrackList::create(m_source-&gt;mediaElement(), scriptExecutionContext());</span>
1068     return *m_audioTracks;
1069 }
1070 
1071 TextTrackList&amp; SourceBuffer::textTracks()
1072 {
1073     if (!m_textTracks)
<span class="line-modified">1074         m_textTracks = TextTrackList::create(m_source-&gt;mediaElement(), scriptExecutionContext());</span>
1075     return *m_textTracks;
1076 }
1077 
1078 void SourceBuffer::setActive(bool active)
1079 {
1080     if (m_active == active)
1081         return;
1082 
1083     m_active = active;
1084     m_private-&gt;setActive(active);
1085     if (!isRemoved())
1086         m_source-&gt;sourceBufferDidChangeActiveState(*this, active);
1087 }
1088 
1089 void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(const InitializationSegment&amp; segment)
1090 {
1091     if (isRemoved())
1092         return;
1093 
1094     ALWAYS_LOG(LOGIDENTIFIER);
</pre>
<hr />
<pre>
1288 
1289             m_textCodecs.append(trackBuffer.description-&gt;codec());
1290         }
1291 
1292         // 5.5 If active track flag equals true, then run the following steps:
1293         if (activeTrackFlag) {
1294             // 5.5.1 Add this SourceBuffer to activeSourceBuffers.
1295             // 5.5.2 Queue a task to fire a simple event named addsourcebuffer at activeSourceBuffers
1296             setActive(true);
1297         }
1298 
1299         // 5.6 Set first initialization segment flag to true.
1300         m_receivedFirstInitializationSegment = true;
1301     }
1302 
1303     // (Note: Issue #155 adds this step after step 5:)
1304     // 6. Set  pending initialization segment for changeType flag  to false.
1305     m_pendingInitializationSegmentForChangeType = false;
1306 
1307     // 6. If the HTMLMediaElement.readyState attribute is HAVE_NOTHING, then run the following steps:
<span class="line-modified">1308     if (m_private-&gt;readyState() == MediaPlayer::HaveNothing) {</span>
1309         // 6.1 If one or more objects in sourceBuffers have first initialization segment flag set to false, then abort these steps.
1310         for (auto&amp; sourceBuffer : *m_source-&gt;sourceBuffers()) {
1311             if (!sourceBuffer-&gt;m_receivedFirstInitializationSegment)
1312                 return;
1313         }
1314 
1315         // 6.2 Set the HTMLMediaElement.readyState attribute to HAVE_METADATA.
1316         // 6.3 Queue a task to fire a simple event named loadedmetadata at the media element.
<span class="line-modified">1317         m_private-&gt;setReadyState(MediaPlayer::HaveMetadata);</span>
1318     }
1319 
1320     // 7. If the active track flag equals true and the HTMLMediaElement.readyState
1321     // attribute is greater than HAVE_CURRENT_DATA, then set the HTMLMediaElement.readyState
1322     // attribute to HAVE_METADATA.
<span class="line-modified">1323     if (activeTrackFlag &amp;&amp; m_private-&gt;readyState() &gt; MediaPlayer::HaveCurrentData)</span>
<span class="line-modified">1324         m_private-&gt;setReadyState(MediaPlayer::HaveMetadata);</span>
1325 }
1326 
1327 bool SourceBuffer::validateInitializationSegment(const InitializationSegment&amp; segment)
1328 {
1329     // FIXME: ordering of all 3.5.X (X&gt;=7) functions needs to be updated to post-[24 July 2014 Editor&#39;s Draft] version
1330     // 3.5.8 Initialization Segment Received (ctd)
1331     // https://rawgit.com/w3c/media-source/c3ad59c7a370d04430969ba73d18dc9bcde57a33/index.html#sourcebuffer-init-segment-received [Editor&#39;s Draft 09 January 2015]
1332 
1333     // Note: those are checks from step 3.1
1334     //   * The number of audio, video, and text tracks match what was in the first initialization segment.
1335     if (segment.audioTracks.size() != audioTracks().length()
1336         || segment.videoTracks.size() != videoTracks().length()
1337         || segment.textTracks.size() != textTracks().length())
1338         return false;
1339 
1340     //   * The codecs for each track, match what was specified in the first initialization segment.
1341     // (Note: Issue #155 strikes out this check. For broad compatibility when this experimental feature
1342     // is not enabled, only perform this check if the &quot;pending initialization segment for changeType flag&quot;
1343     // is not set.)
1344     for (auto&amp; audioTrackInfo : segment.audioTracks) {
</pre>
<hr />
<pre>
1679                     if (presentationTimestamp &lt; removeWindowTimestamp)
1680                         erasedSamples.addSample(*iter-&gt;second);
1681                 }
1682 
1683                 // If track buffer contains timed text coded frames:
1684                 // Run the text splice frame algorithm and if a splice frame is returned, assign it to spliced timed text frame.
1685                 // FIXME: Add support for sample splicing.
1686             }
1687         }
1688 
1689         // 1.15 Remove existing coded frames in track buffer:
1690         // If highest presentation timestamp for track buffer is not set:
1691         if (trackBuffer.highestPresentationTimestamp.isInvalid()) {
1692             // Remove all coded frames from track buffer that have a presentation timestamp greater than or
1693             // equal to presentation timestamp and less than frame end timestamp.
1694             auto iter_pair = trackBuffer.samples.presentationOrder().findSamplesBetweenPresentationTimes(presentationTimestamp, frameEndTimestamp);
1695             if (iter_pair.first != trackBuffer.samples.presentationOrder().end())
1696                 erasedSamples.addRange(iter_pair.first, iter_pair.second);
1697         }
1698 























1699         // There are many files out there where the frame times are not perfectly contiguous and may have small overlaps
1700         // between the beginning of a frame and the end of the previous one; therefore a tolerance is needed whenever
1701         // durations are considered.
1702         // For instance, most WebM files are muxed rounded to the millisecond (the default TimecodeScale of the format)
1703         // but their durations use a finer timescale (causing a sub-millisecond overlap). More rarely, there are also
1704         // MP4 files with slightly off tfdt boxes, presenting a similar problem at the beginning of each fragment.
1705         const MediaTime contiguousFrameTolerance = MediaTime(1, 1000);
1706 
1707         // If highest presentation timestamp for track buffer is set and less than or equal to presentation timestamp
1708         if (trackBuffer.highestPresentationTimestamp.isValid() &amp;&amp; trackBuffer.highestPresentationTimestamp - contiguousFrameTolerance &lt;= presentationTimestamp) {
1709             // Remove all coded frames from track buffer that have a presentation timestamp greater than highest
1710             // presentation timestamp and less than or equal to frame end timestamp.
1711             do {
1712                 // NOTE: Searching from the end of the trackBuffer will be vastly more efficient if the search range is
1713                 // near the end of the buffered range. Use a linear-backwards search if the search range is within one
1714                 // frame duration of the end:
1715                 unsigned bufferedLength = trackBuffer.buffered.length();
1716                 if (!bufferedLength)
1717                     break;
1718 
</pre>
<hr />
<pre>
1742             // Otherwise: Remove all coded frames between the coded frames removed in the previous step
1743             // and the next random access point after those removed frames.
1744             auto firstDecodeIter = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(erasedSamples.decodeOrder().begin()-&gt;first);
1745             auto lastDecodeIter = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(erasedSamples.decodeOrder().rbegin()-&gt;first);
1746             auto nextSyncIter = trackBuffer.samples.decodeOrder().findSyncSampleAfterDecodeIterator(lastDecodeIter);
1747             dependentSamples.insert(firstDecodeIter, nextSyncIter);
1748 
1749             // NOTE: in the case of b-frames, the previous step may leave in place samples whose presentation
1750             // timestamp &lt; presentationTime, but whose decode timestamp &gt;= decodeTime. These will eventually cause
1751             // a decode error if left in place, so remove these samples as well.
1752             DecodeOrderSampleMap::KeyType decodeKey(sample.decodeTime(), sample.presentationTime());
1753             auto samplesWithHigherDecodeTimes = trackBuffer.samples.decodeOrder().findSamplesBetweenDecodeKeys(decodeKey, erasedSamples.decodeOrder().begin()-&gt;first);
1754             if (samplesWithHigherDecodeTimes.first != samplesWithHigherDecodeTimes.second)
1755                 dependentSamples.insert(samplesWithHigherDecodeTimes.first, samplesWithHigherDecodeTimes.second);
1756 
1757             PlatformTimeRanges erasedRanges = removeSamplesFromTrackBuffer(dependentSamples, trackBuffer, this, &quot;sourceBufferPrivateDidReceiveSample&quot;);
1758 
1759             // Only force the TrackBuffer to re-enqueue if the removed ranges overlap with enqueued and possibly
1760             // not yet displayed samples.
1761             MediaTime currentMediaTime = m_source-&gt;currentTime();
<span class="line-modified">1762             if (trackBuffer.lastEnqueuedPresentationTime.isValid() &amp;&amp; currentMediaTime &lt; trackBuffer.lastEnqueuedPresentationTime) {</span>
<span class="line-modified">1763                 PlatformTimeRanges possiblyEnqueuedRanges(currentMediaTime, trackBuffer.lastEnqueuedPresentationTime);</span>
1764                 possiblyEnqueuedRanges.intersectWith(erasedRanges);
1765                 if (possiblyEnqueuedRanges.length())
1766                     trackBuffer.needsReenqueueing = true;
1767             }
1768 
1769             erasedRanges.invert();
1770             trackBuffer.buffered.intersectWith(erasedRanges);
1771             setBufferedDirty(true);
1772         }
1773 
1774         // 1.17 If spliced audio frame is set:
1775         // Add spliced audio frame to the track buffer.
1776         // If spliced timed text frame is set:
1777         // Add spliced timed text frame to the track buffer.
1778         // FIXME: Add support for sample splicing.
1779 
1780         // Otherwise:
1781         // Add the coded frame with the presentation timestamp, decode timestamp, and frame duration to the track buffer.
1782         trackBuffer.samples.addSample(sample);
1783 
1784         // Note: The terminology here is confusing: &quot;enqueuing&quot; means providing a frame to the inner media framework.
<span class="line-modified">1785         // First, frames are inserted in the decode queue; later, at the end of the append all the frames in the decode</span>
<span class="line-modified">1786         // queue are &quot;enqueued&quot; (sent to the inner media framework) in `provideMediaData()`.</span>
1787         //
<span class="line-modified">1788         // In order to check whether a frame should be added to the decode queue we check whether it starts after the</span>
<span class="line-modified">1789         // lastEnqueuedDecodeKey.</span>




1790         DecodeOrderSampleMap::KeyType decodeKey(sample.decodeTime(), sample.presentationTime());
1791         if (trackBuffer.lastEnqueuedDecodeKey.first.isInvalid() || decodeKey &gt; trackBuffer.lastEnqueuedDecodeKey) {
1792             trackBuffer.decodeQueue.insert(DecodeOrderSampleMap::MapType::value_type(decodeKey, &amp;sample));
1793 
1794             if (trackBuffer.minimumEnqueuedPresentationTime.isValid() &amp;&amp; sample.presentationTime() &lt; trackBuffer.minimumEnqueuedPresentationTime)
1795                 trackBuffer.needsMinimumUpcomingPresentationTimeUpdating = true;
1796         }
1797 
1798         // NOTE: the spec considers &quot;Coded Frame Duration&quot; to be the presentation duration, but this is not necessarily equal
1799         // to the decoded duration. When comparing deltas between decode timestamps, the decode duration, not the presentation.
1800         if (trackBuffer.lastDecodeTimestamp.isValid()) {
1801             MediaTime lastDecodeDuration = decodeTimestamp - trackBuffer.lastDecodeTimestamp;
1802             if (!trackBuffer.greatestDecodeDuration.isValid() || lastDecodeDuration &gt; trackBuffer.greatestDecodeDuration)
1803                 trackBuffer.greatestDecodeDuration = lastDecodeDuration;
1804         }
1805 
1806         // 1.18 Set last decode timestamp for track buffer to decode timestamp.
1807         trackBuffer.lastDecodeTimestamp = decodeTimestamp;
1808 
1809         // 1.19 Set last frame duration for track buffer to frame duration.
</pre>
<hr />
<pre>
2024 
2025 #if !RELEASE_LOG_DISABLED
2026     unsigned enqueuedSamples = 0;
2027 #endif
2028 
2029     if (trackBuffer.needsMinimumUpcomingPresentationTimeUpdating)
2030         resetMinimumUpcomingPresentationTime(trackBuffer, trackID);
2031 
2032     while (!trackBuffer.decodeQueue.empty()) {
2033         if (!m_private-&gt;isReadyForMoreSamples(trackID)) {
2034             DEBUG_LOG(LOGIDENTIFIER, &quot;bailing early, track id &quot;, trackID, &quot; is not ready for more data&quot;);
2035             m_private-&gt;notifyClientWhenReadyForMoreSamples(trackID);
2036             break;
2037         }
2038 
2039         // FIXME(rdar://problem/20635969): Remove this re-entrancy protection when the aforementioned radar is resolved; protecting
2040         // against re-entrancy introduces a small inefficency when removing appended samples from the decode queue one at a time
2041         // rather than when all samples have been enqueued.
2042         auto sample = trackBuffer.decodeQueue.begin()-&gt;second;
2043 
<span class="line-modified">2044         // Do not enqueue samples spanning a significant unbuffered gap.</span>
<span class="line-modified">2045         // NOTE: one second is somewhat arbitrary. MediaSource::monitorSourceBuffers() is run</span>
<span class="line-removed">2046         // on the playbackTimer, which is effectively every 350ms. Allowing &gt; 350ms gap between</span>
<span class="line-removed">2047         // enqueued samples allows for situations where we overrun the end of a buffered range</span>
<span class="line-removed">2048         // but don&#39;t notice for 350s of playback time, and the client can enqueue data for the</span>
<span class="line-removed">2049         // new current time without triggering this early return.</span>
<span class="line-removed">2050         // FIXME(135867): Make this gap detection logic less arbitrary.</span>
<span class="line-removed">2051         MediaTime oneSecond(1, 1);</span>
<span class="line-removed">2052         if (trackBuffer.lastEnqueuedDecodeKey.first.isValid()</span>
<span class="line-removed">2053             &amp;&amp; trackBuffer.lastEnqueuedDecodeDuration.isValid()</span>
<span class="line-removed">2054             &amp;&amp; sample-&gt;decodeTime() - trackBuffer.lastEnqueuedDecodeKey.first &gt; oneSecond + trackBuffer.lastEnqueuedDecodeDuration) {</span>
<span class="line-removed">2055 </span>
<span class="line-removed">2056         DEBUG_LOG(LOGIDENTIFIER, &quot;bailing early because of unbuffered gap, new sample: &quot;, sample-&gt;decodeTime(), &quot;, last enqueued sample ends: &quot;, trackBuffer.lastEnqueuedDecodeKey.first + trackBuffer.lastEnqueuedDecodeDuration);</span>
2057             break;
2058         }
2059 
2060         // Remove the sample from the decode queue now.
2061         trackBuffer.decodeQueue.erase(trackBuffer.decodeQueue.begin());
2062 
<span class="line-modified">2063         trackBuffer.lastEnqueuedPresentationTime = sample-&gt;presentationTime();</span>



2064         trackBuffer.lastEnqueuedDecodeKey = {sample-&gt;decodeTime(), sample-&gt;presentationTime()};
<span class="line-modified">2065         trackBuffer.lastEnqueuedDecodeDuration = sample-&gt;duration();</span>

2066         m_private-&gt;enqueueSample(sample.releaseNonNull(), trackID);
2067 #if !RELEASE_LOG_DISABLED
2068         ++enqueuedSamples;
2069 #endif
2070     }
2071 
2072     updateMinimumUpcomingPresentationTime(trackBuffer, trackID);
2073 
2074 #if !RELEASE_LOG_DISABLED
2075     DEBUG_LOG(LOGIDENTIFIER, &quot;enqueued &quot;, enqueuedSamples, &quot; samples, &quot;, static_cast&lt;size_t&gt;(trackBuffer.decodeQueue.size()), &quot; remaining&quot;);
2076 #endif
2077 
2078     trySignalAllSamplesInTrackEnqueued(trackID);
2079 }
2080 
2081 void SourceBuffer::updateMinimumUpcomingPresentationTime(TrackBuffer&amp; trackBuffer, const AtomString&amp; trackID)
2082 {
2083     if (!m_private-&gt;canSetMinimumUpcomingPresentationTime(trackID))
2084         return;
2085 
</pre>
<hr />
<pre>
2115 
2116 void SourceBuffer::trySignalAllSamplesInTrackEnqueued(const AtomString&amp; trackID)
2117 {
2118     if (m_source-&gt;isEnded() &amp;&amp; m_trackBufferMap.get(trackID).decodeQueue.empty()) {
2119         DEBUG_LOG(LOGIDENTIFIER, &quot;enqueued all samples from track &quot;, trackID);
2120         m_private-&gt;allSamplesInTrackEnqueued(trackID);
2121     }
2122 }
2123 
2124 void SourceBuffer::trySignalAllSamplesEnqueued()
2125 {
2126     for (const AtomString&amp; trackID : m_trackBufferMap.keys())
2127         trySignalAllSamplesInTrackEnqueued(trackID);
2128 }
2129 
2130 void SourceBuffer::reenqueueMediaForTime(TrackBuffer&amp; trackBuffer, const AtomString&amp; trackID, const MediaTime&amp; time)
2131 {
2132     m_private-&gt;flush(trackID);
2133     trackBuffer.decodeQueue.clear();
2134 




2135     // Find the sample which contains the current presentation time.
2136     auto currentSamplePTSIterator = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(time);
2137 
2138     if (currentSamplePTSIterator == trackBuffer.samples.presentationOrder().end())
2139         currentSamplePTSIterator = trackBuffer.samples.presentationOrder().findSampleStartingOnOrAfterPresentationTime(time);
2140 
2141     if (currentSamplePTSIterator == trackBuffer.samples.presentationOrder().end()
2142         || (currentSamplePTSIterator-&gt;first - time) &gt; MediaSource::currentTimeFudgeFactor())
2143         return;
2144 
2145     // Seach backward for the previous sync sample.
2146     DecodeOrderSampleMap::KeyType decodeKey(currentSamplePTSIterator-&gt;second-&gt;decodeTime(), currentSamplePTSIterator-&gt;second-&gt;presentationTime());
2147     auto currentSampleDTSIterator = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(decodeKey);
2148     ASSERT(currentSampleDTSIterator != trackBuffer.samples.decodeOrder().end());
2149 
2150     auto reverseCurrentSampleIter = --DecodeOrderSampleMap::reverse_iterator(currentSampleDTSIterator);
2151     auto reverseLastSyncSampleIter = trackBuffer.samples.decodeOrder().findSyncSamplePriorToDecodeIterator(reverseCurrentSampleIter);
2152     if (reverseLastSyncSampleIter == trackBuffer.samples.decodeOrder().rend())
2153         return;
2154 
2155     // Fill the decode queue with the non-displaying samples.
2156     for (auto iter = reverseLastSyncSampleIter; iter != reverseCurrentSampleIter; --iter) {
2157         auto copy = iter-&gt;second-&gt;createNonDisplayingCopy();
2158         DecodeOrderSampleMap::KeyType decodeKey(copy-&gt;decodeTime(), copy-&gt;presentationTime());
2159         trackBuffer.decodeQueue.insert(DecodeOrderSampleMap::MapType::value_type(decodeKey, WTFMove(copy)));
2160     }
2161 
<span class="line-removed">2162     if (!trackBuffer.decodeQueue.empty()) {</span>
<span class="line-removed">2163         auto lastSampleIter = trackBuffer.decodeQueue.rbegin();</span>
<span class="line-removed">2164         auto lastSampleDecodeKey = lastSampleIter-&gt;first;</span>
<span class="line-removed">2165         auto lastSampleDuration = lastSampleIter-&gt;second-&gt;duration();</span>
<span class="line-removed">2166         trackBuffer.lastEnqueuedPresentationTime = lastSampleDecodeKey.second;</span>
<span class="line-removed">2167         trackBuffer.lastEnqueuedDecodeKey = lastSampleDecodeKey;</span>
<span class="line-removed">2168         trackBuffer.lastEnqueuedDecodeDuration = lastSampleDuration;</span>
<span class="line-removed">2169     } else {</span>
<span class="line-removed">2170         trackBuffer.lastEnqueuedPresentationTime = MediaTime::invalidTime();</span>
<span class="line-removed">2171         trackBuffer.lastEnqueuedDecodeKey = {MediaTime::invalidTime(), MediaTime::invalidTime()};</span>
<span class="line-removed">2172         trackBuffer.lastEnqueuedDecodeDuration = MediaTime::invalidTime();</span>
<span class="line-removed">2173     }</span>
<span class="line-removed">2174 </span>
2175     // Fill the decode queue with the remaining samples.
2176     for (auto iter = currentSampleDTSIterator; iter != trackBuffer.samples.decodeOrder().end(); ++iter)
2177         trackBuffer.decodeQueue.insert(*iter);
2178     provideMediaData(trackBuffer, trackID);
2179 
2180     trackBuffer.needsReenqueueing = false;
2181 }
2182 
2183 
2184 void SourceBuffer::didDropSample()
2185 {
2186     if (!isRemoved())
2187         m_source-&gt;mediaElement()-&gt;incrementDroppedFrameCount();
2188 }
2189 
2190 void SourceBuffer::monitorBufferingRate()
2191 {
2192     MonotonicTime now = MonotonicTime::now();
2193     Seconds interval = now - m_timeOfBufferingMonitor;
2194     double rateSinceLastMonitor = m_bufferedSinceLastMonitor / interval.seconds();
</pre>
</td>
<td>
<hr />
<pre>
  24  * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
  25  * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
  26  * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
  27  * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  28  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  29  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  30  */
  31 
  32 #include &quot;config.h&quot;
  33 #include &quot;SourceBuffer.h&quot;
  34 
  35 #if ENABLE(MEDIA_SOURCE)
  36 
  37 #include &quot;AudioTrackList.h&quot;
  38 #include &quot;BufferSource.h&quot;
  39 #include &quot;Event.h&quot;
  40 #include &quot;EventNames.h&quot;
  41 #include &quot;GenericEventQueue.h&quot;
  42 #include &quot;HTMLMediaElement.h&quot;
  43 #include &quot;InbandTextTrack.h&quot;
<span class="line-added">  44 #include &quot;InbandTextTrackPrivate.h&quot;</span>
  45 #include &quot;Logging.h&quot;
  46 #include &quot;MediaDescription.h&quot;
  47 #include &quot;MediaSample.h&quot;
  48 #include &quot;MediaSource.h&quot;
  49 #include &quot;SampleMap.h&quot;
  50 #include &quot;SourceBufferList.h&quot;
  51 #include &quot;SourceBufferPrivate.h&quot;
  52 #include &quot;TextTrackList.h&quot;
  53 #include &quot;TimeRanges.h&quot;
  54 #include &quot;VideoTrackList.h&quot;
  55 #include &lt;JavaScriptCore/JSCInlines.h&gt;
  56 #include &lt;JavaScriptCore/JSLock.h&gt;
  57 #include &lt;JavaScriptCore/VM.h&gt;
  58 #include &lt;limits&gt;
  59 #include &lt;wtf/CheckedArithmetic.h&gt;
  60 #include &lt;wtf/IsoMallocInlines.h&gt;
<span class="line-added">  61 #include &lt;wtf/WeakPtr.h&gt;</span>
  62 
  63 namespace WebCore {
  64 
  65 WTF_MAKE_ISO_ALLOCATED_IMPL(SourceBuffer);
  66 
  67 static const double ExponentialMovingAverageCoefficient = 0.1;
  68 
<span class="line-added">  69 // Do not enqueue samples spanning a significant unbuffered gap.</span>
<span class="line-added">  70 // NOTE: one second is somewhat arbitrary. MediaSource::monitorSourceBuffers() is run</span>
<span class="line-added">  71 // on the playbackTimer, which is effectively every 350ms. Allowing &gt; 350ms gap between</span>
<span class="line-added">  72 // enqueued samples allows for situations where we overrun the end of a buffered range</span>
<span class="line-added">  73 // but don&#39;t notice for 350s of playback time, and the client can enqueue data for the</span>
<span class="line-added">  74 // new current time without triggering this early return.</span>
<span class="line-added">  75 // FIXME(135867): Make this gap detection logic less arbitrary.</span>
<span class="line-added">  76 static const MediaTime discontinuityTolerance = MediaTime(1, 1);</span>
<span class="line-added">  77 </span>
  78 struct SourceBuffer::TrackBuffer {
  79     MediaTime lastDecodeTimestamp;
  80     MediaTime greatestDecodeDuration;
  81     MediaTime lastFrameDuration;
  82     MediaTime highestPresentationTimestamp;
<span class="line-modified">  83     MediaTime highestEnqueuedPresentationTime;</span>
  84     MediaTime minimumEnqueuedPresentationTime;
  85     DecodeOrderSampleMap::KeyType lastEnqueuedDecodeKey;
<span class="line-modified">  86     MediaTime enqueueDiscontinuityBoundary { MediaTime::zeroTime() };</span>
  87     MediaTime roundedTimestampOffset;
  88     uint32_t lastFrameTimescale { 0 };
  89     bool needRandomAccessFlag { true };
  90     bool enabled { false };
  91     bool needsReenqueueing { false };
  92     bool needsMinimumUpcomingPresentationTimeUpdating { false };
  93     SampleMap samples;
  94     DecodeOrderSampleMap::MapType decodeQueue;
  95     RefPtr&lt;MediaDescription&gt; description;
  96     PlatformTimeRanges buffered;
  97 
  98     TrackBuffer()
  99         : lastDecodeTimestamp(MediaTime::invalidTime())
 100         , greatestDecodeDuration(MediaTime::invalidTime())
 101         , lastFrameDuration(MediaTime::invalidTime())
 102         , highestPresentationTimestamp(MediaTime::invalidTime())
<span class="line-modified"> 103         , highestEnqueuedPresentationTime(MediaTime::invalidTime())</span>
 104         , lastEnqueuedDecodeKey({MediaTime::invalidTime(), MediaTime::invalidTime()})
<span class="line-modified"> 105         , enqueueDiscontinuityBoundary(discontinuityTolerance)</span>
 106     {
 107     }
 108 };
 109 
 110 Ref&lt;SourceBuffer&gt; SourceBuffer::create(Ref&lt;SourceBufferPrivate&gt;&amp;&amp; sourceBufferPrivate, MediaSource* source)
 111 {
 112     auto sourceBuffer = adoptRef(*new SourceBuffer(WTFMove(sourceBufferPrivate), source));
 113     sourceBuffer-&gt;suspendIfNeeded();
 114     return sourceBuffer;
 115 }
 116 
 117 SourceBuffer::SourceBuffer(Ref&lt;SourceBufferPrivate&gt;&amp;&amp; sourceBufferPrivate, MediaSource* source)
 118     : ActiveDOMObject(source-&gt;scriptExecutionContext())
 119     , m_private(WTFMove(sourceBufferPrivate))
 120     , m_source(source)
<span class="line-modified"> 121     , m_asyncEventQueue(MainThreadGenericEventQueue::create(*this))</span>
 122     , m_appendBufferTimer(*this, &amp;SourceBuffer::appendBufferTimerFired)
 123     , m_appendWindowStart(MediaTime::zeroTime())
 124     , m_appendWindowEnd(MediaTime::positiveInfiniteTime())
 125     , m_groupStartTimestamp(MediaTime::invalidTime())
 126     , m_groupEndTimestamp(MediaTime::zeroTime())
 127     , m_buffered(TimeRanges::create())
 128     , m_appendState(WaitingForSegment)
 129     , m_timeOfBufferingMonitor(MonotonicTime::now())
 130     , m_pendingRemoveStart(MediaTime::invalidTime())
 131     , m_pendingRemoveEnd(MediaTime::invalidTime())
 132     , m_removeTimer(*this, &amp;SourceBuffer::removeTimerFired)
 133 #if !RELEASE_LOG_DISABLED
 134     , m_logger(m_private-&gt;sourceBufferLogger())
 135     , m_logIdentifier(m_private-&gt;sourceBufferLogIdentifier())
 136 #endif
 137 {
 138     ASSERT(m_source);
 139     ALWAYS_LOG(LOGIDENTIFIER);
 140 
 141     m_private-&gt;setClient(this);
</pre>
<hr />
<pre>
 487     m_private-&gt;removedFromMediaSource();
 488     m_source = nullptr;
 489 }
 490 
 491 void SourceBuffer::seekToTime(const MediaTime&amp; time)
 492 {
 493     ALWAYS_LOG(LOGIDENTIFIER, time);
 494 
 495     for (auto&amp; trackBufferPair : m_trackBufferMap) {
 496         TrackBuffer&amp; trackBuffer = trackBufferPair.value;
 497         const AtomString&amp; trackID = trackBufferPair.key;
 498 
 499         trackBuffer.needsReenqueueing = true;
 500         reenqueueMediaForTime(trackBuffer, trackID, time);
 501     }
 502 }
 503 
 504 MediaTime SourceBuffer::sourceBufferPrivateFastSeekTimeForMediaTime(const MediaTime&amp; targetTime, const MediaTime&amp; negativeThreshold, const MediaTime&amp; positiveThreshold)
 505 {
 506     MediaTime seekTime = targetTime;


 507 
 508     for (auto&amp; trackBuffer : m_trackBufferMap.values()) {
 509         // Find the sample which contains the target time time.
 510         auto futureSyncSampleIterator = trackBuffer.samples.decodeOrder().findSyncSampleAfterPresentationTime(targetTime, positiveThreshold);
 511         auto pastSyncSampleIterator = trackBuffer.samples.decodeOrder().findSyncSamplePriorToPresentationTime(targetTime, negativeThreshold);
 512         auto upperBound = trackBuffer.samples.decodeOrder().end();
 513         auto lowerBound = trackBuffer.samples.decodeOrder().rend();
 514 
 515         if (futureSyncSampleIterator == upperBound &amp;&amp; pastSyncSampleIterator == lowerBound)
 516             continue;
 517 
 518         MediaTime futureSeekTime = MediaTime::positiveInfiniteTime();
 519         if (futureSyncSampleIterator != upperBound) {
 520             RefPtr&lt;MediaSample&gt;&amp; sample = futureSyncSampleIterator-&gt;second;
 521             futureSeekTime = sample-&gt;presentationTime();
 522         }
 523 
 524         MediaTime pastSeekTime = MediaTime::negativeInfiniteTime();
 525         if (pastSyncSampleIterator != lowerBound) {
 526             RefPtr&lt;MediaSample&gt;&amp; sample = pastSyncSampleIterator-&gt;second;
 527             pastSeekTime = sample-&gt;presentationTime();
 528         }
 529 
 530         MediaTime trackSeekTime = abs(targetTime - futureSeekTime) &lt; abs(targetTime - pastSeekTime) ? futureSeekTime : pastSeekTime;
 531         if (abs(targetTime - trackSeekTime) &gt; abs(targetTime - seekTime))
 532             seekTime = trackSeekTime;
 533     }
 534 
 535     return seekTime;
 536 }
 537 
 538 bool SourceBuffer::hasPendingActivity() const
 539 {
<span class="line-modified"> 540     return m_source || m_asyncEventQueue-&gt;hasPendingEvents();</span>



















 541 }
 542 
 543 void SourceBuffer::stop()
 544 {

 545     m_appendBufferTimer.stop();
 546     m_removeTimer.stop();
 547 }
 548 





 549 const char* SourceBuffer::activeDOMObjectName() const
 550 {
 551     return &quot;SourceBuffer&quot;;
 552 }
 553 
 554 bool SourceBuffer::isRemoved() const
 555 {
 556     return !m_source;
 557 }
 558 
 559 void SourceBuffer::scheduleEvent(const AtomString&amp; eventName)
 560 {
 561     auto event = Event::create(eventName, Event::CanBubble::No, Event::IsCancelable::No);
 562     event-&gt;setTarget(this);
 563 
<span class="line-modified"> 564     m_asyncEventQueue-&gt;enqueueEvent(WTFMove(event));</span>
 565 }
 566 
 567 ExceptionOr&lt;void&gt; SourceBuffer::appendBufferInternal(const unsigned char* data, unsigned size)
 568 {
 569     // Section 3.2 appendBuffer()
 570     // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-SourceBuffer-appendBuffer-void-ArrayBufferView-data
 571 
 572     // Step 1 is enforced by the caller.
 573     // 2. Run the prepare append algorithm.
 574     // Section 3.5.4 Prepare AppendAlgorithm
 575 
 576     // 1. If the SourceBuffer has been removed from the sourceBuffers attribute of the parent media source
 577     // then throw an InvalidStateError exception and abort these steps.
 578     // 2. If the updating attribute equals true, then throw an InvalidStateError exception and abort these steps.
 579     if (isRemoved() || m_updating)
 580         return Exception { InvalidStateError };
 581 
 582     // 3. If the readyState attribute of the parent media source is in the &quot;ended&quot; state then run the following steps:
 583     // 3.1. Set the readyState attribute of the parent media source to &quot;open&quot;
 584     // 3.2. Queue a task to fire a simple event named sourceopen at the parent media source .
</pre>
<hr />
<pre>
 792             auto&amp; nextSample = *endIterator-&gt;second;
 793             if (nextSample.presentationTime() &gt; erasedEnd)
 794                 additionalErasedRanges.add(erasedEnd, nextSample.presentationTime());
 795         }
 796     }
 797     if (additionalErasedRanges.length())
 798         erasedRanges.unionWith(additionalErasedRanges);
 799 
 800 #if !RELEASE_LOG_DISABLED
 801     if (bytesRemoved &amp;&amp; willLog)
 802         logger.debug(buffer-&gt;logChannel(), logIdentifier, &quot;removed &quot;, bytesRemoved, &quot;, start = &quot;, earliestSample, &quot;, end = &quot;, latestSample);
 803 #endif
 804 
 805     return erasedRanges;
 806 }
 807 
 808 void SourceBuffer::removeCodedFrames(const MediaTime&amp; start, const MediaTime&amp; end)
 809 {
 810     DEBUG_LOG(LOGIDENTIFIER, &quot;start = &quot;, start, &quot;, end = &quot;, end);
 811 
<span class="line-added"> 812     ASSERT(start &lt; end);</span>
<span class="line-added"> 813     if (start &gt;= end)</span>
<span class="line-added"> 814         return;</span>
<span class="line-added"> 815 </span>
 816     // 3.5.9 Coded Frame Removal Algorithm
 817     // https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#sourcebuffer-coded-frame-removal
 818 
 819     // 1. Let start be the starting presentation timestamp for the removal range.

 820     MediaTime currentMediaTime = m_source-&gt;currentTime();
 821 
 822     // 2. Let end be the end presentation timestamp for the removal range.
 823     // 3. For each track buffer in this source buffer, run the following steps:
 824     for (auto&amp; trackBufferKeyValue : m_trackBufferMap) {
 825         TrackBuffer&amp; trackBuffer = trackBufferKeyValue.value;
 826         AtomString trackID = trackBufferKeyValue.key;
 827 
 828         // 3.1. Let remove end timestamp be the current value of duration
 829         // 3.2 If this track buffer has a random access point timestamp that is greater than or equal to end, then update
 830         // remove end timestamp to that random access point timestamp.
 831         // NOTE: Step 3.2 will be incorrect for any random access point timestamp whose decode time is later than the sample at end,
 832         // but whose presentation time is less than the sample at end. Skip this step until step 3.3 below.
 833 
 834         // NOTE: To handle MediaSamples which may be an amalgamation of multiple shorter samples, find samples whose presentation
 835         // interval straddles the start and end times, and divide them if possible:
 836         auto divideSampleIfPossibleAtPresentationTime = [&amp;] (const MediaTime&amp; time) {
 837             auto sampleIterator = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(time);
 838             if (sampleIterator == trackBuffer.samples.presentationOrder().end())
 839                 return;
</pre>
<hr />
<pre>
 856         if (removePresentationStart == removePresentationEnd)
 857             continue;
 858 
 859         // 3.3 Remove all media data, from this track buffer, that contain starting timestamps greater than or equal to
 860         // start and less than the remove end timestamp.
 861         // NOTE: frames must be removed in decode order, so that all dependant frames between the frame to be removed
 862         // and the next sync sample frame are removed. But we must start from the first sample in decode order, not
 863         // presentation order.
 864         auto minmaxDecodeTimeIterPair = std::minmax_element(removePresentationStart, removePresentationEnd, decodeTimeComparator);
 865         auto&amp; firstSample = *minmaxDecodeTimeIterPair.first-&gt;second;
 866         auto&amp; lastSample = *minmaxDecodeTimeIterPair.second-&gt;second;
 867         auto removeDecodeStart = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey({firstSample.decodeTime(), firstSample.presentationTime()});
 868         auto removeDecodeLast = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey({lastSample.decodeTime(), lastSample.presentationTime()});
 869         auto removeDecodeEnd = trackBuffer.samples.decodeOrder().findSyncSampleAfterDecodeIterator(removeDecodeLast);
 870 
 871         DecodeOrderSampleMap::MapType erasedSamples(removeDecodeStart, removeDecodeEnd);
 872         PlatformTimeRanges erasedRanges = removeSamplesFromTrackBuffer(erasedSamples, trackBuffer, this, &quot;removeCodedFrames&quot;);
 873 
 874         // Only force the TrackBuffer to re-enqueue if the removed ranges overlap with enqueued and possibly
 875         // not yet displayed samples.
<span class="line-modified"> 876         if (trackBuffer.highestEnqueuedPresentationTime.isValid() &amp;&amp; currentMediaTime &lt; trackBuffer.highestEnqueuedPresentationTime) {</span>
<span class="line-modified"> 877             PlatformTimeRanges possiblyEnqueuedRanges(currentMediaTime, trackBuffer.highestEnqueuedPresentationTime);</span>
 878             possiblyEnqueuedRanges.intersectWith(erasedRanges);
 879             if (possiblyEnqueuedRanges.length()) {
 880                 trackBuffer.needsReenqueueing = true;
 881                 DEBUG_LOG(LOGIDENTIFIER, &quot;the range in removeCodedFrames() includes already enqueued samples, reenqueueing from &quot;, currentMediaTime);
 882                 reenqueueMediaForTime(trackBuffer, trackID, currentMediaTime);
 883             }
 884         }
 885 
 886         erasedRanges.invert();
 887         trackBuffer.buffered.intersectWith(erasedRanges);
 888         setBufferedDirty(true);
 889 
 890         // 3.4 If this object is in activeSourceBuffers, the current playback position is greater than or equal to start
 891         // and less than the remove end timestamp, and HTMLMediaElement.readyState is greater than HAVE_METADATA, then set
 892         // the HTMLMediaElement.readyState attribute to HAVE_METADATA and stall playback.
<span class="line-modified"> 893         if (m_active &amp;&amp; currentMediaTime &gt;= start &amp;&amp; currentMediaTime &lt; end &amp;&amp; m_private-&gt;readyState() &gt; MediaPlayer::ReadyState::HaveMetadata)</span>
<span class="line-modified"> 894             m_private-&gt;setReadyState(MediaPlayer::ReadyState::HaveMetadata);</span>
 895     }
 896 
 897     updateBufferedFromTrackBuffers();
 898 
 899     // 4. If buffer full flag equals true and this object is ready to accept more bytes, then set the buffer full flag to false.
 900     // No-op
 901 
 902     LOG(Media, &quot;SourceBuffer::removeCodedFrames(%p) - buffered = %s&quot;, this, toString(m_buffered-&gt;ranges()).utf8().data());
 903 }
 904 
 905 void SourceBuffer::removeTimerFired()
 906 {
 907     if (isRemoved())
 908         return;
 909 
 910     ASSERT(m_updating);
 911     ASSERT(m_pendingRemoveStart.isValid());
 912     ASSERT(m_pendingRemoveStart &lt; m_pendingRemoveEnd);
 913 
 914     // Section 3.5.7 Range Removal
</pre>
<hr />
<pre>
1027     else
1028         DEBUG_LOG(LOGIDENTIFIER, &quot;evicted &quot;, initialBufferedSize - extraMemoryCost());
1029 #endif
1030 }
1031 
1032 size_t SourceBuffer::maximumBufferSize() const
1033 {
1034     if (isRemoved())
1035         return 0;
1036 
1037     auto* element = m_source-&gt;mediaElement();
1038     if (!element)
1039         return 0;
1040 
1041     return element-&gt;maximumSourceBufferSize(*this);
1042 }
1043 
1044 VideoTrackList&amp; SourceBuffer::videoTracks()
1045 {
1046     if (!m_videoTracks)
<span class="line-modified">1047         m_videoTracks = VideoTrackList::create(makeWeakPtr(m_source-&gt;mediaElement()), scriptExecutionContext());</span>
1048     return *m_videoTracks;
1049 }
1050 
1051 AudioTrackList&amp; SourceBuffer::audioTracks()
1052 {
1053     if (!m_audioTracks)
<span class="line-modified">1054         m_audioTracks = AudioTrackList::create(makeWeakPtr(m_source-&gt;mediaElement()), scriptExecutionContext());</span>
1055     return *m_audioTracks;
1056 }
1057 
1058 TextTrackList&amp; SourceBuffer::textTracks()
1059 {
1060     if (!m_textTracks)
<span class="line-modified">1061         m_textTracks = TextTrackList::create(makeWeakPtr(m_source-&gt;mediaElement()), scriptExecutionContext());</span>
1062     return *m_textTracks;
1063 }
1064 
1065 void SourceBuffer::setActive(bool active)
1066 {
1067     if (m_active == active)
1068         return;
1069 
1070     m_active = active;
1071     m_private-&gt;setActive(active);
1072     if (!isRemoved())
1073         m_source-&gt;sourceBufferDidChangeActiveState(*this, active);
1074 }
1075 
1076 void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(const InitializationSegment&amp; segment)
1077 {
1078     if (isRemoved())
1079         return;
1080 
1081     ALWAYS_LOG(LOGIDENTIFIER);
</pre>
<hr />
<pre>
1275 
1276             m_textCodecs.append(trackBuffer.description-&gt;codec());
1277         }
1278 
1279         // 5.5 If active track flag equals true, then run the following steps:
1280         if (activeTrackFlag) {
1281             // 5.5.1 Add this SourceBuffer to activeSourceBuffers.
1282             // 5.5.2 Queue a task to fire a simple event named addsourcebuffer at activeSourceBuffers
1283             setActive(true);
1284         }
1285 
1286         // 5.6 Set first initialization segment flag to true.
1287         m_receivedFirstInitializationSegment = true;
1288     }
1289 
1290     // (Note: Issue #155 adds this step after step 5:)
1291     // 6. Set  pending initialization segment for changeType flag  to false.
1292     m_pendingInitializationSegmentForChangeType = false;
1293 
1294     // 6. If the HTMLMediaElement.readyState attribute is HAVE_NOTHING, then run the following steps:
<span class="line-modified">1295     if (m_private-&gt;readyState() == MediaPlayer::ReadyState::HaveNothing) {</span>
1296         // 6.1 If one or more objects in sourceBuffers have first initialization segment flag set to false, then abort these steps.
1297         for (auto&amp; sourceBuffer : *m_source-&gt;sourceBuffers()) {
1298             if (!sourceBuffer-&gt;m_receivedFirstInitializationSegment)
1299                 return;
1300         }
1301 
1302         // 6.2 Set the HTMLMediaElement.readyState attribute to HAVE_METADATA.
1303         // 6.3 Queue a task to fire a simple event named loadedmetadata at the media element.
<span class="line-modified">1304         m_private-&gt;setReadyState(MediaPlayer::ReadyState::HaveMetadata);</span>
1305     }
1306 
1307     // 7. If the active track flag equals true and the HTMLMediaElement.readyState
1308     // attribute is greater than HAVE_CURRENT_DATA, then set the HTMLMediaElement.readyState
1309     // attribute to HAVE_METADATA.
<span class="line-modified">1310     if (activeTrackFlag &amp;&amp; m_private-&gt;readyState() &gt; MediaPlayer::ReadyState::HaveCurrentData)</span>
<span class="line-modified">1311         m_private-&gt;setReadyState(MediaPlayer::ReadyState::HaveMetadata);</span>
1312 }
1313 
1314 bool SourceBuffer::validateInitializationSegment(const InitializationSegment&amp; segment)
1315 {
1316     // FIXME: ordering of all 3.5.X (X&gt;=7) functions needs to be updated to post-[24 July 2014 Editor&#39;s Draft] version
1317     // 3.5.8 Initialization Segment Received (ctd)
1318     // https://rawgit.com/w3c/media-source/c3ad59c7a370d04430969ba73d18dc9bcde57a33/index.html#sourcebuffer-init-segment-received [Editor&#39;s Draft 09 January 2015]
1319 
1320     // Note: those are checks from step 3.1
1321     //   * The number of audio, video, and text tracks match what was in the first initialization segment.
1322     if (segment.audioTracks.size() != audioTracks().length()
1323         || segment.videoTracks.size() != videoTracks().length()
1324         || segment.textTracks.size() != textTracks().length())
1325         return false;
1326 
1327     //   * The codecs for each track, match what was specified in the first initialization segment.
1328     // (Note: Issue #155 strikes out this check. For broad compatibility when this experimental feature
1329     // is not enabled, only perform this check if the &quot;pending initialization segment for changeType flag&quot;
1330     // is not set.)
1331     for (auto&amp; audioTrackInfo : segment.audioTracks) {
</pre>
<hr />
<pre>
1666                     if (presentationTimestamp &lt; removeWindowTimestamp)
1667                         erasedSamples.addSample(*iter-&gt;second);
1668                 }
1669 
1670                 // If track buffer contains timed text coded frames:
1671                 // Run the text splice frame algorithm and if a splice frame is returned, assign it to spliced timed text frame.
1672                 // FIXME: Add support for sample splicing.
1673             }
1674         }
1675 
1676         // 1.15 Remove existing coded frames in track buffer:
1677         // If highest presentation timestamp for track buffer is not set:
1678         if (trackBuffer.highestPresentationTimestamp.isInvalid()) {
1679             // Remove all coded frames from track buffer that have a presentation timestamp greater than or
1680             // equal to presentation timestamp and less than frame end timestamp.
1681             auto iter_pair = trackBuffer.samples.presentationOrder().findSamplesBetweenPresentationTimes(presentationTimestamp, frameEndTimestamp);
1682             if (iter_pair.first != trackBuffer.samples.presentationOrder().end())
1683                 erasedSamples.addRange(iter_pair.first, iter_pair.second);
1684         }
1685 
<span class="line-added">1686         // When appending media containing B-frames (media whose samples&#39; presentation timestamps</span>
<span class="line-added">1687         // do not increase monotonically, the prior erase steps could leave a sample in the trackBuffer</span>
<span class="line-added">1688         // which will be disconnected from its previous I-frame. If the incoming frame is an I-frame,</span>
<span class="line-added">1689         // remove all samples in decode order between the incoming I-frame&#39;s decode timestamp and the</span>
<span class="line-added">1690         // next I-frame. See &lt;https://github.com/w3c/media-source/issues/187&gt; for a discussion of what</span>
<span class="line-added">1691         // the how the MSE specification should handlie this secnario.</span>
<span class="line-added">1692         do {</span>
<span class="line-added">1693             if (!sample.isSync())</span>
<span class="line-added">1694                 break;</span>
<span class="line-added">1695 </span>
<span class="line-added">1696             DecodeOrderSampleMap::KeyType decodeKey(sample.decodeTime(), sample.presentationTime());</span>
<span class="line-added">1697             auto nextSampleInDecodeOrder = trackBuffer.samples.decodeOrder().findSampleAfterDecodeKey(decodeKey);</span>
<span class="line-added">1698             if (nextSampleInDecodeOrder == trackBuffer.samples.decodeOrder().end())</span>
<span class="line-added">1699                 break;</span>
<span class="line-added">1700 </span>
<span class="line-added">1701             if (nextSampleInDecodeOrder-&gt;second-&gt;isSync())</span>
<span class="line-added">1702                 break;</span>
<span class="line-added">1703 </span>
<span class="line-added">1704             auto nextSyncSample = trackBuffer.samples.decodeOrder().findSyncSampleAfterDecodeIterator(nextSampleInDecodeOrder);</span>
<span class="line-added">1705             INFO_LOG(LOGIDENTIFIER, &quot;Discovered out-of-order frames, from: &quot;, *nextSampleInDecodeOrder-&gt;second, &quot; to: &quot;, (nextSyncSample == trackBuffer.samples.decodeOrder().end() ? &quot;[end]&quot;_s : toString(*nextSyncSample-&gt;second)));</span>
<span class="line-added">1706             erasedSamples.addRange(nextSampleInDecodeOrder, nextSyncSample);</span>
<span class="line-added">1707         } while (false);</span>
<span class="line-added">1708 </span>
1709         // There are many files out there where the frame times are not perfectly contiguous and may have small overlaps
1710         // between the beginning of a frame and the end of the previous one; therefore a tolerance is needed whenever
1711         // durations are considered.
1712         // For instance, most WebM files are muxed rounded to the millisecond (the default TimecodeScale of the format)
1713         // but their durations use a finer timescale (causing a sub-millisecond overlap). More rarely, there are also
1714         // MP4 files with slightly off tfdt boxes, presenting a similar problem at the beginning of each fragment.
1715         const MediaTime contiguousFrameTolerance = MediaTime(1, 1000);
1716 
1717         // If highest presentation timestamp for track buffer is set and less than or equal to presentation timestamp
1718         if (trackBuffer.highestPresentationTimestamp.isValid() &amp;&amp; trackBuffer.highestPresentationTimestamp - contiguousFrameTolerance &lt;= presentationTimestamp) {
1719             // Remove all coded frames from track buffer that have a presentation timestamp greater than highest
1720             // presentation timestamp and less than or equal to frame end timestamp.
1721             do {
1722                 // NOTE: Searching from the end of the trackBuffer will be vastly more efficient if the search range is
1723                 // near the end of the buffered range. Use a linear-backwards search if the search range is within one
1724                 // frame duration of the end:
1725                 unsigned bufferedLength = trackBuffer.buffered.length();
1726                 if (!bufferedLength)
1727                     break;
1728 
</pre>
<hr />
<pre>
1752             // Otherwise: Remove all coded frames between the coded frames removed in the previous step
1753             // and the next random access point after those removed frames.
1754             auto firstDecodeIter = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(erasedSamples.decodeOrder().begin()-&gt;first);
1755             auto lastDecodeIter = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(erasedSamples.decodeOrder().rbegin()-&gt;first);
1756             auto nextSyncIter = trackBuffer.samples.decodeOrder().findSyncSampleAfterDecodeIterator(lastDecodeIter);
1757             dependentSamples.insert(firstDecodeIter, nextSyncIter);
1758 
1759             // NOTE: in the case of b-frames, the previous step may leave in place samples whose presentation
1760             // timestamp &lt; presentationTime, but whose decode timestamp &gt;= decodeTime. These will eventually cause
1761             // a decode error if left in place, so remove these samples as well.
1762             DecodeOrderSampleMap::KeyType decodeKey(sample.decodeTime(), sample.presentationTime());
1763             auto samplesWithHigherDecodeTimes = trackBuffer.samples.decodeOrder().findSamplesBetweenDecodeKeys(decodeKey, erasedSamples.decodeOrder().begin()-&gt;first);
1764             if (samplesWithHigherDecodeTimes.first != samplesWithHigherDecodeTimes.second)
1765                 dependentSamples.insert(samplesWithHigherDecodeTimes.first, samplesWithHigherDecodeTimes.second);
1766 
1767             PlatformTimeRanges erasedRanges = removeSamplesFromTrackBuffer(dependentSamples, trackBuffer, this, &quot;sourceBufferPrivateDidReceiveSample&quot;);
1768 
1769             // Only force the TrackBuffer to re-enqueue if the removed ranges overlap with enqueued and possibly
1770             // not yet displayed samples.
1771             MediaTime currentMediaTime = m_source-&gt;currentTime();
<span class="line-modified">1772             if (trackBuffer.highestEnqueuedPresentationTime.isValid() &amp;&amp; currentMediaTime &lt; trackBuffer.highestEnqueuedPresentationTime) {</span>
<span class="line-modified">1773                 PlatformTimeRanges possiblyEnqueuedRanges(currentMediaTime, trackBuffer.highestEnqueuedPresentationTime);</span>
1774                 possiblyEnqueuedRanges.intersectWith(erasedRanges);
1775                 if (possiblyEnqueuedRanges.length())
1776                     trackBuffer.needsReenqueueing = true;
1777             }
1778 
1779             erasedRanges.invert();
1780             trackBuffer.buffered.intersectWith(erasedRanges);
1781             setBufferedDirty(true);
1782         }
1783 
1784         // 1.17 If spliced audio frame is set:
1785         // Add spliced audio frame to the track buffer.
1786         // If spliced timed text frame is set:
1787         // Add spliced timed text frame to the track buffer.
1788         // FIXME: Add support for sample splicing.
1789 
1790         // Otherwise:
1791         // Add the coded frame with the presentation timestamp, decode timestamp, and frame duration to the track buffer.
1792         trackBuffer.samples.addSample(sample);
1793 
1794         // Note: The terminology here is confusing: &quot;enqueuing&quot; means providing a frame to the inner media framework.
<span class="line-modified">1795         // First, frames are inserted in the decode queue; later, at the end of the append some of the frames in the</span>
<span class="line-modified">1796         // decode may be &quot;enqueued&quot; (sent to the inner media framework) in `provideMediaData()`.</span>
1797         //
<span class="line-modified">1798         // In order to check whether a frame should be added to the decode queue we check that it does not precede any</span>
<span class="line-modified">1799         // frame already enqueued.</span>
<span class="line-added">1800         //</span>
<span class="line-added">1801         // Note that adding a frame to the decode queue is no guarantee that it will be actually enqueued at that point.</span>
<span class="line-added">1802         // If the frame is after the discontinuity boundary, the enqueueing algorithm will hold it there until samples</span>
<span class="line-added">1803         // with earlier timestamps are enqueued. The decode queue is not FIFO, but rather an ordered map.</span>
1804         DecodeOrderSampleMap::KeyType decodeKey(sample.decodeTime(), sample.presentationTime());
1805         if (trackBuffer.lastEnqueuedDecodeKey.first.isInvalid() || decodeKey &gt; trackBuffer.lastEnqueuedDecodeKey) {
1806             trackBuffer.decodeQueue.insert(DecodeOrderSampleMap::MapType::value_type(decodeKey, &amp;sample));
1807 
1808             if (trackBuffer.minimumEnqueuedPresentationTime.isValid() &amp;&amp; sample.presentationTime() &lt; trackBuffer.minimumEnqueuedPresentationTime)
1809                 trackBuffer.needsMinimumUpcomingPresentationTimeUpdating = true;
1810         }
1811 
1812         // NOTE: the spec considers &quot;Coded Frame Duration&quot; to be the presentation duration, but this is not necessarily equal
1813         // to the decoded duration. When comparing deltas between decode timestamps, the decode duration, not the presentation.
1814         if (trackBuffer.lastDecodeTimestamp.isValid()) {
1815             MediaTime lastDecodeDuration = decodeTimestamp - trackBuffer.lastDecodeTimestamp;
1816             if (!trackBuffer.greatestDecodeDuration.isValid() || lastDecodeDuration &gt; trackBuffer.greatestDecodeDuration)
1817                 trackBuffer.greatestDecodeDuration = lastDecodeDuration;
1818         }
1819 
1820         // 1.18 Set last decode timestamp for track buffer to decode timestamp.
1821         trackBuffer.lastDecodeTimestamp = decodeTimestamp;
1822 
1823         // 1.19 Set last frame duration for track buffer to frame duration.
</pre>
<hr />
<pre>
2038 
2039 #if !RELEASE_LOG_DISABLED
2040     unsigned enqueuedSamples = 0;
2041 #endif
2042 
2043     if (trackBuffer.needsMinimumUpcomingPresentationTimeUpdating)
2044         resetMinimumUpcomingPresentationTime(trackBuffer, trackID);
2045 
2046     while (!trackBuffer.decodeQueue.empty()) {
2047         if (!m_private-&gt;isReadyForMoreSamples(trackID)) {
2048             DEBUG_LOG(LOGIDENTIFIER, &quot;bailing early, track id &quot;, trackID, &quot; is not ready for more data&quot;);
2049             m_private-&gt;notifyClientWhenReadyForMoreSamples(trackID);
2050             break;
2051         }
2052 
2053         // FIXME(rdar://problem/20635969): Remove this re-entrancy protection when the aforementioned radar is resolved; protecting
2054         // against re-entrancy introduces a small inefficency when removing appended samples from the decode queue one at a time
2055         // rather than when all samples have been enqueued.
2056         auto sample = trackBuffer.decodeQueue.begin()-&gt;second;
2057 
<span class="line-modified">2058         if (sample-&gt;decodeTime() &gt; trackBuffer.enqueueDiscontinuityBoundary) {</span>
<span class="line-modified">2059             DEBUG_LOG(LOGIDENTIFIER, &quot;bailing early because of unbuffered gap, new sample: &quot;, sample-&gt;decodeTime(), &quot; &gt;= the current discontinuity boundary: &quot;, trackBuffer.enqueueDiscontinuityBoundary);</span>











2060             break;
2061         }
2062 
2063         // Remove the sample from the decode queue now.
2064         trackBuffer.decodeQueue.erase(trackBuffer.decodeQueue.begin());
2065 
<span class="line-modified">2066         MediaTime samplePresentationEnd = sample-&gt;presentationTime() + sample-&gt;duration();</span>
<span class="line-added">2067         if (trackBuffer.highestEnqueuedPresentationTime.isInvalid() || samplePresentationEnd &gt; trackBuffer.highestEnqueuedPresentationTime)</span>
<span class="line-added">2068             trackBuffer.highestEnqueuedPresentationTime = samplePresentationEnd;</span>
<span class="line-added">2069 </span>
2070         trackBuffer.lastEnqueuedDecodeKey = {sample-&gt;decodeTime(), sample-&gt;presentationTime()};
<span class="line-modified">2071         trackBuffer.enqueueDiscontinuityBoundary = sample-&gt;decodeTime() + sample-&gt;duration() + discontinuityTolerance;</span>
<span class="line-added">2072 </span>
2073         m_private-&gt;enqueueSample(sample.releaseNonNull(), trackID);
2074 #if !RELEASE_LOG_DISABLED
2075         ++enqueuedSamples;
2076 #endif
2077     }
2078 
2079     updateMinimumUpcomingPresentationTime(trackBuffer, trackID);
2080 
2081 #if !RELEASE_LOG_DISABLED
2082     DEBUG_LOG(LOGIDENTIFIER, &quot;enqueued &quot;, enqueuedSamples, &quot; samples, &quot;, static_cast&lt;size_t&gt;(trackBuffer.decodeQueue.size()), &quot; remaining&quot;);
2083 #endif
2084 
2085     trySignalAllSamplesInTrackEnqueued(trackID);
2086 }
2087 
2088 void SourceBuffer::updateMinimumUpcomingPresentationTime(TrackBuffer&amp; trackBuffer, const AtomString&amp; trackID)
2089 {
2090     if (!m_private-&gt;canSetMinimumUpcomingPresentationTime(trackID))
2091         return;
2092 
</pre>
<hr />
<pre>
2122 
2123 void SourceBuffer::trySignalAllSamplesInTrackEnqueued(const AtomString&amp; trackID)
2124 {
2125     if (m_source-&gt;isEnded() &amp;&amp; m_trackBufferMap.get(trackID).decodeQueue.empty()) {
2126         DEBUG_LOG(LOGIDENTIFIER, &quot;enqueued all samples from track &quot;, trackID);
2127         m_private-&gt;allSamplesInTrackEnqueued(trackID);
2128     }
2129 }
2130 
2131 void SourceBuffer::trySignalAllSamplesEnqueued()
2132 {
2133     for (const AtomString&amp; trackID : m_trackBufferMap.keys())
2134         trySignalAllSamplesInTrackEnqueued(trackID);
2135 }
2136 
2137 void SourceBuffer::reenqueueMediaForTime(TrackBuffer&amp; trackBuffer, const AtomString&amp; trackID, const MediaTime&amp; time)
2138 {
2139     m_private-&gt;flush(trackID);
2140     trackBuffer.decodeQueue.clear();
2141 
<span class="line-added">2142     trackBuffer.highestEnqueuedPresentationTime = MediaTime::invalidTime();</span>
<span class="line-added">2143     trackBuffer.lastEnqueuedDecodeKey = {MediaTime::invalidTime(), MediaTime::invalidTime()};</span>
<span class="line-added">2144     trackBuffer.enqueueDiscontinuityBoundary = time + discontinuityTolerance;</span>
<span class="line-added">2145 </span>
2146     // Find the sample which contains the current presentation time.
2147     auto currentSamplePTSIterator = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(time);
2148 
2149     if (currentSamplePTSIterator == trackBuffer.samples.presentationOrder().end())
2150         currentSamplePTSIterator = trackBuffer.samples.presentationOrder().findSampleStartingOnOrAfterPresentationTime(time);
2151 
2152     if (currentSamplePTSIterator == trackBuffer.samples.presentationOrder().end()
2153         || (currentSamplePTSIterator-&gt;first - time) &gt; MediaSource::currentTimeFudgeFactor())
2154         return;
2155 
2156     // Seach backward for the previous sync sample.
2157     DecodeOrderSampleMap::KeyType decodeKey(currentSamplePTSIterator-&gt;second-&gt;decodeTime(), currentSamplePTSIterator-&gt;second-&gt;presentationTime());
2158     auto currentSampleDTSIterator = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(decodeKey);
2159     ASSERT(currentSampleDTSIterator != trackBuffer.samples.decodeOrder().end());
2160 
2161     auto reverseCurrentSampleIter = --DecodeOrderSampleMap::reverse_iterator(currentSampleDTSIterator);
2162     auto reverseLastSyncSampleIter = trackBuffer.samples.decodeOrder().findSyncSamplePriorToDecodeIterator(reverseCurrentSampleIter);
2163     if (reverseLastSyncSampleIter == trackBuffer.samples.decodeOrder().rend())
2164         return;
2165 
2166     // Fill the decode queue with the non-displaying samples.
2167     for (auto iter = reverseLastSyncSampleIter; iter != reverseCurrentSampleIter; --iter) {
2168         auto copy = iter-&gt;second-&gt;createNonDisplayingCopy();
2169         DecodeOrderSampleMap::KeyType decodeKey(copy-&gt;decodeTime(), copy-&gt;presentationTime());
2170         trackBuffer.decodeQueue.insert(DecodeOrderSampleMap::MapType::value_type(decodeKey, WTFMove(copy)));
2171     }
2172 













2173     // Fill the decode queue with the remaining samples.
2174     for (auto iter = currentSampleDTSIterator; iter != trackBuffer.samples.decodeOrder().end(); ++iter)
2175         trackBuffer.decodeQueue.insert(*iter);
2176     provideMediaData(trackBuffer, trackID);
2177 
2178     trackBuffer.needsReenqueueing = false;
2179 }
2180 
2181 
2182 void SourceBuffer::didDropSample()
2183 {
2184     if (!isRemoved())
2185         m_source-&gt;mediaElement()-&gt;incrementDroppedFrameCount();
2186 }
2187 
2188 void SourceBuffer::monitorBufferingRate()
2189 {
2190     MonotonicTime now = MonotonicTime::now();
2191     Seconds interval = now - m_timeOfBufferingMonitor;
2192     double rateSinceLastMonitor = m_bufferedSinceLastMonitor / interval.seconds();
</pre>
</td>
</tr>
</table>
<center><a href="SampleMap.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="SourceBuffer.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>