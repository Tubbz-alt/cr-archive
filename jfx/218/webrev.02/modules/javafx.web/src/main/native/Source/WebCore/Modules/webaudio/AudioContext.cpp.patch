diff a/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.cpp b/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.cpp
--- a/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.cpp
+++ b/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.cpp
@@ -138,11 +138,11 @@
 #if !RELEASE_LOG_DISABLED
     , m_logger(document.logger())
     , m_logIdentifier(uniqueLogIdentifier())
 #endif
     , m_mediaSession(PlatformMediaSession::create(*this))
-    , m_eventQueue(makeUnique<GenericEventQueue>(*this))
+    , m_eventQueue(MainThreadGenericEventQueue::create(*this))
 {
     // According to spec AudioContext must die only after page navigate.
     // Lets mark it as ActiveDOMObject with pending activity and unmark it in clear method.
     makePendingActivity();
 
@@ -156,24 +156,24 @@
     document.addAudioProducer(*this);
     document.registerForVisibilityStateChangedCallbacks(*this);
 }
 
 // Constructor for offline (non-realtime) rendering.
-AudioContext::AudioContext(Document& document, unsigned numberOfChannels, size_t numberOfFrames, float sampleRate)
+AudioContext::AudioContext(Document& document, AudioBuffer* renderTarget)
     : ActiveDOMObject(document)
 #if !RELEASE_LOG_DISABLED
     , m_logger(document.logger())
     , m_logIdentifier(uniqueLogIdentifier())
 #endif
     , m_isOfflineContext(true)
     , m_mediaSession(PlatformMediaSession::create(*this))
-    , m_eventQueue(makeUnique<GenericEventQueue>(*this))
+    , m_eventQueue(MainThreadGenericEventQueue::create(*this))
+    , m_renderTarget(renderTarget)
 {
     constructCommon();
 
     // Create a new destination for offline rendering.
-    m_renderTarget = AudioBuffer::create(numberOfChannels, numberOfFrames, sampleRate);
     m_destinationNode = OfflineAudioDestinationNode::create(*this, m_renderTarget.get());
 }
 
 void AudioContext::constructCommon()
 {
@@ -334,20 +334,28 @@
     m_isStopScheduled = true;
 
     ASSERT(document());
     document()->updateIsPlayingMedia();
 
-    m_eventQueue->close();
-
     uninitialize();
     clear();
 }
 
-bool AudioContext::canSuspendForDocumentSuspension() const
+void AudioContext::suspend(ReasonForSuspension)
+{
+    if (state() == State::Running) {
+        m_mediaSession->beginInterruption(PlatformMediaSession::PlaybackSuspended);
+        document()->updateIsPlayingMedia();
+    }
+}
+
+void AudioContext::resume()
 {
-    // FIXME: We should be able to suspend while rendering as well with some more code.
-    return m_state == State::Suspended || m_state == State::Closed;
+    if (state() == State::Interrupted) {
+        m_mediaSession->endInterruption(PlatformMediaSession::MayResumePlaying);
+        document()->updateIsPlayingMedia();
+    }
 }
 
 const char* AudioContext::activeDOMObjectName() const
 {
     return "AudioContext";
@@ -1229,11 +1237,11 @@
 void AudioContext::decrementActiveSourceCount()
 {
     --m_activeSourceCount;
 }
 
-void AudioContext::suspend(DOMPromiseDeferred<void>&& promise)
+void AudioContext::suspendRendering(DOMPromiseDeferred<void>&& promise)
 {
     if (isOfflineContext() || m_isStopScheduled) {
         promise.reject(InvalidStateError);
         return;
     }
@@ -1258,11 +1266,11 @@
     m_destinationNode->suspend([this, protectedThis = makeRef(*this)] {
         setState(State::Suspended);
     });
 }
 
-void AudioContext::resume(DOMPromiseDeferred<void>&& promise)
+void AudioContext::resumeRendering(DOMPromiseDeferred<void>&& promise)
 {
     if (isOfflineContext() || m_isStopScheduled) {
         promise.reject(InvalidStateError);
         return;
     }
