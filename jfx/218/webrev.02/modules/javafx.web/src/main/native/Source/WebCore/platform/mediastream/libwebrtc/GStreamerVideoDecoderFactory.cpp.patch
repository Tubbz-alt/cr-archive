diff a/modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoDecoderFactory.cpp b/modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoDecoderFactory.cpp
--- a/modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoDecoderFactory.cpp
+++ b/modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoDecoderFactory.cpp
@@ -192,15 +192,14 @@
         return WEBRTC_VIDEO_CODEC_OK;
     }
 
     int32_t Decode(const webrtc::EncodedImage& inputImage,
         bool,
-        const webrtc::CodecSpecificInfo*,
         int64_t renderTimeMs) override
     {
         if (m_needsKeyframe) {
-            if (inputImage._frameType != webrtc::kVideoFrameKey) {
+            if (inputImage._frameType != webrtc::VideoFrameType::kVideoFrameKey) {
                 GST_ERROR("Waiting for keyframe but got a delta unit... asking for keyframe");
                 return WEBRTC_VIDEO_CODEC_ERROR;
             }
             if (inputImage._completeFrame)
                 m_needsKeyframe = false;
@@ -222,12 +221,12 @@
             m_firstBufferPts = (static_cast<guint64>(renderTimeMs)) * GST_MSECOND;
             m_firstBufferDts = (static_cast<guint64>(inputImage.Timestamp())) * GST_MSECOND;
         }
 
         // FIXME- Use a GstBufferPool.
-        auto buffer = adoptGRef(gst_buffer_new_wrapped(g_memdup(inputImage._buffer, inputImage._size),
-            inputImage._size));
+        auto buffer = adoptGRef(gst_buffer_new_wrapped(g_memdup(inputImage.data(), inputImage.size()),
+            inputImage.size()));
         GST_BUFFER_DTS(buffer.get()) = (static_cast<guint64>(inputImage.Timestamp()) * GST_MSECOND) - m_firstBufferDts;
         GST_BUFFER_PTS(buffer.get()) = (static_cast<guint64>(renderTimeMs) * GST_MSECOND) - m_firstBufferPts;
         InputTimestamps timestamps = {inputImage.Timestamp(), renderTimeMs};
         m_dtsPtsMap[GST_BUFFER_PTS(buffer.get())] = timestamps;
 
@@ -352,33 +351,10 @@
     int32_t InitDecode(const webrtc::VideoCodec* codecInfo, int32_t nCores) final
     {
         if (codecInfo && codecInfo->codecType != webrtc::kVideoCodecH264)
             return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
 
-        m_profile = nullptr;
-        if (codecInfo) {
-            auto h264Info = codecInfo->H264();
-
-            switch (h264Info.profile) {
-            case webrtc::H264::kProfileConstrainedBaseline:
-                m_profile = "constrained-baseline";
-                break;
-            case webrtc::H264::kProfileBaseline:
-                m_profile = "baseline";
-                break;
-            case webrtc::H264::kProfileMain:
-                m_profile = "main";
-                break;
-            case webrtc::H264::kProfileConstrainedHigh:
-                m_profile = "constrained-high";
-                break;
-            case webrtc::H264::kProfileHigh:
-                m_profile = "high";
-                break;
-            }
-        }
-
         return GStreamerVideoDecoder::InitDecode(codecInfo, nCores);
     }
 
     GstCaps* GetCapsForFrame(const webrtc::EncodedImage& image) final
     {
@@ -393,13 +369,10 @@
         return m_caps.get();
     }
     const gchar* Caps() final { return "video/x-h264"; }
     const gchar* Name() final { return cricket::kH264CodecName; }
     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecH264; }
-
-private:
-    const gchar* m_profile;
 };
 
 class VP8Decoder : public GStreamerVideoDecoder {
 public:
     VP8Decoder() { }
