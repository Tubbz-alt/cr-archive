<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGByteCodeParser.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="DFGBlockInsertionSet.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGCFAPhase.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGByteCodeParser.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (C) 2011-2019 Apple Inc. All rights reserved.</span>
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;DFGByteCodeParser.h&quot;
  28 
  29 #if ENABLE(DFG_JIT)
  30 
  31 #include &quot;ArithProfile.h&quot;
  32 #include &quot;ArrayConstructor.h&quot;
  33 #include &quot;BasicBlockLocation.h&quot;
  34 #include &quot;BuiltinNames.h&quot;
<span class="line-modified">  35 #include &quot;BytecodeStructs.h&quot;</span>


  36 #include &quot;CallLinkStatus.h&quot;
  37 #include &quot;CodeBlock.h&quot;
  38 #include &quot;CodeBlockWithJITType.h&quot;
  39 #include &quot;CommonSlowPaths.h&quot;
  40 #include &quot;DFGAbstractHeap.h&quot;
  41 #include &quot;DFGArrayMode.h&quot;
  42 #include &quot;DFGCFG.h&quot;
  43 #include &quot;DFGCapabilities.h&quot;
  44 #include &quot;DFGClobberize.h&quot;
  45 #include &quot;DFGClobbersExitState.h&quot;
  46 #include &quot;DFGGraph.h&quot;
  47 #include &quot;DFGJITCode.h&quot;
  48 #include &quot;FunctionCodeBlock.h&quot;
<span class="line-modified">  49 #include &quot;GetByIdStatus.h&quot;</span>

  50 #include &quot;Heap.h&quot;
  51 #include &quot;InByIdStatus.h&quot;
  52 #include &quot;InstanceOfStatus.h&quot;

  53 #include &quot;JSCInlines.h&quot;
<span class="line-removed">  54 #include &quot;JSFixedArray.h&quot;</span>
  55 #include &quot;JSImmutableButterfly.h&quot;


  56 #include &quot;JSModuleEnvironment.h&quot;
  57 #include &quot;JSModuleNamespaceObject.h&quot;

  58 #include &quot;NumberConstructor.h&quot;
  59 #include &quot;ObjectConstructor.h&quot;
  60 #include &quot;OpcodeInlines.h&quot;
  61 #include &quot;PreciseJumpTargets.h&quot;
  62 #include &quot;PutByIdFlags.h&quot;
  63 #include &quot;PutByIdStatus.h&quot;
  64 #include &quot;RegExpPrototype.h&quot;
  65 #include &quot;StackAlignment.h&quot;
  66 #include &quot;StringConstructor.h&quot;
  67 #include &quot;StructureStubInfo.h&quot;
  68 #include &quot;SymbolConstructor.h&quot;
  69 #include &quot;Watchdog.h&quot;
  70 #include &lt;wtf/CommaPrinter.h&gt;
  71 #include &lt;wtf/HashMap.h&gt;
  72 #include &lt;wtf/MathExtras.h&gt;

  73 #include &lt;wtf/SetForScope.h&gt;
  74 #include &lt;wtf/StdLibExtras.h&gt;
  75 
  76 namespace JSC { namespace DFG {
  77 
  78 namespace DFGByteCodeParserInternal {
  79 #ifdef NDEBUG
<span class="line-modified">  80 static const bool verbose = false;</span>
  81 #else
<span class="line-modified">  82 static const bool verbose = true;</span>
  83 #endif
  84 } // namespace DFGByteCodeParserInternal
  85 
  86 #define VERBOSE_LOG(...) do { \
  87 if (DFGByteCodeParserInternal::verbose &amp;&amp; Options::verboseDFGBytecodeParsing()) \
  88 dataLog(__VA_ARGS__); \
  89 } while (false)
  90 
  91 // === ByteCodeParser ===
  92 //
  93 // This class is used to compile the dataflow graph from a CodeBlock.
  94 class ByteCodeParser {
  95 public:
  96     ByteCodeParser(Graph&amp; graph)
  97         : m_vm(&amp;graph.m_vm)
  98         , m_codeBlock(graph.m_codeBlock)
  99         , m_profiledBlock(graph.m_profiledBlock)
 100         , m_graph(graph)
 101         , m_currentBlock(0)
 102         , m_currentIndex(0)
 103         , m_constantUndefined(graph.freeze(jsUndefined()))
 104         , m_constantNull(graph.freeze(jsNull()))
 105         , m_constantNaN(graph.freeze(jsNumber(PNaN)))
 106         , m_constantOne(graph.freeze(jsNumber(1)))
 107         , m_numArguments(m_codeBlock-&gt;numParameters())
 108         , m_numLocals(m_codeBlock-&gt;numCalleeLocals())

 109         , m_parameterSlots(0)
 110         , m_numPassedVarArgs(0)
 111         , m_inlineStackTop(0)
 112         , m_currentInstruction(0)
 113         , m_hasDebuggerEnabled(graph.hasDebuggerEnabled())
 114     {
 115         ASSERT(m_profiledBlock);
 116     }
 117 
 118     // Parse a full CodeBlock of bytecode.
 119     void parse();
 120 
 121 private:
 122     struct InlineStackEntry;
 123 
 124     // Just parse from m_currentIndex to the end of the current CodeBlock.
 125     void parseCodeBlock();
 126 
 127     void ensureLocals(unsigned newNumLocals)
 128     {
 129         VERBOSE_LOG(&quot;   ensureLocals: trying to raise m_numLocals from &quot;, m_numLocals, &quot; to &quot;, newNumLocals, &quot;\n&quot;);
 130         if (newNumLocals &lt;= m_numLocals)
 131             return;
 132         m_numLocals = newNumLocals;
 133         for (size_t i = 0; i &lt; m_graph.numBlocks(); ++i)
 134             m_graph.block(i)-&gt;ensureLocals(newNumLocals);
 135     }
 136 











 137     // Helper for min and max.
 138     template&lt;typename ChecksFunctor&gt;
 139     bool handleMinMax(VirtualRegister result, NodeType op, int registerOffset, int argumentCountIncludingThis, const ChecksFunctor&amp; insertChecks);
 140 
 141     void refineStatically(CallLinkStatus&amp;, Node* callTarget);
 142     // Blocks can either be targetable (i.e. in the m_blockLinkingTargets of one InlineStackEntry) with a well-defined bytecodeBegin,
 143     // or they can be untargetable, with bytecodeBegin==UINT_MAX, to be managed manually and not by the linkBlock machinery.
 144     // This is used most notably when doing polyvariant inlining (it requires a fair bit of control-flow with no bytecode analog).
 145     // It is also used when doing an early return from an inlined callee: it is easier to fix the bytecode index later on if needed
 146     // than to move the right index all the way to the treatment of op_ret.
<span class="line-modified"> 147     BasicBlock* allocateTargetableBlock(unsigned bytecodeIndex);</span>
 148     BasicBlock* allocateUntargetableBlock();
 149     // An untargetable block can be given a bytecodeIndex to be later managed by linkBlock, but only once, and it can never go in the other direction
<span class="line-modified"> 150     void makeBlockTargetable(BasicBlock*, unsigned bytecodeIndex);</span>
 151     void addJumpTo(BasicBlock*);
 152     void addJumpTo(unsigned bytecodeIndex);
 153     // Handle calls. This resolves issues surrounding inlining and intrinsics.
 154     enum Terminality { Terminal, NonTerminal };
 155     Terminality handleCall(
 156         VirtualRegister result, NodeType op, InlineCallFrame::Kind, unsigned instructionSize,
 157         Node* callTarget, int argumentCountIncludingThis, int registerOffset, CallLinkStatus,
 158         SpeculatedType prediction);
 159     template&lt;typename CallOp&gt;
 160     Terminality handleCall(const Instruction* pc, NodeType op, CallMode);
 161     template&lt;typename CallOp&gt;
 162     Terminality handleVarargsCall(const Instruction* pc, NodeType op, CallMode);
 163     void emitFunctionChecks(CallVariant, Node* callTarget, VirtualRegister thisArgumnt);
 164     void emitArgumentPhantoms(int registerOffset, int argumentCountIncludingThis);
 165     Node* getArgumentCount();
 166     template&lt;typename ChecksFunctor&gt;
 167     bool handleRecursiveTailCall(Node* callTargetNode, CallVariant, int registerOffset, int argumentCountIncludingThis, const ChecksFunctor&amp; emitFunctionCheckIfNeeded);
 168     unsigned inliningCost(CallVariant, int argumentCountIncludingThis, InlineCallFrame::Kind); // Return UINT_MAX if it&#39;s not an inlining candidate. By convention, intrinsics have a cost of 1.
 169     // Handle inlining. Return true if it succeeded, false if we need to plant a call.
 170     bool handleVarargsInlining(Node* callTargetNode, VirtualRegister result, const CallLinkStatus&amp;, int registerOffset, VirtualRegister thisArgument, VirtualRegister argumentsArgument, unsigned argumentsOffset, NodeType callOp, InlineCallFrame::Kind);
 171     unsigned getInliningBalance(const CallLinkStatus&amp;, CodeSpecializationKind);
 172     enum class CallOptimizationResult { OptimizedToJump, Inlined, DidNothing };
<span class="line-modified"> 173     CallOptimizationResult handleCallVariant(Node* callTargetNode, VirtualRegister result, CallVariant, int registerOffset, VirtualRegister thisArgument, int argumentCountIncludingThis, unsigned nextOffset, InlineCallFrame::Kind, SpeculatedType prediction, unsigned&amp; inliningBalance, BasicBlock* continuationBlock, bool needsToCheckCallee);</span>
<span class="line-modified"> 174     CallOptimizationResult handleInlining(Node* callTargetNode, VirtualRegister result, const CallLinkStatus&amp;, int registerOffset, VirtualRegister thisArgument, int argumentCountIncludingThis, unsigned nextOffset, NodeType callOp, InlineCallFrame::Kind, SpeculatedType prediction);</span>
 175     template&lt;typename ChecksFunctor&gt;
 176     void inlineCall(Node* callTargetNode, VirtualRegister result, CallVariant, int registerOffset, int argumentCountIncludingThis, InlineCallFrame::Kind, BasicBlock* continuationBlock, const ChecksFunctor&amp; insertChecks);
 177     // Handle intrinsic functions. Return true if it succeeded, false if we need to plant a call.
 178     template&lt;typename ChecksFunctor&gt;
 179     bool handleIntrinsicCall(Node* callee, VirtualRegister result, Intrinsic, int registerOffset, int argumentCountIncludingThis, SpeculatedType prediction, const ChecksFunctor&amp; insertChecks);
 180     template&lt;typename ChecksFunctor&gt;
 181     bool handleDOMJITCall(Node* callee, VirtualRegister result, const DOMJIT::Signature*, int registerOffset, int argumentCountIncludingThis, SpeculatedType prediction, const ChecksFunctor&amp; insertChecks);
 182     template&lt;typename ChecksFunctor&gt;
 183     bool handleIntrinsicGetter(VirtualRegister result, SpeculatedType prediction, const GetByIdVariant&amp; intrinsicVariant, Node* thisNode, const ChecksFunctor&amp; insertChecks);
 184     template&lt;typename ChecksFunctor&gt;
 185     bool handleTypedArrayConstructor(VirtualRegister result, InternalFunction*, int registerOffset, int argumentCountIncludingThis, TypedArrayType, const ChecksFunctor&amp; insertChecks);
 186     template&lt;typename ChecksFunctor&gt;
 187     bool handleConstantInternalFunction(Node* callTargetNode, VirtualRegister result, InternalFunction*, int registerOffset, int argumentCountIncludingThis, CodeSpecializationKind, SpeculatedType, const ChecksFunctor&amp; insertChecks);
 188     Node* handlePutByOffset(Node* base, unsigned identifier, PropertyOffset, Node* value);
 189     Node* handleGetByOffset(SpeculatedType, Node* base, unsigned identifierNumber, PropertyOffset, NodeType = GetByOffset);
 190     bool handleDOMJITGetter(VirtualRegister result, const GetByIdVariant&amp;, Node* thisNode, unsigned identifierNumber, SpeculatedType prediction);
<span class="line-modified"> 191     bool handleModuleNamespaceLoad(VirtualRegister result, SpeculatedType, Node* base, GetByIdStatus);</span>
 192 
 193     template&lt;typename Bytecode&gt;
 194     void handlePutByVal(Bytecode, unsigned instructionSize);
 195     template &lt;typename Bytecode&gt;
 196     void handlePutAccessorById(NodeType, Bytecode);
 197     template &lt;typename Bytecode&gt;
 198     void handlePutAccessorByVal(NodeType, Bytecode);
 199     template &lt;typename Bytecode&gt;
 200     void handleNewFunc(NodeType, Bytecode);
 201     template &lt;typename Bytecode&gt;
 202     void handleNewFuncExp(NodeType, Bytecode);


 203 
 204     // Create a presence ObjectPropertyCondition based on some known offset and structure set. Does not
 205     // check the validity of the condition, but it may return a null one if it encounters a contradiction.
 206     ObjectPropertyCondition presenceLike(
 207         JSObject* knownBase, UniquedStringImpl*, PropertyOffset, const StructureSet&amp;);
 208 
 209     // Attempt to watch the presence of a property. It will watch that the property is present in the same
 210     // way as in all of the structures in the set. It may emit code instead of just setting a watchpoint.
 211     // Returns true if this all works out.
 212     bool checkPresenceLike(JSObject* knownBase, UniquedStringImpl*, PropertyOffset, const StructureSet&amp;);
 213     void checkPresenceLike(Node* base, UniquedStringImpl*, PropertyOffset, const StructureSet&amp;);
 214 
 215     // Works with both GetByIdVariant and the setter form of PutByIdVariant.
 216     template&lt;typename VariantType&gt;
 217     Node* load(SpeculatedType, Node* base, unsigned identifierNumber, const VariantType&amp;);
 218 
 219     Node* store(Node* base, unsigned identifier, const PutByIdVariant&amp;, Node* value);
 220 
 221     template&lt;typename Op&gt;
 222     void parseGetById(const Instruction*);
 223     void handleGetById(
<span class="line-modified"> 224         VirtualRegister destination, SpeculatedType, Node* base, unsigned identifierNumber, GetByIdStatus, AccessType, unsigned instructionSize);</span>
 225     void emitPutById(
 226         Node* base, unsigned identifierNumber, Node* value,  const PutByIdStatus&amp;, bool isDirect);
 227     void handlePutById(
 228         Node* base, unsigned identifierNumber, Node* value, const PutByIdStatus&amp;,
 229         bool isDirect, unsigned intructionSize);
 230 
 231     // Either register a watchpoint or emit a check for this condition. Returns false if the
 232     // condition no longer holds, and therefore no reasonable check can be emitted.
 233     bool check(const ObjectPropertyCondition&amp;);
 234 
 235     GetByOffsetMethod promoteToConstant(GetByOffsetMethod);
 236 
 237     // Either register a watchpoint or emit a check for this condition. It must be a Presence
 238     // condition. It will attempt to promote a Presence condition to an Equivalence condition.
 239     // Emits code for the loaded value that the condition guards, and returns a node containing
 240     // the loaded value. Returns null if the condition no longer holds.
 241     GetByOffsetMethod planLoad(const ObjectPropertyCondition&amp;);
 242     Node* load(SpeculatedType, unsigned identifierNumber, const GetByOffsetMethod&amp;, NodeType = GetByOffset);
 243     Node* load(SpeculatedType, const ObjectPropertyCondition&amp;, NodeType = GetByOffset);
 244 
</pre>
<hr />
<pre>
 246     // watchpoints (or a combination of the two) to make the conditions hold. If any of those
 247     // conditions are no longer checkable, returns false.
 248     bool check(const ObjectPropertyConditionSet&amp;);
 249 
 250     // Calls check() for those conditions that aren&#39;t the slot base, and calls load() for the slot
 251     // base. Does a combination of watchpoint registration and check emission to guard the
 252     // conditions, and emits code to load the value from the slot base. Returns a node containing
 253     // the loaded value. Returns null if any of the conditions were no longer checkable.
 254     GetByOffsetMethod planLoad(const ObjectPropertyConditionSet&amp;);
 255     Node* load(SpeculatedType, const ObjectPropertyConditionSet&amp;, NodeType = GetByOffset);
 256 
 257     void prepareToParseBlock();
 258     void clearCaches();
 259 
 260     // Parse a single basic block of bytecode instructions.
 261     void parseBlock(unsigned limit);
 262     // Link block successors.
 263     void linkBlock(BasicBlock*, Vector&lt;BasicBlock*&gt;&amp; possibleTargets);
 264     void linkBlocks(Vector&lt;BasicBlock*&gt;&amp; unlinkedBlocks, Vector&lt;BasicBlock*&gt;&amp; possibleTargets);
 265 
<span class="line-modified"> 266     VariableAccessData* newVariableAccessData(VirtualRegister operand)</span>










 267     {
 268         ASSERT(!operand.isConstant());
 269 
 270         m_graph.m_variableAccessData.append(operand);
 271         return &amp;m_graph.m_variableAccessData.last();
 272     }
 273 
 274     // Get/Set the operands/result of a bytecode instruction.
<span class="line-modified"> 275     Node* getDirect(VirtualRegister operand)</span>
 276     {
 277         ASSERT(!operand.isConstant());
 278 
<span class="line-removed"> 279         // Is this an argument?</span>
 280         if (operand.isArgument())
<span class="line-modified"> 281             return getArgument(operand);</span>
 282 
<span class="line-modified"> 283         // Must be a local.</span>
<span class="line-removed"> 284         return getLocal(operand);</span>
 285     }
 286 
 287     Node* get(VirtualRegister operand)
 288     {
 289         if (operand.isConstant()) {
 290             unsigned constantIndex = operand.toConstantIndex();
 291             unsigned oldSize = m_constants.size();
 292             if (constantIndex &gt;= oldSize || !m_constants[constantIndex]) {
 293                 const CodeBlock&amp; codeBlock = *m_inlineStackTop-&gt;m_codeBlock;
<span class="line-modified"> 294                 JSValue value = codeBlock.getConstant(operand.offset());</span>
<span class="line-modified"> 295                 SourceCodeRepresentation sourceCodeRepresentation = codeBlock.constantSourceCodeRepresentation(operand.offset());</span>
 296                 if (constantIndex &gt;= oldSize) {
 297                     m_constants.grow(constantIndex + 1);
 298                     for (unsigned i = oldSize; i &lt; m_constants.size(); ++i)
 299                         m_constants[i] = nullptr;
 300                 }
 301 
 302                 Node* constantNode = nullptr;
 303                 if (sourceCodeRepresentation == SourceCodeRepresentation::Double)
 304                     constantNode = addToGraph(DoubleConstant, OpInfo(m_graph.freezeStrong(jsDoubleNumber(value.asNumber()))));
 305                 else
 306                     constantNode = addToGraph(JSConstant, OpInfo(m_graph.freezeStrong(value)));
 307                 m_constants[constantIndex] = constantNode;
 308             }
 309             ASSERT(m_constants[constantIndex]);
 310             return m_constants[constantIndex];
 311         }
 312 
 313         if (inlineCallFrame()) {
 314             if (!inlineCallFrame()-&gt;isClosureCall) {
 315                 JSFunction* callee = inlineCallFrame()-&gt;calleeConstant();
</pre>
<hr />
<pre>
 334 
 335     enum SetMode {
 336         // A normal set which follows a two-phase commit that spans code origins. During
 337         // the current code origin it issues a MovHint, and at the start of the next
 338         // code origin there will be a SetLocal. If the local needs flushing, the second
 339         // SetLocal will be preceded with a Flush.
 340         NormalSet,
 341 
 342         // A set where the SetLocal happens immediately and there is still a Flush. This
 343         // is relevant when assigning to a local in tricky situations for the delayed
 344         // SetLocal logic but where we know that we have not performed any side effects
 345         // within this code origin. This is a safe replacement for NormalSet anytime we
 346         // know that we have not yet performed side effects in this code origin.
 347         ImmediateSetWithFlush,
 348 
 349         // A set where the SetLocal happens immediately and we do not Flush it even if
 350         // this is a local that is marked as needing it. This is relevant when
 351         // initializing locals at the top of a function.
 352         ImmediateNakedSet
 353     };
<span class="line-modified"> 354     Node* setDirect(VirtualRegister operand, Node* value, SetMode setMode = NormalSet)</span>

 355     {
<span class="line-modified"> 356         addToGraph(MovHint, OpInfo(operand.offset()), value);</span>
 357 
 358         // We can&#39;t exit anymore because our OSR exit state has changed.
 359         m_exitOK = false;
 360 
 361         DelayedSetLocal delayed(currentCodeOrigin(), operand, value, setMode);
 362 
 363         if (setMode == NormalSet) {
 364             m_setLocalQueue.append(delayed);
 365             return nullptr;
 366         }
 367 
 368         return delayed.execute(this);
 369     }
 370 
 371     void processSetLocalQueue()
 372     {
 373         for (unsigned i = 0; i &lt; m_setLocalQueue.size(); ++i)
 374             m_setLocalQueue[i].execute(this);
 375         m_setLocalQueue.shrink(0);
 376     }
 377 
 378     Node* set(VirtualRegister operand, Node* value, SetMode setMode = NormalSet)
 379     {
 380         return setDirect(m_inlineStackTop-&gt;remapOperand(operand), value, setMode);
 381     }
 382 
 383     Node* injectLazyOperandSpeculation(Node* node)
 384     {
 385         ASSERT(node-&gt;op() == GetLocal);
 386         ASSERT(node-&gt;origin.semantic.bytecodeIndex() == m_currentIndex);
 387         ConcurrentJSLocker locker(m_inlineStackTop-&gt;m_profiledBlock-&gt;m_lock);
<span class="line-modified"> 388         LazyOperandValueProfileKey key(m_currentIndex, node-&gt;local());</span>
 389         SpeculatedType prediction = m_inlineStackTop-&gt;m_lazyOperands.prediction(locker, key);
 390         node-&gt;variableAccessData()-&gt;predict(prediction);
 391         return node;
 392     }
 393 
 394     // Used in implementing get/set, above, where the operand is a local variable.
<span class="line-modified"> 395     Node* getLocal(VirtualRegister operand)</span>
 396     {
<span class="line-modified"> 397         unsigned local = operand.toLocal();</span>
<span class="line-modified"> 398 </span>
<span class="line-removed"> 399         Node* node = m_currentBlock-&gt;variablesAtTail.local(local);</span>
 400 
 401         // This has two goals: 1) link together variable access datas, and 2)
 402         // try to avoid creating redundant GetLocals. (1) is required for
 403         // correctness - no other phase will ensure that block-local variable
 404         // access data unification is done correctly. (2) is purely opportunistic
 405         // and is meant as an compile-time optimization only.
 406 
 407         VariableAccessData* variable;
 408 
 409         if (node) {
 410             variable = node-&gt;variableAccessData();
 411 
 412             switch (node-&gt;op()) {
 413             case GetLocal:
 414                 return node;
 415             case SetLocal:
 416                 return node-&gt;child1().node();
 417             default:
 418                 break;
 419             }
 420         } else
 421             variable = newVariableAccessData(operand);
 422 
 423         node = injectLazyOperandSpeculation(addToGraph(GetLocal, OpInfo(variable)));
<span class="line-removed"> 424         m_currentBlock-&gt;variablesAtTail.local(local) = node;</span>
 425         return node;
 426     }
<span class="line-modified"> 427     Node* setLocal(const CodeOrigin&amp; semanticOrigin, VirtualRegister operand, Node* value, SetMode setMode = NormalSet)</span>
 428     {

 429         SetForScope&lt;CodeOrigin&gt; originChange(m_currentSemanticOrigin, semanticOrigin);
 430 
<span class="line-modified"> 431         unsigned local = operand.toLocal();</span>





 432 
<span class="line-modified"> 433         if (setMode != ImmediateNakedSet) {</span>
<span class="line-modified"> 434             ArgumentPosition* argumentPosition = findArgumentPositionForLocal(operand);</span>

 435             if (argumentPosition)
 436                 flushDirect(operand, argumentPosition);
<span class="line-modified"> 437             else if (m_graph.needsScopeRegister() &amp;&amp; operand == m_codeBlock-&gt;scopeRegister())</span>
 438                 flush(operand);
 439         }
 440 
 441         VariableAccessData* variableAccessData = newVariableAccessData(operand);
 442         variableAccessData-&gt;mergeStructureCheckHoistingFailed(
 443             m_inlineStackTop-&gt;m_exitProfile.hasExitSite(semanticOrigin.bytecodeIndex(), BadCache));
 444         variableAccessData-&gt;mergeCheckArrayHoistingFailed(
 445             m_inlineStackTop-&gt;m_exitProfile.hasExitSite(semanticOrigin.bytecodeIndex(), BadIndexingType));
 446         Node* node = addToGraph(SetLocal, OpInfo(variableAccessData), value);
<span class="line-modified"> 447         m_currentBlock-&gt;variablesAtTail.local(local) = node;</span>
 448         return node;
 449     }
 450 
 451     // Used in implementing get/set, above, where the operand is an argument.
 452     Node* getArgument(VirtualRegister operand)
 453     {
 454         unsigned argument = operand.toArgument();
 455         ASSERT(argument &lt; m_numArguments);
 456 
 457         Node* node = m_currentBlock-&gt;variablesAtTail.argument(argument);
 458 
 459         VariableAccessData* variable;
 460 
 461         if (node) {
 462             variable = node-&gt;variableAccessData();
 463 
 464             switch (node-&gt;op()) {
 465             case GetLocal:
 466                 return node;
 467             case SetLocal:
 468                 return node-&gt;child1().node();
 469             default:
 470                 break;
 471             }
 472         } else
 473             variable = newVariableAccessData(operand);
 474 
 475         node = injectLazyOperandSpeculation(addToGraph(GetLocal, OpInfo(variable)));
 476         m_currentBlock-&gt;variablesAtTail.argument(argument) = node;
 477         return node;
 478     }
<span class="line-modified"> 479     Node* setArgument(const CodeOrigin&amp; semanticOrigin, VirtualRegister operand, Node* value, SetMode setMode = NormalSet)</span>
 480     {
 481         SetForScope&lt;CodeOrigin&gt; originChange(m_currentSemanticOrigin, semanticOrigin);
 482 
<span class="line-modified"> 483         unsigned argument = operand.toArgument();</span>

 484         ASSERT(argument &lt; m_numArguments);
 485 
<span class="line-modified"> 486         VariableAccessData* variableAccessData = newVariableAccessData(operand);</span>
 487 
 488         // Always flush arguments, except for &#39;this&#39;. If &#39;this&#39; is created by us,
 489         // then make sure that it&#39;s never unboxed.
 490         if (argument || m_graph.needsFlushedThis()) {
 491             if (setMode != ImmediateNakedSet)
<span class="line-modified"> 492                 flushDirect(operand);</span>
 493         }
 494 
 495         if (!argument &amp;&amp; m_codeBlock-&gt;specializationKind() == CodeForConstruct)
 496             variableAccessData-&gt;mergeShouldNeverUnbox(true);
 497 
 498         variableAccessData-&gt;mergeStructureCheckHoistingFailed(
 499             m_inlineStackTop-&gt;m_exitProfile.hasExitSite(semanticOrigin.bytecodeIndex(), BadCache));
 500         variableAccessData-&gt;mergeCheckArrayHoistingFailed(
 501             m_inlineStackTop-&gt;m_exitProfile.hasExitSite(semanticOrigin.bytecodeIndex(), BadIndexingType));
 502         Node* node = addToGraph(SetLocal, OpInfo(variableAccessData), value);
 503         m_currentBlock-&gt;variablesAtTail.argument(argument) = node;
 504         return node;
 505     }
 506 
 507     ArgumentPosition* findArgumentPositionForArgument(int argument)
 508     {
 509         InlineStackEntry* stack = m_inlineStackTop;
 510         while (stack-&gt;m_inlineCallFrame)
 511             stack = stack-&gt;m_caller;
 512         return stack-&gt;m_argumentPositions[argument];
 513     }
 514 
 515     ArgumentPosition* findArgumentPositionForLocal(VirtualRegister operand)
 516     {
 517         for (InlineStackEntry* stack = m_inlineStackTop; ; stack = stack-&gt;m_caller) {
 518             InlineCallFrame* inlineCallFrame = stack-&gt;m_inlineCallFrame;
 519             if (!inlineCallFrame)
 520                 break;
 521             if (operand.offset() &lt; static_cast&lt;int&gt;(inlineCallFrame-&gt;stackOffset + CallFrame::headerSizeInRegisters))
 522                 continue;
 523             if (operand.offset() &gt;= static_cast&lt;int&gt;(inlineCallFrame-&gt;stackOffset + CallFrame::thisArgumentOffset() + inlineCallFrame-&gt;argumentsWithFixup.size()))
 524                 continue;
 525             int argument = VirtualRegister(operand.offset() - inlineCallFrame-&gt;stackOffset).toArgument();
 526             return stack-&gt;m_argumentPositions[argument];
 527         }
<span class="line-modified"> 528         return 0;</span>
 529     }
 530 
<span class="line-modified"> 531     ArgumentPosition* findArgumentPosition(VirtualRegister operand)</span>
 532     {


 533         if (operand.isArgument())
 534             return findArgumentPositionForArgument(operand.toArgument());
<span class="line-modified"> 535         return findArgumentPositionForLocal(operand);</span>
 536     }
 537 
 538     template&lt;typename AddFlushDirectFunc&gt;
 539     void flushImpl(InlineCallFrame* inlineCallFrame, const AddFlushDirectFunc&amp; addFlushDirect)
 540     {
 541         int numArguments;
 542         if (inlineCallFrame) {
 543             ASSERT(!m_graph.hasDebuggerEnabled());
 544             numArguments = inlineCallFrame-&gt;argumentsWithFixup.size();
 545             if (inlineCallFrame-&gt;isClosureCall)
<span class="line-modified"> 546                 addFlushDirect(inlineCallFrame, remapOperand(inlineCallFrame, VirtualRegister(CallFrameSlot::callee)));</span>
 547             if (inlineCallFrame-&gt;isVarargs())
<span class="line-modified"> 548                 addFlushDirect(inlineCallFrame, remapOperand(inlineCallFrame, VirtualRegister(CallFrameSlot::argumentCount)));</span>
 549         } else
 550             numArguments = m_graph.baselineCodeBlockFor(inlineCallFrame)-&gt;numParameters();
 551 
 552         for (unsigned argument = numArguments; argument--;)
<span class="line-modified"> 553             addFlushDirect(inlineCallFrame, remapOperand(inlineCallFrame, virtualRegisterForArgument(argument)));</span>
 554 
 555         if (m_graph.needsScopeRegister())
 556             addFlushDirect(nullptr, m_graph.m_codeBlock-&gt;scopeRegister());
 557     }
 558 
 559     template&lt;typename AddFlushDirectFunc, typename AddPhantomLocalDirectFunc&gt;
 560     void flushForTerminalImpl(CodeOrigin origin, const AddFlushDirectFunc&amp; addFlushDirect, const AddPhantomLocalDirectFunc&amp; addPhantomLocalDirect)
 561     {

 562         origin.walkUpInlineStack(
 563             [&amp;] (CodeOrigin origin) {
<span class="line-modified"> 564                 unsigned bytecodeIndex = origin.bytecodeIndex();</span>
 565                 InlineCallFrame* inlineCallFrame = origin.inlineCallFrame();
 566                 flushImpl(inlineCallFrame, addFlushDirect);
 567 
 568                 CodeBlock* codeBlock = m_graph.baselineCodeBlockFor(inlineCallFrame);
 569                 FullBytecodeLiveness&amp; fullLiveness = m_graph.livenessFor(codeBlock);
<span class="line-modified"> 570                 const FastBitVector&amp; livenessAtBytecode = fullLiveness.getLiveness(bytecodeIndex);</span>
<span class="line-modified"> 571 </span>
 572                 for (unsigned local = codeBlock-&gt;numCalleeLocals(); local--;) {
 573                     if (livenessAtBytecode[local])
 574                         addPhantomLocalDirect(inlineCallFrame, remapOperand(inlineCallFrame, virtualRegisterForLocal(local)));
 575                 }

 576             });
 577     }
 578 
<span class="line-modified"> 579     void flush(VirtualRegister operand)</span>
 580     {
 581         flushDirect(m_inlineStackTop-&gt;remapOperand(operand));
 582     }
 583 
<span class="line-modified"> 584     void flushDirect(VirtualRegister operand)</span>
 585     {
 586         flushDirect(operand, findArgumentPosition(operand));
 587     }
 588 
<span class="line-modified"> 589     void flushDirect(VirtualRegister operand, ArgumentPosition* argumentPosition)</span>
 590     {
 591         addFlushOrPhantomLocal&lt;Flush&gt;(operand, argumentPosition);
 592     }
 593 
 594     template&lt;NodeType nodeType&gt;
<span class="line-modified"> 595     void addFlushOrPhantomLocal(VirtualRegister operand, ArgumentPosition* argumentPosition)</span>
 596     {
 597         ASSERT(!operand.isConstant());
 598 
<span class="line-modified"> 599         Node* node = m_currentBlock-&gt;variablesAtTail.operand(operand);</span>
 600 
 601         VariableAccessData* variable;
 602 
 603         if (node)
 604             variable = node-&gt;variableAccessData();
 605         else
 606             variable = newVariableAccessData(operand);
 607 
 608         node = addToGraph(nodeType, OpInfo(variable));
<span class="line-removed"> 609         m_currentBlock-&gt;variablesAtTail.operand(operand) = node;</span>
 610         if (argumentPosition)
 611             argumentPosition-&gt;addVariable(variable);
 612     }
 613 
<span class="line-modified"> 614     void phantomLocalDirect(VirtualRegister operand)</span>
 615     {
 616         addFlushOrPhantomLocal&lt;PhantomLocal&gt;(operand, findArgumentPosition(operand));
 617     }
 618 
 619     void flush(InlineStackEntry* inlineStackEntry)
 620     {
<span class="line-modified"> 621         auto addFlushDirect = [&amp;] (InlineCallFrame*, VirtualRegister reg) { flushDirect(reg); };</span>
 622         flushImpl(inlineStackEntry-&gt;m_inlineCallFrame, addFlushDirect);
 623     }
 624 
 625     void flushForTerminal()
 626     {
<span class="line-modified"> 627         auto addFlushDirect = [&amp;] (InlineCallFrame*, VirtualRegister reg) { flushDirect(reg); };</span>
<span class="line-modified"> 628         auto addPhantomLocalDirect = [&amp;] (InlineCallFrame*, VirtualRegister reg) { phantomLocalDirect(reg); };</span>
 629         flushForTerminalImpl(currentCodeOrigin(), addFlushDirect, addPhantomLocalDirect);
 630     }
 631 
 632     void flushForReturn()
 633     {
 634         flush(m_inlineStackTop);
 635     }
 636 
 637     void flushIfTerminal(SwitchData&amp; data)
 638     {
<span class="line-modified"> 639         if (data.fallThrough.bytecodeIndex() &gt; m_currentIndex)</span>
 640             return;
 641 
 642         for (unsigned i = data.cases.size(); i--;) {
<span class="line-modified"> 643             if (data.cases[i].target.bytecodeIndex() &gt; m_currentIndex)</span>
 644                 return;
 645         }
 646 
 647         flushForTerminal();
 648     }
 649 
 650     // Assumes that the constant should be strongly marked.
 651     Node* jsConstant(JSValue constantValue)
 652     {
 653         return addToGraph(JSConstant, OpInfo(m_graph.freezeStrong(constantValue)));
 654     }
 655 
 656     Node* weakJSConstant(JSValue constantValue)
 657     {
 658         return addToGraph(JSConstant, OpInfo(m_graph.freeze(constantValue)));
 659     }
 660 
 661     // Helper functions to get/set the this value.
 662     Node* getThis()
 663     {
</pre>
<hr />
<pre>
 686 
 687     NodeOrigin currentNodeOrigin()
 688     {
 689         CodeOrigin semantic;
 690         CodeOrigin forExit;
 691 
 692         if (m_currentSemanticOrigin.isSet())
 693             semantic = m_currentSemanticOrigin;
 694         else
 695             semantic = currentCodeOrigin();
 696 
 697         forExit = currentCodeOrigin();
 698 
 699         return NodeOrigin(semantic, forExit, m_exitOK);
 700     }
 701 
 702     BranchData* branchData(unsigned taken, unsigned notTaken)
 703     {
 704         // We assume that branches originating from bytecode always have a fall-through. We
 705         // use this assumption to avoid checking for the creation of terminal blocks.
<span class="line-modified"> 706         ASSERT((taken &gt; m_currentIndex) || (notTaken &gt; m_currentIndex));</span>
 707         BranchData* data = m_graph.m_branchData.add();
 708         *data = BranchData::withBytecodeIndices(taken, notTaken);
 709         return data;
 710     }
 711 
 712     Node* addToGraph(Node* node)
 713     {
 714         VERBOSE_LOG(&quot;        appended &quot;, node, &quot; &quot;, Graph::opName(node-&gt;op()), &quot;\n&quot;);
 715 
 716         m_hasAnyForceOSRExits |= (node-&gt;op() == ForceOSRExit);
 717 
 718         m_currentBlock-&gt;append(node);
 719         if (clobbersExitState(m_graph, node))
 720             m_exitOK = false;
 721         return node;
 722     }
 723 
 724     Node* addToGraph(NodeType op, Node* child1 = 0, Node* child2 = 0, Node* child3 = 0)
 725     {
 726         Node* result = m_graph.addNode(
</pre>
<hr />
<pre>
 736     }
 737     Node* addToGraph(NodeType op, OpInfo info, Node* child1 = 0, Node* child2 = 0, Node* child3 = 0)
 738     {
 739         Node* result = m_graph.addNode(
 740             op, currentNodeOrigin(), info, Edge(child1), Edge(child2),
 741             Edge(child3));
 742         return addToGraph(result);
 743     }
 744     Node* addToGraph(NodeType op, OpInfo info, Edge child1, Edge child2 = Edge(), Edge child3 = Edge())
 745     {
 746         Node* result = m_graph.addNode(op, currentNodeOrigin(), info, child1, child2, child3);
 747         return addToGraph(result);
 748     }
 749     Node* addToGraph(NodeType op, OpInfo info1, OpInfo info2, Node* child1 = 0, Node* child2 = 0, Node* child3 = 0)
 750     {
 751         Node* result = m_graph.addNode(
 752             op, currentNodeOrigin(), info1, info2,
 753             Edge(child1), Edge(child2), Edge(child3));
 754         return addToGraph(result);
 755     }





 756     Node* addToGraph(NodeType op, OpInfo info1, OpInfo info2, Edge child1, Edge child2 = Edge(), Edge child3 = Edge())
 757     {
 758         Node* result = m_graph.addNode(
 759             op, currentNodeOrigin(), info1, info2, child1, child2, child3);
 760         return addToGraph(result);
 761     }
 762 
 763     Node* addToGraph(Node::VarArgTag, NodeType op, OpInfo info1, OpInfo info2 = OpInfo())
 764     {
 765         Node* result = m_graph.addNode(
 766             Node::VarArg, op, currentNodeOrigin(), info1, info2,
 767             m_graph.m_varArgChildren.size() - m_numPassedVarArgs, m_numPassedVarArgs);
 768         addToGraph(result);
 769 
 770         m_numPassedVarArgs = 0;
 771 
 772         return result;
 773     }
 774 
 775     void addVarArgChild(Node* child)
</pre>
<hr />
<pre>
 778         m_numPassedVarArgs++;
 779     }
 780 
 781     void addVarArgChild(Edge child)
 782     {
 783         m_graph.m_varArgChildren.append(child);
 784         m_numPassedVarArgs++;
 785     }
 786 
 787     Node* addCallWithoutSettingResult(
 788         NodeType op, OpInfo opInfo, Node* callee, int argCount, int registerOffset,
 789         OpInfo prediction)
 790     {
 791         addVarArgChild(callee);
 792         size_t parameterSlots = Graph::parameterSlotsForArgCount(argCount);
 793 
 794         if (parameterSlots &gt; m_parameterSlots)
 795             m_parameterSlots = parameterSlots;
 796 
 797         for (int i = 0; i &lt; argCount; ++i)
<span class="line-modified"> 798             addVarArgChild(get(virtualRegisterForArgument(i, registerOffset)));</span>
 799 
 800         return addToGraph(Node::VarArg, op, opInfo, prediction);
 801     }
 802 
 803     Node* addCall(
 804         VirtualRegister result, NodeType op, const DOMJIT::Signature* signature, Node* callee, int argCount, int registerOffset,
 805         SpeculatedType prediction)
 806     {
 807         if (op == TailCall) {
 808             if (allInlineFramesAreTailCalls())
 809                 return addCallWithoutSettingResult(op, OpInfo(signature), callee, argCount, registerOffset, OpInfo());
 810             op = TailCallInlinedCaller;
 811         }
 812 
 813 
 814         Node* call = addCallWithoutSettingResult(
 815             op, OpInfo(signature), callee, argCount, registerOffset, OpInfo(prediction));
 816         if (result.isValid())
 817             set(result, call);
 818         return call;
 819     }
 820 
 821     Node* cellConstantWithStructureCheck(JSCell* object, Structure* structure)
 822     {
 823         // FIXME: This should route to emitPropertyCheck, not the other way around. But currently,
 824         // this gets no profit from using emitPropertyCheck() since we&#39;ll non-adaptively watch the
 825         // object&#39;s structure as soon as we make it a weakJSCosntant.
 826         Node* objectNode = weakJSConstant(object);
 827         addToGraph(CheckStructure, OpInfo(m_graph.addStructureSet(structure)), objectNode);
 828         return objectNode;
 829     }
 830 
<span class="line-modified"> 831     SpeculatedType getPredictionWithoutOSRExit(unsigned bytecodeIndex)</span>
 832     {
 833         auto getValueProfilePredictionFromForCodeBlockAndBytecodeOffset = [&amp;] (CodeBlock* codeBlock, const CodeOrigin&amp; codeOrigin)
 834         {
 835             SpeculatedType prediction;
 836             {
 837                 ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
<span class="line-modified"> 838                 prediction = codeBlock-&gt;valueProfilePredictionForBytecodeOffset(locker, codeOrigin.bytecodeIndex());</span>
 839             }
 840             auto* fuzzerAgent = m_vm-&gt;fuzzerAgent();
 841             if (UNLIKELY(fuzzerAgent))
 842                 return fuzzerAgent-&gt;getPrediction(codeBlock, codeOrigin, prediction) &amp; SpecBytecodeTop;
 843             return prediction;
 844         };
 845 
 846         SpeculatedType prediction = getValueProfilePredictionFromForCodeBlockAndBytecodeOffset(m_inlineStackTop-&gt;m_profiledBlock, CodeOrigin(bytecodeIndex, inlineCallFrame()));
 847         if (prediction != SpecNone)
 848             return prediction;
 849 
 850         // If we have no information about the values this
 851         // node generates, we check if by any chance it is
 852         // a tail call opcode. In that case, we walk up the
 853         // inline frames to find a call higher in the call
 854         // chain and use its prediction. If we only have
 855         // inlined tail call frames, we use SpecFullTop
 856         // to avoid a spurious OSR exit.
<span class="line-modified"> 857         auto instruction = m_inlineStackTop-&gt;m_profiledBlock-&gt;instructions().at(bytecodeIndex);</span>
 858         OpcodeID opcodeID = instruction-&gt;opcodeID();
 859 
 860         switch (opcodeID) {
 861         case op_tail_call:
 862         case op_tail_call_varargs:
 863         case op_tail_call_forward_arguments: {
 864             // Things should be more permissive to us returning BOTTOM instead of TOP here.
 865             // Currently, this will cause us to Force OSR exit. This is bad because returning
 866             // TOP will cause anything that transitively touches this speculated type to
 867             // also become TOP during prediction propagation.
 868             // https://bugs.webkit.org/show_bug.cgi?id=164337
 869             if (!inlineCallFrame())
 870                 return SpecFullTop;
 871 
 872             CodeOrigin* codeOrigin = inlineCallFrame()-&gt;getCallerSkippingTailCalls();
 873             if (!codeOrigin)
 874                 return SpecFullTop;
 875 
 876             InlineStackEntry* stack = m_inlineStackTop;
 877             while (stack-&gt;m_inlineCallFrame != codeOrigin-&gt;inlineCallFrame())
 878                 stack = stack-&gt;m_caller;
 879 
 880             return getValueProfilePredictionFromForCodeBlockAndBytecodeOffset(stack-&gt;m_profiledBlock, *codeOrigin);
 881         }
 882 
 883         default:
 884             return SpecNone;
 885         }
 886 
 887         RELEASE_ASSERT_NOT_REACHED();
 888         return SpecNone;
 889     }
 890 
<span class="line-modified"> 891     SpeculatedType getPrediction(unsigned bytecodeIndex)</span>
 892     {
 893         SpeculatedType prediction = getPredictionWithoutOSRExit(bytecodeIndex);
 894 
 895         if (prediction == SpecNone) {
 896             // We have no information about what values this node generates. Give up
 897             // on executing this code, since we&#39;re likely to do more damage than good.
 898             addToGraph(ForceOSRExit);
 899         }
 900 
 901         return prediction;
 902     }
 903 
 904     SpeculatedType getPredictionWithoutOSRExit()
 905     {
 906         return getPredictionWithoutOSRExit(m_currentIndex);
 907     }
 908 
 909     SpeculatedType getPrediction()
 910     {
 911         return getPrediction(m_currentIndex);
 912     }
 913 
 914     ArrayMode getArrayMode(Array::Action action)
 915     {
 916         CodeBlock* codeBlock = m_inlineStackTop-&gt;m_profiledBlock;
<span class="line-modified"> 917         ArrayProfile* profile = codeBlock-&gt;getArrayProfile(codeBlock-&gt;bytecodeOffset(m_currentInstruction));</span>
 918         return getArrayMode(*profile, action);
 919     }
 920 
 921     ArrayMode getArrayMode(ArrayProfile&amp; profile, Array::Action action)
 922     {
 923         ConcurrentJSLocker locker(m_inlineStackTop-&gt;m_profiledBlock-&gt;m_lock);
 924         profile.computeUpdatedPrediction(locker, m_inlineStackTop-&gt;m_profiledBlock);
 925         bool makeSafe = profile.outOfBounds(locker);
 926         return ArrayMode::fromObserved(locker, &amp;profile, action, makeSafe);
 927     }
 928 
 929     Node* makeSafe(Node* node)
 930     {
 931         if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, Overflow))
 932             node-&gt;mergeFlags(NodeMayOverflowInt32InDFG);
 933         if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, NegativeZero))
 934             node-&gt;mergeFlags(NodeMayNegZeroInDFG);
 935 
 936         if (!isX86() &amp;&amp; (node-&gt;op() == ArithMod || node-&gt;op() == ValueMod))
 937             return node;
 938 
<span class="line-modified"> 939         {</span>
<span class="line-modified"> 940             ArithProfile* arithProfile = m_inlineStackTop-&gt;m_profiledBlock-&gt;arithProfileForBytecodeOffset(m_currentIndex);</span>
<span class="line-modified"> 941             if (arithProfile) {</span>
<span class="line-modified"> 942                 switch (node-&gt;op()) {</span>
<span class="line-modified"> 943                 case ArithAdd:</span>
<span class="line-modified"> 944                 case ArithSub:</span>
<span class="line-modified"> 945                 case ValueAdd:</span>
<span class="line-modified"> 946                     if (arithProfile-&gt;didObserveDouble())</span>
<span class="line-modified"> 947                         node-&gt;mergeFlags(NodeMayHaveDoubleResult);</span>
<span class="line-modified"> 948                     if (arithProfile-&gt;didObserveNonNumeric())</span>
<span class="line-modified"> 949                         node-&gt;mergeFlags(NodeMayHaveNonNumericResult);</span>
<span class="line-modified"> 950                     if (arithProfile-&gt;didObserveBigInt())</span>
<span class="line-removed"> 951                         node-&gt;mergeFlags(NodeMayHaveBigIntResult);</span>
<span class="line-removed"> 952                     break;</span>
 953 
<span class="line-modified"> 954                 case ValueMul:</span>
<span class="line-modified"> 955                 case ArithMul: {</span>
<span class="line-modified"> 956                     if (arithProfile-&gt;didObserveInt52Overflow())</span>
<span class="line-modified"> 957                         node-&gt;mergeFlags(NodeMayOverflowInt52);</span>
<span class="line-modified"> 958                     if (arithProfile-&gt;didObserveInt32Overflow() || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, Overflow))</span>
<span class="line-modified"> 959                         node-&gt;mergeFlags(NodeMayOverflowInt32InBaseline);</span>
<span class="line-modified"> 960                     if (arithProfile-&gt;didObserveNegZeroDouble() || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, NegativeZero))</span>
<span class="line-modified"> 961                         node-&gt;mergeFlags(NodeMayNegZeroInBaseline);</span>
<span class="line-modified"> 962                     if (arithProfile-&gt;didObserveDouble())</span>
<span class="line-modified"> 963                         node-&gt;mergeFlags(NodeMayHaveDoubleResult);</span>
<span class="line-modified"> 964                     if (arithProfile-&gt;didObserveNonNumeric())</span>
<span class="line-modified"> 965                         node-&gt;mergeFlags(NodeMayHaveNonNumericResult);</span>
<span class="line-modified"> 966                     if (arithProfile-&gt;didObserveBigInt())</span>
<span class="line-modified"> 967                         node-&gt;mergeFlags(NodeMayHaveBigIntResult);</span>
<span class="line-modified"> 968                     break;</span>
<span class="line-modified"> 969                 }</span>
<span class="line-modified"> 970                 case ValueNegate:</span>
<span class="line-modified"> 971                 case ArithNegate: {</span>
<span class="line-modified"> 972                     if (arithProfile-&gt;lhsObservedType().sawNumber() || arithProfile-&gt;didObserveDouble())</span>
<span class="line-modified"> 973                         node-&gt;mergeFlags(NodeMayHaveDoubleResult);</span>
<span class="line-modified"> 974                     if (arithProfile-&gt;didObserveNegZeroDouble() || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, NegativeZero))</span>
<span class="line-modified"> 975                         node-&gt;mergeFlags(NodeMayNegZeroInBaseline);</span>
<span class="line-modified"> 976                     if (arithProfile-&gt;didObserveInt32Overflow() || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, Overflow))</span>
<span class="line-modified"> 977                         node-&gt;mergeFlags(NodeMayOverflowInt32InBaseline);</span>
<span class="line-modified"> 978                     if (arithProfile-&gt;didObserveNonNumeric())</span>
<span class="line-modified"> 979                         node-&gt;mergeFlags(NodeMayHaveNonNumericResult);</span>
<span class="line-modified"> 980                     if (arithProfile-&gt;didObserveBigInt())</span>
<span class="line-modified"> 981                         node-&gt;mergeFlags(NodeMayHaveBigIntResult);</span>
<span class="line-modified"> 982                     break;</span>
<span class="line-modified"> 983                 }</span>
















 984 
<span class="line-modified"> 985                 default:</span>
<span class="line-modified"> 986                     break;</span>
<span class="line-removed"> 987                 }</span>
<span class="line-removed"> 988             }</span>
 989         }
 990 
 991         if (m_inlineStackTop-&gt;m_profiledBlock-&gt;likelyToTakeSlowCase(m_currentIndex)) {
 992             switch (node-&gt;op()) {
 993             case UInt32ToNumber:
 994             case ArithAdd:
 995             case ArithSub:
 996             case ValueAdd:
 997             case ValueMod:
 998             case ArithMod: // for ArithMod &quot;MayOverflow&quot; means we tried to divide by zero, or we saw double.
 999                 node-&gt;mergeFlags(NodeMayOverflowInt32InBaseline);
1000                 break;
1001 
1002             default:
1003                 break;
1004             }
1005         }
1006 
1007         return node;
1008     }
1009 
1010     Node* makeDivSafe(Node* node)
1011     {
1012         ASSERT(node-&gt;op() == ArithDiv || node-&gt;op() == ValueDiv);
1013 
1014         if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, Overflow))
1015             node-&gt;mergeFlags(NodeMayOverflowInt32InDFG);
1016         if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, NegativeZero))
1017             node-&gt;mergeFlags(NodeMayNegZeroInDFG);
1018 
1019         // The main slow case counter for op_div in the old JIT counts only when
1020         // the operands are not numbers. We don&#39;t care about that since we already
1021         // have speculations in place that take care of that separately. We only
1022         // care about when the outcome of the division is not an integer, which
1023         // is what the special fast case counter tells us.
1024 
<span class="line-modified">1025         if (!m_inlineStackTop-&gt;m_profiledBlock-&gt;couldTakeSpecialFastCase(m_currentIndex))</span>
1026             return node;
1027 
1028         // FIXME: It might be possible to make this more granular.
1029         node-&gt;mergeFlags(NodeMayOverflowInt32InBaseline | NodeMayNegZeroInBaseline);
1030 
<span class="line-modified">1031         ArithProfile* arithProfile = m_inlineStackTop-&gt;m_profiledBlock-&gt;arithProfileForBytecodeOffset(m_currentIndex);</span>
1032         if (arithProfile-&gt;didObserveBigInt())
1033             node-&gt;mergeFlags(NodeMayHaveBigIntResult);
1034 
1035         return node;
1036     }
1037 
1038     void noticeArgumentsUse()
1039     {
1040         // All of the arguments in this function need to be formatted as JSValues because we will
1041         // load from them in a random-access fashion and we don&#39;t want to have to switch on
1042         // format.
1043 
1044         for (ArgumentPosition* argument : m_inlineStackTop-&gt;m_argumentPositions)
1045             argument-&gt;mergeShouldNeverUnbox(true);
1046     }
1047 
1048     bool needsDynamicLookup(ResolveType, OpcodeID);
1049 
1050     VM* m_vm;
1051     CodeBlock* m_codeBlock;
1052     CodeBlock* m_profiledBlock;
1053     Graph&amp; m_graph;
1054 
1055     // The current block being generated.
1056     BasicBlock* m_currentBlock;
1057     // The bytecode index of the current instruction being generated.
<span class="line-modified">1058     unsigned m_currentIndex;</span>
1059     // The semantic origin of the current node if different from the current Index.
1060     CodeOrigin m_currentSemanticOrigin;
1061     // True if it&#39;s OK to OSR exit right now.
1062     bool m_exitOK { false };
1063 
1064     FrozenValue* m_constantUndefined;
1065     FrozenValue* m_constantNull;
1066     FrozenValue* m_constantNaN;
1067     FrozenValue* m_constantOne;
1068     Vector&lt;Node*, 16&gt; m_constants;
1069 
1070     HashMap&lt;InlineCallFrame*, Vector&lt;ArgumentPosition*&gt;, WTF::DefaultHash&lt;InlineCallFrame*&gt;::Hash, WTF::NullableHashTraits&lt;InlineCallFrame*&gt;&gt; m_inlineCallFrameToArgumentPositions;
1071 
1072     // The number of arguments passed to the function.
1073     unsigned m_numArguments;
<span class="line-modified">1074     // The number of locals (vars + temporaries) used in the function.</span>
1075     unsigned m_numLocals;


1076     // The number of slots (in units of sizeof(Register)) that we need to
1077     // preallocate for arguments to outgoing calls from this frame. This
1078     // number includes the CallFrame slots that we initialize for the callee
1079     // (but not the callee-initialized CallerFrame and ReturnPC slots).
1080     // This number is 0 if and only if this function is a leaf.
1081     unsigned m_parameterSlots;
1082     // The number of var args passed to the next var arg node.
1083     unsigned m_numPassedVarArgs;
1084 
1085     struct InlineStackEntry {
1086         ByteCodeParser* m_byteCodeParser;
1087 
1088         CodeBlock* m_codeBlock;
1089         CodeBlock* m_profiledBlock;
1090         InlineCallFrame* m_inlineCallFrame;
1091 
1092         ScriptExecutable* executable() { return m_codeBlock-&gt;ownerExecutable(); }
1093 
1094         QueryableExitProfile m_exitProfile;
1095 
</pre>
<hr />
<pre>
1122         ICStatusContext m_optimizedContext;
1123 
1124         // Pointers to the argument position trackers for this slice of code.
1125         Vector&lt;ArgumentPosition*&gt; m_argumentPositions;
1126 
1127         InlineStackEntry* m_caller;
1128 
1129         InlineStackEntry(
1130             ByteCodeParser*,
1131             CodeBlock*,
1132             CodeBlock* profiledBlock,
1133             JSFunction* callee, // Null if this is a closure call.
1134             VirtualRegister returnValueVR,
1135             VirtualRegister inlineCallFrameStart,
1136             int argumentCountIncludingThis,
1137             InlineCallFrame::Kind,
1138             BasicBlock* continuationBlock);
1139 
1140         ~InlineStackEntry();
1141 
<span class="line-modified">1142         VirtualRegister remapOperand(VirtualRegister operand) const</span>
1143         {
1144             if (!m_inlineCallFrame)
1145                 return operand;
1146 
<span class="line-modified">1147             ASSERT(!operand.isConstant());</span>

1148 
<span class="line-modified">1149             return VirtualRegister(operand.offset() + m_inlineCallFrame-&gt;stackOffset);</span>


1150         }
1151     };
1152 
1153     InlineStackEntry* m_inlineStackTop;
1154 
1155     ICStatusContextStack m_icContextStack;
1156 
1157     struct DelayedSetLocal {
<span class="line-removed">1158         CodeOrigin m_origin;</span>
<span class="line-removed">1159         VirtualRegister m_operand;</span>
<span class="line-removed">1160         Node* m_value;</span>
<span class="line-removed">1161         SetMode m_setMode;</span>
<span class="line-removed">1162 </span>
1163         DelayedSetLocal() { }
<span class="line-modified">1164         DelayedSetLocal(const CodeOrigin&amp; origin, VirtualRegister operand, Node* value, SetMode setMode)</span>
1165             : m_origin(origin)
1166             , m_operand(operand)
1167             , m_value(value)
1168             , m_setMode(setMode)
1169         {
1170             RELEASE_ASSERT(operand.isValid());
1171         }
1172 
1173         Node* execute(ByteCodeParser* parser)
1174         {
1175             if (m_operand.isArgument())
1176                 return parser-&gt;setArgument(m_origin, m_operand, m_value, m_setMode);
<span class="line-modified">1177             return parser-&gt;setLocal(m_origin, m_operand, m_value, m_setMode);</span>
1178         }





1179     };
1180 
1181     Vector&lt;DelayedSetLocal, 2&gt; m_setLocalQueue;
1182 
1183     const Instruction* m_currentInstruction;
1184     bool m_hasDebuggerEnabled;
1185     bool m_hasAnyForceOSRExits { false };
1186 };
1187 
<span class="line-modified">1188 BasicBlock* ByteCodeParser::allocateTargetableBlock(unsigned bytecodeIndex)</span>
1189 {
<span class="line-modified">1190     ASSERT(bytecodeIndex != UINT_MAX);</span>
<span class="line-modified">1191     Ref&lt;BasicBlock&gt; block = adoptRef(*new BasicBlock(bytecodeIndex, m_numArguments, m_numLocals, 1));</span>
1192     BasicBlock* blockPtr = block.ptr();
1193     // m_blockLinkingTargets must always be sorted in increasing order of bytecodeBegin
1194     if (m_inlineStackTop-&gt;m_blockLinkingTargets.size())
<span class="line-modified">1195         ASSERT(m_inlineStackTop-&gt;m_blockLinkingTargets.last()-&gt;bytecodeBegin &lt; bytecodeIndex);</span>
1196     m_inlineStackTop-&gt;m_blockLinkingTargets.append(blockPtr);
1197     m_graph.appendBlock(WTFMove(block));
1198     return blockPtr;
1199 }
1200 
1201 BasicBlock* ByteCodeParser::allocateUntargetableBlock()
1202 {
<span class="line-modified">1203     Ref&lt;BasicBlock&gt; block = adoptRef(*new BasicBlock(UINT_MAX, m_numArguments, m_numLocals, 1));</span>
1204     BasicBlock* blockPtr = block.ptr();
1205     m_graph.appendBlock(WTFMove(block));
1206     return blockPtr;
1207 }
1208 
<span class="line-modified">1209 void ByteCodeParser::makeBlockTargetable(BasicBlock* block, unsigned bytecodeIndex)</span>
1210 {
<span class="line-modified">1211     RELEASE_ASSERT(block-&gt;bytecodeBegin == UINT_MAX);</span>
1212     block-&gt;bytecodeBegin = bytecodeIndex;
1213     // m_blockLinkingTargets must always be sorted in increasing order of bytecodeBegin
1214     if (m_inlineStackTop-&gt;m_blockLinkingTargets.size())
<span class="line-modified">1215         ASSERT(m_inlineStackTop-&gt;m_blockLinkingTargets.last()-&gt;bytecodeBegin &lt; bytecodeIndex);</span>
1216     m_inlineStackTop-&gt;m_blockLinkingTargets.append(block);
1217 }
1218 
1219 void ByteCodeParser::addJumpTo(BasicBlock* block)
1220 {
1221     ASSERT(!m_currentBlock-&gt;terminal());
1222     Node* jumpNode = addToGraph(Jump);
1223     jumpNode-&gt;targetBlock() = block;
1224     m_currentBlock-&gt;didLink();
1225 }
1226 
1227 void ByteCodeParser::addJumpTo(unsigned bytecodeIndex)
1228 {
1229     ASSERT(!m_currentBlock-&gt;terminal());
1230     addToGraph(Jump, OpInfo(bytecodeIndex));
1231     m_inlineStackTop-&gt;m_unlinkedBlocks.append(m_currentBlock);
1232 }
1233 
1234 template&lt;typename CallOp&gt;
1235 ByteCodeParser::Terminality ByteCodeParser::handleCall(const Instruction* pc, NodeType op, CallMode callMode)
</pre>
<hr />
<pre>
1253     if (callTarget-&gt;isCellConstant())
1254         callLinkStatus.setProvenConstantCallee(CallVariant(callTarget-&gt;asCell()));
1255 }
1256 
1257 ByteCodeParser::Terminality ByteCodeParser::handleCall(
1258     VirtualRegister result, NodeType op, InlineCallFrame::Kind kind, unsigned instructionSize,
1259     Node* callTarget, int argumentCountIncludingThis, int registerOffset,
1260     CallLinkStatus callLinkStatus, SpeculatedType prediction)
1261 {
1262     ASSERT(registerOffset &lt;= 0);
1263 
1264     refineStatically(callLinkStatus, callTarget);
1265 
1266     VERBOSE_LOG(&quot;    Handling call at &quot;, currentCodeOrigin(), &quot;: &quot;, callLinkStatus, &quot;\n&quot;);
1267 
1268     // If we have profiling information about this call, and it did not behave too polymorphically,
1269     // we may be able to inline it, or in the case of recursive tail calls turn it into a jump.
1270     if (callLinkStatus.canOptimize()) {
1271         addToGraph(FilterCallLinkStatus, OpInfo(m_graph.m_plan.recordedStatuses().addCallLinkStatus(currentCodeOrigin(), callLinkStatus)), callTarget);
1272 
<span class="line-modified">1273         VirtualRegister thisArgument = virtualRegisterForArgument(0, registerOffset);</span>
1274         auto optimizationResult = handleInlining(callTarget, result, callLinkStatus, registerOffset, thisArgument,
<span class="line-modified">1275             argumentCountIncludingThis, m_currentIndex + instructionSize, op, kind, prediction);</span>
1276         if (optimizationResult == CallOptimizationResult::OptimizedToJump)
1277             return Terminal;
1278         if (optimizationResult == CallOptimizationResult::Inlined) {
1279             if (UNLIKELY(m_graph.compilation()))
1280                 m_graph.compilation()-&gt;noticeInlinedCall();
1281             return NonTerminal;
1282         }
1283     }
1284 
1285     Node* callNode = addCall(result, op, nullptr, callTarget, argumentCountIncludingThis, registerOffset, prediction);
1286     ASSERT(callNode-&gt;op() != TailCallVarargs &amp;&amp; callNode-&gt;op() != TailCallForwardVarargs);
1287     return callNode-&gt;op() == TailCall ? Terminal : NonTerminal;
1288 }
1289 
1290 template&lt;typename CallOp&gt;
1291 ByteCodeParser::Terminality ByteCodeParser::handleVarargsCall(const Instruction* pc, NodeType op, CallMode callMode)
1292 {
1293     auto bytecode = pc-&gt;as&lt;CallOp&gt;();
1294     int firstFreeReg = bytecode.m_firstFree.offset();
1295     int firstVarArgOffset = bytecode.m_firstVarArg;
</pre>
<hr />
<pre>
1360 
1361     ASSERT(calleeCell);
1362     addToGraph(CheckCell, OpInfo(m_graph.freeze(calleeCell)), callTargetForCheck);
1363     if (thisArgument)
1364         addToGraph(Phantom, thisArgument);
1365 }
1366 
1367 Node* ByteCodeParser::getArgumentCount()
1368 {
1369     Node* argumentCount;
1370     if (m_inlineStackTop-&gt;m_inlineCallFrame &amp;&amp; !m_inlineStackTop-&gt;m_inlineCallFrame-&gt;isVarargs())
1371         argumentCount = jsConstant(m_graph.freeze(jsNumber(m_inlineStackTop-&gt;m_inlineCallFrame-&gt;argumentCountIncludingThis))-&gt;value());
1372     else
1373         argumentCount = addToGraph(GetArgumentCountIncludingThis, OpInfo(m_inlineStackTop-&gt;m_inlineCallFrame), OpInfo(SpecInt32Only));
1374     return argumentCount;
1375 }
1376 
1377 void ByteCodeParser::emitArgumentPhantoms(int registerOffset, int argumentCountIncludingThis)
1378 {
1379     for (int i = 0; i &lt; argumentCountIncludingThis; ++i)
<span class="line-modified">1380         addToGraph(Phantom, get(virtualRegisterForArgument(i, registerOffset)));</span>
1381 }
1382 
1383 template&lt;typename ChecksFunctor&gt;
1384 bool ByteCodeParser::handleRecursiveTailCall(Node* callTargetNode, CallVariant callVariant, int registerOffset, int argumentCountIncludingThis, const ChecksFunctor&amp; emitFunctionCheckIfNeeded)
1385 {
1386     if (UNLIKELY(!Options::optimizeRecursiveTailCalls()))
1387         return false;
1388 
1389     auto targetExecutable = callVariant.executable();
1390     InlineStackEntry* stackEntry = m_inlineStackTop;
1391     do {
1392         if (targetExecutable != stackEntry-&gt;executable())
1393             continue;
1394         VERBOSE_LOG(&quot;   We found a recursive tail call, trying to optimize it into a jump.\n&quot;);
1395 
1396         if (auto* callFrame = stackEntry-&gt;m_inlineCallFrame) {




1397             // Some code may statically use the argument count from the InlineCallFrame, so it would be invalid to loop back if it does not match.
1398             // We &quot;continue&quot; instead of returning false in case another stack entry further on the stack has the right number of arguments.
1399             if (argumentCountIncludingThis != static_cast&lt;int&gt;(callFrame-&gt;argumentCountIncludingThis))
1400                 continue;





1401         } else {
1402             // We are in the machine code entry (i.e. the original caller).
1403             // If we have more arguments than the number of parameters to the function, it is not clear where we could put them on the stack.
1404             if (argumentCountIncludingThis &gt; m_codeBlock-&gt;numParameters())
1405                 return false;
1406         }
1407 
1408         // If an InlineCallFrame is not a closure, it was optimized using a constant callee.
1409         // Check if this is the same callee that we try to inline here.
1410         if (stackEntry-&gt;m_inlineCallFrame &amp;&amp; !stackEntry-&gt;m_inlineCallFrame-&gt;isClosureCall) {
1411             if (stackEntry-&gt;m_inlineCallFrame-&gt;calleeConstant() != callVariant.function())
1412                 continue;
1413         }
1414 
1415         // We must add some check that the profiling information was correct and the target of this call is what we thought.
1416         emitFunctionCheckIfNeeded();
1417         // We flush everything, as if we were in the backedge of a loop (see treatment of op_jmp in parseBlock).
1418         flushForTerminal();
1419 
1420         // We must set the callee to the right value
1421         if (stackEntry-&gt;m_inlineCallFrame) {
1422             if (stackEntry-&gt;m_inlineCallFrame-&gt;isClosureCall)
<span class="line-modified">1423                 setDirect(stackEntry-&gt;remapOperand(VirtualRegister(CallFrameSlot::callee)), callTargetNode, NormalSet);</span>
1424         } else
1425             addToGraph(SetCallee, callTargetNode);
1426 
1427         // We must set the arguments to the right values
1428         if (!stackEntry-&gt;m_inlineCallFrame)
1429             addToGraph(SetArgumentCountIncludingThis, OpInfo(argumentCountIncludingThis));
1430         int argIndex = 0;
1431         for (; argIndex &lt; argumentCountIncludingThis; ++argIndex) {
<span class="line-modified">1432             Node* value = get(virtualRegisterForArgument(argIndex, registerOffset));</span>
<span class="line-modified">1433             setDirect(stackEntry-&gt;remapOperand(virtualRegisterForArgument(argIndex)), value, NormalSet);</span>
1434         }
1435         Node* undefined = addToGraph(JSConstant, OpInfo(m_constantUndefined));
1436         for (; argIndex &lt; stackEntry-&gt;m_codeBlock-&gt;numParameters(); ++argIndex)
<span class="line-modified">1437             setDirect(stackEntry-&gt;remapOperand(virtualRegisterForArgument(argIndex)), undefined, NormalSet);</span>
1438 
1439         // We must repeat the work of op_enter here as we will jump right after it.
1440         // We jump right after it and not before it, because of some invariant saying that a CFG root cannot have predecessors in the IR.
1441         for (int i = 0; i &lt; stackEntry-&gt;m_codeBlock-&gt;numVars(); ++i)
1442             setDirect(stackEntry-&gt;remapOperand(virtualRegisterForLocal(i)), undefined, NormalSet);
1443 
<span class="line-modified">1444         unsigned oldIndex = m_currentIndex;</span>

1445         auto oldStackTop = m_inlineStackTop;
<span class="line-removed">1446 </span>
<span class="line-removed">1447         // First, we emit check-traps operation pointing to bc#0 as exit.</span>
1448         m_inlineStackTop = stackEntry;
<span class="line-modified">1449         m_currentIndex = 0;</span>
<span class="line-removed">1450         m_exitOK = true;</span>
<span class="line-removed">1451         addToGraph(Options::usePollingTraps() ? CheckTraps : InvalidationPoint);</span>
<span class="line-removed">1452 </span>
<span class="line-removed">1453         // Then, we want to emit the SetLocals with an exit origin that points to the place we are jumping to.</span>
<span class="line-removed">1454         m_currentIndex = opcodeLengths[op_enter];</span>
1455         m_exitOK = true;
1456         processSetLocalQueue();
1457         m_currentIndex = oldIndex;
1458         m_inlineStackTop = oldStackTop;
1459         m_exitOK = false;
1460 
<span class="line-modified">1461         BasicBlock** entryBlockPtr = tryBinarySearch&lt;BasicBlock*, unsigned&gt;(stackEntry-&gt;m_blockLinkingTargets, stackEntry-&gt;m_blockLinkingTargets.size(), opcodeLengths[op_enter], getBytecodeBeginForBlock);</span>
1462         RELEASE_ASSERT(entryBlockPtr);
1463         addJumpTo(*entryBlockPtr);
1464         return true;
1465         // It would be unsound to jump over a non-tail call: the &quot;tail&quot; call is not really a tail call in that case.
1466     } while (stackEntry-&gt;m_inlineCallFrame &amp;&amp; stackEntry-&gt;m_inlineCallFrame-&gt;kind == InlineCallFrame::TailCall &amp;&amp; (stackEntry = stackEntry-&gt;m_caller));
1467 
1468     // The tail call was not recursive
1469     return false;
1470 }
1471 
1472 unsigned ByteCodeParser::inliningCost(CallVariant callee, int argumentCountIncludingThis, InlineCallFrame::Kind kind)
1473 {
1474     CallMode callMode = InlineCallFrame::callModeFor(kind);
1475     CodeSpecializationKind specializationKind = specializationKindFor(callMode);
1476     VERBOSE_LOG(&quot;Considering inlining &quot;, callee, &quot; into &quot;, currentCodeOrigin(), &quot;\n&quot;);
1477 
1478     if (m_hasDebuggerEnabled) {
1479         VERBOSE_LOG(&quot;    Failing because the debugger is in use.\n&quot;);
1480         return UINT_MAX;
1481     }
</pre>
<hr />
<pre>
1574     CodeSpecializationKind specializationKind = InlineCallFrame::specializationKindFor(kind);
1575 
1576     CodeBlock* codeBlock = callee.functionExecutable()-&gt;baselineCodeBlockFor(specializationKind);
1577     insertChecks(codeBlock);
1578 
1579     // FIXME: Don&#39;t flush constants!
1580 
1581     // arityFixupCount and numberOfStackPaddingSlots are different. While arityFixupCount does not consider about stack alignment,
1582     // numberOfStackPaddingSlots consider alignment. Consider the following case,
1583     //
1584     // before: [ ... ][arg0][header]
1585     // after:  [ ... ][ext ][arg1][arg0][header]
1586     //
1587     // In the above case, arityFixupCount is 1. But numberOfStackPaddingSlots is 2 because the stack needs to be aligned.
1588     // We insert extra slots to align stack.
1589     int arityFixupCount = std::max&lt;int&gt;(codeBlock-&gt;numParameters() - argumentCountIncludingThis, 0);
1590     int numberOfStackPaddingSlots = CommonSlowPaths::numberOfStackPaddingSlots(codeBlock, argumentCountIncludingThis);
1591     ASSERT(!(numberOfStackPaddingSlots % stackAlignmentRegisters()));
1592     int registerOffsetAfterFixup = registerOffset - numberOfStackPaddingSlots;
1593 
<span class="line-modified">1594     int inlineCallFrameStart = m_inlineStackTop-&gt;remapOperand(VirtualRegister(registerOffsetAfterFixup)).offset() + CallFrame::headerSizeInRegisters;</span>
1595 
1596     ensureLocals(
<span class="line-modified">1597         VirtualRegister(inlineCallFrameStart).toLocal() + 1 +</span>
1598         CallFrame::headerSizeInRegisters + codeBlock-&gt;numCalleeLocals());
1599 


1600     size_t argumentPositionStart = m_graph.m_argumentPositions.size();
1601 
1602     if (result.isValid())
<span class="line-modified">1603         result = m_inlineStackTop-&gt;remapOperand(result);</span>
1604 
1605     VariableAccessData* calleeVariable = nullptr;
1606     if (callee.isClosureCall()) {
1607         Node* calleeSet = set(
1608             VirtualRegister(registerOffsetAfterFixup + CallFrameSlot::callee), callTargetNode, ImmediateNakedSet);
1609 
1610         calleeVariable = calleeSet-&gt;variableAccessData();
1611         calleeVariable-&gt;mergeShouldNeverUnbox(true);
1612     }
1613 
1614     InlineStackEntry* callerStackTop = m_inlineStackTop;
1615     InlineStackEntry inlineStackEntry(this, codeBlock, codeBlock, callee.function(), result,
<span class="line-modified">1616         (VirtualRegister)inlineCallFrameStart, argumentCountIncludingThis, kind, continuationBlock);</span>
1617 
1618     // This is where the actual inlining really happens.
<span class="line-modified">1619     unsigned oldIndex = m_currentIndex;</span>
<span class="line-modified">1620     m_currentIndex = 0;</span>
1621 
1622     switch (kind) {
1623     case InlineCallFrame::GetterCall:
1624     case InlineCallFrame::SetterCall: {
1625         // When inlining getter and setter calls, we setup a stack frame which does not appear in the bytecode.
1626         // Because Inlining can switch on executable, we could have a graph like this.
1627         //
1628         // BB#0
1629         //     ...
1630         //     30: GetSetter
1631         //     31: MovHint(loc10)
1632         //     32: SetLocal(loc10)
1633         //     33: MovHint(loc9)
1634         //     34: SetLocal(loc9)
1635         //     ...
1636         //     37: GetExecutable(@30)
1637         //     ...
1638         //     41: Switch(@37)
1639         //
1640         // BB#2
1641         //     42: GetLocal(loc12, bc#7 of caller)
1642         //     ...
1643         //     --&gt; callee: loc9 and loc10 are arguments of callee.
1644         //       ...
1645         //       &lt;HERE, exit to callee, loc9 and loc10 are required in the bytecode&gt;
1646         //
1647         // When we prune OSR availability at the beginning of BB#2 (bc#7 in the caller), we prune loc9 and loc10&#39;s liveness because the caller does not actually have loc9 and loc10.
1648         // However, when we begin executing the callee, we need OSR exit to be aware of where it can recover the arguments to the setter, loc9 and loc10. The MovHints in the inlined
1649         // callee make it so that if we exit at &lt;HERE&gt;, we can recover loc9 and loc10.
1650         for (int index = 0; index &lt; argumentCountIncludingThis; ++index) {
<span class="line-modified">1651             VirtualRegister argumentToGet = callerStackTop-&gt;remapOperand(virtualRegisterForArgument(index, registerOffset));</span>
1652             Node* value = getDirect(argumentToGet);
<span class="line-modified">1653             addToGraph(MovHint, OpInfo(argumentToGet.offset()), value);</span>
1654             m_setLocalQueue.append(DelayedSetLocal { currentCodeOrigin(), argumentToGet, value, ImmediateNakedSet });
1655         }
1656         break;
1657     }
1658     default:
1659         break;
1660     }
1661 
1662     if (arityFixupCount) {
1663         // Note: we do arity fixup in two phases:
1664         // 1. We get all the values we need and MovHint them to the expected locals.
1665         // 2. We SetLocal them after that. This way, if we exit, the callee&#39;s
1666         //    frame is already set up. If any SetLocal exits, we have a valid exit state.
1667         //    This is required because if we didn&#39;t do this in two phases, we may exit in
1668         //    the middle of arity fixup from the callee&#39;s CodeOrigin. This is unsound because exited
1669         //    code does not have arity fixup so that remaining necessary fixups are not executed.
1670         //    For example, consider if we need to pad two args:
1671         //    [arg3][arg2][arg1][arg0]
1672         //    [fix ][fix ][arg3][arg2][arg1][arg0]
1673         //    We memcpy starting from arg0 in the direction of arg3. If we were to exit at a type check
</pre>
<hr />
<pre>
1677         //    And the callee would then just end up thinking its argument are:
1678         //    [fix ][fix ][arg3][arg2][arg1][arg0]
1679         //    which is incorrect.
1680 
1681         Node* undefined = addToGraph(JSConstant, OpInfo(m_constantUndefined));
1682         // The stack needs to be aligned due to the JS calling convention. Thus, we have a hole if the count of arguments is not aligned.
1683         // We call this hole &quot;extra slot&quot;. Consider the following case, the number of arguments is 2. If this argument
1684         // count does not fulfill the stack alignment requirement, we already inserted extra slots.
1685         //
1686         // before: [ ... ][ext ][arg1][arg0][header]
1687         //
1688         // In the above case, one extra slot is inserted. If the code&#39;s parameter count is 3, we will fixup arguments.
1689         // At that time, we can simply use this extra slots. So the fixuped stack is the following.
1690         //
1691         // before: [ ... ][ext ][arg1][arg0][header]
1692         // after:  [ ... ][arg2][arg1][arg0][header]
1693         //
1694         // In such cases, we do not need to move frames.
1695         if (registerOffsetAfterFixup != registerOffset) {
1696             for (int index = 0; index &lt; argumentCountIncludingThis; ++index) {
<span class="line-modified">1697                 VirtualRegister argumentToGet = callerStackTop-&gt;remapOperand(virtualRegisterForArgument(index, registerOffset));</span>
1698                 Node* value = getDirect(argumentToGet);
<span class="line-modified">1699                 VirtualRegister argumentToSet = m_inlineStackTop-&gt;remapOperand(virtualRegisterForArgument(index));</span>
<span class="line-modified">1700                 addToGraph(MovHint, OpInfo(argumentToSet.offset()), value);</span>
1701                 m_setLocalQueue.append(DelayedSetLocal { currentCodeOrigin(), argumentToSet, value, ImmediateNakedSet });
1702             }
1703         }
1704         for (int index = 0; index &lt; arityFixupCount; ++index) {
<span class="line-modified">1705             VirtualRegister argumentToSet = m_inlineStackTop-&gt;remapOperand(virtualRegisterForArgument(argumentCountIncludingThis + index));</span>
<span class="line-modified">1706             addToGraph(MovHint, OpInfo(argumentToSet.offset()), undefined);</span>
1707             m_setLocalQueue.append(DelayedSetLocal { currentCodeOrigin(), argumentToSet, undefined, ImmediateNakedSet });
1708         }
1709 
1710         // At this point, it&#39;s OK to OSR exit because we finished setting up
1711         // our callee&#39;s frame. We emit an ExitOK below.
1712     }
1713 
1714     // At this point, it&#39;s again OK to OSR exit.
1715     m_exitOK = true;
1716     addToGraph(ExitOK);
1717 
1718     processSetLocalQueue();
1719 
1720     InlineVariableData inlineVariableData;
1721     inlineVariableData.inlineCallFrame = m_inlineStackTop-&gt;m_inlineCallFrame;
1722     inlineVariableData.argumentPositionStart = argumentPositionStart;
1723     inlineVariableData.calleeVariable = 0;
1724 
1725     RELEASE_ASSERT(
1726         m_inlineStackTop-&gt;m_inlineCallFrame-&gt;isClosureCall
</pre>
<hr />
<pre>
1735     parseCodeBlock();
1736     clearCaches(); // Reset our state now that we&#39;re back to the outer code.
1737 
1738     m_currentIndex = oldIndex;
1739     m_exitOK = false;
1740 
1741     linkBlocks(inlineStackEntry.m_unlinkedBlocks, inlineStackEntry.m_blockLinkingTargets);
1742 
1743     // Most functions have at least one op_ret and thus set up the continuation block.
1744     // In some rare cases, a function ends in op_unreachable, forcing us to allocate a new continuationBlock here.
1745     if (inlineStackEntry.m_continuationBlock)
1746         m_currentBlock = inlineStackEntry.m_continuationBlock;
1747     else
1748         m_currentBlock = allocateUntargetableBlock();
1749     ASSERT(!m_currentBlock-&gt;terminal());
1750 
1751     prepareToParseBlock();
1752     m_currentInstruction = savedCurrentInstruction;
1753 }
1754 
<span class="line-modified">1755 ByteCodeParser::CallOptimizationResult ByteCodeParser::handleCallVariant(Node* callTargetNode, VirtualRegister result, CallVariant callee, int registerOffset, VirtualRegister thisArgument, int argumentCountIncludingThis, unsigned nextOffset, InlineCallFrame::Kind kind, SpeculatedType prediction, unsigned&amp; inliningBalance, BasicBlock* continuationBlock, bool needsToCheckCallee)</span>
1756 {
1757     VERBOSE_LOG(&quot;    Considering callee &quot;, callee, &quot;\n&quot;);
1758 
1759     bool didInsertChecks = false;
1760     auto insertChecksWithAccounting = [&amp;] () {
1761         if (needsToCheckCallee)
1762             emitFunctionChecks(callee, callTargetNode, thisArgument);
1763         didInsertChecks = true;
1764     };
1765 
1766     if (kind == InlineCallFrame::TailCall &amp;&amp; ByteCodeParser::handleRecursiveTailCall(callTargetNode, callee, registerOffset, argumentCountIncludingThis, insertChecksWithAccounting)) {
1767         RELEASE_ASSERT(didInsertChecks);
1768         return CallOptimizationResult::OptimizedToJump;
1769     }
1770     RELEASE_ASSERT(!didInsertChecks);
1771 
1772     if (!inliningBalance)
1773         return CallOptimizationResult::DidNothing;
1774 
1775     CodeSpecializationKind specializationKind = InlineCallFrame::specializationKindFor(kind);
1776 
1777     auto endSpecialCase = [&amp;] () {
1778         RELEASE_ASSERT(didInsertChecks);
1779         addToGraph(Phantom, callTargetNode);
1780         emitArgumentPhantoms(registerOffset, argumentCountIncludingThis);
1781         inliningBalance--;
1782         if (continuationBlock) {
<span class="line-modified">1783             m_currentIndex = nextOffset;</span>
1784             m_exitOK = true;
1785             processSetLocalQueue();
1786             addJumpTo(continuationBlock);
1787         }
1788     };
1789 
1790     if (InternalFunction* function = callee.internalFunction()) {
1791         if (handleConstantInternalFunction(callTargetNode, result, function, registerOffset, argumentCountIncludingThis, specializationKind, prediction, insertChecksWithAccounting)) {
1792             endSpecialCase();
1793             return CallOptimizationResult::Inlined;
1794         }
1795         RELEASE_ASSERT(!didInsertChecks);
1796         return CallOptimizationResult::DidNothing;
1797     }
1798 
1799     Intrinsic intrinsic = callee.intrinsicFor(specializationKind);
1800     if (intrinsic != NoIntrinsic) {
1801         if (handleIntrinsicCall(callTargetNode, result, intrinsic, registerOffset, argumentCountIncludingThis, prediction, insertChecksWithAccounting)) {
1802             endSpecialCase();
1803             return CallOptimizationResult::Inlined;
</pre>
<hr />
<pre>
1818 
1819     unsigned myInliningCost = inliningCost(callee, argumentCountIncludingThis, kind);
1820     if (myInliningCost &gt; inliningBalance)
1821         return CallOptimizationResult::DidNothing;
1822 
1823     auto insertCheck = [&amp;] (CodeBlock*) {
1824         if (needsToCheckCallee)
1825             emitFunctionChecks(callee, callTargetNode, thisArgument);
1826     };
1827     inlineCall(callTargetNode, result, callee, registerOffset, argumentCountIncludingThis, kind, continuationBlock, insertCheck);
1828     inliningBalance -= myInliningCost;
1829     return CallOptimizationResult::Inlined;
1830 }
1831 
1832 bool ByteCodeParser::handleVarargsInlining(Node* callTargetNode, VirtualRegister result,
1833     const CallLinkStatus&amp; callLinkStatus, int firstFreeReg, VirtualRegister thisArgument,
1834     VirtualRegister argumentsArgument, unsigned argumentsOffset,
1835     NodeType callOp, InlineCallFrame::Kind kind)
1836 {
1837     VERBOSE_LOG(&quot;Handling inlining (Varargs)...\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
<span class="line-modified">1838     if (callLinkStatus.maxNumArguments() &gt; Options::maximumVarargsForInlining()) {</span>
1839         VERBOSE_LOG(&quot;Bailing inlining: too many arguments for varargs inlining.\n&quot;);
1840         return false;
1841     }
1842     if (callLinkStatus.couldTakeSlowPath() || callLinkStatus.size() != 1) {
1843         VERBOSE_LOG(&quot;Bailing inlining: polymorphic inlining is not yet supported for varargs.\n&quot;);
1844         return false;
1845     }
1846 
1847     CallVariant callVariant = callLinkStatus[0];
1848 
1849     unsigned mandatoryMinimum;
1850     if (FunctionExecutable* functionExecutable = callVariant.functionExecutable())
1851         mandatoryMinimum = functionExecutable-&gt;parameterCount();
1852     else
1853         mandatoryMinimum = 0;
1854 
1855     // includes &quot;this&quot;
<span class="line-modified">1856     unsigned maxNumArguments = std::max(callLinkStatus.maxNumArguments(), mandatoryMinimum + 1);</span>
1857 
1858     CodeSpecializationKind specializationKind = InlineCallFrame::specializationKindFor(kind);
<span class="line-modified">1859     if (inliningCost(callVariant, maxNumArguments, kind) &gt; getInliningBalance(callLinkStatus, specializationKind)) {</span>
1860         VERBOSE_LOG(&quot;Bailing inlining: inlining cost too high.\n&quot;);
1861         return false;
1862     }
1863 
<span class="line-modified">1864     int registerOffset = firstFreeReg + 1;</span>
<span class="line-modified">1865     registerOffset -= maxNumArguments; // includes &quot;this&quot;</span>
1866     registerOffset -= CallFrame::headerSizeInRegisters;
1867     registerOffset = -WTF::roundUpToMultipleOf(stackAlignmentRegisters(), -registerOffset);
1868 
1869     auto insertChecks = [&amp;] (CodeBlock* codeBlock) {
1870         emitFunctionChecks(callVariant, callTargetNode, thisArgument);
1871 
1872         int remappedRegisterOffset =
<span class="line-modified">1873         m_inlineStackTop-&gt;remapOperand(VirtualRegister(registerOffset)).offset();</span>
1874 
1875         ensureLocals(VirtualRegister(remappedRegisterOffset).toLocal());
1876 
1877         int argumentStart = registerOffset + CallFrame::headerSizeInRegisters;
<span class="line-modified">1878         int remappedArgumentStart = m_inlineStackTop-&gt;remapOperand(VirtualRegister(argumentStart)).offset();</span>
1879 
1880         LoadVarargsData* data = m_graph.m_loadVarargsData.add();
1881         data-&gt;start = VirtualRegister(remappedArgumentStart + 1);
<span class="line-modified">1882         data-&gt;count = VirtualRegister(remappedRegisterOffset + CallFrameSlot::argumentCount);</span>
1883         data-&gt;offset = argumentsOffset;
<span class="line-modified">1884         data-&gt;limit = maxNumArguments;</span>
1885         data-&gt;mandatoryMinimum = mandatoryMinimum;
1886 
<span class="line-modified">1887         if (callOp == TailCallForwardVarargs)</span>
<span class="line-modified">1888             addToGraph(ForwardVarargs, OpInfo(data));</span>
<span class="line-modified">1889         else</span>
<span class="line-modified">1890             addToGraph(LoadVarargs, OpInfo(data), get(argumentsArgument));</span>













1891 
1892         // LoadVarargs may OSR exit. Hence, we need to keep alive callTargetNode, thisArgument
1893         // and argumentsArgument for the baseline JIT. However, we only need a Phantom for
1894         // callTargetNode because the other 2 are still in use and alive at this point.
1895         addToGraph(Phantom, callTargetNode);
1896 
1897         // In DFG IR before SSA, we cannot insert control flow between after the
1898         // LoadVarargs and the last SetArgumentDefinitely. This isn&#39;t a problem once we get to DFG
1899         // SSA. Fortunately, we also have other reasons for not inserting control flow
1900         // before SSA.
1901 
<span class="line-modified">1902         VariableAccessData* countVariable = newVariableAccessData(VirtualRegister(remappedRegisterOffset + CallFrameSlot::argumentCount));</span>
1903         // This is pretty lame, but it will force the count to be flushed as an int. This doesn&#39;t
1904         // matter very much, since our use of a SetArgumentDefinitely and Flushes for this local slot is
1905         // mostly just a formality.
1906         countVariable-&gt;predict(SpecInt32Only);
1907         countVariable-&gt;mergeIsProfitableToUnbox(true);
1908         Node* setArgumentCount = addToGraph(SetArgumentDefinitely, OpInfo(countVariable));
<span class="line-modified">1909         m_currentBlock-&gt;variablesAtTail.setOperand(countVariable-&gt;local(), setArgumentCount);</span>
1910 
1911         set(VirtualRegister(argumentStart), get(thisArgument), ImmediateNakedSet);
1912         unsigned numSetArguments = 0;
<span class="line-modified">1913         for (unsigned argument = 1; argument &lt; maxNumArguments; ++argument) {</span>
1914             VariableAccessData* variable = newVariableAccessData(VirtualRegister(remappedArgumentStart + argument));
1915             variable-&gt;mergeShouldNeverUnbox(true); // We currently have nowhere to put the type check on the LoadVarargs. LoadVarargs is effectful, so after it finishes, we cannot exit.
1916 
1917             // For a while it had been my intention to do things like this inside the
1918             // prediction injection phase. But in this case it&#39;s really best to do it here,
1919             // because it&#39;s here that we have access to the variable access datas for the
1920             // inlining we&#39;re about to do.
1921             //
1922             // Something else that&#39;s interesting here is that we&#39;d really love to get
1923             // predictions from the arguments loaded at the callsite, rather than the
1924             // arguments received inside the callee. But that probably won&#39;t matter for most
1925             // calls.
1926             if (codeBlock &amp;&amp; argument &lt; static_cast&lt;unsigned&gt;(codeBlock-&gt;numParameters())) {
1927                 ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
1928                 ValueProfile&amp; profile = codeBlock-&gt;valueProfileForArgument(argument);
1929                 variable-&gt;predict(profile.computeUpdatedPrediction(locker));
1930             }
1931 
1932             Node* setArgument = addToGraph(numSetArguments &gt;= mandatoryMinimum ? SetArgumentMaybe : SetArgumentDefinitely, OpInfo(variable));
<span class="line-modified">1933             m_currentBlock-&gt;variablesAtTail.setOperand(variable-&gt;local(), setArgument);</span>
1934             ++numSetArguments;
1935         }
1936     };
1937 
1938     // Intrinsics and internal functions can only be inlined if we&#39;re not doing varargs. This is because
1939     // we currently don&#39;t have any way of getting profiling information for arguments to non-JS varargs
1940     // calls. The prediction propagator won&#39;t be of any help because LoadVarargs obscures the data flow,
1941     // and there are no callsite value profiles and native function won&#39;t have callee value profiles for
1942     // those arguments. Even worse, if the intrinsic decides to exit, it won&#39;t really have anywhere to
1943     // exit to: LoadVarargs is effectful and it&#39;s part of the op_call_varargs, so we can&#39;t exit without
1944     // calling LoadVarargs twice.
<span class="line-modified">1945     inlineCall(callTargetNode, result, callVariant, registerOffset, maxNumArguments, kind, nullptr, insertChecks);</span>
1946 
1947 
1948     VERBOSE_LOG(&quot;Successful inlining (varargs, monomorphic).\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
1949     return true;
1950 }
1951 
1952 unsigned ByteCodeParser::getInliningBalance(const CallLinkStatus&amp; callLinkStatus, CodeSpecializationKind specializationKind)
1953 {
1954     unsigned inliningBalance = Options::maximumFunctionForCallInlineCandidateBytecodeCost();
1955     if (specializationKind == CodeForConstruct)
1956         inliningBalance = std::min(inliningBalance, Options::maximumFunctionForConstructInlineCandidateBytecoodeCost());
1957     if (callLinkStatus.isClosureCall())
1958         inliningBalance = std::min(inliningBalance, Options::maximumFunctionForClosureCallInlineCandidateBytecodeCost());
1959     return inliningBalance;
1960 }
1961 
1962 ByteCodeParser::CallOptimizationResult ByteCodeParser::handleInlining(
1963     Node* callTargetNode, VirtualRegister result, const CallLinkStatus&amp; callLinkStatus,
1964     int registerOffset, VirtualRegister thisArgument,
1965     int argumentCountIncludingThis,
<span class="line-modified">1966     unsigned nextOffset, NodeType callOp, InlineCallFrame::Kind kind, SpeculatedType prediction)</span>
1967 {
1968     VERBOSE_LOG(&quot;Handling inlining...\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
1969 
1970     CodeSpecializationKind specializationKind = InlineCallFrame::specializationKindFor(kind);
1971     unsigned inliningBalance = getInliningBalance(callLinkStatus, specializationKind);
1972 
1973     // First check if we can avoid creating control flow. Our inliner does some CFG
1974     // simplification on the fly and this helps reduce compile times, but we can only leverage
1975     // this in cases where we don&#39;t need control flow diamonds to check the callee.
1976     if (!callLinkStatus.couldTakeSlowPath() &amp;&amp; callLinkStatus.size() == 1) {
1977         return handleCallVariant(
1978             callTargetNode, result, callLinkStatus[0], registerOffset, thisArgument,
<span class="line-modified">1979             argumentCountIncludingThis, nextOffset, kind, prediction, inliningBalance, nullptr, true);</span>
1980     }
1981 
1982     // We need to create some kind of switch over callee. For now we only do this if we believe that
1983     // we&#39;re in the top tier. We have two reasons for this: first, it provides us an opportunity to
1984     // do more detailed polyvariant/polymorphic profiling; and second, it reduces compile times in
1985     // the DFG. And by polyvariant profiling we mean polyvariant profiling of *this* call. Note that
1986     // we could improve that aspect of this by doing polymorphic inlining but having the profiling
1987     // also.
1988     if (!m_graph.m_plan.isFTL() || !Options::usePolymorphicCallInlining()) {
1989         VERBOSE_LOG(&quot;Bailing inlining (hard).\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
1990         return CallOptimizationResult::DidNothing;
1991     }
1992 
1993     // If the claim is that this did not originate from a stub, then we don&#39;t want to emit a switch
1994     // statement. Whenever the non-stub profiling says that it could take slow path, it really means that
1995     // it has no idea.
1996     if (!Options::usePolymorphicCallInliningForNonStubStatus()
1997         &amp;&amp; !callLinkStatus.isBasedOnStub()) {
1998         VERBOSE_LOG(&quot;Bailing inlining (non-stub polymorphism).\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
1999         return CallOptimizationResult::DidNothing;
</pre>
<hr />
<pre>
2013         thingToSwitchOn = callTargetNode;
2014     else if (allAreClosureCalls)
2015         thingToSwitchOn = addToGraph(GetExecutable, callTargetNode);
2016     else {
2017         // FIXME: We should be able to handle this case, but it&#39;s tricky and we don&#39;t know of cases
2018         // where it would be beneficial. It might be best to handle these cases as if all calls were
2019         // closure calls.
2020         // https://bugs.webkit.org/show_bug.cgi?id=136020
2021         VERBOSE_LOG(&quot;Bailing inlining (mix).\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
2022         return CallOptimizationResult::DidNothing;
2023     }
2024 
2025     VERBOSE_LOG(&quot;Doing hard inlining...\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
2026 
2027     // This makes me wish that we were in SSA all the time. We need to pick a variable into which to
2028     // store the callee so that it will be accessible to all of the blocks we&#39;re about to create. We
2029     // get away with doing an immediate-set here because we wouldn&#39;t have performed any side effects
2030     // yet.
2031     VERBOSE_LOG(&quot;Register offset: &quot;, registerOffset);
2032     VirtualRegister calleeReg(registerOffset + CallFrameSlot::callee);
<span class="line-modified">2033     calleeReg = m_inlineStackTop-&gt;remapOperand(calleeReg);</span>
2034     VERBOSE_LOG(&quot;Callee is going to be &quot;, calleeReg, &quot;\n&quot;);
2035     setDirect(calleeReg, callTargetNode, ImmediateSetWithFlush);
2036 
2037     // It&#39;s OK to exit right now, even though we set some locals. That&#39;s because those locals are not
2038     // user-visible.
2039     m_exitOK = true;
2040     addToGraph(ExitOK);
2041 
2042     SwitchData&amp; data = *m_graph.m_switchData.add();
2043     data.kind = SwitchCell;
2044     addToGraph(Switch, OpInfo(&amp;data), thingToSwitchOn);
2045     m_currentBlock-&gt;didLink();
2046 
2047     BasicBlock* continuationBlock = allocateUntargetableBlock();
2048     VERBOSE_LOG(&quot;Adding untargetable block &quot;, RawPointer(continuationBlock), &quot; (continuation)\n&quot;);
2049 
2050     // We may force this true if we give up on inlining any of the edges.
2051     bool couldTakeSlowPath = callLinkStatus.couldTakeSlowPath();
2052 
2053     VERBOSE_LOG(&quot;About to loop over functions at &quot;, currentCodeOrigin(), &quot;.\n&quot;);
2054 
<span class="line-modified">2055     unsigned oldOffset = m_currentIndex;</span>
2056     for (unsigned i = 0; i &lt; callLinkStatus.size(); ++i) {
<span class="line-modified">2057         m_currentIndex = oldOffset;</span>
2058         BasicBlock* calleeEntryBlock = allocateUntargetableBlock();
2059         m_currentBlock = calleeEntryBlock;
2060         prepareToParseBlock();
2061 
2062         // At the top of each switch case, we can exit.
2063         m_exitOK = true;
2064 
2065         Node* myCallTargetNode = getDirect(calleeReg);
2066 
2067         auto inliningResult = handleCallVariant(
2068             myCallTargetNode, result, callLinkStatus[i], registerOffset,
<span class="line-modified">2069             thisArgument, argumentCountIncludingThis, nextOffset, kind, prediction,</span>
2070             inliningBalance, continuationBlock, false);
2071 
2072         if (inliningResult == CallOptimizationResult::DidNothing) {
2073             // That failed so we let the block die. Nothing interesting should have been added to
2074             // the block. We also give up on inlining any of the (less frequent) callees.
2075             ASSERT(m_graph.m_blocks.last() == m_currentBlock);
2076             m_graph.killBlockAndItsContents(m_currentBlock);
2077             m_graph.m_blocks.removeLast();
2078             VERBOSE_LOG(&quot;Inlining of a poly call failed, we will have to go through a slow path\n&quot;);
2079 
2080             // The fact that inlining failed means we need a slow path.
2081             couldTakeSlowPath = true;
2082             break;
2083         }
2084 
2085         JSCell* thingToCaseOn;
2086         if (allAreDirectCalls)
2087             thingToCaseOn = callLinkStatus[i].nonExecutableCallee();
2088         else {
2089             ASSERT(allAreClosureCalls);
2090             thingToCaseOn = callLinkStatus[i].executable();
2091         }
2092         data.cases.append(SwitchCase(m_graph.freeze(thingToCaseOn), calleeEntryBlock));
2093         VERBOSE_LOG(&quot;Finished optimizing &quot;, callLinkStatus[i], &quot; at &quot;, currentCodeOrigin(), &quot;.\n&quot;);
2094     }
2095 
2096     // Slow path block
2097     m_currentBlock = allocateUntargetableBlock();
<span class="line-modified">2098     m_currentIndex = oldOffset;</span>
2099     m_exitOK = true;
2100     data.fallThrough = BranchTarget(m_currentBlock);
2101     prepareToParseBlock();
2102     Node* myCallTargetNode = getDirect(calleeReg);
2103     if (couldTakeSlowPath) {
2104         addCall(
2105             result, callOp, nullptr, myCallTargetNode, argumentCountIncludingThis,
2106             registerOffset, prediction);
2107         VERBOSE_LOG(&quot;We added a call in the slow path\n&quot;);
2108     } else {
2109         addToGraph(CheckBadCell);
2110         addToGraph(Phantom, myCallTargetNode);
2111         emitArgumentPhantoms(registerOffset, argumentCountIncludingThis);
2112 
2113         if (result.isValid())
2114             set(result, addToGraph(BottomValue));
2115         VERBOSE_LOG(&quot;couldTakeSlowPath was false\n&quot;);
2116     }
2117 
<span class="line-modified">2118     m_currentIndex = nextOffset;</span>
2119     m_exitOK = true; // Origin changed, so it&#39;s fine to exit again.
2120     processSetLocalQueue();
2121 
2122     if (Node* terminal = m_currentBlock-&gt;terminal())
2123         ASSERT_UNUSED(terminal, terminal-&gt;op() == TailCall || terminal-&gt;op() == TailCallVarargs || terminal-&gt;op() == TailCallForwardVarargs);
2124     else {
2125         addJumpTo(continuationBlock);
2126     }
2127 
2128     prepareToParseBlock();
2129 
<span class="line-modified">2130     m_currentIndex = oldOffset;</span>
2131     m_currentBlock = continuationBlock;
2132     m_exitOK = true;
2133 
2134     VERBOSE_LOG(&quot;Done inlining (hard).\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
2135     return CallOptimizationResult::Inlined;
2136 }
2137 
2138 template&lt;typename ChecksFunctor&gt;
2139 bool ByteCodeParser::handleMinMax(VirtualRegister result, NodeType op, int registerOffset, int argumentCountIncludingThis, const ChecksFunctor&amp; insertChecks)
2140 {
2141     ASSERT(op == ArithMin || op == ArithMax);
2142 
2143     if (argumentCountIncludingThis == 1) {
2144         insertChecks();
2145         double limit = op == ArithMax ? -std::numeric_limits&lt;double&gt;::infinity() : +std::numeric_limits&lt;double&gt;::infinity();
2146         set(result, addToGraph(JSConstant, OpInfo(m_graph.freeze(jsDoubleNumber(limit)))));
2147         return true;
2148     }
2149 
2150     if (argumentCountIncludingThis == 2) {
2151         insertChecks();
<span class="line-modified">2152         Node* resultNode = get(VirtualRegister(virtualRegisterForArgument(1, registerOffset)));</span>
2153         addToGraph(Phantom, Edge(resultNode, NumberUse));
2154         set(result, resultNode);
2155         return true;
2156     }
2157 
2158     if (argumentCountIncludingThis == 3) {
2159         insertChecks();
<span class="line-modified">2160         set(result, addToGraph(op, get(virtualRegisterForArgument(1, registerOffset)), get(virtualRegisterForArgument(2, registerOffset))));</span>
2161         return true;
2162     }
2163 
2164     // Don&#39;t handle &gt;=3 arguments for now.
2165     return false;
2166 }
2167 
2168 template&lt;typename ChecksFunctor&gt;
2169 bool ByteCodeParser::handleIntrinsicCall(Node* callee, VirtualRegister result, Intrinsic intrinsic, int registerOffset, int argumentCountIncludingThis, SpeculatedType prediction, const ChecksFunctor&amp; insertChecks)
2170 {
2171     VERBOSE_LOG(&quot;       The intrinsic is &quot;, intrinsic, &quot;\n&quot;);
2172 
2173     if (!isOpcodeShape&lt;OpCallShape&gt;(m_currentInstruction))
2174         return false;
2175 
2176     // It so happens that the code below doesn&#39;t handle the invalid result case. We could fix that, but
2177     // it would only benefit intrinsics called as setters, like if you do:
2178     //
2179     //     o.__defineSetter__(&quot;foo&quot;, Math.pow)
2180     //
</pre>
<hr />
<pre>
2188         set(result, node);
2189         didSetResult = true;
2190     };
2191 
2192     auto inlineIntrinsic = [&amp;] {
2193         switch (intrinsic) {
2194 
2195         // Intrinsic Functions:
2196 
2197         case AbsIntrinsic: {
2198             if (argumentCountIncludingThis == 1) { // Math.abs()
2199                 insertChecks();
2200                 setResult(addToGraph(JSConstant, OpInfo(m_constantNaN)));
2201                 return true;
2202             }
2203 
2204             if (!MacroAssembler::supportsFloatingPointAbs())
2205                 return false;
2206 
2207             insertChecks();
<span class="line-modified">2208             Node* node = addToGraph(ArithAbs, get(virtualRegisterForArgument(1, registerOffset)));</span>
2209             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, Overflow))
2210                 node-&gt;mergeFlags(NodeMayOverflowInt32InDFG);
2211             setResult(node);
2212             return true;
2213         }
2214 
2215         case MinIntrinsic:
2216         case MaxIntrinsic:
2217             if (handleMinMax(result, intrinsic == MinIntrinsic ? ArithMin : ArithMax, registerOffset, argumentCountIncludingThis, insertChecks)) {
2218                 didSetResult = true;
2219                 return true;
2220             }
2221             return false;
2222 
2223 #define DFG_ARITH_UNARY(capitalizedName, lowerName) \
2224         case capitalizedName##Intrinsic:
2225         FOR_EACH_DFG_ARITH_UNARY_OP(DFG_ARITH_UNARY)
2226 #undef DFG_ARITH_UNARY
2227         {
2228             if (argumentCountIncludingThis == 1) {
2229                 insertChecks();
2230                 setResult(addToGraph(JSConstant, OpInfo(m_constantNaN)));
2231                 return true;
2232             }
2233             Arith::UnaryType type = Arith::UnaryType::Sin;
2234             switch (intrinsic) {
2235 #define DFG_ARITH_UNARY(capitalizedName, lowerName) \
2236             case capitalizedName##Intrinsic: \
2237                 type = Arith::UnaryType::capitalizedName; \
2238                 break;
2239         FOR_EACH_DFG_ARITH_UNARY_OP(DFG_ARITH_UNARY)
2240 #undef DFG_ARITH_UNARY
2241             default:
2242                 RELEASE_ASSERT_NOT_REACHED();
2243             }
2244             insertChecks();
<span class="line-modified">2245             setResult(addToGraph(ArithUnary, OpInfo(static_cast&lt;std::underlying_type&lt;Arith::UnaryType&gt;::type&gt;(type)), get(virtualRegisterForArgument(1, registerOffset))));</span>
2246             return true;
2247         }
2248 
2249         case FRoundIntrinsic:
2250         case SqrtIntrinsic: {
2251             if (argumentCountIncludingThis == 1) {
2252                 insertChecks();
2253                 setResult(addToGraph(JSConstant, OpInfo(m_constantNaN)));
2254                 return true;
2255             }
2256 
2257             NodeType nodeType = Unreachable;
2258             switch (intrinsic) {
2259             case FRoundIntrinsic:
2260                 nodeType = ArithFRound;
2261                 break;
2262             case SqrtIntrinsic:
2263                 nodeType = ArithSqrt;
2264                 break;
2265             default:
2266                 RELEASE_ASSERT_NOT_REACHED();
2267             }
2268             insertChecks();
<span class="line-modified">2269             setResult(addToGraph(nodeType, get(virtualRegisterForArgument(1, registerOffset))));</span>
2270             return true;
2271         }
2272 
2273         case PowIntrinsic: {
2274             if (argumentCountIncludingThis &lt; 3) {
2275                 // Math.pow() and Math.pow(x) return NaN.
2276                 insertChecks();
2277                 setResult(addToGraph(JSConstant, OpInfo(m_constantNaN)));
2278                 return true;
2279             }
2280             insertChecks();
<span class="line-modified">2281             VirtualRegister xOperand = virtualRegisterForArgument(1, registerOffset);</span>
<span class="line-modified">2282             VirtualRegister yOperand = virtualRegisterForArgument(2, registerOffset);</span>
2283             setResult(addToGraph(ArithPow, get(xOperand), get(yOperand)));
2284             return true;
2285         }
2286 
<span class="line-modified">2287         case ArrayPushIntrinsic: {</span>
<span class="line-modified">2288 #if USE(JSVALUE32_64)</span>
<span class="line-modified">2289             if (isX86()) {</span>
<span class="line-modified">2290                 if (argumentCountIncludingThis &gt; 2)</span>
<span class="line-modified">2291                     return false;</span>

































2292             }
<span class="line-removed">2293 #endif</span>
2294 


















2295             if (static_cast&lt;unsigned&gt;(argumentCountIncludingThis) &gt;= MIN_SPARSE_ARRAY_INDEX)
2296                 return false;
2297 
2298             ArrayMode arrayMode = getArrayMode(Array::Write);
2299             if (!arrayMode.isJSArray())
2300                 return false;
2301             switch (arrayMode.type()) {
2302             case Array::Int32:
2303             case Array::Double:
2304             case Array::Contiguous:
2305             case Array::ArrayStorage: {
2306                 insertChecks();
2307 
2308                 addVarArgChild(nullptr); // For storage.
2309                 for (int i = 0; i &lt; argumentCountIncludingThis; ++i)
<span class="line-modified">2310                     addVarArgChild(get(virtualRegisterForArgument(i, registerOffset)));</span>
2311                 Node* arrayPush = addToGraph(Node::VarArg, ArrayPush, OpInfo(arrayMode.asWord()), OpInfo(prediction));
2312                 setResult(arrayPush);
2313                 return true;
2314             }
2315 
2316             default:
2317                 return false;
2318             }
2319         }
2320 
2321         case ArraySliceIntrinsic: {
<span class="line-removed">2322 #if USE(JSVALUE32_64)</span>
<span class="line-removed">2323             if (isX86()) {</span>
<span class="line-removed">2324                 // There aren&#39;t enough registers for this to be done easily.</span>
<span class="line-removed">2325                 return false;</span>
<span class="line-removed">2326             }</span>
<span class="line-removed">2327 #endif</span>
2328             if (argumentCountIncludingThis &lt; 1)
2329                 return false;
2330 
2331             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadConstantCache)
2332                 || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCache))
2333                 return false;
2334 
2335             ArrayMode arrayMode = getArrayMode(Array::Read);
2336             if (!arrayMode.isJSArray())
2337                 return false;
2338 
2339             if (!arrayMode.isJSArrayWithOriginalStructure())
2340                 return false;
2341 
2342             switch (arrayMode.type()) {
2343             case Array::Double:
2344             case Array::Int32:
2345             case Array::Contiguous: {
2346                 JSGlobalObject* globalObject = m_graph.globalObjectFor(currentNodeOrigin().semantic);
2347 
2348                 Structure* arrayPrototypeStructure = globalObject-&gt;arrayPrototype()-&gt;structure(*m_vm);
2349                 Structure* objectPrototypeStructure = globalObject-&gt;objectPrototype()-&gt;structure(*m_vm);
2350 
2351                 // FIXME: We could easily relax the Array/Object.prototype transition as long as we OSR exitted if we saw a hole.
2352                 // https://bugs.webkit.org/show_bug.cgi?id=173171
2353                 if (globalObject-&gt;arraySpeciesWatchpointSet().state() == IsWatched
2354                     &amp;&amp; globalObject-&gt;havingABadTimeWatchpoint()-&gt;isStillValid()
2355                     &amp;&amp; arrayPrototypeStructure-&gt;transitionWatchpointSetIsStillValid()
2356                     &amp;&amp; objectPrototypeStructure-&gt;transitionWatchpointSetIsStillValid()
2357                     &amp;&amp; globalObject-&gt;arrayPrototypeChainIsSane()) {
2358 
2359                     m_graph.watchpoints().addLazily(globalObject-&gt;arraySpeciesWatchpointSet());
2360                     m_graph.watchpoints().addLazily(globalObject-&gt;havingABadTimeWatchpoint());
2361                     m_graph.registerAndWatchStructureTransition(arrayPrototypeStructure);
2362                     m_graph.registerAndWatchStructureTransition(objectPrototypeStructure);
2363 
2364                     insertChecks();
2365 
<span class="line-modified">2366                     Node* array = get(virtualRegisterForArgument(0, registerOffset));</span>
2367                     // We do a few things here to prove that we aren&#39;t skipping doing side-effects in an observable way:
2368                     // 1. We ensure that the &quot;constructor&quot; property hasn&#39;t been changed (because the observable
2369                     // effects of slice require that we perform a Get(array, &quot;constructor&quot;) and we can skip
2370                     // that if we&#39;re an original array structure. (We can relax this in the future by using
2371                     // TryGetById and CheckCell).
2372                     //
2373                     // 2. We check that the array we&#39;re calling slice on has the same global object as the lexical
2374                     // global object that this code is running in. This requirement is necessary because we setup the
2375                     // watchpoints above on the lexical global object. This means that code that calls slice on
2376                     // arrays produced by other global objects won&#39;t get this optimization. We could relax this
2377                     // requirement in the future by checking that the watchpoint hasn&#39;t fired at runtime in the code
2378                     // we generate instead of registering it as a watchpoint that would invalidate the compilation.
2379                     //
2380                     // 3. By proving we&#39;re an original array structure, we guarantee that the incoming array
2381                     // isn&#39;t a subclass of Array.
2382 
2383                     StructureSet structureSet;
2384                     structureSet.add(globalObject-&gt;originalArrayStructureForIndexingType(ArrayWithInt32));
2385                     structureSet.add(globalObject-&gt;originalArrayStructureForIndexingType(ArrayWithContiguous));
2386                     structureSet.add(globalObject-&gt;originalArrayStructureForIndexingType(ArrayWithDouble));
2387                     structureSet.add(globalObject-&gt;originalArrayStructureForIndexingType(CopyOnWriteArrayWithInt32));
2388                     structureSet.add(globalObject-&gt;originalArrayStructureForIndexingType(CopyOnWriteArrayWithContiguous));
2389                     structureSet.add(globalObject-&gt;originalArrayStructureForIndexingType(CopyOnWriteArrayWithDouble));
2390                     addToGraph(CheckStructure, OpInfo(m_graph.addStructureSet(structureSet)), array);
2391 
2392                     addVarArgChild(array);
2393                     if (argumentCountIncludingThis &gt;= 2)
<span class="line-modified">2394                         addVarArgChild(get(virtualRegisterForArgument(1, registerOffset))); // Start index.</span>
2395                     if (argumentCountIncludingThis &gt;= 3)
<span class="line-modified">2396                         addVarArgChild(get(virtualRegisterForArgument(2, registerOffset))); // End index.</span>
2397                     addVarArgChild(addToGraph(GetButterfly, array));
2398 
2399                     Node* arraySlice = addToGraph(Node::VarArg, ArraySlice, OpInfo(), OpInfo());
2400                     setResult(arraySlice);
2401                     return true;
2402                 }
2403 
2404                 return false;
2405             }
2406             default:
2407                 return false;
2408             }
2409 
2410             RELEASE_ASSERT_NOT_REACHED();
2411             return false;
2412         }
2413 
2414         case ArrayIndexOfIntrinsic: {
2415             if (argumentCountIncludingThis &lt; 2)
2416                 return false;
</pre>
<hr />
<pre>
2435             switch (arrayMode.type()) {
2436             case Array::Double:
2437             case Array::Int32:
2438             case Array::Contiguous: {
2439                 JSGlobalObject* globalObject = m_graph.globalObjectFor(currentNodeOrigin().semantic);
2440 
2441                 Structure* arrayPrototypeStructure = globalObject-&gt;arrayPrototype()-&gt;structure(*m_vm);
2442                 Structure* objectPrototypeStructure = globalObject-&gt;objectPrototype()-&gt;structure(*m_vm);
2443 
2444                 // FIXME: We could easily relax the Array/Object.prototype transition as long as we OSR exitted if we saw a hole.
2445                 // https://bugs.webkit.org/show_bug.cgi?id=173171
2446                 if (arrayPrototypeStructure-&gt;transitionWatchpointSetIsStillValid()
2447                     &amp;&amp; objectPrototypeStructure-&gt;transitionWatchpointSetIsStillValid()
2448                     &amp;&amp; globalObject-&gt;arrayPrototypeChainIsSane()) {
2449 
2450                     m_graph.registerAndWatchStructureTransition(arrayPrototypeStructure);
2451                     m_graph.registerAndWatchStructureTransition(objectPrototypeStructure);
2452 
2453                     insertChecks();
2454 
<span class="line-modified">2455                     Node* array = get(virtualRegisterForArgument(0, registerOffset));</span>
2456                     addVarArgChild(array);
<span class="line-modified">2457                     addVarArgChild(get(virtualRegisterForArgument(1, registerOffset))); // Search element.</span>
2458                     if (argumentCountIncludingThis &gt;= 3)
<span class="line-modified">2459                         addVarArgChild(get(virtualRegisterForArgument(2, registerOffset))); // Start index.</span>
2460                     addVarArgChild(nullptr);
2461 
2462                     Node* node = addToGraph(Node::VarArg, ArrayIndexOf, OpInfo(arrayMode.asWord()), OpInfo());
2463                     setResult(node);
2464                     return true;
2465                 }
2466 
2467                 return false;
2468             }
2469             default:
2470                 return false;
2471             }
2472 
2473             RELEASE_ASSERT_NOT_REACHED();
2474             return false;
2475 
2476         }
2477 
2478         case ArrayPopIntrinsic: {
<span class="line-removed">2479             if (argumentCountIncludingThis != 1)</span>
<span class="line-removed">2480                 return false;</span>
<span class="line-removed">2481 </span>
2482             ArrayMode arrayMode = getArrayMode(Array::Write);
2483             if (!arrayMode.isJSArray())
2484                 return false;
2485             switch (arrayMode.type()) {
2486             case Array::Int32:
2487             case Array::Double:
2488             case Array::Contiguous:
2489             case Array::ArrayStorage: {
2490                 insertChecks();
<span class="line-modified">2491                 Node* arrayPop = addToGraph(ArrayPop, OpInfo(arrayMode.asWord()), OpInfo(prediction), get(virtualRegisterForArgument(0, registerOffset)));</span>
2492                 setResult(arrayPop);
2493                 return true;
2494             }
2495 
2496             default:
2497                 return false;
2498             }
2499         }
2500 
2501         case AtomicsAddIntrinsic:
2502         case AtomicsAndIntrinsic:
2503         case AtomicsCompareExchangeIntrinsic:
2504         case AtomicsExchangeIntrinsic:
2505         case AtomicsIsLockFreeIntrinsic:
2506         case AtomicsLoadIntrinsic:
2507         case AtomicsOrIntrinsic:
2508         case AtomicsStoreIntrinsic:
2509         case AtomicsSubIntrinsic:
2510         case AtomicsXorIntrinsic: {
2511             if (!is64Bit())
</pre>
<hr />
<pre>
2553             case AtomicsSubIntrinsic:
2554                 op = AtomicsSub;
2555                 numArgs = 3;
2556                 break;
2557             case AtomicsXorIntrinsic:
2558                 op = AtomicsXor;
2559                 numArgs = 3;
2560                 break;
2561             default:
2562                 RELEASE_ASSERT_NOT_REACHED();
2563                 break;
2564             }
2565 
2566             if (static_cast&lt;unsigned&gt;(argumentCountIncludingThis) &lt; 1 + numArgs)
2567                 return false;
2568 
2569             insertChecks();
2570 
2571             Vector&lt;Node*, 3&gt; args;
2572             for (unsigned i = 0; i &lt; numArgs; ++i)
<span class="line-modified">2573                 args.append(get(virtualRegisterForArgument(1 + i, registerOffset)));</span>
2574 
2575             Node* resultNode;
2576             if (numArgs + 1 &lt;= 3) {
2577                 while (args.size() &lt; 3)
2578                     args.append(nullptr);
2579                 resultNode = addToGraph(op, OpInfo(ArrayMode(Array::SelectUsingPredictions, action).asWord()), OpInfo(prediction), args[0], args[1], args[2]);
2580             } else {
2581                 for (Node* node : args)
2582                     addVarArgChild(node);
2583                 addVarArgChild(nullptr);
2584                 resultNode = addToGraph(Node::VarArg, op, OpInfo(ArrayMode(Array::SelectUsingPredictions, action).asWord()), OpInfo(prediction));
2585             }
2586 
2587             setResult(resultNode);
2588             return true;
2589         }
2590 
2591         case ParseIntIntrinsic: {
2592             if (argumentCountIncludingThis &lt; 2)
2593                 return false;
2594 
2595             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell) || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
2596                 return false;
2597 
2598             insertChecks();
<span class="line-modified">2599             VirtualRegister valueOperand = virtualRegisterForArgument(1, registerOffset);</span>
2600             Node* parseInt;
2601             if (argumentCountIncludingThis == 2)
2602                 parseInt = addToGraph(ParseInt, OpInfo(), OpInfo(prediction), get(valueOperand));
2603             else {
2604                 ASSERT(argumentCountIncludingThis &gt; 2);
<span class="line-modified">2605                 VirtualRegister radixOperand = virtualRegisterForArgument(2, registerOffset);</span>
2606                 parseInt = addToGraph(ParseInt, OpInfo(), OpInfo(prediction), get(valueOperand), get(radixOperand));
2607             }
2608             setResult(parseInt);
2609             return true;
2610         }
2611 
2612         case CharCodeAtIntrinsic: {
<span class="line-modified">2613             if (argumentCountIncludingThis != 2)</span>



2614                 return false;
2615 
2616             insertChecks();
<span class="line-modified">2617             VirtualRegister thisOperand = virtualRegisterForArgument(0, registerOffset);</span>
<span class="line-modified">2618             VirtualRegister indexOperand = virtualRegisterForArgument(1, registerOffset);</span>
2619             Node* charCode = addToGraph(StringCharCodeAt, OpInfo(ArrayMode(Array::String, Array::Read).asWord()), get(thisOperand), get(indexOperand));
2620 
2621             setResult(charCode);
2622             return true;
2623         }
2624 



















2625         case CharAtIntrinsic: {
<span class="line-modified">2626             if (argumentCountIncludingThis != 2)</span>
2627                 return false;
2628 







2629             insertChecks();
<span class="line-modified">2630             VirtualRegister thisOperand = virtualRegisterForArgument(0, registerOffset);</span>
<span class="line-modified">2631             VirtualRegister indexOperand = virtualRegisterForArgument(1, registerOffset);</span>
2632             Node* charCode = addToGraph(StringCharAt, OpInfo(ArrayMode(Array::String, Array::Read).asWord()), get(thisOperand), get(indexOperand));
2633 
2634             setResult(charCode);
2635             return true;
2636         }
2637         case Clz32Intrinsic: {
2638             insertChecks();
2639             if (argumentCountIncludingThis == 1)
2640                 setResult(addToGraph(JSConstant, OpInfo(m_graph.freeze(jsNumber(32)))));
2641             else {
<span class="line-modified">2642                 Node* operand = get(virtualRegisterForArgument(1, registerOffset));</span>
2643                 setResult(addToGraph(ArithClz32, operand));
2644             }
2645             return true;
2646         }
2647         case FromCharCodeIntrinsic: {
2648             if (argumentCountIncludingThis != 2)
2649                 return false;
2650 
2651             insertChecks();
<span class="line-modified">2652             VirtualRegister indexOperand = virtualRegisterForArgument(1, registerOffset);</span>
2653             Node* charCode = addToGraph(StringFromCharCode, get(indexOperand));
2654 
2655             setResult(charCode);
2656 
2657             return true;
2658         }
2659 
2660         case RegExpExecIntrinsic: {
<span class="line-modified">2661             if (argumentCountIncludingThis != 2)</span>
2662                 return false;
2663 
2664             insertChecks();
<span class="line-modified">2665             Node* regExpExec = addToGraph(RegExpExec, OpInfo(0), OpInfo(prediction), addToGraph(GetGlobalObject, callee), get(virtualRegisterForArgument(0, registerOffset)), get(virtualRegisterForArgument(1, registerOffset)));</span>
2666             setResult(regExpExec);
2667 
2668             return true;
2669         }
2670 
2671         case RegExpTestIntrinsic:
2672         case RegExpTestFastIntrinsic: {
<span class="line-modified">2673             if (argumentCountIncludingThis != 2)</span>
2674                 return false;
2675 
2676             if (intrinsic == RegExpTestIntrinsic) {
2677                 // Don&#39;t inline intrinsic if we exited due to one of the primordial RegExp checks failing.
2678                 if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell))
2679                     return false;
2680 
2681                 JSGlobalObject* globalObject = m_inlineStackTop-&gt;m_codeBlock-&gt;globalObject();
2682                 Structure* regExpStructure = globalObject-&gt;regExpStructure();
2683                 m_graph.registerStructure(regExpStructure);
2684                 ASSERT(regExpStructure-&gt;storedPrototype().isObject());
2685                 ASSERT(regExpStructure-&gt;storedPrototype().asCell()-&gt;classInfo(*m_vm) == RegExpPrototype::info());
2686 
2687                 FrozenValue* regExpPrototypeObjectValue = m_graph.freeze(regExpStructure-&gt;storedPrototype());
2688                 Structure* regExpPrototypeStructure = regExpPrototypeObjectValue-&gt;structure();
2689 
2690                 auto isRegExpPropertySame = [&amp;] (JSValue primordialProperty, UniquedStringImpl* propertyUID) {
2691                     JSValue currentProperty;
2692                     if (!m_graph.getRegExpPrototypeProperty(regExpStructure-&gt;storedPrototypeObject(), regExpPrototypeStructure, propertyUID, currentProperty))
2693                         return false;
2694 
2695                     return currentProperty == primordialProperty;
2696                 };
2697 
2698                 // Check that RegExp.exec is still the primordial RegExp.prototype.exec
2699                 if (!isRegExpPropertySame(globalObject-&gt;regExpProtoExecFunction(), m_vm-&gt;propertyNames-&gt;exec.impl()))
2700                     return false;
2701 
2702                 // Check that regExpObject is actually a RegExp object.
<span class="line-modified">2703                 Node* regExpObject = get(virtualRegisterForArgument(0, registerOffset));</span>
2704                 addToGraph(Check, Edge(regExpObject, RegExpObjectUse));
2705 
2706                 // Check that regExpObject&#39;s exec is actually the primodial RegExp.prototype.exec.
2707                 UniquedStringImpl* execPropertyID = m_vm-&gt;propertyNames-&gt;exec.impl();
2708                 unsigned execIndex = m_graph.identifiers().ensure(execPropertyID);
2709                 Node* actualProperty = addToGraph(TryGetById, OpInfo(execIndex), OpInfo(SpecFunction), Edge(regExpObject, CellUse));
2710                 FrozenValue* regExpPrototypeExec = m_graph.freeze(globalObject-&gt;regExpProtoExecFunction());
2711                 addToGraph(CheckCell, OpInfo(regExpPrototypeExec), Edge(actualProperty, CellUse));
2712             }
2713 
2714             insertChecks();
<span class="line-modified">2715             Node* regExpObject = get(virtualRegisterForArgument(0, registerOffset));</span>
<span class="line-modified">2716             Node* regExpExec = addToGraph(RegExpTest, OpInfo(0), OpInfo(prediction), addToGraph(GetGlobalObject, callee), regExpObject, get(virtualRegisterForArgument(1, registerOffset)));</span>
2717             setResult(regExpExec);
2718 
2719             return true;
2720         }
2721 
2722         case RegExpMatchFastIntrinsic: {
2723             RELEASE_ASSERT(argumentCountIncludingThis == 2);
2724 
2725             insertChecks();
<span class="line-modified">2726             Node* regExpMatch = addToGraph(RegExpMatchFast, OpInfo(0), OpInfo(prediction), addToGraph(GetGlobalObject, callee), get(virtualRegisterForArgument(0, registerOffset)), get(virtualRegisterForArgument(1, registerOffset)));</span>
2727             setResult(regExpMatch);
2728             return true;
2729         }
2730 
2731         case ObjectCreateIntrinsic: {
2732             if (argumentCountIncludingThis != 2)
2733                 return false;
2734 
2735             insertChecks();
<span class="line-modified">2736             setResult(addToGraph(ObjectCreate, get(virtualRegisterForArgument(1, registerOffset))));</span>
2737             return true;
2738         }
2739 
2740         case ObjectGetPrototypeOfIntrinsic: {
<span class="line-modified">2741             if (argumentCountIncludingThis != 2)</span>
2742                 return false;
2743 
2744             insertChecks();
<span class="line-modified">2745             setResult(addToGraph(GetPrototypeOf, OpInfo(0), OpInfo(prediction), get(virtualRegisterForArgument(1, registerOffset))));</span>
2746             return true;
2747         }
2748 
2749         case ObjectIsIntrinsic: {
2750             if (argumentCountIncludingThis &lt; 3)
2751                 return false;
2752 
2753             insertChecks();
<span class="line-modified">2754             setResult(addToGraph(SameValue, get(virtualRegisterForArgument(1, registerOffset)), get(virtualRegisterForArgument(2, registerOffset))));</span>
2755             return true;
2756         }
2757 
2758         case ObjectKeysIntrinsic: {
2759             if (argumentCountIncludingThis &lt; 2)
2760                 return false;
2761 
2762             insertChecks();
<span class="line-modified">2763             setResult(addToGraph(ObjectKeys, get(virtualRegisterForArgument(1, registerOffset))));</span>
2764             return true;
2765         }
2766 
2767         case ReflectGetPrototypeOfIntrinsic: {
<span class="line-modified">2768             if (argumentCountIncludingThis != 2)</span>
2769                 return false;
2770 
2771             insertChecks();
<span class="line-modified">2772             setResult(addToGraph(GetPrototypeOf, OpInfo(0), OpInfo(prediction), Edge(get(virtualRegisterForArgument(1, registerOffset)), ObjectUse)));</span>
2773             return true;
2774         }
2775 
2776         case IsTypedArrayViewIntrinsic: {
2777             ASSERT(argumentCountIncludingThis == 2);
2778 
2779             insertChecks();
<span class="line-modified">2780             setResult(addToGraph(IsTypedArrayView, OpInfo(prediction), get(virtualRegisterForArgument(1, registerOffset))));</span>
2781             return true;
2782         }
2783 
2784         case StringPrototypeValueOfIntrinsic: {
2785             insertChecks();
<span class="line-modified">2786             Node* value = get(virtualRegisterForArgument(0, registerOffset));</span>
2787             setResult(addToGraph(StringValueOf, value));
2788             return true;
2789         }
2790 
2791         case StringPrototypeReplaceIntrinsic: {
<span class="line-modified">2792             if (argumentCountIncludingThis != 3)</span>
2793                 return false;
2794 
2795             // Don&#39;t inline intrinsic if we exited due to &quot;search&quot; not being a RegExp or String object.
2796             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
2797                 return false;
2798 
2799             // Don&#39;t inline intrinsic if we exited due to one of the primordial RegExp checks failing.
2800             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell))
2801                 return false;
2802 
2803             JSGlobalObject* globalObject = m_inlineStackTop-&gt;m_codeBlock-&gt;globalObject();
2804             Structure* regExpStructure = globalObject-&gt;regExpStructure();
2805             m_graph.registerStructure(regExpStructure);
2806             ASSERT(regExpStructure-&gt;storedPrototype().isObject());
2807             ASSERT(regExpStructure-&gt;storedPrototype().asCell()-&gt;classInfo(*m_vm) == RegExpPrototype::info());
2808 
2809             FrozenValue* regExpPrototypeObjectValue = m_graph.freeze(regExpStructure-&gt;storedPrototype());
2810             Structure* regExpPrototypeStructure = regExpPrototypeObjectValue-&gt;structure();
2811 
2812             auto isRegExpPropertySame = [&amp;] (JSValue primordialProperty, UniquedStringImpl* propertyUID) {
</pre>
<hr />
<pre>
2818             };
2819 
2820             // Check that searchRegExp.exec is still the primordial RegExp.prototype.exec
2821             if (!isRegExpPropertySame(globalObject-&gt;regExpProtoExecFunction(), m_vm-&gt;propertyNames-&gt;exec.impl()))
2822                 return false;
2823 
2824             // Check that searchRegExp.global is still the primordial RegExp.prototype.global
2825             if (!isRegExpPropertySame(globalObject-&gt;regExpProtoGlobalGetter(), m_vm-&gt;propertyNames-&gt;global.impl()))
2826                 return false;
2827 
2828             // Check that searchRegExp.unicode is still the primordial RegExp.prototype.unicode
2829             if (!isRegExpPropertySame(globalObject-&gt;regExpProtoUnicodeGetter(), m_vm-&gt;propertyNames-&gt;unicode.impl()))
2830                 return false;
2831 
2832             // Check that searchRegExp[Symbol.match] is still the primordial RegExp.prototype[Symbol.replace]
2833             if (!isRegExpPropertySame(globalObject-&gt;regExpProtoSymbolReplaceFunction(), m_vm-&gt;propertyNames-&gt;replaceSymbol.impl()))
2834                 return false;
2835 
2836             insertChecks();
2837 
<span class="line-modified">2838             Node* resultNode = addToGraph(StringReplace, OpInfo(0), OpInfo(prediction), get(virtualRegisterForArgument(0, registerOffset)), get(virtualRegisterForArgument(1, registerOffset)), get(virtualRegisterForArgument(2, registerOffset)));</span>
2839             setResult(resultNode);
2840             return true;
2841         }
2842 
2843         case StringPrototypeReplaceRegExpIntrinsic: {
<span class="line-modified">2844             if (argumentCountIncludingThis != 3)</span>
2845                 return false;
2846 
2847             insertChecks();
<span class="line-modified">2848             Node* resultNode = addToGraph(StringReplaceRegExp, OpInfo(0), OpInfo(prediction), get(virtualRegisterForArgument(0, registerOffset)), get(virtualRegisterForArgument(1, registerOffset)), get(virtualRegisterForArgument(2, registerOffset)));</span>
2849             setResult(resultNode);
2850             return true;
2851         }
2852 
2853         case RoundIntrinsic:
2854         case FloorIntrinsic:
2855         case CeilIntrinsic:
2856         case TruncIntrinsic: {
2857             if (argumentCountIncludingThis == 1) {
2858                 insertChecks();
2859                 setResult(addToGraph(JSConstant, OpInfo(m_constantNaN)));
2860                 return true;
2861             }
2862             insertChecks();
<span class="line-modified">2863             Node* operand = get(virtualRegisterForArgument(1, registerOffset));</span>
2864             NodeType op;
2865             if (intrinsic == RoundIntrinsic)
2866                 op = ArithRound;
2867             else if (intrinsic == FloorIntrinsic)
2868                 op = ArithFloor;
2869             else if (intrinsic == CeilIntrinsic)
2870                 op = ArithCeil;
2871             else {
2872                 ASSERT(intrinsic == TruncIntrinsic);
2873                 op = ArithTrunc;
2874             }
2875             Node* roundNode = addToGraph(op, OpInfo(0), OpInfo(prediction), operand);
2876             setResult(roundNode);
2877             return true;
2878         }
2879         case IMulIntrinsic: {
<span class="line-modified">2880             if (argumentCountIncludingThis != 3)</span>
2881                 return false;
2882             insertChecks();
<span class="line-modified">2883             VirtualRegister leftOperand = virtualRegisterForArgument(1, registerOffset);</span>
<span class="line-modified">2884             VirtualRegister rightOperand = virtualRegisterForArgument(2, registerOffset);</span>
2885             Node* left = get(leftOperand);
2886             Node* right = get(rightOperand);
2887             setResult(addToGraph(ArithIMul, left, right));
2888             return true;
2889         }
2890 
2891         case RandomIntrinsic: {
<span class="line-removed">2892             if (argumentCountIncludingThis != 1)</span>
<span class="line-removed">2893                 return false;</span>
2894             insertChecks();
2895             setResult(addToGraph(ArithRandom));
2896             return true;
2897         }
2898 
2899         case DFGTrueIntrinsic: {
2900             insertChecks();
2901             setResult(jsConstant(jsBoolean(true)));
2902             return true;
2903         }
2904 
2905         case FTLTrueIntrinsic: {
2906             insertChecks();
2907             setResult(jsConstant(jsBoolean(m_graph.m_plan.isFTL())));
2908             return true;
2909         }
2910 
2911         case OSRExitIntrinsic: {
2912             insertChecks();
2913             addToGraph(ForceOSRExit);
2914             setResult(addToGraph(JSConstant, OpInfo(m_constantUndefined)));
2915             return true;
2916         }
2917 
2918         case IsFinalTierIntrinsic: {
2919             insertChecks();
2920             setResult(jsConstant(jsBoolean(Options::useFTLJIT() ? m_graph.m_plan.isFTL() : true)));
2921             return true;
2922         }
2923 
2924         case SetInt32HeapPredictionIntrinsic: {
2925             insertChecks();
2926             for (int i = 1; i &lt; argumentCountIncludingThis; ++i) {
<span class="line-modified">2927                 Node* node = get(virtualRegisterForArgument(i, registerOffset));</span>
2928                 if (node-&gt;hasHeapPrediction())
2929                     node-&gt;setHeapPrediction(SpecInt32Only);
2930             }
2931             setResult(addToGraph(JSConstant, OpInfo(m_constantUndefined)));
2932             return true;
2933         }
2934 
2935         case CheckInt32Intrinsic: {
2936             insertChecks();
2937             for (int i = 1; i &lt; argumentCountIncludingThis; ++i) {
<span class="line-modified">2938                 Node* node = get(virtualRegisterForArgument(i, registerOffset));</span>
2939                 addToGraph(Phantom, Edge(node, Int32Use));
2940             }
2941             setResult(jsConstant(jsBoolean(true)));
2942             return true;
2943         }
2944 
2945         case FiatInt52Intrinsic: {
<span class="line-modified">2946             if (argumentCountIncludingThis != 2)</span>
2947                 return false;
2948             insertChecks();
<span class="line-modified">2949             VirtualRegister operand = virtualRegisterForArgument(1, registerOffset);</span>
2950             if (enableInt52())
2951                 setResult(addToGraph(FiatInt52, get(operand)));
2952             else
2953                 setResult(get(operand));
2954             return true;
2955         }
2956 
2957         case JSMapGetIntrinsic: {
<span class="line-modified">2958             if (argumentCountIncludingThis != 2)</span>
2959                 return false;
2960 
2961             insertChecks();
<span class="line-modified">2962             Node* map = get(virtualRegisterForArgument(0, registerOffset));</span>
<span class="line-modified">2963             Node* key = get(virtualRegisterForArgument(1, registerOffset));</span>
2964             Node* normalizedKey = addToGraph(NormalizeMapKey, key);
2965             Node* hash = addToGraph(MapHash, normalizedKey);
2966             Node* bucket = addToGraph(GetMapBucket, Edge(map, MapObjectUse), Edge(normalizedKey), Edge(hash));
2967             Node* resultNode = addToGraph(LoadValueFromMapBucket, OpInfo(BucketOwnerType::Map), OpInfo(prediction), bucket);
2968             setResult(resultNode);
2969             return true;
2970         }
2971 
2972         case JSSetHasIntrinsic:
2973         case JSMapHasIntrinsic: {
<span class="line-modified">2974             if (argumentCountIncludingThis != 2)</span>
2975                 return false;
2976 
2977             insertChecks();
<span class="line-modified">2978             Node* mapOrSet = get(virtualRegisterForArgument(0, registerOffset));</span>
<span class="line-modified">2979             Node* key = get(virtualRegisterForArgument(1, registerOffset));</span>
2980             Node* normalizedKey = addToGraph(NormalizeMapKey, key);
2981             Node* hash = addToGraph(MapHash, normalizedKey);
2982             UseKind useKind = intrinsic == JSSetHasIntrinsic ? SetObjectUse : MapObjectUse;
2983             Node* bucket = addToGraph(GetMapBucket, OpInfo(0), Edge(mapOrSet, useKind), Edge(normalizedKey), Edge(hash));
2984             JSCell* sentinel = nullptr;
2985             if (intrinsic == JSMapHasIntrinsic)
2986                 sentinel = m_vm-&gt;sentinelMapBucket();
2987             else
2988                 sentinel = m_vm-&gt;sentinelSetBucket();
2989 
2990             FrozenValue* frozenPointer = m_graph.freeze(sentinel);
2991             Node* invertedResult = addToGraph(CompareEqPtr, OpInfo(frozenPointer), bucket);
2992             Node* resultNode = addToGraph(LogicalNot, invertedResult);
2993             setResult(resultNode);
2994             return true;
2995         }
2996 
2997         case JSSetAddIntrinsic: {
<span class="line-modified">2998             if (argumentCountIncludingThis != 2)</span>
2999                 return false;
3000 
3001             insertChecks();
<span class="line-modified">3002             Node* base = get(virtualRegisterForArgument(0, registerOffset));</span>
<span class="line-modified">3003             Node* key = get(virtualRegisterForArgument(1, registerOffset));</span>
3004             Node* normalizedKey = addToGraph(NormalizeMapKey, key);
3005             Node* hash = addToGraph(MapHash, normalizedKey);
3006             addToGraph(SetAdd, base, normalizedKey, hash);
3007             setResult(base);
3008             return true;
3009         }
3010 
3011         case JSMapSetIntrinsic: {
<span class="line-modified">3012             if (argumentCountIncludingThis != 3)</span>
3013                 return false;
3014 
3015             insertChecks();
<span class="line-modified">3016             Node* base = get(virtualRegisterForArgument(0, registerOffset));</span>
<span class="line-modified">3017             Node* key = get(virtualRegisterForArgument(1, registerOffset));</span>
<span class="line-modified">3018             Node* value = get(virtualRegisterForArgument(2, registerOffset));</span>
3019 
3020             Node* normalizedKey = addToGraph(NormalizeMapKey, key);
3021             Node* hash = addToGraph(MapHash, normalizedKey);
3022 
3023             addVarArgChild(base);
3024             addVarArgChild(normalizedKey);
3025             addVarArgChild(value);
3026             addVarArgChild(hash);
3027             addToGraph(Node::VarArg, MapSet, OpInfo(0), OpInfo(0));
3028             setResult(base);
3029             return true;
3030         }
3031 
3032         case JSSetBucketHeadIntrinsic:
3033         case JSMapBucketHeadIntrinsic: {
3034             ASSERT(argumentCountIncludingThis == 2);
3035 
3036             insertChecks();
<span class="line-modified">3037             Node* map = get(virtualRegisterForArgument(1, registerOffset));</span>
3038             UseKind useKind = intrinsic == JSSetBucketHeadIntrinsic ? SetObjectUse : MapObjectUse;
3039             Node* resultNode = addToGraph(GetMapBucketHead, Edge(map, useKind));
3040             setResult(resultNode);
3041             return true;
3042         }
3043 
3044         case JSSetBucketNextIntrinsic:
3045         case JSMapBucketNextIntrinsic: {
3046             ASSERT(argumentCountIncludingThis == 2);
3047 
3048             insertChecks();
<span class="line-modified">3049             Node* bucket = get(virtualRegisterForArgument(1, registerOffset));</span>
3050             BucketOwnerType type = intrinsic == JSSetBucketNextIntrinsic ? BucketOwnerType::Set : BucketOwnerType::Map;
3051             Node* resultNode = addToGraph(GetMapBucketNext, OpInfo(type), bucket);
3052             setResult(resultNode);
3053             return true;
3054         }
3055 
3056         case JSSetBucketKeyIntrinsic:
3057         case JSMapBucketKeyIntrinsic: {
3058             ASSERT(argumentCountIncludingThis == 2);
3059 
3060             insertChecks();
<span class="line-modified">3061             Node* bucket = get(virtualRegisterForArgument(1, registerOffset));</span>
3062             BucketOwnerType type = intrinsic == JSSetBucketKeyIntrinsic ? BucketOwnerType::Set : BucketOwnerType::Map;
3063             Node* resultNode = addToGraph(LoadKeyFromMapBucket, OpInfo(type), OpInfo(prediction), bucket);
3064             setResult(resultNode);
3065             return true;
3066         }
3067 
3068         case JSMapBucketValueIntrinsic: {
3069             ASSERT(argumentCountIncludingThis == 2);
3070 
3071             insertChecks();
<span class="line-modified">3072             Node* bucket = get(virtualRegisterForArgument(1, registerOffset));</span>
3073             Node* resultNode = addToGraph(LoadValueFromMapBucket, OpInfo(BucketOwnerType::Map), OpInfo(prediction), bucket);
3074             setResult(resultNode);
3075             return true;
3076         }
3077 
3078         case JSWeakMapGetIntrinsic: {
<span class="line-modified">3079             if (argumentCountIncludingThis != 2)</span>
3080                 return false;
3081 
3082             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3083                 return false;
3084 
3085             insertChecks();
<span class="line-modified">3086             Node* map = get(virtualRegisterForArgument(0, registerOffset));</span>
<span class="line-modified">3087             Node* key = get(virtualRegisterForArgument(1, registerOffset));</span>
3088             addToGraph(Check, Edge(key, ObjectUse));
3089             Node* hash = addToGraph(MapHash, key);
3090             Node* holder = addToGraph(WeakMapGet, Edge(map, WeakMapObjectUse), Edge(key, ObjectUse), Edge(hash, Int32Use));
3091             Node* resultNode = addToGraph(ExtractValueFromWeakMapGet, OpInfo(), OpInfo(prediction), holder);
3092 
3093             setResult(resultNode);
3094             return true;
3095         }
3096 
3097         case JSWeakMapHasIntrinsic: {
<span class="line-modified">3098             if (argumentCountIncludingThis != 2)</span>
3099                 return false;
3100 
3101             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3102                 return false;
3103 
3104             insertChecks();
<span class="line-modified">3105             Node* map = get(virtualRegisterForArgument(0, registerOffset));</span>
<span class="line-modified">3106             Node* key = get(virtualRegisterForArgument(1, registerOffset));</span>
3107             addToGraph(Check, Edge(key, ObjectUse));
3108             Node* hash = addToGraph(MapHash, key);
3109             Node* holder = addToGraph(WeakMapGet, Edge(map, WeakMapObjectUse), Edge(key, ObjectUse), Edge(hash, Int32Use));
3110             Node* invertedResult = addToGraph(IsEmpty, holder);
3111             Node* resultNode = addToGraph(LogicalNot, invertedResult);
3112 
3113             setResult(resultNode);
3114             return true;
3115         }
3116 
3117         case JSWeakSetHasIntrinsic: {
<span class="line-modified">3118             if (argumentCountIncludingThis != 2)</span>
3119                 return false;
3120 
3121             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3122                 return false;
3123 
3124             insertChecks();
<span class="line-modified">3125             Node* map = get(virtualRegisterForArgument(0, registerOffset));</span>
<span class="line-modified">3126             Node* key = get(virtualRegisterForArgument(1, registerOffset));</span>
3127             addToGraph(Check, Edge(key, ObjectUse));
3128             Node* hash = addToGraph(MapHash, key);
3129             Node* holder = addToGraph(WeakMapGet, Edge(map, WeakSetObjectUse), Edge(key, ObjectUse), Edge(hash, Int32Use));
3130             Node* invertedResult = addToGraph(IsEmpty, holder);
3131             Node* resultNode = addToGraph(LogicalNot, invertedResult);
3132 
3133             setResult(resultNode);
3134             return true;
3135         }
3136 
3137         case JSWeakSetAddIntrinsic: {
<span class="line-modified">3138             if (argumentCountIncludingThis != 2)</span>
3139                 return false;
3140 
3141             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3142                 return false;
3143 
3144             insertChecks();
<span class="line-modified">3145             Node* base = get(virtualRegisterForArgument(0, registerOffset));</span>
<span class="line-modified">3146             Node* key = get(virtualRegisterForArgument(1, registerOffset));</span>
3147             addToGraph(Check, Edge(key, ObjectUse));
3148             Node* hash = addToGraph(MapHash, key);
3149             addToGraph(WeakSetAdd, Edge(base, WeakSetObjectUse), Edge(key, ObjectUse), Edge(hash, Int32Use));
3150             setResult(base);
3151             return true;
3152         }
3153 
3154         case JSWeakMapSetIntrinsic: {
<span class="line-modified">3155             if (argumentCountIncludingThis != 3)</span>
3156                 return false;
3157 
3158             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3159                 return false;
3160 
3161             insertChecks();
<span class="line-modified">3162             Node* base = get(virtualRegisterForArgument(0, registerOffset));</span>
<span class="line-modified">3163             Node* key = get(virtualRegisterForArgument(1, registerOffset));</span>
<span class="line-modified">3164             Node* value = get(virtualRegisterForArgument(2, registerOffset));</span>
3165 
3166             addToGraph(Check, Edge(key, ObjectUse));
3167             Node* hash = addToGraph(MapHash, key);
3168 
3169             addVarArgChild(Edge(base, WeakMapObjectUse));
3170             addVarArgChild(Edge(key, ObjectUse));
3171             addVarArgChild(Edge(value));
3172             addVarArgChild(Edge(hash, Int32Use));
3173             addToGraph(Node::VarArg, WeakMapSet, OpInfo(0), OpInfo(0));
3174             setResult(base);
3175             return true;
3176         }
3177 



































3178         case DataViewGetInt8:
3179         case DataViewGetUint8:
3180         case DataViewGetInt16:
3181         case DataViewGetUint16:
3182         case DataViewGetInt32:
3183         case DataViewGetUint32:
3184         case DataViewGetFloat32:
3185         case DataViewGetFloat64: {
3186             if (!is64Bit())
3187                 return false;
3188 
3189             // To inline data view accesses, we assume the architecture we&#39;re running on:
3190             // - Is little endian.
3191             // - Allows unaligned loads/stores without crashing.
3192 
3193             if (argumentCountIncludingThis &lt; 2)
3194                 return false;
3195             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3196                 return false;
3197 
</pre>
<hr />
<pre>
3223                 break;
3224 
3225             case DataViewGetFloat32:
3226                 byteSize = 4;
3227                 op = DataViewGetFloat;
3228                 break;
3229             case DataViewGetFloat64:
3230                 byteSize = 8;
3231                 op = DataViewGetFloat;
3232                 break;
3233             default:
3234                 RELEASE_ASSERT_NOT_REACHED();
3235             }
3236 
3237             TriState isLittleEndian = MixedTriState;
3238             Node* littleEndianChild = nullptr;
3239             if (byteSize &gt; 1) {
3240                 if (argumentCountIncludingThis &lt; 3)
3241                     isLittleEndian = FalseTriState;
3242                 else {
<span class="line-modified">3243                     littleEndianChild = get(virtualRegisterForArgument(2, registerOffset));</span>
3244                     if (littleEndianChild-&gt;hasConstant()) {
3245                         JSValue constant = littleEndianChild-&gt;constant()-&gt;value();
3246                         if (constant) {
3247                             isLittleEndian = constant.pureToBoolean();
3248                             if (isLittleEndian != MixedTriState)
3249                                 littleEndianChild = nullptr;
3250                         }
3251                     } else
3252                         isLittleEndian = MixedTriState;
3253                 }
3254             }
3255 
3256             DataViewData data { };
3257             data.isLittleEndian = isLittleEndian;
3258             data.isSigned = isSigned;
3259             data.byteSize = byteSize;
3260 
3261             setResult(
<span class="line-modified">3262                 addToGraph(op, OpInfo(data.asQuadWord), OpInfo(prediction), get(virtualRegisterForArgument(0, registerOffset)), get(virtualRegisterForArgument(1, registerOffset)), littleEndianChild));</span>
3263             return true;
3264         }
3265 
3266         case DataViewSetInt8:
3267         case DataViewSetUint8:
3268         case DataViewSetInt16:
3269         case DataViewSetUint16:
3270         case DataViewSetInt32:
3271         case DataViewSetUint32:
3272         case DataViewSetFloat32:
3273         case DataViewSetFloat64: {
3274             if (!is64Bit())
3275                 return false;
3276 
3277             if (argumentCountIncludingThis &lt; 3)
3278                 return false;
3279 
3280             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3281                 return false;
3282 
</pre>
<hr />
<pre>
3308                 break;
3309 
3310             case DataViewSetFloat32:
3311                 isFloatingPoint = true;
3312                 byteSize = 4;
3313                 break;
3314             case DataViewSetFloat64:
3315                 isFloatingPoint = true;
3316                 byteSize = 8;
3317                 break;
3318             default:
3319                 RELEASE_ASSERT_NOT_REACHED();
3320             }
3321 
3322             TriState isLittleEndian = MixedTriState;
3323             Node* littleEndianChild = nullptr;
3324             if (byteSize &gt; 1) {
3325                 if (argumentCountIncludingThis &lt; 4)
3326                     isLittleEndian = FalseTriState;
3327                 else {
<span class="line-modified">3328                     littleEndianChild = get(virtualRegisterForArgument(3, registerOffset));</span>
3329                     if (littleEndianChild-&gt;hasConstant()) {
3330                         JSValue constant = littleEndianChild-&gt;constant()-&gt;value();
3331                         if (constant) {
3332                             isLittleEndian = constant.pureToBoolean();
3333                             if (isLittleEndian != MixedTriState)
3334                                 littleEndianChild = nullptr;
3335                         }
3336                     } else
3337                         isLittleEndian = MixedTriState;
3338                 }
3339             }
3340 
3341             DataViewData data { };
3342             data.isLittleEndian = isLittleEndian;
3343             data.isSigned = isSigned;
3344             data.byteSize = byteSize;
3345             data.isFloatingPoint = isFloatingPoint;
3346 
<span class="line-modified">3347             addVarArgChild(get(virtualRegisterForArgument(0, registerOffset)));</span>
<span class="line-modified">3348             addVarArgChild(get(virtualRegisterForArgument(1, registerOffset)));</span>
<span class="line-modified">3349             addVarArgChild(get(virtualRegisterForArgument(2, registerOffset)));</span>
3350             addVarArgChild(littleEndianChild);
3351 
3352             addToGraph(Node::VarArg, DataViewSet, OpInfo(data.asQuadWord), OpInfo());
3353             setResult(addToGraph(JSConstant, OpInfo(m_constantUndefined)));
3354             return true;
3355         }
3356 
3357         case HasOwnPropertyIntrinsic: {
<span class="line-modified">3358             if (argumentCountIncludingThis != 2)</span>
3359                 return false;
3360 
3361             // This can be racy, that&#39;s fine. We know that once we observe that this is created,
3362             // that it will never be destroyed until the VM is destroyed. It&#39;s unlikely that
3363             // we&#39;d ever get to the point where we inline this as an intrinsic without the
3364             // cache being created, however, it&#39;s possible if we always throw exceptions inside
3365             // hasOwnProperty.
3366             if (!m_vm-&gt;hasOwnPropertyCache())
3367                 return false;
3368 
3369             insertChecks();
<span class="line-modified">3370             Node* object = get(virtualRegisterForArgument(0, registerOffset));</span>
<span class="line-modified">3371             Node* key = get(virtualRegisterForArgument(1, registerOffset));</span>
3372             Node* resultNode = addToGraph(HasOwnProperty, object, key);
3373             setResult(resultNode);
3374             return true;
3375         }
3376 
3377         case StringPrototypeSliceIntrinsic: {
3378             if (argumentCountIncludingThis &lt; 2)
3379                 return false;
3380 
3381             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3382                 return false;
3383 
3384             insertChecks();
<span class="line-modified">3385             Node* thisString = get(virtualRegisterForArgument(0, registerOffset));</span>
<span class="line-modified">3386             Node* start = get(virtualRegisterForArgument(1, registerOffset));</span>
3387             Node* end = nullptr;
3388             if (argumentCountIncludingThis &gt; 2)
<span class="line-modified">3389                 end = get(virtualRegisterForArgument(2, registerOffset));</span>
3390             Node* resultNode = addToGraph(StringSlice, thisString, start, end);
3391             setResult(resultNode);
3392             return true;
3393         }
3394 
3395         case StringPrototypeToLowerCaseIntrinsic: {
<span class="line-removed">3396             if (argumentCountIncludingThis != 1)</span>
<span class="line-removed">3397                 return false;</span>
<span class="line-removed">3398 </span>
3399             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3400                 return false;
3401 
3402             insertChecks();
<span class="line-modified">3403             Node* thisString = get(virtualRegisterForArgument(0, registerOffset));</span>
3404             Node* resultNode = addToGraph(ToLowerCase, thisString);
3405             setResult(resultNode);
3406             return true;
3407         }
3408 
3409         case NumberPrototypeToStringIntrinsic: {
<span class="line-removed">3410             if (argumentCountIncludingThis != 1 &amp;&amp; argumentCountIncludingThis != 2)</span>
<span class="line-removed">3411                 return false;</span>
<span class="line-removed">3412 </span>
3413             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3414                 return false;
3415 
3416             insertChecks();
<span class="line-modified">3417             Node* thisNumber = get(virtualRegisterForArgument(0, registerOffset));</span>
3418             if (argumentCountIncludingThis == 1) {
3419                 Node* resultNode = addToGraph(ToString, thisNumber);
3420                 setResult(resultNode);
3421             } else {
<span class="line-modified">3422                 Node* radix = get(virtualRegisterForArgument(1, registerOffset));</span>
3423                 Node* resultNode = addToGraph(NumberToStringWithRadix, thisNumber, radix);
3424                 setResult(resultNode);
3425             }
3426             return true;
3427         }
3428 
3429         case NumberIsIntegerIntrinsic: {
3430             if (argumentCountIncludingThis &lt; 2)
3431                 return false;
3432 
3433             insertChecks();
<span class="line-modified">3434             Node* input = get(virtualRegisterForArgument(1, registerOffset));</span>
3435             Node* resultNode = addToGraph(NumberIsInteger, input);
3436             setResult(resultNode);
3437             return true;
3438         }
3439 
3440         case CPUMfenceIntrinsic:
3441         case CPURdtscIntrinsic:
3442         case CPUCpuidIntrinsic:
3443         case CPUPauseIntrinsic: {
3444 #if CPU(X86_64)
3445             if (!m_graph.m_plan.isFTL())
3446                 return false;
3447             insertChecks();
3448             setResult(addToGraph(CPUIntrinsic, OpInfo(intrinsic), OpInfo()));
3449             return true;
3450 #else
3451             return false;
3452 #endif
3453         }
3454 
</pre>
<hr />
<pre>
3587     }
3588 
3589     default:
3590         return false;
3591     }
3592     RELEASE_ASSERT_NOT_REACHED();
3593 }
3594 
3595 static void blessCallDOMGetter(Node* node)
3596 {
3597     DOMJIT::CallDOMGetterSnippet* snippet = node-&gt;callDOMGetterData()-&gt;snippet;
3598     if (snippet &amp;&amp; !snippet-&gt;effect.mustGenerate())
3599         node-&gt;clearFlags(NodeMustGenerate);
3600 }
3601 
3602 bool ByteCodeParser::handleDOMJITGetter(VirtualRegister result, const GetByIdVariant&amp; variant, Node* thisNode, unsigned identifierNumber, SpeculatedType prediction)
3603 {
3604     if (!variant.domAttribute())
3605         return false;
3606 
<span class="line-modified">3607     auto domAttribute = variant.domAttribute().value();</span>
3608 
3609     // We do not need to actually look up CustomGetterSetter here. Checking Structures or registering watchpoints are enough,
3610     // since replacement of CustomGetterSetter always incurs Structure transition.
3611     if (!check(variant.conditionSet()))
3612         return false;
3613     addToGraph(CheckStructure, OpInfo(m_graph.addStructureSet(variant.structureSet())), thisNode);
3614 
3615     // We do not need to emit CheckCell thingy here. When the custom accessor is replaced to different one, Structure transition occurs.
<span class="line-modified">3616     addToGraph(CheckSubClass, OpInfo(domAttribute.classInfo), thisNode);</span>
3617 
3618     bool wasSeenInJIT = true;
<span class="line-modified">3619     addToGraph(FilterGetByIdStatus, OpInfo(m_graph.m_plan.recordedStatuses().addGetByIdStatus(currentCodeOrigin(), GetByIdStatus(GetByIdStatus::Custom, wasSeenInJIT, variant))), thisNode);</span>



3620 
3621     CallDOMGetterData* callDOMGetterData = m_graph.m_callDOMGetterData.add();
3622     callDOMGetterData-&gt;customAccessorGetter = variant.customAccessorGetter();
3623     ASSERT(callDOMGetterData-&gt;customAccessorGetter);
3624 
<span class="line-modified">3625     if (const auto* domJIT = domAttribute.domJIT) {</span>
3626         callDOMGetterData-&gt;domJIT = domJIT;
3627         Ref&lt;DOMJIT::CallDOMGetterSnippet&gt; snippet = domJIT-&gt;compiler()();
3628         callDOMGetterData-&gt;snippet = snippet.ptr();
3629         m_graph.m_domJITSnippets.append(WTFMove(snippet));
3630     }
3631     DOMJIT::CallDOMGetterSnippet* callDOMGetterSnippet = callDOMGetterData-&gt;snippet;
3632     callDOMGetterData-&gt;identifierNumber = identifierNumber;
3633 
3634     Node* callDOMGetterNode = nullptr;
3635     // GlobalObject of thisNode is always used to create a DOMWrapper.
3636     if (callDOMGetterSnippet &amp;&amp; callDOMGetterSnippet-&gt;requireGlobalObject) {
3637         Node* globalObject = addToGraph(GetGlobalObject, thisNode);
3638         callDOMGetterNode = addToGraph(CallDOMGetter, OpInfo(callDOMGetterData), OpInfo(prediction), thisNode, globalObject);
3639     } else
3640         callDOMGetterNode = addToGraph(CallDOMGetter, OpInfo(callDOMGetterData), OpInfo(prediction), thisNode);
3641     blessCallDOMGetter(callDOMGetterNode);
3642     set(result, callDOMGetterNode);
3643     return true;
3644 }
3645 
<span class="line-modified">3646 bool ByteCodeParser::handleModuleNamespaceLoad(VirtualRegister result, SpeculatedType prediction, Node* base, GetByIdStatus getById)</span>
3647 {
3648     if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell))
3649         return false;
3650     addToGraph(CheckCell, OpInfo(m_graph.freeze(getById.moduleNamespaceObject())), Edge(base, CellUse));
3651 
<span class="line-modified">3652     addToGraph(FilterGetByIdStatus, OpInfo(m_graph.m_plan.recordedStatuses().addGetByIdStatus(currentCodeOrigin(), getById)), base);</span>
3653 
3654     // Ideally we wouldn&#39;t have to do this Phantom. But:
3655     //
3656     // For the constant case: we must do it because otherwise we would have no way of knowing
3657     // that the scope is live at OSR here.
3658     //
3659     // For the non-constant case: GetClosureVar could be DCE&#39;d, but baseline&#39;s implementation
3660     // won&#39;t be able to handle an Undefined scope.
3661     addToGraph(Phantom, base);
3662 
3663     // Constant folding in the bytecode parser is important for performance. This may not
3664     // have executed yet. If it hasn&#39;t, then we won&#39;t have a prediction. Lacking a
3665     // prediction, we&#39;d otherwise think that it has to exit. Then when it did execute, we
3666     // would recompile. But if we can fold it here, we avoid the exit.
3667     m_graph.freeze(getById.moduleEnvironment());
3668     if (JSValue value = m_graph.tryGetConstantClosureVar(getById.moduleEnvironment(), getById.scopeOffset())) {
3669         set(result, weakJSConstant(value));
3670         return true;
3671     }
3672     set(result, addToGraph(GetClosureVar, OpInfo(getById.scopeOffset().offset()), OpInfo(prediction), weakJSConstant(getById.moduleEnvironment())));
3673     return true;
3674 }
3675 
3676 template&lt;typename ChecksFunctor&gt;
3677 bool ByteCodeParser::handleTypedArrayConstructor(
3678     VirtualRegister result, InternalFunction* function, int registerOffset,
3679     int argumentCountIncludingThis, TypedArrayType type, const ChecksFunctor&amp; insertChecks)
3680 {
3681     if (!isTypedView(type))
3682         return false;
3683 
<span class="line-modified">3684     if (function-&gt;classInfo() != constructorClassInfoForType(type))</span>
3685         return false;
3686 
<span class="line-modified">3687     if (function-&gt;globalObject(*m_vm) != m_inlineStackTop-&gt;m_codeBlock-&gt;globalObject())</span>
3688         return false;
3689 
3690     // We only have an intrinsic for the case where you say:
3691     //
3692     // new FooArray(blah);
3693     //
3694     // Of course, &#39;blah&#39; could be any of the following:
3695     //
3696     // - Integer, indicating that you want to allocate an array of that length.
3697     //   This is the thing we&#39;re hoping for, and what we can actually do meaningful
3698     //   optimizations for.
3699     //
3700     // - Array buffer, indicating that you want to create a view onto that _entire_
3701     //   buffer.
3702     //
3703     // - Non-buffer object, indicating that you want to create a copy of that
3704     //   object by pretending that it quacks like an array.
3705     //
3706     // - Anything else, indicating that you want to have an exception thrown at
3707     //   you.
3708     //
3709     // The intrinsic, NewTypedArray, will behave as if it could do any of these
3710     // things up until we do Fixup. Thereafter, if child1 (i.e. &#39;blah&#39;) is
3711     // predicted Int32, then we lock it in as a normal typed array allocation.
3712     // Otherwise, NewTypedArray turns into a totally opaque function call that
3713     // may clobber the world - by virtue of it accessing properties on what could
3714     // be an object.
3715     //
3716     // Note that although the generic form of NewTypedArray sounds sort of awful,
3717     // it is actually quite likely to be more efficient than a fully generic
3718     // Construct. So, we might want to think about making NewTypedArray variadic,
3719     // or else making Construct not super slow.
3720 
3721     if (argumentCountIncludingThis != 2)
3722         return false;
3723 
<span class="line-modified">3724     if (!function-&gt;globalObject(*m_vm)-&gt;typedArrayStructureConcurrently(type))</span>
3725         return false;
3726 
3727     insertChecks();
3728     set(result,
<span class="line-modified">3729         addToGraph(NewTypedArray, OpInfo(type), get(virtualRegisterForArgument(1, registerOffset))));</span>
3730     return true;
3731 }
3732 
3733 template&lt;typename ChecksFunctor&gt;
3734 bool ByteCodeParser::handleConstantInternalFunction(
3735     Node* callTargetNode, VirtualRegister result, InternalFunction* function, int registerOffset,
3736     int argumentCountIncludingThis, CodeSpecializationKind kind, SpeculatedType prediction, const ChecksFunctor&amp; insertChecks)
3737 {
3738     VERBOSE_LOG(&quot;    Handling constant internal function &quot;, JSValue(function), &quot;\n&quot;);
3739 
3740     // It so happens that the code below assumes that the result operand is valid. It&#39;s extremely
3741     // unlikely that the result operand would be invalid - you&#39;d have to call this via a setter call.
3742     if (!result.isValid())
3743         return false;
3744 
3745     if (kind == CodeForConstruct) {
<span class="line-modified">3746         Node* newTargetNode = get(virtualRegisterForArgument(0, registerOffset));</span>
3747         // We cannot handle the case where new.target != callee (i.e. a construct from a super call) because we
3748         // don&#39;t know what the prototype of the constructed object will be.
3749         // FIXME: If we have inlined super calls up to the call site, however, we should be able to figure out the structure. https://bugs.webkit.org/show_bug.cgi?id=152700
3750         if (newTargetNode != callTargetNode)
3751             return false;
3752     }
3753 
<span class="line-modified">3754     if (function-&gt;classInfo() == ArrayConstructor::info()) {</span>
<span class="line-modified">3755         if (function-&gt;globalObject(*m_vm) != m_inlineStackTop-&gt;m_codeBlock-&gt;globalObject())</span>
3756             return false;
3757 
3758         insertChecks();
3759         if (argumentCountIncludingThis == 2) {
3760             set(result,
<span class="line-modified">3761                 addToGraph(NewArrayWithSize, OpInfo(ArrayWithUndecided), get(virtualRegisterForArgument(1, registerOffset))));</span>
3762             return true;
3763         }
3764 
3765         for (int i = 1; i &lt; argumentCountIncludingThis; ++i)
<span class="line-modified">3766             addVarArgChild(get(virtualRegisterForArgument(i, registerOffset)));</span>
3767         set(result,
3768             addToGraph(Node::VarArg, NewArray, OpInfo(ArrayWithUndecided), OpInfo(argumentCountIncludingThis - 1)));
3769         return true;
3770     }
3771 
<span class="line-modified">3772     if (function-&gt;classInfo() == NumberConstructor::info()) {</span>
3773         if (kind == CodeForConstruct)
3774             return false;
3775 
3776         insertChecks();
3777         if (argumentCountIncludingThis &lt;= 1)
3778             set(result, jsConstant(jsNumber(0)));
3779         else
<span class="line-modified">3780             set(result, addToGraph(ToNumber, OpInfo(0), OpInfo(prediction), get(virtualRegisterForArgument(1, registerOffset))));</span>
3781 
3782         return true;
3783     }
3784 
<span class="line-modified">3785     if (function-&gt;classInfo() == StringConstructor::info()) {</span>
3786         insertChecks();
3787 
3788         Node* resultNode;
3789 
3790         if (argumentCountIncludingThis &lt;= 1)
3791             resultNode = jsConstant(m_vm-&gt;smallStrings.emptyString());
3792         else
<span class="line-modified">3793             resultNode = addToGraph(CallStringConstructor, get(virtualRegisterForArgument(1, registerOffset)));</span>
3794 
3795         if (kind == CodeForConstruct)
<span class="line-modified">3796             resultNode = addToGraph(NewStringObject, OpInfo(m_graph.registerStructure(function-&gt;globalObject(*m_vm)-&gt;stringObjectStructure())), resultNode);</span>
3797 
3798         set(result, resultNode);
3799         return true;
3800     }
3801 
<span class="line-modified">3802     if (function-&gt;classInfo() == SymbolConstructor::info() &amp;&amp; kind == CodeForCall) {</span>
3803         insertChecks();
3804 
3805         Node* resultNode;
3806 
3807         if (argumentCountIncludingThis &lt;= 1)
3808             resultNode = addToGraph(NewSymbol);
3809         else
<span class="line-modified">3810             resultNode = addToGraph(NewSymbol, addToGraph(ToString, get(virtualRegisterForArgument(1, registerOffset))));</span>
3811 
3812         set(result, resultNode);
3813         return true;
3814     }
3815 
3816     // FIXME: This should handle construction as well. https://bugs.webkit.org/show_bug.cgi?id=155591
<span class="line-modified">3817     if (function-&gt;classInfo() == ObjectConstructor::info() &amp;&amp; kind == CodeForCall) {</span>
3818         insertChecks();
3819 
3820         Node* resultNode;
3821         if (argumentCountIncludingThis &lt;= 1)
<span class="line-modified">3822             resultNode = addToGraph(NewObject, OpInfo(m_graph.registerStructure(function-&gt;globalObject(*m_vm)-&gt;objectStructureForObjectConstructor())));</span>
3823         else
<span class="line-modified">3824             resultNode = addToGraph(CallObjectConstructor, OpInfo(m_graph.freeze(function-&gt;globalObject(*m_vm))), OpInfo(prediction), get(virtualRegisterForArgument(1, registerOffset)));</span>
3825         set(result, resultNode);
3826         return true;
3827     }
3828 
3829     for (unsigned typeIndex = 0; typeIndex &lt; NumberOfTypedArrayTypes; ++typeIndex) {
3830         bool handled = handleTypedArrayConstructor(
3831             result, function, registerOffset, argumentCountIncludingThis,
3832             indexToTypedArrayType(typeIndex), insertChecks);
3833         if (handled)
3834             return true;
3835     }
3836 
3837     return false;
3838 }
3839 
3840 Node* ByteCodeParser::handleGetByOffset(
3841     SpeculatedType prediction, Node* base, unsigned identifierNumber, PropertyOffset offset, NodeType op)
3842 {
3843     Node* propertyStorage;
3844     if (isInlineOffset(offset))
</pre>
<hr />
<pre>
4144 Node* ByteCodeParser::load(
4145     SpeculatedType prediction, Node* base, unsigned identifierNumber, const VariantType&amp; variant)
4146 {
4147     // Make sure backwards propagation knows that we&#39;ve used base.
4148     addToGraph(Phantom, base);
4149 
4150     bool needStructureCheck = true;
4151 
4152     UniquedStringImpl* uid = m_graph.identifiers()[identifierNumber];
4153 
4154     if (JSObject* knownBase = base-&gt;dynamicCastConstant&lt;JSObject*&gt;(*m_vm)) {
4155         // Try to optimize away the structure check. Note that it&#39;s not worth doing anything about this
4156         // if the base&#39;s structure is watched.
4157         Structure* structure = base-&gt;constant()-&gt;structure();
4158         if (!structure-&gt;dfgShouldWatch()) {
4159             if (!variant.conditionSet().isEmpty()) {
4160                 // This means that we&#39;re loading from a prototype or we have a property miss. We expect
4161                 // the base not to have the property. We can only use ObjectPropertyCondition if all of
4162                 // the structures in the variant.structureSet() agree on the prototype (it would be
4163                 // hilariously rare if they didn&#39;t). Note that we are relying on structureSet() having
<span class="line-modified">4164                 // at least one element. That will always be true here because of how GetByIdStatus/PutByIdStatus work.</span>
4165 
4166                 // FIXME: right now, if we have an OPCS, we have mono proto. However, this will
4167                 // need to be changed in the future once we have a hybrid data structure for
4168                 // poly proto:
4169                 // https://bugs.webkit.org/show_bug.cgi?id=177339
4170                 JSObject* prototype = variant.structureSet()[0]-&gt;storedPrototypeObject();
4171                 bool allAgree = true;
4172                 for (unsigned i = 1; i &lt; variant.structureSet().size(); ++i) {
4173                     if (variant.structureSet()[i]-&gt;storedPrototypeObject() != prototype) {
4174                         allAgree = false;
4175                         break;
4176                     }
4177                 }
4178                 if (allAgree) {
4179                     ObjectPropertyCondition condition = ObjectPropertyCondition::absenceWithoutBarrier(
4180                         knownBase, uid, prototype);
4181                     if (check(condition))
4182                         needStructureCheck = false;
4183                 }
4184             } else {
</pre>
<hr />
<pre>
4233                 return weakJSConstant(constant);
4234         }
4235 
4236         loadedValue = handleGetByOffset(
4237             loadPrediction, base, identifierNumber, variant.offset(), loadOp);
4238     }
4239 
4240     return loadedValue;
4241 }
4242 
4243 Node* ByteCodeParser::store(Node* base, unsigned identifier, const PutByIdVariant&amp; variant, Node* value)
4244 {
4245     RELEASE_ASSERT(variant.kind() == PutByIdVariant::Replace);
4246 
4247     checkPresenceLike(base, m_graph.identifiers()[identifier], variant.offset(), variant.structure());
4248     return handlePutByOffset(base, identifier, variant.offset(), value);
4249 }
4250 
4251 void ByteCodeParser::handleGetById(
4252     VirtualRegister destination, SpeculatedType prediction, Node* base, unsigned identifierNumber,
<span class="line-modified">4253     GetByIdStatus getByIdStatus, AccessType type, unsigned instructionSize)</span>
4254 {
<span class="line-modified">4255     // Attempt to reduce the set of things in the GetByIdStatus.</span>
4256     if (base-&gt;op() == NewObject) {
4257         bool ok = true;
4258         for (unsigned i = m_currentBlock-&gt;size(); i--;) {
4259             Node* node = m_currentBlock-&gt;at(i);
4260             if (node == base)
4261                 break;
4262             if (writesOverlap(m_graph, node, JSCell_structureID)) {
4263                 ok = false;
4264                 break;
4265             }
4266         }
4267         if (ok)
<span class="line-modified">4268             getByIdStatus.filter(base-&gt;structure().get());</span>
4269     }
4270 
4271     NodeType getById;
<span class="line-modified">4272     if (type == AccessType::Get)</span>
<span class="line-modified">4273         getById = getByIdStatus.makesCalls() ? GetByIdFlush : GetById;</span>
<span class="line-modified">4274     else if (type == AccessType::TryGet)</span>
4275         getById = TryGetById;
4276     else
<span class="line-modified">4277         getById = getByIdStatus.makesCalls() ? GetByIdDirectFlush : GetByIdDirect;</span>
4278 
<span class="line-modified">4279     if (getById != TryGetById &amp;&amp; getByIdStatus.isModuleNamespace()) {</span>
<span class="line-modified">4280         if (handleModuleNamespaceLoad(destination, prediction, base, getByIdStatus)) {</span>
4281             if (UNLIKELY(m_graph.compilation()))
4282                 m_graph.compilation()-&gt;noticeInlinedGetById();
4283             return;
4284         }
4285     }
4286 
4287     // Special path for custom accessors since custom&#39;s offset does not have any meanings.
4288     // So, this is completely different from Simple one. But we have a chance to optimize it when we use DOMJIT.
<span class="line-modified">4289     if (Options::useDOMJIT() &amp;&amp; getByIdStatus.isCustom()) {</span>
<span class="line-modified">4290         ASSERT(getByIdStatus.numVariants() == 1);</span>
<span class="line-modified">4291         ASSERT(!getByIdStatus.makesCalls());</span>
<span class="line-modified">4292         GetByIdVariant variant = getByIdStatus[0];</span>
4293         ASSERT(variant.domAttribute());
4294         if (handleDOMJITGetter(destination, variant, base, identifierNumber, prediction)) {
4295             if (UNLIKELY(m_graph.compilation()))
4296                 m_graph.compilation()-&gt;noticeInlinedGetById();
4297             return;
4298         }
4299     }
4300 
<span class="line-modified">4301     ASSERT(type == AccessType::Get || type == AccessType::GetDirect ||  !getByIdStatus.makesCalls());</span>
<span class="line-modified">4302     if (!getByIdStatus.isSimple() || !getByIdStatus.numVariants() || !Options::useAccessInlining()) {</span>
4303         set(destination,
4304             addToGraph(getById, OpInfo(identifierNumber), OpInfo(prediction), base));
4305         return;
4306     }
4307 
<span class="line-modified">4308     // FIXME: If we use the GetByIdStatus for anything then we should record it and insert a node</span>
4309     // after everything else (like the GetByOffset or whatever) that will filter the recorded
<span class="line-modified">4310     // GetByIdStatus. That means that the constant folder also needs to do the same!</span>
4311 
<span class="line-modified">4312     if (getByIdStatus.numVariants() &gt; 1) {</span>
<span class="line-modified">4313         if (getByIdStatus.makesCalls() || !m_graph.m_plan.isFTL()</span>
4314             || !Options::usePolymorphicAccessInlining()
<span class="line-modified">4315             || getByIdStatus.numVariants() &gt; Options::maxPolymorphicAccessInliningListSize()) {</span>
4316             set(destination,
4317                 addToGraph(getById, OpInfo(identifierNumber), OpInfo(prediction), base));
4318             return;
4319         }
4320 
<span class="line-modified">4321         addToGraph(FilterGetByIdStatus, OpInfo(m_graph.m_plan.recordedStatuses().addGetByIdStatus(currentCodeOrigin(), getByIdStatus)), base);</span>
4322 
4323         Vector&lt;MultiGetByOffsetCase, 2&gt; cases;
4324 
4325         // 1) Emit prototype structure checks for all chains. This could sort of maybe not be
4326         //    optimal, if there is some rarely executed case in the chain that requires a lot
4327         //    of checks and those checks are not watchpointable.
<span class="line-modified">4328         for (const GetByIdVariant&amp; variant : getByIdStatus.variants()) {</span>
4329             if (variant.intrinsic() != NoIntrinsic) {
4330                 set(destination,
4331                     addToGraph(getById, OpInfo(identifierNumber), OpInfo(prediction), base));
4332                 return;
4333             }
4334 
4335             if (variant.conditionSet().isEmpty()) {
4336                 cases.append(
4337                     MultiGetByOffsetCase(
4338                         *m_graph.addStructureSet(variant.structureSet()),
4339                         GetByOffsetMethod::load(variant.offset())));
4340                 continue;
4341             }
4342 
4343             GetByOffsetMethod method = planLoad(variant.conditionSet());
4344             if (!method) {
4345                 set(destination,
4346                     addToGraph(getById, OpInfo(identifierNumber), OpInfo(prediction), base));
4347                 return;
4348             }
4349 
4350             cases.append(MultiGetByOffsetCase(*m_graph.addStructureSet(variant.structureSet()), method));
4351         }
4352 
4353         if (UNLIKELY(m_graph.compilation()))
4354             m_graph.compilation()-&gt;noticeInlinedGetById();
4355 
4356         // 2) Emit a MultiGetByOffset
4357         MultiGetByOffsetData* data = m_graph.m_multiGetByOffsetData.add();
4358         data-&gt;cases = cases;
4359         data-&gt;identifierNumber = identifierNumber;
4360         set(destination,
4361             addToGraph(MultiGetByOffset, OpInfo(data), OpInfo(prediction), base));
4362         return;
4363     }
4364 
<span class="line-modified">4365     addToGraph(FilterGetByIdStatus, OpInfo(m_graph.m_plan.recordedStatuses().addGetByIdStatus(currentCodeOrigin(), getByIdStatus)), base);</span>
4366 
<span class="line-modified">4367     ASSERT(getByIdStatus.numVariants() == 1);</span>
<span class="line-modified">4368     GetByIdVariant variant = getByIdStatus[0];</span>
4369 
4370     Node* loadedValue = load(prediction, base, identifierNumber, variant);
4371     if (!loadedValue) {
4372         set(destination,
4373             addToGraph(getById, OpInfo(identifierNumber), OpInfo(prediction), base));
4374         return;
4375     }
4376 
4377     if (UNLIKELY(m_graph.compilation()))
4378         m_graph.compilation()-&gt;noticeInlinedGetById();
4379 
<span class="line-modified">4380     ASSERT(type == AccessType::Get || type == AccessType::GetDirect || !variant.callLinkStatus());</span>
4381     if (!variant.callLinkStatus() &amp;&amp; variant.intrinsic() == NoIntrinsic) {
4382         set(destination, loadedValue);
4383         return;
4384     }
4385 
4386     Node* getter = addToGraph(GetGetter, loadedValue);
4387 
4388     if (handleIntrinsicGetter(destination, prediction, variant, base,
4389             [&amp;] () {
4390                 addToGraph(CheckCell, OpInfo(m_graph.freeze(variant.intrinsicFunction())), getter);
4391             })) {
4392         addToGraph(Phantom, base);
4393         return;
4394     }
4395 
4396     ASSERT(variant.intrinsic() == NoIntrinsic);
4397 
4398     // Make a call. We don&#39;t try to get fancy with using the smallest operand number because
4399     // the stack layout phase should compress the stack anyway.
4400 
</pre>
<hr />
<pre>
4406     int registerOffset = virtualRegisterForLocal(
4407         m_inlineStackTop-&gt;m_profiledBlock-&gt;numCalleeLocals() - 1).offset();
4408     registerOffset -= numberOfParameters;
4409     registerOffset -= CallFrame::headerSizeInRegisters;
4410 
4411     // Get the alignment right.
4412     registerOffset = -WTF::roundUpToMultipleOf(
4413         stackAlignmentRegisters(),
4414         -registerOffset);
4415 
4416     ensureLocals(
4417         m_inlineStackTop-&gt;remapOperand(
4418             VirtualRegister(registerOffset)).toLocal());
4419 
4420     // Issue SetLocals. This has two effects:
4421     // 1) That&#39;s how handleCall() sees the arguments.
4422     // 2) If we inline then this ensures that the arguments are flushed so that if you use
4423     //    the dreaded arguments object on the getter, the right things happen. Well, sort of -
4424     //    since we only really care about &#39;this&#39; in this case. But we&#39;re not going to take that
4425     //    shortcut.
<span class="line-modified">4426     set(virtualRegisterForArgument(0, registerOffset), base, ImmediateNakedSet);</span>
4427 
4428     // We&#39;ve set some locals, but they are not user-visible. It&#39;s still OK to exit from here.
4429     m_exitOK = true;
4430     addToGraph(ExitOK);
4431 
4432     handleCall(
4433         destination, Call, InlineCallFrame::GetterCall, instructionSize,
4434         getter, numberOfParameters - 1, registerOffset, *variant.callLinkStatus(), prediction);
4435 }
4436 
4437 void ByteCodeParser::emitPutById(
4438     Node* base, unsigned identifierNumber, Node* value, const PutByIdStatus&amp; putByIdStatus, bool isDirect)
4439 {
4440     if (isDirect)
4441         addToGraph(PutByIdDirect, OpInfo(identifierNumber), base, value);
4442     else
4443         addToGraph(putByIdStatus.makesCalls() ? PutByIdFlush : PutById, OpInfo(identifierNumber), base, value);
4444 }
4445 
4446 void ByteCodeParser::handlePutById(
</pre>
<hr />
<pre>
4589         unsigned numberOfParameters = 0;
4590         numberOfParameters++; // The &#39;this&#39; argument.
4591         numberOfParameters++; // The new value.
4592         numberOfParameters++; // True return PC.
4593 
4594         // Start with a register offset that corresponds to the last in-use register.
4595         int registerOffset = virtualRegisterForLocal(
4596             m_inlineStackTop-&gt;m_profiledBlock-&gt;numCalleeLocals() - 1).offset();
4597         registerOffset -= numberOfParameters;
4598         registerOffset -= CallFrame::headerSizeInRegisters;
4599 
4600         // Get the alignment right.
4601         registerOffset = -WTF::roundUpToMultipleOf(
4602             stackAlignmentRegisters(),
4603             -registerOffset);
4604 
4605         ensureLocals(
4606             m_inlineStackTop-&gt;remapOperand(
4607                 VirtualRegister(registerOffset)).toLocal());
4608 
<span class="line-modified">4609         set(virtualRegisterForArgument(0, registerOffset), base, ImmediateNakedSet);</span>
<span class="line-modified">4610         set(virtualRegisterForArgument(1, registerOffset), value, ImmediateNakedSet);</span>
4611 
4612         // We&#39;ve set some locals, but they are not user-visible. It&#39;s still OK to exit from here.
4613         m_exitOK = true;
4614         addToGraph(ExitOK);
4615 
4616         handleCall(
4617             VirtualRegister(), Call, InlineCallFrame::SetterCall,
4618             instructionSize, setter, numberOfParameters - 1, registerOffset,
4619             *variant.callLinkStatus(), SpecOther);
4620         return;
4621     }
4622 
4623     default: {
4624         emitPutById(base, identifierNumber, value, putByIdStatus, isDirect);
4625         return;
4626     } }
4627 }
4628 
4629 void ByteCodeParser::prepareToParseBlock()
4630 {
4631     clearCaches();
4632     ASSERT(m_setLocalQueue.isEmpty());
4633 }
4634 
4635 void ByteCodeParser::clearCaches()
4636 {
4637     m_constants.shrink(0);
4638 }
4639 
4640 template&lt;typename Op&gt;
4641 void ByteCodeParser::parseGetById(const Instruction* currentInstruction)
4642 {
4643     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
4644     SpeculatedType prediction = getPrediction();
4645 
4646     Node* base = get(bytecode.m_base);
4647     unsigned identifierNumber = m_inlineStackTop-&gt;m_identifierRemap[bytecode.m_property];
4648 
<span class="line-modified">4649     UniquedStringImpl* uid = m_graph.identifiers()[identifierNumber];</span>
<span class="line-removed">4650     GetByIdStatus getByIdStatus = GetByIdStatus::computeFor(</span>
<span class="line-removed">4651         m_inlineStackTop-&gt;m_profiledBlock,</span>
<span class="line-removed">4652         m_inlineStackTop-&gt;m_baselineMap, m_icContextStack,</span>
<span class="line-removed">4653         currentCodeOrigin(), uid);</span>
<span class="line-removed">4654 </span>
<span class="line-removed">4655     AccessType type = AccessType::Get;</span>
4656     unsigned opcodeLength = currentInstruction-&gt;size();
4657     if (Op::opcodeID == op_try_get_by_id)
<span class="line-modified">4658         type = AccessType::TryGet;</span>
4659     else if (Op::opcodeID == op_get_by_id_direct)
<span class="line-modified">4660         type = AccessType::GetDirect;</span>
4661 
<span class="line-modified">4662     handleGetById(</span>
<span class="line-modified">4663         bytecode.m_dst, prediction, base, identifierNumber, getByIdStatus, type, opcodeLength);</span>


4664 


4665 }
4666 
4667 static uint64_t makeDynamicVarOpInfo(unsigned identifierNumber, unsigned getPutInfo)
4668 {
4669     static_assert(sizeof(identifierNumber) == 4,
4670         &quot;We cannot fit identifierNumber into the high bits of m_opInfo&quot;);
4671     return static_cast&lt;uint64_t&gt;(identifierNumber) | (static_cast&lt;uint64_t&gt;(getPutInfo) &lt;&lt; 32);
4672 }
4673 
4674 // The idiom:
4675 //     if (true) { ...; goto label; } else label: continue
4676 // Allows using NEXT_OPCODE as a statement, even in unbraced if+else, while containing a `continue`.
4677 // The more common idiom:
4678 //     do { ...; } while (false)
4679 // Doesn&#39;t allow using `continue`.
4680 #define NEXT_OPCODE(name) \
4681     if (true) { \
<span class="line-modified">4682         m_currentIndex += currentInstruction-&gt;size(); \</span>
4683         goto WTF_CONCAT(NEXT_OPCODE_, __LINE__); /* Need a unique label: usable more than once per function. */ \
4684     } else \
4685         WTF_CONCAT(NEXT_OPCODE_, __LINE__): \
4686     continue
4687 
4688 #define LAST_OPCODE_LINKED(name) do { \
<span class="line-modified">4689         m_currentIndex += currentInstruction-&gt;size(); \</span>
4690         m_exitOK = false; \
4691         return; \
4692     } while (false)
4693 
4694 #define LAST_OPCODE(name) \
4695     do { \
4696         if (m_currentBlock-&gt;terminal()) { \
4697             switch (m_currentBlock-&gt;terminal()-&gt;op()) { \
4698             case Jump: \
4699             case Branch: \
4700             case Switch: \
4701                 ASSERT(!m_currentBlock-&gt;isLinked); \
4702                 m_inlineStackTop-&gt;m_unlinkedBlocks.append(m_currentBlock); \
4703                 break;\
4704             default: break; \
4705             } \
4706         } \
4707         LAST_OPCODE_LINKED(name); \
4708     } while (false)
4709 
4710 void ByteCodeParser::parseBlock(unsigned limit)
4711 {
4712     auto&amp; instructions = m_inlineStackTop-&gt;m_codeBlock-&gt;instructions();
<span class="line-modified">4713     unsigned blockBegin = m_currentIndex;</span>
4714 
4715     // If we are the first basic block, introduce markers for arguments. This allows
4716     // us to track if a use of an argument may use the actual argument passed, as
4717     // opposed to using a value we set explicitly.
4718     if (m_currentBlock == m_graph.block(0) &amp;&amp; !inlineCallFrame()) {
4719         auto addResult = m_graph.m_rootToArguments.add(m_currentBlock, ArgumentsVector());
4720         RELEASE_ASSERT(addResult.isNewEntry);
4721         ArgumentsVector&amp; entrypointArguments = addResult.iterator-&gt;value;
4722         entrypointArguments.resize(m_numArguments);
4723 
4724         // We will emit SetArgumentDefinitely nodes. They don&#39;t exit, but we&#39;re at the top of an op_enter so
4725         // exitOK = true.
4726         m_exitOK = true;
4727         for (unsigned argument = 0; argument &lt; m_numArguments; ++argument) {
4728             VariableAccessData* variable = newVariableAccessData(
<span class="line-modified">4729                 virtualRegisterForArgument(argument));</span>
4730             variable-&gt;mergeStructureCheckHoistingFailed(
4731                 m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCache));
4732             variable-&gt;mergeCheckArrayHoistingFailed(
4733                 m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadIndexingType));
4734 
4735             Node* setArgument = addToGraph(SetArgumentDefinitely, OpInfo(variable));
4736             entrypointArguments[argument] = setArgument;
4737             m_currentBlock-&gt;variablesAtTail.setArgumentFirstTime(argument, setArgument);
4738         }
4739     }
4740 
4741     CodeBlock* codeBlock = m_inlineStackTop-&gt;m_codeBlock;
4742 
4743     auto jumpTarget = [&amp;](int target) {
4744         if (target)
4745             return target;
4746         return codeBlock-&gt;outOfLineJumpOffset(m_currentInstruction);
4747     };
4748 
4749     while (true) {
4750         // We&#39;re staring at a new bytecode instruction. So we once again have a place that we can exit
4751         // to.
4752         m_exitOK = true;
4753 
4754         processSetLocalQueue();
4755 
4756         // Don&#39;t extend over jump destinations.
<span class="line-modified">4757         if (m_currentIndex == limit) {</span>
4758             // Ordinarily we want to plant a jump. But refuse to do this if the block is
4759             // empty. This is a special case for inlining, which might otherwise create
4760             // some empty blocks in some cases. When parseBlock() returns with an empty
4761             // block, it will get repurposed instead of creating a new one. Note that this
4762             // logic relies on every bytecode resulting in one or more nodes, which would
4763             // be true anyway except for op_loop_hint, which emits a Phantom to force this
4764             // to be true.
4765 
4766             if (!m_currentBlock-&gt;isEmpty())
<span class="line-modified">4767                 addJumpTo(m_currentIndex);</span>
4768             return;
4769         }
4770 
4771         // Switch on the current bytecode opcode.
4772         const Instruction* currentInstruction = instructions.at(m_currentIndex).ptr();
4773         m_currentInstruction = currentInstruction; // Some methods want to use this, and we&#39;d rather not thread it through calls.
4774         OpcodeID opcodeID = currentInstruction-&gt;opcodeID();
4775 
4776         VERBOSE_LOG(&quot;    parsing &quot;, currentCodeOrigin(), &quot;: &quot;, opcodeID, &quot;\n&quot;);
4777 
4778         if (UNLIKELY(m_graph.compilation())) {
4779             addToGraph(CountExecution, OpInfo(m_graph.compilation()-&gt;executionCounterFor(
4780                 Profiler::OriginStack(*m_vm-&gt;m_perBytecodeProfiler, m_codeBlock, currentCodeOrigin()))));
4781         }
4782 
4783         switch (opcodeID) {
4784 
4785         // === Function entry opcodes ===
4786 
4787         case op_enter: {
<span class="line-removed">4788             addToGraph(Options::usePollingTraps() ? CheckTraps : InvalidationPoint);</span>
4789             Node* undefined = addToGraph(JSConstant, OpInfo(m_constantUndefined));
4790             // Initialize all locals to undefined.
4791             for (int i = 0; i &lt; m_inlineStackTop-&gt;m_codeBlock-&gt;numVars(); ++i)
4792                 set(virtualRegisterForLocal(i), undefined, ImmediateNakedSet);

4793             NEXT_OPCODE(op_enter);
4794         }
4795 
4796         case op_to_this: {
4797             Node* op1 = getThis();
4798             auto&amp; metadata = currentInstruction-&gt;as&lt;OpToThis&gt;().metadata(codeBlock);
4799             StructureID cachedStructureID = metadata.m_cachedStructureID;
4800             Structure* cachedStructure = nullptr;
4801             if (cachedStructureID)
4802                 cachedStructure = m_vm-&gt;heap.structureIDTable().get(cachedStructureID);
4803             if (metadata.m_toThisStatus != ToThisOK
4804                 || !cachedStructure
4805                 || cachedStructure-&gt;classInfo()-&gt;methodTable.toThis != JSObject::info()-&gt;methodTable.toThis
4806                 || m_inlineStackTop-&gt;m_profiledBlock-&gt;couldTakeSlowCase(m_currentIndex)
4807                 || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCache)
4808                 || (op1-&gt;op() == GetLocal &amp;&amp; op1-&gt;variableAccessData()-&gt;structureCheckHoistingFailed())) {
4809                 setThis(addToGraph(ToThis, OpInfo(), OpInfo(getPrediction()), op1));
4810             } else {
4811                 addToGraph(
4812                     CheckStructure,
</pre>
<hr />
<pre>
4831                     FrozenValue* frozen = m_graph.freeze(cachedFunction);
4832                     addToGraph(CheckCell, OpInfo(frozen), callee);
4833 
4834                     function = static_cast&lt;JSFunction*&gt;(cachedFunction);
4835                 }
4836             }
4837 
4838             bool alreadyEmitted = false;
4839             if (function) {
4840                 if (FunctionRareData* rareData = function-&gt;rareData()) {
4841                     if (rareData-&gt;allocationProfileWatchpointSet().isStillValid()) {
4842                         Structure* structure = rareData-&gt;objectAllocationStructure();
4843                         JSObject* prototype = rareData-&gt;objectAllocationPrototype();
4844                         if (structure
4845                             &amp;&amp; (structure-&gt;hasMonoProto() || prototype)
4846                             &amp;&amp; rareData-&gt;allocationProfileWatchpointSet().isStillValid()) {
4847 
4848                             m_graph.freeze(rareData);
4849                             m_graph.watchpoints().addLazily(rareData-&gt;allocationProfileWatchpointSet());
4850 
<span class="line-removed">4851                             // The callee is still live up to this point.</span>
<span class="line-removed">4852                             addToGraph(Phantom, callee);</span>
4853                             Node* object = addToGraph(NewObject, OpInfo(m_graph.registerStructure(structure)));
4854                             if (structure-&gt;hasPolyProto()) {
4855                                 StorageAccessData* data = m_graph.m_storageAccessData.add();
4856                                 data-&gt;offset = knownPolyProtoOffset;
4857                                 data-&gt;identifierNumber = m_graph.identifiers().ensure(m_graph.m_vm.propertyNames-&gt;builtinNames().polyProtoName().impl());
4858                                 ASSERT(isInlineOffset(knownPolyProtoOffset));
4859                                 addToGraph(PutByOffset, OpInfo(data), object, object, weakJSConstant(prototype));
4860                             }
4861                             set(VirtualRegister(bytecode.m_dst), object);


4862                             alreadyEmitted = true;
4863                         }
4864                     }
4865                 }
4866             }
4867             if (!alreadyEmitted) {
4868                 set(VirtualRegister(bytecode.m_dst),
4869                     addToGraph(CreateThis, OpInfo(bytecode.m_inlineCapacity), callee));
4870             }
4871             NEXT_OPCODE(op_create_this);
4872         }
4873 

















































































4874         case op_new_object: {
4875             auto bytecode = currentInstruction-&gt;as&lt;OpNewObject&gt;();
4876             set(bytecode.m_dst,
4877                 addToGraph(NewObject,
4878                     OpInfo(m_graph.registerStructure(bytecode.metadata(codeBlock).m_objectAllocationProfile.structure()))));
4879             NEXT_OPCODE(op_new_object);
4880         }
4881 














4882         case op_new_array: {
4883             auto bytecode = currentInstruction-&gt;as&lt;OpNewArray&gt;();
4884             int startOperand = bytecode.m_argv.offset();
4885             int numOperands = bytecode.m_argc;
4886             ArrayAllocationProfile&amp; profile = bytecode.metadata(codeBlock).m_arrayAllocationProfile;
4887             for (int operandIdx = startOperand; operandIdx &gt; startOperand - numOperands; --operandIdx)
4888                 addVarArgChild(get(VirtualRegister(operandIdx)));
4889             unsigned vectorLengthHint = std::max&lt;unsigned&gt;(profile.vectorLengthHintConcurrently(), numOperands);
4890             set(bytecode.m_dst, addToGraph(Node::VarArg, NewArray, OpInfo(profile.selectIndexingTypeConcurrently()), OpInfo(vectorLengthHint)));
4891             NEXT_OPCODE(op_new_array);
4892         }
4893 
4894         case op_new_array_with_spread: {
4895             auto bytecode = currentInstruction-&gt;as&lt;OpNewArrayWithSpread&gt;();
4896             int startOperand = bytecode.m_argv.offset();
4897             int numOperands = bytecode.m_argc;
4898             const BitVector&amp; bitVector = m_inlineStackTop-&gt;m_profiledBlock-&gt;unlinkedCodeBlock()-&gt;bitVector(bytecode.m_bitVector);
4899             for (int operandIdx = startOperand; operandIdx &gt; startOperand - numOperands; --operandIdx)
4900                 addVarArgChild(get(VirtualRegister(operandIdx)));
4901 
</pre>
<hr />
<pre>
4923 
4924         case op_new_array_buffer: {
4925             auto bytecode = currentInstruction-&gt;as&lt;OpNewArrayBuffer&gt;();
4926             // Unfortunately, we can&#39;t allocate a new JSImmutableButterfly if the profile tells us new information because we
4927             // cannot allocate from compilation threads.
4928             WTF::loadLoadFence();
4929             FrozenValue* frozen = get(VirtualRegister(bytecode.m_immutableButterfly))-&gt;constant();
4930             WTF::loadLoadFence();
4931             JSImmutableButterfly* immutableButterfly = frozen-&gt;cast&lt;JSImmutableButterfly*&gt;();
4932             NewArrayBufferData data { };
4933             data.indexingMode = immutableButterfly-&gt;indexingMode();
4934             data.vectorLengthHint = immutableButterfly-&gt;toButterfly()-&gt;vectorLength();
4935 
4936             set(VirtualRegister(bytecode.m_dst), addToGraph(NewArrayBuffer, OpInfo(frozen), OpInfo(data.asQuadWord)));
4937             NEXT_OPCODE(op_new_array_buffer);
4938         }
4939 
4940         case op_new_regexp: {
4941             auto bytecode = currentInstruction-&gt;as&lt;OpNewRegexp&gt;();
4942             ASSERT(bytecode.m_regexp.isConstant());
<span class="line-modified">4943             FrozenValue* frozenRegExp = m_graph.freezeStrong(m_inlineStackTop-&gt;m_codeBlock-&gt;getConstant(bytecode.m_regexp.offset()));</span>
4944             set(bytecode.m_dst, addToGraph(NewRegexp, OpInfo(frozenRegExp), jsConstant(jsNumber(0))));
4945             NEXT_OPCODE(op_new_regexp);
4946         }
4947 
4948         case op_get_rest_length: {
4949             auto bytecode = currentInstruction-&gt;as&lt;OpGetRestLength&gt;();
4950             InlineCallFrame* inlineCallFrame = this-&gt;inlineCallFrame();
4951             Node* length;
4952             if (inlineCallFrame &amp;&amp; !inlineCallFrame-&gt;isVarargs()) {
4953                 unsigned argumentsLength = inlineCallFrame-&gt;argumentCountIncludingThis - 1;
4954                 JSValue restLength;
4955                 if (argumentsLength &lt;= bytecode.m_numParametersToSkip)
4956                     restLength = jsNumber(0);
4957                 else
4958                     restLength = jsNumber(argumentsLength - bytecode.m_numParametersToSkip);
4959 
4960                 length = jsConstant(restLength);
4961             } else
4962                 length = addToGraph(GetRestLength, OpInfo(bytecode.m_numParametersToSkip));
4963             set(bytecode.m_dst, length);
</pre>
<hr />
<pre>
5009                 set(bytecode.m_dst, addToGraph(ValueBitOr, OpInfo(), OpInfo(prediction), op1, op2));
5010             NEXT_OPCODE(op_bitor);
5011         }
5012 
5013         case op_bitxor: {
5014             auto bytecode = currentInstruction-&gt;as&lt;OpBitxor&gt;();
5015             SpeculatedType prediction = getPrediction();
5016             Node* op1 = get(bytecode.m_lhs);
5017             Node* op2 = get(bytecode.m_rhs);
5018             if (op1-&gt;hasNumberOrAnyIntResult() &amp;&amp; op2-&gt;hasNumberOrAnyIntResult())
5019                 set(bytecode.m_dst, addToGraph(ArithBitXor, op1, op2));
5020             else
5021                 set(bytecode.m_dst, addToGraph(ValueBitXor, OpInfo(), OpInfo(prediction), op1, op2));
5022             NEXT_OPCODE(op_bitxor);
5023         }
5024 
5025         case op_rshift: {
5026             auto bytecode = currentInstruction-&gt;as&lt;OpRshift&gt;();
5027             Node* op1 = get(bytecode.m_lhs);
5028             Node* op2 = get(bytecode.m_rhs);
<span class="line-modified">5029             set(bytecode.m_dst, addToGraph(BitRShift, op1, op2));</span>





5030             NEXT_OPCODE(op_rshift);
5031         }
5032 
5033         case op_lshift: {
5034             auto bytecode = currentInstruction-&gt;as&lt;OpLshift&gt;();
5035             Node* op1 = get(bytecode.m_lhs);
5036             Node* op2 = get(bytecode.m_rhs);
5037             if (op1-&gt;hasNumberOrAnyIntResult() &amp;&amp; op2-&gt;hasNumberOrAnyIntResult())
5038                 set(bytecode.m_dst, addToGraph(ArithBitLShift, op1, op2));
5039             else {
5040                 SpeculatedType prediction = getPredictionWithoutOSRExit();
5041                 set(bytecode.m_dst, addToGraph(ValueBitLShift, OpInfo(), OpInfo(prediction), op1, op2));
5042             }
5043             NEXT_OPCODE(op_lshift);
5044         }
5045 
5046         case op_urshift: {
5047             auto bytecode = currentInstruction-&gt;as&lt;OpUrshift&gt;();
5048             Node* op1 = get(bytecode.m_lhs);
5049             Node* op2 = get(bytecode.m_rhs);
5050             set(bytecode.m_dst, addToGraph(BitURShift, op1, op2));
5051             NEXT_OPCODE(op_urshift);
5052         }
5053 
5054         case op_unsigned: {
5055             auto bytecode = currentInstruction-&gt;as&lt;OpUnsigned&gt;();
5056             set(bytecode.m_dst, makeSafe(addToGraph(UInt32ToNumber, get(bytecode.m_operand))));
5057             NEXT_OPCODE(op_unsigned);
5058         }
5059 
5060         // === Increment/Decrement opcodes ===
5061 
5062         case op_inc: {
5063             auto bytecode = currentInstruction-&gt;as&lt;OpInc&gt;();
5064             Node* op = get(bytecode.m_srcDst);
<span class="line-modified">5065             set(bytecode.m_srcDst, makeSafe(addToGraph(ArithAdd, op, addToGraph(JSConstant, OpInfo(m_constantOne)))));</span>



5066             NEXT_OPCODE(op_inc);
5067         }
5068 
5069         case op_dec: {
5070             auto bytecode = currentInstruction-&gt;as&lt;OpDec&gt;();
5071             Node* op = get(bytecode.m_srcDst);
<span class="line-modified">5072             set(bytecode.m_srcDst, makeSafe(addToGraph(ArithSub, op, addToGraph(JSConstant, OpInfo(m_constantOne)))));</span>



5073             NEXT_OPCODE(op_dec);
5074         }
5075 
5076         // === Arithmetic operations ===
5077 
5078         case op_add: {
5079             auto bytecode = currentInstruction-&gt;as&lt;OpAdd&gt;();
5080             Node* op1 = get(bytecode.m_lhs);
5081             Node* op2 = get(bytecode.m_rhs);
5082             if (op1-&gt;hasNumberResult() &amp;&amp; op2-&gt;hasNumberResult())
5083                 set(bytecode.m_dst, makeSafe(addToGraph(ArithAdd, op1, op2)));
5084             else
5085                 set(bytecode.m_dst, makeSafe(addToGraph(ValueAdd, op1, op2)));
5086             NEXT_OPCODE(op_add);
5087         }
5088 
5089         case op_sub: {
5090             auto bytecode = currentInstruction-&gt;as&lt;OpSub&gt;();
5091             Node* op1 = get(bytecode.m_lhs);
5092             Node* op2 = get(bytecode.m_rhs);
</pre>
<hr />
<pre>
5304             auto bytecode = currentInstruction-&gt;as&lt;OpIsFunction&gt;();
5305             Node* value = get(bytecode.m_operand);
5306             set(bytecode.m_dst, addToGraph(IsFunction, value));
5307             NEXT_OPCODE(op_is_function);
5308         }
5309 
5310         case op_not: {
5311             auto bytecode = currentInstruction-&gt;as&lt;OpNot&gt;();
5312             Node* value = get(bytecode.m_operand);
5313             set(bytecode.m_dst, addToGraph(LogicalNot, value));
5314             NEXT_OPCODE(op_not);
5315         }
5316 
5317         case op_to_primitive: {
5318             auto bytecode = currentInstruction-&gt;as&lt;OpToPrimitive&gt;();
5319             Node* value = get(bytecode.m_src);
5320             set(bytecode.m_dst, addToGraph(ToPrimitive, value));
5321             NEXT_OPCODE(op_to_primitive);
5322         }
5323 







5324         case op_strcat: {
5325             auto bytecode = currentInstruction-&gt;as&lt;OpStrcat&gt;();
5326             int startOperand = bytecode.m_src.offset();
5327             int numOperands = bytecode.m_count;
<span class="line-removed">5328 #if CPU(X86)</span>
<span class="line-removed">5329             // X86 doesn&#39;t have enough registers to compile MakeRope with three arguments. The</span>
<span class="line-removed">5330             // StrCat we emit here may be turned into a MakeRope. Rather than try to be clever,</span>
<span class="line-removed">5331             // we just make StrCat dumber on this processor.</span>
<span class="line-removed">5332             const unsigned maxArguments = 2;</span>
<span class="line-removed">5333 #else</span>
5334             const unsigned maxArguments = 3;
<span class="line-removed">5335 #endif</span>
5336             Node* operands[AdjacencyList::Size];
5337             unsigned indexInOperands = 0;
5338             for (unsigned i = 0; i &lt; AdjacencyList::Size; ++i)
5339                 operands[i] = 0;
5340             for (int operandIdx = 0; operandIdx &lt; numOperands; ++operandIdx) {
5341                 if (indexInOperands == maxArguments) {
5342                     operands[0] = addToGraph(StrCat, operands[0], operands[1], operands[2]);
5343                     for (unsigned i = 1; i &lt; AdjacencyList::Size; ++i)
5344                         operands[i] = 0;
5345                     indexInOperands = 1;
5346                 }
5347 
5348                 ASSERT(indexInOperands &lt; AdjacencyList::Size);
5349                 ASSERT(indexInOperands &lt; maxArguments);
5350                 operands[indexInOperands++] = get(VirtualRegister(startOperand - operandIdx));
5351             }
5352             set(bytecode.m_dst, addToGraph(StrCat, operands[0], operands[1], operands[2]));
5353             NEXT_OPCODE(op_strcat);
5354         }
5355 
</pre>
<hr />
<pre>
5442         }
5443 
5444         case op_nstricteq: {
5445             auto bytecode = currentInstruction-&gt;as&lt;OpNstricteq&gt;();
5446             Node* op1 = get(bytecode.m_lhs);
5447             Node* op2 = get(bytecode.m_rhs);
5448             Node* invertedResult;
5449             invertedResult = addToGraph(CompareStrictEq, op1, op2);
5450             set(bytecode.m_dst, addToGraph(LogicalNot, invertedResult));
5451             NEXT_OPCODE(op_nstricteq);
5452         }
5453 
5454         // === Property access operations ===
5455 
5456         case op_get_by_val: {
5457             auto bytecode = currentInstruction-&gt;as&lt;OpGetByVal&gt;();
5458             SpeculatedType prediction = getPredictionWithoutOSRExit();
5459 
5460             Node* base = get(bytecode.m_base);
5461             Node* property = get(bytecode.m_property);
<span class="line-modified">5462             bool compiledAsGetById = false;</span>
<span class="line-modified">5463             GetByIdStatus getByIdStatus;</span>

5464             unsigned identifierNumber = 0;
<span class="line-removed">5465             {</span>
<span class="line-removed">5466                 ConcurrentJSLocker locker(m_inlineStackTop-&gt;m_profiledBlock-&gt;m_lock);</span>
<span class="line-removed">5467                 ByValInfo* byValInfo = m_inlineStackTop-&gt;m_baselineMap.get(CodeOrigin(currentCodeOrigin().bytecodeIndex())).byValInfo;</span>
<span class="line-removed">5468                 // FIXME: When the bytecode is not compiled in the baseline JIT, byValInfo becomes null.</span>
<span class="line-removed">5469                 // At that time, there is no information.</span>
<span class="line-removed">5470                 if (byValInfo</span>
<span class="line-removed">5471                     &amp;&amp; byValInfo-&gt;stubInfo</span>
<span class="line-removed">5472                     &amp;&amp; !byValInfo-&gt;tookSlowPath</span>
<span class="line-removed">5473                     &amp;&amp; !m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadIdent)</span>
<span class="line-removed">5474                     &amp;&amp; !m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType)</span>
<span class="line-removed">5475                     &amp;&amp; !m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell)) {</span>
<span class="line-removed">5476                     compiledAsGetById = true;</span>
<span class="line-removed">5477                     identifierNumber = m_graph.identifiers().ensure(byValInfo-&gt;cachedId.impl());</span>
<span class="line-removed">5478                     UniquedStringImpl* uid = m_graph.identifiers()[identifierNumber];</span>
<span class="line-removed">5479 </span>
<span class="line-removed">5480                     if (Symbol* symbol = byValInfo-&gt;cachedSymbol.get()) {</span>
<span class="line-removed">5481                         FrozenValue* frozen = m_graph.freezeStrong(symbol);</span>
<span class="line-removed">5482                         addToGraph(CheckCell, OpInfo(frozen), property);</span>
<span class="line-removed">5483                     } else {</span>
<span class="line-removed">5484                         ASSERT(!uid-&gt;isSymbol());</span>
<span class="line-removed">5485                         addToGraph(CheckStringIdent, OpInfo(uid), property);</span>
<span class="line-removed">5486                     }</span>
5487 
<span class="line-modified">5488                     getByIdStatus = GetByIdStatus::computeForStubInfo(</span>
<span class="line-modified">5489                         locker, m_inlineStackTop-&gt;m_profiledBlock,</span>
<span class="line-modified">5490                         byValInfo-&gt;stubInfo, currentCodeOrigin(), uid);</span>
















5491                 }
5492             }
5493 
<span class="line-modified">5494             if (compiledAsGetById)</span>
<span class="line-modified">5495                 handleGetById(bytecode.m_dst, prediction, base, identifierNumber, getByIdStatus, AccessType::Get, currentInstruction-&gt;size());</span>
5496             else {
5497                 ArrayMode arrayMode = getArrayMode(bytecode.metadata(codeBlock).m_arrayProfile, Array::Read);
5498                 // FIXME: We could consider making this not vararg, since it only uses three child
5499                 // slots.
5500                 // https://bugs.webkit.org/show_bug.cgi?id=184192
5501                 addVarArgChild(base);
5502                 addVarArgChild(property);
5503                 addVarArgChild(0); // Leave room for property storage.
5504                 Node* getByVal = addToGraph(Node::VarArg, GetByVal, OpInfo(arrayMode.asWord()), OpInfo(prediction));
5505                 m_exitOK = false; // GetByVal must be treated as if it clobbers exit state, since FixupPhase may make it generic.
5506                 set(bytecode.m_dst, getByVal);


5507             }
5508 
5509             NEXT_OPCODE(op_get_by_val);
5510         }
5511 
5512         case op_get_by_val_with_this: {
5513             auto bytecode = currentInstruction-&gt;as&lt;OpGetByValWithThis&gt;();
5514             SpeculatedType prediction = getPrediction();
5515 
5516             Node* base = get(bytecode.m_base);
5517             Node* thisValue = get(bytecode.m_thisValue);
5518             Node* property = get(bytecode.m_property);
5519             Node* getByValWithThis = addToGraph(GetByValWithThis, OpInfo(), OpInfo(prediction), base, thisValue, property);
5520             set(bytecode.m_dst, getByValWithThis);
5521 
5522             NEXT_OPCODE(op_get_by_val_with_this);
5523         }
5524 
5525         case op_put_by_val_direct:
5526             handlePutByVal(currentInstruction-&gt;as&lt;OpPutByValDirect&gt;(), currentInstruction-&gt;size());
</pre>
<hr />
<pre>
5679             auto bytecode = currentInstruction-&gt;as&lt;OpProfileType&gt;();
5680             auto&amp; metadata = bytecode.metadata(codeBlock);
5681             Node* valueToProfile = get(bytecode.m_targetVirtualRegister);
5682             addToGraph(ProfileType, OpInfo(metadata.m_typeLocation), valueToProfile);
5683             NEXT_OPCODE(op_profile_type);
5684         }
5685 
5686         case op_profile_control_flow: {
5687             auto bytecode = currentInstruction-&gt;as&lt;OpProfileControlFlow&gt;();
5688             BasicBlockLocation* basicBlockLocation = bytecode.metadata(codeBlock).m_basicBlockLocation;
5689             addToGraph(ProfileControlFlow, OpInfo(basicBlockLocation));
5690             NEXT_OPCODE(op_profile_control_flow);
5691         }
5692 
5693         // === Block terminators. ===
5694 
5695         case op_jmp: {
5696             ASSERT(!m_currentBlock-&gt;terminal());
5697             auto bytecode = currentInstruction-&gt;as&lt;OpJmp&gt;();
5698             int relativeOffset = jumpTarget(bytecode.m_targetLabel);
<span class="line-modified">5699             addToGraph(Jump, OpInfo(m_currentIndex + relativeOffset));</span>
5700             if (relativeOffset &lt;= 0)
5701                 flushForTerminal();
5702             LAST_OPCODE(op_jmp);
5703         }
5704 
5705         case op_jtrue: {
5706             auto bytecode = currentInstruction-&gt;as&lt;OpJtrue&gt;();
5707             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5708             Node* condition = get(bytecode.m_condition);
<span class="line-modified">5709             addToGraph(Branch, OpInfo(branchData(m_currentIndex + relativeOffset, m_currentIndex + currentInstruction-&gt;size())), condition);</span>
5710             LAST_OPCODE(op_jtrue);
5711         }
5712 
5713         case op_jfalse: {
5714             auto bytecode = currentInstruction-&gt;as&lt;OpJfalse&gt;();
5715             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5716             Node* condition = get(bytecode.m_condition);
<span class="line-modified">5717             addToGraph(Branch, OpInfo(branchData(m_currentIndex + currentInstruction-&gt;size(), m_currentIndex + relativeOffset)), condition);</span>
5718             LAST_OPCODE(op_jfalse);
5719         }
5720 
5721         case op_jeq_null: {
5722             auto bytecode = currentInstruction-&gt;as&lt;OpJeqNull&gt;();
5723             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5724             Node* value = get(bytecode.m_value);
5725             Node* nullConstant = addToGraph(JSConstant, OpInfo(m_constantNull));
5726             Node* condition = addToGraph(CompareEq, value, nullConstant);
<span class="line-modified">5727             addToGraph(Branch, OpInfo(branchData(m_currentIndex + relativeOffset, m_currentIndex + currentInstruction-&gt;size())), condition);</span>
5728             LAST_OPCODE(op_jeq_null);
5729         }
5730 
5731         case op_jneq_null: {
5732             auto bytecode = currentInstruction-&gt;as&lt;OpJneqNull&gt;();
5733             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5734             Node* value = get(bytecode.m_value);
5735             Node* nullConstant = addToGraph(JSConstant, OpInfo(m_constantNull));
5736             Node* condition = addToGraph(CompareEq, value, nullConstant);
<span class="line-modified">5737             addToGraph(Branch, OpInfo(branchData(m_currentIndex + currentInstruction-&gt;size(), m_currentIndex + relativeOffset)), condition);</span>
5738             LAST_OPCODE(op_jneq_null);
5739         }
5740 
5741         case op_jundefined_or_null: {
5742             auto bytecode = currentInstruction-&gt;as&lt;OpJundefinedOrNull&gt;();
5743             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5744             Node* value = get(bytecode.m_value);
5745             Node* condition = addToGraph(IsUndefinedOrNull, value);
<span class="line-modified">5746             addToGraph(Branch, OpInfo(branchData(m_currentIndex + relativeOffset, m_currentIndex + currentInstruction-&gt;size())), condition);</span>
5747             LAST_OPCODE(op_jundefined_or_null);
5748         }
5749 
5750         case op_jnundefined_or_null: {
5751             auto bytecode = currentInstruction-&gt;as&lt;OpJnundefinedOrNull&gt;();
5752             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5753             Node* value = get(bytecode.m_value);
5754             Node* condition = addToGraph(IsUndefinedOrNull, value);
<span class="line-modified">5755             addToGraph(Branch, OpInfo(branchData(m_currentIndex + currentInstruction-&gt;size(), m_currentIndex + relativeOffset)), condition);</span>
5756             LAST_OPCODE(op_jnundefined_or_null);
5757         }
5758 
5759         case op_jless: {
5760             auto bytecode = currentInstruction-&gt;as&lt;OpJless&gt;();
5761             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5762             Node* op1 = get(bytecode.m_lhs);
5763             Node* op2 = get(bytecode.m_rhs);
5764             Node* condition = addToGraph(CompareLess, op1, op2);
<span class="line-modified">5765             addToGraph(Branch, OpInfo(branchData(m_currentIndex + relativeOffset, m_currentIndex + currentInstruction-&gt;size())), condition);</span>
5766             LAST_OPCODE(op_jless);
5767         }
5768 
5769         case op_jlesseq: {
5770             auto bytecode = currentInstruction-&gt;as&lt;OpJlesseq&gt;();
5771             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5772             Node* op1 = get(bytecode.m_lhs);
5773             Node* op2 = get(bytecode.m_rhs);
5774             Node* condition = addToGraph(CompareLessEq, op1, op2);
<span class="line-modified">5775             addToGraph(Branch, OpInfo(branchData(m_currentIndex + relativeOffset, m_currentIndex + currentInstruction-&gt;size())), condition);</span>
5776             LAST_OPCODE(op_jlesseq);
5777         }
5778 
5779         case op_jgreater: {
5780             auto bytecode = currentInstruction-&gt;as&lt;OpJgreater&gt;();
5781             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5782             Node* op1 = get(bytecode.m_lhs);
5783             Node* op2 = get(bytecode.m_rhs);
5784             Node* condition = addToGraph(CompareGreater, op1, op2);
<span class="line-modified">5785             addToGraph(Branch, OpInfo(branchData(m_currentIndex + relativeOffset, m_currentIndex + currentInstruction-&gt;size())), condition);</span>
5786             LAST_OPCODE(op_jgreater);
5787         }
5788 
5789         case op_jgreatereq: {
5790             auto bytecode = currentInstruction-&gt;as&lt;OpJgreatereq&gt;();
5791             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5792             Node* op1 = get(bytecode.m_lhs);
5793             Node* op2 = get(bytecode.m_rhs);
5794             Node* condition = addToGraph(CompareGreaterEq, op1, op2);
<span class="line-modified">5795             addToGraph(Branch, OpInfo(branchData(m_currentIndex + relativeOffset, m_currentIndex + currentInstruction-&gt;size())), condition);</span>
5796             LAST_OPCODE(op_jgreatereq);
5797         }
5798 
5799         case op_jeq: {
5800             auto bytecode = currentInstruction-&gt;as&lt;OpJeq&gt;();
5801             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5802             Node* op1 = get(bytecode.m_lhs);
5803             Node* op2 = get(bytecode.m_rhs);
5804             Node* condition = addToGraph(CompareEq, op1, op2);
<span class="line-modified">5805             addToGraph(Branch, OpInfo(branchData(m_currentIndex + relativeOffset, m_currentIndex + currentInstruction-&gt;size())), condition);</span>
5806             LAST_OPCODE(op_jeq);
5807         }
5808 
5809         case op_jstricteq: {
5810             auto bytecode = currentInstruction-&gt;as&lt;OpJstricteq&gt;();
5811             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5812             Node* op1 = get(bytecode.m_lhs);
5813             Node* op2 = get(bytecode.m_rhs);
5814             Node* condition = addToGraph(CompareStrictEq, op1, op2);
<span class="line-modified">5815             addToGraph(Branch, OpInfo(branchData(m_currentIndex + relativeOffset, m_currentIndex + currentInstruction-&gt;size())), condition);</span>
5816             LAST_OPCODE(op_jstricteq);
5817         }
5818 
5819         case op_jnless: {
5820             auto bytecode = currentInstruction-&gt;as&lt;OpJnless&gt;();
5821             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5822             Node* op1 = get(bytecode.m_lhs);
5823             Node* op2 = get(bytecode.m_rhs);
5824             Node* condition = addToGraph(CompareLess, op1, op2);
<span class="line-modified">5825             addToGraph(Branch, OpInfo(branchData(m_currentIndex + currentInstruction-&gt;size(), m_currentIndex + relativeOffset)), condition);</span>
5826             LAST_OPCODE(op_jnless);
5827         }
5828 
5829         case op_jnlesseq: {
5830             auto bytecode = currentInstruction-&gt;as&lt;OpJnlesseq&gt;();
5831             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5832             Node* op1 = get(bytecode.m_lhs);
5833             Node* op2 = get(bytecode.m_rhs);
5834             Node* condition = addToGraph(CompareLessEq, op1, op2);
<span class="line-modified">5835             addToGraph(Branch, OpInfo(branchData(m_currentIndex + currentInstruction-&gt;size(), m_currentIndex + relativeOffset)), condition);</span>
5836             LAST_OPCODE(op_jnlesseq);
5837         }
5838 
5839         case op_jngreater: {
5840             auto bytecode = currentInstruction-&gt;as&lt;OpJngreater&gt;();
5841             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5842             Node* op1 = get(bytecode.m_lhs);
5843             Node* op2 = get(bytecode.m_rhs);
5844             Node* condition = addToGraph(CompareGreater, op1, op2);
<span class="line-modified">5845             addToGraph(Branch, OpInfo(branchData(m_currentIndex + currentInstruction-&gt;size(), m_currentIndex + relativeOffset)), condition);</span>
5846             LAST_OPCODE(op_jngreater);
5847         }
5848 
5849         case op_jngreatereq: {
5850             auto bytecode = currentInstruction-&gt;as&lt;OpJngreatereq&gt;();
5851             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5852             Node* op1 = get(bytecode.m_lhs);
5853             Node* op2 = get(bytecode.m_rhs);
5854             Node* condition = addToGraph(CompareGreaterEq, op1, op2);
<span class="line-modified">5855             addToGraph(Branch, OpInfo(branchData(m_currentIndex + currentInstruction-&gt;size(), m_currentIndex + relativeOffset)), condition);</span>
5856             LAST_OPCODE(op_jngreatereq);
5857         }
5858 
5859         case op_jneq: {
5860             auto bytecode = currentInstruction-&gt;as&lt;OpJneq&gt;();
5861             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5862             Node* op1 = get(bytecode.m_lhs);
5863             Node* op2 = get(bytecode.m_rhs);
5864             Node* condition = addToGraph(CompareEq, op1, op2);
<span class="line-modified">5865             addToGraph(Branch, OpInfo(branchData(m_currentIndex + currentInstruction-&gt;size(), m_currentIndex + relativeOffset)), condition);</span>
5866             LAST_OPCODE(op_jneq);
5867         }
5868 
5869         case op_jnstricteq: {
5870             auto bytecode = currentInstruction-&gt;as&lt;OpJnstricteq&gt;();
5871             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5872             Node* op1 = get(bytecode.m_lhs);
5873             Node* op2 = get(bytecode.m_rhs);
5874             Node* condition = addToGraph(CompareStrictEq, op1, op2);
<span class="line-modified">5875             addToGraph(Branch, OpInfo(branchData(m_currentIndex + currentInstruction-&gt;size(), m_currentIndex + relativeOffset)), condition);</span>
5876             LAST_OPCODE(op_jnstricteq);
5877         }
5878 
5879         case op_jbelow: {
5880             auto bytecode = currentInstruction-&gt;as&lt;OpJbelow&gt;();
5881             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5882             Node* op1 = get(bytecode.m_lhs);
5883             Node* op2 = get(bytecode.m_rhs);
5884             Node* condition = addToGraph(CompareBelow, op1, op2);
<span class="line-modified">5885             addToGraph(Branch, OpInfo(branchData(m_currentIndex + relativeOffset, m_currentIndex + currentInstruction-&gt;size())), condition);</span>
5886             LAST_OPCODE(op_jbelow);
5887         }
5888 
5889         case op_jbeloweq: {
5890             auto bytecode = currentInstruction-&gt;as&lt;OpJbeloweq&gt;();
5891             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5892             Node* op1 = get(bytecode.m_lhs);
5893             Node* op2 = get(bytecode.m_rhs);
5894             Node* condition = addToGraph(CompareBelowEq, op1, op2);
<span class="line-modified">5895             addToGraph(Branch, OpInfo(branchData(m_currentIndex + relativeOffset, m_currentIndex + currentInstruction-&gt;size())), condition);</span>
5896             LAST_OPCODE(op_jbeloweq);
5897         }
5898 
5899         case op_switch_imm: {
5900             auto bytecode = currentInstruction-&gt;as&lt;OpSwitchImm&gt;();
5901             SwitchData&amp; data = *m_graph.m_switchData.add();
5902             data.kind = SwitchImm;
5903             data.switchTableIndex = m_inlineStackTop-&gt;m_switchRemap[bytecode.m_tableIndex];
<span class="line-modified">5904             data.fallThrough.setBytecodeIndex(m_currentIndex + jumpTarget(bytecode.m_defaultOffset));</span>
5905             SimpleJumpTable&amp; table = m_codeBlock-&gt;switchJumpTable(data.switchTableIndex);
5906             for (unsigned i = 0; i &lt; table.branchOffsets.size(); ++i) {
5907                 if (!table.branchOffsets[i])
5908                     continue;
<span class="line-modified">5909                 unsigned target = m_currentIndex + table.branchOffsets[i];</span>
5910                 if (target == data.fallThrough.bytecodeIndex())
5911                     continue;
5912                 data.cases.append(SwitchCase::withBytecodeIndex(m_graph.freeze(jsNumber(static_cast&lt;int32_t&gt;(table.min + i))), target));
5913             }
5914             addToGraph(Switch, OpInfo(&amp;data), get(bytecode.m_scrutinee));
5915             flushIfTerminal(data);
5916             LAST_OPCODE(op_switch_imm);
5917         }
5918 
5919         case op_switch_char: {
5920             auto bytecode = currentInstruction-&gt;as&lt;OpSwitchChar&gt;();
5921             SwitchData&amp; data = *m_graph.m_switchData.add();
5922             data.kind = SwitchChar;
5923             data.switchTableIndex = m_inlineStackTop-&gt;m_switchRemap[bytecode.m_tableIndex];
<span class="line-modified">5924             data.fallThrough.setBytecodeIndex(m_currentIndex + jumpTarget(bytecode.m_defaultOffset));</span>
5925             SimpleJumpTable&amp; table = m_codeBlock-&gt;switchJumpTable(data.switchTableIndex);
5926             for (unsigned i = 0; i &lt; table.branchOffsets.size(); ++i) {
5927                 if (!table.branchOffsets[i])
5928                     continue;
<span class="line-modified">5929                 unsigned target = m_currentIndex + table.branchOffsets[i];</span>
5930                 if (target == data.fallThrough.bytecodeIndex())
5931                     continue;
5932                 data.cases.append(
5933                     SwitchCase::withBytecodeIndex(LazyJSValue::singleCharacterString(table.min + i), target));
5934             }
5935             addToGraph(Switch, OpInfo(&amp;data), get(bytecode.m_scrutinee));
5936             flushIfTerminal(data);
5937             LAST_OPCODE(op_switch_char);
5938         }
5939 
5940         case op_switch_string: {
5941             auto bytecode = currentInstruction-&gt;as&lt;OpSwitchString&gt;();
5942             SwitchData&amp; data = *m_graph.m_switchData.add();
5943             data.kind = SwitchString;
5944             data.switchTableIndex = bytecode.m_tableIndex;
<span class="line-modified">5945             data.fallThrough.setBytecodeIndex(m_currentIndex + jumpTarget(bytecode.m_defaultOffset));</span>
5946             StringJumpTable&amp; table = m_codeBlock-&gt;stringSwitchJumpTable(data.switchTableIndex);
5947             StringJumpTable::StringOffsetTable::iterator iter;
5948             StringJumpTable::StringOffsetTable::iterator end = table.offsetTable.end();
5949             for (iter = table.offsetTable.begin(); iter != end; ++iter) {
<span class="line-modified">5950                 unsigned target = m_currentIndex + iter-&gt;value.branchOffset;</span>
5951                 if (target == data.fallThrough.bytecodeIndex())
5952                     continue;
5953                 data.cases.append(
5954                     SwitchCase::withBytecodeIndex(LazyJSValue::knownStringImpl(iter-&gt;key.get()), target));
5955             }
5956             addToGraph(Switch, OpInfo(&amp;data), get(bytecode.m_scrutinee));
5957             flushIfTerminal(data);
5958             LAST_OPCODE(op_switch_string);
5959         }
5960 
5961         case op_ret: {
5962             auto bytecode = currentInstruction-&gt;as&lt;OpRet&gt;();
5963             ASSERT(!m_currentBlock-&gt;terminal());
5964             if (!inlineCallFrame()) {
5965                 // Simple case: we are just producing a return
5966                 addToGraph(Return, get(bytecode.m_value));
5967                 flushForReturn();
5968                 LAST_OPCODE(op_ret);
5969             }
5970 
5971             flushForReturn();
5972             if (m_inlineStackTop-&gt;m_returnValue.isValid())
5973                 setDirect(m_inlineStackTop-&gt;m_returnValue, get(bytecode.m_value), ImmediateSetWithFlush);
5974 
<span class="line-modified">5975             if (!m_inlineStackTop-&gt;m_continuationBlock &amp;&amp; m_currentIndex + currentInstruction-&gt;size() != m_inlineStackTop-&gt;m_codeBlock-&gt;instructions().size()) {</span>
5976                 // This is an early return from an inlined function and we do not have a continuation block, so we must allocate one.
5977                 // It is untargetable, because we do not know the appropriate index.
5978                 // If this block turns out to be a jump target, parseCodeBlock will fix its bytecodeIndex before putting it in m_blockLinkingTargets
5979                 m_inlineStackTop-&gt;m_continuationBlock = allocateUntargetableBlock();
5980             }
5981 
5982             if (m_inlineStackTop-&gt;m_continuationBlock)
5983                 addJumpTo(m_inlineStackTop-&gt;m_continuationBlock);
5984             else {
5985                 // We are returning from an inlined function, and do not need to jump anywhere, so we just keep the current block
5986                 m_inlineStackTop-&gt;m_continuationBlock = m_currentBlock;
5987             }
5988             LAST_OPCODE_LINKED(op_ret);
5989         }
5990         case op_end:
5991             ASSERT(!inlineCallFrame());
5992             addToGraph(Return, get(currentInstruction-&gt;as&lt;OpEnd&gt;().m_value));
5993             flushForReturn();
5994             LAST_OPCODE(op_end);
5995 
</pre>
<hr />
<pre>
6003             addToGraph(ThrowStaticError, OpInfo(bytecode.m_errorType), get(bytecode.m_message));
6004             flushForTerminal();
6005             LAST_OPCODE(op_throw_static_error);
6006         }
6007 
6008         case op_catch: {
6009             auto bytecode = currentInstruction-&gt;as&lt;OpCatch&gt;();
6010             m_graph.m_hasExceptionHandlers = true;
6011 
6012             if (inlineCallFrame()) {
6013                 // We can&#39;t do OSR entry into an inlined frame.
6014                 NEXT_OPCODE(op_catch);
6015             }
6016 
6017             if (m_graph.m_plan.mode() == FTLForOSREntryMode) {
6018                 NEXT_OPCODE(op_catch);
6019             }
6020 
6021             RELEASE_ASSERT(!m_currentBlock-&gt;size() || (m_graph.compilation() &amp;&amp; m_currentBlock-&gt;size() == 1 &amp;&amp; m_currentBlock-&gt;at(0)-&gt;op() == CountExecution));
6022 
<span class="line-modified">6023             ValueProfileAndOperandBuffer* buffer = bytecode.metadata(codeBlock).m_buffer;</span>
6024 
6025             if (!buffer) {
6026                 NEXT_OPCODE(op_catch); // This catch has yet to execute. Note: this load can be racy with the main thread.
6027             }
6028 
6029             // We&#39;re now committed to compiling this as an entrypoint.
6030             m_currentBlock-&gt;isCatchEntrypoint = true;
6031             m_graph.m_roots.append(m_currentBlock);
6032 
6033             Vector&lt;SpeculatedType&gt; argumentPredictions(m_numArguments);
6034             Vector&lt;SpeculatedType&gt; localPredictions;
6035             HashSet&lt;unsigned, WTF::IntHash&lt;unsigned&gt;, WTF::UnsignedWithZeroKeyHashTraits&lt;unsigned&gt;&gt; seenArguments;
6036 
6037             {
6038                 ConcurrentJSLocker locker(m_inlineStackTop-&gt;m_profiledBlock-&gt;m_lock);
6039 
<span class="line-modified">6040                 buffer-&gt;forEach([&amp;] (ValueProfileAndOperand&amp; profile) {</span>
6041                     VirtualRegister operand(profile.m_operand);
6042                     SpeculatedType prediction = profile.computeUpdatedPrediction(locker);
6043                     if (operand.isLocal())
6044                         localPredictions.append(prediction);
6045                     else {
6046                         RELEASE_ASSERT(operand.isArgument());
6047                         RELEASE_ASSERT(static_cast&lt;uint32_t&gt;(operand.toArgument()) &lt; argumentPredictions.size());
6048                         if (validationEnabled())
6049                             seenArguments.add(operand.toArgument());
6050                         argumentPredictions[operand.toArgument()] = prediction;
6051                     }
6052                 });
6053 
6054                 if (validationEnabled()) {
6055                     for (unsigned argument = 0; argument &lt; m_numArguments; ++argument)
6056                         RELEASE_ASSERT(seenArguments.contains(argument));
6057                 }
6058             }
6059 
6060             Vector&lt;std::pair&lt;VirtualRegister, Node*&gt;&gt; localsToSet;
6061             localsToSet.reserveInitialCapacity(buffer-&gt;m_size); // Note: This will reserve more than the number of locals we see below because the buffer includes arguments.
6062 
6063             // We&#39;re not allowed to exit here since we would not properly recover values.
6064             // We first need to bootstrap the catch entrypoint state.
6065             m_exitOK = false;
6066 
6067             unsigned numberOfLocals = 0;
<span class="line-modified">6068             buffer-&gt;forEach([&amp;] (ValueProfileAndOperand&amp; profile) {</span>
6069                 VirtualRegister operand(profile.m_operand);
6070                 if (operand.isArgument())
6071                     return;
6072                 ASSERT(operand.isLocal());
6073                 Node* value = addToGraph(ExtractCatchLocal, OpInfo(numberOfLocals), OpInfo(localPredictions[numberOfLocals]));
6074                 ++numberOfLocals;
<span class="line-modified">6075                 addToGraph(MovHint, OpInfo(profile.m_operand), value);</span>
6076                 localsToSet.uncheckedAppend(std::make_pair(operand, value));
6077             });
6078             if (numberOfLocals)
6079                 addToGraph(ClearCatchLocals);
6080 
6081             if (!m_graph.m_maxLocalsForCatchOSREntry)
6082                 m_graph.m_maxLocalsForCatchOSREntry = 0;
6083             m_graph.m_maxLocalsForCatchOSREntry = std::max(numberOfLocals, *m_graph.m_maxLocalsForCatchOSREntry);
6084 
6085             // We could not exit before this point in the program because we would not know how to do value
6086             // recovery for live locals. The above IR sets up the necessary state so we can recover values
6087             // during OSR exit.
6088             //
6089             // The nodes that follow here all exit to the following bytecode instruction, not
6090             // the op_catch. Exiting to op_catch is reserved for when an exception is thrown.
6091             // The SetArgumentDefinitely nodes that follow below may exit because we may hoist type checks
6092             // to them. The SetLocal nodes that follow below may exit because we may choose
6093             // a flush format that speculates on the type of the local.
6094             m_exitOK = true;
6095             addToGraph(ExitOK);
6096 
6097             {
6098                 auto addResult = m_graph.m_rootToArguments.add(m_currentBlock, ArgumentsVector());
6099                 RELEASE_ASSERT(addResult.isNewEntry);
6100                 ArgumentsVector&amp; entrypointArguments = addResult.iterator-&gt;value;
6101                 entrypointArguments.resize(m_numArguments);
6102 
<span class="line-modified">6103                 unsigned exitBytecodeIndex = m_currentIndex + currentInstruction-&gt;size();</span>
6104 
6105                 for (unsigned argument = 0; argument &lt; argumentPredictions.size(); ++argument) {
<span class="line-modified">6106                     VariableAccessData* variable = newVariableAccessData(virtualRegisterForArgument(argument));</span>
6107                     variable-&gt;predict(argumentPredictions[argument]);
6108 
6109                     variable-&gt;mergeStructureCheckHoistingFailed(
6110                         m_inlineStackTop-&gt;m_exitProfile.hasExitSite(exitBytecodeIndex, BadCache));
6111                     variable-&gt;mergeCheckArrayHoistingFailed(
6112                         m_inlineStackTop-&gt;m_exitProfile.hasExitSite(exitBytecodeIndex, BadIndexingType));
6113 
6114                     Node* setArgument = addToGraph(SetArgumentDefinitely, OpInfo(variable));
6115                     setArgument-&gt;origin.forExit = CodeOrigin(exitBytecodeIndex, setArgument-&gt;origin.forExit.inlineCallFrame());
6116                     m_currentBlock-&gt;variablesAtTail.setArgumentFirstTime(argument, setArgument);
6117                     entrypointArguments[argument] = setArgument;
6118                 }
6119             }
6120 
6121             for (const std::pair&lt;VirtualRegister, Node*&gt;&amp; pair : localsToSet) {
6122                 DelayedSetLocal delayed { currentCodeOrigin(), pair.first, pair.second, ImmediateNakedSet };
6123                 m_setLocalQueue.append(delayed);
6124             }
6125 
6126             NEXT_OPCODE(op_catch);
</pre>
<hr />
<pre>
6183                 NEXT_OPCODE(op_tail_call_forward_arguments);
6184             else
6185                 LAST_OPCODE(op_tail_call_forward_arguments);
6186         }
6187 
6188         case op_construct_varargs: {
6189             handleVarargsCall&lt;OpConstructVarargs&gt;(currentInstruction, ConstructVarargs, CallMode::Construct);
6190             ASSERT_WITH_MESSAGE(m_currentInstruction == currentInstruction, &quot;handleVarargsCall, which may have inlined the callee, trashed m_currentInstruction&quot;);
6191             NEXT_OPCODE(op_construct_varargs);
6192         }
6193 
6194         case op_call_eval: {
6195             auto bytecode = currentInstruction-&gt;as&lt;OpCallEval&gt;();
6196             int registerOffset = -bytecode.m_argv;
6197             addCall(bytecode.m_dst, CallEval, nullptr, get(bytecode.m_callee), bytecode.m_argc, registerOffset, getPrediction());
6198             NEXT_OPCODE(op_call_eval);
6199         }
6200 
6201         case op_jneq_ptr: {
6202             auto bytecode = currentInstruction-&gt;as&lt;OpJneqPtr&gt;();
<span class="line-modified">6203             Special::Pointer specialPointer = bytecode.m_specialPointer;</span>
<span class="line-removed">6204             ASSERT(pointerIsCell(specialPointer));</span>
<span class="line-removed">6205             JSCell* actualPointer = static_cast&lt;JSCell*&gt;(</span>
<span class="line-removed">6206                 actualPointerFor(m_inlineStackTop-&gt;m_codeBlock, specialPointer));</span>
<span class="line-removed">6207             FrozenValue* frozenPointer = m_graph.freeze(actualPointer);</span>
6208             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6209             Node* child = get(bytecode.m_value);
6210             if (bytecode.metadata(codeBlock).m_hasJumped) {
6211                 Node* condition = addToGraph(CompareEqPtr, OpInfo(frozenPointer), child);
<span class="line-modified">6212                 addToGraph(Branch, OpInfo(branchData(m_currentIndex + currentInstruction-&gt;size(), m_currentIndex + relativeOffset)), condition);</span>
6213                 LAST_OPCODE(op_jneq_ptr);
6214             }
6215             addToGraph(CheckCell, OpInfo(frozenPointer), child);
6216             NEXT_OPCODE(op_jneq_ptr);
6217         }
6218 
6219         case op_resolve_scope: {
6220             auto bytecode = currentInstruction-&gt;as&lt;OpResolveScope&gt;();
6221             auto&amp; metadata = bytecode.metadata(codeBlock);
6222 
6223             ResolveType resolveType;
6224             unsigned depth;
6225             JSScope* constantScope = nullptr;
6226             JSCell* lexicalEnvironment = nullptr;
6227             SymbolTable* symbolTable = nullptr;
6228             {
6229                 ConcurrentJSLocker locker(m_inlineStackTop-&gt;m_profiledBlock-&gt;m_lock);
6230                 resolveType = metadata.m_resolveType;
6231                 depth = metadata.m_localScopeDepth;
6232                 switch (resolveType) {
</pre>
<hr />
<pre>
6369                     addToGraph(GetDynamicVar, OpInfo(opInfo1), OpInfo(prediction), get(bytecode.m_scope)));
6370                 NEXT_OPCODE(op_get_from_scope);
6371             }
6372 
6373             UNUSED_PARAM(watchpoints); // We will use this in the future. For now we set it as a way of documenting the fact that that&#39;s what index 5 is in GlobalVar mode.
6374 
6375             JSGlobalObject* globalObject = m_inlineStackTop-&gt;m_codeBlock-&gt;globalObject();
6376 
6377             switch (resolveType) {
6378             case GlobalProperty:
6379             case GlobalPropertyWithVarInjectionChecks: {
6380                 // FIXME: Currently, module code do not query to JSGlobalLexicalEnvironment. So this case should be removed once it is fixed.
6381                 // https://bugs.webkit.org/show_bug.cgi?id=193347
6382                 if (m_inlineStackTop-&gt;m_codeBlock-&gt;scriptMode() != JSParserScriptMode::Module) {
6383                     if (!m_graph.watchGlobalProperty(globalObject, identifierNumber))
6384                         addToGraph(ForceOSRExit);
6385                 }
6386 
6387                 SpeculatedType prediction = getPrediction();
6388 
<span class="line-modified">6389                 GetByIdStatus status = GetByIdStatus::computeFor(structure, uid);</span>
<span class="line-modified">6390                 if (status.state() != GetByIdStatus::Simple</span>
6391                     || status.numVariants() != 1
6392                     || status[0].structureSet().size() != 1) {
6393                     set(bytecode.m_dst, addToGraph(GetByIdFlush, OpInfo(identifierNumber), OpInfo(prediction), get(bytecode.m_scope)));
6394                     break;
6395                 }
6396 
6397                 Node* base = weakJSConstant(globalObject);
6398                 Node* result = load(prediction, base, identifierNumber, status[0]);
6399                 addToGraph(Phantom, get(bytecode.m_scope));
6400                 set(bytecode.m_dst, result);
6401                 break;
6402             }
6403             case GlobalVar:
6404             case GlobalVarWithVarInjectionChecks:
6405             case GlobalLexicalVar:
6406             case GlobalLexicalVarWithVarInjectionChecks: {
6407                 addToGraph(Phantom, get(bytecode.m_scope));
6408                 WatchpointSet* watchpointSet;
6409                 ScopeOffset offset;
6410                 JSSegmentedVariableObject* scopeObject = jsCast&lt;JSSegmentedVariableObject*&gt;(JSScope::constantScopeForCodeBlock(resolveType, m_inlineStackTop-&gt;m_codeBlock));
</pre>
<hr />
<pre>
6629             case UnresolvedPropertyWithVarInjectionChecks:
6630                 RELEASE_ASSERT_NOT_REACHED();
6631                 break;
6632             }
6633             NEXT_OPCODE(op_put_to_scope);
6634         }
6635 
6636         case op_loop_hint: {
6637             // Baseline-&gt;DFG OSR jumps between loop hints. The DFG assumes that Baseline-&gt;DFG
6638             // OSR can only happen at basic block boundaries. Assert that these two statements
6639             // are compatible.
6640             RELEASE_ASSERT(m_currentIndex == blockBegin);
6641 
6642             // We never do OSR into an inlined code block. That could not happen, since OSR
6643             // looks up the code block that is the replacement for the baseline JIT code
6644             // block. Hence, machine code block = true code block = not inline code block.
6645             if (!m_inlineStackTop-&gt;m_caller)
6646                 m_currentBlock-&gt;isOSRTarget = true;
6647 
6648             addToGraph(LoopHint);
<span class="line-removed">6649             addToGraph(Options::usePollingTraps() ? CheckTraps : InvalidationPoint);</span>
6650             NEXT_OPCODE(op_loop_hint);
6651         }
6652 





6653         case op_nop: {
6654             addToGraph(Check); // We add a nop here so that basic block linking doesn&#39;t break.
6655             NEXT_OPCODE(op_nop);
6656         }
6657 
6658         case op_super_sampler_begin: {
6659             addToGraph(SuperSamplerBegin);
6660             NEXT_OPCODE(op_super_sampler_begin);
6661         }
6662 
6663         case op_super_sampler_end: {
6664             addToGraph(SuperSamplerEnd);
6665             NEXT_OPCODE(op_super_sampler_end);
6666         }
6667 
6668         case op_create_lexical_environment: {
6669             auto bytecode = currentInstruction-&gt;as&lt;OpCreateLexicalEnvironment&gt;();
6670             ASSERT(bytecode.m_symbolTable.isConstant() &amp;&amp; bytecode.m_initialValue.isConstant());
<span class="line-modified">6671             FrozenValue* symbolTable = m_graph.freezeStrong(m_inlineStackTop-&gt;m_codeBlock-&gt;getConstant(bytecode.m_symbolTable.offset()));</span>
<span class="line-modified">6672             FrozenValue* initialValue = m_graph.freezeStrong(m_inlineStackTop-&gt;m_codeBlock-&gt;getConstant(bytecode.m_initialValue.offset()));</span>
6673             Node* scope = get(bytecode.m_scope);
6674             Node* lexicalEnvironment = addToGraph(CreateActivation, OpInfo(symbolTable), OpInfo(initialValue), scope);
6675             set(bytecode.m_dst, lexicalEnvironment);
6676             NEXT_OPCODE(op_create_lexical_environment);
6677         }
6678 
6679         case op_push_with_scope: {
6680             auto bytecode = currentInstruction-&gt;as&lt;OpPushWithScope&gt;();
6681             Node* currentScope = get(bytecode.m_currentScope);
6682             Node* object = get(bytecode.m_newScope);
6683             set(bytecode.m_dst, addToGraph(PushWithScope, currentScope, object));
6684             NEXT_OPCODE(op_push_with_scope);
6685         }
6686 
6687         case op_get_parent_scope: {
6688             auto bytecode = currentInstruction-&gt;as&lt;OpGetParentScope&gt;();
6689             Node* currentScope = get(bytecode.m_scope);
6690             Node* newScope = addToGraph(SkipScope, currentScope);
6691             set(bytecode.m_dst, newScope);
6692             addToGraph(Phantom, currentScope);
6693             NEXT_OPCODE(op_get_parent_scope);
6694         }
6695 
6696         case op_get_scope: {
6697             // Help the later stages a bit by doing some small constant folding here. Note that this
6698             // only helps for the first basic block. It&#39;s extremely important not to constant fold
6699             // loads from the scope register later, as that would prevent the DFG from tracking the
6700             // bytecode-level liveness of the scope register.
6701             auto bytecode = currentInstruction-&gt;as&lt;OpGetScope&gt;();
<span class="line-modified">6702             Node* callee = get(VirtualRegister(CallFrameSlot::callee));</span>
6703             Node* result;
6704             if (JSFunction* function = callee-&gt;dynamicCastConstant&lt;JSFunction*&gt;(*m_vm))
6705                 result = weakJSConstant(function-&gt;scope());
6706             else
6707                 result = addToGraph(GetScope, callee);
6708             set(bytecode.m_dst, result);
6709             NEXT_OPCODE(op_get_scope);
6710         }
6711 
6712         case op_argument_count: {
6713             auto bytecode = currentInstruction-&gt;as&lt;OpArgumentCount&gt;();
6714             Node* sub = addToGraph(ArithSub, OpInfo(Arith::Unchecked), OpInfo(SpecInt32Only), getArgumentCount(), addToGraph(JSConstant, OpInfo(m_constantOne)));
6715             set(bytecode.m_dst, sub);
6716             NEXT_OPCODE(op_argument_count);
6717         }
6718 
6719         case op_create_direct_arguments: {
6720             auto bytecode = currentInstruction-&gt;as&lt;OpCreateDirectArguments&gt;();
6721             noticeArgumentsUse();
6722             Node* createArguments = addToGraph(CreateDirectArguments);
6723             set(bytecode.m_dst, createArguments);
6724             NEXT_OPCODE(op_create_direct_arguments);
6725         }
6726 
6727         case op_create_scoped_arguments: {
6728             auto bytecode = currentInstruction-&gt;as&lt;OpCreateScopedArguments&gt;();
6729             noticeArgumentsUse();
6730             Node* createArguments = addToGraph(CreateScopedArguments, get(bytecode.m_scope));
6731             set(bytecode.m_dst, createArguments);
6732             NEXT_OPCODE(op_create_scoped_arguments);
6733         }
6734 
6735         case op_create_cloned_arguments: {
6736             auto bytecode = currentInstruction-&gt;as&lt;OpCreateClonedArguments&gt;();
6737             noticeArgumentsUse();
6738             Node* createArguments = addToGraph(CreateClonedArguments);
6739             set(bytecode.m_dst, createArguments);
6740             NEXT_OPCODE(op_create_cloned_arguments);
6741         }
6742 







6743         case op_get_from_arguments: {
6744             auto bytecode = currentInstruction-&gt;as&lt;OpGetFromArguments&gt;();
6745             set(bytecode.m_dst,
6746                 addToGraph(
6747                     GetFromArguments,
6748                     OpInfo(bytecode.m_index),
6749                     OpInfo(getPrediction()),
6750                     get(bytecode.m_arguments)));
6751             NEXT_OPCODE(op_get_from_arguments);
6752         }
6753 
6754         case op_put_to_arguments: {
6755             auto bytecode = currentInstruction-&gt;as&lt;OpPutToArguments&gt;();
6756             addToGraph(
6757                 PutToArguments,
6758                 OpInfo(bytecode.m_index),
6759                 get(bytecode.m_arguments),
6760                 get(bytecode.m_value));
6761             NEXT_OPCODE(op_put_to_arguments);
6762         }
6763 
6764         case op_get_argument: {
6765             auto bytecode = currentInstruction-&gt;as&lt;OpGetArgument&gt;();
6766             InlineCallFrame* inlineCallFrame = this-&gt;inlineCallFrame();
6767             Node* argument;
6768             int32_t argumentIndexIncludingThis = bytecode.m_index;
6769             if (inlineCallFrame &amp;&amp; !inlineCallFrame-&gt;isVarargs()) {
6770                 int32_t argumentCountIncludingThisWithFixup = inlineCallFrame-&gt;argumentsWithFixup.size();
6771                 if (argumentIndexIncludingThis &lt; argumentCountIncludingThisWithFixup)
<span class="line-modified">6772                     argument = get(virtualRegisterForArgument(argumentIndexIncludingThis));</span>
6773                 else
6774                     argument = addToGraph(JSConstant, OpInfo(m_constantUndefined));
6775             } else
6776                 argument = addToGraph(GetArgument, OpInfo(argumentIndexIncludingThis), OpInfo(getPrediction()));
6777             set(bytecode.m_dst, argument);
6778             NEXT_OPCODE(op_get_argument);
6779         }
6780         case op_new_async_generator_func:
6781             handleNewFunc(NewAsyncGeneratorFunction, currentInstruction-&gt;as&lt;OpNewAsyncGeneratorFunc&gt;());
6782             NEXT_OPCODE(op_new_async_generator_func);
6783         case op_new_func:
6784             handleNewFunc(NewFunction, currentInstruction-&gt;as&lt;OpNewFunc&gt;());
6785             NEXT_OPCODE(op_new_func);
6786         case op_new_generator_func:
6787             handleNewFunc(NewGeneratorFunction, currentInstruction-&gt;as&lt;OpNewGeneratorFunc&gt;());
6788             NEXT_OPCODE(op_new_generator_func);
6789         case op_new_async_func:
6790             handleNewFunc(NewAsyncFunction, currentInstruction-&gt;as&lt;OpNewAsyncFunc&gt;());
6791             NEXT_OPCODE(op_new_async_func);
6792 
</pre>
<hr />
<pre>
6808             Node* func = get(bytecode.m_function);
6809             Node* name = get(bytecode.m_name);
6810             addToGraph(SetFunctionName, func, name);
6811             NEXT_OPCODE(op_set_function_name);
6812         }
6813 
6814         case op_typeof: {
6815             auto bytecode = currentInstruction-&gt;as&lt;OpTypeof&gt;();
6816             set(bytecode.m_dst, addToGraph(TypeOf, get(bytecode.m_value)));
6817             NEXT_OPCODE(op_typeof);
6818         }
6819 
6820         case op_to_number: {
6821             auto bytecode = currentInstruction-&gt;as&lt;OpToNumber&gt;();
6822             SpeculatedType prediction = getPrediction();
6823             Node* value = get(bytecode.m_operand);
6824             set(bytecode.m_dst, addToGraph(ToNumber, OpInfo(0), OpInfo(prediction), value));
6825             NEXT_OPCODE(op_to_number);
6826         }
6827 








6828         case op_to_string: {
6829             auto bytecode = currentInstruction-&gt;as&lt;OpToString&gt;();
6830             Node* value = get(bytecode.m_operand);
6831             set(bytecode.m_dst, addToGraph(ToString, value));
6832             NEXT_OPCODE(op_to_string);
6833         }
6834 
6835         case op_to_object: {
6836             auto bytecode = currentInstruction-&gt;as&lt;OpToObject&gt;();
6837             SpeculatedType prediction = getPrediction();
6838             Node* value = get(bytecode.m_operand);
6839             unsigned identifierNumber = m_inlineStackTop-&gt;m_identifierRemap[bytecode.m_message];
6840             set(bytecode.m_dst, addToGraph(ToObject, OpInfo(identifierNumber), OpInfo(prediction), value));
6841             NEXT_OPCODE(op_to_object);
6842         }
6843 
6844         case op_in_by_val: {
6845             auto bytecode = currentInstruction-&gt;as&lt;OpInByVal&gt;();
6846             ArrayMode arrayMode = getArrayMode(bytecode.metadata(codeBlock).m_arrayProfile, Array::Read);
6847             set(bytecode.m_dst, addToGraph(InByVal, OpInfo(arrayMode.asWord()), get(bytecode.m_base), get(bytecode.m_property)));
</pre>
<hr />
<pre>
6953             set(bytecode.m_dst, addToGraph(GetEnumeratorStructurePname,
6954                 get(bytecode.m_enumerator),
6955                 get(bytecode.m_index)));
6956             NEXT_OPCODE(op_enumerator_structure_pname);
6957         }
6958 
6959         case op_enumerator_generic_pname: {
6960             auto bytecode = currentInstruction-&gt;as&lt;OpEnumeratorGenericPname&gt;();
6961             set(bytecode.m_dst, addToGraph(GetEnumeratorGenericPname,
6962                 get(bytecode.m_enumerator),
6963                 get(bytecode.m_index)));
6964             NEXT_OPCODE(op_enumerator_generic_pname);
6965         }
6966 
6967         case op_to_index_string: {
6968             auto bytecode = currentInstruction-&gt;as&lt;OpToIndexString&gt;();
6969             set(bytecode.m_dst, addToGraph(ToIndexString, get(bytecode.m_index)));
6970             NEXT_OPCODE(op_to_index_string);
6971         }
6972 












6973         case op_log_shadow_chicken_prologue: {
6974             auto bytecode = currentInstruction-&gt;as&lt;OpLogShadowChickenPrologue&gt;();
6975             if (!m_inlineStackTop-&gt;m_inlineCallFrame)
6976                 addToGraph(LogShadowChickenPrologue, get(bytecode.m_scope));
6977             NEXT_OPCODE(op_log_shadow_chicken_prologue);
6978         }
6979 
6980         case op_log_shadow_chicken_tail: {
6981             auto bytecode = currentInstruction-&gt;as&lt;OpLogShadowChickenTail&gt;();
6982             if (!m_inlineStackTop-&gt;m_inlineCallFrame) {
6983                 // FIXME: The right solution for inlining is to elide these whenever the tail call
6984                 // ends up being inlined.
6985                 // https://bugs.webkit.org/show_bug.cgi?id=155686
6986                 addToGraph(LogShadowChickenTail, get(bytecode.m_thisValue), get(bytecode.m_scope));
6987             }
6988             NEXT_OPCODE(op_log_shadow_chicken_tail);
6989         }
6990 
6991         case op_unreachable: {
6992             flushForTerminal();
</pre>
<hr />
<pre>
6995         }
6996 
6997         default:
6998             // Parse failed! This should not happen because the capabilities checker
6999             // should have caught it.
7000             RELEASE_ASSERT_NOT_REACHED();
7001             return;
7002         }
7003     }
7004 }
7005 
7006 void ByteCodeParser::linkBlock(BasicBlock* block, Vector&lt;BasicBlock*&gt;&amp; possibleTargets)
7007 {
7008     ASSERT(!block-&gt;isLinked);
7009     ASSERT(!block-&gt;isEmpty());
7010     Node* node = block-&gt;terminal();
7011     ASSERT(node-&gt;isTerminal());
7012 
7013     switch (node-&gt;op()) {
7014     case Jump:
<span class="line-modified">7015         node-&gt;targetBlock() = blockForBytecodeOffset(possibleTargets, node-&gt;targetBytecodeOffsetDuringParsing());</span>
7016         break;
7017 
7018     case Branch: {
7019         BranchData* data = node-&gt;branchData();
<span class="line-modified">7020         data-&gt;taken.block = blockForBytecodeOffset(possibleTargets, data-&gt;takenBytecodeIndex());</span>
<span class="line-modified">7021         data-&gt;notTaken.block = blockForBytecodeOffset(possibleTargets, data-&gt;notTakenBytecodeIndex());</span>
7022         break;
7023     }
7024 
7025     case Switch: {
7026         SwitchData* data = node-&gt;switchData();
7027         for (unsigned i = node-&gt;switchData()-&gt;cases.size(); i--;)
<span class="line-modified">7028             data-&gt;cases[i].target.block = blockForBytecodeOffset(possibleTargets, data-&gt;cases[i].target.bytecodeIndex());</span>
<span class="line-modified">7029         data-&gt;fallThrough.block = blockForBytecodeOffset(possibleTargets, data-&gt;fallThrough.bytecodeIndex());</span>
7030         break;
7031     }
7032 
7033     default:
7034         RELEASE_ASSERT_NOT_REACHED();
7035     }
7036 
7037     VERBOSE_LOG(&quot;Marking &quot;, RawPointer(block), &quot; as linked (actually did linking)\n&quot;);
7038     block-&gt;didLink();
7039 }
7040 
7041 void ByteCodeParser::linkBlocks(Vector&lt;BasicBlock*&gt;&amp; unlinkedBlocks, Vector&lt;BasicBlock*&gt;&amp; possibleTargets)
7042 {
7043     for (size_t i = 0; i &lt; unlinkedBlocks.size(); ++i) {
7044         VERBOSE_LOG(&quot;Attempting to link &quot;, RawPointer(unlinkedBlocks[i]), &quot;\n&quot;);
7045         linkBlock(unlinkedBlocks[i], possibleTargets);
7046     }
7047 }
7048 
7049 ByteCodeParser::InlineStackEntry::InlineStackEntry(
</pre>
<hr />
<pre>
7080     m_optimizedContext.optimizedCodeBlock = optimizedBlock;
7081     if (Options::usePolyvariantDevirtualization() &amp;&amp; optimizedBlock) {
7082         ConcurrentJSLocker locker(optimizedBlock-&gt;m_lock);
7083         optimizedBlock-&gt;getICStatusMap(locker, m_optimizedContext.map);
7084     }
7085     byteCodeParser-&gt;m_icContextStack.append(&amp;m_optimizedContext);
7086 
7087     int argumentCountIncludingThisWithFixup = std::max&lt;int&gt;(argumentCountIncludingThis, codeBlock-&gt;numParameters());
7088 
7089     if (m_caller) {
7090         // Inline case.
7091         ASSERT(codeBlock != byteCodeParser-&gt;m_codeBlock);
7092         ASSERT(inlineCallFrameStart.isValid());
7093 
7094         m_inlineCallFrame = byteCodeParser-&gt;m_graph.m_plan.inlineCallFrames()-&gt;add();
7095         m_optimizedContext.inlineCallFrame = m_inlineCallFrame;
7096 
7097         // The owner is the machine code block, and we already have a barrier on that when the
7098         // plan finishes.
7099         m_inlineCallFrame-&gt;baselineCodeBlock.setWithoutWriteBarrier(codeBlock-&gt;baselineVersion());

7100         m_inlineCallFrame-&gt;setStackOffset(inlineCallFrameStart.offset() - CallFrame::headerSizeInRegisters);
7101         m_inlineCallFrame-&gt;argumentCountIncludingThis = argumentCountIncludingThis;

7102         if (callee) {
7103             m_inlineCallFrame-&gt;calleeRecovery = ValueRecovery::constant(callee);
7104             m_inlineCallFrame-&gt;isClosureCall = false;
7105         } else
7106             m_inlineCallFrame-&gt;isClosureCall = true;
7107         m_inlineCallFrame-&gt;directCaller = byteCodeParser-&gt;currentCodeOrigin();
7108         m_inlineCallFrame-&gt;argumentsWithFixup.resizeToFit(argumentCountIncludingThisWithFixup); // Set the number of arguments including this, but don&#39;t configure the value recoveries, yet.
7109         m_inlineCallFrame-&gt;kind = kind;
7110 
7111         m_identifierRemap.resize(codeBlock-&gt;numberOfIdentifiers());
7112         m_switchRemap.resize(codeBlock-&gt;numberOfSwitchJumpTables());
7113 
7114         for (size_t i = 0; i &lt; codeBlock-&gt;numberOfIdentifiers(); ++i) {
7115             UniquedStringImpl* rep = codeBlock-&gt;identifier(i).impl();
7116             unsigned index = byteCodeParser-&gt;m_graph.identifiers().ensure(rep);
7117             m_identifierRemap[i] = index;
7118         }
7119         for (unsigned i = 0; i &lt; codeBlock-&gt;numberOfSwitchJumpTables(); ++i) {
7120             m_switchRemap[i] = byteCodeParser-&gt;m_codeBlock-&gt;numberOfSwitchJumpTables();
7121             byteCodeParser-&gt;m_codeBlock-&gt;addSwitchJumpTableFromProfiledCodeBlock(codeBlock-&gt;switchJumpTable(i));
</pre>
<hr />
<pre>
7158 void ByteCodeParser::parseCodeBlock()
7159 {
7160     clearCaches();
7161 
7162     CodeBlock* codeBlock = m_inlineStackTop-&gt;m_codeBlock;
7163 
7164     if (UNLIKELY(m_graph.compilation())) {
7165         m_graph.compilation()-&gt;addProfiledBytecodes(
7166             *m_vm-&gt;m_perBytecodeProfiler, m_inlineStackTop-&gt;m_profiledBlock);
7167     }
7168 
7169     if (UNLIKELY(Options::dumpSourceAtDFGTime())) {
7170         Vector&lt;DeferredSourceDump&gt;&amp; deferredSourceDump = m_graph.m_plan.callback()-&gt;ensureDeferredSourceDump();
7171         if (inlineCallFrame()) {
7172             DeferredSourceDump dump(codeBlock-&gt;baselineVersion(), m_codeBlock, JITType::DFGJIT, inlineCallFrame()-&gt;directCaller.bytecodeIndex());
7173             deferredSourceDump.append(dump);
7174         } else
7175             deferredSourceDump.append(DeferredSourceDump(codeBlock-&gt;baselineVersion()));
7176     }
7177 
<span class="line-modified">7178     if (Options::dumpBytecodeAtDFGTime()) {</span>
7179         dataLog(&quot;Parsing &quot;, *codeBlock);
7180         if (inlineCallFrame()) {
7181             dataLog(
7182                 &quot; for inlining at &quot;, CodeBlockWithJITType(m_codeBlock, JITType::DFGJIT),
7183                 &quot; &quot;, inlineCallFrame()-&gt;directCaller);
7184         }
7185         dataLog(
7186             &quot;, isStrictMode = &quot;, codeBlock-&gt;ownerExecutable()-&gt;isStrictMode(), &quot;\n&quot;);
7187         codeBlock-&gt;baselineVersion()-&gt;dumpBytecode();
7188     }
7189 
7190     Vector&lt;InstructionStream::Offset, 32&gt; jumpTargets;
7191     computePreciseJumpTargets(codeBlock, jumpTargets);
<span class="line-modified">7192     if (Options::dumpBytecodeAtDFGTime()) {</span>
7193         dataLog(&quot;Jump targets: &quot;);
7194         CommaPrinter comma;
7195         for (unsigned i = 0; i &lt; jumpTargets.size(); ++i)
7196             dataLog(comma, jumpTargets[i]);
7197         dataLog(&quot;\n&quot;);
7198     }
7199 
7200     for (unsigned jumpTargetIndex = 0; jumpTargetIndex &lt;= jumpTargets.size(); ++jumpTargetIndex) {
7201         // The maximum bytecode offset to go into the current basicblock is either the next jump target, or the end of the instructions.
7202         unsigned limit = jumpTargetIndex &lt; jumpTargets.size() ? jumpTargets[jumpTargetIndex] : codeBlock-&gt;instructions().size();
<span class="line-modified">7203         ASSERT(m_currentIndex &lt; limit);</span>
7204 
7205         // Loop until we reach the current limit (i.e. next jump target).
7206         do {
7207             // There may already be a currentBlock in two cases:
7208             // - we may have just entered the loop for the first time
7209             // - we may have just returned from an inlined callee that had some early returns and
7210             //   so allocated a continuation block, and the instruction after the call is a jump target.
7211             // In both cases, we want to keep using it.
7212             if (!m_currentBlock) {
7213                 m_currentBlock = allocateTargetableBlock(m_currentIndex);
7214 
7215                 // The first block is definitely an OSR target.
7216                 if (m_graph.numBlocks() == 1) {
7217                     m_currentBlock-&gt;isOSRTarget = true;
7218                     m_graph.m_roots.append(m_currentBlock);
7219                 }
7220                 prepareToParseBlock();
7221             }
7222 
7223             parseBlock(limit);
7224 
7225             // We should not have gone beyond the limit.
<span class="line-modified">7226             ASSERT(m_currentIndex &lt;= limit);</span>
7227 
7228             if (m_currentBlock-&gt;isEmpty()) {
7229                 // This case only happens if the last instruction was an inlined call with early returns
7230                 // or polymorphic (creating an empty continuation block),
7231                 // and then we hit the limit before putting anything in the continuation block.
<span class="line-modified">7232                 ASSERT(m_currentIndex == limit);</span>
7233                 makeBlockTargetable(m_currentBlock, m_currentIndex);
7234             } else {
<span class="line-modified">7235                 ASSERT(m_currentBlock-&gt;terminal() || (m_currentIndex == codeBlock-&gt;instructions().size() &amp;&amp; inlineCallFrame()));</span>
7236                 m_currentBlock = nullptr;
7237             }
<span class="line-modified">7238         } while (m_currentIndex &lt; limit);</span>
7239     }
7240 
7241     // Should have reached the end of the instructions.
<span class="line-modified">7242     ASSERT(m_currentIndex == codeBlock-&gt;instructions().size());</span>
7243 
7244     VERBOSE_LOG(&quot;Done parsing &quot;, *codeBlock, &quot; (fell off end)\n&quot;);
7245 }
7246 
7247 template &lt;typename Bytecode&gt;
7248 void ByteCodeParser::handlePutByVal(Bytecode bytecode, unsigned instructionSize)
7249 {
7250     Node* base = get(bytecode.m_base);
7251     Node* property = get(bytecode.m_property);
7252     Node* value = get(bytecode.m_value);
7253     bool isDirect = Bytecode::opcodeID == op_put_by_val_direct;
7254     bool compiledAsPutById = false;
7255     {
7256         unsigned identifierNumber = std::numeric_limits&lt;unsigned&gt;::max();
7257         PutByIdStatus putByIdStatus;
7258         {
7259             ConcurrentJSLocker locker(m_inlineStackTop-&gt;m_profiledBlock-&gt;m_lock);
7260             ByValInfo* byValInfo = m_inlineStackTop-&gt;m_baselineMap.get(CodeOrigin(currentCodeOrigin().bytecodeIndex())).byValInfo;
7261             // FIXME: When the bytecode is not compiled in the baseline JIT, byValInfo becomes null.
7262             // At that time, there is no information.
7263             if (byValInfo
7264                 &amp;&amp; byValInfo-&gt;stubInfo
7265                 &amp;&amp; !byValInfo-&gt;tookSlowPath
7266                 &amp;&amp; !m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadIdent)
7267                 &amp;&amp; !m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType)
7268                 &amp;&amp; !m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell)) {
7269                 compiledAsPutById = true;
7270                 identifierNumber = m_graph.identifiers().ensure(byValInfo-&gt;cachedId.impl());
7271                 UniquedStringImpl* uid = m_graph.identifiers()[identifierNumber];
7272 
7273                 if (Symbol* symbol = byValInfo-&gt;cachedSymbol.get()) {
7274                     FrozenValue* frozen = m_graph.freezeStrong(symbol);
7275                     addToGraph(CheckCell, OpInfo(frozen), property);
7276                 } else {
7277                     ASSERT(!uid-&gt;isSymbol());
<span class="line-modified">7278                     addToGraph(CheckStringIdent, OpInfo(uid), property);</span>
7279                 }
7280 
7281                 putByIdStatus = PutByIdStatus::computeForStubInfo(
7282                     locker, m_inlineStackTop-&gt;m_profiledBlock,
7283                     byValInfo-&gt;stubInfo, currentCodeOrigin(), uid);
7284 
7285             }
7286         }
7287 
7288         if (compiledAsPutById)
7289             handlePutById(base, identifierNumber, value, putByIdStatus, isDirect, instructionSize);
7290     }
7291 
7292     if (!compiledAsPutById) {
7293         ArrayMode arrayMode = getArrayMode(bytecode.metadata(m_inlineStackTop-&gt;m_codeBlock).m_arrayProfile, Array::Write);
7294 
7295         addVarArgChild(base);
7296         addVarArgChild(property);
7297         addVarArgChild(value);
7298         addVarArgChild(0); // Leave room for property storage.
</pre>
<hr />
<pre>
7337     addToGraph(Phantom, scope);
7338 }
7339 
7340 template &lt;typename Bytecode&gt;
7341 void ByteCodeParser::handleNewFuncExp(NodeType op, Bytecode bytecode)
7342 {
7343     FunctionExecutable* expr = m_inlineStackTop-&gt;m_profiledBlock-&gt;functionExpr(bytecode.m_functionDecl);
7344     FrozenValue* frozen = m_graph.freezeStrong(expr);
7345     Node* scope = get(bytecode.m_scope);
7346     set(bytecode.m_dst, addToGraph(op, OpInfo(frozen), scope));
7347     // Ideally we wouldn&#39;t have to do this Phantom. But:
7348     //
7349     // For the constant case: we must do it because otherwise we would have no way of knowing
7350     // that the scope is live at OSR here.
7351     //
7352     // For the non-constant case: NewFunction could be DCE&#39;d, but baseline&#39;s implementation
7353     // won&#39;t be able to handle an Undefined scope.
7354     addToGraph(Phantom, scope);
7355 }
7356 













































7357 void ByteCodeParser::parse()
7358 {
7359     // Set during construction.
<span class="line-modified">7360     ASSERT(!m_currentIndex);</span>
7361 
7362     VERBOSE_LOG(&quot;Parsing &quot;, *m_codeBlock, &quot;\n&quot;);
7363 
7364     InlineStackEntry inlineStackEntry(
7365         this, m_codeBlock, m_profiledBlock, 0, VirtualRegister(), VirtualRegister(),
7366         m_codeBlock-&gt;numParameters(), InlineCallFrame::Call, nullptr);
7367 
7368     parseCodeBlock();
7369     linkBlocks(inlineStackEntry.m_unlinkedBlocks, inlineStackEntry.m_blockLinkingTargets);
7370 
7371     if (m_hasAnyForceOSRExits) {
7372         BlockSet blocksToIgnore;
7373         for (BasicBlock* block : m_graph.blocksInNaturalOrder()) {
7374             if (block-&gt;isOSRTarget &amp;&amp; block-&gt;bytecodeBegin == m_graph.m_plan.osrEntryBytecodeIndex()) {
7375                 blocksToIgnore.add(block);
7376                 break;
7377             }
7378         }
7379 
7380         {
</pre>
<hr />
<pre>
7398         Operands&lt;VariableAccessData*&gt; mapping(OperandsLike, m_graph.block(0)-&gt;variablesAtHead);
7399 
7400         for (BasicBlock* block : m_graph.blocksInNaturalOrder()) {
7401             if (blocksToIgnore.contains(block))
7402                 continue;
7403 
7404             mapping.fill(nullptr);
7405             if (validationEnabled()) {
7406                 // Verify that it&#39;s correct to fill mapping with nullptr.
7407                 for (unsigned i = 0; i &lt; block-&gt;variablesAtHead.size(); ++i) {
7408                     Node* node = block-&gt;variablesAtHead.at(i);
7409                     RELEASE_ASSERT(!node);
7410                 }
7411             }
7412 
7413             for (unsigned nodeIndex = 0; nodeIndex &lt; block-&gt;size(); ++nodeIndex) {
7414                 {
7415                     Node* node = block-&gt;at(nodeIndex);
7416 
7417                     if (node-&gt;hasVariableAccessData(m_graph))
<span class="line-modified">7418                         mapping.operand(node-&gt;local()) = node-&gt;variableAccessData();</span>
7419 
7420                     if (node-&gt;op() != ForceOSRExit)
7421                         continue;
7422                 }
7423 
7424                 NodeOrigin origin = block-&gt;at(nodeIndex)-&gt;origin;
7425                 RELEASE_ASSERT(origin.exitOK);
7426 
7427                 ++nodeIndex;
7428 
7429                 {
7430                     if (validationEnabled()) {
7431                         // This verifies that we don&#39;t need to change any of the successors&#39;s predecessor
7432                         // list after planting the Unreachable below. At this point in the bytecode
7433                         // parser, we haven&#39;t linked up the predecessor lists yet.
7434                         for (BasicBlock* successor : block-&gt;successors())
7435                             RELEASE_ASSERT(successor-&gt;predecessors.isEmpty());
7436                     }
7437 
<span class="line-modified">7438                     auto insertLivenessPreservingOp = [&amp;] (InlineCallFrame* inlineCallFrame, NodeType op, VirtualRegister operand) {</span>
7439                         VariableAccessData* variable = mapping.operand(operand);
7440                         if (!variable) {
7441                             variable = newVariableAccessData(operand);
7442                             mapping.operand(operand) = variable;
7443                         }
7444 
<span class="line-modified">7445                         VirtualRegister argument = operand - (inlineCallFrame ? inlineCallFrame-&gt;stackOffset : 0);</span>
7446                         if (argument.isArgument() &amp;&amp; !argument.isHeader()) {
7447                             const Vector&lt;ArgumentPosition*&gt;&amp; arguments = m_inlineCallFrameToArgumentPositions.get(inlineCallFrame);
7448                             arguments[argument.toArgument()]-&gt;addVariable(variable);
7449                         }
7450                         insertionSet.insertNode(nodeIndex, SpecNone, op, origin, OpInfo(variable));
7451                     };
<span class="line-modified">7452                     auto addFlushDirect = [&amp;] (InlineCallFrame* inlineCallFrame, VirtualRegister operand) {</span>
7453                         insertLivenessPreservingOp(inlineCallFrame, Flush, operand);
7454                     };
<span class="line-modified">7455                     auto addPhantomLocalDirect = [&amp;] (InlineCallFrame* inlineCallFrame, VirtualRegister operand) {</span>
7456                         insertLivenessPreservingOp(inlineCallFrame, PhantomLocal, operand);
7457                     };
7458                     flushForTerminalImpl(origin.semantic, addFlushDirect, addPhantomLocalDirect);
7459                 }
7460 
7461                 while (true) {
7462                     RELEASE_ASSERT(nodeIndex &lt; block-&gt;size());
7463 
7464                     Node* node = block-&gt;at(nodeIndex);
7465 
7466                     node-&gt;origin = origin;
7467                     m_graph.doToChildren(node, [&amp;] (Edge edge) {
7468                         // We only need to keep data flow edges to nodes defined prior to the ForceOSRExit. The reason
7469                         // for this is we rely on backwards propagation being able to see the &quot;full&quot; bytecode. To model
7470                         // this, we preserve uses of a node in a generic way so that backwards propagation can reason
7471                         // about them. Therefore, we can&#39;t remove uses of a node which is defined before the ForceOSRExit
7472                         // even when we&#39;re at a point in the program after the ForceOSRExit, because that would break backwards
7473                         // propagation&#39;s analysis over the uses of a node. However, we don&#39;t need this same preservation for
7474                         // nodes defined after ForceOSRExit, as we&#39;ve already exitted before those defs.
7475                         if (edge-&gt;hasResult())
</pre>
<hr />
<pre>
7500         // Ensure our bookkeeping for ForceOSRExit nodes is working.
7501         for (BasicBlock* block : m_graph.blocksInNaturalOrder()) {
7502             for (Node* node : *block)
7503                 RELEASE_ASSERT(node-&gt;op() != ForceOSRExit);
7504         }
7505     }
7506 
7507     m_graph.determineReachability();
7508     m_graph.killUnreachableBlocks();
7509 
7510     for (BlockIndex blockIndex = m_graph.numBlocks(); blockIndex--;) {
7511         BasicBlock* block = m_graph.block(blockIndex);
7512         if (!block)
7513             continue;
7514         ASSERT(block-&gt;variablesAtHead.numberOfLocals() == m_graph.block(0)-&gt;variablesAtHead.numberOfLocals());
7515         ASSERT(block-&gt;variablesAtHead.numberOfArguments() == m_graph.block(0)-&gt;variablesAtHead.numberOfArguments());
7516         ASSERT(block-&gt;variablesAtTail.numberOfLocals() == m_graph.block(0)-&gt;variablesAtHead.numberOfLocals());
7517         ASSERT(block-&gt;variablesAtTail.numberOfArguments() == m_graph.block(0)-&gt;variablesAtHead.numberOfArguments());
7518     }
7519 

7520     m_graph.m_localVars = m_numLocals;
7521     m_graph.m_parameterSlots = m_parameterSlots;
7522 }
7523 
7524 void parse(Graph&amp; graph)
7525 {
7526     ByteCodeParser(graph).parse();
7527 }
7528 
7529 } } // namespace JSC::DFG
7530 
7531 #endif
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (C) 2011-2020 Apple Inc. All rights reserved.</span>
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;DFGByteCodeParser.h&quot;
  28 
  29 #if ENABLE(DFG_JIT)
  30 
  31 #include &quot;ArithProfile.h&quot;
  32 #include &quot;ArrayConstructor.h&quot;
  33 #include &quot;BasicBlockLocation.h&quot;
  34 #include &quot;BuiltinNames.h&quot;
<span class="line-modified">  35 #include &quot;BytecodeGenerator.h&quot;</span>
<span class="line-added">  36 #include &quot;BytecodeUseDef.h&quot;</span>
<span class="line-added">  37 #include &quot;CacheableIdentifierInlines.h&quot;</span>
  38 #include &quot;CallLinkStatus.h&quot;
  39 #include &quot;CodeBlock.h&quot;
  40 #include &quot;CodeBlockWithJITType.h&quot;
  41 #include &quot;CommonSlowPaths.h&quot;
  42 #include &quot;DFGAbstractHeap.h&quot;
  43 #include &quot;DFGArrayMode.h&quot;
  44 #include &quot;DFGCFG.h&quot;
  45 #include &quot;DFGCapabilities.h&quot;
  46 #include &quot;DFGClobberize.h&quot;
  47 #include &quot;DFGClobbersExitState.h&quot;
  48 #include &quot;DFGGraph.h&quot;
  49 #include &quot;DFGJITCode.h&quot;
  50 #include &quot;FunctionCodeBlock.h&quot;
<span class="line-modified">  51 #include &quot;GetByStatus.h&quot;</span>
<span class="line-added">  52 #include &quot;GetterSetter.h&quot;</span>
  53 #include &quot;Heap.h&quot;
  54 #include &quot;InByIdStatus.h&quot;
  55 #include &quot;InstanceOfStatus.h&quot;
<span class="line-added">  56 #include &quot;JSArrayIterator.h&quot;</span>
  57 #include &quot;JSCInlines.h&quot;

  58 #include &quot;JSImmutableButterfly.h&quot;
<span class="line-added">  59 #include &quot;JSInternalPromise.h&quot;</span>
<span class="line-added">  60 #include &quot;JSInternalPromiseConstructor.h&quot;</span>
  61 #include &quot;JSModuleEnvironment.h&quot;
  62 #include &quot;JSModuleNamespaceObject.h&quot;
<span class="line-added">  63 #include &quot;JSPromiseConstructor.h&quot;</span>
  64 #include &quot;NumberConstructor.h&quot;
  65 #include &quot;ObjectConstructor.h&quot;
  66 #include &quot;OpcodeInlines.h&quot;
  67 #include &quot;PreciseJumpTargets.h&quot;
  68 #include &quot;PutByIdFlags.h&quot;
  69 #include &quot;PutByIdStatus.h&quot;
  70 #include &quot;RegExpPrototype.h&quot;
  71 #include &quot;StackAlignment.h&quot;
  72 #include &quot;StringConstructor.h&quot;
  73 #include &quot;StructureStubInfo.h&quot;
  74 #include &quot;SymbolConstructor.h&quot;
  75 #include &quot;Watchdog.h&quot;
  76 #include &lt;wtf/CommaPrinter.h&gt;
  77 #include &lt;wtf/HashMap.h&gt;
  78 #include &lt;wtf/MathExtras.h&gt;
<span class="line-added">  79 #include &lt;wtf/Scope.h&gt;</span>
  80 #include &lt;wtf/SetForScope.h&gt;
  81 #include &lt;wtf/StdLibExtras.h&gt;
  82 
  83 namespace JSC { namespace DFG {
  84 
  85 namespace DFGByteCodeParserInternal {
  86 #ifdef NDEBUG
<span class="line-modified">  87 static constexpr bool verbose = false;</span>
  88 #else
<span class="line-modified">  89 static constexpr bool verbose = true;</span>
  90 #endif
  91 } // namespace DFGByteCodeParserInternal
  92 
  93 #define VERBOSE_LOG(...) do { \
  94 if (DFGByteCodeParserInternal::verbose &amp;&amp; Options::verboseDFGBytecodeParsing()) \
  95 dataLog(__VA_ARGS__); \
  96 } while (false)
  97 
  98 // === ByteCodeParser ===
  99 //
 100 // This class is used to compile the dataflow graph from a CodeBlock.
 101 class ByteCodeParser {
 102 public:
 103     ByteCodeParser(Graph&amp; graph)
 104         : m_vm(&amp;graph.m_vm)
 105         , m_codeBlock(graph.m_codeBlock)
 106         , m_profiledBlock(graph.m_profiledBlock)
 107         , m_graph(graph)
 108         , m_currentBlock(0)
 109         , m_currentIndex(0)
 110         , m_constantUndefined(graph.freeze(jsUndefined()))
 111         , m_constantNull(graph.freeze(jsNull()))
 112         , m_constantNaN(graph.freeze(jsNumber(PNaN)))
 113         , m_constantOne(graph.freeze(jsNumber(1)))
 114         , m_numArguments(m_codeBlock-&gt;numParameters())
 115         , m_numLocals(m_codeBlock-&gt;numCalleeLocals())
<span class="line-added"> 116         , m_numTmps(m_codeBlock-&gt;numTmps())</span>
 117         , m_parameterSlots(0)
 118         , m_numPassedVarArgs(0)
 119         , m_inlineStackTop(0)
 120         , m_currentInstruction(0)
 121         , m_hasDebuggerEnabled(graph.hasDebuggerEnabled())
 122     {
 123         ASSERT(m_profiledBlock);
 124     }
 125 
 126     // Parse a full CodeBlock of bytecode.
 127     void parse();
 128 
 129 private:
 130     struct InlineStackEntry;
 131 
 132     // Just parse from m_currentIndex to the end of the current CodeBlock.
 133     void parseCodeBlock();
 134 
 135     void ensureLocals(unsigned newNumLocals)
 136     {
 137         VERBOSE_LOG(&quot;   ensureLocals: trying to raise m_numLocals from &quot;, m_numLocals, &quot; to &quot;, newNumLocals, &quot;\n&quot;);
 138         if (newNumLocals &lt;= m_numLocals)
 139             return;
 140         m_numLocals = newNumLocals;
 141         for (size_t i = 0; i &lt; m_graph.numBlocks(); ++i)
 142             m_graph.block(i)-&gt;ensureLocals(newNumLocals);
 143     }
 144 
<span class="line-added"> 145     void ensureTmps(unsigned newNumTmps)</span>
<span class="line-added"> 146     {</span>
<span class="line-added"> 147         VERBOSE_LOG(&quot;   ensureTmps: trying to raise m_numTmps from &quot;, m_numTmps, &quot; to &quot;, newNumTmps, &quot;\n&quot;);</span>
<span class="line-added"> 148         if (newNumTmps &lt;= m_numTmps)</span>
<span class="line-added"> 149             return;</span>
<span class="line-added"> 150         m_numTmps = newNumTmps;</span>
<span class="line-added"> 151         for (size_t i = 0; i &lt; m_graph.numBlocks(); ++i)</span>
<span class="line-added"> 152             m_graph.block(i)-&gt;ensureTmps(newNumTmps);</span>
<span class="line-added"> 153     }</span>
<span class="line-added"> 154 </span>
<span class="line-added"> 155 </span>
 156     // Helper for min and max.
 157     template&lt;typename ChecksFunctor&gt;
 158     bool handleMinMax(VirtualRegister result, NodeType op, int registerOffset, int argumentCountIncludingThis, const ChecksFunctor&amp; insertChecks);
 159 
 160     void refineStatically(CallLinkStatus&amp;, Node* callTarget);
 161     // Blocks can either be targetable (i.e. in the m_blockLinkingTargets of one InlineStackEntry) with a well-defined bytecodeBegin,
 162     // or they can be untargetable, with bytecodeBegin==UINT_MAX, to be managed manually and not by the linkBlock machinery.
 163     // This is used most notably when doing polyvariant inlining (it requires a fair bit of control-flow with no bytecode analog).
 164     // It is also used when doing an early return from an inlined callee: it is easier to fix the bytecode index later on if needed
 165     // than to move the right index all the way to the treatment of op_ret.
<span class="line-modified"> 166     BasicBlock* allocateTargetableBlock(BytecodeIndex);</span>
 167     BasicBlock* allocateUntargetableBlock();
 168     // An untargetable block can be given a bytecodeIndex to be later managed by linkBlock, but only once, and it can never go in the other direction
<span class="line-modified"> 169     void makeBlockTargetable(BasicBlock*, BytecodeIndex);</span>
 170     void addJumpTo(BasicBlock*);
 171     void addJumpTo(unsigned bytecodeIndex);
 172     // Handle calls. This resolves issues surrounding inlining and intrinsics.
 173     enum Terminality { Terminal, NonTerminal };
 174     Terminality handleCall(
 175         VirtualRegister result, NodeType op, InlineCallFrame::Kind, unsigned instructionSize,
 176         Node* callTarget, int argumentCountIncludingThis, int registerOffset, CallLinkStatus,
 177         SpeculatedType prediction);
 178     template&lt;typename CallOp&gt;
 179     Terminality handleCall(const Instruction* pc, NodeType op, CallMode);
 180     template&lt;typename CallOp&gt;
 181     Terminality handleVarargsCall(const Instruction* pc, NodeType op, CallMode);
 182     void emitFunctionChecks(CallVariant, Node* callTarget, VirtualRegister thisArgumnt);
 183     void emitArgumentPhantoms(int registerOffset, int argumentCountIncludingThis);
 184     Node* getArgumentCount();
 185     template&lt;typename ChecksFunctor&gt;
 186     bool handleRecursiveTailCall(Node* callTargetNode, CallVariant, int registerOffset, int argumentCountIncludingThis, const ChecksFunctor&amp; emitFunctionCheckIfNeeded);
 187     unsigned inliningCost(CallVariant, int argumentCountIncludingThis, InlineCallFrame::Kind); // Return UINT_MAX if it&#39;s not an inlining candidate. By convention, intrinsics have a cost of 1.
 188     // Handle inlining. Return true if it succeeded, false if we need to plant a call.
 189     bool handleVarargsInlining(Node* callTargetNode, VirtualRegister result, const CallLinkStatus&amp;, int registerOffset, VirtualRegister thisArgument, VirtualRegister argumentsArgument, unsigned argumentsOffset, NodeType callOp, InlineCallFrame::Kind);
 190     unsigned getInliningBalance(const CallLinkStatus&amp;, CodeSpecializationKind);
 191     enum class CallOptimizationResult { OptimizedToJump, Inlined, DidNothing };
<span class="line-modified"> 192     CallOptimizationResult handleCallVariant(Node* callTargetNode, VirtualRegister result, CallVariant, int registerOffset, VirtualRegister thisArgument, int argumentCountIncludingThis, BytecodeIndex nextIndex, InlineCallFrame::Kind, SpeculatedType prediction, unsigned&amp; inliningBalance, BasicBlock* continuationBlock, bool needsToCheckCallee);</span>
<span class="line-modified"> 193     CallOptimizationResult handleInlining(Node* callTargetNode, VirtualRegister result, const CallLinkStatus&amp;, int registerOffset, VirtualRegister thisArgument, int argumentCountIncludingThis, BytecodeIndex nextIndex, NodeType callOp, InlineCallFrame::Kind, SpeculatedType prediction);</span>
 194     template&lt;typename ChecksFunctor&gt;
 195     void inlineCall(Node* callTargetNode, VirtualRegister result, CallVariant, int registerOffset, int argumentCountIncludingThis, InlineCallFrame::Kind, BasicBlock* continuationBlock, const ChecksFunctor&amp; insertChecks);
 196     // Handle intrinsic functions. Return true if it succeeded, false if we need to plant a call.
 197     template&lt;typename ChecksFunctor&gt;
 198     bool handleIntrinsicCall(Node* callee, VirtualRegister result, Intrinsic, int registerOffset, int argumentCountIncludingThis, SpeculatedType prediction, const ChecksFunctor&amp; insertChecks);
 199     template&lt;typename ChecksFunctor&gt;
 200     bool handleDOMJITCall(Node* callee, VirtualRegister result, const DOMJIT::Signature*, int registerOffset, int argumentCountIncludingThis, SpeculatedType prediction, const ChecksFunctor&amp; insertChecks);
 201     template&lt;typename ChecksFunctor&gt;
 202     bool handleIntrinsicGetter(VirtualRegister result, SpeculatedType prediction, const GetByIdVariant&amp; intrinsicVariant, Node* thisNode, const ChecksFunctor&amp; insertChecks);
 203     template&lt;typename ChecksFunctor&gt;
 204     bool handleTypedArrayConstructor(VirtualRegister result, InternalFunction*, int registerOffset, int argumentCountIncludingThis, TypedArrayType, const ChecksFunctor&amp; insertChecks);
 205     template&lt;typename ChecksFunctor&gt;
 206     bool handleConstantInternalFunction(Node* callTargetNode, VirtualRegister result, InternalFunction*, int registerOffset, int argumentCountIncludingThis, CodeSpecializationKind, SpeculatedType, const ChecksFunctor&amp; insertChecks);
 207     Node* handlePutByOffset(Node* base, unsigned identifier, PropertyOffset, Node* value);
 208     Node* handleGetByOffset(SpeculatedType, Node* base, unsigned identifierNumber, PropertyOffset, NodeType = GetByOffset);
 209     bool handleDOMJITGetter(VirtualRegister result, const GetByIdVariant&amp;, Node* thisNode, unsigned identifierNumber, SpeculatedType prediction);
<span class="line-modified"> 210     bool handleModuleNamespaceLoad(VirtualRegister result, SpeculatedType, Node* base, GetByStatus);</span>
 211 
 212     template&lt;typename Bytecode&gt;
 213     void handlePutByVal(Bytecode, unsigned instructionSize);
 214     template &lt;typename Bytecode&gt;
 215     void handlePutAccessorById(NodeType, Bytecode);
 216     template &lt;typename Bytecode&gt;
 217     void handlePutAccessorByVal(NodeType, Bytecode);
 218     template &lt;typename Bytecode&gt;
 219     void handleNewFunc(NodeType, Bytecode);
 220     template &lt;typename Bytecode&gt;
 221     void handleNewFuncExp(NodeType, Bytecode);
<span class="line-added"> 222     template &lt;typename Bytecode&gt;</span>
<span class="line-added"> 223     void handleCreateInternalFieldObject(const ClassInfo*, NodeType createOp, NodeType newOp, Bytecode);</span>
 224 
 225     // Create a presence ObjectPropertyCondition based on some known offset and structure set. Does not
 226     // check the validity of the condition, but it may return a null one if it encounters a contradiction.
 227     ObjectPropertyCondition presenceLike(
 228         JSObject* knownBase, UniquedStringImpl*, PropertyOffset, const StructureSet&amp;);
 229 
 230     // Attempt to watch the presence of a property. It will watch that the property is present in the same
 231     // way as in all of the structures in the set. It may emit code instead of just setting a watchpoint.
 232     // Returns true if this all works out.
 233     bool checkPresenceLike(JSObject* knownBase, UniquedStringImpl*, PropertyOffset, const StructureSet&amp;);
 234     void checkPresenceLike(Node* base, UniquedStringImpl*, PropertyOffset, const StructureSet&amp;);
 235 
 236     // Works with both GetByIdVariant and the setter form of PutByIdVariant.
 237     template&lt;typename VariantType&gt;
 238     Node* load(SpeculatedType, Node* base, unsigned identifierNumber, const VariantType&amp;);
 239 
 240     Node* store(Node* base, unsigned identifier, const PutByIdVariant&amp;, Node* value);
 241 
 242     template&lt;typename Op&gt;
 243     void parseGetById(const Instruction*);
 244     void handleGetById(
<span class="line-modified"> 245         VirtualRegister destination, SpeculatedType, Node* base, unsigned identifierNumber, GetByStatus, AccessType, unsigned instructionSize);</span>
 246     void emitPutById(
 247         Node* base, unsigned identifierNumber, Node* value,  const PutByIdStatus&amp;, bool isDirect);
 248     void handlePutById(
 249         Node* base, unsigned identifierNumber, Node* value, const PutByIdStatus&amp;,
 250         bool isDirect, unsigned intructionSize);
 251 
 252     // Either register a watchpoint or emit a check for this condition. Returns false if the
 253     // condition no longer holds, and therefore no reasonable check can be emitted.
 254     bool check(const ObjectPropertyCondition&amp;);
 255 
 256     GetByOffsetMethod promoteToConstant(GetByOffsetMethod);
 257 
 258     // Either register a watchpoint or emit a check for this condition. It must be a Presence
 259     // condition. It will attempt to promote a Presence condition to an Equivalence condition.
 260     // Emits code for the loaded value that the condition guards, and returns a node containing
 261     // the loaded value. Returns null if the condition no longer holds.
 262     GetByOffsetMethod planLoad(const ObjectPropertyCondition&amp;);
 263     Node* load(SpeculatedType, unsigned identifierNumber, const GetByOffsetMethod&amp;, NodeType = GetByOffset);
 264     Node* load(SpeculatedType, const ObjectPropertyCondition&amp;, NodeType = GetByOffset);
 265 
</pre>
<hr />
<pre>
 267     // watchpoints (or a combination of the two) to make the conditions hold. If any of those
 268     // conditions are no longer checkable, returns false.
 269     bool check(const ObjectPropertyConditionSet&amp;);
 270 
 271     // Calls check() for those conditions that aren&#39;t the slot base, and calls load() for the slot
 272     // base. Does a combination of watchpoint registration and check emission to guard the
 273     // conditions, and emits code to load the value from the slot base. Returns a node containing
 274     // the loaded value. Returns null if any of the conditions were no longer checkable.
 275     GetByOffsetMethod planLoad(const ObjectPropertyConditionSet&amp;);
 276     Node* load(SpeculatedType, const ObjectPropertyConditionSet&amp;, NodeType = GetByOffset);
 277 
 278     void prepareToParseBlock();
 279     void clearCaches();
 280 
 281     // Parse a single basic block of bytecode instructions.
 282     void parseBlock(unsigned limit);
 283     // Link block successors.
 284     void linkBlock(BasicBlock*, Vector&lt;BasicBlock*&gt;&amp; possibleTargets);
 285     void linkBlocks(Vector&lt;BasicBlock*&gt;&amp; unlinkedBlocks, Vector&lt;BasicBlock*&gt;&amp; possibleTargets);
 286 
<span class="line-modified"> 287     void progressToNextCheckpoint()</span>
<span class="line-added"> 288     {</span>
<span class="line-added"> 289         m_currentIndex = BytecodeIndex(m_currentIndex.offset(), m_currentIndex.checkpoint() + 1);</span>
<span class="line-added"> 290         // At this point, it&#39;s again OK to OSR exit.</span>
<span class="line-added"> 291         m_exitOK = true;</span>
<span class="line-added"> 292         addToGraph(ExitOK);</span>
<span class="line-added"> 293 </span>
<span class="line-added"> 294         processSetLocalQueue();</span>
<span class="line-added"> 295     }</span>
<span class="line-added"> 296 </span>
<span class="line-added"> 297     VariableAccessData* newVariableAccessData(Operand operand)</span>
 298     {
 299         ASSERT(!operand.isConstant());
 300 
 301         m_graph.m_variableAccessData.append(operand);
 302         return &amp;m_graph.m_variableAccessData.last();
 303     }
 304 
 305     // Get/Set the operands/result of a bytecode instruction.
<span class="line-modified"> 306     Node* getDirect(Operand operand)</span>
 307     {
 308         ASSERT(!operand.isConstant());
 309 

 310         if (operand.isArgument())
<span class="line-modified"> 311             return getArgument(operand.virtualRegister());</span>
 312 
<span class="line-modified"> 313         return getLocalOrTmp(operand);</span>

 314     }
 315 
 316     Node* get(VirtualRegister operand)
 317     {
 318         if (operand.isConstant()) {
 319             unsigned constantIndex = operand.toConstantIndex();
 320             unsigned oldSize = m_constants.size();
 321             if (constantIndex &gt;= oldSize || !m_constants[constantIndex]) {
 322                 const CodeBlock&amp; codeBlock = *m_inlineStackTop-&gt;m_codeBlock;
<span class="line-modified"> 323                 JSValue value = codeBlock.getConstant(operand);</span>
<span class="line-modified"> 324                 SourceCodeRepresentation sourceCodeRepresentation = codeBlock.constantSourceCodeRepresentation(operand);</span>
 325                 if (constantIndex &gt;= oldSize) {
 326                     m_constants.grow(constantIndex + 1);
 327                     for (unsigned i = oldSize; i &lt; m_constants.size(); ++i)
 328                         m_constants[i] = nullptr;
 329                 }
 330 
 331                 Node* constantNode = nullptr;
 332                 if (sourceCodeRepresentation == SourceCodeRepresentation::Double)
 333                     constantNode = addToGraph(DoubleConstant, OpInfo(m_graph.freezeStrong(jsDoubleNumber(value.asNumber()))));
 334                 else
 335                     constantNode = addToGraph(JSConstant, OpInfo(m_graph.freezeStrong(value)));
 336                 m_constants[constantIndex] = constantNode;
 337             }
 338             ASSERT(m_constants[constantIndex]);
 339             return m_constants[constantIndex];
 340         }
 341 
 342         if (inlineCallFrame()) {
 343             if (!inlineCallFrame()-&gt;isClosureCall) {
 344                 JSFunction* callee = inlineCallFrame()-&gt;calleeConstant();
</pre>
<hr />
<pre>
 363 
 364     enum SetMode {
 365         // A normal set which follows a two-phase commit that spans code origins. During
 366         // the current code origin it issues a MovHint, and at the start of the next
 367         // code origin there will be a SetLocal. If the local needs flushing, the second
 368         // SetLocal will be preceded with a Flush.
 369         NormalSet,
 370 
 371         // A set where the SetLocal happens immediately and there is still a Flush. This
 372         // is relevant when assigning to a local in tricky situations for the delayed
 373         // SetLocal logic but where we know that we have not performed any side effects
 374         // within this code origin. This is a safe replacement for NormalSet anytime we
 375         // know that we have not yet performed side effects in this code origin.
 376         ImmediateSetWithFlush,
 377 
 378         // A set where the SetLocal happens immediately and we do not Flush it even if
 379         // this is a local that is marked as needing it. This is relevant when
 380         // initializing locals at the top of a function.
 381         ImmediateNakedSet
 382     };
<span class="line-modified"> 383 </span>
<span class="line-added"> 384     Node* setDirect(Operand operand, Node* value, SetMode setMode = NormalSet)</span>
 385     {
<span class="line-modified"> 386         addToGraph(MovHint, OpInfo(operand), value);</span>
 387 
 388         // We can&#39;t exit anymore because our OSR exit state has changed.
 389         m_exitOK = false;
 390 
 391         DelayedSetLocal delayed(currentCodeOrigin(), operand, value, setMode);
 392 
 393         if (setMode == NormalSet) {
 394             m_setLocalQueue.append(delayed);
 395             return nullptr;
 396         }
 397 
 398         return delayed.execute(this);
 399     }
 400 
 401     void processSetLocalQueue()
 402     {
 403         for (unsigned i = 0; i &lt; m_setLocalQueue.size(); ++i)
 404             m_setLocalQueue[i].execute(this);
 405         m_setLocalQueue.shrink(0);
 406     }
 407 
 408     Node* set(VirtualRegister operand, Node* value, SetMode setMode = NormalSet)
 409     {
 410         return setDirect(m_inlineStackTop-&gt;remapOperand(operand), value, setMode);
 411     }
 412 
 413     Node* injectLazyOperandSpeculation(Node* node)
 414     {
 415         ASSERT(node-&gt;op() == GetLocal);
 416         ASSERT(node-&gt;origin.semantic.bytecodeIndex() == m_currentIndex);
 417         ConcurrentJSLocker locker(m_inlineStackTop-&gt;m_profiledBlock-&gt;m_lock);
<span class="line-modified"> 418         LazyOperandValueProfileKey key(m_currentIndex, node-&gt;operand());</span>
 419         SpeculatedType prediction = m_inlineStackTop-&gt;m_lazyOperands.prediction(locker, key);
 420         node-&gt;variableAccessData()-&gt;predict(prediction);
 421         return node;
 422     }
 423 
 424     // Used in implementing get/set, above, where the operand is a local variable.
<span class="line-modified"> 425     Node* getLocalOrTmp(Operand operand)</span>
 426     {
<span class="line-modified"> 427         ASSERT(operand.isTmp() || operand.isLocal());</span>
<span class="line-modified"> 428         Node*&amp; node = m_currentBlock-&gt;variablesAtTail.operand(operand);</span>

 429 
 430         // This has two goals: 1) link together variable access datas, and 2)
 431         // try to avoid creating redundant GetLocals. (1) is required for
 432         // correctness - no other phase will ensure that block-local variable
 433         // access data unification is done correctly. (2) is purely opportunistic
 434         // and is meant as an compile-time optimization only.
 435 
 436         VariableAccessData* variable;
 437 
 438         if (node) {
 439             variable = node-&gt;variableAccessData();
 440 
 441             switch (node-&gt;op()) {
 442             case GetLocal:
 443                 return node;
 444             case SetLocal:
 445                 return node-&gt;child1().node();
 446             default:
 447                 break;
 448             }
 449         } else
 450             variable = newVariableAccessData(operand);
 451 
 452         node = injectLazyOperandSpeculation(addToGraph(GetLocal, OpInfo(variable)));

 453         return node;
 454     }
<span class="line-modified"> 455     Node* setLocalOrTmp(const CodeOrigin&amp; semanticOrigin, Operand operand, Node* value, SetMode setMode = NormalSet)</span>
 456     {
<span class="line-added"> 457         ASSERT(operand.isTmp() || operand.isLocal());</span>
 458         SetForScope&lt;CodeOrigin&gt; originChange(m_currentSemanticOrigin, semanticOrigin);
 459 
<span class="line-modified"> 460         if (operand.isTmp() &amp;&amp; static_cast&lt;unsigned&gt;(operand.value()) &gt;= m_numTmps) {</span>
<span class="line-added"> 461             if (inlineCallFrame())</span>
<span class="line-added"> 462                 dataLogLn(*inlineCallFrame());</span>
<span class="line-added"> 463             dataLogLn(&quot;Bad operand: &quot;, operand, &quot; but current number of tmps is: &quot;, m_numTmps, &quot; code block has: &quot;, m_profiledBlock-&gt;numTmps(), &quot; tmps.&quot;);</span>
<span class="line-added"> 464             CRASH();</span>
<span class="line-added"> 465         }</span>
 466 
<span class="line-modified"> 467         if (setMode != ImmediateNakedSet &amp;&amp; !operand.isTmp()) {</span>
<span class="line-modified"> 468             VirtualRegister reg = operand.virtualRegister();</span>
<span class="line-added"> 469             ArgumentPosition* argumentPosition = findArgumentPositionForLocal(reg);</span>
 470             if (argumentPosition)
 471                 flushDirect(operand, argumentPosition);
<span class="line-modified"> 472             else if (m_graph.needsScopeRegister() &amp;&amp; reg == m_codeBlock-&gt;scopeRegister())</span>
 473                 flush(operand);
 474         }
 475 
 476         VariableAccessData* variableAccessData = newVariableAccessData(operand);
 477         variableAccessData-&gt;mergeStructureCheckHoistingFailed(
 478             m_inlineStackTop-&gt;m_exitProfile.hasExitSite(semanticOrigin.bytecodeIndex(), BadCache));
 479         variableAccessData-&gt;mergeCheckArrayHoistingFailed(
 480             m_inlineStackTop-&gt;m_exitProfile.hasExitSite(semanticOrigin.bytecodeIndex(), BadIndexingType));
 481         Node* node = addToGraph(SetLocal, OpInfo(variableAccessData), value);
<span class="line-modified"> 482         m_currentBlock-&gt;variablesAtTail.operand(operand) = node;</span>
 483         return node;
 484     }
 485 
 486     // Used in implementing get/set, above, where the operand is an argument.
 487     Node* getArgument(VirtualRegister operand)
 488     {
 489         unsigned argument = operand.toArgument();
 490         ASSERT(argument &lt; m_numArguments);
 491 
 492         Node* node = m_currentBlock-&gt;variablesAtTail.argument(argument);
 493 
 494         VariableAccessData* variable;
 495 
 496         if (node) {
 497             variable = node-&gt;variableAccessData();
 498 
 499             switch (node-&gt;op()) {
 500             case GetLocal:
 501                 return node;
 502             case SetLocal:
 503                 return node-&gt;child1().node();
 504             default:
 505                 break;
 506             }
 507         } else
 508             variable = newVariableAccessData(operand);
 509 
 510         node = injectLazyOperandSpeculation(addToGraph(GetLocal, OpInfo(variable)));
 511         m_currentBlock-&gt;variablesAtTail.argument(argument) = node;
 512         return node;
 513     }
<span class="line-modified"> 514     Node* setArgument(const CodeOrigin&amp; semanticOrigin, Operand operand, Node* value, SetMode setMode = NormalSet)</span>
 515     {
 516         SetForScope&lt;CodeOrigin&gt; originChange(m_currentSemanticOrigin, semanticOrigin);
 517 
<span class="line-modified"> 518         VirtualRegister reg = operand.virtualRegister();</span>
<span class="line-added"> 519         unsigned argument = reg.toArgument();</span>
 520         ASSERT(argument &lt; m_numArguments);
 521 
<span class="line-modified"> 522         VariableAccessData* variableAccessData = newVariableAccessData(reg);</span>
 523 
 524         // Always flush arguments, except for &#39;this&#39;. If &#39;this&#39; is created by us,
 525         // then make sure that it&#39;s never unboxed.
 526         if (argument || m_graph.needsFlushedThis()) {
 527             if (setMode != ImmediateNakedSet)
<span class="line-modified"> 528                 flushDirect(reg);</span>
 529         }
 530 
 531         if (!argument &amp;&amp; m_codeBlock-&gt;specializationKind() == CodeForConstruct)
 532             variableAccessData-&gt;mergeShouldNeverUnbox(true);
 533 
 534         variableAccessData-&gt;mergeStructureCheckHoistingFailed(
 535             m_inlineStackTop-&gt;m_exitProfile.hasExitSite(semanticOrigin.bytecodeIndex(), BadCache));
 536         variableAccessData-&gt;mergeCheckArrayHoistingFailed(
 537             m_inlineStackTop-&gt;m_exitProfile.hasExitSite(semanticOrigin.bytecodeIndex(), BadIndexingType));
 538         Node* node = addToGraph(SetLocal, OpInfo(variableAccessData), value);
 539         m_currentBlock-&gt;variablesAtTail.argument(argument) = node;
 540         return node;
 541     }
 542 
 543     ArgumentPosition* findArgumentPositionForArgument(int argument)
 544     {
 545         InlineStackEntry* stack = m_inlineStackTop;
 546         while (stack-&gt;m_inlineCallFrame)
 547             stack = stack-&gt;m_caller;
 548         return stack-&gt;m_argumentPositions[argument];
 549     }
 550 
 551     ArgumentPosition* findArgumentPositionForLocal(VirtualRegister operand)
 552     {
 553         for (InlineStackEntry* stack = m_inlineStackTop; ; stack = stack-&gt;m_caller) {
 554             InlineCallFrame* inlineCallFrame = stack-&gt;m_inlineCallFrame;
 555             if (!inlineCallFrame)
 556                 break;
 557             if (operand.offset() &lt; static_cast&lt;int&gt;(inlineCallFrame-&gt;stackOffset + CallFrame::headerSizeInRegisters))
 558                 continue;
 559             if (operand.offset() &gt;= static_cast&lt;int&gt;(inlineCallFrame-&gt;stackOffset + CallFrame::thisArgumentOffset() + inlineCallFrame-&gt;argumentsWithFixup.size()))
 560                 continue;
 561             int argument = VirtualRegister(operand.offset() - inlineCallFrame-&gt;stackOffset).toArgument();
 562             return stack-&gt;m_argumentPositions[argument];
 563         }
<span class="line-modified"> 564         return nullptr;</span>
 565     }
 566 
<span class="line-modified"> 567     ArgumentPosition* findArgumentPosition(Operand operand)</span>
 568     {
<span class="line-added"> 569         if (operand.isTmp())</span>
<span class="line-added"> 570             return nullptr;</span>
 571         if (operand.isArgument())
 572             return findArgumentPositionForArgument(operand.toArgument());
<span class="line-modified"> 573         return findArgumentPositionForLocal(operand.virtualRegister());</span>
 574     }
 575 
 576     template&lt;typename AddFlushDirectFunc&gt;
 577     void flushImpl(InlineCallFrame* inlineCallFrame, const AddFlushDirectFunc&amp; addFlushDirect)
 578     {
 579         int numArguments;
 580         if (inlineCallFrame) {
 581             ASSERT(!m_graph.hasDebuggerEnabled());
 582             numArguments = inlineCallFrame-&gt;argumentsWithFixup.size();
 583             if (inlineCallFrame-&gt;isClosureCall)
<span class="line-modified"> 584                 addFlushDirect(inlineCallFrame, remapOperand(inlineCallFrame, CallFrameSlot::callee));</span>
 585             if (inlineCallFrame-&gt;isVarargs())
<span class="line-modified"> 586                 addFlushDirect(inlineCallFrame, remapOperand(inlineCallFrame, CallFrameSlot::argumentCountIncludingThis));</span>
 587         } else
 588             numArguments = m_graph.baselineCodeBlockFor(inlineCallFrame)-&gt;numParameters();
 589 
 590         for (unsigned argument = numArguments; argument--;)
<span class="line-modified"> 591             addFlushDirect(inlineCallFrame, remapOperand(inlineCallFrame, virtualRegisterForArgumentIncludingThis(argument)));</span>
 592 
 593         if (m_graph.needsScopeRegister())
 594             addFlushDirect(nullptr, m_graph.m_codeBlock-&gt;scopeRegister());
 595     }
 596 
 597     template&lt;typename AddFlushDirectFunc, typename AddPhantomLocalDirectFunc&gt;
 598     void flushForTerminalImpl(CodeOrigin origin, const AddFlushDirectFunc&amp; addFlushDirect, const AddPhantomLocalDirectFunc&amp; addPhantomLocalDirect)
 599     {
<span class="line-added"> 600         bool isCallerOrigin = false;</span>
 601         origin.walkUpInlineStack(
 602             [&amp;] (CodeOrigin origin) {
<span class="line-modified"> 603                 BytecodeIndex bytecodeIndex = origin.bytecodeIndex();</span>
 604                 InlineCallFrame* inlineCallFrame = origin.inlineCallFrame();
 605                 flushImpl(inlineCallFrame, addFlushDirect);
 606 
 607                 CodeBlock* codeBlock = m_graph.baselineCodeBlockFor(inlineCallFrame);
 608                 FullBytecodeLiveness&amp; fullLiveness = m_graph.livenessFor(codeBlock);
<span class="line-modified"> 609                 // Note: We don&#39;t need to handle tmps here because tmps are not required to be flushed to the stack.</span>
<span class="line-modified"> 610                 const auto&amp; livenessAtBytecode = fullLiveness.getLiveness(bytecodeIndex, m_graph.appropriateLivenessCalculationPoint(origin, isCallerOrigin));</span>
 611                 for (unsigned local = codeBlock-&gt;numCalleeLocals(); local--;) {
 612                     if (livenessAtBytecode[local])
 613                         addPhantomLocalDirect(inlineCallFrame, remapOperand(inlineCallFrame, virtualRegisterForLocal(local)));
 614                 }
<span class="line-added"> 615                 isCallerOrigin = true;</span>
 616             });
 617     }
 618 
<span class="line-modified"> 619     void flush(Operand operand)</span>
 620     {
 621         flushDirect(m_inlineStackTop-&gt;remapOperand(operand));
 622     }
 623 
<span class="line-modified"> 624     void flushDirect(Operand operand)</span>
 625     {
 626         flushDirect(operand, findArgumentPosition(operand));
 627     }
 628 
<span class="line-modified"> 629     void flushDirect(Operand operand, ArgumentPosition* argumentPosition)</span>
 630     {
 631         addFlushOrPhantomLocal&lt;Flush&gt;(operand, argumentPosition);
 632     }
 633 
 634     template&lt;NodeType nodeType&gt;
<span class="line-modified"> 635     void addFlushOrPhantomLocal(Operand operand, ArgumentPosition* argumentPosition)</span>
 636     {
 637         ASSERT(!operand.isConstant());
 638 
<span class="line-modified"> 639         Node*&amp; node = m_currentBlock-&gt;variablesAtTail.operand(operand);</span>
 640 
 641         VariableAccessData* variable;
 642 
 643         if (node)
 644             variable = node-&gt;variableAccessData();
 645         else
 646             variable = newVariableAccessData(operand);
 647 
 648         node = addToGraph(nodeType, OpInfo(variable));

 649         if (argumentPosition)
 650             argumentPosition-&gt;addVariable(variable);
 651     }
 652 
<span class="line-modified"> 653     void phantomLocalDirect(Operand operand)</span>
 654     {
 655         addFlushOrPhantomLocal&lt;PhantomLocal&gt;(operand, findArgumentPosition(operand));
 656     }
 657 
 658     void flush(InlineStackEntry* inlineStackEntry)
 659     {
<span class="line-modified"> 660         auto addFlushDirect = [&amp;] (InlineCallFrame*, Operand operand) { flushDirect(operand); };</span>
 661         flushImpl(inlineStackEntry-&gt;m_inlineCallFrame, addFlushDirect);
 662     }
 663 
 664     void flushForTerminal()
 665     {
<span class="line-modified"> 666         auto addFlushDirect = [&amp;] (InlineCallFrame*, Operand operand) { flushDirect(operand); };</span>
<span class="line-modified"> 667         auto addPhantomLocalDirect = [&amp;] (InlineCallFrame*, Operand operand) { phantomLocalDirect(operand); };</span>
 668         flushForTerminalImpl(currentCodeOrigin(), addFlushDirect, addPhantomLocalDirect);
 669     }
 670 
 671     void flushForReturn()
 672     {
 673         flush(m_inlineStackTop);
 674     }
 675 
 676     void flushIfTerminal(SwitchData&amp; data)
 677     {
<span class="line-modified"> 678         if (data.fallThrough.bytecodeIndex() &gt; m_currentIndex.offset())</span>
 679             return;
 680 
 681         for (unsigned i = data.cases.size(); i--;) {
<span class="line-modified"> 682             if (data.cases[i].target.bytecodeIndex() &gt; m_currentIndex.offset())</span>
 683                 return;
 684         }
 685 
 686         flushForTerminal();
 687     }
 688 
 689     // Assumes that the constant should be strongly marked.
 690     Node* jsConstant(JSValue constantValue)
 691     {
 692         return addToGraph(JSConstant, OpInfo(m_graph.freezeStrong(constantValue)));
 693     }
 694 
 695     Node* weakJSConstant(JSValue constantValue)
 696     {
 697         return addToGraph(JSConstant, OpInfo(m_graph.freeze(constantValue)));
 698     }
 699 
 700     // Helper functions to get/set the this value.
 701     Node* getThis()
 702     {
</pre>
<hr />
<pre>
 725 
 726     NodeOrigin currentNodeOrigin()
 727     {
 728         CodeOrigin semantic;
 729         CodeOrigin forExit;
 730 
 731         if (m_currentSemanticOrigin.isSet())
 732             semantic = m_currentSemanticOrigin;
 733         else
 734             semantic = currentCodeOrigin();
 735 
 736         forExit = currentCodeOrigin();
 737 
 738         return NodeOrigin(semantic, forExit, m_exitOK);
 739     }
 740 
 741     BranchData* branchData(unsigned taken, unsigned notTaken)
 742     {
 743         // We assume that branches originating from bytecode always have a fall-through. We
 744         // use this assumption to avoid checking for the creation of terminal blocks.
<span class="line-modified"> 745         ASSERT((taken &gt; m_currentIndex.offset()) || (notTaken &gt; m_currentIndex.offset()));</span>
 746         BranchData* data = m_graph.m_branchData.add();
 747         *data = BranchData::withBytecodeIndices(taken, notTaken);
 748         return data;
 749     }
 750 
 751     Node* addToGraph(Node* node)
 752     {
 753         VERBOSE_LOG(&quot;        appended &quot;, node, &quot; &quot;, Graph::opName(node-&gt;op()), &quot;\n&quot;);
 754 
 755         m_hasAnyForceOSRExits |= (node-&gt;op() == ForceOSRExit);
 756 
 757         m_currentBlock-&gt;append(node);
 758         if (clobbersExitState(m_graph, node))
 759             m_exitOK = false;
 760         return node;
 761     }
 762 
 763     Node* addToGraph(NodeType op, Node* child1 = 0, Node* child2 = 0, Node* child3 = 0)
 764     {
 765         Node* result = m_graph.addNode(
</pre>
<hr />
<pre>
 775     }
 776     Node* addToGraph(NodeType op, OpInfo info, Node* child1 = 0, Node* child2 = 0, Node* child3 = 0)
 777     {
 778         Node* result = m_graph.addNode(
 779             op, currentNodeOrigin(), info, Edge(child1), Edge(child2),
 780             Edge(child3));
 781         return addToGraph(result);
 782     }
 783     Node* addToGraph(NodeType op, OpInfo info, Edge child1, Edge child2 = Edge(), Edge child3 = Edge())
 784     {
 785         Node* result = m_graph.addNode(op, currentNodeOrigin(), info, child1, child2, child3);
 786         return addToGraph(result);
 787     }
 788     Node* addToGraph(NodeType op, OpInfo info1, OpInfo info2, Node* child1 = 0, Node* child2 = 0, Node* child3 = 0)
 789     {
 790         Node* result = m_graph.addNode(
 791             op, currentNodeOrigin(), info1, info2,
 792             Edge(child1), Edge(child2), Edge(child3));
 793         return addToGraph(result);
 794     }
<span class="line-added"> 795     Node* addToGraph(NodeType op, Operand operand, Node* child1)</span>
<span class="line-added"> 796     {</span>
<span class="line-added"> 797         ASSERT(op == MovHint);</span>
<span class="line-added"> 798         return addToGraph(op, OpInfo(operand.kind()), OpInfo(operand.value()), child1);</span>
<span class="line-added"> 799     }</span>
 800     Node* addToGraph(NodeType op, OpInfo info1, OpInfo info2, Edge child1, Edge child2 = Edge(), Edge child3 = Edge())
 801     {
 802         Node* result = m_graph.addNode(
 803             op, currentNodeOrigin(), info1, info2, child1, child2, child3);
 804         return addToGraph(result);
 805     }
 806 
 807     Node* addToGraph(Node::VarArgTag, NodeType op, OpInfo info1, OpInfo info2 = OpInfo())
 808     {
 809         Node* result = m_graph.addNode(
 810             Node::VarArg, op, currentNodeOrigin(), info1, info2,
 811             m_graph.m_varArgChildren.size() - m_numPassedVarArgs, m_numPassedVarArgs);
 812         addToGraph(result);
 813 
 814         m_numPassedVarArgs = 0;
 815 
 816         return result;
 817     }
 818 
 819     void addVarArgChild(Node* child)
</pre>
<hr />
<pre>
 822         m_numPassedVarArgs++;
 823     }
 824 
 825     void addVarArgChild(Edge child)
 826     {
 827         m_graph.m_varArgChildren.append(child);
 828         m_numPassedVarArgs++;
 829     }
 830 
 831     Node* addCallWithoutSettingResult(
 832         NodeType op, OpInfo opInfo, Node* callee, int argCount, int registerOffset,
 833         OpInfo prediction)
 834     {
 835         addVarArgChild(callee);
 836         size_t parameterSlots = Graph::parameterSlotsForArgCount(argCount);
 837 
 838         if (parameterSlots &gt; m_parameterSlots)
 839             m_parameterSlots = parameterSlots;
 840 
 841         for (int i = 0; i &lt; argCount; ++i)
<span class="line-modified"> 842             addVarArgChild(get(virtualRegisterForArgumentIncludingThis(i, registerOffset)));</span>
 843 
 844         return addToGraph(Node::VarArg, op, opInfo, prediction);
 845     }
 846 
 847     Node* addCall(
 848         VirtualRegister result, NodeType op, const DOMJIT::Signature* signature, Node* callee, int argCount, int registerOffset,
 849         SpeculatedType prediction)
 850     {
 851         if (op == TailCall) {
 852             if (allInlineFramesAreTailCalls())
 853                 return addCallWithoutSettingResult(op, OpInfo(signature), callee, argCount, registerOffset, OpInfo());
 854             op = TailCallInlinedCaller;
 855         }
 856 
 857 
 858         Node* call = addCallWithoutSettingResult(
 859             op, OpInfo(signature), callee, argCount, registerOffset, OpInfo(prediction));
 860         if (result.isValid())
 861             set(result, call);
 862         return call;
 863     }
 864 
 865     Node* cellConstantWithStructureCheck(JSCell* object, Structure* structure)
 866     {
 867         // FIXME: This should route to emitPropertyCheck, not the other way around. But currently,
 868         // this gets no profit from using emitPropertyCheck() since we&#39;ll non-adaptively watch the
 869         // object&#39;s structure as soon as we make it a weakJSCosntant.
 870         Node* objectNode = weakJSConstant(object);
 871         addToGraph(CheckStructure, OpInfo(m_graph.addStructureSet(structure)), objectNode);
 872         return objectNode;
 873     }
 874 
<span class="line-modified"> 875     SpeculatedType getPredictionWithoutOSRExit(BytecodeIndex bytecodeIndex)</span>
 876     {
 877         auto getValueProfilePredictionFromForCodeBlockAndBytecodeOffset = [&amp;] (CodeBlock* codeBlock, const CodeOrigin&amp; codeOrigin)
 878         {
 879             SpeculatedType prediction;
 880             {
 881                 ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
<span class="line-modified"> 882                 prediction = codeBlock-&gt;valueProfilePredictionForBytecodeIndex(locker, codeOrigin.bytecodeIndex());</span>
 883             }
 884             auto* fuzzerAgent = m_vm-&gt;fuzzerAgent();
 885             if (UNLIKELY(fuzzerAgent))
 886                 return fuzzerAgent-&gt;getPrediction(codeBlock, codeOrigin, prediction) &amp; SpecBytecodeTop;
 887             return prediction;
 888         };
 889 
 890         SpeculatedType prediction = getValueProfilePredictionFromForCodeBlockAndBytecodeOffset(m_inlineStackTop-&gt;m_profiledBlock, CodeOrigin(bytecodeIndex, inlineCallFrame()));
 891         if (prediction != SpecNone)
 892             return prediction;
 893 
 894         // If we have no information about the values this
 895         // node generates, we check if by any chance it is
 896         // a tail call opcode. In that case, we walk up the
 897         // inline frames to find a call higher in the call
 898         // chain and use its prediction. If we only have
 899         // inlined tail call frames, we use SpecFullTop
 900         // to avoid a spurious OSR exit.
<span class="line-modified"> 901         auto instruction = m_inlineStackTop-&gt;m_profiledBlock-&gt;instructions().at(bytecodeIndex.offset());</span>
 902         OpcodeID opcodeID = instruction-&gt;opcodeID();
 903 
 904         switch (opcodeID) {
 905         case op_tail_call:
 906         case op_tail_call_varargs:
 907         case op_tail_call_forward_arguments: {
 908             // Things should be more permissive to us returning BOTTOM instead of TOP here.
 909             // Currently, this will cause us to Force OSR exit. This is bad because returning
 910             // TOP will cause anything that transitively touches this speculated type to
 911             // also become TOP during prediction propagation.
 912             // https://bugs.webkit.org/show_bug.cgi?id=164337
 913             if (!inlineCallFrame())
 914                 return SpecFullTop;
 915 
 916             CodeOrigin* codeOrigin = inlineCallFrame()-&gt;getCallerSkippingTailCalls();
 917             if (!codeOrigin)
 918                 return SpecFullTop;
 919 
 920             InlineStackEntry* stack = m_inlineStackTop;
 921             while (stack-&gt;m_inlineCallFrame != codeOrigin-&gt;inlineCallFrame())
 922                 stack = stack-&gt;m_caller;
 923 
 924             return getValueProfilePredictionFromForCodeBlockAndBytecodeOffset(stack-&gt;m_profiledBlock, *codeOrigin);
 925         }
 926 
 927         default:
 928             return SpecNone;
 929         }
 930 
 931         RELEASE_ASSERT_NOT_REACHED();
 932         return SpecNone;
 933     }
 934 
<span class="line-modified"> 935     SpeculatedType getPrediction(BytecodeIndex bytecodeIndex)</span>
 936     {
 937         SpeculatedType prediction = getPredictionWithoutOSRExit(bytecodeIndex);
 938 
 939         if (prediction == SpecNone) {
 940             // We have no information about what values this node generates. Give up
 941             // on executing this code, since we&#39;re likely to do more damage than good.
 942             addToGraph(ForceOSRExit);
 943         }
 944 
 945         return prediction;
 946     }
 947 
 948     SpeculatedType getPredictionWithoutOSRExit()
 949     {
 950         return getPredictionWithoutOSRExit(m_currentIndex);
 951     }
 952 
 953     SpeculatedType getPrediction()
 954     {
 955         return getPrediction(m_currentIndex);
 956     }
 957 
 958     ArrayMode getArrayMode(Array::Action action)
 959     {
 960         CodeBlock* codeBlock = m_inlineStackTop-&gt;m_profiledBlock;
<span class="line-modified"> 961         ArrayProfile* profile = codeBlock-&gt;getArrayProfile(codeBlock-&gt;bytecodeIndex(m_currentInstruction));</span>
 962         return getArrayMode(*profile, action);
 963     }
 964 
 965     ArrayMode getArrayMode(ArrayProfile&amp; profile, Array::Action action)
 966     {
 967         ConcurrentJSLocker locker(m_inlineStackTop-&gt;m_profiledBlock-&gt;m_lock);
 968         profile.computeUpdatedPrediction(locker, m_inlineStackTop-&gt;m_profiledBlock);
 969         bool makeSafe = profile.outOfBounds(locker);
 970         return ArrayMode::fromObserved(locker, &amp;profile, action, makeSafe);
 971     }
 972 
 973     Node* makeSafe(Node* node)
 974     {
 975         if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, Overflow))
 976             node-&gt;mergeFlags(NodeMayOverflowInt32InDFG);
 977         if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, NegativeZero))
 978             node-&gt;mergeFlags(NodeMayNegZeroInDFG);
 979 
 980         if (!isX86() &amp;&amp; (node-&gt;op() == ArithMod || node-&gt;op() == ValueMod))
 981             return node;
 982 
<span class="line-modified"> 983         switch (node-&gt;op()) {</span>
<span class="line-modified"> 984         case ArithAdd:</span>
<span class="line-modified"> 985         case ArithSub:</span>
<span class="line-modified"> 986         case ValueAdd: {</span>
<span class="line-modified"> 987             ObservedResults observed;</span>
<span class="line-modified"> 988             if (BinaryArithProfile* arithProfile = m_inlineStackTop-&gt;m_profiledBlock-&gt;binaryArithProfileForBytecodeIndex(m_currentIndex))</span>
<span class="line-modified"> 989                 observed = arithProfile-&gt;observedResults();</span>
<span class="line-modified"> 990             else if (UnaryArithProfile* arithProfile = m_inlineStackTop-&gt;m_profiledBlock-&gt;unaryArithProfileForBytecodeIndex(m_currentIndex)) {</span>
<span class="line-modified"> 991                 // Happens for OpInc/OpDec</span>
<span class="line-modified"> 992                 observed = arithProfile-&gt;observedResults();</span>
<span class="line-modified"> 993             } else</span>
<span class="line-modified"> 994                 break;</span>


 995 
<span class="line-modified"> 996             if (observed.didObserveDouble())</span>
<span class="line-modified"> 997                 node-&gt;mergeFlags(NodeMayHaveDoubleResult);</span>
<span class="line-modified"> 998             if (observed.didObserveNonNumeric())</span>
<span class="line-modified"> 999                 node-&gt;mergeFlags(NodeMayHaveNonNumericResult);</span>
<span class="line-modified">1000             if (observed.didObserveBigInt())</span>
<span class="line-modified">1001                 node-&gt;mergeFlags(NodeMayHaveBigIntResult);</span>
<span class="line-modified">1002             break;</span>
<span class="line-modified">1003         }</span>
<span class="line-modified">1004         case ValueMul:</span>
<span class="line-modified">1005         case ArithMul: {</span>
<span class="line-modified">1006             BinaryArithProfile* arithProfile = m_inlineStackTop-&gt;m_profiledBlock-&gt;binaryArithProfileForBytecodeIndex(m_currentIndex);</span>
<span class="line-modified">1007             if (!arithProfile)</span>
<span class="line-modified">1008                 break;</span>
<span class="line-modified">1009             if (arithProfile-&gt;didObserveInt52Overflow())</span>
<span class="line-modified">1010                 node-&gt;mergeFlags(NodeMayOverflowInt52);</span>
<span class="line-modified">1011             if (arithProfile-&gt;didObserveInt32Overflow() || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, Overflow))</span>
<span class="line-modified">1012                 node-&gt;mergeFlags(NodeMayOverflowInt32InBaseline);</span>
<span class="line-modified">1013             if (arithProfile-&gt;didObserveNegZeroDouble() || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, NegativeZero))</span>
<span class="line-modified">1014                 node-&gt;mergeFlags(NodeMayNegZeroInBaseline);</span>
<span class="line-modified">1015             if (arithProfile-&gt;didObserveDouble())</span>
<span class="line-modified">1016                 node-&gt;mergeFlags(NodeMayHaveDoubleResult);</span>
<span class="line-modified">1017             if (arithProfile-&gt;didObserveNonNumeric())</span>
<span class="line-modified">1018                 node-&gt;mergeFlags(NodeMayHaveNonNumericResult);</span>
<span class="line-modified">1019             if (arithProfile-&gt;didObserveBigInt())</span>
<span class="line-modified">1020                 node-&gt;mergeFlags(NodeMayHaveBigIntResult);</span>
<span class="line-modified">1021             break;</span>
<span class="line-modified">1022         }</span>
<span class="line-modified">1023         case ValueNegate:</span>
<span class="line-modified">1024         case ArithNegate:</span>
<span class="line-modified">1025         case Inc:</span>
<span class="line-added">1026         case Dec: {</span>
<span class="line-added">1027             UnaryArithProfile* arithProfile = m_inlineStackTop-&gt;m_profiledBlock-&gt;unaryArithProfileForBytecodeIndex(m_currentIndex);</span>
<span class="line-added">1028             if (!arithProfile)</span>
<span class="line-added">1029                 break;</span>
<span class="line-added">1030             if (arithProfile-&gt;argObservedType().sawNumber() || arithProfile-&gt;didObserveDouble())</span>
<span class="line-added">1031                 node-&gt;mergeFlags(NodeMayHaveDoubleResult);</span>
<span class="line-added">1032             if (arithProfile-&gt;didObserveNegZeroDouble() || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, NegativeZero))</span>
<span class="line-added">1033                 node-&gt;mergeFlags(NodeMayNegZeroInBaseline);</span>
<span class="line-added">1034             if (arithProfile-&gt;didObserveInt32Overflow() || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, Overflow))</span>
<span class="line-added">1035                 node-&gt;mergeFlags(NodeMayOverflowInt32InBaseline);</span>
<span class="line-added">1036             if (arithProfile-&gt;didObserveNonNumeric())</span>
<span class="line-added">1037                 node-&gt;mergeFlags(NodeMayHaveNonNumericResult);</span>
<span class="line-added">1038             if (arithProfile-&gt;didObserveBigInt())</span>
<span class="line-added">1039                 node-&gt;mergeFlags(NodeMayHaveBigIntResult);</span>
<span class="line-added">1040             break;</span>
<span class="line-added">1041         }</span>
1042 
<span class="line-modified">1043         default:</span>
<span class="line-modified">1044             break;</span>


1045         }
1046 
1047         if (m_inlineStackTop-&gt;m_profiledBlock-&gt;likelyToTakeSlowCase(m_currentIndex)) {
1048             switch (node-&gt;op()) {
1049             case UInt32ToNumber:
1050             case ArithAdd:
1051             case ArithSub:
1052             case ValueAdd:
1053             case ValueMod:
1054             case ArithMod: // for ArithMod &quot;MayOverflow&quot; means we tried to divide by zero, or we saw double.
1055                 node-&gt;mergeFlags(NodeMayOverflowInt32InBaseline);
1056                 break;
1057 
1058             default:
1059                 break;
1060             }
1061         }
1062 
1063         return node;
1064     }
1065 
1066     Node* makeDivSafe(Node* node)
1067     {
1068         ASSERT(node-&gt;op() == ArithDiv || node-&gt;op() == ValueDiv);
1069 
1070         if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, Overflow))
1071             node-&gt;mergeFlags(NodeMayOverflowInt32InDFG);
1072         if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, NegativeZero))
1073             node-&gt;mergeFlags(NodeMayNegZeroInDFG);
1074 
1075         // The main slow case counter for op_div in the old JIT counts only when
1076         // the operands are not numbers. We don&#39;t care about that since we already
1077         // have speculations in place that take care of that separately. We only
1078         // care about when the outcome of the division is not an integer, which
1079         // is what the special fast case counter tells us.
1080 
<span class="line-modified">1081         if (!m_inlineStackTop-&gt;m_profiledBlock-&gt;couldTakeSpecialArithFastCase(m_currentIndex))</span>
1082             return node;
1083 
1084         // FIXME: It might be possible to make this more granular.
1085         node-&gt;mergeFlags(NodeMayOverflowInt32InBaseline | NodeMayNegZeroInBaseline);
1086 
<span class="line-modified">1087         BinaryArithProfile* arithProfile = m_inlineStackTop-&gt;m_profiledBlock-&gt;binaryArithProfileForBytecodeIndex(m_currentIndex);</span>
1088         if (arithProfile-&gt;didObserveBigInt())
1089             node-&gt;mergeFlags(NodeMayHaveBigIntResult);
1090 
1091         return node;
1092     }
1093 
1094     void noticeArgumentsUse()
1095     {
1096         // All of the arguments in this function need to be formatted as JSValues because we will
1097         // load from them in a random-access fashion and we don&#39;t want to have to switch on
1098         // format.
1099 
1100         for (ArgumentPosition* argument : m_inlineStackTop-&gt;m_argumentPositions)
1101             argument-&gt;mergeShouldNeverUnbox(true);
1102     }
1103 
1104     bool needsDynamicLookup(ResolveType, OpcodeID);
1105 
1106     VM* m_vm;
1107     CodeBlock* m_codeBlock;
1108     CodeBlock* m_profiledBlock;
1109     Graph&amp; m_graph;
1110 
1111     // The current block being generated.
1112     BasicBlock* m_currentBlock;
1113     // The bytecode index of the current instruction being generated.
<span class="line-modified">1114     BytecodeIndex m_currentIndex;</span>
1115     // The semantic origin of the current node if different from the current Index.
1116     CodeOrigin m_currentSemanticOrigin;
1117     // True if it&#39;s OK to OSR exit right now.
1118     bool m_exitOK { false };
1119 
1120     FrozenValue* m_constantUndefined;
1121     FrozenValue* m_constantNull;
1122     FrozenValue* m_constantNaN;
1123     FrozenValue* m_constantOne;
1124     Vector&lt;Node*, 16&gt; m_constants;
1125 
1126     HashMap&lt;InlineCallFrame*, Vector&lt;ArgumentPosition*&gt;, WTF::DefaultHash&lt;InlineCallFrame*&gt;::Hash, WTF::NullableHashTraits&lt;InlineCallFrame*&gt;&gt; m_inlineCallFrameToArgumentPositions;
1127 
1128     // The number of arguments passed to the function.
1129     unsigned m_numArguments;
<span class="line-modified">1130     // The number of locals (vars + temporaries) used by the bytecode for the function.</span>
1131     unsigned m_numLocals;
<span class="line-added">1132     // The max number of temps used for forwarding data to an OSR exit checkpoint.</span>
<span class="line-added">1133     unsigned m_numTmps;</span>
1134     // The number of slots (in units of sizeof(Register)) that we need to
1135     // preallocate for arguments to outgoing calls from this frame. This
1136     // number includes the CallFrame slots that we initialize for the callee
1137     // (but not the callee-initialized CallerFrame and ReturnPC slots).
1138     // This number is 0 if and only if this function is a leaf.
1139     unsigned m_parameterSlots;
1140     // The number of var args passed to the next var arg node.
1141     unsigned m_numPassedVarArgs;
1142 
1143     struct InlineStackEntry {
1144         ByteCodeParser* m_byteCodeParser;
1145 
1146         CodeBlock* m_codeBlock;
1147         CodeBlock* m_profiledBlock;
1148         InlineCallFrame* m_inlineCallFrame;
1149 
1150         ScriptExecutable* executable() { return m_codeBlock-&gt;ownerExecutable(); }
1151 
1152         QueryableExitProfile m_exitProfile;
1153 
</pre>
<hr />
<pre>
1180         ICStatusContext m_optimizedContext;
1181 
1182         // Pointers to the argument position trackers for this slice of code.
1183         Vector&lt;ArgumentPosition*&gt; m_argumentPositions;
1184 
1185         InlineStackEntry* m_caller;
1186 
1187         InlineStackEntry(
1188             ByteCodeParser*,
1189             CodeBlock*,
1190             CodeBlock* profiledBlock,
1191             JSFunction* callee, // Null if this is a closure call.
1192             VirtualRegister returnValueVR,
1193             VirtualRegister inlineCallFrameStart,
1194             int argumentCountIncludingThis,
1195             InlineCallFrame::Kind,
1196             BasicBlock* continuationBlock);
1197 
1198         ~InlineStackEntry();
1199 
<span class="line-modified">1200         Operand remapOperand(Operand operand) const</span>
1201         {
1202             if (!m_inlineCallFrame)
1203                 return operand;
1204 
<span class="line-modified">1205             if (operand.isTmp())</span>
<span class="line-added">1206                 return Operand::tmp(operand.value() + m_inlineCallFrame-&gt;tmpOffset);</span>
1207 
<span class="line-modified">1208             ASSERT(!operand.virtualRegister().isConstant());</span>
<span class="line-added">1209 </span>
<span class="line-added">1210             return operand.virtualRegister() + m_inlineCallFrame-&gt;stackOffset;</span>
1211         }
1212     };
1213 
1214     InlineStackEntry* m_inlineStackTop;
1215 
1216     ICStatusContextStack m_icContextStack;
1217 
1218     struct DelayedSetLocal {





1219         DelayedSetLocal() { }
<span class="line-modified">1220         DelayedSetLocal(const CodeOrigin&amp; origin, Operand operand, Node* value, SetMode setMode)</span>
1221             : m_origin(origin)
1222             , m_operand(operand)
1223             , m_value(value)
1224             , m_setMode(setMode)
1225         {
1226             RELEASE_ASSERT(operand.isValid());
1227         }
1228 
1229         Node* execute(ByteCodeParser* parser)
1230         {
1231             if (m_operand.isArgument())
1232                 return parser-&gt;setArgument(m_origin, m_operand, m_value, m_setMode);
<span class="line-modified">1233             return parser-&gt;setLocalOrTmp(m_origin, m_operand, m_value, m_setMode);</span>
1234         }
<span class="line-added">1235 </span>
<span class="line-added">1236         CodeOrigin m_origin;</span>
<span class="line-added">1237         Operand m_operand;</span>
<span class="line-added">1238         Node* m_value { nullptr };</span>
<span class="line-added">1239         SetMode m_setMode;</span>
1240     };
1241 
1242     Vector&lt;DelayedSetLocal, 2&gt; m_setLocalQueue;
1243 
1244     const Instruction* m_currentInstruction;
1245     bool m_hasDebuggerEnabled;
1246     bool m_hasAnyForceOSRExits { false };
1247 };
1248 
<span class="line-modified">1249 BasicBlock* ByteCodeParser::allocateTargetableBlock(BytecodeIndex bytecodeIndex)</span>
1250 {
<span class="line-modified">1251     ASSERT(bytecodeIndex);</span>
<span class="line-modified">1252     Ref&lt;BasicBlock&gt; block = adoptRef(*new BasicBlock(bytecodeIndex, m_numArguments, m_numLocals, m_numTmps, 1));</span>
1253     BasicBlock* blockPtr = block.ptr();
1254     // m_blockLinkingTargets must always be sorted in increasing order of bytecodeBegin
1255     if (m_inlineStackTop-&gt;m_blockLinkingTargets.size())
<span class="line-modified">1256         ASSERT(m_inlineStackTop-&gt;m_blockLinkingTargets.last()-&gt;bytecodeBegin.offset() &lt; bytecodeIndex.offset());</span>
1257     m_inlineStackTop-&gt;m_blockLinkingTargets.append(blockPtr);
1258     m_graph.appendBlock(WTFMove(block));
1259     return blockPtr;
1260 }
1261 
1262 BasicBlock* ByteCodeParser::allocateUntargetableBlock()
1263 {
<span class="line-modified">1264     Ref&lt;BasicBlock&gt; block = adoptRef(*new BasicBlock(BytecodeIndex(), m_numArguments, m_numLocals, m_numTmps, 1));</span>
1265     BasicBlock* blockPtr = block.ptr();
1266     m_graph.appendBlock(WTFMove(block));
1267     return blockPtr;
1268 }
1269 
<span class="line-modified">1270 void ByteCodeParser::makeBlockTargetable(BasicBlock* block, BytecodeIndex bytecodeIndex)</span>
1271 {
<span class="line-modified">1272     RELEASE_ASSERT(!block-&gt;bytecodeBegin);</span>
1273     block-&gt;bytecodeBegin = bytecodeIndex;
1274     // m_blockLinkingTargets must always be sorted in increasing order of bytecodeBegin
1275     if (m_inlineStackTop-&gt;m_blockLinkingTargets.size())
<span class="line-modified">1276         ASSERT(m_inlineStackTop-&gt;m_blockLinkingTargets.last()-&gt;bytecodeBegin.offset() &lt; bytecodeIndex.offset());</span>
1277     m_inlineStackTop-&gt;m_blockLinkingTargets.append(block);
1278 }
1279 
1280 void ByteCodeParser::addJumpTo(BasicBlock* block)
1281 {
1282     ASSERT(!m_currentBlock-&gt;terminal());
1283     Node* jumpNode = addToGraph(Jump);
1284     jumpNode-&gt;targetBlock() = block;
1285     m_currentBlock-&gt;didLink();
1286 }
1287 
1288 void ByteCodeParser::addJumpTo(unsigned bytecodeIndex)
1289 {
1290     ASSERT(!m_currentBlock-&gt;terminal());
1291     addToGraph(Jump, OpInfo(bytecodeIndex));
1292     m_inlineStackTop-&gt;m_unlinkedBlocks.append(m_currentBlock);
1293 }
1294 
1295 template&lt;typename CallOp&gt;
1296 ByteCodeParser::Terminality ByteCodeParser::handleCall(const Instruction* pc, NodeType op, CallMode callMode)
</pre>
<hr />
<pre>
1314     if (callTarget-&gt;isCellConstant())
1315         callLinkStatus.setProvenConstantCallee(CallVariant(callTarget-&gt;asCell()));
1316 }
1317 
1318 ByteCodeParser::Terminality ByteCodeParser::handleCall(
1319     VirtualRegister result, NodeType op, InlineCallFrame::Kind kind, unsigned instructionSize,
1320     Node* callTarget, int argumentCountIncludingThis, int registerOffset,
1321     CallLinkStatus callLinkStatus, SpeculatedType prediction)
1322 {
1323     ASSERT(registerOffset &lt;= 0);
1324 
1325     refineStatically(callLinkStatus, callTarget);
1326 
1327     VERBOSE_LOG(&quot;    Handling call at &quot;, currentCodeOrigin(), &quot;: &quot;, callLinkStatus, &quot;\n&quot;);
1328 
1329     // If we have profiling information about this call, and it did not behave too polymorphically,
1330     // we may be able to inline it, or in the case of recursive tail calls turn it into a jump.
1331     if (callLinkStatus.canOptimize()) {
1332         addToGraph(FilterCallLinkStatus, OpInfo(m_graph.m_plan.recordedStatuses().addCallLinkStatus(currentCodeOrigin(), callLinkStatus)), callTarget);
1333 
<span class="line-modified">1334         VirtualRegister thisArgument = virtualRegisterForArgumentIncludingThis(0, registerOffset);</span>
1335         auto optimizationResult = handleInlining(callTarget, result, callLinkStatus, registerOffset, thisArgument,
<span class="line-modified">1336             argumentCountIncludingThis, BytecodeIndex(m_currentIndex.offset() + instructionSize), op, kind, prediction);</span>
1337         if (optimizationResult == CallOptimizationResult::OptimizedToJump)
1338             return Terminal;
1339         if (optimizationResult == CallOptimizationResult::Inlined) {
1340             if (UNLIKELY(m_graph.compilation()))
1341                 m_graph.compilation()-&gt;noticeInlinedCall();
1342             return NonTerminal;
1343         }
1344     }
1345 
1346     Node* callNode = addCall(result, op, nullptr, callTarget, argumentCountIncludingThis, registerOffset, prediction);
1347     ASSERT(callNode-&gt;op() != TailCallVarargs &amp;&amp; callNode-&gt;op() != TailCallForwardVarargs);
1348     return callNode-&gt;op() == TailCall ? Terminal : NonTerminal;
1349 }
1350 
1351 template&lt;typename CallOp&gt;
1352 ByteCodeParser::Terminality ByteCodeParser::handleVarargsCall(const Instruction* pc, NodeType op, CallMode callMode)
1353 {
1354     auto bytecode = pc-&gt;as&lt;CallOp&gt;();
1355     int firstFreeReg = bytecode.m_firstFree.offset();
1356     int firstVarArgOffset = bytecode.m_firstVarArg;
</pre>
<hr />
<pre>
1421 
1422     ASSERT(calleeCell);
1423     addToGraph(CheckCell, OpInfo(m_graph.freeze(calleeCell)), callTargetForCheck);
1424     if (thisArgument)
1425         addToGraph(Phantom, thisArgument);
1426 }
1427 
1428 Node* ByteCodeParser::getArgumentCount()
1429 {
1430     Node* argumentCount;
1431     if (m_inlineStackTop-&gt;m_inlineCallFrame &amp;&amp; !m_inlineStackTop-&gt;m_inlineCallFrame-&gt;isVarargs())
1432         argumentCount = jsConstant(m_graph.freeze(jsNumber(m_inlineStackTop-&gt;m_inlineCallFrame-&gt;argumentCountIncludingThis))-&gt;value());
1433     else
1434         argumentCount = addToGraph(GetArgumentCountIncludingThis, OpInfo(m_inlineStackTop-&gt;m_inlineCallFrame), OpInfo(SpecInt32Only));
1435     return argumentCount;
1436 }
1437 
1438 void ByteCodeParser::emitArgumentPhantoms(int registerOffset, int argumentCountIncludingThis)
1439 {
1440     for (int i = 0; i &lt; argumentCountIncludingThis; ++i)
<span class="line-modified">1441         addToGraph(Phantom, get(virtualRegisterForArgumentIncludingThis(i, registerOffset)));</span>
1442 }
1443 
1444 template&lt;typename ChecksFunctor&gt;
1445 bool ByteCodeParser::handleRecursiveTailCall(Node* callTargetNode, CallVariant callVariant, int registerOffset, int argumentCountIncludingThis, const ChecksFunctor&amp; emitFunctionCheckIfNeeded)
1446 {
1447     if (UNLIKELY(!Options::optimizeRecursiveTailCalls()))
1448         return false;
1449 
1450     auto targetExecutable = callVariant.executable();
1451     InlineStackEntry* stackEntry = m_inlineStackTop;
1452     do {
1453         if (targetExecutable != stackEntry-&gt;executable())
1454             continue;
1455         VERBOSE_LOG(&quot;   We found a recursive tail call, trying to optimize it into a jump.\n&quot;);
1456 
1457         if (auto* callFrame = stackEntry-&gt;m_inlineCallFrame) {
<span class="line-added">1458             // FIXME: We only accept jump to CallFrame which has exact same argumentCountIncludingThis. But we can remove this by fixing up arguments.</span>
<span class="line-added">1459             // And we can also allow jumping into CallFrame with Varargs if the passing number of arguments is greater than or equal to mandatoryMinimum of CallFrame.</span>
<span class="line-added">1460             // https://bugs.webkit.org/show_bug.cgi?id=202317</span>
<span class="line-added">1461 </span>
1462             // Some code may statically use the argument count from the InlineCallFrame, so it would be invalid to loop back if it does not match.
1463             // We &quot;continue&quot; instead of returning false in case another stack entry further on the stack has the right number of arguments.
1464             if (argumentCountIncludingThis != static_cast&lt;int&gt;(callFrame-&gt;argumentCountIncludingThis))
1465                 continue;
<span class="line-added">1466             // If the target InlineCallFrame is Varargs, we do not know how many arguments are actually filled by LoadVarargs. Varargs InlineCallFrame&#39;s</span>
<span class="line-added">1467             // argumentCountIncludingThis is maximum number of potentially filled arguments by xkLoadVarargs. We &quot;continue&quot; to the upper frame which may be</span>
<span class="line-added">1468             // a good target to jump into.</span>
<span class="line-added">1469             if (callFrame-&gt;isVarargs())</span>
<span class="line-added">1470                 continue;</span>
1471         } else {
1472             // We are in the machine code entry (i.e. the original caller).
1473             // If we have more arguments than the number of parameters to the function, it is not clear where we could put them on the stack.
1474             if (argumentCountIncludingThis &gt; m_codeBlock-&gt;numParameters())
1475                 return false;
1476         }
1477 
1478         // If an InlineCallFrame is not a closure, it was optimized using a constant callee.
1479         // Check if this is the same callee that we try to inline here.
1480         if (stackEntry-&gt;m_inlineCallFrame &amp;&amp; !stackEntry-&gt;m_inlineCallFrame-&gt;isClosureCall) {
1481             if (stackEntry-&gt;m_inlineCallFrame-&gt;calleeConstant() != callVariant.function())
1482                 continue;
1483         }
1484 
1485         // We must add some check that the profiling information was correct and the target of this call is what we thought.
1486         emitFunctionCheckIfNeeded();
1487         // We flush everything, as if we were in the backedge of a loop (see treatment of op_jmp in parseBlock).
1488         flushForTerminal();
1489 
1490         // We must set the callee to the right value
1491         if (stackEntry-&gt;m_inlineCallFrame) {
1492             if (stackEntry-&gt;m_inlineCallFrame-&gt;isClosureCall)
<span class="line-modified">1493                 setDirect(remapOperand(stackEntry-&gt;m_inlineCallFrame, CallFrameSlot::callee), callTargetNode, NormalSet);</span>
1494         } else
1495             addToGraph(SetCallee, callTargetNode);
1496 
1497         // We must set the arguments to the right values
1498         if (!stackEntry-&gt;m_inlineCallFrame)
1499             addToGraph(SetArgumentCountIncludingThis, OpInfo(argumentCountIncludingThis));
1500         int argIndex = 0;
1501         for (; argIndex &lt; argumentCountIncludingThis; ++argIndex) {
<span class="line-modified">1502             Node* value = get(virtualRegisterForArgumentIncludingThis(argIndex, registerOffset));</span>
<span class="line-modified">1503             setDirect(stackEntry-&gt;remapOperand(virtualRegisterForArgumentIncludingThis(argIndex)), value, NormalSet);</span>
1504         }
1505         Node* undefined = addToGraph(JSConstant, OpInfo(m_constantUndefined));
1506         for (; argIndex &lt; stackEntry-&gt;m_codeBlock-&gt;numParameters(); ++argIndex)
<span class="line-modified">1507             setDirect(stackEntry-&gt;remapOperand(virtualRegisterForArgumentIncludingThis(argIndex)), undefined, NormalSet);</span>
1508 
1509         // We must repeat the work of op_enter here as we will jump right after it.
1510         // We jump right after it and not before it, because of some invariant saying that a CFG root cannot have predecessors in the IR.
1511         for (int i = 0; i &lt; stackEntry-&gt;m_codeBlock-&gt;numVars(); ++i)
1512             setDirect(stackEntry-&gt;remapOperand(virtualRegisterForLocal(i)), undefined, NormalSet);
1513 
<span class="line-modified">1514         // We want to emit the SetLocals with an exit origin that points to the place we are jumping to.</span>
<span class="line-added">1515         BytecodeIndex oldIndex = m_currentIndex;</span>
1516         auto oldStackTop = m_inlineStackTop;


1517         m_inlineStackTop = stackEntry;
<span class="line-modified">1518         m_currentIndex = BytecodeIndex(opcodeLengths[op_enter]);</span>





1519         m_exitOK = true;
1520         processSetLocalQueue();
1521         m_currentIndex = oldIndex;
1522         m_inlineStackTop = oldStackTop;
1523         m_exitOK = false;
1524 
<span class="line-modified">1525         BasicBlock** entryBlockPtr = tryBinarySearch&lt;BasicBlock*, BytecodeIndex&gt;(stackEntry-&gt;m_blockLinkingTargets, stackEntry-&gt;m_blockLinkingTargets.size(), BytecodeIndex(opcodeLengths[op_enter]), getBytecodeBeginForBlock);</span>
1526         RELEASE_ASSERT(entryBlockPtr);
1527         addJumpTo(*entryBlockPtr);
1528         return true;
1529         // It would be unsound to jump over a non-tail call: the &quot;tail&quot; call is not really a tail call in that case.
1530     } while (stackEntry-&gt;m_inlineCallFrame &amp;&amp; stackEntry-&gt;m_inlineCallFrame-&gt;kind == InlineCallFrame::TailCall &amp;&amp; (stackEntry = stackEntry-&gt;m_caller));
1531 
1532     // The tail call was not recursive
1533     return false;
1534 }
1535 
1536 unsigned ByteCodeParser::inliningCost(CallVariant callee, int argumentCountIncludingThis, InlineCallFrame::Kind kind)
1537 {
1538     CallMode callMode = InlineCallFrame::callModeFor(kind);
1539     CodeSpecializationKind specializationKind = specializationKindFor(callMode);
1540     VERBOSE_LOG(&quot;Considering inlining &quot;, callee, &quot; into &quot;, currentCodeOrigin(), &quot;\n&quot;);
1541 
1542     if (m_hasDebuggerEnabled) {
1543         VERBOSE_LOG(&quot;    Failing because the debugger is in use.\n&quot;);
1544         return UINT_MAX;
1545     }
</pre>
<hr />
<pre>
1638     CodeSpecializationKind specializationKind = InlineCallFrame::specializationKindFor(kind);
1639 
1640     CodeBlock* codeBlock = callee.functionExecutable()-&gt;baselineCodeBlockFor(specializationKind);
1641     insertChecks(codeBlock);
1642 
1643     // FIXME: Don&#39;t flush constants!
1644 
1645     // arityFixupCount and numberOfStackPaddingSlots are different. While arityFixupCount does not consider about stack alignment,
1646     // numberOfStackPaddingSlots consider alignment. Consider the following case,
1647     //
1648     // before: [ ... ][arg0][header]
1649     // after:  [ ... ][ext ][arg1][arg0][header]
1650     //
1651     // In the above case, arityFixupCount is 1. But numberOfStackPaddingSlots is 2 because the stack needs to be aligned.
1652     // We insert extra slots to align stack.
1653     int arityFixupCount = std::max&lt;int&gt;(codeBlock-&gt;numParameters() - argumentCountIncludingThis, 0);
1654     int numberOfStackPaddingSlots = CommonSlowPaths::numberOfStackPaddingSlots(codeBlock, argumentCountIncludingThis);
1655     ASSERT(!(numberOfStackPaddingSlots % stackAlignmentRegisters()));
1656     int registerOffsetAfterFixup = registerOffset - numberOfStackPaddingSlots;
1657 
<span class="line-modified">1658     Operand inlineCallFrameStart = VirtualRegister(m_inlineStackTop-&gt;remapOperand(VirtualRegister(registerOffsetAfterFixup)).value() + CallFrame::headerSizeInRegisters);</span>
1659 
1660     ensureLocals(
<span class="line-modified">1661         inlineCallFrameStart.toLocal() + 1 +</span>
1662         CallFrame::headerSizeInRegisters + codeBlock-&gt;numCalleeLocals());
1663 
<span class="line-added">1664     ensureTmps((m_inlineStackTop-&gt;m_inlineCallFrame ? m_inlineStackTop-&gt;m_inlineCallFrame-&gt;tmpOffset : 0) + m_inlineStackTop-&gt;m_codeBlock-&gt;numTmps() + codeBlock-&gt;numTmps());</span>
<span class="line-added">1665 </span>
1666     size_t argumentPositionStart = m_graph.m_argumentPositions.size();
1667 
1668     if (result.isValid())
<span class="line-modified">1669         result = m_inlineStackTop-&gt;remapOperand(result).virtualRegister();</span>
1670 
1671     VariableAccessData* calleeVariable = nullptr;
1672     if (callee.isClosureCall()) {
1673         Node* calleeSet = set(
1674             VirtualRegister(registerOffsetAfterFixup + CallFrameSlot::callee), callTargetNode, ImmediateNakedSet);
1675 
1676         calleeVariable = calleeSet-&gt;variableAccessData();
1677         calleeVariable-&gt;mergeShouldNeverUnbox(true);
1678     }
1679 
1680     InlineStackEntry* callerStackTop = m_inlineStackTop;
1681     InlineStackEntry inlineStackEntry(this, codeBlock, codeBlock, callee.function(), result,
<span class="line-modified">1682         inlineCallFrameStart.virtualRegister(), argumentCountIncludingThis, kind, continuationBlock);</span>
1683 
1684     // This is where the actual inlining really happens.
<span class="line-modified">1685     BytecodeIndex oldIndex = m_currentIndex;</span>
<span class="line-modified">1686     m_currentIndex = BytecodeIndex(0);</span>
1687 
1688     switch (kind) {
1689     case InlineCallFrame::GetterCall:
1690     case InlineCallFrame::SetterCall: {
1691         // When inlining getter and setter calls, we setup a stack frame which does not appear in the bytecode.
1692         // Because Inlining can switch on executable, we could have a graph like this.
1693         //
1694         // BB#0
1695         //     ...
1696         //     30: GetSetter
1697         //     31: MovHint(loc10)
1698         //     32: SetLocal(loc10)
1699         //     33: MovHint(loc9)
1700         //     34: SetLocal(loc9)
1701         //     ...
1702         //     37: GetExecutable(@30)
1703         //     ...
1704         //     41: Switch(@37)
1705         //
1706         // BB#2
1707         //     42: GetLocal(loc12, bc#7 of caller)
1708         //     ...
1709         //     --&gt; callee: loc9 and loc10 are arguments of callee.
1710         //       ...
1711         //       &lt;HERE, exit to callee, loc9 and loc10 are required in the bytecode&gt;
1712         //
1713         // When we prune OSR availability at the beginning of BB#2 (bc#7 in the caller), we prune loc9 and loc10&#39;s liveness because the caller does not actually have loc9 and loc10.
1714         // However, when we begin executing the callee, we need OSR exit to be aware of where it can recover the arguments to the setter, loc9 and loc10. The MovHints in the inlined
1715         // callee make it so that if we exit at &lt;HERE&gt;, we can recover loc9 and loc10.
1716         for (int index = 0; index &lt; argumentCountIncludingThis; ++index) {
<span class="line-modified">1717             Operand argumentToGet = callerStackTop-&gt;remapOperand(virtualRegisterForArgumentIncludingThis(index, registerOffset));</span>
1718             Node* value = getDirect(argumentToGet);
<span class="line-modified">1719             addToGraph(MovHint, OpInfo(argumentToGet), value);</span>
1720             m_setLocalQueue.append(DelayedSetLocal { currentCodeOrigin(), argumentToGet, value, ImmediateNakedSet });
1721         }
1722         break;
1723     }
1724     default:
1725         break;
1726     }
1727 
1728     if (arityFixupCount) {
1729         // Note: we do arity fixup in two phases:
1730         // 1. We get all the values we need and MovHint them to the expected locals.
1731         // 2. We SetLocal them after that. This way, if we exit, the callee&#39;s
1732         //    frame is already set up. If any SetLocal exits, we have a valid exit state.
1733         //    This is required because if we didn&#39;t do this in two phases, we may exit in
1734         //    the middle of arity fixup from the callee&#39;s CodeOrigin. This is unsound because exited
1735         //    code does not have arity fixup so that remaining necessary fixups are not executed.
1736         //    For example, consider if we need to pad two args:
1737         //    [arg3][arg2][arg1][arg0]
1738         //    [fix ][fix ][arg3][arg2][arg1][arg0]
1739         //    We memcpy starting from arg0 in the direction of arg3. If we were to exit at a type check
</pre>
<hr />
<pre>
1743         //    And the callee would then just end up thinking its argument are:
1744         //    [fix ][fix ][arg3][arg2][arg1][arg0]
1745         //    which is incorrect.
1746 
1747         Node* undefined = addToGraph(JSConstant, OpInfo(m_constantUndefined));
1748         // The stack needs to be aligned due to the JS calling convention. Thus, we have a hole if the count of arguments is not aligned.
1749         // We call this hole &quot;extra slot&quot;. Consider the following case, the number of arguments is 2. If this argument
1750         // count does not fulfill the stack alignment requirement, we already inserted extra slots.
1751         //
1752         // before: [ ... ][ext ][arg1][arg0][header]
1753         //
1754         // In the above case, one extra slot is inserted. If the code&#39;s parameter count is 3, we will fixup arguments.
1755         // At that time, we can simply use this extra slots. So the fixuped stack is the following.
1756         //
1757         // before: [ ... ][ext ][arg1][arg0][header]
1758         // after:  [ ... ][arg2][arg1][arg0][header]
1759         //
1760         // In such cases, we do not need to move frames.
1761         if (registerOffsetAfterFixup != registerOffset) {
1762             for (int index = 0; index &lt; argumentCountIncludingThis; ++index) {
<span class="line-modified">1763                 Operand argumentToGet = callerStackTop-&gt;remapOperand(virtualRegisterForArgumentIncludingThis(index, registerOffset));</span>
1764                 Node* value = getDirect(argumentToGet);
<span class="line-modified">1765                 Operand argumentToSet = m_inlineStackTop-&gt;remapOperand(virtualRegisterForArgumentIncludingThis(index));</span>
<span class="line-modified">1766                 addToGraph(MovHint, OpInfo(argumentToSet), value);</span>
1767                 m_setLocalQueue.append(DelayedSetLocal { currentCodeOrigin(), argumentToSet, value, ImmediateNakedSet });
1768             }
1769         }
1770         for (int index = 0; index &lt; arityFixupCount; ++index) {
<span class="line-modified">1771             Operand argumentToSet = m_inlineStackTop-&gt;remapOperand(virtualRegisterForArgumentIncludingThis(argumentCountIncludingThis + index));</span>
<span class="line-modified">1772             addToGraph(MovHint, OpInfo(argumentToSet), undefined);</span>
1773             m_setLocalQueue.append(DelayedSetLocal { currentCodeOrigin(), argumentToSet, undefined, ImmediateNakedSet });
1774         }
1775 
1776         // At this point, it&#39;s OK to OSR exit because we finished setting up
1777         // our callee&#39;s frame. We emit an ExitOK below.
1778     }
1779 
1780     // At this point, it&#39;s again OK to OSR exit.
1781     m_exitOK = true;
1782     addToGraph(ExitOK);
1783 
1784     processSetLocalQueue();
1785 
1786     InlineVariableData inlineVariableData;
1787     inlineVariableData.inlineCallFrame = m_inlineStackTop-&gt;m_inlineCallFrame;
1788     inlineVariableData.argumentPositionStart = argumentPositionStart;
1789     inlineVariableData.calleeVariable = 0;
1790 
1791     RELEASE_ASSERT(
1792         m_inlineStackTop-&gt;m_inlineCallFrame-&gt;isClosureCall
</pre>
<hr />
<pre>
1801     parseCodeBlock();
1802     clearCaches(); // Reset our state now that we&#39;re back to the outer code.
1803 
1804     m_currentIndex = oldIndex;
1805     m_exitOK = false;
1806 
1807     linkBlocks(inlineStackEntry.m_unlinkedBlocks, inlineStackEntry.m_blockLinkingTargets);
1808 
1809     // Most functions have at least one op_ret and thus set up the continuation block.
1810     // In some rare cases, a function ends in op_unreachable, forcing us to allocate a new continuationBlock here.
1811     if (inlineStackEntry.m_continuationBlock)
1812         m_currentBlock = inlineStackEntry.m_continuationBlock;
1813     else
1814         m_currentBlock = allocateUntargetableBlock();
1815     ASSERT(!m_currentBlock-&gt;terminal());
1816 
1817     prepareToParseBlock();
1818     m_currentInstruction = savedCurrentInstruction;
1819 }
1820 
<span class="line-modified">1821 ByteCodeParser::CallOptimizationResult ByteCodeParser::handleCallVariant(Node* callTargetNode, VirtualRegister result, CallVariant callee, int registerOffset, VirtualRegister thisArgument, int argumentCountIncludingThis, BytecodeIndex nextIndex, InlineCallFrame::Kind kind, SpeculatedType prediction, unsigned&amp; inliningBalance, BasicBlock* continuationBlock, bool needsToCheckCallee)</span>
1822 {
1823     VERBOSE_LOG(&quot;    Considering callee &quot;, callee, &quot;\n&quot;);
1824 
1825     bool didInsertChecks = false;
1826     auto insertChecksWithAccounting = [&amp;] () {
1827         if (needsToCheckCallee)
1828             emitFunctionChecks(callee, callTargetNode, thisArgument);
1829         didInsertChecks = true;
1830     };
1831 
1832     if (kind == InlineCallFrame::TailCall &amp;&amp; ByteCodeParser::handleRecursiveTailCall(callTargetNode, callee, registerOffset, argumentCountIncludingThis, insertChecksWithAccounting)) {
1833         RELEASE_ASSERT(didInsertChecks);
1834         return CallOptimizationResult::OptimizedToJump;
1835     }
1836     RELEASE_ASSERT(!didInsertChecks);
1837 
1838     if (!inliningBalance)
1839         return CallOptimizationResult::DidNothing;
1840 
1841     CodeSpecializationKind specializationKind = InlineCallFrame::specializationKindFor(kind);
1842 
1843     auto endSpecialCase = [&amp;] () {
1844         RELEASE_ASSERT(didInsertChecks);
1845         addToGraph(Phantom, callTargetNode);
1846         emitArgumentPhantoms(registerOffset, argumentCountIncludingThis);
1847         inliningBalance--;
1848         if (continuationBlock) {
<span class="line-modified">1849             m_currentIndex = nextIndex;</span>
1850             m_exitOK = true;
1851             processSetLocalQueue();
1852             addJumpTo(continuationBlock);
1853         }
1854     };
1855 
1856     if (InternalFunction* function = callee.internalFunction()) {
1857         if (handleConstantInternalFunction(callTargetNode, result, function, registerOffset, argumentCountIncludingThis, specializationKind, prediction, insertChecksWithAccounting)) {
1858             endSpecialCase();
1859             return CallOptimizationResult::Inlined;
1860         }
1861         RELEASE_ASSERT(!didInsertChecks);
1862         return CallOptimizationResult::DidNothing;
1863     }
1864 
1865     Intrinsic intrinsic = callee.intrinsicFor(specializationKind);
1866     if (intrinsic != NoIntrinsic) {
1867         if (handleIntrinsicCall(callTargetNode, result, intrinsic, registerOffset, argumentCountIncludingThis, prediction, insertChecksWithAccounting)) {
1868             endSpecialCase();
1869             return CallOptimizationResult::Inlined;
</pre>
<hr />
<pre>
1884 
1885     unsigned myInliningCost = inliningCost(callee, argumentCountIncludingThis, kind);
1886     if (myInliningCost &gt; inliningBalance)
1887         return CallOptimizationResult::DidNothing;
1888 
1889     auto insertCheck = [&amp;] (CodeBlock*) {
1890         if (needsToCheckCallee)
1891             emitFunctionChecks(callee, callTargetNode, thisArgument);
1892     };
1893     inlineCall(callTargetNode, result, callee, registerOffset, argumentCountIncludingThis, kind, continuationBlock, insertCheck);
1894     inliningBalance -= myInliningCost;
1895     return CallOptimizationResult::Inlined;
1896 }
1897 
1898 bool ByteCodeParser::handleVarargsInlining(Node* callTargetNode, VirtualRegister result,
1899     const CallLinkStatus&amp; callLinkStatus, int firstFreeReg, VirtualRegister thisArgument,
1900     VirtualRegister argumentsArgument, unsigned argumentsOffset,
1901     NodeType callOp, InlineCallFrame::Kind kind)
1902 {
1903     VERBOSE_LOG(&quot;Handling inlining (Varargs)...\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
<span class="line-modified">1904     if (callLinkStatus.maxArgumentCountIncludingThis() &gt; Options::maximumVarargsForInlining()) {</span>
1905         VERBOSE_LOG(&quot;Bailing inlining: too many arguments for varargs inlining.\n&quot;);
1906         return false;
1907     }
1908     if (callLinkStatus.couldTakeSlowPath() || callLinkStatus.size() != 1) {
1909         VERBOSE_LOG(&quot;Bailing inlining: polymorphic inlining is not yet supported for varargs.\n&quot;);
1910         return false;
1911     }
1912 
1913     CallVariant callVariant = callLinkStatus[0];
1914 
1915     unsigned mandatoryMinimum;
1916     if (FunctionExecutable* functionExecutable = callVariant.functionExecutable())
1917         mandatoryMinimum = functionExecutable-&gt;parameterCount();
1918     else
1919         mandatoryMinimum = 0;
1920 
1921     // includes &quot;this&quot;
<span class="line-modified">1922     unsigned maxArgumentCountIncludingThis = std::max(callLinkStatus.maxArgumentCountIncludingThis(), mandatoryMinimum + 1);</span>
1923 
1924     CodeSpecializationKind specializationKind = InlineCallFrame::specializationKindFor(kind);
<span class="line-modified">1925     if (inliningCost(callVariant, maxArgumentCountIncludingThis, kind) &gt; getInliningBalance(callLinkStatus, specializationKind)) {</span>
1926         VERBOSE_LOG(&quot;Bailing inlining: inlining cost too high.\n&quot;);
1927         return false;
1928     }
1929 
<span class="line-modified">1930     int registerOffset = firstFreeReg;</span>
<span class="line-modified">1931     registerOffset -= maxArgumentCountIncludingThis;</span>
1932     registerOffset -= CallFrame::headerSizeInRegisters;
1933     registerOffset = -WTF::roundUpToMultipleOf(stackAlignmentRegisters(), -registerOffset);
1934 
1935     auto insertChecks = [&amp;] (CodeBlock* codeBlock) {
1936         emitFunctionChecks(callVariant, callTargetNode, thisArgument);
1937 
1938         int remappedRegisterOffset =
<span class="line-modified">1939         m_inlineStackTop-&gt;remapOperand(VirtualRegister(registerOffset)).virtualRegister().offset();</span>
1940 
1941         ensureLocals(VirtualRegister(remappedRegisterOffset).toLocal());
1942 
1943         int argumentStart = registerOffset + CallFrame::headerSizeInRegisters;
<span class="line-modified">1944         int remappedArgumentStart = m_inlineStackTop-&gt;remapOperand(VirtualRegister(argumentStart)).virtualRegister().offset();</span>
1945 
1946         LoadVarargsData* data = m_graph.m_loadVarargsData.add();
1947         data-&gt;start = VirtualRegister(remappedArgumentStart + 1);
<span class="line-modified">1948         data-&gt;count = VirtualRegister(remappedRegisterOffset + CallFrameSlot::argumentCountIncludingThis);</span>
1949         data-&gt;offset = argumentsOffset;
<span class="line-modified">1950         data-&gt;limit = maxArgumentCountIncludingThis;</span>
1951         data-&gt;mandatoryMinimum = mandatoryMinimum;
1952 
<span class="line-modified">1953         if (callOp == TailCallForwardVarargs) {</span>
<span class="line-modified">1954             Node* argumentCount;</span>
<span class="line-modified">1955             if (!inlineCallFrame())</span>
<span class="line-modified">1956                 argumentCount = addToGraph(GetArgumentCountIncludingThis);</span>
<span class="line-added">1957             else if (inlineCallFrame()-&gt;isVarargs())</span>
<span class="line-added">1958                 argumentCount = getDirect(remapOperand(inlineCallFrame(), CallFrameSlot::argumentCountIncludingThis));</span>
<span class="line-added">1959             else</span>
<span class="line-added">1960                 argumentCount = addToGraph(JSConstant, OpInfo(m_graph.freeze(jsNumber(inlineCallFrame()-&gt;argumentCountIncludingThis))));</span>
<span class="line-added">1961             addToGraph(ForwardVarargs, OpInfo(data), argumentCount);</span>
<span class="line-added">1962         } else {</span>
<span class="line-added">1963             Node* arguments = get(argumentsArgument);</span>
<span class="line-added">1964             auto argCountTmp = m_inlineStackTop-&gt;remapOperand(Operand::tmp(OpCallVarargs::argCountIncludingThis));</span>
<span class="line-added">1965             setDirect(argCountTmp, addToGraph(VarargsLength, OpInfo(data), arguments));</span>
<span class="line-added">1966             progressToNextCheckpoint();</span>
<span class="line-added">1967 </span>
<span class="line-added">1968             addToGraph(LoadVarargs, OpInfo(data), getLocalOrTmp(argCountTmp), arguments);</span>
<span class="line-added">1969         }</span>
1970 
1971         // LoadVarargs may OSR exit. Hence, we need to keep alive callTargetNode, thisArgument
1972         // and argumentsArgument for the baseline JIT. However, we only need a Phantom for
1973         // callTargetNode because the other 2 are still in use and alive at this point.
1974         addToGraph(Phantom, callTargetNode);
1975 
1976         // In DFG IR before SSA, we cannot insert control flow between after the
1977         // LoadVarargs and the last SetArgumentDefinitely. This isn&#39;t a problem once we get to DFG
1978         // SSA. Fortunately, we also have other reasons for not inserting control flow
1979         // before SSA.
1980 
<span class="line-modified">1981         VariableAccessData* countVariable = newVariableAccessData(data-&gt;count);</span>
1982         // This is pretty lame, but it will force the count to be flushed as an int. This doesn&#39;t
1983         // matter very much, since our use of a SetArgumentDefinitely and Flushes for this local slot is
1984         // mostly just a formality.
1985         countVariable-&gt;predict(SpecInt32Only);
1986         countVariable-&gt;mergeIsProfitableToUnbox(true);
1987         Node* setArgumentCount = addToGraph(SetArgumentDefinitely, OpInfo(countVariable));
<span class="line-modified">1988         m_currentBlock-&gt;variablesAtTail.setOperand(countVariable-&gt;operand(), setArgumentCount);</span>
1989 
1990         set(VirtualRegister(argumentStart), get(thisArgument), ImmediateNakedSet);
1991         unsigned numSetArguments = 0;
<span class="line-modified">1992         for (unsigned argument = 1; argument &lt; maxArgumentCountIncludingThis; ++argument) {</span>
1993             VariableAccessData* variable = newVariableAccessData(VirtualRegister(remappedArgumentStart + argument));
1994             variable-&gt;mergeShouldNeverUnbox(true); // We currently have nowhere to put the type check on the LoadVarargs. LoadVarargs is effectful, so after it finishes, we cannot exit.
1995 
1996             // For a while it had been my intention to do things like this inside the
1997             // prediction injection phase. But in this case it&#39;s really best to do it here,
1998             // because it&#39;s here that we have access to the variable access datas for the
1999             // inlining we&#39;re about to do.
2000             //
2001             // Something else that&#39;s interesting here is that we&#39;d really love to get
2002             // predictions from the arguments loaded at the callsite, rather than the
2003             // arguments received inside the callee. But that probably won&#39;t matter for most
2004             // calls.
2005             if (codeBlock &amp;&amp; argument &lt; static_cast&lt;unsigned&gt;(codeBlock-&gt;numParameters())) {
2006                 ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
2007                 ValueProfile&amp; profile = codeBlock-&gt;valueProfileForArgument(argument);
2008                 variable-&gt;predict(profile.computeUpdatedPrediction(locker));
2009             }
2010 
2011             Node* setArgument = addToGraph(numSetArguments &gt;= mandatoryMinimum ? SetArgumentMaybe : SetArgumentDefinitely, OpInfo(variable));
<span class="line-modified">2012             m_currentBlock-&gt;variablesAtTail.setOperand(variable-&gt;operand(), setArgument);</span>
2013             ++numSetArguments;
2014         }
2015     };
2016 
2017     // Intrinsics and internal functions can only be inlined if we&#39;re not doing varargs. This is because
2018     // we currently don&#39;t have any way of getting profiling information for arguments to non-JS varargs
2019     // calls. The prediction propagator won&#39;t be of any help because LoadVarargs obscures the data flow,
2020     // and there are no callsite value profiles and native function won&#39;t have callee value profiles for
2021     // those arguments. Even worse, if the intrinsic decides to exit, it won&#39;t really have anywhere to
2022     // exit to: LoadVarargs is effectful and it&#39;s part of the op_call_varargs, so we can&#39;t exit without
2023     // calling LoadVarargs twice.
<span class="line-modified">2024     inlineCall(callTargetNode, result, callVariant, registerOffset, maxArgumentCountIncludingThis, kind, nullptr, insertChecks);</span>
2025 
2026 
2027     VERBOSE_LOG(&quot;Successful inlining (varargs, monomorphic).\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
2028     return true;
2029 }
2030 
2031 unsigned ByteCodeParser::getInliningBalance(const CallLinkStatus&amp; callLinkStatus, CodeSpecializationKind specializationKind)
2032 {
2033     unsigned inliningBalance = Options::maximumFunctionForCallInlineCandidateBytecodeCost();
2034     if (specializationKind == CodeForConstruct)
2035         inliningBalance = std::min(inliningBalance, Options::maximumFunctionForConstructInlineCandidateBytecoodeCost());
2036     if (callLinkStatus.isClosureCall())
2037         inliningBalance = std::min(inliningBalance, Options::maximumFunctionForClosureCallInlineCandidateBytecodeCost());
2038     return inliningBalance;
2039 }
2040 
2041 ByteCodeParser::CallOptimizationResult ByteCodeParser::handleInlining(
2042     Node* callTargetNode, VirtualRegister result, const CallLinkStatus&amp; callLinkStatus,
2043     int registerOffset, VirtualRegister thisArgument,
2044     int argumentCountIncludingThis,
<span class="line-modified">2045     BytecodeIndex nextIndex, NodeType callOp, InlineCallFrame::Kind kind, SpeculatedType prediction)</span>
2046 {
2047     VERBOSE_LOG(&quot;Handling inlining...\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
2048 
2049     CodeSpecializationKind specializationKind = InlineCallFrame::specializationKindFor(kind);
2050     unsigned inliningBalance = getInliningBalance(callLinkStatus, specializationKind);
2051 
2052     // First check if we can avoid creating control flow. Our inliner does some CFG
2053     // simplification on the fly and this helps reduce compile times, but we can only leverage
2054     // this in cases where we don&#39;t need control flow diamonds to check the callee.
2055     if (!callLinkStatus.couldTakeSlowPath() &amp;&amp; callLinkStatus.size() == 1) {
2056         return handleCallVariant(
2057             callTargetNode, result, callLinkStatus[0], registerOffset, thisArgument,
<span class="line-modified">2058             argumentCountIncludingThis, nextIndex, kind, prediction, inliningBalance, nullptr, true);</span>
2059     }
2060 
2061     // We need to create some kind of switch over callee. For now we only do this if we believe that
2062     // we&#39;re in the top tier. We have two reasons for this: first, it provides us an opportunity to
2063     // do more detailed polyvariant/polymorphic profiling; and second, it reduces compile times in
2064     // the DFG. And by polyvariant profiling we mean polyvariant profiling of *this* call. Note that
2065     // we could improve that aspect of this by doing polymorphic inlining but having the profiling
2066     // also.
2067     if (!m_graph.m_plan.isFTL() || !Options::usePolymorphicCallInlining()) {
2068         VERBOSE_LOG(&quot;Bailing inlining (hard).\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
2069         return CallOptimizationResult::DidNothing;
2070     }
2071 
2072     // If the claim is that this did not originate from a stub, then we don&#39;t want to emit a switch
2073     // statement. Whenever the non-stub profiling says that it could take slow path, it really means that
2074     // it has no idea.
2075     if (!Options::usePolymorphicCallInliningForNonStubStatus()
2076         &amp;&amp; !callLinkStatus.isBasedOnStub()) {
2077         VERBOSE_LOG(&quot;Bailing inlining (non-stub polymorphism).\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
2078         return CallOptimizationResult::DidNothing;
</pre>
<hr />
<pre>
2092         thingToSwitchOn = callTargetNode;
2093     else if (allAreClosureCalls)
2094         thingToSwitchOn = addToGraph(GetExecutable, callTargetNode);
2095     else {
2096         // FIXME: We should be able to handle this case, but it&#39;s tricky and we don&#39;t know of cases
2097         // where it would be beneficial. It might be best to handle these cases as if all calls were
2098         // closure calls.
2099         // https://bugs.webkit.org/show_bug.cgi?id=136020
2100         VERBOSE_LOG(&quot;Bailing inlining (mix).\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
2101         return CallOptimizationResult::DidNothing;
2102     }
2103 
2104     VERBOSE_LOG(&quot;Doing hard inlining...\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
2105 
2106     // This makes me wish that we were in SSA all the time. We need to pick a variable into which to
2107     // store the callee so that it will be accessible to all of the blocks we&#39;re about to create. We
2108     // get away with doing an immediate-set here because we wouldn&#39;t have performed any side effects
2109     // yet.
2110     VERBOSE_LOG(&quot;Register offset: &quot;, registerOffset);
2111     VirtualRegister calleeReg(registerOffset + CallFrameSlot::callee);
<span class="line-modified">2112     calleeReg = m_inlineStackTop-&gt;remapOperand(calleeReg).virtualRegister();</span>
2113     VERBOSE_LOG(&quot;Callee is going to be &quot;, calleeReg, &quot;\n&quot;);
2114     setDirect(calleeReg, callTargetNode, ImmediateSetWithFlush);
2115 
2116     // It&#39;s OK to exit right now, even though we set some locals. That&#39;s because those locals are not
2117     // user-visible.
2118     m_exitOK = true;
2119     addToGraph(ExitOK);
2120 
2121     SwitchData&amp; data = *m_graph.m_switchData.add();
2122     data.kind = SwitchCell;
2123     addToGraph(Switch, OpInfo(&amp;data), thingToSwitchOn);
2124     m_currentBlock-&gt;didLink();
2125 
2126     BasicBlock* continuationBlock = allocateUntargetableBlock();
2127     VERBOSE_LOG(&quot;Adding untargetable block &quot;, RawPointer(continuationBlock), &quot; (continuation)\n&quot;);
2128 
2129     // We may force this true if we give up on inlining any of the edges.
2130     bool couldTakeSlowPath = callLinkStatus.couldTakeSlowPath();
2131 
2132     VERBOSE_LOG(&quot;About to loop over functions at &quot;, currentCodeOrigin(), &quot;.\n&quot;);
2133 
<span class="line-modified">2134     BytecodeIndex oldIndex = m_currentIndex;</span>
2135     for (unsigned i = 0; i &lt; callLinkStatus.size(); ++i) {
<span class="line-modified">2136         m_currentIndex = oldIndex;</span>
2137         BasicBlock* calleeEntryBlock = allocateUntargetableBlock();
2138         m_currentBlock = calleeEntryBlock;
2139         prepareToParseBlock();
2140 
2141         // At the top of each switch case, we can exit.
2142         m_exitOK = true;
2143 
2144         Node* myCallTargetNode = getDirect(calleeReg);
2145 
2146         auto inliningResult = handleCallVariant(
2147             myCallTargetNode, result, callLinkStatus[i], registerOffset,
<span class="line-modified">2148             thisArgument, argumentCountIncludingThis, nextIndex, kind, prediction,</span>
2149             inliningBalance, continuationBlock, false);
2150 
2151         if (inliningResult == CallOptimizationResult::DidNothing) {
2152             // That failed so we let the block die. Nothing interesting should have been added to
2153             // the block. We also give up on inlining any of the (less frequent) callees.
2154             ASSERT(m_graph.m_blocks.last() == m_currentBlock);
2155             m_graph.killBlockAndItsContents(m_currentBlock);
2156             m_graph.m_blocks.removeLast();
2157             VERBOSE_LOG(&quot;Inlining of a poly call failed, we will have to go through a slow path\n&quot;);
2158 
2159             // The fact that inlining failed means we need a slow path.
2160             couldTakeSlowPath = true;
2161             break;
2162         }
2163 
2164         JSCell* thingToCaseOn;
2165         if (allAreDirectCalls)
2166             thingToCaseOn = callLinkStatus[i].nonExecutableCallee();
2167         else {
2168             ASSERT(allAreClosureCalls);
2169             thingToCaseOn = callLinkStatus[i].executable();
2170         }
2171         data.cases.append(SwitchCase(m_graph.freeze(thingToCaseOn), calleeEntryBlock));
2172         VERBOSE_LOG(&quot;Finished optimizing &quot;, callLinkStatus[i], &quot; at &quot;, currentCodeOrigin(), &quot;.\n&quot;);
2173     }
2174 
2175     // Slow path block
2176     m_currentBlock = allocateUntargetableBlock();
<span class="line-modified">2177     m_currentIndex = oldIndex;</span>
2178     m_exitOK = true;
2179     data.fallThrough = BranchTarget(m_currentBlock);
2180     prepareToParseBlock();
2181     Node* myCallTargetNode = getDirect(calleeReg);
2182     if (couldTakeSlowPath) {
2183         addCall(
2184             result, callOp, nullptr, myCallTargetNode, argumentCountIncludingThis,
2185             registerOffset, prediction);
2186         VERBOSE_LOG(&quot;We added a call in the slow path\n&quot;);
2187     } else {
2188         addToGraph(CheckBadCell);
2189         addToGraph(Phantom, myCallTargetNode);
2190         emitArgumentPhantoms(registerOffset, argumentCountIncludingThis);
2191 
2192         if (result.isValid())
2193             set(result, addToGraph(BottomValue));
2194         VERBOSE_LOG(&quot;couldTakeSlowPath was false\n&quot;);
2195     }
2196 
<span class="line-modified">2197     m_currentIndex = nextIndex;</span>
2198     m_exitOK = true; // Origin changed, so it&#39;s fine to exit again.
2199     processSetLocalQueue();
2200 
2201     if (Node* terminal = m_currentBlock-&gt;terminal())
2202         ASSERT_UNUSED(terminal, terminal-&gt;op() == TailCall || terminal-&gt;op() == TailCallVarargs || terminal-&gt;op() == TailCallForwardVarargs);
2203     else {
2204         addJumpTo(continuationBlock);
2205     }
2206 
2207     prepareToParseBlock();
2208 
<span class="line-modified">2209     m_currentIndex = oldIndex;</span>
2210     m_currentBlock = continuationBlock;
2211     m_exitOK = true;
2212 
2213     VERBOSE_LOG(&quot;Done inlining (hard).\nStack: &quot;, currentCodeOrigin(), &quot;\n&quot;);
2214     return CallOptimizationResult::Inlined;
2215 }
2216 
2217 template&lt;typename ChecksFunctor&gt;
2218 bool ByteCodeParser::handleMinMax(VirtualRegister result, NodeType op, int registerOffset, int argumentCountIncludingThis, const ChecksFunctor&amp; insertChecks)
2219 {
2220     ASSERT(op == ArithMin || op == ArithMax);
2221 
2222     if (argumentCountIncludingThis == 1) {
2223         insertChecks();
2224         double limit = op == ArithMax ? -std::numeric_limits&lt;double&gt;::infinity() : +std::numeric_limits&lt;double&gt;::infinity();
2225         set(result, addToGraph(JSConstant, OpInfo(m_graph.freeze(jsDoubleNumber(limit)))));
2226         return true;
2227     }
2228 
2229     if (argumentCountIncludingThis == 2) {
2230         insertChecks();
<span class="line-modified">2231         Node* resultNode = get(VirtualRegister(virtualRegisterForArgumentIncludingThis(1, registerOffset)));</span>
2232         addToGraph(Phantom, Edge(resultNode, NumberUse));
2233         set(result, resultNode);
2234         return true;
2235     }
2236 
2237     if (argumentCountIncludingThis == 3) {
2238         insertChecks();
<span class="line-modified">2239         set(result, addToGraph(op, get(virtualRegisterForArgumentIncludingThis(1, registerOffset)), get(virtualRegisterForArgumentIncludingThis(2, registerOffset))));</span>
2240         return true;
2241     }
2242 
2243     // Don&#39;t handle &gt;=3 arguments for now.
2244     return false;
2245 }
2246 
2247 template&lt;typename ChecksFunctor&gt;
2248 bool ByteCodeParser::handleIntrinsicCall(Node* callee, VirtualRegister result, Intrinsic intrinsic, int registerOffset, int argumentCountIncludingThis, SpeculatedType prediction, const ChecksFunctor&amp; insertChecks)
2249 {
2250     VERBOSE_LOG(&quot;       The intrinsic is &quot;, intrinsic, &quot;\n&quot;);
2251 
2252     if (!isOpcodeShape&lt;OpCallShape&gt;(m_currentInstruction))
2253         return false;
2254 
2255     // It so happens that the code below doesn&#39;t handle the invalid result case. We could fix that, but
2256     // it would only benefit intrinsics called as setters, like if you do:
2257     //
2258     //     o.__defineSetter__(&quot;foo&quot;, Math.pow)
2259     //
</pre>
<hr />
<pre>
2267         set(result, node);
2268         didSetResult = true;
2269     };
2270 
2271     auto inlineIntrinsic = [&amp;] {
2272         switch (intrinsic) {
2273 
2274         // Intrinsic Functions:
2275 
2276         case AbsIntrinsic: {
2277             if (argumentCountIncludingThis == 1) { // Math.abs()
2278                 insertChecks();
2279                 setResult(addToGraph(JSConstant, OpInfo(m_constantNaN)));
2280                 return true;
2281             }
2282 
2283             if (!MacroAssembler::supportsFloatingPointAbs())
2284                 return false;
2285 
2286             insertChecks();
<span class="line-modified">2287             Node* node = addToGraph(ArithAbs, get(virtualRegisterForArgumentIncludingThis(1, registerOffset)));</span>
2288             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, Overflow))
2289                 node-&gt;mergeFlags(NodeMayOverflowInt32InDFG);
2290             setResult(node);
2291             return true;
2292         }
2293 
2294         case MinIntrinsic:
2295         case MaxIntrinsic:
2296             if (handleMinMax(result, intrinsic == MinIntrinsic ? ArithMin : ArithMax, registerOffset, argumentCountIncludingThis, insertChecks)) {
2297                 didSetResult = true;
2298                 return true;
2299             }
2300             return false;
2301 
2302 #define DFG_ARITH_UNARY(capitalizedName, lowerName) \
2303         case capitalizedName##Intrinsic:
2304         FOR_EACH_DFG_ARITH_UNARY_OP(DFG_ARITH_UNARY)
2305 #undef DFG_ARITH_UNARY
2306         {
2307             if (argumentCountIncludingThis == 1) {
2308                 insertChecks();
2309                 setResult(addToGraph(JSConstant, OpInfo(m_constantNaN)));
2310                 return true;
2311             }
2312             Arith::UnaryType type = Arith::UnaryType::Sin;
2313             switch (intrinsic) {
2314 #define DFG_ARITH_UNARY(capitalizedName, lowerName) \
2315             case capitalizedName##Intrinsic: \
2316                 type = Arith::UnaryType::capitalizedName; \
2317                 break;
2318         FOR_EACH_DFG_ARITH_UNARY_OP(DFG_ARITH_UNARY)
2319 #undef DFG_ARITH_UNARY
2320             default:
2321                 RELEASE_ASSERT_NOT_REACHED();
2322             }
2323             insertChecks();
<span class="line-modified">2324             setResult(addToGraph(ArithUnary, OpInfo(static_cast&lt;std::underlying_type&lt;Arith::UnaryType&gt;::type&gt;(type)), get(virtualRegisterForArgumentIncludingThis(1, registerOffset))));</span>
2325             return true;
2326         }
2327 
2328         case FRoundIntrinsic:
2329         case SqrtIntrinsic: {
2330             if (argumentCountIncludingThis == 1) {
2331                 insertChecks();
2332                 setResult(addToGraph(JSConstant, OpInfo(m_constantNaN)));
2333                 return true;
2334             }
2335 
2336             NodeType nodeType = Unreachable;
2337             switch (intrinsic) {
2338             case FRoundIntrinsic:
2339                 nodeType = ArithFRound;
2340                 break;
2341             case SqrtIntrinsic:
2342                 nodeType = ArithSqrt;
2343                 break;
2344             default:
2345                 RELEASE_ASSERT_NOT_REACHED();
2346             }
2347             insertChecks();
<span class="line-modified">2348             setResult(addToGraph(nodeType, get(virtualRegisterForArgumentIncludingThis(1, registerOffset))));</span>
2349             return true;
2350         }
2351 
2352         case PowIntrinsic: {
2353             if (argumentCountIncludingThis &lt; 3) {
2354                 // Math.pow() and Math.pow(x) return NaN.
2355                 insertChecks();
2356                 setResult(addToGraph(JSConstant, OpInfo(m_constantNaN)));
2357                 return true;
2358             }
2359             insertChecks();
<span class="line-modified">2360             VirtualRegister xOperand = virtualRegisterForArgumentIncludingThis(1, registerOffset);</span>
<span class="line-modified">2361             VirtualRegister yOperand = virtualRegisterForArgumentIncludingThis(2, registerOffset);</span>
2362             setResult(addToGraph(ArithPow, get(xOperand), get(yOperand)));
2363             return true;
2364         }
2365 
<span class="line-modified">2366         case TypedArrayEntriesIntrinsic:</span>
<span class="line-modified">2367         case TypedArrayKeysIntrinsic:</span>
<span class="line-modified">2368         case TypedArrayValuesIntrinsic: {</span>
<span class="line-modified">2369             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadIndexingType)</span>
<span class="line-modified">2370                 || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))</span>
<span class="line-added">2371                 return false;</span>
<span class="line-added">2372 </span>
<span class="line-added">2373             ArrayMode mode = getArrayMode(Array::Read);</span>
<span class="line-added">2374             if (!mode.isSomeTypedArrayView())</span>
<span class="line-added">2375                 return false;</span>
<span class="line-added">2376 </span>
<span class="line-added">2377             addToGraph(CheckArray, OpInfo(mode.asWord()), get(virtualRegisterForArgumentIncludingThis(0, registerOffset)));</span>
<span class="line-added">2378             addToGraph(CheckNeutered, get(virtualRegisterForArgumentIncludingThis(0, registerOffset)));</span>
<span class="line-added">2379             FALLTHROUGH;</span>
<span class="line-added">2380         }</span>
<span class="line-added">2381 </span>
<span class="line-added">2382         case ArrayEntriesIntrinsic:</span>
<span class="line-added">2383         case ArrayKeysIntrinsic:</span>
<span class="line-added">2384         case ArrayValuesIntrinsic: {</span>
<span class="line-added">2385             insertChecks();</span>
<span class="line-added">2386 </span>
<span class="line-added">2387             IterationKind kind;</span>
<span class="line-added">2388             switch (intrinsic) {</span>
<span class="line-added">2389             case ArrayValuesIntrinsic:</span>
<span class="line-added">2390             case TypedArrayValuesIntrinsic:</span>
<span class="line-added">2391                 kind = IterationKind::Values;</span>
<span class="line-added">2392                 break;</span>
<span class="line-added">2393             case ArrayKeysIntrinsic:</span>
<span class="line-added">2394             case TypedArrayKeysIntrinsic:</span>
<span class="line-added">2395                 kind = IterationKind::Keys;</span>
<span class="line-added">2396                 break;</span>
<span class="line-added">2397             case ArrayEntriesIntrinsic:</span>
<span class="line-added">2398             case TypedArrayEntriesIntrinsic:</span>
<span class="line-added">2399                 kind = IterationKind::Entries;</span>
<span class="line-added">2400                 break;</span>
<span class="line-added">2401             default:</span>
<span class="line-added">2402                 RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-added">2403                 break;</span>
2404             }

2405 
<span class="line-added">2406             // Add the constant before exit becomes invalid because we may want to insert (redundant) checks on it in Fixup.</span>
<span class="line-added">2407             Node* kindNode = jsConstant(jsNumber(static_cast&lt;uint32_t&gt;(kind)));</span>
<span class="line-added">2408 </span>
<span class="line-added">2409             // We don&#39;t have an existing error string.</span>
<span class="line-added">2410             unsigned errorStringIndex = UINT32_MAX;</span>
<span class="line-added">2411             Node* object = addToGraph(ToObject, OpInfo(errorStringIndex), OpInfo(SpecNone), get(virtualRegisterForArgumentIncludingThis(0, registerOffset)));</span>
<span class="line-added">2412 </span>
<span class="line-added">2413             JSGlobalObject* globalObject = m_graph.globalObjectFor(currentNodeOrigin().semantic);</span>
<span class="line-added">2414             Node* iterator = addToGraph(NewArrayIterator, OpInfo(m_graph.registerStructure(globalObject-&gt;arrayIteratorStructure())));</span>
<span class="line-added">2415 </span>
<span class="line-added">2416             addToGraph(PutInternalField, OpInfo(static_cast&lt;uint32_t&gt;(JSArrayIterator::Field::IteratedObject)), iterator, object);</span>
<span class="line-added">2417             addToGraph(PutInternalField, OpInfo(static_cast&lt;uint32_t&gt;(JSArrayIterator::Field::Kind)), iterator, kindNode);</span>
<span class="line-added">2418 </span>
<span class="line-added">2419             setResult(iterator);</span>
<span class="line-added">2420             return true;</span>
<span class="line-added">2421         }</span>
<span class="line-added">2422 </span>
<span class="line-added">2423         case ArrayPushIntrinsic: {</span>
2424             if (static_cast&lt;unsigned&gt;(argumentCountIncludingThis) &gt;= MIN_SPARSE_ARRAY_INDEX)
2425                 return false;
2426 
2427             ArrayMode arrayMode = getArrayMode(Array::Write);
2428             if (!arrayMode.isJSArray())
2429                 return false;
2430             switch (arrayMode.type()) {
2431             case Array::Int32:
2432             case Array::Double:
2433             case Array::Contiguous:
2434             case Array::ArrayStorage: {
2435                 insertChecks();
2436 
2437                 addVarArgChild(nullptr); // For storage.
2438                 for (int i = 0; i &lt; argumentCountIncludingThis; ++i)
<span class="line-modified">2439                     addVarArgChild(get(virtualRegisterForArgumentIncludingThis(i, registerOffset)));</span>
2440                 Node* arrayPush = addToGraph(Node::VarArg, ArrayPush, OpInfo(arrayMode.asWord()), OpInfo(prediction));
2441                 setResult(arrayPush);
2442                 return true;
2443             }
2444 
2445             default:
2446                 return false;
2447             }
2448         }
2449 
2450         case ArraySliceIntrinsic: {






2451             if (argumentCountIncludingThis &lt; 1)
2452                 return false;
2453 
2454             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadConstantCache)
2455                 || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCache))
2456                 return false;
2457 
2458             ArrayMode arrayMode = getArrayMode(Array::Read);
2459             if (!arrayMode.isJSArray())
2460                 return false;
2461 
2462             if (!arrayMode.isJSArrayWithOriginalStructure())
2463                 return false;
2464 
2465             switch (arrayMode.type()) {
2466             case Array::Double:
2467             case Array::Int32:
2468             case Array::Contiguous: {
2469                 JSGlobalObject* globalObject = m_graph.globalObjectFor(currentNodeOrigin().semantic);
2470 
2471                 Structure* arrayPrototypeStructure = globalObject-&gt;arrayPrototype()-&gt;structure(*m_vm);
2472                 Structure* objectPrototypeStructure = globalObject-&gt;objectPrototype()-&gt;structure(*m_vm);
2473 
2474                 // FIXME: We could easily relax the Array/Object.prototype transition as long as we OSR exitted if we saw a hole.
2475                 // https://bugs.webkit.org/show_bug.cgi?id=173171
2476                 if (globalObject-&gt;arraySpeciesWatchpointSet().state() == IsWatched
2477                     &amp;&amp; globalObject-&gt;havingABadTimeWatchpoint()-&gt;isStillValid()
2478                     &amp;&amp; arrayPrototypeStructure-&gt;transitionWatchpointSetIsStillValid()
2479                     &amp;&amp; objectPrototypeStructure-&gt;transitionWatchpointSetIsStillValid()
2480                     &amp;&amp; globalObject-&gt;arrayPrototypeChainIsSane()) {
2481 
2482                     m_graph.watchpoints().addLazily(globalObject-&gt;arraySpeciesWatchpointSet());
2483                     m_graph.watchpoints().addLazily(globalObject-&gt;havingABadTimeWatchpoint());
2484                     m_graph.registerAndWatchStructureTransition(arrayPrototypeStructure);
2485                     m_graph.registerAndWatchStructureTransition(objectPrototypeStructure);
2486 
2487                     insertChecks();
2488 
<span class="line-modified">2489                     Node* array = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
2490                     // We do a few things here to prove that we aren&#39;t skipping doing side-effects in an observable way:
2491                     // 1. We ensure that the &quot;constructor&quot; property hasn&#39;t been changed (because the observable
2492                     // effects of slice require that we perform a Get(array, &quot;constructor&quot;) and we can skip
2493                     // that if we&#39;re an original array structure. (We can relax this in the future by using
2494                     // TryGetById and CheckCell).
2495                     //
2496                     // 2. We check that the array we&#39;re calling slice on has the same global object as the lexical
2497                     // global object that this code is running in. This requirement is necessary because we setup the
2498                     // watchpoints above on the lexical global object. This means that code that calls slice on
2499                     // arrays produced by other global objects won&#39;t get this optimization. We could relax this
2500                     // requirement in the future by checking that the watchpoint hasn&#39;t fired at runtime in the code
2501                     // we generate instead of registering it as a watchpoint that would invalidate the compilation.
2502                     //
2503                     // 3. By proving we&#39;re an original array structure, we guarantee that the incoming array
2504                     // isn&#39;t a subclass of Array.
2505 
2506                     StructureSet structureSet;
2507                     structureSet.add(globalObject-&gt;originalArrayStructureForIndexingType(ArrayWithInt32));
2508                     structureSet.add(globalObject-&gt;originalArrayStructureForIndexingType(ArrayWithContiguous));
2509                     structureSet.add(globalObject-&gt;originalArrayStructureForIndexingType(ArrayWithDouble));
2510                     structureSet.add(globalObject-&gt;originalArrayStructureForIndexingType(CopyOnWriteArrayWithInt32));
2511                     structureSet.add(globalObject-&gt;originalArrayStructureForIndexingType(CopyOnWriteArrayWithContiguous));
2512                     structureSet.add(globalObject-&gt;originalArrayStructureForIndexingType(CopyOnWriteArrayWithDouble));
2513                     addToGraph(CheckStructure, OpInfo(m_graph.addStructureSet(structureSet)), array);
2514 
2515                     addVarArgChild(array);
2516                     if (argumentCountIncludingThis &gt;= 2)
<span class="line-modified">2517                         addVarArgChild(get(virtualRegisterForArgumentIncludingThis(1, registerOffset))); // Start index.</span>
2518                     if (argumentCountIncludingThis &gt;= 3)
<span class="line-modified">2519                         addVarArgChild(get(virtualRegisterForArgumentIncludingThis(2, registerOffset))); // End index.</span>
2520                     addVarArgChild(addToGraph(GetButterfly, array));
2521 
2522                     Node* arraySlice = addToGraph(Node::VarArg, ArraySlice, OpInfo(), OpInfo());
2523                     setResult(arraySlice);
2524                     return true;
2525                 }
2526 
2527                 return false;
2528             }
2529             default:
2530                 return false;
2531             }
2532 
2533             RELEASE_ASSERT_NOT_REACHED();
2534             return false;
2535         }
2536 
2537         case ArrayIndexOfIntrinsic: {
2538             if (argumentCountIncludingThis &lt; 2)
2539                 return false;
</pre>
<hr />
<pre>
2558             switch (arrayMode.type()) {
2559             case Array::Double:
2560             case Array::Int32:
2561             case Array::Contiguous: {
2562                 JSGlobalObject* globalObject = m_graph.globalObjectFor(currentNodeOrigin().semantic);
2563 
2564                 Structure* arrayPrototypeStructure = globalObject-&gt;arrayPrototype()-&gt;structure(*m_vm);
2565                 Structure* objectPrototypeStructure = globalObject-&gt;objectPrototype()-&gt;structure(*m_vm);
2566 
2567                 // FIXME: We could easily relax the Array/Object.prototype transition as long as we OSR exitted if we saw a hole.
2568                 // https://bugs.webkit.org/show_bug.cgi?id=173171
2569                 if (arrayPrototypeStructure-&gt;transitionWatchpointSetIsStillValid()
2570                     &amp;&amp; objectPrototypeStructure-&gt;transitionWatchpointSetIsStillValid()
2571                     &amp;&amp; globalObject-&gt;arrayPrototypeChainIsSane()) {
2572 
2573                     m_graph.registerAndWatchStructureTransition(arrayPrototypeStructure);
2574                     m_graph.registerAndWatchStructureTransition(objectPrototypeStructure);
2575 
2576                     insertChecks();
2577 
<span class="line-modified">2578                     Node* array = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
2579                     addVarArgChild(array);
<span class="line-modified">2580                     addVarArgChild(get(virtualRegisterForArgumentIncludingThis(1, registerOffset))); // Search element.</span>
2581                     if (argumentCountIncludingThis &gt;= 3)
<span class="line-modified">2582                         addVarArgChild(get(virtualRegisterForArgumentIncludingThis(2, registerOffset))); // Start index.</span>
2583                     addVarArgChild(nullptr);
2584 
2585                     Node* node = addToGraph(Node::VarArg, ArrayIndexOf, OpInfo(arrayMode.asWord()), OpInfo());
2586                     setResult(node);
2587                     return true;
2588                 }
2589 
2590                 return false;
2591             }
2592             default:
2593                 return false;
2594             }
2595 
2596             RELEASE_ASSERT_NOT_REACHED();
2597             return false;
2598 
2599         }
2600 
2601         case ArrayPopIntrinsic: {



2602             ArrayMode arrayMode = getArrayMode(Array::Write);
2603             if (!arrayMode.isJSArray())
2604                 return false;
2605             switch (arrayMode.type()) {
2606             case Array::Int32:
2607             case Array::Double:
2608             case Array::Contiguous:
2609             case Array::ArrayStorage: {
2610                 insertChecks();
<span class="line-modified">2611                 Node* arrayPop = addToGraph(ArrayPop, OpInfo(arrayMode.asWord()), OpInfo(prediction), get(virtualRegisterForArgumentIncludingThis(0, registerOffset)));</span>
2612                 setResult(arrayPop);
2613                 return true;
2614             }
2615 
2616             default:
2617                 return false;
2618             }
2619         }
2620 
2621         case AtomicsAddIntrinsic:
2622         case AtomicsAndIntrinsic:
2623         case AtomicsCompareExchangeIntrinsic:
2624         case AtomicsExchangeIntrinsic:
2625         case AtomicsIsLockFreeIntrinsic:
2626         case AtomicsLoadIntrinsic:
2627         case AtomicsOrIntrinsic:
2628         case AtomicsStoreIntrinsic:
2629         case AtomicsSubIntrinsic:
2630         case AtomicsXorIntrinsic: {
2631             if (!is64Bit())
</pre>
<hr />
<pre>
2673             case AtomicsSubIntrinsic:
2674                 op = AtomicsSub;
2675                 numArgs = 3;
2676                 break;
2677             case AtomicsXorIntrinsic:
2678                 op = AtomicsXor;
2679                 numArgs = 3;
2680                 break;
2681             default:
2682                 RELEASE_ASSERT_NOT_REACHED();
2683                 break;
2684             }
2685 
2686             if (static_cast&lt;unsigned&gt;(argumentCountIncludingThis) &lt; 1 + numArgs)
2687                 return false;
2688 
2689             insertChecks();
2690 
2691             Vector&lt;Node*, 3&gt; args;
2692             for (unsigned i = 0; i &lt; numArgs; ++i)
<span class="line-modified">2693                 args.append(get(virtualRegisterForArgumentIncludingThis(1 + i, registerOffset)));</span>
2694 
2695             Node* resultNode;
2696             if (numArgs + 1 &lt;= 3) {
2697                 while (args.size() &lt; 3)
2698                     args.append(nullptr);
2699                 resultNode = addToGraph(op, OpInfo(ArrayMode(Array::SelectUsingPredictions, action).asWord()), OpInfo(prediction), args[0], args[1], args[2]);
2700             } else {
2701                 for (Node* node : args)
2702                     addVarArgChild(node);
2703                 addVarArgChild(nullptr);
2704                 resultNode = addToGraph(Node::VarArg, op, OpInfo(ArrayMode(Array::SelectUsingPredictions, action).asWord()), OpInfo(prediction));
2705             }
2706 
2707             setResult(resultNode);
2708             return true;
2709         }
2710 
2711         case ParseIntIntrinsic: {
2712             if (argumentCountIncludingThis &lt; 2)
2713                 return false;
2714 
2715             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell) || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
2716                 return false;
2717 
2718             insertChecks();
<span class="line-modified">2719             VirtualRegister valueOperand = virtualRegisterForArgumentIncludingThis(1, registerOffset);</span>
2720             Node* parseInt;
2721             if (argumentCountIncludingThis == 2)
2722                 parseInt = addToGraph(ParseInt, OpInfo(), OpInfo(prediction), get(valueOperand));
2723             else {
2724                 ASSERT(argumentCountIncludingThis &gt; 2);
<span class="line-modified">2725                 VirtualRegister radixOperand = virtualRegisterForArgumentIncludingThis(2, registerOffset);</span>
2726                 parseInt = addToGraph(ParseInt, OpInfo(), OpInfo(prediction), get(valueOperand), get(radixOperand));
2727             }
2728             setResult(parseInt);
2729             return true;
2730         }
2731 
2732         case CharCodeAtIntrinsic: {
<span class="line-modified">2733             if (argumentCountIncludingThis &lt; 2)</span>
<span class="line-added">2734                 return false;</span>
<span class="line-added">2735 </span>
<span class="line-added">2736             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, Uncountable) || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))</span>
2737                 return false;
2738 
2739             insertChecks();
<span class="line-modified">2740             VirtualRegister thisOperand = virtualRegisterForArgumentIncludingThis(0, registerOffset);</span>
<span class="line-modified">2741             VirtualRegister indexOperand = virtualRegisterForArgumentIncludingThis(1, registerOffset);</span>
2742             Node* charCode = addToGraph(StringCharCodeAt, OpInfo(ArrayMode(Array::String, Array::Read).asWord()), get(thisOperand), get(indexOperand));
2743 
2744             setResult(charCode);
2745             return true;
2746         }
2747 
<span class="line-added">2748         case StringPrototypeCodePointAtIntrinsic: {</span>
<span class="line-added">2749             if (!is64Bit())</span>
<span class="line-added">2750                 return false;</span>
<span class="line-added">2751 </span>
<span class="line-added">2752             if (argumentCountIncludingThis &lt; 2)</span>
<span class="line-added">2753                 return false;</span>
<span class="line-added">2754 </span>
<span class="line-added">2755             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, Uncountable) || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))</span>
<span class="line-added">2756                 return false;</span>
<span class="line-added">2757 </span>
<span class="line-added">2758             insertChecks();</span>
<span class="line-added">2759             VirtualRegister thisOperand = virtualRegisterForArgumentIncludingThis(0, registerOffset);</span>
<span class="line-added">2760             VirtualRegister indexOperand = virtualRegisterForArgumentIncludingThis(1, registerOffset);</span>
<span class="line-added">2761             Node* result = addToGraph(StringCodePointAt, OpInfo(ArrayMode(Array::String, Array::Read).asWord()), get(thisOperand), get(indexOperand));</span>
<span class="line-added">2762 </span>
<span class="line-added">2763             setResult(result);</span>
<span class="line-added">2764             return true;</span>
<span class="line-added">2765         }</span>
<span class="line-added">2766 </span>
2767         case CharAtIntrinsic: {
<span class="line-modified">2768             if (argumentCountIncludingThis &lt; 2)</span>
2769                 return false;
2770 
<span class="line-added">2771             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))</span>
<span class="line-added">2772                 return false;</span>
<span class="line-added">2773 </span>
<span class="line-added">2774             // FIXME: String#charAt returns empty string when index is out-of-bounds, and this does not break the AI&#39;s claim.</span>
<span class="line-added">2775             // Only FTL supports out-of-bounds version now. We should support out-of-bounds version even in DFG.</span>
<span class="line-added">2776             // https://bugs.webkit.org/show_bug.cgi?id=201678</span>
<span class="line-added">2777 </span>
2778             insertChecks();
<span class="line-modified">2779             VirtualRegister thisOperand = virtualRegisterForArgumentIncludingThis(0, registerOffset);</span>
<span class="line-modified">2780             VirtualRegister indexOperand = virtualRegisterForArgumentIncludingThis(1, registerOffset);</span>
2781             Node* charCode = addToGraph(StringCharAt, OpInfo(ArrayMode(Array::String, Array::Read).asWord()), get(thisOperand), get(indexOperand));
2782 
2783             setResult(charCode);
2784             return true;
2785         }
2786         case Clz32Intrinsic: {
2787             insertChecks();
2788             if (argumentCountIncludingThis == 1)
2789                 setResult(addToGraph(JSConstant, OpInfo(m_graph.freeze(jsNumber(32)))));
2790             else {
<span class="line-modified">2791                 Node* operand = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
2792                 setResult(addToGraph(ArithClz32, operand));
2793             }
2794             return true;
2795         }
2796         case FromCharCodeIntrinsic: {
2797             if (argumentCountIncludingThis != 2)
2798                 return false;
2799 
2800             insertChecks();
<span class="line-modified">2801             VirtualRegister indexOperand = virtualRegisterForArgumentIncludingThis(1, registerOffset);</span>
2802             Node* charCode = addToGraph(StringFromCharCode, get(indexOperand));
2803 
2804             setResult(charCode);
2805 
2806             return true;
2807         }
2808 
2809         case RegExpExecIntrinsic: {
<span class="line-modified">2810             if (argumentCountIncludingThis &lt; 2)</span>
2811                 return false;
2812 
2813             insertChecks();
<span class="line-modified">2814             Node* regExpExec = addToGraph(RegExpExec, OpInfo(0), OpInfo(prediction), addToGraph(GetGlobalObject, callee), get(virtualRegisterForArgumentIncludingThis(0, registerOffset)), get(virtualRegisterForArgumentIncludingThis(1, registerOffset)));</span>
2815             setResult(regExpExec);
2816 
2817             return true;
2818         }
2819 
2820         case RegExpTestIntrinsic:
2821         case RegExpTestFastIntrinsic: {
<span class="line-modified">2822             if (argumentCountIncludingThis &lt; 2)</span>
2823                 return false;
2824 
2825             if (intrinsic == RegExpTestIntrinsic) {
2826                 // Don&#39;t inline intrinsic if we exited due to one of the primordial RegExp checks failing.
2827                 if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell))
2828                     return false;
2829 
2830                 JSGlobalObject* globalObject = m_inlineStackTop-&gt;m_codeBlock-&gt;globalObject();
2831                 Structure* regExpStructure = globalObject-&gt;regExpStructure();
2832                 m_graph.registerStructure(regExpStructure);
2833                 ASSERT(regExpStructure-&gt;storedPrototype().isObject());
2834                 ASSERT(regExpStructure-&gt;storedPrototype().asCell()-&gt;classInfo(*m_vm) == RegExpPrototype::info());
2835 
2836                 FrozenValue* regExpPrototypeObjectValue = m_graph.freeze(regExpStructure-&gt;storedPrototype());
2837                 Structure* regExpPrototypeStructure = regExpPrototypeObjectValue-&gt;structure();
2838 
2839                 auto isRegExpPropertySame = [&amp;] (JSValue primordialProperty, UniquedStringImpl* propertyUID) {
2840                     JSValue currentProperty;
2841                     if (!m_graph.getRegExpPrototypeProperty(regExpStructure-&gt;storedPrototypeObject(), regExpPrototypeStructure, propertyUID, currentProperty))
2842                         return false;
2843 
2844                     return currentProperty == primordialProperty;
2845                 };
2846 
2847                 // Check that RegExp.exec is still the primordial RegExp.prototype.exec
2848                 if (!isRegExpPropertySame(globalObject-&gt;regExpProtoExecFunction(), m_vm-&gt;propertyNames-&gt;exec.impl()))
2849                     return false;
2850 
2851                 // Check that regExpObject is actually a RegExp object.
<span class="line-modified">2852                 Node* regExpObject = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
2853                 addToGraph(Check, Edge(regExpObject, RegExpObjectUse));
2854 
2855                 // Check that regExpObject&#39;s exec is actually the primodial RegExp.prototype.exec.
2856                 UniquedStringImpl* execPropertyID = m_vm-&gt;propertyNames-&gt;exec.impl();
2857                 unsigned execIndex = m_graph.identifiers().ensure(execPropertyID);
2858                 Node* actualProperty = addToGraph(TryGetById, OpInfo(execIndex), OpInfo(SpecFunction), Edge(regExpObject, CellUse));
2859                 FrozenValue* regExpPrototypeExec = m_graph.freeze(globalObject-&gt;regExpProtoExecFunction());
2860                 addToGraph(CheckCell, OpInfo(regExpPrototypeExec), Edge(actualProperty, CellUse));
2861             }
2862 
2863             insertChecks();
<span class="line-modified">2864             Node* regExpObject = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
<span class="line-modified">2865             Node* regExpExec = addToGraph(RegExpTest, OpInfo(0), OpInfo(prediction), addToGraph(GetGlobalObject, callee), regExpObject, get(virtualRegisterForArgumentIncludingThis(1, registerOffset)));</span>
2866             setResult(regExpExec);
2867 
2868             return true;
2869         }
2870 
2871         case RegExpMatchFastIntrinsic: {
2872             RELEASE_ASSERT(argumentCountIncludingThis == 2);
2873 
2874             insertChecks();
<span class="line-modified">2875             Node* regExpMatch = addToGraph(RegExpMatchFast, OpInfo(0), OpInfo(prediction), addToGraph(GetGlobalObject, callee), get(virtualRegisterForArgumentIncludingThis(0, registerOffset)), get(virtualRegisterForArgumentIncludingThis(1, registerOffset)));</span>
2876             setResult(regExpMatch);
2877             return true;
2878         }
2879 
2880         case ObjectCreateIntrinsic: {
2881             if (argumentCountIncludingThis != 2)
2882                 return false;
2883 
2884             insertChecks();
<span class="line-modified">2885             setResult(addToGraph(ObjectCreate, get(virtualRegisterForArgumentIncludingThis(1, registerOffset))));</span>
2886             return true;
2887         }
2888 
2889         case ObjectGetPrototypeOfIntrinsic: {
<span class="line-modified">2890             if (argumentCountIncludingThis &lt; 2)</span>
2891                 return false;
2892 
2893             insertChecks();
<span class="line-modified">2894             setResult(addToGraph(GetPrototypeOf, OpInfo(0), OpInfo(prediction), get(virtualRegisterForArgumentIncludingThis(1, registerOffset))));</span>
2895             return true;
2896         }
2897 
2898         case ObjectIsIntrinsic: {
2899             if (argumentCountIncludingThis &lt; 3)
2900                 return false;
2901 
2902             insertChecks();
<span class="line-modified">2903             setResult(addToGraph(SameValue, get(virtualRegisterForArgumentIncludingThis(1, registerOffset)), get(virtualRegisterForArgumentIncludingThis(2, registerOffset))));</span>
2904             return true;
2905         }
2906 
2907         case ObjectKeysIntrinsic: {
2908             if (argumentCountIncludingThis &lt; 2)
2909                 return false;
2910 
2911             insertChecks();
<span class="line-modified">2912             setResult(addToGraph(ObjectKeys, get(virtualRegisterForArgumentIncludingThis(1, registerOffset))));</span>
2913             return true;
2914         }
2915 
2916         case ReflectGetPrototypeOfIntrinsic: {
<span class="line-modified">2917             if (argumentCountIncludingThis &lt; 2)</span>
2918                 return false;
2919 
2920             insertChecks();
<span class="line-modified">2921             setResult(addToGraph(GetPrototypeOf, OpInfo(0), OpInfo(prediction), Edge(get(virtualRegisterForArgumentIncludingThis(1, registerOffset)), ObjectUse)));</span>
2922             return true;
2923         }
2924 
2925         case IsTypedArrayViewIntrinsic: {
2926             ASSERT(argumentCountIncludingThis == 2);
2927 
2928             insertChecks();
<span class="line-modified">2929             setResult(addToGraph(IsTypedArrayView, OpInfo(prediction), get(virtualRegisterForArgumentIncludingThis(1, registerOffset))));</span>
2930             return true;
2931         }
2932 
2933         case StringPrototypeValueOfIntrinsic: {
2934             insertChecks();
<span class="line-modified">2935             Node* value = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
2936             setResult(addToGraph(StringValueOf, value));
2937             return true;
2938         }
2939 
2940         case StringPrototypeReplaceIntrinsic: {
<span class="line-modified">2941             if (argumentCountIncludingThis &lt; 3)</span>
2942                 return false;
2943 
2944             // Don&#39;t inline intrinsic if we exited due to &quot;search&quot; not being a RegExp or String object.
2945             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
2946                 return false;
2947 
2948             // Don&#39;t inline intrinsic if we exited due to one of the primordial RegExp checks failing.
2949             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell))
2950                 return false;
2951 
2952             JSGlobalObject* globalObject = m_inlineStackTop-&gt;m_codeBlock-&gt;globalObject();
2953             Structure* regExpStructure = globalObject-&gt;regExpStructure();
2954             m_graph.registerStructure(regExpStructure);
2955             ASSERT(regExpStructure-&gt;storedPrototype().isObject());
2956             ASSERT(regExpStructure-&gt;storedPrototype().asCell()-&gt;classInfo(*m_vm) == RegExpPrototype::info());
2957 
2958             FrozenValue* regExpPrototypeObjectValue = m_graph.freeze(regExpStructure-&gt;storedPrototype());
2959             Structure* regExpPrototypeStructure = regExpPrototypeObjectValue-&gt;structure();
2960 
2961             auto isRegExpPropertySame = [&amp;] (JSValue primordialProperty, UniquedStringImpl* propertyUID) {
</pre>
<hr />
<pre>
2967             };
2968 
2969             // Check that searchRegExp.exec is still the primordial RegExp.prototype.exec
2970             if (!isRegExpPropertySame(globalObject-&gt;regExpProtoExecFunction(), m_vm-&gt;propertyNames-&gt;exec.impl()))
2971                 return false;
2972 
2973             // Check that searchRegExp.global is still the primordial RegExp.prototype.global
2974             if (!isRegExpPropertySame(globalObject-&gt;regExpProtoGlobalGetter(), m_vm-&gt;propertyNames-&gt;global.impl()))
2975                 return false;
2976 
2977             // Check that searchRegExp.unicode is still the primordial RegExp.prototype.unicode
2978             if (!isRegExpPropertySame(globalObject-&gt;regExpProtoUnicodeGetter(), m_vm-&gt;propertyNames-&gt;unicode.impl()))
2979                 return false;
2980 
2981             // Check that searchRegExp[Symbol.match] is still the primordial RegExp.prototype[Symbol.replace]
2982             if (!isRegExpPropertySame(globalObject-&gt;regExpProtoSymbolReplaceFunction(), m_vm-&gt;propertyNames-&gt;replaceSymbol.impl()))
2983                 return false;
2984 
2985             insertChecks();
2986 
<span class="line-modified">2987             Node* resultNode = addToGraph(StringReplace, OpInfo(0), OpInfo(prediction), get(virtualRegisterForArgumentIncludingThis(0, registerOffset)), get(virtualRegisterForArgumentIncludingThis(1, registerOffset)), get(virtualRegisterForArgumentIncludingThis(2, registerOffset)));</span>
2988             setResult(resultNode);
2989             return true;
2990         }
2991 
2992         case StringPrototypeReplaceRegExpIntrinsic: {
<span class="line-modified">2993             if (argumentCountIncludingThis &lt; 3)</span>
2994                 return false;
2995 
2996             insertChecks();
<span class="line-modified">2997             Node* resultNode = addToGraph(StringReplaceRegExp, OpInfo(0), OpInfo(prediction), get(virtualRegisterForArgumentIncludingThis(0, registerOffset)), get(virtualRegisterForArgumentIncludingThis(1, registerOffset)), get(virtualRegisterForArgumentIncludingThis(2, registerOffset)));</span>
2998             setResult(resultNode);
2999             return true;
3000         }
3001 
3002         case RoundIntrinsic:
3003         case FloorIntrinsic:
3004         case CeilIntrinsic:
3005         case TruncIntrinsic: {
3006             if (argumentCountIncludingThis == 1) {
3007                 insertChecks();
3008                 setResult(addToGraph(JSConstant, OpInfo(m_constantNaN)));
3009                 return true;
3010             }
3011             insertChecks();
<span class="line-modified">3012             Node* operand = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3013             NodeType op;
3014             if (intrinsic == RoundIntrinsic)
3015                 op = ArithRound;
3016             else if (intrinsic == FloorIntrinsic)
3017                 op = ArithFloor;
3018             else if (intrinsic == CeilIntrinsic)
3019                 op = ArithCeil;
3020             else {
3021                 ASSERT(intrinsic == TruncIntrinsic);
3022                 op = ArithTrunc;
3023             }
3024             Node* roundNode = addToGraph(op, OpInfo(0), OpInfo(prediction), operand);
3025             setResult(roundNode);
3026             return true;
3027         }
3028         case IMulIntrinsic: {
<span class="line-modified">3029             if (argumentCountIncludingThis &lt; 3)</span>
3030                 return false;
3031             insertChecks();
<span class="line-modified">3032             VirtualRegister leftOperand = virtualRegisterForArgumentIncludingThis(1, registerOffset);</span>
<span class="line-modified">3033             VirtualRegister rightOperand = virtualRegisterForArgumentIncludingThis(2, registerOffset);</span>
3034             Node* left = get(leftOperand);
3035             Node* right = get(rightOperand);
3036             setResult(addToGraph(ArithIMul, left, right));
3037             return true;
3038         }
3039 
3040         case RandomIntrinsic: {


3041             insertChecks();
3042             setResult(addToGraph(ArithRandom));
3043             return true;
3044         }
3045 
3046         case DFGTrueIntrinsic: {
3047             insertChecks();
3048             setResult(jsConstant(jsBoolean(true)));
3049             return true;
3050         }
3051 
3052         case FTLTrueIntrinsic: {
3053             insertChecks();
3054             setResult(jsConstant(jsBoolean(m_graph.m_plan.isFTL())));
3055             return true;
3056         }
3057 
3058         case OSRExitIntrinsic: {
3059             insertChecks();
3060             addToGraph(ForceOSRExit);
3061             setResult(addToGraph(JSConstant, OpInfo(m_constantUndefined)));
3062             return true;
3063         }
3064 
3065         case IsFinalTierIntrinsic: {
3066             insertChecks();
3067             setResult(jsConstant(jsBoolean(Options::useFTLJIT() ? m_graph.m_plan.isFTL() : true)));
3068             return true;
3069         }
3070 
3071         case SetInt32HeapPredictionIntrinsic: {
3072             insertChecks();
3073             for (int i = 1; i &lt; argumentCountIncludingThis; ++i) {
<span class="line-modified">3074                 Node* node = get(virtualRegisterForArgumentIncludingThis(i, registerOffset));</span>
3075                 if (node-&gt;hasHeapPrediction())
3076                     node-&gt;setHeapPrediction(SpecInt32Only);
3077             }
3078             setResult(addToGraph(JSConstant, OpInfo(m_constantUndefined)));
3079             return true;
3080         }
3081 
3082         case CheckInt32Intrinsic: {
3083             insertChecks();
3084             for (int i = 1; i &lt; argumentCountIncludingThis; ++i) {
<span class="line-modified">3085                 Node* node = get(virtualRegisterForArgumentIncludingThis(i, registerOffset));</span>
3086                 addToGraph(Phantom, Edge(node, Int32Use));
3087             }
3088             setResult(jsConstant(jsBoolean(true)));
3089             return true;
3090         }
3091 
3092         case FiatInt52Intrinsic: {
<span class="line-modified">3093             if (argumentCountIncludingThis &lt; 2)</span>
3094                 return false;
3095             insertChecks();
<span class="line-modified">3096             VirtualRegister operand = virtualRegisterForArgumentIncludingThis(1, registerOffset);</span>
3097             if (enableInt52())
3098                 setResult(addToGraph(FiatInt52, get(operand)));
3099             else
3100                 setResult(get(operand));
3101             return true;
3102         }
3103 
3104         case JSMapGetIntrinsic: {
<span class="line-modified">3105             if (argumentCountIncludingThis &lt; 2)</span>
3106                 return false;
3107 
3108             insertChecks();
<span class="line-modified">3109             Node* map = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
<span class="line-modified">3110             Node* key = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3111             Node* normalizedKey = addToGraph(NormalizeMapKey, key);
3112             Node* hash = addToGraph(MapHash, normalizedKey);
3113             Node* bucket = addToGraph(GetMapBucket, Edge(map, MapObjectUse), Edge(normalizedKey), Edge(hash));
3114             Node* resultNode = addToGraph(LoadValueFromMapBucket, OpInfo(BucketOwnerType::Map), OpInfo(prediction), bucket);
3115             setResult(resultNode);
3116             return true;
3117         }
3118 
3119         case JSSetHasIntrinsic:
3120         case JSMapHasIntrinsic: {
<span class="line-modified">3121             if (argumentCountIncludingThis &lt; 2)</span>
3122                 return false;
3123 
3124             insertChecks();
<span class="line-modified">3125             Node* mapOrSet = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
<span class="line-modified">3126             Node* key = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3127             Node* normalizedKey = addToGraph(NormalizeMapKey, key);
3128             Node* hash = addToGraph(MapHash, normalizedKey);
3129             UseKind useKind = intrinsic == JSSetHasIntrinsic ? SetObjectUse : MapObjectUse;
3130             Node* bucket = addToGraph(GetMapBucket, OpInfo(0), Edge(mapOrSet, useKind), Edge(normalizedKey), Edge(hash));
3131             JSCell* sentinel = nullptr;
3132             if (intrinsic == JSMapHasIntrinsic)
3133                 sentinel = m_vm-&gt;sentinelMapBucket();
3134             else
3135                 sentinel = m_vm-&gt;sentinelSetBucket();
3136 
3137             FrozenValue* frozenPointer = m_graph.freeze(sentinel);
3138             Node* invertedResult = addToGraph(CompareEqPtr, OpInfo(frozenPointer), bucket);
3139             Node* resultNode = addToGraph(LogicalNot, invertedResult);
3140             setResult(resultNode);
3141             return true;
3142         }
3143 
3144         case JSSetAddIntrinsic: {
<span class="line-modified">3145             if (argumentCountIncludingThis &lt; 2)</span>
3146                 return false;
3147 
3148             insertChecks();
<span class="line-modified">3149             Node* base = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
<span class="line-modified">3150             Node* key = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3151             Node* normalizedKey = addToGraph(NormalizeMapKey, key);
3152             Node* hash = addToGraph(MapHash, normalizedKey);
3153             addToGraph(SetAdd, base, normalizedKey, hash);
3154             setResult(base);
3155             return true;
3156         }
3157 
3158         case JSMapSetIntrinsic: {
<span class="line-modified">3159             if (argumentCountIncludingThis &lt; 3)</span>
3160                 return false;
3161 
3162             insertChecks();
<span class="line-modified">3163             Node* base = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
<span class="line-modified">3164             Node* key = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
<span class="line-modified">3165             Node* value = get(virtualRegisterForArgumentIncludingThis(2, registerOffset));</span>
3166 
3167             Node* normalizedKey = addToGraph(NormalizeMapKey, key);
3168             Node* hash = addToGraph(MapHash, normalizedKey);
3169 
3170             addVarArgChild(base);
3171             addVarArgChild(normalizedKey);
3172             addVarArgChild(value);
3173             addVarArgChild(hash);
3174             addToGraph(Node::VarArg, MapSet, OpInfo(0), OpInfo(0));
3175             setResult(base);
3176             return true;
3177         }
3178 
3179         case JSSetBucketHeadIntrinsic:
3180         case JSMapBucketHeadIntrinsic: {
3181             ASSERT(argumentCountIncludingThis == 2);
3182 
3183             insertChecks();
<span class="line-modified">3184             Node* map = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3185             UseKind useKind = intrinsic == JSSetBucketHeadIntrinsic ? SetObjectUse : MapObjectUse;
3186             Node* resultNode = addToGraph(GetMapBucketHead, Edge(map, useKind));
3187             setResult(resultNode);
3188             return true;
3189         }
3190 
3191         case JSSetBucketNextIntrinsic:
3192         case JSMapBucketNextIntrinsic: {
3193             ASSERT(argumentCountIncludingThis == 2);
3194 
3195             insertChecks();
<span class="line-modified">3196             Node* bucket = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3197             BucketOwnerType type = intrinsic == JSSetBucketNextIntrinsic ? BucketOwnerType::Set : BucketOwnerType::Map;
3198             Node* resultNode = addToGraph(GetMapBucketNext, OpInfo(type), bucket);
3199             setResult(resultNode);
3200             return true;
3201         }
3202 
3203         case JSSetBucketKeyIntrinsic:
3204         case JSMapBucketKeyIntrinsic: {
3205             ASSERT(argumentCountIncludingThis == 2);
3206 
3207             insertChecks();
<span class="line-modified">3208             Node* bucket = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3209             BucketOwnerType type = intrinsic == JSSetBucketKeyIntrinsic ? BucketOwnerType::Set : BucketOwnerType::Map;
3210             Node* resultNode = addToGraph(LoadKeyFromMapBucket, OpInfo(type), OpInfo(prediction), bucket);
3211             setResult(resultNode);
3212             return true;
3213         }
3214 
3215         case JSMapBucketValueIntrinsic: {
3216             ASSERT(argumentCountIncludingThis == 2);
3217 
3218             insertChecks();
<span class="line-modified">3219             Node* bucket = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3220             Node* resultNode = addToGraph(LoadValueFromMapBucket, OpInfo(BucketOwnerType::Map), OpInfo(prediction), bucket);
3221             setResult(resultNode);
3222             return true;
3223         }
3224 
3225         case JSWeakMapGetIntrinsic: {
<span class="line-modified">3226             if (argumentCountIncludingThis &lt; 2)</span>
3227                 return false;
3228 
3229             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3230                 return false;
3231 
3232             insertChecks();
<span class="line-modified">3233             Node* map = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
<span class="line-modified">3234             Node* key = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3235             addToGraph(Check, Edge(key, ObjectUse));
3236             Node* hash = addToGraph(MapHash, key);
3237             Node* holder = addToGraph(WeakMapGet, Edge(map, WeakMapObjectUse), Edge(key, ObjectUse), Edge(hash, Int32Use));
3238             Node* resultNode = addToGraph(ExtractValueFromWeakMapGet, OpInfo(), OpInfo(prediction), holder);
3239 
3240             setResult(resultNode);
3241             return true;
3242         }
3243 
3244         case JSWeakMapHasIntrinsic: {
<span class="line-modified">3245             if (argumentCountIncludingThis &lt; 2)</span>
3246                 return false;
3247 
3248             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3249                 return false;
3250 
3251             insertChecks();
<span class="line-modified">3252             Node* map = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
<span class="line-modified">3253             Node* key = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3254             addToGraph(Check, Edge(key, ObjectUse));
3255             Node* hash = addToGraph(MapHash, key);
3256             Node* holder = addToGraph(WeakMapGet, Edge(map, WeakMapObjectUse), Edge(key, ObjectUse), Edge(hash, Int32Use));
3257             Node* invertedResult = addToGraph(IsEmpty, holder);
3258             Node* resultNode = addToGraph(LogicalNot, invertedResult);
3259 
3260             setResult(resultNode);
3261             return true;
3262         }
3263 
3264         case JSWeakSetHasIntrinsic: {
<span class="line-modified">3265             if (argumentCountIncludingThis &lt; 2)</span>
3266                 return false;
3267 
3268             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3269                 return false;
3270 
3271             insertChecks();
<span class="line-modified">3272             Node* map = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
<span class="line-modified">3273             Node* key = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3274             addToGraph(Check, Edge(key, ObjectUse));
3275             Node* hash = addToGraph(MapHash, key);
3276             Node* holder = addToGraph(WeakMapGet, Edge(map, WeakSetObjectUse), Edge(key, ObjectUse), Edge(hash, Int32Use));
3277             Node* invertedResult = addToGraph(IsEmpty, holder);
3278             Node* resultNode = addToGraph(LogicalNot, invertedResult);
3279 
3280             setResult(resultNode);
3281             return true;
3282         }
3283 
3284         case JSWeakSetAddIntrinsic: {
<span class="line-modified">3285             if (argumentCountIncludingThis &lt; 2)</span>
3286                 return false;
3287 
3288             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3289                 return false;
3290 
3291             insertChecks();
<span class="line-modified">3292             Node* base = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
<span class="line-modified">3293             Node* key = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3294             addToGraph(Check, Edge(key, ObjectUse));
3295             Node* hash = addToGraph(MapHash, key);
3296             addToGraph(WeakSetAdd, Edge(base, WeakSetObjectUse), Edge(key, ObjectUse), Edge(hash, Int32Use));
3297             setResult(base);
3298             return true;
3299         }
3300 
3301         case JSWeakMapSetIntrinsic: {
<span class="line-modified">3302             if (argumentCountIncludingThis &lt; 3)</span>
3303                 return false;
3304 
3305             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3306                 return false;
3307 
3308             insertChecks();
<span class="line-modified">3309             Node* base = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
<span class="line-modified">3310             Node* key = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
<span class="line-modified">3311             Node* value = get(virtualRegisterForArgumentIncludingThis(2, registerOffset));</span>
3312 
3313             addToGraph(Check, Edge(key, ObjectUse));
3314             Node* hash = addToGraph(MapHash, key);
3315 
3316             addVarArgChild(Edge(base, WeakMapObjectUse));
3317             addVarArgChild(Edge(key, ObjectUse));
3318             addVarArgChild(Edge(value));
3319             addVarArgChild(Edge(hash, Int32Use));
3320             addToGraph(Node::VarArg, WeakMapSet, OpInfo(0), OpInfo(0));
3321             setResult(base);
3322             return true;
3323         }
3324 
<span class="line-added">3325         case DatePrototypeGetTimeIntrinsic: {</span>
<span class="line-added">3326             if (!is64Bit())</span>
<span class="line-added">3327                 return false;</span>
<span class="line-added">3328             insertChecks();</span>
<span class="line-added">3329             Node* base = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
<span class="line-added">3330             setResult(addToGraph(DateGetTime, OpInfo(intrinsic), OpInfo(), base));</span>
<span class="line-added">3331             return true;</span>
<span class="line-added">3332         }</span>
<span class="line-added">3333 </span>
<span class="line-added">3334         case DatePrototypeGetFullYearIntrinsic:</span>
<span class="line-added">3335         case DatePrototypeGetUTCFullYearIntrinsic:</span>
<span class="line-added">3336         case DatePrototypeGetMonthIntrinsic:</span>
<span class="line-added">3337         case DatePrototypeGetUTCMonthIntrinsic:</span>
<span class="line-added">3338         case DatePrototypeGetDateIntrinsic:</span>
<span class="line-added">3339         case DatePrototypeGetUTCDateIntrinsic:</span>
<span class="line-added">3340         case DatePrototypeGetDayIntrinsic:</span>
<span class="line-added">3341         case DatePrototypeGetUTCDayIntrinsic:</span>
<span class="line-added">3342         case DatePrototypeGetHoursIntrinsic:</span>
<span class="line-added">3343         case DatePrototypeGetUTCHoursIntrinsic:</span>
<span class="line-added">3344         case DatePrototypeGetMinutesIntrinsic:</span>
<span class="line-added">3345         case DatePrototypeGetUTCMinutesIntrinsic:</span>
<span class="line-added">3346         case DatePrototypeGetSecondsIntrinsic:</span>
<span class="line-added">3347         case DatePrototypeGetUTCSecondsIntrinsic:</span>
<span class="line-added">3348         case DatePrototypeGetMillisecondsIntrinsic:</span>
<span class="line-added">3349         case DatePrototypeGetUTCMillisecondsIntrinsic:</span>
<span class="line-added">3350         case DatePrototypeGetTimezoneOffsetIntrinsic:</span>
<span class="line-added">3351         case DatePrototypeGetYearIntrinsic: {</span>
<span class="line-added">3352             if (!is64Bit())</span>
<span class="line-added">3353                 return false;</span>
<span class="line-added">3354             insertChecks();</span>
<span class="line-added">3355             Node* base = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
<span class="line-added">3356             setResult(addToGraph(DateGetInt32OrNaN, OpInfo(intrinsic), OpInfo(prediction), base));</span>
<span class="line-added">3357             return true;</span>
<span class="line-added">3358         }</span>
<span class="line-added">3359 </span>
3360         case DataViewGetInt8:
3361         case DataViewGetUint8:
3362         case DataViewGetInt16:
3363         case DataViewGetUint16:
3364         case DataViewGetInt32:
3365         case DataViewGetUint32:
3366         case DataViewGetFloat32:
3367         case DataViewGetFloat64: {
3368             if (!is64Bit())
3369                 return false;
3370 
3371             // To inline data view accesses, we assume the architecture we&#39;re running on:
3372             // - Is little endian.
3373             // - Allows unaligned loads/stores without crashing.
3374 
3375             if (argumentCountIncludingThis &lt; 2)
3376                 return false;
3377             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3378                 return false;
3379 
</pre>
<hr />
<pre>
3405                 break;
3406 
3407             case DataViewGetFloat32:
3408                 byteSize = 4;
3409                 op = DataViewGetFloat;
3410                 break;
3411             case DataViewGetFloat64:
3412                 byteSize = 8;
3413                 op = DataViewGetFloat;
3414                 break;
3415             default:
3416                 RELEASE_ASSERT_NOT_REACHED();
3417             }
3418 
3419             TriState isLittleEndian = MixedTriState;
3420             Node* littleEndianChild = nullptr;
3421             if (byteSize &gt; 1) {
3422                 if (argumentCountIncludingThis &lt; 3)
3423                     isLittleEndian = FalseTriState;
3424                 else {
<span class="line-modified">3425                     littleEndianChild = get(virtualRegisterForArgumentIncludingThis(2, registerOffset));</span>
3426                     if (littleEndianChild-&gt;hasConstant()) {
3427                         JSValue constant = littleEndianChild-&gt;constant()-&gt;value();
3428                         if (constant) {
3429                             isLittleEndian = constant.pureToBoolean();
3430                             if (isLittleEndian != MixedTriState)
3431                                 littleEndianChild = nullptr;
3432                         }
3433                     } else
3434                         isLittleEndian = MixedTriState;
3435                 }
3436             }
3437 
3438             DataViewData data { };
3439             data.isLittleEndian = isLittleEndian;
3440             data.isSigned = isSigned;
3441             data.byteSize = byteSize;
3442 
3443             setResult(
<span class="line-modified">3444                 addToGraph(op, OpInfo(data.asQuadWord), OpInfo(prediction), get(virtualRegisterForArgumentIncludingThis(0, registerOffset)), get(virtualRegisterForArgumentIncludingThis(1, registerOffset)), littleEndianChild));</span>
3445             return true;
3446         }
3447 
3448         case DataViewSetInt8:
3449         case DataViewSetUint8:
3450         case DataViewSetInt16:
3451         case DataViewSetUint16:
3452         case DataViewSetInt32:
3453         case DataViewSetUint32:
3454         case DataViewSetFloat32:
3455         case DataViewSetFloat64: {
3456             if (!is64Bit())
3457                 return false;
3458 
3459             if (argumentCountIncludingThis &lt; 3)
3460                 return false;
3461 
3462             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3463                 return false;
3464 
</pre>
<hr />
<pre>
3490                 break;
3491 
3492             case DataViewSetFloat32:
3493                 isFloatingPoint = true;
3494                 byteSize = 4;
3495                 break;
3496             case DataViewSetFloat64:
3497                 isFloatingPoint = true;
3498                 byteSize = 8;
3499                 break;
3500             default:
3501                 RELEASE_ASSERT_NOT_REACHED();
3502             }
3503 
3504             TriState isLittleEndian = MixedTriState;
3505             Node* littleEndianChild = nullptr;
3506             if (byteSize &gt; 1) {
3507                 if (argumentCountIncludingThis &lt; 4)
3508                     isLittleEndian = FalseTriState;
3509                 else {
<span class="line-modified">3510                     littleEndianChild = get(virtualRegisterForArgumentIncludingThis(3, registerOffset));</span>
3511                     if (littleEndianChild-&gt;hasConstant()) {
3512                         JSValue constant = littleEndianChild-&gt;constant()-&gt;value();
3513                         if (constant) {
3514                             isLittleEndian = constant.pureToBoolean();
3515                             if (isLittleEndian != MixedTriState)
3516                                 littleEndianChild = nullptr;
3517                         }
3518                     } else
3519                         isLittleEndian = MixedTriState;
3520                 }
3521             }
3522 
3523             DataViewData data { };
3524             data.isLittleEndian = isLittleEndian;
3525             data.isSigned = isSigned;
3526             data.byteSize = byteSize;
3527             data.isFloatingPoint = isFloatingPoint;
3528 
<span class="line-modified">3529             addVarArgChild(get(virtualRegisterForArgumentIncludingThis(0, registerOffset)));</span>
<span class="line-modified">3530             addVarArgChild(get(virtualRegisterForArgumentIncludingThis(1, registerOffset)));</span>
<span class="line-modified">3531             addVarArgChild(get(virtualRegisterForArgumentIncludingThis(2, registerOffset)));</span>
3532             addVarArgChild(littleEndianChild);
3533 
3534             addToGraph(Node::VarArg, DataViewSet, OpInfo(data.asQuadWord), OpInfo());
3535             setResult(addToGraph(JSConstant, OpInfo(m_constantUndefined)));
3536             return true;
3537         }
3538 
3539         case HasOwnPropertyIntrinsic: {
<span class="line-modified">3540             if (argumentCountIncludingThis &lt; 2)</span>
3541                 return false;
3542 
3543             // This can be racy, that&#39;s fine. We know that once we observe that this is created,
3544             // that it will never be destroyed until the VM is destroyed. It&#39;s unlikely that
3545             // we&#39;d ever get to the point where we inline this as an intrinsic without the
3546             // cache being created, however, it&#39;s possible if we always throw exceptions inside
3547             // hasOwnProperty.
3548             if (!m_vm-&gt;hasOwnPropertyCache())
3549                 return false;
3550 
3551             insertChecks();
<span class="line-modified">3552             Node* object = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
<span class="line-modified">3553             Node* key = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3554             Node* resultNode = addToGraph(HasOwnProperty, object, key);
3555             setResult(resultNode);
3556             return true;
3557         }
3558 
3559         case StringPrototypeSliceIntrinsic: {
3560             if (argumentCountIncludingThis &lt; 2)
3561                 return false;
3562 
3563             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3564                 return false;
3565 
3566             insertChecks();
<span class="line-modified">3567             Node* thisString = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
<span class="line-modified">3568             Node* start = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3569             Node* end = nullptr;
3570             if (argumentCountIncludingThis &gt; 2)
<span class="line-modified">3571                 end = get(virtualRegisterForArgumentIncludingThis(2, registerOffset));</span>
3572             Node* resultNode = addToGraph(StringSlice, thisString, start, end);
3573             setResult(resultNode);
3574             return true;
3575         }
3576 
3577         case StringPrototypeToLowerCaseIntrinsic: {



3578             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3579                 return false;
3580 
3581             insertChecks();
<span class="line-modified">3582             Node* thisString = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
3583             Node* resultNode = addToGraph(ToLowerCase, thisString);
3584             setResult(resultNode);
3585             return true;
3586         }
3587 
3588         case NumberPrototypeToStringIntrinsic: {



3589             if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType))
3590                 return false;
3591 
3592             insertChecks();
<span class="line-modified">3593             Node* thisNumber = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
3594             if (argumentCountIncludingThis == 1) {
3595                 Node* resultNode = addToGraph(ToString, thisNumber);
3596                 setResult(resultNode);
3597             } else {
<span class="line-modified">3598                 Node* radix = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3599                 Node* resultNode = addToGraph(NumberToStringWithRadix, thisNumber, radix);
3600                 setResult(resultNode);
3601             }
3602             return true;
3603         }
3604 
3605         case NumberIsIntegerIntrinsic: {
3606             if (argumentCountIncludingThis &lt; 2)
3607                 return false;
3608 
3609             insertChecks();
<span class="line-modified">3610             Node* input = get(virtualRegisterForArgumentIncludingThis(1, registerOffset));</span>
3611             Node* resultNode = addToGraph(NumberIsInteger, input);
3612             setResult(resultNode);
3613             return true;
3614         }
3615 
3616         case CPUMfenceIntrinsic:
3617         case CPURdtscIntrinsic:
3618         case CPUCpuidIntrinsic:
3619         case CPUPauseIntrinsic: {
3620 #if CPU(X86_64)
3621             if (!m_graph.m_plan.isFTL())
3622                 return false;
3623             insertChecks();
3624             setResult(addToGraph(CPUIntrinsic, OpInfo(intrinsic), OpInfo()));
3625             return true;
3626 #else
3627             return false;
3628 #endif
3629         }
3630 
</pre>
<hr />
<pre>
3763     }
3764 
3765     default:
3766         return false;
3767     }
3768     RELEASE_ASSERT_NOT_REACHED();
3769 }
3770 
3771 static void blessCallDOMGetter(Node* node)
3772 {
3773     DOMJIT::CallDOMGetterSnippet* snippet = node-&gt;callDOMGetterData()-&gt;snippet;
3774     if (snippet &amp;&amp; !snippet-&gt;effect.mustGenerate())
3775         node-&gt;clearFlags(NodeMustGenerate);
3776 }
3777 
3778 bool ByteCodeParser::handleDOMJITGetter(VirtualRegister result, const GetByIdVariant&amp; variant, Node* thisNode, unsigned identifierNumber, SpeculatedType prediction)
3779 {
3780     if (!variant.domAttribute())
3781         return false;
3782 
<span class="line-modified">3783     auto* domAttribute = variant.domAttribute();</span>
3784 
3785     // We do not need to actually look up CustomGetterSetter here. Checking Structures or registering watchpoints are enough,
3786     // since replacement of CustomGetterSetter always incurs Structure transition.
3787     if (!check(variant.conditionSet()))
3788         return false;
3789     addToGraph(CheckStructure, OpInfo(m_graph.addStructureSet(variant.structureSet())), thisNode);
3790 
3791     // We do not need to emit CheckCell thingy here. When the custom accessor is replaced to different one, Structure transition occurs.
<span class="line-modified">3792     addToGraph(CheckSubClass, OpInfo(domAttribute-&gt;classInfo), thisNode);</span>
3793 
3794     bool wasSeenInJIT = true;
<span class="line-modified">3795     GetByStatus* status = m_graph.m_plan.recordedStatuses().addGetByStatus(currentCodeOrigin(), GetByStatus(GetByStatus::Custom, wasSeenInJIT));</span>
<span class="line-added">3796     bool success = status-&gt;appendVariant(variant);</span>
<span class="line-added">3797     RELEASE_ASSERT(success);</span>
<span class="line-added">3798     addToGraph(FilterGetByStatus, OpInfo(status), thisNode);</span>
3799 
3800     CallDOMGetterData* callDOMGetterData = m_graph.m_callDOMGetterData.add();
3801     callDOMGetterData-&gt;customAccessorGetter = variant.customAccessorGetter();
3802     ASSERT(callDOMGetterData-&gt;customAccessorGetter);
3803 
<span class="line-modified">3804     if (const auto* domJIT = domAttribute-&gt;domJIT) {</span>
3805         callDOMGetterData-&gt;domJIT = domJIT;
3806         Ref&lt;DOMJIT::CallDOMGetterSnippet&gt; snippet = domJIT-&gt;compiler()();
3807         callDOMGetterData-&gt;snippet = snippet.ptr();
3808         m_graph.m_domJITSnippets.append(WTFMove(snippet));
3809     }
3810     DOMJIT::CallDOMGetterSnippet* callDOMGetterSnippet = callDOMGetterData-&gt;snippet;
3811     callDOMGetterData-&gt;identifierNumber = identifierNumber;
3812 
3813     Node* callDOMGetterNode = nullptr;
3814     // GlobalObject of thisNode is always used to create a DOMWrapper.
3815     if (callDOMGetterSnippet &amp;&amp; callDOMGetterSnippet-&gt;requireGlobalObject) {
3816         Node* globalObject = addToGraph(GetGlobalObject, thisNode);
3817         callDOMGetterNode = addToGraph(CallDOMGetter, OpInfo(callDOMGetterData), OpInfo(prediction), thisNode, globalObject);
3818     } else
3819         callDOMGetterNode = addToGraph(CallDOMGetter, OpInfo(callDOMGetterData), OpInfo(prediction), thisNode);
3820     blessCallDOMGetter(callDOMGetterNode);
3821     set(result, callDOMGetterNode);
3822     return true;
3823 }
3824 
<span class="line-modified">3825 bool ByteCodeParser::handleModuleNamespaceLoad(VirtualRegister result, SpeculatedType prediction, Node* base, GetByStatus getById)</span>
3826 {
3827     if (m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell))
3828         return false;
3829     addToGraph(CheckCell, OpInfo(m_graph.freeze(getById.moduleNamespaceObject())), Edge(base, CellUse));
3830 
<span class="line-modified">3831     addToGraph(FilterGetByStatus, OpInfo(m_graph.m_plan.recordedStatuses().addGetByStatus(currentCodeOrigin(), getById)), base);</span>
3832 
3833     // Ideally we wouldn&#39;t have to do this Phantom. But:
3834     //
3835     // For the constant case: we must do it because otherwise we would have no way of knowing
3836     // that the scope is live at OSR here.
3837     //
3838     // For the non-constant case: GetClosureVar could be DCE&#39;d, but baseline&#39;s implementation
3839     // won&#39;t be able to handle an Undefined scope.
3840     addToGraph(Phantom, base);
3841 
3842     // Constant folding in the bytecode parser is important for performance. This may not
3843     // have executed yet. If it hasn&#39;t, then we won&#39;t have a prediction. Lacking a
3844     // prediction, we&#39;d otherwise think that it has to exit. Then when it did execute, we
3845     // would recompile. But if we can fold it here, we avoid the exit.
3846     m_graph.freeze(getById.moduleEnvironment());
3847     if (JSValue value = m_graph.tryGetConstantClosureVar(getById.moduleEnvironment(), getById.scopeOffset())) {
3848         set(result, weakJSConstant(value));
3849         return true;
3850     }
3851     set(result, addToGraph(GetClosureVar, OpInfo(getById.scopeOffset().offset()), OpInfo(prediction), weakJSConstant(getById.moduleEnvironment())));
3852     return true;
3853 }
3854 
3855 template&lt;typename ChecksFunctor&gt;
3856 bool ByteCodeParser::handleTypedArrayConstructor(
3857     VirtualRegister result, InternalFunction* function, int registerOffset,
3858     int argumentCountIncludingThis, TypedArrayType type, const ChecksFunctor&amp; insertChecks)
3859 {
3860     if (!isTypedView(type))
3861         return false;
3862 
<span class="line-modified">3863     if (function-&gt;classInfo(*m_vm) != constructorClassInfoForType(type))</span>
3864         return false;
3865 
<span class="line-modified">3866     if (function-&gt;globalObject() != m_inlineStackTop-&gt;m_codeBlock-&gt;globalObject())</span>
3867         return false;
3868 
3869     // We only have an intrinsic for the case where you say:
3870     //
3871     // new FooArray(blah);
3872     //
3873     // Of course, &#39;blah&#39; could be any of the following:
3874     //
3875     // - Integer, indicating that you want to allocate an array of that length.
3876     //   This is the thing we&#39;re hoping for, and what we can actually do meaningful
3877     //   optimizations for.
3878     //
3879     // - Array buffer, indicating that you want to create a view onto that _entire_
3880     //   buffer.
3881     //
3882     // - Non-buffer object, indicating that you want to create a copy of that
3883     //   object by pretending that it quacks like an array.
3884     //
3885     // - Anything else, indicating that you want to have an exception thrown at
3886     //   you.
3887     //
3888     // The intrinsic, NewTypedArray, will behave as if it could do any of these
3889     // things up until we do Fixup. Thereafter, if child1 (i.e. &#39;blah&#39;) is
3890     // predicted Int32, then we lock it in as a normal typed array allocation.
3891     // Otherwise, NewTypedArray turns into a totally opaque function call that
3892     // may clobber the world - by virtue of it accessing properties on what could
3893     // be an object.
3894     //
3895     // Note that although the generic form of NewTypedArray sounds sort of awful,
3896     // it is actually quite likely to be more efficient than a fully generic
3897     // Construct. So, we might want to think about making NewTypedArray variadic,
3898     // or else making Construct not super slow.
3899 
3900     if (argumentCountIncludingThis != 2)
3901         return false;
3902 
<span class="line-modified">3903     if (!function-&gt;globalObject()-&gt;typedArrayStructureConcurrently(type))</span>
3904         return false;
3905 
3906     insertChecks();
3907     set(result,
<span class="line-modified">3908         addToGraph(NewTypedArray, OpInfo(type), get(virtualRegisterForArgumentIncludingThis(1, registerOffset))));</span>
3909     return true;
3910 }
3911 
3912 template&lt;typename ChecksFunctor&gt;
3913 bool ByteCodeParser::handleConstantInternalFunction(
3914     Node* callTargetNode, VirtualRegister result, InternalFunction* function, int registerOffset,
3915     int argumentCountIncludingThis, CodeSpecializationKind kind, SpeculatedType prediction, const ChecksFunctor&amp; insertChecks)
3916 {
3917     VERBOSE_LOG(&quot;    Handling constant internal function &quot;, JSValue(function), &quot;\n&quot;);
3918 
3919     // It so happens that the code below assumes that the result operand is valid. It&#39;s extremely
3920     // unlikely that the result operand would be invalid - you&#39;d have to call this via a setter call.
3921     if (!result.isValid())
3922         return false;
3923 
3924     if (kind == CodeForConstruct) {
<span class="line-modified">3925         Node* newTargetNode = get(virtualRegisterForArgumentIncludingThis(0, registerOffset));</span>
3926         // We cannot handle the case where new.target != callee (i.e. a construct from a super call) because we
3927         // don&#39;t know what the prototype of the constructed object will be.
3928         // FIXME: If we have inlined super calls up to the call site, however, we should be able to figure out the structure. https://bugs.webkit.org/show_bug.cgi?id=152700
3929         if (newTargetNode != callTargetNode)
3930             return false;
3931     }
3932 
<span class="line-modified">3933     if (function-&gt;classInfo(*m_vm) == ArrayConstructor::info()) {</span>
<span class="line-modified">3934         if (function-&gt;globalObject() != m_inlineStackTop-&gt;m_codeBlock-&gt;globalObject())</span>
3935             return false;
3936 
3937         insertChecks();
3938         if (argumentCountIncludingThis == 2) {
3939             set(result,
<span class="line-modified">3940                 addToGraph(NewArrayWithSize, OpInfo(ArrayWithUndecided), get(virtualRegisterForArgumentIncludingThis(1, registerOffset))));</span>
3941             return true;
3942         }
3943 
3944         for (int i = 1; i &lt; argumentCountIncludingThis; ++i)
<span class="line-modified">3945             addVarArgChild(get(virtualRegisterForArgumentIncludingThis(i, registerOffset)));</span>
3946         set(result,
3947             addToGraph(Node::VarArg, NewArray, OpInfo(ArrayWithUndecided), OpInfo(argumentCountIncludingThis - 1)));
3948         return true;
3949     }
3950 
<span class="line-modified">3951     if (function-&gt;classInfo(*m_vm) == NumberConstructor::info()) {</span>
3952         if (kind == CodeForConstruct)
3953             return false;
3954 
3955         insertChecks();
3956         if (argumentCountIncludingThis &lt;= 1)
3957             set(result, jsConstant(jsNumber(0)));
3958         else
<span class="line-modified">3959             set(result, addToGraph(ToNumber, OpInfo(0), OpInfo(prediction), get(virtualRegisterForArgumentIncludingThis(1, registerOffset))));</span>
3960 
3961         return true;
3962     }
3963 
<span class="line-modified">3964     if (function-&gt;classInfo(*m_vm) == StringConstructor::info()) {</span>
3965         insertChecks();
3966 
3967         Node* resultNode;
3968 
3969         if (argumentCountIncludingThis &lt;= 1)
3970             resultNode = jsConstant(m_vm-&gt;smallStrings.emptyString());
3971         else
<span class="line-modified">3972             resultNode = addToGraph(CallStringConstructor, get(virtualRegisterForArgumentIncludingThis(1, registerOffset)));</span>
3973 
3974         if (kind == CodeForConstruct)
<span class="line-modified">3975             resultNode = addToGraph(NewStringObject, OpInfo(m_graph.registerStructure(function-&gt;globalObject()-&gt;stringObjectStructure())), resultNode);</span>
3976 
3977         set(result, resultNode);
3978         return true;
3979     }
3980 
<span class="line-modified">3981     if (function-&gt;classInfo(*m_vm) == SymbolConstructor::info() &amp;&amp; kind == CodeForCall) {</span>
3982         insertChecks();
3983 
3984         Node* resultNode;
3985 
3986         if (argumentCountIncludingThis &lt;= 1)
3987             resultNode = addToGraph(NewSymbol);
3988         else
<span class="line-modified">3989             resultNode = addToGraph(NewSymbol, addToGraph(ToString, get(virtualRegisterForArgumentIncludingThis(1, registerOffset))));</span>
3990 
3991         set(result, resultNode);
3992         return true;
3993     }
3994 
3995     // FIXME: This should handle construction as well. https://bugs.webkit.org/show_bug.cgi?id=155591
<span class="line-modified">3996     if (function-&gt;classInfo(*m_vm) == ObjectConstructor::info() &amp;&amp; kind == CodeForCall) {</span>
3997         insertChecks();
3998 
3999         Node* resultNode;
4000         if (argumentCountIncludingThis &lt;= 1)
<span class="line-modified">4001             resultNode = addToGraph(NewObject, OpInfo(m_graph.registerStructure(function-&gt;globalObject()-&gt;objectStructureForObjectConstructor())));</span>
4002         else
<span class="line-modified">4003             resultNode = addToGraph(CallObjectConstructor, OpInfo(m_graph.freeze(function-&gt;globalObject())), OpInfo(prediction), get(virtualRegisterForArgumentIncludingThis(1, registerOffset)));</span>
4004         set(result, resultNode);
4005         return true;
4006     }
4007 
4008     for (unsigned typeIndex = 0; typeIndex &lt; NumberOfTypedArrayTypes; ++typeIndex) {
4009         bool handled = handleTypedArrayConstructor(
4010             result, function, registerOffset, argumentCountIncludingThis,
4011             indexToTypedArrayType(typeIndex), insertChecks);
4012         if (handled)
4013             return true;
4014     }
4015 
4016     return false;
4017 }
4018 
4019 Node* ByteCodeParser::handleGetByOffset(
4020     SpeculatedType prediction, Node* base, unsigned identifierNumber, PropertyOffset offset, NodeType op)
4021 {
4022     Node* propertyStorage;
4023     if (isInlineOffset(offset))
</pre>
<hr />
<pre>
4323 Node* ByteCodeParser::load(
4324     SpeculatedType prediction, Node* base, unsigned identifierNumber, const VariantType&amp; variant)
4325 {
4326     // Make sure backwards propagation knows that we&#39;ve used base.
4327     addToGraph(Phantom, base);
4328 
4329     bool needStructureCheck = true;
4330 
4331     UniquedStringImpl* uid = m_graph.identifiers()[identifierNumber];
4332 
4333     if (JSObject* knownBase = base-&gt;dynamicCastConstant&lt;JSObject*&gt;(*m_vm)) {
4334         // Try to optimize away the structure check. Note that it&#39;s not worth doing anything about this
4335         // if the base&#39;s structure is watched.
4336         Structure* structure = base-&gt;constant()-&gt;structure();
4337         if (!structure-&gt;dfgShouldWatch()) {
4338             if (!variant.conditionSet().isEmpty()) {
4339                 // This means that we&#39;re loading from a prototype or we have a property miss. We expect
4340                 // the base not to have the property. We can only use ObjectPropertyCondition if all of
4341                 // the structures in the variant.structureSet() agree on the prototype (it would be
4342                 // hilariously rare if they didn&#39;t). Note that we are relying on structureSet() having
<span class="line-modified">4343                 // at least one element. That will always be true here because of how GetByStatus/PutByIdStatus work.</span>
4344 
4345                 // FIXME: right now, if we have an OPCS, we have mono proto. However, this will
4346                 // need to be changed in the future once we have a hybrid data structure for
4347                 // poly proto:
4348                 // https://bugs.webkit.org/show_bug.cgi?id=177339
4349                 JSObject* prototype = variant.structureSet()[0]-&gt;storedPrototypeObject();
4350                 bool allAgree = true;
4351                 for (unsigned i = 1; i &lt; variant.structureSet().size(); ++i) {
4352                     if (variant.structureSet()[i]-&gt;storedPrototypeObject() != prototype) {
4353                         allAgree = false;
4354                         break;
4355                     }
4356                 }
4357                 if (allAgree) {
4358                     ObjectPropertyCondition condition = ObjectPropertyCondition::absenceWithoutBarrier(
4359                         knownBase, uid, prototype);
4360                     if (check(condition))
4361                         needStructureCheck = false;
4362                 }
4363             } else {
</pre>
<hr />
<pre>
4412                 return weakJSConstant(constant);
4413         }
4414 
4415         loadedValue = handleGetByOffset(
4416             loadPrediction, base, identifierNumber, variant.offset(), loadOp);
4417     }
4418 
4419     return loadedValue;
4420 }
4421 
4422 Node* ByteCodeParser::store(Node* base, unsigned identifier, const PutByIdVariant&amp; variant, Node* value)
4423 {
4424     RELEASE_ASSERT(variant.kind() == PutByIdVariant::Replace);
4425 
4426     checkPresenceLike(base, m_graph.identifiers()[identifier], variant.offset(), variant.structure());
4427     return handlePutByOffset(base, identifier, variant.offset(), value);
4428 }
4429 
4430 void ByteCodeParser::handleGetById(
4431     VirtualRegister destination, SpeculatedType prediction, Node* base, unsigned identifierNumber,
<span class="line-modified">4432     GetByStatus getByStatus, AccessType type, unsigned instructionSize)</span>
4433 {
<span class="line-modified">4434     // Attempt to reduce the set of things in the GetByStatus.</span>
4435     if (base-&gt;op() == NewObject) {
4436         bool ok = true;
4437         for (unsigned i = m_currentBlock-&gt;size(); i--;) {
4438             Node* node = m_currentBlock-&gt;at(i);
4439             if (node == base)
4440                 break;
4441             if (writesOverlap(m_graph, node, JSCell_structureID)) {
4442                 ok = false;
4443                 break;
4444             }
4445         }
4446         if (ok)
<span class="line-modified">4447             getByStatus.filter(base-&gt;structure().get());</span>
4448     }
4449 
4450     NodeType getById;
<span class="line-modified">4451     if (type == AccessType::GetById)</span>
<span class="line-modified">4452         getById = getByStatus.makesCalls() ? GetByIdFlush : GetById;</span>
<span class="line-modified">4453     else if (type == AccessType::TryGetById)</span>
4454         getById = TryGetById;
4455     else
<span class="line-modified">4456         getById = getByStatus.makesCalls() ? GetByIdDirectFlush : GetByIdDirect;</span>
4457 
<span class="line-modified">4458     if (getById != TryGetById &amp;&amp; getByStatus.isModuleNamespace()) {</span>
<span class="line-modified">4459         if (handleModuleNamespaceLoad(destination, prediction, base, getByStatus)) {</span>
4460             if (UNLIKELY(m_graph.compilation()))
4461                 m_graph.compilation()-&gt;noticeInlinedGetById();
4462             return;
4463         }
4464     }
4465 
4466     // Special path for custom accessors since custom&#39;s offset does not have any meanings.
4467     // So, this is completely different from Simple one. But we have a chance to optimize it when we use DOMJIT.
<span class="line-modified">4468     if (Options::useDOMJIT() &amp;&amp; getByStatus.isCustom()) {</span>
<span class="line-modified">4469         ASSERT(getByStatus.numVariants() == 1);</span>
<span class="line-modified">4470         ASSERT(!getByStatus.makesCalls());</span>
<span class="line-modified">4471         GetByIdVariant variant = getByStatus[0];</span>
4472         ASSERT(variant.domAttribute());
4473         if (handleDOMJITGetter(destination, variant, base, identifierNumber, prediction)) {
4474             if (UNLIKELY(m_graph.compilation()))
4475                 m_graph.compilation()-&gt;noticeInlinedGetById();
4476             return;
4477         }
4478     }
4479 
<span class="line-modified">4480     ASSERT(type == AccessType::GetById || type == AccessType::GetByIdDirect ||  !getByStatus.makesCalls());</span>
<span class="line-modified">4481     if (!getByStatus.isSimple() || !getByStatus.numVariants() || !Options::useAccessInlining()) {</span>
4482         set(destination,
4483             addToGraph(getById, OpInfo(identifierNumber), OpInfo(prediction), base));
4484         return;
4485     }
4486 
<span class="line-modified">4487     // FIXME: If we use the GetByStatus for anything then we should record it and insert a node</span>
4488     // after everything else (like the GetByOffset or whatever) that will filter the recorded
<span class="line-modified">4489     // GetByStatus. That means that the constant folder also needs to do the same!</span>
4490 
<span class="line-modified">4491     if (getByStatus.numVariants() &gt; 1) {</span>
<span class="line-modified">4492         if (getByStatus.makesCalls() || !m_graph.m_plan.isFTL()</span>
4493             || !Options::usePolymorphicAccessInlining()
<span class="line-modified">4494             || getByStatus.numVariants() &gt; Options::maxPolymorphicAccessInliningListSize()) {</span>
4495             set(destination,
4496                 addToGraph(getById, OpInfo(identifierNumber), OpInfo(prediction), base));
4497             return;
4498         }
4499 
<span class="line-modified">4500         addToGraph(FilterGetByStatus, OpInfo(m_graph.m_plan.recordedStatuses().addGetByStatus(currentCodeOrigin(), getByStatus)), base);</span>
4501 
4502         Vector&lt;MultiGetByOffsetCase, 2&gt; cases;
4503 
4504         // 1) Emit prototype structure checks for all chains. This could sort of maybe not be
4505         //    optimal, if there is some rarely executed case in the chain that requires a lot
4506         //    of checks and those checks are not watchpointable.
<span class="line-modified">4507         for (const GetByIdVariant&amp; variant : getByStatus.variants()) {</span>
4508             if (variant.intrinsic() != NoIntrinsic) {
4509                 set(destination,
4510                     addToGraph(getById, OpInfo(identifierNumber), OpInfo(prediction), base));
4511                 return;
4512             }
4513 
4514             if (variant.conditionSet().isEmpty()) {
4515                 cases.append(
4516                     MultiGetByOffsetCase(
4517                         *m_graph.addStructureSet(variant.structureSet()),
4518                         GetByOffsetMethod::load(variant.offset())));
4519                 continue;
4520             }
4521 
4522             GetByOffsetMethod method = planLoad(variant.conditionSet());
4523             if (!method) {
4524                 set(destination,
4525                     addToGraph(getById, OpInfo(identifierNumber), OpInfo(prediction), base));
4526                 return;
4527             }
4528 
4529             cases.append(MultiGetByOffsetCase(*m_graph.addStructureSet(variant.structureSet()), method));
4530         }
4531 
4532         if (UNLIKELY(m_graph.compilation()))
4533             m_graph.compilation()-&gt;noticeInlinedGetById();
4534 
4535         // 2) Emit a MultiGetByOffset
4536         MultiGetByOffsetData* data = m_graph.m_multiGetByOffsetData.add();
4537         data-&gt;cases = cases;
4538         data-&gt;identifierNumber = identifierNumber;
4539         set(destination,
4540             addToGraph(MultiGetByOffset, OpInfo(data), OpInfo(prediction), base));
4541         return;
4542     }
4543 
<span class="line-modified">4544     addToGraph(FilterGetByStatus, OpInfo(m_graph.m_plan.recordedStatuses().addGetByStatus(currentCodeOrigin(), getByStatus)), base);</span>
4545 
<span class="line-modified">4546     ASSERT(getByStatus.numVariants() == 1);</span>
<span class="line-modified">4547     GetByIdVariant variant = getByStatus[0];</span>
4548 
4549     Node* loadedValue = load(prediction, base, identifierNumber, variant);
4550     if (!loadedValue) {
4551         set(destination,
4552             addToGraph(getById, OpInfo(identifierNumber), OpInfo(prediction), base));
4553         return;
4554     }
4555 
4556     if (UNLIKELY(m_graph.compilation()))
4557         m_graph.compilation()-&gt;noticeInlinedGetById();
4558 
<span class="line-modified">4559     ASSERT(type == AccessType::GetById || type == AccessType::GetByIdDirect || !variant.callLinkStatus());</span>
4560     if (!variant.callLinkStatus() &amp;&amp; variant.intrinsic() == NoIntrinsic) {
4561         set(destination, loadedValue);
4562         return;
4563     }
4564 
4565     Node* getter = addToGraph(GetGetter, loadedValue);
4566 
4567     if (handleIntrinsicGetter(destination, prediction, variant, base,
4568             [&amp;] () {
4569                 addToGraph(CheckCell, OpInfo(m_graph.freeze(variant.intrinsicFunction())), getter);
4570             })) {
4571         addToGraph(Phantom, base);
4572         return;
4573     }
4574 
4575     ASSERT(variant.intrinsic() == NoIntrinsic);
4576 
4577     // Make a call. We don&#39;t try to get fancy with using the smallest operand number because
4578     // the stack layout phase should compress the stack anyway.
4579 
</pre>
<hr />
<pre>
4585     int registerOffset = virtualRegisterForLocal(
4586         m_inlineStackTop-&gt;m_profiledBlock-&gt;numCalleeLocals() - 1).offset();
4587     registerOffset -= numberOfParameters;
4588     registerOffset -= CallFrame::headerSizeInRegisters;
4589 
4590     // Get the alignment right.
4591     registerOffset = -WTF::roundUpToMultipleOf(
4592         stackAlignmentRegisters(),
4593         -registerOffset);
4594 
4595     ensureLocals(
4596         m_inlineStackTop-&gt;remapOperand(
4597             VirtualRegister(registerOffset)).toLocal());
4598 
4599     // Issue SetLocals. This has two effects:
4600     // 1) That&#39;s how handleCall() sees the arguments.
4601     // 2) If we inline then this ensures that the arguments are flushed so that if you use
4602     //    the dreaded arguments object on the getter, the right things happen. Well, sort of -
4603     //    since we only really care about &#39;this&#39; in this case. But we&#39;re not going to take that
4604     //    shortcut.
<span class="line-modified">4605     set(virtualRegisterForArgumentIncludingThis(0, registerOffset), base, ImmediateNakedSet);</span>
4606 
4607     // We&#39;ve set some locals, but they are not user-visible. It&#39;s still OK to exit from here.
4608     m_exitOK = true;
4609     addToGraph(ExitOK);
4610 
4611     handleCall(
4612         destination, Call, InlineCallFrame::GetterCall, instructionSize,
4613         getter, numberOfParameters - 1, registerOffset, *variant.callLinkStatus(), prediction);
4614 }
4615 
4616 void ByteCodeParser::emitPutById(
4617     Node* base, unsigned identifierNumber, Node* value, const PutByIdStatus&amp; putByIdStatus, bool isDirect)
4618 {
4619     if (isDirect)
4620         addToGraph(PutByIdDirect, OpInfo(identifierNumber), base, value);
4621     else
4622         addToGraph(putByIdStatus.makesCalls() ? PutByIdFlush : PutById, OpInfo(identifierNumber), base, value);
4623 }
4624 
4625 void ByteCodeParser::handlePutById(
</pre>
<hr />
<pre>
4768         unsigned numberOfParameters = 0;
4769         numberOfParameters++; // The &#39;this&#39; argument.
4770         numberOfParameters++; // The new value.
4771         numberOfParameters++; // True return PC.
4772 
4773         // Start with a register offset that corresponds to the last in-use register.
4774         int registerOffset = virtualRegisterForLocal(
4775             m_inlineStackTop-&gt;m_profiledBlock-&gt;numCalleeLocals() - 1).offset();
4776         registerOffset -= numberOfParameters;
4777         registerOffset -= CallFrame::headerSizeInRegisters;
4778 
4779         // Get the alignment right.
4780         registerOffset = -WTF::roundUpToMultipleOf(
4781             stackAlignmentRegisters(),
4782             -registerOffset);
4783 
4784         ensureLocals(
4785             m_inlineStackTop-&gt;remapOperand(
4786                 VirtualRegister(registerOffset)).toLocal());
4787 
<span class="line-modified">4788         set(virtualRegisterForArgumentIncludingThis(0, registerOffset), base, ImmediateNakedSet);</span>
<span class="line-modified">4789         set(virtualRegisterForArgumentIncludingThis(1, registerOffset), value, ImmediateNakedSet);</span>
4790 
4791         // We&#39;ve set some locals, but they are not user-visible. It&#39;s still OK to exit from here.
4792         m_exitOK = true;
4793         addToGraph(ExitOK);
4794 
4795         handleCall(
4796             VirtualRegister(), Call, InlineCallFrame::SetterCall,
4797             instructionSize, setter, numberOfParameters - 1, registerOffset,
4798             *variant.callLinkStatus(), SpecOther);
4799         return;
4800     }
4801 
4802     default: {
4803         emitPutById(base, identifierNumber, value, putByIdStatus, isDirect);
4804         return;
4805     } }
4806 }
4807 
4808 void ByteCodeParser::prepareToParseBlock()
4809 {
4810     clearCaches();
4811     ASSERT(m_setLocalQueue.isEmpty());
4812 }
4813 
4814 void ByteCodeParser::clearCaches()
4815 {
4816     m_constants.shrink(0);
4817 }
4818 
4819 template&lt;typename Op&gt;
4820 void ByteCodeParser::parseGetById(const Instruction* currentInstruction)
4821 {
4822     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
4823     SpeculatedType prediction = getPrediction();
4824 
4825     Node* base = get(bytecode.m_base);
4826     unsigned identifierNumber = m_inlineStackTop-&gt;m_identifierRemap[bytecode.m_property];
4827 
<span class="line-modified">4828     AccessType type = AccessType::GetById;</span>






4829     unsigned opcodeLength = currentInstruction-&gt;size();
4830     if (Op::opcodeID == op_try_get_by_id)
<span class="line-modified">4831         type = AccessType::TryGetById;</span>
4832     else if (Op::opcodeID == op_get_by_id_direct)
<span class="line-modified">4833         type = AccessType::GetByIdDirect;</span>
4834 
<span class="line-modified">4835     GetByStatus getByStatus = GetByStatus::computeFor(</span>
<span class="line-modified">4836         m_inlineStackTop-&gt;m_profiledBlock,</span>
<span class="line-added">4837         m_inlineStackTop-&gt;m_baselineMap, m_icContextStack,</span>
<span class="line-added">4838         currentCodeOrigin());</span>
4839 
<span class="line-added">4840     handleGetById(</span>
<span class="line-added">4841         bytecode.m_dst, prediction, base, identifierNumber, getByStatus, type, opcodeLength);</span>
4842 }
4843 
4844 static uint64_t makeDynamicVarOpInfo(unsigned identifierNumber, unsigned getPutInfo)
4845 {
4846     static_assert(sizeof(identifierNumber) == 4,
4847         &quot;We cannot fit identifierNumber into the high bits of m_opInfo&quot;);
4848     return static_cast&lt;uint64_t&gt;(identifierNumber) | (static_cast&lt;uint64_t&gt;(getPutInfo) &lt;&lt; 32);
4849 }
4850 
4851 // The idiom:
4852 //     if (true) { ...; goto label; } else label: continue
4853 // Allows using NEXT_OPCODE as a statement, even in unbraced if+else, while containing a `continue`.
4854 // The more common idiom:
4855 //     do { ...; } while (false)
4856 // Doesn&#39;t allow using `continue`.
4857 #define NEXT_OPCODE(name) \
4858     if (true) { \
<span class="line-modified">4859         m_currentIndex = BytecodeIndex(m_currentIndex.offset() + currentInstruction-&gt;size()); \</span>
4860         goto WTF_CONCAT(NEXT_OPCODE_, __LINE__); /* Need a unique label: usable more than once per function. */ \
4861     } else \
4862         WTF_CONCAT(NEXT_OPCODE_, __LINE__): \
4863     continue
4864 
4865 #define LAST_OPCODE_LINKED(name) do { \
<span class="line-modified">4866         m_currentIndex = BytecodeIndex(m_currentIndex.offset() + currentInstruction-&gt;size()); \</span>
4867         m_exitOK = false; \
4868         return; \
4869     } while (false)
4870 
4871 #define LAST_OPCODE(name) \
4872     do { \
4873         if (m_currentBlock-&gt;terminal()) { \
4874             switch (m_currentBlock-&gt;terminal()-&gt;op()) { \
4875             case Jump: \
4876             case Branch: \
4877             case Switch: \
4878                 ASSERT(!m_currentBlock-&gt;isLinked); \
4879                 m_inlineStackTop-&gt;m_unlinkedBlocks.append(m_currentBlock); \
4880                 break;\
4881             default: break; \
4882             } \
4883         } \
4884         LAST_OPCODE_LINKED(name); \
4885     } while (false)
4886 
4887 void ByteCodeParser::parseBlock(unsigned limit)
4888 {
4889     auto&amp; instructions = m_inlineStackTop-&gt;m_codeBlock-&gt;instructions();
<span class="line-modified">4890     BytecodeIndex blockBegin = m_currentIndex;</span>
4891 
4892     // If we are the first basic block, introduce markers for arguments. This allows
4893     // us to track if a use of an argument may use the actual argument passed, as
4894     // opposed to using a value we set explicitly.
4895     if (m_currentBlock == m_graph.block(0) &amp;&amp; !inlineCallFrame()) {
4896         auto addResult = m_graph.m_rootToArguments.add(m_currentBlock, ArgumentsVector());
4897         RELEASE_ASSERT(addResult.isNewEntry);
4898         ArgumentsVector&amp; entrypointArguments = addResult.iterator-&gt;value;
4899         entrypointArguments.resize(m_numArguments);
4900 
4901         // We will emit SetArgumentDefinitely nodes. They don&#39;t exit, but we&#39;re at the top of an op_enter so
4902         // exitOK = true.
4903         m_exitOK = true;
4904         for (unsigned argument = 0; argument &lt; m_numArguments; ++argument) {
4905             VariableAccessData* variable = newVariableAccessData(
<span class="line-modified">4906                 virtualRegisterForArgumentIncludingThis(argument));</span>
4907             variable-&gt;mergeStructureCheckHoistingFailed(
4908                 m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCache));
4909             variable-&gt;mergeCheckArrayHoistingFailed(
4910                 m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadIndexingType));
4911 
4912             Node* setArgument = addToGraph(SetArgumentDefinitely, OpInfo(variable));
4913             entrypointArguments[argument] = setArgument;
4914             m_currentBlock-&gt;variablesAtTail.setArgumentFirstTime(argument, setArgument);
4915         }
4916     }
4917 
4918     CodeBlock* codeBlock = m_inlineStackTop-&gt;m_codeBlock;
4919 
4920     auto jumpTarget = [&amp;](int target) {
4921         if (target)
4922             return target;
4923         return codeBlock-&gt;outOfLineJumpOffset(m_currentInstruction);
4924     };
4925 
4926     while (true) {
4927         // We&#39;re staring at a new bytecode instruction. So we once again have a place that we can exit
4928         // to.
4929         m_exitOK = true;
4930 
4931         processSetLocalQueue();
4932 
4933         // Don&#39;t extend over jump destinations.
<span class="line-modified">4934         if (m_currentIndex.offset() == limit) {</span>
4935             // Ordinarily we want to plant a jump. But refuse to do this if the block is
4936             // empty. This is a special case for inlining, which might otherwise create
4937             // some empty blocks in some cases. When parseBlock() returns with an empty
4938             // block, it will get repurposed instead of creating a new one. Note that this
4939             // logic relies on every bytecode resulting in one or more nodes, which would
4940             // be true anyway except for op_loop_hint, which emits a Phantom to force this
4941             // to be true.
4942 
4943             if (!m_currentBlock-&gt;isEmpty())
<span class="line-modified">4944                 addJumpTo(m_currentIndex.offset());</span>
4945             return;
4946         }
4947 
4948         // Switch on the current bytecode opcode.
4949         const Instruction* currentInstruction = instructions.at(m_currentIndex).ptr();
4950         m_currentInstruction = currentInstruction; // Some methods want to use this, and we&#39;d rather not thread it through calls.
4951         OpcodeID opcodeID = currentInstruction-&gt;opcodeID();
4952 
4953         VERBOSE_LOG(&quot;    parsing &quot;, currentCodeOrigin(), &quot;: &quot;, opcodeID, &quot;\n&quot;);
4954 
4955         if (UNLIKELY(m_graph.compilation())) {
4956             addToGraph(CountExecution, OpInfo(m_graph.compilation()-&gt;executionCounterFor(
4957                 Profiler::OriginStack(*m_vm-&gt;m_perBytecodeProfiler, m_codeBlock, currentCodeOrigin()))));
4958         }
4959 
4960         switch (opcodeID) {
4961 
4962         // === Function entry opcodes ===
4963 
4964         case op_enter: {

4965             Node* undefined = addToGraph(JSConstant, OpInfo(m_constantUndefined));
4966             // Initialize all locals to undefined.
4967             for (int i = 0; i &lt; m_inlineStackTop-&gt;m_codeBlock-&gt;numVars(); ++i)
4968                 set(virtualRegisterForLocal(i), undefined, ImmediateNakedSet);
<span class="line-added">4969 </span>
4970             NEXT_OPCODE(op_enter);
4971         }
4972 
4973         case op_to_this: {
4974             Node* op1 = getThis();
4975             auto&amp; metadata = currentInstruction-&gt;as&lt;OpToThis&gt;().metadata(codeBlock);
4976             StructureID cachedStructureID = metadata.m_cachedStructureID;
4977             Structure* cachedStructure = nullptr;
4978             if (cachedStructureID)
4979                 cachedStructure = m_vm-&gt;heap.structureIDTable().get(cachedStructureID);
4980             if (metadata.m_toThisStatus != ToThisOK
4981                 || !cachedStructure
4982                 || cachedStructure-&gt;classInfo()-&gt;methodTable.toThis != JSObject::info()-&gt;methodTable.toThis
4983                 || m_inlineStackTop-&gt;m_profiledBlock-&gt;couldTakeSlowCase(m_currentIndex)
4984                 || m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCache)
4985                 || (op1-&gt;op() == GetLocal &amp;&amp; op1-&gt;variableAccessData()-&gt;structureCheckHoistingFailed())) {
4986                 setThis(addToGraph(ToThis, OpInfo(), OpInfo(getPrediction()), op1));
4987             } else {
4988                 addToGraph(
4989                     CheckStructure,
</pre>
<hr />
<pre>
5008                     FrozenValue* frozen = m_graph.freeze(cachedFunction);
5009                     addToGraph(CheckCell, OpInfo(frozen), callee);
5010 
5011                     function = static_cast&lt;JSFunction*&gt;(cachedFunction);
5012                 }
5013             }
5014 
5015             bool alreadyEmitted = false;
5016             if (function) {
5017                 if (FunctionRareData* rareData = function-&gt;rareData()) {
5018                     if (rareData-&gt;allocationProfileWatchpointSet().isStillValid()) {
5019                         Structure* structure = rareData-&gt;objectAllocationStructure();
5020                         JSObject* prototype = rareData-&gt;objectAllocationPrototype();
5021                         if (structure
5022                             &amp;&amp; (structure-&gt;hasMonoProto() || prototype)
5023                             &amp;&amp; rareData-&gt;allocationProfileWatchpointSet().isStillValid()) {
5024 
5025                             m_graph.freeze(rareData);
5026                             m_graph.watchpoints().addLazily(rareData-&gt;allocationProfileWatchpointSet());
5027 


5028                             Node* object = addToGraph(NewObject, OpInfo(m_graph.registerStructure(structure)));
5029                             if (structure-&gt;hasPolyProto()) {
5030                                 StorageAccessData* data = m_graph.m_storageAccessData.add();
5031                                 data-&gt;offset = knownPolyProtoOffset;
5032                                 data-&gt;identifierNumber = m_graph.identifiers().ensure(m_graph.m_vm.propertyNames-&gt;builtinNames().polyProtoName().impl());
5033                                 ASSERT(isInlineOffset(knownPolyProtoOffset));
5034                                 addToGraph(PutByOffset, OpInfo(data), object, object, weakJSConstant(prototype));
5035                             }
5036                             set(VirtualRegister(bytecode.m_dst), object);
<span class="line-added">5037                             // The callee is still live up to this point.</span>
<span class="line-added">5038                             addToGraph(Phantom, callee);</span>
5039                             alreadyEmitted = true;
5040                         }
5041                     }
5042                 }
5043             }
5044             if (!alreadyEmitted) {
5045                 set(VirtualRegister(bytecode.m_dst),
5046                     addToGraph(CreateThis, OpInfo(bytecode.m_inlineCapacity), callee));
5047             }
5048             NEXT_OPCODE(op_create_this);
5049         }
5050 
<span class="line-added">5051         case op_create_promise: {</span>
<span class="line-added">5052             JSGlobalObject* globalObject = m_graph.globalObjectFor(currentNodeOrigin().semantic);</span>
<span class="line-added">5053             auto bytecode = currentInstruction-&gt;as&lt;OpCreatePromise&gt;();</span>
<span class="line-added">5054             Node* callee = get(VirtualRegister(bytecode.m_callee));</span>
<span class="line-added">5055 </span>
<span class="line-added">5056             bool alreadyEmitted = false;</span>
<span class="line-added">5057 </span>
<span class="line-added">5058             {</span>
<span class="line-added">5059                 // Attempt to convert to NewPromise first in easy case.</span>
<span class="line-added">5060                 JSPromiseConstructor* promiseConstructor = callee-&gt;dynamicCastConstant&lt;JSPromiseConstructor*&gt;(*m_vm);</span>
<span class="line-added">5061                 if (promiseConstructor == (bytecode.m_isInternalPromise ? globalObject-&gt;internalPromiseConstructor() : globalObject-&gt;promiseConstructor())) {</span>
<span class="line-added">5062                     JSCell* cachedFunction = bytecode.metadata(codeBlock).m_cachedCallee.unvalidatedGet();</span>
<span class="line-added">5063                     if (cachedFunction</span>
<span class="line-added">5064                         &amp;&amp; cachedFunction != JSCell::seenMultipleCalleeObjects()</span>
<span class="line-added">5065                         &amp;&amp; !m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell)</span>
<span class="line-added">5066                         &amp;&amp; cachedFunction == (bytecode.m_isInternalPromise ? globalObject-&gt;internalPromiseConstructor() : globalObject-&gt;promiseConstructor())) {</span>
<span class="line-added">5067                         FrozenValue* frozen = m_graph.freeze(cachedFunction);</span>
<span class="line-added">5068                         addToGraph(CheckCell, OpInfo(frozen), callee);</span>
<span class="line-added">5069 </span>
<span class="line-added">5070                         promiseConstructor = jsCast&lt;JSPromiseConstructor*&gt;(cachedFunction);</span>
<span class="line-added">5071                     }</span>
<span class="line-added">5072                 }</span>
<span class="line-added">5073                 if (promiseConstructor) {</span>
<span class="line-added">5074                     addToGraph(Phantom, callee);</span>
<span class="line-added">5075                     set(VirtualRegister(bytecode.m_dst), addToGraph(NewPromise, OpInfo(m_graph.registerStructure(bytecode.m_isInternalPromise ? globalObject-&gt;internalPromiseStructure() : globalObject-&gt;promiseStructure())), OpInfo(bytecode.m_isInternalPromise)));</span>
<span class="line-added">5076                     alreadyEmitted = true;</span>
<span class="line-added">5077                 }</span>
<span class="line-added">5078             }</span>
<span class="line-added">5079 </span>
<span class="line-added">5080             // Derived function case.</span>
<span class="line-added">5081             if (!alreadyEmitted) {</span>
<span class="line-added">5082                 JSFunction* function = callee-&gt;dynamicCastConstant&lt;JSFunction*&gt;(*m_vm);</span>
<span class="line-added">5083                 if (!function) {</span>
<span class="line-added">5084                     JSCell* cachedFunction = bytecode.metadata(codeBlock).m_cachedCallee.unvalidatedGet();</span>
<span class="line-added">5085                     if (cachedFunction</span>
<span class="line-added">5086                         &amp;&amp; cachedFunction != JSCell::seenMultipleCalleeObjects()</span>
<span class="line-added">5087                         &amp;&amp; !m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell)) {</span>
<span class="line-added">5088                         ASSERT(cachedFunction-&gt;inherits&lt;JSFunction&gt;(*m_vm));</span>
<span class="line-added">5089 </span>
<span class="line-added">5090                         FrozenValue* frozen = m_graph.freeze(cachedFunction);</span>
<span class="line-added">5091                         addToGraph(CheckCell, OpInfo(frozen), callee);</span>
<span class="line-added">5092 </span>
<span class="line-added">5093                         function = static_cast&lt;JSFunction*&gt;(cachedFunction);</span>
<span class="line-added">5094                     }</span>
<span class="line-added">5095                 }</span>
<span class="line-added">5096 </span>
<span class="line-added">5097                 if (function) {</span>
<span class="line-added">5098                     if (FunctionRareData* rareData = function-&gt;rareData()) {</span>
<span class="line-added">5099                         if (rareData-&gt;allocationProfileWatchpointSet().isStillValid()) {</span>
<span class="line-added">5100                             Structure* structure = rareData-&gt;internalFunctionAllocationStructure();</span>
<span class="line-added">5101                             if (structure</span>
<span class="line-added">5102                                 &amp;&amp; structure-&gt;classInfo() == (bytecode.m_isInternalPromise ? JSInternalPromise::info() : JSPromise::info())</span>
<span class="line-added">5103                                 &amp;&amp; structure-&gt;globalObject() == globalObject</span>
<span class="line-added">5104                                 &amp;&amp; rareData-&gt;allocationProfileWatchpointSet().isStillValid()) {</span>
<span class="line-added">5105                                 m_graph.freeze(rareData);</span>
<span class="line-added">5106                                 m_graph.watchpoints().addLazily(rareData-&gt;allocationProfileWatchpointSet());</span>
<span class="line-added">5107 </span>
<span class="line-added">5108                                 set(VirtualRegister(bytecode.m_dst), addToGraph(NewPromise, OpInfo(m_graph.registerStructure(structure)), OpInfo(bytecode.m_isInternalPromise)));</span>
<span class="line-added">5109                                 // The callee is still live up to this point.</span>
<span class="line-added">5110                                 addToGraph(Phantom, callee);</span>
<span class="line-added">5111                                 alreadyEmitted = true;</span>
<span class="line-added">5112                             }</span>
<span class="line-added">5113                         }</span>
<span class="line-added">5114                     }</span>
<span class="line-added">5115                 }</span>
<span class="line-added">5116                 if (!alreadyEmitted)</span>
<span class="line-added">5117                     set(VirtualRegister(bytecode.m_dst), addToGraph(CreatePromise, OpInfo(), OpInfo(bytecode.m_isInternalPromise), callee));</span>
<span class="line-added">5118             }</span>
<span class="line-added">5119             NEXT_OPCODE(op_create_promise);</span>
<span class="line-added">5120         }</span>
<span class="line-added">5121 </span>
<span class="line-added">5122         case op_create_generator: {</span>
<span class="line-added">5123             handleCreateInternalFieldObject(JSGenerator::info(), CreateGenerator, NewGenerator, currentInstruction-&gt;as&lt;OpCreateGenerator&gt;());</span>
<span class="line-added">5124             NEXT_OPCODE(op_create_generator);</span>
<span class="line-added">5125         }</span>
<span class="line-added">5126 </span>
<span class="line-added">5127         case op_create_async_generator: {</span>
<span class="line-added">5128             handleCreateInternalFieldObject(JSAsyncGenerator::info(), CreateAsyncGenerator, NewAsyncGenerator, currentInstruction-&gt;as&lt;OpCreateAsyncGenerator&gt;());</span>
<span class="line-added">5129             NEXT_OPCODE(op_create_async_generator);</span>
<span class="line-added">5130         }</span>
<span class="line-added">5131 </span>
5132         case op_new_object: {
5133             auto bytecode = currentInstruction-&gt;as&lt;OpNewObject&gt;();
5134             set(bytecode.m_dst,
5135                 addToGraph(NewObject,
5136                     OpInfo(m_graph.registerStructure(bytecode.metadata(codeBlock).m_objectAllocationProfile.structure()))));
5137             NEXT_OPCODE(op_new_object);
5138         }
5139 
<span class="line-added">5140         case op_new_promise: {</span>
<span class="line-added">5141             auto bytecode = currentInstruction-&gt;as&lt;OpNewPromise&gt;();</span>
<span class="line-added">5142             JSGlobalObject* globalObject = m_graph.globalObjectFor(currentNodeOrigin().semantic);</span>
<span class="line-added">5143             set(bytecode.m_dst, addToGraph(NewPromise, OpInfo(m_graph.registerStructure(bytecode.m_isInternalPromise ? globalObject-&gt;internalPromiseStructure() : globalObject-&gt;promiseStructure())), OpInfo(bytecode.m_isInternalPromise)));</span>
<span class="line-added">5144             NEXT_OPCODE(op_new_promise);</span>
<span class="line-added">5145         }</span>
<span class="line-added">5146 </span>
<span class="line-added">5147         case op_new_generator: {</span>
<span class="line-added">5148             auto bytecode = currentInstruction-&gt;as&lt;OpNewGenerator&gt;();</span>
<span class="line-added">5149             JSGlobalObject* globalObject = m_graph.globalObjectFor(currentNodeOrigin().semantic);</span>
<span class="line-added">5150             set(bytecode.m_dst, addToGraph(NewGenerator, OpInfo(m_graph.registerStructure(globalObject-&gt;generatorStructure()))));</span>
<span class="line-added">5151             NEXT_OPCODE(op_new_generator);</span>
<span class="line-added">5152         }</span>
<span class="line-added">5153 </span>
5154         case op_new_array: {
5155             auto bytecode = currentInstruction-&gt;as&lt;OpNewArray&gt;();
5156             int startOperand = bytecode.m_argv.offset();
5157             int numOperands = bytecode.m_argc;
5158             ArrayAllocationProfile&amp; profile = bytecode.metadata(codeBlock).m_arrayAllocationProfile;
5159             for (int operandIdx = startOperand; operandIdx &gt; startOperand - numOperands; --operandIdx)
5160                 addVarArgChild(get(VirtualRegister(operandIdx)));
5161             unsigned vectorLengthHint = std::max&lt;unsigned&gt;(profile.vectorLengthHintConcurrently(), numOperands);
5162             set(bytecode.m_dst, addToGraph(Node::VarArg, NewArray, OpInfo(profile.selectIndexingTypeConcurrently()), OpInfo(vectorLengthHint)));
5163             NEXT_OPCODE(op_new_array);
5164         }
5165 
5166         case op_new_array_with_spread: {
5167             auto bytecode = currentInstruction-&gt;as&lt;OpNewArrayWithSpread&gt;();
5168             int startOperand = bytecode.m_argv.offset();
5169             int numOperands = bytecode.m_argc;
5170             const BitVector&amp; bitVector = m_inlineStackTop-&gt;m_profiledBlock-&gt;unlinkedCodeBlock()-&gt;bitVector(bytecode.m_bitVector);
5171             for (int operandIdx = startOperand; operandIdx &gt; startOperand - numOperands; --operandIdx)
5172                 addVarArgChild(get(VirtualRegister(operandIdx)));
5173 
</pre>
<hr />
<pre>
5195 
5196         case op_new_array_buffer: {
5197             auto bytecode = currentInstruction-&gt;as&lt;OpNewArrayBuffer&gt;();
5198             // Unfortunately, we can&#39;t allocate a new JSImmutableButterfly if the profile tells us new information because we
5199             // cannot allocate from compilation threads.
5200             WTF::loadLoadFence();
5201             FrozenValue* frozen = get(VirtualRegister(bytecode.m_immutableButterfly))-&gt;constant();
5202             WTF::loadLoadFence();
5203             JSImmutableButterfly* immutableButterfly = frozen-&gt;cast&lt;JSImmutableButterfly*&gt;();
5204             NewArrayBufferData data { };
5205             data.indexingMode = immutableButterfly-&gt;indexingMode();
5206             data.vectorLengthHint = immutableButterfly-&gt;toButterfly()-&gt;vectorLength();
5207 
5208             set(VirtualRegister(bytecode.m_dst), addToGraph(NewArrayBuffer, OpInfo(frozen), OpInfo(data.asQuadWord)));
5209             NEXT_OPCODE(op_new_array_buffer);
5210         }
5211 
5212         case op_new_regexp: {
5213             auto bytecode = currentInstruction-&gt;as&lt;OpNewRegexp&gt;();
5214             ASSERT(bytecode.m_regexp.isConstant());
<span class="line-modified">5215             FrozenValue* frozenRegExp = m_graph.freezeStrong(m_inlineStackTop-&gt;m_codeBlock-&gt;getConstant(bytecode.m_regexp));</span>
5216             set(bytecode.m_dst, addToGraph(NewRegexp, OpInfo(frozenRegExp), jsConstant(jsNumber(0))));
5217             NEXT_OPCODE(op_new_regexp);
5218         }
5219 
5220         case op_get_rest_length: {
5221             auto bytecode = currentInstruction-&gt;as&lt;OpGetRestLength&gt;();
5222             InlineCallFrame* inlineCallFrame = this-&gt;inlineCallFrame();
5223             Node* length;
5224             if (inlineCallFrame &amp;&amp; !inlineCallFrame-&gt;isVarargs()) {
5225                 unsigned argumentsLength = inlineCallFrame-&gt;argumentCountIncludingThis - 1;
5226                 JSValue restLength;
5227                 if (argumentsLength &lt;= bytecode.m_numParametersToSkip)
5228                     restLength = jsNumber(0);
5229                 else
5230                     restLength = jsNumber(argumentsLength - bytecode.m_numParametersToSkip);
5231 
5232                 length = jsConstant(restLength);
5233             } else
5234                 length = addToGraph(GetRestLength, OpInfo(bytecode.m_numParametersToSkip));
5235             set(bytecode.m_dst, length);
</pre>
<hr />
<pre>
5281                 set(bytecode.m_dst, addToGraph(ValueBitOr, OpInfo(), OpInfo(prediction), op1, op2));
5282             NEXT_OPCODE(op_bitor);
5283         }
5284 
5285         case op_bitxor: {
5286             auto bytecode = currentInstruction-&gt;as&lt;OpBitxor&gt;();
5287             SpeculatedType prediction = getPrediction();
5288             Node* op1 = get(bytecode.m_lhs);
5289             Node* op2 = get(bytecode.m_rhs);
5290             if (op1-&gt;hasNumberOrAnyIntResult() &amp;&amp; op2-&gt;hasNumberOrAnyIntResult())
5291                 set(bytecode.m_dst, addToGraph(ArithBitXor, op1, op2));
5292             else
5293                 set(bytecode.m_dst, addToGraph(ValueBitXor, OpInfo(), OpInfo(prediction), op1, op2));
5294             NEXT_OPCODE(op_bitxor);
5295         }
5296 
5297         case op_rshift: {
5298             auto bytecode = currentInstruction-&gt;as&lt;OpRshift&gt;();
5299             Node* op1 = get(bytecode.m_lhs);
5300             Node* op2 = get(bytecode.m_rhs);
<span class="line-modified">5301             if (op1-&gt;hasNumberOrAnyIntResult() &amp;&amp; op2-&gt;hasNumberOrAnyIntResult())</span>
<span class="line-added">5302                 set(bytecode.m_dst, addToGraph(ArithBitRShift, op1, op2));</span>
<span class="line-added">5303             else {</span>
<span class="line-added">5304                 SpeculatedType prediction = getPredictionWithoutOSRExit();</span>
<span class="line-added">5305                 set(bytecode.m_dst, addToGraph(ValueBitRShift, OpInfo(), OpInfo(prediction), op1, op2));</span>
<span class="line-added">5306             }</span>
5307             NEXT_OPCODE(op_rshift);
5308         }
5309 
5310         case op_lshift: {
5311             auto bytecode = currentInstruction-&gt;as&lt;OpLshift&gt;();
5312             Node* op1 = get(bytecode.m_lhs);
5313             Node* op2 = get(bytecode.m_rhs);
5314             if (op1-&gt;hasNumberOrAnyIntResult() &amp;&amp; op2-&gt;hasNumberOrAnyIntResult())
5315                 set(bytecode.m_dst, addToGraph(ArithBitLShift, op1, op2));
5316             else {
5317                 SpeculatedType prediction = getPredictionWithoutOSRExit();
5318                 set(bytecode.m_dst, addToGraph(ValueBitLShift, OpInfo(), OpInfo(prediction), op1, op2));
5319             }
5320             NEXT_OPCODE(op_lshift);
5321         }
5322 
5323         case op_urshift: {
5324             auto bytecode = currentInstruction-&gt;as&lt;OpUrshift&gt;();
5325             Node* op1 = get(bytecode.m_lhs);
5326             Node* op2 = get(bytecode.m_rhs);
5327             set(bytecode.m_dst, addToGraph(BitURShift, op1, op2));
5328             NEXT_OPCODE(op_urshift);
5329         }
5330 
5331         case op_unsigned: {
5332             auto bytecode = currentInstruction-&gt;as&lt;OpUnsigned&gt;();
5333             set(bytecode.m_dst, makeSafe(addToGraph(UInt32ToNumber, get(bytecode.m_operand))));
5334             NEXT_OPCODE(op_unsigned);
5335         }
5336 
5337         // === Increment/Decrement opcodes ===
5338 
5339         case op_inc: {
5340             auto bytecode = currentInstruction-&gt;as&lt;OpInc&gt;();
5341             Node* op = get(bytecode.m_srcDst);
<span class="line-modified">5342             // FIXME: we can replace the Inc by either ArithAdd with m_constantOne or ArithAdd with the equivalent BigInt in many cases.</span>
<span class="line-added">5343             // For now we only do so in DFGFixupPhase.</span>
<span class="line-added">5344             // We could probably do it earlier in some cases, but it is not clearly worth the trouble.</span>
<span class="line-added">5345             set(bytecode.m_srcDst, makeSafe(addToGraph(Inc, op)));</span>
5346             NEXT_OPCODE(op_inc);
5347         }
5348 
5349         case op_dec: {
5350             auto bytecode = currentInstruction-&gt;as&lt;OpDec&gt;();
5351             Node* op = get(bytecode.m_srcDst);
<span class="line-modified">5352             // FIXME: we can replace the Inc by either ArithSub with m_constantOne or ArithSub with the equivalent BigInt in many cases.</span>
<span class="line-added">5353             // For now we only do so in DFGFixupPhase.</span>
<span class="line-added">5354             // We could probably do it earlier in some cases, but it is not clearly worth the trouble.</span>
<span class="line-added">5355             set(bytecode.m_srcDst, makeSafe(addToGraph(Dec, op)));</span>
5356             NEXT_OPCODE(op_dec);
5357         }
5358 
5359         // === Arithmetic operations ===
5360 
5361         case op_add: {
5362             auto bytecode = currentInstruction-&gt;as&lt;OpAdd&gt;();
5363             Node* op1 = get(bytecode.m_lhs);
5364             Node* op2 = get(bytecode.m_rhs);
5365             if (op1-&gt;hasNumberResult() &amp;&amp; op2-&gt;hasNumberResult())
5366                 set(bytecode.m_dst, makeSafe(addToGraph(ArithAdd, op1, op2)));
5367             else
5368                 set(bytecode.m_dst, makeSafe(addToGraph(ValueAdd, op1, op2)));
5369             NEXT_OPCODE(op_add);
5370         }
5371 
5372         case op_sub: {
5373             auto bytecode = currentInstruction-&gt;as&lt;OpSub&gt;();
5374             Node* op1 = get(bytecode.m_lhs);
5375             Node* op2 = get(bytecode.m_rhs);
</pre>
<hr />
<pre>
5587             auto bytecode = currentInstruction-&gt;as&lt;OpIsFunction&gt;();
5588             Node* value = get(bytecode.m_operand);
5589             set(bytecode.m_dst, addToGraph(IsFunction, value));
5590             NEXT_OPCODE(op_is_function);
5591         }
5592 
5593         case op_not: {
5594             auto bytecode = currentInstruction-&gt;as&lt;OpNot&gt;();
5595             Node* value = get(bytecode.m_operand);
5596             set(bytecode.m_dst, addToGraph(LogicalNot, value));
5597             NEXT_OPCODE(op_not);
5598         }
5599 
5600         case op_to_primitive: {
5601             auto bytecode = currentInstruction-&gt;as&lt;OpToPrimitive&gt;();
5602             Node* value = get(bytecode.m_src);
5603             set(bytecode.m_dst, addToGraph(ToPrimitive, value));
5604             NEXT_OPCODE(op_to_primitive);
5605         }
5606 
<span class="line-added">5607         case op_to_property_key: {</span>
<span class="line-added">5608             auto bytecode = currentInstruction-&gt;as&lt;OpToPropertyKey&gt;();</span>
<span class="line-added">5609             Node* value = get(bytecode.m_src);</span>
<span class="line-added">5610             set(bytecode.m_dst, addToGraph(ToPropertyKey, value));</span>
<span class="line-added">5611             NEXT_OPCODE(op_to_property_key);</span>
<span class="line-added">5612         }</span>
<span class="line-added">5613 </span>
5614         case op_strcat: {
5615             auto bytecode = currentInstruction-&gt;as&lt;OpStrcat&gt;();
5616             int startOperand = bytecode.m_src.offset();
5617             int numOperands = bytecode.m_count;






5618             const unsigned maxArguments = 3;

5619             Node* operands[AdjacencyList::Size];
5620             unsigned indexInOperands = 0;
5621             for (unsigned i = 0; i &lt; AdjacencyList::Size; ++i)
5622                 operands[i] = 0;
5623             for (int operandIdx = 0; operandIdx &lt; numOperands; ++operandIdx) {
5624                 if (indexInOperands == maxArguments) {
5625                     operands[0] = addToGraph(StrCat, operands[0], operands[1], operands[2]);
5626                     for (unsigned i = 1; i &lt; AdjacencyList::Size; ++i)
5627                         operands[i] = 0;
5628                     indexInOperands = 1;
5629                 }
5630 
5631                 ASSERT(indexInOperands &lt; AdjacencyList::Size);
5632                 ASSERT(indexInOperands &lt; maxArguments);
5633                 operands[indexInOperands++] = get(VirtualRegister(startOperand - operandIdx));
5634             }
5635             set(bytecode.m_dst, addToGraph(StrCat, operands[0], operands[1], operands[2]));
5636             NEXT_OPCODE(op_strcat);
5637         }
5638 
</pre>
<hr />
<pre>
5725         }
5726 
5727         case op_nstricteq: {
5728             auto bytecode = currentInstruction-&gt;as&lt;OpNstricteq&gt;();
5729             Node* op1 = get(bytecode.m_lhs);
5730             Node* op2 = get(bytecode.m_rhs);
5731             Node* invertedResult;
5732             invertedResult = addToGraph(CompareStrictEq, op1, op2);
5733             set(bytecode.m_dst, addToGraph(LogicalNot, invertedResult));
5734             NEXT_OPCODE(op_nstricteq);
5735         }
5736 
5737         // === Property access operations ===
5738 
5739         case op_get_by_val: {
5740             auto bytecode = currentInstruction-&gt;as&lt;OpGetByVal&gt;();
5741             SpeculatedType prediction = getPredictionWithoutOSRExit();
5742 
5743             Node* base = get(bytecode.m_base);
5744             Node* property = get(bytecode.m_property);
<span class="line-modified">5745             bool shouldCompileAsGetById = false;</span>
<span class="line-modified">5746             GetByStatus getByStatus = GetByStatus::computeFor(m_inlineStackTop-&gt;m_profiledBlock, m_inlineStackTop-&gt;m_baselineMap, m_icContextStack, currentCodeOrigin());</span>
<span class="line-added">5747 </span>
5748             unsigned identifierNumber = 0;






















5749 
<span class="line-modified">5750             if (!m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadIdent)</span>
<span class="line-modified">5751                 &amp;&amp; !m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType)</span>
<span class="line-modified">5752                 &amp;&amp; !m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell)) {</span>
<span class="line-added">5753 </span>
<span class="line-added">5754                 // FIXME: In the future, we should be able to do something like MultiGetByOffset in a multi identifier mode.</span>
<span class="line-added">5755                 // That way, we could both switch on multiple structures and multiple identifiers (or int 32 properties).</span>
<span class="line-added">5756                 // https://bugs.webkit.org/show_bug.cgi?id=204216</span>
<span class="line-added">5757                 if (CacheableIdentifier identifier = getByStatus.singleIdentifier()) {</span>
<span class="line-added">5758                     UniquedStringImpl* uid = identifier.uid();</span>
<span class="line-added">5759                     identifierNumber = m_graph.identifiers().ensure(identifier.uid());</span>
<span class="line-added">5760                     if (identifier.isCell()) {</span>
<span class="line-added">5761                         FrozenValue* frozen = m_graph.freezeStrong(identifier.cell());</span>
<span class="line-added">5762                         if (identifier.isSymbolCell())</span>
<span class="line-added">5763                             addToGraph(CheckCell, OpInfo(frozen), property);</span>
<span class="line-added">5764                         else</span>
<span class="line-added">5765                             addToGraph(CheckIdent, OpInfo(uid), property);</span>
<span class="line-added">5766                     } else</span>
<span class="line-added">5767                         addToGraph(CheckIdent, OpInfo(uid), property);</span>
<span class="line-added">5768                     shouldCompileAsGetById = true;</span>
5769                 }
5770             }
5771 
<span class="line-modified">5772             if (shouldCompileAsGetById)</span>
<span class="line-modified">5773                 handleGetById(bytecode.m_dst, prediction, base, identifierNumber, getByStatus, AccessType::GetById, currentInstruction-&gt;size());</span>
5774             else {
5775                 ArrayMode arrayMode = getArrayMode(bytecode.metadata(codeBlock).m_arrayProfile, Array::Read);
5776                 // FIXME: We could consider making this not vararg, since it only uses three child
5777                 // slots.
5778                 // https://bugs.webkit.org/show_bug.cgi?id=184192
5779                 addVarArgChild(base);
5780                 addVarArgChild(property);
5781                 addVarArgChild(0); // Leave room for property storage.
5782                 Node* getByVal = addToGraph(Node::VarArg, GetByVal, OpInfo(arrayMode.asWord()), OpInfo(prediction));
5783                 m_exitOK = false; // GetByVal must be treated as if it clobbers exit state, since FixupPhase may make it generic.
5784                 set(bytecode.m_dst, getByVal);
<span class="line-added">5785                 if (getByStatus.observedStructureStubInfoSlowPath() || bytecode.metadata(codeBlock).m_seenIdentifiers.count() &gt; Options::getByValICMaxNumberOfIdentifiers())</span>
<span class="line-added">5786                     m_graph.m_slowGetByVal.add(getByVal);</span>
5787             }
5788 
5789             NEXT_OPCODE(op_get_by_val);
5790         }
5791 
5792         case op_get_by_val_with_this: {
5793             auto bytecode = currentInstruction-&gt;as&lt;OpGetByValWithThis&gt;();
5794             SpeculatedType prediction = getPrediction();
5795 
5796             Node* base = get(bytecode.m_base);
5797             Node* thisValue = get(bytecode.m_thisValue);
5798             Node* property = get(bytecode.m_property);
5799             Node* getByValWithThis = addToGraph(GetByValWithThis, OpInfo(), OpInfo(prediction), base, thisValue, property);
5800             set(bytecode.m_dst, getByValWithThis);
5801 
5802             NEXT_OPCODE(op_get_by_val_with_this);
5803         }
5804 
5805         case op_put_by_val_direct:
5806             handlePutByVal(currentInstruction-&gt;as&lt;OpPutByValDirect&gt;(), currentInstruction-&gt;size());
</pre>
<hr />
<pre>
5959             auto bytecode = currentInstruction-&gt;as&lt;OpProfileType&gt;();
5960             auto&amp; metadata = bytecode.metadata(codeBlock);
5961             Node* valueToProfile = get(bytecode.m_targetVirtualRegister);
5962             addToGraph(ProfileType, OpInfo(metadata.m_typeLocation), valueToProfile);
5963             NEXT_OPCODE(op_profile_type);
5964         }
5965 
5966         case op_profile_control_flow: {
5967             auto bytecode = currentInstruction-&gt;as&lt;OpProfileControlFlow&gt;();
5968             BasicBlockLocation* basicBlockLocation = bytecode.metadata(codeBlock).m_basicBlockLocation;
5969             addToGraph(ProfileControlFlow, OpInfo(basicBlockLocation));
5970             NEXT_OPCODE(op_profile_control_flow);
5971         }
5972 
5973         // === Block terminators. ===
5974 
5975         case op_jmp: {
5976             ASSERT(!m_currentBlock-&gt;terminal());
5977             auto bytecode = currentInstruction-&gt;as&lt;OpJmp&gt;();
5978             int relativeOffset = jumpTarget(bytecode.m_targetLabel);
<span class="line-modified">5979             addToGraph(Jump, OpInfo(m_currentIndex.offset() + relativeOffset));</span>
5980             if (relativeOffset &lt;= 0)
5981                 flushForTerminal();
5982             LAST_OPCODE(op_jmp);
5983         }
5984 
5985         case op_jtrue: {
5986             auto bytecode = currentInstruction-&gt;as&lt;OpJtrue&gt;();
5987             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5988             Node* condition = get(bytecode.m_condition);
<span class="line-modified">5989             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + relativeOffset, m_currentIndex.offset() + currentInstruction-&gt;size())), condition);</span>
5990             LAST_OPCODE(op_jtrue);
5991         }
5992 
5993         case op_jfalse: {
5994             auto bytecode = currentInstruction-&gt;as&lt;OpJfalse&gt;();
5995             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
5996             Node* condition = get(bytecode.m_condition);
<span class="line-modified">5997             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + currentInstruction-&gt;size(), m_currentIndex.offset() + relativeOffset)), condition);</span>
5998             LAST_OPCODE(op_jfalse);
5999         }
6000 
6001         case op_jeq_null: {
6002             auto bytecode = currentInstruction-&gt;as&lt;OpJeqNull&gt;();
6003             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6004             Node* value = get(bytecode.m_value);
6005             Node* nullConstant = addToGraph(JSConstant, OpInfo(m_constantNull));
6006             Node* condition = addToGraph(CompareEq, value, nullConstant);
<span class="line-modified">6007             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + relativeOffset, m_currentIndex.offset() + currentInstruction-&gt;size())), condition);</span>
6008             LAST_OPCODE(op_jeq_null);
6009         }
6010 
6011         case op_jneq_null: {
6012             auto bytecode = currentInstruction-&gt;as&lt;OpJneqNull&gt;();
6013             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6014             Node* value = get(bytecode.m_value);
6015             Node* nullConstant = addToGraph(JSConstant, OpInfo(m_constantNull));
6016             Node* condition = addToGraph(CompareEq, value, nullConstant);
<span class="line-modified">6017             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + currentInstruction-&gt;size(), m_currentIndex.offset() + relativeOffset)), condition);</span>
6018             LAST_OPCODE(op_jneq_null);
6019         }
6020 
6021         case op_jundefined_or_null: {
6022             auto bytecode = currentInstruction-&gt;as&lt;OpJundefinedOrNull&gt;();
6023             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6024             Node* value = get(bytecode.m_value);
6025             Node* condition = addToGraph(IsUndefinedOrNull, value);
<span class="line-modified">6026             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + relativeOffset, m_currentIndex.offset() + currentInstruction-&gt;size())), condition);</span>
6027             LAST_OPCODE(op_jundefined_or_null);
6028         }
6029 
6030         case op_jnundefined_or_null: {
6031             auto bytecode = currentInstruction-&gt;as&lt;OpJnundefinedOrNull&gt;();
6032             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6033             Node* value = get(bytecode.m_value);
6034             Node* condition = addToGraph(IsUndefinedOrNull, value);
<span class="line-modified">6035             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + currentInstruction-&gt;size(), m_currentIndex.offset() + relativeOffset)), condition);</span>
6036             LAST_OPCODE(op_jnundefined_or_null);
6037         }
6038 
6039         case op_jless: {
6040             auto bytecode = currentInstruction-&gt;as&lt;OpJless&gt;();
6041             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6042             Node* op1 = get(bytecode.m_lhs);
6043             Node* op2 = get(bytecode.m_rhs);
6044             Node* condition = addToGraph(CompareLess, op1, op2);
<span class="line-modified">6045             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + relativeOffset, m_currentIndex.offset() + currentInstruction-&gt;size())), condition);</span>
6046             LAST_OPCODE(op_jless);
6047         }
6048 
6049         case op_jlesseq: {
6050             auto bytecode = currentInstruction-&gt;as&lt;OpJlesseq&gt;();
6051             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6052             Node* op1 = get(bytecode.m_lhs);
6053             Node* op2 = get(bytecode.m_rhs);
6054             Node* condition = addToGraph(CompareLessEq, op1, op2);
<span class="line-modified">6055             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + relativeOffset, m_currentIndex.offset() + currentInstruction-&gt;size())), condition);</span>
6056             LAST_OPCODE(op_jlesseq);
6057         }
6058 
6059         case op_jgreater: {
6060             auto bytecode = currentInstruction-&gt;as&lt;OpJgreater&gt;();
6061             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6062             Node* op1 = get(bytecode.m_lhs);
6063             Node* op2 = get(bytecode.m_rhs);
6064             Node* condition = addToGraph(CompareGreater, op1, op2);
<span class="line-modified">6065             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + relativeOffset, m_currentIndex.offset() + currentInstruction-&gt;size())), condition);</span>
6066             LAST_OPCODE(op_jgreater);
6067         }
6068 
6069         case op_jgreatereq: {
6070             auto bytecode = currentInstruction-&gt;as&lt;OpJgreatereq&gt;();
6071             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6072             Node* op1 = get(bytecode.m_lhs);
6073             Node* op2 = get(bytecode.m_rhs);
6074             Node* condition = addToGraph(CompareGreaterEq, op1, op2);
<span class="line-modified">6075             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + relativeOffset, m_currentIndex.offset() + currentInstruction-&gt;size())), condition);</span>
6076             LAST_OPCODE(op_jgreatereq);
6077         }
6078 
6079         case op_jeq: {
6080             auto bytecode = currentInstruction-&gt;as&lt;OpJeq&gt;();
6081             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6082             Node* op1 = get(bytecode.m_lhs);
6083             Node* op2 = get(bytecode.m_rhs);
6084             Node* condition = addToGraph(CompareEq, op1, op2);
<span class="line-modified">6085             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + relativeOffset, m_currentIndex.offset() + currentInstruction-&gt;size())), condition);</span>
6086             LAST_OPCODE(op_jeq);
6087         }
6088 
6089         case op_jstricteq: {
6090             auto bytecode = currentInstruction-&gt;as&lt;OpJstricteq&gt;();
6091             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6092             Node* op1 = get(bytecode.m_lhs);
6093             Node* op2 = get(bytecode.m_rhs);
6094             Node* condition = addToGraph(CompareStrictEq, op1, op2);
<span class="line-modified">6095             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + relativeOffset, m_currentIndex.offset() + currentInstruction-&gt;size())), condition);</span>
6096             LAST_OPCODE(op_jstricteq);
6097         }
6098 
6099         case op_jnless: {
6100             auto bytecode = currentInstruction-&gt;as&lt;OpJnless&gt;();
6101             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6102             Node* op1 = get(bytecode.m_lhs);
6103             Node* op2 = get(bytecode.m_rhs);
6104             Node* condition = addToGraph(CompareLess, op1, op2);
<span class="line-modified">6105             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + currentInstruction-&gt;size(), m_currentIndex.offset() + relativeOffset)), condition);</span>
6106             LAST_OPCODE(op_jnless);
6107         }
6108 
6109         case op_jnlesseq: {
6110             auto bytecode = currentInstruction-&gt;as&lt;OpJnlesseq&gt;();
6111             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6112             Node* op1 = get(bytecode.m_lhs);
6113             Node* op2 = get(bytecode.m_rhs);
6114             Node* condition = addToGraph(CompareLessEq, op1, op2);
<span class="line-modified">6115             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + currentInstruction-&gt;size(), m_currentIndex.offset() + relativeOffset)), condition);</span>
6116             LAST_OPCODE(op_jnlesseq);
6117         }
6118 
6119         case op_jngreater: {
6120             auto bytecode = currentInstruction-&gt;as&lt;OpJngreater&gt;();
6121             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6122             Node* op1 = get(bytecode.m_lhs);
6123             Node* op2 = get(bytecode.m_rhs);
6124             Node* condition = addToGraph(CompareGreater, op1, op2);
<span class="line-modified">6125             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + currentInstruction-&gt;size(), m_currentIndex.offset() + relativeOffset)), condition);</span>
6126             LAST_OPCODE(op_jngreater);
6127         }
6128 
6129         case op_jngreatereq: {
6130             auto bytecode = currentInstruction-&gt;as&lt;OpJngreatereq&gt;();
6131             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6132             Node* op1 = get(bytecode.m_lhs);
6133             Node* op2 = get(bytecode.m_rhs);
6134             Node* condition = addToGraph(CompareGreaterEq, op1, op2);
<span class="line-modified">6135             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + currentInstruction-&gt;size(), m_currentIndex.offset() + relativeOffset)), condition);</span>
6136             LAST_OPCODE(op_jngreatereq);
6137         }
6138 
6139         case op_jneq: {
6140             auto bytecode = currentInstruction-&gt;as&lt;OpJneq&gt;();
6141             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6142             Node* op1 = get(bytecode.m_lhs);
6143             Node* op2 = get(bytecode.m_rhs);
6144             Node* condition = addToGraph(CompareEq, op1, op2);
<span class="line-modified">6145             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + currentInstruction-&gt;size(), m_currentIndex.offset() + relativeOffset)), condition);</span>
6146             LAST_OPCODE(op_jneq);
6147         }
6148 
6149         case op_jnstricteq: {
6150             auto bytecode = currentInstruction-&gt;as&lt;OpJnstricteq&gt;();
6151             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6152             Node* op1 = get(bytecode.m_lhs);
6153             Node* op2 = get(bytecode.m_rhs);
6154             Node* condition = addToGraph(CompareStrictEq, op1, op2);
<span class="line-modified">6155             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + currentInstruction-&gt;size(), m_currentIndex.offset() + relativeOffset)), condition);</span>
6156             LAST_OPCODE(op_jnstricteq);
6157         }
6158 
6159         case op_jbelow: {
6160             auto bytecode = currentInstruction-&gt;as&lt;OpJbelow&gt;();
6161             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6162             Node* op1 = get(bytecode.m_lhs);
6163             Node* op2 = get(bytecode.m_rhs);
6164             Node* condition = addToGraph(CompareBelow, op1, op2);
<span class="line-modified">6165             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + relativeOffset, m_currentIndex.offset() + currentInstruction-&gt;size())), condition);</span>
6166             LAST_OPCODE(op_jbelow);
6167         }
6168 
6169         case op_jbeloweq: {
6170             auto bytecode = currentInstruction-&gt;as&lt;OpJbeloweq&gt;();
6171             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6172             Node* op1 = get(bytecode.m_lhs);
6173             Node* op2 = get(bytecode.m_rhs);
6174             Node* condition = addToGraph(CompareBelowEq, op1, op2);
<span class="line-modified">6175             addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + relativeOffset, m_currentIndex.offset() + currentInstruction-&gt;size())), condition);</span>
6176             LAST_OPCODE(op_jbeloweq);
6177         }
6178 
6179         case op_switch_imm: {
6180             auto bytecode = currentInstruction-&gt;as&lt;OpSwitchImm&gt;();
6181             SwitchData&amp; data = *m_graph.m_switchData.add();
6182             data.kind = SwitchImm;
6183             data.switchTableIndex = m_inlineStackTop-&gt;m_switchRemap[bytecode.m_tableIndex];
<span class="line-modified">6184             data.fallThrough.setBytecodeIndex(m_currentIndex.offset() + jumpTarget(bytecode.m_defaultOffset));</span>
6185             SimpleJumpTable&amp; table = m_codeBlock-&gt;switchJumpTable(data.switchTableIndex);
6186             for (unsigned i = 0; i &lt; table.branchOffsets.size(); ++i) {
6187                 if (!table.branchOffsets[i])
6188                     continue;
<span class="line-modified">6189                 unsigned target = m_currentIndex.offset() + table.branchOffsets[i];</span>
6190                 if (target == data.fallThrough.bytecodeIndex())
6191                     continue;
6192                 data.cases.append(SwitchCase::withBytecodeIndex(m_graph.freeze(jsNumber(static_cast&lt;int32_t&gt;(table.min + i))), target));
6193             }
6194             addToGraph(Switch, OpInfo(&amp;data), get(bytecode.m_scrutinee));
6195             flushIfTerminal(data);
6196             LAST_OPCODE(op_switch_imm);
6197         }
6198 
6199         case op_switch_char: {
6200             auto bytecode = currentInstruction-&gt;as&lt;OpSwitchChar&gt;();
6201             SwitchData&amp; data = *m_graph.m_switchData.add();
6202             data.kind = SwitchChar;
6203             data.switchTableIndex = m_inlineStackTop-&gt;m_switchRemap[bytecode.m_tableIndex];
<span class="line-modified">6204             data.fallThrough.setBytecodeIndex(m_currentIndex.offset() + jumpTarget(bytecode.m_defaultOffset));</span>
6205             SimpleJumpTable&amp; table = m_codeBlock-&gt;switchJumpTable(data.switchTableIndex);
6206             for (unsigned i = 0; i &lt; table.branchOffsets.size(); ++i) {
6207                 if (!table.branchOffsets[i])
6208                     continue;
<span class="line-modified">6209                 unsigned target = m_currentIndex.offset() + table.branchOffsets[i];</span>
6210                 if (target == data.fallThrough.bytecodeIndex())
6211                     continue;
6212                 data.cases.append(
6213                     SwitchCase::withBytecodeIndex(LazyJSValue::singleCharacterString(table.min + i), target));
6214             }
6215             addToGraph(Switch, OpInfo(&amp;data), get(bytecode.m_scrutinee));
6216             flushIfTerminal(data);
6217             LAST_OPCODE(op_switch_char);
6218         }
6219 
6220         case op_switch_string: {
6221             auto bytecode = currentInstruction-&gt;as&lt;OpSwitchString&gt;();
6222             SwitchData&amp; data = *m_graph.m_switchData.add();
6223             data.kind = SwitchString;
6224             data.switchTableIndex = bytecode.m_tableIndex;
<span class="line-modified">6225             data.fallThrough.setBytecodeIndex(m_currentIndex.offset() + jumpTarget(bytecode.m_defaultOffset));</span>
6226             StringJumpTable&amp; table = m_codeBlock-&gt;stringSwitchJumpTable(data.switchTableIndex);
6227             StringJumpTable::StringOffsetTable::iterator iter;
6228             StringJumpTable::StringOffsetTable::iterator end = table.offsetTable.end();
6229             for (iter = table.offsetTable.begin(); iter != end; ++iter) {
<span class="line-modified">6230                 unsigned target = m_currentIndex.offset() + iter-&gt;value.branchOffset;</span>
6231                 if (target == data.fallThrough.bytecodeIndex())
6232                     continue;
6233                 data.cases.append(
6234                     SwitchCase::withBytecodeIndex(LazyJSValue::knownStringImpl(iter-&gt;key.get()), target));
6235             }
6236             addToGraph(Switch, OpInfo(&amp;data), get(bytecode.m_scrutinee));
6237             flushIfTerminal(data);
6238             LAST_OPCODE(op_switch_string);
6239         }
6240 
6241         case op_ret: {
6242             auto bytecode = currentInstruction-&gt;as&lt;OpRet&gt;();
6243             ASSERT(!m_currentBlock-&gt;terminal());
6244             if (!inlineCallFrame()) {
6245                 // Simple case: we are just producing a return
6246                 addToGraph(Return, get(bytecode.m_value));
6247                 flushForReturn();
6248                 LAST_OPCODE(op_ret);
6249             }
6250 
6251             flushForReturn();
6252             if (m_inlineStackTop-&gt;m_returnValue.isValid())
6253                 setDirect(m_inlineStackTop-&gt;m_returnValue, get(bytecode.m_value), ImmediateSetWithFlush);
6254 
<span class="line-modified">6255             if (!m_inlineStackTop-&gt;m_continuationBlock &amp;&amp; m_currentIndex.offset() + currentInstruction-&gt;size() != m_inlineStackTop-&gt;m_codeBlock-&gt;instructions().size()) {</span>
6256                 // This is an early return from an inlined function and we do not have a continuation block, so we must allocate one.
6257                 // It is untargetable, because we do not know the appropriate index.
6258                 // If this block turns out to be a jump target, parseCodeBlock will fix its bytecodeIndex before putting it in m_blockLinkingTargets
6259                 m_inlineStackTop-&gt;m_continuationBlock = allocateUntargetableBlock();
6260             }
6261 
6262             if (m_inlineStackTop-&gt;m_continuationBlock)
6263                 addJumpTo(m_inlineStackTop-&gt;m_continuationBlock);
6264             else {
6265                 // We are returning from an inlined function, and do not need to jump anywhere, so we just keep the current block
6266                 m_inlineStackTop-&gt;m_continuationBlock = m_currentBlock;
6267             }
6268             LAST_OPCODE_LINKED(op_ret);
6269         }
6270         case op_end:
6271             ASSERT(!inlineCallFrame());
6272             addToGraph(Return, get(currentInstruction-&gt;as&lt;OpEnd&gt;().m_value));
6273             flushForReturn();
6274             LAST_OPCODE(op_end);
6275 
</pre>
<hr />
<pre>
6283             addToGraph(ThrowStaticError, OpInfo(bytecode.m_errorType), get(bytecode.m_message));
6284             flushForTerminal();
6285             LAST_OPCODE(op_throw_static_error);
6286         }
6287 
6288         case op_catch: {
6289             auto bytecode = currentInstruction-&gt;as&lt;OpCatch&gt;();
6290             m_graph.m_hasExceptionHandlers = true;
6291 
6292             if (inlineCallFrame()) {
6293                 // We can&#39;t do OSR entry into an inlined frame.
6294                 NEXT_OPCODE(op_catch);
6295             }
6296 
6297             if (m_graph.m_plan.mode() == FTLForOSREntryMode) {
6298                 NEXT_OPCODE(op_catch);
6299             }
6300 
6301             RELEASE_ASSERT(!m_currentBlock-&gt;size() || (m_graph.compilation() &amp;&amp; m_currentBlock-&gt;size() == 1 &amp;&amp; m_currentBlock-&gt;at(0)-&gt;op() == CountExecution));
6302 
<span class="line-modified">6303             ValueProfileAndVirtualRegisterBuffer* buffer = bytecode.metadata(codeBlock).m_buffer;</span>
6304 
6305             if (!buffer) {
6306                 NEXT_OPCODE(op_catch); // This catch has yet to execute. Note: this load can be racy with the main thread.
6307             }
6308 
6309             // We&#39;re now committed to compiling this as an entrypoint.
6310             m_currentBlock-&gt;isCatchEntrypoint = true;
6311             m_graph.m_roots.append(m_currentBlock);
6312 
6313             Vector&lt;SpeculatedType&gt; argumentPredictions(m_numArguments);
6314             Vector&lt;SpeculatedType&gt; localPredictions;
6315             HashSet&lt;unsigned, WTF::IntHash&lt;unsigned&gt;, WTF::UnsignedWithZeroKeyHashTraits&lt;unsigned&gt;&gt; seenArguments;
6316 
6317             {
6318                 ConcurrentJSLocker locker(m_inlineStackTop-&gt;m_profiledBlock-&gt;m_lock);
6319 
<span class="line-modified">6320                 buffer-&gt;forEach([&amp;] (ValueProfileAndVirtualRegister&amp; profile) {</span>
6321                     VirtualRegister operand(profile.m_operand);
6322                     SpeculatedType prediction = profile.computeUpdatedPrediction(locker);
6323                     if (operand.isLocal())
6324                         localPredictions.append(prediction);
6325                     else {
6326                         RELEASE_ASSERT(operand.isArgument());
6327                         RELEASE_ASSERT(static_cast&lt;uint32_t&gt;(operand.toArgument()) &lt; argumentPredictions.size());
6328                         if (validationEnabled())
6329                             seenArguments.add(operand.toArgument());
6330                         argumentPredictions[operand.toArgument()] = prediction;
6331                     }
6332                 });
6333 
6334                 if (validationEnabled()) {
6335                     for (unsigned argument = 0; argument &lt; m_numArguments; ++argument)
6336                         RELEASE_ASSERT(seenArguments.contains(argument));
6337                 }
6338             }
6339 
6340             Vector&lt;std::pair&lt;VirtualRegister, Node*&gt;&gt; localsToSet;
6341             localsToSet.reserveInitialCapacity(buffer-&gt;m_size); // Note: This will reserve more than the number of locals we see below because the buffer includes arguments.
6342 
6343             // We&#39;re not allowed to exit here since we would not properly recover values.
6344             // We first need to bootstrap the catch entrypoint state.
6345             m_exitOK = false;
6346 
6347             unsigned numberOfLocals = 0;
<span class="line-modified">6348             buffer-&gt;forEach([&amp;] (ValueProfileAndVirtualRegister&amp; profile) {</span>
6349                 VirtualRegister operand(profile.m_operand);
6350                 if (operand.isArgument())
6351                     return;
6352                 ASSERT(operand.isLocal());
6353                 Node* value = addToGraph(ExtractCatchLocal, OpInfo(numberOfLocals), OpInfo(localPredictions[numberOfLocals]));
6354                 ++numberOfLocals;
<span class="line-modified">6355                 addToGraph(MovHint, OpInfo(operand), value);</span>
6356                 localsToSet.uncheckedAppend(std::make_pair(operand, value));
6357             });
6358             if (numberOfLocals)
6359                 addToGraph(ClearCatchLocals);
6360 
6361             if (!m_graph.m_maxLocalsForCatchOSREntry)
6362                 m_graph.m_maxLocalsForCatchOSREntry = 0;
6363             m_graph.m_maxLocalsForCatchOSREntry = std::max(numberOfLocals, *m_graph.m_maxLocalsForCatchOSREntry);
6364 
6365             // We could not exit before this point in the program because we would not know how to do value
6366             // recovery for live locals. The above IR sets up the necessary state so we can recover values
6367             // during OSR exit.
6368             //
6369             // The nodes that follow here all exit to the following bytecode instruction, not
6370             // the op_catch. Exiting to op_catch is reserved for when an exception is thrown.
6371             // The SetArgumentDefinitely nodes that follow below may exit because we may hoist type checks
6372             // to them. The SetLocal nodes that follow below may exit because we may choose
6373             // a flush format that speculates on the type of the local.
6374             m_exitOK = true;
6375             addToGraph(ExitOK);
6376 
6377             {
6378                 auto addResult = m_graph.m_rootToArguments.add(m_currentBlock, ArgumentsVector());
6379                 RELEASE_ASSERT(addResult.isNewEntry);
6380                 ArgumentsVector&amp; entrypointArguments = addResult.iterator-&gt;value;
6381                 entrypointArguments.resize(m_numArguments);
6382 
<span class="line-modified">6383                 BytecodeIndex exitBytecodeIndex = BytecodeIndex(m_currentIndex.offset() + currentInstruction-&gt;size());</span>
6384 
6385                 for (unsigned argument = 0; argument &lt; argumentPredictions.size(); ++argument) {
<span class="line-modified">6386                     VariableAccessData* variable = newVariableAccessData(virtualRegisterForArgumentIncludingThis(argument));</span>
6387                     variable-&gt;predict(argumentPredictions[argument]);
6388 
6389                     variable-&gt;mergeStructureCheckHoistingFailed(
6390                         m_inlineStackTop-&gt;m_exitProfile.hasExitSite(exitBytecodeIndex, BadCache));
6391                     variable-&gt;mergeCheckArrayHoistingFailed(
6392                         m_inlineStackTop-&gt;m_exitProfile.hasExitSite(exitBytecodeIndex, BadIndexingType));
6393 
6394                     Node* setArgument = addToGraph(SetArgumentDefinitely, OpInfo(variable));
6395                     setArgument-&gt;origin.forExit = CodeOrigin(exitBytecodeIndex, setArgument-&gt;origin.forExit.inlineCallFrame());
6396                     m_currentBlock-&gt;variablesAtTail.setArgumentFirstTime(argument, setArgument);
6397                     entrypointArguments[argument] = setArgument;
6398                 }
6399             }
6400 
6401             for (const std::pair&lt;VirtualRegister, Node*&gt;&amp; pair : localsToSet) {
6402                 DelayedSetLocal delayed { currentCodeOrigin(), pair.first, pair.second, ImmediateNakedSet };
6403                 m_setLocalQueue.append(delayed);
6404             }
6405 
6406             NEXT_OPCODE(op_catch);
</pre>
<hr />
<pre>
6463                 NEXT_OPCODE(op_tail_call_forward_arguments);
6464             else
6465                 LAST_OPCODE(op_tail_call_forward_arguments);
6466         }
6467 
6468         case op_construct_varargs: {
6469             handleVarargsCall&lt;OpConstructVarargs&gt;(currentInstruction, ConstructVarargs, CallMode::Construct);
6470             ASSERT_WITH_MESSAGE(m_currentInstruction == currentInstruction, &quot;handleVarargsCall, which may have inlined the callee, trashed m_currentInstruction&quot;);
6471             NEXT_OPCODE(op_construct_varargs);
6472         }
6473 
6474         case op_call_eval: {
6475             auto bytecode = currentInstruction-&gt;as&lt;OpCallEval&gt;();
6476             int registerOffset = -bytecode.m_argv;
6477             addCall(bytecode.m_dst, CallEval, nullptr, get(bytecode.m_callee), bytecode.m_argc, registerOffset, getPrediction());
6478             NEXT_OPCODE(op_call_eval);
6479         }
6480 
6481         case op_jneq_ptr: {
6482             auto bytecode = currentInstruction-&gt;as&lt;OpJneqPtr&gt;();
<span class="line-modified">6483             FrozenValue* frozenPointer = m_graph.freezeStrong(m_inlineStackTop-&gt;m_codeBlock-&gt;getConstant(bytecode.m_specialPointer));</span>




6484             unsigned relativeOffset = jumpTarget(bytecode.m_targetLabel);
6485             Node* child = get(bytecode.m_value);
6486             if (bytecode.metadata(codeBlock).m_hasJumped) {
6487                 Node* condition = addToGraph(CompareEqPtr, OpInfo(frozenPointer), child);
<span class="line-modified">6488                 addToGraph(Branch, OpInfo(branchData(m_currentIndex.offset() + currentInstruction-&gt;size(), m_currentIndex.offset() + relativeOffset)), condition);</span>
6489                 LAST_OPCODE(op_jneq_ptr);
6490             }
6491             addToGraph(CheckCell, OpInfo(frozenPointer), child);
6492             NEXT_OPCODE(op_jneq_ptr);
6493         }
6494 
6495         case op_resolve_scope: {
6496             auto bytecode = currentInstruction-&gt;as&lt;OpResolveScope&gt;();
6497             auto&amp; metadata = bytecode.metadata(codeBlock);
6498 
6499             ResolveType resolveType;
6500             unsigned depth;
6501             JSScope* constantScope = nullptr;
6502             JSCell* lexicalEnvironment = nullptr;
6503             SymbolTable* symbolTable = nullptr;
6504             {
6505                 ConcurrentJSLocker locker(m_inlineStackTop-&gt;m_profiledBlock-&gt;m_lock);
6506                 resolveType = metadata.m_resolveType;
6507                 depth = metadata.m_localScopeDepth;
6508                 switch (resolveType) {
</pre>
<hr />
<pre>
6645                     addToGraph(GetDynamicVar, OpInfo(opInfo1), OpInfo(prediction), get(bytecode.m_scope)));
6646                 NEXT_OPCODE(op_get_from_scope);
6647             }
6648 
6649             UNUSED_PARAM(watchpoints); // We will use this in the future. For now we set it as a way of documenting the fact that that&#39;s what index 5 is in GlobalVar mode.
6650 
6651             JSGlobalObject* globalObject = m_inlineStackTop-&gt;m_codeBlock-&gt;globalObject();
6652 
6653             switch (resolveType) {
6654             case GlobalProperty:
6655             case GlobalPropertyWithVarInjectionChecks: {
6656                 // FIXME: Currently, module code do not query to JSGlobalLexicalEnvironment. So this case should be removed once it is fixed.
6657                 // https://bugs.webkit.org/show_bug.cgi?id=193347
6658                 if (m_inlineStackTop-&gt;m_codeBlock-&gt;scriptMode() != JSParserScriptMode::Module) {
6659                     if (!m_graph.watchGlobalProperty(globalObject, identifierNumber))
6660                         addToGraph(ForceOSRExit);
6661                 }
6662 
6663                 SpeculatedType prediction = getPrediction();
6664 
<span class="line-modified">6665                 GetByStatus status = GetByStatus::computeFor(structure, uid);</span>
<span class="line-modified">6666                 if (status.state() != GetByStatus::Simple</span>
6667                     || status.numVariants() != 1
6668                     || status[0].structureSet().size() != 1) {
6669                     set(bytecode.m_dst, addToGraph(GetByIdFlush, OpInfo(identifierNumber), OpInfo(prediction), get(bytecode.m_scope)));
6670                     break;
6671                 }
6672 
6673                 Node* base = weakJSConstant(globalObject);
6674                 Node* result = load(prediction, base, identifierNumber, status[0]);
6675                 addToGraph(Phantom, get(bytecode.m_scope));
6676                 set(bytecode.m_dst, result);
6677                 break;
6678             }
6679             case GlobalVar:
6680             case GlobalVarWithVarInjectionChecks:
6681             case GlobalLexicalVar:
6682             case GlobalLexicalVarWithVarInjectionChecks: {
6683                 addToGraph(Phantom, get(bytecode.m_scope));
6684                 WatchpointSet* watchpointSet;
6685                 ScopeOffset offset;
6686                 JSSegmentedVariableObject* scopeObject = jsCast&lt;JSSegmentedVariableObject*&gt;(JSScope::constantScopeForCodeBlock(resolveType, m_inlineStackTop-&gt;m_codeBlock));
</pre>
<hr />
<pre>
6905             case UnresolvedPropertyWithVarInjectionChecks:
6906                 RELEASE_ASSERT_NOT_REACHED();
6907                 break;
6908             }
6909             NEXT_OPCODE(op_put_to_scope);
6910         }
6911 
6912         case op_loop_hint: {
6913             // Baseline-&gt;DFG OSR jumps between loop hints. The DFG assumes that Baseline-&gt;DFG
6914             // OSR can only happen at basic block boundaries. Assert that these two statements
6915             // are compatible.
6916             RELEASE_ASSERT(m_currentIndex == blockBegin);
6917 
6918             // We never do OSR into an inlined code block. That could not happen, since OSR
6919             // looks up the code block that is the replacement for the baseline JIT code
6920             // block. Hence, machine code block = true code block = not inline code block.
6921             if (!m_inlineStackTop-&gt;m_caller)
6922                 m_currentBlock-&gt;isOSRTarget = true;
6923 
6924             addToGraph(LoopHint);

6925             NEXT_OPCODE(op_loop_hint);
6926         }
6927 
<span class="line-added">6928         case op_check_traps: {</span>
<span class="line-added">6929             addToGraph(Options::usePollingTraps() ? CheckTraps : InvalidationPoint);</span>
<span class="line-added">6930             NEXT_OPCODE(op_check_traps);</span>
<span class="line-added">6931         }</span>
<span class="line-added">6932 </span>
6933         case op_nop: {
6934             addToGraph(Check); // We add a nop here so that basic block linking doesn&#39;t break.
6935             NEXT_OPCODE(op_nop);
6936         }
6937 
6938         case op_super_sampler_begin: {
6939             addToGraph(SuperSamplerBegin);
6940             NEXT_OPCODE(op_super_sampler_begin);
6941         }
6942 
6943         case op_super_sampler_end: {
6944             addToGraph(SuperSamplerEnd);
6945             NEXT_OPCODE(op_super_sampler_end);
6946         }
6947 
6948         case op_create_lexical_environment: {
6949             auto bytecode = currentInstruction-&gt;as&lt;OpCreateLexicalEnvironment&gt;();
6950             ASSERT(bytecode.m_symbolTable.isConstant() &amp;&amp; bytecode.m_initialValue.isConstant());
<span class="line-modified">6951             FrozenValue* symbolTable = m_graph.freezeStrong(m_inlineStackTop-&gt;m_codeBlock-&gt;getConstant(bytecode.m_symbolTable));</span>
<span class="line-modified">6952             FrozenValue* initialValue = m_graph.freezeStrong(m_inlineStackTop-&gt;m_codeBlock-&gt;getConstant(bytecode.m_initialValue));</span>
6953             Node* scope = get(bytecode.m_scope);
6954             Node* lexicalEnvironment = addToGraph(CreateActivation, OpInfo(symbolTable), OpInfo(initialValue), scope);
6955             set(bytecode.m_dst, lexicalEnvironment);
6956             NEXT_OPCODE(op_create_lexical_environment);
6957         }
6958 
6959         case op_push_with_scope: {
6960             auto bytecode = currentInstruction-&gt;as&lt;OpPushWithScope&gt;();
6961             Node* currentScope = get(bytecode.m_currentScope);
6962             Node* object = get(bytecode.m_newScope);
6963             set(bytecode.m_dst, addToGraph(PushWithScope, currentScope, object));
6964             NEXT_OPCODE(op_push_with_scope);
6965         }
6966 
6967         case op_get_parent_scope: {
6968             auto bytecode = currentInstruction-&gt;as&lt;OpGetParentScope&gt;();
6969             Node* currentScope = get(bytecode.m_scope);
6970             Node* newScope = addToGraph(SkipScope, currentScope);
6971             set(bytecode.m_dst, newScope);
6972             addToGraph(Phantom, currentScope);
6973             NEXT_OPCODE(op_get_parent_scope);
6974         }
6975 
6976         case op_get_scope: {
6977             // Help the later stages a bit by doing some small constant folding here. Note that this
6978             // only helps for the first basic block. It&#39;s extremely important not to constant fold
6979             // loads from the scope register later, as that would prevent the DFG from tracking the
6980             // bytecode-level liveness of the scope register.
6981             auto bytecode = currentInstruction-&gt;as&lt;OpGetScope&gt;();
<span class="line-modified">6982             Node* callee = get(CallFrameSlot::callee);</span>
6983             Node* result;
6984             if (JSFunction* function = callee-&gt;dynamicCastConstant&lt;JSFunction*&gt;(*m_vm))
6985                 result = weakJSConstant(function-&gt;scope());
6986             else
6987                 result = addToGraph(GetScope, callee);
6988             set(bytecode.m_dst, result);
6989             NEXT_OPCODE(op_get_scope);
6990         }
6991 
6992         case op_argument_count: {
6993             auto bytecode = currentInstruction-&gt;as&lt;OpArgumentCount&gt;();
6994             Node* sub = addToGraph(ArithSub, OpInfo(Arith::Unchecked), OpInfo(SpecInt32Only), getArgumentCount(), addToGraph(JSConstant, OpInfo(m_constantOne)));
6995             set(bytecode.m_dst, sub);
6996             NEXT_OPCODE(op_argument_count);
6997         }
6998 
6999         case op_create_direct_arguments: {
7000             auto bytecode = currentInstruction-&gt;as&lt;OpCreateDirectArguments&gt;();
7001             noticeArgumentsUse();
7002             Node* createArguments = addToGraph(CreateDirectArguments);
7003             set(bytecode.m_dst, createArguments);
7004             NEXT_OPCODE(op_create_direct_arguments);
7005         }
7006 
7007         case op_create_scoped_arguments: {
7008             auto bytecode = currentInstruction-&gt;as&lt;OpCreateScopedArguments&gt;();
7009             noticeArgumentsUse();
7010             Node* createArguments = addToGraph(CreateScopedArguments, get(bytecode.m_scope));
7011             set(bytecode.m_dst, createArguments);
7012             NEXT_OPCODE(op_create_scoped_arguments);
7013         }
7014 
7015         case op_create_cloned_arguments: {
7016             auto bytecode = currentInstruction-&gt;as&lt;OpCreateClonedArguments&gt;();
7017             noticeArgumentsUse();
7018             Node* createArguments = addToGraph(CreateClonedArguments);
7019             set(bytecode.m_dst, createArguments);
7020             NEXT_OPCODE(op_create_cloned_arguments);
7021         }
7022 
<span class="line-added">7023         case op_create_arguments_butterfly: {</span>
<span class="line-added">7024             auto bytecode = currentInstruction-&gt;as&lt;OpCreateArgumentsButterfly&gt;();</span>
<span class="line-added">7025             noticeArgumentsUse();</span>
<span class="line-added">7026             set(bytecode.m_dst, addToGraph(CreateArgumentsButterfly));</span>
<span class="line-added">7027             NEXT_OPCODE(op_create_arguments_butterfly);</span>
<span class="line-added">7028         }</span>
<span class="line-added">7029 </span>
7030         case op_get_from_arguments: {
7031             auto bytecode = currentInstruction-&gt;as&lt;OpGetFromArguments&gt;();
7032             set(bytecode.m_dst,
7033                 addToGraph(
7034                     GetFromArguments,
7035                     OpInfo(bytecode.m_index),
7036                     OpInfo(getPrediction()),
7037                     get(bytecode.m_arguments)));
7038             NEXT_OPCODE(op_get_from_arguments);
7039         }
7040 
7041         case op_put_to_arguments: {
7042             auto bytecode = currentInstruction-&gt;as&lt;OpPutToArguments&gt;();
7043             addToGraph(
7044                 PutToArguments,
7045                 OpInfo(bytecode.m_index),
7046                 get(bytecode.m_arguments),
7047                 get(bytecode.m_value));
7048             NEXT_OPCODE(op_put_to_arguments);
7049         }
7050 
7051         case op_get_argument: {
7052             auto bytecode = currentInstruction-&gt;as&lt;OpGetArgument&gt;();
7053             InlineCallFrame* inlineCallFrame = this-&gt;inlineCallFrame();
7054             Node* argument;
7055             int32_t argumentIndexIncludingThis = bytecode.m_index;
7056             if (inlineCallFrame &amp;&amp; !inlineCallFrame-&gt;isVarargs()) {
7057                 int32_t argumentCountIncludingThisWithFixup = inlineCallFrame-&gt;argumentsWithFixup.size();
7058                 if (argumentIndexIncludingThis &lt; argumentCountIncludingThisWithFixup)
<span class="line-modified">7059                     argument = get(virtualRegisterForArgumentIncludingThis(argumentIndexIncludingThis));</span>
7060                 else
7061                     argument = addToGraph(JSConstant, OpInfo(m_constantUndefined));
7062             } else
7063                 argument = addToGraph(GetArgument, OpInfo(argumentIndexIncludingThis), OpInfo(getPrediction()));
7064             set(bytecode.m_dst, argument);
7065             NEXT_OPCODE(op_get_argument);
7066         }
7067         case op_new_async_generator_func:
7068             handleNewFunc(NewAsyncGeneratorFunction, currentInstruction-&gt;as&lt;OpNewAsyncGeneratorFunc&gt;());
7069             NEXT_OPCODE(op_new_async_generator_func);
7070         case op_new_func:
7071             handleNewFunc(NewFunction, currentInstruction-&gt;as&lt;OpNewFunc&gt;());
7072             NEXT_OPCODE(op_new_func);
7073         case op_new_generator_func:
7074             handleNewFunc(NewGeneratorFunction, currentInstruction-&gt;as&lt;OpNewGeneratorFunc&gt;());
7075             NEXT_OPCODE(op_new_generator_func);
7076         case op_new_async_func:
7077             handleNewFunc(NewAsyncFunction, currentInstruction-&gt;as&lt;OpNewAsyncFunc&gt;());
7078             NEXT_OPCODE(op_new_async_func);
7079 
</pre>
<hr />
<pre>
7095             Node* func = get(bytecode.m_function);
7096             Node* name = get(bytecode.m_name);
7097             addToGraph(SetFunctionName, func, name);
7098             NEXT_OPCODE(op_set_function_name);
7099         }
7100 
7101         case op_typeof: {
7102             auto bytecode = currentInstruction-&gt;as&lt;OpTypeof&gt;();
7103             set(bytecode.m_dst, addToGraph(TypeOf, get(bytecode.m_value)));
7104             NEXT_OPCODE(op_typeof);
7105         }
7106 
7107         case op_to_number: {
7108             auto bytecode = currentInstruction-&gt;as&lt;OpToNumber&gt;();
7109             SpeculatedType prediction = getPrediction();
7110             Node* value = get(bytecode.m_operand);
7111             set(bytecode.m_dst, addToGraph(ToNumber, OpInfo(0), OpInfo(prediction), value));
7112             NEXT_OPCODE(op_to_number);
7113         }
7114 
<span class="line-added">7115         case op_to_numeric: {</span>
<span class="line-added">7116             auto bytecode = currentInstruction-&gt;as&lt;OpToNumeric&gt;();</span>
<span class="line-added">7117             SpeculatedType prediction = getPrediction();</span>
<span class="line-added">7118             Node* value = get(bytecode.m_operand);</span>
<span class="line-added">7119             set(bytecode.m_dst, addToGraph(ToNumeric, OpInfo(0), OpInfo(prediction), value));</span>
<span class="line-added">7120             NEXT_OPCODE(op_to_numeric);</span>
<span class="line-added">7121         }</span>
<span class="line-added">7122 </span>
7123         case op_to_string: {
7124             auto bytecode = currentInstruction-&gt;as&lt;OpToString&gt;();
7125             Node* value = get(bytecode.m_operand);
7126             set(bytecode.m_dst, addToGraph(ToString, value));
7127             NEXT_OPCODE(op_to_string);
7128         }
7129 
7130         case op_to_object: {
7131             auto bytecode = currentInstruction-&gt;as&lt;OpToObject&gt;();
7132             SpeculatedType prediction = getPrediction();
7133             Node* value = get(bytecode.m_operand);
7134             unsigned identifierNumber = m_inlineStackTop-&gt;m_identifierRemap[bytecode.m_message];
7135             set(bytecode.m_dst, addToGraph(ToObject, OpInfo(identifierNumber), OpInfo(prediction), value));
7136             NEXT_OPCODE(op_to_object);
7137         }
7138 
7139         case op_in_by_val: {
7140             auto bytecode = currentInstruction-&gt;as&lt;OpInByVal&gt;();
7141             ArrayMode arrayMode = getArrayMode(bytecode.metadata(codeBlock).m_arrayProfile, Array::Read);
7142             set(bytecode.m_dst, addToGraph(InByVal, OpInfo(arrayMode.asWord()), get(bytecode.m_base), get(bytecode.m_property)));
</pre>
<hr />
<pre>
7248             set(bytecode.m_dst, addToGraph(GetEnumeratorStructurePname,
7249                 get(bytecode.m_enumerator),
7250                 get(bytecode.m_index)));
7251             NEXT_OPCODE(op_enumerator_structure_pname);
7252         }
7253 
7254         case op_enumerator_generic_pname: {
7255             auto bytecode = currentInstruction-&gt;as&lt;OpEnumeratorGenericPname&gt;();
7256             set(bytecode.m_dst, addToGraph(GetEnumeratorGenericPname,
7257                 get(bytecode.m_enumerator),
7258                 get(bytecode.m_index)));
7259             NEXT_OPCODE(op_enumerator_generic_pname);
7260         }
7261 
7262         case op_to_index_string: {
7263             auto bytecode = currentInstruction-&gt;as&lt;OpToIndexString&gt;();
7264             set(bytecode.m_dst, addToGraph(ToIndexString, get(bytecode.m_index)));
7265             NEXT_OPCODE(op_to_index_string);
7266         }
7267 
<span class="line-added">7268         case op_get_internal_field: {</span>
<span class="line-added">7269             auto bytecode = currentInstruction-&gt;as&lt;OpGetInternalField&gt;();</span>
<span class="line-added">7270             set(bytecode.m_dst, addToGraph(GetInternalField, OpInfo(bytecode.m_index), OpInfo(getPrediction()), get(bytecode.m_base)));</span>
<span class="line-added">7271             NEXT_OPCODE(op_get_internal_field);</span>
<span class="line-added">7272         }</span>
<span class="line-added">7273 </span>
<span class="line-added">7274         case op_put_internal_field: {</span>
<span class="line-added">7275             auto bytecode = currentInstruction-&gt;as&lt;OpPutInternalField&gt;();</span>
<span class="line-added">7276             addToGraph(PutInternalField, OpInfo(bytecode.m_index), get(bytecode.m_base), get(bytecode.m_value));</span>
<span class="line-added">7277             NEXT_OPCODE(op_put_internal_field);</span>
<span class="line-added">7278         }</span>
<span class="line-added">7279 </span>
7280         case op_log_shadow_chicken_prologue: {
7281             auto bytecode = currentInstruction-&gt;as&lt;OpLogShadowChickenPrologue&gt;();
7282             if (!m_inlineStackTop-&gt;m_inlineCallFrame)
7283                 addToGraph(LogShadowChickenPrologue, get(bytecode.m_scope));
7284             NEXT_OPCODE(op_log_shadow_chicken_prologue);
7285         }
7286 
7287         case op_log_shadow_chicken_tail: {
7288             auto bytecode = currentInstruction-&gt;as&lt;OpLogShadowChickenTail&gt;();
7289             if (!m_inlineStackTop-&gt;m_inlineCallFrame) {
7290                 // FIXME: The right solution for inlining is to elide these whenever the tail call
7291                 // ends up being inlined.
7292                 // https://bugs.webkit.org/show_bug.cgi?id=155686
7293                 addToGraph(LogShadowChickenTail, get(bytecode.m_thisValue), get(bytecode.m_scope));
7294             }
7295             NEXT_OPCODE(op_log_shadow_chicken_tail);
7296         }
7297 
7298         case op_unreachable: {
7299             flushForTerminal();
</pre>
<hr />
<pre>
7302         }
7303 
7304         default:
7305             // Parse failed! This should not happen because the capabilities checker
7306             // should have caught it.
7307             RELEASE_ASSERT_NOT_REACHED();
7308             return;
7309         }
7310     }
7311 }
7312 
7313 void ByteCodeParser::linkBlock(BasicBlock* block, Vector&lt;BasicBlock*&gt;&amp; possibleTargets)
7314 {
7315     ASSERT(!block-&gt;isLinked);
7316     ASSERT(!block-&gt;isEmpty());
7317     Node* node = block-&gt;terminal();
7318     ASSERT(node-&gt;isTerminal());
7319 
7320     switch (node-&gt;op()) {
7321     case Jump:
<span class="line-modified">7322         node-&gt;targetBlock() = blockForBytecodeIndex(possibleTargets, BytecodeIndex(node-&gt;targetBytecodeOffsetDuringParsing()));</span>
7323         break;
7324 
7325     case Branch: {
7326         BranchData* data = node-&gt;branchData();
<span class="line-modified">7327         data-&gt;taken.block = blockForBytecodeIndex(possibleTargets, BytecodeIndex(data-&gt;takenBytecodeIndex()));</span>
<span class="line-modified">7328         data-&gt;notTaken.block = blockForBytecodeIndex(possibleTargets, BytecodeIndex(data-&gt;notTakenBytecodeIndex()));</span>
7329         break;
7330     }
7331 
7332     case Switch: {
7333         SwitchData* data = node-&gt;switchData();
7334         for (unsigned i = node-&gt;switchData()-&gt;cases.size(); i--;)
<span class="line-modified">7335             data-&gt;cases[i].target.block = blockForBytecodeIndex(possibleTargets, BytecodeIndex(data-&gt;cases[i].target.bytecodeIndex()));</span>
<span class="line-modified">7336         data-&gt;fallThrough.block = blockForBytecodeIndex(possibleTargets, BytecodeIndex(data-&gt;fallThrough.bytecodeIndex()));</span>
7337         break;
7338     }
7339 
7340     default:
7341         RELEASE_ASSERT_NOT_REACHED();
7342     }
7343 
7344     VERBOSE_LOG(&quot;Marking &quot;, RawPointer(block), &quot; as linked (actually did linking)\n&quot;);
7345     block-&gt;didLink();
7346 }
7347 
7348 void ByteCodeParser::linkBlocks(Vector&lt;BasicBlock*&gt;&amp; unlinkedBlocks, Vector&lt;BasicBlock*&gt;&amp; possibleTargets)
7349 {
7350     for (size_t i = 0; i &lt; unlinkedBlocks.size(); ++i) {
7351         VERBOSE_LOG(&quot;Attempting to link &quot;, RawPointer(unlinkedBlocks[i]), &quot;\n&quot;);
7352         linkBlock(unlinkedBlocks[i], possibleTargets);
7353     }
7354 }
7355 
7356 ByteCodeParser::InlineStackEntry::InlineStackEntry(
</pre>
<hr />
<pre>
7387     m_optimizedContext.optimizedCodeBlock = optimizedBlock;
7388     if (Options::usePolyvariantDevirtualization() &amp;&amp; optimizedBlock) {
7389         ConcurrentJSLocker locker(optimizedBlock-&gt;m_lock);
7390         optimizedBlock-&gt;getICStatusMap(locker, m_optimizedContext.map);
7391     }
7392     byteCodeParser-&gt;m_icContextStack.append(&amp;m_optimizedContext);
7393 
7394     int argumentCountIncludingThisWithFixup = std::max&lt;int&gt;(argumentCountIncludingThis, codeBlock-&gt;numParameters());
7395 
7396     if (m_caller) {
7397         // Inline case.
7398         ASSERT(codeBlock != byteCodeParser-&gt;m_codeBlock);
7399         ASSERT(inlineCallFrameStart.isValid());
7400 
7401         m_inlineCallFrame = byteCodeParser-&gt;m_graph.m_plan.inlineCallFrames()-&gt;add();
7402         m_optimizedContext.inlineCallFrame = m_inlineCallFrame;
7403 
7404         // The owner is the machine code block, and we already have a barrier on that when the
7405         // plan finishes.
7406         m_inlineCallFrame-&gt;baselineCodeBlock.setWithoutWriteBarrier(codeBlock-&gt;baselineVersion());
<span class="line-added">7407         m_inlineCallFrame-&gt;setTmpOffset((m_caller-&gt;m_inlineCallFrame ? m_caller-&gt;m_inlineCallFrame-&gt;tmpOffset : 0) + m_caller-&gt;m_codeBlock-&gt;numTmps());</span>
7408         m_inlineCallFrame-&gt;setStackOffset(inlineCallFrameStart.offset() - CallFrame::headerSizeInRegisters);
7409         m_inlineCallFrame-&gt;argumentCountIncludingThis = argumentCountIncludingThis;
<span class="line-added">7410         RELEASE_ASSERT(m_inlineCallFrame-&gt;argumentCountIncludingThis == argumentCountIncludingThis);</span>
7411         if (callee) {
7412             m_inlineCallFrame-&gt;calleeRecovery = ValueRecovery::constant(callee);
7413             m_inlineCallFrame-&gt;isClosureCall = false;
7414         } else
7415             m_inlineCallFrame-&gt;isClosureCall = true;
7416         m_inlineCallFrame-&gt;directCaller = byteCodeParser-&gt;currentCodeOrigin();
7417         m_inlineCallFrame-&gt;argumentsWithFixup.resizeToFit(argumentCountIncludingThisWithFixup); // Set the number of arguments including this, but don&#39;t configure the value recoveries, yet.
7418         m_inlineCallFrame-&gt;kind = kind;
7419 
7420         m_identifierRemap.resize(codeBlock-&gt;numberOfIdentifiers());
7421         m_switchRemap.resize(codeBlock-&gt;numberOfSwitchJumpTables());
7422 
7423         for (size_t i = 0; i &lt; codeBlock-&gt;numberOfIdentifiers(); ++i) {
7424             UniquedStringImpl* rep = codeBlock-&gt;identifier(i).impl();
7425             unsigned index = byteCodeParser-&gt;m_graph.identifiers().ensure(rep);
7426             m_identifierRemap[i] = index;
7427         }
7428         for (unsigned i = 0; i &lt; codeBlock-&gt;numberOfSwitchJumpTables(); ++i) {
7429             m_switchRemap[i] = byteCodeParser-&gt;m_codeBlock-&gt;numberOfSwitchJumpTables();
7430             byteCodeParser-&gt;m_codeBlock-&gt;addSwitchJumpTableFromProfiledCodeBlock(codeBlock-&gt;switchJumpTable(i));
</pre>
<hr />
<pre>
7467 void ByteCodeParser::parseCodeBlock()
7468 {
7469     clearCaches();
7470 
7471     CodeBlock* codeBlock = m_inlineStackTop-&gt;m_codeBlock;
7472 
7473     if (UNLIKELY(m_graph.compilation())) {
7474         m_graph.compilation()-&gt;addProfiledBytecodes(
7475             *m_vm-&gt;m_perBytecodeProfiler, m_inlineStackTop-&gt;m_profiledBlock);
7476     }
7477 
7478     if (UNLIKELY(Options::dumpSourceAtDFGTime())) {
7479         Vector&lt;DeferredSourceDump&gt;&amp; deferredSourceDump = m_graph.m_plan.callback()-&gt;ensureDeferredSourceDump();
7480         if (inlineCallFrame()) {
7481             DeferredSourceDump dump(codeBlock-&gt;baselineVersion(), m_codeBlock, JITType::DFGJIT, inlineCallFrame()-&gt;directCaller.bytecodeIndex());
7482             deferredSourceDump.append(dump);
7483         } else
7484             deferredSourceDump.append(DeferredSourceDump(codeBlock-&gt;baselineVersion()));
7485     }
7486 
<span class="line-modified">7487     if (UNLIKELY(Options::dumpBytecodeAtDFGTime())) {</span>
7488         dataLog(&quot;Parsing &quot;, *codeBlock);
7489         if (inlineCallFrame()) {
7490             dataLog(
7491                 &quot; for inlining at &quot;, CodeBlockWithJITType(m_codeBlock, JITType::DFGJIT),
7492                 &quot; &quot;, inlineCallFrame()-&gt;directCaller);
7493         }
7494         dataLog(
7495             &quot;, isStrictMode = &quot;, codeBlock-&gt;ownerExecutable()-&gt;isStrictMode(), &quot;\n&quot;);
7496         codeBlock-&gt;baselineVersion()-&gt;dumpBytecode();
7497     }
7498 
7499     Vector&lt;InstructionStream::Offset, 32&gt; jumpTargets;
7500     computePreciseJumpTargets(codeBlock, jumpTargets);
<span class="line-modified">7501     if (UNLIKELY(Options::dumpBytecodeAtDFGTime())) {</span>
7502         dataLog(&quot;Jump targets: &quot;);
7503         CommaPrinter comma;
7504         for (unsigned i = 0; i &lt; jumpTargets.size(); ++i)
7505             dataLog(comma, jumpTargets[i]);
7506         dataLog(&quot;\n&quot;);
7507     }
7508 
7509     for (unsigned jumpTargetIndex = 0; jumpTargetIndex &lt;= jumpTargets.size(); ++jumpTargetIndex) {
7510         // The maximum bytecode offset to go into the current basicblock is either the next jump target, or the end of the instructions.
7511         unsigned limit = jumpTargetIndex &lt; jumpTargets.size() ? jumpTargets[jumpTargetIndex] : codeBlock-&gt;instructions().size();
<span class="line-modified">7512         ASSERT(m_currentIndex.offset() &lt; limit);</span>
7513 
7514         // Loop until we reach the current limit (i.e. next jump target).
7515         do {
7516             // There may already be a currentBlock in two cases:
7517             // - we may have just entered the loop for the first time
7518             // - we may have just returned from an inlined callee that had some early returns and
7519             //   so allocated a continuation block, and the instruction after the call is a jump target.
7520             // In both cases, we want to keep using it.
7521             if (!m_currentBlock) {
7522                 m_currentBlock = allocateTargetableBlock(m_currentIndex);
7523 
7524                 // The first block is definitely an OSR target.
7525                 if (m_graph.numBlocks() == 1) {
7526                     m_currentBlock-&gt;isOSRTarget = true;
7527                     m_graph.m_roots.append(m_currentBlock);
7528                 }
7529                 prepareToParseBlock();
7530             }
7531 
7532             parseBlock(limit);
7533 
7534             // We should not have gone beyond the limit.
<span class="line-modified">7535             ASSERT(m_currentIndex.offset() &lt;= limit);</span>
7536 
7537             if (m_currentBlock-&gt;isEmpty()) {
7538                 // This case only happens if the last instruction was an inlined call with early returns
7539                 // or polymorphic (creating an empty continuation block),
7540                 // and then we hit the limit before putting anything in the continuation block.
<span class="line-modified">7541                 ASSERT(m_currentIndex.offset() == limit);</span>
7542                 makeBlockTargetable(m_currentBlock, m_currentIndex);
7543             } else {
<span class="line-modified">7544                 ASSERT(m_currentBlock-&gt;terminal() || (m_currentIndex.offset() == codeBlock-&gt;instructions().size() &amp;&amp; inlineCallFrame()));</span>
7545                 m_currentBlock = nullptr;
7546             }
<span class="line-modified">7547         } while (m_currentIndex.offset() &lt; limit);</span>
7548     }
7549 
7550     // Should have reached the end of the instructions.
<span class="line-modified">7551     ASSERT(m_currentIndex.offset() == codeBlock-&gt;instructions().size());</span>
7552 
7553     VERBOSE_LOG(&quot;Done parsing &quot;, *codeBlock, &quot; (fell off end)\n&quot;);
7554 }
7555 
7556 template &lt;typename Bytecode&gt;
7557 void ByteCodeParser::handlePutByVal(Bytecode bytecode, unsigned instructionSize)
7558 {
7559     Node* base = get(bytecode.m_base);
7560     Node* property = get(bytecode.m_property);
7561     Node* value = get(bytecode.m_value);
7562     bool isDirect = Bytecode::opcodeID == op_put_by_val_direct;
7563     bool compiledAsPutById = false;
7564     {
7565         unsigned identifierNumber = std::numeric_limits&lt;unsigned&gt;::max();
7566         PutByIdStatus putByIdStatus;
7567         {
7568             ConcurrentJSLocker locker(m_inlineStackTop-&gt;m_profiledBlock-&gt;m_lock);
7569             ByValInfo* byValInfo = m_inlineStackTop-&gt;m_baselineMap.get(CodeOrigin(currentCodeOrigin().bytecodeIndex())).byValInfo;
7570             // FIXME: When the bytecode is not compiled in the baseline JIT, byValInfo becomes null.
7571             // At that time, there is no information.
7572             if (byValInfo
7573                 &amp;&amp; byValInfo-&gt;stubInfo
7574                 &amp;&amp; !byValInfo-&gt;tookSlowPath
7575                 &amp;&amp; !m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadIdent)
7576                 &amp;&amp; !m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadType)
7577                 &amp;&amp; !m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell)) {
7578                 compiledAsPutById = true;
7579                 identifierNumber = m_graph.identifiers().ensure(byValInfo-&gt;cachedId.impl());
7580                 UniquedStringImpl* uid = m_graph.identifiers()[identifierNumber];
7581 
7582                 if (Symbol* symbol = byValInfo-&gt;cachedSymbol.get()) {
7583                     FrozenValue* frozen = m_graph.freezeStrong(symbol);
7584                     addToGraph(CheckCell, OpInfo(frozen), property);
7585                 } else {
7586                     ASSERT(!uid-&gt;isSymbol());
<span class="line-modified">7587                     addToGraph(CheckIdent, OpInfo(uid), property);</span>
7588                 }
7589 
7590                 putByIdStatus = PutByIdStatus::computeForStubInfo(
7591                     locker, m_inlineStackTop-&gt;m_profiledBlock,
7592                     byValInfo-&gt;stubInfo, currentCodeOrigin(), uid);
7593 
7594             }
7595         }
7596 
7597         if (compiledAsPutById)
7598             handlePutById(base, identifierNumber, value, putByIdStatus, isDirect, instructionSize);
7599     }
7600 
7601     if (!compiledAsPutById) {
7602         ArrayMode arrayMode = getArrayMode(bytecode.metadata(m_inlineStackTop-&gt;m_codeBlock).m_arrayProfile, Array::Write);
7603 
7604         addVarArgChild(base);
7605         addVarArgChild(property);
7606         addVarArgChild(value);
7607         addVarArgChild(0); // Leave room for property storage.
</pre>
<hr />
<pre>
7646     addToGraph(Phantom, scope);
7647 }
7648 
7649 template &lt;typename Bytecode&gt;
7650 void ByteCodeParser::handleNewFuncExp(NodeType op, Bytecode bytecode)
7651 {
7652     FunctionExecutable* expr = m_inlineStackTop-&gt;m_profiledBlock-&gt;functionExpr(bytecode.m_functionDecl);
7653     FrozenValue* frozen = m_graph.freezeStrong(expr);
7654     Node* scope = get(bytecode.m_scope);
7655     set(bytecode.m_dst, addToGraph(op, OpInfo(frozen), scope));
7656     // Ideally we wouldn&#39;t have to do this Phantom. But:
7657     //
7658     // For the constant case: we must do it because otherwise we would have no way of knowing
7659     // that the scope is live at OSR here.
7660     //
7661     // For the non-constant case: NewFunction could be DCE&#39;d, but baseline&#39;s implementation
7662     // won&#39;t be able to handle an Undefined scope.
7663     addToGraph(Phantom, scope);
7664 }
7665 
<span class="line-added">7666 template &lt;typename Bytecode&gt;</span>
<span class="line-added">7667 void ByteCodeParser::handleCreateInternalFieldObject(const ClassInfo* classInfo, NodeType createOp, NodeType newOp, Bytecode bytecode)</span>
<span class="line-added">7668 {</span>
<span class="line-added">7669     CodeBlock* codeBlock = m_inlineStackTop-&gt;m_codeBlock;</span>
<span class="line-added">7670     JSGlobalObject* globalObject = m_graph.globalObjectFor(currentNodeOrigin().semantic);</span>
<span class="line-added">7671     Node* callee = get(VirtualRegister(bytecode.m_callee));</span>
<span class="line-added">7672 </span>
<span class="line-added">7673     JSFunction* function = callee-&gt;dynamicCastConstant&lt;JSFunction*&gt;(*m_vm);</span>
<span class="line-added">7674     if (!function) {</span>
<span class="line-added">7675         JSCell* cachedFunction = bytecode.metadata(codeBlock).m_cachedCallee.unvalidatedGet();</span>
<span class="line-added">7676         if (cachedFunction</span>
<span class="line-added">7677             &amp;&amp; cachedFunction != JSCell::seenMultipleCalleeObjects()</span>
<span class="line-added">7678             &amp;&amp; !m_inlineStackTop-&gt;m_exitProfile.hasExitSite(m_currentIndex, BadCell)) {</span>
<span class="line-added">7679             ASSERT(cachedFunction-&gt;inherits&lt;JSFunction&gt;(*m_vm));</span>
<span class="line-added">7680 </span>
<span class="line-added">7681             FrozenValue* frozen = m_graph.freeze(cachedFunction);</span>
<span class="line-added">7682             addToGraph(CheckCell, OpInfo(frozen), callee);</span>
<span class="line-added">7683 </span>
<span class="line-added">7684             function = static_cast&lt;JSFunction*&gt;(cachedFunction);</span>
<span class="line-added">7685         }</span>
<span class="line-added">7686     }</span>
<span class="line-added">7687 </span>
<span class="line-added">7688     if (function) {</span>
<span class="line-added">7689         if (FunctionRareData* rareData = function-&gt;rareData()) {</span>
<span class="line-added">7690             if (rareData-&gt;allocationProfileWatchpointSet().isStillValid()) {</span>
<span class="line-added">7691                 Structure* structure = rareData-&gt;internalFunctionAllocationStructure();</span>
<span class="line-added">7692                 if (structure</span>
<span class="line-added">7693                     &amp;&amp; structure-&gt;classInfo() == classInfo</span>
<span class="line-added">7694                     &amp;&amp; structure-&gt;globalObject() == globalObject</span>
<span class="line-added">7695                     &amp;&amp; rareData-&gt;allocationProfileWatchpointSet().isStillValid()) {</span>
<span class="line-added">7696                     m_graph.freeze(rareData);</span>
<span class="line-added">7697                     m_graph.watchpoints().addLazily(rareData-&gt;allocationProfileWatchpointSet());</span>
<span class="line-added">7698 </span>
<span class="line-added">7699                     set(VirtualRegister(bytecode.m_dst), addToGraph(newOp, OpInfo(m_graph.registerStructure(structure))));</span>
<span class="line-added">7700                     // The callee is still live up to this point.</span>
<span class="line-added">7701                     addToGraph(Phantom, callee);</span>
<span class="line-added">7702                     return;</span>
<span class="line-added">7703                 }</span>
<span class="line-added">7704             }</span>
<span class="line-added">7705         }</span>
<span class="line-added">7706     }</span>
<span class="line-added">7707 </span>
<span class="line-added">7708     set(VirtualRegister(bytecode.m_dst), addToGraph(createOp, callee));</span>
<span class="line-added">7709 }</span>
<span class="line-added">7710 </span>
7711 void ByteCodeParser::parse()
7712 {
7713     // Set during construction.
<span class="line-modified">7714     ASSERT(!m_currentIndex.offset());</span>
7715 
7716     VERBOSE_LOG(&quot;Parsing &quot;, *m_codeBlock, &quot;\n&quot;);
7717 
7718     InlineStackEntry inlineStackEntry(
7719         this, m_codeBlock, m_profiledBlock, 0, VirtualRegister(), VirtualRegister(),
7720         m_codeBlock-&gt;numParameters(), InlineCallFrame::Call, nullptr);
7721 
7722     parseCodeBlock();
7723     linkBlocks(inlineStackEntry.m_unlinkedBlocks, inlineStackEntry.m_blockLinkingTargets);
7724 
7725     if (m_hasAnyForceOSRExits) {
7726         BlockSet blocksToIgnore;
7727         for (BasicBlock* block : m_graph.blocksInNaturalOrder()) {
7728             if (block-&gt;isOSRTarget &amp;&amp; block-&gt;bytecodeBegin == m_graph.m_plan.osrEntryBytecodeIndex()) {
7729                 blocksToIgnore.add(block);
7730                 break;
7731             }
7732         }
7733 
7734         {
</pre>
<hr />
<pre>
7752         Operands&lt;VariableAccessData*&gt; mapping(OperandsLike, m_graph.block(0)-&gt;variablesAtHead);
7753 
7754         for (BasicBlock* block : m_graph.blocksInNaturalOrder()) {
7755             if (blocksToIgnore.contains(block))
7756                 continue;
7757 
7758             mapping.fill(nullptr);
7759             if (validationEnabled()) {
7760                 // Verify that it&#39;s correct to fill mapping with nullptr.
7761                 for (unsigned i = 0; i &lt; block-&gt;variablesAtHead.size(); ++i) {
7762                     Node* node = block-&gt;variablesAtHead.at(i);
7763                     RELEASE_ASSERT(!node);
7764                 }
7765             }
7766 
7767             for (unsigned nodeIndex = 0; nodeIndex &lt; block-&gt;size(); ++nodeIndex) {
7768                 {
7769                     Node* node = block-&gt;at(nodeIndex);
7770 
7771                     if (node-&gt;hasVariableAccessData(m_graph))
<span class="line-modified">7772                         mapping.operand(node-&gt;operand()) = node-&gt;variableAccessData();</span>
7773 
7774                     if (node-&gt;op() != ForceOSRExit)
7775                         continue;
7776                 }
7777 
7778                 NodeOrigin origin = block-&gt;at(nodeIndex)-&gt;origin;
7779                 RELEASE_ASSERT(origin.exitOK);
7780 
7781                 ++nodeIndex;
7782 
7783                 {
7784                     if (validationEnabled()) {
7785                         // This verifies that we don&#39;t need to change any of the successors&#39;s predecessor
7786                         // list after planting the Unreachable below. At this point in the bytecode
7787                         // parser, we haven&#39;t linked up the predecessor lists yet.
7788                         for (BasicBlock* successor : block-&gt;successors())
7789                             RELEASE_ASSERT(successor-&gt;predecessors.isEmpty());
7790                     }
7791 
<span class="line-modified">7792                     auto insertLivenessPreservingOp = [&amp;] (InlineCallFrame* inlineCallFrame, NodeType op, Operand operand) {</span>
7793                         VariableAccessData* variable = mapping.operand(operand);
7794                         if (!variable) {
7795                             variable = newVariableAccessData(operand);
7796                             mapping.operand(operand) = variable;
7797                         }
7798 
<span class="line-modified">7799                         Operand argument = unmapOperand(inlineCallFrame, operand);</span>
7800                         if (argument.isArgument() &amp;&amp; !argument.isHeader()) {
7801                             const Vector&lt;ArgumentPosition*&gt;&amp; arguments = m_inlineCallFrameToArgumentPositions.get(inlineCallFrame);
7802                             arguments[argument.toArgument()]-&gt;addVariable(variable);
7803                         }
7804                         insertionSet.insertNode(nodeIndex, SpecNone, op, origin, OpInfo(variable));
7805                     };
<span class="line-modified">7806                     auto addFlushDirect = [&amp;] (InlineCallFrame* inlineCallFrame, Operand operand) {</span>
7807                         insertLivenessPreservingOp(inlineCallFrame, Flush, operand);
7808                     };
<span class="line-modified">7809                     auto addPhantomLocalDirect = [&amp;] (InlineCallFrame* inlineCallFrame, Operand operand) {</span>
7810                         insertLivenessPreservingOp(inlineCallFrame, PhantomLocal, operand);
7811                     };
7812                     flushForTerminalImpl(origin.semantic, addFlushDirect, addPhantomLocalDirect);
7813                 }
7814 
7815                 while (true) {
7816                     RELEASE_ASSERT(nodeIndex &lt; block-&gt;size());
7817 
7818                     Node* node = block-&gt;at(nodeIndex);
7819 
7820                     node-&gt;origin = origin;
7821                     m_graph.doToChildren(node, [&amp;] (Edge edge) {
7822                         // We only need to keep data flow edges to nodes defined prior to the ForceOSRExit. The reason
7823                         // for this is we rely on backwards propagation being able to see the &quot;full&quot; bytecode. To model
7824                         // this, we preserve uses of a node in a generic way so that backwards propagation can reason
7825                         // about them. Therefore, we can&#39;t remove uses of a node which is defined before the ForceOSRExit
7826                         // even when we&#39;re at a point in the program after the ForceOSRExit, because that would break backwards
7827                         // propagation&#39;s analysis over the uses of a node. However, we don&#39;t need this same preservation for
7828                         // nodes defined after ForceOSRExit, as we&#39;ve already exitted before those defs.
7829                         if (edge-&gt;hasResult())
</pre>
<hr />
<pre>
7854         // Ensure our bookkeeping for ForceOSRExit nodes is working.
7855         for (BasicBlock* block : m_graph.blocksInNaturalOrder()) {
7856             for (Node* node : *block)
7857                 RELEASE_ASSERT(node-&gt;op() != ForceOSRExit);
7858         }
7859     }
7860 
7861     m_graph.determineReachability();
7862     m_graph.killUnreachableBlocks();
7863 
7864     for (BlockIndex blockIndex = m_graph.numBlocks(); blockIndex--;) {
7865         BasicBlock* block = m_graph.block(blockIndex);
7866         if (!block)
7867             continue;
7868         ASSERT(block-&gt;variablesAtHead.numberOfLocals() == m_graph.block(0)-&gt;variablesAtHead.numberOfLocals());
7869         ASSERT(block-&gt;variablesAtHead.numberOfArguments() == m_graph.block(0)-&gt;variablesAtHead.numberOfArguments());
7870         ASSERT(block-&gt;variablesAtTail.numberOfLocals() == m_graph.block(0)-&gt;variablesAtHead.numberOfLocals());
7871         ASSERT(block-&gt;variablesAtTail.numberOfArguments() == m_graph.block(0)-&gt;variablesAtHead.numberOfArguments());
7872     }
7873 
<span class="line-added">7874     m_graph.m_tmps = m_numTmps;</span>
7875     m_graph.m_localVars = m_numLocals;
7876     m_graph.m_parameterSlots = m_parameterSlots;
7877 }
7878 
7879 void parse(Graph&amp; graph)
7880 {
7881     ByteCodeParser(graph).parse();
7882 }
7883 
7884 } } // namespace JSC::DFG
7885 
7886 #endif
</pre>
</td>
</tr>
</table>
<center><a href="DFGBlockInsertionSet.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGCFAPhase.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>