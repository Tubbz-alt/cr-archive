<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JITInlines.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2008-2019 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #if ENABLE(JIT)
<a name="1" id="anc1"></a><span class="line-added"> 29 #include &quot;CommonSlowPathsInlines.h&quot;</span>
 30 #include &quot;JSCInlines.h&quot;
 31 
 32 namespace JSC {
 33 
<a name="2" id="anc2"></a>











 34 ALWAYS_INLINE MacroAssembler::JumpList JIT::emitLoadForArrayMode(const Instruction* currentInstruction, JITArrayMode arrayMode, PatchableJump&amp; badType)
 35 {
 36     switch (arrayMode) {
 37     case JITInt32:
 38         return emitInt32Load(currentInstruction, badType);
 39     case JITDouble:
 40         return emitDoubleLoad(currentInstruction, badType);
 41     case JITContiguous:
 42         return emitContiguousLoad(currentInstruction, badType);
 43     case JITArrayStorage:
 44         return emitArrayStorageLoad(currentInstruction, badType);
 45     default:
 46         break;
 47     }
 48     RELEASE_ASSERT_NOT_REACHED();
 49     return MacroAssembler::JumpList();
 50 }
 51 
<a name="3" id="anc3"></a><span class="line-modified"> 52 ALWAYS_INLINE bool JIT::isOperandConstantDouble(VirtualRegister src)</span>
 53 {
<a name="4" id="anc4"></a><span class="line-modified"> 54     return src.isConstant() &amp;&amp; getConstantOperand(src).isDouble();</span>
 55 }
 56 
<a name="5" id="anc5"></a><span class="line-modified"> 57 ALWAYS_INLINE JSValue JIT::getConstantOperand(VirtualRegister src)</span>
 58 {
<a name="6" id="anc6"></a><span class="line-modified"> 59     ASSERT(src.isConstant());</span>










 60     return m_codeBlock-&gt;getConstant(src);
 61 }
 62 
<a name="7" id="anc7"></a><span class="line-modified"> 63 ALWAYS_INLINE void JIT::emitPutIntToCallFrameHeader(RegisterID from, VirtualRegister entry)</span>
 64 {
<a name="8" id="anc8"></a><span class="line-added"> 65     ASSERT(entry.isHeader());</span>
 66 #if USE(JSVALUE32_64)
 67     store32(TrustedImm32(JSValue::Int32Tag), tagFor(entry));
 68     store32(from, payloadFor(entry));
 69 #else
 70     store64(from, addressFor(entry));
 71 #endif
 72 }
 73 
 74 ALWAYS_INLINE void JIT::emitLoadCharacterString(RegisterID src, RegisterID dst, JumpList&amp; failures)
 75 {
 76     failures.append(branchIfNotString(src));
 77     loadPtr(MacroAssembler::Address(src, JSString::offsetOfValue()), dst);
 78     failures.append(branchIfRopeStringImpl(dst));
 79     failures.append(branch32(NotEqual, MacroAssembler::Address(dst, StringImpl::lengthMemoryOffset()), TrustedImm32(1)));
<a name="9" id="anc9"></a><span class="line-modified"> 80     loadPtr(MacroAssembler::Address(dst, StringImpl::dataOffset()), regT1);</span>
<span class="line-modified"> 81 </span>
<span class="line-modified"> 82     auto is16Bit = branchTest32(Zero, Address(dst, StringImpl::flagsOffset()), TrustedImm32(StringImpl::flagIs8Bit()));</span>
<span class="line-modified"> 83     load8(MacroAssembler::Address(regT1, 0), dst);</span>
<span class="line-modified"> 84     auto done = jump();</span>



 85     is16Bit.link(this);
<a name="10" id="anc10"></a><span class="line-modified"> 86     load16(MacroAssembler::Address(regT1, 0), dst);</span>
<span class="line-modified"> 87     done.link(this);</span>
 88 }
 89 
 90 ALWAYS_INLINE JIT::Call JIT::emitNakedCall(CodePtr&lt;NoPtrTag&gt; target)
 91 {
<a name="11" id="anc11"></a><span class="line-modified"> 92     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
 93     Call nakedCall = nearCall();
<a name="12" id="anc12"></a><span class="line-modified"> 94     m_calls.append(CallRecord(nakedCall, m_bytecodeIndex, FunctionPtr&lt;OperationPtrTag&gt;(target.retagged&lt;OperationPtrTag&gt;())));</span>
 95     return nakedCall;
 96 }
 97 
 98 ALWAYS_INLINE JIT::Call JIT::emitNakedTailCall(CodePtr&lt;NoPtrTag&gt; target)
 99 {
<a name="13" id="anc13"></a><span class="line-modified">100     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
101     Call nakedCall = nearTailCall();
<a name="14" id="anc14"></a><span class="line-modified">102     m_calls.append(CallRecord(nakedCall, m_bytecodeIndex, FunctionPtr&lt;OperationPtrTag&gt;(target.retagged&lt;OperationPtrTag&gt;())));</span>
103     return nakedCall;
104 }
105 
106 ALWAYS_INLINE void JIT::updateTopCallFrame()
107 {
<a name="15" id="anc15"></a><span class="line-modified">108     uint32_t locationBits = CallSiteIndex(m_bytecodeIndex).bits();</span>
<span class="line-modified">109     store32(TrustedImm32(locationBits), tagFor(CallFrameSlot::argumentCountIncludingThis));</span>






110 
111     // FIXME: It&#39;s not clear that this is needed. JITOperations tend to update the top call frame on
112     // the C++ side.
113     // https://bugs.webkit.org/show_bug.cgi?id=155693
114     storePtr(callFrameRegister, &amp;m_vm-&gt;topCallFrame);
115 }
116 
117 ALWAYS_INLINE MacroAssembler::Call JIT::appendCallWithExceptionCheck(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
118 {
119     updateTopCallFrame();
120     MacroAssembler::Call call = appendCall(function);
121     exceptionCheck();
122     return call;
123 }
124 
125 #if OS(WINDOWS) &amp;&amp; CPU(X86_64)
126 ALWAYS_INLINE MacroAssembler::Call JIT::appendCallWithExceptionCheckAndSlowPathReturnType(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
127 {
128     updateTopCallFrame();
129     MacroAssembler::Call call = appendCallWithSlowPathReturnType(function);
130     exceptionCheck();
131     return call;
132 }
133 #endif
134 
135 ALWAYS_INLINE MacroAssembler::Call JIT::appendCallWithCallFrameRollbackOnException(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
136 {
137     updateTopCallFrame(); // The callee is responsible for setting topCallFrame to their caller
138     MacroAssembler::Call call = appendCall(function);
139     exceptionCheckWithCallFrameRollback();
140     return call;
141 }
142 
<a name="16" id="anc16"></a><span class="line-modified">143 ALWAYS_INLINE MacroAssembler::Call JIT::appendCallWithExceptionCheckSetJSValueResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, VirtualRegister dst)</span>
144 {
145     MacroAssembler::Call call = appendCallWithExceptionCheck(function);
146 #if USE(JSVALUE64)
147     emitPutVirtualRegister(dst, returnValueGPR);
148 #else
149     emitStore(dst, returnValueGPR2, returnValueGPR);
150 #endif
151     return call;
152 }
153 
154 template&lt;typename Metadata&gt;
<a name="17" id="anc17"></a><span class="line-modified">155 ALWAYS_INLINE MacroAssembler::Call JIT::appendCallWithExceptionCheckSetJSValueResultWithProfile(Metadata&amp; metadata, const FunctionPtr&lt;CFunctionPtrTag&gt; function, VirtualRegister dst)</span>
156 {
157     MacroAssembler::Call call = appendCallWithExceptionCheck(function);
158     emitValueProfilingSite(metadata);
159 #if USE(JSVALUE64)
160     emitPutVirtualRegister(dst, returnValueGPR);
161 #else
162     emitStore(dst, returnValueGPR2, returnValueGPR);
163 #endif
164     return call;
165 }
166 
<a name="18" id="anc18"></a><span class="line-modified">167 ALWAYS_INLINE void JIT::linkSlowCaseIfNotJSCell(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter, VirtualRegister reg)</span>
168 {
<a name="19" id="anc19"></a><span class="line-modified">169     if (!m_codeBlock-&gt;isKnownNotImmediate(reg))</span>
170         linkSlowCase(iter);
171 }
172 
<a name="20" id="anc20"></a><span class="line-modified">173 ALWAYS_INLINE void JIT::linkAllSlowCasesForBytecodeIndex(Vector&lt;SlowCaseEntry&gt;&amp; slowCases, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter, BytecodeIndex bytecodeIndex)</span>
174 {
<a name="21" id="anc21"></a><span class="line-modified">175     while (iter != slowCases.end() &amp;&amp; iter-&gt;to == bytecodeIndex)</span>
176         linkSlowCase(iter);
177 }
178 
<a name="22" id="anc22"></a><span class="line-added">179 ALWAYS_INLINE bool JIT::hasAnySlowCases(Vector&lt;SlowCaseEntry&gt;&amp; slowCases, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter, BytecodeIndex bytecodeIndex)</span>
<span class="line-added">180 {</span>
<span class="line-added">181     if (iter != slowCases.end() &amp;&amp; iter-&gt;to == bytecodeIndex)</span>
<span class="line-added">182         return true;</span>
<span class="line-added">183     return false;</span>
<span class="line-added">184 }</span>
<span class="line-added">185 </span>
186 ALWAYS_INLINE void JIT::addSlowCase(Jump jump)
187 {
<a name="23" id="anc23"></a><span class="line-modified">188     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
189 
<a name="24" id="anc24"></a><span class="line-modified">190     m_slowCases.append(SlowCaseEntry(jump, m_bytecodeIndex));</span>
191 }
192 
193 ALWAYS_INLINE void JIT::addSlowCase(const JumpList&amp; jumpList)
194 {
<a name="25" id="anc25"></a><span class="line-modified">195     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
196 
197     for (const Jump&amp; jump : jumpList.jumps())
<a name="26" id="anc26"></a><span class="line-modified">198         m_slowCases.append(SlowCaseEntry(jump, m_bytecodeIndex));</span>
199 }
200 
201 ALWAYS_INLINE void JIT::addSlowCase()
202 {
<a name="27" id="anc27"></a><span class="line-modified">203     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
204 
205     Jump emptyJump; // Doing it this way to make Windows happy.
<a name="28" id="anc28"></a><span class="line-modified">206     m_slowCases.append(SlowCaseEntry(emptyJump, m_bytecodeIndex));</span>
207 }
208 
209 ALWAYS_INLINE void JIT::addJump(Jump jump, int relativeOffset)
210 {
<a name="29" id="anc29"></a><span class="line-modified">211     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
212 
<a name="30" id="anc30"></a><span class="line-modified">213     m_jmpTable.append(JumpTable(jump, m_bytecodeIndex.offset() + relativeOffset));</span>
214 }
215 
216 ALWAYS_INLINE void JIT::addJump(const JumpList&amp; jumpList, int relativeOffset)
217 {
<a name="31" id="anc31"></a><span class="line-modified">218     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
219 
220     for (auto&amp; jump : jumpList.jumps())
221         addJump(jump, relativeOffset);
222 }
223 
224 ALWAYS_INLINE void JIT::emitJumpSlowToHot(Jump jump, int relativeOffset)
225 {
<a name="32" id="anc32"></a><span class="line-modified">226     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
227 
<a name="33" id="anc33"></a><span class="line-modified">228     jump.linkTo(m_labels[m_bytecodeIndex.offset() + relativeOffset], this);</span>
229 }
230 
231 #if ENABLE(SAMPLING_FLAGS)
232 ALWAYS_INLINE void JIT::setSamplingFlag(int32_t flag)
233 {
234     ASSERT(flag &gt;= 1);
235     ASSERT(flag &lt;= 32);
236     or32(TrustedImm32(1u &lt;&lt; (flag - 1)), AbsoluteAddress(SamplingFlags::addressOfFlags()));
237 }
238 
239 ALWAYS_INLINE void JIT::clearSamplingFlag(int32_t flag)
240 {
241     ASSERT(flag &gt;= 1);
242     ASSERT(flag &lt;= 32);
243     and32(TrustedImm32(~(1u &lt;&lt; (flag - 1))), AbsoluteAddress(SamplingFlags::addressOfFlags()));
244 }
245 #endif
246 
247 #if ENABLE(SAMPLING_COUNTERS)
248 ALWAYS_INLINE void JIT::emitCount(AbstractSamplingCounter&amp; counter, int32_t count)
249 {
250     add64(TrustedImm32(count), AbsoluteAddress(counter.addressOfCounter()));
251 }
252 #endif
253 
254 #if ENABLE(OPCODE_SAMPLING)
255 #if CPU(X86_64)
256 ALWAYS_INLINE void JIT::sampleInstruction(const Instruction* instruction, bool inHostFunction)
257 {
258     move(TrustedImmPtr(m_interpreter-&gt;sampler()-&gt;sampleSlot()), X86Registers::ecx);
259     storePtr(TrustedImmPtr(m_interpreter-&gt;sampler()-&gt;encodeSample(instruction, inHostFunction)), X86Registers::ecx);
260 }
261 #else
262 ALWAYS_INLINE void JIT::sampleInstruction(const Instruction* instruction, bool inHostFunction)
263 {
264     storePtr(TrustedImmPtr(m_interpreter-&gt;sampler()-&gt;encodeSample(instruction, inHostFunction)), m_interpreter-&gt;sampler()-&gt;sampleSlot());
265 }
266 #endif
267 #endif
268 
269 #if ENABLE(CODEBLOCK_SAMPLING)
270 #if CPU(X86_64)
271 ALWAYS_INLINE void JIT::sampleCodeBlock(CodeBlock* codeBlock)
272 {
273     move(TrustedImmPtr(m_interpreter-&gt;sampler()-&gt;codeBlockSlot()), X86Registers::ecx);
274     storePtr(TrustedImmPtr(codeBlock), X86Registers::ecx);
275 }
276 #else
277 ALWAYS_INLINE void JIT::sampleCodeBlock(CodeBlock* codeBlock)
278 {
279     storePtr(TrustedImmPtr(codeBlock), m_interpreter-&gt;sampler()-&gt;codeBlockSlot());
280 }
281 #endif
282 #endif
283 
<a name="34" id="anc34"></a><span class="line-modified">284 ALWAYS_INLINE bool JIT::isOperandConstantChar(VirtualRegister src)</span>
285 {
<a name="35" id="anc35"></a><span class="line-modified">286     return src.isConstant() &amp;&amp; getConstantOperand(src).isString() &amp;&amp; asString(getConstantOperand(src).asCell())-&gt;length() == 1;</span>
287 }
288 
289 inline void JIT::emitValueProfilingSite(ValueProfile&amp; valueProfile)
290 {
291     ASSERT(shouldEmitProfiling());
292 
293     const RegisterID value = regT0;
294 #if USE(JSVALUE32_64)
295     const RegisterID valueTag = regT1;
296 #endif
297 
298     // We&#39;re in a simple configuration: only one bucket, so we can just do a direct
299     // store.
300 #if USE(JSVALUE64)
301     store64(value, valueProfile.m_buckets);
302 #else
303     EncodedValueDescriptor* descriptor = bitwise_cast&lt;EncodedValueDescriptor*&gt;(valueProfile.m_buckets);
304     store32(value, &amp;descriptor-&gt;asBits.payload);
305     store32(valueTag, &amp;descriptor-&gt;asBits.tag);
306 #endif
307 }
308 
309 template&lt;typename Op&gt;
310 inline std::enable_if_t&lt;std::is_same&lt;decltype(Op::Metadata::m_profile), ValueProfile&gt;::value, void&gt; JIT::emitValueProfilingSiteIfProfiledOpcode(Op bytecode)
311 {
312     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
313 }
314 
315 inline void JIT::emitValueProfilingSiteIfProfiledOpcode(...) { }
316 
317 template&lt;typename Metadata&gt;
318 inline void JIT::emitValueProfilingSite(Metadata&amp; metadata)
319 {
320     if (!shouldEmitProfiling())
321         return;
322     emitValueProfilingSite(metadata.m_profile);
323 }
324 
325 inline void JIT::emitArrayProfilingSiteWithCell(RegisterID cell, RegisterID indexingType, ArrayProfile* arrayProfile)
326 {
327     if (shouldEmitProfiling()) {
328         load32(MacroAssembler::Address(cell, JSCell::structureIDOffset()), indexingType);
329         store32(indexingType, arrayProfile-&gt;addressOfLastSeenStructureID());
330     }
331 
332     load8(Address(cell, JSCell::indexingTypeAndMiscOffset()), indexingType);
333 }
334 
335 inline void JIT::emitArrayProfileStoreToHoleSpecialCase(ArrayProfile* arrayProfile)
336 {
337     store8(TrustedImm32(1), arrayProfile-&gt;addressOfMayStoreToHole());
338 }
339 
340 inline void JIT::emitArrayProfileOutOfBoundsSpecialCase(ArrayProfile* arrayProfile)
341 {
342     store8(TrustedImm32(1), arrayProfile-&gt;addressOfOutOfBounds());
343 }
344 
345 inline JITArrayMode JIT::chooseArrayMode(ArrayProfile* profile)
346 {
347     auto arrayProfileSaw = [] (ArrayModes arrayModes, IndexingType capability) {
348         return arrayModesIncludeIgnoringTypedArrays(arrayModes, capability);
349     };
350 
351     ConcurrentJSLocker locker(m_codeBlock-&gt;m_lock);
352     profile-&gt;computeUpdatedPrediction(locker, m_codeBlock);
353     ArrayModes arrayModes = profile-&gt;observedArrayModes(locker);
354     if (arrayProfileSaw(arrayModes, DoubleShape))
355         return JITDouble;
356     if (arrayProfileSaw(arrayModes, Int32Shape))
357         return JITInt32;
358     if (arrayProfileSaw(arrayModes, ArrayStorageShape))
359         return JITArrayStorage;
360     return JITContiguous;
361 }
362 
<a name="36" id="anc36"></a><span class="line-modified">363 ALWAYS_INLINE int32_t JIT::getOperandConstantInt(VirtualRegister src)</span>
364 {
365     return getConstantOperand(src).asInt32();
366 }
367 
<a name="37" id="anc37"></a><span class="line-modified">368 ALWAYS_INLINE double JIT::getOperandConstantDouble(VirtualRegister src)</span>
369 {
370     return getConstantOperand(src).asDouble();
371 }
372 
<a name="38" id="anc38"></a><span class="line-modified">373 ALWAYS_INLINE void JIT::emitInitRegister(VirtualRegister dst)</span>
374 {
375     storeTrustedValue(jsUndefined(), addressFor(dst));
376 }
377 
378 #if USE(JSVALUE32_64)
379 
<a name="39" id="anc39"></a><span class="line-modified">380 inline void JIT::emitLoadDouble(VirtualRegister reg, FPRegisterID value)</span>
381 {
<a name="40" id="anc40"></a><span class="line-modified">382     if (reg.isConstant()) {</span>
<span class="line-modified">383         WriteBarrier&lt;Unknown&gt;&amp; inConstantPool = m_codeBlock-&gt;constantRegister(reg);</span>
<span class="line-added">384         loadDouble(TrustedImmPtr(&amp;inConstantPool), value);</span>
<span class="line-added">385     } else</span>
<span class="line-added">386         loadDouble(addressFor(reg), value);</span>
<span class="line-added">387 }</span>
<span class="line-added">388 </span>
<span class="line-added">389 inline void JIT::emitLoadTag(VirtualRegister reg, RegisterID tag)</span>
<span class="line-added">390 {</span>
<span class="line-added">391     if (reg.isConstant()) {</span>
<span class="line-added">392         move(Imm32(getConstantOperand(reg).tag()), tag);</span>
393         return;
394     }
395 
<a name="41" id="anc41"></a><span class="line-modified">396     load32(tagFor(reg), tag);</span>
397 }
398 
<a name="42" id="anc42"></a><span class="line-modified">399 inline void JIT::emitLoadPayload(VirtualRegister reg, RegisterID payload)</span>
400 {
<a name="43" id="anc43"></a><span class="line-modified">401     if (reg.isConstant()) {</span>
<span class="line-modified">402         move(Imm32(getConstantOperand(reg).payload()), payload);</span>
403         return;
404     }
405 
<a name="44" id="anc44"></a><span class="line-modified">406     load32(payloadFor(reg), payload);</span>
407 }
408 
409 inline void JIT::emitLoad(const JSValue&amp; v, RegisterID tag, RegisterID payload)
410 {
411     move(Imm32(v.payload()), payload);
412     move(Imm32(v.tag()), tag);
413 }
414 
<a name="45" id="anc45"></a><span class="line-modified">415 ALWAYS_INLINE void JIT::emitGetVirtualRegister(VirtualRegister src, JSValueRegs dst)</span>
416 {
417     emitLoad(src, dst.tagGPR(), dst.payloadGPR());
418 }
419 
<a name="46" id="anc46"></a><span class="line-modified">420 ALWAYS_INLINE void JIT::emitPutVirtualRegister(VirtualRegister dst, JSValueRegs from)</span>
421 {
422     emitStore(dst, from.tagGPR(), from.payloadGPR());
423 }
424 
<a name="47" id="anc47"></a><span class="line-modified">425 inline void JIT::emitLoad(VirtualRegister reg, RegisterID tag, RegisterID payload, RegisterID base)</span>
426 {
427     RELEASE_ASSERT(tag != payload);
428 
429     if (base == callFrameRegister) {
430         RELEASE_ASSERT(payload != base);
<a name="48" id="anc48"></a><span class="line-modified">431         emitLoadPayload(reg, payload);</span>
<span class="line-modified">432         emitLoadTag(reg, tag);</span>
433         return;
434     }
435 
<a name="49" id="anc49"></a>
436     if (payload == base) { // avoid stomping base
<a name="50" id="anc50"></a><span class="line-modified">437         load32(tagFor(reg, base), tag);</span>
<span class="line-modified">438         load32(payloadFor(reg, base), payload);</span>
439         return;
440     }
441 
<a name="51" id="anc51"></a><span class="line-modified">442     load32(payloadFor(reg, base), payload);</span>
<span class="line-modified">443     load32(tagFor(reg, base), tag);</span>















444 }
445 
<a name="52" id="anc52"></a><span class="line-modified">446 inline void JIT::emitLoad2(VirtualRegister reg1, RegisterID tag1, RegisterID payload1, VirtualRegister reg2, RegisterID tag2, RegisterID payload2)</span>
447 {
<a name="53" id="anc53"></a><span class="line-modified">448     emitLoad(reg2, tag2, payload2);</span>
<span class="line-modified">449     emitLoad(reg1, tag1, payload1);</span>




450 }
451 
<a name="54" id="anc54"></a><span class="line-modified">452 inline void JIT::emitStore(VirtualRegister reg, RegisterID tag, RegisterID payload, RegisterID base)</span>
453 {
<a name="55" id="anc55"></a><span class="line-modified">454     store32(payload, payloadFor(reg, base));</span>
<span class="line-modified">455     store32(tag, tagFor(reg, base));</span>

456 }
457 
<a name="56" id="anc56"></a><span class="line-modified">458 inline void JIT::emitStoreInt32(VirtualRegister reg, RegisterID payload, bool indexIsInt32)</span>
459 {
<a name="57" id="anc57"></a><span class="line-modified">460     store32(payload, payloadFor(reg));</span>
461     if (!indexIsInt32)
<a name="58" id="anc58"></a><span class="line-modified">462         store32(TrustedImm32(JSValue::Int32Tag), tagFor(reg));</span>
463 }
464 
<a name="59" id="anc59"></a><span class="line-modified">465 inline void JIT::emitStoreInt32(VirtualRegister reg, TrustedImm32 payload, bool indexIsInt32)</span>
466 {
<a name="60" id="anc60"></a><span class="line-modified">467     store32(payload, payloadFor(reg));</span>
468     if (!indexIsInt32)
<a name="61" id="anc61"></a><span class="line-modified">469         store32(TrustedImm32(JSValue::Int32Tag), tagFor(reg));</span>
470 }
471 
<a name="62" id="anc62"></a><span class="line-modified">472 inline void JIT::emitStoreCell(VirtualRegister reg, RegisterID payload, bool indexIsCell)</span>
473 {
<a name="63" id="anc63"></a><span class="line-modified">474     store32(payload, payloadFor(reg));</span>
475     if (!indexIsCell)
<a name="64" id="anc64"></a><span class="line-modified">476         store32(TrustedImm32(JSValue::CellTag), tagFor(reg));</span>
477 }
478 
<a name="65" id="anc65"></a><span class="line-modified">479 inline void JIT::emitStoreBool(VirtualRegister reg, RegisterID payload, bool indexIsBool)</span>
480 {
<a name="66" id="anc66"></a><span class="line-modified">481     store32(payload, payloadFor(reg));</span>
482     if (!indexIsBool)
<a name="67" id="anc67"></a><span class="line-modified">483         store32(TrustedImm32(JSValue::BooleanTag), tagFor(reg));</span>
484 }
485 
<a name="68" id="anc68"></a><span class="line-modified">486 inline void JIT::emitStoreDouble(VirtualRegister reg, FPRegisterID value)</span>
487 {
<a name="69" id="anc69"></a><span class="line-modified">488     storeDouble(value, addressFor(reg));</span>
489 }
490 
<a name="70" id="anc70"></a><span class="line-modified">491 inline void JIT::emitStore(VirtualRegister reg, const JSValue constant, RegisterID base)</span>
492 {
<a name="71" id="anc71"></a><span class="line-modified">493     store32(Imm32(constant.payload()), payloadFor(reg, base));</span>
<span class="line-modified">494     store32(Imm32(constant.tag()), tagFor(reg, base));</span>

495 }
496 
<a name="72" id="anc72"></a><span class="line-modified">497 inline void JIT::emitJumpSlowCaseIfNotJSCell(VirtualRegister reg)</span>
498 {
<a name="73" id="anc73"></a><span class="line-modified">499     if (!m_codeBlock-&gt;isKnownNotImmediate(reg)) {</span>
<span class="line-modified">500         if (reg.isConstant())</span>
501             addSlowCase(jump());
502         else
<a name="74" id="anc74"></a><span class="line-modified">503             addSlowCase(emitJumpIfNotJSCell(reg));</span>
504     }
505 }
506 
<a name="75" id="anc75"></a><span class="line-modified">507 inline void JIT::emitJumpSlowCaseIfNotJSCell(VirtualRegister reg, RegisterID tag)</span>
508 {
<a name="76" id="anc76"></a><span class="line-modified">509     if (!m_codeBlock-&gt;isKnownNotImmediate(reg)) {</span>
<span class="line-modified">510         if (reg.isConstant())</span>
511             addSlowCase(jump());
512         else
513             addSlowCase(branchIfNotCell(tag));
514     }
515 }
516 
<a name="77" id="anc77"></a><span class="line-modified">517 ALWAYS_INLINE bool JIT::isOperandConstantInt(VirtualRegister src)</span>
518 {
<a name="78" id="anc78"></a><span class="line-modified">519     return src.isConstant() &amp;&amp; getConstantOperand(src).isInt32();</span>
520 }
521 
<a name="79" id="anc79"></a><span class="line-modified">522 ALWAYS_INLINE bool JIT::getOperandConstantInt(VirtualRegister op1, VirtualRegister op2, VirtualRegister&amp; op, int32_t&amp; constant)</span>
523 {
524     if (isOperandConstantInt(op1)) {
525         constant = getConstantOperand(op1).asInt32();
526         op = op2;
527         return true;
528     }
529 
530     if (isOperandConstantInt(op2)) {
531         constant = getConstantOperand(op2).asInt32();
532         op = op1;
533         return true;
534     }
535 
536     return false;
537 }
538 
539 #else // USE(JSVALUE32_64)
540 
541 // get arg puts an arg from the SF register array into a h/w register
<a name="80" id="anc80"></a><span class="line-modified">542 ALWAYS_INLINE void JIT::emitGetVirtualRegister(VirtualRegister src, RegisterID dst)</span>
543 {
<a name="81" id="anc81"></a><span class="line-modified">544     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
545 
<a name="82" id="anc82"></a><span class="line-modified">546     if (src.isConstant()) {</span>
547         JSValue value = m_codeBlock-&gt;getConstant(src);
548         if (!value.isNumber())
549             move(TrustedImm64(JSValue::encode(value)), dst);
550         else
551             move(Imm64(JSValue::encode(value)), dst);
552         return;
553     }
554 
555     load64(addressFor(src), dst);
556 }
557 
<a name="83" id="anc83"></a><span class="line-modified">558 ALWAYS_INLINE void JIT::emitGetVirtualRegister(VirtualRegister src, JSValueRegs dst)</span>
559 {
560     emitGetVirtualRegister(src, dst.payloadGPR());
561 }
562 
<a name="84" id="anc84"></a><span class="line-modified">563 ALWAYS_INLINE void JIT::emitGetVirtualRegisters(VirtualRegister src1, RegisterID dst1, VirtualRegister src2, RegisterID dst2)</span>





564 {
565     emitGetVirtualRegister(src1, dst1);
566     emitGetVirtualRegister(src2, dst2);
567 }
568 
<a name="85" id="anc85"></a><span class="line-modified">569 ALWAYS_INLINE bool JIT::isOperandConstantInt(VirtualRegister src)</span>





570 {
<a name="86" id="anc86"></a><span class="line-modified">571     return src.isConstant() &amp;&amp; getConstantOperand(src).isInt32();</span>
572 }
573 
<a name="87" id="anc87"></a><span class="line-modified">574 ALWAYS_INLINE void JIT::emitPutVirtualRegister(VirtualRegister dst, RegisterID from)</span>
575 {
576     store64(from, addressFor(dst));
577 }
578 
<a name="88" id="anc88"></a><span class="line-modified">579 ALWAYS_INLINE void JIT::emitPutVirtualRegister(VirtualRegister dst, JSValueRegs from)</span>
580 {
581     emitPutVirtualRegister(dst, from.payloadGPR());
582 }
583 
<a name="89" id="anc89"></a>




584 ALWAYS_INLINE JIT::Jump JIT::emitJumpIfBothJSCells(RegisterID reg1, RegisterID reg2, RegisterID scratch)
585 {
586     move(reg1, scratch);
587     or64(reg2, scratch);
588     return branchIfCell(scratch);
589 }
590 
591 ALWAYS_INLINE void JIT::emitJumpSlowCaseIfJSCell(RegisterID reg)
592 {
593     addSlowCase(branchIfCell(reg));
594 }
595 
596 ALWAYS_INLINE void JIT::emitJumpSlowCaseIfNotJSCell(RegisterID reg)
597 {
598     addSlowCase(branchIfNotCell(reg));
599 }
600 
<a name="90" id="anc90"></a><span class="line-modified">601 ALWAYS_INLINE void JIT::emitJumpSlowCaseIfNotJSCell(RegisterID reg, VirtualRegister vReg)</span>
602 {
603     if (!m_codeBlock-&gt;isKnownNotImmediate(vReg))
604         emitJumpSlowCaseIfNotJSCell(reg);
605 }
606 
<a name="91" id="anc91"></a>

















607 ALWAYS_INLINE JIT::PatchableJump JIT::emitPatchableJumpIfNotInt(RegisterID reg)
608 {
<a name="92" id="anc92"></a><span class="line-modified">609     return patchableBranch64(Below, reg, numberTagRegister);</span>
610 }
611 
612 ALWAYS_INLINE JIT::Jump JIT::emitJumpIfNotInt(RegisterID reg1, RegisterID reg2, RegisterID scratch)
613 {
614     move(reg1, scratch);
615     and64(reg2, scratch);
616     return branchIfNotInt32(scratch);
617 }
618 
619 ALWAYS_INLINE void JIT::emitJumpSlowCaseIfNotInt(RegisterID reg)
620 {
621     addSlowCase(branchIfNotInt32(reg));
622 }
623 
624 ALWAYS_INLINE void JIT::emitJumpSlowCaseIfNotInt(RegisterID reg1, RegisterID reg2, RegisterID scratch)
625 {
626     addSlowCase(emitJumpIfNotInt(reg1, reg2, scratch));
627 }
628 
629 ALWAYS_INLINE void JIT::emitJumpSlowCaseIfNotNumber(RegisterID reg)
630 {
631     addSlowCase(branchIfNotNumber(reg));
632 }
633 
634 #endif // USE(JSVALUE32_64)
635 
636 ALWAYS_INLINE int JIT::jumpTarget(const Instruction* instruction, int target)
637 {
638     if (target)
639         return target;
640     return m_codeBlock-&gt;outOfLineJumpOffset(instruction);
641 }
642 
643 ALWAYS_INLINE GetPutInfo JIT::copiedGetPutInfo(OpPutToScope bytecode)
644 {
645     unsigned key = bytecode.m_metadataID + 1; // HashMap doesn&#39;t like 0 as a key
646     auto iterator = m_copiedGetPutInfos.find(key);
647     if (iterator != m_copiedGetPutInfos.end())
648         return GetPutInfo(iterator-&gt;value);
649     GetPutInfo getPutInfo = bytecode.metadata(m_codeBlock).m_getPutInfo;
650     m_copiedGetPutInfos.add(key, getPutInfo.operand());
651     return getPutInfo;
652 }
653 
654 template&lt;typename BinaryOp&gt;
<a name="93" id="anc93"></a><span class="line-modified">655 ALWAYS_INLINE BinaryArithProfile JIT::copiedArithProfile(BinaryOp bytecode)</span>
656 {
<a name="94" id="anc94"></a><span class="line-modified">657     uint64_t key = (static_cast&lt;uint64_t&gt;(BinaryOp::opcodeID) + 1) &lt;&lt; 32 | static_cast&lt;uint64_t&gt;(bytecode.m_metadataID);</span>
658     auto iterator = m_copiedArithProfiles.find(key);
659     if (iterator != m_copiedArithProfiles.end())
660         return iterator-&gt;value;
<a name="95" id="anc95"></a><span class="line-modified">661     BinaryArithProfile arithProfile = bytecode.metadata(m_codeBlock).m_arithProfile;</span>
662     m_copiedArithProfiles.add(key, arithProfile);
663     return arithProfile;
664 }
665 
666 } // namespace JSC
667 
668 #endif // ENABLE(JIT)
<a name="96" id="anc96"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="96" type="hidden" />
</body>
</html>