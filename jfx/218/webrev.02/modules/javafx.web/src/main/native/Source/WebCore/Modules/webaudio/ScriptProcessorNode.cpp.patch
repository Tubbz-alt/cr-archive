diff a/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/ScriptProcessorNode.cpp b/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/ScriptProcessorNode.cpp
--- a/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/ScriptProcessorNode.cpp
+++ b/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/ScriptProcessorNode.cpp
@@ -49,19 +49,19 @@
     return adoptRef(*new ScriptProcessorNode(context, sampleRate, bufferSize, numberOfInputChannels, numberOfOutputChannels));
 }
 
 ScriptProcessorNode::ScriptProcessorNode(AudioContext& context, float sampleRate, size_t bufferSize, unsigned numberOfInputChannels, unsigned numberOfOutputChannels)
     : AudioNode(context, sampleRate)
+    , ActiveDOMObject(context.scriptExecutionContext())
     , m_doubleBufferIndex(0)
     , m_doubleBufferIndexForEvent(0)
     , m_bufferSize(bufferSize)
     , m_bufferReadWriteIndex(0)
     , m_isRequestOutstanding(false)
     , m_numberOfInputChannels(numberOfInputChannels)
     , m_numberOfOutputChannels(numberOfOutputChannels)
     , m_internalInputBus(AudioBus::create(numberOfInputChannels, AudioNode::ProcessingSizeInFrames, false))
-    , m_hasAudioProcessListener(false)
 {
     // Regardless of the allowed buffer sizes, we still need to process at the granularity of the AudioNode.
     if (m_bufferSize < AudioNode::ProcessingSizeInFrames)
         m_bufferSize = AudioNode::ProcessingSizeInFrames;
 
@@ -70,14 +70,17 @@
     setNodeType(NodeTypeJavaScript);
     addInput(makeUnique<AudioNodeInput>(this));
     addOutput(makeUnique<AudioNodeOutput>(this, numberOfOutputChannels));
 
     initialize();
+    suspendIfNeeded();
+    m_pendingActivity = makePendingActivity(*this);
 }
 
 ScriptProcessorNode::~ScriptProcessorNode()
 {
+    ASSERT(!hasPendingActivity());
     uninitialize();
 }
 
 void ScriptProcessorNode::initialize()
 {
@@ -108,22 +111,25 @@
     m_outputBuffers.clear();
 
     AudioNode::uninitialize();
 }
 
+void ScriptProcessorNode::didBecomeMarkedForDeletion()
+{
+    ASSERT(context().isGraphOwner());
+    m_pendingActivity = nullptr;
+    ASSERT(!hasPendingActivity());
+}
+
 void ScriptProcessorNode::process(size_t framesToProcess)
 {
     // Discussion about inputs and outputs:
     // As in other AudioNodes, ScriptProcessorNode uses an AudioBus for its input and output (see inputBus and outputBus below).
     // Additionally, there is a double-buffering for input and output which is exposed directly to JavaScript (see inputBuffer and outputBuffer below).
     // This node is the producer for inputBuffer and the consumer for outputBuffer.
     // The JavaScript code is the consumer of inputBuffer and the producer for outputBuffer.
 
-    // Check if audioprocess listener is set.
-    if (!m_hasAudioProcessListener)
-        return;
-
     // Get input and output busses.
     AudioBus* inputBus = this->input(0)->bus();
     AudioBus* outputBus = this->output(0)->bus();
 
     // Get input and output buffers. We double-buffer both the input and output sides.
@@ -190,13 +196,10 @@
             // Fire the event on the main thread, not this one (which is the realtime audio thread).
             m_doubleBufferIndexForEvent = m_doubleBufferIndex;
             m_isRequestOutstanding = true;
 
             callOnMainThread([this] {
-                if (!m_hasAudioProcessListener)
-                    return;
-
                 fireProcessEvent();
 
                 // De-reference to match the ref() call in process().
                 deref();
             });
@@ -254,30 +257,8 @@
 double ScriptProcessorNode::latencyTime() const
 {
     return std::numeric_limits<double>::infinity();
 }
 
-bool ScriptProcessorNode::addEventListener(const AtomString& eventType, Ref<EventListener>&& listener, const AddEventListenerOptions& options)
-{
-    bool success = AudioNode::addEventListener(eventType, WTFMove(listener), options);
-    if (success && eventType == eventNames().audioprocessEvent)
-        m_hasAudioProcessListener = hasEventListeners(eventNames().audioprocessEvent);
-    return success;
-}
-
-bool ScriptProcessorNode::removeEventListener(const AtomString& eventType, EventListener& listener, const ListenerOptions& options)
-{
-    bool success = AudioNode::removeEventListener(eventType, listener, options);
-    if (success && eventType == eventNames().audioprocessEvent)
-        m_hasAudioProcessListener = hasEventListeners(eventNames().audioprocessEvent);
-    return success;
-}
-
-void ScriptProcessorNode::removeAllEventListeners()
-{
-    m_hasAudioProcessListener = false;
-    AudioNode::removeAllEventListeners();
-}
-
 } // namespace WebCore
 
 #endif // ENABLE(WEB_AUDIO)
