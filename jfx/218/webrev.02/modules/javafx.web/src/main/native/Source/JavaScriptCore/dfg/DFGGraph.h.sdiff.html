<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGGraph.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="DFGGraph.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGHeapLocation.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGGraph.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  35 #include &quot;DFGFrozenValue.h&quot;
  36 #include &quot;DFGNode.h&quot;
  37 #include &quot;DFGPlan.h&quot;
  38 #include &quot;DFGPropertyTypeKey.h&quot;
  39 #include &quot;DFGScannable.h&quot;
  40 #include &quot;FullBytecodeLiveness.h&quot;
  41 #include &quot;MethodOfGettingAValueProfile.h&quot;
  42 #include &lt;wtf/BitVector.h&gt;
  43 #include &lt;wtf/HashMap.h&gt;
  44 #include &lt;wtf/Vector.h&gt;
  45 #include &lt;wtf/StdLibExtras.h&gt;
  46 #include &lt;wtf/StdUnorderedMap.h&gt;
  47 
  48 namespace WTF {
  49 template &lt;typename T&gt; class SingleRootGraph;
  50 }
  51 
  52 namespace JSC {
  53 
  54 class CodeBlock;
<span class="line-modified">  55 class ExecState;</span>
  56 
  57 namespace DFG {
  58 
  59 class BackwardsCFG;
  60 class BackwardsDominators;
  61 class CFG;
  62 class CPSCFG;
  63 class ControlEquivalenceAnalysis;
  64 template &lt;typename T&gt; class Dominators;
  65 template &lt;typename T&gt; class NaturalLoops;
  66 class FlowIndexing;
  67 template&lt;typename&gt; class FlowMap;
  68 
  69 using ArgumentsVector = Vector&lt;Node*, 8&gt;;
  70 
  71 using SSACFG = CFG;
  72 using CPSDominators = Dominators&lt;CPSCFG&gt;;
  73 using SSADominators = Dominators&lt;SSACFG&gt;;
  74 using CPSNaturalLoops = NaturalLoops&lt;CPSCFG&gt;;
  75 using SSANaturalLoops = NaturalLoops&lt;SSACFG&gt;;
</pre>
<hr />
<pre>
 424 
 425     RegisteredStructureSet* addStructureSet(const RegisteredStructureSet&amp; structureSet)
 426     {
 427         m_structureSets.append();
 428         RegisteredStructureSet* result = &amp;m_structureSets.last();
 429 
 430         for (RegisteredStructure structure : structureSet)
 431             result-&gt;add(structure);
 432 
 433         return result;
 434     }
 435 
 436     JSGlobalObject* globalObjectFor(CodeOrigin codeOrigin)
 437     {
 438         return m_codeBlock-&gt;globalObjectFor(codeOrigin);
 439     }
 440 
 441     JSObject* globalThisObjectFor(CodeOrigin codeOrigin)
 442     {
 443         JSGlobalObject* object = globalObjectFor(codeOrigin);
<span class="line-modified"> 444         return jsCast&lt;JSObject*&gt;(object-&gt;methodTable(m_vm)-&gt;toThis(object, object-&gt;globalExec(), NotStrictMode));</span>
 445     }
 446 
 447     ScriptExecutable* executableFor(InlineCallFrame* inlineCallFrame)
 448     {
 449         if (!inlineCallFrame)
 450             return m_codeBlock-&gt;ownerExecutable();
 451 
 452         return inlineCallFrame-&gt;baselineCodeBlock-&gt;ownerExecutable();
 453     }
 454 
 455     ScriptExecutable* executableFor(const CodeOrigin&amp; codeOrigin)
 456     {
 457         return executableFor(codeOrigin.inlineCallFrame());
 458     }
 459 
 460     CodeBlock* baselineCodeBlockFor(InlineCallFrame* inlineCallFrame)
 461     {
 462         if (!inlineCallFrame)
 463             return m_profiledBlock;
 464         return baselineCodeBlockForInlineCallFrame(inlineCallFrame);
</pre>
<hr />
<pre>
 823     bool watchCondition(const ObjectPropertyCondition&amp;);
 824     bool watchConditions(const ObjectPropertyConditionSet&amp;);
 825 
 826     bool watchGlobalProperty(JSGlobalObject*, unsigned identifierNumber);
 827 
 828     // Checks if it&#39;s known that loading from the given object at the given offset is fine. This is
 829     // computed by tracking which conditions we track with watchCondition().
 830     bool isSafeToLoad(JSObject* base, PropertyOffset);
 831 
 832     // This uses either constant property inference or property type inference to derive a good abstract
 833     // value for some property accessed with the given abstract value base.
 834     AbstractValue inferredValueForProperty(
 835         const AbstractValue&amp; base, PropertyOffset, StructureClobberState);
 836 
 837     FullBytecodeLiveness&amp; livenessFor(CodeBlock*);
 838     FullBytecodeLiveness&amp; livenessFor(InlineCallFrame*);
 839 
 840     // Quickly query if a single local is live at the given point. This is faster than calling
 841     // forAllLiveInBytecode() if you will only query one local. But, if you want to know all of the
 842     // locals live, then calling this for each local is much slower than forAllLiveInBytecode().
<span class="line-modified"> 843     bool isLiveInBytecode(VirtualRegister, CodeOrigin);</span>
 844 
<span class="line-modified"> 845     // Quickly get all of the non-argument locals live at the given point. This doesn&#39;t give you</span>
 846     // any arguments because those are all presumed live. You can call forAllLiveInBytecode() to
 847     // also get the arguments. This is much faster than calling isLiveInBytecode() for each local.
 848     template&lt;typename Functor&gt;
<span class="line-modified"> 849     void forAllLocalsLiveInBytecode(CodeOrigin codeOrigin, const Functor&amp; functor)</span>
 850     {
 851         // Support for not redundantly reporting arguments. Necessary because in case of a varargs
 852         // call, only the callee knows that arguments are live while in the case of a non-varargs
 853         // call, both callee and caller will see the variables live.
 854         VirtualRegister exclusionStart;
 855         VirtualRegister exclusionEnd;
 856 
 857         CodeOrigin* codeOriginPtr = &amp;codeOrigin;
 858 

 859         for (;;) {
 860             InlineCallFrame* inlineCallFrame = codeOriginPtr-&gt;inlineCallFrame();
 861             VirtualRegister stackOffset(inlineCallFrame ? inlineCallFrame-&gt;stackOffset : 0);
 862 
 863             if (inlineCallFrame) {
 864                 if (inlineCallFrame-&gt;isClosureCall)
 865                     functor(stackOffset + CallFrameSlot::callee);
 866                 if (inlineCallFrame-&gt;isVarargs())
<span class="line-modified"> 867                     functor(stackOffset + CallFrameSlot::argumentCount);</span>
 868             }
 869 
 870             CodeBlock* codeBlock = baselineCodeBlockFor(inlineCallFrame);
 871             FullBytecodeLiveness&amp; fullLiveness = livenessFor(codeBlock);
<span class="line-modified"> 872             const FastBitVector&amp; liveness = fullLiveness.getLiveness(codeOriginPtr-&gt;bytecodeIndex());</span>
 873             for (unsigned relativeLocal = codeBlock-&gt;numCalleeLocals(); relativeLocal--;) {
 874                 VirtualRegister reg = stackOffset + virtualRegisterForLocal(relativeLocal);
 875 
 876                 // Don&#39;t report if our callee already reported.
 877                 if (reg &gt;= exclusionStart &amp;&amp; reg &lt; exclusionEnd)
 878                     continue;
 879 
<span class="line-modified"> 880                 if (liveness[relativeLocal])</span>
 881                     functor(reg);
 882             }
 883 








 884             if (!inlineCallFrame)
 885                 break;
 886 
 887             // Arguments are always live. This would be redundant if it wasn&#39;t for our
 888             // op_call_varargs inlining. See the comment above.
 889             exclusionStart = stackOffset + CallFrame::argumentOffsetIncludingThis(0);
 890             exclusionEnd = stackOffset + CallFrame::argumentOffsetIncludingThis(inlineCallFrame-&gt;argumentsWithFixup.size());
 891 
 892             // We will always have a &quot;this&quot; argument and exclusionStart should be a smaller stack
 893             // offset than exclusionEnd.
 894             ASSERT(exclusionStart &lt; exclusionEnd);
 895 
 896             for (VirtualRegister reg = exclusionStart; reg &lt; exclusionEnd; reg += 1)
 897                 functor(reg);
 898 
 899             // We need to handle tail callers because we may decide to exit to the
 900             // the return bytecode following the tail call.
 901             codeOriginPtr = &amp;inlineCallFrame-&gt;directCaller;

 902         }
 903     }
 904 
<span class="line-modified"> 905     // Get a BitVector of all of the non-argument locals live right now. This is mostly useful if</span>
 906     // you want to compare two sets of live locals from two different CodeOrigins.
<span class="line-modified"> 907     BitVector localsLiveInBytecode(CodeOrigin);</span>






























 908 
<span class="line-modified"> 909     // Tells you all of the arguments and locals live at the given CodeOrigin. This is a small</span>
<span class="line-modified"> 910     // extension to forAllLocalsLiveInBytecode(), since all arguments are always presumed live.</span>
 911     template&lt;typename Functor&gt;
 912     void forAllLiveInBytecode(CodeOrigin codeOrigin, const Functor&amp; functor)
 913     {
<span class="line-modified"> 914         forAllLocalsLiveInBytecode(codeOrigin, functor);</span>
 915 
 916         // Report all arguments as being live.
 917         for (unsigned argument = block(0)-&gt;variablesAtHead.numberOfArguments(); argument--;)
<span class="line-modified"> 918             functor(virtualRegisterForArgument(argument));</span>
 919     }
 920 
 921     BytecodeKills&amp; killsFor(CodeBlock*);
 922     BytecodeKills&amp; killsFor(InlineCallFrame*);
 923 
 924     static unsigned parameterSlotsForArgCount(unsigned);
 925 
 926     unsigned frameRegisterCount();
 927     unsigned stackPointerOffset();
 928     unsigned requiredRegisterCountForExit();
 929     unsigned requiredRegisterCountForExecutionAndExit();
 930 
 931     JSValue tryGetConstantProperty(JSValue base, const RegisteredStructureSet&amp;, PropertyOffset);
 932     JSValue tryGetConstantProperty(JSValue base, Structure*, PropertyOffset);
 933     JSValue tryGetConstantProperty(JSValue base, const StructureAbstractValue&amp;, PropertyOffset);
 934     JSValue tryGetConstantProperty(const AbstractValue&amp;, PropertyOffset);
 935 
 936     JSValue tryGetConstantClosureVar(JSValue base, ScopeOffset);
 937     JSValue tryGetConstantClosureVar(const AbstractValue&amp;, ScopeOffset);
 938     JSValue tryGetConstantClosureVar(Node*, ScopeOffset);
</pre>
<hr />
<pre>
1065     Bag&lt;CallVarargsData&gt; m_callVarargsData;
1066     Bag&lt;LoadVarargsData&gt; m_loadVarargsData;
1067     Bag&lt;StackAccessData&gt; m_stackAccessData;
1068     Bag&lt;LazyJSValue&gt; m_lazyJSValues;
1069     Bag&lt;CallDOMGetterData&gt; m_callDOMGetterData;
1070     Bag&lt;BitVector&gt; m_bitVectors;
1071     Vector&lt;InlineVariableData, 4&gt; m_inlineVariableData;
1072     HashMap&lt;CodeBlock*, std::unique_ptr&lt;FullBytecodeLiveness&gt;&gt; m_bytecodeLiveness;
1073     HashMap&lt;CodeBlock*, std::unique_ptr&lt;BytecodeKills&gt;&gt; m_bytecodeKills;
1074     HashSet&lt;std::pair&lt;JSObject*, PropertyOffset&gt;&gt; m_safeToLoad;
1075     Vector&lt;Ref&lt;Snippet&gt;&gt; m_domJITSnippets;
1076     std::unique_ptr&lt;CPSDominators&gt; m_cpsDominators;
1077     std::unique_ptr&lt;SSADominators&gt; m_ssaDominators;
1078     std::unique_ptr&lt;CPSNaturalLoops&gt; m_cpsNaturalLoops;
1079     std::unique_ptr&lt;SSANaturalLoops&gt; m_ssaNaturalLoops;
1080     std::unique_ptr&lt;SSACFG&gt; m_ssaCFG;
1081     std::unique_ptr&lt;CPSCFG&gt; m_cpsCFG;
1082     std::unique_ptr&lt;BackwardsCFG&gt; m_backwardsCFG;
1083     std::unique_ptr&lt;BackwardsDominators&gt; m_backwardsDominators;
1084     std::unique_ptr&lt;ControlEquivalenceAnalysis&gt; m_controlEquivalenceAnalysis;

1085     unsigned m_localVars;
1086     unsigned m_nextMachineLocal;
1087     unsigned m_parameterSlots;
1088 
1089     // This is the number of logical entrypoints that we&#39;re compiling. This is only used
1090     // in SSA. Each EntrySwitch node must have m_numberOfEntrypoints cases. Note, this is
1091     // not the same as m_roots.size(). m_roots.size() represents the number of roots in
1092     // the CFG. In SSA, m_roots.size() == 1 even if we&#39;re compiling more than one entrypoint.
1093     unsigned m_numberOfEntrypoints { UINT_MAX };
1094 
1095     // This maps an entrypoint index to a particular op_catch bytecode offset. By convention,
1096     // it&#39;ll never have zero as a key because we use zero to mean the op_enter entrypoint.
<span class="line-modified">1097     HashMap&lt;unsigned, unsigned&gt; m_entrypointIndexToCatchBytecodeOffset;</span>
1098 
1099     HashSet&lt;String&gt; m_localStrings;
1100     HashMap&lt;const StringImpl*, String&gt; m_copiedStrings;
1101 
1102 #if USE(JSVALUE32_64)
1103     StdUnorderedMap&lt;int64_t, double*&gt; m_doubleConstantsMap;
1104     std::unique_ptr&lt;Bag&lt;double&gt;&gt; m_doubleConstants;
1105 #endif
1106 
1107     OptimizationFixpointState m_fixpointState;
1108     StructureRegistrationState m_structureRegistrationState;
1109     GraphForm m_form;
1110     UnificationState m_unificationState;
1111     PlanStage m_planStage { PlanStage::Initial };
1112     RefCountState m_refCountState;
1113     bool m_hasDebuggerEnabled;
1114     bool m_hasExceptionHandlers { false };
1115     bool m_isInSSAConversion { false };
1116     Optional&lt;uint32_t&gt; m_maxLocalsForCatchOSREntry;
1117     std::unique_ptr&lt;FlowIndexing&gt; m_indexingCache;
1118     std::unique_ptr&lt;FlowMap&lt;AbstractValue&gt;&gt; m_abstractValuesCache;
1119     Bag&lt;EntrySwitchData&gt; m_entrySwitchData;
1120 
1121     RegisteredStructure stringStructure;
1122     RegisteredStructure symbolStructure;
1123 


1124 private:
1125     bool isStringPrototypeMethodSane(JSGlobalObject*, UniquedStringImpl*);
1126 
1127     void handleSuccessor(Vector&lt;BasicBlock*, 16&gt;&amp; worklist, BasicBlock*, BasicBlock* successor);
1128 
1129     AddSpeculationMode addImmediateShouldSpeculateInt32(Node* add, bool variableShouldSpeculateInt32, Node* operand, Node*immediate, RareCaseProfilingSource source)
1130     {
1131         ASSERT(immediate-&gt;hasConstant());
1132 
1133         JSValue immediateValue = immediate-&gt;asJSValue();
1134         if (!immediateValue.isNumber() &amp;&amp; !immediateValue.isBoolean())
1135             return DontSpeculateInt32;
1136 
1137         if (!variableShouldSpeculateInt32)
1138             return DontSpeculateInt32;
1139 
1140         // Integer constants can be typed Double if they are written like a double in the source code (e.g. 42.0).
1141         // In that case, we stay conservative unless the other operand was explicitly typed as integer.
1142         NodeFlags operandResultType = operand-&gt;result();
1143         if (operandResultType != NodeResultInt32 &amp;&amp; immediateValue.isDouble())
</pre>
</td>
<td>
<hr />
<pre>
  35 #include &quot;DFGFrozenValue.h&quot;
  36 #include &quot;DFGNode.h&quot;
  37 #include &quot;DFGPlan.h&quot;
  38 #include &quot;DFGPropertyTypeKey.h&quot;
  39 #include &quot;DFGScannable.h&quot;
  40 #include &quot;FullBytecodeLiveness.h&quot;
  41 #include &quot;MethodOfGettingAValueProfile.h&quot;
  42 #include &lt;wtf/BitVector.h&gt;
  43 #include &lt;wtf/HashMap.h&gt;
  44 #include &lt;wtf/Vector.h&gt;
  45 #include &lt;wtf/StdLibExtras.h&gt;
  46 #include &lt;wtf/StdUnorderedMap.h&gt;
  47 
  48 namespace WTF {
  49 template &lt;typename T&gt; class SingleRootGraph;
  50 }
  51 
  52 namespace JSC {
  53 
  54 class CodeBlock;
<span class="line-modified">  55 class CallFrame;</span>
  56 
  57 namespace DFG {
  58 
  59 class BackwardsCFG;
  60 class BackwardsDominators;
  61 class CFG;
  62 class CPSCFG;
  63 class ControlEquivalenceAnalysis;
  64 template &lt;typename T&gt; class Dominators;
  65 template &lt;typename T&gt; class NaturalLoops;
  66 class FlowIndexing;
  67 template&lt;typename&gt; class FlowMap;
  68 
  69 using ArgumentsVector = Vector&lt;Node*, 8&gt;;
  70 
  71 using SSACFG = CFG;
  72 using CPSDominators = Dominators&lt;CPSCFG&gt;;
  73 using SSADominators = Dominators&lt;SSACFG&gt;;
  74 using CPSNaturalLoops = NaturalLoops&lt;CPSCFG&gt;;
  75 using SSANaturalLoops = NaturalLoops&lt;SSACFG&gt;;
</pre>
<hr />
<pre>
 424 
 425     RegisteredStructureSet* addStructureSet(const RegisteredStructureSet&amp; structureSet)
 426     {
 427         m_structureSets.append();
 428         RegisteredStructureSet* result = &amp;m_structureSets.last();
 429 
 430         for (RegisteredStructure structure : structureSet)
 431             result-&gt;add(structure);
 432 
 433         return result;
 434     }
 435 
 436     JSGlobalObject* globalObjectFor(CodeOrigin codeOrigin)
 437     {
 438         return m_codeBlock-&gt;globalObjectFor(codeOrigin);
 439     }
 440 
 441     JSObject* globalThisObjectFor(CodeOrigin codeOrigin)
 442     {
 443         JSGlobalObject* object = globalObjectFor(codeOrigin);
<span class="line-modified"> 444         return jsCast&lt;JSObject*&gt;(object-&gt;methodTable(m_vm)-&gt;toThis(object, object, NotStrictMode));</span>
 445     }
 446 
 447     ScriptExecutable* executableFor(InlineCallFrame* inlineCallFrame)
 448     {
 449         if (!inlineCallFrame)
 450             return m_codeBlock-&gt;ownerExecutable();
 451 
 452         return inlineCallFrame-&gt;baselineCodeBlock-&gt;ownerExecutable();
 453     }
 454 
 455     ScriptExecutable* executableFor(const CodeOrigin&amp; codeOrigin)
 456     {
 457         return executableFor(codeOrigin.inlineCallFrame());
 458     }
 459 
 460     CodeBlock* baselineCodeBlockFor(InlineCallFrame* inlineCallFrame)
 461     {
 462         if (!inlineCallFrame)
 463             return m_profiledBlock;
 464         return baselineCodeBlockForInlineCallFrame(inlineCallFrame);
</pre>
<hr />
<pre>
 823     bool watchCondition(const ObjectPropertyCondition&amp;);
 824     bool watchConditions(const ObjectPropertyConditionSet&amp;);
 825 
 826     bool watchGlobalProperty(JSGlobalObject*, unsigned identifierNumber);
 827 
 828     // Checks if it&#39;s known that loading from the given object at the given offset is fine. This is
 829     // computed by tracking which conditions we track with watchCondition().
 830     bool isSafeToLoad(JSObject* base, PropertyOffset);
 831 
 832     // This uses either constant property inference or property type inference to derive a good abstract
 833     // value for some property accessed with the given abstract value base.
 834     AbstractValue inferredValueForProperty(
 835         const AbstractValue&amp; base, PropertyOffset, StructureClobberState);
 836 
 837     FullBytecodeLiveness&amp; livenessFor(CodeBlock*);
 838     FullBytecodeLiveness&amp; livenessFor(InlineCallFrame*);
 839 
 840     // Quickly query if a single local is live at the given point. This is faster than calling
 841     // forAllLiveInBytecode() if you will only query one local. But, if you want to know all of the
 842     // locals live, then calling this for each local is much slower than forAllLiveInBytecode().
<span class="line-modified"> 843     bool isLiveInBytecode(Operand, CodeOrigin);</span>
 844 
<span class="line-modified"> 845     // Quickly get all of the non-argument locals and tmps live at the given point. This doesn&#39;t give you</span>
 846     // any arguments because those are all presumed live. You can call forAllLiveInBytecode() to
 847     // also get the arguments. This is much faster than calling isLiveInBytecode() for each local.
 848     template&lt;typename Functor&gt;
<span class="line-modified"> 849     void forAllLocalsAndTmpsLiveInBytecode(CodeOrigin codeOrigin, const Functor&amp; functor)</span>
 850     {
 851         // Support for not redundantly reporting arguments. Necessary because in case of a varargs
 852         // call, only the callee knows that arguments are live while in the case of a non-varargs
 853         // call, both callee and caller will see the variables live.
 854         VirtualRegister exclusionStart;
 855         VirtualRegister exclusionEnd;
 856 
 857         CodeOrigin* codeOriginPtr = &amp;codeOrigin;
 858 
<span class="line-added"> 859         bool isCallerOrigin = false;</span>
 860         for (;;) {
 861             InlineCallFrame* inlineCallFrame = codeOriginPtr-&gt;inlineCallFrame();
 862             VirtualRegister stackOffset(inlineCallFrame ? inlineCallFrame-&gt;stackOffset : 0);
 863 
 864             if (inlineCallFrame) {
 865                 if (inlineCallFrame-&gt;isClosureCall)
 866                     functor(stackOffset + CallFrameSlot::callee);
 867                 if (inlineCallFrame-&gt;isVarargs())
<span class="line-modified"> 868                     functor(stackOffset + CallFrameSlot::argumentCountIncludingThis);</span>
 869             }
 870 
 871             CodeBlock* codeBlock = baselineCodeBlockFor(inlineCallFrame);
 872             FullBytecodeLiveness&amp; fullLiveness = livenessFor(codeBlock);
<span class="line-modified"> 873             const auto&amp; livenessAtBytecode = fullLiveness.getLiveness(codeOriginPtr-&gt;bytecodeIndex(), appropriateLivenessCalculationPoint(*codeOriginPtr, isCallerOrigin));</span>
 874             for (unsigned relativeLocal = codeBlock-&gt;numCalleeLocals(); relativeLocal--;) {
 875                 VirtualRegister reg = stackOffset + virtualRegisterForLocal(relativeLocal);
 876 
 877                 // Don&#39;t report if our callee already reported.
 878                 if (reg &gt;= exclusionStart &amp;&amp; reg &lt; exclusionEnd)
 879                     continue;
 880 
<span class="line-modified"> 881                 if (livenessAtBytecode[relativeLocal])</span>
 882                     functor(reg);
 883             }
 884 
<span class="line-added"> 885             if (codeOriginPtr-&gt;bytecodeIndex().checkpoint()) {</span>
<span class="line-added"> 886                 ASSERT(codeBlock-&gt;numTmps());</span>
<span class="line-added"> 887                 auto liveTmps = tmpLivenessForCheckpoint(*codeBlock, codeOriginPtr-&gt;bytecodeIndex());</span>
<span class="line-added"> 888                 liveTmps.forEachSetBit([&amp;] (size_t tmp) {</span>
<span class="line-added"> 889                     functor(remapOperand(inlineCallFrame, Operand::tmp(tmp)));</span>
<span class="line-added"> 890                 });</span>
<span class="line-added"> 891             }</span>
<span class="line-added"> 892 </span>
 893             if (!inlineCallFrame)
 894                 break;
 895 
 896             // Arguments are always live. This would be redundant if it wasn&#39;t for our
 897             // op_call_varargs inlining. See the comment above.
 898             exclusionStart = stackOffset + CallFrame::argumentOffsetIncludingThis(0);
 899             exclusionEnd = stackOffset + CallFrame::argumentOffsetIncludingThis(inlineCallFrame-&gt;argumentsWithFixup.size());
 900 
 901             // We will always have a &quot;this&quot; argument and exclusionStart should be a smaller stack
 902             // offset than exclusionEnd.
 903             ASSERT(exclusionStart &lt; exclusionEnd);
 904 
 905             for (VirtualRegister reg = exclusionStart; reg &lt; exclusionEnd; reg += 1)
 906                 functor(reg);
 907 
 908             // We need to handle tail callers because we may decide to exit to the
 909             // the return bytecode following the tail call.
 910             codeOriginPtr = &amp;inlineCallFrame-&gt;directCaller;
<span class="line-added"> 911             isCallerOrigin = true;</span>
 912         }
 913     }
 914 
<span class="line-modified"> 915     // Get a BitVector of all of the locals and tmps live right now. This is mostly useful if</span>
 916     // you want to compare two sets of live locals from two different CodeOrigins.
<span class="line-modified"> 917     BitVector localsAndTmpsLiveInBytecode(CodeOrigin);</span>
<span class="line-added"> 918 </span>
<span class="line-added"> 919     LivenessCalculationPoint appropriateLivenessCalculationPoint(CodeOrigin origin, bool isCallerOrigin)</span>
<span class="line-added"> 920     {</span>
<span class="line-added"> 921         if (isCallerOrigin) {</span>
<span class="line-added"> 922             // We do not need to keep used registers of call bytecodes live when terminating in inlined function,</span>
<span class="line-added"> 923             // except for inlining invoked by non call bytecodes including getter/setter calls.</span>
<span class="line-added"> 924             BytecodeIndex bytecodeIndex = origin.bytecodeIndex();</span>
<span class="line-added"> 925             InlineCallFrame* inlineCallFrame = origin.inlineCallFrame();</span>
<span class="line-added"> 926             CodeBlock* codeBlock = baselineCodeBlockFor(inlineCallFrame);</span>
<span class="line-added"> 927             auto instruction = codeBlock-&gt;instructions().at(bytecodeIndex.offset());</span>
<span class="line-added"> 928             switch (instruction-&gt;opcodeID()) {</span>
<span class="line-added"> 929             case op_call_varargs:</span>
<span class="line-added"> 930             case op_tail_call_varargs:</span>
<span class="line-added"> 931             case op_construct_varargs:</span>
<span class="line-added"> 932                 // When inlining varargs call, uses include array used for varargs. But when we are in inlined function,</span>
<span class="line-added"> 933                 // the content of this is already read and flushed to the stack. So, at this point, we no longer need to</span>
<span class="line-added"> 934                 // keep these use registers. We can use the liveness at LivenessCalculationPoint::AfterUse point.</span>
<span class="line-added"> 935                 // This is important to kill arguments allocations in DFG (not in FTL) when calling a function in a</span>
<span class="line-added"> 936                 // `func.apply(undefined, arguments)` manner.</span>
<span class="line-added"> 937                 return LivenessCalculationPoint::AfterUse;</span>
<span class="line-added"> 938             default:</span>
<span class="line-added"> 939                 // We could list up the other bytecodes here, like, `op_call`, `op_get_by_id` (getter inlining). But we don&#39;t do that.</span>
<span class="line-added"> 940                 // To list up bytecodes here, we must ensure that these bytecodes never use `uses` registers after inlining. So we cannot</span>
<span class="line-added"> 941                 // return LivenessCalculationPoint::AfterUse blindly if isCallerOrigin = true. And since excluding liveness in the other</span>
<span class="line-added"> 942                 // bytecodes does not offer practical benefit, we do not try it.</span>
<span class="line-added"> 943                 break;</span>
<span class="line-added"> 944             }</span>
<span class="line-added"> 945         }</span>
<span class="line-added"> 946         return LivenessCalculationPoint::BeforeUse;</span>
<span class="line-added"> 947     }</span>
 948 
<span class="line-modified"> 949     // Tells you all of the operands live at the given CodeOrigin. This is a small</span>
<span class="line-modified"> 950     // extension to forAllLocalsOrTmpsLiveInBytecode(), since all arguments are always presumed live.</span>
 951     template&lt;typename Functor&gt;
 952     void forAllLiveInBytecode(CodeOrigin codeOrigin, const Functor&amp; functor)
 953     {
<span class="line-modified"> 954         forAllLocalsAndTmpsLiveInBytecode(codeOrigin, functor);</span>
 955 
 956         // Report all arguments as being live.
 957         for (unsigned argument = block(0)-&gt;variablesAtHead.numberOfArguments(); argument--;)
<span class="line-modified"> 958             functor(virtualRegisterForArgumentIncludingThis(argument));</span>
 959     }
 960 
 961     BytecodeKills&amp; killsFor(CodeBlock*);
 962     BytecodeKills&amp; killsFor(InlineCallFrame*);
 963 
 964     static unsigned parameterSlotsForArgCount(unsigned);
 965 
 966     unsigned frameRegisterCount();
 967     unsigned stackPointerOffset();
 968     unsigned requiredRegisterCountForExit();
 969     unsigned requiredRegisterCountForExecutionAndExit();
 970 
 971     JSValue tryGetConstantProperty(JSValue base, const RegisteredStructureSet&amp;, PropertyOffset);
 972     JSValue tryGetConstantProperty(JSValue base, Structure*, PropertyOffset);
 973     JSValue tryGetConstantProperty(JSValue base, const StructureAbstractValue&amp;, PropertyOffset);
 974     JSValue tryGetConstantProperty(const AbstractValue&amp;, PropertyOffset);
 975 
 976     JSValue tryGetConstantClosureVar(JSValue base, ScopeOffset);
 977     JSValue tryGetConstantClosureVar(const AbstractValue&amp;, ScopeOffset);
 978     JSValue tryGetConstantClosureVar(Node*, ScopeOffset);
</pre>
<hr />
<pre>
1105     Bag&lt;CallVarargsData&gt; m_callVarargsData;
1106     Bag&lt;LoadVarargsData&gt; m_loadVarargsData;
1107     Bag&lt;StackAccessData&gt; m_stackAccessData;
1108     Bag&lt;LazyJSValue&gt; m_lazyJSValues;
1109     Bag&lt;CallDOMGetterData&gt; m_callDOMGetterData;
1110     Bag&lt;BitVector&gt; m_bitVectors;
1111     Vector&lt;InlineVariableData, 4&gt; m_inlineVariableData;
1112     HashMap&lt;CodeBlock*, std::unique_ptr&lt;FullBytecodeLiveness&gt;&gt; m_bytecodeLiveness;
1113     HashMap&lt;CodeBlock*, std::unique_ptr&lt;BytecodeKills&gt;&gt; m_bytecodeKills;
1114     HashSet&lt;std::pair&lt;JSObject*, PropertyOffset&gt;&gt; m_safeToLoad;
1115     Vector&lt;Ref&lt;Snippet&gt;&gt; m_domJITSnippets;
1116     std::unique_ptr&lt;CPSDominators&gt; m_cpsDominators;
1117     std::unique_ptr&lt;SSADominators&gt; m_ssaDominators;
1118     std::unique_ptr&lt;CPSNaturalLoops&gt; m_cpsNaturalLoops;
1119     std::unique_ptr&lt;SSANaturalLoops&gt; m_ssaNaturalLoops;
1120     std::unique_ptr&lt;SSACFG&gt; m_ssaCFG;
1121     std::unique_ptr&lt;CPSCFG&gt; m_cpsCFG;
1122     std::unique_ptr&lt;BackwardsCFG&gt; m_backwardsCFG;
1123     std::unique_ptr&lt;BackwardsDominators&gt; m_backwardsDominators;
1124     std::unique_ptr&lt;ControlEquivalenceAnalysis&gt; m_controlEquivalenceAnalysis;
<span class="line-added">1125     unsigned m_tmps;</span>
1126     unsigned m_localVars;
1127     unsigned m_nextMachineLocal;
1128     unsigned m_parameterSlots;
1129 
1130     // This is the number of logical entrypoints that we&#39;re compiling. This is only used
1131     // in SSA. Each EntrySwitch node must have m_numberOfEntrypoints cases. Note, this is
1132     // not the same as m_roots.size(). m_roots.size() represents the number of roots in
1133     // the CFG. In SSA, m_roots.size() == 1 even if we&#39;re compiling more than one entrypoint.
1134     unsigned m_numberOfEntrypoints { UINT_MAX };
1135 
1136     // This maps an entrypoint index to a particular op_catch bytecode offset. By convention,
1137     // it&#39;ll never have zero as a key because we use zero to mean the op_enter entrypoint.
<span class="line-modified">1138     HashMap&lt;unsigned, BytecodeIndex&gt; m_entrypointIndexToCatchBytecodeIndex;</span>
1139 
1140     HashSet&lt;String&gt; m_localStrings;
1141     HashMap&lt;const StringImpl*, String&gt; m_copiedStrings;
1142 
1143 #if USE(JSVALUE32_64)
1144     StdUnorderedMap&lt;int64_t, double*&gt; m_doubleConstantsMap;
1145     std::unique_ptr&lt;Bag&lt;double&gt;&gt; m_doubleConstants;
1146 #endif
1147 
1148     OptimizationFixpointState m_fixpointState;
1149     StructureRegistrationState m_structureRegistrationState;
1150     GraphForm m_form;
1151     UnificationState m_unificationState;
1152     PlanStage m_planStage { PlanStage::Initial };
1153     RefCountState m_refCountState;
1154     bool m_hasDebuggerEnabled;
1155     bool m_hasExceptionHandlers { false };
1156     bool m_isInSSAConversion { false };
1157     Optional&lt;uint32_t&gt; m_maxLocalsForCatchOSREntry;
1158     std::unique_ptr&lt;FlowIndexing&gt; m_indexingCache;
1159     std::unique_ptr&lt;FlowMap&lt;AbstractValue&gt;&gt; m_abstractValuesCache;
1160     Bag&lt;EntrySwitchData&gt; m_entrySwitchData;
1161 
1162     RegisteredStructure stringStructure;
1163     RegisteredStructure symbolStructure;
1164 
<span class="line-added">1165     HashSet&lt;Node*&gt; m_slowGetByVal;</span>
<span class="line-added">1166 </span>
1167 private:
1168     bool isStringPrototypeMethodSane(JSGlobalObject*, UniquedStringImpl*);
1169 
1170     void handleSuccessor(Vector&lt;BasicBlock*, 16&gt;&amp; worklist, BasicBlock*, BasicBlock* successor);
1171 
1172     AddSpeculationMode addImmediateShouldSpeculateInt32(Node* add, bool variableShouldSpeculateInt32, Node* operand, Node*immediate, RareCaseProfilingSource source)
1173     {
1174         ASSERT(immediate-&gt;hasConstant());
1175 
1176         JSValue immediateValue = immediate-&gt;asJSValue();
1177         if (!immediateValue.isNumber() &amp;&amp; !immediateValue.isBoolean())
1178             return DontSpeculateInt32;
1179 
1180         if (!variableShouldSpeculateInt32)
1181             return DontSpeculateInt32;
1182 
1183         // Integer constants can be typed Double if they are written like a double in the source code (e.g. 42.0).
1184         // In that case, we stay conservative unless the other operand was explicitly typed as integer.
1185         NodeFlags operandResultType = operand-&gt;result();
1186         if (operandResultType != NodeResultInt32 &amp;&amp; immediateValue.isDouble())
</pre>
</td>
</tr>
</table>
<center><a href="DFGGraph.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGHeapLocation.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>