<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter32_64.asm</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="LowLevelInterpreter.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="LowLevelInterpreter64.asm.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter32_64.asm</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   6 # 1. Redistributions of source code must retain the above copyright
   7 #    notice, this list of conditions and the following disclaimer.
   8 # 2. Redistributions in binary form must reproduce the above copyright
   9 #    notice, this list of conditions and the following disclaimer in the
  10 #    documentation and/or other materials provided with the distribution.
  11 #
  12 # THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
  13 # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
  14 # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  15 # PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
  16 # BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  17 # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  18 # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
  19 # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
  20 # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
  21 # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
  22 # THE POSSIBILITY OF SUCH DAMAGE.
  23 
  24 
  25 # Utilities
<span class="line-modified">  26 macro nextInstruction()</span>
<span class="line-modified">  27     loadb [PC], t0</span>
<span class="line-removed">  28     leap _g_opcodeMap, t1</span>
<span class="line-removed">  29     jmp [t1, t0, 4], BytecodePtrTag</span>
<span class="line-removed">  30 end</span>
<span class="line-removed">  31 </span>
<span class="line-removed">  32 macro nextInstructionWide16()</span>
<span class="line-removed">  33     loadh 1[PC], t0</span>
<span class="line-removed">  34     leap _g_opcodeMapWide16, t1</span>
<span class="line-removed">  35     jmp [t1, t0, 4], BytecodePtrTag</span>
<span class="line-removed">  36 end</span>
<span class="line-removed">  37 </span>
<span class="line-removed">  38 macro nextInstructionWide32()</span>
<span class="line-removed">  39     loadi 1[PC], t0</span>
<span class="line-removed">  40     leap _g_opcodeMapWide32, t1</span>
<span class="line-removed">  41     jmp [t1, t0, 4], BytecodePtrTag</span>
<span class="line-removed">  42 end</span>
  43 
  44 macro getuOperandNarrow(opcodeStruct, fieldName, dst)
<span class="line-modified">  45     loadb constexpr %opcodeStruct%_%fieldName%_index[PC], dst</span>
  46 end
  47 
  48 macro getOperandNarrow(opcodeStruct, fieldName, dst)
<span class="line-modified">  49     loadbsi constexpr %opcodeStruct%_%fieldName%_index[PC], dst</span>
  50 end
  51 
  52 macro getuOperandWide16(opcodeStruct, fieldName, dst)
<span class="line-modified">  53     loadh constexpr %opcodeStruct%_%fieldName%_index * 2 + 1[PC], dst</span>
  54 end
  55 
  56 macro getOperandWide16(opcodeStruct, fieldName, dst)
<span class="line-modified">  57     loadhsi constexpr %opcodeStruct%_%fieldName%_index * 2 + 1[PC], dst</span>
  58 end
  59 
  60 macro getuOperandWide32(opcodeStruct, fieldName, dst)
<span class="line-modified">  61     loadi constexpr %opcodeStruct%_%fieldName%_index * 4 + 1[PC], dst</span>
  62 end
  63 
  64 macro getOperandWide32(opcodeStruct, fieldName, dst)
<span class="line-modified">  65     loadis constexpr %opcodeStruct%_%fieldName%_index * 4 + 1[PC], dst</span>
  66 end
  67 
  68 macro makeReturn(get, dispatch, fn)
  69     fn(macro(tag, payload)
  70         move tag, t5
  71         move payload, t3
  72         get(m_dst, t2)
  73         storei t5, TagOffset[cfr, t2, 8]
  74         storei t3, PayloadOffset[cfr, t2, 8]
  75         dispatch()
  76     end)
  77 end
  78 
  79 macro makeReturnProfiled(opcodeStruct, get, metadata, dispatch, fn)
  80     fn(macro (tag, payload)
  81         move tag, t1
  82         move payload, t0
  83 
  84         metadata(t5, t2)
  85         valueProfile(opcodeStruct, t5, t1, t0)
  86         get(m_dst, t2)
  87         storei t1, TagOffset[cfr, t2, 8]
  88         storei t0, PayloadOffset[cfr, t2, 8]
  89         dispatch()
  90     end)
  91 end
  92 
  93 

  94 macro dispatchAfterCall(size, opcodeStruct, dispatch)
<span class="line-modified">  95     loadi ArgumentCount + TagOffset[cfr], PC</span>


  96     get(size, opcodeStruct, m_dst, t3)
  97     storei r1, TagOffset[cfr, t3, 8]
  98     storei r0, PayloadOffset[cfr, t3, 8]
  99     metadata(size, opcodeStruct, t2, t3)
 100     valueProfile(opcodeStruct, t2, r1, r0)
 101     dispatch()
 102 end
 103 
 104 macro cCall2(function)
 105     if ARMv7 or MIPS
 106         call function
 107     elsif X86 or X86_WIN
 108         subp 8, sp
 109         push a1
 110         push a0
 111         call function
 112         addp 16, sp
 113     elsif C_LOOP or C_LOOP_WIN
 114         cloopCallSlowPath function, a0, a1
 115     else
</pre>
<hr />
<pre>
 125     end
 126 end
 127 
 128 macro cCall4(function)
 129     if ARMv7 or MIPS
 130         call function
 131     elsif X86 or X86_WIN
 132         push a3
 133         push a2
 134         push a1
 135         push a0
 136         call function
 137         addp 16, sp
 138     elsif C_LOOP or C_LOOP_WIN
 139         error
 140     else
 141         error
 142     end
 143 end
 144 









 145 macro callSlowPath(slowPath)

 146     move cfr, a0
 147     move PC, a1
 148     cCall2(slowPath)
<span class="line-modified"> 149     move r0, PC</span>
 150 end
 151 
 152 macro doVMEntry(makeCall)
 153     functionPrologue()
 154     pushCalleeSaves()
 155 
 156     # x86 needs to load arguments from the stack
 157     if X86 or X86_WIN
 158         loadp 16[cfr], a2
 159         loadp 12[cfr], a1
 160         loadp 8[cfr], a0
 161     end
 162 
 163     const entry = a0
 164     const vm = a1
 165     const protoCallFrame = a2
 166 
 167     # We are using t3, t4 and t5 as temporaries through the function.
 168     # Since we have the guarantee that tX != aY when X != Y, we are safe from
 169     # aliasing problems with our arguments.
</pre>
<hr />
<pre>
 245     storei UndefinedTag, ThisArgumentOffset + 8 + TagOffset[sp, t5, 8]
 246     storei 0, ThisArgumentOffset + 8 + PayloadOffset[sp, t5, 8]
 247     bineq t4, t5, .fillExtraArgsLoop
 248 
 249 .copyArgs:
 250     loadp ProtoCallFrame::args[protoCallFrame], t3
 251 
 252 .copyArgsLoop:
 253     btiz t4, .copyArgsDone
 254     subi 1, t4
 255     loadi TagOffset[t3, t4, 8], t5
 256     storei t5, ThisArgumentOffset + 8 + TagOffset[sp, t4, 8]
 257     loadi PayloadOffset[t3, t4, 8], t5
 258     storei t5, ThisArgumentOffset + 8 + PayloadOffset[sp, t4, 8]
 259     jmp .copyArgsLoop
 260 
 261 .copyArgsDone:
 262     storep sp, VM::topCallFrame[vm]
 263     storep cfr, VM::topEntryFrame[vm]
 264 
<span class="line-modified"> 265     makeCall(entry, t3, t4)</span>
 266 
 267     if ARMv7
 268         vmEntryRecord(cfr, t3)
 269         move t3, sp
 270     else
 271         vmEntryRecord(cfr, sp)
 272     end
 273 
 274     loadp VMEntryRecord::m_vm[sp], t5
 275     loadp VMEntryRecord::m_prevTopCallFrame[sp], t4
 276     storep t4, VM::topCallFrame[t5]
 277     loadp VMEntryRecord::m_prevTopEntryFrame[sp], t4
 278     storep t4, VM::topEntryFrame[t5]
 279 
 280     if ARMv7
 281         subp cfr, CalleeRegisterSaveSize, t5
 282         move t5, sp
 283     else
 284         subp cfr, CalleeRegisterSaveSize, sp
 285     end
</pre>
<hr />
<pre>
 302     end
 303 
 304     loadp VMEntryRecord::m_vm[sp], t5
 305     loadp VMEntryRecord::m_prevTopCallFrame[sp], t4
 306     storep t4, VM::topCallFrame[t5]
 307     loadp VMEntryRecord::m_prevTopEntryFrame[sp], t4
 308     storep t4, VM::topEntryFrame[t5]
 309 
 310     if ARMv7
 311         subp cfr, CalleeRegisterSaveSize, t5
 312         move t5, sp
 313     else
 314         subp cfr, CalleeRegisterSaveSize, sp
 315     end
 316 
 317     popCalleeSaves()
 318     functionEpilogue()
 319     ret
 320 end
 321 
<span class="line-modified"> 322 macro makeJavaScriptCall(entry, temp, unused)</span>

 323     addp CallerFrameAndPCSize, sp
<span class="line-modified"> 324     checkStackPointerAlignment(temp, 0xbad0dc02)</span>
 325     if C_LOOP or C_LOOP_WIN
 326         cloopCallJSFunction entry
 327     else
 328         call entry
 329     end
<span class="line-modified"> 330     checkStackPointerAlignment(temp, 0xbad0dc03)</span>
 331     subp CallerFrameAndPCSize, sp
 332 end
 333 
<span class="line-modified"> 334 macro makeHostFunctionCall(entry, temp1, temp2)</span>

 335     move entry, temp1
 336     storep cfr, [sp]
 337     if C_LOOP or C_LOOP_WIN
<span class="line-modified"> 338         move sp, a0</span>

 339         storep lr, PtrSize[sp]
 340         cloopCallNative temp1
 341     elsif X86 or X86_WIN
<span class="line-modified"> 342         # Put callee frame pointer on stack as arg0, also put it in ecx for &quot;fastcall&quot; targets</span>
 343         move 0, temp2
 344         move temp2, 4[sp] # put 0 in ReturnPC
<span class="line-modified"> 345         move sp, a0 # a0 is ecx</span>
<span class="line-modified"> 346         push temp2 # Push dummy arg1</span>

 347         push a0
 348         call temp1
 349         addp 8, sp








 350     else
<span class="line-modified"> 351         move sp, a0</span>

 352         call temp1
 353     end
 354 end
 355 
 356 op(handleUncaughtException, macro()
 357     loadp Callee + PayloadOffset[cfr], t3
<span class="line-modified"> 358     andp MarkedBlockMask, t3</span>
<span class="line-removed"> 359     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3</span>
 360     restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(t3, t0)
 361     storep 0, VM::callFrameForCatch[t3]
 362 
 363     loadp VM::topEntryFrame[t3], cfr
 364     if ARMv7
 365         vmEntryRecord(cfr, t3)
 366         move t3, sp
 367     else
 368         vmEntryRecord(cfr, sp)
 369     end
 370 
 371     loadp VMEntryRecord::m_vm[sp], t3
 372     loadp VMEntryRecord::m_prevTopCallFrame[sp], t5
 373     storep t5, VM::topCallFrame[t3]
 374     loadp VMEntryRecord::m_prevTopEntryFrame[sp], t5
 375     storep t5, VM::topEntryFrame[t3]
 376 
 377     if ARMv7
 378         subp cfr, CalleeRegisterSaveSize, t3
 379         move t3, sp
 380     else
 381         subp cfr, CalleeRegisterSaveSize, sp
 382     end
 383 
 384     popCalleeSaves()
 385     functionEpilogue()
 386     ret
 387 end)
 388 
 389 macro doReturnFromHostFunction(extraStackSpace)
 390     functionEpilogue(extraStackSpace)
 391     ret
 392 end
 393 
 394 # Debugging operation if you&#39;d like to print an operand in the instruction stream. fromWhere
 395 # should be an immediate integer - any integer you like; use it to identify the place you&#39;re
 396 # debugging from. operand should likewise be an immediate, and should identify the operand
 397 # in the instruction stream you&#39;d like to print out.
 398 macro traceOperand(fromWhere, operand)

 399     move fromWhere, a2
 400     move operand, a3
 401     move cfr, a0
 402     move PC, a1
 403     cCall4(_llint_trace_operand)
<span class="line-modified"> 404     move r0, PC</span>
 405     move r1, cfr
 406 end
 407 
 408 # Debugging operation if you&#39;d like to print the value of an operand in the instruction
 409 # stream. Same as traceOperand(), but assumes that the operand is a register, and prints its
 410 # value.
 411 macro traceValue(fromWhere, operand)

 412     move fromWhere, a2
 413     move operand, a3
 414     move cfr, a0
 415     move PC, a1
 416     cCall4(_llint_trace_value)
<span class="line-modified"> 417     move r0, PC</span>
 418     move r1, cfr
 419 end
 420 
 421 # Call a slowPath for call opcodes.
 422 macro callCallSlowPath(slowPath, action)
<span class="line-modified"> 423     storep PC, ArgumentCount + TagOffset[cfr]</span>

 424     move cfr, a0
 425     move PC, a1
 426     cCall2(slowPath)
 427     action(r0, r1)
 428 end
 429 
 430 macro callTrapHandler(throwHandler)
<span class="line-modified"> 431     storei PC, ArgumentCount + TagOffset[cfr]</span>

 432     move cfr, a0
 433     move PC, a1
 434     cCall2(_llint_slow_path_handle_traps)
 435     btpnz r0, throwHandler
<span class="line-modified"> 436     loadi ArgumentCount + TagOffset[cfr], PC</span>
 437 end
 438 
 439 macro checkSwitchToJITForLoop()
 440     checkSwitchToJIT(
 441         1,
 442         macro ()
<span class="line-modified"> 443             storei PC, ArgumentCount + TagOffset[cfr]</span>

 444             move cfr, a0
 445             move PC, a1
 446             cCall2(_llint_loop_osr)
 447             btpz r0, .recover
 448             move r1, sp
 449             jmp r0
 450         .recover:
<span class="line-modified"> 451             loadi ArgumentCount + TagOffset[cfr], PC</span>
 452         end)
 453 end
 454 
 455 macro loadVariable(get, fieldName, indexReg, tagReg, payloadReg)
 456     get(fieldName, indexReg)
 457     loadi TagOffset[cfr, indexReg, 8], tagReg
 458     loadi PayloadOffset[cfr, indexReg, 8], payloadReg
 459 end
 460 












 461 # Index, tag, and payload must be different registers. Index is not
 462 # changed.
 463 macro loadConstantOrVariable(size, index, tag, payload)
 464     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)
 465         bigteq index, FirstConstantRegisterIndex, .constant
 466         loadi TagOffset[cfr, index, 8], tag
 467         loadi PayloadOffset[cfr, index, 8], payload
 468         jmp .done
 469     .constant:
<span class="line-modified"> 470         loadp CodeBlock[cfr], payload</span>
<span class="line-removed"> 471         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[payload], payload</span>
<span class="line-removed"> 472         subp FirstConstantRegisterIndex, index</span>
<span class="line-removed"> 473         loadp TagOffset[payload, index, 8], tag</span>
<span class="line-removed"> 474         loadp PayloadOffset[payload, index, 8], payload</span>
 475     .done:
 476     end)
 477 end
 478 
 479 macro loadConstantOrVariableTag(size, index, tag)
 480     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)
 481         bigteq index, FirstConstantRegisterIndex, .constant
 482         loadi TagOffset[cfr, index, 8], tag
 483         jmp .done
 484     .constant:
 485         loadp CodeBlock[cfr], tag
 486         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[tag], tag
 487         subi FirstConstantRegisterIndex, index
 488         loadp TagOffset[tag, index, 8], tag
 489     .done:
 490     end)
 491 end
 492 
 493 # Index and payload may be the same register. Index may be clobbered.
 494 macro loadConstantOrVariable2Reg(size, index, tag, payload)
</pre>
<hr />
<pre>
 533 macro loadConstantOrVariablePayload(size, index, expectedTag, payload, slow)
 534     loadConstantOrVariablePayloadTagCustom(
 535         size,
 536         index,
 537         macro (actualTag) bineq actualTag, expectedTag, slow end,
 538         payload)
 539 end
 540 
 541 macro loadConstantOrVariablePayloadUnchecked(size, index, payload)
 542     loadConstantOrVariablePayloadTagCustom(
 543         size,
 544         index,
 545         macro (actualTag) end,
 546         payload)
 547 end
 548 
 549 macro writeBarrierOnCellWithReload(cell, reloadAfterSlowPath)
 550     skipIfIsRememberedOrInEden(
 551         cell,
 552         macro()
<span class="line-modified"> 553             push cfr, PC</span>
 554             # We make two extra slots because cCall2 will poke.
 555             subp 8, sp
 556             move cell, a1 # cell can be a0
 557             move cfr, a0
 558             cCall2Void(_llint_write_barrier_slow)
 559             addp 8, sp
<span class="line-modified"> 560             pop PC, cfr</span>
 561             reloadAfterSlowPath()
 562         end)
 563 end
 564 
 565 macro writeBarrierOnOperand(size, get, cellFieldName)
 566     get(cellFieldName, t1)
 567     loadConstantOrVariablePayload(size, t1, CellTag, t2, .writeBarrierDone)
 568     writeBarrierOnCellWithReload(t2, macro() end)
 569 .writeBarrierDone:
 570 end
 571 
 572 macro writeBarrierOnOperands(size, get, cellFieldName, valueFieldName)
 573     get(valueFieldName, t1)
 574     loadConstantOrVariableTag(size, t1, t0)
 575     bineq t0, CellTag, .writeBarrierDone
 576 
 577     writeBarrierOnOperand(size, get, cellFieldName)
 578 .writeBarrierDone:
 579 end
 580 
</pre>
<hr />
<pre>
 599 
 600 macro writeBarrierOnGlobalLexicalEnvironment(size, get, valueFieldName)
 601     writeBarrierOnGlobal(size, get, valueFieldName,
 602         macro(registerToStoreGlobal)
 603             loadp CodeBlock[cfr], registerToStoreGlobal
 604             loadp CodeBlock::m_globalObject[registerToStoreGlobal], registerToStoreGlobal
 605             loadp JSGlobalObject::m_globalLexicalEnvironment[registerToStoreGlobal], registerToStoreGlobal
 606         end)
 607 end
 608 
 609 macro valueProfile(opcodeStruct, metadata, tag, payload)
 610     storei tag, %opcodeStruct%::Metadata::m_profile.m_buckets + TagOffset[metadata]
 611     storei payload, %opcodeStruct%::Metadata::m_profile.m_buckets + PayloadOffset[metadata]
 612 end
 613 
 614 
 615 # Entrypoints into the interpreter
 616 
 617 # Expects that CodeBlock is in t1, which is what prologue() leaves behind.
 618 macro functionArityCheck(doneLabel, slowPath)
<span class="line-modified"> 619     loadi PayloadOffset + ArgumentCount[cfr], t0</span>
 620     biaeq t0, CodeBlock::m_numParameters[t1], doneLabel

 621     move cfr, a0
 622     move PC, a1
 623     cCall2(slowPath)   # This slowPath has a simple protocol: t0 = 0 =&gt; no error, t0 != 0 =&gt; error
 624     btiz r0, .noError
 625 
 626     # We&#39;re throwing before the frame is fully set up. This frame will be
 627     # ignored by the unwinder. So, let&#39;s restore the callee saves before we
 628     # start unwinding. We need to do this before we change the cfr.
 629     restoreCalleeSavesUsedByLLInt()
 630 
 631     move r1, cfr   # r1 contains caller frame
 632     jmp _llint_throw_from_slow_path_trampoline
 633 
 634 .noError:
 635     move r1, t1 # r1 contains slotsToAdd.
 636     btiz t1, .continue
<span class="line-modified"> 637     loadi PayloadOffset + ArgumentCount[cfr], t2</span>
 638     addi CallFrameHeaderSlots, t2
 639 
 640     // Check if there are some unaligned slots we can use
 641     move t1, t3
 642     andi StackAlignmentSlots - 1, t3
 643     btiz t3, .noExtraSlot
 644 .fillExtraSlots:
 645     move 0, t0
 646     storei t0, PayloadOffset[cfr, t2, 8]
 647     move UndefinedTag, t0
 648     storei t0, TagOffset[cfr, t2, 8]
 649     addi 1, t2
 650     bsubinz 1, t3, .fillExtraSlots
 651     andi ~(StackAlignmentSlots - 1), t1
 652     btiz t1, .continue
 653 
 654 .noExtraSlot:
 655     // Move frame up t1 slots
 656     negi t1
 657     move cfr, t3
</pre>
<hr />
<pre>
 665     loadi PayloadOffset[t3], t0
 666     storei t0, PayloadOffset[t3, t1, 8]
 667     loadi TagOffset[t3], t0
 668     storei t0, TagOffset[t3, t1, 8]
 669     addp 8, t3
 670     bsubinz 1, t2, .copyLoop
 671 
 672     // Fill new slots with JSUndefined
 673     move t1, t2
 674 .fillLoop:
 675     move 0, t0
 676     storei t0, PayloadOffset[t3, t1, 8]
 677     move UndefinedTag, t0
 678     storei t0, TagOffset[t3, t1, 8]
 679     addp 8, t3
 680     baddinz 1, t2, .fillLoop
 681 
 682 .continue:
 683     # Reload CodeBlock and PC, since the slow_path clobbered it.
 684     loadp CodeBlock[cfr], t1
<span class="line-modified"> 685     loadp CodeBlock::m_instructionsRawPointer[t1], PC</span>

 686     jmp doneLabel
 687 end
 688 
<span class="line-removed"> 689 macro branchIfException(label)</span>
<span class="line-removed"> 690     loadp Callee + PayloadOffset[cfr], t3</span>
<span class="line-removed"> 691     andp MarkedBlockMask, t3</span>
<span class="line-removed"> 692     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3</span>
<span class="line-removed"> 693     btpz VM::m_exception[t3], .noException</span>
<span class="line-removed"> 694     jmp label</span>
<span class="line-removed"> 695 .noException:</span>
<span class="line-removed"> 696 end</span>
<span class="line-removed"> 697 </span>
<span class="line-removed"> 698 </span>
 699 # Instruction implementations
 700 
 701 _llint_op_enter:
 702     traceExecution()
 703     checkStackPointerAlignment(t2, 0xdead00e1)
<span class="line-modified"> 704     loadp CodeBlock[cfr], t1                // t1&lt;CodeBlock&gt; = cfr.CodeBlock</span>
<span class="line-modified"> 705     loadi CodeBlock::m_numVars[t1], t2      // t2&lt;size_t&gt; = t1&lt;CodeBlock&gt;.m_numVars</span>
 706     subi CalleeSaveSpaceAsVirtualRegisters, t2
 707     move cfr, t3
 708     subp CalleeSaveSpaceAsVirtualRegisters * SlotSize, t3
 709     btiz t2, .opEnterDone
 710     move UndefinedTag, t0

 711     negi t2
 712 .opEnterLoop:
 713     storei t0, TagOffset[t3, t2, 8]
<span class="line-modified"> 714     storei 0, PayloadOffset[t3, t2, 8]</span>
 715     addi 1, t2
 716     btinz t2, .opEnterLoop
 717 .opEnterDone:
<span class="line-modified"> 718     writeBarrierOnCellWithReload(t1, macro ()</span>
<span class="line-removed"> 719         loadp CodeBlock[cfr], t1 # Reload CodeBlock</span>
<span class="line-removed"> 720     end)</span>
<span class="line-removed"> 721     # Checking traps.</span>
<span class="line-removed"> 722     loadp CodeBlock::m_vm[t1], t1</span>
<span class="line-removed"> 723     btpnz VM::m_traps + VMTraps::m_needTrapHandling[t1], .handleTraps</span>
<span class="line-removed"> 724 .afterHandlingTraps:</span>
 725     dispatchOp(narrow, op_enter)
<span class="line-modified"> 726 .handleTraps:</span>
<span class="line-removed"> 727     callTrapHandler(_llint_throw_from_slow_path_trampoline)</span>
<span class="line-removed"> 728     jmp .afterHandlingTraps</span>
 729 
 730 llintOpWithProfile(op_get_argument, OpGetArgument, macro (size, get, dispatch, return)
 731     get(m_index, t2)
<span class="line-modified"> 732     loadi PayloadOffset + ArgumentCount[cfr], t0</span>
 733     bilteq t0, t2, .opGetArgumentOutOfBounds
 734     loadi ThisArgumentOffset + TagOffset[cfr, t2, 8], t0
 735     loadi ThisArgumentOffset + PayloadOffset[cfr, t2, 8], t3
 736     return (t0, t3)
 737 
 738 .opGetArgumentOutOfBounds:
 739     return (UndefinedTag, 0)
 740 end)
 741 
 742 
 743 llintOpWithReturn(op_argument_count, OpArgumentCount, macro (size, get, dispatch, return)
<span class="line-modified"> 744     loadi PayloadOffset + ArgumentCount[cfr], t0</span>
 745     subi 1, t0
 746     return(Int32Tag, t0)
 747 end)
 748 
 749 
 750 llintOpWithReturn(op_get_scope, OpGetScope, macro (size, get, dispatch, return)
 751     loadi Callee + PayloadOffset[cfr], t0
 752     loadp JSCallee::m_scope[t0], t0
 753     return (CellTag, t0)
 754 end)
 755 
 756 
 757 llintOpWithMetadata(op_to_this, OpToThis, macro (size, get, dispatch, metadata, return)
 758     get(m_srcDst, t0)
 759     bineq TagOffset[cfr, t0, 8], CellTag, .opToThisSlow
 760     loadi PayloadOffset[cfr, t0, 8], t0
 761     bbneq JSCell::m_type[t0], FinalObjectType, .opToThisSlow
 762     metadata(t2, t3)
 763     loadi OpToThis::Metadata::m_cachedStructureID[t2], t2
 764     bineq JSCell::m_structureID[t0], t2, .opToThisSlow
</pre>
<hr />
<pre>
 929     end)
 930 end
 931 
 932 
 933 strictEqOp(stricteq, OpStricteq,
 934     macro (left, right, result) cieq left, right, result end)
 935 
 936 
 937 strictEqOp(nstricteq, OpNstricteq,
 938     macro (left, right, result) cineq left, right, result end)
 939 
 940 
 941 strictEqualityJumpOp(jstricteq, OpJstricteq,
 942     macro (left, right, target) bieq left, right, target end)
 943 
 944 
 945 strictEqualityJumpOp(jnstricteq, OpJnstricteq,
 946     macro (left, right, target) bineq left, right, target end)
 947 
 948 
<span class="line-modified"> 949 macro preOp(opcodeName, opcodeStruct, operation)</span>
<span class="line-modified"> 950     llintOp(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch)</span>





 951         get(m_srcDst, t0)
 952         bineq TagOffset[cfr, t0, 8], Int32Tag, .slow
<span class="line-modified"> 953         loadi PayloadOffset[cfr, t0, 8], t1</span>
<span class="line-modified"> 954         operation(t1, .slow)</span>
<span class="line-modified"> 955         storei t1, PayloadOffset[cfr, t0, 8]</span>


 956         dispatch()
 957 
 958     .slow:
 959         callSlowPath(_slow_path_%opcodeName%)
 960         dispatch()
 961     end)
 962 end
 963 
 964 
 965 llintOpWithProfile(op_to_number, OpToNumber, macro (size, get, dispatch, return)
 966     get(m_operand, t0)
 967     loadConstantOrVariable(size, t0, t2, t3)
 968     bieq t2, Int32Tag, .opToNumberIsInt
 969     biaeq t2, LowestTag, .opToNumberSlow
 970 .opToNumberIsInt:
 971     return(t2, t3)
 972 
 973 .opToNumberSlow:
 974     callSlowPath(_slow_path_to_number)
 975     dispatch()
 976 end)
 977 













 978 
 979 llintOpWithReturn(op_to_string, OpToString, macro (size, get, dispatch, return)
 980     get(m_operand, t0)
 981     loadConstantOrVariable(size, t0, t2, t3)
 982     bineq t2, CellTag, .opToStringSlow
 983     bbneq JSCell::m_type[t3], StringType, .opToStringSlow
 984 .opToStringIsString:
 985     return(t2, t3)
 986 
 987 .opToStringSlow:
 988     callSlowPath(_slow_path_to_string)
 989     dispatch()
 990 end)
 991 
 992 
 993 llintOpWithProfile(op_to_object, OpToObject, macro (size, get, dispatch, return)
 994     get(m_operand, t0)
 995     loadConstantOrVariable(size, t0, t2, t3)
 996     bineq t2, CellTag, .opToObjectSlow
 997     bbb JSCell::m_type[t3], ObjectType, .opToObjectSlow
 998     return(t2, t3)
 999 
1000 .opToObjectSlow:
1001     callSlowPath(_slow_path_to_object)
1002     dispatch()
1003 end)
1004 
1005 
1006 llintOpWithMetadata(op_negate, OpNegate, macro (size, get, dispatch, metadata, return)
1007 
<span class="line-modified">1008     macro arithProfile(type)</span>
<span class="line-modified">1009         ori type, OpNegate::Metadata::m_arithProfile + ArithProfile::m_bits[t5]</span>
1010     end
1011 
1012     metadata(t5, t0)
1013     get(m_operand, t0)
1014     loadConstantOrVariable(size, t0, t1, t2)
1015     bineq t1, Int32Tag, .opNegateSrcNotInt
1016     btiz t2, 0x7fffffff, .opNegateSlow
1017     negi t2
<span class="line-modified">1018     arithProfile(ArithProfileInt)</span>
1019     return (Int32Tag, t2)
1020 .opNegateSrcNotInt:
1021     bia t1, LowestTag, .opNegateSlow
1022     xori 0x80000000, t1
<span class="line-modified">1023     arithProfile(ArithProfileNumber)</span>
1024     return(t1, t2)
1025 
1026 .opNegateSlow:
1027     callSlowPath(_slow_path_negate)
1028     dispatch()
1029 end)
1030 
1031 
1032 macro binaryOpCustomStore(opcodeName, opcodeStruct, integerOperationAndStore, doubleOperation)
1033     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)
1034         macro arithProfile(type)
<span class="line-modified">1035             ori type, %opcodeStruct%::Metadata::m_arithProfile + ArithProfile::m_bits[t5]</span>
1036         end
1037 
1038         metadata(t5, t2)
1039         get(m_rhs, t2)
1040         get(m_lhs, t0)
1041         loadConstantOrVariable(size, t2, t3, t1)
1042         loadConstantOrVariable2Reg(size, t0, t2, t0)
1043         bineq t2, Int32Tag, .op1NotInt
1044         bineq t3, Int32Tag, .op2NotInt
1045         arithProfile(ArithProfileIntInt)
1046         get(m_dst, t2)
1047         integerOperationAndStore(t3, t1, t0, .slow, t2)
1048         dispatch()
1049 
1050     .op1NotInt:
1051         # First operand is definitely not an int, the second operand could be anything.
1052         bia t2, LowestTag, .slow
1053         bib t3, LowestTag, .op1NotIntOp2Double
1054         bineq t3, Int32Tag, .slow
1055         arithProfile(ArithProfileNumberInt)
<span class="line-modified">1056         ci2d t1, ft1</span>
1057         jmp .op1NotIntReady
1058     .op1NotIntOp2Double:
1059         fii2d t1, t3, ft1
1060         arithProfile(ArithProfileNumberNumber)
1061     .op1NotIntReady:
1062         get(m_dst, t1)
1063         fii2d t0, t2, ft0
1064         doubleOperation(ft1, ft0)
1065         stored ft0, [cfr, t1, 8]
1066         dispatch()
1067 
1068     .op2NotInt:
1069         # First operand is definitely an int, the second operand is definitely not.
1070         get(m_dst, t2)
1071         bia t3, LowestTag, .slow
1072         arithProfile(ArithProfileIntNumber)
<span class="line-modified">1073         ci2d t0, ft0</span>
1074         fii2d t1, t3, ft1
1075         doubleOperation(ft1, ft0)
1076         stored ft0, [cfr, t2, 8]
1077         dispatch()
1078 
1079     .slow:
1080         callSlowPath(_slow_path_%opcodeName%)
1081         dispatch()
1082     end)
1083 end
1084 
1085 macro binaryOp(opcodeName, opcodeStruct, integerOperation, doubleOperation)
1086     binaryOpCustomStore(opcodeName, opcodeStruct,
1087         macro (int32Tag, left, right, slow, index)
1088             integerOperation(left, right, slow)
1089             storei int32Tag, TagOffset[cfr, index, 8]
1090             storei right, PayloadOffset[cfr, index, 8]
1091         end,
1092         doubleOperation)
1093 end
</pre>
<hr />
<pre>
1102         const scratch = int32Tag   # We know that we can reuse the int32Tag register since it has a constant.
1103         move right, scratch
1104         bmulio left, scratch, slow
1105         btinz scratch, .done
1106         bilt left, 0, slow
1107         bilt right, 0, slow
1108     .done:
1109         storei Int32Tag, TagOffset[cfr, index, 8]
1110         storei scratch, PayloadOffset[cfr, index, 8]
1111     end,
1112     macro (left, right) muld left, right end)
1113 
1114 
1115 binaryOp(sub, OpSub,
1116     macro (left, right, slow) bsubio left, right, slow end,
1117     macro (left, right) subd left, right end)
1118 
1119 
1120 binaryOpCustomStore(div, OpDiv,
1121     macro (int32Tag, left, right, slow, index)
<span class="line-modified">1122         ci2d left, ft0</span>
<span class="line-modified">1123         ci2d right, ft1</span>
1124         divd ft0, ft1
1125         bcd2i ft1, right, .notInt
1126         storei int32Tag, TagOffset[cfr, index, 8]
1127         storei right, PayloadOffset[cfr, index, 8]
1128         jmp .done
1129     .notInt:
1130         stored ft1, [cfr, index, 8]
1131     .done:
1132     end,
1133     macro (left, right) divd left, right end)
1134 
1135 
1136 llintOpWithReturn(op_unsigned, OpUnsigned, macro (size, get, dispatch, return)
1137     get(m_operand, t1)
1138     loadConstantOrVariablePayload(size, t1, Int32Tag, t2, .opUnsignedSlow)
1139     bilt t2, 0, .opUnsignedSlow
1140     return (Int32Tag, t2)
1141 .opUnsignedSlow:
1142     callSlowPath(_slow_path_unsigned)
1143     dispatch()
</pre>
<hr />
<pre>
1388 .opGetByIdUnset:
1389     bbneq t1, constexpr GetByIdMode::Unset, .opGetByIdDefault
1390     loadi OpGetById::Metadata::m_modeMetadata.unsetMode.structureID[t5], t1
1391     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1392     bineq JSCell::m_structureID[t3], t1, .opGetByIdSlow
1393     valueProfile(OpGetById, t5, UndefinedTag, 0)
1394     return(UndefinedTag, 0)
1395 
1396 .opGetByIdDefault:
1397     loadi OpGetById::Metadata::m_modeMetadata.defaultMode.structureID[t5], t1
1398     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1399     loadis OpGetById::Metadata::m_modeMetadata.defaultMode.cachedOffset[t5], t2
1400     bineq JSCell::m_structureID[t3], t1, .opGetByIdSlow
1401     loadPropertyAtVariableOffset(t2, t3, t0, t1)
1402     valueProfile(OpGetById, t5, t0, t1)
1403     return(t0, t1)
1404 
1405 .opGetByIdSlow:
1406     callSlowPath(_llint_slow_path_get_by_id)
1407     dispatch()







1408 end)
1409 
1410 
1411 llintOpWithMetadata(op_put_by_id, OpPutById, macro (size, get, dispatch, metadata, return)
1412     writeBarrierOnOperands(size, get, m_base, m_value)
1413     metadata(t5, t3)
1414     get(m_base, t3)
1415     loadConstantOrVariablePayload(size, t3, CellTag, t0, .opPutByIdSlow)
1416     loadi JSCell::m_structureID[t0], t2
1417     bineq t2, OpPutById::Metadata::m_oldStructureID[t5], .opPutByIdSlow
1418 
1419     # At this point, we have:
1420     # t5 -&gt; metadata
1421     # t2 -&gt; currentStructureID
1422     # t0 -&gt; object base
1423     # We will lose currentStructureID in the shenanigans below.
1424 
1425     loadi OpPutById::Metadata::m_newStructureID[t5], t1
1426 
1427     btiz t1, .opPutByIdNotTransition
</pre>
<hr />
<pre>
1450 .opPutByIdTransitionDirect:
1451     storei t1, JSCell::m_structureID[t0]
1452     get(m_value, t1)
1453     loadConstantOrVariable(size, t1, t2, t3)
1454     loadi OpPutById::Metadata::m_offset[t5], t1
1455     storePropertyAtVariableOffset(t1, t0, t2, t3)
1456     writeBarrierOnOperand(size, get, m_base)
1457     dispatch()
1458 
1459 .opPutByIdNotTransition:
1460     # The only thing live right now is t0, which holds the base.
1461     get(m_value, t1)
1462     loadConstantOrVariable(size, t1, t2, t3)
1463     loadi OpPutById::Metadata::m_offset[t5], t1
1464     storePropertyAtVariableOffset(t1, t0, t2, t3)
1465     dispatch()
1466 
1467 .opPutByIdSlow:
1468     callSlowPath(_llint_slow_path_put_by_id)
1469     dispatch()





1470 end)
1471 
1472 
1473 llintOpWithMetadata(op_get_by_val, OpGetByVal, macro (size, get, dispatch, metadata, return)
1474     metadata(t5, t2)
1475     get(m_base, t2)
1476     loadConstantOrVariablePayload(size, t2, CellTag, t0, .opGetByValSlow)
1477     move t0, t2
1478     arrayProfile(OpGetByVal::Metadata::m_arrayProfile, t2, t5, t1)
1479     get(m_property, t3)
1480     loadConstantOrVariablePayload(size, t3, Int32Tag, t1, .opGetByValSlow)
1481     loadp JSObject::m_butterfly[t0], t3
1482     andi IndexingShapeMask, t2
1483     bieq t2, Int32Shape, .opGetByValIsContiguous
1484     bineq t2, ContiguousShape, .opGetByValNotContiguous
1485 
1486 .opGetByValIsContiguous:
1487     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t3], .opGetByValSlow
1488     loadi TagOffset[t3, t1, 8], t2
1489     loadi PayloadOffset[t3, t1, 8], t1
</pre>
<hr />
<pre>
1501 
1502 .opGetByValNotDouble:
1503     subi ArrayStorageShape, t2
1504     bia t2, SlowPutArrayStorageShape - ArrayStorageShape, .opGetByValSlow
1505     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t3], .opGetByValSlow
1506     loadi ArrayStorage::m_vector + TagOffset[t3, t1, 8], t2
1507     loadi ArrayStorage::m_vector + PayloadOffset[t3, t1, 8], t1
1508 
1509 .opGetByValDone:
1510     get(m_dst, t0)
1511     bieq t2, EmptyValueTag, .opGetByValSlow
1512 .opGetByValNotEmpty:
1513     storei t2, TagOffset[cfr, t0, 8]
1514     storei t1, PayloadOffset[cfr, t0, 8]
1515     valueProfile(OpGetByVal, t5, t2, t1)
1516     dispatch()
1517 
1518 .opGetByValSlow:
1519     callSlowPath(_llint_slow_path_get_by_val)
1520     dispatch()







1521 end)
1522 
1523 
<span class="line-modified">1524 macro putByValOp(opcodeName, opcodeStruct)</span>
1525     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)
1526         macro contiguousPutByVal(storeCallback)
1527             biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], .outOfBounds
1528         .storeResult:
1529             get(m_value, t2)
1530             storeCallback(t2, t1, t0, t3)
1531             dispatch()
1532 
1533         .outOfBounds:
1534             biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t0], .opPutByValOutOfBounds
1535             storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_mayStoreToHole[t5]
1536             addi 1, t3, t2
1537             storei t2, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0]
1538             jmp .storeResult
1539         end
1540 
1541         writeBarrierOnOperands(size, get, m_base, m_value)
1542         metadata(t5, t0)
1543         get(m_base, t0)
1544         loadConstantOrVariablePayload(size, t0, CellTag, t1, .opPutByValSlow)
</pre>
<hr />
<pre>
1548         loadConstantOrVariablePayload(size, t0, Int32Tag, t3, .opPutByValSlow)
1549         loadp JSObject::m_butterfly[t1], t0
1550         btinz t2, CopyOnWrite, .opPutByValSlow
1551         andi IndexingShapeMask, t2
1552         bineq t2, Int32Shape, .opPutByValNotInt32
1553         contiguousPutByVal(
1554             macro (operand, scratch, base, index)
1555                 loadConstantOrVariablePayload(size, operand, Int32Tag, scratch, .opPutByValSlow)
1556                 storei Int32Tag, TagOffset[base, index, 8]
1557                 storei scratch, PayloadOffset[base, index, 8]
1558             end)
1559 
1560     .opPutByValNotInt32:
1561         bineq t2, DoubleShape, .opPutByValNotDouble
1562         contiguousPutByVal(
1563             macro (operand, scratch, base, index)
1564                 const tag = scratch
1565                 const payload = operand
1566                 loadConstantOrVariable2Reg(size, operand, tag, payload)
1567                 bineq tag, Int32Tag, .notInt
<span class="line-modified">1568                 ci2d payload, ft0</span>
1569                 jmp .ready
1570             .notInt:
1571                 fii2d payload, tag, ft0
1572                 bdnequn ft0, ft0, .opPutByValSlow
1573             .ready:
1574                 stored ft0, [base, index, 8]
1575             end)
1576 
1577     .opPutByValNotDouble:
1578         bineq t2, ContiguousShape, .opPutByValNotContiguous
1579         contiguousPutByVal(
1580             macro (operand, scratch, base, index)
1581                 const tag = scratch
1582                 const payload = operand
1583                 loadConstantOrVariable2Reg(size, operand, tag, payload)
1584                 storei tag, TagOffset[base, index, 8]
1585                 storei payload, PayloadOffset[base, index, 8]
1586             end)
1587 
1588     .opPutByValNotContiguous:
</pre>
<hr />
<pre>
1592     .opPutByValArrayStorageStoreResult:
1593         get(m_value, t2)
1594         loadConstantOrVariable2Reg(size, t2, t1, t2)
1595         storei t1, ArrayStorage::m_vector + TagOffset[t0, t3, 8]
1596         storei t2, ArrayStorage::m_vector + PayloadOffset[t0, t3, 8]
1597         dispatch()
1598 
1599     .opPutByValArrayStorageEmpty:
1600         storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_mayStoreToHole[t5]
1601         addi 1, ArrayStorage::m_numValuesInVector[t0]
1602         bib t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], .opPutByValArrayStorageStoreResult
1603         addi 1, t3, t1
1604         storei t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0]
1605         jmp .opPutByValArrayStorageStoreResult
1606 
1607     .opPutByValOutOfBounds:
1608         storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_outOfBounds[t5]
1609     .opPutByValSlow:
1610         callSlowPath(_llint_slow_path_%opcodeName%)
1611         dispatch()



1612     end)
1613 end
1614 
1615 
<span class="line-modified">1616 putByValOp(put_by_val, OpPutByVal)</span>




1617 
<span class="line-modified">1618 putByValOp(put_by_val_direct, OpPutByValDirect)</span>
1619 
1620 
1621 macro llintJumpTrueOrFalseOp(opcodeName, opcodeStruct, conditionOp)
1622     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1623         get(m_condition, t1)
1624         loadConstantOrVariablePayload(size, t1, BooleanTag, t0, .slow)
1625         conditionOp(t0, .target)
1626         dispatch()
1627 
1628     .target:
1629         jump(m_targetLabel)
1630 
1631     .slow:
1632         callSlowPath(_llint_slow_path_%opcodeName%)
1633         nextInstruction()
1634     end)
1635 end
1636 
1637 
1638 macro equalNullJumpOp(opcodeName, opcodeStruct, cellHandler, immediateHandler)
</pre>
<hr />
<pre>
1680     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1681         get(m_value, t1)
1682         loadConstantOrVariableTag(size, t1, t0)
1683         ori 1, t0
1684         fn(t0, .target)
1685         dispatch()
1686 
1687     .target:
1688         jump(m_targetLabel)
1689     end)
1690 end
1691 
1692 undefinedOrNullJumpOp(jundefined_or_null, OpJundefinedOrNull,
1693     macro (value, target) bieq value, NullTag, target end)
1694 
1695 undefinedOrNullJumpOp(jnundefined_or_null, OpJnundefinedOrNull,
1696     macro (value, target) bineq value, NullTag, target end)
1697 
1698 llintOpWithMetadata(op_jneq_ptr, OpJneqPtr, macro (size, get, dispatch, metadata, return)
1699     get(m_value, t0)
<span class="line-modified">1700     getu(size, OpJneqPtr, m_specialPointer, t1)</span>
<span class="line-modified">1701     loadp CodeBlock[cfr], t2</span>
<span class="line-removed">1702     loadp CodeBlock::m_globalObject[t2], t2</span>
1703     bineq TagOffset[cfr, t0, 8], CellTag, .opJneqPtrBranch
<span class="line-modified">1704     loadp JSGlobalObject::m_specialPointers[t2, t1, 4], t1</span>
<span class="line-removed">1705     bpeq PayloadOffset[cfr, t0, 8], t1, .opJneqPtrFallThrough</span>
1706 .opJneqPtrBranch:
1707     metadata(t5, t2)
1708     storeb 1, OpJneqPtr::Metadata::m_hasJumped[t5]
1709     get(m_targetLabel, t0)
<span class="line-modified">1710     jumpImpl(t0)</span>
1711 .opJneqPtrFallThrough:
1712     dispatch()
1713 end)
1714 
1715 
1716 macro compareUnsignedJumpOp(opcodeName, opcodeStruct, integerCompare)
1717     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1718         get(m_lhs, t2)
1719         get(m_rhs, t3)
1720         loadConstantOrVariable(size, t2, t0, t1)
1721         loadConstantOrVariable2Reg(size, t3, t2, t3)
1722         integerCompare(t1, t3, .jumpTarget)
1723         dispatch()
1724 
1725     .jumpTarget:
1726         jump(m_targetLabel)
1727     end)
1728 end
1729 
1730 
</pre>
<hr />
<pre>
1738         return(BooleanTag, t0)
1739     end)
1740 end
1741 
1742 
1743 macro compareJumpOp(opcodeName, opcodeStruct, integerCompare, doubleCompare)
1744     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1745         get(m_lhs, t2)
1746         get(m_rhs, t3)
1747         loadConstantOrVariable(size, t2, t0, t1)
1748         loadConstantOrVariable2Reg(size, t3, t2, t3)
1749         bineq t0, Int32Tag, .op1NotInt
1750         bineq t2, Int32Tag, .op2NotInt
1751         integerCompare(t1, t3, .jumpTarget)
1752         dispatch()
1753 
1754     .op1NotInt:
1755         bia t0, LowestTag, .slow
1756         bib t2, LowestTag, .op1NotIntOp2Double
1757         bineq t2, Int32Tag, .slow
<span class="line-modified">1758         ci2d t3, ft1</span>
1759         jmp .op1NotIntReady
1760     .op1NotIntOp2Double:
1761         fii2d t3, t2, ft1
1762     .op1NotIntReady:
1763         fii2d t1, t0, ft0
1764         doubleCompare(ft0, ft1, .jumpTarget)
1765         dispatch()
1766 
1767     .op2NotInt:
<span class="line-modified">1768         ci2d t1, ft0</span>
1769         bia t2, LowestTag, .slow
1770         fii2d t3, t2, ft1
1771         doubleCompare(ft0, ft1, .jumpTarget)
1772         dispatch()
1773 
1774     .jumpTarget:
1775         jump(m_targetLabel)
1776 
1777     .slow:
1778         callSlowPath(_llint_slow_path_%opcodeName%)
1779         nextInstruction()
1780     end)
1781 end
1782 
1783 
1784 llintOpWithJump(op_switch_imm, OpSwitchImm, macro (size, get, jump, dispatch)
1785     get(m_scrutinee, t2)
1786     getu(size, OpSwitchImm, m_tableIndex, t3)
1787     loadConstantOrVariable(size, t2, t1, t0)
1788     loadp CodeBlock[cfr], t2
</pre>
<hr />
<pre>
1860 end
1861 
1862 macro commonCallOp(opcodeName, slowPath, opcodeStruct, prepareCall, prologue)
1863     llintOpWithMetadata(opcodeName, opcodeStruct, macro (size, get, dispatch, metadata, return)
1864         metadata(t5, t0)
1865 
1866         prologue(macro (fieldName, dst)
1867             getu(size, opcodeStruct, fieldName, dst)
1868         end, metadata)
1869 
1870         get(m_callee, t0)
1871         loadp %opcodeStruct%::Metadata::m_callLinkInfo.m_calleeOrLastSeenCalleeWithLinkBit[t5], t2
1872         loadConstantOrVariablePayload(size, t0, CellTag, t3, .opCallSlow)
1873         bineq t3, t2, .opCallSlow
1874         getu(size, opcodeStruct, m_argv, t3)
1875         lshifti 3, t3
1876         negi t3
1877         addp cfr, t3  # t3 contains the new value of cfr
1878         storei t2, Callee + PayloadOffset[t3]
1879         getu(size, opcodeStruct, m_argc, t2)
<span class="line-modified">1880         storei PC, ArgumentCount + TagOffset[cfr]</span>
<span class="line-modified">1881         storei t2, ArgumentCount + PayloadOffset[t3]</span>
1882         storei CellTag, Callee + TagOffset[t3]
1883         move t3, sp
1884         prepareCall(%opcodeStruct%::Metadata::m_callLinkInfo.m_machineCodeTarget[t5], t2, t3, t4, JSEntryPtrTag)
<span class="line-modified">1885         callTargetFunction(size, opcodeStruct, dispatch, %opcodeStruct%::Metadata::m_callLinkInfo.m_machineCodeTarget[t5], JSEntryPtrTag)</span>
1886 
1887     .opCallSlow:
<span class="line-modified">1888         slowPathForCall(size, opcodeStruct, dispatch, slowPath, prepareCall)</span>
1889     end)
1890 end
1891 
1892 llintOp(op_ret, OpRet, macro (size, get, dispatch)
1893     checkSwitchToJITForEpilogue()
1894     get(m_value, t2)
1895     loadConstantOrVariable(size, t2, t1, t0)
1896     doReturn()
1897 end)
1898 
1899 
1900 llintOpWithReturn(op_to_primitive, OpToPrimitive, macro (size, get, dispatch, return)
1901     get(m_src, t2)
1902     loadConstantOrVariable(size, t2, t1, t0)
1903     bineq t1, CellTag, .opToPrimitiveIsImm
1904     bbaeq JSCell::m_type[t0], ObjectType, .opToPrimitiveSlowCase
1905 .opToPrimitiveIsImm:
1906     return(t1, t0)
1907 
1908 .opToPrimitiveSlowCase:
1909     callSlowPath(_slow_path_to_primitive)
1910     dispatch()
1911 end)
1912 
1913 
















1914 commonOp(llint_op_catch, macro() end, macro (size)
1915     # This is where we end up from the JIT&#39;s throw trampoline (because the
1916     # machine code return address will be set to _llint_op_catch), and from
1917     # the interpreter&#39;s throw trampoline (see _llint_throw_trampoline).
1918     # The throwing code must have known that we were throwing to the interpreter,
1919     # and have set VM::targetInterpreterPCForThrow.
1920     loadp Callee + PayloadOffset[cfr], t3
<span class="line-modified">1921     andp MarkedBlockMask, t3</span>
<span class="line-removed">1922     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3</span>
1923     restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(t3, t0)
1924     loadp VM::callFrameForCatch[t3], cfr
1925     storep 0, VM::callFrameForCatch[t3]
1926     restoreStackPointerAfterCall()
1927 
1928     # restore metadataTable since we don&#39;t restore callee saves for CLoop during unwinding
1929     loadp CodeBlock[cfr], t1
1930     loadp CodeBlock::m_metadata[t1], metadataTable

1931 
<span class="line-modified">1932     loadi VM::targetInterpreterPCForThrow[t3], PC</span>

1933 
1934     callSlowPath(_llint_slow_path_check_if_exception_is_uncatchable_and_notify_profiler)
1935     bpeq r1, 0, .isCatchableException
1936     jmp _llint_throw_from_slow_path_trampoline
1937 
1938 .isCatchableException:
<span class="line-modified">1939     loadp Callee + PayloadOffset[cfr], t3</span>
<span class="line-modified">1940     andp MarkedBlockMask, t3</span>
<span class="line-removed">1941     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3</span>
1942 
1943     loadp VM::m_exception[t3], t0
1944     storep 0, VM::m_exception[t3]
1945     get(size, OpCatch, m_exception, t2)
1946     storei t0, PayloadOffset[cfr, t2, 8]
1947     storei CellTag, TagOffset[cfr, t2, 8]
1948 
1949     loadi Exception::m_value + TagOffset[t0], t1
1950     loadi Exception::m_value + PayloadOffset[t0], t0
1951     get(size, OpCatch, m_thrownValue, t2)
1952     storei t0, PayloadOffset[cfr, t2, 8]
1953     storei t1, TagOffset[cfr, t2, 8]
1954 
1955     traceExecution()  # This needs to be here because we don&#39;t want to clobber t0, t1, t2, t3 above.
1956 
1957     callSlowPath(_llint_slow_path_profile_catch)
1958 
1959     dispatchOp(size, op_catch)
1960 end)
1961 
1962 llintOp(op_end, OpEnd, macro (size, get, dispatch)
1963     checkSwitchToJITForEpilogue()
1964     get(m_value, t0)
1965     assertNotConstant(size, t0)
1966     loadi TagOffset[cfr, t0, 8], t1
1967     loadi PayloadOffset[cfr, t0, 8], t0
1968     doReturn()
1969 end)
1970 
1971 
1972 op(llint_throw_from_slow_path_trampoline, macro()
1973     loadp Callee[cfr], t1
<span class="line-modified">1974     andp MarkedBlockMask, t1</span>
<span class="line-removed">1975     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1</span>
1976     copyCalleeSavesToVMEntryFrameCalleeSavesBuffer(t1, t2)
1977 
1978     callSlowPath(_llint_slow_path_handle_exception)
1979 
1980     # When throwing from the interpreter (i.e. throwing from LLIntSlowPaths), so
1981     # the throw target is not necessarily interpreted code, we come to here.
1982     # This essentially emulates the JIT&#39;s throwing protocol.
1983     loadp Callee[cfr], t1
<span class="line-modified">1984     andp MarkedBlockMask, t1</span>
<span class="line-removed">1985     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1</span>
1986     jmp VM::targetMachinePCForThrow[t1]
1987 end)
1988 
1989 
1990 op(llint_throw_during_call_trampoline, macro()
1991     preserveReturnAddressAfterCall(t2)
1992     jmp _llint_throw_from_slow_path_trampoline
1993 end)
1994 
1995 
1996 macro nativeCallTrampoline(executableOffsetToFunction)
<span class="line-removed">1997 </span>
1998     functionPrologue()
1999     storep 0, CodeBlock[cfr]
<span class="line-modified">2000     loadi Callee + PayloadOffset[cfr], t1</span>
<span class="line-removed">2001     // Callee is still in t1 for code below</span>
2002     if X86 or X86_WIN
2003         subp 8, sp # align stack pointer
<span class="line-modified">2004         andp MarkedBlockMask, t1</span>
<span class="line-modified">2005         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t3</span>
<span class="line-removed">2006         storep cfr, VM::topCallFrame[t3]</span>
<span class="line-removed">2007         move cfr, a0  # a0 = ecx</span>
<span class="line-removed">2008         storep a0, [sp]</span>
<span class="line-removed">2009         loadi Callee + PayloadOffset[cfr], t1</span>
<span class="line-removed">2010         loadp JSFunction::m_executable[t1], t1</span>
<span class="line-removed">2011         checkStackPointerAlignment(t3, 0xdead0001)</span>
<span class="line-removed">2012         call executableOffsetToFunction[t1]</span>
<span class="line-removed">2013         loadp Callee + PayloadOffset[cfr], t3</span>
<span class="line-removed">2014         andp MarkedBlockMask, t3</span>
<span class="line-removed">2015         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3</span>
<span class="line-removed">2016         addp 8, sp</span>
<span class="line-removed">2017     elsif ARMv7 or C_LOOP or C_LOOP_WIN or MIPS</span>
<span class="line-removed">2018         if MIPS</span>
2019         # calling convention says to save stack space for 4 first registers in
2020         # all cases. To match our 16-byte alignment, that means we need to
2021         # take 24 bytes
<span class="line-modified">2022             subp 24, sp</span>
<span class="line-removed">2023         else</span>
<span class="line-removed">2024             subp 8, sp # align stack pointer</span>
<span class="line-removed">2025         end</span>
<span class="line-removed">2026         # t1 already contains the Callee.</span>
<span class="line-removed">2027         andp MarkedBlockMask, t1</span>
<span class="line-removed">2028         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1</span>
<span class="line-removed">2029         storep cfr, VM::topCallFrame[t1]</span>
<span class="line-removed">2030         move cfr, a0</span>
<span class="line-removed">2031         loadi Callee + PayloadOffset[cfr], t1</span>
<span class="line-removed">2032         loadp JSFunction::m_executable[t1], t1</span>
<span class="line-removed">2033         checkStackPointerAlignment(t3, 0xdead0001)</span>
<span class="line-removed">2034         if C_LOOP or C_LOOP_WIN</span>
<span class="line-removed">2035             cloopCallNative executableOffsetToFunction[t1]</span>
<span class="line-removed">2036         else</span>
<span class="line-removed">2037             call executableOffsetToFunction[t1]</span>
<span class="line-removed">2038         end</span>
<span class="line-removed">2039         loadp Callee + PayloadOffset[cfr], t3</span>
<span class="line-removed">2040         andp MarkedBlockMask, t3</span>
<span class="line-removed">2041         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3</span>
<span class="line-removed">2042         if MIPS</span>
<span class="line-removed">2043             addp 24, sp</span>
<span class="line-removed">2044         else</span>
<span class="line-removed">2045             addp 8, sp</span>
<span class="line-removed">2046         end</span>
2047     else
<span class="line-modified">2048         error</span>
2049     end
<span class="line-modified">2050     </span>



























2051     btpnz VM::m_exception[t3], .handleException
2052 
2053     functionEpilogue()
2054     ret
2055 
2056 .handleException:
<span class="line-modified">2057 if X86 or X86_WIN</span>
<span class="line-modified">2058     subp 8, sp # align stack pointer</span>
<span class="line-modified">2059 end</span>
2060     storep cfr, VM::topCallFrame[t3]
2061     jmp _llint_throw_from_slow_path_trampoline
2062 end
2063 
2064 
2065 macro internalFunctionCallTrampoline(offsetOfFunction)
2066     functionPrologue()
2067     storep 0, CodeBlock[cfr]
<span class="line-modified">2068     loadi Callee + PayloadOffset[cfr], t1</span>
2069     // Callee is still in t1 for code below
2070     if X86 or X86_WIN
2071         subp 8, sp # align stack pointer
<span class="line-modified">2072         andp MarkedBlockMask, t1</span>
<span class="line-modified">2073         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t3</span>
<span class="line-removed">2074         storep cfr, VM::topCallFrame[t3]</span>
<span class="line-removed">2075         move cfr, a0  # a0 = ecx</span>
<span class="line-removed">2076         storep a0, [sp]</span>
<span class="line-removed">2077         loadi Callee + PayloadOffset[cfr], t1</span>
<span class="line-removed">2078         checkStackPointerAlignment(t3, 0xdead0001)</span>
<span class="line-removed">2079         call offsetOfFunction[t1]</span>
<span class="line-removed">2080         loadp Callee + PayloadOffset[cfr], t3</span>
<span class="line-removed">2081         andp MarkedBlockMask, t3</span>
<span class="line-removed">2082         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3</span>
<span class="line-removed">2083         addp 8, sp</span>
<span class="line-removed">2084     elsif ARMv7 or C_LOOP or C_LOOP_WIN or MIPS</span>
2085         subp 8, sp # align stack pointer
<span class="line-modified">2086         # t1 already contains the Callee.</span>
<span class="line-modified">2087         andp MarkedBlockMask, t1</span>
<span class="line-modified">2088         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1</span>
<span class="line-modified">2089         storep cfr, VM::topCallFrame[t1]</span>
<span class="line-modified">2090         move cfr, a0</span>
<span class="line-modified">2091         loadi Callee + PayloadOffset[cfr], t1</span>
<span class="line-modified">2092         checkStackPointerAlignment(t3, 0xdead0001)</span>
<span class="line-modified">2093         if C_LOOP or C_LOOP_WIN</span>
<span class="line-modified">2094             cloopCallNative offsetOfFunction[t1]</span>
<span class="line-modified">2095         else</span>
<span class="line-modified">2096             call offsetOfFunction[t1]</span>
<span class="line-removed">2097         end</span>
<span class="line-removed">2098         loadp Callee + PayloadOffset[cfr], t3</span>
<span class="line-removed">2099         andp MarkedBlockMask, t3</span>
<span class="line-removed">2100         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3</span>
<span class="line-removed">2101         addp 8, sp</span>
2102     else
<span class="line-modified">2103         error</span>
2104     end
2105 






2106     btpnz VM::m_exception[t3], .handleException
2107 
2108     functionEpilogue()
2109     ret
2110 
2111 .handleException:
<span class="line-modified">2112 if X86 or X86_WIN</span>
<span class="line-modified">2113     subp 8, sp # align stack pointer</span>
<span class="line-modified">2114 end</span>
2115     storep cfr, VM::topCallFrame[t3]
2116     jmp _llint_throw_from_slow_path_trampoline
2117 end
2118 
2119 
2120 macro varInjectionCheck(slowPath)
2121     loadp CodeBlock[cfr], t0
2122     loadp CodeBlock::m_globalObject[t0], t0
2123     loadp JSGlobalObject::m_varInjectionWatchpoint[t0], t0
2124     bbeq WatchpointSet::m_state[t0], IsInvalidated, slowPath
2125 end
2126 
2127 
2128 llintOpWithMetadata(op_resolve_scope, OpResolveScope, macro (size, get, dispatch, metadata, return)
2129 
2130     macro getConstantScope(dst)
2131         loadp OpResolveScope::Metadata::m_constantScope[t5], dst
2132     end
2133 
2134     macro returnConstantScope()
</pre>
<hr />
<pre>
2498     bpneq t2, t1, .opProfileTypeDone
2499     callSlowPath(_slow_path_profile_type_clear_log)
2500 
2501 .opProfileTypeDone:
2502     dispatch()
2503 end)
2504 
2505 
2506 llintOpWithMetadata(op_profile_control_flow, OpProfileControlFlow, macro (size, get, dispatch, metadata, return)
2507     metadata(t5, t0)
2508     loadp OpProfileControlFlow::Metadata::m_basicBlockLocation[t5], t0
2509     loadi BasicBlockLocation::m_executionCount[t0], t1
2510     baddio 1, t1, .done
2511     storei t1, BasicBlockLocation::m_executionCount[t0]
2512 .done:
2513     dispatch()
2514 end)
2515 
2516 
2517 llintOpWithReturn(op_get_rest_length, OpGetRestLength, macro (size, get, dispatch, return)
<span class="line-modified">2518     loadi PayloadOffset + ArgumentCount[cfr], t0</span>
2519     subi 1, t0
2520     getu(size, OpGetRestLength, m_numParametersToSkip, t1)
2521     bilteq t0, t1, .storeZero
2522     subi t1, t0
2523     jmp .finish
2524 .storeZero:
2525     move 0, t0
2526 .finish:
2527     return(Int32Tag, t0)
2528 end)
2529 
2530 






















2531 llintOp(op_log_shadow_chicken_prologue, OpLogShadowChickenPrologue, macro (size, get, dispatch)
2532     acquireShadowChickenPacket(.opLogShadowChickenPrologueSlow)
2533     storep cfr, ShadowChicken::Packet::frame[t0]
2534     loadp CallerFrame[cfr], t1
2535     storep t1, ShadowChicken::Packet::callerFrame[t0]
2536     loadp Callee + PayloadOffset[cfr], t1
2537     storep t1, ShadowChicken::Packet::callee[t0]
2538     get(m_scope, t1)
2539     loadi PayloadOffset[cfr, t1, 8], t1
2540     storep t1, ShadowChicken::Packet::scope[t0]
2541     dispatch()
2542 .opLogShadowChickenPrologueSlow:
2543     callSlowPath(_llint_slow_path_log_shadow_chicken_prologue)
2544     dispatch()
2545 end)
2546 
2547 
2548 llintOp(op_log_shadow_chicken_tail, OpLogShadowChickenTail, macro (size, get, dispatch)
2549     acquireShadowChickenPacket(.opLogShadowChickenTailSlow)
2550     storep cfr, ShadowChicken::Packet::frame[t0]
</pre>
</td>
<td>
<hr />
<pre>
   6 # 1. Redistributions of source code must retain the above copyright
   7 #    notice, this list of conditions and the following disclaimer.
   8 # 2. Redistributions in binary form must reproduce the above copyright
   9 #    notice, this list of conditions and the following disclaimer in the
  10 #    documentation and/or other materials provided with the distribution.
  11 #
  12 # THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
  13 # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
  14 # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  15 # PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
  16 # BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  17 # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  18 # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
  19 # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
  20 # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
  21 # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
  22 # THE POSSIBILITY OF SUCH DAMAGE.
  23 
  24 
  25 # Utilities
<span class="line-modified">  26 # FIXME:  Merge &quot;getOperand&quot; macros on 32 and 64 bits LLInt</span>
<span class="line-modified">  27 # https://bugs.webkit.org/show_bug.cgi?id=206342</span>















  28 
  29 macro getuOperandNarrow(opcodeStruct, fieldName, dst)
<span class="line-modified">  30     loadb constexpr %opcodeStruct%_%fieldName%_index + OpcodeIDNarrowSize[PB, PC, 1], dst</span>
  31 end
  32 
  33 macro getOperandNarrow(opcodeStruct, fieldName, dst)
<span class="line-modified">  34     loadbsi constexpr %opcodeStruct%_%fieldName%_index + OpcodeIDNarrowSize[PB, PC, 1], dst</span>
  35 end
  36 
  37 macro getuOperandWide16(opcodeStruct, fieldName, dst)
<span class="line-modified">  38     loadh constexpr %opcodeStruct%_%fieldName%_index * 2 + OpcodeIDWide16Size[PB, PC, 1], dst</span>
  39 end
  40 
  41 macro getOperandWide16(opcodeStruct, fieldName, dst)
<span class="line-modified">  42     loadhsi constexpr %opcodeStruct%_%fieldName%_index * 2 + OpcodeIDWide16Size[PB, PC, 1], dst</span>
  43 end
  44 
  45 macro getuOperandWide32(opcodeStruct, fieldName, dst)
<span class="line-modified">  46     loadi constexpr %opcodeStruct%_%fieldName%_index * 4 + OpcodeIDWide32Size[PB, PC, 1], dst</span>
  47 end
  48 
  49 macro getOperandWide32(opcodeStruct, fieldName, dst)
<span class="line-modified">  50     loadis constexpr %opcodeStruct%_%fieldName%_index * 4 + OpcodeIDWide32Size[PB, PC, 1], dst</span>
  51 end
  52 
  53 macro makeReturn(get, dispatch, fn)
  54     fn(macro(tag, payload)
  55         move tag, t5
  56         move payload, t3
  57         get(m_dst, t2)
  58         storei t5, TagOffset[cfr, t2, 8]
  59         storei t3, PayloadOffset[cfr, t2, 8]
  60         dispatch()
  61     end)
  62 end
  63 
  64 macro makeReturnProfiled(opcodeStruct, get, metadata, dispatch, fn)
  65     fn(macro (tag, payload)
  66         move tag, t1
  67         move payload, t0
  68 
  69         metadata(t5, t2)
  70         valueProfile(opcodeStruct, t5, t1, t0)
  71         get(m_dst, t2)
  72         storei t1, TagOffset[cfr, t2, 8]
  73         storei t0, PayloadOffset[cfr, t2, 8]
  74         dispatch()
  75     end)
  76 end
  77 
  78 
<span class="line-added">  79 # After calling, calling bytecode is claiming input registers are not used.</span>
  80 macro dispatchAfterCall(size, opcodeStruct, dispatch)
<span class="line-modified">  81     loadi ArgumentCountIncludingThis + TagOffset[cfr], PC</span>
<span class="line-added">  82     loadp CodeBlock[cfr], PB</span>
<span class="line-added">  83     loadp CodeBlock::m_instructionsRawPointer[PB], PB</span>
  84     get(size, opcodeStruct, m_dst, t3)
  85     storei r1, TagOffset[cfr, t3, 8]
  86     storei r0, PayloadOffset[cfr, t3, 8]
  87     metadata(size, opcodeStruct, t2, t3)
  88     valueProfile(opcodeStruct, t2, r1, r0)
  89     dispatch()
  90 end
  91 
  92 macro cCall2(function)
  93     if ARMv7 or MIPS
  94         call function
  95     elsif X86 or X86_WIN
  96         subp 8, sp
  97         push a1
  98         push a0
  99         call function
 100         addp 16, sp
 101     elsif C_LOOP or C_LOOP_WIN
 102         cloopCallSlowPath function, a0, a1
 103     else
</pre>
<hr />
<pre>
 113     end
 114 end
 115 
 116 macro cCall4(function)
 117     if ARMv7 or MIPS
 118         call function
 119     elsif X86 or X86_WIN
 120         push a3
 121         push a2
 122         push a1
 123         push a0
 124         call function
 125         addp 16, sp
 126     elsif C_LOOP or C_LOOP_WIN
 127         error
 128     else
 129         error
 130     end
 131 end
 132 
<span class="line-added"> 133 macro prepareStateForCCall()</span>
<span class="line-added"> 134     addp PB, PC</span>
<span class="line-added"> 135 end</span>
<span class="line-added"> 136 </span>
<span class="line-added"> 137 macro restoreStateAfterCCall()</span>
<span class="line-added"> 138     move r0, PC</span>
<span class="line-added"> 139     subp PB, PC</span>
<span class="line-added"> 140 end</span>
<span class="line-added"> 141 </span>
 142 macro callSlowPath(slowPath)
<span class="line-added"> 143     prepareStateForCCall()</span>
 144     move cfr, a0
 145     move PC, a1
 146     cCall2(slowPath)
<span class="line-modified"> 147     restoreStateAfterCCall()</span>
 148 end
 149 
 150 macro doVMEntry(makeCall)
 151     functionPrologue()
 152     pushCalleeSaves()
 153 
 154     # x86 needs to load arguments from the stack
 155     if X86 or X86_WIN
 156         loadp 16[cfr], a2
 157         loadp 12[cfr], a1
 158         loadp 8[cfr], a0
 159     end
 160 
 161     const entry = a0
 162     const vm = a1
 163     const protoCallFrame = a2
 164 
 165     # We are using t3, t4 and t5 as temporaries through the function.
 166     # Since we have the guarantee that tX != aY when X != Y, we are safe from
 167     # aliasing problems with our arguments.
</pre>
<hr />
<pre>
 243     storei UndefinedTag, ThisArgumentOffset + 8 + TagOffset[sp, t5, 8]
 244     storei 0, ThisArgumentOffset + 8 + PayloadOffset[sp, t5, 8]
 245     bineq t4, t5, .fillExtraArgsLoop
 246 
 247 .copyArgs:
 248     loadp ProtoCallFrame::args[protoCallFrame], t3
 249 
 250 .copyArgsLoop:
 251     btiz t4, .copyArgsDone
 252     subi 1, t4
 253     loadi TagOffset[t3, t4, 8], t5
 254     storei t5, ThisArgumentOffset + 8 + TagOffset[sp, t4, 8]
 255     loadi PayloadOffset[t3, t4, 8], t5
 256     storei t5, ThisArgumentOffset + 8 + PayloadOffset[sp, t4, 8]
 257     jmp .copyArgsLoop
 258 
 259 .copyArgsDone:
 260     storep sp, VM::topCallFrame[vm]
 261     storep cfr, VM::topEntryFrame[vm]
 262 
<span class="line-modified"> 263     makeCall(entry, protoCallFrame, t3, t4)</span>
 264 
 265     if ARMv7
 266         vmEntryRecord(cfr, t3)
 267         move t3, sp
 268     else
 269         vmEntryRecord(cfr, sp)
 270     end
 271 
 272     loadp VMEntryRecord::m_vm[sp], t5
 273     loadp VMEntryRecord::m_prevTopCallFrame[sp], t4
 274     storep t4, VM::topCallFrame[t5]
 275     loadp VMEntryRecord::m_prevTopEntryFrame[sp], t4
 276     storep t4, VM::topEntryFrame[t5]
 277 
 278     if ARMv7
 279         subp cfr, CalleeRegisterSaveSize, t5
 280         move t5, sp
 281     else
 282         subp cfr, CalleeRegisterSaveSize, sp
 283     end
</pre>
<hr />
<pre>
 300     end
 301 
 302     loadp VMEntryRecord::m_vm[sp], t5
 303     loadp VMEntryRecord::m_prevTopCallFrame[sp], t4
 304     storep t4, VM::topCallFrame[t5]
 305     loadp VMEntryRecord::m_prevTopEntryFrame[sp], t4
 306     storep t4, VM::topEntryFrame[t5]
 307 
 308     if ARMv7
 309         subp cfr, CalleeRegisterSaveSize, t5
 310         move t5, sp
 311     else
 312         subp cfr, CalleeRegisterSaveSize, sp
 313     end
 314 
 315     popCalleeSaves()
 316     functionEpilogue()
 317     ret
 318 end
 319 
<span class="line-modified"> 320 # a0, a2, t3, t4</span>
<span class="line-added"> 321 macro makeJavaScriptCall(entry, protoCallFrame, temp1, temp2)</span>
 322     addp CallerFrameAndPCSize, sp
<span class="line-modified"> 323     checkStackPointerAlignment(temp1, 0xbad0dc02)</span>
 324     if C_LOOP or C_LOOP_WIN
 325         cloopCallJSFunction entry
 326     else
 327         call entry
 328     end
<span class="line-modified"> 329     checkStackPointerAlignment(temp1, 0xbad0dc03)</span>
 330     subp CallerFrameAndPCSize, sp
 331 end
 332 
<span class="line-modified"> 333 # a0, a2, t3, t4</span>
<span class="line-added"> 334 macro makeHostFunctionCall(entry, protoCallFrame, temp1, temp2)</span>
 335     move entry, temp1
 336     storep cfr, [sp]
 337     if C_LOOP or C_LOOP_WIN
<span class="line-modified"> 338         loadp ProtoCallFrame::globalObject[protoCallFrame], a0</span>
<span class="line-added"> 339         move sp, a1</span>
 340         storep lr, PtrSize[sp]
 341         cloopCallNative temp1
 342     elsif X86 or X86_WIN
<span class="line-modified"> 343         # Put callee frame pointer on stack as arg1, also put it in ecx for &quot;fastcall&quot; targets</span>
 344         move 0, temp2
 345         move temp2, 4[sp] # put 0 in ReturnPC
<span class="line-modified"> 346         move sp, a1 # a1 is edx</span>
<span class="line-modified"> 347         loadp ProtoCallFrame::globalObject[protoCallFrame], a0</span>
<span class="line-added"> 348         push a1</span>
 349         push a0
 350         call temp1
 351         addp 8, sp
<span class="line-added"> 352     elsif MIPS</span>
<span class="line-added"> 353         move sp, a1</span>
<span class="line-added"> 354         # We need to allocate stack space for 16 bytes (8-byte aligned)</span>
<span class="line-added"> 355         # for 4 arguments, since callee can use this space.</span>
<span class="line-added"> 356         subp 16, sp</span>
<span class="line-added"> 357         loadp ProtoCallFrame::globalObject[protoCallFrame], a0</span>
<span class="line-added"> 358         call temp1</span>
<span class="line-added"> 359         addp 16, sp</span>
 360     else
<span class="line-modified"> 361         loadp ProtoCallFrame::globalObject[protoCallFrame], a0</span>
<span class="line-added"> 362         move sp, a1</span>
 363         call temp1
 364     end
 365 end
 366 
 367 op(handleUncaughtException, macro()
 368     loadp Callee + PayloadOffset[cfr], t3
<span class="line-modified"> 369     convertCalleeToVM(t3)</span>

 370     restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(t3, t0)
 371     storep 0, VM::callFrameForCatch[t3]
 372 
 373     loadp VM::topEntryFrame[t3], cfr
 374     if ARMv7
 375         vmEntryRecord(cfr, t3)
 376         move t3, sp
 377     else
 378         vmEntryRecord(cfr, sp)
 379     end
 380 
 381     loadp VMEntryRecord::m_vm[sp], t3
 382     loadp VMEntryRecord::m_prevTopCallFrame[sp], t5
 383     storep t5, VM::topCallFrame[t3]
 384     loadp VMEntryRecord::m_prevTopEntryFrame[sp], t5
 385     storep t5, VM::topEntryFrame[t3]
 386 
 387     if ARMv7
 388         subp cfr, CalleeRegisterSaveSize, t3
 389         move t3, sp
 390     else
 391         subp cfr, CalleeRegisterSaveSize, sp
 392     end
 393 
 394     popCalleeSaves()
 395     functionEpilogue()
 396     ret
 397 end)
 398 
 399 macro doReturnFromHostFunction(extraStackSpace)
 400     functionEpilogue(extraStackSpace)
 401     ret
 402 end
 403 
 404 # Debugging operation if you&#39;d like to print an operand in the instruction stream. fromWhere
 405 # should be an immediate integer - any integer you like; use it to identify the place you&#39;re
 406 # debugging from. operand should likewise be an immediate, and should identify the operand
 407 # in the instruction stream you&#39;d like to print out.
 408 macro traceOperand(fromWhere, operand)
<span class="line-added"> 409     prepareStateForCCall()</span>
 410     move fromWhere, a2
 411     move operand, a3
 412     move cfr, a0
 413     move PC, a1
 414     cCall4(_llint_trace_operand)
<span class="line-modified"> 415     restoreStateAfterCCall()</span>
 416     move r1, cfr
 417 end
 418 
 419 # Debugging operation if you&#39;d like to print the value of an operand in the instruction
 420 # stream. Same as traceOperand(), but assumes that the operand is a register, and prints its
 421 # value.
 422 macro traceValue(fromWhere, operand)
<span class="line-added"> 423     prepareStateForCCall()</span>
 424     move fromWhere, a2
 425     move operand, a3
 426     move cfr, a0
 427     move PC, a1
 428     cCall4(_llint_trace_value)
<span class="line-modified"> 429     restoreStateAfterCCall()</span>
 430     move r1, cfr
 431 end
 432 
 433 # Call a slowPath for call opcodes.
 434 macro callCallSlowPath(slowPath, action)
<span class="line-modified"> 435     storep PC, ArgumentCountIncludingThis + TagOffset[cfr]</span>
<span class="line-added"> 436     prepareStateForCCall()</span>
 437     move cfr, a0
 438     move PC, a1
 439     cCall2(slowPath)
 440     action(r0, r1)
 441 end
 442 
 443 macro callTrapHandler(throwHandler)
<span class="line-modified"> 444     storei PC, ArgumentCountIncludingThis + TagOffset[cfr]</span>
<span class="line-added"> 445     prepareStateForCCall()</span>
 446     move cfr, a0
 447     move PC, a1
 448     cCall2(_llint_slow_path_handle_traps)
 449     btpnz r0, throwHandler
<span class="line-modified"> 450     loadi ArgumentCountIncludingThis + TagOffset[cfr], PC</span>
 451 end
 452 
 453 macro checkSwitchToJITForLoop()
 454     checkSwitchToJIT(
 455         1,
 456         macro ()
<span class="line-modified"> 457             storei PC, ArgumentCountIncludingThis + TagOffset[cfr]</span>
<span class="line-added"> 458             prepareStateForCCall()</span>
 459             move cfr, a0
 460             move PC, a1
 461             cCall2(_llint_loop_osr)
 462             btpz r0, .recover
 463             move r1, sp
 464             jmp r0
 465         .recover:
<span class="line-modified"> 466             loadi ArgumentCountIncludingThis + TagOffset[cfr], PC</span>
 467         end)
 468 end
 469 
 470 macro loadVariable(get, fieldName, indexReg, tagReg, payloadReg)
 471     get(fieldName, indexReg)
 472     loadi TagOffset[cfr, indexReg, 8], tagReg
 473     loadi PayloadOffset[cfr, indexReg, 8], payloadReg
 474 end
 475 
<span class="line-added"> 476 # Index, tag, and payload must be different registers. Index is not</span>
<span class="line-added"> 477 # changed.</span>
<span class="line-added"> 478 macro loadConstant(size, index, tag, payload)</span>
<span class="line-added"> 479     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)</span>
<span class="line-added"> 480         loadp CodeBlock[cfr], payload</span>
<span class="line-added"> 481         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[payload], payload</span>
<span class="line-added"> 482         subp FirstConstantRegisterIndex, index</span>
<span class="line-added"> 483         loadp TagOffset[payload, index, 8], tag</span>
<span class="line-added"> 484         loadp PayloadOffset[payload, index, 8], payload</span>
<span class="line-added"> 485     end)</span>
<span class="line-added"> 486 end</span>
<span class="line-added"> 487 </span>
 488 # Index, tag, and payload must be different registers. Index is not
 489 # changed.
 490 macro loadConstantOrVariable(size, index, tag, payload)
 491     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)
 492         bigteq index, FirstConstantRegisterIndex, .constant
 493         loadi TagOffset[cfr, index, 8], tag
 494         loadi PayloadOffset[cfr, index, 8], payload
 495         jmp .done
 496     .constant:
<span class="line-modified"> 497         loadConstant(size, index, tag, payload)</span>




 498     .done:
 499     end)
 500 end
 501 
 502 macro loadConstantOrVariableTag(size, index, tag)
 503     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)
 504         bigteq index, FirstConstantRegisterIndex, .constant
 505         loadi TagOffset[cfr, index, 8], tag
 506         jmp .done
 507     .constant:
 508         loadp CodeBlock[cfr], tag
 509         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[tag], tag
 510         subi FirstConstantRegisterIndex, index
 511         loadp TagOffset[tag, index, 8], tag
 512     .done:
 513     end)
 514 end
 515 
 516 # Index and payload may be the same register. Index may be clobbered.
 517 macro loadConstantOrVariable2Reg(size, index, tag, payload)
</pre>
<hr />
<pre>
 556 macro loadConstantOrVariablePayload(size, index, expectedTag, payload, slow)
 557     loadConstantOrVariablePayloadTagCustom(
 558         size,
 559         index,
 560         macro (actualTag) bineq actualTag, expectedTag, slow end,
 561         payload)
 562 end
 563 
 564 macro loadConstantOrVariablePayloadUnchecked(size, index, payload)
 565     loadConstantOrVariablePayloadTagCustom(
 566         size,
 567         index,
 568         macro (actualTag) end,
 569         payload)
 570 end
 571 
 572 macro writeBarrierOnCellWithReload(cell, reloadAfterSlowPath)
 573     skipIfIsRememberedOrInEden(
 574         cell,
 575         macro()
<span class="line-modified"> 576             push PB, PC</span>
 577             # We make two extra slots because cCall2 will poke.
 578             subp 8, sp
 579             move cell, a1 # cell can be a0
 580             move cfr, a0
 581             cCall2Void(_llint_write_barrier_slow)
 582             addp 8, sp
<span class="line-modified"> 583             pop PC, PB</span>
 584             reloadAfterSlowPath()
 585         end)
 586 end
 587 
 588 macro writeBarrierOnOperand(size, get, cellFieldName)
 589     get(cellFieldName, t1)
 590     loadConstantOrVariablePayload(size, t1, CellTag, t2, .writeBarrierDone)
 591     writeBarrierOnCellWithReload(t2, macro() end)
 592 .writeBarrierDone:
 593 end
 594 
 595 macro writeBarrierOnOperands(size, get, cellFieldName, valueFieldName)
 596     get(valueFieldName, t1)
 597     loadConstantOrVariableTag(size, t1, t0)
 598     bineq t0, CellTag, .writeBarrierDone
 599 
 600     writeBarrierOnOperand(size, get, cellFieldName)
 601 .writeBarrierDone:
 602 end
 603 
</pre>
<hr />
<pre>
 622 
 623 macro writeBarrierOnGlobalLexicalEnvironment(size, get, valueFieldName)
 624     writeBarrierOnGlobal(size, get, valueFieldName,
 625         macro(registerToStoreGlobal)
 626             loadp CodeBlock[cfr], registerToStoreGlobal
 627             loadp CodeBlock::m_globalObject[registerToStoreGlobal], registerToStoreGlobal
 628             loadp JSGlobalObject::m_globalLexicalEnvironment[registerToStoreGlobal], registerToStoreGlobal
 629         end)
 630 end
 631 
 632 macro valueProfile(opcodeStruct, metadata, tag, payload)
 633     storei tag, %opcodeStruct%::Metadata::m_profile.m_buckets + TagOffset[metadata]
 634     storei payload, %opcodeStruct%::Metadata::m_profile.m_buckets + PayloadOffset[metadata]
 635 end
 636 
 637 
 638 # Entrypoints into the interpreter
 639 
 640 # Expects that CodeBlock is in t1, which is what prologue() leaves behind.
 641 macro functionArityCheck(doneLabel, slowPath)
<span class="line-modified"> 642     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t0</span>
 643     biaeq t0, CodeBlock::m_numParameters[t1], doneLabel
<span class="line-added"> 644     prepareStateForCCall()</span>
 645     move cfr, a0
 646     move PC, a1
 647     cCall2(slowPath)   # This slowPath has a simple protocol: t0 = 0 =&gt; no error, t0 != 0 =&gt; error
 648     btiz r0, .noError
 649 
 650     # We&#39;re throwing before the frame is fully set up. This frame will be
 651     # ignored by the unwinder. So, let&#39;s restore the callee saves before we
 652     # start unwinding. We need to do this before we change the cfr.
 653     restoreCalleeSavesUsedByLLInt()
 654 
 655     move r1, cfr   # r1 contains caller frame
 656     jmp _llint_throw_from_slow_path_trampoline
 657 
 658 .noError:
 659     move r1, t1 # r1 contains slotsToAdd.
 660     btiz t1, .continue
<span class="line-modified"> 661     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t2</span>
 662     addi CallFrameHeaderSlots, t2
 663 
 664     // Check if there are some unaligned slots we can use
 665     move t1, t3
 666     andi StackAlignmentSlots - 1, t3
 667     btiz t3, .noExtraSlot
 668 .fillExtraSlots:
 669     move 0, t0
 670     storei t0, PayloadOffset[cfr, t2, 8]
 671     move UndefinedTag, t0
 672     storei t0, TagOffset[cfr, t2, 8]
 673     addi 1, t2
 674     bsubinz 1, t3, .fillExtraSlots
 675     andi ~(StackAlignmentSlots - 1), t1
 676     btiz t1, .continue
 677 
 678 .noExtraSlot:
 679     // Move frame up t1 slots
 680     negi t1
 681     move cfr, t3
</pre>
<hr />
<pre>
 689     loadi PayloadOffset[t3], t0
 690     storei t0, PayloadOffset[t3, t1, 8]
 691     loadi TagOffset[t3], t0
 692     storei t0, TagOffset[t3, t1, 8]
 693     addp 8, t3
 694     bsubinz 1, t2, .copyLoop
 695 
 696     // Fill new slots with JSUndefined
 697     move t1, t2
 698 .fillLoop:
 699     move 0, t0
 700     storei t0, PayloadOffset[t3, t1, 8]
 701     move UndefinedTag, t0
 702     storei t0, TagOffset[t3, t1, 8]
 703     addp 8, t3
 704     baddinz 1, t2, .fillLoop
 705 
 706 .continue:
 707     # Reload CodeBlock and PC, since the slow_path clobbered it.
 708     loadp CodeBlock[cfr], t1
<span class="line-modified"> 709     loadp CodeBlock::m_instructionsRawPointer[t1], PB</span>
<span class="line-added"> 710     move 0, PC</span>
 711     jmp doneLabel
 712 end
 713 










 714 # Instruction implementations
 715 
 716 _llint_op_enter:
 717     traceExecution()
 718     checkStackPointerAlignment(t2, 0xdead00e1)
<span class="line-modified"> 719     loadp CodeBlock[cfr], t2                // t2&lt;CodeBlock&gt; = cfr.CodeBlock</span>
<span class="line-modified"> 720     loadi CodeBlock::m_numVars[t2], t2      // t2&lt;size_t&gt; = t2&lt;CodeBlock&gt;.m_numVars</span>
 721     subi CalleeSaveSpaceAsVirtualRegisters, t2
 722     move cfr, t3
 723     subp CalleeSaveSpaceAsVirtualRegisters * SlotSize, t3
 724     btiz t2, .opEnterDone
 725     move UndefinedTag, t0
<span class="line-added"> 726     move 0, t1</span>
 727     negi t2
 728 .opEnterLoop:
 729     storei t0, TagOffset[t3, t2, 8]
<span class="line-modified"> 730     storei t1, PayloadOffset[t3, t2, 8]</span>
 731     addi 1, t2
 732     btinz t2, .opEnterLoop
 733 .opEnterDone:
<span class="line-modified"> 734     callSlowPath(_slow_path_enter)</span>






 735     dispatchOp(narrow, op_enter)
<span class="line-modified"> 736 </span>


 737 
 738 llintOpWithProfile(op_get_argument, OpGetArgument, macro (size, get, dispatch, return)
 739     get(m_index, t2)
<span class="line-modified"> 740     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t0</span>
 741     bilteq t0, t2, .opGetArgumentOutOfBounds
 742     loadi ThisArgumentOffset + TagOffset[cfr, t2, 8], t0
 743     loadi ThisArgumentOffset + PayloadOffset[cfr, t2, 8], t3
 744     return (t0, t3)
 745 
 746 .opGetArgumentOutOfBounds:
 747     return (UndefinedTag, 0)
 748 end)
 749 
 750 
 751 llintOpWithReturn(op_argument_count, OpArgumentCount, macro (size, get, dispatch, return)
<span class="line-modified"> 752     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t0</span>
 753     subi 1, t0
 754     return(Int32Tag, t0)
 755 end)
 756 
 757 
 758 llintOpWithReturn(op_get_scope, OpGetScope, macro (size, get, dispatch, return)
 759     loadi Callee + PayloadOffset[cfr], t0
 760     loadp JSCallee::m_scope[t0], t0
 761     return (CellTag, t0)
 762 end)
 763 
 764 
 765 llintOpWithMetadata(op_to_this, OpToThis, macro (size, get, dispatch, metadata, return)
 766     get(m_srcDst, t0)
 767     bineq TagOffset[cfr, t0, 8], CellTag, .opToThisSlow
 768     loadi PayloadOffset[cfr, t0, 8], t0
 769     bbneq JSCell::m_type[t0], FinalObjectType, .opToThisSlow
 770     metadata(t2, t3)
 771     loadi OpToThis::Metadata::m_cachedStructureID[t2], t2
 772     bineq JSCell::m_structureID[t0], t2, .opToThisSlow
</pre>
<hr />
<pre>
 937     end)
 938 end
 939 
 940 
 941 strictEqOp(stricteq, OpStricteq,
 942     macro (left, right, result) cieq left, right, result end)
 943 
 944 
 945 strictEqOp(nstricteq, OpNstricteq,
 946     macro (left, right, result) cineq left, right, result end)
 947 
 948 
 949 strictEqualityJumpOp(jstricteq, OpJstricteq,
 950     macro (left, right, target) bieq left, right, target end)
 951 
 952 
 953 strictEqualityJumpOp(jnstricteq, OpJnstricteq,
 954     macro (left, right, target) bineq left, right, target end)
 955 
 956 
<span class="line-modified"> 957 macro preOp(opcodeName, opcodeStruct, integerOperation)</span>
<span class="line-modified"> 958     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)</span>
<span class="line-added"> 959         macro updateArithProfile(type)</span>
<span class="line-added"> 960             orh type, %opcodeStruct%::Metadata::m_arithProfile + UnaryArithProfile::m_bits[t1]</span>
<span class="line-added"> 961         end</span>
<span class="line-added"> 962 </span>
<span class="line-added"> 963         metadata(t1, t2)</span>
 964         get(m_srcDst, t0)
 965         bineq TagOffset[cfr, t0, 8], Int32Tag, .slow
<span class="line-modified"> 966         loadi PayloadOffset[cfr, t0, 8], t2</span>
<span class="line-modified"> 967         # Metadata in t1, srcDst in t2</span>
<span class="line-modified"> 968         integerOperation(t2, .slow)</span>
<span class="line-added"> 969         storei t2, PayloadOffset[cfr, t0, 8]</span>
<span class="line-added"> 970         updateArithProfile(ArithProfileInt)</span>
 971         dispatch()
 972 
 973     .slow:
 974         callSlowPath(_slow_path_%opcodeName%)
 975         dispatch()
 976     end)
 977 end
 978 
 979 
 980 llintOpWithProfile(op_to_number, OpToNumber, macro (size, get, dispatch, return)
 981     get(m_operand, t0)
 982     loadConstantOrVariable(size, t0, t2, t3)
 983     bieq t2, Int32Tag, .opToNumberIsInt
 984     biaeq t2, LowestTag, .opToNumberSlow
 985 .opToNumberIsInt:
 986     return(t2, t3)
 987 
 988 .opToNumberSlow:
 989     callSlowPath(_slow_path_to_number)
 990     dispatch()
 991 end)
 992 
<span class="line-added"> 993 llintOpWithProfile(op_to_numeric, OpToNumeric, macro (size, get, dispatch, return)</span>
<span class="line-added"> 994     get(m_operand, t0)</span>
<span class="line-added"> 995     loadConstantOrVariable(size, t0, t2, t3)</span>
<span class="line-added"> 996     bieq t2, Int32Tag, .opToNumericIsInt</span>
<span class="line-added"> 997     biaeq t2, LowestTag, .opToNumericSlow</span>
<span class="line-added"> 998 .opToNumericIsInt:</span>
<span class="line-added"> 999     return(t2, t3)</span>
<span class="line-added">1000 </span>
<span class="line-added">1001 .opToNumericSlow:</span>
<span class="line-added">1002     callSlowPath(_slow_path_to_numeric)</span>
<span class="line-added">1003     dispatch()</span>
<span class="line-added">1004 end)</span>
<span class="line-added">1005 </span>
1006 
1007 llintOpWithReturn(op_to_string, OpToString, macro (size, get, dispatch, return)
1008     get(m_operand, t0)
1009     loadConstantOrVariable(size, t0, t2, t3)
1010     bineq t2, CellTag, .opToStringSlow
1011     bbneq JSCell::m_type[t3], StringType, .opToStringSlow
1012 .opToStringIsString:
1013     return(t2, t3)
1014 
1015 .opToStringSlow:
1016     callSlowPath(_slow_path_to_string)
1017     dispatch()
1018 end)
1019 
1020 
1021 llintOpWithProfile(op_to_object, OpToObject, macro (size, get, dispatch, return)
1022     get(m_operand, t0)
1023     loadConstantOrVariable(size, t0, t2, t3)
1024     bineq t2, CellTag, .opToObjectSlow
1025     bbb JSCell::m_type[t3], ObjectType, .opToObjectSlow
1026     return(t2, t3)
1027 
1028 .opToObjectSlow:
1029     callSlowPath(_slow_path_to_object)
1030     dispatch()
1031 end)
1032 
1033 
1034 llintOpWithMetadata(op_negate, OpNegate, macro (size, get, dispatch, metadata, return)
1035 
<span class="line-modified">1036     macro updateArithProfile(type)</span>
<span class="line-modified">1037         orh type, OpNegate::Metadata::m_arithProfile + UnaryArithProfile::m_bits[t5]</span>
1038     end
1039 
1040     metadata(t5, t0)
1041     get(m_operand, t0)
1042     loadConstantOrVariable(size, t0, t1, t2)
1043     bineq t1, Int32Tag, .opNegateSrcNotInt
1044     btiz t2, 0x7fffffff, .opNegateSlow
1045     negi t2
<span class="line-modified">1046     updateArithProfile(ArithProfileInt)</span>
1047     return (Int32Tag, t2)
1048 .opNegateSrcNotInt:
1049     bia t1, LowestTag, .opNegateSlow
1050     xori 0x80000000, t1
<span class="line-modified">1051     updateArithProfile(ArithProfileNumber)</span>
1052     return(t1, t2)
1053 
1054 .opNegateSlow:
1055     callSlowPath(_slow_path_negate)
1056     dispatch()
1057 end)
1058 
1059 
1060 macro binaryOpCustomStore(opcodeName, opcodeStruct, integerOperationAndStore, doubleOperation)
1061     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)
1062         macro arithProfile(type)
<span class="line-modified">1063             orh type, %opcodeStruct%::Metadata::m_arithProfile + BinaryArithProfile::m_bits[t5]</span>
1064         end
1065 
1066         metadata(t5, t2)
1067         get(m_rhs, t2)
1068         get(m_lhs, t0)
1069         loadConstantOrVariable(size, t2, t3, t1)
1070         loadConstantOrVariable2Reg(size, t0, t2, t0)
1071         bineq t2, Int32Tag, .op1NotInt
1072         bineq t3, Int32Tag, .op2NotInt
1073         arithProfile(ArithProfileIntInt)
1074         get(m_dst, t2)
1075         integerOperationAndStore(t3, t1, t0, .slow, t2)
1076         dispatch()
1077 
1078     .op1NotInt:
1079         # First operand is definitely not an int, the second operand could be anything.
1080         bia t2, LowestTag, .slow
1081         bib t3, LowestTag, .op1NotIntOp2Double
1082         bineq t3, Int32Tag, .slow
1083         arithProfile(ArithProfileNumberInt)
<span class="line-modified">1084         ci2ds t1, ft1</span>
1085         jmp .op1NotIntReady
1086     .op1NotIntOp2Double:
1087         fii2d t1, t3, ft1
1088         arithProfile(ArithProfileNumberNumber)
1089     .op1NotIntReady:
1090         get(m_dst, t1)
1091         fii2d t0, t2, ft0
1092         doubleOperation(ft1, ft0)
1093         stored ft0, [cfr, t1, 8]
1094         dispatch()
1095 
1096     .op2NotInt:
1097         # First operand is definitely an int, the second operand is definitely not.
1098         get(m_dst, t2)
1099         bia t3, LowestTag, .slow
1100         arithProfile(ArithProfileIntNumber)
<span class="line-modified">1101         ci2ds t0, ft0</span>
1102         fii2d t1, t3, ft1
1103         doubleOperation(ft1, ft0)
1104         stored ft0, [cfr, t2, 8]
1105         dispatch()
1106 
1107     .slow:
1108         callSlowPath(_slow_path_%opcodeName%)
1109         dispatch()
1110     end)
1111 end
1112 
1113 macro binaryOp(opcodeName, opcodeStruct, integerOperation, doubleOperation)
1114     binaryOpCustomStore(opcodeName, opcodeStruct,
1115         macro (int32Tag, left, right, slow, index)
1116             integerOperation(left, right, slow)
1117             storei int32Tag, TagOffset[cfr, index, 8]
1118             storei right, PayloadOffset[cfr, index, 8]
1119         end,
1120         doubleOperation)
1121 end
</pre>
<hr />
<pre>
1130         const scratch = int32Tag   # We know that we can reuse the int32Tag register since it has a constant.
1131         move right, scratch
1132         bmulio left, scratch, slow
1133         btinz scratch, .done
1134         bilt left, 0, slow
1135         bilt right, 0, slow
1136     .done:
1137         storei Int32Tag, TagOffset[cfr, index, 8]
1138         storei scratch, PayloadOffset[cfr, index, 8]
1139     end,
1140     macro (left, right) muld left, right end)
1141 
1142 
1143 binaryOp(sub, OpSub,
1144     macro (left, right, slow) bsubio left, right, slow end,
1145     macro (left, right) subd left, right end)
1146 
1147 
1148 binaryOpCustomStore(div, OpDiv,
1149     macro (int32Tag, left, right, slow, index)
<span class="line-modified">1150         ci2ds left, ft0</span>
<span class="line-modified">1151         ci2ds right, ft1</span>
1152         divd ft0, ft1
1153         bcd2i ft1, right, .notInt
1154         storei int32Tag, TagOffset[cfr, index, 8]
1155         storei right, PayloadOffset[cfr, index, 8]
1156         jmp .done
1157     .notInt:
1158         stored ft1, [cfr, index, 8]
1159     .done:
1160     end,
1161     macro (left, right) divd left, right end)
1162 
1163 
1164 llintOpWithReturn(op_unsigned, OpUnsigned, macro (size, get, dispatch, return)
1165     get(m_operand, t1)
1166     loadConstantOrVariablePayload(size, t1, Int32Tag, t2, .opUnsignedSlow)
1167     bilt t2, 0, .opUnsignedSlow
1168     return (Int32Tag, t2)
1169 .opUnsignedSlow:
1170     callSlowPath(_slow_path_unsigned)
1171     dispatch()
</pre>
<hr />
<pre>
1416 .opGetByIdUnset:
1417     bbneq t1, constexpr GetByIdMode::Unset, .opGetByIdDefault
1418     loadi OpGetById::Metadata::m_modeMetadata.unsetMode.structureID[t5], t1
1419     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1420     bineq JSCell::m_structureID[t3], t1, .opGetByIdSlow
1421     valueProfile(OpGetById, t5, UndefinedTag, 0)
1422     return(UndefinedTag, 0)
1423 
1424 .opGetByIdDefault:
1425     loadi OpGetById::Metadata::m_modeMetadata.defaultMode.structureID[t5], t1
1426     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1427     loadis OpGetById::Metadata::m_modeMetadata.defaultMode.cachedOffset[t5], t2
1428     bineq JSCell::m_structureID[t3], t1, .opGetByIdSlow
1429     loadPropertyAtVariableOffset(t2, t3, t0, t1)
1430     valueProfile(OpGetById, t5, t0, t1)
1431     return(t0, t1)
1432 
1433 .opGetByIdSlow:
1434     callSlowPath(_llint_slow_path_get_by_id)
1435     dispatch()
<span class="line-added">1436 </span>
<span class="line-added">1437 .osrReturnPoint:</span>
<span class="line-added">1438     getterSetterOSRExitReturnPoint(op_get_by_id, size)</span>
<span class="line-added">1439     metadata(t2, t3)</span>
<span class="line-added">1440     valueProfile(OpGetById, t2, r1, r0)</span>
<span class="line-added">1441     return(r1, r0)</span>
<span class="line-added">1442 </span>
1443 end)
1444 
1445 
1446 llintOpWithMetadata(op_put_by_id, OpPutById, macro (size, get, dispatch, metadata, return)
1447     writeBarrierOnOperands(size, get, m_base, m_value)
1448     metadata(t5, t3)
1449     get(m_base, t3)
1450     loadConstantOrVariablePayload(size, t3, CellTag, t0, .opPutByIdSlow)
1451     loadi JSCell::m_structureID[t0], t2
1452     bineq t2, OpPutById::Metadata::m_oldStructureID[t5], .opPutByIdSlow
1453 
1454     # At this point, we have:
1455     # t5 -&gt; metadata
1456     # t2 -&gt; currentStructureID
1457     # t0 -&gt; object base
1458     # We will lose currentStructureID in the shenanigans below.
1459 
1460     loadi OpPutById::Metadata::m_newStructureID[t5], t1
1461 
1462     btiz t1, .opPutByIdNotTransition
</pre>
<hr />
<pre>
1485 .opPutByIdTransitionDirect:
1486     storei t1, JSCell::m_structureID[t0]
1487     get(m_value, t1)
1488     loadConstantOrVariable(size, t1, t2, t3)
1489     loadi OpPutById::Metadata::m_offset[t5], t1
1490     storePropertyAtVariableOffset(t1, t0, t2, t3)
1491     writeBarrierOnOperand(size, get, m_base)
1492     dispatch()
1493 
1494 .opPutByIdNotTransition:
1495     # The only thing live right now is t0, which holds the base.
1496     get(m_value, t1)
1497     loadConstantOrVariable(size, t1, t2, t3)
1498     loadi OpPutById::Metadata::m_offset[t5], t1
1499     storePropertyAtVariableOffset(t1, t0, t2, t3)
1500     dispatch()
1501 
1502 .opPutByIdSlow:
1503     callSlowPath(_llint_slow_path_put_by_id)
1504     dispatch()
<span class="line-added">1505 </span>
<span class="line-added">1506 .osrReturnPoint:</span>
<span class="line-added">1507     getterSetterOSRExitReturnPoint(op_put_by_id, size)</span>
<span class="line-added">1508     dispatch()</span>
<span class="line-added">1509 </span>
1510 end)
1511 
1512 
1513 llintOpWithMetadata(op_get_by_val, OpGetByVal, macro (size, get, dispatch, metadata, return)
1514     metadata(t5, t2)
1515     get(m_base, t2)
1516     loadConstantOrVariablePayload(size, t2, CellTag, t0, .opGetByValSlow)
1517     move t0, t2
1518     arrayProfile(OpGetByVal::Metadata::m_arrayProfile, t2, t5, t1)
1519     get(m_property, t3)
1520     loadConstantOrVariablePayload(size, t3, Int32Tag, t1, .opGetByValSlow)
1521     loadp JSObject::m_butterfly[t0], t3
1522     andi IndexingShapeMask, t2
1523     bieq t2, Int32Shape, .opGetByValIsContiguous
1524     bineq t2, ContiguousShape, .opGetByValNotContiguous
1525 
1526 .opGetByValIsContiguous:
1527     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t3], .opGetByValSlow
1528     loadi TagOffset[t3, t1, 8], t2
1529     loadi PayloadOffset[t3, t1, 8], t1
</pre>
<hr />
<pre>
1541 
1542 .opGetByValNotDouble:
1543     subi ArrayStorageShape, t2
1544     bia t2, SlowPutArrayStorageShape - ArrayStorageShape, .opGetByValSlow
1545     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t3], .opGetByValSlow
1546     loadi ArrayStorage::m_vector + TagOffset[t3, t1, 8], t2
1547     loadi ArrayStorage::m_vector + PayloadOffset[t3, t1, 8], t1
1548 
1549 .opGetByValDone:
1550     get(m_dst, t0)
1551     bieq t2, EmptyValueTag, .opGetByValSlow
1552 .opGetByValNotEmpty:
1553     storei t2, TagOffset[cfr, t0, 8]
1554     storei t1, PayloadOffset[cfr, t0, 8]
1555     valueProfile(OpGetByVal, t5, t2, t1)
1556     dispatch()
1557 
1558 .opGetByValSlow:
1559     callSlowPath(_llint_slow_path_get_by_val)
1560     dispatch()
<span class="line-added">1561 </span>
<span class="line-added">1562 .osrReturnPoint:</span>
<span class="line-added">1563     getterSetterOSRExitReturnPoint(op_get_by_val, size)</span>
<span class="line-added">1564     metadata(t2, t3)</span>
<span class="line-added">1565     valueProfile(OpGetByVal, t2, r1, r0)</span>
<span class="line-added">1566     return(r1, r0)</span>
<span class="line-added">1567 </span>
1568 end)
1569 
1570 
<span class="line-modified">1571 macro putByValOp(opcodeName, opcodeStruct, osrExitPoint)</span>
1572     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)
1573         macro contiguousPutByVal(storeCallback)
1574             biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], .outOfBounds
1575         .storeResult:
1576             get(m_value, t2)
1577             storeCallback(t2, t1, t0, t3)
1578             dispatch()
1579 
1580         .outOfBounds:
1581             biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t0], .opPutByValOutOfBounds
1582             storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_mayStoreToHole[t5]
1583             addi 1, t3, t2
1584             storei t2, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0]
1585             jmp .storeResult
1586         end
1587 
1588         writeBarrierOnOperands(size, get, m_base, m_value)
1589         metadata(t5, t0)
1590         get(m_base, t0)
1591         loadConstantOrVariablePayload(size, t0, CellTag, t1, .opPutByValSlow)
</pre>
<hr />
<pre>
1595         loadConstantOrVariablePayload(size, t0, Int32Tag, t3, .opPutByValSlow)
1596         loadp JSObject::m_butterfly[t1], t0
1597         btinz t2, CopyOnWrite, .opPutByValSlow
1598         andi IndexingShapeMask, t2
1599         bineq t2, Int32Shape, .opPutByValNotInt32
1600         contiguousPutByVal(
1601             macro (operand, scratch, base, index)
1602                 loadConstantOrVariablePayload(size, operand, Int32Tag, scratch, .opPutByValSlow)
1603                 storei Int32Tag, TagOffset[base, index, 8]
1604                 storei scratch, PayloadOffset[base, index, 8]
1605             end)
1606 
1607     .opPutByValNotInt32:
1608         bineq t2, DoubleShape, .opPutByValNotDouble
1609         contiguousPutByVal(
1610             macro (operand, scratch, base, index)
1611                 const tag = scratch
1612                 const payload = operand
1613                 loadConstantOrVariable2Reg(size, operand, tag, payload)
1614                 bineq tag, Int32Tag, .notInt
<span class="line-modified">1615                 ci2ds payload, ft0</span>
1616                 jmp .ready
1617             .notInt:
1618                 fii2d payload, tag, ft0
1619                 bdnequn ft0, ft0, .opPutByValSlow
1620             .ready:
1621                 stored ft0, [base, index, 8]
1622             end)
1623 
1624     .opPutByValNotDouble:
1625         bineq t2, ContiguousShape, .opPutByValNotContiguous
1626         contiguousPutByVal(
1627             macro (operand, scratch, base, index)
1628                 const tag = scratch
1629                 const payload = operand
1630                 loadConstantOrVariable2Reg(size, operand, tag, payload)
1631                 storei tag, TagOffset[base, index, 8]
1632                 storei payload, PayloadOffset[base, index, 8]
1633             end)
1634 
1635     .opPutByValNotContiguous:
</pre>
<hr />
<pre>
1639     .opPutByValArrayStorageStoreResult:
1640         get(m_value, t2)
1641         loadConstantOrVariable2Reg(size, t2, t1, t2)
1642         storei t1, ArrayStorage::m_vector + TagOffset[t0, t3, 8]
1643         storei t2, ArrayStorage::m_vector + PayloadOffset[t0, t3, 8]
1644         dispatch()
1645 
1646     .opPutByValArrayStorageEmpty:
1647         storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_mayStoreToHole[t5]
1648         addi 1, ArrayStorage::m_numValuesInVector[t0]
1649         bib t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], .opPutByValArrayStorageStoreResult
1650         addi 1, t3, t1
1651         storei t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0]
1652         jmp .opPutByValArrayStorageStoreResult
1653 
1654     .opPutByValOutOfBounds:
1655         storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_outOfBounds[t5]
1656     .opPutByValSlow:
1657         callSlowPath(_llint_slow_path_%opcodeName%)
1658         dispatch()
<span class="line-added">1659 </span>
<span class="line-added">1660     .osrExitPoint:</span>
<span class="line-added">1661         osrExitPoint(size, dispatch)</span>
1662     end)
1663 end
1664 
1665 
<span class="line-modified">1666 putByValOp(put_by_val, OpPutByVal, macro (size, dispatch)</span>
<span class="line-added">1667 .osrReturnPoint:</span>
<span class="line-added">1668     getterSetterOSRExitReturnPoint(op_put_by_val, size)</span>
<span class="line-added">1669     dispatch()</span>
<span class="line-added">1670 end)</span>
1671 
<span class="line-modified">1672 putByValOp(put_by_val_direct, OpPutByValDirect, macro (a, b) end)</span>
1673 
1674 
1675 macro llintJumpTrueOrFalseOp(opcodeName, opcodeStruct, conditionOp)
1676     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1677         get(m_condition, t1)
1678         loadConstantOrVariablePayload(size, t1, BooleanTag, t0, .slow)
1679         conditionOp(t0, .target)
1680         dispatch()
1681 
1682     .target:
1683         jump(m_targetLabel)
1684 
1685     .slow:
1686         callSlowPath(_llint_slow_path_%opcodeName%)
1687         nextInstruction()
1688     end)
1689 end
1690 
1691 
1692 macro equalNullJumpOp(opcodeName, opcodeStruct, cellHandler, immediateHandler)
</pre>
<hr />
<pre>
1734     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1735         get(m_value, t1)
1736         loadConstantOrVariableTag(size, t1, t0)
1737         ori 1, t0
1738         fn(t0, .target)
1739         dispatch()
1740 
1741     .target:
1742         jump(m_targetLabel)
1743     end)
1744 end
1745 
1746 undefinedOrNullJumpOp(jundefined_or_null, OpJundefinedOrNull,
1747     macro (value, target) bieq value, NullTag, target end)
1748 
1749 undefinedOrNullJumpOp(jnundefined_or_null, OpJnundefinedOrNull,
1750     macro (value, target) bineq value, NullTag, target end)
1751 
1752 llintOpWithMetadata(op_jneq_ptr, OpJneqPtr, macro (size, get, dispatch, metadata, return)
1753     get(m_value, t0)
<span class="line-modified">1754     get(m_specialPointer, t1)</span>
<span class="line-modified">1755     loadConstant(size, t1, t3, t2)</span>

1756     bineq TagOffset[cfr, t0, 8], CellTag, .opJneqPtrBranch
<span class="line-modified">1757     bpeq PayloadOffset[cfr, t0, 8], t2, .opJneqPtrFallThrough</span>

1758 .opJneqPtrBranch:
1759     metadata(t5, t2)
1760     storeb 1, OpJneqPtr::Metadata::m_hasJumped[t5]
1761     get(m_targetLabel, t0)
<span class="line-modified">1762     jumpImpl(dispatchIndirect, t0)</span>
1763 .opJneqPtrFallThrough:
1764     dispatch()
1765 end)
1766 
1767 
1768 macro compareUnsignedJumpOp(opcodeName, opcodeStruct, integerCompare)
1769     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1770         get(m_lhs, t2)
1771         get(m_rhs, t3)
1772         loadConstantOrVariable(size, t2, t0, t1)
1773         loadConstantOrVariable2Reg(size, t3, t2, t3)
1774         integerCompare(t1, t3, .jumpTarget)
1775         dispatch()
1776 
1777     .jumpTarget:
1778         jump(m_targetLabel)
1779     end)
1780 end
1781 
1782 
</pre>
<hr />
<pre>
1790         return(BooleanTag, t0)
1791     end)
1792 end
1793 
1794 
1795 macro compareJumpOp(opcodeName, opcodeStruct, integerCompare, doubleCompare)
1796     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1797         get(m_lhs, t2)
1798         get(m_rhs, t3)
1799         loadConstantOrVariable(size, t2, t0, t1)
1800         loadConstantOrVariable2Reg(size, t3, t2, t3)
1801         bineq t0, Int32Tag, .op1NotInt
1802         bineq t2, Int32Tag, .op2NotInt
1803         integerCompare(t1, t3, .jumpTarget)
1804         dispatch()
1805 
1806     .op1NotInt:
1807         bia t0, LowestTag, .slow
1808         bib t2, LowestTag, .op1NotIntOp2Double
1809         bineq t2, Int32Tag, .slow
<span class="line-modified">1810         ci2ds t3, ft1</span>
1811         jmp .op1NotIntReady
1812     .op1NotIntOp2Double:
1813         fii2d t3, t2, ft1
1814     .op1NotIntReady:
1815         fii2d t1, t0, ft0
1816         doubleCompare(ft0, ft1, .jumpTarget)
1817         dispatch()
1818 
1819     .op2NotInt:
<span class="line-modified">1820         ci2ds t1, ft0</span>
1821         bia t2, LowestTag, .slow
1822         fii2d t3, t2, ft1
1823         doubleCompare(ft0, ft1, .jumpTarget)
1824         dispatch()
1825 
1826     .jumpTarget:
1827         jump(m_targetLabel)
1828 
1829     .slow:
1830         callSlowPath(_llint_slow_path_%opcodeName%)
1831         nextInstruction()
1832     end)
1833 end
1834 
1835 
1836 llintOpWithJump(op_switch_imm, OpSwitchImm, macro (size, get, jump, dispatch)
1837     get(m_scrutinee, t2)
1838     getu(size, OpSwitchImm, m_tableIndex, t3)
1839     loadConstantOrVariable(size, t2, t1, t0)
1840     loadp CodeBlock[cfr], t2
</pre>
<hr />
<pre>
1912 end
1913 
1914 macro commonCallOp(opcodeName, slowPath, opcodeStruct, prepareCall, prologue)
1915     llintOpWithMetadata(opcodeName, opcodeStruct, macro (size, get, dispatch, metadata, return)
1916         metadata(t5, t0)
1917 
1918         prologue(macro (fieldName, dst)
1919             getu(size, opcodeStruct, fieldName, dst)
1920         end, metadata)
1921 
1922         get(m_callee, t0)
1923         loadp %opcodeStruct%::Metadata::m_callLinkInfo.m_calleeOrLastSeenCalleeWithLinkBit[t5], t2
1924         loadConstantOrVariablePayload(size, t0, CellTag, t3, .opCallSlow)
1925         bineq t3, t2, .opCallSlow
1926         getu(size, opcodeStruct, m_argv, t3)
1927         lshifti 3, t3
1928         negi t3
1929         addp cfr, t3  # t3 contains the new value of cfr
1930         storei t2, Callee + PayloadOffset[t3]
1931         getu(size, opcodeStruct, m_argc, t2)
<span class="line-modified">1932         storei PC, ArgumentCountIncludingThis + TagOffset[cfr]</span>
<span class="line-modified">1933         storei t2, ArgumentCountIncludingThis + PayloadOffset[t3]</span>
1934         storei CellTag, Callee + TagOffset[t3]
1935         move t3, sp
1936         prepareCall(%opcodeStruct%::Metadata::m_callLinkInfo.m_machineCodeTarget[t5], t2, t3, t4, JSEntryPtrTag)
<span class="line-modified">1937         callTargetFunction(opcodeName, size, opcodeStruct, dispatch, %opcodeStruct%::Metadata::m_callLinkInfo.m_machineCodeTarget[t5], JSEntryPtrTag)</span>
1938 
1939     .opCallSlow:
<span class="line-modified">1940         slowPathForCall(opcodeName, size, opcodeStruct, dispatch, slowPath, prepareCall)</span>
1941     end)
1942 end
1943 
1944 llintOp(op_ret, OpRet, macro (size, get, dispatch)
1945     checkSwitchToJITForEpilogue()
1946     get(m_value, t2)
1947     loadConstantOrVariable(size, t2, t1, t0)
1948     doReturn()
1949 end)
1950 
1951 
1952 llintOpWithReturn(op_to_primitive, OpToPrimitive, macro (size, get, dispatch, return)
1953     get(m_src, t2)
1954     loadConstantOrVariable(size, t2, t1, t0)
1955     bineq t1, CellTag, .opToPrimitiveIsImm
1956     bbaeq JSCell::m_type[t0], ObjectType, .opToPrimitiveSlowCase
1957 .opToPrimitiveIsImm:
1958     return(t1, t0)
1959 
1960 .opToPrimitiveSlowCase:
1961     callSlowPath(_slow_path_to_primitive)
1962     dispatch()
1963 end)
1964 
1965 
<span class="line-added">1966 llintOpWithReturn(op_to_property_key, OpToPropertyKey, macro (size, get, dispatch, return)</span>
<span class="line-added">1967     get(m_src, t2)</span>
<span class="line-added">1968     loadConstantOrVariable(size, t2, t1, t0)</span>
<span class="line-added">1969     bineq t1, CellTag, .opToPropertyKeySlow</span>
<span class="line-added">1970     bbeq JSCell::m_type[t0], SymbolType, .done</span>
<span class="line-added">1971     bbneq JSCell::m_type[t0], StringType, .opToPropertyKeySlow</span>
<span class="line-added">1972 </span>
<span class="line-added">1973 .done:</span>
<span class="line-added">1974     return(t1, t0)</span>
<span class="line-added">1975 </span>
<span class="line-added">1976 .opToPropertyKeySlow:</span>
<span class="line-added">1977     callSlowPath(_slow_path_to_property_key)</span>
<span class="line-added">1978     dispatch()</span>
<span class="line-added">1979 end)</span>
<span class="line-added">1980 </span>
<span class="line-added">1981 </span>
1982 commonOp(llint_op_catch, macro() end, macro (size)
1983     # This is where we end up from the JIT&#39;s throw trampoline (because the
1984     # machine code return address will be set to _llint_op_catch), and from
1985     # the interpreter&#39;s throw trampoline (see _llint_throw_trampoline).
1986     # The throwing code must have known that we were throwing to the interpreter,
1987     # and have set VM::targetInterpreterPCForThrow.
1988     loadp Callee + PayloadOffset[cfr], t3
<span class="line-modified">1989     convertCalleeToVM(t3)</span>

1990     restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(t3, t0)
1991     loadp VM::callFrameForCatch[t3], cfr
1992     storep 0, VM::callFrameForCatch[t3]
1993     restoreStackPointerAfterCall()
1994 
1995     # restore metadataTable since we don&#39;t restore callee saves for CLoop during unwinding
1996     loadp CodeBlock[cfr], t1
1997     loadp CodeBlock::m_metadata[t1], metadataTable
<span class="line-added">1998     loadp CodeBlock::m_instructionsRawPointer[t1], PB</span>
1999 
<span class="line-modified">2000     loadp VM::targetInterpreterPCForThrow[t3], PC</span>
<span class="line-added">2001     subp PB, PC</span>
2002 
2003     callSlowPath(_llint_slow_path_check_if_exception_is_uncatchable_and_notify_profiler)
2004     bpeq r1, 0, .isCatchableException
2005     jmp _llint_throw_from_slow_path_trampoline
2006 
2007 .isCatchableException:
<span class="line-modified">2008     loadp CodeBlock[cfr], t3</span>
<span class="line-modified">2009     loadp CodeBlock::m_vm[t3], t3</span>

2010 
2011     loadp VM::m_exception[t3], t0
2012     storep 0, VM::m_exception[t3]
2013     get(size, OpCatch, m_exception, t2)
2014     storei t0, PayloadOffset[cfr, t2, 8]
2015     storei CellTag, TagOffset[cfr, t2, 8]
2016 
2017     loadi Exception::m_value + TagOffset[t0], t1
2018     loadi Exception::m_value + PayloadOffset[t0], t0
2019     get(size, OpCatch, m_thrownValue, t2)
2020     storei t0, PayloadOffset[cfr, t2, 8]
2021     storei t1, TagOffset[cfr, t2, 8]
2022 
2023     traceExecution()  # This needs to be here because we don&#39;t want to clobber t0, t1, t2, t3 above.
2024 
2025     callSlowPath(_llint_slow_path_profile_catch)
2026 
2027     dispatchOp(size, op_catch)
2028 end)
2029 
2030 llintOp(op_end, OpEnd, macro (size, get, dispatch)
2031     checkSwitchToJITForEpilogue()
2032     get(m_value, t0)
2033     assertNotConstant(size, t0)
2034     loadi TagOffset[cfr, t0, 8], t1
2035     loadi PayloadOffset[cfr, t0, 8], t0
2036     doReturn()
2037 end)
2038 
2039 
2040 op(llint_throw_from_slow_path_trampoline, macro()
2041     loadp Callee[cfr], t1
<span class="line-modified">2042     convertCalleeToVM(t1)</span>

2043     copyCalleeSavesToVMEntryFrameCalleeSavesBuffer(t1, t2)
2044 
2045     callSlowPath(_llint_slow_path_handle_exception)
2046 
2047     # When throwing from the interpreter (i.e. throwing from LLIntSlowPaths), so
2048     # the throw target is not necessarily interpreted code, we come to here.
2049     # This essentially emulates the JIT&#39;s throwing protocol.
2050     loadp Callee[cfr], t1
<span class="line-modified">2051     convertCalleeToVM(t1)</span>

2052     jmp VM::targetMachinePCForThrow[t1]
2053 end)
2054 
2055 
2056 op(llint_throw_during_call_trampoline, macro()
2057     preserveReturnAddressAfterCall(t2)
2058     jmp _llint_throw_from_slow_path_trampoline
2059 end)
2060 
2061 
2062 macro nativeCallTrampoline(executableOffsetToFunction)

2063     functionPrologue()
2064     storep 0, CodeBlock[cfr]
<span class="line-modified">2065 </span>

2066     if X86 or X86_WIN
2067         subp 8, sp # align stack pointer
<span class="line-modified">2068         storep cfr, [sp]</span>
<span class="line-modified">2069     elsif MIPS</span>













2070         # calling convention says to save stack space for 4 first registers in
2071         # all cases. To match our 16-byte alignment, that means we need to
2072         # take 24 bytes
<span class="line-modified">2073         subp 24, sp</span>
























2074     else
<span class="line-modified">2075         subp 8, sp # align stack pointer</span>
2076     end
<span class="line-modified">2077 </span>
<span class="line-added">2078     loadp Callee + PayloadOffset[cfr], a0</span>
<span class="line-added">2079     loadp JSFunction::m_executableOrRareData[a0], a2</span>
<span class="line-added">2080     btpz a2, (constexpr JSFunction::rareDataTag), .isExecutable</span>
<span class="line-added">2081     loadp (FunctionRareData::m_executable - (constexpr JSFunction::rareDataTag))[a2], a2</span>
<span class="line-added">2082 .isExecutable:</span>
<span class="line-added">2083     loadp JSFunction::m_scope[a0], a0</span>
<span class="line-added">2084     loadp JSGlobalObject::m_vm[a0], a1</span>
<span class="line-added">2085     storep cfr, VM::topCallFrame[a1]</span>
<span class="line-added">2086     move cfr, a1</span>
<span class="line-added">2087 </span>
<span class="line-added">2088     checkStackPointerAlignment(t3, 0xdead0001)</span>
<span class="line-added">2089     if C_LOOP or C_LOOP_WIN</span>
<span class="line-added">2090         cloopCallNative executableOffsetToFunction[a2]</span>
<span class="line-added">2091     else</span>
<span class="line-added">2092         call executableOffsetToFunction[a2]</span>
<span class="line-added">2093     end</span>
<span class="line-added">2094 </span>
<span class="line-added">2095     loadp Callee + PayloadOffset[cfr], t3</span>
<span class="line-added">2096     loadp JSFunction::m_scope[t3], t3</span>
<span class="line-added">2097     loadp JSGlobalObject::m_vm[t3], t3</span>
<span class="line-added">2098 </span>
<span class="line-added">2099     if MIPS</span>
<span class="line-added">2100         addp 24, sp</span>
<span class="line-added">2101     else</span>
<span class="line-added">2102         addp 8, sp</span>
<span class="line-added">2103     end</span>
<span class="line-added">2104 </span>
2105     btpnz VM::m_exception[t3], .handleException
2106 
2107     functionEpilogue()
2108     ret
2109 
2110 .handleException:
<span class="line-modified">2111     if X86 or X86_WIN</span>
<span class="line-modified">2112         subp 8, sp # align stack pointer</span>
<span class="line-modified">2113     end</span>
2114     storep cfr, VM::topCallFrame[t3]
2115     jmp _llint_throw_from_slow_path_trampoline
2116 end
2117 
2118 
2119 macro internalFunctionCallTrampoline(offsetOfFunction)
2120     functionPrologue()
2121     storep 0, CodeBlock[cfr]
<span class="line-modified">2122 </span>
2123     // Callee is still in t1 for code below
2124     if X86 or X86_WIN
2125         subp 8, sp # align stack pointer
<span class="line-modified">2126         storep cfr, [sp]</span>
<span class="line-modified">2127     else</span>











2128         subp 8, sp # align stack pointer
<span class="line-modified">2129     end</span>
<span class="line-modified">2130 </span>
<span class="line-modified">2131     loadp Callee + PayloadOffset[cfr], a2</span>
<span class="line-modified">2132     loadp InternalFunction::m_globalObject[a2], a0</span>
<span class="line-modified">2133     loadp JSGlobalObject::m_vm[a0], a1</span>
<span class="line-modified">2134     storep cfr, VM::topCallFrame[a1]</span>
<span class="line-modified">2135     move cfr, a1</span>
<span class="line-modified">2136 </span>
<span class="line-modified">2137     checkStackPointerAlignment(t3, 0xdead0001)</span>
<span class="line-modified">2138     if C_LOOP or C_LOOP_WIN</span>
<span class="line-modified">2139         cloopCallNative offsetOfFunction[a2]</span>





2140     else
<span class="line-modified">2141         call offsetOfFunction[a2]</span>
2142     end
2143 
<span class="line-added">2144     loadp Callee + PayloadOffset[cfr], t3</span>
<span class="line-added">2145     loadp InternalFunction::m_globalObject[t3], t3</span>
<span class="line-added">2146     loadp JSGlobalObject::m_vm[t3], t3</span>
<span class="line-added">2147 </span>
<span class="line-added">2148     addp 8, sp</span>
<span class="line-added">2149 </span>
2150     btpnz VM::m_exception[t3], .handleException
2151 
2152     functionEpilogue()
2153     ret
2154 
2155 .handleException:
<span class="line-modified">2156     if X86 or X86_WIN</span>
<span class="line-modified">2157         subp 8, sp # align stack pointer</span>
<span class="line-modified">2158     end</span>
2159     storep cfr, VM::topCallFrame[t3]
2160     jmp _llint_throw_from_slow_path_trampoline
2161 end
2162 
2163 
2164 macro varInjectionCheck(slowPath)
2165     loadp CodeBlock[cfr], t0
2166     loadp CodeBlock::m_globalObject[t0], t0
2167     loadp JSGlobalObject::m_varInjectionWatchpoint[t0], t0
2168     bbeq WatchpointSet::m_state[t0], IsInvalidated, slowPath
2169 end
2170 
2171 
2172 llintOpWithMetadata(op_resolve_scope, OpResolveScope, macro (size, get, dispatch, metadata, return)
2173 
2174     macro getConstantScope(dst)
2175         loadp OpResolveScope::Metadata::m_constantScope[t5], dst
2176     end
2177 
2178     macro returnConstantScope()
</pre>
<hr />
<pre>
2542     bpneq t2, t1, .opProfileTypeDone
2543     callSlowPath(_slow_path_profile_type_clear_log)
2544 
2545 .opProfileTypeDone:
2546     dispatch()
2547 end)
2548 
2549 
2550 llintOpWithMetadata(op_profile_control_flow, OpProfileControlFlow, macro (size, get, dispatch, metadata, return)
2551     metadata(t5, t0)
2552     loadp OpProfileControlFlow::Metadata::m_basicBlockLocation[t5], t0
2553     loadi BasicBlockLocation::m_executionCount[t0], t1
2554     baddio 1, t1, .done
2555     storei t1, BasicBlockLocation::m_executionCount[t0]
2556 .done:
2557     dispatch()
2558 end)
2559 
2560 
2561 llintOpWithReturn(op_get_rest_length, OpGetRestLength, macro (size, get, dispatch, return)
<span class="line-modified">2562     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t0</span>
2563     subi 1, t0
2564     getu(size, OpGetRestLength, m_numParametersToSkip, t1)
2565     bilteq t0, t1, .storeZero
2566     subi t1, t0
2567     jmp .finish
2568 .storeZero:
2569     move 0, t0
2570 .finish:
2571     return(Int32Tag, t0)
2572 end)
2573 
2574 
<span class="line-added">2575 llintOpWithProfile(op_get_internal_field, OpGetInternalField, macro (size, get, dispatch, return)</span>
<span class="line-added">2576     get(m_base, t0)</span>
<span class="line-added">2577     loadi PayloadOffset[cfr, t0, 8], t0</span>
<span class="line-added">2578     getu(size, OpGetInternalField, m_index, t1)</span>
<span class="line-added">2579     loadi JSInternalFieldObjectImpl_internalFields + TagOffset[t0, t1, SlotSize], t2</span>
<span class="line-added">2580     loadi JSInternalFieldObjectImpl_internalFields + PayloadOffset[t0, t1, SlotSize], t3</span>
<span class="line-added">2581     return(t2, t3)</span>
<span class="line-added">2582 end)</span>
<span class="line-added">2583 </span>
<span class="line-added">2584 llintOp(op_put_internal_field, OpPutInternalField, macro (size, get, dispatch)</span>
<span class="line-added">2585     get(m_base, t0)</span>
<span class="line-added">2586     loadi PayloadOffset[cfr, t0, 8], t0</span>
<span class="line-added">2587     get(m_value, t1)</span>
<span class="line-added">2588     loadConstantOrVariable(size, t1, t2, t3)</span>
<span class="line-added">2589     getu(size, OpPutInternalField, m_index, t1)</span>
<span class="line-added">2590     storei t2, JSInternalFieldObjectImpl_internalFields + TagOffset[t0, t1, SlotSize]</span>
<span class="line-added">2591     storei t3, JSInternalFieldObjectImpl_internalFields + PayloadOffset[t0, t1, SlotSize]</span>
<span class="line-added">2592     writeBarrierOnOperand(size, get, m_base)</span>
<span class="line-added">2593     dispatch()</span>
<span class="line-added">2594 end)</span>
<span class="line-added">2595 </span>
<span class="line-added">2596 </span>
2597 llintOp(op_log_shadow_chicken_prologue, OpLogShadowChickenPrologue, macro (size, get, dispatch)
2598     acquireShadowChickenPacket(.opLogShadowChickenPrologueSlow)
2599     storep cfr, ShadowChicken::Packet::frame[t0]
2600     loadp CallerFrame[cfr], t1
2601     storep t1, ShadowChicken::Packet::callerFrame[t0]
2602     loadp Callee + PayloadOffset[cfr], t1
2603     storep t1, ShadowChicken::Packet::callee[t0]
2604     get(m_scope, t1)
2605     loadi PayloadOffset[cfr, t1, 8], t1
2606     storep t1, ShadowChicken::Packet::scope[t0]
2607     dispatch()
2608 .opLogShadowChickenPrologueSlow:
2609     callSlowPath(_llint_slow_path_log_shadow_chicken_prologue)
2610     dispatch()
2611 end)
2612 
2613 
2614 llintOp(op_log_shadow_chicken_tail, OpLogShadowChickenTail, macro (size, get, dispatch)
2615     acquireShadowChickenPacket(.opLogShadowChickenTailSlow)
2616     storep cfr, ShadowChicken::Packet::frame[t0]
</pre>
</td>
</tr>
</table>
<center><a href="LowLevelInterpreter.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="LowLevelInterpreter64.asm.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>