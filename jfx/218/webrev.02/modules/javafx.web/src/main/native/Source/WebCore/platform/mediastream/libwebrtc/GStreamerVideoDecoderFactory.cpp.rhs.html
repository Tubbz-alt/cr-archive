<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoDecoderFactory.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2018 Metrological Group B.V.
  3  * Copyright (C) 2018 Igalia S.L. All rights reserved.
  4  *
  5  * This library is free software; you can redistribute it and/or
  6  * modify it under the terms of the GNU Library General Public
  7  * License as published by the Free Software Foundation; either
  8  * version 2 of the License, or (at your option) any later version.
  9  *
 10  * This library is distributed in the hope that it will be useful,
 11  * but WITHOUT ANY WARRANTY; without even the implied warranty of
 12  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 13  * Library General Public License for more details.
 14  *
 15  * You should have received a copy of the GNU Library General Public License
 16  * aint with this library; see the file COPYING.LIB.  If not, write to
 17  * the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
 18  * Boston, MA 02110-1301, USA.
 19  */
 20 
 21 #include &quot;config.h&quot;
 22 
 23 #if ENABLE(VIDEO) &amp;&amp; ENABLE(MEDIA_STREAM) &amp;&amp; USE(LIBWEBRTC) &amp;&amp; USE(GSTREAMER)
 24 #include &quot;GStreamerVideoDecoderFactory.h&quot;
 25 
 26 #include &quot;GStreamerVideoFrameLibWebRTC.h&quot;
 27 #include &quot;webrtc/common_video/h264/h264_common.h&quot;
 28 #include &quot;webrtc/common_video/h264/profile_level_id.h&quot;
 29 #include &quot;webrtc/media/base/codec.h&quot;
 30 #include &quot;webrtc/modules/video_coding/codecs/h264/include/h264.h&quot;
 31 #include &quot;webrtc/modules/video_coding/codecs/vp8/include/vp8.h&quot;
 32 #include &quot;webrtc/modules/video_coding/codecs/vp8/libvpx_vp8_decoder.h&quot;
 33 #include &quot;webrtc/modules/video_coding/include/video_codec_interface.h&quot;
 34 #include &lt;gst/app/gstappsink.h&gt;
 35 #include &lt;gst/app/gstappsrc.h&gt;
 36 #include &lt;gst/video/video.h&gt;
 37 #include &lt;mutex&gt;
 38 #include &lt;wtf/Lock.h&gt;
 39 #include &lt;wtf/StdMap.h&gt;
 40 #include &lt;wtf/glib/RunLoopSourcePriority.h&gt;
 41 #include &lt;wtf/text/WTFString.h&gt;
 42 
 43 GST_DEBUG_CATEGORY(webkit_webrtcdec_debug);
 44 #define GST_CAT_DEFAULT webkit_webrtcdec_debug
 45 
 46 namespace WebCore {
 47 
 48 typedef struct {
 49     uint64_t timestamp;
 50     int64_t renderTimeMs;
 51 } InputTimestamps;
 52 
 53 class GStreamerVideoDecoder : public webrtc::VideoDecoder {
 54 public:
 55     GStreamerVideoDecoder()
 56         : m_pictureId(0)
 57         , m_width(0)
 58         , m_height(0)
 59         , m_requireParse(false)
 60         , m_needsKeyframe(true)
 61         , m_firstBufferPts(GST_CLOCK_TIME_NONE)
 62         , m_firstBufferDts(GST_CLOCK_TIME_NONE)
 63     {
 64     }
 65 
 66     static void decodebinPadAddedCb(GstElement*,
 67         GstPad* srcpad,
 68         GstPad* sinkpad)
 69     {
 70         GST_INFO_OBJECT(srcpad, &quot;connecting pad with %&quot; GST_PTR_FORMAT, sinkpad);
 71         if (gst_pad_link(srcpad, sinkpad) != GST_PAD_LINK_OK)
 72             ASSERT_NOT_REACHED();
 73     }
 74 
 75     GstElement* pipeline()
 76     {
 77         return m_pipeline.get();
 78     }
 79 
 80     GstElement* makeElement(const gchar* factoryName)
 81     {
 82         GUniquePtr&lt;char&gt; name(g_strdup_printf(&quot;%s_dec_%s_%p&quot;, Name(), factoryName, this));
 83 
 84         return gst_element_factory_make(factoryName, name.get());
 85     }
 86 
 87     int32_t InitDecode(const webrtc::VideoCodec* codecSettings, int32_t) override
 88     {
 89         m_src = makeElement(&quot;appsrc&quot;);
 90 
 91         GRefPtr&lt;GstCaps&gt; caps = nullptr;
 92         auto capsfilter = CreateFilter();
 93         auto decoder = makeElement(&quot;decodebin&quot;);
 94 
 95         if (codecSettings) {
 96             m_width = codecSettings-&gt;width;
 97             m_height = codecSettings-&gt;height;
 98         }
 99 
100         m_pipeline = makeElement(&quot;pipeline&quot;);
101         connectSimpleBusMessageCallback(m_pipeline.get());
102 
103         auto sinkpad = adoptGRef(gst_element_get_static_pad(capsfilter, &quot;sink&quot;));
104         g_signal_connect(decoder, &quot;pad-added&quot;, G_CALLBACK(decodebinPadAddedCb), sinkpad.get());
105         // Make the decoder output &quot;parsed&quot; frames only and let the main decodebin
106         // do the real decoding. This allows us to have optimized decoding/rendering
107         // happening in the main pipeline.
108         if (m_requireParse) {
109             caps = gst_caps_new_simple(Caps(), &quot;parsed&quot;, G_TYPE_BOOLEAN, TRUE, nullptr);
110             GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
111 
112             gst_bus_enable_sync_message_emission(bus.get());
113             g_signal_connect(bus.get(), &quot;sync-message::warning&quot;,
114                 G_CALLBACK(+[](GstBus*, GstMessage* message, GStreamerVideoDecoder* justThis) {
115                 GUniqueOutPtr&lt;GError&gt; err;
116 
117                 switch (GST_MESSAGE_TYPE(message)) {
118                 case GST_MESSAGE_WARNING: {
119                     gst_message_parse_warning(message, &amp;err.outPtr(), nullptr);
120                     FALLTHROUGH;
121                 }
122                 case GST_MESSAGE_ERROR: {
123                     if (!err)
124                         gst_message_parse_error(message, &amp;err.outPtr(), nullptr);
125 
126                     if (g_error_matches(err.get(), GST_STREAM_ERROR, GST_STREAM_ERROR_DECODE)) {
127                         GST_INFO_OBJECT(justThis-&gt;pipeline(), &quot;--&gt; needs keyframe (%s)&quot;,
128                             err-&gt;message);
129                         justThis-&gt;m_needsKeyframe = true;
130                     }
131                     break;
132                 }
133                 default:
134                     break;
135                 }
136                 }), this);
137         } else {
138             /* FIXME - How could we handle missing keyframes case we do not plug parsers ? */
139             caps = gst_caps_new_empty_simple(Caps());
140         }
141         g_object_set(decoder, &quot;caps&quot;, caps.get(), nullptr);
142 
143         m_sink = makeElement(&quot;appsink&quot;);
144         gst_app_sink_set_emit_signals(GST_APP_SINK(m_sink), true);
145         // This is an decoder, everything should happen as fast as possible and not
146         // be synced on the clock.
147         g_object_set(m_sink, &quot;sync&quot;, false, nullptr);
148 
149         gst_bin_add_many(GST_BIN(pipeline()), m_src, decoder, capsfilter, m_sink, nullptr);
150         if (!gst_element_link(m_src, decoder)) {
151             GST_ERROR_OBJECT(pipeline(), &quot;Could not link src to decoder.&quot;);
152             return WEBRTC_VIDEO_CODEC_ERROR;
153         }
154 
155         if (!gst_element_link(capsfilter, m_sink)) {
156             GST_ERROR_OBJECT(pipeline(), &quot;Could not link capsfilter to sink.&quot;);
157             return WEBRTC_VIDEO_CODEC_ERROR;
158         }
159 
160         if (gst_element_set_state(pipeline(), GST_STATE_PLAYING) == GST_STATE_CHANGE_FAILURE) {
161             GST_ERROR_OBJECT(pipeline(), &quot;Could not set state to PLAYING.&quot;);
162             return WEBRTC_VIDEO_CODEC_ERROR;
163         }
164 
165         return WEBRTC_VIDEO_CODEC_OK;
166     }
167 
168     int32_t RegisterDecodeCompleteCallback(webrtc::DecodedImageCallback* callback)
169     {
170         m_imageReadyCb = callback;
171 
172         return WEBRTC_VIDEO_CODEC_OK;
173     }
174 
175     virtual GstElement* CreateFilter()
176     {
177         return makeElement(&quot;identity&quot;);
178     }
179 
180     int32_t Release() final
181     {
182         if (m_pipeline.get()) {
183             GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
184             gst_bus_set_sync_handler(bus.get(), nullptr, nullptr, nullptr);
185 
186             gst_element_set_state(m_pipeline.get(), GST_STATE_NULL);
187             m_src = nullptr;
188             m_sink = nullptr;
189             m_pipeline = nullptr;
190         }
191 
192         return WEBRTC_VIDEO_CODEC_OK;
193     }
194 
195     int32_t Decode(const webrtc::EncodedImage&amp; inputImage,
196         bool,
<a name="1" id="anc1"></a>
197         int64_t renderTimeMs) override
198     {
199         if (m_needsKeyframe) {
<a name="2" id="anc2"></a><span class="line-modified">200             if (inputImage._frameType != webrtc::VideoFrameType::kVideoFrameKey) {</span>
201                 GST_ERROR(&quot;Waiting for keyframe but got a delta unit... asking for keyframe&quot;);
202                 return WEBRTC_VIDEO_CODEC_ERROR;
203             }
204             if (inputImage._completeFrame)
205                 m_needsKeyframe = false;
206             else {
207                 GST_ERROR(&quot;Waiting for keyframe but didn&#39;t get full frame, getting out&quot;);
208                 return WEBRTC_VIDEO_CODEC_ERROR;
209             }
210         }
211 
212 
213         if (!m_src) {
214             GST_ERROR(&quot;No source set, can&#39;t decode.&quot;);
215 
216             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
217         }
218 
219         if (!GST_CLOCK_TIME_IS_VALID(m_firstBufferPts)) {
220             GRefPtr&lt;GstPad&gt; srcpad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
221             m_firstBufferPts = (static_cast&lt;guint64&gt;(renderTimeMs)) * GST_MSECOND;
222             m_firstBufferDts = (static_cast&lt;guint64&gt;(inputImage.Timestamp())) * GST_MSECOND;
223         }
224 
225         // FIXME- Use a GstBufferPool.
<a name="3" id="anc3"></a><span class="line-modified">226         auto buffer = adoptGRef(gst_buffer_new_wrapped(g_memdup(inputImage.data(), inputImage.size()),</span>
<span class="line-modified">227             inputImage.size()));</span>
228         GST_BUFFER_DTS(buffer.get()) = (static_cast&lt;guint64&gt;(inputImage.Timestamp()) * GST_MSECOND) - m_firstBufferDts;
229         GST_BUFFER_PTS(buffer.get()) = (static_cast&lt;guint64&gt;(renderTimeMs) * GST_MSECOND) - m_firstBufferPts;
230         InputTimestamps timestamps = {inputImage.Timestamp(), renderTimeMs};
231         m_dtsPtsMap[GST_BUFFER_PTS(buffer.get())] = timestamps;
232 
233         GST_LOG_OBJECT(pipeline(), &quot;%&quot; G_GINT64_FORMAT &quot; Decoding: %&quot; GST_PTR_FORMAT, renderTimeMs, buffer.get());
234         auto sample = adoptGRef(gst_sample_new(buffer.get(), GetCapsForFrame(inputImage), nullptr, nullptr));
235         switch (gst_app_src_push_sample(GST_APP_SRC(m_src), sample.get())) {
236         case GST_FLOW_OK:
237             break;
238         case GST_FLOW_FLUSHING:
239             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
240         default:
241             return WEBRTC_VIDEO_CODEC_ERROR;
242         }
243 
244         return pullSample();
245     }
246 
247     int32_t pullSample()
248     {
249         auto sample = gst_app_sink_try_pull_sample(GST_APP_SINK(m_sink), GST_SECOND / 30);
250         if (!sample) {
251             GST_ERROR(&quot;Needs more data&quot;);
252             return WEBRTC_VIDEO_CODEC_OK;
253         }
254         auto buffer = gst_sample_get_buffer(sample);
255 
256         // Make sure that the frame.timestamp == previsouly input_frame._timeStamp
257         // as it is required by the VideoDecoder baseclass.
258         auto timestamps = m_dtsPtsMap[GST_BUFFER_PTS(buffer)];
259         m_dtsPtsMap.erase(GST_BUFFER_PTS(buffer));
260 
261         auto frame(LibWebRTCVideoFrameFromGStreamerSample(sample, webrtc::kVideoRotation_0,
262             timestamps.timestamp, timestamps.renderTimeMs));
263 
264         GST_BUFFER_DTS(buffer) = GST_CLOCK_TIME_NONE;
265         GST_LOG_OBJECT(pipeline(), &quot;Output decoded frame! %d -&gt; %&quot; GST_PTR_FORMAT,
266             frame-&gt;timestamp(), buffer);
267 
268         m_imageReadyCb-&gt;Decoded(*frame.get(), absl::optional&lt;int32_t&gt;(), absl::optional&lt;uint8_t&gt;());
269 
270         return WEBRTC_VIDEO_CODEC_OK;
271     }
272 
273     virtual GstCaps* GetCapsForFrame(const webrtc::EncodedImage&amp; image)
274     {
275         if (!m_caps) {
276             m_caps = adoptGRef(gst_caps_new_simple(Caps(),
277                 &quot;width&quot;, G_TYPE_INT, image._encodedWidth ? image._encodedWidth : m_width,
278                 &quot;height&quot;, G_TYPE_INT, image._encodedHeight ? image._encodedHeight : m_height,
279                 nullptr));
280         }
281 
282         return m_caps.get();
283     }
284 
285     void AddDecoderIfSupported(std::vector&lt;webrtc::SdpVideoFormat&gt; codecList)
286     {
287         if (HasGstDecoder()) {
288             webrtc::SdpVideoFormat format = ConfigureSupportedDecoder();
289 
290             codecList.push_back(format);
291         }
292     }
293 
294     virtual webrtc::SdpVideoFormat ConfigureSupportedDecoder()
295     {
296         return webrtc::SdpVideoFormat(Name());
297     }
298 
299     static GRefPtr&lt;GstElementFactory&gt; GstDecoderFactory(const char *capsStr)
300     {
301         auto all_decoders = gst_element_factory_list_get_elements(GST_ELEMENT_FACTORY_TYPE_DECODER,
302             GST_RANK_MARGINAL);
303         auto caps = adoptGRef(gst_caps_from_string(capsStr));
304         auto decoders = gst_element_factory_list_filter(all_decoders,
305             caps.get(), GST_PAD_SINK, FALSE);
306 
307         gst_plugin_feature_list_free(all_decoders);
308         GRefPtr&lt;GstElementFactory&gt; res;
309         if (decoders)
310             res = GST_ELEMENT_FACTORY(decoders-&gt;data);
311         gst_plugin_feature_list_free(decoders);
312 
313         return res;
314     }
315 
316     bool HasGstDecoder()
317     {
318         return GstDecoderFactory(Caps());
319     }
320 
321     virtual const gchar* Caps() = 0;
322     virtual webrtc::VideoCodecType CodecType() = 0;
323     const char* ImplementationName() const { return &quot;GStreamer&quot;; }
324     virtual const gchar* Name() = 0;
325 
326 protected:
327     GRefPtr&lt;GstCaps&gt; m_caps;
328     gint m_pictureId;
329     gint m_width;
330     gint m_height;
331     bool m_requireParse = false;
332     bool m_needsKeyframe;
333 
334 private:
335     GRefPtr&lt;GstElement&gt; m_pipeline;
336     GstElement* m_sink;
337     GstElement* m_src;
338 
339     GstVideoInfo m_info;
340     webrtc::DecodedImageCallback* m_imageReadyCb;
341 
342     StdMap&lt;GstClockTime, InputTimestamps&gt; m_dtsPtsMap;
343     GstClockTime m_firstBufferPts;
344     GstClockTime m_firstBufferDts;
345 };
346 
347 class H264Decoder : public GStreamerVideoDecoder {
348 public:
349     H264Decoder() { m_requireParse = true; }
350 
351     int32_t InitDecode(const webrtc::VideoCodec* codecInfo, int32_t nCores) final
352     {
353         if (codecInfo &amp;&amp; codecInfo-&gt;codecType != webrtc::kVideoCodecH264)
354             return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
355 
<a name="4" id="anc4"></a>






















356         return GStreamerVideoDecoder::InitDecode(codecInfo, nCores);
357     }
358 
359     GstCaps* GetCapsForFrame(const webrtc::EncodedImage&amp; image) final
360     {
361         if (!m_caps) {
362             m_caps = adoptGRef(gst_caps_new_simple(Caps(),
363                 &quot;width&quot;, G_TYPE_INT, image._encodedWidth ? image._encodedWidth : m_width,
364                 &quot;height&quot;, G_TYPE_INT, image._encodedHeight ? image._encodedHeight : m_height,
365                 &quot;alignment&quot;, G_TYPE_STRING, &quot;au&quot;,
366                 nullptr));
367         }
368 
369         return m_caps.get();
370     }
371     const gchar* Caps() final { return &quot;video/x-h264&quot;; }
372     const gchar* Name() final { return cricket::kH264CodecName; }
373     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecH264; }
<a name="5" id="anc5"></a>


374 };
375 
376 class VP8Decoder : public GStreamerVideoDecoder {
377 public:
378     VP8Decoder() { }
379     const gchar* Caps() final { return &quot;video/x-vp8&quot;; }
380     const gchar* Name() final { return cricket::kVp8CodecName; }
381     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecVP8; }
382     static std::unique_ptr&lt;webrtc::VideoDecoder&gt; Create()
383     {
384         auto factory = GstDecoderFactory(&quot;video/x-vp8&quot;);
385 
386         if (factory &amp;&amp; !g_strcmp0(GST_OBJECT_NAME(GST_OBJECT(factory.get())), &quot;vp8dec&quot;)) {
387             GST_INFO(&quot;Our best GStreamer VP8 decoder is vp8dec, better use the one from LibWebRTC&quot;);
388 
389             return std::unique_ptr&lt;webrtc::VideoDecoder&gt;(new webrtc::LibvpxVp8Decoder());
390         }
391 
392         return std::unique_ptr&lt;webrtc::VideoDecoder&gt;(new VP8Decoder());
393     }
394 };
395 
396 std::unique_ptr&lt;webrtc::VideoDecoder&gt; GStreamerVideoDecoderFactory::CreateVideoDecoder(const webrtc::SdpVideoFormat&amp; format)
397 {
398     webrtc::VideoDecoder* dec;
399 
400     if (format.name == cricket::kH264CodecName)
401         dec = new H264Decoder();
402     else if (format.name == cricket::kVp8CodecName)
403         return VP8Decoder::Create();
404     else {
405         GST_ERROR(&quot;Could not create decoder for %s&quot;, format.name.c_str());
406 
407         return nullptr;
408     }
409 
410     return std::unique_ptr&lt;webrtc::VideoDecoder&gt;(dec);
411 }
412 
413 GStreamerVideoDecoderFactory::GStreamerVideoDecoderFactory()
414 {
415     static std::once_flag debugRegisteredFlag;
416 
417     std::call_once(debugRegisteredFlag, [] {
418         GST_DEBUG_CATEGORY_INIT(webkit_webrtcdec_debug, &quot;webkitlibwebrtcvideodecoder&quot;, 0, &quot;WebKit WebRTC video decoder&quot;);
419     });
420 }
421 std::vector&lt;webrtc::SdpVideoFormat&gt; GStreamerVideoDecoderFactory::GetSupportedFormats() const
422 {
423     std::vector&lt;webrtc::SdpVideoFormat&gt; formats;
424 
425     VP8Decoder().AddDecoderIfSupported(formats);
426     H264Decoder().AddDecoderIfSupported(formats);
427 
428     return formats;
429 }
430 }
431 #endif
<a name="6" id="anc6"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="6" type="hidden" />
</body>
</html>