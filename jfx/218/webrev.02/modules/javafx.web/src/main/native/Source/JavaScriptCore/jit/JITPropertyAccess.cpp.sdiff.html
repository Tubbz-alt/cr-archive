<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JITPropertyAccess.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="JITOperationsMSVC64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="JITPropertyAccess32_64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JITPropertyAccess.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 
  28 #if ENABLE(JIT)
  29 #include &quot;JIT.h&quot;
  30 
  31 #include &quot;CodeBlock.h&quot;
  32 #include &quot;DirectArguments.h&quot;
  33 #include &quot;GCAwareJITStubRoutine.h&quot;
  34 #include &quot;GetterSetter.h&quot;
  35 #include &quot;InterpreterInlines.h&quot;
  36 #include &quot;JITInlines.h&quot;
  37 #include &quot;JSArray.h&quot;
  38 #include &quot;JSFunction.h&quot;
  39 #include &quot;JSLexicalEnvironment.h&quot;

  40 #include &quot;LinkBuffer.h&quot;
  41 #include &quot;OpcodeInlines.h&quot;
  42 #include &quot;ResultType.h&quot;
  43 #include &quot;ScopedArguments.h&quot;
  44 #include &quot;ScopedArgumentsTable.h&quot;
  45 #include &quot;SlowPathCall.h&quot;
  46 #include &quot;StructureStubInfo.h&quot;
  47 #include &quot;ThunkGenerators.h&quot;
  48 #include &lt;wtf/ScopedLambda.h&gt;
  49 #include &lt;wtf/StringPrintStream.h&gt;
  50 
  51 
  52 namespace JSC {
  53 #if USE(JSVALUE64)
  54 
  55 void JIT::emit_op_get_by_val(const Instruction* currentInstruction)
  56 {
  57     auto bytecode = currentInstruction-&gt;as&lt;OpGetByVal&gt;();
  58     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified">  59     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified">  60     int base = bytecode.m_base.offset();</span>
<span class="line-modified">  61     int property = bytecode.m_property.offset();</span>
  62     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
<span class="line-removed">  63     ByValInfo* byValInfo = m_codeBlock-&gt;addByValInfo();</span>
  64 
  65     emitGetVirtualRegister(base, regT0);
<span class="line-modified">  66     bool propertyNameIsIntegerConstant = isOperandConstantInt(property);</span>
<span class="line-removed">  67     if (propertyNameIsIntegerConstant)</span>
<span class="line-removed">  68         move(Imm32(getOperandConstantInt(property)), regT1);</span>
<span class="line-removed">  69     else</span>
<span class="line-removed">  70         emitGetVirtualRegister(property, regT1);</span>
<span class="line-removed">  71 </span>
<span class="line-removed">  72     emitJumpSlowCaseIfNotJSCell(regT0, base);</span>
<span class="line-removed">  73 </span>
<span class="line-removed">  74     PatchableJump notIndex;</span>
<span class="line-removed">  75     if (!propertyNameIsIntegerConstant) {</span>
<span class="line-removed">  76         notIndex = emitPatchableJumpIfNotInt(regT1);</span>
<span class="line-removed">  77         addSlowCase(notIndex);</span>
<span class="line-removed">  78 </span>
<span class="line-removed">  79         // This is technically incorrect - we&#39;re zero-extending an int32. On the hot path this doesn&#39;t matter.</span>
<span class="line-removed">  80         // We check the value as if it was a uint32 against the m_vectorLength - which will always fail if</span>
<span class="line-removed">  81         // number was signed since m_vectorLength is always less than intmax (since the total allocation</span>
<span class="line-removed">  82         // size is always less than 4Gb). As such zero extending will have been correct (and extending the value</span>
<span class="line-removed">  83         // to 64-bits is necessary since it&#39;s used in the address calculation). We zero extend rather than sign</span>
<span class="line-removed">  84         // extending since it makes it easier to re-tag the value in the slow case.</span>
<span class="line-removed">  85         zeroExtend32ToPtr(regT1, regT1);</span>
<span class="line-removed">  86     }</span>
<span class="line-removed">  87 </span>
<span class="line-removed">  88     emitArrayProfilingSiteWithCell(regT0, regT2, profile);</span>
<span class="line-removed">  89     and32(TrustedImm32(IndexingShapeMask), regT2);</span>
<span class="line-removed">  90 </span>
<span class="line-removed">  91     PatchableJump badType;</span>
<span class="line-removed">  92     JumpList slowCases;</span>
<span class="line-removed">  93 </span>
<span class="line-removed">  94     JITArrayMode mode = chooseArrayMode(profile);</span>
<span class="line-removed">  95     switch (mode) {</span>
<span class="line-removed">  96     case JITInt32:</span>
<span class="line-removed">  97         slowCases = emitInt32GetByVal(currentInstruction, badType);</span>
<span class="line-removed">  98         break;</span>
<span class="line-removed">  99     case JITDouble:</span>
<span class="line-removed"> 100         slowCases = emitDoubleGetByVal(currentInstruction, badType);</span>
<span class="line-removed"> 101         break;</span>
<span class="line-removed"> 102     case JITContiguous:</span>
<span class="line-removed"> 103         slowCases = emitContiguousGetByVal(currentInstruction, badType);</span>
<span class="line-removed"> 104         break;</span>
<span class="line-removed"> 105     case JITArrayStorage:</span>
<span class="line-removed"> 106         slowCases = emitArrayStorageGetByVal(currentInstruction, badType);</span>
<span class="line-removed"> 107         break;</span>
<span class="line-removed"> 108     default:</span>
<span class="line-removed"> 109         CRASH();</span>
<span class="line-removed"> 110         break;</span>
<span class="line-removed"> 111     }</span>
<span class="line-removed"> 112 </span>
<span class="line-removed"> 113     addSlowCase(badType);</span>
<span class="line-removed"> 114     addSlowCase(slowCases);</span>
<span class="line-removed"> 115 </span>
<span class="line-removed"> 116     Label done = label();</span>
 117 
<span class="line-modified"> 118     if (!ASSERT_DISABLED) {</span>
<span class="line-modified"> 119         Jump resultOK = branchIfNotEmpty(regT0);</span>
<span class="line-modified"> 120         abortWithReason(JITGetByValResultIsNotEmpty);</span>
<span class="line-modified"> 121         resultOK.link(this);</span>
















 122     }
 123 
<span class="line-removed"> 124     emitValueProfilingSite(metadata);</span>
<span class="line-removed"> 125     emitPutVirtualRegister(dst);</span>
<span class="line-removed"> 126 </span>
<span class="line-removed"> 127     Label nextHotPath = label();</span>
<span class="line-removed"> 128 </span>
<span class="line-removed"> 129     m_byValCompilationInfo.append(ByValCompilationInfo(byValInfo, m_bytecodeOffset, notIndex, badType, mode, profile, done, nextHotPath));</span>
<span class="line-removed"> 130 }</span>
<span class="line-removed"> 131 </span>
<span class="line-removed"> 132 JITGetByIdGenerator JIT::emitGetByValWithCachedId(ByValInfo* byValInfo, OpGetByVal bytecode, const Identifier&amp; propertyName, Jump&amp; fastDoneCase, Jump&amp; slowDoneCase, JumpList&amp; slowCases)</span>
<span class="line-removed"> 133 {</span>
<span class="line-removed"> 134     // base: regT0</span>
<span class="line-removed"> 135     // property: regT1</span>
<span class="line-removed"> 136     // scratch: regT3</span>
<span class="line-removed"> 137 </span>
<span class="line-removed"> 138     int dst = bytecode.m_dst.offset();</span>
<span class="line-removed"> 139 </span>
<span class="line-removed"> 140     slowCases.append(branchIfNotCell(regT1));</span>
<span class="line-removed"> 141     emitByValIdentifierCheck(byValInfo, regT1, regT3, propertyName, slowCases);</span>
<span class="line-removed"> 142 </span>
<span class="line-removed"> 143     JITGetByIdGenerator gen(</span>
<span class="line-removed"> 144         m_codeBlock, CodeOrigin(m_bytecodeOffset), CallSiteIndex(m_bytecodeOffset), RegisterSet::stubUnavailableRegisters(),</span>
<span class="line-removed"> 145         propertyName.impl(), JSValueRegs(regT0), JSValueRegs(regT0), AccessType::Get);</span>
<span class="line-removed"> 146     gen.generateFastPath(*this);</span>
<span class="line-removed"> 147 </span>
<span class="line-removed"> 148     fastDoneCase = jump();</span>
<span class="line-removed"> 149 </span>
<span class="line-removed"> 150     Label coldPathBegin = label();</span>
<span class="line-removed"> 151     gen.slowPathJump().link(this);</span>
<span class="line-removed"> 152 </span>
<span class="line-removed"> 153     Call call = callOperationWithProfile(bytecode.metadata(m_codeBlock), operationGetByIdOptimize, dst, gen.stubInfo(), regT0, propertyName.impl());</span>
<span class="line-removed"> 154     gen.reportSlowPathCall(coldPathBegin, call);</span>
<span class="line-removed"> 155     slowDoneCase = jump();</span>
<span class="line-removed"> 156 </span>
<span class="line-removed"> 157     return gen;</span>
 158 }
 159 
 160 void JIT::emitSlow_op_get_by_val(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 161 {
<span class="line-modified"> 162     auto bytecode = currentInstruction-&gt;as&lt;OpGetByVal&gt;();</span>
<span class="line-modified"> 163     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 164     int base = bytecode.m_base.offset();</span>
<span class="line-modified"> 165     int property = bytecode.m_property.offset();</span>
<span class="line-modified"> 166     ByValInfo* byValInfo = m_byValCompilationInfo[m_byValInstructionIndex].byValInfo;</span>
<span class="line-modified"> 167 </span>
<span class="line-modified"> 168     linkSlowCaseIfNotJSCell(iter, base); // base cell check</span>
<span class="line-modified"> 169 </span>
<span class="line-modified"> 170     if (!isOperandConstantInt(property))</span>
<span class="line-modified"> 171         linkSlowCase(iter); // property int32 check</span>
<span class="line-modified"> 172     Jump nonCell = jump();</span>
<span class="line-modified"> 173     linkSlowCase(iter); // base array check</span>
<span class="line-modified"> 174     Jump notString = branchIfNotString(regT0);</span>
<span class="line-modified"> 175     emitNakedCall(CodeLocationLabel&lt;NoPtrTag&gt;(m_vm-&gt;getCTIStub(stringGetByValGenerator).retaggedCode&lt;NoPtrTag&gt;()));</span>
<span class="line-removed"> 176     Jump failed = branchTest64(Zero, regT0);</span>
<span class="line-removed"> 177     emitPutVirtualRegister(dst, regT0);</span>
<span class="line-removed"> 178     emitJumpSlowToHot(jump(), currentInstruction-&gt;size());</span>
<span class="line-removed"> 179     failed.link(this);</span>
<span class="line-removed"> 180     notString.link(this);</span>
<span class="line-removed"> 181     nonCell.link(this);</span>
<span class="line-removed"> 182 </span>
<span class="line-removed"> 183     linkSlowCase(iter); // vector length check</span>
<span class="line-removed"> 184     linkSlowCase(iter); // empty value</span>
<span class="line-removed"> 185 </span>
<span class="line-removed"> 186     Label slowPath = label();</span>
<span class="line-removed"> 187 </span>
<span class="line-removed"> 188     emitGetVirtualRegister(base, regT0);</span>
<span class="line-removed"> 189     emitGetVirtualRegister(property, regT1);</span>
<span class="line-removed"> 190     Call call = callOperation(operationGetByValOptimize, dst, regT0, regT1, byValInfo);</span>
<span class="line-removed"> 191 </span>
<span class="line-removed"> 192     m_byValCompilationInfo[m_byValInstructionIndex].slowPathTarget = slowPath;</span>
<span class="line-removed"> 193     m_byValCompilationInfo[m_byValInstructionIndex].returnAddress = call;</span>
<span class="line-removed"> 194     m_byValInstructionIndex++;</span>
<span class="line-removed"> 195 </span>
<span class="line-removed"> 196     emitValueProfilingSite(bytecode.metadata(m_codeBlock));</span>
 197 }
 198 
 199 void JIT::emit_op_put_by_val_direct(const Instruction* currentInstruction)
 200 {
 201     emit_op_put_by_val&lt;OpPutByValDirect&gt;(currentInstruction);
 202 }
 203 
 204 template&lt;typename Op&gt;
 205 void JIT::emit_op_put_by_val(const Instruction* currentInstruction)
 206 {
 207     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
 208     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 209     int base = bytecode.m_base.offset();</span>
<span class="line-modified"> 210     int property = bytecode.m_property.offset();</span>
 211     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
 212     ByValInfo* byValInfo = m_codeBlock-&gt;addByValInfo();
 213 
 214     emitGetVirtualRegister(base, regT0);
 215     bool propertyNameIsIntegerConstant = isOperandConstantInt(property);
 216     if (propertyNameIsIntegerConstant)
 217         move(Imm32(getOperandConstantInt(property)), regT1);
 218     else
 219         emitGetVirtualRegister(property, regT1);
 220 
 221     emitJumpSlowCaseIfNotJSCell(regT0, base);
 222     PatchableJump notIndex;
 223     if (!propertyNameIsIntegerConstant) {
 224         notIndex = emitPatchableJumpIfNotInt(regT1);
 225         addSlowCase(notIndex);
 226         // See comment in op_get_by_val.
 227         zeroExtend32ToPtr(regT1, regT1);
 228     }
 229     emitArrayProfilingSiteWithCell(regT0, regT2, profile);
 230 
</pre>
<hr />
<pre>
 242         break;
 243     case JITDouble:
 244         slowCases = emitDoublePutByVal(bytecode, badType);
 245         break;
 246     case JITContiguous:
 247         slowCases = emitContiguousPutByVal(bytecode, badType);
 248         break;
 249     case JITArrayStorage:
 250         slowCases = emitArrayStoragePutByVal(bytecode, badType);
 251         break;
 252     default:
 253         CRASH();
 254         break;
 255     }
 256 
 257     addSlowCase(badType);
 258     addSlowCase(slowCases);
 259 
 260     Label done = label();
 261 
<span class="line-modified"> 262     m_byValCompilationInfo.append(ByValCompilationInfo(byValInfo, m_bytecodeOffset, notIndex, badType, mode, profile, done, done));</span>
 263 }
 264 
 265 template&lt;typename Op&gt;
 266 JIT::JumpList JIT::emitGenericContiguousPutByVal(Op bytecode, PatchableJump&amp; badType, IndexingType indexingShape)
 267 {
 268     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 269     int value = bytecode.m_value.offset();</span>
 270     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
 271 
 272     JumpList slowCases;
 273 
 274     badType = patchableBranch32(NotEqual, regT2, TrustedImm32(indexingShape));
 275 
 276     loadPtr(Address(regT0, JSObject::butterflyOffset()), regT2);
 277     Jump outOfBounds = branch32(AboveOrEqual, regT1, Address(regT2, Butterfly::offsetOfPublicLength()));
 278 
 279     Label storeResult = label();
 280     emitGetVirtualRegister(value, regT3);
 281     switch (indexingShape) {
 282     case Int32Shape:
 283         slowCases.append(branchIfNotInt32(regT3));
 284         store64(regT3, BaseIndex(regT2, regT1, TimesEight));
 285         break;
 286     case DoubleShape: {
 287         Jump notInt = branchIfNotInt32(regT3);
 288         convertInt32ToDouble(regT3, fpRegT0);
 289         Jump ready = jump();
 290         notInt.link(this);
<span class="line-modified"> 291         add64(tagTypeNumberRegister, regT3);</span>
 292         move64ToDouble(regT3, fpRegT0);
 293         slowCases.append(branchIfNaN(fpRegT0));
 294         ready.link(this);
 295         storeDouble(fpRegT0, BaseIndex(regT2, regT1, TimesEight));
 296         break;
 297     }
 298     case ContiguousShape:
 299         store64(regT3, BaseIndex(regT2, regT1, TimesEight));
<span class="line-modified"> 300         emitWriteBarrier(bytecode.m_base.offset(), value, ShouldFilterValue);</span>
 301         break;
 302     default:
 303         CRASH();
 304         break;
 305     }
 306 
 307     Jump done = jump();
 308     outOfBounds.link(this);
 309 
 310     slowCases.append(branch32(AboveOrEqual, regT1, Address(regT2, Butterfly::offsetOfVectorLength())));
 311 
 312     emitArrayProfileStoreToHoleSpecialCase(profile);
 313 
 314     add32(TrustedImm32(1), regT1, regT3);
 315     store32(regT3, Address(regT2, Butterfly::offsetOfPublicLength()));
 316     jump().linkTo(storeResult, this);
 317 
 318     done.link(this);
 319 
 320     return slowCases;
 321 }
 322 
 323 template&lt;typename Op&gt;
 324 JIT::JumpList JIT::emitArrayStoragePutByVal(Op bytecode, PatchableJump&amp; badType)
 325 {
 326     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 327     int value = bytecode.m_value.offset();</span>
 328     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
 329 
 330     JumpList slowCases;
 331 
 332     badType = patchableBranch32(NotEqual, regT2, TrustedImm32(ArrayStorageShape));
 333     loadPtr(Address(regT0, JSObject::butterflyOffset()), regT2);
 334     slowCases.append(branch32(AboveOrEqual, regT1, Address(regT2, ArrayStorage::vectorLengthOffset())));
 335 
 336     Jump empty = branchTest64(Zero, BaseIndex(regT2, regT1, TimesEight, ArrayStorage::vectorOffset()));
 337 
 338     Label storeResult(this);
 339     emitGetVirtualRegister(value, regT3);
 340     store64(regT3, BaseIndex(regT2, regT1, TimesEight, ArrayStorage::vectorOffset()));
<span class="line-modified"> 341     emitWriteBarrier(bytecode.m_base.offset(), value, ShouldFilterValue);</span>
 342     Jump end = jump();
 343 
 344     empty.link(this);
 345     emitArrayProfileStoreToHoleSpecialCase(profile);
 346     add32(TrustedImm32(1), Address(regT2, ArrayStorage::numValuesInVectorOffset()));
 347     branch32(Below, regT1, Address(regT2, ArrayStorage::lengthOffset())).linkTo(storeResult, this);
 348 
 349     add32(TrustedImm32(1), regT1);
 350     store32(regT1, Address(regT2, ArrayStorage::lengthOffset()));
 351     sub32(TrustedImm32(1), regT1);
 352     jump().linkTo(storeResult, this);
 353 
 354     end.link(this);
 355 
 356     return slowCases;
 357 }
 358 
 359 template&lt;typename Op&gt;
 360 JITPutByIdGenerator JIT::emitPutByValWithCachedId(ByValInfo* byValInfo, Op bytecode, PutKind putKind, const Identifier&amp; propertyName, JumpList&amp; doneCases, JumpList&amp; slowCases)
 361 {
 362     // base: regT0
 363     // property: regT1
 364     // scratch: regT2
 365 
<span class="line-modified"> 366     int base = bytecode.m_base.offset();</span>
<span class="line-modified"> 367     int value = bytecode.m_value.offset();</span>
 368 
 369     slowCases.append(branchIfNotCell(regT1));
 370     emitByValIdentifierCheck(byValInfo, regT1, regT1, propertyName, slowCases);
 371 
 372     // Write barrier breaks the registers. So after issuing the write barrier,
 373     // reload the registers.
 374     emitGetVirtualRegisters(base, regT0, value, regT1);
 375 
 376     JITPutByIdGenerator gen(
<span class="line-modified"> 377         m_codeBlock, CodeOrigin(m_bytecodeOffset), CallSiteIndex(m_bytecodeOffset), RegisterSet::stubUnavailableRegisters(),</span>
 378         JSValueRegs(regT0), JSValueRegs(regT1), regT2, m_codeBlock-&gt;ecmaMode(), putKind);
 379     gen.generateFastPath(*this);
 380     emitWriteBarrier(base, value, ShouldFilterBase);
 381     doneCases.append(jump());
 382 
 383     Label coldPathBegin = label();
 384     gen.slowPathJump().link(this);
 385 
<span class="line-modified"> 386     Call call = callOperation(gen.slowPathFunction(), gen.stubInfo(), regT1, regT0, propertyName.impl());</span>
 387     gen.reportSlowPathCall(coldPathBegin, call);
 388     doneCases.append(jump());
 389 
 390     return gen;
 391 }
 392 
 393 void JIT::emitSlow_op_put_by_val(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 394 {
 395     bool isDirect = currentInstruction-&gt;opcodeID() == op_put_by_val_direct;
<span class="line-modified"> 396     int base;</span>
<span class="line-modified"> 397     int property;</span>
<span class="line-modified"> 398     int value;</span>
 399 
 400     auto load = [&amp;](auto bytecode) {
<span class="line-modified"> 401         base = bytecode.m_base.offset();</span>
<span class="line-modified"> 402         property = bytecode.m_property.offset();</span>
<span class="line-modified"> 403         value = bytecode.m_value.offset();</span>
 404     };
 405 
 406     if (isDirect)
 407         load(currentInstruction-&gt;as&lt;OpPutByValDirect&gt;());
 408     else
 409         load(currentInstruction-&gt;as&lt;OpPutByVal&gt;());
 410 
 411     ByValInfo* byValInfo = m_byValCompilationInfo[m_byValInstructionIndex].byValInfo;
 412 
 413     linkAllSlowCases(iter);
 414     Label slowPath = label();
 415 
 416     emitGetVirtualRegister(base, regT0);
 417     emitGetVirtualRegister(property, regT1);
 418     emitGetVirtualRegister(value, regT2);
<span class="line-modified"> 419     Call call = callOperation(isDirect ? operationDirectPutByValOptimize : operationPutByValOptimize, regT0, regT1, regT2, byValInfo);</span>
 420 
 421     m_byValCompilationInfo[m_byValInstructionIndex].slowPathTarget = slowPath;
 422     m_byValCompilationInfo[m_byValInstructionIndex].returnAddress = call;
 423     m_byValInstructionIndex++;
 424 }
 425 
 426 void JIT::emit_op_put_getter_by_id(const Instruction* currentInstruction)
 427 {
 428     auto bytecode = currentInstruction-&gt;as&lt;OpPutGetterById&gt;();
<span class="line-modified"> 429     emitGetVirtualRegister(bytecode.m_base.offset(), regT0);</span>
 430     int32_t options = bytecode.m_attributes;
<span class="line-modified"> 431     emitGetVirtualRegister(bytecode.m_accessor.offset(), regT1);</span>
<span class="line-modified"> 432     callOperation(operationPutGetterById, regT0, m_codeBlock-&gt;identifier(bytecode.m_property).impl(), options, regT1);</span>
 433 }
 434 
 435 void JIT::emit_op_put_setter_by_id(const Instruction* currentInstruction)
 436 {
 437     auto bytecode = currentInstruction-&gt;as&lt;OpPutSetterById&gt;();
<span class="line-modified"> 438     emitGetVirtualRegister(bytecode.m_base.offset(), regT0);</span>
 439     int32_t options = bytecode.m_attributes;
<span class="line-modified"> 440     emitGetVirtualRegister(bytecode.m_accessor.offset(), regT1);</span>
<span class="line-modified"> 441     callOperation(operationPutSetterById, regT0, m_codeBlock-&gt;identifier(bytecode.m_property).impl(), options, regT1);</span>
 442 }
 443 
 444 void JIT::emit_op_put_getter_setter_by_id(const Instruction* currentInstruction)
 445 {
 446     auto bytecode = currentInstruction-&gt;as&lt;OpPutGetterSetterById&gt;();
<span class="line-modified"> 447     emitGetVirtualRegister(bytecode.m_base.offset(), regT0);</span>
 448     int32_t attribute = bytecode.m_attributes;
<span class="line-modified"> 449     emitGetVirtualRegister(bytecode.m_getter.offset(), regT1);</span>
<span class="line-modified"> 450     emitGetVirtualRegister(bytecode.m_setter.offset(), regT2);</span>
<span class="line-modified"> 451     callOperation(operationPutGetterSetter, regT0, m_codeBlock-&gt;identifier(bytecode.m_property).impl(), attribute, regT1, regT2);</span>
 452 }
 453 
 454 void JIT::emit_op_put_getter_by_val(const Instruction* currentInstruction)
 455 {
 456     auto bytecode = currentInstruction-&gt;as&lt;OpPutGetterByVal&gt;();
<span class="line-modified"> 457     emitGetVirtualRegister(bytecode.m_base.offset(), regT0);</span>
<span class="line-modified"> 458     emitGetVirtualRegister(bytecode.m_property.offset(), regT1);</span>
 459     int32_t attributes = bytecode.m_attributes;
 460     emitGetVirtualRegister(bytecode.m_accessor, regT2);
<span class="line-modified"> 461     callOperation(operationPutGetterByVal, regT0, regT1, attributes, regT2);</span>
 462 }
 463 
 464 void JIT::emit_op_put_setter_by_val(const Instruction* currentInstruction)
 465 {
 466     auto bytecode = currentInstruction-&gt;as&lt;OpPutSetterByVal&gt;();
<span class="line-modified"> 467     emitGetVirtualRegister(bytecode.m_base.offset(), regT0);</span>
<span class="line-modified"> 468     emitGetVirtualRegister(bytecode.m_property.offset(), regT1);</span>
 469     int32_t attributes = bytecode.m_attributes;
<span class="line-modified"> 470     emitGetVirtualRegister(bytecode.m_accessor.offset(), regT2);</span>
<span class="line-modified"> 471     callOperation(operationPutSetterByVal, regT0, regT1, attributes, regT2);</span>
 472 }
 473 
 474 void JIT::emit_op_del_by_id(const Instruction* currentInstruction)
 475 {
 476     auto bytecode = currentInstruction-&gt;as&lt;OpDelById&gt;();
<span class="line-modified"> 477     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 478     int base = bytecode.m_base.offset();</span>
 479     int property = bytecode.m_property;
 480     emitGetVirtualRegister(base, regT0);
<span class="line-modified"> 481     callOperation(operationDeleteByIdJSResult, dst, regT0, m_codeBlock-&gt;identifier(property).impl());</span>
 482 }
 483 
 484 void JIT::emit_op_del_by_val(const Instruction* currentInstruction)
 485 {
 486     auto bytecode = currentInstruction-&gt;as&lt;OpDelByVal&gt;();
<span class="line-modified"> 487     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 488     int base = bytecode.m_base.offset();</span>
<span class="line-modified"> 489     int property = bytecode.m_property.offset();</span>
 490     emitGetVirtualRegister(base, regT0);
 491     emitGetVirtualRegister(property, regT1);
<span class="line-modified"> 492     callOperation(operationDeleteByValJSResult, dst, regT0, regT1);</span>
 493 }
 494 
 495 void JIT::emit_op_try_get_by_id(const Instruction* currentInstruction)
 496 {
 497     auto bytecode = currentInstruction-&gt;as&lt;OpTryGetById&gt;();
<span class="line-modified"> 498     int resultVReg = bytecode.m_dst.offset();</span>
<span class="line-modified"> 499     int baseVReg = bytecode.m_base.offset();</span>
 500     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 501 
 502     emitGetVirtualRegister(baseVReg, regT0);
 503 
 504     emitJumpSlowCaseIfNotJSCell(regT0, baseVReg);
 505 
 506     JITGetByIdGenerator gen(
<span class="line-modified"> 507         m_codeBlock, CodeOrigin(m_bytecodeOffset), CallSiteIndex(m_bytecodeOffset), RegisterSet::stubUnavailableRegisters(),</span>
<span class="line-modified"> 508         ident-&gt;impl(), JSValueRegs(regT0), JSValueRegs(regT0), AccessType::TryGet);</span>
 509     gen.generateFastPath(*this);
 510     addSlowCase(gen.slowPathJump());
 511     m_getByIds.append(gen);
 512 
 513     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 514     emitPutVirtualRegister(resultVReg);
 515 }
 516 
 517 void JIT::emitSlow_op_try_get_by_id(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 518 {
 519     linkAllSlowCases(iter);
 520 
 521     auto bytecode = currentInstruction-&gt;as&lt;OpTryGetById&gt;();
<span class="line-modified"> 522     int resultVReg = bytecode.m_dst.offset();</span>
 523     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 524 
 525     JITGetByIdGenerator&amp; gen = m_getByIds[m_getByIdIndex++];
 526 
 527     Label coldPathBegin = label();
 528 
<span class="line-modified"> 529     Call call = callOperation(operationTryGetByIdOptimize, resultVReg, gen.stubInfo(), regT0, ident-&gt;impl());</span>
 530 
 531     gen.reportSlowPathCall(coldPathBegin, call);
 532 }
 533 
 534 void JIT::emit_op_get_by_id_direct(const Instruction* currentInstruction)
 535 {
 536     auto bytecode = currentInstruction-&gt;as&lt;OpGetByIdDirect&gt;();
<span class="line-modified"> 537     int resultVReg = bytecode.m_dst.offset();</span>
<span class="line-modified"> 538     int baseVReg = bytecode.m_base.offset();</span>
 539     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 540 
 541     emitGetVirtualRegister(baseVReg, regT0);
 542 
 543     emitJumpSlowCaseIfNotJSCell(regT0, baseVReg);
 544 
 545     JITGetByIdGenerator gen(
<span class="line-modified"> 546         m_codeBlock, CodeOrigin(m_bytecodeOffset), CallSiteIndex(m_bytecodeOffset), RegisterSet::stubUnavailableRegisters(),</span>
<span class="line-modified"> 547         ident-&gt;impl(), JSValueRegs(regT0), JSValueRegs(regT0), AccessType::GetDirect);</span>
 548     gen.generateFastPath(*this);
 549     addSlowCase(gen.slowPathJump());
 550     m_getByIds.append(gen);
 551 
 552     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 553     emitPutVirtualRegister(resultVReg);
 554 }
 555 
 556 void JIT::emitSlow_op_get_by_id_direct(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 557 {
 558     linkAllSlowCases(iter);
 559 
 560     auto bytecode = currentInstruction-&gt;as&lt;OpGetByIdDirect&gt;();
<span class="line-modified"> 561     int resultVReg = bytecode.m_dst.offset();</span>
 562     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 563 
 564     JITGetByIdGenerator&amp; gen = m_getByIds[m_getByIdIndex++];
 565 
 566     Label coldPathBegin = label();
 567 
<span class="line-modified"> 568     Call call = callOperationWithProfile(bytecode.metadata(m_codeBlock), operationGetByIdDirectOptimize, resultVReg, gen.stubInfo(), regT0, ident-&gt;impl());</span>
 569 
 570     gen.reportSlowPathCall(coldPathBegin, call);
 571 }
 572 
 573 void JIT::emit_op_get_by_id(const Instruction* currentInstruction)
 574 {
 575     auto bytecode = currentInstruction-&gt;as&lt;OpGetById&gt;();
 576     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 577     int resultVReg = bytecode.m_dst.offset();</span>
<span class="line-modified"> 578     int baseVReg = bytecode.m_base.offset();</span>
 579     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 580 
 581     emitGetVirtualRegister(baseVReg, regT0);
 582 
 583     emitJumpSlowCaseIfNotJSCell(regT0, baseVReg);
 584 
 585     if (*ident == m_vm-&gt;propertyNames-&gt;length &amp;&amp; shouldEmitProfiling()) {
 586         Jump notArrayLengthMode = branch8(NotEqual, AbsoluteAddress(&amp;metadata.m_modeMetadata.mode), TrustedImm32(static_cast&lt;uint8_t&gt;(GetByIdMode::ArrayLength)));
 587         emitArrayProfilingSiteWithCell(regT0, regT1, &amp;metadata.m_modeMetadata.arrayLengthMode.arrayProfile);
 588         notArrayLengthMode.link(this);
 589     }
 590 
 591     JITGetByIdGenerator gen(
<span class="line-modified"> 592         m_codeBlock, CodeOrigin(m_bytecodeOffset), CallSiteIndex(m_bytecodeOffset), RegisterSet::stubUnavailableRegisters(),</span>
<span class="line-modified"> 593         ident-&gt;impl(), JSValueRegs(regT0), JSValueRegs(regT0), AccessType::Get);</span>
 594     gen.generateFastPath(*this);
 595     addSlowCase(gen.slowPathJump());
 596     m_getByIds.append(gen);
 597 
 598     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 599     emitPutVirtualRegister(resultVReg);
 600 }
 601 
 602 void JIT::emit_op_get_by_id_with_this(const Instruction* currentInstruction)
 603 {
 604     auto bytecode = currentInstruction-&gt;as&lt;OpGetByIdWithThis&gt;();
<span class="line-modified"> 605     int resultVReg = bytecode.m_dst.offset();</span>
<span class="line-modified"> 606     int baseVReg = bytecode.m_base.offset();</span>
<span class="line-modified"> 607     int thisVReg = bytecode.m_thisValue.offset();</span>
 608     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 609 
 610     emitGetVirtualRegister(baseVReg, regT0);
 611     emitGetVirtualRegister(thisVReg, regT1);
 612     emitJumpSlowCaseIfNotJSCell(regT0, baseVReg);
 613     emitJumpSlowCaseIfNotJSCell(regT1, thisVReg);
 614 
 615     JITGetByIdWithThisGenerator gen(
<span class="line-modified"> 616         m_codeBlock, CodeOrigin(m_bytecodeOffset), CallSiteIndex(m_bytecodeOffset), RegisterSet::stubUnavailableRegisters(),</span>
<span class="line-modified"> 617         ident-&gt;impl(), JSValueRegs(regT0), JSValueRegs(regT0), JSValueRegs(regT1), AccessType::GetWithThis);</span>
 618     gen.generateFastPath(*this);
 619     addSlowCase(gen.slowPathJump());
 620     m_getByIdsWithThis.append(gen);
 621 
 622     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 623     emitPutVirtualRegister(resultVReg);
 624 }
 625 
 626 void JIT::emitSlow_op_get_by_id(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 627 {
 628     linkAllSlowCases(iter);
 629 
 630     auto bytecode = currentInstruction-&gt;as&lt;OpGetById&gt;();
<span class="line-modified"> 631     int resultVReg = bytecode.m_dst.offset();</span>
 632     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 633 
 634     JITGetByIdGenerator&amp; gen = m_getByIds[m_getByIdIndex++];
 635 
 636     Label coldPathBegin = label();
 637 
<span class="line-modified"> 638     Call call = callOperationWithProfile(bytecode.metadata(m_codeBlock), operationGetByIdOptimize, resultVReg, gen.stubInfo(), regT0, ident-&gt;impl());</span>
 639 
 640     gen.reportSlowPathCall(coldPathBegin, call);
 641 }
 642 
 643 void JIT::emitSlow_op_get_by_id_with_this(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 644 {
 645     linkAllSlowCases(iter);
 646 
 647     auto bytecode = currentInstruction-&gt;as&lt;OpGetByIdWithThis&gt;();
<span class="line-modified"> 648     int resultVReg = bytecode.m_dst.offset();</span>
 649     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 650 
 651     JITGetByIdWithThisGenerator&amp; gen = m_getByIdsWithThis[m_getByIdWithThisIndex++];
 652 
 653     Label coldPathBegin = label();
 654 
<span class="line-modified"> 655     Call call = callOperationWithProfile(bytecode.metadata(m_codeBlock), operationGetByIdWithThisOptimize, resultVReg, gen.stubInfo(), regT0, regT1, ident-&gt;impl());</span>
 656 
 657     gen.reportSlowPathCall(coldPathBegin, call);
 658 }
 659 
 660 void JIT::emit_op_put_by_id(const Instruction* currentInstruction)
 661 {
 662     auto bytecode = currentInstruction-&gt;as&lt;OpPutById&gt;();
<span class="line-modified"> 663     int baseVReg = bytecode.m_base.offset();</span>
<span class="line-modified"> 664     int valueVReg = bytecode.m_value.offset();</span>
 665     bool direct = !!(bytecode.m_flags &amp; PutByIdIsDirect);
 666 
 667     // In order to be able to patch both the Structure, and the object offset, we store one pointer,
 668     // to just after the arguments have been loaded into registers &#39;hotPathBegin&#39;, and we generate code
 669     // such that the Structure &amp; offset are always at the same distance from this.
 670 
 671     emitGetVirtualRegisters(baseVReg, regT0, valueVReg, regT1);
 672 
 673     emitJumpSlowCaseIfNotJSCell(regT0, baseVReg);
 674 
 675     JITPutByIdGenerator gen(
<span class="line-modified"> 676         m_codeBlock, CodeOrigin(m_bytecodeOffset), CallSiteIndex(m_bytecodeOffset), RegisterSet::stubUnavailableRegisters(),</span>
 677         JSValueRegs(regT0), JSValueRegs(regT1), regT2, m_codeBlock-&gt;ecmaMode(),
 678         direct ? Direct : NotDirect);
 679 
 680     gen.generateFastPath(*this);
 681     addSlowCase(gen.slowPathJump());
 682 
 683     emitWriteBarrier(baseVReg, valueVReg, ShouldFilterBase);
 684 
 685     m_putByIds.append(gen);
 686 }
 687 
 688 void JIT::emitSlow_op_put_by_id(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 689 {
 690     linkAllSlowCases(iter);
 691 
 692     auto bytecode = currentInstruction-&gt;as&lt;OpPutById&gt;();
 693     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 694 
 695     Label coldPathBegin(this);
 696 
 697     JITPutByIdGenerator&amp; gen = m_putByIds[m_putByIdIndex++];
 698 
<span class="line-modified"> 699     Call call = callOperation(gen.slowPathFunction(), gen.stubInfo(), regT1, regT0, ident-&gt;impl());</span>
 700 
 701     gen.reportSlowPathCall(coldPathBegin, call);
 702 }
 703 
 704 void JIT::emit_op_in_by_id(const Instruction* currentInstruction)
 705 {
 706     auto bytecode = currentInstruction-&gt;as&lt;OpInById&gt;();
<span class="line-modified"> 707     int resultVReg = bytecode.m_dst.offset();</span>
<span class="line-modified"> 708     int baseVReg = bytecode.m_base.offset();</span>
 709     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 710 
 711     emitGetVirtualRegister(baseVReg, regT0);
 712 
 713     emitJumpSlowCaseIfNotJSCell(regT0, baseVReg);
 714 
 715     JITInByIdGenerator gen(
<span class="line-modified"> 716         m_codeBlock, CodeOrigin(m_bytecodeOffset), CallSiteIndex(m_bytecodeOffset), RegisterSet::stubUnavailableRegisters(),</span>
 717         ident-&gt;impl(), JSValueRegs(regT0), JSValueRegs(regT0));
 718     gen.generateFastPath(*this);
 719     addSlowCase(gen.slowPathJump());
 720     m_inByIds.append(gen);
 721 
 722     emitPutVirtualRegister(resultVReg);
 723 }
 724 
 725 void JIT::emitSlow_op_in_by_id(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 726 {
 727     linkAllSlowCases(iter);
 728 
 729     auto bytecode = currentInstruction-&gt;as&lt;OpInById&gt;();
<span class="line-modified"> 730     int resultVReg = bytecode.m_dst.offset();</span>
 731     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 732 
 733     JITInByIdGenerator&amp; gen = m_inByIds[m_inByIdIndex++];
 734 
 735     Label coldPathBegin = label();
 736 
<span class="line-modified"> 737     Call call = callOperation(operationInByIdOptimize, resultVReg, gen.stubInfo(), regT0, ident-&gt;impl());</span>
 738 
 739     gen.reportSlowPathCall(coldPathBegin, call);
 740 }
 741 
 742 void JIT::emitVarInjectionCheck(bool needsVarInjectionChecks)
 743 {
 744     if (!needsVarInjectionChecks)
 745         return;
 746     addSlowCase(branch8(Equal, AbsoluteAddress(m_codeBlock-&gt;globalObject()-&gt;varInjectionWatchpoint()-&gt;addressOfState()), TrustedImm32(IsInvalidated)));
 747 }
 748 
<span class="line-modified"> 749 void JIT::emitResolveClosure(int dst, int scope, bool needsVarInjectionChecks, unsigned depth)</span>
 750 {
 751     emitVarInjectionCheck(needsVarInjectionChecks);
 752     emitGetVirtualRegister(scope, regT0);
 753     for (unsigned i = 0; i &lt; depth; ++i)
 754         loadPtr(Address(regT0, JSScope::offsetOfNext()), regT0);
 755     emitPutVirtualRegister(dst);
 756 }
 757 
 758 void JIT::emit_op_resolve_scope(const Instruction* currentInstruction)
 759 {
 760     auto bytecode = currentInstruction-&gt;as&lt;OpResolveScope&gt;();
 761     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 762     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 763     int scope = bytecode.m_scope.offset();</span>
 764     ResolveType resolveType = metadata.m_resolveType;
 765     unsigned depth = metadata.m_localScopeDepth;
 766 
 767     auto emitCode = [&amp;] (ResolveType resolveType) {
 768         switch (resolveType) {
 769         case GlobalProperty:
 770         case GlobalPropertyWithVarInjectionChecks: {
 771             JSScope* constantScope = JSScope::constantScopeForCodeBlock(resolveType, m_codeBlock);
 772             RELEASE_ASSERT(constantScope);
 773             emitVarInjectionCheck(needsVarInjectionChecks(resolveType));
 774             load32(&amp;metadata.m_globalLexicalBindingEpoch, regT1);
 775             addSlowCase(branch32(NotEqual, AbsoluteAddress(m_codeBlock-&gt;globalObject()-&gt;addressOfGlobalLexicalBindingEpoch()), regT1));
 776             move(TrustedImmPtr(constantScope), regT0);
 777             emitPutVirtualRegister(dst);
 778             break;
 779         }
 780 
 781         case GlobalVar:
 782         case GlobalVarWithVarInjectionChecks:
 783         case GlobalLexicalVar:
</pre>
<hr />
<pre>
 842         emitCode(GlobalLexicalVar);
 843         skipToEnd.append(jump());
 844         notGlobalLexicalVar.link(this);
 845 
 846         Jump notGlobalLexicalVarWithVarInjections = branch32(NotEqual, regT0, TrustedImm32(GlobalLexicalVarWithVarInjectionChecks));
 847         emitCode(GlobalLexicalVarWithVarInjectionChecks);
 848         skipToEnd.append(jump());
 849         notGlobalLexicalVarWithVarInjections.link(this);
 850 
 851         addSlowCase(jump());
 852         skipToEnd.link(this);
 853         break;
 854     }
 855 
 856     default:
 857         emitCode(resolveType);
 858         break;
 859     }
 860 }
 861 
<span class="line-modified"> 862 void JIT::emitLoadWithStructureCheck(int scope, Structure** structureSlot)</span>
 863 {
 864     loadPtr(structureSlot, regT1);
 865     emitGetVirtualRegister(scope, regT0);
 866     addSlowCase(branchTestPtr(Zero, regT1));
 867     load32(Address(regT1, Structure::structureIDOffset()), regT1);
 868     addSlowCase(branch32(NotEqual, Address(regT0, JSCell::structureIDOffset()), regT1));
 869 }
 870 
 871 void JIT::emitGetVarFromPointer(JSValue* operand, GPRReg reg)
 872 {
 873     loadPtr(operand, reg);
 874 }
 875 
 876 void JIT::emitGetVarFromIndirectPointer(JSValue** operand, GPRReg reg)
 877 {
 878     loadPtr(operand, reg);
 879     loadPtr(reg, reg);
 880 }
 881 
<span class="line-modified"> 882 void JIT::emitGetClosureVar(int scope, uintptr_t operand)</span>
 883 {
 884     emitGetVirtualRegister(scope, regT0);
 885     loadPtr(Address(regT0, JSLexicalEnvironment::offsetOfVariables() + operand * sizeof(Register)), regT0);
 886 }
 887 
 888 void JIT::emit_op_get_from_scope(const Instruction* currentInstruction)
 889 {
 890     auto bytecode = currentInstruction-&gt;as&lt;OpGetFromScope&gt;();
 891     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 892     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 893     int scope = bytecode.m_scope.offset();</span>
 894     ResolveType resolveType = metadata.m_getPutInfo.resolveType();
 895     Structure** structureSlot = metadata.m_structure.slot();
 896     uintptr_t* operandSlot = reinterpret_cast&lt;uintptr_t*&gt;(&amp;metadata.m_operand);
 897 
 898     auto emitCode = [&amp;] (ResolveType resolveType, bool indirectLoadForOperand) {
 899         switch (resolveType) {
 900         case GlobalProperty:
 901         case GlobalPropertyWithVarInjectionChecks: {
 902             emitLoadWithStructureCheck(scope, structureSlot); // Structure check covers var injection since we don&#39;t cache structures for anything but the GlobalObject. Additionally, resolve_scope handles checking for the var injection.
 903             GPRReg base = regT0;
 904             GPRReg result = regT0;
 905             GPRReg offset = regT1;
 906             GPRReg scratch = regT2;
 907 
 908             jitAssert(scopedLambda&lt;Jump(void)&gt;([&amp;] () -&gt; Jump {
 909                 return branchPtr(Equal, base, TrustedImmPtr(m_codeBlock-&gt;globalObject()));
 910             }));
 911 
 912             load32(operandSlot, offset);
<span class="line-modified"> 913             if (!ASSERT_DISABLED) {</span>
 914                 Jump isOutOfLine = branch32(GreaterThanOrEqual, offset, TrustedImm32(firstOutOfLineOffset));
 915                 abortWithReason(JITOffsetIsNotOutOfLine);
 916                 isOutOfLine.link(this);
 917             }
 918             loadPtr(Address(base, JSObject::butterflyOffset()), scratch);
 919             neg32(offset);
 920             signExtend32ToPtr(offset, offset);
 921             load64(BaseIndex(scratch, offset, TimesEight, (firstOutOfLineOffset - 2) * sizeof(EncodedJSValue)), result);
 922             break;
 923         }
 924         case GlobalVar:
 925         case GlobalVarWithVarInjectionChecks:
 926         case GlobalLexicalVar:
 927         case GlobalLexicalVarWithVarInjectionChecks:
 928             emitVarInjectionCheck(needsVarInjectionChecks(resolveType));
 929             if (indirectLoadForOperand)
 930                 emitGetVarFromIndirectPointer(bitwise_cast&lt;JSValue**&gt;(operandSlot), regT0);
 931             else
 932                 emitGetVarFromPointer(bitwise_cast&lt;JSValue*&gt;(*operandSlot), regT0);
 933             if (resolveType == GlobalLexicalVar || resolveType == GlobalLexicalVarWithVarInjectionChecks) // TDZ check.
</pre>
<hr />
<pre>
 991 
 992         addSlowCase(jump());
 993 
 994         skipToEnd.link(this);
 995         break;
 996     }
 997 
 998     default:
 999         emitCode(resolveType, false);
1000         break;
1001     }
1002     emitPutVirtualRegister(dst);
1003     emitValueProfilingSite(metadata);
1004 }
1005 
1006 void JIT::emitSlow_op_get_from_scope(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
1007 {
1008     linkAllSlowCases(iter);
1009 
1010     auto bytecode = currentInstruction-&gt;as&lt;OpGetFromScope&gt;();
<span class="line-modified">1011     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified">1012     callOperationWithProfile(bytecode.metadata(m_codeBlock), operationGetFromScope, dst, currentInstruction);</span>
1013 }
1014 
<span class="line-modified">1015 void JIT::emitPutGlobalVariable(JSValue* operand, int value, WatchpointSet* set)</span>
1016 {
1017     emitGetVirtualRegister(value, regT0);
1018     emitNotifyWrite(set);
1019     storePtr(regT0, operand);
1020 }
<span class="line-modified">1021 void JIT::emitPutGlobalVariableIndirect(JSValue** addressOfOperand, int value, WatchpointSet** indirectWatchpointSet)</span>
1022 {
1023     emitGetVirtualRegister(value, regT0);
1024     loadPtr(indirectWatchpointSet, regT1);
1025     emitNotifyWrite(regT1);
1026     loadPtr(addressOfOperand, regT1);
1027     storePtr(regT0, regT1);
1028 }
1029 
<span class="line-modified">1030 void JIT::emitPutClosureVar(int scope, uintptr_t operand, int value, WatchpointSet* set)</span>
1031 {
1032     emitGetVirtualRegister(value, regT1);
1033     emitGetVirtualRegister(scope, regT0);
1034     emitNotifyWrite(set);
1035     storePtr(regT1, Address(regT0, JSLexicalEnvironment::offsetOfVariables() + operand * sizeof(Register)));
1036 }
1037 
1038 void JIT::emit_op_put_to_scope(const Instruction* currentInstruction)
1039 {
1040     auto bytecode = currentInstruction-&gt;as&lt;OpPutToScope&gt;();
1041     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified">1042     int scope = bytecode.m_scope.offset();</span>
<span class="line-modified">1043     int value = bytecode.m_value.offset();</span>
1044     GetPutInfo getPutInfo = copiedGetPutInfo(bytecode);
1045     ResolveType resolveType = getPutInfo.resolveType();
1046     Structure** structureSlot = metadata.m_structure.slot();
1047     uintptr_t* operandSlot = reinterpret_cast&lt;uintptr_t*&gt;(&amp;metadata.m_operand);
1048 
1049     auto emitCode = [&amp;] (ResolveType resolveType, bool indirectLoadForOperand) {
1050         switch (resolveType) {
1051         case GlobalProperty:
1052         case GlobalPropertyWithVarInjectionChecks: {
1053             emitLoadWithStructureCheck(scope, structureSlot); // Structure check covers var injection since we don&#39;t cache structures for anything but the GlobalObject. Additionally, resolve_scope handles checking for the var injection.
1054             emitGetVirtualRegister(value, regT2);
1055 
1056             jitAssert(scopedLambda&lt;Jump(void)&gt;([&amp;] () -&gt; Jump {
1057                 return branchPtr(Equal, regT0, TrustedImmPtr(m_codeBlock-&gt;globalObject()));
1058             }));
1059 
1060             loadPtr(Address(regT0, JSObject::butterflyOffset()), regT0);
1061             loadPtr(operandSlot, regT1);
1062             negPtr(regT1);
1063             storePtr(regT2, BaseIndex(regT0, regT1, TimesEight, (firstOutOfLineOffset - 2) * sizeof(EncodedJSValue)));
</pre>
<hr />
<pre>
1152         skipToEnd.link(this);
1153         break;
1154     }
1155 
1156     default:
1157         emitCode(resolveType, false);
1158         break;
1159     }
1160 }
1161 
1162 void JIT::emitSlow_op_put_to_scope(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
1163 {
1164     linkAllSlowCases(iter);
1165 
1166     auto bytecode = currentInstruction-&gt;as&lt;OpPutToScope&gt;();
1167     ResolveType resolveType = copiedGetPutInfo(bytecode).resolveType();
1168     if (resolveType == ModuleVar) {
1169         JITSlowPathCall slowPathCall(this, currentInstruction, slow_path_throw_strict_mode_readonly_property_write_error);
1170         slowPathCall.call();
1171     } else
<span class="line-modified">1172         callOperation(operationPutToScope, currentInstruction);</span>
1173 }
1174 
1175 void JIT::emit_op_get_from_arguments(const Instruction* currentInstruction)
1176 {
1177     auto bytecode = currentInstruction-&gt;as&lt;OpGetFromArguments&gt;();
<span class="line-modified">1178     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified">1179     int arguments = bytecode.m_arguments.offset();</span>
1180     int index = bytecode.m_index;
1181 
1182     emitGetVirtualRegister(arguments, regT0);
1183     load64(Address(regT0, DirectArguments::storageOffset() + index * sizeof(WriteBarrier&lt;Unknown&gt;)), regT0);
1184     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
1185     emitPutVirtualRegister(dst);
1186 }
1187 
1188 void JIT::emit_op_put_to_arguments(const Instruction* currentInstruction)
1189 {
1190     auto bytecode = currentInstruction-&gt;as&lt;OpPutToArguments&gt;();
<span class="line-modified">1191     int arguments = bytecode.m_arguments.offset();</span>
1192     int index = bytecode.m_index;
<span class="line-modified">1193     int value = bytecode.m_value.offset();</span>
1194 
1195     emitGetVirtualRegister(arguments, regT0);
1196     emitGetVirtualRegister(value, regT1);
1197     store64(regT1, Address(regT0, DirectArguments::storageOffset() + index * sizeof(WriteBarrier&lt;Unknown&gt;)));
1198 
1199     emitWriteBarrier(arguments, value, ShouldFilterValue);
1200 }
1201 
<span class="line-modified">1202 void JIT::emitWriteBarrier(unsigned owner, unsigned value, WriteBarrierMode mode)</span>
1203 {
1204     Jump valueNotCell;
1205     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue) {
1206         emitGetVirtualRegister(value, regT0);
1207         valueNotCell = branchIfNotCell(regT0);
1208     }
1209 
1210     emitGetVirtualRegister(owner, regT0);
1211     Jump ownerNotCell;
1212     if (mode == ShouldFilterBaseAndValue || mode == ShouldFilterBase)
1213         ownerNotCell = branchIfNotCell(regT0);
1214 
1215     Jump ownerIsRememberedOrInEden = barrierBranch(vm(), regT0, regT1);
<span class="line-modified">1216     callOperation(operationWriteBarrierSlowPath, regT0);</span>
1217     ownerIsRememberedOrInEden.link(this);
1218 
1219     if (mode == ShouldFilterBaseAndValue || mode == ShouldFilterBase)
1220         ownerNotCell.link(this);
1221     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue)
1222         valueNotCell.link(this);
1223 }
1224 
<span class="line-modified">1225 void JIT::emitWriteBarrier(JSCell* owner, unsigned value, WriteBarrierMode mode)</span>
1226 {
1227     emitGetVirtualRegister(value, regT0);
1228     Jump valueNotCell;
1229     if (mode == ShouldFilterValue)
1230         valueNotCell = branchIfNotCell(regT0);
1231 
1232     emitWriteBarrier(owner);
1233 
1234     if (mode == ShouldFilterValue)
1235         valueNotCell.link(this);
1236 }
1237 




























1238 #else // USE(JSVALUE64)
1239 
<span class="line-modified">1240 void JIT::emitWriteBarrier(unsigned owner, unsigned value, WriteBarrierMode mode)</span>
1241 {
1242     Jump valueNotCell;
1243     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue) {
1244         emitLoadTag(value, regT0);
1245         valueNotCell = branchIfNotCell(regT0);
1246     }
1247 
1248     emitLoad(owner, regT0, regT1);
1249     Jump ownerNotCell;
1250     if (mode == ShouldFilterBase || mode == ShouldFilterBaseAndValue)
1251         ownerNotCell = branchIfNotCell(regT0);
1252 
1253     Jump ownerIsRememberedOrInEden = barrierBranch(vm(), regT1, regT2);
<span class="line-modified">1254     callOperation(operationWriteBarrierSlowPath, regT1);</span>
1255     ownerIsRememberedOrInEden.link(this);
1256 
1257     if (mode == ShouldFilterBase || mode == ShouldFilterBaseAndValue)
1258         ownerNotCell.link(this);
1259     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue)
1260         valueNotCell.link(this);
1261 }
1262 
<span class="line-modified">1263 void JIT::emitWriteBarrier(JSCell* owner, unsigned value, WriteBarrierMode mode)</span>
1264 {
1265     Jump valueNotCell;
1266     if (mode == ShouldFilterValue) {
1267         emitLoadTag(value, regT0);
1268         valueNotCell = branchIfNotCell(regT0);
1269     }
1270 
1271     emitWriteBarrier(owner);
1272 
1273     if (mode == ShouldFilterValue)
1274         valueNotCell.link(this);
1275 }
1276 
1277 #endif // USE(JSVALUE64)
1278 
1279 void JIT::emitWriteBarrier(JSCell* owner)
1280 {
1281     Jump ownerIsRememberedOrInEden = barrierBranch(vm(), owner, regT0);
<span class="line-modified">1282     callOperation(operationWriteBarrierSlowPath, owner);</span>
1283     ownerIsRememberedOrInEden.link(this);
1284 }
1285 
1286 void JIT::emitByValIdentifierCheck(ByValInfo* byValInfo, RegisterID cell, RegisterID scratch, const Identifier&amp; propertyName, JumpList&amp; slowCases)
1287 {
1288     if (propertyName.isSymbol())
1289         slowCases.append(branchPtr(NotEqual, cell, TrustedImmPtr(byValInfo-&gt;cachedSymbol.get())));
1290     else {
1291         slowCases.append(branchIfNotString(cell));
1292         loadPtr(Address(cell, JSString::offsetOfValue()), scratch);
1293         slowCases.append(branchPtr(NotEqual, scratch, TrustedImmPtr(propertyName.impl())));
1294     }
1295 }
1296 
<span class="line-removed">1297 void JIT::privateCompileGetByVal(const ConcurrentJSLocker&amp;, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
<span class="line-removed">1298 {</span>
<span class="line-removed">1299     const Instruction* currentInstruction = m_codeBlock-&gt;instructions().at(byValInfo-&gt;bytecodeIndex).ptr();</span>
<span class="line-removed">1300 </span>
<span class="line-removed">1301     PatchableJump badType;</span>
<span class="line-removed">1302     JumpList slowCases;</span>
<span class="line-removed">1303 </span>
<span class="line-removed">1304     switch (arrayMode) {</span>
<span class="line-removed">1305     case JITInt32:</span>
<span class="line-removed">1306         slowCases = emitInt32GetByVal(currentInstruction, badType);</span>
<span class="line-removed">1307         break;</span>
<span class="line-removed">1308     case JITDouble:</span>
<span class="line-removed">1309         slowCases = emitDoubleGetByVal(currentInstruction, badType);</span>
<span class="line-removed">1310         break;</span>
<span class="line-removed">1311     case JITContiguous:</span>
<span class="line-removed">1312         slowCases = emitContiguousGetByVal(currentInstruction, badType);</span>
<span class="line-removed">1313         break;</span>
<span class="line-removed">1314     case JITArrayStorage:</span>
<span class="line-removed">1315         slowCases = emitArrayStorageGetByVal(currentInstruction, badType);</span>
<span class="line-removed">1316         break;</span>
<span class="line-removed">1317     case JITDirectArguments:</span>
<span class="line-removed">1318         slowCases = emitDirectArgumentsGetByVal(currentInstruction, badType);</span>
<span class="line-removed">1319         break;</span>
<span class="line-removed">1320     case JITScopedArguments:</span>
<span class="line-removed">1321         slowCases = emitScopedArgumentsGetByVal(currentInstruction, badType);</span>
<span class="line-removed">1322         break;</span>
<span class="line-removed">1323     default:</span>
<span class="line-removed">1324         TypedArrayType type = typedArrayTypeForJITArrayMode(arrayMode);</span>
<span class="line-removed">1325         if (isInt(type))</span>
<span class="line-removed">1326             slowCases = emitIntTypedArrayGetByVal(currentInstruction, badType, type);</span>
<span class="line-removed">1327         else</span>
<span class="line-removed">1328             slowCases = emitFloatTypedArrayGetByVal(currentInstruction, badType, type);</span>
<span class="line-removed">1329         break;</span>
<span class="line-removed">1330     }</span>
<span class="line-removed">1331 </span>
<span class="line-removed">1332     Jump done = jump();</span>
<span class="line-removed">1333 </span>
<span class="line-removed">1334     LinkBuffer patchBuffer(*this, m_codeBlock);</span>
<span class="line-removed">1335 </span>
<span class="line-removed">1336     patchBuffer.link(badType, byValInfo-&gt;slowPathTarget);</span>
<span class="line-removed">1337     patchBuffer.link(slowCases, byValInfo-&gt;slowPathTarget);</span>
<span class="line-removed">1338 </span>
<span class="line-removed">1339     patchBuffer.link(done, byValInfo-&gt;badTypeDoneTarget);</span>
<span class="line-removed">1340 </span>
<span class="line-removed">1341     byValInfo-&gt;stubRoutine = FINALIZE_CODE_FOR_STUB(</span>
<span class="line-removed">1342         m_codeBlock, patchBuffer, JITStubRoutinePtrTag,</span>
<span class="line-removed">1343         &quot;Baseline get_by_val stub for %s, return point %p&quot;, toCString(*m_codeBlock).data(), returnAddress.value());</span>
<span class="line-removed">1344 </span>
<span class="line-removed">1345     MacroAssembler::repatchJump(byValInfo-&gt;badTypeJump, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(byValInfo-&gt;stubRoutine-&gt;code().code()));</span>
<span class="line-removed">1346     MacroAssembler::repatchCall(CodeLocationCall&lt;NoPtrTag&gt;(MacroAssemblerCodePtr&lt;NoPtrTag&gt;(returnAddress)), FunctionPtr&lt;OperationPtrTag&gt;(operationGetByValGeneric));</span>
<span class="line-removed">1347 }</span>
<span class="line-removed">1348 </span>
<span class="line-removed">1349 void JIT::privateCompileGetByValWithCachedId(ByValInfo* byValInfo, ReturnAddressPtr returnAddress, const Identifier&amp; propertyName)</span>
<span class="line-removed">1350 {</span>
<span class="line-removed">1351     const Instruction* currentInstruction = m_codeBlock-&gt;instructions().at(byValInfo-&gt;bytecodeIndex).ptr();</span>
<span class="line-removed">1352     auto bytecode = currentInstruction-&gt;as&lt;OpGetByVal&gt;();</span>
<span class="line-removed">1353 </span>
<span class="line-removed">1354     Jump fastDoneCase;</span>
<span class="line-removed">1355     Jump slowDoneCase;</span>
<span class="line-removed">1356     JumpList slowCases;</span>
<span class="line-removed">1357 </span>
<span class="line-removed">1358     JITGetByIdGenerator gen = emitGetByValWithCachedId(byValInfo, bytecode, propertyName, fastDoneCase, slowDoneCase, slowCases);</span>
<span class="line-removed">1359 </span>
<span class="line-removed">1360     ConcurrentJSLocker locker(m_codeBlock-&gt;m_lock);</span>
<span class="line-removed">1361     LinkBuffer patchBuffer(*this, m_codeBlock);</span>
<span class="line-removed">1362     patchBuffer.link(slowCases, byValInfo-&gt;slowPathTarget);</span>
<span class="line-removed">1363     patchBuffer.link(fastDoneCase, byValInfo-&gt;badTypeDoneTarget);</span>
<span class="line-removed">1364     patchBuffer.link(slowDoneCase, byValInfo-&gt;badTypeNextHotPathTarget);</span>
<span class="line-removed">1365     if (!m_exceptionChecks.empty())</span>
<span class="line-removed">1366         patchBuffer.link(m_exceptionChecks, byValInfo-&gt;exceptionHandler);</span>
<span class="line-removed">1367 </span>
<span class="line-removed">1368     for (const auto&amp; callSite : m_calls) {</span>
<span class="line-removed">1369         if (callSite.callee)</span>
<span class="line-removed">1370             patchBuffer.link(callSite.from, callSite.callee);</span>
<span class="line-removed">1371     }</span>
<span class="line-removed">1372     gen.finalize(patchBuffer, patchBuffer);</span>
<span class="line-removed">1373 </span>
<span class="line-removed">1374     byValInfo-&gt;stubRoutine = FINALIZE_CODE_FOR_STUB(</span>
<span class="line-removed">1375         m_codeBlock, patchBuffer, JITStubRoutinePtrTag,</span>
<span class="line-removed">1376         &quot;Baseline get_by_val with cached property name &#39;%s&#39; stub for %s, return point %p&quot;, propertyName.impl()-&gt;utf8().data(), toCString(*m_codeBlock).data(), returnAddress.value());</span>
<span class="line-removed">1377     byValInfo-&gt;stubInfo = gen.stubInfo();</span>
<span class="line-removed">1378 </span>
<span class="line-removed">1379     MacroAssembler::repatchJump(byValInfo-&gt;notIndexJump, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(byValInfo-&gt;stubRoutine-&gt;code().code()));</span>
<span class="line-removed">1380     MacroAssembler::repatchCall(CodeLocationCall&lt;NoPtrTag&gt;(MacroAssemblerCodePtr&lt;NoPtrTag&gt;(returnAddress)), FunctionPtr&lt;OperationPtrTag&gt;(operationGetByValGeneric));</span>
<span class="line-removed">1381 }</span>
<span class="line-removed">1382 </span>
1383 template&lt;typename Op&gt;
1384 void JIT::privateCompilePutByVal(const ConcurrentJSLocker&amp;, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)
1385 {
1386     const Instruction* currentInstruction = m_codeBlock-&gt;instructions().at(byValInfo-&gt;bytecodeIndex).ptr();
1387     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
1388 
1389     PatchableJump badType;
1390     JumpList slowCases;
1391 
1392     bool needsLinkForWriteBarrier = false;
1393 
1394     switch (arrayMode) {
1395     case JITInt32:
1396         slowCases = emitInt32PutByVal(bytecode, badType);
1397         break;
1398     case JITDouble:
1399         slowCases = emitDoublePutByVal(bytecode, badType);
1400         break;
1401     case JITContiguous:
1402         slowCases = emitContiguousPutByVal(bytecode, badType);
</pre>
<hr />
<pre>
1548     RegisterID property = regT2;
1549     RegisterID indexing = regT1;
1550     JSValueRegs result = JSValueRegs(regT1, regT0);
1551     RegisterID scratch = regT3;
1552 #endif
1553 
1554     JumpList slowCases;
1555 
1556     add32(TrustedImm32(-ArrayStorageShape), indexing, scratch);
1557     badType = patchableBranch32(Above, scratch, TrustedImm32(SlowPutArrayStorageShape - ArrayStorageShape));
1558 
1559     loadPtr(Address(base, JSObject::butterflyOffset()), scratch);
1560     slowCases.append(branch32(AboveOrEqual, property, Address(scratch, ArrayStorage::vectorLengthOffset())));
1561 
1562     loadValue(BaseIndex(scratch, property, TimesEight, ArrayStorage::vectorOffset()), result);
1563     slowCases.append(branchIfEmpty(result));
1564 
1565     return slowCases;
1566 }
1567 
<span class="line-removed">1568 JIT::JumpList JIT::emitDirectArgumentsGetByVal(const Instruction*, PatchableJump&amp; badType)</span>
<span class="line-removed">1569 {</span>
<span class="line-removed">1570     JumpList slowCases;</span>
<span class="line-removed">1571 </span>
<span class="line-removed">1572 #if USE(JSVALUE64)</span>
<span class="line-removed">1573     RegisterID base = regT0;</span>
<span class="line-removed">1574     RegisterID property = regT1;</span>
<span class="line-removed">1575     JSValueRegs result = JSValueRegs(regT0);</span>
<span class="line-removed">1576     RegisterID scratch = regT3;</span>
<span class="line-removed">1577     RegisterID scratch2 = regT4;</span>
<span class="line-removed">1578 #else</span>
<span class="line-removed">1579     RegisterID base = regT0;</span>
<span class="line-removed">1580     RegisterID property = regT2;</span>
<span class="line-removed">1581     JSValueRegs result = JSValueRegs(regT1, regT0);</span>
<span class="line-removed">1582     RegisterID scratch = regT3;</span>
<span class="line-removed">1583     RegisterID scratch2 = regT4;</span>
<span class="line-removed">1584 #endif</span>
<span class="line-removed">1585 </span>
<span class="line-removed">1586     load8(Address(base, JSCell::typeInfoTypeOffset()), scratch);</span>
<span class="line-removed">1587     badType = patchableBranch32(NotEqual, scratch, TrustedImm32(DirectArgumentsType));</span>
<span class="line-removed">1588 </span>
<span class="line-removed">1589     load32(Address(base, DirectArguments::offsetOfLength()), scratch2);</span>
<span class="line-removed">1590     slowCases.append(branch32(AboveOrEqual, property, scratch2));</span>
<span class="line-removed">1591     slowCases.append(branchTestPtr(NonZero, Address(base, DirectArguments::offsetOfMappedArguments())));</span>
<span class="line-removed">1592 </span>
<span class="line-removed">1593     loadValue(BaseIndex(base, property, TimesEight, DirectArguments::storageOffset()), result);</span>
<span class="line-removed">1594 </span>
<span class="line-removed">1595     return slowCases;</span>
<span class="line-removed">1596 }</span>
<span class="line-removed">1597 </span>
<span class="line-removed">1598 JIT::JumpList JIT::emitScopedArgumentsGetByVal(const Instruction*, PatchableJump&amp; badType)</span>
<span class="line-removed">1599 {</span>
<span class="line-removed">1600     JumpList slowCases;</span>
<span class="line-removed">1601 </span>
<span class="line-removed">1602 #if USE(JSVALUE64)</span>
<span class="line-removed">1603     RegisterID base = regT0;</span>
<span class="line-removed">1604     RegisterID property = regT1;</span>
<span class="line-removed">1605     JSValueRegs result = JSValueRegs(regT0);</span>
<span class="line-removed">1606     RegisterID scratch = regT3;</span>
<span class="line-removed">1607     RegisterID scratch2 = regT4;</span>
<span class="line-removed">1608     RegisterID scratch3 = regT5;</span>
<span class="line-removed">1609 #else</span>
<span class="line-removed">1610     RegisterID base = regT0;</span>
<span class="line-removed">1611     RegisterID property = regT2;</span>
<span class="line-removed">1612     JSValueRegs result = JSValueRegs(regT1, regT0);</span>
<span class="line-removed">1613     RegisterID scratch = regT3;</span>
<span class="line-removed">1614     RegisterID scratch2 = regT4;</span>
<span class="line-removed">1615     RegisterID scratch3 = regT5;</span>
<span class="line-removed">1616 #endif</span>
<span class="line-removed">1617 </span>
<span class="line-removed">1618     load8(Address(base, JSCell::typeInfoTypeOffset()), scratch);</span>
<span class="line-removed">1619     badType = patchableBranch32(NotEqual, scratch, TrustedImm32(ScopedArgumentsType));</span>
<span class="line-removed">1620     loadPtr(Address(base, ScopedArguments::offsetOfStorage()), scratch3);</span>
<span class="line-removed">1621     slowCases.append(branch32(AboveOrEqual, property, Address(scratch3, ScopedArguments::offsetOfTotalLengthInStorage())));</span>
<span class="line-removed">1622 </span>
<span class="line-removed">1623     loadPtr(Address(base, ScopedArguments::offsetOfTable()), scratch);</span>
<span class="line-removed">1624     load32(Address(scratch, ScopedArgumentsTable::offsetOfLength()), scratch2);</span>
<span class="line-removed">1625     Jump overflowCase = branch32(AboveOrEqual, property, scratch2);</span>
<span class="line-removed">1626     loadPtr(Address(base, ScopedArguments::offsetOfScope()), scratch2);</span>
<span class="line-removed">1627     loadPtr(Address(scratch, ScopedArgumentsTable::offsetOfArguments()), scratch);</span>
<span class="line-removed">1628     load32(BaseIndex(scratch, property, TimesFour), scratch);</span>
<span class="line-removed">1629     slowCases.append(branch32(Equal, scratch, TrustedImm32(ScopeOffset::invalidOffset)));</span>
<span class="line-removed">1630     loadValue(BaseIndex(scratch2, scratch, TimesEight, JSLexicalEnvironment::offsetOfVariables()), result);</span>
<span class="line-removed">1631     Jump done = jump();</span>
<span class="line-removed">1632     overflowCase.link(this);</span>
<span class="line-removed">1633     sub32(property, scratch2);</span>
<span class="line-removed">1634     neg32(scratch2);</span>
<span class="line-removed">1635     loadValue(BaseIndex(scratch3, scratch2, TimesEight), result);</span>
<span class="line-removed">1636     slowCases.append(branchIfEmpty(result));</span>
<span class="line-removed">1637     done.link(this);</span>
<span class="line-removed">1638 </span>
<span class="line-removed">1639     load32(Address(scratch3, ScopedArguments::offsetOfTotalLengthInStorage()), scratch);</span>
<span class="line-removed">1640     emitPreparePreciseIndexMask32(property, scratch, scratch2);</span>
<span class="line-removed">1641     andPtr(scratch2, result.payloadGPR());</span>
<span class="line-removed">1642 </span>
<span class="line-removed">1643     return slowCases;</span>
<span class="line-removed">1644 }</span>
<span class="line-removed">1645 </span>
<span class="line-removed">1646 JIT::JumpList JIT::emitIntTypedArrayGetByVal(const Instruction*, PatchableJump&amp; badType, TypedArrayType type)</span>
<span class="line-removed">1647 {</span>
<span class="line-removed">1648     ASSERT(isInt(type));</span>
<span class="line-removed">1649 </span>
<span class="line-removed">1650     // The best way to test the array type is to use the classInfo. We need to do so without</span>
<span class="line-removed">1651     // clobbering the register that holds the indexing type, base, and property.</span>
<span class="line-removed">1652 </span>
<span class="line-removed">1653 #if USE(JSVALUE64)</span>
<span class="line-removed">1654     RegisterID base = regT0;</span>
<span class="line-removed">1655     RegisterID property = regT1;</span>
<span class="line-removed">1656     JSValueRegs result = JSValueRegs(regT0);</span>
<span class="line-removed">1657     RegisterID scratch = regT3;</span>
<span class="line-removed">1658     RegisterID scratch2 = regT4;</span>
<span class="line-removed">1659 #else</span>
<span class="line-removed">1660     RegisterID base = regT0;</span>
<span class="line-removed">1661     RegisterID property = regT2;</span>
<span class="line-removed">1662     JSValueRegs result = JSValueRegs(regT1, regT0);</span>
<span class="line-removed">1663     RegisterID scratch = regT3;</span>
<span class="line-removed">1664     RegisterID scratch2 = regT4;</span>
<span class="line-removed">1665 #endif</span>
<span class="line-removed">1666     RegisterID resultPayload = result.payloadGPR();</span>
<span class="line-removed">1667 </span>
<span class="line-removed">1668     JumpList slowCases;</span>
<span class="line-removed">1669 </span>
<span class="line-removed">1670     load8(Address(base, JSCell::typeInfoTypeOffset()), scratch);</span>
<span class="line-removed">1671     badType = patchableBranch32(NotEqual, scratch, TrustedImm32(typeForTypedArrayType(type)));</span>
<span class="line-removed">1672     load32(Address(base, JSArrayBufferView::offsetOfLength()), scratch2);</span>
<span class="line-removed">1673     slowCases.append(branch32(AboveOrEqual, property, scratch2));</span>
<span class="line-removed">1674     loadPtr(Address(base, JSArrayBufferView::offsetOfVector()), scratch);</span>
<span class="line-removed">1675     cageConditionally(Gigacage::Primitive, scratch, scratch2, scratch2);</span>
<span class="line-removed">1676 </span>
<span class="line-removed">1677     switch (elementSize(type)) {</span>
<span class="line-removed">1678     case 1:</span>
<span class="line-removed">1679         if (JSC::isSigned(type))</span>
<span class="line-removed">1680             load8SignedExtendTo32(BaseIndex(scratch, property, TimesOne), resultPayload);</span>
<span class="line-removed">1681         else</span>
<span class="line-removed">1682             load8(BaseIndex(scratch, property, TimesOne), resultPayload);</span>
<span class="line-removed">1683         break;</span>
<span class="line-removed">1684     case 2:</span>
<span class="line-removed">1685         if (JSC::isSigned(type))</span>
<span class="line-removed">1686             load16SignedExtendTo32(BaseIndex(scratch, property, TimesTwo), resultPayload);</span>
<span class="line-removed">1687         else</span>
<span class="line-removed">1688             load16(BaseIndex(scratch, property, TimesTwo), resultPayload);</span>
<span class="line-removed">1689         break;</span>
<span class="line-removed">1690     case 4:</span>
<span class="line-removed">1691         load32(BaseIndex(scratch, property, TimesFour), resultPayload);</span>
<span class="line-removed">1692         break;</span>
<span class="line-removed">1693     default:</span>
<span class="line-removed">1694         CRASH();</span>
<span class="line-removed">1695     }</span>
<span class="line-removed">1696 </span>
<span class="line-removed">1697     Jump done;</span>
<span class="line-removed">1698     if (type == TypeUint32) {</span>
<span class="line-removed">1699         Jump canBeInt = branch32(GreaterThanOrEqual, resultPayload, TrustedImm32(0));</span>
<span class="line-removed">1700 </span>
<span class="line-removed">1701         convertInt32ToDouble(resultPayload, fpRegT0);</span>
<span class="line-removed">1702         addDouble(AbsoluteAddress(&amp;twoToThe32), fpRegT0);</span>
<span class="line-removed">1703         boxDouble(fpRegT0, result);</span>
<span class="line-removed">1704         done = jump();</span>
<span class="line-removed">1705         canBeInt.link(this);</span>
<span class="line-removed">1706     }</span>
<span class="line-removed">1707 </span>
<span class="line-removed">1708     boxInt32(resultPayload, result);</span>
<span class="line-removed">1709     if (done.isSet())</span>
<span class="line-removed">1710         done.link(this);</span>
<span class="line-removed">1711     return slowCases;</span>
<span class="line-removed">1712 }</span>
<span class="line-removed">1713 </span>
<span class="line-removed">1714 JIT::JumpList JIT::emitFloatTypedArrayGetByVal(const Instruction*, PatchableJump&amp; badType, TypedArrayType type)</span>
<span class="line-removed">1715 {</span>
<span class="line-removed">1716     ASSERT(isFloat(type));</span>
<span class="line-removed">1717 </span>
<span class="line-removed">1718 #if USE(JSVALUE64)</span>
<span class="line-removed">1719     RegisterID base = regT0;</span>
<span class="line-removed">1720     RegisterID property = regT1;</span>
<span class="line-removed">1721     JSValueRegs result = JSValueRegs(regT0);</span>
<span class="line-removed">1722     RegisterID scratch = regT3;</span>
<span class="line-removed">1723     RegisterID scratch2 = regT4;</span>
<span class="line-removed">1724 #else</span>
<span class="line-removed">1725     RegisterID base = regT0;</span>
<span class="line-removed">1726     RegisterID property = regT2;</span>
<span class="line-removed">1727     JSValueRegs result = JSValueRegs(regT1, regT0);</span>
<span class="line-removed">1728     RegisterID scratch = regT3;</span>
<span class="line-removed">1729     RegisterID scratch2 = regT4;</span>
<span class="line-removed">1730 #endif</span>
<span class="line-removed">1731 </span>
<span class="line-removed">1732     JumpList slowCases;</span>
<span class="line-removed">1733 </span>
<span class="line-removed">1734     load8(Address(base, JSCell::typeInfoTypeOffset()), scratch);</span>
<span class="line-removed">1735     badType = patchableBranch32(NotEqual, scratch, TrustedImm32(typeForTypedArrayType(type)));</span>
<span class="line-removed">1736     load32(Address(base, JSArrayBufferView::offsetOfLength()), scratch2);</span>
<span class="line-removed">1737     slowCases.append(branch32(AboveOrEqual, property, scratch2));</span>
<span class="line-removed">1738     loadPtr(Address(base, JSArrayBufferView::offsetOfVector()), scratch);</span>
<span class="line-removed">1739     cageConditionally(Gigacage::Primitive, scratch, scratch2, scratch2);</span>
<span class="line-removed">1740 </span>
<span class="line-removed">1741     switch (elementSize(type)) {</span>
<span class="line-removed">1742     case 4:</span>
<span class="line-removed">1743         loadFloat(BaseIndex(scratch, property, TimesFour), fpRegT0);</span>
<span class="line-removed">1744         convertFloatToDouble(fpRegT0, fpRegT0);</span>
<span class="line-removed">1745         break;</span>
<span class="line-removed">1746     case 8: {</span>
<span class="line-removed">1747         loadDouble(BaseIndex(scratch, property, TimesEight), fpRegT0);</span>
<span class="line-removed">1748         break;</span>
<span class="line-removed">1749     }</span>
<span class="line-removed">1750     default:</span>
<span class="line-removed">1751         CRASH();</span>
<span class="line-removed">1752     }</span>
<span class="line-removed">1753 </span>
<span class="line-removed">1754     purifyNaN(fpRegT0);</span>
<span class="line-removed">1755 </span>
<span class="line-removed">1756     boxDouble(fpRegT0, result);</span>
<span class="line-removed">1757     return slowCases;</span>
<span class="line-removed">1758 }</span>
<span class="line-removed">1759 </span>
1760 template&lt;typename Op&gt;
1761 JIT::JumpList JIT::emitIntTypedArrayPutByVal(Op bytecode, PatchableJump&amp; badType, TypedArrayType type)
1762 {
1763     auto&amp; metadata = bytecode.metadata(m_codeBlock);
1764     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
1765     ASSERT(isInt(type));
1766 
<span class="line-modified">1767     int value = bytecode.m_value.offset();</span>
1768 
1769 #if USE(JSVALUE64)
1770     RegisterID base = regT0;
1771     RegisterID property = regT1;
1772     RegisterID earlyScratch = regT3;
1773     RegisterID lateScratch = regT2;
1774     RegisterID lateScratch2 = regT4;
1775 #else
1776     RegisterID base = regT0;
1777     RegisterID property = regT2;
1778     RegisterID earlyScratch = regT3;
1779     RegisterID lateScratch = regT1;
1780     RegisterID lateScratch2 = regT4;
1781 #endif
1782 
1783     JumpList slowCases;
1784 
1785     load8(Address(base, JSCell::typeInfoTypeOffset()), earlyScratch);
1786     badType = patchableBranch32(NotEqual, earlyScratch, TrustedImm32(typeForTypedArrayType(type)));
1787     load32(Address(base, JSArrayBufferView::offsetOfLength()), lateScratch2);
</pre>
<hr />
<pre>
1823     case 2:
1824         store16(earlyScratch, BaseIndex(lateScratch, property, TimesTwo));
1825         break;
1826     case 4:
1827         store32(earlyScratch, BaseIndex(lateScratch, property, TimesFour));
1828         break;
1829     default:
1830         CRASH();
1831     }
1832 
1833     return slowCases;
1834 }
1835 
1836 template&lt;typename Op&gt;
1837 JIT::JumpList JIT::emitFloatTypedArrayPutByVal(Op bytecode, PatchableJump&amp; badType, TypedArrayType type)
1838 {
1839     auto&amp; metadata = bytecode.metadata(m_codeBlock);
1840     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
1841     ASSERT(isFloat(type));
1842 
<span class="line-modified">1843     int value = bytecode.m_value.offset();</span>
1844 
1845 #if USE(JSVALUE64)
1846     RegisterID base = regT0;
1847     RegisterID property = regT1;
1848     RegisterID earlyScratch = regT3;
1849     RegisterID lateScratch = regT2;
1850     RegisterID lateScratch2 = regT4;
1851 #else
1852     RegisterID base = regT0;
1853     RegisterID property = regT2;
1854     RegisterID earlyScratch = regT3;
1855     RegisterID lateScratch = regT1;
1856     RegisterID lateScratch2 = regT4;
1857 #endif
1858 
1859     JumpList slowCases;
1860 
1861     load8(Address(base, JSCell::typeInfoTypeOffset()), earlyScratch);
1862     badType = patchableBranch32(NotEqual, earlyScratch, TrustedImm32(typeForTypedArrayType(type)));
1863     load32(Address(base, JSArrayBufferView::offsetOfLength()), lateScratch2);
1864     Jump inBounds = branch32(Below, property, lateScratch2);
1865     emitArrayProfileOutOfBoundsSpecialCase(profile);
1866     slowCases.append(jump());
1867     inBounds.link(this);
1868 
1869 #if USE(JSVALUE64)
1870     emitGetVirtualRegister(value, earlyScratch);
1871     Jump doubleCase = branchIfNotInt32(earlyScratch);
1872     convertInt32ToDouble(earlyScratch, fpRegT0);
1873     Jump ready = jump();
1874     doubleCase.link(this);
1875     slowCases.append(branchIfNotNumber(earlyScratch));
<span class="line-modified">1876     add64(tagTypeNumberRegister, earlyScratch);</span>
1877     move64ToDouble(earlyScratch, fpRegT0);
1878     ready.link(this);
1879 #else
1880     emitLoad(value, lateScratch, earlyScratch);
1881     Jump doubleCase = branchIfNotInt32(lateScratch);
1882     convertInt32ToDouble(earlyScratch, fpRegT0);
1883     Jump ready = jump();
1884     doubleCase.link(this);
1885     slowCases.append(branch32(Above, lateScratch, TrustedImm32(JSValue::LowestTag)));
1886     moveIntsToDouble(earlyScratch, lateScratch, fpRegT0, fpRegT1);
1887     ready.link(this);
1888 #endif
1889 
1890     // We would be loading this into base as in get_by_val, except that the slow
1891     // path expects the base to be unclobbered.
1892     loadPtr(Address(base, JSArrayBufferView::offsetOfVector()), lateScratch);
1893     cageConditionally(Gigacage::Primitive, lateScratch, lateScratch2, lateScratch2);
1894 
1895     switch (elementSize(type)) {
1896     case 4:
</pre>
</td>
<td>
<hr />
<pre>
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 
  28 #if ENABLE(JIT)
  29 #include &quot;JIT.h&quot;
  30 
  31 #include &quot;CodeBlock.h&quot;
  32 #include &quot;DirectArguments.h&quot;
  33 #include &quot;GCAwareJITStubRoutine.h&quot;
  34 #include &quot;GetterSetter.h&quot;
  35 #include &quot;InterpreterInlines.h&quot;
  36 #include &quot;JITInlines.h&quot;
  37 #include &quot;JSArray.h&quot;
  38 #include &quot;JSFunction.h&quot;
  39 #include &quot;JSLexicalEnvironment.h&quot;
<span class="line-added">  40 #include &quot;JSPromise.h&quot;</span>
  41 #include &quot;LinkBuffer.h&quot;
  42 #include &quot;OpcodeInlines.h&quot;
  43 #include &quot;ResultType.h&quot;
  44 #include &quot;ScopedArguments.h&quot;
  45 #include &quot;ScopedArgumentsTable.h&quot;
  46 #include &quot;SlowPathCall.h&quot;
  47 #include &quot;StructureStubInfo.h&quot;
  48 #include &quot;ThunkGenerators.h&quot;
  49 #include &lt;wtf/ScopedLambda.h&gt;
  50 #include &lt;wtf/StringPrintStream.h&gt;
  51 
  52 
  53 namespace JSC {
  54 #if USE(JSVALUE64)
  55 
  56 void JIT::emit_op_get_by_val(const Instruction* currentInstruction)
  57 {
  58     auto bytecode = currentInstruction-&gt;as&lt;OpGetByVal&gt;();
  59     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified">  60     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified">  61     VirtualRegister base = bytecode.m_base;</span>
<span class="line-modified">  62     VirtualRegister property = bytecode.m_property;</span>
  63     ArrayProfile* profile = &amp;metadata.m_arrayProfile;

  64 
  65     emitGetVirtualRegister(base, regT0);
<span class="line-modified">  66     emitGetVirtualRegister(property, regT1);</span>


















































  67 
<span class="line-modified">  68     if (metadata.m_seenIdentifiers.count() &gt; Options::getByValICMaxNumberOfIdentifiers()) {</span>
<span class="line-modified">  69         auto notCell = branchIfNotCell(regT0);</span>
<span class="line-modified">  70         emitArrayProfilingSiteWithCell(regT0, regT2, profile);</span>
<span class="line-modified">  71         notCell.link(this);</span>
<span class="line-added">  72         callOperationWithProfile(bytecode.metadata(m_codeBlock), operationGetByVal, dst, TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0, regT1);</span>
<span class="line-added">  73     } else {</span>
<span class="line-added">  74         emitJumpSlowCaseIfNotJSCell(regT0, base);</span>
<span class="line-added">  75         emitArrayProfilingSiteWithCell(regT0, regT2, profile);</span>
<span class="line-added">  76 </span>
<span class="line-added">  77         JITGetByValGenerator gen(</span>
<span class="line-added">  78             m_codeBlock, CodeOrigin(m_bytecodeIndex), CallSiteIndex(m_bytecodeIndex), RegisterSet::stubUnavailableRegisters(),</span>
<span class="line-added">  79             JSValueRegs(regT0), JSValueRegs(regT1), JSValueRegs(regT0));</span>
<span class="line-added">  80         if (isOperandConstantInt(property))</span>
<span class="line-added">  81             gen.stubInfo()-&gt;propertyIsInt32 = true;</span>
<span class="line-added">  82         gen.generateFastPath(*this);</span>
<span class="line-added">  83         addSlowCase(gen.slowPathJump());</span>
<span class="line-added">  84         m_getByVals.append(gen);</span>
<span class="line-added">  85 </span>
<span class="line-added">  86         emitValueProfilingSite(bytecode.metadata(m_codeBlock));</span>
<span class="line-added">  87         emitPutVirtualRegister(dst);</span>
  88     }
  89 


































  90 }
  91 
  92 void JIT::emitSlow_op_get_by_val(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
  93 {
<span class="line-modified">  94     if (hasAnySlowCases(iter)) {</span>
<span class="line-modified">  95         auto bytecode = currentInstruction-&gt;as&lt;OpGetByVal&gt;();</span>
<span class="line-modified">  96         VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified">  97         auto&amp; metadata = bytecode.metadata(m_codeBlock);</span>
<span class="line-modified">  98         ArrayProfile* profile = &amp;metadata.m_arrayProfile;</span>
<span class="line-modified">  99 </span>
<span class="line-modified"> 100         linkAllSlowCases(iter);</span>
<span class="line-modified"> 101 </span>
<span class="line-modified"> 102         JITGetByValGenerator&amp; gen = m_getByVals[m_getByValIndex];</span>
<span class="line-modified"> 103         ++m_getByValIndex;</span>
<span class="line-modified"> 104         Label coldPathBegin = label();</span>
<span class="line-modified"> 105         Call call = callOperationWithProfile(bytecode.metadata(m_codeBlock), operationGetByValOptimize, dst, TrustedImmPtr(m_codeBlock-&gt;globalObject()), gen.stubInfo(), profile, regT0, regT1);</span>
<span class="line-modified"> 106         gen.reportSlowPathCall(coldPathBegin, call);</span>
<span class="line-modified"> 107     }</span>





















 108 }
 109 
 110 void JIT::emit_op_put_by_val_direct(const Instruction* currentInstruction)
 111 {
 112     emit_op_put_by_val&lt;OpPutByValDirect&gt;(currentInstruction);
 113 }
 114 
 115 template&lt;typename Op&gt;
 116 void JIT::emit_op_put_by_val(const Instruction* currentInstruction)
 117 {
 118     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
 119     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 120     VirtualRegister base = bytecode.m_base;</span>
<span class="line-modified"> 121     VirtualRegister property = bytecode.m_property;</span>
 122     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
 123     ByValInfo* byValInfo = m_codeBlock-&gt;addByValInfo();
 124 
 125     emitGetVirtualRegister(base, regT0);
 126     bool propertyNameIsIntegerConstant = isOperandConstantInt(property);
 127     if (propertyNameIsIntegerConstant)
 128         move(Imm32(getOperandConstantInt(property)), regT1);
 129     else
 130         emitGetVirtualRegister(property, regT1);
 131 
 132     emitJumpSlowCaseIfNotJSCell(regT0, base);
 133     PatchableJump notIndex;
 134     if (!propertyNameIsIntegerConstant) {
 135         notIndex = emitPatchableJumpIfNotInt(regT1);
 136         addSlowCase(notIndex);
 137         // See comment in op_get_by_val.
 138         zeroExtend32ToPtr(regT1, regT1);
 139     }
 140     emitArrayProfilingSiteWithCell(regT0, regT2, profile);
 141 
</pre>
<hr />
<pre>
 153         break;
 154     case JITDouble:
 155         slowCases = emitDoublePutByVal(bytecode, badType);
 156         break;
 157     case JITContiguous:
 158         slowCases = emitContiguousPutByVal(bytecode, badType);
 159         break;
 160     case JITArrayStorage:
 161         slowCases = emitArrayStoragePutByVal(bytecode, badType);
 162         break;
 163     default:
 164         CRASH();
 165         break;
 166     }
 167 
 168     addSlowCase(badType);
 169     addSlowCase(slowCases);
 170 
 171     Label done = label();
 172 
<span class="line-modified"> 173     m_byValCompilationInfo.append(ByValCompilationInfo(byValInfo, m_bytecodeIndex, notIndex, badType, mode, profile, done, done));</span>
 174 }
 175 
 176 template&lt;typename Op&gt;
 177 JIT::JumpList JIT::emitGenericContiguousPutByVal(Op bytecode, PatchableJump&amp; badType, IndexingType indexingShape)
 178 {
 179     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 180     VirtualRegister value = bytecode.m_value;</span>
 181     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
 182 
 183     JumpList slowCases;
 184 
 185     badType = patchableBranch32(NotEqual, regT2, TrustedImm32(indexingShape));
 186 
 187     loadPtr(Address(regT0, JSObject::butterflyOffset()), regT2);
 188     Jump outOfBounds = branch32(AboveOrEqual, regT1, Address(regT2, Butterfly::offsetOfPublicLength()));
 189 
 190     Label storeResult = label();
 191     emitGetVirtualRegister(value, regT3);
 192     switch (indexingShape) {
 193     case Int32Shape:
 194         slowCases.append(branchIfNotInt32(regT3));
 195         store64(regT3, BaseIndex(regT2, regT1, TimesEight));
 196         break;
 197     case DoubleShape: {
 198         Jump notInt = branchIfNotInt32(regT3);
 199         convertInt32ToDouble(regT3, fpRegT0);
 200         Jump ready = jump();
 201         notInt.link(this);
<span class="line-modified"> 202         add64(numberTagRegister, regT3);</span>
 203         move64ToDouble(regT3, fpRegT0);
 204         slowCases.append(branchIfNaN(fpRegT0));
 205         ready.link(this);
 206         storeDouble(fpRegT0, BaseIndex(regT2, regT1, TimesEight));
 207         break;
 208     }
 209     case ContiguousShape:
 210         store64(regT3, BaseIndex(regT2, regT1, TimesEight));
<span class="line-modified"> 211         emitWriteBarrier(bytecode.m_base, value, ShouldFilterValue);</span>
 212         break;
 213     default:
 214         CRASH();
 215         break;
 216     }
 217 
 218     Jump done = jump();
 219     outOfBounds.link(this);
 220 
 221     slowCases.append(branch32(AboveOrEqual, regT1, Address(regT2, Butterfly::offsetOfVectorLength())));
 222 
 223     emitArrayProfileStoreToHoleSpecialCase(profile);
 224 
 225     add32(TrustedImm32(1), regT1, regT3);
 226     store32(regT3, Address(regT2, Butterfly::offsetOfPublicLength()));
 227     jump().linkTo(storeResult, this);
 228 
 229     done.link(this);
 230 
 231     return slowCases;
 232 }
 233 
 234 template&lt;typename Op&gt;
 235 JIT::JumpList JIT::emitArrayStoragePutByVal(Op bytecode, PatchableJump&amp; badType)
 236 {
 237     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 238     VirtualRegister value = bytecode.m_value;</span>
 239     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
 240 
 241     JumpList slowCases;
 242 
 243     badType = patchableBranch32(NotEqual, regT2, TrustedImm32(ArrayStorageShape));
 244     loadPtr(Address(regT0, JSObject::butterflyOffset()), regT2);
 245     slowCases.append(branch32(AboveOrEqual, regT1, Address(regT2, ArrayStorage::vectorLengthOffset())));
 246 
 247     Jump empty = branchTest64(Zero, BaseIndex(regT2, regT1, TimesEight, ArrayStorage::vectorOffset()));
 248 
 249     Label storeResult(this);
 250     emitGetVirtualRegister(value, regT3);
 251     store64(regT3, BaseIndex(regT2, regT1, TimesEight, ArrayStorage::vectorOffset()));
<span class="line-modified"> 252     emitWriteBarrier(bytecode.m_base, value, ShouldFilterValue);</span>
 253     Jump end = jump();
 254 
 255     empty.link(this);
 256     emitArrayProfileStoreToHoleSpecialCase(profile);
 257     add32(TrustedImm32(1), Address(regT2, ArrayStorage::numValuesInVectorOffset()));
 258     branch32(Below, regT1, Address(regT2, ArrayStorage::lengthOffset())).linkTo(storeResult, this);
 259 
 260     add32(TrustedImm32(1), regT1);
 261     store32(regT1, Address(regT2, ArrayStorage::lengthOffset()));
 262     sub32(TrustedImm32(1), regT1);
 263     jump().linkTo(storeResult, this);
 264 
 265     end.link(this);
 266 
 267     return slowCases;
 268 }
 269 
 270 template&lt;typename Op&gt;
 271 JITPutByIdGenerator JIT::emitPutByValWithCachedId(ByValInfo* byValInfo, Op bytecode, PutKind putKind, const Identifier&amp; propertyName, JumpList&amp; doneCases, JumpList&amp; slowCases)
 272 {
 273     // base: regT0
 274     // property: regT1
 275     // scratch: regT2
 276 
<span class="line-modified"> 277     VirtualRegister base = bytecode.m_base;</span>
<span class="line-modified"> 278     VirtualRegister value = bytecode.m_value;</span>
 279 
 280     slowCases.append(branchIfNotCell(regT1));
 281     emitByValIdentifierCheck(byValInfo, regT1, regT1, propertyName, slowCases);
 282 
 283     // Write barrier breaks the registers. So after issuing the write barrier,
 284     // reload the registers.
 285     emitGetVirtualRegisters(base, regT0, value, regT1);
 286 
 287     JITPutByIdGenerator gen(
<span class="line-modified"> 288         m_codeBlock, CodeOrigin(m_bytecodeIndex), CallSiteIndex(m_bytecodeIndex), RegisterSet::stubUnavailableRegisters(),</span>
 289         JSValueRegs(regT0), JSValueRegs(regT1), regT2, m_codeBlock-&gt;ecmaMode(), putKind);
 290     gen.generateFastPath(*this);
 291     emitWriteBarrier(base, value, ShouldFilterBase);
 292     doneCases.append(jump());
 293 
 294     Label coldPathBegin = label();
 295     gen.slowPathJump().link(this);
 296 
<span class="line-modified"> 297     Call call = callOperation(gen.slowPathFunction(), TrustedImmPtr(m_codeBlock-&gt;globalObject()), gen.stubInfo(), regT1, regT0, propertyName.impl());</span>
 298     gen.reportSlowPathCall(coldPathBegin, call);
 299     doneCases.append(jump());
 300 
 301     return gen;
 302 }
 303 
 304 void JIT::emitSlow_op_put_by_val(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 305 {
 306     bool isDirect = currentInstruction-&gt;opcodeID() == op_put_by_val_direct;
<span class="line-modified"> 307     VirtualRegister base;</span>
<span class="line-modified"> 308     VirtualRegister property;</span>
<span class="line-modified"> 309     VirtualRegister value;</span>
 310 
 311     auto load = [&amp;](auto bytecode) {
<span class="line-modified"> 312         base = bytecode.m_base;</span>
<span class="line-modified"> 313         property = bytecode.m_property;</span>
<span class="line-modified"> 314         value = bytecode.m_value;</span>
 315     };
 316 
 317     if (isDirect)
 318         load(currentInstruction-&gt;as&lt;OpPutByValDirect&gt;());
 319     else
 320         load(currentInstruction-&gt;as&lt;OpPutByVal&gt;());
 321 
 322     ByValInfo* byValInfo = m_byValCompilationInfo[m_byValInstructionIndex].byValInfo;
 323 
 324     linkAllSlowCases(iter);
 325     Label slowPath = label();
 326 
 327     emitGetVirtualRegister(base, regT0);
 328     emitGetVirtualRegister(property, regT1);
 329     emitGetVirtualRegister(value, regT2);
<span class="line-modified"> 330     Call call = callOperation(isDirect ? operationDirectPutByValOptimize : operationPutByValOptimize, TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0, regT1, regT2, byValInfo);</span>
 331 
 332     m_byValCompilationInfo[m_byValInstructionIndex].slowPathTarget = slowPath;
 333     m_byValCompilationInfo[m_byValInstructionIndex].returnAddress = call;
 334     m_byValInstructionIndex++;
 335 }
 336 
 337 void JIT::emit_op_put_getter_by_id(const Instruction* currentInstruction)
 338 {
 339     auto bytecode = currentInstruction-&gt;as&lt;OpPutGetterById&gt;();
<span class="line-modified"> 340     emitGetVirtualRegister(bytecode.m_base, regT0);</span>
 341     int32_t options = bytecode.m_attributes;
<span class="line-modified"> 342     emitGetVirtualRegister(bytecode.m_accessor, regT1);</span>
<span class="line-modified"> 343     callOperation(operationPutGetterById, TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0, m_codeBlock-&gt;identifier(bytecode.m_property).impl(), options, regT1);</span>
 344 }
 345 
 346 void JIT::emit_op_put_setter_by_id(const Instruction* currentInstruction)
 347 {
 348     auto bytecode = currentInstruction-&gt;as&lt;OpPutSetterById&gt;();
<span class="line-modified"> 349     emitGetVirtualRegister(bytecode.m_base, regT0);</span>
 350     int32_t options = bytecode.m_attributes;
<span class="line-modified"> 351     emitGetVirtualRegister(bytecode.m_accessor, regT1);</span>
<span class="line-modified"> 352     callOperation(operationPutSetterById, TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0, m_codeBlock-&gt;identifier(bytecode.m_property).impl(), options, regT1);</span>
 353 }
 354 
 355 void JIT::emit_op_put_getter_setter_by_id(const Instruction* currentInstruction)
 356 {
 357     auto bytecode = currentInstruction-&gt;as&lt;OpPutGetterSetterById&gt;();
<span class="line-modified"> 358     emitGetVirtualRegister(bytecode.m_base, regT0);</span>
 359     int32_t attribute = bytecode.m_attributes;
<span class="line-modified"> 360     emitGetVirtualRegister(bytecode.m_getter, regT1);</span>
<span class="line-modified"> 361     emitGetVirtualRegister(bytecode.m_setter, regT2);</span>
<span class="line-modified"> 362     callOperation(operationPutGetterSetter, TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0, m_codeBlock-&gt;identifier(bytecode.m_property).impl(), attribute, regT1, regT2);</span>
 363 }
 364 
 365 void JIT::emit_op_put_getter_by_val(const Instruction* currentInstruction)
 366 {
 367     auto bytecode = currentInstruction-&gt;as&lt;OpPutGetterByVal&gt;();
<span class="line-modified"> 368     emitGetVirtualRegister(bytecode.m_base, regT0);</span>
<span class="line-modified"> 369     emitGetVirtualRegister(bytecode.m_property, regT1);</span>
 370     int32_t attributes = bytecode.m_attributes;
 371     emitGetVirtualRegister(bytecode.m_accessor, regT2);
<span class="line-modified"> 372     callOperation(operationPutGetterByVal, TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0, regT1, attributes, regT2);</span>
 373 }
 374 
 375 void JIT::emit_op_put_setter_by_val(const Instruction* currentInstruction)
 376 {
 377     auto bytecode = currentInstruction-&gt;as&lt;OpPutSetterByVal&gt;();
<span class="line-modified"> 378     emitGetVirtualRegister(bytecode.m_base, regT0);</span>
<span class="line-modified"> 379     emitGetVirtualRegister(bytecode.m_property, regT1);</span>
 380     int32_t attributes = bytecode.m_attributes;
<span class="line-modified"> 381     emitGetVirtualRegister(bytecode.m_accessor, regT2);</span>
<span class="line-modified"> 382     callOperation(operationPutSetterByVal, TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0, regT1, attributes, regT2);</span>
 383 }
 384 
 385 void JIT::emit_op_del_by_id(const Instruction* currentInstruction)
 386 {
 387     auto bytecode = currentInstruction-&gt;as&lt;OpDelById&gt;();
<span class="line-modified"> 388     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 389     VirtualRegister base = bytecode.m_base;</span>
 390     int property = bytecode.m_property;
 391     emitGetVirtualRegister(base, regT0);
<span class="line-modified"> 392     callOperation(operationDeleteByIdJSResult, dst, TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0, m_codeBlock-&gt;identifier(property).impl());</span>
 393 }
 394 
 395 void JIT::emit_op_del_by_val(const Instruction* currentInstruction)
 396 {
 397     auto bytecode = currentInstruction-&gt;as&lt;OpDelByVal&gt;();
<span class="line-modified"> 398     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 399     VirtualRegister base = bytecode.m_base;</span>
<span class="line-modified"> 400     VirtualRegister property = bytecode.m_property;</span>
 401     emitGetVirtualRegister(base, regT0);
 402     emitGetVirtualRegister(property, regT1);
<span class="line-modified"> 403     callOperation(operationDeleteByValJSResult, dst, TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0, regT1);</span>
 404 }
 405 
 406 void JIT::emit_op_try_get_by_id(const Instruction* currentInstruction)
 407 {
 408     auto bytecode = currentInstruction-&gt;as&lt;OpTryGetById&gt;();
<span class="line-modified"> 409     VirtualRegister resultVReg = bytecode.m_dst;</span>
<span class="line-modified"> 410     VirtualRegister baseVReg = bytecode.m_base;</span>
 411     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 412 
 413     emitGetVirtualRegister(baseVReg, regT0);
 414 
 415     emitJumpSlowCaseIfNotJSCell(regT0, baseVReg);
 416 
 417     JITGetByIdGenerator gen(
<span class="line-modified"> 418         m_codeBlock, CodeOrigin(m_bytecodeIndex), CallSiteIndex(m_bytecodeIndex), RegisterSet::stubUnavailableRegisters(),</span>
<span class="line-modified"> 419         ident-&gt;impl(), JSValueRegs(regT0), JSValueRegs(regT0), AccessType::TryGetById);</span>
 420     gen.generateFastPath(*this);
 421     addSlowCase(gen.slowPathJump());
 422     m_getByIds.append(gen);
 423 
 424     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 425     emitPutVirtualRegister(resultVReg);
 426 }
 427 
 428 void JIT::emitSlow_op_try_get_by_id(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 429 {
 430     linkAllSlowCases(iter);
 431 
 432     auto bytecode = currentInstruction-&gt;as&lt;OpTryGetById&gt;();
<span class="line-modified"> 433     VirtualRegister resultVReg = bytecode.m_dst;</span>
 434     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 435 
 436     JITGetByIdGenerator&amp; gen = m_getByIds[m_getByIdIndex++];
 437 
 438     Label coldPathBegin = label();
 439 
<span class="line-modified"> 440     Call call = callOperation(operationTryGetByIdOptimize, resultVReg, TrustedImmPtr(m_codeBlock-&gt;globalObject()), gen.stubInfo(), regT0, ident-&gt;impl());</span>
 441 
 442     gen.reportSlowPathCall(coldPathBegin, call);
 443 }
 444 
 445 void JIT::emit_op_get_by_id_direct(const Instruction* currentInstruction)
 446 {
 447     auto bytecode = currentInstruction-&gt;as&lt;OpGetByIdDirect&gt;();
<span class="line-modified"> 448     VirtualRegister resultVReg = bytecode.m_dst;</span>
<span class="line-modified"> 449     VirtualRegister baseVReg = bytecode.m_base;</span>
 450     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 451 
 452     emitGetVirtualRegister(baseVReg, regT0);
 453 
 454     emitJumpSlowCaseIfNotJSCell(regT0, baseVReg);
 455 
 456     JITGetByIdGenerator gen(
<span class="line-modified"> 457         m_codeBlock, CodeOrigin(m_bytecodeIndex), CallSiteIndex(m_bytecodeIndex), RegisterSet::stubUnavailableRegisters(),</span>
<span class="line-modified"> 458         ident-&gt;impl(), JSValueRegs(regT0), JSValueRegs(regT0), AccessType::GetByIdDirect);</span>
 459     gen.generateFastPath(*this);
 460     addSlowCase(gen.slowPathJump());
 461     m_getByIds.append(gen);
 462 
 463     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 464     emitPutVirtualRegister(resultVReg);
 465 }
 466 
 467 void JIT::emitSlow_op_get_by_id_direct(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 468 {
 469     linkAllSlowCases(iter);
 470 
 471     auto bytecode = currentInstruction-&gt;as&lt;OpGetByIdDirect&gt;();
<span class="line-modified"> 472     VirtualRegister resultVReg = bytecode.m_dst;</span>
 473     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 474 
 475     JITGetByIdGenerator&amp; gen = m_getByIds[m_getByIdIndex++];
 476 
 477     Label coldPathBegin = label();
 478 
<span class="line-modified"> 479     Call call = callOperationWithProfile(bytecode.metadata(m_codeBlock), operationGetByIdDirectOptimize, resultVReg, TrustedImmPtr(m_codeBlock-&gt;globalObject()), gen.stubInfo(), regT0, ident-&gt;impl());</span>
 480 
 481     gen.reportSlowPathCall(coldPathBegin, call);
 482 }
 483 
 484 void JIT::emit_op_get_by_id(const Instruction* currentInstruction)
 485 {
 486     auto bytecode = currentInstruction-&gt;as&lt;OpGetById&gt;();
 487     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 488     VirtualRegister resultVReg = bytecode.m_dst;</span>
<span class="line-modified"> 489     VirtualRegister baseVReg = bytecode.m_base;</span>
 490     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 491 
 492     emitGetVirtualRegister(baseVReg, regT0);
 493 
 494     emitJumpSlowCaseIfNotJSCell(regT0, baseVReg);
 495 
 496     if (*ident == m_vm-&gt;propertyNames-&gt;length &amp;&amp; shouldEmitProfiling()) {
 497         Jump notArrayLengthMode = branch8(NotEqual, AbsoluteAddress(&amp;metadata.m_modeMetadata.mode), TrustedImm32(static_cast&lt;uint8_t&gt;(GetByIdMode::ArrayLength)));
 498         emitArrayProfilingSiteWithCell(regT0, regT1, &amp;metadata.m_modeMetadata.arrayLengthMode.arrayProfile);
 499         notArrayLengthMode.link(this);
 500     }
 501 
 502     JITGetByIdGenerator gen(
<span class="line-modified"> 503         m_codeBlock, CodeOrigin(m_bytecodeIndex), CallSiteIndex(m_bytecodeIndex), RegisterSet::stubUnavailableRegisters(),</span>
<span class="line-modified"> 504         ident-&gt;impl(), JSValueRegs(regT0), JSValueRegs(regT0), AccessType::GetById);</span>
 505     gen.generateFastPath(*this);
 506     addSlowCase(gen.slowPathJump());
 507     m_getByIds.append(gen);
 508 
 509     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 510     emitPutVirtualRegister(resultVReg);
 511 }
 512 
 513 void JIT::emit_op_get_by_id_with_this(const Instruction* currentInstruction)
 514 {
 515     auto bytecode = currentInstruction-&gt;as&lt;OpGetByIdWithThis&gt;();
<span class="line-modified"> 516     VirtualRegister resultVReg = bytecode.m_dst;</span>
<span class="line-modified"> 517     VirtualRegister baseVReg = bytecode.m_base;</span>
<span class="line-modified"> 518     VirtualRegister thisVReg = bytecode.m_thisValue;</span>
 519     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 520 
 521     emitGetVirtualRegister(baseVReg, regT0);
 522     emitGetVirtualRegister(thisVReg, regT1);
 523     emitJumpSlowCaseIfNotJSCell(regT0, baseVReg);
 524     emitJumpSlowCaseIfNotJSCell(regT1, thisVReg);
 525 
 526     JITGetByIdWithThisGenerator gen(
<span class="line-modified"> 527         m_codeBlock, CodeOrigin(m_bytecodeIndex), CallSiteIndex(m_bytecodeIndex), RegisterSet::stubUnavailableRegisters(),</span>
<span class="line-modified"> 528         ident-&gt;impl(), JSValueRegs(regT0), JSValueRegs(regT0), JSValueRegs(regT1));</span>
 529     gen.generateFastPath(*this);
 530     addSlowCase(gen.slowPathJump());
 531     m_getByIdsWithThis.append(gen);
 532 
 533     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 534     emitPutVirtualRegister(resultVReg);
 535 }
 536 
 537 void JIT::emitSlow_op_get_by_id(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 538 {
 539     linkAllSlowCases(iter);
 540 
 541     auto bytecode = currentInstruction-&gt;as&lt;OpGetById&gt;();
<span class="line-modified"> 542     VirtualRegister resultVReg = bytecode.m_dst;</span>
 543     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 544 
 545     JITGetByIdGenerator&amp; gen = m_getByIds[m_getByIdIndex++];
 546 
 547     Label coldPathBegin = label();
 548 
<span class="line-modified"> 549     Call call = callOperationWithProfile(bytecode.metadata(m_codeBlock), operationGetByIdOptimize, resultVReg, TrustedImmPtr(m_codeBlock-&gt;globalObject()), gen.stubInfo(), regT0, ident-&gt;impl());</span>
 550 
 551     gen.reportSlowPathCall(coldPathBegin, call);
 552 }
 553 
 554 void JIT::emitSlow_op_get_by_id_with_this(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 555 {
 556     linkAllSlowCases(iter);
 557 
 558     auto bytecode = currentInstruction-&gt;as&lt;OpGetByIdWithThis&gt;();
<span class="line-modified"> 559     VirtualRegister resultVReg = bytecode.m_dst;</span>
 560     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 561 
 562     JITGetByIdWithThisGenerator&amp; gen = m_getByIdsWithThis[m_getByIdWithThisIndex++];
 563 
 564     Label coldPathBegin = label();
 565 
<span class="line-modified"> 566     Call call = callOperationWithProfile(bytecode.metadata(m_codeBlock), operationGetByIdWithThisOptimize, resultVReg, TrustedImmPtr(m_codeBlock-&gt;globalObject()), gen.stubInfo(), regT0, regT1, ident-&gt;impl());</span>
 567 
 568     gen.reportSlowPathCall(coldPathBegin, call);
 569 }
 570 
 571 void JIT::emit_op_put_by_id(const Instruction* currentInstruction)
 572 {
 573     auto bytecode = currentInstruction-&gt;as&lt;OpPutById&gt;();
<span class="line-modified"> 574     VirtualRegister baseVReg = bytecode.m_base;</span>
<span class="line-modified"> 575     VirtualRegister valueVReg = bytecode.m_value;</span>
 576     bool direct = !!(bytecode.m_flags &amp; PutByIdIsDirect);
 577 
 578     // In order to be able to patch both the Structure, and the object offset, we store one pointer,
 579     // to just after the arguments have been loaded into registers &#39;hotPathBegin&#39;, and we generate code
 580     // such that the Structure &amp; offset are always at the same distance from this.
 581 
 582     emitGetVirtualRegisters(baseVReg, regT0, valueVReg, regT1);
 583 
 584     emitJumpSlowCaseIfNotJSCell(regT0, baseVReg);
 585 
 586     JITPutByIdGenerator gen(
<span class="line-modified"> 587         m_codeBlock, CodeOrigin(m_bytecodeIndex), CallSiteIndex(m_bytecodeIndex), RegisterSet::stubUnavailableRegisters(),</span>
 588         JSValueRegs(regT0), JSValueRegs(regT1), regT2, m_codeBlock-&gt;ecmaMode(),
 589         direct ? Direct : NotDirect);
 590 
 591     gen.generateFastPath(*this);
 592     addSlowCase(gen.slowPathJump());
 593 
 594     emitWriteBarrier(baseVReg, valueVReg, ShouldFilterBase);
 595 
 596     m_putByIds.append(gen);
 597 }
 598 
 599 void JIT::emitSlow_op_put_by_id(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 600 {
 601     linkAllSlowCases(iter);
 602 
 603     auto bytecode = currentInstruction-&gt;as&lt;OpPutById&gt;();
 604     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 605 
 606     Label coldPathBegin(this);
 607 
 608     JITPutByIdGenerator&amp; gen = m_putByIds[m_putByIdIndex++];
 609 
<span class="line-modified"> 610     Call call = callOperation(gen.slowPathFunction(), TrustedImmPtr(m_codeBlock-&gt;globalObject()), gen.stubInfo(), regT1, regT0, ident-&gt;impl());</span>
 611 
 612     gen.reportSlowPathCall(coldPathBegin, call);
 613 }
 614 
 615 void JIT::emit_op_in_by_id(const Instruction* currentInstruction)
 616 {
 617     auto bytecode = currentInstruction-&gt;as&lt;OpInById&gt;();
<span class="line-modified"> 618     VirtualRegister resultVReg = bytecode.m_dst;</span>
<span class="line-modified"> 619     VirtualRegister baseVReg = bytecode.m_base;</span>
 620     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 621 
 622     emitGetVirtualRegister(baseVReg, regT0);
 623 
 624     emitJumpSlowCaseIfNotJSCell(regT0, baseVReg);
 625 
 626     JITInByIdGenerator gen(
<span class="line-modified"> 627         m_codeBlock, CodeOrigin(m_bytecodeIndex), CallSiteIndex(m_bytecodeIndex), RegisterSet::stubUnavailableRegisters(),</span>
 628         ident-&gt;impl(), JSValueRegs(regT0), JSValueRegs(regT0));
 629     gen.generateFastPath(*this);
 630     addSlowCase(gen.slowPathJump());
 631     m_inByIds.append(gen);
 632 
 633     emitPutVirtualRegister(resultVReg);
 634 }
 635 
 636 void JIT::emitSlow_op_in_by_id(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 637 {
 638     linkAllSlowCases(iter);
 639 
 640     auto bytecode = currentInstruction-&gt;as&lt;OpInById&gt;();
<span class="line-modified"> 641     VirtualRegister resultVReg = bytecode.m_dst;</span>
 642     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 643 
 644     JITInByIdGenerator&amp; gen = m_inByIds[m_inByIdIndex++];
 645 
 646     Label coldPathBegin = label();
 647 
<span class="line-modified"> 648     Call call = callOperation(operationInByIdOptimize, resultVReg, TrustedImmPtr(m_codeBlock-&gt;globalObject()), gen.stubInfo(), regT0, ident-&gt;impl());</span>
 649 
 650     gen.reportSlowPathCall(coldPathBegin, call);
 651 }
 652 
 653 void JIT::emitVarInjectionCheck(bool needsVarInjectionChecks)
 654 {
 655     if (!needsVarInjectionChecks)
 656         return;
 657     addSlowCase(branch8(Equal, AbsoluteAddress(m_codeBlock-&gt;globalObject()-&gt;varInjectionWatchpoint()-&gt;addressOfState()), TrustedImm32(IsInvalidated)));
 658 }
 659 
<span class="line-modified"> 660 void JIT::emitResolveClosure(VirtualRegister dst, VirtualRegister scope, bool needsVarInjectionChecks, unsigned depth)</span>
 661 {
 662     emitVarInjectionCheck(needsVarInjectionChecks);
 663     emitGetVirtualRegister(scope, regT0);
 664     for (unsigned i = 0; i &lt; depth; ++i)
 665         loadPtr(Address(regT0, JSScope::offsetOfNext()), regT0);
 666     emitPutVirtualRegister(dst);
 667 }
 668 
 669 void JIT::emit_op_resolve_scope(const Instruction* currentInstruction)
 670 {
 671     auto bytecode = currentInstruction-&gt;as&lt;OpResolveScope&gt;();
 672     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 673     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 674     VirtualRegister scope = bytecode.m_scope;</span>
 675     ResolveType resolveType = metadata.m_resolveType;
 676     unsigned depth = metadata.m_localScopeDepth;
 677 
 678     auto emitCode = [&amp;] (ResolveType resolveType) {
 679         switch (resolveType) {
 680         case GlobalProperty:
 681         case GlobalPropertyWithVarInjectionChecks: {
 682             JSScope* constantScope = JSScope::constantScopeForCodeBlock(resolveType, m_codeBlock);
 683             RELEASE_ASSERT(constantScope);
 684             emitVarInjectionCheck(needsVarInjectionChecks(resolveType));
 685             load32(&amp;metadata.m_globalLexicalBindingEpoch, regT1);
 686             addSlowCase(branch32(NotEqual, AbsoluteAddress(m_codeBlock-&gt;globalObject()-&gt;addressOfGlobalLexicalBindingEpoch()), regT1));
 687             move(TrustedImmPtr(constantScope), regT0);
 688             emitPutVirtualRegister(dst);
 689             break;
 690         }
 691 
 692         case GlobalVar:
 693         case GlobalVarWithVarInjectionChecks:
 694         case GlobalLexicalVar:
</pre>
<hr />
<pre>
 753         emitCode(GlobalLexicalVar);
 754         skipToEnd.append(jump());
 755         notGlobalLexicalVar.link(this);
 756 
 757         Jump notGlobalLexicalVarWithVarInjections = branch32(NotEqual, regT0, TrustedImm32(GlobalLexicalVarWithVarInjectionChecks));
 758         emitCode(GlobalLexicalVarWithVarInjectionChecks);
 759         skipToEnd.append(jump());
 760         notGlobalLexicalVarWithVarInjections.link(this);
 761 
 762         addSlowCase(jump());
 763         skipToEnd.link(this);
 764         break;
 765     }
 766 
 767     default:
 768         emitCode(resolveType);
 769         break;
 770     }
 771 }
 772 
<span class="line-modified"> 773 void JIT::emitLoadWithStructureCheck(VirtualRegister scope, Structure** structureSlot)</span>
 774 {
 775     loadPtr(structureSlot, regT1);
 776     emitGetVirtualRegister(scope, regT0);
 777     addSlowCase(branchTestPtr(Zero, regT1));
 778     load32(Address(regT1, Structure::structureIDOffset()), regT1);
 779     addSlowCase(branch32(NotEqual, Address(regT0, JSCell::structureIDOffset()), regT1));
 780 }
 781 
 782 void JIT::emitGetVarFromPointer(JSValue* operand, GPRReg reg)
 783 {
 784     loadPtr(operand, reg);
 785 }
 786 
 787 void JIT::emitGetVarFromIndirectPointer(JSValue** operand, GPRReg reg)
 788 {
 789     loadPtr(operand, reg);
 790     loadPtr(reg, reg);
 791 }
 792 
<span class="line-modified"> 793 void JIT::emitGetClosureVar(VirtualRegister scope, uintptr_t operand)</span>
 794 {
 795     emitGetVirtualRegister(scope, regT0);
 796     loadPtr(Address(regT0, JSLexicalEnvironment::offsetOfVariables() + operand * sizeof(Register)), regT0);
 797 }
 798 
 799 void JIT::emit_op_get_from_scope(const Instruction* currentInstruction)
 800 {
 801     auto bytecode = currentInstruction-&gt;as&lt;OpGetFromScope&gt;();
 802     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 803     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 804     VirtualRegister scope = bytecode.m_scope;</span>
 805     ResolveType resolveType = metadata.m_getPutInfo.resolveType();
 806     Structure** structureSlot = metadata.m_structure.slot();
 807     uintptr_t* operandSlot = reinterpret_cast&lt;uintptr_t*&gt;(&amp;metadata.m_operand);
 808 
 809     auto emitCode = [&amp;] (ResolveType resolveType, bool indirectLoadForOperand) {
 810         switch (resolveType) {
 811         case GlobalProperty:
 812         case GlobalPropertyWithVarInjectionChecks: {
 813             emitLoadWithStructureCheck(scope, structureSlot); // Structure check covers var injection since we don&#39;t cache structures for anything but the GlobalObject. Additionally, resolve_scope handles checking for the var injection.
 814             GPRReg base = regT0;
 815             GPRReg result = regT0;
 816             GPRReg offset = regT1;
 817             GPRReg scratch = regT2;
 818 
 819             jitAssert(scopedLambda&lt;Jump(void)&gt;([&amp;] () -&gt; Jump {
 820                 return branchPtr(Equal, base, TrustedImmPtr(m_codeBlock-&gt;globalObject()));
 821             }));
 822 
 823             load32(operandSlot, offset);
<span class="line-modified"> 824             if (ASSERT_ENABLED) {</span>
 825                 Jump isOutOfLine = branch32(GreaterThanOrEqual, offset, TrustedImm32(firstOutOfLineOffset));
 826                 abortWithReason(JITOffsetIsNotOutOfLine);
 827                 isOutOfLine.link(this);
 828             }
 829             loadPtr(Address(base, JSObject::butterflyOffset()), scratch);
 830             neg32(offset);
 831             signExtend32ToPtr(offset, offset);
 832             load64(BaseIndex(scratch, offset, TimesEight, (firstOutOfLineOffset - 2) * sizeof(EncodedJSValue)), result);
 833             break;
 834         }
 835         case GlobalVar:
 836         case GlobalVarWithVarInjectionChecks:
 837         case GlobalLexicalVar:
 838         case GlobalLexicalVarWithVarInjectionChecks:
 839             emitVarInjectionCheck(needsVarInjectionChecks(resolveType));
 840             if (indirectLoadForOperand)
 841                 emitGetVarFromIndirectPointer(bitwise_cast&lt;JSValue**&gt;(operandSlot), regT0);
 842             else
 843                 emitGetVarFromPointer(bitwise_cast&lt;JSValue*&gt;(*operandSlot), regT0);
 844             if (resolveType == GlobalLexicalVar || resolveType == GlobalLexicalVarWithVarInjectionChecks) // TDZ check.
</pre>
<hr />
<pre>
 902 
 903         addSlowCase(jump());
 904 
 905         skipToEnd.link(this);
 906         break;
 907     }
 908 
 909     default:
 910         emitCode(resolveType, false);
 911         break;
 912     }
 913     emitPutVirtualRegister(dst);
 914     emitValueProfilingSite(metadata);
 915 }
 916 
 917 void JIT::emitSlow_op_get_from_scope(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 918 {
 919     linkAllSlowCases(iter);
 920 
 921     auto bytecode = currentInstruction-&gt;as&lt;OpGetFromScope&gt;();
<span class="line-modified"> 922     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 923     callOperationWithProfile(bytecode.metadata(m_codeBlock), operationGetFromScope, dst, TrustedImmPtr(m_codeBlock-&gt;globalObject()), currentInstruction);</span>
 924 }
 925 
<span class="line-modified"> 926 void JIT::emitPutGlobalVariable(JSValue* operand, VirtualRegister value, WatchpointSet* set)</span>
 927 {
 928     emitGetVirtualRegister(value, regT0);
 929     emitNotifyWrite(set);
 930     storePtr(regT0, operand);
 931 }
<span class="line-modified"> 932 void JIT::emitPutGlobalVariableIndirect(JSValue** addressOfOperand, VirtualRegister value, WatchpointSet** indirectWatchpointSet)</span>
 933 {
 934     emitGetVirtualRegister(value, regT0);
 935     loadPtr(indirectWatchpointSet, regT1);
 936     emitNotifyWrite(regT1);
 937     loadPtr(addressOfOperand, regT1);
 938     storePtr(regT0, regT1);
 939 }
 940 
<span class="line-modified"> 941 void JIT::emitPutClosureVar(VirtualRegister scope, uintptr_t operand, VirtualRegister value, WatchpointSet* set)</span>
 942 {
 943     emitGetVirtualRegister(value, regT1);
 944     emitGetVirtualRegister(scope, regT0);
 945     emitNotifyWrite(set);
 946     storePtr(regT1, Address(regT0, JSLexicalEnvironment::offsetOfVariables() + operand * sizeof(Register)));
 947 }
 948 
 949 void JIT::emit_op_put_to_scope(const Instruction* currentInstruction)
 950 {
 951     auto bytecode = currentInstruction-&gt;as&lt;OpPutToScope&gt;();
 952     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 953     VirtualRegister scope = bytecode.m_scope;</span>
<span class="line-modified"> 954     VirtualRegister value = bytecode.m_value;</span>
 955     GetPutInfo getPutInfo = copiedGetPutInfo(bytecode);
 956     ResolveType resolveType = getPutInfo.resolveType();
 957     Structure** structureSlot = metadata.m_structure.slot();
 958     uintptr_t* operandSlot = reinterpret_cast&lt;uintptr_t*&gt;(&amp;metadata.m_operand);
 959 
 960     auto emitCode = [&amp;] (ResolveType resolveType, bool indirectLoadForOperand) {
 961         switch (resolveType) {
 962         case GlobalProperty:
 963         case GlobalPropertyWithVarInjectionChecks: {
 964             emitLoadWithStructureCheck(scope, structureSlot); // Structure check covers var injection since we don&#39;t cache structures for anything but the GlobalObject. Additionally, resolve_scope handles checking for the var injection.
 965             emitGetVirtualRegister(value, regT2);
 966 
 967             jitAssert(scopedLambda&lt;Jump(void)&gt;([&amp;] () -&gt; Jump {
 968                 return branchPtr(Equal, regT0, TrustedImmPtr(m_codeBlock-&gt;globalObject()));
 969             }));
 970 
 971             loadPtr(Address(regT0, JSObject::butterflyOffset()), regT0);
 972             loadPtr(operandSlot, regT1);
 973             negPtr(regT1);
 974             storePtr(regT2, BaseIndex(regT0, regT1, TimesEight, (firstOutOfLineOffset - 2) * sizeof(EncodedJSValue)));
</pre>
<hr />
<pre>
1063         skipToEnd.link(this);
1064         break;
1065     }
1066 
1067     default:
1068         emitCode(resolveType, false);
1069         break;
1070     }
1071 }
1072 
1073 void JIT::emitSlow_op_put_to_scope(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
1074 {
1075     linkAllSlowCases(iter);
1076 
1077     auto bytecode = currentInstruction-&gt;as&lt;OpPutToScope&gt;();
1078     ResolveType resolveType = copiedGetPutInfo(bytecode).resolveType();
1079     if (resolveType == ModuleVar) {
1080         JITSlowPathCall slowPathCall(this, currentInstruction, slow_path_throw_strict_mode_readonly_property_write_error);
1081         slowPathCall.call();
1082     } else
<span class="line-modified">1083         callOperation(operationPutToScope, TrustedImmPtr(m_codeBlock-&gt;globalObject()), currentInstruction);</span>
1084 }
1085 
1086 void JIT::emit_op_get_from_arguments(const Instruction* currentInstruction)
1087 {
1088     auto bytecode = currentInstruction-&gt;as&lt;OpGetFromArguments&gt;();
<span class="line-modified">1089     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified">1090     VirtualRegister arguments = bytecode.m_arguments;</span>
1091     int index = bytecode.m_index;
1092 
1093     emitGetVirtualRegister(arguments, regT0);
1094     load64(Address(regT0, DirectArguments::storageOffset() + index * sizeof(WriteBarrier&lt;Unknown&gt;)), regT0);
1095     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
1096     emitPutVirtualRegister(dst);
1097 }
1098 
1099 void JIT::emit_op_put_to_arguments(const Instruction* currentInstruction)
1100 {
1101     auto bytecode = currentInstruction-&gt;as&lt;OpPutToArguments&gt;();
<span class="line-modified">1102     VirtualRegister arguments = bytecode.m_arguments;</span>
1103     int index = bytecode.m_index;
<span class="line-modified">1104     VirtualRegister value = bytecode.m_value;</span>
1105 
1106     emitGetVirtualRegister(arguments, regT0);
1107     emitGetVirtualRegister(value, regT1);
1108     store64(regT1, Address(regT0, DirectArguments::storageOffset() + index * sizeof(WriteBarrier&lt;Unknown&gt;)));
1109 
1110     emitWriteBarrier(arguments, value, ShouldFilterValue);
1111 }
1112 
<span class="line-modified">1113 void JIT::emitWriteBarrier(VirtualRegister owner, VirtualRegister value, WriteBarrierMode mode)</span>
1114 {
1115     Jump valueNotCell;
1116     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue) {
1117         emitGetVirtualRegister(value, regT0);
1118         valueNotCell = branchIfNotCell(regT0);
1119     }
1120 
1121     emitGetVirtualRegister(owner, regT0);
1122     Jump ownerNotCell;
1123     if (mode == ShouldFilterBaseAndValue || mode == ShouldFilterBase)
1124         ownerNotCell = branchIfNotCell(regT0);
1125 
1126     Jump ownerIsRememberedOrInEden = barrierBranch(vm(), regT0, regT1);
<span class="line-modified">1127     callOperation(operationWriteBarrierSlowPath, &amp;vm(), regT0);</span>
1128     ownerIsRememberedOrInEden.link(this);
1129 
1130     if (mode == ShouldFilterBaseAndValue || mode == ShouldFilterBase)
1131         ownerNotCell.link(this);
1132     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue)
1133         valueNotCell.link(this);
1134 }
1135 
<span class="line-modified">1136 void JIT::emitWriteBarrier(JSCell* owner, VirtualRegister value, WriteBarrierMode mode)</span>
1137 {
1138     emitGetVirtualRegister(value, regT0);
1139     Jump valueNotCell;
1140     if (mode == ShouldFilterValue)
1141         valueNotCell = branchIfNotCell(regT0);
1142 
1143     emitWriteBarrier(owner);
1144 
1145     if (mode == ShouldFilterValue)
1146         valueNotCell.link(this);
1147 }
1148 
<span class="line-added">1149 void JIT::emit_op_get_internal_field(const Instruction* currentInstruction)</span>
<span class="line-added">1150 {</span>
<span class="line-added">1151     auto bytecode = currentInstruction-&gt;as&lt;OpGetInternalField&gt;();</span>
<span class="line-added">1152     auto&amp; metadata = bytecode.metadata(m_codeBlock);</span>
<span class="line-added">1153     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-added">1154     VirtualRegister base = bytecode.m_base;</span>
<span class="line-added">1155     unsigned index = bytecode.m_index;</span>
<span class="line-added">1156 </span>
<span class="line-added">1157     emitGetVirtualRegister(base, regT1);</span>
<span class="line-added">1158     loadPtr(Address(regT1, JSInternalFieldObjectImpl&lt;&gt;::offsetOfInternalField(index)), regT0);</span>
<span class="line-added">1159 </span>
<span class="line-added">1160     emitValueProfilingSite(metadata);</span>
<span class="line-added">1161     emitPutVirtualRegister(dst);</span>
<span class="line-added">1162 }</span>
<span class="line-added">1163 </span>
<span class="line-added">1164 void JIT::emit_op_put_internal_field(const Instruction* currentInstruction)</span>
<span class="line-added">1165 {</span>
<span class="line-added">1166     auto bytecode = currentInstruction-&gt;as&lt;OpPutInternalField&gt;();</span>
<span class="line-added">1167     VirtualRegister base = bytecode.m_base;</span>
<span class="line-added">1168     VirtualRegister value = bytecode.m_value;</span>
<span class="line-added">1169     unsigned index = bytecode.m_index;</span>
<span class="line-added">1170 </span>
<span class="line-added">1171     emitGetVirtualRegister(base, regT0);</span>
<span class="line-added">1172     emitGetVirtualRegister(value, regT1);</span>
<span class="line-added">1173     storePtr(regT1, Address(regT0, JSInternalFieldObjectImpl&lt;&gt;::offsetOfInternalField(index)));</span>
<span class="line-added">1174     emitWriteBarrier(base, value, ShouldFilterValue);</span>
<span class="line-added">1175 }</span>
<span class="line-added">1176 </span>
1177 #else // USE(JSVALUE64)
1178 
<span class="line-modified">1179 void JIT::emitWriteBarrier(VirtualRegister owner, VirtualRegister value, WriteBarrierMode mode)</span>
1180 {
1181     Jump valueNotCell;
1182     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue) {
1183         emitLoadTag(value, regT0);
1184         valueNotCell = branchIfNotCell(regT0);
1185     }
1186 
1187     emitLoad(owner, regT0, regT1);
1188     Jump ownerNotCell;
1189     if (mode == ShouldFilterBase || mode == ShouldFilterBaseAndValue)
1190         ownerNotCell = branchIfNotCell(regT0);
1191 
1192     Jump ownerIsRememberedOrInEden = barrierBranch(vm(), regT1, regT2);
<span class="line-modified">1193     callOperation(operationWriteBarrierSlowPath, &amp;vm(), regT1);</span>
1194     ownerIsRememberedOrInEden.link(this);
1195 
1196     if (mode == ShouldFilterBase || mode == ShouldFilterBaseAndValue)
1197         ownerNotCell.link(this);
1198     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue)
1199         valueNotCell.link(this);
1200 }
1201 
<span class="line-modified">1202 void JIT::emitWriteBarrier(JSCell* owner, VirtualRegister value, WriteBarrierMode mode)</span>
1203 {
1204     Jump valueNotCell;
1205     if (mode == ShouldFilterValue) {
1206         emitLoadTag(value, regT0);
1207         valueNotCell = branchIfNotCell(regT0);
1208     }
1209 
1210     emitWriteBarrier(owner);
1211 
1212     if (mode == ShouldFilterValue)
1213         valueNotCell.link(this);
1214 }
1215 
1216 #endif // USE(JSVALUE64)
1217 
1218 void JIT::emitWriteBarrier(JSCell* owner)
1219 {
1220     Jump ownerIsRememberedOrInEden = barrierBranch(vm(), owner, regT0);
<span class="line-modified">1221     callOperation(operationWriteBarrierSlowPath, &amp;vm(), owner);</span>
1222     ownerIsRememberedOrInEden.link(this);
1223 }
1224 
1225 void JIT::emitByValIdentifierCheck(ByValInfo* byValInfo, RegisterID cell, RegisterID scratch, const Identifier&amp; propertyName, JumpList&amp; slowCases)
1226 {
1227     if (propertyName.isSymbol())
1228         slowCases.append(branchPtr(NotEqual, cell, TrustedImmPtr(byValInfo-&gt;cachedSymbol.get())));
1229     else {
1230         slowCases.append(branchIfNotString(cell));
1231         loadPtr(Address(cell, JSString::offsetOfValue()), scratch);
1232         slowCases.append(branchPtr(NotEqual, scratch, TrustedImmPtr(propertyName.impl())));
1233     }
1234 }
1235 






















































































1236 template&lt;typename Op&gt;
1237 void JIT::privateCompilePutByVal(const ConcurrentJSLocker&amp;, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)
1238 {
1239     const Instruction* currentInstruction = m_codeBlock-&gt;instructions().at(byValInfo-&gt;bytecodeIndex).ptr();
1240     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
1241 
1242     PatchableJump badType;
1243     JumpList slowCases;
1244 
1245     bool needsLinkForWriteBarrier = false;
1246 
1247     switch (arrayMode) {
1248     case JITInt32:
1249         slowCases = emitInt32PutByVal(bytecode, badType);
1250         break;
1251     case JITDouble:
1252         slowCases = emitDoublePutByVal(bytecode, badType);
1253         break;
1254     case JITContiguous:
1255         slowCases = emitContiguousPutByVal(bytecode, badType);
</pre>
<hr />
<pre>
1401     RegisterID property = regT2;
1402     RegisterID indexing = regT1;
1403     JSValueRegs result = JSValueRegs(regT1, regT0);
1404     RegisterID scratch = regT3;
1405 #endif
1406 
1407     JumpList slowCases;
1408 
1409     add32(TrustedImm32(-ArrayStorageShape), indexing, scratch);
1410     badType = patchableBranch32(Above, scratch, TrustedImm32(SlowPutArrayStorageShape - ArrayStorageShape));
1411 
1412     loadPtr(Address(base, JSObject::butterflyOffset()), scratch);
1413     slowCases.append(branch32(AboveOrEqual, property, Address(scratch, ArrayStorage::vectorLengthOffset())));
1414 
1415     loadValue(BaseIndex(scratch, property, TimesEight, ArrayStorage::vectorOffset()), result);
1416     slowCases.append(branchIfEmpty(result));
1417 
1418     return slowCases;
1419 }
1420 
































































































































































































1421 template&lt;typename Op&gt;
1422 JIT::JumpList JIT::emitIntTypedArrayPutByVal(Op bytecode, PatchableJump&amp; badType, TypedArrayType type)
1423 {
1424     auto&amp; metadata = bytecode.metadata(m_codeBlock);
1425     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
1426     ASSERT(isInt(type));
1427 
<span class="line-modified">1428     VirtualRegister value = bytecode.m_value;</span>
1429 
1430 #if USE(JSVALUE64)
1431     RegisterID base = regT0;
1432     RegisterID property = regT1;
1433     RegisterID earlyScratch = regT3;
1434     RegisterID lateScratch = regT2;
1435     RegisterID lateScratch2 = regT4;
1436 #else
1437     RegisterID base = regT0;
1438     RegisterID property = regT2;
1439     RegisterID earlyScratch = regT3;
1440     RegisterID lateScratch = regT1;
1441     RegisterID lateScratch2 = regT4;
1442 #endif
1443 
1444     JumpList slowCases;
1445 
1446     load8(Address(base, JSCell::typeInfoTypeOffset()), earlyScratch);
1447     badType = patchableBranch32(NotEqual, earlyScratch, TrustedImm32(typeForTypedArrayType(type)));
1448     load32(Address(base, JSArrayBufferView::offsetOfLength()), lateScratch2);
</pre>
<hr />
<pre>
1484     case 2:
1485         store16(earlyScratch, BaseIndex(lateScratch, property, TimesTwo));
1486         break;
1487     case 4:
1488         store32(earlyScratch, BaseIndex(lateScratch, property, TimesFour));
1489         break;
1490     default:
1491         CRASH();
1492     }
1493 
1494     return slowCases;
1495 }
1496 
1497 template&lt;typename Op&gt;
1498 JIT::JumpList JIT::emitFloatTypedArrayPutByVal(Op bytecode, PatchableJump&amp; badType, TypedArrayType type)
1499 {
1500     auto&amp; metadata = bytecode.metadata(m_codeBlock);
1501     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
1502     ASSERT(isFloat(type));
1503 
<span class="line-modified">1504     VirtualRegister value = bytecode.m_value;</span>
1505 
1506 #if USE(JSVALUE64)
1507     RegisterID base = regT0;
1508     RegisterID property = regT1;
1509     RegisterID earlyScratch = regT3;
1510     RegisterID lateScratch = regT2;
1511     RegisterID lateScratch2 = regT4;
1512 #else
1513     RegisterID base = regT0;
1514     RegisterID property = regT2;
1515     RegisterID earlyScratch = regT3;
1516     RegisterID lateScratch = regT1;
1517     RegisterID lateScratch2 = regT4;
1518 #endif
1519 
1520     JumpList slowCases;
1521 
1522     load8(Address(base, JSCell::typeInfoTypeOffset()), earlyScratch);
1523     badType = patchableBranch32(NotEqual, earlyScratch, TrustedImm32(typeForTypedArrayType(type)));
1524     load32(Address(base, JSArrayBufferView::offsetOfLength()), lateScratch2);
1525     Jump inBounds = branch32(Below, property, lateScratch2);
1526     emitArrayProfileOutOfBoundsSpecialCase(profile);
1527     slowCases.append(jump());
1528     inBounds.link(this);
1529 
1530 #if USE(JSVALUE64)
1531     emitGetVirtualRegister(value, earlyScratch);
1532     Jump doubleCase = branchIfNotInt32(earlyScratch);
1533     convertInt32ToDouble(earlyScratch, fpRegT0);
1534     Jump ready = jump();
1535     doubleCase.link(this);
1536     slowCases.append(branchIfNotNumber(earlyScratch));
<span class="line-modified">1537     add64(numberTagRegister, earlyScratch);</span>
1538     move64ToDouble(earlyScratch, fpRegT0);
1539     ready.link(this);
1540 #else
1541     emitLoad(value, lateScratch, earlyScratch);
1542     Jump doubleCase = branchIfNotInt32(lateScratch);
1543     convertInt32ToDouble(earlyScratch, fpRegT0);
1544     Jump ready = jump();
1545     doubleCase.link(this);
1546     slowCases.append(branch32(Above, lateScratch, TrustedImm32(JSValue::LowestTag)));
1547     moveIntsToDouble(earlyScratch, lateScratch, fpRegT0, fpRegT1);
1548     ready.link(this);
1549 #endif
1550 
1551     // We would be loading this into base as in get_by_val, except that the slow
1552     // path expects the base to be unclobbered.
1553     loadPtr(Address(base, JSArrayBufferView::offsetOfVector()), lateScratch);
1554     cageConditionally(Gigacage::Primitive, lateScratch, lateScratch2, lateScratch2);
1555 
1556     switch (elementSize(type)) {
1557     case 4:
</pre>
</td>
</tr>
</table>
<center><a href="JITOperationsMSVC64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="JITPropertyAccess32_64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>