<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGGraph.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (C) 2011-2020 Apple Inc. All rights reserved.
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;DFGGraph.h&quot;
  28 
  29 #if ENABLE(DFG_JIT)
  30 
  31 #include &quot;BytecodeKills.h&quot;
  32 #include &quot;BytecodeLivenessAnalysisInlines.h&quot;
  33 #include &quot;CodeBlock.h&quot;
  34 #include &quot;CodeBlockWithJITType.h&quot;
  35 #include &quot;DFGBackwardsCFG.h&quot;
  36 #include &quot;DFGBackwardsDominators.h&quot;
  37 #include &quot;DFGBlockWorklist.h&quot;
  38 #include &quot;DFGCFG.h&quot;
  39 #include &quot;DFGClobberSet.h&quot;
  40 #include &quot;DFGClobbersExitState.h&quot;
  41 #include &quot;DFGControlEquivalenceAnalysis.h&quot;
  42 #include &quot;DFGDominators.h&quot;
  43 #include &quot;DFGFlowIndexing.h&quot;
  44 #include &quot;DFGFlowMap.h&quot;
  45 #include &quot;DFGJITCode.h&quot;
  46 #include &quot;DFGMayExit.h&quot;
  47 #include &quot;DFGNaturalLoops.h&quot;
  48 #include &quot;DFGVariableAccessDataDump.h&quot;
  49 #include &quot;FullBytecodeLiveness.h&quot;
  50 #include &quot;FunctionExecutableDump.h&quot;
  51 #include &quot;GetterSetter.h&quot;
  52 #include &quot;JIT.h&quot;
  53 #include &quot;JSLexicalEnvironment.h&quot;
  54 #include &quot;MaxFrameExtentForSlowPathCall.h&quot;
  55 #include &quot;OperandsInlines.h&quot;
  56 #include &quot;JSCInlines.h&quot;
  57 #include &quot;StackAlignment.h&quot;
  58 #include &lt;wtf/CommaPrinter.h&gt;
  59 #include &lt;wtf/ListDump.h&gt;
  60 
  61 namespace JSC { namespace DFG {
  62 
  63 static constexpr bool dumpOSRAvailabilityData = false;
  64 
  65 // Creates an array of stringized names.
  66 static const char* dfgOpNames[] = {
  67 #define STRINGIZE_DFG_OP_ENUM(opcode, flags) #opcode ,
  68     FOR_EACH_DFG_OP(STRINGIZE_DFG_OP_ENUM)
  69 #undef STRINGIZE_DFG_OP_ENUM
  70 };
  71 
  72 Graph::Graph(VM&amp; vm, Plan&amp; plan)
  73     : m_vm(vm)
  74     , m_plan(plan)
  75     , m_codeBlock(m_plan.codeBlock())
  76     , m_profiledBlock(m_codeBlock-&gt;alternative())
  77     , m_ssaCFG(makeUnique&lt;SSACFG&gt;(*this))
  78     , m_nextMachineLocal(0)
  79     , m_fixpointState(BeforeFixpoint)
  80     , m_structureRegistrationState(HaveNotStartedRegistering)
  81     , m_form(LoadStore)
  82     , m_unificationState(LocallyUnified)
  83     , m_refCountState(EverythingIsLive)
  84 {
  85     ASSERT(m_profiledBlock);
  86 
  87     m_hasDebuggerEnabled = m_profiledBlock-&gt;wasCompiledWithDebuggingOpcodes() || Options::forceDebuggerBytecodeGeneration();
  88 
  89     m_indexingCache = makeUnique&lt;FlowIndexing&gt;(*this);
  90     m_abstractValuesCache = makeUnique&lt;FlowMap&lt;AbstractValue&gt;&gt;(*this);
  91 
  92     registerStructure(vm.structureStructure.get());
  93     this-&gt;stringStructure = registerStructure(vm.stringStructure.get());
  94     this-&gt;symbolStructure = registerStructure(vm.symbolStructure.get());
  95 }
  96 
  97 Graph::~Graph()
  98 {
  99 }
 100 
 101 const char *Graph::opName(NodeType op)
 102 {
 103     return dfgOpNames[op];
 104 }
 105 
 106 static void printWhiteSpace(PrintStream&amp; out, unsigned amount)
 107 {
 108     while (amount-- &gt; 0)
 109         out.print(&quot; &quot;);
 110 }
 111 
 112 bool Graph::dumpCodeOrigin(PrintStream&amp; out, const char* prefixStr, Node*&amp; previousNodeRef, Node* currentNode, DumpContext* context)
 113 {
 114     Prefix myPrefix(prefixStr);
 115     Prefix&amp; prefix = prefixStr ? myPrefix : m_prefix;
 116 
 117     if (!currentNode-&gt;origin.semantic)
 118         return false;
 119 
 120     Node* previousNode = previousNodeRef;
 121     previousNodeRef = currentNode;
 122 
 123     if (!previousNode)
 124         return false;
 125 
 126     if (previousNode-&gt;origin.semantic.inlineCallFrame() == currentNode-&gt;origin.semantic.inlineCallFrame())
 127         return false;
 128 
 129     Vector&lt;CodeOrigin&gt; previousInlineStack = previousNode-&gt;origin.semantic.inlineStack();
 130     Vector&lt;CodeOrigin&gt; currentInlineStack = currentNode-&gt;origin.semantic.inlineStack();
 131     unsigned commonSize = std::min(previousInlineStack.size(), currentInlineStack.size());
 132     unsigned indexOfDivergence = commonSize;
 133     for (unsigned i = 0; i &lt; commonSize; ++i) {
 134         if (previousInlineStack[i].inlineCallFrame() != currentInlineStack[i].inlineCallFrame()) {
 135             indexOfDivergence = i;
 136             break;
 137         }
 138     }
 139 
 140     bool hasPrinted = false;
 141 
 142     // Print the pops.
 143     for (unsigned i = previousInlineStack.size(); i-- &gt; indexOfDivergence;) {
 144         out.print(prefix);
 145         printWhiteSpace(out, i * 2);
 146         out.print(&quot;&lt;-- &quot;, inContext(*previousInlineStack[i].inlineCallFrame(), context), &quot;\n&quot;);
 147         hasPrinted = true;
 148     }
 149 
 150     // Print the pushes.
 151     for (unsigned i = indexOfDivergence; i &lt; currentInlineStack.size(); ++i) {
 152         out.print(prefix);
 153         printWhiteSpace(out, i * 2);
 154         out.print(&quot;--&gt; &quot;, inContext(*currentInlineStack[i].inlineCallFrame(), context), &quot;\n&quot;);
 155         hasPrinted = true;
 156     }
 157 
 158     return hasPrinted;
 159 }
 160 
 161 int Graph::amountOfNodeWhiteSpace(Node* node)
 162 {
 163     return (node-&gt;origin.semantic.inlineDepth() - 1) * 2;
 164 }
 165 
 166 void Graph::printNodeWhiteSpace(PrintStream&amp; out, Node* node)
 167 {
 168     printWhiteSpace(out, amountOfNodeWhiteSpace(node));
 169 }
 170 
 171 void Graph::dump(PrintStream&amp; out, const char* prefixStr, Node* node, DumpContext* context)
 172 {
 173     Prefix myPrefix(prefixStr);
 174     Prefix&amp; prefix = prefixStr ? myPrefix : m_prefix;
 175 
 176     NodeType op = node-&gt;op();
 177 
 178     unsigned refCount = node-&gt;refCount();
 179     bool mustGenerate = node-&gt;mustGenerate();
 180     if (mustGenerate)
 181         --refCount;
 182 
 183     out.print(prefix);
 184     printNodeWhiteSpace(out, node);
 185 
 186     // Example/explanation of dataflow dump output
 187     //
 188     //   D@14:   &lt;!2:7&gt;  GetByVal(@3, @13)
 189     //     ^1     ^2 ^3     ^4       ^5
 190     //
 191     // (1) The nodeIndex of this operation.
 192     // (2) The reference count. The number printed is the &#39;real&#39; count,
 193     //     not including the &#39;mustGenerate&#39; ref. If the node is
 194     //     &#39;mustGenerate&#39; then the count it prefixed with &#39;!&#39;.
 195     // (3) The virtual register slot assigned to this node.
 196     // (4) The name of the operation.
 197     // (5) The arguments to the operation. The may be of the form:
 198     //         D@#  - a NodeIndex referencing a prior node in the graph.
 199     //         arg# - an argument number.
 200     //         id#  - the index in the CodeBlock of an identifier { if codeBlock is passed to dump(), the string representation is displayed }.
 201     //         var# - the index of a var on the global object, used by GetGlobalVar/GetGlobalLexicalVariable/PutGlobalVariable operations.
 202     int nodeIndex = node-&gt;index();
 203     const char* prefixPadding = nodeIndex &lt; 10 ? &quot;   &quot; : nodeIndex &lt; 100 ? &quot;  &quot; : &quot; &quot;;
 204     out.printf(&quot;%sD@%d:&lt;%c%u:&quot;, prefixPadding, nodeIndex, mustGenerate ? &#39;!&#39; : &#39; &#39;, refCount);
 205     if (node-&gt;hasResult() &amp;&amp; node-&gt;hasVirtualRegister() &amp;&amp; node-&gt;virtualRegister().isValid())
 206         out.print(node-&gt;virtualRegister());
 207     else
 208         out.print(&quot;-&quot;);
 209     out.print(&quot;&gt;\t&quot;, opName(op), &quot;(&quot;);
 210     CommaPrinter comma;
 211     if (node-&gt;flags() &amp; NodeHasVarArgs) {
 212         for (unsigned childIdx = node-&gt;firstChild(); childIdx &lt; node-&gt;firstChild() + node-&gt;numChildren(); childIdx++) {
 213             if (!m_varArgChildren[childIdx])
 214                 continue;
 215             out.print(comma, m_varArgChildren[childIdx]);
 216         }
 217     } else {
 218         if (!!node-&gt;child1() || !!node-&gt;child2() || !!node-&gt;child3())
 219             out.print(comma, node-&gt;child1());
 220         if (!!node-&gt;child2() || !!node-&gt;child3())
 221             out.print(comma, node-&gt;child2());
 222         if (!!node-&gt;child3())
 223             out.print(comma, node-&gt;child3());
 224     }
 225 
 226     if (toCString(NodeFlagsDump(node-&gt;flags())) != &quot;&lt;empty&gt;&quot;)
 227         out.print(comma, NodeFlagsDump(node-&gt;flags()));
 228     if (node-&gt;prediction())
 229         out.print(comma, SpeculationDump(node-&gt;prediction()));
 230     if (node-&gt;hasNumberOfArgumentsToSkip())
 231         out.print(comma, &quot;numberOfArgumentsToSkip = &quot;, node-&gt;numberOfArgumentsToSkip());
 232     if (node-&gt;hasArrayMode())
 233         out.print(comma, node-&gt;arrayMode());
 234     if (node-&gt;hasArithUnaryType())
 235         out.print(comma, &quot;Type:&quot;, node-&gt;arithUnaryType());
 236     if (node-&gt;hasArithMode())
 237         out.print(comma, node-&gt;arithMode());
 238     if (node-&gt;hasArithRoundingMode())
 239         out.print(comma, &quot;Rounding:&quot;, node-&gt;arithRoundingMode());
 240     if (node-&gt;hasScopeOffset())
 241         out.print(comma, node-&gt;scopeOffset());
 242     if (node-&gt;hasDirectArgumentsOffset())
 243         out.print(comma, node-&gt;capturedArgumentsOffset());
 244     if (node-&gt;hasArgumentIndex())
 245         out.print(comma, node-&gt;argumentIndex());
 246     if (node-&gt;hasRegisterPointer())
 247         out.print(comma, &quot;global&quot;, &quot;(&quot;, RawPointer(node-&gt;variablePointer()), &quot;)&quot;);
 248     if (node-&gt;hasIdentifier() &amp;&amp; node-&gt;identifierNumber() != UINT32_MAX)
 249         out.print(comma, &quot;id&quot;, node-&gt;identifierNumber(), &quot;{&quot;, identifiers()[node-&gt;identifierNumber()], &quot;}&quot;);
 250     if (node-&gt;hasPromotedLocationDescriptor())
 251         out.print(comma, node-&gt;promotedLocationDescriptor());
 252     if (node-&gt;hasClassInfo())
 253         out.print(comma, *node-&gt;classInfo());
 254     if (node-&gt;hasStructureSet())
 255         out.print(comma, inContext(node-&gt;structureSet().toStructureSet(), context));
 256     if (node-&gt;hasStructure())
 257         out.print(comma, inContext(*node-&gt;structure().get(), context));
 258     if (node-&gt;op() == CPUIntrinsic)
 259         out.print(comma, intrinsicName(node-&gt;intrinsic()));
 260     if (node-&gt;hasTransition()) {
 261         out.print(comma, pointerDumpInContext(node-&gt;transition(), context));
 262 #if USE(JSVALUE64)
 263         out.print(&quot;, ID:&quot;, node-&gt;transition()-&gt;next-&gt;id());
 264 #else
 265         out.print(&quot;, ID:&quot;, RawPointer(node-&gt;transition()-&gt;next.get()));
 266 #endif
 267     }
 268     if (node-&gt;hasCellOperand()) {
 269         if (!node-&gt;cellOperand()-&gt;value() || !node-&gt;cellOperand()-&gt;value().isCell())
 270             out.print(comma, &quot;invalid cell operand: &quot;, node-&gt;cellOperand()-&gt;value());
 271         else {
 272             out.print(comma, pointerDump(node-&gt;cellOperand()-&gt;value().asCell()));
 273             if (node-&gt;cellOperand()-&gt;value().isCell()) {
 274                 CallVariant variant(node-&gt;cellOperand()-&gt;value().asCell());
 275                 if (ExecutableBase* executable = variant.executable()) {
 276                     if (executable-&gt;isHostFunction())
 277                         out.print(comma, &quot;&lt;host function&gt;&quot;);
 278                     else if (FunctionExecutable* functionExecutable = jsDynamicCast&lt;FunctionExecutable*&gt;(m_vm, executable))
 279                         out.print(comma, FunctionExecutableDump(functionExecutable));
 280                     else
 281                         out.print(comma, &quot;&lt;non-function executable&gt;&quot;);
 282                 }
 283             }
 284         }
 285     }
 286     if (node-&gt;hasQueriedType())
 287         out.print(comma, node-&gt;queriedType());
 288     if (node-&gt;hasStorageAccessData()) {
 289         StorageAccessData&amp; storageAccessData = node-&gt;storageAccessData();
 290         out.print(comma, &quot;id&quot;, storageAccessData.identifierNumber, &quot;{&quot;, identifiers()[storageAccessData.identifierNumber], &quot;}&quot;);
 291         out.print(&quot;, &quot;, static_cast&lt;ptrdiff_t&gt;(storageAccessData.offset));
 292     }
 293     if (node-&gt;hasMultiGetByOffsetData()) {
 294         MultiGetByOffsetData&amp; data = node-&gt;multiGetByOffsetData();
 295         out.print(comma, &quot;id&quot;, data.identifierNumber, &quot;{&quot;, identifiers()[data.identifierNumber], &quot;}&quot;);
 296         for (unsigned i = 0; i &lt; data.cases.size(); ++i)
 297             out.print(comma, inContext(data.cases[i], context));
 298     }
 299     if (node-&gt;hasMultiPutByOffsetData()) {
 300         MultiPutByOffsetData&amp; data = node-&gt;multiPutByOffsetData();
 301         out.print(comma, &quot;id&quot;, data.identifierNumber, &quot;{&quot;, identifiers()[data.identifierNumber], &quot;}&quot;);
 302         for (unsigned i = 0; i &lt; data.variants.size(); ++i)
 303             out.print(comma, inContext(data.variants[i], context));
 304     }
 305     if (node-&gt;hasMatchStructureData()) {
 306         for (MatchStructureVariant&amp; variant : node-&gt;matchStructureData().variants)
 307             out.print(comma, inContext(*variant.structure.get(), context), &quot;=&gt;&quot;, variant.result);
 308     }
 309     ASSERT(node-&gt;hasVariableAccessData(*this) == node-&gt;accessesStack(*this));
 310     if (node-&gt;hasVariableAccessData(*this)) {
 311         VariableAccessData* variableAccessData = node-&gt;tryGetVariableAccessData();
 312         if (variableAccessData) {
 313             Operand operand = variableAccessData-&gt;operand();
 314             out.print(comma, variableAccessData-&gt;operand(), &quot;(&quot;, VariableAccessDataDump(*this, variableAccessData), &quot;)&quot;);
 315             operand = variableAccessData-&gt;machineLocal();
 316             if (operand.isValid())
 317                 out.print(comma, &quot;machine:&quot;, operand);
 318         }
 319     }
 320     if (node-&gt;hasStackAccessData()) {
 321         StackAccessData* data = node-&gt;stackAccessData();
 322         out.print(comma, data-&gt;operand);
 323         if (data-&gt;machineLocal.isValid())
 324             out.print(comma, &quot;machine:&quot;, data-&gt;machineLocal);
 325         out.print(comma, data-&gt;format);
 326     }
 327     if (node-&gt;hasUnlinkedOperand())
 328         out.print(comma, node-&gt;unlinkedOperand());
 329     if (node-&gt;hasVectorLengthHint())
 330         out.print(comma, &quot;vectorLengthHint = &quot;, node-&gt;vectorLengthHint());
 331     if (node-&gt;hasLazyJSValue())
 332         out.print(comma, node-&gt;lazyJSValue());
 333     if (node-&gt;hasIndexingType())
 334         out.print(comma, IndexingTypeDump(node-&gt;indexingMode()));
 335     if (node-&gt;hasTypedArrayType())
 336         out.print(comma, node-&gt;typedArrayType());
 337     if (node-&gt;hasPhi())
 338         out.print(comma, &quot;^&quot;, node-&gt;phi()-&gt;index());
 339     if (node-&gt;hasExecutionCounter())
 340         out.print(comma, RawPointer(node-&gt;executionCounter()));
 341     if (node-&gt;hasWatchpointSet())
 342         out.print(comma, RawPointer(node-&gt;watchpointSet()));
 343     if (node-&gt;hasStoragePointer())
 344         out.print(comma, RawPointer(node-&gt;storagePointer()));
 345     if (node-&gt;hasObjectMaterializationData())
 346         out.print(comma, node-&gt;objectMaterializationData());
 347     if (node-&gt;hasCallVarargsData())
 348         out.print(comma, &quot;firstVarArgOffset = &quot;, node-&gt;callVarargsData()-&gt;firstVarArgOffset);
 349     if (node-&gt;hasLoadVarargsData()) {
 350         LoadVarargsData* data = node-&gt;loadVarargsData();
 351         out.print(comma, &quot;start = &quot;, data-&gt;start, &quot;, count = &quot;, data-&gt;count);
 352         if (data-&gt;machineStart.isValid())
 353             out.print(&quot;, machineStart = &quot;, data-&gt;machineStart);
 354         if (data-&gt;machineCount.isValid())
 355             out.print(&quot;, machineCount = &quot;, data-&gt;machineCount);
 356         out.print(&quot;, offset = &quot;, data-&gt;offset, &quot;, mandatoryMinimum = &quot;, data-&gt;mandatoryMinimum);
 357         out.print(&quot;, limit = &quot;, data-&gt;limit);
 358     }
 359     if (node-&gt;hasIsInternalPromise())
 360         out.print(comma, &quot;isInternalPromise = &quot;, node-&gt;isInternalPromise());
 361     if (node-&gt;hasInternalFieldIndex())
 362         out.print(comma, &quot;internalFieldIndex = &quot;, node-&gt;internalFieldIndex());
 363     if (node-&gt;hasCallDOMGetterData()) {
 364         CallDOMGetterData* data = node-&gt;callDOMGetterData();
 365         out.print(comma, &quot;id&quot;, data-&gt;identifierNumber, &quot;{&quot;, identifiers()[data-&gt;identifierNumber], &quot;}&quot;);
 366         out.print(&quot;, domJIT = &quot;, RawPointer(data-&gt;domJIT));
 367     }
 368     if (node-&gt;hasIgnoreLastIndexIsWritable())
 369         out.print(comma, &quot;ignoreLastIndexIsWritable = &quot;, node-&gt;ignoreLastIndexIsWritable());
 370     if (node-&gt;hasIntrinsic())
 371         out.print(comma, &quot;intrinsic = &quot;, node-&gt;intrinsic());
 372     if (node-&gt;isConstant())
 373         out.print(comma, pointerDumpInContext(node-&gt;constant(), context));
 374     if (node-&gt;hasCallLinkStatus())
 375         out.print(comma, *node-&gt;callLinkStatus());
 376     if (node-&gt;hasGetByStatus())
 377         out.print(comma, *node-&gt;getByStatus());
 378     if (node-&gt;hasInByIdStatus())
 379         out.print(comma, *node-&gt;inByIdStatus());
 380     if (node-&gt;hasPutByIdStatus())
 381         out.print(comma, *node-&gt;putByIdStatus());
 382     if (node-&gt;isJump())
 383         out.print(comma, &quot;T:&quot;, *node-&gt;targetBlock());
 384     if (node-&gt;isBranch())
 385         out.print(comma, &quot;T:&quot;, node-&gt;branchData()-&gt;taken, &quot;, F:&quot;, node-&gt;branchData()-&gt;notTaken);
 386     if (node-&gt;isSwitch()) {
 387         SwitchData* data = node-&gt;switchData();
 388         out.print(comma, data-&gt;kind);
 389         for (unsigned i = 0; i &lt; data-&gt;cases.size(); ++i)
 390             out.print(comma, inContext(data-&gt;cases[i].value, context), &quot;:&quot;, data-&gt;cases[i].target);
 391         out.print(comma, &quot;default:&quot;, data-&gt;fallThrough);
 392     }
 393     if (node-&gt;isEntrySwitch()) {
 394         EntrySwitchData* data = node-&gt;entrySwitchData();
 395         for (unsigned i = 0; i &lt; data-&gt;cases.size(); ++i)
 396             out.print(comma, BranchTarget(data-&gt;cases[i]));
 397     }
 398     ClobberSet reads;
 399     ClobberSet writes;
 400     addReadsAndWrites(*this, node, reads, writes);
 401     if (!reads.isEmpty())
 402         out.print(comma, &quot;R:&quot;, sortedListDump(reads.direct(), &quot;,&quot;));
 403     if (!writes.isEmpty())
 404         out.print(comma, &quot;W:&quot;, sortedListDump(writes.direct(), &quot;,&quot;));
 405     ExitMode exitMode = mayExit(*this, node);
 406     if (exitMode != DoesNotExit)
 407         out.print(comma, exitMode);
 408     if (clobbersExitState(*this, node))
 409         out.print(comma, &quot;ClobbersExit&quot;);
 410     if (node-&gt;origin.isSet()) {
 411         out.print(comma, node-&gt;origin.semantic.bytecodeIndex());
 412         if (node-&gt;origin.semantic != node-&gt;origin.forExit &amp;&amp; node-&gt;origin.forExit.isSet())
 413             out.print(comma, &quot;exit: &quot;, node-&gt;origin.forExit);
 414     }
 415     out.print(comma, node-&gt;origin.exitOK ? &quot;ExitValid&quot; : &quot;ExitInvalid&quot;);
 416     if (node-&gt;origin.wasHoisted)
 417         out.print(comma, &quot;WasHoisted&quot;);
 418     out.print(&quot;)&quot;);
 419 
 420     if (node-&gt;accessesStack(*this) &amp;&amp; node-&gt;tryGetVariableAccessData())
 421         out.print(&quot;  predicting &quot;, SpeculationDump(node-&gt;tryGetVariableAccessData()-&gt;prediction()));
 422     else if (node-&gt;hasHeapPrediction())
 423         out.print(&quot;  predicting &quot;, SpeculationDump(node-&gt;getHeapPrediction()));
 424 
 425     out.print(&quot;\n&quot;);
 426 }
 427 
 428 bool Graph::terminalsAreValid()
 429 {
 430     for (BasicBlock* block : blocksInNaturalOrder()) {
 431         if (!block-&gt;terminal())
 432             return false;
 433     }
 434     return true;
 435 }
 436 
 437 static BasicBlock* unboxLoopNode(const CPSCFG::Node&amp; node) { return node.node(); }
 438 static BasicBlock* unboxLoopNode(BasicBlock* block) { return block; }
 439 
 440 void Graph::dumpBlockHeader(PrintStream&amp; out, const char* prefixStr, BasicBlock* block, PhiNodeDumpMode phiNodeDumpMode, DumpContext* context)
 441 {
 442     Prefix myPrefix(prefixStr);
 443     Prefix&amp; prefix = prefixStr ? myPrefix : m_prefix;
 444 
 445     out.print(prefix, &quot;Block &quot;, *block, &quot; (&quot;, inContext(block-&gt;at(0)-&gt;origin.semantic, context), &quot;):&quot;,
 446         block-&gt;isReachable ? &quot;&quot; : &quot; (skipped)&quot;, block-&gt;isOSRTarget ? &quot; (OSR target)&quot; : &quot;&quot;, block-&gt;isCatchEntrypoint ? &quot; (Catch Entrypoint)&quot; : &quot;&quot;, &quot;\n&quot;);
 447     if (block-&gt;executionCount == block-&gt;executionCount)
 448         out.print(prefix, &quot;  Execution count: &quot;, block-&gt;executionCount, &quot;\n&quot;);
 449     out.print(prefix, &quot;  Predecessors:&quot;);
 450     for (size_t i = 0; i &lt; block-&gt;predecessors.size(); ++i)
 451         out.print(&quot; &quot;, *block-&gt;predecessors[i]);
 452     out.print(&quot;\n&quot;);
 453     out.print(prefix, &quot;  Successors:&quot;);
 454     if (block-&gt;terminal()) {
 455         for (BasicBlock* successor : block-&gt;successors()) {
 456             out.print(&quot; &quot;, *successor);
 457         }
 458     } else
 459         out.print(&quot; &lt;invalid&gt;&quot;);
 460     out.print(&quot;\n&quot;);
 461 
 462     auto printDominators = [&amp;] (auto&amp; dominators) {
 463         out.print(prefix, &quot;  Dominated by: &quot;, dominators.dominatorsOf(block), &quot;\n&quot;);
 464         out.print(prefix, &quot;  Dominates: &quot;, dominators.blocksDominatedBy(block), &quot;\n&quot;);
 465         out.print(prefix, &quot;  Dominance Frontier: &quot;, dominators.dominanceFrontierOf(block), &quot;\n&quot;);
 466         out.print(prefix, &quot;  Iterated Dominance Frontier: &quot;,
 467             dominators.iteratedDominanceFrontierOf(typename std::remove_reference&lt;decltype(dominators)&gt;::type::List { block }), &quot;\n&quot;);
 468     };
 469 
 470     if (terminalsAreValid()) {
 471         if (m_ssaDominators)
 472             printDominators(*m_ssaDominators);
 473         else if (m_cpsDominators)
 474             printDominators(*m_cpsDominators);
 475     }
 476 
 477     if (m_backwardsDominators &amp;&amp; terminalsAreValid()) {
 478         out.print(prefix, &quot;  Backwards dominates by: &quot;, m_backwardsDominators-&gt;dominatorsOf(block), &quot;\n&quot;);
 479         out.print(prefix, &quot;  Backwards dominates: &quot;, m_backwardsDominators-&gt;blocksDominatedBy(block), &quot;\n&quot;);
 480     }
 481     if (m_controlEquivalenceAnalysis &amp;&amp; terminalsAreValid()) {
 482         out.print(prefix, &quot;  Control equivalent to:&quot;);
 483         for (BasicBlock* otherBlock : blocksInNaturalOrder()) {
 484             if (m_controlEquivalenceAnalysis-&gt;areEquivalent(block, otherBlock))
 485                 out.print(&quot; &quot;, *otherBlock);
 486         }
 487         out.print(&quot;\n&quot;);
 488     }
 489 
 490     auto printNaturalLoops = [&amp;] (auto&amp; naturalLoops) {
 491         if (const auto* loop = naturalLoops-&gt;headerOf(block)) {
 492             out.print(prefix, &quot;  Loop header, contains:&quot;);
 493             Vector&lt;BlockIndex&gt; sortedBlockList;
 494             for (unsigned i = 0; i &lt; loop-&gt;size(); ++i)
 495                 sortedBlockList.append(unboxLoopNode(loop-&gt;at(i))-&gt;index);
 496             std::sort(sortedBlockList.begin(), sortedBlockList.end());
 497             for (unsigned i = 0; i &lt; sortedBlockList.size(); ++i)
 498                 out.print(&quot; #&quot;, sortedBlockList[i]);
 499             out.print(&quot;\n&quot;);
 500         }
 501 
 502         auto containingLoops = naturalLoops-&gt;loopsOf(block);
 503         if (!containingLoops.isEmpty()) {
 504             out.print(prefix, &quot;  Containing loop headers:&quot;);
 505             for (unsigned i = 0; i &lt; containingLoops.size(); ++i)
 506                 out.print(&quot; &quot;, *unboxLoopNode(containingLoops[i]-&gt;header()));
 507             out.print(&quot;\n&quot;);
 508         }
 509     };
 510 
 511     if (m_ssaNaturalLoops)
 512         printNaturalLoops(m_ssaNaturalLoops);
 513     else if (m_cpsNaturalLoops)
 514         printNaturalLoops(m_cpsNaturalLoops);
 515 
 516     if (!block-&gt;phis.isEmpty()) {
 517         out.print(prefix, &quot;  Phi Nodes:&quot;);
 518         for (size_t i = 0; i &lt; block-&gt;phis.size(); ++i) {
 519             Node* phiNode = block-&gt;phis[i];
 520             ASSERT(phiNode-&gt;op() == Phi);
 521             if (!phiNode-&gt;shouldGenerate() &amp;&amp; phiNodeDumpMode == DumpLivePhisOnly)
 522                 continue;
 523             out.print(&quot; D@&quot;, phiNode-&gt;index(), &quot;&lt;&quot;, phiNode-&gt;operand(), &quot;,&quot;, phiNode-&gt;refCount(), &quot;&gt;-&gt;(&quot;);
 524             if (phiNode-&gt;child1()) {
 525                 out.print(&quot;D@&quot;, phiNode-&gt;child1()-&gt;index());
 526                 if (phiNode-&gt;child2()) {
 527                     out.print(&quot;, D@&quot;, phiNode-&gt;child2()-&gt;index());
 528                     if (phiNode-&gt;child3())
 529                         out.print(&quot;, D@&quot;, phiNode-&gt;child3()-&gt;index());
 530                 }
 531             }
 532             out.print(&quot;)&quot;, i + 1 &lt; block-&gt;phis.size() ? &quot;,&quot; : &quot;&quot;);
 533         }
 534         out.print(&quot;\n&quot;);
 535     }
 536 }
 537 
 538 void Graph::dump(PrintStream&amp; out, DumpContext* context)
 539 {
 540     Prefix&amp; prefix = m_prefix;
 541     DumpContext myContext;
 542     myContext.graph = this;
 543     if (!context)
 544         context = &amp;myContext;
 545 
 546     out.print(&quot;\n&quot;);
 547     out.print(prefix, &quot;DFG for &quot;, CodeBlockWithJITType(m_codeBlock, JITType::DFGJIT), &quot;:\n&quot;);
 548     out.print(prefix, &quot;  Fixpoint state: &quot;, m_fixpointState, &quot;; Form: &quot;, m_form, &quot;; Unification state: &quot;, m_unificationState, &quot;; Ref count state: &quot;, m_refCountState, &quot;\n&quot;);
 549     if (m_form == SSA) {
 550         for (unsigned entrypointIndex = 0; entrypointIndex &lt; m_argumentFormats.size(); ++entrypointIndex)
 551             out.print(prefix, &quot;  Argument formats for entrypoint index: &quot;, entrypointIndex, &quot; : &quot;, listDump(m_argumentFormats[entrypointIndex]), &quot;\n&quot;);
 552     }
 553     else {
 554         for (const auto&amp; pair : m_rootToArguments)
 555             out.print(prefix, &quot;  Arguments for block#&quot;, pair.key-&gt;index, &quot;: &quot;, listDump(pair.value), &quot;\n&quot;);
 556     }
 557     out.print(&quot;\n&quot;);
 558 
 559     Node* lastNode = nullptr;
 560     for (size_t b = 0; b &lt; m_blocks.size(); ++b) {
 561         BasicBlock* block = m_blocks[b].get();
 562         if (!block)
 563             continue;
 564         prefix.blockIndex = block-&gt;index;
 565         dumpBlockHeader(out, Prefix::noString, block, DumpAllPhis, context);
 566         out.print(prefix, &quot;  States: &quot;, block-&gt;cfaStructureClobberStateAtHead);
 567         if (!block-&gt;cfaHasVisited)
 568             out.print(&quot;, CurrentlyCFAUnreachable&quot;);
 569         if (!block-&gt;intersectionOfCFAHasVisited)
 570             out.print(&quot;, CFAUnreachable&quot;);
 571         out.print(&quot;\n&quot;);
 572         switch (m_form) {
 573         case LoadStore:
 574         case ThreadedCPS: {
 575             out.print(prefix, &quot;  Vars Before: &quot;);
 576             if (block-&gt;cfaHasVisited)
 577                 out.print(inContext(block-&gt;valuesAtHead, context));
 578             else
 579                 out.print(&quot;&lt;empty&gt;&quot;);
 580             out.print(&quot;\n&quot;);
 581             out.print(prefix, &quot;  Intersected Vars Before: &quot;);
 582             if (block-&gt;intersectionOfCFAHasVisited)
 583                 out.print(inContext(block-&gt;intersectionOfPastValuesAtHead, context));
 584             else
 585                 out.print(&quot;&lt;empty&gt;&quot;);
 586             out.print(&quot;\n&quot;);
 587             out.print(prefix, &quot;  Var Links: &quot;, block-&gt;variablesAtHead, &quot;\n&quot;);
 588             break;
 589         }
 590 
 591         case SSA: {
 592             RELEASE_ASSERT(block-&gt;ssa);
 593             if (dumpOSRAvailabilityData)
 594                 out.print(prefix, &quot;  Availability: &quot;, block-&gt;ssa-&gt;availabilityAtHead, &quot;\n&quot;);
 595             out.print(prefix, &quot;  Live: &quot;, nodeListDump(block-&gt;ssa-&gt;liveAtHead), &quot;\n&quot;);
 596             out.print(prefix, &quot;  Values: &quot;, nodeValuePairListDump(block-&gt;ssa-&gt;valuesAtHead, context), &quot;\n&quot;);
 597             break;
 598         } }
 599         for (size_t i = 0; i &lt; block-&gt;size(); ++i) {
 600             prefix.clearNodeIndex();
 601             dumpCodeOrigin(out, Prefix::noString, lastNode, block-&gt;at(i), context);
 602             prefix.nodeIndex = i;
 603             dump(out, Prefix::noString, block-&gt;at(i), context);
 604         }
 605         prefix.clearNodeIndex();
 606         out.print(prefix, &quot;  States: &quot;, block-&gt;cfaBranchDirection, &quot;, &quot;, block-&gt;cfaStructureClobberStateAtTail);
 607         if (!block-&gt;cfaDidFinish)
 608             out.print(&quot;, CFAInvalidated&quot;);
 609         out.print(&quot;\n&quot;);
 610         switch (m_form) {
 611         case LoadStore:
 612         case ThreadedCPS: {
 613             out.print(prefix, &quot;  Vars After: &quot;);
 614             if (block-&gt;cfaHasVisited)
 615                 out.print(inContext(block-&gt;valuesAtTail, context));
 616             else
 617                 out.print(&quot;&lt;empty&gt;&quot;);
 618             out.print(&quot;\n&quot;);
 619             out.print(prefix, &quot;  Var Links: &quot;, block-&gt;variablesAtTail, &quot;\n&quot;);
 620             break;
 621         }
 622 
 623         case SSA: {
 624             RELEASE_ASSERT(block-&gt;ssa);
 625             if (dumpOSRAvailabilityData)
 626                 out.print(prefix, &quot;  Availability: &quot;, block-&gt;ssa-&gt;availabilityAtTail, &quot;\n&quot;);
 627             out.print(prefix, &quot;  Live: &quot;, nodeListDump(block-&gt;ssa-&gt;liveAtTail), &quot;\n&quot;);
 628             out.print(prefix, &quot;  Values: &quot;, nodeValuePairListDump(block-&gt;ssa-&gt;valuesAtTail, context), &quot;\n&quot;);
 629             break;
 630         } }
 631         out.print(&quot;\n&quot;);
 632     }
 633     prefix.clearBlockIndex();
 634 
 635     out.print(prefix, &quot;GC Values:\n&quot;);
 636     for (FrozenValue* value : m_frozenValues) {
 637         if (value-&gt;pointsToHeap())
 638             out.print(prefix, &quot;    &quot;, inContext(*value, &amp;myContext), &quot;\n&quot;);
 639     }
 640 
 641     out.print(inContext(watchpoints(), &amp;myContext));
 642 
 643     if (!myContext.isEmpty()) {
 644         StringPrintStream prefixStr;
 645         prefixStr.print(prefix);
 646         myContext.dump(out, prefixStr.toCString().data());
 647         out.print(&quot;\n&quot;);
 648     }
 649 }
 650 
 651 void Graph::deleteNode(Node* node)
 652 {
 653     if (validationEnabled() &amp;&amp; m_form == SSA) {
 654         for (BasicBlock* block : blocksInNaturalOrder()) {
 655             DFG_ASSERT(*this, node, !block-&gt;ssa-&gt;liveAtHead.contains(node));
 656             DFG_ASSERT(*this, node, !block-&gt;ssa-&gt;liveAtTail.contains(node));
 657         }
 658     }
 659 
 660     m_nodes.remove(node);
 661 }
 662 
 663 void Graph::packNodeIndices()
 664 {
 665     m_nodes.packIndices();
 666 }
 667 
 668 void Graph::dethread()
 669 {
 670     if (m_form == LoadStore || m_form == SSA)
 671         return;
 672 
 673     if (logCompilationChanges())
 674         dataLog(&quot;Dethreading DFG graph.\n&quot;);
 675 
 676     for (BlockIndex blockIndex = m_blocks.size(); blockIndex--;) {
 677         BasicBlock* block = m_blocks[blockIndex].get();
 678         if (!block)
 679             continue;
 680         for (unsigned phiIndex = block-&gt;phis.size(); phiIndex--;) {
 681             Node* phi = block-&gt;phis[phiIndex];
 682             phi-&gt;children.reset();
 683         }
 684     }
 685 
 686     m_form = LoadStore;
 687 }
 688 
 689 void Graph::handleSuccessor(Vector&lt;BasicBlock*, 16&gt;&amp; worklist, BasicBlock* block, BasicBlock* successor)
 690 {
 691     if (!successor-&gt;isReachable) {
 692         successor-&gt;isReachable = true;
 693         worklist.append(successor);
 694     }
 695 
 696     if (!successor-&gt;predecessors.contains(block))
 697         successor-&gt;predecessors.append(block);
 698 }
 699 
 700 void Graph::determineReachability()
 701 {
 702     Vector&lt;BasicBlock*, 16&gt; worklist;
 703     for (BasicBlock* entrypoint : m_roots) {
 704         entrypoint-&gt;isReachable = true;
 705         worklist.append(entrypoint);
 706     }
 707     while (!worklist.isEmpty()) {
 708         BasicBlock* block = worklist.takeLast();
 709         for (unsigned i = block-&gt;numSuccessors(); i--;)
 710             handleSuccessor(worklist, block, block-&gt;successor(i));
 711     }
 712 }
 713 
 714 void Graph::resetReachability()
 715 {
 716     for (BlockIndex blockIndex = m_blocks.size(); blockIndex--;) {
 717         BasicBlock* block = m_blocks[blockIndex].get();
 718         if (!block)
 719             continue;
 720         block-&gt;isReachable = false;
 721         block-&gt;predecessors.clear();
 722     }
 723 
 724     determineReachability();
 725 }
 726 
 727 namespace {
 728 
 729 class RefCountCalculator {
 730 public:
 731     RefCountCalculator(Graph&amp; graph)
 732         : m_graph(graph)
 733     {
 734     }
 735 
 736     void calculate()
 737     {
 738         // First reset the counts to 0 for all nodes.
 739         for (BlockIndex blockIndex = 0; blockIndex &lt; m_graph.numBlocks(); ++blockIndex) {
 740             BasicBlock* block = m_graph.block(blockIndex);
 741             if (!block)
 742                 continue;
 743             for (unsigned indexInBlock = block-&gt;size(); indexInBlock--;)
 744                 block-&gt;at(indexInBlock)-&gt;setRefCount(0);
 745             for (unsigned phiIndex = block-&gt;phis.size(); phiIndex--;)
 746                 block-&gt;phis[phiIndex]-&gt;setRefCount(0);
 747         }
 748 
 749         // Now find the roots:
 750         // - Nodes that are must-generate.
 751         // - Nodes that are reachable from type checks.
 752         // Set their ref counts to 1 and put them on the worklist.
 753         for (BlockIndex blockIndex = 0; blockIndex &lt; m_graph.numBlocks(); ++blockIndex) {
 754             BasicBlock* block = m_graph.block(blockIndex);
 755             if (!block)
 756                 continue;
 757             for (unsigned indexInBlock = block-&gt;size(); indexInBlock--;) {
 758                 Node* node = block-&gt;at(indexInBlock);
 759                 DFG_NODE_DO_TO_CHILDREN(m_graph, node, findTypeCheckRoot);
 760                 if (!(node-&gt;flags() &amp; NodeMustGenerate))
 761                     continue;
 762                 if (!node-&gt;postfixRef())
 763                     m_worklist.append(node);
 764             }
 765         }
 766 
 767         while (!m_worklist.isEmpty()) {
 768             while (!m_worklist.isEmpty()) {
 769                 Node* node = m_worklist.last();
 770                 m_worklist.removeLast();
 771                 ASSERT(node-&gt;shouldGenerate()); // It should not be on the worklist unless it&#39;s ref&#39;ed.
 772                 DFG_NODE_DO_TO_CHILDREN(m_graph, node, countEdge);
 773             }
 774 
 775             if (m_graph.m_form == SSA) {
 776                 // Find Phi-&gt;Upsilon edges, which are represented as meta-data in the
 777                 // Upsilon.
 778                 for (BlockIndex blockIndex = m_graph.numBlocks(); blockIndex--;) {
 779                     BasicBlock* block = m_graph.block(blockIndex);
 780                     if (!block)
 781                         continue;
 782                     for (unsigned nodeIndex = block-&gt;size(); nodeIndex--;) {
 783                         Node* node = block-&gt;at(nodeIndex);
 784                         if (node-&gt;op() != Upsilon)
 785                             continue;
 786                         if (node-&gt;shouldGenerate())
 787                             continue;
 788                         if (node-&gt;phi()-&gt;shouldGenerate())
 789                             countNode(node);
 790                     }
 791                 }
 792             }
 793         }
 794     }
 795 
 796 private:
 797     void findTypeCheckRoot(Node*, Edge edge)
 798     {
 799         // We may have an &quot;unproved&quot; untyped use for code that is unreachable. The CFA
 800         // will just not have gotten around to it.
 801         if (edge.isProved() || edge.willNotHaveCheck())
 802             return;
 803         if (!edge-&gt;postfixRef())
 804             m_worklist.append(edge.node());
 805     }
 806 
 807     void countNode(Node* node)
 808     {
 809         if (node-&gt;postfixRef())
 810             return;
 811         m_worklist.append(node);
 812     }
 813 
 814     void countEdge(Node*, Edge edge)
 815     {
 816         // Don&#39;t count edges that are already counted for their type checks.
 817         if (!(edge.isProved() || edge.willNotHaveCheck()))
 818             return;
 819         countNode(edge.node());
 820     }
 821 
 822     Graph&amp; m_graph;
 823     Vector&lt;Node*, 128&gt; m_worklist;
 824 };
 825 
 826 } // anonymous namespace
 827 
 828 void Graph::computeRefCounts()
 829 {
 830     RefCountCalculator calculator(*this);
 831     calculator.calculate();
 832 }
 833 
 834 void Graph::killBlockAndItsContents(BasicBlock* block)
 835 {
 836     if (auto&amp; ssaData = block-&gt;ssa)
 837         ssaData-&gt;invalidate();
 838     for (unsigned phiIndex = block-&gt;phis.size(); phiIndex--;)
 839         deleteNode(block-&gt;phis[phiIndex]);
 840     for (Node* node : *block)
 841         deleteNode(node);
 842 
 843     killBlock(block);
 844 }
 845 
 846 void Graph::killUnreachableBlocks()
 847 {
 848     invalidateNodeLiveness();
 849 
 850     for (BlockIndex blockIndex = 0; blockIndex &lt; numBlocks(); ++blockIndex) {
 851         BasicBlock* block = this-&gt;block(blockIndex);
 852         if (!block)
 853             continue;
 854         if (block-&gt;isReachable)
 855             continue;
 856 
 857         dataLogIf(Options::verboseDFGBytecodeParsing(), &quot;Basic block #&quot;, blockIndex, &quot; was killed because it was unreachable\n&quot;);
 858         killBlockAndItsContents(block);
 859     }
 860 }
 861 
 862 void Graph::invalidateCFG()
 863 {
 864     m_cpsDominators = nullptr;
 865     m_ssaDominators = nullptr;
 866     m_cpsNaturalLoops = nullptr;
 867     m_ssaNaturalLoops = nullptr;
 868     m_controlEquivalenceAnalysis = nullptr;
 869     m_backwardsDominators = nullptr;
 870     m_backwardsCFG = nullptr;
 871     m_cpsCFG = nullptr;
 872 }
 873 
 874 void Graph::invalidateNodeLiveness()
 875 {
 876     if (m_form != SSA)
 877         return;
 878 
 879     for (BasicBlock* block : blocksInNaturalOrder())
 880         block-&gt;ssa-&gt;invalidate();
 881 }
 882 
 883 void Graph::substituteGetLocal(BasicBlock&amp; block, unsigned startIndexInBlock, VariableAccessData* variableAccessData, Node* newGetLocal)
 884 {
 885     for (unsigned indexInBlock = startIndexInBlock; indexInBlock &lt; block.size(); ++indexInBlock) {
 886         Node* node = block[indexInBlock];
 887         bool shouldContinue = true;
 888         switch (node-&gt;op()) {
 889         case SetLocal: {
 890             if (node-&gt;operand() == variableAccessData-&gt;operand())
 891                 shouldContinue = false;
 892             break;
 893         }
 894 
 895         case GetLocal: {
 896             if (node-&gt;variableAccessData() != variableAccessData)
 897                 continue;
 898             substitute(block, indexInBlock, node, newGetLocal);
 899             Node* oldTailNode = block.variablesAtTail.operand(variableAccessData-&gt;operand());
 900             if (oldTailNode == node)
 901                 block.variablesAtTail.operand(variableAccessData-&gt;operand()) = newGetLocal;
 902             shouldContinue = false;
 903             break;
 904         }
 905 
 906         default:
 907             break;
 908         }
 909         if (!shouldContinue)
 910             break;
 911     }
 912 }
 913 
 914 BlockList Graph::blocksInPreOrder()
 915 {
 916     BlockList result;
 917     result.reserveInitialCapacity(m_blocks.size());
 918     BlockWorklist worklist;
 919     for (BasicBlock* entrypoint : m_roots)
 920         worklist.push(entrypoint);
 921     while (BasicBlock* block = worklist.pop()) {
 922         result.append(block);
 923         for (unsigned i = block-&gt;numSuccessors(); i--;)
 924             worklist.push(block-&gt;successor(i));
 925     }
 926 
 927     if (validationEnabled()) {
 928         // When iterating over pre order, we should see dominators
 929         // before things they dominate.
 930         auto validateResults = [&amp;] (auto&amp; dominators) {
 931             for (unsigned i = 0; i &lt; result.size(); ++i) {
 932                 BasicBlock* a = result[i];
 933                 if (!a)
 934                     continue;
 935                 for (unsigned j = 0; j &lt; result.size(); ++j) {
 936                     BasicBlock* b = result[j];
 937                     if (!b || a == b)
 938                         continue;
 939                     if (dominators.dominates(a, b))
 940                         RELEASE_ASSERT(i &lt; j);
 941                 }
 942             }
 943         };
 944 
 945         if (m_form == SSA || m_isInSSAConversion)
 946             validateResults(ensureSSADominators());
 947         else
 948             validateResults(ensureCPSDominators());
 949     }
 950     return result;
 951 }
 952 
 953 BlockList Graph::blocksInPostOrder(bool isSafeToValidate)
 954 {
 955     BlockList result;
 956     result.reserveInitialCapacity(m_blocks.size());
 957     PostOrderBlockWorklist worklist;
 958     for (BasicBlock* entrypoint : m_roots)
 959         worklist.push(entrypoint);
 960     while (BlockWithOrder item = worklist.pop()) {
 961         switch (item.order) {
 962         case VisitOrder::Pre:
 963             worklist.pushPost(item.node);
 964             for (unsigned i = item.node-&gt;numSuccessors(); i--;)
 965                 worklist.push(item.node-&gt;successor(i));
 966             break;
 967         case VisitOrder::Post:
 968             result.append(item.node);
 969             break;
 970         }
 971     }
 972 
 973     if (isSafeToValidate &amp;&amp; validationEnabled()) { // There are users of this where we haven&#39;t yet built of the CFG enough to be able to run dominators.
 974         auto validateResults = [&amp;] (auto&amp; dominators) {
 975             // When iterating over reverse post order, we should see dominators
 976             // before things they dominate.
 977             for (unsigned i = 0; i &lt; result.size(); ++i) {
 978                 BasicBlock* a = result[i];
 979                 if (!a)
 980                     continue;
 981                 for (unsigned j = 0; j &lt; result.size(); ++j) {
 982                     BasicBlock* b = result[j];
 983                     if (!b || a == b)
 984                         continue;
 985                     if (dominators.dominates(a, b))
 986                         RELEASE_ASSERT(i &gt; j);
 987                 }
 988             }
 989         };
 990 
 991         if (m_form == SSA || m_isInSSAConversion)
 992             validateResults(ensureSSADominators());
 993         else
 994             validateResults(ensureCPSDominators());
 995     }
 996 
 997     return result;
 998 }
 999 
1000 void Graph::clearReplacements()
1001 {
1002     for (BlockIndex blockIndex = numBlocks(); blockIndex--;) {
1003         BasicBlock* block = m_blocks[blockIndex].get();
1004         if (!block)
1005             continue;
1006         for (unsigned phiIndex = block-&gt;phis.size(); phiIndex--;)
1007             block-&gt;phis[phiIndex]-&gt;setReplacement(nullptr);
1008         for (unsigned nodeIndex = block-&gt;size(); nodeIndex--;)
1009             block-&gt;at(nodeIndex)-&gt;setReplacement(nullptr);
1010     }
1011 }
1012 
1013 void Graph::clearEpochs()
1014 {
1015     for (BlockIndex blockIndex = numBlocks(); blockIndex--;) {
1016         BasicBlock* block = m_blocks[blockIndex].get();
1017         if (!block)
1018             continue;
1019         for (unsigned phiIndex = block-&gt;phis.size(); phiIndex--;)
1020             block-&gt;phis[phiIndex]-&gt;setEpoch(Epoch());
1021         for (unsigned nodeIndex = block-&gt;size(); nodeIndex--;)
1022             block-&gt;at(nodeIndex)-&gt;setEpoch(Epoch());
1023     }
1024 }
1025 
1026 void Graph::initializeNodeOwners()
1027 {
1028     for (BlockIndex blockIndex = numBlocks(); blockIndex--;) {
1029         BasicBlock* block = m_blocks[blockIndex].get();
1030         if (!block)
1031             continue;
1032         for (unsigned phiIndex = block-&gt;phis.size(); phiIndex--;)
1033             block-&gt;phis[phiIndex]-&gt;owner = block;
1034         for (unsigned nodeIndex = block-&gt;size(); nodeIndex--;)
1035             block-&gt;at(nodeIndex)-&gt;owner = block;
1036     }
1037 }
1038 
1039 void Graph::clearFlagsOnAllNodes(NodeFlags flags)
1040 {
1041     for (BlockIndex blockIndex = numBlocks(); blockIndex--;) {
1042         BasicBlock* block = m_blocks[blockIndex].get();
1043         if (!block)
1044             continue;
1045         for (unsigned phiIndex = block-&gt;phis.size(); phiIndex--;)
1046             block-&gt;phis[phiIndex]-&gt;clearFlags(flags);
1047         for (unsigned nodeIndex = block-&gt;size(); nodeIndex--;)
1048             block-&gt;at(nodeIndex)-&gt;clearFlags(flags);
1049     }
1050 }
1051 
1052 bool Graph::watchCondition(const ObjectPropertyCondition&amp; key)
1053 {
1054     if (!key.isWatchable())
1055         return false;
1056 
1057     DesiredWeakReferences&amp; weakReferences = m_plan.weakReferences();
1058     weakReferences.addLazily(key.object());
1059     if (key.hasPrototype())
1060         weakReferences.addLazily(key.prototype());
1061     if (key.hasRequiredValue())
1062         weakReferences.addLazily(key.requiredValue());
1063 
1064     m_plan.watchpoints().addLazily(key);
1065 
1066     if (key.kind() == PropertyCondition::Presence)
1067         m_safeToLoad.add(std::make_pair(key.object(), key.offset()));
1068 
1069     return true;
1070 }
1071 
1072 bool Graph::watchConditions(const ObjectPropertyConditionSet&amp; keys)
1073 {
1074     if (!keys.isValid())
1075         return false;
1076 
1077     for (const ObjectPropertyCondition&amp; key : keys) {
1078         if (!watchCondition(key))
1079             return false;
1080     }
1081     return true;
1082 }
1083 
1084 bool Graph::isSafeToLoad(JSObject* base, PropertyOffset offset)
1085 {
1086     return m_safeToLoad.contains(std::make_pair(base, offset));
1087 }
1088 
1089 bool Graph::watchGlobalProperty(JSGlobalObject* globalObject, unsigned identifierNumber)
1090 {
1091     UniquedStringImpl* uid = identifiers()[identifierNumber];
1092     // If we already have a WatchpointSet, and it is already invalidated, it means that this scope operation must be changed from GlobalProperty to GlobalLexicalVar,
1093     // but we still have stale metadata here since we have not yet executed this bytecode operation since the invalidation. Just emitting ForceOSRExit to update the
1094     // metadata when it reaches to this code.
1095     if (auto* watchpoint = globalObject-&gt;getReferencedPropertyWatchpointSet(uid)) {
1096         if (!watchpoint-&gt;isStillValid())
1097             return false;
1098     }
1099     globalProperties().addLazily(DesiredGlobalProperty(globalObject, identifierNumber));
1100     return true;
1101 }
1102 
1103 FullBytecodeLiveness&amp; Graph::livenessFor(CodeBlock* codeBlock)
1104 {
1105     HashMap&lt;CodeBlock*, std::unique_ptr&lt;FullBytecodeLiveness&gt;&gt;::iterator iter = m_bytecodeLiveness.find(codeBlock);
1106     if (iter != m_bytecodeLiveness.end())
1107         return *iter-&gt;value;
1108 
1109     std::unique_ptr&lt;FullBytecodeLiveness&gt; liveness = makeUnique&lt;FullBytecodeLiveness&gt;();
1110     codeBlock-&gt;livenessAnalysis().computeFullLiveness(codeBlock, *liveness);
1111     FullBytecodeLiveness&amp; result = *liveness;
1112     m_bytecodeLiveness.add(codeBlock, WTFMove(liveness));
1113     return result;
1114 }
1115 
1116 FullBytecodeLiveness&amp; Graph::livenessFor(InlineCallFrame* inlineCallFrame)
1117 {
1118     return livenessFor(baselineCodeBlockFor(inlineCallFrame));
1119 }
1120 
1121 BytecodeKills&amp; Graph::killsFor(CodeBlock* codeBlock)
1122 {
1123     HashMap&lt;CodeBlock*, std::unique_ptr&lt;BytecodeKills&gt;&gt;::iterator iter = m_bytecodeKills.find(codeBlock);
1124     if (iter != m_bytecodeKills.end())
1125         return *iter-&gt;value;
1126 
1127     std::unique_ptr&lt;BytecodeKills&gt; kills = makeUnique&lt;BytecodeKills&gt;();
1128     codeBlock-&gt;livenessAnalysis().computeKills(codeBlock, *kills);
1129     BytecodeKills&amp; result = *kills;
1130     m_bytecodeKills.add(codeBlock, WTFMove(kills));
1131     return result;
1132 }
1133 
1134 BytecodeKills&amp; Graph::killsFor(InlineCallFrame* inlineCallFrame)
1135 {
1136     return killsFor(baselineCodeBlockFor(inlineCallFrame));
1137 }
1138 
1139 bool Graph::isLiveInBytecode(Operand operand, CodeOrigin codeOrigin)
1140 {
1141     static constexpr bool verbose = false;
1142 
1143     if (verbose)
1144         dataLog(&quot;Checking of operand is live: &quot;, operand, &quot;\n&quot;);
1145     bool isCallerOrigin = false;
1146 
1147     CodeOrigin* codeOriginPtr = &amp;codeOrigin;
1148     auto* inlineCallFrame = codeOriginPtr-&gt;inlineCallFrame();
1149     // We need to handle tail callers because we may decide to exit to the
1150     // the return bytecode following the tail call.
1151     for (; codeOriginPtr; codeOriginPtr = inlineCallFrame ? &amp;inlineCallFrame-&gt;directCaller : nullptr) {
1152         inlineCallFrame = codeOriginPtr-&gt;inlineCallFrame();
1153         if (operand.isTmp()) {
1154             unsigned tmpOffset = inlineCallFrame ? inlineCallFrame-&gt;tmpOffset : 0;
1155             unsigned operandIndex = static_cast&lt;unsigned&gt;(operand.value());
1156 
1157             ASSERT(operand.value() &gt;= 0);
1158             // This tmp should have belonged to someone we inlined.
1159             if (operandIndex &gt; tmpOffset + maxNumCheckpointTmps)
1160                 return false;
1161 
1162             CodeBlock* codeBlock = baselineCodeBlockFor(inlineCallFrame);
1163             if (!codeBlock-&gt;numTmps() || operandIndex &lt; tmpOffset)
1164                 continue;
1165 
1166             auto bitMap = tmpLivenessForCheckpoint(*codeBlock, codeOriginPtr-&gt;bytecodeIndex());
1167             return bitMap.get(operandIndex - tmpOffset);
1168         }
1169 
1170         VirtualRegister reg = operand.virtualRegister() - codeOriginPtr-&gt;stackOffset();
1171 
1172         if (verbose)
1173             dataLog(&quot;reg = &quot;, reg, &quot;\n&quot;);
1174 
1175         if (operand.virtualRegister().offset() &lt; codeOriginPtr-&gt;stackOffset() + CallFrame::headerSizeInRegisters) {
1176             if (reg.isArgument()) {
1177                 RELEASE_ASSERT(reg.offset() &lt; CallFrame::headerSizeInRegisters);
1178 
1179 
1180                 if (inlineCallFrame-&gt;isClosureCall
1181                     &amp;&amp; reg == CallFrameSlot::callee) {
1182                     if (verbose)
1183                         dataLog(&quot;Looks like a callee.\n&quot;);
1184                     return true;
1185                 }
1186 
1187                 if (inlineCallFrame-&gt;isVarargs()
1188                     &amp;&amp; reg == CallFrameSlot::argumentCountIncludingThis) {
1189                     if (verbose)
1190                         dataLog(&quot;Looks like the argument count.\n&quot;);
1191                     return true;
1192                 }
1193 
1194                 return false;
1195             }
1196 
1197             if (verbose)
1198                 dataLog(&quot;Asking the bytecode liveness.\n&quot;);
1199             CodeBlock* codeBlock = baselineCodeBlockFor(inlineCallFrame);
1200             FullBytecodeLiveness&amp; fullLiveness = livenessFor(codeBlock);
1201             BytecodeIndex bytecodeIndex = codeOriginPtr-&gt;bytecodeIndex();
1202             return fullLiveness.virtualRegisterIsLive(reg, bytecodeIndex, appropriateLivenessCalculationPoint(*codeOriginPtr, isCallerOrigin));
1203         }
1204 
1205         // Arguments are always live. This would be redundant if it wasn&#39;t for our
1206         // op_call_varargs inlining.
1207         if (inlineCallFrame &amp;&amp; reg.isArgument()
1208             &amp;&amp; static_cast&lt;size_t&gt;(reg.toArgument()) &lt; inlineCallFrame-&gt;argumentsWithFixup.size()) {
1209             if (verbose)
1210                 dataLog(&quot;Argument is live.\n&quot;);
1211             return true;
1212         }
1213 
1214         isCallerOrigin = true;
1215     }
1216 
1217     if (operand.isTmp())
1218         return false;
1219 
1220     if (verbose)
1221         dataLog(&quot;Ran out of stack, returning true.\n&quot;);
1222     return true;
1223 }
1224 
1225 BitVector Graph::localsAndTmpsLiveInBytecode(CodeOrigin codeOrigin)
1226 {
1227     BitVector result;
1228     unsigned numLocals = block(0)-&gt;variablesAtHead.numberOfLocals();
1229     result.ensureSize(numLocals + block(0)-&gt;variablesAtHead.numberOfTmps());
1230     forAllLocalsAndTmpsLiveInBytecode(
1231         codeOrigin,
1232         [&amp;] (Operand operand) {
1233             unsigned offset = operand.isTmp() ? numLocals + operand.value() : operand.toLocal();
1234             result.quickSet(offset);
1235         });
1236     return result;
1237 }
1238 
1239 unsigned Graph::parameterSlotsForArgCount(unsigned argCount)
1240 {
1241     size_t frameSize = CallFrame::headerSizeInRegisters + argCount;
1242     size_t alignedFrameSize = WTF::roundUpToMultipleOf(stackAlignmentRegisters(), frameSize);
1243     return alignedFrameSize - CallerFrameAndPC::sizeInRegisters;
1244 }
1245 
1246 unsigned Graph::frameRegisterCount()
1247 {
1248     unsigned result = m_nextMachineLocal + std::max(m_parameterSlots, static_cast&lt;unsigned&gt;(maxFrameExtentForSlowPathCallInRegisters));
1249     return roundLocalRegisterCountForFramePointerOffset(result);
1250 }
1251 
1252 unsigned Graph::stackPointerOffset()
1253 {
1254     return virtualRegisterForLocal(frameRegisterCount() - 1).offset();
1255 }
1256 
1257 unsigned Graph::requiredRegisterCountForExit()
1258 {
1259     unsigned count = JIT::frameRegisterCountFor(m_profiledBlock);
1260     for (InlineCallFrameSet::iterator iter = m_plan.inlineCallFrames()-&gt;begin(); !!iter; ++iter) {
1261         InlineCallFrame* inlineCallFrame = *iter;
1262         CodeBlock* codeBlock = baselineCodeBlockForInlineCallFrame(inlineCallFrame);
1263         unsigned requiredCount = VirtualRegister(inlineCallFrame-&gt;stackOffset).toLocal() + 1 + JIT::frameRegisterCountFor(codeBlock);
1264         count = std::max(count, requiredCount);
1265     }
1266     return count;
1267 }
1268 
1269 unsigned Graph::requiredRegisterCountForExecutionAndExit()
1270 {
1271     // FIXME: We should make sure that frameRegisterCount() and requiredRegisterCountForExit()
1272     // never overflows. https://bugs.webkit.org/show_bug.cgi?id=173852
1273     return std::max(frameRegisterCount(), requiredRegisterCountForExit());
1274 }
1275 
1276 JSValue Graph::tryGetConstantProperty(
1277     JSValue base, const RegisteredStructureSet&amp; structureSet, PropertyOffset offset)
1278 {
1279     if (!base || !base.isObject())
1280         return JSValue();
1281 
1282     JSObject* object = asObject(base);
1283 
1284     for (unsigned i = structureSet.size(); i--;) {
1285         RegisteredStructure structure = structureSet[i];
1286 
1287         WatchpointSet* set = structure-&gt;propertyReplacementWatchpointSet(offset);
1288         if (!set || !set-&gt;isStillValid())
1289             return JSValue();
1290 
1291         ASSERT(structure-&gt;isValidOffset(offset));
1292         ASSERT(!structure-&gt;isUncacheableDictionary());
1293 
1294         watchpoints().addLazily(set);
1295     }
1296 
1297     // What follows may require some extra thought. We need this load to load a valid JSValue. If
1298     // our profiling makes sense and we&#39;re still on track to generate code that won&#39;t be
1299     // invalidated, then we have nothing to worry about. We do, however, have to worry about
1300     // loading - and then using - an invalid JSValue in the case that unbeknownst to us our code
1301     // is doomed.
1302     //
1303     // One argument in favor of this code is that it should definitely work because the butterfly
1304     // is always set before the structure. However, we don&#39;t currently have a fence between those
1305     // stores. It&#39;s not clear if this matters, however. We only shrink the propertyStorage while
1306     // holding the Structure&#39;s lock. So, for this to fail, you&#39;d need an access on a constant
1307     // object pointer such that the inline caches told us that the object had a structure that it
1308     // did not *yet* have, and then later,the object transitioned to that structure that the inline
1309     // caches had already seen. And then the processor reordered the stores. Seems unlikely and
1310     // difficult to test. I believe that this is worth revisiting but it isn&#39;t worth losing sleep
1311     // over. Filed:
1312     // https://bugs.webkit.org/show_bug.cgi?id=134641
1313     //
1314     // For now, we just do the minimal thing: defend against the structure right now being
1315     // incompatible with the getDirect we&#39;re trying to do. The easiest way to do that is to
1316     // determine if the structure belongs to the proven set.
1317 
1318     Structure* structure = object-&gt;structure(m_vm);
1319     if (!structureSet.toStructureSet().contains(structure))
1320         return JSValue();
1321 
1322     return object-&gt;getDirectConcurrently(structure, offset);
1323 }
1324 
1325 JSValue Graph::tryGetConstantProperty(JSValue base, Structure* structure, PropertyOffset offset)
1326 {
1327     return tryGetConstantProperty(base, RegisteredStructureSet(registerStructure(structure)), offset);
1328 }
1329 
1330 JSValue Graph::tryGetConstantProperty(
1331     JSValue base, const StructureAbstractValue&amp; structure, PropertyOffset offset)
1332 {
1333     if (structure.isInfinite()) {
1334         // FIXME: If we just converted the offset to a uid, we could do ObjectPropertyCondition
1335         // watching to constant-fold the property.
1336         // https://bugs.webkit.org/show_bug.cgi?id=147271
1337         return JSValue();
1338     }
1339 
1340     return tryGetConstantProperty(base, structure.set(), offset);
1341 }
1342 
1343 JSValue Graph::tryGetConstantProperty(const AbstractValue&amp; base, PropertyOffset offset)
1344 {
1345     return tryGetConstantProperty(base.m_value, base.m_structure, offset);
1346 }
1347 
1348 AbstractValue Graph::inferredValueForProperty(
1349     const AbstractValue&amp; base, PropertyOffset offset,
1350     StructureClobberState clobberState)
1351 {
1352     if (JSValue value = tryGetConstantProperty(base, offset)) {
1353         AbstractValue result;
1354         result.set(*this, *freeze(value), clobberState);
1355         return result;
1356     }
1357 
1358     return AbstractValue::heapTop();
1359 }
1360 
1361 JSValue Graph::tryGetConstantClosureVar(JSValue base, ScopeOffset offset)
1362 {
1363     // This has an awesome concurrency story. See comment for GetGlobalVar in ByteCodeParser.
1364 
1365     if (!base)
1366         return JSValue();
1367 
1368     JSLexicalEnvironment* activation = jsDynamicCast&lt;JSLexicalEnvironment*&gt;(m_vm, base);
1369     if (!activation)
1370         return JSValue();
1371 
1372     SymbolTable* symbolTable = activation-&gt;symbolTable();
1373     JSValue value;
1374     WatchpointSet* set;
1375     {
1376         ConcurrentJSLocker locker(symbolTable-&gt;m_lock);
1377 
1378         SymbolTableEntry* entry = symbolTable-&gt;entryFor(locker, offset);
1379         if (!entry)
1380             return JSValue();
1381 
1382         set = entry-&gt;watchpointSet();
1383         if (!set)
1384             return JSValue();
1385 
1386         if (set-&gt;state() != IsWatched)
1387             return JSValue();
1388 
1389         ASSERT(entry-&gt;scopeOffset() == offset);
1390         value = activation-&gt;variableAt(offset).get();
1391         if (!value)
1392             return JSValue();
1393     }
1394 
1395     watchpoints().addLazily(set);
1396 
1397     return value;
1398 }
1399 
1400 JSValue Graph::tryGetConstantClosureVar(const AbstractValue&amp; value, ScopeOffset offset)
1401 {
1402     return tryGetConstantClosureVar(value.m_value, offset);
1403 }
1404 
1405 JSValue Graph::tryGetConstantClosureVar(Node* node, ScopeOffset offset)
1406 {
1407     if (!node-&gt;hasConstant())
1408         return JSValue();
1409     return tryGetConstantClosureVar(node-&gt;asJSValue(), offset);
1410 }
1411 
1412 JSArrayBufferView* Graph::tryGetFoldableView(JSValue value)
1413 {
1414     if (!value)
1415         return nullptr;
1416     JSArrayBufferView* view = jsDynamicCast&lt;JSArrayBufferView*&gt;(m_vm, value);
1417     if (!view)
1418         return nullptr;
1419     if (!view-&gt;length())
1420         return nullptr;
1421     WTF::loadLoadFence();
1422     freeze(view);
1423     watchpoints().addLazily(view);
1424     return view;
1425 }
1426 
1427 JSArrayBufferView* Graph::tryGetFoldableView(JSValue value, ArrayMode arrayMode)
1428 {
1429     if (arrayMode.type() != Array::AnyTypedArray &amp;&amp; arrayMode.typedArrayType() == NotTypedArray)
1430         return nullptr;
1431     return tryGetFoldableView(value);
1432 }
1433 
1434 void Graph::registerFrozenValues()
1435 {
1436     ConcurrentJSLocker locker(m_codeBlock-&gt;m_lock);
1437     m_codeBlock-&gt;constants().shrink(0);
1438     m_codeBlock-&gt;constantsSourceCodeRepresentation().resize(0);
1439     for (FrozenValue* value : m_frozenValues) {
1440         if (!value-&gt;pointsToHeap())
1441             continue;
1442 
1443         ASSERT(value-&gt;structure());
1444         ASSERT(m_plan.weakReferences().contains(value-&gt;structure()));
1445 
1446         switch (value-&gt;strength()) {
1447         case WeakValue: {
1448             m_plan.weakReferences().addLazily(value-&gt;value().asCell());
1449             break;
1450         }
1451         case StrongValue: {
1452             unsigned constantIndex = m_codeBlock-&gt;addConstantLazily(locker);
1453             // We already have a barrier on the code block.
1454             m_codeBlock-&gt;constants()[constantIndex].setWithoutWriteBarrier(value-&gt;value());
1455             break;
1456         } }
1457     }
1458     m_codeBlock-&gt;constants().shrinkToFit();
1459     m_codeBlock-&gt;constantsSourceCodeRepresentation().shrinkToFit();
1460 }
1461 
1462 void Graph::visitChildren(SlotVisitor&amp; visitor)
1463 {
1464     for (FrozenValue* value : m_frozenValues) {
1465         visitor.appendUnbarriered(value-&gt;value());
1466         visitor.appendUnbarriered(value-&gt;structure());
1467     }
1468 }
1469 
1470 FrozenValue* Graph::freeze(JSValue value)
1471 {
1472     if (UNLIKELY(!value))
1473         return FrozenValue::emptySingleton();
1474 
1475     // There are weird relationships in how optimized CodeBlocks
1476     // point to other CodeBlocks. We don&#39;t want to have them be
1477     // part of the weak pointer set. For example, an optimized CodeBlock
1478     // having a weak pointer to itself will cause it to get collected.
1479     RELEASE_ASSERT(!jsDynamicCast&lt;CodeBlock*&gt;(m_vm, value));
1480 
1481     auto result = m_frozenValueMap.add(JSValue::encode(value), nullptr);
1482     if (LIKELY(!result.isNewEntry))
1483         return result.iterator-&gt;value;
1484 
1485     if (value.isUInt32())
1486         m_uint32ValuesInUse.append(value.asUInt32());
1487 
1488     FrozenValue frozenValue = FrozenValue::freeze(value);
1489     if (Structure* structure = frozenValue.structure())
1490         registerStructure(structure);
1491 
1492     return result.iterator-&gt;value = m_frozenValues.add(frozenValue);
1493 }
1494 
1495 FrozenValue* Graph::freezeStrong(JSValue value)
1496 {
1497     FrozenValue* result = freeze(value);
1498     result-&gt;strengthenTo(StrongValue);
1499     return result;
1500 }
1501 
1502 void Graph::convertToConstant(Node* node, FrozenValue* value)
1503 {
1504     if (value-&gt;structure())
1505         assertIsRegistered(value-&gt;structure());
1506     node-&gt;convertToConstant(value);
1507 }
1508 
1509 void Graph::convertToConstant(Node* node, JSValue value)
1510 {
1511     convertToConstant(node, freeze(value));
1512 }
1513 
1514 void Graph::convertToStrongConstant(Node* node, JSValue value)
1515 {
1516     convertToConstant(node, freezeStrong(value));
1517 }
1518 
1519 RegisteredStructure Graph::registerStructure(Structure* structure, StructureRegistrationResult&amp; result)
1520 {
1521     m_plan.weakReferences().addLazily(structure);
1522     if (m_plan.watchpoints().consider(structure))
1523         result = StructureRegisteredAndWatched;
1524     else
1525         result = StructureRegisteredNormally;
1526     return RegisteredStructure::createPrivate(structure);
1527 }
1528 
1529 void Graph::registerAndWatchStructureTransition(Structure* structure)
1530 {
1531     m_plan.weakReferences().addLazily(structure);
1532     m_plan.watchpoints().addLazily(structure-&gt;transitionWatchpointSet());
1533 }
1534 
1535 void Graph::assertIsRegistered(Structure* structure)
1536 {
1537     // It&#39;s convenient to be able to call this with a maybe-null structure.
1538     if (!structure)
1539         return;
1540 
1541     DFG_ASSERT(*this, nullptr, m_plan.weakReferences().contains(structure));
1542 
1543     if (!structure-&gt;dfgShouldWatch())
1544         return;
1545     if (watchpoints().isWatched(structure-&gt;transitionWatchpointSet()))
1546         return;
1547 
1548     DFG_CRASH(*this, nullptr, toCString(&quot;Structure &quot;, pointerDump(structure), &quot; is watchable but isn&#39;t being watched.&quot;).data());
1549 }
1550 
1551 static void logDFGAssertionFailure(
1552     Graph&amp; graph, const CString&amp; whileText, const char* file, int line, const char* function,
1553     const char* assertion)
1554 {
1555     startCrashing();
1556     dataLog(&quot;DFG ASSERTION FAILED: &quot;, assertion, &quot;\n&quot;);
1557     dataLog(file, &quot;(&quot;, line, &quot;) : &quot;, function, &quot;\n&quot;);
1558     dataLog(&quot;\n&quot;);
1559     dataLog(whileText);
1560     dataLog(&quot;Graph at time of failure:\n&quot;);
1561     graph.dump();
1562     dataLog(&quot;\n&quot;);
1563     dataLog(&quot;DFG ASSERTION FAILED: &quot;, assertion, &quot;\n&quot;);
1564     dataLog(file, &quot;(&quot;, line, &quot;) : &quot;, function, &quot;\n&quot;);
1565 }
1566 
1567 void Graph::logAssertionFailure(
1568     std::nullptr_t, const char* file, int line, const char* function, const char* assertion)
1569 {
1570     logDFGAssertionFailure(*this, &quot;&quot;, file, line, function, assertion);
1571 }
1572 
1573 void Graph::logAssertionFailure(
1574     Node* node, const char* file, int line, const char* function, const char* assertion)
1575 {
1576     logDFGAssertionFailure(*this, toCString(&quot;While handling node &quot;, node, &quot;\n\n&quot;), file, line, function, assertion);
1577 }
1578 
1579 void Graph::logAssertionFailure(
1580     BasicBlock* block, const char* file, int line, const char* function, const char* assertion)
1581 {
1582     logDFGAssertionFailure(*this, toCString(&quot;While handling block &quot;, pointerDump(block), &quot;\n\n&quot;), file, line, function, assertion);
1583 }
1584 
1585 CPSCFG&amp; Graph::ensureCPSCFG()
1586 {
1587     RELEASE_ASSERT(m_form != SSA &amp;&amp; !m_isInSSAConversion);
1588     if (!m_cpsCFG)
1589         m_cpsCFG = makeUnique&lt;CPSCFG&gt;(*this);
1590     return *m_cpsCFG;
1591 }
1592 
1593 CPSDominators&amp; Graph::ensureCPSDominators()
1594 {
1595     RELEASE_ASSERT(m_form != SSA &amp;&amp; !m_isInSSAConversion);
1596     if (!m_cpsDominators)
1597         m_cpsDominators = makeUnique&lt;CPSDominators&gt;(*this);
1598     return *m_cpsDominators;
1599 }
1600 
1601 SSADominators&amp; Graph::ensureSSADominators()
1602 {
1603     RELEASE_ASSERT(m_form == SSA || m_isInSSAConversion);
1604     if (!m_ssaDominators)
1605         m_ssaDominators = makeUnique&lt;SSADominators&gt;(*this);
1606     return *m_ssaDominators;
1607 }
1608 
1609 CPSNaturalLoops&amp; Graph::ensureCPSNaturalLoops()
1610 {
1611     RELEASE_ASSERT(m_form != SSA &amp;&amp; !m_isInSSAConversion);
1612     ensureCPSDominators();
1613     if (!m_cpsNaturalLoops)
1614         m_cpsNaturalLoops = makeUnique&lt;CPSNaturalLoops&gt;(*this);
1615     return *m_cpsNaturalLoops;
1616 }
1617 
1618 SSANaturalLoops&amp; Graph::ensureSSANaturalLoops()
1619 {
1620     RELEASE_ASSERT(m_form == SSA);
1621     ensureSSADominators();
1622     if (!m_ssaNaturalLoops)
1623         m_ssaNaturalLoops = makeUnique&lt;SSANaturalLoops&gt;(*this);
1624     return *m_ssaNaturalLoops;
1625 }
1626 
1627 BackwardsCFG&amp; Graph::ensureBackwardsCFG()
1628 {
1629     // We could easily relax this in the future to work over CPS, but today, it&#39;s only used in SSA.
1630     RELEASE_ASSERT(m_form == SSA);
1631     if (!m_backwardsCFG)
1632         m_backwardsCFG = makeUnique&lt;BackwardsCFG&gt;(*this);
1633     return *m_backwardsCFG;
1634 }
1635 
1636 BackwardsDominators&amp; Graph::ensureBackwardsDominators()
1637 {
1638     RELEASE_ASSERT(m_form == SSA);
1639     if (!m_backwardsDominators)
1640         m_backwardsDominators = makeUnique&lt;BackwardsDominators&gt;(*this);
1641     return *m_backwardsDominators;
1642 }
1643 
1644 ControlEquivalenceAnalysis&amp; Graph::ensureControlEquivalenceAnalysis()
1645 {
1646     RELEASE_ASSERT(m_form == SSA);
1647     if (!m_controlEquivalenceAnalysis)
1648         m_controlEquivalenceAnalysis = makeUnique&lt;ControlEquivalenceAnalysis&gt;(*this);
1649     return *m_controlEquivalenceAnalysis;
1650 }
1651 
1652 MethodOfGettingAValueProfile Graph::methodOfGettingAValueProfileFor(Node* currentNode, Node* operandNode)
1653 {
1654     // This represents IR like `CurrentNode(@operandNode)`. For example: `GetByVal(..., Int32:@GetLocal)`.
1655 
1656     for (Node* node = operandNode; node;) {
1657         if (node-&gt;accessesStack(*this)) {
1658             if (m_form != SSA &amp;&amp; node-&gt;operand().isArgument()) {
1659                 int argument = node-&gt;operand().toArgument();
1660                 Node* argumentNode = m_rootToArguments.find(block(0))-&gt;value[argument];
1661                 // FIXME: We should match SetArgumentDefinitely nodes at other entrypoints as well:
1662                 // https://bugs.webkit.org/show_bug.cgi?id=175841
1663                 if (argumentNode &amp;&amp; node-&gt;variableAccessData() == argumentNode-&gt;variableAccessData()) {
1664                     CodeBlock* profiledBlock = baselineCodeBlockFor(node-&gt;origin.semantic);
1665                     return &amp;profiledBlock-&gt;valueProfileForArgument(argument);
1666                 }
1667             }
1668         }
1669 
1670         // currentNode is null when we&#39;re doing speculation checks for checkArgumentTypes().
1671         if (!currentNode || node-&gt;origin.semantic != currentNode-&gt;origin.semantic || !currentNode-&gt;hasResult()) {
1672             CodeBlock* profiledBlock = baselineCodeBlockFor(node-&gt;origin.semantic);
1673 
1674             if (node-&gt;accessesStack(*this)) {
1675                 if (node-&gt;op() == GetLocal) {
1676                     return MethodOfGettingAValueProfile::fromLazyOperand(
1677                         profiledBlock,
1678                         LazyOperandValueProfileKey(
1679                             node-&gt;origin.semantic.bytecodeIndex(), node-&gt;operand()));
1680                 }
1681             }
1682 
1683             if (node-&gt;hasHeapPrediction())
1684                 return &amp;profiledBlock-&gt;valueProfileForBytecodeIndex(node-&gt;origin.semantic.bytecodeIndex());
1685 
1686             if (profiledBlock-&gt;hasBaselineJITProfiling()) {
1687                 if (BinaryArithProfile* result = profiledBlock-&gt;binaryArithProfileForBytecodeIndex(node-&gt;origin.semantic.bytecodeIndex()))
1688                     return result;
1689                 if (UnaryArithProfile* result = profiledBlock-&gt;unaryArithProfileForBytecodeIndex(node-&gt;origin.semantic.bytecodeIndex()))
1690                     return result;
1691             }
1692         }
1693 
1694         switch (node-&gt;op()) {
1695         case BooleanToNumber:
1696         case Identity:
1697         case ValueRep:
1698         case DoubleRep:
1699         case Int52Rep:
1700             node = node-&gt;child1().node();
1701             break;
1702         default:
1703             node = nullptr;
1704         }
1705     }
1706 
1707     return MethodOfGettingAValueProfile();
1708 }
1709 
1710 bool Graph::getRegExpPrototypeProperty(JSObject* regExpPrototype, Structure* regExpPrototypeStructure, UniquedStringImpl* uid, JSValue&amp; returnJSValue)
1711 {
1712     unsigned attributesUnused;
1713     PropertyOffset offset = regExpPrototypeStructure-&gt;getConcurrently(uid, attributesUnused);
1714     if (!isValidOffset(offset))
1715         return false;
1716 
1717     JSValue value = tryGetConstantProperty(regExpPrototype, regExpPrototypeStructure, offset);
1718     if (!value)
1719         return false;
1720 
1721     // We only care about functions and getters at this point. If you want to access other properties
1722     // you&#39;ll have to add code for those types.
1723     JSFunction* function = jsDynamicCast&lt;JSFunction*&gt;(m_vm, value);
1724     if (!function) {
1725         GetterSetter* getterSetter = jsDynamicCast&lt;GetterSetter*&gt;(m_vm, value);
1726 
1727         if (!getterSetter)
1728             return false;
1729 
1730         returnJSValue = JSValue(getterSetter);
1731         return true;
1732     }
1733 
1734     returnJSValue = value;
1735     return true;
1736 }
1737 
1738 bool Graph::isStringPrototypeMethodSane(JSGlobalObject* globalObject, UniquedStringImpl* uid)
1739 {
1740     ObjectPropertyConditionSet conditions = generateConditionsForPrototypeEquivalenceConcurrently(m_vm, globalObject, globalObject-&gt;stringObjectStructure(), globalObject-&gt;stringPrototype(), uid);
1741 
1742     if (!conditions.isValid())
1743         return false;
1744 
1745     ObjectPropertyCondition equivalenceCondition = conditions.slotBaseCondition();
1746     RELEASE_ASSERT(equivalenceCondition.hasRequiredValue());
1747     JSFunction* function = jsDynamicCast&lt;JSFunction*&gt;(m_vm, equivalenceCondition.condition().requiredValue());
1748     if (!function)
1749         return false;
1750 
1751     if (function-&gt;executable()-&gt;intrinsicFor(CodeForCall) != StringPrototypeValueOfIntrinsic)
1752         return false;
1753 
1754     return watchConditions(conditions);
1755 }
1756 
1757 
1758 bool Graph::canOptimizeStringObjectAccess(const CodeOrigin&amp; codeOrigin)
1759 {
1760     if (hasExitSite(codeOrigin, BadCache) || hasExitSite(codeOrigin, BadConstantCache))
1761         return false;
1762 
1763     JSGlobalObject* globalObject = globalObjectFor(codeOrigin);
1764     Structure* stringObjectStructure = globalObjectFor(codeOrigin)-&gt;stringObjectStructure();
1765     registerStructure(stringObjectStructure);
1766     ASSERT(stringObjectStructure-&gt;storedPrototype().isObject());
1767     ASSERT(stringObjectStructure-&gt;storedPrototype().asCell()-&gt;classInfo(stringObjectStructure-&gt;storedPrototype().asCell()-&gt;vm()) == StringPrototype::info());
1768 
1769     if (!watchConditions(generateConditionsForPropertyMissConcurrently(m_vm, globalObject, stringObjectStructure, m_vm.propertyNames-&gt;toPrimitiveSymbol.impl())))
1770         return false;
1771 
1772     // We&#39;re being conservative here. We want DFG&#39;s ToString on StringObject to be
1773     // used in both numeric contexts (that would call valueOf()) and string contexts
1774     // (that would call toString()). We don&#39;t want the DFG to have to distinguish
1775     // between the two, just because that seems like it would get confusing. So we
1776     // just require both methods to be sane.
1777     if (!isStringPrototypeMethodSane(globalObject, m_vm.propertyNames-&gt;valueOf.impl()))
1778         return false;
1779     return isStringPrototypeMethodSane(globalObject, m_vm.propertyNames-&gt;toString.impl());
1780 }
1781 
1782 bool Graph::willCatchExceptionInMachineFrame(CodeOrigin codeOrigin, CodeOrigin&amp; opCatchOriginOut, HandlerInfo*&amp; catchHandlerOut)
1783 {
1784     if (!m_hasExceptionHandlers)
1785         return false;
1786 
1787     BytecodeIndex bytecodeIndexToCheck = codeOrigin.bytecodeIndex();
1788     while (1) {
1789         InlineCallFrame* inlineCallFrame = codeOrigin.inlineCallFrame();
1790         CodeBlock* codeBlock = baselineCodeBlockFor(inlineCallFrame);
1791         if (HandlerInfo* handler = codeBlock-&gt;handlerForBytecodeIndex(bytecodeIndexToCheck)) {
1792             opCatchOriginOut = CodeOrigin(BytecodeIndex(handler-&gt;target), inlineCallFrame);
1793             catchHandlerOut = handler;
1794             return true;
1795         }
1796 
1797         if (!inlineCallFrame)
1798             return false;
1799 
1800         bytecodeIndexToCheck = inlineCallFrame-&gt;directCaller.bytecodeIndex();
1801         codeOrigin = inlineCallFrame-&gt;directCaller;
1802     }
1803 
1804     RELEASE_ASSERT_NOT_REACHED();
1805 }
1806 
1807 bool Graph::canDoFastSpread(Node* node, const AbstractValue&amp; value)
1808 {
1809     // The parameter &#39;value&#39; is the AbstractValue for child1 (the thing being spread).
1810     ASSERT(node-&gt;op() == Spread);
1811 
1812     if (node-&gt;child1().useKind() != ArrayUse) {
1813         // Note: we only speculate on ArrayUse when we&#39;ve set up the necessary watchpoints
1814         // to prove that the iteration protocol is non-observable starting from ArrayPrototype.
1815         return false;
1816     }
1817 
1818     // FIXME: We should add profiling of the incoming operand to Spread
1819     // so we can speculate in such a way that we guarantee that this
1820     // function would return true:
1821     // https://bugs.webkit.org/show_bug.cgi?id=171198
1822 
1823     if (!value.m_structure.isFinite())
1824         return false;
1825 
1826     ArrayPrototype* arrayPrototype = globalObjectFor(node-&gt;child1()-&gt;origin.semantic)-&gt;arrayPrototype();
1827     bool allGood = true;
1828     value.m_structure.forEach([&amp;] (RegisteredStructure structure) {
1829         allGood &amp;= structure-&gt;hasMonoProto()
1830             &amp;&amp; structure-&gt;storedPrototype() == arrayPrototype
1831             &amp;&amp; !structure-&gt;isDictionary()
1832             &amp;&amp; structure-&gt;getConcurrently(m_vm.propertyNames-&gt;iteratorSymbol.impl()) == invalidOffset
1833             &amp;&amp; !structure-&gt;mayInterceptIndexedAccesses();
1834     });
1835 
1836     return allGood;
1837 }
1838 
1839 void Graph::clearCPSCFGData()
1840 {
1841     m_cpsNaturalLoops = nullptr;
1842     m_cpsDominators = nullptr;
1843     m_cpsCFG = nullptr;
1844 }
1845 
1846 void Prefix::dump(PrintStream&amp; out) const
1847 {
1848     if (!m_enabled)
1849         return;
1850 
1851     if (!noHeader) {
1852         if (nodeIndex &gt;= 0)
1853             out.printf(&quot;%3d &quot;, nodeIndex);
1854         else
1855             out.printf(&quot;    &quot;);
1856 
1857         if (blockIndex &gt;= 0)
1858             out.printf(&quot;%2d &quot;, blockIndex);
1859         else
1860             out.printf(&quot;   &quot;);
1861 
1862         if (phaseNumber &gt;= 0)
1863             out.printf(&quot;%2d: &quot;, phaseNumber);
1864         else
1865             out.printf(&quot;  : &quot;);
1866     }
1867     if (prefixStr)
1868         out.printf(&quot;%s&quot;, prefixStr);
1869 }
1870 
1871 } } // namespace JSC::DFG
1872 
1873 #endif // ENABLE(DFG_JIT)
    </pre>
  </body>
</html>