<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JITOpcodes32_64.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="JITOpcodes.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="JITOperations.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JITOpcodes32_64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  33 #include &quot;BytecodeStructs.h&quot;
  34 #include &quot;CCallHelpers.h&quot;
  35 #include &quot;Exception.h&quot;
  36 #include &quot;JITInlines.h&quot;
  37 #include &quot;JSArray.h&quot;
  38 #include &quot;JSCast.h&quot;
  39 #include &quot;JSFunction.h&quot;
  40 #include &quot;JSPropertyNameEnumerator.h&quot;
  41 #include &quot;LinkBuffer.h&quot;
  42 #include &quot;MaxFrameExtentForSlowPathCall.h&quot;
  43 #include &quot;OpcodeInlines.h&quot;
  44 #include &quot;SlowPathCall.h&quot;
  45 #include &quot;TypeProfilerLog.h&quot;
  46 #include &quot;VirtualRegister.h&quot;
  47 
  48 namespace JSC {
  49 
  50 void JIT::emit_op_mov(const Instruction* currentInstruction)
  51 {
  52     auto bytecode = currentInstruction-&gt;as&lt;OpMov&gt;();
<span class="line-modified">  53     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified">  54     int src = bytecode.m_src.offset();</span>
  55 
<span class="line-modified">  56     if (m_codeBlock-&gt;isConstantRegisterIndex(src))</span>
  57         emitStore(dst, getConstantOperand(src));
  58     else {
  59         emitLoad(src, regT1, regT0);
  60         emitStore(dst, regT1, regT0);
  61     }
  62 }
  63 
  64 void JIT::emit_op_end(const Instruction* currentInstruction)
  65 {
  66     ASSERT(returnValueGPR != callFrameRegister);
  67     auto bytecode = currentInstruction-&gt;as&lt;OpEnd&gt;();
<span class="line-modified">  68     emitLoad(bytecode.m_value.offset(), regT1, returnValueGPR);</span>
  69     emitRestoreCalleeSaves();
  70     emitFunctionEpilogue();
  71     ret();
  72 }
  73 
  74 void JIT::emit_op_jmp(const Instruction* currentInstruction)
  75 {
  76     auto bytecode = currentInstruction-&gt;as&lt;OpJmp&gt;();
  77     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
  78     addJump(jump(), target);
  79 }
  80 
  81 void JIT::emit_op_new_object(const Instruction* currentInstruction)
  82 {
  83     auto bytecode = currentInstruction-&gt;as&lt;OpNewObject&gt;();
  84     auto&amp; metadata = bytecode.metadata(m_codeBlock);
  85     Structure* structure = metadata.m_objectAllocationProfile.structure();
  86     size_t allocationSize = JSFinalObject::allocationSize(structure-&gt;inlineCapacity());
  87     Allocator allocator = allocatorForNonVirtualConcurrently&lt;JSFinalObject&gt;(*m_vm, allocationSize, AllocatorForMode::AllocatorIfExists);
  88 
  89     RegisterID resultReg = returnValueGPR;
  90     RegisterID allocatorReg = regT1;
  91     RegisterID scratchReg = regT3;
  92 
  93     if (!allocator)
  94         addSlowCase(jump());
  95     else {
  96         JumpList slowCases;
  97         auto butterfly = TrustedImmPtr(nullptr);
  98         emitAllocateJSObject(resultReg, JITAllocator::constant(allocator), allocatorReg, TrustedImmPtr(structure), butterfly, scratchReg, slowCases);
  99         emitInitializeInlineStorage(resultReg, structure-&gt;inlineCapacity());
 100         addSlowCase(slowCases);
<span class="line-modified"> 101         emitStoreCell(bytecode.m_dst.offset(), resultReg);</span>
 102     }
 103 }
 104 
 105 void JIT::emitSlow_op_new_object(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 106 {
 107     linkAllSlowCases(iter);
 108 
 109     auto bytecode = currentInstruction-&gt;as&lt;OpNewObject&gt;();
 110     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 111     int dst = bytecode.m_dst.offset();</span>
 112     Structure* structure = metadata.m_objectAllocationProfile.structure();
<span class="line-modified"> 113     callOperation(operationNewObject, structure);</span>
 114     emitStoreCell(dst, returnValueGPR);
 115 }
 116 
 117 void JIT::emit_op_overrides_has_instance(const Instruction* currentInstruction)
 118 {
 119     auto bytecode = currentInstruction-&gt;as&lt;OpOverridesHasInstance&gt;();
<span class="line-modified"> 120     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 121     int constructor = bytecode.m_constructor.offset();</span>
<span class="line-modified"> 122     int hasInstanceValue = bytecode.m_hasInstanceValue.offset();</span>
 123 
 124     emitLoadPayload(hasInstanceValue, regT0);
 125     // We don&#39;t jump if we know what Symbol.hasInstance would do.
 126     Jump hasInstanceValueNotCell = emitJumpIfNotJSCell(hasInstanceValue);
 127     Jump customhasInstanceValue = branchPtr(NotEqual, regT0, TrustedImmPtr(m_codeBlock-&gt;globalObject()-&gt;functionProtoHasInstanceSymbolFunction()));
 128 
 129     // We know that constructor is an object from the way bytecode is emitted for instanceof expressions.
 130     emitLoadPayload(constructor, regT0);
 131 
 132     // Check that constructor &#39;ImplementsDefaultHasInstance&#39; i.e. the object is not a C-API user nor a bound function.
 133     test8(Zero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(ImplementsDefaultHasInstance), regT0);
 134     Jump done = jump();
 135 
 136     hasInstanceValueNotCell.link(this);
 137     customhasInstanceValue.link(this);
 138     move(TrustedImm32(1), regT0);
 139 
 140     done.link(this);
 141     emitStoreBool(dst, regT0);
 142 
 143 }
 144 
 145 void JIT::emit_op_instanceof(const Instruction* currentInstruction)
 146 {
 147     auto bytecode = currentInstruction-&gt;as&lt;OpInstanceof&gt;();
<span class="line-modified"> 148     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 149     int value = bytecode.m_value.offset();</span>
<span class="line-modified"> 150     int proto = bytecode.m_prototype.offset();</span>
 151 
 152     // Load the operands into registers.
 153     // We use regT0 for baseVal since we will be done with this first, and we can then use it for the result.
 154     emitLoadPayload(value, regT2);
 155     emitLoadPayload(proto, regT1);
 156 
 157     // Check that proto are cells. baseVal must be a cell - this is checked by the get_by_id for Symbol.hasInstance.
 158     emitJumpSlowCaseIfNotJSCell(value);
 159     emitJumpSlowCaseIfNotJSCell(proto);
 160 
 161     JITInstanceOfGenerator gen(
<span class="line-modified"> 162         m_codeBlock, CodeOrigin(m_bytecodeOffset), CallSiteIndex(m_bytecodeOffset),</span>
 163         RegisterSet::stubUnavailableRegisters(),
 164         regT0, // result
 165         regT2, // value
 166         regT1, // proto
 167         regT3, regT4); // scratch
 168     gen.generateFastPath(*this);
 169     m_instanceOfs.append(gen);
 170 
 171     emitStoreBool(dst, regT0);
 172 }
 173 
 174 void JIT::emit_op_instanceof_custom(const Instruction*)
 175 {
 176     // This always goes to slow path since we expect it to be rare.
 177     addSlowCase(jump());
 178 }
 179 
 180 void JIT::emitSlow_op_instanceof(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 181 {
 182     linkAllSlowCases(iter);
 183 
 184     auto bytecode = currentInstruction-&gt;as&lt;OpInstanceof&gt;();
<span class="line-modified"> 185     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 186     int value = bytecode.m_value.offset();</span>
<span class="line-modified"> 187     int proto = bytecode.m_prototype.offset();</span>
 188 
 189     JITInstanceOfGenerator&amp; gen = m_instanceOfs[m_instanceOfIndex++];
 190 
 191     Label coldPathBegin = label();
 192     emitLoadTag(value, regT0);
 193     emitLoadTag(proto, regT3);
<span class="line-modified"> 194     Call call = callOperation(operationInstanceOfOptimize, dst, gen.stubInfo(), JSValueRegs(regT0, regT2), JSValueRegs(regT3, regT1));</span>
 195     gen.reportSlowPathCall(coldPathBegin, call);
 196 }
 197 
 198 void JIT::emitSlow_op_instanceof_custom(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 199 {
 200     linkAllSlowCases(iter);
 201 
 202     auto bytecode = currentInstruction-&gt;as&lt;OpInstanceofCustom&gt;();
<span class="line-modified"> 203     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 204     int value = bytecode.m_value.offset();</span>
<span class="line-modified"> 205     int constructor = bytecode.m_constructor.offset();</span>
<span class="line-modified"> 206     int hasInstanceValue = bytecode.m_hasInstanceValue.offset();</span>
 207 
 208     emitLoad(value, regT1, regT0);
 209     emitLoadPayload(constructor, regT2);
 210     emitLoad(hasInstanceValue, regT4, regT3);
<span class="line-modified"> 211     callOperation(operationInstanceOfCustom, JSValueRegs(regT1, regT0), regT2, JSValueRegs(regT4, regT3));</span>
 212     emitStoreBool(dst, returnValueGPR);
 213 }
 214 
 215 void JIT::emit_op_is_empty(const Instruction* currentInstruction)
 216 {
 217     auto bytecode = currentInstruction-&gt;as&lt;OpIsEmpty&gt;();
<span class="line-modified"> 218     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 219     int value = bytecode.m_operand.offset();</span>
 220 
 221     emitLoad(value, regT1, regT0);
 222     compare32(Equal, regT1, TrustedImm32(JSValue::EmptyValueTag), regT0);
 223 
 224     emitStoreBool(dst, regT0);
 225 }
 226 
 227 void JIT::emit_op_is_undefined(const Instruction* currentInstruction)
 228 {
 229     auto bytecode = currentInstruction-&gt;as&lt;OpIsUndefined&gt;();
<span class="line-modified"> 230     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 231     int value = bytecode.m_operand.offset();</span>
 232 
 233     emitLoad(value, regT1, regT0);
 234     Jump isCell = branchIfCell(regT1);
 235 
 236     compare32(Equal, regT1, TrustedImm32(JSValue::UndefinedTag), regT0);
 237     Jump done = jump();
 238 
 239     isCell.link(this);
 240     Jump isMasqueradesAsUndefined = branchTest8(NonZero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined));
 241     move(TrustedImm32(0), regT0);
 242     Jump notMasqueradesAsUndefined = jump();
 243 
 244     isMasqueradesAsUndefined.link(this);
 245     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT1);
 246     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 247     loadPtr(Address(regT1, Structure::globalObjectOffset()), regT1);
 248     compare32(Equal, regT0, regT1, regT0);
 249 
 250     notMasqueradesAsUndefined.link(this);
 251     done.link(this);
 252     emitStoreBool(dst, regT0);
 253 }
 254 
 255 void JIT::emit_op_is_undefined_or_null(const Instruction* currentInstruction)
 256 {
 257     auto bytecode = currentInstruction-&gt;as&lt;OpIsUndefinedOrNull&gt;();
<span class="line-modified"> 258     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 259     int value = bytecode.m_operand.offset();</span>
 260 
 261     emitLoadTag(value, regT0);
 262     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);
 263     or32(TrustedImm32(1), regT0);
 264     compare32(Equal, regT0, TrustedImm32(JSValue::NullTag), regT0);
 265     emitStoreBool(dst, regT0);
 266 }
 267 
 268 void JIT::emit_op_is_boolean(const Instruction* currentInstruction)
 269 {
 270     auto bytecode = currentInstruction-&gt;as&lt;OpIsBoolean&gt;();
<span class="line-modified"> 271     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 272     int value = bytecode.m_operand.offset();</span>
 273 
 274     emitLoadTag(value, regT0);
 275     compare32(Equal, regT0, TrustedImm32(JSValue::BooleanTag), regT0);
 276     emitStoreBool(dst, regT0);
 277 }
 278 
 279 void JIT::emit_op_is_number(const Instruction* currentInstruction)
 280 {
 281     auto bytecode = currentInstruction-&gt;as&lt;OpIsNumber&gt;();
<span class="line-modified"> 282     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 283     int value = bytecode.m_operand.offset();</span>
 284 
 285     emitLoadTag(value, regT0);
 286     add32(TrustedImm32(1), regT0);
 287     compare32(Below, regT0, TrustedImm32(JSValue::LowestTag + 1), regT0);
 288     emitStoreBool(dst, regT0);
 289 }
 290 
 291 void JIT::emit_op_is_cell_with_type(const Instruction* currentInstruction)
 292 {
 293     auto bytecode = currentInstruction-&gt;as&lt;OpIsCellWithType&gt;();
<span class="line-modified"> 294     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 295     int value = bytecode.m_operand.offset();</span>
 296     int type = bytecode.m_type;
 297 
 298     emitLoad(value, regT1, regT0);
 299     Jump isNotCell = branchIfNotCell(regT1);
 300 
 301     compare8(Equal, Address(regT0, JSCell::typeInfoTypeOffset()), TrustedImm32(type), regT0);
 302     Jump done = jump();
 303 
 304     isNotCell.link(this);
 305     move(TrustedImm32(0), regT0);
 306 
 307     done.link(this);
 308     emitStoreBool(dst, regT0);
 309 }
 310 
 311 void JIT::emit_op_is_object(const Instruction* currentInstruction)
 312 {
 313     auto bytecode = currentInstruction-&gt;as&lt;OpIsObject&gt;();
<span class="line-modified"> 314     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 315     int value = bytecode.m_operand.offset();</span>
 316 
 317     emitLoad(value, regT1, regT0);
 318     Jump isNotCell = branchIfNotCell(regT1);
 319 
 320     compare8(AboveOrEqual, Address(regT0, JSCell::typeInfoTypeOffset()), TrustedImm32(ObjectType), regT0);
 321     Jump done = jump();
 322 
 323     isNotCell.link(this);
 324     move(TrustedImm32(0), regT0);
 325 
 326     done.link(this);
 327     emitStoreBool(dst, regT0);
 328 }
 329 
 330 void JIT::emit_op_to_primitive(const Instruction* currentInstruction)
 331 {
 332     auto bytecode = currentInstruction-&gt;as&lt;OpToPrimitive&gt;();
<span class="line-modified"> 333     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 334     int src = bytecode.m_src.offset();</span>
 335 
 336     emitLoad(src, regT1, regT0);
 337 
 338     Jump isImm = branchIfNotCell(regT1);
 339     addSlowCase(branchIfObject(regT0));
 340     isImm.link(this);
 341 
 342     if (dst != src)
 343         emitStore(dst, regT1, regT0);
 344 }
 345 

















 346 void JIT::emit_op_set_function_name(const Instruction* currentInstruction)
 347 {
 348     auto bytecode = currentInstruction-&gt;as&lt;OpSetFunctionName&gt;();
<span class="line-modified"> 349     int func = bytecode.m_function.offset();</span>
<span class="line-modified"> 350     int name = bytecode.m_name.offset();</span>
 351     emitLoadPayload(func, regT1);
 352     emitLoad(name, regT3, regT2);
<span class="line-modified"> 353     callOperation(operationSetFunctionName, regT1, JSValueRegs(regT3, regT2));</span>
 354 }
 355 
 356 void JIT::emit_op_not(const Instruction* currentInstruction)
 357 {
 358     auto bytecode = currentInstruction-&gt;as&lt;OpNot&gt;();
<span class="line-modified"> 359     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 360     int src = bytecode.m_operand.offset();</span>
 361 
 362     emitLoadTag(src, regT0);
 363 
 364     emitLoad(src, regT1, regT0);
 365     addSlowCase(branchIfNotBoolean(regT1, InvalidGPRReg));
 366     xor32(TrustedImm32(1), regT0);
 367 
 368     emitStoreBool(dst, regT0, (dst == src));
 369 }
 370 
 371 void JIT::emit_op_jfalse(const Instruction* currentInstruction)
 372 {
 373     auto bytecode = currentInstruction-&gt;as&lt;OpJfalse&gt;();
<span class="line-modified"> 374     int cond = bytecode.m_condition.offset();</span>
 375     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 376 
 377     emitLoad(cond, regT1, regT0);
 378 
 379     JSValueRegs value(regT1, regT0);
 380     GPRReg scratch1 = regT2;
 381     GPRReg scratch2 = regT3;
 382     bool shouldCheckMasqueradesAsUndefined = true;
 383     addJump(branchIfFalsey(vm(), value, scratch1, scratch2, fpRegT0, fpRegT1, shouldCheckMasqueradesAsUndefined, m_codeBlock-&gt;globalObject()), target);
 384 }
 385 
 386 void JIT::emit_op_jtrue(const Instruction* currentInstruction)
 387 {
 388     auto bytecode = currentInstruction-&gt;as&lt;OpJtrue&gt;();
<span class="line-modified"> 389     int cond = bytecode.m_condition.offset();</span>
 390     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 391 
 392     emitLoad(cond, regT1, regT0);
 393     bool shouldCheckMasqueradesAsUndefined = true;
 394     JSValueRegs value(regT1, regT0);
 395     GPRReg scratch1 = regT2;
 396     GPRReg scratch2 = regT3;
 397     addJump(branchIfTruthy(vm(), value, scratch1, scratch2, fpRegT0, fpRegT1, shouldCheckMasqueradesAsUndefined, m_codeBlock-&gt;globalObject()), target);
 398 }
 399 
 400 void JIT::emit_op_jeq_null(const Instruction* currentInstruction)
 401 {
 402     auto bytecode = currentInstruction-&gt;as&lt;OpJeqNull&gt;();
<span class="line-modified"> 403     int src = bytecode.m_value.offset();</span>
 404     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 405 
 406     emitLoad(src, regT1, regT0);
 407 
 408     Jump isImmediate = branchIfNotCell(regT1);
 409 
 410     Jump isNotMasqueradesAsUndefined = branchTest8(Zero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined));
 411     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT2);
 412     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 413     addJump(branchPtr(Equal, Address(regT2, Structure::globalObjectOffset()), regT0), target);
 414     Jump masqueradesGlobalObjectIsForeign = jump();
 415 
 416     // Now handle the immediate cases - undefined &amp; null
 417     isImmediate.link(this);
 418     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);
 419     or32(TrustedImm32(1), regT1);
 420     addJump(branchIfNull(regT1), target);
 421 
 422     isNotMasqueradesAsUndefined.link(this);
 423     masqueradesGlobalObjectIsForeign.link(this);
 424 }
 425 
 426 void JIT::emit_op_jneq_null(const Instruction* currentInstruction)
 427 {
 428     auto bytecode = currentInstruction-&gt;as&lt;OpJneqNull&gt;();
<span class="line-modified"> 429     int src = bytecode.m_value.offset();</span>
 430     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 431 
 432     emitLoad(src, regT1, regT0);
 433 
 434     Jump isImmediate = branchIfNotCell(regT1);
 435 
 436     addJump(branchTest8(Zero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined)), target);
 437     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT2);
 438     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 439     addJump(branchPtr(NotEqual, Address(regT2, Structure::globalObjectOffset()), regT0), target);
 440     Jump wasNotImmediate = jump();
 441 
 442     // Now handle the immediate cases - undefined &amp; null
 443     isImmediate.link(this);
 444 
 445     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);
 446     or32(TrustedImm32(1), regT1);
 447     addJump(branchIfNotNull(regT1), target);
 448 
 449     wasNotImmediate.link(this);
 450 }
 451 
 452 void JIT::emit_op_jundefined_or_null(const Instruction* currentInstruction)
 453 {
 454     auto bytecode = currentInstruction-&gt;as&lt;OpJundefinedOrNull&gt;();
<span class="line-modified"> 455     int value = bytecode.m_value.offset();</span>
 456     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 457 
 458     emitLoadTag(value, regT0);
 459     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);
 460     or32(TrustedImm32(1), regT0);
 461     addJump(branchIfNull(regT0), target);
 462 }
 463 
 464 void JIT::emit_op_jnundefined_or_null(const Instruction* currentInstruction)
 465 {
 466     auto bytecode = currentInstruction-&gt;as&lt;OpJnundefinedOrNull&gt;();
<span class="line-modified"> 467     int value = bytecode.m_value.offset();</span>
 468     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 469 
 470     emitLoadTag(value, regT0);
 471     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);
 472     or32(TrustedImm32(1), regT0);
 473     addJump(branchIfNotNull(regT0), target);
 474 }
 475 
 476 void JIT::emit_op_jneq_ptr(const Instruction* currentInstruction)
 477 {
 478     auto bytecode = currentInstruction-&gt;as&lt;OpJneqPtr&gt;();
 479     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 480     int src = bytecode.m_value.offset();</span>
<span class="line-modified"> 481     Special::Pointer ptr = bytecode.m_specialPointer;</span>

 482     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 483 
 484     emitLoad(src, regT1, regT0);
 485     Jump notCell = branchIfNotCell(regT1);
<span class="line-modified"> 486     Jump equal = branchPtr(Equal, regT0, TrustedImmPtr(actualPointerFor(m_codeBlock, ptr)));</span>
 487     notCell.link(this);
 488     store8(TrustedImm32(1), &amp;metadata.m_hasJumped);
 489     addJump(jump(), target);
 490     equal.link(this);
 491 }
 492 
 493 void JIT::emit_op_eq(const Instruction* currentInstruction)
 494 {
 495     auto bytecode = currentInstruction-&gt;as&lt;OpEq&gt;();
 496 
<span class="line-modified"> 497     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 498     int src1 = bytecode.m_lhs.offset();</span>
<span class="line-modified"> 499     int src2 = bytecode.m_rhs.offset();</span>
 500 
 501     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 502     addSlowCase(branch32(NotEqual, regT1, regT3));
 503     addSlowCase(branchIfCell(regT1));
 504     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 505 
 506     compare32(Equal, regT0, regT2, regT0);
 507 
 508     emitStoreBool(dst, regT0);
 509 }
 510 
 511 void JIT::emitSlow_op_eq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 512 {
 513     auto bytecode = currentInstruction-&gt;as&lt;OpEq&gt;();
<span class="line-modified"> 514     int dst = bytecode.m_dst.offset();</span>
 515 
 516     JumpList storeResult;
 517     JumpList genericCase;
 518 
 519     genericCase.append(getSlowCase(iter)); // tags not equal
 520 
 521     linkSlowCase(iter); // tags equal and JSCell
 522     genericCase.append(branchIfNotString(regT0));
 523     genericCase.append(branchIfNotString(regT2));
 524 
 525     // String case.
<span class="line-modified"> 526     callOperation(operationCompareStringEq, regT0, regT2);</span>
 527     storeResult.append(jump());
 528 
 529     // Generic case.
 530     genericCase.append(getSlowCase(iter)); // doubles
 531     genericCase.link(this);
<span class="line-modified"> 532     callOperation(operationCompareEq, JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));</span>
 533 
 534     storeResult.link(this);
 535     emitStoreBool(dst, returnValueGPR);
 536 }
 537 
 538 void JIT::emit_op_jeq(const Instruction* currentInstruction)
 539 {
 540     auto bytecode = currentInstruction-&gt;as&lt;OpJeq&gt;();
 541     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
<span class="line-modified"> 542     int src1 = bytecode.m_lhs.offset();</span>
<span class="line-modified"> 543     int src2 = bytecode.m_rhs.offset();</span>
 544 
 545     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 546     addSlowCase(branch32(NotEqual, regT1, regT3));
 547     addSlowCase(branchIfCell(regT1));
 548     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 549 
 550     addJump(branch32(Equal, regT0, regT2), target);
 551 }
 552 
 553 void JIT::compileOpEqJumpSlow(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter, CompileOpEqType type, int jumpTarget)
 554 {
 555     JumpList done;
 556     JumpList genericCase;
 557 
 558     genericCase.append(getSlowCase(iter)); // tags not equal
 559 
 560     linkSlowCase(iter); // tags equal and JSCell
 561     genericCase.append(branchIfNotString(regT0));
 562     genericCase.append(branchIfNotString(regT2));
 563 
 564     // String case.
<span class="line-modified"> 565     callOperation(operationCompareStringEq, regT0, regT2);</span>
 566     emitJumpSlowToHot(branchTest32(type == CompileOpEqType::Eq ? NonZero : Zero, returnValueGPR), jumpTarget);
 567     done.append(jump());
 568 
 569     // Generic case.
 570     genericCase.append(getSlowCase(iter)); // doubles
 571     genericCase.link(this);
<span class="line-modified"> 572     callOperation(operationCompareEq, JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));</span>
 573     emitJumpSlowToHot(branchTest32(type == CompileOpEqType::Eq ? NonZero : Zero, returnValueGPR), jumpTarget);
 574 
 575     done.link(this);
 576 }
 577 
 578 void JIT::emitSlow_op_jeq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 579 {
 580     auto bytecode = currentInstruction-&gt;as&lt;OpJeq&gt;();
 581     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 582     compileOpEqJumpSlow(iter, CompileOpEqType::Eq, target);
 583 }
 584 
 585 void JIT::emit_op_neq(const Instruction* currentInstruction)
 586 {
 587     auto bytecode = currentInstruction-&gt;as&lt;OpNeq&gt;();
<span class="line-modified"> 588     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 589     int src1 = bytecode.m_lhs.offset();</span>
<span class="line-modified"> 590     int src2 = bytecode.m_rhs.offset();</span>
 591 
 592     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 593     addSlowCase(branch32(NotEqual, regT1, regT3));
 594     addSlowCase(branchIfCell(regT1));
 595     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 596 
 597     compare32(NotEqual, regT0, regT2, regT0);
 598 
 599     emitStoreBool(dst, regT0);
 600 }
 601 
 602 void JIT::emitSlow_op_neq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 603 {
 604     auto bytecode = currentInstruction-&gt;as&lt;OpNeq&gt;();
<span class="line-modified"> 605     int dst = bytecode.m_dst.offset();</span>
 606 
 607     JumpList storeResult;
 608     JumpList genericCase;
 609 
 610     genericCase.append(getSlowCase(iter)); // tags not equal
 611 
 612     linkSlowCase(iter); // tags equal and JSCell
 613     genericCase.append(branchIfNotString(regT0));
 614     genericCase.append(branchIfNotString(regT2));
 615 
 616     // String case.
<span class="line-modified"> 617     callOperation(operationCompareStringEq, regT0, regT2);</span>
 618     storeResult.append(jump());
 619 
 620     // Generic case.
 621     genericCase.append(getSlowCase(iter)); // doubles
 622     genericCase.link(this);
<span class="line-modified"> 623     callOperation(operationCompareEq, JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));</span>
 624 
 625     storeResult.link(this);
 626     xor32(TrustedImm32(0x1), returnValueGPR);
 627     emitStoreBool(dst, returnValueGPR);
 628 }
 629 
 630 void JIT::emit_op_jneq(const Instruction* currentInstruction)
 631 {
 632     auto bytecode = currentInstruction-&gt;as&lt;OpJneq&gt;();
 633     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
<span class="line-modified"> 634     int src1 = bytecode.m_lhs.offset();</span>
<span class="line-modified"> 635     int src2 = bytecode.m_rhs.offset();</span>
 636 
 637     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 638     addSlowCase(branch32(NotEqual, regT1, regT3));
 639     addSlowCase(branchIfCell(regT1));
 640     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 641 
 642     addJump(branch32(NotEqual, regT0, regT2), target);
 643 }
 644 
 645 void JIT::emitSlow_op_jneq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 646 {
 647     auto bytecode = currentInstruction-&gt;as&lt;OpJneq&gt;();
 648     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 649     compileOpEqJumpSlow(iter, CompileOpEqType::NEq, target);
 650 }
 651 
 652 template &lt;typename Op&gt;
 653 void JIT::compileOpStrictEq(const Instruction* currentInstruction, CompileOpStrictEqType type)
 654 {
 655     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 656     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 657     int src1 = bytecode.m_lhs.offset();</span>
<span class="line-modified"> 658     int src2 = bytecode.m_rhs.offset();</span>
 659 
 660     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 661 
 662     // Bail if the tags differ, or are double.
 663     addSlowCase(branch32(NotEqual, regT1, regT3));
 664     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 665 
 666     // Jump to a slow case if both are strings or symbols (non object).
 667     Jump notCell = branchIfNotCell(regT1);
 668     Jump firstIsObject = branchIfObject(regT0);
 669     addSlowCase(branchIfNotObject(regT2));
 670     notCell.link(this);
 671     firstIsObject.link(this);
 672 
 673     // Simply compare the payloads.
 674     if (type == CompileOpStrictEqType::StrictEq)
 675         compare32(Equal, regT0, regT2, regT0);
 676     else
 677         compare32(NotEqual, regT0, regT2, regT0);
 678 
 679     emitStoreBool(dst, regT0);
 680 }
 681 
 682 void JIT::emit_op_stricteq(const Instruction* currentInstruction)
 683 {
 684     compileOpStrictEq&lt;OpStricteq&gt;(currentInstruction, CompileOpStrictEqType::StrictEq);
 685 }
 686 
 687 void JIT::emit_op_nstricteq(const Instruction* currentInstruction)
 688 {
 689     compileOpStrictEq&lt;OpNstricteq&gt;(currentInstruction, CompileOpStrictEqType::NStrictEq);
 690 }
 691 
 692 template&lt;typename Op&gt;
 693 void JIT::compileOpStrictEqJump(const Instruction* currentInstruction, CompileOpStrictEqType type)
 694 {
 695     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
 696     int target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
<span class="line-modified"> 697     int src1 = bytecode.m_lhs.offset();</span>
<span class="line-modified"> 698     int src2 = bytecode.m_rhs.offset();</span>
 699 
 700     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 701 
 702     // Bail if the tags differ, or are double.
 703     addSlowCase(branch32(NotEqual, regT1, regT3));
 704     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 705 
 706     // Jump to a slow case if both are strings or symbols (non object).
 707     Jump notCell = branchIfNotCell(regT1);
 708     Jump firstIsObject = branchIfObject(regT0);
 709     addSlowCase(branchIfNotObject(regT2));
 710     notCell.link(this);
 711     firstIsObject.link(this);
 712 
 713     // Simply compare the payloads.
 714     if (type == CompileOpStrictEqType::StrictEq)
 715         addJump(branch32(Equal, regT0, regT2), target);
 716     else
 717         addJump(branch32(NotEqual, regT0, regT2), target);
 718 }
 719 
 720 void JIT::emit_op_jstricteq(const Instruction* currentInstruction)
 721 {
 722     compileOpStrictEqJump&lt;OpJstricteq&gt;(currentInstruction, CompileOpStrictEqType::StrictEq);
 723 }
 724 
 725 void JIT::emit_op_jnstricteq(const Instruction* currentInstruction)
 726 {
 727     compileOpStrictEqJump&lt;OpJnstricteq&gt;(currentInstruction, CompileOpStrictEqType::NStrictEq);
 728 }
 729 
 730 void JIT::emitSlow_op_jstricteq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 731 {
 732     linkAllSlowCases(iter);
 733 
 734     auto bytecode = currentInstruction-&gt;as&lt;OpJstricteq&gt;();
 735     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
<span class="line-modified"> 736     callOperation(operationCompareStrictEq, JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));</span>
 737     emitJumpSlowToHot(branchTest32(NonZero, returnValueGPR), target);
 738 }
 739 
 740 void JIT::emitSlow_op_jnstricteq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 741 {
 742     linkAllSlowCases(iter);
 743 
 744     auto bytecode = currentInstruction-&gt;as&lt;OpJnstricteq&gt;();
 745     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
<span class="line-modified"> 746     callOperation(operationCompareStrictEq, JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));</span>
 747     emitJumpSlowToHot(branchTest32(Zero, returnValueGPR), target);
 748 }
 749 
 750 void JIT::emit_op_eq_null(const Instruction* currentInstruction)
 751 {
 752     auto bytecode = currentInstruction-&gt;as&lt;OpEqNull&gt;();
<span class="line-modified"> 753     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 754     int src = bytecode.m_operand.offset();</span>
 755 
 756     emitLoad(src, regT1, regT0);
 757     Jump isImmediate = branchIfNotCell(regT1);
 758 
 759     Jump isMasqueradesAsUndefined = branchTest8(NonZero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined));
 760     move(TrustedImm32(0), regT1);
 761     Jump wasNotMasqueradesAsUndefined = jump();
 762 
 763     isMasqueradesAsUndefined.link(this);
 764     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT2);
 765     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 766     loadPtr(Address(regT2, Structure::globalObjectOffset()), regT2);
 767     compare32(Equal, regT0, regT2, regT1);
 768     Jump wasNotImmediate = jump();
 769 
 770     isImmediate.link(this);
 771 
 772     compare32(Equal, regT1, TrustedImm32(JSValue::NullTag), regT2);
 773     compare32(Equal, regT1, TrustedImm32(JSValue::UndefinedTag), regT1);
 774     or32(regT2, regT1);
 775 
 776     wasNotImmediate.link(this);
 777     wasNotMasqueradesAsUndefined.link(this);
 778 
 779     emitStoreBool(dst, regT1);
 780 }
 781 
 782 void JIT::emit_op_neq_null(const Instruction* currentInstruction)
 783 {
 784     auto bytecode = currentInstruction-&gt;as&lt;OpNeqNull&gt;();
<span class="line-modified"> 785     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 786     int src = bytecode.m_operand.offset();</span>
 787 
 788     emitLoad(src, regT1, regT0);
 789     Jump isImmediate = branchIfNotCell(regT1);
 790 
 791     Jump isMasqueradesAsUndefined = branchTest8(NonZero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined));
 792     move(TrustedImm32(1), regT1);
 793     Jump wasNotMasqueradesAsUndefined = jump();
 794 
 795     isMasqueradesAsUndefined.link(this);
 796     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT2);
 797     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 798     loadPtr(Address(regT2, Structure::globalObjectOffset()), regT2);
 799     compare32(NotEqual, regT0, regT2, regT1);
 800     Jump wasNotImmediate = jump();
 801 
 802     isImmediate.link(this);
 803 
 804     compare32(NotEqual, regT1, TrustedImm32(JSValue::NullTag), regT2);
 805     compare32(NotEqual, regT1, TrustedImm32(JSValue::UndefinedTag), regT1);
 806     and32(regT2, regT1);
 807 
 808     wasNotImmediate.link(this);
 809     wasNotMasqueradesAsUndefined.link(this);
 810 
 811     emitStoreBool(dst, regT1);
 812 }
 813 
 814 void JIT::emit_op_throw(const Instruction* currentInstruction)
 815 {
 816     auto bytecode = currentInstruction-&gt;as&lt;OpThrow&gt;();
 817     ASSERT(regT0 == returnValueGPR);
 818     copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm().topEntryFrame);
<span class="line-modified"> 819     emitLoad(bytecode.m_value.offset(), regT1, regT0);</span>
<span class="line-modified"> 820     callOperationNoExceptionCheck(operationThrow, JSValueRegs(regT1, regT0));</span>
 821     jumpToExceptionHandler(vm());
 822 }
 823 
 824 void JIT::emit_op_to_number(const Instruction* currentInstruction)
 825 {
 826     auto bytecode = currentInstruction-&gt;as&lt;OpToNumber&gt;();
<span class="line-modified"> 827     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 828     int src = bytecode.m_operand.offset();</span>
 829 
 830     emitLoad(src, regT1, regT0);
 831 
 832     Jump isInt32 = branchIfInt32(regT1);
 833     addSlowCase(branch32(AboveOrEqual, regT1, TrustedImm32(JSValue::LowestTag)));
 834     isInt32.link(this);
 835 
 836     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 837     if (src != dst)
 838         emitStore(dst, regT1, regT0);
 839 }
 840 






















 841 void JIT::emit_op_to_string(const Instruction* currentInstruction)
 842 {
 843     auto bytecode = currentInstruction-&gt;as&lt;OpToString&gt;();
<span class="line-modified"> 844     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 845     int src = bytecode.m_operand.offset();</span>
 846 
 847     emitLoad(src, regT1, regT0);
 848 
 849     addSlowCase(branchIfNotCell(regT1));
 850     addSlowCase(branchIfNotString(regT0));
 851 
 852     if (src != dst)
 853         emitStore(dst, regT1, regT0);
 854 }
 855 
 856 void JIT::emit_op_to_object(const Instruction* currentInstruction)
 857 {
 858     auto bytecode = currentInstruction-&gt;as&lt;OpToObject&gt;();
<span class="line-modified"> 859     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 860     int src = bytecode.m_operand.offset();</span>
 861 
 862     emitLoad(src, regT1, regT0);
 863 
 864     addSlowCase(branchIfNotCell(regT1));
 865     addSlowCase(branchIfNotObject(regT0));
 866 
 867     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 868     if (src != dst)
 869         emitStore(dst, regT1, regT0);
 870 }
 871 
 872 void JIT::emit_op_catch(const Instruction* currentInstruction)
 873 {
 874     auto bytecode = currentInstruction-&gt;as&lt;OpCatch&gt;();
 875 
 876     restoreCalleeSavesFromEntryFrameCalleeSavesBuffer(vm().topEntryFrame);
 877 
 878     move(TrustedImmPtr(m_vm), regT3);
 879     // operationThrow returns the callFrame for the handler.
 880     load32(Address(regT3, VM::callFrameForCatchOffset()), callFrameRegister);
 881     storePtr(TrustedImmPtr(nullptr), Address(regT3, VM::callFrameForCatchOffset()));
 882 
 883     addPtr(TrustedImm32(stackPointerOffsetFor(codeBlock()) * sizeof(Register)), callFrameRegister, stackPointerRegister);
 884 
<span class="line-modified"> 885     callOperationNoExceptionCheck(operationCheckIfExceptionIsUncatchableAndNotifyProfiler);</span>
 886     Jump isCatchableException = branchTest32(Zero, returnValueGPR);
 887     jumpToExceptionHandler(vm());
 888     isCatchableException.link(this);
 889 
 890     move(TrustedImmPtr(m_vm), regT3);
 891 
 892     // Now store the exception returned by operationThrow.
 893     load32(Address(regT3, VM::exceptionOffset()), regT2);
 894     move(TrustedImm32(JSValue::CellTag), regT1);
 895 
 896     store32(TrustedImm32(0), Address(regT3, VM::exceptionOffset()));
 897 
<span class="line-modified"> 898     unsigned exception = bytecode.m_exception.offset();</span>
<span class="line-removed"> 899     emitStore(exception, regT1, regT2);</span>
 900 
 901     load32(Address(regT2, Exception::valueOffset() + OBJECT_OFFSETOF(JSValue, u.asBits.payload)), regT0);
 902     load32(Address(regT2, Exception::valueOffset() + OBJECT_OFFSETOF(JSValue, u.asBits.tag)), regT1);
 903 
<span class="line-modified"> 904     unsigned thrownValue = bytecode.m_thrownValue.offset();</span>
<span class="line-removed"> 905     emitStore(thrownValue, regT1, regT0);</span>
 906 
 907 #if ENABLE(DFG_JIT)
 908     // FIXME: consider inline caching the process of doing OSR entry, including
 909     // argument type proofs, storing locals to the buffer, etc
 910     // https://bugs.webkit.org/show_bug.cgi?id=175598
 911 
 912     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 913     ValueProfileAndOperandBuffer* buffer = metadata.m_buffer;</span>
 914     if (buffer || !shouldEmitProfiling())
<span class="line-modified"> 915         callOperation(operationTryOSREnterAtCatch, m_bytecodeOffset);</span>
 916     else
<span class="line-modified"> 917         callOperation(operationTryOSREnterAtCatchAndValueProfile, m_bytecodeOffset);</span>
 918     auto skipOSREntry = branchTestPtr(Zero, returnValueGPR);
 919     emitRestoreCalleeSaves();
 920     farJump(returnValueGPR, NoPtrTag);
 921     skipOSREntry.link(this);
 922     if (buffer &amp;&amp; shouldEmitProfiling()) {
<span class="line-modified"> 923         buffer-&gt;forEach([&amp;] (ValueProfileAndOperand&amp; profile) {</span>
 924             JSValueRegs regs(regT1, regT0);
 925             emitGetVirtualRegister(profile.m_operand, regs);
 926             emitValueProfilingSite(static_cast&lt;ValueProfile&amp;&gt;(profile));
 927         });
 928     }
 929 #endif // ENABLE(DFG_JIT)
 930 }
 931 
 932 void JIT::emit_op_identity_with_profile(const Instruction*)
 933 {
 934     // We don&#39;t need to do anything here...
 935 }
 936 
 937 void JIT::emit_op_get_parent_scope(const Instruction* currentInstruction)
 938 {
 939     auto bytecode = currentInstruction-&gt;as&lt;OpGetParentScope&gt;();
<span class="line-modified"> 940     int currentScope = bytecode.m_scope.offset();</span>
 941     emitLoadPayload(currentScope, regT0);
 942     loadPtr(Address(regT0, JSScope::offsetOfNext()), regT0);
<span class="line-modified"> 943     emitStoreCell(bytecode.m_dst.offset(), regT0);</span>
 944 }
 945 
 946 void JIT::emit_op_switch_imm(const Instruction* currentInstruction)
 947 {
 948     auto bytecode = currentInstruction-&gt;as&lt;OpSwitchImm&gt;();
 949     size_t tableIndex = bytecode.m_tableIndex;
 950     unsigned defaultOffset = jumpTarget(currentInstruction, bytecode.m_defaultOffset);
<span class="line-modified"> 951     unsigned scrutinee = bytecode.m_scrutinee.offset();</span>
 952 
 953     // create jump table for switch destinations, track this switch statement.
 954     SimpleJumpTable* jumpTable = &amp;m_codeBlock-&gt;switchJumpTable(tableIndex);
<span class="line-modified"> 955     m_switches.append(SwitchRecord(jumpTable, m_bytecodeOffset, defaultOffset, SwitchRecord::Immediate));</span>
 956     jumpTable-&gt;ensureCTITable();
 957 
 958     emitLoad(scrutinee, regT1, regT0);
<span class="line-modified"> 959     callOperation(operationSwitchImmWithUnknownKeyType, JSValueRegs(regT1, regT0), tableIndex);</span>
 960     farJump(returnValueGPR, NoPtrTag);
 961 }
 962 
 963 void JIT::emit_op_switch_char(const Instruction* currentInstruction)
 964 {
 965     auto bytecode = currentInstruction-&gt;as&lt;OpSwitchChar&gt;();
 966     size_t tableIndex = bytecode.m_tableIndex;
 967     unsigned defaultOffset = jumpTarget(currentInstruction, bytecode.m_defaultOffset);
<span class="line-modified"> 968     unsigned scrutinee = bytecode.m_scrutinee.offset();</span>
 969 
 970     // create jump table for switch destinations, track this switch statement.
 971     SimpleJumpTable* jumpTable = &amp;m_codeBlock-&gt;switchJumpTable(tableIndex);
<span class="line-modified"> 972     m_switches.append(SwitchRecord(jumpTable, m_bytecodeOffset, defaultOffset, SwitchRecord::Character));</span>
 973     jumpTable-&gt;ensureCTITable();
 974 
 975     emitLoad(scrutinee, regT1, regT0);
<span class="line-modified"> 976     callOperation(operationSwitchCharWithUnknownKeyType, JSValueRegs(regT1, regT0), tableIndex);</span>
 977     farJump(returnValueGPR, NoPtrTag);
 978 }
 979 
 980 void JIT::emit_op_switch_string(const Instruction* currentInstruction)
 981 {
 982     auto bytecode = currentInstruction-&gt;as&lt;OpSwitchString&gt;();
 983     size_t tableIndex = bytecode.m_tableIndex;
 984     unsigned defaultOffset = jumpTarget(currentInstruction, bytecode.m_defaultOffset);
<span class="line-modified"> 985     unsigned scrutinee = bytecode.m_scrutinee.offset();</span>
 986 
 987     // create jump table for switch destinations, track this switch statement.
 988     StringJumpTable* jumpTable = &amp;m_codeBlock-&gt;stringSwitchJumpTable(tableIndex);
<span class="line-modified"> 989     m_switches.append(SwitchRecord(jumpTable, m_bytecodeOffset, defaultOffset));</span>
 990 
 991     emitLoad(scrutinee, regT1, regT0);
<span class="line-modified"> 992     callOperation(operationSwitchStringWithUnknownKeyType, JSValueRegs(regT1, regT0), tableIndex);</span>
 993     farJump(returnValueGPR, NoPtrTag);
 994 }
 995 
 996 void JIT::emit_op_debug(const Instruction* currentInstruction)
 997 {
 998     auto bytecode = currentInstruction-&gt;as&lt;OpDebug&gt;();
 999     load32(codeBlock()-&gt;debuggerRequestsAddress(), regT0);
1000     Jump noDebuggerRequests = branchTest32(Zero, regT0);
<span class="line-modified">1001     callOperation(operationDebug, static_cast&lt;int&gt;(bytecode.m_debugHookType));</span>
1002     noDebuggerRequests.link(this);
1003 }
1004 















1005 void JIT::emit_op_get_scope(const Instruction* currentInstruction)
1006 {
1007     auto bytecode = currentInstruction-&gt;as&lt;OpGetScope&gt;();
<span class="line-modified">1008     int dst = bytecode.m_dst.offset();</span>
1009     emitGetFromCallFrameHeaderPtr(CallFrameSlot::callee, regT0);
1010     loadPtr(Address(regT0, JSFunction::offsetOfScopeChain()), regT0);
1011     emitStoreCell(dst, regT0);
1012 }
1013 
1014 void JIT::emit_op_create_this(const Instruction* currentInstruction)
1015 {
1016     auto bytecode = currentInstruction-&gt;as&lt;OpCreateThis&gt;();
1017     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified">1018     int callee = bytecode.m_callee.offset();</span>
1019     WriteBarrierBase&lt;JSCell&gt;* cachedFunction = &amp;metadata.m_cachedCallee;
1020     RegisterID calleeReg = regT0;
1021     RegisterID rareDataReg = regT4;
1022     RegisterID resultReg = regT0;
1023     RegisterID allocatorReg = regT1;
1024     RegisterID structureReg = regT2;
1025     RegisterID cachedFunctionReg = regT4;
1026     RegisterID scratchReg = regT3;
1027 
1028     emitLoadPayload(callee, calleeReg);
1029     addSlowCase(branchIfNotFunction(calleeReg));
<span class="line-modified">1030     loadPtr(Address(calleeReg, JSFunction::offsetOfRareData()), rareDataReg);</span>
<span class="line-modified">1031     addSlowCase(branchTestPtr(Zero, rareDataReg));</span>
<span class="line-modified">1032     load32(Address(rareDataReg, FunctionRareData::offsetOfObjectAllocationProfile() + ObjectAllocationProfileWithPrototype::offsetOfAllocator()), allocatorReg);</span>
<span class="line-modified">1033     loadPtr(Address(rareDataReg, FunctionRareData::offsetOfObjectAllocationProfile() + ObjectAllocationProfileWithPrototype::offsetOfStructure()), structureReg);</span>
1034 
1035     loadPtr(cachedFunction, cachedFunctionReg);
1036     Jump hasSeenMultipleCallees = branchPtr(Equal, cachedFunctionReg, TrustedImmPtr(JSCell::seenMultipleCalleeObjects()));
1037     addSlowCase(branchPtr(NotEqual, calleeReg, cachedFunctionReg));
1038     hasSeenMultipleCallees.link(this);
1039 
1040     JumpList slowCases;
1041     auto butterfly = TrustedImmPtr(nullptr);
1042     emitAllocateJSObject(resultReg, JITAllocator::variable(), allocatorReg, structureReg, butterfly, scratchReg, slowCases);
1043     load8(Address(structureReg, Structure::inlineCapacityOffset()), scratchReg);
1044     emitInitializeInlineStorage(resultReg, scratchReg);
1045     addSlowCase(slowCases);
<span class="line-modified">1046     emitStoreCell(bytecode.m_dst.offset(), resultReg);</span>
1047 }
1048 
1049 void JIT::emit_op_to_this(const Instruction* currentInstruction)
1050 {
1051     auto bytecode = currentInstruction-&gt;as&lt;OpToThis&gt;();
1052     auto&amp; metadata = bytecode.metadata(m_codeBlock);
1053     StructureID* cachedStructureID = &amp;metadata.m_cachedStructureID;
<span class="line-modified">1054     int thisRegister = bytecode.m_srcDst.offset();</span>
1055 
1056     emitLoad(thisRegister, regT3, regT2);
1057 
1058     addSlowCase(branchIfNotCell(regT3));
1059     addSlowCase(branchIfNotType(regT2, FinalObjectType));
1060     loadPtr(Address(regT2, JSCell::structureIDOffset()), regT0);
1061     load32(cachedStructureID, regT2);
1062     addSlowCase(branchPtr(NotEqual, regT0, regT2));
1063 }
1064 
1065 void JIT::emit_op_check_tdz(const Instruction* currentInstruction)
1066 {
1067     auto bytecode = currentInstruction-&gt;as&lt;OpCheckTdz&gt;();
<span class="line-modified">1068     emitLoadTag(bytecode.m_targetVirtualRegister.offset(), regT0);</span>
1069     addSlowCase(branchIfEmpty(regT0));
1070 }
1071 
1072 void JIT::emit_op_has_structure_property(const Instruction* currentInstruction)
1073 {
1074     auto bytecode = currentInstruction-&gt;as&lt;OpHasStructureProperty&gt;();
<span class="line-modified">1075     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified">1076     int base = bytecode.m_base.offset();</span>
<span class="line-modified">1077     int enumerator = bytecode.m_enumerator.offset();</span>
1078 
1079     emitLoadPayload(base, regT0);
1080     emitJumpSlowCaseIfNotJSCell(base);
1081 
1082     emitLoadPayload(enumerator, regT1);
1083 
1084     load32(Address(regT0, JSCell::structureIDOffset()), regT0);
1085     addSlowCase(branch32(NotEqual, regT0, Address(regT1, JSPropertyNameEnumerator::cachedStructureIDOffset())));
1086 
1087     move(TrustedImm32(1), regT0);
1088     emitStoreBool(dst, regT0);
1089 }
1090 
1091 void JIT::privateCompileHasIndexedProperty(ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)
1092 {
1093     const Instruction* currentInstruction = m_codeBlock-&gt;instructions().at(byValInfo-&gt;bytecodeIndex).ptr();
1094 
1095     PatchableJump badType;
1096 
1097     // FIXME: Add support for other types like TypedArrays and Arguments.
</pre>
<hr />
<pre>
1102 
1103     LinkBuffer patchBuffer(*this, m_codeBlock);
1104 
1105     patchBuffer.link(badType, byValInfo-&gt;slowPathTarget);
1106     patchBuffer.link(slowCases, byValInfo-&gt;slowPathTarget);
1107 
1108     patchBuffer.link(done, byValInfo-&gt;badTypeDoneTarget);
1109 
1110     byValInfo-&gt;stubRoutine = FINALIZE_CODE_FOR_STUB(
1111         m_codeBlock, patchBuffer, JITStubRoutinePtrTag,
1112         &quot;Baseline has_indexed_property stub for %s, return point %p&quot;, toCString(*m_codeBlock).data(), returnAddress.value());
1113 
1114     MacroAssembler::repatchJump(byValInfo-&gt;badTypeJump, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(byValInfo-&gt;stubRoutine-&gt;code().code()));
1115     MacroAssembler::repatchCall(CodeLocationCall&lt;NoPtrTag&gt;(MacroAssemblerCodePtr&lt;NoPtrTag&gt;(returnAddress)), FunctionPtr&lt;OperationPtrTag&gt;(operationHasIndexedPropertyGeneric));
1116 }
1117 
1118 void JIT::emit_op_has_indexed_property(const Instruction* currentInstruction)
1119 {
1120     auto bytecode = currentInstruction-&gt;as&lt;OpHasIndexedProperty&gt;();
1121     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified">1122     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified">1123     int base = bytecode.m_base.offset();</span>
<span class="line-modified">1124     int property = bytecode.m_property.offset();</span>
1125     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
1126     ByValInfo* byValInfo = m_codeBlock-&gt;addByValInfo();
1127 
1128     emitLoadPayload(base, regT0);
1129     emitJumpSlowCaseIfNotJSCell(base);
1130 
1131     emitLoad(property, regT3, regT1);
1132     addSlowCase(branchIfNotInt32(regT3));
1133 
1134     // This is technically incorrect - we&#39;re zero-extending an int32. On the hot path this doesn&#39;t matter.
1135     // We check the value as if it was a uint32 against the m_vectorLength - which will always fail if
1136     // number was signed since m_vectorLength is always less than intmax (since the total allocation
1137     // size is always less than 4Gb). As such zero extending will have been correct (and extending the value
1138     // to 64-bits is necessary since it&#39;s used in the address calculation. We zero extend rather than sign
1139     // extending since it makes it easier to re-tag the value in the slow case.
1140     zeroExtend32ToPtr(regT1, regT1);
1141 
1142     emitArrayProfilingSiteWithCell(regT0, regT2, profile);
1143     and32(TrustedImm32(IndexingShapeMask), regT2);
1144 
1145     JITArrayMode mode = chooseArrayMode(profile);
1146     PatchableJump badType;
1147 
1148     // FIXME: Add support for other types like TypedArrays and Arguments.
1149     // See https://bugs.webkit.org/show_bug.cgi?id=135033 and https://bugs.webkit.org/show_bug.cgi?id=135034.
1150     JumpList slowCases = emitLoadForArrayMode(currentInstruction, mode, badType);
1151     move(TrustedImm32(1), regT0);
1152 
1153     addSlowCase(badType);
1154     addSlowCase(slowCases);
1155 
1156     Label done = label();
1157 
1158     emitStoreBool(dst, regT0);
1159 
1160     Label nextHotPath = label();
1161 
<span class="line-modified">1162     m_byValCompilationInfo.append(ByValCompilationInfo(byValInfo, m_bytecodeOffset, PatchableJump(), badType, mode, profile, done, nextHotPath));</span>
1163 }
1164 
1165 void JIT::emitSlow_op_has_indexed_property(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
1166 {
1167     linkAllSlowCases(iter);
1168 
1169     auto bytecode = currentInstruction-&gt;as&lt;OpHasIndexedProperty&gt;();
<span class="line-modified">1170     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified">1171     int base = bytecode.m_base.offset();</span>
<span class="line-modified">1172     int property = bytecode.m_property.offset();</span>
1173     ByValInfo* byValInfo = m_byValCompilationInfo[m_byValInstructionIndex].byValInfo;
1174 
1175     Label slowPath = label();
1176 
1177     emitLoad(base, regT1, regT0);
1178     emitLoad(property, regT3, regT2);
<span class="line-modified">1179     Call call = callOperation(operationHasIndexedPropertyDefault, dst, JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2), byValInfo);</span>
1180 
1181     m_byValCompilationInfo[m_byValInstructionIndex].slowPathTarget = slowPath;
1182     m_byValCompilationInfo[m_byValInstructionIndex].returnAddress = call;
1183     m_byValInstructionIndex++;
1184 }
1185 
1186 void JIT::emit_op_get_direct_pname(const Instruction* currentInstruction)
1187 {
1188     auto bytecode = currentInstruction-&gt;as&lt;OpGetDirectPname&gt;();
<span class="line-modified">1189     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified">1190     int base = bytecode.m_base.offset();</span>
<span class="line-modified">1191     int index = bytecode.m_index.offset();</span>
<span class="line-modified">1192     int enumerator = bytecode.m_enumerator.offset();</span>
1193 
1194     // Check that base is a cell
1195     emitLoadPayload(base, regT0);
1196     emitJumpSlowCaseIfNotJSCell(base);
1197 
1198     // Check the structure
1199     emitLoadPayload(enumerator, regT1);
1200     load32(Address(regT0, JSCell::structureIDOffset()), regT2);
1201     addSlowCase(branch32(NotEqual, regT2, Address(regT1, JSPropertyNameEnumerator::cachedStructureIDOffset())));
1202 
1203     // Compute the offset
1204     emitLoadPayload(index, regT2);
1205     // If index is less than the enumerator&#39;s cached inline storage, then it&#39;s an inline access
1206     Jump outOfLineAccess = branch32(AboveOrEqual, regT2, Address(regT1, JSPropertyNameEnumerator::cachedInlineCapacityOffset()));
1207     addPtr(TrustedImm32(JSObject::offsetOfInlineStorage()), regT0);
1208     load32(BaseIndex(regT0, regT2, TimesEight, OBJECT_OFFSETOF(JSValue, u.asBits.tag)), regT1);
1209     load32(BaseIndex(regT0, regT2, TimesEight, OBJECT_OFFSETOF(JSValue, u.asBits.payload)), regT0);
1210 
1211     Jump done = jump();
1212 
1213     // Otherwise it&#39;s out of line
1214     outOfLineAccess.link(this);
1215     loadPtr(Address(regT0, JSObject::butterflyOffset()), regT0);
1216     sub32(Address(regT1, JSPropertyNameEnumerator::cachedInlineCapacityOffset()), regT2);
1217     neg32(regT2);
1218     int32_t offsetOfFirstProperty = static_cast&lt;int32_t&gt;(offsetInButterfly(firstOutOfLineOffset)) * sizeof(EncodedJSValue);
1219     load32(BaseIndex(regT0, regT2, TimesEight, offsetOfFirstProperty + OBJECT_OFFSETOF(JSValue, u.asBits.tag)), regT1);
1220     load32(BaseIndex(regT0, regT2, TimesEight, offsetOfFirstProperty + OBJECT_OFFSETOF(JSValue, u.asBits.payload)), regT0);
1221 
1222     done.link(this);
1223     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
1224     emitStore(dst, regT1, regT0);
1225 }
1226 
1227 void JIT::emit_op_enumerator_structure_pname(const Instruction* currentInstruction)
1228 {
1229     auto bytecode = currentInstruction-&gt;as&lt;OpEnumeratorStructurePname&gt;();
<span class="line-modified">1230     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified">1231     int enumerator = bytecode.m_enumerator.offset();</span>
<span class="line-modified">1232     int index = bytecode.m_index.offset();</span>
1233 
1234     emitLoadPayload(index, regT0);
1235     emitLoadPayload(enumerator, regT1);
1236     Jump inBounds = branch32(Below, regT0, Address(regT1, JSPropertyNameEnumerator::endStructurePropertyIndexOffset()));
1237 
1238     move(TrustedImm32(JSValue::NullTag), regT2);
1239     move(TrustedImm32(0), regT0);
1240 
1241     Jump done = jump();
1242     inBounds.link(this);
1243 
1244     loadPtr(Address(regT1, JSPropertyNameEnumerator::cachedPropertyNamesVectorOffset()), regT1);
1245     loadPtr(BaseIndex(regT1, regT0, timesPtr()), regT0);
1246     move(TrustedImm32(JSValue::CellTag), regT2);
1247 
1248     done.link(this);
1249     emitStore(dst, regT2, regT0);
1250 }
1251 
1252 void JIT::emit_op_enumerator_generic_pname(const Instruction* currentInstruction)
1253 {
1254     auto bytecode = currentInstruction-&gt;as&lt;OpEnumeratorGenericPname&gt;();
<span class="line-modified">1255     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified">1256     int enumerator = bytecode.m_enumerator.offset();</span>
<span class="line-modified">1257     int index = bytecode.m_index.offset();</span>
1258 
1259     emitLoadPayload(index, regT0);
1260     emitLoadPayload(enumerator, regT1);
1261     Jump inBounds = branch32(Below, regT0, Address(regT1, JSPropertyNameEnumerator::endGenericPropertyIndexOffset()));
1262 
1263     move(TrustedImm32(JSValue::NullTag), regT2);
1264     move(TrustedImm32(0), regT0);
1265 
1266     Jump done = jump();
1267     inBounds.link(this);
1268 
1269     loadPtr(Address(regT1, JSPropertyNameEnumerator::cachedPropertyNamesVectorOffset()), regT1);
1270     loadPtr(BaseIndex(regT1, regT0, timesPtr()), regT0);
1271     move(TrustedImm32(JSValue::CellTag), regT2);
1272 
1273     done.link(this);
1274     emitStore(dst, regT2, regT0);
1275 }
1276 
1277 void JIT::emit_op_profile_type(const Instruction* currentInstruction)
1278 {
1279     auto bytecode = currentInstruction-&gt;as&lt;OpProfileType&gt;();
1280     auto&amp; metadata = bytecode.metadata(m_codeBlock);
1281     TypeLocation* cachedTypeLocation = metadata.m_typeLocation;
<span class="line-modified">1282     int valueToProfile = bytecode.m_targetVirtualRegister.offset();</span>
1283 
1284     // Load payload in T0. Load tag in T3.
1285     emitLoadPayload(valueToProfile, regT0);
1286     emitLoadTag(valueToProfile, regT3);
1287 
1288     JumpList jumpToEnd;
1289 
1290     jumpToEnd.append(branchIfEmpty(regT3));
1291 
1292     // Compile in a predictive type check, if possible, to see if we can skip writing to the log.
1293     // These typechecks are inlined to match those of the 32-bit JSValue type checks.
1294     if (cachedTypeLocation-&gt;m_lastSeenType == TypeUndefined)
1295         jumpToEnd.append(branchIfUndefined(regT3));
1296     else if (cachedTypeLocation-&gt;m_lastSeenType == TypeNull)
1297         jumpToEnd.append(branchIfNull(regT3));
1298     else if (cachedTypeLocation-&gt;m_lastSeenType == TypeBoolean)
1299         jumpToEnd.append(branchIfBoolean(regT3, InvalidGPRReg));
1300     else if (cachedTypeLocation-&gt;m_lastSeenType == TypeAnyInt)
1301         jumpToEnd.append(branchIfInt32(regT3));
1302     else if (cachedTypeLocation-&gt;m_lastSeenType == TypeNumber) {
</pre>
<hr />
<pre>
1319     store32(regT3, Address(regT1, TypeProfilerLog::LogEntry::valueOffset() + OBJECT_OFFSETOF(JSValue, u.asBits.tag)));
1320 
1321     // Store the structureID of the cell if argument is a cell, otherwise, store 0 on the log entry.
1322     Jump notCell = branchIfNotCell(regT3);
1323     load32(Address(regT0, JSCell::structureIDOffset()), regT0);
1324     store32(regT0, Address(regT1, TypeProfilerLog::LogEntry::structureIDOffset()));
1325     Jump skipNotCell = jump();
1326     notCell.link(this);
1327     store32(TrustedImm32(0), Address(regT1, TypeProfilerLog::LogEntry::structureIDOffset()));
1328     skipNotCell.link(this);
1329 
1330     // Store the typeLocation on the log entry.
1331     move(TrustedImmPtr(cachedTypeLocation), regT0);
1332     store32(regT0, Address(regT1, TypeProfilerLog::LogEntry::locationOffset()));
1333 
1334     // Increment the current log entry.
1335     addPtr(TrustedImm32(sizeof(TypeProfilerLog::LogEntry)), regT1);
1336     store32(regT1, Address(regT2, TypeProfilerLog::currentLogEntryOffset()));
1337     jumpToEnd.append(branchPtr(NotEqual, regT1, TrustedImmPtr(cachedTypeProfilerLog-&gt;logEndPtr())));
1338     // Clear the log if we&#39;re at the end of the log.
<span class="line-modified">1339     callOperation(operationProcessTypeProfilerLog);</span>
1340 
1341     jumpToEnd.link(this);
1342 }
1343 
1344 void JIT::emit_op_log_shadow_chicken_prologue(const Instruction* currentInstruction)
1345 {
1346     RELEASE_ASSERT(vm().shadowChicken());
1347     updateTopCallFrame();
1348     static_assert(nonArgGPR0 != regT0 &amp;&amp; nonArgGPR0 != regT2, &quot;we will have problems if this is true.&quot;);
1349     auto bytecode = currentInstruction-&gt;as&lt;OpLogShadowChickenPrologue&gt;();
1350     GPRReg shadowPacketReg = regT0;
1351     GPRReg scratch1Reg = nonArgGPR0; // This must be a non-argument register.
1352     GPRReg scratch2Reg = regT2;
1353     ensureShadowChickenPacket(vm(), shadowPacketReg, scratch1Reg, scratch2Reg);
1354 
1355     scratch1Reg = regT4;
<span class="line-modified">1356     emitLoadPayload(bytecode.m_scope.offset(), regT3);</span>
1357     logShadowChickenProloguePacket(shadowPacketReg, scratch1Reg, regT3);
1358 }
1359 
1360 void JIT::emit_op_log_shadow_chicken_tail(const Instruction* currentInstruction)
1361 {
1362     RELEASE_ASSERT(vm().shadowChicken());
1363     updateTopCallFrame();
1364     static_assert(nonArgGPR0 != regT0 &amp;&amp; nonArgGPR0 != regT2, &quot;we will have problems if this is true.&quot;);
1365     auto bytecode = currentInstruction-&gt;as&lt;OpLogShadowChickenTail&gt;();
1366     GPRReg shadowPacketReg = regT0;
1367     GPRReg scratch1Reg = nonArgGPR0; // This must be a non-argument register.
1368     GPRReg scratch2Reg = regT2;
1369     ensureShadowChickenPacket(vm(), shadowPacketReg, scratch1Reg, scratch2Reg);
<span class="line-modified">1370     emitLoadPayload(bytecode.m_thisValue.offset(), regT2);</span>
<span class="line-modified">1371     emitLoadTag(bytecode.m_thisValue.offset(), regT1);</span>
1372     JSValueRegs thisRegs(regT1, regT2);
<span class="line-modified">1373     emitLoadPayload(bytecode.m_scope.offset(), regT3);</span>
<span class="line-modified">1374     logShadowChickenTailPacket(shadowPacketReg, thisRegs, regT3, m_codeBlock, CallSiteIndex(currentInstruction));</span>
1375 }
1376 
1377 } // namespace JSC
1378 
1379 #endif // USE(JSVALUE32_64)
1380 #endif // ENABLE(JIT)
</pre>
</td>
<td>
<hr />
<pre>
  33 #include &quot;BytecodeStructs.h&quot;
  34 #include &quot;CCallHelpers.h&quot;
  35 #include &quot;Exception.h&quot;
  36 #include &quot;JITInlines.h&quot;
  37 #include &quot;JSArray.h&quot;
  38 #include &quot;JSCast.h&quot;
  39 #include &quot;JSFunction.h&quot;
  40 #include &quot;JSPropertyNameEnumerator.h&quot;
  41 #include &quot;LinkBuffer.h&quot;
  42 #include &quot;MaxFrameExtentForSlowPathCall.h&quot;
  43 #include &quot;OpcodeInlines.h&quot;
  44 #include &quot;SlowPathCall.h&quot;
  45 #include &quot;TypeProfilerLog.h&quot;
  46 #include &quot;VirtualRegister.h&quot;
  47 
  48 namespace JSC {
  49 
  50 void JIT::emit_op_mov(const Instruction* currentInstruction)
  51 {
  52     auto bytecode = currentInstruction-&gt;as&lt;OpMov&gt;();
<span class="line-modified">  53     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified">  54     VirtualRegister src = bytecode.m_src;</span>
  55 
<span class="line-modified">  56     if (src.isConstant())</span>
  57         emitStore(dst, getConstantOperand(src));
  58     else {
  59         emitLoad(src, regT1, regT0);
  60         emitStore(dst, regT1, regT0);
  61     }
  62 }
  63 
  64 void JIT::emit_op_end(const Instruction* currentInstruction)
  65 {
  66     ASSERT(returnValueGPR != callFrameRegister);
  67     auto bytecode = currentInstruction-&gt;as&lt;OpEnd&gt;();
<span class="line-modified">  68     emitLoad(bytecode.m_value, regT1, returnValueGPR);</span>
  69     emitRestoreCalleeSaves();
  70     emitFunctionEpilogue();
  71     ret();
  72 }
  73 
  74 void JIT::emit_op_jmp(const Instruction* currentInstruction)
  75 {
  76     auto bytecode = currentInstruction-&gt;as&lt;OpJmp&gt;();
  77     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
  78     addJump(jump(), target);
  79 }
  80 
  81 void JIT::emit_op_new_object(const Instruction* currentInstruction)
  82 {
  83     auto bytecode = currentInstruction-&gt;as&lt;OpNewObject&gt;();
  84     auto&amp; metadata = bytecode.metadata(m_codeBlock);
  85     Structure* structure = metadata.m_objectAllocationProfile.structure();
  86     size_t allocationSize = JSFinalObject::allocationSize(structure-&gt;inlineCapacity());
  87     Allocator allocator = allocatorForNonVirtualConcurrently&lt;JSFinalObject&gt;(*m_vm, allocationSize, AllocatorForMode::AllocatorIfExists);
  88 
  89     RegisterID resultReg = returnValueGPR;
  90     RegisterID allocatorReg = regT1;
  91     RegisterID scratchReg = regT3;
  92 
  93     if (!allocator)
  94         addSlowCase(jump());
  95     else {
  96         JumpList slowCases;
  97         auto butterfly = TrustedImmPtr(nullptr);
  98         emitAllocateJSObject(resultReg, JITAllocator::constant(allocator), allocatorReg, TrustedImmPtr(structure), butterfly, scratchReg, slowCases);
  99         emitInitializeInlineStorage(resultReg, structure-&gt;inlineCapacity());
 100         addSlowCase(slowCases);
<span class="line-modified"> 101         emitStoreCell(bytecode.m_dst, resultReg);</span>
 102     }
 103 }
 104 
 105 void JIT::emitSlow_op_new_object(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 106 {
 107     linkAllSlowCases(iter);
 108 
 109     auto bytecode = currentInstruction-&gt;as&lt;OpNewObject&gt;();
 110     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 111     VirtualRegister dst = bytecode.m_dst;</span>
 112     Structure* structure = metadata.m_objectAllocationProfile.structure();
<span class="line-modified"> 113     callOperation(operationNewObject, TrustedImmPtr(&amp;vm()), structure);</span>
 114     emitStoreCell(dst, returnValueGPR);
 115 }
 116 
 117 void JIT::emit_op_overrides_has_instance(const Instruction* currentInstruction)
 118 {
 119     auto bytecode = currentInstruction-&gt;as&lt;OpOverridesHasInstance&gt;();
<span class="line-modified"> 120     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 121     VirtualRegister constructor = bytecode.m_constructor;</span>
<span class="line-modified"> 122     VirtualRegister hasInstanceValue = bytecode.m_hasInstanceValue;</span>
 123 
 124     emitLoadPayload(hasInstanceValue, regT0);
 125     // We don&#39;t jump if we know what Symbol.hasInstance would do.
 126     Jump hasInstanceValueNotCell = emitJumpIfNotJSCell(hasInstanceValue);
 127     Jump customhasInstanceValue = branchPtr(NotEqual, regT0, TrustedImmPtr(m_codeBlock-&gt;globalObject()-&gt;functionProtoHasInstanceSymbolFunction()));
 128 
 129     // We know that constructor is an object from the way bytecode is emitted for instanceof expressions.
 130     emitLoadPayload(constructor, regT0);
 131 
 132     // Check that constructor &#39;ImplementsDefaultHasInstance&#39; i.e. the object is not a C-API user nor a bound function.
 133     test8(Zero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(ImplementsDefaultHasInstance), regT0);
 134     Jump done = jump();
 135 
 136     hasInstanceValueNotCell.link(this);
 137     customhasInstanceValue.link(this);
 138     move(TrustedImm32(1), regT0);
 139 
 140     done.link(this);
 141     emitStoreBool(dst, regT0);
 142 
 143 }
 144 
 145 void JIT::emit_op_instanceof(const Instruction* currentInstruction)
 146 {
 147     auto bytecode = currentInstruction-&gt;as&lt;OpInstanceof&gt;();
<span class="line-modified"> 148     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 149     VirtualRegister value = bytecode.m_value;</span>
<span class="line-modified"> 150     VirtualRegister proto = bytecode.m_prototype;</span>
 151 
 152     // Load the operands into registers.
 153     // We use regT0 for baseVal since we will be done with this first, and we can then use it for the result.
 154     emitLoadPayload(value, regT2);
 155     emitLoadPayload(proto, regT1);
 156 
 157     // Check that proto are cells. baseVal must be a cell - this is checked by the get_by_id for Symbol.hasInstance.
 158     emitJumpSlowCaseIfNotJSCell(value);
 159     emitJumpSlowCaseIfNotJSCell(proto);
 160 
 161     JITInstanceOfGenerator gen(
<span class="line-modified"> 162         m_codeBlock, CodeOrigin(m_bytecodeIndex), CallSiteIndex(m_bytecodeIndex),</span>
 163         RegisterSet::stubUnavailableRegisters(),
 164         regT0, // result
 165         regT2, // value
 166         regT1, // proto
 167         regT3, regT4); // scratch
 168     gen.generateFastPath(*this);
 169     m_instanceOfs.append(gen);
 170 
 171     emitStoreBool(dst, regT0);
 172 }
 173 
 174 void JIT::emit_op_instanceof_custom(const Instruction*)
 175 {
 176     // This always goes to slow path since we expect it to be rare.
 177     addSlowCase(jump());
 178 }
 179 
 180 void JIT::emitSlow_op_instanceof(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 181 {
 182     linkAllSlowCases(iter);
 183 
 184     auto bytecode = currentInstruction-&gt;as&lt;OpInstanceof&gt;();
<span class="line-modified"> 185     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 186     VirtualRegister value = bytecode.m_value;</span>
<span class="line-modified"> 187     VirtualRegister proto = bytecode.m_prototype;</span>
 188 
 189     JITInstanceOfGenerator&amp; gen = m_instanceOfs[m_instanceOfIndex++];
 190 
 191     Label coldPathBegin = label();
 192     emitLoadTag(value, regT0);
 193     emitLoadTag(proto, regT3);
<span class="line-modified"> 194     Call call = callOperation(operationInstanceOfOptimize, dst, m_codeBlock-&gt;globalObject(), gen.stubInfo(), JSValueRegs(regT0, regT2), JSValueRegs(regT3, regT1));</span>
 195     gen.reportSlowPathCall(coldPathBegin, call);
 196 }
 197 
 198 void JIT::emitSlow_op_instanceof_custom(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 199 {
 200     linkAllSlowCases(iter);
 201 
 202     auto bytecode = currentInstruction-&gt;as&lt;OpInstanceofCustom&gt;();
<span class="line-modified"> 203     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 204     VirtualRegister value = bytecode.m_value;</span>
<span class="line-modified"> 205     VirtualRegister constructor = bytecode.m_constructor;</span>
<span class="line-modified"> 206     VirtualRegister hasInstanceValue = bytecode.m_hasInstanceValue;</span>
 207 
 208     emitLoad(value, regT1, regT0);
 209     emitLoadPayload(constructor, regT2);
 210     emitLoad(hasInstanceValue, regT4, regT3);
<span class="line-modified"> 211     callOperation(operationInstanceOfCustom, m_codeBlock-&gt;globalObject(), JSValueRegs(regT1, regT0), regT2, JSValueRegs(regT4, regT3));</span>
 212     emitStoreBool(dst, returnValueGPR);
 213 }
 214 
 215 void JIT::emit_op_is_empty(const Instruction* currentInstruction)
 216 {
 217     auto bytecode = currentInstruction-&gt;as&lt;OpIsEmpty&gt;();
<span class="line-modified"> 218     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 219     VirtualRegister value = bytecode.m_operand;</span>
 220 
 221     emitLoad(value, regT1, regT0);
 222     compare32(Equal, regT1, TrustedImm32(JSValue::EmptyValueTag), regT0);
 223 
 224     emitStoreBool(dst, regT0);
 225 }
 226 
 227 void JIT::emit_op_is_undefined(const Instruction* currentInstruction)
 228 {
 229     auto bytecode = currentInstruction-&gt;as&lt;OpIsUndefined&gt;();
<span class="line-modified"> 230     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 231     VirtualRegister value = bytecode.m_operand;</span>
 232 
 233     emitLoad(value, regT1, regT0);
 234     Jump isCell = branchIfCell(regT1);
 235 
 236     compare32(Equal, regT1, TrustedImm32(JSValue::UndefinedTag), regT0);
 237     Jump done = jump();
 238 
 239     isCell.link(this);
 240     Jump isMasqueradesAsUndefined = branchTest8(NonZero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined));
 241     move(TrustedImm32(0), regT0);
 242     Jump notMasqueradesAsUndefined = jump();
 243 
 244     isMasqueradesAsUndefined.link(this);
 245     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT1);
 246     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 247     loadPtr(Address(regT1, Structure::globalObjectOffset()), regT1);
 248     compare32(Equal, regT0, regT1, regT0);
 249 
 250     notMasqueradesAsUndefined.link(this);
 251     done.link(this);
 252     emitStoreBool(dst, regT0);
 253 }
 254 
 255 void JIT::emit_op_is_undefined_or_null(const Instruction* currentInstruction)
 256 {
 257     auto bytecode = currentInstruction-&gt;as&lt;OpIsUndefinedOrNull&gt;();
<span class="line-modified"> 258     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 259     VirtualRegister value = bytecode.m_operand;</span>
 260 
 261     emitLoadTag(value, regT0);
 262     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);
 263     or32(TrustedImm32(1), regT0);
 264     compare32(Equal, regT0, TrustedImm32(JSValue::NullTag), regT0);
 265     emitStoreBool(dst, regT0);
 266 }
 267 
 268 void JIT::emit_op_is_boolean(const Instruction* currentInstruction)
 269 {
 270     auto bytecode = currentInstruction-&gt;as&lt;OpIsBoolean&gt;();
<span class="line-modified"> 271     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 272     VirtualRegister value = bytecode.m_operand;</span>
 273 
 274     emitLoadTag(value, regT0);
 275     compare32(Equal, regT0, TrustedImm32(JSValue::BooleanTag), regT0);
 276     emitStoreBool(dst, regT0);
 277 }
 278 
 279 void JIT::emit_op_is_number(const Instruction* currentInstruction)
 280 {
 281     auto bytecode = currentInstruction-&gt;as&lt;OpIsNumber&gt;();
<span class="line-modified"> 282     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 283     VirtualRegister value = bytecode.m_operand;</span>
 284 
 285     emitLoadTag(value, regT0);
 286     add32(TrustedImm32(1), regT0);
 287     compare32(Below, regT0, TrustedImm32(JSValue::LowestTag + 1), regT0);
 288     emitStoreBool(dst, regT0);
 289 }
 290 
 291 void JIT::emit_op_is_cell_with_type(const Instruction* currentInstruction)
 292 {
 293     auto bytecode = currentInstruction-&gt;as&lt;OpIsCellWithType&gt;();
<span class="line-modified"> 294     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 295     VirtualRegister value = bytecode.m_operand;</span>
 296     int type = bytecode.m_type;
 297 
 298     emitLoad(value, regT1, regT0);
 299     Jump isNotCell = branchIfNotCell(regT1);
 300 
 301     compare8(Equal, Address(regT0, JSCell::typeInfoTypeOffset()), TrustedImm32(type), regT0);
 302     Jump done = jump();
 303 
 304     isNotCell.link(this);
 305     move(TrustedImm32(0), regT0);
 306 
 307     done.link(this);
 308     emitStoreBool(dst, regT0);
 309 }
 310 
 311 void JIT::emit_op_is_object(const Instruction* currentInstruction)
 312 {
 313     auto bytecode = currentInstruction-&gt;as&lt;OpIsObject&gt;();
<span class="line-modified"> 314     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 315     VirtualRegister value = bytecode.m_operand;</span>
 316 
 317     emitLoad(value, regT1, regT0);
 318     Jump isNotCell = branchIfNotCell(regT1);
 319 
 320     compare8(AboveOrEqual, Address(regT0, JSCell::typeInfoTypeOffset()), TrustedImm32(ObjectType), regT0);
 321     Jump done = jump();
 322 
 323     isNotCell.link(this);
 324     move(TrustedImm32(0), regT0);
 325 
 326     done.link(this);
 327     emitStoreBool(dst, regT0);
 328 }
 329 
 330 void JIT::emit_op_to_primitive(const Instruction* currentInstruction)
 331 {
 332     auto bytecode = currentInstruction-&gt;as&lt;OpToPrimitive&gt;();
<span class="line-modified"> 333     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 334     VirtualRegister src = bytecode.m_src;</span>
 335 
 336     emitLoad(src, regT1, regT0);
 337 
 338     Jump isImm = branchIfNotCell(regT1);
 339     addSlowCase(branchIfObject(regT0));
 340     isImm.link(this);
 341 
 342     if (dst != src)
 343         emitStore(dst, regT1, regT0);
 344 }
 345 
<span class="line-added"> 346 void JIT::emit_op_to_property_key(const Instruction* currentInstruction)</span>
<span class="line-added"> 347 {</span>
<span class="line-added"> 348     auto bytecode = currentInstruction-&gt;as&lt;OpToPropertyKey&gt;();</span>
<span class="line-added"> 349     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-added"> 350     VirtualRegister src = bytecode.m_src;</span>
<span class="line-added"> 351 </span>
<span class="line-added"> 352     emitLoad(src, regT1, regT0);</span>
<span class="line-added"> 353 </span>
<span class="line-added"> 354     addSlowCase(branchIfNotCell(regT1));</span>
<span class="line-added"> 355     Jump done = branchIfSymbol(regT0);</span>
<span class="line-added"> 356     addSlowCase(branchIfNotString(regT0));</span>
<span class="line-added"> 357 </span>
<span class="line-added"> 358     done.link(this);</span>
<span class="line-added"> 359     if (src != dst)</span>
<span class="line-added"> 360         emitStore(dst, regT1, regT0);</span>
<span class="line-added"> 361 }</span>
<span class="line-added"> 362 </span>
 363 void JIT::emit_op_set_function_name(const Instruction* currentInstruction)
 364 {
 365     auto bytecode = currentInstruction-&gt;as&lt;OpSetFunctionName&gt;();
<span class="line-modified"> 366     VirtualRegister func = bytecode.m_function;</span>
<span class="line-modified"> 367     VirtualRegister name = bytecode.m_name;</span>
 368     emitLoadPayload(func, regT1);
 369     emitLoad(name, regT3, regT2);
<span class="line-modified"> 370     callOperation(operationSetFunctionName, m_codeBlock-&gt;globalObject(), regT1, JSValueRegs(regT3, regT2));</span>
 371 }
 372 
 373 void JIT::emit_op_not(const Instruction* currentInstruction)
 374 {
 375     auto bytecode = currentInstruction-&gt;as&lt;OpNot&gt;();
<span class="line-modified"> 376     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 377     VirtualRegister src = bytecode.m_operand;</span>
 378 
 379     emitLoadTag(src, regT0);
 380 
 381     emitLoad(src, regT1, regT0);
 382     addSlowCase(branchIfNotBoolean(regT1, InvalidGPRReg));
 383     xor32(TrustedImm32(1), regT0);
 384 
 385     emitStoreBool(dst, regT0, (dst == src));
 386 }
 387 
 388 void JIT::emit_op_jfalse(const Instruction* currentInstruction)
 389 {
 390     auto bytecode = currentInstruction-&gt;as&lt;OpJfalse&gt;();
<span class="line-modified"> 391     VirtualRegister cond = bytecode.m_condition;</span>
 392     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 393 
 394     emitLoad(cond, regT1, regT0);
 395 
 396     JSValueRegs value(regT1, regT0);
 397     GPRReg scratch1 = regT2;
 398     GPRReg scratch2 = regT3;
 399     bool shouldCheckMasqueradesAsUndefined = true;
 400     addJump(branchIfFalsey(vm(), value, scratch1, scratch2, fpRegT0, fpRegT1, shouldCheckMasqueradesAsUndefined, m_codeBlock-&gt;globalObject()), target);
 401 }
 402 
 403 void JIT::emit_op_jtrue(const Instruction* currentInstruction)
 404 {
 405     auto bytecode = currentInstruction-&gt;as&lt;OpJtrue&gt;();
<span class="line-modified"> 406     VirtualRegister cond = bytecode.m_condition;</span>
 407     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 408 
 409     emitLoad(cond, regT1, regT0);
 410     bool shouldCheckMasqueradesAsUndefined = true;
 411     JSValueRegs value(regT1, regT0);
 412     GPRReg scratch1 = regT2;
 413     GPRReg scratch2 = regT3;
 414     addJump(branchIfTruthy(vm(), value, scratch1, scratch2, fpRegT0, fpRegT1, shouldCheckMasqueradesAsUndefined, m_codeBlock-&gt;globalObject()), target);
 415 }
 416 
 417 void JIT::emit_op_jeq_null(const Instruction* currentInstruction)
 418 {
 419     auto bytecode = currentInstruction-&gt;as&lt;OpJeqNull&gt;();
<span class="line-modified"> 420     VirtualRegister src = bytecode.m_value;</span>
 421     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 422 
 423     emitLoad(src, regT1, regT0);
 424 
 425     Jump isImmediate = branchIfNotCell(regT1);
 426 
 427     Jump isNotMasqueradesAsUndefined = branchTest8(Zero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined));
 428     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT2);
 429     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 430     addJump(branchPtr(Equal, Address(regT2, Structure::globalObjectOffset()), regT0), target);
 431     Jump masqueradesGlobalObjectIsForeign = jump();
 432 
 433     // Now handle the immediate cases - undefined &amp; null
 434     isImmediate.link(this);
 435     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);
 436     or32(TrustedImm32(1), regT1);
 437     addJump(branchIfNull(regT1), target);
 438 
 439     isNotMasqueradesAsUndefined.link(this);
 440     masqueradesGlobalObjectIsForeign.link(this);
 441 }
 442 
 443 void JIT::emit_op_jneq_null(const Instruction* currentInstruction)
 444 {
 445     auto bytecode = currentInstruction-&gt;as&lt;OpJneqNull&gt;();
<span class="line-modified"> 446     VirtualRegister src = bytecode.m_value;</span>
 447     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 448 
 449     emitLoad(src, regT1, regT0);
 450 
 451     Jump isImmediate = branchIfNotCell(regT1);
 452 
 453     addJump(branchTest8(Zero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined)), target);
 454     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT2);
 455     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 456     addJump(branchPtr(NotEqual, Address(regT2, Structure::globalObjectOffset()), regT0), target);
 457     Jump wasNotImmediate = jump();
 458 
 459     // Now handle the immediate cases - undefined &amp; null
 460     isImmediate.link(this);
 461 
 462     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);
 463     or32(TrustedImm32(1), regT1);
 464     addJump(branchIfNotNull(regT1), target);
 465 
 466     wasNotImmediate.link(this);
 467 }
 468 
 469 void JIT::emit_op_jundefined_or_null(const Instruction* currentInstruction)
 470 {
 471     auto bytecode = currentInstruction-&gt;as&lt;OpJundefinedOrNull&gt;();
<span class="line-modified"> 472     VirtualRegister value = bytecode.m_value;</span>
 473     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 474 
 475     emitLoadTag(value, regT0);
 476     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);
 477     or32(TrustedImm32(1), regT0);
 478     addJump(branchIfNull(regT0), target);
 479 }
 480 
 481 void JIT::emit_op_jnundefined_or_null(const Instruction* currentInstruction)
 482 {
 483     auto bytecode = currentInstruction-&gt;as&lt;OpJnundefinedOrNull&gt;();
<span class="line-modified"> 484     VirtualRegister value = bytecode.m_value;</span>
 485     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 486 
 487     emitLoadTag(value, regT0);
 488     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);
 489     or32(TrustedImm32(1), regT0);
 490     addJump(branchIfNotNull(regT0), target);
 491 }
 492 
 493 void JIT::emit_op_jneq_ptr(const Instruction* currentInstruction)
 494 {
 495     auto bytecode = currentInstruction-&gt;as&lt;OpJneqPtr&gt;();
 496     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 497     VirtualRegister src = bytecode.m_value;</span>
<span class="line-modified"> 498     JSValue specialPointer = getConstantOperand(bytecode.m_specialPointer);</span>
<span class="line-added"> 499     ASSERT(specialPointer.isCell());</span>
 500     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 501 
 502     emitLoad(src, regT1, regT0);
 503     Jump notCell = branchIfNotCell(regT1);
<span class="line-modified"> 504     Jump equal = branchPtr(Equal, regT0, TrustedImmPtr(specialPointer.asCell()));</span>
 505     notCell.link(this);
 506     store8(TrustedImm32(1), &amp;metadata.m_hasJumped);
 507     addJump(jump(), target);
 508     equal.link(this);
 509 }
 510 
 511 void JIT::emit_op_eq(const Instruction* currentInstruction)
 512 {
 513     auto bytecode = currentInstruction-&gt;as&lt;OpEq&gt;();
 514 
<span class="line-modified"> 515     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 516     VirtualRegister src1 = bytecode.m_lhs;</span>
<span class="line-modified"> 517     VirtualRegister src2 = bytecode.m_rhs;</span>
 518 
 519     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 520     addSlowCase(branch32(NotEqual, regT1, regT3));
 521     addSlowCase(branchIfCell(regT1));
 522     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 523 
 524     compare32(Equal, regT0, regT2, regT0);
 525 
 526     emitStoreBool(dst, regT0);
 527 }
 528 
 529 void JIT::emitSlow_op_eq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 530 {
 531     auto bytecode = currentInstruction-&gt;as&lt;OpEq&gt;();
<span class="line-modified"> 532     VirtualRegister dst = bytecode.m_dst;</span>
 533 
 534     JumpList storeResult;
 535     JumpList genericCase;
 536 
 537     genericCase.append(getSlowCase(iter)); // tags not equal
 538 
 539     linkSlowCase(iter); // tags equal and JSCell
 540     genericCase.append(branchIfNotString(regT0));
 541     genericCase.append(branchIfNotString(regT2));
 542 
 543     // String case.
<span class="line-modified"> 544     callOperation(operationCompareStringEq, m_codeBlock-&gt;globalObject(), regT0, regT2);</span>
 545     storeResult.append(jump());
 546 
 547     // Generic case.
 548     genericCase.append(getSlowCase(iter)); // doubles
 549     genericCase.link(this);
<span class="line-modified"> 550     callOperation(operationCompareEq, m_codeBlock-&gt;globalObject(), JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));</span>
 551 
 552     storeResult.link(this);
 553     emitStoreBool(dst, returnValueGPR);
 554 }
 555 
 556 void JIT::emit_op_jeq(const Instruction* currentInstruction)
 557 {
 558     auto bytecode = currentInstruction-&gt;as&lt;OpJeq&gt;();
 559     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
<span class="line-modified"> 560     VirtualRegister src1 = bytecode.m_lhs;</span>
<span class="line-modified"> 561     VirtualRegister src2 = bytecode.m_rhs;</span>
 562 
 563     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 564     addSlowCase(branch32(NotEqual, regT1, regT3));
 565     addSlowCase(branchIfCell(regT1));
 566     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 567 
 568     addJump(branch32(Equal, regT0, regT2), target);
 569 }
 570 
 571 void JIT::compileOpEqJumpSlow(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter, CompileOpEqType type, int jumpTarget)
 572 {
 573     JumpList done;
 574     JumpList genericCase;
 575 
 576     genericCase.append(getSlowCase(iter)); // tags not equal
 577 
 578     linkSlowCase(iter); // tags equal and JSCell
 579     genericCase.append(branchIfNotString(regT0));
 580     genericCase.append(branchIfNotString(regT2));
 581 
 582     // String case.
<span class="line-modified"> 583     callOperation(operationCompareStringEq, m_codeBlock-&gt;globalObject(), regT0, regT2);</span>
 584     emitJumpSlowToHot(branchTest32(type == CompileOpEqType::Eq ? NonZero : Zero, returnValueGPR), jumpTarget);
 585     done.append(jump());
 586 
 587     // Generic case.
 588     genericCase.append(getSlowCase(iter)); // doubles
 589     genericCase.link(this);
<span class="line-modified"> 590     callOperation(operationCompareEq, m_codeBlock-&gt;globalObject(), JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));</span>
 591     emitJumpSlowToHot(branchTest32(type == CompileOpEqType::Eq ? NonZero : Zero, returnValueGPR), jumpTarget);
 592 
 593     done.link(this);
 594 }
 595 
 596 void JIT::emitSlow_op_jeq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 597 {
 598     auto bytecode = currentInstruction-&gt;as&lt;OpJeq&gt;();
 599     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 600     compileOpEqJumpSlow(iter, CompileOpEqType::Eq, target);
 601 }
 602 
 603 void JIT::emit_op_neq(const Instruction* currentInstruction)
 604 {
 605     auto bytecode = currentInstruction-&gt;as&lt;OpNeq&gt;();
<span class="line-modified"> 606     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 607     VirtualRegister src1 = bytecode.m_lhs;</span>
<span class="line-modified"> 608     VirtualRegister src2 = bytecode.m_rhs;</span>
 609 
 610     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 611     addSlowCase(branch32(NotEqual, regT1, regT3));
 612     addSlowCase(branchIfCell(regT1));
 613     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 614 
 615     compare32(NotEqual, regT0, regT2, regT0);
 616 
 617     emitStoreBool(dst, regT0);
 618 }
 619 
 620 void JIT::emitSlow_op_neq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 621 {
 622     auto bytecode = currentInstruction-&gt;as&lt;OpNeq&gt;();
<span class="line-modified"> 623     VirtualRegister dst = bytecode.m_dst;</span>
 624 
 625     JumpList storeResult;
 626     JumpList genericCase;
 627 
 628     genericCase.append(getSlowCase(iter)); // tags not equal
 629 
 630     linkSlowCase(iter); // tags equal and JSCell
 631     genericCase.append(branchIfNotString(regT0));
 632     genericCase.append(branchIfNotString(regT2));
 633 
 634     // String case.
<span class="line-modified"> 635     callOperation(operationCompareStringEq, m_codeBlock-&gt;globalObject(), regT0, regT2);</span>
 636     storeResult.append(jump());
 637 
 638     // Generic case.
 639     genericCase.append(getSlowCase(iter)); // doubles
 640     genericCase.link(this);
<span class="line-modified"> 641     callOperation(operationCompareEq, m_codeBlock-&gt;globalObject(), JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));</span>
 642 
 643     storeResult.link(this);
 644     xor32(TrustedImm32(0x1), returnValueGPR);
 645     emitStoreBool(dst, returnValueGPR);
 646 }
 647 
 648 void JIT::emit_op_jneq(const Instruction* currentInstruction)
 649 {
 650     auto bytecode = currentInstruction-&gt;as&lt;OpJneq&gt;();
 651     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
<span class="line-modified"> 652     VirtualRegister src1 = bytecode.m_lhs;</span>
<span class="line-modified"> 653     VirtualRegister src2 = bytecode.m_rhs;</span>
 654 
 655     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 656     addSlowCase(branch32(NotEqual, regT1, regT3));
 657     addSlowCase(branchIfCell(regT1));
 658     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 659 
 660     addJump(branch32(NotEqual, regT0, regT2), target);
 661 }
 662 
 663 void JIT::emitSlow_op_jneq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 664 {
 665     auto bytecode = currentInstruction-&gt;as&lt;OpJneq&gt;();
 666     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 667     compileOpEqJumpSlow(iter, CompileOpEqType::NEq, target);
 668 }
 669 
 670 template &lt;typename Op&gt;
 671 void JIT::compileOpStrictEq(const Instruction* currentInstruction, CompileOpStrictEqType type)
 672 {
 673     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 674     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 675     VirtualRegister src1 = bytecode.m_lhs;</span>
<span class="line-modified"> 676     VirtualRegister src2 = bytecode.m_rhs;</span>
 677 
 678     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 679 
 680     // Bail if the tags differ, or are double.
 681     addSlowCase(branch32(NotEqual, regT1, regT3));
 682     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 683 
 684     // Jump to a slow case if both are strings or symbols (non object).
 685     Jump notCell = branchIfNotCell(regT1);
 686     Jump firstIsObject = branchIfObject(regT0);
 687     addSlowCase(branchIfNotObject(regT2));
 688     notCell.link(this);
 689     firstIsObject.link(this);
 690 
 691     // Simply compare the payloads.
 692     if (type == CompileOpStrictEqType::StrictEq)
 693         compare32(Equal, regT0, regT2, regT0);
 694     else
 695         compare32(NotEqual, regT0, regT2, regT0);
 696 
 697     emitStoreBool(dst, regT0);
 698 }
 699 
 700 void JIT::emit_op_stricteq(const Instruction* currentInstruction)
 701 {
 702     compileOpStrictEq&lt;OpStricteq&gt;(currentInstruction, CompileOpStrictEqType::StrictEq);
 703 }
 704 
 705 void JIT::emit_op_nstricteq(const Instruction* currentInstruction)
 706 {
 707     compileOpStrictEq&lt;OpNstricteq&gt;(currentInstruction, CompileOpStrictEqType::NStrictEq);
 708 }
 709 
 710 template&lt;typename Op&gt;
 711 void JIT::compileOpStrictEqJump(const Instruction* currentInstruction, CompileOpStrictEqType type)
 712 {
 713     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
 714     int target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
<span class="line-modified"> 715     VirtualRegister src1 = bytecode.m_lhs;</span>
<span class="line-modified"> 716     VirtualRegister src2 = bytecode.m_rhs;</span>
 717 
 718     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 719 
 720     // Bail if the tags differ, or are double.
 721     addSlowCase(branch32(NotEqual, regT1, regT3));
 722     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 723 
 724     // Jump to a slow case if both are strings or symbols (non object).
 725     Jump notCell = branchIfNotCell(regT1);
 726     Jump firstIsObject = branchIfObject(regT0);
 727     addSlowCase(branchIfNotObject(regT2));
 728     notCell.link(this);
 729     firstIsObject.link(this);
 730 
 731     // Simply compare the payloads.
 732     if (type == CompileOpStrictEqType::StrictEq)
 733         addJump(branch32(Equal, regT0, regT2), target);
 734     else
 735         addJump(branch32(NotEqual, regT0, regT2), target);
 736 }
 737 
 738 void JIT::emit_op_jstricteq(const Instruction* currentInstruction)
 739 {
 740     compileOpStrictEqJump&lt;OpJstricteq&gt;(currentInstruction, CompileOpStrictEqType::StrictEq);
 741 }
 742 
 743 void JIT::emit_op_jnstricteq(const Instruction* currentInstruction)
 744 {
 745     compileOpStrictEqJump&lt;OpJnstricteq&gt;(currentInstruction, CompileOpStrictEqType::NStrictEq);
 746 }
 747 
 748 void JIT::emitSlow_op_jstricteq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 749 {
 750     linkAllSlowCases(iter);
 751 
 752     auto bytecode = currentInstruction-&gt;as&lt;OpJstricteq&gt;();
 753     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
<span class="line-modified"> 754     callOperation(operationCompareStrictEq, m_codeBlock-&gt;globalObject(), JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));</span>
 755     emitJumpSlowToHot(branchTest32(NonZero, returnValueGPR), target);
 756 }
 757 
 758 void JIT::emitSlow_op_jnstricteq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 759 {
 760     linkAllSlowCases(iter);
 761 
 762     auto bytecode = currentInstruction-&gt;as&lt;OpJnstricteq&gt;();
 763     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
<span class="line-modified"> 764     callOperation(operationCompareStrictEq, m_codeBlock-&gt;globalObject(), JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));</span>
 765     emitJumpSlowToHot(branchTest32(Zero, returnValueGPR), target);
 766 }
 767 
 768 void JIT::emit_op_eq_null(const Instruction* currentInstruction)
 769 {
 770     auto bytecode = currentInstruction-&gt;as&lt;OpEqNull&gt;();
<span class="line-modified"> 771     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 772     VirtualRegister src = bytecode.m_operand;</span>
 773 
 774     emitLoad(src, regT1, regT0);
 775     Jump isImmediate = branchIfNotCell(regT1);
 776 
 777     Jump isMasqueradesAsUndefined = branchTest8(NonZero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined));
 778     move(TrustedImm32(0), regT1);
 779     Jump wasNotMasqueradesAsUndefined = jump();
 780 
 781     isMasqueradesAsUndefined.link(this);
 782     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT2);
 783     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 784     loadPtr(Address(regT2, Structure::globalObjectOffset()), regT2);
 785     compare32(Equal, regT0, regT2, regT1);
 786     Jump wasNotImmediate = jump();
 787 
 788     isImmediate.link(this);
 789 
 790     compare32(Equal, regT1, TrustedImm32(JSValue::NullTag), regT2);
 791     compare32(Equal, regT1, TrustedImm32(JSValue::UndefinedTag), regT1);
 792     or32(regT2, regT1);
 793 
 794     wasNotImmediate.link(this);
 795     wasNotMasqueradesAsUndefined.link(this);
 796 
 797     emitStoreBool(dst, regT1);
 798 }
 799 
 800 void JIT::emit_op_neq_null(const Instruction* currentInstruction)
 801 {
 802     auto bytecode = currentInstruction-&gt;as&lt;OpNeqNull&gt;();
<span class="line-modified"> 803     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 804     VirtualRegister src = bytecode.m_operand;</span>
 805 
 806     emitLoad(src, regT1, regT0);
 807     Jump isImmediate = branchIfNotCell(regT1);
 808 
 809     Jump isMasqueradesAsUndefined = branchTest8(NonZero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined));
 810     move(TrustedImm32(1), regT1);
 811     Jump wasNotMasqueradesAsUndefined = jump();
 812 
 813     isMasqueradesAsUndefined.link(this);
 814     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT2);
 815     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 816     loadPtr(Address(regT2, Structure::globalObjectOffset()), regT2);
 817     compare32(NotEqual, regT0, regT2, regT1);
 818     Jump wasNotImmediate = jump();
 819 
 820     isImmediate.link(this);
 821 
 822     compare32(NotEqual, regT1, TrustedImm32(JSValue::NullTag), regT2);
 823     compare32(NotEqual, regT1, TrustedImm32(JSValue::UndefinedTag), regT1);
 824     and32(regT2, regT1);
 825 
 826     wasNotImmediate.link(this);
 827     wasNotMasqueradesAsUndefined.link(this);
 828 
 829     emitStoreBool(dst, regT1);
 830 }
 831 
 832 void JIT::emit_op_throw(const Instruction* currentInstruction)
 833 {
 834     auto bytecode = currentInstruction-&gt;as&lt;OpThrow&gt;();
 835     ASSERT(regT0 == returnValueGPR);
 836     copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm().topEntryFrame);
<span class="line-modified"> 837     emitLoad(bytecode.m_value, regT1, regT0);</span>
<span class="line-modified"> 838     callOperationNoExceptionCheck(operationThrow, m_codeBlock-&gt;globalObject(), JSValueRegs(regT1, regT0));</span>
 839     jumpToExceptionHandler(vm());
 840 }
 841 
 842 void JIT::emit_op_to_number(const Instruction* currentInstruction)
 843 {
 844     auto bytecode = currentInstruction-&gt;as&lt;OpToNumber&gt;();
<span class="line-modified"> 845     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 846     VirtualRegister src = bytecode.m_operand;</span>
 847 
 848     emitLoad(src, regT1, regT0);
 849 
 850     Jump isInt32 = branchIfInt32(regT1);
 851     addSlowCase(branch32(AboveOrEqual, regT1, TrustedImm32(JSValue::LowestTag)));
 852     isInt32.link(this);
 853 
 854     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 855     if (src != dst)
 856         emitStore(dst, regT1, regT0);
 857 }
 858 
<span class="line-added"> 859 void JIT::emit_op_to_numeric(const Instruction* currentInstruction)</span>
<span class="line-added"> 860 {</span>
<span class="line-added"> 861     auto bytecode = currentInstruction-&gt;as&lt;OpToNumeric&gt;();</span>
<span class="line-added"> 862     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-added"> 863     VirtualRegister src = bytecode.m_operand;</span>
<span class="line-added"> 864     JSValueRegs argumentValueRegs(regT1, regT0);</span>
<span class="line-added"> 865 </span>
<span class="line-added"> 866     emitLoad(src, regT1, regT0);</span>
<span class="line-added"> 867 </span>
<span class="line-added"> 868     Jump isNotCell = branchIfNotCell(regT1);</span>
<span class="line-added"> 869     addSlowCase(branchIfNotBigInt(regT0));</span>
<span class="line-added"> 870     Jump isBigInt = jump();</span>
<span class="line-added"> 871 </span>
<span class="line-added"> 872     isNotCell.link(this);</span>
<span class="line-added"> 873     addSlowCase(branchIfNotNumber(argumentValueRegs, regT2));</span>
<span class="line-added"> 874     isBigInt.link(this);</span>
<span class="line-added"> 875 </span>
<span class="line-added"> 876     emitValueProfilingSite(bytecode.metadata(m_codeBlock));</span>
<span class="line-added"> 877     if (src != dst)</span>
<span class="line-added"> 878         emitStore(dst, regT1, regT0);</span>
<span class="line-added"> 879 }</span>
<span class="line-added"> 880 </span>
 881 void JIT::emit_op_to_string(const Instruction* currentInstruction)
 882 {
 883     auto bytecode = currentInstruction-&gt;as&lt;OpToString&gt;();
<span class="line-modified"> 884     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 885     VirtualRegister src = bytecode.m_operand;</span>
 886 
 887     emitLoad(src, regT1, regT0);
 888 
 889     addSlowCase(branchIfNotCell(regT1));
 890     addSlowCase(branchIfNotString(regT0));
 891 
 892     if (src != dst)
 893         emitStore(dst, regT1, regT0);
 894 }
 895 
 896 void JIT::emit_op_to_object(const Instruction* currentInstruction)
 897 {
 898     auto bytecode = currentInstruction-&gt;as&lt;OpToObject&gt;();
<span class="line-modified"> 899     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 900     VirtualRegister src = bytecode.m_operand;</span>
 901 
 902     emitLoad(src, regT1, regT0);
 903 
 904     addSlowCase(branchIfNotCell(regT1));
 905     addSlowCase(branchIfNotObject(regT0));
 906 
 907     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 908     if (src != dst)
 909         emitStore(dst, regT1, regT0);
 910 }
 911 
 912 void JIT::emit_op_catch(const Instruction* currentInstruction)
 913 {
 914     auto bytecode = currentInstruction-&gt;as&lt;OpCatch&gt;();
 915 
 916     restoreCalleeSavesFromEntryFrameCalleeSavesBuffer(vm().topEntryFrame);
 917 
 918     move(TrustedImmPtr(m_vm), regT3);
 919     // operationThrow returns the callFrame for the handler.
 920     load32(Address(regT3, VM::callFrameForCatchOffset()), callFrameRegister);
 921     storePtr(TrustedImmPtr(nullptr), Address(regT3, VM::callFrameForCatchOffset()));
 922 
 923     addPtr(TrustedImm32(stackPointerOffsetFor(codeBlock()) * sizeof(Register)), callFrameRegister, stackPointerRegister);
 924 
<span class="line-modified"> 925     callOperationNoExceptionCheck(operationCheckIfExceptionIsUncatchableAndNotifyProfiler, TrustedImmPtr(&amp;vm()));</span>
 926     Jump isCatchableException = branchTest32(Zero, returnValueGPR);
 927     jumpToExceptionHandler(vm());
 928     isCatchableException.link(this);
 929 
 930     move(TrustedImmPtr(m_vm), regT3);
 931 
 932     // Now store the exception returned by operationThrow.
 933     load32(Address(regT3, VM::exceptionOffset()), regT2);
 934     move(TrustedImm32(JSValue::CellTag), regT1);
 935 
 936     store32(TrustedImm32(0), Address(regT3, VM::exceptionOffset()));
 937 
<span class="line-modified"> 938     emitStore(bytecode.m_exception, regT1, regT2);</span>

 939 
 940     load32(Address(regT2, Exception::valueOffset() + OBJECT_OFFSETOF(JSValue, u.asBits.payload)), regT0);
 941     load32(Address(regT2, Exception::valueOffset() + OBJECT_OFFSETOF(JSValue, u.asBits.tag)), regT1);
 942 
<span class="line-modified"> 943     emitStore(bytecode.m_thrownValue, regT1, regT0);</span>

 944 
 945 #if ENABLE(DFG_JIT)
 946     // FIXME: consider inline caching the process of doing OSR entry, including
 947     // argument type proofs, storing locals to the buffer, etc
 948     // https://bugs.webkit.org/show_bug.cgi?id=175598
 949 
 950     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified"> 951     ValueProfileAndVirtualRegisterBuffer* buffer = metadata.m_buffer;</span>
 952     if (buffer || !shouldEmitProfiling())
<span class="line-modified"> 953         callOperation(operationTryOSREnterAtCatch, &amp;vm(), m_bytecodeIndex.asBits());</span>
 954     else
<span class="line-modified"> 955         callOperation(operationTryOSREnterAtCatchAndValueProfile, &amp;vm(), m_bytecodeIndex.asBits());</span>
 956     auto skipOSREntry = branchTestPtr(Zero, returnValueGPR);
 957     emitRestoreCalleeSaves();
 958     farJump(returnValueGPR, NoPtrTag);
 959     skipOSREntry.link(this);
 960     if (buffer &amp;&amp; shouldEmitProfiling()) {
<span class="line-modified"> 961         buffer-&gt;forEach([&amp;] (ValueProfileAndVirtualRegister&amp; profile) {</span>
 962             JSValueRegs regs(regT1, regT0);
 963             emitGetVirtualRegister(profile.m_operand, regs);
 964             emitValueProfilingSite(static_cast&lt;ValueProfile&amp;&gt;(profile));
 965         });
 966     }
 967 #endif // ENABLE(DFG_JIT)
 968 }
 969 
 970 void JIT::emit_op_identity_with_profile(const Instruction*)
 971 {
 972     // We don&#39;t need to do anything here...
 973 }
 974 
 975 void JIT::emit_op_get_parent_scope(const Instruction* currentInstruction)
 976 {
 977     auto bytecode = currentInstruction-&gt;as&lt;OpGetParentScope&gt;();
<span class="line-modified"> 978     VirtualRegister currentScope = bytecode.m_scope;</span>
 979     emitLoadPayload(currentScope, regT0);
 980     loadPtr(Address(regT0, JSScope::offsetOfNext()), regT0);
<span class="line-modified"> 981     emitStoreCell(bytecode.m_dst, regT0);</span>
 982 }
 983 
 984 void JIT::emit_op_switch_imm(const Instruction* currentInstruction)
 985 {
 986     auto bytecode = currentInstruction-&gt;as&lt;OpSwitchImm&gt;();
 987     size_t tableIndex = bytecode.m_tableIndex;
 988     unsigned defaultOffset = jumpTarget(currentInstruction, bytecode.m_defaultOffset);
<span class="line-modified"> 989     VirtualRegister scrutinee = bytecode.m_scrutinee;</span>
 990 
 991     // create jump table for switch destinations, track this switch statement.
 992     SimpleJumpTable* jumpTable = &amp;m_codeBlock-&gt;switchJumpTable(tableIndex);
<span class="line-modified"> 993     m_switches.append(SwitchRecord(jumpTable, m_bytecodeIndex, defaultOffset, SwitchRecord::Immediate));</span>
 994     jumpTable-&gt;ensureCTITable();
 995 
 996     emitLoad(scrutinee, regT1, regT0);
<span class="line-modified"> 997     callOperation(operationSwitchImmWithUnknownKeyType, TrustedImmPtr(&amp;vm()), JSValueRegs(regT1, regT0), tableIndex);</span>
 998     farJump(returnValueGPR, NoPtrTag);
 999 }
1000 
1001 void JIT::emit_op_switch_char(const Instruction* currentInstruction)
1002 {
1003     auto bytecode = currentInstruction-&gt;as&lt;OpSwitchChar&gt;();
1004     size_t tableIndex = bytecode.m_tableIndex;
1005     unsigned defaultOffset = jumpTarget(currentInstruction, bytecode.m_defaultOffset);
<span class="line-modified">1006     VirtualRegister scrutinee = bytecode.m_scrutinee;</span>
1007 
1008     // create jump table for switch destinations, track this switch statement.
1009     SimpleJumpTable* jumpTable = &amp;m_codeBlock-&gt;switchJumpTable(tableIndex);
<span class="line-modified">1010     m_switches.append(SwitchRecord(jumpTable, m_bytecodeIndex, defaultOffset, SwitchRecord::Character));</span>
1011     jumpTable-&gt;ensureCTITable();
1012 
1013     emitLoad(scrutinee, regT1, regT0);
<span class="line-modified">1014     callOperation(operationSwitchCharWithUnknownKeyType, m_codeBlock-&gt;globalObject(), JSValueRegs(regT1, regT0), tableIndex);</span>
1015     farJump(returnValueGPR, NoPtrTag);
1016 }
1017 
1018 void JIT::emit_op_switch_string(const Instruction* currentInstruction)
1019 {
1020     auto bytecode = currentInstruction-&gt;as&lt;OpSwitchString&gt;();
1021     size_t tableIndex = bytecode.m_tableIndex;
1022     unsigned defaultOffset = jumpTarget(currentInstruction, bytecode.m_defaultOffset);
<span class="line-modified">1023     VirtualRegister scrutinee = bytecode.m_scrutinee;</span>
1024 
1025     // create jump table for switch destinations, track this switch statement.
1026     StringJumpTable* jumpTable = &amp;m_codeBlock-&gt;stringSwitchJumpTable(tableIndex);
<span class="line-modified">1027     m_switches.append(SwitchRecord(jumpTable, m_bytecodeIndex, defaultOffset));</span>
1028 
1029     emitLoad(scrutinee, regT1, regT0);
<span class="line-modified">1030     callOperation(operationSwitchStringWithUnknownKeyType, m_codeBlock-&gt;globalObject(), JSValueRegs(regT1, regT0), tableIndex);</span>
1031     farJump(returnValueGPR, NoPtrTag);
1032 }
1033 
1034 void JIT::emit_op_debug(const Instruction* currentInstruction)
1035 {
1036     auto bytecode = currentInstruction-&gt;as&lt;OpDebug&gt;();
1037     load32(codeBlock()-&gt;debuggerRequestsAddress(), regT0);
1038     Jump noDebuggerRequests = branchTest32(Zero, regT0);
<span class="line-modified">1039     callOperation(operationDebug, &amp;vm(), static_cast&lt;int&gt;(bytecode.m_debugHookType));</span>
1040     noDebuggerRequests.link(this);
1041 }
1042 
<span class="line-added">1043 </span>
<span class="line-added">1044 void JIT::emit_op_enter(const Instruction* currentInstruction)</span>
<span class="line-added">1045 {</span>
<span class="line-added">1046     emitEnterOptimizationCheck();</span>
<span class="line-added">1047 </span>
<span class="line-added">1048     // Even though JIT code doesn&#39;t use them, we initialize our constant</span>
<span class="line-added">1049     // registers to zap stale pointers, to avoid unnecessarily prolonging</span>
<span class="line-added">1050     // object lifetime and increasing GC pressure.</span>
<span class="line-added">1051     for (int i = CodeBlock::llintBaselineCalleeSaveSpaceAsVirtualRegisters(); i &lt; m_codeBlock-&gt;numVars(); ++i)</span>
<span class="line-added">1052         emitStore(virtualRegisterForLocal(i), jsUndefined());</span>
<span class="line-added">1053 </span>
<span class="line-added">1054     JITSlowPathCall slowPathCall(this, currentInstruction, slow_path_enter);</span>
<span class="line-added">1055     slowPathCall.call();</span>
<span class="line-added">1056 }</span>
<span class="line-added">1057 </span>
1058 void JIT::emit_op_get_scope(const Instruction* currentInstruction)
1059 {
1060     auto bytecode = currentInstruction-&gt;as&lt;OpGetScope&gt;();
<span class="line-modified">1061     VirtualRegister dst = bytecode.m_dst;</span>
1062     emitGetFromCallFrameHeaderPtr(CallFrameSlot::callee, regT0);
1063     loadPtr(Address(regT0, JSFunction::offsetOfScopeChain()), regT0);
1064     emitStoreCell(dst, regT0);
1065 }
1066 
1067 void JIT::emit_op_create_this(const Instruction* currentInstruction)
1068 {
1069     auto bytecode = currentInstruction-&gt;as&lt;OpCreateThis&gt;();
1070     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified">1071     VirtualRegister callee = bytecode.m_callee;</span>
1072     WriteBarrierBase&lt;JSCell&gt;* cachedFunction = &amp;metadata.m_cachedCallee;
1073     RegisterID calleeReg = regT0;
1074     RegisterID rareDataReg = regT4;
1075     RegisterID resultReg = regT0;
1076     RegisterID allocatorReg = regT1;
1077     RegisterID structureReg = regT2;
1078     RegisterID cachedFunctionReg = regT4;
1079     RegisterID scratchReg = regT3;
1080 
1081     emitLoadPayload(callee, calleeReg);
1082     addSlowCase(branchIfNotFunction(calleeReg));
<span class="line-modified">1083     loadPtr(Address(calleeReg, JSFunction::offsetOfExecutableOrRareData()), rareDataReg);</span>
<span class="line-modified">1084     addSlowCase(branchTestPtr(Zero, rareDataReg, TrustedImm32(JSFunction::rareDataTag)));</span>
<span class="line-modified">1085     load32(Address(rareDataReg, FunctionRareData::offsetOfObjectAllocationProfile() + ObjectAllocationProfileWithPrototype::offsetOfAllocator() - JSFunction::rareDataTag), allocatorReg);</span>
<span class="line-modified">1086     loadPtr(Address(rareDataReg, FunctionRareData::offsetOfObjectAllocationProfile() + ObjectAllocationProfileWithPrototype::offsetOfStructure() - JSFunction::rareDataTag), structureReg);</span>
1087 
1088     loadPtr(cachedFunction, cachedFunctionReg);
1089     Jump hasSeenMultipleCallees = branchPtr(Equal, cachedFunctionReg, TrustedImmPtr(JSCell::seenMultipleCalleeObjects()));
1090     addSlowCase(branchPtr(NotEqual, calleeReg, cachedFunctionReg));
1091     hasSeenMultipleCallees.link(this);
1092 
1093     JumpList slowCases;
1094     auto butterfly = TrustedImmPtr(nullptr);
1095     emitAllocateJSObject(resultReg, JITAllocator::variable(), allocatorReg, structureReg, butterfly, scratchReg, slowCases);
1096     load8(Address(structureReg, Structure::inlineCapacityOffset()), scratchReg);
1097     emitInitializeInlineStorage(resultReg, scratchReg);
1098     addSlowCase(slowCases);
<span class="line-modified">1099     emitStoreCell(bytecode.m_dst, resultReg);</span>
1100 }
1101 
1102 void JIT::emit_op_to_this(const Instruction* currentInstruction)
1103 {
1104     auto bytecode = currentInstruction-&gt;as&lt;OpToThis&gt;();
1105     auto&amp; metadata = bytecode.metadata(m_codeBlock);
1106     StructureID* cachedStructureID = &amp;metadata.m_cachedStructureID;
<span class="line-modified">1107     VirtualRegister thisRegister = bytecode.m_srcDst;</span>
1108 
1109     emitLoad(thisRegister, regT3, regT2);
1110 
1111     addSlowCase(branchIfNotCell(regT3));
1112     addSlowCase(branchIfNotType(regT2, FinalObjectType));
1113     loadPtr(Address(regT2, JSCell::structureIDOffset()), regT0);
1114     load32(cachedStructureID, regT2);
1115     addSlowCase(branchPtr(NotEqual, regT0, regT2));
1116 }
1117 
1118 void JIT::emit_op_check_tdz(const Instruction* currentInstruction)
1119 {
1120     auto bytecode = currentInstruction-&gt;as&lt;OpCheckTdz&gt;();
<span class="line-modified">1121     emitLoadTag(bytecode.m_targetVirtualRegister, regT0);</span>
1122     addSlowCase(branchIfEmpty(regT0));
1123 }
1124 
1125 void JIT::emit_op_has_structure_property(const Instruction* currentInstruction)
1126 {
1127     auto bytecode = currentInstruction-&gt;as&lt;OpHasStructureProperty&gt;();
<span class="line-modified">1128     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified">1129     VirtualRegister base = bytecode.m_base;</span>
<span class="line-modified">1130     VirtualRegister enumerator = bytecode.m_enumerator;</span>
1131 
1132     emitLoadPayload(base, regT0);
1133     emitJumpSlowCaseIfNotJSCell(base);
1134 
1135     emitLoadPayload(enumerator, regT1);
1136 
1137     load32(Address(regT0, JSCell::structureIDOffset()), regT0);
1138     addSlowCase(branch32(NotEqual, regT0, Address(regT1, JSPropertyNameEnumerator::cachedStructureIDOffset())));
1139 
1140     move(TrustedImm32(1), regT0);
1141     emitStoreBool(dst, regT0);
1142 }
1143 
1144 void JIT::privateCompileHasIndexedProperty(ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)
1145 {
1146     const Instruction* currentInstruction = m_codeBlock-&gt;instructions().at(byValInfo-&gt;bytecodeIndex).ptr();
1147 
1148     PatchableJump badType;
1149 
1150     // FIXME: Add support for other types like TypedArrays and Arguments.
</pre>
<hr />
<pre>
1155 
1156     LinkBuffer patchBuffer(*this, m_codeBlock);
1157 
1158     patchBuffer.link(badType, byValInfo-&gt;slowPathTarget);
1159     patchBuffer.link(slowCases, byValInfo-&gt;slowPathTarget);
1160 
1161     patchBuffer.link(done, byValInfo-&gt;badTypeDoneTarget);
1162 
1163     byValInfo-&gt;stubRoutine = FINALIZE_CODE_FOR_STUB(
1164         m_codeBlock, patchBuffer, JITStubRoutinePtrTag,
1165         &quot;Baseline has_indexed_property stub for %s, return point %p&quot;, toCString(*m_codeBlock).data(), returnAddress.value());
1166 
1167     MacroAssembler::repatchJump(byValInfo-&gt;badTypeJump, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(byValInfo-&gt;stubRoutine-&gt;code().code()));
1168     MacroAssembler::repatchCall(CodeLocationCall&lt;NoPtrTag&gt;(MacroAssemblerCodePtr&lt;NoPtrTag&gt;(returnAddress)), FunctionPtr&lt;OperationPtrTag&gt;(operationHasIndexedPropertyGeneric));
1169 }
1170 
1171 void JIT::emit_op_has_indexed_property(const Instruction* currentInstruction)
1172 {
1173     auto bytecode = currentInstruction-&gt;as&lt;OpHasIndexedProperty&gt;();
1174     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<span class="line-modified">1175     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified">1176     VirtualRegister base = bytecode.m_base;</span>
<span class="line-modified">1177     VirtualRegister property = bytecode.m_property;</span>
1178     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
1179     ByValInfo* byValInfo = m_codeBlock-&gt;addByValInfo();
1180 
1181     emitLoadPayload(base, regT0);
1182     emitJumpSlowCaseIfNotJSCell(base);
1183 
1184     emitLoad(property, regT3, regT1);
1185     addSlowCase(branchIfNotInt32(regT3));
1186 
1187     // This is technically incorrect - we&#39;re zero-extending an int32. On the hot path this doesn&#39;t matter.
1188     // We check the value as if it was a uint32 against the m_vectorLength - which will always fail if
1189     // number was signed since m_vectorLength is always less than intmax (since the total allocation
1190     // size is always less than 4Gb). As such zero extending will have been correct (and extending the value
1191     // to 64-bits is necessary since it&#39;s used in the address calculation. We zero extend rather than sign
1192     // extending since it makes it easier to re-tag the value in the slow case.
1193     zeroExtend32ToPtr(regT1, regT1);
1194 
1195     emitArrayProfilingSiteWithCell(regT0, regT2, profile);
1196     and32(TrustedImm32(IndexingShapeMask), regT2);
1197 
1198     JITArrayMode mode = chooseArrayMode(profile);
1199     PatchableJump badType;
1200 
1201     // FIXME: Add support for other types like TypedArrays and Arguments.
1202     // See https://bugs.webkit.org/show_bug.cgi?id=135033 and https://bugs.webkit.org/show_bug.cgi?id=135034.
1203     JumpList slowCases = emitLoadForArrayMode(currentInstruction, mode, badType);
1204     move(TrustedImm32(1), regT0);
1205 
1206     addSlowCase(badType);
1207     addSlowCase(slowCases);
1208 
1209     Label done = label();
1210 
1211     emitStoreBool(dst, regT0);
1212 
1213     Label nextHotPath = label();
1214 
<span class="line-modified">1215     m_byValCompilationInfo.append(ByValCompilationInfo(byValInfo, m_bytecodeIndex, PatchableJump(), badType, mode, profile, done, nextHotPath));</span>
1216 }
1217 
1218 void JIT::emitSlow_op_has_indexed_property(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
1219 {
1220     linkAllSlowCases(iter);
1221 
1222     auto bytecode = currentInstruction-&gt;as&lt;OpHasIndexedProperty&gt;();
<span class="line-modified">1223     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified">1224     VirtualRegister base = bytecode.m_base;</span>
<span class="line-modified">1225     VirtualRegister property = bytecode.m_property;</span>
1226     ByValInfo* byValInfo = m_byValCompilationInfo[m_byValInstructionIndex].byValInfo;
1227 
1228     Label slowPath = label();
1229 
1230     emitLoad(base, regT1, regT0);
1231     emitLoad(property, regT3, regT2);
<span class="line-modified">1232     Call call = callOperation(operationHasIndexedPropertyDefault, dst, m_codeBlock-&gt;globalObject(), JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2), byValInfo);</span>
1233 
1234     m_byValCompilationInfo[m_byValInstructionIndex].slowPathTarget = slowPath;
1235     m_byValCompilationInfo[m_byValInstructionIndex].returnAddress = call;
1236     m_byValInstructionIndex++;
1237 }
1238 
1239 void JIT::emit_op_get_direct_pname(const Instruction* currentInstruction)
1240 {
1241     auto bytecode = currentInstruction-&gt;as&lt;OpGetDirectPname&gt;();
<span class="line-modified">1242     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified">1243     VirtualRegister base = bytecode.m_base;</span>
<span class="line-modified">1244     VirtualRegister index = bytecode.m_index;</span>
<span class="line-modified">1245     VirtualRegister enumerator = bytecode.m_enumerator;</span>
1246 
1247     // Check that base is a cell
1248     emitLoadPayload(base, regT0);
1249     emitJumpSlowCaseIfNotJSCell(base);
1250 
1251     // Check the structure
1252     emitLoadPayload(enumerator, regT1);
1253     load32(Address(regT0, JSCell::structureIDOffset()), regT2);
1254     addSlowCase(branch32(NotEqual, regT2, Address(regT1, JSPropertyNameEnumerator::cachedStructureIDOffset())));
1255 
1256     // Compute the offset
1257     emitLoadPayload(index, regT2);
1258     // If index is less than the enumerator&#39;s cached inline storage, then it&#39;s an inline access
1259     Jump outOfLineAccess = branch32(AboveOrEqual, regT2, Address(regT1, JSPropertyNameEnumerator::cachedInlineCapacityOffset()));
1260     addPtr(TrustedImm32(JSObject::offsetOfInlineStorage()), regT0);
1261     load32(BaseIndex(regT0, regT2, TimesEight, OBJECT_OFFSETOF(JSValue, u.asBits.tag)), regT1);
1262     load32(BaseIndex(regT0, regT2, TimesEight, OBJECT_OFFSETOF(JSValue, u.asBits.payload)), regT0);
1263 
1264     Jump done = jump();
1265 
1266     // Otherwise it&#39;s out of line
1267     outOfLineAccess.link(this);
1268     loadPtr(Address(regT0, JSObject::butterflyOffset()), regT0);
1269     sub32(Address(regT1, JSPropertyNameEnumerator::cachedInlineCapacityOffset()), regT2);
1270     neg32(regT2);
1271     int32_t offsetOfFirstProperty = static_cast&lt;int32_t&gt;(offsetInButterfly(firstOutOfLineOffset)) * sizeof(EncodedJSValue);
1272     load32(BaseIndex(regT0, regT2, TimesEight, offsetOfFirstProperty + OBJECT_OFFSETOF(JSValue, u.asBits.tag)), regT1);
1273     load32(BaseIndex(regT0, regT2, TimesEight, offsetOfFirstProperty + OBJECT_OFFSETOF(JSValue, u.asBits.payload)), regT0);
1274 
1275     done.link(this);
1276     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
1277     emitStore(dst, regT1, regT0);
1278 }
1279 
1280 void JIT::emit_op_enumerator_structure_pname(const Instruction* currentInstruction)
1281 {
1282     auto bytecode = currentInstruction-&gt;as&lt;OpEnumeratorStructurePname&gt;();
<span class="line-modified">1283     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified">1284     VirtualRegister enumerator = bytecode.m_enumerator;</span>
<span class="line-modified">1285     VirtualRegister index = bytecode.m_index;</span>
1286 
1287     emitLoadPayload(index, regT0);
1288     emitLoadPayload(enumerator, regT1);
1289     Jump inBounds = branch32(Below, regT0, Address(regT1, JSPropertyNameEnumerator::endStructurePropertyIndexOffset()));
1290 
1291     move(TrustedImm32(JSValue::NullTag), regT2);
1292     move(TrustedImm32(0), regT0);
1293 
1294     Jump done = jump();
1295     inBounds.link(this);
1296 
1297     loadPtr(Address(regT1, JSPropertyNameEnumerator::cachedPropertyNamesVectorOffset()), regT1);
1298     loadPtr(BaseIndex(regT1, regT0, timesPtr()), regT0);
1299     move(TrustedImm32(JSValue::CellTag), regT2);
1300 
1301     done.link(this);
1302     emitStore(dst, regT2, regT0);
1303 }
1304 
1305 void JIT::emit_op_enumerator_generic_pname(const Instruction* currentInstruction)
1306 {
1307     auto bytecode = currentInstruction-&gt;as&lt;OpEnumeratorGenericPname&gt;();
<span class="line-modified">1308     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified">1309     VirtualRegister enumerator = bytecode.m_enumerator;</span>
<span class="line-modified">1310     VirtualRegister index = bytecode.m_index;</span>
1311 
1312     emitLoadPayload(index, regT0);
1313     emitLoadPayload(enumerator, regT1);
1314     Jump inBounds = branch32(Below, regT0, Address(regT1, JSPropertyNameEnumerator::endGenericPropertyIndexOffset()));
1315 
1316     move(TrustedImm32(JSValue::NullTag), regT2);
1317     move(TrustedImm32(0), regT0);
1318 
1319     Jump done = jump();
1320     inBounds.link(this);
1321 
1322     loadPtr(Address(regT1, JSPropertyNameEnumerator::cachedPropertyNamesVectorOffset()), regT1);
1323     loadPtr(BaseIndex(regT1, regT0, timesPtr()), regT0);
1324     move(TrustedImm32(JSValue::CellTag), regT2);
1325 
1326     done.link(this);
1327     emitStore(dst, regT2, regT0);
1328 }
1329 
1330 void JIT::emit_op_profile_type(const Instruction* currentInstruction)
1331 {
1332     auto bytecode = currentInstruction-&gt;as&lt;OpProfileType&gt;();
1333     auto&amp; metadata = bytecode.metadata(m_codeBlock);
1334     TypeLocation* cachedTypeLocation = metadata.m_typeLocation;
<span class="line-modified">1335     VirtualRegister valueToProfile = bytecode.m_targetVirtualRegister;</span>
1336 
1337     // Load payload in T0. Load tag in T3.
1338     emitLoadPayload(valueToProfile, regT0);
1339     emitLoadTag(valueToProfile, regT3);
1340 
1341     JumpList jumpToEnd;
1342 
1343     jumpToEnd.append(branchIfEmpty(regT3));
1344 
1345     // Compile in a predictive type check, if possible, to see if we can skip writing to the log.
1346     // These typechecks are inlined to match those of the 32-bit JSValue type checks.
1347     if (cachedTypeLocation-&gt;m_lastSeenType == TypeUndefined)
1348         jumpToEnd.append(branchIfUndefined(regT3));
1349     else if (cachedTypeLocation-&gt;m_lastSeenType == TypeNull)
1350         jumpToEnd.append(branchIfNull(regT3));
1351     else if (cachedTypeLocation-&gt;m_lastSeenType == TypeBoolean)
1352         jumpToEnd.append(branchIfBoolean(regT3, InvalidGPRReg));
1353     else if (cachedTypeLocation-&gt;m_lastSeenType == TypeAnyInt)
1354         jumpToEnd.append(branchIfInt32(regT3));
1355     else if (cachedTypeLocation-&gt;m_lastSeenType == TypeNumber) {
</pre>
<hr />
<pre>
1372     store32(regT3, Address(regT1, TypeProfilerLog::LogEntry::valueOffset() + OBJECT_OFFSETOF(JSValue, u.asBits.tag)));
1373 
1374     // Store the structureID of the cell if argument is a cell, otherwise, store 0 on the log entry.
1375     Jump notCell = branchIfNotCell(regT3);
1376     load32(Address(regT0, JSCell::structureIDOffset()), regT0);
1377     store32(regT0, Address(regT1, TypeProfilerLog::LogEntry::structureIDOffset()));
1378     Jump skipNotCell = jump();
1379     notCell.link(this);
1380     store32(TrustedImm32(0), Address(regT1, TypeProfilerLog::LogEntry::structureIDOffset()));
1381     skipNotCell.link(this);
1382 
1383     // Store the typeLocation on the log entry.
1384     move(TrustedImmPtr(cachedTypeLocation), regT0);
1385     store32(regT0, Address(regT1, TypeProfilerLog::LogEntry::locationOffset()));
1386 
1387     // Increment the current log entry.
1388     addPtr(TrustedImm32(sizeof(TypeProfilerLog::LogEntry)), regT1);
1389     store32(regT1, Address(regT2, TypeProfilerLog::currentLogEntryOffset()));
1390     jumpToEnd.append(branchPtr(NotEqual, regT1, TrustedImmPtr(cachedTypeProfilerLog-&gt;logEndPtr())));
1391     // Clear the log if we&#39;re at the end of the log.
<span class="line-modified">1392     callOperation(operationProcessTypeProfilerLog, &amp;vm());</span>
1393 
1394     jumpToEnd.link(this);
1395 }
1396 
1397 void JIT::emit_op_log_shadow_chicken_prologue(const Instruction* currentInstruction)
1398 {
1399     RELEASE_ASSERT(vm().shadowChicken());
1400     updateTopCallFrame();
1401     static_assert(nonArgGPR0 != regT0 &amp;&amp; nonArgGPR0 != regT2, &quot;we will have problems if this is true.&quot;);
1402     auto bytecode = currentInstruction-&gt;as&lt;OpLogShadowChickenPrologue&gt;();
1403     GPRReg shadowPacketReg = regT0;
1404     GPRReg scratch1Reg = nonArgGPR0; // This must be a non-argument register.
1405     GPRReg scratch2Reg = regT2;
1406     ensureShadowChickenPacket(vm(), shadowPacketReg, scratch1Reg, scratch2Reg);
1407 
1408     scratch1Reg = regT4;
<span class="line-modified">1409     emitLoadPayload(bytecode.m_scope, regT3);</span>
1410     logShadowChickenProloguePacket(shadowPacketReg, scratch1Reg, regT3);
1411 }
1412 
1413 void JIT::emit_op_log_shadow_chicken_tail(const Instruction* currentInstruction)
1414 {
1415     RELEASE_ASSERT(vm().shadowChicken());
1416     updateTopCallFrame();
1417     static_assert(nonArgGPR0 != regT0 &amp;&amp; nonArgGPR0 != regT2, &quot;we will have problems if this is true.&quot;);
1418     auto bytecode = currentInstruction-&gt;as&lt;OpLogShadowChickenTail&gt;();
1419     GPRReg shadowPacketReg = regT0;
1420     GPRReg scratch1Reg = nonArgGPR0; // This must be a non-argument register.
1421     GPRReg scratch2Reg = regT2;
1422     ensureShadowChickenPacket(vm(), shadowPacketReg, scratch1Reg, scratch2Reg);
<span class="line-modified">1423     emitLoadPayload(bytecode.m_thisValue, regT2);</span>
<span class="line-modified">1424     emitLoadTag(bytecode.m_thisValue, regT1);</span>
1425     JSValueRegs thisRegs(regT1, regT2);
<span class="line-modified">1426     emitLoadPayload(bytecode.m_scope, regT3);</span>
<span class="line-modified">1427     logShadowChickenTailPacket(shadowPacketReg, thisRegs, regT3, m_codeBlock, CallSiteIndex(m_bytecodeIndex));</span>
1428 }
1429 
1430 } // namespace JSC
1431 
1432 #endif // USE(JSVALUE32_64)
1433 #endif // ENABLE(JIT)
</pre>
</td>
</tr>
</table>
<center><a href="JITOpcodes.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="JITOperations.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>