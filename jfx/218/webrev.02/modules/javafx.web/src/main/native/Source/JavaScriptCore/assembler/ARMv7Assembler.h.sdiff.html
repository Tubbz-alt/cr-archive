<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/ARMv7Assembler.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="ARM64Registers.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="ARMv7Registers.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/ARMv7Assembler.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (C) 2009-2017 Apple Inc. All rights reserved.</span>
   3  * Copyright (C) 2010 University of Szeged
   4  *
   5  * Redistribution and use in source and binary forms, with or without
   6  * modification, are permitted provided that the following conditions
   7  * are met:
   8  * 1. Redistributions of source code must retain the above copyright
   9  *    notice, this list of conditions and the following disclaimer.
  10  * 2. Redistributions in binary form must reproduce the above copyright
  11  *    notice, this list of conditions and the following disclaimer in the
  12  *    documentation and/or other materials provided with the distribution.
  13  *
  14  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  15  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  16  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  17  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  18  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  19  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  20  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  21  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  22  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
</pre>
<hr />
<pre>
  86 
  87     inline FPSingleRegisterID asSingleUpper(FPDoubleRegisterID reg)
  88     {
  89         ASSERT(reg &lt; d16);
  90         return (FPSingleRegisterID)((reg &lt;&lt; 1) + 1);
  91     }
  92 
  93     inline FPDoubleRegisterID asDouble(FPSingleRegisterID reg)
  94     {
  95         ASSERT(!(reg &amp; 1));
  96         return (FPDoubleRegisterID)(reg &gt;&gt; 1);
  97     }
  98 
  99 } // namespace ARMRegisters
 100 
 101 class ARMv7Assembler;
 102 class ARMThumbImmediate {
 103     friend class ARMv7Assembler;
 104 
 105     typedef uint8_t ThumbImmediateType;
<span class="line-modified"> 106     static const ThumbImmediateType TypeInvalid = 0;</span>
<span class="line-modified"> 107     static const ThumbImmediateType TypeEncoded = 1;</span>
<span class="line-modified"> 108     static const ThumbImmediateType TypeUInt16 = 2;</span>
 109 
 110     typedef union {
 111         int16_t asInt;
 112         struct {
 113             unsigned imm8 : 8;
 114             unsigned imm3 : 3;
 115             unsigned i    : 1;
 116             unsigned imm4 : 4;
 117         };
 118         // If this is an encoded immediate, then it may describe a shift, or a pattern.
 119         struct {
 120             unsigned shiftValue7 : 7;
 121             unsigned shiftAmount : 5;
 122         };
 123         struct {
 124             unsigned immediate   : 8;
 125             unsigned pattern     : 4;
 126         };
 127     } ThumbImmediateValue;
 128 
</pre>
<hr />
<pre>
1012     {
1013         m_formatter.oneWordOp8Imm8(OP_IT, ifThenElse(cond, inst2if));
1014     }
1015 
1016     ALWAYS_INLINE void it(Condition cond, bool inst2if, bool inst3if)
1017     {
1018         m_formatter.oneWordOp8Imm8(OP_IT, ifThenElse(cond, inst2if, inst3if));
1019     }
1020 
1021     ALWAYS_INLINE void it(Condition cond, bool inst2if, bool inst3if, bool inst4if)
1022     {
1023         m_formatter.oneWordOp8Imm8(OP_IT, ifThenElse(cond, inst2if, inst3if, inst4if));
1024     }
1025 
1026     // rt == ARMRegisters::pc only allowed if last instruction in IT (if then) block.
1027     ALWAYS_INLINE void ldr(RegisterID rt, RegisterID rn, ARMThumbImmediate imm)
1028     {
1029         ASSERT(rn != ARMRegisters::pc); // LDR (literal)
1030         ASSERT(imm.isUInt12());
1031 
<span class="line-modified">1032         if (!((rt | rn) &amp; 8) &amp;&amp; imm.isUInt7())</span>




1033             m_formatter.oneWordOp5Imm5Reg3Reg3(OP_LDR_imm_T1, imm.getUInt7() &gt;&gt; 2, rn, rt);
<span class="line-modified">1034         else if ((rn == ARMRegisters::sp) &amp;&amp; !(rt &amp; 8) &amp;&amp; imm.isUInt10())</span>
1035             m_formatter.oneWordOp5Reg3Imm8(OP_LDR_imm_T2, rt, static_cast&lt;uint8_t&gt;(imm.getUInt10() &gt;&gt; 2));
1036         else
1037             m_formatter.twoWordOp12Reg4Reg4Imm12(OP_LDR_imm_T3, rn, rt, imm.getUInt12());
1038     }
1039 
1040     ALWAYS_INLINE void ldrWide8BitImmediate(RegisterID rt, RegisterID rn, uint8_t immediate)
1041     {
1042         ASSERT(rn != ARMRegisters::pc);
1043         m_formatter.twoWordOp12Reg4Reg4Imm12(OP_LDR_imm_T3, rn, rt, immediate);
1044     }
1045 
1046     ALWAYS_INLINE void ldrCompact(RegisterID rt, RegisterID rn, ARMThumbImmediate imm)
1047     {
1048         ASSERT(rn != ARMRegisters::pc); // LDR (literal)
1049         ASSERT(imm.isUInt7());
1050         ASSERT(!((rt | rn) &amp; 8));
1051         m_formatter.oneWordOp5Imm5Reg3Reg3(OP_LDR_imm_T1, imm.getUInt7() &gt;&gt; 2, rn, rt);
1052     }
1053 
1054     // If index is set, this is a regular offset or a pre-indexed load;
</pre>
<hr />
<pre>
1952     void nop()
1953     {
1954         m_formatter.oneWordOp8Imm8(OP_NOP_T1, 0);
1955     }
1956 
1957     void nopw()
1958     {
1959         m_formatter.twoWordOp16Op16(OP_NOP_T2a, OP_NOP_T2b);
1960     }
1961 
1962     static constexpr int16_t nopPseudo16()
1963     {
1964         return OP_NOP_T1;
1965     }
1966 
1967     static constexpr int32_t nopPseudo32()
1968     {
1969         return OP_NOP_T2a | (OP_NOP_T2b &lt;&lt; 16);
1970     }
1971 
<span class="line-modified">1972     template &lt;typename CopyFunction&gt;</span>
<span class="line-modified">1973     static void fillNops(void* base, size_t size, CopyFunction copy)</span>


1974     {
1975         RELEASE_ASSERT(!(size % sizeof(int16_t)));
1976 
1977         char* ptr = static_cast&lt;char*&gt;(base);
1978         const size_t num32s = size / sizeof(int32_t);
1979         for (size_t i = 0; i &lt; num32s; i++) {
1980             const int32_t insn = nopPseudo32();
1981             copy(ptr, &amp;insn, sizeof(int32_t));
1982             ptr += sizeof(int32_t);
1983         }
1984 
1985         const size_t num16s = (size % sizeof(int32_t)) / sizeof(int16_t);
1986         ASSERT(num16s == 0 || num16s == 1);
1987         ASSERT(num16s * sizeof(int16_t) + num32s * sizeof(int32_t) == size);
1988         if (num16s) {
1989             const int16_t insn = nopPseudo16();
1990             copy(ptr, &amp;insn, sizeof(int16_t));
1991         }
1992     }
1993 
</pre>
<hr />
<pre>
2106             return LinkBX;
2107         }
2108 
2109         ASSERT(jumpType == JumpCondition);
2110         return LinkConditionalBX;
2111     }
2112 
2113     static JumpLinkType computeJumpType(LinkRecord&amp; record, const uint8_t* from, const uint8_t* to)
2114     {
2115         JumpLinkType linkType = computeJumpType(record.type(), from, to);
2116         record.setLinkType(linkType);
2117         return linkType;
2118     }
2119 
2120     Vector&lt;LinkRecord, 0, UnsafeVectorOverflow&gt;&amp; jumpsToLink()
2121     {
2122         std::sort(m_jumpsToLink.begin(), m_jumpsToLink.end(), linkRecordSourceComparator);
2123         return m_jumpsToLink;
2124     }
2125 
<span class="line-modified">2126     typedef void* (*CopyFunction)(void*, const void*, size_t);</span>
<span class="line-modified">2127 </span>
<span class="line-removed">2128     static void ALWAYS_INLINE link(LinkRecord&amp; record, uint8_t* from, const uint8_t* fromInstruction8, uint8_t* to, CopyFunction copy)</span>
2129     {
2130         const uint16_t* fromInstruction = reinterpret_cast_ptr&lt;const uint16_t*&gt;(fromInstruction8);
2131         switch (record.linkType()) {
2132         case LinkJumpT1:
<span class="line-modified">2133             linkJumpT1(record.condition(), reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to, copy);</span>
2134             break;
2135         case LinkJumpT2:
<span class="line-modified">2136             linkJumpT2(reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to, copy);</span>
2137             break;
2138         case LinkJumpT3:
<span class="line-modified">2139             linkJumpT3(record.condition(), reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to, copy);</span>
2140             break;
2141         case LinkJumpT4:
<span class="line-modified">2142             linkJumpT4(reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to, copy);</span>
2143             break;
2144         case LinkConditionalJumpT4:
<span class="line-modified">2145             linkConditionalJumpT4(record.condition(), reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to, copy);</span>
2146             break;
2147         case LinkConditionalBX:
<span class="line-modified">2148             linkConditionalBX(record.condition(), reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to, copy);</span>
2149             break;
2150         case LinkBX:
<span class="line-modified">2151             linkBX(reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to, copy);</span>
2152             break;
2153         default:
2154             RELEASE_ASSERT_NOT_REACHED();
2155             break;
2156         }
2157     }
2158 
2159     size_t codeSize() const { return m_formatter.codeSize(); }
2160 
2161     static unsigned getCallReturnOffset(AssemblerLabel call)
2162     {
2163         ASSERT(call.isSet());
2164         return call.m_offset;
2165     }
2166 
2167     // Linking &amp; patching:
2168     //
2169     // &#39;link&#39; and &#39;patch&#39; methods are for use on unprotected code - such as the code
2170     // within the AssemblerBuffer, and code being patched by the patch buffer.  Once
2171     // code has been finalized it is (platform support permitting) within a non-
</pre>
<hr />
<pre>
2358 #if OS(LINUX)
2359     static inline void linuxPageFlush(uintptr_t begin, uintptr_t end)
2360     {
2361         asm volatile(
2362             &quot;push    {r7}\n&quot;
2363             &quot;mov     r0, %0\n&quot;
2364             &quot;mov     r1, %1\n&quot;
2365             &quot;movw    r7, #0x2\n&quot;
2366             &quot;movt    r7, #0xf\n&quot;
2367             &quot;movs    r2, #0x0\n&quot;
2368             &quot;svc     0x0\n&quot;
2369             &quot;pop     {r7}\n&quot;
2370             :
2371             : &quot;r&quot; (begin), &quot;r&quot; (end)
2372             : &quot;r0&quot;, &quot;r1&quot;, &quot;r2&quot;);
2373     }
2374 #endif
2375 
2376     static void cacheFlush(void* code, size_t size)
2377     {
<span class="line-modified">2378 #if OS(IOS_FAMILY)</span>
2379         sys_cache_control(kCacheFunctionPrepareForExecution, code, size);
2380 #elif OS(LINUX)
2381         size_t page = pageSize();
2382         uintptr_t current = reinterpret_cast&lt;uintptr_t&gt;(code);
2383         uintptr_t end = current + size;
2384         uintptr_t firstPageEnd = (current &amp; ~(page - 1)) + page;
2385 
2386         if (end &lt;= firstPageEnd) {
2387             linuxPageFlush(current, end);
2388             return;
2389         }
2390 
2391         linuxPageFlush(current, firstPageEnd);
2392 
2393         for (current = firstPageEnd; current + page &lt; end; current += page)
2394             linuxPageFlush(current, current + page);
2395 
2396         linuxPageFlush(current, end);
2397 #else
2398 #error &quot;The cacheFlush support is missing on this platform.&quot;
</pre>
<hr />
<pre>
2582     }
2583 
2584     static bool canBeJumpT3(const uint16_t* instruction, const void* target)
2585     {
2586         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2587         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2588 
2589         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2590         return ((relative &lt;&lt; 11) &gt;&gt; 11) == relative;
2591     }
2592 
2593     static bool canBeJumpT4(const uint16_t* instruction, const void* target)
2594     {
2595         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2596         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2597 
2598         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2599         return ((relative &lt;&lt; 7) &gt;&gt; 7) == relative;
2600     }
2601 
<span class="line-modified">2602     static void linkJumpT1(Condition cond, uint16_t* writeTarget, const uint16_t* instruction, void* target, CopyFunction copy = performJITMemcpy)</span>

2603     {
2604         // FIMXE: this should be up in the MacroAssembler layer. :-(
2605         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2606         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2607         ASSERT(canBeJumpT1(instruction, target));
2608 
2609         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2610         // It does not appear to be documented in the ARM ARM (big surprise), but
2611         // for OP_B_T1 the branch displacement encoded in the instruction is 2
2612         // less than the actual displacement.
2613         relative -= 2;
2614 
2615         // All branch offsets should be an even distance.
2616         ASSERT(!(relative &amp; 1));
2617         uint16_t newInstruction = OP_B_T1 | ((cond &amp; 0xf) &lt;&lt; 8) | ((relative &amp; 0x1fe) &gt;&gt; 1);
2618         copy(writeTarget - 1, &amp;newInstruction, sizeof(uint16_t));
2619     }
2620 
<span class="line-modified">2621     static void linkJumpT2(uint16_t* writeTarget, const uint16_t* instruction, void* target, CopyFunction copy = performJITMemcpy)</span>

2622     {
2623         // FIMXE: this should be up in the MacroAssembler layer. :-(
2624         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2625         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2626         ASSERT(canBeJumpT2(instruction, target));
2627 
2628         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2629         // It does not appear to be documented in the ARM ARM (big surprise), but
2630         // for OP_B_T2 the branch displacement encoded in the instruction is 2
2631         // less than the actual displacement.
2632         relative -= 2;
2633 
2634         // All branch offsets should be an even distance.
2635         ASSERT(!(relative &amp; 1));
2636         uint16_t newInstruction = OP_B_T2 | ((relative &amp; 0xffe) &gt;&gt; 1);
2637         copy(writeTarget - 1, &amp;newInstruction, sizeof(uint16_t));
2638     }
2639 
<span class="line-modified">2640     static void linkJumpT3(Condition cond, uint16_t* writeTarget, const uint16_t* instruction, void* target, CopyFunction copy = performJITMemcpy)</span>

2641     {
2642         // FIMXE: this should be up in the MacroAssembler layer. :-(
2643         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2644         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2645         ASSERT(canBeJumpT3(instruction, target));
2646 
2647         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2648 
2649         // All branch offsets should be an even distance.
2650         ASSERT(!(relative &amp; 1));
2651         uint16_t instructions[2];
2652         instructions[0] = OP_B_T3a | ((relative &amp; 0x100000) &gt;&gt; 10) | ((cond &amp; 0xf) &lt;&lt; 6) | ((relative &amp; 0x3f000) &gt;&gt; 12);
2653         instructions[1] = OP_B_T3b | ((relative &amp; 0x80000) &gt;&gt; 8) | ((relative &amp; 0x40000) &gt;&gt; 5) | ((relative &amp; 0xffe) &gt;&gt; 1);
2654         copy(writeTarget - 2, instructions, 2 * sizeof(uint16_t));
2655     }
2656 
<span class="line-modified">2657     static void linkJumpT4(uint16_t* writeTarget, const uint16_t* instruction, void* target, CopyFunction copy = performJITMemcpy)</span>

2658     {
2659         // FIMXE: this should be up in the MacroAssembler layer. :-(
2660         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2661         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2662         ASSERT(canBeJumpT4(instruction, target));
2663 
2664         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2665         // ARM encoding for the top two bits below the sign bit is &#39;peculiar&#39;.
2666         if (relative &gt;= 0)
2667             relative ^= 0xC00000;
2668 
2669         // All branch offsets should be an even distance.
2670         ASSERT(!(relative &amp; 1));
2671         uint16_t instructions[2];
2672         instructions[0] = OP_B_T4a | ((relative &amp; 0x1000000) &gt;&gt; 14) | ((relative &amp; 0x3ff000) &gt;&gt; 12);
2673         instructions[1] = OP_B_T4b | ((relative &amp; 0x800000) &gt;&gt; 10) | ((relative &amp; 0x400000) &gt;&gt; 11) | ((relative &amp; 0xffe) &gt;&gt; 1);
2674         copy(writeTarget - 2, instructions, 2 * sizeof(uint16_t));
2675     }
2676 
<span class="line-modified">2677     static void linkConditionalJumpT4(Condition cond, uint16_t* writeTarget, const uint16_t* instruction, void* target, CopyFunction copy = performJITMemcpy)</span>

2678     {
2679         // FIMXE: this should be up in the MacroAssembler layer. :-(
2680         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2681         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2682 
2683         uint16_t newInstruction = ifThenElse(cond) | OP_IT;
2684         copy(writeTarget - 3, &amp;newInstruction, sizeof(uint16_t));
<span class="line-modified">2685         linkJumpT4(writeTarget, instruction, target, copy);</span>
2686     }
2687 
<span class="line-modified">2688     static void linkBX(uint16_t* writeTarget, const uint16_t* instruction, void* target, CopyFunction copy = performJITMemcpy)</span>

2689     {
2690         // FIMXE: this should be up in the MacroAssembler layer. :-(
2691         ASSERT_UNUSED(instruction, !(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2692         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(writeTarget) &amp; 1));
2693         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2694 
2695         const uint16_t JUMP_TEMPORARY_REGISTER = ARMRegisters::ip;
2696         ARMThumbImmediate lo16 = ARMThumbImmediate::makeUInt16(static_cast&lt;uint16_t&gt;(reinterpret_cast&lt;uint32_t&gt;(target) + 1));
2697         ARMThumbImmediate hi16 = ARMThumbImmediate::makeUInt16(static_cast&lt;uint16_t&gt;(reinterpret_cast&lt;uint32_t&gt;(target) &gt;&gt; 16));
2698         uint16_t instructions[5];
2699         instructions[0] = twoWordOp5i6Imm4Reg4EncodedImmFirst(OP_MOV_imm_T3, lo16);
2700         instructions[1] = twoWordOp5i6Imm4Reg4EncodedImmSecond(JUMP_TEMPORARY_REGISTER, lo16);
2701         instructions[2] = twoWordOp5i6Imm4Reg4EncodedImmFirst(OP_MOVT, hi16);
2702         instructions[3] = twoWordOp5i6Imm4Reg4EncodedImmSecond(JUMP_TEMPORARY_REGISTER, hi16);
2703         instructions[4] = OP_BX | (JUMP_TEMPORARY_REGISTER &lt;&lt; 3);
2704 
2705         copy(writeTarget - 5, instructions, 5 * sizeof(uint16_t));
2706     }
2707 
<span class="line-modified">2708     static void linkConditionalBX(Condition cond, uint16_t* writeTarget, const uint16_t* instruction, void* target, CopyFunction copy = performJITMemcpy)</span>

2709     {
2710         // FIMXE: this should be up in the MacroAssembler layer. :-(
2711         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2712         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2713 
2714         linkBX(writeTarget, instruction, target);
2715         uint16_t newInstruction = ifThenElse(cond, true, true) | OP_IT;
2716         copy(writeTarget - 6, &amp;newInstruction, sizeof(uint16_t));
2717     }
2718 
2719     static void linkJumpAbsolute(uint16_t* writeTarget, const uint16_t* instruction, void* target)
2720     {
2721         // FIMXE: this should be up in the MacroAssembler layer. :-(
2722         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2723         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2724 
2725         ASSERT((isMOV_imm_T3(instruction - 5) &amp;&amp; isMOVT(instruction - 3) &amp;&amp; isBX(instruction - 1))
2726                || (isNOP_T1(instruction - 5) &amp;&amp; isNOP_T2(instruction - 4) &amp;&amp; isB(instruction - 2)));
2727 
2728         if (canBeJumpT4(instruction, target)) {
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (C) 2009-2019 Apple Inc. All rights reserved.</span>
   3  * Copyright (C) 2010 University of Szeged
   4  *
   5  * Redistribution and use in source and binary forms, with or without
   6  * modification, are permitted provided that the following conditions
   7  * are met:
   8  * 1. Redistributions of source code must retain the above copyright
   9  *    notice, this list of conditions and the following disclaimer.
  10  * 2. Redistributions in binary form must reproduce the above copyright
  11  *    notice, this list of conditions and the following disclaimer in the
  12  *    documentation and/or other materials provided with the distribution.
  13  *
  14  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  15  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  16  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  17  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  18  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  19  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  20  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  21  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  22  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
</pre>
<hr />
<pre>
  86 
  87     inline FPSingleRegisterID asSingleUpper(FPDoubleRegisterID reg)
  88     {
  89         ASSERT(reg &lt; d16);
  90         return (FPSingleRegisterID)((reg &lt;&lt; 1) + 1);
  91     }
  92 
  93     inline FPDoubleRegisterID asDouble(FPSingleRegisterID reg)
  94     {
  95         ASSERT(!(reg &amp; 1));
  96         return (FPDoubleRegisterID)(reg &gt;&gt; 1);
  97     }
  98 
  99 } // namespace ARMRegisters
 100 
 101 class ARMv7Assembler;
 102 class ARMThumbImmediate {
 103     friend class ARMv7Assembler;
 104 
 105     typedef uint8_t ThumbImmediateType;
<span class="line-modified"> 106     static constexpr ThumbImmediateType TypeInvalid = 0;</span>
<span class="line-modified"> 107     static constexpr ThumbImmediateType TypeEncoded = 1;</span>
<span class="line-modified"> 108     static constexpr ThumbImmediateType TypeUInt16 = 2;</span>
 109 
 110     typedef union {
 111         int16_t asInt;
 112         struct {
 113             unsigned imm8 : 8;
 114             unsigned imm3 : 3;
 115             unsigned i    : 1;
 116             unsigned imm4 : 4;
 117         };
 118         // If this is an encoded immediate, then it may describe a shift, or a pattern.
 119         struct {
 120             unsigned shiftValue7 : 7;
 121             unsigned shiftAmount : 5;
 122         };
 123         struct {
 124             unsigned immediate   : 8;
 125             unsigned pattern     : 4;
 126         };
 127     } ThumbImmediateValue;
 128 
</pre>
<hr />
<pre>
1012     {
1013         m_formatter.oneWordOp8Imm8(OP_IT, ifThenElse(cond, inst2if));
1014     }
1015 
1016     ALWAYS_INLINE void it(Condition cond, bool inst2if, bool inst3if)
1017     {
1018         m_formatter.oneWordOp8Imm8(OP_IT, ifThenElse(cond, inst2if, inst3if));
1019     }
1020 
1021     ALWAYS_INLINE void it(Condition cond, bool inst2if, bool inst3if, bool inst4if)
1022     {
1023         m_formatter.oneWordOp8Imm8(OP_IT, ifThenElse(cond, inst2if, inst3if, inst4if));
1024     }
1025 
1026     // rt == ARMRegisters::pc only allowed if last instruction in IT (if then) block.
1027     ALWAYS_INLINE void ldr(RegisterID rt, RegisterID rn, ARMThumbImmediate imm)
1028     {
1029         ASSERT(rn != ARMRegisters::pc); // LDR (literal)
1030         ASSERT(imm.isUInt12());
1031 
<span class="line-modified">1032         if (!((rt | rn) &amp; 8) &amp;&amp; imm.isUInt7() &amp;&amp; !(imm.getUInt7() % 4)) {</span>
<span class="line-added">1033             // We can only use Encoding T1 when imm is a multiple of 4.</span>
<span class="line-added">1034             // For details see A8.8.63 on ARM Architecture Reference</span>
<span class="line-added">1035             // Manual ARMv7-A and ARMv7-R edition available on</span>
<span class="line-added">1036             // https://static.docs.arm.com/ddi0406/cd/DDI0406C_d_armv7ar_arm.pdf</span>
1037             m_formatter.oneWordOp5Imm5Reg3Reg3(OP_LDR_imm_T1, imm.getUInt7() &gt;&gt; 2, rn, rt);
<span class="line-modified">1038         } else if ((rn == ARMRegisters::sp) &amp;&amp; !(rt &amp; 8) &amp;&amp; imm.isUInt10())</span>
1039             m_formatter.oneWordOp5Reg3Imm8(OP_LDR_imm_T2, rt, static_cast&lt;uint8_t&gt;(imm.getUInt10() &gt;&gt; 2));
1040         else
1041             m_formatter.twoWordOp12Reg4Reg4Imm12(OP_LDR_imm_T3, rn, rt, imm.getUInt12());
1042     }
1043 
1044     ALWAYS_INLINE void ldrWide8BitImmediate(RegisterID rt, RegisterID rn, uint8_t immediate)
1045     {
1046         ASSERT(rn != ARMRegisters::pc);
1047         m_formatter.twoWordOp12Reg4Reg4Imm12(OP_LDR_imm_T3, rn, rt, immediate);
1048     }
1049 
1050     ALWAYS_INLINE void ldrCompact(RegisterID rt, RegisterID rn, ARMThumbImmediate imm)
1051     {
1052         ASSERT(rn != ARMRegisters::pc); // LDR (literal)
1053         ASSERT(imm.isUInt7());
1054         ASSERT(!((rt | rn) &amp; 8));
1055         m_formatter.oneWordOp5Imm5Reg3Reg3(OP_LDR_imm_T1, imm.getUInt7() &gt;&gt; 2, rn, rt);
1056     }
1057 
1058     // If index is set, this is a regular offset or a pre-indexed load;
</pre>
<hr />
<pre>
1956     void nop()
1957     {
1958         m_formatter.oneWordOp8Imm8(OP_NOP_T1, 0);
1959     }
1960 
1961     void nopw()
1962     {
1963         m_formatter.twoWordOp16Op16(OP_NOP_T2a, OP_NOP_T2b);
1964     }
1965 
1966     static constexpr int16_t nopPseudo16()
1967     {
1968         return OP_NOP_T1;
1969     }
1970 
1971     static constexpr int32_t nopPseudo32()
1972     {
1973         return OP_NOP_T2a | (OP_NOP_T2b &lt;&lt; 16);
1974     }
1975 
<span class="line-modified">1976     using CopyFunction = void*(&amp;)(void*, const void*, size_t);</span>
<span class="line-modified">1977 </span>
<span class="line-added">1978     template &lt;CopyFunction copy&gt;</span>
<span class="line-added">1979     static void fillNops(void* base, size_t size)</span>
1980     {
1981         RELEASE_ASSERT(!(size % sizeof(int16_t)));
1982 
1983         char* ptr = static_cast&lt;char*&gt;(base);
1984         const size_t num32s = size / sizeof(int32_t);
1985         for (size_t i = 0; i &lt; num32s; i++) {
1986             const int32_t insn = nopPseudo32();
1987             copy(ptr, &amp;insn, sizeof(int32_t));
1988             ptr += sizeof(int32_t);
1989         }
1990 
1991         const size_t num16s = (size % sizeof(int32_t)) / sizeof(int16_t);
1992         ASSERT(num16s == 0 || num16s == 1);
1993         ASSERT(num16s * sizeof(int16_t) + num32s * sizeof(int32_t) == size);
1994         if (num16s) {
1995             const int16_t insn = nopPseudo16();
1996             copy(ptr, &amp;insn, sizeof(int16_t));
1997         }
1998     }
1999 
</pre>
<hr />
<pre>
2112             return LinkBX;
2113         }
2114 
2115         ASSERT(jumpType == JumpCondition);
2116         return LinkConditionalBX;
2117     }
2118 
2119     static JumpLinkType computeJumpType(LinkRecord&amp; record, const uint8_t* from, const uint8_t* to)
2120     {
2121         JumpLinkType linkType = computeJumpType(record.type(), from, to);
2122         record.setLinkType(linkType);
2123         return linkType;
2124     }
2125 
2126     Vector&lt;LinkRecord, 0, UnsafeVectorOverflow&gt;&amp; jumpsToLink()
2127     {
2128         std::sort(m_jumpsToLink.begin(), m_jumpsToLink.end(), linkRecordSourceComparator);
2129         return m_jumpsToLink;
2130     }
2131 
<span class="line-modified">2132     template&lt;CopyFunction copy&gt;</span>
<span class="line-modified">2133     static void ALWAYS_INLINE link(LinkRecord&amp; record, uint8_t* from, const uint8_t* fromInstruction8, uint8_t* to)</span>

2134     {
2135         const uint16_t* fromInstruction = reinterpret_cast_ptr&lt;const uint16_t*&gt;(fromInstruction8);
2136         switch (record.linkType()) {
2137         case LinkJumpT1:
<span class="line-modified">2138             linkJumpT1&lt;copy&gt;(record.condition(), reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to);</span>
2139             break;
2140         case LinkJumpT2:
<span class="line-modified">2141             linkJumpT2&lt;copy&gt;(reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to);</span>
2142             break;
2143         case LinkJumpT3:
<span class="line-modified">2144             linkJumpT3&lt;copy&gt;(record.condition(), reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to);</span>
2145             break;
2146         case LinkJumpT4:
<span class="line-modified">2147             linkJumpT4&lt;copy&gt;(reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to);</span>
2148             break;
2149         case LinkConditionalJumpT4:
<span class="line-modified">2150             linkConditionalJumpT4&lt;copy&gt;(record.condition(), reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to);</span>
2151             break;
2152         case LinkConditionalBX:
<span class="line-modified">2153             linkConditionalBX&lt;copy&gt;(record.condition(), reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to);</span>
2154             break;
2155         case LinkBX:
<span class="line-modified">2156             linkBX&lt;copy&gt;(reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to);</span>
2157             break;
2158         default:
2159             RELEASE_ASSERT_NOT_REACHED();
2160             break;
2161         }
2162     }
2163 
2164     size_t codeSize() const { return m_formatter.codeSize(); }
2165 
2166     static unsigned getCallReturnOffset(AssemblerLabel call)
2167     {
2168         ASSERT(call.isSet());
2169         return call.m_offset;
2170     }
2171 
2172     // Linking &amp; patching:
2173     //
2174     // &#39;link&#39; and &#39;patch&#39; methods are for use on unprotected code - such as the code
2175     // within the AssemblerBuffer, and code being patched by the patch buffer.  Once
2176     // code has been finalized it is (platform support permitting) within a non-
</pre>
<hr />
<pre>
2363 #if OS(LINUX)
2364     static inline void linuxPageFlush(uintptr_t begin, uintptr_t end)
2365     {
2366         asm volatile(
2367             &quot;push    {r7}\n&quot;
2368             &quot;mov     r0, %0\n&quot;
2369             &quot;mov     r1, %1\n&quot;
2370             &quot;movw    r7, #0x2\n&quot;
2371             &quot;movt    r7, #0xf\n&quot;
2372             &quot;movs    r2, #0x0\n&quot;
2373             &quot;svc     0x0\n&quot;
2374             &quot;pop     {r7}\n&quot;
2375             :
2376             : &quot;r&quot; (begin), &quot;r&quot; (end)
2377             : &quot;r0&quot;, &quot;r1&quot;, &quot;r2&quot;);
2378     }
2379 #endif
2380 
2381     static void cacheFlush(void* code, size_t size)
2382     {
<span class="line-modified">2383 #if OS(DARWIN)</span>
2384         sys_cache_control(kCacheFunctionPrepareForExecution, code, size);
2385 #elif OS(LINUX)
2386         size_t page = pageSize();
2387         uintptr_t current = reinterpret_cast&lt;uintptr_t&gt;(code);
2388         uintptr_t end = current + size;
2389         uintptr_t firstPageEnd = (current &amp; ~(page - 1)) + page;
2390 
2391         if (end &lt;= firstPageEnd) {
2392             linuxPageFlush(current, end);
2393             return;
2394         }
2395 
2396         linuxPageFlush(current, firstPageEnd);
2397 
2398         for (current = firstPageEnd; current + page &lt; end; current += page)
2399             linuxPageFlush(current, current + page);
2400 
2401         linuxPageFlush(current, end);
2402 #else
2403 #error &quot;The cacheFlush support is missing on this platform.&quot;
</pre>
<hr />
<pre>
2587     }
2588 
2589     static bool canBeJumpT3(const uint16_t* instruction, const void* target)
2590     {
2591         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2592         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2593 
2594         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2595         return ((relative &lt;&lt; 11) &gt;&gt; 11) == relative;
2596     }
2597 
2598     static bool canBeJumpT4(const uint16_t* instruction, const void* target)
2599     {
2600         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2601         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2602 
2603         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2604         return ((relative &lt;&lt; 7) &gt;&gt; 7) == relative;
2605     }
2606 
<span class="line-modified">2607     template&lt;CopyFunction copy = performJITMemcpy&gt;</span>
<span class="line-added">2608     static void linkJumpT1(Condition cond, uint16_t* writeTarget, const uint16_t* instruction, void* target)</span>
2609     {
2610         // FIMXE: this should be up in the MacroAssembler layer. :-(
2611         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2612         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2613         ASSERT(canBeJumpT1(instruction, target));
2614 
2615         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2616         // It does not appear to be documented in the ARM ARM (big surprise), but
2617         // for OP_B_T1 the branch displacement encoded in the instruction is 2
2618         // less than the actual displacement.
2619         relative -= 2;
2620 
2621         // All branch offsets should be an even distance.
2622         ASSERT(!(relative &amp; 1));
2623         uint16_t newInstruction = OP_B_T1 | ((cond &amp; 0xf) &lt;&lt; 8) | ((relative &amp; 0x1fe) &gt;&gt; 1);
2624         copy(writeTarget - 1, &amp;newInstruction, sizeof(uint16_t));
2625     }
2626 
<span class="line-modified">2627     template&lt;CopyFunction copy = performJITMemcpy&gt;</span>
<span class="line-added">2628     static void linkJumpT2(uint16_t* writeTarget, const uint16_t* instruction, void* target)</span>
2629     {
2630         // FIMXE: this should be up in the MacroAssembler layer. :-(
2631         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2632         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2633         ASSERT(canBeJumpT2(instruction, target));
2634 
2635         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2636         // It does not appear to be documented in the ARM ARM (big surprise), but
2637         // for OP_B_T2 the branch displacement encoded in the instruction is 2
2638         // less than the actual displacement.
2639         relative -= 2;
2640 
2641         // All branch offsets should be an even distance.
2642         ASSERT(!(relative &amp; 1));
2643         uint16_t newInstruction = OP_B_T2 | ((relative &amp; 0xffe) &gt;&gt; 1);
2644         copy(writeTarget - 1, &amp;newInstruction, sizeof(uint16_t));
2645     }
2646 
<span class="line-modified">2647     template&lt;CopyFunction copy = performJITMemcpy&gt;</span>
<span class="line-added">2648     static void linkJumpT3(Condition cond, uint16_t* writeTarget, const uint16_t* instruction, void* target)</span>
2649     {
2650         // FIMXE: this should be up in the MacroAssembler layer. :-(
2651         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2652         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2653         ASSERT(canBeJumpT3(instruction, target));
2654 
2655         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2656 
2657         // All branch offsets should be an even distance.
2658         ASSERT(!(relative &amp; 1));
2659         uint16_t instructions[2];
2660         instructions[0] = OP_B_T3a | ((relative &amp; 0x100000) &gt;&gt; 10) | ((cond &amp; 0xf) &lt;&lt; 6) | ((relative &amp; 0x3f000) &gt;&gt; 12);
2661         instructions[1] = OP_B_T3b | ((relative &amp; 0x80000) &gt;&gt; 8) | ((relative &amp; 0x40000) &gt;&gt; 5) | ((relative &amp; 0xffe) &gt;&gt; 1);
2662         copy(writeTarget - 2, instructions, 2 * sizeof(uint16_t));
2663     }
2664 
<span class="line-modified">2665     template&lt;CopyFunction copy = performJITMemcpy&gt;</span>
<span class="line-added">2666     static void linkJumpT4(uint16_t* writeTarget, const uint16_t* instruction, void* target)</span>
2667     {
2668         // FIMXE: this should be up in the MacroAssembler layer. :-(
2669         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2670         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2671         ASSERT(canBeJumpT4(instruction, target));
2672 
2673         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2674         // ARM encoding for the top two bits below the sign bit is &#39;peculiar&#39;.
2675         if (relative &gt;= 0)
2676             relative ^= 0xC00000;
2677 
2678         // All branch offsets should be an even distance.
2679         ASSERT(!(relative &amp; 1));
2680         uint16_t instructions[2];
2681         instructions[0] = OP_B_T4a | ((relative &amp; 0x1000000) &gt;&gt; 14) | ((relative &amp; 0x3ff000) &gt;&gt; 12);
2682         instructions[1] = OP_B_T4b | ((relative &amp; 0x800000) &gt;&gt; 10) | ((relative &amp; 0x400000) &gt;&gt; 11) | ((relative &amp; 0xffe) &gt;&gt; 1);
2683         copy(writeTarget - 2, instructions, 2 * sizeof(uint16_t));
2684     }
2685 
<span class="line-modified">2686     template&lt;CopyFunction copy = performJITMemcpy&gt;</span>
<span class="line-added">2687     static void linkConditionalJumpT4(Condition cond, uint16_t* writeTarget, const uint16_t* instruction, void* target)</span>
2688     {
2689         // FIMXE: this should be up in the MacroAssembler layer. :-(
2690         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2691         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2692 
2693         uint16_t newInstruction = ifThenElse(cond) | OP_IT;
2694         copy(writeTarget - 3, &amp;newInstruction, sizeof(uint16_t));
<span class="line-modified">2695         linkJumpT4&lt;copy&gt;(writeTarget, instruction, target);</span>
2696     }
2697 
<span class="line-modified">2698     template&lt;CopyFunction copy = performJITMemcpy&gt;</span>
<span class="line-added">2699     static void linkBX(uint16_t* writeTarget, const uint16_t* instruction, void* target)</span>
2700     {
2701         // FIMXE: this should be up in the MacroAssembler layer. :-(
2702         ASSERT_UNUSED(instruction, !(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2703         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(writeTarget) &amp; 1));
2704         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2705 
2706         const uint16_t JUMP_TEMPORARY_REGISTER = ARMRegisters::ip;
2707         ARMThumbImmediate lo16 = ARMThumbImmediate::makeUInt16(static_cast&lt;uint16_t&gt;(reinterpret_cast&lt;uint32_t&gt;(target) + 1));
2708         ARMThumbImmediate hi16 = ARMThumbImmediate::makeUInt16(static_cast&lt;uint16_t&gt;(reinterpret_cast&lt;uint32_t&gt;(target) &gt;&gt; 16));
2709         uint16_t instructions[5];
2710         instructions[0] = twoWordOp5i6Imm4Reg4EncodedImmFirst(OP_MOV_imm_T3, lo16);
2711         instructions[1] = twoWordOp5i6Imm4Reg4EncodedImmSecond(JUMP_TEMPORARY_REGISTER, lo16);
2712         instructions[2] = twoWordOp5i6Imm4Reg4EncodedImmFirst(OP_MOVT, hi16);
2713         instructions[3] = twoWordOp5i6Imm4Reg4EncodedImmSecond(JUMP_TEMPORARY_REGISTER, hi16);
2714         instructions[4] = OP_BX | (JUMP_TEMPORARY_REGISTER &lt;&lt; 3);
2715 
2716         copy(writeTarget - 5, instructions, 5 * sizeof(uint16_t));
2717     }
2718 
<span class="line-modified">2719     template&lt;CopyFunction copy = performJITMemcpy&gt;</span>
<span class="line-added">2720     static void linkConditionalBX(Condition cond, uint16_t* writeTarget, const uint16_t* instruction, void* target)</span>
2721     {
2722         // FIMXE: this should be up in the MacroAssembler layer. :-(
2723         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2724         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2725 
2726         linkBX(writeTarget, instruction, target);
2727         uint16_t newInstruction = ifThenElse(cond, true, true) | OP_IT;
2728         copy(writeTarget - 6, &amp;newInstruction, sizeof(uint16_t));
2729     }
2730 
2731     static void linkJumpAbsolute(uint16_t* writeTarget, const uint16_t* instruction, void* target)
2732     {
2733         // FIMXE: this should be up in the MacroAssembler layer. :-(
2734         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2735         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2736 
2737         ASSERT((isMOV_imm_T3(instruction - 5) &amp;&amp; isMOVT(instruction - 3) &amp;&amp; isBX(instruction - 1))
2738                || (isNOP_T1(instruction - 5) &amp;&amp; isNOP_T2(instruction - 4) &amp;&amp; isB(instruction - 2)));
2739 
2740         if (canBeJumpT4(instruction, target)) {
</pre>
</td>
</tr>
</table>
<center><a href="ARM64Registers.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="ARMv7Registers.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>