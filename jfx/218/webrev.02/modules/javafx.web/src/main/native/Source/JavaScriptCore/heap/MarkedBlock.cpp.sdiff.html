<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/MarkedBlock.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="MarkStackMergingConstraint.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="MarkedBlock.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/MarkedBlock.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;MarkedBlock.h&quot;
 28 
 29 #include &quot;AlignedMemoryAllocator.h&quot;
 30 #include &quot;BlockDirectoryInlines.h&quot;
 31 #include &quot;FreeListInlines.h&quot;
 32 #include &quot;JSCast.h&quot;
 33 #include &quot;JSDestructibleObject.h&quot;
 34 #include &quot;JSCInlines.h&quot;
 35 #include &quot;MarkedBlockInlines.h&quot;
 36 #include &quot;SuperSampler.h&quot;
 37 #include &quot;SweepingScope.h&quot;
 38 #include &lt;wtf/CommaPrinter.h&gt;
 39 
 40 namespace JSC {
 41 namespace MarkedBlockInternal {
 42 static constexpr bool verbose = false;
 43 }
 44 
<span class="line-modified"> 45 const size_t MarkedBlock::blockSize;</span>
<span class="line-removed"> 46 </span>
<span class="line-removed"> 47 static const bool computeBalance = false;</span>
 48 static size_t balance;
 49 



 50 MarkedBlock::Handle* MarkedBlock::tryCreate(Heap&amp; heap, AlignedMemoryAllocator* alignedMemoryAllocator)
 51 {
 52     if (computeBalance) {
 53         balance++;
 54         if (!(balance % 10))
 55             dataLog(&quot;MarkedBlock Balance: &quot;, balance, &quot;\n&quot;);
 56     }
 57     void* blockSpace = alignedMemoryAllocator-&gt;tryAllocateAlignedMemory(blockSize, blockSize);
 58     if (!blockSpace)
 59         return nullptr;
 60     if (scribbleFreeCells())
 61         scribble(blockSpace, blockSize);
 62     return new Handle(heap, alignedMemoryAllocator, blockSpace);
 63 }
 64 
 65 MarkedBlock::Handle::Handle(Heap&amp; heap, AlignedMemoryAllocator* alignedMemoryAllocator, void* blockSpace)
 66     : m_alignedMemoryAllocator(alignedMemoryAllocator)
<span class="line-modified"> 67     , m_weakSet(heap.vm(), CellContainer())</span>
 68 {
 69     m_block = new (NotNull, blockSpace) MarkedBlock(heap.vm(), *this);
 70 
<span class="line-removed"> 71     m_weakSet.setContainer(*m_block);</span>
<span class="line-removed"> 72 </span>
 73     heap.didAllocateBlock(blockSize);
 74 }
 75 
 76 MarkedBlock::Handle::~Handle()
 77 {
 78     Heap&amp; heap = *this-&gt;heap();
 79     if (computeBalance) {
 80         balance--;
 81         if (!(balance % 10))
 82             dataLog(&quot;MarkedBlock Balance: &quot;, balance, &quot;\n&quot;);
 83     }
 84     removeFromDirectory();
 85     m_block-&gt;~MarkedBlock();
 86     m_alignedMemoryAllocator-&gt;freeAlignedMemory(m_block);
 87     heap.didFreeBlock(blockSize);
 88 }
 89 
 90 MarkedBlock::MarkedBlock(VM&amp; vm, Handle&amp; handle)
 91 {
 92     new (&amp;footer()) Footer(vm, handle);
</pre>
<hr />
<pre>
100 }
101 
102 MarkedBlock::Footer::Footer(VM&amp; vm, Handle&amp; handle)
103     : m_handle(handle)
104     , m_vm(&amp;vm)
105     , m_markingVersion(MarkedSpace::nullVersion)
106     , m_newlyAllocatedVersion(MarkedSpace::nullVersion)
107 {
108 }
109 
110 MarkedBlock::Footer::~Footer()
111 {
112 }
113 
114 void MarkedBlock::Handle::unsweepWithNoNewlyAllocated()
115 {
116     RELEASE_ASSERT(m_isFreeListed);
117     m_isFreeListed = false;
118 }
119 
<span class="line-removed">120 void MarkedBlock::Handle::setIsFreeListed()</span>
<span class="line-removed">121 {</span>
<span class="line-removed">122     m_directory-&gt;setIsEmpty(NoLockingNecessary, this, false);</span>
<span class="line-removed">123     m_isFreeListed = true;</span>
<span class="line-removed">124 }</span>
<span class="line-removed">125 </span>
126 void MarkedBlock::Handle::stopAllocating(const FreeList&amp; freeList)
127 {
128     auto locker = holdLock(blockFooter().m_lock);
129 
130     if (MarkedBlockInternal::verbose)
131         dataLog(RawPointer(this), &quot;: MarkedBlock::Handle::stopAllocating!\n&quot;);
132     ASSERT(!directory()-&gt;isAllocated(NoLockingNecessary, this));
133 
134     if (!isFreeListed()) {
135         if (MarkedBlockInternal::verbose)
136             dataLog(&quot;There ain&#39;t no newly allocated.\n&quot;);
137         // This means that we either didn&#39;t use this block at all for allocation since last GC,
138         // or someone had already done stopAllocating() before.
139         ASSERT(freeList.allocationWillFail());
140         return;
141     }
142 
143     if (MarkedBlockInternal::verbose)
144         dataLog(&quot;Free list: &quot;, freeList, &quot;\n&quot;);
145 
146     // Roll back to a coherent state for Heap introspection. Cells newly
147     // allocated from our free list are not currently marked, so we need another
148     // way to tell what&#39;s live vs dead.
149 
150     blockFooter().m_newlyAllocated.clearAll();
151     blockFooter().m_newlyAllocatedVersion = heap()-&gt;objectSpace().newlyAllocatedVersion();
152 
153     forEachCell(
<span class="line-modified">154         [&amp;] (HeapCell* cell, HeapCell::Kind) -&gt; IterationStatus {</span>
155             block().setNewlyAllocated(cell);
156             return IterationStatus::Continue;
157         });
158 
159     freeList.forEach(
160         [&amp;] (HeapCell* cell) {
161             if (MarkedBlockInternal::verbose)
162                 dataLog(&quot;Free cell: &quot;, RawPointer(cell), &quot;\n&quot;);
163             if (m_attributes.destruction == NeedsDestruction)
164                 cell-&gt;zap(HeapCell::StopAllocating);
165             block().clearNewlyAllocated(cell);
166         });
167 
168     m_isFreeListed = false;
169 }
170 
171 void MarkedBlock::Handle::lastChanceToFinalize()
172 {
173     directory()-&gt;setIsAllocated(NoLockingNecessary, this, false);
174     directory()-&gt;setIsDestructible(NoLockingNecessary, this, true);
</pre>
<hr />
<pre>
255 
256 void MarkedBlock::resetAllocated()
257 {
258     footer().m_newlyAllocated.clearAll();
259     footer().m_newlyAllocatedVersion = MarkedSpace::nullVersion;
260 }
261 
262 void MarkedBlock::resetMarks()
263 {
264     // We want aboutToMarkSlow() to see what the mark bits were after the last collection. It uses
265     // the version number to distinguish between the marks having already been stale before
266     // beginMarking(), or just stale now that beginMarking() bumped the version. If we have a version
267     // wraparound, then we will call this method before resetting the version to null. When the
268     // version is null, aboutToMarkSlow() will assume that the marks were not stale as of before
269     // beginMarking(). Hence the need to whip the marks into shape.
270     if (areMarksStale())
271         footer().m_marks.clearAll();
272     footer().m_markingVersion = MarkedSpace::nullVersion;
273 }
274 
<span class="line-modified">275 #if !ASSERT_DISABLED</span>
276 void MarkedBlock::assertMarksNotStale()
277 {
278     ASSERT(footer().m_markingVersion == vm().heap.objectSpace().markingVersion());
279 }
<span class="line-modified">280 #endif // !ASSERT_DISABLED</span>
281 
282 bool MarkedBlock::areMarksStale()
283 {
284     return areMarksStale(vm().heap.objectSpace().markingVersion());
285 }
286 
287 bool MarkedBlock::Handle::areMarksStale()
288 {
289     return m_block-&gt;areMarksStale();
290 }
291 
292 bool MarkedBlock::isMarked(const void* p)
293 {
294     return isMarked(vm().heap.objectSpace().markingVersion(), p);
295 }
296 
297 void MarkedBlock::Handle::didConsumeFreeList()
298 {
299     auto locker = holdLock(blockFooter().m_lock);
300     if (MarkedBlockInternal::verbose)
</pre>
<hr />
<pre>
311 
312 void MarkedBlock::clearHasAnyMarked()
313 {
314     footer().m_biasedMarkCount = footer().m_markCountBias;
315 }
316 
317 void MarkedBlock::noteMarkedSlow()
318 {
319     BlockDirectory* directory = handle().directory();
320     directory-&gt;setIsMarkingRetired(holdLock(directory-&gt;bitvectorLock()), &amp;handle(), true);
321 }
322 
323 void MarkedBlock::Handle::removeFromDirectory()
324 {
325     if (!m_directory)
326         return;
327 
328     m_directory-&gt;removeBlock(this);
329 }
330 
<span class="line-modified">331 void MarkedBlock::Handle::didAddToDirectory(BlockDirectory* directory, size_t index)</span>
332 {
<span class="line-modified">333     ASSERT(m_index == std::numeric_limits&lt;size_t&gt;::max());</span>
334     ASSERT(!m_directory);
335 
336     RELEASE_ASSERT(directory-&gt;subspace()-&gt;alignedMemoryAllocator() == m_alignedMemoryAllocator);
337 
338     m_index = index;
339     m_directory = directory;
340     blockFooter().m_subspace = directory-&gt;subspace();
341 
342     size_t cellSize = directory-&gt;cellSize();
343     m_atomsPerCell = (cellSize + atomSize - 1) / atomSize;
344     m_endAtom = endAtom - m_atomsPerCell + 1;
345 
346     m_attributes = directory-&gt;attributes();
347 
348     if (!isJSCellKind(m_attributes.cellKind))
349         RELEASE_ASSERT(m_attributes.destruction == DoesNotNeedDestruction);
350 
351     double markCountBias = -(Options::minMarkedBlockUtilization() * cellsPerBlock());
352 
353     // The mark count bias should be comfortably within this range.
354     RELEASE_ASSERT(markCountBias &gt; static_cast&lt;double&gt;(std::numeric_limits&lt;int16_t&gt;::min()));
355     RELEASE_ASSERT(markCountBias &lt; 0);
356 
357     // This means we haven&#39;t marked anything yet.
358     blockFooter().m_biasedMarkCount = blockFooter().m_markCountBias = static_cast&lt;int16_t&gt;(markCountBias);
359 }
360 
361 void MarkedBlock::Handle::didRemoveFromDirectory()
362 {
<span class="line-modified">363     ASSERT(m_index != std::numeric_limits&lt;size_t&gt;::max());</span>
364     ASSERT(m_directory);
365 
<span class="line-modified">366     m_index = std::numeric_limits&lt;size_t&gt;::max();</span>
367     m_directory = nullptr;
368     blockFooter().m_subspace = nullptr;
369 }
370 
<span class="line-modified">371 #if !ASSERT_DISABLED</span>
372 void MarkedBlock::assertValidCell(VM&amp; vm, HeapCell* cell) const
373 {
374     RELEASE_ASSERT(&amp;vm == &amp;this-&gt;vm());
375     RELEASE_ASSERT(const_cast&lt;MarkedBlock*&gt;(this)-&gt;handle().cellAlign(cell) == cell);
376 }
<span class="line-modified">377 #endif</span>
378 
379 void MarkedBlock::Handle::dumpState(PrintStream&amp; out)
380 {
381     CommaPrinter comma;
382     directory()-&gt;forEachBitVectorWithName(
383         holdLock(directory()-&gt;bitvectorLock()),
<span class="line-modified">384         [&amp;] (FastBitVector&amp; bitvector, const char* name) {</span>
<span class="line-modified">385             out.print(comma, name, &quot;:&quot;, bitvector[index()] ? &quot;YES&quot; : &quot;no&quot;);</span>
386         });
387 }
388 
389 Subspace* MarkedBlock::Handle::subspace() const
390 {
391     return directory()-&gt;subspace();
392 }
393 
394 void MarkedBlock::Handle::sweep(FreeList* freeList)
395 {
396     SweepingScope sweepingScope(*heap());
397 
398     SweepMode sweepMode = freeList ? SweepToFreeList : SweepOnly;
399 
400     m_directory-&gt;setIsUnswept(NoLockingNecessary, this, false);
401 
402     m_weakSet.sweep();
403 
404     bool needsDestruction = m_attributes.destruction == NeedsDestruction
405         &amp;&amp; m_directory-&gt;isDestructible(NoLockingNecessary, this);
</pre>
</td>
<td>
<hr />
<pre>
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;MarkedBlock.h&quot;
 28 
 29 #include &quot;AlignedMemoryAllocator.h&quot;
 30 #include &quot;BlockDirectoryInlines.h&quot;
 31 #include &quot;FreeListInlines.h&quot;
 32 #include &quot;JSCast.h&quot;
 33 #include &quot;JSDestructibleObject.h&quot;
 34 #include &quot;JSCInlines.h&quot;
 35 #include &quot;MarkedBlockInlines.h&quot;
 36 #include &quot;SuperSampler.h&quot;
 37 #include &quot;SweepingScope.h&quot;
 38 #include &lt;wtf/CommaPrinter.h&gt;
 39 
 40 namespace JSC {
 41 namespace MarkedBlockInternal {
 42 static constexpr bool verbose = false;
 43 }
 44 
<span class="line-modified"> 45 static constexpr bool computeBalance = false;</span>


 46 static size_t balance;
 47 
<span class="line-added"> 48 DEFINE_ALLOCATOR_WITH_HEAP_IDENTIFIER(MarkedBlock);</span>
<span class="line-added"> 49 DEFINE_ALLOCATOR_WITH_HEAP_IDENTIFIER(MarkedBlockHandle);</span>
<span class="line-added"> 50 </span>
 51 MarkedBlock::Handle* MarkedBlock::tryCreate(Heap&amp; heap, AlignedMemoryAllocator* alignedMemoryAllocator)
 52 {
 53     if (computeBalance) {
 54         balance++;
 55         if (!(balance % 10))
 56             dataLog(&quot;MarkedBlock Balance: &quot;, balance, &quot;\n&quot;);
 57     }
 58     void* blockSpace = alignedMemoryAllocator-&gt;tryAllocateAlignedMemory(blockSize, blockSize);
 59     if (!blockSpace)
 60         return nullptr;
 61     if (scribbleFreeCells())
 62         scribble(blockSpace, blockSize);
 63     return new Handle(heap, alignedMemoryAllocator, blockSpace);
 64 }
 65 
 66 MarkedBlock::Handle::Handle(Heap&amp; heap, AlignedMemoryAllocator* alignedMemoryAllocator, void* blockSpace)
 67     : m_alignedMemoryAllocator(alignedMemoryAllocator)
<span class="line-modified"> 68     , m_weakSet(heap.vm())</span>
 69 {
 70     m_block = new (NotNull, blockSpace) MarkedBlock(heap.vm(), *this);
 71 


 72     heap.didAllocateBlock(blockSize);
 73 }
 74 
 75 MarkedBlock::Handle::~Handle()
 76 {
 77     Heap&amp; heap = *this-&gt;heap();
 78     if (computeBalance) {
 79         balance--;
 80         if (!(balance % 10))
 81             dataLog(&quot;MarkedBlock Balance: &quot;, balance, &quot;\n&quot;);
 82     }
 83     removeFromDirectory();
 84     m_block-&gt;~MarkedBlock();
 85     m_alignedMemoryAllocator-&gt;freeAlignedMemory(m_block);
 86     heap.didFreeBlock(blockSize);
 87 }
 88 
 89 MarkedBlock::MarkedBlock(VM&amp; vm, Handle&amp; handle)
 90 {
 91     new (&amp;footer()) Footer(vm, handle);
</pre>
<hr />
<pre>
 99 }
100 
101 MarkedBlock::Footer::Footer(VM&amp; vm, Handle&amp; handle)
102     : m_handle(handle)
103     , m_vm(&amp;vm)
104     , m_markingVersion(MarkedSpace::nullVersion)
105     , m_newlyAllocatedVersion(MarkedSpace::nullVersion)
106 {
107 }
108 
109 MarkedBlock::Footer::~Footer()
110 {
111 }
112 
113 void MarkedBlock::Handle::unsweepWithNoNewlyAllocated()
114 {
115     RELEASE_ASSERT(m_isFreeListed);
116     m_isFreeListed = false;
117 }
118 






119 void MarkedBlock::Handle::stopAllocating(const FreeList&amp; freeList)
120 {
121     auto locker = holdLock(blockFooter().m_lock);
122 
123     if (MarkedBlockInternal::verbose)
124         dataLog(RawPointer(this), &quot;: MarkedBlock::Handle::stopAllocating!\n&quot;);
125     ASSERT(!directory()-&gt;isAllocated(NoLockingNecessary, this));
126 
127     if (!isFreeListed()) {
128         if (MarkedBlockInternal::verbose)
129             dataLog(&quot;There ain&#39;t no newly allocated.\n&quot;);
130         // This means that we either didn&#39;t use this block at all for allocation since last GC,
131         // or someone had already done stopAllocating() before.
132         ASSERT(freeList.allocationWillFail());
133         return;
134     }
135 
136     if (MarkedBlockInternal::verbose)
137         dataLog(&quot;Free list: &quot;, freeList, &quot;\n&quot;);
138 
139     // Roll back to a coherent state for Heap introspection. Cells newly
140     // allocated from our free list are not currently marked, so we need another
141     // way to tell what&#39;s live vs dead.
142 
143     blockFooter().m_newlyAllocated.clearAll();
144     blockFooter().m_newlyAllocatedVersion = heap()-&gt;objectSpace().newlyAllocatedVersion();
145 
146     forEachCell(
<span class="line-modified">147         [&amp;] (size_t, HeapCell* cell, HeapCell::Kind) -&gt; IterationStatus {</span>
148             block().setNewlyAllocated(cell);
149             return IterationStatus::Continue;
150         });
151 
152     freeList.forEach(
153         [&amp;] (HeapCell* cell) {
154             if (MarkedBlockInternal::verbose)
155                 dataLog(&quot;Free cell: &quot;, RawPointer(cell), &quot;\n&quot;);
156             if (m_attributes.destruction == NeedsDestruction)
157                 cell-&gt;zap(HeapCell::StopAllocating);
158             block().clearNewlyAllocated(cell);
159         });
160 
161     m_isFreeListed = false;
162 }
163 
164 void MarkedBlock::Handle::lastChanceToFinalize()
165 {
166     directory()-&gt;setIsAllocated(NoLockingNecessary, this, false);
167     directory()-&gt;setIsDestructible(NoLockingNecessary, this, true);
</pre>
<hr />
<pre>
248 
249 void MarkedBlock::resetAllocated()
250 {
251     footer().m_newlyAllocated.clearAll();
252     footer().m_newlyAllocatedVersion = MarkedSpace::nullVersion;
253 }
254 
255 void MarkedBlock::resetMarks()
256 {
257     // We want aboutToMarkSlow() to see what the mark bits were after the last collection. It uses
258     // the version number to distinguish between the marks having already been stale before
259     // beginMarking(), or just stale now that beginMarking() bumped the version. If we have a version
260     // wraparound, then we will call this method before resetting the version to null. When the
261     // version is null, aboutToMarkSlow() will assume that the marks were not stale as of before
262     // beginMarking(). Hence the need to whip the marks into shape.
263     if (areMarksStale())
264         footer().m_marks.clearAll();
265     footer().m_markingVersion = MarkedSpace::nullVersion;
266 }
267 
<span class="line-modified">268 #if ASSERT_ENABLED</span>
269 void MarkedBlock::assertMarksNotStale()
270 {
271     ASSERT(footer().m_markingVersion == vm().heap.objectSpace().markingVersion());
272 }
<span class="line-modified">273 #endif // ASSERT_ENABLED</span>
274 
275 bool MarkedBlock::areMarksStale()
276 {
277     return areMarksStale(vm().heap.objectSpace().markingVersion());
278 }
279 
280 bool MarkedBlock::Handle::areMarksStale()
281 {
282     return m_block-&gt;areMarksStale();
283 }
284 
285 bool MarkedBlock::isMarked(const void* p)
286 {
287     return isMarked(vm().heap.objectSpace().markingVersion(), p);
288 }
289 
290 void MarkedBlock::Handle::didConsumeFreeList()
291 {
292     auto locker = holdLock(blockFooter().m_lock);
293     if (MarkedBlockInternal::verbose)
</pre>
<hr />
<pre>
304 
305 void MarkedBlock::clearHasAnyMarked()
306 {
307     footer().m_biasedMarkCount = footer().m_markCountBias;
308 }
309 
310 void MarkedBlock::noteMarkedSlow()
311 {
312     BlockDirectory* directory = handle().directory();
313     directory-&gt;setIsMarkingRetired(holdLock(directory-&gt;bitvectorLock()), &amp;handle(), true);
314 }
315 
316 void MarkedBlock::Handle::removeFromDirectory()
317 {
318     if (!m_directory)
319         return;
320 
321     m_directory-&gt;removeBlock(this);
322 }
323 
<span class="line-modified">324 void MarkedBlock::Handle::didAddToDirectory(BlockDirectory* directory, unsigned index)</span>
325 {
<span class="line-modified">326     ASSERT(m_index == std::numeric_limits&lt;unsigned&gt;::max());</span>
327     ASSERT(!m_directory);
328 
329     RELEASE_ASSERT(directory-&gt;subspace()-&gt;alignedMemoryAllocator() == m_alignedMemoryAllocator);
330 
331     m_index = index;
332     m_directory = directory;
333     blockFooter().m_subspace = directory-&gt;subspace();
334 
335     size_t cellSize = directory-&gt;cellSize();
336     m_atomsPerCell = (cellSize + atomSize - 1) / atomSize;
337     m_endAtom = endAtom - m_atomsPerCell + 1;
338 
339     m_attributes = directory-&gt;attributes();
340 
341     if (!isJSCellKind(m_attributes.cellKind))
342         RELEASE_ASSERT(m_attributes.destruction == DoesNotNeedDestruction);
343 
344     double markCountBias = -(Options::minMarkedBlockUtilization() * cellsPerBlock());
345 
346     // The mark count bias should be comfortably within this range.
347     RELEASE_ASSERT(markCountBias &gt; static_cast&lt;double&gt;(std::numeric_limits&lt;int16_t&gt;::min()));
348     RELEASE_ASSERT(markCountBias &lt; 0);
349 
350     // This means we haven&#39;t marked anything yet.
351     blockFooter().m_biasedMarkCount = blockFooter().m_markCountBias = static_cast&lt;int16_t&gt;(markCountBias);
352 }
353 
354 void MarkedBlock::Handle::didRemoveFromDirectory()
355 {
<span class="line-modified">356     ASSERT(m_index != std::numeric_limits&lt;unsigned&gt;::max());</span>
357     ASSERT(m_directory);
358 
<span class="line-modified">359     m_index = std::numeric_limits&lt;unsigned&gt;::max();</span>
360     m_directory = nullptr;
361     blockFooter().m_subspace = nullptr;
362 }
363 
<span class="line-modified">364 #if ASSERT_ENABLED</span>
365 void MarkedBlock::assertValidCell(VM&amp; vm, HeapCell* cell) const
366 {
367     RELEASE_ASSERT(&amp;vm == &amp;this-&gt;vm());
368     RELEASE_ASSERT(const_cast&lt;MarkedBlock*&gt;(this)-&gt;handle().cellAlign(cell) == cell);
369 }
<span class="line-modified">370 #endif // ASSERT_ENABLED</span>
371 
372 void MarkedBlock::Handle::dumpState(PrintStream&amp; out)
373 {
374     CommaPrinter comma;
375     directory()-&gt;forEachBitVectorWithName(
376         holdLock(directory()-&gt;bitvectorLock()),
<span class="line-modified">377         [&amp;](auto vectorRef, const char* name) {</span>
<span class="line-modified">378             out.print(comma, name, &quot;:&quot;, vectorRef[index()] ? &quot;YES&quot; : &quot;no&quot;);</span>
379         });
380 }
381 
382 Subspace* MarkedBlock::Handle::subspace() const
383 {
384     return directory()-&gt;subspace();
385 }
386 
387 void MarkedBlock::Handle::sweep(FreeList* freeList)
388 {
389     SweepingScope sweepingScope(*heap());
390 
391     SweepMode sweepMode = freeList ? SweepToFreeList : SweepOnly;
392 
393     m_directory-&gt;setIsUnswept(NoLockingNecessary, this, false);
394 
395     m_weakSet.sweep();
396 
397     bool needsDestruction = m_attributes.destruction == NeedsDestruction
398         &amp;&amp; m_directory-&gt;isDestructible(NoLockingNecessary, this);
</pre>
</td>
</tr>
</table>
<center><a href="MarkStackMergingConstraint.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="MarkedBlock.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>