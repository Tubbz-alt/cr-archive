diff a/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediastream/MediaStreamTrack.h b/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediastream/MediaStreamTrack.h
--- a/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediastream/MediaStreamTrack.h
+++ b/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediastream/MediaStreamTrack.h
@@ -30,31 +30,32 @@
 #if ENABLE(MEDIA_STREAM)
 
 #include "ActiveDOMObject.h"
 #include "DoubleRange.h"
 #include "EventTarget.h"
-#include "GenericTaskQueue.h"
-#include "JSDOMPromiseDeferred.h"
 #include "LongRange.h"
 #include "MediaProducer.h"
 #include "MediaStreamTrackPrivate.h"
 #include "MediaTrackConstraints.h"
+#include "PlatformMediaSession.h"
 #include <wtf/LoggerHelper.h>
 
 namespace WebCore {
 
 class AudioSourceProvider;
 class Document;
 
 struct MediaTrackConstraints;
 
+template<typename IDLType> class DOMPromiseDeferred;
+
 class MediaStreamTrack
     : public RefCounted<MediaStreamTrack>
     , public ActiveDOMObject
     , public EventTargetWithInlineData
-    , public MediaProducer
     , private MediaStreamTrackPrivate::Observer
+    , private PlatformMediaSessionClient
 #if !RELEASE_LOG_DISABLED
     , private LoggerHelper
 #endif
 {
     WTF_MAKE_ISO_ALLOCATED(MediaStreamTrack);
@@ -68,14 +69,12 @@
     static Ref<MediaStreamTrack> create(ScriptExecutionContext&, Ref<MediaStreamTrackPrivate>&&);
     virtual ~MediaStreamTrack();
 
     static void endCapture(Document&);
 
-#if PLATFORM(IOS_FAMILY)
-    static MediaProducer::MediaStateFlags captureState();
-    static void muteCapture();
-#endif
+    static MediaProducer::MediaStateFlags captureState(Document&);
+    static void updateCaptureAccordingToMutedState(Document&);
 
     virtual bool isCanvas() const { return false; }
 
     const AtomString& kind() const;
     WEBCORE_EXPORT const String& id() const;
@@ -140,13 +139,11 @@
     RealtimeMediaSource& source() const { return m_private->source(); }
     MediaStreamTrackPrivate& privateTrack() { return m_private.get(); }
 
     AudioSourceProvider* audioSourceProvider();
 
-    // MediaProducer
-    void pageMutedStateDidChange() final;
-    MediaProducer::MediaStateFlags mediaState() const final;
+    MediaProducer::MediaStateFlags mediaState() const;
 
     void addObserver(Observer&);
     void removeObserver(Observer&);
 
     using RefCounted::ref;
@@ -175,13 +172,13 @@
     void configureTrackRendering();
 
     Document* document() const;
 
     // ActiveDOMObject API.
-    void stop() final;
-    const char* activeDOMObjectName() const final;
-    bool canSuspendForDocumentSuspension() const final;
+    void stop() final { stopTrack(); }
+    const char* activeDOMObjectName() const override;
+    void suspend(ReasonForSuspension) final;
 
     // EventTarget
     void refEventTarget() final { ref(); }
     void derefEventTarget() final { deref(); }
     EventTargetInterface eventTargetInterface() const final { return MediaStreamTrackEventTargetInterfaceType; }
@@ -191,24 +188,39 @@
     void trackEnded(MediaStreamTrackPrivate&) final;
     void trackMutedChanged(MediaStreamTrackPrivate&) final;
     void trackSettingsChanged(MediaStreamTrackPrivate&) final;
     void trackEnabledChanged(MediaStreamTrackPrivate&) final;
 
+    // PlatformMediaSessionClient
+    PlatformMediaSession::MediaType mediaType() const final;
+    PlatformMediaSession::MediaType presentationType() const final;
+    PlatformMediaSession::CharacteristicsFlags characteristics() const final;
+    void mayResumePlayback(bool shouldResume) final;
+    void suspendPlayback() final;
+    bool canReceiveRemoteControlCommands() const final { return false; }
+    void didReceiveRemoteControlCommand(PlatformMediaSession::RemoteControlCommandType, const PlatformMediaSession::RemoteCommandArgument*) final { }
+    bool supportsSeeking() const final { return false; }
+    bool shouldOverrideBackgroundPlaybackRestriction(PlatformMediaSession::InterruptionType) const final { return false; }
+    String sourceApplicationIdentifier() const final;
+    bool canProduceAudio() const final;
+    Document* hostingDocument() const final { return document(); }
+    bool processingUserGestureForMedia() const final;
+    bool shouldOverridePauseDuringRouteChange() const final { return true; }
+
 #if !RELEASE_LOG_DISABLED
     const char* logClassName() const final { return "MediaStreamTrack"; }
     WTFLogChannel& logChannel() const final;
 #endif
 
     Vector<Observer*> m_observers;
 
     MediaTrackConstraints m_constraints;
-    Optional<DOMPromiseDeferred<void>> m_promise;
-    GenericTaskQueue<ScriptExecutionContext> m_taskQueue;
-    GenericTaskQueue<Timer> m_eventTaskQueue;
+    std::unique_ptr<DOMPromiseDeferred<void>> m_promise;
 
     bool m_ended { false };
     const bool m_isCaptureTrack { false };
+    std::unique_ptr<PlatformMediaSession> m_mediaSession;
 };
 
 typedef Vector<RefPtr<MediaStreamTrack>> MediaStreamTrackVector;
 
 } // namespace WebCore
