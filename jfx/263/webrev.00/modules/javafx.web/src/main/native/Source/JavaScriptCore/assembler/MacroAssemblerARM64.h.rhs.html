<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerARM64.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
<a name="1" id="anc1"></a><span class="line-modified">   2  * Copyright (C) 2012-2019 Apple Inc. All rights reserved.</span>
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #pragma once
  27 
  28 #if ENABLE(ASSEMBLER)
  29 
  30 #include &quot;ARM64Assembler.h&quot;
  31 #include &quot;AbstractMacroAssembler.h&quot;
  32 #include &lt;wtf/MathExtras.h&gt;
  33 #include &lt;wtf/Optional.h&gt;
  34 
  35 namespace JSC {
  36 
  37 using Assembler = TARGET_ASSEMBLER;
<a name="2" id="anc2"></a><span class="line-added">  38 class Reg;</span>
  39 
  40 class MacroAssemblerARM64 : public AbstractMacroAssembler&lt;Assembler&gt; {
  41 public:
<a name="3" id="anc3"></a><span class="line-modified">  42     static constexpr unsigned numGPRs = 32;</span>
<span class="line-modified">  43     static constexpr unsigned numFPRs = 32;</span>
  44 
  45     static constexpr RegisterID dataTempRegister = ARM64Registers::ip0;
  46     static constexpr RegisterID memoryTempRegister = ARM64Registers::ip1;
  47 
  48     RegisterID scratchRegister()
  49     {
  50         RELEASE_ASSERT(m_allowScratchRegister);
  51         return getCachedDataTempRegisterIDAndInvalidate();
  52     }
  53 
  54 protected:
<a name="4" id="anc4"></a><span class="line-modified">  55     static constexpr ARM64Registers::FPRegisterID fpTempRegister = ARM64Registers::q31;</span>
<span class="line-modified">  56     static constexpr Assembler::SetFlags S = Assembler::S;</span>
<span class="line-modified">  57     static constexpr int64_t maskHalfWord0 = 0xffffl;</span>
<span class="line-modified">  58     static constexpr int64_t maskHalfWord1 = 0xffff0000l;</span>
<span class="line-modified">  59     static constexpr int64_t maskUpperWord = 0xffffffff00000000l;</span>
  60 
  61     static constexpr size_t INSTRUCTION_SIZE = 4;
  62 
  63     // N instructions to load the pointer + 1 call instruction.
  64     static constexpr ptrdiff_t REPATCH_OFFSET_CALL_TO_POINTER = -((Assembler::MAX_POINTER_BITS / 16 + 1) * INSTRUCTION_SIZE);
  65 
  66 public:
  67     MacroAssemblerARM64()
  68         : m_dataMemoryTempRegister(this, dataTempRegister)
  69         , m_cachedMemoryTempRegister(this, memoryTempRegister)
  70         , m_makeJumpPatchable(false)
  71     {
  72     }
  73 
  74     typedef Assembler::LinkRecord LinkRecord;
  75     typedef Assembler::JumpType JumpType;
  76     typedef Assembler::JumpLinkType JumpLinkType;
  77     typedef Assembler::Condition Condition;
  78 
<a name="5" id="anc5"></a><span class="line-modified">  79     static constexpr Assembler::Condition DefaultCondition = Assembler::ConditionInvalid;</span>
<span class="line-modified">  80     static constexpr Assembler::JumpType DefaultJump = Assembler::JumpNoConditionFixedSize;</span>
  81 
  82     Vector&lt;LinkRecord, 0, UnsafeVectorOverflow&gt;&amp; jumpsToLink() { return m_assembler.jumpsToLink(); }
  83     static bool canCompact(JumpType jumpType) { return Assembler::canCompact(jumpType); }
  84     static JumpLinkType computeJumpType(JumpType jumpType, const uint8_t* from, const uint8_t* to) { return Assembler::computeJumpType(jumpType, from, to); }
  85     static JumpLinkType computeJumpType(LinkRecord&amp; record, const uint8_t* from, const uint8_t* to) { return Assembler::computeJumpType(record, from, to); }
  86     static int jumpSizeDelta(JumpType jumpType, JumpLinkType jumpLinkType) { return Assembler::jumpSizeDelta(jumpType, jumpLinkType); }
<a name="6" id="anc6"></a><span class="line-modified">  87     template &lt;Assembler::CopyFunction copy&gt;</span>
<span class="line-modified">  88     static void link(LinkRecord&amp; record, uint8_t* from, const uint8_t* fromInstruction, uint8_t* to) { return Assembler::link&lt;copy&gt;(record, from, fromInstruction, to); }</span>
  89 
<a name="7" id="anc7"></a><span class="line-modified">  90     static constexpr Scale ScalePtr = TimesEight;</span>
  91 
  92     static bool isCompactPtrAlignedAddressOffset(ptrdiff_t value)
  93     {
  94         // This is the largest 32-bit access allowed, aligned to 64-bit boundary.
  95         return !(value &amp; ~0x3ff8);
  96     }
  97 
  98     enum RelationalCondition {
  99         Equal = Assembler::ConditionEQ,
 100         NotEqual = Assembler::ConditionNE,
 101         Above = Assembler::ConditionHI,
 102         AboveOrEqual = Assembler::ConditionHS,
 103         Below = Assembler::ConditionLO,
 104         BelowOrEqual = Assembler::ConditionLS,
 105         GreaterThan = Assembler::ConditionGT,
 106         GreaterThanOrEqual = Assembler::ConditionGE,
 107         LessThan = Assembler::ConditionLT,
 108         LessThanOrEqual = Assembler::ConditionLE
 109     };
 110 
 111     enum ResultCondition {
 112         Overflow = Assembler::ConditionVS,
 113         Signed = Assembler::ConditionMI,
 114         PositiveOrZero = Assembler::ConditionPL,
 115         Zero = Assembler::ConditionEQ,
 116         NonZero = Assembler::ConditionNE
 117     };
 118 
 119     enum ZeroCondition {
 120         IsZero = Assembler::ConditionEQ,
 121         IsNonZero = Assembler::ConditionNE
 122     };
 123 
 124     enum DoubleCondition {
 125         // These conditions will only evaluate to true if the comparison is ordered - i.e. neither operand is NaN.
 126         DoubleEqual = Assembler::ConditionEQ,
 127         DoubleNotEqual = Assembler::ConditionVC, // Not the right flag! check for this &amp; handle differently.
 128         DoubleGreaterThan = Assembler::ConditionGT,
 129         DoubleGreaterThanOrEqual = Assembler::ConditionGE,
 130         DoubleLessThan = Assembler::ConditionLO,
 131         DoubleLessThanOrEqual = Assembler::ConditionLS,
 132         // If either operand is NaN, these conditions always evaluate to true.
 133         DoubleEqualOrUnordered = Assembler::ConditionVS, // Not the right flag! check for this &amp; handle differently.
 134         DoubleNotEqualOrUnordered = Assembler::ConditionNE,
 135         DoubleGreaterThanOrUnordered = Assembler::ConditionHI,
 136         DoubleGreaterThanOrEqualOrUnordered = Assembler::ConditionHS,
 137         DoubleLessThanOrUnordered = Assembler::ConditionLT,
 138         DoubleLessThanOrEqualOrUnordered = Assembler::ConditionLE,
 139     };
 140 
<a name="8" id="anc8"></a><span class="line-modified"> 141     static constexpr RegisterID stackPointerRegister = ARM64Registers::sp;</span>
<span class="line-modified"> 142     static constexpr RegisterID framePointerRegister = ARM64Registers::fp;</span>
<span class="line-modified"> 143     static constexpr RegisterID linkRegister = ARM64Registers::lr;</span>
 144 
 145     // FIXME: Get reasonable implementations for these
 146     static bool shouldBlindForSpecificArch(uint32_t value) { return value &gt;= 0x00ffffff; }
 147     static bool shouldBlindForSpecificArch(uint64_t value) { return value &gt;= 0x00ffffff; }
 148 
 149     // Integer operations:
 150 
 151     void add32(RegisterID a, RegisterID b, RegisterID dest)
 152     {
 153         ASSERT(a != ARM64Registers::sp &amp;&amp; b != ARM64Registers::sp);
 154         m_assembler.add&lt;32&gt;(dest, a, b);
 155     }
 156 
 157     void add32(RegisterID src, RegisterID dest)
 158     {
 159         m_assembler.add&lt;32&gt;(dest, dest, src);
 160     }
 161 
 162     void add32(TrustedImm32 imm, RegisterID dest)
 163     {
 164         add32(imm, dest, dest);
 165     }
 166 
 167     void add32(TrustedImm32 imm, RegisterID src, RegisterID dest)
 168     {
 169         if (isUInt12(imm.m_value))
 170             m_assembler.add&lt;32&gt;(dest, src, UInt12(imm.m_value));
 171         else if (isUInt12(-imm.m_value))
 172             m_assembler.sub&lt;32&gt;(dest, src, UInt12(-imm.m_value));
 173         else if (src != dest) {
 174             move(imm, dest);
 175             add32(src, dest);
 176         } else {
 177             move(imm, getCachedDataTempRegisterIDAndInvalidate());
 178             m_assembler.add&lt;32&gt;(dest, src, dataTempRegister);
 179         }
 180     }
 181 
 182     void add32(TrustedImm32 imm, Address address)
 183     {
 184         load32(address, getCachedDataTempRegisterIDAndInvalidate());
 185 
 186         if (isUInt12(imm.m_value))
 187             m_assembler.add&lt;32&gt;(dataTempRegister, dataTempRegister, UInt12(imm.m_value));
 188         else if (isUInt12(-imm.m_value))
 189             m_assembler.sub&lt;32&gt;(dataTempRegister, dataTempRegister, UInt12(-imm.m_value));
 190         else {
 191             move(imm, getCachedMemoryTempRegisterIDAndInvalidate());
 192             m_assembler.add&lt;32&gt;(dataTempRegister, dataTempRegister, memoryTempRegister);
 193         }
 194 
 195         store32(dataTempRegister, address);
 196     }
 197 
 198     void add32(TrustedImm32 imm, AbsoluteAddress address)
 199     {
 200         load32(address.m_ptr, getCachedDataTempRegisterIDAndInvalidate());
 201 
 202         if (isUInt12(imm.m_value)) {
 203             m_assembler.add&lt;32&gt;(dataTempRegister, dataTempRegister, UInt12(imm.m_value));
 204             store32(dataTempRegister, address.m_ptr);
 205             return;
 206         }
 207 
 208         if (isUInt12(-imm.m_value)) {
 209             m_assembler.sub&lt;32&gt;(dataTempRegister, dataTempRegister, UInt12(-imm.m_value));
 210             store32(dataTempRegister, address.m_ptr);
 211             return;
 212         }
 213 
 214         move(imm, getCachedMemoryTempRegisterIDAndInvalidate());
 215         m_assembler.add&lt;32&gt;(dataTempRegister, dataTempRegister, memoryTempRegister);
 216         store32(dataTempRegister, address.m_ptr);
 217     }
 218 
 219     void add32(Address src, RegisterID dest)
 220     {
 221         load32(src, getCachedDataTempRegisterIDAndInvalidate());
 222         add32(dataTempRegister, dest);
 223     }
 224 
 225     void add64(RegisterID a, RegisterID b, RegisterID dest)
 226     {
 227         ASSERT(a != ARM64Registers::sp || b != ARM64Registers::sp);
 228         if (b == ARM64Registers::sp)
 229             std::swap(a, b);
 230         m_assembler.add&lt;64&gt;(dest, a, b);
 231     }
 232 
 233     void add64(RegisterID src, RegisterID dest)
 234     {
 235         if (src == ARM64Registers::sp)
 236             m_assembler.add&lt;64&gt;(dest, src, dest);
 237         else
 238             m_assembler.add&lt;64&gt;(dest, dest, src);
 239     }
 240 
 241     void add64(TrustedImm32 imm, RegisterID dest)
 242     {
 243         if (isUInt12(imm.m_value)) {
 244             m_assembler.add&lt;64&gt;(dest, dest, UInt12(imm.m_value));
 245             return;
 246         }
 247         if (isUInt12(-imm.m_value)) {
 248             m_assembler.sub&lt;64&gt;(dest, dest, UInt12(-imm.m_value));
 249             return;
 250         }
 251 
 252         signExtend32ToPtr(imm, getCachedDataTempRegisterIDAndInvalidate());
 253         m_assembler.add&lt;64&gt;(dest, dest, dataTempRegister);
 254     }
 255 
 256     void add64(TrustedImm64 imm, RegisterID dest)
 257     {
 258         intptr_t immediate = imm.m_value;
 259 
 260         if (isUInt12(immediate)) {
 261             m_assembler.add&lt;64&gt;(dest, dest, UInt12(static_cast&lt;int32_t&gt;(immediate)));
 262             return;
 263         }
 264         if (isUInt12(-immediate)) {
 265             m_assembler.sub&lt;64&gt;(dest, dest, UInt12(static_cast&lt;int32_t&gt;(-immediate)));
 266             return;
 267         }
 268 
 269         move(imm, getCachedDataTempRegisterIDAndInvalidate());
 270         m_assembler.add&lt;64&gt;(dest, dest, dataTempRegister);
 271     }
 272 
 273     void add64(TrustedImm32 imm, RegisterID src, RegisterID dest)
 274     {
 275         if (isUInt12(imm.m_value)) {
 276             m_assembler.add&lt;64&gt;(dest, src, UInt12(imm.m_value));
 277             return;
 278         }
 279         if (isUInt12(-imm.m_value)) {
 280             m_assembler.sub&lt;64&gt;(dest, src, UInt12(-imm.m_value));
 281             return;
 282         }
 283 
 284         signExtend32ToPtr(imm, getCachedDataTempRegisterIDAndInvalidate());
 285         m_assembler.add&lt;64&gt;(dest, src, dataTempRegister);
 286     }
 287 
 288     void add64(TrustedImm32 imm, Address address)
 289     {
 290         load64(address, getCachedDataTempRegisterIDAndInvalidate());
 291 
 292         if (isUInt12(imm.m_value))
 293             m_assembler.add&lt;64&gt;(dataTempRegister, dataTempRegister, UInt12(imm.m_value));
 294         else if (isUInt12(-imm.m_value))
 295             m_assembler.sub&lt;64&gt;(dataTempRegister, dataTempRegister, UInt12(-imm.m_value));
 296         else {
 297             signExtend32ToPtr(imm, getCachedMemoryTempRegisterIDAndInvalidate());
 298             m_assembler.add&lt;64&gt;(dataTempRegister, dataTempRegister, memoryTempRegister);
 299         }
 300 
 301         store64(dataTempRegister, address);
 302     }
 303 
 304     void add64(TrustedImm32 imm, AbsoluteAddress address)
 305     {
 306         load64(address.m_ptr, getCachedDataTempRegisterIDAndInvalidate());
 307 
 308         if (isUInt12(imm.m_value)) {
 309             m_assembler.add&lt;64&gt;(dataTempRegister, dataTempRegister, UInt12(imm.m_value));
 310             store64(dataTempRegister, address.m_ptr);
 311             return;
 312         }
 313 
 314         if (isUInt12(-imm.m_value)) {
 315             m_assembler.sub&lt;64&gt;(dataTempRegister, dataTempRegister, UInt12(-imm.m_value));
 316             store64(dataTempRegister, address.m_ptr);
 317             return;
 318         }
 319 
 320         signExtend32ToPtr(imm, getCachedMemoryTempRegisterIDAndInvalidate());
 321         m_assembler.add&lt;64&gt;(dataTempRegister, dataTempRegister, memoryTempRegister);
 322         store64(dataTempRegister, address.m_ptr);
 323     }
 324 
 325     void addPtrNoFlags(TrustedImm32 imm, RegisterID srcDest)
 326     {
 327         add64(imm, srcDest);
 328     }
 329 
 330     void add64(Address src, RegisterID dest)
 331     {
 332         load64(src, getCachedDataTempRegisterIDAndInvalidate());
 333         m_assembler.add&lt;64&gt;(dest, dest, dataTempRegister);
 334     }
 335 
 336     void add64(AbsoluteAddress src, RegisterID dest)
 337     {
 338         load64(src.m_ptr, getCachedDataTempRegisterIDAndInvalidate());
 339         m_assembler.add&lt;64&gt;(dest, dest, dataTempRegister);
 340     }
 341 
 342     void and32(RegisterID src, RegisterID dest)
 343     {
 344         and32(dest, src, dest);
 345     }
 346 
 347     void and32(RegisterID op1, RegisterID op2, RegisterID dest)
 348     {
 349         m_assembler.and_&lt;32&gt;(dest, op1, op2);
 350     }
 351 
 352     void and32(TrustedImm32 imm, RegisterID dest)
 353     {
 354         and32(imm, dest, dest);
 355     }
 356 
 357     void and32(TrustedImm32 imm, RegisterID src, RegisterID dest)
 358     {
 359         LogicalImmediate logicalImm = LogicalImmediate::create32(imm.m_value);
 360 
 361         if (logicalImm.isValid()) {
 362             m_assembler.and_&lt;32&gt;(dest, src, logicalImm);
 363             return;
 364         }
 365 
 366         move(imm, getCachedDataTempRegisterIDAndInvalidate());
 367         m_assembler.and_&lt;32&gt;(dest, src, dataTempRegister);
 368     }
 369 
 370     void and32(Address src, RegisterID dest)
 371     {
 372         load32(src, getCachedDataTempRegisterIDAndInvalidate());
 373         and32(dataTempRegister, dest);
 374     }
 375 
 376     void and16(Address src, RegisterID dest)
 377     {
 378         load16(src, getCachedDataTempRegisterIDAndInvalidate());
 379         and32(dataTempRegister, dest);
 380     }
 381 
 382     void and64(RegisterID src1, RegisterID src2, RegisterID dest)
 383     {
 384         m_assembler.and_&lt;64&gt;(dest, src1, src2);
 385     }
 386 
 387     void and64(TrustedImm64 imm, RegisterID src, RegisterID dest)
 388     {
 389         LogicalImmediate logicalImm = LogicalImmediate::create64(imm.m_value);
 390 
 391         if (logicalImm.isValid()) {
 392             m_assembler.and_&lt;64&gt;(dest, src, logicalImm);
 393             return;
 394         }
 395 
 396         move(imm, getCachedDataTempRegisterIDAndInvalidate());
 397         m_assembler.and_&lt;64&gt;(dest, src, dataTempRegister);
 398     }
 399 
 400     void and64(RegisterID src, RegisterID dest)
 401     {
 402         m_assembler.and_&lt;64&gt;(dest, dest, src);
 403     }
 404 
 405     void and64(TrustedImm32 imm, RegisterID dest)
 406     {
 407         LogicalImmediate logicalImm = LogicalImmediate::create64(static_cast&lt;intptr_t&gt;(static_cast&lt;int64_t&gt;(imm.m_value)));
 408 
 409         if (logicalImm.isValid()) {
 410             m_assembler.and_&lt;64&gt;(dest, dest, logicalImm);
 411             return;
 412         }
 413 
 414         signExtend32ToPtr(imm, getCachedDataTempRegisterIDAndInvalidate());
 415         m_assembler.and_&lt;64&gt;(dest, dest, dataTempRegister);
 416     }
 417 
 418     void and64(TrustedImmPtr imm, RegisterID dest)
 419     {
 420         LogicalImmediate logicalImm = LogicalImmediate::create64(reinterpret_cast&lt;uint64_t&gt;(imm.m_value));
 421 
 422         if (logicalImm.isValid()) {
 423             m_assembler.and_&lt;64&gt;(dest, dest, logicalImm);
 424             return;
 425         }
 426 
 427         move(imm, getCachedDataTempRegisterIDAndInvalidate());
 428         m_assembler.and_&lt;64&gt;(dest, dest, dataTempRegister);
 429     }
 430 
 431     void countLeadingZeros32(RegisterID src, RegisterID dest)
 432     {
 433         m_assembler.clz&lt;32&gt;(dest, src);
 434     }
 435 
 436     void countLeadingZeros64(RegisterID src, RegisterID dest)
 437     {
 438         m_assembler.clz&lt;64&gt;(dest, src);
 439     }
 440 
 441     void countTrailingZeros32(RegisterID src, RegisterID dest)
 442     {
 443         // Arm does not have a count trailing zeros only a count leading zeros.
 444         m_assembler.rbit&lt;32&gt;(dest, src);
 445         m_assembler.clz&lt;32&gt;(dest, dest);
 446     }
 447 
 448     void countTrailingZeros64(RegisterID src, RegisterID dest)
 449     {
 450         // Arm does not have a count trailing zeros only a count leading zeros.
 451         m_assembler.rbit&lt;64&gt;(dest, src);
 452         m_assembler.clz&lt;64&gt;(dest, dest);
 453     }
 454 
 455     void byteSwap16(RegisterID dst)
 456     {
 457         m_assembler.rev16&lt;32&gt;(dst, dst);
 458         zeroExtend16To32(dst, dst);
 459     }
 460 
 461     void byteSwap32(RegisterID dst)
 462     {
 463         m_assembler.rev&lt;32&gt;(dst, dst);
 464     }
 465 
 466     void byteSwap64(RegisterID dst)
 467     {
 468         m_assembler.rev&lt;64&gt;(dst, dst);
 469     }
 470 
 471     // Only used for testing purposes.
 472     void illegalInstruction()
 473     {
 474         m_assembler.illegalInstruction();
 475     }
 476 
 477     void lshift32(RegisterID src, RegisterID shiftAmount, RegisterID dest)
 478     {
 479         m_assembler.lsl&lt;32&gt;(dest, src, shiftAmount);
 480     }
 481 
 482     void lshift32(RegisterID src, TrustedImm32 imm, RegisterID dest)
 483     {
 484         m_assembler.lsl&lt;32&gt;(dest, src, imm.m_value &amp; 0x1f);
 485     }
 486 
 487     void lshift32(RegisterID shiftAmount, RegisterID dest)
 488     {
 489         lshift32(dest, shiftAmount, dest);
 490     }
 491 
 492     void lshift32(TrustedImm32 imm, RegisterID dest)
 493     {
 494         lshift32(dest, imm, dest);
 495     }
 496 
 497     void lshift64(RegisterID src, RegisterID shiftAmount, RegisterID dest)
 498     {
 499         m_assembler.lsl&lt;64&gt;(dest, src, shiftAmount);
 500     }
 501 
 502     void lshift64(RegisterID src, TrustedImm32 imm, RegisterID dest)
 503     {
 504         m_assembler.lsl&lt;64&gt;(dest, src, imm.m_value &amp; 0x3f);
 505     }
 506 
 507     void lshift64(RegisterID shiftAmount, RegisterID dest)
 508     {
 509         lshift64(dest, shiftAmount, dest);
 510     }
 511 
 512     void lshift64(TrustedImm32 imm, RegisterID dest)
 513     {
 514         lshift64(dest, imm, dest);
 515     }
 516 
 517     void mul32(RegisterID left, RegisterID right, RegisterID dest)
 518     {
 519         m_assembler.mul&lt;32&gt;(dest, left, right);
 520     }
 521 
 522     void mul32(RegisterID src, RegisterID dest)
 523     {
 524         m_assembler.mul&lt;32&gt;(dest, dest, src);
 525     }
 526 
 527     void mul32(TrustedImm32 imm, RegisterID src, RegisterID dest)
 528     {
 529         move(imm, getCachedDataTempRegisterIDAndInvalidate());
 530         m_assembler.mul&lt;32&gt;(dest, src, dataTempRegister);
 531     }
 532 
 533     void mul64(RegisterID src, RegisterID dest)
 534     {
 535         m_assembler.mul&lt;64&gt;(dest, dest, src);
 536     }
 537 
 538     void mul64(RegisterID left, RegisterID right, RegisterID dest)
 539     {
 540         m_assembler.mul&lt;64&gt;(dest, left, right);
 541     }
 542 
 543     void multiplyAdd32(RegisterID mulLeft, RegisterID mulRight, RegisterID summand, RegisterID dest)
 544     {
 545         m_assembler.madd&lt;32&gt;(dest, mulLeft, mulRight, summand);
 546     }
 547 
 548     void multiplySub32(RegisterID mulLeft, RegisterID mulRight, RegisterID minuend, RegisterID dest)
 549     {
 550         m_assembler.msub&lt;32&gt;(dest, mulLeft, mulRight, minuend);
 551     }
 552 
 553     void multiplyNeg32(RegisterID mulLeft, RegisterID mulRight, RegisterID dest)
 554     {
 555         m_assembler.msub&lt;32&gt;(dest, mulLeft, mulRight, ARM64Registers::zr);
 556     }
 557 
 558     void multiplyAdd64(RegisterID mulLeft, RegisterID mulRight, RegisterID summand, RegisterID dest)
 559     {
 560         m_assembler.madd&lt;64&gt;(dest, mulLeft, mulRight, summand);
 561     }
 562 
 563     void multiplySub64(RegisterID mulLeft, RegisterID mulRight, RegisterID minuend, RegisterID dest)
 564     {
 565         m_assembler.msub&lt;64&gt;(dest, mulLeft, mulRight, minuend);
 566     }
 567 
 568     void multiplyNeg64(RegisterID mulLeft, RegisterID mulRight, RegisterID dest)
 569     {
 570         m_assembler.msub&lt;64&gt;(dest, mulLeft, mulRight, ARM64Registers::zr);
 571     }
 572 
 573     void multiplySignExtend32(RegisterID left, RegisterID right, RegisterID dest)
 574     {
 575         m_assembler.smull(dest, left, right);
 576     }
 577 
 578     void div32(RegisterID dividend, RegisterID divisor, RegisterID dest)
 579     {
 580         m_assembler.sdiv&lt;32&gt;(dest, dividend, divisor);
 581     }
 582 
 583     void div64(RegisterID dividend, RegisterID divisor, RegisterID dest)
 584     {
 585         m_assembler.sdiv&lt;64&gt;(dest, dividend, divisor);
 586     }
 587 
 588     void uDiv32(RegisterID dividend, RegisterID divisor, RegisterID dest)
 589     {
 590         m_assembler.udiv&lt;32&gt;(dest, dividend, divisor);
 591     }
 592 
 593     void uDiv64(RegisterID dividend, RegisterID divisor, RegisterID dest)
 594     {
 595         m_assembler.udiv&lt;64&gt;(dest, dividend, divisor);
 596     }
 597 
 598     void neg32(RegisterID dest)
 599     {
 600         m_assembler.neg&lt;32&gt;(dest, dest);
 601     }
 602 
 603     void neg32(RegisterID src, RegisterID dest)
 604     {
 605         m_assembler.neg&lt;32&gt;(dest, src);
 606     }
 607 
 608     void neg64(RegisterID dest)
 609     {
 610         m_assembler.neg&lt;64&gt;(dest, dest);
 611     }
 612 
 613     void neg64(RegisterID src, RegisterID dest)
 614     {
 615         m_assembler.neg&lt;64&gt;(dest, src);
 616     }
 617 
<a name="9" id="anc9"></a><span class="line-added"> 618     void or16(TrustedImm32 imm, AbsoluteAddress address)</span>
<span class="line-added"> 619     {</span>
<span class="line-added"> 620         LogicalImmediate logicalImm = LogicalImmediate::create32(imm.m_value);</span>
<span class="line-added"> 621         if (logicalImm.isValid()) {</span>
<span class="line-added"> 622             load16(address.m_ptr, getCachedDataTempRegisterIDAndInvalidate());</span>
<span class="line-added"> 623             m_assembler.orr&lt;32&gt;(dataTempRegister, dataTempRegister, logicalImm);</span>
<span class="line-added"> 624             store16(dataTempRegister, address.m_ptr);</span>
<span class="line-added"> 625         } else {</span>
<span class="line-added"> 626             load16(address.m_ptr, getCachedMemoryTempRegisterIDAndInvalidate());</span>
<span class="line-added"> 627             or32(imm, memoryTempRegister, getCachedDataTempRegisterIDAndInvalidate());</span>
<span class="line-added"> 628             store16(dataTempRegister, address.m_ptr);</span>
<span class="line-added"> 629         }</span>
<span class="line-added"> 630     }</span>
<span class="line-added"> 631 </span>
 632     void or32(RegisterID src, RegisterID dest)
 633     {
 634         or32(dest, src, dest);
 635     }
 636 
 637     void or32(RegisterID op1, RegisterID op2, RegisterID dest)
 638     {
 639         m_assembler.orr&lt;32&gt;(dest, op1, op2);
 640     }
 641 
 642     void or32(TrustedImm32 imm, RegisterID dest)
 643     {
 644         or32(imm, dest, dest);
 645     }
 646 
 647     void or32(TrustedImm32 imm, RegisterID src, RegisterID dest)
 648     {
 649         LogicalImmediate logicalImm = LogicalImmediate::create32(imm.m_value);
 650 
 651         if (logicalImm.isValid()) {
 652             m_assembler.orr&lt;32&gt;(dest, src, logicalImm);
 653             return;
 654         }
 655 
 656         ASSERT(src != dataTempRegister);
 657         move(imm, getCachedDataTempRegisterIDAndInvalidate());
 658         m_assembler.orr&lt;32&gt;(dest, src, dataTempRegister);
 659     }
 660 
 661     void or32(RegisterID src, AbsoluteAddress address)
 662     {
 663         load32(address.m_ptr, getCachedDataTempRegisterIDAndInvalidate());
 664         m_assembler.orr&lt;32&gt;(dataTempRegister, dataTempRegister, src);
 665         store32(dataTempRegister, address.m_ptr);
 666     }
 667 
 668     void or32(TrustedImm32 imm, AbsoluteAddress address)
 669     {
 670         LogicalImmediate logicalImm = LogicalImmediate::create32(imm.m_value);
 671         if (logicalImm.isValid()) {
 672             load32(address.m_ptr, getCachedDataTempRegisterIDAndInvalidate());
 673             m_assembler.orr&lt;32&gt;(dataTempRegister, dataTempRegister, logicalImm);
 674             store32(dataTempRegister, address.m_ptr);
 675         } else {
 676             load32(address.m_ptr, getCachedMemoryTempRegisterIDAndInvalidate());
 677             or32(imm, memoryTempRegister, getCachedDataTempRegisterIDAndInvalidate());
 678             store32(dataTempRegister, address.m_ptr);
 679         }
 680     }
 681 
 682     void or32(TrustedImm32 imm, Address address)
 683     {
 684         load32(address, getCachedDataTempRegisterIDAndInvalidate());
 685         or32(imm, dataTempRegister, dataTempRegister);
 686         store32(dataTempRegister, address);
 687     }
 688 
 689     void or64(RegisterID src, RegisterID dest)
 690     {
 691         or64(dest, src, dest);
 692     }
 693 
 694     void or64(RegisterID op1, RegisterID op2, RegisterID dest)
 695     {
 696         m_assembler.orr&lt;64&gt;(dest, op1, op2);
 697     }
 698 
 699     void or64(TrustedImm32 imm, RegisterID dest)
 700     {
 701         or64(imm, dest, dest);
 702     }
 703 
 704     void or64(TrustedImm32 imm, RegisterID src, RegisterID dest)
 705     {
 706         LogicalImmediate logicalImm = LogicalImmediate::create64(static_cast&lt;intptr_t&gt;(static_cast&lt;int64_t&gt;(imm.m_value)));
 707 
 708         if (logicalImm.isValid()) {
 709             m_assembler.orr&lt;64&gt;(dest, src, logicalImm);
 710             return;
 711         }
 712 
 713         signExtend32ToPtr(imm, getCachedDataTempRegisterIDAndInvalidate());
 714         m_assembler.orr&lt;64&gt;(dest, src, dataTempRegister);
 715     }
 716 
 717     void or64(TrustedImm64 imm, RegisterID src, RegisterID dest)
 718     {
 719         LogicalImmediate logicalImm = LogicalImmediate::create64(imm.m_value);
 720 
 721         if (logicalImm.isValid()) {
 722             m_assembler.orr&lt;64&gt;(dest, src, logicalImm);
 723             return;
 724         }
 725 
 726         move(imm, getCachedDataTempRegisterIDAndInvalidate());
 727         m_assembler.orr&lt;64&gt;(dest, src, dataTempRegister);
 728     }
 729 
 730     void or64(TrustedImm64 imm, RegisterID dest)
 731     {
 732         LogicalImmediate logicalImm = LogicalImmediate::create64(static_cast&lt;intptr_t&gt;(static_cast&lt;int64_t&gt;(imm.m_value)));
 733 
 734         if (logicalImm.isValid()) {
 735             m_assembler.orr&lt;64&gt;(dest, dest, logicalImm);
 736             return;
 737         }
 738 
 739         move(imm, getCachedDataTempRegisterIDAndInvalidate());
 740         m_assembler.orr&lt;64&gt;(dest, dest, dataTempRegister);
 741     }
 742 
 743     void rotateRight32(RegisterID src, TrustedImm32 imm, RegisterID dest)
 744     {
 745         m_assembler.ror&lt;32&gt;(dest, src, imm.m_value &amp; 31);
 746     }
 747 
 748     void rotateRight32(TrustedImm32 imm, RegisterID srcDst)
 749     {
 750         rotateRight32(srcDst, imm, srcDst);
 751     }
 752 
 753     void rotateRight32(RegisterID src, RegisterID shiftAmmount, RegisterID dest)
 754     {
 755         m_assembler.ror&lt;32&gt;(dest, src, shiftAmmount);
 756     }
 757 
 758     void rotateRight64(RegisterID src, TrustedImm32 imm, RegisterID dest)
 759     {
 760         m_assembler.ror&lt;64&gt;(dest, src, imm.m_value &amp; 63);
 761     }
 762 
 763     void rotateRight64(TrustedImm32 imm, RegisterID srcDst)
 764     {
 765         rotateRight64(srcDst, imm, srcDst);
 766     }
 767 
 768     void rotateRight64(RegisterID src, RegisterID shiftAmmount, RegisterID dest)
 769     {
 770         m_assembler.ror&lt;64&gt;(dest, src, shiftAmmount);
 771     }
 772 
 773     void rshift32(RegisterID src, RegisterID shiftAmount, RegisterID dest)
 774     {
 775         m_assembler.asr&lt;32&gt;(dest, src, shiftAmount);
 776     }
 777 
 778     void rshift32(RegisterID src, TrustedImm32 imm, RegisterID dest)
 779     {
 780         m_assembler.asr&lt;32&gt;(dest, src, imm.m_value &amp; 0x1f);
 781     }
 782 
 783     void rshift32(RegisterID shiftAmount, RegisterID dest)
 784     {
 785         rshift32(dest, shiftAmount, dest);
 786     }
 787 
 788     void rshift32(TrustedImm32 imm, RegisterID dest)
 789     {
 790         rshift32(dest, imm, dest);
 791     }
 792 
 793     void rshift64(RegisterID src, RegisterID shiftAmount, RegisterID dest)
 794     {
 795         m_assembler.asr&lt;64&gt;(dest, src, shiftAmount);
 796     }
 797 
 798     void rshift64(RegisterID src, TrustedImm32 imm, RegisterID dest)
 799     {
 800         m_assembler.asr&lt;64&gt;(dest, src, imm.m_value &amp; 0x3f);
 801     }
 802 
 803     void rshift64(RegisterID shiftAmount, RegisterID dest)
 804     {
 805         rshift64(dest, shiftAmount, dest);
 806     }
 807 
 808     void rshift64(TrustedImm32 imm, RegisterID dest)
 809     {
 810         rshift64(dest, imm, dest);
 811     }
 812 
 813     void sub32(RegisterID src, RegisterID dest)
 814     {
 815         m_assembler.sub&lt;32&gt;(dest, dest, src);
 816     }
 817 
 818     void sub32(RegisterID left, RegisterID right, RegisterID dest)
 819     {
 820         m_assembler.sub&lt;32&gt;(dest, left, right);
 821     }
 822 
 823     void sub32(TrustedImm32 imm, RegisterID dest)
 824     {
 825         if (isUInt12(imm.m_value)) {
 826             m_assembler.sub&lt;32&gt;(dest, dest, UInt12(imm.m_value));
 827             return;
 828         }
 829         if (isUInt12(-imm.m_value)) {
 830             m_assembler.add&lt;32&gt;(dest, dest, UInt12(-imm.m_value));
 831             return;
 832         }
 833 
 834         move(imm, getCachedDataTempRegisterIDAndInvalidate());
 835         m_assembler.sub&lt;32&gt;(dest, dest, dataTempRegister);
 836     }
 837 
 838     void sub32(TrustedImm32 imm, Address address)
 839     {
 840         load32(address, getCachedDataTempRegisterIDAndInvalidate());
 841 
 842         if (isUInt12(imm.m_value))
 843             m_assembler.sub&lt;32&gt;(dataTempRegister, dataTempRegister, UInt12(imm.m_value));
 844         else if (isUInt12(-imm.m_value))
 845             m_assembler.add&lt;32&gt;(dataTempRegister, dataTempRegister, UInt12(-imm.m_value));
 846         else {
 847             move(imm, getCachedMemoryTempRegisterIDAndInvalidate());
 848             m_assembler.sub&lt;32&gt;(dataTempRegister, dataTempRegister, memoryTempRegister);
 849         }
 850 
 851         store32(dataTempRegister, address);
 852     }
 853 
 854     void sub32(TrustedImm32 imm, AbsoluteAddress address)
 855     {
 856         load32(address.m_ptr, getCachedDataTempRegisterIDAndInvalidate());
 857 
 858         if (isUInt12(imm.m_value)) {
 859             m_assembler.sub&lt;32&gt;(dataTempRegister, dataTempRegister, UInt12(imm.m_value));
 860             store32(dataTempRegister, address.m_ptr);
 861             return;
 862         }
 863 
 864         if (isUInt12(-imm.m_value)) {
 865             m_assembler.add&lt;32&gt;(dataTempRegister, dataTempRegister, UInt12(-imm.m_value));
 866             store32(dataTempRegister, address.m_ptr);
 867             return;
 868         }
 869 
 870         move(imm, getCachedMemoryTempRegisterIDAndInvalidate());
 871         m_assembler.sub&lt;32&gt;(dataTempRegister, dataTempRegister, memoryTempRegister);
 872         store32(dataTempRegister, address.m_ptr);
 873     }
 874 
 875     void sub32(Address src, RegisterID dest)
 876     {
 877         load32(src, getCachedDataTempRegisterIDAndInvalidate());
 878         sub32(dataTempRegister, dest);
 879     }
 880 
 881     void sub64(RegisterID src, RegisterID dest)
 882     {
 883         m_assembler.sub&lt;64&gt;(dest, dest, src);
 884     }
 885 
 886     void sub64(RegisterID a, RegisterID b, RegisterID dest)
 887     {
 888         m_assembler.sub&lt;64&gt;(dest, a, b);
 889     }
 890 
 891     void sub64(TrustedImm32 imm, RegisterID dest)
 892     {
 893         if (isUInt12(imm.m_value)) {
 894             m_assembler.sub&lt;64&gt;(dest, dest, UInt12(imm.m_value));
 895             return;
 896         }
 897         if (isUInt12(-imm.m_value)) {
 898             m_assembler.add&lt;64&gt;(dest, dest, UInt12(-imm.m_value));
 899             return;
 900         }
 901 
 902         signExtend32ToPtr(imm, getCachedDataTempRegisterIDAndInvalidate());
 903         m_assembler.sub&lt;64&gt;(dest, dest, dataTempRegister);
 904     }
 905 
 906     void sub64(TrustedImm64 imm, RegisterID dest)
 907     {
 908         intptr_t immediate = imm.m_value;
 909 
 910         if (isUInt12(immediate)) {
 911             m_assembler.sub&lt;64&gt;(dest, dest, UInt12(static_cast&lt;int32_t&gt;(immediate)));
 912             return;
 913         }
 914         if (isUInt12(-immediate)) {
 915             m_assembler.add&lt;64&gt;(dest, dest, UInt12(static_cast&lt;int32_t&gt;(-immediate)));
 916             return;
 917         }
 918 
 919         move(imm, getCachedDataTempRegisterIDAndInvalidate());
 920         m_assembler.sub&lt;64&gt;(dest, dest, dataTempRegister);
 921     }
 922 
 923     void urshift32(RegisterID src, RegisterID shiftAmount, RegisterID dest)
 924     {
 925         m_assembler.lsr&lt;32&gt;(dest, src, shiftAmount);
 926     }
 927 
 928     void urshift32(RegisterID src, TrustedImm32 imm, RegisterID dest)
 929     {
 930         m_assembler.lsr&lt;32&gt;(dest, src, imm.m_value &amp; 0x1f);
 931     }
 932 
 933     void urshift32(RegisterID shiftAmount, RegisterID dest)
 934     {
 935         urshift32(dest, shiftAmount, dest);
 936     }
 937 
 938     void urshift32(TrustedImm32 imm, RegisterID dest)
 939     {
 940         urshift32(dest, imm, dest);
 941     }
 942 
 943     void urshift64(RegisterID src, RegisterID shiftAmount, RegisterID dest)
 944     {
 945         m_assembler.lsr&lt;64&gt;(dest, src, shiftAmount);
 946     }
 947 
 948     void urshift64(RegisterID src, TrustedImm32 imm, RegisterID dest)
 949     {
 950         m_assembler.lsr&lt;64&gt;(dest, src, imm.m_value &amp; 0x3f);
 951     }
 952 
 953     void urshift64(RegisterID shiftAmount, RegisterID dest)
 954     {
 955         urshift64(dest, shiftAmount, dest);
 956     }
 957 
 958     void urshift64(TrustedImm32 imm, RegisterID dest)
 959     {
 960         urshift64(dest, imm, dest);
 961     }
 962 
 963     void xor32(RegisterID src, RegisterID dest)
 964     {
 965         xor32(dest, src, dest);
 966     }
 967 
 968     void xor32(Address src, RegisterID dest)
 969     {
 970         load32(src, getCachedDataTempRegisterIDAndInvalidate());
 971         xor32(dataTempRegister, dest);
 972     }
 973 
 974     void xor32(RegisterID op1, RegisterID op2, RegisterID dest)
 975     {
 976         m_assembler.eor&lt;32&gt;(dest, op1, op2);
 977     }
 978 
 979     void xor32(TrustedImm32 imm, RegisterID dest)
 980     {
 981         xor32(imm, dest, dest);
 982     }
 983 
 984     void xor32(TrustedImm32 imm, RegisterID src, RegisterID dest)
 985     {
 986         if (imm.m_value == -1)
 987             m_assembler.mvn&lt;32&gt;(dest, src);
 988         else {
 989             LogicalImmediate logicalImm = LogicalImmediate::create32(imm.m_value);
 990 
 991             if (logicalImm.isValid()) {
 992                 m_assembler.eor&lt;32&gt;(dest, src, logicalImm);
 993                 return;
 994             }
 995 
 996             move(imm, getCachedDataTempRegisterIDAndInvalidate());
 997             m_assembler.eor&lt;32&gt;(dest, src, dataTempRegister);
 998         }
 999     }
1000 
1001     void xor64(RegisterID src, Address address)
1002     {
1003         load64(address, getCachedDataTempRegisterIDAndInvalidate());
1004         m_assembler.eor&lt;64&gt;(dataTempRegister, dataTempRegister, src);
1005         store64(dataTempRegister, address);
1006     }
1007 
1008     void xor64(RegisterID src, RegisterID dest)
1009     {
1010         xor64(dest, src, dest);
1011     }
1012 
1013     void xor64(RegisterID op1, RegisterID op2, RegisterID dest)
1014     {
1015         m_assembler.eor&lt;64&gt;(dest, op1, op2);
1016     }
1017 
1018     void xor64(TrustedImm32 imm, RegisterID dest)
1019     {
1020         xor64(imm, dest, dest);
1021     }
1022 
1023     void xor64(TrustedImm64 imm, RegisterID src, RegisterID dest)
1024     {
1025         if (imm.m_value == -1)
1026             m_assembler.mvn&lt;64&gt;(dest, src);
1027         else {
1028             LogicalImmediate logicalImm = LogicalImmediate::create64(imm.m_value);
1029 
1030             if (logicalImm.isValid()) {
1031                 m_assembler.eor&lt;64&gt;(dest, src, logicalImm);
1032                 return;
1033             }
1034 
1035             move(imm, getCachedDataTempRegisterIDAndInvalidate());
1036             m_assembler.eor&lt;64&gt;(dest, src, dataTempRegister);
1037         }
1038     }
1039 
1040     void xor64(TrustedImm64 imm, RegisterID srcDest)
1041     {
1042         xor64(imm, srcDest, srcDest);
1043     }
1044 
1045     void xor64(TrustedImm32 imm, RegisterID src, RegisterID dest)
1046     {
1047         if (imm.m_value == -1)
1048             m_assembler.mvn&lt;64&gt;(dest, src);
1049         else {
1050             LogicalImmediate logicalImm = LogicalImmediate::create64(static_cast&lt;intptr_t&gt;(static_cast&lt;int64_t&gt;(imm.m_value)));
1051 
1052             if (logicalImm.isValid()) {
1053                 m_assembler.eor&lt;64&gt;(dest, src, logicalImm);
1054                 return;
1055             }
1056 
1057             signExtend32ToPtr(imm, getCachedDataTempRegisterIDAndInvalidate());
1058             m_assembler.eor&lt;64&gt;(dest, src, dataTempRegister);
1059         }
1060     }
1061 
1062     void xor64(Address src, RegisterID dest)
1063     {
1064         load64(src, getCachedDataTempRegisterIDAndInvalidate());
1065         xor64(dataTempRegister, dest);
1066     }
1067 
1068     void not32(RegisterID srcDest)
1069     {
1070         m_assembler.mvn&lt;32&gt;(srcDest, srcDest);
1071     }
1072 
1073     void not32(RegisterID src, RegisterID dest)
1074     {
1075         m_assembler.mvn&lt;32&gt;(dest, src);
1076     }
1077 
1078     void not64(RegisterID src, RegisterID dest)
1079     {
1080         m_assembler.mvn&lt;64&gt;(dest, src);
1081     }
1082 
1083     void not64(RegisterID srcDst)
1084     {
1085         m_assembler.mvn&lt;64&gt;(srcDst, srcDst);
1086     }
1087 
1088     // Memory access operations:
1089 
1090     void load64(ImplicitAddress address, RegisterID dest)
1091     {
1092         if (tryLoadWithOffset&lt;64&gt;(dest, address.base, address.offset))
1093             return;
1094 
1095         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1096         m_assembler.ldr&lt;64&gt;(dest, address.base, memoryTempRegister);
1097     }
1098 
1099     void load64(BaseIndex address, RegisterID dest)
1100     {
1101         if (!address.offset &amp;&amp; (!address.scale || address.scale == 3)) {
1102             m_assembler.ldr&lt;64&gt;(dest, address.base, address.index, Assembler::UXTX, address.scale);
1103             return;
1104         }
1105 
1106         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1107         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1108         m_assembler.ldr&lt;64&gt;(dest, address.base, memoryTempRegister);
1109     }
1110 
1111     void load64(const void* address, RegisterID dest)
1112     {
1113         load&lt;64&gt;(address, dest);
1114     }
1115 
1116     void load64(RegisterID src, PostIndex simm, RegisterID dest)
1117     {
1118         m_assembler.ldr&lt;64&gt;(dest, src, simm);
1119     }
1120 
1121     DataLabel32 load64WithAddressOffsetPatch(Address address, RegisterID dest)
1122     {
1123         DataLabel32 label(this);
1124         signExtend32ToPtrWithFixedWidth(address.offset, getCachedMemoryTempRegisterIDAndInvalidate());
1125         m_assembler.ldr&lt;64&gt;(dest, address.base, memoryTempRegister, Assembler::SXTW, 0);
1126         return label;
1127     }
1128 
1129     DataLabelCompact load64WithCompactAddressOffsetPatch(Address address, RegisterID dest)
1130     {
1131         ASSERT(isCompactPtrAlignedAddressOffset(address.offset));
1132         DataLabelCompact label(this);
1133         m_assembler.ldr&lt;64&gt;(dest, address.base, address.offset);
1134         return label;
1135     }
1136 
1137     void loadPair64(RegisterID src, RegisterID dest1, RegisterID dest2)
1138     {
1139         loadPair64(src, TrustedImm32(0), dest1, dest2);
1140     }
1141 
1142     void loadPair64(RegisterID src, TrustedImm32 offset, RegisterID dest1, RegisterID dest2)
1143     {
1144         m_assembler.ldp&lt;64&gt;(dest1, dest2, src, offset.m_value);
1145     }
1146 
1147     void loadPair64WithNonTemporalAccess(RegisterID src, RegisterID dest1, RegisterID dest2)
1148     {
1149         loadPair64WithNonTemporalAccess(src, TrustedImm32(0), dest1, dest2);
1150     }
1151 
1152     void loadPair64WithNonTemporalAccess(RegisterID src, TrustedImm32 offset, RegisterID dest1, RegisterID dest2)
1153     {
1154         m_assembler.ldnp&lt;64&gt;(dest1, dest2, src, offset.m_value);
1155     }
1156 
1157     void abortWithReason(AbortReason reason)
1158     {
1159         // It is safe to use dataTempRegister directly since this is a crashing JIT Assert.
1160         move(TrustedImm32(reason), dataTempRegister);
1161         breakpoint();
1162     }
1163 
1164     void abortWithReason(AbortReason reason, intptr_t misc)
1165     {
1166         // It is safe to use memoryTempRegister directly since this is a crashing JIT Assert.
1167         move(TrustedImm64(misc), memoryTempRegister);
1168         abortWithReason(reason);
1169     }
1170 
1171     ConvertibleLoadLabel convertibleLoadPtr(Address address, RegisterID dest)
1172     {
1173         ConvertibleLoadLabel result(this);
1174         ASSERT(!(address.offset &amp; ~0xff8));
1175         m_assembler.ldr&lt;64&gt;(dest, address.base, address.offset);
1176         return result;
1177     }
1178 
1179     void load32(ImplicitAddress address, RegisterID dest)
1180     {
1181         if (tryLoadWithOffset&lt;32&gt;(dest, address.base, address.offset))
1182             return;
1183 
1184         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1185         m_assembler.ldr&lt;32&gt;(dest, address.base, memoryTempRegister);
1186     }
1187 
1188     void load32(BaseIndex address, RegisterID dest)
1189     {
1190         if (!address.offset &amp;&amp; (!address.scale || address.scale == 2)) {
1191             m_assembler.ldr&lt;32&gt;(dest, address.base, address.index, Assembler::UXTX, address.scale);
1192             return;
1193         }
1194 
1195         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1196         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1197         m_assembler.ldr&lt;32&gt;(dest, address.base, memoryTempRegister);
1198     }
1199 
1200     void load32(const void* address, RegisterID dest)
1201     {
1202         load&lt;32&gt;(address, dest);
1203     }
1204 
1205     DataLabel32 load32WithAddressOffsetPatch(Address address, RegisterID dest)
1206     {
1207         DataLabel32 label(this);
1208         signExtend32ToPtrWithFixedWidth(address.offset, getCachedMemoryTempRegisterIDAndInvalidate());
1209         m_assembler.ldr&lt;32&gt;(dest, address.base, memoryTempRegister, Assembler::SXTW, 0);
1210         return label;
1211     }
1212 
1213     DataLabelCompact load32WithCompactAddressOffsetPatch(Address address, RegisterID dest)
1214     {
1215         ASSERT(isCompactPtrAlignedAddressOffset(address.offset));
1216         DataLabelCompact label(this);
1217         m_assembler.ldr&lt;32&gt;(dest, address.base, address.offset);
1218         return label;
1219     }
1220 
1221     void load32WithUnalignedHalfWords(BaseIndex address, RegisterID dest)
1222     {
1223         load32(address, dest);
1224     }
1225 
1226     void load16(ImplicitAddress address, RegisterID dest)
1227     {
1228         if (tryLoadWithOffset&lt;16&gt;(dest, address.base, address.offset))
1229             return;
1230 
1231         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1232         m_assembler.ldrh(dest, address.base, memoryTempRegister);
1233     }
1234 
1235     void load16(BaseIndex address, RegisterID dest)
1236     {
1237         if (!address.offset &amp;&amp; (!address.scale || address.scale == 1)) {
1238             m_assembler.ldrh(dest, address.base, address.index, Assembler::UXTX, address.scale);
1239             return;
1240         }
1241 
1242         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1243         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1244         m_assembler.ldrh(dest, address.base, memoryTempRegister);
1245     }
1246 
1247     void load16(ExtendedAddress address, RegisterID dest)
1248     {
1249         moveToCachedReg(TrustedImmPtr(reinterpret_cast&lt;void*&gt;(address.offset)), cachedMemoryTempRegister());
1250         m_assembler.ldrh(dest, memoryTempRegister, address.base, Assembler::UXTX, 1);
1251         if (dest == memoryTempRegister)
1252             cachedMemoryTempRegister().invalidate();
1253     }
1254 
<a name="10" id="anc10"></a><span class="line-added">1255     void load16(const void* address, RegisterID dest)</span>
<span class="line-added">1256     {</span>
<span class="line-added">1257         load&lt;16&gt;(address, dest);</span>
<span class="line-added">1258     }</span>
<span class="line-added">1259 </span>
1260     void load16Unaligned(ImplicitAddress address, RegisterID dest)
1261     {
1262         load16(address, dest);
1263     }
1264 
1265     void load16Unaligned(BaseIndex address, RegisterID dest)
1266     {
1267         load16(address, dest);
1268     }
1269 
1270     void load16SignedExtendTo32(ImplicitAddress address, RegisterID dest)
1271     {
1272         if (tryLoadSignedWithOffset&lt;16&gt;(dest, address.base, address.offset))
1273             return;
1274 
1275         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1276         m_assembler.ldrsh&lt;32&gt;(dest, address.base, memoryTempRegister);
1277     }
1278 
1279     void load16SignedExtendTo32(BaseIndex address, RegisterID dest)
1280     {
1281         if (!address.offset &amp;&amp; (!address.scale || address.scale == 1)) {
1282             m_assembler.ldrsh&lt;32&gt;(dest, address.base, address.index, Assembler::UXTX, address.scale);
1283             return;
1284         }
1285 
1286         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1287         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1288         m_assembler.ldrsh&lt;32&gt;(dest, address.base, memoryTempRegister);
1289     }
1290 
1291     void zeroExtend16To32(RegisterID src, RegisterID dest)
1292     {
1293         m_assembler.uxth&lt;32&gt;(dest, src);
1294     }
1295 
1296     void signExtend16To32(RegisterID src, RegisterID dest)
1297     {
1298         m_assembler.sxth&lt;32&gt;(dest, src);
1299     }
1300 
1301     void load8(ImplicitAddress address, RegisterID dest)
1302     {
1303         if (tryLoadWithOffset&lt;8&gt;(dest, address.base, address.offset))
1304             return;
1305 
1306         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1307         m_assembler.ldrb(dest, address.base, memoryTempRegister);
1308     }
1309 
1310     void load8(BaseIndex address, RegisterID dest)
1311     {
1312         if (!address.offset &amp;&amp; !address.scale) {
1313             m_assembler.ldrb(dest, address.base, address.index, Assembler::UXTX, address.scale);
1314             return;
1315         }
1316 
1317         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1318         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1319         m_assembler.ldrb(dest, address.base, memoryTempRegister);
1320     }
1321 
1322     void load8(const void* address, RegisterID dest)
1323     {
1324         moveToCachedReg(TrustedImmPtr(address), cachedMemoryTempRegister());
1325         m_assembler.ldrb(dest, memoryTempRegister, ARM64Registers::zr);
1326         if (dest == memoryTempRegister)
1327             cachedMemoryTempRegister().invalidate();
1328     }
1329 
1330     void load8(RegisterID src, PostIndex simm, RegisterID dest)
1331     {
1332         m_assembler.ldrb(dest, src, simm);
1333     }
1334 
1335     void load8SignedExtendTo32(ImplicitAddress address, RegisterID dest)
1336     {
1337         if (tryLoadSignedWithOffset&lt;8&gt;(dest, address.base, address.offset))
1338             return;
1339 
1340         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1341         m_assembler.ldrsb&lt;32&gt;(dest, address.base, memoryTempRegister);
1342     }
1343 
1344     void load8SignedExtendTo32(BaseIndex address, RegisterID dest)
1345     {
1346         if (!address.offset &amp;&amp; !address.scale) {
1347             m_assembler.ldrsb&lt;32&gt;(dest, address.base, address.index, Assembler::UXTX, address.scale);
1348             return;
1349         }
1350 
1351         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1352         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1353         m_assembler.ldrsb&lt;32&gt;(dest, address.base, memoryTempRegister);
1354     }
1355 
1356     void load8SignedExtendTo32(const void* address, RegisterID dest)
1357     {
1358         moveToCachedReg(TrustedImmPtr(address), cachedMemoryTempRegister());
1359         m_assembler.ldrsb&lt;32&gt;(dest, memoryTempRegister, ARM64Registers::zr);
1360         if (dest == memoryTempRegister)
1361             cachedMemoryTempRegister().invalidate();
1362     }
1363 
1364     void zeroExtend8To32(RegisterID src, RegisterID dest)
1365     {
1366         m_assembler.uxtb&lt;32&gt;(dest, src);
1367     }
1368 
1369     void signExtend8To32(RegisterID src, RegisterID dest)
1370     {
1371         m_assembler.sxtb&lt;32&gt;(dest, src);
1372     }
1373 
1374     void store64(RegisterID src, ImplicitAddress address)
1375     {
1376         if (tryStoreWithOffset&lt;64&gt;(src, address.base, address.offset))
1377             return;
1378 
1379         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1380         m_assembler.str&lt;64&gt;(src, address.base, memoryTempRegister);
1381     }
1382 
1383     void store64(RegisterID src, BaseIndex address)
1384     {
1385         if (!address.offset &amp;&amp; (!address.scale || address.scale == 3)) {
1386             m_assembler.str&lt;64&gt;(src, address.base, address.index, Assembler::UXTX, address.scale);
1387             return;
1388         }
1389 
1390         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1391         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1392         m_assembler.str&lt;64&gt;(src, address.base, memoryTempRegister);
1393     }
1394 
1395     void store64(RegisterID src, const void* address)
1396     {
1397         store&lt;64&gt;(src, address);
1398     }
1399 
1400     void store64(TrustedImm32 imm, ImplicitAddress address)
1401     {
1402         store64(TrustedImm64(imm.m_value), address);
1403     }
1404 
1405     void store64(TrustedImm64 imm, ImplicitAddress address)
1406     {
1407         if (!imm.m_value) {
1408             store64(ARM64Registers::zr, address);
1409             return;
1410         }
1411 
1412         moveToCachedReg(imm, dataMemoryTempRegister());
1413         store64(dataTempRegister, address);
1414     }
1415 
1416     void store64(TrustedImm64 imm, BaseIndex address)
1417     {
1418         if (!imm.m_value) {
1419             store64(ARM64Registers::zr, address);
1420             return;
1421         }
1422 
1423         moveToCachedReg(imm, dataMemoryTempRegister());
1424         store64(dataTempRegister, address);
1425     }
1426 
1427     void store64(RegisterID src, RegisterID dest, PostIndex simm)
1428     {
1429         m_assembler.str&lt;64&gt;(src, dest, simm);
1430     }
1431 
1432     void storeZero64(ImplicitAddress address)
1433     {
1434         store64(ARM64Registers::zr, address);
1435     }
1436 
1437     void storeZero64(BaseIndex address)
1438     {
1439         store64(ARM64Registers::zr, address);
1440     }
1441 
1442     DataLabel32 store64WithAddressOffsetPatch(RegisterID src, Address address)
1443     {
1444         DataLabel32 label(this);
1445         signExtend32ToPtrWithFixedWidth(address.offset, getCachedMemoryTempRegisterIDAndInvalidate());
1446         m_assembler.str&lt;64&gt;(src, address.base, memoryTempRegister, Assembler::SXTW, 0);
1447         return label;
1448     }
1449 
1450     void storePair64(RegisterID src1, RegisterID src2, RegisterID dest)
1451     {
1452         storePair64(src1, src2, dest, TrustedImm32(0));
1453     }
1454 
1455     void storePair64(RegisterID src1, RegisterID src2, RegisterID dest, TrustedImm32 offset)
1456     {
1457         m_assembler.stp&lt;64&gt;(src1, src2, dest, offset.m_value);
1458     }
1459 
1460     void storePair64WithNonTemporalAccess(RegisterID src1, RegisterID src2, RegisterID dest)
1461     {
1462         storePair64WithNonTemporalAccess(src1, src2, dest, TrustedImm32(0));
1463     }
1464 
1465     void storePair64WithNonTemporalAccess(RegisterID src1, RegisterID src2, RegisterID dest, TrustedImm32 offset)
1466     {
1467         m_assembler.stnp&lt;64&gt;(src1, src2, dest, offset.m_value);
1468     }
1469 
1470     void store32(RegisterID src, ImplicitAddress address)
1471     {
1472         if (tryStoreWithOffset&lt;32&gt;(src, address.base, address.offset))
1473             return;
1474 
1475         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1476         m_assembler.str&lt;32&gt;(src, address.base, memoryTempRegister);
1477     }
1478 
1479     void store32(RegisterID src, BaseIndex address)
1480     {
1481         if (!address.offset &amp;&amp; (!address.scale || address.scale == 2)) {
1482             m_assembler.str&lt;32&gt;(src, address.base, address.index, Assembler::UXTX, address.scale);
1483             return;
1484         }
1485 
1486         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1487         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1488         m_assembler.str&lt;32&gt;(src, address.base, memoryTempRegister);
1489     }
1490 
1491     void store32(RegisterID src, const void* address)
1492     {
1493         store&lt;32&gt;(src, address);
1494     }
1495 
1496     void store32(TrustedImm32 imm, ImplicitAddress address)
1497     {
1498         if (!imm.m_value) {
1499             store32(ARM64Registers::zr, address);
1500             return;
1501         }
1502 
1503         moveToCachedReg(imm, dataMemoryTempRegister());
1504         store32(dataTempRegister, address);
1505     }
1506 
1507     void store32(TrustedImm32 imm, BaseIndex address)
1508     {
1509         if (!imm.m_value) {
1510             store32(ARM64Registers::zr, address);
1511             return;
1512         }
1513 
1514         moveToCachedReg(imm, dataMemoryTempRegister());
1515         store32(dataTempRegister, address);
1516     }
1517 
1518     void store32(TrustedImm32 imm, const void* address)
1519     {
1520         if (!imm.m_value) {
1521             store32(ARM64Registers::zr, address);
1522             return;
1523         }
1524 
1525         moveToCachedReg(imm, dataMemoryTempRegister());
1526         store32(dataTempRegister, address);
1527     }
1528 
1529     void storeZero32(ImplicitAddress address)
1530     {
1531         store32(ARM64Registers::zr, address);
1532     }
1533 
1534     void storeZero32(BaseIndex address)
1535     {
1536         store32(ARM64Registers::zr, address);
1537     }
1538 
1539     DataLabel32 store32WithAddressOffsetPatch(RegisterID src, Address address)
1540     {
1541         DataLabel32 label(this);
1542         signExtend32ToPtrWithFixedWidth(address.offset, getCachedMemoryTempRegisterIDAndInvalidate());
1543         m_assembler.str&lt;32&gt;(src, address.base, memoryTempRegister, Assembler::SXTW, 0);
1544         return label;
1545     }
1546 
1547     void store16(RegisterID src, ImplicitAddress address)
1548     {
1549         if (tryStoreWithOffset&lt;16&gt;(src, address.base, address.offset))
1550             return;
1551 
1552         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1553         m_assembler.strh(src, address.base, memoryTempRegister);
1554     }
1555 
1556     void store16(RegisterID src, BaseIndex address)
1557     {
1558         if (!address.offset &amp;&amp; (!address.scale || address.scale == 1)) {
1559             m_assembler.strh(src, address.base, address.index, Assembler::UXTX, address.scale);
1560             return;
1561         }
1562 
1563         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1564         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1565         m_assembler.strh(src, address.base, memoryTempRegister);
1566     }
1567 
<a name="11" id="anc11"></a><span class="line-added">1568     void store16(RegisterID src, const void* address)</span>
<span class="line-added">1569     {</span>
<span class="line-added">1570         store&lt;16&gt;(src, address);</span>
<span class="line-added">1571     }</span>
<span class="line-added">1572 </span>
<span class="line-added">1573     void store16(TrustedImm32 imm, const void* address)</span>
<span class="line-added">1574     {</span>
<span class="line-added">1575         if (!imm.m_value) {</span>
<span class="line-added">1576             store16(ARM64Registers::zr, address);</span>
<span class="line-added">1577             return;</span>
<span class="line-added">1578         }</span>
<span class="line-added">1579 </span>
<span class="line-added">1580         moveToCachedReg(imm, dataMemoryTempRegister());</span>
<span class="line-added">1581         store16(dataTempRegister, address);</span>
<span class="line-added">1582     }</span>
<span class="line-added">1583 </span>
1584     void storeZero16(ImplicitAddress address)
1585     {
1586         store16(ARM64Registers::zr, address);
1587     }
1588 
1589     void storeZero16(BaseIndex address)
1590     {
1591         store16(ARM64Registers::zr, address);
1592     }
1593 
1594     void store8(RegisterID src, BaseIndex address)
1595     {
1596         if (!address.offset &amp;&amp; !address.scale) {
1597             m_assembler.strb(src, address.base, address.index, Assembler::UXTX, address.scale);
1598             return;
1599         }
1600 
1601         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1602         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1603         m_assembler.strb(src, address.base, memoryTempRegister);
1604     }
1605 
1606     void store8(RegisterID src, void* address)
1607     {
1608         move(TrustedImmPtr(address), getCachedMemoryTempRegisterIDAndInvalidate());
1609         m_assembler.strb(src, memoryTempRegister, 0);
1610     }
1611 
1612     void store8(RegisterID src, ImplicitAddress address)
1613     {
1614         if (tryStoreWithOffset&lt;8&gt;(src, address.base, address.offset))
1615             return;
1616 
1617         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1618         m_assembler.strb(src, address.base, memoryTempRegister);
1619     }
1620 
1621     void store8(TrustedImm32 imm, void* address)
1622     {
1623         TrustedImm32 imm8(static_cast&lt;int8_t&gt;(imm.m_value));
1624         if (!imm8.m_value) {
1625             store8(ARM64Registers::zr, address);
1626             return;
1627         }
1628 
1629         move(imm8, getCachedDataTempRegisterIDAndInvalidate());
1630         store8(dataTempRegister, address);
1631     }
1632 
1633     void store8(TrustedImm32 imm, ImplicitAddress address)
1634     {
1635         TrustedImm32 imm8(static_cast&lt;int8_t&gt;(imm.m_value));
1636         if (!imm8.m_value) {
1637             store8(ARM64Registers::zr, address);
1638             return;
1639         }
1640 
1641         move(imm8, getCachedDataTempRegisterIDAndInvalidate());
1642         store8(dataTempRegister, address);
1643     }
1644 
1645     void store8(RegisterID src, RegisterID dest, PostIndex simm)
1646     {
1647         m_assembler.strb(src, dest, simm);
1648     }
1649 
1650     void getEffectiveAddress(BaseIndex address, RegisterID dest)
1651     {
1652         m_assembler.add&lt;64&gt;(dest, address.base, address.index, Assembler::LSL, address.scale);
1653         if (address.offset)
1654             add64(TrustedImm32(address.offset), dest);
1655     }
1656 
1657     // Floating-point operations:
1658 
1659     static bool supportsFloatingPoint() { return true; }
1660     static bool supportsFloatingPointTruncate() { return true; }
1661     static bool supportsFloatingPointSqrt() { return true; }
1662     static bool supportsFloatingPointAbs() { return true; }
1663     static bool supportsFloatingPointRounding() { return true; }
1664     static bool supportsCountPopulation() { return false; }
1665 
1666     enum BranchTruncateType { BranchIfTruncateFailed, BranchIfTruncateSuccessful };
1667 
1668     void absDouble(FPRegisterID src, FPRegisterID dest)
1669     {
1670         m_assembler.fabs&lt;64&gt;(dest, src);
1671     }
1672 
1673     void absFloat(FPRegisterID src, FPRegisterID dest)
1674     {
1675         m_assembler.fabs&lt;32&gt;(dest, src);
1676     }
1677 
1678     void addDouble(FPRegisterID src, FPRegisterID dest)
1679     {
1680         addDouble(dest, src, dest);
1681     }
1682 
1683     void addDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1684     {
1685         m_assembler.fadd&lt;64&gt;(dest, op1, op2);
1686     }
1687 
1688     void addDouble(Address src, FPRegisterID dest)
1689     {
1690         loadDouble(src, fpTempRegister);
1691         addDouble(fpTempRegister, dest);
1692     }
1693 
1694     void addDouble(AbsoluteAddress address, FPRegisterID dest)
1695     {
1696         loadDouble(TrustedImmPtr(address.m_ptr), fpTempRegister);
1697         addDouble(fpTempRegister, dest);
1698     }
1699 
1700     void addFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1701     {
1702         m_assembler.fadd&lt;32&gt;(dest, op1, op2);
1703     }
1704 
1705     void ceilDouble(FPRegisterID src, FPRegisterID dest)
1706     {
1707         m_assembler.frintp&lt;64&gt;(dest, src);
1708     }
1709 
1710     void ceilFloat(FPRegisterID src, FPRegisterID dest)
1711     {
1712         m_assembler.frintp&lt;32&gt;(dest, src);
1713     }
1714 
1715     void floorDouble(FPRegisterID src, FPRegisterID dest)
1716     {
1717         m_assembler.frintm&lt;64&gt;(dest, src);
1718     }
1719 
1720     void floorFloat(FPRegisterID src, FPRegisterID dest)
1721     {
1722         m_assembler.frintm&lt;32&gt;(dest, src);
1723     }
1724 
1725     void roundTowardNearestIntDouble(FPRegisterID src, FPRegisterID dest)
1726     {
1727         m_assembler.frintn&lt;64&gt;(dest, src);
1728     }
1729 
1730     void roundTowardNearestIntFloat(FPRegisterID src, FPRegisterID dest)
1731     {
1732         m_assembler.frintn&lt;32&gt;(dest, src);
1733     }
1734 
1735     void roundTowardZeroDouble(FPRegisterID src, FPRegisterID dest)
1736     {
1737         m_assembler.frintz&lt;64&gt;(dest, src);
1738     }
1739 
1740     void roundTowardZeroFloat(FPRegisterID src, FPRegisterID dest)
1741     {
1742         m_assembler.frintz&lt;32&gt;(dest, src);
1743     }
1744 
1745 
1746     // Convert &#39;src&#39; to an integer, and places the resulting &#39;dest&#39;.
1747     // If the result is not representable as a 32 bit value, branch.
1748     // May also branch for some values that are representable in 32 bits
1749     // (specifically, in this case, 0).
1750     void branchConvertDoubleToInt32(FPRegisterID src, RegisterID dest, JumpList&amp; failureCases, FPRegisterID, bool negZeroCheck = true)
1751     {
1752         m_assembler.fcvtns&lt;32, 64&gt;(dest, src);
1753 
1754         // Convert the integer result back to float &amp; compare to the original value - if not equal or unordered (NaN) then jump.
1755         m_assembler.scvtf&lt;64, 32&gt;(fpTempRegister, dest);
1756         failureCases.append(branchDouble(DoubleNotEqualOrUnordered, src, fpTempRegister));
1757 
1758         // Test for negative zero.
1759         if (negZeroCheck) {
1760             Jump valueIsNonZero = branchTest32(NonZero, dest);
1761             RegisterID scratch = getCachedMemoryTempRegisterIDAndInvalidate();
1762             m_assembler.fmov&lt;64&gt;(scratch, src);
1763             failureCases.append(makeTestBitAndBranch(scratch, 63, IsNonZero));
1764             valueIsNonZero.link(this);
1765         }
1766     }
1767 
1768     Jump branchDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right)
1769     {
1770         m_assembler.fcmp&lt;64&gt;(left, right);
1771         return jumpAfterFloatingPointCompare(cond);
1772     }
1773 
1774     Jump branchFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right)
1775     {
1776         m_assembler.fcmp&lt;32&gt;(left, right);
1777         return jumpAfterFloatingPointCompare(cond);
1778     }
1779 
1780     void compareDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID dest)
1781     {
1782         floatingPointCompare(cond, left, right, dest, [this] (FPRegisterID arg1, FPRegisterID arg2) {
1783             m_assembler.fcmp&lt;64&gt;(arg1, arg2);
1784         });
1785     }
1786 
1787     void compareFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID dest)
1788     {
1789         floatingPointCompare(cond, left, right, dest, [this] (FPRegisterID arg1, FPRegisterID arg2) {
1790             m_assembler.fcmp&lt;32&gt;(arg1, arg2);
1791         });
1792     }
1793 
1794     Jump branchDoubleNonZero(FPRegisterID reg, FPRegisterID)
1795     {
1796         m_assembler.fcmp_0&lt;64&gt;(reg);
1797         Jump unordered = makeBranch(Assembler::ConditionVS);
1798         Jump result = makeBranch(Assembler::ConditionNE);
1799         unordered.link(this);
1800         return result;
1801     }
1802 
1803     Jump branchDoubleZeroOrNaN(FPRegisterID reg, FPRegisterID)
1804     {
1805         m_assembler.fcmp_0&lt;64&gt;(reg);
1806         Jump unordered = makeBranch(Assembler::ConditionVS);
1807         Jump notEqual = makeBranch(Assembler::ConditionNE);
1808         unordered.link(this);
1809         // We get here if either unordered or equal.
1810         Jump result = jump();
1811         notEqual.link(this);
1812         return result;
1813     }
1814 
1815     Jump branchTruncateDoubleToInt32(FPRegisterID src, RegisterID dest, BranchTruncateType branchType = BranchIfTruncateFailed)
1816     {
1817         // Truncate to a 64-bit integer in dataTempRegister, copy the low 32-bit to dest.
1818         m_assembler.fcvtzs&lt;64, 64&gt;(getCachedDataTempRegisterIDAndInvalidate(), src);
1819         zeroExtend32ToPtr(dataTempRegister, dest);
1820         // Check the low 32-bits sign extend to be equal to the full value.
1821         m_assembler.cmp&lt;64&gt;(dataTempRegister, dataTempRegister, Assembler::SXTW, 0);
1822         return Jump(makeBranch(branchType == BranchIfTruncateSuccessful ? Equal : NotEqual));
1823     }
1824 
1825     void convertDoubleToFloat(FPRegisterID src, FPRegisterID dest)
1826     {
1827         m_assembler.fcvt&lt;32, 64&gt;(dest, src);
1828     }
1829 
1830     void convertFloatToDouble(FPRegisterID src, FPRegisterID dest)
1831     {
1832         m_assembler.fcvt&lt;64, 32&gt;(dest, src);
1833     }
1834 
1835     void convertInt32ToDouble(TrustedImm32 imm, FPRegisterID dest)
1836     {
1837         move(imm, getCachedDataTempRegisterIDAndInvalidate());
1838         convertInt32ToDouble(dataTempRegister, dest);
1839     }
1840 
1841     void convertInt32ToDouble(RegisterID src, FPRegisterID dest)
1842     {
1843         m_assembler.scvtf&lt;64, 32&gt;(dest, src);
1844     }
1845 
1846     void convertInt32ToDouble(Address address, FPRegisterID dest)
1847     {
1848         load32(address, getCachedDataTempRegisterIDAndInvalidate());
1849         convertInt32ToDouble(dataTempRegister, dest);
1850     }
1851 
1852     void convertInt32ToDouble(AbsoluteAddress address, FPRegisterID dest)
1853     {
1854         load32(address.m_ptr, getCachedDataTempRegisterIDAndInvalidate());
1855         convertInt32ToDouble(dataTempRegister, dest);
1856     }
1857 
1858     void convertInt32ToFloat(RegisterID src, FPRegisterID dest)
1859     {
1860         m_assembler.scvtf&lt;32, 32&gt;(dest, src);
1861     }
1862 
1863     void convertInt64ToDouble(RegisterID src, FPRegisterID dest)
1864     {
1865         m_assembler.scvtf&lt;64, 64&gt;(dest, src);
1866     }
1867 
1868     void convertInt64ToFloat(RegisterID src, FPRegisterID dest)
1869     {
1870         m_assembler.scvtf&lt;32, 64&gt;(dest, src);
1871     }
1872 
1873     void convertUInt64ToDouble(RegisterID src, FPRegisterID dest)
1874     {
1875         m_assembler.ucvtf&lt;64, 64&gt;(dest, src);
1876     }
1877 
1878     void convertUInt64ToFloat(RegisterID src, FPRegisterID dest)
1879     {
1880         m_assembler.ucvtf&lt;32, 64&gt;(dest, src);
1881     }
1882 
1883     void divDouble(FPRegisterID src, FPRegisterID dest)
1884     {
1885         divDouble(dest, src, dest);
1886     }
1887 
1888     void divDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1889     {
1890         m_assembler.fdiv&lt;64&gt;(dest, op1, op2);
1891     }
1892 
1893     void divFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1894     {
1895         m_assembler.fdiv&lt;32&gt;(dest, op1, op2);
1896     }
1897 
1898     void loadDouble(ImplicitAddress address, FPRegisterID dest)
1899     {
1900         if (tryLoadWithOffset&lt;64&gt;(dest, address.base, address.offset))
1901             return;
1902 
1903         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1904         m_assembler.ldr&lt;64&gt;(dest, address.base, memoryTempRegister);
1905     }
1906 
1907     void loadDouble(BaseIndex address, FPRegisterID dest)
1908     {
1909         if (!address.offset &amp;&amp; (!address.scale || address.scale == 3)) {
1910             m_assembler.ldr&lt;64&gt;(dest, address.base, address.index, Assembler::UXTX, address.scale);
1911             return;
1912         }
1913 
1914         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1915         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1916         m_assembler.ldr&lt;64&gt;(dest, address.base, memoryTempRegister);
1917     }
1918 
1919     void loadDouble(TrustedImmPtr address, FPRegisterID dest)
1920     {
1921         moveToCachedReg(address, cachedMemoryTempRegister());
1922         m_assembler.ldr&lt;64&gt;(dest, memoryTempRegister, ARM64Registers::zr);
1923     }
1924 
1925     void loadFloat(ImplicitAddress address, FPRegisterID dest)
1926     {
1927         if (tryLoadWithOffset&lt;32&gt;(dest, address.base, address.offset))
1928             return;
1929 
1930         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1931         m_assembler.ldr&lt;32&gt;(dest, address.base, memoryTempRegister);
1932     }
1933 
1934     void loadFloat(BaseIndex address, FPRegisterID dest)
1935     {
1936         if (!address.offset &amp;&amp; (!address.scale || address.scale == 2)) {
1937             m_assembler.ldr&lt;32&gt;(dest, address.base, address.index, Assembler::UXTX, address.scale);
1938             return;
1939         }
1940 
1941         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1942         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1943         m_assembler.ldr&lt;32&gt;(dest, address.base, memoryTempRegister);
1944     }
1945 
1946     void loadFloat(TrustedImmPtr address, FPRegisterID dest)
1947     {
1948         moveToCachedReg(address, cachedMemoryTempRegister());
1949         m_assembler.ldr&lt;32&gt;(dest, memoryTempRegister, ARM64Registers::zr);
1950     }
1951 
1952     void moveDouble(FPRegisterID src, FPRegisterID dest)
1953     {
1954         m_assembler.fmov&lt;64&gt;(dest, src);
1955     }
1956 
1957     void moveZeroToDouble(FPRegisterID reg)
1958     {
1959         m_assembler.fmov&lt;64&gt;(reg, ARM64Registers::zr);
1960     }
1961 
1962     void moveDoubleTo64(FPRegisterID src, RegisterID dest)
1963     {
1964         m_assembler.fmov&lt;64&gt;(dest, src);
1965     }
1966 
1967     void moveFloatTo32(FPRegisterID src, RegisterID dest)
1968     {
1969         m_assembler.fmov&lt;32&gt;(dest, src);
1970     }
1971 
1972     void move64ToDouble(RegisterID src, FPRegisterID dest)
1973     {
1974         m_assembler.fmov&lt;64&gt;(dest, src);
1975     }
1976 
1977     void move32ToFloat(RegisterID src, FPRegisterID dest)
1978     {
1979         m_assembler.fmov&lt;32&gt;(dest, src);
1980     }
1981 
1982     void moveConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
1983     {
1984         m_assembler.fcmp&lt;64&gt;(left, right);
1985         moveConditionallyAfterFloatingPointCompare&lt;64&gt;(cond, src, dest);
1986     }
1987 
1988     void moveConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
1989     {
1990         m_assembler.fcmp&lt;64&gt;(left, right);
1991         moveConditionallyAfterFloatingPointCompare&lt;64&gt;(cond, thenCase, elseCase, dest);
1992     }
1993 
1994     void moveConditionallyFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
1995     {
1996         m_assembler.fcmp&lt;32&gt;(left, right);
1997         moveConditionallyAfterFloatingPointCompare&lt;64&gt;(cond, src, dest);
1998     }
1999 
2000     void moveConditionallyFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2001     {
2002         m_assembler.fcmp&lt;32&gt;(left, right);
2003         moveConditionallyAfterFloatingPointCompare&lt;64&gt;(cond, thenCase, elseCase, dest);
2004     }
2005 
2006     template&lt;int datasize&gt;
2007     void moveConditionallyAfterFloatingPointCompare(DoubleCondition cond, RegisterID src, RegisterID dest)
2008     {
2009         if (cond == DoubleNotEqual) {
2010             Jump unordered = makeBranch(Assembler::ConditionVS);
2011             m_assembler.csel&lt;datasize&gt;(dest, src, dest, Assembler::ConditionNE);
2012             unordered.link(this);
2013             return;
2014         }
2015         if (cond == DoubleEqualOrUnordered) {
2016             // If the compare is unordered, src is copied to dest and the
2017             // next csel has all arguments equal to src.
2018             // If the compare is ordered, dest is unchanged and EQ decides
2019             // what value to set.
2020             m_assembler.csel&lt;datasize&gt;(dest, src, dest, Assembler::ConditionVS);
2021             m_assembler.csel&lt;datasize&gt;(dest, src, dest, Assembler::ConditionEQ);
2022             return;
2023         }
2024         m_assembler.csel&lt;datasize&gt;(dest, src, dest, ARM64Condition(cond));
2025     }
2026 
2027     template&lt;int datasize&gt;
2028     void moveConditionallyAfterFloatingPointCompare(DoubleCondition cond, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2029     {
2030         if (cond == DoubleNotEqual) {
2031             Jump unordered = makeBranch(Assembler::ConditionVS);
2032             m_assembler.csel&lt;datasize&gt;(dest, thenCase, elseCase, Assembler::ConditionNE);
2033             unordered.link(this);
2034             return;
2035         }
2036         if (cond == DoubleEqualOrUnordered) {
2037             // If the compare is unordered, thenCase is copied to elseCase and the
2038             // next csel has all arguments equal to thenCase.
2039             // If the compare is ordered, dest is unchanged and EQ decides
2040             // what value to set.
2041             m_assembler.csel&lt;datasize&gt;(elseCase, thenCase, elseCase, Assembler::ConditionVS);
2042             m_assembler.csel&lt;datasize&gt;(dest, thenCase, elseCase, Assembler::ConditionEQ);
2043             return;
2044         }
2045         m_assembler.csel&lt;datasize&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2046     }
2047 
2048     template&lt;int datasize&gt;
2049     void moveDoubleConditionallyAfterFloatingPointCompare(DoubleCondition cond, FPRegisterID thenCase, FPRegisterID elseCase, FPRegisterID dest)
2050     {
2051         if (cond == DoubleNotEqual) {
2052             Jump unordered = makeBranch(Assembler::ConditionVS);
2053             m_assembler.fcsel&lt;datasize&gt;(dest, thenCase, elseCase, Assembler::ConditionNE);
2054             unordered.link(this);
2055             return;
2056         }
2057         if (cond == DoubleEqualOrUnordered) {
2058             // If the compare is unordered, thenCase is copied to elseCase and the
2059             // next csel has all arguments equal to thenCase.
2060             // If the compare is ordered, dest is unchanged and EQ decides
2061             // what value to set.
2062             m_assembler.fcsel&lt;datasize&gt;(elseCase, thenCase, elseCase, Assembler::ConditionVS);
2063             m_assembler.fcsel&lt;datasize&gt;(dest, thenCase, elseCase, Assembler::ConditionEQ);
2064             return;
2065         }
2066         m_assembler.fcsel&lt;datasize&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2067     }
2068 
2069     void moveDoubleConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, FPRegisterID thenCase, FPRegisterID elseCase, FPRegisterID dest)
2070     {
2071         m_assembler.fcmp&lt;64&gt;(left, right);
2072         moveDoubleConditionallyAfterFloatingPointCompare&lt;64&gt;(cond, thenCase, elseCase, dest);
2073     }
2074 
2075     void moveDoubleConditionallyFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, FPRegisterID thenCase, FPRegisterID elseCase, FPRegisterID dest)
2076     {
2077         m_assembler.fcmp&lt;32&gt;(left, right);
2078         moveDoubleConditionallyAfterFloatingPointCompare&lt;64&gt;(cond, thenCase, elseCase, dest);
2079     }
2080 
2081     void mulDouble(FPRegisterID src, FPRegisterID dest)
2082     {
2083         mulDouble(dest, src, dest);
2084     }
2085 
2086     void mulDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
2087     {
2088         m_assembler.fmul&lt;64&gt;(dest, op1, op2);
2089     }
2090 
2091     void mulDouble(Address src, FPRegisterID dest)
2092     {
2093         loadDouble(src, fpTempRegister);
2094         mulDouble(fpTempRegister, dest);
2095     }
2096 
2097     void mulFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
2098     {
2099         m_assembler.fmul&lt;32&gt;(dest, op1, op2);
2100     }
2101 
2102     void andDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
2103     {
2104         m_assembler.vand&lt;64&gt;(dest, op1, op2);
2105     }
2106 
2107     void andFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
2108     {
2109         andDouble(op1, op2, dest);
2110     }
2111 
2112     void orDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
2113     {
2114         m_assembler.vorr&lt;64&gt;(dest, op1, op2);
2115     }
2116 
2117     void orFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
2118     {
2119         orDouble(op1, op2, dest);
2120     }
2121 
2122     void negateDouble(FPRegisterID src, FPRegisterID dest)
2123     {
2124         m_assembler.fneg&lt;64&gt;(dest, src);
2125     }
2126 
2127     void negateFloat(FPRegisterID src, FPRegisterID dest)
2128     {
2129         m_assembler.fneg&lt;32&gt;(dest, src);
2130     }
2131 
2132     void sqrtDouble(FPRegisterID src, FPRegisterID dest)
2133     {
2134         m_assembler.fsqrt&lt;64&gt;(dest, src);
2135     }
2136 
2137     void sqrtFloat(FPRegisterID src, FPRegisterID dest)
2138     {
2139         m_assembler.fsqrt&lt;32&gt;(dest, src);
2140     }
2141 
2142     void storeDouble(FPRegisterID src, ImplicitAddress address)
2143     {
2144         if (tryStoreWithOffset&lt;64&gt;(src, address.base, address.offset))
2145             return;
2146 
2147         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
2148         m_assembler.str&lt;64&gt;(src, address.base, memoryTempRegister);
2149     }
2150 
2151     void storeDouble(FPRegisterID src, TrustedImmPtr address)
2152     {
2153         moveToCachedReg(address, cachedMemoryTempRegister());
2154         m_assembler.str&lt;64&gt;(src, memoryTempRegister, ARM64Registers::zr);
2155     }
2156 
2157     void storeDouble(FPRegisterID src, BaseIndex address)
2158     {
2159         if (!address.offset &amp;&amp; (!address.scale || address.scale == 3)) {
2160             m_assembler.str&lt;64&gt;(src, address.base, address.index, Assembler::UXTX, address.scale);
2161             return;
2162         }
2163 
2164         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
2165         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
2166         m_assembler.str&lt;64&gt;(src, address.base, memoryTempRegister);
2167     }
2168 
2169     void storeFloat(FPRegisterID src, ImplicitAddress address)
2170     {
2171         if (tryStoreWithOffset&lt;32&gt;(src, address.base, address.offset))
2172             return;
2173 
2174         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
2175         m_assembler.str&lt;32&gt;(src, address.base, memoryTempRegister);
2176     }
2177 
2178     void storeFloat(FPRegisterID src, BaseIndex address)
2179     {
2180         if (!address.offset &amp;&amp; (!address.scale || address.scale == 2)) {
2181             m_assembler.str&lt;32&gt;(src, address.base, address.index, Assembler::UXTX, address.scale);
2182             return;
2183         }
2184 
2185         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
2186         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
2187         m_assembler.str&lt;32&gt;(src, address.base, memoryTempRegister);
2188     }
2189 
2190     void subDouble(FPRegisterID src, FPRegisterID dest)
2191     {
2192         subDouble(dest, src, dest);
2193     }
2194 
2195     void subDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
2196     {
2197         m_assembler.fsub&lt;64&gt;(dest, op1, op2);
2198     }
2199 
2200     void subDouble(Address src, FPRegisterID dest)
2201     {
2202         loadDouble(src, fpTempRegister);
2203         subDouble(fpTempRegister, dest);
2204     }
2205 
2206     void subFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
2207     {
2208         m_assembler.fsub&lt;32&gt;(dest, op1, op2);
2209     }
2210 
2211     // Result is undefined if the value is outside of the integer range.
2212     void truncateDoubleToInt32(FPRegisterID src, RegisterID dest)
2213     {
2214         m_assembler.fcvtzs&lt;32, 64&gt;(dest, src);
2215     }
2216 
2217     void truncateDoubleToUint32(FPRegisterID src, RegisterID dest)
2218     {
2219         m_assembler.fcvtzu&lt;32, 64&gt;(dest, src);
2220     }
2221 
2222     void truncateDoubleToInt64(FPRegisterID src, RegisterID dest)
2223     {
2224         m_assembler.fcvtzs&lt;64, 64&gt;(dest, src);
2225     }
2226 
2227     void truncateDoubleToUint64(FPRegisterID src, RegisterID dest, FPRegisterID, FPRegisterID)
2228     {
2229         truncateDoubleToUint64(src, dest);
2230     }
2231 
2232     void truncateDoubleToUint64(FPRegisterID src, RegisterID dest)
2233     {
2234         m_assembler.fcvtzu&lt;64, 64&gt;(dest, src);
2235     }
2236 
2237     void truncateFloatToInt32(FPRegisterID src, RegisterID dest)
2238     {
2239         m_assembler.fcvtzs&lt;32, 32&gt;(dest, src);
2240     }
2241 
2242     void truncateFloatToUint32(FPRegisterID src, RegisterID dest)
2243     {
2244         m_assembler.fcvtzu&lt;32, 32&gt;(dest, src);
2245     }
2246 
2247     void truncateFloatToInt64(FPRegisterID src, RegisterID dest)
2248     {
2249         m_assembler.fcvtzs&lt;64, 32&gt;(dest, src);
2250     }
2251 
2252     void truncateFloatToUint64(FPRegisterID src, RegisterID dest, FPRegisterID, FPRegisterID)
2253     {
2254         truncateFloatToUint64(src, dest);
2255     }
2256 
2257     void truncateFloatToUint64(FPRegisterID src, RegisterID dest)
2258     {
2259         m_assembler.fcvtzu&lt;64, 32&gt;(dest, src);
2260     }
2261 
2262     // Stack manipulation operations:
2263     //
2264     // The ABI is assumed to provide a stack abstraction to memory,
2265     // containing machine word sized units of data. Push and pop
2266     // operations add and remove a single register sized unit of data
2267     // to or from the stack. These operations are not supported on
2268     // ARM64. Peek and poke operations read or write values on the
2269     // stack, without moving the current stack position. Additionally,
2270     // there are popToRestore and pushToSave operations, which are
2271     // designed just for quick-and-dirty saving and restoring of
2272     // temporary values. These operations don&#39;t claim to have any
2273     // ABI compatibility.
2274 
2275     void pop(RegisterID) NO_RETURN_DUE_TO_CRASH
2276     {
2277         CRASH();
2278     }
2279 
2280     void push(RegisterID) NO_RETURN_DUE_TO_CRASH
2281     {
2282         CRASH();
2283     }
2284 
2285     void push(Address) NO_RETURN_DUE_TO_CRASH
2286     {
2287         CRASH();
2288     }
2289 
2290     void push(TrustedImm32) NO_RETURN_DUE_TO_CRASH
2291     {
2292         CRASH();
2293     }
2294 
2295     void popPair(RegisterID dest1, RegisterID dest2)
2296     {
2297         m_assembler.ldp&lt;64&gt;(dest1, dest2, ARM64Registers::sp, PairPostIndex(16));
2298     }
2299 
2300     void pushPair(RegisterID src1, RegisterID src2)
2301     {
2302         m_assembler.stp&lt;64&gt;(src1, src2, ARM64Registers::sp, PairPreIndex(-16));
2303     }
2304 
2305     void popToRestore(RegisterID dest)
2306     {
2307         m_assembler.ldr&lt;64&gt;(dest, ARM64Registers::sp, PostIndex(16));
2308     }
2309 
2310     void pushToSave(RegisterID src)
2311     {
2312         m_assembler.str&lt;64&gt;(src, ARM64Registers::sp, PreIndex(-16));
2313     }
2314 
2315     void pushToSaveImmediateWithoutTouchingRegisters(TrustedImm32 imm)
2316     {
2317         // We can use any non-hardware reserved register here since we restore its value.
2318         // We pick dataTempRegister arbitrarily. We don&#39;t need to invalidate it here since
2319         // we restore its original value.
2320         RegisterID reg = dataTempRegister;
2321 
2322         pushPair(reg, reg);
2323         move(imm, reg);
2324         store64(reg, stackPointerRegister);
2325         load64(Address(stackPointerRegister, 8), reg);
2326     }
2327 
2328     void pushToSave(Address address)
2329     {
2330         load32(address, getCachedDataTempRegisterIDAndInvalidate());
2331         pushToSave(dataTempRegister);
2332     }
2333 
2334     void pushToSave(TrustedImm32 imm)
2335     {
2336         move(imm, getCachedDataTempRegisterIDAndInvalidate());
2337         pushToSave(dataTempRegister);
2338     }
2339 
2340     void popToRestore(FPRegisterID dest)
2341     {
2342         loadDouble(stackPointerRegister, dest);
2343         add64(TrustedImm32(16), stackPointerRegister);
2344     }
2345 
2346     void pushToSave(FPRegisterID src)
2347     {
2348         sub64(TrustedImm32(16), stackPointerRegister);
2349         storeDouble(src, stackPointerRegister);
2350     }
2351 
2352     static ptrdiff_t pushToSaveByteOffset() { return 16; }
2353 
2354     // Register move operations:
2355 
2356     void move(RegisterID src, RegisterID dest)
2357     {
2358         if (src != dest)
2359             m_assembler.mov&lt;64&gt;(dest, src);
2360     }
2361 
2362     void move(TrustedImm32 imm, RegisterID dest)
2363     {
2364         moveInternal&lt;TrustedImm32, int32_t&gt;(imm, dest);
2365     }
2366 
2367     void move(TrustedImmPtr imm, RegisterID dest)
2368     {
2369         moveInternal&lt;TrustedImmPtr, intptr_t&gt;(imm, dest);
2370     }
2371 
2372     void move(TrustedImm64 imm, RegisterID dest)
2373     {
2374         moveInternal&lt;TrustedImm64, int64_t&gt;(imm, dest);
2375     }
2376 
2377     void swap(RegisterID reg1, RegisterID reg2)
2378     {
2379         move(reg1, getCachedDataTempRegisterIDAndInvalidate());
2380         move(reg2, reg1);
2381         move(dataTempRegister, reg2);
2382     }
2383 
2384     void swap(FPRegisterID reg1, FPRegisterID reg2)
2385     {
2386         moveDouble(reg1, fpTempRegister);
2387         moveDouble(reg2, reg1);
2388         moveDouble(fpTempRegister, reg2);
2389     }
2390 
2391     void signExtend32ToPtr(TrustedImm32 imm, RegisterID dest)
2392     {
2393         move(TrustedImmPtr(reinterpret_cast&lt;void*&gt;(static_cast&lt;intptr_t&gt;(imm.m_value))), dest);
2394     }
2395 
2396     void signExtend32ToPtr(RegisterID src, RegisterID dest)
2397     {
2398         m_assembler.sxtw(dest, src);
2399     }
2400 
2401     void zeroExtend32ToPtr(RegisterID src, RegisterID dest)
2402     {
2403         m_assembler.uxtw(dest, src);
2404     }
2405 
2406     void moveConditionally32(RelationalCondition cond, RegisterID left, RegisterID right, RegisterID src, RegisterID dest)
2407     {
2408         m_assembler.cmp&lt;32&gt;(left, right);
2409         m_assembler.csel&lt;64&gt;(dest, src, dest, ARM64Condition(cond));
2410     }
2411 
2412     void moveConditionally32(RelationalCondition cond, RegisterID left, RegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2413     {
2414         m_assembler.cmp&lt;32&gt;(left, right);
2415         m_assembler.csel&lt;64&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2416     }
2417 
2418     void moveConditionally32(RelationalCondition cond, RegisterID left, TrustedImm32 right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2419     {
2420         if (!right.m_value) {
2421             if (auto resultCondition = commuteCompareToZeroIntoTest(cond)) {
2422                 moveConditionallyTest32(*resultCondition, left, left, thenCase, elseCase, dest);
2423                 return;
2424             }
2425         }
2426 
2427         if (isUInt12(right.m_value))
2428             m_assembler.cmp&lt;32&gt;(left, UInt12(right.m_value));
2429         else if (isUInt12(-right.m_value))
2430             m_assembler.cmn&lt;32&gt;(left, UInt12(-right.m_value));
2431         else {
2432             moveToCachedReg(right, dataMemoryTempRegister());
2433             m_assembler.cmp&lt;32&gt;(left, dataTempRegister);
2434         }
2435         m_assembler.csel&lt;64&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2436     }
2437 
2438     void moveConditionally64(RelationalCondition cond, RegisterID left, RegisterID right, RegisterID src, RegisterID dest)
2439     {
2440         m_assembler.cmp&lt;64&gt;(left, right);
2441         m_assembler.csel&lt;64&gt;(dest, src, dest, ARM64Condition(cond));
2442     }
2443 
2444     void moveConditionally64(RelationalCondition cond, RegisterID left, RegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2445     {
2446         m_assembler.cmp&lt;64&gt;(left, right);
2447         m_assembler.csel&lt;64&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2448     }
2449 
2450     void moveConditionally64(RelationalCondition cond, RegisterID left, TrustedImm32 right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2451     {
2452         if (!right.m_value) {
2453             if (auto resultCondition = commuteCompareToZeroIntoTest(cond)) {
2454                 moveConditionallyTest64(*resultCondition, left, left, thenCase, elseCase, dest);
2455                 return;
2456             }
2457         }
2458 
2459         if (isUInt12(right.m_value))
2460             m_assembler.cmp&lt;64&gt;(left, UInt12(right.m_value));
2461         else if (isUInt12(-right.m_value))
2462             m_assembler.cmn&lt;64&gt;(left, UInt12(-right.m_value));
2463         else {
2464             moveToCachedReg(right, dataMemoryTempRegister());
2465             m_assembler.cmp&lt;64&gt;(left, dataTempRegister);
2466         }
2467         m_assembler.csel&lt;64&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2468     }
2469 
2470     void moveConditionallyTest32(ResultCondition cond, RegisterID testReg, RegisterID mask, RegisterID src, RegisterID dest)
2471     {
2472         m_assembler.tst&lt;32&gt;(testReg, mask);
2473         m_assembler.csel&lt;64&gt;(dest, src, dest, ARM64Condition(cond));
2474     }
2475 
2476     void moveConditionallyTest32(ResultCondition cond, RegisterID left, RegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2477     {
2478         m_assembler.tst&lt;32&gt;(left, right);
2479         m_assembler.csel&lt;64&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2480     }
2481 
2482     void moveConditionallyTest32(ResultCondition cond, RegisterID left, TrustedImm32 right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2483     {
2484         test32(left, right);
2485         m_assembler.csel&lt;64&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2486     }
2487 
2488     void moveConditionallyTest64(ResultCondition cond, RegisterID testReg, RegisterID mask, RegisterID src, RegisterID dest)
2489     {
2490         m_assembler.tst&lt;64&gt;(testReg, mask);
2491         m_assembler.csel&lt;64&gt;(dest, src, dest, ARM64Condition(cond));
2492     }
2493 
2494     void moveConditionallyTest64(ResultCondition cond, RegisterID left, RegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2495     {
2496         m_assembler.tst&lt;64&gt;(left, right);
2497         m_assembler.csel&lt;64&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2498     }
2499 
2500     void moveDoubleConditionally32(RelationalCondition cond, RegisterID left, RegisterID right, FPRegisterID thenCase, FPRegisterID elseCase, FPRegisterID dest)
2501     {
2502         m_assembler.cmp&lt;32&gt;(left, right);
2503         m_assembler.fcsel&lt;64&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2504     }
2505 
2506     void moveDoubleConditionally32(RelationalCondition cond, RegisterID left, TrustedImm32 right, FPRegisterID thenCase, FPRegisterID elseCase, FPRegisterID dest)
2507     {
2508         if (!right.m_value) {
2509             if (auto resultCondition = commuteCompareToZeroIntoTest(cond)) {
2510                 moveDoubleConditionallyTest32(*resultCondition, left, left, thenCase, elseCase, dest);
2511                 return;
2512             }
2513         }
2514 
2515         if (isUInt12(right.m_value))
2516             m_assembler.cmp&lt;32&gt;(left, UInt12(right.m_value));
2517         else if (isUInt12(-right.m_value))
2518             m_assembler.cmn&lt;32&gt;(left, UInt12(-right.m_value));
2519         else {
2520             moveToCachedReg(right, dataMemoryTempRegister());
2521             m_assembler.cmp&lt;32&gt;(left, dataTempRegister);
2522         }
2523         m_assembler.fcsel&lt;64&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2524     }
2525 
2526     void moveDoubleConditionally64(RelationalCondition cond, RegisterID left, RegisterID right, FPRegisterID thenCase, FPRegisterID elseCase, FPRegisterID dest)
2527     {
2528         m_assembler.cmp&lt;64&gt;(left, right);
2529         m_assembler.fcsel&lt;64&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2530     }
2531 
2532     void moveDoubleConditionally64(RelationalCondition cond, RegisterID left, TrustedImm32 right, FPRegisterID thenCase, FPRegisterID elseCase, FPRegisterID dest)
2533     {
2534         if (!right.m_value) {
2535             if (auto resultCondition = commuteCompareToZeroIntoTest(cond)) {
2536                 moveDoubleConditionallyTest64(*resultCondition, left, left, thenCase, elseCase, dest);
2537                 return;
2538             }
2539         }
2540 
2541         if (isUInt12(right.m_value))
2542             m_assembler.cmp&lt;64&gt;(left, UInt12(right.m_value));
2543         else if (isUInt12(-right.m_value))
2544             m_assembler.cmn&lt;64&gt;(left, UInt12(-right.m_value));
2545         else {
2546             moveToCachedReg(right, dataMemoryTempRegister());
2547             m_assembler.cmp&lt;64&gt;(left, dataTempRegister);
2548         }
2549         m_assembler.fcsel&lt;64&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2550     }
2551 
2552     void moveDoubleConditionallyTest32(ResultCondition cond, RegisterID left, RegisterID right, FPRegisterID thenCase, FPRegisterID elseCase, FPRegisterID dest)
2553     {
2554         m_assembler.tst&lt;32&gt;(left, right);
2555         m_assembler.fcsel&lt;64&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2556     }
2557 
2558     void moveDoubleConditionallyTest32(ResultCondition cond, RegisterID left, TrustedImm32 right, FPRegisterID thenCase, FPRegisterID elseCase, FPRegisterID dest)
2559     {
2560         test32(left, right);
2561         m_assembler.fcsel&lt;64&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2562     }
2563 
2564     void moveDoubleConditionallyTest64(ResultCondition cond, RegisterID left, RegisterID right, FPRegisterID thenCase, FPRegisterID elseCase, FPRegisterID dest)
2565     {
2566         m_assembler.tst&lt;64&gt;(left, right);
2567         m_assembler.fcsel&lt;64&gt;(dest, thenCase, elseCase, ARM64Condition(cond));
2568     }
2569 
2570     // Bit field operations:
2571 
2572     // destBitOffset is the top bit of the destination where the bits should be copied to. Zero is the lowest order bit.
2573     void bitFieldInsert64(RegisterID source, unsigned destBitOffset, unsigned width, RegisterID dest)
2574     {
2575         ASSERT(width &lt;= 64 - destBitOffset &amp;&amp; destBitOffset &lt; 64);
2576         m_assembler.bfi&lt;64&gt;(dest, source, destBitOffset, width);
2577     }
2578 
2579     // Forwards / external control flow operations:
2580     //
2581     // This set of jump and conditional branch operations return a Jump
2582     // object which may linked at a later point, allow forwards jump,
2583     // or jumps that will require external linkage (after the code has been
2584     // relocated).
2585     //
2586     // For branches, signed &lt;, &gt;, &lt;= and &gt;= are denoted as l, g, le, and ge
2587     // respecitvely, for unsigned comparisons the names b, a, be, and ae are
2588     // used (representing the names &#39;below&#39; and &#39;above&#39;).
2589     //
2590     // Operands to the comparision are provided in the expected order, e.g.
2591     // jle32(reg1, TrustedImm32(5)) will branch if the value held in reg1, when
2592     // treated as a signed 32bit value, is less than or equal to 5.
2593     //
2594     // jz and jnz test whether the first operand is equal to zero, and take
2595     // an optional second operand of a mask under which to perform the test.
2596 
2597     Jump branch32(RelationalCondition cond, RegisterID left, RegisterID right)
2598     {
2599         m_assembler.cmp&lt;32&gt;(left, right);
2600         return Jump(makeBranch(cond));
2601     }
2602 
2603     Jump branch32(RelationalCondition cond, RegisterID left, TrustedImm32 right)
2604     {
2605         if (!right.m_value) {
2606             if (auto resultCondition = commuteCompareToZeroIntoTest(cond))
2607                 return branchTest32(*resultCondition, left, left);
2608         }
2609 
2610         if (isUInt12(right.m_value))
2611             m_assembler.cmp&lt;32&gt;(left, UInt12(right.m_value));
2612         else if (isUInt12(-right.m_value))
2613             m_assembler.cmn&lt;32&gt;(left, UInt12(-right.m_value));
2614         else {
2615             moveToCachedReg(right, dataMemoryTempRegister());
2616             m_assembler.cmp&lt;32&gt;(left, dataTempRegister);
2617         }
2618         return Jump(makeBranch(cond));
2619     }
2620 
2621     Jump branch32(RelationalCondition cond, RegisterID left, Address right)
2622     {
2623         load32(right, getCachedMemoryTempRegisterIDAndInvalidate());
2624         return branch32(cond, left, memoryTempRegister);
2625     }
2626 
2627     Jump branch32(RelationalCondition cond, Address left, RegisterID right)
2628     {
2629         load32(left, getCachedMemoryTempRegisterIDAndInvalidate());
2630         return branch32(cond, memoryTempRegister, right);
2631     }
2632 
2633     Jump branch32(RelationalCondition cond, Address left, TrustedImm32 right)
2634     {
2635         load32(left, getCachedMemoryTempRegisterIDAndInvalidate());
2636         return branch32(cond, memoryTempRegister, right);
2637     }
2638 
2639     Jump branch32(RelationalCondition cond, BaseIndex left, TrustedImm32 right)
2640     {
2641         load32(left, getCachedMemoryTempRegisterIDAndInvalidate());
2642         return branch32(cond, memoryTempRegister, right);
2643     }
2644 
2645     Jump branch32(RelationalCondition cond, AbsoluteAddress left, RegisterID right)
2646     {
2647         load32(left.m_ptr, getCachedDataTempRegisterIDAndInvalidate());
2648         return branch32(cond, dataTempRegister, right);
2649     }
2650 
2651     Jump branch32(RelationalCondition cond, AbsoluteAddress left, TrustedImm32 right)
2652     {
2653         load32(left.m_ptr, getCachedMemoryTempRegisterIDAndInvalidate());
2654         return branch32(cond, memoryTempRegister, right);
2655     }
2656 
2657     Jump branch64(RelationalCondition cond, RegisterID left, RegisterID right)
2658     {
2659         if (right == ARM64Registers::sp) {
2660             if (cond == Equal &amp;&amp; left != ARM64Registers::sp) {
2661                 // CMP can only use SP for the left argument, since we are testing for equality, the order
2662                 // does not matter here.
2663                 std::swap(left, right);
2664             } else {
2665                 move(right, getCachedDataTempRegisterIDAndInvalidate());
2666                 right = dataTempRegister;
2667             }
2668         }
2669         m_assembler.cmp&lt;64&gt;(left, right);
2670         return Jump(makeBranch(cond));
2671     }
2672 
2673     Jump branch64(RelationalCondition cond, RegisterID left, TrustedImm32 right)
2674     {
2675         if (!right.m_value) {
2676             if (auto resultCondition = commuteCompareToZeroIntoTest(cond))
2677                 return branchTest64(*resultCondition, left, left);
2678         }
2679 
2680         if (isUInt12(right.m_value))
2681             m_assembler.cmp&lt;64&gt;(left, UInt12(right.m_value));
2682         else if (isUInt12(-right.m_value))
2683             m_assembler.cmn&lt;64&gt;(left, UInt12(-right.m_value));
2684         else {
2685             moveToCachedReg(right, dataMemoryTempRegister());
2686             m_assembler.cmp&lt;64&gt;(left, dataTempRegister);
2687         }
2688         return Jump(makeBranch(cond));
2689     }
2690 
2691     Jump branch64(RelationalCondition cond, RegisterID left, TrustedImm64 right)
2692     {
2693         intptr_t immediate = right.m_value;
2694         if (!immediate) {
2695             if (auto resultCondition = commuteCompareToZeroIntoTest(cond))
2696                 return branchTest64(*resultCondition, left, left);
2697         }
2698 
2699         if (isUInt12(immediate))
2700             m_assembler.cmp&lt;64&gt;(left, UInt12(static_cast&lt;int32_t&gt;(immediate)));
2701         else if (isUInt12(-immediate))
2702             m_assembler.cmn&lt;64&gt;(left, UInt12(static_cast&lt;int32_t&gt;(-immediate)));
2703         else {
2704             moveToCachedReg(right, dataMemoryTempRegister());
2705             m_assembler.cmp&lt;64&gt;(left, dataTempRegister);
2706         }
2707         return Jump(makeBranch(cond));
2708     }
2709 
2710     Jump branch64(RelationalCondition cond, RegisterID left, Address right)
2711     {
2712         load64(right, getCachedMemoryTempRegisterIDAndInvalidate());
2713         return branch64(cond, left, memoryTempRegister);
2714     }
2715 
2716     Jump branch64(RelationalCondition cond, AbsoluteAddress left, RegisterID right)
2717     {
2718         load64(left.m_ptr, getCachedDataTempRegisterIDAndInvalidate());
2719         return branch64(cond, dataTempRegister, right);
2720     }
2721 
2722     Jump branch64(RelationalCondition cond, Address left, RegisterID right)
2723     {
2724         load64(left, getCachedMemoryTempRegisterIDAndInvalidate());
2725         return branch64(cond, memoryTempRegister, right);
2726     }
2727 
2728     Jump branch64(RelationalCondition cond, Address left, TrustedImm64 right)
2729     {
2730         load64(left, getCachedMemoryTempRegisterIDAndInvalidate());
2731         return branch64(cond, memoryTempRegister, right);
2732     }
2733 
2734     Jump branch64(RelationalCondition cond, BaseIndex left, RegisterID right)
2735     {
2736         load64(left, getCachedMemoryTempRegisterIDAndInvalidate());
2737         return branch64(cond, memoryTempRegister, right);
2738     }
2739 
2740     Jump branchPtr(RelationalCondition cond, BaseIndex left, RegisterID right)
2741     {
2742         return branch64(cond, left, right);
2743     }
2744 
2745     Jump branch8(RelationalCondition cond, Address left, TrustedImm32 right)
2746     {
2747         TrustedImm32 right8 = MacroAssemblerHelpers::mask8OnCondition(*this, cond, right);
2748         MacroAssemblerHelpers::load8OnCondition(*this, cond, left, getCachedMemoryTempRegisterIDAndInvalidate());
2749         return branch32(cond, memoryTempRegister, right8);
2750     }
2751 
2752     Jump branch8(RelationalCondition cond, BaseIndex left, TrustedImm32 right)
2753     {
2754         TrustedImm32 right8 = MacroAssemblerHelpers::mask8OnCondition(*this, cond, right);
2755         MacroAssemblerHelpers::load8OnCondition(*this, cond, left, getCachedMemoryTempRegisterIDAndInvalidate());
2756         return branch32(cond, memoryTempRegister, right8);
2757     }
2758 
2759     Jump branch8(RelationalCondition cond, AbsoluteAddress left, TrustedImm32 right)
2760     {
2761         TrustedImm32 right8 = MacroAssemblerHelpers::mask8OnCondition(*this, cond, right);
2762         MacroAssemblerHelpers::load8OnCondition(*this, cond, left.m_ptr, getCachedMemoryTempRegisterIDAndInvalidate());
2763         return branch32(cond, memoryTempRegister, right8);
2764     }
2765 
2766     Jump branchTest32(ResultCondition cond, RegisterID reg, RegisterID mask)
2767     {
2768         if (reg == mask &amp;&amp; (cond == Zero || cond == NonZero))
2769             return Jump(makeCompareAndBranch&lt;32&gt;(static_cast&lt;ZeroCondition&gt;(cond), reg));
2770         m_assembler.tst&lt;32&gt;(reg, mask);
2771         return Jump(makeBranch(cond));
2772     }
2773 
2774     void test32(RegisterID reg, TrustedImm32 mask = TrustedImm32(-1))
2775     {
2776         if (mask.m_value == -1)
2777             m_assembler.tst&lt;32&gt;(reg, reg);
2778         else {
2779             LogicalImmediate logicalImm = LogicalImmediate::create32(mask.m_value);
2780 
2781             if (logicalImm.isValid())
2782                 m_assembler.tst&lt;32&gt;(reg, logicalImm);
2783             else {
2784                 move(mask, getCachedDataTempRegisterIDAndInvalidate());
2785                 m_assembler.tst&lt;32&gt;(reg, dataTempRegister);
2786             }
2787         }
2788     }
2789 
2790     Jump branch(ResultCondition cond)
2791     {
2792         return Jump(makeBranch(cond));
2793     }
2794 
2795     Jump branchTest32(ResultCondition cond, RegisterID reg, TrustedImm32 mask = TrustedImm32(-1))
2796     {
2797         if (mask.m_value == -1) {
2798             if ((cond == Zero) || (cond == NonZero))
2799                 return Jump(makeCompareAndBranch&lt;32&gt;(static_cast&lt;ZeroCondition&gt;(cond), reg));
2800             m_assembler.tst&lt;32&gt;(reg, reg);
2801         } else if (hasOneBitSet(mask.m_value) &amp;&amp; ((cond == Zero) || (cond == NonZero)))
2802             return Jump(makeTestBitAndBranch(reg, getLSBSet(mask.m_value), static_cast&lt;ZeroCondition&gt;(cond)));
2803         else {
2804             LogicalImmediate logicalImm = LogicalImmediate::create32(mask.m_value);
2805             if (logicalImm.isValid()) {
2806                 m_assembler.tst&lt;32&gt;(reg, logicalImm);
2807                 return Jump(makeBranch(cond));
2808             }
2809 
2810             move(mask, getCachedDataTempRegisterIDAndInvalidate());
2811             m_assembler.tst&lt;32&gt;(reg, dataTempRegister);
2812         }
2813         return Jump(makeBranch(cond));
2814     }
2815 
2816     Jump branchTest32(ResultCondition cond, Address address, TrustedImm32 mask = TrustedImm32(-1))
2817     {
2818         load32(address, getCachedMemoryTempRegisterIDAndInvalidate());
2819         return branchTest32(cond, memoryTempRegister, mask);
2820     }
2821 
2822     Jump branchTest32(ResultCondition cond, BaseIndex address, TrustedImm32 mask = TrustedImm32(-1))
2823     {
2824         load32(address, getCachedMemoryTempRegisterIDAndInvalidate());
2825         return branchTest32(cond, memoryTempRegister, mask);
2826     }
2827 
2828     Jump branchTest64(ResultCondition cond, RegisterID reg, RegisterID mask)
2829     {
2830         if (reg == mask &amp;&amp; (cond == Zero || cond == NonZero))
2831             return Jump(makeCompareAndBranch&lt;64&gt;(static_cast&lt;ZeroCondition&gt;(cond), reg));
2832         m_assembler.tst&lt;64&gt;(reg, mask);
2833         return Jump(makeBranch(cond));
2834     }
2835 
2836     Jump branchTest64(ResultCondition cond, RegisterID reg, TrustedImm32 mask = TrustedImm32(-1))
2837     {
2838         if (mask.m_value == -1) {
2839             if ((cond == Zero) || (cond == NonZero))
2840                 return Jump(makeCompareAndBranch&lt;64&gt;(static_cast&lt;ZeroCondition&gt;(cond), reg));
2841             m_assembler.tst&lt;64&gt;(reg, reg);
2842         } else if (hasOneBitSet(mask.m_value) &amp;&amp; ((cond == Zero) || (cond == NonZero)))
2843             return Jump(makeTestBitAndBranch(reg, getLSBSet(mask.m_value), static_cast&lt;ZeroCondition&gt;(cond)));
2844         else {
2845             LogicalImmediate logicalImm = LogicalImmediate::create64(mask.m_value);
2846 
2847             if (logicalImm.isValid()) {
2848                 m_assembler.tst&lt;64&gt;(reg, logicalImm);
2849                 return Jump(makeBranch(cond));
2850             }
2851 
2852             signExtend32ToPtr(mask, getCachedDataTempRegisterIDAndInvalidate());
2853             m_assembler.tst&lt;64&gt;(reg, dataTempRegister);
2854         }
2855         return Jump(makeBranch(cond));
2856     }
2857 
2858     Jump branchTest64(ResultCondition cond, RegisterID reg, TrustedImm64 mask)
2859     {
2860         if (mask.m_value == -1) {
2861             if ((cond == Zero) || (cond == NonZero))
2862                 return Jump(makeCompareAndBranch&lt;64&gt;(static_cast&lt;ZeroCondition&gt;(cond), reg));
2863             m_assembler.tst&lt;64&gt;(reg, reg);
2864         } else if (hasOneBitSet(mask.m_value) &amp;&amp; ((cond == Zero) || (cond == NonZero)))
2865             return Jump(makeTestBitAndBranch(reg, getLSBSet(mask.m_value), static_cast&lt;ZeroCondition&gt;(cond)));
2866         else {
2867             LogicalImmediate logicalImm = LogicalImmediate::create64(mask.m_value);
2868 
2869             if (logicalImm.isValid()) {
2870                 m_assembler.tst&lt;64&gt;(reg, logicalImm);
2871                 return Jump(makeBranch(cond));
2872             }
2873 
2874             move(mask, getCachedDataTempRegisterIDAndInvalidate());
2875             m_assembler.tst&lt;64&gt;(reg, dataTempRegister);
2876         }
2877         return Jump(makeBranch(cond));
2878     }
2879 
2880     Jump branchTest64(ResultCondition cond, Address address, RegisterID mask)
2881     {
2882         load64(address, getCachedDataTempRegisterIDAndInvalidate());
2883         return branchTest64(cond, dataTempRegister, mask);
2884     }
2885 
2886     Jump branchTest64(ResultCondition cond, Address address, TrustedImm32 mask = TrustedImm32(-1))
2887     {
2888         load64(address, getCachedDataTempRegisterIDAndInvalidate());
2889         return branchTest64(cond, dataTempRegister, mask);
2890     }
2891 
2892     Jump branchTest64(ResultCondition cond, BaseIndex address, TrustedImm32 mask = TrustedImm32(-1))
2893     {
2894         load64(address, getCachedDataTempRegisterIDAndInvalidate());
2895         return branchTest64(cond, dataTempRegister, mask);
2896     }
2897 
2898     Jump branchTest64(ResultCondition cond, AbsoluteAddress address, TrustedImm32 mask = TrustedImm32(-1))
2899     {
2900         load64(address.m_ptr, getCachedDataTempRegisterIDAndInvalidate());
2901         return branchTest64(cond, dataTempRegister, mask);
2902     }
2903 
2904     Jump branchTest8(ResultCondition cond, Address address, TrustedImm32 mask = TrustedImm32(-1))
2905     {
2906         TrustedImm32 mask8 = MacroAssemblerHelpers::mask8OnCondition(*this, cond, mask);
2907         MacroAssemblerHelpers::load8OnCondition(*this, cond, address, getCachedDataTempRegisterIDAndInvalidate());
2908         return branchTest32(cond, dataTempRegister, mask8);
2909     }
2910 
2911     Jump branchTest8(ResultCondition cond, AbsoluteAddress address, TrustedImm32 mask = TrustedImm32(-1))
2912     {
2913         TrustedImm32 mask8 = MacroAssemblerHelpers::mask8OnCondition(*this, cond, mask);
2914         MacroAssemblerHelpers::load8OnCondition(*this, cond, address.m_ptr, getCachedDataTempRegisterIDAndInvalidate());
2915         return branchTest32(cond, dataTempRegister, mask8);
2916     }
2917 
2918     Jump branchTest8(ResultCondition cond, ExtendedAddress address, TrustedImm32 mask = TrustedImm32(-1))
2919     {
2920         TrustedImm32 mask8 = MacroAssemblerHelpers::mask8OnCondition(*this, cond, mask);
2921         move(TrustedImmPtr(reinterpret_cast&lt;void*&gt;(address.offset)), getCachedDataTempRegisterIDAndInvalidate());
2922 
2923         if (MacroAssemblerHelpers::isUnsigned&lt;MacroAssemblerARM64&gt;(cond))
2924             m_assembler.ldrb(dataTempRegister, address.base, dataTempRegister);
2925         else
2926             m_assembler.ldrsb&lt;32&gt;(dataTempRegister, address.base, dataTempRegister);
2927 
2928         return branchTest32(cond, dataTempRegister, mask8);
2929     }
2930 
2931     Jump branchTest8(ResultCondition cond, BaseIndex address, TrustedImm32 mask = TrustedImm32(-1))
2932     {
2933         TrustedImm32 mask8 = MacroAssemblerHelpers::mask8OnCondition(*this, cond, mask);
2934         MacroAssemblerHelpers::load8OnCondition(*this, cond, address, getCachedDataTempRegisterIDAndInvalidate());
2935         return branchTest32(cond, dataTempRegister, mask8);
2936     }
2937 
2938     Jump branch32WithUnalignedHalfWords(RelationalCondition cond, BaseIndex left, TrustedImm32 right)
2939     {
2940         return branch32(cond, left, right);
2941     }
2942 
2943 
2944     // Arithmetic control flow operations:
2945     //
2946     // This set of conditional branch operations branch based
2947     // on the result of an arithmetic operation. The operation
2948     // is performed as normal, storing the result.
2949     //
2950     // * jz operations branch if the result is zero.
2951     // * jo operations branch if the (signed) arithmetic
2952     //   operation caused an overflow to occur.
2953 
2954     Jump branchAdd32(ResultCondition cond, RegisterID op1, RegisterID op2, RegisterID dest)
2955     {
2956         m_assembler.add&lt;32, S&gt;(dest, op1, op2);
2957         return Jump(makeBranch(cond));
2958     }
2959 
2960     Jump branchAdd32(ResultCondition cond, RegisterID op1, TrustedImm32 imm, RegisterID dest)
2961     {
2962         if (isUInt12(imm.m_value)) {
2963             m_assembler.add&lt;32, S&gt;(dest, op1, UInt12(imm.m_value));
2964             return Jump(makeBranch(cond));
2965         }
2966         if (isUInt12(-imm.m_value)) {
2967             m_assembler.sub&lt;32, S&gt;(dest, op1, UInt12(-imm.m_value));
2968             return Jump(makeBranch(cond));
2969         }
2970 
2971         signExtend32ToPtr(imm, getCachedDataTempRegisterIDAndInvalidate());
2972         return branchAdd32(cond, op1, dataTempRegister, dest);
2973     }
2974 
2975     Jump branchAdd32(ResultCondition cond, Address src, RegisterID dest)
2976     {
2977         load32(src, getCachedDataTempRegisterIDAndInvalidate());
2978         return branchAdd32(cond, dest, dataTempRegister, dest);
2979     }
2980 
2981     Jump branchAdd32(ResultCondition cond, RegisterID src, RegisterID dest)
2982     {
2983         return branchAdd32(cond, dest, src, dest);
2984     }
2985 
2986     Jump branchAdd32(ResultCondition cond, TrustedImm32 imm, RegisterID dest)
2987     {
2988         return branchAdd32(cond, dest, imm, dest);
2989     }
2990 
2991     Jump branchAdd32(ResultCondition cond, TrustedImm32 imm, AbsoluteAddress address)
2992     {
2993         load32(address.m_ptr, getCachedDataTempRegisterIDAndInvalidate());
2994 
2995         if (isUInt12(imm.m_value)) {
2996             m_assembler.add&lt;32, S&gt;(dataTempRegister, dataTempRegister, UInt12(imm.m_value));
2997             store32(dataTempRegister, address.m_ptr);
2998         } else if (isUInt12(-imm.m_value)) {
2999             m_assembler.sub&lt;32, S&gt;(dataTempRegister, dataTempRegister, UInt12(-imm.m_value));
3000             store32(dataTempRegister, address.m_ptr);
3001         } else {
3002             move(imm, getCachedMemoryTempRegisterIDAndInvalidate());
3003             m_assembler.add&lt;32, S&gt;(dataTempRegister, dataTempRegister, memoryTempRegister);
3004             store32(dataTempRegister, address.m_ptr);
3005         }
3006 
3007         return Jump(makeBranch(cond));
3008     }
3009 
3010     Jump branchAdd32(ResultCondition cond, TrustedImm32 imm, Address address)
3011     {
3012         load32(address, getCachedDataTempRegisterIDAndInvalidate());
3013 
3014         if (isUInt12(imm.m_value))
3015             m_assembler.add&lt;32, S&gt;(dataTempRegister, dataTempRegister, UInt12(imm.m_value));
3016         else if (isUInt12(-imm.m_value))
3017             m_assembler.sub&lt;32, S&gt;(dataTempRegister, dataTempRegister, UInt12(-imm.m_value));
3018         else {
3019             move(imm, getCachedMemoryTempRegisterIDAndInvalidate());
3020             m_assembler.add&lt;32, S&gt;(dataTempRegister, dataTempRegister, memoryTempRegister);
3021         }
3022 
3023         store32(dataTempRegister, address);
3024         return Jump(makeBranch(cond));
3025     }
3026 
3027     Jump branchAdd64(ResultCondition cond, RegisterID op1, RegisterID op2, RegisterID dest)
3028     {
3029         m_assembler.add&lt;64, S&gt;(dest, op1, op2);
3030         return Jump(makeBranch(cond));
3031     }
3032 
3033     Jump branchAdd64(ResultCondition cond, RegisterID op1, TrustedImm32 imm, RegisterID dest)
3034     {
3035         if (isUInt12(imm.m_value)) {
3036             m_assembler.add&lt;64, S&gt;(dest, op1, UInt12(imm.m_value));
3037             return Jump(makeBranch(cond));
3038         }
3039         if (isUInt12(-imm.m_value)) {
3040             m_assembler.sub&lt;64, S&gt;(dest, op1, UInt12(-imm.m_value));
3041             return Jump(makeBranch(cond));
3042         }
3043 
3044         move(imm, getCachedDataTempRegisterIDAndInvalidate());
3045         return branchAdd64(cond, op1, dataTempRegister, dest);
3046     }
3047 
3048     Jump branchAdd64(ResultCondition cond, RegisterID src, RegisterID dest)
3049     {
3050         return branchAdd64(cond, dest, src, dest);
3051     }
3052 
3053     Jump branchAdd64(ResultCondition cond, TrustedImm32 imm, RegisterID dest)
3054     {
3055         return branchAdd64(cond, dest, imm, dest);
3056     }
3057 
3058     Jump branchAdd64(RelationalCondition cond, TrustedImm32 imm, RegisterID dest)
3059     {
3060         ASSERT(isUInt12(imm.m_value));
3061         m_assembler.add&lt;64, S&gt;(dest, dest, UInt12(imm.m_value));
3062         return Jump(makeBranch(cond));
3063     }
3064 
3065     Jump branchMul32(ResultCondition cond, RegisterID src1, RegisterID src2, RegisterID scratch1, RegisterID scratch2, RegisterID dest)
3066     {
3067         ASSERT(cond != Signed);
3068 
3069         if (cond != Overflow) {
3070             m_assembler.mul&lt;32&gt;(dest, src1, src2);
3071             return branchTest32(cond, dest);
3072         }
3073 
3074         // This is a signed multiple of two 32-bit values, producing a 64-bit result.
3075         m_assembler.smull(dest, src1, src2);
3076         // Copy bits 63..32 of the result to bits 31..0 of scratch1.
3077         m_assembler.asr&lt;64&gt;(scratch1, dest, 32);
3078         // Splat bit 31 of the result to bits 31..0 of scratch2.
3079         m_assembler.asr&lt;32&gt;(scratch2, dest, 31);
3080         // After a mul32 the top 32 bits of the register should be clear.
3081         zeroExtend32ToPtr(dest, dest);
3082         // Check that bits 31..63 of the original result were all equal.
3083         return branch32(NotEqual, scratch2, scratch1);
3084     }
3085 
3086     Jump branchMul32(ResultCondition cond, RegisterID src1, RegisterID src2, RegisterID dest)
3087     {
3088         return branchMul32(cond, src1, src2, getCachedDataTempRegisterIDAndInvalidate(), getCachedMemoryTempRegisterIDAndInvalidate(), dest);
3089     }
3090 
3091     Jump branchMul32(ResultCondition cond, RegisterID src, RegisterID dest)
3092     {
3093         return branchMul32(cond, dest, src, dest);
3094     }
3095 
3096     Jump branchMul32(ResultCondition cond, RegisterID src, TrustedImm32 imm, RegisterID dest)
3097     {
3098         move(imm, getCachedDataTempRegisterIDAndInvalidate());
3099         return branchMul32(cond, dataTempRegister, src, dest);
3100     }
3101 
3102     Jump branchMul64(ResultCondition cond, RegisterID src1, RegisterID src2, RegisterID scratch1, RegisterID scratch2, RegisterID dest)
3103     {
3104         ASSERT(cond != Signed);
3105 
3106         // This is a signed multiple of two 64-bit values, producing a 64-bit result.
3107         m_assembler.mul&lt;64&gt;(dest, src1, src2);
3108 
3109         if (cond != Overflow)
3110             return branchTest64(cond, dest);
3111 
3112         // Compute bits 127..64 of the result into scratch1.
3113         m_assembler.smulh(scratch1, src1, src2);
3114         // Splat bit 63 of the result to bits 63..0 of scratch2.
3115         m_assembler.asr&lt;64&gt;(scratch2, dest, 63);
3116         // Check that bits 31..63 of the original result were all equal.
3117         return branch64(NotEqual, scratch2, scratch1);
3118     }
3119 
3120     Jump branchMul64(ResultCondition cond, RegisterID src1, RegisterID src2, RegisterID dest)
3121     {
3122         return branchMul64(cond, src1, src2, getCachedDataTempRegisterIDAndInvalidate(), getCachedMemoryTempRegisterIDAndInvalidate(), dest);
3123     }
3124 
3125     Jump branchMul64(ResultCondition cond, RegisterID src, RegisterID dest)
3126     {
3127         return branchMul64(cond, dest, src, dest);
3128     }
3129 
3130     Jump branchNeg32(ResultCondition cond, RegisterID dest)
3131     {
3132         m_assembler.neg&lt;32, S&gt;(dest, dest);
3133         return Jump(makeBranch(cond));
3134     }
3135 
3136     Jump branchNeg64(ResultCondition cond, RegisterID srcDest)
3137     {
3138         m_assembler.neg&lt;64, S&gt;(srcDest, srcDest);
3139         return Jump(makeBranch(cond));
3140     }
3141 
3142     Jump branchSub32(ResultCondition cond, RegisterID dest)
3143     {
3144         m_assembler.neg&lt;32, S&gt;(dest, dest);
3145         return Jump(makeBranch(cond));
3146     }
3147 
3148     Jump branchSub32(ResultCondition cond, RegisterID op1, RegisterID op2, RegisterID dest)
3149     {
3150         m_assembler.sub&lt;32, S&gt;(dest, op1, op2);
3151         return Jump(makeBranch(cond));
3152     }
3153 
3154     Jump branchSub32(ResultCondition cond, RegisterID op1, TrustedImm32 imm, RegisterID dest)
3155     {
3156         if (isUInt12(imm.m_value)) {
3157             m_assembler.sub&lt;32, S&gt;(dest, op1, UInt12(imm.m_value));
3158             return Jump(makeBranch(cond));
3159         }
3160         if (isUInt12(-imm.m_value)) {
3161             m_assembler.add&lt;32, S&gt;(dest, op1, UInt12(-imm.m_value));
3162             return Jump(makeBranch(cond));
3163         }
3164 
3165         signExtend32ToPtr(imm, getCachedDataTempRegisterIDAndInvalidate());
3166         return branchSub32(cond, op1, dataTempRegister, dest);
3167     }
3168 
3169     Jump branchSub32(ResultCondition cond, RegisterID src, RegisterID dest)
3170     {
3171         return branchSub32(cond, dest, src, dest);
3172     }
3173 
3174     Jump branchSub32(ResultCondition cond, TrustedImm32 imm, RegisterID dest)
3175     {
3176         return branchSub32(cond, dest, imm, dest);
3177     }
3178 
3179     Jump branchSub64(ResultCondition cond, RegisterID op1, RegisterID op2, RegisterID dest)
3180     {
3181         m_assembler.sub&lt;64, S&gt;(dest, op1, op2);
3182         return Jump(makeBranch(cond));
3183     }
3184 
3185     Jump branchSub64(ResultCondition cond, RegisterID op1, TrustedImm32 imm, RegisterID dest)
3186     {
3187         if (isUInt12(imm.m_value)) {
3188             m_assembler.sub&lt;64, S&gt;(dest, op1, UInt12(imm.m_value));
3189             return Jump(makeBranch(cond));
3190         }
3191         if (isUInt12(-imm.m_value)) {
3192             m_assembler.add&lt;64, S&gt;(dest, op1, UInt12(-imm.m_value));
3193             return Jump(makeBranch(cond));
3194         }
3195 
3196         move(imm, getCachedDataTempRegisterIDAndInvalidate());
3197         return branchSub64(cond, op1, dataTempRegister, dest);
3198     }
3199 
3200     Jump branchSub64(ResultCondition cond, RegisterID src, RegisterID dest)
3201     {
3202         return branchSub64(cond, dest, src, dest);
3203     }
3204 
3205     Jump branchSub64(ResultCondition cond, TrustedImm32 imm, RegisterID dest)
3206     {
3207         return branchSub64(cond, dest, imm, dest);
3208     }
3209 
3210     Jump branchSub64(RelationalCondition cond, TrustedImm32 imm, RegisterID dest)
3211     {
3212         ASSERT(isUInt12(imm.m_value));
3213         m_assembler.sub&lt;64, S&gt;(dest, dest, UInt12(imm.m_value));
3214         return Jump(makeBranch(cond));
3215     }
3216 
3217 
3218     // Jumps, calls, returns
3219 
3220     ALWAYS_INLINE Call call(PtrTag)
3221     {
3222         AssemblerLabel pointerLabel = m_assembler.label();
3223         moveWithFixedWidth(TrustedImmPtr(nullptr), getCachedDataTempRegisterIDAndInvalidate());
3224         invalidateAllTempRegisters();
3225         m_assembler.blr(dataTempRegister);
3226         AssemblerLabel callLabel = m_assembler.label();
3227         ASSERT_UNUSED(pointerLabel, Assembler::getDifferenceBetweenLabels(callLabel, pointerLabel) == REPATCH_OFFSET_CALL_TO_POINTER);
3228         return Call(callLabel, Call::Linkable);
3229     }
3230 
3231     ALWAYS_INLINE Call call(RegisterID target, PtrTag)
3232     {
3233         invalidateAllTempRegisters();
3234         m_assembler.blr(target);
3235         return Call(m_assembler.label(), Call::None);
3236     }
3237 
3238     ALWAYS_INLINE Call call(Address address, PtrTag tag)
3239     {
3240         load64(address, getCachedDataTempRegisterIDAndInvalidate());
3241         return call(dataTempRegister, tag);
3242     }
3243 
3244     ALWAYS_INLINE Call call(RegisterID callTag) { return UNUSED_PARAM(callTag), call(NoPtrTag); }
3245     ALWAYS_INLINE Call call(RegisterID target, RegisterID callTag) { return UNUSED_PARAM(callTag), call(target, NoPtrTag); }
3246     ALWAYS_INLINE Call call(Address address, RegisterID callTag) { return UNUSED_PARAM(callTag), call(address, NoPtrTag); }
3247 
<a name="12" id="anc12"></a><span class="line-added">3248     ALWAYS_INLINE void callOperation(const FunctionPtr&lt;OperationPtrTag&gt; operation)</span>
<span class="line-added">3249     {</span>
<span class="line-added">3250         auto tmp = getCachedDataTempRegisterIDAndInvalidate();</span>
<span class="line-added">3251         move(TrustedImmPtr(operation.executableAddress()), tmp);</span>
<span class="line-added">3252         call(tmp, OperationPtrTag);</span>
<span class="line-added">3253     }</span>
<span class="line-added">3254 </span>
3255     ALWAYS_INLINE Jump jump()
3256     {
3257         AssemblerLabel label = m_assembler.label();
3258         m_assembler.b();
3259         return Jump(label, m_makeJumpPatchable ? Assembler::JumpNoConditionFixedSize : Assembler::JumpNoCondition);
3260     }
3261 
3262     void farJump(RegisterID target, PtrTag)
3263     {
3264         m_assembler.br(target);
3265     }
3266 
3267     void farJump(Address address, PtrTag)
3268     {
3269         load64(address, getCachedDataTempRegisterIDAndInvalidate());
3270         m_assembler.br(dataTempRegister);
3271     }
3272 
3273     void farJump(BaseIndex address, PtrTag)
3274     {
3275         load64(address, getCachedDataTempRegisterIDAndInvalidate());
3276         m_assembler.br(dataTempRegister);
3277     }
3278 
3279     void farJump(AbsoluteAddress address, PtrTag)
3280     {
3281         move(TrustedImmPtr(address.m_ptr), getCachedDataTempRegisterIDAndInvalidate());
3282         load64(Address(dataTempRegister), dataTempRegister);
3283         m_assembler.br(dataTempRegister);
3284     }
3285 
3286     ALWAYS_INLINE void farJump(RegisterID target, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(target, NoPtrTag); }
3287     ALWAYS_INLINE void farJump(Address address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }
3288     ALWAYS_INLINE void farJump(BaseIndex address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }
3289     ALWAYS_INLINE void farJump(AbsoluteAddress address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }
3290 
3291     ALWAYS_INLINE Call nearCall()
3292     {
<a name="13" id="anc13"></a><span class="line-added">3293         invalidateAllTempRegisters();</span>
3294         m_assembler.bl();
3295         return Call(m_assembler.label(), Call::LinkableNear);
3296     }
3297 
3298     ALWAYS_INLINE Call nearTailCall()
3299     {
3300         AssemblerLabel label = m_assembler.label();
3301         m_assembler.b();
3302         return Call(label, Call::LinkableNearTail);
3303     }
3304 
3305     ALWAYS_INLINE Call threadSafePatchableNearCall()
3306     {
<a name="14" id="anc14"></a><span class="line-added">3307         invalidateAllTempRegisters();</span>
3308         m_assembler.bl();
3309         return Call(m_assembler.label(), Call::LinkableNear);
3310     }
3311 
3312     ALWAYS_INLINE void ret()
3313     {
3314         m_assembler.ret();
3315     }
3316 
3317     // Comparisons operations
3318 
3319     void compare32(RelationalCondition cond, RegisterID left, RegisterID right, RegisterID dest)
3320     {
3321         m_assembler.cmp&lt;32&gt;(left, right);
3322         m_assembler.cset&lt;32&gt;(dest, ARM64Condition(cond));
3323     }
3324 
3325     void compare32(RelationalCondition cond, Address left, RegisterID right, RegisterID dest)
3326     {
3327         load32(left, getCachedDataTempRegisterIDAndInvalidate());
3328         m_assembler.cmp&lt;32&gt;(dataTempRegister, right);
3329         m_assembler.cset&lt;32&gt;(dest, ARM64Condition(cond));
3330     }
3331 
3332     void compare32(RelationalCondition cond, RegisterID left, TrustedImm32 right, RegisterID dest)
3333     {
3334         if (!right.m_value) {
3335             if (auto resultCondition = commuteCompareToZeroIntoTest(cond)) {
3336                 test32(*resultCondition, left, left, dest);
3337                 return;
3338             }
3339         }
3340 
3341         if (isUInt12(right.m_value))
3342             m_assembler.cmp&lt;32&gt;(left, UInt12(right.m_value));
3343         else if (isUInt12(-right.m_value))
3344             m_assembler.cmn&lt;32&gt;(left, UInt12(-right.m_value));
3345         else {
3346             move(right, getCachedDataTempRegisterIDAndInvalidate());
3347             m_assembler.cmp&lt;32&gt;(left, dataTempRegister);
3348         }
3349         m_assembler.cset&lt;32&gt;(dest, ARM64Condition(cond));
3350     }
3351 
3352     void compare64(RelationalCondition cond, RegisterID left, RegisterID right, RegisterID dest)
3353     {
3354         m_assembler.cmp&lt;64&gt;(left, right);
3355         m_assembler.cset&lt;32&gt;(dest, ARM64Condition(cond));
3356     }
3357 
3358     void compare64(RelationalCondition cond, RegisterID left, TrustedImm32 right, RegisterID dest)
3359     {
3360         if (!right.m_value) {
3361             if (auto resultCondition = commuteCompareToZeroIntoTest(cond)) {
3362                 test64(*resultCondition, left, left, dest);
3363                 return;
3364             }
3365         }
3366 
3367         signExtend32ToPtr(right, getCachedDataTempRegisterIDAndInvalidate());
3368         m_assembler.cmp&lt;64&gt;(left, dataTempRegister);
3369         m_assembler.cset&lt;32&gt;(dest, ARM64Condition(cond));
3370     }
3371 
3372     void compare8(RelationalCondition cond, Address left, TrustedImm32 right, RegisterID dest)
3373     {
3374         TrustedImm32 right8 = MacroAssemblerHelpers::mask8OnCondition(*this, cond, right);
3375         MacroAssemblerHelpers::load8OnCondition(*this, cond, left, getCachedMemoryTempRegisterIDAndInvalidate());
3376         move(right8, getCachedDataTempRegisterIDAndInvalidate());
3377         compare32(cond, memoryTempRegister, dataTempRegister, dest);
3378     }
3379 
3380     void test32(ResultCondition cond, RegisterID src, RegisterID mask, RegisterID dest)
3381     {
3382         m_assembler.tst&lt;32&gt;(src, mask);
3383         m_assembler.cset&lt;32&gt;(dest, ARM64Condition(cond));
3384     }
3385 
3386     void test32(ResultCondition cond, RegisterID src, TrustedImm32 mask, RegisterID dest)
3387     {
3388         test32(src, mask);
3389         m_assembler.cset&lt;32&gt;(dest, ARM64Condition(cond));
3390     }
3391 
3392     void test32(ResultCondition cond, Address address, TrustedImm32 mask, RegisterID dest)
3393     {
3394         load32(address, getCachedMemoryTempRegisterIDAndInvalidate());
3395         test32(cond, memoryTempRegister, mask, dest);
3396     }
3397 
3398     void test8(ResultCondition cond, Address address, TrustedImm32 mask, RegisterID dest)
3399     {
3400         TrustedImm32 mask8 = MacroAssemblerHelpers::mask8OnCondition(*this, cond, mask);
3401         MacroAssemblerHelpers::load8OnCondition(*this, cond, address, getCachedMemoryTempRegisterIDAndInvalidate());
3402         test32(cond, memoryTempRegister, mask8, dest);
3403     }
3404 
3405     void test64(ResultCondition cond, RegisterID op1, RegisterID op2, RegisterID dest)
3406     {
3407         m_assembler.tst&lt;64&gt;(op1, op2);
3408         m_assembler.cset&lt;32&gt;(dest, ARM64Condition(cond));
3409     }
3410 
3411     void test64(ResultCondition cond, RegisterID src, TrustedImm32 mask, RegisterID dest)
3412     {
3413         if (mask.m_value == -1)
3414             m_assembler.tst&lt;64&gt;(src, src);
3415         else {
3416             signExtend32ToPtr(mask, getCachedDataTempRegisterIDAndInvalidate());
3417             m_assembler.tst&lt;64&gt;(src, dataTempRegister);
3418         }
3419         m_assembler.cset&lt;32&gt;(dest, ARM64Condition(cond));
3420     }
3421 
3422     void setCarry(RegisterID dest)
3423     {
3424         m_assembler.cset&lt;32&gt;(dest, Assembler::ConditionCS);
3425     }
3426 
3427     // Patchable operations
3428 
3429     ALWAYS_INLINE DataLabel32 moveWithPatch(TrustedImm32 imm, RegisterID dest)
3430     {
3431         DataLabel32 label(this);
3432         moveWithFixedWidth(imm, dest);
3433         return label;
3434     }
3435 
3436     ALWAYS_INLINE DataLabelPtr moveWithPatch(TrustedImmPtr imm, RegisterID dest)
3437     {
3438         DataLabelPtr label(this);
3439         moveWithFixedWidth(imm, dest);
3440         return label;
3441     }
3442 
3443     ALWAYS_INLINE Jump branchPtrWithPatch(RelationalCondition cond, RegisterID left, DataLabelPtr&amp; dataLabel, TrustedImmPtr initialRightValue = TrustedImmPtr(nullptr))
3444     {
3445         dataLabel = DataLabelPtr(this);
3446         moveWithPatch(initialRightValue, getCachedDataTempRegisterIDAndInvalidate());
3447         return branch64(cond, left, dataTempRegister);
3448     }
3449 
3450     ALWAYS_INLINE Jump branchPtrWithPatch(RelationalCondition cond, Address left, DataLabelPtr&amp; dataLabel, TrustedImmPtr initialRightValue = TrustedImmPtr(nullptr))
3451     {
3452         dataLabel = DataLabelPtr(this);
3453         moveWithPatch(initialRightValue, getCachedDataTempRegisterIDAndInvalidate());
3454         return branch64(cond, left, dataTempRegister);
3455     }
3456 
3457     ALWAYS_INLINE Jump branch32WithPatch(RelationalCondition cond, Address left, DataLabel32&amp; dataLabel, TrustedImm32 initialRightValue = TrustedImm32(0))
3458     {
3459         dataLabel = DataLabel32(this);
3460         moveWithPatch(initialRightValue, getCachedDataTempRegisterIDAndInvalidate());
3461         return branch32(cond, left, dataTempRegister);
3462     }
3463 
3464     PatchableJump patchableBranchPtr(RelationalCondition cond, Address left, TrustedImmPtr right)
3465     {
3466         m_makeJumpPatchable = true;
3467         Jump result = branch64(cond, left, TrustedImm64(right));
3468         m_makeJumpPatchable = false;
3469         return PatchableJump(result);
3470     }
3471 
3472     PatchableJump patchableBranch8(RelationalCondition cond, Address left, TrustedImm32 imm)
3473     {
3474         m_makeJumpPatchable = true;
3475         Jump result = branch8(cond, left, imm);
3476         m_makeJumpPatchable = false;
3477         return PatchableJump(result);
3478     }
3479 
3480     PatchableJump patchableBranchTest32(ResultCondition cond, RegisterID reg, TrustedImm32 mask = TrustedImm32(-1))
3481     {
3482         m_makeJumpPatchable = true;
3483         Jump result = branchTest32(cond, reg, mask);
3484         m_makeJumpPatchable = false;
3485         return PatchableJump(result);
3486     }
3487 
3488     PatchableJump patchableBranch32(RelationalCondition cond, RegisterID reg, TrustedImm32 imm)
3489     {
3490         m_makeJumpPatchable = true;
3491         Jump result = branch32(cond, reg, imm);
3492         m_makeJumpPatchable = false;
3493         return PatchableJump(result);
3494     }
3495 
3496     PatchableJump patchableBranch32(RelationalCondition cond, Address left, TrustedImm32 imm)
3497     {
3498         m_makeJumpPatchable = true;
3499         Jump result = branch32(cond, left, imm);
3500         m_makeJumpPatchable = false;
3501         return PatchableJump(result);
3502     }
3503 
3504     PatchableJump patchableBranch64(RelationalCondition cond, RegisterID reg, TrustedImm64 imm)
3505     {
3506         m_makeJumpPatchable = true;
3507         Jump result = branch64(cond, reg, imm);
3508         m_makeJumpPatchable = false;
3509         return PatchableJump(result);
3510     }
3511 
3512     PatchableJump patchableBranch64(RelationalCondition cond, RegisterID left, RegisterID right)
3513     {
3514         m_makeJumpPatchable = true;
3515         Jump result = branch64(cond, left, right);
3516         m_makeJumpPatchable = false;
3517         return PatchableJump(result);
3518     }
3519 
3520     PatchableJump patchableBranchPtrWithPatch(RelationalCondition cond, Address left, DataLabelPtr&amp; dataLabel, TrustedImmPtr initialRightValue = TrustedImmPtr(nullptr))
3521     {
3522         m_makeJumpPatchable = true;
3523         Jump result = branchPtrWithPatch(cond, left, dataLabel, initialRightValue);
3524         m_makeJumpPatchable = false;
3525         return PatchableJump(result);
3526     }
3527 
3528     PatchableJump patchableBranch32WithPatch(RelationalCondition cond, Address left, DataLabel32&amp; dataLabel, TrustedImm32 initialRightValue = TrustedImm32(0))
3529     {
3530         m_makeJumpPatchable = true;
3531         Jump result = branch32WithPatch(cond, left, dataLabel, initialRightValue);
3532         m_makeJumpPatchable = false;
3533         return PatchableJump(result);
3534     }
3535 
3536     PatchableJump patchableJump()
3537     {
3538         m_makeJumpPatchable = true;
3539         Jump result = jump();
3540         m_makeJumpPatchable = false;
3541         return PatchableJump(result);
3542     }
3543 
3544     ALWAYS_INLINE DataLabelPtr storePtrWithPatch(TrustedImmPtr initialValue, ImplicitAddress address)
3545     {
3546         DataLabelPtr label(this);
3547         moveWithFixedWidth(initialValue, getCachedDataTempRegisterIDAndInvalidate());
3548         store64(dataTempRegister, address);
3549         return label;
3550     }
3551 
3552     ALWAYS_INLINE DataLabelPtr storePtrWithPatch(ImplicitAddress address)
3553     {
3554         return storePtrWithPatch(TrustedImmPtr(nullptr), address);
3555     }
3556 
3557     static void reemitInitialMoveWithPatch(void* address, void* value)
3558     {
3559         Assembler::setPointer(static_cast&lt;int*&gt;(address), value, dataTempRegister, true);
3560     }
3561 
3562     // Miscellaneous operations:
3563 
3564     void breakpoint(uint16_t imm = 0)
3565     {
3566         m_assembler.brk(imm);
3567     }
3568 
3569     static bool isBreakpoint(void* address) { return Assembler::isBrk(address); }
3570 
3571     void nop()
3572     {
3573         m_assembler.nop();
3574     }
3575 
3576     // We take memoryFence to mean acqrel. This has acqrel semantics on ARM64.
3577     void memoryFence()
3578     {
3579         m_assembler.dmbISH();
3580     }
3581 
3582     // We take this to mean that it prevents motion of normal stores. That&#39;s a store fence on ARM64 (hence the &quot;ST&quot;).
3583     void storeFence()
3584     {
3585         m_assembler.dmbISHST();
3586     }
3587 
3588     // We take this to mean that it prevents motion of normal loads. Ideally we&#39;d have expressed this
3589     // using dependencies or half fences, but there are cases where this is as good as it gets. The only
3590     // way to get a standalone load fence instruction on ARM is to use the ISH fence, which is just like
3591     // the memoryFence().
3592     void loadFence()
3593     {
3594         m_assembler.dmbISH();
3595     }
3596 
3597     void loadAcq8SignedExtendTo32(ImplicitAddress address, RegisterID dest)
3598     {
3599         m_assembler.ldar&lt;8&gt;(dest, extractSimpleAddress(address));
3600     }
3601 
3602     void loadAcq8(ImplicitAddress address, RegisterID dest)
3603     {
3604         loadAcq8SignedExtendTo32(address, dest);
3605         and32(TrustedImm32(0xff), dest);
3606     }
3607 
3608     void storeRel8(RegisterID src, ImplicitAddress address)
3609     {
3610         m_assembler.stlr&lt;8&gt;(src, extractSimpleAddress(address));
3611     }
3612 
3613     void loadAcq16SignedExtendTo32(ImplicitAddress address, RegisterID dest)
3614     {
3615         m_assembler.ldar&lt;16&gt;(dest, extractSimpleAddress(address));
3616     }
3617 
3618     void loadAcq16(ImplicitAddress address, RegisterID dest)
3619     {
3620         loadAcq16SignedExtendTo32(address, dest);
3621         and32(TrustedImm32(0xffff), dest);
3622     }
3623 
3624     void storeRel16(RegisterID src, ImplicitAddress address)
3625     {
3626         m_assembler.stlr&lt;16&gt;(src, extractSimpleAddress(address));
3627     }
3628 
3629     void loadAcq32(ImplicitAddress address, RegisterID dest)
3630     {
3631         m_assembler.ldar&lt;32&gt;(dest, extractSimpleAddress(address));
3632     }
3633 
3634     void loadAcq64(ImplicitAddress address, RegisterID dest)
3635     {
3636         m_assembler.ldar&lt;64&gt;(dest, extractSimpleAddress(address));
3637     }
3638 
3639     void storeRel32(RegisterID dest, ImplicitAddress address)
3640     {
3641         m_assembler.stlr&lt;32&gt;(dest, extractSimpleAddress(address));
3642     }
3643 
3644     void storeRel64(RegisterID dest, ImplicitAddress address)
3645     {
3646         m_assembler.stlr&lt;64&gt;(dest, extractSimpleAddress(address));
3647     }
3648 
3649     void loadLink8(ImplicitAddress address, RegisterID dest)
3650     {
3651         m_assembler.ldxr&lt;8&gt;(dest, extractSimpleAddress(address));
3652     }
3653 
3654     void loadLinkAcq8(ImplicitAddress address, RegisterID dest)
3655     {
3656         m_assembler.ldaxr&lt;8&gt;(dest, extractSimpleAddress(address));
3657     }
3658 
3659     void storeCond8(RegisterID src, ImplicitAddress address, RegisterID result)
3660     {
3661         m_assembler.stxr&lt;8&gt;(result, src, extractSimpleAddress(address));
3662     }
3663 
3664     void storeCondRel8(RegisterID src, ImplicitAddress address, RegisterID result)
3665     {
3666         m_assembler.stlxr&lt;8&gt;(result, src, extractSimpleAddress(address));
3667     }
3668 
3669     void loadLink16(ImplicitAddress address, RegisterID dest)
3670     {
3671         m_assembler.ldxr&lt;16&gt;(dest, extractSimpleAddress(address));
3672     }
3673 
3674     void loadLinkAcq16(ImplicitAddress address, RegisterID dest)
3675     {
3676         m_assembler.ldaxr&lt;16&gt;(dest, extractSimpleAddress(address));
3677     }
3678 
3679     void storeCond16(RegisterID src, ImplicitAddress address, RegisterID result)
3680     {
3681         m_assembler.stxr&lt;16&gt;(result, src, extractSimpleAddress(address));
3682     }
3683 
3684     void storeCondRel16(RegisterID src, ImplicitAddress address, RegisterID result)
3685     {
3686         m_assembler.stlxr&lt;16&gt;(result, src, extractSimpleAddress(address));
3687     }
3688 
3689     void loadLink32(ImplicitAddress address, RegisterID dest)
3690     {
3691         m_assembler.ldxr&lt;32&gt;(dest, extractSimpleAddress(address));
3692     }
3693 
3694     void loadLinkAcq32(ImplicitAddress address, RegisterID dest)
3695     {
3696         m_assembler.ldaxr&lt;32&gt;(dest, extractSimpleAddress(address));
3697     }
3698 
3699     void storeCond32(RegisterID src, ImplicitAddress address, RegisterID result)
3700     {
3701         m_assembler.stxr&lt;32&gt;(result, src, extractSimpleAddress(address));
3702     }
3703 
3704     void storeCondRel32(RegisterID src, ImplicitAddress address, RegisterID result)
3705     {
3706         m_assembler.stlxr&lt;32&gt;(result, src, extractSimpleAddress(address));
3707     }
3708 
3709     void loadLink64(ImplicitAddress address, RegisterID dest)
3710     {
3711         m_assembler.ldxr&lt;64&gt;(dest, extractSimpleAddress(address));
3712     }
3713 
3714     void loadLinkAcq64(ImplicitAddress address, RegisterID dest)
3715     {
3716         m_assembler.ldaxr&lt;64&gt;(dest, extractSimpleAddress(address));
3717     }
3718 
3719     void storeCond64(RegisterID src, ImplicitAddress address, RegisterID result)
3720     {
3721         m_assembler.stxr&lt;64&gt;(result, src, extractSimpleAddress(address));
3722     }
3723 
3724     void storeCondRel64(RegisterID src, ImplicitAddress address, RegisterID result)
3725     {
3726         m_assembler.stlxr&lt;64&gt;(result, src, extractSimpleAddress(address));
3727     }
3728 
3729     template&lt;typename AddressType&gt;
3730     void atomicStrongCAS8(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, AddressType address, RegisterID result)
3731     {
3732         atomicStrongCAS&lt;8&gt;(cond, expectedAndResult, newValue, address, result);
3733     }
3734 
3735     template&lt;typename AddressType&gt;
3736     void atomicStrongCAS16(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, AddressType address, RegisterID result)
3737     {
3738         atomicStrongCAS&lt;16&gt;(cond, expectedAndResult, newValue, address, result);
3739     }
3740 
3741     template&lt;typename AddressType&gt;
3742     void atomicStrongCAS32(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, AddressType address, RegisterID result)
3743     {
3744         atomicStrongCAS&lt;32&gt;(cond, expectedAndResult, newValue, address, result);
3745     }
3746 
3747     template&lt;typename AddressType&gt;
3748     void atomicStrongCAS64(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, AddressType address, RegisterID result)
3749     {
3750         atomicStrongCAS&lt;64&gt;(cond, expectedAndResult, newValue, address, result);
3751     }
3752 
3753     template&lt;typename AddressType&gt;
3754     void atomicRelaxedStrongCAS8(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, AddressType address, RegisterID result)
3755     {
3756         atomicRelaxedStrongCAS&lt;8&gt;(cond, expectedAndResult, newValue, address, result);
3757     }
3758 
3759     template&lt;typename AddressType&gt;
3760     void atomicRelaxedStrongCAS16(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, AddressType address, RegisterID result)
3761     {
3762         atomicRelaxedStrongCAS&lt;16&gt;(cond, expectedAndResult, newValue, address, result);
3763     }
3764 
3765     template&lt;typename AddressType&gt;
3766     void atomicRelaxedStrongCAS32(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, AddressType address, RegisterID result)
3767     {
3768         atomicRelaxedStrongCAS&lt;32&gt;(cond, expectedAndResult, newValue, address, result);
3769     }
3770 
3771     template&lt;typename AddressType&gt;
3772     void atomicRelaxedStrongCAS64(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, AddressType address, RegisterID result)
3773     {
3774         atomicRelaxedStrongCAS&lt;64&gt;(cond, expectedAndResult, newValue, address, result);
3775     }
3776 
3777     template&lt;typename AddressType&gt;
3778     JumpList branchAtomicWeakCAS8(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, AddressType address)
3779     {
3780         return branchAtomicWeakCAS&lt;8&gt;(cond, expectedAndClobbered, newValue, address);
3781     }
3782 
3783     template&lt;typename AddressType&gt;
3784     JumpList branchAtomicWeakCAS16(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, AddressType address)
3785     {
3786         return branchAtomicWeakCAS&lt;16&gt;(cond, expectedAndClobbered, newValue, address);
3787     }
3788 
3789     template&lt;typename AddressType&gt;
3790     JumpList branchAtomicWeakCAS32(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, AddressType address)
3791     {
3792         return branchAtomicWeakCAS&lt;32&gt;(cond, expectedAndClobbered, newValue, address);
3793     }
3794 
3795     template&lt;typename AddressType&gt;
3796     JumpList branchAtomicWeakCAS64(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, AddressType address)
3797     {
3798         return branchAtomicWeakCAS&lt;64&gt;(cond, expectedAndClobbered, newValue, address);
3799     }
3800 
3801     template&lt;typename AddressType&gt;
3802     JumpList branchAtomicRelaxedWeakCAS8(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, AddressType address)
3803     {
3804         return branchAtomicRelaxedWeakCAS&lt;8&gt;(cond, expectedAndClobbered, newValue, address);
3805     }
3806 
3807     template&lt;typename AddressType&gt;
3808     JumpList branchAtomicRelaxedWeakCAS16(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, AddressType address)
3809     {
3810         return branchAtomicRelaxedWeakCAS&lt;16&gt;(cond, expectedAndClobbered, newValue, address);
3811     }
3812 
3813     template&lt;typename AddressType&gt;
3814     JumpList branchAtomicRelaxedWeakCAS32(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, AddressType address)
3815     {
3816         return branchAtomicRelaxedWeakCAS&lt;32&gt;(cond, expectedAndClobbered, newValue, address);
3817     }
3818 
3819     template&lt;typename AddressType&gt;
3820     JumpList branchAtomicRelaxedWeakCAS64(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, AddressType address)
3821     {
3822         return branchAtomicRelaxedWeakCAS&lt;64&gt;(cond, expectedAndClobbered, newValue, address);
3823     }
3824 
3825     void depend32(RegisterID src, RegisterID dest)
3826     {
3827         m_assembler.eor&lt;32&gt;(dest, src, src);
3828     }
3829 
3830     void depend64(RegisterID src, RegisterID dest)
3831     {
3832         m_assembler.eor&lt;64&gt;(dest, src, src);
3833     }
3834 
3835     ALWAYS_INLINE static bool supportsDoubleToInt32ConversionUsingJavaScriptSemantics()
3836     {
3837 #if HAVE(FJCVTZS_INSTRUCTION)
3838         return true;
3839 #else
3840         if (s_jscvtCheckState == CPUIDCheckState::NotChecked)
3841             collectCPUFeatures();
3842 
3843         return s_jscvtCheckState == CPUIDCheckState::Set;
3844 #endif
3845     }
3846 
3847     void convertDoubleToInt32UsingJavaScriptSemantics(FPRegisterID src, RegisterID dest)
3848     {
3849         m_assembler.fjcvtzs(dest, src); // This zero extends.
3850     }
3851 
3852 #if ENABLE(FAST_TLS_JIT)
3853     // This will use scratch registers if the offset is not legal.
3854 
3855     void loadFromTLS32(uint32_t offset, RegisterID dst)
3856     {
3857         m_assembler.mrs_TPIDRRO_EL0(dst);
3858         and64(TrustedImm32(~7), dst);
3859         load32(Address(dst, offset), dst);
3860     }
3861 
3862     void loadFromTLS64(uint32_t offset, RegisterID dst)
3863     {
3864         m_assembler.mrs_TPIDRRO_EL0(dst);
3865         and64(TrustedImm32(~7), dst);
3866         load64(Address(dst, offset), dst);
3867     }
3868 
3869     static bool loadFromTLSPtrNeedsMacroScratchRegister()
3870     {
3871         return true;
3872     }
3873 
3874     void storeToTLS32(RegisterID src, uint32_t offset)
3875     {
3876         RegisterID tmp = getCachedDataTempRegisterIDAndInvalidate();
3877         ASSERT(src != tmp);
3878         m_assembler.mrs_TPIDRRO_EL0(tmp);
3879         and64(TrustedImm32(~7), tmp);
3880         store32(src, Address(tmp, offset));
3881     }
3882 
3883     void storeToTLS64(RegisterID src, uint32_t offset)
3884     {
3885         RegisterID tmp = getCachedDataTempRegisterIDAndInvalidate();
3886         ASSERT(src != tmp);
3887         m_assembler.mrs_TPIDRRO_EL0(tmp);
3888         and64(TrustedImm32(~7), tmp);
3889         store64(src, Address(tmp, offset));
3890     }
3891 
3892     static bool storeToTLSPtrNeedsMacroScratchRegister()
3893     {
3894         return true;
3895     }
3896 #endif // ENABLE(FAST_TLS_JIT)
3897 
3898     // Misc helper functions.
3899 
3900     // Invert a relational condition, e.g. == becomes !=, &lt; becomes &gt;=, etc.
3901     static RelationalCondition invert(RelationalCondition cond)
3902     {
3903         return static_cast&lt;RelationalCondition&gt;(Assembler::invert(static_cast&lt;Assembler::Condition&gt;(cond)));
3904     }
3905 
3906     static Optional&lt;ResultCondition&gt; commuteCompareToZeroIntoTest(RelationalCondition cond)
3907     {
3908         switch (cond) {
3909         case Equal:
3910             return Zero;
3911         case NotEqual:
3912             return NonZero;
3913         case LessThan:
3914             return Signed;
3915         case GreaterThanOrEqual:
3916             return PositiveOrZero;
3917             break;
3918         default:
3919             return WTF::nullopt;
3920         }
3921     }
3922 
3923     template&lt;PtrTag resultTag, PtrTag locationTag&gt;
3924     static FunctionPtr&lt;resultTag&gt; readCallTarget(CodeLocationCall&lt;locationTag&gt; call)
3925     {
3926         return FunctionPtr&lt;resultTag&gt;(MacroAssemblerCodePtr&lt;resultTag&gt;(Assembler::readCallTarget(call.dataLocation())));
3927     }
3928 
3929     template&lt;PtrTag tag&gt;
3930     static void replaceWithVMHalt(CodeLocationLabel&lt;tag&gt; instructionStart)
3931     {
3932         Assembler::replaceWithVMHalt(instructionStart.dataLocation());
3933     }
3934 
3935     template&lt;PtrTag startTag, PtrTag destTag&gt;
3936     static void replaceWithJump(CodeLocationLabel&lt;startTag&gt; instructionStart, CodeLocationLabel&lt;destTag&gt; destination)
3937     {
3938         Assembler::replaceWithJump(instructionStart.dataLocation(), destination.dataLocation());
3939     }
3940 
3941     static ptrdiff_t maxJumpReplacementSize()
3942     {
3943         return Assembler::maxJumpReplacementSize();
3944     }
3945 
3946     static ptrdiff_t patchableJumpSize()
3947     {
3948         return Assembler::patchableJumpSize();
3949     }
3950 
3951     RegisterID scratchRegisterForBlinding()
3952     {
3953         // We *do not* have a scratch register for blinding.
3954         RELEASE_ASSERT_NOT_REACHED();
3955         return getCachedDataTempRegisterIDAndInvalidate();
3956     }
3957 
3958     static bool canJumpReplacePatchableBranchPtrWithPatch() { return false; }
3959     static bool canJumpReplacePatchableBranch32WithPatch() { return false; }
3960 
3961     template&lt;PtrTag tag&gt;
3962     static CodeLocationLabel&lt;tag&gt; startOfBranchPtrWithPatchOnRegister(CodeLocationDataLabelPtr&lt;tag&gt; label)
3963     {
3964         return label.labelAtOffset(0);
3965     }
3966 
3967     template&lt;PtrTag tag&gt;
3968     static CodeLocationLabel&lt;tag&gt; startOfPatchableBranchPtrWithPatchOnAddress(CodeLocationDataLabelPtr&lt;tag&gt;)
3969     {
3970         UNREACHABLE_FOR_PLATFORM();
3971         return CodeLocationLabel&lt;tag&gt;();
3972     }
3973 
3974     template&lt;PtrTag tag&gt;
3975     static CodeLocationLabel&lt;tag&gt; startOfPatchableBranch32WithPatchOnAddress(CodeLocationDataLabel32&lt;tag&gt;)
3976     {
3977         UNREACHABLE_FOR_PLATFORM();
3978         return CodeLocationLabel&lt;tag&gt;();
3979     }
3980 
3981     template&lt;PtrTag tag&gt;
3982     static void revertJumpReplacementToBranchPtrWithPatch(CodeLocationLabel&lt;tag&gt; instructionStart, RegisterID, void* initialValue)
3983     {
3984         reemitInitialMoveWithPatch(instructionStart.dataLocation(), initialValue);
3985     }
3986 
3987     template&lt;PtrTag tag&gt;
3988     static void revertJumpReplacementToPatchableBranchPtrWithPatch(CodeLocationLabel&lt;tag&gt;, Address, void*)
3989     {
3990         UNREACHABLE_FOR_PLATFORM();
3991     }
3992 
3993     template&lt;PtrTag tag&gt;
3994     static void revertJumpReplacementToPatchableBranch32WithPatch(CodeLocationLabel&lt;tag&gt;, Address, int32_t)
3995     {
3996         UNREACHABLE_FOR_PLATFORM();
3997     }
3998 
3999     template&lt;PtrTag callTag, PtrTag destTag&gt;
4000     static void repatchCall(CodeLocationCall&lt;callTag&gt; call, CodeLocationLabel&lt;destTag&gt; destination)
4001     {
4002         Assembler::repatchPointer(call.dataLabelPtrAtOffset(REPATCH_OFFSET_CALL_TO_POINTER).dataLocation(), destination.executableAddress());
4003     }
4004 
4005     template&lt;PtrTag callTag, PtrTag destTag&gt;
4006     static void repatchCall(CodeLocationCall&lt;callTag&gt; call, FunctionPtr&lt;destTag&gt; destination)
4007     {
4008         Assembler::repatchPointer(call.dataLabelPtrAtOffset(REPATCH_OFFSET_CALL_TO_POINTER).dataLocation(), destination.executableAddress());
4009     }
4010 
4011 protected:
4012     ALWAYS_INLINE Jump makeBranch(Assembler::Condition cond)
4013     {
4014         m_assembler.b_cond(cond);
4015         AssemblerLabel label = m_assembler.label();
4016         m_assembler.nop();
4017         return Jump(label, m_makeJumpPatchable ? Assembler::JumpConditionFixedSize : Assembler::JumpCondition, cond);
4018     }
4019     ALWAYS_INLINE Jump makeBranch(RelationalCondition cond) { return makeBranch(ARM64Condition(cond)); }
4020     ALWAYS_INLINE Jump makeBranch(ResultCondition cond) { return makeBranch(ARM64Condition(cond)); }
4021     ALWAYS_INLINE Jump makeBranch(DoubleCondition cond) { return makeBranch(ARM64Condition(cond)); }
4022 
4023     template &lt;int dataSize&gt;
4024     ALWAYS_INLINE Jump makeCompareAndBranch(ZeroCondition cond, RegisterID reg)
4025     {
4026         if (cond == IsZero)
4027             m_assembler.cbz&lt;dataSize&gt;(reg);
4028         else
4029             m_assembler.cbnz&lt;dataSize&gt;(reg);
4030         AssemblerLabel label = m_assembler.label();
4031         m_assembler.nop();
4032         return Jump(label, m_makeJumpPatchable ? Assembler::JumpCompareAndBranchFixedSize : Assembler::JumpCompareAndBranch, static_cast&lt;Assembler::Condition&gt;(cond), dataSize == 64, reg);
4033     }
4034 
4035     ALWAYS_INLINE Jump makeTestBitAndBranch(RegisterID reg, unsigned bit, ZeroCondition cond)
4036     {
4037         ASSERT(bit &lt; 64);
4038         bit &amp;= 0x3f;
4039         if (cond == IsZero)
4040             m_assembler.tbz(reg, bit);
4041         else
4042             m_assembler.tbnz(reg, bit);
4043         AssemblerLabel label = m_assembler.label();
4044         m_assembler.nop();
4045         return Jump(label, m_makeJumpPatchable ? Assembler::JumpTestBitFixedSize : Assembler::JumpTestBit, static_cast&lt;Assembler::Condition&gt;(cond), bit, reg);
4046     }
4047 
4048     Assembler::Condition ARM64Condition(RelationalCondition cond)
4049     {
4050         return static_cast&lt;Assembler::Condition&gt;(cond);
4051     }
4052 
4053     Assembler::Condition ARM64Condition(ResultCondition cond)
4054     {
4055         return static_cast&lt;Assembler::Condition&gt;(cond);
4056     }
4057 
4058     Assembler::Condition ARM64Condition(DoubleCondition cond)
4059     {
4060         return static_cast&lt;Assembler::Condition&gt;(cond);
4061     }
4062 
4063 protected:
4064     ALWAYS_INLINE RegisterID getCachedDataTempRegisterIDAndInvalidate()
4065     {
4066         RELEASE_ASSERT(m_allowScratchRegister);
4067         return dataMemoryTempRegister().registerIDInvalidate();
4068     }
4069     ALWAYS_INLINE RegisterID getCachedMemoryTempRegisterIDAndInvalidate()
4070     {
4071         RELEASE_ASSERT(m_allowScratchRegister);
4072         return cachedMemoryTempRegister().registerIDInvalidate();
4073     }
4074     ALWAYS_INLINE CachedTempRegister&amp; dataMemoryTempRegister()
4075     {
4076         RELEASE_ASSERT(m_allowScratchRegister);
4077         return m_dataMemoryTempRegister;
4078     }
4079     ALWAYS_INLINE CachedTempRegister&amp; cachedMemoryTempRegister()
4080     {
4081         RELEASE_ASSERT(m_allowScratchRegister);
4082         return m_cachedMemoryTempRegister;
4083     }
4084 
4085     template&lt;typename ImmediateType, typename rawType&gt;
4086     void moveInternal(ImmediateType imm, RegisterID dest)
4087     {
4088         const int dataSize = sizeof(rawType) * 8;
4089         const int numberHalfWords = dataSize / 16;
4090         rawType value = bitwise_cast&lt;rawType&gt;(imm.m_value);
4091         uint16_t halfword[numberHalfWords];
4092 
4093         // Handle 0 and ~0 here to simplify code below
4094         if (!value) {
4095             m_assembler.movz&lt;dataSize&gt;(dest, 0);
4096             return;
4097         }
4098         if (!~value) {
4099             m_assembler.movn&lt;dataSize&gt;(dest, 0);
4100             return;
4101         }
4102 
4103         LogicalImmediate logicalImm = dataSize == 64 ? LogicalImmediate::create64(static_cast&lt;uint64_t&gt;(value)) : LogicalImmediate::create32(static_cast&lt;uint32_t&gt;(value));
4104 
4105         if (logicalImm.isValid()) {
4106             m_assembler.movi&lt;dataSize&gt;(dest, logicalImm);
4107             return;
4108         }
4109 
4110         // Figure out how many halfwords are 0 or FFFF, then choose movz or movn accordingly.
4111         int zeroOrNegateVote = 0;
4112         for (int i = 0; i &lt; numberHalfWords; ++i) {
4113             halfword[i] = getHalfword(value, i);
4114             if (!halfword[i])
4115                 zeroOrNegateVote++;
4116             else if (halfword[i] == 0xffff)
4117                 zeroOrNegateVote--;
4118         }
4119 
4120         bool needToClearRegister = true;
4121         if (zeroOrNegateVote &gt;= 0) {
4122             for (int i = 0; i &lt; numberHalfWords; i++) {
4123                 if (halfword[i]) {
4124                     if (needToClearRegister) {
4125                         m_assembler.movz&lt;dataSize&gt;(dest, halfword[i], 16*i);
4126                         needToClearRegister = false;
4127                     } else
4128                         m_assembler.movk&lt;dataSize&gt;(dest, halfword[i], 16*i);
4129                 }
4130             }
4131         } else {
4132             for (int i = 0; i &lt; numberHalfWords; i++) {
4133                 if (halfword[i] != 0xffff) {
4134                     if (needToClearRegister) {
4135                         m_assembler.movn&lt;dataSize&gt;(dest, ~halfword[i], 16*i);
4136                         needToClearRegister = false;
4137                     } else
4138                         m_assembler.movk&lt;dataSize&gt;(dest, halfword[i], 16*i);
4139                 }
4140             }
4141         }
4142     }
4143 
4144     template&lt;int datasize&gt;
4145     ALWAYS_INLINE void loadUnsignedImmediate(RegisterID rt, RegisterID rn, unsigned pimm)
4146     {
4147         m_assembler.ldr&lt;datasize&gt;(rt, rn, pimm);
4148     }
4149 
4150     template&lt;int datasize&gt;
4151     ALWAYS_INLINE void loadUnscaledImmediate(RegisterID rt, RegisterID rn, int simm)
4152     {
4153         m_assembler.ldur&lt;datasize&gt;(rt, rn, simm);
4154     }
4155 
4156     template&lt;int datasize&gt;
4157     ALWAYS_INLINE void loadSignedAddressedByUnsignedImmediate(RegisterID rt, RegisterID rn, unsigned pimm)
4158     {
4159         loadUnsignedImmediate&lt;datasize&gt;(rt, rn, pimm);
4160     }
4161 
4162     template&lt;int datasize&gt;
4163     ALWAYS_INLINE void loadSignedAddressedByUnscaledImmediate(RegisterID rt, RegisterID rn, int simm)
4164     {
4165         loadUnscaledImmediate&lt;datasize&gt;(rt, rn, simm);
4166     }
4167 
4168     template&lt;int datasize&gt;
4169     ALWAYS_INLINE void storeUnsignedImmediate(RegisterID rt, RegisterID rn, unsigned pimm)
4170     {
4171         m_assembler.str&lt;datasize&gt;(rt, rn, pimm);
4172     }
4173 
4174     template&lt;int datasize&gt;
4175     ALWAYS_INLINE void storeUnscaledImmediate(RegisterID rt, RegisterID rn, int simm)
4176     {
4177         m_assembler.stur&lt;datasize&gt;(rt, rn, simm);
4178     }
4179 
4180     void moveWithFixedWidth(TrustedImm32 imm, RegisterID dest)
4181     {
4182         int32_t value = imm.m_value;
4183         m_assembler.movz&lt;32&gt;(dest, getHalfword(value, 0));
4184         m_assembler.movk&lt;32&gt;(dest, getHalfword(value, 1), 16);
4185     }
4186 
4187     void moveWithFixedWidth(TrustedImmPtr imm, RegisterID dest)
4188     {
4189         intptr_t value = reinterpret_cast&lt;intptr_t&gt;(imm.m_value);
4190         m_assembler.movz&lt;64&gt;(dest, getHalfword(value, 0));
4191         m_assembler.movk&lt;64&gt;(dest, getHalfword(value, 1), 16);
4192         m_assembler.movk&lt;64&gt;(dest, getHalfword(value, 2), 32);
4193         if (Assembler::MAX_POINTER_BITS &gt; 48)
4194             m_assembler.movk&lt;64&gt;(dest, getHalfword(value, 3), 48);
4195     }
4196 
4197     void signExtend32ToPtrWithFixedWidth(int32_t value, RegisterID dest)
4198     {
4199         if (value &gt;= 0) {
4200             m_assembler.movz&lt;32&gt;(dest, getHalfword(value, 0));
4201             m_assembler.movk&lt;32&gt;(dest, getHalfword(value, 1), 16);
4202         } else {
4203             m_assembler.movn&lt;32&gt;(dest, ~getHalfword(value, 0));
4204             m_assembler.movk&lt;32&gt;(dest, getHalfword(value, 1), 16);
4205         }
4206     }
4207 
4208     template&lt;int datasize&gt;
4209     ALWAYS_INLINE void load(const void* address, RegisterID dest)
4210     {
4211         intptr_t currentRegisterContents;
4212         if (cachedMemoryTempRegister().value(currentRegisterContents)) {
4213             intptr_t addressAsInt = reinterpret_cast&lt;intptr_t&gt;(address);
4214             intptr_t addressDelta = addressAsInt - currentRegisterContents;
4215 
4216             if (dest == memoryTempRegister)
4217                 cachedMemoryTempRegister().invalidate();
4218 
4219             if (isInt&lt;32&gt;(addressDelta)) {
4220                 if (Assembler::canEncodeSImmOffset(addressDelta)) {
<a name="15" id="anc15"></a><span class="line-modified">4221                     loadUnscaledImmediate&lt;datasize&gt;(dest, memoryTempRegister, addressDelta);</span>
4222                     return;
4223                 }
4224 
4225                 if (Assembler::canEncodePImmOffset&lt;datasize&gt;(addressDelta)) {
<a name="16" id="anc16"></a><span class="line-modified">4226                     loadUnsignedImmediate&lt;datasize&gt;(dest, memoryTempRegister, addressDelta);</span>
4227                     return;
4228                 }
4229             }
4230 
4231             if ((addressAsInt &amp; (~maskHalfWord0)) == (currentRegisterContents &amp; (~maskHalfWord0))) {
4232                 m_assembler.movk&lt;64&gt;(memoryTempRegister, addressAsInt &amp; maskHalfWord0, 0);
4233                 cachedMemoryTempRegister().setValue(reinterpret_cast&lt;intptr_t&gt;(address));
<a name="17" id="anc17"></a><span class="line-modified">4234                 if constexpr (datasize == 16)</span>
<span class="line-added">4235                     m_assembler.ldrh(dest, memoryTempRegister, ARM64Registers::zr);</span>
<span class="line-added">4236                 else</span>
<span class="line-added">4237                     m_assembler.ldr&lt;datasize&gt;(dest, memoryTempRegister, ARM64Registers::zr);</span>
4238                 return;
4239             }
4240         }
4241 
4242         move(TrustedImmPtr(address), memoryTempRegister);
4243         if (dest == memoryTempRegister)
4244             cachedMemoryTempRegister().invalidate();
4245         else
4246             cachedMemoryTempRegister().setValue(reinterpret_cast&lt;intptr_t&gt;(address));
<a name="18" id="anc18"></a><span class="line-modified">4247         if constexpr (datasize == 16)</span>
<span class="line-added">4248             m_assembler.ldrh(dest, memoryTempRegister, ARM64Registers::zr);</span>
<span class="line-added">4249         else</span>
<span class="line-added">4250             m_assembler.ldr&lt;datasize&gt;(dest, memoryTempRegister, ARM64Registers::zr);</span>
4251     }
4252 
4253     template&lt;int datasize&gt;
4254     ALWAYS_INLINE void store(RegisterID src, const void* address)
4255     {
4256         ASSERT(src != memoryTempRegister);
4257         intptr_t currentRegisterContents;
4258         if (cachedMemoryTempRegister().value(currentRegisterContents)) {
4259             intptr_t addressAsInt = reinterpret_cast&lt;intptr_t&gt;(address);
4260             intptr_t addressDelta = addressAsInt - currentRegisterContents;
4261 
4262             if (isInt&lt;32&gt;(addressDelta)) {
4263                 if (Assembler::canEncodeSImmOffset(addressDelta)) {
<a name="19" id="anc19"></a><span class="line-modified">4264                     storeUnscaledImmediate&lt;datasize&gt;(src, memoryTempRegister, addressDelta);</span>
4265                     return;
4266                 }
4267 
4268                 if (Assembler::canEncodePImmOffset&lt;datasize&gt;(addressDelta)) {
<a name="20" id="anc20"></a><span class="line-modified">4269                     storeUnsignedImmediate&lt;datasize&gt;(src, memoryTempRegister, addressDelta);</span>
4270                     return;
4271                 }
4272             }
4273 
4274             if ((addressAsInt &amp; (~maskHalfWord0)) == (currentRegisterContents &amp; (~maskHalfWord0))) {
4275                 m_assembler.movk&lt;64&gt;(memoryTempRegister, addressAsInt &amp; maskHalfWord0, 0);
4276                 cachedMemoryTempRegister().setValue(reinterpret_cast&lt;intptr_t&gt;(address));
<a name="21" id="anc21"></a><span class="line-modified">4277                 if constexpr (datasize == 16)</span>
<span class="line-added">4278                     m_assembler.strh(src, memoryTempRegister, ARM64Registers::zr);</span>
<span class="line-added">4279                 else</span>
<span class="line-added">4280                     m_assembler.str&lt;datasize&gt;(src, memoryTempRegister, ARM64Registers::zr);</span>
4281                 return;
4282             }
4283         }
4284 
4285         move(TrustedImmPtr(address), memoryTempRegister);
4286         cachedMemoryTempRegister().setValue(reinterpret_cast&lt;intptr_t&gt;(address));
<a name="22" id="anc22"></a><span class="line-modified">4287         if constexpr (datasize == 16)</span>
<span class="line-added">4288             m_assembler.strh(src, memoryTempRegister, ARM64Registers::zr);</span>
<span class="line-added">4289         else</span>
<span class="line-added">4290             m_assembler.str&lt;datasize&gt;(src, memoryTempRegister, ARM64Registers::zr);</span>
4291     }
4292 
4293     template &lt;int dataSize&gt;
4294     ALWAYS_INLINE bool tryMoveUsingCacheRegisterContents(intptr_t immediate, CachedTempRegister&amp; dest)
4295     {
4296         intptr_t currentRegisterContents;
4297         if (dest.value(currentRegisterContents)) {
4298             if (currentRegisterContents == immediate)
4299                 return true;
4300 
4301             LogicalImmediate logicalImm = dataSize == 64 ? LogicalImmediate::create64(static_cast&lt;uint64_t&gt;(immediate)) : LogicalImmediate::create32(static_cast&lt;uint32_t&gt;(immediate));
4302 
4303             if (logicalImm.isValid()) {
4304                 m_assembler.movi&lt;dataSize&gt;(dest.registerIDNoInvalidate(), logicalImm);
4305                 dest.setValue(immediate);
4306                 return true;
4307             }
4308 
4309             if ((immediate &amp; maskUpperWord) == (currentRegisterContents &amp; maskUpperWord)) {
4310                 if ((immediate &amp; maskHalfWord1) != (currentRegisterContents &amp; maskHalfWord1))
4311                     m_assembler.movk&lt;dataSize&gt;(dest.registerIDNoInvalidate(), (immediate &amp; maskHalfWord1) &gt;&gt; 16, 16);
4312 
4313                 if ((immediate &amp; maskHalfWord0) != (currentRegisterContents &amp; maskHalfWord0))
4314                     m_assembler.movk&lt;dataSize&gt;(dest.registerIDNoInvalidate(), immediate &amp; maskHalfWord0, 0);
4315 
4316                 dest.setValue(immediate);
4317                 return true;
4318             }
4319         }
4320 
4321         return false;
4322     }
4323 
4324     void moveToCachedReg(TrustedImm32 imm, CachedTempRegister&amp; dest)
4325     {
4326         if (tryMoveUsingCacheRegisterContents&lt;32&gt;(static_cast&lt;intptr_t&gt;(imm.m_value), dest))
4327             return;
4328 
4329         moveInternal&lt;TrustedImm32, int32_t&gt;(imm, dest.registerIDNoInvalidate());
4330         dest.setValue(imm.m_value);
4331     }
4332 
4333     void moveToCachedReg(TrustedImmPtr imm, CachedTempRegister&amp; dest)
4334     {
4335         if (tryMoveUsingCacheRegisterContents&lt;64&gt;(imm.asIntptr(), dest))
4336             return;
4337 
4338         moveInternal&lt;TrustedImmPtr, intptr_t&gt;(imm, dest.registerIDNoInvalidate());
4339         dest.setValue(imm.asIntptr());
4340     }
4341 
4342     void moveToCachedReg(TrustedImm64 imm, CachedTempRegister&amp; dest)
4343     {
4344         if (tryMoveUsingCacheRegisterContents&lt;64&gt;(static_cast&lt;intptr_t&gt;(imm.m_value), dest))
4345             return;
4346 
4347         moveInternal&lt;TrustedImm64, int64_t&gt;(imm, dest.registerIDNoInvalidate());
4348         dest.setValue(imm.m_value);
4349     }
4350 
4351     template&lt;int datasize&gt;
4352     ALWAYS_INLINE bool tryLoadWithOffset(RegisterID rt, RegisterID rn, int32_t offset)
4353     {
4354         if (Assembler::canEncodeSImmOffset(offset)) {
4355             loadUnscaledImmediate&lt;datasize&gt;(rt, rn, offset);
4356             return true;
4357         }
4358         if (Assembler::canEncodePImmOffset&lt;datasize&gt;(offset)) {
4359             loadUnsignedImmediate&lt;datasize&gt;(rt, rn, static_cast&lt;unsigned&gt;(offset));
4360             return true;
4361         }
4362         return false;
4363     }
4364 
4365     template&lt;int datasize&gt;
4366     ALWAYS_INLINE bool tryLoadSignedWithOffset(RegisterID rt, RegisterID rn, int32_t offset)
4367     {
4368         if (Assembler::canEncodeSImmOffset(offset)) {
4369             loadSignedAddressedByUnscaledImmediate&lt;datasize&gt;(rt, rn, offset);
4370             return true;
4371         }
4372         if (Assembler::canEncodePImmOffset&lt;datasize&gt;(offset)) {
4373             loadSignedAddressedByUnsignedImmediate&lt;datasize&gt;(rt, rn, static_cast&lt;unsigned&gt;(offset));
4374             return true;
4375         }
4376         return false;
4377     }
4378 
4379     template&lt;int datasize&gt;
4380     ALWAYS_INLINE bool tryLoadWithOffset(FPRegisterID rt, RegisterID rn, int32_t offset)
4381     {
4382         if (Assembler::canEncodeSImmOffset(offset)) {
4383             m_assembler.ldur&lt;datasize&gt;(rt, rn, offset);
4384             return true;
4385         }
4386         if (Assembler::canEncodePImmOffset&lt;datasize&gt;(offset)) {
4387             m_assembler.ldr&lt;datasize&gt;(rt, rn, static_cast&lt;unsigned&gt;(offset));
4388             return true;
4389         }
4390         return false;
4391     }
4392 
4393     template&lt;int datasize&gt;
4394     ALWAYS_INLINE bool tryStoreWithOffset(RegisterID rt, RegisterID rn, int32_t offset)
4395     {
4396         if (Assembler::canEncodeSImmOffset(offset)) {
4397             storeUnscaledImmediate&lt;datasize&gt;(rt, rn, offset);
4398             return true;
4399         }
4400         if (Assembler::canEncodePImmOffset&lt;datasize&gt;(offset)) {
4401             storeUnsignedImmediate&lt;datasize&gt;(rt, rn, static_cast&lt;unsigned&gt;(offset));
4402             return true;
4403         }
4404         return false;
4405     }
4406 
4407     template&lt;int datasize&gt;
4408     ALWAYS_INLINE bool tryStoreWithOffset(FPRegisterID rt, RegisterID rn, int32_t offset)
4409     {
4410         if (Assembler::canEncodeSImmOffset(offset)) {
4411             m_assembler.stur&lt;datasize&gt;(rt, rn, offset);
4412             return true;
4413         }
4414         if (Assembler::canEncodePImmOffset&lt;datasize&gt;(offset)) {
4415             m_assembler.str&lt;datasize&gt;(rt, rn, static_cast&lt;unsigned&gt;(offset));
4416             return true;
4417         }
4418         return false;
4419     }
4420 
4421     template&lt;int datasize&gt;
4422     void loadLink(RegisterID src, RegisterID dest)
4423     {
4424         m_assembler.ldxr&lt;datasize&gt;(dest, src);
4425     }
4426 
4427     template&lt;int datasize&gt;
4428     void loadLinkAcq(RegisterID src, RegisterID dest)
4429     {
4430         m_assembler.ldaxr&lt;datasize&gt;(dest, src);
4431     }
4432 
4433     template&lt;int datasize&gt;
4434     void storeCond(RegisterID src, RegisterID dest, RegisterID result)
4435     {
4436         m_assembler.stxr&lt;datasize&gt;(src, dest, result);
4437     }
4438 
4439     template&lt;int datasize&gt;
4440     void storeCondRel(RegisterID src, RegisterID dest, RegisterID result)
4441     {
4442         m_assembler.stlxr&lt;datasize&gt;(result, src, dest);
4443     }
4444 
4445     template&lt;int datasize&gt;
4446     void signExtend(RegisterID src, RegisterID dest)
4447     {
4448         move(src, dest);
4449     }
4450 
4451     template&lt;int datasize&gt;
4452     Jump branch(RelationalCondition cond, RegisterID left, RegisterID right)
4453     {
4454         return branch32(cond, left, right);
4455     }
4456 
4457     template&lt;int datasize&gt;
4458     void atomicStrongCAS(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, Address address, RegisterID result)
4459     {
4460         signExtend&lt;datasize&gt;(expectedAndResult, expectedAndResult);
4461 
4462         RegisterID simpleAddress = extractSimpleAddress(address);
4463         RegisterID tmp = getCachedDataTempRegisterIDAndInvalidate();
4464 
4465         Label reloop = label();
4466         loadLinkAcq&lt;datasize&gt;(simpleAddress, tmp);
4467         Jump failure = branch&lt;datasize&gt;(NotEqual, expectedAndResult, tmp);
4468 
4469         storeCondRel&lt;datasize&gt;(newValue, simpleAddress, result);
4470         branchTest32(NonZero, result).linkTo(reloop, this);
4471         move(TrustedImm32(cond == Success), result);
4472         Jump done = jump();
4473 
4474         failure.link(this);
4475         move(tmp, expectedAndResult);
4476         storeCondRel&lt;datasize&gt;(tmp, simpleAddress, result);
4477         branchTest32(NonZero, result).linkTo(reloop, this);
4478         move(TrustedImm32(cond == Failure), result);
4479 
4480         done.link(this);
4481     }
4482 
4483     template&lt;int datasize, typename AddressType&gt;
4484     void atomicRelaxedStrongCAS(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, AddressType address, RegisterID result)
4485     {
4486         signExtend&lt;datasize&gt;(expectedAndResult, expectedAndResult);
4487 
4488         RegisterID simpleAddress = extractSimpleAddress(address);
4489         RegisterID tmp = getCachedDataTempRegisterIDAndInvalidate();
4490 
4491         Label reloop = label();
4492         loadLink&lt;datasize&gt;(simpleAddress, tmp);
4493         Jump failure = branch&lt;datasize&gt;(NotEqual, expectedAndResult, tmp);
4494 
4495         storeCond&lt;datasize&gt;(newValue, simpleAddress, result);
4496         branchTest32(NonZero, result).linkTo(reloop, this);
4497         move(TrustedImm32(cond == Success), result);
4498         Jump done = jump();
4499 
4500         failure.link(this);
4501         move(tmp, expectedAndResult);
4502         move(TrustedImm32(cond == Failure), result);
4503 
4504         done.link(this);
4505     }
4506 
4507     template&lt;int datasize, typename AddressType&gt;
4508     JumpList branchAtomicWeakCAS(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, AddressType address)
4509     {
4510         signExtend&lt;datasize&gt;(expectedAndClobbered, expectedAndClobbered);
4511 
4512         RegisterID simpleAddress = extractSimpleAddress(address);
4513         RegisterID tmp = getCachedDataTempRegisterIDAndInvalidate();
4514 
4515         JumpList success;
4516         JumpList failure;
4517 
4518         loadLinkAcq&lt;datasize&gt;(simpleAddress, tmp);
4519         failure.append(branch&lt;datasize&gt;(NotEqual, expectedAndClobbered, tmp));
4520         storeCondRel&lt;datasize&gt;(newValue, simpleAddress, expectedAndClobbered);
4521 
4522         switch (cond) {
4523         case Success:
4524             success.append(branchTest32(Zero, expectedAndClobbered));
4525             failure.link(this);
4526             return success;
4527         case Failure:
4528             failure.append(branchTest32(NonZero, expectedAndClobbered));
4529             return failure;
4530         }
4531 
4532         RELEASE_ASSERT_NOT_REACHED();
4533     }
4534 
4535     template&lt;int datasize, typename AddressType&gt;
4536     JumpList branchAtomicRelaxedWeakCAS(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, AddressType address)
4537     {
4538         signExtend&lt;datasize&gt;(expectedAndClobbered, expectedAndClobbered);
4539 
4540         RegisterID simpleAddress = extractSimpleAddress(address);
4541         RegisterID tmp = getCachedDataTempRegisterIDAndInvalidate();
4542 
4543         JumpList success;
4544         JumpList failure;
4545 
4546         loadLink&lt;datasize&gt;(simpleAddress, tmp);
4547         failure.append(branch&lt;datasize&gt;(NotEqual, expectedAndClobbered, tmp));
4548         storeCond&lt;datasize&gt;(newValue, simpleAddress, expectedAndClobbered);
4549 
4550         switch (cond) {
4551         case Success:
4552             success.append(branchTest32(Zero, expectedAndClobbered));
4553             failure.link(this);
4554             return success;
4555         case Failure:
4556             failure.append(branchTest32(NonZero, expectedAndClobbered));
4557             return failure;
4558         }
4559 
4560         RELEASE_ASSERT_NOT_REACHED();
4561     }
4562 
4563     RegisterID extractSimpleAddress(ImplicitAddress address)
4564     {
4565         if (!address.offset)
4566             return address.base;
4567 
4568         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
4569         add64(address.base, memoryTempRegister);
4570         return memoryTempRegister;
4571     }
4572 
4573     // This uses both the memory and data temp, but only returns the memorty temp. So you can use the
4574     // data temp after this finishes.
4575     RegisterID extractSimpleAddress(BaseIndex address)
4576     {
4577         RegisterID result = getCachedMemoryTempRegisterIDAndInvalidate();
4578         lshift64(address.index, TrustedImm32(address.scale), result);
4579         add64(address.base, result);
4580         add64(TrustedImm32(address.offset), result);
4581         return result;
4582     }
4583 
4584     Jump jumpAfterFloatingPointCompare(DoubleCondition cond)
4585     {
4586         if (cond == DoubleNotEqual) {
4587             // ConditionNE jumps if NotEqual *or* unordered - force the unordered cases not to jump.
4588             Jump unordered = makeBranch(Assembler::ConditionVS);
4589             Jump result = makeBranch(Assembler::ConditionNE);
4590             unordered.link(this);
4591             return result;
4592         }
4593         if (cond == DoubleEqualOrUnordered) {
4594             Jump unordered = makeBranch(Assembler::ConditionVS);
4595             Jump notEqual = makeBranch(Assembler::ConditionNE);
4596             unordered.link(this);
4597             // We get here if either unordered or equal.
4598             Jump result = jump();
4599             notEqual.link(this);
4600             return result;
4601         }
4602         return makeBranch(cond);
4603     }
4604 
4605     template&lt;typename Function&gt;
4606     void floatingPointCompare(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID dest, Function compare)
4607     {
4608         if (cond == DoubleNotEqual) {
4609             // ConditionNE sets 1 if NotEqual *or* unordered - force the unordered cases not to set 1.
4610             move(TrustedImm32(0), dest);
4611             compare(left, right);
4612             Jump unordered = makeBranch(Assembler::ConditionVS);
4613             m_assembler.cset&lt;32&gt;(dest, Assembler::ConditionNE);
4614             unordered.link(this);
4615             return;
4616         }
4617         if (cond == DoubleEqualOrUnordered) {
4618             // ConditionEQ sets 1 only if Equal - force the unordered cases to set 1 too.
4619             move(TrustedImm32(1), dest);
4620             compare(left, right);
4621             Jump unordered = makeBranch(Assembler::ConditionVS);
4622             m_assembler.cset&lt;32&gt;(dest, Assembler::ConditionEQ);
4623             unordered.link(this);
4624             return;
4625         }
4626         compare(left, right);
4627         m_assembler.cset&lt;32&gt;(dest, ARM64Condition(cond));
4628     }
4629 
4630     friend class LinkBuffer;
4631 
4632     template&lt;PtrTag tag&gt;
4633     static void linkCall(void* code, Call call, FunctionPtr&lt;tag&gt; function)
4634     {
4635         if (!call.isFlagSet(Call::Near))
4636             Assembler::linkPointer(code, call.m_label.labelAtOffset(REPATCH_OFFSET_CALL_TO_POINTER), function.executableAddress());
4637         else if (call.isFlagSet(Call::Tail))
4638             Assembler::linkJump(code, call.m_label, function.template retaggedExecutableAddress&lt;NoPtrTag&gt;());
4639         else
4640             Assembler::linkCall(code, call.m_label, function.template retaggedExecutableAddress&lt;NoPtrTag&gt;());
4641     }
4642 
4643     JS_EXPORT_PRIVATE static void collectCPUFeatures();
4644 
4645     JS_EXPORT_PRIVATE static CPUIDCheckState s_jscvtCheckState;
4646 
4647     CachedTempRegister m_dataMemoryTempRegister;
4648     CachedTempRegister m_cachedMemoryTempRegister;
4649     bool m_makeJumpPatchable;
4650 };
4651 
4652 // Extend the {load,store}{Unsigned,Unscaled}Immediate templated general register methods to cover all load/store sizes
4653 template&lt;&gt;
4654 ALWAYS_INLINE void MacroAssemblerARM64::loadUnsignedImmediate&lt;8&gt;(RegisterID rt, RegisterID rn, unsigned pimm)
4655 {
4656     m_assembler.ldrb(rt, rn, pimm);
4657 }
4658 
4659 template&lt;&gt;
4660 ALWAYS_INLINE void MacroAssemblerARM64::loadUnsignedImmediate&lt;16&gt;(RegisterID rt, RegisterID rn, unsigned pimm)
4661 {
4662     m_assembler.ldrh(rt, rn, pimm);
4663 }
4664 
4665 template&lt;&gt;
4666 ALWAYS_INLINE void MacroAssemblerARM64::loadSignedAddressedByUnsignedImmediate&lt;8&gt;(RegisterID rt, RegisterID rn, unsigned pimm)
4667 {
4668     m_assembler.ldrsb&lt;64&gt;(rt, rn, pimm);
4669 }
4670 
4671 template&lt;&gt;
4672 ALWAYS_INLINE void MacroAssemblerARM64::loadSignedAddressedByUnsignedImmediate&lt;16&gt;(RegisterID rt, RegisterID rn, unsigned pimm)
4673 {
4674     m_assembler.ldrsh&lt;64&gt;(rt, rn, pimm);
4675 }
4676 
4677 template&lt;&gt;
4678 ALWAYS_INLINE void MacroAssemblerARM64::loadUnscaledImmediate&lt;8&gt;(RegisterID rt, RegisterID rn, int simm)
4679 {
4680     m_assembler.ldurb(rt, rn, simm);
4681 }
4682 
4683 template&lt;&gt;
4684 ALWAYS_INLINE void MacroAssemblerARM64::loadUnscaledImmediate&lt;16&gt;(RegisterID rt, RegisterID rn, int simm)
4685 {
4686     m_assembler.ldurh(rt, rn, simm);
4687 }
4688 
4689 template&lt;&gt;
4690 ALWAYS_INLINE void MacroAssemblerARM64::loadSignedAddressedByUnscaledImmediate&lt;8&gt;(RegisterID rt, RegisterID rn, int simm)
4691 {
4692     m_assembler.ldursb&lt;64&gt;(rt, rn, simm);
4693 }
4694 
4695 template&lt;&gt;
4696 ALWAYS_INLINE void MacroAssemblerARM64::loadSignedAddressedByUnscaledImmediate&lt;16&gt;(RegisterID rt, RegisterID rn, int simm)
4697 {
4698     m_assembler.ldursh&lt;64&gt;(rt, rn, simm);
4699 }
4700 
4701 template&lt;&gt;
4702 ALWAYS_INLINE void MacroAssemblerARM64::storeUnsignedImmediate&lt;8&gt;(RegisterID rt, RegisterID rn, unsigned pimm)
4703 {
4704     m_assembler.strb(rt, rn, pimm);
4705 }
4706 
4707 template&lt;&gt;
4708 ALWAYS_INLINE void MacroAssemblerARM64::storeUnsignedImmediate&lt;16&gt;(RegisterID rt, RegisterID rn, unsigned pimm)
4709 {
4710     m_assembler.strh(rt, rn, pimm);
4711 }
4712 
4713 template&lt;&gt;
4714 ALWAYS_INLINE void MacroAssemblerARM64::storeUnscaledImmediate&lt;8&gt;(RegisterID rt, RegisterID rn, int simm)
4715 {
4716     m_assembler.sturb(rt, rn, simm);
4717 }
4718 
4719 template&lt;&gt;
4720 ALWAYS_INLINE void MacroAssemblerARM64::storeUnscaledImmediate&lt;16&gt;(RegisterID rt, RegisterID rn, int simm)
4721 {
4722     m_assembler.sturh(rt, rn, simm);
4723 }
4724 
4725 template&lt;&gt;
4726 inline void MacroAssemblerARM64::signExtend&lt;8&gt;(RegisterID src, RegisterID dest)
4727 {
4728     signExtend8To32(src, dest);
4729 }
4730 
4731 template&lt;&gt;
4732 inline void MacroAssemblerARM64::signExtend&lt;16&gt;(RegisterID src, RegisterID dest)
4733 {
4734     signExtend16To32(src, dest);
4735 }
4736 
4737 template&lt;&gt;
4738 inline MacroAssemblerARM64::Jump MacroAssemblerARM64::branch&lt;64&gt;(RelationalCondition cond, RegisterID left, RegisterID right)
4739 {
4740     return branch64(cond, left, right);
4741 }
4742 
4743 } // namespace JSC
4744 
4745 #endif // ENABLE(ASSEMBLER)
<a name="23" id="anc23"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="23" type="hidden" />
</body>
</html>