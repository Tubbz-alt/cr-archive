<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/JavaScriptCore/bytecode/StructureStubInfo.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2008-2020 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;StructureStubInfo.h&quot;
 28 
 29 #include &quot;CacheableIdentifierInlines.h&quot;
 30 #include &quot;JSObject.h&quot;
 31 #include &quot;JSCInlines.h&quot;
 32 #include &quot;PolymorphicAccess.h&quot;
 33 #include &quot;Repatch.h&quot;
 34 
 35 namespace JSC {
 36 
 37 #if ENABLE(JIT)
 38 
 39 namespace StructureStubInfoInternal {
 40 static constexpr bool verbose = false;
 41 }
 42 
 43 StructureStubInfo::StructureStubInfo(AccessType accessType)
 44     : accessType(accessType)
 45     , m_cacheType(CacheType::Unset)
 46     , countdown(1) // For a totally clear stub, we&#39;ll patch it after the first execution.
 47     , repatchCount(0)
 48     , numberOfCoolDowns(0)
 49     , bufferingCountdown(Options::repatchBufferingCountdown())
 50     , resetByGC(false)
 51     , tookSlowPath(false)
 52     , everConsidered(false)
 53     , prototypeIsKnownObject(false)
 54     , sawNonCell(false)
 55     , hasConstantIdentifier(true)
 56     , propertyIsString(false)
 57     , propertyIsInt32(false)
 58     , propertyIsSymbol(false)
 59 {
 60 }
 61 
 62 StructureStubInfo::~StructureStubInfo()
 63 {
 64 }
 65 
 66 void StructureStubInfo::initGetByIdSelf(CodeBlock* codeBlock, Structure* baseObjectStructure, PropertyOffset offset, CacheableIdentifier identifier)
 67 {
 68     ASSERT(hasConstantIdentifier);
 69     setCacheType(CacheType::GetByIdSelf);
 70     m_getByIdSelfIdentifier = identifier;
 71     codeBlock-&gt;vm().heap.writeBarrier(codeBlock);
 72 
 73     u.byIdSelf.baseObjectStructure.set(
 74         codeBlock-&gt;vm(), codeBlock, baseObjectStructure);
 75     u.byIdSelf.offset = offset;
 76 }
 77 
 78 void StructureStubInfo::initArrayLength()
 79 {
 80     setCacheType(CacheType::ArrayLength);
 81 }
 82 
 83 void StructureStubInfo::initStringLength()
 84 {
 85     setCacheType(CacheType::StringLength);
 86 }
 87 
 88 void StructureStubInfo::initPutByIdReplace(CodeBlock* codeBlock, Structure* baseObjectStructure, PropertyOffset offset)
 89 {
 90     setCacheType(CacheType::PutByIdReplace);
 91 
 92     u.byIdSelf.baseObjectStructure.set(
 93         codeBlock-&gt;vm(), codeBlock, baseObjectStructure);
 94     u.byIdSelf.offset = offset;
 95 }
 96 
 97 void StructureStubInfo::initInByIdSelf(CodeBlock* codeBlock, Structure* baseObjectStructure, PropertyOffset offset)
 98 {
 99     setCacheType(CacheType::InByIdSelf);
100 
101     u.byIdSelf.baseObjectStructure.set(
102         codeBlock-&gt;vm(), codeBlock, baseObjectStructure);
103     u.byIdSelf.offset = offset;
104 }
105 
106 void StructureStubInfo::deref()
107 {
108     switch (m_cacheType) {
109     case CacheType::Stub:
110         delete u.stub;
111         return;
112     case CacheType::Unset:
113     case CacheType::GetByIdSelf:
114     case CacheType::PutByIdReplace:
115     case CacheType::InByIdSelf:
116     case CacheType::ArrayLength:
117     case CacheType::StringLength:
118         return;
119     }
120 
121     RELEASE_ASSERT_NOT_REACHED();
122 }
123 
124 void StructureStubInfo::aboutToDie()
125 {
126     switch (m_cacheType) {
127     case CacheType::Stub:
128         u.stub-&gt;aboutToDie();
129         return;
130     case CacheType::Unset:
131     case CacheType::GetByIdSelf:
132     case CacheType::PutByIdReplace:
133     case CacheType::InByIdSelf:
134     case CacheType::ArrayLength:
135     case CacheType::StringLength:
136         return;
137     }
138 
139     RELEASE_ASSERT_NOT_REACHED();
140 }
141 
142 AccessGenerationResult StructureStubInfo::addAccessCase(
143     const GCSafeConcurrentJSLocker&amp; locker, CodeBlock* codeBlock, CacheableIdentifier ident, std::unique_ptr&lt;AccessCase&gt; accessCase)
144 {
145     checkConsistency();
146 
147     VM&amp; vm = codeBlock-&gt;vm();
148     ASSERT(vm.heap.isDeferred());
149     AccessGenerationResult result = ([&amp;] () -&gt; AccessGenerationResult {
150         if (StructureStubInfoInternal::verbose)
151             dataLog(&quot;Adding access case: &quot;, accessCase, &quot;\n&quot;);
152 
153         if (!accessCase)
154             return AccessGenerationResult::GaveUp;
155 
156         AccessGenerationResult result;
157 
158         if (m_cacheType == CacheType::Stub) {
159             result = u.stub-&gt;addCase(locker, vm, codeBlock, *this, WTFMove(accessCase));
160 
161             if (StructureStubInfoInternal::verbose)
162                 dataLog(&quot;Had stub, result: &quot;, result, &quot;\n&quot;);
163 
164             if (result.shouldResetStubAndFireWatchpoints())
165                 return result;
166 
167             if (!result.buffered()) {
168                 bufferedStructures.clear();
169                 return result;
170             }
171         } else {
172             std::unique_ptr&lt;PolymorphicAccess&gt; access = makeUnique&lt;PolymorphicAccess&gt;();
173 
174             Vector&lt;std::unique_ptr&lt;AccessCase&gt;, 2&gt; accessCases;
175 
176             std::unique_ptr&lt;AccessCase&gt; previousCase = AccessCase::fromStructureStubInfo(vm, codeBlock, ident, *this);
177             if (previousCase)
178                 accessCases.append(WTFMove(previousCase));
179 
180             accessCases.append(WTFMove(accessCase));
181 
182             result = access-&gt;addCases(locker, vm, codeBlock, *this, WTFMove(accessCases));
183 
184             if (StructureStubInfoInternal::verbose)
185                 dataLog(&quot;Created stub, result: &quot;, result, &quot;\n&quot;);
186 
187             if (result.shouldResetStubAndFireWatchpoints())
188                 return result;
189 
190             if (!result.buffered()) {
191                 bufferedStructures.clear();
192                 return result;
193             }
194 
195             setCacheType(CacheType::Stub);
196             u.stub = access.release();
197         }
198 
199         ASSERT(m_cacheType == CacheType::Stub);
200         RELEASE_ASSERT(!result.generatedSomeCode());
201 
202         // If we didn&#39;t buffer any cases then bail. If this made no changes then we&#39;ll just try again
203         // subject to cool-down.
204         if (!result.buffered()) {
205             if (StructureStubInfoInternal::verbose)
206                 dataLog(&quot;Didn&#39;t buffer anything, bailing.\n&quot;);
207             bufferedStructures.clear();
208             return result;
209         }
210 
211         // The buffering countdown tells us if we should be repatching now.
212         if (bufferingCountdown) {
213             if (StructureStubInfoInternal::verbose)
214                 dataLog(&quot;Countdown is too high: &quot;, bufferingCountdown, &quot;.\n&quot;);
215             return result;
216         }
217 
218         // Forget the buffered structures so that all future attempts to cache get fully handled by the
219         // PolymorphicAccess.
220         bufferedStructures.clear();
221 
222         result = u.stub-&gt;regenerate(locker, vm, codeBlock, *this);
223 
224         if (StructureStubInfoInternal::verbose)
225             dataLog(&quot;Regeneration result: &quot;, result, &quot;\n&quot;);
226 
227         RELEASE_ASSERT(!result.buffered());
228 
229         if (!result.generatedSomeCode())
230             return result;
231 
232         // If we generated some code then we don&#39;t want to attempt to repatch in the future until we
233         // gather enough cases.
234         bufferingCountdown = Options::repatchBufferingCountdown();
235         return result;
236     })();
237     vm.heap.writeBarrier(codeBlock);
238     return result;
239 }
240 
241 void StructureStubInfo::reset(CodeBlock* codeBlock)
242 {
243     bufferedStructures.clear();
244 
245     if (m_cacheType == CacheType::Unset)
246         return;
247 
248     if (Options::verboseOSR()) {
249         // This can be called from GC destructor calls, so we don&#39;t try to do a full dump
250         // of the CodeBlock.
251         dataLog(&quot;Clearing structure cache (kind &quot;, static_cast&lt;int&gt;(accessType), &quot;) in &quot;, RawPointer(codeBlock), &quot;.\n&quot;);
252     }
253 
254     switch (accessType) {
255     case AccessType::TryGetById:
256         resetGetBy(codeBlock, *this, GetByKind::Try);
257         break;
258     case AccessType::GetById:
259         resetGetBy(codeBlock, *this, GetByKind::Normal);
260         break;
261     case AccessType::GetByIdWithThis:
262         resetGetBy(codeBlock, *this, GetByKind::WithThis);
263         break;
264     case AccessType::GetByIdDirect:
265         resetGetBy(codeBlock, *this, GetByKind::Direct);
266         break;
267     case AccessType::GetByVal:
268         resetGetBy(codeBlock, *this, GetByKind::NormalByVal);
269         break;
270     case AccessType::Put:
271         resetPutByID(codeBlock, *this);
272         break;
273     case AccessType::In:
274         resetInByID(codeBlock, *this);
275         break;
276     case AccessType::InstanceOf:
277         resetInstanceOf(*this);
278         break;
279     }
280 
281     deref();
282     setCacheType(CacheType::Unset);
283 }
284 
285 void StructureStubInfo::visitAggregate(SlotVisitor&amp; visitor)
286 {
287     switch (m_cacheType) {
288     case CacheType::Unset:
289     case CacheType::ArrayLength:
290     case CacheType::StringLength:
291     case CacheType::PutByIdReplace:
292     case CacheType::InByIdSelf:
293         return;
294     case CacheType::GetByIdSelf:
295         m_getByIdSelfIdentifier.visitAggregate(visitor);
296         return;
297     case CacheType::Stub:
298         u.stub-&gt;visitAggregate(visitor);
299         return;
300     }
301 
302     RELEASE_ASSERT_NOT_REACHED();
303     return;
304 }
305 
306 void StructureStubInfo::visitWeakReferences(CodeBlock* codeBlock)
307 {
308     VM&amp; vm = codeBlock-&gt;vm();
309 
310     bufferedStructures.removeIf(
311         [&amp;] (auto&amp; pair) -&gt; bool {
312             Structure* structure = pair.first;
313             return !vm.heap.isMarked(structure);
314         });
315 
316     switch (m_cacheType) {
317     case CacheType::GetByIdSelf:
318     case CacheType::PutByIdReplace:
319     case CacheType::InByIdSelf:
320         if (vm.heap.isMarked(u.byIdSelf.baseObjectStructure.get()))
321             return;
322         break;
323     case CacheType::Stub:
324         if (u.stub-&gt;visitWeak(vm))
325             return;
326         break;
327     default:
328         return;
329     }
330 
331     reset(codeBlock);
332     resetByGC = true;
333 }
334 
335 bool StructureStubInfo::propagateTransitions(SlotVisitor&amp; visitor)
336 {
337     switch (m_cacheType) {
338     case CacheType::Unset:
339     case CacheType::ArrayLength:
340     case CacheType::StringLength:
341         return true;
342     case CacheType::GetByIdSelf:
343     case CacheType::PutByIdReplace:
344     case CacheType::InByIdSelf:
345         return u.byIdSelf.baseObjectStructure-&gt;markIfCheap(visitor);
346     case CacheType::Stub:
347         return u.stub-&gt;propagateTransitions(visitor);
348     }
349 
350     RELEASE_ASSERT_NOT_REACHED();
351     return true;
352 }
353 
354 StubInfoSummary StructureStubInfo::summary(VM&amp; vm) const
355 {
356     StubInfoSummary takesSlowPath = StubInfoSummary::TakesSlowPath;
357     StubInfoSummary simple = StubInfoSummary::Simple;
358     if (m_cacheType == CacheType::Stub) {
359         PolymorphicAccess* list = u.stub;
360         for (unsigned i = 0; i &lt; list-&gt;size(); ++i) {
361             const AccessCase&amp; access = list-&gt;at(i);
362             if (access.doesCalls(vm)) {
363                 takesSlowPath = StubInfoSummary::TakesSlowPathAndMakesCalls;
364                 simple = StubInfoSummary::MakesCalls;
365                 break;
366             }
367         }
368     }
369 
370     if (tookSlowPath || sawNonCell)
371         return takesSlowPath;
372 
373     if (!everConsidered)
374         return StubInfoSummary::NoInformation;
375 
376     return simple;
377 }
378 
379 StubInfoSummary StructureStubInfo::summary(VM&amp; vm, const StructureStubInfo* stubInfo)
380 {
381     if (!stubInfo)
382         return StubInfoSummary::NoInformation;
383 
384     return stubInfo-&gt;summary(vm);
385 }
386 
387 bool StructureStubInfo::containsPC(void* pc) const
388 {
389     if (m_cacheType != CacheType::Stub)
390         return false;
391     return u.stub-&gt;containsPC(pc);
392 }
393 
394 void StructureStubInfo::setCacheType(CacheType newCacheType)
395 {
396     if (m_cacheType == CacheType::GetByIdSelf)
397         m_getByIdSelfIdentifier = nullptr;
398     m_cacheType = newCacheType;
399 }
400 
401 #if ASSERT_ENABLED
402 void StructureStubInfo::checkConsistency()
403 {
404     if (thisValueIsInThisGPR()) {
405         // We currently use a union for both &quot;thisGPR&quot; and &quot;propertyGPR&quot;. If this were
406         // not the case, we&#39;d need to take one of them out of the union.
407         RELEASE_ASSERT(hasConstantIdentifier);
408     }
409 }
410 #endif // ASSERT_ENABLED
411 
412 #endif // ENABLE(JIT)
413 
414 } // namespace JSC
    </pre>
  </body>
</html>