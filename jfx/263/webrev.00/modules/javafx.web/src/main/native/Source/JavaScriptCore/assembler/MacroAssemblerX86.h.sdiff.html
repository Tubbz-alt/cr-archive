<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerX86.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="MacroAssemblerMIPS.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="MacroAssemblerX86Common.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerX86.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (C) 2008-2018 Apple Inc. All rights reserved.</span>
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #if ENABLE(ASSEMBLER) &amp;&amp; CPU(X86)
 29 
 30 #include &quot;MacroAssemblerX86Common.h&quot;
 31 
 32 namespace JSC {
 33 
 34 class MacroAssemblerX86 : public MacroAssemblerX86Common {
 35 public:
<span class="line-modified"> 36     static const unsigned numGPRs = 8;</span>
<span class="line-modified"> 37     static const unsigned numFPRs = 8;</span>
 38 
<span class="line-modified"> 39     static const Scale ScalePtr = TimesFour;</span>
 40 
 41     using MacroAssemblerX86Common::add32;
 42     using MacroAssemblerX86Common::and32;
 43     using MacroAssemblerX86Common::branchAdd32;
 44     using MacroAssemblerX86Common::branchSub32;
 45     using MacroAssemblerX86Common::sub32;
 46     using MacroAssemblerX86Common::or32;
 47     using MacroAssemblerX86Common::load32;
 48     using MacroAssemblerX86Common::load8;
 49     using MacroAssemblerX86Common::store32;
 50     using MacroAssemblerX86Common::store8;
 51     using MacroAssemblerX86Common::branch32;
 52     using MacroAssemblerX86Common::call;
 53     using MacroAssemblerX86Common::jump;
 54     using MacroAssemblerX86Common::farJump;
 55     using MacroAssemblerX86Common::addDouble;
 56     using MacroAssemblerX86Common::loadDouble;
 57     using MacroAssemblerX86Common::storeDouble;
 58     using MacroAssemblerX86Common::convertInt32ToDouble;
 59     using MacroAssemblerX86Common::branch8;
</pre>
<hr />
<pre>
 83     void getEffectiveAddress(BaseIndex address, RegisterID dest)
 84     {
 85         return x86Lea32(address, dest);
 86     }
 87 
 88     void and32(TrustedImm32 imm, AbsoluteAddress address)
 89     {
 90         m_assembler.andl_im(imm.m_value, address.m_ptr);
 91     }
 92 
 93     void or32(TrustedImm32 imm, AbsoluteAddress address)
 94     {
 95         m_assembler.orl_im(imm.m_value, address.m_ptr);
 96     }
 97 
 98     void or32(RegisterID reg, AbsoluteAddress address)
 99     {
100         m_assembler.orl_rm(reg, address.m_ptr);
101     }
102 





103     void sub32(TrustedImm32 imm, AbsoluteAddress address)
104     {
105         m_assembler.subl_im(imm.m_value, address.m_ptr);
106     }
107 
108     void load32(const void* address, RegisterID dest)
109     {
110         m_assembler.movl_mr(address, dest);
111     }
112 
113     void load8(const void* address, RegisterID dest)
114     {
115         m_assembler.movzbl_mr(address, dest);
116     }
117 
118     void abortWithReason(AbortReason reason)
119     {
120         move(TrustedImm32(reason), X86Registers::eax);
121         breakpoint();
122     }
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (C) 2008-2019 Apple Inc. All rights reserved.</span>
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #if ENABLE(ASSEMBLER) &amp;&amp; CPU(X86)
 29 
 30 #include &quot;MacroAssemblerX86Common.h&quot;
 31 
 32 namespace JSC {
 33 
 34 class MacroAssemblerX86 : public MacroAssemblerX86Common {
 35 public:
<span class="line-modified"> 36     static constexpr unsigned numGPRs = 8;</span>
<span class="line-modified"> 37     static constexpr unsigned numFPRs = 8;</span>
 38 
<span class="line-modified"> 39     static constexpr Scale ScalePtr = TimesFour;</span>
 40 
 41     using MacroAssemblerX86Common::add32;
 42     using MacroAssemblerX86Common::and32;
 43     using MacroAssemblerX86Common::branchAdd32;
 44     using MacroAssemblerX86Common::branchSub32;
 45     using MacroAssemblerX86Common::sub32;
 46     using MacroAssemblerX86Common::or32;
 47     using MacroAssemblerX86Common::load32;
 48     using MacroAssemblerX86Common::load8;
 49     using MacroAssemblerX86Common::store32;
 50     using MacroAssemblerX86Common::store8;
 51     using MacroAssemblerX86Common::branch32;
 52     using MacroAssemblerX86Common::call;
 53     using MacroAssemblerX86Common::jump;
 54     using MacroAssemblerX86Common::farJump;
 55     using MacroAssemblerX86Common::addDouble;
 56     using MacroAssemblerX86Common::loadDouble;
 57     using MacroAssemblerX86Common::storeDouble;
 58     using MacroAssemblerX86Common::convertInt32ToDouble;
 59     using MacroAssemblerX86Common::branch8;
</pre>
<hr />
<pre>
 83     void getEffectiveAddress(BaseIndex address, RegisterID dest)
 84     {
 85         return x86Lea32(address, dest);
 86     }
 87 
 88     void and32(TrustedImm32 imm, AbsoluteAddress address)
 89     {
 90         m_assembler.andl_im(imm.m_value, address.m_ptr);
 91     }
 92 
 93     void or32(TrustedImm32 imm, AbsoluteAddress address)
 94     {
 95         m_assembler.orl_im(imm.m_value, address.m_ptr);
 96     }
 97 
 98     void or32(RegisterID reg, AbsoluteAddress address)
 99     {
100         m_assembler.orl_rm(reg, address.m_ptr);
101     }
102 
<span class="line-added">103     void or16(TrustedImm32 imm, AbsoluteAddress address)</span>
<span class="line-added">104     {</span>
<span class="line-added">105         m_assembler.orw_im(imm.m_value, address.m_ptr);</span>
<span class="line-added">106     }</span>
<span class="line-added">107 </span>
108     void sub32(TrustedImm32 imm, AbsoluteAddress address)
109     {
110         m_assembler.subl_im(imm.m_value, address.m_ptr);
111     }
112 
113     void load32(const void* address, RegisterID dest)
114     {
115         m_assembler.movl_mr(address, dest);
116     }
117 
118     void load8(const void* address, RegisterID dest)
119     {
120         m_assembler.movzbl_mr(address, dest);
121     }
122 
123     void abortWithReason(AbortReason reason)
124     {
125         move(TrustedImm32(reason), X86Registers::eax);
126         breakpoint();
127     }
</pre>
</td>
</tr>
</table>
<center><a href="MacroAssemblerMIPS.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="MacroAssemblerX86Common.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>