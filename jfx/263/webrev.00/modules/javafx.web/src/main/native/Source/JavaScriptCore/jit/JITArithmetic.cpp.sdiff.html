<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JITArithmetic.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="JITAddGenerator.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="JITArithmetic32_64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JITArithmetic.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 
  28 #if ENABLE(JIT)
  29 #include &quot;JIT.h&quot;
  30 
  31 #include &quot;ArithProfile.h&quot;

  32 #include &quot;CodeBlock.h&quot;
  33 #include &quot;JITAddGenerator.h&quot;
  34 #include &quot;JITBitAndGenerator.h&quot;
  35 #include &quot;JITBitOrGenerator.h&quot;
  36 #include &quot;JITBitXorGenerator.h&quot;
  37 #include &quot;JITDivGenerator.h&quot;
  38 #include &quot;JITInlines.h&quot;
  39 #include &quot;JITLeftShiftGenerator.h&quot;
  40 #include &quot;JITMathIC.h&quot;
  41 #include &quot;JITMulGenerator.h&quot;
  42 #include &quot;JITNegGenerator.h&quot;
  43 #include &quot;JITOperations.h&quot;
  44 #include &quot;JITSubGenerator.h&quot;
  45 #include &quot;JSArray.h&quot;
  46 #include &quot;JSFunction.h&quot;
  47 #include &quot;Interpreter.h&quot;
  48 #include &quot;JSCInlines.h&quot;
  49 #include &quot;LinkBuffer.h&quot;
  50 #include &quot;ResultType.h&quot;
  51 #include &quot;SlowPathCall.h&quot;
</pre>
<hr />
<pre>
 140 void JIT::emit_op_beloweq(const Instruction* currentInstruction)
 141 {
 142     emit_compareUnsigned&lt;OpBeloweq&gt;(currentInstruction, BelowOrEqual);
 143 }
 144 
 145 void JIT::emit_op_jbelow(const Instruction* currentInstruction)
 146 {
 147     emit_compareUnsignedAndJump&lt;OpJbelow&gt;(currentInstruction, Below);
 148 }
 149 
 150 void JIT::emit_op_jbeloweq(const Instruction* currentInstruction)
 151 {
 152     emit_compareUnsignedAndJump&lt;OpJbeloweq&gt;(currentInstruction, BelowOrEqual);
 153 }
 154 
 155 #if USE(JSVALUE64)
 156 
 157 void JIT::emit_op_unsigned(const Instruction* currentInstruction)
 158 {
 159     auto bytecode = currentInstruction-&gt;as&lt;OpUnsigned&gt;();
<span class="line-modified"> 160     int result = bytecode.m_dst.offset();</span>
<span class="line-modified"> 161     int op1 = bytecode.m_operand.offset();</span>
 162 
 163     emitGetVirtualRegister(op1, regT0);
 164     emitJumpSlowCaseIfNotInt(regT0);
 165     addSlowCase(branch32(LessThan, regT0, TrustedImm32(0)));
 166     boxInt32(regT0, JSValueRegs { regT0 });
 167     emitPutVirtualRegister(result, regT0);
 168 }
 169 
 170 template&lt;typename Op&gt;
 171 void JIT::emit_compareAndJump(const Instruction* instruction, RelationalCondition condition)









 172 {
 173     // We generate inline code for the following cases in the fast path:
 174     // - int immediate to constant int immediate
 175     // - constant int immediate to int immediate
 176     // - int immediate to int immediate
 177 
<span class="line-removed"> 178     auto bytecode = instruction-&gt;as&lt;Op&gt;();</span>
<span class="line-removed"> 179     int op1 = bytecode.m_lhs.offset();</span>
<span class="line-removed"> 180     int op2 = bytecode.m_rhs.offset();</span>
<span class="line-removed"> 181     unsigned target = jumpTarget(instruction, bytecode.m_targetLabel);</span>
 182     bool disallowAllocation = false;
 183     if (isOperandConstantChar(op1)) {
 184         emitGetVirtualRegister(op2, regT0);
 185         addSlowCase(branchIfNotCell(regT0));
 186         JumpList failures;
 187         emitLoadCharacterString(regT0, regT0, failures);
 188         addSlowCase(failures);
 189         addJump(branch32(commute(condition), regT0, Imm32(asString(getConstantOperand(op1))-&gt;tryGetValue(disallowAllocation)[0])), target);
 190         return;
 191     }
 192     if (isOperandConstantChar(op2)) {
 193         emitGetVirtualRegister(op1, regT0);
 194         addSlowCase(branchIfNotCell(regT0));
 195         JumpList failures;
 196         emitLoadCharacterString(regT0, regT0, failures);
 197         addSlowCase(failures);
 198         addJump(branch32(condition, regT0, Imm32(asString(getConstantOperand(op2))-&gt;tryGetValue(disallowAllocation)[0])), target);
 199         return;
 200     }
 201     if (isOperandConstantInt(op2)) {
</pre>
<hr />
<pre>
 207     }
 208     if (isOperandConstantInt(op1)) {
 209         emitGetVirtualRegister(op2, regT1);
 210         emitJumpSlowCaseIfNotInt(regT1);
 211         int32_t op1imm = getOperandConstantInt(op1);
 212         addJump(branch32(commute(condition), regT1, Imm32(op1imm)), target);
 213         return;
 214     }
 215 
 216     emitGetVirtualRegisters(op1, regT0, op2, regT1);
 217     emitJumpSlowCaseIfNotInt(regT0);
 218     emitJumpSlowCaseIfNotInt(regT1);
 219 
 220     addJump(branch32(condition, regT0, regT1), target);
 221 }
 222 
 223 template&lt;typename Op&gt;
 224 void JIT::emit_compareUnsignedAndJump(const Instruction* instruction, RelationalCondition condition)
 225 {
 226     auto bytecode = instruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 227     int op1 = bytecode.m_lhs.offset();</span>
<span class="line-modified"> 228     int op2 = bytecode.m_rhs.offset();</span>
 229     unsigned target = jumpTarget(instruction, bytecode.m_targetLabel);





 230     if (isOperandConstantInt(op2)) {
 231         emitGetVirtualRegister(op1, regT0);
 232         int32_t op2imm = getOperandConstantInt(op2);
 233         addJump(branch32(condition, regT0, Imm32(op2imm)), target);
 234     } else if (isOperandConstantInt(op1)) {
 235         emitGetVirtualRegister(op2, regT1);
 236         int32_t op1imm = getOperandConstantInt(op1);
 237         addJump(branch32(commute(condition), regT1, Imm32(op1imm)), target);
 238     } else {
 239         emitGetVirtualRegisters(op1, regT0, op2, regT1);
 240         addJump(branch32(condition, regT0, regT1), target);
 241     }
 242 }
 243 
 244 template&lt;typename Op&gt;
 245 void JIT::emit_compareUnsigned(const Instruction* instruction, RelationalCondition condition)
 246 {
 247     auto bytecode = instruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 248     int dst = bytecode.m_dst.offset();</span>
<span class="line-modified"> 249     int op1 = bytecode.m_lhs.offset();</span>
<span class="line-modified"> 250     int op2 = bytecode.m_rhs.offset();</span>





 251     if (isOperandConstantInt(op2)) {
 252         emitGetVirtualRegister(op1, regT0);
 253         int32_t op2imm = getOperandConstantInt(op2);
 254         compare32(condition, regT0, Imm32(op2imm), regT0);
 255     } else if (isOperandConstantInt(op1)) {
 256         emitGetVirtualRegister(op2, regT0);
 257         int32_t op1imm = getOperandConstantInt(op1);
 258         compare32(commute(condition), regT0, Imm32(op1imm), regT0);
 259     } else {
 260         emitGetVirtualRegisters(op1, regT0, op2, regT1);
 261         compare32(condition, regT0, regT1, regT0);
 262     }
 263     boxBoolean(regT0, JSValueRegs { regT0 });
 264     emitPutVirtualRegister(dst);
 265 }
 266 
 267 template&lt;typename Op&gt;
<span class="line-modified"> 268 void JIT::emit_compareAndJumpSlow(const Instruction* instruction, DoubleCondition condition, size_t (JIT_OPERATION *operation)(ExecState*, EncodedJSValue, EncodedJSValue), bool invert, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)</span>
 269 {
 270     auto bytecode = instruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 271     int op1 = bytecode.m_lhs.offset();</span>
<span class="line-modified"> 272     int op2 = bytecode.m_rhs.offset();</span>
 273     unsigned target = jumpTarget(instruction, bytecode.m_targetLabel);





 274 
 275     // We generate inline code for the following cases in the slow path:
 276     // - floating-point number to constant int immediate
 277     // - constant int immediate to floating-point number
 278     // - floating-point number to floating-point number.
 279     if (isOperandConstantChar(op1) || isOperandConstantChar(op2)) {
 280         linkAllSlowCases(iter);
 281 
 282         emitGetVirtualRegister(op1, argumentGPR0);
 283         emitGetVirtualRegister(op2, argumentGPR1);
<span class="line-modified"> 284         callOperation(operation, argumentGPR0, argumentGPR1);</span>
 285         emitJumpSlowToHot(branchTest32(invert ? Zero : NonZero, returnValueGPR), target);
 286         return;
 287     }
 288 
 289     if (isOperandConstantInt(op2)) {
 290         linkAllSlowCases(iter);
 291 
 292         if (supportsFloatingPoint()) {
 293             Jump fail1 = branchIfNotNumber(regT0);
<span class="line-modified"> 294             add64(tagTypeNumberRegister, regT0);</span>
 295             move64ToDouble(regT0, fpRegT0);
 296 
 297             int32_t op2imm = getConstantOperand(op2).asInt32();
 298 
 299             move(Imm32(op2imm), regT1);
 300             convertInt32ToDouble(regT1, fpRegT1);
 301 
 302             emitJumpSlowToHot(branchDouble(condition, fpRegT0, fpRegT1), target);
 303 
<span class="line-modified"> 304             emitJumpSlowToHot(jump(), instruction-&gt;size());</span>
 305 
 306             fail1.link(this);
 307         }
 308 
 309         emitGetVirtualRegister(op2, regT1);
<span class="line-modified"> 310         callOperation(operation, regT0, regT1);</span>
 311         emitJumpSlowToHot(branchTest32(invert ? Zero : NonZero, returnValueGPR), target);
 312         return;
 313     }
 314 
 315     if (isOperandConstantInt(op1)) {
 316         linkAllSlowCases(iter);
 317 
 318         if (supportsFloatingPoint()) {
 319             Jump fail1 = branchIfNotNumber(regT1);
<span class="line-modified"> 320             add64(tagTypeNumberRegister, regT1);</span>
 321             move64ToDouble(regT1, fpRegT1);
 322 
 323             int32_t op1imm = getConstantOperand(op1).asInt32();
 324 
 325             move(Imm32(op1imm), regT0);
 326             convertInt32ToDouble(regT0, fpRegT0);
 327 
 328             emitJumpSlowToHot(branchDouble(condition, fpRegT0, fpRegT1), target);
 329 
<span class="line-modified"> 330             emitJumpSlowToHot(jump(), instruction-&gt;size());</span>
 331 
 332             fail1.link(this);
 333         }
 334 
 335         emitGetVirtualRegister(op1, regT2);
<span class="line-modified"> 336         callOperation(operation, regT2, regT1);</span>
 337         emitJumpSlowToHot(branchTest32(invert ? Zero : NonZero, returnValueGPR), target);
 338         return;
 339     }
 340 
 341     linkSlowCase(iter); // LHS is not Int.
 342 
 343     if (supportsFloatingPoint()) {
 344         Jump fail1 = branchIfNotNumber(regT0);
 345         Jump fail2 = branchIfNotNumber(regT1);
 346         Jump fail3 = branchIfInt32(regT1);
<span class="line-modified"> 347         add64(tagTypeNumberRegister, regT0);</span>
<span class="line-modified"> 348         add64(tagTypeNumberRegister, regT1);</span>
 349         move64ToDouble(regT0, fpRegT0);
 350         move64ToDouble(regT1, fpRegT1);
 351 
 352         emitJumpSlowToHot(branchDouble(condition, fpRegT0, fpRegT1), target);
 353 
<span class="line-modified"> 354         emitJumpSlowToHot(jump(), instruction-&gt;size());</span>
 355 
 356         fail1.link(this);
 357         fail2.link(this);
 358         fail3.link(this);
 359     }
 360 
 361     linkSlowCase(iter); // RHS is not Int.
<span class="line-modified"> 362     callOperation(operation, regT0, regT1);</span>
 363     emitJumpSlowToHot(branchTest32(invert ? Zero : NonZero, returnValueGPR), target);
 364 }
 365 
 366 void JIT::emit_op_inc(const Instruction* currentInstruction)
 367 {
 368     auto bytecode = currentInstruction-&gt;as&lt;OpInc&gt;();
<span class="line-modified"> 369     int srcDst = bytecode.m_srcDst.offset();</span>
 370 
 371     emitGetVirtualRegister(srcDst, regT0);
 372     emitJumpSlowCaseIfNotInt(regT0);
 373     addSlowCase(branchAdd32(Overflow, TrustedImm32(1), regT0));
 374     boxInt32(regT0, JSValueRegs { regT0 });
 375     emitPutVirtualRegister(srcDst);
 376 }
 377 
 378 void JIT::emit_op_dec(const Instruction* currentInstruction)
 379 {
 380     auto bytecode = currentInstruction-&gt;as&lt;OpDec&gt;();
<span class="line-modified"> 381     int srcDst = bytecode.m_srcDst.offset();</span>
 382 
 383     emitGetVirtualRegister(srcDst, regT0);
 384     emitJumpSlowCaseIfNotInt(regT0);
 385     addSlowCase(branchSub32(Overflow, TrustedImm32(1), regT0));
 386     boxInt32(regT0, JSValueRegs { regT0 });
 387     emitPutVirtualRegister(srcDst);
 388 }
 389 
 390 /* ------------------------------ BEGIN: OP_MOD ------------------------------ */
 391 
 392 #if CPU(X86_64)
 393 
 394 void JIT::emit_op_mod(const Instruction* currentInstruction)
 395 {
 396     auto bytecode = currentInstruction-&gt;as&lt;OpMod&gt;();
<span class="line-modified"> 397     int result = bytecode.m_dst.offset();</span>
<span class="line-modified"> 398     int op1 = bytecode.m_lhs.offset();</span>
<span class="line-modified"> 399     int op2 = bytecode.m_rhs.offset();</span>
 400 
 401     // Make sure registers are correct for x86 IDIV instructions.
 402     ASSERT(regT0 == X86Registers::eax);
 403     auto edx = X86Registers::edx;
 404     auto ecx = X86Registers::ecx;
 405     ASSERT(regT4 != edx);
 406     ASSERT(regT4 != ecx);
 407 
 408     emitGetVirtualRegisters(op1, regT4, op2, ecx);
 409     emitJumpSlowCaseIfNotInt(regT4);
 410     emitJumpSlowCaseIfNotInt(ecx);
 411 
 412     move(regT4, regT0);
 413     addSlowCase(branchTest32(Zero, ecx));
 414     Jump denominatorNotNeg1 = branch32(NotEqual, ecx, TrustedImm32(-1));
 415     addSlowCase(branch32(Equal, regT0, TrustedImm32(-2147483647-1)));
 416     denominatorNotNeg1.link(this);
 417     x86ConvertToDoubleWord32();
 418     x86Div32(ecx);
 419     Jump numeratorPositive = branch32(GreaterThanOrEqual, regT4, TrustedImm32(0));
</pre>
<hr />
<pre>
 435 
 436 void JIT::emit_op_mod(const Instruction* currentInstruction)
 437 {
 438     JITSlowPathCall slowPathCall(this, currentInstruction, slow_path_mod);
 439     slowPathCall.call();
 440 }
 441 
 442 void JIT::emitSlow_op_mod(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;)
 443 {
 444     UNREACHABLE_FOR_PLATFORM();
 445 }
 446 
 447 #endif // CPU(X86_64)
 448 
 449 /* ------------------------------ END: OP_MOD ------------------------------ */
 450 
 451 #endif // USE(JSVALUE64)
 452 
 453 void JIT::emit_op_negate(const Instruction* currentInstruction)
 454 {
<span class="line-modified"> 455     ArithProfile* arithProfile = &amp;currentInstruction-&gt;as&lt;OpNegate&gt;().metadata(m_codeBlock).m_arithProfile;</span>
 456     JITNegIC* negateIC = m_codeBlock-&gt;addJITNegIC(arithProfile);
 457     m_instructionToMathIC.add(currentInstruction, negateIC);
 458     emitMathICFast&lt;OpNegate&gt;(negateIC, currentInstruction, operationArithNegateProfiled, operationArithNegate);
 459 }
 460 
 461 void JIT::emitSlow_op_negate(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 462 {
 463     linkAllSlowCases(iter);
 464 
 465     JITNegIC* negIC = bitwise_cast&lt;JITNegIC*&gt;(m_instructionToMathIC.get(currentInstruction));
 466     emitMathICSlow&lt;OpNegate&gt;(negIC, currentInstruction, operationArithNegateProfiledOptimize, operationArithNegateProfiled, operationArithNegateOptimize);
 467 }
 468 
 469 template&lt;typename Op, typename SnippetGenerator&gt;
 470 void JIT::emitBitBinaryOpFastPath(const Instruction* currentInstruction, ProfilingPolicy profilingPolicy)
 471 {
 472     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 473     int result = bytecode.m_dst.offset();</span>
<span class="line-modified"> 474     int op1 = bytecode.m_lhs.offset();</span>
<span class="line-modified"> 475     int op2 = bytecode.m_rhs.offset();</span>
 476 
 477 #if USE(JSVALUE64)
 478     JSValueRegs leftRegs = JSValueRegs(regT0);
 479     JSValueRegs rightRegs = JSValueRegs(regT1);
 480     JSValueRegs resultRegs = leftRegs;
 481     GPRReg scratchGPR = regT2;
 482 #else
 483     JSValueRegs leftRegs = JSValueRegs(regT1, regT0);
 484     JSValueRegs rightRegs = JSValueRegs(regT3, regT2);
 485     JSValueRegs resultRegs = leftRegs;
 486     GPRReg scratchGPR = regT4;
 487 #endif
 488 
 489     SnippetOperand leftOperand;
 490     SnippetOperand rightOperand;
 491 
 492     if (isOperandConstantInt(op1))
 493         leftOperand.setConstInt32(getOperandConstantInt(op1));
 494     else if (isOperandConstantInt(op2))
 495         rightOperand.setConstInt32(getOperandConstantInt(op2));
</pre>
<hr />
<pre>
 500         emitGetVirtualRegister(op1, leftRegs);
 501     if (!rightOperand.isConst())
 502         emitGetVirtualRegister(op2, rightRegs);
 503 
 504     SnippetGenerator gen(leftOperand, rightOperand, resultRegs, leftRegs, rightRegs, scratchGPR);
 505 
 506     gen.generateFastPath(*this);
 507 
 508     ASSERT(gen.didEmitFastPath());
 509     gen.endJumpList().link(this);
 510     if (profilingPolicy == ProfilingPolicy::ShouldEmitProfiling)
 511         emitValueProfilingSiteIfProfiledOpcode(bytecode);
 512     emitPutVirtualRegister(result, resultRegs);
 513 
 514     addSlowCase(gen.slowPathJumpList());
 515 }
 516 
 517 void JIT::emit_op_bitnot(const Instruction* currentInstruction)
 518 {
 519     auto bytecode = currentInstruction-&gt;as&lt;OpBitnot&gt;();
<span class="line-modified"> 520     int result = bytecode.m_dst.offset();</span>
<span class="line-modified"> 521     int op1 = bytecode.m_operand.offset();</span>
 522 
 523 #if USE(JSVALUE64)
 524     JSValueRegs leftRegs = JSValueRegs(regT0);
 525 #else
 526     JSValueRegs leftRegs = JSValueRegs(regT1, regT0);
 527 #endif
 528 
 529     emitGetVirtualRegister(op1, leftRegs);
 530 
 531     addSlowCase(branchIfNotInt32(leftRegs));
 532     not32(leftRegs.payloadGPR());
 533 #if USE(JSVALUE64)
 534     boxInt32(leftRegs.payloadGPR(), leftRegs);
 535 #endif
 536 
 537     emitValueProfilingSiteIfProfiledOpcode(bytecode);
 538 
 539     emitPutVirtualRegister(result, leftRegs);
 540 }
 541 
</pre>
<hr />
<pre>
 561 
 562 void JIT::emitRightShiftFastPath(const Instruction* currentInstruction, OpcodeID opcodeID)
 563 {
 564     ASSERT(opcodeID == op_rshift || opcodeID == op_urshift);
 565     switch (opcodeID) {
 566     case op_rshift:
 567         emitRightShiftFastPath&lt;OpRshift&gt;(currentInstruction, JITRightShiftGenerator::SignedShift);
 568         break;
 569     case op_urshift:
 570         emitRightShiftFastPath&lt;OpUrshift&gt;(currentInstruction, JITRightShiftGenerator::UnsignedShift);
 571         break;
 572     default:
 573         ASSERT_NOT_REACHED();
 574     }
 575 }
 576 
 577 template&lt;typename Op&gt;
 578 void JIT::emitRightShiftFastPath(const Instruction* currentInstruction, JITRightShiftGenerator::ShiftType snippetShiftType)
 579 {
 580     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 581     int result = bytecode.m_dst.offset();</span>
<span class="line-modified"> 582     int op1 = bytecode.m_lhs.offset();</span>
<span class="line-modified"> 583     int op2 = bytecode.m_rhs.offset();</span>
 584 
 585 #if USE(JSVALUE64)
 586     JSValueRegs leftRegs = JSValueRegs(regT0);
 587     JSValueRegs rightRegs = JSValueRegs(regT1);
 588     JSValueRegs resultRegs = leftRegs;
 589     GPRReg scratchGPR = regT2;
 590     FPRReg scratchFPR = InvalidFPRReg;
 591 #else
 592     JSValueRegs leftRegs = JSValueRegs(regT1, regT0);
 593     JSValueRegs rightRegs = JSValueRegs(regT3, regT2);
 594     JSValueRegs resultRegs = leftRegs;
 595     GPRReg scratchGPR = regT4;
 596     FPRReg scratchFPR = fpRegT2;
 597 #endif
 598 
 599     SnippetOperand leftOperand;
 600     SnippetOperand rightOperand;
 601 
 602     if (isOperandConstantInt(op1))
 603         leftOperand.setConstInt32(getOperandConstantInt(op1));
</pre>
<hr />
<pre>
 616 
 617     gen.generateFastPath(*this);
 618 
 619     ASSERT(gen.didEmitFastPath());
 620     gen.endJumpList().link(this);
 621     emitPutVirtualRegister(result, resultRegs);
 622 
 623     addSlowCase(gen.slowPathJumpList());
 624 }
 625 
 626 void JIT::emit_op_rshift(const Instruction* currentInstruction)
 627 {
 628     emitRightShiftFastPath(currentInstruction, op_rshift);
 629 }
 630 
 631 void JIT::emit_op_urshift(const Instruction* currentInstruction)
 632 {
 633     emitRightShiftFastPath(currentInstruction, op_urshift);
 634 }
 635 
<span class="line-removed"> 636 ALWAYS_INLINE static OperandTypes getOperandTypes(const ArithProfile&amp; arithProfile)</span>
<span class="line-removed"> 637 {</span>
<span class="line-removed"> 638     return OperandTypes(arithProfile.lhsResultType(), arithProfile.rhsResultType());</span>
<span class="line-removed"> 639 }</span>
<span class="line-removed"> 640 </span>
 641 void JIT::emit_op_add(const Instruction* currentInstruction)
 642 {
<span class="line-modified"> 643     ArithProfile* arithProfile = &amp;currentInstruction-&gt;as&lt;OpAdd&gt;().metadata(m_codeBlock).m_arithProfile;</span>
 644     JITAddIC* addIC = m_codeBlock-&gt;addJITAddIC(arithProfile);
 645     m_instructionToMathIC.add(currentInstruction, addIC);
 646     emitMathICFast&lt;OpAdd&gt;(addIC, currentInstruction, operationValueAddProfiled, operationValueAdd);
 647 }
 648 
 649 void JIT::emitSlow_op_add(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 650 {
 651     linkAllSlowCases(iter);
 652 
 653     JITAddIC* addIC = bitwise_cast&lt;JITAddIC*&gt;(m_instructionToMathIC.get(currentInstruction));
 654     emitMathICSlow&lt;OpAdd&gt;(addIC, currentInstruction, operationValueAddProfiledOptimize, operationValueAddProfiled, operationValueAddOptimize);
 655 }
 656 
 657 template &lt;typename Op, typename Generator, typename ProfiledFunction, typename NonProfiledFunction&gt;
 658 void JIT::emitMathICFast(JITUnaryMathIC&lt;Generator&gt;* mathIC, const Instruction* currentInstruction, ProfiledFunction profiledFunction, NonProfiledFunction nonProfiledFunction)
 659 {
 660     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 661     int result = bytecode.m_dst.offset();</span>
<span class="line-modified"> 662     int operand = bytecode.m_operand.offset();</span>
 663 
 664 #if USE(JSVALUE64)
 665     // ArithNegate benefits from using the same register as src and dst.
 666     // Since regT1==argumentGPR1, using regT1 avoid shuffling register to call the slow path.
 667     JSValueRegs srcRegs = JSValueRegs(regT1);
 668     JSValueRegs resultRegs = JSValueRegs(regT1);
 669     GPRReg scratchGPR = regT2;
 670 #else
 671     JSValueRegs srcRegs = JSValueRegs(regT1, regT0);
 672     JSValueRegs resultRegs = JSValueRegs(regT3, regT2);
 673     GPRReg scratchGPR = regT4;
 674 #endif
 675 
 676 #if ENABLE(MATH_IC_STATS)
 677     auto inlineStart = label();
 678 #endif
 679 
 680     mathIC-&gt;m_generator = Generator(resultRegs, srcRegs, scratchGPR);
 681 
 682     emitGetVirtualRegister(operand, srcRegs);
 683 
 684     MathICGenerationState&amp; mathICGenerationState = m_instructionToMathICGenerationState.add(currentInstruction, MathICGenerationState()).iterator-&gt;value;
 685 
 686     bool generatedInlineCode = mathIC-&gt;generateInline(*this, mathICGenerationState);
 687     if (!generatedInlineCode) {
<span class="line-modified"> 688         ArithProfile* arithProfile = mathIC-&gt;arithProfile();</span>
 689         if (arithProfile &amp;&amp; shouldEmitProfiling())
<span class="line-modified"> 690             callOperationWithResult(profiledFunction, resultRegs, srcRegs, arithProfile);</span>
 691         else
<span class="line-modified"> 692             callOperationWithResult(nonProfiledFunction, resultRegs, srcRegs);</span>
 693     } else
 694         addSlowCase(mathICGenerationState.slowPathJumps);
 695 
 696 #if ENABLE(MATH_IC_STATS)
 697     auto inlineEnd = label();
 698     addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
 699         size_t size = linkBuffer.locationOf(inlineEnd).executableAddress&lt;char*&gt;() - linkBuffer.locationOf(inlineStart).executableAddress&lt;char*&gt;();
 700         mathIC-&gt;m_generatedCodeSize += size;
 701     });
 702 #endif
 703 
 704     emitPutVirtualRegister(result, resultRegs);
 705 }
 706 
 707 template &lt;typename Op, typename Generator, typename ProfiledFunction, typename NonProfiledFunction&gt;
 708 void JIT::emitMathICFast(JITBinaryMathIC&lt;Generator&gt;* mathIC, const Instruction* currentInstruction, ProfiledFunction profiledFunction, NonProfiledFunction nonProfiledFunction)
 709 {
 710     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 711     OperandTypes types = getOperandTypes(copiedArithProfile(bytecode));</span>
<span class="line-modified"> 712     int result = bytecode.m_dst.offset();</span>
<span class="line-modified"> 713     int op1 = bytecode.m_lhs.offset();</span>
<span class="line-removed"> 714     int op2 = bytecode.m_rhs.offset();</span>
 715 
 716 #if USE(JSVALUE64)
 717     JSValueRegs leftRegs = JSValueRegs(regT1);
 718     JSValueRegs rightRegs = JSValueRegs(regT2);
 719     JSValueRegs resultRegs = JSValueRegs(regT0);
 720     GPRReg scratchGPR = regT3;
 721     FPRReg scratchFPR = fpRegT2;
 722 #else
 723     JSValueRegs leftRegs = JSValueRegs(regT1, regT0);
 724     JSValueRegs rightRegs = JSValueRegs(regT3, regT2);
 725     JSValueRegs resultRegs = leftRegs;
 726     GPRReg scratchGPR = regT4;
 727     FPRReg scratchFPR = fpRegT2;
 728 #endif
 729 
<span class="line-modified"> 730     SnippetOperand leftOperand(types.first());</span>
<span class="line-modified"> 731     SnippetOperand rightOperand(types.second());</span>
 732 
 733     if (isOperandConstantInt(op1))
 734         leftOperand.setConstInt32(getOperandConstantInt(op1));
 735     else if (isOperandConstantInt(op2))
 736         rightOperand.setConstInt32(getOperandConstantInt(op2));
 737 
 738     RELEASE_ASSERT(!leftOperand.isConst() || !rightOperand.isConst());
 739 
 740     mathIC-&gt;m_generator = Generator(leftOperand, rightOperand, resultRegs, leftRegs, rightRegs, fpRegT0, fpRegT1, scratchGPR, scratchFPR);
 741 
 742     ASSERT(!(Generator::isLeftOperandValidConstant(leftOperand) &amp;&amp; Generator::isRightOperandValidConstant(rightOperand)));
 743 
 744     if (!Generator::isLeftOperandValidConstant(leftOperand))
 745         emitGetVirtualRegister(op1, leftRegs);
 746     if (!Generator::isRightOperandValidConstant(rightOperand))
 747         emitGetVirtualRegister(op2, rightRegs);
 748 
 749 #if ENABLE(MATH_IC_STATS)
 750     auto inlineStart = label();
 751 #endif
 752 
 753     MathICGenerationState&amp; mathICGenerationState = m_instructionToMathICGenerationState.add(currentInstruction, MathICGenerationState()).iterator-&gt;value;
 754 
 755     bool generatedInlineCode = mathIC-&gt;generateInline(*this, mathICGenerationState);
 756     if (!generatedInlineCode) {
 757         if (leftOperand.isConst())
 758             emitGetVirtualRegister(op1, leftRegs);
 759         else if (rightOperand.isConst())
 760             emitGetVirtualRegister(op2, rightRegs);
<span class="line-modified"> 761         ArithProfile* arithProfile = mathIC-&gt;arithProfile();</span>
 762         if (arithProfile &amp;&amp; shouldEmitProfiling())
<span class="line-modified"> 763             callOperationWithResult(profiledFunction, resultRegs, leftRegs, rightRegs, arithProfile);</span>
 764         else
<span class="line-modified"> 765             callOperationWithResult(nonProfiledFunction, resultRegs, leftRegs, rightRegs);</span>
 766     } else
 767         addSlowCase(mathICGenerationState.slowPathJumps);
 768 
 769 #if ENABLE(MATH_IC_STATS)
 770     auto inlineEnd = label();
 771     addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
 772         size_t size = linkBuffer.locationOf(inlineEnd).executableAddress&lt;char*&gt;() - linkBuffer.locationOf(inlineStart).executableAddress&lt;char*&gt;();
 773         mathIC-&gt;m_generatedCodeSize += size;
 774     });
 775 #endif
 776 
 777     emitPutVirtualRegister(result, resultRegs);
 778 }
 779 
 780 template &lt;typename Op, typename Generator, typename ProfiledRepatchFunction, typename ProfiledFunction, typename RepatchFunction&gt;
 781 void JIT::emitMathICSlow(JITUnaryMathIC&lt;Generator&gt;* mathIC, const Instruction* currentInstruction, ProfiledRepatchFunction profiledRepatchFunction, ProfiledFunction profiledFunction, RepatchFunction repatchFunction)
 782 {
 783     MathICGenerationState&amp; mathICGenerationState = m_instructionToMathICGenerationState.find(currentInstruction)-&gt;value;
 784     mathICGenerationState.slowPathStart = label();
 785 
 786     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 787     int result = bytecode.m_dst.offset();</span>
 788 
 789 #if USE(JSVALUE64)
 790     JSValueRegs srcRegs = JSValueRegs(regT1);
 791     JSValueRegs resultRegs = JSValueRegs(regT0);
 792 #else
 793     JSValueRegs srcRegs = JSValueRegs(regT1, regT0);
 794     JSValueRegs resultRegs = JSValueRegs(regT3, regT2);
 795 #endif
 796 
 797 #if ENABLE(MATH_IC_STATS)
 798     auto slowPathStart = label();
 799 #endif
 800 
<span class="line-modified"> 801     ArithProfile* arithProfile = mathIC-&gt;arithProfile();</span>
 802     if (arithProfile &amp;&amp; shouldEmitProfiling()) {
 803         if (mathICGenerationState.shouldSlowPathRepatch)
<span class="line-modified"> 804             mathICGenerationState.slowPathCall = callOperationWithResult(reinterpret_cast&lt;J_JITOperation_EJMic&gt;(profiledRepatchFunction), resultRegs, srcRegs, TrustedImmPtr(mathIC));</span>
 805         else
<span class="line-modified"> 806             mathICGenerationState.slowPathCall = callOperationWithResult(profiledFunction, resultRegs, srcRegs, arithProfile);</span>
 807     } else
<span class="line-modified"> 808         mathICGenerationState.slowPathCall = callOperationWithResult(reinterpret_cast&lt;J_JITOperation_EJMic&gt;(repatchFunction), resultRegs, srcRegs, TrustedImmPtr(mathIC));</span>
 809 
 810 #if ENABLE(MATH_IC_STATS)
 811     auto slowPathEnd = label();
 812     addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
 813         size_t size = linkBuffer.locationOf(slowPathEnd).executableAddress&lt;char*&gt;() - linkBuffer.locationOf(slowPathStart).executableAddress&lt;char*&gt;();
 814         mathIC-&gt;m_generatedCodeSize += size;
 815     });
 816 #endif
 817 
 818     emitPutVirtualRegister(result, resultRegs);
 819 
 820     addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
 821         MathICGenerationState&amp; mathICGenerationState = m_instructionToMathICGenerationState.find(currentInstruction)-&gt;value;
 822         mathIC-&gt;finalizeInlineCode(mathICGenerationState, linkBuffer);
 823     });
 824 }
 825 
 826 template &lt;typename Op, typename Generator, typename ProfiledRepatchFunction, typename ProfiledFunction, typename RepatchFunction&gt;
 827 void JIT::emitMathICSlow(JITBinaryMathIC&lt;Generator&gt;* mathIC, const Instruction* currentInstruction, ProfiledRepatchFunction profiledRepatchFunction, ProfiledFunction profiledFunction, RepatchFunction repatchFunction)
 828 {
 829     MathICGenerationState&amp; mathICGenerationState = m_instructionToMathICGenerationState.find(currentInstruction)-&gt;value;
 830     mathICGenerationState.slowPathStart = label();
 831 
 832     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 833     OperandTypes types = getOperandTypes(copiedArithProfile(bytecode));</span>
<span class="line-modified"> 834     int result = bytecode.m_dst.offset();</span>
<span class="line-modified"> 835     int op1 = bytecode.m_lhs.offset();</span>
<span class="line-removed"> 836     int op2 = bytecode.m_rhs.offset();</span>
 837 
 838 #if USE(JSVALUE64)
 839     JSValueRegs leftRegs = JSValueRegs(regT1);
 840     JSValueRegs rightRegs = JSValueRegs(regT2);
 841     JSValueRegs resultRegs = JSValueRegs(regT0);
 842 #else
 843     JSValueRegs leftRegs = JSValueRegs(regT1, regT0);
 844     JSValueRegs rightRegs = JSValueRegs(regT3, regT2);
 845     JSValueRegs resultRegs = leftRegs;
 846 #endif
 847 
<span class="line-modified"> 848     SnippetOperand leftOperand(types.first());</span>
<span class="line-modified"> 849     SnippetOperand rightOperand(types.second());</span>
 850 
 851     if (isOperandConstantInt(op1))
 852         leftOperand.setConstInt32(getOperandConstantInt(op1));
 853     else if (isOperandConstantInt(op2))
 854         rightOperand.setConstInt32(getOperandConstantInt(op2));
 855 
 856     ASSERT(!(Generator::isLeftOperandValidConstant(leftOperand) &amp;&amp; Generator::isRightOperandValidConstant(rightOperand)));
 857 
 858     if (Generator::isLeftOperandValidConstant(leftOperand))
 859         emitGetVirtualRegister(op1, leftRegs);
 860     else if (Generator::isRightOperandValidConstant(rightOperand))
 861         emitGetVirtualRegister(op2, rightRegs);
 862 
 863 #if ENABLE(MATH_IC_STATS)
 864     auto slowPathStart = label();
 865 #endif
 866 
<span class="line-modified"> 867     ArithProfile* arithProfile = mathIC-&gt;arithProfile();</span>
 868     if (arithProfile &amp;&amp; shouldEmitProfiling()) {
 869         if (mathICGenerationState.shouldSlowPathRepatch)
<span class="line-modified"> 870             mathICGenerationState.slowPathCall = callOperationWithResult(bitwise_cast&lt;J_JITOperation_EJJMic&gt;(profiledRepatchFunction), resultRegs, leftRegs, rightRegs, TrustedImmPtr(mathIC));</span>
 871         else
<span class="line-modified"> 872             mathICGenerationState.slowPathCall = callOperationWithResult(profiledFunction, resultRegs, leftRegs, rightRegs, arithProfile);</span>
 873     } else
<span class="line-modified"> 874         mathICGenerationState.slowPathCall = callOperationWithResult(bitwise_cast&lt;J_JITOperation_EJJMic&gt;(repatchFunction), resultRegs, leftRegs, rightRegs, TrustedImmPtr(mathIC));</span>
 875 
 876 #if ENABLE(MATH_IC_STATS)
 877     auto slowPathEnd = label();
 878     addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
 879         size_t size = linkBuffer.locationOf(slowPathEnd).executableAddress&lt;char*&gt;() - linkBuffer.locationOf(slowPathStart).executableAddress&lt;char*&gt;();
 880         mathIC-&gt;m_generatedCodeSize += size;
 881     });
 882 #endif
 883 
 884     emitPutVirtualRegister(result, resultRegs);
 885 
 886     addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
 887         MathICGenerationState&amp; mathICGenerationState = m_instructionToMathICGenerationState.find(currentInstruction)-&gt;value;
 888         mathIC-&gt;finalizeInlineCode(mathICGenerationState, linkBuffer);
 889     });
 890 }
 891 
 892 void JIT::emit_op_div(const Instruction* currentInstruction)
 893 {
 894     auto bytecode = currentInstruction-&gt;as&lt;OpDiv&gt;();
<span class="line-modified"> 895     auto&amp; metadata = bytecode.metadata(m_codeBlock);</span>
<span class="line-modified"> 896     int result = bytecode.m_dst.offset();</span>
<span class="line-modified"> 897     int op1 = bytecode.m_lhs.offset();</span>
<span class="line-removed"> 898     int op2 = bytecode.m_rhs.offset();</span>
 899 
 900 #if USE(JSVALUE64)
<span class="line-removed"> 901     OperandTypes types = getOperandTypes(metadata.m_arithProfile);</span>
 902     JSValueRegs leftRegs = JSValueRegs(regT0);
 903     JSValueRegs rightRegs = JSValueRegs(regT1);
 904     JSValueRegs resultRegs = leftRegs;
 905     GPRReg scratchGPR = regT2;
 906 #else
<span class="line-removed"> 907     OperandTypes types = getOperandTypes(metadata.m_arithProfile);</span>
 908     JSValueRegs leftRegs = JSValueRegs(regT1, regT0);
 909     JSValueRegs rightRegs = JSValueRegs(regT3, regT2);
 910     JSValueRegs resultRegs = leftRegs;
 911     GPRReg scratchGPR = regT4;
 912 #endif
 913     FPRReg scratchFPR = fpRegT2;
 914 
<span class="line-modified"> 915     ArithProfile* arithProfile = nullptr;</span>
 916     if (shouldEmitProfiling())
 917         arithProfile = &amp;currentInstruction-&gt;as&lt;OpDiv&gt;().metadata(m_codeBlock).m_arithProfile;
 918 
<span class="line-modified"> 919     SnippetOperand leftOperand(types.first());</span>
<span class="line-modified"> 920     SnippetOperand rightOperand(types.second());</span>
 921 
 922     if (isOperandConstantInt(op1))
 923         leftOperand.setConstInt32(getOperandConstantInt(op1));
 924 #if USE(JSVALUE64)
 925     else if (isOperandConstantDouble(op1))
 926         leftOperand.setConstDouble(getOperandConstantDouble(op1));
 927 #endif
 928     else if (isOperandConstantInt(op2))
 929         rightOperand.setConstInt32(getOperandConstantInt(op2));
 930 #if USE(JSVALUE64)
 931     else if (isOperandConstantDouble(op2))
 932         rightOperand.setConstDouble(getOperandConstantDouble(op2));
 933 #endif
 934 
 935     RELEASE_ASSERT(!leftOperand.isConst() || !rightOperand.isConst());
 936 
 937     if (!leftOperand.isConst())
 938         emitGetVirtualRegister(op1, leftRegs);
 939     if (!rightOperand.isConst())
 940         emitGetVirtualRegister(op2, rightRegs);
</pre>
<hr />
<pre>
 942     JITDivGenerator gen(leftOperand, rightOperand, resultRegs, leftRegs, rightRegs,
 943         fpRegT0, fpRegT1, scratchGPR, scratchFPR, arithProfile);
 944 
 945     gen.generateFastPath(*this);
 946 
 947     if (gen.didEmitFastPath()) {
 948         gen.endJumpList().link(this);
 949         emitPutVirtualRegister(result, resultRegs);
 950 
 951         addSlowCase(gen.slowPathJumpList());
 952     } else {
 953         ASSERT(gen.endJumpList().empty());
 954         ASSERT(gen.slowPathJumpList().empty());
 955         JITSlowPathCall slowPathCall(this, currentInstruction, slow_path_div);
 956         slowPathCall.call();
 957     }
 958 }
 959 
 960 void JIT::emit_op_mul(const Instruction* currentInstruction)
 961 {
<span class="line-modified"> 962     ArithProfile* arithProfile = &amp;currentInstruction-&gt;as&lt;OpMul&gt;().metadata(m_codeBlock).m_arithProfile;</span>
 963     JITMulIC* mulIC = m_codeBlock-&gt;addJITMulIC(arithProfile);
 964     m_instructionToMathIC.add(currentInstruction, mulIC);
 965     emitMathICFast&lt;OpMul&gt;(mulIC, currentInstruction, operationValueMulProfiled, operationValueMul);
 966 }
 967 
 968 void JIT::emitSlow_op_mul(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 969 {
 970     linkAllSlowCases(iter);
 971 
 972     JITMulIC* mulIC = bitwise_cast&lt;JITMulIC*&gt;(m_instructionToMathIC.get(currentInstruction));
 973     emitMathICSlow&lt;OpMul&gt;(mulIC, currentInstruction, operationValueMulProfiledOptimize, operationValueMulProfiled, operationValueMulOptimize);
 974 }
 975 
 976 void JIT::emit_op_sub(const Instruction* currentInstruction)
 977 {
<span class="line-modified"> 978     ArithProfile* arithProfile = &amp;currentInstruction-&gt;as&lt;OpSub&gt;().metadata(m_codeBlock).m_arithProfile;</span>
 979     JITSubIC* subIC = m_codeBlock-&gt;addJITSubIC(arithProfile);
 980     m_instructionToMathIC.add(currentInstruction, subIC);
 981     emitMathICFast&lt;OpSub&gt;(subIC, currentInstruction, operationValueSubProfiled, operationValueSub);
 982 }
 983 
 984 void JIT::emitSlow_op_sub(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 985 {
 986     linkAllSlowCases(iter);
 987 
 988     JITSubIC* subIC = bitwise_cast&lt;JITSubIC*&gt;(m_instructionToMathIC.get(currentInstruction));
 989     emitMathICSlow&lt;OpSub&gt;(subIC, currentInstruction, operationValueSubProfiledOptimize, operationValueSubProfiled, operationValueSubOptimize);
 990 }
 991 
 992 /* ------------------------------ END: OP_ADD, OP_SUB, OP_MUL, OP_POW ------------------------------ */
 993 
 994 } // namespace JSC
 995 
 996 #endif // ENABLE(JIT)
</pre>
</td>
<td>
<hr />
<pre>
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 
  28 #if ENABLE(JIT)
  29 #include &quot;JIT.h&quot;
  30 
  31 #include &quot;ArithProfile.h&quot;
<span class="line-added">  32 #include &quot;BytecodeGenerator.h&quot;</span>
  33 #include &quot;CodeBlock.h&quot;
  34 #include &quot;JITAddGenerator.h&quot;
  35 #include &quot;JITBitAndGenerator.h&quot;
  36 #include &quot;JITBitOrGenerator.h&quot;
  37 #include &quot;JITBitXorGenerator.h&quot;
  38 #include &quot;JITDivGenerator.h&quot;
  39 #include &quot;JITInlines.h&quot;
  40 #include &quot;JITLeftShiftGenerator.h&quot;
  41 #include &quot;JITMathIC.h&quot;
  42 #include &quot;JITMulGenerator.h&quot;
  43 #include &quot;JITNegGenerator.h&quot;
  44 #include &quot;JITOperations.h&quot;
  45 #include &quot;JITSubGenerator.h&quot;
  46 #include &quot;JSArray.h&quot;
  47 #include &quot;JSFunction.h&quot;
  48 #include &quot;Interpreter.h&quot;
  49 #include &quot;JSCInlines.h&quot;
  50 #include &quot;LinkBuffer.h&quot;
  51 #include &quot;ResultType.h&quot;
  52 #include &quot;SlowPathCall.h&quot;
</pre>
<hr />
<pre>
 141 void JIT::emit_op_beloweq(const Instruction* currentInstruction)
 142 {
 143     emit_compareUnsigned&lt;OpBeloweq&gt;(currentInstruction, BelowOrEqual);
 144 }
 145 
 146 void JIT::emit_op_jbelow(const Instruction* currentInstruction)
 147 {
 148     emit_compareUnsignedAndJump&lt;OpJbelow&gt;(currentInstruction, Below);
 149 }
 150 
 151 void JIT::emit_op_jbeloweq(const Instruction* currentInstruction)
 152 {
 153     emit_compareUnsignedAndJump&lt;OpJbeloweq&gt;(currentInstruction, BelowOrEqual);
 154 }
 155 
 156 #if USE(JSVALUE64)
 157 
 158 void JIT::emit_op_unsigned(const Instruction* currentInstruction)
 159 {
 160     auto bytecode = currentInstruction-&gt;as&lt;OpUnsigned&gt;();
<span class="line-modified"> 161     VirtualRegister result = bytecode.m_dst;</span>
<span class="line-modified"> 162     VirtualRegister op1 = bytecode.m_operand;</span>
 163 
 164     emitGetVirtualRegister(op1, regT0);
 165     emitJumpSlowCaseIfNotInt(regT0);
 166     addSlowCase(branch32(LessThan, regT0, TrustedImm32(0)));
 167     boxInt32(regT0, JSValueRegs { regT0 });
 168     emitPutVirtualRegister(result, regT0);
 169 }
 170 
 171 template&lt;typename Op&gt;
 172 void JIT::emit_compareAndJump(const Instruction* instruction, RelationalCondition condition)
<span class="line-added"> 173 {</span>
<span class="line-added"> 174     auto bytecode = instruction-&gt;as&lt;Op&gt;();</span>
<span class="line-added"> 175     VirtualRegister op1 = bytecode.m_lhs;</span>
<span class="line-added"> 176     VirtualRegister op2 = bytecode.m_rhs;</span>
<span class="line-added"> 177     unsigned target = jumpTarget(instruction, bytecode.m_targetLabel);</span>
<span class="line-added"> 178     emit_compareAndJumpImpl(op1, op2, target, condition);</span>
<span class="line-added"> 179 }</span>
<span class="line-added"> 180 </span>
<span class="line-added"> 181 void JIT::emit_compareAndJumpImpl(VirtualRegister op1, VirtualRegister op2, unsigned target, RelationalCondition condition)</span>
 182 {
 183     // We generate inline code for the following cases in the fast path:
 184     // - int immediate to constant int immediate
 185     // - constant int immediate to int immediate
 186     // - int immediate to int immediate
 187 




 188     bool disallowAllocation = false;
 189     if (isOperandConstantChar(op1)) {
 190         emitGetVirtualRegister(op2, regT0);
 191         addSlowCase(branchIfNotCell(regT0));
 192         JumpList failures;
 193         emitLoadCharacterString(regT0, regT0, failures);
 194         addSlowCase(failures);
 195         addJump(branch32(commute(condition), regT0, Imm32(asString(getConstantOperand(op1))-&gt;tryGetValue(disallowAllocation)[0])), target);
 196         return;
 197     }
 198     if (isOperandConstantChar(op2)) {
 199         emitGetVirtualRegister(op1, regT0);
 200         addSlowCase(branchIfNotCell(regT0));
 201         JumpList failures;
 202         emitLoadCharacterString(regT0, regT0, failures);
 203         addSlowCase(failures);
 204         addJump(branch32(condition, regT0, Imm32(asString(getConstantOperand(op2))-&gt;tryGetValue(disallowAllocation)[0])), target);
 205         return;
 206     }
 207     if (isOperandConstantInt(op2)) {
</pre>
<hr />
<pre>
 213     }
 214     if (isOperandConstantInt(op1)) {
 215         emitGetVirtualRegister(op2, regT1);
 216         emitJumpSlowCaseIfNotInt(regT1);
 217         int32_t op1imm = getOperandConstantInt(op1);
 218         addJump(branch32(commute(condition), regT1, Imm32(op1imm)), target);
 219         return;
 220     }
 221 
 222     emitGetVirtualRegisters(op1, regT0, op2, regT1);
 223     emitJumpSlowCaseIfNotInt(regT0);
 224     emitJumpSlowCaseIfNotInt(regT1);
 225 
 226     addJump(branch32(condition, regT0, regT1), target);
 227 }
 228 
 229 template&lt;typename Op&gt;
 230 void JIT::emit_compareUnsignedAndJump(const Instruction* instruction, RelationalCondition condition)
 231 {
 232     auto bytecode = instruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 233     VirtualRegister op1 = bytecode.m_lhs;</span>
<span class="line-modified"> 234     VirtualRegister op2 = bytecode.m_rhs;</span>
 235     unsigned target = jumpTarget(instruction, bytecode.m_targetLabel);
<span class="line-added"> 236     emit_compareUnsignedAndJumpImpl(op1, op2, target, condition);</span>
<span class="line-added"> 237 }</span>
<span class="line-added"> 238 </span>
<span class="line-added"> 239 void JIT::emit_compareUnsignedAndJumpImpl(VirtualRegister op1, VirtualRegister op2, unsigned target, RelationalCondition condition)</span>
<span class="line-added"> 240 {</span>
 241     if (isOperandConstantInt(op2)) {
 242         emitGetVirtualRegister(op1, regT0);
 243         int32_t op2imm = getOperandConstantInt(op2);
 244         addJump(branch32(condition, regT0, Imm32(op2imm)), target);
 245     } else if (isOperandConstantInt(op1)) {
 246         emitGetVirtualRegister(op2, regT1);
 247         int32_t op1imm = getOperandConstantInt(op1);
 248         addJump(branch32(commute(condition), regT1, Imm32(op1imm)), target);
 249     } else {
 250         emitGetVirtualRegisters(op1, regT0, op2, regT1);
 251         addJump(branch32(condition, regT0, regT1), target);
 252     }
 253 }
 254 
 255 template&lt;typename Op&gt;
 256 void JIT::emit_compareUnsigned(const Instruction* instruction, RelationalCondition condition)
 257 {
 258     auto bytecode = instruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 259     VirtualRegister dst = bytecode.m_dst;</span>
<span class="line-modified"> 260     VirtualRegister op1 = bytecode.m_lhs;</span>
<span class="line-modified"> 261     VirtualRegister op2 = bytecode.m_rhs;</span>
<span class="line-added"> 262     emit_compareUnsignedImpl(dst, op1, op2, condition);</span>
<span class="line-added"> 263 }</span>
<span class="line-added"> 264 </span>
<span class="line-added"> 265 void JIT::emit_compareUnsignedImpl(VirtualRegister dst, VirtualRegister op1, VirtualRegister op2, RelationalCondition condition)</span>
<span class="line-added"> 266 {</span>
 267     if (isOperandConstantInt(op2)) {
 268         emitGetVirtualRegister(op1, regT0);
 269         int32_t op2imm = getOperandConstantInt(op2);
 270         compare32(condition, regT0, Imm32(op2imm), regT0);
 271     } else if (isOperandConstantInt(op1)) {
 272         emitGetVirtualRegister(op2, regT0);
 273         int32_t op1imm = getOperandConstantInt(op1);
 274         compare32(commute(condition), regT0, Imm32(op1imm), regT0);
 275     } else {
 276         emitGetVirtualRegisters(op1, regT0, op2, regT1);
 277         compare32(condition, regT0, regT1, regT0);
 278     }
 279     boxBoolean(regT0, JSValueRegs { regT0 });
 280     emitPutVirtualRegister(dst);
 281 }
 282 
 283 template&lt;typename Op&gt;
<span class="line-modified"> 284 void JIT::emit_compareAndJumpSlow(const Instruction* instruction, DoubleCondition condition, size_t (JIT_OPERATION *operation)(JSGlobalObject*, EncodedJSValue, EncodedJSValue), bool invert, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)</span>
 285 {
 286     auto bytecode = instruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 287     VirtualRegister op1 = bytecode.m_lhs;</span>
<span class="line-modified"> 288     VirtualRegister op2 = bytecode.m_rhs;</span>
 289     unsigned target = jumpTarget(instruction, bytecode.m_targetLabel);
<span class="line-added"> 290     emit_compareAndJumpSlowImpl(op1, op2, target, instruction-&gt;size(), condition, operation, invert, iter);</span>
<span class="line-added"> 291 }</span>
<span class="line-added"> 292 </span>
<span class="line-added"> 293 void JIT::emit_compareAndJumpSlowImpl(VirtualRegister op1, VirtualRegister op2, unsigned target, size_t instructionSize, DoubleCondition condition, size_t (JIT_OPERATION *operation)(JSGlobalObject*, EncodedJSValue, EncodedJSValue), bool invert, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)</span>
<span class="line-added"> 294 {</span>
 295 
 296     // We generate inline code for the following cases in the slow path:
 297     // - floating-point number to constant int immediate
 298     // - constant int immediate to floating-point number
 299     // - floating-point number to floating-point number.
 300     if (isOperandConstantChar(op1) || isOperandConstantChar(op2)) {
 301         linkAllSlowCases(iter);
 302 
 303         emitGetVirtualRegister(op1, argumentGPR0);
 304         emitGetVirtualRegister(op2, argumentGPR1);
<span class="line-modified"> 305         callOperation(operation, TrustedImmPtr(m_codeBlock-&gt;globalObject()), argumentGPR0, argumentGPR1);</span>
 306         emitJumpSlowToHot(branchTest32(invert ? Zero : NonZero, returnValueGPR), target);
 307         return;
 308     }
 309 
 310     if (isOperandConstantInt(op2)) {
 311         linkAllSlowCases(iter);
 312 
 313         if (supportsFloatingPoint()) {
 314             Jump fail1 = branchIfNotNumber(regT0);
<span class="line-modified"> 315             add64(numberTagRegister, regT0);</span>
 316             move64ToDouble(regT0, fpRegT0);
 317 
 318             int32_t op2imm = getConstantOperand(op2).asInt32();
 319 
 320             move(Imm32(op2imm), regT1);
 321             convertInt32ToDouble(regT1, fpRegT1);
 322 
 323             emitJumpSlowToHot(branchDouble(condition, fpRegT0, fpRegT1), target);
 324 
<span class="line-modified"> 325             emitJumpSlowToHot(jump(), instructionSize);</span>
 326 
 327             fail1.link(this);
 328         }
 329 
 330         emitGetVirtualRegister(op2, regT1);
<span class="line-modified"> 331         callOperation(operation, TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0, regT1);</span>
 332         emitJumpSlowToHot(branchTest32(invert ? Zero : NonZero, returnValueGPR), target);
 333         return;
 334     }
 335 
 336     if (isOperandConstantInt(op1)) {
 337         linkAllSlowCases(iter);
 338 
 339         if (supportsFloatingPoint()) {
 340             Jump fail1 = branchIfNotNumber(regT1);
<span class="line-modified"> 341             add64(numberTagRegister, regT1);</span>
 342             move64ToDouble(regT1, fpRegT1);
 343 
 344             int32_t op1imm = getConstantOperand(op1).asInt32();
 345 
 346             move(Imm32(op1imm), regT0);
 347             convertInt32ToDouble(regT0, fpRegT0);
 348 
 349             emitJumpSlowToHot(branchDouble(condition, fpRegT0, fpRegT1), target);
 350 
<span class="line-modified"> 351             emitJumpSlowToHot(jump(), instructionSize);</span>
 352 
 353             fail1.link(this);
 354         }
 355 
 356         emitGetVirtualRegister(op1, regT2);
<span class="line-modified"> 357         callOperation(operation, TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT2, regT1);</span>
 358         emitJumpSlowToHot(branchTest32(invert ? Zero : NonZero, returnValueGPR), target);
 359         return;
 360     }
 361 
 362     linkSlowCase(iter); // LHS is not Int.
 363 
 364     if (supportsFloatingPoint()) {
 365         Jump fail1 = branchIfNotNumber(regT0);
 366         Jump fail2 = branchIfNotNumber(regT1);
 367         Jump fail3 = branchIfInt32(regT1);
<span class="line-modified"> 368         add64(numberTagRegister, regT0);</span>
<span class="line-modified"> 369         add64(numberTagRegister, regT1);</span>
 370         move64ToDouble(regT0, fpRegT0);
 371         move64ToDouble(regT1, fpRegT1);
 372 
 373         emitJumpSlowToHot(branchDouble(condition, fpRegT0, fpRegT1), target);
 374 
<span class="line-modified"> 375         emitJumpSlowToHot(jump(), instructionSize);</span>
 376 
 377         fail1.link(this);
 378         fail2.link(this);
 379         fail3.link(this);
 380     }
 381 
 382     linkSlowCase(iter); // RHS is not Int.
<span class="line-modified"> 383     callOperation(operation, TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0, regT1);</span>
 384     emitJumpSlowToHot(branchTest32(invert ? Zero : NonZero, returnValueGPR), target);
 385 }
 386 
 387 void JIT::emit_op_inc(const Instruction* currentInstruction)
 388 {
 389     auto bytecode = currentInstruction-&gt;as&lt;OpInc&gt;();
<span class="line-modified"> 390     VirtualRegister srcDst = bytecode.m_srcDst;</span>
 391 
 392     emitGetVirtualRegister(srcDst, regT0);
 393     emitJumpSlowCaseIfNotInt(regT0);
 394     addSlowCase(branchAdd32(Overflow, TrustedImm32(1), regT0));
 395     boxInt32(regT0, JSValueRegs { regT0 });
 396     emitPutVirtualRegister(srcDst);
 397 }
 398 
 399 void JIT::emit_op_dec(const Instruction* currentInstruction)
 400 {
 401     auto bytecode = currentInstruction-&gt;as&lt;OpDec&gt;();
<span class="line-modified"> 402     VirtualRegister srcDst = bytecode.m_srcDst;</span>
 403 
 404     emitGetVirtualRegister(srcDst, regT0);
 405     emitJumpSlowCaseIfNotInt(regT0);
 406     addSlowCase(branchSub32(Overflow, TrustedImm32(1), regT0));
 407     boxInt32(regT0, JSValueRegs { regT0 });
 408     emitPutVirtualRegister(srcDst);
 409 }
 410 
 411 /* ------------------------------ BEGIN: OP_MOD ------------------------------ */
 412 
 413 #if CPU(X86_64)
 414 
 415 void JIT::emit_op_mod(const Instruction* currentInstruction)
 416 {
 417     auto bytecode = currentInstruction-&gt;as&lt;OpMod&gt;();
<span class="line-modified"> 418     VirtualRegister result = bytecode.m_dst;</span>
<span class="line-modified"> 419     VirtualRegister op1 = bytecode.m_lhs;</span>
<span class="line-modified"> 420     VirtualRegister op2 = bytecode.m_rhs;</span>
 421 
 422     // Make sure registers are correct for x86 IDIV instructions.
 423     ASSERT(regT0 == X86Registers::eax);
 424     auto edx = X86Registers::edx;
 425     auto ecx = X86Registers::ecx;
 426     ASSERT(regT4 != edx);
 427     ASSERT(regT4 != ecx);
 428 
 429     emitGetVirtualRegisters(op1, regT4, op2, ecx);
 430     emitJumpSlowCaseIfNotInt(regT4);
 431     emitJumpSlowCaseIfNotInt(ecx);
 432 
 433     move(regT4, regT0);
 434     addSlowCase(branchTest32(Zero, ecx));
 435     Jump denominatorNotNeg1 = branch32(NotEqual, ecx, TrustedImm32(-1));
 436     addSlowCase(branch32(Equal, regT0, TrustedImm32(-2147483647-1)));
 437     denominatorNotNeg1.link(this);
 438     x86ConvertToDoubleWord32();
 439     x86Div32(ecx);
 440     Jump numeratorPositive = branch32(GreaterThanOrEqual, regT4, TrustedImm32(0));
</pre>
<hr />
<pre>
 456 
 457 void JIT::emit_op_mod(const Instruction* currentInstruction)
 458 {
 459     JITSlowPathCall slowPathCall(this, currentInstruction, slow_path_mod);
 460     slowPathCall.call();
 461 }
 462 
 463 void JIT::emitSlow_op_mod(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;)
 464 {
 465     UNREACHABLE_FOR_PLATFORM();
 466 }
 467 
 468 #endif // CPU(X86_64)
 469 
 470 /* ------------------------------ END: OP_MOD ------------------------------ */
 471 
 472 #endif // USE(JSVALUE64)
 473 
 474 void JIT::emit_op_negate(const Instruction* currentInstruction)
 475 {
<span class="line-modified"> 476     UnaryArithProfile* arithProfile = &amp;currentInstruction-&gt;as&lt;OpNegate&gt;().metadata(m_codeBlock).m_arithProfile;</span>
 477     JITNegIC* negateIC = m_codeBlock-&gt;addJITNegIC(arithProfile);
 478     m_instructionToMathIC.add(currentInstruction, negateIC);
 479     emitMathICFast&lt;OpNegate&gt;(negateIC, currentInstruction, operationArithNegateProfiled, operationArithNegate);
 480 }
 481 
 482 void JIT::emitSlow_op_negate(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 483 {
 484     linkAllSlowCases(iter);
 485 
 486     JITNegIC* negIC = bitwise_cast&lt;JITNegIC*&gt;(m_instructionToMathIC.get(currentInstruction));
 487     emitMathICSlow&lt;OpNegate&gt;(negIC, currentInstruction, operationArithNegateProfiledOptimize, operationArithNegateProfiled, operationArithNegateOptimize);
 488 }
 489 
 490 template&lt;typename Op, typename SnippetGenerator&gt;
 491 void JIT::emitBitBinaryOpFastPath(const Instruction* currentInstruction, ProfilingPolicy profilingPolicy)
 492 {
 493     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 494     VirtualRegister result = bytecode.m_dst;</span>
<span class="line-modified"> 495     VirtualRegister op1 = bytecode.m_lhs;</span>
<span class="line-modified"> 496     VirtualRegister op2 = bytecode.m_rhs;</span>
 497 
 498 #if USE(JSVALUE64)
 499     JSValueRegs leftRegs = JSValueRegs(regT0);
 500     JSValueRegs rightRegs = JSValueRegs(regT1);
 501     JSValueRegs resultRegs = leftRegs;
 502     GPRReg scratchGPR = regT2;
 503 #else
 504     JSValueRegs leftRegs = JSValueRegs(regT1, regT0);
 505     JSValueRegs rightRegs = JSValueRegs(regT3, regT2);
 506     JSValueRegs resultRegs = leftRegs;
 507     GPRReg scratchGPR = regT4;
 508 #endif
 509 
 510     SnippetOperand leftOperand;
 511     SnippetOperand rightOperand;
 512 
 513     if (isOperandConstantInt(op1))
 514         leftOperand.setConstInt32(getOperandConstantInt(op1));
 515     else if (isOperandConstantInt(op2))
 516         rightOperand.setConstInt32(getOperandConstantInt(op2));
</pre>
<hr />
<pre>
 521         emitGetVirtualRegister(op1, leftRegs);
 522     if (!rightOperand.isConst())
 523         emitGetVirtualRegister(op2, rightRegs);
 524 
 525     SnippetGenerator gen(leftOperand, rightOperand, resultRegs, leftRegs, rightRegs, scratchGPR);
 526 
 527     gen.generateFastPath(*this);
 528 
 529     ASSERT(gen.didEmitFastPath());
 530     gen.endJumpList().link(this);
 531     if (profilingPolicy == ProfilingPolicy::ShouldEmitProfiling)
 532         emitValueProfilingSiteIfProfiledOpcode(bytecode);
 533     emitPutVirtualRegister(result, resultRegs);
 534 
 535     addSlowCase(gen.slowPathJumpList());
 536 }
 537 
 538 void JIT::emit_op_bitnot(const Instruction* currentInstruction)
 539 {
 540     auto bytecode = currentInstruction-&gt;as&lt;OpBitnot&gt;();
<span class="line-modified"> 541     VirtualRegister result = bytecode.m_dst;</span>
<span class="line-modified"> 542     VirtualRegister op1 = bytecode.m_operand;</span>
 543 
 544 #if USE(JSVALUE64)
 545     JSValueRegs leftRegs = JSValueRegs(regT0);
 546 #else
 547     JSValueRegs leftRegs = JSValueRegs(regT1, regT0);
 548 #endif
 549 
 550     emitGetVirtualRegister(op1, leftRegs);
 551 
 552     addSlowCase(branchIfNotInt32(leftRegs));
 553     not32(leftRegs.payloadGPR());
 554 #if USE(JSVALUE64)
 555     boxInt32(leftRegs.payloadGPR(), leftRegs);
 556 #endif
 557 
 558     emitValueProfilingSiteIfProfiledOpcode(bytecode);
 559 
 560     emitPutVirtualRegister(result, leftRegs);
 561 }
 562 
</pre>
<hr />
<pre>
 582 
 583 void JIT::emitRightShiftFastPath(const Instruction* currentInstruction, OpcodeID opcodeID)
 584 {
 585     ASSERT(opcodeID == op_rshift || opcodeID == op_urshift);
 586     switch (opcodeID) {
 587     case op_rshift:
 588         emitRightShiftFastPath&lt;OpRshift&gt;(currentInstruction, JITRightShiftGenerator::SignedShift);
 589         break;
 590     case op_urshift:
 591         emitRightShiftFastPath&lt;OpUrshift&gt;(currentInstruction, JITRightShiftGenerator::UnsignedShift);
 592         break;
 593     default:
 594         ASSERT_NOT_REACHED();
 595     }
 596 }
 597 
 598 template&lt;typename Op&gt;
 599 void JIT::emitRightShiftFastPath(const Instruction* currentInstruction, JITRightShiftGenerator::ShiftType snippetShiftType)
 600 {
 601     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 602     VirtualRegister result = bytecode.m_dst;</span>
<span class="line-modified"> 603     VirtualRegister op1 = bytecode.m_lhs;</span>
<span class="line-modified"> 604     VirtualRegister op2 = bytecode.m_rhs;</span>
 605 
 606 #if USE(JSVALUE64)
 607     JSValueRegs leftRegs = JSValueRegs(regT0);
 608     JSValueRegs rightRegs = JSValueRegs(regT1);
 609     JSValueRegs resultRegs = leftRegs;
 610     GPRReg scratchGPR = regT2;
 611     FPRReg scratchFPR = InvalidFPRReg;
 612 #else
 613     JSValueRegs leftRegs = JSValueRegs(regT1, regT0);
 614     JSValueRegs rightRegs = JSValueRegs(regT3, regT2);
 615     JSValueRegs resultRegs = leftRegs;
 616     GPRReg scratchGPR = regT4;
 617     FPRReg scratchFPR = fpRegT2;
 618 #endif
 619 
 620     SnippetOperand leftOperand;
 621     SnippetOperand rightOperand;
 622 
 623     if (isOperandConstantInt(op1))
 624         leftOperand.setConstInt32(getOperandConstantInt(op1));
</pre>
<hr />
<pre>
 637 
 638     gen.generateFastPath(*this);
 639 
 640     ASSERT(gen.didEmitFastPath());
 641     gen.endJumpList().link(this);
 642     emitPutVirtualRegister(result, resultRegs);
 643 
 644     addSlowCase(gen.slowPathJumpList());
 645 }
 646 
 647 void JIT::emit_op_rshift(const Instruction* currentInstruction)
 648 {
 649     emitRightShiftFastPath(currentInstruction, op_rshift);
 650 }
 651 
 652 void JIT::emit_op_urshift(const Instruction* currentInstruction)
 653 {
 654     emitRightShiftFastPath(currentInstruction, op_urshift);
 655 }
 656 





 657 void JIT::emit_op_add(const Instruction* currentInstruction)
 658 {
<span class="line-modified"> 659     BinaryArithProfile* arithProfile = &amp;currentInstruction-&gt;as&lt;OpAdd&gt;().metadata(m_codeBlock).m_arithProfile;</span>
 660     JITAddIC* addIC = m_codeBlock-&gt;addJITAddIC(arithProfile);
 661     m_instructionToMathIC.add(currentInstruction, addIC);
 662     emitMathICFast&lt;OpAdd&gt;(addIC, currentInstruction, operationValueAddProfiled, operationValueAdd);
 663 }
 664 
 665 void JIT::emitSlow_op_add(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 666 {
 667     linkAllSlowCases(iter);
 668 
 669     JITAddIC* addIC = bitwise_cast&lt;JITAddIC*&gt;(m_instructionToMathIC.get(currentInstruction));
 670     emitMathICSlow&lt;OpAdd&gt;(addIC, currentInstruction, operationValueAddProfiledOptimize, operationValueAddProfiled, operationValueAddOptimize);
 671 }
 672 
 673 template &lt;typename Op, typename Generator, typename ProfiledFunction, typename NonProfiledFunction&gt;
 674 void JIT::emitMathICFast(JITUnaryMathIC&lt;Generator&gt;* mathIC, const Instruction* currentInstruction, ProfiledFunction profiledFunction, NonProfiledFunction nonProfiledFunction)
 675 {
 676     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 677     VirtualRegister result = bytecode.m_dst;</span>
<span class="line-modified"> 678     VirtualRegister operand = bytecode.m_operand;</span>
 679 
 680 #if USE(JSVALUE64)
 681     // ArithNegate benefits from using the same register as src and dst.
 682     // Since regT1==argumentGPR1, using regT1 avoid shuffling register to call the slow path.
 683     JSValueRegs srcRegs = JSValueRegs(regT1);
 684     JSValueRegs resultRegs = JSValueRegs(regT1);
 685     GPRReg scratchGPR = regT2;
 686 #else
 687     JSValueRegs srcRegs = JSValueRegs(regT1, regT0);
 688     JSValueRegs resultRegs = JSValueRegs(regT3, regT2);
 689     GPRReg scratchGPR = regT4;
 690 #endif
 691 
 692 #if ENABLE(MATH_IC_STATS)
 693     auto inlineStart = label();
 694 #endif
 695 
 696     mathIC-&gt;m_generator = Generator(resultRegs, srcRegs, scratchGPR);
 697 
 698     emitGetVirtualRegister(operand, srcRegs);
 699 
 700     MathICGenerationState&amp; mathICGenerationState = m_instructionToMathICGenerationState.add(currentInstruction, MathICGenerationState()).iterator-&gt;value;
 701 
 702     bool generatedInlineCode = mathIC-&gt;generateInline(*this, mathICGenerationState);
 703     if (!generatedInlineCode) {
<span class="line-modified"> 704         UnaryArithProfile* arithProfile = mathIC-&gt;arithProfile();</span>
 705         if (arithProfile &amp;&amp; shouldEmitProfiling())
<span class="line-modified"> 706             callOperationWithResult(profiledFunction, resultRegs, TrustedImmPtr(m_codeBlock-&gt;globalObject()), srcRegs, arithProfile);</span>
 707         else
<span class="line-modified"> 708             callOperationWithResult(nonProfiledFunction, resultRegs, TrustedImmPtr(m_codeBlock-&gt;globalObject()), srcRegs);</span>
 709     } else
 710         addSlowCase(mathICGenerationState.slowPathJumps);
 711 
 712 #if ENABLE(MATH_IC_STATS)
 713     auto inlineEnd = label();
 714     addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
 715         size_t size = linkBuffer.locationOf(inlineEnd).executableAddress&lt;char*&gt;() - linkBuffer.locationOf(inlineStart).executableAddress&lt;char*&gt;();
 716         mathIC-&gt;m_generatedCodeSize += size;
 717     });
 718 #endif
 719 
 720     emitPutVirtualRegister(result, resultRegs);
 721 }
 722 
 723 template &lt;typename Op, typename Generator, typename ProfiledFunction, typename NonProfiledFunction&gt;
 724 void JIT::emitMathICFast(JITBinaryMathIC&lt;Generator&gt;* mathIC, const Instruction* currentInstruction, ProfiledFunction profiledFunction, NonProfiledFunction nonProfiledFunction)
 725 {
 726     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 727     VirtualRegister result = bytecode.m_dst;</span>
<span class="line-modified"> 728     VirtualRegister op1 = bytecode.m_lhs;</span>
<span class="line-modified"> 729     VirtualRegister op2 = bytecode.m_rhs;</span>

 730 
 731 #if USE(JSVALUE64)
 732     JSValueRegs leftRegs = JSValueRegs(regT1);
 733     JSValueRegs rightRegs = JSValueRegs(regT2);
 734     JSValueRegs resultRegs = JSValueRegs(regT0);
 735     GPRReg scratchGPR = regT3;
 736     FPRReg scratchFPR = fpRegT2;
 737 #else
 738     JSValueRegs leftRegs = JSValueRegs(regT1, regT0);
 739     JSValueRegs rightRegs = JSValueRegs(regT3, regT2);
 740     JSValueRegs resultRegs = leftRegs;
 741     GPRReg scratchGPR = regT4;
 742     FPRReg scratchFPR = fpRegT2;
 743 #endif
 744 
<span class="line-modified"> 745     SnippetOperand leftOperand(bytecode.m_operandTypes.first());</span>
<span class="line-modified"> 746     SnippetOperand rightOperand(bytecode.m_operandTypes.second());</span>
 747 
 748     if (isOperandConstantInt(op1))
 749         leftOperand.setConstInt32(getOperandConstantInt(op1));
 750     else if (isOperandConstantInt(op2))
 751         rightOperand.setConstInt32(getOperandConstantInt(op2));
 752 
 753     RELEASE_ASSERT(!leftOperand.isConst() || !rightOperand.isConst());
 754 
 755     mathIC-&gt;m_generator = Generator(leftOperand, rightOperand, resultRegs, leftRegs, rightRegs, fpRegT0, fpRegT1, scratchGPR, scratchFPR);
 756 
 757     ASSERT(!(Generator::isLeftOperandValidConstant(leftOperand) &amp;&amp; Generator::isRightOperandValidConstant(rightOperand)));
 758 
 759     if (!Generator::isLeftOperandValidConstant(leftOperand))
 760         emitGetVirtualRegister(op1, leftRegs);
 761     if (!Generator::isRightOperandValidConstant(rightOperand))
 762         emitGetVirtualRegister(op2, rightRegs);
 763 
 764 #if ENABLE(MATH_IC_STATS)
 765     auto inlineStart = label();
 766 #endif
 767 
 768     MathICGenerationState&amp; mathICGenerationState = m_instructionToMathICGenerationState.add(currentInstruction, MathICGenerationState()).iterator-&gt;value;
 769 
 770     bool generatedInlineCode = mathIC-&gt;generateInline(*this, mathICGenerationState);
 771     if (!generatedInlineCode) {
 772         if (leftOperand.isConst())
 773             emitGetVirtualRegister(op1, leftRegs);
 774         else if (rightOperand.isConst())
 775             emitGetVirtualRegister(op2, rightRegs);
<span class="line-modified"> 776         BinaryArithProfile* arithProfile = mathIC-&gt;arithProfile();</span>
 777         if (arithProfile &amp;&amp; shouldEmitProfiling())
<span class="line-modified"> 778             callOperationWithResult(profiledFunction, resultRegs, TrustedImmPtr(m_codeBlock-&gt;globalObject()), leftRegs, rightRegs, arithProfile);</span>
 779         else
<span class="line-modified"> 780             callOperationWithResult(nonProfiledFunction, resultRegs, TrustedImmPtr(m_codeBlock-&gt;globalObject()), leftRegs, rightRegs);</span>
 781     } else
 782         addSlowCase(mathICGenerationState.slowPathJumps);
 783 
 784 #if ENABLE(MATH_IC_STATS)
 785     auto inlineEnd = label();
 786     addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
 787         size_t size = linkBuffer.locationOf(inlineEnd).executableAddress&lt;char*&gt;() - linkBuffer.locationOf(inlineStart).executableAddress&lt;char*&gt;();
 788         mathIC-&gt;m_generatedCodeSize += size;
 789     });
 790 #endif
 791 
 792     emitPutVirtualRegister(result, resultRegs);
 793 }
 794 
 795 template &lt;typename Op, typename Generator, typename ProfiledRepatchFunction, typename ProfiledFunction, typename RepatchFunction&gt;
 796 void JIT::emitMathICSlow(JITUnaryMathIC&lt;Generator&gt;* mathIC, const Instruction* currentInstruction, ProfiledRepatchFunction profiledRepatchFunction, ProfiledFunction profiledFunction, RepatchFunction repatchFunction)
 797 {
 798     MathICGenerationState&amp; mathICGenerationState = m_instructionToMathICGenerationState.find(currentInstruction)-&gt;value;
 799     mathICGenerationState.slowPathStart = label();
 800 
 801     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 802     VirtualRegister result = bytecode.m_dst;</span>
 803 
 804 #if USE(JSVALUE64)
 805     JSValueRegs srcRegs = JSValueRegs(regT1);
 806     JSValueRegs resultRegs = JSValueRegs(regT0);
 807 #else
 808     JSValueRegs srcRegs = JSValueRegs(regT1, regT0);
 809     JSValueRegs resultRegs = JSValueRegs(regT3, regT2);
 810 #endif
 811 
 812 #if ENABLE(MATH_IC_STATS)
 813     auto slowPathStart = label();
 814 #endif
 815 
<span class="line-modified"> 816     UnaryArithProfile* arithProfile = mathIC-&gt;arithProfile();</span>
 817     if (arithProfile &amp;&amp; shouldEmitProfiling()) {
 818         if (mathICGenerationState.shouldSlowPathRepatch)
<span class="line-modified"> 819             mathICGenerationState.slowPathCall = callOperationWithResult(reinterpret_cast&lt;J_JITOperation_GJMic&gt;(profiledRepatchFunction), resultRegs, TrustedImmPtr(m_codeBlock-&gt;globalObject()), srcRegs, TrustedImmPtr(mathIC));</span>
 820         else
<span class="line-modified"> 821             mathICGenerationState.slowPathCall = callOperationWithResult(profiledFunction, resultRegs, TrustedImmPtr(m_codeBlock-&gt;globalObject()), srcRegs, arithProfile);</span>
 822     } else
<span class="line-modified"> 823         mathICGenerationState.slowPathCall = callOperationWithResult(reinterpret_cast&lt;J_JITOperation_GJMic&gt;(repatchFunction), resultRegs, TrustedImmPtr(m_codeBlock-&gt;globalObject()), srcRegs, TrustedImmPtr(mathIC));</span>
 824 
 825 #if ENABLE(MATH_IC_STATS)
 826     auto slowPathEnd = label();
 827     addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
 828         size_t size = linkBuffer.locationOf(slowPathEnd).executableAddress&lt;char*&gt;() - linkBuffer.locationOf(slowPathStart).executableAddress&lt;char*&gt;();
 829         mathIC-&gt;m_generatedCodeSize += size;
 830     });
 831 #endif
 832 
 833     emitPutVirtualRegister(result, resultRegs);
 834 
 835     addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
 836         MathICGenerationState&amp; mathICGenerationState = m_instructionToMathICGenerationState.find(currentInstruction)-&gt;value;
 837         mathIC-&gt;finalizeInlineCode(mathICGenerationState, linkBuffer);
 838     });
 839 }
 840 
 841 template &lt;typename Op, typename Generator, typename ProfiledRepatchFunction, typename ProfiledFunction, typename RepatchFunction&gt;
 842 void JIT::emitMathICSlow(JITBinaryMathIC&lt;Generator&gt;* mathIC, const Instruction* currentInstruction, ProfiledRepatchFunction profiledRepatchFunction, ProfiledFunction profiledFunction, RepatchFunction repatchFunction)
 843 {
 844     MathICGenerationState&amp; mathICGenerationState = m_instructionToMathICGenerationState.find(currentInstruction)-&gt;value;
 845     mathICGenerationState.slowPathStart = label();
 846 
 847     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
<span class="line-modified"> 848     VirtualRegister result = bytecode.m_dst;</span>
<span class="line-modified"> 849     VirtualRegister op1 = bytecode.m_lhs;</span>
<span class="line-modified"> 850     VirtualRegister op2 = bytecode.m_rhs;</span>

 851 
 852 #if USE(JSVALUE64)
 853     JSValueRegs leftRegs = JSValueRegs(regT1);
 854     JSValueRegs rightRegs = JSValueRegs(regT2);
 855     JSValueRegs resultRegs = JSValueRegs(regT0);
 856 #else
 857     JSValueRegs leftRegs = JSValueRegs(regT1, regT0);
 858     JSValueRegs rightRegs = JSValueRegs(regT3, regT2);
 859     JSValueRegs resultRegs = leftRegs;
 860 #endif
 861 
<span class="line-modified"> 862     SnippetOperand leftOperand(bytecode.m_operandTypes.first());</span>
<span class="line-modified"> 863     SnippetOperand rightOperand(bytecode.m_operandTypes.second());</span>
 864 
 865     if (isOperandConstantInt(op1))
 866         leftOperand.setConstInt32(getOperandConstantInt(op1));
 867     else if (isOperandConstantInt(op2))
 868         rightOperand.setConstInt32(getOperandConstantInt(op2));
 869 
 870     ASSERT(!(Generator::isLeftOperandValidConstant(leftOperand) &amp;&amp; Generator::isRightOperandValidConstant(rightOperand)));
 871 
 872     if (Generator::isLeftOperandValidConstant(leftOperand))
 873         emitGetVirtualRegister(op1, leftRegs);
 874     else if (Generator::isRightOperandValidConstant(rightOperand))
 875         emitGetVirtualRegister(op2, rightRegs);
 876 
 877 #if ENABLE(MATH_IC_STATS)
 878     auto slowPathStart = label();
 879 #endif
 880 
<span class="line-modified"> 881     BinaryArithProfile* arithProfile = mathIC-&gt;arithProfile();</span>
 882     if (arithProfile &amp;&amp; shouldEmitProfiling()) {
 883         if (mathICGenerationState.shouldSlowPathRepatch)
<span class="line-modified"> 884             mathICGenerationState.slowPathCall = callOperationWithResult(bitwise_cast&lt;J_JITOperation_GJJMic&gt;(profiledRepatchFunction), resultRegs, TrustedImmPtr(m_codeBlock-&gt;globalObject()), leftRegs, rightRegs, TrustedImmPtr(mathIC));</span>
 885         else
<span class="line-modified"> 886             mathICGenerationState.slowPathCall = callOperationWithResult(profiledFunction, resultRegs, TrustedImmPtr(m_codeBlock-&gt;globalObject()), leftRegs, rightRegs, arithProfile);</span>
 887     } else
<span class="line-modified"> 888         mathICGenerationState.slowPathCall = callOperationWithResult(bitwise_cast&lt;J_JITOperation_GJJMic&gt;(repatchFunction), resultRegs, TrustedImmPtr(m_codeBlock-&gt;globalObject()), leftRegs, rightRegs, TrustedImmPtr(mathIC));</span>
 889 
 890 #if ENABLE(MATH_IC_STATS)
 891     auto slowPathEnd = label();
 892     addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
 893         size_t size = linkBuffer.locationOf(slowPathEnd).executableAddress&lt;char*&gt;() - linkBuffer.locationOf(slowPathStart).executableAddress&lt;char*&gt;();
 894         mathIC-&gt;m_generatedCodeSize += size;
 895     });
 896 #endif
 897 
 898     emitPutVirtualRegister(result, resultRegs);
 899 
 900     addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
 901         MathICGenerationState&amp; mathICGenerationState = m_instructionToMathICGenerationState.find(currentInstruction)-&gt;value;
 902         mathIC-&gt;finalizeInlineCode(mathICGenerationState, linkBuffer);
 903     });
 904 }
 905 
 906 void JIT::emit_op_div(const Instruction* currentInstruction)
 907 {
 908     auto bytecode = currentInstruction-&gt;as&lt;OpDiv&gt;();
<span class="line-modified"> 909     VirtualRegister result = bytecode.m_dst;</span>
<span class="line-modified"> 910     VirtualRegister op1 = bytecode.m_lhs;</span>
<span class="line-modified"> 911     VirtualRegister op2 = bytecode.m_rhs;</span>

 912 
 913 #if USE(JSVALUE64)

 914     JSValueRegs leftRegs = JSValueRegs(regT0);
 915     JSValueRegs rightRegs = JSValueRegs(regT1);
 916     JSValueRegs resultRegs = leftRegs;
 917     GPRReg scratchGPR = regT2;
 918 #else

 919     JSValueRegs leftRegs = JSValueRegs(regT1, regT0);
 920     JSValueRegs rightRegs = JSValueRegs(regT3, regT2);
 921     JSValueRegs resultRegs = leftRegs;
 922     GPRReg scratchGPR = regT4;
 923 #endif
 924     FPRReg scratchFPR = fpRegT2;
 925 
<span class="line-modified"> 926     BinaryArithProfile* arithProfile = nullptr;</span>
 927     if (shouldEmitProfiling())
 928         arithProfile = &amp;currentInstruction-&gt;as&lt;OpDiv&gt;().metadata(m_codeBlock).m_arithProfile;
 929 
<span class="line-modified"> 930     SnippetOperand leftOperand(bytecode.m_operandTypes.first());</span>
<span class="line-modified"> 931     SnippetOperand rightOperand(bytecode.m_operandTypes.second());</span>
 932 
 933     if (isOperandConstantInt(op1))
 934         leftOperand.setConstInt32(getOperandConstantInt(op1));
 935 #if USE(JSVALUE64)
 936     else if (isOperandConstantDouble(op1))
 937         leftOperand.setConstDouble(getOperandConstantDouble(op1));
 938 #endif
 939     else if (isOperandConstantInt(op2))
 940         rightOperand.setConstInt32(getOperandConstantInt(op2));
 941 #if USE(JSVALUE64)
 942     else if (isOperandConstantDouble(op2))
 943         rightOperand.setConstDouble(getOperandConstantDouble(op2));
 944 #endif
 945 
 946     RELEASE_ASSERT(!leftOperand.isConst() || !rightOperand.isConst());
 947 
 948     if (!leftOperand.isConst())
 949         emitGetVirtualRegister(op1, leftRegs);
 950     if (!rightOperand.isConst())
 951         emitGetVirtualRegister(op2, rightRegs);
</pre>
<hr />
<pre>
 953     JITDivGenerator gen(leftOperand, rightOperand, resultRegs, leftRegs, rightRegs,
 954         fpRegT0, fpRegT1, scratchGPR, scratchFPR, arithProfile);
 955 
 956     gen.generateFastPath(*this);
 957 
 958     if (gen.didEmitFastPath()) {
 959         gen.endJumpList().link(this);
 960         emitPutVirtualRegister(result, resultRegs);
 961 
 962         addSlowCase(gen.slowPathJumpList());
 963     } else {
 964         ASSERT(gen.endJumpList().empty());
 965         ASSERT(gen.slowPathJumpList().empty());
 966         JITSlowPathCall slowPathCall(this, currentInstruction, slow_path_div);
 967         slowPathCall.call();
 968     }
 969 }
 970 
 971 void JIT::emit_op_mul(const Instruction* currentInstruction)
 972 {
<span class="line-modified"> 973     BinaryArithProfile* arithProfile = &amp;currentInstruction-&gt;as&lt;OpMul&gt;().metadata(m_codeBlock).m_arithProfile;</span>
 974     JITMulIC* mulIC = m_codeBlock-&gt;addJITMulIC(arithProfile);
 975     m_instructionToMathIC.add(currentInstruction, mulIC);
 976     emitMathICFast&lt;OpMul&gt;(mulIC, currentInstruction, operationValueMulProfiled, operationValueMul);
 977 }
 978 
 979 void JIT::emitSlow_op_mul(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 980 {
 981     linkAllSlowCases(iter);
 982 
 983     JITMulIC* mulIC = bitwise_cast&lt;JITMulIC*&gt;(m_instructionToMathIC.get(currentInstruction));
 984     emitMathICSlow&lt;OpMul&gt;(mulIC, currentInstruction, operationValueMulProfiledOptimize, operationValueMulProfiled, operationValueMulOptimize);
 985 }
 986 
 987 void JIT::emit_op_sub(const Instruction* currentInstruction)
 988 {
<span class="line-modified"> 989     BinaryArithProfile* arithProfile = &amp;currentInstruction-&gt;as&lt;OpSub&gt;().metadata(m_codeBlock).m_arithProfile;</span>
 990     JITSubIC* subIC = m_codeBlock-&gt;addJITSubIC(arithProfile);
 991     m_instructionToMathIC.add(currentInstruction, subIC);
 992     emitMathICFast&lt;OpSub&gt;(subIC, currentInstruction, operationValueSubProfiled, operationValueSub);
 993 }
 994 
 995 void JIT::emitSlow_op_sub(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 996 {
 997     linkAllSlowCases(iter);
 998 
 999     JITSubIC* subIC = bitwise_cast&lt;JITSubIC*&gt;(m_instructionToMathIC.get(currentInstruction));
1000     emitMathICSlow&lt;OpSub&gt;(subIC, currentInstruction, operationValueSubProfiledOptimize, operationValueSubProfiled, operationValueSubOptimize);
1001 }
1002 
1003 /* ------------------------------ END: OP_ADD, OP_SUB, OP_MUL, OP_POW ------------------------------ */
1004 
1005 } // namespace JSC
1006 
1007 #endif // ENABLE(JIT)
</pre>
</td>
</tr>
</table>
<center><a href="JITAddGenerator.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="JITArithmetic32_64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>