<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/bytecode/InlineAccess.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="InByIdVariant.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="InlineCallFrame.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/bytecode/InlineAccess.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
135         jit.patchableBranch32(
136             MacroAssembler::NotEqual,
137             MacroAssembler::Address(base, JSCell::structureIDOffset()),
138             MacroAssembler::TrustedImm32(0x000ab21ca));
139 
140         jit.loadPtr(MacroAssembler::Address(base, JSObject::butterflyOffset()), value);
141         jit.storeValue(
142             regs,
143             MacroAssembler::Address(base, 120342));
144 
145         dataLog(&quot;replace out of line cache size: &quot;, jit.m_assembler.buffer().codeSize(), &quot;\n&quot;);
146     }
147 
148     CRASH();
149 }
150 
151 
152 template &lt;typename Function&gt;
153 ALWAYS_INLINE static bool linkCodeInline(const char* name, CCallHelpers&amp; jit, StructureStubInfo&amp; stubInfo, const Function&amp; function)
154 {
<span class="line-modified">155     if (jit.m_assembler.buffer().codeSize() &lt;= stubInfo.patch.inlineSize()) {</span>
156         bool needsBranchCompaction = true;
<span class="line-modified">157         LinkBuffer linkBuffer(jit, stubInfo.patch.start, stubInfo.patch.inlineSize(), JITCompilationMustSucceed, needsBranchCompaction);</span>
158         ASSERT(linkBuffer.isValid());
159         function(linkBuffer);
160         FINALIZE_CODE(linkBuffer, NoPtrTag, &quot;InlineAccessType: &#39;%s&#39;&quot;, name);
161         return true;
162     }
163 
164     // This is helpful when determining the size for inline ICs on various
165     // platforms. You want to choose a size that usually succeeds, but sometimes
166     // there may be variability in the length of the code we generate just because
167     // of randomness. It&#39;s helpful to flip this on when running tests or browsing
168     // the web just to see how often it fails. You don&#39;t want an IC size that always fails.
169     constexpr bool failIfCantInline = false;
170     if (failIfCantInline) {
171         dataLog(&quot;Failure for: &quot;, name, &quot;\n&quot;);
<span class="line-modified">172         dataLog(&quot;real size: &quot;, jit.m_assembler.buffer().codeSize(), &quot; inline size:&quot;, stubInfo.patch.inlineSize(), &quot;\n&quot;);</span>
173         CRASH();
174     }
175 
176     return false;
177 }
178 
179 bool InlineAccess::generateSelfPropertyAccess(StructureStubInfo&amp; stubInfo, Structure* structure, PropertyOffset offset)
180 {



181     CCallHelpers jit;
182 
<span class="line-modified">183     GPRReg base = stubInfo.baseGPR();</span>
184     JSValueRegs value = stubInfo.valueRegs();
185 
186     auto branchToSlowPath = jit.patchableBranch32(
187         MacroAssembler::NotEqual,
188         MacroAssembler::Address(base, JSCell::structureIDOffset()),
189         MacroAssembler::TrustedImm32(bitwise_cast&lt;uint32_t&gt;(structure-&gt;id())));
190     GPRReg storage;
191     if (isInlineOffset(offset))
192         storage = base;
193     else {
194         jit.loadPtr(CCallHelpers::Address(base, JSObject::butterflyOffset()), value.payloadGPR());
195         storage = value.payloadGPR();
196     }
197 
198     jit.loadValue(
199         MacroAssembler::Address(storage, offsetRelativeToBase(offset)), value);
200 
201     bool linkedCodeInline = linkCodeInline(&quot;property access&quot;, jit, stubInfo, [&amp;] (LinkBuffer&amp; linkBuffer) {
<span class="line-modified">202         linkBuffer.link(branchToSlowPath, stubInfo.slowPathStartLocation());</span>
203     });
204     return linkedCodeInline;
205 }
206 
207 ALWAYS_INLINE static GPRReg getScratchRegister(StructureStubInfo&amp; stubInfo)
208 {
<span class="line-modified">209     ScratchRegisterAllocator allocator(stubInfo.patch.usedRegisters);</span>
<span class="line-modified">210     allocator.lock(stubInfo.baseGPR());</span>
<span class="line-modified">211     allocator.lock(stubInfo.patch.valueGPR);</span>
212 #if USE(JSVALUE32_64)
<span class="line-modified">213     allocator.lock(stubInfo.patch.baseTagGPR);</span>
<span class="line-modified">214     allocator.lock(stubInfo.patch.valueTagGPR);</span>
215 #endif
216     GPRReg scratch = allocator.allocateScratchGPR();
217     if (allocator.didReuseRegisters())
218         return InvalidGPRReg;
219     return scratch;
220 }
221 
222 ALWAYS_INLINE static bool hasFreeRegister(StructureStubInfo&amp; stubInfo)
223 {
224     return getScratchRegister(stubInfo) != InvalidGPRReg;
225 }
226 
227 bool InlineAccess::canGenerateSelfPropertyReplace(StructureStubInfo&amp; stubInfo, PropertyOffset offset)
228 {



229     if (isInlineOffset(offset))
230         return true;
231 
232     return hasFreeRegister(stubInfo);
233 }
234 
235 bool InlineAccess::generateSelfPropertyReplace(StructureStubInfo&amp; stubInfo, Structure* structure, PropertyOffset offset)
236 {



237     ASSERT(canGenerateSelfPropertyReplace(stubInfo, offset));
238 
239     CCallHelpers jit;
240 
<span class="line-modified">241     GPRReg base = stubInfo.baseGPR();</span>
242     JSValueRegs value = stubInfo.valueRegs();
243 
244     auto branchToSlowPath = jit.patchableBranch32(
245         MacroAssembler::NotEqual,
246         MacroAssembler::Address(base, JSCell::structureIDOffset()),
247         MacroAssembler::TrustedImm32(bitwise_cast&lt;uint32_t&gt;(structure-&gt;id())));
248 
249     GPRReg storage;
250     if (isInlineOffset(offset))
251         storage = base;
252     else {
253         storage = getScratchRegister(stubInfo);
254         ASSERT(storage != InvalidGPRReg);
255         jit.loadPtr(CCallHelpers::Address(base, JSObject::butterflyOffset()), storage);
256     }
257 
258     jit.storeValue(
259         value, MacroAssembler::Address(storage, offsetRelativeToBase(offset)));
260 
261     bool linkedCodeInline = linkCodeInline(&quot;property replace&quot;, jit, stubInfo, [&amp;] (LinkBuffer&amp; linkBuffer) {
<span class="line-modified">262         linkBuffer.link(branchToSlowPath, stubInfo.slowPathStartLocation());</span>
263     });
264     return linkedCodeInline;
265 }
266 
267 bool InlineAccess::isCacheableArrayLength(StructureStubInfo&amp; stubInfo, JSArray* array)
268 {
269     ASSERT(array-&gt;indexingType() &amp; IsArray);
270 



271     if (!hasFreeRegister(stubInfo))
272         return false;
273 
274     return !hasAnyArrayStorage(array-&gt;indexingType()) &amp;&amp; array-&gt;indexingType() != ArrayClass;
275 }
276 
277 bool InlineAccess::generateArrayLength(StructureStubInfo&amp; stubInfo, JSArray* array)
278 {
279     ASSERT(isCacheableArrayLength(stubInfo, array));
280 



281     CCallHelpers jit;
282 
<span class="line-modified">283     GPRReg base = stubInfo.baseGPR();</span>
284     JSValueRegs value = stubInfo.valueRegs();
285     GPRReg scratch = getScratchRegister(stubInfo);
286 
287     jit.load8(CCallHelpers::Address(base, JSCell::indexingTypeAndMiscOffset()), scratch);
288     jit.and32(CCallHelpers::TrustedImm32(IndexingTypeMask), scratch);
289     auto branchToSlowPath = jit.patchableBranch32(
290         CCallHelpers::NotEqual, scratch, CCallHelpers::TrustedImm32(array-&gt;indexingType()));
291     jit.loadPtr(CCallHelpers::Address(base, JSObject::butterflyOffset()), value.payloadGPR());
292     jit.load32(CCallHelpers::Address(value.payloadGPR(), ArrayStorage::lengthOffset()), value.payloadGPR());
293     jit.boxInt32(value.payloadGPR(), value);
294 
295     bool linkedCodeInline = linkCodeInline(&quot;array length&quot;, jit, stubInfo, [&amp;] (LinkBuffer&amp; linkBuffer) {
<span class="line-modified">296         linkBuffer.link(branchToSlowPath, stubInfo.slowPathStartLocation());</span>
297     });
298     return linkedCodeInline;
299 }
300 
301 bool InlineAccess::isCacheableStringLength(StructureStubInfo&amp; stubInfo)
302 {



303     return hasFreeRegister(stubInfo);
304 }
305 
306 bool InlineAccess::generateStringLength(StructureStubInfo&amp; stubInfo)
307 {
308     ASSERT(isCacheableStringLength(stubInfo));
309 



310     CCallHelpers jit;
311 
<span class="line-modified">312     GPRReg base = stubInfo.baseGPR();</span>
313     JSValueRegs value = stubInfo.valueRegs();
314     GPRReg scratch = getScratchRegister(stubInfo);
315 
316     auto branchToSlowPath = jit.patchableBranch8(
317         CCallHelpers::NotEqual,
318         CCallHelpers::Address(base, JSCell::typeInfoTypeOffset()),
319         CCallHelpers::TrustedImm32(StringType));
320 
321     jit.loadPtr(CCallHelpers::Address(base, JSString::offsetOfValue()), scratch);
322     auto isRope = jit.branchIfRopeStringImpl(scratch);
323     jit.load32(CCallHelpers::Address(scratch, StringImpl::lengthMemoryOffset()), value.payloadGPR());
324     auto done = jit.jump();
325 
326     isRope.link(&amp;jit);
327     jit.load32(CCallHelpers::Address(base, JSRopeString::offsetOfLength()), value.payloadGPR());
328 
329     done.link(&amp;jit);
330     jit.boxInt32(value.payloadGPR(), value);
331 
332     bool linkedCodeInline = linkCodeInline(&quot;string length&quot;, jit, stubInfo, [&amp;] (LinkBuffer&amp; linkBuffer) {
<span class="line-modified">333         linkBuffer.link(branchToSlowPath, stubInfo.slowPathStartLocation());</span>
334     });
335     return linkedCodeInline;
336 }
337 
338 
339 bool InlineAccess::generateSelfInAccess(StructureStubInfo&amp; stubInfo, Structure* structure)
340 {
341     CCallHelpers jit;
342 
<span class="line-modified">343     GPRReg base = stubInfo.baseGPR();</span>



344     JSValueRegs value = stubInfo.valueRegs();
345 
346     auto branchToSlowPath = jit.patchableBranch32(
347         MacroAssembler::NotEqual,
348         MacroAssembler::Address(base, JSCell::structureIDOffset()),
349         MacroAssembler::TrustedImm32(bitwise_cast&lt;uint32_t&gt;(structure-&gt;id())));
350     jit.boxBoolean(true, value);
351 
352     bool linkedCodeInline = linkCodeInline(&quot;in access&quot;, jit, stubInfo, [&amp;] (LinkBuffer&amp; linkBuffer) {
<span class="line-modified">353         linkBuffer.link(branchToSlowPath, stubInfo.slowPathStartLocation());</span>
354     });
355     return linkedCodeInline;
356 }
357 
358 void InlineAccess::rewireStubAsJump(StructureStubInfo&amp; stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt; target)
359 {
360     CCallHelpers jit;
361 
362     auto jump = jit.jump();
363 
364     // We don&#39;t need a nop sled here because nobody should be jumping into the middle of an IC.
365     bool needsBranchCompaction = false;
<span class="line-modified">366     LinkBuffer linkBuffer(jit, stubInfo.patch.start, jit.m_assembler.buffer().codeSize(), JITCompilationMustSucceed, needsBranchCompaction);</span>
367     RELEASE_ASSERT(linkBuffer.isValid());
368     linkBuffer.link(jump, target);
369 
370     FINALIZE_CODE(linkBuffer, NoPtrTag, &quot;InlineAccess: linking constant jump&quot;);
371 }
372 
373 } // namespace JSC
374 
375 #endif // ENABLE(JIT)
</pre>
</td>
<td>
<hr />
<pre>
135         jit.patchableBranch32(
136             MacroAssembler::NotEqual,
137             MacroAssembler::Address(base, JSCell::structureIDOffset()),
138             MacroAssembler::TrustedImm32(0x000ab21ca));
139 
140         jit.loadPtr(MacroAssembler::Address(base, JSObject::butterflyOffset()), value);
141         jit.storeValue(
142             regs,
143             MacroAssembler::Address(base, 120342));
144 
145         dataLog(&quot;replace out of line cache size: &quot;, jit.m_assembler.buffer().codeSize(), &quot;\n&quot;);
146     }
147 
148     CRASH();
149 }
150 
151 
152 template &lt;typename Function&gt;
153 ALWAYS_INLINE static bool linkCodeInline(const char* name, CCallHelpers&amp; jit, StructureStubInfo&amp; stubInfo, const Function&amp; function)
154 {
<span class="line-modified">155     if (jit.m_assembler.buffer().codeSize() &lt;= stubInfo.inlineSize()) {</span>
156         bool needsBranchCompaction = true;
<span class="line-modified">157         LinkBuffer linkBuffer(jit, stubInfo.start, stubInfo.inlineSize(), JITCompilationMustSucceed, needsBranchCompaction);</span>
158         ASSERT(linkBuffer.isValid());
159         function(linkBuffer);
160         FINALIZE_CODE(linkBuffer, NoPtrTag, &quot;InlineAccessType: &#39;%s&#39;&quot;, name);
161         return true;
162     }
163 
164     // This is helpful when determining the size for inline ICs on various
165     // platforms. You want to choose a size that usually succeeds, but sometimes
166     // there may be variability in the length of the code we generate just because
167     // of randomness. It&#39;s helpful to flip this on when running tests or browsing
168     // the web just to see how often it fails. You don&#39;t want an IC size that always fails.
169     constexpr bool failIfCantInline = false;
170     if (failIfCantInline) {
171         dataLog(&quot;Failure for: &quot;, name, &quot;\n&quot;);
<span class="line-modified">172         dataLog(&quot;real size: &quot;, jit.m_assembler.buffer().codeSize(), &quot; inline size:&quot;, stubInfo.inlineSize(), &quot;\n&quot;);</span>
173         CRASH();
174     }
175 
176     return false;
177 }
178 
179 bool InlineAccess::generateSelfPropertyAccess(StructureStubInfo&amp; stubInfo, Structure* structure, PropertyOffset offset)
180 {
<span class="line-added">181     if (!stubInfo.hasConstantIdentifier)</span>
<span class="line-added">182         return false;</span>
<span class="line-added">183 </span>
184     CCallHelpers jit;
185 
<span class="line-modified">186     GPRReg base = stubInfo.baseGPR;</span>
187     JSValueRegs value = stubInfo.valueRegs();
188 
189     auto branchToSlowPath = jit.patchableBranch32(
190         MacroAssembler::NotEqual,
191         MacroAssembler::Address(base, JSCell::structureIDOffset()),
192         MacroAssembler::TrustedImm32(bitwise_cast&lt;uint32_t&gt;(structure-&gt;id())));
193     GPRReg storage;
194     if (isInlineOffset(offset))
195         storage = base;
196     else {
197         jit.loadPtr(CCallHelpers::Address(base, JSObject::butterflyOffset()), value.payloadGPR());
198         storage = value.payloadGPR();
199     }
200 
201     jit.loadValue(
202         MacroAssembler::Address(storage, offsetRelativeToBase(offset)), value);
203 
204     bool linkedCodeInline = linkCodeInline(&quot;property access&quot;, jit, stubInfo, [&amp;] (LinkBuffer&amp; linkBuffer) {
<span class="line-modified">205         linkBuffer.link(branchToSlowPath, stubInfo.slowPathStartLocation);</span>
206     });
207     return linkedCodeInline;
208 }
209 
210 ALWAYS_INLINE static GPRReg getScratchRegister(StructureStubInfo&amp; stubInfo)
211 {
<span class="line-modified">212     ScratchRegisterAllocator allocator(stubInfo.usedRegisters);</span>
<span class="line-modified">213     allocator.lock(stubInfo.baseGPR);</span>
<span class="line-modified">214     allocator.lock(stubInfo.valueGPR);</span>
215 #if USE(JSVALUE32_64)
<span class="line-modified">216     allocator.lock(stubInfo.baseTagGPR);</span>
<span class="line-modified">217     allocator.lock(stubInfo.valueTagGPR);</span>
218 #endif
219     GPRReg scratch = allocator.allocateScratchGPR();
220     if (allocator.didReuseRegisters())
221         return InvalidGPRReg;
222     return scratch;
223 }
224 
225 ALWAYS_INLINE static bool hasFreeRegister(StructureStubInfo&amp; stubInfo)
226 {
227     return getScratchRegister(stubInfo) != InvalidGPRReg;
228 }
229 
230 bool InlineAccess::canGenerateSelfPropertyReplace(StructureStubInfo&amp; stubInfo, PropertyOffset offset)
231 {
<span class="line-added">232     if (!stubInfo.hasConstantIdentifier)</span>
<span class="line-added">233         return false;</span>
<span class="line-added">234 </span>
235     if (isInlineOffset(offset))
236         return true;
237 
238     return hasFreeRegister(stubInfo);
239 }
240 
241 bool InlineAccess::generateSelfPropertyReplace(StructureStubInfo&amp; stubInfo, Structure* structure, PropertyOffset offset)
242 {
<span class="line-added">243     if (!stubInfo.hasConstantIdentifier)</span>
<span class="line-added">244         return false;</span>
<span class="line-added">245 </span>
246     ASSERT(canGenerateSelfPropertyReplace(stubInfo, offset));
247 
248     CCallHelpers jit;
249 
<span class="line-modified">250     GPRReg base = stubInfo.baseGPR;</span>
251     JSValueRegs value = stubInfo.valueRegs();
252 
253     auto branchToSlowPath = jit.patchableBranch32(
254         MacroAssembler::NotEqual,
255         MacroAssembler::Address(base, JSCell::structureIDOffset()),
256         MacroAssembler::TrustedImm32(bitwise_cast&lt;uint32_t&gt;(structure-&gt;id())));
257 
258     GPRReg storage;
259     if (isInlineOffset(offset))
260         storage = base;
261     else {
262         storage = getScratchRegister(stubInfo);
263         ASSERT(storage != InvalidGPRReg);
264         jit.loadPtr(CCallHelpers::Address(base, JSObject::butterflyOffset()), storage);
265     }
266 
267     jit.storeValue(
268         value, MacroAssembler::Address(storage, offsetRelativeToBase(offset)));
269 
270     bool linkedCodeInline = linkCodeInline(&quot;property replace&quot;, jit, stubInfo, [&amp;] (LinkBuffer&amp; linkBuffer) {
<span class="line-modified">271         linkBuffer.link(branchToSlowPath, stubInfo.slowPathStartLocation);</span>
272     });
273     return linkedCodeInline;
274 }
275 
276 bool InlineAccess::isCacheableArrayLength(StructureStubInfo&amp; stubInfo, JSArray* array)
277 {
278     ASSERT(array-&gt;indexingType() &amp; IsArray);
279 
<span class="line-added">280     if (!stubInfo.hasConstantIdentifier)</span>
<span class="line-added">281         return false;</span>
<span class="line-added">282 </span>
283     if (!hasFreeRegister(stubInfo))
284         return false;
285 
286     return !hasAnyArrayStorage(array-&gt;indexingType()) &amp;&amp; array-&gt;indexingType() != ArrayClass;
287 }
288 
289 bool InlineAccess::generateArrayLength(StructureStubInfo&amp; stubInfo, JSArray* array)
290 {
291     ASSERT(isCacheableArrayLength(stubInfo, array));
292 
<span class="line-added">293     if (!stubInfo.hasConstantIdentifier)</span>
<span class="line-added">294         return false;</span>
<span class="line-added">295 </span>
296     CCallHelpers jit;
297 
<span class="line-modified">298     GPRReg base = stubInfo.baseGPR;</span>
299     JSValueRegs value = stubInfo.valueRegs();
300     GPRReg scratch = getScratchRegister(stubInfo);
301 
302     jit.load8(CCallHelpers::Address(base, JSCell::indexingTypeAndMiscOffset()), scratch);
303     jit.and32(CCallHelpers::TrustedImm32(IndexingTypeMask), scratch);
304     auto branchToSlowPath = jit.patchableBranch32(
305         CCallHelpers::NotEqual, scratch, CCallHelpers::TrustedImm32(array-&gt;indexingType()));
306     jit.loadPtr(CCallHelpers::Address(base, JSObject::butterflyOffset()), value.payloadGPR());
307     jit.load32(CCallHelpers::Address(value.payloadGPR(), ArrayStorage::lengthOffset()), value.payloadGPR());
308     jit.boxInt32(value.payloadGPR(), value);
309 
310     bool linkedCodeInline = linkCodeInline(&quot;array length&quot;, jit, stubInfo, [&amp;] (LinkBuffer&amp; linkBuffer) {
<span class="line-modified">311         linkBuffer.link(branchToSlowPath, stubInfo.slowPathStartLocation);</span>
312     });
313     return linkedCodeInline;
314 }
315 
316 bool InlineAccess::isCacheableStringLength(StructureStubInfo&amp; stubInfo)
317 {
<span class="line-added">318     if (!stubInfo.hasConstantIdentifier)</span>
<span class="line-added">319         return false;</span>
<span class="line-added">320 </span>
321     return hasFreeRegister(stubInfo);
322 }
323 
324 bool InlineAccess::generateStringLength(StructureStubInfo&amp; stubInfo)
325 {
326     ASSERT(isCacheableStringLength(stubInfo));
327 
<span class="line-added">328     if (!stubInfo.hasConstantIdentifier)</span>
<span class="line-added">329         return false;</span>
<span class="line-added">330 </span>
331     CCallHelpers jit;
332 
<span class="line-modified">333     GPRReg base = stubInfo.baseGPR;</span>
334     JSValueRegs value = stubInfo.valueRegs();
335     GPRReg scratch = getScratchRegister(stubInfo);
336 
337     auto branchToSlowPath = jit.patchableBranch8(
338         CCallHelpers::NotEqual,
339         CCallHelpers::Address(base, JSCell::typeInfoTypeOffset()),
340         CCallHelpers::TrustedImm32(StringType));
341 
342     jit.loadPtr(CCallHelpers::Address(base, JSString::offsetOfValue()), scratch);
343     auto isRope = jit.branchIfRopeStringImpl(scratch);
344     jit.load32(CCallHelpers::Address(scratch, StringImpl::lengthMemoryOffset()), value.payloadGPR());
345     auto done = jit.jump();
346 
347     isRope.link(&amp;jit);
348     jit.load32(CCallHelpers::Address(base, JSRopeString::offsetOfLength()), value.payloadGPR());
349 
350     done.link(&amp;jit);
351     jit.boxInt32(value.payloadGPR(), value);
352 
353     bool linkedCodeInline = linkCodeInline(&quot;string length&quot;, jit, stubInfo, [&amp;] (LinkBuffer&amp; linkBuffer) {
<span class="line-modified">354         linkBuffer.link(branchToSlowPath, stubInfo.slowPathStartLocation);</span>
355     });
356     return linkedCodeInline;
357 }
358 
359 
360 bool InlineAccess::generateSelfInAccess(StructureStubInfo&amp; stubInfo, Structure* structure)
361 {
362     CCallHelpers jit;
363 
<span class="line-modified">364     if (!stubInfo.hasConstantIdentifier)</span>
<span class="line-added">365         return false;</span>
<span class="line-added">366 </span>
<span class="line-added">367     GPRReg base = stubInfo.baseGPR;</span>
368     JSValueRegs value = stubInfo.valueRegs();
369 
370     auto branchToSlowPath = jit.patchableBranch32(
371         MacroAssembler::NotEqual,
372         MacroAssembler::Address(base, JSCell::structureIDOffset()),
373         MacroAssembler::TrustedImm32(bitwise_cast&lt;uint32_t&gt;(structure-&gt;id())));
374     jit.boxBoolean(true, value);
375 
376     bool linkedCodeInline = linkCodeInline(&quot;in access&quot;, jit, stubInfo, [&amp;] (LinkBuffer&amp; linkBuffer) {
<span class="line-modified">377         linkBuffer.link(branchToSlowPath, stubInfo.slowPathStartLocation);</span>
378     });
379     return linkedCodeInline;
380 }
381 
382 void InlineAccess::rewireStubAsJump(StructureStubInfo&amp; stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt; target)
383 {
384     CCallHelpers jit;
385 
386     auto jump = jit.jump();
387 
388     // We don&#39;t need a nop sled here because nobody should be jumping into the middle of an IC.
389     bool needsBranchCompaction = false;
<span class="line-modified">390     LinkBuffer linkBuffer(jit, stubInfo.start, jit.m_assembler.buffer().codeSize(), JITCompilationMustSucceed, needsBranchCompaction);</span>
391     RELEASE_ASSERT(linkBuffer.isValid());
392     linkBuffer.link(jump, target);
393 
394     FINALIZE_CODE(linkBuffer, NoPtrTag, &quot;InlineAccess: linking constant jump&quot;);
395 }
396 
397 } // namespace JSC
398 
399 #endif // ENABLE(JIT)
</pre>
</td>
</tr>
</table>
<center><a href="InByIdVariant.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="InlineCallFrame.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>