<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGJITCode.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2013-2018 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;DFGJITCode.h&quot;
 28 
 29 #if ENABLE(DFG_JIT)
 30 
 31 #include &quot;CodeBlock.h&quot;
 32 #include &quot;FTLForOSREntryJITCode.h&quot;
 33 #include &quot;JSCInlines.h&quot;
 34 #include &quot;TrackedReferences.h&quot;
 35 
 36 namespace JSC { namespace DFG {
 37 
 38 JITCode::JITCode()
 39     : DirectJITCode(JITType::DFGJIT)
 40 #if ENABLE(FTL_JIT)
 41     , osrEntryRetry(0)
 42     , abandonOSREntry(false)
 43 #endif // ENABLE(FTL_JIT)
 44 {
 45 }
 46 
 47 JITCode::~JITCode()
 48 {
 49 }
 50 
 51 CommonData* JITCode::dfgCommon()
 52 {
 53     return &amp;common;
 54 }
 55 
 56 JITCode* JITCode::dfg()
 57 {
 58     return this;
 59 }
 60 
 61 void JITCode::shrinkToFit(const ConcurrentJSLocker&amp;)
 62 {
 63     common.shrinkToFit();
 64     osrEntry.shrinkToFit();
 65     osrExit.shrinkToFit();
 66     speculationRecovery.shrinkToFit();
 67     minifiedDFG.prepareAndShrink();
 68     variableEventStream.shrinkToFit();
 69 }
 70 
 71 void JITCode::reconstruct(
 72     CodeBlock* codeBlock, CodeOrigin codeOrigin, unsigned streamIndex,
 73     Operands&lt;ValueRecovery&gt;&amp; result)
 74 {
 75     variableEventStream.reconstruct(
 76         codeBlock, codeOrigin, minifiedDFG, streamIndex, result);
 77 }
 78 
 79 void JITCode::reconstruct(CallFrame* callFrame, CodeBlock* codeBlock, CodeOrigin codeOrigin, unsigned streamIndex, Operands&lt;Optional&lt;JSValue&gt;&gt;&amp; result)
 80 {
 81     Operands&lt;ValueRecovery&gt; recoveries;
 82     reconstruct(codeBlock, codeOrigin, streamIndex, recoveries);
 83 
 84     result = Operands&lt;Optional&lt;JSValue&gt;&gt;(OperandsLike, recoveries);
 85     for (size_t i = result.size(); i--;)
 86         result[i] = recoveries[i].recover(callFrame);
 87 }
 88 
 89 RegisterSet JITCode::liveRegistersToPreserveAtExceptionHandlingCallSite(CodeBlock* codeBlock, CallSiteIndex callSiteIndex)
 90 {
 91     for (OSRExit&amp; exit : osrExit) {
 92         if (exit.isExceptionHandler() &amp;&amp; exit.m_exceptionHandlerCallSiteIndex.bits() == callSiteIndex.bits()) {
 93             Operands&lt;ValueRecovery&gt; valueRecoveries;
 94             reconstruct(codeBlock, exit.m_codeOrigin, exit.m_streamIndex, valueRecoveries);
 95             RegisterSet liveAtOSRExit;
 96             for (size_t index = 0; index &lt; valueRecoveries.size(); ++index) {
 97                 const ValueRecovery&amp; recovery = valueRecoveries[index];
 98                 if (recovery.isInRegisters()) {
 99                     if (recovery.isInGPR())
100                         liveAtOSRExit.set(recovery.gpr());
101                     else if (recovery.isInFPR())
102                         liveAtOSRExit.set(recovery.fpr());
103 #if USE(JSVALUE32_64)
104                     else if (recovery.isInJSValueRegs()) {
105                         liveAtOSRExit.set(recovery.payloadGPR());
106                         liveAtOSRExit.set(recovery.tagGPR());
107                     }
108 #endif
109                     else
110                         RELEASE_ASSERT_NOT_REACHED();
111                 }
112             }
113 
114             return liveAtOSRExit;
115         }
116     }
117 
118     return { };
119 }
120 
121 #if ENABLE(FTL_JIT)
122 bool JITCode::checkIfOptimizationThresholdReached(CodeBlock* codeBlock)
123 {
124     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);
125     return tierUpCounter.checkIfThresholdCrossedAndSet(codeBlock);
126 }
127 
128 void JITCode::optimizeNextInvocation(CodeBlock* codeBlock)
129 {
130     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);
131     dataLogLnIf(Options::verboseOSR(), *codeBlock, &quot;: FTL-optimizing next invocation.&quot;);
132     tierUpCounter.setNewThreshold(0, codeBlock);
133 }
134 
135 void JITCode::dontOptimizeAnytimeSoon(CodeBlock* codeBlock)
136 {
137     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);
138     dataLogLnIf(Options::verboseOSR(), *codeBlock, &quot;: Not FTL-optimizing anytime soon.&quot;);
139     tierUpCounter.deferIndefinitely();
140 }
141 
142 void JITCode::optimizeAfterWarmUp(CodeBlock* codeBlock)
143 {
144     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);
145     dataLogLnIf(Options::verboseOSR(), *codeBlock, &quot;: FTL-optimizing after warm-up.&quot;);
146     CodeBlock* baseline = codeBlock-&gt;baselineVersion();
147     tierUpCounter.setNewThreshold(
148         baseline-&gt;adjustedCounterValue(Options::thresholdForFTLOptimizeAfterWarmUp()),
149         baseline);
150 }
151 
152 void JITCode::optimizeSoon(CodeBlock* codeBlock)
153 {
154     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);
155     dataLogLnIf(Options::verboseOSR(), *codeBlock, &quot;: FTL-optimizing soon.&quot;);
156     CodeBlock* baseline = codeBlock-&gt;baselineVersion();
157     tierUpCounter.setNewThreshold(
158         baseline-&gt;adjustedCounterValue(Options::thresholdForFTLOptimizeSoon()),
159         codeBlock);
160 }
161 
162 void JITCode::forceOptimizationSlowPathConcurrently(CodeBlock* codeBlock)
163 {
164     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);
165     dataLogLnIf(Options::verboseOSR(), *codeBlock, &quot;: Forcing slow path concurrently for FTL entry.&quot;);
166     tierUpCounter.forceSlowPathConcurrently();
167 }
168 
169 void JITCode::setOptimizationThresholdBasedOnCompilationResult(
170     CodeBlock* codeBlock, CompilationResult result)
171 {
172     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);
173     switch (result) {
174     case CompilationSuccessful:
175         optimizeNextInvocation(codeBlock);
176         codeBlock-&gt;baselineVersion()-&gt;m_hasBeenCompiledWithFTL = true;
177         return;
178     case CompilationFailed:
179         dontOptimizeAnytimeSoon(codeBlock);
180         codeBlock-&gt;baselineVersion()-&gt;m_didFailFTLCompilation = true;
181         return;
182     case CompilationDeferred:
183         optimizeAfterWarmUp(codeBlock);
184         return;
185     case CompilationInvalidated:
186         // This is weird - it will only happen in cases when the DFG code block (i.e.
187         // the code block that this JITCode belongs to) is also invalidated. So it
188         // doesn&#39;t really matter what we do. But, we do the right thing anyway. Note
189         // that us counting the reoptimization actually means that we might count it
190         // twice. But that&#39;s generally OK. It&#39;s better to overcount reoptimizations
191         // than it is to undercount them.
192         codeBlock-&gt;baselineVersion()-&gt;countReoptimization();
193         optimizeAfterWarmUp(codeBlock);
194         return;
195     }
196     RELEASE_ASSERT_NOT_REACHED();
197 }
198 
199 void JITCode::setOSREntryBlock(VM&amp; vm, const JSCell* owner, CodeBlock* osrEntryBlock)
200 {
201     if (Options::verboseOSR()) {
202         dataLogLn(RawPointer(this), &quot;: Setting OSR entry block to &quot;, RawPointer(osrEntryBlock));
203         dataLogLn(&quot;OSR entries will go to &quot;, osrEntryBlock-&gt;jitCode()-&gt;ftlForOSREntry()-&gt;addressForCall(ArityCheckNotRequired));
204     }
205     m_osrEntryBlock.set(vm, owner, osrEntryBlock);
206 }
207 
208 void JITCode::clearOSREntryBlockAndResetThresholds(CodeBlock *dfgCodeBlock)
209 {
210     ASSERT(m_osrEntryBlock);
211 
212     BytecodeIndex osrEntryBytecode = m_osrEntryBlock-&gt;jitCode()-&gt;ftlForOSREntry()-&gt;bytecodeIndex();
213     m_osrEntryBlock.clear();
214     osrEntryRetry = 0;
215     tierUpEntryTriggers.set(osrEntryBytecode, JITCode::TriggerReason::DontTrigger);
216     setOptimizationThresholdBasedOnCompilationResult(dfgCodeBlock, CompilationDeferred);
217 }
218 #endif // ENABLE(FTL_JIT)
219 
220 void JITCode::validateReferences(const TrackedReferences&amp; trackedReferences)
221 {
222     common.validateReferences(trackedReferences);
223 
224     for (OSREntryData&amp; entry : osrEntry) {
225         for (unsigned i = entry.m_expectedValues.size(); i--;)
226             entry.m_expectedValues[i].validateReferences(trackedReferences);
227     }
228 
229     minifiedDFG.validateReferences(trackedReferences);
230 }
231 
232 Optional&lt;CodeOrigin&gt; JITCode::findPC(CodeBlock*, void* pc)
233 {
234     for (OSRExit&amp; exit : osrExit) {
235         if (ExecutableMemoryHandle* handle = exit.m_code.executableMemory()) {
236             if (handle-&gt;start().untaggedPtr() &lt;= pc &amp;&amp; pc &lt; handle-&gt;end().untaggedPtr())
237                 return Optional&lt;CodeOrigin&gt;(exit.m_codeOriginForExitProfile);
238         }
239     }
240 
241     return WTF::nullopt;
242 }
243 
244 void JITCode::finalizeOSREntrypoints()
245 {
246     auto comparator = [] (const auto&amp; a, const auto&amp; b) {
247         return a.m_bytecodeIndex &lt; b.m_bytecodeIndex;
248     };
249     std::sort(osrEntry.begin(), osrEntry.end(), comparator);
250 
251 #if ASSERT_ENABLED
252     auto verifyIsSorted = [&amp;] (auto&amp; osrVector) {
253         for (unsigned i = 0; i + 1 &lt; osrVector.size(); ++i)
254             ASSERT(osrVector[i].m_bytecodeIndex &lt;= osrVector[i + 1].m_bytecodeIndex);
255     };
256     verifyIsSorted(osrEntry);
257 #endif
258 }
259 
260 } } // namespace JSC::DFG
261 
262 #endif // ENABLE(DFG_JIT)
    </pre>
  </body>
</html>