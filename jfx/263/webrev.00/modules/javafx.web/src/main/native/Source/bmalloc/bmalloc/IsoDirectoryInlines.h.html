<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/IsoDirectoryInlines.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2017-2019 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #include &quot;IsoDirectory.h&quot;
 29 
 30 namespace bmalloc {
 31 
 32 template&lt;typename Config&gt;
 33 IsoDirectoryBase&lt;Config&gt;::IsoDirectoryBase(IsoHeapImpl&lt;Config&gt;&amp; heap)
 34     : m_heap(heap)
 35 {
 36 }
 37 
 38 template&lt;typename Config, unsigned passedNumPages&gt;
 39 IsoDirectory&lt;Config, passedNumPages&gt;::IsoDirectory(IsoHeapImpl&lt;Config&gt;&amp; heap)
 40     : IsoDirectoryBase&lt;Config&gt;(heap)
 41 {
 42 }
 43 
 44 template&lt;typename Config, unsigned passedNumPages&gt;
 45 EligibilityResult&lt;Config&gt; IsoDirectory&lt;Config, passedNumPages&gt;::takeFirstEligible(const LockHolder&amp;)
 46 {
 47     unsigned pageIndex = (m_eligible | ~m_committed).findBit(m_firstEligibleOrDecommitted, true);
 48     m_firstEligibleOrDecommitted = pageIndex;
 49     BASSERT((m_eligible | ~m_committed).findBit(0, true) == pageIndex);
 50     if (pageIndex &gt;= numPages)
 51         return EligibilityKind::Full;
 52 
 53 #if BUSE(PARTIAL_SCAVENGE)
 54     m_highWatermark = std::max(pageIndex, m_highWatermark);
 55 #endif
 56 
 57     Scavenger&amp; scavenger = *Scavenger::get();
 58     scavenger.didStartGrowing();
 59 
 60     IsoPage&lt;Config&gt;* page = m_pages[pageIndex].get();
 61 
 62     if (!m_committed[pageIndex]) {
 63         scavenger.scheduleIfUnderMemoryPressure(IsoPageBase::pageSize);
 64 
 65         // It could be that we haven&#39;t even allocated a page yet. Do that now!
 66         if (!page) {
 67             page = IsoPage&lt;Config&gt;::tryCreate(*this, pageIndex);
 68             if (!page)
 69                 return EligibilityKind::OutOfMemory;
 70             m_pages[pageIndex] = page;
 71         } else {
 72             // This means that we have a page that we previously allocated and that page just needs to be
 73             // committed.
 74             vmAllocatePhysicalPages(page, IsoPageBase::pageSize);
 75             new (page) IsoPage&lt;Config&gt;(*this, pageIndex);
 76         }
 77 
 78         m_committed[pageIndex] = true;
 79         this-&gt;m_heap.didCommit(page, IsoPageBase::pageSize);
 80     } else {
 81         if (m_empty[pageIndex])
 82             this-&gt;m_heap.isNoLongerFreeable(page, IsoPageBase::pageSize);
 83     }
 84 
 85     RELEASE_BASSERT(page);
 86 
 87     // Make the page non-empty and non-eligible.
 88     m_eligible[pageIndex] = false;
 89     m_empty[pageIndex] = false;
 90     return page;
 91 }
 92 
 93 template&lt;typename Config, unsigned passedNumPages&gt;
 94 void IsoDirectory&lt;Config, passedNumPages&gt;::didBecome(const LockHolder&amp; locker, IsoPage&lt;Config&gt;* page, IsoPageTrigger trigger)
 95 {
 96     static constexpr bool verbose = false;
 97     unsigned pageIndex = page-&gt;index();
 98     switch (trigger) {
 99     case IsoPageTrigger::Eligible:
100         if (verbose)
101             fprintf(stderr, &quot;%p: %p did become eligible.\n&quot;, this, page);
102         m_eligible[pageIndex] = true;
103         m_firstEligibleOrDecommitted = std::min(m_firstEligibleOrDecommitted, pageIndex);
104         this-&gt;m_heap.didBecomeEligibleOrDecommited(locker, this);
105         return;
106     case IsoPageTrigger::Empty:
107         if (verbose)
108             fprintf(stderr, &quot;%p: %p did become empty.\n&quot;, this, page);
109         BASSERT(!!m_committed[pageIndex]);
110         this-&gt;m_heap.isNowFreeable(page, IsoPageBase::pageSize);
111         m_empty[pageIndex] = true;
112         Scavenger::get()-&gt;schedule(IsoPageBase::pageSize);
113         return;
114     }
115     BCRASH();
116 }
117 
118 template&lt;typename Config, unsigned passedNumPages&gt;
119 void IsoDirectory&lt;Config, passedNumPages&gt;::didDecommit(unsigned index)
120 {
121     // FIXME: We could do this without grabbing the lock. I just doubt that it matters. This is not going
122     // to be a frequently executed path, in the sense that decommitting perf will be dominated by the
123     // syscall itself (which has to do many hard things).
124     LockHolder locker(this-&gt;m_heap.lock);
125     BASSERT(!!m_committed[index]);
126     this-&gt;m_heap.isNoLongerFreeable(m_pages[index].get(), IsoPageBase::pageSize);
127     m_committed[index] = false;
128     m_firstEligibleOrDecommitted = std::min(m_firstEligibleOrDecommitted, index);
129     this-&gt;m_heap.didBecomeEligibleOrDecommited(locker, this);
130     this-&gt;m_heap.didDecommit(m_pages[index].get(), IsoPageBase::pageSize);
131 }
132 
133 template&lt;typename Config, unsigned passedNumPages&gt;
134 void IsoDirectory&lt;Config, passedNumPages&gt;::scavengePage(const LockHolder&amp;, size_t index, Vector&lt;DeferredDecommit&gt;&amp; decommits)
135 {
136     // Make sure that this page is now off limits.
137     m_empty[index] = false;
138     m_eligible[index] = false;
139     decommits.push(DeferredDecommit(this, m_pages[index].get(), index));
140 }
141 
142 template&lt;typename Config, unsigned passedNumPages&gt;
143 void IsoDirectory&lt;Config, passedNumPages&gt;::scavenge(const LockHolder&amp; locker, Vector&lt;DeferredDecommit&gt;&amp; decommits)
144 {
145     (m_empty &amp; m_committed).forEachSetBit(
146         [&amp;] (size_t index) {
147             scavengePage(locker, index, decommits);
148         });
149 #if BUSE(PARTIAL_SCAVENGE)
150     m_highWatermark = 0;
151 #endif
152 }
153 
154 #if BUSE(PARTIAL_SCAVENGE)
155 template&lt;typename Config, unsigned passedNumPages&gt;
156 void IsoDirectory&lt;Config, passedNumPages&gt;::scavengeToHighWatermark(const LockHolder&amp; locker, Vector&lt;DeferredDecommit&gt;&amp; decommits)
157 {
158     (m_empty &amp; m_committed).forEachSetBit(
159         [&amp;] (size_t index) {
160             if (index &gt; m_highWatermark)
161                 scavengePage(locker, index, decommits);
162         });
163     m_highWatermark = 0;
164 }
165 #endif
166 
167 template&lt;typename Config, unsigned passedNumPages&gt;
168 template&lt;typename Func&gt;
169 void IsoDirectory&lt;Config, passedNumPages&gt;::forEachCommittedPage(const LockHolder&amp;, const Func&amp; func)
170 {
171     m_committed.forEachSetBit(
172         [&amp;] (size_t index) {
173             func(*(m_pages[index].get()));
174         });
175 }
176 
177 } // namespace bmalloc
178 
    </pre>
  </body>
</html>