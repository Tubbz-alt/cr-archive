<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LLIntSlowPaths.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (C) 2011-2019 Apple Inc. All rights reserved.
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;LLIntSlowPaths.h&quot;
  28 
  29 #include &quot;ArrayConstructor.h&quot;
  30 #include &quot;BytecodeGenerator.h&quot;
  31 #include &quot;CallFrame.h&quot;
  32 #include &quot;CheckpointOSRExitSideState.h&quot;
  33 #include &quot;CommonSlowPathsInlines.h&quot;
  34 #include &quot;Error.h&quot;
  35 #include &quot;ErrorHandlingScope.h&quot;
  36 #include &quot;EvalCodeBlock.h&quot;
  37 #include &quot;Exception.h&quot;
  38 #include &quot;ExceptionFuzz.h&quot;
  39 #include &quot;ExecutableBaseInlines.h&quot;
  40 #include &quot;FrameTracers.h&quot;
  41 #include &quot;FunctionCodeBlock.h&quot;
  42 #include &quot;FunctionWhitelist.h&quot;
  43 #include &quot;GetterSetter.h&quot;
  44 #include &quot;HostCallReturnValue.h&quot;
  45 #include &quot;InterpreterInlines.h&quot;
  46 #include &quot;IteratorOperations.h&quot;
  47 #include &quot;JIT.h&quot;
  48 #include &quot;JITExceptions.h&quot;
  49 #include &quot;JITWorklist.h&quot;
  50 #include &quot;JSAsyncFunction.h&quot;
  51 #include &quot;JSAsyncGeneratorFunction.h&quot;
  52 #include &quot;JSCInlines.h&quot;
  53 #include &quot;JSCJSValue.h&quot;
  54 #include &quot;JSGeneratorFunction.h&quot;
  55 #include &quot;JSGlobalObjectFunctions.h&quot;
  56 #include &quot;JSLexicalEnvironment.h&quot;
  57 #include &quot;JSString.h&quot;
  58 #include &quot;JSWithScope.h&quot;
  59 #include &quot;LLIntCommon.h&quot;
  60 #include &quot;LLIntData.h&quot;
  61 #include &quot;LLIntExceptions.h&quot;
  62 #include &quot;LLIntPrototypeLoadAdaptiveStructureWatchpoint.h&quot;
  63 #include &quot;LowLevelInterpreter.h&quot;
  64 #include &quot;ModuleProgramCodeBlock.h&quot;
  65 #include &quot;ObjectConstructor.h&quot;
  66 #include &quot;ObjectPropertyConditionSet.h&quot;
  67 #include &quot;OpcodeInlines.h&quot;
  68 #include &quot;ProgramCodeBlock.h&quot;
  69 #include &quot;ProtoCallFrameInlines.h&quot;
  70 #include &quot;RegExpObject.h&quot;
  71 #include &quot;ShadowChicken.h&quot;
  72 #include &quot;StructureRareDataInlines.h&quot;
  73 #include &quot;SuperSampler.h&quot;
  74 #include &quot;VMInlines.h&quot;
  75 #include &lt;wtf/NeverDestroyed.h&gt;
  76 #include &lt;wtf/StringPrintStream.h&gt;
  77 
  78 namespace JSC { namespace LLInt {
  79 
  80 #define LLINT_BEGIN_NO_SET_PC() \
  81     CodeBlock* codeBlock = callFrame-&gt;codeBlock(); \
  82     JSGlobalObject* globalObject = codeBlock-&gt;globalObject(); \
  83     VM&amp; vm = codeBlock-&gt;vm(); \
  84     SlowPathFrameTracer tracer(vm, callFrame); \
  85     auto throwScope = DECLARE_THROW_SCOPE(vm)
  86 
  87 #ifndef NDEBUG
  88 #define LLINT_SET_PC_FOR_STUBS() do { \
  89         codeBlock-&gt;bytecodeOffset(pc); \
  90         callFrame-&gt;setCurrentVPC(pc); \
  91     } while (false)
  92 #else
  93 #define LLINT_SET_PC_FOR_STUBS() do { \
  94         callFrame-&gt;setCurrentVPC(pc); \
  95     } while (false)
  96 #endif
  97 
  98 #define LLINT_BEGIN()                           \
  99     LLINT_BEGIN_NO_SET_PC();                    \
 100     LLINT_SET_PC_FOR_STUBS()
 101 
 102 inline JSValue getNonConstantOperand(CallFrame* callFrame, VirtualRegister operand) { return callFrame-&gt;uncheckedR(operand).jsValue(); }
 103 inline JSValue getOperand(CallFrame* callFrame, VirtualRegister operand) { return callFrame-&gt;r(operand).jsValue(); }
 104 
 105 #define LLINT_RETURN_TWO(first, second) do {       \
 106         return encodeResult(first, second);        \
 107     } while (false)
 108 
 109 #define LLINT_END_IMPL() LLINT_RETURN_TWO(pc, nullptr)
 110 
 111 #define LLINT_THROW(exceptionToThrow) do {                        \
 112         throwException(globalObject, throwScope, exceptionToThrow);       \
 113         pc = returnToThrow(vm);                                 \
 114         LLINT_END_IMPL();                                         \
 115     } while (false)
 116 
 117 #define LLINT_CHECK_EXCEPTION() do {                    \
 118         doExceptionFuzzingIfEnabled(globalObject, throwScope, &quot;LLIntSlowPaths&quot;, pc);    \
 119         if (UNLIKELY(throwScope.exception())) {         \
 120             pc = returnToThrow(vm);                   \
 121             LLINT_END_IMPL();                           \
 122         }                                               \
 123     } while (false)
 124 
 125 #define LLINT_END() do {                        \
 126         LLINT_CHECK_EXCEPTION();                \
 127         LLINT_END_IMPL();                       \
 128     } while (false)
 129 
 130 #define JUMP_OFFSET(targetOffset) \
 131     ((targetOffset) ? (targetOffset) : codeBlock-&gt;outOfLineJumpOffset(pc))
 132 
 133 #define JUMP_TO(target) do { \
 134         pc = reinterpret_cast&lt;const Instruction*&gt;(reinterpret_cast&lt;const uint8_t*&gt;(pc) + (target)); \
 135     } while (false)
 136 
 137 #define LLINT_BRANCH(condition) do {                  \
 138         bool __b_condition = (condition);                         \
 139         LLINT_CHECK_EXCEPTION();                                  \
 140         if (__b_condition)                                        \
 141             JUMP_TO(JUMP_OFFSET(bytecode.m_targetLabel));         \
 142         else                                                      \
 143             JUMP_TO(pc-&gt;size()); \
 144         LLINT_END_IMPL();                                         \
 145     } while (false)
 146 
 147 #define LLINT_RETURN(value) do {                \
 148         JSValue __r_returnValue = (value);      \
 149         LLINT_CHECK_EXCEPTION();                \
 150         callFrame-&gt;uncheckedR(bytecode.m_dst) = __r_returnValue;          \
 151         LLINT_END_IMPL();                       \
 152     } while (false)
 153 
 154 #define LLINT_RETURN_PROFILED(value) do {               \
 155         JSValue __rp_returnValue = (value);                     \
 156         LLINT_CHECK_EXCEPTION();                                \
 157         callFrame-&gt;uncheckedR(bytecode.m_dst) = __rp_returnValue;                         \
 158         LLINT_PROFILE_VALUE(__rp_returnValue);          \
 159         LLINT_END_IMPL();                                       \
 160     } while (false)
 161 
 162 #define LLINT_PROFILE_VALUE(value) do { \
 163         bytecode.metadata(codeBlock).m_profile.m_buckets[0] = JSValue::encode(value); \
 164     } while (false)
 165 
 166 #define LLINT_CALL_END_IMPL(callFrame, callTarget, callTargetTag) \
 167     LLINT_RETURN_TWO(retagCodePtr((callTarget), callTargetTag, SlowPathPtrTag), (callFrame))
 168 
 169 #define LLINT_CALL_THROW(globalObject, exceptionToThrow) do {                   \
 170         JSGlobalObject* __ct_globalObject = (globalObject);                                  \
 171         throwException(__ct_globalObject, throwScope, exceptionToThrow);        \
 172         LLINT_CALL_END_IMPL(nullptr, callToThrow(vm), ExceptionHandlerPtrTag);                 \
 173     } while (false)
 174 
 175 #define LLINT_CALL_CHECK_EXCEPTION(globalObject) do {               \
 176         JSGlobalObject* __cce_globalObject = (globalObject);                                 \
 177         doExceptionFuzzingIfEnabled(__cce_globalObject, throwScope, &quot;LLIntSlowPaths/call&quot;, nullptr); \
 178         if (UNLIKELY(throwScope.exception()))                           \
 179             LLINT_CALL_END_IMPL(nullptr, callToThrow(vm), ExceptionHandlerPtrTag); \
 180     } while (false)
 181 
 182 #define LLINT_CALL_RETURN(globalObject, calleeFrame, callTarget, callTargetTag) do { \
 183         JSGlobalObject* __cr_globalObject = (globalObject); \
 184         CallFrame* __cr_calleeFrame = (calleeFrame); \
 185         void* __cr_callTarget = (callTarget); \
 186         LLINT_CALL_CHECK_EXCEPTION(__cr_globalObject);         \
 187         LLINT_CALL_END_IMPL(__cr_calleeFrame, __cr_callTarget, callTargetTag); \
 188     } while (false)
 189 
 190 #define LLINT_RETURN_CALLEE_FRAME(calleeFrame) do { \
 191         CallFrame* __rcf_calleeFrame = (calleeFrame); \
 192         LLINT_RETURN_TWO(pc, __rcf_calleeFrame); \
 193     } while (false)
 194 
 195 #if LLINT_TRACING
 196 
 197 template&lt;typename... Types&gt;
 198 void slowPathLog(const Types&amp;... values)
 199 {
 200     dataLogIf(Options::traceLLIntSlowPath(), values...);
 201 }
 202 
 203 template&lt;typename... Types&gt;
 204 void slowPathLn(const Types&amp;... values)
 205 {
 206     dataLogLnIf(Options::traceLLIntSlowPath(), values...);
 207 }
 208 
 209 template&lt;typename... Types&gt;
 210 void slowPathLogF(const char* format, const Types&amp;... values)
 211 {
 212     ALLOW_NONLITERAL_FORMAT_BEGIN
 213     IGNORE_WARNINGS_BEGIN(&quot;format-security&quot;)
 214     if (Options::traceLLIntSlowPath())
 215         dataLogF(format, values...);
 216     IGNORE_WARNINGS_END
 217     ALLOW_NONLITERAL_FORMAT_END
 218 }
 219 
 220 #else // not LLINT_TRACING
 221 
 222 template&lt;typename... Types&gt; void slowPathLog(const Types&amp;...) { }
 223 template&lt;typename... Types&gt; void slowPathLogLn(const Types&amp;...) { }
 224 template&lt;typename... Types&gt; void slowPathLogF(const char*, const Types&amp;...) { }
 225 
 226 #endif // LLINT_TRACING
 227 
 228 extern &quot;C&quot; SlowPathReturnType llint_trace_operand(CallFrame* callFrame, const Instruction* pc, int fromWhere, int operand)
 229 {
 230     if (!Options::traceLLIntExecution())
 231         LLINT_END_IMPL();
 232 
 233     LLINT_BEGIN();
 234     dataLogF(
 235         &quot;&lt;%p&gt; %p / %p: executing bc#%zu, op#%u: Trace(%d): %d\n&quot;,
 236         &amp;Thread::current(),
 237         callFrame-&gt;codeBlock(),
 238         globalObject,
 239         static_cast&lt;intptr_t&gt;(callFrame-&gt;codeBlock()-&gt;bytecodeOffset(pc)),
 240         pc-&gt;opcodeID(),
 241         fromWhere,
 242         operand);
 243     LLINT_END();
 244 }
 245 
 246 extern &quot;C&quot; SlowPathReturnType llint_trace_value(CallFrame* callFrame, const Instruction* pc, int fromWhere, VirtualRegister operand)
 247 {
 248     if (!Options::traceLLIntExecution())
 249         LLINT_END_IMPL();
 250 
 251     JSValue value = getOperand(callFrame, operand);
 252     union {
 253         struct {
 254             uint32_t tag;
 255             uint32_t payload;
 256         } bits;
 257         EncodedJSValue asValue;
 258     } u;
 259     u.asValue = JSValue::encode(value);
 260     dataLogF(
 261         &quot;&lt;%p&gt; %p / %p: executing bc#%zu, op#%u: Trace(%d): %d: %08x:%08x: %s\n&quot;,
 262         &amp;Thread::current(),
 263         callFrame-&gt;codeBlock(),
 264         callFrame,
 265         static_cast&lt;intptr_t&gt;(callFrame-&gt;codeBlock()-&gt;bytecodeOffset(pc)),
 266         pc-&gt;opcodeID(),
 267         fromWhere,
 268         operand.offset(),
 269         u.bits.tag,
 270         u.bits.payload,
 271         toCString(value).data());
 272     LLINT_END_IMPL();
 273 }
 274 
 275 LLINT_SLOW_PATH_DECL(trace_prologue)
 276 {
 277     if (!Options::traceLLIntExecution())
 278         LLINT_END_IMPL();
 279 
 280     CodeBlock* codeBlock = callFrame-&gt;codeBlock();
 281     dataLogF(&quot;&lt;%p&gt; %p / %p: in prologue of &quot;, &amp;Thread::current(), codeBlock, callFrame);
 282     dataLog(codeBlock, &quot;\n&quot;);
 283     LLINT_END_IMPL();
 284 }
 285 
 286 static void traceFunctionPrologue(CallFrame* callFrame, const char* comment, CodeSpecializationKind kind)
 287 {
 288     if (!Options::traceLLIntExecution())
 289         return;
 290 
 291     JSFunction* callee = jsCast&lt;JSFunction*&gt;(callFrame-&gt;jsCallee());
 292     FunctionExecutable* executable = callee-&gt;jsExecutable();
 293     CodeBlock* codeBlock = executable-&gt;codeBlockFor(kind);
 294     dataLogF(&quot;&lt;%p&gt; %p / %p: in %s of &quot;, &amp;Thread::current(), codeBlock, callFrame, comment);
 295     dataLog(codeBlock);
 296     dataLogF(&quot; function %p, executable %p; numVars = %u, numParameters = %u, numCalleeLocals = %u, caller = %p.\n&quot;,
 297         callee, executable, codeBlock-&gt;numVars(), codeBlock-&gt;numParameters(), codeBlock-&gt;numCalleeLocals(), callFrame-&gt;callerFrame());
 298 }
 299 
 300 LLINT_SLOW_PATH_DECL(trace_prologue_function_for_call)
 301 {
 302     traceFunctionPrologue(callFrame, &quot;call prologue&quot;, CodeForCall);
 303     LLINT_END_IMPL();
 304 }
 305 
 306 LLINT_SLOW_PATH_DECL(trace_prologue_function_for_construct)
 307 {
 308     traceFunctionPrologue(callFrame, &quot;construct prologue&quot;, CodeForConstruct);
 309     LLINT_END_IMPL();
 310 }
 311 
 312 LLINT_SLOW_PATH_DECL(trace_arityCheck_for_call)
 313 {
 314     traceFunctionPrologue(callFrame, &quot;call arity check&quot;, CodeForCall);
 315     LLINT_END_IMPL();
 316 }
 317 
 318 LLINT_SLOW_PATH_DECL(trace_arityCheck_for_construct)
 319 {
 320     traceFunctionPrologue(callFrame, &quot;construct arity check&quot;, CodeForConstruct);
 321     LLINT_END_IMPL();
 322 }
 323 
 324 LLINT_SLOW_PATH_DECL(trace)
 325 {
 326     if (!Options::traceLLIntExecution())
 327         LLINT_END_IMPL();
 328 
 329     CodeBlock* codeBlock = callFrame-&gt;codeBlock();
 330     OpcodeID opcodeID = pc-&gt;opcodeID();
 331     dataLogF(&quot;&lt;%p&gt; %p / %p: executing bc#%zu, %s, pc = %p\n&quot;,
 332             &amp;Thread::current(),
 333             codeBlock,
 334             callFrame,
 335             static_cast&lt;intptr_t&gt;(codeBlock-&gt;bytecodeOffset(pc)),
 336             pc-&gt;name(),
 337             pc);
 338     if (opcodeID == op_enter) {
 339         dataLogF(&quot;Frame will eventually return to %p\n&quot;, callFrame-&gt;returnPC().value());
 340         *removeCodePtrTag&lt;volatile char*&gt;(callFrame-&gt;returnPC().value());
 341     }
 342     if (opcodeID == op_ret) {
 343         dataLogF(&quot;Will be returning to %p\n&quot;, callFrame-&gt;returnPC().value());
 344         dataLogF(&quot;The new cfr will be %p\n&quot;, callFrame-&gt;callerFrame());
 345     }
 346     LLINT_END_IMPL();
 347 }
 348 
 349 enum EntryKind { Prologue, ArityCheck };
 350 
 351 #if ENABLE(JIT)
 352 static FunctionWhitelist&amp; ensureGlobalJITWhitelist()
 353 {
 354     static LazyNeverDestroyed&lt;FunctionWhitelist&gt; baselineWhitelist;
 355     static std::once_flag initializeWhitelistFlag;
 356     std::call_once(initializeWhitelistFlag, [] {
 357         const char* functionWhitelistFile = Options::jitWhitelist();
 358         baselineWhitelist.construct(functionWhitelistFile);
 359     });
 360     return baselineWhitelist;
 361 }
 362 
 363 inline bool shouldJIT(CodeBlock* codeBlock)
 364 {
 365     if (!Options::bytecodeRangeToJITCompile().isInRange(codeBlock-&gt;instructionsSize())
 366         || !ensureGlobalJITWhitelist().contains(codeBlock))
 367         return false;
 368 
 369     return VM::canUseJIT() &amp;&amp; Options::useBaselineJIT();
 370 }
 371 
 372 // Returns true if we should try to OSR.
 373 inline bool jitCompileAndSetHeuristics(VM&amp; vm, CodeBlock* codeBlock, BytecodeIndex loopOSREntryBytecodeIndex = BytecodeIndex(0))
 374 {
 375     DeferGCForAWhile deferGC(vm.heap); // My callers don&#39;t set top callframe, so we don&#39;t want to GC here at all.
 376     ASSERT(VM::canUseJIT());
 377 
 378     codeBlock-&gt;updateAllValueProfilePredictions();
 379 
 380     if (!codeBlock-&gt;checkIfJITThresholdReached()) {
 381         CODEBLOCK_LOG_EVENT(codeBlock, &quot;delayJITCompile&quot;, (&quot;threshold not reached, counter = &quot;, codeBlock-&gt;llintExecuteCounter()));
 382         dataLogLnIf(Options::verboseOSR(), &quot;    JIT threshold should be lifted.&quot;);
 383         return false;
 384     }
 385 
 386     JITWorklist::ensureGlobalWorklist().poll(vm);
 387 
 388     switch (codeBlock-&gt;jitType()) {
 389     case JITType::BaselineJIT: {
 390         dataLogLnIf(Options::verboseOSR(), &quot;    Code was already compiled.&quot;);
 391         codeBlock-&gt;jitSoon();
 392         return true;
 393     }
 394     case JITType::InterpreterThunk: {
 395         JITWorklist::ensureGlobalWorklist().compileLater(codeBlock, loopOSREntryBytecodeIndex);
 396         return codeBlock-&gt;jitType() == JITType::BaselineJIT;
 397     }
 398     default:
 399         dataLog(&quot;Unexpected code block in LLInt: &quot;, *codeBlock, &quot;\n&quot;);
 400         RELEASE_ASSERT_NOT_REACHED();
 401         return false;
 402     }
 403 }
 404 
 405 static SlowPathReturnType entryOSR(CodeBlock* codeBlock, const char *name, EntryKind kind)
 406 {
 407     dataLogLnIf(Options::verboseOSR(),
 408         *codeBlock, &quot;: Entered &quot;, name, &quot; with executeCounter = &quot;,
 409         codeBlock-&gt;llintExecuteCounter());
 410 
 411     if (!shouldJIT(codeBlock)) {
 412         codeBlock-&gt;dontJITAnytimeSoon();
 413         LLINT_RETURN_TWO(nullptr, nullptr);
 414     }
 415     VM&amp; vm = codeBlock-&gt;vm();
 416     if (!jitCompileAndSetHeuristics(vm, codeBlock))
 417         LLINT_RETURN_TWO(nullptr, nullptr);
 418 
 419     CODEBLOCK_LOG_EVENT(codeBlock, &quot;OSR entry&quot;, (&quot;in prologue&quot;));
 420 
 421     if (kind == Prologue)
 422         LLINT_RETURN_TWO(codeBlock-&gt;jitCode()-&gt;executableAddress(), nullptr);
 423     ASSERT(kind == ArityCheck);
 424     LLINT_RETURN_TWO(codeBlock-&gt;jitCode()-&gt;addressForCall(MustCheckArity).executableAddress(), nullptr);
 425 }
 426 #else // ENABLE(JIT)
 427 static SlowPathReturnType entryOSR(CodeBlock* codeBlock, const char*, EntryKind)
 428 {
 429     codeBlock-&gt;dontJITAnytimeSoon();
 430     LLINT_RETURN_TWO(nullptr, nullptr);
 431 }
 432 #endif // ENABLE(JIT)
 433 
 434 LLINT_SLOW_PATH_DECL(entry_osr)
 435 {
 436     UNUSED_PARAM(pc);
 437     return entryOSR(callFrame-&gt;codeBlock(), &quot;entry_osr&quot;, Prologue);
 438 }
 439 
 440 LLINT_SLOW_PATH_DECL(entry_osr_function_for_call)
 441 {
 442     UNUSED_PARAM(pc);
 443     return entryOSR(jsCast&lt;JSFunction*&gt;(callFrame-&gt;jsCallee())-&gt;jsExecutable()-&gt;codeBlockForCall(), &quot;entry_osr_function_for_call&quot;, Prologue);
 444 }
 445 
 446 LLINT_SLOW_PATH_DECL(entry_osr_function_for_construct)
 447 {
 448     UNUSED_PARAM(pc);
 449     return entryOSR(jsCast&lt;JSFunction*&gt;(callFrame-&gt;jsCallee())-&gt;jsExecutable()-&gt;codeBlockForConstruct(), &quot;entry_osr_function_for_construct&quot;, Prologue);
 450 }
 451 
 452 LLINT_SLOW_PATH_DECL(entry_osr_function_for_call_arityCheck)
 453 {
 454     UNUSED_PARAM(pc);
 455     return entryOSR(jsCast&lt;JSFunction*&gt;(callFrame-&gt;jsCallee())-&gt;jsExecutable()-&gt;codeBlockForCall(), &quot;entry_osr_function_for_call_arityCheck&quot;, ArityCheck);
 456 }
 457 
 458 LLINT_SLOW_PATH_DECL(entry_osr_function_for_construct_arityCheck)
 459 {
 460     UNUSED_PARAM(pc);
 461     return entryOSR(jsCast&lt;JSFunction*&gt;(callFrame-&gt;jsCallee())-&gt;jsExecutable()-&gt;codeBlockForConstruct(), &quot;entry_osr_function_for_construct_arityCheck&quot;, ArityCheck);
 462 }
 463 
 464 LLINT_SLOW_PATH_DECL(loop_osr)
 465 {
 466     LLINT_BEGIN_NO_SET_PC();
 467     UNUSED_PARAM(throwScope);
 468     UNUSED_PARAM(globalObject);
 469 
 470 #if ENABLE(JIT)
 471     dataLogLnIf(Options::verboseOSR(),
 472             *codeBlock, &quot;: Entered loop_osr with executeCounter = &quot;,
 473             codeBlock-&gt;llintExecuteCounter());
 474 
 475     auto loopOSREntryBytecodeIndex = BytecodeIndex(codeBlock-&gt;bytecodeOffset(pc));
 476 
 477     if (!shouldJIT(codeBlock)) {
 478         codeBlock-&gt;dontJITAnytimeSoon();
 479         LLINT_RETURN_TWO(0, 0);
 480     }
 481 
 482     if (!jitCompileAndSetHeuristics(vm, codeBlock, loopOSREntryBytecodeIndex))
 483         LLINT_RETURN_TWO(0, 0);
 484 
 485     CODEBLOCK_LOG_EVENT(codeBlock, &quot;osrEntry&quot;, (&quot;at &quot;, loopOSREntryBytecodeIndex));
 486 
 487     ASSERT(codeBlock-&gt;jitType() == JITType::BaselineJIT);
 488 
 489     const JITCodeMap&amp; codeMap = codeBlock-&gt;jitCodeMap();
 490     CodeLocationLabel&lt;JSEntryPtrTag&gt; codeLocation = codeMap.find(loopOSREntryBytecodeIndex);
 491     ASSERT(codeLocation);
 492 
 493     void* jumpTarget = codeLocation.executableAddress();
 494     ASSERT(jumpTarget);
 495 
 496     LLINT_RETURN_TWO(jumpTarget, callFrame-&gt;topOfFrame());
 497 #else // ENABLE(JIT)
 498     UNUSED_PARAM(pc);
 499     codeBlock-&gt;dontJITAnytimeSoon();
 500     LLINT_RETURN_TWO(0, 0);
 501 #endif // ENABLE(JIT)
 502 }
 503 
 504 LLINT_SLOW_PATH_DECL(replace)
 505 {
 506     LLINT_BEGIN_NO_SET_PC();
 507     UNUSED_PARAM(throwScope);
 508     UNUSED_PARAM(globalObject);
 509 
 510 #if ENABLE(JIT)
 511     dataLogLnIf(Options::verboseOSR(),
 512         *codeBlock, &quot;: Entered replace with executeCounter = &quot;,
 513         codeBlock-&gt;llintExecuteCounter());
 514 
 515     if (shouldJIT(codeBlock))
 516         jitCompileAndSetHeuristics(vm, codeBlock);
 517     else
 518         codeBlock-&gt;dontJITAnytimeSoon();
 519     LLINT_END_IMPL();
 520 #else // ENABLE(JIT)
 521     codeBlock-&gt;dontJITAnytimeSoon();
 522     LLINT_END_IMPL();
 523 #endif // ENABLE(JIT)
 524 }
 525 
 526 LLINT_SLOW_PATH_DECL(stack_check)
 527 {
 528     CodeBlock* codeBlock = callFrame-&gt;codeBlock();
 529     JSGlobalObject* globalObject = codeBlock-&gt;globalObject();
 530     VM&amp; vm = codeBlock-&gt;vm();
 531     auto throwScope = DECLARE_THROW_SCOPE(vm);
 532 
 533     // It&#39;s ok to create the SlowPathFrameTracer here before we
 534     // convertToStackOverflowFrame() because this function is always called
 535     // after the frame has been propulated with a proper CodeBlock and callee.
 536     SlowPathFrameTracer tracer(vm, callFrame);
 537 
 538     LLINT_SET_PC_FOR_STUBS();
 539 
 540     slowPathLogF(&quot;Checking stack height with callFrame = %p.\n&quot;, callFrame);
 541     slowPathLog(&quot;CodeBlock = &quot;, codeBlock, &quot;\n&quot;);
 542     if (codeBlock) {
 543         slowPathLogF(&quot;Num callee registers = %u.\n&quot;, codeBlock-&gt;numCalleeLocals());
 544         slowPathLogF(&quot;Num vars = %u.\n&quot;, codeBlock-&gt;numVars());
 545     }
 546     slowPathLogF(&quot;Current OS stack end is at %p.\n&quot;, vm.softStackLimit());
 547 #if ENABLE(C_LOOP)
 548     slowPathLogF(&quot;Current C Loop stack end is at %p.\n&quot;, vm.cloopStackLimit());
 549 #endif
 550 
 551     // If the stack check succeeds and we don&#39;t need to throw the error, then
 552     // we&#39;ll return 0 instead. The prologue will check for a non-zero value
 553     // when determining whether to set the callFrame or not.
 554 
 555     // For JIT enabled builds which uses the C stack, the stack is not growable.
 556     // Hence, if we get here, then we know a stack overflow is imminent. So, just
 557     // throw the StackOverflowError unconditionally.
 558 #if ENABLE(C_LOOP)
 559     Register* topOfFrame = callFrame-&gt;topOfFrame();
 560     if (LIKELY(topOfFrame &lt; reinterpret_cast&lt;Register*&gt;(callFrame))) {
 561         ASSERT(!vm.interpreter-&gt;cloopStack().containsAddress(topOfFrame));
 562         if (LIKELY(vm.ensureStackCapacityFor(topOfFrame)))
 563             LLINT_RETURN_TWO(pc, 0);
 564     }
 565 #endif
 566 
 567     callFrame-&gt;convertToStackOverflowFrame(vm, codeBlock);
 568     ErrorHandlingScope errorScope(vm);
 569     throwStackOverflowError(globalObject, throwScope);
 570     pc = returnToThrow(vm);
 571     LLINT_RETURN_TWO(pc, callFrame);
 572 }
 573 
 574 LLINT_SLOW_PATH_DECL(slow_path_new_object)
 575 {
 576     LLINT_BEGIN();
 577     auto bytecode = pc-&gt;as&lt;OpNewObject&gt;();
 578     auto&amp; metadata = bytecode.metadata(codeBlock);
 579     LLINT_RETURN(constructEmptyObject(vm, metadata.m_objectAllocationProfile.structure()));
 580 }
 581 
 582 LLINT_SLOW_PATH_DECL(slow_path_new_array)
 583 {
 584     LLINT_BEGIN();
 585     auto bytecode = pc-&gt;as&lt;OpNewArray&gt;();
 586     auto&amp; metadata = bytecode.metadata(codeBlock);
 587     LLINT_RETURN(constructArrayNegativeIndexed(globalObject, &amp;metadata.m_arrayAllocationProfile, bitwise_cast&lt;JSValue*&gt;(&amp;callFrame-&gt;uncheckedR(bytecode.m_argv)), bytecode.m_argc));
 588 }
 589 
 590 LLINT_SLOW_PATH_DECL(slow_path_new_array_with_size)
 591 {
 592     LLINT_BEGIN();
 593     auto bytecode = pc-&gt;as&lt;OpNewArrayWithSize&gt;();
 594     auto&amp; metadata = bytecode.metadata(codeBlock);
 595     LLINT_RETURN(constructArrayWithSizeQuirk(globalObject, &amp;metadata.m_arrayAllocationProfile, getOperand(callFrame, bytecode.m_length)));
 596 }
 597 
 598 LLINT_SLOW_PATH_DECL(slow_path_new_regexp)
 599 {
 600     LLINT_BEGIN();
 601     auto bytecode = pc-&gt;as&lt;OpNewRegexp&gt;();
 602     RegExp* regExp = jsCast&lt;RegExp*&gt;(getOperand(callFrame, bytecode.m_regexp));
 603     ASSERT(regExp-&gt;isValid());
 604     LLINT_RETURN(RegExpObject::create(vm, globalObject-&gt;regExpStructure(), regExp));
 605 }
 606 
 607 LLINT_SLOW_PATH_DECL(slow_path_instanceof)
 608 {
 609     LLINT_BEGIN();
 610     auto bytecode = pc-&gt;as&lt;OpInstanceof&gt;();
 611     JSValue value = getOperand(callFrame, bytecode.m_value);
 612     JSValue proto = getOperand(callFrame, bytecode.m_prototype);
 613     LLINT_RETURN(jsBoolean(JSObject::defaultHasInstance(globalObject, value, proto)));
 614 }
 615 
 616 LLINT_SLOW_PATH_DECL(slow_path_instanceof_custom)
 617 {
 618     LLINT_BEGIN();
 619 
 620     auto bytecode = pc-&gt;as&lt;OpInstanceofCustom&gt;();
 621     JSValue value = getOperand(callFrame, bytecode.m_value);
 622     JSValue constructor = getOperand(callFrame, bytecode.m_constructor);
 623     JSValue hasInstanceValue = getOperand(callFrame, bytecode.m_hasInstanceValue);
 624 
 625     ASSERT(constructor.isObject());
 626     ASSERT(hasInstanceValue != globalObject-&gt;functionProtoHasInstanceSymbolFunction() || !constructor.getObject()-&gt;structure(vm)-&gt;typeInfo().implementsDefaultHasInstance());
 627 
 628     JSValue result = jsBoolean(constructor.getObject()-&gt;hasInstance(globalObject, value, hasInstanceValue));
 629     LLINT_RETURN(result);
 630 }
 631 
 632 LLINT_SLOW_PATH_DECL(slow_path_try_get_by_id)
 633 {
 634     LLINT_BEGIN();
 635     auto bytecode = pc-&gt;as&lt;OpTryGetById&gt;();
 636     const Identifier&amp; ident = codeBlock-&gt;identifier(bytecode.m_property);
 637     JSValue baseValue = getOperand(callFrame, bytecode.m_base);
 638     PropertySlot slot(baseValue, PropertySlot::PropertySlot::InternalMethodType::VMInquiry);
 639 
 640     baseValue.getPropertySlot(globalObject, ident, slot);
 641     JSValue result = slot.getPureResult();
 642 
 643     LLINT_RETURN_PROFILED(result);
 644 }
 645 
 646 LLINT_SLOW_PATH_DECL(slow_path_get_by_id_direct)
 647 {
 648     LLINT_BEGIN();
 649     auto bytecode = pc-&gt;as&lt;OpGetByIdDirect&gt;();
 650     const Identifier&amp; ident = codeBlock-&gt;identifier(bytecode.m_property);
 651     JSValue baseValue = getOperand(callFrame, bytecode.m_base);
 652     PropertySlot slot(baseValue, PropertySlot::PropertySlot::InternalMethodType::GetOwnProperty);
 653 
 654     bool found = baseValue.getOwnPropertySlot(globalObject, ident, slot);
 655     LLINT_CHECK_EXCEPTION();
 656     JSValue result = found ? slot.getValue(globalObject, ident) : jsUndefined();
 657     LLINT_CHECK_EXCEPTION();
 658 
 659     if (!LLINT_ALWAYS_ACCESS_SLOW &amp;&amp; slot.isCacheable() &amp;&amp; !slot.isUnset()) {
 660         auto&amp; metadata = bytecode.metadata(codeBlock);
 661         {
 662             StructureID oldStructureID = metadata.m_structureID;
 663             if (oldStructureID) {
 664                 Structure* a = vm.heap.structureIDTable().get(oldStructureID);
 665                 Structure* b = baseValue.asCell()-&gt;structure(vm);
 666 
 667                 if (Structure::shouldConvertToPolyProto(a, b)) {
 668                     ASSERT(a-&gt;rareData()-&gt;sharedPolyProtoWatchpoint().get() == b-&gt;rareData()-&gt;sharedPolyProtoWatchpoint().get());
 669                     a-&gt;rareData()-&gt;sharedPolyProtoWatchpoint()-&gt;invalidate(vm, StringFireDetail(&quot;Detected poly proto opportunity.&quot;));
 670                 }
 671             }
 672         }
 673 
 674         JSCell* baseCell = baseValue.asCell();
 675         Structure* structure = baseCell-&gt;structure(vm);
 676         if (slot.isValue()) {
 677             // Start out by clearing out the old cache.
 678             metadata.m_structureID = 0;
 679             metadata.m_offset = 0;
 680 
 681             if (structure-&gt;propertyAccessesAreCacheable() &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()) {
 682                 {
 683                     ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
 684                     metadata.m_structureID = structure-&gt;id();
 685                     metadata.m_offset = slot.cachedOffset();
 686                 }
 687                 vm.heap.writeBarrier(codeBlock);
 688             }
 689         }
 690     }
 691 
 692     LLINT_RETURN_PROFILED(result);
 693 }
 694 
 695 
 696 static void setupGetByIdPrototypeCache(JSGlobalObject* globalObject, VM&amp; vm, CodeBlock* codeBlock, const Instruction* pc, OpGetById::Metadata&amp; metadata, JSCell* baseCell, PropertySlot&amp; slot, const Identifier&amp; ident)
 697 {
 698     Structure* structure = baseCell-&gt;structure(vm);
 699 
 700     if (structure-&gt;typeInfo().prohibitsPropertyCaching())
 701         return;
 702 
 703     if (structure-&gt;needImpurePropertyWatchpoint())
 704         return;
 705 
 706     if (structure-&gt;isDictionary()) {
 707         if (structure-&gt;hasBeenFlattenedBefore())
 708             return;
 709         structure-&gt;flattenDictionaryStructure(vm, jsCast&lt;JSObject*&gt;(baseCell));
 710     }
 711 
 712     prepareChainForCaching(globalObject, baseCell, slot);
 713 
 714     ObjectPropertyConditionSet conditions;
 715     if (slot.isUnset())
 716         conditions = generateConditionsForPropertyMiss(vm, codeBlock, globalObject, structure, ident.impl());
 717     else
 718         conditions = generateConditionsForPrototypePropertyHit(vm, codeBlock, globalObject, structure, slot.slotBase(), ident.impl());
 719 
 720     if (!conditions.isValid())
 721         return;
 722 
 723     unsigned bytecodeOffset = codeBlock-&gt;bytecodeOffset(pc);
 724     PropertyOffset offset = invalidOffset;
 725     CodeBlock::StructureWatchpointMap&amp; watchpointMap = codeBlock-&gt;llintGetByIdWatchpointMap();
 726     Vector&lt;LLIntPrototypeLoadAdaptiveStructureWatchpoint&gt; watchpoints;
 727     watchpoints.reserveInitialCapacity(conditions.size());
 728     for (ObjectPropertyCondition condition : conditions) {
 729         if (!condition.isWatchable())
 730             return;
 731         if (condition.condition().kind() == PropertyCondition::Presence)
 732             offset = condition.condition().offset();
 733         watchpoints.uncheckedConstructAndAppend(codeBlock, condition, bytecodeOffset);
 734         watchpoints.last().install(vm);
 735     }
 736 
 737     ASSERT((offset == invalidOffset) == slot.isUnset());
 738     auto result = watchpointMap.add(std::make_tuple(structure-&gt;id(), bytecodeOffset), WTFMove(watchpoints));
 739     ASSERT_UNUSED(result, result.isNewEntry);
 740 
 741     {
 742         ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
 743         if (slot.isUnset())
 744             metadata.m_modeMetadata.setUnsetMode(structure);
 745         else {
 746             ASSERT(slot.isValue());
 747             metadata.m_modeMetadata.setProtoLoadMode(structure, offset, slot.slotBase());
 748         }
 749     }
 750     vm.heap.writeBarrier(codeBlock);
 751 }
 752 
 753 
 754 LLINT_SLOW_PATH_DECL(slow_path_get_by_id)
 755 {
 756     LLINT_BEGIN();
 757     auto bytecode = pc-&gt;as&lt;OpGetById&gt;();
 758     auto&amp; metadata = bytecode.metadata(codeBlock);
 759     const Identifier&amp; ident = codeBlock-&gt;identifier(bytecode.m_property);
 760     JSValue baseValue = getOperand(callFrame, bytecode.m_base);
 761     PropertySlot slot(baseValue, PropertySlot::PropertySlot::InternalMethodType::Get);
 762 
 763     JSValue result = baseValue.get(globalObject, ident, slot);
 764     LLINT_CHECK_EXCEPTION();
 765     callFrame-&gt;uncheckedR(bytecode.m_dst) = result;
 766 
 767     if (!LLINT_ALWAYS_ACCESS_SLOW
 768         &amp;&amp; baseValue.isCell()
 769         &amp;&amp; slot.isCacheable()
 770         &amp;&amp; !slot.isUnset()) {
 771         {
 772             StructureID oldStructureID;
 773             switch (metadata.m_modeMetadata.mode) {
 774             case GetByIdMode::Default:
 775                 oldStructureID = metadata.m_modeMetadata.defaultMode.structureID;
 776                 break;
 777             case GetByIdMode::Unset:
 778                 oldStructureID = metadata.m_modeMetadata.unsetMode.structureID;
 779                 break;
 780             case GetByIdMode::ProtoLoad:
 781                 oldStructureID = metadata.m_modeMetadata.protoLoadMode.structureID;
 782                 break;
 783             default:
 784                 oldStructureID = 0;
 785             }
 786             if (oldStructureID) {
 787                 Structure* a = vm.heap.structureIDTable().get(oldStructureID);
 788                 Structure* b = baseValue.asCell()-&gt;structure(vm);
 789 
 790                 if (Structure::shouldConvertToPolyProto(a, b)) {
 791                     ASSERT(a-&gt;rareData()-&gt;sharedPolyProtoWatchpoint().get() == b-&gt;rareData()-&gt;sharedPolyProtoWatchpoint().get());
 792                     a-&gt;rareData()-&gt;sharedPolyProtoWatchpoint()-&gt;invalidate(vm, StringFireDetail(&quot;Detected poly proto opportunity.&quot;));
 793                 }
 794             }
 795         }
 796 
 797         JSCell* baseCell = baseValue.asCell();
 798         Structure* structure = baseCell-&gt;structure(vm);
 799         if (slot.isValue() &amp;&amp; slot.slotBase() == baseValue) {
 800             ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
 801             // Start out by clearing out the old cache.
 802             metadata.m_modeMetadata.clearToDefaultModeWithoutCache();
 803 
 804             // Prevent the prototype cache from ever happening.
 805             metadata.m_modeMetadata.hitCountForLLIntCaching = 0;
 806 
 807             if (structure-&gt;propertyAccessesAreCacheable() &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()) {
 808                 metadata.m_modeMetadata.defaultMode.structureID = structure-&gt;id();
 809                 metadata.m_modeMetadata.defaultMode.cachedOffset = slot.cachedOffset();
 810                 vm.heap.writeBarrier(codeBlock);
 811             }
 812         } else if (UNLIKELY(metadata.m_modeMetadata.hitCountForLLIntCaching &amp;&amp; slot.isValue())) {
 813             ASSERT(slot.slotBase() != baseValue);
 814 
 815             if (!(--metadata.m_modeMetadata.hitCountForLLIntCaching))
 816                 setupGetByIdPrototypeCache(globalObject, vm, codeBlock, pc, metadata, baseCell, slot, ident);
 817         }
 818     } else if (!LLINT_ALWAYS_ACCESS_SLOW &amp;&amp; isJSArray(baseValue) &amp;&amp; ident == vm.propertyNames-&gt;length) {
 819         {
 820             ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
 821             metadata.m_modeMetadata.setArrayLengthMode();
 822             metadata.m_modeMetadata.arrayLengthMode.arrayProfile.observeStructure(baseValue.asCell()-&gt;structure(vm));
 823         }
 824         vm.heap.writeBarrier(codeBlock);
 825     }
 826 
 827     LLINT_PROFILE_VALUE(result);
 828     LLINT_END();
 829 }
 830 
 831 LLINT_SLOW_PATH_DECL(slow_path_put_by_id)
 832 {
 833     LLINT_BEGIN();
 834     auto bytecode = pc-&gt;as&lt;OpPutById&gt;();
 835     auto&amp; metadata = bytecode.metadata(codeBlock);
 836     const Identifier&amp; ident = codeBlock-&gt;identifier(bytecode.m_property);
 837 
 838     JSValue baseValue = getOperand(callFrame, bytecode.m_base);
 839     PutPropertySlot slot(baseValue, codeBlock-&gt;isStrictMode(), codeBlock-&gt;putByIdContext());
 840 
 841     Structure* oldStructure = baseValue.isCell() ? baseValue.asCell()-&gt;structure(vm) : nullptr;
 842     if (bytecode.m_flags &amp; PutByIdIsDirect)
 843         CommonSlowPaths::putDirectWithReify(vm, globalObject, asObject(baseValue), ident, getOperand(callFrame, bytecode.m_value), slot);
 844     else
 845         baseValue.putInline(globalObject, ident, getOperand(callFrame, bytecode.m_value), slot);
 846     LLINT_CHECK_EXCEPTION();
 847 
 848     if (!LLINT_ALWAYS_ACCESS_SLOW
 849         &amp;&amp; baseValue.isCell()
 850         &amp;&amp; slot.isCacheablePut()
 851         &amp;&amp; oldStructure-&gt;propertyAccessesAreCacheable()) {
 852         {
 853             StructureID oldStructureID = metadata.m_oldStructureID;
 854             if (oldStructureID) {
 855                 Structure* a = vm.heap.structureIDTable().get(oldStructureID);
 856                 Structure* b = baseValue.asCell()-&gt;structure(vm);
 857                 if (slot.type() == PutPropertySlot::NewProperty)
 858                     b = b-&gt;previousID();
 859 
 860                 if (Structure::shouldConvertToPolyProto(a, b)) {
 861                     a-&gt;rareData()-&gt;sharedPolyProtoWatchpoint()-&gt;invalidate(vm, StringFireDetail(&quot;Detected poly proto opportunity.&quot;));
 862                     b-&gt;rareData()-&gt;sharedPolyProtoWatchpoint()-&gt;invalidate(vm, StringFireDetail(&quot;Detected poly proto opportunity.&quot;));
 863                 }
 864             }
 865         }
 866 
 867         // Start out by clearing out the old cache.
 868         metadata.m_oldStructureID = 0;
 869         metadata.m_offset = 0;
 870         metadata.m_newStructureID = 0;
 871         metadata.m_structureChain.clear();
 872 
 873         JSCell* baseCell = baseValue.asCell();
 874         Structure* newStructure = baseCell-&gt;structure(vm);
 875 
 876         if (newStructure-&gt;propertyAccessesAreCacheable() &amp;&amp; baseCell == slot.base()) {
 877             if (slot.type() == PutPropertySlot::NewProperty) {
 878                 GCSafeConcurrentJSLocker locker(codeBlock-&gt;m_lock, vm.heap);
 879                 if (!newStructure-&gt;isDictionary() &amp;&amp; newStructure-&gt;previousID()-&gt;outOfLineCapacity() == newStructure-&gt;outOfLineCapacity()) {
 880                     ASSERT(oldStructure == newStructure-&gt;previousID());
 881                     if (oldStructure == newStructure-&gt;previousID()) {
 882                         ASSERT(oldStructure-&gt;transitionWatchpointSetHasBeenInvalidated());
 883 
 884                         bool sawPolyProto = false;
 885                         auto result = normalizePrototypeChain(globalObject, baseCell, sawPolyProto);
 886                         if (result != InvalidPrototypeChain &amp;&amp; !sawPolyProto) {
 887                             ASSERT(oldStructure-&gt;isObject());
 888                             metadata.m_oldStructureID = oldStructure-&gt;id();
 889                             metadata.m_offset = slot.cachedOffset();
 890                             metadata.m_newStructureID = newStructure-&gt;id();
 891                             if (!(bytecode.m_flags &amp; PutByIdIsDirect)) {
 892                                 StructureChain* chain = newStructure-&gt;prototypeChain(globalObject, asObject(baseCell));
 893                                 ASSERT(chain);
 894                                 metadata.m_structureChain.set(vm, codeBlock, chain);
 895                             }
 896                             vm.heap.writeBarrier(codeBlock);
 897                         }
 898                     }
 899                 }
 900             } else {
 901                 // This assert helps catch bugs if we accidentally forget to disable caching
 902                 // when we transition then store to an existing property. This is common among
 903                 // paths that reify lazy properties. If we reify a lazy property and forget
 904                 // to disable caching, we may come down this path. The Replace IC does not
 905                 // know how to model these types of structure transitions (or any structure
 906                 // transition for that matter).
 907                 RELEASE_ASSERT(newStructure == oldStructure);
 908                 newStructure-&gt;didCachePropertyReplacement(vm, slot.cachedOffset());
 909                 {
 910                     ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
 911                     metadata.m_oldStructureID = newStructure-&gt;id();
 912                     metadata.m_offset = slot.cachedOffset();
 913                 }
 914                 vm.heap.writeBarrier(codeBlock);
 915             }
 916         }
 917     }
 918 
 919     LLINT_END();
 920 }
 921 
 922 LLINT_SLOW_PATH_DECL(slow_path_del_by_id)
 923 {
 924     LLINT_BEGIN();
 925     auto bytecode = pc-&gt;as&lt;OpDelById&gt;();
 926     JSObject* baseObject = getOperand(callFrame, bytecode.m_base).toObject(globalObject);
 927     LLINT_CHECK_EXCEPTION();
 928     bool couldDelete = baseObject-&gt;methodTable(vm)-&gt;deleteProperty(baseObject, globalObject, codeBlock-&gt;identifier(bytecode.m_property));
 929     LLINT_CHECK_EXCEPTION();
 930     if (!couldDelete &amp;&amp; codeBlock-&gt;isStrictMode())
 931         LLINT_THROW(createTypeError(globalObject, UnableToDeletePropertyError));
 932     LLINT_RETURN(jsBoolean(couldDelete));
 933 }
 934 
 935 static ALWAYS_INLINE JSValue getByVal(VM&amp; vm, JSGlobalObject* globalObject, CodeBlock* codeBlock, JSValue baseValue, JSValue subscript, OpGetByVal bytecode)
 936 {
 937     auto scope = DECLARE_THROW_SCOPE(vm);
 938 
 939     if (LIKELY(baseValue.isCell() &amp;&amp; subscript.isString())) {
 940         Structure&amp; structure = *baseValue.asCell()-&gt;structure(vm);
 941         if (JSCell::canUseFastGetOwnProperty(structure)) {
 942             RefPtr&lt;AtomStringImpl&gt; existingAtomString = asString(subscript)-&gt;toExistingAtomString(globalObject);
 943             RETURN_IF_EXCEPTION(scope, JSValue());
 944             if (existingAtomString) {
 945                 if (JSValue result = baseValue.asCell()-&gt;fastGetOwnProperty(vm, structure, existingAtomString.get()))
 946                     return result;
 947             }
 948         }
 949     }
 950 
 951     if (subscript.isUInt32()) {
 952         uint32_t i = subscript.asUInt32();
 953         auto&amp; metadata = bytecode.metadata(codeBlock);
 954         ArrayProfile* arrayProfile = &amp;metadata.m_arrayProfile;
 955 
 956         if (isJSString(baseValue)) {
 957             if (asString(baseValue)-&gt;canGetIndex(i)) {
 958                 scope.release();
 959                 return asString(baseValue)-&gt;getIndex(globalObject, i);
 960             }
 961             arrayProfile-&gt;setOutOfBounds();
 962         } else if (baseValue.isObject()) {
 963             JSObject* object = asObject(baseValue);
 964             if (object-&gt;canGetIndexQuickly(i))
 965                 return object-&gt;getIndexQuickly(i);
 966 
 967             bool skipMarkingOutOfBounds = false;
 968 
 969             if (object-&gt;indexingType() == ArrayWithContiguous &amp;&amp; i &lt; object-&gt;butterfly()-&gt;publicLength()) {
 970                 // FIXME: expand this to ArrayStorage, Int32, and maybe Double:
 971                 // https://bugs.webkit.org/show_bug.cgi?id=182940
 972                 auto* globalObject = object-&gt;globalObject(vm);
 973                 skipMarkingOutOfBounds = globalObject-&gt;isOriginalArrayStructure(object-&gt;structure(vm)) &amp;&amp; globalObject-&gt;arrayPrototypeChainIsSane();
 974             }
 975 
 976             if (!skipMarkingOutOfBounds &amp;&amp; !CommonSlowPaths::canAccessArgumentIndexQuickly(*object, i))
 977                 arrayProfile-&gt;setOutOfBounds();
 978         }
 979 
 980         scope.release();
 981         return baseValue.get(globalObject, i);
 982     }
 983 
 984     baseValue.requireObjectCoercible(globalObject);
 985     RETURN_IF_EXCEPTION(scope, JSValue());
 986     auto property = subscript.toPropertyKey(globalObject);
 987     RETURN_IF_EXCEPTION(scope, JSValue());
 988     scope.release();
 989     return baseValue.get(globalObject, property);
 990 }
 991 
 992 LLINT_SLOW_PATH_DECL(slow_path_get_by_val)
 993 {
 994     LLINT_BEGIN();
 995     auto bytecode = pc-&gt;as&lt;OpGetByVal&gt;();
 996     JSValue baseValue = getOperand(callFrame, bytecode.m_base);
 997     JSValue subscript = getOperand(callFrame, bytecode.m_property);
 998 
 999     if (subscript.isString() || subscript.isSymbol()) {
1000         auto&amp; metadata = bytecode.metadata(codeBlock);
1001         if (metadata.m_seenIdentifiers.count() &lt;= Options::getByValICMaxNumberOfIdentifiers()) {
1002             const UniquedStringImpl* impl = nullptr;
1003             if (subscript.isSymbol())
1004                 impl = &amp;jsCast&lt;Symbol*&gt;(subscript)-&gt;privateName().uid();
1005             else {
1006                 JSString* string = asString(subscript);
1007                 if (auto* maybeUID = string-&gt;tryGetValueImpl()) {
1008                     if (maybeUID-&gt;isAtom())
1009                         impl = static_cast&lt;const UniquedStringImpl*&gt;(maybeUID);
1010                 }
1011             }
1012 
1013             metadata.m_seenIdentifiers.observe(impl);
1014         }
1015     }
1016 
1017     LLINT_RETURN_PROFILED(getByVal(vm, globalObject, codeBlock, baseValue, subscript, bytecode));
1018 }
1019 
1020 LLINT_SLOW_PATH_DECL(slow_path_put_by_val)
1021 {
1022     LLINT_BEGIN();
1023 
1024     auto bytecode = pc-&gt;as&lt;OpPutByVal&gt;();
1025     JSValue baseValue = getOperand(callFrame, bytecode.m_base);
1026     JSValue subscript = getOperand(callFrame, bytecode.m_property);
1027     JSValue value = getOperand(callFrame, bytecode.m_value);
1028     bool isStrictMode = codeBlock-&gt;isStrictMode();
1029 
1030     if (LIKELY(subscript.isUInt32())) {
1031         uint32_t i = subscript.asUInt32();
1032         if (baseValue.isObject()) {
1033             JSObject* object = asObject(baseValue);
1034             if (object-&gt;canSetIndexQuickly(i, value))
1035                 object-&gt;setIndexQuickly(vm, i, value);
1036             else
1037                 object-&gt;methodTable(vm)-&gt;putByIndex(object, globalObject, i, value, isStrictMode);
1038             LLINT_END();
1039         }
1040         baseValue.putByIndex(globalObject, i, value, isStrictMode);
1041         LLINT_END();
1042     }
1043 
1044     auto property = subscript.toPropertyKey(globalObject);
1045     LLINT_CHECK_EXCEPTION();
1046     PutPropertySlot slot(baseValue, isStrictMode);
1047     baseValue.put(globalObject, property, value, slot);
1048     LLINT_END();
1049 }
1050 
1051 LLINT_SLOW_PATH_DECL(slow_path_put_by_val_direct)
1052 {
1053     LLINT_BEGIN();
1054 
1055     auto bytecode = pc-&gt;as&lt;OpPutByValDirect&gt;();
1056     JSValue baseValue = getOperand(callFrame, bytecode.m_base);
1057     JSValue subscript = getOperand(callFrame, bytecode.m_property);
1058     JSValue value = getOperand(callFrame, bytecode.m_value);
1059     RELEASE_ASSERT(baseValue.isObject());
1060     JSObject* baseObject = asObject(baseValue);
1061     bool isStrictMode = codeBlock-&gt;isStrictMode();
1062     if (LIKELY(subscript.isUInt32())) {
1063         // Despite its name, JSValue::isUInt32 will return true only for positive boxed int32_t; all those values are valid array indices.
1064         ASSERT(isIndex(subscript.asUInt32()));
1065         baseObject-&gt;putDirectIndex(globalObject, subscript.asUInt32(), value, 0, isStrictMode ? PutDirectIndexShouldThrow : PutDirectIndexShouldNotThrow);
1066         LLINT_END();
1067     }
1068 
1069     if (subscript.isDouble()) {
1070         double subscriptAsDouble = subscript.asDouble();
1071         uint32_t subscriptAsUInt32 = static_cast&lt;uint32_t&gt;(subscriptAsDouble);
1072         if (subscriptAsDouble == subscriptAsUInt32 &amp;&amp; isIndex(subscriptAsUInt32)) {
1073             baseObject-&gt;putDirectIndex(globalObject, subscriptAsUInt32, value, 0, isStrictMode ? PutDirectIndexShouldThrow : PutDirectIndexShouldNotThrow);
1074             LLINT_END();
1075         }
1076     }
1077 
1078     // Don&#39;t put to an object if toString threw an exception.
1079     auto property = subscript.toPropertyKey(globalObject);
1080     if (UNLIKELY(throwScope.exception()))
1081         LLINT_END();
1082 
1083     if (Optional&lt;uint32_t&gt; index = parseIndex(property))
1084         baseObject-&gt;putDirectIndex(globalObject, index.value(), value, 0, isStrictMode ? PutDirectIndexShouldThrow : PutDirectIndexShouldNotThrow);
1085     else {
1086         PutPropertySlot slot(baseObject, isStrictMode);
1087         CommonSlowPaths::putDirectWithReify(vm, globalObject, baseObject, property, value, slot);
1088     }
1089     LLINT_END();
1090 }
1091 
1092 LLINT_SLOW_PATH_DECL(slow_path_del_by_val)
1093 {
1094     LLINT_BEGIN();
1095     auto bytecode = pc-&gt;as&lt;OpDelByVal&gt;();
1096     JSValue baseValue = getOperand(callFrame, bytecode.m_base);
1097     JSObject* baseObject = baseValue.toObject(globalObject);
1098     LLINT_CHECK_EXCEPTION();
1099 
1100     JSValue subscript = getOperand(callFrame, bytecode.m_property);
1101 
1102     bool couldDelete;
1103 
1104     uint32_t i;
1105     if (subscript.getUInt32(i))
1106         couldDelete = baseObject-&gt;methodTable(vm)-&gt;deletePropertyByIndex(baseObject, globalObject, i);
1107     else {
1108         LLINT_CHECK_EXCEPTION();
1109         auto property = subscript.toPropertyKey(globalObject);
1110         LLINT_CHECK_EXCEPTION();
1111         couldDelete = baseObject-&gt;methodTable(vm)-&gt;deleteProperty(baseObject, globalObject, property);
1112     }
1113     LLINT_CHECK_EXCEPTION();
1114 
1115     if (!couldDelete &amp;&amp; codeBlock-&gt;isStrictMode())
1116         LLINT_THROW(createTypeError(globalObject, UnableToDeletePropertyError));
1117 
1118     LLINT_RETURN(jsBoolean(couldDelete));
1119 }
1120 
1121 LLINT_SLOW_PATH_DECL(slow_path_put_getter_by_id)
1122 {
1123     LLINT_BEGIN();
1124     auto bytecode = pc-&gt;as&lt;OpPutGetterById&gt;();
1125     ASSERT(getNonConstantOperand(callFrame, bytecode.m_base).isObject());
1126     JSObject* baseObj = asObject(getNonConstantOperand(callFrame, bytecode.m_base));
1127 
1128     unsigned options = bytecode.m_attributes;
1129 
1130     JSValue getter = getNonConstantOperand(callFrame, bytecode.m_accessor);
1131     ASSERT(getter.isObject());
1132 
1133     baseObj-&gt;putGetter(globalObject, codeBlock-&gt;identifier(bytecode.m_property), asObject(getter), options);
1134     LLINT_END();
1135 }
1136 
1137 LLINT_SLOW_PATH_DECL(slow_path_put_setter_by_id)
1138 {
1139     LLINT_BEGIN();
1140     auto bytecode = pc-&gt;as&lt;OpPutSetterById&gt;();
1141     ASSERT(getNonConstantOperand(callFrame, bytecode.m_base).isObject());
1142     JSObject* baseObj = asObject(getNonConstantOperand(callFrame, bytecode.m_base));
1143 
1144     unsigned options = bytecode.m_attributes;
1145 
1146     JSValue setter = getNonConstantOperand(callFrame, bytecode.m_accessor);
1147     ASSERT(setter.isObject());
1148 
1149     baseObj-&gt;putSetter(globalObject, codeBlock-&gt;identifier(bytecode.m_property), asObject(setter), options);
1150     LLINT_END();
1151 }
1152 
1153 LLINT_SLOW_PATH_DECL(slow_path_put_getter_setter_by_id)
1154 {
1155     LLINT_BEGIN();
1156     auto bytecode = pc-&gt;as&lt;OpPutGetterSetterById&gt;();
1157     ASSERT(getNonConstantOperand(callFrame, bytecode.m_base).isObject());
1158     JSObject* baseObject = asObject(getNonConstantOperand(callFrame, bytecode.m_base));
1159 
1160     JSValue getter = getNonConstantOperand(callFrame, bytecode.m_getter);
1161     JSValue setter = getNonConstantOperand(callFrame, bytecode.m_setter);
1162     ASSERT(getter.isObject() || setter.isObject());
1163     GetterSetter* accessor = GetterSetter::create(vm, globalObject, getter, setter);
1164 
1165     CommonSlowPaths::putDirectAccessorWithReify(vm, globalObject, baseObject, codeBlock-&gt;identifier(bytecode.m_property), accessor, bytecode.m_attributes);
1166     LLINT_END();
1167 }
1168 
1169 LLINT_SLOW_PATH_DECL(slow_path_put_getter_by_val)
1170 {
1171     LLINT_BEGIN();
1172     auto bytecode = pc-&gt;as&lt;OpPutGetterByVal&gt;();
1173     ASSERT(getNonConstantOperand(callFrame, bytecode.m_base).isObject());
1174     JSObject* baseObj = asObject(getNonConstantOperand(callFrame, bytecode.m_base));
1175     JSValue subscript = getOperand(callFrame, bytecode.m_property);
1176 
1177     unsigned options = bytecode.m_attributes;
1178 
1179     JSValue getter = getNonConstantOperand(callFrame, bytecode.m_accessor);
1180     ASSERT(getter.isObject());
1181 
1182     auto property = subscript.toPropertyKey(globalObject);
1183     LLINT_CHECK_EXCEPTION();
1184 
1185     baseObj-&gt;putGetter(globalObject, property, asObject(getter), options);
1186     LLINT_END();
1187 }
1188 
1189 LLINT_SLOW_PATH_DECL(slow_path_put_setter_by_val)
1190 {
1191     LLINT_BEGIN();
1192     auto bytecode = pc-&gt;as&lt;OpPutSetterByVal&gt;();
1193     ASSERT(getNonConstantOperand(callFrame, bytecode.m_base).isObject());
1194     JSObject* baseObj = asObject(getNonConstantOperand(callFrame, bytecode.m_base));
1195     JSValue subscript = getOperand(callFrame, bytecode.m_property);
1196 
1197     unsigned options = bytecode.m_attributes;
1198 
1199     JSValue setter = getNonConstantOperand(callFrame, bytecode.m_accessor);
1200     ASSERT(setter.isObject());
1201 
1202     auto property = subscript.toPropertyKey(globalObject);
1203     LLINT_CHECK_EXCEPTION();
1204 
1205     baseObj-&gt;putSetter(globalObject, property, asObject(setter), options);
1206     LLINT_END();
1207 }
1208 
1209 LLINT_SLOW_PATH_DECL(slow_path_jtrue)
1210 {
1211     LLINT_BEGIN();
1212     auto bytecode = pc-&gt;as&lt;OpJtrue&gt;();
1213     LLINT_BRANCH(getOperand(callFrame, bytecode.m_condition).toBoolean(globalObject));
1214 }
1215 
1216 LLINT_SLOW_PATH_DECL(slow_path_jfalse)
1217 {
1218     LLINT_BEGIN();
1219     auto bytecode = pc-&gt;as&lt;OpJfalse&gt;();
1220     LLINT_BRANCH(!getOperand(callFrame, bytecode.m_condition).toBoolean(globalObject));
1221 }
1222 
1223 LLINT_SLOW_PATH_DECL(slow_path_jless)
1224 {
1225     LLINT_BEGIN();
1226     auto bytecode = pc-&gt;as&lt;OpJless&gt;();
1227     LLINT_BRANCH(jsLess&lt;true&gt;(globalObject, getOperand(callFrame, bytecode.m_lhs), getOperand(callFrame, bytecode.m_rhs)));
1228 }
1229 
1230 LLINT_SLOW_PATH_DECL(slow_path_jnless)
1231 {
1232     LLINT_BEGIN();
1233     auto bytecode = pc-&gt;as&lt;OpJnless&gt;();
1234     LLINT_BRANCH(!jsLess&lt;true&gt;(globalObject, getOperand(callFrame, bytecode.m_lhs), getOperand(callFrame, bytecode.m_rhs)));
1235 }
1236 
1237 LLINT_SLOW_PATH_DECL(slow_path_jgreater)
1238 {
1239     LLINT_BEGIN();
1240     auto bytecode = pc-&gt;as&lt;OpJgreater&gt;();
1241     LLINT_BRANCH(jsLess&lt;false&gt;(globalObject, getOperand(callFrame, bytecode.m_rhs), getOperand(callFrame, bytecode.m_lhs)));
1242 }
1243 
1244 LLINT_SLOW_PATH_DECL(slow_path_jngreater)
1245 {
1246     LLINT_BEGIN();
1247     auto bytecode = pc-&gt;as&lt;OpJngreater&gt;();
1248     LLINT_BRANCH(!jsLess&lt;false&gt;(globalObject, getOperand(callFrame, bytecode.m_rhs), getOperand(callFrame, bytecode.m_lhs)));
1249 }
1250 
1251 LLINT_SLOW_PATH_DECL(slow_path_jlesseq)
1252 {
1253     LLINT_BEGIN();
1254     auto bytecode = pc-&gt;as&lt;OpJlesseq&gt;();
1255     LLINT_BRANCH(jsLessEq&lt;true&gt;(globalObject, getOperand(callFrame, bytecode.m_lhs), getOperand(callFrame, bytecode.m_rhs)));
1256 }
1257 
1258 LLINT_SLOW_PATH_DECL(slow_path_jnlesseq)
1259 {
1260     LLINT_BEGIN();
1261     auto bytecode = pc-&gt;as&lt;OpJnlesseq&gt;();
1262     LLINT_BRANCH(!jsLessEq&lt;true&gt;(globalObject, getOperand(callFrame, bytecode.m_lhs), getOperand(callFrame, bytecode.m_rhs)));
1263 }
1264 
1265 LLINT_SLOW_PATH_DECL(slow_path_jgreatereq)
1266 {
1267     LLINT_BEGIN();
1268     auto bytecode = pc-&gt;as&lt;OpJgreatereq&gt;();
1269     LLINT_BRANCH(jsLessEq&lt;false&gt;(globalObject, getOperand(callFrame, bytecode.m_rhs), getOperand(callFrame, bytecode.m_lhs)));
1270 }
1271 
1272 LLINT_SLOW_PATH_DECL(slow_path_jngreatereq)
1273 {
1274     LLINT_BEGIN();
1275     auto bytecode = pc-&gt;as&lt;OpJngreatereq&gt;();
1276     LLINT_BRANCH(!jsLessEq&lt;false&gt;(globalObject, getOperand(callFrame, bytecode.m_rhs), getOperand(callFrame, bytecode.m_lhs)));
1277 }
1278 
1279 LLINT_SLOW_PATH_DECL(slow_path_jeq)
1280 {
1281     LLINT_BEGIN();
1282     auto bytecode = pc-&gt;as&lt;OpJeq&gt;();
1283     LLINT_BRANCH(JSValue::equal(globalObject, getOperand(callFrame, bytecode.m_lhs), getOperand(callFrame, bytecode.m_rhs)));
1284 }
1285 
1286 LLINT_SLOW_PATH_DECL(slow_path_jneq)
1287 {
1288     LLINT_BEGIN();
1289     auto bytecode = pc-&gt;as&lt;OpJneq&gt;();
1290     LLINT_BRANCH(!JSValue::equal(globalObject, getOperand(callFrame, bytecode.m_lhs), getOperand(callFrame, bytecode.m_rhs)));
1291 }
1292 
1293 LLINT_SLOW_PATH_DECL(slow_path_jstricteq)
1294 {
1295     LLINT_BEGIN();
1296     auto bytecode = pc-&gt;as&lt;OpJstricteq&gt;();
1297     LLINT_BRANCH(JSValue::strictEqual(globalObject, getOperand(callFrame, bytecode.m_lhs), getOperand(callFrame, bytecode.m_rhs)));
1298 }
1299 
1300 LLINT_SLOW_PATH_DECL(slow_path_jnstricteq)
1301 {
1302     LLINT_BEGIN();
1303     auto bytecode = pc-&gt;as&lt;OpJnstricteq&gt;();
1304     LLINT_BRANCH(!JSValue::strictEqual(globalObject, getOperand(callFrame, bytecode.m_lhs), getOperand(callFrame, bytecode.m_rhs)));
1305 }
1306 
1307 LLINT_SLOW_PATH_DECL(slow_path_switch_imm)
1308 {
1309     LLINT_BEGIN();
1310     auto bytecode = pc-&gt;as&lt;OpSwitchImm&gt;();
1311     JSValue scrutinee = getOperand(callFrame, bytecode.m_scrutinee);
1312     ASSERT(scrutinee.isDouble());
1313     double value = scrutinee.asDouble();
1314     int32_t intValue = static_cast&lt;int32_t&gt;(value);
1315     int defaultOffset = JUMP_OFFSET(bytecode.m_defaultOffset);
1316     if (value == intValue)
1317         JUMP_TO(codeBlock-&gt;switchJumpTable(bytecode.m_tableIndex).offsetForValue(intValue, defaultOffset));
1318     else
1319         JUMP_TO(defaultOffset);
1320     LLINT_END();
1321 }
1322 
1323 LLINT_SLOW_PATH_DECL(slow_path_switch_char)
1324 {
1325     LLINT_BEGIN();
1326     auto bytecode = pc-&gt;as&lt;OpSwitchChar&gt;();
1327     JSValue scrutinee = getOperand(callFrame, bytecode.m_scrutinee);
1328     ASSERT(scrutinee.isString());
1329     JSString* string = asString(scrutinee);
1330     ASSERT(string-&gt;length() == 1);
1331     int defaultOffset = JUMP_OFFSET(bytecode.m_defaultOffset);
1332     StringImpl* impl = string-&gt;value(globalObject).impl();
1333     JUMP_TO(codeBlock-&gt;switchJumpTable(bytecode.m_tableIndex).offsetForValue((*impl)[0], defaultOffset));
1334     LLINT_END();
1335 }
1336 
1337 LLINT_SLOW_PATH_DECL(slow_path_switch_string)
1338 {
1339     LLINT_BEGIN();
1340     auto bytecode = pc-&gt;as&lt;OpSwitchString&gt;();
1341     JSValue scrutinee = getOperand(callFrame, bytecode.m_scrutinee);
1342     int defaultOffset = JUMP_OFFSET(bytecode.m_defaultOffset);
1343     if (!scrutinee.isString())
1344         JUMP_TO(defaultOffset);
1345     else {
1346         StringImpl* scrutineeStringImpl = asString(scrutinee)-&gt;value(globalObject).impl();
1347 
1348         LLINT_CHECK_EXCEPTION();
1349 
1350         JUMP_TO(codeBlock-&gt;stringSwitchJumpTable(bytecode.m_tableIndex).offsetForValue(scrutineeStringImpl, defaultOffset));
1351     }
1352     LLINT_END();
1353 }
1354 
1355 LLINT_SLOW_PATH_DECL(slow_path_new_func)
1356 {
1357     LLINT_BEGIN();
1358     auto bytecode = pc-&gt;as&lt;OpNewFunc&gt;();
1359     JSScope* scope = callFrame-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1360     slowPathLogF(&quot;Creating function!\n&quot;);
1361     LLINT_RETURN(JSFunction::create(vm, codeBlock-&gt;functionDecl(bytecode.m_functionDecl), scope));
1362 }
1363 
1364 LLINT_SLOW_PATH_DECL(slow_path_new_generator_func)
1365 {
1366     LLINT_BEGIN();
1367     auto bytecode = pc-&gt;as&lt;OpNewGeneratorFunc&gt;();
1368     JSScope* scope = callFrame-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1369     slowPathLogF(&quot;Creating function!\n&quot;);
1370     LLINT_RETURN(JSGeneratorFunction::create(vm, codeBlock-&gt;functionDecl(bytecode.m_functionDecl), scope));
1371 }
1372 
1373 LLINT_SLOW_PATH_DECL(slow_path_new_async_func)
1374 {
1375     LLINT_BEGIN();
1376     auto bytecode = pc-&gt;as&lt;OpNewAsyncFunc&gt;();
1377     JSScope* scope = callFrame-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1378     slowPathLogF(&quot;Creating async function!\n&quot;);
1379     LLINT_RETURN(JSAsyncFunction::create(vm, codeBlock-&gt;functionDecl(bytecode.m_functionDecl), scope));
1380 }
1381 
1382 LLINT_SLOW_PATH_DECL(slow_path_new_async_generator_func)
1383 {
1384     LLINT_BEGIN();
1385     auto bytecode = pc-&gt;as&lt;OpNewAsyncGeneratorFunc&gt;();
1386     JSScope* scope = callFrame-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1387     slowPathLogF(&quot;Creating async generator function!\n&quot;);
1388     LLINT_RETURN(JSAsyncGeneratorFunction::create(vm, codeBlock-&gt;functionDecl(bytecode.m_functionDecl), scope));
1389 }
1390 
1391 LLINT_SLOW_PATH_DECL(slow_path_new_func_exp)
1392 {
1393     LLINT_BEGIN();
1394 
1395     auto bytecode = pc-&gt;as&lt;OpNewFuncExp&gt;();
1396     JSScope* scope = callFrame-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1397     FunctionExecutable* executable = codeBlock-&gt;functionExpr(bytecode.m_functionDecl);
1398 
1399     LLINT_RETURN(JSFunction::create(vm, executable, scope));
1400 }
1401 
1402 LLINT_SLOW_PATH_DECL(slow_path_new_generator_func_exp)
1403 {
1404     LLINT_BEGIN();
1405 
1406     auto bytecode = pc-&gt;as&lt;OpNewGeneratorFuncExp&gt;();
1407     JSScope* scope = callFrame-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1408     FunctionExecutable* executable = codeBlock-&gt;functionExpr(bytecode.m_functionDecl);
1409 
1410     LLINT_RETURN(JSGeneratorFunction::create(vm, executable, scope));
1411 }
1412 
1413 LLINT_SLOW_PATH_DECL(slow_path_new_async_func_exp)
1414 {
1415     LLINT_BEGIN();
1416 
1417     auto bytecode = pc-&gt;as&lt;OpNewAsyncFuncExp&gt;();
1418     JSScope* scope = callFrame-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1419     FunctionExecutable* executable = codeBlock-&gt;functionExpr(bytecode.m_functionDecl);
1420 
1421     LLINT_RETURN(JSAsyncFunction::create(vm, executable, scope));
1422 }
1423 
1424 LLINT_SLOW_PATH_DECL(slow_path_new_async_generator_func_exp)
1425 {
1426     LLINT_BEGIN();
1427 
1428     auto bytecode = pc-&gt;as&lt;OpNewAsyncGeneratorFuncExp&gt;();
1429     JSScope* scope = callFrame-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1430     FunctionExecutable* executable = codeBlock-&gt;functionExpr(bytecode.m_functionDecl);
1431 
1432     LLINT_RETURN(JSAsyncGeneratorFunction::create(vm, executable, scope));
1433 }
1434 
1435 LLINT_SLOW_PATH_DECL(slow_path_set_function_name)
1436 {
1437     LLINT_BEGIN();
1438     auto bytecode = pc-&gt;as&lt;OpSetFunctionName&gt;();
1439     JSFunction* func = jsCast&lt;JSFunction*&gt;(getNonConstantOperand(callFrame, bytecode.m_function));
1440     JSValue name = getOperand(callFrame, bytecode.m_name);
1441     func-&gt;setFunctionName(globalObject, name);
1442     LLINT_END();
1443 }
1444 
1445 static SlowPathReturnType handleHostCall(CallFrame* calleeFrame, JSValue callee, CodeSpecializationKind kind)
1446 {
1447     slowPathLog(&quot;Performing host call.\n&quot;);
1448 
1449     CallFrame* callFrame = calleeFrame-&gt;callerFrame();
1450     CodeBlock* callerCodeBlock = callFrame-&gt;codeBlock();
1451     JSGlobalObject* globalObject = callerCodeBlock-&gt;globalObject();
1452     VM&amp; vm = callerCodeBlock-&gt;vm();
1453     auto throwScope = DECLARE_THROW_SCOPE(vm);
1454 
1455     calleeFrame-&gt;setCodeBlock(nullptr);
1456     calleeFrame-&gt;clearReturnPC();
1457 
1458     if (kind == CodeForCall) {
1459         CallData callData;
1460         CallType callType = getCallData(vm, callee, callData);
1461 
1462         ASSERT(callType != CallType::JS);
1463 
1464         if (callType == CallType::Host) {
1465             SlowPathFrameTracer tracer(vm, calleeFrame);
1466             calleeFrame-&gt;setCallee(asObject(callee));
1467             vm.hostCallReturnValue = JSValue::decode(callData.native.function(asObject(callee)-&gt;globalObject(vm), calleeFrame));
1468             LLINT_CALL_RETURN(globalObject, calleeFrame, LLInt::getCodePtr(getHostCallReturnValue), CFunctionPtrTag);
1469         }
1470 
1471         slowPathLog(&quot;Call callee is not a function: &quot;, callee, &quot;\n&quot;);
1472 
1473         ASSERT(callType == CallType::None);
1474         LLINT_CALL_THROW(globalObject, createNotAFunctionError(globalObject, callee));
1475     }
1476 
1477     ASSERT(kind == CodeForConstruct);
1478 
1479     ConstructData constructData;
1480     ConstructType constructType = getConstructData(vm, callee, constructData);
1481 
1482     ASSERT(constructType != ConstructType::JS);
1483 
1484     if (constructType == ConstructType::Host) {
1485         SlowPathFrameTracer tracer(vm, calleeFrame);
1486         calleeFrame-&gt;setCallee(asObject(callee));
1487         vm.hostCallReturnValue = JSValue::decode(constructData.native.function(asObject(callee)-&gt;globalObject(vm), calleeFrame));
1488         LLINT_CALL_RETURN(globalObject, calleeFrame, LLInt::getCodePtr(getHostCallReturnValue), CFunctionPtrTag);
1489     }
1490 
1491     slowPathLog(&quot;Constructor callee is not a function: &quot;, callee, &quot;\n&quot;);
1492 
1493     ASSERT(constructType == ConstructType::None);
1494     LLINT_CALL_THROW(globalObject, createNotAConstructorError(globalObject, callee));
1495 }
1496 
1497 inline SlowPathReturnType setUpCall(CallFrame* calleeFrame, CodeSpecializationKind kind, JSValue calleeAsValue, LLIntCallLinkInfo* callLinkInfo = nullptr)
1498 {
1499     CallFrame* callFrame = calleeFrame-&gt;callerFrame();
1500     CodeBlock* callerCodeBlock = callFrame-&gt;codeBlock();
1501     JSGlobalObject* globalObject = callerCodeBlock-&gt;globalObject();
1502     VM&amp; vm = callerCodeBlock-&gt;vm();
1503     auto throwScope = DECLARE_THROW_SCOPE(vm);
1504 
1505     slowPathLogF(&quot;Performing call with recorded PC = %p\n&quot;, callFrame-&gt;currentVPC());
1506 
1507     JSCell* calleeAsFunctionCell = getJSFunction(calleeAsValue);
1508     if (!calleeAsFunctionCell) {
1509         if (auto* internalFunction = jsDynamicCast&lt;InternalFunction*&gt;(vm, calleeAsValue)) {
1510             MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr = vm.getCTIInternalFunctionTrampolineFor(kind);
1511             ASSERT(!!codePtr);
1512 
1513             if (!LLINT_ALWAYS_ACCESS_SLOW &amp;&amp; callLinkInfo) {
1514                 ConcurrentJSLocker locker(callerCodeBlock-&gt;m_lock);
1515                 callLinkInfo-&gt;link(vm, callerCodeBlock, internalFunction, codePtr);
1516             }
1517 
1518             assertIsTaggedWith(codePtr.executableAddress(), JSEntryPtrTag);
1519             LLINT_CALL_RETURN(globalObject, calleeFrame, codePtr.executableAddress(), JSEntryPtrTag);
1520         }
1521         RELEASE_AND_RETURN(throwScope, handleHostCall(calleeFrame, calleeAsValue, kind));
1522     }
1523     JSFunction* callee = jsCast&lt;JSFunction*&gt;(calleeAsFunctionCell);
1524     JSScope* scope = callee-&gt;scopeUnchecked();
1525     ExecutableBase* executable = callee-&gt;executable();
1526 
1527     MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr;
1528     CodeBlock* codeBlock = nullptr;
1529     if (executable-&gt;isHostFunction())
1530         codePtr = executable-&gt;entrypointFor(kind, MustCheckArity);
1531     else {
1532         FunctionExecutable* functionExecutable = static_cast&lt;FunctionExecutable*&gt;(executable);
1533 
1534         if (!isCall(kind) &amp;&amp; functionExecutable-&gt;constructAbility() == ConstructAbility::CannotConstruct)
1535             LLINT_CALL_THROW(globalObject, createNotAConstructorError(globalObject, callee));
1536 
1537         CodeBlock** codeBlockSlot = calleeFrame-&gt;addressOfCodeBlock();
1538         Exception* error = functionExecutable-&gt;prepareForExecution&lt;FunctionExecutable&gt;(vm, callee, scope, kind, *codeBlockSlot);
1539         EXCEPTION_ASSERT(throwScope.exception() == error);
1540         if (UNLIKELY(error))
1541             LLINT_CALL_THROW(globalObject, error);
1542         codeBlock = *codeBlockSlot;
1543         ASSERT(codeBlock);
1544         ArityCheckMode arity;
1545         if (calleeFrame-&gt;argumentCountIncludingThis() &lt; static_cast&lt;size_t&gt;(codeBlock-&gt;numParameters()))
1546             arity = MustCheckArity;
1547         else
1548             arity = ArityCheckNotRequired;
1549         codePtr = functionExecutable-&gt;entrypointFor(kind, arity);
1550     }
1551 
1552     ASSERT(!!codePtr);
1553 
1554     if (!LLINT_ALWAYS_ACCESS_SLOW &amp;&amp; callLinkInfo) {
1555         ConcurrentJSLocker locker(callerCodeBlock-&gt;m_lock);
1556         callLinkInfo-&gt;link(vm, callerCodeBlock, callee, codePtr);
1557         if (codeBlock)
1558             codeBlock-&gt;linkIncomingCall(callFrame, callLinkInfo);
1559     }
1560 
1561     assertIsTaggedWith(codePtr.executableAddress(), JSEntryPtrTag);
1562     LLINT_CALL_RETURN(globalObject, calleeFrame, codePtr.executableAddress(), JSEntryPtrTag);
1563 }
1564 
1565 template&lt;typename Op&gt;
1566 inline SlowPathReturnType genericCall(CodeBlock* codeBlock, CallFrame* callFrame, Op&amp;&amp; bytecode, CodeSpecializationKind kind)
1567 {
1568     // This needs to:
1569     // - Set up a call frame.
1570     // - Figure out what to call and compile it if necessary.
1571     // - If possible, link the call&#39;s inline cache.
1572     // - Return a tuple of machine code address to call and the new call frame.
1573 
1574     JSValue calleeAsValue = getOperand(callFrame, bytecode.m_callee);
1575 
1576     CallFrame* calleeFrame = callFrame - bytecode.m_argv;
1577 
1578     calleeFrame-&gt;setArgumentCountIncludingThis(bytecode.m_argc);
1579     calleeFrame-&gt;uncheckedR(VirtualRegister(CallFrameSlot::callee)) = calleeAsValue;
1580     calleeFrame-&gt;setCallerFrame(callFrame);
1581 
1582     auto&amp; metadata = bytecode.metadata(codeBlock);
1583     return setUpCall(calleeFrame, kind, calleeAsValue, &amp;metadata.m_callLinkInfo);
1584 }
1585 
1586 LLINT_SLOW_PATH_DECL(slow_path_call)
1587 {
1588     LLINT_BEGIN_NO_SET_PC();
1589     UNUSED_PARAM(globalObject);
1590     RELEASE_AND_RETURN(throwScope, genericCall(codeBlock, callFrame, pc-&gt;as&lt;OpCall&gt;(), CodeForCall));
1591 }
1592 
1593 LLINT_SLOW_PATH_DECL(slow_path_tail_call)
1594 {
1595     LLINT_BEGIN_NO_SET_PC();
1596     UNUSED_PARAM(globalObject);
1597     RELEASE_AND_RETURN(throwScope, genericCall(codeBlock, callFrame, pc-&gt;as&lt;OpTailCall&gt;(), CodeForCall));
1598 }
1599 
1600 LLINT_SLOW_PATH_DECL(slow_path_construct)
1601 {
1602     LLINT_BEGIN_NO_SET_PC();
1603     UNUSED_PARAM(globalObject);
1604     RELEASE_AND_RETURN(throwScope, genericCall(codeBlock, callFrame, pc-&gt;as&lt;OpConstruct&gt;(), CodeForConstruct));
1605 }
1606 
1607 LLINT_SLOW_PATH_DECL(slow_path_size_frame_for_varargs)
1608 {
1609     LLINT_BEGIN();
1610     // This needs to:
1611     // - Set up a call frame while respecting the variable arguments.
1612 
1613     unsigned numUsedStackSlots;
1614     JSValue arguments;
1615     int firstVarArg;
1616     switch (pc-&gt;opcodeID()) {
1617     case op_call_varargs: {
1618         auto bytecode = pc-&gt;as&lt;OpCallVarargs&gt;();
1619         numUsedStackSlots = -bytecode.m_firstFree.offset();
1620         arguments = getOperand(callFrame, bytecode.m_arguments);
1621         firstVarArg = bytecode.m_firstVarArg;
1622         break;
1623     }
1624     case op_tail_call_varargs: {
1625         auto bytecode = pc-&gt;as&lt;OpTailCallVarargs&gt;();
1626         numUsedStackSlots = -bytecode.m_firstFree.offset();
1627         arguments = getOperand(callFrame, bytecode.m_arguments);
1628         firstVarArg = bytecode.m_firstVarArg;
1629         break;
1630     }
1631     case op_construct_varargs: {
1632         auto bytecode = pc-&gt;as&lt;OpConstructVarargs&gt;();
1633         numUsedStackSlots = -bytecode.m_firstFree.offset();
1634         arguments = getOperand(callFrame, bytecode.m_arguments);
1635         firstVarArg = bytecode.m_firstVarArg;
1636         break;
1637     }
1638     default:
1639         RELEASE_ASSERT_NOT_REACHED();
1640     }
1641     unsigned length = sizeFrameForVarargs(globalObject, callFrame, vm, arguments, numUsedStackSlots, firstVarArg);
1642     LLINT_CALL_CHECK_EXCEPTION(globalObject);
1643 
1644     CallFrame* calleeFrame = calleeFrameForVarargs(callFrame, numUsedStackSlots, length + 1);
1645     vm.varargsLength = length;
1646     vm.newCallFrameReturnValue = calleeFrame;
1647 
1648     LLINT_RETURN_CALLEE_FRAME(calleeFrame);
1649 }
1650 
1651 LLINT_SLOW_PATH_DECL(slow_path_size_frame_for_forward_arguments)
1652 {
1653     LLINT_BEGIN();
1654     // This needs to:
1655     // - Set up a call frame with the same arguments as the current frame.
1656 
1657     auto bytecode = pc-&gt;as&lt;OpTailCallForwardArguments&gt;();
1658     unsigned numUsedStackSlots = -bytecode.m_firstFree.offset();
1659 
1660     unsigned arguments = sizeFrameForForwardArguments(globalObject, callFrame, vm, numUsedStackSlots);
1661     LLINT_CALL_CHECK_EXCEPTION(globalObject);
1662 
1663     CallFrame* calleeFrame = calleeFrameForVarargs(callFrame, numUsedStackSlots, arguments + 1);
1664 
1665     vm.varargsLength = arguments;
1666     vm.newCallFrameReturnValue = calleeFrame;
1667 
1668     LLINT_RETURN_CALLEE_FRAME(calleeFrame);
1669 }
1670 
1671 enum class SetArgumentsWith {
1672     Object,
1673     CurrentArguments
1674 };
1675 
1676 template&lt;typename Op&gt;
1677 inline SlowPathReturnType varargsSetup(CallFrame* callFrame, const Instruction* pc, CodeSpecializationKind kind, SetArgumentsWith set)
1678 {
1679     LLINT_BEGIN_NO_SET_PC();
1680 
1681     // This needs to:
1682     // - Figure out what to call and compile it if necessary.
1683     // - Return a tuple of machine code address to call and the new call frame.
1684 
1685     auto bytecode = pc-&gt;as&lt;Op&gt;();
1686     JSValue calleeAsValue = getOperand(callFrame, bytecode.m_callee);
1687 
1688     CallFrame* calleeFrame = vm.newCallFrameReturnValue;
1689 
1690     if (set == SetArgumentsWith::Object) {
1691         setupVarargsFrameAndSetThis(globalObject, callFrame, calleeFrame, getOperand(callFrame, bytecode.m_thisValue), getOperand(callFrame, bytecode.m_arguments), bytecode.m_firstVarArg, vm.varargsLength);
1692         LLINT_CALL_CHECK_EXCEPTION(globalObject);
1693     } else
1694         setupForwardArgumentsFrameAndSetThis(globalObject, callFrame, calleeFrame, getOperand(callFrame, bytecode.m_thisValue), vm.varargsLength);
1695 
1696     calleeFrame-&gt;setCallerFrame(callFrame);
1697     calleeFrame-&gt;uncheckedR(VirtualRegister(CallFrameSlot::callee)) = calleeAsValue;
1698     callFrame-&gt;setCurrentVPC(pc);
1699 
1700     RELEASE_AND_RETURN(throwScope, setUpCall(calleeFrame, kind, calleeAsValue));
1701 }
1702 
1703 LLINT_SLOW_PATH_DECL(slow_path_call_varargs)
1704 {
1705     return varargsSetup&lt;OpCallVarargs&gt;(callFrame, pc, CodeForCall, SetArgumentsWith::Object);
1706 }
1707 
1708 LLINT_SLOW_PATH_DECL(slow_path_tail_call_varargs)
1709 {
1710     return varargsSetup&lt;OpTailCallVarargs&gt;(callFrame, pc, CodeForCall, SetArgumentsWith::Object);
1711 }
1712 
1713 LLINT_SLOW_PATH_DECL(slow_path_tail_call_forward_arguments)
1714 {
1715     return varargsSetup&lt;OpTailCallForwardArguments&gt;(callFrame, pc, CodeForCall, SetArgumentsWith::CurrentArguments);
1716 }
1717 
1718 LLINT_SLOW_PATH_DECL(slow_path_construct_varargs)
1719 {
1720     return varargsSetup&lt;OpConstructVarargs&gt;(callFrame, pc, CodeForConstruct, SetArgumentsWith::Object);
1721 }
1722 
1723 inline SlowPathReturnType commonCallEval(CallFrame* callFrame, const Instruction* pc, MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; returnPoint)
1724 {
1725     LLINT_BEGIN_NO_SET_PC();
1726     auto bytecode = pc-&gt;as&lt;OpCallEval&gt;();
1727     JSValue calleeAsValue = getNonConstantOperand(callFrame, bytecode.m_callee);
1728 
1729     CallFrame* calleeFrame = callFrame - bytecode.m_argv;
1730 
1731     calleeFrame-&gt;setArgumentCountIncludingThis(bytecode.m_argc);
1732     calleeFrame-&gt;setCallerFrame(callFrame);
1733     calleeFrame-&gt;uncheckedR(VirtualRegister(CallFrameSlot::callee)) = calleeAsValue;
1734     calleeFrame-&gt;setReturnPC(returnPoint.executableAddress());
1735     calleeFrame-&gt;setCodeBlock(nullptr);
1736     callFrame-&gt;setCurrentVPC(pc);
1737 
1738     if (!isHostFunction(calleeAsValue, globalFuncEval))
1739         RELEASE_AND_RETURN(throwScope, setUpCall(calleeFrame, CodeForCall, calleeAsValue));
1740 
1741     vm.hostCallReturnValue = eval(globalObject, calleeFrame);
1742     LLINT_CALL_RETURN(globalObject, calleeFrame, LLInt::getCodePtr(getHostCallReturnValue), CFunctionPtrTag);
1743 }
1744 
1745 LLINT_SLOW_PATH_DECL(slow_path_call_eval)
1746 {
1747     return commonCallEval(callFrame, pc, LLInt::getCodePtr&lt;JSEntryPtrTag&gt;(llint_generic_return_point));
1748 }
1749 
1750 LLINT_SLOW_PATH_DECL(slow_path_call_eval_wide16)
1751 {
1752     return commonCallEval(callFrame, pc, LLInt::getWide16CodePtr&lt;JSEntryPtrTag&gt;(llint_generic_return_point));
1753 }
1754 
1755 LLINT_SLOW_PATH_DECL(slow_path_call_eval_wide32)
1756 {
1757     return commonCallEval(callFrame, pc, LLInt::getWide32CodePtr&lt;JSEntryPtrTag&gt;(llint_generic_return_point));
1758 }
1759 
1760 LLINT_SLOW_PATH_DECL(slow_path_strcat)
1761 {
1762     LLINT_BEGIN();
1763     auto bytecode = pc-&gt;as&lt;OpStrcat&gt;();
1764     LLINT_RETURN(jsStringFromRegisterArray(globalObject, &amp;callFrame-&gt;uncheckedR(bytecode.m_src), bytecode.m_count));
1765 }
1766 
1767 LLINT_SLOW_PATH_DECL(slow_path_to_primitive)
1768 {
1769     LLINT_BEGIN();
1770     auto bytecode = pc-&gt;as&lt;OpToPrimitive&gt;();
1771     LLINT_RETURN(getOperand(callFrame, bytecode.m_src).toPrimitive(globalObject));
1772 }
1773 
1774 LLINT_SLOW_PATH_DECL(slow_path_throw)
1775 {
1776     LLINT_BEGIN();
1777     auto bytecode = pc-&gt;as&lt;OpThrow&gt;();
1778     LLINT_THROW(getOperand(callFrame, bytecode.m_value));
1779 }
1780 
1781 LLINT_SLOW_PATH_DECL(slow_path_handle_traps)
1782 {
1783     LLINT_BEGIN_NO_SET_PC();
1784     ASSERT(vm.needTrapHandling());
1785     vm.handleTraps(globalObject, callFrame);
1786     UNUSED_PARAM(pc);
1787     LLINT_RETURN_TWO(throwScope.exception(), globalObject);
1788 }
1789 
1790 LLINT_SLOW_PATH_DECL(slow_path_debug)
1791 {
1792     LLINT_BEGIN();
1793     auto bytecode = pc-&gt;as&lt;OpDebug&gt;();
1794     vm.interpreter-&gt;debug(callFrame, bytecode.m_debugHookType);
1795 
1796     LLINT_END();
1797 }
1798 
1799 LLINT_SLOW_PATH_DECL(slow_path_handle_exception)
1800 {
1801     VM&amp; vm = callFrame-&gt;deprecatedVM();
1802     SlowPathFrameTracer tracer(vm, callFrame);
1803     genericUnwind(vm, callFrame);
1804     LLINT_END_IMPL();
1805 }
1806 
1807 LLINT_SLOW_PATH_DECL(slow_path_get_from_scope)
1808 {
1809     LLINT_BEGIN();
1810     auto bytecode = pc-&gt;as&lt;OpGetFromScope&gt;();
1811     auto&amp; metadata = bytecode.metadata(codeBlock);
1812     const Identifier&amp; ident = codeBlock-&gt;identifier(bytecode.m_var);
1813     JSObject* scope = jsCast&lt;JSObject*&gt;(getNonConstantOperand(callFrame, bytecode.m_scope));
1814 
1815     // ModuleVar is always converted to ClosureVar for get_from_scope.
1816     ASSERT(metadata.m_getPutInfo.resolveType() != ModuleVar);
1817 
1818     LLINT_RETURN(scope-&gt;getPropertySlot(globalObject, ident, [&amp;] (bool found, PropertySlot&amp; slot) -&gt; JSValue {
1819         if (!found) {
1820             if (metadata.m_getPutInfo.resolveMode() == ThrowIfNotFound)
1821                 return throwException(globalObject, throwScope, createUndefinedVariableError(globalObject, ident));
1822             return jsUndefined();
1823         }
1824 
1825         JSValue result = JSValue();
1826         if (scope-&gt;isGlobalLexicalEnvironment()) {
1827             // When we can&#39;t statically prove we need a TDZ check, we must perform the check on the slow path.
1828             result = slot.getValue(globalObject, ident);
1829             if (result == jsTDZValue())
1830                 return throwException(globalObject, throwScope, createTDZError(globalObject));
1831         }
1832 
1833         CommonSlowPaths::tryCacheGetFromScopeGlobal(globalObject, codeBlock, vm, bytecode, scope, slot, ident);
1834 
1835         if (!result)
1836             return slot.getValue(globalObject, ident);
1837         return result;
1838     }));
1839 }
1840 
1841 LLINT_SLOW_PATH_DECL(slow_path_put_to_scope)
1842 {
1843     LLINT_BEGIN();
1844 
1845     auto bytecode = pc-&gt;as&lt;OpPutToScope&gt;();
1846     auto&amp; metadata = bytecode.metadata(codeBlock);
1847     const Identifier&amp; ident = codeBlock-&gt;identifier(bytecode.m_var);
1848     JSObject* scope = jsCast&lt;JSObject*&gt;(getNonConstantOperand(callFrame, bytecode.m_scope));
1849     JSValue value = getOperand(callFrame, bytecode.m_value);
1850     if (metadata.m_getPutInfo.resolveType() == LocalClosureVar) {
1851         JSLexicalEnvironment* environment = jsCast&lt;JSLexicalEnvironment*&gt;(scope);
1852         environment-&gt;variableAt(ScopeOffset(metadata.m_operand)).set(vm, environment, value);
1853 
1854         // Have to do this *after* the write, because if this puts the set into IsWatched, then we need
1855         // to have already changed the value of the variable. Otherwise we might watch and constant-fold
1856         // to the Undefined value from before the assignment.
1857         if (metadata.m_watchpointSet)
1858             metadata.m_watchpointSet-&gt;touch(vm, &quot;Executed op_put_scope&lt;LocalClosureVar&gt;&quot;);
1859         LLINT_END();
1860     }
1861 
1862     bool hasProperty = scope-&gt;hasProperty(globalObject, ident);
1863     LLINT_CHECK_EXCEPTION();
1864     if (hasProperty
1865         &amp;&amp; scope-&gt;isGlobalLexicalEnvironment()
1866         &amp;&amp; !isInitialization(metadata.m_getPutInfo.initializationMode())) {
1867         // When we can&#39;t statically prove we need a TDZ check, we must perform the check on the slow path.
1868         PropertySlot slot(scope, PropertySlot::InternalMethodType::Get);
1869         JSGlobalLexicalEnvironment::getOwnPropertySlot(scope, globalObject, ident, slot);
1870         if (slot.getValue(globalObject, ident) == jsTDZValue())
1871             LLINT_THROW(createTDZError(globalObject));
1872     }
1873 
1874     if (metadata.m_getPutInfo.resolveMode() == ThrowIfNotFound &amp;&amp; !hasProperty)
1875         LLINT_THROW(createUndefinedVariableError(globalObject, ident));
1876 
1877     PutPropertySlot slot(scope, codeBlock-&gt;isStrictMode(), PutPropertySlot::UnknownContext, isInitialization(metadata.m_getPutInfo.initializationMode()));
1878     scope-&gt;methodTable(vm)-&gt;put(scope, globalObject, ident, value, slot);
1879 
1880     CommonSlowPaths::tryCachePutToScopeGlobal(globalObject, codeBlock, bytecode, scope, slot, ident);
1881 
1882     LLINT_END();
1883 }
1884 
1885 LLINT_SLOW_PATH_DECL(slow_path_check_if_exception_is_uncatchable_and_notify_profiler)
1886 {
1887     LLINT_BEGIN();
1888     UNUSED_PARAM(globalObject);
1889     RELEASE_ASSERT(!!throwScope.exception());
1890 
1891     if (isTerminatedExecutionException(vm, throwScope.exception()))
1892         LLINT_RETURN_TWO(pc, bitwise_cast&lt;void*&gt;(static_cast&lt;uintptr_t&gt;(1)));
1893     LLINT_RETURN_TWO(pc, nullptr);
1894 }
1895 
1896 LLINT_SLOW_PATH_DECL(slow_path_log_shadow_chicken_prologue)
1897 {
1898     LLINT_BEGIN();
1899 
1900     auto bytecode = pc-&gt;as&lt;OpLogShadowChickenPrologue&gt;();
1901     JSScope* scope = callFrame-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1902     ShadowChicken* shadowChicken = vm.shadowChicken();
1903     RELEASE_ASSERT(shadowChicken);
1904     shadowChicken-&gt;log(vm, callFrame, ShadowChicken::Packet::prologue(callFrame-&gt;jsCallee(), callFrame, callFrame-&gt;callerFrame(), scope));
1905 
1906     LLINT_END();
1907 }
1908 
1909 LLINT_SLOW_PATH_DECL(slow_path_log_shadow_chicken_tail)
1910 {
1911     LLINT_BEGIN();
1912 
1913     auto bytecode = pc-&gt;as&lt;OpLogShadowChickenTail&gt;();
1914     JSValue thisValue = getNonConstantOperand(callFrame, bytecode.m_thisValue);
1915     JSScope* scope = callFrame-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1916 
1917     CallSiteIndex callSiteIndex(BytecodeIndex(codeBlock-&gt;bytecodeOffset(pc)));
1918 
1919     ShadowChicken* shadowChicken = vm.shadowChicken();
1920     RELEASE_ASSERT(shadowChicken);
1921     shadowChicken-&gt;log(vm, callFrame, ShadowChicken::Packet::tail(callFrame, thisValue, scope, codeBlock, callSiteIndex));
1922 
1923     LLINT_END();
1924 }
1925 
1926 LLINT_SLOW_PATH_DECL(slow_path_profile_catch)
1927 {
1928     LLINT_BEGIN();
1929 
1930     codeBlock-&gt;ensureCatchLivenessIsComputedForBytecodeIndex(callFrame-&gt;bytecodeIndex());
1931 
1932     auto bytecode = pc-&gt;as&lt;OpCatch&gt;();
1933     auto&amp; metadata = bytecode.metadata(codeBlock);
1934     metadata.m_buffer-&gt;forEach([&amp;] (ValueProfileAndVirtualRegister&amp; profile) {
1935         profile.m_buckets[0] = JSValue::encode(callFrame-&gt;uncheckedR(profile.m_operand).jsValue());
1936     });
1937 
1938     LLINT_END();
1939 }
1940 
1941 LLINT_SLOW_PATH_DECL(slow_path_super_sampler_begin)
1942 {
1943     // FIXME: It seems like we should be able to do this in asm but llint doesn&#39;t seem to like global variables.
1944     // See: https://bugs.webkit.org/show_bug.cgi?id=179438
1945     UNUSED_PARAM(callFrame);
1946     g_superSamplerCount++;
1947     LLINT_END_IMPL();
1948 }
1949 
1950 LLINT_SLOW_PATH_DECL(slow_path_super_sampler_end)
1951 {
1952     // FIXME: It seems like we should be able to do this in asm but llint doesn&#39;t seem to like global variables.
1953     // See: https://bugs.webkit.org/show_bug.cgi?id=179438
1954     UNUSED_PARAM(callFrame);
1955     g_superSamplerCount--;
1956     LLINT_END_IMPL();
1957 }
1958 
1959 LLINT_SLOW_PATH_DECL(slow_path_out_of_line_jump_target)
1960 {
1961     pc = callFrame-&gt;codeBlock()-&gt;outOfLineJumpTarget(pc);
1962     LLINT_END_IMPL();
1963 }
1964 
1965 template&lt;typename Opcode&gt;
1966 static void handleVarargsCheckpoint(VM&amp; vm, CallFrame* callFrame, JSGlobalObject* globalObject, const Opcode&amp; bytecode, CheckpointOSRExitSideState&amp; sideState)
1967 {
1968     auto scope = DECLARE_THROW_SCOPE(vm);
1969     unsigned argumentCountIncludingThis = sideState.tmps[Opcode::argCountIncludingThis].asUInt32();
1970     unsigned firstVarArg = bytecode.m_firstVarArg;
1971 
1972     MarkedArgumentBuffer args;
1973     args.fill(argumentCountIncludingThis - 1, [&amp;] (JSValue* buffer) {
1974         loadVarargs(globalObject, buffer, callFrame-&gt;r(bytecode.m_arguments).jsValue(), firstVarArg, argumentCountIncludingThis - 1);
1975     });
1976     if (args.hasOverflowed()) {
1977         throwStackOverflowError(globalObject, scope);
1978         return;
1979     }
1980 
1981     RETURN_IF_EXCEPTION(scope, void());
1982 
1983     JSValue result;
1984     if (Opcode::opcodeID != op_construct_varargs)
1985         result = call(globalObject, getOperand(callFrame, bytecode.m_callee), getOperand(callFrame, bytecode.m_thisValue), args, &quot;&quot;);
1986     else
1987         result = construct(globalObject, getOperand(callFrame, bytecode.m_callee), getOperand(callFrame, bytecode.m_thisValue), args, &quot;&quot;);
1988 
1989     RETURN_IF_EXCEPTION(scope, void());
1990     callFrame-&gt;uncheckedR(bytecode.m_dst) = result;
1991 }
1992 
1993 inline SlowPathReturnType dispatchToNextInstruction(CodeBlock* codeBlock, InstructionStream::Ref pc)
1994 {
1995     RELEASE_ASSERT(!codeBlock-&gt;vm().exceptionForInspection());
1996     if (Options::forceOSRExitToLLInt() || codeBlock-&gt;jitType() == JITType::InterpreterThunk) {
1997         const Instruction* nextPC = pc.next().ptr();
1998         auto nextBytecode = LLInt::getCodePtr&lt;JSEntryPtrTag&gt;(*pc.next().ptr());
1999         return encodeResult(nextPC, nextBytecode.executableAddress());
2000     }
2001 
2002 #if ENABLE(JIT)
2003     ASSERT(codeBlock-&gt;jitType() == JITType::BaselineJIT);
2004     BytecodeIndex nextBytecodeIndex = pc.next().index();
2005     auto nextBytecode = codeBlock-&gt;jitCodeMap().find(nextBytecodeIndex);
2006     return encodeResult(nullptr, nextBytecode.executableAddress());
2007 #endif
2008     RELEASE_ASSERT_NOT_REACHED();
2009 }
2010 
2011 extern &quot;C&quot; SlowPathReturnType slow_path_checkpoint_osr_exit_from_inlined_call(CallFrame* callFrame, EncodedJSValue result)
2012 {
2013     // Since all our calling checkpoints do right now is move result into our dest we can just do that here and return.
2014     CodeBlock* codeBlock = callFrame-&gt;codeBlock();
2015     VM&amp; vm = codeBlock-&gt;vm();
2016     SlowPathFrameTracer tracer(vm, callFrame);
2017 
2018     std::unique_ptr&lt;CheckpointOSRExitSideState&gt; sideState = vm.findCheckpointOSRSideState(callFrame);
2019     BytecodeIndex bytecodeIndex = sideState-&gt;bytecodeIndex;
2020     auto pc = codeBlock-&gt;instructions().at(bytecodeIndex);
2021 
2022     auto opcode = pc-&gt;opcodeID();
2023     switch (opcode) {
2024     case op_call_varargs: {
2025         callFrame-&gt;uncheckedR(pc-&gt;as&lt;OpCallVarargs&gt;().m_dst) = JSValue::decode(result);
2026         break;
2027     }
2028     case op_construct_varargs: {
2029         callFrame-&gt;uncheckedR(pc-&gt;as&lt;OpConstructVarargs&gt;().m_dst) = JSValue::decode(result);
2030         break;
2031     }
2032     // op_tail_call_varargs should never return if the thing it was calling was inlined.
2033     default:
2034         RELEASE_ASSERT_NOT_REACHED();
2035         break;
2036     }
2037 
2038     return dispatchToNextInstruction(codeBlock, pc);
2039 }
2040 
2041 extern &quot;C&quot; SlowPathReturnType slow_path_checkpoint_osr_exit(CallFrame* callFrame, EncodedJSValue /* needed for cCall2 in CLoop */)
2042 {
2043     CodeBlock* codeBlock = callFrame-&gt;codeBlock();
2044     VM&amp; vm = codeBlock-&gt;vm();
2045     SlowPathFrameTracer tracer(vm, callFrame);
2046     auto scope = DECLARE_THROW_SCOPE(vm);
2047 
2048     JSGlobalObject* globalObject = codeBlock-&gt;globalObject();
2049 
2050     std::unique_ptr&lt;CheckpointOSRExitSideState&gt; sideState = vm.findCheckpointOSRSideState(callFrame);
2051     BytecodeIndex bytecodeIndex = sideState-&gt;bytecodeIndex;
2052     ASSERT(bytecodeIndex.checkpoint());
2053 
2054     auto pc = codeBlock-&gt;instructions().at(bytecodeIndex);
2055 
2056     auto opcode = pc-&gt;opcodeID();
2057     switch (opcode) {
2058     case op_call_varargs:
2059         handleVarargsCheckpoint(vm, callFrame, globalObject, pc-&gt;as&lt;OpCallVarargs&gt;(), *sideState.get());
2060         break;
2061     case op_construct_varargs:
2062         handleVarargsCheckpoint(vm, callFrame, globalObject, pc-&gt;as&lt;OpConstructVarargs&gt;(), *sideState.get());
2063         break;
2064     case op_tail_call_varargs:
2065         ASSERT_WITH_MESSAGE(pc.next()-&gt;opcodeID() == op_ret || pc.next()-&gt;opcodeID() == op_jmp, &quot;We strongly assume all tail calls are followed by an op_ret (or sometimes a jmp to a ret).&quot;);
2066         handleVarargsCheckpoint(vm, callFrame, globalObject, pc-&gt;as&lt;OpTailCallVarargs&gt;(), *sideState.get());
2067         break;
2068 
2069     default:
2070         RELEASE_ASSERT_NOT_REACHED();
2071         break;
2072     }
2073     if (UNLIKELY(scope.exception()))
2074         return encodeResult(returnToThrow(vm), 0);
2075 
2076     return dispatchToNextInstruction(codeBlock, pc);
2077 }
2078 
2079 extern &quot;C&quot; SlowPathReturnType llint_throw_stack_overflow_error(VM* vm, ProtoCallFrame* protoFrame)
2080 {
2081     CallFrame* callFrame = vm-&gt;topCallFrame;
2082     auto scope = DECLARE_THROW_SCOPE(*vm);
2083     JSGlobalObject* globalObject = nullptr;
2084     if (callFrame)
2085         globalObject = callFrame-&gt;lexicalGlobalObject(*vm);
2086     else
2087         globalObject = protoFrame-&gt;callee()-&gt;globalObject(*vm);
2088     throwStackOverflowError(globalObject, scope);
2089     return encodeResult(0, 0);
2090 }
2091 
2092 #if ENABLE(C_LOOP)
2093 extern &quot;C&quot; SlowPathReturnType llint_stack_check_at_vm_entry(VM* vm, Register* newTopOfStack)
2094 {
2095     bool success = vm-&gt;ensureStackCapacityFor(newTopOfStack);
2096     return encodeResult(reinterpret_cast&lt;void*&gt;(success), 0);
2097 }
2098 #endif
2099 
2100 extern &quot;C&quot; void llint_write_barrier_slow(CallFrame* callFrame, JSCell* cell)
2101 {
2102     VM&amp; vm = callFrame-&gt;codeBlock()-&gt;vm();
2103     vm.heap.writeBarrier(cell);
2104 }
2105 
2106 extern &quot;C&quot; NO_RETURN_DUE_TO_CRASH void llint_crash()
2107 {
2108     CRASH();
2109 }
2110 
2111 } } // namespace JSC::LLInt
    </pre>
  </body>
</html>