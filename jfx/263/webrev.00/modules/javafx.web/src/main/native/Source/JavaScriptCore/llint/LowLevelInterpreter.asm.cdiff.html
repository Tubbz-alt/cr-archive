<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter.asm</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="LLIntThunks.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="LowLevelInterpreter.cpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter.asm</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 1,6 ***</span>
<span class="line-modified">! # Copyrsght (C) 2011-2019 Apple Inc. All rights reserved.</span>
  #
  # Redistribution and use in source and binary forms, with or without
  # modification, are permitted provided that the following conditions
  # are met:
  # 1. Redistributions of source code must retain the above copyright
<span class="line-new-header">--- 1,6 ---</span>
<span class="line-modified">! # Copyright (C) 2011-2019 Apple Inc. All rights reserved.</span>
  #
  # Redistribution and use in source and binary forms, with or without
  # modification, are permitted provided that the following conditions
  # are met:
  # 1. Redistributions of source code must retain the above copyright
</pre>
<hr />
<pre>
<span class="line-old-header">*** 72,12 ***</span>
  #  registers on all architectures.
  #
  #  - lr is defined on non-X86 architectures (ARM64, ARM64E, ARMv7, MIPS and CLOOP)
  #  and holds the return PC
  #
<span class="line-removed">- #  - pc holds the (native) program counter on 32-bits ARM architectures (ARMv7)</span>
<span class="line-removed">- #</span>
  #  - t0, t1, t2, t3, t4, and optionally t5, t6, and t7 are temporary registers that can get trashed on
  #  calls, and are pairwise distinct registers. t4 holds the JS program counter, so use
  #  with caution in opcodes (actually, don&#39;t use it in opcodes at all, except as PC).
  #
  #  - r0 and r1 are the platform&#39;s customary return registers, and thus are
<span class="line-new-header">--- 72,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 104,13 ***</span>
  #  can be return registers.
  #
  #  - t4 and t5 are never argument registers, t3 can only be a3, t1 can only be
  #  a1; but t0 and t2 can be either a0 or a2.
  #
<span class="line-modified">! #  - On 64 bits, there are callee-save registers named csr0, csr1, ... csrN.</span>
  #  The last three csr registers are used used to store the PC base and
<span class="line-modified">! #  two special tag values. Don&#39;t use them for anything else.</span>
  #
  # Additional platform-specific details (you shouldn&#39;t rely on this remaining
  # true):
  #
  #  - For consistency with the baseline JIT, t0 is always r0 (and t1 is always
<span class="line-new-header">--- 102,13 ---</span>
  #  can be return registers.
  #
  #  - t4 and t5 are never argument registers, t3 can only be a3, t1 can only be
  #  a1; but t0 and t2 can be either a0 or a2.
  #
<span class="line-modified">! #  - There are callee-save registers named csr0, csr1, ... csrN.</span>
  #  The last three csr registers are used used to store the PC base and
<span class="line-modified">! #  two special tag values (on 64-bits only). Don&#39;t use them for anything else.</span>
  #
  # Additional platform-specific details (you shouldn&#39;t rely on this remaining
  # true):
  #
  #  - For consistency with the baseline JIT, t0 is always r0 (and t1 is always
</pre>
<hr />
<pre>
<span class="line-old-header">*** 163,10 ***</span>
<span class="line-new-header">--- 161,11 ---</span>
      const CallFrameAlignSlots = 1
  end
  
  const JSLexicalEnvironment_variables = (sizeof JSLexicalEnvironment + SlotSize - 1) &amp; ~(SlotSize - 1)
  const DirectArguments_storage = (sizeof DirectArguments + SlotSize - 1) &amp; ~(SlotSize - 1)
<span class="line-added">+ const JSInternalFieldObjectImpl_internalFields = JSInternalFieldObjectImpl::m_internalFields</span>
  
  const StackAlignment = constexpr (stackAlignmentBytes())
  const StackAlignmentSlots = constexpr (stackAlignmentRegisters())
  const StackAlignmentMask = StackAlignment - 1
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 174,30 ***</span>
  
  const CallerFrame = 0
  const ReturnPC = CallerFrame + MachineRegisterSize
  const CodeBlock = ReturnPC + MachineRegisterSize
  const Callee = CodeBlock + SlotSize
<span class="line-modified">! const ArgumentCount = Callee + SlotSize</span>
<span class="line-modified">! const ThisArgumentOffset = ArgumentCount + SlotSize</span>
  const FirstArgumentOffset = ThisArgumentOffset + SlotSize
  const CallFrameHeaderSize = ThisArgumentOffset
  
  const MetadataOffsetTable16Offset = 0
  const MetadataOffsetTable32Offset = constexpr UnlinkedMetadataTable::s_offset16TableSize
  
  # Some value representation constants.
  if JSVALUE64
<span class="line-modified">!     const TagBitTypeOther = constexpr TagBitTypeOther</span>
<span class="line-modified">!     const TagBitBool      = constexpr TagBitBool</span>
<span class="line-modified">!     const TagBitUndefined = constexpr TagBitUndefined</span>
<span class="line-modified">!     const ValueEmpty      = constexpr ValueEmpty</span>
<span class="line-modified">!     const ValueFalse      = constexpr ValueFalse</span>
<span class="line-modified">!     const ValueTrue       = constexpr ValueTrue</span>
<span class="line-modified">!     const ValueUndefined  = constexpr ValueUndefined</span>
<span class="line-modified">!     const ValueNull       = constexpr ValueNull</span>
<span class="line-modified">!     const TagTypeNumber   = constexpr TagTypeNumber</span>
<span class="line-modified">!     const TagMask         = constexpr TagMask</span>
  else
      const Int32Tag = constexpr JSValue::Int32Tag
      const BooleanTag = constexpr JSValue::BooleanTag
      const NullTag = constexpr JSValue::NullTag
      const UndefinedTag = constexpr JSValue::UndefinedTag
<span class="line-new-header">--- 173,31 ---</span>
  
  const CallerFrame = 0
  const ReturnPC = CallerFrame + MachineRegisterSize
  const CodeBlock = ReturnPC + MachineRegisterSize
  const Callee = CodeBlock + SlotSize
<span class="line-modified">! const ArgumentCountIncludingThis = Callee + SlotSize</span>
<span class="line-modified">! const ThisArgumentOffset = ArgumentCountIncludingThis + SlotSize</span>
  const FirstArgumentOffset = ThisArgumentOffset + SlotSize
  const CallFrameHeaderSize = ThisArgumentOffset
  
  const MetadataOffsetTable16Offset = 0
  const MetadataOffsetTable32Offset = constexpr UnlinkedMetadataTable::s_offset16TableSize
<span class="line-added">+ const NumberOfJSOpcodeIDs = constexpr numOpcodeIDs</span>
  
  # Some value representation constants.
  if JSVALUE64
<span class="line-modified">!     const TagOther        = constexpr JSValue::OtherTag</span>
<span class="line-modified">!     const TagBool         = constexpr JSValue::BoolTag</span>
<span class="line-modified">!     const TagUndefined    = constexpr JSValue::UndefinedTag</span>
<span class="line-modified">!     const ValueEmpty      = constexpr JSValue::ValueEmpty</span>
<span class="line-modified">!     const ValueFalse      = constexpr JSValue::ValueFalse</span>
<span class="line-modified">!     const ValueTrue       = constexpr JSValue::ValueTrue</span>
<span class="line-modified">!     const ValueUndefined  = constexpr JSValue::ValueUndefined</span>
<span class="line-modified">!     const ValueNull       = constexpr JSValue::ValueNull</span>
<span class="line-modified">!     const TagNumber       = constexpr JSValue::NumberTag</span>
<span class="line-modified">!     const NotCellMask     = constexpr JSValue::NotCellMask</span>
  else
      const Int32Tag = constexpr JSValue::Int32Tag
      const BooleanTag = constexpr JSValue::BooleanTag
      const NullTag = constexpr JSValue::NullTag
      const UndefinedTag = constexpr JSValue::UndefinedTag
</pre>
<hr />
<pre>
<span class="line-old-header">*** 210,12 ***</span>
  if JSVALUE64
      const NumberOfStructureIDEntropyBits = constexpr StructureIDTable::s_numberOfEntropyBits
      const StructureEntropyBitsShift = constexpr StructureIDTable::s_entropyBitsShiftForStructurePointer
  end
  
<span class="line-removed">- const CallOpCodeSize = constexpr op_call_length</span>
<span class="line-removed">- </span>
  const maxFrameExtentForSlowPathCall = constexpr maxFrameExtentForSlowPathCall
  
  if X86_64 or X86_64_WIN or ARM64 or ARM64E
      const CalleeSaveSpaceAsVirtualRegisters = 4
  elsif C_LOOP or C_LOOP_WIN
<span class="line-new-header">--- 210,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 237,93 ***</span>
  const IsInvalidated = constexpr IsInvalidated
  
  # ShadowChicken data
  const ShadowChickenTailMarker = constexpr ShadowChicken::Packet::tailMarkerValue
  
<span class="line-modified">! # ArithProfile data</span>
<span class="line-modified">! const ArithProfileInt = constexpr (ArithProfile::observedUnaryInt().bits())</span>
<span class="line-modified">! const ArithProfileNumber = constexpr (ArithProfile::observedUnaryNumber().bits())</span>
<span class="line-modified">! const ArithProfileIntInt = constexpr (ArithProfile::observedBinaryIntInt().bits())</span>
<span class="line-modified">! const ArithProfileNumberInt = constexpr (ArithProfile::observedBinaryNumberInt().bits())</span>
<span class="line-modified">! const ArithProfileIntNumber = constexpr (ArithProfile::observedBinaryIntNumber().bits())</span>
<span class="line-modified">! const ArithProfileNumberNumber = constexpr (ArithProfile::observedBinaryNumberNumber().bits())</span>
  
  # Pointer Tags
  const BytecodePtrTag = constexpr BytecodePtrTag
  const JSEntryPtrTag = constexpr JSEntryPtrTag
  const ExceptionHandlerPtrTag = constexpr ExceptionHandlerPtrTag
  const NoPtrTag = constexpr NoPtrTag
  const SlowPathPtrTag = constexpr SlowPathPtrTag
  
  # Some register conventions.
  if JSVALUE64
<span class="line-removed">-     # - Use a pair of registers to represent the PC: one register for the</span>
<span class="line-removed">-     #   base of the bytecodes, and one register for the index.</span>
<span class="line-removed">-     # - The PC base (or PB for short) must be stored in a callee-save register.</span>
<span class="line-removed">-     # - C calls are still given the Instruction* rather than the PC index.</span>
<span class="line-removed">-     #   This requires an add before the call, and a sub after.</span>
      const PC = t4 # When changing this, make sure LLIntPC is up to date in LLIntPCRanges.h
      if ARM64 or ARM64E
          const metadataTable = csr6
          const PB = csr7
<span class="line-modified">!         const tagTypeNumber = csr8</span>
<span class="line-modified">!         const tagMask = csr9</span>
      elsif X86_64
          const metadataTable = csr1
          const PB = csr2
<span class="line-modified">!         const tagTypeNumber = csr3</span>
<span class="line-modified">!         const tagMask = csr4</span>
      elsif X86_64_WIN
          const metadataTable = csr3
          const PB = csr4
<span class="line-modified">!         const tagTypeNumber = csr5</span>
<span class="line-modified">!         const tagMask = csr6</span>
      elsif C_LOOP or C_LOOP_WIN
          const PB = csr0
<span class="line-modified">!         const tagTypeNumber = csr1</span>
<span class="line-modified">!         const tagMask = csr2</span>
          const metadataTable = csr3
      end
  
  else
      const PC = t4 # When changing this, make sure LLIntPC is up to date in LLIntPCRanges.h
      if C_LOOP or C_LOOP_WIN
          const metadataTable = csr3
      elsif ARMv7
          const metadataTable = csr0
      elsif MIPS
          const metadataTable = csr0
      else
          error
      end
  end
  
  macro dispatch(advanceReg)
      addp advanceReg, PC
      nextInstruction()
  end
  
  macro dispatchIndirect(offsetReg)
      dispatch(offsetReg)
  end
  
<span class="line-modified">! macro dispatchOp(size, opcodeName)</span>
      macro dispatchNarrow()
<span class="line-modified">!         dispatch(constexpr %opcodeName%_length)</span>
      end
  
      macro dispatchWide16()
<span class="line-modified">!         dispatch(constexpr %opcodeName%_length * 2 + 1)</span>
      end
  
      macro dispatchWide32()
<span class="line-modified">!         dispatch(constexpr %opcodeName%_length * 4 + 1)</span>
      end
  
      size(dispatchNarrow, dispatchWide16, dispatchWide32, macro (dispatch) dispatch() end)
  end
  
  macro getu(size, opcodeStruct, fieldName, dst)
      size(getuOperandNarrow, getuOperandWide16, getuOperandWide32, macro (getu)
          getu(opcodeStruct, fieldName, dst)
      end)
  end
<span class="line-new-header">--- 235,132 ---</span>
  const IsInvalidated = constexpr IsInvalidated
  
  # ShadowChicken data
  const ShadowChickenTailMarker = constexpr ShadowChicken::Packet::tailMarkerValue
  
<span class="line-modified">! # UnaryArithProfile data</span>
<span class="line-modified">! const ArithProfileInt = constexpr (UnaryArithProfile::observedIntBits())</span>
<span class="line-modified">! const ArithProfileNumber = constexpr (UnaryArithProfile::observedNumberBits())</span>
<span class="line-modified">! </span>
<span class="line-modified">! # BinaryArithProfile data</span>
<span class="line-modified">! const ArithProfileIntInt = constexpr (BinaryArithProfile::observedIntIntBits())</span>
<span class="line-modified">! const ArithProfileNumberInt = constexpr (BinaryArithProfile::observedNumberIntBits())</span>
<span class="line-added">+ const ArithProfileIntNumber = constexpr (BinaryArithProfile::observedIntNumberBits())</span>
<span class="line-added">+ const ArithProfileNumberNumber = constexpr (BinaryArithProfile::observedNumberNumberBits())</span>
  
  # Pointer Tags
  const BytecodePtrTag = constexpr BytecodePtrTag
  const JSEntryPtrTag = constexpr JSEntryPtrTag
  const ExceptionHandlerPtrTag = constexpr ExceptionHandlerPtrTag
  const NoPtrTag = constexpr NoPtrTag
  const SlowPathPtrTag = constexpr SlowPathPtrTag
  
  # Some register conventions.
<span class="line-added">+ # - We use a pair of registers to represent the PC: one register for the</span>
<span class="line-added">+ #   base of the bytecodes, and one register for the index.</span>
<span class="line-added">+ # - The PC base (or PB for short) must be stored in a callee-save register.</span>
<span class="line-added">+ # - C calls are still given the Instruction* rather than the PC index.</span>
<span class="line-added">+ #   This requires an add before the call, and a sub after.</span>
  if JSVALUE64
      const PC = t4 # When changing this, make sure LLIntPC is up to date in LLIntPCRanges.h
      if ARM64 or ARM64E
          const metadataTable = csr6
          const PB = csr7
<span class="line-modified">!         const numberTag = csr8</span>
<span class="line-modified">!         const notCellMask = csr9</span>
      elsif X86_64
          const metadataTable = csr1
          const PB = csr2
<span class="line-modified">!         const numberTag = csr3</span>
<span class="line-modified">!         const notCellMask = csr4</span>
      elsif X86_64_WIN
          const metadataTable = csr3
          const PB = csr4
<span class="line-modified">!         const numberTag = csr5</span>
<span class="line-modified">!         const notCellMask = csr6</span>
      elsif C_LOOP or C_LOOP_WIN
          const PB = csr0
<span class="line-modified">!         const numberTag = csr1</span>
<span class="line-modified">!         const notCellMask = csr2</span>
          const metadataTable = csr3
      end
  
  else
      const PC = t4 # When changing this, make sure LLIntPC is up to date in LLIntPCRanges.h
      if C_LOOP or C_LOOP_WIN
<span class="line-added">+         const PB = csr0</span>
          const metadataTable = csr3
      elsif ARMv7
          const metadataTable = csr0
<span class="line-added">+         const PB = csr1</span>
      elsif MIPS
          const metadataTable = csr0
<span class="line-added">+         const PB = csr1</span>
      else
          error
      end
  end
  
<span class="line-added">+ if GIGACAGE_ENABLED</span>
<span class="line-added">+     const GigacagePrimitiveBasePtrOffset = constexpr Gigacage::offsetOfPrimitiveGigacageBasePtr</span>
<span class="line-added">+     const GigacageJSValueBasePtrOffset = constexpr Gigacage::offsetOfJSValueGigacageBasePtr</span>
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
<span class="line-added">+ # Opcode offsets</span>
<span class="line-added">+ const OpcodeIDNarrowSize = 1 # OpcodeID</span>
<span class="line-added">+ const OpcodeIDWide16Size = 2 # Wide16 Prefix + OpcodeID</span>
<span class="line-added">+ const OpcodeIDWide32Size = 2 # Wide32 Prefix + OpcodeID</span>
<span class="line-added">+ </span>
<span class="line-added">+ </span>
<span class="line-added">+ macro nextInstruction()</span>
<span class="line-added">+     loadb [PB, PC, 1], t0</span>
<span class="line-added">+     leap _g_opcodeMap, t1</span>
<span class="line-added">+     jmp [t1, t0, PtrSize], BytecodePtrTag</span>
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
<span class="line-added">+ macro nextInstructionWide16()</span>
<span class="line-added">+     loadb OpcodeIDNarrowSize[PB, PC, 1], t0</span>
<span class="line-added">+     leap _g_opcodeMapWide16, t1</span>
<span class="line-added">+     jmp [t1, t0, PtrSize], BytecodePtrTag</span>
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
<span class="line-added">+ macro nextInstructionWide32()</span>
<span class="line-added">+     loadb OpcodeIDNarrowSize[PB, PC, 1], t0</span>
<span class="line-added">+     leap _g_opcodeMapWide32, t1</span>
<span class="line-added">+     jmp [t1, t0, PtrSize], BytecodePtrTag</span>
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
  macro dispatch(advanceReg)
      addp advanceReg, PC
      nextInstruction()
  end
  
  macro dispatchIndirect(offsetReg)
      dispatch(offsetReg)
  end
  
<span class="line-modified">! macro genericDispatchOp(dispatch, size, opcodeName)</span>
      macro dispatchNarrow()
<span class="line-modified">!         dispatch((constexpr %opcodeName%_length - 1) * 1 + OpcodeIDNarrowSize)</span>
      end
  
      macro dispatchWide16()
<span class="line-modified">!         dispatch((constexpr %opcodeName%_length - 1) * 2 + OpcodeIDWide16Size)</span>
      end
  
      macro dispatchWide32()
<span class="line-modified">!         dispatch((constexpr %opcodeName%_length - 1) * 4 + OpcodeIDWide32Size)</span>
      end
  
      size(dispatchNarrow, dispatchWide16, dispatchWide32, macro (dispatch) dispatch() end)
  end
  
<span class="line-added">+ macro dispatchOp(size, opcodeName)</span>
<span class="line-added">+     genericDispatchOp(dispatch, size, opcodeName)</span>
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
<span class="line-added">+ </span>
  macro getu(size, opcodeStruct, fieldName, dst)
      size(getuOperandNarrow, getuOperandWide16, getuOperandWide32, macro (getu)
          getu(opcodeStruct, fieldName, dst)
      end)
  end
</pre>
<hr />
<pre>
<span class="line-old-header">*** 355,11 ***</span>
      muli sizeof %opcode%::Metadata, scratch # scratch *= sizeof(Op::Metadata)
      addi scratch, dst # offset += scratch
      addp metadataTable, dst # return &amp;metadataTable[offset]
  end
  
<span class="line-modified">! macro jumpImpl(targetOffsetReg)</span>
      btiz targetOffsetReg, .outOfLineJumpTarget
      dispatchIndirect(targetOffsetReg)
  .outOfLineJumpTarget:
      callSlowPath(_llint_slow_path_out_of_line_jump_target)
      nextInstruction()
<span class="line-new-header">--- 392,11 ---</span>
      muli sizeof %opcode%::Metadata, scratch # scratch *= sizeof(Op::Metadata)
      addi scratch, dst # offset += scratch
      addp metadataTable, dst # return &amp;metadataTable[offset]
  end
  
<span class="line-modified">! macro jumpImpl(dispatchIndirect, targetOffsetReg)</span>
      btiz targetOffsetReg, .outOfLineJumpTarget
      dispatchIndirect(targetOffsetReg)
  .outOfLineJumpTarget:
      callSlowPath(_llint_slow_path_out_of_line_jump_target)
      nextInstruction()
</pre>
<hr />
<pre>
<span class="line-old-header">*** 367,24 ***</span>
<span class="line-new-header">--- 404,36 ---</span>
  
  macro commonOp(label, prologue, fn)
  _%label%:
      prologue()
      fn(narrow)
<span class="line-added">+     if ASSERT_ENABLED</span>
<span class="line-added">+         break</span>
<span class="line-added">+         break</span>
<span class="line-added">+     end</span>
  
  # FIXME: We cannot enable wide16 bytecode in Windows CLoop. With MSVC, as CLoop::execute gets larger code
  # size, CLoop::execute gets higher stack height requirement. This makes CLoop::execute takes 160KB stack
  # per call, causes stack overflow error easily. For now, we disable wide16 optimization for Windows CLoop.
  # https://bugs.webkit.org/show_bug.cgi?id=198283
  if not C_LOOP_WIN
  _%label%_wide16:
      prologue()
      fn(wide16)
<span class="line-added">+     if ASSERT_ENABLED</span>
<span class="line-added">+         break</span>
<span class="line-added">+         break</span>
<span class="line-added">+     end</span>
  end
  
  _%label%_wide32:
      prologue()
      fn(wide32)
<span class="line-added">+     if ASSERT_ENABLED</span>
<span class="line-added">+         break</span>
<span class="line-added">+         break</span>
<span class="line-added">+     end</span>
  end
  
  macro op(l, fn)
      commonOp(l, macro () end, macro (size)
          size(fn, macro() end, macro() end, macro(gen) gen() end)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 424,11 ***</span>
  
  macro llintOpWithJump(opcodeName, opcodeStruct, impl)
      llintOpWithMetadata(opcodeName, opcodeStruct, macro(size, get, dispatch, metadata, return)
          macro jump(fieldName)
              get(fieldName, t0)
<span class="line-modified">!             jumpImpl(t0)</span>
          end
  
          impl(size, get, jump, dispatch)
      end)
  end
<span class="line-new-header">--- 473,11 ---</span>
  
  macro llintOpWithJump(opcodeName, opcodeStruct, impl)
      llintOpWithMetadata(opcodeName, opcodeStruct, macro(size, get, dispatch, metadata, return)
          macro jump(fieldName)
              get(fieldName, t0)
<span class="line-modified">!             jumpImpl(dispatchIndirect, t0)</span>
          end
  
          impl(size, get, jump, dispatch)
      end)
  end
</pre>
<hr />
<pre>
<span class="line-old-header">*** 502,11 ***</span>
  const EvalCode = constexpr EvalCode
  const FunctionCode = constexpr FunctionCode
  const ModuleCode = constexpr ModuleCode
  
  # The interpreter steals the tag word of the argument count.
<span class="line-modified">! const LLIntReturnPC = ArgumentCount + TagOffset</span>
  
  # String flags.
  const isRopeInPointer = constexpr JSString::isRopeInPointer
  const HashFlags8BitBuffer = constexpr StringImpl::s_hashFlag8BitBuffer
  
<span class="line-new-header">--- 551,11 ---</span>
  const EvalCode = constexpr EvalCode
  const FunctionCode = constexpr FunctionCode
  const ModuleCode = constexpr ModuleCode
  
  # The interpreter steals the tag word of the argument count.
<span class="line-modified">! const LLIntReturnPC = ArgumentCountIncludingThis + TagOffset</span>
  
  # String flags.
  const isRopeInPointer = constexpr JSString::isRopeInPointer
  const HashFlags8BitBuffer = constexpr StringImpl::s_hashFlag8BitBuffer
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 531,10 ***</span>
<span class="line-new-header">--- 580,12 ---</span>
  const NotInitialization = constexpr InitializationMode::NotInitialization
  
  const MarkedBlockSize = constexpr MarkedBlock::blockSize
  const MarkedBlockMask = ~(MarkedBlockSize - 1)
  const MarkedBlockFooterOffset = constexpr MarkedBlock::offsetOfFooter
<span class="line-added">+ const PreciseAllocationHeaderSize = constexpr (PreciseAllocation::headerSize())</span>
<span class="line-added">+ const PreciseAllocationVMOffset = (PreciseAllocation::m_weakSet + WeakSet::m_vm - PreciseAllocationHeaderSize)</span>
  
  const BlackThreshold = constexpr blackThreshold
  
  const VectorBufferOffset = Vector::m_buffer
  const VectorSizeOffset = Vector::m_size
</pre>
<hr />
<pre>
<span class="line-old-header">*** 554,10 ***</span>
<span class="line-new-header">--- 605,18 ---</span>
          crash()
      .ok:
      end
  end
  
<span class="line-added">+ macro assert_with(assertion, crash)</span>
<span class="line-added">+     if ASSERT_ENABLED</span>
<span class="line-added">+         assertion(.ok)</span>
<span class="line-added">+         crash()</span>
<span class="line-added">+     .ok:</span>
<span class="line-added">+     end</span>
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
  # The probe macro can be used to insert some debugging code without perturbing scalar
  # registers. Presently, the probe macro only preserves scalar registers. Hence, the
  # C probe callback function should not trash floating point registers.
  #
  # The macro you pass to probe() can pass whatever registers you like to your probe
</pre>
<hr />
<pre>
<span class="line-old-header">*** 567,11 ***</span>
  #
  # Here&#39;s an example of how it&#39;s used:
  #
  #     probe(
  #         macro()
<span class="line-modified">! #             move cfr, a0 # pass the ExecState* as arg0.</span>
  #             move t0, a1 # pass the value of register t0 as arg1.
  #             call _cProbeCallbackFunction # to do whatever you want.
  #         end
  #     )
  #
<span class="line-new-header">--- 626,11 ---</span>
  #
  # Here&#39;s an example of how it&#39;s used:
  #
  #     probe(
  #         macro()
<span class="line-modified">! #             move cfr, a0 # pass the CallFrame* as arg0.</span>
  #             move t0, a1 # pass the value of register t0 as arg1.
  #             call _cProbeCallbackFunction # to do whatever you want.
  #         end
  #     )
  #
</pre>
<hr />
<pre>
<span class="line-old-header">*** 591,11 ***</span>
              push csr2, csr3
              push csr4, csr5
              push csr6, csr7
              push csr8, csr9
          elsif ARMv7
<span class="line-modified">!             push csr0</span>
          end
  
          action()
  
          # restore all the registers we saved previously.
<span class="line-new-header">--- 650,11 ---</span>
              push csr2, csr3
              push csr4, csr5
              push csr6, csr7
              push csr8, csr9
          elsif ARMv7
<span class="line-modified">!             push csr0, csr1</span>
          end
  
          action()
  
          # restore all the registers we saved previously.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 604,11 ***</span>
              pop csr7, csr6
              pop csr5, csr4
              pop csr3, csr2
              pop csr1, csr0
          elsif ARMv7
<span class="line-modified">!             pop csr0</span>
          end
          pop t5, t4
          pop t3, t2
          pop t1, t0
          pop a3, a2
<span class="line-new-header">--- 663,11 ---</span>
              pop csr7, csr6
              pop csr5, csr4
              pop csr3, csr2
              pop csr1, csr0
          elsif ARMv7
<span class="line-modified">!             pop csr1, csr0</span>
          end
          pop t5, t4
          pop t3, t2
          pop t1, t0
          pop a3, a2
</pre>
<hr />
<pre>
<span class="line-old-header">*** 647,11 ***</span>
  if C_LOOP or C_LOOP_WIN or ARM64 or ARM64E or X86_64 or X86_64_WIN
      const CalleeSaveRegisterCount = 0
  elsif ARMv7
      const CalleeSaveRegisterCount = 7
  elsif MIPS
<span class="line-modified">!     const CalleeSaveRegisterCount = 2</span>
  elsif X86 or X86_WIN
      const CalleeSaveRegisterCount = 3
  end
  
  const CalleeRegisterSaveSize = CalleeSaveRegisterCount * MachineRegisterSize
<span class="line-new-header">--- 706,11 ---</span>
  if C_LOOP or C_LOOP_WIN or ARM64 or ARM64E or X86_64 or X86_64_WIN
      const CalleeSaveRegisterCount = 0
  elsif ARMv7
      const CalleeSaveRegisterCount = 7
  elsif MIPS
<span class="line-modified">!     const CalleeSaveRegisterCount = 3</span>
  elsif X86 or X86_WIN
      const CalleeSaveRegisterCount = 3
  end
  
  const CalleeRegisterSaveSize = CalleeSaveRegisterCount * MachineRegisterSize
</pre>
<hr />
<pre>
<span class="line-old-header">*** 663,13 ***</span>
  macro pushCalleeSaves()
      if C_LOOP or C_LOOP_WIN or ARM64 or ARM64E or X86_64 or X86_64_WIN
      elsif ARMv7
          emit &quot;push {r4-r6, r8-r11}&quot;
      elsif MIPS
<span class="line-modified">!         emit &quot;addiu $sp, $sp, -8&quot;</span>
          emit &quot;sw $s0, 0($sp)&quot; # csr0/metaData
<span class="line-modified">!         emit &quot;sw $s4, 4($sp)&quot;</span>
          # save $gp to $s4 so that we can restore it after a function call
          emit &quot;move $s4, $gp&quot;
      elsif X86
          emit &quot;push %esi&quot;
          emit &quot;push %edi&quot;
<span class="line-new-header">--- 722,14 ---</span>
  macro pushCalleeSaves()
      if C_LOOP or C_LOOP_WIN or ARM64 or ARM64E or X86_64 or X86_64_WIN
      elsif ARMv7
          emit &quot;push {r4-r6, r8-r11}&quot;
      elsif MIPS
<span class="line-modified">!         emit &quot;addiu $sp, $sp, -12&quot;</span>
          emit &quot;sw $s0, 0($sp)&quot; # csr0/metaData
<span class="line-modified">!         emit &quot;sw $s1, 4($sp)&quot; # csr1/PB</span>
<span class="line-added">+         emit &quot;sw $s4, 8($sp)&quot;</span>
          # save $gp to $s4 so that we can restore it after a function call
          emit &quot;move $s4, $gp&quot;
      elsif X86
          emit &quot;push %esi&quot;
          emit &quot;push %edi&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 685,12 ***</span>
      if C_LOOP or C_LOOP_WIN or ARM64 or ARM64E or X86_64 or X86_64_WIN
      elsif ARMv7
          emit &quot;pop {r4-r6, r8-r11}&quot;
      elsif MIPS
          emit &quot;lw $s0, 0($sp)&quot;
<span class="line-modified">!         emit &quot;lw $s4, 4($sp)&quot;</span>
<span class="line-modified">!         emit &quot;addiu $sp, $sp, 8&quot;</span>
      elsif X86
          emit &quot;pop %ebx&quot;
          emit &quot;pop %edi&quot;
          emit &quot;pop %esi&quot;
      elsif X86_WIN
<span class="line-new-header">--- 745,13 ---</span>
      if C_LOOP or C_LOOP_WIN or ARM64 or ARM64E or X86_64 or X86_64_WIN
      elsif ARMv7
          emit &quot;pop {r4-r6, r8-r11}&quot;
      elsif MIPS
          emit &quot;lw $s0, 0($sp)&quot;
<span class="line-modified">!         emit &quot;lw $s1, 4($sp)&quot;</span>
<span class="line-modified">!         emit &quot;lw $s4, 8($sp)&quot;</span>
<span class="line-added">+         emit &quot;addiu $sp, $sp, 12&quot;</span>
      elsif X86
          emit &quot;pop %ebx&quot;
          emit &quot;pop %edi&quot;
          emit &quot;pop %esi&quot;
      elsif X86_WIN
</pre>
<hr />
<pre>
<span class="line-old-header">*** 728,12 ***</span>
  
  macro preserveCalleeSavesUsedByLLInt()
      subp CalleeSaveSpaceStackAligned, sp
      if C_LOOP or C_LOOP_WIN
          storep metadataTable, -PtrSize[cfr]
<span class="line-modified">!     elsif ARMv7 or MIPS</span>
          storep metadataTable, -4[cfr]
      elsif ARM64 or ARM64E
          emit &quot;stp x27, x28, [x29, #-16]&quot;
          emit &quot;stp x25, x26, [x29, #-32]&quot;
      elsif X86
      elsif X86_WIN
<span class="line-new-header">--- 789,24 ---</span>
  
  macro preserveCalleeSavesUsedByLLInt()
      subp CalleeSaveSpaceStackAligned, sp
      if C_LOOP or C_LOOP_WIN
          storep metadataTable, -PtrSize[cfr]
<span class="line-modified">! </span>
<span class="line-added">+     # Next ARMv7 and MIPS differ in how we store metadataTable and PB,</span>
<span class="line-added">+     # because this codes needs to be in sync with how registers are</span>
<span class="line-added">+     # restored in Baseline JIT (specifically in emitRestoreCalleeSavesFor).</span>
<span class="line-added">+     # emitRestoreCalleeSavesFor restores registers in order instead of by name.</span>
<span class="line-added">+     # However, ARMv7 and MIPS differ in the order in which registers are assigned</span>
<span class="line-added">+     # to metadataTable and PB, therefore they can also not have the same saving</span>
<span class="line-added">+     # order.</span>
<span class="line-added">+     elsif ARMv7</span>
          storep metadataTable, -4[cfr]
<span class="line-added">+         storep PB, -8[cfr]</span>
<span class="line-added">+     elsif MIPS</span>
<span class="line-added">+         storep PB, -4[cfr]</span>
<span class="line-added">+         storep metadataTable, -8[cfr]</span>
      elsif ARM64 or ARM64E
          emit &quot;stp x27, x28, [x29, #-16]&quot;
          emit &quot;stp x25, x26, [x29, #-32]&quot;
      elsif X86
      elsif X86_WIN
</pre>
<hr />
<pre>
<span class="line-old-header">*** 751,12 ***</span>
  end
  
  macro restoreCalleeSavesUsedByLLInt()
      if C_LOOP or C_LOOP_WIN
          loadp -PtrSize[cfr], metadataTable
<span class="line-modified">!     elsif ARMv7 or MIPS</span>
          loadp -4[cfr], metadataTable
      elsif ARM64 or ARM64E
          emit &quot;ldp x25, x26, [x29, #-32]&quot;
          emit &quot;ldp x27, x28, [x29, #-16]&quot;
      elsif X86
      elsif X86_WIN
<span class="line-new-header">--- 824,18 ---</span>
  end
  
  macro restoreCalleeSavesUsedByLLInt()
      if C_LOOP or C_LOOP_WIN
          loadp -PtrSize[cfr], metadataTable
<span class="line-modified">!     # To understand why ARMv7 and MIPS differ in restore order,</span>
<span class="line-added">+     # see comment in preserveCalleeSavesUsedByLLInt</span>
<span class="line-added">+     elsif ARMv7</span>
          loadp -4[cfr], metadataTable
<span class="line-added">+         loadp -8[cfr], PB</span>
<span class="line-added">+     elsif MIPS</span>
<span class="line-added">+         loadp -4[cfr], PB</span>
<span class="line-added">+         loadp -8[cfr], metadataTable</span>
      elsif ARM64 or ARM64E
          emit &quot;ldp x25, x26, [x29, #-32]&quot;
          emit &quot;ldp x27, x28, [x29, #-16]&quot;
      elsif X86
      elsif X86_WIN
</pre>
<hr />
<pre>
<span class="line-old-header">*** 771,54 ***</span>
          loadp -16[cfr], csr5
          loadp -8[cfr], csr6
      end
  end
  
<span class="line-modified">! macro copyCalleeSavesToVMEntryFrameCalleeSavesBuffer(vm, temp)</span>
      if ARM64 or ARM64E or X86_64 or X86_64_WIN or ARMv7 or MIPS
<span class="line-modified">!         loadp VM::topEntryFrame[vm], temp</span>
<span class="line-modified">!         vmEntryRecord(temp, temp)</span>
<span class="line-removed">-         leap VMEntryRecord::calleeSaveRegistersBuffer[temp], temp</span>
          if ARM64 or ARM64E
<span class="line-modified">!             storeq csr0, [temp]</span>
<span class="line-modified">!             storeq csr1, 8[temp]</span>
<span class="line-modified">!             storeq csr2, 16[temp]</span>
<span class="line-modified">!             storeq csr3, 24[temp]</span>
<span class="line-modified">!             storeq csr4, 32[temp]</span>
<span class="line-modified">!             storeq csr5, 40[temp]</span>
<span class="line-modified">!             storeq csr6, 48[temp]</span>
<span class="line-modified">!             storeq csr7, 56[temp]</span>
<span class="line-modified">!             storeq csr8, 64[temp]</span>
<span class="line-modified">!             storeq csr9, 72[temp]</span>
<span class="line-modified">!             stored csfr0, 80[temp]</span>
<span class="line-modified">!             stored csfr1, 88[temp]</span>
<span class="line-modified">!             stored csfr2, 96[temp]</span>
<span class="line-modified">!             stored csfr3, 104[temp]</span>
<span class="line-modified">!             stored csfr4, 112[temp]</span>
<span class="line-modified">!             stored csfr5, 120[temp]</span>
<span class="line-modified">!             stored csfr6, 128[temp]</span>
<span class="line-modified">!             stored csfr7, 136[temp]</span>
          elsif X86_64
<span class="line-modified">!             storeq csr0, [temp]</span>
<span class="line-modified">!             storeq csr1, 8[temp]</span>
<span class="line-modified">!             storeq csr2, 16[temp]</span>
<span class="line-modified">!             storeq csr3, 24[temp]</span>
<span class="line-modified">!             storeq csr4, 32[temp]</span>
          elsif X86_64_WIN
<span class="line-modified">!             storeq csr0, [temp]</span>
<span class="line-modified">!             storeq csr1, 8[temp]</span>
<span class="line-modified">!             storeq csr2, 16[temp]</span>
<span class="line-modified">!             storeq csr3, 24[temp]</span>
<span class="line-modified">!             storeq csr4, 32[temp]</span>
<span class="line-modified">!             storeq csr5, 40[temp]</span>
<span class="line-modified">!             storeq csr6, 48[temp]</span>
          elsif ARMv7 or MIPS
<span class="line-modified">!             storep csr0, [temp]</span>
          end
      end
  end
  
  macro restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(vm, temp)
      if ARM64 or ARM64E or X86_64 or X86_64_WIN or ARMv7 or MIPS
          loadp VM::topEntryFrame[vm], temp
          vmEntryRecord(temp, temp)
          leap VMEntryRecord::calleeSaveRegistersBuffer[temp], temp
<span class="line-new-header">--- 850,61 ---</span>
          loadp -16[cfr], csr5
          loadp -8[cfr], csr6
      end
  end
  
<span class="line-modified">! macro copyCalleeSavesToEntryFrameCalleeSavesBuffer(entryFrame)</span>
      if ARM64 or ARM64E or X86_64 or X86_64_WIN or ARMv7 or MIPS
<span class="line-modified">!         vmEntryRecord(entryFrame, entryFrame)</span>
<span class="line-modified">!         leap VMEntryRecord::calleeSaveRegistersBuffer[entryFrame], entryFrame</span>
          if ARM64 or ARM64E
<span class="line-modified">!             storeq csr0, [entryFrame]</span>
<span class="line-modified">!             storeq csr1, 8[entryFrame]</span>
<span class="line-modified">!             storeq csr2, 16[entryFrame]</span>
<span class="line-modified">!             storeq csr3, 24[entryFrame]</span>
<span class="line-modified">!             storeq csr4, 32[entryFrame]</span>
<span class="line-modified">!             storeq csr5, 40[entryFrame]</span>
<span class="line-modified">!             storeq csr6, 48[entryFrame]</span>
<span class="line-modified">!             storeq csr7, 56[entryFrame]</span>
<span class="line-modified">!             storeq csr8, 64[entryFrame]</span>
<span class="line-modified">!             storeq csr9, 72[entryFrame]</span>
<span class="line-modified">!             stored csfr0, 80[entryFrame]</span>
<span class="line-modified">!             stored csfr1, 88[entryFrame]</span>
<span class="line-modified">!             stored csfr2, 96[entryFrame]</span>
<span class="line-modified">!             stored csfr3, 104[entryFrame]</span>
<span class="line-modified">!             stored csfr4, 112[entryFrame]</span>
<span class="line-modified">!             stored csfr5, 120[entryFrame]</span>
<span class="line-modified">!             stored csfr6, 128[entryFrame]</span>
<span class="line-modified">!             stored csfr7, 136[entryFrame]</span>
          elsif X86_64
<span class="line-modified">!             storeq csr0, [entryFrame]</span>
<span class="line-modified">!             storeq csr1, 8[entryFrame]</span>
<span class="line-modified">!             storeq csr2, 16[entryFrame]</span>
<span class="line-modified">!             storeq csr3, 24[entryFrame]</span>
<span class="line-modified">!             storeq csr4, 32[entryFrame]</span>
          elsif X86_64_WIN
<span class="line-modified">!             storeq csr0, [entryFrame]</span>
<span class="line-modified">!             storeq csr1, 8[entryFrame]</span>
<span class="line-modified">!             storeq csr2, 16[entryFrame]</span>
<span class="line-modified">!             storeq csr3, 24[entryFrame]</span>
<span class="line-modified">!             storeq csr4, 32[entryFrame]</span>
<span class="line-modified">!             storeq csr5, 40[entryFrame]</span>
<span class="line-modified">!             storeq csr6, 48[entryFrame]</span>
          elsif ARMv7 or MIPS
<span class="line-modified">!             storep csr0, [entryFrame]</span>
<span class="line-added">+             storep csr1, 4[entryFrame]</span>
          end
      end
  end
  
<span class="line-added">+ macro copyCalleeSavesToVMEntryFrameCalleeSavesBuffer(vm, temp)</span>
<span class="line-added">+     if ARM64 or ARM64E or X86_64 or X86_64_WIN or ARMv7 or MIPS</span>
<span class="line-added">+         loadp VM::topEntryFrame[vm], temp</span>
<span class="line-added">+         copyCalleeSavesToEntryFrameCalleeSavesBuffer(temp)</span>
<span class="line-added">+     end</span>
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
  macro restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(vm, temp)
      if ARM64 or ARM64E or X86_64 or X86_64_WIN or ARMv7 or MIPS
          loadp VM::topEntryFrame[vm], temp
          vmEntryRecord(temp, temp)
          leap VMEntryRecord::calleeSaveRegistersBuffer[temp], temp
</pre>
<hr />
<pre>
<span class="line-old-header">*** 855,10 ***</span>
<span class="line-new-header">--- 941,11 ---</span>
              loadq 32[temp], csr4
              loadq 40[temp], csr5
              loadq 48[temp], csr6
          elsif ARMv7 or MIPS
              loadp [temp], csr0
<span class="line-added">+             loadp 4[temp], csr1</span>
          end
      end
  end
  
  macro preserveReturnAddressAfterCall(destinationRegister)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 921,16 ***</span>
      if TRACING
          callSlowPath(_llint_trace)
      end
  end
  
<span class="line-modified">! macro callTargetFunction(size, opcodeStruct, dispatch, callee, callPtrTag)</span>
      if C_LOOP or C_LOOP_WIN
          cloopCallJSFunction callee
      else
          call callee, callPtrTag
      end
      restoreStackPointerAfterCall()
      dispatchAfterCall(size, opcodeStruct, dispatch)
  end
  
  macro prepareForRegularCall(callee, temp1, temp2, temp3, callPtrTag)
<span class="line-new-header">--- 1008,48 ---</span>
      if TRACING
          callSlowPath(_llint_trace)
      end
  end
  
<span class="line-modified">! macro defineOSRExitReturnLabel(opcodeName, size)</span>
<span class="line-added">+     macro defineNarrow()</span>
<span class="line-added">+         if not C_LOOP_WIN</span>
<span class="line-added">+             _%opcodeName%_return_location:</span>
<span class="line-added">+         end</span>
<span class="line-added">+     end</span>
<span class="line-added">+ </span>
<span class="line-added">+     macro defineWide16()</span>
<span class="line-added">+         if not C_LOOP_WIN</span>
<span class="line-added">+             _%opcodeName%_return_location_wide16:</span>
<span class="line-added">+         end</span>
<span class="line-added">+     end</span>
<span class="line-added">+ </span>
<span class="line-added">+     macro defineWide32()</span>
<span class="line-added">+         if not C_LOOP_WIN</span>
<span class="line-added">+             _%opcodeName%_return_location_wide32:</span>
<span class="line-added">+         end</span>
<span class="line-added">+     end</span>
<span class="line-added">+ </span>
<span class="line-added">+     size(defineNarrow, defineWide16, defineWide32, macro (f) f() end)</span>
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
<span class="line-added">+ macro callTargetFunction(opcodeName, size, opcodeStruct, dispatch, callee, callPtrTag)</span>
      if C_LOOP or C_LOOP_WIN
          cloopCallJSFunction callee
      else
          call callee, callPtrTag
      end
<span class="line-added">+ </span>
<span class="line-added">+     if ARMv7 or MIPS</span>
<span class="line-added">+         # It is required in ARMv7 and MIPs because global label definitions</span>
<span class="line-added">+         # for those architectures generates a set of instructions</span>
<span class="line-added">+         # that can clobber LLInt execution, resulting in unexpected</span>
<span class="line-added">+         # crashes.</span>
<span class="line-added">+         restoreStackPointerAfterCall()</span>
<span class="line-added">+         dispatchAfterCall(size, opcodeStruct, dispatch)</span>
<span class="line-added">+     end</span>
<span class="line-added">+     defineOSRExitReturnLabel(opcodeName, size)</span>
      restoreStackPointerAfterCall()
      dispatchAfterCall(size, opcodeStruct, dispatch)
  end
  
  macro prepareForRegularCall(callee, temp1, temp2, temp3, callPtrTag)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 939,11 ***</span>
  
  # sp points to the new frame
  macro prepareForTailCall(callee, temp1, temp2, temp3, callPtrTag)
      restoreCalleeSavesUsedByLLInt()
  
<span class="line-modified">!     loadi PayloadOffset + ArgumentCount[cfr], temp2</span>
      loadp CodeBlock[cfr], temp1
      loadi CodeBlock::m_numParameters[temp1], temp1
      bilteq temp1, temp2, .noArityFixup
      move temp1, temp2
  
<span class="line-new-header">--- 1058,11 ---</span>
  
  # sp points to the new frame
  macro prepareForTailCall(callee, temp1, temp2, temp3, callPtrTag)
      restoreCalleeSavesUsedByLLInt()
  
<span class="line-modified">!     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], temp2</span>
      loadp CodeBlock[cfr], temp1
      loadi CodeBlock::m_numParameters[temp1], temp1
      bilteq temp1, temp2, .noArityFixup
      move temp1, temp2
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 954,11 ***</span>
      andi ~StackAlignmentMask, temp2
  
      move cfr, temp1
      addp temp2, temp1
  
<span class="line-modified">!     loadi PayloadOffset + ArgumentCount[sp], temp2</span>
      # We assume &lt; 2^28 arguments
      muli SlotSize, temp2
      addi StackAlignment - 1 + CallFrameHeaderSize, temp2
      andi ~StackAlignmentMask, temp2
  
<span class="line-new-header">--- 1073,11 ---</span>
      andi ~StackAlignmentMask, temp2
  
      move cfr, temp1
      addp temp2, temp1
  
<span class="line-modified">!     loadi PayloadOffset + ArgumentCountIncludingThis[sp], temp2</span>
      # We assume &lt; 2^28 arguments
      muli SlotSize, temp2
      addi StackAlignment - 1 + CallFrameHeaderSize, temp2
      andi ~StackAlignmentMask, temp2
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 996,23 ***</span>
  
      move temp1, sp
      jmp callee, callPtrTag
  end
  
<span class="line-modified">! macro slowPathForCall(size, opcodeStruct, dispatch, slowPath, prepareCall)</span>
      callCallSlowPath(
          slowPath,
          # Those are r0 and r1
          macro (callee, calleeFramePtr)
              btpz calleeFramePtr, .dontUpdateSP
              move calleeFramePtr, sp
              prepareCall(callee, t2, t3, t4, SlowPathPtrTag)
          .dontUpdateSP:
<span class="line-modified">!             callTargetFunction(size, opcodeStruct, dispatch, callee, SlowPathPtrTag)</span>
          end)
  end
  
  macro arrayProfile(offset, cellAndIndexingType, metadata, scratch)
      const cell = cellAndIndexingType
      const indexingType = cellAndIndexingType 
      loadi JSCell::m_structureID[cell], scratch
      storei scratch, offset + ArrayProfile::m_lastSeenStructureID[metadata]
<span class="line-new-header">--- 1115,32 ---</span>
  
      move temp1, sp
      jmp callee, callPtrTag
  end
  
<span class="line-modified">! macro slowPathForCall(opcodeName, size, opcodeStruct, dispatch, slowPath, prepareCall)</span>
      callCallSlowPath(
          slowPath,
          # Those are r0 and r1
          macro (callee, calleeFramePtr)
              btpz calleeFramePtr, .dontUpdateSP
              move calleeFramePtr, sp
              prepareCall(callee, t2, t3, t4, SlowPathPtrTag)
          .dontUpdateSP:
<span class="line-modified">!             callTargetFunction(%opcodeName%_slow, size, opcodeStruct, dispatch, callee, SlowPathPtrTag)</span>
          end)
  end
  
<span class="line-added">+ macro getterSetterOSRExitReturnPoint(opName, size)</span>
<span class="line-added">+     crash() # We don&#39;t reach this in straight line code. We only reach it via returning to the code below when reconstructing stack frames during OSR exit.</span>
<span class="line-added">+ </span>
<span class="line-added">+     defineOSRExitReturnLabel(opName, size)</span>
<span class="line-added">+ </span>
<span class="line-added">+     restoreStackPointerAfterCall()</span>
<span class="line-added">+     loadi LLIntReturnPC[cfr], PC</span>
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
  macro arrayProfile(offset, cellAndIndexingType, metadata, scratch)
      const cell = cellAndIndexingType
      const indexingType = cellAndIndexingType 
      loadi JSCell::m_structureID[cell], scratch
      storei scratch, offset + ArrayProfile::m_lastSeenStructureID[metadata]
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1055,22 ***</span>
      if JSVALUE64
          loadp Callee[cfr], targetRegister
      else
          loadp Callee + PayloadOffset[cfr], targetRegister
      end
<span class="line-modified">!     loadp JSFunction::m_executable[targetRegister], targetRegister</span>
      loadp FunctionExecutable::m_codeBlockForCall[targetRegister], targetRegister
      loadp ExecutableToCodeBlockEdge::m_codeBlock[targetRegister], targetRegister
  end
  
  macro functionForConstructCodeBlockGetter(targetRegister)
      if JSVALUE64
          loadp Callee[cfr], targetRegister
      else
          loadp Callee + PayloadOffset[cfr], targetRegister
      end
<span class="line-modified">!     loadp JSFunction::m_executable[targetRegister], targetRegister</span>
      loadp FunctionExecutable::m_codeBlockForConstruct[targetRegister], targetRegister
      loadp ExecutableToCodeBlockEdge::m_codeBlock[targetRegister], targetRegister
  end
  
  macro notFunctionCodeBlockGetter(targetRegister)
<span class="line-new-header">--- 1183,28 ---</span>
      if JSVALUE64
          loadp Callee[cfr], targetRegister
      else
          loadp Callee + PayloadOffset[cfr], targetRegister
      end
<span class="line-modified">!     loadp JSFunction::m_executableOrRareData[targetRegister], targetRegister</span>
<span class="line-added">+     btpz targetRegister, (constexpr JSFunction::rareDataTag), .isExecutable</span>
<span class="line-added">+     loadp (FunctionRareData::m_executable - (constexpr JSFunction::rareDataTag))[targetRegister], targetRegister</span>
<span class="line-added">+ .isExecutable:</span>
      loadp FunctionExecutable::m_codeBlockForCall[targetRegister], targetRegister
      loadp ExecutableToCodeBlockEdge::m_codeBlock[targetRegister], targetRegister
  end
  
  macro functionForConstructCodeBlockGetter(targetRegister)
      if JSVALUE64
          loadp Callee[cfr], targetRegister
      else
          loadp Callee + PayloadOffset[cfr], targetRegister
      end
<span class="line-modified">!     loadp JSFunction::m_executableOrRareData[targetRegister], targetRegister</span>
<span class="line-added">+     btpz targetRegister, (constexpr JSFunction::rareDataTag), .isExecutable</span>
<span class="line-added">+     loadp (FunctionRareData::m_executable - (constexpr JSFunction::rareDataTag))[targetRegister], targetRegister</span>
<span class="line-added">+ .isExecutable:</span>
      loadp FunctionExecutable::m_codeBlockForConstruct[targetRegister], targetRegister
      loadp ExecutableToCodeBlockEdge::m_codeBlock[targetRegister], targetRegister
  end
  
  macro notFunctionCodeBlockGetter(targetRegister)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1083,10 ***</span>
<span class="line-new-header">--- 1217,20 ---</span>
  
  macro notFunctionCodeBlockSetter(sourceRegister)
      # Nothing to do!
  end
  
<span class="line-added">+ macro convertCalleeToVM(callee)</span>
<span class="line-added">+     btpnz callee, (constexpr PreciseAllocation::halfAlignment), .preciseAllocation</span>
<span class="line-added">+     andp MarkedBlockMask, callee</span>
<span class="line-added">+     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[callee], callee</span>
<span class="line-added">+     jmp .done</span>
<span class="line-added">+ .preciseAllocation:</span>
<span class="line-added">+     loadp PreciseAllocationVMOffset[callee], callee</span>
<span class="line-added">+ .done:</span>
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
  # Do the bare minimum required to execute code. Sets up the PC, leave the CodeBlock*
  # in t1. May also trigger prologue entry OSR.
  macro prologue(codeBlockGetter, codeBlockSetter, osrSlowPath, traceSlowPath)
      # Set up the call frame and check if we should OSR.
      tagReturnAddress sp
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1096,10 ***</span>
<span class="line-new-header">--- 1240,11 ---</span>
          subp maxFrameExtentForSlowPathCall, sp
          callSlowPath(traceSlowPath)
          addp maxFrameExtentForSlowPathCall, sp
      end
      codeBlockGetter(t1)
<span class="line-added">+     codeBlockSetter(t1)</span>
      if not (C_LOOP or C_LOOP_WIN)
          baddis 5, CodeBlock::m_llintExecuteCounter + BaselineExecutionCounter::m_counter[t1], .continue
          if JSVALUE64
              move cfr, a0
              move PC, a1
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1125,25 ***</span>
          else
              pop cfr
          end
          jmp r0, JSEntryPtrTag
      .recover:
<span class="line-modified">!         codeBlockGetter(t1)</span>
      .continue:
      end
  
<span class="line-removed">-     codeBlockSetter(t1)</span>
<span class="line-removed">- </span>
      preserveCalleeSavesUsedByLLInt()
  
      # Set up the PC.
<span class="line-modified">!     if JSVALUE64</span>
<span class="line-modified">!         loadp CodeBlock::m_instructionsRawPointer[t1], PB</span>
<span class="line-removed">-         move 0, PC</span>
<span class="line-removed">-     else</span>
<span class="line-removed">-         loadp CodeBlock::m_instructionsRawPointer[t1], PC</span>
<span class="line-removed">-     end</span>
  
      # Get new sp in t0 and check stack height.
      getFrameRegisterSizeForCodeBlock(t1, t0)
      subp cfr, t0, t0
      bpa t0, cfr, .needStackCheck
<span class="line-new-header">--- 1270,19 ---</span>
          else
              pop cfr
          end
          jmp r0, JSEntryPtrTag
      .recover:
<span class="line-modified">!         notFunctionCodeBlockGetter(t1)</span>
      .continue:
      end
  
      preserveCalleeSavesUsedByLLInt()
  
      # Set up the PC.
<span class="line-modified">!     loadp CodeBlock::m_instructionsRawPointer[t1], PB</span>
<span class="line-modified">!     move 0, PC</span>
  
      # Get new sp in t0 and check stack height.
      getFrameRegisterSizeForCodeBlock(t1, t0)
      subp cfr, t0, t0
      bpa t0, cfr, .needStackCheck
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1170,11 ***</span>
      jmp _llint_throw_from_slow_path_trampoline
  
  .stackHeightOKGetCodeBlock:
      # Stack check slow path returned that the stack was ok.
      # Since they were clobbered, need to get CodeBlock and new sp
<span class="line-modified">!     codeBlockGetter(t1)</span>
      getFrameRegisterSizeForCodeBlock(t1, t0)
      subp cfr, t0, t0
  
  .stackHeightOK:
      if X86_64 or ARM64
<span class="line-new-header">--- 1309,11 ---</span>
      jmp _llint_throw_from_slow_path_trampoline
  
  .stackHeightOKGetCodeBlock:
      # Stack check slow path returned that the stack was ok.
      # Since they were clobbered, need to get CodeBlock and new sp
<span class="line-modified">!     notFunctionCodeBlockGetter(t1)</span>
      getFrameRegisterSizeForCodeBlock(t1, t0)
      subp cfr, t0, t0
  
  .stackHeightOK:
      if X86_64 or ARM64
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1192,12 ***</span>
      end
  
      loadp CodeBlock::m_metadata[t1], metadataTable
  
      if JSVALUE64
<span class="line-modified">!         move TagTypeNumber, tagTypeNumber</span>
<span class="line-modified">!         addq TagBitTypeOther, tagTypeNumber, tagMask</span>
      end
  end
  
  # Expects that CodeBlock is in t1, which is what prologue() leaves behind.
  # Must call dispatch(0) after calling this.
<span class="line-new-header">--- 1331,12 ---</span>
      end
  
      loadp CodeBlock::m_metadata[t1], metadataTable
  
      if JSVALUE64
<span class="line-modified">!         move TagNumber, numberTag</span>
<span class="line-modified">!         addq TagOther, numberTag, notCellMask</span>
      end
  end
  
  # Expects that CodeBlock is in t1, which is what prologue() leaves behind.
  # Must call dispatch(0) after calling this.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1277,26 ***</span>
          # We need three non-aliased caller-save registers. We are guaranteed
          # this for a0, a1 and a2 on all architectures.
          if X86 or X86_WIN
              loadp 4[sp], a0
          end
<span class="line-modified">!         const vm = a0</span>
          const address = a1
          const zeroValue = a2
      
<span class="line-modified">!         loadp VM::m_lastStackTop[vm], address</span>
          bpbeq sp, address, .zeroFillDone
<span class="line-modified">!     </span>
          move 0, zeroValue
      .zeroFillLoop:
          storep zeroValue, [address]
          addp PtrSize, address
<span class="line-modified">!         bpa sp, address, .zeroFillLoop</span>
  
      .zeroFillDone:
<span class="line-modified">!         move sp, address</span>
<span class="line-removed">-         storep address, VM::m_lastStackTop[vm]</span>
          ret
      
      # VMEntryRecord* vmEntryRecord(const EntryFrame* entryFrame)
      global _vmEntryRecord
      _vmEntryRecord:
<span class="line-new-header">--- 1416,30 ---</span>
          # We need three non-aliased caller-save registers. We are guaranteed
          # this for a0, a1 and a2 on all architectures.
          if X86 or X86_WIN
              loadp 4[sp], a0
          end
<span class="line-modified">!         const vmOrStartSP = a0</span>
          const address = a1
          const zeroValue = a2
      
<span class="line-modified">!         loadp VM::m_lastStackTop[vmOrStartSP], address</span>
<span class="line-added">+         move sp, zeroValue</span>
<span class="line-added">+         storep zeroValue, VM::m_lastStackTop[vmOrStartSP]</span>
<span class="line-added">+         move sp, vmOrStartSP</span>
<span class="line-added">+ </span>
          bpbeq sp, address, .zeroFillDone
<span class="line-modified">!         move address, sp</span>
<span class="line-added">+ </span>
          move 0, zeroValue
      .zeroFillLoop:
          storep zeroValue, [address]
          addp PtrSize, address
<span class="line-modified">!         bpa vmOrStartSP, address, .zeroFillLoop</span>
  
      .zeroFillDone:
<span class="line-modified">!         move vmOrStartSP, sp</span>
          ret
      
      # VMEntryRecord* vmEntryRecord(const EntryFrame* entryFrame)
      global _vmEntryRecord
      _vmEntryRecord:
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1312,111 ***</span>
  if C_LOOP or C_LOOP_WIN
      # Dummy entry point the C Loop uses to initialize.
      _llint_entry:
          crash()
  else
<span class="line-modified">!     macro initPCRelative(pcBase)</span>
          if X86_64 or X86_64_WIN or X86 or X86_WIN
<span class="line-modified">!             call _relativePCBase</span>
<span class="line-modified">!         _relativePCBase:</span>
              pop pcBase
          elsif ARM64 or ARM64E
          elsif ARMv7
<span class="line-modified">!         _relativePCBase:</span>
              move pc, pcBase
              subp 3, pcBase   # Need to back up the PC and set the Thumb2 bit
          elsif MIPS
<span class="line-modified">!             la _relativePCBase, pcBase</span>
              setcallreg pcBase # needed to set $t9 to the right value for the .cpload created by the label.
<span class="line-modified">!         _relativePCBase:</span>
          end
<span class="line-modified">! end</span>
  
<span class="line-modified">! # The PC base is in t3, as this is what _llint_entry leaves behind through</span>
<span class="line-modified">! # initPCRelative(t3)</span>
<span class="line-modified">! macro setEntryAddress(index, label)</span>
<span class="line-modified">!     setEntryAddressCommon(index, label, a0)</span>
<span class="line-modified">! end</span>
  
<span class="line-removed">- macro setEntryAddressWide16(index, label)</span>
<span class="line-removed">-      setEntryAddressCommon(index, label, a1)</span>
<span class="line-removed">- end</span>
  
<span class="line-removed">- macro setEntryAddressWide32(index, label)</span>
<span class="line-removed">-      setEntryAddressCommon(index, label, a2)</span>
<span class="line-removed">- end</span>
  
<span class="line-modified">! macro setEntryAddressCommon(index, label, map)</span>
<span class="line-modified">!     if X86_64</span>
<span class="line-modified">!         leap (label - _relativePCBase)[t3], t4</span>
<span class="line-modified">!         move index, t5</span>
<span class="line-removed">-         storep t4, [map, t5, 8]</span>
<span class="line-removed">-     elsif X86_64_WIN</span>
<span class="line-removed">-         leap (label - _relativePCBase)[t3], t4</span>
<span class="line-removed">-         move index, t0</span>
<span class="line-removed">-         storep t4, [map, t0, 8]</span>
<span class="line-removed">-     elsif X86 or X86_WIN</span>
<span class="line-removed">-         leap (label - _relativePCBase)[t3], t4</span>
<span class="line-removed">-         move index, t5</span>
<span class="line-removed">-         storep t4, [map, t5, 4]</span>
<span class="line-removed">-     elsif ARM64 or ARM64E</span>
<span class="line-removed">-         pcrtoaddr label, t3</span>
<span class="line-removed">-         move index, t4</span>
<span class="line-removed">-         storep t3, [map, t4, PtrSize]</span>
<span class="line-removed">-     elsif ARMv7</span>
<span class="line-removed">-         mvlbl (label - _relativePCBase), t4</span>
<span class="line-removed">-         addp t4, t3, t4</span>
<span class="line-removed">-         move index, t5</span>
<span class="line-removed">-         storep t4, [map, t5, 4]</span>
<span class="line-removed">-     elsif MIPS</span>
<span class="line-removed">-         la label, t4</span>
<span class="line-removed">-         la _relativePCBase, t3</span>
<span class="line-removed">-         subp t3, t4</span>
<span class="line-removed">-         addp t4, t3, t4</span>
<span class="line-removed">-         move index, t5</span>
<span class="line-removed">-         storep t4, [map, t5, 4]</span>
<span class="line-removed">-     end</span>
<span class="line-removed">- end</span>
  
<span class="line-modified">! global _llint_entry</span>
<span class="line-modified">! # Entry point for the llint to initialize.</span>
<span class="line-modified">! _llint_entry:</span>
<span class="line-modified">!     functionPrologue()</span>
<span class="line-modified">!     pushCalleeSaves()</span>
<span class="line-modified">!     if X86 or X86_WIN</span>
<span class="line-modified">!         loadp 20[sp], a0</span>
<span class="line-modified">!         loadp 24[sp], a1</span>
<span class="line-modified">!         loadp 28[sp], a2</span>
      end
  
<span class="line-removed">-     initPCRelative(t3)</span>
  
<span class="line-modified">!     # Include generated bytecode initialization file.</span>
<span class="line-modified">!     include InitBytecodes</span>
  
<span class="line-modified">!     popCalleeSaves()</span>
<span class="line-modified">!     functionEpilogue()</span>
<span class="line-modified">!     ret</span>
  end
  
  _llint_op_wide16:
      nextInstructionWide16()
  
  _llint_op_wide32:
      nextInstructionWide32()
  
  macro noWide(label)
<span class="line-modified">! _llint_%label%_wide16:</span>
      crash()
  
<span class="line-modified">! _llint_%label%_wide32:</span>
      crash()
  end
  
<span class="line-modified">! noWide(op_wide16)</span>
<span class="line-modified">! noWide(op_wide32)</span>
<span class="line-modified">! noWide(op_enter)</span>
  
  op(llint_program_prologue, macro ()
      prologue(notFunctionCodeBlockGetter, notFunctionCodeBlockSetter, _llint_entry_osr, _llint_trace_prologue)
      dispatch(0)
  end)
<span class="line-new-header">--- 1455,124 ---</span>
  if C_LOOP or C_LOOP_WIN
      # Dummy entry point the C Loop uses to initialize.
      _llint_entry:
          crash()
  else
<span class="line-modified">!     macro initPCRelative(kind, pcBase)</span>
          if X86_64 or X86_64_WIN or X86 or X86_WIN
<span class="line-modified">!             call _%kind%_relativePCBase</span>
<span class="line-modified">!         _%kind%_relativePCBase:</span>
              pop pcBase
          elsif ARM64 or ARM64E
          elsif ARMv7
<span class="line-modified">!         _%kind%_relativePCBase:</span>
              move pc, pcBase
              subp 3, pcBase   # Need to back up the PC and set the Thumb2 bit
          elsif MIPS
<span class="line-modified">!             la _%kind%_relativePCBase, pcBase</span>
              setcallreg pcBase # needed to set $t9 to the right value for the .cpload created by the label.
<span class="line-modified">!         _%kind%_relativePCBase:</span>
          end
<span class="line-modified">!     end</span>
  
<span class="line-modified">!     # The PC base is in t3, as this is what _llint_entry leaves behind through</span>
<span class="line-modified">!     # initPCRelative(t3)</span>
<span class="line-modified">!     macro setEntryAddressCommon(kind, index, label, map)</span>
<span class="line-modified">!         if X86_64</span>
<span class="line-modified">!             leap (label - _%kind%_relativePCBase)[t3], t4</span>
<span class="line-added">+             move index, t5</span>
<span class="line-added">+             storep t4, [map, t5, 8]</span>
<span class="line-added">+         elsif X86_64_WIN</span>
<span class="line-added">+             leap (label - _%kind%_relativePCBase)[t3], t4</span>
<span class="line-added">+             move index, t0</span>
<span class="line-added">+             storep t4, [map, t0, 8]</span>
<span class="line-added">+         elsif X86 or X86_WIN</span>
<span class="line-added">+             leap (label - _%kind%_relativePCBase)[t3], t4</span>
<span class="line-added">+             move index, t5</span>
<span class="line-added">+             storep t4, [map, t5, 4]</span>
<span class="line-added">+         elsif ARM64 or ARM64E</span>
<span class="line-added">+             pcrtoaddr label, t3</span>
<span class="line-added">+             move index, t4</span>
<span class="line-added">+             storep t3, [map, t4, PtrSize]</span>
<span class="line-added">+         elsif ARMv7</span>
<span class="line-added">+             mvlbl (label - _%kind%_relativePCBase), t4</span>
<span class="line-added">+             addp t4, t3, t4</span>
<span class="line-added">+             move index, t5</span>
<span class="line-added">+             storep t4, [map, t5, 4]</span>
<span class="line-added">+         elsif MIPS</span>
<span class="line-added">+             la label, t4</span>
<span class="line-added">+             la _%kind%_relativePCBase, t3</span>
<span class="line-added">+             subp t3, t4</span>
<span class="line-added">+             addp t4, t3, t4</span>
<span class="line-added">+             move index, t5</span>
<span class="line-added">+             storep t4, [map, t5, 4]</span>
<span class="line-added">+         end</span>
<span class="line-added">+     end</span>
  
  
  
<span class="line-modified">!     macro includeEntriesAtOffset(kind, fn)</span>
<span class="line-modified">!         macro setEntryAddress(index, label)</span>
<span class="line-modified">!             setEntryAddressCommon(kind, index, label, a0)</span>
<span class="line-modified">!         end</span>
  
<span class="line-modified">!         macro setEntryAddressWide16(index, label)</span>
<span class="line-modified">!              setEntryAddressCommon(kind, index, label, a1)</span>
<span class="line-modified">!         end</span>
<span class="line-modified">! </span>
<span class="line-modified">!         macro setEntryAddressWide32(index, label)</span>
<span class="line-modified">!              setEntryAddressCommon(kind, index, label, a2)</span>
<span class="line-modified">!         end</span>
<span class="line-modified">! </span>
<span class="line-modified">!         fn()</span>
      end
  
  
<span class="line-modified">! macro entry(kind, initialize)</span>
<span class="line-modified">!     global _%kind%_entry</span>
<span class="line-added">+     _%kind%_entry:</span>
<span class="line-added">+         functionPrologue()</span>
<span class="line-added">+         pushCalleeSaves()</span>
<span class="line-added">+         if X86 or X86_WIN</span>
<span class="line-added">+             loadp 20[sp], a0</span>
<span class="line-added">+             loadp 24[sp], a1</span>
<span class="line-added">+             loadp 28[sp], a2</span>
<span class="line-added">+         end</span>
  
<span class="line-modified">!         initPCRelative(kind, t3)</span>
<span class="line-modified">! </span>
<span class="line-modified">!         # Include generated bytecode initialization file.</span>
<span class="line-added">+         includeEntriesAtOffset(kind, initialize)</span>
<span class="line-added">+         popCalleeSaves()</span>
<span class="line-added">+         functionEpilogue()</span>
<span class="line-added">+         ret</span>
  end
  
<span class="line-added">+ # Entry point for the llint to initialize.</span>
<span class="line-added">+ entry(llint, macro()</span>
<span class="line-added">+     include InitBytecodes</span>
<span class="line-added">+ end)</span>
<span class="line-added">+ </span>
<span class="line-added">+ end // not (C_LOOP or C_LOOP_WIN)</span>
<span class="line-added">+ </span>
  _llint_op_wide16:
      nextInstructionWide16()
  
  _llint_op_wide32:
      nextInstructionWide32()
  
  macro noWide(label)
<span class="line-modified">! _%label%_wide16:</span>
      crash()
  
<span class="line-modified">! _%label%_wide32:</span>
      crash()
  end
  
<span class="line-modified">! noWide(llint_op_wide16)</span>
<span class="line-modified">! noWide(llint_op_wide32)</span>
<span class="line-modified">! noWide(llint_op_enter)</span>
  
  op(llint_program_prologue, macro ()
      prologue(notFunctionCodeBlockGetter, notFunctionCodeBlockSetter, _llint_entry_osr, _llint_trace_prologue)
      dispatch(0)
  end)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1481,15 ***</span>
<span class="line-new-header">--- 1637,19 ---</span>
          dispatch()
      end)
  end
  
  slowPathOp(create_cloned_arguments)
<span class="line-added">+ slowPathOp(create_arguments_butterfly)</span>
  slowPathOp(create_direct_arguments)
  slowPathOp(create_lexical_environment)
  slowPathOp(create_rest)
  slowPathOp(create_scoped_arguments)
  slowPathOp(create_this)
<span class="line-added">+ slowPathOp(create_promise)</span>
<span class="line-added">+ slowPathOp(create_generator)</span>
<span class="line-added">+ slowPathOp(create_async_generator)</span>
  slowPathOp(define_accessor_property)
  slowPathOp(define_data_property)
  slowPathOp(enumerator_generic_pname)
  slowPathOp(enumerator_structure_pname)
  slowPathOp(get_by_id_with_this)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1520,10 ***</span>
<span class="line-new-header">--- 1680,12 ---</span>
  slowPathOp(strcat)
  slowPathOp(throw_static_error)
  slowPathOp(to_index_string)
  slowPathOp(typeof)
  slowPathOp(unreachable)
<span class="line-added">+ slowPathOp(new_promise)</span>
<span class="line-added">+ slowPathOp(new_generator)</span>
  
  macro llintSlowPathOp(opcodeName)
      llintOp(op_%opcodeName%, unused, macro (unused, unused, dispatch)
          callSlowPath(_llint_slow_path_%opcodeName%)
          dispatch()
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1663,26 ***</span>
  
  
  preOp(inc, OpInc,
      macro (value, slow) baddio 1, value, slow end)
  
<span class="line-removed">- </span>
  preOp(dec, OpDec,
      macro (value, slow) bsubio 1, value, slow end)
  
  
  llintOp(op_loop_hint, OpLoopHint, macro (unused, unused, dispatch)
<span class="line-modified">!     # CheckTraps.</span>
      loadp CodeBlock[cfr], t1
      loadp CodeBlock::m_vm[t1], t1
<span class="line-modified">!     btbnz VM::m_traps + VMTraps::m_needTrapHandling[t1], .handleTraps</span>
  .afterHandlingTraps:
<span class="line-removed">-     checkSwitchToJITForLoop()</span>
      dispatch()
  .handleTraps:
<span class="line-modified">!     callTrapHandler(_llint_throw_from_slow_path_trampoline)</span>
      jmp .afterHandlingTraps
  end)
  
  
  # Returns the packet pointer in t0.
  macro acquireShadowChickenPacket(slow)
<span class="line-new-header">--- 1825,32 ---</span>
  
  
  preOp(inc, OpInc,
      macro (value, slow) baddio 1, value, slow end)
  
  preOp(dec, OpDec,
      macro (value, slow) bsubio 1, value, slow end)
  
  
  llintOp(op_loop_hint, OpLoopHint, macro (unused, unused, dispatch)
<span class="line-modified">!     checkSwitchToJITForLoop()</span>
<span class="line-added">+     dispatch()</span>
<span class="line-added">+ end)</span>
<span class="line-added">+ </span>
<span class="line-added">+ </span>
<span class="line-added">+ llintOp(op_check_traps, OpCheckTraps, macro (unused, unused, dispatch)</span>
      loadp CodeBlock[cfr], t1
      loadp CodeBlock::m_vm[t1], t1
<span class="line-modified">!     loadb VM::m_traps+VMTraps::m_needTrapHandling[t1], t0</span>
<span class="line-added">+     btpnz t0, .handleTraps</span>
  .afterHandlingTraps:
      dispatch()
  .handleTraps:
<span class="line-modified">!     callTrapHandler(.throwHandler)</span>
      jmp .afterHandlingTraps
<span class="line-added">+ .throwHandler:</span>
<span class="line-added">+     jmp _llint_throw_from_slow_path_trampoline</span>
  end)
  
  
  # Returns the packet pointer in t0.
  macro acquireShadowChickenPacket(slow)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1721,11 ***</span>
  
  
  callOp(construct, OpConstruct, prepareForRegularCall, macro (getu, metadata) end)
  
  
<span class="line-modified">! macro doCallVarargs(size, opcodeStruct, dispatch, frameSlowPath, slowPath, prepareCall)</span>
      callSlowPath(frameSlowPath)
      branchIfException(_llint_throw_from_slow_path_trampoline)
      # calleeFrame in r1
      if JSVALUE64
          move r1, sp
<span class="line-new-header">--- 1889,19 ---</span>
  
  
  callOp(construct, OpConstruct, prepareForRegularCall, macro (getu, metadata) end)
  
  
<span class="line-modified">! macro branchIfException(exceptionTarget)</span>
<span class="line-added">+     loadp CodeBlock[cfr], t3</span>
<span class="line-added">+     loadp CodeBlock::m_vm[t3], t3</span>
<span class="line-added">+     btpz VM::m_exception[t3], .noException</span>
<span class="line-added">+     jmp exceptionTarget</span>
<span class="line-added">+ .noException:</span>
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
<span class="line-added">+ macro doCallVarargs(opcodeName, size, opcodeStruct, dispatch, frameSlowPath, slowPath, prepareCall)</span>
      callSlowPath(frameSlowPath)
      branchIfException(_llint_throw_from_slow_path_trampoline)
      # calleeFrame in r1
      if JSVALUE64
          move r1, sp
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1736,36 ***</span>
              move t2, sp
          else
              subp r1, CallerFrameAndPCSize, sp
          end
      end
<span class="line-modified">!     slowPathForCall(size, opcodeStruct, dispatch, slowPath, prepareCall)</span>
  end
  
  
  llintOp(op_call_varargs, OpCallVarargs, macro (size, get, dispatch)
<span class="line-modified">!     doCallVarargs(size, OpCallVarargs, dispatch, _llint_slow_path_size_frame_for_varargs, _llint_slow_path_call_varargs, prepareForRegularCall)</span>
  end)
  
  llintOp(op_tail_call_varargs, OpTailCallVarargs, macro (size, get, dispatch)
      checkSwitchToJITForEpilogue()
      # We lie and perform the tail call instead of preparing it since we can&#39;t
      # prepare the frame for a call opcode
<span class="line-modified">!     doCallVarargs(size, OpTailCallVarargs, dispatch, _llint_slow_path_size_frame_for_varargs, _llint_slow_path_tail_call_varargs, prepareForTailCall)</span>
  end)
  
  
  llintOp(op_tail_call_forward_arguments, OpTailCallForwardArguments, macro (size, get, dispatch)
      checkSwitchToJITForEpilogue()
      # We lie and perform the tail call instead of preparing it since we can&#39;t
      # prepare the frame for a call opcode
<span class="line-modified">!     doCallVarargs(size, OpTailCallForwardArguments, dispatch, _llint_slow_path_size_frame_for_forward_arguments, _llint_slow_path_tail_call_forward_arguments, prepareForTailCall)</span>
  end)
  
  
  llintOp(op_construct_varargs, OpConstructVarargs, macro (size, get, dispatch)
<span class="line-modified">!     doCallVarargs(size, OpConstructVarargs, dispatch, _llint_slow_path_size_frame_for_varargs, _llint_slow_path_construct_varargs, prepareForRegularCall)</span>
  end)
  
  
  # Eval is executed in one of two modes:
  #
<span class="line-new-header">--- 1912,36 ---</span>
              move t2, sp
          else
              subp r1, CallerFrameAndPCSize, sp
          end
      end
<span class="line-modified">!     slowPathForCall(opcodeName, size, opcodeStruct, dispatch, slowPath, prepareCall)</span>
  end
  
  
  llintOp(op_call_varargs, OpCallVarargs, macro (size, get, dispatch)
<span class="line-modified">!     doCallVarargs(op_call_varargs, size, OpCallVarargs, dispatch, _llint_slow_path_size_frame_for_varargs, _llint_slow_path_call_varargs, prepareForRegularCall)</span>
  end)
  
  llintOp(op_tail_call_varargs, OpTailCallVarargs, macro (size, get, dispatch)
      checkSwitchToJITForEpilogue()
      # We lie and perform the tail call instead of preparing it since we can&#39;t
      # prepare the frame for a call opcode
<span class="line-modified">!     doCallVarargs(op_tail_call_varargs, size, OpTailCallVarargs, dispatch, _llint_slow_path_size_frame_for_varargs, _llint_slow_path_tail_call_varargs, prepareForTailCall)</span>
  end)
  
  
  llintOp(op_tail_call_forward_arguments, OpTailCallForwardArguments, macro (size, get, dispatch)
      checkSwitchToJITForEpilogue()
      # We lie and perform the tail call instead of preparing it since we can&#39;t
      # prepare the frame for a call opcode
<span class="line-modified">!     doCallVarargs(op_tail_call_forward_arguments, size, OpTailCallForwardArguments, dispatch, _llint_slow_path_size_frame_for_forward_arguments, _llint_slow_path_tail_call_forward_arguments, prepareForTailCall)</span>
  end)
  
  
  llintOp(op_construct_varargs, OpConstructVarargs, macro (size, get, dispatch)
<span class="line-modified">!     doCallVarargs(op_construct_varargs, size, OpConstructVarargs, dispatch, _llint_slow_path_size_frame_for_varargs, _llint_slow_path_construct_varargs, prepareForRegularCall)</span>
  end)
  
  
  # Eval is executed in one of two modes:
  #
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1800,26 ***</span>
<span class="line-new-header">--- 1976,29 ---</span>
  # and a PC to call, and that PC may be a dummy thunk that just
  # returns the JS value that the eval returned.
  
  _llint_op_call_eval:
      slowPathForCall(
<span class="line-added">+         op_call_eval_narrow,</span>
          narrow,
          OpCallEval,
          macro () dispatchOp(narrow, op_call_eval) end,
          _llint_slow_path_call_eval,
          prepareForRegularCall)
  
  _llint_op_call_eval_wide16:
      slowPathForCall(
<span class="line-added">+         op_call_eval_wide16,</span>
          wide16,
          OpCallEval,
          macro () dispatchOp(wide16, op_call_eval) end,
          _llint_slow_path_call_eval_wide16,
          prepareForRegularCall)
  
  _llint_op_call_eval_wide32:
      slowPathForCall(
<span class="line-added">+         op_call_eval_wide32,</span>
          wide32,
          OpCallEval,
          macro () dispatchOp(wide32, op_call_eval) end,
          _llint_slow_path_call_eval_wide32,
          prepareForRegularCall)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1875,10 ***</span>
<span class="line-new-header">--- 2054,57 ---</span>
  op(llint_internal_function_construct_trampoline, macro ()
      internalFunctionCallTrampoline(InternalFunction::m_functionForConstruct)
  end)
  
  
<span class="line-added">+ op(checkpoint_osr_exit_from_inlined_call_trampoline, macro ()</span>
<span class="line-added">+     if (JSVALUE64 and not (C_LOOP or C_LOOP_WIN)) or ARMv7 or MIPS</span>
<span class="line-added">+         restoreStackPointerAfterCall()</span>
<span class="line-added">+ </span>
<span class="line-added">+         # Make sure we move r0 to a1 first since r0 might be the same as a0, for instance, on arm.</span>
<span class="line-added">+         if ARMv7 or MIPS</span>
<span class="line-added">+             # Given _slow_path_checkpoint_osr_exit_from_inlined_call has</span>
<span class="line-added">+             # parameters as CallFrame* and EncodedJSValue,</span>
<span class="line-added">+             # we need to store call result on a2, a3 and call frame on a0,</span>
<span class="line-added">+             # leaving a1 as dummy value.</span>
<span class="line-added">+             move r1, a3</span>
<span class="line-added">+             move r0, a2</span>
<span class="line-added">+             move cfr, a0</span>
<span class="line-added">+             # We don&#39;t call saveStateForCCall() because we are going to use the bytecodeIndex from our side state.</span>
<span class="line-added">+             cCall4(_slow_path_checkpoint_osr_exit_from_inlined_call)</span>
<span class="line-added">+         else</span>
<span class="line-added">+             move r0, a1</span>
<span class="line-added">+             move cfr, a0</span>
<span class="line-added">+             # We don&#39;t call saveStateForCCall() because we are going to use the bytecodeIndex from our side state.</span>
<span class="line-added">+             cCall2(_slow_path_checkpoint_osr_exit_from_inlined_call)</span>
<span class="line-added">+         end</span>
<span class="line-added">+ </span>
<span class="line-added">+         restoreStateAfterCCall()</span>
<span class="line-added">+         branchIfException(_llint_throw_from_slow_path_trampoline)</span>
<span class="line-added">+         jmp r1, JSEntryPtrTag</span>
<span class="line-added">+     else</span>
<span class="line-added">+         notSupported()</span>
<span class="line-added">+     end</span>
<span class="line-added">+ end)</span>
<span class="line-added">+ </span>
<span class="line-added">+ op(checkpoint_osr_exit_trampoline, macro ()</span>
<span class="line-added">+     # FIXME: We can probably dispatch to the checkpoint handler directly but this was easier</span>
<span class="line-added">+     # and probably doesn&#39;t matter for performance.</span>
<span class="line-added">+     if (JSVALUE64 and not (C_LOOP or C_LOOP_WIN)) or ARMv7 or MIPS</span>
<span class="line-added">+         restoreStackPointerAfterCall()</span>
<span class="line-added">+ </span>
<span class="line-added">+         move cfr, a0</span>
<span class="line-added">+         # We don&#39;t call saveStateForCCall() because we are going to use the bytecodeIndex from our side state.</span>
<span class="line-added">+         cCall2(_slow_path_checkpoint_osr_exit)</span>
<span class="line-added">+         restoreStateAfterCCall()</span>
<span class="line-added">+         branchIfException(_llint_throw_from_slow_path_trampoline)</span>
<span class="line-added">+         jmp r1, JSEntryPtrTag</span>
<span class="line-added">+     else</span>
<span class="line-added">+         notSupported()</span>
<span class="line-added">+     end</span>
<span class="line-added">+ end)</span>
<span class="line-added">+ </span>
  # Lastly, make sure that we can link even though we don&#39;t support all opcodes.
  # These opcodes should never arise when using LLInt or either JIT. We assert
  # as much.
  
  macro notSupported()
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1892,5 ***</span>
<span class="line-new-header">--- 2118,33 ---</span>
          # instruction on all architectures we&#39;re interested in. (Break is int3
          # on Intel, which is 1 byte, and bkpt on ARMv7, which is 2 bytes.)
          break
      end
  end
<span class="line-added">+ </span>
<span class="line-added">+ // FIXME: We should not need the X86_64_WIN condition here, since WEBASSEMBLY should already be false on Windows</span>
<span class="line-added">+ // https://bugs.webkit.org/show_bug.cgi?id=203716</span>
<span class="line-added">+ if WEBASSEMBLY and not X86_64_WIN</span>
<span class="line-added">+ </span>
<span class="line-added">+ entry(wasm, macro()</span>
<span class="line-added">+     include InitWasm</span>
<span class="line-added">+ end)</span>
<span class="line-added">+ </span>
<span class="line-added">+ macro wasmScope()</span>
<span class="line-added">+     # Wrap the script in a macro since it overwrites some of the LLInt macros,</span>
<span class="line-added">+     # but we don&#39;t want to interfere with the LLInt opcodes</span>
<span class="line-added">+     include WebAssembly</span>
<span class="line-added">+ end</span>
<span class="line-added">+ wasmScope()</span>
<span class="line-added">+ </span>
<span class="line-added">+ else</span>
<span class="line-added">+ </span>
<span class="line-added">+ # These need to be defined even when WebAssembly is disabled</span>
<span class="line-added">+ op(wasm_function_prologue, macro ()</span>
<span class="line-added">+     crash()</span>
<span class="line-added">+ end)</span>
<span class="line-added">+ </span>
<span class="line-added">+ op(wasm_function_prologue_no_tls, macro ()</span>
<span class="line-added">+     crash()</span>
<span class="line-added">+ end)</span>
<span class="line-added">+ </span>
<span class="line-added">+ end</span>
</pre>
<center><a href="LLIntThunks.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="LowLevelInterpreter.cpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>