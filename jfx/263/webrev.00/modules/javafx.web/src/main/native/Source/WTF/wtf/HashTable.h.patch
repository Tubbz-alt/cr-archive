diff a/modules/javafx.web/src/main/native/Source/WTF/wtf/HashTable.h b/modules/javafx.web/src/main/native/Source/WTF/wtf/HashTable.h
--- a/modules/javafx.web/src/main/native/Source/WTF/wtf/HashTable.h
+++ b/modules/javafx.web/src/main/native/Source/WTF/wtf/HashTable.h
@@ -1,7 +1,7 @@
 /*
- * Copyright (C) 2005, 2006, 2007, 2008, 2011, 2012, 2015 Apple Inc. All rights reserved.
+ * Copyright (C) 2005-2019 Apple Inc. All rights reserved.
  * Copyright (C) 2008 David Levin <levin@chromium.org>
  *
  * This library is free software; you can redistribute it and/or
  * modify it under the terms of the GNU Library General Public
  * License as published by the Free Software Foundation; either
@@ -26,10 +26,11 @@
 #include <mutex>
 #include <string.h>
 #include <type_traits>
 #include <utility>
 #include <wtf/Assertions.h>
+#include <wtf/DebugHeap.h>
 #include <wtf/FastMalloc.h>
 #include <wtf/HashTraits.h>
 #include <wtf/Lock.h>
 #include <wtf/MathExtras.h>
 #include <wtf/RandomNumber.h>
@@ -43,10 +44,12 @@
 #include <wtf/DataLog.h>
 #endif
 
 namespace WTF {
 
+DECLARE_ALLOCATOR_WITH_HEAP_IDENTIFIER(HashTable);
+
 // Enables internal WTF consistency checks that are invoked automatically. Non-WTF callers can call checkTableConsistency() even if internal checks are disabled.
 #define CHECK_HASHTABLE_CONSISTENCY 0
 
 #ifdef NDEBUG
 #define CHECK_HASHTABLE_ITERATORS 0
@@ -298,10 +301,51 @@
         bool isNewEntry;
 
         explicit operator bool() const { return isNewEntry; }
     };
 
+    // HashTableCapacityForSize computes the upper power of two capacity to hold the size parameter.
+    // This is done at compile time to initialize the HashTraits.
+    template<unsigned size>
+    struct HashTableCapacityForSize {
+        // Load-factor for small table is 75%.
+        static constexpr unsigned smallMaxLoadNumerator = 3;
+        static constexpr unsigned smallMaxLoadDenominator = 4;
+        // Load-factor for large table is 50%.
+        static constexpr unsigned largeMaxLoadNumerator = 1;
+        static constexpr unsigned largeMaxLoadDenominator = 2;
+        static constexpr unsigned maxSmallTableCapacity = 1024;
+        static constexpr unsigned minLoad = 6;
+
+        static constexpr bool shouldExpand(uint64_t keyAndDeleteCount, uint64_t tableSize)
+        {
+            if (tableSize <= maxSmallTableCapacity)
+                return keyAndDeleteCount * smallMaxLoadDenominator >= tableSize * smallMaxLoadNumerator;
+            return keyAndDeleteCount * largeMaxLoadDenominator >= tableSize * largeMaxLoadNumerator;
+        }
+
+        static constexpr unsigned capacityForSize(uint32_t sizeArg)
+        {
+            if (!sizeArg)
+                return 0;
+            constexpr unsigned maxCapacity = 1U << 31;
+            UNUSED_PARAM(maxCapacity);
+            ASSERT_UNDER_CONSTEXPR_CONTEXT(sizeArg <= maxCapacity);
+            uint32_t capacity = roundUpToPowerOfTwo(sizeArg);
+            ASSERT_UNDER_CONSTEXPR_CONTEXT(capacity <= maxCapacity);
+            if (shouldExpand(sizeArg, capacity)) {
+                ASSERT_UNDER_CONSTEXPR_CONTEXT((static_cast<uint64_t>(capacity) * 2) <= maxCapacity);
+                return capacity * 2;
+            }
+            return capacity;
+        }
+
+        static constexpr unsigned value = capacityForSize(size);
+        static_assert(size > 0, "HashTableNonZeroMinimumCapacity");
+        static_assert(!static_cast<unsigned>(value >> 31), "HashTableNoCapacityOverflow");
+    };
+
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
     class HashTable {
     public:
         typedef HashTableIterator<Key, Value, Extractor, HashFunctions, Traits, KeyTraits> iterator;
         typedef HashTableConstIterator<Key, Value, Extractor, HashFunctions, Traits, KeyTraits> const_iterator;
@@ -309,10 +353,12 @@
         typedef Key KeyType;
         typedef Value ValueType;
         typedef IdentityHashTranslator<ValueTraits, HashFunctions> IdentityTranslatorType;
         typedef HashTableAddResult<iterator> AddResult;
 
+        using HashTableSizePolicy = HashTableCapacityForSize<1>;
+
 #if DUMP_HASHTABLE_STATS_PER_TABLE
         struct Stats {
             WTF_MAKE_STRUCT_FAST_ALLOCATED;
 
             Stats()
@@ -379,11 +425,11 @@
 #else
             invalidateIterators();
 #endif
 
             if (m_table)
-                deallocateTable(m_table, m_tableSize);
+                deallocateTable(m_table);
 #if CHECK_HASHTABLE_USE_AFTER_DESTRUCTION
             m_table = (ValueType*)(uintptr_t)0xbbadbeef;
 #endif
         }
 
@@ -396,44 +442,45 @@
 
         // When the hash table is empty, just return the same iterator for end as for begin.
         // This is more efficient because we don't have to skip all the empty and deleted
         // buckets, and iterating an empty table is a common case that's worth optimizing.
         iterator begin() { return isEmpty() ? end() : makeIterator(m_table); }
-        iterator end() { return makeKnownGoodIterator(m_table + m_tableSize); }
+        iterator end() { return makeKnownGoodIterator(m_table + tableSize()); }
         const_iterator begin() const { return isEmpty() ? end() : makeConstIterator(m_table); }
-        const_iterator end() const { return makeKnownGoodConstIterator(m_table + m_tableSize); }
+        const_iterator end() const { return makeKnownGoodConstIterator(m_table + tableSize()); }
 
         iterator random()
         {
             if (isEmpty())
                 return end();
 
             while (1) {
-                auto& bucket = m_table[weakRandomUint32() & m_tableSizeMask];
+                auto& bucket = m_table[weakRandomUint32() & tableSizeMask()];
                 if (!isEmptyOrDeletedBucket(bucket))
                     return makeKnownGoodIterator(&bucket);
             };
         }
 
         const_iterator random() const { return static_cast<const_iterator>(const_cast<HashTable*>(this)->random()); }
 
-        unsigned size() const { return m_keyCount; }
-        unsigned capacity() const { return m_tableSize; }
-        bool isEmpty() const { return !m_keyCount; }
+        unsigned size() const { return keyCount(); }
+        unsigned capacity() const { return tableSize(); }
+        bool isEmpty() const { return !keyCount(); }
 
         void reserveInitialCapacity(unsigned keyCount)
         {
             ASSERT(!m_table);
-            ASSERT(!m_tableSize);
-            ASSERT(!m_deletedCount);
+            ASSERT(!tableSize());
 
             unsigned minimumTableSize = KeyTraits::minimumTableSize;
             unsigned newTableSize = std::max(minimumTableSize, computeBestTableSize(keyCount));
 
-            m_tableSize = newTableSize;
-            m_tableSizeMask = newTableSize - 1;
             m_table = allocateTable(newTableSize);
+            setTableSize(newTableSize);
+            setTableSizeMask(newTableSize - 1);
+            setDeletedCount(0);
+            setKeyCount(0);
         }
 
         AddResult add(const ValueType& value) { return add<IdentityTranslatorType>(Extractor::extract(value), value); }
         AddResult add(ValueType&& value) { return add<IdentityTranslatorType>(Extractor::extract(value), WTFMove(value)); }
 
@@ -466,11 +513,11 @@
 
         ValueType* lookup(const Key& key) { return lookup<IdentityTranslatorType>(key); }
         template<typename HashTranslator, typename T> ValueType* lookup(const T&);
         template<typename HashTranslator, typename T> ValueType* inlineLookup(const T&);
 
-#if !ASSERT_DISABLED
+#if ASSERT_ENABLED
         void checkTableConsistency() const;
 #else
         static void checkTableConsistency() { }
 #endif
 #if CHECK_HASHTABLE_CONSISTENCY
@@ -481,11 +528,11 @@
         static void internalCheckTableConsistency() { }
 #endif
 
     private:
         static ValueType* allocateTable(unsigned size);
-        static void deallocateTable(ValueType* table, unsigned size);
+        static void deallocateTable(ValueType* table);
 
         typedef std::pair<ValueType*, bool> LookupType;
         typedef std::pair<LookupType, unsigned> FullLookupType;
 
         LookupType lookupForWriting(const Key& key) { return lookupForWriting<IdentityTranslatorType>(key); };
@@ -499,15 +546,15 @@
         void removeAndInvalidateWithoutEntryConsistencyCheck(ValueType*);
         void removeAndInvalidate(ValueType*);
         void remove(ValueType*);
 
         static constexpr unsigned computeBestTableSize(unsigned keyCount);
-        bool shouldExpand() const { return (m_keyCount + m_deletedCount) * m_maxLoad >= m_tableSize; }
-        bool mustRehashInPlace() const { return m_keyCount * m_minLoad < m_tableSize * 2; }
-        bool shouldShrink() const { return m_keyCount * m_minLoad < m_tableSize && m_tableSize > KeyTraits::minimumTableSize; }
+        bool shouldExpand() const { return HashTableSizePolicy::shouldExpand(keyCount() + deletedCount(), tableSize()); }
+        bool mustRehashInPlace() const { return keyCount() * minLoad < tableSize() * 2; }
+        bool shouldShrink() const { return keyCount() * minLoad < tableSize() && tableSize() > KeyTraits::minimumTableSize; }
         ValueType* expand(ValueType* entry = nullptr);
-        void shrink() { rehash(m_tableSize / 2, nullptr); }
+        void shrink() { rehash(tableSize() / 2, nullptr); }
         void shrinkToBestSize();
 
         void deleteReleasedWeakBuckets();
 
         ValueType* rehash(unsigned newTableSize, ValueType* entry);
@@ -517,16 +564,16 @@
         static void deleteBucket(ValueType& bucket) { hashTraitsDeleteBucket<Traits>(bucket); }
 
         FullLookupType makeLookupResult(ValueType* position, bool found, unsigned hash)
             { return FullLookupType(LookupType(position, found), hash); }
 
-        iterator makeIterator(ValueType* pos) { return iterator(this, pos, m_table + m_tableSize); }
-        const_iterator makeConstIterator(ValueType* pos) const { return const_iterator(this, pos, m_table + m_tableSize); }
-        iterator makeKnownGoodIterator(ValueType* pos) { return iterator(this, pos, m_table + m_tableSize, HashItemKnownGood); }
-        const_iterator makeKnownGoodConstIterator(ValueType* pos) const { return const_iterator(this, pos, m_table + m_tableSize, HashItemKnownGood); }
+        iterator makeIterator(ValueType* pos) { return iterator(this, pos, m_table + tableSize()); }
+        const_iterator makeConstIterator(ValueType* pos) const { return const_iterator(this, pos, m_table + tableSize()); }
+        iterator makeKnownGoodIterator(ValueType* pos) { return iterator(this, pos, m_table + tableSize(), HashItemKnownGood); }
+        const_iterator makeKnownGoodConstIterator(ValueType* pos) const { return const_iterator(this, pos, m_table + tableSize(), HashItemKnownGood); }
 
-#if !ASSERT_DISABLED
+#if ASSERT_ENABLED
         void checkTableConsistencyExceptSize() const;
 #else
         static void checkTableConsistencyExceptSize() { }
 #endif
 
@@ -534,18 +581,35 @@
         void invalidateIterators();
 #else
         static void invalidateIterators() { }
 #endif
 
-        static const unsigned m_maxLoad = 2;
-        static const unsigned m_minLoad = 6;
-
-        ValueType* m_table;
-        unsigned m_tableSize;
-        unsigned m_tableSizeMask;
-        unsigned m_keyCount;
-        unsigned m_deletedCount;
+        // Load-factor for small table is 75%.
+        static constexpr unsigned smallMaxLoadNumerator = HashTableSizePolicy::smallMaxLoadNumerator;
+        static constexpr unsigned smallMaxLoadDenominator = HashTableSizePolicy::smallMaxLoadDenominator;
+        // Load-factor for large table is 50%.
+        static constexpr unsigned largeMaxLoadNumerator = HashTableSizePolicy::largeMaxLoadNumerator;
+        static constexpr unsigned largeMaxLoadDenominator = HashTableSizePolicy::largeMaxLoadDenominator;
+        static constexpr unsigned maxSmallTableCapacity = HashTableSizePolicy::maxSmallTableCapacity;
+        static constexpr unsigned minLoad = HashTableSizePolicy::minLoad;
+
+        static constexpr int tableSizeOffset = -1;
+        static constexpr int tableSizeMaskOffset = -2;
+        static constexpr int keyCountOffset = -3;
+        static constexpr int deletedCountOffset = -4;
+        static constexpr unsigned metadataSize = 4 * sizeof(unsigned);
+
+        unsigned tableSize() const { return m_table ? reinterpret_cast_ptr<unsigned*>(m_table)[tableSizeOffset] : 0; }
+        void setTableSize(unsigned size) const { ASSERT(m_table); reinterpret_cast_ptr<unsigned*>(m_table)[tableSizeOffset] = size; }
+        unsigned tableSizeMask() const { ASSERT(m_table); return m_table ? reinterpret_cast_ptr<unsigned*>(m_table)[tableSizeMaskOffset] : 0; }
+        void setTableSizeMask(unsigned mask) { ASSERT(m_table); reinterpret_cast_ptr<unsigned*>(m_table)[tableSizeMaskOffset] = mask; }
+        unsigned keyCount() const { return m_table ? reinterpret_cast_ptr<unsigned*>(m_table)[keyCountOffset] : 0; }
+        void setKeyCount(unsigned count) const { ASSERT(m_table); reinterpret_cast_ptr<unsigned*>(m_table)[keyCountOffset] = count; }
+        unsigned deletedCount() const { ASSERT(m_table); return reinterpret_cast_ptr<unsigned*>(m_table)[deletedCountOffset]; }
+        void setDeletedCount(unsigned count) const { ASSERT(m_table); reinterpret_cast_ptr<unsigned*>(m_table)[deletedCountOffset] = count; }
+
+        ValueType* m_table { nullptr };
 
 #if CHECK_HASHTABLE_ITERATORS
     public:
         // All access to m_iterators should be guarded with m_mutex.
         mutable const_iterator* m_iterators;
@@ -557,55 +621,13 @@
     public:
         mutable std::unique_ptr<Stats> m_stats;
 #endif
     };
 
-    // Set all the bits to one after the most significant bit: 00110101010 -> 00111111111.
-    template<unsigned size> struct OneifyLowBits;
-    template<>
-    struct OneifyLowBits<0> {
-        static const unsigned value = 0;
-    };
-    template<unsigned number>
-    struct OneifyLowBits {
-        static const unsigned value = number | OneifyLowBits<(number >> 1)>::value;
-    };
-    // Compute the first power of two integer that is an upper bound of the parameter 'number'.
-    template<unsigned number>
-    struct UpperPowerOfTwoBound {
-        static const unsigned value = (OneifyLowBits<number - 1>::value + 1) * 2;
-    };
-
-    // Because power of two numbers are the limit of maxLoad, their capacity is twice the
-    // UpperPowerOfTwoBound, or 4 times their values.
-    template<unsigned size, bool isPowerOfTwo> struct HashTableCapacityForSizeSplitter;
-    template<unsigned size>
-    struct HashTableCapacityForSizeSplitter<size, true> {
-        static const unsigned value = size * 4;
-    };
-    template<unsigned size>
-    struct HashTableCapacityForSizeSplitter<size, false> {
-        static const unsigned value = UpperPowerOfTwoBound<size>::value;
-    };
-
-    // HashTableCapacityForSize computes the upper power of two capacity to hold the size parameter.
-    // This is done at compile time to initialize the HashTraits.
-    template<unsigned size>
-    struct HashTableCapacityForSize {
-        static const unsigned value = HashTableCapacityForSizeSplitter<size, !(size & (size - 1))>::value;
-        COMPILE_ASSERT(size > 0, HashTableNonZeroMinimumCapacity);
-        COMPILE_ASSERT(!static_cast<unsigned>(value >> 31), HashTableNoCapacityOverflow);
-        COMPILE_ASSERT(value > (2 * size), HashTableCapacityHoldsContentSize);
-    };
-
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
     inline HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::HashTable()
-        : m_table(0)
-        , m_tableSize(0)
-        , m_tableSizeMask(0)
-        , m_keyCount(0)
-        , m_deletedCount(0)
+        : m_table(nullptr)
 #if CHECK_HASHTABLE_ITERATORS
         , m_iterators(0)
         , m_mutex(makeUnique<Lock>())
 #endif
 #if DUMP_HASHTABLE_STATS_PER_TABLE
@@ -622,19 +644,19 @@
         key ^= (key << 2);
         key ^= (key >> 20);
         return key;
     }
 
-#if ASSERT_DISABLED
+#if !ASSERT_ENABLED
 
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
     template<typename HashTranslator, typename T>
     inline void HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::checkKey(const T&)
     {
     }
 
-#else
+#else // ASSERT_ENABLED
 
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
     template<typename HashTranslator, typename T>
     void HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::checkKey(const T& key)
     {
@@ -646,11 +668,11 @@
         ValueType& deletedValue = *deletedValuePtr;
         Traits::constructDeletedValue(deletedValue);
         ASSERT(!HashTranslator::equal(Extractor::extract(deletedValue), key));
     }
 
-#endif
+#endif // ASSERT_ENABLED
 
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
     template<typename HashTranslator, typename T>
     inline auto HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::lookup(const T& key) -> ValueType*
     {
@@ -662,18 +684,18 @@
     ALWAYS_INLINE auto HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::inlineLookup(const T& key) -> ValueType*
     {
         checkKey<HashTranslator>(key);
 
         unsigned k = 0;
-        unsigned sizeMask = m_tableSizeMask;
         ValueType* table = m_table;
+        if (!table)
+            return nullptr;
+
+        unsigned sizeMask = tableSizeMask();
         unsigned h = HashTranslator::hash(key);
         unsigned i = h & sizeMask;
 
-        if (!table)
-            return 0;
-
 #if DUMP_HASHTABLE_STATS
         ++HashTableStats::numAccesses;
         unsigned probeCount = 0;
 #endif
 
@@ -720,11 +742,11 @@
         ASSERT(m_table);
         checkKey<HashTranslator>(key);
 
         unsigned k = 0;
         ValueType* table = m_table;
-        unsigned sizeMask = m_tableSizeMask;
+        unsigned sizeMask = tableSizeMask();
         unsigned h = HashTranslator::hash(key);
         unsigned i = h & sizeMask;
 
 #if DUMP_HASHTABLE_STATS
         ++HashTableStats::numAccesses;
@@ -781,11 +803,11 @@
         ASSERT(m_table);
         checkKey<HashTranslator>(key);
 
         unsigned k = 0;
         ValueType* table = m_table;
-        unsigned sizeMask = m_tableSizeMask;
+        unsigned sizeMask = tableSizeMask();
         unsigned h = HashTranslator::hash(key);
         unsigned i = h & sizeMask;
 
 #if DUMP_HASHTABLE_STATS
         ++HashTableStats::numAccesses;
@@ -847,11 +869,11 @@
 
         internalCheckTableConsistency();
 
         unsigned k = 0;
         ValueType* table = m_table;
-        unsigned sizeMask = m_tableSizeMask;
+        unsigned sizeMask = tableSizeMask();
         unsigned h = HashTranslator::hash(key);
         unsigned i = h & sizeMask;
 
 #if DUMP_HASHTABLE_STATS
         ++HashTableStats::numAccesses;
@@ -928,11 +950,11 @@
 
         ASSERT(m_table);
 
         unsigned k = 0;
         ValueType* table = m_table;
-        unsigned sizeMask = m_tableSizeMask;
+        unsigned sizeMask = tableSizeMask();
         unsigned h = HashTranslator::hash(key);
         unsigned i = h & sizeMask;
 
 #if DUMP_HASHTABLE_STATS
         ++HashTableStats::numAccesses;
@@ -982,15 +1004,15 @@
         }
 
         if (deletedEntry) {
             initializeBucket(*deletedEntry);
             entry = deletedEntry;
-            --m_deletedCount;
+            setDeletedCount(deletedCount() - 1);
         }
 
         HashTranslator::translate(*entry, std::forward<T>(key), std::forward<Extra>(extra));
-        ++m_keyCount;
+        setKeyCount(keyCount() + 1);
 
         if (shouldExpand())
             entry = expand(entry);
 
         internalCheckTableConsistency();
@@ -1020,15 +1042,15 @@
         if (found)
             return AddResult(makeKnownGoodIterator(entry), false);
 
         if (isDeletedBucket(*entry)) {
             initializeBucket(*entry);
-            --m_deletedCount;
+            setDeletedCount(deletedCount() - 1);
         }
 
         HashTranslator::translate(*entry, std::forward<T>(key), std::forward<Extra>(extra), h);
-        ++m_keyCount;
+        setKeyCount(keyCount() + 1);
 
         if (shouldExpand())
             entry = expand(entry);
 
         internalCheckTableConsistency();
@@ -1118,12 +1140,12 @@
 #if DUMP_HASHTABLE_STATS_PER_TABLE
         ++m_stats->numRemoves;
 #endif
 
         deleteBucket(*pos);
-        ++m_deletedCount;
-        --m_keyCount;
+        setDeletedCount(deletedCount() + 1);
+        setKeyCount(keyCount() - 1);
 
         if (shouldShrink())
             shrink();
 
         internalCheckTableConsistency();
@@ -1170,23 +1192,25 @@
         // make a function call, which prevents the compiler from keeping
         // the values in register.
         unsigned removedBucketCount = 0;
         ValueType* table = m_table;
 
-        for (unsigned i = m_tableSize; i--;) {
+        for (unsigned i = tableSize(); i--;) {
             ValueType& bucket = table[i];
             if (isEmptyOrDeletedBucket(bucket))
                 continue;
 
             if (!functor(bucket))
                 continue;
 
             deleteBucket(bucket);
             ++removedBucketCount;
         }
-        m_deletedCount += removedBucketCount;
-        m_keyCount -= removedBucketCount;
+        if (removedBucketCount) {
+            setDeletedCount(deletedCount() + removedBucketCount);
+            setKeyCount(keyCount() - removedBucketCount);
+        }
 
         if (shouldShrink())
             shrinkToBestSize();
 
         internalCheckTableConsistency();
@@ -1194,89 +1218,114 @@
     }
 
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
     auto HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::allocateTable(unsigned size) -> ValueType*
     {
+        static_assert(!(metadataSize % alignof(ValueType)));
+
         // would use a template member function with explicit specializations here, but
         // gcc doesn't appear to support that
         if (Traits::emptyValueIsZero)
-            return static_cast<ValueType*>(fastZeroedMalloc(size * sizeof(ValueType)));
-        ValueType* result = static_cast<ValueType*>(fastMalloc(size * sizeof(ValueType)));
+            return reinterpret_cast_ptr<ValueType*>(static_cast<char*>(HashTableMalloc::zeroedMalloc(metadataSize + size * sizeof(ValueType))) + metadataSize);
+
+        ValueType* result = reinterpret_cast_ptr<ValueType*>(static_cast<char*>(HashTableMalloc::malloc(metadataSize + size * sizeof(ValueType))) + metadataSize);
         for (unsigned i = 0; i < size; i++)
             initializeBucket(result[i]);
         return result;
     }
 
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
-    void HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::deallocateTable(ValueType* table, unsigned size)
+    void HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::deallocateTable(ValueType* table)
     {
+        unsigned size = reinterpret_cast_ptr<unsigned*>(table)[tableSizeOffset];
         for (unsigned i = 0; i < size; ++i) {
             if (!isDeletedBucket(table[i]))
                 table[i].~ValueType();
         }
-        fastFree(table);
+        HashTableMalloc::free(reinterpret_cast<char*>(table) - metadataSize);
     }
 
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
     auto HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::expand(ValueType* entry) -> ValueType*
     {
         if (KeyTraits::hasIsReleasedWeakValueFunction)
             deleteReleasedWeakBuckets();
 
         unsigned newSize;
-        if (m_tableSize == 0)
+        unsigned oldSize = tableSize();
+        if (!oldSize)
             newSize = KeyTraits::minimumTableSize;
         else if (mustRehashInPlace())
-            newSize = m_tableSize;
+            newSize = oldSize;
         else
-            newSize = m_tableSize * 2;
+            newSize = oldSize * 2;
 
         return rehash(newSize, entry);
     }
 
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
     constexpr unsigned HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::computeBestTableSize(unsigned keyCount)
     {
-        unsigned bestTableSize = WTF::roundUpToPowerOfTwo(keyCount) * 2;
+        unsigned bestTableSize = WTF::roundUpToPowerOfTwo(keyCount);
 
-        // With maxLoad at 1/2 and minLoad at 1/6, our average load is 2/6.
-        // If we are getting halfway between 2/6 and 1/2 (past 5/12), we double the size to avoid being too close to
-        // loadMax and bring the ratio close to 2/6. This give us a load in the bounds [3/12, 5/12).
-        bool aboveThreeQuarterLoad = keyCount * 12 >= bestTableSize * 5;
-        if (aboveThreeQuarterLoad)
+        if (HashTableSizePolicy::shouldExpand(keyCount, bestTableSize))
             bestTableSize *= 2;
 
+        auto aboveThresholdForEagerExpansion = [](double loadFactor, unsigned keyCount, unsigned tableSize)
+        {
+            // Here is the rationale behind this calculation, using 3/4 load-factor.
+            // With maxLoad at 3/4 and minLoad at 1/6, our average load is 11/24.
+            // If we are getting half-way between 11/24 and 3/4, we double the size
+            // to avoid being too close to loadMax and bring the ratio close to 11/24. This
+            // give us a load in the bounds [9/24, 15/24).
+            double maxLoadRatio = loadFactor;
+            double minLoadRatio = 1.0 / minLoad;
+            double averageLoadRatio = (maxLoadRatio + minLoadRatio) / 2;
+            double halfWayBetweenAverageAndMaxLoadRatio = (averageLoadRatio + maxLoadRatio) / 2;
+            return keyCount >= tableSize * halfWayBetweenAverageAndMaxLoadRatio;
+        };
+
+        if (bestTableSize <= maxSmallTableCapacity) {
+            constexpr double smallLoadFactor = static_cast<double>(smallMaxLoadNumerator) / smallMaxLoadDenominator;
+            if (aboveThresholdForEagerExpansion(smallLoadFactor, keyCount, bestTableSize))
+                bestTableSize *= 2;
+        } else {
+            constexpr double largeLoadFactor = static_cast<double>(largeMaxLoadNumerator) / largeMaxLoadDenominator;
+            if (aboveThresholdForEagerExpansion(largeLoadFactor, keyCount, bestTableSize))
+                bestTableSize *= 2;
+        }
         unsigned minimumTableSize = KeyTraits::minimumTableSize;
         return std::max(bestTableSize, minimumTableSize);
     }
 
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
     void HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::shrinkToBestSize()
     {
         unsigned minimumTableSize = KeyTraits::minimumTableSize;
-        rehash(std::max(minimumTableSize, computeBestTableSize(m_keyCount)), nullptr);
+        rehash(std::max(minimumTableSize, computeBestTableSize(keyCount())), nullptr);
     }
 
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
     void HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::deleteReleasedWeakBuckets()
     {
-        for (unsigned i = 0; i < m_tableSize; ++i) {
+        unsigned tableSize = this->tableSize();
+        for (unsigned i = 0; i < tableSize; ++i) {
             auto& entry = m_table[i];
             if (isReleasedWeakBucket(entry)) {
                 deleteBucket(entry);
-                ++m_deletedCount;
-                --m_keyCount;
+                setDeletedCount(deletedCount() + 1);
+                setKeyCount(keyCount() - 1);
             }
         }
     }
 
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
     auto HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::rehash(unsigned newTableSize, ValueType* entry) -> ValueType*
     {
         internalCheckTableConsistencyExceptSize();
 
-        unsigned oldTableSize = m_tableSize;
+        unsigned oldTableSize = tableSize();
         ValueType* oldTable = m_table;
 
 #if DUMP_HASHTABLE_STATS
         if (oldTableSize != 0)
             ++HashTableStats::numRehashes;
@@ -1285,13 +1334,16 @@
 #if DUMP_HASHTABLE_STATS_PER_TABLE
         if (oldTableSize != 0)
             ++m_stats->numRehashes;
 #endif
 
-        m_tableSize = newTableSize;
-        m_tableSizeMask = newTableSize - 1;
+        unsigned oldKeyCount = keyCount();
         m_table = allocateTable(newTableSize);
+        setTableSize(newTableSize);
+        setTableSizeMask(newTableSize - 1);
+        setDeletedCount(0);
+        setKeyCount(oldKeyCount);
 
         Value* newEntry = nullptr;
         for (unsigned i = 0; i != oldTableSize; ++i) {
             auto& oldEntry = oldTable[i];
             if (isDeletedBucket(oldEntry)) {
@@ -1306,11 +1358,11 @@
             }
 
             if (isReleasedWeakBucket(oldEntry)) {
                 ASSERT(std::addressof(oldEntry) != entry);
                 oldEntry.~ValueType();
-                --m_keyCount;
+                setKeyCount(keyCount() - 1);
                 continue;
             }
 
             Value* reinsertedEntry = reinsert(WTFMove(oldEntry));
             oldEntry.~ValueType();
@@ -1318,13 +1370,12 @@
                 ASSERT(!newEntry);
                 newEntry = reinsertedEntry;
             }
         }
 
-        m_deletedCount = 0;
-
-        fastFree(oldTable);
+        if (oldTable)
+            HashTableMalloc::free(reinterpret_cast<char*>(oldTable) - metadataSize);
 
         internalCheckTableConsistency();
         return newEntry;
     }
 
@@ -1333,25 +1384,17 @@
     {
         invalidateIterators();
         if (!m_table)
             return;
 
-        deallocateTable(m_table, m_tableSize);
-        m_table = 0;
-        m_tableSize = 0;
-        m_tableSizeMask = 0;
-        m_keyCount = 0;
-        m_deletedCount = 0;
+        deallocateTable(m_table);
+        m_table = nullptr;
     }
 
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
     HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::HashTable(const HashTable& other)
         : m_table(nullptr)
-        , m_tableSize(0)
-        , m_tableSizeMask(0)
-        , m_keyCount(0)
-        , m_deletedCount(0)
 #if CHECK_HASHTABLE_ITERATORS
         , m_iterators(nullptr)
         , m_mutex(makeUnique<Lock>())
 #endif
 #if DUMP_HASHTABLE_STATS_PER_TABLE
@@ -1360,14 +1403,16 @@
     {
         unsigned otherKeyCount = other.size();
         if (!otherKeyCount)
             return;
 
-        m_tableSize = computeBestTableSize(otherKeyCount);
-        m_tableSizeMask = m_tableSize - 1;
-        m_keyCount = otherKeyCount;
-        m_table = allocateTable(m_tableSize);
+        unsigned bestTableSize = computeBestTableSize(otherKeyCount);
+        m_table = allocateTable(bestTableSize);
+        setTableSize(bestTableSize);
+        setTableSizeMask(bestTableSize - 1);
+        setKeyCount(otherKeyCount);
+        setDeletedCount(0);
 
         for (const auto& otherValue : other)
             addUniqueForInitialization<IdentityTranslatorType>(Extractor::extract(otherValue), otherValue);
     }
 
@@ -1376,14 +1421,10 @@
     {
         invalidateIterators();
         other.invalidateIterators();
 
         std::swap(m_table, other.m_table);
-        std::swap(m_tableSize, other.m_tableSize);
-        std::swap(m_tableSizeMask, other.m_tableSizeMask);
-        std::swap(m_keyCount, other.m_keyCount);
-        std::swap(m_deletedCount, other.m_deletedCount);
 
 #if DUMP_HASHTABLE_STATS_PER_TABLE
         m_stats.swap(other.m_stats);
 #endif
     }
@@ -1403,21 +1444,11 @@
         , m_mutex(makeUnique<Lock>())
 #endif
     {
         other.invalidateIterators();
 
-        m_table = other.m_table;
-        m_tableSize = other.m_tableSize;
-        m_tableSizeMask = other.m_tableSizeMask;
-        m_keyCount = other.m_keyCount;
-        m_deletedCount = other.m_deletedCount;
-
-        other.m_table = nullptr;
-        other.m_tableSize = 0;
-        other.m_tableSizeMask = 0;
-        other.m_keyCount = 0;
-        other.m_deletedCount = 0;
+        m_table = std::exchange(other.m_table, nullptr);
 
 #if DUMP_HASHTABLE_STATS_PER_TABLE
         m_stats = WTFMove(other.m_stats);
         other.m_stats = nullptr;
 #endif
@@ -1429,11 +1460,11 @@
         HashTable temp = WTFMove(other);
         swap(temp);
         return *this;
     }
 
-#if !ASSERT_DISABLED
+#if ASSERT_ENABLED
 
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
     void HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::checkTableConsistency() const
     {
         checkTableConsistencyExceptSize();
@@ -1447,11 +1478,12 @@
         if (!m_table)
             return;
 
         unsigned count = 0;
         unsigned deletedCount = 0;
-        for (unsigned j = 0; j < m_tableSize; ++j) {
+        unsigned tableSize = this->tableSize();
+        for (unsigned j = 0; j < tableSize; ++j) {
             ValueType* entry = m_table + j;
             if (isEmptyBucket(*entry))
                 continue;
 
             if (isDeletedBucket(*entry)) {
@@ -1465,18 +1497,18 @@
             ++count;
 
             ValueCheck<Key>::checkConsistency(key);
         }
 
-        ASSERT(count == m_keyCount);
-        ASSERT(deletedCount == m_deletedCount);
-        ASSERT(m_tableSize >= KeyTraits::minimumTableSize);
-        ASSERT(m_tableSizeMask);
-        ASSERT(m_tableSize == m_tableSizeMask + 1);
+        ASSERT(count == keyCount());
+        ASSERT(deletedCount == this->deletedCount());
+        ASSERT(this->tableSize() >= KeyTraits::minimumTableSize);
+        ASSERT(tableSizeMask());
+        ASSERT(this->tableSize() == tableSizeMask() + 1);
     }
 
-#endif // ASSERT_DISABLED
+#endif // ASSERT_ENABLED
 
 #if CHECK_HASHTABLE_ITERATORS
 
     template<typename Key, typename Value, typename Extractor, typename HashFunctions, typename Traits, typename KeyTraits>
     void HashTable<Key, Value, Extractor, HashFunctions, Traits, KeyTraits>::invalidateIterators()
