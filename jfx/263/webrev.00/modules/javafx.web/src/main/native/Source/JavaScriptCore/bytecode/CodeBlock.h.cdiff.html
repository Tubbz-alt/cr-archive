<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/bytecode/CodeBlock.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="CodeBlock.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="CodeBlockHash.cpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/bytecode/CodeBlock.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 81,10 ***</span>
<span class="line-new-header">--- 81,12 ---</span>
  namespace DFG {
  struct OSRExitState;
  } // namespace DFG
  #endif
  
<span class="line-added">+ class UnaryArithProfile;</span>
<span class="line-added">+ class BinaryArithProfile;</span>
  class BytecodeLivenessAnalysis;
  class CodeBlockSet;
  class ExecutableToCodeBlockEdge;
  class JSModuleEnvironment;
  class LLIntOffsetsExtractor;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 92,13 ***</span>
  class MetadataTable;
  class PCToCodeOriginMap;
  class RegisterAtOffsetList;
  class StructureStubInfo;
  
  enum class AccessType : int8_t;
  
<span class="line-removed">- struct ArithProfile;</span>
  struct OpCatch;
  
  enum ReoptimizationMode { DontCountReoptimization, CountReoptimization };
  
  class CodeBlock : public JSCell {
<span class="line-new-header">--- 94,14 ---</span>
  class MetadataTable;
  class PCToCodeOriginMap;
  class RegisterAtOffsetList;
  class StructureStubInfo;
  
<span class="line-added">+ DECLARE_ALLOCATOR_WITH_HEAP_IDENTIFIER(CodeBlockRareData);</span>
<span class="line-added">+ </span>
  enum class AccessType : int8_t;
  
  struct OpCatch;
  
  enum ReoptimizationMode { DontCountReoptimization, CountReoptimization };
  
  class CodeBlock : public JSCell {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 109,15 ***</span>
  
  public:
  
      enum CopyParsedBlockTag { CopyParsedBlock };
  
<span class="line-modified">!     static const unsigned StructureFlags = Base::StructureFlags | StructureIsImmortal;</span>
<span class="line-modified">!     static const bool needsDestruction = true;</span>
  
      template&lt;typename, SubspaceAccess&gt;
<span class="line-modified">!     static IsoSubspace* subspaceFor(VM&amp;) { return nullptr; }</span>
  
      DECLARE_INFO;
  
  protected:
      CodeBlock(VM&amp;, Structure*, CopyParsedBlockTag, CodeBlock&amp; other);
<span class="line-new-header">--- 112,20 ---</span>
  
  public:
  
      enum CopyParsedBlockTag { CopyParsedBlock };
  
<span class="line-modified">!     static constexpr unsigned StructureFlags = Base::StructureFlags | StructureIsImmortal;</span>
<span class="line-modified">!     static constexpr bool needsDestruction = true;</span>
  
      template&lt;typename, SubspaceAccess&gt;
<span class="line-modified">!     static void subspaceFor(VM&amp;)</span>
<span class="line-added">+     {</span>
<span class="line-added">+         RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-added">+     }</span>
<span class="line-added">+     // GC strongly assumes CodeBlock is not a PreciseAllocation for now.</span>
<span class="line-added">+     static constexpr uint8_t numberOfLowerTierCells = 0;</span>
  
      DECLARE_INFO;
  
  protected:
      CodeBlock(VM&amp;, Structure*, CopyParsedBlockTag, CodeBlock&amp; other);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 153,10 ***</span>
<span class="line-new-header">--- 161,11 ---</span>
      int numberOfArgumentsToSkip() const { return m_numberOfArgumentsToSkip; }
  
      int numCalleeLocals() const { return m_numCalleeLocals; }
  
      int numVars() const { return m_numVars; }
<span class="line-added">+     int numTmps() const { return m_unlinkedCode-&gt;hasCheckpoints() * maxNumCheckpointTmps; }</span>
  
      int* addressOfNumParameters() { return &amp;m_numParameters; }
      static ptrdiff_t offsetOfNumParameters() { return OBJECT_OFFSETOF(CodeBlock, m_numParameters); }
  
      CodeBlock* alternative() const { return static_cast&lt;CodeBlock*&gt;(m_alternative.get()); }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 221,36 ***</span>
      JSParserScriptMode scriptMode() const { return m_unlinkedCode-&gt;scriptMode(); }
  
      bool hasInstalledVMTrapBreakpoints() const;
      bool installVMTrapBreakpoints();
  
<span class="line-modified">!     inline bool isKnownNotImmediate(int index)</span>
      {
<span class="line-modified">!         if (index == thisRegister().offset() &amp;&amp; !isStrictMode())</span>
              return true;
  
<span class="line-modified">!         if (isConstantRegisterIndex(index))</span>
<span class="line-modified">!             return getConstant(index).isCell();</span>
  
          return false;
      }
  
<span class="line-modified">!     ALWAYS_INLINE bool isTemporaryRegisterIndex(int index)</span>
      {
<span class="line-modified">!         return index &gt;= m_numVars;</span>
      }
  
<span class="line-modified">!     HandlerInfo* handlerForBytecodeOffset(unsigned bytecodeOffset, RequiredHandler = RequiredHandler::AnyHandler);</span>
      HandlerInfo* handlerForIndex(unsigned, RequiredHandler = RequiredHandler::AnyHandler);
      void removeExceptionHandlerForCallSite(DisposableCallSiteIndex);
<span class="line-modified">!     unsigned lineNumberForBytecodeOffset(unsigned bytecodeOffset);</span>
<span class="line-modified">!     unsigned columnNumberForBytecodeOffset(unsigned bytecodeOffset);</span>
<span class="line-modified">!     void expressionRangeForBytecodeOffset(unsigned bytecodeOffset, int&amp; divot,</span>
          int&amp; startOffset, int&amp; endOffset, unsigned&amp; line, unsigned&amp; column) const;
  
<span class="line-modified">!     Optional&lt;unsigned&gt; bytecodeOffsetFromCallSiteIndex(CallSiteIndex);</span>
  
      void getICStatusMap(const ConcurrentJSLocker&amp;, ICStatusMap&amp; result);
      void getICStatusMap(ICStatusMap&amp; result);
  
  #if ENABLE(JIT)
      struct JITData {
<span class="line-new-header">--- 230,41 ---</span>
      JSParserScriptMode scriptMode() const { return m_unlinkedCode-&gt;scriptMode(); }
  
      bool hasInstalledVMTrapBreakpoints() const;
      bool installVMTrapBreakpoints();
  
<span class="line-modified">!     inline bool isKnownNotImmediate(VirtualRegister reg)</span>
      {
<span class="line-modified">!         if (reg == thisRegister() &amp;&amp; !isStrictMode())</span>
              return true;
  
<span class="line-modified">!         if (reg.isConstant())</span>
<span class="line-modified">!             return getConstant(reg).isCell();</span>
  
          return false;
      }
  
<span class="line-modified">!     ALWAYS_INLINE bool isTemporaryRegister(VirtualRegister reg)</span>
      {
<span class="line-modified">!         return reg.offset() &gt;= m_numVars;</span>
      }
  
<span class="line-modified">!     HandlerInfo* handlerForBytecodeIndex(BytecodeIndex, RequiredHandler = RequiredHandler::AnyHandler);</span>
      HandlerInfo* handlerForIndex(unsigned, RequiredHandler = RequiredHandler::AnyHandler);
      void removeExceptionHandlerForCallSite(DisposableCallSiteIndex);
<span class="line-modified">!     unsigned lineNumberForBytecodeIndex(BytecodeIndex);</span>
<span class="line-modified">!     unsigned columnNumberForBytecodeIndex(BytecodeIndex);</span>
<span class="line-modified">!     void expressionRangeForBytecodeIndex(BytecodeIndex, int&amp; divot,</span>
          int&amp; startOffset, int&amp; endOffset, unsigned&amp; line, unsigned&amp; column) const;
  
<span class="line-modified">!     Optional&lt;BytecodeIndex&gt; bytecodeIndexFromCallSiteIndex(CallSiteIndex);</span>
  
<span class="line-added">+     // Because we might throw out baseline JIT code and all its baseline JIT data (m_jitData),</span>
<span class="line-added">+     // you need to be careful about the lifetime of when you use the return value of this function.</span>
<span class="line-added">+     // The return value may have raw pointers into this data structure that gets thrown away.</span>
<span class="line-added">+     // Specifically, you need to ensure that no GC can be finalized (typically that means no</span>
<span class="line-added">+     // allocations) between calling this and the last use of it.</span>
      void getICStatusMap(const ConcurrentJSLocker&amp;, ICStatusMap&amp; result);
      void getICStatusMap(ICStatusMap&amp; result);
  
  #if ENABLE(JIT)
      struct JITData {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 263,11 ***</span>
          Bag&lt;JITSubIC&gt; m_subICs;
          Bag&lt;ByValInfo&gt; m_byValInfos;
          Bag&lt;CallLinkInfo&gt; m_callLinkInfos;
          SentinelLinkedList&lt;CallLinkInfo, PackedRawSentinelNode&lt;CallLinkInfo&gt;&gt; m_incomingCalls;
          SentinelLinkedList&lt;PolymorphicCallNode, PackedRawSentinelNode&lt;PolymorphicCallNode&gt;&gt; m_incomingPolymorphicCalls;
<span class="line-modified">!         SegmentedVector&lt;RareCaseProfile, 8&gt; m_rareCaseProfiles;</span>
          std::unique_ptr&lt;PCToCodeOriginMap&gt; m_pcToCodeOriginMap;
          std::unique_ptr&lt;RegisterAtOffsetList&gt; m_calleeSaveRegisters;
          JITCodeMap m_jitCodeMap;
      };
  
<span class="line-new-header">--- 277,11 ---</span>
          Bag&lt;JITSubIC&gt; m_subICs;
          Bag&lt;ByValInfo&gt; m_byValInfos;
          Bag&lt;CallLinkInfo&gt; m_callLinkInfos;
          SentinelLinkedList&lt;CallLinkInfo, PackedRawSentinelNode&lt;CallLinkInfo&gt;&gt; m_incomingCalls;
          SentinelLinkedList&lt;PolymorphicCallNode, PackedRawSentinelNode&lt;PolymorphicCallNode&gt;&gt; m_incomingPolymorphicCalls;
<span class="line-modified">!         RefCountedArray&lt;RareCaseProfile&gt; m_rareCaseProfiles;</span>
          std::unique_ptr&lt;PCToCodeOriginMap&gt; m_pcToCodeOriginMap;
          std::unique_ptr&lt;RegisterAtOffsetList&gt; m_calleeSaveRegisters;
          JITCodeMap m_jitCodeMap;
      };
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 277,26 ***</span>
              return *m_jitData;
          return ensureJITDataSlow(locker);
      }
      JITData&amp; ensureJITDataSlow(const ConcurrentJSLocker&amp;);
  
<span class="line-modified">!     JITAddIC* addJITAddIC(ArithProfile*);</span>
<span class="line-modified">!     JITMulIC* addJITMulIC(ArithProfile*);</span>
<span class="line-modified">!     JITNegIC* addJITNegIC(ArithProfile*);</span>
<span class="line-modified">!     JITSubIC* addJITSubIC(ArithProfile*);</span>
  
      template &lt;typename Generator, typename = typename std::enable_if&lt;std::is_same&lt;Generator, JITAddGenerator&gt;::value&gt;::type&gt;
<span class="line-modified">!     JITAddIC* addMathIC(ArithProfile* profile) { return addJITAddIC(profile); }</span>
  
      template &lt;typename Generator, typename = typename std::enable_if&lt;std::is_same&lt;Generator, JITMulGenerator&gt;::value&gt;::type&gt;
<span class="line-modified">!     JITMulIC* addMathIC(ArithProfile* profile) { return addJITMulIC(profile); }</span>
  
      template &lt;typename Generator, typename = typename std::enable_if&lt;std::is_same&lt;Generator, JITNegGenerator&gt;::value&gt;::type&gt;
<span class="line-modified">!     JITNegIC* addMathIC(ArithProfile* profile) { return addJITNegIC(profile); }</span>
  
      template &lt;typename Generator, typename = typename std::enable_if&lt;std::is_same&lt;Generator, JITSubGenerator&gt;::value&gt;::type&gt;
<span class="line-modified">!     JITSubIC* addMathIC(ArithProfile* profile) { return addJITSubIC(profile); }</span>
  
      StructureStubInfo* addStubInfo(AccessType);
  
      // O(n) operation. Use getStubInfoMap() unless you really only intend to get one
      // stub info.
<span class="line-new-header">--- 291,26 ---</span>
              return *m_jitData;
          return ensureJITDataSlow(locker);
      }
      JITData&amp; ensureJITDataSlow(const ConcurrentJSLocker&amp;);
  
<span class="line-modified">!     JITAddIC* addJITAddIC(BinaryArithProfile*);</span>
<span class="line-modified">!     JITMulIC* addJITMulIC(BinaryArithProfile*);</span>
<span class="line-modified">!     JITNegIC* addJITNegIC(UnaryArithProfile*);</span>
<span class="line-modified">!     JITSubIC* addJITSubIC(BinaryArithProfile*);</span>
  
      template &lt;typename Generator, typename = typename std::enable_if&lt;std::is_same&lt;Generator, JITAddGenerator&gt;::value&gt;::type&gt;
<span class="line-modified">!     JITAddIC* addMathIC(BinaryArithProfile* profile) { return addJITAddIC(profile); }</span>
  
      template &lt;typename Generator, typename = typename std::enable_if&lt;std::is_same&lt;Generator, JITMulGenerator&gt;::value&gt;::type&gt;
<span class="line-modified">!     JITMulIC* addMathIC(BinaryArithProfile* profile) { return addJITMulIC(profile); }</span>
  
      template &lt;typename Generator, typename = typename std::enable_if&lt;std::is_same&lt;Generator, JITNegGenerator&gt;::value&gt;::type&gt;
<span class="line-modified">!     JITNegIC* addMathIC(UnaryArithProfile* profile) { return addJITNegIC(profile); }</span>
  
      template &lt;typename Generator, typename = typename std::enable_if&lt;std::is_same&lt;Generator, JITSubGenerator&gt;::value&gt;::type&gt;
<span class="line-modified">!     JITSubIC* addMathIC(BinaryArithProfile* profile) { return addJITSubIC(profile); }</span>
  
      StructureStubInfo* addStubInfo(AccessType);
  
      // O(n) operation. Use getStubInfoMap() unless you really only intend to get one
      // stub info.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 307,11 ***</span>
      CallLinkInfo* addCallLinkInfo();
  
      // This is a slow function call used primarily for compiling OSR exits in the case
      // that there had been inlining. Chances are if you want to use this, you&#39;re really
      // looking for a CallLinkInfoMap to amortize the cost of calling this.
<span class="line-modified">!     CallLinkInfo* getCallLinkInfoForBytecodeIndex(unsigned bytecodeIndex);</span>
  
      void setJITCodeMap(JITCodeMap&amp;&amp; jitCodeMap)
      {
          ConcurrentJSLocker locker(m_lock);
          ensureJITData(locker).m_jitCodeMap = WTFMove(jitCodeMap);
<span class="line-new-header">--- 321,11 ---</span>
      CallLinkInfo* addCallLinkInfo();
  
      // This is a slow function call used primarily for compiling OSR exits in the case
      // that there had been inlining. Chances are if you want to use this, you&#39;re really
      // looking for a CallLinkInfoMap to amortize the cost of calling this.
<span class="line-modified">!     CallLinkInfo* getCallLinkInfoForBytecodeIndex(BytecodeIndex);</span>
  
      void setJITCodeMap(JITCodeMap&amp;&amp; jitCodeMap)
      {
          ConcurrentJSLocker locker(m_lock);
          ensureJITData(locker).m_jitCodeMap = WTFMove(jitCodeMap);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 326,29 ***</span>
      Optional&lt;CodeOrigin&gt; findPC(void* pc);
  
      void setCalleeSaveRegisters(RegisterSet);
      void setCalleeSaveRegisters(std::unique_ptr&lt;RegisterAtOffsetList&gt;);
  
<span class="line-modified">!     RareCaseProfile* addRareCaseProfile(int bytecodeOffset);</span>
<span class="line-modified">!     RareCaseProfile* rareCaseProfileForBytecodeOffset(const ConcurrentJSLocker&amp;, int bytecodeOffset);</span>
<span class="line-modified">!     unsigned rareCaseProfileCountForBytecodeOffset(const ConcurrentJSLocker&amp;, int bytecodeOffset);</span>
  
<span class="line-modified">!     bool likelyToTakeSlowCase(int bytecodeOffset)</span>
      {
          if (!hasBaselineJITProfiling())
              return false;
          ConcurrentJSLocker locker(m_lock);
<span class="line-modified">!         unsigned value = rareCaseProfileCountForBytecodeOffset(locker, bytecodeOffset);</span>
          return value &gt;= Options::likelyToTakeSlowCaseMinimumCount();
      }
  
<span class="line-modified">!     bool couldTakeSlowCase(int bytecodeOffset)</span>
      {
          if (!hasBaselineJITProfiling())
              return false;
          ConcurrentJSLocker locker(m_lock);
<span class="line-modified">!         unsigned value = rareCaseProfileCountForBytecodeOffset(locker, bytecodeOffset);</span>
          return value &gt;= Options::couldTakeSlowCaseMinimumCount();
      }
  
      // We call this when we want to reattempt compiling something with the baseline JIT. Ideally
      // the baseline JIT would not add data to CodeBlock, but instead it would put its data into
<span class="line-new-header">--- 340,29 ---</span>
      Optional&lt;CodeOrigin&gt; findPC(void* pc);
  
      void setCalleeSaveRegisters(RegisterSet);
      void setCalleeSaveRegisters(std::unique_ptr&lt;RegisterAtOffsetList&gt;);
  
<span class="line-modified">!     void setRareCaseProfiles(RefCountedArray&lt;RareCaseProfile&gt;&amp;&amp;);</span>
<span class="line-modified">!     RareCaseProfile* rareCaseProfileForBytecodeIndex(const ConcurrentJSLocker&amp;, BytecodeIndex);</span>
<span class="line-modified">!     unsigned rareCaseProfileCountForBytecodeIndex(const ConcurrentJSLocker&amp;, BytecodeIndex);</span>
  
<span class="line-modified">!     bool likelyToTakeSlowCase(BytecodeIndex bytecodeIndex)</span>
      {
          if (!hasBaselineJITProfiling())
              return false;
          ConcurrentJSLocker locker(m_lock);
<span class="line-modified">!         unsigned value = rareCaseProfileCountForBytecodeIndex(locker, bytecodeIndex);</span>
          return value &gt;= Options::likelyToTakeSlowCaseMinimumCount();
      }
  
<span class="line-modified">!     bool couldTakeSlowCase(BytecodeIndex bytecodeIndex)</span>
      {
          if (!hasBaselineJITProfiling())
              return false;
          ConcurrentJSLocker locker(m_lock);
<span class="line-modified">!         unsigned value = rareCaseProfileCountForBytecodeIndex(locker, bytecodeIndex);</span>
          return value &gt;= Options::couldTakeSlowCaseMinimumCount();
      }
  
      // We call this when we want to reattempt compiling something with the baseline JIT. Ideally
      // the baseline JIT would not add data to CodeBlock, but instead it would put its data into
</pre>
<hr />
<pre>
<span class="line-old-header">*** 359,17 ***</span>
  #endif // ENABLE(JIT)
  
      void unlinkIncomingCalls();
  
  #if ENABLE(JIT)
<span class="line-modified">!     void linkIncomingCall(ExecState* callerFrame, CallLinkInfo*);</span>
<span class="line-modified">!     void linkIncomingPolymorphicCall(ExecState* callerFrame, PolymorphicCallNode*);</span>
  #endif // ENABLE(JIT)
  
<span class="line-modified">!     void linkIncomingCall(ExecState* callerFrame, LLIntCallLinkInfo*);</span>
  
      const Instruction* outOfLineJumpTarget(const Instruction* pc);
      int outOfLineJumpOffset(const Instruction* pc);
      int outOfLineJumpOffset(const InstructionStream::Ref&amp; instruction)
      {
          return outOfLineJumpOffset(instruction.ptr());
      }
<span class="line-new-header">--- 373,21 ---</span>
  #endif // ENABLE(JIT)
  
      void unlinkIncomingCalls();
  
  #if ENABLE(JIT)
<span class="line-modified">!     void linkIncomingCall(CallFrame* callerFrame, CallLinkInfo*);</span>
<span class="line-modified">!     void linkIncomingPolymorphicCall(CallFrame* callerFrame, PolymorphicCallNode*);</span>
  #endif // ENABLE(JIT)
  
<span class="line-modified">!     void linkIncomingCall(CallFrame* callerFrame, LLIntCallLinkInfo*);</span>
  
      const Instruction* outOfLineJumpTarget(const Instruction* pc);
<span class="line-added">+     int outOfLineJumpOffset(InstructionStream::Offset offset)</span>
<span class="line-added">+     {</span>
<span class="line-added">+         return m_unlinkedCode-&gt;outOfLineJumpOffset(offset);</span>
<span class="line-added">+     }</span>
      int outOfLineJumpOffset(const Instruction* pc);
      int outOfLineJumpOffset(const InstructionStream::Ref&amp; instruction)
      {
          return outOfLineJumpOffset(instruction.ptr());
      }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 380,10 ***</span>
<span class="line-new-header">--- 398,15 ---</span>
          const auto* instructionsEnd = reinterpret_cast&lt;const Instruction*&gt;(reinterpret_cast&lt;uintptr_t&gt;(instructionsBegin) + instructions().size());
          RELEASE_ASSERT(returnAddress &gt;= instructionsBegin &amp;&amp; returnAddress &lt; instructionsEnd);
          return returnAddress - instructionsBegin;
      }
  
<span class="line-added">+     inline BytecodeIndex bytecodeIndex(const Instruction* returnAddress)</span>
<span class="line-added">+     {</span>
<span class="line-added">+         return BytecodeIndex(bytecodeOffset(returnAddress));</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
      const InstructionStream&amp; instructions() const { return m_unlinkedCode-&gt;instructions(); }
  
      size_t predictedMachineCodeSize();
  
      unsigned instructionsSize() const { return instructions().size(); }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 392,11 ***</span>
      // Exactly equivalent to codeBlock-&gt;ownerExecutable()-&gt;newReplacementCodeBlockFor(codeBlock-&gt;specializationKind())
      CodeBlock* newReplacement();
  
      void setJITCode(Ref&lt;JITCode&gt;&amp;&amp; code)
      {
<span class="line-removed">-         ASSERT(heap()-&gt;isDeferred());</span>
          if (!code-&gt;isShared())
              heap()-&gt;reportExtraMemoryAllocated(code-&gt;size());
  
          ConcurrentJSLocker locker(m_lock);
          WTF::storeStoreFence(); // This is probably not needed because the lock will also do something similar, but it&#39;s good to be paranoid.
<span class="line-new-header">--- 415,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 424,10 ***</span>
<span class="line-new-header">--- 446,12 ---</span>
  
      DFG::CapabilityLevel computeCapabilityLevel();
      DFG::CapabilityLevel capabilityLevel();
      DFG::CapabilityLevel capabilityLevelState() { return static_cast&lt;DFG::CapabilityLevel&gt;(m_capabilityLevelState); }
  
<span class="line-added">+     CodeBlock* optimizedReplacement(JITType typeToReplace);</span>
<span class="line-added">+     CodeBlock* optimizedReplacement(); // the typeToReplace is my JITType</span>
      bool hasOptimizedReplacement(JITType typeToReplace);
      bool hasOptimizedReplacement(); // the typeToReplace is my JITType
  #endif
  
      void jettison(Profiler::JettisonReason, ReoptimizationMode = DontCountReoptimization, const FireDetail* = nullptr);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 481,26 ***</span>
          ASSERT(vm().canUseJIT()); // This is only called from the various JIT compilers or places that first check numberOfArgumentValueProfiles before calling this.
          ValueProfile&amp; result = m_argumentValueProfiles[argumentIndex];
          return result;
      }
  
<span class="line-modified">!     ValueProfile&amp; valueProfileForBytecodeOffset(int bytecodeOffset);</span>
<span class="line-modified">!     SpeculatedType valueProfilePredictionForBytecodeOffset(const ConcurrentJSLocker&amp;, int bytecodeOffset);</span>
  
      template&lt;typename Functor&gt; void forEachValueProfile(const Functor&amp;);
      template&lt;typename Functor&gt; void forEachArrayProfile(const Functor&amp;);
      template&lt;typename Functor&gt; void forEachArrayAllocationProfile(const Functor&amp;);
      template&lt;typename Functor&gt; void forEachObjectAllocationProfile(const Functor&amp;);
      template&lt;typename Functor&gt; void forEachLLIntCallLinkInfo(const Functor&amp;);
  
<span class="line-modified">!     ArithProfile* arithProfileForBytecodeOffset(InstructionStream::Offset bytecodeOffset);</span>
<span class="line-modified">!     ArithProfile* arithProfileForPC(const Instruction*);</span>
  
<span class="line-modified">!     bool couldTakeSpecialFastCase(InstructionStream::Offset bytecodeOffset);</span>
  
<span class="line-modified">!     ArrayProfile* getArrayProfile(const ConcurrentJSLocker&amp;, unsigned bytecodeOffset);</span>
<span class="line-modified">!     ArrayProfile* getArrayProfile(unsigned bytecodeOffset);</span>
  
      // Exception handling support
  
      size_t numberOfExceptionHandlers() const { return m_rareData ? m_rareData-&gt;m_exceptionHandlers.size() : 0; }
      HandlerInfo&amp; exceptionHandler(int index) { RELEASE_ASSERT(m_rareData); return m_rareData-&gt;m_exceptionHandlers[index]; }
<span class="line-new-header">--- 505,28 ---</span>
          ASSERT(vm().canUseJIT()); // This is only called from the various JIT compilers or places that first check numberOfArgumentValueProfiles before calling this.
          ValueProfile&amp; result = m_argumentValueProfiles[argumentIndex];
          return result;
      }
  
<span class="line-modified">!     ValueProfile&amp; valueProfileForBytecodeIndex(BytecodeIndex);</span>
<span class="line-modified">!     SpeculatedType valueProfilePredictionForBytecodeIndex(const ConcurrentJSLocker&amp;, BytecodeIndex);</span>
  
      template&lt;typename Functor&gt; void forEachValueProfile(const Functor&amp;);
      template&lt;typename Functor&gt; void forEachArrayProfile(const Functor&amp;);
      template&lt;typename Functor&gt; void forEachArrayAllocationProfile(const Functor&amp;);
      template&lt;typename Functor&gt; void forEachObjectAllocationProfile(const Functor&amp;);
      template&lt;typename Functor&gt; void forEachLLIntCallLinkInfo(const Functor&amp;);
  
<span class="line-modified">!     BinaryArithProfile* binaryArithProfileForBytecodeIndex(BytecodeIndex);</span>
<span class="line-modified">!     UnaryArithProfile* unaryArithProfileForBytecodeIndex(BytecodeIndex);</span>
<span class="line-added">+     BinaryArithProfile* binaryArithProfileForPC(const Instruction*);</span>
<span class="line-added">+     UnaryArithProfile* unaryArithProfileForPC(const Instruction*);</span>
  
<span class="line-modified">!     bool couldTakeSpecialArithFastCase(BytecodeIndex bytecodeOffset);</span>
  
<span class="line-modified">!     ArrayProfile* getArrayProfile(const ConcurrentJSLocker&amp;, BytecodeIndex);</span>
<span class="line-modified">!     ArrayProfile* getArrayProfile(BytecodeIndex);</span>
  
      // Exception handling support
  
      size_t numberOfExceptionHandlers() const { return m_rareData ? m_rareData-&gt;m_exceptionHandlers.size() : 0; }
      HandlerInfo&amp; exceptionHandler(int index) { RELEASE_ASSERT(m_rareData); return m_rareData-&gt;m_exceptionHandlers[index]; }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 544,32 ***</span>
      const Identifier&amp; identifier(int index) const { return m_unlinkedCode-&gt;identifier(index); }
  #endif
  
      Vector&lt;WriteBarrier&lt;Unknown&gt;&gt;&amp; constants() { return m_constantRegisters; }
      Vector&lt;SourceCodeRepresentation&gt;&amp; constantsSourceCodeRepresentation() { return m_constantsSourceCodeRepresentation; }
<span class="line-modified">!     unsigned addConstant(JSValue v)</span>
      {
          unsigned result = m_constantRegisters.size();
          m_constantRegisters.append(WriteBarrier&lt;Unknown&gt;());
          m_constantRegisters.last().set(*m_vm, this, v);
          m_constantsSourceCodeRepresentation.append(SourceCodeRepresentation::Other);
          return result;
      }
  
<span class="line-modified">!     unsigned addConstantLazily()</span>
      {
          unsigned result = m_constantRegisters.size();
          m_constantRegisters.append(WriteBarrier&lt;Unknown&gt;());
          m_constantsSourceCodeRepresentation.append(SourceCodeRepresentation::Other);
          return result;
      }
  
      const Vector&lt;WriteBarrier&lt;Unknown&gt;&gt;&amp; constantRegisters() { return m_constantRegisters; }
<span class="line-modified">!     WriteBarrier&lt;Unknown&gt;&amp; constantRegister(int index) { return m_constantRegisters[index - FirstConstantRegisterIndex]; }</span>
<span class="line-modified">!     static ALWAYS_INLINE bool isConstantRegisterIndex(int index) { return index &gt;= FirstConstantRegisterIndex; }</span>
<span class="line-modified">!     ALWAYS_INLINE JSValue getConstant(int index) const { return m_constantRegisters[index - FirstConstantRegisterIndex].get(); }</span>
<span class="line-removed">-     ALWAYS_INLINE SourceCodeRepresentation constantSourceCodeRepresentation(int index) const { return m_constantsSourceCodeRepresentation[index - FirstConstantRegisterIndex]; }</span>
  
      FunctionExecutable* functionDecl(int index) { return m_functionDecls[index].get(); }
      int numberOfFunctionDecls() { return m_functionDecls.size(); }
      FunctionExecutable* functionExpr(int index) { return m_functionExprs[index].get(); }
  
<span class="line-new-header">--- 570,31 ---</span>
      const Identifier&amp; identifier(int index) const { return m_unlinkedCode-&gt;identifier(index); }
  #endif
  
      Vector&lt;WriteBarrier&lt;Unknown&gt;&gt;&amp; constants() { return m_constantRegisters; }
      Vector&lt;SourceCodeRepresentation&gt;&amp; constantsSourceCodeRepresentation() { return m_constantsSourceCodeRepresentation; }
<span class="line-modified">!     unsigned addConstant(const ConcurrentJSLocker&amp;, JSValue v)</span>
      {
          unsigned result = m_constantRegisters.size();
          m_constantRegisters.append(WriteBarrier&lt;Unknown&gt;());
          m_constantRegisters.last().set(*m_vm, this, v);
          m_constantsSourceCodeRepresentation.append(SourceCodeRepresentation::Other);
          return result;
      }
  
<span class="line-modified">!     unsigned addConstantLazily(const ConcurrentJSLocker&amp;)</span>
      {
          unsigned result = m_constantRegisters.size();
          m_constantRegisters.append(WriteBarrier&lt;Unknown&gt;());
          m_constantsSourceCodeRepresentation.append(SourceCodeRepresentation::Other);
          return result;
      }
  
      const Vector&lt;WriteBarrier&lt;Unknown&gt;&gt;&amp; constantRegisters() { return m_constantRegisters; }
<span class="line-modified">!     WriteBarrier&lt;Unknown&gt;&amp; constantRegister(VirtualRegister reg) { return m_constantRegisters[reg.toConstantIndex()]; }</span>
<span class="line-modified">!     ALWAYS_INLINE JSValue getConstant(VirtualRegister reg) const { return m_constantRegisters[reg.toConstantIndex()].get(); }</span>
<span class="line-modified">!     ALWAYS_INLINE SourceCodeRepresentation constantSourceCodeRepresentation(VirtualRegister reg) const { return m_constantsSourceCodeRepresentation[reg.toConstantIndex()]; }</span>
  
      FunctionExecutable* functionDecl(int index) { return m_functionDecls[index].get(); }
      int numberOfFunctionDecls() { return m_functionDecls.size(); }
      FunctionExecutable* functionExpr(int index) { return m_functionExprs[index].get(); }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 588,11 ***</span>
      void validate();
  
      // Jump Tables
  
      size_t numberOfSwitchJumpTables() const { return m_rareData ? m_rareData-&gt;m_switchJumpTables.size() : 0; }
<span class="line-removed">-     SimpleJumpTable&amp; addSwitchJumpTable() { createRareDataIfNecessary(); m_rareData-&gt;m_switchJumpTables.append(SimpleJumpTable()); return m_rareData-&gt;m_switchJumpTables.last(); }</span>
      SimpleJumpTable&amp; switchJumpTable(int tableIndex) { RELEASE_ASSERT(m_rareData); return m_rareData-&gt;m_switchJumpTables[tableIndex]; }
      void clearSwitchJumpTables()
      {
          if (!m_rareData)
              return;
<span class="line-new-header">--- 613,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 605,25 ***</span>
          m_rareData-&gt;m_switchJumpTables.append(profiled.cloneNonJITPart());
      }
  #endif
  
      size_t numberOfStringSwitchJumpTables() const { return m_rareData ? m_rareData-&gt;m_stringSwitchJumpTables.size() : 0; }
<span class="line-removed">-     StringJumpTable&amp; addStringSwitchJumpTable() { createRareDataIfNecessary(); m_rareData-&gt;m_stringSwitchJumpTables.append(StringJumpTable()); return m_rareData-&gt;m_stringSwitchJumpTables.last(); }</span>
      StringJumpTable&amp; stringSwitchJumpTable(int tableIndex) { RELEASE_ASSERT(m_rareData); return m_rareData-&gt;m_stringSwitchJumpTables[tableIndex]; }
  
      DirectEvalCodeCache&amp; directEvalCodeCache() { createRareDataIfNecessary(); return m_rareData-&gt;m_directEvalCodeCache; }
  
<span class="line-modified">!     enum ShrinkMode {</span>
          // Shrink prior to generating machine code that may point directly into vectors.
          EarlyShrink,
  
          // Shrink after generating machine code, and after possibly creating new vectors
          // and appending to others. At this time it is not safe to shrink certain vectors
          // because we would have generated machine code that references them directly.
<span class="line-modified">!         LateShrink</span>
      };
<span class="line-modified">!     void shrinkToFit(ShrinkMode);</span>
  
      // Functions for controlling when JITting kicks in, in a mixed mode
      // execution world.
  
      bool checkIfJITThresholdReached()
<span class="line-new-header">--- 629,24 ---</span>
          m_rareData-&gt;m_switchJumpTables.append(profiled.cloneNonJITPart());
      }
  #endif
  
      size_t numberOfStringSwitchJumpTables() const { return m_rareData ? m_rareData-&gt;m_stringSwitchJumpTables.size() : 0; }
      StringJumpTable&amp; stringSwitchJumpTable(int tableIndex) { RELEASE_ASSERT(m_rareData); return m_rareData-&gt;m_stringSwitchJumpTables[tableIndex]; }
  
      DirectEvalCodeCache&amp; directEvalCodeCache() { createRareDataIfNecessary(); return m_rareData-&gt;m_directEvalCodeCache; }
  
<span class="line-modified">!     enum class ShrinkMode {</span>
          // Shrink prior to generating machine code that may point directly into vectors.
          EarlyShrink,
  
          // Shrink after generating machine code, and after possibly creating new vectors
          // and appending to others. At this time it is not safe to shrink certain vectors
          // because we would have generated machine code that references them directly.
<span class="line-modified">!         LateShrink,</span>
      };
<span class="line-modified">!     void shrinkToFit(const ConcurrentJSLocker&amp;, ShrinkMode);</span>
  
      // Functions for controlling when JITting kicks in, in a mixed mode
      // execution world.
  
      bool checkIfJITThresholdReached()
</pre>
<hr />
<pre>
<span class="line-old-header">*** 755,10 ***</span>
<span class="line-new-header">--- 778,11 ---</span>
  
      void forceOptimizationSlowPathConcurrently();
  
      void setOptimizationThresholdBasedOnCompilationResult(CompilationResult);
  
<span class="line-added">+     BytecodeIndex bytecodeIndexForExit(BytecodeIndex) const;</span>
      uint32_t osrExitCounter() const { return m_osrExitCounter; }
  
      void countOSRExit() { m_osrExitCounter++; }
  
      enum class OptimizeAction { None, ReoptimizeNow };
</pre>
<hr />
<pre>
<span class="line-old-header">*** 785,11 ***</span>
      void updateAllPredictions();
  
      unsigned frameRegisterCount();
      int stackPointerOffset();
  
<span class="line-modified">!     bool hasOpDebugForLineAndColumn(unsigned line, unsigned column);</span>
  
      bool hasDebuggerRequests() const { return m_debuggerRequests; }
      void* debuggerRequestsAddress() { return &amp;m_debuggerRequests; }
  
      void addBreakpoint(unsigned numBreakpoints);
<span class="line-new-header">--- 809,11 ---</span>
      void updateAllPredictions();
  
      unsigned frameRegisterCount();
      int stackPointerOffset();
  
<span class="line-modified">!     bool hasOpDebugForLineAndColumn(unsigned line, Optional&lt;unsigned&gt; column);</span>
  
      bool hasDebuggerRequests() const { return m_debuggerRequests; }
      void* debuggerRequestsAddress() { return &amp;m_debuggerRequests; }
  
      void addBreakpoint(unsigned numBreakpoints);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 841,25 ***</span>
  
      bool m_didFailJITCompilation : 1;
      bool m_didFailFTLCompilation : 1;
      bool m_hasBeenCompiledWithFTL : 1;
  
      // Internal methods for use by validation code. It would be private if it wasn&#39;t
      // for the fact that we use it from anonymous namespaces.
      void beginValidationDidFail();
      NO_RETURN_DUE_TO_CRASH void endValidationDidFail();
  
      struct RareData {
<span class="line-modified">!         WTF_MAKE_FAST_ALLOCATED;</span>
      public:
          Vector&lt;HandlerInfo&gt; m_exceptionHandlers;
  
          // Jump Tables
          Vector&lt;SimpleJumpTable&gt; m_switchJumpTables;
          Vector&lt;StringJumpTable&gt; m_stringSwitchJumpTables;
  
<span class="line-modified">!         Vector&lt;std::unique_ptr&lt;ValueProfileAndOperandBuffer&gt;&gt; m_catchProfiles;</span>
  
          DirectEvalCodeCache m_directEvalCodeCache;
      };
  
      void clearExceptionHandlers()
<span class="line-new-header">--- 865,28 ---</span>
  
      bool m_didFailJITCompilation : 1;
      bool m_didFailFTLCompilation : 1;
      bool m_hasBeenCompiledWithFTL : 1;
  
<span class="line-added">+     bool m_hasLinkedOSRExit : 1;</span>
<span class="line-added">+     bool m_isEligibleForLLIntDowngrade : 1;</span>
<span class="line-added">+ </span>
      // Internal methods for use by validation code. It would be private if it wasn&#39;t
      // for the fact that we use it from anonymous namespaces.
      void beginValidationDidFail();
      NO_RETURN_DUE_TO_CRASH void endValidationDidFail();
  
      struct RareData {
<span class="line-modified">!         WTF_MAKE_STRUCT_FAST_ALLOCATED_WITH_HEAP_IDENTIFIER(CodeBlockRareData);</span>
      public:
          Vector&lt;HandlerInfo&gt; m_exceptionHandlers;
  
          // Jump Tables
          Vector&lt;SimpleJumpTable&gt; m_switchJumpTables;
          Vector&lt;StringJumpTable&gt; m_stringSwitchJumpTables;
  
<span class="line-modified">!         Vector&lt;std::unique_ptr&lt;ValueProfileAndVirtualRegisterBuffer&gt;&gt; m_catchProfiles;</span>
  
          DirectEvalCodeCache m_directEvalCodeCache;
      };
  
      void clearExceptionHandlers()
</pre>
<hr />
<pre>
<span class="line-old-header">*** 874,11 ***</span>
          m_rareData-&gt;m_exceptionHandlers.append(handler);
      }
  
      DisposableCallSiteIndex newExceptionHandlingCallSiteIndex(CallSiteIndex originalCallSite);
  
<span class="line-modified">!     void ensureCatchLivenessIsComputedForBytecodeOffset(InstructionStream::Offset bytecodeOffset);</span>
  
      bool hasTailCalls() const { return m_unlinkedCode-&gt;hasTailCalls(); }
  
      template&lt;typename Metadata&gt;
      Metadata&amp; metadata(OpcodeID opcodeID, unsigned metadataID)
<span class="line-new-header">--- 901,11 ---</span>
          m_rareData-&gt;m_exceptionHandlers.append(handler);
      }
  
      DisposableCallSiteIndex newExceptionHandlingCallSiteIndex(CallSiteIndex originalCallSite);
  
<span class="line-modified">!     void ensureCatchLivenessIsComputedForBytecodeIndex(BytecodeIndex);</span>
  
      bool hasTailCalls() const { return m_unlinkedCode-&gt;hasTailCalls(); }
  
      template&lt;typename Metadata&gt;
      Metadata&amp; metadata(OpcodeID opcodeID, unsigned metadataID)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 890,10 ***</span>
<span class="line-new-header">--- 917,13 ---</span>
      size_t metadataSizeInBytes()
      {
          return m_unlinkedCode-&gt;metadataSizeInBytes();
      }
  
<span class="line-added">+     MetadataTable* metadataTable() { return m_metadata.get(); }</span>
<span class="line-added">+     const void* instructionsRawPointer() { return m_instructionsRawPointer; }</span>
<span class="line-added">+ </span>
  protected:
      void finalizeLLIntInlineCaches();
  #if ENABLE(JIT)
      void finalizeBaselineJITInlineCaches();
  #endif
</pre>
<hr />
<pre>
<span class="line-old-header">*** 909,24 ***</span>
  
      BytecodeLivenessAnalysis&amp; livenessAnalysisSlow();
  
      CodeBlock* specialOSREntryBlockOrNull();
  
<span class="line-modified">!     void noticeIncomingCall(ExecState* callerFrame);</span>
  
      double optimizationThresholdScalingFactor();
  
      void updateAllValueProfilePredictionsAndCountLiveness(unsigned&amp; numberOfLiveNonArgumentValueProfiles, unsigned&amp; numberOfSamplesInProfiles);
  
<span class="line-modified">!     void setConstantIdentifierSetRegisters(VM&amp;, const Vector&lt;ConstantIdentifierSetEntry&gt;&amp; constants);</span>
  
<span class="line-modified">!     void setConstantRegisters(const Vector&lt;WriteBarrier&lt;Unknown&gt;&gt;&amp; constants, const Vector&lt;SourceCodeRepresentation&gt;&amp; constantsSourceCodeRepresentation, ScriptExecutable* topLevelExecutable);</span>
  
<span class="line-modified">!     void replaceConstant(int index, JSValue value)</span>
      {
<span class="line-modified">!         ASSERT(isConstantRegisterIndex(index) &amp;&amp; static_cast&lt;size_t&gt;(index - FirstConstantRegisterIndex) &lt; m_constantRegisters.size());</span>
<span class="line-modified">!         m_constantRegisters[index - FirstConstantRegisterIndex].set(*m_vm, this, value);</span>
      }
  
      bool shouldVisitStrongly(const ConcurrentJSLocker&amp;);
      bool shouldJettisonDueToWeakReference(VM&amp;);
      bool shouldJettisonDueToOldAge(const ConcurrentJSLocker&amp;);
<span class="line-new-header">--- 939,24 ---</span>
  
      BytecodeLivenessAnalysis&amp; livenessAnalysisSlow();
  
      CodeBlock* specialOSREntryBlockOrNull();
  
<span class="line-modified">!     void noticeIncomingCall(CallFrame* callerFrame);</span>
  
      double optimizationThresholdScalingFactor();
  
      void updateAllValueProfilePredictionsAndCountLiveness(unsigned&amp; numberOfLiveNonArgumentValueProfiles, unsigned&amp; numberOfSamplesInProfiles);
  
<span class="line-modified">!     void setConstantIdentifierSetRegisters(VM&amp;, const RefCountedArray&lt;ConstantIdentifierSetEntry&gt;&amp; constants);</span>
  
<span class="line-modified">!     void setConstantRegisters(const RefCountedArray&lt;WriteBarrier&lt;Unknown&gt;&gt;&amp; constants, const RefCountedArray&lt;SourceCodeRepresentation&gt;&amp; constantsSourceCodeRepresentation, ScriptExecutable* topLevelExecutable);</span>
  
<span class="line-modified">!     void replaceConstant(VirtualRegister reg, JSValue value)</span>
      {
<span class="line-modified">!         ASSERT(reg.isConstant() &amp;&amp; static_cast&lt;size_t&gt;(reg.toConstantIndex()) &lt; m_constantRegisters.size());</span>
<span class="line-modified">!         m_constantRegisters[reg.toConstantIndex()].set(*m_vm, this, value);</span>
      }
  
      bool shouldVisitStrongly(const ConcurrentJSLocker&amp;);
      bool shouldJettisonDueToWeakReference(VM&amp;);
      bool shouldJettisonDueToOldAge(const ConcurrentJSLocker&amp;);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 938,11 ***</span>
      void stronglyVisitWeakReferences(const ConcurrentJSLocker&amp;, SlotVisitor&amp;);
      void visitOSRExitTargets(const ConcurrentJSLocker&amp;, SlotVisitor&amp;);
  
      unsigned numberOfNonArgumentValueProfiles() { return m_numberOfNonArgumentValueProfiles; }
      unsigned totalNumberOfValueProfiles() { return numberOfArgumentValueProfiles() + numberOfNonArgumentValueProfiles(); }
<span class="line-modified">!     ValueProfile* tryGetValueProfileForBytecodeOffset(int bytecodeOffset);</span>
  
      Seconds timeSinceCreation()
      {
          return MonotonicTime::now() - m_creationTime;
      }
<span class="line-new-header">--- 968,11 ---</span>
      void stronglyVisitWeakReferences(const ConcurrentJSLocker&amp;, SlotVisitor&amp;);
      void visitOSRExitTargets(const ConcurrentJSLocker&amp;, SlotVisitor&amp;);
  
      unsigned numberOfNonArgumentValueProfiles() { return m_numberOfNonArgumentValueProfiles; }
      unsigned totalNumberOfValueProfiles() { return numberOfArgumentValueProfiles() + numberOfNonArgumentValueProfiles(); }
<span class="line-modified">!     ValueProfile* tryGetValueProfileForBytecodeIndex(BytecodeIndex);</span>
  
      Seconds timeSinceCreation()
      {
          return MonotonicTime::now() - m_creationTime;
      }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 955,11 ***</span>
              m_rareData = WTFMove(rareData);
          }
      }
  
      void insertBasicBlockBoundariesForControlFlowProfiler();
<span class="line-modified">!     void ensureCatchLivenessIsComputedForBytecodeOffsetSlow(const OpCatch&amp;, InstructionStream::Offset);</span>
  
      int m_numCalleeLocals;
      int m_numVars;
      int m_numParameters;
      int m_numberOfArgumentsToSkip { 0 };
<span class="line-new-header">--- 985,11 ---</span>
              m_rareData = WTFMove(rareData);
          }
      }
  
      void insertBasicBlockBoundariesForControlFlowProfiler();
<span class="line-modified">!     void ensureCatchLivenessIsComputedForBytecodeIndexSlow(const OpCatch&amp;, BytecodeIndex);</span>
  
      int m_numCalleeLocals;
      int m_numVars;
      int m_numParameters;
      int m_numberOfArgumentsToSkip { 0 };
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1022,34 ***</span>
      double m_previousCounter { 0 };
  
      std::unique_ptr&lt;RareData&gt; m_rareData;
  };
  
<span class="line-removed">- inline Register&amp; ExecState::r(int index)</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     CodeBlock* codeBlock = this-&gt;codeBlock();</span>
<span class="line-removed">-     if (codeBlock-&gt;isConstantRegisterIndex(index))</span>
<span class="line-removed">-         return *reinterpret_cast&lt;Register*&gt;(&amp;codeBlock-&gt;constantRegister(index));</span>
<span class="line-removed">-     return this[index];</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- inline Register&amp; ExecState::r(VirtualRegister reg)</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     return r(reg.offset());</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- inline Register&amp; ExecState::uncheckedR(int index)</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     RELEASE_ASSERT(index &lt; FirstConstantRegisterIndex);</span>
<span class="line-removed">-     return this[index];</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- inline Register&amp; ExecState::uncheckedR(VirtualRegister reg)</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     return uncheckedR(reg.offset());</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
  template &lt;typename ExecutableType&gt;
  Exception* ScriptExecutable::prepareForExecution(VM&amp; vm, JSFunction* function, JSScope* scope, CodeSpecializationKind kind, CodeBlock*&amp; resultCodeBlock)
  {
      if (hasJITCodeFor(kind)) {
          if (std::is_same&lt;ExecutableType, EvalExecutable&gt;::value)
<span class="line-new-header">--- 1052,10 ---</span>
</pre>
<center><a href="CodeBlock.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="CodeBlockHash.cpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>