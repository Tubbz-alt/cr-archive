<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerARM64.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="MacroAssembler.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="MacroAssemblerARM64E.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerARM64.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (C) 2012-2018 Apple Inc. All rights reserved.</span>
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #pragma once
  27 
  28 #if ENABLE(ASSEMBLER)
  29 
  30 #include &quot;ARM64Assembler.h&quot;
  31 #include &quot;AbstractMacroAssembler.h&quot;
  32 #include &lt;wtf/MathExtras.h&gt;
  33 #include &lt;wtf/Optional.h&gt;
  34 
  35 namespace JSC {
  36 
  37 using Assembler = TARGET_ASSEMBLER;

  38 
  39 class MacroAssemblerARM64 : public AbstractMacroAssembler&lt;Assembler&gt; {
  40 public:
<span class="line-modified">  41     static const unsigned numGPRs = 32;</span>
<span class="line-modified">  42     static const unsigned numFPRs = 32;</span>
  43 
  44     static constexpr RegisterID dataTempRegister = ARM64Registers::ip0;
  45     static constexpr RegisterID memoryTempRegister = ARM64Registers::ip1;
  46 
  47     RegisterID scratchRegister()
  48     {
  49         RELEASE_ASSERT(m_allowScratchRegister);
  50         return getCachedDataTempRegisterIDAndInvalidate();
  51     }
  52 
  53 protected:
<span class="line-modified">  54     static const ARM64Registers::FPRegisterID fpTempRegister = ARM64Registers::q31;</span>
<span class="line-modified">  55     static const Assembler::SetFlags S = Assembler::S;</span>
<span class="line-modified">  56     static const int64_t maskHalfWord0 = 0xffffl;</span>
<span class="line-modified">  57     static const int64_t maskHalfWord1 = 0xffff0000l;</span>
<span class="line-modified">  58     static const int64_t maskUpperWord = 0xffffffff00000000l;</span>
  59 
  60     static constexpr size_t INSTRUCTION_SIZE = 4;
  61 
  62     // N instructions to load the pointer + 1 call instruction.
  63     static constexpr ptrdiff_t REPATCH_OFFSET_CALL_TO_POINTER = -((Assembler::MAX_POINTER_BITS / 16 + 1) * INSTRUCTION_SIZE);
  64 
  65 public:
  66     MacroAssemblerARM64()
  67         : m_dataMemoryTempRegister(this, dataTempRegister)
  68         , m_cachedMemoryTempRegister(this, memoryTempRegister)
  69         , m_makeJumpPatchable(false)
  70     {
  71     }
  72 
  73     typedef Assembler::LinkRecord LinkRecord;
  74     typedef Assembler::JumpType JumpType;
  75     typedef Assembler::JumpLinkType JumpLinkType;
  76     typedef Assembler::Condition Condition;
  77 
<span class="line-modified">  78     static const Assembler::Condition DefaultCondition = Assembler::ConditionInvalid;</span>
<span class="line-modified">  79     static const Assembler::JumpType DefaultJump = Assembler::JumpNoConditionFixedSize;</span>
  80 
  81     Vector&lt;LinkRecord, 0, UnsafeVectorOverflow&gt;&amp; jumpsToLink() { return m_assembler.jumpsToLink(); }
  82     static bool canCompact(JumpType jumpType) { return Assembler::canCompact(jumpType); }
  83     static JumpLinkType computeJumpType(JumpType jumpType, const uint8_t* from, const uint8_t* to) { return Assembler::computeJumpType(jumpType, from, to); }
  84     static JumpLinkType computeJumpType(LinkRecord&amp; record, const uint8_t* from, const uint8_t* to) { return Assembler::computeJumpType(record, from, to); }
  85     static int jumpSizeDelta(JumpType jumpType, JumpLinkType jumpLinkType) { return Assembler::jumpSizeDelta(jumpType, jumpLinkType); }
<span class="line-modified">  86     template &lt;typename CopyFunction&gt;</span>
<span class="line-modified">  87     static void link(LinkRecord&amp; record, uint8_t* from, const uint8_t* fromInstruction, uint8_t* to, CopyFunction copy) { return Assembler::link(record, from, fromInstruction, to, copy); }</span>
  88 
<span class="line-modified">  89     static const Scale ScalePtr = TimesEight;</span>
  90 
  91     static bool isCompactPtrAlignedAddressOffset(ptrdiff_t value)
  92     {
  93         // This is the largest 32-bit access allowed, aligned to 64-bit boundary.
  94         return !(value &amp; ~0x3ff8);
  95     }
  96 
  97     enum RelationalCondition {
  98         Equal = Assembler::ConditionEQ,
  99         NotEqual = Assembler::ConditionNE,
 100         Above = Assembler::ConditionHI,
 101         AboveOrEqual = Assembler::ConditionHS,
 102         Below = Assembler::ConditionLO,
 103         BelowOrEqual = Assembler::ConditionLS,
 104         GreaterThan = Assembler::ConditionGT,
 105         GreaterThanOrEqual = Assembler::ConditionGE,
 106         LessThan = Assembler::ConditionLT,
 107         LessThanOrEqual = Assembler::ConditionLE
 108     };
 109 
</pre>
<hr />
<pre>
 120         IsNonZero = Assembler::ConditionNE
 121     };
 122 
 123     enum DoubleCondition {
 124         // These conditions will only evaluate to true if the comparison is ordered - i.e. neither operand is NaN.
 125         DoubleEqual = Assembler::ConditionEQ,
 126         DoubleNotEqual = Assembler::ConditionVC, // Not the right flag! check for this &amp; handle differently.
 127         DoubleGreaterThan = Assembler::ConditionGT,
 128         DoubleGreaterThanOrEqual = Assembler::ConditionGE,
 129         DoubleLessThan = Assembler::ConditionLO,
 130         DoubleLessThanOrEqual = Assembler::ConditionLS,
 131         // If either operand is NaN, these conditions always evaluate to true.
 132         DoubleEqualOrUnordered = Assembler::ConditionVS, // Not the right flag! check for this &amp; handle differently.
 133         DoubleNotEqualOrUnordered = Assembler::ConditionNE,
 134         DoubleGreaterThanOrUnordered = Assembler::ConditionHI,
 135         DoubleGreaterThanOrEqualOrUnordered = Assembler::ConditionHS,
 136         DoubleLessThanOrUnordered = Assembler::ConditionLT,
 137         DoubleLessThanOrEqualOrUnordered = Assembler::ConditionLE,
 138     };
 139 
<span class="line-modified"> 140     static const RegisterID stackPointerRegister = ARM64Registers::sp;</span>
<span class="line-modified"> 141     static const RegisterID framePointerRegister = ARM64Registers::fp;</span>
<span class="line-modified"> 142     static const RegisterID linkRegister = ARM64Registers::lr;</span>
 143 
 144     // FIXME: Get reasonable implementations for these
 145     static bool shouldBlindForSpecificArch(uint32_t value) { return value &gt;= 0x00ffffff; }
 146     static bool shouldBlindForSpecificArch(uint64_t value) { return value &gt;= 0x00ffffff; }
 147 
 148     // Integer operations:
 149 
 150     void add32(RegisterID a, RegisterID b, RegisterID dest)
 151     {
 152         ASSERT(a != ARM64Registers::sp &amp;&amp; b != ARM64Registers::sp);
 153         m_assembler.add&lt;32&gt;(dest, a, b);
 154     }
 155 
 156     void add32(RegisterID src, RegisterID dest)
 157     {
 158         m_assembler.add&lt;32&gt;(dest, dest, src);
 159     }
 160 
 161     void add32(TrustedImm32 imm, RegisterID dest)
 162     {
</pre>
<hr />
<pre>
 597     void neg32(RegisterID dest)
 598     {
 599         m_assembler.neg&lt;32&gt;(dest, dest);
 600     }
 601 
 602     void neg32(RegisterID src, RegisterID dest)
 603     {
 604         m_assembler.neg&lt;32&gt;(dest, src);
 605     }
 606 
 607     void neg64(RegisterID dest)
 608     {
 609         m_assembler.neg&lt;64&gt;(dest, dest);
 610     }
 611 
 612     void neg64(RegisterID src, RegisterID dest)
 613     {
 614         m_assembler.neg&lt;64&gt;(dest, src);
 615     }
 616 














 617     void or32(RegisterID src, RegisterID dest)
 618     {
 619         or32(dest, src, dest);
 620     }
 621 
 622     void or32(RegisterID op1, RegisterID op2, RegisterID dest)
 623     {
 624         m_assembler.orr&lt;32&gt;(dest, op1, op2);
 625     }
 626 
 627     void or32(TrustedImm32 imm, RegisterID dest)
 628     {
 629         or32(imm, dest, dest);
 630     }
 631 
 632     void or32(TrustedImm32 imm, RegisterID src, RegisterID dest)
 633     {
 634         LogicalImmediate logicalImm = LogicalImmediate::create32(imm.m_value);
 635 
 636         if (logicalImm.isValid()) {
</pre>
<hr />
<pre>
1220     void load16(BaseIndex address, RegisterID dest)
1221     {
1222         if (!address.offset &amp;&amp; (!address.scale || address.scale == 1)) {
1223             m_assembler.ldrh(dest, address.base, address.index, Assembler::UXTX, address.scale);
1224             return;
1225         }
1226 
1227         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1228         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1229         m_assembler.ldrh(dest, address.base, memoryTempRegister);
1230     }
1231 
1232     void load16(ExtendedAddress address, RegisterID dest)
1233     {
1234         moveToCachedReg(TrustedImmPtr(reinterpret_cast&lt;void*&gt;(address.offset)), cachedMemoryTempRegister());
1235         m_assembler.ldrh(dest, memoryTempRegister, address.base, Assembler::UXTX, 1);
1236         if (dest == memoryTempRegister)
1237             cachedMemoryTempRegister().invalidate();
1238     }
1239 





1240     void load16Unaligned(ImplicitAddress address, RegisterID dest)
1241     {
1242         load16(address, dest);
1243     }
1244 
1245     void load16Unaligned(BaseIndex address, RegisterID dest)
1246     {
1247         load16(address, dest);
1248     }
1249 
1250     void load16SignedExtendTo32(ImplicitAddress address, RegisterID dest)
1251     {
1252         if (tryLoadSignedWithOffset&lt;16&gt;(dest, address.base, address.offset))
1253             return;
1254 
1255         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1256         m_assembler.ldrsh&lt;32&gt;(dest, address.base, memoryTempRegister);
1257     }
1258 
1259     void load16SignedExtendTo32(BaseIndex address, RegisterID dest)
</pre>
<hr />
<pre>
1528     {
1529         if (tryStoreWithOffset&lt;16&gt;(src, address.base, address.offset))
1530             return;
1531 
1532         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1533         m_assembler.strh(src, address.base, memoryTempRegister);
1534     }
1535 
1536     void store16(RegisterID src, BaseIndex address)
1537     {
1538         if (!address.offset &amp;&amp; (!address.scale || address.scale == 1)) {
1539             m_assembler.strh(src, address.base, address.index, Assembler::UXTX, address.scale);
1540             return;
1541         }
1542 
1543         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1544         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1545         m_assembler.strh(src, address.base, memoryTempRegister);
1546     }
1547 
















1548     void storeZero16(ImplicitAddress address)
1549     {
1550         store16(ARM64Registers::zr, address);
1551     }
1552 
1553     void storeZero16(BaseIndex address)
1554     {
1555         store16(ARM64Registers::zr, address);
1556     }
1557 
1558     void store8(RegisterID src, BaseIndex address)
1559     {
1560         if (!address.offset &amp;&amp; !address.scale) {
1561             m_assembler.strb(src, address.base, address.index, Assembler::UXTX, address.scale);
1562             return;
1563         }
1564 
1565         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1566         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1567         m_assembler.strb(src, address.base, memoryTempRegister);
</pre>
<hr />
<pre>
3192         return Call(callLabel, Call::Linkable);
3193     }
3194 
3195     ALWAYS_INLINE Call call(RegisterID target, PtrTag)
3196     {
3197         invalidateAllTempRegisters();
3198         m_assembler.blr(target);
3199         return Call(m_assembler.label(), Call::None);
3200     }
3201 
3202     ALWAYS_INLINE Call call(Address address, PtrTag tag)
3203     {
3204         load64(address, getCachedDataTempRegisterIDAndInvalidate());
3205         return call(dataTempRegister, tag);
3206     }
3207 
3208     ALWAYS_INLINE Call call(RegisterID callTag) { return UNUSED_PARAM(callTag), call(NoPtrTag); }
3209     ALWAYS_INLINE Call call(RegisterID target, RegisterID callTag) { return UNUSED_PARAM(callTag), call(target, NoPtrTag); }
3210     ALWAYS_INLINE Call call(Address address, RegisterID callTag) { return UNUSED_PARAM(callTag), call(address, NoPtrTag); }
3211 







3212     ALWAYS_INLINE Jump jump()
3213     {
3214         AssemblerLabel label = m_assembler.label();
3215         m_assembler.b();
3216         return Jump(label, m_makeJumpPatchable ? Assembler::JumpNoConditionFixedSize : Assembler::JumpNoCondition);
3217     }
3218 
3219     void farJump(RegisterID target, PtrTag)
3220     {
3221         m_assembler.br(target);
3222     }
3223 
3224     void farJump(Address address, PtrTag)
3225     {
3226         load64(address, getCachedDataTempRegisterIDAndInvalidate());
3227         m_assembler.br(dataTempRegister);
3228     }
3229 
3230     void farJump(BaseIndex address, PtrTag)
3231     {
3232         load64(address, getCachedDataTempRegisterIDAndInvalidate());
3233         m_assembler.br(dataTempRegister);
3234     }
3235 
3236     void farJump(AbsoluteAddress address, PtrTag)
3237     {
3238         move(TrustedImmPtr(address.m_ptr), getCachedDataTempRegisterIDAndInvalidate());
3239         load64(Address(dataTempRegister), dataTempRegister);
3240         m_assembler.br(dataTempRegister);
3241     }
3242 
3243     ALWAYS_INLINE void farJump(RegisterID target, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(target, NoPtrTag); }
3244     ALWAYS_INLINE void farJump(Address address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }
3245     ALWAYS_INLINE void farJump(BaseIndex address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }
3246     ALWAYS_INLINE void farJump(AbsoluteAddress address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }
3247 
3248     ALWAYS_INLINE Call nearCall()
3249     {

3250         m_assembler.bl();
3251         return Call(m_assembler.label(), Call::LinkableNear);
3252     }
3253 
3254     ALWAYS_INLINE Call nearTailCall()
3255     {
3256         AssemblerLabel label = m_assembler.label();
3257         m_assembler.b();
3258         return Call(label, Call::LinkableNearTail);
3259     }
3260 
3261     ALWAYS_INLINE Call threadSafePatchableNearCall()
3262     {

3263         m_assembler.bl();
3264         return Call(m_assembler.label(), Call::LinkableNear);
3265     }
3266 
3267     ALWAYS_INLINE void ret()
3268     {
3269         m_assembler.ret();
3270     }
3271 
3272     // Comparisons operations
3273 
3274     void compare32(RelationalCondition cond, RegisterID left, RegisterID right, RegisterID dest)
3275     {
3276         m_assembler.cmp&lt;32&gt;(left, right);
3277         m_assembler.cset&lt;32&gt;(dest, ARM64Condition(cond));
3278     }
3279 
3280     void compare32(RelationalCondition cond, Address left, RegisterID right, RegisterID dest)
3281     {
3282         load32(left, getCachedDataTempRegisterIDAndInvalidate());
</pre>
<hr />
<pre>
4156             m_assembler.movk&lt;32&gt;(dest, getHalfword(value, 1), 16);
4157         } else {
4158             m_assembler.movn&lt;32&gt;(dest, ~getHalfword(value, 0));
4159             m_assembler.movk&lt;32&gt;(dest, getHalfword(value, 1), 16);
4160         }
4161     }
4162 
4163     template&lt;int datasize&gt;
4164     ALWAYS_INLINE void load(const void* address, RegisterID dest)
4165     {
4166         intptr_t currentRegisterContents;
4167         if (cachedMemoryTempRegister().value(currentRegisterContents)) {
4168             intptr_t addressAsInt = reinterpret_cast&lt;intptr_t&gt;(address);
4169             intptr_t addressDelta = addressAsInt - currentRegisterContents;
4170 
4171             if (dest == memoryTempRegister)
4172                 cachedMemoryTempRegister().invalidate();
4173 
4174             if (isInt&lt;32&gt;(addressDelta)) {
4175                 if (Assembler::canEncodeSImmOffset(addressDelta)) {
<span class="line-modified">4176                     m_assembler.ldur&lt;datasize&gt;(dest,  memoryTempRegister, addressDelta);</span>
4177                     return;
4178                 }
4179 
4180                 if (Assembler::canEncodePImmOffset&lt;datasize&gt;(addressDelta)) {
<span class="line-modified">4181                     m_assembler.ldr&lt;datasize&gt;(dest,  memoryTempRegister, addressDelta);</span>
4182                     return;
4183                 }
4184             }
4185 
4186             if ((addressAsInt &amp; (~maskHalfWord0)) == (currentRegisterContents &amp; (~maskHalfWord0))) {
4187                 m_assembler.movk&lt;64&gt;(memoryTempRegister, addressAsInt &amp; maskHalfWord0, 0);
4188                 cachedMemoryTempRegister().setValue(reinterpret_cast&lt;intptr_t&gt;(address));
<span class="line-modified">4189                 m_assembler.ldr&lt;datasize&gt;(dest, memoryTempRegister, ARM64Registers::zr);</span>



4190                 return;
4191             }
4192         }
4193 
4194         move(TrustedImmPtr(address), memoryTempRegister);
4195         if (dest == memoryTempRegister)
4196             cachedMemoryTempRegister().invalidate();
4197         else
4198             cachedMemoryTempRegister().setValue(reinterpret_cast&lt;intptr_t&gt;(address));
<span class="line-modified">4199         m_assembler.ldr&lt;datasize&gt;(dest, memoryTempRegister, ARM64Registers::zr);</span>



4200     }
4201 
4202     template&lt;int datasize&gt;
4203     ALWAYS_INLINE void store(RegisterID src, const void* address)
4204     {
4205         ASSERT(src != memoryTempRegister);
4206         intptr_t currentRegisterContents;
4207         if (cachedMemoryTempRegister().value(currentRegisterContents)) {
4208             intptr_t addressAsInt = reinterpret_cast&lt;intptr_t&gt;(address);
4209             intptr_t addressDelta = addressAsInt - currentRegisterContents;
4210 
4211             if (isInt&lt;32&gt;(addressDelta)) {
4212                 if (Assembler::canEncodeSImmOffset(addressDelta)) {
<span class="line-modified">4213                     m_assembler.stur&lt;datasize&gt;(src, memoryTempRegister, addressDelta);</span>
4214                     return;
4215                 }
4216 
4217                 if (Assembler::canEncodePImmOffset&lt;datasize&gt;(addressDelta)) {
<span class="line-modified">4218                     m_assembler.str&lt;datasize&gt;(src, memoryTempRegister, addressDelta);</span>
4219                     return;
4220                 }
4221             }
4222 
4223             if ((addressAsInt &amp; (~maskHalfWord0)) == (currentRegisterContents &amp; (~maskHalfWord0))) {
4224                 m_assembler.movk&lt;64&gt;(memoryTempRegister, addressAsInt &amp; maskHalfWord0, 0);
4225                 cachedMemoryTempRegister().setValue(reinterpret_cast&lt;intptr_t&gt;(address));
<span class="line-modified">4226                 m_assembler.str&lt;datasize&gt;(src, memoryTempRegister, ARM64Registers::zr);</span>



4227                 return;
4228             }
4229         }
4230 
4231         move(TrustedImmPtr(address), memoryTempRegister);
4232         cachedMemoryTempRegister().setValue(reinterpret_cast&lt;intptr_t&gt;(address));
<span class="line-modified">4233         m_assembler.str&lt;datasize&gt;(src, memoryTempRegister, ARM64Registers::zr);</span>



4234     }
4235 
4236     template &lt;int dataSize&gt;
4237     ALWAYS_INLINE bool tryMoveUsingCacheRegisterContents(intptr_t immediate, CachedTempRegister&amp; dest)
4238     {
4239         intptr_t currentRegisterContents;
4240         if (dest.value(currentRegisterContents)) {
4241             if (currentRegisterContents == immediate)
4242                 return true;
4243 
4244             LogicalImmediate logicalImm = dataSize == 64 ? LogicalImmediate::create64(static_cast&lt;uint64_t&gt;(immediate)) : LogicalImmediate::create32(static_cast&lt;uint32_t&gt;(immediate));
4245 
4246             if (logicalImm.isValid()) {
4247                 m_assembler.movi&lt;dataSize&gt;(dest.registerIDNoInvalidate(), logicalImm);
4248                 dest.setValue(immediate);
4249                 return true;
4250             }
4251 
4252             if ((immediate &amp; maskUpperWord) == (currentRegisterContents &amp; maskUpperWord)) {
4253                 if ((immediate &amp; maskHalfWord1) != (currentRegisterContents &amp; maskHalfWord1))
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (C) 2012-2019 Apple Inc. All rights reserved.</span>
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #pragma once
  27 
  28 #if ENABLE(ASSEMBLER)
  29 
  30 #include &quot;ARM64Assembler.h&quot;
  31 #include &quot;AbstractMacroAssembler.h&quot;
  32 #include &lt;wtf/MathExtras.h&gt;
  33 #include &lt;wtf/Optional.h&gt;
  34 
  35 namespace JSC {
  36 
  37 using Assembler = TARGET_ASSEMBLER;
<span class="line-added">  38 class Reg;</span>
  39 
  40 class MacroAssemblerARM64 : public AbstractMacroAssembler&lt;Assembler&gt; {
  41 public:
<span class="line-modified">  42     static constexpr unsigned numGPRs = 32;</span>
<span class="line-modified">  43     static constexpr unsigned numFPRs = 32;</span>
  44 
  45     static constexpr RegisterID dataTempRegister = ARM64Registers::ip0;
  46     static constexpr RegisterID memoryTempRegister = ARM64Registers::ip1;
  47 
  48     RegisterID scratchRegister()
  49     {
  50         RELEASE_ASSERT(m_allowScratchRegister);
  51         return getCachedDataTempRegisterIDAndInvalidate();
  52     }
  53 
  54 protected:
<span class="line-modified">  55     static constexpr ARM64Registers::FPRegisterID fpTempRegister = ARM64Registers::q31;</span>
<span class="line-modified">  56     static constexpr Assembler::SetFlags S = Assembler::S;</span>
<span class="line-modified">  57     static constexpr int64_t maskHalfWord0 = 0xffffl;</span>
<span class="line-modified">  58     static constexpr int64_t maskHalfWord1 = 0xffff0000l;</span>
<span class="line-modified">  59     static constexpr int64_t maskUpperWord = 0xffffffff00000000l;</span>
  60 
  61     static constexpr size_t INSTRUCTION_SIZE = 4;
  62 
  63     // N instructions to load the pointer + 1 call instruction.
  64     static constexpr ptrdiff_t REPATCH_OFFSET_CALL_TO_POINTER = -((Assembler::MAX_POINTER_BITS / 16 + 1) * INSTRUCTION_SIZE);
  65 
  66 public:
  67     MacroAssemblerARM64()
  68         : m_dataMemoryTempRegister(this, dataTempRegister)
  69         , m_cachedMemoryTempRegister(this, memoryTempRegister)
  70         , m_makeJumpPatchable(false)
  71     {
  72     }
  73 
  74     typedef Assembler::LinkRecord LinkRecord;
  75     typedef Assembler::JumpType JumpType;
  76     typedef Assembler::JumpLinkType JumpLinkType;
  77     typedef Assembler::Condition Condition;
  78 
<span class="line-modified">  79     static constexpr Assembler::Condition DefaultCondition = Assembler::ConditionInvalid;</span>
<span class="line-modified">  80     static constexpr Assembler::JumpType DefaultJump = Assembler::JumpNoConditionFixedSize;</span>
  81 
  82     Vector&lt;LinkRecord, 0, UnsafeVectorOverflow&gt;&amp; jumpsToLink() { return m_assembler.jumpsToLink(); }
  83     static bool canCompact(JumpType jumpType) { return Assembler::canCompact(jumpType); }
  84     static JumpLinkType computeJumpType(JumpType jumpType, const uint8_t* from, const uint8_t* to) { return Assembler::computeJumpType(jumpType, from, to); }
  85     static JumpLinkType computeJumpType(LinkRecord&amp; record, const uint8_t* from, const uint8_t* to) { return Assembler::computeJumpType(record, from, to); }
  86     static int jumpSizeDelta(JumpType jumpType, JumpLinkType jumpLinkType) { return Assembler::jumpSizeDelta(jumpType, jumpLinkType); }
<span class="line-modified">  87     template &lt;Assembler::CopyFunction copy&gt;</span>
<span class="line-modified">  88     static void link(LinkRecord&amp; record, uint8_t* from, const uint8_t* fromInstruction, uint8_t* to) { return Assembler::link&lt;copy&gt;(record, from, fromInstruction, to); }</span>
  89 
<span class="line-modified">  90     static constexpr Scale ScalePtr = TimesEight;</span>
  91 
  92     static bool isCompactPtrAlignedAddressOffset(ptrdiff_t value)
  93     {
  94         // This is the largest 32-bit access allowed, aligned to 64-bit boundary.
  95         return !(value &amp; ~0x3ff8);
  96     }
  97 
  98     enum RelationalCondition {
  99         Equal = Assembler::ConditionEQ,
 100         NotEqual = Assembler::ConditionNE,
 101         Above = Assembler::ConditionHI,
 102         AboveOrEqual = Assembler::ConditionHS,
 103         Below = Assembler::ConditionLO,
 104         BelowOrEqual = Assembler::ConditionLS,
 105         GreaterThan = Assembler::ConditionGT,
 106         GreaterThanOrEqual = Assembler::ConditionGE,
 107         LessThan = Assembler::ConditionLT,
 108         LessThanOrEqual = Assembler::ConditionLE
 109     };
 110 
</pre>
<hr />
<pre>
 121         IsNonZero = Assembler::ConditionNE
 122     };
 123 
 124     enum DoubleCondition {
 125         // These conditions will only evaluate to true if the comparison is ordered - i.e. neither operand is NaN.
 126         DoubleEqual = Assembler::ConditionEQ,
 127         DoubleNotEqual = Assembler::ConditionVC, // Not the right flag! check for this &amp; handle differently.
 128         DoubleGreaterThan = Assembler::ConditionGT,
 129         DoubleGreaterThanOrEqual = Assembler::ConditionGE,
 130         DoubleLessThan = Assembler::ConditionLO,
 131         DoubleLessThanOrEqual = Assembler::ConditionLS,
 132         // If either operand is NaN, these conditions always evaluate to true.
 133         DoubleEqualOrUnordered = Assembler::ConditionVS, // Not the right flag! check for this &amp; handle differently.
 134         DoubleNotEqualOrUnordered = Assembler::ConditionNE,
 135         DoubleGreaterThanOrUnordered = Assembler::ConditionHI,
 136         DoubleGreaterThanOrEqualOrUnordered = Assembler::ConditionHS,
 137         DoubleLessThanOrUnordered = Assembler::ConditionLT,
 138         DoubleLessThanOrEqualOrUnordered = Assembler::ConditionLE,
 139     };
 140 
<span class="line-modified"> 141     static constexpr RegisterID stackPointerRegister = ARM64Registers::sp;</span>
<span class="line-modified"> 142     static constexpr RegisterID framePointerRegister = ARM64Registers::fp;</span>
<span class="line-modified"> 143     static constexpr RegisterID linkRegister = ARM64Registers::lr;</span>
 144 
 145     // FIXME: Get reasonable implementations for these
 146     static bool shouldBlindForSpecificArch(uint32_t value) { return value &gt;= 0x00ffffff; }
 147     static bool shouldBlindForSpecificArch(uint64_t value) { return value &gt;= 0x00ffffff; }
 148 
 149     // Integer operations:
 150 
 151     void add32(RegisterID a, RegisterID b, RegisterID dest)
 152     {
 153         ASSERT(a != ARM64Registers::sp &amp;&amp; b != ARM64Registers::sp);
 154         m_assembler.add&lt;32&gt;(dest, a, b);
 155     }
 156 
 157     void add32(RegisterID src, RegisterID dest)
 158     {
 159         m_assembler.add&lt;32&gt;(dest, dest, src);
 160     }
 161 
 162     void add32(TrustedImm32 imm, RegisterID dest)
 163     {
</pre>
<hr />
<pre>
 598     void neg32(RegisterID dest)
 599     {
 600         m_assembler.neg&lt;32&gt;(dest, dest);
 601     }
 602 
 603     void neg32(RegisterID src, RegisterID dest)
 604     {
 605         m_assembler.neg&lt;32&gt;(dest, src);
 606     }
 607 
 608     void neg64(RegisterID dest)
 609     {
 610         m_assembler.neg&lt;64&gt;(dest, dest);
 611     }
 612 
 613     void neg64(RegisterID src, RegisterID dest)
 614     {
 615         m_assembler.neg&lt;64&gt;(dest, src);
 616     }
 617 
<span class="line-added"> 618     void or16(TrustedImm32 imm, AbsoluteAddress address)</span>
<span class="line-added"> 619     {</span>
<span class="line-added"> 620         LogicalImmediate logicalImm = LogicalImmediate::create32(imm.m_value);</span>
<span class="line-added"> 621         if (logicalImm.isValid()) {</span>
<span class="line-added"> 622             load16(address.m_ptr, getCachedDataTempRegisterIDAndInvalidate());</span>
<span class="line-added"> 623             m_assembler.orr&lt;32&gt;(dataTempRegister, dataTempRegister, logicalImm);</span>
<span class="line-added"> 624             store16(dataTempRegister, address.m_ptr);</span>
<span class="line-added"> 625         } else {</span>
<span class="line-added"> 626             load16(address.m_ptr, getCachedMemoryTempRegisterIDAndInvalidate());</span>
<span class="line-added"> 627             or32(imm, memoryTempRegister, getCachedDataTempRegisterIDAndInvalidate());</span>
<span class="line-added"> 628             store16(dataTempRegister, address.m_ptr);</span>
<span class="line-added"> 629         }</span>
<span class="line-added"> 630     }</span>
<span class="line-added"> 631 </span>
 632     void or32(RegisterID src, RegisterID dest)
 633     {
 634         or32(dest, src, dest);
 635     }
 636 
 637     void or32(RegisterID op1, RegisterID op2, RegisterID dest)
 638     {
 639         m_assembler.orr&lt;32&gt;(dest, op1, op2);
 640     }
 641 
 642     void or32(TrustedImm32 imm, RegisterID dest)
 643     {
 644         or32(imm, dest, dest);
 645     }
 646 
 647     void or32(TrustedImm32 imm, RegisterID src, RegisterID dest)
 648     {
 649         LogicalImmediate logicalImm = LogicalImmediate::create32(imm.m_value);
 650 
 651         if (logicalImm.isValid()) {
</pre>
<hr />
<pre>
1235     void load16(BaseIndex address, RegisterID dest)
1236     {
1237         if (!address.offset &amp;&amp; (!address.scale || address.scale == 1)) {
1238             m_assembler.ldrh(dest, address.base, address.index, Assembler::UXTX, address.scale);
1239             return;
1240         }
1241 
1242         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1243         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1244         m_assembler.ldrh(dest, address.base, memoryTempRegister);
1245     }
1246 
1247     void load16(ExtendedAddress address, RegisterID dest)
1248     {
1249         moveToCachedReg(TrustedImmPtr(reinterpret_cast&lt;void*&gt;(address.offset)), cachedMemoryTempRegister());
1250         m_assembler.ldrh(dest, memoryTempRegister, address.base, Assembler::UXTX, 1);
1251         if (dest == memoryTempRegister)
1252             cachedMemoryTempRegister().invalidate();
1253     }
1254 
<span class="line-added">1255     void load16(const void* address, RegisterID dest)</span>
<span class="line-added">1256     {</span>
<span class="line-added">1257         load&lt;16&gt;(address, dest);</span>
<span class="line-added">1258     }</span>
<span class="line-added">1259 </span>
1260     void load16Unaligned(ImplicitAddress address, RegisterID dest)
1261     {
1262         load16(address, dest);
1263     }
1264 
1265     void load16Unaligned(BaseIndex address, RegisterID dest)
1266     {
1267         load16(address, dest);
1268     }
1269 
1270     void load16SignedExtendTo32(ImplicitAddress address, RegisterID dest)
1271     {
1272         if (tryLoadSignedWithOffset&lt;16&gt;(dest, address.base, address.offset))
1273             return;
1274 
1275         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1276         m_assembler.ldrsh&lt;32&gt;(dest, address.base, memoryTempRegister);
1277     }
1278 
1279     void load16SignedExtendTo32(BaseIndex address, RegisterID dest)
</pre>
<hr />
<pre>
1548     {
1549         if (tryStoreWithOffset&lt;16&gt;(src, address.base, address.offset))
1550             return;
1551 
1552         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1553         m_assembler.strh(src, address.base, memoryTempRegister);
1554     }
1555 
1556     void store16(RegisterID src, BaseIndex address)
1557     {
1558         if (!address.offset &amp;&amp; (!address.scale || address.scale == 1)) {
1559             m_assembler.strh(src, address.base, address.index, Assembler::UXTX, address.scale);
1560             return;
1561         }
1562 
1563         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1564         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1565         m_assembler.strh(src, address.base, memoryTempRegister);
1566     }
1567 
<span class="line-added">1568     void store16(RegisterID src, const void* address)</span>
<span class="line-added">1569     {</span>
<span class="line-added">1570         store&lt;16&gt;(src, address);</span>
<span class="line-added">1571     }</span>
<span class="line-added">1572 </span>
<span class="line-added">1573     void store16(TrustedImm32 imm, const void* address)</span>
<span class="line-added">1574     {</span>
<span class="line-added">1575         if (!imm.m_value) {</span>
<span class="line-added">1576             store16(ARM64Registers::zr, address);</span>
<span class="line-added">1577             return;</span>
<span class="line-added">1578         }</span>
<span class="line-added">1579 </span>
<span class="line-added">1580         moveToCachedReg(imm, dataMemoryTempRegister());</span>
<span class="line-added">1581         store16(dataTempRegister, address);</span>
<span class="line-added">1582     }</span>
<span class="line-added">1583 </span>
1584     void storeZero16(ImplicitAddress address)
1585     {
1586         store16(ARM64Registers::zr, address);
1587     }
1588 
1589     void storeZero16(BaseIndex address)
1590     {
1591         store16(ARM64Registers::zr, address);
1592     }
1593 
1594     void store8(RegisterID src, BaseIndex address)
1595     {
1596         if (!address.offset &amp;&amp; !address.scale) {
1597             m_assembler.strb(src, address.base, address.index, Assembler::UXTX, address.scale);
1598             return;
1599         }
1600 
1601         signExtend32ToPtr(TrustedImm32(address.offset), getCachedMemoryTempRegisterIDAndInvalidate());
1602         m_assembler.add&lt;64&gt;(memoryTempRegister, memoryTempRegister, address.index, Assembler::UXTX, address.scale);
1603         m_assembler.strb(src, address.base, memoryTempRegister);
</pre>
<hr />
<pre>
3228         return Call(callLabel, Call::Linkable);
3229     }
3230 
3231     ALWAYS_INLINE Call call(RegisterID target, PtrTag)
3232     {
3233         invalidateAllTempRegisters();
3234         m_assembler.blr(target);
3235         return Call(m_assembler.label(), Call::None);
3236     }
3237 
3238     ALWAYS_INLINE Call call(Address address, PtrTag tag)
3239     {
3240         load64(address, getCachedDataTempRegisterIDAndInvalidate());
3241         return call(dataTempRegister, tag);
3242     }
3243 
3244     ALWAYS_INLINE Call call(RegisterID callTag) { return UNUSED_PARAM(callTag), call(NoPtrTag); }
3245     ALWAYS_INLINE Call call(RegisterID target, RegisterID callTag) { return UNUSED_PARAM(callTag), call(target, NoPtrTag); }
3246     ALWAYS_INLINE Call call(Address address, RegisterID callTag) { return UNUSED_PARAM(callTag), call(address, NoPtrTag); }
3247 
<span class="line-added">3248     ALWAYS_INLINE void callOperation(const FunctionPtr&lt;OperationPtrTag&gt; operation)</span>
<span class="line-added">3249     {</span>
<span class="line-added">3250         auto tmp = getCachedDataTempRegisterIDAndInvalidate();</span>
<span class="line-added">3251         move(TrustedImmPtr(operation.executableAddress()), tmp);</span>
<span class="line-added">3252         call(tmp, OperationPtrTag);</span>
<span class="line-added">3253     }</span>
<span class="line-added">3254 </span>
3255     ALWAYS_INLINE Jump jump()
3256     {
3257         AssemblerLabel label = m_assembler.label();
3258         m_assembler.b();
3259         return Jump(label, m_makeJumpPatchable ? Assembler::JumpNoConditionFixedSize : Assembler::JumpNoCondition);
3260     }
3261 
3262     void farJump(RegisterID target, PtrTag)
3263     {
3264         m_assembler.br(target);
3265     }
3266 
3267     void farJump(Address address, PtrTag)
3268     {
3269         load64(address, getCachedDataTempRegisterIDAndInvalidate());
3270         m_assembler.br(dataTempRegister);
3271     }
3272 
3273     void farJump(BaseIndex address, PtrTag)
3274     {
3275         load64(address, getCachedDataTempRegisterIDAndInvalidate());
3276         m_assembler.br(dataTempRegister);
3277     }
3278 
3279     void farJump(AbsoluteAddress address, PtrTag)
3280     {
3281         move(TrustedImmPtr(address.m_ptr), getCachedDataTempRegisterIDAndInvalidate());
3282         load64(Address(dataTempRegister), dataTempRegister);
3283         m_assembler.br(dataTempRegister);
3284     }
3285 
3286     ALWAYS_INLINE void farJump(RegisterID target, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(target, NoPtrTag); }
3287     ALWAYS_INLINE void farJump(Address address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }
3288     ALWAYS_INLINE void farJump(BaseIndex address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }
3289     ALWAYS_INLINE void farJump(AbsoluteAddress address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }
3290 
3291     ALWAYS_INLINE Call nearCall()
3292     {
<span class="line-added">3293         invalidateAllTempRegisters();</span>
3294         m_assembler.bl();
3295         return Call(m_assembler.label(), Call::LinkableNear);
3296     }
3297 
3298     ALWAYS_INLINE Call nearTailCall()
3299     {
3300         AssemblerLabel label = m_assembler.label();
3301         m_assembler.b();
3302         return Call(label, Call::LinkableNearTail);
3303     }
3304 
3305     ALWAYS_INLINE Call threadSafePatchableNearCall()
3306     {
<span class="line-added">3307         invalidateAllTempRegisters();</span>
3308         m_assembler.bl();
3309         return Call(m_assembler.label(), Call::LinkableNear);
3310     }
3311 
3312     ALWAYS_INLINE void ret()
3313     {
3314         m_assembler.ret();
3315     }
3316 
3317     // Comparisons operations
3318 
3319     void compare32(RelationalCondition cond, RegisterID left, RegisterID right, RegisterID dest)
3320     {
3321         m_assembler.cmp&lt;32&gt;(left, right);
3322         m_assembler.cset&lt;32&gt;(dest, ARM64Condition(cond));
3323     }
3324 
3325     void compare32(RelationalCondition cond, Address left, RegisterID right, RegisterID dest)
3326     {
3327         load32(left, getCachedDataTempRegisterIDAndInvalidate());
</pre>
<hr />
<pre>
4201             m_assembler.movk&lt;32&gt;(dest, getHalfword(value, 1), 16);
4202         } else {
4203             m_assembler.movn&lt;32&gt;(dest, ~getHalfword(value, 0));
4204             m_assembler.movk&lt;32&gt;(dest, getHalfword(value, 1), 16);
4205         }
4206     }
4207 
4208     template&lt;int datasize&gt;
4209     ALWAYS_INLINE void load(const void* address, RegisterID dest)
4210     {
4211         intptr_t currentRegisterContents;
4212         if (cachedMemoryTempRegister().value(currentRegisterContents)) {
4213             intptr_t addressAsInt = reinterpret_cast&lt;intptr_t&gt;(address);
4214             intptr_t addressDelta = addressAsInt - currentRegisterContents;
4215 
4216             if (dest == memoryTempRegister)
4217                 cachedMemoryTempRegister().invalidate();
4218 
4219             if (isInt&lt;32&gt;(addressDelta)) {
4220                 if (Assembler::canEncodeSImmOffset(addressDelta)) {
<span class="line-modified">4221                     loadUnscaledImmediate&lt;datasize&gt;(dest, memoryTempRegister, addressDelta);</span>
4222                     return;
4223                 }
4224 
4225                 if (Assembler::canEncodePImmOffset&lt;datasize&gt;(addressDelta)) {
<span class="line-modified">4226                     loadUnsignedImmediate&lt;datasize&gt;(dest, memoryTempRegister, addressDelta);</span>
4227                     return;
4228                 }
4229             }
4230 
4231             if ((addressAsInt &amp; (~maskHalfWord0)) == (currentRegisterContents &amp; (~maskHalfWord0))) {
4232                 m_assembler.movk&lt;64&gt;(memoryTempRegister, addressAsInt &amp; maskHalfWord0, 0);
4233                 cachedMemoryTempRegister().setValue(reinterpret_cast&lt;intptr_t&gt;(address));
<span class="line-modified">4234                 if constexpr (datasize == 16)</span>
<span class="line-added">4235                     m_assembler.ldrh(dest, memoryTempRegister, ARM64Registers::zr);</span>
<span class="line-added">4236                 else</span>
<span class="line-added">4237                     m_assembler.ldr&lt;datasize&gt;(dest, memoryTempRegister, ARM64Registers::zr);</span>
4238                 return;
4239             }
4240         }
4241 
4242         move(TrustedImmPtr(address), memoryTempRegister);
4243         if (dest == memoryTempRegister)
4244             cachedMemoryTempRegister().invalidate();
4245         else
4246             cachedMemoryTempRegister().setValue(reinterpret_cast&lt;intptr_t&gt;(address));
<span class="line-modified">4247         if constexpr (datasize == 16)</span>
<span class="line-added">4248             m_assembler.ldrh(dest, memoryTempRegister, ARM64Registers::zr);</span>
<span class="line-added">4249         else</span>
<span class="line-added">4250             m_assembler.ldr&lt;datasize&gt;(dest, memoryTempRegister, ARM64Registers::zr);</span>
4251     }
4252 
4253     template&lt;int datasize&gt;
4254     ALWAYS_INLINE void store(RegisterID src, const void* address)
4255     {
4256         ASSERT(src != memoryTempRegister);
4257         intptr_t currentRegisterContents;
4258         if (cachedMemoryTempRegister().value(currentRegisterContents)) {
4259             intptr_t addressAsInt = reinterpret_cast&lt;intptr_t&gt;(address);
4260             intptr_t addressDelta = addressAsInt - currentRegisterContents;
4261 
4262             if (isInt&lt;32&gt;(addressDelta)) {
4263                 if (Assembler::canEncodeSImmOffset(addressDelta)) {
<span class="line-modified">4264                     storeUnscaledImmediate&lt;datasize&gt;(src, memoryTempRegister, addressDelta);</span>
4265                     return;
4266                 }
4267 
4268                 if (Assembler::canEncodePImmOffset&lt;datasize&gt;(addressDelta)) {
<span class="line-modified">4269                     storeUnsignedImmediate&lt;datasize&gt;(src, memoryTempRegister, addressDelta);</span>
4270                     return;
4271                 }
4272             }
4273 
4274             if ((addressAsInt &amp; (~maskHalfWord0)) == (currentRegisterContents &amp; (~maskHalfWord0))) {
4275                 m_assembler.movk&lt;64&gt;(memoryTempRegister, addressAsInt &amp; maskHalfWord0, 0);
4276                 cachedMemoryTempRegister().setValue(reinterpret_cast&lt;intptr_t&gt;(address));
<span class="line-modified">4277                 if constexpr (datasize == 16)</span>
<span class="line-added">4278                     m_assembler.strh(src, memoryTempRegister, ARM64Registers::zr);</span>
<span class="line-added">4279                 else</span>
<span class="line-added">4280                     m_assembler.str&lt;datasize&gt;(src, memoryTempRegister, ARM64Registers::zr);</span>
4281                 return;
4282             }
4283         }
4284 
4285         move(TrustedImmPtr(address), memoryTempRegister);
4286         cachedMemoryTempRegister().setValue(reinterpret_cast&lt;intptr_t&gt;(address));
<span class="line-modified">4287         if constexpr (datasize == 16)</span>
<span class="line-added">4288             m_assembler.strh(src, memoryTempRegister, ARM64Registers::zr);</span>
<span class="line-added">4289         else</span>
<span class="line-added">4290             m_assembler.str&lt;datasize&gt;(src, memoryTempRegister, ARM64Registers::zr);</span>
4291     }
4292 
4293     template &lt;int dataSize&gt;
4294     ALWAYS_INLINE bool tryMoveUsingCacheRegisterContents(intptr_t immediate, CachedTempRegister&amp; dest)
4295     {
4296         intptr_t currentRegisterContents;
4297         if (dest.value(currentRegisterContents)) {
4298             if (currentRegisterContents == immediate)
4299                 return true;
4300 
4301             LogicalImmediate logicalImm = dataSize == 64 ? LogicalImmediate::create64(static_cast&lt;uint64_t&gt;(immediate)) : LogicalImmediate::create32(static_cast&lt;uint32_t&gt;(immediate));
4302 
4303             if (logicalImm.isValid()) {
4304                 m_assembler.movi&lt;dataSize&gt;(dest.registerIDNoInvalidate(), logicalImm);
4305                 dest.setValue(immediate);
4306                 return true;
4307             }
4308 
4309             if ((immediate &amp; maskUpperWord) == (currentRegisterContents &amp; maskUpperWord)) {
4310                 if ((immediate &amp; maskHalfWord1) != (currentRegisterContents &amp; maskHalfWord1))
</pre>
</td>
</tr>
</table>
<center><a href="MacroAssembler.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="MacroAssemblerARM64E.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>