<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/BlockDirectory.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="AtomIndices.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="BlockDirectory.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/BlockDirectory.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;BlockDirectory.h&quot;
 28 
 29 #include &quot;BlockDirectoryInlines.h&quot;
 30 #include &quot;GCActivityCallback.h&quot;
 31 #include &quot;Heap.h&quot;
 32 #include &quot;IncrementalSweeper.h&quot;
 33 #include &quot;JSCInlines.h&quot;
 34 #include &quot;MarkedBlockInlines.h&quot;
 35 #include &quot;SubspaceInlines.h&quot;
 36 #include &quot;SuperSampler.h&quot;
 37 #include &quot;VM.h&quot;
 38 
 39 namespace JSC {
 40 
<span class="line-modified"> 41 BlockDirectory::BlockDirectory(Heap* heap, size_t cellSize)</span>


 42     : m_cellSize(static_cast&lt;unsigned&gt;(cellSize))
<span class="line-removed"> 43     , m_heap(heap)</span>
 44 {
 45 }
 46 
 47 BlockDirectory::~BlockDirectory()
 48 {
 49     auto locker = holdLock(m_localAllocatorsLock);
 50     while (!m_localAllocators.isEmpty())
 51         m_localAllocators.begin()-&gt;remove();
 52 }
 53 
 54 void BlockDirectory::setSubspace(Subspace* subspace)
 55 {
 56     m_attributes = subspace-&gt;attributes();
 57     m_subspace = subspace;
 58 }
 59 
 60 bool BlockDirectory::isPagedOut(MonotonicTime deadline)
 61 {
 62     unsigned itersSinceLastTimeCheck = 0;
 63     for (auto* block : m_blocks) {
 64         if (block)
 65             block-&gt;block().populatePage();
 66         ++itersSinceLastTimeCheck;
 67         if (itersSinceLastTimeCheck &gt;= Heap::s_timeCheckResolution) {
 68             MonotonicTime currentTime = MonotonicTime::now();
 69             if (currentTime &gt; deadline)
 70                 return true;
 71             itersSinceLastTimeCheck = 0;
 72         }
 73     }
 74     return false;
 75 }
 76 
 77 MarkedBlock::Handle* BlockDirectory::findEmptyBlockToSteal()
 78 {
<span class="line-modified"> 79     m_emptyCursor = m_empty.findBit(m_emptyCursor, true);</span>
 80     if (m_emptyCursor &gt;= m_blocks.size())
 81         return nullptr;
 82     return m_blocks[m_emptyCursor];
 83 }
 84 
 85 MarkedBlock::Handle* BlockDirectory::findBlockForAllocation(LocalAllocator&amp; allocator)
 86 {
 87     for (;;) {
<span class="line-modified"> 88         allocator.m_allocationCursor = (m_canAllocateButNotEmpty | m_empty).findBit(allocator.m_allocationCursor, true);</span>
 89         if (allocator.m_allocationCursor &gt;= m_blocks.size())
 90             return nullptr;
 91 
<span class="line-modified"> 92         size_t blockIndex = allocator.m_allocationCursor++;</span>
 93         MarkedBlock::Handle* result = m_blocks[blockIndex];
 94         setIsCanAllocateButNotEmpty(NoLockingNecessary, blockIndex, false);
 95         return result;
 96     }
 97 }
 98 
<span class="line-modified"> 99 MarkedBlock::Handle* BlockDirectory::tryAllocateBlock()</span>
100 {
101     SuperSamplerScope superSamplerScope(false);
102 
<span class="line-modified">103     MarkedBlock::Handle* handle = MarkedBlock::tryCreate(*m_heap, subspace()-&gt;alignedMemoryAllocator());</span>
104     if (!handle)
105         return nullptr;
106 
107     markedSpace().didAddBlock(handle);
108 
109     return handle;
110 }
111 
112 void BlockDirectory::addBlock(MarkedBlock::Handle* block)
113 {
<span class="line-modified">114     size_t index;</span>
115     if (m_freeBlockIndices.isEmpty()) {
116         index = m_blocks.size();
117 
118         size_t oldCapacity = m_blocks.capacity();
119         m_blocks.append(block);
120         if (m_blocks.capacity() != oldCapacity) {
<span class="line-modified">121             forEachBitVector(</span>
<span class="line-removed">122                 NoLockingNecessary,</span>
<span class="line-removed">123                 [&amp;] (FastBitVector&amp; vector) {</span>
<span class="line-removed">124                     ASSERT_UNUSED(vector, vector.numBits() == oldCapacity);</span>
<span class="line-removed">125                 });</span>
<span class="line-removed">126 </span>
127             ASSERT(m_blocks.capacity() &gt; oldCapacity);
128 
129             LockHolder locker(m_bitvectorLock);
130             subspace()-&gt;didResizeBits(m_blocks.capacity());
<span class="line-modified">131             forEachBitVector(</span>
<span class="line-removed">132                 locker,</span>
<span class="line-removed">133                 [&amp;] (FastBitVector&amp; vector) {</span>
<span class="line-removed">134                     vector.resize(m_blocks.capacity());</span>
<span class="line-removed">135                 });</span>
136         }
137     } else {
138         index = m_freeBlockIndices.takeLast();
139         ASSERT(!m_blocks[index]);
140         m_blocks[index] = block;
141     }
142 
143     forEachBitVector(
144         NoLockingNecessary,
<span class="line-modified">145         [&amp;] (FastBitVector&amp; vector) {</span>
<span class="line-modified">146             ASSERT_UNUSED(vector, !vector[index]);</span>
147         });
148 
149     // This is the point at which the block learns of its cellSize() and attributes().
150     block-&gt;didAddToDirectory(this, index);
151 
152     setIsLive(NoLockingNecessary, index, true);
153     setIsEmpty(NoLockingNecessary, index, true);
154 }
155 
156 void BlockDirectory::removeBlock(MarkedBlock::Handle* block)
157 {
158     ASSERT(block-&gt;directory() == this);
159     ASSERT(m_blocks[block-&gt;index()] == block);
160 
161     subspace()-&gt;didRemoveBlock(block-&gt;index());
162 
163     m_blocks[block-&gt;index()] = nullptr;
164     m_freeBlockIndices.append(block-&gt;index());
165 
166     forEachBitVector(
167         holdLock(m_bitvectorLock),
<span class="line-modified">168         [&amp;] (FastBitVector&amp; vector) {</span>
<span class="line-modified">169             vector[block-&gt;index()] = false;</span>
170         });
171 
172     block-&gt;didRemoveFromDirectory();
173 }
174 
175 void BlockDirectory::stopAllocating()
176 {
177     if (false)
178         dataLog(RawPointer(this), &quot;: BlockDirectory::stopAllocating!\n&quot;);
179     m_localAllocators.forEach(
180         [&amp;] (LocalAllocator* allocator) {
181             allocator-&gt;stopAllocating();
182         });
183 }
184 
185 void BlockDirectory::prepareForAllocation()
186 {
187     m_localAllocators.forEach(
188         [&amp;] (LocalAllocator* allocator) {
189             allocator-&gt;prepareForAllocation();
190         });
191 
192     m_unsweptCursor = 0;
193     m_emptyCursor = 0;
194 
<span class="line-modified">195     m_eden.clearAll();</span>
196 
197     if (UNLIKELY(Options::useImmortalObjects())) {
198         // FIXME: Make this work again.
199         // https://bugs.webkit.org/show_bug.cgi?id=162296
200         RELEASE_ASSERT_NOT_REACHED();
201     }
202 }
203 
204 void BlockDirectory::stopAllocatingForGood()
205 {
206     if (false)
207         dataLog(RawPointer(this), &quot;: BlockDirectory::stopAllocatingForGood!\n&quot;);
208 
209     m_localAllocators.forEach(
210         [&amp;] (LocalAllocator* allocator) {
211             allocator-&gt;stopAllocatingForGood();
212         });
213 
214     auto locker = holdLock(m_localAllocatorsLock);
215     while (!m_localAllocators.isEmpty())
</pre>
<hr />
<pre>
220 {
221     forEachBlock(
222         [&amp;] (MarkedBlock::Handle* block) {
223             block-&gt;lastChanceToFinalize();
224         });
225 }
226 
227 void BlockDirectory::resumeAllocating()
228 {
229     m_localAllocators.forEach(
230         [&amp;] (LocalAllocator* allocator) {
231             allocator-&gt;resumeAllocating();
232         });
233 }
234 
235 void BlockDirectory::beginMarkingForFullCollection()
236 {
237     // Mark bits are sticky and so is our summary of mark bits. We only clear these during full
238     // collections, so if you survived the last collection you will survive the next one so long
239     // as the next one is eden.
<span class="line-modified">240     m_markingNotEmpty.clearAll();</span>
<span class="line-modified">241     m_markingRetired.clearAll();</span>
242 }
243 
244 void BlockDirectory::endMarking()
245 {
<span class="line-modified">246     m_allocated.clearAll();</span>
247 
248     // It&#39;s surprising and frustrating to comprehend, but the end-of-marking flip does not need to
249     // know what kind of collection it is. That knowledge is already encoded in the m_markingXYZ
250     // vectors.
251 
<span class="line-modified">252     m_empty = m_live &amp; ~m_markingNotEmpty;</span>
<span class="line-modified">253     m_canAllocateButNotEmpty = m_live &amp; m_markingNotEmpty &amp; ~m_markingRetired;</span>
254 
255     if (needsDestruction()) {
256         // There are some blocks that we didn&#39;t allocate out of in the last cycle, but we swept them. This
257         // will forget that we did that and we will end up sweeping them again and attempting to call their
258         // destructors again. That&#39;s fine because of zapping. The only time when we cannot forget is when
259         // we just allocate a block or when we move a block from one size class to another. That doesn&#39;t
260         // happen here.
<span class="line-modified">261         m_destructible = m_live;</span>
262     }
263 
264     if (false) {
265         dataLog(&quot;Bits for &quot;, m_cellSize, &quot;, &quot;, m_attributes, &quot; after endMarking:\n&quot;);
266         dumpBits(WTF::dataFile());
267     }
268 }
269 
270 void BlockDirectory::snapshotUnsweptForEdenCollection()
271 {
<span class="line-modified">272     m_unswept |= m_eden;</span>
273 }
274 
275 void BlockDirectory::snapshotUnsweptForFullCollection()
276 {
<span class="line-modified">277     m_unswept = m_live;</span>
278 }
279 
280 MarkedBlock::Handle* BlockDirectory::findBlockToSweep()
281 {
<span class="line-modified">282     m_unsweptCursor = m_unswept.findBit(m_unsweptCursor, true);</span>
283     if (m_unsweptCursor &gt;= m_blocks.size())
284         return nullptr;
285     return m_blocks[m_unsweptCursor];
286 }
287 
288 void BlockDirectory::sweep()
289 {
<span class="line-modified">290     m_unswept.forEachSetBit(</span>
291         [&amp;] (size_t index) {
292             MarkedBlock::Handle* block = m_blocks[index];
293             block-&gt;sweep(nullptr);
294         });
295 }
296 
297 void BlockDirectory::shrink()
298 {
<span class="line-modified">299     (m_empty &amp; ~m_destructible).forEachSetBit(</span>
300         [&amp;] (size_t index) {
301             markedSpace().freeBlock(m_blocks[index]);
302         });
303 }
304 
305 void BlockDirectory::assertNoUnswept()
306 {
<span class="line-modified">307     if (ASSERT_DISABLED)</span>
308         return;
309 
<span class="line-modified">310     if (m_unswept.isEmpty())</span>
311         return;
312 
313     dataLog(&quot;Assertion failed: unswept not empty in &quot;, *this, &quot;.\n&quot;);
314     dumpBits();
315     ASSERT_NOT_REACHED();
316 }
317 
318 RefPtr&lt;SharedTask&lt;MarkedBlock::Handle*()&gt;&gt; BlockDirectory::parallelNotEmptyBlockSource()
319 {
320     class Task : public SharedTask&lt;MarkedBlock::Handle*()&gt; {
321     public:
322         Task(BlockDirectory&amp; directory)
323             : m_directory(directory)
324         {
325         }
326 
327         MarkedBlock::Handle* run() override
328         {
329             if (m_done)
330                 return nullptr;
331             auto locker = holdLock(m_lock);
<span class="line-modified">332             m_index = m_directory.m_markingNotEmpty.findBit(m_index, true);</span>
333             if (m_index &gt;= m_directory.m_blocks.size()) {
334                 m_done = true;
335                 return nullptr;
336             }
337             return m_directory.m_blocks[m_index++];
338         }
339 
340     private:
341         BlockDirectory&amp; m_directory;
342         size_t m_index { 0 };
343         Lock m_lock;
344         bool m_done { false };
345     };
346 
347     return adoptRef(new Task(*this));
348 }
349 
350 void BlockDirectory::dump(PrintStream&amp; out) const
351 {
352     out.print(RawPointer(this), &quot;:&quot;, m_cellSize, &quot;/&quot;, m_attributes);
353 }
354 
355 void BlockDirectory::dumpBits(PrintStream&amp; out)
356 {
357     unsigned maxNameLength = 0;
358     forEachBitVectorWithName(
359         NoLockingNecessary,
<span class="line-modified">360         [&amp;] (FastBitVector&amp;, const char* name) {</span>

361             unsigned length = strlen(name);
362             maxNameLength = std::max(maxNameLength, length);
363         });
364 
365     forEachBitVectorWithName(
366         NoLockingNecessary,
<span class="line-modified">367         [&amp;] (FastBitVector&amp; vector, const char* name) {</span>
368             out.print(&quot;    &quot;, name, &quot;: &quot;);
369             for (unsigned i = maxNameLength - strlen(name); i--;)
370                 out.print(&quot; &quot;);
<span class="line-modified">371             out.print(vector, &quot;\n&quot;);</span>
372         });
373 }
374 
375 MarkedSpace&amp; BlockDirectory::markedSpace() const
376 {
377     return m_subspace-&gt;space();
378 }
379 
380 bool BlockDirectory::isFreeListedCell(const void* target)
381 {
382     bool result = false;
383     m_localAllocators.forEach(
384         [&amp;] (LocalAllocator* allocator) {
385             result |= allocator-&gt;isFreeListedCell(target);
386         });
387     return result;
388 }
389 
390 } // namespace JSC
391 
</pre>
</td>
<td>
<hr />
<pre>
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;BlockDirectory.h&quot;
 28 
 29 #include &quot;BlockDirectoryInlines.h&quot;
 30 #include &quot;GCActivityCallback.h&quot;
 31 #include &quot;Heap.h&quot;
 32 #include &quot;IncrementalSweeper.h&quot;
 33 #include &quot;JSCInlines.h&quot;
 34 #include &quot;MarkedBlockInlines.h&quot;
 35 #include &quot;SubspaceInlines.h&quot;
 36 #include &quot;SuperSampler.h&quot;
 37 #include &quot;VM.h&quot;
 38 
 39 namespace JSC {
 40 
<span class="line-modified"> 41 DEFINE_ALLOCATOR_WITH_HEAP_IDENTIFIER(BlockDirectory);</span>
<span class="line-added"> 42 </span>
<span class="line-added"> 43 BlockDirectory::BlockDirectory(size_t cellSize)</span>
 44     : m_cellSize(static_cast&lt;unsigned&gt;(cellSize))

 45 {
 46 }
 47 
 48 BlockDirectory::~BlockDirectory()
 49 {
 50     auto locker = holdLock(m_localAllocatorsLock);
 51     while (!m_localAllocators.isEmpty())
 52         m_localAllocators.begin()-&gt;remove();
 53 }
 54 
 55 void BlockDirectory::setSubspace(Subspace* subspace)
 56 {
 57     m_attributes = subspace-&gt;attributes();
 58     m_subspace = subspace;
 59 }
 60 
 61 bool BlockDirectory::isPagedOut(MonotonicTime deadline)
 62 {
 63     unsigned itersSinceLastTimeCheck = 0;
 64     for (auto* block : m_blocks) {
 65         if (block)
 66             block-&gt;block().populatePage();
 67         ++itersSinceLastTimeCheck;
 68         if (itersSinceLastTimeCheck &gt;= Heap::s_timeCheckResolution) {
 69             MonotonicTime currentTime = MonotonicTime::now();
 70             if (currentTime &gt; deadline)
 71                 return true;
 72             itersSinceLastTimeCheck = 0;
 73         }
 74     }
 75     return false;
 76 }
 77 
 78 MarkedBlock::Handle* BlockDirectory::findEmptyBlockToSteal()
 79 {
<span class="line-modified"> 80     m_emptyCursor = m_bits.empty().findBit(m_emptyCursor, true);</span>
 81     if (m_emptyCursor &gt;= m_blocks.size())
 82         return nullptr;
 83     return m_blocks[m_emptyCursor];
 84 }
 85 
 86 MarkedBlock::Handle* BlockDirectory::findBlockForAllocation(LocalAllocator&amp; allocator)
 87 {
 88     for (;;) {
<span class="line-modified"> 89         allocator.m_allocationCursor = (m_bits.canAllocateButNotEmpty() | m_bits.empty()).findBit(allocator.m_allocationCursor, true);</span>
 90         if (allocator.m_allocationCursor &gt;= m_blocks.size())
 91             return nullptr;
 92 
<span class="line-modified"> 93         unsigned blockIndex = allocator.m_allocationCursor++;</span>
 94         MarkedBlock::Handle* result = m_blocks[blockIndex];
 95         setIsCanAllocateButNotEmpty(NoLockingNecessary, blockIndex, false);
 96         return result;
 97     }
 98 }
 99 
<span class="line-modified">100 MarkedBlock::Handle* BlockDirectory::tryAllocateBlock(Heap&amp; heap)</span>
101 {
102     SuperSamplerScope superSamplerScope(false);
103 
<span class="line-modified">104     MarkedBlock::Handle* handle = MarkedBlock::tryCreate(heap, subspace()-&gt;alignedMemoryAllocator());</span>
105     if (!handle)
106         return nullptr;
107 
108     markedSpace().didAddBlock(handle);
109 
110     return handle;
111 }
112 
113 void BlockDirectory::addBlock(MarkedBlock::Handle* block)
114 {
<span class="line-modified">115     unsigned index;</span>
116     if (m_freeBlockIndices.isEmpty()) {
117         index = m_blocks.size();
118 
119         size_t oldCapacity = m_blocks.capacity();
120         m_blocks.append(block);
121         if (m_blocks.capacity() != oldCapacity) {
<span class="line-modified">122             ASSERT(m_bits.numBits() == oldCapacity);</span>





123             ASSERT(m_blocks.capacity() &gt; oldCapacity);
124 
125             LockHolder locker(m_bitvectorLock);
126             subspace()-&gt;didResizeBits(m_blocks.capacity());
<span class="line-modified">127             m_bits.resize(m_blocks.capacity());</span>




128         }
129     } else {
130         index = m_freeBlockIndices.takeLast();
131         ASSERT(!m_blocks[index]);
132         m_blocks[index] = block;
133     }
134 
135     forEachBitVector(
136         NoLockingNecessary,
<span class="line-modified">137         [&amp;](auto vectorRef) {</span>
<span class="line-modified">138             ASSERT_UNUSED(vectorRef, !vectorRef[index]);</span>
139         });
140 
141     // This is the point at which the block learns of its cellSize() and attributes().
142     block-&gt;didAddToDirectory(this, index);
143 
144     setIsLive(NoLockingNecessary, index, true);
145     setIsEmpty(NoLockingNecessary, index, true);
146 }
147 
148 void BlockDirectory::removeBlock(MarkedBlock::Handle* block)
149 {
150     ASSERT(block-&gt;directory() == this);
151     ASSERT(m_blocks[block-&gt;index()] == block);
152 
153     subspace()-&gt;didRemoveBlock(block-&gt;index());
154 
155     m_blocks[block-&gt;index()] = nullptr;
156     m_freeBlockIndices.append(block-&gt;index());
157 
158     forEachBitVector(
159         holdLock(m_bitvectorLock),
<span class="line-modified">160         [&amp;](auto vectorRef) {</span>
<span class="line-modified">161             vectorRef[block-&gt;index()] = false;</span>
162         });
163 
164     block-&gt;didRemoveFromDirectory();
165 }
166 
167 void BlockDirectory::stopAllocating()
168 {
169     if (false)
170         dataLog(RawPointer(this), &quot;: BlockDirectory::stopAllocating!\n&quot;);
171     m_localAllocators.forEach(
172         [&amp;] (LocalAllocator* allocator) {
173             allocator-&gt;stopAllocating();
174         });
175 }
176 
177 void BlockDirectory::prepareForAllocation()
178 {
179     m_localAllocators.forEach(
180         [&amp;] (LocalAllocator* allocator) {
181             allocator-&gt;prepareForAllocation();
182         });
183 
184     m_unsweptCursor = 0;
185     m_emptyCursor = 0;
186 
<span class="line-modified">187     m_bits.eden().clearAll();</span>
188 
189     if (UNLIKELY(Options::useImmortalObjects())) {
190         // FIXME: Make this work again.
191         // https://bugs.webkit.org/show_bug.cgi?id=162296
192         RELEASE_ASSERT_NOT_REACHED();
193     }
194 }
195 
196 void BlockDirectory::stopAllocatingForGood()
197 {
198     if (false)
199         dataLog(RawPointer(this), &quot;: BlockDirectory::stopAllocatingForGood!\n&quot;);
200 
201     m_localAllocators.forEach(
202         [&amp;] (LocalAllocator* allocator) {
203             allocator-&gt;stopAllocatingForGood();
204         });
205 
206     auto locker = holdLock(m_localAllocatorsLock);
207     while (!m_localAllocators.isEmpty())
</pre>
<hr />
<pre>
212 {
213     forEachBlock(
214         [&amp;] (MarkedBlock::Handle* block) {
215             block-&gt;lastChanceToFinalize();
216         });
217 }
218 
219 void BlockDirectory::resumeAllocating()
220 {
221     m_localAllocators.forEach(
222         [&amp;] (LocalAllocator* allocator) {
223             allocator-&gt;resumeAllocating();
224         });
225 }
226 
227 void BlockDirectory::beginMarkingForFullCollection()
228 {
229     // Mark bits are sticky and so is our summary of mark bits. We only clear these during full
230     // collections, so if you survived the last collection you will survive the next one so long
231     // as the next one is eden.
<span class="line-modified">232     m_bits.markingNotEmpty().clearAll();</span>
<span class="line-modified">233     m_bits.markingRetired().clearAll();</span>
234 }
235 
236 void BlockDirectory::endMarking()
237 {
<span class="line-modified">238     m_bits.allocated().clearAll();</span>
239 
240     // It&#39;s surprising and frustrating to comprehend, but the end-of-marking flip does not need to
241     // know what kind of collection it is. That knowledge is already encoded in the m_markingXYZ
242     // vectors.
243 
<span class="line-modified">244     m_bits.empty() = m_bits.live() &amp; ~m_bits.markingNotEmpty();</span>
<span class="line-modified">245     m_bits.canAllocateButNotEmpty() = m_bits.live() &amp; m_bits.markingNotEmpty() &amp; ~m_bits.markingRetired();</span>
246 
247     if (needsDestruction()) {
248         // There are some blocks that we didn&#39;t allocate out of in the last cycle, but we swept them. This
249         // will forget that we did that and we will end up sweeping them again and attempting to call their
250         // destructors again. That&#39;s fine because of zapping. The only time when we cannot forget is when
251         // we just allocate a block or when we move a block from one size class to another. That doesn&#39;t
252         // happen here.
<span class="line-modified">253         m_bits.destructible() = m_bits.live();</span>
254     }
255 
256     if (false) {
257         dataLog(&quot;Bits for &quot;, m_cellSize, &quot;, &quot;, m_attributes, &quot; after endMarking:\n&quot;);
258         dumpBits(WTF::dataFile());
259     }
260 }
261 
262 void BlockDirectory::snapshotUnsweptForEdenCollection()
263 {
<span class="line-modified">264     m_bits.unswept() |= m_bits.eden();</span>
265 }
266 
267 void BlockDirectory::snapshotUnsweptForFullCollection()
268 {
<span class="line-modified">269     m_bits.unswept() = m_bits.live();</span>
270 }
271 
272 MarkedBlock::Handle* BlockDirectory::findBlockToSweep()
273 {
<span class="line-modified">274     m_unsweptCursor = m_bits.unswept().findBit(m_unsweptCursor, true);</span>
275     if (m_unsweptCursor &gt;= m_blocks.size())
276         return nullptr;
277     return m_blocks[m_unsweptCursor];
278 }
279 
280 void BlockDirectory::sweep()
281 {
<span class="line-modified">282     m_bits.unswept().forEachSetBit(</span>
283         [&amp;] (size_t index) {
284             MarkedBlock::Handle* block = m_blocks[index];
285             block-&gt;sweep(nullptr);
286         });
287 }
288 
289 void BlockDirectory::shrink()
290 {
<span class="line-modified">291     (m_bits.empty() &amp; ~m_bits.destructible()).forEachSetBit(</span>
292         [&amp;] (size_t index) {
293             markedSpace().freeBlock(m_blocks[index]);
294         });
295 }
296 
297 void BlockDirectory::assertNoUnswept()
298 {
<span class="line-modified">299     if (!ASSERT_ENABLED)</span>
300         return;
301 
<span class="line-modified">302     if (m_bits.unswept().isEmpty())</span>
303         return;
304 
305     dataLog(&quot;Assertion failed: unswept not empty in &quot;, *this, &quot;.\n&quot;);
306     dumpBits();
307     ASSERT_NOT_REACHED();
308 }
309 
310 RefPtr&lt;SharedTask&lt;MarkedBlock::Handle*()&gt;&gt; BlockDirectory::parallelNotEmptyBlockSource()
311 {
312     class Task : public SharedTask&lt;MarkedBlock::Handle*()&gt; {
313     public:
314         Task(BlockDirectory&amp; directory)
315             : m_directory(directory)
316         {
317         }
318 
319         MarkedBlock::Handle* run() override
320         {
321             if (m_done)
322                 return nullptr;
323             auto locker = holdLock(m_lock);
<span class="line-modified">324             m_index = m_directory.m_bits.markingNotEmpty().findBit(m_index, true);</span>
325             if (m_index &gt;= m_directory.m_blocks.size()) {
326                 m_done = true;
327                 return nullptr;
328             }
329             return m_directory.m_blocks[m_index++];
330         }
331 
332     private:
333         BlockDirectory&amp; m_directory;
334         size_t m_index { 0 };
335         Lock m_lock;
336         bool m_done { false };
337     };
338 
339     return adoptRef(new Task(*this));
340 }
341 
342 void BlockDirectory::dump(PrintStream&amp; out) const
343 {
344     out.print(RawPointer(this), &quot;:&quot;, m_cellSize, &quot;/&quot;, m_attributes);
345 }
346 
347 void BlockDirectory::dumpBits(PrintStream&amp; out)
348 {
349     unsigned maxNameLength = 0;
350     forEachBitVectorWithName(
351         NoLockingNecessary,
<span class="line-modified">352         [&amp;](auto vectorRef, const char* name) {</span>
<span class="line-added">353             UNUSED_PARAM(vectorRef);</span>
354             unsigned length = strlen(name);
355             maxNameLength = std::max(maxNameLength, length);
356         });
357 
358     forEachBitVectorWithName(
359         NoLockingNecessary,
<span class="line-modified">360         [&amp;](auto vectorRef, const char* name) {</span>
361             out.print(&quot;    &quot;, name, &quot;: &quot;);
362             for (unsigned i = maxNameLength - strlen(name); i--;)
363                 out.print(&quot; &quot;);
<span class="line-modified">364             out.print(vectorRef, &quot;\n&quot;);</span>
365         });
366 }
367 
368 MarkedSpace&amp; BlockDirectory::markedSpace() const
369 {
370     return m_subspace-&gt;space();
371 }
372 
373 bool BlockDirectory::isFreeListedCell(const void* target)
374 {
375     bool result = false;
376     m_localAllocators.forEach(
377         [&amp;] (LocalAllocator* allocator) {
378             result |= allocator-&gt;isFreeListedCell(target);
379         });
380     return result;
381 }
382 
383 } // namespace JSC
384 
</pre>
</td>
</tr>
</table>
<center><a href="AtomIndices.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="BlockDirectory.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>