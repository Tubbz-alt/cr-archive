diff a/modules/javafx.web/src/main/native/Source/JavaScriptCore/ftl/FTLThunks.cpp b/modules/javafx.web/src/main/native/Source/JavaScriptCore/ftl/FTLThunks.cpp
--- a/modules/javafx.web/src/main/native/Source/JavaScriptCore/ftl/FTLThunks.cpp
+++ b/modules/javafx.web/src/main/native/Source/JavaScriptCore/ftl/FTLThunks.cpp
@@ -84,10 +84,11 @@
 
     jit.loadPtr(GPRInfo::callFrameRegister, GPRInfo::argumentGPR0);
     jit.peek(
         GPRInfo::argumentGPR1,
         (stackMisalignment - MacroAssembler::pushToSaveByteOffset()) / sizeof(void*));
+    jit.prepareCallOperation(vm);
     MacroAssembler::Call functionCall = jit.call(OperationPtrTag);
 
     // At this point we want to make a tail call to what was returned to us in the
     // returnValueGPR. But at the same time as we do this, we must restore all registers.
     // The way we will accomplish this is by arranging to have the tail call target in the
@@ -130,18 +131,18 @@
 
 MacroAssemblerCodeRef<JITThunkPtrTag> osrExitGenerationThunkGenerator(VM& vm)
 {
     unsigned extraPopsToRestore = 0;
     return genericGenerationThunkGenerator(
-        vm, compileFTLOSRExit, OSRExitPtrTag, "FTL OSR exit generation thunk", extraPopsToRestore, FrameAndStackAdjustmentRequirement::Needed);
+        vm, operationCompileFTLOSRExit, OSRExitPtrTag, "FTL OSR exit generation thunk", extraPopsToRestore, FrameAndStackAdjustmentRequirement::Needed);
 }
 
 MacroAssemblerCodeRef<JITThunkPtrTag> lazySlowPathGenerationThunkGenerator(VM& vm)
 {
     unsigned extraPopsToRestore = 1;
     return genericGenerationThunkGenerator(
-        vm, compileFTLLazySlowPath, JITStubRoutinePtrTag, "FTL lazy slow path generation thunk", extraPopsToRestore, FrameAndStackAdjustmentRequirement::NotNeeded);
+        vm, operationCompileFTLLazySlowPath, JITStubRoutinePtrTag, "FTL lazy slow path generation thunk", extraPopsToRestore, FrameAndStackAdjustmentRequirement::NotNeeded);
 }
 
 static void registerClobberCheck(AssemblyHelpers& jit, RegisterSet dontClobber)
 {
     if (!Options::clobberAllRegsInFTLICSlowPath())
@@ -151,11 +152,11 @@
     clobber.exclude(RegisterSet::reservedHardwareRegisters());
     clobber.exclude(RegisterSet::stackRegisters());
     clobber.exclude(RegisterSet::calleeSaveRegisters());
     clobber.exclude(dontClobber);
 
-    GPRReg someGPR;
+    GPRReg someGPR = InvalidGPRReg;
     for (Reg reg = Reg::first(); reg <= Reg::last(); reg = reg.next()) {
         if (!clobber.get(reg) || !reg.isGPR())
             continue;
 
         jit.move(AssemblyHelpers::TrustedImm32(0x1337beef), reg.gpr());
@@ -168,22 +169,22 @@
 
         jit.move64ToDouble(someGPR, reg.fpr());
     }
 }
 
-MacroAssemblerCodeRef<JITThunkPtrTag> slowPathCallThunkGenerator(const SlowPathCallKey& key)
+MacroAssemblerCodeRef<JITThunkPtrTag> slowPathCallThunkGenerator(VM& vm, const SlowPathCallKey& key)
 {
     AssemblyHelpers jit(nullptr);
     jit.tagReturnAddress();
 
     // We want to save the given registers at the given offset, then we want to save the
     // old return address somewhere past that offset, and then finally we want to make the
     // call.
 
     size_t currentOffset = key.offset() + sizeof(void*);
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
     currentOffset += sizeof(void*);
 #endif
 
     for (MacroAssembler::RegisterID reg = MacroAssembler::firstRegister(); reg <= MacroAssembler::lastRegister(); reg = static_cast<MacroAssembler::RegisterID>(reg + 1)) {
         if (!key.usedRegisters().get(reg))
@@ -199,10 +200,11 @@
         currentOffset += sizeof(double);
     }
 
     jit.preserveReturnAddressAfterCall(GPRInfo::nonArgGPR0);
     jit.storePtr(GPRInfo::nonArgGPR0, AssemblyHelpers::Address(MacroAssembler::stackPointerRegister, key.offset()));
+    jit.prepareCallOperation(vm);
 
     registerClobberCheck(jit, key.argumentRegisters());
 
     AssemblyHelpers::Call call = jit.call(OperationPtrTag);
 
