<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JITInlines.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="JITInlineCacheGenerator.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="JITLeftShiftGenerator.cpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JITInlines.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 24,26 ***</span>
   */
  
  #pragma once
  
  #if ENABLE(JIT)
  #include &quot;JSCInlines.h&quot;
  
  namespace JSC {
  
<span class="line-removed">- inline MacroAssembler::JumpList JIT::emitDoubleGetByVal(const Instruction* instruction, PatchableJump&amp; badType)</span>
<span class="line-removed">- {</span>
<span class="line-removed">- #if USE(JSVALUE64)</span>
<span class="line-removed">-     JSValueRegs result = JSValueRegs(regT0);</span>
<span class="line-removed">- #else</span>
<span class="line-removed">-     JSValueRegs result = JSValueRegs(regT1, regT0);</span>
<span class="line-removed">- #endif</span>
<span class="line-removed">-     JumpList slowCases = emitDoubleLoad(instruction, badType);</span>
<span class="line-removed">-     boxDouble(fpRegT0, result);</span>
<span class="line-removed">-     return slowCases;</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
  ALWAYS_INLINE MacroAssembler::JumpList JIT::emitLoadForArrayMode(const Instruction* currentInstruction, JITArrayMode arrayMode, PatchableJump&amp; badType)
  {
      switch (arrayMode) {
      case JITInt32:
          return emitInt32Load(currentInstruction, badType);
<span class="line-new-header">--- 24,15 ---</span>
   */
  
  #pragma once
  
  #if ENABLE(JIT)
<span class="line-added">+ #include &quot;CommonSlowPathsInlines.h&quot;</span>
  #include &quot;JSCInlines.h&quot;
  
  namespace JSC {
  
  ALWAYS_INLINE MacroAssembler::JumpList JIT::emitLoadForArrayMode(const Instruction* currentInstruction, JITArrayMode arrayMode, PatchableJump&amp; badType)
  {
      switch (arrayMode) {
      case JITInt32:
          return emitInt32Load(currentInstruction, badType);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 58,33 ***</span>
      }
      RELEASE_ASSERT_NOT_REACHED();
      return MacroAssembler::JumpList();
  }
  
<span class="line-modified">! inline MacroAssembler::JumpList JIT::emitContiguousGetByVal(const Instruction* instruction, PatchableJump&amp; badType, IndexingType expectedShape)</span>
  {
<span class="line-modified">!     return emitContiguousLoad(instruction, badType, expectedShape);</span>
  }
  
<span class="line-modified">! inline MacroAssembler::JumpList JIT::emitArrayStorageGetByVal(const Instruction* instruction, PatchableJump&amp; badType)</span>
  {
<span class="line-modified">!     return emitArrayStorageLoad(instruction, badType);</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- ALWAYS_INLINE bool JIT::isOperandConstantDouble(int src)</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     return m_codeBlock-&gt;isConstantRegisterIndex(src) &amp;&amp; getConstantOperand(src).isDouble();</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- ALWAYS_INLINE JSValue JIT::getConstantOperand(int src)</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     ASSERT(m_codeBlock-&gt;isConstantRegisterIndex(src));</span>
      return m_codeBlock-&gt;getConstant(src);
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitPutIntToCallFrameHeader(RegisterID from, int entry)</span>
  {
  #if USE(JSVALUE32_64)
      store32(TrustedImm32(JSValue::Int32Tag), tagFor(entry));
      store32(from, payloadFor(entry));
  #else
      store64(from, addressFor(entry));
<span class="line-new-header">--- 47,24 ---</span>
      }
      RELEASE_ASSERT_NOT_REACHED();
      return MacroAssembler::JumpList();
  }
  
<span class="line-modified">! ALWAYS_INLINE bool JIT::isOperandConstantDouble(VirtualRegister src)</span>
  {
<span class="line-modified">!     return src.isConstant() &amp;&amp; getConstantOperand(src).isDouble();</span>
  }
  
<span class="line-modified">! ALWAYS_INLINE JSValue JIT::getConstantOperand(VirtualRegister src)</span>
  {
<span class="line-modified">!     ASSERT(src.isConstant());</span>
      return m_codeBlock-&gt;getConstant(src);
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitPutIntToCallFrameHeader(RegisterID from, VirtualRegister entry)</span>
  {
<span class="line-added">+     ASSERT(entry.isHeader());</span>
  #if USE(JSVALUE32_64)
      store32(TrustedImm32(JSValue::Int32Tag), tagFor(entry));
      store32(from, payloadFor(entry));
  #else
      store64(from, addressFor(entry));
</pre>
<hr />
<pre>
<span class="line-old-header">*** 95,49 ***</span>
  {
      failures.append(branchIfNotString(src));
      loadPtr(MacroAssembler::Address(src, JSString::offsetOfValue()), dst);
      failures.append(branchIfRopeStringImpl(dst));
      failures.append(branch32(NotEqual, MacroAssembler::Address(dst, StringImpl::lengthMemoryOffset()), TrustedImm32(1)));
<span class="line-modified">!     loadPtr(MacroAssembler::Address(dst, StringImpl::flagsOffset()), regT1);</span>
<span class="line-modified">!     loadPtr(MacroAssembler::Address(dst, StringImpl::dataOffset()), dst);</span>
<span class="line-modified">! </span>
<span class="line-modified">!     JumpList is16Bit;</span>
<span class="line-modified">!     JumpList cont8Bit;</span>
<span class="line-removed">-     is16Bit.append(branchTest32(Zero, regT1, TrustedImm32(StringImpl::flagIs8Bit())));</span>
<span class="line-removed">-     load8(MacroAssembler::Address(dst, 0), dst);</span>
<span class="line-removed">-     cont8Bit.append(jump());</span>
      is16Bit.link(this);
<span class="line-modified">!     load16(MacroAssembler::Address(dst, 0), dst);</span>
<span class="line-modified">!     cont8Bit.link(this);</span>
  }
  
  ALWAYS_INLINE JIT::Call JIT::emitNakedCall(CodePtr&lt;NoPtrTag&gt; target)
  {
<span class="line-modified">!     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
      Call nakedCall = nearCall();
<span class="line-modified">!     m_calls.append(CallRecord(nakedCall, m_bytecodeOffset, FunctionPtr&lt;OperationPtrTag&gt;(target.retagged&lt;OperationPtrTag&gt;())));</span>
      return nakedCall;
  }
  
  ALWAYS_INLINE JIT::Call JIT::emitNakedTailCall(CodePtr&lt;NoPtrTag&gt; target)
  {
<span class="line-modified">!     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
      Call nakedCall = nearTailCall();
<span class="line-modified">!     m_calls.append(CallRecord(nakedCall, m_bytecodeOffset, FunctionPtr&lt;OperationPtrTag&gt;(target.retagged&lt;OperationPtrTag&gt;())));</span>
      return nakedCall;
  }
  
  ALWAYS_INLINE void JIT::updateTopCallFrame()
  {
<span class="line-modified">!     ASSERT(static_cast&lt;int&gt;(m_bytecodeOffset) &gt;= 0);</span>
<span class="line-modified">! #if USE(JSVALUE32_64)</span>
<span class="line-removed">-     const Instruction* instruction = m_codeBlock-&gt;instructions().at(m_bytecodeOffset).ptr();</span>
<span class="line-removed">-     uint32_t locationBits = CallSiteIndex(instruction).bits();</span>
<span class="line-removed">- #else</span>
<span class="line-removed">-     uint32_t locationBits = CallSiteIndex(m_bytecodeOffset).bits();</span>
<span class="line-removed">- #endif</span>
<span class="line-removed">-     store32(TrustedImm32(locationBits), tagFor(CallFrameSlot::argumentCount));</span>
  
      // FIXME: It&#39;s not clear that this is needed. JITOperations tend to update the top call frame on
      // the C++ side.
      // https://bugs.webkit.org/show_bug.cgi?id=155693
      storePtr(callFrameRegister, &amp;m_vm-&gt;topCallFrame);
<span class="line-new-header">--- 75,40 ---</span>
  {
      failures.append(branchIfNotString(src));
      loadPtr(MacroAssembler::Address(src, JSString::offsetOfValue()), dst);
      failures.append(branchIfRopeStringImpl(dst));
      failures.append(branch32(NotEqual, MacroAssembler::Address(dst, StringImpl::lengthMemoryOffset()), TrustedImm32(1)));
<span class="line-modified">!     loadPtr(MacroAssembler::Address(dst, StringImpl::dataOffset()), regT1);</span>
<span class="line-modified">! </span>
<span class="line-modified">!     auto is16Bit = branchTest32(Zero, Address(dst, StringImpl::flagsOffset()), TrustedImm32(StringImpl::flagIs8Bit()));</span>
<span class="line-modified">!     load8(MacroAssembler::Address(regT1, 0), dst);</span>
<span class="line-modified">!     auto done = jump();</span>
      is16Bit.link(this);
<span class="line-modified">!     load16(MacroAssembler::Address(regT1, 0), dst);</span>
<span class="line-modified">!     done.link(this);</span>
  }
  
  ALWAYS_INLINE JIT::Call JIT::emitNakedCall(CodePtr&lt;NoPtrTag&gt; target)
  {
<span class="line-modified">!     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
      Call nakedCall = nearCall();
<span class="line-modified">!     m_calls.append(CallRecord(nakedCall, m_bytecodeIndex, FunctionPtr&lt;OperationPtrTag&gt;(target.retagged&lt;OperationPtrTag&gt;())));</span>
      return nakedCall;
  }
  
  ALWAYS_INLINE JIT::Call JIT::emitNakedTailCall(CodePtr&lt;NoPtrTag&gt; target)
  {
<span class="line-modified">!     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
      Call nakedCall = nearTailCall();
<span class="line-modified">!     m_calls.append(CallRecord(nakedCall, m_bytecodeIndex, FunctionPtr&lt;OperationPtrTag&gt;(target.retagged&lt;OperationPtrTag&gt;())));</span>
      return nakedCall;
  }
  
  ALWAYS_INLINE void JIT::updateTopCallFrame()
  {
<span class="line-modified">!     uint32_t locationBits = CallSiteIndex(m_bytecodeIndex).bits();</span>
<span class="line-modified">!     store32(TrustedImm32(locationBits), tagFor(CallFrameSlot::argumentCountIncludingThis));</span>
  
      // FIXME: It&#39;s not clear that this is needed. JITOperations tend to update the top call frame on
      // the C++ side.
      // https://bugs.webkit.org/show_bug.cgi?id=155693
      storePtr(callFrameRegister, &amp;m_vm-&gt;topCallFrame);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 167,11 ***</span>
      MacroAssembler::Call call = appendCall(function);
      exceptionCheckWithCallFrameRollback();
      return call;
  }
  
<span class="line-modified">! ALWAYS_INLINE MacroAssembler::Call JIT::appendCallWithExceptionCheckSetJSValueResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, int dst)</span>
  {
      MacroAssembler::Call call = appendCallWithExceptionCheck(function);
  #if USE(JSVALUE64)
      emitPutVirtualRegister(dst, returnValueGPR);
  #else
<span class="line-new-header">--- 138,11 ---</span>
      MacroAssembler::Call call = appendCall(function);
      exceptionCheckWithCallFrameRollback();
      return call;
  }
  
<span class="line-modified">! ALWAYS_INLINE MacroAssembler::Call JIT::appendCallWithExceptionCheckSetJSValueResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, VirtualRegister dst)</span>
  {
      MacroAssembler::Call call = appendCallWithExceptionCheck(function);
  #if USE(JSVALUE64)
      emitPutVirtualRegister(dst, returnValueGPR);
  #else
</pre>
<hr />
<pre>
<span class="line-old-header">*** 179,11 ***</span>
  #endif
      return call;
  }
  
  template&lt;typename Metadata&gt;
<span class="line-modified">! ALWAYS_INLINE MacroAssembler::Call JIT::appendCallWithExceptionCheckSetJSValueResultWithProfile(Metadata&amp; metadata, const FunctionPtr&lt;CFunctionPtrTag&gt; function, int dst)</span>
  {
      MacroAssembler::Call call = appendCallWithExceptionCheck(function);
      emitValueProfilingSite(metadata);
  #if USE(JSVALUE64)
      emitPutVirtualRegister(dst, returnValueGPR);
<span class="line-new-header">--- 150,11 ---</span>
  #endif
      return call;
  }
  
  template&lt;typename Metadata&gt;
<span class="line-modified">! ALWAYS_INLINE MacroAssembler::Call JIT::appendCallWithExceptionCheckSetJSValueResultWithProfile(Metadata&amp; metadata, const FunctionPtr&lt;CFunctionPtrTag&gt; function, VirtualRegister dst)</span>
  {
      MacroAssembler::Call call = appendCallWithExceptionCheck(function);
      emitValueProfilingSite(metadata);
  #if USE(JSVALUE64)
      emitPutVirtualRegister(dst, returnValueGPR);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 191,65 ***</span>
      emitStore(dst, returnValueGPR2, returnValueGPR);
  #endif
      return call;
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::linkSlowCaseIfNotJSCell(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter, int vReg)</span>
  {
<span class="line-modified">!     if (!m_codeBlock-&gt;isKnownNotImmediate(vReg))</span>
          linkSlowCase(iter);
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::linkAllSlowCasesForBytecodeOffset(Vector&lt;SlowCaseEntry&gt;&amp; slowCases, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter, unsigned bytecodeOffset)</span>
  {
<span class="line-modified">!     while (iter != slowCases.end() &amp;&amp; iter-&gt;to == bytecodeOffset)</span>
          linkSlowCase(iter);
  }
  
  ALWAYS_INLINE void JIT::addSlowCase(Jump jump)
  {
<span class="line-modified">!     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
  
<span class="line-modified">!     m_slowCases.append(SlowCaseEntry(jump, m_bytecodeOffset));</span>
  }
  
  ALWAYS_INLINE void JIT::addSlowCase(const JumpList&amp; jumpList)
  {
<span class="line-modified">!     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
  
      for (const Jump&amp; jump : jumpList.jumps())
<span class="line-modified">!         m_slowCases.append(SlowCaseEntry(jump, m_bytecodeOffset));</span>
  }
  
  ALWAYS_INLINE void JIT::addSlowCase()
  {
<span class="line-modified">!     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
  
      Jump emptyJump; // Doing it this way to make Windows happy.
<span class="line-modified">!     m_slowCases.append(SlowCaseEntry(emptyJump, m_bytecodeOffset));</span>
  }
  
  ALWAYS_INLINE void JIT::addJump(Jump jump, int relativeOffset)
  {
<span class="line-modified">!     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
  
<span class="line-modified">!     m_jmpTable.append(JumpTable(jump, m_bytecodeOffset + relativeOffset));</span>
  }
  
  ALWAYS_INLINE void JIT::addJump(const JumpList&amp; jumpList, int relativeOffset)
  {
<span class="line-modified">!     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
  
      for (auto&amp; jump : jumpList.jumps())
          addJump(jump, relativeOffset);
  }
  
  ALWAYS_INLINE void JIT::emitJumpSlowToHot(Jump jump, int relativeOffset)
  {
<span class="line-modified">!     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
  
<span class="line-modified">!     jump.linkTo(m_labels[m_bytecodeOffset + relativeOffset], this);</span>
  }
  
  #if ENABLE(SAMPLING_FLAGS)
  ALWAYS_INLINE void JIT::setSamplingFlag(int32_t flag)
  {
<span class="line-new-header">--- 162,72 ---</span>
      emitStore(dst, returnValueGPR2, returnValueGPR);
  #endif
      return call;
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::linkSlowCaseIfNotJSCell(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter, VirtualRegister reg)</span>
  {
<span class="line-modified">!     if (!m_codeBlock-&gt;isKnownNotImmediate(reg))</span>
          linkSlowCase(iter);
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::linkAllSlowCasesForBytecodeIndex(Vector&lt;SlowCaseEntry&gt;&amp; slowCases, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter, BytecodeIndex bytecodeIndex)</span>
  {
<span class="line-modified">!     while (iter != slowCases.end() &amp;&amp; iter-&gt;to == bytecodeIndex)</span>
          linkSlowCase(iter);
  }
  
<span class="line-added">+ ALWAYS_INLINE bool JIT::hasAnySlowCases(Vector&lt;SlowCaseEntry&gt;&amp; slowCases, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter, BytecodeIndex bytecodeIndex)</span>
<span class="line-added">+ {</span>
<span class="line-added">+     if (iter != slowCases.end() &amp;&amp; iter-&gt;to == bytecodeIndex)</span>
<span class="line-added">+         return true;</span>
<span class="line-added">+     return false;</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  ALWAYS_INLINE void JIT::addSlowCase(Jump jump)
  {
<span class="line-modified">!     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
  
<span class="line-modified">!     m_slowCases.append(SlowCaseEntry(jump, m_bytecodeIndex));</span>
  }
  
  ALWAYS_INLINE void JIT::addSlowCase(const JumpList&amp; jumpList)
  {
<span class="line-modified">!     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
  
      for (const Jump&amp; jump : jumpList.jumps())
<span class="line-modified">!         m_slowCases.append(SlowCaseEntry(jump, m_bytecodeIndex));</span>
  }
  
  ALWAYS_INLINE void JIT::addSlowCase()
  {
<span class="line-modified">!     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
  
      Jump emptyJump; // Doing it this way to make Windows happy.
<span class="line-modified">!     m_slowCases.append(SlowCaseEntry(emptyJump, m_bytecodeIndex));</span>
  }
  
  ALWAYS_INLINE void JIT::addJump(Jump jump, int relativeOffset)
  {
<span class="line-modified">!     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
  
<span class="line-modified">!     m_jmpTable.append(JumpTable(jump, m_bytecodeIndex.offset() + relativeOffset));</span>
  }
  
  ALWAYS_INLINE void JIT::addJump(const JumpList&amp; jumpList, int relativeOffset)
  {
<span class="line-modified">!     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
  
      for (auto&amp; jump : jumpList.jumps())
          addJump(jump, relativeOffset);
  }
  
  ALWAYS_INLINE void JIT::emitJumpSlowToHot(Jump jump, int relativeOffset)
  {
<span class="line-modified">!     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
  
<span class="line-modified">!     jump.linkTo(m_labels[m_bytecodeIndex.offset() + relativeOffset], this);</span>
  }
  
  #if ENABLE(SAMPLING_FLAGS)
  ALWAYS_INLINE void JIT::setSamplingFlag(int32_t flag)
  {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 301,13 ***</span>
      storePtr(TrustedImmPtr(codeBlock), m_interpreter-&gt;sampler()-&gt;codeBlockSlot());
  }
  #endif
  #endif
  
<span class="line-modified">! ALWAYS_INLINE bool JIT::isOperandConstantChar(int src)</span>
  {
<span class="line-modified">!     return m_codeBlock-&gt;isConstantRegisterIndex(src) &amp;&amp; getConstantOperand(src).isString() &amp;&amp; asString(getConstantOperand(src).asCell())-&gt;length() == 1;</span>
  }
  
  inline void JIT::emitValueProfilingSite(ValueProfile&amp; valueProfile)
  {
      ASSERT(shouldEmitProfiling());
<span class="line-new-header">--- 279,13 ---</span>
      storePtr(TrustedImmPtr(codeBlock), m_interpreter-&gt;sampler()-&gt;codeBlockSlot());
  }
  #endif
  #endif
  
<span class="line-modified">! ALWAYS_INLINE bool JIT::isOperandConstantChar(VirtualRegister src)</span>
  {
<span class="line-modified">!     return src.isConstant() &amp;&amp; getConstantOperand(src).isString() &amp;&amp; asString(getConstantOperand(src).asCell())-&gt;length() == 1;</span>
  }
  
  inline void JIT::emitValueProfilingSite(ValueProfile&amp; valueProfile)
  {
      ASSERT(shouldEmitProfiling());
</pre>
<hr />
<pre>
<span class="line-old-header">*** 380,183 ***</span>
      if (arrayProfileSaw(arrayModes, ArrayStorageShape))
          return JITArrayStorage;
      return JITContiguous;
  }
  
<span class="line-modified">! ALWAYS_INLINE int32_t JIT::getOperandConstantInt(int src)</span>
  {
      return getConstantOperand(src).asInt32();
  }
  
<span class="line-modified">! ALWAYS_INLINE double JIT::getOperandConstantDouble(int src)</span>
  {
      return getConstantOperand(src).asDouble();
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitInitRegister(int dst)</span>
  {
      storeTrustedValue(jsUndefined(), addressFor(dst));
  }
  
  #if USE(JSVALUE32_64)
  
<span class="line-modified">! inline void JIT::emitLoadTag(int index, RegisterID tag)</span>
  {
<span class="line-modified">!     if (m_codeBlock-&gt;isConstantRegisterIndex(index)) {</span>
<span class="line-modified">!         move(Imm32(getConstantOperand(index).tag()), tag);</span>
          return;
      }
  
<span class="line-modified">!     load32(tagFor(index), tag);</span>
  }
  
<span class="line-modified">! inline void JIT::emitLoadPayload(int index, RegisterID payload)</span>
  {
<span class="line-modified">!     if (m_codeBlock-&gt;isConstantRegisterIndex(index)) {</span>
<span class="line-modified">!         move(Imm32(getConstantOperand(index).payload()), payload);</span>
          return;
      }
  
<span class="line-modified">!     load32(payloadFor(index), payload);</span>
  }
  
  inline void JIT::emitLoad(const JSValue&amp; v, RegisterID tag, RegisterID payload)
  {
      move(Imm32(v.payload()), payload);
      move(Imm32(v.tag()), tag);
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitGetVirtualRegister(int src, JSValueRegs dst)</span>
  {
      emitLoad(src, dst.tagGPR(), dst.payloadGPR());
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitPutVirtualRegister(int dst, JSValueRegs from)</span>
  {
      emitStore(dst, from.tagGPR(), from.payloadGPR());
  }
  
<span class="line-modified">! inline void JIT::emitLoad(int index, RegisterID tag, RegisterID payload, RegisterID base)</span>
  {
      RELEASE_ASSERT(tag != payload);
  
      if (base == callFrameRegister) {
          RELEASE_ASSERT(payload != base);
<span class="line-modified">!         emitLoadPayload(index, payload);</span>
<span class="line-modified">!         emitLoadTag(index, tag);</span>
          return;
      }
  
<span class="line-removed">-     VirtualRegister target { index };</span>
      if (payload == base) { // avoid stomping base
<span class="line-modified">!         load32(tagFor(target, base), tag);</span>
<span class="line-modified">!         load32(payloadFor(target, base), payload);</span>
          return;
      }
  
<span class="line-modified">!     load32(payloadFor(target, base), payload);</span>
<span class="line-modified">!     load32(tagFor(target, base), tag);</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- inline void JIT::emitLoad2(int index1, RegisterID tag1, RegisterID payload1, int index2, RegisterID tag2, RegisterID payload2)</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     emitLoad(index2, tag2, payload2);</span>
<span class="line-removed">-     emitLoad(index1, tag1, payload1);</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- inline void JIT::emitLoadDouble(int index, FPRegisterID value)</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     if (m_codeBlock-&gt;isConstantRegisterIndex(index)) {</span>
<span class="line-removed">-         WriteBarrier&lt;Unknown&gt;&amp; inConstantPool = m_codeBlock-&gt;constantRegister(index);</span>
<span class="line-removed">-         loadDouble(TrustedImmPtr(&amp;inConstantPool), value);</span>
<span class="line-removed">-     } else</span>
<span class="line-removed">-         loadDouble(addressFor(index), value);</span>
  }
  
<span class="line-modified">! inline void JIT::emitLoadInt32ToDouble(int index, FPRegisterID value)</span>
  {
<span class="line-modified">!     if (m_codeBlock-&gt;isConstantRegisterIndex(index)) {</span>
<span class="line-modified">!         WriteBarrier&lt;Unknown&gt;&amp; inConstantPool = m_codeBlock-&gt;constantRegister(index);</span>
<span class="line-removed">-         char* bytePointer = reinterpret_cast&lt;char*&gt;(&amp;inConstantPool);</span>
<span class="line-removed">-         convertInt32ToDouble(AbsoluteAddress(bytePointer + OBJECT_OFFSETOF(JSValue, u.asBits.payload)), value);</span>
<span class="line-removed">-     } else</span>
<span class="line-removed">-         convertInt32ToDouble(payloadFor(index), value);</span>
  }
  
<span class="line-modified">! inline void JIT::emitStore(int index, RegisterID tag, RegisterID payload, RegisterID base)</span>
  {
<span class="line-modified">!     VirtualRegister target { index };</span>
<span class="line-modified">!     store32(payload, payloadFor(target, base));</span>
<span class="line-removed">-     store32(tag, tagFor(target, base));</span>
  }
  
<span class="line-modified">! inline void JIT::emitStoreInt32(int index, RegisterID payload, bool indexIsInt32)</span>
  {
<span class="line-modified">!     store32(payload, payloadFor(index));</span>
      if (!indexIsInt32)
<span class="line-modified">!         store32(TrustedImm32(JSValue::Int32Tag), tagFor(index));</span>
  }
  
<span class="line-modified">! inline void JIT::emitStoreInt32(int index, TrustedImm32 payload, bool indexIsInt32)</span>
  {
<span class="line-modified">!     store32(payload, payloadFor(index));</span>
      if (!indexIsInt32)
<span class="line-modified">!         store32(TrustedImm32(JSValue::Int32Tag), tagFor(index));</span>
  }
  
<span class="line-modified">! inline void JIT::emitStoreCell(int index, RegisterID payload, bool indexIsCell)</span>
  {
<span class="line-modified">!     store32(payload, payloadFor(index));</span>
      if (!indexIsCell)
<span class="line-modified">!         store32(TrustedImm32(JSValue::CellTag), tagFor(index));</span>
  }
  
<span class="line-modified">! inline void JIT::emitStoreBool(int index, RegisterID payload, bool indexIsBool)</span>
  {
<span class="line-modified">!     store32(payload, payloadFor(index));</span>
      if (!indexIsBool)
<span class="line-modified">!         store32(TrustedImm32(JSValue::BooleanTag), tagFor(index));</span>
  }
  
<span class="line-modified">! inline void JIT::emitStoreDouble(int index, FPRegisterID value)</span>
  {
<span class="line-modified">!     storeDouble(value, addressFor(index));</span>
  }
  
<span class="line-modified">! inline void JIT::emitStore(int index, const JSValue constant, RegisterID base)</span>
  {
<span class="line-modified">!     VirtualRegister target { index };</span>
<span class="line-modified">!     store32(Imm32(constant.payload()), payloadFor(target, base));</span>
<span class="line-removed">-     store32(Imm32(constant.tag()), tagFor(target, base));</span>
  }
  
<span class="line-modified">! inline void JIT::emitJumpSlowCaseIfNotJSCell(int virtualRegisterIndex)</span>
  {
<span class="line-modified">!     if (!m_codeBlock-&gt;isKnownNotImmediate(virtualRegisterIndex)) {</span>
<span class="line-modified">!         if (m_codeBlock-&gt;isConstantRegisterIndex(virtualRegisterIndex))</span>
              addSlowCase(jump());
          else
<span class="line-modified">!             addSlowCase(emitJumpIfNotJSCell(virtualRegisterIndex));</span>
      }
  }
  
<span class="line-modified">! inline void JIT::emitJumpSlowCaseIfNotJSCell(int virtualRegisterIndex, RegisterID tag)</span>
  {
<span class="line-modified">!     if (!m_codeBlock-&gt;isKnownNotImmediate(virtualRegisterIndex)) {</span>
<span class="line-modified">!         if (m_codeBlock-&gt;isConstantRegisterIndex(virtualRegisterIndex))</span>
              addSlowCase(jump());
          else
              addSlowCase(branchIfNotCell(tag));
      }
  }
  
<span class="line-modified">! ALWAYS_INLINE bool JIT::isOperandConstantInt(int src)</span>
  {
<span class="line-modified">!     return m_codeBlock-&gt;isConstantRegisterIndex(src) &amp;&amp; getConstantOperand(src).isInt32();</span>
  }
  
<span class="line-modified">! ALWAYS_INLINE bool JIT::getOperandConstantInt(int op1, int op2, int&amp; op, int32_t&amp; constant)</span>
  {
      if (isOperandConstantInt(op1)) {
          constant = getConstantOperand(op1).asInt32();
          op = op2;
          return true;
<span class="line-new-header">--- 358,170 ---</span>
      if (arrayProfileSaw(arrayModes, ArrayStorageShape))
          return JITArrayStorage;
      return JITContiguous;
  }
  
<span class="line-modified">! ALWAYS_INLINE int32_t JIT::getOperandConstantInt(VirtualRegister src)</span>
  {
      return getConstantOperand(src).asInt32();
  }
  
<span class="line-modified">! ALWAYS_INLINE double JIT::getOperandConstantDouble(VirtualRegister src)</span>
  {
      return getConstantOperand(src).asDouble();
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitInitRegister(VirtualRegister dst)</span>
  {
      storeTrustedValue(jsUndefined(), addressFor(dst));
  }
  
  #if USE(JSVALUE32_64)
  
<span class="line-modified">! inline void JIT::emitLoadDouble(VirtualRegister reg, FPRegisterID value)</span>
  {
<span class="line-modified">!     if (reg.isConstant()) {</span>
<span class="line-modified">!         WriteBarrier&lt;Unknown&gt;&amp; inConstantPool = m_codeBlock-&gt;constantRegister(reg);</span>
<span class="line-added">+         loadDouble(TrustedImmPtr(&amp;inConstantPool), value);</span>
<span class="line-added">+     } else</span>
<span class="line-added">+         loadDouble(addressFor(reg), value);</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ inline void JIT::emitLoadTag(VirtualRegister reg, RegisterID tag)</span>
<span class="line-added">+ {</span>
<span class="line-added">+     if (reg.isConstant()) {</span>
<span class="line-added">+         move(Imm32(getConstantOperand(reg).tag()), tag);</span>
          return;
      }
  
<span class="line-modified">!     load32(tagFor(reg), tag);</span>
  }
  
<span class="line-modified">! inline void JIT::emitLoadPayload(VirtualRegister reg, RegisterID payload)</span>
  {
<span class="line-modified">!     if (reg.isConstant()) {</span>
<span class="line-modified">!         move(Imm32(getConstantOperand(reg).payload()), payload);</span>
          return;
      }
  
<span class="line-modified">!     load32(payloadFor(reg), payload);</span>
  }
  
  inline void JIT::emitLoad(const JSValue&amp; v, RegisterID tag, RegisterID payload)
  {
      move(Imm32(v.payload()), payload);
      move(Imm32(v.tag()), tag);
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitGetVirtualRegister(VirtualRegister src, JSValueRegs dst)</span>
  {
      emitLoad(src, dst.tagGPR(), dst.payloadGPR());
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitPutVirtualRegister(VirtualRegister dst, JSValueRegs from)</span>
  {
      emitStore(dst, from.tagGPR(), from.payloadGPR());
  }
  
<span class="line-modified">! inline void JIT::emitLoad(VirtualRegister reg, RegisterID tag, RegisterID payload, RegisterID base)</span>
  {
      RELEASE_ASSERT(tag != payload);
  
      if (base == callFrameRegister) {
          RELEASE_ASSERT(payload != base);
<span class="line-modified">!         emitLoadPayload(reg, payload);</span>
<span class="line-modified">!         emitLoadTag(reg, tag);</span>
          return;
      }
  
      if (payload == base) { // avoid stomping base
<span class="line-modified">!         load32(tagFor(reg, base), tag);</span>
<span class="line-modified">!         load32(payloadFor(reg, base), payload);</span>
          return;
      }
  
<span class="line-modified">!     load32(payloadFor(reg, base), payload);</span>
<span class="line-modified">!     load32(tagFor(reg, base), tag);</span>
  }
  
<span class="line-modified">! inline void JIT::emitLoad2(VirtualRegister reg1, RegisterID tag1, RegisterID payload1, VirtualRegister reg2, RegisterID tag2, RegisterID payload2)</span>
  {
<span class="line-modified">!     emitLoad(reg2, tag2, payload2);</span>
<span class="line-modified">!     emitLoad(reg1, tag1, payload1);</span>
  }
  
<span class="line-modified">! inline void JIT::emitStore(VirtualRegister reg, RegisterID tag, RegisterID payload, RegisterID base)</span>
  {
<span class="line-modified">!     store32(payload, payloadFor(reg, base));</span>
<span class="line-modified">!     store32(tag, tagFor(reg, base));</span>
  }
  
<span class="line-modified">! inline void JIT::emitStoreInt32(VirtualRegister reg, RegisterID payload, bool indexIsInt32)</span>
  {
<span class="line-modified">!     store32(payload, payloadFor(reg));</span>
      if (!indexIsInt32)
<span class="line-modified">!         store32(TrustedImm32(JSValue::Int32Tag), tagFor(reg));</span>
  }
  
<span class="line-modified">! inline void JIT::emitStoreInt32(VirtualRegister reg, TrustedImm32 payload, bool indexIsInt32)</span>
  {
<span class="line-modified">!     store32(payload, payloadFor(reg));</span>
      if (!indexIsInt32)
<span class="line-modified">!         store32(TrustedImm32(JSValue::Int32Tag), tagFor(reg));</span>
  }
  
<span class="line-modified">! inline void JIT::emitStoreCell(VirtualRegister reg, RegisterID payload, bool indexIsCell)</span>
  {
<span class="line-modified">!     store32(payload, payloadFor(reg));</span>
      if (!indexIsCell)
<span class="line-modified">!         store32(TrustedImm32(JSValue::CellTag), tagFor(reg));</span>
  }
  
<span class="line-modified">! inline void JIT::emitStoreBool(VirtualRegister reg, RegisterID payload, bool indexIsBool)</span>
  {
<span class="line-modified">!     store32(payload, payloadFor(reg));</span>
      if (!indexIsBool)
<span class="line-modified">!         store32(TrustedImm32(JSValue::BooleanTag), tagFor(reg));</span>
  }
  
<span class="line-modified">! inline void JIT::emitStoreDouble(VirtualRegister reg, FPRegisterID value)</span>
  {
<span class="line-modified">!     storeDouble(value, addressFor(reg));</span>
  }
  
<span class="line-modified">! inline void JIT::emitStore(VirtualRegister reg, const JSValue constant, RegisterID base)</span>
  {
<span class="line-modified">!     store32(Imm32(constant.payload()), payloadFor(reg, base));</span>
<span class="line-modified">!     store32(Imm32(constant.tag()), tagFor(reg, base));</span>
  }
  
<span class="line-modified">! inline void JIT::emitJumpSlowCaseIfNotJSCell(VirtualRegister reg)</span>
  {
<span class="line-modified">!     if (!m_codeBlock-&gt;isKnownNotImmediate(reg)) {</span>
<span class="line-modified">!         if (reg.isConstant())</span>
              addSlowCase(jump());
          else
<span class="line-modified">!             addSlowCase(emitJumpIfNotJSCell(reg));</span>
      }
  }
  
<span class="line-modified">! inline void JIT::emitJumpSlowCaseIfNotJSCell(VirtualRegister reg, RegisterID tag)</span>
  {
<span class="line-modified">!     if (!m_codeBlock-&gt;isKnownNotImmediate(reg)) {</span>
<span class="line-modified">!         if (reg.isConstant())</span>
              addSlowCase(jump());
          else
              addSlowCase(branchIfNotCell(tag));
      }
  }
  
<span class="line-modified">! ALWAYS_INLINE bool JIT::isOperandConstantInt(VirtualRegister src)</span>
  {
<span class="line-modified">!     return src.isConstant() &amp;&amp; getConstantOperand(src).isInt32();</span>
  }
  
<span class="line-modified">! ALWAYS_INLINE bool JIT::getOperandConstantInt(VirtualRegister op1, VirtualRegister op2, VirtualRegister&amp; op, int32_t&amp; constant)</span>
  {
      if (isOperandConstantInt(op1)) {
          constant = getConstantOperand(op1).asInt32();
          op = op2;
          return true;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 572,15 ***</span>
  }
  
  #else // USE(JSVALUE32_64)
  
  // get arg puts an arg from the SF register array into a h/w register
<span class="line-modified">! ALWAYS_INLINE void JIT::emitGetVirtualRegister(int src, RegisterID dst)</span>
  {
<span class="line-modified">!     ASSERT(m_bytecodeOffset != std::numeric_limits&lt;unsigned&gt;::max()); // This method should only be called during hot/cold path generation, so that m_bytecodeOffset is set.</span>
  
<span class="line-modified">!     if (m_codeBlock-&gt;isConstantRegisterIndex(src)) {</span>
          JSValue value = m_codeBlock-&gt;getConstant(src);
          if (!value.isNumber())
              move(TrustedImm64(JSValue::encode(value)), dst);
          else
              move(Imm64(JSValue::encode(value)), dst);
<span class="line-new-header">--- 537,15 ---</span>
  }
  
  #else // USE(JSVALUE32_64)
  
  // get arg puts an arg from the SF register array into a h/w register
<span class="line-modified">! ALWAYS_INLINE void JIT::emitGetVirtualRegister(VirtualRegister src, RegisterID dst)</span>
  {
<span class="line-modified">!     ASSERT(m_bytecodeIndex); // This method should only be called during hot/cold path generation, so that m_bytecodeIndex is set.</span>
  
<span class="line-modified">!     if (src.isConstant()) {</span>
          JSValue value = m_codeBlock-&gt;getConstant(src);
          if (!value.isNumber())
              move(TrustedImm64(JSValue::encode(value)), dst);
          else
              move(Imm64(JSValue::encode(value)), dst);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 588,51 ***</span>
      }
  
      load64(addressFor(src), dst);
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitGetVirtualRegister(int src, JSValueRegs dst)</span>
  {
      emitGetVirtualRegister(src, dst.payloadGPR());
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitGetVirtualRegister(VirtualRegister src, RegisterID dst)</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     emitGetVirtualRegister(src.offset(), dst);</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- ALWAYS_INLINE void JIT::emitGetVirtualRegisters(int src1, RegisterID dst1, int src2, RegisterID dst2)</span>
  {
      emitGetVirtualRegister(src1, dst1);
      emitGetVirtualRegister(src2, dst2);
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitGetVirtualRegisters(VirtualRegister src1, RegisterID dst1, VirtualRegister src2, RegisterID dst2)</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     emitGetVirtualRegisters(src1.offset(), dst1, src2.offset(), dst2);</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- ALWAYS_INLINE bool JIT::isOperandConstantInt(int src)</span>
  {
<span class="line-modified">!     return m_codeBlock-&gt;isConstantRegisterIndex(src) &amp;&amp; getConstantOperand(src).isInt32();</span>
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitPutVirtualRegister(int dst, RegisterID from)</span>
  {
      store64(from, addressFor(dst));
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitPutVirtualRegister(int dst, JSValueRegs from)</span>
  {
      emitPutVirtualRegister(dst, from.payloadGPR());
  }
  
<span class="line-removed">- ALWAYS_INLINE void JIT::emitPutVirtualRegister(VirtualRegister dst, RegisterID from)</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     emitPutVirtualRegister(dst.offset(), from);</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
  ALWAYS_INLINE JIT::Jump JIT::emitJumpIfBothJSCells(RegisterID reg1, RegisterID reg2, RegisterID scratch)
  {
      move(reg1, scratch);
      or64(reg2, scratch);
      return branchIfCell(scratch);
<span class="line-new-header">--- 553,36 ---</span>
      }
  
      load64(addressFor(src), dst);
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitGetVirtualRegister(VirtualRegister src, JSValueRegs dst)</span>
  {
      emitGetVirtualRegister(src, dst.payloadGPR());
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitGetVirtualRegisters(VirtualRegister src1, RegisterID dst1, VirtualRegister src2, RegisterID dst2)</span>
  {
      emitGetVirtualRegister(src1, dst1);
      emitGetVirtualRegister(src2, dst2);
  }
  
<span class="line-modified">! ALWAYS_INLINE bool JIT::isOperandConstantInt(VirtualRegister src)</span>
  {
<span class="line-modified">!     return src.isConstant() &amp;&amp; getConstantOperand(src).isInt32();</span>
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitPutVirtualRegister(VirtualRegister dst, RegisterID from)</span>
  {
      store64(from, addressFor(dst));
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitPutVirtualRegister(VirtualRegister dst, JSValueRegs from)</span>
  {
      emitPutVirtualRegister(dst, from.payloadGPR());
  }
  
  ALWAYS_INLINE JIT::Jump JIT::emitJumpIfBothJSCells(RegisterID reg1, RegisterID reg2, RegisterID scratch)
  {
      move(reg1, scratch);
      or64(reg2, scratch);
      return branchIfCell(scratch);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 646,37 ***</span>
  ALWAYS_INLINE void JIT::emitJumpSlowCaseIfNotJSCell(RegisterID reg)
  {
      addSlowCase(branchIfNotCell(reg));
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitJumpSlowCaseIfNotJSCell(RegisterID reg, int vReg)</span>
  {
      if (!m_codeBlock-&gt;isKnownNotImmediate(vReg))
          emitJumpSlowCaseIfNotJSCell(reg);
  }
  
<span class="line-removed">- inline void JIT::emitLoadDouble(int index, FPRegisterID value)</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     if (m_codeBlock-&gt;isConstantRegisterIndex(index)) {</span>
<span class="line-removed">-         WriteBarrier&lt;Unknown&gt;&amp; inConstantPool = m_codeBlock-&gt;constantRegister(index);</span>
<span class="line-removed">-         loadDouble(TrustedImmPtr(&amp;inConstantPool), value);</span>
<span class="line-removed">-     } else</span>
<span class="line-removed">-         loadDouble(addressFor(index), value);</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- inline void JIT::emitLoadInt32ToDouble(int index, FPRegisterID value)</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     if (m_codeBlock-&gt;isConstantRegisterIndex(index)) {</span>
<span class="line-removed">-         ASSERT(isOperandConstantInt(index));</span>
<span class="line-removed">-         convertInt32ToDouble(Imm32(getConstantOperand(index).asInt32()), value);</span>
<span class="line-removed">-     } else</span>
<span class="line-removed">-         convertInt32ToDouble(addressFor(index), value);</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
  ALWAYS_INLINE JIT::PatchableJump JIT::emitPatchableJumpIfNotInt(RegisterID reg)
  {
<span class="line-modified">!     return patchableBranch64(Below, reg, tagTypeNumberRegister);</span>
  }
  
  ALWAYS_INLINE JIT::Jump JIT::emitJumpIfNotInt(RegisterID reg1, RegisterID reg2, RegisterID scratch)
  {
      move(reg1, scratch);
<span class="line-new-header">--- 596,19 ---</span>
  ALWAYS_INLINE void JIT::emitJumpSlowCaseIfNotJSCell(RegisterID reg)
  {
      addSlowCase(branchIfNotCell(reg));
  }
  
<span class="line-modified">! ALWAYS_INLINE void JIT::emitJumpSlowCaseIfNotJSCell(RegisterID reg, VirtualRegister vReg)</span>
  {
      if (!m_codeBlock-&gt;isKnownNotImmediate(vReg))
          emitJumpSlowCaseIfNotJSCell(reg);
  }
  
  ALWAYS_INLINE JIT::PatchableJump JIT::emitPatchableJumpIfNotInt(RegisterID reg)
  {
<span class="line-modified">!     return patchableBranch64(Below, reg, numberTagRegister);</span>
  }
  
  ALWAYS_INLINE JIT::Jump JIT::emitJumpIfNotInt(RegisterID reg1, RegisterID reg2, RegisterID scratch)
  {
      move(reg1, scratch);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 718,17 ***</span>
      m_copiedGetPutInfos.add(key, getPutInfo.operand());
      return getPutInfo;
  }
  
  template&lt;typename BinaryOp&gt;
<span class="line-modified">! ALWAYS_INLINE ArithProfile JIT::copiedArithProfile(BinaryOp bytecode)</span>
  {
<span class="line-modified">!     uint64_t key = static_cast&lt;uint64_t&gt;(BinaryOp::opcodeID) &lt;&lt; 32 | static_cast&lt;uint64_t&gt;(bytecode.m_metadataID);</span>
      auto iterator = m_copiedArithProfiles.find(key);
      if (iterator != m_copiedArithProfiles.end())
          return iterator-&gt;value;
<span class="line-modified">!     ArithProfile arithProfile = bytecode.metadata(m_codeBlock).m_arithProfile;</span>
      m_copiedArithProfiles.add(key, arithProfile);
      return arithProfile;
  }
  
  } // namespace JSC
<span class="line-new-header">--- 650,17 ---</span>
      m_copiedGetPutInfos.add(key, getPutInfo.operand());
      return getPutInfo;
  }
  
  template&lt;typename BinaryOp&gt;
<span class="line-modified">! ALWAYS_INLINE BinaryArithProfile JIT::copiedArithProfile(BinaryOp bytecode)</span>
  {
<span class="line-modified">!     uint64_t key = (static_cast&lt;uint64_t&gt;(BinaryOp::opcodeID) + 1) &lt;&lt; 32 | static_cast&lt;uint64_t&gt;(bytecode.m_metadataID);</span>
      auto iterator = m_copiedArithProfiles.find(key);
      if (iterator != m_copiedArithProfiles.end())
          return iterator-&gt;value;
<span class="line-modified">!     BinaryArithProfile arithProfile = bytecode.metadata(m_codeBlock).m_arithProfile;</span>
      m_copiedArithProfiles.add(key, arithProfile);
      return arithProfile;
  }
  
  } // namespace JSC
</pre>
<center><a href="JITInlineCacheGenerator.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="JITLeftShiftGenerator.cpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>