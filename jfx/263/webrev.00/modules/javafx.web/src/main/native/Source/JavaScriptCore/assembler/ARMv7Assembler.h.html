<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/ARMv7Assembler.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (C) 2009-2019 Apple Inc. All rights reserved.
   3  * Copyright (C) 2010 University of Szeged
   4  *
   5  * Redistribution and use in source and binary forms, with or without
   6  * modification, are permitted provided that the following conditions
   7  * are met:
   8  * 1. Redistributions of source code must retain the above copyright
   9  *    notice, this list of conditions and the following disclaimer.
  10  * 2. Redistributions in binary form must reproduce the above copyright
  11  *    notice, this list of conditions and the following disclaimer in the
  12  *    documentation and/or other materials provided with the distribution.
  13  *
  14  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  15  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  16  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  17  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  18  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  19  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  20  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  21  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  22  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  23  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  24  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  25  */
  26 
  27 #pragma once
  28 
  29 #if ENABLE(ASSEMBLER) &amp;&amp; CPU(ARM_THUMB2)
  30 
  31 #include &quot;AssemblerBuffer.h&quot;
  32 #include &quot;AssemblerCommon.h&quot;
  33 #include &quot;RegisterInfo.h&quot;
  34 #include &lt;limits.h&gt;
  35 #include &lt;wtf/Assertions.h&gt;
  36 #include &lt;wtf/Vector.h&gt;
  37 #include &lt;stdint.h&gt;
  38 
  39 namespace JSC {
  40 
  41 namespace RegisterNames {
  42 
  43     typedef enum : int8_t {
  44 #define REGISTER_ID(id, name, r, cs) id,
  45         FOR_EACH_GP_REGISTER(REGISTER_ID)
  46 #undef REGISTER_ID
  47 
  48 #define REGISTER_ALIAS(id, name, alias) id = alias,
  49         FOR_EACH_REGISTER_ALIAS(REGISTER_ALIAS)
  50 #undef REGISTER_ALIAS
  51         InvalidGPRReg = -1,
  52     } RegisterID;
  53 
  54     typedef enum : int8_t {
  55 #define REGISTER_ID(id, name) id,
  56         FOR_EACH_SP_REGISTER(REGISTER_ID)
  57 #undef REGISTER_ID
  58     } SPRegisterID;
  59 
  60     typedef enum : int8_t {
  61 #define REGISTER_ID(id, name, r, cs) id,
  62         FOR_EACH_FP_SINGLE_REGISTER(REGISTER_ID)
  63 #undef REGISTER_ID
  64     } FPSingleRegisterID;
  65 
  66     typedef enum : int8_t {
  67 #define REGISTER_ID(id, name, r, cs) id,
  68         FOR_EACH_FP_DOUBLE_REGISTER(REGISTER_ID)
  69 #undef REGISTER_ID
  70         InvalidFPRReg = -1,
  71     } FPDoubleRegisterID;
  72 
  73 #if CPU(ARM_NEON)
  74     typedef enum : int8_t {
  75 #define REGISTER_ID(id, name, r, cs) id,
  76         FOR_EACH_FP_QUAD_REGISTER(REGISTER_ID)
  77 #undef REGISTER_ID
  78     } FPQuadRegisterID;
  79 #endif // CPU(ARM_NEON)
  80 
  81     inline FPSingleRegisterID asSingle(FPDoubleRegisterID reg)
  82     {
  83         ASSERT(reg &lt; d16);
  84         return (FPSingleRegisterID)(reg &lt;&lt; 1);
  85     }
  86 
  87     inline FPSingleRegisterID asSingleUpper(FPDoubleRegisterID reg)
  88     {
  89         ASSERT(reg &lt; d16);
  90         return (FPSingleRegisterID)((reg &lt;&lt; 1) + 1);
  91     }
  92 
  93     inline FPDoubleRegisterID asDouble(FPSingleRegisterID reg)
  94     {
  95         ASSERT(!(reg &amp; 1));
  96         return (FPDoubleRegisterID)(reg &gt;&gt; 1);
  97     }
  98 
  99 } // namespace ARMRegisters
 100 
 101 class ARMv7Assembler;
 102 class ARMThumbImmediate {
 103     friend class ARMv7Assembler;
 104 
 105     typedef uint8_t ThumbImmediateType;
 106     static constexpr ThumbImmediateType TypeInvalid = 0;
 107     static constexpr ThumbImmediateType TypeEncoded = 1;
 108     static constexpr ThumbImmediateType TypeUInt16 = 2;
 109 
 110     typedef union {
 111         int16_t asInt;
 112         struct {
 113             unsigned imm8 : 8;
 114             unsigned imm3 : 3;
 115             unsigned i    : 1;
 116             unsigned imm4 : 4;
 117         };
 118         // If this is an encoded immediate, then it may describe a shift, or a pattern.
 119         struct {
 120             unsigned shiftValue7 : 7;
 121             unsigned shiftAmount : 5;
 122         };
 123         struct {
 124             unsigned immediate   : 8;
 125             unsigned pattern     : 4;
 126         };
 127     } ThumbImmediateValue;
 128 
 129     // byte0 contains least significant bit; not using an array to make client code endian agnostic.
 130     typedef union {
 131         int32_t asInt;
 132         struct {
 133             uint8_t byte0;
 134             uint8_t byte1;
 135             uint8_t byte2;
 136             uint8_t byte3;
 137         };
 138     } PatternBytes;
 139 
 140     ALWAYS_INLINE static void countLeadingZerosPartial(uint32_t&amp; value, int32_t&amp; zeros, const int N)
 141     {
 142         if (value &amp; ~((1 &lt;&lt; N) - 1)) /* check for any of the top N bits (of 2N bits) are set */
 143             value &gt;&gt;= N;             /* if any were set, lose the bottom N */
 144         else                         /* if none of the top N bits are set, */
 145             zeros += N;              /* then we have identified N leading zeros */
 146     }
 147 
 148     static int32_t countLeadingZeros(uint32_t value)
 149     {
 150         if (!value)
 151             return 32;
 152 
 153         int32_t zeros = 0;
 154         countLeadingZerosPartial(value, zeros, 16);
 155         countLeadingZerosPartial(value, zeros, 8);
 156         countLeadingZerosPartial(value, zeros, 4);
 157         countLeadingZerosPartial(value, zeros, 2);
 158         countLeadingZerosPartial(value, zeros, 1);
 159         return zeros;
 160     }
 161 
 162     ARMThumbImmediate()
 163         : m_type(TypeInvalid)
 164     {
 165         m_value.asInt = 0;
 166     }
 167 
 168     ARMThumbImmediate(ThumbImmediateType type, ThumbImmediateValue value)
 169         : m_type(type)
 170         , m_value(value)
 171     {
 172     }
 173 
 174     ARMThumbImmediate(ThumbImmediateType type, uint16_t value)
 175         : m_type(TypeUInt16)
 176     {
 177         // Make sure this constructor is only reached with type TypeUInt16;
 178         // this extra parameter makes the code a little clearer by making it
 179         // explicit at call sites which type is being constructed
 180         ASSERT_UNUSED(type, type == TypeUInt16);
 181 
 182         m_value.asInt = value;
 183     }
 184 
 185 public:
 186     static ARMThumbImmediate makeEncodedImm(uint32_t value)
 187     {
 188         ThumbImmediateValue encoding;
 189         encoding.asInt = 0;
 190 
 191         // okay, these are easy.
 192         if (value &lt; 256) {
 193             encoding.immediate = value;
 194             encoding.pattern = 0;
 195             return ARMThumbImmediate(TypeEncoded, encoding);
 196         }
 197 
 198         int32_t leadingZeros = countLeadingZeros(value);
 199         // if there were 24 or more leading zeros, then we&#39;d have hit the (value &lt; 256) case.
 200         ASSERT(leadingZeros &lt; 24);
 201 
 202         // Given a number with bit fields Z:B:C, where count(Z)+count(B)+count(C) == 32,
 203         // Z are the bits known zero, B is the 8-bit immediate, C are the bits to check for
 204         // zero.  count(B) == 8, so the count of bits to be checked is 24 - count(Z).
 205         int32_t rightShiftAmount = 24 - leadingZeros;
 206         if (value == ((value &gt;&gt; rightShiftAmount) &lt;&lt; rightShiftAmount)) {
 207             // Shift the value down to the low byte position.  The assign to
 208             // shiftValue7 drops the implicit top bit.
 209             encoding.shiftValue7 = value &gt;&gt; rightShiftAmount;
 210             // The endoded shift amount is the magnitude of a right rotate.
 211             encoding.shiftAmount = 8 + leadingZeros;
 212             return ARMThumbImmediate(TypeEncoded, encoding);
 213         }
 214 
 215         PatternBytes bytes;
 216         bytes.asInt = value;
 217 
 218         if ((bytes.byte0 == bytes.byte1) &amp;&amp; (bytes.byte0 == bytes.byte2) &amp;&amp; (bytes.byte0 == bytes.byte3)) {
 219             encoding.immediate = bytes.byte0;
 220             encoding.pattern = 3;
 221             return ARMThumbImmediate(TypeEncoded, encoding);
 222         }
 223 
 224         if ((bytes.byte0 == bytes.byte2) &amp;&amp; !(bytes.byte1 | bytes.byte3)) {
 225             encoding.immediate = bytes.byte0;
 226             encoding.pattern = 1;
 227             return ARMThumbImmediate(TypeEncoded, encoding);
 228         }
 229 
 230         if ((bytes.byte1 == bytes.byte3) &amp;&amp; !(bytes.byte0 | bytes.byte2)) {
 231             encoding.immediate = bytes.byte1;
 232             encoding.pattern = 2;
 233             return ARMThumbImmediate(TypeEncoded, encoding);
 234         }
 235 
 236         return ARMThumbImmediate();
 237     }
 238 
 239     static ARMThumbImmediate makeUInt12(int32_t value)
 240     {
 241         return (!(value &amp; 0xfffff000))
 242             ? ARMThumbImmediate(TypeUInt16, (uint16_t)value)
 243             : ARMThumbImmediate();
 244     }
 245 
 246     static ARMThumbImmediate makeUInt12OrEncodedImm(int32_t value)
 247     {
 248         // If this is not a 12-bit unsigned it, try making an encoded immediate.
 249         return (!(value &amp; 0xfffff000))
 250             ? ARMThumbImmediate(TypeUInt16, (uint16_t)value)
 251             : makeEncodedImm(value);
 252     }
 253 
 254     // The &#39;make&#39; methods, above, return a !isValid() value if the argument
 255     // cannot be represented as the requested type.  This methods  is called
 256     // &#39;get&#39; since the argument can always be represented.
 257     static ARMThumbImmediate makeUInt16(uint16_t value)
 258     {
 259         return ARMThumbImmediate(TypeUInt16, value);
 260     }
 261 
 262     bool isValid()
 263     {
 264         return m_type != TypeInvalid;
 265     }
 266 
 267     uint16_t asUInt16() const { return m_value.asInt; }
 268 
 269     // These methods rely on the format of encoded byte values.
 270     bool isUInt3() { return !(m_value.asInt &amp; 0xfff8); }
 271     bool isUInt4() { return !(m_value.asInt &amp; 0xfff0); }
 272     bool isUInt5() { return !(m_value.asInt &amp; 0xffe0); }
 273     bool isUInt6() { return !(m_value.asInt &amp; 0xffc0); }
 274     bool isUInt7() { return !(m_value.asInt &amp; 0xff80); }
 275     bool isUInt8() { return !(m_value.asInt &amp; 0xff00); }
 276     bool isUInt9() { return (m_type == TypeUInt16) &amp;&amp; !(m_value.asInt &amp; 0xfe00); }
 277     bool isUInt10() { return (m_type == TypeUInt16) &amp;&amp; !(m_value.asInt &amp; 0xfc00); }
 278     bool isUInt12() { return (m_type == TypeUInt16) &amp;&amp; !(m_value.asInt &amp; 0xf000); }
 279     bool isUInt16() { return m_type == TypeUInt16; }
 280     uint8_t getUInt3() { ASSERT(isUInt3()); return m_value.asInt; }
 281     uint8_t getUInt4() { ASSERT(isUInt4()); return m_value.asInt; }
 282     uint8_t getUInt5() { ASSERT(isUInt5()); return m_value.asInt; }
 283     uint8_t getUInt6() { ASSERT(isUInt6()); return m_value.asInt; }
 284     uint8_t getUInt7() { ASSERT(isUInt7()); return m_value.asInt; }
 285     uint8_t getUInt8() { ASSERT(isUInt8()); return m_value.asInt; }
 286     uint16_t getUInt9() { ASSERT(isUInt9()); return m_value.asInt; }
 287     uint16_t getUInt10() { ASSERT(isUInt10()); return m_value.asInt; }
 288     uint16_t getUInt12() { ASSERT(isUInt12()); return m_value.asInt; }
 289     uint16_t getUInt16() { ASSERT(isUInt16()); return m_value.asInt; }
 290 
 291     bool isEncodedImm() { return m_type == TypeEncoded; }
 292 
 293 private:
 294     ThumbImmediateType m_type;
 295     ThumbImmediateValue m_value;
 296 };
 297 
 298 typedef enum {
 299     SRType_LSL,
 300     SRType_LSR,
 301     SRType_ASR,
 302     SRType_ROR,
 303 
 304     SRType_RRX = SRType_ROR
 305 } ARMShiftType;
 306 
 307 class ShiftTypeAndAmount {
 308     friend class ARMv7Assembler;
 309 
 310 public:
 311     ShiftTypeAndAmount()
 312     {
 313         m_u.type = (ARMShiftType)0;
 314         m_u.amount = 0;
 315     }
 316 
 317     ShiftTypeAndAmount(ARMShiftType type, unsigned amount)
 318     {
 319         m_u.type = type;
 320         m_u.amount = amount &amp; 31;
 321     }
 322 
 323     unsigned lo4() { return m_u.lo4; }
 324     unsigned hi4() { return m_u.hi4; }
 325 
 326 private:
 327     union {
 328         struct {
 329             unsigned lo4 : 4;
 330             unsigned hi4 : 4;
 331         };
 332         struct {
 333             unsigned type   : 2;
 334             unsigned amount : 6;
 335         };
 336     } m_u;
 337 };
 338 
 339 class ARMv7Assembler {
 340 public:
 341     typedef ARMRegisters::RegisterID RegisterID;
 342     typedef ARMRegisters::FPSingleRegisterID FPSingleRegisterID;
 343     typedef ARMRegisters::FPDoubleRegisterID FPDoubleRegisterID;
 344 #if CPU(ARM_NEON)
 345     typedef ARMRegisters::FPQuadRegisterID FPQuadRegisterID;
 346 #endif
 347     typedef ARMRegisters::SPRegisterID SPRegisterID;
 348     typedef FPDoubleRegisterID FPRegisterID;
 349 
 350     static constexpr RegisterID firstRegister() { return ARMRegisters::r0; }
 351     static constexpr RegisterID lastRegister() { return ARMRegisters::r15; }
 352     static constexpr unsigned numberOfRegisters() { return lastRegister() - firstRegister() + 1; }
 353 
 354     static constexpr SPRegisterID firstSPRegister() { return ARMRegisters::apsr; }
 355     static constexpr SPRegisterID lastSPRegister() { return ARMRegisters::fpscr; }
 356     static constexpr unsigned numberOfSPRegisters() { return lastSPRegister() - firstSPRegister() + 1; }
 357 
 358     static constexpr FPRegisterID firstFPRegister() { return ARMRegisters::d0; }
 359 #if CPU(ARM_NEON) || CPU(ARM_VFP_V3_D32)
 360     static constexpr FPRegisterID lastFPRegister() { return ARMRegisters::d31; }
 361 #else
 362     static constexpr FPRegisterID lastFPRegister() { return ARMRegisters::d15; }
 363 #endif
 364     static constexpr unsigned numberOfFPRegisters() { return lastFPRegister() - firstFPRegister() + 1; }
 365 
 366     static const char* gprName(RegisterID id)
 367     {
 368         ASSERT(id &gt;= firstRegister() &amp;&amp; id &lt;= lastRegister());
 369         static const char* const nameForRegister[numberOfRegisters()] = {
 370 #define REGISTER_NAME(id, name, r, cs) name,
 371         FOR_EACH_GP_REGISTER(REGISTER_NAME)
 372 #undef REGISTER_NAME
 373         };
 374         return nameForRegister[id];
 375     }
 376 
 377     static const char* sprName(SPRegisterID id)
 378     {
 379         ASSERT(id &gt;= firstSPRegister() &amp;&amp; id &lt;= lastSPRegister());
 380         static const char* const nameForRegister[numberOfSPRegisters()] = {
 381 #define REGISTER_NAME(id, name) name,
 382         FOR_EACH_SP_REGISTER(REGISTER_NAME)
 383 #undef REGISTER_NAME
 384         };
 385         return nameForRegister[id];
 386     }
 387 
 388     static const char* fprName(FPRegisterID id)
 389     {
 390         ASSERT(id &gt;= firstFPRegister() &amp;&amp; id &lt;= lastFPRegister());
 391         static const char* const nameForRegister[numberOfFPRegisters()] = {
 392 #define REGISTER_NAME(id, name, r, cs) name,
 393         FOR_EACH_FP_DOUBLE_REGISTER(REGISTER_NAME)
 394 #undef REGISTER_NAME
 395         };
 396         return nameForRegister[id];
 397     }
 398 
 399     // (HS, LO, HI, LS) -&gt; (AE, B, A, BE)
 400     // (VS, VC) -&gt; (O, NO)
 401     typedef enum {
 402         ConditionEQ, // Zero / Equal.
 403         ConditionNE, // Non-zero / Not equal.
 404         ConditionHS, ConditionCS = ConditionHS, // Unsigned higher or same.
 405         ConditionLO, ConditionCC = ConditionLO, // Unsigned lower.
 406         ConditionMI, // Negative.
 407         ConditionPL, // Positive or zero.
 408         ConditionVS, // Overflowed.
 409         ConditionVC, // Not overflowed.
 410         ConditionHI, // Unsigned higher.
 411         ConditionLS, // Unsigned lower or same.
 412         ConditionGE, // Signed greater than or equal.
 413         ConditionLT, // Signed less than.
 414         ConditionGT, // Signed greater than.
 415         ConditionLE, // Signed less than or equal.
 416         ConditionAL, // Unconditional / Always execute.
 417         ConditionInvalid
 418     } Condition;
 419 
 420 #define JUMP_ENUM_WITH_SIZE(index, value) (((value) &lt;&lt; 3) | (index))
 421 #define JUMP_ENUM_SIZE(jump) ((jump) &gt;&gt; 3)
 422     enum JumpType { JumpFixed = JUMP_ENUM_WITH_SIZE(0, 0),
 423                     JumpNoCondition = JUMP_ENUM_WITH_SIZE(1, 5 * sizeof(uint16_t)),
 424                     JumpCondition = JUMP_ENUM_WITH_SIZE(2, 6 * sizeof(uint16_t)),
 425                     JumpNoConditionFixedSize = JUMP_ENUM_WITH_SIZE(3, 5 * sizeof(uint16_t)),
 426                     JumpConditionFixedSize = JUMP_ENUM_WITH_SIZE(4, 6 * sizeof(uint16_t))
 427     };
 428     enum JumpLinkType {
 429         LinkInvalid = JUMP_ENUM_WITH_SIZE(0, 0),
 430         LinkJumpT1 = JUMP_ENUM_WITH_SIZE(1, sizeof(uint16_t)),
 431         LinkJumpT2 = JUMP_ENUM_WITH_SIZE(2, sizeof(uint16_t)),
 432         LinkJumpT3 = JUMP_ENUM_WITH_SIZE(3, 2 * sizeof(uint16_t)),
 433         LinkJumpT4 = JUMP_ENUM_WITH_SIZE(4, 2 * sizeof(uint16_t)),
 434         LinkConditionalJumpT4 = JUMP_ENUM_WITH_SIZE(5, 3 * sizeof(uint16_t)),
 435         LinkBX = JUMP_ENUM_WITH_SIZE(6, 5 * sizeof(uint16_t)),
 436         LinkConditionalBX = JUMP_ENUM_WITH_SIZE(7, 6 * sizeof(uint16_t))
 437     };
 438 
 439     class LinkRecord {
 440     public:
 441         LinkRecord(intptr_t from, intptr_t to, JumpType type, Condition condition)
 442         {
 443             data.realTypes.m_from = from;
 444             data.realTypes.m_to = to;
 445             data.realTypes.m_type = type;
 446             data.realTypes.m_linkType = LinkInvalid;
 447             data.realTypes.m_condition = condition;
 448         }
 449         void operator=(const LinkRecord&amp; other)
 450         {
 451             data.copyTypes.content[0] = other.data.copyTypes.content[0];
 452             data.copyTypes.content[1] = other.data.copyTypes.content[1];
 453             data.copyTypes.content[2] = other.data.copyTypes.content[2];
 454         }
 455         intptr_t from() const { return data.realTypes.m_from; }
 456         void setFrom(intptr_t from) { data.realTypes.m_from = from; }
 457         intptr_t to() const { return data.realTypes.m_to; }
 458         JumpType type() const { return data.realTypes.m_type; }
 459         JumpLinkType linkType() const { return data.realTypes.m_linkType; }
 460         void setLinkType(JumpLinkType linkType) { ASSERT(data.realTypes.m_linkType == LinkInvalid); data.realTypes.m_linkType = linkType; }
 461         Condition condition() const { return data.realTypes.m_condition; }
 462     private:
 463         union {
 464             struct RealTypes {
 465                 intptr_t m_from : 31;
 466                 intptr_t m_to : 31;
 467                 JumpType m_type : 8;
 468                 JumpLinkType m_linkType : 8;
 469                 Condition m_condition : 16;
 470             } realTypes;
 471             struct CopyTypes {
 472                 uint32_t content[3];
 473             } copyTypes;
 474             COMPILE_ASSERT(sizeof(RealTypes) == sizeof(CopyTypes), LinkRecordCopyStructSizeEqualsRealStruct);
 475         } data;
 476     };
 477 
 478     ARMv7Assembler()
 479         : m_indexOfLastWatchpoint(INT_MIN)
 480         , m_indexOfTailOfLastWatchpoint(INT_MIN)
 481     {
 482     }
 483 
 484     AssemblerBuffer&amp; buffer() { return m_formatter.m_buffer; }
 485 
 486 private:
 487 
 488     // ARMv7, Appx-A.6.3
 489     static bool BadReg(RegisterID reg)
 490     {
 491         return (reg == ARMRegisters::sp) || (reg == ARMRegisters::pc);
 492     }
 493 
 494     uint32_t singleRegisterMask(FPSingleRegisterID rdNum, int highBitsShift, int lowBitShift)
 495     {
 496         uint32_t rdMask = (rdNum &gt;&gt; 1) &lt;&lt; highBitsShift;
 497         if (rdNum &amp; 1)
 498             rdMask |= 1 &lt;&lt; lowBitShift;
 499         return rdMask;
 500     }
 501 
 502     uint32_t doubleRegisterMask(FPDoubleRegisterID rdNum, int highBitShift, int lowBitsShift)
 503     {
 504         uint32_t rdMask = (rdNum &amp; 0xf) &lt;&lt; lowBitsShift;
 505         if (rdNum &amp; 16)
 506             rdMask |= 1 &lt;&lt; highBitShift;
 507         return rdMask;
 508     }
 509 
 510     typedef enum {
 511         OP_ADD_reg_T1       = 0x1800,
 512         OP_SUB_reg_T1       = 0x1A00,
 513         OP_ADD_imm_T1       = 0x1C00,
 514         OP_SUB_imm_T1       = 0x1E00,
 515         OP_MOV_imm_T1       = 0x2000,
 516         OP_CMP_imm_T1       = 0x2800,
 517         OP_ADD_imm_T2       = 0x3000,
 518         OP_SUB_imm_T2       = 0x3800,
 519         OP_AND_reg_T1       = 0x4000,
 520         OP_EOR_reg_T1       = 0x4040,
 521         OP_TST_reg_T1       = 0x4200,
 522         OP_RSB_imm_T1       = 0x4240,
 523         OP_CMP_reg_T1       = 0x4280,
 524         OP_ORR_reg_T1       = 0x4300,
 525         OP_MVN_reg_T1       = 0x43C0,
 526         OP_ADD_reg_T2       = 0x4400,
 527         OP_MOV_reg_T1       = 0x4600,
 528         OP_BLX              = 0x4700,
 529         OP_BX               = 0x4700,
 530         OP_STR_reg_T1       = 0x5000,
 531         OP_STRH_reg_T1      = 0x5200,
 532         OP_STRB_reg_T1      = 0x5400,
 533         OP_LDRSB_reg_T1     = 0x5600,
 534         OP_LDR_reg_T1       = 0x5800,
 535         OP_LDRH_reg_T1      = 0x5A00,
 536         OP_LDRB_reg_T1      = 0x5C00,
 537         OP_LDRSH_reg_T1     = 0x5E00,
 538         OP_STR_imm_T1       = 0x6000,
 539         OP_LDR_imm_T1       = 0x6800,
 540         OP_STRB_imm_T1      = 0x7000,
 541         OP_LDRB_imm_T1      = 0x7800,
 542         OP_STRH_imm_T1      = 0x8000,
 543         OP_LDRH_imm_T1      = 0x8800,
 544         OP_STR_imm_T2       = 0x9000,
 545         OP_LDR_imm_T2       = 0x9800,
 546         OP_ADD_SP_imm_T1    = 0xA800,
 547         OP_ADD_SP_imm_T2    = 0xB000,
 548         OP_SUB_SP_imm_T1    = 0xB080,
 549         OP_PUSH_T1          = 0xB400,
 550         OP_POP_T1           = 0xBC00,
 551         OP_BKPT             = 0xBE00,
 552         OP_IT               = 0xBF00,
 553         OP_NOP_T1           = 0xBF00,
 554     } OpcodeID;
 555 
 556     typedef enum {
 557         OP_B_T1         = 0xD000,
 558         OP_B_T2         = 0xE000,
 559         OP_POP_T2       = 0xE8BD,
 560         OP_PUSH_T2      = 0xE92D,
 561         OP_AND_reg_T2   = 0xEA00,
 562         OP_TST_reg_T2   = 0xEA10,
 563         OP_ORR_reg_T2   = 0xEA40,
 564         OP_ORR_S_reg_T2 = 0xEA50,
 565         OP_ASR_imm_T1   = 0xEA4F,
 566         OP_LSL_imm_T1   = 0xEA4F,
 567         OP_LSR_imm_T1   = 0xEA4F,
 568         OP_ROR_imm_T1   = 0xEA4F,
 569         OP_MVN_reg_T2   = 0xEA6F,
 570         OP_EOR_reg_T2   = 0xEA80,
 571         OP_ADD_reg_T3   = 0xEB00,
 572         OP_ADD_S_reg_T3 = 0xEB10,
 573         OP_SUB_reg_T2   = 0xEBA0,
 574         OP_SUB_S_reg_T2 = 0xEBB0,
 575         OP_CMP_reg_T2   = 0xEBB0,
 576         OP_VMOV_CtoD    = 0xEC00,
 577         OP_VMOV_DtoC    = 0xEC10,
 578         OP_FSTS         = 0xED00,
 579         OP_VSTR         = 0xED00,
 580         OP_FLDS         = 0xED10,
 581         OP_VLDR         = 0xED10,
 582         OP_VMOV_CtoS    = 0xEE00,
 583         OP_VMOV_StoC    = 0xEE10,
 584         OP_VMUL_T2      = 0xEE20,
 585         OP_VADD_T2      = 0xEE30,
 586         OP_VSUB_T2      = 0xEE30,
 587         OP_VDIV         = 0xEE80,
 588         OP_VABS_T2      = 0xEEB0,
 589         OP_VCMP         = 0xEEB0,
 590         OP_VCVT_FPIVFP  = 0xEEB0,
 591         OP_VMOV_T2      = 0xEEB0,
 592         OP_VMOV_IMM_T2  = 0xEEB0,
 593         OP_VMRS         = 0xEEB0,
 594         OP_VNEG_T2      = 0xEEB0,
 595         OP_VSQRT_T1     = 0xEEB0,
 596         OP_VCVTSD_T1    = 0xEEB0,
 597         OP_VCVTDS_T1    = 0xEEB0,
 598         OP_B_T3a        = 0xF000,
 599         OP_B_T4a        = 0xF000,
 600         OP_AND_imm_T1   = 0xF000,
 601         OP_TST_imm      = 0xF010,
 602         OP_ORR_imm_T1   = 0xF040,
 603         OP_MOV_imm_T2   = 0xF040,
 604         OP_MVN_imm      = 0xF060,
 605         OP_EOR_imm_T1   = 0xF080,
 606         OP_ADD_imm_T3   = 0xF100,
 607         OP_ADD_S_imm_T3 = 0xF110,
 608         OP_CMN_imm      = 0xF110,
 609         OP_ADC_imm      = 0xF140,
 610         OP_SUB_imm_T3   = 0xF1A0,
 611         OP_SUB_S_imm_T3 = 0xF1B0,
 612         OP_CMP_imm_T2   = 0xF1B0,
 613         OP_RSB_imm_T2   = 0xF1C0,
 614         OP_RSB_S_imm_T2 = 0xF1D0,
 615         OP_ADD_imm_T4   = 0xF200,
 616         OP_MOV_imm_T3   = 0xF240,
 617         OP_SUB_imm_T4   = 0xF2A0,
 618         OP_MOVT         = 0xF2C0,
 619         OP_UBFX_T1      = 0xF3C0,
 620         OP_NOP_T2a      = 0xF3AF,
 621         OP_DMB_T1a      = 0xF3BF,
 622         OP_STRB_imm_T3  = 0xF800,
 623         OP_STRB_reg_T2  = 0xF800,
 624         OP_LDRB_imm_T3  = 0xF810,
 625         OP_LDRB_reg_T2  = 0xF810,
 626         OP_STRH_imm_T3  = 0xF820,
 627         OP_STRH_reg_T2  = 0xF820,
 628         OP_LDRH_reg_T2  = 0xF830,
 629         OP_LDRH_imm_T3  = 0xF830,
 630         OP_STR_imm_T4   = 0xF840,
 631         OP_STR_reg_T2   = 0xF840,
 632         OP_LDR_imm_T4   = 0xF850,
 633         OP_LDR_reg_T2   = 0xF850,
 634         OP_STRB_imm_T2  = 0xF880,
 635         OP_LDRB_imm_T2  = 0xF890,
 636         OP_STRH_imm_T2  = 0xF8A0,
 637         OP_LDRH_imm_T2  = 0xF8B0,
 638         OP_STR_imm_T3   = 0xF8C0,
 639         OP_LDR_imm_T3   = 0xF8D0,
 640         OP_LDRSB_reg_T2 = 0xF910,
 641         OP_LDRSH_reg_T2 = 0xF930,
 642         OP_LSL_reg_T2   = 0xFA00,
 643         OP_LSR_reg_T2   = 0xFA20,
 644         OP_ASR_reg_T2   = 0xFA40,
 645         OP_ROR_reg_T2   = 0xFA60,
 646         OP_CLZ          = 0xFAB0,
 647         OP_SMULL_T1     = 0xFB80,
 648 #if HAVE(ARM_IDIV_INSTRUCTIONS)
 649         OP_SDIV_T1      = 0xFB90,
 650         OP_UDIV_T1      = 0xFBB0,
 651 #endif
 652         OP_MRS_T1       = 0xF3EF,
 653     } OpcodeID1;
 654 
 655     typedef enum {
 656         OP_VADD_T2b      = 0x0A00,
 657         OP_VDIVb         = 0x0A00,
 658         OP_FLDSb         = 0x0A00,
 659         OP_VLDRb         = 0x0A00,
 660         OP_VMOV_IMM_T2b  = 0x0A00,
 661         OP_VMOV_T2b      = 0x0A40,
 662         OP_VMUL_T2b      = 0x0A00,
 663         OP_FSTSb         = 0x0A00,
 664         OP_VSTRb         = 0x0A00,
 665         OP_VMOV_StoCb    = 0x0A10,
 666         OP_VMOV_CtoSb    = 0x0A10,
 667         OP_VMOV_DtoCb    = 0x0A10,
 668         OP_VMOV_CtoDb    = 0x0A10,
 669         OP_VMRSb         = 0x0A10,
 670         OP_VABS_T2b      = 0x0A40,
 671         OP_VCMPb         = 0x0A40,
 672         OP_VCVT_FPIVFPb  = 0x0A40,
 673         OP_VNEG_T2b      = 0x0A40,
 674         OP_VSUB_T2b      = 0x0A40,
 675         OP_VSQRT_T1b     = 0x0A40,
 676         OP_VCVTSD_T1b    = 0x0A40,
 677         OP_VCVTDS_T1b    = 0x0A40,
 678         OP_NOP_T2b       = 0x8000,
 679         OP_DMB_SY_T1b    = 0x8F5F,
 680         OP_DMB_ISHST_T1b = 0x8F5A,
 681         OP_B_T3b         = 0x8000,
 682         OP_B_T4b         = 0x9000,
 683     } OpcodeID2;
 684 
 685     struct FourFours {
 686         FourFours(unsigned f3, unsigned f2, unsigned f1, unsigned f0)
 687         {
 688             m_u.f0 = f0;
 689             m_u.f1 = f1;
 690             m_u.f2 = f2;
 691             m_u.f3 = f3;
 692         }
 693 
 694         union {
 695             unsigned value;
 696             struct {
 697                 unsigned f0 : 4;
 698                 unsigned f1 : 4;
 699                 unsigned f2 : 4;
 700                 unsigned f3 : 4;
 701             };
 702         } m_u;
 703     };
 704 
 705     class ARMInstructionFormatter;
 706 
 707     // false means else!
 708     static bool ifThenElseConditionBit(Condition condition, bool isIf)
 709     {
 710         return isIf ? (condition &amp; 1) : !(condition &amp; 1);
 711     }
 712     static uint8_t ifThenElse(Condition condition, bool inst2if, bool inst3if, bool inst4if)
 713     {
 714         int mask = (ifThenElseConditionBit(condition, inst2if) &lt;&lt; 3)
 715             | (ifThenElseConditionBit(condition, inst3if) &lt;&lt; 2)
 716             | (ifThenElseConditionBit(condition, inst4if) &lt;&lt; 1)
 717             | 1;
 718         ASSERT((condition != ConditionAL) || !(mask &amp; (mask - 1)));
 719         return (condition &lt;&lt; 4) | mask;
 720     }
 721     static uint8_t ifThenElse(Condition condition, bool inst2if, bool inst3if)
 722     {
 723         int mask = (ifThenElseConditionBit(condition, inst2if) &lt;&lt; 3)
 724             | (ifThenElseConditionBit(condition, inst3if) &lt;&lt; 2)
 725             | 2;
 726         ASSERT((condition != ConditionAL) || !(mask &amp; (mask - 1)));
 727         return (condition &lt;&lt; 4) | mask;
 728     }
 729     static uint8_t ifThenElse(Condition condition, bool inst2if)
 730     {
 731         int mask = (ifThenElseConditionBit(condition, inst2if) &lt;&lt; 3)
 732             | 4;
 733         ASSERT((condition != ConditionAL) || !(mask &amp; (mask - 1)));
 734         return (condition &lt;&lt; 4) | mask;
 735     }
 736 
 737     static uint8_t ifThenElse(Condition condition)
 738     {
 739         int mask = 8;
 740         return (condition &lt;&lt; 4) | mask;
 741     }
 742 
 743 public:
 744 
 745     void adc(RegisterID rd, RegisterID rn, ARMThumbImmediate imm)
 746     {
 747         // Rd can only be SP if Rn is also SP.
 748         ASSERT((rd != ARMRegisters::sp) || (rn == ARMRegisters::sp));
 749         ASSERT(rd != ARMRegisters::pc);
 750         ASSERT(rn != ARMRegisters::pc);
 751         ASSERT(imm.isEncodedImm());
 752 
 753         m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_ADC_imm, rn, rd, imm);
 754     }
 755 
 756     void add(RegisterID rd, RegisterID rn, ARMThumbImmediate imm)
 757     {
 758         // Rd can only be SP if Rn is also SP.
 759         ASSERT((rd != ARMRegisters::sp) || (rn == ARMRegisters::sp));
 760         ASSERT(rd != ARMRegisters::pc);
 761         ASSERT(rn != ARMRegisters::pc);
 762         ASSERT(imm.isValid());
 763 
 764         if (rn == ARMRegisters::sp &amp;&amp; imm.isUInt16()) {
 765             ASSERT(!(imm.getUInt16() &amp; 3));
 766             if (!(rd &amp; 8) &amp;&amp; imm.isUInt10()) {
 767                 m_formatter.oneWordOp5Reg3Imm8(OP_ADD_SP_imm_T1, rd, static_cast&lt;uint8_t&gt;(imm.getUInt10() &gt;&gt; 2));
 768                 return;
 769             } else if ((rd == ARMRegisters::sp) &amp;&amp; imm.isUInt9()) {
 770                 m_formatter.oneWordOp9Imm7(OP_ADD_SP_imm_T2, static_cast&lt;uint8_t&gt;(imm.getUInt9() &gt;&gt; 2));
 771                 return;
 772             }
 773         } else if (!((rd | rn) &amp; 8)) {
 774             if (imm.isUInt3()) {
 775                 m_formatter.oneWordOp7Reg3Reg3Reg3(OP_ADD_imm_T1, (RegisterID)imm.getUInt3(), rn, rd);
 776                 return;
 777             } else if ((rd == rn) &amp;&amp; imm.isUInt8()) {
 778                 m_formatter.oneWordOp5Reg3Imm8(OP_ADD_imm_T2, rd, imm.getUInt8());
 779                 return;
 780             }
 781         }
 782 
 783         if (imm.isEncodedImm())
 784             m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_ADD_imm_T3, rn, rd, imm);
 785         else {
 786             ASSERT(imm.isUInt12());
 787             m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_ADD_imm_T4, rn, rd, imm);
 788         }
 789     }
 790 
 791     ALWAYS_INLINE void add(RegisterID rd, RegisterID rn, RegisterID rm, ShiftTypeAndAmount shift)
 792     {
 793         ASSERT((rd != ARMRegisters::sp) || (rn == ARMRegisters::sp));
 794         ASSERT(rd != ARMRegisters::pc);
 795         ASSERT(rn != ARMRegisters::pc);
 796         ASSERT(!BadReg(rm));
 797         m_formatter.twoWordOp12Reg4FourFours(OP_ADD_reg_T3, rn, FourFours(shift.hi4(), rd, shift.lo4(), rm));
 798     }
 799 
 800     // NOTE: In an IT block, add doesn&#39;t modify the flags register.
 801     ALWAYS_INLINE void add(RegisterID rd, RegisterID rn, RegisterID rm)
 802     {
 803         if (rd == ARMRegisters::sp) {
 804             mov(rd, rn);
 805             rn = rd;
 806         }
 807 
 808         if (rd == rn)
 809             m_formatter.oneWordOp8RegReg143(OP_ADD_reg_T2, rm, rd);
 810         else if (rd == rm)
 811             m_formatter.oneWordOp8RegReg143(OP_ADD_reg_T2, rn, rd);
 812         else if (!((rd | rn | rm) &amp; 8))
 813             m_formatter.oneWordOp7Reg3Reg3Reg3(OP_ADD_reg_T1, rm, rn, rd);
 814         else
 815             add(rd, rn, rm, ShiftTypeAndAmount());
 816     }
 817 
 818     // Not allowed in an IT (if then) block.
 819     ALWAYS_INLINE void add_S(RegisterID rd, RegisterID rn, ARMThumbImmediate imm)
 820     {
 821         // Rd can only be SP if Rn is also SP.
 822         ASSERT((rd != ARMRegisters::sp) || (rn == ARMRegisters::sp));
 823         ASSERT(rd != ARMRegisters::pc);
 824         ASSERT(rn != ARMRegisters::pc);
 825         ASSERT(imm.isEncodedImm());
 826 
 827         if (!((rd | rn) &amp; 8)) {
 828             if (imm.isUInt3()) {
 829                 m_formatter.oneWordOp7Reg3Reg3Reg3(OP_ADD_imm_T1, (RegisterID)imm.getUInt3(), rn, rd);
 830                 return;
 831             } else if ((rd == rn) &amp;&amp; imm.isUInt8()) {
 832                 m_formatter.oneWordOp5Reg3Imm8(OP_ADD_imm_T2, rd, imm.getUInt8());
 833                 return;
 834             }
 835         }
 836 
 837         m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_ADD_S_imm_T3, rn, rd, imm);
 838     }
 839 
 840     // Not allowed in an IT (if then) block?
 841     ALWAYS_INLINE void add_S(RegisterID rd, RegisterID rn, RegisterID rm, ShiftTypeAndAmount shift)
 842     {
 843         ASSERT((rd != ARMRegisters::sp) || (rn == ARMRegisters::sp));
 844         ASSERT(rd != ARMRegisters::pc);
 845         ASSERT(rn != ARMRegisters::pc);
 846         ASSERT(!BadReg(rm));
 847         m_formatter.twoWordOp12Reg4FourFours(OP_ADD_S_reg_T3, rn, FourFours(shift.hi4(), rd, shift.lo4(), rm));
 848     }
 849 
 850     // Not allowed in an IT (if then) block.
 851     ALWAYS_INLINE void add_S(RegisterID rd, RegisterID rn, RegisterID rm)
 852     {
 853         if (!((rd | rn | rm) &amp; 8))
 854             m_formatter.oneWordOp7Reg3Reg3Reg3(OP_ADD_reg_T1, rm, rn, rd);
 855         else
 856             add_S(rd, rn, rm, ShiftTypeAndAmount());
 857     }
 858 
 859     ALWAYS_INLINE void ARM_and(RegisterID rd, RegisterID rn, ARMThumbImmediate imm)
 860     {
 861         ASSERT(!BadReg(rd));
 862         ASSERT(!BadReg(rn));
 863         ASSERT(imm.isEncodedImm());
 864         m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_AND_imm_T1, rn, rd, imm);
 865     }
 866 
 867     ALWAYS_INLINE void ARM_and(RegisterID rd, RegisterID rn, RegisterID rm, ShiftTypeAndAmount shift)
 868     {
 869         ASSERT(!BadReg(rd));
 870         ASSERT(!BadReg(rn));
 871         ASSERT(!BadReg(rm));
 872         m_formatter.twoWordOp12Reg4FourFours(OP_AND_reg_T2, rn, FourFours(shift.hi4(), rd, shift.lo4(), rm));
 873     }
 874 
 875     ALWAYS_INLINE void ARM_and(RegisterID rd, RegisterID rn, RegisterID rm)
 876     {
 877         if ((rd == rn) &amp;&amp; !((rd | rm) &amp; 8))
 878             m_formatter.oneWordOp10Reg3Reg3(OP_AND_reg_T1, rm, rd);
 879         else if ((rd == rm) &amp;&amp; !((rd | rn) &amp; 8))
 880             m_formatter.oneWordOp10Reg3Reg3(OP_AND_reg_T1, rn, rd);
 881         else
 882             ARM_and(rd, rn, rm, ShiftTypeAndAmount());
 883     }
 884 
 885     ALWAYS_INLINE void asr(RegisterID rd, RegisterID rm, int32_t shiftAmount)
 886     {
 887         ASSERT(!BadReg(rd));
 888         ASSERT(!BadReg(rm));
 889         ShiftTypeAndAmount shift(SRType_ASR, shiftAmount);
 890         m_formatter.twoWordOp16FourFours(OP_ASR_imm_T1, FourFours(shift.hi4(), rd, shift.lo4(), rm));
 891     }
 892 
 893     ALWAYS_INLINE void asr(RegisterID rd, RegisterID rn, RegisterID rm)
 894     {
 895         ASSERT(!BadReg(rd));
 896         ASSERT(!BadReg(rn));
 897         ASSERT(!BadReg(rm));
 898         m_formatter.twoWordOp12Reg4FourFours(OP_ASR_reg_T2, rn, FourFours(0xf, rd, 0, rm));
 899     }
 900 
 901     // Only allowed in IT (if then) block if last instruction.
 902     ALWAYS_INLINE AssemblerLabel b()
 903     {
 904         m_formatter.twoWordOp16Op16(OP_B_T4a, OP_B_T4b);
 905         return m_formatter.label();
 906     }
 907 
 908     // Only allowed in IT (if then) block if last instruction.
 909     ALWAYS_INLINE AssemblerLabel blx(RegisterID rm)
 910     {
 911         ASSERT(rm != ARMRegisters::pc);
 912         m_formatter.oneWordOp8RegReg143(OP_BLX, rm, (RegisterID)8);
 913         return m_formatter.label();
 914     }
 915 
 916     // Only allowed in IT (if then) block if last instruction.
 917     ALWAYS_INLINE AssemblerLabel bx(RegisterID rm)
 918     {
 919         m_formatter.oneWordOp8RegReg143(OP_BX, rm, (RegisterID)0);
 920         return m_formatter.label();
 921     }
 922 
 923     void bkpt(uint8_t imm = 0)
 924     {
 925         m_formatter.oneWordOp8Imm8(OP_BKPT, imm);
 926     }
 927 
 928     static bool isBkpt(void* address)
 929     {
 930         unsigned short expected = OP_BKPT;
 931         unsigned short immediateMask = 0xff;
 932         unsigned short candidateInstruction = *reinterpret_cast&lt;unsigned short*&gt;(address);
 933         return (candidateInstruction &amp; ~immediateMask) == expected;
 934     }
 935 
 936     ALWAYS_INLINE void clz(RegisterID rd, RegisterID rm)
 937     {
 938         ASSERT(!BadReg(rd));
 939         ASSERT(!BadReg(rm));
 940         m_formatter.twoWordOp12Reg4FourFours(OP_CLZ, rm, FourFours(0xf, rd, 8, rm));
 941     }
 942 
 943     ALWAYS_INLINE void cmn(RegisterID rn, ARMThumbImmediate imm)
 944     {
 945         ASSERT(rn != ARMRegisters::pc);
 946         ASSERT(imm.isEncodedImm());
 947 
 948         m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_CMN_imm, rn, (RegisterID)0xf, imm);
 949     }
 950 
 951     ALWAYS_INLINE void cmp(RegisterID rn, ARMThumbImmediate imm)
 952     {
 953         ASSERT(rn != ARMRegisters::pc);
 954         ASSERT(imm.isEncodedImm());
 955 
 956         if (!(rn &amp; 8) &amp;&amp; imm.isUInt8())
 957             m_formatter.oneWordOp5Reg3Imm8(OP_CMP_imm_T1, rn, imm.getUInt8());
 958         else
 959             m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_CMP_imm_T2, rn, (RegisterID)0xf, imm);
 960     }
 961 
 962     ALWAYS_INLINE void cmp(RegisterID rn, RegisterID rm, ShiftTypeAndAmount shift)
 963     {
 964         ASSERT(rn != ARMRegisters::pc);
 965         ASSERT(!BadReg(rm));
 966         m_formatter.twoWordOp12Reg4FourFours(OP_CMP_reg_T2, rn, FourFours(shift.hi4(), 0xf, shift.lo4(), rm));
 967     }
 968 
 969     ALWAYS_INLINE void cmp(RegisterID rn, RegisterID rm)
 970     {
 971         if ((rn | rm) &amp; 8)
 972             cmp(rn, rm, ShiftTypeAndAmount());
 973         else
 974             m_formatter.oneWordOp10Reg3Reg3(OP_CMP_reg_T1, rm, rn);
 975     }
 976 
 977     // xor is not spelled with an &#39;e&#39;. :-(
 978     ALWAYS_INLINE void eor(RegisterID rd, RegisterID rn, ARMThumbImmediate imm)
 979     {
 980         ASSERT(!BadReg(rd));
 981         ASSERT(!BadReg(rn));
 982         ASSERT(imm.isEncodedImm());
 983         m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_EOR_imm_T1, rn, rd, imm);
 984     }
 985 
 986     // xor is not spelled with an &#39;e&#39;. :-(
 987     ALWAYS_INLINE void eor(RegisterID rd, RegisterID rn, RegisterID rm, ShiftTypeAndAmount shift)
 988     {
 989         ASSERT(!BadReg(rd));
 990         ASSERT(!BadReg(rn));
 991         ASSERT(!BadReg(rm));
 992         m_formatter.twoWordOp12Reg4FourFours(OP_EOR_reg_T2, rn, FourFours(shift.hi4(), rd, shift.lo4(), rm));
 993     }
 994 
 995     // xor is not spelled with an &#39;e&#39;. :-(
 996     void eor(RegisterID rd, RegisterID rn, RegisterID rm)
 997     {
 998         if ((rd == rn) &amp;&amp; !((rd | rm) &amp; 8))
 999             m_formatter.oneWordOp10Reg3Reg3(OP_EOR_reg_T1, rm, rd);
1000         else if ((rd == rm) &amp;&amp; !((rd | rn) &amp; 8))
1001             m_formatter.oneWordOp10Reg3Reg3(OP_EOR_reg_T1, rn, rd);
1002         else
1003             eor(rd, rn, rm, ShiftTypeAndAmount());
1004     }
1005 
1006     ALWAYS_INLINE void it(Condition cond)
1007     {
1008         m_formatter.oneWordOp8Imm8(OP_IT, ifThenElse(cond));
1009     }
1010 
1011     ALWAYS_INLINE void it(Condition cond, bool inst2if)
1012     {
1013         m_formatter.oneWordOp8Imm8(OP_IT, ifThenElse(cond, inst2if));
1014     }
1015 
1016     ALWAYS_INLINE void it(Condition cond, bool inst2if, bool inst3if)
1017     {
1018         m_formatter.oneWordOp8Imm8(OP_IT, ifThenElse(cond, inst2if, inst3if));
1019     }
1020 
1021     ALWAYS_INLINE void it(Condition cond, bool inst2if, bool inst3if, bool inst4if)
1022     {
1023         m_formatter.oneWordOp8Imm8(OP_IT, ifThenElse(cond, inst2if, inst3if, inst4if));
1024     }
1025 
1026     // rt == ARMRegisters::pc only allowed if last instruction in IT (if then) block.
1027     ALWAYS_INLINE void ldr(RegisterID rt, RegisterID rn, ARMThumbImmediate imm)
1028     {
1029         ASSERT(rn != ARMRegisters::pc); // LDR (literal)
1030         ASSERT(imm.isUInt12());
1031 
1032         if (!((rt | rn) &amp; 8) &amp;&amp; imm.isUInt7() &amp;&amp; !(imm.getUInt7() % 4)) {
1033             // We can only use Encoding T1 when imm is a multiple of 4.
1034             // For details see A8.8.63 on ARM Architecture Reference
1035             // Manual ARMv7-A and ARMv7-R edition available on
1036             // https://static.docs.arm.com/ddi0406/cd/DDI0406C_d_armv7ar_arm.pdf
1037             m_formatter.oneWordOp5Imm5Reg3Reg3(OP_LDR_imm_T1, imm.getUInt7() &gt;&gt; 2, rn, rt);
1038         } else if ((rn == ARMRegisters::sp) &amp;&amp; !(rt &amp; 8) &amp;&amp; imm.isUInt10())
1039             m_formatter.oneWordOp5Reg3Imm8(OP_LDR_imm_T2, rt, static_cast&lt;uint8_t&gt;(imm.getUInt10() &gt;&gt; 2));
1040         else
1041             m_formatter.twoWordOp12Reg4Reg4Imm12(OP_LDR_imm_T3, rn, rt, imm.getUInt12());
1042     }
1043 
1044     ALWAYS_INLINE void ldrWide8BitImmediate(RegisterID rt, RegisterID rn, uint8_t immediate)
1045     {
1046         ASSERT(rn != ARMRegisters::pc);
1047         m_formatter.twoWordOp12Reg4Reg4Imm12(OP_LDR_imm_T3, rn, rt, immediate);
1048     }
1049 
1050     ALWAYS_INLINE void ldrCompact(RegisterID rt, RegisterID rn, ARMThumbImmediate imm)
1051     {
1052         ASSERT(rn != ARMRegisters::pc); // LDR (literal)
1053         ASSERT(imm.isUInt7());
1054         ASSERT(!((rt | rn) &amp; 8));
1055         m_formatter.oneWordOp5Imm5Reg3Reg3(OP_LDR_imm_T1, imm.getUInt7() &gt;&gt; 2, rn, rt);
1056     }
1057 
1058     // If index is set, this is a regular offset or a pre-indexed load;
1059     // if index is not set then is is a post-index load.
1060     //
1061     // If wback is set rn is updated - this is a pre or post index load,
1062     // if wback is not set this is a regular offset memory access.
1063     //
1064     // (-255 &lt;= offset &lt;= 255)
1065     // _reg = REG[rn]
1066     // _tmp = _reg + offset
1067     // MEM[index ? _tmp : _reg] = REG[rt]
1068     // if (wback) REG[rn] = _tmp
1069     ALWAYS_INLINE void ldr(RegisterID rt, RegisterID rn, int offset, bool index, bool wback)
1070     {
1071         ASSERT(rt != ARMRegisters::pc);
1072         ASSERT(rn != ARMRegisters::pc);
1073         ASSERT(index || wback);
1074         ASSERT(!wback | (rt != rn));
1075 
1076         bool add = true;
1077         if (offset &lt; 0) {
1078             add = false;
1079             offset = -offset;
1080         }
1081         ASSERT((offset &amp; ~0xff) == 0);
1082 
1083         offset |= (wback &lt;&lt; 8);
1084         offset |= (add   &lt;&lt; 9);
1085         offset |= (index &lt;&lt; 10);
1086         offset |= (1 &lt;&lt; 11);
1087 
1088         m_formatter.twoWordOp12Reg4Reg4Imm12(OP_LDR_imm_T4, rn, rt, offset);
1089     }
1090 
1091     // rt == ARMRegisters::pc only allowed if last instruction in IT (if then) block.
1092     ALWAYS_INLINE void ldr(RegisterID rt, RegisterID rn, RegisterID rm, unsigned shift = 0)
1093     {
1094         ASSERT(rn != ARMRegisters::pc); // LDR (literal)
1095         ASSERT(!BadReg(rm));
1096         ASSERT(shift &lt;= 3);
1097 
1098         if (!shift &amp;&amp; !((rt | rn | rm) &amp; 8))
1099             m_formatter.oneWordOp7Reg3Reg3Reg3(OP_LDR_reg_T1, rm, rn, rt);
1100         else
1101             m_formatter.twoWordOp12Reg4FourFours(OP_LDR_reg_T2, rn, FourFours(rt, 0, shift, rm));
1102     }
1103 
1104     // rt == ARMRegisters::pc only allowed if last instruction in IT (if then) block.
1105     ALWAYS_INLINE void ldrh(RegisterID rt, RegisterID rn, ARMThumbImmediate imm)
1106     {
1107         ASSERT(rn != ARMRegisters::pc); // LDR (literal)
1108         ASSERT(imm.isUInt12());
1109         ASSERT(!(imm.getUInt12() &amp; 1));
1110 
1111         if (!((rt | rn) &amp; 8) &amp;&amp; imm.isUInt6())
1112             m_formatter.oneWordOp5Imm5Reg3Reg3(OP_LDRH_imm_T1, imm.getUInt6() &gt;&gt; 1, rn, rt);
1113         else
1114             m_formatter.twoWordOp12Reg4Reg4Imm12(OP_LDRH_imm_T2, rn, rt, imm.getUInt12());
1115     }
1116 
1117     // If index is set, this is a regular offset or a pre-indexed load;
1118     // if index is not set then is is a post-index load.
1119     //
1120     // If wback is set rn is updated - this is a pre or post index load,
1121     // if wback is not set this is a regular offset memory access.
1122     //
1123     // (-255 &lt;= offset &lt;= 255)
1124     // _reg = REG[rn]
1125     // _tmp = _reg + offset
1126     // MEM[index ? _tmp : _reg] = REG[rt]
1127     // if (wback) REG[rn] = _tmp
1128     ALWAYS_INLINE void ldrh(RegisterID rt, RegisterID rn, int offset, bool index, bool wback)
1129     {
1130         ASSERT(rt != ARMRegisters::pc);
1131         ASSERT(rn != ARMRegisters::pc);
1132         ASSERT(index || wback);
1133         ASSERT(!wback | (rt != rn));
1134 
1135         bool add = true;
1136         if (offset &lt; 0) {
1137             add = false;
1138             offset = -offset;
1139         }
1140         ASSERT((offset &amp; ~0xff) == 0);
1141 
1142         offset |= (wback &lt;&lt; 8);
1143         offset |= (add   &lt;&lt; 9);
1144         offset |= (index &lt;&lt; 10);
1145         offset |= (1 &lt;&lt; 11);
1146 
1147         m_formatter.twoWordOp12Reg4Reg4Imm12(OP_LDRH_imm_T3, rn, rt, offset);
1148     }
1149 
1150     ALWAYS_INLINE void ldrh(RegisterID rt, RegisterID rn, RegisterID rm, unsigned shift = 0)
1151     {
1152         ASSERT(!BadReg(rt));   // Memory hint
1153         ASSERT(rn != ARMRegisters::pc); // LDRH (literal)
1154         ASSERT(!BadReg(rm));
1155         ASSERT(shift &lt;= 3);
1156 
1157         if (!shift &amp;&amp; !((rt | rn | rm) &amp; 8))
1158             m_formatter.oneWordOp7Reg3Reg3Reg3(OP_LDRH_reg_T1, rm, rn, rt);
1159         else
1160             m_formatter.twoWordOp12Reg4FourFours(OP_LDRH_reg_T2, rn, FourFours(rt, 0, shift, rm));
1161     }
1162 
1163     void ldrb(RegisterID rt, RegisterID rn, ARMThumbImmediate imm)
1164     {
1165         ASSERT(rn != ARMRegisters::pc); // LDR (literal)
1166         ASSERT(imm.isUInt12());
1167 
1168         if (!((rt | rn) &amp; 8) &amp;&amp; imm.isUInt5())
1169             m_formatter.oneWordOp5Imm5Reg3Reg3(OP_LDRB_imm_T1, imm.getUInt5(), rn, rt);
1170         else
1171             m_formatter.twoWordOp12Reg4Reg4Imm12(OP_LDRB_imm_T2, rn, rt, imm.getUInt12());
1172     }
1173 
1174     void ldrb(RegisterID rt, RegisterID rn, int offset, bool index, bool wback)
1175     {
1176         ASSERT(rt != ARMRegisters::pc);
1177         ASSERT(rn != ARMRegisters::pc);
1178         ASSERT(index || wback);
1179         ASSERT(!wback | (rt != rn));
1180 
1181         bool add = true;
1182         if (offset &lt; 0) {
1183             add = false;
1184             offset = -offset;
1185         }
1186 
1187         ASSERT(!(offset &amp; ~0xff));
1188 
1189         offset |= (wback &lt;&lt; 8);
1190         offset |= (add   &lt;&lt; 9);
1191         offset |= (index &lt;&lt; 10);
1192         offset |= (1 &lt;&lt; 11);
1193 
1194         m_formatter.twoWordOp12Reg4Reg4Imm12(OP_LDRB_imm_T3, rn, rt, offset);
1195     }
1196 
1197     ALWAYS_INLINE void ldrb(RegisterID rt, RegisterID rn, RegisterID rm, unsigned shift = 0)
1198     {
1199         ASSERT(rn != ARMRegisters::pc); // LDR (literal)
1200         ASSERT(!BadReg(rm));
1201         ASSERT(shift &lt;= 3);
1202 
1203         if (!shift &amp;&amp; !((rt | rn | rm) &amp; 8))
1204             m_formatter.oneWordOp7Reg3Reg3Reg3(OP_LDRB_reg_T1, rm, rn, rt);
1205         else
1206             m_formatter.twoWordOp12Reg4FourFours(OP_LDRB_reg_T2, rn, FourFours(rt, 0, shift, rm));
1207     }
1208 
1209     void ldrsb(RegisterID rt, RegisterID rn, RegisterID rm, unsigned shift = 0)
1210     {
1211         ASSERT(rn != ARMRegisters::pc);
1212         ASSERT(!BadReg(rm));
1213         ASSERT(shift &lt;= 3);
1214 
1215         if (!shift &amp;&amp; !((rt | rn | rm) &amp; 8))
1216             m_formatter.oneWordOp7Reg3Reg3Reg3(OP_LDRSB_reg_T1, rm, rn, rt);
1217         else
1218             m_formatter.twoWordOp12Reg4FourFours(OP_LDRSB_reg_T2, rn, FourFours(rt, 0, shift, rm));
1219     }
1220 
1221     void ldrsh(RegisterID rt, RegisterID rn, RegisterID rm, unsigned shift = 0)
1222     {
1223         ASSERT(rn != ARMRegisters::pc);
1224         ASSERT(!BadReg(rm));
1225         ASSERT(shift &lt;= 3);
1226 
1227         if (!shift &amp;&amp; !((rt | rn | rm) &amp; 8))
1228             m_formatter.oneWordOp7Reg3Reg3Reg3(OP_LDRSH_reg_T1, rm, rn, rt);
1229         else
1230             m_formatter.twoWordOp12Reg4FourFours(OP_LDRSH_reg_T2, rn, FourFours(rt, 0, shift, rm));
1231     }
1232 
1233     void lsl(RegisterID rd, RegisterID rm, int32_t shiftAmount)
1234     {
1235         ASSERT(!BadReg(rd));
1236         ASSERT(!BadReg(rm));
1237         ShiftTypeAndAmount shift(SRType_LSL, shiftAmount);
1238         m_formatter.twoWordOp16FourFours(OP_LSL_imm_T1, FourFours(shift.hi4(), rd, shift.lo4(), rm));
1239     }
1240 
1241     ALWAYS_INLINE void lsl(RegisterID rd, RegisterID rn, RegisterID rm)
1242     {
1243         ASSERT(!BadReg(rd));
1244         ASSERT(!BadReg(rn));
1245         ASSERT(!BadReg(rm));
1246         m_formatter.twoWordOp12Reg4FourFours(OP_LSL_reg_T2, rn, FourFours(0xf, rd, 0, rm));
1247     }
1248 
1249     ALWAYS_INLINE void lsr(RegisterID rd, RegisterID rm, int32_t shiftAmount)
1250     {
1251         ASSERT(!BadReg(rd));
1252         ASSERT(!BadReg(rm));
1253         ShiftTypeAndAmount shift(SRType_LSR, shiftAmount);
1254         m_formatter.twoWordOp16FourFours(OP_LSR_imm_T1, FourFours(shift.hi4(), rd, shift.lo4(), rm));
1255     }
1256 
1257     ALWAYS_INLINE void lsr(RegisterID rd, RegisterID rn, RegisterID rm)
1258     {
1259         ASSERT(!BadReg(rd));
1260         ASSERT(!BadReg(rn));
1261         ASSERT(!BadReg(rm));
1262         m_formatter.twoWordOp12Reg4FourFours(OP_LSR_reg_T2, rn, FourFours(0xf, rd, 0, rm));
1263     }
1264 
1265     ALWAYS_INLINE void movT3(RegisterID rd, ARMThumbImmediate imm)
1266     {
1267         ASSERT(imm.isValid());
1268         ASSERT(!imm.isEncodedImm());
1269         ASSERT(!BadReg(rd));
1270 
1271         m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_MOV_imm_T3, imm.m_value.imm4, rd, imm);
1272     }
1273 
1274 #if OS(LINUX)
1275     static void revertJumpTo_movT3movtcmpT2(void* instructionStart, RegisterID left, RegisterID right, uintptr_t imm)
1276     {
1277         uint16_t* address = static_cast&lt;uint16_t*&gt;(instructionStart);
1278         ARMThumbImmediate lo16 = ARMThumbImmediate::makeUInt16(static_cast&lt;uint16_t&gt;(imm));
1279         ARMThumbImmediate hi16 = ARMThumbImmediate::makeUInt16(static_cast&lt;uint16_t&gt;(imm &gt;&gt; 16));
1280         uint16_t instruction[] = {
1281             twoWordOp5i6Imm4Reg4EncodedImmFirst(OP_MOV_imm_T3, lo16),
1282             twoWordOp5i6Imm4Reg4EncodedImmSecond(right, lo16),
1283             twoWordOp5i6Imm4Reg4EncodedImmFirst(OP_MOVT, hi16),
1284             twoWordOp5i6Imm4Reg4EncodedImmSecond(right, hi16),
1285             static_cast&lt;uint16_t&gt;(OP_CMP_reg_T2 | left)
1286         };
1287         performJITMemcpy(address, instruction, sizeof(uint16_t) * 5);
1288         cacheFlush(address, sizeof(uint16_t) * 5);
1289     }
1290 #else
1291     static void revertJumpTo_movT3(void* instructionStart, RegisterID rd, ARMThumbImmediate imm)
1292     {
1293         ASSERT(imm.isValid());
1294         ASSERT(!imm.isEncodedImm());
1295         ASSERT(!BadReg(rd));
1296 
1297         uint16_t* address = static_cast&lt;uint16_t*&gt;(instructionStart);
1298         uint16_t instruction[] = {
1299             twoWordOp5i6Imm4Reg4EncodedImmFirst(OP_MOV_imm_T3, imm),
1300             twoWordOp5i6Imm4Reg4EncodedImmSecond(rd, imm)
1301         };
1302         performJITMemcpy(address, instruction, sizeof(uint16_t) * 2);
1303         cacheFlush(address, sizeof(uint16_t) * 2);
1304     }
1305 #endif
1306 
1307     ALWAYS_INLINE void mov(RegisterID rd, ARMThumbImmediate imm)
1308     {
1309         ASSERT(imm.isValid());
1310         ASSERT(!BadReg(rd));
1311 
1312         if ((rd &lt; 8) &amp;&amp; imm.isUInt8())
1313             m_formatter.oneWordOp5Reg3Imm8(OP_MOV_imm_T1, rd, imm.getUInt8());
1314         else if (imm.isEncodedImm())
1315             m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_MOV_imm_T2, 0xf, rd, imm);
1316         else
1317             movT3(rd, imm);
1318     }
1319 
1320     ALWAYS_INLINE void mov(RegisterID rd, RegisterID rm)
1321     {
1322         m_formatter.oneWordOp8RegReg143(OP_MOV_reg_T1, rm, rd);
1323     }
1324 
1325     ALWAYS_INLINE void movt(RegisterID rd, ARMThumbImmediate imm)
1326     {
1327         ASSERT(imm.isUInt16());
1328         ASSERT(!BadReg(rd));
1329         m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_MOVT, imm.m_value.imm4, rd, imm);
1330     }
1331 
1332     ALWAYS_INLINE void mvn(RegisterID rd, ARMThumbImmediate imm)
1333     {
1334         ASSERT(imm.isEncodedImm());
1335         ASSERT(!BadReg(rd));
1336 
1337         m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_MVN_imm, 0xf, rd, imm);
1338     }
1339 
1340     ALWAYS_INLINE void mvn(RegisterID rd, RegisterID rm, ShiftTypeAndAmount shift)
1341     {
1342         ASSERT(!BadReg(rd));
1343         ASSERT(!BadReg(rm));
1344         m_formatter.twoWordOp16FourFours(OP_MVN_reg_T2, FourFours(shift.hi4(), rd, shift.lo4(), rm));
1345     }
1346 
1347     ALWAYS_INLINE void mvn(RegisterID rd, RegisterID rm)
1348     {
1349         if (!((rd | rm) &amp; 8))
1350             m_formatter.oneWordOp10Reg3Reg3(OP_MVN_reg_T1, rm, rd);
1351         else
1352             mvn(rd, rm, ShiftTypeAndAmount());
1353     }
1354 
1355     ALWAYS_INLINE void mrs(RegisterID rd, SPRegisterID specReg)
1356     {
1357         ASSERT(specReg == ARMRegisters::apsr);
1358         ASSERT(!BadReg(rd));
1359         unsigned short specialRegisterBit = (specReg == ARMRegisters::apsr) ? 0 : (1 &lt;&lt; 4);
1360         OpcodeID1 mrsOp = static_cast&lt;OpcodeID1&gt;(OP_MRS_T1 | specialRegisterBit);
1361         m_formatter.twoWordOp16FourFours(mrsOp, FourFours(0x8, rd, 0, 0));
1362     }
1363 
1364     ALWAYS_INLINE void neg(RegisterID rd, RegisterID rm)
1365     {
1366         ARMThumbImmediate zero = ARMThumbImmediate::makeUInt12(0);
1367         sub(rd, zero, rm);
1368     }
1369 
1370     ALWAYS_INLINE void orr(RegisterID rd, RegisterID rn, ARMThumbImmediate imm)
1371     {
1372         ASSERT(!BadReg(rd));
1373         ASSERT(!BadReg(rn));
1374         ASSERT(imm.isEncodedImm());
1375         m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_ORR_imm_T1, rn, rd, imm);
1376     }
1377 
1378     ALWAYS_INLINE void orr(RegisterID rd, RegisterID rn, RegisterID rm, ShiftTypeAndAmount shift)
1379     {
1380         ASSERT(!BadReg(rd));
1381         ASSERT(!BadReg(rn));
1382         ASSERT(!BadReg(rm));
1383         m_formatter.twoWordOp12Reg4FourFours(OP_ORR_reg_T2, rn, FourFours(shift.hi4(), rd, shift.lo4(), rm));
1384     }
1385 
1386     void orr(RegisterID rd, RegisterID rn, RegisterID rm)
1387     {
1388         if ((rd == rn) &amp;&amp; !((rd | rm) &amp; 8))
1389             m_formatter.oneWordOp10Reg3Reg3(OP_ORR_reg_T1, rm, rd);
1390         else if ((rd == rm) &amp;&amp; !((rd | rn) &amp; 8))
1391             m_formatter.oneWordOp10Reg3Reg3(OP_ORR_reg_T1, rn, rd);
1392         else
1393             orr(rd, rn, rm, ShiftTypeAndAmount());
1394     }
1395 
1396     ALWAYS_INLINE void orr_S(RegisterID rd, RegisterID rn, RegisterID rm, ShiftTypeAndAmount shift)
1397     {
1398         ASSERT(!BadReg(rd));
1399         ASSERT(!BadReg(rn));
1400         ASSERT(!BadReg(rm));
1401         m_formatter.twoWordOp12Reg4FourFours(OP_ORR_S_reg_T2, rn, FourFours(shift.hi4(), rd, shift.lo4(), rm));
1402     }
1403 
1404     void orr_S(RegisterID rd, RegisterID rn, RegisterID rm)
1405     {
1406         if ((rd == rn) &amp;&amp; !((rd | rm) &amp; 8))
1407             m_formatter.oneWordOp10Reg3Reg3(OP_ORR_reg_T1, rm, rd);
1408         else if ((rd == rm) &amp;&amp; !((rd | rn) &amp; 8))
1409             m_formatter.oneWordOp10Reg3Reg3(OP_ORR_reg_T1, rn, rd);
1410         else
1411             orr_S(rd, rn, rm, ShiftTypeAndAmount());
1412     }
1413 
1414     ALWAYS_INLINE void ror(RegisterID rd, RegisterID rm, int32_t shiftAmount)
1415     {
1416         ASSERT(!BadReg(rd));
1417         ASSERT(!BadReg(rm));
1418         ShiftTypeAndAmount shift(SRType_ROR, shiftAmount);
1419         m_formatter.twoWordOp16FourFours(OP_ROR_imm_T1, FourFours(shift.hi4(), rd, shift.lo4(), rm));
1420     }
1421 
1422     ALWAYS_INLINE void ror(RegisterID rd, RegisterID rn, RegisterID rm)
1423     {
1424         ASSERT(!BadReg(rd));
1425         ASSERT(!BadReg(rn));
1426         ASSERT(!BadReg(rm));
1427         m_formatter.twoWordOp12Reg4FourFours(OP_ROR_reg_T2, rn, FourFours(0xf, rd, 0, rm));
1428     }
1429 
1430     ALWAYS_INLINE void pop(RegisterID dest)
1431     {
1432         if (dest &lt; ARMRegisters::r8)
1433             m_formatter.oneWordOp7Imm9(OP_POP_T1, 1 &lt;&lt; dest);
1434         else {
1435             // Load postindexed with writeback.
1436             ldr(dest, ARMRegisters::sp, sizeof(void*), false, true);
1437         }
1438     }
1439 
1440     ALWAYS_INLINE void pop(uint32_t registerList)
1441     {
1442         ASSERT(WTF::bitCount(registerList) &gt; 1);
1443         ASSERT(!((1 &lt;&lt; ARMRegisters::pc) &amp; registerList) || !((1 &lt;&lt; ARMRegisters::lr) &amp; registerList));
1444         ASSERT(!((1 &lt;&lt; ARMRegisters::sp) &amp; registerList));
1445         m_formatter.twoWordOp16Imm16(OP_POP_T2, registerList);
1446     }
1447 
1448     ALWAYS_INLINE void push(RegisterID src)
1449     {
1450         if (src &lt; ARMRegisters::r8)
1451             m_formatter.oneWordOp7Imm9(OP_PUSH_T1, 1 &lt;&lt; src);
1452         else if (src == ARMRegisters::lr)
1453             m_formatter.oneWordOp7Imm9(OP_PUSH_T1, 0x100);
1454         else {
1455             // Store preindexed with writeback.
1456             str(src, ARMRegisters::sp, -sizeof(void*), true, true);
1457         }
1458     }
1459 
1460     ALWAYS_INLINE void push(uint32_t registerList)
1461     {
1462         ASSERT(WTF::bitCount(registerList) &gt; 1);
1463         ASSERT(!((1 &lt;&lt; ARMRegisters::pc) &amp; registerList));
1464         ASSERT(!((1 &lt;&lt; ARMRegisters::sp) &amp; registerList));
1465         m_formatter.twoWordOp16Imm16(OP_PUSH_T2, registerList);
1466     }
1467 
1468 #if HAVE(ARM_IDIV_INSTRUCTIONS)
1469     template&lt;int datasize&gt;
1470     ALWAYS_INLINE void sdiv(RegisterID rd, RegisterID rn, RegisterID rm)
1471     {
1472         static_assert(datasize == 32, &quot;sdiv datasize must be 32 for armv7s&quot;);
1473         ASSERT(!BadReg(rd));
1474         ASSERT(!BadReg(rn));
1475         ASSERT(!BadReg(rm));
1476         m_formatter.twoWordOp12Reg4FourFours(OP_SDIV_T1, rn, FourFours(0xf, rd, 0xf, rm));
1477     }
1478 #endif
1479 
1480     ALWAYS_INLINE void smull(RegisterID rdLo, RegisterID rdHi, RegisterID rn, RegisterID rm)
1481     {
1482         ASSERT(!BadReg(rdLo));
1483         ASSERT(!BadReg(rdHi));
1484         ASSERT(!BadReg(rn));
1485         ASSERT(!BadReg(rm));
1486         ASSERT(rdLo != rdHi);
1487         m_formatter.twoWordOp12Reg4FourFours(OP_SMULL_T1, rn, FourFours(rdLo, rdHi, 0, rm));
1488     }
1489 
1490     // rt == ARMRegisters::pc only allowed if last instruction in IT (if then) block.
1491     ALWAYS_INLINE void str(RegisterID rt, RegisterID rn, ARMThumbImmediate imm)
1492     {
1493         ASSERT(rt != ARMRegisters::pc);
1494         ASSERT(rn != ARMRegisters::pc);
1495         ASSERT(imm.isUInt12());
1496 
1497         if (!((rt | rn) &amp; 8) &amp;&amp; imm.isUInt7())
1498             m_formatter.oneWordOp5Imm5Reg3Reg3(OP_STR_imm_T1, imm.getUInt7() &gt;&gt; 2, rn, rt);
1499         else if ((rn == ARMRegisters::sp) &amp;&amp; !(rt &amp; 8) &amp;&amp; imm.isUInt10())
1500             m_formatter.oneWordOp5Reg3Imm8(OP_STR_imm_T2, rt, static_cast&lt;uint8_t&gt;(imm.getUInt10() &gt;&gt; 2));
1501         else
1502             m_formatter.twoWordOp12Reg4Reg4Imm12(OP_STR_imm_T3, rn, rt, imm.getUInt12());
1503     }
1504 
1505     // If index is set, this is a regular offset or a pre-indexed store;
1506     // if index is not set then is is a post-index store.
1507     //
1508     // If wback is set rn is updated - this is a pre or post index store,
1509     // if wback is not set this is a regular offset memory access.
1510     //
1511     // (-255 &lt;= offset &lt;= 255)
1512     // _reg = REG[rn]
1513     // _tmp = _reg + offset
1514     // MEM[index ? _tmp : _reg] = REG[rt]
1515     // if (wback) REG[rn] = _tmp
1516     ALWAYS_INLINE void str(RegisterID rt, RegisterID rn, int offset, bool index, bool wback)
1517     {
1518         ASSERT(rt != ARMRegisters::pc);
1519         ASSERT(rn != ARMRegisters::pc);
1520         ASSERT(index || wback);
1521         ASSERT(!wback | (rt != rn));
1522 
1523         bool add = true;
1524         if (offset &lt; 0) {
1525             add = false;
1526             offset = -offset;
1527         }
1528         ASSERT((offset &amp; ~0xff) == 0);
1529 
1530         offset |= (wback &lt;&lt; 8);
1531         offset |= (add   &lt;&lt; 9);
1532         offset |= (index &lt;&lt; 10);
1533         offset |= (1 &lt;&lt; 11);
1534 
1535         m_formatter.twoWordOp12Reg4Reg4Imm12(OP_STR_imm_T4, rn, rt, offset);
1536     }
1537 
1538     // rt == ARMRegisters::pc only allowed if last instruction in IT (if then) block.
1539     ALWAYS_INLINE void str(RegisterID rt, RegisterID rn, RegisterID rm, unsigned shift = 0)
1540     {
1541         ASSERT(rn != ARMRegisters::pc);
1542         ASSERT(!BadReg(rm));
1543         ASSERT(shift &lt;= 3);
1544 
1545         if (!shift &amp;&amp; !((rt | rn | rm) &amp; 8))
1546             m_formatter.oneWordOp7Reg3Reg3Reg3(OP_STR_reg_T1, rm, rn, rt);
1547         else
1548             m_formatter.twoWordOp12Reg4FourFours(OP_STR_reg_T2, rn, FourFours(rt, 0, shift, rm));
1549     }
1550 
1551     // rt == ARMRegisters::pc only allowed if last instruction in IT (if then) block.
1552     ALWAYS_INLINE void strb(RegisterID rt, RegisterID rn, ARMThumbImmediate imm)
1553     {
1554         ASSERT(rt != ARMRegisters::pc);
1555         ASSERT(rn != ARMRegisters::pc);
1556         ASSERT(imm.isUInt12());
1557 
1558         if (!((rt | rn) &amp; 8) &amp;&amp; imm.isUInt7())
1559             m_formatter.oneWordOp5Imm5Reg3Reg3(OP_STRB_imm_T1, imm.getUInt7() &gt;&gt; 2, rn, rt);
1560         else
1561             m_formatter.twoWordOp12Reg4Reg4Imm12(OP_STRB_imm_T2, rn, rt, imm.getUInt12());
1562     }
1563 
1564     // If index is set, this is a regular offset or a pre-indexed store;
1565     // if index is not set then is is a post-index store.
1566     //
1567     // If wback is set rn is updated - this is a pre or post index store,
1568     // if wback is not set this is a regular offset memory access.
1569     //
1570     // (-255 &lt;= offset &lt;= 255)
1571     // _reg = REG[rn]
1572     // _tmp = _reg + offset
1573     // MEM[index ? _tmp : _reg] = REG[rt]
1574     // if (wback) REG[rn] = _tmp
1575     ALWAYS_INLINE void strb(RegisterID rt, RegisterID rn, int offset, bool index, bool wback)
1576     {
1577         ASSERT(rt != ARMRegisters::pc);
1578         ASSERT(rn != ARMRegisters::pc);
1579         ASSERT(index || wback);
1580         ASSERT(!wback | (rt != rn));
1581 
1582         bool add = true;
1583         if (offset &lt; 0) {
1584             add = false;
1585             offset = -offset;
1586         }
1587         ASSERT((offset &amp; ~0xff) == 0);
1588 
1589         offset |= (wback &lt;&lt; 8);
1590         offset |= (add   &lt;&lt; 9);
1591         offset |= (index &lt;&lt; 10);
1592         offset |= (1 &lt;&lt; 11);
1593 
1594         m_formatter.twoWordOp12Reg4Reg4Imm12(OP_STRB_imm_T3, rn, rt, offset);
1595     }
1596 
1597     // rt == ARMRegisters::pc only allowed if last instruction in IT (if then) block.
1598     ALWAYS_INLINE void strb(RegisterID rt, RegisterID rn, RegisterID rm, unsigned shift = 0)
1599     {
1600         ASSERT(rn != ARMRegisters::pc);
1601         ASSERT(!BadReg(rm));
1602         ASSERT(shift &lt;= 3);
1603 
1604         if (!shift &amp;&amp; !((rt | rn | rm) &amp; 8))
1605             m_formatter.oneWordOp7Reg3Reg3Reg3(OP_STRB_reg_T1, rm, rn, rt);
1606         else
1607             m_formatter.twoWordOp12Reg4FourFours(OP_STRB_reg_T2, rn, FourFours(rt, 0, shift, rm));
1608     }
1609 
1610     // rt == ARMRegisters::pc only allowed if last instruction in IT (if then) block.
1611     ALWAYS_INLINE void strh(RegisterID rt, RegisterID rn, ARMThumbImmediate imm)
1612     {
1613         ASSERT(rt != ARMRegisters::pc);
1614         ASSERT(rn != ARMRegisters::pc);
1615         ASSERT(imm.isUInt12());
1616 
1617         if (!((rt | rn) &amp; 8) &amp;&amp; imm.isUInt6())
1618             m_formatter.oneWordOp5Imm5Reg3Reg3(OP_STRH_imm_T1, imm.getUInt6() &gt;&gt; 1, rn, rt);
1619         else
1620             m_formatter.twoWordOp12Reg4Reg4Imm12(OP_STRH_imm_T2, rn, rt, imm.getUInt12());
1621     }
1622 
1623     // If index is set, this is a regular offset or a pre-indexed store;
1624     // if index is not set then is is a post-index store.
1625     //
1626     // If wback is set rn is updated - this is a pre or post index store,
1627     // if wback is not set this is a regular offset memory access.
1628     //
1629     // (-255 &lt;= offset &lt;= 255)
1630     // _reg = REG[rn]
1631     // _tmp = _reg + offset
1632     // MEM[index ? _tmp : _reg] = REG[rt]
1633     // if (wback) REG[rn] = _tmp
1634     ALWAYS_INLINE void strh(RegisterID rt, RegisterID rn, int offset, bool index, bool wback)
1635     {
1636         ASSERT(rt != ARMRegisters::pc);
1637         ASSERT(rn != ARMRegisters::pc);
1638         ASSERT(index || wback);
1639         ASSERT(!wback | (rt != rn));
1640 
1641         bool add = true;
1642         if (offset &lt; 0) {
1643             add = false;
1644             offset = -offset;
1645         }
1646         ASSERT(!(offset &amp; ~0xff));
1647 
1648         offset |= (wback &lt;&lt; 8);
1649         offset |= (add   &lt;&lt; 9);
1650         offset |= (index &lt;&lt; 10);
1651         offset |= (1 &lt;&lt; 11);
1652 
1653         m_formatter.twoWordOp12Reg4Reg4Imm12(OP_STRH_imm_T3, rn, rt, offset);
1654     }
1655 
1656     // rt == ARMRegisters::pc only allowed if last instruction in IT (if then) block.
1657     ALWAYS_INLINE void strh(RegisterID rt, RegisterID rn, RegisterID rm, unsigned shift = 0)
1658     {
1659         ASSERT(rn != ARMRegisters::pc);
1660         ASSERT(!BadReg(rm));
1661         ASSERT(shift &lt;= 3);
1662 
1663         if (!shift &amp;&amp; !((rt | rn | rm) &amp; 8))
1664             m_formatter.oneWordOp7Reg3Reg3Reg3(OP_STRH_reg_T1, rm, rn, rt);
1665         else
1666             m_formatter.twoWordOp12Reg4FourFours(OP_STRH_reg_T2, rn, FourFours(rt, 0, shift, rm));
1667     }
1668 
1669     ALWAYS_INLINE void sub(RegisterID rd, RegisterID rn, ARMThumbImmediate imm)
1670     {
1671         // Rd can only be SP if Rn is also SP.
1672         ASSERT((rd != ARMRegisters::sp) || (rn == ARMRegisters::sp));
1673         ASSERT(rd != ARMRegisters::pc);
1674         ASSERT(rn != ARMRegisters::pc);
1675         ASSERT(imm.isValid());
1676 
1677         if ((rn == ARMRegisters::sp) &amp;&amp; (rd == ARMRegisters::sp) &amp;&amp; imm.isUInt9()) {
1678             ASSERT(!(imm.getUInt16() &amp; 3));
1679             m_formatter.oneWordOp9Imm7(OP_SUB_SP_imm_T1, static_cast&lt;uint8_t&gt;(imm.getUInt9() &gt;&gt; 2));
1680             return;
1681         } else if (!((rd | rn) &amp; 8)) {
1682             if (imm.isUInt3()) {
1683                 m_formatter.oneWordOp7Reg3Reg3Reg3(OP_SUB_imm_T1, (RegisterID)imm.getUInt3(), rn, rd);
1684                 return;
1685             } else if ((rd == rn) &amp;&amp; imm.isUInt8()) {
1686                 m_formatter.oneWordOp5Reg3Imm8(OP_SUB_imm_T2, rd, imm.getUInt8());
1687                 return;
1688             }
1689         }
1690 
1691         if (imm.isEncodedImm())
1692             m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_SUB_imm_T3, rn, rd, imm);
1693         else {
1694             ASSERT(imm.isUInt12());
1695             m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_SUB_imm_T4, rn, rd, imm);
1696         }
1697     }
1698 
1699     ALWAYS_INLINE void sub(RegisterID rd, ARMThumbImmediate imm, RegisterID rn)
1700     {
1701         ASSERT(rd != ARMRegisters::pc);
1702         ASSERT(rn != ARMRegisters::pc);
1703         ASSERT(imm.isValid());
1704         ASSERT(imm.isUInt12());
1705 
1706         if (!((rd | rn) &amp; 8) &amp;&amp; !imm.getUInt12())
1707             m_formatter.oneWordOp10Reg3Reg3(OP_RSB_imm_T1, rn, rd);
1708         else
1709             m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_RSB_imm_T2, rn, rd, imm);
1710     }
1711 
1712     ALWAYS_INLINE void sub(RegisterID rd, RegisterID rn, RegisterID rm, ShiftTypeAndAmount shift)
1713     {
1714         ASSERT((rd != ARMRegisters::sp) || (rn == ARMRegisters::sp));
1715         ASSERT(rd != ARMRegisters::pc);
1716         ASSERT(rn != ARMRegisters::pc);
1717         ASSERT(!BadReg(rm));
1718         m_formatter.twoWordOp12Reg4FourFours(OP_SUB_reg_T2, rn, FourFours(shift.hi4(), rd, shift.lo4(), rm));
1719     }
1720 
1721     // NOTE: In an IT block, add doesn&#39;t modify the flags register.
1722     ALWAYS_INLINE void sub(RegisterID rd, RegisterID rn, RegisterID rm)
1723     {
1724         if (!((rd | rn | rm) &amp; 8))
1725             m_formatter.oneWordOp7Reg3Reg3Reg3(OP_SUB_reg_T1, rm, rn, rd);
1726         else
1727             sub(rd, rn, rm, ShiftTypeAndAmount());
1728     }
1729 
1730     // Not allowed in an IT (if then) block.
1731     void sub_S(RegisterID rd, RegisterID rn, ARMThumbImmediate imm)
1732     {
1733         // Rd can only be SP if Rn is also SP.
1734         ASSERT((rd != ARMRegisters::sp) || (rn == ARMRegisters::sp));
1735         ASSERT(rd != ARMRegisters::pc);
1736         ASSERT(rn != ARMRegisters::pc);
1737         ASSERT(imm.isValid());
1738 
1739         if ((rn == ARMRegisters::sp) &amp;&amp; (rd == ARMRegisters::sp) &amp;&amp; imm.isUInt9()) {
1740             ASSERT(!(imm.getUInt16() &amp; 3));
1741             m_formatter.oneWordOp9Imm7(OP_SUB_SP_imm_T1, static_cast&lt;uint8_t&gt;(imm.getUInt9() &gt;&gt; 2));
1742             return;
1743         } else if (!((rd | rn) &amp; 8)) {
1744             if (imm.isUInt3()) {
1745                 m_formatter.oneWordOp7Reg3Reg3Reg3(OP_SUB_imm_T1, (RegisterID)imm.getUInt3(), rn, rd);
1746                 return;
1747             } else if ((rd == rn) &amp;&amp; imm.isUInt8()) {
1748                 m_formatter.oneWordOp5Reg3Imm8(OP_SUB_imm_T2, rd, imm.getUInt8());
1749                 return;
1750             }
1751         }
1752 
1753         m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_SUB_S_imm_T3, rn, rd, imm);
1754     }
1755 
1756     ALWAYS_INLINE void sub_S(RegisterID rd, ARMThumbImmediate imm, RegisterID rn)
1757     {
1758         ASSERT(rd != ARMRegisters::pc);
1759         ASSERT(rn != ARMRegisters::pc);
1760         ASSERT(imm.isValid());
1761         ASSERT(imm.isUInt12());
1762 
1763         m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_RSB_S_imm_T2, rn, rd, imm);
1764     }
1765 
1766     // Not allowed in an IT (if then) block?
1767     ALWAYS_INLINE void sub_S(RegisterID rd, RegisterID rn, RegisterID rm, ShiftTypeAndAmount shift)
1768     {
1769         ASSERT((rd != ARMRegisters::sp) || (rn == ARMRegisters::sp));
1770         ASSERT(rd != ARMRegisters::pc);
1771         ASSERT(rn != ARMRegisters::pc);
1772         ASSERT(!BadReg(rm));
1773         m_formatter.twoWordOp12Reg4FourFours(OP_SUB_S_reg_T2, rn, FourFours(shift.hi4(), rd, shift.lo4(), rm));
1774     }
1775 
1776     // Not allowed in an IT (if then) block.
1777     ALWAYS_INLINE void sub_S(RegisterID rd, RegisterID rn, RegisterID rm)
1778     {
1779         if (!((rd | rn | rm) &amp; 8))
1780             m_formatter.oneWordOp7Reg3Reg3Reg3(OP_SUB_reg_T1, rm, rn, rd);
1781         else
1782             sub_S(rd, rn, rm, ShiftTypeAndAmount());
1783     }
1784 
1785     ALWAYS_INLINE void tst(RegisterID rn, ARMThumbImmediate imm)
1786     {
1787         ASSERT(!BadReg(rn));
1788         ASSERT(imm.isEncodedImm());
1789 
1790         m_formatter.twoWordOp5i6Imm4Reg4EncodedImm(OP_TST_imm, rn, (RegisterID)0xf, imm);
1791     }
1792 
1793     ALWAYS_INLINE void tst(RegisterID rn, RegisterID rm, ShiftTypeAndAmount shift)
1794     {
1795         ASSERT(!BadReg(rn));
1796         ASSERT(!BadReg(rm));
1797         m_formatter.twoWordOp12Reg4FourFours(OP_TST_reg_T2, rn, FourFours(shift.hi4(), 0xf, shift.lo4(), rm));
1798     }
1799 
1800     ALWAYS_INLINE void tst(RegisterID rn, RegisterID rm)
1801     {
1802         if ((rn | rm) &amp; 8)
1803             tst(rn, rm, ShiftTypeAndAmount());
1804         else
1805             m_formatter.oneWordOp10Reg3Reg3(OP_TST_reg_T1, rm, rn);
1806     }
1807 
1808     ALWAYS_INLINE void ubfx(RegisterID rd, RegisterID rn, unsigned lsb, unsigned width)
1809     {
1810         ASSERT(lsb &lt; 32);
1811         ASSERT((width &gt;= 1) &amp;&amp; (width &lt;= 32));
1812         ASSERT((lsb + width) &lt;= 32);
1813         m_formatter.twoWordOp12Reg40Imm3Reg4Imm20Imm5(OP_UBFX_T1, rd, rn, (lsb &amp; 0x1c) &lt;&lt; 10, (lsb &amp; 0x3) &lt;&lt; 6, (width - 1) &amp; 0x1f);
1814     }
1815 
1816 #if HAVE(ARM_IDIV_INSTRUCTIONS)
1817     ALWAYS_INLINE void udiv(RegisterID rd, RegisterID rn, RegisterID rm)
1818     {
1819         ASSERT(!BadReg(rd));
1820         ASSERT(!BadReg(rn));
1821         ASSERT(!BadReg(rm));
1822         m_formatter.twoWordOp12Reg4FourFours(OP_UDIV_T1, rn, FourFours(0xf, rd, 0xf, rm));
1823     }
1824 #endif
1825 
1826     void vadd(FPDoubleRegisterID rd, FPDoubleRegisterID rn, FPDoubleRegisterID rm)
1827     {
1828         m_formatter.vfpOp(OP_VADD_T2, OP_VADD_T2b, true, rn, rd, rm);
1829     }
1830 
1831     void vcmp(FPDoubleRegisterID rd, FPDoubleRegisterID rm)
1832     {
1833         m_formatter.vfpOp(OP_VCMP, OP_VCMPb, true, VFPOperand(4), rd, rm);
1834     }
1835 
1836     void vcmpz(FPDoubleRegisterID rd)
1837     {
1838         m_formatter.vfpOp(OP_VCMP, OP_VCMPb, true, VFPOperand(5), rd, VFPOperand(0));
1839     }
1840 
1841     void vcvt_signedToFloatingPoint(FPDoubleRegisterID rd, FPSingleRegisterID rm)
1842     {
1843         // boolean values are 64bit (toInt, unsigned, roundZero)
1844         m_formatter.vfpOp(OP_VCVT_FPIVFP, OP_VCVT_FPIVFPb, true, vcvtOp(false, false, false), rd, rm);
1845     }
1846 
1847     void vcvt_floatingPointToSigned(FPSingleRegisterID rd, FPDoubleRegisterID rm)
1848     {
1849         // boolean values are 64bit (toInt, unsigned, roundZero)
1850         m_formatter.vfpOp(OP_VCVT_FPIVFP, OP_VCVT_FPIVFPb, true, vcvtOp(true, false, true), rd, rm);
1851     }
1852 
1853     void vcvt_floatingPointToUnsigned(FPSingleRegisterID rd, FPDoubleRegisterID rm)
1854     {
1855         // boolean values are 64bit (toInt, unsigned, roundZero)
1856         m_formatter.vfpOp(OP_VCVT_FPIVFP, OP_VCVT_FPIVFPb, true, vcvtOp(true, true, true), rd, rm);
1857     }
1858 
1859     void vdiv(FPDoubleRegisterID rd, FPDoubleRegisterID rn, FPDoubleRegisterID rm)
1860     {
1861         m_formatter.vfpOp(OP_VDIV, OP_VDIVb, true, rn, rd, rm);
1862     }
1863 
1864     void vldr(FPDoubleRegisterID rd, RegisterID rn, int32_t imm)
1865     {
1866         m_formatter.vfpMemOp(OP_VLDR, OP_VLDRb, true, rn, rd, imm);
1867     }
1868 
1869     void flds(FPSingleRegisterID rd, RegisterID rn, int32_t imm)
1870     {
1871         m_formatter.vfpMemOp(OP_FLDS, OP_FLDSb, false, rn, rd, imm);
1872     }
1873 
1874     void vmov(RegisterID rd, FPSingleRegisterID rn)
1875     {
1876         ASSERT(!BadReg(rd));
1877         m_formatter.vfpOp(OP_VMOV_StoC, OP_VMOV_StoCb, false, rn, rd, VFPOperand(0));
1878     }
1879 
1880     void vmov(FPSingleRegisterID rd, RegisterID rn)
1881     {
1882         ASSERT(!BadReg(rn));
1883         m_formatter.vfpOp(OP_VMOV_CtoS, OP_VMOV_CtoSb, false, rd, rn, VFPOperand(0));
1884     }
1885 
1886     void vmov(RegisterID rd1, RegisterID rd2, FPDoubleRegisterID rn)
1887     {
1888         ASSERT(!BadReg(rd1));
1889         ASSERT(!BadReg(rd2));
1890         m_formatter.vfpOp(OP_VMOV_DtoC, OP_VMOV_DtoCb, true, rd2, VFPOperand(rd1 | 16), rn);
1891     }
1892 
1893     void vmov(FPDoubleRegisterID rd, RegisterID rn1, RegisterID rn2)
1894     {
1895         ASSERT(!BadReg(rn1));
1896         ASSERT(!BadReg(rn2));
1897         m_formatter.vfpOp(OP_VMOV_CtoD, OP_VMOV_CtoDb, true, rn2, VFPOperand(rn1 | 16), rd);
1898     }
1899 
1900     void vmov(FPDoubleRegisterID rd, FPDoubleRegisterID rn)
1901     {
1902         m_formatter.vfpOp(OP_VMOV_T2, OP_VMOV_T2b, true, VFPOperand(0), rd, rn);
1903     }
1904 
1905     void vmrs(RegisterID reg = ARMRegisters::pc)
1906     {
1907         ASSERT(reg != ARMRegisters::sp);
1908         m_formatter.vfpOp(OP_VMRS, OP_VMRSb, false, VFPOperand(1), VFPOperand(0x10 | reg), VFPOperand(0));
1909     }
1910 
1911     void vmul(FPDoubleRegisterID rd, FPDoubleRegisterID rn, FPDoubleRegisterID rm)
1912     {
1913         m_formatter.vfpOp(OP_VMUL_T2, OP_VMUL_T2b, true, rn, rd, rm);
1914     }
1915 
1916     void vstr(FPDoubleRegisterID rd, RegisterID rn, int32_t imm)
1917     {
1918         m_formatter.vfpMemOp(OP_VSTR, OP_VSTRb, true, rn, rd, imm);
1919     }
1920 
1921     void fsts(FPSingleRegisterID rd, RegisterID rn, int32_t imm)
1922     {
1923         m_formatter.vfpMemOp(OP_FSTS, OP_FSTSb, false, rn, rd, imm);
1924     }
1925 
1926     void vsub(FPDoubleRegisterID rd, FPDoubleRegisterID rn, FPDoubleRegisterID rm)
1927     {
1928         m_formatter.vfpOp(OP_VSUB_T2, OP_VSUB_T2b, true, rn, rd, rm);
1929     }
1930 
1931     void vabs(FPDoubleRegisterID rd, FPDoubleRegisterID rm)
1932     {
1933         m_formatter.vfpOp(OP_VABS_T2, OP_VABS_T2b, true, VFPOperand(16), rd, rm);
1934     }
1935 
1936     void vneg(FPDoubleRegisterID rd, FPDoubleRegisterID rm)
1937     {
1938         m_formatter.vfpOp(OP_VNEG_T2, OP_VNEG_T2b, true, VFPOperand(1), rd, rm);
1939     }
1940 
1941     void vsqrt(FPDoubleRegisterID rd, FPDoubleRegisterID rm)
1942     {
1943         m_formatter.vfpOp(OP_VSQRT_T1, OP_VSQRT_T1b, true, VFPOperand(17), rd, rm);
1944     }
1945 
1946     void vcvtds(FPDoubleRegisterID rd, FPSingleRegisterID rm)
1947     {
1948         m_formatter.vfpOp(OP_VCVTDS_T1, OP_VCVTDS_T1b, false, VFPOperand(23), rd, rm);
1949     }
1950 
1951     void vcvtsd(FPSingleRegisterID rd, FPDoubleRegisterID rm)
1952     {
1953         m_formatter.vfpOp(OP_VCVTSD_T1, OP_VCVTSD_T1b, true, VFPOperand(23), rd, rm);
1954     }
1955 
1956     void nop()
1957     {
1958         m_formatter.oneWordOp8Imm8(OP_NOP_T1, 0);
1959     }
1960 
1961     void nopw()
1962     {
1963         m_formatter.twoWordOp16Op16(OP_NOP_T2a, OP_NOP_T2b);
1964     }
1965 
1966     static constexpr int16_t nopPseudo16()
1967     {
1968         return OP_NOP_T1;
1969     }
1970 
1971     static constexpr int32_t nopPseudo32()
1972     {
1973         return OP_NOP_T2a | (OP_NOP_T2b &lt;&lt; 16);
1974     }
1975 
1976     using CopyFunction = void*(&amp;)(void*, const void*, size_t);
1977 
1978     template &lt;CopyFunction copy&gt;
1979     static void fillNops(void* base, size_t size)
1980     {
1981         RELEASE_ASSERT(!(size % sizeof(int16_t)));
1982 
1983         char* ptr = static_cast&lt;char*&gt;(base);
1984         const size_t num32s = size / sizeof(int32_t);
1985         for (size_t i = 0; i &lt; num32s; i++) {
1986             const int32_t insn = nopPseudo32();
1987             copy(ptr, &amp;insn, sizeof(int32_t));
1988             ptr += sizeof(int32_t);
1989         }
1990 
1991         const size_t num16s = (size % sizeof(int32_t)) / sizeof(int16_t);
1992         ASSERT(num16s == 0 || num16s == 1);
1993         ASSERT(num16s * sizeof(int16_t) + num32s * sizeof(int32_t) == size);
1994         if (num16s) {
1995             const int16_t insn = nopPseudo16();
1996             copy(ptr, &amp;insn, sizeof(int16_t));
1997         }
1998     }
1999 
2000     void dmbSY()
2001     {
2002         m_formatter.twoWordOp16Op16(OP_DMB_T1a, OP_DMB_SY_T1b);
2003     }
2004 
2005     void dmbISHST()
2006     {
2007         m_formatter.twoWordOp16Op16(OP_DMB_T1a, OP_DMB_ISHST_T1b);
2008     }
2009 
2010     AssemblerLabel labelIgnoringWatchpoints()
2011     {
2012         return m_formatter.label();
2013     }
2014 
2015     AssemblerLabel labelForWatchpoint()
2016     {
2017         AssemblerLabel result = m_formatter.label();
2018         if (static_cast&lt;int&gt;(result.m_offset) != m_indexOfLastWatchpoint)
2019             result = label();
2020         m_indexOfLastWatchpoint = result.m_offset;
2021         m_indexOfTailOfLastWatchpoint = result.m_offset + maxJumpReplacementSize();
2022         return result;
2023     }
2024 
2025     AssemblerLabel label()
2026     {
2027         AssemblerLabel result = m_formatter.label();
2028         while (UNLIKELY(static_cast&lt;int&gt;(result.m_offset) &lt; m_indexOfTailOfLastWatchpoint)) {
2029             if (UNLIKELY(static_cast&lt;int&gt;(result.m_offset) + 4 &lt;= m_indexOfTailOfLastWatchpoint))
2030                 nopw();
2031             else
2032                 nop();
2033             result = m_formatter.label();
2034         }
2035         return result;
2036     }
2037 
2038     AssemblerLabel align(int alignment)
2039     {
2040         while (!m_formatter.isAligned(alignment))
2041             bkpt();
2042 
2043         return label();
2044     }
2045 
2046     static void* getRelocatedAddress(void* code, AssemblerLabel label)
2047     {
2048         ASSERT(label.isSet());
2049         return reinterpret_cast&lt;void*&gt;(reinterpret_cast&lt;ptrdiff_t&gt;(code) + label.m_offset);
2050     }
2051 
2052     static int getDifferenceBetweenLabels(AssemblerLabel a, AssemblerLabel b)
2053     {
2054         return b.m_offset - a.m_offset;
2055     }
2056 
2057     static int jumpSizeDelta(JumpType jumpType, JumpLinkType jumpLinkType) { return JUMP_ENUM_SIZE(jumpType) - JUMP_ENUM_SIZE(jumpLinkType); }
2058 
2059     // Assembler admin methods:
2060 
2061     static ALWAYS_INLINE bool linkRecordSourceComparator(const LinkRecord&amp; a, const LinkRecord&amp; b)
2062     {
2063         return a.from() &lt; b.from();
2064     }
2065 
2066     static bool canCompact(JumpType jumpType)
2067     {
2068         // The following cannot be compacted:
2069         //   JumpFixed: represents custom jump sequence
2070         //   JumpNoConditionFixedSize: represents unconditional jump that must remain a fixed size
2071         //   JumpConditionFixedSize: represents conditional jump that must remain a fixed size
2072         return (jumpType == JumpNoCondition) || (jumpType == JumpCondition);
2073     }
2074 
2075     static JumpLinkType computeJumpType(JumpType jumpType, const uint8_t* from, const uint8_t* to)
2076     {
2077         if (jumpType == JumpFixed)
2078             return LinkInvalid;
2079 
2080         // for patchable jump we must leave space for the longest code sequence
2081         if (jumpType == JumpNoConditionFixedSize)
2082             return LinkBX;
2083         if (jumpType == JumpConditionFixedSize)
2084             return LinkConditionalBX;
2085 
2086         const int paddingSize = JUMP_ENUM_SIZE(jumpType);
2087 
2088         if (jumpType == JumpCondition) {
2089             // 2-byte conditional T1
2090             const uint16_t* jumpT1Location = reinterpret_cast_ptr&lt;const uint16_t*&gt;(from - (paddingSize - JUMP_ENUM_SIZE(LinkJumpT1)));
2091             if (canBeJumpT1(jumpT1Location, to))
2092                 return LinkJumpT1;
2093             // 4-byte conditional T3
2094             const uint16_t* jumpT3Location = reinterpret_cast_ptr&lt;const uint16_t*&gt;(from - (paddingSize - JUMP_ENUM_SIZE(LinkJumpT3)));
2095             if (canBeJumpT3(jumpT3Location, to))
2096                 return LinkJumpT3;
2097             // 4-byte conditional T4 with IT
2098             const uint16_t* conditionalJumpT4Location =
2099             reinterpret_cast_ptr&lt;const uint16_t*&gt;(from - (paddingSize - JUMP_ENUM_SIZE(LinkConditionalJumpT4)));
2100             if (canBeJumpT4(conditionalJumpT4Location, to))
2101                 return LinkConditionalJumpT4;
2102         } else {
2103             // 2-byte unconditional T2
2104             const uint16_t* jumpT2Location = reinterpret_cast_ptr&lt;const uint16_t*&gt;(from - (paddingSize - JUMP_ENUM_SIZE(LinkJumpT2)));
2105             if (canBeJumpT2(jumpT2Location, to))
2106                 return LinkJumpT2;
2107             // 4-byte unconditional T4
2108             const uint16_t* jumpT4Location = reinterpret_cast_ptr&lt;const uint16_t*&gt;(from - (paddingSize - JUMP_ENUM_SIZE(LinkJumpT4)));
2109             if (canBeJumpT4(jumpT4Location, to))
2110                 return LinkJumpT4;
2111             // use long jump sequence
2112             return LinkBX;
2113         }
2114 
2115         ASSERT(jumpType == JumpCondition);
2116         return LinkConditionalBX;
2117     }
2118 
2119     static JumpLinkType computeJumpType(LinkRecord&amp; record, const uint8_t* from, const uint8_t* to)
2120     {
2121         JumpLinkType linkType = computeJumpType(record.type(), from, to);
2122         record.setLinkType(linkType);
2123         return linkType;
2124     }
2125 
2126     Vector&lt;LinkRecord, 0, UnsafeVectorOverflow&gt;&amp; jumpsToLink()
2127     {
2128         std::sort(m_jumpsToLink.begin(), m_jumpsToLink.end(), linkRecordSourceComparator);
2129         return m_jumpsToLink;
2130     }
2131 
2132     template&lt;CopyFunction copy&gt;
2133     static void ALWAYS_INLINE link(LinkRecord&amp; record, uint8_t* from, const uint8_t* fromInstruction8, uint8_t* to)
2134     {
2135         const uint16_t* fromInstruction = reinterpret_cast_ptr&lt;const uint16_t*&gt;(fromInstruction8);
2136         switch (record.linkType()) {
2137         case LinkJumpT1:
2138             linkJumpT1&lt;copy&gt;(record.condition(), reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to);
2139             break;
2140         case LinkJumpT2:
2141             linkJumpT2&lt;copy&gt;(reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to);
2142             break;
2143         case LinkJumpT3:
2144             linkJumpT3&lt;copy&gt;(record.condition(), reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to);
2145             break;
2146         case LinkJumpT4:
2147             linkJumpT4&lt;copy&gt;(reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to);
2148             break;
2149         case LinkConditionalJumpT4:
2150             linkConditionalJumpT4&lt;copy&gt;(record.condition(), reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to);
2151             break;
2152         case LinkConditionalBX:
2153             linkConditionalBX&lt;copy&gt;(record.condition(), reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to);
2154             break;
2155         case LinkBX:
2156             linkBX&lt;copy&gt;(reinterpret_cast_ptr&lt;uint16_t*&gt;(from), fromInstruction, to);
2157             break;
2158         default:
2159             RELEASE_ASSERT_NOT_REACHED();
2160             break;
2161         }
2162     }
2163 
2164     size_t codeSize() const { return m_formatter.codeSize(); }
2165 
2166     static unsigned getCallReturnOffset(AssemblerLabel call)
2167     {
2168         ASSERT(call.isSet());
2169         return call.m_offset;
2170     }
2171 
2172     // Linking &amp; patching:
2173     //
2174     // &#39;link&#39; and &#39;patch&#39; methods are for use on unprotected code - such as the code
2175     // within the AssemblerBuffer, and code being patched by the patch buffer.  Once
2176     // code has been finalized it is (platform support permitting) within a non-
2177     // writable region of memory; to modify the code in an execute-only execuable
2178     // pool the &#39;repatch&#39; and &#39;relink&#39; methods should be used.
2179 
2180     void linkJump(AssemblerLabel from, AssemblerLabel to, JumpType type, Condition condition)
2181     {
2182         ASSERT(to.isSet());
2183         ASSERT(from.isSet());
2184         m_jumpsToLink.append(LinkRecord(from.m_offset, to.m_offset, type, condition));
2185     }
2186 
2187     static void linkJump(void* code, AssemblerLabel from, void* to)
2188     {
2189         ASSERT(from.isSet());
2190 
2191         uint16_t* location = reinterpret_cast&lt;uint16_t*&gt;(reinterpret_cast&lt;intptr_t&gt;(code) + from.m_offset);
2192         linkJumpAbsolute(location, location, to);
2193     }
2194 
2195     static void linkCall(void* code, AssemblerLabel from, void* to)
2196     {
2197         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(code) &amp; 1));
2198         ASSERT(from.isSet());
2199 
2200         setPointer(reinterpret_cast&lt;uint16_t*&gt;(reinterpret_cast&lt;intptr_t&gt;(code) + from.m_offset) - 1, to, false);
2201     }
2202 
2203     static void linkPointer(void* code, AssemblerLabel where, void* value)
2204     {
2205         setPointer(reinterpret_cast&lt;char*&gt;(code) + where.m_offset, value, false);
2206     }
2207 
2208     // The static relink and replace methods can use can use |from| for both
2209     // the write and executable address for call and jump patching
2210     // as they&#39;re modifying existing (linked) code, so the address being
2211     // provided is correct for relative address computation.
2212     static void relinkJump(void* from, void* to)
2213     {
2214         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(from) &amp; 1));
2215         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(to) &amp; 1));
2216 
2217         linkJumpAbsolute(reinterpret_cast&lt;uint16_t*&gt;(from), reinterpret_cast&lt;uint16_t*&gt;(from), to);
2218 
2219         cacheFlush(reinterpret_cast&lt;uint16_t*&gt;(from) - 5, 5 * sizeof(uint16_t));
2220     }
2221 
2222     static void relinkJumpToNop(void* from)
2223     {
2224         relinkJump(from, from);
2225     }
2226 
2227     static void relinkCall(void* from, void* to)
2228     {
2229         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(from) &amp; 1));
2230 
2231         setPointer(reinterpret_cast&lt;uint16_t*&gt;(from) - 1, to, true);
2232     }
2233 
2234     static void* readCallTarget(void* from)
2235     {
2236         return readPointer(reinterpret_cast&lt;uint16_t*&gt;(from) - 1);
2237     }
2238 
2239     static void repatchInt32(void* where, int32_t value)
2240     {
2241         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(where) &amp; 1));
2242 
2243         setInt32(where, value, true);
2244     }
2245 
2246     static void repatchCompact(void* where, int32_t offset)
2247     {
2248         ASSERT(offset &gt;= -255 &amp;&amp; offset &lt;= 255);
2249 
2250         bool add = true;
2251         if (offset &lt; 0) {
2252             add = false;
2253             offset = -offset;
2254         }
2255 
2256         offset |= (add &lt;&lt; 9);
2257         offset |= (1 &lt;&lt; 10);
2258         offset |= (1 &lt;&lt; 11);
2259 
2260         uint16_t* location = reinterpret_cast&lt;uint16_t*&gt;(where);
2261         uint16_t instruction = location[1] &amp; ~((1 &lt;&lt; 12) - 1);
2262         instruction |= offset;
2263         performJITMemcpy(location + 1, &amp;instruction, sizeof(uint16_t));
2264         cacheFlush(location, sizeof(uint16_t) * 2);
2265     }
2266 
2267     static void repatchPointer(void* where, void* value)
2268     {
2269         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(where) &amp; 1));
2270 
2271         setPointer(where, value, true);
2272     }
2273 
2274     static void* readPointer(void* where)
2275     {
2276         return reinterpret_cast&lt;void*&gt;(readInt32(where));
2277     }
2278 
2279     static void replaceWithJump(void* instructionStart, void* to)
2280     {
2281         ASSERT(!(bitwise_cast&lt;uintptr_t&gt;(instructionStart) &amp; 1));
2282         ASSERT(!(bitwise_cast&lt;uintptr_t&gt;(to) &amp; 1));
2283 
2284 #if OS(LINUX)
2285         if (canBeJumpT4(reinterpret_cast&lt;uint16_t*&gt;(instructionStart), to)) {
2286             uint16_t* ptr = reinterpret_cast&lt;uint16_t*&gt;(instructionStart) + 2;
2287             linkJumpT4(ptr, ptr, to);
2288             cacheFlush(ptr - 2, sizeof(uint16_t) * 2);
2289         } else {
2290             uint16_t* ptr = reinterpret_cast&lt;uint16_t*&gt;(instructionStart) + 5;
2291             linkBX(ptr, ptr, to);
2292             cacheFlush(ptr - 5, sizeof(uint16_t) * 5);
2293         }
2294 #else
2295         uint16_t* ptr = reinterpret_cast&lt;uint16_t*&gt;(instructionStart) + 2;
2296         linkJumpT4(ptr, ptr, to);
2297         cacheFlush(ptr - 2, sizeof(uint16_t) * 2);
2298 #endif
2299     }
2300 
2301     static ptrdiff_t maxJumpReplacementSize()
2302     {
2303 #if OS(LINUX)
2304         return 10;
2305 #else
2306         return 4;
2307 #endif
2308     }
2309 
2310     static constexpr ptrdiff_t patchableJumpSize()
2311     {
2312         return 10;
2313     }
2314 
2315     static void replaceWithLoad(void* instructionStart)
2316     {
2317         ASSERT(!(bitwise_cast&lt;uintptr_t&gt;(instructionStart) &amp; 1));
2318         uint16_t* ptr = reinterpret_cast&lt;uint16_t*&gt;(instructionStart);
2319         switch (ptr[0] &amp; 0xFFF0) {
2320         case OP_LDR_imm_T3:
2321             break;
2322         case OP_ADD_imm_T3: {
2323             ASSERT(!(ptr[1] &amp; 0xF000));
2324             uint16_t instructions[2];
2325             instructions[0] = ptr[0] &amp; 0x000F;
2326             instructions[0] |= OP_LDR_imm_T3;
2327             instructions[1] = ptr[1] | (ptr[1] &amp; 0x0F00) &lt;&lt; 4;
2328             instructions[1] &amp;= 0xF0FF;
2329             performJITMemcpy(ptr, instructions, sizeof(uint16_t) * 2);
2330             cacheFlush(ptr, sizeof(uint16_t) * 2);
2331             break;
2332         }
2333         default:
2334             RELEASE_ASSERT_NOT_REACHED();
2335         }
2336     }
2337 
2338     static void replaceWithAddressComputation(void* instructionStart)
2339     {
2340         ASSERT(!(bitwise_cast&lt;uintptr_t&gt;(instructionStart) &amp; 1));
2341         uint16_t* ptr = reinterpret_cast&lt;uint16_t*&gt;(instructionStart);
2342         switch (ptr[0] &amp; 0xFFF0) {
2343         case OP_LDR_imm_T3: {
2344             ASSERT(!(ptr[1] &amp; 0x0F00));
2345             uint16_t instructions[2];
2346             instructions[0] = ptr[0] &amp; 0x000F;
2347             instructions[0] |= OP_ADD_imm_T3;
2348             instructions[1] = ptr[1] | (ptr[1] &amp; 0xF000) &gt;&gt; 4;
2349             instructions[1] &amp;= 0x0FFF;
2350             performJITMemcpy(ptr, instructions, sizeof(uint16_t) * 2);
2351             cacheFlush(ptr, sizeof(uint16_t) * 2);
2352             break;
2353         }
2354         case OP_ADD_imm_T3:
2355             break;
2356         default:
2357             RELEASE_ASSERT_NOT_REACHED();
2358         }
2359     }
2360 
2361     unsigned debugOffset() { return m_formatter.debugOffset(); }
2362 
2363 #if OS(LINUX)
2364     static inline void linuxPageFlush(uintptr_t begin, uintptr_t end)
2365     {
2366         asm volatile(
2367             &quot;push    {r7}\n&quot;
2368             &quot;mov     r0, %0\n&quot;
2369             &quot;mov     r1, %1\n&quot;
2370             &quot;movw    r7, #0x2\n&quot;
2371             &quot;movt    r7, #0xf\n&quot;
2372             &quot;movs    r2, #0x0\n&quot;
2373             &quot;svc     0x0\n&quot;
2374             &quot;pop     {r7}\n&quot;
2375             :
2376             : &quot;r&quot; (begin), &quot;r&quot; (end)
2377             : &quot;r0&quot;, &quot;r1&quot;, &quot;r2&quot;);
2378     }
2379 #endif
2380 
2381     static void cacheFlush(void* code, size_t size)
2382     {
2383 #if OS(DARWIN)
2384         sys_cache_control(kCacheFunctionPrepareForExecution, code, size);
2385 #elif OS(LINUX)
2386         size_t page = pageSize();
2387         uintptr_t current = reinterpret_cast&lt;uintptr_t&gt;(code);
2388         uintptr_t end = current + size;
2389         uintptr_t firstPageEnd = (current &amp; ~(page - 1)) + page;
2390 
2391         if (end &lt;= firstPageEnd) {
2392             linuxPageFlush(current, end);
2393             return;
2394         }
2395 
2396         linuxPageFlush(current, firstPageEnd);
2397 
2398         for (current = firstPageEnd; current + page &lt; end; current += page)
2399             linuxPageFlush(current, current + page);
2400 
2401         linuxPageFlush(current, end);
2402 #else
2403 #error &quot;The cacheFlush support is missing on this platform.&quot;
2404 #endif
2405     }
2406 
2407 private:
2408     // VFP operations commonly take one or more 5-bit operands, typically representing a
2409     // floating point register number.  This will commonly be encoded in the instruction
2410     // in two parts, with one single bit field, and one 4-bit field.  In the case of
2411     // double precision operands the high bit of the register number will be encoded
2412     // separately, and for single precision operands the high bit of the register number
2413     // will be encoded individually.
2414     // VFPOperand encapsulates a 5-bit VFP operand, with bits 0..3 containing the 4-bit
2415     // field to be encoded together in the instruction (the low 4-bits of a double
2416     // register number, or the high 4-bits of a single register number), and bit 4
2417     // contains the bit value to be encoded individually.
2418     struct VFPOperand {
2419         explicit VFPOperand(uint32_t value)
2420             : m_value(value)
2421         {
2422             ASSERT(!(m_value &amp; ~0x1f));
2423         }
2424 
2425         VFPOperand(FPDoubleRegisterID reg)
2426             : m_value(reg)
2427         {
2428         }
2429 
2430         VFPOperand(RegisterID reg)
2431             : m_value(reg)
2432         {
2433         }
2434 
2435         VFPOperand(FPSingleRegisterID reg)
2436             : m_value(((reg &amp; 1) &lt;&lt; 4) | (reg &gt;&gt; 1)) // rotate the lowest bit of &#39;reg&#39; to the top.
2437         {
2438         }
2439 
2440         uint32_t bits1()
2441         {
2442             return m_value &gt;&gt; 4;
2443         }
2444 
2445         uint32_t bits4()
2446         {
2447             return m_value &amp; 0xf;
2448         }
2449 
2450         uint32_t m_value;
2451     };
2452 
2453     VFPOperand vcvtOp(bool toInteger, bool isUnsigned, bool isRoundZero)
2454     {
2455         // Cannot specify rounding when converting to float.
2456         ASSERT(toInteger || !isRoundZero);
2457 
2458         uint32_t op = 0x8;
2459         if (toInteger) {
2460             // opc2 indicates both toInteger &amp; isUnsigned.
2461             op |= isUnsigned ? 0x4 : 0x5;
2462             // &#39;op&#39; field in instruction is isRoundZero
2463             if (isRoundZero)
2464                 op |= 0x10;
2465         } else {
2466             ASSERT(!isRoundZero);
2467             // &#39;op&#39; field in instruction is isUnsigned
2468             if (!isUnsigned)
2469                 op |= 0x10;
2470         }
2471         return VFPOperand(op);
2472     }
2473 
2474     static void setInt32(void* code, uint32_t value, bool flush)
2475     {
2476         uint16_t* location = reinterpret_cast&lt;uint16_t*&gt;(code);
2477         ASSERT(isMOV_imm_T3(location - 4) &amp;&amp; isMOVT(location - 2));
2478 
2479         ARMThumbImmediate lo16 = ARMThumbImmediate::makeUInt16(static_cast&lt;uint16_t&gt;(value));
2480         ARMThumbImmediate hi16 = ARMThumbImmediate::makeUInt16(static_cast&lt;uint16_t&gt;(value &gt;&gt; 16));
2481         uint16_t instructions[4];
2482         instructions[0] = twoWordOp5i6Imm4Reg4EncodedImmFirst(OP_MOV_imm_T3, lo16);
2483         instructions[1] = twoWordOp5i6Imm4Reg4EncodedImmSecond((location[-3] &gt;&gt; 8) &amp; 0xf, lo16);
2484         instructions[2] = twoWordOp5i6Imm4Reg4EncodedImmFirst(OP_MOVT, hi16);
2485         instructions[3] = twoWordOp5i6Imm4Reg4EncodedImmSecond((location[-1] &gt;&gt; 8) &amp; 0xf, hi16);
2486 
2487         performJITMemcpy(location - 4, instructions, 4 * sizeof(uint16_t));
2488         if (flush)
2489             cacheFlush(location - 4, 4 * sizeof(uint16_t));
2490     }
2491 
2492     static int32_t readInt32(void* code)
2493     {
2494         uint16_t* location = reinterpret_cast&lt;uint16_t*&gt;(code);
2495         ASSERT(isMOV_imm_T3(location - 4) &amp;&amp; isMOVT(location - 2));
2496 
2497         ARMThumbImmediate lo16;
2498         ARMThumbImmediate hi16;
2499         decodeTwoWordOp5i6Imm4Reg4EncodedImmFirst(lo16, location[-4]);
2500         decodeTwoWordOp5i6Imm4Reg4EncodedImmSecond(lo16, location[-3]);
2501         decodeTwoWordOp5i6Imm4Reg4EncodedImmFirst(hi16, location[-2]);
2502         decodeTwoWordOp5i6Imm4Reg4EncodedImmSecond(hi16, location[-1]);
2503         uint32_t result = hi16.asUInt16();
2504         result &lt;&lt;= 16;
2505         result |= lo16.asUInt16();
2506         return static_cast&lt;int32_t&gt;(result);
2507     }
2508 
2509     static void setUInt7ForLoad(void* code, ARMThumbImmediate imm)
2510     {
2511         // Requires us to have planted a LDR_imm_T1
2512         ASSERT(imm.isValid());
2513         ASSERT(imm.isUInt7());
2514         uint16_t* location = reinterpret_cast&lt;uint16_t*&gt;(code);
2515         uint16_t instruction;
2516         instruction = location[0] &amp; ~((static_cast&lt;uint16_t&gt;(0x7f) &gt;&gt; 2) &lt;&lt; 6);
2517         instruction |= (imm.getUInt7() &gt;&gt; 2) &lt;&lt; 6;
2518         performJITMemcpy(location, &amp;instruction, sizeof(uint16_t));
2519         cacheFlush(location, sizeof(uint16_t));
2520     }
2521 
2522     static void setPointer(void* code, void* value, bool flush)
2523     {
2524         setInt32(code, reinterpret_cast&lt;uint32_t&gt;(value), flush);
2525     }
2526 
2527     static bool isB(const void* address)
2528     {
2529         const uint16_t* instruction = static_cast&lt;const uint16_t*&gt;(address);
2530         return ((instruction[0] &amp; 0xf800) == OP_B_T4a) &amp;&amp; ((instruction[1] &amp; 0xd000) == OP_B_T4b);
2531     }
2532 
2533     static bool isBX(const void* address)
2534     {
2535         const uint16_t* instruction = static_cast&lt;const uint16_t*&gt;(address);
2536         return (instruction[0] &amp; 0xff87) == OP_BX;
2537     }
2538 
2539     static bool isMOV_imm_T3(const void* address)
2540     {
2541         const uint16_t* instruction = static_cast&lt;const uint16_t*&gt;(address);
2542         return ((instruction[0] &amp; 0xFBF0) == OP_MOV_imm_T3) &amp;&amp; ((instruction[1] &amp; 0x8000) == 0);
2543     }
2544 
2545     static bool isMOVT(const void* address)
2546     {
2547         const uint16_t* instruction = static_cast&lt;const uint16_t*&gt;(address);
2548         return ((instruction[0] &amp; 0xFBF0) == OP_MOVT) &amp;&amp; ((instruction[1] &amp; 0x8000) == 0);
2549     }
2550 
2551     static bool isNOP_T1(const void* address)
2552     {
2553         const uint16_t* instruction = static_cast&lt;const uint16_t*&gt;(address);
2554         return instruction[0] == OP_NOP_T1;
2555     }
2556 
2557     static bool isNOP_T2(const void* address)
2558     {
2559         const uint16_t* instruction = static_cast&lt;const uint16_t*&gt;(address);
2560         return (instruction[0] == OP_NOP_T2a) &amp;&amp; (instruction[1] == OP_NOP_T2b);
2561     }
2562 
2563     static bool canBeJumpT1(const uint16_t* instruction, const void* target)
2564     {
2565         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2566         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2567 
2568         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2569         // It does not appear to be documented in the ARM ARM (big surprise), but
2570         // for OP_B_T1 the branch displacement encoded in the instruction is 2
2571         // less than the actual displacement.
2572         relative -= 2;
2573         return ((relative &lt;&lt; 23) &gt;&gt; 23) == relative;
2574     }
2575 
2576     static bool canBeJumpT2(const uint16_t* instruction, const void* target)
2577     {
2578         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2579         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2580 
2581         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2582         // It does not appear to be documented in the ARM ARM (big surprise), but
2583         // for OP_B_T2 the branch displacement encoded in the instruction is 2
2584         // less than the actual displacement.
2585         relative -= 2;
2586         return ((relative &lt;&lt; 20) &gt;&gt; 20) == relative;
2587     }
2588 
2589     static bool canBeJumpT3(const uint16_t* instruction, const void* target)
2590     {
2591         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2592         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2593 
2594         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2595         return ((relative &lt;&lt; 11) &gt;&gt; 11) == relative;
2596     }
2597 
2598     static bool canBeJumpT4(const uint16_t* instruction, const void* target)
2599     {
2600         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2601         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2602 
2603         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2604         return ((relative &lt;&lt; 7) &gt;&gt; 7) == relative;
2605     }
2606 
2607     template&lt;CopyFunction copy = performJITMemcpy&gt;
2608     static void linkJumpT1(Condition cond, uint16_t* writeTarget, const uint16_t* instruction, void* target)
2609     {
2610         // FIMXE: this should be up in the MacroAssembler layer. :-(
2611         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2612         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2613         ASSERT(canBeJumpT1(instruction, target));
2614 
2615         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2616         // It does not appear to be documented in the ARM ARM (big surprise), but
2617         // for OP_B_T1 the branch displacement encoded in the instruction is 2
2618         // less than the actual displacement.
2619         relative -= 2;
2620 
2621         // All branch offsets should be an even distance.
2622         ASSERT(!(relative &amp; 1));
2623         uint16_t newInstruction = OP_B_T1 | ((cond &amp; 0xf) &lt;&lt; 8) | ((relative &amp; 0x1fe) &gt;&gt; 1);
2624         copy(writeTarget - 1, &amp;newInstruction, sizeof(uint16_t));
2625     }
2626 
2627     template&lt;CopyFunction copy = performJITMemcpy&gt;
2628     static void linkJumpT2(uint16_t* writeTarget, const uint16_t* instruction, void* target)
2629     {
2630         // FIMXE: this should be up in the MacroAssembler layer. :-(
2631         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2632         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2633         ASSERT(canBeJumpT2(instruction, target));
2634 
2635         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2636         // It does not appear to be documented in the ARM ARM (big surprise), but
2637         // for OP_B_T2 the branch displacement encoded in the instruction is 2
2638         // less than the actual displacement.
2639         relative -= 2;
2640 
2641         // All branch offsets should be an even distance.
2642         ASSERT(!(relative &amp; 1));
2643         uint16_t newInstruction = OP_B_T2 | ((relative &amp; 0xffe) &gt;&gt; 1);
2644         copy(writeTarget - 1, &amp;newInstruction, sizeof(uint16_t));
2645     }
2646 
2647     template&lt;CopyFunction copy = performJITMemcpy&gt;
2648     static void linkJumpT3(Condition cond, uint16_t* writeTarget, const uint16_t* instruction, void* target)
2649     {
2650         // FIMXE: this should be up in the MacroAssembler layer. :-(
2651         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2652         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2653         ASSERT(canBeJumpT3(instruction, target));
2654 
2655         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2656 
2657         // All branch offsets should be an even distance.
2658         ASSERT(!(relative &amp; 1));
2659         uint16_t instructions[2];
2660         instructions[0] = OP_B_T3a | ((relative &amp; 0x100000) &gt;&gt; 10) | ((cond &amp; 0xf) &lt;&lt; 6) | ((relative &amp; 0x3f000) &gt;&gt; 12);
2661         instructions[1] = OP_B_T3b | ((relative &amp; 0x80000) &gt;&gt; 8) | ((relative &amp; 0x40000) &gt;&gt; 5) | ((relative &amp; 0xffe) &gt;&gt; 1);
2662         copy(writeTarget - 2, instructions, 2 * sizeof(uint16_t));
2663     }
2664 
2665     template&lt;CopyFunction copy = performJITMemcpy&gt;
2666     static void linkJumpT4(uint16_t* writeTarget, const uint16_t* instruction, void* target)
2667     {
2668         // FIMXE: this should be up in the MacroAssembler layer. :-(
2669         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2670         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2671         ASSERT(canBeJumpT4(instruction, target));
2672 
2673         intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(target) - (reinterpret_cast&lt;intptr_t&gt;(instruction));
2674         // ARM encoding for the top two bits below the sign bit is &#39;peculiar&#39;.
2675         if (relative &gt;= 0)
2676             relative ^= 0xC00000;
2677 
2678         // All branch offsets should be an even distance.
2679         ASSERT(!(relative &amp; 1));
2680         uint16_t instructions[2];
2681         instructions[0] = OP_B_T4a | ((relative &amp; 0x1000000) &gt;&gt; 14) | ((relative &amp; 0x3ff000) &gt;&gt; 12);
2682         instructions[1] = OP_B_T4b | ((relative &amp; 0x800000) &gt;&gt; 10) | ((relative &amp; 0x400000) &gt;&gt; 11) | ((relative &amp; 0xffe) &gt;&gt; 1);
2683         copy(writeTarget - 2, instructions, 2 * sizeof(uint16_t));
2684     }
2685 
2686     template&lt;CopyFunction copy = performJITMemcpy&gt;
2687     static void linkConditionalJumpT4(Condition cond, uint16_t* writeTarget, const uint16_t* instruction, void* target)
2688     {
2689         // FIMXE: this should be up in the MacroAssembler layer. :-(
2690         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2691         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2692 
2693         uint16_t newInstruction = ifThenElse(cond) | OP_IT;
2694         copy(writeTarget - 3, &amp;newInstruction, sizeof(uint16_t));
2695         linkJumpT4&lt;copy&gt;(writeTarget, instruction, target);
2696     }
2697 
2698     template&lt;CopyFunction copy = performJITMemcpy&gt;
2699     static void linkBX(uint16_t* writeTarget, const uint16_t* instruction, void* target)
2700     {
2701         // FIMXE: this should be up in the MacroAssembler layer. :-(
2702         ASSERT_UNUSED(instruction, !(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2703         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(writeTarget) &amp; 1));
2704         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2705 
2706         const uint16_t JUMP_TEMPORARY_REGISTER = ARMRegisters::ip;
2707         ARMThumbImmediate lo16 = ARMThumbImmediate::makeUInt16(static_cast&lt;uint16_t&gt;(reinterpret_cast&lt;uint32_t&gt;(target) + 1));
2708         ARMThumbImmediate hi16 = ARMThumbImmediate::makeUInt16(static_cast&lt;uint16_t&gt;(reinterpret_cast&lt;uint32_t&gt;(target) &gt;&gt; 16));
2709         uint16_t instructions[5];
2710         instructions[0] = twoWordOp5i6Imm4Reg4EncodedImmFirst(OP_MOV_imm_T3, lo16);
2711         instructions[1] = twoWordOp5i6Imm4Reg4EncodedImmSecond(JUMP_TEMPORARY_REGISTER, lo16);
2712         instructions[2] = twoWordOp5i6Imm4Reg4EncodedImmFirst(OP_MOVT, hi16);
2713         instructions[3] = twoWordOp5i6Imm4Reg4EncodedImmSecond(JUMP_TEMPORARY_REGISTER, hi16);
2714         instructions[4] = OP_BX | (JUMP_TEMPORARY_REGISTER &lt;&lt; 3);
2715 
2716         copy(writeTarget - 5, instructions, 5 * sizeof(uint16_t));
2717     }
2718 
2719     template&lt;CopyFunction copy = performJITMemcpy&gt;
2720     static void linkConditionalBX(Condition cond, uint16_t* writeTarget, const uint16_t* instruction, void* target)
2721     {
2722         // FIMXE: this should be up in the MacroAssembler layer. :-(
2723         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2724         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2725 
2726         linkBX(writeTarget, instruction, target);
2727         uint16_t newInstruction = ifThenElse(cond, true, true) | OP_IT;
2728         copy(writeTarget - 6, &amp;newInstruction, sizeof(uint16_t));
2729     }
2730 
2731     static void linkJumpAbsolute(uint16_t* writeTarget, const uint16_t* instruction, void* target)
2732     {
2733         // FIMXE: this should be up in the MacroAssembler layer. :-(
2734         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(instruction) &amp; 1));
2735         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(target) &amp; 1));
2736 
2737         ASSERT((isMOV_imm_T3(instruction - 5) &amp;&amp; isMOVT(instruction - 3) &amp;&amp; isBX(instruction - 1))
2738                || (isNOP_T1(instruction - 5) &amp;&amp; isNOP_T2(instruction - 4) &amp;&amp; isB(instruction - 2)));
2739 
2740         if (canBeJumpT4(instruction, target)) {
2741             // There may be a better way to fix this, but right now put the NOPs first, since in the
2742             // case of an conditional branch this will be coming after an ITTT predicating *three*
2743             // instructions!  Looking backwards to modify the ITTT to an IT is not easy, due to
2744             // variable wdith encoding - the previous instruction might *look* like an ITTT but
2745             // actually be the second half of a 2-word op.
2746             uint16_t instructions[3];
2747             instructions[0] = OP_NOP_T1;
2748             instructions[1] = OP_NOP_T2a;
2749             instructions[2] = OP_NOP_T2b;
2750             performJITMemcpy(writeTarget - 5, instructions, 3 * sizeof(uint16_t));
2751             linkJumpT4(writeTarget, instruction, target);
2752         } else {
2753             const uint16_t JUMP_TEMPORARY_REGISTER = ARMRegisters::ip;
2754             ARMThumbImmediate lo16 = ARMThumbImmediate::makeUInt16(static_cast&lt;uint16_t&gt;(reinterpret_cast&lt;uint32_t&gt;(target) + 1));
2755             ARMThumbImmediate hi16 = ARMThumbImmediate::makeUInt16(static_cast&lt;uint16_t&gt;(reinterpret_cast&lt;uint32_t&gt;(target) &gt;&gt; 16));
2756 
2757             uint16_t instructions[5];
2758             instructions[0] = twoWordOp5i6Imm4Reg4EncodedImmFirst(OP_MOV_imm_T3, lo16);
2759             instructions[1] = twoWordOp5i6Imm4Reg4EncodedImmSecond(JUMP_TEMPORARY_REGISTER, lo16);
2760             instructions[2] = twoWordOp5i6Imm4Reg4EncodedImmFirst(OP_MOVT, hi16);
2761             instructions[3] = twoWordOp5i6Imm4Reg4EncodedImmSecond(JUMP_TEMPORARY_REGISTER, hi16);
2762             instructions[4] = OP_BX | (JUMP_TEMPORARY_REGISTER &lt;&lt; 3);
2763             performJITMemcpy(writeTarget - 5, instructions, 5 * sizeof(uint16_t));
2764         }
2765     }
2766 
2767     static uint16_t twoWordOp5i6Imm4Reg4EncodedImmFirst(uint16_t op, ARMThumbImmediate imm)
2768     {
2769         return op | (imm.m_value.i &lt;&lt; 10) | imm.m_value.imm4;
2770     }
2771 
2772     static void decodeTwoWordOp5i6Imm4Reg4EncodedImmFirst(ARMThumbImmediate&amp; result, uint16_t value)
2773     {
2774         result.m_value.i = (value &gt;&gt; 10) &amp; 1;
2775         result.m_value.imm4 = value &amp; 15;
2776     }
2777 
2778     static uint16_t twoWordOp5i6Imm4Reg4EncodedImmSecond(uint16_t rd, ARMThumbImmediate imm)
2779     {
2780         return (imm.m_value.imm3 &lt;&lt; 12) | (rd &lt;&lt; 8) | imm.m_value.imm8;
2781     }
2782 
2783     static void decodeTwoWordOp5i6Imm4Reg4EncodedImmSecond(ARMThumbImmediate&amp; result, uint16_t value)
2784     {
2785         result.m_value.imm3 = (value &gt;&gt; 12) &amp; 7;
2786         result.m_value.imm8 = value &amp; 255;
2787     }
2788 
2789     class ARMInstructionFormatter {
2790     public:
2791         ALWAYS_INLINE void oneWordOp5Reg3Imm8(OpcodeID op, RegisterID rd, uint8_t imm)
2792         {
2793             m_buffer.putShort(op | (rd &lt;&lt; 8) | imm);
2794         }
2795 
2796         ALWAYS_INLINE void oneWordOp5Imm5Reg3Reg3(OpcodeID op, uint8_t imm, RegisterID reg1, RegisterID reg2)
2797         {
2798             m_buffer.putShort(op | (imm &lt;&lt; 6) | (reg1 &lt;&lt; 3) | reg2);
2799         }
2800 
2801         ALWAYS_INLINE void oneWordOp7Reg3Reg3Reg3(OpcodeID op, RegisterID reg1, RegisterID reg2, RegisterID reg3)
2802         {
2803             m_buffer.putShort(op | (reg1 &lt;&lt; 6) | (reg2 &lt;&lt; 3) | reg3);
2804         }
2805 
2806         ALWAYS_INLINE void oneWordOp7Imm9(OpcodeID op, uint16_t imm)
2807         {
2808             m_buffer.putShort(op | imm);
2809         }
2810 
2811         ALWAYS_INLINE void oneWordOp8Imm8(OpcodeID op, uint8_t imm)
2812         {
2813             m_buffer.putShort(op | imm);
2814         }
2815 
2816         ALWAYS_INLINE void oneWordOp8RegReg143(OpcodeID op, RegisterID reg1, RegisterID reg2)
2817         {
2818             m_buffer.putShort(op | ((reg2 &amp; 8) &lt;&lt; 4) | (reg1 &lt;&lt; 3) | (reg2 &amp; 7));
2819         }
2820 
2821         ALWAYS_INLINE void oneWordOp9Imm7(OpcodeID op, uint8_t imm)
2822         {
2823             m_buffer.putShort(op | imm);
2824         }
2825 
2826         ALWAYS_INLINE void oneWordOp10Reg3Reg3(OpcodeID op, RegisterID reg1, RegisterID reg2)
2827         {
2828             m_buffer.putShort(op | (reg1 &lt;&lt; 3) | reg2);
2829         }
2830 
2831         ALWAYS_INLINE void twoWordOp12Reg4FourFours(OpcodeID1 op, RegisterID reg, FourFours ff)
2832         {
2833             m_buffer.putShort(op | reg);
2834             m_buffer.putShort(ff.m_u.value);
2835         }
2836 
2837         ALWAYS_INLINE void twoWordOp16FourFours(OpcodeID1 op, FourFours ff)
2838         {
2839             m_buffer.putShort(op);
2840             m_buffer.putShort(ff.m_u.value);
2841         }
2842 
2843         ALWAYS_INLINE void twoWordOp16Op16(OpcodeID1 op1, OpcodeID2 op2)
2844         {
2845             m_buffer.putShort(op1);
2846             m_buffer.putShort(op2);
2847         }
2848 
2849         ALWAYS_INLINE void twoWordOp16Imm16(OpcodeID1 op1, uint16_t imm)
2850         {
2851             m_buffer.putShort(op1);
2852             m_buffer.putShort(imm);
2853         }
2854 
2855         ALWAYS_INLINE void twoWordOp5i6Imm4Reg4EncodedImm(OpcodeID1 op, int imm4, RegisterID rd, ARMThumbImmediate imm)
2856         {
2857             ARMThumbImmediate newImm = imm;
2858             newImm.m_value.imm4 = imm4;
2859 
2860             m_buffer.putShort(ARMv7Assembler::twoWordOp5i6Imm4Reg4EncodedImmFirst(op, newImm));
2861             m_buffer.putShort(ARMv7Assembler::twoWordOp5i6Imm4Reg4EncodedImmSecond(rd, newImm));
2862         }
2863 
2864         ALWAYS_INLINE void twoWordOp12Reg4Reg4Imm12(OpcodeID1 op, RegisterID reg1, RegisterID reg2, uint16_t imm)
2865         {
2866             m_buffer.putShort(op | reg1);
2867             m_buffer.putShort((reg2 &lt;&lt; 12) | imm);
2868         }
2869 
2870         ALWAYS_INLINE void twoWordOp12Reg40Imm3Reg4Imm20Imm5(OpcodeID1 op, RegisterID reg1, RegisterID reg2, uint16_t imm1, uint16_t imm2, uint16_t imm3)
2871         {
2872             m_buffer.putShort(op | reg1);
2873             m_buffer.putShort((imm1 &lt;&lt; 12) | (reg2 &lt;&lt; 8) | (imm2 &lt;&lt; 6) | imm3);
2874         }
2875 
2876         // Formats up instructions of the pattern:
2877         //    111111111B11aaaa:bbbb222SA2C2cccc
2878         // Where 1s in the pattern come from op1, 2s in the pattern come from op2, S is the provided size bit.
2879         // Operands provide 5 bit values of the form Aaaaa, Bbbbb, Ccccc.
2880         ALWAYS_INLINE void vfpOp(OpcodeID1 op1, OpcodeID2 op2, bool size, VFPOperand a, VFPOperand b, VFPOperand c)
2881         {
2882             ASSERT(!(op1 &amp; 0x004f));
2883             ASSERT(!(op2 &amp; 0xf1af));
2884             m_buffer.putShort(op1 | b.bits1() &lt;&lt; 6 | a.bits4());
2885             m_buffer.putShort(op2 | b.bits4() &lt;&lt; 12 | size &lt;&lt; 8 | a.bits1() &lt;&lt; 7 | c.bits1() &lt;&lt; 5 | c.bits4());
2886         }
2887 
2888         // Arm vfp addresses can be offset by a 9-bit ones-comp immediate, left shifted by 2.
2889         // (i.e. +/-(0..255) 32-bit words)
2890         ALWAYS_INLINE void vfpMemOp(OpcodeID1 op1, OpcodeID2 op2, bool size, RegisterID rn, VFPOperand rd, int32_t imm)
2891         {
2892             bool up = true;
2893             if (imm &lt; 0) {
2894                 imm = -imm;
2895                 up = false;
2896             }
2897 
2898             uint32_t offset = imm;
2899             ASSERT(!(offset &amp; ~0x3fc));
2900             offset &gt;&gt;= 2;
2901 
2902             m_buffer.putShort(op1 | (up &lt;&lt; 7) | rd.bits1() &lt;&lt; 6 | rn);
2903             m_buffer.putShort(op2 | rd.bits4() &lt;&lt; 12 | size &lt;&lt; 8 | offset);
2904         }
2905 
2906         // Administrative methods:
2907 
2908         size_t codeSize() const { return m_buffer.codeSize(); }
2909         AssemblerLabel label() const { return m_buffer.label(); }
2910         bool isAligned(int alignment) const { return m_buffer.isAligned(alignment); }
2911         void* data() const { return m_buffer.data(); }
2912 
2913         unsigned debugOffset() { return m_buffer.debugOffset(); }
2914 
2915         AssemblerBuffer m_buffer;
2916     } m_formatter;
2917 
2918     Vector&lt;LinkRecord, 0, UnsafeVectorOverflow&gt; m_jumpsToLink;
2919     int m_indexOfLastWatchpoint;
2920     int m_indexOfTailOfLastWatchpoint;
2921 };
2922 
2923 } // namespace JSC
2924 
2925 #endif // ENABLE(ASSEMBLER) &amp;&amp; CPU(ARM_THUMB2)
    </pre>
  </body>
</html>