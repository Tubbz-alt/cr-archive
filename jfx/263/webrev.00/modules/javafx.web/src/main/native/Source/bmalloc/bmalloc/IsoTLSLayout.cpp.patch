diff a/modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/IsoTLSLayout.cpp b/modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/IsoTLSLayout.cpp
--- a/modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/IsoTLSLayout.cpp
+++ b/modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/IsoTLSLayout.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (C) 2017 Apple Inc. All rights reserved.
+ * Copyright (C) 2017-2019 Apple Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions
  * are met:
  * 1. Redistributions of source code must retain the above copyright
@@ -29,27 +29,33 @@
 
 namespace bmalloc {
 
 DEFINE_STATIC_PER_PROCESS_STORAGE(IsoTLSLayout);
 
-IsoTLSLayout::IsoTLSLayout(const std::lock_guard<Mutex>&)
+IsoTLSLayout::IsoTLSLayout(const LockHolder&)
 {
 }
 
 void IsoTLSLayout::add(IsoTLSEntry* entry)
 {
     static Mutex addingMutex;
     RELEASE_BASSERT(!entry->m_next);
-    std::lock_guard<Mutex> locking(addingMutex);
+    // IsoTLSLayout::head() does not take a lock. So we should emit memory fence to make sure that newly added entry is initialized when it is chained to this linked-list.
+    // Emitting memory fence here is OK since this function is not frequently called.
+    LockHolder locking(addingMutex);
     if (m_head) {
         RELEASE_BASSERT(m_tail);
-        entry->m_offset = roundUpToMultipleOf(entry->alignment(), m_tail->extent());
+        size_t offset = roundUpToMultipleOf(entry->alignment(), m_tail->extent());
+        RELEASE_BASSERT(offset < UINT_MAX);
+        entry->m_offset = offset;
+        std::atomic_thread_fence(std::memory_order_seq_cst);
         m_tail->m_next = entry;
         m_tail = entry;
     } else {
         RELEASE_BASSERT(!m_tail);
         entry->m_offset = 0;
+        std::atomic_thread_fence(std::memory_order_seq_cst);
         m_head = entry;
         m_tail = entry;
     }
 }
 
