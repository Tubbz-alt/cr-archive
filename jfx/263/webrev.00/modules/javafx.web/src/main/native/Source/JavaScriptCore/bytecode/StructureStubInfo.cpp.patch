diff a/modules/javafx.web/src/main/native/Source/JavaScriptCore/bytecode/StructureStubInfo.cpp b/modules/javafx.web/src/main/native/Source/JavaScriptCore/bytecode/StructureStubInfo.cpp
--- a/modules/javafx.web/src/main/native/Source/JavaScriptCore/bytecode/StructureStubInfo.cpp
+++ b/modules/javafx.web/src/main/native/Source/JavaScriptCore/bytecode/StructureStubInfo.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (C) 2008-2019 Apple Inc. All rights reserved.
+ * Copyright (C) 2008-2020 Apple Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions
  * are met:
  * 1. Redistributions of source code must retain the above copyright
@@ -24,83 +24,90 @@
  */
 
 #include "config.h"
 #include "StructureStubInfo.h"
 
+#include "CacheableIdentifierInlines.h"
 #include "JSObject.h"
 #include "JSCInlines.h"
 #include "PolymorphicAccess.h"
 #include "Repatch.h"
 
 namespace JSC {
 
 #if ENABLE(JIT)
 
 namespace StructureStubInfoInternal {
-static const bool verbose = false;
+static constexpr bool verbose = false;
 }
 
 StructureStubInfo::StructureStubInfo(AccessType accessType)
-    : callSiteIndex(UINT_MAX)
-    , accessType(accessType)
-    , cacheType(CacheType::Unset)
+    : accessType(accessType)
+    , m_cacheType(CacheType::Unset)
     , countdown(1) // For a totally clear stub, we'll patch it after the first execution.
     , repatchCount(0)
     , numberOfCoolDowns(0)
     , bufferingCountdown(Options::repatchBufferingCountdown())
     , resetByGC(false)
     , tookSlowPath(false)
     , everConsidered(false)
     , prototypeIsKnownObject(false)
     , sawNonCell(false)
+    , hasConstantIdentifier(true)
+    , propertyIsString(false)
+    , propertyIsInt32(false)
+    , propertyIsSymbol(false)
 {
 }
 
 StructureStubInfo::~StructureStubInfo()
 {
 }
 
-void StructureStubInfo::initGetByIdSelf(CodeBlock* codeBlock, Structure* baseObjectStructure, PropertyOffset offset)
+void StructureStubInfo::initGetByIdSelf(CodeBlock* codeBlock, Structure* baseObjectStructure, PropertyOffset offset, CacheableIdentifier identifier)
 {
-    cacheType = CacheType::GetByIdSelf;
+    ASSERT(hasConstantIdentifier);
+    setCacheType(CacheType::GetByIdSelf);
+    m_getByIdSelfIdentifier = identifier;
+    codeBlock->vm().heap.writeBarrier(codeBlock);
 
     u.byIdSelf.baseObjectStructure.set(
         codeBlock->vm(), codeBlock, baseObjectStructure);
     u.byIdSelf.offset = offset;
 }
 
 void StructureStubInfo::initArrayLength()
 {
-    cacheType = CacheType::ArrayLength;
+    setCacheType(CacheType::ArrayLength);
 }
 
 void StructureStubInfo::initStringLength()
 {
-    cacheType = CacheType::StringLength;
+    setCacheType(CacheType::StringLength);
 }
 
 void StructureStubInfo::initPutByIdReplace(CodeBlock* codeBlock, Structure* baseObjectStructure, PropertyOffset offset)
 {
-    cacheType = CacheType::PutByIdReplace;
+    setCacheType(CacheType::PutByIdReplace);
 
     u.byIdSelf.baseObjectStructure.set(
         codeBlock->vm(), codeBlock, baseObjectStructure);
     u.byIdSelf.offset = offset;
 }
 
 void StructureStubInfo::initInByIdSelf(CodeBlock* codeBlock, Structure* baseObjectStructure, PropertyOffset offset)
 {
-    cacheType = CacheType::InByIdSelf;
+    setCacheType(CacheType::InByIdSelf);
 
     u.byIdSelf.baseObjectStructure.set(
         codeBlock->vm(), codeBlock, baseObjectStructure);
     u.byIdSelf.offset = offset;
 }
 
 void StructureStubInfo::deref()
 {
-    switch (cacheType) {
+    switch (m_cacheType) {
     case CacheType::Stub:
         delete u.stub;
         return;
     case CacheType::Unset:
     case CacheType::GetByIdSelf:
@@ -114,11 +121,11 @@
     RELEASE_ASSERT_NOT_REACHED();
 }
 
 void StructureStubInfo::aboutToDie()
 {
-    switch (cacheType) {
+    switch (m_cacheType) {
     case CacheType::Stub:
         u.stub->aboutToDie();
         return;
     case CacheType::Unset:
     case CacheType::GetByIdSelf:
@@ -131,12 +138,14 @@
 
     RELEASE_ASSERT_NOT_REACHED();
 }
 
 AccessGenerationResult StructureStubInfo::addAccessCase(
-    const GCSafeConcurrentJSLocker& locker, CodeBlock* codeBlock, const Identifier& ident, std::unique_ptr<AccessCase> accessCase)
+    const GCSafeConcurrentJSLocker& locker, CodeBlock* codeBlock, CacheableIdentifier ident, std::unique_ptr<AccessCase> accessCase)
 {
+    checkConsistency();
+
     VM& vm = codeBlock->vm();
     ASSERT(vm.heap.isDeferred());
     AccessGenerationResult result = ([&] () -> AccessGenerationResult {
         if (StructureStubInfoInternal::verbose)
             dataLog("Adding access case: ", accessCase, "\n");
@@ -144,12 +153,12 @@
         if (!accessCase)
             return AccessGenerationResult::GaveUp;
 
         AccessGenerationResult result;
 
-        if (cacheType == CacheType::Stub) {
-            result = u.stub->addCase(locker, vm, codeBlock, *this, ident, WTFMove(accessCase));
+        if (m_cacheType == CacheType::Stub) {
+            result = u.stub->addCase(locker, vm, codeBlock, *this, WTFMove(accessCase));
 
             if (StructureStubInfoInternal::verbose)
                 dataLog("Had stub, result: ", result, "\n");
 
             if (result.shouldResetStubAndFireWatchpoints())
@@ -162,18 +171,17 @@
         } else {
             std::unique_ptr<PolymorphicAccess> access = makeUnique<PolymorphicAccess>();
 
             Vector<std::unique_ptr<AccessCase>, 2> accessCases;
 
-            std::unique_ptr<AccessCase> previousCase =
-                AccessCase::fromStructureStubInfo(vm, codeBlock, *this);
+            std::unique_ptr<AccessCase> previousCase = AccessCase::fromStructureStubInfo(vm, codeBlock, ident, *this);
             if (previousCase)
                 accessCases.append(WTFMove(previousCase));
 
             accessCases.append(WTFMove(accessCase));
 
-            result = access->addCases(locker, vm, codeBlock, *this, ident, WTFMove(accessCases));
+            result = access->addCases(locker, vm, codeBlock, *this, WTFMove(accessCases));
 
             if (StructureStubInfoInternal::verbose)
                 dataLog("Created stub, result: ", result, "\n");
 
             if (result.shouldResetStubAndFireWatchpoints())
@@ -182,14 +190,15 @@
             if (!result.buffered()) {
                 bufferedStructures.clear();
                 return result;
             }
 
-            cacheType = CacheType::Stub;
+            setCacheType(CacheType::Stub);
             u.stub = access.release();
         }
 
+        ASSERT(m_cacheType == CacheType::Stub);
         RELEASE_ASSERT(!result.generatedSomeCode());
 
         // If we didn't buffer any cases then bail. If this made no changes then we'll just try again
         // subject to cool-down.
         if (!result.buffered()) {
@@ -208,11 +217,11 @@
 
         // Forget the buffered structures so that all future attempts to cache get fully handled by the
         // PolymorphicAccess.
         bufferedStructures.clear();
 
-        result = u.stub->regenerate(locker, vm, codeBlock, *this, ident);
+        result = u.stub->regenerate(locker, vm, codeBlock, *this);
 
         if (StructureStubInfoInternal::verbose)
             dataLog("Regeneration result: ", result, "\n");
 
         RELEASE_ASSERT(!result.buffered());
@@ -231,31 +240,34 @@
 
 void StructureStubInfo::reset(CodeBlock* codeBlock)
 {
     bufferedStructures.clear();
 
-    if (cacheType == CacheType::Unset)
+    if (m_cacheType == CacheType::Unset)
         return;
 
     if (Options::verboseOSR()) {
         // This can be called from GC destructor calls, so we don't try to do a full dump
         // of the CodeBlock.
         dataLog("Clearing structure cache (kind ", static_cast<int>(accessType), ") in ", RawPointer(codeBlock), ".\n");
     }
 
     switch (accessType) {
-    case AccessType::TryGet:
-        resetGetByID(codeBlock, *this, GetByIDKind::Try);
+    case AccessType::TryGetById:
+        resetGetBy(codeBlock, *this, GetByKind::Try);
+        break;
+    case AccessType::GetById:
+        resetGetBy(codeBlock, *this, GetByKind::Normal);
         break;
-    case AccessType::Get:
-        resetGetByID(codeBlock, *this, GetByIDKind::Normal);
+    case AccessType::GetByIdWithThis:
+        resetGetBy(codeBlock, *this, GetByKind::WithThis);
         break;
-    case AccessType::GetWithThis:
-        resetGetByID(codeBlock, *this, GetByIDKind::WithThis);
+    case AccessType::GetByIdDirect:
+        resetGetBy(codeBlock, *this, GetByKind::Direct);
         break;
-    case AccessType::GetDirect:
-        resetGetByID(codeBlock, *this, GetByIDKind::Direct);
+    case AccessType::GetByVal:
+        resetGetBy(codeBlock, *this, GetByKind::NormalByVal);
         break;
     case AccessType::Put:
         resetPutByID(codeBlock, *this);
         break;
     case AccessType::In:
@@ -265,23 +277,45 @@
         resetInstanceOf(*this);
         break;
     }
 
     deref();
-    cacheType = CacheType::Unset;
+    setCacheType(CacheType::Unset);
+}
+
+void StructureStubInfo::visitAggregate(SlotVisitor& visitor)
+{
+    switch (m_cacheType) {
+    case CacheType::Unset:
+    case CacheType::ArrayLength:
+    case CacheType::StringLength:
+    case CacheType::PutByIdReplace:
+    case CacheType::InByIdSelf:
+        return;
+    case CacheType::GetByIdSelf:
+        m_getByIdSelfIdentifier.visitAggregate(visitor);
+        return;
+    case CacheType::Stub:
+        u.stub->visitAggregate(visitor);
+        return;
+    }
+
+    RELEASE_ASSERT_NOT_REACHED();
+    return;
 }
 
 void StructureStubInfo::visitWeakReferences(CodeBlock* codeBlock)
 {
     VM& vm = codeBlock->vm();
 
-    bufferedStructures.genericFilter(
-        [&] (Structure* structure) -> bool {
-            return vm.heap.isMarked(structure);
+    bufferedStructures.removeIf(
+        [&] (auto& pair) -> bool {
+            Structure* structure = pair.first;
+            return !vm.heap.isMarked(structure);
         });
 
-    switch (cacheType) {
+    switch (m_cacheType) {
     case CacheType::GetByIdSelf:
     case CacheType::PutByIdReplace:
     case CacheType::InByIdSelf:
         if (vm.heap.isMarked(u.byIdSelf.baseObjectStructure.get()))
             return;
@@ -298,11 +332,11 @@
     resetByGC = true;
 }
 
 bool StructureStubInfo::propagateTransitions(SlotVisitor& visitor)
 {
-    switch (cacheType) {
+    switch (m_cacheType) {
     case CacheType::Unset:
     case CacheType::ArrayLength:
     case CacheType::StringLength:
         return true;
     case CacheType::GetByIdSelf:
@@ -315,19 +349,19 @@
 
     RELEASE_ASSERT_NOT_REACHED();
     return true;
 }
 
-StubInfoSummary StructureStubInfo::summary() const
+StubInfoSummary StructureStubInfo::summary(VM& vm) const
 {
     StubInfoSummary takesSlowPath = StubInfoSummary::TakesSlowPath;
     StubInfoSummary simple = StubInfoSummary::Simple;
-    if (cacheType == CacheType::Stub) {
+    if (m_cacheType == CacheType::Stub) {
         PolymorphicAccess* list = u.stub;
         for (unsigned i = 0; i < list->size(); ++i) {
             const AccessCase& access = list->at(i);
-            if (access.doesCalls()) {
+            if (access.doesCalls(vm)) {
                 takesSlowPath = StubInfoSummary::TakesSlowPathAndMakesCalls;
                 simple = StubInfoSummary::MakesCalls;
                 break;
             }
         }
@@ -340,23 +374,41 @@
         return StubInfoSummary::NoInformation;
 
     return simple;
 }
 
-StubInfoSummary StructureStubInfo::summary(const StructureStubInfo* stubInfo)
+StubInfoSummary StructureStubInfo::summary(VM& vm, const StructureStubInfo* stubInfo)
 {
     if (!stubInfo)
         return StubInfoSummary::NoInformation;
 
-    return stubInfo->summary();
+    return stubInfo->summary(vm);
 }
 
 bool StructureStubInfo::containsPC(void* pc) const
 {
-    if (cacheType != CacheType::Stub)
+    if (m_cacheType != CacheType::Stub)
         return false;
     return u.stub->containsPC(pc);
 }
 
+void StructureStubInfo::setCacheType(CacheType newCacheType)
+{
+    if (m_cacheType == CacheType::GetByIdSelf)
+        m_getByIdSelfIdentifier = nullptr;
+    m_cacheType = newCacheType;
+}
+
+#if ASSERT_ENABLED
+void StructureStubInfo::checkConsistency()
+{
+    if (thisValueIsInThisGPR()) {
+        // We currently use a union for both "thisGPR" and "propertyGPR". If this were
+        // not the case, we'd need to take one of them out of the union.
+        RELEASE_ASSERT(hasConstantIdentifier);
+    }
+}
+#endif // ASSERT_ENABLED
+
 #endif // ENABLE(JIT)
 
 } // namespace JSC
