<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/bytecode/PolymorphicAccess.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="PolyProtoAccessChain.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="PolymorphicAccess.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/bytecode/PolymorphicAccess.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (C) 2014-2018 Apple Inc. All rights reserved.</span>
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;PolymorphicAccess.h&quot;
 28 
 29 #if ENABLE(JIT)
 30 
 31 #include &quot;BinarySwitch.h&quot;
 32 #include &quot;CCallHelpers.h&quot;

 33 #include &quot;CodeBlock.h&quot;
 34 #include &quot;FullCodeOrigin.h&quot;
 35 #include &quot;Heap.h&quot;
 36 #include &quot;JITOperations.h&quot;
 37 #include &quot;JSCInlines.h&quot;
 38 #include &quot;LinkBuffer.h&quot;
 39 #include &quot;StructureStubClearingWatchpoint.h&quot;
 40 #include &quot;StructureStubInfo.h&quot;
 41 #include &quot;SuperSampler.h&quot;
 42 #include &lt;wtf/CommaPrinter.h&gt;
 43 #include &lt;wtf/ListDump.h&gt;
 44 
 45 namespace JSC {
 46 
 47 namespace PolymorphicAccessInternal {
<span class="line-modified"> 48 static const bool verbose = false;</span>
 49 }
 50 


 51 void AccessGenerationResult::dump(PrintStream&amp; out) const
 52 {
 53     out.print(m_kind);
 54     if (m_code)
 55         out.print(&quot;:&quot;, m_code);
 56 }
 57 
<span class="line-modified"> 58 Watchpoint* AccessGenerationState::addWatchpoint(const ObjectPropertyCondition&amp; condition)</span>
 59 {
<span class="line-modified"> 60     return WatchpointsOnStructureStubInfo::ensureReferenceAndAddWatchpoint(</span>
 61         watchpoints, jit-&gt;codeBlock(), stubInfo, condition);
 62 }
 63 
 64 void AccessGenerationState::restoreScratch()
 65 {
 66     allocator-&gt;restoreReusedRegistersByPopping(*jit, preservedReusedRegisterState);
 67 }
 68 
 69 void AccessGenerationState::succeed()
 70 {
 71     restoreScratch();
 72     success.append(jit-&gt;jump());
 73 }
 74 
 75 const RegisterSet&amp; AccessGenerationState::liveRegistersForCall()
 76 {
 77     if (!m_calculatedRegistersForCallAndExceptionHandling)
 78         calculateLiveRegistersForCallAndExceptionHandling();
 79     return m_liveRegistersForCall;
 80 }
</pre>
<hr />
<pre>
193     jit-&gt;popToRestore(GPRInfo::regT0);
194 
195     if (needsToRestoreRegistersIfException()) {
196         // To the JIT that produces the original exception handling
197         // call site, they will expect the OSR exit to be arrived
198         // at from genericUnwind. Therefore we must model what genericUnwind
199         // does here. I.e, set callFrameForCatch and copy callee saves.
200 
201         jit-&gt;storePtr(GPRInfo::callFrameRegister, m_vm.addressOfCallFrameForCatch());
202         CCallHelpers::Jump jumpToOSRExitExceptionHandler = jit-&gt;jump();
203 
204         // We don&#39;t need to insert a new exception handler in the table
205         // because we&#39;re doing a manual exception check here. i.e, we&#39;ll
206         // never arrive here from genericUnwind().
207         HandlerInfo originalHandler = originalExceptionHandler();
208         jit-&gt;addLinkTask(
209             [=] (LinkBuffer&amp; linkBuffer) {
210                 linkBuffer.link(jumpToOSRExitExceptionHandler, originalHandler.nativeCode);
211             });
212     } else {
<span class="line-modified">213         jit-&gt;setupArguments&lt;decltype(lookupExceptionHandler)&gt;(CCallHelpers::TrustedImmPtr(&amp;m_vm), GPRInfo::callFrameRegister);</span>

214         CCallHelpers::Call lookupExceptionHandlerCall = jit-&gt;call(OperationPtrTag);
215         jit-&gt;addLinkTask(
216             [=] (LinkBuffer&amp; linkBuffer) {
<span class="line-modified">217                 linkBuffer.link(lookupExceptionHandlerCall, FunctionPtr&lt;OperationPtrTag&gt;(lookupExceptionHandler));</span>
218             });
219         jit-&gt;jumpToExceptionHandler(m_vm);
220     }
221 }
222 
<span class="line-removed">223 </span>
224 PolymorphicAccess::PolymorphicAccess() { }
225 PolymorphicAccess::~PolymorphicAccess() { }
226 
227 AccessGenerationResult PolymorphicAccess::addCases(
228     const GCSafeConcurrentJSLocker&amp; locker, VM&amp; vm, CodeBlock* codeBlock, StructureStubInfo&amp; stubInfo,
<span class="line-modified">229     const Identifier&amp; ident, Vector&lt;std::unique_ptr&lt;AccessCase&gt;, 2&gt; originalCasesToAdd)</span>
230 {
231     SuperSamplerScope superSamplerScope(false);
232 
233     // This method will add the originalCasesToAdd to the list one at a time while preserving the
234     // invariants:
235     // - If a newly added case canReplace() any existing case, then the existing case is removed before
236     //   the new case is added. Removal doesn&#39;t change order of the list. Any number of existing cases
237     //   can be removed via the canReplace() rule.
238     // - Cases in the list always appear in ascending order of time of addition. Therefore, if you
239     //   cascade through the cases in reverse order, you will get the most recent cases first.
240     // - If this method fails (returns null, doesn&#39;t add the cases), then both the previous case list
241     //   and the previous stub are kept intact and the new cases are destroyed. It&#39;s OK to attempt to
242     //   add more things after failure.
243 
244     // First ensure that the originalCasesToAdd doesn&#39;t contain duplicates.
245     Vector&lt;std::unique_ptr&lt;AccessCase&gt;&gt; casesToAdd;
246     for (unsigned i = 0; i &lt; originalCasesToAdd.size(); ++i) {
247         std::unique_ptr&lt;AccessCase&gt; myCase = WTFMove(originalCasesToAdd[i]);
248 
249         // Add it only if it is not replaced by the subsequent cases in the list.
</pre>
<hr />
<pre>
292                 Structure* a = caseToAdd-&gt;structure();
293                 Structure* b = existingCase-&gt;structure();
294                 considerPolyProtoReset(a, b);
295             }
296         }
297         for (unsigned i = 0; i &lt; casesToAdd.size(); ++i) {
298             for (unsigned j = i + 1; j &lt; casesToAdd.size(); ++j) {
299                 Structure* a = casesToAdd[i]-&gt;structure();
300                 Structure* b = casesToAdd[j]-&gt;structure();
301                 considerPolyProtoReset(a, b);
302             }
303         }
304 
305         if (shouldReset)
306             return resetResult;
307     }
308 
309     // Now add things to the new list. Note that at this point, we will still have old cases that
310     // may be replaced by the new ones. That&#39;s fine. We will sort that out when we regenerate.
311     for (auto&amp; caseToAdd : casesToAdd) {
<span class="line-modified">312         commit(locker, vm, m_watchpoints, codeBlock, stubInfo, ident, *caseToAdd);</span>
313         m_list.append(WTFMove(caseToAdd));
314     }
315 
316     if (PolymorphicAccessInternal::verbose)
317         dataLog(&quot;After addCases: m_list: &quot;, listDump(m_list), &quot;\n&quot;);
318 
319     return AccessGenerationResult::Buffered;
320 }
321 
322 AccessGenerationResult PolymorphicAccess::addCase(
<span class="line-modified">323     const GCSafeConcurrentJSLocker&amp; locker, VM&amp; vm, CodeBlock* codeBlock, StructureStubInfo&amp; stubInfo,</span>
<span class="line-removed">324     const Identifier&amp; ident, std::unique_ptr&lt;AccessCase&gt; newAccess)</span>
325 {
326     Vector&lt;std::unique_ptr&lt;AccessCase&gt;, 2&gt; newAccesses;
327     newAccesses.append(WTFMove(newAccess));
<span class="line-modified">328     return addCases(locker, vm, codeBlock, stubInfo, ident, WTFMove(newAccesses));</span>
329 }
330 
331 bool PolymorphicAccess::visitWeak(VM&amp; vm) const
332 {
333     for (unsigned i = 0; i &lt; size(); ++i) {
334         if (!at(i).visitWeak(vm))
335             return false;
336     }
337     if (Vector&lt;WriteBarrier&lt;JSCell&gt;&gt;* weakReferences = m_weakReferences.get()) {
338         for (WriteBarrier&lt;JSCell&gt;&amp; weakReference : *weakReferences) {
339             if (!vm.heap.isMarked(weakReference.get()))
340                 return false;
341         }
342     }
343     return true;
344 }
345 
346 bool PolymorphicAccess::propagateTransitions(SlotVisitor&amp; visitor) const
347 {
348     bool result = true;
349     for (unsigned i = 0; i &lt; size(); ++i)
350         result &amp;= at(i).propagateTransitions(visitor);
351     return result;
352 }
353 






354 void PolymorphicAccess::dump(PrintStream&amp; out) const
355 {
356     out.print(RawPointer(this), &quot;:[&quot;);
357     CommaPrinter comma;
358     for (auto&amp; entry : m_list)
359         out.print(comma, *entry);
360     out.print(&quot;]&quot;);
361 }
362 
363 void PolymorphicAccess::commit(
364     const GCSafeConcurrentJSLocker&amp;, VM&amp; vm, std::unique_ptr&lt;WatchpointsOnStructureStubInfo&gt;&amp; watchpoints, CodeBlock* codeBlock,
<span class="line-modified">365     StructureStubInfo&amp; stubInfo, const Identifier&amp; ident, AccessCase&amp; accessCase)</span>
366 {
367     // NOTE: We currently assume that this is relatively rare. It mainly arises for accesses to
368     // properties on DOM nodes. For sure we cache many DOM node accesses, but even in
369     // Real Pages (TM), we appear to spend most of our time caching accesses to properties on
370     // vanilla objects or exotic objects from within JSC (like Arguments, those are super popular).
371     // Those common kinds of JSC object accesses don&#39;t hit this case.
372 
<span class="line-modified">373     for (WatchpointSet* set : accessCase.commit(vm, ident)) {</span>
374         Watchpoint* watchpoint =
375             WatchpointsOnStructureStubInfo::ensureReferenceAndAddWatchpoint(
<span class="line-modified">376                 watchpoints, codeBlock, &amp;stubInfo, ObjectPropertyCondition());</span>
377 
378         set-&gt;add(watchpoint);
379     }
380 }
381 
382 AccessGenerationResult PolymorphicAccess::regenerate(
<span class="line-modified">383     const GCSafeConcurrentJSLocker&amp; locker, VM&amp; vm, CodeBlock* codeBlock, StructureStubInfo&amp; stubInfo, const Identifier&amp; ident)</span>
384 {
385     SuperSamplerScope superSamplerScope(false);
386 
387     if (PolymorphicAccessInternal::verbose)
388         dataLog(&quot;Regenerate with m_list: &quot;, listDump(m_list), &quot;\n&quot;);
389 
390     AccessGenerationState state(vm, codeBlock-&gt;globalObject());
391 
392     state.access = this;
393     state.stubInfo = &amp;stubInfo;
<span class="line-removed">394     state.ident = &amp;ident;</span>
395 
<span class="line-modified">396     state.baseGPR = stubInfo.baseGPR();</span>
<span class="line-modified">397     state.thisGPR = stubInfo.patch.thisGPR;</span>
398     state.valueRegs = stubInfo.valueRegs();
399 
<span class="line-removed">400     ScratchRegisterAllocator allocator(stubInfo.patch.usedRegisters);</span>
<span class="line-removed">401     state.allocator = &amp;allocator;</span>
<span class="line-removed">402     allocator.lock(state.baseGPR);</span>
<span class="line-removed">403     if (state.thisGPR != InvalidGPRReg)</span>
<span class="line-removed">404         allocator.lock(state.thisGPR);</span>
<span class="line-removed">405     allocator.lock(state.valueRegs);</span>
<span class="line-removed">406 #if USE(JSVALUE32_64)</span>
<span class="line-removed">407     allocator.lock(stubInfo.patch.baseTagGPR);</span>
<span class="line-removed">408 #endif</span>
<span class="line-removed">409 </span>
<span class="line-removed">410     state.scratchGPR = allocator.allocateScratchGPR();</span>
<span class="line-removed">411 </span>
<span class="line-removed">412     CCallHelpers jit(codeBlock);</span>
<span class="line-removed">413     state.jit = &amp;jit;</span>
<span class="line-removed">414 </span>
<span class="line-removed">415     state.preservedReusedRegisterState =</span>
<span class="line-removed">416         allocator.preserveReusedRegistersByPushing(jit, ScratchRegisterAllocator::ExtraStackSpace::NoExtraSpace);</span>
<span class="line-removed">417 </span>
418     // Regenerating is our opportunity to figure out what our list of cases should look like. We
419     // do this here. The newly produced &#39;cases&#39; list may be smaller than m_list. We don&#39;t edit
420     // m_list in-place because we may still fail, in which case we want the PolymorphicAccess object
421     // to be unmutated. For sure, we want it to hang onto any data structures that may be referenced
422     // from the code of the current stub (aka previous).
423     ListType cases;
424     unsigned srcIndex = 0;
425     unsigned dstIndex = 0;
426     while (srcIndex &lt; m_list.size()) {
427         std::unique_ptr&lt;AccessCase&gt; someCase = WTFMove(m_list[srcIndex++]);
428 
429         // If the case had been generated, then we have to keep the original in m_list in case we
430         // fail to regenerate. That case may have data structures that are used by the code that it
431         // had generated. If the case had not been generated, then we want to remove it from m_list.
432         bool isGenerated = someCase-&gt;state() == AccessCase::Generated;
433 
434         [&amp;] () {
435             if (!someCase-&gt;couldStillSucceed())
436                 return;
437 
</pre>
<hr />
<pre>
446             // don&#39;t need A anymore.
447             //
448             // If we can generate a binary switch, then A-&gt;canReplace(B) == B-&gt;canReplace(A). So,
449             // it doesn&#39;t matter that we only do the check in one direction.
450             for (unsigned j = srcIndex; j &lt; m_list.size(); ++j) {
451                 if (m_list[j]-&gt;canReplace(*someCase))
452                     return;
453             }
454 
455             if (isGenerated)
456                 cases.append(someCase-&gt;clone());
457             else
458                 cases.append(WTFMove(someCase));
459         }();
460 
461         if (isGenerated)
462             m_list[dstIndex++] = WTFMove(someCase);
463     }
464     m_list.resize(dstIndex);
465 



























466     bool generatedFinalCode = false;
467 
468     // If the resulting set of cases is so big that we would stop caching and this is InstanceOf,
469     // then we want to generate the generic InstanceOf and then stop.
470     if (cases.size() &gt;= Options::maxAccessVariantListSize()
471         &amp;&amp; stubInfo.accessType == AccessType::InstanceOf) {
472         while (!cases.isEmpty())
473             m_list.append(cases.takeLast());
<span class="line-modified">474         cases.append(AccessCase::create(vm, codeBlock, AccessCase::InstanceOfGeneric));</span>
475         generatedFinalCode = true;
476     }
477 
478     if (PolymorphicAccessInternal::verbose)
479         dataLog(&quot;Optimized cases: &quot;, listDump(cases), &quot;\n&quot;);
480 
481     // At this point we&#39;re convinced that &#39;cases&#39; contains the cases that we want to JIT now and we
482     // won&#39;t change that set anymore.
483 
484     bool allGuardedByStructureCheck = true;
485     bool hasJSGetterSetterCall = false;



486     for (auto&amp; newCase : cases) {
<span class="line-modified">487         commit(locker, vm, state.watchpoints, codeBlock, stubInfo, ident, *newCase);</span>
<span class="line-modified">488         allGuardedByStructureCheck &amp;= newCase-&gt;guardedByStructureCheck();</span>









489         if (newCase-&gt;type() == AccessCase::Getter || newCase-&gt;type() == AccessCase::Setter)
490             hasJSGetterSetterCall = true;
491     }
492 
493     if (cases.isEmpty()) {
494         // This is super unlikely, but we make it legal anyway.
495         state.failAndRepatch.append(jit.jump());
496     } else if (!allGuardedByStructureCheck || cases.size() == 1) {
497         // If there are any proxies in the list, we cannot just use a binary switch over the structure.
498         // We need to resort to a cascade. A cascade also happens to be optimal if we only have just
499         // one case.
500         CCallHelpers::JumpList fallThrough;
















































































501 
<span class="line-modified">502         // Cascade through the list, preferring newer entries.</span>
<span class="line-modified">503         for (unsigned i = cases.size(); i--;) {</span>
<span class="line-modified">504             fallThrough.link(&amp;jit);</span>
<span class="line-modified">505             fallThrough.clear();</span>
<span class="line-modified">506             cases[i]-&gt;generateWithGuard(state, fallThrough);</span>




507         }

508         state.failAndRepatch.append(fallThrough);

509     } else {
510         jit.load32(
511             CCallHelpers::Address(state.baseGPR, JSCell::structureIDOffset()),
512             state.scratchGPR);
513 
514         Vector&lt;int64_t&gt; caseValues(cases.size());
515         for (unsigned i = 0; i &lt; cases.size(); ++i)
516             caseValues[i] = bitwise_cast&lt;int32_t&gt;(cases[i]-&gt;structure()-&gt;id());
517 
518         BinarySwitch binarySwitch(state.scratchGPR, caseValues, BinarySwitch::Int32);
519         while (binarySwitch.advance(jit))
520             cases[binarySwitch.caseIndex()]-&gt;generate(state);
521         state.failAndRepatch.append(binarySwitch.fallThrough());
522     }
523 
524     if (!state.failAndIgnore.empty()) {
525         state.failAndIgnore.link(&amp;jit);
526 
527         // Make sure that the inline cache optimization code knows that we are taking slow path because
528         // of something that isn&#39;t patchable. The slow path will decrement &quot;countdown&quot; and will only
</pre>
<hr />
<pre>
578                 handlerToRegister.nativeCode = linkBuffer.locationOf&lt;ExceptionHandlerPtrTag&gt;(makeshiftCatchHandler);
579                 handlerToRegister.start = newExceptionHandlingCallSite.bits();
580                 handlerToRegister.end = newExceptionHandlingCallSite.bits() + 1;
581                 codeBlock-&gt;appendExceptionHandler(handlerToRegister);
582             });
583 
584         // We set these to indicate to the stub to remove itself from the CodeBlock&#39;s
585         // exception handler table when it is deallocated.
586         codeBlockThatOwnsExceptionHandlers = codeBlock;
587         ASSERT(JITCode::isOptimizingJIT(codeBlockThatOwnsExceptionHandlers-&gt;jitType()));
588         callSiteIndexForExceptionHandling = state.callSiteIndexForExceptionHandling();
589     }
590 
591     LinkBuffer linkBuffer(jit, codeBlock, JITCompilationCanFail);
592     if (linkBuffer.didFailToAllocate()) {
593         if (PolymorphicAccessInternal::verbose)
594             dataLog(&quot;Did fail to allocate.\n&quot;);
595         return AccessGenerationResult::GaveUp;
596     }
597 
<span class="line-modified">598     CodeLocationLabel&lt;JSInternalPtrTag&gt; successLabel = stubInfo.doneLocation();</span>
599 
600     linkBuffer.link(state.success, successLabel);
601 
<span class="line-modified">602     linkBuffer.link(failure, stubInfo.slowPathStartLocation());</span>
603 
604     if (PolymorphicAccessInternal::verbose)
605         dataLog(FullCodeOrigin(codeBlock, stubInfo.codeOrigin), &quot;: Generating polymorphic access stub for &quot;, listDump(cases), &quot;\n&quot;);
606 
607     MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; code = FINALIZE_CODE_FOR(
608         codeBlock, linkBuffer, JITStubRoutinePtrTag,
609         &quot;%s&quot;, toCString(&quot;Access stub for &quot;, *codeBlock, &quot; &quot;, stubInfo.codeOrigin, &quot; with return point &quot;, successLabel, &quot;: &quot;, listDump(cases)).data());
610 
611     bool doesCalls = false;
612     Vector&lt;JSCell*&gt; cellsToMark;
613     for (auto&amp; entry : cases)
<span class="line-modified">614         doesCalls |= entry-&gt;doesCalls(&amp;cellsToMark);</span>
615 
<span class="line-modified">616     m_stubRoutine = createJITStubRoutine(code, vm, codeBlock, doesCalls, cellsToMark, codeBlockThatOwnsExceptionHandlers, callSiteIndexForExceptionHandling);</span>
617     m_watchpoints = WTFMove(state.watchpoints);
<span class="line-modified">618     if (!state.weakReferences.isEmpty())</span>

619         m_weakReferences = makeUnique&lt;Vector&lt;WriteBarrier&lt;JSCell&gt;&gt;&gt;(WTFMove(state.weakReferences));

620     if (PolymorphicAccessInternal::verbose)
621         dataLog(&quot;Returning: &quot;, code.code(), &quot;\n&quot;);
622 
623     m_list = WTFMove(cases);

624 
625     AccessGenerationResult::Kind resultKind;
626     if (m_list.size() &gt;= Options::maxAccessVariantListSize() || generatedFinalCode)
627         resultKind = AccessGenerationResult::GeneratedFinalCode;
628     else
629         resultKind = AccessGenerationResult::GeneratedNewCode;
630 
631     return AccessGenerationResult(resultKind, code.code());
632 }
633 
634 void PolymorphicAccess::aboutToDie()
635 {
636     if (m_stubRoutine)
637         m_stubRoutine-&gt;aboutToDie();
638 }
639 
640 } // namespace JSC
641 
642 namespace WTF {
643 
</pre>
<hr />
<pre>
721         out.print(&quot;StringLength&quot;);
722         return;
723     case AccessCase::DirectArgumentsLength:
724         out.print(&quot;DirectArgumentsLength&quot;);
725         return;
726     case AccessCase::ScopedArgumentsLength:
727         out.print(&quot;ScopedArgumentsLength&quot;);
728         return;
729     case AccessCase::ModuleNamespaceLoad:
730         out.print(&quot;ModuleNamespaceLoad&quot;);
731         return;
732     case AccessCase::InstanceOfHit:
733         out.print(&quot;InstanceOfHit&quot;);
734         return;
735     case AccessCase::InstanceOfMiss:
736         out.print(&quot;InstanceOfMiss&quot;);
737         return;
738     case AccessCase::InstanceOfGeneric:
739         out.print(&quot;InstanceOfGeneric&quot;);
740         return;
















































741     }
742 
743     RELEASE_ASSERT_NOT_REACHED();
744 }
745 
746 void printInternal(PrintStream&amp; out, AccessCase::State state)
747 {
748     switch (state) {
749     case AccessCase::Primordial:
750         out.print(&quot;Primordial&quot;);
751         return;
752     case AccessCase::Committed:
753         out.print(&quot;Committed&quot;);
754         return;
755     case AccessCase::Generated:
756         out.print(&quot;Generated&quot;);
757         return;
758     }
759 
760     RELEASE_ASSERT_NOT_REACHED();
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (C) 2014-2020 Apple Inc. All rights reserved.</span>
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;PolymorphicAccess.h&quot;
 28 
 29 #if ENABLE(JIT)
 30 
 31 #include &quot;BinarySwitch.h&quot;
 32 #include &quot;CCallHelpers.h&quot;
<span class="line-added"> 33 #include &quot;CacheableIdentifierInlines.h&quot;</span>
 34 #include &quot;CodeBlock.h&quot;
 35 #include &quot;FullCodeOrigin.h&quot;
 36 #include &quot;Heap.h&quot;
 37 #include &quot;JITOperations.h&quot;
 38 #include &quot;JSCInlines.h&quot;
 39 #include &quot;LinkBuffer.h&quot;
 40 #include &quot;StructureStubClearingWatchpoint.h&quot;
 41 #include &quot;StructureStubInfo.h&quot;
 42 #include &quot;SuperSampler.h&quot;
 43 #include &lt;wtf/CommaPrinter.h&gt;
 44 #include &lt;wtf/ListDump.h&gt;
 45 
 46 namespace JSC {
 47 
 48 namespace PolymorphicAccessInternal {
<span class="line-modified"> 49 static constexpr bool verbose = false;</span>
 50 }
 51 
<span class="line-added"> 52 DEFINE_ALLOCATOR_WITH_HEAP_IDENTIFIER(PolymorphicAccess);</span>
<span class="line-added"> 53 </span>
 54 void AccessGenerationResult::dump(PrintStream&amp; out) const
 55 {
 56     out.print(m_kind);
 57     if (m_code)
 58         out.print(&quot;:&quot;, m_code);
 59 }
 60 
<span class="line-modified"> 61 void AccessGenerationState::installWatchpoint(const ObjectPropertyCondition&amp; condition)</span>
 62 {
<span class="line-modified"> 63     WatchpointsOnStructureStubInfo::ensureReferenceAndInstallWatchpoint(</span>
 64         watchpoints, jit-&gt;codeBlock(), stubInfo, condition);
 65 }
 66 
 67 void AccessGenerationState::restoreScratch()
 68 {
 69     allocator-&gt;restoreReusedRegistersByPopping(*jit, preservedReusedRegisterState);
 70 }
 71 
 72 void AccessGenerationState::succeed()
 73 {
 74     restoreScratch();
 75     success.append(jit-&gt;jump());
 76 }
 77 
 78 const RegisterSet&amp; AccessGenerationState::liveRegistersForCall()
 79 {
 80     if (!m_calculatedRegistersForCallAndExceptionHandling)
 81         calculateLiveRegistersForCallAndExceptionHandling();
 82     return m_liveRegistersForCall;
 83 }
</pre>
<hr />
<pre>
196     jit-&gt;popToRestore(GPRInfo::regT0);
197 
198     if (needsToRestoreRegistersIfException()) {
199         // To the JIT that produces the original exception handling
200         // call site, they will expect the OSR exit to be arrived
201         // at from genericUnwind. Therefore we must model what genericUnwind
202         // does here. I.e, set callFrameForCatch and copy callee saves.
203 
204         jit-&gt;storePtr(GPRInfo::callFrameRegister, m_vm.addressOfCallFrameForCatch());
205         CCallHelpers::Jump jumpToOSRExitExceptionHandler = jit-&gt;jump();
206 
207         // We don&#39;t need to insert a new exception handler in the table
208         // because we&#39;re doing a manual exception check here. i.e, we&#39;ll
209         // never arrive here from genericUnwind().
210         HandlerInfo originalHandler = originalExceptionHandler();
211         jit-&gt;addLinkTask(
212             [=] (LinkBuffer&amp; linkBuffer) {
213                 linkBuffer.link(jumpToOSRExitExceptionHandler, originalHandler.nativeCode);
214             });
215     } else {
<span class="line-modified">216         jit-&gt;setupArguments&lt;decltype(operationLookupExceptionHandler)&gt;(CCallHelpers::TrustedImmPtr(&amp;m_vm));</span>
<span class="line-added">217         jit-&gt;prepareCallOperation(m_vm);</span>
218         CCallHelpers::Call lookupExceptionHandlerCall = jit-&gt;call(OperationPtrTag);
219         jit-&gt;addLinkTask(
220             [=] (LinkBuffer&amp; linkBuffer) {
<span class="line-modified">221                 linkBuffer.link(lookupExceptionHandlerCall, FunctionPtr&lt;OperationPtrTag&gt;(operationLookupExceptionHandler));</span>
222             });
223         jit-&gt;jumpToExceptionHandler(m_vm);
224     }
225 }
226 

227 PolymorphicAccess::PolymorphicAccess() { }
228 PolymorphicAccess::~PolymorphicAccess() { }
229 
230 AccessGenerationResult PolymorphicAccess::addCases(
231     const GCSafeConcurrentJSLocker&amp; locker, VM&amp; vm, CodeBlock* codeBlock, StructureStubInfo&amp; stubInfo,
<span class="line-modified">232     Vector&lt;std::unique_ptr&lt;AccessCase&gt;, 2&gt; originalCasesToAdd)</span>
233 {
234     SuperSamplerScope superSamplerScope(false);
235 
236     // This method will add the originalCasesToAdd to the list one at a time while preserving the
237     // invariants:
238     // - If a newly added case canReplace() any existing case, then the existing case is removed before
239     //   the new case is added. Removal doesn&#39;t change order of the list. Any number of existing cases
240     //   can be removed via the canReplace() rule.
241     // - Cases in the list always appear in ascending order of time of addition. Therefore, if you
242     //   cascade through the cases in reverse order, you will get the most recent cases first.
243     // - If this method fails (returns null, doesn&#39;t add the cases), then both the previous case list
244     //   and the previous stub are kept intact and the new cases are destroyed. It&#39;s OK to attempt to
245     //   add more things after failure.
246 
247     // First ensure that the originalCasesToAdd doesn&#39;t contain duplicates.
248     Vector&lt;std::unique_ptr&lt;AccessCase&gt;&gt; casesToAdd;
249     for (unsigned i = 0; i &lt; originalCasesToAdd.size(); ++i) {
250         std::unique_ptr&lt;AccessCase&gt; myCase = WTFMove(originalCasesToAdd[i]);
251 
252         // Add it only if it is not replaced by the subsequent cases in the list.
</pre>
<hr />
<pre>
295                 Structure* a = caseToAdd-&gt;structure();
296                 Structure* b = existingCase-&gt;structure();
297                 considerPolyProtoReset(a, b);
298             }
299         }
300         for (unsigned i = 0; i &lt; casesToAdd.size(); ++i) {
301             for (unsigned j = i + 1; j &lt; casesToAdd.size(); ++j) {
302                 Structure* a = casesToAdd[i]-&gt;structure();
303                 Structure* b = casesToAdd[j]-&gt;structure();
304                 considerPolyProtoReset(a, b);
305             }
306         }
307 
308         if (shouldReset)
309             return resetResult;
310     }
311 
312     // Now add things to the new list. Note that at this point, we will still have old cases that
313     // may be replaced by the new ones. That&#39;s fine. We will sort that out when we regenerate.
314     for (auto&amp; caseToAdd : casesToAdd) {
<span class="line-modified">315         commit(locker, vm, m_watchpoints, codeBlock, stubInfo, *caseToAdd);</span>
316         m_list.append(WTFMove(caseToAdd));
317     }
318 
319     if (PolymorphicAccessInternal::verbose)
320         dataLog(&quot;After addCases: m_list: &quot;, listDump(m_list), &quot;\n&quot;);
321 
322     return AccessGenerationResult::Buffered;
323 }
324 
325 AccessGenerationResult PolymorphicAccess::addCase(
<span class="line-modified">326     const GCSafeConcurrentJSLocker&amp; locker, VM&amp; vm, CodeBlock* codeBlock, StructureStubInfo&amp; stubInfo, std::unique_ptr&lt;AccessCase&gt; newAccess)</span>

327 {
328     Vector&lt;std::unique_ptr&lt;AccessCase&gt;, 2&gt; newAccesses;
329     newAccesses.append(WTFMove(newAccess));
<span class="line-modified">330     return addCases(locker, vm, codeBlock, stubInfo, WTFMove(newAccesses));</span>
331 }
332 
333 bool PolymorphicAccess::visitWeak(VM&amp; vm) const
334 {
335     for (unsigned i = 0; i &lt; size(); ++i) {
336         if (!at(i).visitWeak(vm))
337             return false;
338     }
339     if (Vector&lt;WriteBarrier&lt;JSCell&gt;&gt;* weakReferences = m_weakReferences.get()) {
340         for (WriteBarrier&lt;JSCell&gt;&amp; weakReference : *weakReferences) {
341             if (!vm.heap.isMarked(weakReference.get()))
342                 return false;
343         }
344     }
345     return true;
346 }
347 
348 bool PolymorphicAccess::propagateTransitions(SlotVisitor&amp; visitor) const
349 {
350     bool result = true;
351     for (unsigned i = 0; i &lt; size(); ++i)
352         result &amp;= at(i).propagateTransitions(visitor);
353     return result;
354 }
355 
<span class="line-added">356 void PolymorphicAccess::visitAggregate(SlotVisitor&amp; visitor)</span>
<span class="line-added">357 {</span>
<span class="line-added">358     for (unsigned i = 0; i &lt; size(); ++i)</span>
<span class="line-added">359         at(i).visitAggregate(visitor);</span>
<span class="line-added">360 }</span>
<span class="line-added">361 </span>
362 void PolymorphicAccess::dump(PrintStream&amp; out) const
363 {
364     out.print(RawPointer(this), &quot;:[&quot;);
365     CommaPrinter comma;
366     for (auto&amp; entry : m_list)
367         out.print(comma, *entry);
368     out.print(&quot;]&quot;);
369 }
370 
371 void PolymorphicAccess::commit(
372     const GCSafeConcurrentJSLocker&amp;, VM&amp; vm, std::unique_ptr&lt;WatchpointsOnStructureStubInfo&gt;&amp; watchpoints, CodeBlock* codeBlock,
<span class="line-modified">373     StructureStubInfo&amp; stubInfo, AccessCase&amp; accessCase)</span>
374 {
375     // NOTE: We currently assume that this is relatively rare. It mainly arises for accesses to
376     // properties on DOM nodes. For sure we cache many DOM node accesses, but even in
377     // Real Pages (TM), we appear to spend most of our time caching accesses to properties on
378     // vanilla objects or exotic objects from within JSC (like Arguments, those are super popular).
379     // Those common kinds of JSC object accesses don&#39;t hit this case.
380 
<span class="line-modified">381     for (WatchpointSet* set : accessCase.commit(vm)) {</span>
382         Watchpoint* watchpoint =
383             WatchpointsOnStructureStubInfo::ensureReferenceAndAddWatchpoint(
<span class="line-modified">384                 watchpoints, codeBlock, &amp;stubInfo);</span>
385 
386         set-&gt;add(watchpoint);
387     }
388 }
389 
390 AccessGenerationResult PolymorphicAccess::regenerate(
<span class="line-modified">391     const GCSafeConcurrentJSLocker&amp; locker, VM&amp; vm, CodeBlock* codeBlock, StructureStubInfo&amp; stubInfo)</span>
392 {
393     SuperSamplerScope superSamplerScope(false);
394 
395     if (PolymorphicAccessInternal::verbose)
396         dataLog(&quot;Regenerate with m_list: &quot;, listDump(m_list), &quot;\n&quot;);
397 
398     AccessGenerationState state(vm, codeBlock-&gt;globalObject());
399 
400     state.access = this;
401     state.stubInfo = &amp;stubInfo;

402 
<span class="line-modified">403     state.baseGPR = stubInfo.baseGPR;</span>
<span class="line-modified">404     state.u.thisGPR = stubInfo.regs.thisGPR;</span>
405     state.valueRegs = stubInfo.valueRegs();
406 


















407     // Regenerating is our opportunity to figure out what our list of cases should look like. We
408     // do this here. The newly produced &#39;cases&#39; list may be smaller than m_list. We don&#39;t edit
409     // m_list in-place because we may still fail, in which case we want the PolymorphicAccess object
410     // to be unmutated. For sure, we want it to hang onto any data structures that may be referenced
411     // from the code of the current stub (aka previous).
412     ListType cases;
413     unsigned srcIndex = 0;
414     unsigned dstIndex = 0;
415     while (srcIndex &lt; m_list.size()) {
416         std::unique_ptr&lt;AccessCase&gt; someCase = WTFMove(m_list[srcIndex++]);
417 
418         // If the case had been generated, then we have to keep the original in m_list in case we
419         // fail to regenerate. That case may have data structures that are used by the code that it
420         // had generated. If the case had not been generated, then we want to remove it from m_list.
421         bool isGenerated = someCase-&gt;state() == AccessCase::Generated;
422 
423         [&amp;] () {
424             if (!someCase-&gt;couldStillSucceed())
425                 return;
426 
</pre>
<hr />
<pre>
435             // don&#39;t need A anymore.
436             //
437             // If we can generate a binary switch, then A-&gt;canReplace(B) == B-&gt;canReplace(A). So,
438             // it doesn&#39;t matter that we only do the check in one direction.
439             for (unsigned j = srcIndex; j &lt; m_list.size(); ++j) {
440                 if (m_list[j]-&gt;canReplace(*someCase))
441                     return;
442             }
443 
444             if (isGenerated)
445                 cases.append(someCase-&gt;clone());
446             else
447                 cases.append(WTFMove(someCase));
448         }();
449 
450         if (isGenerated)
451             m_list[dstIndex++] = WTFMove(someCase);
452     }
453     m_list.resize(dstIndex);
454 
<span class="line-added">455     ScratchRegisterAllocator allocator(stubInfo.usedRegisters);</span>
<span class="line-added">456     state.allocator = &amp;allocator;</span>
<span class="line-added">457     allocator.lock(state.baseGPR);</span>
<span class="line-added">458     if (state.u.thisGPR != InvalidGPRReg)</span>
<span class="line-added">459         allocator.lock(state.u.thisGPR);</span>
<span class="line-added">460     allocator.lock(state.valueRegs);</span>
<span class="line-added">461 #if USE(JSVALUE32_64)</span>
<span class="line-added">462     allocator.lock(stubInfo.baseTagGPR);</span>
<span class="line-added">463     if (stubInfo.v.thisTagGPR != InvalidGPRReg)</span>
<span class="line-added">464         allocator.lock(stubInfo.v.thisTagGPR);</span>
<span class="line-added">465 #endif</span>
<span class="line-added">466 </span>
<span class="line-added">467     state.scratchGPR = allocator.allocateScratchGPR();</span>
<span class="line-added">468 </span>
<span class="line-added">469     for (auto&amp; accessCase : cases) {</span>
<span class="line-added">470         if (accessCase-&gt;needsScratchFPR()) {</span>
<span class="line-added">471             state.scratchFPR = allocator.allocateScratchFPR();</span>
<span class="line-added">472             break;</span>
<span class="line-added">473         }</span>
<span class="line-added">474     }</span>
<span class="line-added">475 </span>
<span class="line-added">476     CCallHelpers jit(codeBlock);</span>
<span class="line-added">477     state.jit = &amp;jit;</span>
<span class="line-added">478 </span>
<span class="line-added">479     state.preservedReusedRegisterState =</span>
<span class="line-added">480         allocator.preserveReusedRegistersByPushing(jit, ScratchRegisterAllocator::ExtraStackSpace::NoExtraSpace);</span>
<span class="line-added">481 </span>
482     bool generatedFinalCode = false;
483 
484     // If the resulting set of cases is so big that we would stop caching and this is InstanceOf,
485     // then we want to generate the generic InstanceOf and then stop.
486     if (cases.size() &gt;= Options::maxAccessVariantListSize()
487         &amp;&amp; stubInfo.accessType == AccessType::InstanceOf) {
488         while (!cases.isEmpty())
489             m_list.append(cases.takeLast());
<span class="line-modified">490         cases.append(AccessCase::create(vm, codeBlock, AccessCase::InstanceOfGeneric, nullptr));</span>
491         generatedFinalCode = true;
492     }
493 
494     if (PolymorphicAccessInternal::verbose)
495         dataLog(&quot;Optimized cases: &quot;, listDump(cases), &quot;\n&quot;);
496 
497     // At this point we&#39;re convinced that &#39;cases&#39; contains the cases that we want to JIT now and we
498     // won&#39;t change that set anymore.
499 
500     bool allGuardedByStructureCheck = true;
501     bool hasJSGetterSetterCall = false;
<span class="line-added">502     bool needsInt32PropertyCheck = false;</span>
<span class="line-added">503     bool needsStringPropertyCheck = false;</span>
<span class="line-added">504     bool needsSymbolPropertyCheck = false;</span>
505     for (auto&amp; newCase : cases) {
<span class="line-modified">506         if (!stubInfo.hasConstantIdentifier) {</span>
<span class="line-modified">507             if (newCase-&gt;requiresIdentifierNameMatch()) {</span>
<span class="line-added">508                 if (newCase-&gt;uid()-&gt;isSymbol())</span>
<span class="line-added">509                     needsSymbolPropertyCheck = true;</span>
<span class="line-added">510                 else</span>
<span class="line-added">511                     needsStringPropertyCheck = true;</span>
<span class="line-added">512             } else if (newCase-&gt;requiresInt32PropertyCheck())</span>
<span class="line-added">513                 needsInt32PropertyCheck = true;</span>
<span class="line-added">514         }</span>
<span class="line-added">515         commit(locker, vm, state.watchpoints, codeBlock, stubInfo, *newCase);</span>
<span class="line-added">516         allGuardedByStructureCheck &amp;= newCase-&gt;guardedByStructureCheck(stubInfo);</span>
517         if (newCase-&gt;type() == AccessCase::Getter || newCase-&gt;type() == AccessCase::Setter)
518             hasJSGetterSetterCall = true;
519     }
520 
521     if (cases.isEmpty()) {
522         // This is super unlikely, but we make it legal anyway.
523         state.failAndRepatch.append(jit.jump());
524     } else if (!allGuardedByStructureCheck || cases.size() == 1) {
525         // If there are any proxies in the list, we cannot just use a binary switch over the structure.
526         // We need to resort to a cascade. A cascade also happens to be optimal if we only have just
527         // one case.
528         CCallHelpers::JumpList fallThrough;
<span class="line-added">529         if (needsInt32PropertyCheck || needsStringPropertyCheck || needsSymbolPropertyCheck) {</span>
<span class="line-added">530             if (needsInt32PropertyCheck) {</span>
<span class="line-added">531                 CCallHelpers::Jump notInt32;</span>
<span class="line-added">532 </span>
<span class="line-added">533                 if (!stubInfo.propertyIsInt32) {</span>
<span class="line-added">534 #if USE(JSVALUE64)</span>
<span class="line-added">535                     notInt32 = jit.branchIfNotInt32(state.u.propertyGPR);</span>
<span class="line-added">536 #else</span>
<span class="line-added">537                     notInt32 = jit.branchIfNotInt32(state.stubInfo-&gt;v.propertyTagGPR);</span>
<span class="line-added">538 #endif</span>
<span class="line-added">539                 }</span>
<span class="line-added">540                 for (unsigned i = cases.size(); i--;) {</span>
<span class="line-added">541                     fallThrough.link(&amp;jit);</span>
<span class="line-added">542                     fallThrough.clear();</span>
<span class="line-added">543                     if (cases[i]-&gt;requiresInt32PropertyCheck())</span>
<span class="line-added">544                         cases[i]-&gt;generateWithGuard(state, fallThrough);</span>
<span class="line-added">545                 }</span>
<span class="line-added">546 </span>
<span class="line-added">547                 if (needsStringPropertyCheck || needsSymbolPropertyCheck) {</span>
<span class="line-added">548                     if (notInt32.isSet())</span>
<span class="line-added">549                         notInt32.link(&amp;jit);</span>
<span class="line-added">550                     fallThrough.link(&amp;jit);</span>
<span class="line-added">551                     fallThrough.clear();</span>
<span class="line-added">552                 } else {</span>
<span class="line-added">553                     if (notInt32.isSet())</span>
<span class="line-added">554                         state.failAndRepatch.append(notInt32);</span>
<span class="line-added">555                 }</span>
<span class="line-added">556             }</span>
<span class="line-added">557 </span>
<span class="line-added">558             if (needsStringPropertyCheck) {</span>
<span class="line-added">559                 CCallHelpers::JumpList notString;</span>
<span class="line-added">560                 GPRReg propertyGPR = state.u.propertyGPR;</span>
<span class="line-added">561                 if (!stubInfo.propertyIsString) {</span>
<span class="line-added">562 #if USE(JSVALUE32_64)</span>
<span class="line-added">563                     GPRReg propertyTagGPR = state.stubInfo-&gt;v.propertyTagGPR;</span>
<span class="line-added">564                     notString.append(jit.branchIfNotCell(propertyTagGPR));</span>
<span class="line-added">565 #else</span>
<span class="line-added">566                     notString.append(jit.branchIfNotCell(propertyGPR));</span>
<span class="line-added">567 #endif</span>
<span class="line-added">568                     notString.append(jit.branchIfNotString(propertyGPR));</span>
<span class="line-added">569                 }</span>
<span class="line-added">570 </span>
<span class="line-added">571                 jit.loadPtr(MacroAssembler::Address(propertyGPR, JSString::offsetOfValue()), state.scratchGPR);</span>
<span class="line-added">572 </span>
<span class="line-added">573                 state.failAndRepatch.append(jit.branchIfRopeStringImpl(state.scratchGPR));</span>
<span class="line-added">574 </span>
<span class="line-added">575                 for (unsigned i = cases.size(); i--;) {</span>
<span class="line-added">576                     fallThrough.link(&amp;jit);</span>
<span class="line-added">577                     fallThrough.clear();</span>
<span class="line-added">578                     if (cases[i]-&gt;requiresIdentifierNameMatch() &amp;&amp; !cases[i]-&gt;uid()-&gt;isSymbol())</span>
<span class="line-added">579                         cases[i]-&gt;generateWithGuard(state, fallThrough);</span>
<span class="line-added">580                 }</span>
<span class="line-added">581 </span>
<span class="line-added">582                 if (needsSymbolPropertyCheck) {</span>
<span class="line-added">583                     notString.link(&amp;jit);</span>
<span class="line-added">584                     fallThrough.link(&amp;jit);</span>
<span class="line-added">585                     fallThrough.clear();</span>
<span class="line-added">586                 } else</span>
<span class="line-added">587                     state.failAndRepatch.append(notString);</span>
<span class="line-added">588             }</span>
<span class="line-added">589 </span>
<span class="line-added">590             if (needsSymbolPropertyCheck) {</span>
<span class="line-added">591                 CCallHelpers::JumpList notSymbol;</span>
<span class="line-added">592                 if (!stubInfo.propertyIsSymbol) {</span>
<span class="line-added">593                     GPRReg propertyGPR = state.u.propertyGPR;</span>
<span class="line-added">594 #if USE(JSVALUE32_64)</span>
<span class="line-added">595                     GPRReg propertyTagGPR = state.stubInfo-&gt;v.propertyTagGPR;</span>
<span class="line-added">596                     notSymbol.append(jit.branchIfNotCell(propertyTagGPR));</span>
<span class="line-added">597 #else</span>
<span class="line-added">598                     notSymbol.append(jit.branchIfNotCell(propertyGPR));</span>
<span class="line-added">599 #endif</span>
<span class="line-added">600                     notSymbol.append(jit.branchIfNotSymbol(propertyGPR));</span>
<span class="line-added">601                 }</span>
<span class="line-added">602 </span>
<span class="line-added">603                 for (unsigned i = cases.size(); i--;) {</span>
<span class="line-added">604                     fallThrough.link(&amp;jit);</span>
<span class="line-added">605                     fallThrough.clear();</span>
<span class="line-added">606                     if (cases[i]-&gt;requiresIdentifierNameMatch() &amp;&amp; cases[i]-&gt;uid()-&gt;isSymbol())</span>
<span class="line-added">607                         cases[i]-&gt;generateWithGuard(state, fallThrough);</span>
<span class="line-added">608                 }</span>
609 
<span class="line-modified">610                 state.failAndRepatch.append(notSymbol);</span>
<span class="line-modified">611             }</span>
<span class="line-modified">612         } else {</span>
<span class="line-modified">613             // Cascade through the list, preferring newer entries.</span>
<span class="line-modified">614             for (unsigned i = cases.size(); i--;) {</span>
<span class="line-added">615                 fallThrough.link(&amp;jit);</span>
<span class="line-added">616                 fallThrough.clear();</span>
<span class="line-added">617                 cases[i]-&gt;generateWithGuard(state, fallThrough);</span>
<span class="line-added">618             }</span>
619         }
<span class="line-added">620 </span>
621         state.failAndRepatch.append(fallThrough);
<span class="line-added">622 </span>
623     } else {
624         jit.load32(
625             CCallHelpers::Address(state.baseGPR, JSCell::structureIDOffset()),
626             state.scratchGPR);
627 
628         Vector&lt;int64_t&gt; caseValues(cases.size());
629         for (unsigned i = 0; i &lt; cases.size(); ++i)
630             caseValues[i] = bitwise_cast&lt;int32_t&gt;(cases[i]-&gt;structure()-&gt;id());
631 
632         BinarySwitch binarySwitch(state.scratchGPR, caseValues, BinarySwitch::Int32);
633         while (binarySwitch.advance(jit))
634             cases[binarySwitch.caseIndex()]-&gt;generate(state);
635         state.failAndRepatch.append(binarySwitch.fallThrough());
636     }
637 
638     if (!state.failAndIgnore.empty()) {
639         state.failAndIgnore.link(&amp;jit);
640 
641         // Make sure that the inline cache optimization code knows that we are taking slow path because
642         // of something that isn&#39;t patchable. The slow path will decrement &quot;countdown&quot; and will only
</pre>
<hr />
<pre>
692                 handlerToRegister.nativeCode = linkBuffer.locationOf&lt;ExceptionHandlerPtrTag&gt;(makeshiftCatchHandler);
693                 handlerToRegister.start = newExceptionHandlingCallSite.bits();
694                 handlerToRegister.end = newExceptionHandlingCallSite.bits() + 1;
695                 codeBlock-&gt;appendExceptionHandler(handlerToRegister);
696             });
697 
698         // We set these to indicate to the stub to remove itself from the CodeBlock&#39;s
699         // exception handler table when it is deallocated.
700         codeBlockThatOwnsExceptionHandlers = codeBlock;
701         ASSERT(JITCode::isOptimizingJIT(codeBlockThatOwnsExceptionHandlers-&gt;jitType()));
702         callSiteIndexForExceptionHandling = state.callSiteIndexForExceptionHandling();
703     }
704 
705     LinkBuffer linkBuffer(jit, codeBlock, JITCompilationCanFail);
706     if (linkBuffer.didFailToAllocate()) {
707         if (PolymorphicAccessInternal::verbose)
708             dataLog(&quot;Did fail to allocate.\n&quot;);
709         return AccessGenerationResult::GaveUp;
710     }
711 
<span class="line-modified">712     CodeLocationLabel&lt;JSInternalPtrTag&gt; successLabel = stubInfo.doneLocation;</span>
713 
714     linkBuffer.link(state.success, successLabel);
715 
<span class="line-modified">716     linkBuffer.link(failure, stubInfo.slowPathStartLocation);</span>
717 
718     if (PolymorphicAccessInternal::verbose)
719         dataLog(FullCodeOrigin(codeBlock, stubInfo.codeOrigin), &quot;: Generating polymorphic access stub for &quot;, listDump(cases), &quot;\n&quot;);
720 
721     MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; code = FINALIZE_CODE_FOR(
722         codeBlock, linkBuffer, JITStubRoutinePtrTag,
723         &quot;%s&quot;, toCString(&quot;Access stub for &quot;, *codeBlock, &quot; &quot;, stubInfo.codeOrigin, &quot; with return point &quot;, successLabel, &quot;: &quot;, listDump(cases)).data());
724 
725     bool doesCalls = false;
726     Vector&lt;JSCell*&gt; cellsToMark;
727     for (auto&amp; entry : cases)
<span class="line-modified">728         doesCalls |= entry-&gt;doesCalls(vm, &amp;cellsToMark);</span>
729 
<span class="line-modified">730     m_stubRoutine = createJITStubRoutine(code, vm, codeBlock, doesCalls, cellsToMark, WTFMove(state.m_callLinkInfos), codeBlockThatOwnsExceptionHandlers, callSiteIndexForExceptionHandling);</span>
731     m_watchpoints = WTFMove(state.watchpoints);
<span class="line-modified">732     if (!state.weakReferences.isEmpty()) {</span>
<span class="line-added">733         state.weakReferences.shrinkToFit();</span>
734         m_weakReferences = makeUnique&lt;Vector&lt;WriteBarrier&lt;JSCell&gt;&gt;&gt;(WTFMove(state.weakReferences));
<span class="line-added">735     }</span>
736     if (PolymorphicAccessInternal::verbose)
737         dataLog(&quot;Returning: &quot;, code.code(), &quot;\n&quot;);
738 
739     m_list = WTFMove(cases);
<span class="line-added">740     m_list.shrinkToFit();</span>
741 
742     AccessGenerationResult::Kind resultKind;
743     if (m_list.size() &gt;= Options::maxAccessVariantListSize() || generatedFinalCode)
744         resultKind = AccessGenerationResult::GeneratedFinalCode;
745     else
746         resultKind = AccessGenerationResult::GeneratedNewCode;
747 
748     return AccessGenerationResult(resultKind, code.code());
749 }
750 
751 void PolymorphicAccess::aboutToDie()
752 {
753     if (m_stubRoutine)
754         m_stubRoutine-&gt;aboutToDie();
755 }
756 
757 } // namespace JSC
758 
759 namespace WTF {
760 
</pre>
<hr />
<pre>
838         out.print(&quot;StringLength&quot;);
839         return;
840     case AccessCase::DirectArgumentsLength:
841         out.print(&quot;DirectArgumentsLength&quot;);
842         return;
843     case AccessCase::ScopedArgumentsLength:
844         out.print(&quot;ScopedArgumentsLength&quot;);
845         return;
846     case AccessCase::ModuleNamespaceLoad:
847         out.print(&quot;ModuleNamespaceLoad&quot;);
848         return;
849     case AccessCase::InstanceOfHit:
850         out.print(&quot;InstanceOfHit&quot;);
851         return;
852     case AccessCase::InstanceOfMiss:
853         out.print(&quot;InstanceOfMiss&quot;);
854         return;
855     case AccessCase::InstanceOfGeneric:
856         out.print(&quot;InstanceOfGeneric&quot;);
857         return;
<span class="line-added">858     case AccessCase::IndexedInt32Load:</span>
<span class="line-added">859         out.print(&quot;IndexedInt32Load&quot;);</span>
<span class="line-added">860         return;</span>
<span class="line-added">861     case AccessCase::IndexedDoubleLoad:</span>
<span class="line-added">862         out.print(&quot;IndexedDoubleLoad&quot;);</span>
<span class="line-added">863         return;</span>
<span class="line-added">864     case AccessCase::IndexedContiguousLoad:</span>
<span class="line-added">865         out.print(&quot;IndexedContiguousLoad&quot;);</span>
<span class="line-added">866         return;</span>
<span class="line-added">867     case AccessCase::IndexedArrayStorageLoad:</span>
<span class="line-added">868         out.print(&quot;IndexedArrayStorageLoad&quot;);</span>
<span class="line-added">869         return;</span>
<span class="line-added">870     case AccessCase::IndexedScopedArgumentsLoad:</span>
<span class="line-added">871         out.print(&quot;IndexedScopedArgumentsLoad&quot;);</span>
<span class="line-added">872         return;</span>
<span class="line-added">873     case AccessCase::IndexedDirectArgumentsLoad:</span>
<span class="line-added">874         out.print(&quot;IndexedDirectArgumentsLoad&quot;);</span>
<span class="line-added">875         return;</span>
<span class="line-added">876     case AccessCase::IndexedTypedArrayInt8Load:</span>
<span class="line-added">877         out.print(&quot;IndexedTypedArrayInt8Load&quot;);</span>
<span class="line-added">878         return;</span>
<span class="line-added">879     case AccessCase::IndexedTypedArrayUint8Load:</span>
<span class="line-added">880         out.print(&quot;IndexedTypedArrayUint8Load&quot;);</span>
<span class="line-added">881         return;</span>
<span class="line-added">882     case AccessCase::IndexedTypedArrayUint8ClampedLoad:</span>
<span class="line-added">883         out.print(&quot;IndexedTypedArrayUint8ClampedLoad&quot;);</span>
<span class="line-added">884         return;</span>
<span class="line-added">885     case AccessCase::IndexedTypedArrayInt16Load:</span>
<span class="line-added">886         out.print(&quot;IndexedTypedArrayInt16Load&quot;);</span>
<span class="line-added">887         return;</span>
<span class="line-added">888     case AccessCase::IndexedTypedArrayUint16Load:</span>
<span class="line-added">889         out.print(&quot;IndexedTypedArrayUint16Load&quot;);</span>
<span class="line-added">890         return;</span>
<span class="line-added">891     case AccessCase::IndexedTypedArrayInt32Load:</span>
<span class="line-added">892         out.print(&quot;IndexedTypedArrayInt32Load&quot;);</span>
<span class="line-added">893         return;</span>
<span class="line-added">894     case AccessCase::IndexedTypedArrayUint32Load:</span>
<span class="line-added">895         out.print(&quot;IndexedTypedArrayUint32Load&quot;);</span>
<span class="line-added">896         return;</span>
<span class="line-added">897     case AccessCase::IndexedTypedArrayFloat32Load:</span>
<span class="line-added">898         out.print(&quot;IndexedTypedArrayFloat32Load&quot;);</span>
<span class="line-added">899         return;</span>
<span class="line-added">900     case AccessCase::IndexedTypedArrayFloat64Load:</span>
<span class="line-added">901         out.print(&quot;IndexedTypedArrayFloat64Load&quot;);</span>
<span class="line-added">902         return;</span>
<span class="line-added">903     case AccessCase::IndexedStringLoad:</span>
<span class="line-added">904         out.print(&quot;IndexedStringLoad&quot;);</span>
<span class="line-added">905         return;</span>
906     }
907 
908     RELEASE_ASSERT_NOT_REACHED();
909 }
910 
911 void printInternal(PrintStream&amp; out, AccessCase::State state)
912 {
913     switch (state) {
914     case AccessCase::Primordial:
915         out.print(&quot;Primordial&quot;);
916         return;
917     case AccessCase::Committed:
918         out.print(&quot;Committed&quot;);
919         return;
920     case AccessCase::Generated:
921         out.print(&quot;Generated&quot;);
922         return;
923     }
924 
925     RELEASE_ASSERT_NOT_REACHED();
</pre>
</td>
</tr>
</table>
<center><a href="PolyProtoAccessChain.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="PolymorphicAccess.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>