<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoEncoderFactory.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="GStreamerVideoDecoderFactory.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../index.html" target="_top">index</a> <a href="LibWebRTCAudioModule.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoEncoderFactory.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 56 #define GST_CAT_DEFAULT webkit_webrtcenc_debug
 57 
 58 #define KBIT_TO_BIT 1024
 59 
 60 namespace WebCore {
 61 
 62 class GStreamerVideoEncoder : public webrtc::VideoEncoder {
 63     WTF_MAKE_FAST_ALLOCATED;
 64 public:
 65     GStreamerVideoEncoder(const webrtc::SdpVideoFormat&amp;)
 66         : m_firstFramePts(GST_CLOCK_TIME_NONE)
 67         , m_restrictionCaps(adoptGRef(gst_caps_new_empty_simple(&quot;video/x-raw&quot;)))
 68     {
 69     }
 70     GStreamerVideoEncoder()
 71         : m_firstFramePts(GST_CLOCK_TIME_NONE)
 72         , m_restrictionCaps(adoptGRef(gst_caps_new_empty_simple(&quot;video/x-raw&quot;)))
 73     {
 74     }
 75 
<span class="line-modified"> 76     int SetRates(uint32_t newBitrate, uint32_t frameRate) override</span>
 77     {
<span class="line-modified"> 78         GST_INFO_OBJECT(m_pipeline.get(), &quot;New bitrate: %d - framerate is %d&quot;,</span>
<span class="line-modified"> 79             newBitrate, frameRate);</span>
 80 
 81         auto caps = adoptGRef(gst_caps_copy(m_restrictionCaps.get()));
 82 
 83         SetRestrictionCaps(WTFMove(caps));
 84 
 85         if (m_encoder)
<span class="line-modified"> 86             g_object_set(m_encoder, &quot;bitrate&quot;, newBitrate, nullptr);</span>
<span class="line-removed"> 87 </span>
<span class="line-removed"> 88         return WEBRTC_VIDEO_CODEC_OK;</span>
 89     }
 90 
 91     GstElement* pipeline()
 92     {
 93         return m_pipeline.get();
 94     }
 95 
 96     GstElement* makeElement(const gchar* factoryName)
 97     {
 98         static Atomic&lt;uint32_t&gt; elementId;
 99         auto name = makeString(Name(), &quot;-enc-&quot;, factoryName, &quot;-&quot;, elementId.exchangeAdd(1));
100         auto elem = gst_element_factory_make(factoryName, name.utf8().data());
101 
102         return elem;
103     }
104 
105     int32_t InitEncode(const webrtc::VideoCodec* codecSettings, int32_t, size_t)
106     {
107         g_return_val_if_fail(codecSettings, WEBRTC_VIDEO_CODEC_ERR_PARAMETER);
108         g_return_val_if_fail(codecSettings-&gt;codecType == CodecType(), WEBRTC_VIDEO_CODEC_ERR_PARAMETER);
109 
110         if (webrtc::SimulcastUtility::NumberOfSimulcastStreams(*codecSettings) &gt; 1) {
111             GST_ERROR(&quot;Simulcast not supported.&quot;);
112 
113             return WEBRTC_VIDEO_CODEC_ERR_SIMULCAST_PARAMETERS_NOT_SUPPORTED;
114         }
115 
<span class="line-modified">116         m_encodedFrame._size = codecSettings-&gt;width * codecSettings-&gt;height * 3;</span>
<span class="line-modified">117         m_encodedFrame._buffer = new uint8_t[m_encodedFrame._size];</span>
<span class="line-modified">118         m_encodedImageBuffer.reset(m_encodedFrame._buffer);</span>
119         m_encodedFrame._completeFrame = true;
120         m_encodedFrame._encodedWidth = 0;
121         m_encodedFrame._encodedHeight = 0;
<span class="line-removed">122         m_encodedFrame._length = 0;</span>
123 
124         m_pipeline = makeElement(&quot;pipeline&quot;);
125 
126         connectSimpleBusMessageCallback(m_pipeline.get());
127         auto encoder = createEncoder();
128         ASSERT(encoder);
129         m_encoder = encoder.get();
130 
131         g_object_set(m_encoder, &quot;keyframe-interval&quot;, KeyframeInterval(codecSettings), nullptr);
132 
133         m_src = makeElement(&quot;appsrc&quot;);
134         g_object_set(m_src, &quot;is-live&quot;, true, &quot;format&quot;, GST_FORMAT_TIME, nullptr);
135 
136         auto videoconvert = makeElement(&quot;videoconvert&quot;);
137         m_sink = makeElement(&quot;appsink&quot;);
138         g_object_set(m_sink, &quot;sync&quot;, FALSE, nullptr);
139 
140         m_capsFilter = makeElement(&quot;capsfilter&quot;);
141         if (m_restrictionCaps)
142             g_object_set(m_capsFilter, &quot;caps&quot;, m_restrictionCaps.get(), nullptr);
143 
144         gst_bin_add_many(GST_BIN(m_pipeline.get()), m_src, videoconvert, m_capsFilter, encoder.leakRef(), m_sink, nullptr);
145         if (!gst_element_link_many(m_src, videoconvert, m_capsFilter, m_encoder, m_sink, nullptr)) {
146             GST_DEBUG_BIN_TO_DOT_FILE_WITH_TS(GST_BIN(m_pipeline.get()), GST_DEBUG_GRAPH_SHOW_VERBOSE, &quot;webkit-webrtc-encoder.error&quot;);
147 
148             ASSERT_NOT_REACHED();
149         }
150 
151         gst_element_set_state(m_pipeline.get(), GST_STATE_PLAYING);
152 
153         return WEBRTC_VIDEO_CODEC_OK;
154     }
155 
<span class="line-removed">156     bool SupportsNativeHandle() const final</span>
<span class="line-removed">157     {</span>
<span class="line-removed">158         return true;</span>
<span class="line-removed">159     }</span>
<span class="line-removed">160 </span>
161     int32_t RegisterEncodeCompleteCallback(webrtc::EncodedImageCallback* callback) final
162     {
163         m_imageReadyCb = callback;
164 
165         return WEBRTC_VIDEO_CODEC_OK;
166     }
167 
168     int32_t Release() final
169     {
<span class="line-modified">170         m_encodedFrame._buffer = nullptr;</span>
171         m_encodedImageBuffer.reset();
172         if (m_pipeline) {
173             GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
174             gst_bus_set_sync_handler(bus.get(), nullptr, nullptr, nullptr);
175 
176             gst_element_set_state(m_pipeline.get(), GST_STATE_NULL);
177             m_src = nullptr;
178             m_encoder = nullptr;
179             m_capsFilter = nullptr;
180             m_sink = nullptr;
181             m_pipeline = nullptr;
182         }
183 
184         return WEBRTC_VIDEO_CODEC_OK;
185     }
186 
187     int32_t returnFromFlowReturn(GstFlowReturn flow)
188     {
189         switch (flow) {
190         case GST_FLOW_OK:
191             return WEBRTC_VIDEO_CODEC_OK;
192         case GST_FLOW_FLUSHING:
193             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
194         default:
195             return WEBRTC_VIDEO_CODEC_ERROR;
196         }
197     }
198 










199     int32_t Encode(const webrtc::VideoFrame&amp; frame,
<span class="line-modified">200         const webrtc::CodecSpecificInfo*,</span>
<span class="line-removed">201         const std::vector&lt;webrtc::FrameType&gt;* frameTypes) final</span>
202     {
203         int32_t res;
204 
205         if (!m_imageReadyCb) {
206             GST_INFO_OBJECT(m_pipeline.get(), &quot;No encoded callback set yet!&quot;);
207 
208             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
209         }
210 
211         if (!m_src) {
212             GST_INFO_OBJECT(m_pipeline.get(), &quot;No source set yet!&quot;);
213 
214             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
215         }
216 
217         auto sample = GStreamerSampleFromLibWebRTCVideoFrame(frame);
218         auto buffer = gst_sample_get_buffer(sample.get());
219 
220         if (!GST_CLOCK_TIME_IS_VALID(m_firstFramePts)) {
221             m_firstFramePts = GST_BUFFER_PTS(buffer);
222             auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
223             gst_pad_set_offset(pad.get(), -m_firstFramePts);
224         }
225 
226         for (auto frame_type : *frameTypes) {
<span class="line-modified">227             if (frame_type == webrtc::kVideoFrameKey) {</span>
228                 auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
229                 auto forceKeyUnit = gst_video_event_new_downstream_force_key_unit(GST_CLOCK_TIME_NONE,
230                     GST_CLOCK_TIME_NONE, GST_CLOCK_TIME_NONE, FALSE, 1);
231                 GST_INFO_OBJECT(m_pipeline.get(), &quot;Requesting KEYFRAME!&quot;);
232 
233                 if (!gst_pad_push_event(pad.get(), forceKeyUnit))
234                     GST_WARNING_OBJECT(pipeline(), &quot;Could not send ForceKeyUnit event&quot;);
235 
236                 break;
237             }
238         }
239 
240         res = returnFromFlowReturn(gst_app_src_push_sample(GST_APP_SRC(m_src), sample.get()));
241         if (res != WEBRTC_VIDEO_CODEC_OK)
242             return res;
243 
244         auto encodedSample = adoptGRef(gst_app_sink_try_pull_sample(GST_APP_SINK(m_sink), 5 * GST_SECOND));
245         if (!encodedSample) {
246             GST_ERROR(&quot;Didn&#39;t get any encodedSample&quot;);
247             return WEBRTC_VIDEO_CODEC_ERROR;
248         }
249 
250         auto encodedBuffer = gst_sample_get_buffer(encodedSample.get());
251         auto encodedCaps = gst_sample_get_caps(encodedSample.get());
252 
253         webrtc::RTPFragmentationHeader fragmentationInfo;
254 
255         Fragmentize(&amp;m_encodedFrame, &amp;m_encodedImageBuffer, &amp;m_encodedImageBufferSize, encodedBuffer, &amp;fragmentationInfo);
<span class="line-modified">256         if (!m_encodedFrame._size)</span>
257             return WEBRTC_VIDEO_CODEC_OK;
258 
259         gst_structure_get(gst_caps_get_structure(encodedCaps, 0),
260             &quot;width&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedWidth,
261             &quot;height&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedHeight,
262             nullptr);
263 
<span class="line-modified">264         m_encodedFrame._frameType = GST_BUFFER_FLAG_IS_SET(encodedBuffer, GST_BUFFER_FLAG_DELTA_UNIT) ? webrtc::kVideoFrameDelta : webrtc::kVideoFrameKey;</span>
265         m_encodedFrame._completeFrame = true;
266         m_encodedFrame.capture_time_ms_ = frame.render_time_ms();
267         m_encodedFrame.SetTimestamp(frame.timestamp());
268 
269         GST_LOG_OBJECT(m_pipeline.get(), &quot;Got buffer capture_time_ms: %&quot; G_GINT64_FORMAT  &quot; _timestamp: %u&quot;,
270             m_encodedFrame.capture_time_ms_, m_encodedFrame.Timestamp());
271 
272         webrtc::CodecSpecificInfo codecInfo;
273         PopulateCodecSpecific(&amp;codecInfo, encodedBuffer);
274         webrtc::EncodedImageCallback::Result result = m_imageReadyCb-&gt;OnEncodedImage(m_encodedFrame, &amp;codecInfo, &amp;fragmentationInfo);
275         if (result.error != webrtc::EncodedImageCallback::Result::OK)
276             GST_ERROR_OBJECT(m_pipeline.get(), &quot;Encode callback failed: %d&quot;, result.error);
277 
278         return WEBRTC_VIDEO_CODEC_OK;
279     }
280 
281     GRefPtr&lt;GstElement&gt; createEncoder(void)
282     {
283         GRefPtr&lt;GstElement&gt; encoder = nullptr;
284         GstElement* webrtcencoder = GST_ELEMENT(g_object_ref_sink(gst_element_factory_make(&quot;webrtcvideoencoder&quot;, NULL)));
</pre>
<hr />
<pre>
308 
309     virtual const gchar* Caps()
310     {
311         return nullptr;
312     }
313 
314     virtual webrtc::VideoCodecType CodecType() = 0;
315     virtual webrtc::SdpVideoFormat ConfigureSupportedCodec(GstElement*)
316     {
317         return webrtc::SdpVideoFormat(Name());
318     }
319 
320     virtual void PopulateCodecSpecific(webrtc::CodecSpecificInfo*, GstBuffer*) = 0;
321 
322     virtual void Fragmentize(webrtc::EncodedImage* encodedImage, std::unique_ptr&lt;uint8_t[]&gt;* encodedImageBuffer,
323         size_t* bufferSize, GstBuffer* buffer, webrtc::RTPFragmentationHeader* fragmentationInfo)
324     {
325         auto map = GstMappedBuffer::create(buffer, GST_MAP_READ);
326 
327         if (*bufferSize &lt; map-&gt;size()) {
<span class="line-modified">328             encodedImage-&gt;_size = map-&gt;size();</span>
<span class="line-modified">329             encodedImage-&gt;_buffer = new uint8_t[encodedImage-&gt;_size];</span>
<span class="line-modified">330             encodedImageBuffer-&gt;reset(encodedImage-&gt;_buffer);</span>
331             *bufferSize = map-&gt;size();
332         }
333 
<span class="line-modified">334         memcpy(encodedImage-&gt;_buffer, map-&gt;data(), map-&gt;size());</span>
<span class="line-modified">335         encodedImage-&gt;_length = map-&gt;size();</span>
<span class="line-removed">336         encodedImage-&gt;_size = map-&gt;size();</span>
337 
338         fragmentationInfo-&gt;VerifyAndAllocateFragmentationHeader(1);
339         fragmentationInfo-&gt;fragmentationOffset[0] = 0;
340         fragmentationInfo-&gt;fragmentationLength[0] = map-&gt;size();
<span class="line-removed">341         fragmentationInfo-&gt;fragmentationPlType[0] = 0;</span>
<span class="line-removed">342         fragmentationInfo-&gt;fragmentationTimeDiff[0] = 0;</span>
<span class="line-removed">343     }</span>
<span class="line-removed">344 </span>
<span class="line-removed">345     const char* ImplementationName() const</span>
<span class="line-removed">346     {</span>
<span class="line-removed">347         GRefPtr&lt;GstElement&gt; encoderImplementation;</span>
<span class="line-removed">348         g_return_val_if_fail(m_encoder, nullptr);</span>
<span class="line-removed">349 </span>
<span class="line-removed">350         g_object_get(m_encoder, &quot;encoder&quot;, &amp;encoderImplementation.outPtr(), nullptr);</span>
<span class="line-removed">351 </span>
<span class="line-removed">352         return GST_OBJECT_NAME(gst_element_get_factory(encoderImplementation.get()));</span>
353     }
354 
355     virtual const gchar* Name() = 0;
356     virtual int KeyframeInterval(const webrtc::VideoCodec* codecSettings) = 0;
357 
358     void SetRestrictionCaps(GRefPtr&lt;GstCaps&gt; caps)
359     {
360         if (m_restrictionCaps)
361             g_object_set(m_capsFilter, &quot;caps&quot;, m_restrictionCaps.get(), nullptr);
362 
363         m_restrictionCaps = caps;
364     }
365 
366 private:
367     GRefPtr&lt;GstElement&gt; m_pipeline;
368     GstElement* m_src;
369     GstElement* m_encoder;
370     GstElement* m_capsFilter;
371 
372     webrtc::EncodedImageCallback* m_imageReadyCb;
</pre>
<hr />
<pre>
409         gsize offset = 0;
410         size_t requiredSize = 0;
411 
412         std::vector&lt;GstH264NalUnit&gt; nals;
413 
414         const uint8_t startCode[4] = { 0, 0, 0, 1 };
415         auto map = GstMappedBuffer::create(gstbuffer, GST_MAP_READ);
416         while (parserResult == GST_H264_PARSER_OK) {
417             parserResult = gst_h264_parser_identify_nalu(m_parser, map-&gt;data(), offset, map-&gt;size(), &amp;nalu);
418 
419             nalu.sc_offset = offset;
420             nalu.offset = offset + sizeof(startCode);
421             if (parserResult != GST_H264_PARSER_OK &amp;&amp; parserResult != GST_H264_PARSER_NO_NAL_END)
422                 break;
423 
424             requiredSize += nalu.size + sizeof(startCode);
425             nals.push_back(nalu);
426             offset = nalu.offset + nalu.size;
427         }
428 
<span class="line-modified">429         if (encodedImage-&gt;_size &lt; requiredSize) {</span>
<span class="line-modified">430             encodedImage-&gt;_size = requiredSize;</span>
<span class="line-modified">431             encodedImage-&gt;_buffer = new uint8_t[encodedImage-&gt;_size];</span>
<span class="line-modified">432             encodedImageBuffer-&gt;reset(encodedImage-&gt;_buffer);</span>
433             *bufferSize = map-&gt;size();
434         }
435 
436         // Iterate nal units and fill the Fragmentation info.
437         fragmentationHeader-&gt;VerifyAndAllocateFragmentationHeader(nals.size());
438         size_t fragmentIndex = 0;
<span class="line-modified">439         encodedImage-&gt;_length = 0;</span>
440         for (std::vector&lt;GstH264NalUnit&gt;::iterator nal = nals.begin(); nal != nals.end(); ++nal, fragmentIndex++) {
441 
442             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 0] == startCode[0]);
443             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 1] == startCode[1]);
444             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 2] == startCode[2]);
445             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 3] == startCode[3]);
446 
447             fragmentationHeader-&gt;fragmentationOffset[fragmentIndex] = nal-&gt;offset;
448             fragmentationHeader-&gt;fragmentationLength[fragmentIndex] = nal-&gt;size;
449 
<span class="line-modified">450             memcpy(encodedImage-&gt;_buffer + encodedImage-&gt;_length, &amp;map-&gt;data()[nal-&gt;sc_offset],</span>
451                 sizeof(startCode) + nal-&gt;size);
<span class="line-modified">452             encodedImage-&gt;_length += nal-&gt;size + sizeof(startCode);</span>
453         }
454     }
455 
456     webrtc::SdpVideoFormat ConfigureSupportedCodec(GstElement*) final
457     {
458         // TODO- Create from encoder src pad caps template
459         return webrtc::SdpVideoFormat(cricket::kH264CodecName,
460             { { cricket::kH264FmtpProfileLevelId, cricket::kH264ProfileLevelConstrainedBaseline },
461                 { cricket::kH264FmtpLevelAsymmetryAllowed, &quot;1&quot; },
462                 { cricket::kH264FmtpPacketizationMode, &quot;1&quot; } });
463     }
464 
465     const gchar* Caps() final { return &quot;video/x-h264&quot;; }
466     const gchar* Name() final { return cricket::kH264CodecName; }
467     GstH264NalParser* m_parser;
468     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecH264; }
469 
470     void PopulateCodecSpecific(webrtc::CodecSpecificInfo* codecSpecificInfos, GstBuffer*) final
471     {
472         codecSpecificInfos-&gt;codecType = CodecType();
<span class="line-removed">473         codecSpecificInfos-&gt;codec_name = ImplementationName();</span>
474         webrtc::CodecSpecificInfoH264* h264Info = &amp;(codecSpecificInfos-&gt;codecSpecific.H264);
475         h264Info-&gt;packetization_mode = packetizationMode;
476     }
477 
478     webrtc::H264PacketizationMode packetizationMode;
479 };
480 
481 class GStreamerVP8Encoder : public GStreamerVideoEncoder {
482 public:
483     GStreamerVP8Encoder() { }
484     GStreamerVP8Encoder(const webrtc::SdpVideoFormat&amp;) { }
485     const gchar* Caps() final { return &quot;video/x-vp8&quot;; }
486     const gchar* Name() final { return cricket::kVp8CodecName; }
487     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecVP8; }
488 
489     int KeyframeInterval(const webrtc::VideoCodec* codecSettings) final
490     {
491         return codecSettings-&gt;VP8().keyFrameInterval;
492     }
493 
494     void PopulateCodecSpecific(webrtc::CodecSpecificInfo* codecSpecificInfos, GstBuffer* buffer) final
495     {
496         codecSpecificInfos-&gt;codecType = webrtc::kVideoCodecVP8;
<span class="line-removed">497         codecSpecificInfos-&gt;codec_name = ImplementationName();</span>
498         webrtc::CodecSpecificInfoVP8* vp8Info = &amp;(codecSpecificInfos-&gt;codecSpecific.VP8);
499         vp8Info-&gt;temporalIdx = 0;
500 
501         vp8Info-&gt;keyIdx = webrtc::kNoKeyIdx;
502         vp8Info-&gt;nonReference = GST_BUFFER_FLAG_IS_SET(buffer, GST_BUFFER_FLAG_DELTA_UNIT);
503     }
504 };
505 
506 std::unique_ptr&lt;webrtc::VideoEncoder&gt; GStreamerVideoEncoderFactory::CreateVideoEncoder(const webrtc::SdpVideoFormat&amp; format)
507 {
508     if (format.name == cricket::kVp8CodecName) {
509         GRefPtr&lt;GstElement&gt; webrtcencoder = adoptGRef(GST_ELEMENT(g_object_ref_sink(gst_element_factory_make(&quot;webrtcvideoencoder&quot;, NULL))));
510         GRefPtr&lt;GstElement&gt; encoder = nullptr;
511 
512         g_object_set(webrtcencoder.get(), &quot;format&quot;, adoptGRef(gst_caps_from_string(&quot;video/x-vp8&quot;)).get(), NULL);
513         g_object_get(webrtcencoder.get(), &quot;encoder&quot;, &amp;encoder.outPtr(), NULL);
514 
515         if (encoder)
516             return makeUnique&lt;GStreamerVP8Encoder&gt;(format);
517 
</pre>
</td>
<td>
<hr />
<pre>
 56 #define GST_CAT_DEFAULT webkit_webrtcenc_debug
 57 
 58 #define KBIT_TO_BIT 1024
 59 
 60 namespace WebCore {
 61 
 62 class GStreamerVideoEncoder : public webrtc::VideoEncoder {
 63     WTF_MAKE_FAST_ALLOCATED;
 64 public:
 65     GStreamerVideoEncoder(const webrtc::SdpVideoFormat&amp;)
 66         : m_firstFramePts(GST_CLOCK_TIME_NONE)
 67         , m_restrictionCaps(adoptGRef(gst_caps_new_empty_simple(&quot;video/x-raw&quot;)))
 68     {
 69     }
 70     GStreamerVideoEncoder()
 71         : m_firstFramePts(GST_CLOCK_TIME_NONE)
 72         , m_restrictionCaps(adoptGRef(gst_caps_new_empty_simple(&quot;video/x-raw&quot;)))
 73     {
 74     }
 75 
<span class="line-modified"> 76     void SetRates(const webrtc::VideoEncoder::RateControlParameters&amp; parameters) override</span>
 77     {
<span class="line-modified"> 78         GST_INFO_OBJECT(m_pipeline.get(), &quot;New bitrate: %d - framerate is %f&quot;,</span>
<span class="line-modified"> 79             parameters.bitrate.get_sum_bps(), parameters.framerate_fps);</span>
 80 
 81         auto caps = adoptGRef(gst_caps_copy(m_restrictionCaps.get()));
 82 
 83         SetRestrictionCaps(WTFMove(caps));
 84 
 85         if (m_encoder)
<span class="line-modified"> 86             g_object_set(m_encoder, &quot;bitrate&quot;, parameters.bitrate.get_sum_bps(), nullptr);</span>


 87     }
 88 
 89     GstElement* pipeline()
 90     {
 91         return m_pipeline.get();
 92     }
 93 
 94     GstElement* makeElement(const gchar* factoryName)
 95     {
 96         static Atomic&lt;uint32_t&gt; elementId;
 97         auto name = makeString(Name(), &quot;-enc-&quot;, factoryName, &quot;-&quot;, elementId.exchangeAdd(1));
 98         auto elem = gst_element_factory_make(factoryName, name.utf8().data());
 99 
100         return elem;
101     }
102 
103     int32_t InitEncode(const webrtc::VideoCodec* codecSettings, int32_t, size_t)
104     {
105         g_return_val_if_fail(codecSettings, WEBRTC_VIDEO_CODEC_ERR_PARAMETER);
106         g_return_val_if_fail(codecSettings-&gt;codecType == CodecType(), WEBRTC_VIDEO_CODEC_ERR_PARAMETER);
107 
108         if (webrtc::SimulcastUtility::NumberOfSimulcastStreams(*codecSettings) &gt; 1) {
109             GST_ERROR(&quot;Simulcast not supported.&quot;);
110 
111             return WEBRTC_VIDEO_CODEC_ERR_SIMULCAST_PARAMETERS_NOT_SUPPORTED;
112         }
113 
<span class="line-modified">114         auto size = codecSettings-&gt;width * codecSettings-&gt;height * 3;</span>
<span class="line-modified">115         m_encodedFrame.set_buffer(new uint8_t[size], size);</span>
<span class="line-modified">116         m_encodedImageBuffer.reset(m_encodedFrame.data());</span>
117         m_encodedFrame._completeFrame = true;
118         m_encodedFrame._encodedWidth = 0;
119         m_encodedFrame._encodedHeight = 0;

120 
121         m_pipeline = makeElement(&quot;pipeline&quot;);
122 
123         connectSimpleBusMessageCallback(m_pipeline.get());
124         auto encoder = createEncoder();
125         ASSERT(encoder);
126         m_encoder = encoder.get();
127 
128         g_object_set(m_encoder, &quot;keyframe-interval&quot;, KeyframeInterval(codecSettings), nullptr);
129 
130         m_src = makeElement(&quot;appsrc&quot;);
131         g_object_set(m_src, &quot;is-live&quot;, true, &quot;format&quot;, GST_FORMAT_TIME, nullptr);
132 
133         auto videoconvert = makeElement(&quot;videoconvert&quot;);
134         m_sink = makeElement(&quot;appsink&quot;);
135         g_object_set(m_sink, &quot;sync&quot;, FALSE, nullptr);
136 
137         m_capsFilter = makeElement(&quot;capsfilter&quot;);
138         if (m_restrictionCaps)
139             g_object_set(m_capsFilter, &quot;caps&quot;, m_restrictionCaps.get(), nullptr);
140 
141         gst_bin_add_many(GST_BIN(m_pipeline.get()), m_src, videoconvert, m_capsFilter, encoder.leakRef(), m_sink, nullptr);
142         if (!gst_element_link_many(m_src, videoconvert, m_capsFilter, m_encoder, m_sink, nullptr)) {
143             GST_DEBUG_BIN_TO_DOT_FILE_WITH_TS(GST_BIN(m_pipeline.get()), GST_DEBUG_GRAPH_SHOW_VERBOSE, &quot;webkit-webrtc-encoder.error&quot;);
144 
145             ASSERT_NOT_REACHED();
146         }
147 
148         gst_element_set_state(m_pipeline.get(), GST_STATE_PLAYING);
149 
150         return WEBRTC_VIDEO_CODEC_OK;
151     }
152 





153     int32_t RegisterEncodeCompleteCallback(webrtc::EncodedImageCallback* callback) final
154     {
155         m_imageReadyCb = callback;
156 
157         return WEBRTC_VIDEO_CODEC_OK;
158     }
159 
160     int32_t Release() final
161     {
<span class="line-modified">162         m_encodedFrame.set_buffer(nullptr, 0);</span>
163         m_encodedImageBuffer.reset();
164         if (m_pipeline) {
165             GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
166             gst_bus_set_sync_handler(bus.get(), nullptr, nullptr, nullptr);
167 
168             gst_element_set_state(m_pipeline.get(), GST_STATE_NULL);
169             m_src = nullptr;
170             m_encoder = nullptr;
171             m_capsFilter = nullptr;
172             m_sink = nullptr;
173             m_pipeline = nullptr;
174         }
175 
176         return WEBRTC_VIDEO_CODEC_OK;
177     }
178 
179     int32_t returnFromFlowReturn(GstFlowReturn flow)
180     {
181         switch (flow) {
182         case GST_FLOW_OK:
183             return WEBRTC_VIDEO_CODEC_OK;
184         case GST_FLOW_FLUSHING:
185             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
186         default:
187             return WEBRTC_VIDEO_CODEC_ERROR;
188         }
189     }
190 
<span class="line-added">191     VideoEncoder::EncoderInfo GetEncoderInfo() const {</span>
<span class="line-added">192         EncoderInfo info;</span>
<span class="line-added">193         info.supports_native_handle = false;</span>
<span class="line-added">194         info.implementation_name = &quot;GStreamer&quot;;</span>
<span class="line-added">195         info.has_trusted_rate_controller = true;</span>
<span class="line-added">196         info.is_hardware_accelerated = true;</span>
<span class="line-added">197         info.has_internal_source = false;</span>
<span class="line-added">198         return info;</span>
<span class="line-added">199     }</span>
<span class="line-added">200 </span>
201     int32_t Encode(const webrtc::VideoFrame&amp; frame,
<span class="line-modified">202         const std::vector&lt;webrtc::VideoFrameType&gt;* frameTypes) final</span>

203     {
204         int32_t res;
205 
206         if (!m_imageReadyCb) {
207             GST_INFO_OBJECT(m_pipeline.get(), &quot;No encoded callback set yet!&quot;);
208 
209             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
210         }
211 
212         if (!m_src) {
213             GST_INFO_OBJECT(m_pipeline.get(), &quot;No source set yet!&quot;);
214 
215             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
216         }
217 
218         auto sample = GStreamerSampleFromLibWebRTCVideoFrame(frame);
219         auto buffer = gst_sample_get_buffer(sample.get());
220 
221         if (!GST_CLOCK_TIME_IS_VALID(m_firstFramePts)) {
222             m_firstFramePts = GST_BUFFER_PTS(buffer);
223             auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
224             gst_pad_set_offset(pad.get(), -m_firstFramePts);
225         }
226 
227         for (auto frame_type : *frameTypes) {
<span class="line-modified">228             if (frame_type == webrtc::VideoFrameType::kVideoFrameKey) {</span>
229                 auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
230                 auto forceKeyUnit = gst_video_event_new_downstream_force_key_unit(GST_CLOCK_TIME_NONE,
231                     GST_CLOCK_TIME_NONE, GST_CLOCK_TIME_NONE, FALSE, 1);
232                 GST_INFO_OBJECT(m_pipeline.get(), &quot;Requesting KEYFRAME!&quot;);
233 
234                 if (!gst_pad_push_event(pad.get(), forceKeyUnit))
235                     GST_WARNING_OBJECT(pipeline(), &quot;Could not send ForceKeyUnit event&quot;);
236 
237                 break;
238             }
239         }
240 
241         res = returnFromFlowReturn(gst_app_src_push_sample(GST_APP_SRC(m_src), sample.get()));
242         if (res != WEBRTC_VIDEO_CODEC_OK)
243             return res;
244 
245         auto encodedSample = adoptGRef(gst_app_sink_try_pull_sample(GST_APP_SINK(m_sink), 5 * GST_SECOND));
246         if (!encodedSample) {
247             GST_ERROR(&quot;Didn&#39;t get any encodedSample&quot;);
248             return WEBRTC_VIDEO_CODEC_ERROR;
249         }
250 
251         auto encodedBuffer = gst_sample_get_buffer(encodedSample.get());
252         auto encodedCaps = gst_sample_get_caps(encodedSample.get());
253 
254         webrtc::RTPFragmentationHeader fragmentationInfo;
255 
256         Fragmentize(&amp;m_encodedFrame, &amp;m_encodedImageBuffer, &amp;m_encodedImageBufferSize, encodedBuffer, &amp;fragmentationInfo);
<span class="line-modified">257         if (!m_encodedFrame.size())</span>
258             return WEBRTC_VIDEO_CODEC_OK;
259 
260         gst_structure_get(gst_caps_get_structure(encodedCaps, 0),
261             &quot;width&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedWidth,
262             &quot;height&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedHeight,
263             nullptr);
264 
<span class="line-modified">265         m_encodedFrame._frameType = GST_BUFFER_FLAG_IS_SET(encodedBuffer, GST_BUFFER_FLAG_DELTA_UNIT) ? webrtc::VideoFrameType::kVideoFrameDelta : webrtc::VideoFrameType::kVideoFrameKey;</span>
266         m_encodedFrame._completeFrame = true;
267         m_encodedFrame.capture_time_ms_ = frame.render_time_ms();
268         m_encodedFrame.SetTimestamp(frame.timestamp());
269 
270         GST_LOG_OBJECT(m_pipeline.get(), &quot;Got buffer capture_time_ms: %&quot; G_GINT64_FORMAT  &quot; _timestamp: %u&quot;,
271             m_encodedFrame.capture_time_ms_, m_encodedFrame.Timestamp());
272 
273         webrtc::CodecSpecificInfo codecInfo;
274         PopulateCodecSpecific(&amp;codecInfo, encodedBuffer);
275         webrtc::EncodedImageCallback::Result result = m_imageReadyCb-&gt;OnEncodedImage(m_encodedFrame, &amp;codecInfo, &amp;fragmentationInfo);
276         if (result.error != webrtc::EncodedImageCallback::Result::OK)
277             GST_ERROR_OBJECT(m_pipeline.get(), &quot;Encode callback failed: %d&quot;, result.error);
278 
279         return WEBRTC_VIDEO_CODEC_OK;
280     }
281 
282     GRefPtr&lt;GstElement&gt; createEncoder(void)
283     {
284         GRefPtr&lt;GstElement&gt; encoder = nullptr;
285         GstElement* webrtcencoder = GST_ELEMENT(g_object_ref_sink(gst_element_factory_make(&quot;webrtcvideoencoder&quot;, NULL)));
</pre>
<hr />
<pre>
309 
310     virtual const gchar* Caps()
311     {
312         return nullptr;
313     }
314 
315     virtual webrtc::VideoCodecType CodecType() = 0;
316     virtual webrtc::SdpVideoFormat ConfigureSupportedCodec(GstElement*)
317     {
318         return webrtc::SdpVideoFormat(Name());
319     }
320 
321     virtual void PopulateCodecSpecific(webrtc::CodecSpecificInfo*, GstBuffer*) = 0;
322 
323     virtual void Fragmentize(webrtc::EncodedImage* encodedImage, std::unique_ptr&lt;uint8_t[]&gt;* encodedImageBuffer,
324         size_t* bufferSize, GstBuffer* buffer, webrtc::RTPFragmentationHeader* fragmentationInfo)
325     {
326         auto map = GstMappedBuffer::create(buffer, GST_MAP_READ);
327 
328         if (*bufferSize &lt; map-&gt;size()) {
<span class="line-modified">329             encodedImage-&gt;set_size(map-&gt;size());</span>
<span class="line-modified">330             encodedImage-&gt;set_buffer(new uint8_t[map-&gt;size()], map-&gt;size());</span>
<span class="line-modified">331             encodedImageBuffer-&gt;reset(encodedImage-&gt;data());</span>
332             *bufferSize = map-&gt;size();
333         }
334 
<span class="line-modified">335         memcpy(encodedImage-&gt;data(), map-&gt;data(), map-&gt;size());</span>
<span class="line-modified">336         encodedImage-&gt;set_size(map-&gt;size());</span>

337 
338         fragmentationInfo-&gt;VerifyAndAllocateFragmentationHeader(1);
339         fragmentationInfo-&gt;fragmentationOffset[0] = 0;
340         fragmentationInfo-&gt;fragmentationLength[0] = map-&gt;size();












341     }
342 
343     virtual const gchar* Name() = 0;
344     virtual int KeyframeInterval(const webrtc::VideoCodec* codecSettings) = 0;
345 
346     void SetRestrictionCaps(GRefPtr&lt;GstCaps&gt; caps)
347     {
348         if (m_restrictionCaps)
349             g_object_set(m_capsFilter, &quot;caps&quot;, m_restrictionCaps.get(), nullptr);
350 
351         m_restrictionCaps = caps;
352     }
353 
354 private:
355     GRefPtr&lt;GstElement&gt; m_pipeline;
356     GstElement* m_src;
357     GstElement* m_encoder;
358     GstElement* m_capsFilter;
359 
360     webrtc::EncodedImageCallback* m_imageReadyCb;
</pre>
<hr />
<pre>
397         gsize offset = 0;
398         size_t requiredSize = 0;
399 
400         std::vector&lt;GstH264NalUnit&gt; nals;
401 
402         const uint8_t startCode[4] = { 0, 0, 0, 1 };
403         auto map = GstMappedBuffer::create(gstbuffer, GST_MAP_READ);
404         while (parserResult == GST_H264_PARSER_OK) {
405             parserResult = gst_h264_parser_identify_nalu(m_parser, map-&gt;data(), offset, map-&gt;size(), &amp;nalu);
406 
407             nalu.sc_offset = offset;
408             nalu.offset = offset + sizeof(startCode);
409             if (parserResult != GST_H264_PARSER_OK &amp;&amp; parserResult != GST_H264_PARSER_NO_NAL_END)
410                 break;
411 
412             requiredSize += nalu.size + sizeof(startCode);
413             nals.push_back(nalu);
414             offset = nalu.offset + nalu.size;
415         }
416 
<span class="line-modified">417         if (encodedImage-&gt;size() &lt; requiredSize) {</span>
<span class="line-modified">418             encodedImage-&gt;set_size(requiredSize);</span>
<span class="line-modified">419             encodedImage-&gt;set_buffer(new uint8_t[requiredSize], requiredSize);</span>
<span class="line-modified">420             encodedImageBuffer-&gt;reset(encodedImage-&gt;data());</span>
421             *bufferSize = map-&gt;size();
422         }
423 
424         // Iterate nal units and fill the Fragmentation info.
425         fragmentationHeader-&gt;VerifyAndAllocateFragmentationHeader(nals.size());
426         size_t fragmentIndex = 0;
<span class="line-modified">427         encodedImage-&gt;set_size(0);</span>
428         for (std::vector&lt;GstH264NalUnit&gt;::iterator nal = nals.begin(); nal != nals.end(); ++nal, fragmentIndex++) {
429 
430             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 0] == startCode[0]);
431             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 1] == startCode[1]);
432             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 2] == startCode[2]);
433             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 3] == startCode[3]);
434 
435             fragmentationHeader-&gt;fragmentationOffset[fragmentIndex] = nal-&gt;offset;
436             fragmentationHeader-&gt;fragmentationLength[fragmentIndex] = nal-&gt;size;
437 
<span class="line-modified">438             memcpy(encodedImage-&gt;data() + encodedImage-&gt;size(), &amp;map-&gt;data()[nal-&gt;sc_offset],</span>
439                 sizeof(startCode) + nal-&gt;size);
<span class="line-modified">440             encodedImage-&gt;set_size(nal-&gt;size + sizeof(startCode));</span>
441         }
442     }
443 
444     webrtc::SdpVideoFormat ConfigureSupportedCodec(GstElement*) final
445     {
446         // TODO- Create from encoder src pad caps template
447         return webrtc::SdpVideoFormat(cricket::kH264CodecName,
448             { { cricket::kH264FmtpProfileLevelId, cricket::kH264ProfileLevelConstrainedBaseline },
449                 { cricket::kH264FmtpLevelAsymmetryAllowed, &quot;1&quot; },
450                 { cricket::kH264FmtpPacketizationMode, &quot;1&quot; } });
451     }
452 
453     const gchar* Caps() final { return &quot;video/x-h264&quot;; }
454     const gchar* Name() final { return cricket::kH264CodecName; }
455     GstH264NalParser* m_parser;
456     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecH264; }
457 
458     void PopulateCodecSpecific(webrtc::CodecSpecificInfo* codecSpecificInfos, GstBuffer*) final
459     {
460         codecSpecificInfos-&gt;codecType = CodecType();

461         webrtc::CodecSpecificInfoH264* h264Info = &amp;(codecSpecificInfos-&gt;codecSpecific.H264);
462         h264Info-&gt;packetization_mode = packetizationMode;
463     }
464 
465     webrtc::H264PacketizationMode packetizationMode;
466 };
467 
468 class GStreamerVP8Encoder : public GStreamerVideoEncoder {
469 public:
470     GStreamerVP8Encoder() { }
471     GStreamerVP8Encoder(const webrtc::SdpVideoFormat&amp;) { }
472     const gchar* Caps() final { return &quot;video/x-vp8&quot;; }
473     const gchar* Name() final { return cricket::kVp8CodecName; }
474     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecVP8; }
475 
476     int KeyframeInterval(const webrtc::VideoCodec* codecSettings) final
477     {
478         return codecSettings-&gt;VP8().keyFrameInterval;
479     }
480 
481     void PopulateCodecSpecific(webrtc::CodecSpecificInfo* codecSpecificInfos, GstBuffer* buffer) final
482     {
483         codecSpecificInfos-&gt;codecType = webrtc::kVideoCodecVP8;

484         webrtc::CodecSpecificInfoVP8* vp8Info = &amp;(codecSpecificInfos-&gt;codecSpecific.VP8);
485         vp8Info-&gt;temporalIdx = 0;
486 
487         vp8Info-&gt;keyIdx = webrtc::kNoKeyIdx;
488         vp8Info-&gt;nonReference = GST_BUFFER_FLAG_IS_SET(buffer, GST_BUFFER_FLAG_DELTA_UNIT);
489     }
490 };
491 
492 std::unique_ptr&lt;webrtc::VideoEncoder&gt; GStreamerVideoEncoderFactory::CreateVideoEncoder(const webrtc::SdpVideoFormat&amp; format)
493 {
494     if (format.name == cricket::kVp8CodecName) {
495         GRefPtr&lt;GstElement&gt; webrtcencoder = adoptGRef(GST_ELEMENT(g_object_ref_sink(gst_element_factory_make(&quot;webrtcvideoencoder&quot;, NULL))));
496         GRefPtr&lt;GstElement&gt; encoder = nullptr;
497 
498         g_object_set(webrtcencoder.get(), &quot;format&quot;, adoptGRef(gst_caps_from_string(&quot;video/x-vp8&quot;)).get(), NULL);
499         g_object_get(webrtcencoder.get(), &quot;encoder&quot;, &amp;encoder.outPtr(), NULL);
500 
501         if (encoder)
502             return makeUnique&lt;GStreamerVP8Encoder&gt;(format);
503 
</pre>
</td>
</tr>
</table>
<center><a href="GStreamerVideoDecoderFactory.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../index.html" target="_top">index</a> <a href="LibWebRTCAudioModule.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>