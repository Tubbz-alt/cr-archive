<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/IsoDirectoryInlines.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="IsoDirectory.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="IsoHeap.h.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/IsoDirectoryInlines.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 37,27 ***</span>
  
  template&lt;typename Config, unsigned passedNumPages&gt;
  IsoDirectory&lt;Config, passedNumPages&gt;::IsoDirectory(IsoHeapImpl&lt;Config&gt;&amp; heap)
      : IsoDirectoryBase&lt;Config&gt;(heap)
  {
<span class="line-removed">-     for (unsigned i = numPages; i--;)</span>
<span class="line-removed">-         m_pages[i] = nullptr;</span>
  }
  
  template&lt;typename Config, unsigned passedNumPages&gt;
<span class="line-modified">! EligibilityResult&lt;Config&gt; IsoDirectory&lt;Config, passedNumPages&gt;::takeFirstEligible()</span>
  {
      unsigned pageIndex = (m_eligible | ~m_committed).findBit(m_firstEligibleOrDecommitted, true);
      m_firstEligibleOrDecommitted = pageIndex;
      BASSERT((m_eligible | ~m_committed).findBit(0, true) == pageIndex);
      if (pageIndex &gt;= numPages)
          return EligibilityKind::Full;
  
      Scavenger&amp; scavenger = *Scavenger::get();
      scavenger.didStartGrowing();
  
<span class="line-modified">!     IsoPage&lt;Config&gt;* page = m_pages[pageIndex];</span>
  
      if (!m_committed[pageIndex]) {
          scavenger.scheduleIfUnderMemoryPressure(IsoPageBase::pageSize);
  
          // It could be that we haven&#39;t even allocated a page yet. Do that now!
<span class="line-new-header">--- 37,29 ---</span>
  
  template&lt;typename Config, unsigned passedNumPages&gt;
  IsoDirectory&lt;Config, passedNumPages&gt;::IsoDirectory(IsoHeapImpl&lt;Config&gt;&amp; heap)
      : IsoDirectoryBase&lt;Config&gt;(heap)
  {
  }
  
  template&lt;typename Config, unsigned passedNumPages&gt;
<span class="line-modified">! EligibilityResult&lt;Config&gt; IsoDirectory&lt;Config, passedNumPages&gt;::takeFirstEligible(const LockHolder&amp;)</span>
  {
      unsigned pageIndex = (m_eligible | ~m_committed).findBit(m_firstEligibleOrDecommitted, true);
      m_firstEligibleOrDecommitted = pageIndex;
      BASSERT((m_eligible | ~m_committed).findBit(0, true) == pageIndex);
      if (pageIndex &gt;= numPages)
          return EligibilityKind::Full;
  
<span class="line-added">+ #if BUSE(PARTIAL_SCAVENGE)</span>
<span class="line-added">+     m_highWatermark = std::max(pageIndex, m_highWatermark);</span>
<span class="line-added">+ #endif</span>
<span class="line-added">+ </span>
      Scavenger&amp; scavenger = *Scavenger::get();
      scavenger.didStartGrowing();
  
<span class="line-modified">!     IsoPage&lt;Config&gt;* page = m_pages[pageIndex].get();</span>
  
      if (!m_committed[pageIndex]) {
          scavenger.scheduleIfUnderMemoryPressure(IsoPageBase::pageSize);
  
          // It could be that we haven&#39;t even allocated a page yet. Do that now!
</pre>
<hr />
<pre>
<span class="line-old-header">*** 87,21 ***</span>
      m_empty[pageIndex] = false;
      return page;
  }
  
  template&lt;typename Config, unsigned passedNumPages&gt;
<span class="line-modified">! void IsoDirectory&lt;Config, passedNumPages&gt;::didBecome(IsoPage&lt;Config&gt;* page, IsoPageTrigger trigger)</span>
  {
      static constexpr bool verbose = false;
      unsigned pageIndex = page-&gt;index();
      switch (trigger) {
      case IsoPageTrigger::Eligible:
          if (verbose)
              fprintf(stderr, &quot;%p: %p did become eligible.\n&quot;, this, page);
          m_eligible[pageIndex] = true;
          m_firstEligibleOrDecommitted = std::min(m_firstEligibleOrDecommitted, pageIndex);
<span class="line-modified">!         this-&gt;m_heap.didBecomeEligibleOrDecommited(this);</span>
          return;
      case IsoPageTrigger::Empty:
          if (verbose)
              fprintf(stderr, &quot;%p: %p did become empty.\n&quot;, this, page);
          BASSERT(!!m_committed[pageIndex]);
<span class="line-new-header">--- 89,21 ---</span>
      m_empty[pageIndex] = false;
      return page;
  }
  
  template&lt;typename Config, unsigned passedNumPages&gt;
<span class="line-modified">! void IsoDirectory&lt;Config, passedNumPages&gt;::didBecome(const LockHolder&amp; locker, IsoPage&lt;Config&gt;* page, IsoPageTrigger trigger)</span>
  {
      static constexpr bool verbose = false;
      unsigned pageIndex = page-&gt;index();
      switch (trigger) {
      case IsoPageTrigger::Eligible:
          if (verbose)
              fprintf(stderr, &quot;%p: %p did become eligible.\n&quot;, this, page);
          m_eligible[pageIndex] = true;
          m_firstEligibleOrDecommitted = std::min(m_firstEligibleOrDecommitted, pageIndex);
<span class="line-modified">!         this-&gt;m_heap.didBecomeEligibleOrDecommited(locker, this);</span>
          return;
      case IsoPageTrigger::Empty:
          if (verbose)
              fprintf(stderr, &quot;%p: %p did become empty.\n&quot;, this, page);
          BASSERT(!!m_committed[pageIndex]);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 117,44 ***</span>
  void IsoDirectory&lt;Config, passedNumPages&gt;::didDecommit(unsigned index)
  {
      // FIXME: We could do this without grabbing the lock. I just doubt that it matters. This is not going
      // to be a frequently executed path, in the sense that decommitting perf will be dominated by the
      // syscall itself (which has to do many hard things).
<span class="line-modified">!     std::lock_guard&lt;Mutex&gt; locker(this-&gt;m_heap.lock);</span>
      BASSERT(!!m_committed[index]);
<span class="line-modified">!     this-&gt;m_heap.isNoLongerFreeable(m_pages[index], IsoPageBase::pageSize);</span>
      m_committed[index] = false;
      m_firstEligibleOrDecommitted = std::min(m_firstEligibleOrDecommitted, index);
<span class="line-modified">!     this-&gt;m_heap.didBecomeEligibleOrDecommited(this);</span>
<span class="line-modified">!     this-&gt;m_heap.didDecommit(m_pages[index], IsoPageBase::pageSize);</span>
  }
  
  template&lt;typename Config, unsigned passedNumPages&gt;
<span class="line-modified">! void IsoDirectory&lt;Config, passedNumPages&gt;::scavengePage(size_t index, Vector&lt;DeferredDecommit&gt;&amp; decommits)</span>
  {
      // Make sure that this page is now off limits.
      m_empty[index] = false;
      m_eligible[index] = false;
<span class="line-modified">!     decommits.push(DeferredDecommit(this, m_pages[index], index));</span>
  }
  
  template&lt;typename Config, unsigned passedNumPages&gt;
<span class="line-modified">! void IsoDirectory&lt;Config, passedNumPages&gt;::scavenge(Vector&lt;DeferredDecommit&gt;&amp; decommits)</span>
  {
      (m_empty &amp; m_committed).forEachSetBit(
          [&amp;] (size_t index) {
<span class="line-modified">!             scavengePage(index, decommits);</span>
          });
  }
  
  template&lt;typename Config, unsigned passedNumPages&gt;
  template&lt;typename Func&gt;
<span class="line-modified">! void IsoDirectory&lt;Config, passedNumPages&gt;::forEachCommittedPage(const Func&amp; func)</span>
  {
      m_committed.forEachSetBit(
          [&amp;] (size_t index) {
<span class="line-modified">!             func(*m_pages[index]);</span>
          });
  }
  
  } // namespace bmalloc
  
<span class="line-new-header">--- 119,60 ---</span>
  void IsoDirectory&lt;Config, passedNumPages&gt;::didDecommit(unsigned index)
  {
      // FIXME: We could do this without grabbing the lock. I just doubt that it matters. This is not going
      // to be a frequently executed path, in the sense that decommitting perf will be dominated by the
      // syscall itself (which has to do many hard things).
<span class="line-modified">!     LockHolder locker(this-&gt;m_heap.lock);</span>
      BASSERT(!!m_committed[index]);
<span class="line-modified">!     this-&gt;m_heap.isNoLongerFreeable(m_pages[index].get(), IsoPageBase::pageSize);</span>
      m_committed[index] = false;
      m_firstEligibleOrDecommitted = std::min(m_firstEligibleOrDecommitted, index);
<span class="line-modified">!     this-&gt;m_heap.didBecomeEligibleOrDecommited(locker, this);</span>
<span class="line-modified">!     this-&gt;m_heap.didDecommit(m_pages[index].get(), IsoPageBase::pageSize);</span>
  }
  
  template&lt;typename Config, unsigned passedNumPages&gt;
<span class="line-modified">! void IsoDirectory&lt;Config, passedNumPages&gt;::scavengePage(const LockHolder&amp;, size_t index, Vector&lt;DeferredDecommit&gt;&amp; decommits)</span>
  {
      // Make sure that this page is now off limits.
      m_empty[index] = false;
      m_eligible[index] = false;
<span class="line-modified">!     decommits.push(DeferredDecommit(this, m_pages[index].get(), index));</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ template&lt;typename Config, unsigned passedNumPages&gt;</span>
<span class="line-added">+ void IsoDirectory&lt;Config, passedNumPages&gt;::scavenge(const LockHolder&amp; locker, Vector&lt;DeferredDecommit&gt;&amp; decommits)</span>
<span class="line-added">+ {</span>
<span class="line-added">+     (m_empty &amp; m_committed).forEachSetBit(</span>
<span class="line-added">+         [&amp;] (size_t index) {</span>
<span class="line-added">+             scavengePage(locker, index, decommits);</span>
<span class="line-added">+         });</span>
<span class="line-added">+ #if BUSE(PARTIAL_SCAVENGE)</span>
<span class="line-added">+     m_highWatermark = 0;</span>
<span class="line-added">+ #endif</span>
  }
  
<span class="line-added">+ #if BUSE(PARTIAL_SCAVENGE)</span>
  template&lt;typename Config, unsigned passedNumPages&gt;
<span class="line-modified">! void IsoDirectory&lt;Config, passedNumPages&gt;::scavengeToHighWatermark(const LockHolder&amp; locker, Vector&lt;DeferredDecommit&gt;&amp; decommits)</span>
  {
      (m_empty &amp; m_committed).forEachSetBit(
          [&amp;] (size_t index) {
<span class="line-modified">!             if (index &gt; m_highWatermark)</span>
<span class="line-added">+                 scavengePage(locker, index, decommits);</span>
          });
<span class="line-added">+     m_highWatermark = 0;</span>
  }
<span class="line-added">+ #endif</span>
  
  template&lt;typename Config, unsigned passedNumPages&gt;
  template&lt;typename Func&gt;
<span class="line-modified">! void IsoDirectory&lt;Config, passedNumPages&gt;::forEachCommittedPage(const LockHolder&amp;, const Func&amp; func)</span>
  {
      m_committed.forEachSetBit(
          [&amp;] (size_t index) {
<span class="line-modified">!             func(*(m_pages[index].get()));</span>
          });
  }
  
  } // namespace bmalloc
  
</pre>
<center><a href="IsoDirectory.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="IsoHeap.h.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>