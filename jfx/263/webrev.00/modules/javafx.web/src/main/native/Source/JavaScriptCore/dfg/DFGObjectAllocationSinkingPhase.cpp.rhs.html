<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGObjectAllocationSinkingPhase.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
<a name="1" id="anc1"></a><span class="line-modified">   2  * Copyright (C) 2015-2020 Apple Inc. All rights reserved.</span>
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;DFGObjectAllocationSinkingPhase.h&quot;
  28 
  29 #if ENABLE(DFG_JIT)
  30 
  31 #include &quot;DFGBlockMapInlines.h&quot;
  32 #include &quot;DFGClobbersExitState.h&quot;
  33 #include &quot;DFGCombinedLiveness.h&quot;
  34 #include &quot;DFGGraph.h&quot;
  35 #include &quot;DFGInsertionSet.h&quot;
  36 #include &quot;DFGLazyNode.h&quot;
  37 #include &quot;DFGLivenessAnalysisPhase.h&quot;
  38 #include &quot;DFGOSRAvailabilityAnalysisPhase.h&quot;
  39 #include &quot;DFGPhase.h&quot;
  40 #include &quot;DFGPromotedHeapLocation.h&quot;
  41 #include &quot;DFGSSACalculator.h&quot;
  42 #include &quot;DFGValidate.h&quot;
<a name="2" id="anc2"></a><span class="line-added">  43 #include &quot;JSArrayIterator.h&quot;</span>
  44 #include &quot;JSCInlines.h&quot;
  45 #include &lt;wtf/StdList.h&gt;
  46 
  47 namespace JSC { namespace DFG {
  48 
  49 namespace {
  50 
  51 namespace DFGObjectAllocationSinkingPhaseInternal {
<a name="3" id="anc3"></a><span class="line-modified">  52 static constexpr bool verbose = false;</span>
  53 }
  54 
  55 // In order to sink object cycles, we use a points-to analysis coupled
  56 // with an escape analysis. This analysis is actually similar to an
  57 // abstract interpreter focused on local allocations and ignoring
  58 // everything else.
  59 //
  60 // We represent the local heap using two mappings:
  61 //
  62 // - A set of the local allocations present in the function, where
  63 //   each of those have a further mapping from
  64 //   PromotedLocationDescriptor to local allocations they must point
  65 //   to.
  66 //
  67 // - A &quot;pointer&quot; mapping from nodes to local allocations, if they must
  68 //   be equal to said local allocation and are currently live. This
  69 //   can be because the node is the actual node that created the
  70 //   allocation, or any other node that must currently point to it -
  71 //   we don&#39;t make a difference.
  72 //
  73 // The following graph is a motivation for why we separate allocations
  74 // from pointers:
  75 //
  76 // Block #0
  77 //  0: NewObject({})
  78 //  1: NewObject({})
  79 //  -: PutByOffset(@0, @1, x)
  80 //  -: PutStructure(@0, {x:0})
  81 //  2: GetByOffset(@0, x)
  82 //  -: Jump(#1)
  83 //
  84 // Block #1
  85 //  -: Return(@2)
  86 //
  87 // Here, we need to remember in block #1 that @2 points to a local
  88 // allocation with appropriate fields and structures information
  89 // (because we should be able to place a materialization on top of
  90 // block #1 here), even though @1 is dead. We *could* just keep @1
  91 // artificially alive here, but there is no real reason to do it:
  92 // after all, by the end of block #0, @1 and @2 should be completely
  93 // interchangeable, and there is no reason for us to artificially make
  94 // @1 more important.
  95 //
  96 // An important point to consider to understand this separation is
  97 // that we should think of the local heap as follow: we have a
  98 // bunch of nodes that are pointers to &quot;allocations&quot; that live
  99 // someplace on the heap, and those allocations can have pointers in
 100 // between themselves as well. We shouldn&#39;t care about whatever
 101 // names we give to the allocations ; what matters when
 102 // comparing/merging two heaps is the isomorphism/comparison between
 103 // the allocation graphs as seen by the nodes.
 104 //
 105 // For instance, in the following graph:
 106 //
 107 // Block #0
 108 //  0: NewObject({})
 109 //  -: Branch(#1, #2)
 110 //
 111 // Block #1
 112 //  1: NewObject({})
 113 //  -: PutByOffset(@0, @1, x)
 114 //  -: PutStructure(@0, {x:0})
 115 //  -: Jump(#3)
 116 //
 117 // Block #2
 118 //  2: NewObject({})
 119 //  -: PutByOffset(@2, undefined, x)
 120 //  -: PutStructure(@2, {x:0})
 121 //  -: PutByOffset(@0, @2, x)
 122 //  -: PutStructure(@0, {x:0})
 123 //  -: Jump(#3)
 124 //
 125 // Block #3
 126 //  -: Return(@0)
 127 //
 128 // we should think of the heaps at tail of blocks #1 and #2 as being
 129 // exactly the same, even though one has @0.x pointing to @1 and the
 130 // other has @0.x pointing to @2, because in essence this should not
 131 // be different from the graph where we hoisted @1 and @2 into a
 132 // single allocation in block #0. We currently will not handle this
 133 // case, because we merge allocations based on the node they are
 134 // coming from, but this is only a technicality for the sake of
 135 // simplicity that shouldn&#39;t hide the deeper idea outlined here.
 136 
 137 class Allocation {
 138 public:
 139     // We use Escaped as a special allocation kind because when we
 140     // decide to sink an allocation, we still need to keep track of it
 141     // once it is escaped if it still has pointers to it in order to
 142     // replace any use of those pointers by the corresponding
 143     // materialization
<a name="4" id="anc4"></a><span class="line-modified"> 144     enum class Kind { Escaped, Object, Activation, Function, GeneratorFunction, AsyncFunction, AsyncGeneratorFunction, InternalFieldObject, RegExpObject };</span>
 145 
 146     using Fields = HashMap&lt;PromotedLocationDescriptor, Node*&gt;;
 147 
 148     explicit Allocation(Node* identifier = nullptr, Kind kind = Kind::Escaped)
 149         : m_identifier(identifier)
 150         , m_kind(kind)
 151     {
 152     }
 153 
 154 
 155     const Fields&amp; fields() const
 156     {
 157         return m_fields;
 158     }
 159 
 160     Fields&amp; fields()
 161     {
 162         return m_fields;
 163     }
 164 
 165     Node* get(PromotedLocationDescriptor descriptor)
 166     {
 167         return m_fields.get(descriptor);
 168     }
 169 
 170     Allocation&amp; set(PromotedLocationDescriptor descriptor, Node* value)
 171     {
 172         // Pointing to anything else than an unescaped local
 173         // allocation is represented by simply not having the
 174         // field
 175         if (value)
 176             m_fields.set(descriptor, value);
 177         else
 178             m_fields.remove(descriptor);
 179         return *this;
 180     }
 181 
 182     void remove(PromotedLocationDescriptor descriptor)
 183     {
 184         set(descriptor, nullptr);
 185     }
 186 
 187     bool hasStructures() const
 188     {
 189         switch (kind()) {
 190         case Kind::Object:
 191             return true;
 192 
 193         default:
 194             return false;
 195         }
 196     }
 197 
 198     Allocation&amp; setStructures(const RegisteredStructureSet&amp; structures)
 199     {
 200         ASSERT(hasStructures() &amp;&amp; !structures.isEmpty());
 201         m_structures = structures;
 202         return *this;
 203     }
 204 
 205     Allocation&amp; mergeStructures(const RegisteredStructureSet&amp; structures)
 206     {
 207         ASSERT(hasStructures() || structures.isEmpty());
 208         m_structures.merge(structures);
 209         return *this;
 210     }
 211 
 212     Allocation&amp; filterStructures(const RegisteredStructureSet&amp; structures)
 213     {
 214         ASSERT(hasStructures());
 215         m_structures.filter(structures);
 216         RELEASE_ASSERT(!m_structures.isEmpty());
 217         return *this;
 218     }
 219 
 220     const RegisteredStructureSet&amp; structures() const
 221     {
 222         return m_structures;
 223     }
 224 
 225     Node* identifier() const { return m_identifier; }
 226 
 227     Kind kind() const { return m_kind; }
 228 
 229     bool isEscapedAllocation() const
 230     {
 231         return kind() == Kind::Escaped;
 232     }
 233 
 234     bool isObjectAllocation() const
 235     {
 236         return m_kind == Kind::Object;
 237     }
 238 
 239     bool isActivationAllocation() const
 240     {
 241         return m_kind == Kind::Activation;
 242     }
 243 
 244     bool isFunctionAllocation() const
 245     {
 246         return m_kind == Kind::Function || m_kind == Kind::GeneratorFunction || m_kind == Kind::AsyncFunction;
 247     }
 248 
<a name="5" id="anc5"></a><span class="line-added"> 249     bool isInternalFieldObjectAllocation() const</span>
<span class="line-added"> 250     {</span>
<span class="line-added"> 251         return m_kind == Kind::InternalFieldObject;</span>
<span class="line-added"> 252     }</span>
<span class="line-added"> 253 </span>
 254     bool isRegExpObjectAllocation() const
 255     {
 256         return m_kind == Kind::RegExpObject;
 257     }
 258 
 259     bool operator==(const Allocation&amp; other) const
 260     {
 261         return m_identifier == other.m_identifier
 262             &amp;&amp; m_kind == other.m_kind
 263             &amp;&amp; m_fields == other.m_fields
 264             &amp;&amp; m_structures == other.m_structures;
 265     }
 266 
 267     bool operator!=(const Allocation&amp; other) const
 268     {
 269         return !(*this == other);
 270     }
 271 
 272     void dump(PrintStream&amp; out) const
 273     {
 274         dumpInContext(out, nullptr);
 275     }
 276 
 277     void dumpInContext(PrintStream&amp; out, DumpContext* context) const
 278     {
 279         switch (m_kind) {
 280         case Kind::Escaped:
 281             out.print(&quot;Escaped&quot;);
 282             break;
 283 
 284         case Kind::Object:
 285             out.print(&quot;Object&quot;);
 286             break;
 287 
 288         case Kind::Function:
 289             out.print(&quot;Function&quot;);
 290             break;
 291 
 292         case Kind::GeneratorFunction:
 293             out.print(&quot;GeneratorFunction&quot;);
 294             break;
 295 
 296         case Kind::AsyncFunction:
 297             out.print(&quot;AsyncFunction&quot;);
 298             break;
 299 
<a name="6" id="anc6"></a><span class="line-added"> 300         case Kind::InternalFieldObject:</span>
<span class="line-added"> 301             out.print(&quot;InternalFieldObject&quot;);</span>
<span class="line-added"> 302             break;</span>
<span class="line-added"> 303 </span>
 304         case Kind::AsyncGeneratorFunction:
 305             out.print(&quot;AsyncGeneratorFunction&quot;);
 306             break;
 307 
 308         case Kind::Activation:
 309             out.print(&quot;Activation&quot;);
 310             break;
 311 
 312         case Kind::RegExpObject:
 313             out.print(&quot;RegExpObject&quot;);
 314             break;
 315         }
 316         out.print(&quot;Allocation(&quot;);
 317         if (!m_structures.isEmpty())
 318             out.print(inContext(m_structures.toStructureSet(), context));
 319         if (!m_fields.isEmpty()) {
 320             if (!m_structures.isEmpty())
 321                 out.print(&quot;, &quot;);
 322             out.print(mapDump(m_fields, &quot; =&gt; #&quot;, &quot;, &quot;));
 323         }
 324         out.print(&quot;)&quot;);
 325     }
 326 
 327 private:
 328     Node* m_identifier; // This is the actual node that created the allocation
 329     Kind m_kind;
 330     Fields m_fields;
 331     RegisteredStructureSet m_structures;
 332 };
 333 
 334 class LocalHeap {
 335 public:
 336     Allocation&amp; newAllocation(Node* node, Allocation::Kind kind)
 337     {
 338         ASSERT(!m_pointers.contains(node) &amp;&amp; !isAllocation(node));
 339         m_pointers.add(node, node);
 340         return m_allocations.set(node, Allocation(node, kind)).iterator-&gt;value;
 341     }
 342 
 343     bool isAllocation(Node* identifier) const
 344     {
 345         return m_allocations.contains(identifier);
 346     }
 347 
 348     // Note that this is fundamentally different from
 349     // onlyLocalAllocation() below. getAllocation() takes as argument
 350     // a node-as-identifier, that is, an allocation node. This
 351     // allocation node doesn&#39;t have to be alive; it may only be
 352     // pointed to by other nodes or allocation fields.
 353     // For instance, in the following graph:
 354     //
 355     // Block #0
 356     //  0: NewObject({})
 357     //  1: NewObject({})
 358     //  -: PutByOffset(@0, @1, x)
 359     //  -: PutStructure(@0, {x:0})
 360     //  2: GetByOffset(@0, x)
 361     //  -: Jump(#1)
 362     //
 363     // Block #1
 364     //  -: Return(@2)
 365     //
 366     // At head of block #1, the only reachable allocation is #@1,
 367     // which can be reached through node @2. Thus, getAllocation(#@1)
 368     // contains the appropriate metadata for this allocation, but
 369     // onlyLocalAllocation(@1) is null, as @1 is no longer a pointer
 370     // to #@1 (since it is dead). Conversely, onlyLocalAllocation(@2)
 371     // is the same as getAllocation(#@1), while getAllocation(#@2)
 372     // does not make sense since @2 is not an allocation node.
 373     //
 374     // This is meant to be used when the node is already known to be
 375     // an identifier (i.e. an allocation) - probably because it was
 376     // found as value of a field or pointer in the current heap, or
 377     // was the result of a call to follow(). In any other cases (such
 378     // as when doing anything while traversing the graph), the
 379     // appropriate function to call is probably onlyLocalAllocation.
 380     Allocation&amp; getAllocation(Node* identifier)
 381     {
 382         auto iter = m_allocations.find(identifier);
 383         ASSERT(iter != m_allocations.end());
 384         return iter-&gt;value;
 385     }
 386 
 387     void newPointer(Node* node, Node* identifier)
 388     {
 389         ASSERT(!m_allocations.contains(node) &amp;&amp; !m_pointers.contains(node));
 390         ASSERT(isAllocation(identifier));
 391         m_pointers.add(node, identifier);
 392     }
 393 
 394     // follow solves the points-to problem. Given a live node, which
 395     // may be either an allocation itself or a heap read (e.g. a
 396     // GetByOffset node), it returns the corresponding allocation
 397     // node, if there is one. If the argument node is neither an
 398     // allocation or a heap read, or may point to different nodes,
 399     // nullptr will be returned. Note that a node that points to
 400     // different nodes can never point to an unescaped local
 401     // allocation.
 402     Node* follow(Node* node) const
 403     {
 404         auto iter = m_pointers.find(node);
<a name="7" id="anc7"></a><span class="line-modified"> 405         ASSERT(iter == m_pointers.end() || (!iter-&gt;value || m_allocations.contains(iter-&gt;value)));</span>
 406         return iter == m_pointers.end() ? nullptr : iter-&gt;value;
 407     }
 408 
 409     Node* follow(PromotedHeapLocation location) const
 410     {
 411         const Allocation&amp; base = m_allocations.find(location.base())-&gt;value;
 412         auto iter = base.fields().find(location.descriptor());
<a name="8" id="anc8"></a>
 413         if (iter == base.fields().end())
 414             return nullptr;
 415 
 416         return iter-&gt;value;
 417     }
 418 
 419     // onlyLocalAllocation find the corresponding allocation metadata
 420     // for any live node. onlyLocalAllocation(node) is essentially
 421     // getAllocation(follow(node)), with appropriate null handling.
 422     Allocation* onlyLocalAllocation(Node* node)
 423     {
 424         Node* identifier = follow(node);
 425         if (!identifier)
 426             return nullptr;
 427 
 428         return &amp;getAllocation(identifier);
 429     }
 430 
 431     Allocation* onlyLocalAllocation(PromotedHeapLocation location)
 432     {
 433         Node* identifier = follow(location);
 434         if (!identifier)
 435             return nullptr;
 436 
 437         return &amp;getAllocation(identifier);
 438     }
 439 
<a name="9" id="anc9"></a><span class="line-added"> 440     bool isUnescapedAllocation(Node* identifier) const</span>
<span class="line-added"> 441     {</span>
<span class="line-added"> 442         auto iter = m_allocations.find(identifier);</span>
<span class="line-added"> 443         return iter != m_allocations.end() &amp;&amp; !iter-&gt;value.isEscapedAllocation();</span>
<span class="line-added"> 444     }</span>
<span class="line-added"> 445 </span>
 446     // This allows us to store the escapees only when necessary. If
 447     // set, the current escapees can be retrieved at any time using
 448     // takeEscapees(), which will clear the cached set of escapees;
 449     // otherwise the heap won&#39;t remember escaping allocations.
 450     void setWantEscapees()
 451     {
 452         m_wantEscapees = true;
 453     }
 454 
 455     HashMap&lt;Node*, Allocation&gt; takeEscapees()
 456     {
 457         return WTFMove(m_escapees);
 458     }
 459 
 460     void escape(Node* node)
 461     {
 462         Node* identifier = follow(node);
 463         if (!identifier)
 464             return;
 465 
 466         escapeAllocation(identifier);
 467     }
 468 
 469     void merge(const LocalHeap&amp; other)
 470     {
 471         assertIsValid();
 472         other.assertIsValid();
 473         ASSERT(!m_wantEscapees);
 474 
 475         if (!reached()) {
 476             ASSERT(other.reached());
 477             *this = other;
 478             return;
 479         }
 480 
 481         NodeSet toEscape;
 482 
 483         for (auto&amp; allocationEntry : other.m_allocations)
 484             m_allocations.add(allocationEntry.key, allocationEntry.value);
 485         for (auto&amp; allocationEntry : m_allocations) {
 486             auto allocationIter = other.m_allocations.find(allocationEntry.key);
 487 
 488             // If we have it and they don&#39;t, it died for them but we
 489             // are keeping it alive from another field somewhere.
 490             // There is nothing to do - we will be escaped
 491             // automatically when we handle that other field.
 492             // This will also happen for allocation that we have and
 493             // they don&#39;t, and all of those will get pruned.
 494             if (allocationIter == other.m_allocations.end())
 495                 continue;
 496 
 497             if (allocationEntry.value.kind() != allocationIter-&gt;value.kind()) {
 498                 toEscape.addVoid(allocationEntry.key);
 499                 for (const auto&amp; fieldEntry : allocationIter-&gt;value.fields())
 500                     toEscape.addVoid(fieldEntry.value);
 501             } else {
 502                 mergePointerSets(allocationEntry.value.fields(), allocationIter-&gt;value.fields(), toEscape);
 503                 allocationEntry.value.mergeStructures(allocationIter-&gt;value.structures());
 504             }
 505         }
 506 
<a name="10" id="anc10"></a><span class="line-modified"> 507         {</span>
<span class="line-added"> 508             // This works because we won&#39;t collect all pointers until all of our predecessors</span>
<span class="line-added"> 509             // merge their pointer sets with ours. That allows us to see the full state of the</span>
<span class="line-added"> 510             // world during our fixpoint analysis. Once we have the full set of pointers, we</span>
<span class="line-added"> 511             // only mark pointers to TOP, so we will eventually converge.</span>
<span class="line-added"> 512             for (auto entry : other.m_pointers) {</span>
<span class="line-added"> 513                 auto addResult = m_pointers.add(entry.key, entry.value);</span>
<span class="line-added"> 514                 if (addResult.iterator-&gt;value != entry.value) {</span>
<span class="line-added"> 515                     if (addResult.iterator-&gt;value) {</span>
<span class="line-added"> 516                         toEscape.addVoid(addResult.iterator-&gt;value);</span>
<span class="line-added"> 517                         addResult.iterator-&gt;value = nullptr;</span>
<span class="line-added"> 518                     }</span>
<span class="line-added"> 519                     if (entry.value)</span>
<span class="line-added"> 520                         toEscape.addVoid(entry.value);</span>
<span class="line-added"> 521                 }</span>
<span class="line-added"> 522             }</span>
<span class="line-added"> 523             // This allows us to rule out pointers for graphs like this:</span>
<span class="line-added"> 524             // bb#0</span>
<span class="line-added"> 525             // branch #1, #2</span>
<span class="line-added"> 526             // #1:</span>
<span class="line-added"> 527             // x = pointer A</span>
<span class="line-added"> 528             // jump #3</span>
<span class="line-added"> 529             // #2:</span>
<span class="line-added"> 530             // y = pointer B</span>
<span class="line-added"> 531             // jump #3</span>
<span class="line-added"> 532             // #3:</span>
<span class="line-added"> 533             // ...</span>
<span class="line-added"> 534             //</span>
<span class="line-added"> 535             // When we merge state at #3, we&#39;ll very likely prune away the x and y pointer,</span>
<span class="line-added"> 536             // since they&#39;re not live. But if they do happen to make it to this merge function, when</span>
<span class="line-added"> 537             // #3 merges with #2 and #1, it&#39;ll eventually rule out x and y as not existing</span>
<span class="line-added"> 538             // in the other, and therefore not existing in #3, which is the desired behavior.</span>
<span class="line-added"> 539             //</span>
<span class="line-added"> 540             // This also is necessary for a graph like this:</span>
<span class="line-added"> 541             // #0</span>
<span class="line-added"> 542             // o = {}</span>
<span class="line-added"> 543             // o2 = {}</span>
<span class="line-added"> 544             // jump #1</span>
<span class="line-added"> 545             //</span>
<span class="line-added"> 546             // #1</span>
<span class="line-added"> 547             // o.f = o2</span>
<span class="line-added"> 548             // effects()</span>
<span class="line-added"> 549             // x = o.f</span>
<span class="line-added"> 550             // escape(o)</span>
<span class="line-added"> 551             // branch #2, #1</span>
<span class="line-added"> 552             //</span>
<span class="line-added"> 553             // #2</span>
<span class="line-added"> 554             // x cannot be o2 here, it has to be TOP</span>
<span class="line-added"> 555             // ...</span>
<span class="line-added"> 556             //</span>
<span class="line-added"> 557             // On the first fixpoint iteration, we might think that x is o2 at the head</span>
<span class="line-added"> 558             // of #2. However, when we fixpoint our analysis, we determine that o gets</span>
<span class="line-added"> 559             // escaped. This means that when we fixpoint, x will eventually not be a pointer.</span>
<span class="line-added"> 560             // When we merge again here, we&#39;ll notice and mark o2 as escaped.</span>
<span class="line-added"> 561             for (auto&amp; entry : m_pointers) {</span>
<span class="line-added"> 562                 if (!other.m_pointers.contains(entry.key)) {</span>
<span class="line-added"> 563                     if (entry.value) {</span>
<span class="line-added"> 564                         toEscape.addVoid(entry.value);</span>
<span class="line-added"> 565                         entry.value = nullptr;</span>
<span class="line-added"> 566                         ASSERT(!m_pointers.find(entry.key)-&gt;value);</span>
<span class="line-added"> 567                     }</span>
<span class="line-added"> 568                 }</span>
<span class="line-added"> 569             }</span>
<span class="line-added"> 570         }</span>
 571 
 572         for (Node* identifier : toEscape)
 573             escapeAllocation(identifier);
 574 
<a name="11" id="anc11"></a><span class="line-modified"> 575         if (ASSERT_ENABLED) {</span>
 576             for (const auto&amp; entry : m_allocations)
 577                 ASSERT_UNUSED(entry, entry.value.isEscapedAllocation() || other.m_allocations.contains(entry.key));
 578         }
 579 
 580         // If there is no remaining pointer to an allocation, we can
 581         // remove it. This should only happen for escaped allocations,
 582         // because we only merge liveness-pruned heaps in the first
 583         // place.
 584         prune();
 585 
 586         assertIsValid();
 587     }
 588 
 589     void pruneByLiveness(const NodeSet&amp; live)
 590     {
 591         m_pointers.removeIf(
 592             [&amp;] (const auto&amp; entry) {
 593                 return !live.contains(entry.key);
 594             });
 595         prune();
 596     }
 597 
 598     void assertIsValid() const
 599     {
<a name="12" id="anc12"></a><span class="line-modified"> 600         if (!ASSERT_ENABLED)</span>
 601             return;
 602 
 603         // Pointers should point to an actual allocation
 604         for (const auto&amp; entry : m_pointers) {
<a name="13" id="anc13"></a><span class="line-modified"> 605             if (entry.value)</span>
<span class="line-modified"> 606                 ASSERT(m_allocations.contains(entry.value));</span>
 607         }
 608 
 609         for (const auto&amp; allocationEntry : m_allocations) {
 610             // Fields should point to an actual allocation
 611             for (const auto&amp; fieldEntry : allocationEntry.value.fields()) {
 612                 ASSERT_UNUSED(fieldEntry, fieldEntry.value);
 613                 ASSERT(m_allocations.contains(fieldEntry.value));
 614             }
 615         }
 616     }
 617 
 618     bool operator==(const LocalHeap&amp; other) const
 619     {
 620         assertIsValid();
 621         other.assertIsValid();
 622         return m_allocations == other.m_allocations
 623             &amp;&amp; m_pointers == other.m_pointers;
 624     }
 625 
 626     bool operator!=(const LocalHeap&amp; other) const
 627     {
 628         return !(*this == other);
 629     }
 630 
 631     const HashMap&lt;Node*, Allocation&gt;&amp; allocations() const
 632     {
 633         return m_allocations;
 634     }
 635 
<a name="14" id="anc14"></a>




 636     void dump(PrintStream&amp; out) const
 637     {
 638         out.print(&quot;  Allocations:\n&quot;);
 639         for (const auto&amp; entry : m_allocations)
 640             out.print(&quot;    #&quot;, entry.key, &quot;: &quot;, entry.value, &quot;\n&quot;);
 641         out.print(&quot;  Pointers:\n&quot;);
<a name="15" id="anc15"></a><span class="line-modified"> 642         for (const auto&amp; entry : m_pointers) {</span>
<span class="line-modified"> 643             out.print(&quot;    &quot;, entry.key, &quot; =&gt; #&quot;);</span>
<span class="line-added"> 644             if (entry.value)</span>
<span class="line-added"> 645                 out.print(entry.value, &quot;\n&quot;);</span>
<span class="line-added"> 646             else</span>
<span class="line-added"> 647                 out.print(&quot;TOP\n&quot;);</span>
<span class="line-added"> 648         }</span>
 649     }
 650 
 651     bool reached() const
 652     {
 653         return m_reached;
 654     }
 655 
 656     void setReached()
 657     {
 658         m_reached = true;
 659     }
 660 
 661 private:
 662     // When we merge two heaps, we escape all fields of allocations,
 663     // unless they point to the same thing in both heaps.
 664     // The reason for this is that it allows us not to do extra work
 665     // for diamond graphs where we would otherwise have to check
 666     // whether we have a single definition or not, which would be
 667     // cumbersome.
 668     //
 669     // Note that we should try to unify nodes even when they are not
 670     // from the same allocation; for instance we should be able to
 671     // completely eliminate all allocations from the following graph:
 672     //
 673     // Block #0
 674     //  0: NewObject({})
 675     //  -: Branch(#1, #2)
 676     //
 677     // Block #1
 678     //  1: NewObject({})
 679     //  -: PutByOffset(@1, &quot;left&quot;, val)
 680     //  -: PutStructure(@1, {val:0})
 681     //  -: PutByOffset(@0, @1, x)
 682     //  -: PutStructure(@0, {x:0})
 683     //  -: Jump(#3)
 684     //
 685     // Block #2
 686     //  2: NewObject({})
 687     //  -: PutByOffset(@2, &quot;right&quot;, val)
 688     //  -: PutStructure(@2, {val:0})
 689     //  -: PutByOffset(@0, @2, x)
 690     //  -: PutStructure(@0, {x:0})
 691     //  -: Jump(#3)
 692     //
 693     // Block #3:
 694     //  3: GetByOffset(@0, x)
 695     //  4: GetByOffset(@3, val)
 696     //  -: Return(@4)
 697     template&lt;typename Key&gt;
 698     static void mergePointerSets(HashMap&lt;Key, Node*&gt;&amp; my, const HashMap&lt;Key, Node*&gt;&amp; their, NodeSet&amp; toEscape)
 699     {
 700         auto escape = [&amp;] (Node* identifier) {
 701             toEscape.addVoid(identifier);
 702         };
 703 
 704         for (const auto&amp; entry : their) {
 705             if (!my.contains(entry.key))
 706                 escape(entry.value);
 707         }
 708         my.removeIf([&amp;] (const auto&amp; entry) {
 709             auto iter = their.find(entry.key);
 710             if (iter == their.end()) {
 711                 escape(entry.value);
 712                 return true;
 713             }
 714             if (iter-&gt;value != entry.value) {
 715                 escape(entry.value);
 716                 escape(iter-&gt;value);
 717                 return true;
 718             }
 719             return false;
 720         });
 721     }
 722 
 723     void escapeAllocation(Node* identifier)
 724     {
 725         Allocation&amp; allocation = getAllocation(identifier);
 726         if (allocation.isEscapedAllocation())
 727             return;
 728 
 729         Allocation unescaped = WTFMove(allocation);
 730         allocation = Allocation(unescaped.identifier(), Allocation::Kind::Escaped);
 731 
 732         for (const auto&amp; entry : unescaped.fields())
 733             escapeAllocation(entry.value);
 734 
 735         if (m_wantEscapees)
 736             m_escapees.add(unescaped.identifier(), WTFMove(unescaped));
 737     }
 738 
 739     void prune()
 740     {
 741         NodeSet reachable;
<a name="16" id="anc16"></a><span class="line-modified"> 742         for (const auto&amp; entry : m_pointers) {</span>
<span class="line-modified"> 743             if (entry.value)</span>
<span class="line-added"> 744                 reachable.addVoid(entry.value);</span>
<span class="line-added"> 745         }</span>
 746 
 747         // Repeatedly mark as reachable allocations in fields of other
 748         // reachable allocations
 749         {
 750             Vector&lt;Node*&gt; worklist;
 751             worklist.appendRange(reachable.begin(), reachable.end());
 752 
 753             while (!worklist.isEmpty()) {
 754                 Node* identifier = worklist.takeLast();
 755                 Allocation&amp; allocation = m_allocations.find(identifier)-&gt;value;
 756                 for (const auto&amp; entry : allocation.fields()) {
 757                     if (reachable.add(entry.value).isNewEntry)
 758                         worklist.append(entry.value);
 759                 }
 760             }
 761         }
 762 
 763         // Remove unreachable allocations
 764         m_allocations.removeIf(
 765             [&amp;] (const auto&amp; entry) {
 766                 return !reachable.contains(entry.key);
 767             });
 768     }
 769 
 770     bool m_reached = false;
 771     HashMap&lt;Node*, Node*&gt; m_pointers;
 772     HashMap&lt;Node*, Allocation&gt; m_allocations;
 773 
 774     bool m_wantEscapees = false;
 775     HashMap&lt;Node*, Allocation&gt; m_escapees;
 776 };
 777 
 778 class ObjectAllocationSinkingPhase : public Phase {
 779 public:
 780     ObjectAllocationSinkingPhase(Graph&amp; graph)
 781         : Phase(graph, &quot;object allocation elimination&quot;)
 782         , m_pointerSSA(graph)
 783         , m_allocationSSA(graph)
 784         , m_insertionSet(graph)
 785     {
 786     }
 787 
 788     bool run()
 789     {
 790         ASSERT(m_graph.m_form == SSA);
 791         ASSERT(m_graph.m_fixpointState == FixpointNotConverged);
 792 
 793         if (!performSinking())
 794             return false;
 795 
 796         if (DFGObjectAllocationSinkingPhaseInternal::verbose) {
 797             dataLog(&quot;Graph after elimination:\n&quot;);
 798             m_graph.dump();
 799         }
 800 
 801         return true;
 802     }
 803 
 804 private:
 805     bool performSinking()
 806     {
 807         m_graph.computeRefCounts();
 808         m_graph.initializeNodeOwners();
 809         m_graph.ensureSSADominators();
 810         performLivenessAnalysis(m_graph);
 811         performOSRAvailabilityAnalysis(m_graph);
 812         m_combinedLiveness = CombinedLiveness(m_graph);
 813 
 814         CString graphBeforeSinking;
<a name="17" id="anc17"></a><span class="line-modified"> 815         if (UNLIKELY(Options::verboseValidationFailure() &amp;&amp; Options::validateGraphAtEachPhase())) {</span>
 816             StringPrintStream out;
 817             m_graph.dump(out);
 818             graphBeforeSinking = out.toCString();
 819         }
 820 
 821         if (DFGObjectAllocationSinkingPhaseInternal::verbose) {
 822             dataLog(&quot;Graph before elimination:\n&quot;);
 823             m_graph.dump();
 824         }
 825 
 826         performAnalysis();
 827 
 828         if (!determineSinkCandidates())
 829             return false;
 830 
 831         if (DFGObjectAllocationSinkingPhaseInternal::verbose) {
 832             for (BasicBlock* block : m_graph.blocksInNaturalOrder()) {
 833                 dataLog(&quot;Heap at head of &quot;, *block, &quot;: \n&quot;, m_heapAtHead[block]);
 834                 dataLog(&quot;Heap at tail of &quot;, *block, &quot;: \n&quot;, m_heapAtTail[block]);
 835             }
 836         }
 837 
 838         promoteLocalHeap();
 839         removeICStatusFilters();
 840 
 841         if (Options::validateGraphAtEachPhase())
 842             DFG::validate(m_graph, DumpGraph, graphBeforeSinking);
 843         return true;
 844     }
 845 
 846     void performAnalysis()
 847     {
 848         m_heapAtHead = BlockMap&lt;LocalHeap&gt;(m_graph);
 849         m_heapAtTail = BlockMap&lt;LocalHeap&gt;(m_graph);
 850 
 851         bool changed;
 852         do {
 853             if (DFGObjectAllocationSinkingPhaseInternal::verbose)
 854                 dataLog(&quot;Doing iteration of escape analysis.\n&quot;);
 855             changed = false;
 856 
 857             for (BasicBlock* block : m_graph.blocksInPreOrder()) {
 858                 m_heapAtHead[block].setReached();
 859                 m_heap = m_heapAtHead[block];
 860 
 861                 for (Node* node : *block) {
 862                     handleNode(
 863                         node,
 864                         [] (PromotedHeapLocation, LazyNode) { },
 865                         [&amp;] (PromotedHeapLocation) -&gt; Node* {
 866                             return nullptr;
 867                         });
 868                 }
 869 
 870                 if (m_heap == m_heapAtTail[block])
 871                     continue;
 872 
 873                 m_heapAtTail[block] = m_heap;
 874                 changed = true;
 875 
 876                 m_heap.assertIsValid();
 877 
 878                 // We keep only pointers that are live, and only
 879                 // allocations that are either live, pointed to by a
 880                 // live pointer, or (recursively) stored in a field of
 881                 // a live allocation.
 882                 //
<a name="18" id="anc18"></a><span class="line-modified"> 883                 // This means we can accidentally leak non-dominating</span>
 884                 // nodes into the successor. However, due to the
 885                 // non-dominance property, we are guaranteed that the
 886                 // successor has at least one predecessor that is not
 887                 // dominated either: this means any reference to a
 888                 // non-dominating allocation in the successor will
 889                 // trigger an escape and get pruned during the merge.
 890                 m_heap.pruneByLiveness(m_combinedLiveness.liveAtTail[block]);
 891 
<a name="19" id="anc19"></a><span class="line-modified"> 892                 for (BasicBlock* successorBlock : block-&gt;successors()) {</span>
<span class="line-added"> 893                     // FIXME: Maybe we should:</span>
<span class="line-added"> 894                     // 1. Store the liveness pruned heap as part of m_heapAtTail</span>
<span class="line-added"> 895                     // 2. Move this code above where we make block merge with</span>
<span class="line-added"> 896                     // its predecessors before walking the block forward.</span>
<span class="line-added"> 897                     // https://bugs.webkit.org/show_bug.cgi?id=206041</span>
<span class="line-added"> 898                     LocalHeap heap = m_heapAtHead[successorBlock];</span>
 899                     m_heapAtHead[successorBlock].merge(m_heap);
<a name="20" id="anc20"></a><span class="line-added"> 900                     if (heap != m_heapAtHead[successorBlock])</span>
<span class="line-added"> 901                         changed = true;</span>
<span class="line-added"> 902                 }</span>
 903             }
 904         } while (changed);
 905     }
 906 
<a name="21" id="anc21"></a><span class="line-added"> 907     template&lt;typename InternalFieldClass&gt;</span>
<span class="line-added"> 908     Allocation* handleInternalFieldClass(Node* node, HashMap&lt;PromotedLocationDescriptor, LazyNode&gt;&amp; writes)</span>
<span class="line-added"> 909     {</span>
<span class="line-added"> 910         Allocation* result = &amp;m_heap.newAllocation(node, Allocation::Kind::InternalFieldObject);</span>
<span class="line-added"> 911         writes.add(StructurePLoc, LazyNode(m_graph.freeze(node-&gt;structure().get())));</span>
<span class="line-added"> 912         auto initialValues = InternalFieldClass::initialValues();</span>
<span class="line-added"> 913         static_assert(initialValues.size() == InternalFieldClass::numberOfInternalFields);</span>
<span class="line-added"> 914         for (unsigned index = 0; index &lt; initialValues.size(); ++index)</span>
<span class="line-added"> 915             writes.add(PromotedLocationDescriptor(InternalFieldObjectPLoc, index), LazyNode(m_graph.freeze(initialValues[index])));</span>
<span class="line-added"> 916 </span>
<span class="line-added"> 917         return result;</span>
<span class="line-added"> 918     }</span>
<span class="line-added"> 919 </span>
 920     template&lt;typename WriteFunctor, typename ResolveFunctor&gt;
 921     void handleNode(
 922         Node* node,
 923         const WriteFunctor&amp; heapWrite,
 924         const ResolveFunctor&amp; heapResolve)
 925     {
 926         m_heap.assertIsValid();
 927         ASSERT(m_heap.takeEscapees().isEmpty());
 928 
 929         Allocation* target = nullptr;
 930         HashMap&lt;PromotedLocationDescriptor, LazyNode&gt; writes;
 931         PromotedLocationDescriptor exactRead;
 932 
 933         switch (node-&gt;op()) {
 934         case NewObject:
 935             target = &amp;m_heap.newAllocation(node, Allocation::Kind::Object);
 936             target-&gt;setStructures(node-&gt;structure());
 937             writes.add(
 938                 StructurePLoc, LazyNode(m_graph.freeze(node-&gt;structure().get())));
 939             break;
 940 
 941         case NewFunction:
 942         case NewGeneratorFunction:
 943         case NewAsyncGeneratorFunction:
 944         case NewAsyncFunction: {
 945             if (isStillValid(node-&gt;castOperand&lt;FunctionExecutable*&gt;())) {
 946                 m_heap.escape(node-&gt;child1().node());
 947                 break;
 948             }
 949 
 950             if (node-&gt;op() == NewGeneratorFunction)
 951                 target = &amp;m_heap.newAllocation(node, Allocation::Kind::GeneratorFunction);
 952             else if (node-&gt;op() == NewAsyncFunction)
 953                 target = &amp;m_heap.newAllocation(node, Allocation::Kind::AsyncFunction);
 954             else if (node-&gt;op() == NewAsyncGeneratorFunction)
 955                 target = &amp;m_heap.newAllocation(node, Allocation::Kind::AsyncGeneratorFunction);
 956             else
 957                 target = &amp;m_heap.newAllocation(node, Allocation::Kind::Function);
 958 
 959             writes.add(FunctionExecutablePLoc, LazyNode(node-&gt;cellOperand()));
 960             writes.add(FunctionActivationPLoc, LazyNode(node-&gt;child1().node()));
 961             break;
 962         }
 963 
<a name="22" id="anc22"></a><span class="line-added"> 964         case NewArrayIterator: {</span>
<span class="line-added"> 965             target = handleInternalFieldClass&lt;JSArrayIterator&gt;(node, writes);</span>
<span class="line-added"> 966             break;</span>
<span class="line-added"> 967         }</span>
<span class="line-added"> 968 </span>
 969         case NewRegexp: {
 970             target = &amp;m_heap.newAllocation(node, Allocation::Kind::RegExpObject);
 971 
 972             writes.add(RegExpObjectRegExpPLoc, LazyNode(node-&gt;cellOperand()));
 973             writes.add(RegExpObjectLastIndexPLoc, LazyNode(node-&gt;child1().node()));
 974             break;
 975         }
 976 
 977         case CreateActivation: {
 978             if (isStillValid(node-&gt;castOperand&lt;SymbolTable*&gt;())) {
 979                 m_heap.escape(node-&gt;child1().node());
 980                 break;
 981             }
 982             target = &amp;m_heap.newAllocation(node, Allocation::Kind::Activation);
 983             writes.add(ActivationSymbolTablePLoc, LazyNode(node-&gt;cellOperand()));
 984             writes.add(ActivationScopePLoc, LazyNode(node-&gt;child1().node()));
 985             {
 986                 SymbolTable* symbolTable = node-&gt;castOperand&lt;SymbolTable*&gt;();
 987                 LazyNode initialValue(m_graph.freeze(node-&gt;initializationValueForActivation()));
 988                 for (unsigned offset = 0; offset &lt; symbolTable-&gt;scopeSize(); ++offset) {
 989                     writes.add(
 990                         PromotedLocationDescriptor(ClosureVarPLoc, offset),
 991                         initialValue);
 992                 }
 993             }
 994             break;
 995         }
 996 
 997         case PutStructure:
 998             target = m_heap.onlyLocalAllocation(node-&gt;child1().node());
 999             if (target &amp;&amp; target-&gt;isObjectAllocation()) {
1000                 writes.add(StructurePLoc, LazyNode(m_graph.freeze(JSValue(node-&gt;transition()-&gt;next.get()))));
1001                 target-&gt;setStructures(node-&gt;transition()-&gt;next);
1002             } else
1003                 m_heap.escape(node-&gt;child1().node());
1004             break;
1005 
1006         case CheckStructureOrEmpty:
1007         case CheckStructure: {
1008             Allocation* allocation = m_heap.onlyLocalAllocation(node-&gt;child1().node());
1009             if (allocation &amp;&amp; allocation-&gt;isObjectAllocation()) {
1010                 RegisteredStructureSet filteredStructures = allocation-&gt;structures();
1011                 filteredStructures.filter(node-&gt;structureSet());
1012                 if (filteredStructures.isEmpty()) {
1013                     // FIXME: Write a test for this:
1014                     // https://bugs.webkit.org/show_bug.cgi?id=174322
1015                     m_heap.escape(node-&gt;child1().node());
1016                     break;
1017                 }
1018                 allocation-&gt;setStructures(filteredStructures);
1019                 if (Node* value = heapResolve(PromotedHeapLocation(allocation-&gt;identifier(), StructurePLoc)))
1020                     node-&gt;convertToCheckStructureImmediate(value);
1021             } else
1022                 m_heap.escape(node-&gt;child1().node());
1023             break;
1024         }
1025 
1026         case GetByOffset:
1027         case GetGetterSetterByOffset:
1028             target = m_heap.onlyLocalAllocation(node-&gt;child2().node());
1029             if (target &amp;&amp; target-&gt;isObjectAllocation()) {
1030                 unsigned identifierNumber = node-&gt;storageAccessData().identifierNumber;
1031                 exactRead = PromotedLocationDescriptor(NamedPropertyPLoc, identifierNumber);
1032             } else {
1033                 m_heap.escape(node-&gt;child1().node());
1034                 m_heap.escape(node-&gt;child2().node());
1035             }
1036             break;
1037 
1038         case MultiGetByOffset: {
1039             Allocation* allocation = m_heap.onlyLocalAllocation(node-&gt;child1().node());
1040             if (allocation &amp;&amp; allocation-&gt;isObjectAllocation()) {
1041                 MultiGetByOffsetData&amp; data = node-&gt;multiGetByOffsetData();
1042                 RegisteredStructureSet validStructures;
1043                 bool hasInvalidStructures = false;
1044                 for (const auto&amp; multiGetByOffsetCase : data.cases) {
1045                     if (!allocation-&gt;structures().overlaps(multiGetByOffsetCase.set()))
1046                         continue;
1047 
1048                     switch (multiGetByOffsetCase.method().kind()) {
1049                     case GetByOffsetMethod::LoadFromPrototype: // We need to escape those
1050                     case GetByOffsetMethod::Constant: // We don&#39;t really have a way of expressing this
1051                         hasInvalidStructures = true;
1052                         break;
1053 
1054                     case GetByOffsetMethod::Load: // We&#39;re good
1055                         validStructures.merge(multiGetByOffsetCase.set());
1056                         break;
1057 
1058                     default:
1059                         RELEASE_ASSERT_NOT_REACHED();
1060                     }
1061                 }
1062                 if (hasInvalidStructures || validStructures.isEmpty()) {
1063                     m_heap.escape(node-&gt;child1().node());
1064                     break;
1065                 }
1066                 unsigned identifierNumber = data.identifierNumber;
1067                 PromotedHeapLocation location(NamedPropertyPLoc, allocation-&gt;identifier(), identifierNumber);
1068                 if (Node* value = heapResolve(location)) {
1069                     if (allocation-&gt;structures().isSubsetOf(validStructures))
1070                         node-&gt;replaceWithWithoutChecks(value);
1071                     else {
1072                         Node* structure = heapResolve(PromotedHeapLocation(allocation-&gt;identifier(), StructurePLoc));
1073                         ASSERT(structure);
1074                         allocation-&gt;filterStructures(validStructures);
1075                         node-&gt;convertToCheckStructure(m_graph.addStructureSet(allocation-&gt;structures()));
1076                         node-&gt;convertToCheckStructureImmediate(structure);
1077                         node-&gt;setReplacement(value);
1078                     }
1079                 } else if (!allocation-&gt;structures().isSubsetOf(validStructures)) {
1080                     // Even though we don&#39;t need the result here, we still need
1081                     // to make the call to tell our caller that we could need
1082                     // the StructurePLoc.
1083                     // The reason for this is that when we decide not to sink a
1084                     // node, we will still lower any read to its fields before
1085                     // it escapes (which are usually reads across a function
1086                     // call that DFGClobberize can&#39;t handle) - but we only do
1087                     // this for PromotedHeapLocations that we have seen read
1088                     // during the analysis!
1089                     heapResolve(PromotedHeapLocation(allocation-&gt;identifier(), StructurePLoc));
1090                     allocation-&gt;filterStructures(validStructures);
1091                 }
1092                 Node* identifier = allocation-&gt;get(location.descriptor());
1093                 if (identifier)
1094                     m_heap.newPointer(node, identifier);
1095             } else
1096                 m_heap.escape(node-&gt;child1().node());
1097             break;
1098         }
1099 
1100         case PutByOffset:
1101             target = m_heap.onlyLocalAllocation(node-&gt;child2().node());
1102             if (target &amp;&amp; target-&gt;isObjectAllocation()) {
1103                 unsigned identifierNumber = node-&gt;storageAccessData().identifierNumber;
1104                 writes.add(
1105                     PromotedLocationDescriptor(NamedPropertyPLoc, identifierNumber),
1106                     LazyNode(node-&gt;child3().node()));
1107             } else {
1108                 m_heap.escape(node-&gt;child1().node());
1109                 m_heap.escape(node-&gt;child2().node());
1110                 m_heap.escape(node-&gt;child3().node());
1111             }
1112             break;
1113 
1114         case GetClosureVar:
1115             target = m_heap.onlyLocalAllocation(node-&gt;child1().node());
1116             if (target &amp;&amp; target-&gt;isActivationAllocation()) {
1117                 exactRead =
1118                     PromotedLocationDescriptor(ClosureVarPLoc, node-&gt;scopeOffset().offset());
1119             } else
1120                 m_heap.escape(node-&gt;child1().node());
1121             break;
1122 
1123         case PutClosureVar:
1124             target = m_heap.onlyLocalAllocation(node-&gt;child1().node());
1125             if (target &amp;&amp; target-&gt;isActivationAllocation()) {
1126                 writes.add(
1127                     PromotedLocationDescriptor(ClosureVarPLoc, node-&gt;scopeOffset().offset()),
1128                     LazyNode(node-&gt;child2().node()));
1129             } else {
1130                 m_heap.escape(node-&gt;child1().node());
1131                 m_heap.escape(node-&gt;child2().node());
1132             }
1133             break;
1134 
1135         case SkipScope:
1136             target = m_heap.onlyLocalAllocation(node-&gt;child1().node());
1137             if (target &amp;&amp; target-&gt;isActivationAllocation())
1138                 exactRead = ActivationScopePLoc;
1139             else
1140                 m_heap.escape(node-&gt;child1().node());
1141             break;
1142 
1143         case GetExecutable:
1144             target = m_heap.onlyLocalAllocation(node-&gt;child1().node());
1145             if (target &amp;&amp; target-&gt;isFunctionAllocation())
1146                 exactRead = FunctionExecutablePLoc;
1147             else
1148                 m_heap.escape(node-&gt;child1().node());
1149             break;
1150 
1151         case GetScope:
1152             target = m_heap.onlyLocalAllocation(node-&gt;child1().node());
1153             if (target &amp;&amp; target-&gt;isFunctionAllocation())
1154                 exactRead = FunctionActivationPLoc;
1155             else
1156                 m_heap.escape(node-&gt;child1().node());
1157             break;
1158 
1159         case GetRegExpObjectLastIndex:
1160             target = m_heap.onlyLocalAllocation(node-&gt;child1().node());
1161             if (target &amp;&amp; target-&gt;isRegExpObjectAllocation())
1162                 exactRead = RegExpObjectLastIndexPLoc;
1163             else
1164                 m_heap.escape(node-&gt;child1().node());
1165             break;
1166 
1167         case SetRegExpObjectLastIndex:
1168             target = m_heap.onlyLocalAllocation(node-&gt;child1().node());
1169             if (target &amp;&amp; target-&gt;isRegExpObjectAllocation()) {
1170                 writes.add(
1171                     PromotedLocationDescriptor(RegExpObjectLastIndexPLoc),
1172                     LazyNode(node-&gt;child2().node()));
1173             } else {
1174                 m_heap.escape(node-&gt;child1().node());
1175                 m_heap.escape(node-&gt;child2().node());
1176             }
1177             break;
1178 
<a name="23" id="anc23"></a><span class="line-added">1179         case GetInternalField: {</span>
<span class="line-added">1180             target = m_heap.onlyLocalAllocation(node-&gt;child1().node());</span>
<span class="line-added">1181             if (target &amp;&amp; target-&gt;isInternalFieldObjectAllocation())</span>
<span class="line-added">1182                 exactRead = PromotedLocationDescriptor(InternalFieldObjectPLoc, node-&gt;internalFieldIndex());</span>
<span class="line-added">1183             else</span>
<span class="line-added">1184                 m_heap.escape(node-&gt;child1().node());</span>
<span class="line-added">1185             break;</span>
<span class="line-added">1186         }</span>
<span class="line-added">1187 </span>
<span class="line-added">1188         case PutInternalField: {</span>
<span class="line-added">1189             target = m_heap.onlyLocalAllocation(node-&gt;child1().node());</span>
<span class="line-added">1190             if (target &amp;&amp; target-&gt;isInternalFieldObjectAllocation())</span>
<span class="line-added">1191                 writes.add(PromotedLocationDescriptor(InternalFieldObjectPLoc, node-&gt;internalFieldIndex()), LazyNode(node-&gt;child2().node()));</span>
<span class="line-added">1192             else {</span>
<span class="line-added">1193                 m_heap.escape(node-&gt;child1().node());</span>
<span class="line-added">1194                 m_heap.escape(node-&gt;child2().node());</span>
<span class="line-added">1195             }</span>
<span class="line-added">1196             break;</span>
<span class="line-added">1197         }</span>
<span class="line-added">1198 </span>
1199         case Check:
1200         case CheckVarargs:
1201             m_graph.doToChildren(
1202                 node,
1203                 [&amp;] (Edge edge) {
1204                     if (edge.willNotHaveCheck())
1205                         return;
1206 
1207                     if (alreadyChecked(edge.useKind(), SpecObject))
1208                         return;
1209 
1210                     m_heap.escape(edge.node());
1211                 });
1212             break;
1213 
1214         case MovHint:
1215         case PutHint:
1216             // Handled by OSR availability analysis
1217             break;
1218 
1219         case FilterCallLinkStatus:
<a name="24" id="anc24"></a><span class="line-modified">1220         case FilterGetByStatus:</span>
1221         case FilterPutByIdStatus:
1222         case FilterInByIdStatus:
1223             break;
1224 
1225         default:
1226             m_graph.doToChildren(
1227                 node,
1228                 [&amp;] (Edge edge) {
1229                     m_heap.escape(edge.node());
1230                 });
1231             break;
1232         }
1233 
1234         if (exactRead) {
1235             ASSERT(target);
1236             ASSERT(writes.isEmpty());
1237             if (Node* value = heapResolve(PromotedHeapLocation(target-&gt;identifier(), exactRead))) {
1238                 ASSERT(!value-&gt;replacement());
1239                 node-&gt;replaceWith(m_graph, value);
1240             }
1241             Node* identifier = target-&gt;get(exactRead);
1242             if (identifier)
1243                 m_heap.newPointer(node, identifier);
1244         }
1245 
1246         for (auto entry : writes) {
1247             ASSERT(target);
1248             if (entry.value.isNode())
1249                 target-&gt;set(entry.key, m_heap.follow(entry.value.asNode()));
1250             else
1251                 target-&gt;remove(entry.key);
1252             heapWrite(PromotedHeapLocation(target-&gt;identifier(), entry.key), entry.value);
1253         }
1254 
1255         m_heap.assertIsValid();
1256     }
1257 
1258     bool determineSinkCandidates()
1259     {
1260         m_sinkCandidates.clear();
1261         m_materializationToEscapee.clear();
1262         m_materializationSiteToMaterializations.clear();
1263         m_materializationSiteToRecoveries.clear();
1264         m_materializationSiteToHints.clear();
1265 
1266         // Logically we wish to consider every allocation and sink
1267         // it. However, it is probably not profitable to sink an
1268         // allocation that will always escape. So, we only sink an
1269         // allocation if one of the following is true:
1270         //
1271         // 1) There exists a basic block with only backwards outgoing
1272         //    edges (or no outgoing edges) in which the node wasn&#39;t
1273         //    materialized. This is meant to catch
1274         //    effectively-infinite loops in which we don&#39;t need to
1275         //    have allocated the object.
1276         //
1277         // 2) There exists a basic block at the tail of which the node
1278         //    is dead and not materialized.
1279         //
1280         // 3) The sum of execution counts of the materializations is
1281         //    less than the sum of execution counts of the original
1282         //    node.
1283         //
1284         // We currently implement only rule #2.
1285         // FIXME: Implement the two other rules.
1286         // https://bugs.webkit.org/show_bug.cgi?id=137073 (rule #1)
1287         // https://bugs.webkit.org/show_bug.cgi?id=137074 (rule #3)
1288         //
1289         // However, these rules allow for a sunk object to be put into
1290         // a non-sunk one, which we don&#39;t support. We could solve this
1291         // by supporting PutHints on local allocations, making these
1292         // objects only partially correct, and we would need to adapt
1293         // the OSR availability analysis and OSR exit to handle
1294         // this. This would be totally doable, but would create a
1295         // super rare, and thus bug-prone, code path.
1296         // So, instead, we need to implement one of the following
1297         // closure rules:
1298         //
1299         // 1) If we put a sink candidate into a local allocation that
1300         //    is not a sink candidate, change our minds and don&#39;t
1301         //    actually sink the sink candidate.
1302         //
1303         // 2) If we put a sink candidate into a local allocation, that
1304         //    allocation becomes a sink candidate as well.
1305         //
1306         // We currently choose to implement closure rule #2.
1307         HashMap&lt;Node*, Vector&lt;Node*&gt;&gt; dependencies;
1308         bool hasUnescapedReads = false;
1309         for (BasicBlock* block : m_graph.blocksInPreOrder()) {
1310             m_heap = m_heapAtHead[block];
1311 
1312             for (Node* node : *block) {
1313                 handleNode(
1314                     node,
1315                     [&amp;] (PromotedHeapLocation location, LazyNode value) {
1316                         if (!value.isNode())
1317                             return;
1318 
1319                         Allocation* allocation = m_heap.onlyLocalAllocation(value.asNode());
1320                         if (allocation &amp;&amp; !allocation-&gt;isEscapedAllocation())
1321                             dependencies.add(allocation-&gt;identifier(), Vector&lt;Node*&gt;()).iterator-&gt;value.append(location.base());
1322                     },
1323                     [&amp;] (PromotedHeapLocation) -&gt; Node* {
1324                         hasUnescapedReads = true;
1325                         return nullptr;
1326                     });
1327             }
1328 
1329             // The sink candidates are initially the unescaped
1330             // allocations dying at tail of blocks
1331             NodeSet allocations;
1332             for (const auto&amp; entry : m_heap.allocations()) {
1333                 if (!entry.value.isEscapedAllocation())
1334                     allocations.addVoid(entry.key);
1335             }
1336 
1337             m_heap.pruneByLiveness(m_combinedLiveness.liveAtTail[block]);
1338 
1339             for (Node* identifier : allocations) {
1340                 if (!m_heap.isAllocation(identifier))
1341                     m_sinkCandidates.addVoid(identifier);
1342             }
1343         }
1344 
1345         auto forEachEscapee = [&amp;] (auto callback) {
1346             for (BasicBlock* block : m_graph.blocksInNaturalOrder()) {
1347                 m_heap = m_heapAtHead[block];
1348                 m_heap.setWantEscapees();
1349 
1350                 for (Node* node : *block) {
1351                     handleNode(
1352                         node,
1353                         [] (PromotedHeapLocation, LazyNode) { },
1354                         [] (PromotedHeapLocation) -&gt; Node* {
1355                             return nullptr;
1356                         });
1357                     auto escapees = m_heap.takeEscapees();
1358                     escapees.removeIf([&amp;] (const auto&amp; entry) { return !m_sinkCandidates.contains(entry.key); });
1359                     callback(escapees, node);
1360                 }
1361 
1362                 m_heap.pruneByLiveness(m_combinedLiveness.liveAtTail[block]);
1363 
1364                 {
1365                     HashMap&lt;Node*, Allocation&gt; escapingOnEdge;
1366                     for (const auto&amp; entry : m_heap.allocations()) {
1367                         if (entry.value.isEscapedAllocation())
1368                             continue;
1369 
1370                         bool mustEscape = false;
1371                         for (BasicBlock* successorBlock : block-&gt;successors()) {
1372                             if (!m_heapAtHead[successorBlock].isAllocation(entry.key)
1373                                 || m_heapAtHead[successorBlock].getAllocation(entry.key).isEscapedAllocation())
1374                                 mustEscape = true;
1375                         }
1376 
1377                         if (mustEscape &amp;&amp; m_sinkCandidates.contains(entry.key))
1378                             escapingOnEdge.add(entry.key, entry.value);
1379                     }
1380                     callback(escapingOnEdge, block-&gt;terminal());
1381                 }
1382             }
1383         };
1384 
1385         if (m_sinkCandidates.size()) {
1386             // If we&#39;re moving an allocation to `where` in the program, we need to ensure
1387             // we can still walk the stack at that point in the program for the
1388             // InlineCallFrame of the original allocation. Certain InlineCallFrames rely on
1389             // data in the stack when taking a stack trace. All allocation sites can do a
1390             // stack walk (we do a stack walk when we GC). Conservatively, we say we&#39;re
1391             // still ok to move this allocation if we are moving within the same InlineCallFrame.
1392             // We could be more precise here and do an analysis of stack writes. However,
1393             // this scenario is so rare that we just take the conservative-and-straight-forward
1394             // approach of checking that we&#39;re in the same InlineCallFrame.
1395 
1396             forEachEscapee([&amp;] (HashMap&lt;Node*, Allocation&gt;&amp; escapees, Node* where) {
1397                 for (Node* allocation : escapees.keys()) {
1398                     InlineCallFrame* inlineCallFrame = allocation-&gt;origin.semantic.inlineCallFrame();
1399                     if (!inlineCallFrame)
1400                         continue;
1401                     if ((inlineCallFrame-&gt;isClosureCall || inlineCallFrame-&gt;isVarargs()) &amp;&amp; inlineCallFrame != where-&gt;origin.semantic.inlineCallFrame())
1402                         m_sinkCandidates.remove(allocation);
1403                 }
1404             });
1405         }
1406 
1407         // Ensure that the set of sink candidates is closed for put operations
1408         // This is (2) as described above.
1409         Vector&lt;Node*&gt; worklist;
1410         worklist.appendRange(m_sinkCandidates.begin(), m_sinkCandidates.end());
1411 
1412         while (!worklist.isEmpty()) {
1413             for (Node* identifier : dependencies.get(worklist.takeLast())) {
1414                 if (m_sinkCandidates.add(identifier).isNewEntry)
1415                     worklist.append(identifier);
1416             }
1417         }
1418 
1419         if (m_sinkCandidates.isEmpty())
1420             return hasUnescapedReads;
1421 
1422         if (DFGObjectAllocationSinkingPhaseInternal::verbose)
1423             dataLog(&quot;Candidates: &quot;, listDump(m_sinkCandidates), &quot;\n&quot;);
1424 
1425 
1426         // Create the materialization nodes.
1427         forEachEscapee([&amp;] (HashMap&lt;Node*, Allocation&gt;&amp; escapees, Node* where) {
1428             placeMaterializations(WTFMove(escapees), where);
1429         });
1430 
1431         return hasUnescapedReads || !m_sinkCandidates.isEmpty();
1432     }
1433 
1434     void placeMaterializations(HashMap&lt;Node*, Allocation&gt; escapees, Node* where)
1435     {
1436         // First collect the hints that will be needed when the node
1437         // we materialize is still stored into other unescaped sink candidates.
1438         // The way to interpret this vector is:
1439         //
1440         // PromotedHeapLocation(NotEscapedAllocation, field) = identifierAllocation
1441         //
1442         // e.g:
1443         // PromotedHeapLocation(@PhantomNewFunction, FunctionActivationPLoc) = IdentifierOf(@MaterializeCreateActivation)
1444         // or:
1445         // PromotedHeapLocation(@PhantomCreateActivation, ClosureVarPLoc(x)) = IdentifierOf(@NewFunction)
1446         //
1447         // When the rhs of the `=` is to be materialized at this `where` point in the program
1448         // and IdentifierOf(Materialization) is the original sunken allocation of the materialization.
1449         //
1450         // The reason we need to collect all the `identifiers` here is that
1451         // we may materialize multiple versions of the allocation along control
1452         // flow edges. We will PutHint these values along those edges. However,
1453         // we also need to PutHint them when we join and have a Phi of the allocations.
1454         Vector&lt;std::pair&lt;PromotedHeapLocation, Node*&gt;&gt; hints;
1455         for (const auto&amp; entry : m_heap.allocations()) {
1456             if (escapees.contains(entry.key))
1457                 continue;
1458 
1459             for (const auto&amp; field : entry.value.fields()) {
1460                 ASSERT(m_sinkCandidates.contains(entry.key) || !escapees.contains(field.value));
1461                 auto iter = escapees.find(field.value);
1462                 if (iter != escapees.end()) {
1463                     ASSERT(m_sinkCandidates.contains(field.value));
1464                     hints.append(std::make_pair(PromotedHeapLocation(entry.key, field.key), field.value));
1465                 }
1466             }
1467         }
1468 
1469         // Now we need to order the materialization. Any order is
1470         // valid (as long as we materialize a node first if it is
1471         // needed for the materialization of another node, e.g. a
1472         // function&#39;s activation must be materialized before the
1473         // function itself), but we want to try minimizing the number
1474         // of times we have to place Puts to close cycles after a
1475         // materialization. In other words, we are trying to find the
1476         // minimum number of materializations to remove from the
1477         // materialization graph to make it a DAG, known as the
1478         // (vertex) feedback set problem. Unfortunately, this is a
1479         // NP-hard problem, which we don&#39;t want to solve exactly.
1480         //
1481         // Instead, we use a simple greedy procedure, that procedes as
1482         // follow:
1483         //  - While there is at least one node with no outgoing edge
1484         //    amongst the remaining materializations, materialize it
1485         //    first
1486         //
1487         //  - Similarily, while there is at least one node with no
1488         //    incoming edge amongst the remaining materializations,
1489         //    materialize it last.
1490         //
1491         //  - When both previous conditions are false, we have an
1492         //    actual cycle, and we need to pick a node to
1493         //    materialize. We try greedily to remove the &quot;pressure&quot; on
1494         //    the remaining nodes by choosing the node with maximum
1495         //    |incoming edges| * |outgoing edges| as a measure of how
1496         //    &quot;central&quot; to the graph it is. We materialize it first,
1497         //    so that all the recoveries will be Puts of things into
1498         //    it (rather than Puts of the materialization into other
1499         //    objects), which means we will have a single
1500         //    StoreBarrier.
1501 
1502 
1503         // Compute dependencies between materializations
1504         HashMap&lt;Node*, NodeSet&gt; dependencies;
1505         HashMap&lt;Node*, NodeSet&gt; reverseDependencies;
1506         HashMap&lt;Node*, NodeSet&gt; forMaterialization;
1507         for (const auto&amp; entry : escapees) {
1508             auto&amp; myDependencies = dependencies.add(entry.key, NodeSet()).iterator-&gt;value;
1509             auto&amp; myDependenciesForMaterialization = forMaterialization.add(entry.key, NodeSet()).iterator-&gt;value;
1510             reverseDependencies.add(entry.key, NodeSet());
1511             for (const auto&amp; field : entry.value.fields()) {
1512                 if (escapees.contains(field.value) &amp;&amp; field.value != entry.key) {
1513                     myDependencies.addVoid(field.value);
1514                     reverseDependencies.add(field.value, NodeSet()).iterator-&gt;value.addVoid(entry.key);
1515                     if (field.key.neededForMaterialization())
1516                         myDependenciesForMaterialization.addVoid(field.value);
1517                 }
1518             }
1519         }
1520 
1521         // Helper function to update the materialized set and the
1522         // dependencies
1523         NodeSet materialized;
1524         auto materialize = [&amp;] (Node* identifier) {
1525             materialized.addVoid(identifier);
1526             for (Node* dep : dependencies.get(identifier))
1527                 reverseDependencies.find(dep)-&gt;value.remove(identifier);
1528             for (Node* rdep : reverseDependencies.get(identifier)) {
1529                 dependencies.find(rdep)-&gt;value.remove(identifier);
1530                 forMaterialization.find(rdep)-&gt;value.remove(identifier);
1531             }
1532             dependencies.remove(identifier);
1533             reverseDependencies.remove(identifier);
1534             forMaterialization.remove(identifier);
1535         };
1536 
1537         // Nodes without remaining unmaterialized fields will be
1538         // materialized first - amongst the remaining unmaterialized
1539         // nodes
1540         StdList&lt;Allocation&gt; toMaterialize;
1541         auto firstPos = toMaterialize.begin();
1542         auto materializeFirst = [&amp;] (Allocation&amp;&amp; allocation) {
1543             materialize(allocation.identifier());
1544             // We need to insert *after* the current position
1545             if (firstPos != toMaterialize.end())
1546                 ++firstPos;
1547             firstPos = toMaterialize.insert(firstPos, WTFMove(allocation));
1548         };
1549 
1550         // Nodes that no other unmaterialized node points to will be
1551         // materialized last - amongst the remaining unmaterialized
1552         // nodes
1553         auto lastPos = toMaterialize.end();
1554         auto materializeLast = [&amp;] (Allocation&amp;&amp; allocation) {
1555             materialize(allocation.identifier());
1556             lastPos = toMaterialize.insert(lastPos, WTFMove(allocation));
1557         };
1558 
1559         // These are the promoted locations that contains some of the
1560         // allocations we are currently escaping. If they are a location on
1561         // some other allocation we are currently materializing, we will need
1562         // to &quot;recover&quot; their value with a real put once the corresponding
1563         // allocation is materialized; if they are a location on some other
1564         // not-yet-materialized allocation, we will need a PutHint.
1565         Vector&lt;PromotedHeapLocation&gt; toRecover;
1566 
1567         // This loop does the actual cycle breaking
1568         while (!escapees.isEmpty()) {
1569             materialized.clear();
1570 
1571             // Materialize nodes that won&#39;t require recoveries if we can
1572             for (auto&amp; entry : escapees) {
1573                 if (!forMaterialization.find(entry.key)-&gt;value.isEmpty())
1574                     continue;
1575 
1576                 if (dependencies.find(entry.key)-&gt;value.isEmpty()) {
1577                     materializeFirst(WTFMove(entry.value));
1578                     continue;
1579                 }
1580 
1581                 if (reverseDependencies.find(entry.key)-&gt;value.isEmpty()) {
1582                     materializeLast(WTFMove(entry.value));
1583                     continue;
1584                 }
1585             }
1586 
1587             // We reach this only if there is an actual cycle that needs
1588             // breaking. Because we do not want to solve a NP-hard problem
1589             // here, we just heuristically pick a node and materialize it
1590             // first.
1591             if (materialized.isEmpty()) {
1592                 uint64_t maxEvaluation = 0;
1593                 Allocation* bestAllocation = nullptr;
1594                 for (auto&amp; entry : escapees) {
1595                     if (!forMaterialization.find(entry.key)-&gt;value.isEmpty())
1596                         continue;
1597 
1598                     uint64_t evaluation =
1599                         static_cast&lt;uint64_t&gt;(dependencies.get(entry.key).size()) * reverseDependencies.get(entry.key).size();
1600                     if (evaluation &gt; maxEvaluation) {
1601                         maxEvaluation = evaluation;
1602                         bestAllocation = &amp;entry.value;
1603                     }
1604                 }
1605                 RELEASE_ASSERT(maxEvaluation &gt; 0);
1606 
1607                 materializeFirst(WTFMove(*bestAllocation));
1608             }
1609             RELEASE_ASSERT(!materialized.isEmpty());
1610 
1611             for (Node* identifier : materialized)
1612                 escapees.remove(identifier);
1613         }
1614 
1615         materialized.clear();
1616 
1617         NodeSet escaped;
1618         for (const Allocation&amp; allocation : toMaterialize)
1619             escaped.addVoid(allocation.identifier());
1620         for (const Allocation&amp; allocation : toMaterialize) {
1621             for (const auto&amp; field : allocation.fields()) {
1622                 if (escaped.contains(field.value) &amp;&amp; !materialized.contains(field.value))
1623                     toRecover.append(PromotedHeapLocation(allocation.identifier(), field.key));
1624             }
1625             materialized.addVoid(allocation.identifier());
1626         }
1627 
1628         Vector&lt;Node*&gt;&amp; materializations = m_materializationSiteToMaterializations.add(
1629             where, Vector&lt;Node*&gt;()).iterator-&gt;value;
1630 
1631         for (const Allocation&amp; allocation : toMaterialize) {
1632             Node* materialization = createMaterialization(allocation, where);
1633             materializations.append(materialization);
1634             m_materializationToEscapee.add(materialization, allocation.identifier());
1635         }
1636 
1637         if (!toRecover.isEmpty()) {
1638             m_materializationSiteToRecoveries.add(
1639                 where, Vector&lt;PromotedHeapLocation&gt;()).iterator-&gt;value.appendVector(toRecover);
1640         }
1641 
1642         // The hints need to be after the &quot;real&quot; recoveries so that we
1643         // don&#39;t hint not-yet-complete objects
1644         m_materializationSiteToHints.add(
1645             where, Vector&lt;std::pair&lt;PromotedHeapLocation, Node*&gt;&gt;()).iterator-&gt;value.appendVector(hints);
1646     }
1647 
1648     Node* createMaterialization(const Allocation&amp; allocation, Node* where)
1649     {
1650         // FIXME: This is the only place where we actually use the
1651         // fact that an allocation&#39;s identifier is indeed the node
1652         // that created the allocation.
1653         switch (allocation.kind()) {
1654         case Allocation::Kind::Object: {
1655             ObjectMaterializationData* data = m_graph.m_objectMaterializationData.add();
1656 
1657             return m_graph.addNode(
1658                 allocation.identifier()-&gt;prediction(), Node::VarArg, MaterializeNewObject,
1659                 where-&gt;origin.withSemantic(allocation.identifier()-&gt;origin.semantic),
1660                 OpInfo(m_graph.addStructureSet(allocation.structures())), OpInfo(data), 0, 0);
1661         }
1662 
1663         case Allocation::Kind::AsyncGeneratorFunction:
1664         case Allocation::Kind::AsyncFunction:
1665         case Allocation::Kind::GeneratorFunction:
1666         case Allocation::Kind::Function: {
1667             FrozenValue* executable = allocation.identifier()-&gt;cellOperand();
1668 
1669             NodeType nodeType;
1670             switch (allocation.kind()) {
1671             case Allocation::Kind::GeneratorFunction:
1672                 nodeType = NewGeneratorFunction;
1673                 break;
1674             case Allocation::Kind::AsyncGeneratorFunction:
1675                 nodeType = NewAsyncGeneratorFunction;
1676                 break;
1677             case Allocation::Kind::AsyncFunction:
1678                 nodeType = NewAsyncFunction;
1679                 break;
1680             default:
1681                 nodeType = NewFunction;
1682             }
1683 
1684             return m_graph.addNode(
1685                 allocation.identifier()-&gt;prediction(), nodeType,
1686                 where-&gt;origin.withSemantic(
1687                     allocation.identifier()-&gt;origin.semantic),
1688                 OpInfo(executable));
1689         }
1690 
<a name="25" id="anc25"></a><span class="line-added">1691         case Allocation::Kind::InternalFieldObject: {</span>
<span class="line-added">1692             ObjectMaterializationData* data = m_graph.m_objectMaterializationData.add();</span>
<span class="line-added">1693             return m_graph.addNode(</span>
<span class="line-added">1694                 allocation.identifier()-&gt;prediction(), Node::VarArg, MaterializeNewInternalFieldObject,</span>
<span class="line-added">1695                 where-&gt;origin.withSemantic(</span>
<span class="line-added">1696                     allocation.identifier()-&gt;origin.semantic),</span>
<span class="line-added">1697                 OpInfo(allocation.identifier()-&gt;structure()), OpInfo(data), 0, 0);</span>
<span class="line-added">1698         }</span>
<span class="line-added">1699 </span>
1700         case Allocation::Kind::Activation: {
1701             ObjectMaterializationData* data = m_graph.m_objectMaterializationData.add();
1702             FrozenValue* symbolTable = allocation.identifier()-&gt;cellOperand();
1703 
1704             return m_graph.addNode(
1705                 allocation.identifier()-&gt;prediction(), Node::VarArg, MaterializeCreateActivation,
1706                 where-&gt;origin.withSemantic(
1707                     allocation.identifier()-&gt;origin.semantic),
1708                 OpInfo(symbolTable), OpInfo(data), 0, 0);
1709         }
1710 
1711         case Allocation::Kind::RegExpObject: {
1712             FrozenValue* regExp = allocation.identifier()-&gt;cellOperand();
1713             return m_graph.addNode(
1714                 allocation.identifier()-&gt;prediction(), NewRegexp,
1715                 where-&gt;origin.withSemantic(
1716                     allocation.identifier()-&gt;origin.semantic),
1717                 OpInfo(regExp));
1718         }
1719 
1720         default:
1721             DFG_CRASH(m_graph, allocation.identifier(), &quot;Bad allocation kind&quot;);
1722         }
1723     }
1724 
1725     void promoteLocalHeap()
1726     {
1727         // Collect the set of heap locations that we will be operating
1728         // over.
1729         HashSet&lt;PromotedHeapLocation&gt; locations;
1730         for (BasicBlock* block : m_graph.blocksInNaturalOrder()) {
1731             m_heap = m_heapAtHead[block];
1732 
1733             for (Node* node : *block) {
1734                 handleNode(
1735                     node,
1736                     [&amp;] (PromotedHeapLocation location, LazyNode) {
1737                         // If the location is not on a sink candidate,
1738                         // we only sink it if it is read
1739                         if (m_sinkCandidates.contains(location.base()))
1740                             locations.addVoid(location);
1741                     },
1742                     [&amp;] (PromotedHeapLocation location) -&gt; Node* {
1743                         locations.addVoid(location);
1744                         return nullptr;
1745                     });
1746             }
1747         }
1748 
1749         // Figure out which locations belong to which allocations.
1750         m_locationsForAllocation.clear();
1751         for (PromotedHeapLocation location : locations) {
1752             auto result = m_locationsForAllocation.add(
1753                 location.base(),
1754                 Vector&lt;PromotedHeapLocation&gt;());
1755             ASSERT(!result.iterator-&gt;value.contains(location));
1756             result.iterator-&gt;value.append(location);
1757         }
1758 
1759         m_pointerSSA.reset();
1760         m_allocationSSA.reset();
1761 
1762         // Collect the set of &quot;variables&quot; that we will be sinking.
1763         m_locationToVariable.clear();
1764         m_nodeToVariable.clear();
1765         Vector&lt;Node*&gt; indexToNode;
1766         Vector&lt;PromotedHeapLocation&gt; indexToLocation;
1767 
1768         for (Node* index : m_sinkCandidates) {
1769             SSACalculator::Variable* variable = m_allocationSSA.newVariable();
1770             m_nodeToVariable.add(index, variable);
1771             ASSERT(indexToNode.size() == variable-&gt;index());
1772             indexToNode.append(index);
1773         }
1774 
1775         for (PromotedHeapLocation location : locations) {
1776             SSACalculator::Variable* variable = m_pointerSSA.newVariable();
1777             m_locationToVariable.add(location, variable);
1778             ASSERT(indexToLocation.size() == variable-&gt;index());
1779             indexToLocation.append(location);
1780         }
1781 
1782         // We insert all required constants at top of block 0 so that
1783         // they are inserted only once and we don&#39;t clutter the graph
1784         // with useless constants everywhere
1785         HashMap&lt;FrozenValue*, Node*&gt; lazyMapping;
1786         if (!m_bottom)
1787             m_bottom = m_insertionSet.insertConstant(0, m_graph.block(0)-&gt;at(0)-&gt;origin, jsNumber(1927));
1788 
1789         Vector&lt;HashSet&lt;PromotedHeapLocation&gt;&gt; hintsForPhi(m_sinkCandidates.size());
1790 
1791         for (BasicBlock* block : m_graph.blocksInNaturalOrder()) {
1792             m_heap = m_heapAtHead[block];
1793 
1794             for (unsigned nodeIndex = 0; nodeIndex &lt; block-&gt;size(); ++nodeIndex) {
1795                 Node* node = block-&gt;at(nodeIndex);
1796 
1797                 // Some named properties can be added conditionally,
1798                 // and that would necessitate bottoms
1799                 for (PromotedHeapLocation location : m_locationsForAllocation.get(node)) {
1800                     if (location.kind() != NamedPropertyPLoc)
1801                         continue;
1802 
1803                     SSACalculator::Variable* variable = m_locationToVariable.get(location);
1804                     m_pointerSSA.newDef(variable, block, m_bottom);
1805                 }
1806 
1807                 for (Node* materialization : m_materializationSiteToMaterializations.get(node)) {
1808                     Node* escapee = m_materializationToEscapee.get(materialization);
1809                     m_allocationSSA.newDef(m_nodeToVariable.get(escapee), block, materialization);
1810                 }
1811 
1812                 for (std::pair&lt;PromotedHeapLocation, Node*&gt; pair : m_materializationSiteToHints.get(node)) {
1813                     PromotedHeapLocation location = pair.first;
1814                     Node* identifier = pair.second;
1815                     // We&#39;re materializing `identifier` at this point, and the unmaterialized
1816                     // version is inside `location`. We track which SSA variable this belongs
1817                     // to in case we also need a PutHint for the Phi.
1818                     if (UNLIKELY(validationEnabled())) {
1819                         RELEASE_ASSERT(m_sinkCandidates.contains(location.base()));
1820                         RELEASE_ASSERT(m_sinkCandidates.contains(identifier));
1821 
1822                         bool found = false;
1823                         for (Node* materialization : m_materializationSiteToMaterializations.get(node)) {
1824                             // We&#39;re materializing `identifier` here. This asserts that this is indeed the case.
1825                             if (m_materializationToEscapee.get(materialization) == identifier) {
1826                                 found = true;
1827                                 break;
1828                             }
1829                         }
1830                         RELEASE_ASSERT(found);
1831                     }
1832 
1833                     SSACalculator::Variable* variable = m_nodeToVariable.get(identifier);
1834                     hintsForPhi[variable-&gt;index()].addVoid(location);
1835                 }
1836 
1837                 if (m_sinkCandidates.contains(node))
1838                     m_allocationSSA.newDef(m_nodeToVariable.get(node), block, node);
1839 
1840                 handleNode(
1841                     node,
1842                     [&amp;] (PromotedHeapLocation location, LazyNode value) {
1843                         if (!locations.contains(location))
1844                             return;
1845 
1846                         Node* nodeValue;
1847                         if (value.isNode())
1848                             nodeValue = value.asNode();
1849                         else {
1850                             auto iter = lazyMapping.find(value.asValue());
1851                             if (iter != lazyMapping.end())
1852                                 nodeValue = iter-&gt;value;
1853                             else {
1854                                 nodeValue = value.ensureIsNode(
1855                                     m_insertionSet, m_graph.block(0), 0);
1856                                 lazyMapping.add(value.asValue(), nodeValue);
1857                             }
1858                         }
1859 
1860                         SSACalculator::Variable* variable = m_locationToVariable.get(location);
1861                         m_pointerSSA.newDef(variable, block, nodeValue);
1862                     },
1863                     [] (PromotedHeapLocation) -&gt; Node* {
1864                         return nullptr;
1865                     });
1866             }
1867         }
1868         m_insertionSet.execute(m_graph.block(0));
1869 
1870         // Run the SSA calculators to create Phis
1871         m_pointerSSA.computePhis(
1872             [&amp;] (SSACalculator::Variable* variable, BasicBlock* block) -&gt; Node* {
1873                 PromotedHeapLocation location = indexToLocation[variable-&gt;index()];
1874 
1875                 // Don&#39;t create Phi nodes for fields of dead allocations
1876                 if (!m_heapAtHead[block].isAllocation(location.base()))
1877                     return nullptr;
1878 
1879                 // Don&#39;t create Phi nodes once we are escaped
1880                 if (m_heapAtHead[block].getAllocation(location.base()).isEscapedAllocation())
1881                     return nullptr;
1882 
1883                 // If we point to a single allocation, we will
1884                 // directly use its materialization
1885                 if (m_heapAtHead[block].follow(location))
1886                     return nullptr;
1887 
1888                 Node* phiNode = m_graph.addNode(SpecHeapTop, Phi, block-&gt;at(0)-&gt;origin.withInvalidExit());
1889                 phiNode-&gt;mergeFlags(NodeResultJS);
1890                 return phiNode;
1891             });
1892 
1893         m_allocationSSA.computePhis(
1894             [&amp;] (SSACalculator::Variable* variable, BasicBlock* block) -&gt; Node* {
1895                 Node* identifier = indexToNode[variable-&gt;index()];
1896 
1897                 // Don&#39;t create Phi nodes for dead allocations
1898                 if (!m_heapAtHead[block].isAllocation(identifier))
1899                     return nullptr;
1900 
1901                 // Don&#39;t create Phi nodes until we are escaped
1902                 if (!m_heapAtHead[block].getAllocation(identifier).isEscapedAllocation())
1903                     return nullptr;
1904 
1905                 Node* phiNode = m_graph.addNode(SpecHeapTop, Phi, block-&gt;at(0)-&gt;origin.withInvalidExit());
1906                 phiNode-&gt;mergeFlags(NodeResultJS);
1907                 return phiNode;
1908             });
1909 
1910         // Place Phis in the right places, replace all uses of any load with the appropriate
1911         // value, and create the materialization nodes.
1912         LocalOSRAvailabilityCalculator availabilityCalculator(m_graph);
1913         m_graph.clearReplacements();
1914         for (BasicBlock* block : m_graph.blocksInPreOrder()) {
1915             m_heap = m_heapAtHead[block];
1916             availabilityCalculator.beginBlock(block);
1917 
1918             // These mapping tables are intended to be lazy. If
1919             // something is omitted from the table, it means that
1920             // there haven&#39;t been any local stores to the promoted
1921             // heap location (or any local materialization).
1922             m_localMapping.clear();
1923             m_escapeeToMaterialization.clear();
1924 
1925             // Insert the Phi functions that we had previously
1926             // created.
1927             for (SSACalculator::Def* phiDef : m_pointerSSA.phisForBlock(block)) {
1928                 SSACalculator::Variable* variable = phiDef-&gt;variable();
1929                 m_insertionSet.insert(0, phiDef-&gt;value());
1930 
1931                 PromotedHeapLocation location = indexToLocation[variable-&gt;index()];
1932                 m_localMapping.set(location, phiDef-&gt;value());
1933 
1934                 if (m_sinkCandidates.contains(location.base())) {
1935                     m_insertionSet.insert(
1936                         0,
1937                         location.createHint(
1938                             m_graph, block-&gt;at(0)-&gt;origin.withInvalidExit(), phiDef-&gt;value()));
1939                 }
1940             }
1941 
1942             for (SSACalculator::Def* phiDef : m_allocationSSA.phisForBlock(block)) {
1943                 SSACalculator::Variable* variable = phiDef-&gt;variable();
1944                 m_insertionSet.insert(0, phiDef-&gt;value());
1945 
1946                 Node* identifier = indexToNode[variable-&gt;index()];
1947                 m_escapeeToMaterialization.add(identifier, phiDef-&gt;value());
1948                 bool canExit = false;
1949                 insertOSRHintsForUpdate(
1950                     0, block-&gt;at(0)-&gt;origin, canExit,
1951                     availabilityCalculator.m_availability, identifier, phiDef-&gt;value());
1952 
1953                 for (PromotedHeapLocation location : hintsForPhi[variable-&gt;index()]) {
<a name="26" id="anc26"></a><span class="line-modified">1954                     if (m_heap.isUnescapedAllocation(location.base())) {</span>
1955                         m_insertionSet.insert(0,
1956                             location.createHint(m_graph, block-&gt;at(0)-&gt;origin.withInvalidExit(), phiDef-&gt;value()));
1957                         m_localMapping.set(location, phiDef-&gt;value());
1958                     }
1959                 }
1960             }
1961 
1962             if (DFGObjectAllocationSinkingPhaseInternal::verbose) {
1963                 dataLog(&quot;Local mapping at &quot;, pointerDump(block), &quot;: &quot;, mapDump(m_localMapping), &quot;\n&quot;);
1964                 dataLog(&quot;Local materializations at &quot;, pointerDump(block), &quot;: &quot;, mapDump(m_escapeeToMaterialization), &quot;\n&quot;);
1965             }
1966 
1967             for (unsigned nodeIndex = 0; nodeIndex &lt; block-&gt;size(); ++nodeIndex) {
1968                 Node* node = block-&gt;at(nodeIndex);
1969                 bool canExit = true;
1970                 bool nextCanExit = node-&gt;origin.exitOK;
1971                 for (PromotedHeapLocation location : m_locationsForAllocation.get(node)) {
1972                     if (location.kind() != NamedPropertyPLoc)
1973                         continue;
1974 
1975                     m_localMapping.set(location, m_bottom);
1976 
1977                     if (m_sinkCandidates.contains(node)) {
1978                         if (DFGObjectAllocationSinkingPhaseInternal::verbose)
1979                             dataLog(&quot;For sink candidate &quot;, node, &quot; found location &quot;, location, &quot;\n&quot;);
1980                         m_insertionSet.insert(
1981                             nodeIndex + 1,
1982                             location.createHint(
1983                                 m_graph, node-&gt;origin.takeValidExit(nextCanExit), m_bottom));
1984                     }
1985                 }
1986 
1987                 for (Node* materialization : m_materializationSiteToMaterializations.get(node)) {
1988                     materialization-&gt;origin.exitOK &amp;= canExit;
1989                     Node* escapee = m_materializationToEscapee.get(materialization);
1990                     populateMaterialization(block, materialization, escapee);
1991                     m_escapeeToMaterialization.set(escapee, materialization);
1992                     m_insertionSet.insert(nodeIndex, materialization);
1993                     if (DFGObjectAllocationSinkingPhaseInternal::verbose)
1994                         dataLog(&quot;Materializing &quot;, escapee, &quot; =&gt; &quot;, materialization, &quot; at &quot;, node, &quot;\n&quot;);
1995                 }
1996 
1997                 for (PromotedHeapLocation location : m_materializationSiteToRecoveries.get(node))
1998                     m_insertionSet.insert(nodeIndex, createRecovery(block, location, node, canExit));
1999                 for (std::pair&lt;PromotedHeapLocation, Node*&gt; pair : m_materializationSiteToHints.get(node))
2000                     m_insertionSet.insert(nodeIndex, createRecovery(block, pair.first, node, canExit));
2001 
2002                 // We need to put the OSR hints after the recoveries,
2003                 // because we only want the hints once the object is
2004                 // complete
2005                 for (Node* materialization : m_materializationSiteToMaterializations.get(node)) {
2006                     Node* escapee = m_materializationToEscapee.get(materialization);
2007                     insertOSRHintsForUpdate(
2008                         nodeIndex, node-&gt;origin, canExit,
2009                         availabilityCalculator.m_availability, escapee, materialization);
2010                 }
2011 
2012                 if (node-&gt;origin.exitOK &amp;&amp; !canExit) {
2013                     // We indicate that the exit state is fine now. It is OK because we updated the
2014                     // state above. We need to indicate this manually because the validation doesn&#39;t
2015                     // have enough information to infer that the exit state is fine.
2016                     m_insertionSet.insertNode(nodeIndex, SpecNone, ExitOK, node-&gt;origin);
2017                 }
2018 
2019                 if (m_sinkCandidates.contains(node))
2020                     m_escapeeToMaterialization.set(node, node);
2021 
2022                 availabilityCalculator.executeNode(node);
2023 
2024                 bool desiredNextExitOK = node-&gt;origin.exitOK &amp;&amp; !clobbersExitState(m_graph, node);
2025 
2026                 bool doLower = false;
2027                 handleNode(
2028                     node,
2029                     [&amp;] (PromotedHeapLocation location, LazyNode value) {
2030                         if (!locations.contains(location))
2031                             return;
2032 
2033                         Node* nodeValue;
2034                         if (value.isNode())
2035                             nodeValue = value.asNode();
2036                         else
2037                             nodeValue = lazyMapping.get(value.asValue());
2038 
2039                         nodeValue = resolve(block, nodeValue);
2040 
2041                         m_localMapping.set(location, nodeValue);
2042 
2043                         if (!m_sinkCandidates.contains(location.base()))
2044                             return;
2045 
2046                         doLower = true;
2047 
2048                         if (DFGObjectAllocationSinkingPhaseInternal::verbose)
2049                             dataLog(&quot;Creating hint with value &quot;, nodeValue, &quot; before &quot;, node, &quot;\n&quot;);
2050                         m_insertionSet.insert(
2051                             nodeIndex + 1,
2052                             location.createHint(
2053                                 m_graph, node-&gt;origin.takeValidExit(nextCanExit), nodeValue));
2054                     },
2055                     [&amp;] (PromotedHeapLocation location) -&gt; Node* {
2056                         return resolve(block, location);
2057                     });
2058 
2059                 if (!nextCanExit &amp;&amp; desiredNextExitOK) {
2060                     // We indicate that the exit state is fine now. We need to do this because we
2061                     // emitted hints that appear to invalidate the exit state.
2062                     m_insertionSet.insertNode(nodeIndex + 1, SpecNone, ExitOK, node-&gt;origin);
2063                 }
2064 
2065                 if (m_sinkCandidates.contains(node) || doLower) {
2066                     switch (node-&gt;op()) {
2067                     case NewObject:
2068                         node-&gt;convertToPhantomNewObject();
2069                         break;
2070 
2071                     case NewFunction:
2072                         node-&gt;convertToPhantomNewFunction();
2073                         break;
2074 
2075                     case NewGeneratorFunction:
2076                         node-&gt;convertToPhantomNewGeneratorFunction();
2077                         break;
2078 
2079                     case NewAsyncGeneratorFunction:
2080                         node-&gt;convertToPhantomNewAsyncGeneratorFunction();
2081                         break;
2082 
2083                     case NewAsyncFunction:
2084                         node-&gt;convertToPhantomNewAsyncFunction();
2085                         break;
2086 
<a name="27" id="anc27"></a><span class="line-added">2087                     case NewArrayIterator:</span>
<span class="line-added">2088                         node-&gt;convertToPhantomNewArrayIterator();</span>
<span class="line-added">2089                         break;</span>
<span class="line-added">2090 </span>
2091                     case CreateActivation:
2092                         node-&gt;convertToPhantomCreateActivation();
2093                         break;
2094 
2095                     case NewRegexp:
2096                         node-&gt;convertToPhantomNewRegexp();
2097                         break;
2098 
2099                     default:
2100                         node-&gt;remove(m_graph);
2101                         break;
2102                     }
2103                 }
2104 
2105                 m_graph.doToChildren(
2106                     node,
2107                     [&amp;] (Edge&amp; edge) {
2108                         edge.setNode(resolve(block, edge.node()));
2109                     });
2110             }
2111 
2112             // Gotta drop some Upsilons.
2113             NodeAndIndex terminal = block-&gt;findTerminal();
2114             size_t upsilonInsertionPoint = terminal.index;
2115             NodeOrigin upsilonOrigin = terminal.node-&gt;origin;
2116             for (BasicBlock* successorBlock : block-&gt;successors()) {
2117                 for (SSACalculator::Def* phiDef : m_pointerSSA.phisForBlock(successorBlock)) {
2118                     Node* phiNode = phiDef-&gt;value();
2119                     SSACalculator::Variable* variable = phiDef-&gt;variable();
2120                     PromotedHeapLocation location = indexToLocation[variable-&gt;index()];
2121                     Node* incoming = resolve(block, location);
2122 
2123                     m_insertionSet.insertNode(
2124                         upsilonInsertionPoint, SpecNone, Upsilon, upsilonOrigin,
2125                         OpInfo(phiNode), incoming-&gt;defaultEdge());
2126                 }
2127 
2128                 for (SSACalculator::Def* phiDef : m_allocationSSA.phisForBlock(successorBlock)) {
2129                     Node* phiNode = phiDef-&gt;value();
2130                     SSACalculator::Variable* variable = phiDef-&gt;variable();
2131                     Node* incoming = getMaterialization(block, indexToNode[variable-&gt;index()]);
2132 
2133                     m_insertionSet.insertNode(
2134                         upsilonInsertionPoint, SpecNone, Upsilon, upsilonOrigin,
2135                         OpInfo(phiNode), incoming-&gt;defaultEdge());
2136                 }
2137             }
2138 
2139             m_insertionSet.execute(block);
2140         }
2141     }
2142 
2143     NEVER_INLINE Node* resolve(BasicBlock* block, PromotedHeapLocation location)
2144     {
2145         // If we are currently pointing to a single local allocation,
2146         // simply return the associated materialization.
2147         if (Node* identifier = m_heap.follow(location))
2148             return getMaterialization(block, identifier);
2149 
2150         if (Node* result = m_localMapping.get(location))
2151             return result;
2152 
2153         // This implies that there is no local mapping. Find a non-local mapping.
2154         SSACalculator::Def* def = m_pointerSSA.nonLocalReachingDef(
2155             block, m_locationToVariable.get(location));
2156         ASSERT(def);
2157         ASSERT(def-&gt;value());
2158 
2159         Node* result = def-&gt;value();
2160         if (result-&gt;replacement())
2161             result = result-&gt;replacement();
2162         ASSERT(!result-&gt;replacement());
2163 
2164         m_localMapping.add(location, result);
2165         return result;
2166     }
2167 
2168     NEVER_INLINE Node* resolve(BasicBlock* block, Node* node)
2169     {
2170         // If we are currently pointing to a single local allocation,
2171         // simply return the associated materialization.
2172         if (Node* identifier = m_heap.follow(node))
2173             return getMaterialization(block, identifier);
2174 
2175         if (node-&gt;replacement())
2176             node = node-&gt;replacement();
2177         ASSERT(!node-&gt;replacement());
2178 
2179         return node;
2180     }
2181 
2182     NEVER_INLINE Node* getMaterialization(BasicBlock* block, Node* identifier)
2183     {
2184         ASSERT(m_heap.isAllocation(identifier));
2185         if (!m_sinkCandidates.contains(identifier))
2186             return identifier;
2187 
2188         if (Node* materialization = m_escapeeToMaterialization.get(identifier))
2189             return materialization;
2190 
2191         SSACalculator::Def* def = m_allocationSSA.nonLocalReachingDef(
2192             block, m_nodeToVariable.get(identifier));
2193         ASSERT(def &amp;&amp; def-&gt;value());
2194         m_escapeeToMaterialization.add(identifier, def-&gt;value());
2195         ASSERT(!def-&gt;value()-&gt;replacement());
2196         return def-&gt;value();
2197     }
2198 
2199     void insertOSRHintsForUpdate(unsigned nodeIndex, NodeOrigin origin, bool&amp; canExit, AvailabilityMap&amp; availability, Node* escapee, Node* materialization)
2200     {
2201         if (DFGObjectAllocationSinkingPhaseInternal::verbose) {
2202             dataLog(&quot;Inserting OSR hints at &quot;, origin, &quot;:\n&quot;);
2203             dataLog(&quot;    Escapee: &quot;, escapee, &quot;\n&quot;);
2204             dataLog(&quot;    Materialization: &quot;, materialization, &quot;\n&quot;);
2205             dataLog(&quot;    Availability: &quot;, availability, &quot;\n&quot;);
2206         }
2207 
2208         // We need to follow() the value in the heap.
2209         // Consider the following graph:
2210         //
2211         // Block #0
2212         //   0: NewObject({})
2213         //   1: NewObject({})
2214         //   -: PutByOffset(@0, @1, x:0)
2215         //   -: PutStructure(@0, {x:0})
2216         //   2: GetByOffset(@0, x:0)
2217         //   -: MovHint(@2, loc1)
2218         //   -: Branch(#1, #2)
2219         //
2220         // Block #1
2221         //   3: Call(f, @1)
2222         //   4: Return(@0)
2223         //
2224         // Block #2
2225         //   -: Return(undefined)
2226         //
2227         // We need to materialize @1 at @3, and when doing so we need
2228         // to insert a MovHint for the materialization into loc1 as
2229         // well.
2230         // In order to do this, we say that we need to insert an
2231         // update hint for any availability whose node resolve()s to
2232         // the materialization.
2233         for (auto entry : availability.m_heap) {
2234             if (!entry.value.hasNode())
2235                 continue;
2236             if (m_heap.follow(entry.value.node()) != escapee)
2237                 continue;
2238 
2239             m_insertionSet.insert(
2240                 nodeIndex,
2241                 entry.key.createHint(m_graph, origin.takeValidExit(canExit), materialization));
2242         }
2243 
2244         for (unsigned i = availability.m_locals.size(); i--;) {
2245             if (!availability.m_locals[i].hasNode())
2246                 continue;
2247             if (m_heap.follow(availability.m_locals[i].node()) != escapee)
2248                 continue;
2249 
<a name="28" id="anc28"></a><span class="line-modified">2250             Operand operand = availability.m_locals.operandForIndex(i);</span>
2251             m_insertionSet.insertNode(
2252                 nodeIndex, SpecNone, MovHint, origin.takeValidExit(canExit), OpInfo(operand),
2253                 materialization-&gt;defaultEdge());
2254         }
2255     }
2256 
2257     void populateMaterialization(BasicBlock* block, Node* node, Node* escapee)
2258     {
2259         Allocation&amp; allocation = m_heap.getAllocation(escapee);
2260         switch (node-&gt;op()) {
2261         case MaterializeNewObject: {
2262             ObjectMaterializationData&amp; data = node-&gt;objectMaterializationData();
2263             unsigned firstChild = m_graph.m_varArgChildren.size();
2264 
2265             Vector&lt;PromotedHeapLocation&gt; locations = m_locationsForAllocation.get(escapee);
2266 
2267             PromotedHeapLocation structure(StructurePLoc, allocation.identifier());
2268             ASSERT(locations.contains(structure));
2269 
2270             m_graph.m_varArgChildren.append(Edge(resolve(block, structure), KnownCellUse));
2271 
2272             for (PromotedHeapLocation location : locations) {
2273                 switch (location.kind()) {
2274                 case StructurePLoc:
2275                     ASSERT(location == structure);
2276                     break;
2277 
2278                 case NamedPropertyPLoc: {
2279                     ASSERT(location.base() == allocation.identifier());
2280                     data.m_properties.append(location.descriptor());
2281                     Node* value = resolve(block, location);
2282                     if (m_sinkCandidates.contains(value))
2283                         m_graph.m_varArgChildren.append(m_bottom);
2284                     else
2285                         m_graph.m_varArgChildren.append(value);
2286                     break;
2287                 }
2288 
2289                 default:
2290                     DFG_CRASH(m_graph, node, &quot;Bad location kind&quot;);
2291                 }
2292             }
2293 
2294             node-&gt;children = AdjacencyList(
2295                 AdjacencyList::Variable,
2296                 firstChild, m_graph.m_varArgChildren.size() - firstChild);
2297             break;
2298         }
2299 
2300         case MaterializeCreateActivation: {
2301             ObjectMaterializationData&amp; data = node-&gt;objectMaterializationData();
2302 
2303             unsigned firstChild = m_graph.m_varArgChildren.size();
2304 
2305             Vector&lt;PromotedHeapLocation&gt; locations = m_locationsForAllocation.get(escapee);
2306 
2307             PromotedHeapLocation symbolTable(ActivationSymbolTablePLoc, allocation.identifier());
2308             ASSERT(locations.contains(symbolTable));
2309             ASSERT(node-&gt;cellOperand() == resolve(block, symbolTable)-&gt;constant());
2310             m_graph.m_varArgChildren.append(Edge(resolve(block, symbolTable), KnownCellUse));
2311 
2312             PromotedHeapLocation scope(ActivationScopePLoc, allocation.identifier());
2313             ASSERT(locations.contains(scope));
2314             m_graph.m_varArgChildren.append(Edge(resolve(block, scope), KnownCellUse));
2315 
2316             for (PromotedHeapLocation location : locations) {
2317                 switch (location.kind()) {
2318                 case ActivationScopePLoc: {
2319                     ASSERT(location == scope);
2320                     break;
2321                 }
2322 
2323                 case ActivationSymbolTablePLoc: {
2324                     ASSERT(location == symbolTable);
2325                     break;
2326                 }
2327 
2328                 case ClosureVarPLoc: {
2329                     ASSERT(location.base() == allocation.identifier());
2330                     data.m_properties.append(location.descriptor());
2331                     Node* value = resolve(block, location);
2332                     if (m_sinkCandidates.contains(value))
2333                         m_graph.m_varArgChildren.append(m_bottom);
2334                     else
2335                         m_graph.m_varArgChildren.append(value);
2336                     break;
2337                 }
2338 
2339                 default:
2340                     DFG_CRASH(m_graph, node, &quot;Bad location kind&quot;);
2341                 }
2342             }
2343 
2344             node-&gt;children = AdjacencyList(
2345                 AdjacencyList::Variable,
2346                 firstChild, m_graph.m_varArgChildren.size() - firstChild);
2347             break;
2348         }
2349 
2350         case NewFunction:
2351         case NewGeneratorFunction:
2352         case NewAsyncGeneratorFunction:
2353         case NewAsyncFunction: {
2354             Vector&lt;PromotedHeapLocation&gt; locations = m_locationsForAllocation.get(escapee);
2355             ASSERT(locations.size() == 2);
2356 
2357             PromotedHeapLocation executable(FunctionExecutablePLoc, allocation.identifier());
2358             ASSERT_UNUSED(executable, locations.contains(executable));
2359 
2360             PromotedHeapLocation activation(FunctionActivationPLoc, allocation.identifier());
2361             ASSERT(locations.contains(activation));
2362 
2363             node-&gt;child1() = Edge(resolve(block, activation), KnownCellUse);
2364             break;
2365         }
2366 
<a name="29" id="anc29"></a><span class="line-added">2367         case MaterializeNewInternalFieldObject: {</span>
<span class="line-added">2368             ObjectMaterializationData&amp; data = node-&gt;objectMaterializationData();</span>
<span class="line-added">2369 </span>
<span class="line-added">2370             unsigned firstChild = m_graph.m_varArgChildren.size();</span>
<span class="line-added">2371 </span>
<span class="line-added">2372             Vector&lt;PromotedHeapLocation&gt; locations = m_locationsForAllocation.get(escapee);</span>
<span class="line-added">2373 </span>
<span class="line-added">2374             PromotedHeapLocation structure(StructurePLoc, allocation.identifier());</span>
<span class="line-added">2375             ASSERT(locations.contains(structure));</span>
<span class="line-added">2376             m_graph.m_varArgChildren.append(Edge(resolve(block, structure), KnownCellUse));</span>
<span class="line-added">2377 </span>
<span class="line-added">2378             for (PromotedHeapLocation location : locations) {</span>
<span class="line-added">2379                 switch (location.kind()) {</span>
<span class="line-added">2380                 case StructurePLoc: {</span>
<span class="line-added">2381                     ASSERT(location == structure);</span>
<span class="line-added">2382                     break;</span>
<span class="line-added">2383                 }</span>
<span class="line-added">2384 </span>
<span class="line-added">2385                 case InternalFieldObjectPLoc: {</span>
<span class="line-added">2386                     ASSERT(location.base() == allocation.identifier());</span>
<span class="line-added">2387                     data.m_properties.append(location.descriptor());</span>
<span class="line-added">2388                     Node* value = resolve(block, location);</span>
<span class="line-added">2389                     if (m_sinkCandidates.contains(value))</span>
<span class="line-added">2390                         m_graph.m_varArgChildren.append(m_bottom);</span>
<span class="line-added">2391                     else</span>
<span class="line-added">2392                         m_graph.m_varArgChildren.append(value);</span>
<span class="line-added">2393                     break;</span>
<span class="line-added">2394                 }</span>
<span class="line-added">2395 </span>
<span class="line-added">2396                 default:</span>
<span class="line-added">2397                     DFG_CRASH(m_graph, node, &quot;Bad location kind&quot;);</span>
<span class="line-added">2398                 }</span>
<span class="line-added">2399             }</span>
<span class="line-added">2400 </span>
<span class="line-added">2401             node-&gt;children = AdjacencyList(</span>
<span class="line-added">2402                 AdjacencyList::Variable,</span>
<span class="line-added">2403                 firstChild, m_graph.m_varArgChildren.size() - firstChild);</span>
<span class="line-added">2404             break;</span>
<span class="line-added">2405         }</span>
<span class="line-added">2406 </span>
2407         case NewRegexp: {
2408             Vector&lt;PromotedHeapLocation&gt; locations = m_locationsForAllocation.get(escapee);
2409             ASSERT(locations.size() == 2);
2410 
2411             PromotedHeapLocation regExp(RegExpObjectRegExpPLoc, allocation.identifier());
2412             ASSERT_UNUSED(regExp, locations.contains(regExp));
2413 
2414             PromotedHeapLocation lastIndex(RegExpObjectLastIndexPLoc, allocation.identifier());
2415             ASSERT(locations.contains(lastIndex));
2416             Node* value = resolve(block, lastIndex);
2417             if (m_sinkCandidates.contains(value))
2418                 node-&gt;child1() = Edge(m_bottom);
2419             else
2420                 node-&gt;child1() = Edge(value);
2421             break;
2422         }
2423 
2424         default:
2425             DFG_CRASH(m_graph, node, &quot;Bad materialize op&quot;);
2426         }
2427     }
2428 
2429     Node* createRecovery(BasicBlock* block, PromotedHeapLocation location, Node* where, bool&amp; canExit)
2430     {
2431         if (DFGObjectAllocationSinkingPhaseInternal::verbose)
2432             dataLog(&quot;Recovering &quot;, location, &quot; at &quot;, where, &quot;\n&quot;);
2433         ASSERT(location.base()-&gt;isPhantomAllocation());
2434         Node* base = getMaterialization(block, location.base());
2435         Node* value = resolve(block, location);
2436 
2437         NodeOrigin origin = where-&gt;origin.withSemantic(base-&gt;origin.semantic);
2438 
2439         if (DFGObjectAllocationSinkingPhaseInternal::verbose)
2440             dataLog(&quot;Base is &quot;, base, &quot; and value is &quot;, value, &quot;\n&quot;);
2441 
2442         if (base-&gt;isPhantomAllocation()) {
2443             return PromotedHeapLocation(base, location.descriptor()).createHint(
2444                 m_graph, origin.takeValidExit(canExit), value);
2445         }
2446 
2447         switch (location.kind()) {
2448         case NamedPropertyPLoc: {
2449             Allocation&amp; allocation = m_heap.getAllocation(location.base());
2450 
2451             unsigned identifierNumber = location.info();
2452             UniquedStringImpl* uid = m_graph.identifiers()[identifierNumber];
2453 
2454             Vector&lt;RegisteredStructure&gt; structures;
2455             for (RegisteredStructure structure : allocation.structures()) {
2456                 // This structure set is conservative. This set can include Structure which does not have a legit property.
2457                 // We filter out such an apparently inappropriate structures here since MultiPutByOffset assumes all the structures
2458                 // have valid corresponding offset for the given property.
2459                 if (structure-&gt;getConcurrently(uid) != invalidOffset)
2460                     structures.append(structure);
2461             }
2462 
2463             // Since we filter structures, it is possible that we no longer have any structures here. In this case, we emit ForceOSRExit.
2464             if (structures.isEmpty())
2465                 return m_graph.addNode(ForceOSRExit, origin.takeValidExit(canExit));
2466 
2467             std::sort(
2468                 structures.begin(),
2469                 structures.end(),
2470                 [uid] (RegisteredStructure a, RegisteredStructure b) -&gt; bool {
2471                     return a-&gt;getConcurrently(uid) &lt; b-&gt;getConcurrently(uid);
2472                 });
2473 
2474             RELEASE_ASSERT(structures.size());
2475             PropertyOffset firstOffset = structures[0]-&gt;getConcurrently(uid);
2476 
2477             if (firstOffset == structures.last()-&gt;getConcurrently(uid)) {
2478                 Node* storage = base;
2479                 // FIXME: When we decide to sink objects with a
2480                 // property storage, we should handle non-inline offsets.
2481                 RELEASE_ASSERT(isInlineOffset(firstOffset));
2482 
2483                 StorageAccessData* data = m_graph.m_storageAccessData.add();
2484                 data-&gt;offset = firstOffset;
2485                 data-&gt;identifierNumber = identifierNumber;
2486 
2487                 return m_graph.addNode(
2488                     PutByOffset,
2489                     origin.takeValidExit(canExit),
2490                     OpInfo(data),
2491                     Edge(storage, KnownCellUse),
2492                     Edge(base, KnownCellUse),
2493                     value-&gt;defaultEdge());
2494             }
2495 
2496             MultiPutByOffsetData* data = m_graph.m_multiPutByOffsetData.add();
2497             data-&gt;identifierNumber = identifierNumber;
2498 
2499             {
2500                 PropertyOffset currentOffset = firstOffset;
2501                 StructureSet currentSet;
2502                 for (RegisteredStructure structure : structures) {
2503                     PropertyOffset offset = structure-&gt;getConcurrently(uid);
2504                     if (offset != currentOffset) {
2505                         // Because our analysis treats MultiPutByOffset like an escape, we only have to
2506                         // deal with storing results that would have been previously stored by PutByOffset
2507                         // nodes. Those nodes were guarded by the appropriate type checks. This means that
2508                         // at this point, we can simply trust that the incoming value has the right type
2509                         // for whatever structure we are using.
2510                         data-&gt;variants.append(
2511                             PutByIdVariant::replace(currentSet, currentOffset));
2512                         currentOffset = offset;
2513                         currentSet.clear();
2514                     }
2515                     currentSet.add(structure.get());
2516                 }
2517                 data-&gt;variants.append(
2518                     PutByIdVariant::replace(currentSet, currentOffset));
2519             }
2520 
2521             return m_graph.addNode(
2522                 MultiPutByOffset,
2523                 origin.takeValidExit(canExit),
2524                 OpInfo(data),
2525                 Edge(base, KnownCellUse),
2526                 value-&gt;defaultEdge());
2527         }
2528 
2529         case ClosureVarPLoc: {
2530             return m_graph.addNode(
2531                 PutClosureVar,
2532                 origin.takeValidExit(canExit),
2533                 OpInfo(location.info()),
2534                 Edge(base, KnownCellUse),
2535                 value-&gt;defaultEdge());
2536         }
2537 
<a name="30" id="anc30"></a><span class="line-added">2538         case InternalFieldObjectPLoc: {</span>
<span class="line-added">2539             return m_graph.addNode(</span>
<span class="line-added">2540                 PutInternalField,</span>
<span class="line-added">2541                 origin.takeValidExit(canExit),</span>
<span class="line-added">2542                 OpInfo(location.info()),</span>
<span class="line-added">2543                 Edge(base, KnownCellUse),</span>
<span class="line-added">2544                 value-&gt;defaultEdge());</span>
<span class="line-added">2545         }</span>
<span class="line-added">2546 </span>
2547         case RegExpObjectLastIndexPLoc: {
2548             return m_graph.addNode(
2549                 SetRegExpObjectLastIndex,
2550                 origin.takeValidExit(canExit),
2551                 OpInfo(true),
2552                 Edge(base, KnownCellUse),
2553                 value-&gt;defaultEdge());
2554         }
2555 
2556         default:
2557             DFG_CRASH(m_graph, base, &quot;Bad location kind&quot;);
2558             break;
2559         }
2560 
2561         RELEASE_ASSERT_NOT_REACHED();
2562     }
2563 
2564     void removeICStatusFilters()
2565     {
2566         for (BasicBlock* block : m_graph.blocksInNaturalOrder()) {
2567             for (Node* node : *block) {
2568                 switch (node-&gt;op()) {
2569                 case FilterCallLinkStatus:
<a name="31" id="anc31"></a><span class="line-modified">2570                 case FilterGetByStatus:</span>
2571                 case FilterPutByIdStatus:
2572                 case FilterInByIdStatus:
2573                     if (node-&gt;child1()-&gt;isPhantomAllocation())
2574                         node-&gt;removeWithoutChecks();
2575                     break;
2576                 default:
2577                     break;
2578                 }
2579             }
2580         }
2581     }
2582 
2583     // This is a great way of asking value-&gt;isStillValid() without having to worry about getting
2584     // different answers. It turns out that this analysis works OK regardless of what this
2585     // returns but breaks badly if this changes its mind for any particular InferredValue. This
2586     // method protects us from that.
2587     bool isStillValid(SymbolTable* value)
2588     {
2589         return m_validInferredValues.add(value, value-&gt;singleton().isStillValid()).iterator-&gt;value;
2590     }
2591 
2592     bool isStillValid(FunctionExecutable* value)
2593     {
2594         return m_validInferredValues.add(value, value-&gt;singleton().isStillValid()).iterator-&gt;value;
2595     }
2596 
2597 
2598     SSACalculator m_pointerSSA;
2599     SSACalculator m_allocationSSA;
2600     NodeSet m_sinkCandidates;
2601     HashMap&lt;PromotedHeapLocation, SSACalculator::Variable*&gt; m_locationToVariable;
2602     HashMap&lt;Node*, SSACalculator::Variable*&gt; m_nodeToVariable;
2603     HashMap&lt;PromotedHeapLocation, Node*&gt; m_localMapping;
2604     HashMap&lt;Node*, Node*&gt; m_escapeeToMaterialization;
2605     InsertionSet m_insertionSet;
2606     CombinedLiveness m_combinedLiveness;
2607 
2608     HashMap&lt;JSCell*, bool&gt; m_validInferredValues;
2609 
2610     HashMap&lt;Node*, Node*&gt; m_materializationToEscapee;
2611     HashMap&lt;Node*, Vector&lt;Node*&gt;&gt; m_materializationSiteToMaterializations;
2612     HashMap&lt;Node*, Vector&lt;PromotedHeapLocation&gt;&gt; m_materializationSiteToRecoveries;
2613     HashMap&lt;Node*, Vector&lt;std::pair&lt;PromotedHeapLocation, Node*&gt;&gt;&gt; m_materializationSiteToHints;
2614 
2615     HashMap&lt;Node*, Vector&lt;PromotedHeapLocation&gt;&gt; m_locationsForAllocation;
2616 
2617     BlockMap&lt;LocalHeap&gt; m_heapAtHead;
2618     BlockMap&lt;LocalHeap&gt; m_heapAtTail;
2619     LocalHeap m_heap;
2620 
2621     Node* m_bottom = nullptr;
2622 };
2623 
2624 }
2625 
2626 bool performObjectAllocationSinking(Graph&amp; graph)
2627 {
2628     return runPhase&lt;ObjectAllocationSinkingPhase&gt;(graph);
2629 }
2630 
2631 } } // namespace JSC::DFG
2632 
2633 #endif // ENABLE(DFG_JIT)
<a name="32" id="anc32"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="32" type="hidden" />
</body>
</html>