<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/WebCore/Modules/speech/SpeechSynthesis.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2013-2017 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;SpeechSynthesis.h&quot;
 28 
 29 #if ENABLE(SPEECH_SYNTHESIS)
 30 
 31 #include &quot;EventNames.h&quot;
 32 #include &quot;PlatformSpeechSynthesisVoice.h&quot;
 33 #include &quot;PlatformSpeechSynthesizer.h&quot;
 34 #include &quot;SpeechSynthesisEvent.h&quot;
 35 #include &quot;SpeechSynthesisUtterance.h&quot;
 36 #include &quot;UserGestureIndicator.h&quot;
 37 #include &lt;wtf/NeverDestroyed.h&gt;
 38 
 39 namespace WebCore {
 40 
 41 Ref&lt;SpeechSynthesis&gt; SpeechSynthesis::create(WeakPtr&lt;SpeechSynthesisClient&gt; client)
 42 {
 43     return adoptRef(*new SpeechSynthesis(client));
 44 }
 45 
 46 SpeechSynthesis::SpeechSynthesis(WeakPtr&lt;SpeechSynthesisClient&gt; client)
 47     : m_currentSpeechUtterance(nullptr)
 48     , m_isPaused(false)
 49 #if PLATFORM(IOS_FAMILY)
 50     , m_restrictions(RequireUserGestureForSpeechStartRestriction)
 51 #endif
 52     , m_speechSynthesisClient(client)
 53 {
 54     if (m_speechSynthesisClient)
 55         m_speechSynthesisClient-&gt;setObserver(makeWeakPtr(this));
 56 }
 57 
 58 void SpeechSynthesis::setPlatformSynthesizer(std::unique_ptr&lt;PlatformSpeechSynthesizer&gt; synthesizer)
 59 {
 60     m_platformSpeechSynthesizer = WTFMove(synthesizer);
 61     m_voiceList.clear();
 62     m_currentSpeechUtterance = nullptr;
 63     m_utteranceQueue.clear();
 64     m_isPaused = false;
 65     m_speechSynthesisClient = nullptr;
 66 }
 67 
 68 void SpeechSynthesis::voicesDidChange()
 69 {
 70     m_voiceList.clear();
 71 }
 72 
 73 PlatformSpeechSynthesizer&amp; SpeechSynthesis::ensurePlatformSpeechSynthesizer()
 74 {
 75     if (!m_platformSpeechSynthesizer)
 76         m_platformSpeechSynthesizer = makeUnique&lt;PlatformSpeechSynthesizer&gt;(this);
 77     return *m_platformSpeechSynthesizer;
 78 }
 79 
 80 const Vector&lt;Ref&lt;SpeechSynthesisVoice&gt;&gt;&amp; SpeechSynthesis::getVoices()
 81 {
 82     if (!m_voiceList.isEmpty())
 83         return m_voiceList;
 84 
 85     // If the voiceList is empty, that&#39;s the cue to get the voices from the platform again.
 86     for (auto&amp; voice : m_speechSynthesisClient ? m_speechSynthesisClient-&gt;voiceList() : ensurePlatformSpeechSynthesizer().voiceList())
 87         m_voiceList.append(SpeechSynthesisVoice::create(*voice));
 88 
 89     return m_voiceList;
 90 }
 91 
 92 bool SpeechSynthesis::speaking() const
 93 {
 94     // If we have a current speech utterance, then that means we&#39;re assumed to be in a speaking state.
 95     // This state is independent of whether the utterance happens to be paused.
 96     return m_currentSpeechUtterance;
 97 }
 98 
 99 bool SpeechSynthesis::pending() const
100 {
101     // This is true if there are any utterances that have not started.
102     // That means there will be more than one in the queue.
103     return m_utteranceQueue.size() &gt; 1;
104 }
105 
106 bool SpeechSynthesis::paused() const
107 {
108     return m_isPaused;
109 }
110 
111 void SpeechSynthesis::startSpeakingImmediately(SpeechSynthesisUtterance&amp; utterance)
112 {
113     utterance.setStartTime(MonotonicTime::now());
114     m_currentSpeechUtterance = &amp;utterance;
115     m_isPaused = false;
116 
117     // Zero lengthed strings should immediately notify that the event is complete.
118     if (utterance.text().isEmpty()) {
119         handleSpeakingCompleted(utterance, false);
120         return;
121     }
122 
123     if (m_speechSynthesisClient)
124         m_speechSynthesisClient-&gt;speak(utterance.platformUtterance());
125     else
126         ensurePlatformSpeechSynthesizer().speak(utterance.platformUtterance());
127 }
128 
129 void SpeechSynthesis::speak(SpeechSynthesisUtterance&amp; utterance)
130 {
131     // Like Audio, we should require that the user interact to start a speech synthesis session.
132 #if PLATFORM(IOS_FAMILY)
133     if (UserGestureIndicator::processingUserGesture())
134         removeBehaviorRestriction(RequireUserGestureForSpeechStartRestriction);
135     else if (userGestureRequiredForSpeechStart())
136         return;
137 #endif
138 
139     m_utteranceQueue.append(utterance);
140 
141     // If the queue was empty, speak this immediately and add it to the queue.
142     if (m_utteranceQueue.size() == 1)
143         startSpeakingImmediately(m_utteranceQueue.first());
144 }
145 
146 void SpeechSynthesis::cancel()
147 {
148     // Remove all the items from the utterance queue.
149     // Hold on to the current utterance so the platform synthesizer can have a chance to clean up.
150     RefPtr&lt;SpeechSynthesisUtterance&gt; current = m_currentSpeechUtterance;
151     m_utteranceQueue.clear();
<a name="1" id="anc1"></a><span class="line-modified">152     if (m_speechSynthesisClient) {</span>
153         m_speechSynthesisClient-&gt;cancel();
<a name="2" id="anc2"></a><span class="line-modified">154         m_currentSpeechUtterance = nullptr;</span>
<span class="line-added">155     } else if (m_platformSpeechSynthesizer) {</span>
156         m_platformSpeechSynthesizer-&gt;cancel();
157         // The platform should have called back immediately and cleared the current utterance.
158         ASSERT(!m_currentSpeechUtterance);
159     }
160     current = nullptr;
161 }
162 
163 void SpeechSynthesis::pause()
164 {
165     if (!m_isPaused) {
166         if (m_speechSynthesisClient)
167             m_speechSynthesisClient-&gt;pause();
168         else if (m_platformSpeechSynthesizer)
169             m_platformSpeechSynthesizer-&gt;pause();
170     }
171 }
172 
173 void SpeechSynthesis::resume()
174 {
175     if (m_currentSpeechUtterance) {
176         if (m_speechSynthesisClient)
177             m_speechSynthesisClient-&gt;resume();
178         else if (m_platformSpeechSynthesizer)
179             m_platformSpeechSynthesizer-&gt;resume();
180     }
181 }
182 
183 void SpeechSynthesis::fireEvent(const AtomString&amp; type, SpeechSynthesisUtterance&amp; utterance, unsigned long charIndex, const String&amp; name)
184 {
185     utterance.dispatchEvent(SpeechSynthesisEvent::create(type, charIndex, (MonotonicTime::now() - utterance.startTime()).seconds(), name));
186 }
187 
188 void SpeechSynthesis::handleSpeakingCompleted(SpeechSynthesisUtterance&amp; utterance, bool errorOccurred)
189 {
190     ASSERT(m_currentSpeechUtterance);
191     Ref&lt;SpeechSynthesisUtterance&gt; protect(utterance);
192 
193     m_currentSpeechUtterance = nullptr;
194 
195     fireEvent(errorOccurred ? eventNames().errorEvent : eventNames().endEvent, utterance, 0, String());
196 
197     if (m_utteranceQueue.size()) {
198         Ref&lt;SpeechSynthesisUtterance&gt; firstUtterance = m_utteranceQueue.takeFirst();
199         ASSERT(&amp;utterance == firstUtterance.ptr());
200 
201         // Start the next job if there is one pending.
202         if (!m_utteranceQueue.isEmpty())
203             startSpeakingImmediately(m_utteranceQueue.first());
204     }
205 }
206 
207 void SpeechSynthesis::boundaryEventOccurred(PlatformSpeechSynthesisUtterance&amp; utterance, SpeechBoundary boundary, unsigned charIndex)
208 {
209     static NeverDestroyed&lt;const String&gt; wordBoundaryString(MAKE_STATIC_STRING_IMPL(&quot;word&quot;));
210     static NeverDestroyed&lt;const String&gt; sentenceBoundaryString(MAKE_STATIC_STRING_IMPL(&quot;sentence&quot;));
211 
212     ASSERT(utterance.client());
213 
214     switch (boundary) {
215     case SpeechBoundary::SpeechWordBoundary:
216         fireEvent(eventNames().boundaryEvent, static_cast&lt;SpeechSynthesisUtterance&amp;&gt;(*utterance.client()), charIndex, wordBoundaryString);
217         break;
218     case SpeechBoundary::SpeechSentenceBoundary:
219         fireEvent(eventNames().boundaryEvent, static_cast&lt;SpeechSynthesisUtterance&amp;&gt;(*utterance.client()), charIndex, sentenceBoundaryString);
220         break;
221     default:
222         ASSERT_NOT_REACHED();
223     }
224 }
225 
226 void SpeechSynthesis::didStartSpeaking()
227 {
228     if (!m_currentSpeechUtterance)
229         return;
230     didStartSpeaking(*m_currentSpeechUtterance-&gt;platformUtterance());
231 }
232 
233 void SpeechSynthesis::didFinishSpeaking()
234 {
235     if (!m_currentSpeechUtterance)
236         return;
237     didFinishSpeaking(*m_currentSpeechUtterance-&gt;platformUtterance());
238 }
239 
240 void SpeechSynthesis::didPauseSpeaking()
241 {
242     if (!m_currentSpeechUtterance)
243         return;
244     didPauseSpeaking(*m_currentSpeechUtterance-&gt;platformUtterance());
245 }
246 
247 void SpeechSynthesis::didResumeSpeaking()
248 {
249     if (!m_currentSpeechUtterance)
250         return;
251     didResumeSpeaking(*m_currentSpeechUtterance-&gt;platformUtterance());
252 }
253 
254 void SpeechSynthesis::speakingErrorOccurred()
255 {
256     if (!m_currentSpeechUtterance)
257         return;
258     speakingErrorOccurred(*m_currentSpeechUtterance-&gt;platformUtterance());
259 }
260 
261 void SpeechSynthesis::boundaryEventOccurred(bool wordBoundary, unsigned charIndex)
262 {
263     if (!m_currentSpeechUtterance)
264         return;
265     boundaryEventOccurred(*m_currentSpeechUtterance-&gt;platformUtterance(), wordBoundary ? SpeechBoundary::SpeechWordBoundary : SpeechBoundary::SpeechSentenceBoundary, charIndex);
266 }
267 
268 void SpeechSynthesis::voicesChanged()
269 {
270     voicesDidChange();
271 }
272 
273 void SpeechSynthesis::didStartSpeaking(PlatformSpeechSynthesisUtterance&amp; utterance)
274 {
275     if (utterance.client())
276         fireEvent(eventNames().startEvent, static_cast&lt;SpeechSynthesisUtterance&amp;&gt;(*utterance.client()), 0, String());
277 }
278 
279 void SpeechSynthesis::didPauseSpeaking(PlatformSpeechSynthesisUtterance&amp; utterance)
280 {
281     m_isPaused = true;
282     if (utterance.client())
283         fireEvent(eventNames().pauseEvent, static_cast&lt;SpeechSynthesisUtterance&amp;&gt;(*utterance.client()), 0, String());
284 }
285 
286 void SpeechSynthesis::didResumeSpeaking(PlatformSpeechSynthesisUtterance&amp; utterance)
287 {
288     m_isPaused = false;
289     if (utterance.client())
290         fireEvent(eventNames().resumeEvent, static_cast&lt;SpeechSynthesisUtterance&amp;&gt;(*utterance.client()), 0, String());
291 }
292 
293 void SpeechSynthesis::didFinishSpeaking(PlatformSpeechSynthesisUtterance&amp; utterance)
294 {
295     if (utterance.client())
296         handleSpeakingCompleted(static_cast&lt;SpeechSynthesisUtterance&amp;&gt;(*utterance.client()), false);
297 }
298 
299 void SpeechSynthesis::speakingErrorOccurred(PlatformSpeechSynthesisUtterance&amp; utterance)
300 {
301     if (utterance.client())
302         handleSpeakingCompleted(static_cast&lt;SpeechSynthesisUtterance&amp;&gt;(*utterance.client()), true);
303 }
304 
305 } // namespace WebCore
306 
307 #endif // ENABLE(SPEECH_SYNTHESIS)
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="3" type="hidden" />
</body>
</html>