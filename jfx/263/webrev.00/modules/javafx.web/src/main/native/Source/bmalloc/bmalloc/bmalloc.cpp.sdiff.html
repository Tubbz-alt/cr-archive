<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/bmalloc.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="Zone.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="../../cmake/FindEnchant.cmake.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/bmalloc.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 41     free(object, kind);
 42 }
 43 
 44 void* tryLargeZeroedMemalignVirtual(size_t requiredAlignment, size_t requestedSize, HeapKind kind)
 45 {
 46     RELEASE_BASSERT(isPowerOfTwo(requiredAlignment));
 47 
 48     size_t pageSize = vmPageSize();
 49     size_t alignment = roundUpToMultipleOf(pageSize, requiredAlignment);
 50     size_t size = roundUpToMultipleOf(pageSize, requestedSize);
 51     RELEASE_BASSERT(alignment &gt;= requiredAlignment);
 52     RELEASE_BASSERT(size &gt;= requestedSize);
 53 
 54     void* result;
 55     if (auto* debugHeap = DebugHeap::tryGet())
 56         result = debugHeap-&gt;memalignLarge(alignment, size);
 57     else {
 58         kind = mapToActiveHeapKind(kind);
 59         Heap&amp; heap = PerProcess&lt;PerHeapKind&lt;Heap&gt;&gt;::get()-&gt;at(kind);
 60 
<span class="line-modified"> 61         std::unique_lock&lt;Mutex&gt; lock(Heap::mutex());</span>
<span class="line-modified"> 62         result = heap.tryAllocateLarge(lock, alignment, size);</span>
 63         if (result) {
 64             // Don&#39;t track this as dirty memory that dictates how we drive the scavenger.
 65             // FIXME: We should make it so that users of this API inform bmalloc which
 66             // pages they dirty:
 67             // https://bugs.webkit.org/show_bug.cgi?id=184207
 68             heap.externalDecommit(lock, result, size);
 69         }
 70     }
 71 
 72     if (result)
 73         vmZeroAndPurge(result, size);
 74     return result;
 75 }
 76 
 77 void freeLargeVirtual(void* object, size_t size, HeapKind kind)
 78 {
 79     if (auto* debugHeap = DebugHeap::tryGet()) {
 80         debugHeap-&gt;freeLarge(object);
 81         return;
 82     }
 83     kind = mapToActiveHeapKind(kind);
 84     Heap&amp; heap = PerProcess&lt;PerHeapKind&lt;Heap&gt;&gt;::get()-&gt;at(kind);
<span class="line-modified"> 85     std::unique_lock&lt;Mutex&gt; lock(Heap::mutex());</span>
 86     // Balance out the externalDecommit when we allocated the zeroed virtual memory.
 87     heap.externalCommit(lock, object, size);
 88     heap.deallocateLarge(lock, object);
 89 }
 90 
 91 void scavenge()
 92 {
 93     scavengeThisThread();
 94 
 95     if (DebugHeap* debugHeap = DebugHeap::tryGet())
 96         debugHeap-&gt;scavenge();
 97     else
 98         Scavenger::get()-&gt;scavenge();
 99 }
100 
101 bool isEnabled(HeapKind)
102 {
103     return !Environment::get()-&gt;isDebugHeapEnabled();
104 }
105 
106 #if BOS(DARWIN)
107 void setScavengerThreadQOSClass(qos_class_t overrideClass)
108 {
109     if (DebugHeap::tryGet())
110         return;
<span class="line-modified">111     std::unique_lock&lt;Mutex&gt; lock(Heap::mutex());</span>
112     Scavenger::get()-&gt;setScavengerThreadQOSClass(overrideClass);
113 }
114 #endif
115 
116 void commitAlignedPhysical(void* object, size_t size, HeapKind kind)
117 {
118     vmValidatePhysical(object, size);
119     vmAllocatePhysicalPages(object, size);
120     if (!DebugHeap::tryGet())
121         PerProcess&lt;PerHeapKind&lt;Heap&gt;&gt;::get()-&gt;at(kind).externalCommit(object, size);
122 }
123 
124 void decommitAlignedPhysical(void* object, size_t size, HeapKind kind)
125 {
126     vmValidatePhysical(object, size);
127     vmDeallocatePhysicalPages(object, size);
128     if (!DebugHeap::tryGet())
129         PerProcess&lt;PerHeapKind&lt;Heap&gt;&gt;::get()-&gt;at(kind).externalDecommit(object, size);
130 }
131 
</pre>
</td>
<td>
<hr />
<pre>
 41     free(object, kind);
 42 }
 43 
 44 void* tryLargeZeroedMemalignVirtual(size_t requiredAlignment, size_t requestedSize, HeapKind kind)
 45 {
 46     RELEASE_BASSERT(isPowerOfTwo(requiredAlignment));
 47 
 48     size_t pageSize = vmPageSize();
 49     size_t alignment = roundUpToMultipleOf(pageSize, requiredAlignment);
 50     size_t size = roundUpToMultipleOf(pageSize, requestedSize);
 51     RELEASE_BASSERT(alignment &gt;= requiredAlignment);
 52     RELEASE_BASSERT(size &gt;= requestedSize);
 53 
 54     void* result;
 55     if (auto* debugHeap = DebugHeap::tryGet())
 56         result = debugHeap-&gt;memalignLarge(alignment, size);
 57     else {
 58         kind = mapToActiveHeapKind(kind);
 59         Heap&amp; heap = PerProcess&lt;PerHeapKind&lt;Heap&gt;&gt;::get()-&gt;at(kind);
 60 
<span class="line-modified"> 61         UniqueLockHolder lock(Heap::mutex());</span>
<span class="line-modified"> 62         result = heap.allocateLarge(lock, alignment, size, FailureAction::ReturnNull);</span>
 63         if (result) {
 64             // Don&#39;t track this as dirty memory that dictates how we drive the scavenger.
 65             // FIXME: We should make it so that users of this API inform bmalloc which
 66             // pages they dirty:
 67             // https://bugs.webkit.org/show_bug.cgi?id=184207
 68             heap.externalDecommit(lock, result, size);
 69         }
 70     }
 71 
 72     if (result)
 73         vmZeroAndPurge(result, size);
 74     return result;
 75 }
 76 
 77 void freeLargeVirtual(void* object, size_t size, HeapKind kind)
 78 {
 79     if (auto* debugHeap = DebugHeap::tryGet()) {
 80         debugHeap-&gt;freeLarge(object);
 81         return;
 82     }
 83     kind = mapToActiveHeapKind(kind);
 84     Heap&amp; heap = PerProcess&lt;PerHeapKind&lt;Heap&gt;&gt;::get()-&gt;at(kind);
<span class="line-modified"> 85     UniqueLockHolder lock(Heap::mutex());</span>
 86     // Balance out the externalDecommit when we allocated the zeroed virtual memory.
 87     heap.externalCommit(lock, object, size);
 88     heap.deallocateLarge(lock, object);
 89 }
 90 
 91 void scavenge()
 92 {
 93     scavengeThisThread();
 94 
 95     if (DebugHeap* debugHeap = DebugHeap::tryGet())
 96         debugHeap-&gt;scavenge();
 97     else
 98         Scavenger::get()-&gt;scavenge();
 99 }
100 
101 bool isEnabled(HeapKind)
102 {
103     return !Environment::get()-&gt;isDebugHeapEnabled();
104 }
105 
106 #if BOS(DARWIN)
107 void setScavengerThreadQOSClass(qos_class_t overrideClass)
108 {
109     if (DebugHeap::tryGet())
110         return;
<span class="line-modified">111     UniqueLockHolder lock(Heap::mutex());</span>
112     Scavenger::get()-&gt;setScavengerThreadQOSClass(overrideClass);
113 }
114 #endif
115 
116 void commitAlignedPhysical(void* object, size_t size, HeapKind kind)
117 {
118     vmValidatePhysical(object, size);
119     vmAllocatePhysicalPages(object, size);
120     if (!DebugHeap::tryGet())
121         PerProcess&lt;PerHeapKind&lt;Heap&gt;&gt;::get()-&gt;at(kind).externalCommit(object, size);
122 }
123 
124 void decommitAlignedPhysical(void* object, size_t size, HeapKind kind)
125 {
126     vmValidatePhysical(object, size);
127     vmDeallocatePhysicalPages(object, size);
128     if (!DebugHeap::tryGet())
129         PerProcess&lt;PerHeapKind&lt;Heap&gt;&gt;::get()-&gt;at(kind).externalDecommit(object, size);
130 }
131 
</pre>
</td>
</tr>
</table>
<center><a href="Zone.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="../../cmake/FindEnchant.cmake.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>