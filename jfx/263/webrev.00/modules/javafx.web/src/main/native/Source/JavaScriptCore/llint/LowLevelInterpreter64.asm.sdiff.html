<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter64.asm</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="LowLevelInterpreter32_64.asm.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="../offlineasm/arm.rb.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter64.asm</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   6 # 1. Redistributions of source code must retain the above copyright
   7 #    notice, this list of conditions and the following disclaimer.
   8 # 2. Redistributions in binary form must reproduce the above copyright
   9 #    notice, this list of conditions and the following disclaimer in the
  10 #    documentation and/or other materials provided with the distribution.
  11 #
  12 # THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
  13 # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
  14 # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  15 # PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
  16 # BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  17 # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  18 # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
  19 # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
  20 # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
  21 # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
  22 # THE POSSIBILITY OF SUCH DAMAGE.
  23 
  24 
  25 # Utilities.
<span class="line-modified">  26 </span>
<span class="line-modified">  27 macro nextInstruction()</span>
<span class="line-removed">  28     loadb [PB, PC, 1], t0</span>
<span class="line-removed">  29     leap _g_opcodeMap, t1</span>
<span class="line-removed">  30     jmp [t1, t0, PtrSize], BytecodePtrTag</span>
<span class="line-removed">  31 end</span>
<span class="line-removed">  32 </span>
<span class="line-removed">  33 macro nextInstructionWide16()</span>
<span class="line-removed">  34     loadh 1[PB, PC, 1], t0</span>
<span class="line-removed">  35     leap _g_opcodeMapWide16, t1</span>
<span class="line-removed">  36     jmp [t1, t0, PtrSize], BytecodePtrTag</span>
  37 end
  38 
<span class="line-modified">  39 macro nextInstructionWide32()</span>
<span class="line-modified">  40     loadi 1[PB, PC, 1], t0</span>
<span class="line-removed">  41     leap _g_opcodeMapWide32, t1</span>
<span class="line-removed">  42     jmp [t1, t0, PtrSize], BytecodePtrTag</span>
  43 end
  44 
  45 macro getuOperandNarrow(opcodeStruct, fieldName, dst)
<span class="line-modified">  46     loadb constexpr %opcodeStruct%_%fieldName%_index[PB, PC, 1], dst</span>
  47 end
  48 
  49 macro getOperandNarrow(opcodeStruct, fieldName, dst)
<span class="line-modified">  50     loadbsq constexpr %opcodeStruct%_%fieldName%_index[PB, PC, 1], dst</span>
  51 end
  52 
  53 macro getuOperandWide16(opcodeStruct, fieldName, dst)
<span class="line-modified">  54     loadh constexpr %opcodeStruct%_%fieldName%_index * 2 + 1[PB, PC, 1], dst</span>
  55 end
  56 
  57 macro getOperandWide16(opcodeStruct, fieldName, dst)
<span class="line-modified">  58     loadhsq constexpr %opcodeStruct%_%fieldName%_index * 2 + 1[PB, PC, 1], dst</span>
  59 end
  60 
  61 macro getuOperandWide32(opcodeStruct, fieldName, dst)
<span class="line-modified">  62     loadi constexpr %opcodeStruct%_%fieldName%_index * 4 + 1[PB, PC, 1], dst</span>
  63 end
  64 
  65 macro getOperandWide32(opcodeStruct, fieldName, dst)
<span class="line-modified">  66     loadis constexpr %opcodeStruct%_%fieldName%_index * 4 + 1[PB, PC, 1], dst</span>
  67 end
  68 
  69 macro makeReturn(get, dispatch, fn)
  70     fn(macro (value)
  71         move value, t2
  72         get(m_dst, t1)
  73         storeq t2, [cfr, t1, 8]
  74         dispatch()
  75     end)
  76 end
  77 
  78 macro makeReturnProfiled(opcodeStruct, get, metadata, dispatch, fn)
  79     fn(macro (value)
  80         move value, t3
  81         metadata(t1, t2)
  82         valueProfile(opcodeStruct, t1, t3)
  83         get(m_dst, t1)
  84         storeq t3, [cfr, t1, 8]
  85         dispatch()
  86     end)
  87 end
  88 
  89 macro valueProfile(opcodeStruct, metadata, value)
  90     storeq value, %opcodeStruct%::Metadata::m_profile.m_buckets[metadata]
  91 end
  92 

  93 macro dispatchAfterCall(size, opcodeStruct, dispatch)
<span class="line-modified">  94     loadi ArgumentCount + TagOffset[cfr], PC</span>
  95     loadp CodeBlock[cfr], PB
  96     loadp CodeBlock::m_instructionsRawPointer[PB], PB
  97     get(size, opcodeStruct, m_dst, t1)
  98     storeq r0, [cfr, t1, 8]
  99     metadata(size, opcodeStruct, t2, t1)
 100     valueProfile(opcodeStruct, t2, r0)
 101     dispatch()
 102 end
 103 
 104 macro cCall2(function)
 105     checkStackPointerAlignment(t4, 0xbad0c002)
 106     if X86_64 or ARM64 or ARM64E
 107         call function
 108     elsif X86_64_WIN
 109         # Note: this implementation is only correct if the return type size is &gt; 8 bytes.
 110         # See macro cCall2Void for an implementation when the return type &lt;= 8 bytes.
 111         # On Win64, when the return type is larger than 8 bytes, we need to allocate space on the stack for the return value.
 112         # On entry rcx (a0), should contain a pointer to this stack space. The other parameters are shifted to the right,
 113         # rdx (a1) should contain the first argument, and r8 (a2) should contain the second argument.
 114         # On return, rax contains a pointer to this stack value, and we then need to copy the 16 byte return value into rax (r0) and rdx (r1)
</pre>
<hr />
<pre>
 199         move vm, t5
 200         cloopCallSlowPath _llint_stack_check_at_vm_entry, vm, t3
 201         bpeq t0, 0, .stackCheckFailed
 202         move t4, entry
 203         move t5, vm
 204         jmp .stackHeightOK
 205 
 206 .stackCheckFailed:
 207         move t4, entry
 208         move t5, vm
 209         jmp .throwStackOverflow
 210     else
 211         bpb t3, VM::m_softStackLimit[vm], .throwStackOverflow
 212     end
 213 
 214 .stackHeightOK:
 215     move t3, sp
 216     move (constexpr ProtoCallFrame::numberOfRegisters), t3
 217 
 218 .copyHeaderLoop:
<span class="line-modified"> 219     # Copy the CodeBlock/Callee/ArgumentCount/|this| from protoCallFrame into the callee frame.</span>
 220     subi 1, t3
 221     loadq [protoCallFrame, t3, 8], extraTempReg
 222     storeq extraTempReg, CodeBlock[sp, t3, 8]
 223     btinz t3, .copyHeaderLoop
 224 
 225     loadi PayloadOffset + ProtoCallFrame::argCountAndCodeOriginValue[protoCallFrame], t4
 226     subi 1, t4
 227     loadi ProtoCallFrame::paddedArgCount[protoCallFrame], extraTempReg
 228     subi 1, extraTempReg
 229 
 230     bieq t4, extraTempReg, .copyArgs
 231     move ValueUndefined, t3
 232 .fillExtraArgsLoop:
 233     subi 1, extraTempReg
 234     storeq t3, ThisArgumentOffset + 8[sp, extraTempReg, 8]
 235     bineq t4, extraTempReg, .fillExtraArgsLoop
 236 
 237 .copyArgs:
 238     loadp ProtoCallFrame::args[protoCallFrame], t3
 239 
 240 .copyArgsLoop:
 241     btiz t4, .copyArgsDone
 242     subi 1, t4
 243     loadq [t3, t4, 8], extraTempReg
 244     storeq extraTempReg, ThisArgumentOffset + 8[sp, t4, 8]
 245     jmp .copyArgsLoop
 246 
 247 .copyArgsDone:
 248     if ARM64 or ARM64E
 249         move sp, t4
 250         storep t4, VM::topCallFrame[vm]
 251     else
 252         storep sp, VM::topCallFrame[vm]
 253     end
 254     storep cfr, VM::topEntryFrame[vm]
 255 
 256     checkStackPointerAlignment(extraTempReg, 0xbad0dc02)
 257 
<span class="line-modified"> 258     makeCall(entry, t3, t4)</span>
 259 
 260     # We may have just made a call into a JS function, so we can&#39;t rely on sp
 261     # for anything but the fact that our own locals (ie the VMEntryRecord) are
 262     # not below it. It also still has to be aligned, though.
 263     checkStackPointerAlignment(t2, 0xbad0dc03)
 264 
 265     vmEntryRecord(cfr, t4)
 266 
 267     loadp VMEntryRecord::m_vm[t4], vm
 268     loadp VMEntryRecord::m_prevTopCallFrame[t4], t2
 269     storep t2, VM::topCallFrame[vm]
 270     loadp VMEntryRecord::m_prevTopEntryFrame[t4], t2
 271     storep t2, VM::topEntryFrame[vm]
 272 
 273     subp cfr, CalleeRegisterSaveSize, sp
 274 
 275     popCalleeSaves()
 276     functionEpilogue()
 277     ret
 278 
</pre>
<hr />
<pre>
 280     move vm, a0
 281     move protoCallFrame, a1
 282     cCall2(_llint_throw_stack_overflow_error)
 283 
 284     vmEntryRecord(cfr, t4)
 285 
 286     loadp VMEntryRecord::m_vm[t4], vm
 287     loadp VMEntryRecord::m_prevTopCallFrame[t4], extraTempReg
 288     storep extraTempReg, VM::topCallFrame[vm]
 289     loadp VMEntryRecord::m_prevTopEntryFrame[t4], extraTempReg
 290     storep extraTempReg, VM::topEntryFrame[vm]
 291 
 292     subp cfr, CalleeRegisterSaveSize, sp
 293 
 294     popCalleeSaves()
 295     functionEpilogue()
 296     ret
 297 end
 298 
 299 
<span class="line-modified"> 300 macro makeJavaScriptCall(entry, temp, unused)</span>

 301     addp 16, sp
 302     if C_LOOP or C_LOOP_WIN
 303         cloopCallJSFunction entry
 304     else
 305         call entry, JSEntryPtrTag
 306     end
 307     subp 16, sp
 308 end
 309 
<span class="line-modified"> 310 macro makeHostFunctionCall(entry, temp, unused)</span>
<span class="line-modified"> 311     move entry, temp</span>

 312     storep cfr, [sp]
<span class="line-modified"> 313     move sp, a0</span>

 314     if C_LOOP or C_LOOP_WIN
 315         storep lr, 8[sp]
<span class="line-modified"> 316         cloopCallNative temp</span>
 317     elsif X86_64_WIN
 318         # We need to allocate 32 bytes on the stack for the shadow space.
 319         subp 32, sp
<span class="line-modified"> 320         call temp, JSEntryPtrTag</span>
 321         addp 32, sp
 322     else
<span class="line-modified"> 323         call temp, JSEntryPtrTag</span>
 324     end
 325 end
 326 
 327 op(handleUncaughtException, macro ()
 328     loadp Callee[cfr], t3
<span class="line-modified"> 329     andp MarkedBlockMask, t3</span>
<span class="line-removed"> 330     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3</span>
 331     restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(t3, t0)
 332     storep 0, VM::callFrameForCatch[t3]
 333 
 334     loadp VM::topEntryFrame[t3], cfr
 335     vmEntryRecord(cfr, t2)
 336 
 337     loadp VMEntryRecord::m_vm[t2], t3
 338     loadp VMEntryRecord::m_prevTopCallFrame[t2], extraTempReg
 339     storep extraTempReg, VM::topCallFrame[t3]
 340     loadp VMEntryRecord::m_prevTopEntryFrame[t2], extraTempReg
 341     storep extraTempReg, VM::topEntryFrame[t3]
 342 
 343     subp cfr, CalleeRegisterSaveSize, sp
 344 
 345     popCalleeSaves()
 346     functionEpilogue()
 347     ret
 348 end)
 349 
 350 
</pre>
<hr />
<pre>
 368 macro traceOperand(fromWhere, operand)
 369     prepareStateForCCall()
 370     move fromWhere, a2
 371     move operand, a3
 372     move cfr, a0
 373     move PC, a1
 374     cCall4(_llint_trace_operand)
 375     restoreStateAfterCCall()
 376 end
 377 
 378 macro traceValue(fromWhere, operand)
 379     prepareStateForCCall()
 380     move fromWhere, a2
 381     move operand, a3
 382     move cfr, a0
 383     move PC, a1
 384     cCall4(_llint_trace_value)
 385     restoreStateAfterCCall()
 386 end
 387 
<span class="line-modified"> 388 # Call a slow path for call call opcodes.</span>
 389 macro callCallSlowPath(slowPath, action)
<span class="line-modified"> 390     storei PC, ArgumentCount + TagOffset[cfr]</span>
 391     prepareStateForCCall()
 392     move cfr, a0
 393     move PC, a1
 394     cCall2(slowPath)
 395     action(r0, r1)
 396 end
 397 
 398 macro callTrapHandler(throwHandler)
<span class="line-modified"> 399     storei PC, ArgumentCount + TagOffset[cfr]</span>
 400     prepareStateForCCall()
 401     move cfr, a0
 402     move PC, a1
 403     cCall2(_llint_slow_path_handle_traps)
 404     btpnz r0, throwHandler
<span class="line-modified"> 405     loadi ArgumentCount + TagOffset[cfr], PC</span>
 406 end
 407 
 408 macro checkSwitchToJITForLoop()
 409     checkSwitchToJIT(
 410         1,
 411         macro()
<span class="line-modified"> 412             storei PC, ArgumentCount + TagOffset[cfr]</span>
 413             prepareStateForCCall()
 414             move cfr, a0
 415             move PC, a1
 416             cCall2(_llint_loop_osr)
 417             btpz r0, .recover
 418             move r1, sp
 419             jmp r0, JSEntryPtrTag
 420         .recover:
<span class="line-modified"> 421             loadi ArgumentCount + TagOffset[cfr], PC</span>
 422         end)
 423 end
 424 
 425 macro cage(basePtr, mask, ptr, scratch)
 426     if GIGACAGE_ENABLED and not (C_LOOP or C_LOOP_WIN)
 427         loadp basePtr, scratch
 428         btpz scratch, .done
 429         andp mask, ptr
 430         addp scratch, ptr
 431     .done:
 432     end
 433 end
 434 
 435 macro cagedPrimitive(ptr, length, scratch, scratch2)
 436     if ARM64E
 437         const source = scratch2
 438         move ptr, scratch2
 439     else
 440         const source = ptr
 441     end
 442     if GIGACAGE_ENABLED
<span class="line-modified"> 443         cage(_g_gigacageBasePtrs + Gigacage::BasePtrs::primitive, constexpr Gigacage::primitiveGigacageMask, source, scratch)</span>
 444         if ARM64E
 445             const numberOfPACBits = constexpr MacroAssembler::numberOfPACBits
 446             bfiq scratch2, 0, 64 - numberOfPACBits, ptr
 447         end
 448     end
 449     if ARM64E
 450         untagArrayPtr length, ptr
 451     end
 452 end
 453 
 454 macro loadCagedJSValue(source, dest, scratchOrLength)
 455     loadp source, dest
<span class="line-modified"> 456     cage(_g_gigacageBasePtrs + Gigacage::BasePtrs::jsValue, constexpr Gigacage::jsValueGigacageMask, dest, scratchOrLength)</span>


 457 end
 458 
 459 macro loadVariable(get, fieldName, valueReg)
 460     get(fieldName, valueReg)
 461     loadq [cfr, valueReg, 8], valueReg
 462 end
 463 
























 464 # Index and value must be different registers. Index may be clobbered.
 465 macro loadConstantOrVariable(size, index, value)
 466     macro loadNarrow()
 467         bpgteq index, FirstConstantRegisterIndexNarrow, .constant
 468         loadq [cfr, index, 8], value
 469         jmp .done
 470     .constant:
<span class="line-modified"> 471         loadp CodeBlock[cfr], value</span>
<span class="line-removed"> 472         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[value], value</span>
<span class="line-removed"> 473         loadq -(FirstConstantRegisterIndexNarrow * 8)[value, index, 8], value</span>
 474     .done:
 475     end
 476 
 477     macro loadWide16()
 478         bpgteq index, FirstConstantRegisterIndexWide16, .constant
 479         loadq [cfr, index, 8], value
 480         jmp .done
 481     .constant:
<span class="line-modified"> 482         loadp CodeBlock[cfr], value</span>
<span class="line-removed"> 483         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[value], value</span>
<span class="line-removed"> 484         loadq -(FirstConstantRegisterIndexWide16 * 8)[value, index, 8], value</span>
 485     .done:
 486     end
 487 
 488     macro loadWide32()
 489         bpgteq index, FirstConstantRegisterIndexWide32, .constant
 490         loadq [cfr, index, 8], value
 491         jmp .done
 492     .constant:
<span class="line-modified"> 493         loadp CodeBlock[cfr], value</span>
<span class="line-removed"> 494         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[value], value</span>
<span class="line-removed"> 495         subp FirstConstantRegisterIndexWide32, index</span>
<span class="line-removed"> 496         loadq [value, index, 8], value</span>
 497     .done:
 498     end
 499 
 500     size(loadNarrow, loadWide16, loadWide32, macro (load) load() end)
 501 end
 502 
 503 macro loadConstantOrVariableInt32(size, index, value, slow)
 504     loadConstantOrVariable(size, index, value)
<span class="line-modified"> 505     bqb value, tagTypeNumber, slow</span>
 506 end
 507 
 508 macro loadConstantOrVariableCell(size, index, value, slow)
 509     loadConstantOrVariable(size, index, value)
<span class="line-modified"> 510     btqnz value, tagMask, slow</span>
 511 end
 512 
 513 macro writeBarrierOnCellWithReload(cell, reloadAfterSlowPath)
 514     skipIfIsRememberedOrInEden(
 515         cell,
 516         macro()
 517             push PB, PC
 518             move cell, a1 # cell can be a0
 519             move cfr, a0
 520             cCall2Void(_llint_write_barrier_slow)
 521             pop PC, PB
 522             reloadAfterSlowPath()
 523         end)
 524 end
 525 







 526 macro writeBarrierOnOperandWithReload(size, get, cellFieldName, reloadAfterSlowPath)
 527     get(cellFieldName, t1)
 528     loadConstantOrVariableCell(size, t1, t2, .writeBarrierDone)
 529     writeBarrierOnCellWithReload(t2, reloadAfterSlowPath)
 530 .writeBarrierDone:
 531 end
 532 
 533 macro writeBarrierOnOperand(size, get, cellFieldName)
 534     writeBarrierOnOperandWithReload(size, get, cellFieldName, macro () end)
 535 end
 536 
 537 macro writeBarrierOnOperands(size, get, cellFieldName, valueFieldName)
 538     get(valueFieldName, t1)
 539     loadConstantOrVariableCell(size, t1, t0, .writeBarrierDone)
 540     btpz t0, .writeBarrierDone
 541 
 542     writeBarrierOnOperand(size, get, cellFieldName)
 543 .writeBarrierDone:
 544 end
 545 
</pre>
<hr />
<pre>
 573 macro structureIDToStructureWithScratch(structureIDThenStructure, scratch, scratch2)
 574     loadp CodeBlock[cfr], scratch
 575     move structureIDThenStructure, scratch2
 576     loadp CodeBlock::m_vm[scratch], scratch
 577     rshifti NumberOfStructureIDEntropyBits, scratch2
 578     loadp VM::heap + Heap::m_structureIDTable + StructureIDTable::m_table[scratch], scratch
 579     loadp [scratch, scratch2, PtrSize], scratch2
 580     lshiftp StructureEntropyBitsShift, structureIDThenStructure
 581     xorp scratch2, structureIDThenStructure
 582 end
 583 
 584 macro loadStructureWithScratch(cell, structure, scratch, scratch2)
 585     loadi JSCell::m_structureID[cell], structure
 586     structureIDToStructureWithScratch(structure, scratch, scratch2)
 587 end
 588 
 589 # Entrypoints into the interpreter.
 590 
 591 # Expects that CodeBlock is in t1, which is what prologue() leaves behind.
 592 macro functionArityCheck(doneLabel, slowPath)
<span class="line-modified"> 593     loadi PayloadOffset + ArgumentCount[cfr], t0</span>
 594     biaeq t0, CodeBlock::m_numParameters[t1], doneLabel
 595     prepareStateForCCall()
 596     move cfr, a0
 597     move PC, a1
 598     cCall2(slowPath)   # This slowPath has the protocol: r0 = 0 =&gt; no error, r0 != 0 =&gt; error
 599     btiz r0, .noError
 600 
 601     # We&#39;re throwing before the frame is fully set up. This frame will be
 602     # ignored by the unwinder. So, let&#39;s restore the callee saves before we
 603     # start unwinding. We need to do this before we change the cfr.
 604     restoreCalleeSavesUsedByLLInt()
 605 
 606     move r1, cfr   # r1 contains caller frame
 607     jmp _llint_throw_from_slow_path_trampoline
 608 
 609 .noError:
 610     move r1, t1 # r1 contains slotsToAdd.
 611     btiz t1, .continue
<span class="line-modified"> 612     loadi PayloadOffset + ArgumentCount[cfr], t2</span>
 613     addi CallFrameHeaderSlots, t2
 614 
 615     // Check if there are some unaligned slots we can use
 616     move t1, t3
 617     andi StackAlignmentSlots - 1, t3
 618     btiz t3, .noExtraSlot
 619     move ValueUndefined, t0
 620 .fillExtraSlots:
 621     storeq t0, [cfr, t2, 8]
 622     addi 1, t2
 623     bsubinz 1, t3, .fillExtraSlots
 624     andi ~(StackAlignmentSlots - 1), t1
 625     btiz t1, .continue
 626 
 627 .noExtraSlot:
 628     if ARM64E
 629         loadp 8[cfr], lr
 630         addp 16, cfr, t3
 631         untagReturnAddress t3
 632     end
</pre>
<hr />
<pre>
 652     move ValueUndefined, t0
 653 .fillLoop:
 654     storeq t0, [t3, t1, 8]
 655     addp 8, t3
 656     baddinz 1, t2, .fillLoop
 657 
 658     if ARM64E
 659         addp 16, cfr, t1
 660         tagReturnAddress t1
 661         storep lr, 8[cfr]
 662     end
 663 
 664 .continue:
 665     # Reload CodeBlock and reset PC, since the slow_path clobbered them.
 666     loadp CodeBlock[cfr], t1
 667     loadp CodeBlock::m_instructionsRawPointer[t1], PB
 668     move 0, PC
 669     jmp doneLabel
 670 end
 671 
<span class="line-removed"> 672 macro branchIfException(label)</span>
<span class="line-removed"> 673     loadp Callee[cfr], t3</span>
<span class="line-removed"> 674     andp MarkedBlockMask, t3</span>
<span class="line-removed"> 675     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3</span>
<span class="line-removed"> 676     btpz VM::m_exception[t3], .noException</span>
<span class="line-removed"> 677     jmp label</span>
<span class="line-removed"> 678 .noException:</span>
<span class="line-removed"> 679 end</span>
<span class="line-removed"> 680 </span>
 681 # Instruction implementations

 682 _llint_op_enter:
 683     traceExecution()
 684     checkStackPointerAlignment(t2, 0xdead00e1)
<span class="line-modified"> 685     loadp CodeBlock[cfr], t3                // t3&lt;CodeBlock&gt; = cfr.CodeBlock</span>
<span class="line-modified"> 686     loadi CodeBlock::m_numVars[t3], t2      // t2&lt;size_t&gt; = t3&lt;CodeBlock&gt;.m_numVars</span>
 687     subq CalleeSaveSpaceAsVirtualRegisters, t2
 688     move cfr, t1
 689     subq CalleeSaveSpaceAsVirtualRegisters * 8, t1
 690     btiz t2, .opEnterDone
 691     move ValueUndefined, t0
 692     negi t2
 693     sxi2q t2, t2
 694 .opEnterLoop:
 695     storeq t0, [t1, t2, 8]
 696     addq 1, t2
 697     btqnz t2, .opEnterLoop
 698 .opEnterDone:
<span class="line-modified"> 699     writeBarrierOnCellWithReload(t3, macro ()</span>
<span class="line-removed"> 700         loadp CodeBlock[cfr], t3 # Reload CodeBlock</span>
<span class="line-removed"> 701     end)</span>
<span class="line-removed"> 702     loadp CodeBlock::m_vm[t3], t1</span>
<span class="line-removed"> 703     btbnz VM::m_traps + VMTraps::m_needTrapHandling[t1], .handleTraps</span>
<span class="line-removed"> 704 .afterHandlingTraps:</span>
 705     dispatchOp(narrow, op_enter)
<span class="line-modified"> 706 .handleTraps:</span>
<span class="line-removed"> 707     callTrapHandler(_llint_throw_from_slow_path_trampoline)</span>
<span class="line-removed"> 708     jmp .afterHandlingTraps</span>
 709 
 710 llintOpWithProfile(op_get_argument, OpGetArgument, macro (size, get, dispatch, return)
 711     get(m_index, t2)
<span class="line-modified"> 712     loadi PayloadOffset + ArgumentCount[cfr], t0</span>
 713     bilteq t0, t2, .opGetArgumentOutOfBounds
 714     loadq ThisArgumentOffset[cfr, t2, 8], t0
 715     return(t0)
 716 
 717 .opGetArgumentOutOfBounds:
 718     return(ValueUndefined)
 719 end)
 720 
 721 
 722 llintOpWithReturn(op_argument_count, OpArgumentCount, macro (size, get, dispatch, return)
<span class="line-modified"> 723     loadi PayloadOffset + ArgumentCount[cfr], t0</span>
 724     subi 1, t0
<span class="line-modified"> 725     orq TagTypeNumber, t0</span>
 726     return(t0)
 727 end)
 728 
 729 
 730 llintOpWithReturn(op_get_scope, OpGetScope, macro (size, get, dispatch, return)
 731     loadp Callee[cfr], t0
 732     loadp JSCallee::m_scope[t0], t0
 733     return(t0)
 734 end)
 735 
 736 
 737 llintOpWithMetadata(op_to_this, OpToThis, macro (size, get, dispatch, metadata, return)
 738     get(m_srcDst, t0)
 739     loadq [cfr, t0, 8], t0
<span class="line-modified"> 740     btqnz t0, tagMask, .opToThisSlow</span>
 741     bbneq JSCell::m_type[t0], FinalObjectType, .opToThisSlow
 742     loadi JSCell::m_structureID[t0], t1
 743     metadata(t2, t3)
 744     loadi OpToThis::Metadata::m_cachedStructureID[t2], t2
 745     bineq t1, t2, .opToThisSlow
 746     dispatch()
 747 
 748 .opToThisSlow:
 749     callSlowPath(_slow_path_to_this)
 750     dispatch()
 751 end)
 752 
 753 
 754 llintOp(op_check_tdz, OpCheckTdz, macro (size, get, dispatch)
 755     get(m_targetVirtualRegister, t0)
 756     loadConstantOrVariable(size, t0, t1)
 757     bqneq t1, ValueEmpty, .opNotTDZ
 758     callSlowPath(_slow_path_throw_tdz_error)
 759 
 760 .opNotTDZ:
</pre>
<hr />
<pre>
 787     llintOpWithReturn(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
 788         get(m_rhs, t0)
 789         get(m_lhs, t2)
 790         loadConstantOrVariableInt32(size, t0, t1, .slow)
 791         loadConstantOrVariableInt32(size, t2, t0, .slow)
 792         integerComparison(t0, t1, t0)
 793         orq ValueFalse, t0
 794         return(t0)
 795 
 796     .slow:
 797         callSlowPath(_slow_path_%opcodeName%)
 798         dispatch()
 799     end)
 800 end
 801 
 802 
 803 macro equalNullComparisonOp(opcodeName, opcodeStruct, fn)
 804     llintOpWithReturn(opcodeName, opcodeStruct, macro (size, get, dispatch, return)
 805         get(m_operand, t0)
 806         loadq [cfr, t0, 8], t0
<span class="line-modified"> 807         btqnz t0, tagMask, .immediate</span>
 808         btbnz JSCell::m_flags[t0], MasqueradesAsUndefined, .masqueradesAsUndefined
 809         move 0, t0
 810         jmp .done
 811     .masqueradesAsUndefined:
 812         loadStructureWithScratch(t0, t2, t1, t3)
 813         loadp CodeBlock[cfr], t0
 814         loadp CodeBlock::m_globalObject[t0], t0
 815         cpeq Structure::m_globalObject[t2], t0, t0
 816         jmp .done
 817     .immediate:
<span class="line-modified"> 818         andq ~TagBitUndefined, t0</span>
 819         cqeq t0, ValueNull, t0
 820     .done:
 821         fn(t0)
 822         return(t0)
 823     end)
 824 end
 825 
 826 equalNullComparisonOp(op_eq_null, OpEqNull,
 827     macro (value) orq ValueFalse, value end)
 828 
 829 
 830 equalNullComparisonOp(op_neq_null, OpNeqNull,
 831     macro (value) xorq ValueTrue, value end)
 832 
 833 
 834 llintOpWithReturn(op_is_undefined_or_null, OpIsUndefinedOrNull, macro (size, get, dispatch, return)
 835     get(m_operand, t1)
 836     loadConstantOrVariable(size, t1, t0)
<span class="line-modified"> 837     andq ~TagBitUndefined, t0</span>
 838     cqeq t0, ValueNull, t0
 839     orq ValueFalse, t0
 840     return(t0)
 841 end)
 842 
 843 
 844 macro strictEqOp(opcodeName, opcodeStruct, equalityOperation)
 845     llintOpWithReturn(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
 846         get(m_rhs, t0)
 847         get(m_lhs, t2)
 848         loadConstantOrVariable(size, t0, t1)
 849         loadConstantOrVariable(size, t2, t0)
 850         move t0, t2
 851         orq t1, t2
<span class="line-modified"> 852         btqz t2, tagMask, .slow</span>
<span class="line-modified"> 853         bqaeq t0, tagTypeNumber, .leftOK</span>
<span class="line-modified"> 854         btqnz t0, tagTypeNumber, .slow</span>
 855     .leftOK:
<span class="line-modified"> 856         bqaeq t1, tagTypeNumber, .rightOK</span>
<span class="line-modified"> 857         btqnz t1, tagTypeNumber, .slow</span>
 858     .rightOK:
 859         equalityOperation(t0, t1, t0)
 860         orq ValueFalse, t0
 861         return(t0)
 862 
 863     .slow:
 864         callSlowPath(_slow_path_%opcodeName%)
 865         dispatch()
 866     end)
 867 end
 868 
 869 
 870 strictEqOp(stricteq, OpStricteq,
 871     macro (left, right, result) cqeq left, right, result end)
 872 
 873 
 874 strictEqOp(nstricteq, OpNstricteq,
 875     macro (left, right, result) cqneq left, right, result end)
 876 
 877 
 878 macro strictEqualityJumpOp(opcodeName, opcodeStruct, equalityOperation)
 879     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
 880         get(m_lhs, t2)
 881         get(m_rhs, t3)
 882         loadConstantOrVariable(size, t2, t0)
 883         loadConstantOrVariable(size, t3, t1)
 884         move t0, t2
 885         orq t1, t2
<span class="line-modified"> 886         btqz t2, tagMask, .slow</span>
<span class="line-modified"> 887         bqaeq t0, tagTypeNumber, .leftOK</span>
<span class="line-modified"> 888         btqnz t0, tagTypeNumber, .slow</span>
 889     .leftOK:
<span class="line-modified"> 890         bqaeq t1, tagTypeNumber, .rightOK</span>
<span class="line-modified"> 891         btqnz t1, tagTypeNumber, .slow</span>
 892     .rightOK:
 893         equalityOperation(t0, t1, .jumpTarget)
 894         dispatch()
 895 
 896     .jumpTarget:
 897         jump(m_targetLabel)
 898 
 899     .slow:
 900         callSlowPath(_llint_slow_path_%opcodeName%)
 901         nextInstruction()
 902     end)
 903 end
 904 
 905 
 906 strictEqualityJumpOp(jstricteq, OpJstricteq,
 907     macro (left, right, target) bqeq left, right, target end)
 908 
 909 
 910 strictEqualityJumpOp(jnstricteq, OpJnstricteq,
 911     macro (left, right, target) bqneq left, right, target end)
 912 





 913 
<span class="line-removed"> 914 macro preOp(opcodeName, opcodeStruct, arithmeticOperation)</span>
<span class="line-removed"> 915     llintOp(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch)</span>
 916         get(m_srcDst, t0)
<span class="line-modified"> 917         loadq [cfr, t0, 8], t1</span>
<span class="line-modified"> 918         bqb t1, tagTypeNumber, .slow</span>
<span class="line-modified"> 919         arithmeticOperation(t1, .slow)</span>
<span class="line-modified"> 920         orq tagTypeNumber, t1</span>
<span class="line-modified"> 921         storeq t1, [cfr, t0, 8]</span>



 922         dispatch()

 923     .slow:
 924         callSlowPath(_slow_path_%opcodeName%)
 925         dispatch()
 926     end)
 927 end
 928 
 929 llintOpWithProfile(op_to_number, OpToNumber, macro (size, get, dispatch, return)
 930     get(m_operand, t0)
 931     loadConstantOrVariable(size, t0, t2)
<span class="line-modified"> 932     bqaeq t2, tagTypeNumber, .opToNumberIsImmediate</span>
<span class="line-modified"> 933     btqz t2, tagTypeNumber, .opToNumberSlow</span>
 934 .opToNumberIsImmediate:
 935     return(t2)
 936 
 937 .opToNumberSlow:
 938     callSlowPath(_slow_path_to_number)
 939     dispatch()
 940 end)
 941 













 942 
 943 llintOpWithReturn(op_to_string, OpToString, macro (size, get, dispatch, return)
 944     get(m_operand, t1)
 945     loadConstantOrVariable(size, t1, t0)
<span class="line-modified"> 946     btqnz t0, tagMask, .opToStringSlow</span>
 947     bbneq JSCell::m_type[t0], StringType, .opToStringSlow
 948 .opToStringIsString:
 949     return(t0)
 950 
 951 .opToStringSlow:
 952     callSlowPath(_slow_path_to_string)
 953     dispatch()
 954 end)
 955 
 956 
 957 llintOpWithProfile(op_to_object, OpToObject, macro (size, get, dispatch, return)
 958     get(m_operand, t0)
 959     loadConstantOrVariable(size, t0, t2)
<span class="line-modified"> 960     btqnz t2, tagMask, .opToObjectSlow</span>
 961     bbb JSCell::m_type[t2], ObjectType, .opToObjectSlow
 962     return(t2)
 963 
 964 .opToObjectSlow:
 965     callSlowPath(_slow_path_to_object)
 966     dispatch()
 967 end)
 968 
 969 
 970 llintOpWithMetadata(op_negate, OpNegate, macro (size, get, dispatch, metadata, return)





 971     get(m_operand, t0)
 972     loadConstantOrVariable(size, t0, t3)
 973     metadata(t1, t2)
<span class="line-modified"> 974     loadi OpNegate::Metadata::m_arithProfile + ArithProfile::m_bits[t1], t2</span>
<span class="line-removed"> 975     bqb t3, tagTypeNumber, .opNegateNotInt</span>
 976     btiz t3, 0x7fffffff, .opNegateSlow
 977     negi t3
<span class="line-modified"> 978     orq tagTypeNumber, t3</span>
<span class="line-modified"> 979     ori ArithProfileInt, t2</span>
<span class="line-removed"> 980     storei t2, OpNegate::Metadata::m_arithProfile + ArithProfile::m_bits[t1]</span>
 981     return(t3)
 982 .opNegateNotInt:
<span class="line-modified"> 983     btqz t3, tagTypeNumber, .opNegateSlow</span>
 984     xorq 0x8000000000000000, t3
<span class="line-modified"> 985     ori ArithProfileNumber, t2</span>
<span class="line-removed"> 986     storei t2, OpNegate::Metadata::m_arithProfile + ArithProfile::m_bits[t1]</span>
 987     return(t3)
 988 
 989 .opNegateSlow:
 990     callSlowPath(_slow_path_negate)
 991     dispatch()
 992 end)
 993 
 994 
 995 macro binaryOpCustomStore(opcodeName, opcodeStruct, integerOperationAndStore, doubleOperation)
 996     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)
 997         metadata(t5, t0)
 998 
 999         macro profile(type)
<span class="line-modified">1000             ori type, %opcodeStruct%::Metadata::m_arithProfile + ArithProfile::m_bits[t5]</span>
1001         end
1002 
1003         get(m_rhs, t0)
1004         get(m_lhs, t2)
1005         loadConstantOrVariable(size, t0, t1)
1006         loadConstantOrVariable(size, t2, t0)
<span class="line-modified">1007         bqb t0, tagTypeNumber, .op1NotInt</span>
<span class="line-modified">1008         bqb t1, tagTypeNumber, .op2NotInt</span>
1009         get(m_dst, t2)
1010         integerOperationAndStore(t1, t0, .slow, t2)
1011 
1012         profile(ArithProfileIntInt)
1013         dispatch()
1014 
1015     .op1NotInt:
1016         # First operand is definitely not an int, the second operand could be anything.
<span class="line-modified">1017         btqz t0, tagTypeNumber, .slow</span>
<span class="line-modified">1018         bqaeq t1, tagTypeNumber, .op1NotIntOp2Int</span>
<span class="line-modified">1019         btqz t1, tagTypeNumber, .slow</span>
<span class="line-modified">1020         addq tagTypeNumber, t1</span>
1021         fq2d t1, ft1
1022         profile(ArithProfileNumberNumber)
1023         jmp .op1NotIntReady
1024     .op1NotIntOp2Int:
1025         profile(ArithProfileNumberInt)
<span class="line-modified">1026         ci2d t1, ft1</span>
1027     .op1NotIntReady:
1028         get(m_dst, t2)
<span class="line-modified">1029         addq tagTypeNumber, t0</span>
1030         fq2d t0, ft0
1031         doubleOperation(ft1, ft0)
1032         fd2q ft0, t0
<span class="line-modified">1033         subq tagTypeNumber, t0</span>
1034         storeq t0, [cfr, t2, 8]
1035         dispatch()
1036 
1037     .op2NotInt:
1038         # First operand is definitely an int, the second is definitely not.
1039         get(m_dst, t2)
<span class="line-modified">1040         btqz t1, tagTypeNumber, .slow</span>
1041         profile(ArithProfileIntNumber)
<span class="line-modified">1042         ci2d t0, ft0</span>
<span class="line-modified">1043         addq tagTypeNumber, t1</span>
1044         fq2d t1, ft1
1045         doubleOperation(ft1, ft0)
1046         fd2q ft0, t0
<span class="line-modified">1047         subq tagTypeNumber, t0</span>
1048         storeq t0, [cfr, t2, 8]
1049         dispatch()
1050 
1051     .slow:
1052         callSlowPath(_slow_path_%opcodeName%)
1053         dispatch()
1054     end)
1055 end
1056 
1057 if X86_64 or X86_64_WIN
1058     binaryOpCustomStore(div, OpDiv,
1059         macro (left, right, slow, index)
1060             # Assume t3 is scratchable.
1061             btiz left, slow
1062             bineq left, -1, .notNeg2TwoThe31DivByNeg1
1063             bieq right, -2147483648, .slow
1064         .notNeg2TwoThe31DivByNeg1:
1065             btinz right, .intOK
1066             bilt left, 0, slow
1067         .intOK:
1068             move left, t3
1069             move right, t0
1070             cdqi
1071             idivi t3
1072             btinz t1, slow
<span class="line-modified">1073             orq tagTypeNumber, t0</span>
1074             storeq t0, [cfr, index, 8]
1075         end,
1076         macro (left, right) divd left, right end)
1077 else
1078     slowPathOp(div)
1079 end
1080 
1081 
1082 binaryOpCustomStore(mul, OpMul,
1083     macro (left, right, slow, index)
1084         # Assume t3 is scratchable.
1085         move right, t3
1086         bmulio left, t3, slow
1087         btinz t3, .done
1088         bilt left, 0, slow
1089         bilt right, 0, slow
1090     .done:
<span class="line-modified">1091         orq tagTypeNumber, t3</span>
1092         storeq t3, [cfr, index, 8]
1093     end,
1094     macro (left, right) muld left, right end)
1095 
1096 
1097 macro binaryOp(opcodeName, opcodeStruct, integerOperation, doubleOperation)
1098     binaryOpCustomStore(opcodeName, opcodeStruct,
1099         macro (left, right, slow, index)
1100             integerOperation(left, right, slow)
<span class="line-modified">1101             orq tagTypeNumber, right</span>
1102             storeq right, [cfr, index, 8]
1103         end,
1104         doubleOperation)
1105 end
1106 
1107 binaryOp(add, OpAdd,
1108     macro (left, right, slow) baddio left, right, slow end,
1109     macro (left, right) addd left, right end)
1110 
1111 
1112 binaryOp(sub, OpSub,
1113     macro (left, right, slow) bsubio left, right, slow end,
1114     macro (left, right) subd left, right end)
1115 
1116 
1117 llintOpWithReturn(op_unsigned, OpUnsigned, macro (size, get, dispatch, return)
1118     get(m_operand, t1)
1119     loadConstantOrVariable(size, t1, t2)
1120     bilt t2, 0, .opUnsignedSlow
1121     return(t2)
1122 .opUnsignedSlow:
1123     callSlowPath(_slow_path_unsigned)
1124     dispatch()
1125 end)
1126 
1127 
1128 macro commonBitOp(opKind, opcodeName, opcodeStruct, operation)
1129     opKind(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
1130         get(m_rhs, t0)
1131         get(m_lhs, t2)
1132         loadConstantOrVariable(size, t0, t1)
1133         loadConstantOrVariable(size, t2, t0)
<span class="line-modified">1134         bqb t0, tagTypeNumber, .slow</span>
<span class="line-modified">1135         bqb t1, tagTypeNumber, .slow</span>
1136         operation(t1, t0)
<span class="line-modified">1137         orq tagTypeNumber, t0</span>
1138         return(t0)
1139 
1140     .slow:
1141         callSlowPath(_slow_path_%opcodeName%)
1142         dispatch()
1143     end)
1144 end
1145 
1146 macro bitOp(opcodeName, opcodeStruct, operation)
1147     commonBitOp(llintOpWithReturn, opcodeName, opcodeStruct, operation)
1148 end
1149 
1150 macro bitOpProfiled(opcodeName, opcodeStruct, operation)
1151     commonBitOp(llintOpWithProfile, opcodeName, opcodeStruct, operation)
1152 end
1153 
1154 bitOpProfiled(lshift, OpLshift,
1155     macro (left, right) lshifti left, right end)
1156 
1157 
<span class="line-modified">1158 bitOp(rshift, OpRshift,</span>
1159     macro (left, right) rshifti left, right end)
1160 
1161 
1162 bitOp(urshift, OpUrshift,
1163     macro (left, right) urshifti left, right end)
1164 
1165 bitOpProfiled(bitand, OpBitand,
1166     macro (left, right) andi left, right end)
1167 
1168 bitOpProfiled(bitor, OpBitor,
1169     macro (left, right) ori left, right end)
1170 
1171 bitOpProfiled(bitxor, OpBitxor,
1172     macro (left, right) xori left, right end)
1173 
1174 llintOpWithProfile(op_bitnot, OpBitnot, macro (size, get, dispatch, return)
1175     get(m_operand, t0)
1176     loadConstantOrVariableInt32(size, t0, t3, .opBitNotSlow)
1177     noti t3
<span class="line-modified">1178     orq tagTypeNumber, t3</span>
1179     return(t3)
1180 .opBitNotSlow:
1181     callSlowPath(_slow_path_bitnot)
1182     dispatch()
1183 end)
1184 
1185 
1186 llintOp(op_overrides_has_instance, OpOverridesHasInstance, macro (size, get, dispatch)
1187     get(m_dst, t3)
1188 
1189     get(m_hasInstanceValue, t1)
1190     loadConstantOrVariable(size, t1, t0)
1191     loadp CodeBlock[cfr], t2
1192     loadp CodeBlock::m_globalObject[t2], t2
1193     loadp JSGlobalObject::m_functionProtoHasInstanceSymbolFunction[t2], t2
1194     bqneq t0, t2, .opOverridesHasInstanceNotDefaultSymbol
1195 
1196     get(m_constructor, t1)
1197     loadConstantOrVariable(size, t1, t0)
1198     tbz JSCell::m_flags[t0], ImplementsDefaultHasInstance, t1
</pre>
<hr />
<pre>
1201     dispatch()
1202 
1203 .opOverridesHasInstanceNotDefaultSymbol:
1204     storeq ValueTrue, [cfr, t3, 8]
1205     dispatch()
1206 end)
1207 
1208 
1209 llintOpWithReturn(op_is_empty, OpIsEmpty, macro (size, get, dispatch, return)
1210     get(m_operand, t1)
1211     loadConstantOrVariable(size, t1, t0)
1212     cqeq t0, ValueEmpty, t3
1213     orq ValueFalse, t3
1214     return(t3)
1215 end)
1216 
1217 
1218 llintOpWithReturn(op_is_undefined, OpIsUndefined, macro (size, get, dispatch, return)
1219     get(m_operand, t1)
1220     loadConstantOrVariable(size, t1, t0)
<span class="line-modified">1221     btqz t0, tagMask, .opIsUndefinedCell</span>
1222     cqeq t0, ValueUndefined, t3
1223     orq ValueFalse, t3
1224     return(t3)
1225 .opIsUndefinedCell:
1226     btbnz JSCell::m_flags[t0], MasqueradesAsUndefined, .masqueradesAsUndefined
1227     move ValueFalse, t1
1228     return(t1)
1229 .masqueradesAsUndefined:
1230     loadStructureWithScratch(t0, t3, t1, t2)
1231     loadp CodeBlock[cfr], t1
1232     loadp CodeBlock::m_globalObject[t1], t1
1233     cpeq Structure::m_globalObject[t3], t1, t0
1234     orq ValueFalse, t0
1235     return(t0)
1236 end)
1237 
1238 
1239 llintOpWithReturn(op_is_boolean, OpIsBoolean, macro (size, get, dispatch, return)
1240     get(m_operand, t1)
1241     loadConstantOrVariable(size, t1, t0)
1242     xorq ValueFalse, t0
1243     tqz t0, ~1, t0
1244     orq ValueFalse, t0
1245     return(t0)
1246 end)
1247 
1248 
1249 llintOpWithReturn(op_is_number, OpIsNumber, macro (size, get, dispatch, return)
1250     get(m_operand, t1)
1251     loadConstantOrVariable(size, t1, t0)
<span class="line-modified">1252     tqnz t0, tagTypeNumber, t1</span>
1253     orq ValueFalse, t1
1254     return(t1)
1255 end)
1256 
1257 
1258 llintOpWithReturn(op_is_cell_with_type, OpIsCellWithType, macro (size, get, dispatch, return)
1259     getu(size, OpIsCellWithType, m_type, t0)
1260     get(m_operand, t1)
1261     loadConstantOrVariable(size, t1, t3)
<span class="line-modified">1262     btqnz t3, tagMask, .notCellCase</span>
1263     cbeq JSCell::m_type[t3], t0, t1
1264     orq ValueFalse, t1
1265     return(t1)
1266 .notCellCase:
1267     return(ValueFalse)
1268 end)
1269 
1270 
1271 llintOpWithReturn(op_is_object, OpIsObject, macro (size, get, dispatch, return)
1272     get(m_operand, t1)
1273     loadConstantOrVariable(size, t1, t0)
<span class="line-modified">1274     btqnz t0, tagMask, .opIsObjectNotCell</span>
1275     cbaeq JSCell::m_type[t0], ObjectType, t1
1276     orq ValueFalse, t1
1277     return(t1)
1278 .opIsObjectNotCell:
1279     return(ValueFalse)
1280 end)
1281 
1282 
1283 macro loadPropertyAtVariableOffset(propertyOffsetAsInt, objectAndStorage, value)
1284     bilt propertyOffsetAsInt, firstOutOfLineOffset, .isInline
1285     loadp JSObject::m_butterfly[objectAndStorage], objectAndStorage
1286     negi propertyOffsetAsInt
1287     sxi2q propertyOffsetAsInt, propertyOffsetAsInt
1288     jmp .ready
1289 .isInline:
1290     addp sizeof JSObject - (firstOutOfLineOffset - 2) * 8, objectAndStorage
1291 .ready:
1292     loadq (firstOutOfLineOffset - 2) * 8[objectAndStorage, propertyOffsetAsInt, 8], value
1293 end
1294 
</pre>
<hr />
<pre>
1306 end
1307 
1308 
1309 llintOpWithMetadata(op_get_by_id_direct, OpGetByIdDirect, macro (size, get, dispatch, metadata, return)
1310     metadata(t2, t0)
1311     get(m_base, t0)
1312     loadConstantOrVariableCell(size, t0, t3, .opGetByIdDirectSlow)
1313     loadi JSCell::m_structureID[t3], t1
1314     loadi OpGetByIdDirect::Metadata::m_structureID[t2], t0
1315     bineq t0, t1, .opGetByIdDirectSlow
1316     loadi OpGetByIdDirect::Metadata::m_offset[t2], t1
1317     loadPropertyAtVariableOffset(t1, t3, t0)
1318     valueProfile(OpGetByIdDirect, t2, t0)
1319     return(t0)
1320 
1321 .opGetByIdDirectSlow:
1322     callSlowPath(_llint_slow_path_get_by_id_direct)
1323     dispatch()
1324 end)
1325 
<span class="line-removed">1326 </span>
1327 llintOpWithMetadata(op_get_by_id, OpGetById, macro (size, get, dispatch, metadata, return)
1328     metadata(t2, t1)
1329     loadb OpGetById::Metadata::m_modeMetadata.mode[t2], t1
1330     get(m_base, t0)
1331     loadConstantOrVariableCell(size, t0, t3, .opGetByIdSlow)
1332 
1333 .opGetByIdDefault:
1334     bbneq t1, constexpr GetByIdMode::Default, .opGetByIdProtoLoad
1335     loadi JSCell::m_structureID[t3], t1
1336     loadi OpGetById::Metadata::m_modeMetadata.defaultMode.structureID[t2], t0
1337     bineq t0, t1, .opGetByIdSlow
1338     loadis OpGetById::Metadata::m_modeMetadata.defaultMode.cachedOffset[t2], t1
1339     loadPropertyAtVariableOffset(t1, t3, t0)
1340     valueProfile(OpGetById, t2, t0)
1341     return(t0)
1342 
1343 .opGetByIdProtoLoad:
1344     bbneq t1, constexpr GetByIdMode::ProtoLoad, .opGetByIdArrayLength
1345     loadi JSCell::m_structureID[t3], t1
1346     loadi OpGetById::Metadata::m_modeMetadata.protoLoadMode.structureID[t2], t3
1347     bineq t3, t1, .opGetByIdSlow
1348     loadis OpGetById::Metadata::m_modeMetadata.protoLoadMode.cachedOffset[t2], t1
1349     loadp OpGetById::Metadata::m_modeMetadata.protoLoadMode.cachedSlot[t2], t3
1350     loadPropertyAtVariableOffset(t1, t3, t0)
1351     valueProfile(OpGetById, t2, t0)
1352     return(t0)
1353 
1354 .opGetByIdArrayLength:
1355     bbneq t1, constexpr GetByIdMode::ArrayLength, .opGetByIdUnset
1356     move t3, t0
1357     arrayProfile(OpGetById::Metadata::m_modeMetadata.arrayLengthMode.arrayProfile, t0, t2, t5)
1358     btiz t0, IsArray, .opGetByIdSlow
1359     btiz t0, IndexingShapeMask, .opGetByIdSlow
1360     loadCagedJSValue(JSObject::m_butterfly[t3], t0, t1)
1361     loadi -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], t0
1362     bilt t0, 0, .opGetByIdSlow
<span class="line-modified">1363     orq tagTypeNumber, t0</span>
1364     valueProfile(OpGetById, t2, t0)
1365     return(t0)
1366 
1367 .opGetByIdUnset:
1368     loadi JSCell::m_structureID[t3], t1
1369     loadi OpGetById::Metadata::m_modeMetadata.unsetMode.structureID[t2], t0
1370     bineq t0, t1, .opGetByIdSlow
1371     valueProfile(OpGetById, t2, ValueUndefined)
1372     return(ValueUndefined)
1373 
1374 .opGetByIdSlow:
1375     callSlowPath(_llint_slow_path_get_by_id)
1376     dispatch()







1377 end)
1378 
1379 
1380 llintOpWithMetadata(op_put_by_id, OpPutById, macro (size, get, dispatch, metadata, return)
1381     get(m_base, t3)
1382     loadConstantOrVariableCell(size, t3, t0, .opPutByIdSlow)
1383     metadata(t5, t2)
1384     loadi OpPutById::Metadata::m_oldStructureID[t5], t2
1385     bineq t2, JSCell::m_structureID[t0], .opPutByIdSlow
1386 
1387     # At this point, we have:
1388     # t0 -&gt; object base
1389     # t2 -&gt; current structure ID
1390     # t5 -&gt; metadata
1391 
1392     loadi OpPutById::Metadata::m_newStructureID[t5], t1
1393     btiz t1, .opPutByIdNotTransition
1394 
1395     # This is the transition case. t1 holds the new structureID. t2 holds the old structure ID.
1396     # If we have a chain, we need to check it. t0 is the base. We may clobber t1 to use it as
1397     # scratch.
1398     loadp OpPutById::Metadata::m_structureChain[t5], t3
1399     btpz t3, .opPutByIdTransitionDirect
1400 
<span class="line-modified">1401     structureIDToStructureWithScratch(t2, t1, t3)</span>










1402 
<span class="line-modified">1403     # reload the StructureChain since we used t3 as a scratch above</span>
<span class="line-removed">1404     loadp OpPutById::Metadata::m_structureChain[t5], t3</span>
1405 
1406     loadp StructureChain::m_vector[t3], t3
1407     assert(macro (ok) btpnz t3, ok end)
1408 
1409     loadq Structure::m_prototype[t2], t2
1410     bqeq t2, ValueNull, .opPutByIdTransitionChainDone
1411 .opPutByIdTransitionChainLoop:
<span class="line-removed">1412     # At this point, t2 contains a prototye, and [t3] contains the Structure* that we want that</span>
<span class="line-removed">1413     # prototype to have. We don&#39;t want to have to load the Structure* for t2. Instead, we load</span>
<span class="line-removed">1414     # the Structure* from [t3], and then we compare its id to the id in the header of t2.</span>
<span class="line-removed">1415     loadp [t3], t1</span>
1416     loadi JSCell::m_structureID[t2], t2
<span class="line-modified">1417     # Now, t1 has the Structure* and t2 has the StructureID that we want that Structure* to have.</span>
<span class="line-modified">1418     bineq t2, Structure::m_blob + StructureIDBlob::u.fields.structureID[t1], .opPutByIdSlow</span>
<span class="line-modified">1419     addp PtrSize, t3</span>
<span class="line-modified">1420     loadq Structure::m_prototype[t1], t2</span>
1421     bqneq t2, ValueNull, .opPutByIdTransitionChainLoop
1422 
1423 .opPutByIdTransitionChainDone:
1424     # Reload the new structure, since we clobbered it above.
1425     loadi OpPutById::Metadata::m_newStructureID[t5], t1



1426 
1427 .opPutByIdTransitionDirect:
1428     storei t1, JSCell::m_structureID[t0]
1429     writeBarrierOnOperandWithReload(size, get, m_base, macro ()
1430         # Reload metadata into t5
1431         metadata(t5, t1)
1432         # Reload base into t0
1433         get(m_base, t1)
1434         loadConstantOrVariable(size, t1, t0)
1435     end)
1436 
1437 .opPutByIdNotTransition:
1438     # The only thing live right now is t0, which holds the base.
1439     get(m_value, t1)
1440     loadConstantOrVariable(size, t1, t2)
1441     loadi OpPutById::Metadata::m_offset[t5], t1
1442     storePropertyAtVariableOffset(t1, t0, t2)
1443     writeBarrierOnOperands(size, get, m_base, m_value)
1444     dispatch()
1445 
1446 .opPutByIdSlow:
1447     callSlowPath(_llint_slow_path_put_by_id)
1448     dispatch()





1449 end)
1450 
1451 
1452 llintOpWithMetadata(op_get_by_val, OpGetByVal, macro (size, get, dispatch, metadata, return)
1453     macro finishGetByVal(result, scratch)
1454         get(m_dst, scratch)
1455         storeq result, [cfr, scratch, 8]
1456         valueProfile(OpGetByVal, t5, result)
1457         dispatch()
1458     end
1459 
1460     macro finishIntGetByVal(result, scratch)
<span class="line-modified">1461         orq tagTypeNumber, result</span>
1462         finishGetByVal(result, scratch)
1463     end
1464 
1465     macro finishDoubleGetByVal(result, scratch1, scratch2)
1466         fd2q result, scratch1
<span class="line-modified">1467         subq tagTypeNumber, scratch1</span>
1468         finishGetByVal(scratch1, scratch2)
1469     end
1470 
1471     metadata(t5, t2)
1472 
1473     get(m_base, t2)
1474     loadConstantOrVariableCell(size, t2, t0, .opGetByValSlow)
1475 
1476     move t0, t2
1477     arrayProfile(OpGetByVal::Metadata::m_arrayProfile, t2, t5, t1)
1478 
1479     get(m_property, t3)
1480     loadConstantOrVariableInt32(size, t3, t1, .opGetByValSlow)
1481     sxi2q t1, t1
1482 
<span class="line-modified">1483     loadCagedJSValue(JSObject::m_butterfly[t0], t3, tagTypeNumber)</span>
<span class="line-modified">1484     move TagTypeNumber, tagTypeNumber</span>
1485 
1486     andi IndexingShapeMask, t2
1487     bieq t2, Int32Shape, .opGetByValIsContiguous
1488     bineq t2, ContiguousShape, .opGetByValNotContiguous
1489 
1490 .opGetByValIsContiguous:
1491     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t3], .opGetByValSlow
1492     get(m_dst, t0)
1493     loadq [t3, t1, 8], t2
1494     btqz t2, .opGetByValSlow
1495     jmp .opGetByValDone
1496 
1497 .opGetByValNotContiguous:
1498     bineq t2, DoubleShape, .opGetByValNotDouble
1499     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t3], .opGetByValSlow
1500     get(m_dst, t0)
1501     loadd [t3, t1, 8], ft0
1502     bdnequn ft0, ft0, .opGetByValSlow
1503     fd2q ft0, t2
<span class="line-modified">1504     subq tagTypeNumber, t2</span>
1505     jmp .opGetByValDone
1506     
1507 .opGetByValNotDouble:
1508     subi ArrayStorageShape, t2
1509     bia t2, SlowPutArrayStorageShape - ArrayStorageShape, .opGetByValNotIndexedStorage
1510     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t3], .opGetByValSlow
1511     get(m_dst, t0)
1512     loadq ArrayStorage::m_vector[t3, t1, 8], t2
1513     btqz t2, .opGetByValSlow
1514 
1515 .opGetByValDone:
1516     storeq t2, [cfr, t0, 8]
1517     valueProfile(OpGetByVal, t5, t2)
1518     dispatch()
1519 
1520 .opGetByValNotIndexedStorage:
1521     # First lets check if we even have a typed array. This lets us do some boilerplate up front.
1522     loadb JSCell::m_type[t0], t2
1523     subi FirstTypedArrayType, t2
1524     biaeq t2, NumberOfTypedArrayTypesExcludingDataView, .opGetByValSlow
</pre>
<hr />
<pre>
1600 .opGetByValUint32Array:
1601     # We have Uint32ArrayType.
1602     # This is the hardest part because of large unsigned values.
1603     loadi [t3, t1, 4], t0
1604     bilt t0, 0, .opGetByValSlow # This case is still awkward to implement in LLInt.
1605     finishIntGetByVal(t0, t1)
1606 
1607 .opGetByValFloat32ArrayOrFloat64Array:
1608     # We have one of Float32ArrayType or Float64ArrayType. Sadly, we cannot handle Float32Array
1609     # inline yet. That would require some offlineasm changes.
1610     bieq t2, Float32ArrayType - FirstTypedArrayType, .opGetByValSlow
1611 
1612     # We have Float64ArrayType.
1613     loadd [t3, t1, 8], ft0
1614     bdnequn ft0, ft0, .opGetByValSlow
1615     finishDoubleGetByVal(ft0, t0, t1)
1616 
1617 .opGetByValSlow:
1618     callSlowPath(_llint_slow_path_get_by_val)
1619     dispatch()







1620 end)
1621 
1622 
<span class="line-modified">1623 macro putByValOp(opcodeName, opcodeStruct)</span>
1624     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)
1625         macro contiguousPutByVal(storeCallback)
1626             biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], .outOfBounds
1627         .storeResult:
1628             get(m_value, t2)
1629             storeCallback(t2, t1, [t0, t3, 8])
1630             dispatch()
1631 
1632         .outOfBounds:
1633             biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t0], .opPutByValOutOfBounds
1634             storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_mayStoreToHole[t5]
1635             addi 1, t3, t2
1636             storei t2, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0]
1637             jmp .storeResult
1638         end
1639 
1640         get(m_base, t0)
1641         loadConstantOrVariableCell(size, t0, t1, .opPutByValSlow)
1642         move t1, t2
1643         metadata(t5, t0)
1644         arrayProfile(%opcodeStruct%::Metadata::m_arrayProfile, t2, t5, t0)
1645         get(m_property, t0)
1646         loadConstantOrVariableInt32(size, t0, t3, .opPutByValSlow)
1647         sxi2q t3, t3
<span class="line-modified">1648         loadCagedJSValue(JSObject::m_butterfly[t1], t0, tagTypeNumber)</span>
<span class="line-modified">1649         move TagTypeNumber, tagTypeNumber</span>
1650         btinz t2, CopyOnWrite, .opPutByValSlow
1651         andi IndexingShapeMask, t2
1652         bineq t2, Int32Shape, .opPutByValNotInt32
1653         contiguousPutByVal(
1654             macro (operand, scratch, address)
1655                 loadConstantOrVariable(size, operand, scratch)
<span class="line-modified">1656                 bqb scratch, tagTypeNumber, .opPutByValSlow</span>
1657                 storeq scratch, address
1658                 writeBarrierOnOperands(size, get, m_base, m_value)
1659             end)
1660 
1661     .opPutByValNotInt32:
1662         bineq t2, DoubleShape, .opPutByValNotDouble
1663         contiguousPutByVal(
1664             macro (operand, scratch, address)
1665                 loadConstantOrVariable(size, operand, scratch)
<span class="line-modified">1666                 bqb scratch, tagTypeNumber, .notInt</span>
<span class="line-modified">1667                 ci2d scratch, ft0</span>
1668                 jmp .ready
1669             .notInt:
<span class="line-modified">1670                 addq tagTypeNumber, scratch</span>
1671                 fq2d scratch, ft0
1672                 bdnequn ft0, ft0, .opPutByValSlow
1673             .ready:
1674                 stored ft0, address
1675                 writeBarrierOnOperands(size, get, m_base, m_value)
1676             end)
1677 
1678     .opPutByValNotDouble:
1679         bineq t2, ContiguousShape, .opPutByValNotContiguous
1680         contiguousPutByVal(
1681             macro (operand, scratch, address)
1682                 loadConstantOrVariable(size, operand, scratch)
1683                 storeq scratch, address
1684                 writeBarrierOnOperands(size, get, m_base, m_value)
1685             end)
1686 
1687     .opPutByValNotContiguous:
1688         bineq t2, ArrayStorageShape, .opPutByValSlow
1689         biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t0], .opPutByValOutOfBounds
1690         btqz ArrayStorage::m_vector[t0, t3, 8], .opPutByValArrayStorageEmpty
1691     .opPutByValArrayStorageStoreResult:
1692         get(m_value, t2)
1693         loadConstantOrVariable(size, t2, t1)
1694         storeq t1, ArrayStorage::m_vector[t0, t3, 8]
1695         writeBarrierOnOperands(size, get, m_base, m_value)
1696         dispatch()
1697 
1698     .opPutByValArrayStorageEmpty:
1699         storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_mayStoreToHole[t5]
1700         addi 1, ArrayStorage::m_numValuesInVector[t0]
1701         bib t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], .opPutByValArrayStorageStoreResult
1702         addi 1, t3, t1
1703         storei t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0]
1704         jmp .opPutByValArrayStorageStoreResult
1705 
1706     .opPutByValOutOfBounds:
1707         storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_outOfBounds[t5]
1708     .opPutByValSlow:
1709         callSlowPath(_llint_slow_path_%opcodeName%)
1710         dispatch()



1711     end)
1712 end
1713 
<span class="line-modified">1714 putByValOp(put_by_val, OpPutByVal)</span>




1715 
<span class="line-modified">1716 putByValOp(put_by_val_direct, OpPutByValDirect)</span>
1717 
1718 
1719 macro llintJumpTrueOrFalseOp(opcodeName, opcodeStruct, conditionOp)
1720     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1721         get(m_condition, t1)
1722         loadConstantOrVariable(size, t1, t0)
1723         btqnz t0, ~0xf, .slow
1724         conditionOp(t0, .target)
1725         dispatch()
1726 
1727     .target:
1728         jump(m_targetLabel)
1729 
1730     .slow:
1731         callSlowPath(_llint_slow_path_%opcodeName%)
1732         nextInstruction()
1733     end)
1734 end
1735 
1736 
1737 macro equalNullJumpOp(opcodeName, opcodeStruct, cellHandler, immediateHandler)
1738     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1739         get(m_value, t0)
1740         assertNotConstant(size, t0)
1741         loadq [cfr, t0, 8], t0
<span class="line-modified">1742         btqnz t0, tagMask, .immediate</span>
1743         loadStructureWithScratch(t0, t2, t1, t3)
1744         cellHandler(t2, JSCell::m_flags[t0], .target)
1745         dispatch()
1746 
1747     .target:
1748         jump(m_targetLabel)
1749 
1750     .immediate:
<span class="line-modified">1751         andq ~TagBitUndefined, t0</span>
1752         immediateHandler(t0, .target)
1753         dispatch()
1754     end)
1755 end
1756 
1757 equalNullJumpOp(jeq_null, OpJeqNull,
1758     macro (structure, value, target) 
1759         btbz value, MasqueradesAsUndefined, .notMasqueradesAsUndefined
1760         loadp CodeBlock[cfr], t0
1761         loadp CodeBlock::m_globalObject[t0], t0
1762         bpeq Structure::m_globalObject[structure], t0, target
1763 .notMasqueradesAsUndefined:
1764     end,
1765     macro (value, target) bqeq value, ValueNull, target end)
1766 
1767 
1768 equalNullJumpOp(jneq_null, OpJneqNull,
1769     macro (structure, value, target) 
1770         btbz value, MasqueradesAsUndefined, target
1771         loadp CodeBlock[cfr], t0
1772         loadp CodeBlock::m_globalObject[t0], t0
1773         bpneq Structure::m_globalObject[structure], t0, target
1774     end,
1775     macro (value, target) bqneq value, ValueNull, target end)
1776 
1777 macro undefinedOrNullJumpOp(opcodeName, opcodeStruct, fn)
1778     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1779         get(m_value, t1)
1780         loadConstantOrVariable(size, t1, t0)
<span class="line-modified">1781         andq ~TagBitUndefined, t0</span>
1782         fn(t0, .target)
1783         dispatch()
1784 
1785     .target:
1786         jump(m_targetLabel)
1787     end)
1788 end
1789 
1790 undefinedOrNullJumpOp(jundefined_or_null, OpJundefinedOrNull,
1791     macro (value, target) bqeq value, ValueNull, target end)
1792 
1793 undefinedOrNullJumpOp(jnundefined_or_null, OpJnundefinedOrNull,
1794     macro (value, target) bqneq value, ValueNull, target end)
1795 
1796 llintOpWithMetadata(op_jneq_ptr, OpJneqPtr, macro (size, get, dispatch, metadata, return)
1797     get(m_value, t0)
<span class="line-modified">1798     getu(size, OpJneqPtr, m_specialPointer, t1)</span>
<span class="line-modified">1799     loadp CodeBlock[cfr], t2</span>
<span class="line-modified">1800     loadp CodeBlock::m_globalObject[t2], t2</span>
<span class="line-removed">1801     loadp JSGlobalObject::m_specialPointers[t2, t1, PtrSize], t1</span>
<span class="line-removed">1802     bpneq t1, [cfr, t0, 8], .opJneqPtrTarget</span>
1803     dispatch()
1804 
1805 .opJneqPtrTarget:
1806     metadata(t5, t0)
1807     storeb 1, OpJneqPtr::Metadata::m_hasJumped[t5]
1808     get(m_targetLabel, t0)
<span class="line-modified">1809     jumpImpl(t0)</span>
1810 end)
1811 
1812 
1813 macro compareJumpOp(opcodeName, opcodeStruct, integerCompare, doubleCompare)
1814     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1815         get(m_lhs, t2)
1816         get(m_rhs, t3)
1817         loadConstantOrVariable(size, t2, t0)
1818         loadConstantOrVariable(size, t3, t1)
<span class="line-modified">1819         bqb t0, tagTypeNumber, .op1NotInt</span>
<span class="line-modified">1820         bqb t1, tagTypeNumber, .op2NotInt</span>
1821         integerCompare(t0, t1, .jumpTarget)
1822         dispatch()
1823 
1824     .op1NotInt:
<span class="line-modified">1825         btqz t0, tagTypeNumber, .slow</span>
<span class="line-modified">1826         bqb t1, tagTypeNumber, .op1NotIntOp2NotInt</span>
<span class="line-modified">1827         ci2d t1, ft1</span>
1828         jmp .op1NotIntReady
1829     .op1NotIntOp2NotInt:
<span class="line-modified">1830         btqz t1, tagTypeNumber, .slow</span>
<span class="line-modified">1831         addq tagTypeNumber, t1</span>
1832         fq2d t1, ft1
1833     .op1NotIntReady:
<span class="line-modified">1834         addq tagTypeNumber, t0</span>
1835         fq2d t0, ft0
1836         doubleCompare(ft0, ft1, .jumpTarget)
1837         dispatch()
1838 
1839     .op2NotInt:
<span class="line-modified">1840         ci2d t0, ft0</span>
<span class="line-modified">1841         btqz t1, tagTypeNumber, .slow</span>
<span class="line-modified">1842         addq tagTypeNumber, t1</span>
1843         fq2d t1, ft1
1844         doubleCompare(ft0, ft1, .jumpTarget)
1845         dispatch()
1846 
1847     .jumpTarget:
1848         jump(m_targetLabel)
1849 
1850     .slow:
1851         callSlowPath(_llint_slow_path_%opcodeName%)
1852         nextInstruction()
1853     end)
1854 end
1855 
1856 
1857 macro equalityJumpOp(opcodeName, opcodeStruct, integerComparison)
1858     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1859         get(m_lhs, t2)
1860         get(m_rhs, t3)
1861         loadConstantOrVariableInt32(size, t2, t0, .slow)
1862         loadConstantOrVariableInt32(size, t3, t1, .slow)
</pre>
<hr />
<pre>
1893         get(m_lhs, t2)
1894         get(m_rhs,  t0)
1895         loadConstantOrVariable(size, t0, t1)
1896         loadConstantOrVariable(size, t2, t0)
1897         integerCompareAndSet(t0, t1, t0)
1898         orq ValueFalse, t0
1899         return(t0)
1900     end)
1901 end
1902 
1903 
1904 llintOpWithJump(op_switch_imm, OpSwitchImm, macro (size, get, jump, dispatch)
1905     get(m_scrutinee, t2)
1906     getu(size, OpSwitchImm, m_tableIndex, t3)
1907     loadConstantOrVariable(size, t2, t1)
1908     loadp CodeBlock[cfr], t2
1909     loadp CodeBlock::m_rareData[t2], t2
1910     muli sizeof SimpleJumpTable, t3
1911     loadp CodeBlock::RareData::m_switchJumpTables + VectorBufferOffset[t2], t2
1912     addp t3, t2
<span class="line-modified">1913     bqb t1, tagTypeNumber, .opSwitchImmNotInt</span>
1914     subi SimpleJumpTable::min[t2], t1
1915     biaeq t1, SimpleJumpTable::branchOffsets + VectorSizeOffset[t2], .opSwitchImmFallThrough
1916     loadp SimpleJumpTable::branchOffsets + VectorBufferOffset[t2], t3
1917     loadis [t3, t1, 4], t1
1918     btiz t1, .opSwitchImmFallThrough
1919     dispatchIndirect(t1)
1920 
1921 .opSwitchImmNotInt:
<span class="line-modified">1922     btqnz t1, tagTypeNumber, .opSwitchImmSlow   # Go slow if it&#39;s a double.</span>
1923 .opSwitchImmFallThrough:
1924     jump(m_defaultOffset)
1925 
1926 .opSwitchImmSlow:
1927     callSlowPath(_llint_slow_path_switch_imm)
1928     nextInstruction()
1929 end)
1930 
1931 
1932 llintOpWithJump(op_switch_char, OpSwitchChar, macro (size, get, jump, dispatch)
1933     get(m_scrutinee, t2)
1934     getu(size, OpSwitchChar, m_tableIndex, t3)
1935     loadConstantOrVariable(size, t2, t1)
1936     loadp CodeBlock[cfr], t2
1937     loadp CodeBlock::m_rareData[t2], t2
1938     muli sizeof SimpleJumpTable, t3
1939     loadp CodeBlock::RareData::m_switchJumpTables + VectorBufferOffset[t2], t2
1940     addp t3, t2
<span class="line-modified">1941     btqnz t1, tagMask, .opSwitchCharFallThrough</span>
1942     bbneq JSCell::m_type[t1], StringType, .opSwitchCharFallThrough
1943     loadp JSString::m_fiber[t1], t0
1944     btpnz t0, isRopeInPointer, .opSwitchOnRope
1945     bineq StringImpl::m_length[t0], 1, .opSwitchCharFallThrough
1946     loadp StringImpl::m_data8[t0], t1
1947     btinz StringImpl::m_hashAndFlags[t0], HashFlags8BitBuffer, .opSwitchChar8Bit
1948     loadh [t1], t0
1949     jmp .opSwitchCharReady
1950 .opSwitchChar8Bit:
1951     loadb [t1], t0
1952 .opSwitchCharReady:
1953     subi SimpleJumpTable::min[t2], t0
1954     biaeq t0, SimpleJumpTable::branchOffsets + VectorSizeOffset[t2], .opSwitchCharFallThrough
1955     loadp SimpleJumpTable::branchOffsets + VectorBufferOffset[t2], t2
1956     loadis [t2, t0, 4], t1
1957     btiz t1, .opSwitchCharFallThrough
1958     dispatchIndirect(t1)
1959 
1960 .opSwitchCharFallThrough:
1961     jump(m_defaultOffset)
1962 
1963 .opSwitchOnRope:
1964     bineq JSRopeString::m_compactFibers + JSRopeString::CompactFibers::m_length[t1], 1, .opSwitchCharFallThrough
1965 
1966 .opSwitchOnRopeChar:
1967     callSlowPath(_llint_slow_path_switch_char)
1968     nextInstruction()
1969 end)
1970 
1971 
1972 # we assume t5 contains the metadata, and we should not scratch that
1973 macro arrayProfileForCall(opcodeStruct, getu)
1974     getu(m_argv, t3)
1975     negp t3
1976     loadq ThisArgumentOffset[cfr, t3, 8], t0
<span class="line-modified">1977     btqnz t0, tagMask, .done</span>
1978     loadi JSCell::m_structureID[t0], t3
1979     storei t3, %opcodeStruct%::Metadata::m_callLinkInfo.m_arrayProfile.m_lastSeenStructureID[t5]
1980 .done:
1981 end
1982 
1983 macro commonCallOp(opcodeName, slowPath, opcodeStruct, prepareCall, prologue)
1984     llintOpWithMetadata(opcodeName, opcodeStruct, macro (size, get, dispatch, metadata, return)
1985         metadata(t5, t0)
1986 
1987         prologue(macro (fieldName, dst)
1988             getu(size, opcodeStruct, fieldName, dst)
1989         end, metadata)
1990 
1991         get(m_callee, t0)
1992         loadp %opcodeStruct%::Metadata::m_callLinkInfo.m_calleeOrLastSeenCalleeWithLinkBit[t5], t2
1993         loadConstantOrVariable(size, t0, t3)
1994         bqneq t3, t2, .opCallSlow
1995         getu(size, opcodeStruct, m_argv, t3)
1996         lshifti 3, t3
1997         negp t3
1998         addp cfr, t3
1999         storeq t2, Callee[t3]
2000         getu(size, opcodeStruct, m_argc, t2)
<span class="line-modified">2001         storei PC, ArgumentCount + TagOffset[cfr]</span>
<span class="line-modified">2002         storei t2, ArgumentCount + PayloadOffset[t3]</span>
2003         move t3, sp
2004         prepareCall(%opcodeStruct%::Metadata::m_callLinkInfo.m_machineCodeTarget[t5], t2, t3, t4, JSEntryPtrTag)
<span class="line-modified">2005         callTargetFunction(size, opcodeStruct, dispatch, %opcodeStruct%::Metadata::m_callLinkInfo.m_machineCodeTarget[t5], JSEntryPtrTag)</span>
2006 
2007     .opCallSlow:
<span class="line-modified">2008         slowPathForCall(size, opcodeStruct, dispatch, slowPath, prepareCall)</span>
2009     end)
2010 end
2011 
2012 llintOp(op_ret, OpRet, macro (size, get, dispatch)
2013     checkSwitchToJITForEpilogue()
2014     get(m_value, t2)
2015     loadConstantOrVariable(size, t2, r0)
2016     doReturn()
2017 end)
2018 
2019 
2020 llintOpWithReturn(op_to_primitive, OpToPrimitive, macro (size, get, dispatch, return)
2021     get(m_src, t2)
2022     loadConstantOrVariable(size, t2, t0)
<span class="line-modified">2023     btqnz t0, tagMask, .opToPrimitiveIsImm</span>
2024     bbaeq JSCell::m_type[t0], ObjectType, .opToPrimitiveSlowCase
2025 .opToPrimitiveIsImm:
2026     return(t0)
2027 
2028 .opToPrimitiveSlowCase:
2029     callSlowPath(_slow_path_to_primitive)
2030     dispatch()
2031 end)
2032 
2033 

















2034 commonOp(llint_op_catch, macro() end, macro (size)
2035     # This is where we end up from the JIT&#39;s throw trampoline (because the
2036     # machine code return address will be set to _llint_op_catch), and from
2037     # the interpreter&#39;s throw trampoline (see _llint_throw_trampoline).
2038     # The throwing code must have known that we were throwing to the interpreter,
2039     # and have set VM::targetInterpreterPCForThrow.
2040     loadp Callee[cfr], t3
<span class="line-modified">2041     andp MarkedBlockMask, t3</span>
<span class="line-removed">2042     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3</span>
2043     restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(t3, t0)
2044     loadp VM::callFrameForCatch[t3], cfr
2045     storep 0, VM::callFrameForCatch[t3]
2046     restoreStackPointerAfterCall()
2047 
2048     loadp CodeBlock[cfr], PB
2049     loadp CodeBlock::m_metadata[PB], metadataTable
2050     loadp CodeBlock::m_instructionsRawPointer[PB], PB
2051     loadp VM::targetInterpreterPCForThrow[t3], PC
2052     subp PB, PC
2053 
2054     callSlowPath(_llint_slow_path_check_if_exception_is_uncatchable_and_notify_profiler)
2055     bpeq r1, 0, .isCatchableException
2056     jmp _llint_throw_from_slow_path_trampoline
2057 
2058 .isCatchableException:
<span class="line-modified">2059     loadp Callee[cfr], t3</span>
<span class="line-modified">2060     andp MarkedBlockMask, t3</span>
<span class="line-removed">2061     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3</span>
2062 
2063     loadp VM::m_exception[t3], t0
2064     storep 0, VM::m_exception[t3]
2065     get(size, OpCatch, m_exception, t2)
2066     storeq t0, [cfr, t2, 8]
2067 
2068     loadq Exception::m_value[t0], t3
2069     get(size, OpCatch, m_thrownValue, t2)
2070     storeq t3, [cfr, t2, 8]
2071 
2072     traceExecution()
2073 
2074     callSlowPath(_llint_slow_path_profile_catch)
2075 
2076     dispatchOp(size, op_catch)
2077 end)
2078 
2079 
2080 llintOp(op_end, OpEnd, macro (size, get, dispatch)
2081     checkSwitchToJITForEpilogue()
2082     get(m_value, t0)
2083     assertNotConstant(size, t0)
2084     loadq [cfr, t0, 8], r0
2085     doReturn()
2086 end)
2087 
2088 
2089 op(llint_throw_from_slow_path_trampoline, macro ()
2090     loadp Callee[cfr], t1
<span class="line-modified">2091     andp MarkedBlockMask, t1</span>
<span class="line-removed">2092     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1</span>
2093     copyCalleeSavesToVMEntryFrameCalleeSavesBuffer(t1, t2)
2094 
2095     callSlowPath(_llint_slow_path_handle_exception)
2096 
2097     # When throwing from the interpreter (i.e. throwing from LLIntSlowPaths), so
2098     # the throw target is not necessarily interpreted code, we come to here.
2099     # This essentially emulates the JIT&#39;s throwing protocol.
2100     loadp Callee[cfr], t1
<span class="line-modified">2101     andp MarkedBlockMask, t1</span>
<span class="line-removed">2102     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1</span>
2103     jmp VM::targetMachinePCForThrow[t1], ExceptionHandlerPtrTag
2104 end)
2105 
2106 
2107 op(llint_throw_during_call_trampoline, macro ()
2108     preserveReturnAddressAfterCall(t2)
2109     jmp _llint_throw_from_slow_path_trampoline
2110 end)
2111 
2112 
2113 macro nativeCallTrampoline(executableOffsetToFunction)
<span class="line-removed">2114 </span>
2115     functionPrologue()
2116     storep 0, CodeBlock[cfr]
<span class="line-modified">2117     loadp Callee[cfr], t0</span>
<span class="line-modified">2118     andp MarkedBlockMask, t0, t1</span>
<span class="line-modified">2119     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1</span>
<span class="line-modified">2120     storep cfr, VM::topCallFrame[t1]</span>




2121     if ARM64 or ARM64E or C_LOOP or C_LOOP_WIN
2122         storep lr, ReturnPC[cfr]
2123     end
<span class="line-modified">2124     move cfr, a0</span>
<span class="line-removed">2125     loadp Callee[cfr], t1</span>
<span class="line-removed">2126     loadp JSFunction::m_executable[t1], t1</span>
2127     checkStackPointerAlignment(t3, 0xdead0001)
2128     if C_LOOP or C_LOOP_WIN
<span class="line-modified">2129         cloopCallNative executableOffsetToFunction[t1]</span>
2130     else
2131         if X86_64_WIN
2132             subp 32, sp
<span class="line-modified">2133             call executableOffsetToFunction[t1], JSEntryPtrTag</span>
2134             addp 32, sp
2135         else
<span class="line-modified">2136             call executableOffsetToFunction[t1], JSEntryPtrTag</span>
2137         end
2138     end
2139 
2140     loadp Callee[cfr], t3
<span class="line-modified">2141     andp MarkedBlockMask, t3</span>
<span class="line-modified">2142     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3</span>
2143 
2144     btpnz VM::m_exception[t3], .handleException
2145 
2146     functionEpilogue()
2147     ret
2148 
2149 .handleException:
2150     storep cfr, VM::topCallFrame[t3]
2151     jmp _llint_throw_from_slow_path_trampoline
2152 end
2153 
2154 macro internalFunctionCallTrampoline(offsetOfFunction)
2155     functionPrologue()
2156     storep 0, CodeBlock[cfr]
<span class="line-modified">2157     loadp Callee[cfr], t0</span>
<span class="line-modified">2158     andp MarkedBlockMask, t0, t1</span>
<span class="line-modified">2159     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1</span>
<span class="line-modified">2160     storep cfr, VM::topCallFrame[t1]</span>
2161     if ARM64 or ARM64E or C_LOOP or C_LOOP_WIN
2162         storep lr, ReturnPC[cfr]
2163     end
<span class="line-modified">2164     move cfr, a0</span>
<span class="line-removed">2165     loadp Callee[cfr], t1</span>
2166     checkStackPointerAlignment(t3, 0xdead0001)
2167     if C_LOOP or C_LOOP_WIN
<span class="line-modified">2168         cloopCallNative offsetOfFunction[t1]</span>
2169     else
2170         if X86_64_WIN
2171             subp 32, sp
<span class="line-modified">2172             call offsetOfFunction[t1], JSEntryPtrTag</span>
2173             addp 32, sp
2174         else
<span class="line-modified">2175             call offsetOfFunction[t1], JSEntryPtrTag</span>
2176         end
2177     end
2178 
2179     loadp Callee[cfr], t3
<span class="line-modified">2180     andp MarkedBlockMask, t3</span>
<span class="line-modified">2181     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3</span>
2182 
2183     btpnz VM::m_exception[t3], .handleException
2184 
2185     functionEpilogue()
2186     ret
2187 
2188 .handleException:
2189     storep cfr, VM::topCallFrame[t3]
2190     jmp _llint_throw_from_slow_path_trampoline
2191 end
2192 
2193 macro varInjectionCheck(slowPath, scratch)
2194     loadp CodeBlock[cfr], scratch
2195     loadp CodeBlock::m_globalObject[scratch], scratch
2196     loadp JSGlobalObject::m_varInjectionWatchpoint[scratch], scratch
2197     bbeq WatchpointSet::m_state[scratch], IsInvalidated, slowPath
2198 end
2199 
2200 llintOpWithMetadata(op_resolve_scope, OpResolveScope, macro (size, get, dispatch, metadata, return)
2201     metadata(t5, t0)
</pre>
<hr />
<pre>
2525     loadp CodeBlock[cfr], t1
2526     loadp CodeBlock::m_vm[t1], t1
2527     # t1 is holding the pointer to the typeProfilerLog.
2528     loadp VM::m_typeProfilerLog[t1], t1
2529     # t2 is holding the pointer to the current log entry.
2530     loadp TypeProfilerLog::m_currentLogEntryPtr[t1], t2
2531 
2532     # t0 is holding the JSValue argument.
2533     get(m_targetVirtualRegister, t3)
2534     loadConstantOrVariable(size, t3, t0)
2535 
2536     bqeq t0, ValueEmpty, .opProfileTypeDone
2537     # Store the JSValue onto the log entry.
2538     storeq t0, TypeProfilerLog::LogEntry::value[t2]
2539     
2540     # Store the TypeLocation onto the log entry.
2541     metadata(t5, t3)
2542     loadp OpProfileType::Metadata::m_typeLocation[t5], t3
2543     storep t3, TypeProfilerLog::LogEntry::location[t2]
2544 
<span class="line-modified">2545     btqz t0, tagMask, .opProfileTypeIsCell</span>
2546     storei 0, TypeProfilerLog::LogEntry::structureID[t2]
2547     jmp .opProfileTypeSkipIsCell
2548 .opProfileTypeIsCell:
2549     loadi JSCell::m_structureID[t0], t3
2550     storei t3, TypeProfilerLog::LogEntry::structureID[t2]
2551 .opProfileTypeSkipIsCell:
2552     
2553     # Increment the current log entry.
2554     addp sizeof TypeProfilerLog::LogEntry, t2
2555     storep t2, TypeProfilerLog::m_currentLogEntryPtr[t1]
2556 
2557     loadp TypeProfilerLog::m_logEndPtr[t1], t1
2558     bpneq t2, t1, .opProfileTypeDone
2559     callSlowPath(_slow_path_profile_type_clear_log)
2560 
2561 .opProfileTypeDone:
2562     dispatch()
2563 end)
2564 
2565 
2566 llintOpWithMetadata(op_profile_control_flow, OpProfileControlFlow, macro (size, get, dispatch, metadata, return)
2567     metadata(t5, t0)
2568     loadp OpProfileControlFlow::Metadata::m_basicBlockLocation[t5], t0
2569     addq 1, BasicBlockLocation::m_executionCount[t0]
2570     dispatch()
2571 end)
2572 
2573 
2574 llintOpWithReturn(op_get_rest_length, OpGetRestLength, macro (size, get, dispatch, return)
<span class="line-modified">2575     loadi PayloadOffset + ArgumentCount[cfr], t0</span>
2576     subi 1, t0
2577     getu(size, OpGetRestLength, m_numParametersToSkip, t1)
2578     bilteq t0, t1, .storeZero
2579     subi t1, t0
2580     jmp .boxUp
2581 .storeZero:
2582     move 0, t0
2583 .boxUp:
<span class="line-modified">2584     orq tagTypeNumber, t0</span>








2585     return(t0)
2586 end)
2587 










2588 
2589 llintOp(op_log_shadow_chicken_prologue, OpLogShadowChickenPrologue, macro (size, get, dispatch)
2590     acquireShadowChickenPacket(.opLogShadowChickenPrologueSlow)
2591     storep cfr, ShadowChicken::Packet::frame[t0]
2592     loadp CallerFrame[cfr], t1
2593     storep t1, ShadowChicken::Packet::callerFrame[t0]
2594     loadp Callee[cfr], t1
2595     storep t1, ShadowChicken::Packet::callee[t0]
2596     loadVariable(get, m_scope, t1)
2597     storep t1, ShadowChicken::Packet::scope[t0]
2598     dispatch()
2599 .opLogShadowChickenPrologueSlow:
2600     callSlowPath(_llint_slow_path_log_shadow_chicken_prologue)
2601     dispatch()
2602 end)
2603 
2604 
2605 llintOp(op_log_shadow_chicken_tail, OpLogShadowChickenTail, macro (size, get, dispatch)
2606     acquireShadowChickenPacket(.opLogShadowChickenTailSlow)
2607     storep cfr, ShadowChicken::Packet::frame[t0]
</pre>
</td>
<td>
<hr />
<pre>
   6 # 1. Redistributions of source code must retain the above copyright
   7 #    notice, this list of conditions and the following disclaimer.
   8 # 2. Redistributions in binary form must reproduce the above copyright
   9 #    notice, this list of conditions and the following disclaimer in the
  10 #    documentation and/or other materials provided with the distribution.
  11 #
  12 # THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
  13 # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
  14 # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  15 # PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
  16 # BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  17 # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  18 # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
  19 # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
  20 # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
  21 # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
  22 # THE POSSIBILITY OF SUCH DAMAGE.
  23 
  24 
  25 # Utilities.
<span class="line-modified">  26 macro storePC()</span>
<span class="line-modified">  27     storei PC, LLIntReturnPC[cfr]</span>









  28 end
  29 
<span class="line-modified">  30 macro loadPC()</span>
<span class="line-modified">  31     loadi LLIntReturnPC[cfr], PC</span>


  32 end
  33 
  34 macro getuOperandNarrow(opcodeStruct, fieldName, dst)
<span class="line-modified">  35     loadb constexpr %opcodeStruct%_%fieldName%_index + OpcodeIDNarrowSize[PB, PC, 1], dst</span>
  36 end
  37 
  38 macro getOperandNarrow(opcodeStruct, fieldName, dst)
<span class="line-modified">  39     loadbsq constexpr %opcodeStruct%_%fieldName%_index + OpcodeIDNarrowSize[PB, PC, 1], dst</span>
  40 end
  41 
  42 macro getuOperandWide16(opcodeStruct, fieldName, dst)
<span class="line-modified">  43     loadh constexpr %opcodeStruct%_%fieldName%_index * 2 + OpcodeIDWide16Size[PB, PC, 1], dst</span>
  44 end
  45 
  46 macro getOperandWide16(opcodeStruct, fieldName, dst)
<span class="line-modified">  47     loadhsq constexpr %opcodeStruct%_%fieldName%_index * 2 + OpcodeIDWide16Size[PB, PC, 1], dst</span>
  48 end
  49 
  50 macro getuOperandWide32(opcodeStruct, fieldName, dst)
<span class="line-modified">  51     loadi constexpr %opcodeStruct%_%fieldName%_index * 4 + OpcodeIDWide32Size[PB, PC, 1], dst</span>
  52 end
  53 
  54 macro getOperandWide32(opcodeStruct, fieldName, dst)
<span class="line-modified">  55     loadis constexpr %opcodeStruct%_%fieldName%_index * 4 + OpcodeIDWide32Size[PB, PC, 1], dst</span>
  56 end
  57 
  58 macro makeReturn(get, dispatch, fn)
  59     fn(macro (value)
  60         move value, t2
  61         get(m_dst, t1)
  62         storeq t2, [cfr, t1, 8]
  63         dispatch()
  64     end)
  65 end
  66 
  67 macro makeReturnProfiled(opcodeStruct, get, metadata, dispatch, fn)
  68     fn(macro (value)
  69         move value, t3
  70         metadata(t1, t2)
  71         valueProfile(opcodeStruct, t1, t3)
  72         get(m_dst, t1)
  73         storeq t3, [cfr, t1, 8]
  74         dispatch()
  75     end)
  76 end
  77 
  78 macro valueProfile(opcodeStruct, metadata, value)
  79     storeq value, %opcodeStruct%::Metadata::m_profile.m_buckets[metadata]
  80 end
  81 
<span class="line-added">  82 # After calling, calling bytecode is claiming input registers are not used.</span>
  83 macro dispatchAfterCall(size, opcodeStruct, dispatch)
<span class="line-modified">  84     loadPC()</span>
  85     loadp CodeBlock[cfr], PB
  86     loadp CodeBlock::m_instructionsRawPointer[PB], PB
  87     get(size, opcodeStruct, m_dst, t1)
  88     storeq r0, [cfr, t1, 8]
  89     metadata(size, opcodeStruct, t2, t1)
  90     valueProfile(opcodeStruct, t2, r0)
  91     dispatch()
  92 end
  93 
  94 macro cCall2(function)
  95     checkStackPointerAlignment(t4, 0xbad0c002)
  96     if X86_64 or ARM64 or ARM64E
  97         call function
  98     elsif X86_64_WIN
  99         # Note: this implementation is only correct if the return type size is &gt; 8 bytes.
 100         # See macro cCall2Void for an implementation when the return type &lt;= 8 bytes.
 101         # On Win64, when the return type is larger than 8 bytes, we need to allocate space on the stack for the return value.
 102         # On entry rcx (a0), should contain a pointer to this stack space. The other parameters are shifted to the right,
 103         # rdx (a1) should contain the first argument, and r8 (a2) should contain the second argument.
 104         # On return, rax contains a pointer to this stack value, and we then need to copy the 16 byte return value into rax (r0) and rdx (r1)
</pre>
<hr />
<pre>
 189         move vm, t5
 190         cloopCallSlowPath _llint_stack_check_at_vm_entry, vm, t3
 191         bpeq t0, 0, .stackCheckFailed
 192         move t4, entry
 193         move t5, vm
 194         jmp .stackHeightOK
 195 
 196 .stackCheckFailed:
 197         move t4, entry
 198         move t5, vm
 199         jmp .throwStackOverflow
 200     else
 201         bpb t3, VM::m_softStackLimit[vm], .throwStackOverflow
 202     end
 203 
 204 .stackHeightOK:
 205     move t3, sp
 206     move (constexpr ProtoCallFrame::numberOfRegisters), t3
 207 
 208 .copyHeaderLoop:
<span class="line-modified"> 209     # Copy the CodeBlock/Callee/ArgumentCountIncludingThis/|this| from protoCallFrame into the callee frame.</span>
 210     subi 1, t3
 211     loadq [protoCallFrame, t3, 8], extraTempReg
 212     storeq extraTempReg, CodeBlock[sp, t3, 8]
 213     btinz t3, .copyHeaderLoop
 214 
 215     loadi PayloadOffset + ProtoCallFrame::argCountAndCodeOriginValue[protoCallFrame], t4
 216     subi 1, t4
 217     loadi ProtoCallFrame::paddedArgCount[protoCallFrame], extraTempReg
 218     subi 1, extraTempReg
 219 
 220     bieq t4, extraTempReg, .copyArgs
 221     move ValueUndefined, t3
 222 .fillExtraArgsLoop:
 223     subi 1, extraTempReg
 224     storeq t3, ThisArgumentOffset + 8[sp, extraTempReg, 8]
 225     bineq t4, extraTempReg, .fillExtraArgsLoop
 226 
 227 .copyArgs:
 228     loadp ProtoCallFrame::args[protoCallFrame], t3
 229 
 230 .copyArgsLoop:
 231     btiz t4, .copyArgsDone
 232     subi 1, t4
 233     loadq [t3, t4, 8], extraTempReg
 234     storeq extraTempReg, ThisArgumentOffset + 8[sp, t4, 8]
 235     jmp .copyArgsLoop
 236 
 237 .copyArgsDone:
 238     if ARM64 or ARM64E
 239         move sp, t4
 240         storep t4, VM::topCallFrame[vm]
 241     else
 242         storep sp, VM::topCallFrame[vm]
 243     end
 244     storep cfr, VM::topEntryFrame[vm]
 245 
 246     checkStackPointerAlignment(extraTempReg, 0xbad0dc02)
 247 
<span class="line-modified"> 248     makeCall(entry, protoCallFrame, t3, t4)</span>
 249 
 250     # We may have just made a call into a JS function, so we can&#39;t rely on sp
 251     # for anything but the fact that our own locals (ie the VMEntryRecord) are
 252     # not below it. It also still has to be aligned, though.
 253     checkStackPointerAlignment(t2, 0xbad0dc03)
 254 
 255     vmEntryRecord(cfr, t4)
 256 
 257     loadp VMEntryRecord::m_vm[t4], vm
 258     loadp VMEntryRecord::m_prevTopCallFrame[t4], t2
 259     storep t2, VM::topCallFrame[vm]
 260     loadp VMEntryRecord::m_prevTopEntryFrame[t4], t2
 261     storep t2, VM::topEntryFrame[vm]
 262 
 263     subp cfr, CalleeRegisterSaveSize, sp
 264 
 265     popCalleeSaves()
 266     functionEpilogue()
 267     ret
 268 
</pre>
<hr />
<pre>
 270     move vm, a0
 271     move protoCallFrame, a1
 272     cCall2(_llint_throw_stack_overflow_error)
 273 
 274     vmEntryRecord(cfr, t4)
 275 
 276     loadp VMEntryRecord::m_vm[t4], vm
 277     loadp VMEntryRecord::m_prevTopCallFrame[t4], extraTempReg
 278     storep extraTempReg, VM::topCallFrame[vm]
 279     loadp VMEntryRecord::m_prevTopEntryFrame[t4], extraTempReg
 280     storep extraTempReg, VM::topEntryFrame[vm]
 281 
 282     subp cfr, CalleeRegisterSaveSize, sp
 283 
 284     popCalleeSaves()
 285     functionEpilogue()
 286     ret
 287 end
 288 
 289 
<span class="line-modified"> 290 # a0, a2, t3, t4</span>
<span class="line-added"> 291 macro makeJavaScriptCall(entry, protoCallFrame, temp1, temp2)</span>
 292     addp 16, sp
 293     if C_LOOP or C_LOOP_WIN
 294         cloopCallJSFunction entry
 295     else
 296         call entry, JSEntryPtrTag
 297     end
 298     subp 16, sp
 299 end
 300 
<span class="line-modified"> 301 # a0, a2, t3, t4</span>
<span class="line-modified"> 302 macro makeHostFunctionCall(entry, protoCallFrame, temp1, temp2)</span>
<span class="line-added"> 303     move entry, temp1</span>
 304     storep cfr, [sp]
<span class="line-modified"> 305     loadp ProtoCallFrame::globalObject[protoCallFrame], a0</span>
<span class="line-added"> 306     move sp, a1</span>
 307     if C_LOOP or C_LOOP_WIN
 308         storep lr, 8[sp]
<span class="line-modified"> 309         cloopCallNative temp1</span>
 310     elsif X86_64_WIN
 311         # We need to allocate 32 bytes on the stack for the shadow space.
 312         subp 32, sp
<span class="line-modified"> 313         call temp1, JSEntryPtrTag</span>
 314         addp 32, sp
 315     else
<span class="line-modified"> 316         call temp1, JSEntryPtrTag</span>
 317     end
 318 end
 319 
 320 op(handleUncaughtException, macro ()
 321     loadp Callee[cfr], t3
<span class="line-modified"> 322     convertCalleeToVM(t3)</span>

 323     restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(t3, t0)
 324     storep 0, VM::callFrameForCatch[t3]
 325 
 326     loadp VM::topEntryFrame[t3], cfr
 327     vmEntryRecord(cfr, t2)
 328 
 329     loadp VMEntryRecord::m_vm[t2], t3
 330     loadp VMEntryRecord::m_prevTopCallFrame[t2], extraTempReg
 331     storep extraTempReg, VM::topCallFrame[t3]
 332     loadp VMEntryRecord::m_prevTopEntryFrame[t2], extraTempReg
 333     storep extraTempReg, VM::topEntryFrame[t3]
 334 
 335     subp cfr, CalleeRegisterSaveSize, sp
 336 
 337     popCalleeSaves()
 338     functionEpilogue()
 339     ret
 340 end)
 341 
 342 
</pre>
<hr />
<pre>
 360 macro traceOperand(fromWhere, operand)
 361     prepareStateForCCall()
 362     move fromWhere, a2
 363     move operand, a3
 364     move cfr, a0
 365     move PC, a1
 366     cCall4(_llint_trace_operand)
 367     restoreStateAfterCCall()
 368 end
 369 
 370 macro traceValue(fromWhere, operand)
 371     prepareStateForCCall()
 372     move fromWhere, a2
 373     move operand, a3
 374     move cfr, a0
 375     move PC, a1
 376     cCall4(_llint_trace_value)
 377     restoreStateAfterCCall()
 378 end
 379 
<span class="line-modified"> 380 # Call a slow path for call opcodes.</span>
 381 macro callCallSlowPath(slowPath, action)
<span class="line-modified"> 382     storePC()</span>
 383     prepareStateForCCall()
 384     move cfr, a0
 385     move PC, a1
 386     cCall2(slowPath)
 387     action(r0, r1)
 388 end
 389 
 390 macro callTrapHandler(throwHandler)
<span class="line-modified"> 391     storePC()</span>
 392     prepareStateForCCall()
 393     move cfr, a0
 394     move PC, a1
 395     cCall2(_llint_slow_path_handle_traps)
 396     btpnz r0, throwHandler
<span class="line-modified"> 397     loadi LLIntReturnPC[cfr], PC</span>
 398 end
 399 
 400 macro checkSwitchToJITForLoop()
 401     checkSwitchToJIT(
 402         1,
 403         macro()
<span class="line-modified"> 404             storePC()</span>
 405             prepareStateForCCall()
 406             move cfr, a0
 407             move PC, a1
 408             cCall2(_llint_loop_osr)
 409             btpz r0, .recover
 410             move r1, sp
 411             jmp r0, JSEntryPtrTag
 412         .recover:
<span class="line-modified"> 413             loadPC()</span>
 414         end)
 415 end
 416 
 417 macro cage(basePtr, mask, ptr, scratch)
 418     if GIGACAGE_ENABLED and not (C_LOOP or C_LOOP_WIN)
 419         loadp basePtr, scratch
 420         btpz scratch, .done
 421         andp mask, ptr
 422         addp scratch, ptr
 423     .done:
 424     end
 425 end
 426 
 427 macro cagedPrimitive(ptr, length, scratch, scratch2)
 428     if ARM64E
 429         const source = scratch2
 430         move ptr, scratch2
 431     else
 432         const source = ptr
 433     end
 434     if GIGACAGE_ENABLED
<span class="line-modified"> 435         cage(_g_gigacageConfig + Gigacage::Config::basePtrs + GigacagePrimitiveBasePtrOffset, constexpr Gigacage::primitiveGigacageMask, source, scratch)</span>
 436         if ARM64E
 437             const numberOfPACBits = constexpr MacroAssembler::numberOfPACBits
 438             bfiq scratch2, 0, 64 - numberOfPACBits, ptr
 439         end
 440     end
 441     if ARM64E
 442         untagArrayPtr length, ptr
 443     end
 444 end
 445 
 446 macro loadCagedJSValue(source, dest, scratchOrLength)
 447     loadp source, dest
<span class="line-modified"> 448     if GIGACAGE_ENABLED</span>
<span class="line-added"> 449         cage(_g_gigacageConfig + Gigacage::Config::basePtrs + GigacageJSValueBasePtrOffset, constexpr Gigacage::jsValueGigacageMask, dest, scratchOrLength)</span>
<span class="line-added"> 450     end</span>
 451 end
 452 
 453 macro loadVariable(get, fieldName, valueReg)
 454     get(fieldName, valueReg)
 455     loadq [cfr, valueReg, 8], valueReg
 456 end
 457 
<span class="line-added"> 458 # Index and value must be different registers. Index may be clobbered.</span>
<span class="line-added"> 459 macro loadConstant(size, index, value)</span>
<span class="line-added"> 460     macro loadNarrow()</span>
<span class="line-added"> 461         loadp CodeBlock[cfr], value</span>
<span class="line-added"> 462         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[value], value</span>
<span class="line-added"> 463         loadq -(FirstConstantRegisterIndexNarrow * 8)[value, index, 8], value</span>
<span class="line-added"> 464     end</span>
<span class="line-added"> 465 </span>
<span class="line-added"> 466     macro loadWide16()</span>
<span class="line-added"> 467         loadp CodeBlock[cfr], value</span>
<span class="line-added"> 468         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[value], value</span>
<span class="line-added"> 469         loadq -(FirstConstantRegisterIndexWide16 * 8)[value, index, 8], value</span>
<span class="line-added"> 470     end</span>
<span class="line-added"> 471 </span>
<span class="line-added"> 472     macro loadWide32()</span>
<span class="line-added"> 473         loadp CodeBlock[cfr], value</span>
<span class="line-added"> 474         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[value], value</span>
<span class="line-added"> 475         subp FirstConstantRegisterIndexWide32, index</span>
<span class="line-added"> 476         loadq [value, index, 8], value</span>
<span class="line-added"> 477     end</span>
<span class="line-added"> 478 </span>
<span class="line-added"> 479     size(loadNarrow, loadWide16, loadWide32, macro (load) load() end)</span>
<span class="line-added"> 480 end</span>
<span class="line-added"> 481 </span>
 482 # Index and value must be different registers. Index may be clobbered.
 483 macro loadConstantOrVariable(size, index, value)
 484     macro loadNarrow()
 485         bpgteq index, FirstConstantRegisterIndexNarrow, .constant
 486         loadq [cfr, index, 8], value
 487         jmp .done
 488     .constant:
<span class="line-modified"> 489         loadConstant(size, index, value)</span>


 490     .done:
 491     end
 492 
 493     macro loadWide16()
 494         bpgteq index, FirstConstantRegisterIndexWide16, .constant
 495         loadq [cfr, index, 8], value
 496         jmp .done
 497     .constant:
<span class="line-modified"> 498         loadConstant(size, index, value)</span>


 499     .done:
 500     end
 501 
 502     macro loadWide32()
 503         bpgteq index, FirstConstantRegisterIndexWide32, .constant
 504         loadq [cfr, index, 8], value
 505         jmp .done
 506     .constant:
<span class="line-modified"> 507         loadConstant(size, index, value)</span>



 508     .done:
 509     end
 510 
 511     size(loadNarrow, loadWide16, loadWide32, macro (load) load() end)
 512 end
 513 
 514 macro loadConstantOrVariableInt32(size, index, value, slow)
 515     loadConstantOrVariable(size, index, value)
<span class="line-modified"> 516     bqb value, numberTag, slow</span>
 517 end
 518 
 519 macro loadConstantOrVariableCell(size, index, value, slow)
 520     loadConstantOrVariable(size, index, value)
<span class="line-modified"> 521     btqnz value, notCellMask, slow</span>
 522 end
 523 
 524 macro writeBarrierOnCellWithReload(cell, reloadAfterSlowPath)
 525     skipIfIsRememberedOrInEden(
 526         cell,
 527         macro()
 528             push PB, PC
 529             move cell, a1 # cell can be a0
 530             move cfr, a0
 531             cCall2Void(_llint_write_barrier_slow)
 532             pop PC, PB
 533             reloadAfterSlowPath()
 534         end)
 535 end
 536 
<span class="line-added"> 537 macro writeBarrierOnCellAndValueWithReload(cell, value, reloadAfterSlowPath)</span>
<span class="line-added"> 538     btqnz value, notCellMask, .writeBarrierDone</span>
<span class="line-added"> 539     btqz value, .writeBarrierDone</span>
<span class="line-added"> 540     writeBarrierOnCellWithReload(cell, reloadAfterSlowPath)</span>
<span class="line-added"> 541 .writeBarrierDone:</span>
<span class="line-added"> 542 end</span>
<span class="line-added"> 543 </span>
 544 macro writeBarrierOnOperandWithReload(size, get, cellFieldName, reloadAfterSlowPath)
 545     get(cellFieldName, t1)
 546     loadConstantOrVariableCell(size, t1, t2, .writeBarrierDone)
 547     writeBarrierOnCellWithReload(t2, reloadAfterSlowPath)
 548 .writeBarrierDone:
 549 end
 550 
 551 macro writeBarrierOnOperand(size, get, cellFieldName)
 552     writeBarrierOnOperandWithReload(size, get, cellFieldName, macro () end)
 553 end
 554 
 555 macro writeBarrierOnOperands(size, get, cellFieldName, valueFieldName)
 556     get(valueFieldName, t1)
 557     loadConstantOrVariableCell(size, t1, t0, .writeBarrierDone)
 558     btpz t0, .writeBarrierDone
 559 
 560     writeBarrierOnOperand(size, get, cellFieldName)
 561 .writeBarrierDone:
 562 end
 563 
</pre>
<hr />
<pre>
 591 macro structureIDToStructureWithScratch(structureIDThenStructure, scratch, scratch2)
 592     loadp CodeBlock[cfr], scratch
 593     move structureIDThenStructure, scratch2
 594     loadp CodeBlock::m_vm[scratch], scratch
 595     rshifti NumberOfStructureIDEntropyBits, scratch2
 596     loadp VM::heap + Heap::m_structureIDTable + StructureIDTable::m_table[scratch], scratch
 597     loadp [scratch, scratch2, PtrSize], scratch2
 598     lshiftp StructureEntropyBitsShift, structureIDThenStructure
 599     xorp scratch2, structureIDThenStructure
 600 end
 601 
 602 macro loadStructureWithScratch(cell, structure, scratch, scratch2)
 603     loadi JSCell::m_structureID[cell], structure
 604     structureIDToStructureWithScratch(structure, scratch, scratch2)
 605 end
 606 
 607 # Entrypoints into the interpreter.
 608 
 609 # Expects that CodeBlock is in t1, which is what prologue() leaves behind.
 610 macro functionArityCheck(doneLabel, slowPath)
<span class="line-modified"> 611     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t0</span>
 612     biaeq t0, CodeBlock::m_numParameters[t1], doneLabel
 613     prepareStateForCCall()
 614     move cfr, a0
 615     move PC, a1
 616     cCall2(slowPath)   # This slowPath has the protocol: r0 = 0 =&gt; no error, r0 != 0 =&gt; error
 617     btiz r0, .noError
 618 
 619     # We&#39;re throwing before the frame is fully set up. This frame will be
 620     # ignored by the unwinder. So, let&#39;s restore the callee saves before we
 621     # start unwinding. We need to do this before we change the cfr.
 622     restoreCalleeSavesUsedByLLInt()
 623 
 624     move r1, cfr   # r1 contains caller frame
 625     jmp _llint_throw_from_slow_path_trampoline
 626 
 627 .noError:
 628     move r1, t1 # r1 contains slotsToAdd.
 629     btiz t1, .continue
<span class="line-modified"> 630     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t2</span>
 631     addi CallFrameHeaderSlots, t2
 632 
 633     // Check if there are some unaligned slots we can use
 634     move t1, t3
 635     andi StackAlignmentSlots - 1, t3
 636     btiz t3, .noExtraSlot
 637     move ValueUndefined, t0
 638 .fillExtraSlots:
 639     storeq t0, [cfr, t2, 8]
 640     addi 1, t2
 641     bsubinz 1, t3, .fillExtraSlots
 642     andi ~(StackAlignmentSlots - 1), t1
 643     btiz t1, .continue
 644 
 645 .noExtraSlot:
 646     if ARM64E
 647         loadp 8[cfr], lr
 648         addp 16, cfr, t3
 649         untagReturnAddress t3
 650     end
</pre>
<hr />
<pre>
 670     move ValueUndefined, t0
 671 .fillLoop:
 672     storeq t0, [t3, t1, 8]
 673     addp 8, t3
 674     baddinz 1, t2, .fillLoop
 675 
 676     if ARM64E
 677         addp 16, cfr, t1
 678         tagReturnAddress t1
 679         storep lr, 8[cfr]
 680     end
 681 
 682 .continue:
 683     # Reload CodeBlock and reset PC, since the slow_path clobbered them.
 684     loadp CodeBlock[cfr], t1
 685     loadp CodeBlock::m_instructionsRawPointer[t1], PB
 686     move 0, PC
 687     jmp doneLabel
 688 end
 689 









 690 # Instruction implementations
<span class="line-added"> 691 </span>
 692 _llint_op_enter:
 693     traceExecution()
 694     checkStackPointerAlignment(t2, 0xdead00e1)
<span class="line-modified"> 695     loadp CodeBlock[cfr], t2                // t2&lt;CodeBlock&gt; = cfr.CodeBlock</span>
<span class="line-modified"> 696     loadi CodeBlock::m_numVars[t2], t2      // t2&lt;size_t&gt; = t2&lt;CodeBlock&gt;.m_numVars</span>
 697     subq CalleeSaveSpaceAsVirtualRegisters, t2
 698     move cfr, t1
 699     subq CalleeSaveSpaceAsVirtualRegisters * 8, t1
 700     btiz t2, .opEnterDone
 701     move ValueUndefined, t0
 702     negi t2
 703     sxi2q t2, t2
 704 .opEnterLoop:
 705     storeq t0, [t1, t2, 8]
 706     addq 1, t2
 707     btqnz t2, .opEnterLoop
 708 .opEnterDone:
<span class="line-modified"> 709     callSlowPath(_slow_path_enter)</span>





 710     dispatchOp(narrow, op_enter)
<span class="line-modified"> 711 </span>


 712 
 713 llintOpWithProfile(op_get_argument, OpGetArgument, macro (size, get, dispatch, return)
 714     get(m_index, t2)
<span class="line-modified"> 715     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t0</span>
 716     bilteq t0, t2, .opGetArgumentOutOfBounds
 717     loadq ThisArgumentOffset[cfr, t2, 8], t0
 718     return(t0)
 719 
 720 .opGetArgumentOutOfBounds:
 721     return(ValueUndefined)
 722 end)
 723 
 724 
 725 llintOpWithReturn(op_argument_count, OpArgumentCount, macro (size, get, dispatch, return)
<span class="line-modified"> 726     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t0</span>
 727     subi 1, t0
<span class="line-modified"> 728     orq TagNumber, t0</span>
 729     return(t0)
 730 end)
 731 
 732 
 733 llintOpWithReturn(op_get_scope, OpGetScope, macro (size, get, dispatch, return)
 734     loadp Callee[cfr], t0
 735     loadp JSCallee::m_scope[t0], t0
 736     return(t0)
 737 end)
 738 
 739 
 740 llintOpWithMetadata(op_to_this, OpToThis, macro (size, get, dispatch, metadata, return)
 741     get(m_srcDst, t0)
 742     loadq [cfr, t0, 8], t0
<span class="line-modified"> 743     btqnz t0, notCellMask, .opToThisSlow</span>
 744     bbneq JSCell::m_type[t0], FinalObjectType, .opToThisSlow
 745     loadi JSCell::m_structureID[t0], t1
 746     metadata(t2, t3)
 747     loadi OpToThis::Metadata::m_cachedStructureID[t2], t2
 748     bineq t1, t2, .opToThisSlow
 749     dispatch()
 750 
 751 .opToThisSlow:
 752     callSlowPath(_slow_path_to_this)
 753     dispatch()
 754 end)
 755 
 756 
 757 llintOp(op_check_tdz, OpCheckTdz, macro (size, get, dispatch)
 758     get(m_targetVirtualRegister, t0)
 759     loadConstantOrVariable(size, t0, t1)
 760     bqneq t1, ValueEmpty, .opNotTDZ
 761     callSlowPath(_slow_path_throw_tdz_error)
 762 
 763 .opNotTDZ:
</pre>
<hr />
<pre>
 790     llintOpWithReturn(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
 791         get(m_rhs, t0)
 792         get(m_lhs, t2)
 793         loadConstantOrVariableInt32(size, t0, t1, .slow)
 794         loadConstantOrVariableInt32(size, t2, t0, .slow)
 795         integerComparison(t0, t1, t0)
 796         orq ValueFalse, t0
 797         return(t0)
 798 
 799     .slow:
 800         callSlowPath(_slow_path_%opcodeName%)
 801         dispatch()
 802     end)
 803 end
 804 
 805 
 806 macro equalNullComparisonOp(opcodeName, opcodeStruct, fn)
 807     llintOpWithReturn(opcodeName, opcodeStruct, macro (size, get, dispatch, return)
 808         get(m_operand, t0)
 809         loadq [cfr, t0, 8], t0
<span class="line-modified"> 810         btqnz t0, notCellMask, .immediate</span>
 811         btbnz JSCell::m_flags[t0], MasqueradesAsUndefined, .masqueradesAsUndefined
 812         move 0, t0
 813         jmp .done
 814     .masqueradesAsUndefined:
 815         loadStructureWithScratch(t0, t2, t1, t3)
 816         loadp CodeBlock[cfr], t0
 817         loadp CodeBlock::m_globalObject[t0], t0
 818         cpeq Structure::m_globalObject[t2], t0, t0
 819         jmp .done
 820     .immediate:
<span class="line-modified"> 821         andq ~TagUndefined, t0</span>
 822         cqeq t0, ValueNull, t0
 823     .done:
 824         fn(t0)
 825         return(t0)
 826     end)
 827 end
 828 
 829 equalNullComparisonOp(op_eq_null, OpEqNull,
 830     macro (value) orq ValueFalse, value end)
 831 
 832 
 833 equalNullComparisonOp(op_neq_null, OpNeqNull,
 834     macro (value) xorq ValueTrue, value end)
 835 
 836 
 837 llintOpWithReturn(op_is_undefined_or_null, OpIsUndefinedOrNull, macro (size, get, dispatch, return)
 838     get(m_operand, t1)
 839     loadConstantOrVariable(size, t1, t0)
<span class="line-modified"> 840     andq ~TagUndefined, t0</span>
 841     cqeq t0, ValueNull, t0
 842     orq ValueFalse, t0
 843     return(t0)
 844 end)
 845 
 846 
 847 macro strictEqOp(opcodeName, opcodeStruct, equalityOperation)
 848     llintOpWithReturn(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
 849         get(m_rhs, t0)
 850         get(m_lhs, t2)
 851         loadConstantOrVariable(size, t0, t1)
 852         loadConstantOrVariable(size, t2, t0)
 853         move t0, t2
 854         orq t1, t2
<span class="line-modified"> 855         btqz t2, notCellMask, .slow</span>
<span class="line-modified"> 856         bqaeq t0, numberTag, .leftOK</span>
<span class="line-modified"> 857         btqnz t0, numberTag, .slow</span>
 858     .leftOK:
<span class="line-modified"> 859         bqaeq t1, numberTag, .rightOK</span>
<span class="line-modified"> 860         btqnz t1, numberTag, .slow</span>
 861     .rightOK:
 862         equalityOperation(t0, t1, t0)
 863         orq ValueFalse, t0
 864         return(t0)
 865 
 866     .slow:
 867         callSlowPath(_slow_path_%opcodeName%)
 868         dispatch()
 869     end)
 870 end
 871 
 872 
 873 strictEqOp(stricteq, OpStricteq,
 874     macro (left, right, result) cqeq left, right, result end)
 875 
 876 
 877 strictEqOp(nstricteq, OpNstricteq,
 878     macro (left, right, result) cqneq left, right, result end)
 879 
 880 
 881 macro strictEqualityJumpOp(opcodeName, opcodeStruct, equalityOperation)
 882     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
 883         get(m_lhs, t2)
 884         get(m_rhs, t3)
 885         loadConstantOrVariable(size, t2, t0)
 886         loadConstantOrVariable(size, t3, t1)
 887         move t0, t2
 888         orq t1, t2
<span class="line-modified"> 889         btqz t2, notCellMask, .slow</span>
<span class="line-modified"> 890         bqaeq t0, numberTag, .leftOK</span>
<span class="line-modified"> 891         btqnz t0, numberTag, .slow</span>
 892     .leftOK:
<span class="line-modified"> 893         bqaeq t1, numberTag, .rightOK</span>
<span class="line-modified"> 894         btqnz t1, numberTag, .slow</span>
 895     .rightOK:
 896         equalityOperation(t0, t1, .jumpTarget)
 897         dispatch()
 898 
 899     .jumpTarget:
 900         jump(m_targetLabel)
 901 
 902     .slow:
 903         callSlowPath(_llint_slow_path_%opcodeName%)
 904         nextInstruction()
 905     end)
 906 end
 907 
 908 
 909 strictEqualityJumpOp(jstricteq, OpJstricteq,
 910     macro (left, right, target) bqeq left, right, target end)
 911 
 912 
 913 strictEqualityJumpOp(jnstricteq, OpJnstricteq,
 914     macro (left, right, target) bqneq left, right, target end)
 915 
<span class="line-added"> 916 macro preOp(opcodeName, opcodeStruct, integerOperation)</span>
<span class="line-added"> 917     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)</span>
<span class="line-added"> 918         macro updateArithProfile(type)</span>
<span class="line-added"> 919             orh type, %opcodeStruct%::Metadata::m_arithProfile + UnaryArithProfile::m_bits[t1]</span>
<span class="line-added"> 920         end</span>
 921 


 922         get(m_srcDst, t0)
<span class="line-modified"> 923         loadq [cfr, t0, 8], t3</span>
<span class="line-modified"> 924         metadata(t1, t2)</span>
<span class="line-modified"> 925         # Metadata in t1, srcDst in t3</span>
<span class="line-modified"> 926         bqb t3, numberTag, .slow</span>
<span class="line-modified"> 927         integerOperation(t3, .slow)</span>
<span class="line-added"> 928         orq numberTag, t3</span>
<span class="line-added"> 929         storeq t3, [cfr, t0, 8]</span>
<span class="line-added"> 930         updateArithProfile(ArithProfileInt)</span>
 931         dispatch()
<span class="line-added"> 932 </span>
 933     .slow:
 934         callSlowPath(_slow_path_%opcodeName%)
 935         dispatch()
 936     end)
 937 end
 938 
 939 llintOpWithProfile(op_to_number, OpToNumber, macro (size, get, dispatch, return)
 940     get(m_operand, t0)
 941     loadConstantOrVariable(size, t0, t2)
<span class="line-modified"> 942     bqaeq t2, numberTag, .opToNumberIsImmediate</span>
<span class="line-modified"> 943     btqz t2, numberTag, .opToNumberSlow</span>
 944 .opToNumberIsImmediate:
 945     return(t2)
 946 
 947 .opToNumberSlow:
 948     callSlowPath(_slow_path_to_number)
 949     dispatch()
 950 end)
 951 
<span class="line-added"> 952 llintOpWithProfile(op_to_numeric, OpToNumeric, macro (size, get, dispatch, return)</span>
<span class="line-added"> 953     get(m_operand, t0)</span>
<span class="line-added"> 954     loadConstantOrVariable(size, t0, t2)</span>
<span class="line-added"> 955     bqaeq t2, numberTag, .opToNumericIsImmediate</span>
<span class="line-added"> 956     btqz t2, numberTag, .opToNumericSlow</span>
<span class="line-added"> 957 .opToNumericIsImmediate:</span>
<span class="line-added"> 958     return(t2)</span>
<span class="line-added"> 959 </span>
<span class="line-added"> 960 .opToNumericSlow:</span>
<span class="line-added"> 961     callSlowPath(_slow_path_to_numeric)</span>
<span class="line-added"> 962     dispatch()</span>
<span class="line-added"> 963 end)</span>
<span class="line-added"> 964 </span>
 965 
 966 llintOpWithReturn(op_to_string, OpToString, macro (size, get, dispatch, return)
 967     get(m_operand, t1)
 968     loadConstantOrVariable(size, t1, t0)
<span class="line-modified"> 969     btqnz t0, notCellMask, .opToStringSlow</span>
 970     bbneq JSCell::m_type[t0], StringType, .opToStringSlow
 971 .opToStringIsString:
 972     return(t0)
 973 
 974 .opToStringSlow:
 975     callSlowPath(_slow_path_to_string)
 976     dispatch()
 977 end)
 978 
 979 
 980 llintOpWithProfile(op_to_object, OpToObject, macro (size, get, dispatch, return)
 981     get(m_operand, t0)
 982     loadConstantOrVariable(size, t0, t2)
<span class="line-modified"> 983     btqnz t2, notCellMask, .opToObjectSlow</span>
 984     bbb JSCell::m_type[t2], ObjectType, .opToObjectSlow
 985     return(t2)
 986 
 987 .opToObjectSlow:
 988     callSlowPath(_slow_path_to_object)
 989     dispatch()
 990 end)
 991 
 992 
 993 llintOpWithMetadata(op_negate, OpNegate, macro (size, get, dispatch, metadata, return)
<span class="line-added"> 994 </span>
<span class="line-added"> 995     macro updateArithProfile(type)</span>
<span class="line-added"> 996         orh type, OpNegate::Metadata::m_arithProfile + UnaryArithProfile::m_bits[t1]</span>
<span class="line-added"> 997     end</span>
<span class="line-added"> 998 </span>
 999     get(m_operand, t0)
1000     loadConstantOrVariable(size, t0, t3)
1001     metadata(t1, t2)
<span class="line-modified">1002     bqb t3, numberTag, .opNegateNotInt</span>

1003     btiz t3, 0x7fffffff, .opNegateSlow
1004     negi t3
<span class="line-modified">1005     orq numberTag, t3</span>
<span class="line-modified">1006     updateArithProfile(ArithProfileInt)</span>

1007     return(t3)
1008 .opNegateNotInt:
<span class="line-modified">1009     btqz t3, numberTag, .opNegateSlow</span>
1010     xorq 0x8000000000000000, t3
<span class="line-modified">1011     updateArithProfile(ArithProfileNumber)</span>

1012     return(t3)
1013 
1014 .opNegateSlow:
1015     callSlowPath(_slow_path_negate)
1016     dispatch()
1017 end)
1018 
1019 
1020 macro binaryOpCustomStore(opcodeName, opcodeStruct, integerOperationAndStore, doubleOperation)
1021     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)
1022         metadata(t5, t0)
1023 
1024         macro profile(type)
<span class="line-modified">1025             orh type, %opcodeStruct%::Metadata::m_arithProfile + BinaryArithProfile::m_bits[t5]</span>
1026         end
1027 
1028         get(m_rhs, t0)
1029         get(m_lhs, t2)
1030         loadConstantOrVariable(size, t0, t1)
1031         loadConstantOrVariable(size, t2, t0)
<span class="line-modified">1032         bqb t0, numberTag, .op1NotInt</span>
<span class="line-modified">1033         bqb t1, numberTag, .op2NotInt</span>
1034         get(m_dst, t2)
1035         integerOperationAndStore(t1, t0, .slow, t2)
1036 
1037         profile(ArithProfileIntInt)
1038         dispatch()
1039 
1040     .op1NotInt:
1041         # First operand is definitely not an int, the second operand could be anything.
<span class="line-modified">1042         btqz t0, numberTag, .slow</span>
<span class="line-modified">1043         bqaeq t1, numberTag, .op1NotIntOp2Int</span>
<span class="line-modified">1044         btqz t1, numberTag, .slow</span>
<span class="line-modified">1045         addq numberTag, t1</span>
1046         fq2d t1, ft1
1047         profile(ArithProfileNumberNumber)
1048         jmp .op1NotIntReady
1049     .op1NotIntOp2Int:
1050         profile(ArithProfileNumberInt)
<span class="line-modified">1051         ci2ds t1, ft1</span>
1052     .op1NotIntReady:
1053         get(m_dst, t2)
<span class="line-modified">1054         addq numberTag, t0</span>
1055         fq2d t0, ft0
1056         doubleOperation(ft1, ft0)
1057         fd2q ft0, t0
<span class="line-modified">1058         subq numberTag, t0</span>
1059         storeq t0, [cfr, t2, 8]
1060         dispatch()
1061 
1062     .op2NotInt:
1063         # First operand is definitely an int, the second is definitely not.
1064         get(m_dst, t2)
<span class="line-modified">1065         btqz t1, numberTag, .slow</span>
1066         profile(ArithProfileIntNumber)
<span class="line-modified">1067         ci2ds t0, ft0</span>
<span class="line-modified">1068         addq numberTag, t1</span>
1069         fq2d t1, ft1
1070         doubleOperation(ft1, ft0)
1071         fd2q ft0, t0
<span class="line-modified">1072         subq numberTag, t0</span>
1073         storeq t0, [cfr, t2, 8]
1074         dispatch()
1075 
1076     .slow:
1077         callSlowPath(_slow_path_%opcodeName%)
1078         dispatch()
1079     end)
1080 end
1081 
1082 if X86_64 or X86_64_WIN
1083     binaryOpCustomStore(div, OpDiv,
1084         macro (left, right, slow, index)
1085             # Assume t3 is scratchable.
1086             btiz left, slow
1087             bineq left, -1, .notNeg2TwoThe31DivByNeg1
1088             bieq right, -2147483648, .slow
1089         .notNeg2TwoThe31DivByNeg1:
1090             btinz right, .intOK
1091             bilt left, 0, slow
1092         .intOK:
1093             move left, t3
1094             move right, t0
1095             cdqi
1096             idivi t3
1097             btinz t1, slow
<span class="line-modified">1098             orq numberTag, t0</span>
1099             storeq t0, [cfr, index, 8]
1100         end,
1101         macro (left, right) divd left, right end)
1102 else
1103     slowPathOp(div)
1104 end
1105 
1106 
1107 binaryOpCustomStore(mul, OpMul,
1108     macro (left, right, slow, index)
1109         # Assume t3 is scratchable.
1110         move right, t3
1111         bmulio left, t3, slow
1112         btinz t3, .done
1113         bilt left, 0, slow
1114         bilt right, 0, slow
1115     .done:
<span class="line-modified">1116         orq numberTag, t3</span>
1117         storeq t3, [cfr, index, 8]
1118     end,
1119     macro (left, right) muld left, right end)
1120 
1121 
1122 macro binaryOp(opcodeName, opcodeStruct, integerOperation, doubleOperation)
1123     binaryOpCustomStore(opcodeName, opcodeStruct,
1124         macro (left, right, slow, index)
1125             integerOperation(left, right, slow)
<span class="line-modified">1126             orq numberTag, right</span>
1127             storeq right, [cfr, index, 8]
1128         end,
1129         doubleOperation)
1130 end
1131 
1132 binaryOp(add, OpAdd,
1133     macro (left, right, slow) baddio left, right, slow end,
1134     macro (left, right) addd left, right end)
1135 
1136 
1137 binaryOp(sub, OpSub,
1138     macro (left, right, slow) bsubio left, right, slow end,
1139     macro (left, right) subd left, right end)
1140 
1141 
1142 llintOpWithReturn(op_unsigned, OpUnsigned, macro (size, get, dispatch, return)
1143     get(m_operand, t1)
1144     loadConstantOrVariable(size, t1, t2)
1145     bilt t2, 0, .opUnsignedSlow
1146     return(t2)
1147 .opUnsignedSlow:
1148     callSlowPath(_slow_path_unsigned)
1149     dispatch()
1150 end)
1151 
1152 
1153 macro commonBitOp(opKind, opcodeName, opcodeStruct, operation)
1154     opKind(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
1155         get(m_rhs, t0)
1156         get(m_lhs, t2)
1157         loadConstantOrVariable(size, t0, t1)
1158         loadConstantOrVariable(size, t2, t0)
<span class="line-modified">1159         bqb t0, numberTag, .slow</span>
<span class="line-modified">1160         bqb t1, numberTag, .slow</span>
1161         operation(t1, t0)
<span class="line-modified">1162         orq numberTag, t0</span>
1163         return(t0)
1164 
1165     .slow:
1166         callSlowPath(_slow_path_%opcodeName%)
1167         dispatch()
1168     end)
1169 end
1170 
1171 macro bitOp(opcodeName, opcodeStruct, operation)
1172     commonBitOp(llintOpWithReturn, opcodeName, opcodeStruct, operation)
1173 end
1174 
1175 macro bitOpProfiled(opcodeName, opcodeStruct, operation)
1176     commonBitOp(llintOpWithProfile, opcodeName, opcodeStruct, operation)
1177 end
1178 
1179 bitOpProfiled(lshift, OpLshift,
1180     macro (left, right) lshifti left, right end)
1181 
1182 
<span class="line-modified">1183 bitOpProfiled(rshift, OpRshift,</span>
1184     macro (left, right) rshifti left, right end)
1185 
1186 
1187 bitOp(urshift, OpUrshift,
1188     macro (left, right) urshifti left, right end)
1189 
1190 bitOpProfiled(bitand, OpBitand,
1191     macro (left, right) andi left, right end)
1192 
1193 bitOpProfiled(bitor, OpBitor,
1194     macro (left, right) ori left, right end)
1195 
1196 bitOpProfiled(bitxor, OpBitxor,
1197     macro (left, right) xori left, right end)
1198 
1199 llintOpWithProfile(op_bitnot, OpBitnot, macro (size, get, dispatch, return)
1200     get(m_operand, t0)
1201     loadConstantOrVariableInt32(size, t0, t3, .opBitNotSlow)
1202     noti t3
<span class="line-modified">1203     orq numberTag, t3</span>
1204     return(t3)
1205 .opBitNotSlow:
1206     callSlowPath(_slow_path_bitnot)
1207     dispatch()
1208 end)
1209 
1210 
1211 llintOp(op_overrides_has_instance, OpOverridesHasInstance, macro (size, get, dispatch)
1212     get(m_dst, t3)
1213 
1214     get(m_hasInstanceValue, t1)
1215     loadConstantOrVariable(size, t1, t0)
1216     loadp CodeBlock[cfr], t2
1217     loadp CodeBlock::m_globalObject[t2], t2
1218     loadp JSGlobalObject::m_functionProtoHasInstanceSymbolFunction[t2], t2
1219     bqneq t0, t2, .opOverridesHasInstanceNotDefaultSymbol
1220 
1221     get(m_constructor, t1)
1222     loadConstantOrVariable(size, t1, t0)
1223     tbz JSCell::m_flags[t0], ImplementsDefaultHasInstance, t1
</pre>
<hr />
<pre>
1226     dispatch()
1227 
1228 .opOverridesHasInstanceNotDefaultSymbol:
1229     storeq ValueTrue, [cfr, t3, 8]
1230     dispatch()
1231 end)
1232 
1233 
1234 llintOpWithReturn(op_is_empty, OpIsEmpty, macro (size, get, dispatch, return)
1235     get(m_operand, t1)
1236     loadConstantOrVariable(size, t1, t0)
1237     cqeq t0, ValueEmpty, t3
1238     orq ValueFalse, t3
1239     return(t3)
1240 end)
1241 
1242 
1243 llintOpWithReturn(op_is_undefined, OpIsUndefined, macro (size, get, dispatch, return)
1244     get(m_operand, t1)
1245     loadConstantOrVariable(size, t1, t0)
<span class="line-modified">1246     btqz t0, notCellMask, .opIsUndefinedCell</span>
1247     cqeq t0, ValueUndefined, t3
1248     orq ValueFalse, t3
1249     return(t3)
1250 .opIsUndefinedCell:
1251     btbnz JSCell::m_flags[t0], MasqueradesAsUndefined, .masqueradesAsUndefined
1252     move ValueFalse, t1
1253     return(t1)
1254 .masqueradesAsUndefined:
1255     loadStructureWithScratch(t0, t3, t1, t2)
1256     loadp CodeBlock[cfr], t1
1257     loadp CodeBlock::m_globalObject[t1], t1
1258     cpeq Structure::m_globalObject[t3], t1, t0
1259     orq ValueFalse, t0
1260     return(t0)
1261 end)
1262 
1263 
1264 llintOpWithReturn(op_is_boolean, OpIsBoolean, macro (size, get, dispatch, return)
1265     get(m_operand, t1)
1266     loadConstantOrVariable(size, t1, t0)
1267     xorq ValueFalse, t0
1268     tqz t0, ~1, t0
1269     orq ValueFalse, t0
1270     return(t0)
1271 end)
1272 
1273 
1274 llintOpWithReturn(op_is_number, OpIsNumber, macro (size, get, dispatch, return)
1275     get(m_operand, t1)
1276     loadConstantOrVariable(size, t1, t0)
<span class="line-modified">1277     tqnz t0, numberTag, t1</span>
1278     orq ValueFalse, t1
1279     return(t1)
1280 end)
1281 
1282 
1283 llintOpWithReturn(op_is_cell_with_type, OpIsCellWithType, macro (size, get, dispatch, return)
1284     getu(size, OpIsCellWithType, m_type, t0)
1285     get(m_operand, t1)
1286     loadConstantOrVariable(size, t1, t3)
<span class="line-modified">1287     btqnz t3, notCellMask, .notCellCase</span>
1288     cbeq JSCell::m_type[t3], t0, t1
1289     orq ValueFalse, t1
1290     return(t1)
1291 .notCellCase:
1292     return(ValueFalse)
1293 end)
1294 
1295 
1296 llintOpWithReturn(op_is_object, OpIsObject, macro (size, get, dispatch, return)
1297     get(m_operand, t1)
1298     loadConstantOrVariable(size, t1, t0)
<span class="line-modified">1299     btqnz t0, notCellMask, .opIsObjectNotCell</span>
1300     cbaeq JSCell::m_type[t0], ObjectType, t1
1301     orq ValueFalse, t1
1302     return(t1)
1303 .opIsObjectNotCell:
1304     return(ValueFalse)
1305 end)
1306 
1307 
1308 macro loadPropertyAtVariableOffset(propertyOffsetAsInt, objectAndStorage, value)
1309     bilt propertyOffsetAsInt, firstOutOfLineOffset, .isInline
1310     loadp JSObject::m_butterfly[objectAndStorage], objectAndStorage
1311     negi propertyOffsetAsInt
1312     sxi2q propertyOffsetAsInt, propertyOffsetAsInt
1313     jmp .ready
1314 .isInline:
1315     addp sizeof JSObject - (firstOutOfLineOffset - 2) * 8, objectAndStorage
1316 .ready:
1317     loadq (firstOutOfLineOffset - 2) * 8[objectAndStorage, propertyOffsetAsInt, 8], value
1318 end
1319 
</pre>
<hr />
<pre>
1331 end
1332 
1333 
1334 llintOpWithMetadata(op_get_by_id_direct, OpGetByIdDirect, macro (size, get, dispatch, metadata, return)
1335     metadata(t2, t0)
1336     get(m_base, t0)
1337     loadConstantOrVariableCell(size, t0, t3, .opGetByIdDirectSlow)
1338     loadi JSCell::m_structureID[t3], t1
1339     loadi OpGetByIdDirect::Metadata::m_structureID[t2], t0
1340     bineq t0, t1, .opGetByIdDirectSlow
1341     loadi OpGetByIdDirect::Metadata::m_offset[t2], t1
1342     loadPropertyAtVariableOffset(t1, t3, t0)
1343     valueProfile(OpGetByIdDirect, t2, t0)
1344     return(t0)
1345 
1346 .opGetByIdDirectSlow:
1347     callSlowPath(_llint_slow_path_get_by_id_direct)
1348     dispatch()
1349 end)
1350 

1351 llintOpWithMetadata(op_get_by_id, OpGetById, macro (size, get, dispatch, metadata, return)
1352     metadata(t2, t1)
1353     loadb OpGetById::Metadata::m_modeMetadata.mode[t2], t1
1354     get(m_base, t0)
1355     loadConstantOrVariableCell(size, t0, t3, .opGetByIdSlow)
1356 
1357 .opGetByIdDefault:
1358     bbneq t1, constexpr GetByIdMode::Default, .opGetByIdProtoLoad
1359     loadi JSCell::m_structureID[t3], t1
1360     loadi OpGetById::Metadata::m_modeMetadata.defaultMode.structureID[t2], t0
1361     bineq t0, t1, .opGetByIdSlow
1362     loadis OpGetById::Metadata::m_modeMetadata.defaultMode.cachedOffset[t2], t1
1363     loadPropertyAtVariableOffset(t1, t3, t0)
1364     valueProfile(OpGetById, t2, t0)
1365     return(t0)
1366 
1367 .opGetByIdProtoLoad:
1368     bbneq t1, constexpr GetByIdMode::ProtoLoad, .opGetByIdArrayLength
1369     loadi JSCell::m_structureID[t3], t1
1370     loadi OpGetById::Metadata::m_modeMetadata.protoLoadMode.structureID[t2], t3
1371     bineq t3, t1, .opGetByIdSlow
1372     loadis OpGetById::Metadata::m_modeMetadata.protoLoadMode.cachedOffset[t2], t1
1373     loadp OpGetById::Metadata::m_modeMetadata.protoLoadMode.cachedSlot[t2], t3
1374     loadPropertyAtVariableOffset(t1, t3, t0)
1375     valueProfile(OpGetById, t2, t0)
1376     return(t0)
1377 
1378 .opGetByIdArrayLength:
1379     bbneq t1, constexpr GetByIdMode::ArrayLength, .opGetByIdUnset
1380     move t3, t0
1381     arrayProfile(OpGetById::Metadata::m_modeMetadata.arrayLengthMode.arrayProfile, t0, t2, t5)
1382     btiz t0, IsArray, .opGetByIdSlow
1383     btiz t0, IndexingShapeMask, .opGetByIdSlow
1384     loadCagedJSValue(JSObject::m_butterfly[t3], t0, t1)
1385     loadi -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], t0
1386     bilt t0, 0, .opGetByIdSlow
<span class="line-modified">1387     orq numberTag, t0</span>
1388     valueProfile(OpGetById, t2, t0)
1389     return(t0)
1390 
1391 .opGetByIdUnset:
1392     loadi JSCell::m_structureID[t3], t1
1393     loadi OpGetById::Metadata::m_modeMetadata.unsetMode.structureID[t2], t0
1394     bineq t0, t1, .opGetByIdSlow
1395     valueProfile(OpGetById, t2, ValueUndefined)
1396     return(ValueUndefined)
1397 
1398 .opGetByIdSlow:
1399     callSlowPath(_llint_slow_path_get_by_id)
1400     dispatch()
<span class="line-added">1401 </span>
<span class="line-added">1402 .osrReturnPoint:</span>
<span class="line-added">1403     getterSetterOSRExitReturnPoint(op_get_by_id, size)</span>
<span class="line-added">1404     metadata(t2, t3)</span>
<span class="line-added">1405     valueProfile(OpGetById, t2, r0)</span>
<span class="line-added">1406     return(r0)</span>
<span class="line-added">1407 </span>
1408 end)
1409 
1410 
1411 llintOpWithMetadata(op_put_by_id, OpPutById, macro (size, get, dispatch, metadata, return)
1412     get(m_base, t3)
1413     loadConstantOrVariableCell(size, t3, t0, .opPutByIdSlow)
1414     metadata(t5, t2)
1415     loadi OpPutById::Metadata::m_oldStructureID[t5], t2
1416     bineq t2, JSCell::m_structureID[t0], .opPutByIdSlow
1417 
1418     # At this point, we have:
1419     # t0 -&gt; object base
1420     # t2 -&gt; current structure ID
1421     # t5 -&gt; metadata
1422 
1423     loadi OpPutById::Metadata::m_newStructureID[t5], t1
1424     btiz t1, .opPutByIdNotTransition
1425 
1426     # This is the transition case. t1 holds the new structureID. t2 holds the old structure ID.
1427     # If we have a chain, we need to check it. t0 is the base. We may clobber t1 to use it as
1428     # scratch.
1429     loadp OpPutById::Metadata::m_structureChain[t5], t3
1430     btpz t3, .opPutByIdTransitionDirect
1431 
<span class="line-modified">1432     loadp CodeBlock[cfr], t1</span>
<span class="line-added">1433     loadp CodeBlock::m_vm[t1], t1</span>
<span class="line-added">1434     loadp VM::heap + Heap::m_structureIDTable + StructureIDTable::m_table[t1], t1</span>
<span class="line-added">1435 </span>
<span class="line-added">1436     macro structureIDToStructureWithScratchAndTable(structureIDThenStructure, table, scratch)</span>
<span class="line-added">1437         move structureIDThenStructure, scratch</span>
<span class="line-added">1438         rshifti NumberOfStructureIDEntropyBits, scratch</span>
<span class="line-added">1439         loadp [table, scratch, PtrSize], scratch</span>
<span class="line-added">1440         lshiftp StructureEntropyBitsShift, structureIDThenStructure</span>
<span class="line-added">1441         xorp scratch, structureIDThenStructure</span>
<span class="line-added">1442     end</span>
1443 
<span class="line-modified">1444     structureIDToStructureWithScratchAndTable(t2, t1, t0)</span>

1445 
1446     loadp StructureChain::m_vector[t3], t3
1447     assert(macro (ok) btpnz t3, ok end)
1448 
1449     loadq Structure::m_prototype[t2], t2
1450     bqeq t2, ValueNull, .opPutByIdTransitionChainDone
1451 .opPutByIdTransitionChainLoop:




1452     loadi JSCell::m_structureID[t2], t2
<span class="line-modified">1453     bineq t2, [t3], .opPutByIdSlow</span>
<span class="line-modified">1454     addp 4, t3</span>
<span class="line-modified">1455     structureIDToStructureWithScratchAndTable(t2, t1, t0)</span>
<span class="line-modified">1456     loadq Structure::m_prototype[t2], t2</span>
1457     bqneq t2, ValueNull, .opPutByIdTransitionChainLoop
1458 
1459 .opPutByIdTransitionChainDone:
1460     # Reload the new structure, since we clobbered it above.
1461     loadi OpPutById::Metadata::m_newStructureID[t5], t1
<span class="line-added">1462     # Reload base into t0</span>
<span class="line-added">1463     get(m_base, t3)</span>
<span class="line-added">1464     loadConstantOrVariable(size, t3, t0)</span>
1465 
1466 .opPutByIdTransitionDirect:
1467     storei t1, JSCell::m_structureID[t0]
1468     writeBarrierOnOperandWithReload(size, get, m_base, macro ()
1469         # Reload metadata into t5
1470         metadata(t5, t1)
1471         # Reload base into t0
1472         get(m_base, t1)
1473         loadConstantOrVariable(size, t1, t0)
1474     end)
1475 
1476 .opPutByIdNotTransition:
1477     # The only thing live right now is t0, which holds the base.
1478     get(m_value, t1)
1479     loadConstantOrVariable(size, t1, t2)
1480     loadi OpPutById::Metadata::m_offset[t5], t1
1481     storePropertyAtVariableOffset(t1, t0, t2)
1482     writeBarrierOnOperands(size, get, m_base, m_value)
1483     dispatch()
1484 
1485 .opPutByIdSlow:
1486     callSlowPath(_llint_slow_path_put_by_id)
1487     dispatch()
<span class="line-added">1488 </span>
<span class="line-added">1489 .osrReturnPoint:</span>
<span class="line-added">1490     getterSetterOSRExitReturnPoint(op_put_by_id, size)</span>
<span class="line-added">1491     dispatch()</span>
<span class="line-added">1492 </span>
1493 end)
1494 
1495 
1496 llintOpWithMetadata(op_get_by_val, OpGetByVal, macro (size, get, dispatch, metadata, return)
1497     macro finishGetByVal(result, scratch)
1498         get(m_dst, scratch)
1499         storeq result, [cfr, scratch, 8]
1500         valueProfile(OpGetByVal, t5, result)
1501         dispatch()
1502     end
1503 
1504     macro finishIntGetByVal(result, scratch)
<span class="line-modified">1505         orq numberTag, result</span>
1506         finishGetByVal(result, scratch)
1507     end
1508 
1509     macro finishDoubleGetByVal(result, scratch1, scratch2)
1510         fd2q result, scratch1
<span class="line-modified">1511         subq numberTag, scratch1</span>
1512         finishGetByVal(scratch1, scratch2)
1513     end
1514 
1515     metadata(t5, t2)
1516 
1517     get(m_base, t2)
1518     loadConstantOrVariableCell(size, t2, t0, .opGetByValSlow)
1519 
1520     move t0, t2
1521     arrayProfile(OpGetByVal::Metadata::m_arrayProfile, t2, t5, t1)
1522 
1523     get(m_property, t3)
1524     loadConstantOrVariableInt32(size, t3, t1, .opGetByValSlow)
1525     sxi2q t1, t1
1526 
<span class="line-modified">1527     loadCagedJSValue(JSObject::m_butterfly[t0], t3, numberTag)</span>
<span class="line-modified">1528     move TagNumber, numberTag</span>
1529 
1530     andi IndexingShapeMask, t2
1531     bieq t2, Int32Shape, .opGetByValIsContiguous
1532     bineq t2, ContiguousShape, .opGetByValNotContiguous
1533 
1534 .opGetByValIsContiguous:
1535     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t3], .opGetByValSlow
1536     get(m_dst, t0)
1537     loadq [t3, t1, 8], t2
1538     btqz t2, .opGetByValSlow
1539     jmp .opGetByValDone
1540 
1541 .opGetByValNotContiguous:
1542     bineq t2, DoubleShape, .opGetByValNotDouble
1543     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t3], .opGetByValSlow
1544     get(m_dst, t0)
1545     loadd [t3, t1, 8], ft0
1546     bdnequn ft0, ft0, .opGetByValSlow
1547     fd2q ft0, t2
<span class="line-modified">1548     subq numberTag, t2</span>
1549     jmp .opGetByValDone
1550     
1551 .opGetByValNotDouble:
1552     subi ArrayStorageShape, t2
1553     bia t2, SlowPutArrayStorageShape - ArrayStorageShape, .opGetByValNotIndexedStorage
1554     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t3], .opGetByValSlow
1555     get(m_dst, t0)
1556     loadq ArrayStorage::m_vector[t3, t1, 8], t2
1557     btqz t2, .opGetByValSlow
1558 
1559 .opGetByValDone:
1560     storeq t2, [cfr, t0, 8]
1561     valueProfile(OpGetByVal, t5, t2)
1562     dispatch()
1563 
1564 .opGetByValNotIndexedStorage:
1565     # First lets check if we even have a typed array. This lets us do some boilerplate up front.
1566     loadb JSCell::m_type[t0], t2
1567     subi FirstTypedArrayType, t2
1568     biaeq t2, NumberOfTypedArrayTypesExcludingDataView, .opGetByValSlow
</pre>
<hr />
<pre>
1644 .opGetByValUint32Array:
1645     # We have Uint32ArrayType.
1646     # This is the hardest part because of large unsigned values.
1647     loadi [t3, t1, 4], t0
1648     bilt t0, 0, .opGetByValSlow # This case is still awkward to implement in LLInt.
1649     finishIntGetByVal(t0, t1)
1650 
1651 .opGetByValFloat32ArrayOrFloat64Array:
1652     # We have one of Float32ArrayType or Float64ArrayType. Sadly, we cannot handle Float32Array
1653     # inline yet. That would require some offlineasm changes.
1654     bieq t2, Float32ArrayType - FirstTypedArrayType, .opGetByValSlow
1655 
1656     # We have Float64ArrayType.
1657     loadd [t3, t1, 8], ft0
1658     bdnequn ft0, ft0, .opGetByValSlow
1659     finishDoubleGetByVal(ft0, t0, t1)
1660 
1661 .opGetByValSlow:
1662     callSlowPath(_llint_slow_path_get_by_val)
1663     dispatch()
<span class="line-added">1664 </span>
<span class="line-added">1665 .osrReturnPoint:</span>
<span class="line-added">1666     getterSetterOSRExitReturnPoint(op_get_by_val, size)</span>
<span class="line-added">1667     metadata(t5, t2)</span>
<span class="line-added">1668     valueProfile(OpGetByVal, t5, r0)</span>
<span class="line-added">1669     return(r0)</span>
<span class="line-added">1670 </span>
1671 end)
1672 
1673 
<span class="line-modified">1674 macro putByValOp(opcodeName, opcodeStruct, osrExitPoint)</span>
1675     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)
1676         macro contiguousPutByVal(storeCallback)
1677             biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], .outOfBounds
1678         .storeResult:
1679             get(m_value, t2)
1680             storeCallback(t2, t1, [t0, t3, 8])
1681             dispatch()
1682 
1683         .outOfBounds:
1684             biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t0], .opPutByValOutOfBounds
1685             storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_mayStoreToHole[t5]
1686             addi 1, t3, t2
1687             storei t2, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0]
1688             jmp .storeResult
1689         end
1690 
1691         get(m_base, t0)
1692         loadConstantOrVariableCell(size, t0, t1, .opPutByValSlow)
1693         move t1, t2
1694         metadata(t5, t0)
1695         arrayProfile(%opcodeStruct%::Metadata::m_arrayProfile, t2, t5, t0)
1696         get(m_property, t0)
1697         loadConstantOrVariableInt32(size, t0, t3, .opPutByValSlow)
1698         sxi2q t3, t3
<span class="line-modified">1699         loadCagedJSValue(JSObject::m_butterfly[t1], t0, numberTag)</span>
<span class="line-modified">1700         move TagNumber, numberTag</span>
1701         btinz t2, CopyOnWrite, .opPutByValSlow
1702         andi IndexingShapeMask, t2
1703         bineq t2, Int32Shape, .opPutByValNotInt32
1704         contiguousPutByVal(
1705             macro (operand, scratch, address)
1706                 loadConstantOrVariable(size, operand, scratch)
<span class="line-modified">1707                 bqb scratch, numberTag, .opPutByValSlow</span>
1708                 storeq scratch, address
1709                 writeBarrierOnOperands(size, get, m_base, m_value)
1710             end)
1711 
1712     .opPutByValNotInt32:
1713         bineq t2, DoubleShape, .opPutByValNotDouble
1714         contiguousPutByVal(
1715             macro (operand, scratch, address)
1716                 loadConstantOrVariable(size, operand, scratch)
<span class="line-modified">1717                 bqb scratch, numberTag, .notInt</span>
<span class="line-modified">1718                 ci2ds scratch, ft0</span>
1719                 jmp .ready
1720             .notInt:
<span class="line-modified">1721                 addq numberTag, scratch</span>
1722                 fq2d scratch, ft0
1723                 bdnequn ft0, ft0, .opPutByValSlow
1724             .ready:
1725                 stored ft0, address
1726                 writeBarrierOnOperands(size, get, m_base, m_value)
1727             end)
1728 
1729     .opPutByValNotDouble:
1730         bineq t2, ContiguousShape, .opPutByValNotContiguous
1731         contiguousPutByVal(
1732             macro (operand, scratch, address)
1733                 loadConstantOrVariable(size, operand, scratch)
1734                 storeq scratch, address
1735                 writeBarrierOnOperands(size, get, m_base, m_value)
1736             end)
1737 
1738     .opPutByValNotContiguous:
1739         bineq t2, ArrayStorageShape, .opPutByValSlow
1740         biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t0], .opPutByValOutOfBounds
1741         btqz ArrayStorage::m_vector[t0, t3, 8], .opPutByValArrayStorageEmpty
1742     .opPutByValArrayStorageStoreResult:
1743         get(m_value, t2)
1744         loadConstantOrVariable(size, t2, t1)
1745         storeq t1, ArrayStorage::m_vector[t0, t3, 8]
1746         writeBarrierOnOperands(size, get, m_base, m_value)
1747         dispatch()
1748 
1749     .opPutByValArrayStorageEmpty:
1750         storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_mayStoreToHole[t5]
1751         addi 1, ArrayStorage::m_numValuesInVector[t0]
1752         bib t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], .opPutByValArrayStorageStoreResult
1753         addi 1, t3, t1
1754         storei t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0]
1755         jmp .opPutByValArrayStorageStoreResult
1756 
1757     .opPutByValOutOfBounds:
1758         storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_outOfBounds[t5]
1759     .opPutByValSlow:
1760         callSlowPath(_llint_slow_path_%opcodeName%)
1761         dispatch()
<span class="line-added">1762 </span>
<span class="line-added">1763         osrExitPoint(size, dispatch)</span>
<span class="line-added">1764 </span>
1765     end)
1766 end
1767 
<span class="line-modified">1768 putByValOp(put_by_val, OpPutByVal, macro (size, dispatch)</span>
<span class="line-added">1769 .osrReturnPoint:</span>
<span class="line-added">1770     getterSetterOSRExitReturnPoint(op_put_by_val, size)</span>
<span class="line-added">1771     dispatch()</span>
<span class="line-added">1772 end)</span>
1773 
<span class="line-modified">1774 putByValOp(put_by_val_direct, OpPutByValDirect, macro (a, b) end)</span>
1775 
1776 
1777 macro llintJumpTrueOrFalseOp(opcodeName, opcodeStruct, conditionOp)
1778     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1779         get(m_condition, t1)
1780         loadConstantOrVariable(size, t1, t0)
1781         btqnz t0, ~0xf, .slow
1782         conditionOp(t0, .target)
1783         dispatch()
1784 
1785     .target:
1786         jump(m_targetLabel)
1787 
1788     .slow:
1789         callSlowPath(_llint_slow_path_%opcodeName%)
1790         nextInstruction()
1791     end)
1792 end
1793 
1794 
1795 macro equalNullJumpOp(opcodeName, opcodeStruct, cellHandler, immediateHandler)
1796     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1797         get(m_value, t0)
1798         assertNotConstant(size, t0)
1799         loadq [cfr, t0, 8], t0
<span class="line-modified">1800         btqnz t0, notCellMask, .immediate</span>
1801         loadStructureWithScratch(t0, t2, t1, t3)
1802         cellHandler(t2, JSCell::m_flags[t0], .target)
1803         dispatch()
1804 
1805     .target:
1806         jump(m_targetLabel)
1807 
1808     .immediate:
<span class="line-modified">1809         andq ~TagUndefined, t0</span>
1810         immediateHandler(t0, .target)
1811         dispatch()
1812     end)
1813 end
1814 
1815 equalNullJumpOp(jeq_null, OpJeqNull,
1816     macro (structure, value, target) 
1817         btbz value, MasqueradesAsUndefined, .notMasqueradesAsUndefined
1818         loadp CodeBlock[cfr], t0
1819         loadp CodeBlock::m_globalObject[t0], t0
1820         bpeq Structure::m_globalObject[structure], t0, target
1821 .notMasqueradesAsUndefined:
1822     end,
1823     macro (value, target) bqeq value, ValueNull, target end)
1824 
1825 
1826 equalNullJumpOp(jneq_null, OpJneqNull,
1827     macro (structure, value, target) 
1828         btbz value, MasqueradesAsUndefined, target
1829         loadp CodeBlock[cfr], t0
1830         loadp CodeBlock::m_globalObject[t0], t0
1831         bpneq Structure::m_globalObject[structure], t0, target
1832     end,
1833     macro (value, target) bqneq value, ValueNull, target end)
1834 
1835 macro undefinedOrNullJumpOp(opcodeName, opcodeStruct, fn)
1836     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1837         get(m_value, t1)
1838         loadConstantOrVariable(size, t1, t0)
<span class="line-modified">1839         andq ~TagUndefined, t0</span>
1840         fn(t0, .target)
1841         dispatch()
1842 
1843     .target:
1844         jump(m_targetLabel)
1845     end)
1846 end
1847 
1848 undefinedOrNullJumpOp(jundefined_or_null, OpJundefinedOrNull,
1849     macro (value, target) bqeq value, ValueNull, target end)
1850 
1851 undefinedOrNullJumpOp(jnundefined_or_null, OpJnundefinedOrNull,
1852     macro (value, target) bqneq value, ValueNull, target end)
1853 
1854 llintOpWithMetadata(op_jneq_ptr, OpJneqPtr, macro (size, get, dispatch, metadata, return)
1855     get(m_value, t0)
<span class="line-modified">1856     get(m_specialPointer, t1)</span>
<span class="line-modified">1857     loadConstant(size, t1, t2)</span>
<span class="line-modified">1858     bpneq t2, [cfr, t0, 8], .opJneqPtrTarget</span>


1859     dispatch()
1860 
1861 .opJneqPtrTarget:
1862     metadata(t5, t0)
1863     storeb 1, OpJneqPtr::Metadata::m_hasJumped[t5]
1864     get(m_targetLabel, t0)
<span class="line-modified">1865     jumpImpl(dispatchIndirect, t0)</span>
1866 end)
1867 
1868 
1869 macro compareJumpOp(opcodeName, opcodeStruct, integerCompare, doubleCompare)
1870     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1871         get(m_lhs, t2)
1872         get(m_rhs, t3)
1873         loadConstantOrVariable(size, t2, t0)
1874         loadConstantOrVariable(size, t3, t1)
<span class="line-modified">1875         bqb t0, numberTag, .op1NotInt</span>
<span class="line-modified">1876         bqb t1, numberTag, .op2NotInt</span>
1877         integerCompare(t0, t1, .jumpTarget)
1878         dispatch()
1879 
1880     .op1NotInt:
<span class="line-modified">1881         btqz t0, numberTag, .slow</span>
<span class="line-modified">1882         bqb t1, numberTag, .op1NotIntOp2NotInt</span>
<span class="line-modified">1883         ci2ds t1, ft1</span>
1884         jmp .op1NotIntReady
1885     .op1NotIntOp2NotInt:
<span class="line-modified">1886         btqz t1, numberTag, .slow</span>
<span class="line-modified">1887         addq numberTag, t1</span>
1888         fq2d t1, ft1
1889     .op1NotIntReady:
<span class="line-modified">1890         addq numberTag, t0</span>
1891         fq2d t0, ft0
1892         doubleCompare(ft0, ft1, .jumpTarget)
1893         dispatch()
1894 
1895     .op2NotInt:
<span class="line-modified">1896         ci2ds t0, ft0</span>
<span class="line-modified">1897         btqz t1, numberTag, .slow</span>
<span class="line-modified">1898         addq numberTag, t1</span>
1899         fq2d t1, ft1
1900         doubleCompare(ft0, ft1, .jumpTarget)
1901         dispatch()
1902 
1903     .jumpTarget:
1904         jump(m_targetLabel)
1905 
1906     .slow:
1907         callSlowPath(_llint_slow_path_%opcodeName%)
1908         nextInstruction()
1909     end)
1910 end
1911 
1912 
1913 macro equalityJumpOp(opcodeName, opcodeStruct, integerComparison)
1914     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1915         get(m_lhs, t2)
1916         get(m_rhs, t3)
1917         loadConstantOrVariableInt32(size, t2, t0, .slow)
1918         loadConstantOrVariableInt32(size, t3, t1, .slow)
</pre>
<hr />
<pre>
1949         get(m_lhs, t2)
1950         get(m_rhs,  t0)
1951         loadConstantOrVariable(size, t0, t1)
1952         loadConstantOrVariable(size, t2, t0)
1953         integerCompareAndSet(t0, t1, t0)
1954         orq ValueFalse, t0
1955         return(t0)
1956     end)
1957 end
1958 
1959 
1960 llintOpWithJump(op_switch_imm, OpSwitchImm, macro (size, get, jump, dispatch)
1961     get(m_scrutinee, t2)
1962     getu(size, OpSwitchImm, m_tableIndex, t3)
1963     loadConstantOrVariable(size, t2, t1)
1964     loadp CodeBlock[cfr], t2
1965     loadp CodeBlock::m_rareData[t2], t2
1966     muli sizeof SimpleJumpTable, t3
1967     loadp CodeBlock::RareData::m_switchJumpTables + VectorBufferOffset[t2], t2
1968     addp t3, t2
<span class="line-modified">1969     bqb t1, numberTag, .opSwitchImmNotInt</span>
1970     subi SimpleJumpTable::min[t2], t1
1971     biaeq t1, SimpleJumpTable::branchOffsets + VectorSizeOffset[t2], .opSwitchImmFallThrough
1972     loadp SimpleJumpTable::branchOffsets + VectorBufferOffset[t2], t3
1973     loadis [t3, t1, 4], t1
1974     btiz t1, .opSwitchImmFallThrough
1975     dispatchIndirect(t1)
1976 
1977 .opSwitchImmNotInt:
<span class="line-modified">1978     btqnz t1, numberTag, .opSwitchImmSlow   # Go slow if it&#39;s a double.</span>
1979 .opSwitchImmFallThrough:
1980     jump(m_defaultOffset)
1981 
1982 .opSwitchImmSlow:
1983     callSlowPath(_llint_slow_path_switch_imm)
1984     nextInstruction()
1985 end)
1986 
1987 
1988 llintOpWithJump(op_switch_char, OpSwitchChar, macro (size, get, jump, dispatch)
1989     get(m_scrutinee, t2)
1990     getu(size, OpSwitchChar, m_tableIndex, t3)
1991     loadConstantOrVariable(size, t2, t1)
1992     loadp CodeBlock[cfr], t2
1993     loadp CodeBlock::m_rareData[t2], t2
1994     muli sizeof SimpleJumpTable, t3
1995     loadp CodeBlock::RareData::m_switchJumpTables + VectorBufferOffset[t2], t2
1996     addp t3, t2
<span class="line-modified">1997     btqnz t1, notCellMask, .opSwitchCharFallThrough</span>
1998     bbneq JSCell::m_type[t1], StringType, .opSwitchCharFallThrough
1999     loadp JSString::m_fiber[t1], t0
2000     btpnz t0, isRopeInPointer, .opSwitchOnRope
2001     bineq StringImpl::m_length[t0], 1, .opSwitchCharFallThrough
2002     loadp StringImpl::m_data8[t0], t1
2003     btinz StringImpl::m_hashAndFlags[t0], HashFlags8BitBuffer, .opSwitchChar8Bit
2004     loadh [t1], t0
2005     jmp .opSwitchCharReady
2006 .opSwitchChar8Bit:
2007     loadb [t1], t0
2008 .opSwitchCharReady:
2009     subi SimpleJumpTable::min[t2], t0
2010     biaeq t0, SimpleJumpTable::branchOffsets + VectorSizeOffset[t2], .opSwitchCharFallThrough
2011     loadp SimpleJumpTable::branchOffsets + VectorBufferOffset[t2], t2
2012     loadis [t2, t0, 4], t1
2013     btiz t1, .opSwitchCharFallThrough
2014     dispatchIndirect(t1)
2015 
2016 .opSwitchCharFallThrough:
2017     jump(m_defaultOffset)
2018 
2019 .opSwitchOnRope:
2020     bineq JSRopeString::m_compactFibers + JSRopeString::CompactFibers::m_length[t1], 1, .opSwitchCharFallThrough
2021 
2022 .opSwitchOnRopeChar:
2023     callSlowPath(_llint_slow_path_switch_char)
2024     nextInstruction()
2025 end)
2026 
2027 
2028 # we assume t5 contains the metadata, and we should not scratch that
2029 macro arrayProfileForCall(opcodeStruct, getu)
2030     getu(m_argv, t3)
2031     negp t3
2032     loadq ThisArgumentOffset[cfr, t3, 8], t0
<span class="line-modified">2033     btqnz t0, notCellMask, .done</span>
2034     loadi JSCell::m_structureID[t0], t3
2035     storei t3, %opcodeStruct%::Metadata::m_callLinkInfo.m_arrayProfile.m_lastSeenStructureID[t5]
2036 .done:
2037 end
2038 
2039 macro commonCallOp(opcodeName, slowPath, opcodeStruct, prepareCall, prologue)
2040     llintOpWithMetadata(opcodeName, opcodeStruct, macro (size, get, dispatch, metadata, return)
2041         metadata(t5, t0)
2042 
2043         prologue(macro (fieldName, dst)
2044             getu(size, opcodeStruct, fieldName, dst)
2045         end, metadata)
2046 
2047         get(m_callee, t0)
2048         loadp %opcodeStruct%::Metadata::m_callLinkInfo.m_calleeOrLastSeenCalleeWithLinkBit[t5], t2
2049         loadConstantOrVariable(size, t0, t3)
2050         bqneq t3, t2, .opCallSlow
2051         getu(size, opcodeStruct, m_argv, t3)
2052         lshifti 3, t3
2053         negp t3
2054         addp cfr, t3
2055         storeq t2, Callee[t3]
2056         getu(size, opcodeStruct, m_argc, t2)
<span class="line-modified">2057         storePC()</span>
<span class="line-modified">2058         storei t2, ArgumentCountIncludingThis + PayloadOffset[t3]</span>
2059         move t3, sp
2060         prepareCall(%opcodeStruct%::Metadata::m_callLinkInfo.m_machineCodeTarget[t5], t2, t3, t4, JSEntryPtrTag)
<span class="line-modified">2061         callTargetFunction(opcodeName, size, opcodeStruct, dispatch, %opcodeStruct%::Metadata::m_callLinkInfo.m_machineCodeTarget[t5], JSEntryPtrTag)</span>
2062 
2063     .opCallSlow:
<span class="line-modified">2064         slowPathForCall(opcodeName, size, opcodeStruct, dispatch, slowPath, prepareCall)</span>
2065     end)
2066 end
2067 
2068 llintOp(op_ret, OpRet, macro (size, get, dispatch)
2069     checkSwitchToJITForEpilogue()
2070     get(m_value, t2)
2071     loadConstantOrVariable(size, t2, r0)
2072     doReturn()
2073 end)
2074 
2075 
2076 llintOpWithReturn(op_to_primitive, OpToPrimitive, macro (size, get, dispatch, return)
2077     get(m_src, t2)
2078     loadConstantOrVariable(size, t2, t0)
<span class="line-modified">2079     btqnz t0, notCellMask, .opToPrimitiveIsImm</span>
2080     bbaeq JSCell::m_type[t0], ObjectType, .opToPrimitiveSlowCase
2081 .opToPrimitiveIsImm:
2082     return(t0)
2083 
2084 .opToPrimitiveSlowCase:
2085     callSlowPath(_slow_path_to_primitive)
2086     dispatch()
2087 end)
2088 
2089 
<span class="line-added">2090 llintOpWithReturn(op_to_property_key, OpToPropertyKey, macro (size, get, dispatch, return)</span>
<span class="line-added">2091     get(m_src, t2)</span>
<span class="line-added">2092     loadConstantOrVariable(size, t2, t0)</span>
<span class="line-added">2093 </span>
<span class="line-added">2094     btqnz t0, notCellMask, .opToPropertyKeySlow</span>
<span class="line-added">2095     bbeq JSCell::m_type[t0], SymbolType, .done</span>
<span class="line-added">2096     bbneq JSCell::m_type[t0], StringType, .opToPropertyKeySlow</span>
<span class="line-added">2097 </span>
<span class="line-added">2098 .done:</span>
<span class="line-added">2099     return(t0)</span>
<span class="line-added">2100 </span>
<span class="line-added">2101 .opToPropertyKeySlow:</span>
<span class="line-added">2102     callSlowPath(_slow_path_to_property_key)</span>
<span class="line-added">2103     dispatch()</span>
<span class="line-added">2104 end)</span>
<span class="line-added">2105 </span>
<span class="line-added">2106 </span>
2107 commonOp(llint_op_catch, macro() end, macro (size)
2108     # This is where we end up from the JIT&#39;s throw trampoline (because the
2109     # machine code return address will be set to _llint_op_catch), and from
2110     # the interpreter&#39;s throw trampoline (see _llint_throw_trampoline).
2111     # The throwing code must have known that we were throwing to the interpreter,
2112     # and have set VM::targetInterpreterPCForThrow.
2113     loadp Callee[cfr], t3
<span class="line-modified">2114     convertCalleeToVM(t3)</span>

2115     restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(t3, t0)
2116     loadp VM::callFrameForCatch[t3], cfr
2117     storep 0, VM::callFrameForCatch[t3]
2118     restoreStackPointerAfterCall()
2119 
2120     loadp CodeBlock[cfr], PB
2121     loadp CodeBlock::m_metadata[PB], metadataTable
2122     loadp CodeBlock::m_instructionsRawPointer[PB], PB
2123     loadp VM::targetInterpreterPCForThrow[t3], PC
2124     subp PB, PC
2125 
2126     callSlowPath(_llint_slow_path_check_if_exception_is_uncatchable_and_notify_profiler)
2127     bpeq r1, 0, .isCatchableException
2128     jmp _llint_throw_from_slow_path_trampoline
2129 
2130 .isCatchableException:
<span class="line-modified">2131     loadp CodeBlock[cfr], t3</span>
<span class="line-modified">2132     loadp CodeBlock::m_vm[t3], t3</span>

2133 
2134     loadp VM::m_exception[t3], t0
2135     storep 0, VM::m_exception[t3]
2136     get(size, OpCatch, m_exception, t2)
2137     storeq t0, [cfr, t2, 8]
2138 
2139     loadq Exception::m_value[t0], t3
2140     get(size, OpCatch, m_thrownValue, t2)
2141     storeq t3, [cfr, t2, 8]
2142 
2143     traceExecution()
2144 
2145     callSlowPath(_llint_slow_path_profile_catch)
2146 
2147     dispatchOp(size, op_catch)
2148 end)
2149 
2150 
2151 llintOp(op_end, OpEnd, macro (size, get, dispatch)
2152     checkSwitchToJITForEpilogue()
2153     get(m_value, t0)
2154     assertNotConstant(size, t0)
2155     loadq [cfr, t0, 8], r0
2156     doReturn()
2157 end)
2158 
2159 
2160 op(llint_throw_from_slow_path_trampoline, macro ()
2161     loadp Callee[cfr], t1
<span class="line-modified">2162     convertCalleeToVM(t1)</span>

2163     copyCalleeSavesToVMEntryFrameCalleeSavesBuffer(t1, t2)
2164 
2165     callSlowPath(_llint_slow_path_handle_exception)
2166 
2167     # When throwing from the interpreter (i.e. throwing from LLIntSlowPaths), so
2168     # the throw target is not necessarily interpreted code, we come to here.
2169     # This essentially emulates the JIT&#39;s throwing protocol.
2170     loadp Callee[cfr], t1
<span class="line-modified">2171     convertCalleeToVM(t1)</span>

2172     jmp VM::targetMachinePCForThrow[t1], ExceptionHandlerPtrTag
2173 end)
2174 
2175 
2176 op(llint_throw_during_call_trampoline, macro ()
2177     preserveReturnAddressAfterCall(t2)
2178     jmp _llint_throw_from_slow_path_trampoline
2179 end)
2180 
2181 
2182 macro nativeCallTrampoline(executableOffsetToFunction)

2183     functionPrologue()
2184     storep 0, CodeBlock[cfr]
<span class="line-modified">2185     loadp Callee[cfr], a0</span>
<span class="line-modified">2186     loadp JSFunction::m_executableOrRareData[a0], a2</span>
<span class="line-modified">2187     btpz a2, (constexpr JSFunction::rareDataTag), .isExecutable</span>
<span class="line-modified">2188     loadp (FunctionRareData::m_executable - (constexpr JSFunction::rareDataTag))[a2], a2</span>
<span class="line-added">2189 .isExecutable:</span>
<span class="line-added">2190     loadp JSFunction::m_scope[a0], a0</span>
<span class="line-added">2191     loadp JSGlobalObject::m_vm[a0], a1</span>
<span class="line-added">2192     storep cfr, VM::topCallFrame[a1]</span>
2193     if ARM64 or ARM64E or C_LOOP or C_LOOP_WIN
2194         storep lr, ReturnPC[cfr]
2195     end
<span class="line-modified">2196     move cfr, a1</span>


2197     checkStackPointerAlignment(t3, 0xdead0001)
2198     if C_LOOP or C_LOOP_WIN
<span class="line-modified">2199         cloopCallNative executableOffsetToFunction[a2]</span>
2200     else
2201         if X86_64_WIN
2202             subp 32, sp
<span class="line-modified">2203             call executableOffsetToFunction[a2], JSEntryPtrTag</span>
2204             addp 32, sp
2205         else
<span class="line-modified">2206             call executableOffsetToFunction[a2], JSEntryPtrTag</span>
2207         end
2208     end
2209 
2210     loadp Callee[cfr], t3
<span class="line-modified">2211     loadp JSFunction::m_scope[t3], t3</span>
<span class="line-modified">2212     loadp JSGlobalObject::m_vm[t3], t3</span>
2213 
2214     btpnz VM::m_exception[t3], .handleException
2215 
2216     functionEpilogue()
2217     ret
2218 
2219 .handleException:
2220     storep cfr, VM::topCallFrame[t3]
2221     jmp _llint_throw_from_slow_path_trampoline
2222 end
2223 
2224 macro internalFunctionCallTrampoline(offsetOfFunction)
2225     functionPrologue()
2226     storep 0, CodeBlock[cfr]
<span class="line-modified">2227     loadp Callee[cfr], a2</span>
<span class="line-modified">2228     loadp InternalFunction::m_globalObject[a2], a0</span>
<span class="line-modified">2229     loadp JSGlobalObject::m_vm[a0], a1</span>
<span class="line-modified">2230     storep cfr, VM::topCallFrame[a1]</span>
2231     if ARM64 or ARM64E or C_LOOP or C_LOOP_WIN
2232         storep lr, ReturnPC[cfr]
2233     end
<span class="line-modified">2234     move cfr, a1</span>

2235     checkStackPointerAlignment(t3, 0xdead0001)
2236     if C_LOOP or C_LOOP_WIN
<span class="line-modified">2237         cloopCallNative offsetOfFunction[a2]</span>
2238     else
2239         if X86_64_WIN
2240             subp 32, sp
<span class="line-modified">2241             call offsetOfFunction[a2], JSEntryPtrTag</span>
2242             addp 32, sp
2243         else
<span class="line-modified">2244             call offsetOfFunction[a2], JSEntryPtrTag</span>
2245         end
2246     end
2247 
2248     loadp Callee[cfr], t3
<span class="line-modified">2249     loadp InternalFunction::m_globalObject[t3], t3</span>
<span class="line-modified">2250     loadp JSGlobalObject::m_vm[t3], t3</span>
2251 
2252     btpnz VM::m_exception[t3], .handleException
2253 
2254     functionEpilogue()
2255     ret
2256 
2257 .handleException:
2258     storep cfr, VM::topCallFrame[t3]
2259     jmp _llint_throw_from_slow_path_trampoline
2260 end
2261 
2262 macro varInjectionCheck(slowPath, scratch)
2263     loadp CodeBlock[cfr], scratch
2264     loadp CodeBlock::m_globalObject[scratch], scratch
2265     loadp JSGlobalObject::m_varInjectionWatchpoint[scratch], scratch
2266     bbeq WatchpointSet::m_state[scratch], IsInvalidated, slowPath
2267 end
2268 
2269 llintOpWithMetadata(op_resolve_scope, OpResolveScope, macro (size, get, dispatch, metadata, return)
2270     metadata(t5, t0)
</pre>
<hr />
<pre>
2594     loadp CodeBlock[cfr], t1
2595     loadp CodeBlock::m_vm[t1], t1
2596     # t1 is holding the pointer to the typeProfilerLog.
2597     loadp VM::m_typeProfilerLog[t1], t1
2598     # t2 is holding the pointer to the current log entry.
2599     loadp TypeProfilerLog::m_currentLogEntryPtr[t1], t2
2600 
2601     # t0 is holding the JSValue argument.
2602     get(m_targetVirtualRegister, t3)
2603     loadConstantOrVariable(size, t3, t0)
2604 
2605     bqeq t0, ValueEmpty, .opProfileTypeDone
2606     # Store the JSValue onto the log entry.
2607     storeq t0, TypeProfilerLog::LogEntry::value[t2]
2608     
2609     # Store the TypeLocation onto the log entry.
2610     metadata(t5, t3)
2611     loadp OpProfileType::Metadata::m_typeLocation[t5], t3
2612     storep t3, TypeProfilerLog::LogEntry::location[t2]
2613 
<span class="line-modified">2614     btqz t0, notCellMask, .opProfileTypeIsCell</span>
2615     storei 0, TypeProfilerLog::LogEntry::structureID[t2]
2616     jmp .opProfileTypeSkipIsCell
2617 .opProfileTypeIsCell:
2618     loadi JSCell::m_structureID[t0], t3
2619     storei t3, TypeProfilerLog::LogEntry::structureID[t2]
2620 .opProfileTypeSkipIsCell:
2621     
2622     # Increment the current log entry.
2623     addp sizeof TypeProfilerLog::LogEntry, t2
2624     storep t2, TypeProfilerLog::m_currentLogEntryPtr[t1]
2625 
2626     loadp TypeProfilerLog::m_logEndPtr[t1], t1
2627     bpneq t2, t1, .opProfileTypeDone
2628     callSlowPath(_slow_path_profile_type_clear_log)
2629 
2630 .opProfileTypeDone:
2631     dispatch()
2632 end)
2633 
2634 
2635 llintOpWithMetadata(op_profile_control_flow, OpProfileControlFlow, macro (size, get, dispatch, metadata, return)
2636     metadata(t5, t0)
2637     loadp OpProfileControlFlow::Metadata::m_basicBlockLocation[t5], t0
2638     addq 1, BasicBlockLocation::m_executionCount[t0]
2639     dispatch()
2640 end)
2641 
2642 
2643 llintOpWithReturn(op_get_rest_length, OpGetRestLength, macro (size, get, dispatch, return)
<span class="line-modified">2644     loadi PayloadOffset + ArgumentCountIncludingThis[cfr], t0</span>
2645     subi 1, t0
2646     getu(size, OpGetRestLength, m_numParametersToSkip, t1)
2647     bilteq t0, t1, .storeZero
2648     subi t1, t0
2649     jmp .boxUp
2650 .storeZero:
2651     move 0, t0
2652 .boxUp:
<span class="line-modified">2653     orq numberTag, t0</span>
<span class="line-added">2654     return(t0)</span>
<span class="line-added">2655 end)</span>
<span class="line-added">2656 </span>
<span class="line-added">2657 </span>
<span class="line-added">2658 llintOpWithProfile(op_get_internal_field, OpGetInternalField, macro (size, get, dispatch, return)</span>
<span class="line-added">2659     loadVariable(get, m_base, t1)</span>
<span class="line-added">2660     getu(size, OpGetInternalField, m_index, t2)</span>
<span class="line-added">2661     loadq JSInternalFieldObjectImpl_internalFields[t1, t2, SlotSize], t0</span>
2662     return(t0)
2663 end)
2664 
<span class="line-added">2665 llintOp(op_put_internal_field, OpPutInternalField, macro (size, get, dispatch)</span>
<span class="line-added">2666     loadVariable(get, m_base, t0)</span>
<span class="line-added">2667     get(m_value, t1)</span>
<span class="line-added">2668     loadConstantOrVariable(size, t1, t2)</span>
<span class="line-added">2669     getu(size, OpPutInternalField, m_index, t1)</span>
<span class="line-added">2670     storeq t2, JSInternalFieldObjectImpl_internalFields[t0, t1, SlotSize]</span>
<span class="line-added">2671     writeBarrierOnCellAndValueWithReload(t0, t2, macro() end)</span>
<span class="line-added">2672     dispatch()</span>
<span class="line-added">2673 end)</span>
<span class="line-added">2674 </span>
2675 
2676 llintOp(op_log_shadow_chicken_prologue, OpLogShadowChickenPrologue, macro (size, get, dispatch)
2677     acquireShadowChickenPacket(.opLogShadowChickenPrologueSlow)
2678     storep cfr, ShadowChicken::Packet::frame[t0]
2679     loadp CallerFrame[cfr], t1
2680     storep t1, ShadowChicken::Packet::callerFrame[t0]
2681     loadp Callee[cfr], t1
2682     storep t1, ShadowChicken::Packet::callee[t0]
2683     loadVariable(get, m_scope, t1)
2684     storep t1, ShadowChicken::Packet::scope[t0]
2685     dispatch()
2686 .opLogShadowChickenPrologueSlow:
2687     callSlowPath(_llint_slow_path_log_shadow_chicken_prologue)
2688     dispatch()
2689 end)
2690 
2691 
2692 llintOp(op_log_shadow_chicken_tail, OpLogShadowChickenTail, macro (size, get, dispatch)
2693     acquireShadowChickenPacket(.opLogShadowChickenTailSlow)
2694     storep cfr, ShadowChicken::Packet::frame[t0]
</pre>
</td>
</tr>
</table>
<center><a href="LowLevelInterpreter32_64.asm.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="../offlineasm/arm.rb.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>