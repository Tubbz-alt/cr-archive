<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/JavaScriptCore/runtime/SamplingProfiler.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (C) 2016-2019 Apple Inc. All rights reserved.
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;SamplingProfiler.h&quot;
  28 
  29 #if ENABLE(SAMPLING_PROFILER)
  30 
  31 #include &quot;CallFrame.h&quot;
  32 #include &quot;CatchScope.h&quot;
  33 #include &quot;CodeBlock.h&quot;
  34 #include &quot;CodeBlockSet.h&quot;
  35 #include &quot;HeapIterationScope.h&quot;
  36 #include &quot;HeapUtil.h&quot;
  37 #include &quot;InlineCallFrame.h&quot;
  38 #include &quot;Interpreter.h&quot;
  39 #include &quot;JSCInlines.h&quot;
  40 #include &quot;JSFunction.h&quot;
  41 #include &quot;LLIntPCRanges.h&quot;
  42 #include &quot;MachineContext.h&quot;
  43 #include &quot;MarkedBlock.h&quot;
  44 #include &quot;MarkedBlockSet.h&quot;
  45 #include &quot;MarkedSpaceInlines.h&quot;
  46 #include &quot;NativeExecutable.h&quot;
  47 #include &quot;PCToCodeOriginMap.h&quot;
  48 #include &quot;SlotVisitor.h&quot;
  49 #include &quot;StrongInlines.h&quot;
  50 #include &quot;VM.h&quot;
  51 #include &quot;WasmCallee.h&quot;
  52 #include &quot;WasmCalleeRegistry.h&quot;
  53 #include &lt;thread&gt;
  54 #include &lt;wtf/FilePrintStream.h&gt;
  55 #include &lt;wtf/HashSet.h&gt;
  56 #include &lt;wtf/RefPtr.h&gt;
  57 #include &lt;wtf/StackTrace.h&gt;
  58 #include &lt;wtf/text/StringBuilder.h&gt;
  59 #include &lt;wtf/text/StringConcatenateNumbers.h&gt;
  60 
  61 namespace JSC {
  62 
  63 static double sNumTotalStackTraces = 0;
  64 static double sNumTotalWalks = 0;
  65 static double sNumFailedWalks = 0;
  66 static const uint32_t sNumWalkReportingFrequency = 50;
  67 static const double sWalkErrorPercentage = .05;
  68 static constexpr bool sReportStatsOnlyWhenTheyreAboveThreshold = false;
  69 static constexpr bool sReportStats = false;
  70 
  71 using FrameType = SamplingProfiler::FrameType;
  72 using UnprocessedStackFrame = SamplingProfiler::UnprocessedStackFrame;
  73 
  74 ALWAYS_INLINE static void reportStats()
  75 {
  76     if (sReportStats &amp;&amp; sNumTotalWalks &amp;&amp; static_cast&lt;uint64_t&gt;(sNumTotalWalks) % sNumWalkReportingFrequency == 0) {
  77         if (!sReportStatsOnlyWhenTheyreAboveThreshold || (sNumFailedWalks / sNumTotalWalks &gt; sWalkErrorPercentage)) {
  78             dataLogF(&quot;Num total walks: %llu. Failed walks percent: %lf\n&quot;,
  79                 static_cast&lt;unsigned long long&gt;(sNumTotalWalks), sNumFailedWalks / sNumTotalWalks);
  80         }
  81     }
  82 }
  83 
  84 class FrameWalker {
  85 public:
  86     FrameWalker(VM&amp; vm, CallFrame* callFrame, const AbstractLocker&amp; codeBlockSetLocker, const AbstractLocker&amp; machineThreadsLocker, const AbstractLocker&amp; wasmCalleeLocker)
  87         : m_vm(vm)
  88         , m_callFrame(callFrame)
  89         , m_entryFrame(vm.topEntryFrame)
  90         , m_codeBlockSetLocker(codeBlockSetLocker)
  91         , m_machineThreadsLocker(machineThreadsLocker)
  92         , m_wasmCalleeLocker(wasmCalleeLocker)
  93     {
  94     }
  95 
  96     SUPPRESS_ASAN
  97     size_t walk(Vector&lt;UnprocessedStackFrame&gt;&amp; stackTrace, bool&amp; didRunOutOfSpace)
  98     {
  99         if (sReportStats)
 100             sNumTotalWalks++;
 101         resetAtMachineFrame();
 102         size_t maxStackTraceSize = stackTrace.size();
 103         while (!isAtTop() &amp;&amp; !m_bailingOut &amp;&amp; m_depth &lt; maxStackTraceSize) {
 104             recordJITFrame(stackTrace);
 105             advanceToParentFrame();
 106             resetAtMachineFrame();
 107         }
 108         didRunOutOfSpace = m_depth &gt;= maxStackTraceSize &amp;&amp; !isAtTop();
 109         reportStats();
 110         return m_depth;
 111     }
 112 
 113     bool wasValidWalk() const
 114     {
 115         return !m_bailingOut;
 116     }
 117 
 118 protected:
 119 
 120     SUPPRESS_ASAN
 121     void recordJITFrame(Vector&lt;UnprocessedStackFrame&gt;&amp; stackTrace)
 122     {
 123         CallSiteIndex callSiteIndex;
 124         CalleeBits unsafeCallee = m_callFrame-&gt;unsafeCallee();
 125         CodeBlock* codeBlock = m_callFrame-&gt;unsafeCodeBlock();
 126         if (unsafeCallee.isWasm())
 127             codeBlock = nullptr;
 128         if (codeBlock) {
 129             ASSERT(isValidCodeBlock(codeBlock));
 130             callSiteIndex = m_callFrame-&gt;unsafeCallSiteIndex();
 131         }
 132         stackTrace[m_depth] = UnprocessedStackFrame(codeBlock, unsafeCallee, callSiteIndex);
 133 #if ENABLE(WEBASSEMBLY)
 134         if (unsafeCallee.isWasm()) {
 135             auto* wasmCallee = unsafeCallee.asWasmCallee();
 136             if (Wasm::CalleeRegistry::singleton().isValidCallee(m_wasmCalleeLocker, wasmCallee)) {
 137                 // At this point, Wasm::Callee would be dying (ref count is 0), but its fields are still live.
 138                 // And we can safely copy Wasm::IndexOrName even when any lock is held by suspended threads.
 139                 stackTrace[m_depth].wasmIndexOrName = wasmCallee-&gt;indexOrName();
 140                 stackTrace[m_depth].wasmCompilationMode = wasmCallee-&gt;compilationMode();
 141             }
 142         }
 143 #endif
 144         m_depth++;
 145     }
 146 
 147     SUPPRESS_ASAN
 148     void advanceToParentFrame()
 149     {
 150         m_callFrame = m_callFrame-&gt;unsafeCallerFrame(m_entryFrame);
 151     }
 152 
 153     bool isAtTop() const
 154     {
 155         return !m_callFrame;
 156     }
 157 
 158     SUPPRESS_ASAN
 159     void resetAtMachineFrame()
 160     {
 161         if (isAtTop())
 162             return;
 163 
 164         if (!isValidFramePointer(m_callFrame)) {
 165             // Guard against pausing the process at weird program points.
 166             m_bailingOut = true;
 167             if (sReportStats)
 168                 sNumFailedWalks++;
 169             return;
 170         }
 171 
 172         CodeBlock* codeBlock = m_callFrame-&gt;unsafeCodeBlock();
 173         if (!codeBlock || m_callFrame-&gt;unsafeCallee().isWasm())
 174             return;
 175 
 176         if (!isValidCodeBlock(codeBlock)) {
 177             m_bailingOut = true;
 178             if (sReportStats)
 179                 sNumFailedWalks++;
 180             return;
 181         }
 182     }
 183 
 184     bool isValidFramePointer(void* callFrame)
 185     {
 186         uint8_t* fpCast = bitwise_cast&lt;uint8_t*&gt;(callFrame);
 187         for (auto&amp; thread : m_vm.heap.machineThreads().threads(m_machineThreadsLocker)) {
 188             uint8_t* stackBase = static_cast&lt;uint8_t*&gt;(thread-&gt;stack().origin());
 189             uint8_t* stackLimit = static_cast&lt;uint8_t*&gt;(thread-&gt;stack().end());
 190             RELEASE_ASSERT(stackBase);
 191             RELEASE_ASSERT(stackLimit);
 192             RELEASE_ASSERT(stackLimit &lt;= stackBase);
 193             if (fpCast &lt; stackBase &amp;&amp; fpCast &gt;= stackLimit)
 194                 return true;
 195         }
 196         return false;
 197     }
 198 
 199     bool isValidCodeBlock(CodeBlock* codeBlock)
 200     {
 201         if (!codeBlock)
 202             return false;
 203         bool result = m_vm.heap.codeBlockSet().contains(m_codeBlockSetLocker, codeBlock);
 204         return result;
 205     }
 206 
 207     VM&amp; m_vm;
 208     CallFrame* m_callFrame;
 209     EntryFrame* m_entryFrame;
 210     const AbstractLocker&amp; m_codeBlockSetLocker;
 211     const AbstractLocker&amp; m_machineThreadsLocker;
 212     const AbstractLocker&amp; m_wasmCalleeLocker;
 213     bool m_bailingOut { false };
 214     size_t m_depth { 0 };
 215 };
 216 
 217 class CFrameWalker : public FrameWalker {
 218 public:
 219     typedef FrameWalker Base;
 220 
 221     CFrameWalker(VM&amp; vm, void* machineFrame, CallFrame* callFrame, const AbstractLocker&amp; codeBlockSetLocker, const AbstractLocker&amp; machineThreadsLocker, const AbstractLocker&amp; wasmCalleeLocker)
 222         : Base(vm, callFrame, codeBlockSetLocker, machineThreadsLocker, wasmCalleeLocker)
 223         , m_machineFrame(machineFrame)
 224     {
 225     }
 226 
 227     size_t walk(Vector&lt;UnprocessedStackFrame&gt;&amp; stackTrace, bool&amp; didRunOutOfSpace)
 228     {
 229         if (sReportStats)
 230             sNumTotalWalks++;
 231         resetAtMachineFrame();
 232         size_t maxStackTraceSize = stackTrace.size();
 233         // The way the C walker decides if a frame it is about to trace is C or JS is by
 234         // ensuring m_callFrame points to some frame above the machineFrame.
 235         if (!isAtTop() &amp;&amp; !m_bailingOut &amp;&amp; m_machineFrame == m_callFrame) {
 236             recordJITFrame(stackTrace);
 237             Base::advanceToParentFrame();
 238             resetAtMachineFrame();
 239         }
 240 
 241         while (!isAtTop() &amp;&amp; !m_bailingOut &amp;&amp; m_depth &lt; maxStackTraceSize) {
 242             if (m_machineFrame &gt;= m_callFrame) {
 243                 // If we get to this state we probably have an invalid trace.
 244                 m_bailingOut = true;
 245                 break;
 246             }
 247 
 248             if (isCFrame()) {
 249                 RELEASE_ASSERT(!LLInt::isLLIntPC(frame()-&gt;callerFrame));
 250                 stackTrace[m_depth] = UnprocessedStackFrame(frame()-&gt;returnPC);
 251                 m_depth++;
 252             } else
 253                 recordJITFrame(stackTrace);
 254             advanceToParentFrame();
 255             resetAtMachineFrame();
 256         }
 257         didRunOutOfSpace = m_depth &gt;= maxStackTraceSize &amp;&amp; !isAtTop();
 258         reportStats();
 259         return m_depth;
 260     }
 261 
 262 private:
 263 
 264     bool isCFrame()
 265     {
 266         return frame()-&gt;callerFrame != m_callFrame;
 267     }
 268 
 269     void advanceToParentFrame()
 270     {
 271         if (!isCFrame())
 272             Base::advanceToParentFrame();
 273         m_machineFrame = frame()-&gt;callerFrame;
 274     }
 275 
 276     void resetAtMachineFrame()
 277     {
 278         if (!isValidFramePointer(m_machineFrame)) {
 279             // Guard against pausing the process at weird program points.
 280             m_bailingOut = true;
 281             if (sReportStats)
 282                 sNumFailedWalks++;
 283             return;
 284         }
 285         Base::resetAtMachineFrame();
 286     }
 287 
 288     CallerFrameAndPC* frame()
 289     {
 290         return reinterpret_cast&lt;CallerFrameAndPC*&gt;(m_machineFrame);
 291     }
 292 
 293     void* m_machineFrame;
 294 };
 295 
 296 SamplingProfiler::SamplingProfiler(VM&amp; vm, RefPtr&lt;Stopwatch&gt;&amp;&amp; stopwatch)
 297     : m_isPaused(false)
 298     , m_isShutDown(false)
 299     , m_vm(vm)
 300     , m_weakRandom()
 301     , m_stopwatch(WTFMove(stopwatch))
 302     , m_timingInterval(Seconds::fromMicroseconds(Options::sampleInterval()))
 303 {
 304     if (sReportStats) {
 305         sNumTotalWalks = 0;
 306         sNumFailedWalks = 0;
 307     }
 308 
 309     m_currentFrames.grow(256);
 310     vm.heap.objectSpace().enablePreciseAllocationTracking();
 311 }
 312 
 313 SamplingProfiler::~SamplingProfiler()
 314 {
 315 }
 316 
 317 void SamplingProfiler::createThreadIfNecessary(const AbstractLocker&amp;)
 318 {
 319     ASSERT(m_lock.isLocked());
 320 
 321     if (m_thread)
 322         return;
 323 
 324     RefPtr&lt;SamplingProfiler&gt; profiler = this;
 325     m_thread = Thread::create(&quot;jsc.sampling-profiler.thread&quot;, [profiler] {
 326         profiler-&gt;timerLoop();
 327     });
 328 }
 329 
 330 void SamplingProfiler::timerLoop()
 331 {
 332     while (true) {
 333         Seconds stackTraceProcessingTime = 0_s;
 334         {
 335             LockHolder locker(m_lock);
 336             if (UNLIKELY(m_isShutDown))
 337                 return;
 338 
 339             if (!m_isPaused &amp;&amp; m_jscExecutionThread)
 340                 takeSample(locker, stackTraceProcessingTime);
 341 
 342             m_lastTime = m_stopwatch-&gt;elapsedTime();
 343         }
 344 
 345         // Read section 6.2 of this paper for more elaboration of why we add a random
 346         // fluctuation here. The main idea is to prevent our timer from being in sync
 347         // with some system process such as a scheduled context switch.
 348         // http://plv.colorado.edu/papers/mytkowicz-pldi10.pdf
 349         double randomSignedNumber = (m_weakRandom.get() * 2.0) - 1.0; // A random number between [-1, 1).
 350         Seconds randomFluctuation = m_timingInterval * 0.2 * randomSignedNumber;
 351         WTF::sleep(m_timingInterval - std::min(m_timingInterval, stackTraceProcessingTime) + randomFluctuation);
 352     }
 353 }
 354 
 355 void SamplingProfiler::takeSample(const AbstractLocker&amp;, Seconds&amp; stackTraceProcessingTime)
 356 {
 357     ASSERT(m_lock.isLocked());
 358     if (m_vm.entryScope) {
 359         Seconds nowTime = m_stopwatch-&gt;elapsedTime();
 360 
 361         auto machineThreadsLocker = holdLock(m_vm.heap.machineThreads().getLock());
 362         auto codeBlockSetLocker = holdLock(m_vm.heap.codeBlockSet().getLock());
 363         auto executableAllocatorLocker = holdLock(ExecutableAllocator::singleton().getLock());
 364 #if ENABLE(WEBASSEMBLY)
 365         auto wasmCalleesLocker = holdLock(Wasm::CalleeRegistry::singleton().getLock());
 366 #else
 367         LockHolder wasmCalleesLocker(NoLockingNecessary);
 368 #endif
 369 
 370         auto didSuspend = m_jscExecutionThread-&gt;suspend();
 371         if (didSuspend) {
 372             // While the JSC thread is suspended, we can&#39;t do things like malloc because the JSC thread
 373             // may be holding the malloc lock.
 374             void* machineFrame;
 375             CallFrame* callFrame;
 376             void* machinePC;
 377             bool topFrameIsLLInt = false;
 378             void* llintPC;
 379             {
 380                 PlatformRegisters registers;
 381                 m_jscExecutionThread-&gt;getRegisters(registers);
 382                 machineFrame = MachineContext::framePointer(registers);
 383                 callFrame = static_cast&lt;CallFrame*&gt;(machineFrame);
 384                 auto instructionPointer = MachineContext::instructionPointer(registers);
 385                 if (instructionPointer)
 386                     machinePC = instructionPointer-&gt;untaggedExecutableAddress();
 387                 else
 388                     machinePC = nullptr;
 389                 llintPC = removeCodePtrTag(MachineContext::llintInstructionPointer(registers));
 390                 assertIsNotTagged(machinePC);
 391             }
 392             // FIXME: Lets have a way of detecting when we&#39;re parsing code.
 393             // https://bugs.webkit.org/show_bug.cgi?id=152761
 394             if (ExecutableAllocator::singleton().isValidExecutableMemory(executableAllocatorLocker, machinePC)) {
 395                 if (m_vm.isExecutingInRegExpJIT) {
 396                     // FIXME: We&#39;re executing a regexp. Lets gather more intersting data.
 397                     // https://bugs.webkit.org/show_bug.cgi?id=152729
 398                     callFrame = m_vm.topCallFrame; // We need to do this or else we&#39;d fail our backtrace validation b/c this isn&#39;t a JS frame.
 399                 }
 400             } else if (LLInt::isLLIntPC(machinePC)) {
 401                 topFrameIsLLInt = true;
 402                 // We&#39;re okay to take a normal stack trace when the PC
 403                 // is in LLInt code.
 404             } else {
 405                 // We resort to topCallFrame to see if we can get anything
 406                 // useful. We usually get here when we&#39;re executing C code.
 407                 callFrame = m_vm.topCallFrame;
 408             }
 409 
 410             size_t walkSize;
 411             bool wasValidWalk;
 412             bool didRunOutOfVectorSpace;
 413             if (Options::sampleCCode()) {
 414                 CFrameWalker walker(m_vm, machineFrame, callFrame, codeBlockSetLocker, machineThreadsLocker, wasmCalleesLocker);
 415                 walkSize = walker.walk(m_currentFrames, didRunOutOfVectorSpace);
 416                 wasValidWalk = walker.wasValidWalk();
 417             } else {
 418                 FrameWalker walker(m_vm, callFrame, codeBlockSetLocker, machineThreadsLocker, wasmCalleesLocker);
 419                 walkSize = walker.walk(m_currentFrames, didRunOutOfVectorSpace);
 420                 wasValidWalk = walker.wasValidWalk();
 421             }
 422 
 423             m_jscExecutionThread-&gt;resume();
 424 
 425             auto startTime = MonotonicTime::now();
 426             // We can now use data structures that malloc, and do other interesting things, again.
 427 
 428             // FIXME: It&#39;d be interesting to take data about the program&#39;s state when
 429             // we fail to take a stack trace: https://bugs.webkit.org/show_bug.cgi?id=152758
 430             if (wasValidWalk &amp;&amp; walkSize) {
 431                 if (sReportStats)
 432                     sNumTotalStackTraces++;
 433                 Vector&lt;UnprocessedStackFrame&gt; stackTrace;
 434                 stackTrace.reserveInitialCapacity(walkSize);
 435                 for (size_t i = 0; i &lt; walkSize; i++) {
 436                     UnprocessedStackFrame frame = m_currentFrames[i];
 437                     stackTrace.uncheckedAppend(frame);
 438                 }
 439 
 440                 m_unprocessedStackTraces.append(UnprocessedStackTrace { nowTime, machinePC, topFrameIsLLInt, llintPC, WTFMove(stackTrace) });
 441 
 442                 if (didRunOutOfVectorSpace)
 443                     m_currentFrames.grow(m_currentFrames.size() * 1.25);
 444             }
 445 
 446             auto endTime = MonotonicTime::now();
 447             stackTraceProcessingTime = endTime - startTime;
 448         }
 449     }
 450 }
 451 
 452 static ALWAYS_INLINE BytecodeIndex tryGetBytecodeIndex(unsigned llintPC, CodeBlock* codeBlock)
 453 {
 454 #if ENABLE(DFG_JIT)
 455     RELEASE_ASSERT(!codeBlock-&gt;hasCodeOrigins());
 456 #endif
 457 
 458     unsigned bytecodeOffset = llintPC;
 459     if (bytecodeOffset &lt; codeBlock-&gt;instructionsSize())
 460         return BytecodeIndex(bytecodeOffset);
 461     return BytecodeIndex();
 462 }
 463 
 464 void SamplingProfiler::processUnverifiedStackTraces(const AbstractLocker&amp;)
 465 {
 466     // This function needs to be called from the JSC execution thread.
 467     RELEASE_ASSERT(m_lock.isLocked());
 468 
 469     TinyBloomFilter filter = m_vm.heap.objectSpace().blocks().filter();
 470 
 471     for (UnprocessedStackTrace&amp; unprocessedStackTrace : m_unprocessedStackTraces) {
 472         m_stackTraces.append(StackTrace());
 473         StackTrace&amp; stackTrace = m_stackTraces.last();
 474         stackTrace.timestamp = unprocessedStackTrace.timestamp;
 475 
 476         auto populateCodeLocation = [] (CodeBlock* codeBlock, BytecodeIndex bytecodeIndex, StackFrame::CodeLocation&amp; location) {
 477             if (bytecodeIndex.offset() &lt; codeBlock-&gt;instructionsSize()) {
 478                 int divot;
 479                 int startOffset;
 480                 int endOffset;
 481                 codeBlock-&gt;expressionRangeForBytecodeIndex(bytecodeIndex, divot, startOffset, endOffset,
 482                     location.lineNumber, location.columnNumber);
 483                 location.bytecodeIndex = bytecodeIndex;
 484             }
 485             if (Options::collectSamplingProfilerDataForJSCShell()) {
 486                 location.codeBlockHash = codeBlock-&gt;hash();
 487                 location.jitType = codeBlock-&gt;jitType();
 488             }
 489         };
 490 
 491         auto appendCodeBlock = [&amp;] (CodeBlock* codeBlock, BytecodeIndex bytecodeIndex) {
 492             stackTrace.frames.append(StackFrame(codeBlock-&gt;ownerExecutable()));
 493             m_liveCellPointers.add(codeBlock-&gt;ownerExecutable());
 494             populateCodeLocation(codeBlock, bytecodeIndex, stackTrace.frames.last().semanticLocation);
 495         };
 496 
 497         auto appendEmptyFrame = [&amp;] {
 498             stackTrace.frames.append(StackFrame());
 499         };
 500 
 501         auto storeCalleeIntoLastFrame = [&amp;] (UnprocessedStackFrame&amp; unprocessedStackFrame) {
 502             // Set the callee if it&#39;s a valid GC object.
 503             CalleeBits calleeBits = unprocessedStackFrame.unverifiedCallee;
 504             StackFrame&amp; stackFrame = stackTrace.frames.last();
 505             bool alreadyHasExecutable = !!stackFrame.executable;
 506 #if ENABLE(WEBASSEMBLY)
 507             if (calleeBits.isWasm()) {
 508                 stackFrame.frameType = FrameType::Wasm;
 509                 stackFrame.wasmIndexOrName = unprocessedStackFrame.wasmIndexOrName;
 510                 stackFrame.wasmCompilationMode = unprocessedStackFrame.wasmCompilationMode;
 511                 return;
 512             }
 513 #endif
 514 
 515             JSValue callee = calleeBits.asCell();
 516             if (!HeapUtil::isValueGCObject(m_vm.heap, filter, callee)) {
 517                 if (!alreadyHasExecutable)
 518                     stackFrame.frameType = FrameType::Unknown;
 519                 return;
 520             }
 521 
 522             JSCell* calleeCell = callee.asCell();
 523             auto setFallbackFrameType = [&amp;] {
 524                 ASSERT(!alreadyHasExecutable);
 525                 FrameType result = FrameType::Unknown;
 526                 CallData callData;
 527                 CallType callType;
 528                 callType = getCallData(m_vm, calleeCell, callData);
 529                 if (callType == CallType::Host)
 530                     result = FrameType::Host;
 531 
 532                 stackFrame.frameType = result;
 533             };
 534 
 535             auto addCallee = [&amp;] (JSObject* callee) {
 536                 stackFrame.callee = callee;
 537                 m_liveCellPointers.add(callee);
 538             };
 539 
 540             if (calleeCell-&gt;type() != JSFunctionType) {
 541                 if (JSObject* object = jsDynamicCast&lt;JSObject*&gt;(calleeCell-&gt;vm(), calleeCell))
 542                     addCallee(object);
 543 
 544                 if (!alreadyHasExecutable)
 545                     setFallbackFrameType();
 546 
 547                 return;
 548             }
 549 
 550             addCallee(jsCast&lt;JSFunction*&gt;(calleeCell));
 551 
 552             if (alreadyHasExecutable)
 553                 return;
 554 
 555             ExecutableBase* executable = jsCast&lt;JSFunction*&gt;(calleeCell)-&gt;executable();
 556             if (!executable) {
 557                 setFallbackFrameType();
 558                 return;
 559             }
 560 
 561             RELEASE_ASSERT(HeapUtil::isPointerGCObjectJSCell(m_vm.heap, filter, executable));
 562             stackFrame.frameType = FrameType::Executable;
 563             stackFrame.executable = executable;
 564             m_liveCellPointers.add(executable);
 565         };
 566 
 567         auto appendCodeOrigin = [&amp;] (CodeBlock* machineCodeBlock, CodeOrigin origin) {
 568             size_t startIndex = stackTrace.frames.size(); // We want to change stack traces that we&#39;re about to append.
 569 
 570             CodeOrigin machineOrigin;
 571             origin.walkUpInlineStack([&amp;] (const CodeOrigin&amp; codeOrigin) {
 572                 machineOrigin = codeOrigin;
 573                 auto* inlineCallFrame = codeOrigin.inlineCallFrame();
 574                 appendCodeBlock(inlineCallFrame ? inlineCallFrame-&gt;baselineCodeBlock.get() : machineCodeBlock, codeOrigin.bytecodeIndex());
 575             });
 576 
 577             if (Options::collectSamplingProfilerDataForJSCShell()) {
 578                 RELEASE_ASSERT(machineOrigin.isSet());
 579                 RELEASE_ASSERT(!machineOrigin.inlineCallFrame());
 580 
 581                 StackFrame::CodeLocation machineLocation = stackTrace.frames.last().semanticLocation;
 582 
 583                 // We want to tell each inlined frame about the machine frame
 584                 // they were inlined into. Currently, we only use this for dumping
 585                 // output on the command line, but we could extend it to the web
 586                 // inspector in the future if we find a need for it there.
 587                 RELEASE_ASSERT(stackTrace.frames.size());
 588                 m_liveCellPointers.add(machineCodeBlock);
 589                 for (size_t i = startIndex; i &lt; stackTrace.frames.size() - 1; i++)
 590                     stackTrace.frames[i].machineLocation = std::make_pair(machineLocation, machineCodeBlock);
 591             }
 592         };
 593 
 594         // Prepend the top-most inlined frame if needed and gather
 595         // location information about where the top frame is executing.
 596         size_t startIndex = 0;
 597         if (unprocessedStackTrace.frames.size() &amp;&amp; !!unprocessedStackTrace.frames[0].verifiedCodeBlock) {
 598             CodeBlock* topCodeBlock = unprocessedStackTrace.frames[0].verifiedCodeBlock;
 599             if (unprocessedStackTrace.topFrameIsLLInt) {
 600                 // We reuse LLInt CodeBlocks for the baseline JIT, so we need to check for both jit types.
 601                 // This might also be false for various reasons (known and unknown), even though
 602                 // it&#39;s super unlikely. One reason that this can be false is when we throw from a DFG frame,
 603                 // and we end up having to unwind past an EntryFrame, we will end up executing
 604                 // inside the LLInt&#39;s handleUncaughtException. So we just protect against this
 605                 // by ignoring it.
 606                 BytecodeIndex bytecodeIndex = BytecodeIndex(0);
 607                 if (topCodeBlock-&gt;jitType() == JITType::InterpreterThunk || topCodeBlock-&gt;jitType() == JITType::BaselineJIT) {
 608                     unsigned bits = static_cast&lt;unsigned&gt;(bitwise_cast&lt;uintptr_t&gt;(unprocessedStackTrace.llintPC));
 609                     bytecodeIndex = tryGetBytecodeIndex(bits, topCodeBlock);
 610 
 611                     UNUSED_PARAM(bytecodeIndex); // FIXME: do something with this info for the web inspector: https://bugs.webkit.org/show_bug.cgi?id=153455
 612 
 613                     appendCodeBlock(topCodeBlock, bytecodeIndex);
 614                     storeCalleeIntoLastFrame(unprocessedStackTrace.frames[0]);
 615                     startIndex = 1;
 616                 }
 617             } else {
 618 #if ENABLE(JIT)
 619                 if (Optional&lt;CodeOrigin&gt; codeOrigin = topCodeBlock-&gt;findPC(unprocessedStackTrace.topPC)) {
 620                     appendCodeOrigin(topCodeBlock, *codeOrigin);
 621                     storeCalleeIntoLastFrame(unprocessedStackTrace.frames[0]);
 622                     startIndex = 1;
 623                 }
 624 #endif
 625                 UNUSED_PARAM(appendCodeOrigin);
 626             }
 627         }
 628 
 629         for (size_t i = startIndex; i &lt; unprocessedStackTrace.frames.size(); i++) {
 630             UnprocessedStackFrame&amp; unprocessedStackFrame = unprocessedStackTrace.frames[i];
 631             if (CodeBlock* codeBlock = unprocessedStackFrame.verifiedCodeBlock) {
 632                 CallSiteIndex callSiteIndex = unprocessedStackFrame.callSiteIndex;
 633 
 634                 auto appendCodeBlockNoInlining = [&amp;] {
 635                     appendCodeBlock(codeBlock, tryGetBytecodeIndex(callSiteIndex.bits(), codeBlock));
 636                 };
 637 
 638 #if ENABLE(DFG_JIT)
 639                 if (codeBlock-&gt;hasCodeOrigins()) {
 640                     if (codeBlock-&gt;canGetCodeOrigin(callSiteIndex))
 641                         appendCodeOrigin(codeBlock, codeBlock-&gt;codeOrigin(callSiteIndex));
 642                     else
 643                         appendCodeBlock(codeBlock, BytecodeIndex());
 644                 } else
 645                     appendCodeBlockNoInlining();
 646 #else
 647                 appendCodeBlockNoInlining();
 648 #endif
 649             } else if (unprocessedStackFrame.cCodePC) {
 650                 appendEmptyFrame();
 651                 stackTrace.frames.last().cCodePC = unprocessedStackFrame.cCodePC;
 652                 stackTrace.frames.last().frameType = FrameType::C;
 653             } else
 654                 appendEmptyFrame();
 655 
 656             // Note that this is okay to do if we walked the inline stack because
 657             // the machine frame will be at the top of the processed stack trace.
 658             if (!unprocessedStackFrame.cCodePC)
 659                 storeCalleeIntoLastFrame(unprocessedStackFrame);
 660         }
 661     }
 662 
 663     m_unprocessedStackTraces.clear();
 664 }
 665 
 666 void SamplingProfiler::visit(SlotVisitor&amp; slotVisitor)
 667 {
 668     RELEASE_ASSERT(m_lock.isLocked());
 669     for (JSCell* cell : m_liveCellPointers)
 670         slotVisitor.appendUnbarriered(cell);
 671 }
 672 
 673 void SamplingProfiler::shutdown()
 674 {
 675     LockHolder locker(m_lock);
 676     m_isShutDown = true;
 677 }
 678 
 679 void SamplingProfiler::start()
 680 {
 681     LockHolder locker(m_lock);
 682     start(locker);
 683 }
 684 
 685 void SamplingProfiler::start(const AbstractLocker&amp; locker)
 686 {
 687     ASSERT(m_lock.isLocked());
 688     m_isPaused = false;
 689     createThreadIfNecessary(locker);
 690 }
 691 
 692 void SamplingProfiler::pause(const AbstractLocker&amp;)
 693 {
 694     ASSERT(m_lock.isLocked());
 695     m_isPaused = true;
 696     reportStats();
 697 }
 698 
 699 void SamplingProfiler::noticeCurrentThreadAsJSCExecutionThread(const AbstractLocker&amp;)
 700 {
 701     ASSERT(m_lock.isLocked());
 702     m_jscExecutionThread = &amp;Thread::current();
 703 }
 704 
 705 void SamplingProfiler::noticeCurrentThreadAsJSCExecutionThread()
 706 {
 707     LockHolder locker(m_lock);
 708     noticeCurrentThreadAsJSCExecutionThread(locker);
 709 }
 710 
 711 void SamplingProfiler::noticeJSLockAcquisition()
 712 {
 713     LockHolder locker(m_lock);
 714     noticeCurrentThreadAsJSCExecutionThread(locker);
 715 }
 716 
 717 void SamplingProfiler::noticeVMEntry()
 718 {
 719     LockHolder locker(m_lock);
 720     ASSERT(m_vm.entryScope);
 721     noticeCurrentThreadAsJSCExecutionThread(locker);
 722     m_lastTime = m_stopwatch-&gt;elapsedTime();
 723     createThreadIfNecessary(locker);
 724 }
 725 
 726 void SamplingProfiler::clearData(const AbstractLocker&amp;)
 727 {
 728     ASSERT(m_lock.isLocked());
 729     m_stackTraces.clear();
 730     m_liveCellPointers.clear();
 731     m_unprocessedStackTraces.clear();
 732 }
 733 
 734 String SamplingProfiler::StackFrame::nameFromCallee(VM&amp; vm)
 735 {
 736     if (!callee)
 737         return String();
 738 
 739     auto scope = DECLARE_CATCH_SCOPE(vm);
 740     JSGlobalObject* globalObject = callee-&gt;globalObject(vm);
 741     auto getPropertyIfPureOperation = [&amp;] (const Identifier&amp; ident) -&gt; String {
 742         PropertySlot slot(callee, PropertySlot::InternalMethodType::VMInquiry);
 743         PropertyName propertyName(ident);
 744         bool hasProperty = callee-&gt;getPropertySlot(globalObject, propertyName, slot);
 745         scope.assertNoException();
 746         if (hasProperty) {
 747             if (slot.isValue()) {
 748                 JSValue nameValue = slot.getValue(globalObject, propertyName);
 749                 if (isJSString(nameValue))
 750                     return asString(nameValue)-&gt;tryGetValue();
 751             }
 752         }
 753         return String();
 754     };
 755 
 756     String name = getPropertyIfPureOperation(vm.propertyNames-&gt;displayName);
 757     if (!name.isEmpty())
 758         return name;
 759 
 760     return getPropertyIfPureOperation(vm.propertyNames-&gt;name);
 761 }
 762 
 763 String SamplingProfiler::StackFrame::displayName(VM&amp; vm)
 764 {
 765     {
 766         String name = nameFromCallee(vm);
 767         if (!name.isEmpty())
 768             return name;
 769     }
 770 
 771     switch (frameType) {
 772     case FrameType::Unknown:
 773     case FrameType::C:
 774 #if HAVE(DLADDR)
 775         if (frameType == FrameType::C) {
 776             auto demangled = WTF::StackTrace::demangle(const_cast&lt;void*&gt;(cCodePC));
 777             if (demangled)
 778                 return String(demangled-&gt;demangledName() ? demangled-&gt;demangledName() : demangled-&gt;mangledName());
 779             WTF::dataLog(&quot;couldn&#39;t get a name&quot;);
 780         }
 781 #endif
 782         return &quot;(unknown)&quot;_s;
 783 
 784     case FrameType::Host:
 785         return &quot;(host)&quot;_s;
 786 
 787     case FrameType::Wasm:
 788 #if ENABLE(WEBASSEMBLY)
 789         if (wasmIndexOrName)
 790             return makeString(wasmIndexOrName.value());
 791 #endif
 792         return &quot;(wasm)&quot;_s;
 793 
 794     case FrameType::Executable:
 795         if (executable-&gt;isHostFunction())
 796             return static_cast&lt;NativeExecutable*&gt;(executable)-&gt;name();
 797 
 798         if (executable-&gt;isFunctionExecutable())
 799             return static_cast&lt;FunctionExecutable*&gt;(executable)-&gt;ecmaName().string();
 800         if (executable-&gt;isProgramExecutable() || executable-&gt;isEvalExecutable())
 801             return &quot;(program)&quot;_s;
 802         if (executable-&gt;isModuleProgramExecutable())
 803             return &quot;(module)&quot;_s;
 804 
 805         RELEASE_ASSERT_NOT_REACHED();
 806         return String();
 807     }
 808     RELEASE_ASSERT_NOT_REACHED();
 809     return String();
 810 }
 811 
 812 String SamplingProfiler::StackFrame::displayNameForJSONTests(VM&amp; vm)
 813 {
 814     {
 815         String name = nameFromCallee(vm);
 816         if (!name.isEmpty())
 817             return name;
 818     }
 819 
 820     switch (frameType) {
 821     case FrameType::Unknown:
 822     case FrameType::C:
 823         return &quot;(unknown)&quot;_s;
 824 
 825     case FrameType::Host:
 826         return &quot;(host)&quot;_s;
 827 
 828     case FrameType::Wasm: {
 829 #if ENABLE(WEBASSEMBLY)
 830         if (wasmIndexOrName)
 831             return makeString(wasmIndexOrName.value());
 832 #endif
 833         return &quot;(wasm)&quot;_s;
 834     }
 835 
 836     case FrameType::Executable:
 837         if (executable-&gt;isHostFunction())
 838             return static_cast&lt;NativeExecutable*&gt;(executable)-&gt;name();
 839 
 840         if (executable-&gt;isFunctionExecutable()) {
 841             String result = static_cast&lt;FunctionExecutable*&gt;(executable)-&gt;ecmaName().string();
 842             if (result.isEmpty())
 843                 return &quot;(anonymous function)&quot;_s;
 844             return result;
 845         }
 846         if (executable-&gt;isEvalExecutable())
 847             return &quot;(eval)&quot;_s;
 848         if (executable-&gt;isProgramExecutable())
 849             return &quot;(program)&quot;_s;
 850         if (executable-&gt;isModuleProgramExecutable())
 851             return &quot;(module)&quot;_s;
 852 
 853         RELEASE_ASSERT_NOT_REACHED();
 854         return String();
 855     }
 856     RELEASE_ASSERT_NOT_REACHED();
 857     return String();
 858 }
 859 
 860 int SamplingProfiler::StackFrame::functionStartLine()
 861 {
 862     switch (frameType) {
 863     case FrameType::Unknown:
 864     case FrameType::Host:
 865     case FrameType::C:
 866     case FrameType::Wasm:
 867         return -1;
 868 
 869     case FrameType::Executable:
 870         if (executable-&gt;isHostFunction())
 871             return -1;
 872         return static_cast&lt;ScriptExecutable*&gt;(executable)-&gt;firstLine();
 873     }
 874     RELEASE_ASSERT_NOT_REACHED();
 875     return -1;
 876 }
 877 
 878 unsigned SamplingProfiler::StackFrame::functionStartColumn()
 879 {
 880     switch (frameType) {
 881     case FrameType::Unknown:
 882     case FrameType::Host:
 883     case FrameType::C:
 884     case FrameType::Wasm:
 885         return std::numeric_limits&lt;unsigned&gt;::max();
 886 
 887     case FrameType::Executable:
 888         if (executable-&gt;isHostFunction())
 889             return std::numeric_limits&lt;unsigned&gt;::max();
 890 
 891         return static_cast&lt;ScriptExecutable*&gt;(executable)-&gt;startColumn();
 892     }
 893     RELEASE_ASSERT_NOT_REACHED();
 894     return std::numeric_limits&lt;unsigned&gt;::max();
 895 }
 896 
 897 intptr_t SamplingProfiler::StackFrame::sourceID()
 898 {
 899     switch (frameType) {
 900     case FrameType::Unknown:
 901     case FrameType::Host:
 902     case FrameType::C:
 903     case FrameType::Wasm:
 904         return -1;
 905 
 906     case FrameType::Executable:
 907         if (executable-&gt;isHostFunction())
 908             return -1;
 909 
 910         return static_cast&lt;ScriptExecutable*&gt;(executable)-&gt;sourceID();
 911     }
 912     RELEASE_ASSERT_NOT_REACHED();
 913     return -1;
 914 }
 915 
 916 String SamplingProfiler::StackFrame::url()
 917 {
 918     switch (frameType) {
 919     case FrameType::Unknown:
 920     case FrameType::Host:
 921     case FrameType::C:
 922     case FrameType::Wasm:
 923         return emptyString();
 924     case FrameType::Executable:
 925         if (executable-&gt;isHostFunction())
 926             return emptyString();
 927 
 928         String url = static_cast&lt;ScriptExecutable*&gt;(executable)-&gt;sourceURL();
 929         if (url.isEmpty())
 930             return static_cast&lt;ScriptExecutable*&gt;(executable)-&gt;source().provider()-&gt;sourceURLDirective(); // Fall back to sourceURL directive.
 931         return url;
 932     }
 933     RELEASE_ASSERT_NOT_REACHED();
 934     return String();
 935 }
 936 
 937 Vector&lt;SamplingProfiler::StackTrace&gt; SamplingProfiler::releaseStackTraces(const AbstractLocker&amp; locker)
 938 {
 939     ASSERT(m_lock.isLocked());
 940     {
 941         HeapIterationScope heapIterationScope(m_vm.heap);
 942         processUnverifiedStackTraces(locker);
 943     }
 944 
 945     Vector&lt;StackTrace&gt; result(WTFMove(m_stackTraces));
 946     clearData(locker);
 947     return result;
 948 }
 949 
 950 String SamplingProfiler::stackTracesAsJSON()
 951 {
 952     DeferGC deferGC(m_vm.heap);
 953     auto locker = holdLock(m_lock);
 954 
 955     {
 956         HeapIterationScope heapIterationScope(m_vm.heap);
 957         processUnverifiedStackTraces(locker);
 958     }
 959 
 960     StringBuilder json;
 961     json.append(&#39;[&#39;);
 962 
 963     bool loopedOnce = false;
 964     auto comma = [&amp;] {
 965         if (loopedOnce)
 966             json.append(&#39;,&#39;);
 967     };
 968     for (StackTrace&amp; stackTrace : m_stackTraces) {
 969         comma();
 970         json.append(&#39;[&#39;);
 971         loopedOnce = false;
 972         for (StackFrame&amp; stackFrame : stackTrace.frames) {
 973             comma();
 974             json.appendQuotedJSONString(stackFrame.displayNameForJSONTests(m_vm));
 975             loopedOnce = true;
 976         }
 977         json.append(&#39;]&#39;);
 978         loopedOnce = true;
 979     }
 980 
 981     json.append(&#39;]&#39;);
 982 
 983     clearData(locker);
 984 
 985     return json.toString();
 986 }
 987 
 988 void SamplingProfiler::registerForReportAtExit()
 989 {
 990     static Lock registrationLock;
 991     static HashSet&lt;RefPtr&lt;SamplingProfiler&gt;&gt;* profilesToReport;
 992 
 993     LockHolder holder(registrationLock);
 994 
 995     if (!profilesToReport) {
 996         profilesToReport = new HashSet&lt;RefPtr&lt;SamplingProfiler&gt;&gt;();
 997         atexit([]() {
 998             for (const auto&amp; profile : *profilesToReport)
 999                 profile-&gt;reportDataToOptionFile();
1000         });
1001     }
1002 
1003     profilesToReport-&gt;add(adoptRef(this));
1004     m_needsReportAtExit = true;
1005 }
1006 
1007 void SamplingProfiler::reportDataToOptionFile()
1008 {
1009     if (m_needsReportAtExit) {
1010         m_needsReportAtExit = false;
1011         JSLockHolder holder(m_vm);
1012         const char* path = Options::samplingProfilerPath();
1013         StringPrintStream pathOut;
1014         pathOut.print(path, &quot;/&quot;);
1015         pathOut.print(&quot;JSCSampilingProfile-&quot;, reinterpret_cast&lt;uintptr_t&gt;(this), &quot;.txt&quot;);
1016         auto out = FilePrintStream::open(pathOut.toCString().data(), &quot;w&quot;);
1017         reportTopFunctions(*out);
1018         reportTopBytecodes(*out);
1019     }
1020 }
1021 
1022 void SamplingProfiler::reportTopFunctions()
1023 {
1024     reportTopFunctions(WTF::dataFile());
1025 }
1026 
1027 void SamplingProfiler::reportTopFunctions(PrintStream&amp; out)
1028 {
1029     auto locker = holdLock(m_lock);
1030     DeferGCForAWhile deferGC(m_vm.heap);
1031 
1032     {
1033         HeapIterationScope heapIterationScope(m_vm.heap);
1034         processUnverifiedStackTraces(locker);
1035     }
1036 
1037 
1038     HashMap&lt;String, size_t&gt; functionCounts;
1039     for (StackTrace&amp; stackTrace : m_stackTraces) {
1040         if (!stackTrace.frames.size())
1041             continue;
1042 
1043         StackFrame&amp; frame = stackTrace.frames.first();
1044         String frameDescription = makeString(frame.displayName(m_vm), &#39;:&#39;, frame.sourceID());
1045         functionCounts.add(frameDescription, 0).iterator-&gt;value++;
1046     }
1047 
1048     auto takeMax = [&amp;] () -&gt; std::pair&lt;String, size_t&gt; {
1049         String maxFrameDescription;
1050         size_t maxFrameCount = 0;
1051         for (const auto&amp; entry : functionCounts) {
1052             if (entry.value &gt; maxFrameCount) {
1053                 maxFrameCount = entry.value;
1054                 maxFrameDescription = entry.key;
1055             }
1056         }
1057         if (!maxFrameDescription.isEmpty())
1058             functionCounts.remove(maxFrameDescription);
1059         return std::make_pair(maxFrameDescription, maxFrameCount);
1060     };
1061 
1062     if (Options::samplingProfilerTopFunctionsCount()) {
1063         out.print(&quot;\n\nSampling rate: &quot;, m_timingInterval.microseconds(), &quot; microseconds\n&quot;);
1064         out.print(&quot;Top functions as &lt;numSamples  &#39;functionName:sourceID&#39;&gt;\n&quot;);
1065         for (size_t i = 0; i &lt; Options::samplingProfilerTopFunctionsCount(); i++) {
1066             auto pair = takeMax();
1067             if (pair.first.isEmpty())
1068                 break;
1069             out.printf(&quot;%6zu &quot;, pair.second);
1070             out.print(&quot;   &#39;&quot;, pair.first, &quot;&#39;\n&quot;);
1071         }
1072     }
1073 }
1074 
1075 void SamplingProfiler::reportTopBytecodes()
1076 {
1077     reportTopBytecodes(WTF::dataFile());
1078 }
1079 
1080 void SamplingProfiler::reportTopBytecodes(PrintStream&amp; out)
1081 {
1082     auto locker = holdLock(m_lock);
1083     DeferGCForAWhile deferGC(m_vm.heap);
1084 
1085     {
1086         HeapIterationScope heapIterationScope(m_vm.heap);
1087         processUnverifiedStackTraces(locker);
1088     }
1089 
1090     HashMap&lt;String, size_t&gt; bytecodeCounts;
1091     for (StackTrace&amp; stackTrace : m_stackTraces) {
1092         if (!stackTrace.frames.size())
1093             continue;
1094 
1095         auto descriptionForLocation = [&amp;] (StackFrame::CodeLocation location, Optional&lt;Wasm::CompilationMode&gt; wasmCompilationMode) -&gt; String {
1096             String bytecodeIndex;
1097             String codeBlockHash;
1098             String jitType;
1099             if (location.hasBytecodeIndex())
1100                 bytecodeIndex = toString(location.bytecodeIndex);
1101             else
1102                 bytecodeIndex = &quot;&lt;nil&gt;&quot;;
1103 
1104             if (location.hasCodeBlockHash()) {
1105                 StringPrintStream stream;
1106                 location.codeBlockHash.dump(stream);
1107                 codeBlockHash = stream.toString();
1108             } else
1109                 codeBlockHash = &quot;&lt;nil&gt;&quot;;
1110 
1111             if (wasmCompilationMode)
1112                 jitType = Wasm::makeString(wasmCompilationMode.value());
1113             else
1114                 jitType = JITCode::typeName(location.jitType);
1115 
1116             return makeString(&quot;#&quot;, codeBlockHash, &quot;:&quot;, jitType, &quot;:&quot;, bytecodeIndex);
1117         };
1118 
1119         StackFrame&amp; frame = stackTrace.frames.first();
1120         String frameDescription = makeString(frame.displayName(m_vm), descriptionForLocation(frame.semanticLocation, frame.wasmCompilationMode));
1121         if (Optional&lt;std::pair&lt;StackFrame::CodeLocation, CodeBlock*&gt;&gt; machineLocation = frame.machineLocation) {
1122             frameDescription = makeString(frameDescription, &quot; &lt;-- &quot;,
1123                 machineLocation-&gt;second-&gt;inferredName().data(), descriptionForLocation(machineLocation-&gt;first, WTF::nullopt));
1124         }
1125         bytecodeCounts.add(frameDescription, 0).iterator-&gt;value++;
1126     }
1127 
1128     auto takeMax = [&amp;] () -&gt; std::pair&lt;String, size_t&gt; {
1129         String maxFrameDescription;
1130         size_t maxFrameCount = 0;
1131         for (const auto&amp; entry : bytecodeCounts) {
1132             if (entry.value &gt; maxFrameCount) {
1133                 maxFrameCount = entry.value;
1134                 maxFrameDescription = entry.key;
1135             }
1136         }
1137         if (!maxFrameDescription.isEmpty())
1138             bytecodeCounts.remove(maxFrameDescription);
1139         return std::make_pair(maxFrameDescription, maxFrameCount);
1140     };
1141 
1142     if (Options::samplingProfilerTopBytecodesCount()) {
1143         out.print(&quot;\n\nSampling rate: &quot;, m_timingInterval.microseconds(), &quot; microseconds\n&quot;);
1144         out.print(&quot;Hottest bytecodes as &lt;numSamples   &#39;functionName#hash:JITType:bytecodeIndex&#39;&gt;\n&quot;);
1145         for (size_t i = 0; i &lt; Options::samplingProfilerTopBytecodesCount(); i++) {
1146             auto pair = takeMax();
1147             if (pair.first.isEmpty())
1148                 break;
1149             out.printf(&quot;%6zu &quot;, pair.second);
1150             out.print(&quot;   &#39;&quot;, pair.first, &quot;&#39;\n&quot;);
1151         }
1152     }
1153 }
1154 
1155 #if OS(DARWIN)
1156 mach_port_t SamplingProfiler::machThread()
1157 {
1158     if (!m_thread)
1159         return MACH_PORT_NULL;
1160 
1161     return m_thread-&gt;machThread();
1162 }
1163 #endif
1164 
1165 } // namespace JSC
1166 
1167 namespace WTF {
1168 
1169 using namespace JSC;
1170 
1171 void printInternal(PrintStream&amp; out, SamplingProfiler::FrameType frameType)
1172 {
1173     switch (frameType) {
1174     case SamplingProfiler::FrameType::Executable:
1175         out.print(&quot;Executable&quot;);
1176         break;
1177     case SamplingProfiler::FrameType::Wasm:
1178         out.print(&quot;Wasm&quot;);
1179         break;
1180     case SamplingProfiler::FrameType::Host:
1181         out.print(&quot;Host&quot;);
1182         break;
1183     case SamplingProfiler::FrameType::C:
1184     case SamplingProfiler::FrameType::Unknown:
1185         out.print(&quot;Unknown&quot;);
1186         break;
1187     }
1188 }
1189 
1190 } // namespace WTF
1191 
1192 #endif // ENABLE(SAMPLING_PROFILER)
    </pre>
  </body>
</html>