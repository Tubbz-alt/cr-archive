<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/WebCore/Modules/mediastream/MediaStreamTrack.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2011 Google Inc. All rights reserved.
  3  * Copyright (C) 2011, 2015 Ericsson AB. All rights reserved.
  4  * Copyright (C) 2013-2019 Apple Inc. All rights reserved.
  5  * Copyright (C) 2013 Nokia Corporation and/or its subsidiary(-ies).
  6  *
  7  * Redistribution and use in source and binary forms, with or without
  8  * modification, are permitted provided that the following conditions
  9  * are met:
 10  * 1.  Redistributions of source code must retain the above copyright
 11  *     notice, this list of conditions and the following disclaimer.
 12  * 2.  Redistributions in binary form must reproduce the above copyright
 13  *     notice, this list of conditions and the following disclaimer in the
 14  *     documentation and/or other materials provided with the distribution.
 15  *
 16  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
 17  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 18  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 19  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
 20  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 21  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 22  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 23  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 24  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 25  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 26  */
 27 
 28 #include &quot;config.h&quot;
 29 #include &quot;MediaStreamTrack.h&quot;
 30 
 31 #if ENABLE(MEDIA_STREAM)
 32 
 33 #include &quot;Document.h&quot;
 34 #include &quot;Event.h&quot;
 35 #include &quot;EventNames.h&quot;
 36 #include &quot;Frame.h&quot;
 37 #include &quot;FrameLoader.h&quot;
 38 #include &quot;JSDOMPromiseDeferred.h&quot;
 39 #include &quot;JSOverconstrainedError.h&quot;
 40 #include &quot;Logging.h&quot;
 41 #include &quot;MediaConstraints.h&quot;
 42 #include &quot;MediaStream.h&quot;
 43 #include &quot;MediaStreamPrivate.h&quot;
 44 #include &quot;NetworkingContext.h&quot;
 45 #include &quot;NotImplemented.h&quot;
 46 #include &quot;OverconstrainedError.h&quot;
 47 #include &quot;Page.h&quot;
 48 #include &quot;RealtimeMediaSourceCenter.h&quot;
 49 #include &quot;ScriptExecutionContext.h&quot;
 50 #include &lt;wtf/CompletionHandler.h&gt;
 51 #include &lt;wtf/IsoMallocInlines.h&gt;
 52 #include &lt;wtf/NeverDestroyed.h&gt;
 53 
 54 namespace WebCore {
 55 
 56 static HashSet&lt;MediaStreamTrack*&gt;&amp; allCaptureTracks()
 57 {
 58     static NeverDestroyed&lt;HashSet&lt;MediaStreamTrack*&gt;&gt; captureTracks;
 59     return captureTracks;
 60 }
 61 
 62 static MediaProducer::MediaStateFlags sourceCaptureState(RealtimeMediaSource&amp;);
 63 
 64 WTF_MAKE_ISO_ALLOCATED_IMPL(MediaStreamTrack);
 65 
 66 Ref&lt;MediaStreamTrack&gt; MediaStreamTrack::create(ScriptExecutionContext&amp; context, Ref&lt;MediaStreamTrackPrivate&gt;&amp;&amp; privateTrack)
 67 {
 68     auto track = adoptRef(*new MediaStreamTrack(context, WTFMove(privateTrack)));
 69     track-&gt;suspendIfNeeded();
 70     return track;
 71 }
 72 
 73 MediaStreamTrack::MediaStreamTrack(ScriptExecutionContext&amp; context, Ref&lt;MediaStreamTrackPrivate&gt;&amp;&amp; privateTrack)
 74     : ActiveDOMObject(&amp;context)
 75     , m_private(WTFMove(privateTrack))
 76     , m_isCaptureTrack(m_private-&gt;isCaptureTrack())
 77     , m_mediaSession(PlatformMediaSession::create(*this))
 78 {
 79     ALWAYS_LOG(LOGIDENTIFIER);
 80 
 81     m_private-&gt;addObserver(*this);
 82 
 83     if (!isCaptureTrack())
 84         return;
 85 
 86     allCaptureTracks().add(this);
 87 
 88     if (auto document = this-&gt;document()) {
 89         if (document-&gt;page() &amp;&amp; document-&gt;page()-&gt;mutedState())
 90             setMuted(true);
 91     }
 92 }
 93 
 94 MediaStreamTrack::~MediaStreamTrack()
 95 {
 96     m_private-&gt;removeObserver(*this);
 97 
 98     if (!isCaptureTrack())
 99         return;
100 
101     allCaptureTracks().remove(this);
102 }
103 
104 const AtomString&amp; MediaStreamTrack::kind() const
105 {
106     static NeverDestroyed&lt;AtomString&gt; audioKind(&quot;audio&quot;, AtomString::ConstructFromLiteral);
107     static NeverDestroyed&lt;AtomString&gt; videoKind(&quot;video&quot;, AtomString::ConstructFromLiteral);
108 
109     if (m_private-&gt;type() == RealtimeMediaSource::Type::Audio)
110         return audioKind;
111     return videoKind;
112 }
113 
114 const String&amp; MediaStreamTrack::id() const
115 {
116     return m_private-&gt;id();
117 }
118 
119 const String&amp; MediaStreamTrack::label() const
120 {
121     return m_private-&gt;label();
122 }
123 
124 const AtomString&amp; MediaStreamTrack::contentHint() const
125 {
126     static NeverDestroyed&lt;const AtomString&gt; speechHint(&quot;speech&quot;, AtomString::ConstructFromLiteral);
127     static NeverDestroyed&lt;const AtomString&gt; musicHint(&quot;music&quot;, AtomString::ConstructFromLiteral);
128     static NeverDestroyed&lt;const AtomString&gt; detailHint(&quot;detail&quot;, AtomString::ConstructFromLiteral);
129     static NeverDestroyed&lt;const AtomString&gt; textHint(&quot;text&quot;, AtomString::ConstructFromLiteral);
130     static NeverDestroyed&lt;const AtomString&gt; motionHint(&quot;motion&quot;, AtomString::ConstructFromLiteral);
131 
132     switch (m_private-&gt;contentHint()) {
133     case MediaStreamTrackPrivate::HintValue::Empty:
134         return emptyAtom();
135     case MediaStreamTrackPrivate::HintValue::Speech:
136         return speechHint;
137     case MediaStreamTrackPrivate::HintValue::Music:
138         return musicHint;
139     case MediaStreamTrackPrivate::HintValue::Motion:
140         return motionHint;
141     case MediaStreamTrackPrivate::HintValue::Detail:
142         return detailHint;
143     case MediaStreamTrackPrivate::HintValue::Text:
144         return textHint;
145     default:
146         return emptyAtom();
147     }
148 }
149 
150 void MediaStreamTrack::setContentHint(const String&amp; hintValue)
151 {
152     MediaStreamTrackPrivate::HintValue value;
153     if (m_private-&gt;type() == RealtimeMediaSource::Type::Audio) {
154         if (hintValue == &quot;&quot;)
155             value = MediaStreamTrackPrivate::HintValue::Empty;
156         else if (hintValue == &quot;speech&quot;)
157             value = MediaStreamTrackPrivate::HintValue::Speech;
158         else if (hintValue == &quot;music&quot;)
159             value = MediaStreamTrackPrivate::HintValue::Music;
160         else
161             return;
162     } else {
163         if (hintValue == &quot;&quot;)
164             value = MediaStreamTrackPrivate::HintValue::Empty;
165         else if (hintValue == &quot;detail&quot;)
166             value = MediaStreamTrackPrivate::HintValue::Detail;
167         else if (hintValue == &quot;motion&quot;)
168             value = MediaStreamTrackPrivate::HintValue::Motion;
169         else if (hintValue == &quot;text&quot;)
170             value = MediaStreamTrackPrivate::HintValue::Text;
171         else
172             return;
173     }
174     m_private-&gt;setContentHint(value);
175 }
176 
177 bool MediaStreamTrack::enabled() const
178 {
179     return m_private-&gt;enabled();
180 }
181 
182 void MediaStreamTrack::setEnabled(bool enabled)
183 {
184     m_private-&gt;setEnabled(enabled);
185 }
186 
187 bool MediaStreamTrack::muted() const
188 {
189     return m_private-&gt;muted();
190 }
191 
192 void MediaStreamTrack::setMuted(MediaProducer::MutedStateFlags state)
193 {
194     bool trackMuted = false;
195     switch (source().deviceType()) {
196     case CaptureDevice::DeviceType::Microphone:
197     case CaptureDevice::DeviceType::Camera:
198         trackMuted = state &amp; MediaProducer::AudioAndVideoCaptureIsMuted;
199         break;
200     case CaptureDevice::DeviceType::Screen:
201     case CaptureDevice::DeviceType::Window:
202         trackMuted = state &amp; MediaProducer::ScreenCaptureIsMuted;
203         break;
204     case CaptureDevice::DeviceType::Unknown:
205         ASSERT_NOT_REACHED();
206         break;
207     }
208 
209     m_private-&gt;setMuted(trackMuted);
210 }
211 
212 auto MediaStreamTrack::readyState() const -&gt; State
213 {
214     return ended() ? State::Ended : State::Live;
215 }
216 
217 bool MediaStreamTrack::ended() const
218 {
219     return m_ended || m_private-&gt;ended();
220 }
221 
222 RefPtr&lt;MediaStreamTrack&gt; MediaStreamTrack::clone()
223 {
224     if (!scriptExecutionContext())
225         return nullptr;
226 
227     return MediaStreamTrack::create(*scriptExecutionContext(), m_private-&gt;clone());
228 }
229 
230 void MediaStreamTrack::stopTrack(StopMode mode)
231 {
232     // NOTE: this method is called when the &quot;stop&quot; method is called from JS, using the &quot;ImplementedAs&quot; IDL attribute.
233     // This is done because ActiveDOMObject requires a &quot;stop&quot; method.
234 
235     if (ended())
236         return;
237 
238     // An &#39;ended&#39; event is not posted if m_ended is true when trackEnded is called, so set it now if we are
239     // not supposed to post the event.
240     if (mode == StopMode::Silently)
241         m_ended = true;
242 
243     m_private-&gt;endTrack();
244     m_ended = true;
245 
246     configureTrackRendering();
247 }
248 
249 MediaStreamTrack::TrackSettings MediaStreamTrack::getSettings() const
250 {
251     auto&amp; settings = m_private-&gt;settings();
252     TrackSettings result;
253     if (settings.supportsWidth())
254         result.width = settings.width();
255     if (settings.supportsHeight())
256         result.height = settings.height();
257     if (settings.supportsAspectRatio() &amp;&amp; settings.aspectRatio()) // FIXME: Why the check for zero here?
258         result.aspectRatio = settings.aspectRatio();
259     if (settings.supportsFrameRate())
260         result.frameRate = settings.frameRate();
261     if (settings.supportsFacingMode())
262         result.facingMode = RealtimeMediaSourceSettings::facingMode(settings.facingMode());
263     if (settings.supportsVolume())
264         result.volume = settings.volume();
265     if (settings.supportsSampleRate())
266         result.sampleRate = settings.sampleRate();
267     if (settings.supportsSampleSize())
268         result.sampleSize = settings.sampleSize();
269     if (settings.supportsEchoCancellation())
270         result.echoCancellation = settings.echoCancellation();
271     if (settings.supportsDeviceId())
272         result.deviceId = settings.deviceId();
273     if (settings.supportsGroupId())
274         result.groupId = settings.groupId();
275 
276     // FIXME: shouldn&#39;t this include displaySurface and logicalSurface?
277 
278     return result;
279 }
280 
281 static DoubleRange capabilityDoubleRange(const CapabilityValueOrRange&amp; value)
282 {
283     DoubleRange range;
284     switch (value.type()) {
285     case CapabilityValueOrRange::Double:
286         range.min = value.value().asDouble;
287         range.max = range.min;
288         break;
289     case CapabilityValueOrRange::DoubleRange:
290         range.min = value.rangeMin().asDouble;
291         range.max = value.rangeMax().asDouble;
292         break;
293     case CapabilityValueOrRange::Undefined:
294     case CapabilityValueOrRange::ULong:
295     case CapabilityValueOrRange::ULongRange:
296         ASSERT_NOT_REACHED();
297     }
298     return range;
299 }
300 
301 static LongRange capabilityIntRange(const CapabilityValueOrRange&amp; value)
302 {
303     LongRange range;
304     switch (value.type()) {
305     case CapabilityValueOrRange::ULong:
306         range.min = value.value().asInt;
307         range.max = range.min;
308         break;
309     case CapabilityValueOrRange::ULongRange:
310         range.min = value.rangeMin().asInt;
311         range.max = value.rangeMax().asInt;
312         break;
313     case CapabilityValueOrRange::Undefined:
314     case CapabilityValueOrRange::Double:
315     case CapabilityValueOrRange::DoubleRange:
316         ASSERT_NOT_REACHED();
317     }
318     return range;
319 }
320 
321 static Vector&lt;String&gt; capabilityStringVector(const Vector&lt;RealtimeMediaSourceSettings::VideoFacingMode&gt;&amp; modes)
322 {
323     Vector&lt;String&gt; result;
324     result.reserveInitialCapacity(modes.size());
325     for (auto&amp; mode : modes)
326         result.uncheckedAppend(RealtimeMediaSourceSettings::facingMode(mode));
327     return result;
328 }
329 
330 static Vector&lt;bool&gt; capabilityBooleanVector(RealtimeMediaSourceCapabilities::EchoCancellation cancellation)
331 {
332     Vector&lt;bool&gt; result;
333     result.reserveInitialCapacity(2);
334     result.uncheckedAppend(true);
335     if (cancellation == RealtimeMediaSourceCapabilities::EchoCancellation::ReadWrite)
336         result.uncheckedAppend(false);
337     return result;
338 }
339 
340 MediaStreamTrack::TrackCapabilities MediaStreamTrack::getCapabilities() const
341 {
342     auto capabilities = m_private-&gt;capabilities();
343     TrackCapabilities result;
344     if (capabilities.supportsWidth())
345         result.width = capabilityIntRange(capabilities.width());
346     if (capabilities.supportsHeight())
347         result.height = capabilityIntRange(capabilities.height());
348     if (capabilities.supportsAspectRatio())
349         result.aspectRatio = capabilityDoubleRange(capabilities.aspectRatio());
350     if (capabilities.supportsFrameRate())
351         result.frameRate = capabilityDoubleRange(capabilities.frameRate());
352     if (capabilities.supportsFacingMode())
353         result.facingMode = capabilityStringVector(capabilities.facingMode());
354     if (capabilities.supportsVolume())
355         result.volume = capabilityDoubleRange(capabilities.volume());
356     if (capabilities.supportsSampleRate())
357         result.sampleRate = capabilityIntRange(capabilities.sampleRate());
358     if (capabilities.supportsSampleSize())
359         result.sampleSize = capabilityIntRange(capabilities.sampleSize());
360     if (capabilities.supportsEchoCancellation())
361         result.echoCancellation = capabilityBooleanVector(capabilities.echoCancellation());
362     if (capabilities.supportsDeviceId())
363         result.deviceId = capabilities.deviceId();
364     if (capabilities.supportsGroupId())
365         result.groupId = capabilities.groupId();
366     return result;
367 }
368 
369 static MediaConstraints createMediaConstraints(const Optional&lt;MediaTrackConstraints&gt;&amp; constraints)
370 {
371     if (!constraints) {
372         MediaConstraints validConstraints;
373         validConstraints.isValid = true;
374         return validConstraints;
375     }
376     return createMediaConstraints(constraints.value());
377 }
378 
379 void MediaStreamTrack::applyConstraints(const Optional&lt;MediaTrackConstraints&gt;&amp; constraints, DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
380 {
381     m_promise = WTF::makeUnique&lt;DOMPromiseDeferred&lt;void&gt;&gt;(WTFMove(promise));
382 
383     auto completionHandler = [this, protectedThis = makeRef(*this), constraints](auto&amp;&amp; error) mutable {
384         if (!m_promise)
385             return;
386         if (error) {
387             m_promise-&gt;rejectType&lt;IDLInterface&lt;OverconstrainedError&gt;&gt;(OverconstrainedError::create(WTFMove(error-&gt;badConstraint), WTFMove(error-&gt;message)));
388             return;
389         }
390         m_promise-&gt;resolve();
391         m_constraints = constraints.valueOr(MediaTrackConstraints { });
392     };
393     m_private-&gt;applyConstraints(createMediaConstraints(constraints), WTFMove(completionHandler));
394 }
395 
396 void MediaStreamTrack::addObserver(Observer&amp; observer)
397 {
398     m_observers.append(&amp;observer);
399 }
400 
401 void MediaStreamTrack::removeObserver(Observer&amp; observer)
402 {
403     m_observers.removeFirst(&amp;observer);
404 }
405 
406 MediaProducer::MediaStateFlags MediaStreamTrack::mediaState() const
407 {
408     if (m_ended || !isCaptureTrack())
409         return MediaProducer::IsNotPlaying;
410 
411     auto* document = this-&gt;document();
412     if (!document || !document-&gt;page())
413         return MediaProducer::IsNotPlaying;
414 
415     return sourceCaptureState(source());
416 }
417 
418 MediaProducer::MediaStateFlags sourceCaptureState(RealtimeMediaSource&amp; source)
419 {
420     switch (source.deviceType()) {
421     case CaptureDevice::DeviceType::Microphone:
422         if (source.muted())
423             return MediaProducer::HasMutedAudioCaptureDevice;
424         if (source.interrupted())
425             return MediaProducer::HasInterruptedAudioCaptureDevice;
426         if (source.isProducingData())
427             return MediaProducer::HasActiveAudioCaptureDevice;
428         break;
429     case CaptureDevice::DeviceType::Camera:
430         if (source.muted())
431             return MediaProducer::HasMutedVideoCaptureDevice;
432         if (source.interrupted())
433             return MediaProducer::HasInterruptedVideoCaptureDevice;
434         if (source.isProducingData())
435             return MediaProducer::HasActiveVideoCaptureDevice;
436         break;
437     case CaptureDevice::DeviceType::Screen:
438     case CaptureDevice::DeviceType::Window:
439         if (source.muted())
440             return MediaProducer::HasMutedDisplayCaptureDevice;
441         if (source.interrupted())
442             return MediaProducer::HasInterruptedDisplayCaptureDevice;
443         if (source.isProducingData())
444             return MediaProducer::HasActiveDisplayCaptureDevice;
445         break;
446     case CaptureDevice::DeviceType::Unknown:
447         ASSERT_NOT_REACHED();
448     }
449 
450     return MediaProducer::IsNotPlaying;
451 }
452 
453 MediaProducer::MediaStateFlags MediaStreamTrack::captureState(Document&amp; document)
454 {
455     MediaProducer::MediaStateFlags state = MediaProducer::IsNotPlaying;
456     for (auto* captureTrack : allCaptureTracks()) {
457         if (captureTrack-&gt;document() != &amp;document || captureTrack-&gt;ended())
458             continue;
459         state |= sourceCaptureState(captureTrack-&gt;source());
460     }
461     return state;
462 }
463 
464 void MediaStreamTrack::updateCaptureAccordingToMutedState(Document&amp; document)
465 {
466     for (auto* captureTrack : allCaptureTracks()) {
467         if (captureTrack-&gt;document() != &amp;document || captureTrack-&gt;ended())
468             continue;
469         captureTrack-&gt;setMuted(document.page()-&gt;mutedState());
470     }
471 }
472 
473 void MediaStreamTrack::endCapture(Document&amp; document)
474 {
475     bool didEndCapture = false;
476     for (auto* captureTrack : allCaptureTracks()) {
477         if (captureTrack-&gt;document() != &amp;document)
478             continue;
479         captureTrack-&gt;stopTrack(MediaStreamTrack::StopMode::PostEvent);
480         didEndCapture = true;
481     }
482     if (didEndCapture)
483         document.updateIsPlayingMedia();
484 }
485 
486 void MediaStreamTrack::trackStarted(MediaStreamTrackPrivate&amp;)
487 {
488     configureTrackRendering();
489 }
490 
491 void MediaStreamTrack::trackEnded(MediaStreamTrackPrivate&amp;)
492 {
493     // http://w3c.github.io/mediacapture-main/#life-cycle
494     // When a MediaStreamTrack track ends for any reason other than the stop() method being invoked, the User Agent must queue a task that runs the following steps:
495     // 1. If the track&#39;s readyState attribute has the value ended already, then abort these steps.
496     if (m_ended)
497         return;
498 
499     // 2. Set track&#39;s readyState attribute to ended.
500     m_ended = true;
501 
502     if (scriptExecutionContext()-&gt;activeDOMObjectsAreSuspended() || scriptExecutionContext()-&gt;activeDOMObjectsAreStopped())
503         return;
504 
505     // 3. Notify track&#39;s source that track is ended so that the source may be stopped, unless other MediaStreamTrack objects depend on it.
506     // 4. Fire a simple event named ended at the object.
507     dispatchEvent(Event::create(eventNames().endedEvent, Event::CanBubble::No, Event::IsCancelable::No));
508 
509     for (auto&amp; observer : m_observers)
510         observer-&gt;trackDidEnd();
511 
512     configureTrackRendering();
513 }
514 
515 void MediaStreamTrack::trackMutedChanged(MediaStreamTrackPrivate&amp;)
516 {
517     if (scriptExecutionContext()-&gt;activeDOMObjectsAreStopped() || m_ended)
518         return;
519 
520     AtomString eventType = muted() ? eventNames().muteEvent : eventNames().unmuteEvent;
521     queueTaskToDispatchEvent(*this, TaskSource::Networking, Event::create(eventType, Event::CanBubble::No, Event::IsCancelable::No));
522 
523     configureTrackRendering();
524 }
525 
526 void MediaStreamTrack::trackSettingsChanged(MediaStreamTrackPrivate&amp;)
527 {
528     configureTrackRendering();
529 }
530 
531 void MediaStreamTrack::trackEnabledChanged(MediaStreamTrackPrivate&amp;)
532 {
533     configureTrackRendering();
534 }
535 
536 void MediaStreamTrack::configureTrackRendering()
537 {
538     if (m_mediaSession &amp;&amp; m_private-&gt;type() == RealtimeMediaSource::Type::Audio)
539         m_mediaSession-&gt;canProduceAudioChanged();
540 
541     if (auto document = this-&gt;document())
542         document-&gt;updateIsPlayingMedia();
543 
544     // 4.3.1
545     // ... media from the source only flows when a MediaStreamTrack object is both unmuted and enabled
546 }
547 
548 const char* MediaStreamTrack::activeDOMObjectName() const
549 {
550     return &quot;MediaStreamTrack&quot;;
551 }
552 
553 void MediaStreamTrack::suspend(ReasonForSuspension reason)
554 {
555     if (reason != ReasonForSuspension::BackForwardCache)
556         return;
557 
558     // We only end capture tracks, other tracks (capture canvas, remote tracks) can still continue working.
559     if (m_ended || !isCaptureTrack())
560         return;
561 
562     stopTrack();
563 
564     queueTaskToDispatchEvent(*this, TaskSource::Networking, Event::create(eventNames().endedEvent, Event::CanBubble::No, Event::IsCancelable::No));
565 }
566 
567 bool MediaStreamTrack::hasPendingActivity() const
568 {
569     return !m_ended || ActiveDOMObject::hasPendingActivity();
570 }
571 
572 AudioSourceProvider* MediaStreamTrack::audioSourceProvider()
573 {
574     return m_private-&gt;audioSourceProvider();
575 }
576 
577 Document* MediaStreamTrack::document() const
578 {
579     return downcast&lt;Document&gt;(scriptExecutionContext());
580 }
581 
582 PlatformMediaSession::MediaType MediaStreamTrack::mediaType() const
583 {
584     return (isCaptureTrack() &amp;&amp; canProduceAudio()) ? PlatformMediaSession::MediaStreamCapturingAudio : PlatformMediaSession::None;
585 }
586 
587 PlatformMediaSession::MediaType MediaStreamTrack::presentationType() const
588 {
589     return mediaType();
590 }
591 
592 PlatformMediaSession::CharacteristicsFlags MediaStreamTrack::characteristics() const
593 {
594     if (!m_private-&gt;isActive())
595         return PlatformMediaSession::HasNothing;
596 
597     return m_private-&gt;type() == RealtimeMediaSource::Type::Audio ? PlatformMediaSession::HasAudio : PlatformMediaSession::HasVideo;
598 }
599 
600 void MediaStreamTrack::mayResumePlayback(bool)
601 {
602     // FIXME: should a media stream track pay attention to this directly, or only when attached to a media element?
603 }
604 
605 void MediaStreamTrack::suspendPlayback()
606 {
607     // FIXME: should a media stream track pay attention to this directly, or only when attached to a media element?
608 }
609 
610 String MediaStreamTrack::sourceApplicationIdentifier() const
611 {
612     auto* document = this-&gt;document();
613     if (document &amp;&amp; document-&gt;frame()) {
614         if (auto* networkingContext = document-&gt;frame()-&gt;loader().networkingContext())
615             return networkingContext-&gt;sourceApplicationIdentifier();
616     }
617 
618     return emptyString();
619 }
620 
621 bool MediaStreamTrack::canProduceAudio() const
622 {
623     return m_private-&gt;type() == RealtimeMediaSource::Type::Audio &amp;&amp; !ended() &amp;&amp; !muted();
624 }
625 
626 bool MediaStreamTrack::processingUserGestureForMedia() const
627 {
628     return document() ? document()-&gt;processingUserGestureForMedia() : false;
629 }
630 
631 #if !RELEASE_LOG_DISABLED
632 WTFLogChannel&amp; MediaStreamTrack::logChannel() const
633 {
634     return LogWebRTC;
635 }
636 #endif
637 
638 } // namespace WebCore
639 
640 #endif // ENABLE(MEDIA_STREAM)
    </pre>
  </body>
</html>