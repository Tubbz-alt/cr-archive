<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.media/src/main/native/jfxmedia/platform/gstreamer/GstAudioPlaybackPipeline.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 2010, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.  Oracle designates this
   8  * particular file as subject to the &quot;Classpath&quot; exception as provided
   9  * by Oracle in the LICENSE file that accompanied this code.
  10  *
  11  * This code is distributed in the hope that it will be useful, but WITHOUT
  12  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  13  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  14  * version 2 for more details (a copy is included in the LICENSE file that
  15  * accompanied this code).
  16  *
  17  * You should have received a copy of the GNU General Public License version
  18  * 2 along with this work; if not, write to the Free Software Foundation,
  19  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  20  *
  21  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  22  * or visit www.oracle.com if you need additional information or have any
  23  * questions.
  24  */
  25 
  26 #include &quot;GstAudioPlaybackPipeline.h&quot;
  27 #include &quot;GstMediaManager.h&quot;
  28 #include &lt;MediaManagement/MediaTypes.h&gt;
  29 #include &lt;PipelineManagement/AudioTrack.h&gt;
  30 #include &lt;PipelineManagement/PlayerEventDispatcher.h&gt;
  31 #include &lt;MediaManagement/Media.h&gt;
  32 #include &lt;Common/VSMemory.h&gt;
  33 #include &lt;Utils/LowLevelPerf.h&gt;
  34 
  35 #define AUDIO_RESUME_DELTA_TIME   10.0 // seconds
  36 #define VIDEO_RESUME_DELTA_TIME   10.0 // seconds
  37 #define STALL_DELTA_TIME           1.0 // seconds
  38 
  39 //*************************************************************************************************
  40 //********** class CGstAudioPlaybackPipeline
  41 //*************************************************************************************************
  42 
  43 /**
  44  * CGstAudioPlaybackPipeline::CGstAudioPlaybackPipeline()
  45  *
  46  * Constructor
  47  *
  48  * @param   elements    GStreamer container of elements
  49  */
  50 CGstAudioPlaybackPipeline::CGstAudioPlaybackPipeline(const GstElementContainer&amp; elements, int flags, CPipelineOptions* pOptions)
  51 :   CPipeline(pOptions),
  52     m_Elements(elements),
  53     m_pAudioEqualizer(NULL),
  54     m_pAudioSpectrum(NULL),
  55     m_AudioFlags(flags)
  56 {
  57     m_dResumeDeltaTime = m_Elements[VIDEO_SINK] ? VIDEO_RESUME_DELTA_TIME : AUDIO_RESUME_DELTA_TIME;
  58 
  59     m_bSeekInvoked = false;
  60     m_fRate = 1.0F;
  61     m_audioSourcePadProbeHID = 0L;
  62     m_ulLastStreamTime = (GstClockTime)0UL;
  63     m_pBusSource = NULL;
  64     m_bIgnoreError = FALSE;
  65 
  66     m_StallLock = CJfxCriticalSection::Create();
  67     m_BufferPosition = 0.0;
  68     m_bHLSPBFull = false;
  69     m_StallOnPause = false;
  70 
  71     m_SeekLock = CJfxCriticalSection::Create();
  72     m_LastSeekTime = -1;
  73 
  74     m_dLastReportedDuration = DURATION_UNKNOWN;
  75 
  76     m_bSetClock = false;
  77     m_bIsClockSet = false;
  78 
  79     m_StateLock = CJfxCriticalSection::Create();
  80 
  81 #if ENABLE_PROGRESS_BUFFER
  82     m_llLastProgressValueStart = 0;
  83     m_llLastProgressValuePosition = 0;
  84     m_llLastProgressValueStop = 0;
  85     m_bLastProgressValueEOS = 0;
  86 #endif // ENABLE_PROGRESS_BUFFER
  87 
  88     m_audioCodecErrorCode = ERROR_NONE;
  89 
  90     m_pBusCallbackContent = NULL;
  91 }
  92 
  93 /**
  94  * CGstAudioPlaybackPipeline::~CGstAudioPlaybackPipeline()
  95  *
  96  * Destructor
  97  */
  98 CGstAudioPlaybackPipeline::~CGstAudioPlaybackPipeline()
  99 {
 100 #if JFXMEDIA_DEBUG
 101     g_print (&quot;CGstAudioPlaybackPipeline::~CGstAudioPlaybackPipeline()\n&quot;);
 102 #endif
 103     delete m_SeekLock;
 104     delete m_StateLock;
 105     delete m_StallLock;
 106 }
 107 
 108 /**
 109  * CGstAudioPlaybackPipeline::Init()
 110  *
 111  * Init an audio-only playback pipeline.  Called by JNI layer.
 112  */
 113 uint32_t CGstAudioPlaybackPipeline::Init()
 114 {
 115     bool bStaticDecoderBin = false;
 116 
 117     m_pAudioEqualizer = new (nothrow) CGstAudioEqualizer(m_Elements[AUDIO_EQUALIZER]);
 118     if (m_pAudioEqualizer == NULL)
 119         return ERROR_MEMORY_ALLOCATION;
 120 
 121     m_pAudioSpectrum = new (nothrow) CGstAudioSpectrum(m_Elements[AUDIO_SPECTRUM], false);
 122     if (m_pAudioSpectrum == NULL)
 123         return ERROR_MEMORY_ALLOCATION;
 124 
 125     if (m_pOptions-&gt;GetBufferingEnabled())
 126         m_bStaticPipeline = false; // Pipeline is dynamic if we have progress buffer
 127 
 128     CMediaManager *pManager = NULL;
 129     uint32_t ret = CMediaManager::GetInstance(&amp;pManager);
 130     if (ret != ERROR_NONE)
 131         return ret;
 132 
 133     m_pBusCallbackContent = new (nothrow) sBusCallbackContent;
 134     if (m_pBusCallbackContent == NULL)
 135         return ERROR_MEMORY_ALLOCATION;
 136 
 137     m_pBusCallbackContent-&gt;m_pPipeline = this;
 138     m_pBusCallbackContent-&gt;m_DisposeLock = CJfxCriticalSection::Create();
 139     m_pBusCallbackContent-&gt;m_bIsDisposed = false;
 140     m_pBusCallbackContent-&gt;m_bIsDisposeInProgress = false;
 141     m_pBusCallbackContent-&gt;m_bFreeMe = false;
 142 
 143     GstBus *pBus = gst_pipeline_get_bus (GST_PIPELINE (m_Elements[PIPELINE]));
 144     m_pBusSource = gst_bus_create_watch(pBus);
 145     if (m_pBusSource == NULL)
 146         return ERROR_MEMORY_ALLOCATION;
 147 
 148     g_source_set_callback(m_pBusSource, (GSourceFunc)BusCallback, m_pBusCallbackContent, (GDestroyNotify)BusCallbackDestroyNotify);
 149 
 150     ret = g_source_attach(m_pBusSource, ((CGstMediaManager*)pManager)-&gt;m_pMainContext);
 151     gst_object_unref (pBus);
 152 
 153     if (ret == 0)
 154     {
 155         delete m_pBusCallbackContent;
 156         return ERROR_GSTREAMER_BUS_SOURCE_ATTACH;
 157     }
 158 
 159     ((CGstMediaManager*)pManager)-&gt;StartMainLoop();
 160 
 161     // Check if we have static pipeline
 162 #if TARGET_OS_LINUX | TARGET_OS_MAC | TARGET_OS_WIN32
 163     if (m_Elements[AV_DEMUXER] == NULL)
 164         bStaticDecoderBin = true;
 165 #else // TARGET_OS_LINUX | TARGET_OS_MAC | TARGET_OS_WIN32
 166     if (m_Elements[AUDIO_PARSER] == NULL &amp;&amp; m_Elements[AV_DEMUXER] == NULL)
 167         bStaticDecoderBin = true;
 168 #endif // TARGET_OS_LINUX | TARGET_OS_MAC | TARGET_OS_WIN32
 169 
 170     if (bStaticDecoderBin)
 171     {
 172         m_bHasAudio = true;
 173         PostBuildInit();
 174     }
 175     else
 176     {
 177         if (m_Elements[AUDIO_PARSER]) // Add method to link parser to decoder.
 178             g_signal_connect (m_Elements[AUDIO_PARSER], &quot;pad-added&quot;, G_CALLBACK (OnParserSrcPadAdded), this);
 179     }
 180 
 181     // Switch the state
 182     if (GST_STATE_CHANGE_FAILURE == gst_element_set_state (m_Elements[PIPELINE], GST_STATE_PAUSED))
 183         return ERROR_GSTREAMER_PIPELINE_STATE_CHANGE;
 184 
 185     return ERROR_NONE;
 186 }
 187 
 188 uint32_t CGstAudioPlaybackPipeline::PostBuildInit()
 189 {
 190     if (m_bHasAudio &amp;&amp; !m_bAudioInitDone)
 191     {
 192         if (m_Elements[AUDIO_PARSER])
 193         {
 194             GstPad *pPad = gst_element_get_static_pad(m_Elements[AUDIO_PARSER], &quot;src&quot;);
 195             if (NULL == pPad)
 196                 return ERROR_GSTREAMER_ELEMENT_GET_PAD;
 197             m_audioSourcePadProbeHID = gst_pad_add_probe(pPad, GST_PAD_PROBE_TYPE_BUFFER, (GstPadProbeCallback)AudioSourcePadProbe, this, NULL);
 198             gst_object_unref(pPad);
 199         }
 200         else if (m_Elements[AUDIO_DECODER])
 201         {
 202             if (m_AudioFlags &amp; AUDIO_DECODER_HAS_SINK_PROBE) // Add a buffer probe on the sink pad of the decoder
 203             {
 204                 GstPad *pPad = gst_element_get_static_pad(m_Elements[AUDIO_DECODER], &quot;sink&quot;);
 205                 if (NULL == pPad)
 206                     return ERROR_GSTREAMER_AUDIO_DECODER_SINK_PAD;
 207                 m_audioSinkPadProbeHID = gst_pad_add_probe(pPad, GST_PAD_PROBE_TYPE_BUFFER, (GstPadProbeCallback)AudioSinkPadProbe, this, NULL);
 208                 gst_object_unref(pPad);
 209             }
 210 
 211             if (m_AudioFlags &amp; AUDIO_DECODER_HAS_SOURCE_PROBE) // Add a buffer probe on the source pad of the decoder
 212             {
 213                 GstPad *pPad = gst_element_get_static_pad(m_Elements[AUDIO_DECODER], &quot;src&quot;);
 214                 if (NULL == pPad)
 215                     return ERROR_GSTREAMER_AUDIO_DECODER_SRC_PAD;
 216                 m_audioSourcePadProbeHID = gst_pad_add_probe(pPad, GST_PAD_PROBE_TYPE_BUFFER, (GstPadProbeCallback)AudioSourcePadProbe, this, NULL);
 217                 gst_object_unref(pPad);
 218             }
 219         }
 220 
 221         m_bAudioInitDone = true;
 222     }
 223 
 224     return ERROR_NONE;
 225 }
 226 
 227 /**
 228  * CGstAudioPlaybackPipeline::OnParserSrcPadAdded()
 229  *
 230  * Links the parser source pad to the decoder sink pad and adds a buffer probe to
 231  * the parser source pad.
 232  *
 233  * @param element   The audio parser element.
 234  * @param pad       The audio parser source pad.
 235  * @param pPipeline A pointer to the audio pipeline.
 236  */
 237 void CGstAudioPlaybackPipeline::OnParserSrcPadAdded(GstElement *element, GstPad *pad,
 238                                                     CGstAudioPlaybackPipeline* pPipeline)
 239 {
 240     pPipeline-&gt;m_pBusCallbackContent-&gt;m_DisposeLock-&gt;Enter();
 241 
 242     if (pPipeline-&gt;m_pBusCallbackContent-&gt;m_bIsDisposeInProgress)
 243     {
 244         pPipeline-&gt;m_pBusCallbackContent-&gt;m_DisposeLock-&gt;Exit();
 245         return;
 246     }
 247 
 248     GstCaps *pCaps = gst_pad_get_current_caps(pad);
 249 
 250     if (pPipeline-&gt;IsCodecSupported(pCaps))
 251     {
 252         if (!gst_bin_add (GST_BIN (pPipeline-&gt;m_Elements[PIPELINE]), pPipeline-&gt;m_Elements[AUDIO_BIN]))
 253         {
 254             GTimeVal now;
 255             g_get_current_time (&amp;now);
 256 
 257             if (NULL != pPipeline-&gt;m_pEventDispatcher)
 258             {
 259                 if (!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerHaltEvent (&quot;Failed to add audio bin to pipeline!&quot;, (double)GST_TIMEVAL_TO_TIME (now)))
 260                 {
 261                     if(!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_JNI_SEND_PLAYER_HALT_EVENT))
 262                     {
 263                         LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
 264                     }
 265                 }
 266             }
 267         }
 268 
 269         gst_element_set_state(pPipeline-&gt;m_Elements[AUDIO_BIN], GST_STATE_READY);
 270 
 271         // Get the audio decoder sink pad.
 272         GstPad *peerPad = gst_element_get_static_pad(pPipeline-&gt;m_Elements[AUDIO_BIN], &quot;sink&quot;);
 273         if (NULL == peerPad)
 274         {
 275             GTimeVal now;
 276             g_get_current_time (&amp;now);
 277 
 278             if (NULL != pPipeline-&gt;m_pEventDispatcher)
 279             {
 280                 if (!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerHaltEvent (&quot;Failed to retrieve audio bin sink pad!&quot;, (double)GST_TIMEVAL_TO_TIME (now)))
 281                 {
 282                     if(!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_JNI_SEND_PLAYER_HALT_EVENT))
 283                     {
 284                         LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
 285                     }
 286                 }
 287             }
 288         }
 289 
 290         // Link the audio parser src pad to the audio decode sink pad.
 291         if (GST_PAD_LINK_OK != gst_pad_link (pad, peerPad))
 292         {
 293             GTimeVal now;
 294             g_get_current_time (&amp;now);
 295 
 296             if (NULL != pPipeline-&gt;m_pEventDispatcher)
 297             {
 298                 if (!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerHaltEvent (&quot;Failed to link audio parser with audio bin!\n&quot;, (double)GST_TIMEVAL_TO_TIME (now)))
 299                 {
 300                     if(!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_JNI_SEND_PLAYER_HALT_EVENT))
 301                     {
 302                         LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
 303                     }
 304                 }
 305             }
 306         }
 307 
 308         if (peerPad != NULL)
 309         {
 310             gst_object_unref(peerPad);
 311             peerPad = NULL;
 312         }
 313 
 314         pPipeline-&gt;m_bHasAudio = true;
 315         pPipeline-&gt;PostBuildInit();
 316 
 317         if (!gst_element_sync_state_with_parent(pPipeline-&gt;m_Elements[AUDIO_BIN]))
 318         {
 319             GTimeVal now;
 320             g_get_current_time (&amp;now);
 321 
 322             if (NULL != pPipeline-&gt;m_pEventDispatcher)
 323             {
 324                 if (!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerHaltEvent (&quot;Failed to start audio bin!\n&quot;, (double)GST_TIMEVAL_TO_TIME (now)))
 325                 {
 326                     if(!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_JNI_SEND_PLAYER_HALT_EVENT))
 327                     {
 328                         LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
 329                     }
 330                 }
 331             }
 332         }
 333     }
 334 
 335     if (pCaps != NULL)
 336         gst_caps_unref(pCaps);
 337 
 338     // Disconnect this method from the &quot;pad-added&quot; signal of the audio parser.
 339     g_signal_handlers_disconnect_by_func(element, (void*)OnParserSrcPadAdded, pPipeline);
 340 
 341     pPipeline-&gt;CheckCodecSupport();
 342 
 343     pPipeline-&gt;m_pBusCallbackContent-&gt;m_DisposeLock-&gt;Exit();
 344 }
 345 
 346 /**
 347  * CGstAudioPlaybackPipeline::Dispose()
 348  *
 349  * Disposes of resources held by this object. The pipeline should not be used
 350  * once this method has been invoked.
 351  */
 352 void CGstAudioPlaybackPipeline::Dispose()
 353 {
 354 #if JFXMEDIA_DEBUG
 355     g_print (&quot;CGstAudioPlaybackPipeline::Dispose()\n&quot;);
 356 #endif
 357 
 358     if (m_pBusCallbackContent != NULL)
 359     {
 360         m_pBusCallbackContent-&gt;m_DisposeLock-&gt;Enter();
 361         m_pBusCallbackContent-&gt;m_bIsDisposeInProgress = true;
 362         m_pBusCallbackContent-&gt;m_DisposeLock-&gt;Exit();
 363     }
 364 
 365     // Stop pipeline before lock, so all callbacks from pipeline are finished.
 366     if (m_Elements[PIPELINE])
 367     {
 368         gst_element_set_state (m_Elements[PIPELINE], GST_STATE_NULL); // Ignore return value.
 369     }
 370 
 371     if (m_pBusCallbackContent != NULL)
 372     {
 373         m_pBusCallbackContent-&gt;m_DisposeLock-&gt;Enter();
 374 
 375         if (m_pBusCallbackContent-&gt;m_bIsDisposed)
 376         {
 377             m_pBusCallbackContent-&gt;m_DisposeLock-&gt;Exit();
 378             return;
 379         }
 380     }
 381 
 382     if (m_pAudioEqualizer != NULL)
 383     {
 384         delete m_pAudioEqualizer;
 385         m_pAudioEqualizer = NULL;
 386     }
 387 
 388     if (m_pAudioSpectrum != NULL)
 389     {
 390         delete m_pAudioSpectrum;
 391         m_pAudioSpectrum = NULL;
 392     }
 393 
 394     // Destroy the pipeline. This should be done after any other cleanup to
 395     // avert any unexpected contention.
 396     if (m_Elements[PIPELINE])
 397     {
 398         if (m_pBusSource)
 399         {
 400             g_source_destroy(m_pBusSource);
 401             g_source_unref(m_pBusSource);
 402             m_pBusSource = NULL;
 403         }
 404 
 405         gst_object_unref (m_Elements[PIPELINE]);
 406     }
 407 
 408     if (m_pBusCallbackContent != NULL)
 409     {
 410         bool bFreeBusCallbackContent = m_pBusCallbackContent-&gt;m_bFreeMe;
 411 
 412         m_pBusCallbackContent-&gt;m_bIsDisposed = true;
 413 
 414         m_pBusCallbackContent-&gt;m_DisposeLock-&gt;Exit();
 415 
 416         if (bFreeBusCallbackContent)
 417         {
 418             delete m_pBusCallbackContent-&gt;m_DisposeLock;
 419             delete m_pBusCallbackContent;
 420         }
 421     }
 422 }
 423 
 424 /**
 425  * CGstAudioPlaybackPipeline::Play()
 426  *
 427  * Starts the playback of the media.
 428  */
 429 uint32_t CGstAudioPlaybackPipeline::Play()
 430 {
 431     LOWLEVELPERF_EXECTIMESTART(&quot;GST_STATE_PLAYING&quot;);
 432 
 433     m_StateLock-&gt;Enter();
 434     bool ready = (Finished != m_PlayerState &amp;&amp; Error != m_PlayerState &amp;&amp; Playing != m_PlayerState);
 435     if (!ready &amp;&amp; Playing == m_PlayerState) // Re-check if we ready with pipeline
 436     {
 437         GstState state = GST_STATE_NULL;
 438         GstState pending = GST_STATE_VOID_PENDING;
 439         if (gst_element_get_state(m_Elements[PIPELINE], &amp;state, &amp;pending, 0) != GST_STATE_CHANGE_FAILURE)
 440         {
 441             if (state == GST_STATE_PAUSED || pending == GST_STATE_PAUSED)
 442                 ready = true;
 443         }
 444     }
 445     m_StateLock-&gt;Exit();
 446 
 447     uint32_t ret = ERROR_NONE;
 448     if (ready)
 449     {
 450         if (0.0F == m_fRate)
 451             // Set playback resumption flag regardless of whether state change succeeds.
 452             m_bResumePlayOnNonzeroRate = true;
 453         else if (GST_STATE_CHANGE_FAILURE == gst_element_set_state(m_Elements[PIPELINE], GST_STATE_PLAYING))
 454                ret = ERROR_GSTREAMER_PIPELINE_STATE_CHANGE;
 455     }
 456 
 457     return ret;
 458 }
 459 
 460 /**
 461  * CGstAudioPlaybackPipeline::Stop()
 462  *
 463  * Stops the playback of the media. It will not reset stream position.
 464  */
 465 uint32_t CGstAudioPlaybackPipeline::Stop()
 466 {
 467     if (IsPlayerState(Stopped) || IsPlayerState(Error))
 468         return ERROR_NONE;
 469 
 470     if (0.0F == m_fRate)
 471         // Unset playback resumption flag regardless of whether state change succeeds.
 472         m_bResumePlayOnNonzeroRate = false;
 473     else
 474     {
 475         // Pause playback and seek to beginning of media.
 476         m_StateLock-&gt;Enter();
 477         m_PlayerPendingState = Stopped;
 478         m_StateLock-&gt;Exit();
 479 
 480         uint32_t uErrCode = InternalPause();
 481         if (ERROR_NONE != uErrCode)
 482         {
 483             m_StateLock-&gt;Enter();
 484             m_PlayerPendingState = Unknown;
 485             m_StateLock-&gt;Exit();
 486             return uErrCode;
 487         }
 488     }
 489 
 490     return ERROR_NONE;
 491 }
 492 
 493 /**
 494  * CGstAudioPlaybackPipeline::Finish()
 495  *
 496  * Finishs the playback of the media.
 497  */
 498 uint32_t CGstAudioPlaybackPipeline::Finish()
 499 {
 500     uint32_t ret = ERROR_NONE;
 501 
 502     if (IsPlayerState(Finished) || IsPlayerState(Error) || !IsPlayerState(Playing))
 503         return ERROR_NONE;
 504 
 505     ret = InternalPause();
 506 
 507     return ret;
 508 }
 509 
 510 /**
 511  * CGstAudioPlaybackPipeline::Pause()
 512  *
 513  * Pause the playback of the media
 514  */
 515 uint32_t CGstAudioPlaybackPipeline::Pause()
 516 {
 517     uint32_t ret = ERROR_NONE;
 518 
 519     if (IsPlayerState(Paused) || IsPlayerState(Error))
 520         return ERROR_NONE;
 521 
 522     // Check if we really need to pause
 523     m_StateLock-&gt;Enter();
 524     if (Stopped == m_PlayerState || Stalled == m_PlayerState)
 525     {
 526         SetPlayerState(Paused, false);
 527         m_StateLock-&gt;Exit();
 528         return ERROR_NONE;
 529     }
 530     m_PlayerPendingState = Paused;
 531     m_StateLock-&gt;Exit();
 532 
 533     ret = InternalPause();
 534     if (ret != ERROR_NONE)
 535     {
 536         m_StateLock-&gt;Enter();
 537         m_PlayerPendingState = Unknown;
 538         m_StateLock-&gt;Exit();
 539     }
 540 
 541     return ret;
 542 }
 543 
 544 uint32_t CGstAudioPlaybackPipeline::InternalPause()
 545 {
 546     LOWLEVELPERF_EXECTIMESTART(&quot;GST_STATE_PAUSED&quot;);
 547 
 548     m_StateLock-&gt;Enter();
 549     bool ready = (((Finished != m_PlayerState || m_bSeekInvoked) || m_PlayerPendingState == Stopped) &amp;&amp; Error != m_PlayerState);
 550     m_bSeekInvoked = false;
 551     m_StateLock-&gt;Exit();
 552 
 553     uint32_t ret = ERROR_NONE;
 554     // We need to pause if it goes from stop, even if we in Finished state
 555     if (ready)
 556     {
 557         if (0.0F == m_fRate)
 558             // Unset playback resumption flag regardless of whether state change succeeds.
 559             m_bResumePlayOnNonzeroRate = false;
 560         else if (GST_STATE_CHANGE_FAILURE == gst_element_set_state(m_Elements[PIPELINE], GST_STATE_PAUSED))
 561                ret = ERROR_GSTREAMER_PIPELINE_STATE_CHANGE;
 562         else
 563             CheckQueueSize(NULL);
 564     }
 565 
 566     return ret;
 567 }
 568 
 569 uint32_t CGstAudioPlaybackPipeline::SeekPipeline(gint64 seek_time)
 570 {
 571     GstSeekFlags seekFlags;
 572 
 573     m_SeekLock-&gt;Enter();
 574 
 575     m_LastSeekTime = seek_time;
 576 
 577     if (m_fRate &lt; -1.0F || m_fRate &gt; 1.0F)
 578         seekFlags = (GstSeekFlags)(GST_SEEK_FLAG_FLUSH | GST_SEEK_FLAG_SKIP);
 579     else
 580         seekFlags = (GstSeekFlags)(GST_SEEK_FLAG_FLUSH);// | GST_SEEK_FLAG_KEY_UNIT);
 581 
 582     if (m_Elements[AUDIO_SINK] != NULL &amp;&amp; m_bHasAudio &amp;&amp; gst_element_seek(m_Elements[AUDIO_SINK], m_fRate, GST_FORMAT_TIME, seekFlags,
 583         GST_SEEK_TYPE_SET, seek_time,
 584         GST_SEEK_TYPE_NONE, GST_CLOCK_TIME_NONE))
 585     {
 586         m_SeekLock-&gt;Exit();
 587         CheckQueueSize(NULL);
 588         return ERROR_NONE;
 589     }
 590     else if (m_Elements[VIDEO_SINK] != NULL &amp;&amp; m_bHasVideo &amp;&amp; gst_element_seek(m_Elements[VIDEO_SINK], m_fRate, GST_FORMAT_TIME, seekFlags,
 591         GST_SEEK_TYPE_SET, seek_time,
 592         GST_SEEK_TYPE_NONE, GST_CLOCK_TIME_NONE))
 593     {
 594         m_SeekLock-&gt;Exit();
 595         CheckQueueSize(NULL);
 596         return ERROR_NONE;
 597     }
 598 
 599     m_SeekLock-&gt;Exit();
 600 
 601     return ERROR_GSTREAMER_PIPELINE_SEEK;
 602 }
 603 
 604 /**
 605  * CGstAudioPlaybackPipeline::Seek()
 606  *
 607  * Seek to a presentation time.
 608  */
 609 uint32_t CGstAudioPlaybackPipeline::Seek(double dSeekTime)
 610 {
 611     uint32_t ret = ERROR_NONE;
 612 
 613     m_StateLock-&gt;Enter();
 614     bool notReady = (m_PlayerState != Ready &amp;&amp;
 615                      m_PlayerState != Playing &amp;&amp;
 616                      m_PlayerState != Paused &amp;&amp;
 617                      m_PlayerState != Stopped &amp;&amp;
 618                      m_PlayerState != Stalled &amp;&amp;
 619                      m_PlayerState != Finished);
 620 
 621     if (m_PlayerState == Finished)
 622         m_bSeekInvoked = true;
 623     m_StateLock-&gt;Exit();
 624 
 625     // We should only perform seek in Playing, Paused, Stopped, Stalled or Finished states
 626     if (notReady)
 627         return ERROR_NONE;
 628 
 629     ret = SeekPipeline((gint64)(GST_SECOND * dSeekTime));
 630 
 631     // Check if we need to resume pipeline
 632     m_StateLock-&gt;Enter();
 633     bool resume = (ret == ERROR_NONE &amp;&amp; m_PlayerState == Finished &amp;&amp; m_PlayerPendingState != Stopped);
 634     m_StateLock-&gt;Exit();
 635 
 636     if (resume)
 637     {
 638         if (GST_STATE_CHANGE_FAILURE == gst_element_set_state(m_Elements[PIPELINE], GST_STATE_PLAYING))
 639             ret = ERROR_GSTREAMER_PIPELINE_STATE_CHANGE;
 640     }
 641 
 642     return ret;
 643 }
 644 
 645 /**
 646  * CGstAudioPlaybackPipeline::GetDuration()
 647  *
 648  * Get the time duration of the media clip.
 649  *
 650  * @return  double representing time
 651  */
 652 uint32_t CGstAudioPlaybackPipeline::GetDuration(double* dDuration)
 653 {
 654     gint64    duration = GST_CLOCK_TIME_NONE;
 655 
 656     if (IsPlayerState(Error) || !gst_element_query_duration(m_Elements[PIPELINE], GST_FORMAT_TIME, &amp;duration))
 657     {
 658         *dDuration = -1.0;
 659         return ERROR_GSTREAMER_PIPELINE_QUERY_LENGTH;
 660     }
 661 
 662     if (duration &lt; 0)
 663         *dDuration = -1.0;
 664     else
 665         *dDuration = (double)duration/(double)GST_SECOND;
 666 
 667     m_dLastReportedDuration = *dDuration;
 668 
 669     return ERROR_NONE;
 670 }
 671 
 672 /**
 673  * CGstAudioPlaybackPipeline::GetStreamTime()
 674  *
 675  * Get the stream/presentation time of the media clip.
 676  *
 677  * @return  true/false
 678  */
 679 uint32_t CGstAudioPlaybackPipeline::GetStreamTime(double* streamTime)
 680 {
 681     gint64    position = GST_CLOCK_TIME_NONE;
 682 
 683 #if JFXMEDIA_ENABLE_GST_TRACE
 684     gst_alloc_trace_set_flags_all ((GstAllocTraceFlags)(GST_ALLOC_TRACE_LIVE | GST_ALLOC_TRACE_MEM_LIVE));
 685     if (!gst_alloc_trace_available ())
 686         g_warning (&quot;Trace not available (recompile with trace enabled).&quot;);
 687     else
 688         gst_alloc_trace_print_live ();
 689 #endif
 690 
 691     m_StateLock-&gt;Enter();
 692     bool notReady = (m_PlayerState == Stopped || m_PlayerState == Error);
 693     m_StateLock-&gt;Exit();
 694 
 695     // If we in Stopped state report 0 for stream time
 696     if (notReady)
 697     {
 698         *streamTime = 0;
 699         return ERROR_NONE;
 700     }
 701 
 702     if (!gst_element_query_position(m_Elements[PIPELINE], GST_FORMAT_TIME, &amp;position))
 703     {
 704         // Position query failed: use timestamp of most recent buffer instead.
 705         position = (gint64)m_ulLastStreamTime;
 706     }
 707     else
 708     {
 709         m_ulLastStreamTime = position;
 710     }
 711 
 712     *streamTime = (double)position/(double)GST_SECOND;
 713 
 714     // GStreamer may report position which is slightly bigger then duration.
 715     // This is fine due to different rounding errors, but we should not report position which is bigger then duration.
 716     if (m_dLastReportedDuration == DURATION_UNKNOWN)
 717     {
 718         double dDuration = 0;
 719         if (GetDuration(&amp;dDuration) != ERROR_NONE)
 720             m_dLastReportedDuration = DURATION_UNKNOWN; // Hopefully duration will be available next time
 721     }
 722 
 723     if (m_dLastReportedDuration != DURATION_UNKNOWN &amp;&amp; m_dLastReportedDuration != DURATION_INDEFINITE &amp;&amp; *streamTime &gt; m_dLastReportedDuration)
 724         *streamTime = m_dLastReportedDuration;
 725 
 726     return ERROR_NONE;
 727 }
 728 
 729 /**
 730  * CGstAudioPlaybackPipeline::SetRate()
 731  *
 732  * Set the playback rate.  The rate can be a positive or negative float.
 733  *
 734  * @param   fRate   positive/negative float
 735  */
 736 uint32_t CGstAudioPlaybackPipeline::SetRate(float fRate)
 737 {
 738     uint32_t ret = ERROR_NONE;
 739 
 740     if (IsPlayerState(Error))
 741         return ret;
 742 
 743     if (fRate != m_fRate)
 744     {
 745         if (0.0F == fRate)
 746         {
 747             GstState state;
 748             gst_element_get_state(m_Elements[PIPELINE], &amp;state, NULL, 0);
 749 
 750             // It&#39;s not enough to check only m_PlayerState for playing state. There can be penging message to change the state
 751             // while we switch the rate.
 752             bool resume = (state == GST_STATE_PLAYING || IsPlayerState(Stalled));
 753 
 754             if (ERROR_NONE == Pause())
 755             {
 756                 m_fRate = 0.0F;
 757 
 758                 // Set playback resumption flag if currently playing or stalled.
 759                 m_bResumePlayOnNonzeroRate = resume;
 760             }
 761             else
 762                 ret = ERROR_GSTREAMER_PIPELINE_SET_RATE_ZERO;
 763         }
 764         else
 765         {
 766             // Determine current position.
 767             m_SeekLock-&gt;Enter();
 768             m_fRate = fRate;
 769 
 770             gint64 seek_time = 0;
 771             if (m_LastSeekTime == -1)
 772             {
 773                 double streamTime = 0;
 774                 GetStreamTime(&amp;streamTime);
 775                 seek_time = (gint64)(GST_SECOND*streamTime);
 776             }
 777             else
 778             {
 779                 seek_time = m_LastSeekTime;
 780             }
 781 
 782             if (SeekPipeline(seek_time) == ERROR_NONE)
 783             {
 784                 m_SeekLock-&gt;Exit();
 785 
 786                 // Set flag to indicate change from zero rate.
 787                 gboolean rateWasZero = (0.0F == m_fRate);
 788 
 789                 // Resume play if resetting from zero rate and flag is set.
 790                 if (rateWasZero &amp;&amp; m_bResumePlayOnNonzeroRate)
 791                     Play(); // Ignore the return value. TOOD: Emit a warning?
 792 
 793                 ret = ERROR_NONE;
 794             }
 795             else
 796             {
 797                 m_SeekLock-&gt;Exit();
 798                 ret = ERROR_GSTREAMER_PIPELINE_SEEK;
 799             }
 800         }
 801     }
 802 
 803     return ret;
 804 }
 805 
 806 /**
 807  * CGstAudioPlaybackPipeline::GetRate()
 808  *
 809  * Init an audio-only playback pipeline.
 810  *
 811  * @return  float value for the rate.
 812  */
 813 uint32_t CGstAudioPlaybackPipeline::GetRate(float* rate)
 814 {
 815     *rate = m_fRate;
 816     return ERROR_NONE;
 817 }
 818 
 819 /**
 820  * CGstAudioPlaybackPipeline::SetVolume()
 821  *
 822  * Set the volume for audio playback.
 823  *
 824  * @param   fVolume float value between 0.0f and 1.0f.
 825  */
 826 uint32_t CGstAudioPlaybackPipeline::SetVolume(float volume)
 827 {
 828     if (IsPlayerState(Error))
 829         return ERROR_NONE;
 830 
 831     // Clamp the value
 832     volume = (volume &lt; 0.0F) ? 0.0F :
 833              (volume &gt; 1.0F) ? 1.0F :
 834              volume;
 835 
 836     g_object_set (G_OBJECT (m_Elements[AUDIO_VOLUME]), &quot;volume&quot;, volume, NULL);
 837 
 838     return ERROR_NONE;
 839 }
 840 
 841 /**
 842  * CGstAudioPlaybackPipeline::GetVolume()
 843  *
 844  * Get the audio volume.
 845  *
 846  * @return  a float value between -1.0f and 1.0f
 847  */
 848 uint32_t CGstAudioPlaybackPipeline::GetVolume(float* volume)
 849 {
 850     if (IsPlayerState(Error))
 851         return ERROR_NONE;
 852 
 853     gdouble dvolume = 1.0F;
 854     g_object_get (m_Elements[AUDIO_VOLUME], &quot;volume&quot;, &amp;dvolume, NULL);
 855 
 856     *volume = (gfloat)dvolume;
 857 
 858     return ERROR_NONE;
 859 }
 860 
 861 /**
 862  * CGstAudioPlaybackPipeline::SetBalance()
 863  *
 864  * Set the balance for the audio volume between left and right audio channel.
 865  *
 866  * @param   fBalance    float value between -1.0f and 1.0f
 867  */
 868 uint32_t CGstAudioPlaybackPipeline::SetBalance(float fBalance)
 869 {
 870     if (IsPlayerState(Error))
 871         return ERROR_NONE;
 872 
 873     fBalance = (fBalance &lt; -1.0F) ? -1.0F :
 874               (fBalance &gt;  1.0F) ?  1.0F :
 875                fBalance;
 876 
 877     g_object_set (G_OBJECT (m_Elements[AUDIO_BALANCE]), &quot;panorama&quot;, fBalance, NULL);
 878 
 879     return ERROR_NONE;
 880 }
 881 
 882 /**
 883  * CGstAudioPlaybackPipeline::GetBalance()
 884  *
 885  * Get the audio balance between left and right channel.
 886  *
 887  * @return  float value between -1.0f and 1.0f
 888  */
 889 uint32_t CGstAudioPlaybackPipeline::GetBalance(float* balance)
 890 {
 891     if (IsPlayerState(Error))
 892         return ERROR_NONE;
 893 
 894     gfloat fbalance = 0.0F;
 895     g_object_get (m_Elements[AUDIO_BALANCE], &quot;panorama&quot;, &amp;fbalance, NULL);
 896 
 897     *balance = fbalance;
 898 
 899     return ERROR_NONE;
 900 }
 901 
 902 /**
 903  * CGstAudioPlaybackPipeline::SetAudioSyncDelay()
 904  *
 905  * Set an audio sync delay for the audio.  May keep audio and video in sync if video rendering
 906  * has a longer path.
 907  *
 908  * @param   lMillis     time delay in milliseconds
 909  */
 910 uint32_t CGstAudioPlaybackPipeline::SetAudioSyncDelay(long millis)
 911 {
 912     if (IsPlayerState(Error))
 913         return ERROR_NONE;
 914 
 915     g_object_set (G_OBJECT (m_Elements[AUDIO_SINK]), &quot;ts-offset&quot;, (gint64)(millis*GST_MSECOND), NULL);
 916 
 917     return ERROR_NONE;
 918 }
 919 
 920 /**
 921  * CGstAudioPlaybackPipeline::GetAudioSyncDelay()
 922  *
 923  * Get the audio sync delay.
 924  *
 925  * @return  time delay value in milliseconds.
 926  */
 927 uint32_t CGstAudioPlaybackPipeline::GetAudioSyncDelay(long* audioSyncDelay)
 928 {
 929     if (IsPlayerState(Error))
 930         return ERROR_NONE;
 931 
 932     gint64 nanos = 0;
 933     g_object_get (m_Elements[AUDIO_SINK], &quot;ts-offset&quot;, &amp;nanos, NULL);
 934 
 935     *audioSyncDelay = (long)GST_TIME_AS_MSECONDS(nanos);
 936 
 937     return ERROR_NONE;
 938 }
 939 
 940 CAudioEqualizer* CGstAudioPlaybackPipeline::GetAudioEqualizer()
 941 {
 942     return m_pAudioEqualizer;
 943 }
 944 
 945 CAudioSpectrum* CGstAudioPlaybackPipeline::GetAudioSpectrum()
 946 {
 947     return m_pAudioSpectrum;
 948 }
 949 
 950 bool CGstAudioPlaybackPipeline::IsCodecSupported(GstCaps *pCaps)
 951 {
 952 #if TARGET_OS_WIN32
 953     GstStructure *s = NULL;
 954     const gchar *mimetype = NULL;
 955 
 956     if (pCaps)
 957     {
 958         s = gst_caps_get_structure (pCaps, 0);
 959         if (s != NULL)
 960         {
 961             mimetype = gst_structure_get_name (s);
 962             if (mimetype != NULL)
 963             {
 964                 if (strstr(mimetype, CONTENT_TYPE_MPA) != NULL || // AAC or MPEG
 965                     strstr(mimetype, CONTENT_TYPE_MP3) != NULL)    // MPEG-1 or -2
 966                 {
 967                     gint mpegversion = 0;
 968 
 969                     if (gst_structure_get_int(s, &quot;mpegversion&quot;, &amp;mpegversion))
 970                     {
 971                         if (mpegversion == 4)
 972                         {
 973                             gboolean is_supported = FALSE;
 974                             g_object_set(m_Elements[AUDIO_DECODER], &quot;codec-id&quot;, (gint)CODEC_ID_AAC, NULL);
 975                             g_object_get(m_Elements[AUDIO_DECODER], &quot;is-supported&quot;, &amp;is_supported, NULL);
 976                             if (is_supported)
 977                             {
 978                                 return TRUE;
 979                             }
 980                             else
 981                             {
 982                                 m_audioCodecErrorCode = ERROR_MEDIA_AAC_FORMAT_UNSUPPORTED;
 983                                 return FALSE;
 984                             }
 985                         }
 986                     }
 987                 }
 988             }
 989         }
 990     }
 991 
 992     return TRUE;
 993 #else // TARGET_OS_WIN32
 994     GstStructure *s = NULL;
 995     const gchar *mimetype = NULL;
 996 
 997     if (pCaps)
 998     {
 999         s = gst_caps_get_structure (pCaps, 0);
1000         if (s != NULL)
1001         {
1002             mimetype = gst_structure_get_name (s);
1003             if (mimetype != NULL)
1004             {
1005                 if (strstr(mimetype, &quot;audio/unsupported&quot;) != NULL)
1006                 {
1007                     m_audioCodecErrorCode = ERROR_MEDIA_AUDIO_FORMAT_UNSUPPORTED;
1008                     return FALSE;
1009                 }
1010             }
1011         }
1012     }
1013 
1014     return TRUE;
1015 #endif // TRAGET_OS_WIN32
1016 }
1017 
1018 bool CGstAudioPlaybackPipeline::CheckCodecSupport()
1019 {
1020     if (!m_bHasAudio)
1021     {
1022         if (m_pEventDispatcher &amp;&amp; m_audioCodecErrorCode != ERROR_NONE)
1023         {
1024             if (!m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(m_audioCodecErrorCode))
1025             {
1026                 LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
1027             }
1028 
1029             return FALSE;
1030         }
1031     }
1032 
1033     return TRUE;
1034 }
1035 
1036 /**
1037  * CGstAudioPlaybackPipeline::BusCallback()
1038  *
1039  * GStreamer message bus for the audio pipeline.
1040  *
1041  * @param
1042  *
1043  * @return  true/false
1044  */
1045 gboolean CGstAudioPlaybackPipeline::BusCallback(GstBus* bus, GstMessage* msg, sBusCallbackContent* pBusCallbackContent)
1046 {
1047     pBusCallbackContent-&gt;m_DisposeLock-&gt;Enter();
1048 
1049     LOWLEVELPERF_EXECTIMESTART(&quot;BusCallback()&quot;);
1050 
1051     if (pBusCallbackContent-&gt;m_bIsDisposed)
1052     {
1053         pBusCallbackContent-&gt;m_DisposeLock-&gt;Exit();
1054         return FALSE; // Tell to stop sending messaged
1055     }
1056     else if (pBusCallbackContent-&gt;m_bIsDisposeInProgress)
1057     {
1058         pBusCallbackContent-&gt;m_DisposeLock-&gt;Exit();
1059         return TRUE; // Continue processing messages while we disposing, but
1060                      // ignore them.
1061     }
1062 
1063     CGstAudioPlaybackPipeline* pPipeline = pBusCallbackContent-&gt;m_pPipeline;
1064 
1065     switch (GST_MESSAGE_TYPE (msg)) {
1066 
1067         case GST_MESSAGE_DURATION_CHANGED:
1068         {
1069             if(NULL != pPipeline-&gt;m_pEventDispatcher)
1070             {
1071                 GstFormat format;
1072                 gint64 durationNanos;
1073 
1074                 // Parse the message to obtain the value and its format.
1075                 gst_message_parse_duration(msg, &amp;format, &amp;durationNanos);
1076 
1077                 // Continue if the format is time.
1078                 if (format == GST_FORMAT_TIME &amp;&amp; durationNanos &gt; 0)
1079                 {
1080                     // Convert the duration from nanoseconds to seconds.
1081                     double duration = (double)durationNanos/(double)GST_SECOND;
1082 
1083                     // Dispatch the event.
1084                     if (!pPipeline-&gt;m_pEventDispatcher-&gt;SendDurationUpdateEvent(duration))
1085                     {
1086                         if(!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_JNI_SEND_DURATION_UPDATE_EVENT))
1087                         {
1088                             LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
1089                         }
1090                     }
1091                 }
1092             }
1093         }
1094             break;
1095 
1096         case GST_MESSAGE_EOS:
1097         {
1098             // In some cases we may receive several GST_MESSAGE_EOS and signal Finsihed state several times.
1099             // We should enter and signal Finished state only once.
1100             // GST_MESSAGE_EOS will be send several times, because of bug or design issue in gstbin.
1101             // gstbin will check all sinks for EOS message and if all sinks posted EOS message it will forward message to application.
1102             // However, gstbin does not clear EOS message on sinks, which will result in several EOS messages being posted to application.
1103             // This condition reproduces after EOS-&gt; Seek to restart playback -&gt; EOS (2 messages received).
1104             if (!pPipeline-&gt;IsPlayerState(Finished))
1105             {
1106                 // Set the state to Finished which may only be exited by seeking back before the finish time.
1107                 pPipeline-&gt;SetPlayerState(Finished, false);
1108 
1109 #if ENABLE_PROGRESS_BUFFER
1110                 if (pPipeline-&gt;m_pOptions-&gt;GetHLSModeEnabled())
1111                     pPipeline-&gt;m_bLastProgressValueEOS = FALSE; // Otherwise we will resume playback if we loop and user hits stop
1112 #endif // ENABLE_PROGRESS_BUFFER
1113             }
1114         }
1115             break;
1116 
1117         case GST_MESSAGE_ERROR:
1118         {
1119             gchar  *debug = NULL;
1120             GError *error = NULL;
1121 
1122             gst_message_parse_error (msg, &amp;error, &amp;debug);
1123 
1124             if (error &amp;&amp; error-&gt;message)
1125                 LOGGER_LOGMSG(LOGGER_ERROR, error-&gt;message);
1126 
1127             if (debug)
1128                 LOGGER_LOGMSG(LOGGER_DEBUG, debug);
1129 
1130             // Handle connection lost error
1131             if (error)
1132             {
1133                 if (pPipeline != NULL &amp;&amp; pPipeline-&gt;m_pEventDispatcher != NULL &amp;&amp; error-&gt;domain == GST_RESOURCE_ERROR &amp;&amp; error-&gt;code == GST_RESOURCE_ERROR_READ)
1134                 {
1135                     if (!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_LOCATOR_CONNECTION_LOST))
1136                     {
1137                         LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
1138                     }
1139                     pPipeline-&gt;m_bIgnoreError = TRUE;
1140                     g_error_free (error);
1141                     if (debug)
1142                         g_free(debug);
1143                     break;
1144                 }
1145                 // GstBaseSrc will send GST_STREAM_ERROR_FAILED when connection is lost
1146                 // We need to ignore this error if it was received right after GST_RESOURCE_ERROR_READ
1147                 else if (pPipeline != NULL &amp;&amp; pPipeline-&gt;m_bIgnoreError &amp;&amp; error-&gt;domain == GST_STREAM_ERROR &amp;&amp; error-&gt;code == GST_STREAM_ERROR_FAILED)
1148                 {
1149                     pPipeline-&gt;m_bIgnoreError = FALSE;
1150                     g_error_free (error);
1151                     if (debug)
1152                         g_free(debug);
1153                     break;
1154                 }
1155                 else if (pPipeline != NULL &amp;&amp; pPipeline-&gt;m_pEventDispatcher != NULL &amp;&amp; error-&gt;domain == GST_STREAM_ERROR &amp;&amp;
1156                     (error-&gt;code == GST_STREAM_ERROR_DECODE || error-&gt;code == GST_STREAM_ERROR_WRONG_TYPE))
1157                 {
1158                     if (!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_MEDIA_INVALID))
1159                     {
1160                         LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
1161                     }
1162                     g_error_free (error);
1163                     if (debug)
1164                         g_free(debug);
1165                     break;
1166                 }
1167                 else if (pPipeline != NULL &amp;&amp; pPipeline-&gt;m_pEventDispatcher != NULL &amp;&amp; error-&gt;domain == GST_STREAM_ERROR &amp;&amp;
1168                     (error-&gt;code == GST_STREAM_ERROR_CODEC_NOT_FOUND ||
1169                      error-&gt;code == GST_STREAM_ERROR_FAILED ||
1170                      error-&gt;code == GST_STREAM_ERROR_TYPE_NOT_FOUND))
1171                 {
1172                     if (pPipeline-&gt;m_pOptions-&gt;GetHLSModeEnabled())
1173                     {
1174                         if (!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_MEDIA_HLS_FORMAT_UNSUPPORTED))
1175                         {
1176                             LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
1177                         }
1178                     }
1179                     else
1180                     {
1181                         if (!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_MEDIA_INVALID))
1182                         {
1183                             LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
1184                         }
1185                     }
1186                     g_error_free (error);
1187                     if (debug)
1188                         g_free(debug);
1189                     break;
1190                 }
1191             }
1192 
1193             // Clear ignore error in case if we did not receive GST_STREAM_ERROR_FAILED after GST_RESOURCE_ERROR_READ.
1194             pPipeline-&gt;m_bIgnoreError = FALSE;
1195 
1196             // Tear down GStreamer pipeline only if PlayerState is not Error, becuase when GST_MESSAGE_ERROR
1197             // is generated during state change, we may have infinite loop by getting GST_MESSAGE_ERROR
1198             // each time when we try to set pipeline to GST_STATE_NULL.
1199             if (!pPipeline-&gt;IsPlayerState(Error))
1200                 gst_element_set_state(pPipeline-&gt;m_Elements[PIPELINE], GST_STATE_NULL); // Ignore return value.
1201 
1202             pPipeline-&gt;SetPlayerState(Error, true);
1203 
1204             if (error)
1205             {
1206                 if (NULL != pPipeline-&gt;m_pEventDispatcher)
1207                 {
1208                     if (error-&gt;domain == GST_STREAM_ERROR &amp;&amp; error-&gt;code == GST_STREAM_ERROR_DEMUX)
1209                     {
1210                         if (!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_MEDIA_CORRUPTED))
1211                         {
1212                             LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
1213                         }
1214                     }
1215                     else
1216                     {
1217                         if (!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerHaltEvent(error-&gt;message, (double)msg-&gt;timestamp / GST_SECOND))
1218                         {
1219                             if(!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_JNI_SEND_PLAYER_HALT_EVENT))
1220                             {
1221                                 LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
1222                             }
1223                         }
1224                     }
1225                 }
1226                 g_error_free (error);
1227             }
1228 
1229             if (debug)
1230                 g_free (debug);
1231         }
1232             break;
1233 
1234         case GST_MESSAGE_WARNING:
1235         {
1236             gchar  *debug = NULL;
1237             GError *warning = NULL;
1238 
1239             gst_message_parse_warning (msg, &amp;warning, &amp;debug);
1240 
1241             if (warning)
1242             {
1243                 pPipeline-&gt;m_pEventDispatcher-&gt;Warning(WARNING_GSTREAMER_PIPELINE_WARNING,
1244                                                        (const char*)warning-&gt;message);
1245                 LOGGER_LOGMSG(LOGGER_WARNING, warning-&gt;message);
1246                 g_error_free (warning);
1247             }
1248 
1249             if (debug)
1250             {
1251                 LOGGER_LOGMSG(LOGGER_DEBUG, debug);
1252                 g_free (debug);
1253             }
1254         }
1255             break;
1256 
1257         case GST_MESSAGE_INFO:
1258         {
1259             gchar  *debug = NULL;
1260             GError *info = NULL;
1261 
1262             gst_message_parse_info (msg, &amp;info, &amp;debug);
1263 
1264             if (info)
1265             {
1266                 pPipeline-&gt;m_pEventDispatcher-&gt;Warning(WARNING_GSTREAMER_PIPELINE_INFO_ERROR,
1267                                                        (const char*)info-&gt;message);
1268                 LOGGER_LOGMSG(LOGGER_ERROR, info-&gt;message);
1269                 g_error_free (info);
1270             }
1271 
1272             if (debug)
1273             {
1274                 LOGGER_LOGMSG(LOGGER_DEBUG, debug);
1275                 g_free (debug);
1276             }
1277         }
1278             break;
1279 
1280         case GST_MESSAGE_STATE_CHANGED:
1281         {
1282             GstState oldState, newState, pendingState;
1283 
1284             gst_message_parse_state_changed(msg, &amp;oldState, &amp;newState, &amp;pendingState);
1285 #if JFXMEDIA_DEBUG
1286             if (GST_MESSAGE_SRC(msg) == GST_OBJECT(pPipeline-&gt;m_Elements[PIPELINE]))
1287                 g_print (&quot;%s: %s-&gt;%s pending(%s)\n&quot;,
1288                         GST_OBJECT_NAME(GST_MESSAGE_SRC(msg)),
1289                         gst_element_state_get_name(oldState),
1290                         gst_element_state_get_name(newState),
1291                         gst_element_state_get_name(pendingState));
1292 #endif
1293 
1294             // Check if we need to set clock
1295             // Based on GStreamer documentation audio sink should provide clock when it in PAUSED state.
1296             // In NULL or READY state clock maybe invalid.
1297             if (!pPipeline-&gt;m_bIsClockSet &amp;&amp; pPipeline-&gt;m_Elements[AUDIO_SINK] != NULL &amp;&amp; pPipeline-&gt;m_bHasAudio &amp;&amp; GST_MESSAGE_SRC(msg) == GST_OBJECT(pPipeline-&gt;m_Elements[AUDIO_SINK]) &amp;&amp; pendingState == GST_STATE_VOID_PENDING &amp;&amp; newState == GST_STATE_READY)
1298             {
1299                 pPipeline-&gt;m_bSetClock = true;
1300                 pPipeline-&gt;m_bIsClockSet = true;
1301             }
1302 
1303             // Check if sink are ready
1304             if (!pPipeline-&gt;m_bDynamicElementsReady)
1305             {
1306                 if (pPipeline-&gt;m_Elements[AUDIO_SINK] == NULL)
1307                     pPipeline-&gt;m_bAudioSinkReady = true;
1308                 else if (GST_MESSAGE_SRC(msg) == GST_OBJECT(pPipeline-&gt;m_Elements[AUDIO_SINK]) &amp;&amp; newState == GST_STATE_PAUSED &amp;&amp; oldState == GST_STATE_READY &amp;&amp; pendingState == GST_STATE_VOID_PENDING)
1309                     pPipeline-&gt;m_bAudioSinkReady = true;
1310 
1311                 if (pPipeline-&gt;m_Elements[VIDEO_SINK] == NULL)
1312                     pPipeline-&gt;m_bVideoSinkReady = true;
1313                 else if (GST_MESSAGE_SRC(msg) == GST_OBJECT(pPipeline-&gt;m_Elements[VIDEO_SINK]) &amp;&amp; newState == GST_STATE_PAUSED &amp;&amp; oldState == GST_STATE_READY &amp;&amp; pendingState == GST_STATE_VOID_PENDING)
1314                     pPipeline-&gt;m_bVideoSinkReady = true;
1315 
1316                 if (pPipeline-&gt;m_bAudioSinkReady &amp;&amp; pPipeline-&gt;m_bVideoSinkReady)
1317                     pPipeline-&gt;m_bDynamicElementsReady = true;
1318             }
1319 
1320             // Update clock if needed
1321             // Audio sink will provide clock when it in paused or playing state.
1322             // Our pipeline will not find audio sink clock, because we use audio sink inside bin and bin hides clock distribution.
1323             // When pipeline cannot find clock it will use GstSystemClock, so we need to set correct clock to pipeline.
1324             if (pPipeline-&gt;m_bSetClock &amp;&amp; ((pPipeline-&gt;m_bStaticPipeline &amp;&amp; pPipeline-&gt;m_Elements[AUDIO_SINK] != NULL &amp;&amp; pPipeline-&gt;m_bHasAudio &amp;&amp; GST_MESSAGE_SRC(msg) == GST_OBJECT(pPipeline-&gt;m_Elements[AUDIO_SINK]) &amp;&amp; pendingState == GST_STATE_VOID_PENDING &amp;&amp; newState == GST_STATE_PAUSED) || pPipeline-&gt;m_bDynamicElementsReady))
1325             {
1326                 pPipeline-&gt;m_bSetClock = false;
1327 
1328                 // Get clock from audio sink
1329                 GstClock *clock = gst_element_provide_clock(pPipeline-&gt;m_Elements[AUDIO_SINK]);
1330 
1331                 // Set it to pipeline only if we have one
1332                 // If we set NULL as clock pipeline will render as fast as possible and we do not want this to happen.
1333                 // In case if we did not get clock, pipeline will use GstSystemClock which is better then using NULL.
1334                 if (clock != NULL)
1335                 {
1336                     gst_pipeline_set_clock(GST_PIPELINE(pPipeline-&gt;m_Elements[PIPELINE]), clock);
1337                     gst_object_unref(clock);
1338                 }
1339             }
1340 
1341             // We have special case when we in Paused or Stall state and we going to Stopped or Paused state. In this case
1342             // newState and oldState will be set to GST_STATE_PAUSED.
1343             if (GST_MESSAGE_SRC(msg) == GST_OBJECT(pPipeline-&gt;m_Elements[PIPELINE])
1344                 &amp;&amp; ((pendingState == GST_STATE_VOID_PENDING &amp;&amp; newState != oldState &amp;&amp; !pPipeline-&gt;IsPlayerState(Unknown)) // Regular state change
1345                 || ((pPipeline-&gt;IsPlayerPendingState(Stopped) || pPipeline-&gt;IsPlayerPendingState(Paused) || pPipeline-&gt;m_StallOnPause) &amp;&amp; newState == GST_STATE_PAUSED &amp;&amp; oldState == GST_STATE_PAUSED &amp;&amp; pendingState == GST_STATE_VOID_PENDING) // Special cases for pause, stall and stop
1346                      || (pPipeline-&gt;IsPlayerState(Unknown) &amp;&amp; newState == GST_STATE_PAUSED &amp;&amp; (oldState == GST_STATE_READY || oldState == GST_STATE_PAUSED) &amp;&amp; pendingState == GST_STATE_VOID_PENDING &amp;&amp; !pPipeline-&gt;m_bStaticPipeline &amp;&amp; pPipeline-&gt;m_bDynamicElementsReady) // Ready for dynamic pipeline
1347                      || (pPipeline-&gt;IsPlayerState(Unknown) &amp;&amp; newState == GST_STATE_PAUSED &amp;&amp; oldState == GST_STATE_READY &amp;&amp; pendingState == GST_STATE_VOID_PENDING &amp;&amp; pPipeline-&gt;m_bStaticPipeline))) // Ready for static pipeline
1348             {
1349                 if (GST_STATE_PAUSED == newState)
1350                 {
1351                     LOWLEVELPERF_EXECTIMESTOP(&quot;GST_STATE_PAUSED&quot;);
1352 
1353 #if ENABLE_PROGRESS_BUFFER
1354                     // Update buffer position only if progress buffer got EOS.
1355                     // In some case progress may not be reported yet, because duration was not available yet.
1356                     // By now it should be available, so lets update buffer position.
1357                     if (pPipeline-&gt;m_bLastProgressValueEOS)
1358                         pPipeline-&gt;UpdateBufferPosition();
1359 #endif // ENABLE_PROGRESS_BUFFER
1360                 }
1361 
1362                 // Update the player state.
1363                 pPipeline-&gt;UpdatePlayerState(newState, oldState);
1364             }
1365         }
1366             break;
1367 
1368 #if ENABLE_PROGRESS_BUFFER
1369         case GST_MESSAGE_APPLICATION:       //This currently handles messages from the progress buffer element
1370         {
1371             const GstStructure *pStr = gst_message_get_structure(msg);
1372             if (gst_structure_has_name(pStr, PB_MESSAGE_BUFFERING))
1373             {
1374                 // See comment to progressbuffer.c:send_position_message for more details.
1375                 const GValue *start_v    = gst_structure_get_value(pStr, &quot;start&quot;);
1376                 const GValue *position_v = gst_structure_get_value(pStr, &quot;position&quot;);
1377                 const GValue *stop_v     = gst_structure_get_value(pStr, &quot;stop&quot;);
1378                 const GValue *eos_v      = gst_structure_get_value(pStr, &quot;eos&quot;);
1379 
1380                 gint64    start     = g_value_get_int64(start_v);
1381                 gint64    position  = g_value_get_int64(position_v);
1382                 gint64    stop      = g_value_get_int64(stop_v);
1383                 gboolean  eos       = g_value_get_boolean(eos_v); // eos indicates if progress buffer received EOS event.
1384                                                                     // This mean that progress buffer will not send any progress messages anymore and no more data will be available.
1385 
1386                 // When we receive GST_MESSAGE_APPLICATION pipeline may not fully complete transition to PAUSE state.
1387                 // In this case duration will not be available, thus we cannot report progress.
1388                 // Also, file may be very small and in this case progress buffer will able to download all data (no more GST_MESSAGE_APPLICATION)
1389                 // untill pipeline completes transition to PAUSE state. In such case we will never report any progress.
1390                 // To solve this lets save last reported value and update progress when pipeline completed transition to PAUSE state.
1391                 pPipeline-&gt;m_llLastProgressValueStart = start;
1392                 pPipeline-&gt;m_llLastProgressValuePosition = position;
1393                 pPipeline-&gt;m_llLastProgressValueStop = stop;
1394                 pPipeline-&gt;m_bLastProgressValueEOS = eos;
1395 
1396                 // Update buffer position
1397                 pPipeline-&gt;UpdateBufferPosition();
1398             }
1399             else if (gst_structure_has_name(pStr, PB_MESSAGE_UNDERRUN))
1400                 pPipeline-&gt;BufferUnderrun();
1401             else if (gst_structure_has_name(pStr, HLS_PB_MESSAGE_STALL))
1402                 pPipeline-&gt;HLSBufferStall();
1403             else if (gst_structure_has_name(pStr, HLS_PB_MESSAGE_RESUME))
1404                 pPipeline-&gt;HLSBufferResume(false);
1405             else if (gst_structure_has_name(pStr, HLS_PB_MESSAGE_HLS_EOS))
1406                 pPipeline-&gt;HLSBufferResume(true);
1407             else if (gst_structure_has_name(pStr, HLS_PB_MESSAGE_FULL))
1408             {
1409                 pPipeline-&gt;m_StallLock-&gt;Enter();
1410                 pPipeline-&gt;m_bHLSPBFull = true;
1411                 pPipeline-&gt;m_StallLock-&gt;Exit();
1412                 pPipeline-&gt;HLSBufferResume(false);
1413             }
1414             else if (gst_structure_has_name(pStr, HLS_PB_MESSAGE_NOT_FULL))
1415                 pPipeline-&gt;m_bHLSPBFull = false;
1416         }
1417             break;
1418 #endif  //ENABLE_PROGRESS_BUFFER
1419 
1420         case GST_MESSAGE_ELEMENT:
1421         {
1422             const GstStructure *pStr = gst_message_get_structure (msg);
1423             if (gst_structure_has_name(pStr, &quot;spectrum&quot;))
1424             {
1425                 GstClockTime timestamp, duration;
1426 
1427                 if (!gst_structure_get_clock_time (pStr, &quot;timestamp&quot;, &amp;timestamp))
1428                     timestamp = GST_CLOCK_TIME_NONE;
1429 
1430                 if (!gst_structure_get_clock_time (pStr, &quot;duration&quot;, &amp;duration))
1431                     duration = GST_CLOCK_TIME_NONE;
1432 
1433                 size_t bandsNum = pPipeline-&gt;GetAudioSpectrum()-&gt;GetBands();
1434 
1435                 if (bandsNum &gt; 0)
1436                 {
1437                     float *magnitudes = new float[bandsNum];
1438                     float *phases = new float[bandsNum];
1439 
1440                     const GValue *magnitudes_value = gst_structure_get_value(pStr, &quot;magnitude&quot;);
1441                     const GValue *phases_value = gst_structure_get_value(pStr, &quot;phase&quot;);
1442                     for (int i=0; i &lt; bandsNum; i++)
1443                     {
1444                         magnitudes[i] = g_value_get_float( gst_value_list_get_value (magnitudes_value, i));
1445                         phases[i] = g_value_get_float( gst_value_list_get_value (phases_value, i));
1446                     }
1447                     pPipeline-&gt;GetAudioSpectrum()-&gt;UpdateBands((int)bandsNum, magnitudes, phases);
1448 
1449                     delete [] magnitudes;
1450                     delete [] phases;
1451                 }
1452 
1453                 if (!pPipeline-&gt;m_pEventDispatcher-&gt;SendAudioSpectrumEvent(GST_TIME_AS_SECONDS((double)timestamp),
1454                     GST_TIME_AS_SECONDS((double)duration), false)) // Always false, since GStreamer does not need it,
1455                                                                    // but if it will be required such case needs to be
1456                                                                    // tested.
1457                 {
1458                     if(!pPipeline-&gt;m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_JNI_SEND_AUDIO_SPECTRUM_EVENT))
1459                     {
1460                         LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
1461                     }
1462                 }
1463           }
1464 
1465         }
1466             break;
1467 
1468         case GST_MESSAGE_ASYNC_DONE:
1469             pPipeline-&gt;m_SeekLock-&gt;Enter();
1470             pPipeline-&gt;m_LastSeekTime = -1;
1471             pPipeline-&gt;m_SeekLock-&gt;Exit();
1472             break;
1473 
1474         default:
1475             break;
1476     }
1477 
1478     LOWLEVELPERF_EXECTIMESTOP(&quot;BusCallback()&quot;);
1479 
1480     pBusCallbackContent-&gt;m_DisposeLock-&gt;Exit();
1481 
1482     return TRUE;
1483 }
1484 
1485 // This function will be called in 2 cases and it will be always called when no more BusCallbacks is expected:
1486 // 1 - When g_source_destroy() is called from Dispose() and there are no pending or in-progress BusCallbacks. It will be called from Dispose() thread.
1487 // 2 - When g_source_destroy() is called from Dispose() and all pending or in-progress BusCallbacks are done. It will be called from main loop thread and pipeline will be gone at this time.
1488 // So lets figure out who will be responsible to free memory, since DisposeLock is used by Dispose() as well.
1489 void CGstAudioPlaybackPipeline::BusCallbackDestroyNotify(sBusCallbackContent* pBusCallbackContent)
1490 {
1491     if (pBusCallbackContent)
1492     {
1493         bool bFreeMeHere = false;
1494 
1495         pBusCallbackContent-&gt;m_DisposeLock-&gt;Enter();
1496         if (pBusCallbackContent-&gt;m_bIsDisposed)
1497             bFreeMeHere = true; // Everything is gone, so free me here.
1498         else
1499             pBusCallbackContent-&gt;m_bFreeMe = true; // Ask Dispose() when it is done to free me
1500         pBusCallbackContent-&gt;m_DisposeLock-&gt;Exit();
1501 
1502         if (bFreeMeHere)
1503         {
1504             delete pBusCallbackContent-&gt;m_DisposeLock;
1505             delete pBusCallbackContent;
1506         }
1507     }
1508 }
1509 
1510 /**
1511  * CGstAudioPlaybackPipeline::SetPlayerState()
1512  *
1513  * Sets our &quot;player&quot; state.  This is not the same as the gst pipeline state.  This function should not be
1514  * called for normal state changes.  This is for out-of-band changes like stalled condition or EOS.
1515  *
1516  */
1517 void CGstAudioPlaybackPipeline::SetPlayerState(PlayerState newPlayerState, bool bSilent)
1518 {
1519     m_StateLock-&gt;Enter();
1520 
1521     // Determine if we need to send an event out
1522     bool updateState = newPlayerState != m_PlayerState;
1523     if (updateState)
1524     {
1525         if (NULL != m_pEventDispatcher &amp;&amp; !bSilent)
1526         {
1527             m_PlayerState = newPlayerState;
1528 
1529             if (!m_pEventDispatcher-&gt;SendPlayerStateEvent(newPlayerState, 0.0))
1530             {
1531                 if(!m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_JNI_SEND_PLAYER_STATE_EVENT))
1532                 {
1533                     LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
1534                 }
1535             }
1536         }
1537         else
1538         {
1539             m_PlayerState = newPlayerState;
1540         }
1541     }
1542 
1543     m_StateLock-&gt;Exit();
1544 
1545 #if ENABLE_PROGRESS_BUFFER
1546     if ((updateState &amp;&amp; newPlayerState == Stalled &amp;&amp; m_bLastProgressValueEOS) ||
1547         (updateState &amp;&amp; newPlayerState == Stalled &amp;&amp; m_bHLSPBFull))
1548 #else // ENABLE_PROGRESS_BUFFER
1549     if ((updateState &amp;&amp; newPlayerState == Stalled) ||
1550         (updateState &amp;&amp; newPlayerState == Stalled &amp;&amp; m_bHLSPBFull))
1551 #endif // ENABLE_PROGRESS_BUFFER
1552     {
1553        Play();
1554     }
1555 }
1556 
1557 /**
1558  * CGstAudioPlaybackPipeline::IsPlayerState()
1559  *
1560  * Synchronously tests if the player state equals to the mentioned
1561  */
1562 bool CGstAudioPlaybackPipeline::IsPlayerState(PlayerState state)
1563 {
1564     m_StateLock-&gt;Enter();
1565     bool result = (m_PlayerState == state);
1566     m_StateLock-&gt;Exit();
1567 
1568     return result;
1569 }
1570 
1571 /**
1572  * CGstAudioPlaybackPipeline::IsPlayerPendingState()
1573  *
1574  * Synchronously tests if the player pending state equals to the mentioned
1575  */
1576 bool CGstAudioPlaybackPipeline::IsPlayerPendingState(PlayerState state)
1577 {
1578     m_StateLock-&gt;Enter();
1579     bool result = (m_PlayerPendingState == state);
1580     m_StateLock-&gt;Exit();
1581 
1582     return result;
1583 }
1584 
1585 /**
1586  * CGstAudioPlaybackPipeline::UpdatePlayerState()
1587  *
1588  * Intermediates between Gst pipeline state and our &quot;player&quot; state.  This is called when we get a pipeline
1589  * state change.
1590  *
1591  */
1592 void CGstAudioPlaybackPipeline::UpdatePlayerState(GstState newState, GstState oldState)
1593 {
1594     m_StateLock-&gt;Enter();
1595 
1596     PlayerState newPlayerState = m_PlayerState;
1597     bool        bSilent = false;
1598 
1599     switch(m_PlayerState)
1600     {
1601         case Unknown:
1602             if((GST_STATE_READY == oldState &amp;&amp; GST_STATE_PAUSED == newState) || (GST_STATE_PAUSED == oldState &amp;&amp; GST_STATE_PAUSED == newState))
1603             {
1604                 newPlayerState = Ready;
1605             }
1606             break;
1607 
1608         case Ready:
1609             if(GST_STATE_PAUSED == oldState)
1610             {
1611                 if(GST_STATE_READY == newState)
1612                     newPlayerState = Unknown;
1613                 else if(GST_STATE_PLAYING == newState)
1614                     newPlayerState = Playing;
1615             }
1616             break;
1617 
1618         case Playing:
1619             if(GST_STATE_PLAYING == oldState)
1620             {
1621                 if(GST_STATE_PAUSED == newState)
1622                 {
1623                     if(m_PlayerPendingState == Stopped)
1624                     {
1625                         m_StallOnPause = false;
1626                         m_PlayerPendingState = Unknown;
1627                         newPlayerState = Stopped;
1628                     }
1629                     else if (m_StallOnPause &amp;&amp; m_PlayerPendingState != Paused)
1630                     {
1631                         m_StallOnPause = false;
1632                         newPlayerState = Stalled;
1633                     }
1634                     else if (m_PlayerPendingState == Paused)
1635                     {
1636                         m_StallOnPause = false;
1637                         m_PlayerPendingState = Unknown;
1638                         newPlayerState = Paused;
1639                     }
1640                     else
1641                     {
1642                         newPlayerState = Finished;
1643                     }
1644                 }
1645             }
1646             else if(GST_STATE_PAUSED == oldState) // May happen during seek
1647             {
1648                 if(GST_STATE_PAUSED == newState)
1649                 {
1650                     if(m_PlayerPendingState == Stopped)
1651                     {
1652                         m_StallOnPause = false;
1653                         m_PlayerPendingState = Unknown;
1654                         newPlayerState = Stopped;
1655                     }
1656                     else if (m_StallOnPause &amp;&amp; m_PlayerPendingState != Paused)
1657                     {
1658                         m_StallOnPause = false;
1659                         newPlayerState = Stalled;
1660                     }
1661                     else if (m_PlayerPendingState == Paused)
1662                     {
1663                         m_StallOnPause = false;
1664                         m_PlayerPendingState = Unknown;
1665                         newPlayerState = Paused;
1666                     }
1667                 }
1668             }
1669             break;
1670 
1671         case Paused:
1672             if(GST_STATE_PAUSED == oldState)
1673             {
1674                 if(m_PlayerPendingState == Stopped)
1675                 {
1676                     m_PlayerPendingState = Unknown;
1677                     newPlayerState = Stopped;
1678                 }
1679                 else
1680                 {
1681                     if(GST_STATE_PLAYING == newState)
1682                         newPlayerState = Playing;
1683                     else if(GST_STATE_READY == newState)
1684                         newPlayerState = Unknown;
1685                 }
1686             }
1687             break;
1688 
1689         case Stopped:
1690             if(GST_STATE_PAUSED == oldState)
1691             {
1692                 if (m_PlayerPendingState == Paused &amp;&amp; GST_STATE_PAUSED == newState)
1693                 {
1694                     m_PlayerPendingState = Unknown;
1695                     newPlayerState = Paused;
1696                 }
1697                 else if(GST_STATE_PLAYING == newState)
1698                 {
1699                     newPlayerState = Playing;
1700                 }
1701                 else if(GST_STATE_READY == newState)
1702                 {
1703                     newPlayerState = Unknown;
1704                 }
1705             }
1706             break;
1707 
1708         case Stalled:
1709         {
1710             if (GST_STATE_PAUSED == oldState &amp;&amp; GST_STATE_PLAYING == newState)
1711                 newPlayerState = Playing;
1712             else if (GST_STATE_PAUSED == oldState &amp;&amp; GST_STATE_PAUSED == newState)
1713             {
1714                 if (m_PlayerPendingState == Stopped)
1715                 {
1716                     m_PlayerPendingState = Unknown;
1717                     newPlayerState = Stopped;
1718                 }
1719                 else if (m_PlayerPendingState == Paused)
1720                 {
1721                     m_PlayerPendingState = Unknown;
1722                     newPlayerState = Paused;
1723                 }
1724             }
1725             break;
1726         }
1727 
1728         case Finished:
1729             if(GST_STATE_PLAYING == oldState)
1730             {
1731                 if(GST_STATE_PAUSED == newState)
1732                 {
1733                     if(m_PlayerPendingState == Stopped)
1734                     {
1735                         m_PlayerPendingState = Unknown;
1736                         m_bSeekInvoked = false;
1737                         newPlayerState = Stopped;
1738                     }
1739                     // No need to switch to paused state, since Pause is not valid in Finished state
1740                 }
1741             }
1742             else if(GST_STATE_PAUSED == oldState)
1743             {
1744                 if(GST_STATE_PLAYING == newState)
1745                 {
1746                     // We can go from Finished to Playing only when seek happens (or repeat)
1747                     // This state change should be silent.
1748                     newPlayerState = Playing;
1749                     m_bSeekInvoked = false;
1750                     bSilent = true;
1751                 }
1752                 else if(GST_STATE_PAUSED == newState)
1753                 {
1754                     if(m_PlayerPendingState == Stopped)
1755                     {
1756                         m_PlayerPendingState = Unknown;
1757                         m_bSeekInvoked = false;
1758                         newPlayerState = Stopped;
1759                     }
1760                     else
1761                     {
1762                         m_bSeekInvoked = false;
1763                         newPlayerState = Paused;
1764                     }
1765                 }
1766             }
1767             break;
1768 
1769         case Error:
1770             break;
1771     }
1772 
1773     SetPlayerState(newPlayerState, bSilent);
1774     m_StateLock-&gt;Exit();
1775 }
1776 
1777 //*************************************************************************************************
1778 //* Scanning tracks information
1779 //*************************************************************************************************
1780 void CGstAudioPlaybackPipeline::SendTrackEvent()
1781 {
1782     if (NULL != m_pEventDispatcher)
1783     {
1784         CTrack::Encoding encoding;
1785         int              channelMask;
1786 
1787         // Detect the encoding type from the information that we have from caps.
1788         if (m_AudioTrackInfo.mimeType.find(&quot;audio/x-raw&quot;) != string::npos)
1789             encoding = CTrack::PCM;
1790         else if (m_AudioTrackInfo.mimeType.find(CONTENT_TYPE_MPA) != string::npos ||
1791                  m_AudioTrackInfo.mimeType.find(CONTENT_TYPE_MP3) != string::npos)
1792         {
1793             if (m_AudioTrackInfo.mpegversion == 1)
1794                 encoding = (m_AudioTrackInfo.layer == 3) ? CTrack::MPEG1LAYER3 : CTrack::MPEG1AUDIO;
1795             else if (m_AudioTrackInfo.mpegversion == 4)
1796                 encoding = CTrack::AAC;
1797             else
1798                 encoding = CTrack::CUSTOM;
1799         }
1800         else
1801             encoding = CTrack::CUSTOM;
1802 
1803         // Detect the channelmask from the number of channels
1804         switch (m_AudioTrackInfo.channels)
1805         {
1806             case 1:
1807                 channelMask = CAudioTrack::FRONT_CENTER;
1808                 break;
1809 
1810             case 2:
1811                 channelMask = CAudioTrack::FRONT_RIGHT | CAudioTrack::FRONT_LEFT;
1812                 break;
1813 
1814             case 4:
1815                 channelMask = CAudioTrack::FRONT_RIGHT | CAudioTrack::FRONT_LEFT | CAudioTrack::REAR_RIGHT | CAudioTrack::REAR_LEFT;
1816                 break;
1817 
1818             case 0:
1819             default:
1820                 channelMask = CAudioTrack::UNKNOWN;
1821                 break;
1822         }
1823 
1824         CAudioTrack *p_AudioTrack = new CAudioTrack(m_AudioTrackInfo.trackID,
1825                                                     m_AudioTrackInfo.mimeType,
1826                                                     encoding,
1827                                                     (bool)m_AudioTrackInfo.trackEnabled,
1828                                                     &quot;und&quot;,
1829                                                     m_AudioTrackInfo.channels,
1830                                                     channelMask,
1831                                                     (float)m_AudioTrackInfo.rate);
1832 
1833         if (!m_pEventDispatcher-&gt;SendAudioTrackEvent(p_AudioTrack))
1834         {
1835             if(!m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_JNI_SEND_AUDIO_TRACK_EVENT))
1836             {
1837                 LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
1838             }
1839         }
1840 
1841         delete p_AudioTrack;
1842     }
1843 }
1844 
1845 GstPadProbeReturn CGstAudioPlaybackPipeline::AudioSinkPadProbe(GstPad* pPad, GstPadProbeInfo *pInfo, CGstAudioPlaybackPipeline* pPipeline)
1846 {
1847     // Make sure we got requested probe
1848     if ((pInfo-&gt;type &amp; GST_PAD_PROBE_TYPE_BUFFER) != GST_PAD_PROBE_TYPE_BUFFER || pInfo-&gt;data == NULL)
1849         return GST_PAD_PROBE_OK;
1850 
1851     GstCaps* pCaps = gst_pad_get_current_caps(pPad);
1852     if (NULL == pCaps || gst_caps_get_size(pCaps) &lt; 1)
1853     {
1854         if (pCaps != NULL)
1855             gst_caps_unref(pCaps);
1856         return GST_PAD_PROBE_OK;
1857     }
1858 
1859     GstStructure *pStructure = gst_caps_get_structure(pCaps, 0);
1860     pPipeline-&gt;m_AudioTrackInfo.mimeType = gst_structure_get_name(pStructure);
1861 
1862     gint trackID;
1863     gboolean enabled;
1864     if (!gst_structure_get_boolean(pStructure, &quot;track_enabled&quot;, &amp;enabled)) {
1865         enabled = TRUE; // default to enabled if container doesn&#39;t support it
1866     }
1867     if (!gst_structure_get_int(pStructure, &quot;track_id&quot;, &amp;trackID)) {
1868         trackID = 0; // default audio track ID if none present (can only be one in that case)
1869     }
1870     pPipeline-&gt;m_AudioTrackInfo.trackEnabled = enabled;
1871     pPipeline-&gt;m_AudioTrackInfo.trackID = (int64_t)trackID;
1872 
1873     // Don&#39;t use shortcut evaluation here. Try to get as much as possible.
1874     gboolean ready = gst_structure_get_int(pStructure, &quot;channels&quot;, &amp;pPipeline-&gt;m_AudioTrackInfo.channels) &amp;
1875                      gst_structure_get_int(pStructure, &quot;rate&quot;, &amp;pPipeline-&gt;m_AudioTrackInfo.rate);
1876 
1877     if (pPipeline-&gt;m_AudioTrackInfo.mimeType.find(&quot;mpeg&quot;) != string::npos)
1878     {
1879         ready &amp;= gst_structure_get_int(pStructure, &quot;mpegversion&quot;, &amp;pPipeline-&gt;m_AudioTrackInfo.mpegversion);
1880         gst_structure_get_int(pStructure, &quot;layer&quot;, &amp;pPipeline-&gt;m_AudioTrackInfo.layer); // Layer is optional.
1881     }
1882 
1883     if (ready)
1884     {
1885         pPipeline-&gt;SendTrackEvent();
1886 
1887         if (pPipeline-&gt;m_audioSourcePadProbeHID)    // Remove source probe if any because we&#39;ve got all we need.
1888         {
1889             GstPad *pPad = gst_element_get_static_pad(pPipeline-&gt;m_Elements[AUDIO_DECODER], &quot;src&quot;);
1890             gst_pad_remove_probe (pPad, pPipeline-&gt;m_audioSourcePadProbeHID);
1891             gst_object_unref(pPad);
1892         }
1893     }
1894 
1895     if (pCaps != NULL)
1896         gst_caps_unref(pCaps);
1897 
1898     return GST_PAD_PROBE_REMOVE;
1899 }
1900 
1901 GstPadProbeReturn CGstAudioPlaybackPipeline::AudioSourcePadProbe(GstPad* pPad, GstPadProbeInfo *pInfo, CGstAudioPlaybackPipeline* pPipeline)
1902 {
1903     GstPadProbeReturn ret = GST_PAD_PROBE_OK;
1904     GstStructure *pStructure = NULL;
1905     GstCaps* pCaps = NULL;
1906 
1907     // Make sure we got requested probe
1908     if ((pInfo-&gt;type &amp; GST_PAD_PROBE_TYPE_BUFFER) != GST_PAD_PROBE_TYPE_BUFFER || pInfo-&gt;data == NULL)
1909         goto exit;
1910 
1911     pCaps = gst_pad_get_current_caps(pPad);
1912     if (NULL == pCaps || gst_caps_get_size(pCaps) &lt; 1)
1913         goto exit;
1914 
1915     pStructure = gst_caps_get_structure(pCaps, 0);
1916 
1917     // Here we only fill in empty fields. All fields would be empty if this is the only track test probe.
1918     if (pPipeline-&gt;m_AudioTrackInfo.mimeType.empty())
1919         pPipeline-&gt;m_AudioTrackInfo.mimeType = gst_structure_get_name(pStructure);
1920 
1921     if (pPipeline-&gt;m_AudioTrackInfo.channels &lt; 0)
1922         gst_structure_get_int(pStructure, &quot;channels&quot;, &amp;pPipeline-&gt;m_AudioTrackInfo.channels);
1923 
1924     if (pPipeline-&gt;m_AudioTrackInfo.rate &lt; 0)
1925       gst_structure_get_int(pStructure, &quot;rate&quot;, &amp;pPipeline-&gt;m_AudioTrackInfo.rate);
1926 
1927     if (pPipeline-&gt;m_AudioTrackInfo.mimeType.find(&quot;mpeg&quot;) != string::npos)
1928     {
1929         if (pPipeline-&gt;m_AudioTrackInfo.mpegversion &lt; 0)
1930             gst_structure_get_int(pStructure, &quot;mpegversion&quot;, &amp;pPipeline-&gt;m_AudioTrackInfo.mpegversion);
1931 
1932         if (pPipeline-&gt;m_AudioTrackInfo.layer &lt; 0)
1933             gst_structure_get_int(pStructure, &quot;layer&quot;, &amp;pPipeline-&gt;m_AudioTrackInfo.layer);
1934     }
1935 
1936     pPipeline-&gt;SendTrackEvent(); // Send track event anyways. We won&#39;t get any more information.
1937 
1938     ret = GST_PAD_PROBE_REMOVE; // Don&#39;t discard the data.
1939 
1940 exit:
1941     if (pCaps != NULL)
1942         gst_caps_unref(pCaps);
1943 
1944     return ret;
1945 }
1946 
1947 #if ENABLE_PROGRESS_BUFFER
1948 // This callback is called when progressbuffer runs out of data.
1949 // This can happen when we running out of data during playback, because we cannot download data fast enough.
1950 void CGstAudioPlaybackPipeline::BufferUnderrun()
1951 {
1952     if (IsPlayerState(Stalled) || IsPlayerState(Ready) || IsPlayerState(Error))
1953         return;
1954 
1955     GstState state, pending_state;
1956     gst_element_get_state(m_Elements[PIPELINE], &amp;state, &amp;pending_state, 0);
1957 
1958     bool finished = IsPlayerState(Finished);
1959     double streamTime;
1960     GetStreamTime(&amp;streamTime);
1961 
1962     m_StallLock-&gt;Enter();
1963     // Make sure we do not have more data in progress buffer.
1964     // Stall is valid only in PLAY state, when we do seek, pipeline will be in PAUSED state.
1965     // Stall is not valid in Finished state, but pipeline will be in PLAY state, when we in Finsihed state.
1966     bool suspend = m_BufferPosition &gt; 0 &amp;&amp;
1967                    state == GST_STATE_PLAYING &amp;&amp; pending_state != GST_STATE_PAUSED &amp;&amp;
1968                    !m_bLastProgressValueEOS &amp;&amp;
1969                    !finished;
1970 
1971     m_StallLock-&gt;Exit();
1972 
1973     if (suspend)
1974     {
1975         m_StallOnPause = true;
1976         InternalPause();
1977     }
1978 }
1979 
1980 // We do not need to protect this function with mutex, because we
1981 // call it from only one thread (BusCallback).
1982 void CGstAudioPlaybackPipeline::UpdateBufferPosition()
1983 {
1984     if (NULL != m_pEventDispatcher &amp;&amp; m_llLastProgressValueStop &gt; 0)
1985     {
1986         double duration;
1987         GetDuration(&amp;duration);
1988 
1989         if (!m_pEventDispatcher-&gt;SendBufferProgressEvent(duration, m_llLastProgressValueStart,
1990             m_llLastProgressValueStop, m_llLastProgressValuePosition))
1991         {
1992             if(!m_pEventDispatcher-&gt;SendPlayerMediaErrorEvent(ERROR_JNI_SEND_BUFFER_PROGRESS_EVENT))
1993             {
1994                 LOGGER_LOGMSG(LOGGER_ERROR, &quot;Cannot send media error event.\n&quot;);
1995             }
1996         }
1997 
1998         double bufferPosition = duration * m_llLastProgressValuePosition/m_llLastProgressValueStop;
1999 
2000         double streamTime;
2001         GetStreamTime(&amp;streamTime);
2002 
2003         m_StallLock-&gt;Enter();
2004         m_BufferPosition = bufferPosition;
2005         m_StallLock-&gt;Exit();
2006 
2007         // We need to unblock when we have atleast data for duration of m_dResumeDeltaTime or
2008         // if progress buffer got eos, since buffer position will not be updated anymore and no more data will be available.
2009         bool resume = IsPlayerState(Stalled) &amp;&amp; ((bufferPosition - streamTime &gt; m_dResumeDeltaTime) || m_bLastProgressValueEOS) &amp;&amp; !IsPlayerPendingState(Paused) &amp;&amp; !IsPlayerPendingState(Stopped);
2010 
2011         if (resume)
2012         {
2013             Play();
2014         }
2015     }
2016 }
2017 
2018 void CGstAudioPlaybackPipeline::HLSBufferStall()
2019 {
2020     if (!IsPlayerState(Playing))
2021         return;
2022 
2023     GstState state, pending_state;
2024     gst_element_get_state(m_Elements[PIPELINE], &amp;state, &amp;pending_state, 0);
2025 
2026     m_StallLock-&gt;Enter();
2027     // Stall is valid only in PLAY state, when we do seek, pipeline will be in PAUSED state.
2028     bool suspend = (state == GST_STATE_PLAYING) &amp;&amp; (pending_state == GST_STATE_VOID_PENDING) &amp;&amp; !m_bLastProgressValueEOS &amp;&amp; !m_bHLSPBFull;
2029     m_StallLock-&gt;Exit();
2030 
2031     if (suspend)
2032     {
2033         m_StallOnPause = true;
2034         InternalPause();
2035     }
2036 }
2037 
2038 void CGstAudioPlaybackPipeline::HLSBufferResume(bool bEOS)
2039 {
2040     m_StallLock-&gt;Enter();
2041     if (bEOS)
2042         m_bLastProgressValueEOS = bEOS;
2043     bool resume = (IsPlayerState(Stalled) &amp;&amp; !IsPlayerPendingState(Paused) &amp;&amp; !IsPlayerPendingState(Stopped)) || (m_bLastProgressValueEOS &amp;&amp; IsPlayerState(Playing) &amp;&amp; !IsPlayerPendingState(Paused) &amp;&amp; !IsPlayerPendingState(Stopped));
2044     m_StallLock-&gt;Exit();
2045 
2046     if (resume)
2047     {
2048         Play();
2049     }
2050 }
2051 #endif // ENABLE_PROGRESS_BUFFER
    </pre>
  </body>
</html>