<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/oops/compressedOops.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../memory/universe.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="compressedOops.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/oops/compressedOops.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 49   // This also makes implicit null checking work, because the
 50   // memory+1 page below heap_base needs to cause a signal.
 51   // See needs_explicit_null_check.
 52   // Only set the heap base for compressed oops because it indicates
 53   // compressed oops for pstack code.
 54   if ((uint64_t)heap_space.end() &gt; UnscaledOopHeapMax) {
 55     // Didn&#39;t reserve heap below 4Gb.  Must shift.
 56     set_shift(LogMinObjAlignmentInBytes);
 57   }
 58   if ((uint64_t)heap_space.end() &lt;= OopEncodingHeapMax) {
 59     // Did reserve heap below 32Gb. Can use base == 0;
 60     set_base(0);
 61   } else {
 62     set_base((address)heap_space.compressed_oop_base());
 63   }
 64 
 65   AOTLoader::set_narrow_oop_shift();
 66 
 67   _heap_address_range = heap_space.region();
 68 
<span class="line-modified"> 69   LogTarget(Info, gc, heap, coops) lt;</span>
 70   if (lt.is_enabled()) {
 71     ResourceMark rm;
 72     LogStream ls(lt);
 73     print_mode(&amp;ls);
 74   }
 75 
 76   // Tell tests in which mode we run.
 77   Arguments::PropertyList_add(new SystemProperty(&quot;java.vm.compressedOopsMode&quot;,
 78                                                  mode_to_string(mode()),
 79                                                  false));
 80 
 81   // base() is one page below the heap.
 82   assert((intptr_t)base() &lt;= ((intptr_t)_heap_address_range.start() - os::vm_page_size()) ||
 83          base() == NULL, &quot;invalid value&quot;);
 84   assert(shift() == LogMinObjAlignmentInBytes ||
 85          shift() == 0, &quot;invalid value&quot;);
 86 #endif
 87 }
 88 
 89 void CompressedOops::set_base(address base) {
</pre>
<hr />
<pre>
165   st-&gt;print(&quot;, Compressed Oops mode: %s&quot;, mode_to_string(mode()));
166 
167   if (base() != 0) {
168     st-&gt;print(&quot;: &quot; PTR_FORMAT, p2i(base()));
169   }
170 
171   if (shift() != 0) {
172     st-&gt;print(&quot;, Oop shift amount: %d&quot;, shift());
173   }
174 
175   if (!use_implicit_null_checks()) {
176     st-&gt;print(&quot;, no protected page in front of the heap&quot;);
177   }
178   st-&gt;cr();
179 }
180 
181 // For UseCompressedClassPointers.
182 NarrowPtrStruct CompressedKlassPointers::_narrow_klass = { NULL, 0, true };
183 
184 // CompressedClassSpaceSize set to 1GB, but appear 3GB away from _narrow_ptrs_base during CDS dump.
<span class="line-modified">185 uint64_t CompressedKlassPointers::_narrow_klass_range = (uint64_t(max_juint)+1);;</span>
































































































186 
187 void CompressedKlassPointers::set_base(address base) {
188   assert(UseCompressedClassPointers, &quot;no compressed klass ptrs?&quot;);
189   _narrow_klass._base   = base;
190 }
191 
192 void CompressedKlassPointers::set_shift(int shift)       {
193   assert(shift == 0 || shift == LogKlassAlignmentInBytes, &quot;invalid shift for klass ptrs&quot;);
194   _narrow_klass._shift   = shift;
195 }
196 
<span class="line-modified">197 void CompressedKlassPointers::set_range(uint64_t range) {</span>
198   assert(UseCompressedClassPointers, &quot;no compressed klass ptrs?&quot;);
<span class="line-modified">199   _narrow_klass_range = range;</span>
200 }
</pre>
</td>
<td>
<hr />
<pre>
 49   // This also makes implicit null checking work, because the
 50   // memory+1 page below heap_base needs to cause a signal.
 51   // See needs_explicit_null_check.
 52   // Only set the heap base for compressed oops because it indicates
 53   // compressed oops for pstack code.
 54   if ((uint64_t)heap_space.end() &gt; UnscaledOopHeapMax) {
 55     // Didn&#39;t reserve heap below 4Gb.  Must shift.
 56     set_shift(LogMinObjAlignmentInBytes);
 57   }
 58   if ((uint64_t)heap_space.end() &lt;= OopEncodingHeapMax) {
 59     // Did reserve heap below 32Gb. Can use base == 0;
 60     set_base(0);
 61   } else {
 62     set_base((address)heap_space.compressed_oop_base());
 63   }
 64 
 65   AOTLoader::set_narrow_oop_shift();
 66 
 67   _heap_address_range = heap_space.region();
 68 
<span class="line-modified"> 69   LogTarget(Debug, gc, heap, coops) lt;</span>
 70   if (lt.is_enabled()) {
 71     ResourceMark rm;
 72     LogStream ls(lt);
 73     print_mode(&amp;ls);
 74   }
 75 
 76   // Tell tests in which mode we run.
 77   Arguments::PropertyList_add(new SystemProperty(&quot;java.vm.compressedOopsMode&quot;,
 78                                                  mode_to_string(mode()),
 79                                                  false));
 80 
 81   // base() is one page below the heap.
 82   assert((intptr_t)base() &lt;= ((intptr_t)_heap_address_range.start() - os::vm_page_size()) ||
 83          base() == NULL, &quot;invalid value&quot;);
 84   assert(shift() == LogMinObjAlignmentInBytes ||
 85          shift() == 0, &quot;invalid value&quot;);
 86 #endif
 87 }
 88 
 89 void CompressedOops::set_base(address base) {
</pre>
<hr />
<pre>
165   st-&gt;print(&quot;, Compressed Oops mode: %s&quot;, mode_to_string(mode()));
166 
167   if (base() != 0) {
168     st-&gt;print(&quot;: &quot; PTR_FORMAT, p2i(base()));
169   }
170 
171   if (shift() != 0) {
172     st-&gt;print(&quot;, Oop shift amount: %d&quot;, shift());
173   }
174 
175   if (!use_implicit_null_checks()) {
176     st-&gt;print(&quot;, no protected page in front of the heap&quot;);
177   }
178   st-&gt;cr();
179 }
180 
181 // For UseCompressedClassPointers.
182 NarrowPtrStruct CompressedKlassPointers::_narrow_klass = { NULL, 0, true };
183 
184 // CompressedClassSpaceSize set to 1GB, but appear 3GB away from _narrow_ptrs_base during CDS dump.
<span class="line-modified">185 // (Todo: we should #ifdef out CompressedKlassPointers for 32bit completely and fix all call sites which</span>
<span class="line-added">186 //  are compiled for 32bit to LP64_ONLY).</span>
<span class="line-added">187 size_t CompressedKlassPointers::_range = 0;</span>
<span class="line-added">188 </span>
<span class="line-added">189 </span>
<span class="line-added">190 // Given an address range [addr, addr+len) which the encoding is supposed to</span>
<span class="line-added">191 //  cover, choose base, shift and range.</span>
<span class="line-added">192 //  The address range is the expected range of uncompressed Klass pointers we</span>
<span class="line-added">193 //  will encounter (and the implicit promise that there will be no Klass</span>
<span class="line-added">194 //  structures outside this range).</span>
<span class="line-added">195 void CompressedKlassPointers::initialize(address addr, size_t len) {</span>
<span class="line-added">196 #ifdef _LP64</span>
<span class="line-added">197   assert(is_valid_base(addr), &quot;Address must be a valid encoding base&quot;);</span>
<span class="line-added">198   address const end = addr + len;</span>
<span class="line-added">199 </span>
<span class="line-added">200   address base;</span>
<span class="line-added">201   int shift;</span>
<span class="line-added">202   size_t range;</span>
<span class="line-added">203 </span>
<span class="line-added">204   if (UseSharedSpaces || DumpSharedSpaces) {</span>
<span class="line-added">205 </span>
<span class="line-added">206     // Special requirements if CDS is active:</span>
<span class="line-added">207     // Encoding base and shift must be the same between dump and run time.</span>
<span class="line-added">208     //   CDS takes care that the SharedBaseAddress and CompressedClassSpaceSize</span>
<span class="line-added">209     //   are the same. Archive size will be probably different at runtime, but</span>
<span class="line-added">210     //   it can only be smaller than at, never larger, since archives get</span>
<span class="line-added">211     //   shrunk at the end of the dump process.</span>
<span class="line-added">212     //   From that it follows that the range [addr, len) we are handed in at</span>
<span class="line-added">213     //   runtime will start at the same address then at dumptime, and its len</span>
<span class="line-added">214     //   may be smaller at runtime then it was at dump time.</span>
<span class="line-added">215     //</span>
<span class="line-added">216     // To be very careful here, we avoid any optimizations and just keep using</span>
<span class="line-added">217     //  the same address and shift value. Specifically we avoid using zero-based</span>
<span class="line-added">218     //  encoding. We also set the expected value range to 4G (encoding range</span>
<span class="line-added">219     //  cannot be larger than that).</span>
<span class="line-added">220 </span>
<span class="line-added">221     base = addr;</span>
<span class="line-added">222     shift = LogKlassAlignmentInBytes;</span>
<span class="line-added">223 </span>
<span class="line-added">224     // This must be true since at dumptime cds+ccs is 4G, at runtime it can</span>
<span class="line-added">225     //  only be smaller, see comment above.</span>
<span class="line-added">226     assert(len &lt;= 4 * G, &quot;Encoding range cannot be larger than 4G&quot;);</span>
<span class="line-added">227     range = 4 * G;</span>
<span class="line-added">228 </span>
<span class="line-added">229   } else {</span>
<span class="line-added">230 </span>
<span class="line-added">231     // Otherwise we attempt to use a zero base if the range fits in lower 32G.</span>
<span class="line-added">232     if (end &lt;= (address)KlassEncodingMetaspaceMax) {</span>
<span class="line-added">233       base = 0;</span>
<span class="line-added">234     } else {</span>
<span class="line-added">235       base = addr;</span>
<span class="line-added">236     }</span>
<span class="line-added">237 </span>
<span class="line-added">238     // Highest offset a Klass* can ever have in relation to base.</span>
<span class="line-added">239     range = end - base;</span>
<span class="line-added">240 </span>
<span class="line-added">241     // We may not even need a shift if the range fits into 32bit:</span>
<span class="line-added">242     const uint64_t UnscaledClassSpaceMax = (uint64_t(max_juint) + 1);</span>
<span class="line-added">243     if (range &lt; UnscaledClassSpaceMax) {</span>
<span class="line-added">244       shift = 0;</span>
<span class="line-added">245     } else {</span>
<span class="line-added">246       shift = LogKlassAlignmentInBytes;</span>
<span class="line-added">247     }</span>
<span class="line-added">248 </span>
<span class="line-added">249   }</span>
<span class="line-added">250 </span>
<span class="line-added">251   set_base(base);</span>
<span class="line-added">252   set_shift(shift);</span>
<span class="line-added">253   set_range(range);</span>
<span class="line-added">254 </span>
<span class="line-added">255   // Note: this may modify our shift.</span>
<span class="line-added">256   AOTLoader::set_narrow_klass_shift();</span>
<span class="line-added">257 #else</span>
<span class="line-added">258   fatal(&quot;64bit only.&quot;);</span>
<span class="line-added">259 #endif</span>
<span class="line-added">260 }</span>
<span class="line-added">261 </span>
<span class="line-added">262 // Given an address p, return true if p can be used as an encoding base.</span>
<span class="line-added">263 //  (Some platforms have restrictions of what constitutes a valid base address).</span>
<span class="line-added">264 bool CompressedKlassPointers::is_valid_base(address p) {</span>
<span class="line-added">265 #ifdef AARCH64</span>
<span class="line-added">266   // Below 32G, base must be aligned to 4G.</span>
<span class="line-added">267   // Above that point, base must be aligned to 32G</span>
<span class="line-added">268   if (p &lt; (address)(32 * G)) {</span>
<span class="line-added">269     return is_aligned(p, 4 * G);</span>
<span class="line-added">270   }</span>
<span class="line-added">271   return is_aligned(p, (4 &lt;&lt; LogKlassAlignmentInBytes) * G);</span>
<span class="line-added">272 #else</span>
<span class="line-added">273   return true;</span>
<span class="line-added">274 #endif</span>
<span class="line-added">275 }</span>
<span class="line-added">276 </span>
<span class="line-added">277 void CompressedKlassPointers::print_mode(outputStream* st) {</span>
<span class="line-added">278   st-&gt;print_cr(&quot;Narrow klass base: &quot; PTR_FORMAT &quot;, Narrow klass shift: %d, &quot;</span>
<span class="line-added">279                &quot;Narrow klass range: &quot; SIZE_FORMAT_HEX, p2i(base()), shift(),</span>
<span class="line-added">280                range());</span>
<span class="line-added">281 }</span>
282 
283 void CompressedKlassPointers::set_base(address base) {
284   assert(UseCompressedClassPointers, &quot;no compressed klass ptrs?&quot;);
285   _narrow_klass._base   = base;
286 }
287 
288 void CompressedKlassPointers::set_shift(int shift)       {
289   assert(shift == 0 || shift == LogKlassAlignmentInBytes, &quot;invalid shift for klass ptrs&quot;);
290   _narrow_klass._shift   = shift;
291 }
292 
<span class="line-modified">293 void CompressedKlassPointers::set_range(size_t range) {</span>
294   assert(UseCompressedClassPointers, &quot;no compressed klass ptrs?&quot;);
<span class="line-modified">295   _range = range;</span>
296 }
</pre>
</td>
</tr>
</table>
<center><a href="../memory/universe.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="compressedOops.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>