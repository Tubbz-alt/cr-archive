<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/shenandoah/shenandoahHeapRegion.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="shenandoahHeap.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahNMethod.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shenandoah/shenandoahHeapRegion.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
592   // before moving the allocation to region #N+1.
593   //
594   // The worst case realizes when &quot;answer&quot; is &quot;region size&quot;, which means it could
595   // prematurely retire an entire region. Having smaller TLABs does not fix that
596   // completely, but reduces the probability of too wasteful region retirement.
597   // With current divisor, we will waste no more than 1/8 of region size in the worst
598   // case. This also has a secondary effect on collection set selection: even under
599   // the race, the regions would be at least 7/8 used, which allows relying on
600   // &quot;used&quot; - &quot;live&quot; for cset selection. Otherwise, we can get the fragmented region
601   // below the garbage threshold that would never be considered for collection.
602   //
603   // The whole thing is mitigated if Elastic TLABs are enabled.
604   //
605   guarantee(MaxTLABSizeWords == 0, &quot;we should only set it once&quot;);
606   MaxTLABSizeWords = MIN2(ShenandoahElasticTLAB ? RegionSizeWords : (RegionSizeWords / 8), HumongousThresholdWords);
607   MaxTLABSizeWords = align_down(MaxTLABSizeWords, MinObjAlignment);
608 
609   guarantee(MaxTLABSizeBytes == 0, &quot;we should only set it once&quot;);
610   MaxTLABSizeBytes = MaxTLABSizeWords * HeapWordSize;
611   assert (MaxTLABSizeBytes &gt; MinTLABSize, &quot;should be larger&quot;);
<span class="line-removed">612 </span>
<span class="line-removed">613   log_info(gc, init)(&quot;Regions: &quot; SIZE_FORMAT &quot; x &quot; SIZE_FORMAT &quot;%s&quot;,</span>
<span class="line-removed">614                      RegionCount, byte_size_in_proper_unit(RegionSizeBytes), proper_unit_for_byte_size(RegionSizeBytes));</span>
<span class="line-removed">615   log_info(gc, init)(&quot;Humongous object threshold: &quot; SIZE_FORMAT &quot;%s&quot;,</span>
<span class="line-removed">616                      byte_size_in_proper_unit(HumongousThresholdBytes), proper_unit_for_byte_size(HumongousThresholdBytes));</span>
<span class="line-removed">617   log_info(gc, init)(&quot;Max TLAB size: &quot; SIZE_FORMAT &quot;%s&quot;,</span>
<span class="line-removed">618                      byte_size_in_proper_unit(MaxTLABSizeBytes), proper_unit_for_byte_size(MaxTLABSizeBytes));</span>
619 }
620 
621 void ShenandoahHeapRegion::do_commit() {
622   ShenandoahHeap* heap = ShenandoahHeap::heap();
623   if (!heap-&gt;is_heap_region_special() &amp;&amp; !os::commit_memory((char *) bottom(), RegionSizeBytes, false)) {
624     report_java_out_of_memory(&quot;Unable to commit region&quot;);
625   }
626   if (!heap-&gt;commit_bitmap_slice(this)) {
627     report_java_out_of_memory(&quot;Unable to commit bitmaps for region&quot;);
628   }



629   heap-&gt;increase_committed(ShenandoahHeapRegion::region_size_bytes());
630 }
631 
632 void ShenandoahHeapRegion::do_uncommit() {
633   ShenandoahHeap* heap = ShenandoahHeap::heap();
634   if (!heap-&gt;is_heap_region_special() &amp;&amp; !os::uncommit_memory((char *) bottom(), RegionSizeBytes)) {
635     report_java_out_of_memory(&quot;Unable to uncommit region&quot;);
636   }
637   if (!heap-&gt;uncommit_bitmap_slice(this)) {
638     report_java_out_of_memory(&quot;Unable to uncommit bitmaps for region&quot;);
639   }
640   heap-&gt;decrease_committed(ShenandoahHeapRegion::region_size_bytes());
641 }
642 
643 void ShenandoahHeapRegion::set_state(RegionState to) {
644   EventShenandoahHeapRegionStateChange evt;
645   if (evt.should_commit()){
646     evt.set_index((unsigned) index());
647     evt.set_start((uintptr_t)bottom());
648     evt.set_used(used());
</pre>
</td>
<td>
<hr />
<pre>
592   // before moving the allocation to region #N+1.
593   //
594   // The worst case realizes when &quot;answer&quot; is &quot;region size&quot;, which means it could
595   // prematurely retire an entire region. Having smaller TLABs does not fix that
596   // completely, but reduces the probability of too wasteful region retirement.
597   // With current divisor, we will waste no more than 1/8 of region size in the worst
598   // case. This also has a secondary effect on collection set selection: even under
599   // the race, the regions would be at least 7/8 used, which allows relying on
600   // &quot;used&quot; - &quot;live&quot; for cset selection. Otherwise, we can get the fragmented region
601   // below the garbage threshold that would never be considered for collection.
602   //
603   // The whole thing is mitigated if Elastic TLABs are enabled.
604   //
605   guarantee(MaxTLABSizeWords == 0, &quot;we should only set it once&quot;);
606   MaxTLABSizeWords = MIN2(ShenandoahElasticTLAB ? RegionSizeWords : (RegionSizeWords / 8), HumongousThresholdWords);
607   MaxTLABSizeWords = align_down(MaxTLABSizeWords, MinObjAlignment);
608 
609   guarantee(MaxTLABSizeBytes == 0, &quot;we should only set it once&quot;);
610   MaxTLABSizeBytes = MaxTLABSizeWords * HeapWordSize;
611   assert (MaxTLABSizeBytes &gt; MinTLABSize, &quot;should be larger&quot;);







612 }
613 
614 void ShenandoahHeapRegion::do_commit() {
615   ShenandoahHeap* heap = ShenandoahHeap::heap();
616   if (!heap-&gt;is_heap_region_special() &amp;&amp; !os::commit_memory((char *) bottom(), RegionSizeBytes, false)) {
617     report_java_out_of_memory(&quot;Unable to commit region&quot;);
618   }
619   if (!heap-&gt;commit_bitmap_slice(this)) {
620     report_java_out_of_memory(&quot;Unable to commit bitmaps for region&quot;);
621   }
<span class="line-added">622   if (AlwaysPreTouch) {</span>
<span class="line-added">623     os::pretouch_memory(bottom(), end(), heap-&gt;pretouch_heap_page_size());</span>
<span class="line-added">624   }</span>
625   heap-&gt;increase_committed(ShenandoahHeapRegion::region_size_bytes());
626 }
627 
628 void ShenandoahHeapRegion::do_uncommit() {
629   ShenandoahHeap* heap = ShenandoahHeap::heap();
630   if (!heap-&gt;is_heap_region_special() &amp;&amp; !os::uncommit_memory((char *) bottom(), RegionSizeBytes)) {
631     report_java_out_of_memory(&quot;Unable to uncommit region&quot;);
632   }
633   if (!heap-&gt;uncommit_bitmap_slice(this)) {
634     report_java_out_of_memory(&quot;Unable to uncommit bitmaps for region&quot;);
635   }
636   heap-&gt;decrease_committed(ShenandoahHeapRegion::region_size_bytes());
637 }
638 
639 void ShenandoahHeapRegion::set_state(RegionState to) {
640   EventShenandoahHeapRegionStateChange evt;
641   if (evt.should_commit()){
642     evt.set_index((unsigned) index());
643     evt.set_start((uintptr_t)bottom());
644     evt.set_used(used());
</pre>
</td>
</tr>
</table>
<center><a href="shenandoahHeap.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahNMethod.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>