<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.core.amd64/src/org/graalvm/compiler/core/amd64/AMD64LIRGenerator.java</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (c) 2009, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 
 25 
 26 package org.graalvm.compiler.core.amd64;
 27 
 28 import static jdk.vm.ci.code.ValueUtil.asRegister;
 29 import static jdk.vm.ci.code.ValueUtil.isAllocatableValue;
 30 import static jdk.vm.ci.code.ValueUtil.isRegister;
 31 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.BYTE;
 32 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.DWORD;
 33 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.PD;
 34 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.PS;
 35 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.QWORD;
 36 import static org.graalvm.compiler.core.common.GraalOptions.GeneratePIC;
 37 import static org.graalvm.compiler.lir.LIRValueUtil.asConstant;
 38 import static org.graalvm.compiler.lir.LIRValueUtil.asConstantValue;
 39 import static org.graalvm.compiler.lir.LIRValueUtil.asJavaConstant;
 40 import static org.graalvm.compiler.lir.LIRValueUtil.isConstantValue;
 41 import static org.graalvm.compiler.lir.LIRValueUtil.isIntConstant;
 42 import static org.graalvm.compiler.lir.LIRValueUtil.isJavaConstant;
 43 
 44 import java.util.Optional;
 45 
 46 import org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64BinaryArithmetic;
 47 import org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64MIOp;
 48 import org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp;
 49 import org.graalvm.compiler.asm.amd64.AMD64Assembler.ConditionFlag;
 50 import org.graalvm.compiler.asm.amd64.AMD64Assembler.SSEOp;
 51 import org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRMOp;
 52 import org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize;
 53 import org.graalvm.compiler.asm.amd64.AVXKind;
 54 import org.graalvm.compiler.asm.amd64.AVXKind.AVXSize;
 55 import org.graalvm.compiler.core.common.LIRKind;
 56 import org.graalvm.compiler.core.common.NumUtil;
 57 import org.graalvm.compiler.core.common.calc.Condition;
 58 import org.graalvm.compiler.core.common.spi.ForeignCallLinkage;
 59 import org.graalvm.compiler.core.common.spi.LIRKindTool;
 60 import org.graalvm.compiler.debug.GraalError;
 61 import org.graalvm.compiler.lir.ConstantValue;
 62 import org.graalvm.compiler.lir.LIRFrameState;
 63 import org.graalvm.compiler.lir.LIRInstruction;
 64 import org.graalvm.compiler.lir.LIRValueUtil;
 65 import org.graalvm.compiler.lir.LabelRef;
 66 import org.graalvm.compiler.lir.StandardOp.JumpOp;
 67 import org.graalvm.compiler.lir.StandardOp.ZapRegistersOp;
 68 import org.graalvm.compiler.lir.SwitchStrategy;
 69 import org.graalvm.compiler.lir.Variable;
 70 import org.graalvm.compiler.lir.amd64.AMD64AddressValue;
 71 import org.graalvm.compiler.lir.amd64.AMD64ArithmeticLIRGeneratorTool;
 72 import org.graalvm.compiler.lir.amd64.AMD64ArrayCompareToOp;
 73 import org.graalvm.compiler.lir.amd64.AMD64ArrayEqualsOp;
 74 import org.graalvm.compiler.lir.amd64.AMD64ArrayIndexOfOp;
 75 import org.graalvm.compiler.lir.amd64.AMD64Binary;
 76 import org.graalvm.compiler.lir.amd64.AMD64BinaryConsumer;
 77 import org.graalvm.compiler.lir.amd64.AMD64ByteSwapOp;
 78 import org.graalvm.compiler.lir.amd64.AMD64Call;
 79 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow;
 80 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.BranchOp;
 81 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.CmpBranchOp;
 82 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.CmpConstBranchOp;
 83 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.CmpDataBranchOp;
 84 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.CondMoveOp;
 85 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.CondSetOp;
 86 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.FloatBranchOp;
 87 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.FloatCondMoveOp;
 88 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.FloatCondSetOp;
 89 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.HashTableSwitchOp;
 90 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.ReturnOp;
 91 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.StrategySwitchOp;
 92 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.TableSwitchOp;
 93 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.TestBranchOp;
 94 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.TestByteBranchOp;
 95 import org.graalvm.compiler.lir.amd64.AMD64ControlFlow.TestConstBranchOp;
 96 import org.graalvm.compiler.lir.amd64.AMD64LFenceOp;
 97 import org.graalvm.compiler.lir.amd64.AMD64Move;
 98 import org.graalvm.compiler.lir.amd64.AMD64Move.CompareAndSwapOp;
 99 import org.graalvm.compiler.lir.amd64.AMD64Move.MembarOp;
100 import org.graalvm.compiler.lir.amd64.AMD64Move.StackLeaOp;
101 import org.graalvm.compiler.lir.amd64.AMD64PauseOp;
102 import org.graalvm.compiler.lir.amd64.AMD64StringLatin1InflateOp;
103 import org.graalvm.compiler.lir.amd64.AMD64StringUTF16CompressOp;
104 import org.graalvm.compiler.lir.amd64.AMD64ZapRegistersOp;
105 import org.graalvm.compiler.lir.amd64.AMD64ZapStackOp;
106 import org.graalvm.compiler.lir.amd64.AMD64ZeroMemoryOp;
107 import org.graalvm.compiler.lir.amd64.vector.AMD64VectorCompareOp;
108 import org.graalvm.compiler.lir.gen.LIRGenerationResult;
109 import org.graalvm.compiler.lir.gen.LIRGenerator;
110 import org.graalvm.compiler.lir.hashing.Hasher;
111 import org.graalvm.compiler.phases.util.Providers;
112 
113 import jdk.vm.ci.amd64.AMD64;
114 import jdk.vm.ci.amd64.AMD64Kind;
115 import jdk.vm.ci.code.CallingConvention;
116 import jdk.vm.ci.code.Register;
117 import jdk.vm.ci.code.RegisterValue;
118 import jdk.vm.ci.code.StackSlot;
119 import jdk.vm.ci.meta.AllocatableValue;
120 import jdk.vm.ci.meta.Constant;
121 import jdk.vm.ci.meta.JavaConstant;
122 import jdk.vm.ci.meta.JavaKind;
123 import jdk.vm.ci.meta.PlatformKind;
124 import jdk.vm.ci.meta.VMConstant;
125 import jdk.vm.ci.meta.Value;
126 import jdk.vm.ci.meta.ValueKind;
127 
128 /**
129  * This class implements the AMD64 specific portion of the LIR generator.
130  */
131 public abstract class AMD64LIRGenerator extends LIRGenerator {
132 
133     public AMD64LIRGenerator(LIRKindTool lirKindTool, AMD64ArithmeticLIRGenerator arithmeticLIRGen, MoveFactory moveFactory, Providers providers, LIRGenerationResult lirGenRes) {
134         super(lirKindTool, arithmeticLIRGen, moveFactory, providers, lirGenRes);
135     }
136 
137     /**
138      * Checks whether the supplied constant can be used without loading it into a register for store
139      * operations, i.e., on the right hand side of a memory access.
140      *
141      * @param c The constant to check.
142      * @return True if the constant can be used directly, false if the constant needs to be in a
143      *         register.
144      */
145     protected static final boolean canStoreConstant(JavaConstant c) {
146         // there is no immediate move of 64-bit constants on Intel
147         switch (c.getJavaKind()) {
148             case Long:
149                 return NumUtil.isInt(c.asLong());
150             case Double:
151                 return false;
152             case Object:
153                 return c.isNull();
154             default:
155                 return true;
156         }
157     }
158 
159     @Override
160     protected JavaConstant zapValueForKind(PlatformKind kind) {
161         long dead = 0xDEADDEADDEADDEADL;
162         switch ((AMD64Kind) kind) {
163             case BYTE:
164                 return JavaConstant.forByte((byte) dead);
165             case WORD:
166                 return JavaConstant.forShort((short) dead);
167             case DWORD:
168                 return JavaConstant.forInt((int) dead);
169             case QWORD:
170                 return JavaConstant.forLong(dead);
171             case SINGLE:
172                 return JavaConstant.forFloat(Float.intBitsToFloat((int) dead));
173             default:
174                 // we don&#39;t support vector types, so just zap with double for all of them
175                 return JavaConstant.forDouble(Double.longBitsToDouble(dead));
176         }
177     }
178 
179     public AMD64AddressValue asAddressValue(Value address) {
180         if (address instanceof AMD64AddressValue) {
181             return (AMD64AddressValue) address;
182         } else {
183             if (address instanceof JavaConstant) {
184                 long displacement = ((JavaConstant) address).asLong();
185                 if (NumUtil.isInt(displacement)) {
186                     return new AMD64AddressValue(address.getValueKind(), Value.ILLEGAL, (int) displacement);
187                 }
188             }
189             return new AMD64AddressValue(address.getValueKind(), asAllocatable(address), 0);
190         }
191     }
192 
193     @Override
194     public Variable emitAddress(AllocatableValue stackslot) {
195         Variable result = newVariable(LIRKind.value(target().arch.getWordKind()));
196         append(new StackLeaOp(result, stackslot));
197         return result;
198     }
199 
200     /**
201      * The AMD64 backend only uses DWORD and QWORD values in registers because of a performance
202      * penalty when accessing WORD or BYTE registers. This function converts small integer kinds to
203      * DWORD.
204      */
205     @Override
206     public &lt;K extends ValueKind&lt;K&gt;&gt; K toRegisterKind(K kind) {
207         switch ((AMD64Kind) kind.getPlatformKind()) {
208             case BYTE:
209             case WORD:
210                 return kind.changeType(AMD64Kind.DWORD);
211             default:
212                 return kind;
213         }
214     }
215 
216     private AllocatableValue asAllocatable(Value value, ValueKind&lt;?&gt; kind) {
217         if (value.getValueKind().equals(kind)) {
218             return asAllocatable(value);
219         } else if (isRegister(value)) {
220             return asRegister(value).asValue(kind);
221         } else if (isConstantValue(value)) {
222             return emitLoadConstant(kind, asConstant(value));
223         } else {
224             Variable variable = newVariable(kind);
225             emitMove(variable, value);
226             return variable;
227         }
228     }
229 
230     private Value emitCompareAndSwap(boolean isLogic, LIRKind accessKind, Value address, Value expectedValue, Value newValue, Value trueValue, Value falseValue) {
231         ValueKind&lt;?&gt; kind = newValue.getValueKind();
232         assert kind.equals(expectedValue.getValueKind());
233 
234         AMD64AddressValue addressValue = asAddressValue(address);
235         LIRKind integralAccessKind = accessKind;
236         Value reinterpretedExpectedValue = expectedValue;
237         Value reinterpretedNewValue = newValue;
238         boolean isXmm = ((AMD64Kind) accessKind.getPlatformKind()).isXMM();
239         if (isXmm) {
240             if (accessKind.getPlatformKind().equals(AMD64Kind.SINGLE)) {
241                 integralAccessKind = LIRKind.fromJavaKind(target().arch, JavaKind.Int);
242             } else {
243                 integralAccessKind = LIRKind.fromJavaKind(target().arch, JavaKind.Long);
244             }
245             reinterpretedExpectedValue = arithmeticLIRGen.emitReinterpret(integralAccessKind, expectedValue);
246             reinterpretedNewValue = arithmeticLIRGen.emitReinterpret(integralAccessKind, newValue);
247         }
248         AMD64Kind memKind = (AMD64Kind) integralAccessKind.getPlatformKind();
249         RegisterValue aRes = AMD64.rax.asValue(integralAccessKind);
250         AllocatableValue allocatableNewValue = asAllocatable(reinterpretedNewValue, integralAccessKind);
251         emitMove(aRes, reinterpretedExpectedValue);
252         append(new CompareAndSwapOp(memKind, aRes, addressValue, aRes, allocatableNewValue));
253 
254         if (isLogic) {
255             assert trueValue.getValueKind().equals(falseValue.getValueKind());
<a name="1" id="anc1"></a><span class="line-modified">256             Variable result = newVariable(trueValue.getValueKind());</span>
<span class="line-removed">257             append(new CondMoveOp(result, Condition.EQ, asAllocatable(trueValue), falseValue));</span>
<span class="line-removed">258             return result;</span>
259         } else {
260             if (isXmm) {
261                 return arithmeticLIRGen.emitReinterpret(accessKind, aRes);
262             } else {
263                 Variable result = newVariable(kind);
264                 emitMove(result, aRes);
265                 return result;
266             }
267         }
268     }
269 
270     @Override
271     public Variable emitLogicCompareAndSwap(LIRKind accessKind, Value address, Value expectedValue, Value newValue, Value trueValue, Value falseValue) {
272         return (Variable) emitCompareAndSwap(true, accessKind, address, expectedValue, newValue, trueValue, falseValue);
273     }
274 
275     @Override
276     public Value emitValueCompareAndSwap(LIRKind accessKind, Value address, Value expectedValue, Value newValue) {
277         return emitCompareAndSwap(false, accessKind, address, expectedValue, newValue, null, null);
278     }
279 
280     public void emitCompareAndSwapBranch(ValueKind&lt;?&gt; kind, AMD64AddressValue address, Value expectedValue, Value newValue, Condition condition, LabelRef trueLabel, LabelRef falseLabel,
281                     double trueLabelProbability) {
282         assert kind.getPlatformKind().getSizeInBytes() &lt;= expectedValue.getValueKind().getPlatformKind().getSizeInBytes();
283         assert kind.getPlatformKind().getSizeInBytes() &lt;= newValue.getValueKind().getPlatformKind().getSizeInBytes();
284         assert condition == Condition.EQ || condition == Condition.NE;
285         AMD64Kind memKind = (AMD64Kind) kind.getPlatformKind();
286         RegisterValue raxValue = AMD64.rax.asValue(kind);
287         emitMove(raxValue, expectedValue);
288         append(new CompareAndSwapOp(memKind, raxValue, address, raxValue, asAllocatable(newValue)));
289         append(new BranchOp(condition, trueLabel, falseLabel, trueLabelProbability));
290     }
291 
292     @Override
293     public Value emitAtomicReadAndAdd(Value address, ValueKind&lt;?&gt; kind, Value delta) {
294         Variable result = newVariable(kind);
295         AMD64AddressValue addressValue = asAddressValue(address);
296         append(new AMD64Move.AtomicReadAndAddOp((AMD64Kind) kind.getPlatformKind(), result, addressValue, asAllocatable(delta)));
297         return result;
298     }
299 
300     @Override
301     public Value emitAtomicReadAndWrite(Value address, ValueKind&lt;?&gt; kind, Value newValue) {
302         Variable result = newVariable(kind);
303         AMD64AddressValue addressValue = asAddressValue(address);
304         append(new AMD64Move.AtomicReadAndWriteOp((AMD64Kind) kind.getPlatformKind(), result, addressValue, asAllocatable(newValue)));
305         return result;
306     }
307 
308     @Override
309     public void emitNullCheck(Value address, LIRFrameState state) {
310         append(new AMD64Move.NullCheckOp(asAddressValue(address), state));
311     }
312 
313     @Override
314     public void emitJump(LabelRef label) {
315         assert label != null;
316         append(new JumpOp(label));
317     }
318 
319     @Override
320     public void emitCompareBranch(PlatformKind cmpKind, Value left, Value right, Condition cond, boolean unorderedIsTrue, LabelRef trueLabel, LabelRef falseLabel, double trueLabelProbability) {
321         if (cmpKind == AMD64Kind.SINGLE || cmpKind == AMD64Kind.DOUBLE) {
322             Condition finalCondition = emitCompare(cmpKind, left, right, cond);
323             append(new FloatBranchOp(finalCondition, unorderedIsTrue, trueLabel, falseLabel, trueLabelProbability));
324             return;
325         }
326 
327         if (LIRValueUtil.isVariable(right)) {
328             emitRawCompareBranch(OperandSize.get(cmpKind), load(right), loadNonConst(left), cond.mirror(), trueLabel, falseLabel, trueLabelProbability);
329         } else {
330             emitRawCompareBranch(OperandSize.get(cmpKind), load(left), loadNonConst(right), cond, trueLabel, falseLabel, trueLabelProbability);
331         }
332     }
333 
334     private void emitRawCompareBranch(OperandSize size, Variable left, Value right, Condition cond, LabelRef trueLabel, LabelRef falseLabel, double trueLabelProbability) {
335         if (isConstantValue(right)) {
336             Constant c = LIRValueUtil.asConstant(right);
337             if (JavaConstant.isNull(c)) {
338                 AMD64ArithmeticLIRGenerator arithmeticLIRGenerator = (AMD64ArithmeticLIRGenerator) arithmeticLIRGen;
339                 if (arithmeticLIRGenerator.mustReplaceNullWithNullRegister(c)) {
340                     append(new CmpBranchOp(size, left, arithmeticLIRGenerator.getNullRegisterValue(), null, cond, trueLabel, falseLabel, trueLabelProbability));
341                 } else {
342                     append(new TestBranchOp(size, left, left, null, cond, trueLabel, falseLabel, trueLabelProbability));
343                 }
344                 return;
345             } else if (c instanceof VMConstant) {
346                 VMConstant vc = (VMConstant) c;
347                 if (size == DWORD &amp;&amp; !GeneratePIC.getValue(getResult().getLIR().getOptions()) &amp;&amp; target().inlineObjects) {
348                     append(new CmpConstBranchOp(DWORD, left, vc, null, cond, trueLabel, falseLabel, trueLabelProbability));
349                 } else {
350                     append(new CmpDataBranchOp(size, left, vc, cond, trueLabel, falseLabel, trueLabelProbability));
351                 }
352                 return;
353             } else if (c instanceof JavaConstant) {
354                 JavaConstant jc = (JavaConstant) c;
355                 if (jc.isDefaultForKind()) {
356                     if (size == BYTE) {
357                         append(new TestByteBranchOp(left, left, cond, trueLabel, falseLabel, trueLabelProbability));
358                     } else {
359                         append(new TestBranchOp(size, left, left, null, cond, trueLabel, falseLabel, trueLabelProbability));
360                     }
361                     return;
362                 } else if (NumUtil.is32bit(jc.asLong())) {
363                     append(new CmpConstBranchOp(size, left, (int) jc.asLong(), null, cond, trueLabel, falseLabel, trueLabelProbability));
364                     return;
365                 }
366             }
367         }
368 
369         // fallback: load, then compare
370         append(new CmpBranchOp(size, left, asAllocatable(right), null, cond, trueLabel, falseLabel, trueLabelProbability));
371     }
372 
373     public void emitCompareBranchMemory(AMD64Kind cmpKind, Value left, AMD64AddressValue right, LIRFrameState state, Condition cond, boolean unorderedIsTrue, LabelRef trueLabel, LabelRef falseLabel,
374                     double trueLabelProbability) {
375         if (cmpKind.isXMM()) {
376             if (cmpKind == AMD64Kind.SINGLE) {
377                 append(new AMD64BinaryConsumer.MemoryRMOp(SSEOp.UCOMIS, PS, asAllocatable(left), right, state));
378                 append(new FloatBranchOp(cond, unorderedIsTrue, trueLabel, falseLabel, trueLabelProbability));
379             } else if (cmpKind == AMD64Kind.DOUBLE) {
380                 append(new AMD64BinaryConsumer.MemoryRMOp(SSEOp.UCOMIS, PD, asAllocatable(left), right, state));
381                 append(new FloatBranchOp(cond, unorderedIsTrue, trueLabel, falseLabel, trueLabelProbability));
382             } else {
383                 throw GraalError.shouldNotReachHere(&quot;unexpected kind: &quot; + cmpKind);
384             }
385         } else {
386             OperandSize size = OperandSize.get(cmpKind);
387             if (isConstantValue(left)) {
388                 ConstantValue a = asConstantValue(left);
389                 if (JavaConstant.isNull(a.getConstant())) {
390                     append(new CmpConstBranchOp(size, right, 0, state, cond.mirror(), trueLabel, falseLabel, trueLabelProbability));
391                     return;
392                 } else if (a.getConstant() instanceof VMConstant &amp;&amp; size == DWORD &amp;&amp; target().inlineObjects) {
393                     VMConstant vc = (VMConstant) a.getConstant();
394                     append(new CmpConstBranchOp(size, right, vc, state, cond.mirror(), trueLabel, falseLabel, trueLabelProbability));
395                     return;
396                 } else if (a.getConstant() instanceof JavaConstant &amp;&amp; a.getJavaConstant().getJavaKind() != JavaKind.Object) {
397                     long value = a.getJavaConstant().asLong();
398                     if (NumUtil.is32bit(value)) {
399                         append(new CmpConstBranchOp(size, right, (int) value, state, cond.mirror(), trueLabel, falseLabel, trueLabelProbability));
400                         return;
401                     }
402                 }
403             }
404             append(new CmpBranchOp(size, asAllocatable(left), right, state, cond, trueLabel, falseLabel, trueLabelProbability));
405         }
406     }
407 
408     @Override
409     public void emitOverflowCheckBranch(LabelRef overflow, LabelRef noOverflow, LIRKind cmpLIRKind, double overflowProbability) {
410         append(new BranchOp(ConditionFlag.Overflow, overflow, noOverflow, overflowProbability));
411     }
412 
413     @Override
414     public void emitIntegerTestBranch(Value left, Value right, LabelRef trueDestination, LabelRef falseDestination, double trueDestinationProbability) {
415         if (left.getPlatformKind().getVectorLength() &gt; 1) {
416             append(new AMD64VectorCompareOp(VexRMOp.VPTEST, getRegisterSize(left), asAllocatable(left), asAllocatable(right)));
417             append(new BranchOp(Condition.EQ, trueDestination, falseDestination, trueDestinationProbability));
418         } else {
419             assert ((AMD64Kind) left.getPlatformKind()).isInteger();
420             OperandSize size = left.getPlatformKind() == AMD64Kind.QWORD ? QWORD : DWORD;
421             if (isJavaConstant(right) &amp;&amp; NumUtil.is32bit(asJavaConstant(right).asLong())) {
422                 append(new TestConstBranchOp(size, asAllocatable(left), (int) asJavaConstant(right).asLong(), null, Condition.EQ, trueDestination, falseDestination, trueDestinationProbability));
423             } else if (isJavaConstant(left) &amp;&amp; NumUtil.is32bit(asJavaConstant(left).asLong())) {
424                 append(new TestConstBranchOp(size, asAllocatable(right), (int) asJavaConstant(left).asLong(), null, Condition.EQ, trueDestination, falseDestination, trueDestinationProbability));
425             } else if (isAllocatableValue(right)) {
426                 append(new TestBranchOp(size, asAllocatable(right), asAllocatable(left), null, Condition.EQ, trueDestination, falseDestination, trueDestinationProbability));
427             } else {
428                 append(new TestBranchOp(size, asAllocatable(left), asAllocatable(right), null, Condition.EQ, trueDestination, falseDestination, trueDestinationProbability));
429             }
430         }
431     }
432 
433     @Override
434     public Variable emitConditionalMove(PlatformKind cmpKind, Value left, Value right, Condition cond, boolean unorderedIsTrue, Value trueValue, Value falseValue) {
435         boolean isFloatComparison = cmpKind == AMD64Kind.SINGLE || cmpKind == AMD64Kind.DOUBLE;
436 
437         Condition finalCondition = cond;
438         Value finalTrueValue = trueValue;
439         Value finalFalseValue = falseValue;
440         if (isFloatComparison) {
441             // eliminate the parity check in case of a float comparison
442             Value finalLeft = left;
443             Value finalRight = right;
444             if (unorderedIsTrue != AMD64ControlFlow.trueOnUnordered(finalCondition)) {
445                 if (unorderedIsTrue == AMD64ControlFlow.trueOnUnordered(finalCondition.mirror())) {
446                     finalCondition = finalCondition.mirror();
447                     finalLeft = right;
448                     finalRight = left;
449                 } else if (finalCondition != Condition.EQ &amp;&amp; finalCondition != Condition.NE) {
450                     // negating EQ and NE does not make any sense as we would need to negate
451                     // unorderedIsTrue as well (otherwise, we would no longer fulfill the Java
452                     // NaN semantics)
453                     assert unorderedIsTrue == AMD64ControlFlow.trueOnUnordered(finalCondition.negate());
454                     finalCondition = finalCondition.negate();
455                     finalTrueValue = falseValue;
456                     finalFalseValue = trueValue;
457                 }
458             }
459             emitRawCompare(cmpKind, finalLeft, finalRight);
460         } else {
461             finalCondition = emitCompare(cmpKind, left, right, cond);
462         }
463 
<a name="2" id="anc2"></a><span class="line-modified">464         boolean isParityCheckNecessary = isFloatComparison &amp;&amp; unorderedIsTrue != AMD64ControlFlow.trueOnUnordered(finalCondition);</span>
<span class="line-modified">465         Variable result = newVariable(finalTrueValue.getValueKind());</span>
<span class="line-modified">466         if (!isParityCheckNecessary &amp;&amp; isIntConstant(finalTrueValue, 1) &amp;&amp; isIntConstant(finalFalseValue, 0)) {</span>




467             if (isFloatComparison) {
<a name="3" id="anc3"></a><span class="line-modified">468                 append(new FloatCondSetOp(result, finalCondition));</span>
469             } else {
<a name="4" id="anc4"></a><span class="line-modified">470                 append(new CondSetOp(result, finalCondition));</span>
471             }
<a name="5" id="anc5"></a><span class="line-modified">472         } else if (!isParityCheckNecessary &amp;&amp; isIntConstant(finalTrueValue, 0) &amp;&amp; isIntConstant(finalFalseValue, 1)) {</span>
473             if (isFloatComparison) {
<a name="6" id="anc6"></a><span class="line-modified">474                 if (unorderedIsTrue == AMD64ControlFlow.trueOnUnordered(finalCondition.negate())) {</span>
<span class="line-modified">475                     append(new FloatCondSetOp(result, finalCondition.negate()));</span>
476                 } else {
<a name="7" id="anc7"></a><span class="line-modified">477                     append(new FloatCondSetOp(result, finalCondition));</span>
478                     Variable negatedResult = newVariable(result.getValueKind());
479                     append(new AMD64Binary.ConstOp(AMD64BinaryArithmetic.XOR, OperandSize.get(result.getPlatformKind()), negatedResult, result, 1));
480                     result = negatedResult;
481                 }
482             } else {
<a name="8" id="anc8"></a><span class="line-modified">483                 append(new CondSetOp(result, finalCondition.negate()));</span>
484             }
485         } else if (isFloatComparison) {
<a name="9" id="anc9"></a><span class="line-modified">486             append(new FloatCondMoveOp(result, finalCondition, unorderedIsTrue, load(finalTrueValue), load(finalFalseValue)));</span>
487         } else {
<a name="10" id="anc10"></a><span class="line-modified">488             append(new CondMoveOp(result, finalCondition, load(finalTrueValue), loadNonConst(finalFalseValue)));</span>
489         }
490         return result;
491     }
492 
493     @Override
494     public Variable emitIntegerTestMove(Value left, Value right, Value trueValue, Value falseValue) {
495         emitIntegerTest(left, right);
<a name="11" id="anc11"></a><span class="line-modified">496         Variable result = newVariable(trueValue.getValueKind());</span>
<span class="line-removed">497         append(new CondMoveOp(result, Condition.EQ, load(trueValue), loadNonConst(falseValue)));</span>
<span class="line-removed">498         return result;</span>
499     }
500 
501     protected static AVXSize getRegisterSize(Value a) {
502         AMD64Kind kind = (AMD64Kind) a.getPlatformKind();
503         if (kind.isXMM()) {
504             return AVXKind.getRegisterSize(kind);
505         } else {
506             return AVXSize.XMM;
507         }
508     }
509 
510     private void emitIntegerTest(Value a, Value b) {
511         if (a.getPlatformKind().getVectorLength() &gt; 1) {
512             append(new AMD64VectorCompareOp(VexRMOp.VPTEST, getRegisterSize(a), asAllocatable(a), asAllocatable(b)));
513         } else {
514             assert ((AMD64Kind) a.getPlatformKind()).isInteger();
515             OperandSize size = a.getPlatformKind() == AMD64Kind.QWORD ? QWORD : DWORD;
516             if (isJavaConstant(b) &amp;&amp; NumUtil.is32bit(asJavaConstant(b).asLong())) {
517                 append(new AMD64BinaryConsumer.ConstOp(AMD64MIOp.TEST, size, asAllocatable(a), (int) asJavaConstant(b).asLong()));
518             } else if (isJavaConstant(a) &amp;&amp; NumUtil.is32bit(asJavaConstant(a).asLong())) {
519                 append(new AMD64BinaryConsumer.ConstOp(AMD64MIOp.TEST, size, asAllocatable(b), (int) asJavaConstant(a).asLong()));
520             } else if (isAllocatableValue(b)) {
521                 append(new AMD64BinaryConsumer.Op(AMD64RMOp.TEST, size, asAllocatable(b), asAllocatable(a)));
522             } else {
523                 append(new AMD64BinaryConsumer.Op(AMD64RMOp.TEST, size, asAllocatable(a), asAllocatable(b)));
524             }
525         }
526     }
527 
528     /**
529      * This method emits the compare instruction, and may reorder the operands. It returns true if
530      * it did so.
531      *
532      * @param a the left operand of the comparison
533      * @param b the right operand of the comparison
534      * @param cond the condition of the comparison
535      * @return true if the left and right operands were switched, false otherwise
536      */
537     private Condition emitCompare(PlatformKind cmpKind, Value a, Value b, Condition cond) {
538         if (LIRValueUtil.isVariable(b)) {
539             emitRawCompare(cmpKind, b, a);
540             return cond.mirror();
541         } else {
542             emitRawCompare(cmpKind, a, b);
543             return cond;
544         }
545     }
546 
547     private void emitRawCompare(PlatformKind cmpKind, Value left, Value right) {
548         ((AMD64ArithmeticLIRGeneratorTool) arithmeticLIRGen).emitCompareOp((AMD64Kind) cmpKind, load(left), loadNonConst(right));
549     }
550 
551     @Override
552     public void emitMembar(int barriers) {
553         int necessaryBarriers = target().arch.requiredBarriers(barriers);
554         if (target().isMP &amp;&amp; necessaryBarriers != 0) {
555             append(new MembarOp(necessaryBarriers));
556         }
557     }
558 
559     public abstract void emitCCall(long address, CallingConvention nativeCallingConvention, Value[] args, int numberOfFloatingPointArguments);
560 
561     @Override
562     protected void emitForeignCallOp(ForeignCallLinkage linkage, Value result, Value[] arguments, Value[] temps, LIRFrameState info) {
563         long maxOffset = linkage.getMaxCallTargetOffset();
564         if (maxOffset != (int) maxOffset &amp;&amp; !GeneratePIC.getValue(getResult().getLIR().getOptions())) {
565             append(new AMD64Call.DirectFarForeignCallOp(linkage, result, arguments, temps, info));
566         } else {
567             append(new AMD64Call.DirectNearForeignCallOp(linkage, result, arguments, temps, info));
568         }
569     }
570 
571     @Override
572     public Variable emitByteSwap(Value input) {
573         Variable result = newVariable(LIRKind.combine(input));
574         append(new AMD64ByteSwapOp(result, input));
575         return result;
576     }
577 
578     @Override
579     public Variable emitArrayCompareTo(JavaKind kind1, JavaKind kind2, Value array1, Value array2, Value length1, Value length2) {
580         LIRKind resultKind = LIRKind.value(AMD64Kind.DWORD);
581         RegisterValue raxRes = AMD64.rax.asValue(resultKind);
582         RegisterValue cnt1 = AMD64.rcx.asValue(length1.getValueKind());
583         RegisterValue cnt2 = AMD64.rdx.asValue(length2.getValueKind());
584         emitMove(cnt1, length1);
585         emitMove(cnt2, length2);
586         append(new AMD64ArrayCompareToOp(this, getAVX3Threshold(), kind1, kind2, raxRes, array1, array2, cnt1, cnt2));
587         Variable result = newVariable(resultKind);
588         emitMove(result, raxRes);
589         return result;
590     }
591 
592     @Override
593     public Variable emitArrayEquals(JavaKind kind, Value array1, Value array2, Value length, boolean directPointers) {
594         Variable result = newVariable(LIRKind.value(AMD64Kind.DWORD));
595         append(new AMD64ArrayEqualsOp(this, kind, kind, result, array1, array2, length, directPointers, getMaxVectorSize()));
596         return result;
597     }
598 
599     @Override
600     public Variable emitArrayEquals(JavaKind kind1, JavaKind kind2, Value array1, Value array2, Value length, boolean directPointers) {
601         Variable result = newVariable(LIRKind.value(AMD64Kind.DWORD));
602         append(new AMD64ArrayEqualsOp(this, kind1, kind2, result, array1, array2, length, directPointers, getMaxVectorSize()));
603         return result;
604     }
605 
606     /**
607      * Return the maximum size of vector registers used in SSE/AVX instructions.
608      */
609     protected int getMaxVectorSize() {
610         // default for &quot;unlimited&quot;
611         return -1;
612     }
613 
614     /**
615      * Return the minimal array size for using AVX3 instructions.
616      */
617     protected int getAVX3Threshold() {
618         return 4096;
619     }
620 
621     @Override
622     public Variable emitArrayIndexOf(JavaKind arrayKind, JavaKind valueKind, boolean findTwoConsecutive, Value arrayPointer, Value arrayLength, Value fromIndex, Value... searchValues) {
623         Variable result = newVariable(LIRKind.value(AMD64Kind.DWORD));
624         append(new AMD64ArrayIndexOfOp(arrayKind, valueKind, findTwoConsecutive, getMaxVectorSize(), this, result,
625                         asAllocatable(arrayPointer), asAllocatable(arrayLength), asAllocatable(fromIndex), searchValues));
626         return result;
627     }
628 
629     @Override
630     public void emitStringLatin1Inflate(Value src, Value dst, Value len) {
631         RegisterValue rsrc = AMD64.rsi.asValue(src.getValueKind());
632         RegisterValue rdst = AMD64.rdi.asValue(dst.getValueKind());
633         RegisterValue rlen = AMD64.rdx.asValue(len.getValueKind());
634 
635         emitMove(rsrc, src);
636         emitMove(rdst, dst);
637         emitMove(rlen, len);
638 
639         append(new AMD64StringLatin1InflateOp(this, getAVX3Threshold(), rsrc, rdst, rlen));
640     }
641 
642     @Override
643     public Variable emitStringUTF16Compress(Value src, Value dst, Value len) {
644         RegisterValue rsrc = AMD64.rsi.asValue(src.getValueKind());
645         RegisterValue rdst = AMD64.rdi.asValue(dst.getValueKind());
646         RegisterValue rlen = AMD64.rdx.asValue(len.getValueKind());
647 
648         emitMove(rsrc, src);
649         emitMove(rdst, dst);
650         emitMove(rlen, len);
651 
652         LIRKind reskind = LIRKind.value(AMD64Kind.DWORD);
653         RegisterValue rres = AMD64.rax.asValue(reskind);
654 
655         append(new AMD64StringUTF16CompressOp(this, getAVX3Threshold(), rres, rsrc, rdst, rlen));
656 
657         Variable res = newVariable(reskind);
658         emitMove(res, rres);
659         return res;
660     }
661 
662     @Override
663     public void emitReturn(JavaKind kind, Value input) {
664         AllocatableValue operand = Value.ILLEGAL;
665         if (input != null) {
666             operand = resultOperandFor(kind, input.getValueKind());
667             emitMove(operand, input);
668         }
669         append(new ReturnOp(operand));
670     }
671 
672     protected StrategySwitchOp createStrategySwitchOp(SwitchStrategy strategy, LabelRef[] keyTargets, LabelRef defaultTarget, Variable key, AllocatableValue temp) {
673         return new StrategySwitchOp(strategy, keyTargets, defaultTarget, key, temp);
674     }
675 
676     @Override
677     public void emitStrategySwitch(SwitchStrategy strategy, Variable key, LabelRef[] keyTargets, LabelRef defaultTarget) {
678         // a temp is needed for loading object constants
679         boolean needsTemp = !LIRKind.isValue(key);
680         append(createStrategySwitchOp(strategy, keyTargets, defaultTarget, key, needsTemp ? newVariable(key.getValueKind()) : Value.ILLEGAL));
681     }
682 
683     @Override
684     protected void emitTableSwitch(int lowKey, LabelRef defaultTarget, LabelRef[] targets, Value key) {
685         append(new TableSwitchOp(lowKey, defaultTarget, targets, key, newVariable(LIRKind.value(target().arch.getWordKind())), newVariable(key.getValueKind())));
686     }
687 
688     @Override
689     protected Optional&lt;Hasher&gt; hasherFor(JavaConstant[] keyConstants, double minDensity) {
690         return Hasher.forKeys(keyConstants, minDensity);
691     }
692 
693     @Override
694     protected void emitHashTableSwitch(Hasher hasher, JavaConstant[] keys, LabelRef defaultTarget, LabelRef[] targets, Value value) {
695         Value index = hasher.hash(value, arithmeticLIRGen);
696         Variable scratch = newVariable(LIRKind.value(target().arch.getWordKind()));
697         Variable entryScratch = newVariable(LIRKind.value(target().arch.getWordKind()));
698         append(new HashTableSwitchOp(keys, defaultTarget, targets, value, index, scratch, entryScratch));
699     }
700 
701     @Override
702     public void emitPause() {
703         append(new AMD64PauseOp());
704     }
705 
706     @Override
707     public ZapRegistersOp createZapRegisters(Register[] zappedRegisters, JavaConstant[] zapValues) {
708         return new AMD64ZapRegistersOp(zappedRegisters, zapValues);
709     }
710 
711     @Override
712     public LIRInstruction createZapArgumentSpace(StackSlot[] zappedStack, JavaConstant[] zapValues) {
713         return new AMD64ZapStackOp(zappedStack, zapValues);
714     }
715 
716     @Override
717     public void emitSpeculationFence() {
718         append(new AMD64LFenceOp());
719     }
720 
721     @Override
722     public void emitZeroMemory(Value address, Value length, boolean isAligned) {
723         RegisterValue lengthReg = AMD64.rcx.asValue(length.getValueKind());
724         emitMove(lengthReg, length);
725         append(new AMD64ZeroMemoryOp(asAddressValue(address), lengthReg));
726     }
727 }
<a name="12" id="anc12"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="12" type="hidden" />
</body>
</html>