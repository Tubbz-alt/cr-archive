<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/ppc/ppc.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="nativeInst_ppc.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="sharedRuntime_ppc.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/ppc/ppc.ad</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
    1 //
<span class="line-modified">    2 // Copyright (c) 2011, 2019, Oracle and/or its affiliates. All rights reserved.</span>
    3 // Copyright (c) 2012, 2019 SAP SE. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
</pre>
<hr />
<pre>
  965 // This is a block of C++ code which provides values, functions, and
  966 // definitions necessary in the rest of the architecture description.
  967 source_hpp %{
  968   // Header information of the source block.
  969   // Method declarations/definitions which are used outside
  970   // the ad-scope can conveniently be defined here.
  971   //
  972   // To keep related declarations/definitions/uses close together,
  973   // we switch between source %{ }% and source_hpp %{ }% freely as needed.
  974 
  975 #include &quot;opto/convertnode.hpp&quot;
  976 
  977   // Returns true if Node n is followed by a MemBar node that
  978   // will do an acquire. If so, this node must not do the acquire
  979   // operation.
  980   bool followed_by_acquire(const Node *n);
  981 %}
  982 
  983 source %{
  984 
















  985 // Should the Matcher clone shifts on addressing modes, expecting them
  986 // to be subsumed into complex addressing expressions or compute them
  987 // into registers?
<span class="line-modified">  988 bool Matcher::clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {</span>
  989   return clone_base_plus_offset_address(m, mstack, address_visited);
  990 }
  991 
  992 void Compile::reshape_address(AddPNode* addp) {
  993 }
  994 
  995 // Optimize load-acquire.
  996 //
  997 // Check if acquire is unnecessary due to following operation that does
  998 // acquire anyways.
  999 // Walk the pattern:
 1000 //
 1001 //      n: Load.acq
 1002 //           |
 1003 //      MemBarAcquire
 1004 //       |         |
 1005 //  Proj(ctrl)  Proj(mem)
 1006 //       |         |
 1007 //   MemBarRelease/Volatile
 1008 //
</pre>
<hr />
<pre>
 1127 //=============================================================================
 1128 
 1129 // Compute padding required for nodes which need alignment. The padding
 1130 // is the number of bytes (not instructions) which will be inserted before
 1131 // the instruction. The padding must match the size of a NOP instruction.
 1132 
 1133 // Currently not used on this platform.
 1134 
 1135 //=============================================================================
 1136 
 1137 // Indicate if the safepoint node needs the polling page as an input.
 1138 bool SafePointNode::needs_polling_address_input() {
 1139   // The address is loaded from thread by a seperate node.
 1140   return true;
 1141 }
 1142 
 1143 //=============================================================================
 1144 
 1145 // Emit an interrupt that is caught by the debugger (for debugging compiler).
 1146 void emit_break(CodeBuffer &amp;cbuf) {
<span class="line-modified"> 1147   MacroAssembler _masm(&amp;cbuf);</span>
 1148   __ illtrap();
 1149 }
 1150 
 1151 #ifndef PRODUCT
 1152 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1153   st-&gt;print(&quot;BREAKPOINT&quot;);
 1154 }
 1155 #endif
 1156 
 1157 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1158   emit_break(cbuf);
 1159 }
 1160 
 1161 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1162   return MachNode::size(ra_);
 1163 }
 1164 
 1165 //=============================================================================
 1166 
 1167 void emit_nop(CodeBuffer &amp;cbuf) {
<span class="line-modified"> 1168   MacroAssembler _masm(&amp;cbuf);</span>
 1169   __ nop();
 1170 }
 1171 
 1172 static inline void emit_long(CodeBuffer &amp;cbuf, int value) {
 1173   *((int*)(cbuf.insts_end())) = value;
 1174   cbuf.set_insts_end(cbuf.insts_end() + BytesPerInstWord);
 1175 }
 1176 
 1177 //=============================================================================
 1178 
 1179 %} // interrupt source
 1180 
 1181 source_hpp %{ // Header information of the source block.
 1182 
 1183 //--------------------------------------------------------------
 1184 //---&lt;  Used for optimization in Compile::Shorten_branches  &gt;---
 1185 //--------------------------------------------------------------
 1186 


 1187 class CallStubImpl {
 1188 
 1189  public:
 1190 
 1191   // Emit call stub, compiled java to interpreter.
<span class="line-modified"> 1192   static void emit_trampoline_stub(MacroAssembler &amp;_masm, int destination_toc_offset, int insts_call_instruction_offset);</span>
 1193 
 1194   // Size of call trampoline stub.
 1195   // This doesn&#39;t need to be accurate to the byte, but it
 1196   // must be larger than or equal to the real size of the stub.
 1197   static uint size_call_trampoline() {
 1198     return MacroAssembler::trampoline_stub_size;
 1199   }
 1200 
 1201   // number of relocations needed by a call trampoline stub
 1202   static uint reloc_call_trampoline() {
 1203     return 5;
 1204   }
 1205 
 1206 };
 1207 
 1208 %} // end source_hpp
 1209 
 1210 source %{
 1211 
 1212 // Emit a trampoline stub for a call to a target which is too far away.
 1213 //
 1214 // code sequences:
 1215 //
 1216 // call-site:
 1217 //   branch-and-link to &lt;destination&gt; or &lt;trampoline stub&gt;
 1218 //
 1219 // Related trampoline stub for this call-site in the stub section:
 1220 //   load the call target from the constant pool
 1221 //   branch via CTR (LR/link still points to the call-site above)
 1222 
<span class="line-modified"> 1223 void CallStubImpl::emit_trampoline_stub(MacroAssembler &amp;_masm, int destination_toc_offset, int insts_call_instruction_offset) {</span>
 1224   address stub = __ emit_trampoline_stub(destination_toc_offset, insts_call_instruction_offset);
 1225   if (stub == NULL) {
 1226     ciEnv::current()-&gt;record_out_of_memory_failure();
 1227   }
 1228 }
 1229 
 1230 //=============================================================================
 1231 
 1232 // Emit an inline branch-and-link call and a related trampoline stub.
 1233 //
 1234 // code sequences:
 1235 //
 1236 // call-site:
 1237 //   branch-and-link to &lt;destination&gt; or &lt;trampoline stub&gt;
 1238 //
 1239 // Related trampoline stub for this call-site in the stub section:
 1240 //   load the call target from the constant pool
 1241 //   branch via CTR (LR/link still points to the call-site above)
 1242 //
 1243 
 1244 typedef struct {
 1245   int insts_call_instruction_offset;
 1246   int ret_addr_offset;
 1247 } EmitCallOffsets;
 1248 
 1249 // Emit a branch-and-link instruction that branches to a trampoline.
 1250 // - Remember the offset of the branch-and-link instruction.
 1251 // - Add a relocation at the branch-and-link instruction.
 1252 // - Emit a branch-and-link.
 1253 // - Remember the return pc offset.
<span class="line-modified"> 1254 EmitCallOffsets emit_call_with_trampoline_stub(MacroAssembler &amp;_masm, address entry_point, relocInfo::relocType rtype) {</span>
 1255   EmitCallOffsets offsets = { -1, -1 };
 1256   const int start_offset = __ offset();
 1257   offsets.insts_call_instruction_offset = __ offset();
 1258 
 1259   // No entry point given, use the current pc.
 1260   if (entry_point == NULL) entry_point = __ pc();
 1261 
 1262   // Put the entry point as a constant into the constant pool.
 1263   const address entry_point_toc_addr   = __ address_constant(entry_point, RelocationHolder::none);
 1264   if (entry_point_toc_addr == NULL) {
 1265     ciEnv::current()-&gt;record_out_of_memory_failure();
 1266     return offsets;
 1267   }
 1268   const int     entry_point_toc_offset = __ offset_to_method_toc(entry_point_toc_addr);
 1269 
 1270   // Emit the trampoline stub which will be related to the branch-and-link below.
 1271   CallStubImpl::emit_trampoline_stub(_masm, entry_point_toc_offset, offsets.insts_call_instruction_offset);
 1272   if (ciEnv::current()-&gt;failing()) { return offsets; } // Code cache may be full.
 1273   __ relocate(rtype);
 1274 
</pre>
<hr />
<pre>
 1280   offsets.ret_addr_offset = __ offset() - start_offset;
 1281 
 1282   return offsets;
 1283 }
 1284 
 1285 //=============================================================================
 1286 
 1287 // Factory for creating loadConL* nodes for large/small constant pool.
 1288 
 1289 static inline jlong replicate_immF(float con) {
 1290   // Replicate float con 2 times and pack into vector.
 1291   int val = *((int*)&amp;con);
 1292   jlong lval = val;
 1293   lval = (lval &lt;&lt; 32) | (lval &amp; 0xFFFFFFFFl);
 1294   return lval;
 1295 }
 1296 
 1297 //=============================================================================
 1298 
 1299 const RegMask&amp; MachConstantBaseNode::_out_RegMask = BITS64_CONSTANT_TABLE_BASE_mask();
<span class="line-modified"> 1300 int Compile::ConstantTable::calculate_table_base_offset() const {</span>
 1301   return 0;  // absolute addressing, no offset
 1302 }
 1303 
 1304 bool MachConstantBaseNode::requires_postalloc_expand() const { return true; }
 1305 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1306   iRegPdstOper *op_dst = new iRegPdstOper();
 1307   MachNode *m1 = new loadToc_hiNode();
 1308   MachNode *m2 = new loadToc_loNode();
 1309 
 1310   m1-&gt;add_req(NULL);
 1311   m2-&gt;add_req(NULL, m1);
 1312   m1-&gt;_opnds[0] = op_dst;
 1313   m2-&gt;_opnds[0] = op_dst;
 1314   m2-&gt;_opnds[1] = op_dst;
 1315   ra_-&gt;set_pair(m1-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 1316   ra_-&gt;set_pair(m2-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 1317   nodes-&gt;push(m1);
 1318   nodes-&gt;push(m2);
 1319 }
 1320 
 1321 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1322   // Is postalloc expanded.
 1323   ShouldNotReachHere();
 1324 }
 1325 
 1326 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1327   return 0;
 1328 }
 1329 
 1330 #ifndef PRODUCT
 1331 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1332   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1333 }
 1334 #endif
 1335 
 1336 //=============================================================================
 1337 
 1338 #ifndef PRODUCT
 1339 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1340   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1341   const long framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1342 
 1343   st-&gt;print(&quot;PROLOG\n\t&quot;);
<span class="line-modified"> 1344   if (C-&gt;need_stack_bang(framesize)) {</span>
 1345     st-&gt;print(&quot;stack_overflow_check\n\t&quot;);
 1346   }
 1347 
 1348   if (!false /* TODO: PPC port C-&gt;is_frameless_method()*/) {
 1349     st-&gt;print(&quot;save return pc\n\t&quot;);
 1350     st-&gt;print(&quot;push frame %ld\n\t&quot;, -framesize);
 1351   }
 1352 }
 1353 #endif
 1354 
 1355 // Macro used instead of the common __ to emulate the pipes of PPC.
 1356 // Instead of e.g. __ ld(...) one hase to write ___(ld) ld(...) This enables the
 1357 // micro scheduler to cope with &quot;hand written&quot; assembler like in the prolog. Though
 1358 // still no scheduling of this code is possible, the micro scheduler is aware of the
 1359 // code and can update its internal data. The following mechanism is used to achieve this:
 1360 // The micro scheduler calls size() of each compound node during scheduling. size() does a
 1361 // dummy emit and only during this dummy emit C-&gt;hb_scheduling() is not NULL.
 1362 #if 0 // TODO: PPC port
 1363 #define ___(op) if (UsePower6SchedulerPPC64 &amp;&amp; C-&gt;hb_scheduling())                    \
 1364                   C-&gt;hb_scheduling()-&gt;_pdScheduling-&gt;PdEmulatePipe(ppc64Opcode_##op); \
 1365                 _masm.
 1366 #define ___stop if (UsePower6SchedulerPPC64 &amp;&amp; C-&gt;hb_scheduling())                    \
 1367                   C-&gt;hb_scheduling()-&gt;_pdScheduling-&gt;PdEmulatePipe(archOpcode_none)
 1368 #define ___advance if (UsePower6SchedulerPPC64 &amp;&amp; C-&gt;hb_scheduling())                 \
 1369                   C-&gt;hb_scheduling()-&gt;_pdScheduling-&gt;advance_offset
 1370 #else
 1371 #define ___(op) if (UsePower6SchedulerPPC64)                                          \
 1372                   Unimplemented();                                                    \
 1373                 _masm.
 1374 #define ___stop if (UsePower6SchedulerPPC64)                                          \
 1375                   Unimplemented()
 1376 #define ___advance if (UsePower6SchedulerPPC64)                                       \
 1377                   Unimplemented()
 1378 #endif
 1379 
 1380 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1381   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1382   MacroAssembler _masm(&amp;cbuf);</span>
 1383 
<span class="line-modified"> 1384   const long framesize = C-&gt;frame_size_in_bytes();</span>
 1385   assert(framesize % (2 * wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1386 
 1387   const bool method_is_frameless      = false /* TODO: PPC port C-&gt;is_frameless_method()*/;
 1388 
 1389   const Register return_pc            = R20; // Must match return_addr() in frame section.
 1390   const Register callers_sp           = R21;
 1391   const Register push_frame_temp      = R22;
 1392   const Register toc_temp             = R23;
 1393   assert_different_registers(R11, return_pc, callers_sp, push_frame_temp, toc_temp);
 1394 
 1395   if (method_is_frameless) {
 1396     // Add nop at beginning of all frameless methods to prevent any
 1397     // oop instructions from getting overwritten by make_not_entrant
 1398     // (patching attempt would fail).
 1399     ___(nop) nop();
 1400   } else {
 1401     // Get return pc.
 1402     ___(mflr) mflr(return_pc);
 1403   }
 1404 
</pre>
<hr />
<pre>
 1409     Register klass = toc_temp;
 1410 
 1411     // Notify OOP recorder (don&#39;t need the relocation)
 1412     AddressLiteral md = __ constant_metadata_address(C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1413     __ load_const_optimized(klass, md.value(), R0);
 1414     __ clinit_barrier(klass, R16_thread, &amp;L_skip_barrier /*L_fast_path*/);
 1415 
 1416     __ load_const_optimized(klass, SharedRuntime::get_handle_wrong_method_stub(), R0);
 1417     __ mtctr(klass);
 1418     __ bctr();
 1419 
 1420     __ bind(L_skip_barrier);
 1421   }
 1422 
 1423   // Calls to C2R adapters often do not accept exceptional returns.
 1424   // We require that their callers must bang for them. But be
 1425   // careful, because some VM calls (such as call site linkage) can
 1426   // use several kilobytes of stack. But the stack safety zone should
 1427   // account for that. See bugs 4446381, 4468289, 4497237.
 1428 
<span class="line-modified"> 1429   int bangsize = C-&gt;bang_size_in_bytes();</span>
 1430   assert(bangsize &gt;= framesize || bangsize &lt;= 0, &quot;stack bang size incorrect&quot;);
<span class="line-modified"> 1431   if (C-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging) {</span>
 1432     // Unfortunately we cannot use the function provided in
 1433     // assembler.cpp as we have to emulate the pipes. So I had to
 1434     // insert the code of generate_stack_overflow_check(), see
 1435     // assembler.cpp for some illuminative comments.
 1436     const int page_size = os::vm_page_size();
 1437     int bang_end = JavaThread::stack_shadow_zone_size();
 1438 
 1439     // This is how far the previous frame&#39;s stack banging extended.
 1440     const int bang_end_safe = bang_end;
 1441 
 1442     if (bangsize &gt; page_size) {
 1443       bang_end += bangsize;
 1444     }
 1445 
 1446     int bang_offset = bang_end_safe;
 1447 
 1448     while (bang_offset &lt;= bang_end) {
 1449       // Need at least one stack bang at end of shadow zone.
 1450 
 1451       // Again I had to copy code, this time from assembler_ppc.cpp,
</pre>
<hr />
<pre>
 1465         }
 1466       } else if (Assembler::is_simm(stdoffset, 31)) {
 1467         // Use largeoffset calculations for addis &amp; ld/std.
 1468         const int hi = MacroAssembler::largeoffset_si16_si16_hi(stdoffset);
 1469         const int lo = MacroAssembler::largeoffset_si16_si16_lo(stdoffset);
 1470 
 1471         Register tmp = R11;
 1472         ___(addis) addis(tmp, R1_SP, hi);
 1473         if (UseLoadInstructionsForStackBangingPPC64) {
 1474           ___(ld) ld(R0, lo, tmp);
 1475         } else {
 1476           ___(std) std(R0, lo, tmp);
 1477         }
 1478       } else {
 1479         ShouldNotReachHere();
 1480       }
 1481 
 1482       bang_offset += page_size;
 1483     }
 1484     // R11 trashed
<span class="line-modified"> 1485   } // C-&gt;need_stack_bang(framesize) &amp;&amp; UseStackBanging</span>
 1486 
 1487   unsigned int bytes = (unsigned int)framesize;
 1488   long offset = Assembler::align_addr(bytes, frame::alignment_in_bytes);
 1489   ciMethod *currMethod = C-&gt;method();
 1490 
 1491   // Optimized version for most common case.
 1492   if (UsePower6SchedulerPPC64 &amp;&amp;
 1493       !method_is_frameless &amp;&amp; Assembler::is_simm((int)(-offset), 16) &amp;&amp;
 1494       !(false /* ConstantsALot TODO: PPC port*/)) {
 1495     ___(or) mr(callers_sp, R1_SP);
 1496     ___(std) std(return_pc, _abi(lr), R1_SP);
 1497     ___(stdu) stdu(R1_SP, -offset, R1_SP);
 1498     return;
 1499   }
 1500 
 1501   if (!method_is_frameless) {
 1502     // Get callers sp.
 1503     ___(or) mr(callers_sp, R1_SP);
 1504 
 1505     // Push method&#39;s frame, modifies SP.
</pre>
<hr />
<pre>
 1520       ___(ori)    ori( tmp, tmp, (x &amp; 0x0000ffff));
 1521 
 1522       ___(stdux) stdux(R1_SP, R1_SP, tmp);
 1523     }
 1524   }
 1525 #if 0 // TODO: PPC port
 1526   // For testing large constant pools, emit a lot of constants to constant pool.
 1527   // &quot;Randomize&quot; const_size.
 1528   if (ConstantsALot) {
 1529     const int num_consts = const_size();
 1530     for (int i = 0; i &lt; num_consts; i++) {
 1531       __ long_constant(0xB0B5B00BBABE);
 1532     }
 1533   }
 1534 #endif
 1535   if (!method_is_frameless) {
 1536     // Save return pc.
 1537     ___(std) std(return_pc, _abi(lr), callers_sp);
 1538   }
 1539 
<span class="line-modified"> 1540   C-&gt;set_frame_complete(cbuf.insts_size());</span>
 1541 }
 1542 #undef ___
 1543 #undef ___stop
 1544 #undef ___advance
 1545 
 1546 uint MachPrologNode::size(PhaseRegAlloc *ra_) const {
 1547   // Variable size. determine dynamically.
 1548   return MachNode::size(ra_);
 1549 }
 1550 
 1551 int MachPrologNode::reloc() const {
 1552   // Return number of relocatable values contained in this instruction.
 1553   return 1; // 1 reloc entry for load_const(toc).
 1554 }
 1555 
 1556 //=============================================================================
 1557 
 1558 #ifndef PRODUCT
 1559 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1560   Compile* C = ra_-&gt;C;
 1561 
 1562   st-&gt;print(&quot;EPILOG\n\t&quot;);
 1563   st-&gt;print(&quot;restore return pc\n\t&quot;);
 1564   st-&gt;print(&quot;pop frame\n\t&quot;);
 1565 
 1566   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1567     st-&gt;print(&quot;touch polling page\n\t&quot;);
 1568   }
 1569 }
 1570 #endif
 1571 
 1572 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1573   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1574   MacroAssembler _masm(&amp;cbuf);</span>
 1575 
<span class="line-modified"> 1576   const long framesize = ((long)C-&gt;frame_slots()) &lt;&lt; LogBytesPerInt;</span>
 1577   assert(framesize &gt;= 0, &quot;negative frame-size?&quot;);
 1578 
 1579   const bool method_needs_polling = do_polling() &amp;&amp; C-&gt;is_method_compilation();
 1580   const bool method_is_frameless  = false /* TODO: PPC port C-&gt;is_frameless_method()*/;
 1581   const Register return_pc        = R31;  // Must survive C-call to enable_stack_reserved_zone().
 1582   const Register polling_page     = R12;
 1583 
 1584   if (!method_is_frameless) {
 1585     // Restore return pc relative to callers&#39; sp.
 1586     __ ld(return_pc, ((int)framesize) + _abi(lr), R1_SP);
 1587   }
 1588 
 1589   if (method_needs_polling) {
<span class="line-modified"> 1590     if (SafepointMechanism::uses_thread_local_poll()) {</span>
<span class="line-removed"> 1591       __ ld(polling_page, in_bytes(JavaThread::polling_page_offset()), R16_thread);</span>
<span class="line-removed"> 1592     } else {</span>
<span class="line-removed"> 1593       __ load_const_optimized(polling_page, (long)(address) os::get_polling_page());</span>
<span class="line-removed"> 1594     }</span>
 1595   }
 1596 
 1597   if (!method_is_frameless) {
 1598     // Move return pc to LR.
 1599     __ mtlr(return_pc);
 1600     // Pop frame (fixed frame-size).
 1601     __ addi(R1_SP, R1_SP, (int)framesize);
 1602   }
 1603 
 1604   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1605     __ reserved_stack_check(return_pc);
 1606   }
 1607 
 1608   if (method_needs_polling) {
 1609     // We need to mark the code position where the load from the safepoint
 1610     // polling page was emitted as relocInfo::poll_return_type here.
 1611     __ relocate(relocInfo::poll_return_type);
 1612     __ load_from_polling_page(polling_page);
 1613   }
 1614 }
 1615 
 1616 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1617   // Variable size. Determine dynamically.
 1618   return MachNode::size(ra_);
 1619 }
 1620 
 1621 int MachEpilogNode::reloc() const {
 1622   // Return number of relocatable values contained in this instruction.
 1623   return 1; // 1 for load_from_polling_page.
 1624 }
 1625 
 1626 const Pipeline * MachEpilogNode::pipeline() const {
 1627   return MachNode::pipeline_class();
 1628 }
 1629 
<span class="line-removed"> 1630 // This method seems to be obsolete. It is declared in machnode.hpp</span>
<span class="line-removed"> 1631 // and defined in all *.ad files, but it is never called. Should we</span>
<span class="line-removed"> 1632 // get rid of it?</span>
<span class="line-removed"> 1633 int MachEpilogNode::safepoint_offset() const {</span>
<span class="line-removed"> 1634   assert(do_polling(), &quot;no return for this epilog node&quot;);</span>
<span class="line-removed"> 1635   return 0;</span>
<span class="line-removed"> 1636 }</span>
<span class="line-removed"> 1637 </span>
 1638 #if 0 // TODO: PPC port
 1639 void MachLoadPollAddrLateNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
<span class="line-modified"> 1640   MacroAssembler _masm(&amp;cbuf);</span>
 1641   if (LoadPollAddressFromThread) {
 1642     _masm.ld(R11, in_bytes(JavaThread::poll_address_offset()), R16_thread);
 1643   } else {
 1644     _masm.nop();
 1645   }
 1646 }
 1647 
 1648 uint MachLoadPollAddrLateNode::size(PhaseRegAlloc* ra_) const {
 1649   if (LoadPollAddressFromThread) {
 1650     return 4;
 1651   } else {
 1652     return 4;
 1653   }
 1654 }
 1655 
 1656 #ifndef PRODUCT
 1657 void MachLoadPollAddrLateNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1658   st-&gt;print_cr(&quot; LD R11, PollAddressOffset, R16_thread \t// LoadPollAddressFromThread&quot;);
 1659 }
 1660 #endif
</pre>
<hr />
<pre>
 1737   enum RC dst_hi_rc = rc_class(dst_hi);
 1738   enum RC dst_lo_rc = rc_class(dst_lo);
 1739 
 1740   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1741   if (src_hi != OptoReg::Bad)
 1742     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1743            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1744            &quot;expected aligned-adjacent pairs&quot;);
 1745   // Generate spill code!
 1746   int size = 0;
 1747 
 1748   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi)
 1749     return size;            // Self copy, no move.
 1750 
 1751   if (bottom_type()-&gt;isa_vect() != NULL &amp;&amp; ideal_reg() == Op_VecX) {
 1752     // Memory-&gt;Memory Spill.
 1753     if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1754       int src_offset = ra_-&gt;reg2offset(src_lo);
 1755       int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1756       if (cbuf) {
<span class="line-modified"> 1757         MacroAssembler _masm(cbuf);</span>
 1758         __ ld(R0, src_offset, R1_SP);
 1759         __ std(R0, dst_offset, R1_SP);
 1760         __ ld(R0, src_offset+8, R1_SP);
 1761         __ std(R0, dst_offset+8, R1_SP);
 1762       }
 1763       size += 16;
 1764     }
 1765     // VectorSRegister-&gt;Memory Spill.
 1766     else if (src_lo_rc == rc_vs &amp;&amp; dst_lo_rc == rc_stack) {
 1767       VectorSRegister Rsrc = as_VectorSRegister(Matcher::_regEncode[src_lo]);
 1768       int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1769       if (cbuf) {
<span class="line-modified"> 1770         MacroAssembler _masm(cbuf);</span>
 1771         __ addi(R0, R1_SP, dst_offset);
 1772         __ stxvd2x(Rsrc, R0);
 1773       }
 1774       size += 8;
 1775     }
 1776     // Memory-&gt;VectorSRegister Spill.
 1777     else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_vs) {
 1778       VectorSRegister Rdst = as_VectorSRegister(Matcher::_regEncode[dst_lo]);
 1779       int src_offset = ra_-&gt;reg2offset(src_lo);
 1780       if (cbuf) {
<span class="line-modified"> 1781         MacroAssembler _masm(cbuf);</span>
 1782         __ addi(R0, R1_SP, src_offset);
 1783         __ lxvd2x(Rdst, R0);
 1784       }
 1785       size += 8;
 1786     }
 1787     // VectorSRegister-&gt;VectorSRegister.
 1788     else if (src_lo_rc == rc_vs &amp;&amp; dst_lo_rc == rc_vs) {
 1789       VectorSRegister Rsrc = as_VectorSRegister(Matcher::_regEncode[src_lo]);
 1790       VectorSRegister Rdst = as_VectorSRegister(Matcher::_regEncode[dst_lo]);
 1791       if (cbuf) {
<span class="line-modified"> 1792         MacroAssembler _masm(cbuf);</span>
 1793         __ xxlor(Rdst, Rsrc, Rsrc);
 1794       }
 1795       size += 4;
 1796     }
 1797     else {
 1798       ShouldNotReachHere(); // No VSR spill.
 1799     }
 1800     return size;
 1801   }
 1802 
 1803   // --------------------------------------
 1804   // Memory-&gt;Memory Spill. Use R0 to hold the value.
 1805   if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1806     int src_offset = ra_-&gt;reg2offset(src_lo);
 1807     int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1808     if (src_hi != OptoReg::Bad) {
 1809       assert(src_hi_rc==rc_stack &amp;&amp; dst_hi_rc==rc_stack,
 1810              &quot;expected same type of move for high parts&quot;);
 1811       size += ld_st_helper(cbuf, &quot;LD  &quot;, Assembler::LD_OPCODE,  R0_num, src_offset, !do_size, C, st);
 1812       if (!cbuf &amp;&amp; !do_size) st-&gt;print(&quot;\n\t&quot;);
</pre>
<hr />
<pre>
 1816       if (!cbuf &amp;&amp; !do_size) st-&gt;print(&quot;\n\t&quot;);
 1817       size += ld_st_helper(cbuf, &quot;STW &quot;, Assembler::STW_OPCODE, R0_num, dst_offset, !do_size, C, st);
 1818     }
 1819     return size;
 1820   }
 1821 
 1822   // --------------------------------------
 1823   // Check for float-&gt;int copy; requires a trip through memory.
 1824   if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_int) {
 1825     Unimplemented();
 1826   }
 1827 
 1828   // --------------------------------------
 1829   // Check for integer reg-reg copy.
 1830   if (src_lo_rc == rc_int &amp;&amp; dst_lo_rc == rc_int) {
 1831       Register Rsrc = as_Register(Matcher::_regEncode[src_lo]);
 1832       Register Rdst = as_Register(Matcher::_regEncode[dst_lo]);
 1833       size = (Rsrc != Rdst) ? 4 : 0;
 1834 
 1835       if (cbuf) {
<span class="line-modified"> 1836         MacroAssembler _masm(cbuf);</span>
 1837         if (size) {
 1838           __ mr(Rdst, Rsrc);
 1839         }
 1840       }
 1841 #ifndef PRODUCT
 1842       else if (!do_size) {
 1843         if (size) {
 1844           st-&gt;print(&quot;%-7s %s, %s \t// spill copy&quot;, &quot;MR&quot;, Matcher::regName[dst_lo], Matcher::regName[src_lo]);
 1845         } else {
 1846           st-&gt;print(&quot;%-7s %s, %s \t// spill copy&quot;, &quot;MR-NOP&quot;, Matcher::regName[dst_lo], Matcher::regName[src_lo]);
 1847         }
 1848       }
 1849 #endif
 1850       return size;
 1851   }
 1852 
 1853   // Check for integer store.
 1854   if (src_lo_rc == rc_int &amp;&amp; dst_lo_rc == rc_stack) {
 1855     int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1856     if (src_hi != OptoReg::Bad) {
</pre>
<hr />
<pre>
 1862     }
 1863     return size;
 1864   }
 1865 
 1866   // Check for integer load.
 1867   if (dst_lo_rc == rc_int &amp;&amp; src_lo_rc == rc_stack) {
 1868     int src_offset = ra_-&gt;reg2offset(src_lo);
 1869     if (src_hi != OptoReg::Bad) {
 1870       assert(dst_hi_rc==rc_int &amp;&amp; src_hi_rc==rc_stack,
 1871              &quot;expected same type of move for high parts&quot;);
 1872       size += ld_st_helper(cbuf, &quot;LD  &quot;, Assembler::LD_OPCODE, dst_lo, src_offset, !do_size, C, st);
 1873     } else {
 1874       size += ld_st_helper(cbuf, &quot;LWZ &quot;, Assembler::LWZ_OPCODE, dst_lo, src_offset, !do_size, C, st);
 1875     }
 1876     return size;
 1877   }
 1878 
 1879   // Check for float reg-reg copy.
 1880   if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1881     if (cbuf) {
<span class="line-modified"> 1882       MacroAssembler _masm(cbuf);</span>
 1883       FloatRegister Rsrc = as_FloatRegister(Matcher::_regEncode[src_lo]);
 1884       FloatRegister Rdst = as_FloatRegister(Matcher::_regEncode[dst_lo]);
 1885       __ fmr(Rdst, Rsrc);
 1886     }
 1887 #ifndef PRODUCT
 1888     else if (!do_size) {
 1889       st-&gt;print(&quot;%-7s %s, %s \t// spill copy&quot;, &quot;FMR&quot;, Matcher::regName[dst_lo], Matcher::regName[src_lo]);
 1890     }
 1891 #endif
 1892     return 4;
 1893   }
 1894 
 1895   // Check for float store.
 1896   if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1897     int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1898     if (src_hi != OptoReg::Bad) {
 1899       assert(src_hi_rc==rc_float &amp;&amp; dst_hi_rc==rc_stack,
 1900              &quot;expected same type of move for high parts&quot;);
 1901       size += ld_st_helper(cbuf, &quot;STFD&quot;, Assembler::STFD_OPCODE, src_lo, dst_offset, !do_size, C, st);
 1902     } else {
</pre>
<hr />
<pre>
 2032 
 2033   // --------------------------------------------------------------------
 2034   // Check for hi bits still needing moving. Only happens for misaligned
 2035   // arguments to native calls.
 2036   if (src_hi == dst_hi) {
 2037     return ppc64Opcode_none;               // Self copy; no move.
 2038   }
 2039 
 2040   ShouldNotReachHere();
 2041   return ppc64Opcode_undefined;
 2042 }
 2043 #endif // PPC port
 2044 
 2045 #ifndef PRODUCT
 2046 void MachNopNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 2047   st-&gt;print(&quot;NOP \t// %d nops to pad for loops.&quot;, _count);
 2048 }
 2049 #endif
 2050 
 2051 void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *) const {
<span class="line-modified"> 2052   MacroAssembler _masm(&amp;cbuf);</span>
 2053   // _count contains the number of nops needed for padding.
 2054   for (int i = 0; i &lt; _count; i++) {
 2055     __ nop();
 2056   }
 2057 }
 2058 
 2059 uint MachNopNode::size(PhaseRegAlloc *ra_) const {
 2060   return _count * 4;
 2061 }
 2062 
 2063 #ifndef PRODUCT
 2064 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 2065   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 2066   char reg_str[128];
 2067   ra_-&gt;dump_register(this, reg_str);
 2068   st-&gt;print(&quot;ADDI    %s, SP, %d \t// box node&quot;, reg_str, offset);
 2069 }
 2070 #endif
 2071 
 2072 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
<span class="line-modified"> 2073   MacroAssembler _masm(&amp;cbuf);</span>
 2074 
 2075   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 2076   int reg    = ra_-&gt;get_encode(this);
 2077 
 2078   if (Assembler::is_simm(offset, 16)) {
 2079     __ addi(as_Register(reg), R1, offset);
 2080   } else {
 2081     ShouldNotReachHere();
 2082   }
 2083 }
 2084 
 2085 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 2086   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 2087   return 4;
 2088 }
 2089 
 2090 #ifndef PRODUCT
 2091 void MachUEPNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 2092   st-&gt;print_cr(&quot;---- MachUEPNode ----&quot;);
 2093   st-&gt;print_cr(&quot;...&quot;);
 2094 }
 2095 #endif
 2096 
 2097 void MachUEPNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 2098   // This is the unverified entry point.
<span class="line-modified"> 2099   MacroAssembler _masm(&amp;cbuf);</span>
 2100 
 2101   // Inline_cache contains a klass.
 2102   Register ic_klass       = as_Register(Matcher::inline_cache_reg_encode());
 2103   Register receiver_klass = R12_scratch2;  // tmp
 2104 
 2105   assert_different_registers(ic_klass, receiver_klass, R11_scratch1, R3_ARG1);
 2106   assert(R11_scratch1 == R11, &quot;need prologue scratch register&quot;);
 2107 
 2108   // Check for NULL argument if we don&#39;t have implicit null checks.
 2109   if (!ImplicitNullChecks || !os::zero_page_read_protected()) {
 2110     if (TrapBasedNullChecks) {
 2111       __ trap_null_check(R3_ARG1);
 2112     } else {
 2113       Label valid;
 2114       __ cmpdi(CCR0, R3_ARG1, 0);
 2115       __ bne_predict_taken(CCR0, valid);
 2116       // We have a null argument, branch to ic_miss_stub.
 2117       __ b64_patchable((address)SharedRuntime::get_ic_miss_stub(),
 2118                            relocInfo::runtime_call_type);
 2119       __ bind(valid);
</pre>
<hr />
<pre>
 2157 
 2158 class HandlerImpl {
 2159 
 2160  public:
 2161 
 2162   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 2163   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 2164 
 2165   static uint size_exception_handler() {
 2166     // The exception_handler is a b64_patchable.
 2167     return MacroAssembler::b64_patchable_size;
 2168   }
 2169 
 2170   static uint size_deopt_handler() {
 2171     // The deopt_handler is a bl64_patchable.
 2172     return MacroAssembler::bl64_patchable_size;
 2173   }
 2174 
 2175 };
 2176 







 2177 %} // end source_hpp
 2178 
 2179 source %{
 2180 
 2181 int HandlerImpl::emit_exception_handler(CodeBuffer &amp;cbuf) {
<span class="line-modified"> 2182   MacroAssembler _masm(&amp;cbuf);</span>
 2183 
 2184   address base = __ start_a_stub(size_exception_handler());
 2185   if (base == NULL) return 0; // CodeBuffer::expand failed
 2186 
 2187   int offset = __ offset();
 2188   __ b64_patchable((address)OptoRuntime::exception_blob()-&gt;content_begin(),
 2189                        relocInfo::runtime_call_type);
 2190   assert(__ offset() - offset == (int)size_exception_handler(), &quot;must be fixed size&quot;);
 2191   __ end_a_stub();
 2192 
 2193   return offset;
 2194 }
 2195 
 2196 // The deopt_handler is like the exception handler, but it calls to
 2197 // the deoptimization blob instead of jumping to the exception blob.
 2198 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf) {
<span class="line-modified"> 2199   MacroAssembler _masm(&amp;cbuf);</span>
 2200 
 2201   address base = __ start_a_stub(size_deopt_handler());
 2202   if (base == NULL) return 0; // CodeBuffer::expand failed
 2203 
 2204   int offset = __ offset();
 2205   __ bl64_patchable((address)SharedRuntime::deopt_blob()-&gt;unpack(),
 2206                         relocInfo::runtime_call_type);
 2207   assert(__ offset() - offset == (int) size_deopt_handler(), &quot;must be fixed size&quot;);
 2208   __ end_a_stub();
 2209 
 2210   return offset;
 2211 }
 2212 
 2213 //=============================================================================
 2214 
 2215 // Use a frame slots bias for frameless methods if accessing the stack.
 2216 static int frame_slots_bias(int reg_enc, PhaseRegAlloc* ra_) {
 2217   if (as_Register(reg_enc) == R1_SP) {
 2218     return 0; // TODO: PPC port ra_-&gt;C-&gt;frame_slots_sp_bias_in_bytes();
 2219   }
</pre>
<hr />
<pre>
 2643 // operand to generate a function which returns its register number when
 2644 // queried. CONST_INTER causes an operand to generate a function which
 2645 // returns the value of the constant when queried. MEMORY_INTER causes an
 2646 // operand to generate four functions which return the Base Register, the
 2647 // Index Register, the Scale Value, and the Offset Value of the operand when
 2648 // queried. COND_INTER causes an operand to generate six functions which
 2649 // return the encoding code (ie - encoding bits for the instruction)
 2650 // associated with each basic boolean condition for a conditional instruction.
 2651 //
 2652 // Instructions specify two basic values for encoding. Again, a function
 2653 // is available to check if the constant displacement is an oop. They use the
 2654 // ins_encode keyword to specify their encoding classes (which must be
 2655 // a sequence of enc_class names, and their parameters, specified in
 2656 // the encoding block), and they use the
 2657 // opcode keyword to specify, in order, their primary, secondary, and
 2658 // tertiary opcode. Only the opcode sections which a particular instruction
 2659 // needs for encoding need to be specified.
 2660 encode %{
 2661   enc_class enc_unimplemented %{
 2662     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2663     MacroAssembler _masm(&amp;cbuf);</span>
 2664     __ unimplemented(&quot;Unimplemented mach node encoding in AD file.&quot;, 13);
 2665   %}
 2666 
 2667   enc_class enc_untested %{
 2668 #ifdef ASSERT
 2669     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2670     MacroAssembler _masm(&amp;cbuf);</span>
 2671     __ untested(&quot;Untested mach node encoding in AD file.&quot;);
 2672 #else
 2673     // TODO: PPC port $archOpcode(ppc64Opcode_none);
 2674 #endif
 2675   %}
 2676 
 2677   enc_class enc_lbz(iRegIdst dst, memory mem) %{
 2678     // TODO: PPC port $archOpcode(ppc64Opcode_lbz);
<span class="line-modified"> 2679     MacroAssembler _masm(&amp;cbuf);</span>
 2680     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2681     __ lbz($dst$$Register, Idisp, $mem$$base$$Register);
 2682   %}
 2683 
 2684   // Load acquire.
 2685   enc_class enc_lbz_ac(iRegIdst dst, memory mem) %{
 2686     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2687     MacroAssembler _masm(&amp;cbuf);</span>
 2688     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2689     __ lbz($dst$$Register, Idisp, $mem$$base$$Register);
 2690     __ twi_0($dst$$Register);
 2691     __ isync();
 2692   %}
 2693 
 2694   enc_class enc_lhz(iRegIdst dst, memory mem) %{
 2695     // TODO: PPC port $archOpcode(ppc64Opcode_lhz);
 2696 
<span class="line-modified"> 2697     MacroAssembler _masm(&amp;cbuf);</span>
 2698     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2699     __ lhz($dst$$Register, Idisp, $mem$$base$$Register);
 2700   %}
 2701 
 2702   // Load acquire.
 2703   enc_class enc_lhz_ac(iRegIdst dst, memory mem) %{
 2704     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 2705 
<span class="line-modified"> 2706     MacroAssembler _masm(&amp;cbuf);</span>
 2707     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2708     __ lhz($dst$$Register, Idisp, $mem$$base$$Register);
 2709     __ twi_0($dst$$Register);
 2710     __ isync();
 2711   %}
 2712 
 2713   enc_class enc_lwz(iRegIdst dst, memory mem) %{
 2714     // TODO: PPC port $archOpcode(ppc64Opcode_lwz);
 2715 
<span class="line-modified"> 2716     MacroAssembler _masm(&amp;cbuf);</span>
 2717     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2718     __ lwz($dst$$Register, Idisp, $mem$$base$$Register);
 2719   %}
 2720 
 2721   // Load acquire.
 2722   enc_class enc_lwz_ac(iRegIdst dst, memory mem) %{
 2723     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 2724 
<span class="line-modified"> 2725     MacroAssembler _masm(&amp;cbuf);</span>
 2726     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2727     __ lwz($dst$$Register, Idisp, $mem$$base$$Register);
 2728     __ twi_0($dst$$Register);
 2729     __ isync();
 2730   %}
 2731 
 2732   enc_class enc_ld(iRegLdst dst, memoryAlg4 mem) %{
 2733     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
<span class="line-modified"> 2734     MacroAssembler _masm(&amp;cbuf);</span>
 2735     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2736     // Operand &#39;ds&#39; requires 4-alignment.
 2737     assert((Idisp &amp; 0x3) == 0, &quot;unaligned offset&quot;);
 2738     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
 2739   %}
 2740 
 2741   // Load acquire.
 2742   enc_class enc_ld_ac(iRegLdst dst, memoryAlg4 mem) %{
 2743     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2744     MacroAssembler _masm(&amp;cbuf);</span>
 2745     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2746     // Operand &#39;ds&#39; requires 4-alignment.
 2747     assert((Idisp &amp; 0x3) == 0, &quot;unaligned offset&quot;);
 2748     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
 2749     __ twi_0($dst$$Register);
 2750     __ isync();
 2751   %}
 2752 
 2753   enc_class enc_lfd(RegF dst, memory mem) %{
 2754     // TODO: PPC port $archOpcode(ppc64Opcode_lfd);
<span class="line-modified"> 2755     MacroAssembler _masm(&amp;cbuf);</span>
 2756     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2757     __ lfd($dst$$FloatRegister, Idisp, $mem$$base$$Register);
 2758   %}
 2759 
 2760   enc_class enc_load_long_constL(iRegLdst dst, immL src, iRegLdst toc) %{
 2761     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
 2762 
<span class="line-modified"> 2763     MacroAssembler _masm(&amp;cbuf);</span>
 2764     int toc_offset = 0;
 2765 
 2766     address const_toc_addr;
 2767     // Create a non-oop constant, no relocation needed.
 2768     // If it is an IC, it has a virtual_call_Relocation.
 2769     const_toc_addr = __ long_constant((jlong)$src$$constant);
 2770     if (const_toc_addr == NULL) {
 2771       ciEnv::current()-&gt;record_out_of_memory_failure();
 2772       return;
 2773     }
 2774 
 2775     // Get the constant&#39;s TOC offset.
 2776     toc_offset = __ offset_to_method_toc(const_toc_addr);
 2777 
 2778     // Keep the current instruction offset in mind.
 2779     ((loadConLNode*)this)-&gt;_cbuf_insts_offset = __ offset();
 2780 
 2781     __ ld($dst$$Register, toc_offset, $toc$$Register);
 2782   %}
 2783 
 2784   enc_class enc_load_long_constL_hi(iRegLdst dst, iRegLdst toc, immL src) %{
 2785     // TODO: PPC port $archOpcode(ppc64Opcode_addis);
 2786 
<span class="line-modified"> 2787     MacroAssembler _masm(&amp;cbuf);</span>
 2788 
<span class="line-modified"> 2789     if (!ra_-&gt;C-&gt;in_scratch_emit_size()) {</span>
 2790       address const_toc_addr;
 2791       // Create a non-oop constant, no relocation needed.
 2792       // If it is an IC, it has a virtual_call_Relocation.
 2793       const_toc_addr = __ long_constant((jlong)$src$$constant);
 2794       if (const_toc_addr == NULL) {
 2795         ciEnv::current()-&gt;record_out_of_memory_failure();
 2796         return;
 2797       }
 2798 
 2799       // Get the constant&#39;s TOC offset.
 2800       const int toc_offset = __ offset_to_method_toc(const_toc_addr);
 2801       // Store the toc offset of the constant.
 2802       ((loadConL_hiNode*)this)-&gt;_const_toc_offset = toc_offset;
 2803 
 2804       // Also keep the current instruction offset in mind.
 2805       ((loadConL_hiNode*)this)-&gt;_cbuf_insts_offset = __ offset();
 2806     }
 2807 
 2808     __ addis($dst$$Register, $toc$$Register, MacroAssembler::largeoffset_si16_si16_hi(_const_toc_offset));
 2809   %}
</pre>
<hr />
<pre>
 3002   // Enc_class needed as consttanttablebase is not supported by postalloc
 3003   // expand.
 3004   enc_class postalloc_expand_load_long_constant(iRegLdst dst, immL src, iRegLdst toc) %{
 3005     // Create new nodes.
 3006     loadConLNodesTuple loadConLNodes =
 3007       loadConLNodesTuple_create(ra_, n_toc, op_src,
 3008                                 ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3009 
 3010     // Push new nodes.
 3011     if (loadConLNodes._large_hi) nodes-&gt;push(loadConLNodes._large_hi);
 3012     if (loadConLNodes._last)     nodes-&gt;push(loadConLNodes._last);
 3013 
 3014     // some asserts
 3015     assert(nodes-&gt;length() &gt;= 1, &quot;must have created at least 1 node&quot;);
 3016     assert(loadConLNodes._last-&gt;bottom_type()-&gt;isa_long(), &quot;must be long&quot;);
 3017   %}
 3018 
 3019   enc_class enc_load_long_constP(iRegLdst dst, immP src, iRegLdst toc) %{
 3020     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
 3021 
<span class="line-modified"> 3022     MacroAssembler _masm(&amp;cbuf);</span>
 3023     int toc_offset = 0;
 3024 
 3025     intptr_t val = $src$$constant;
 3026     relocInfo::relocType constant_reloc = $src-&gt;constant_reloc();  // src
 3027     address const_toc_addr;
 3028     if (constant_reloc == relocInfo::oop_type) {
 3029       // Create an oop constant and a corresponding relocation.
 3030       AddressLiteral a = __ allocate_oop_address((jobject)val);
 3031       const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3032       __ relocate(a.rspec());
 3033     } else if (constant_reloc == relocInfo::metadata_type) {
 3034       AddressLiteral a = __ constant_metadata_address((Metadata *)val);
 3035       const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3036       __ relocate(a.rspec());
 3037     } else {
 3038       // Create a non-oop constant, no relocation needed.
 3039       const_toc_addr = __ long_constant((jlong)$src$$constant);
 3040     }
 3041 
 3042     if (const_toc_addr == NULL) {
 3043       ciEnv::current()-&gt;record_out_of_memory_failure();
 3044       return;
 3045     }
 3046     // Get the constant&#39;s TOC offset.
 3047     toc_offset = __ offset_to_method_toc(const_toc_addr);
 3048 
 3049     __ ld($dst$$Register, toc_offset, $toc$$Register);
 3050   %}
 3051 
 3052   enc_class enc_load_long_constP_hi(iRegLdst dst, immP src, iRegLdst toc) %{
 3053     // TODO: PPC port $archOpcode(ppc64Opcode_addis);
 3054 
<span class="line-modified"> 3055     MacroAssembler _masm(&amp;cbuf);</span>
<span class="line-modified"> 3056     if (!ra_-&gt;C-&gt;in_scratch_emit_size()) {</span>
 3057       intptr_t val = $src$$constant;
 3058       relocInfo::relocType constant_reloc = $src-&gt;constant_reloc();  // src
 3059       address const_toc_addr;
 3060       if (constant_reloc == relocInfo::oop_type) {
 3061         // Create an oop constant and a corresponding relocation.
 3062         AddressLiteral a = __ allocate_oop_address((jobject)val);
 3063         const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3064         __ relocate(a.rspec());
 3065       } else if (constant_reloc == relocInfo::metadata_type) {
 3066         AddressLiteral a = __ constant_metadata_address((Metadata *)val);
 3067         const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3068         __ relocate(a.rspec());
 3069       } else {  // non-oop pointers, e.g. card mark base, heap top
 3070         // Create a non-oop constant, no relocation needed.
 3071         const_toc_addr = __ long_constant((jlong)$src$$constant);
 3072       }
 3073 
 3074       if (const_toc_addr == NULL) {
 3075         ciEnv::current()-&gt;record_out_of_memory_failure();
 3076         return;
</pre>
<hr />
<pre>
 3169     if (large_constant_pool) {
 3170       m2 = new loadConDCompNode();
 3171     } else {
 3172       m2 = new loadConDNode();
 3173     }
 3174     // inputs for new nodes
 3175     m2-&gt;add_req(NULL, n_toc);
 3176 
 3177     // operands for new nodes
 3178     m2-&gt;_opnds[0] = op_dst;
 3179     m2-&gt;_opnds[1] = op_src;
 3180     m2-&gt;_opnds[2] = new iRegPdstOper(); // constanttablebase
 3181 
 3182     // register allocation for new nodes
 3183     ra_-&gt;set_pair(m2-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3184     nodes-&gt;push(m2);
 3185   %}
 3186 
 3187   enc_class enc_stw(iRegIsrc src, memory mem) %{
 3188     // TODO: PPC port $archOpcode(ppc64Opcode_stw);
<span class="line-modified"> 3189     MacroAssembler _masm(&amp;cbuf);</span>
 3190     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3191     __ stw($src$$Register, Idisp, $mem$$base$$Register);
 3192   %}
 3193 
 3194   enc_class enc_std(iRegIsrc src, memoryAlg4 mem) %{
 3195     // TODO: PPC port $archOpcode(ppc64Opcode_std);
<span class="line-modified"> 3196     MacroAssembler _masm(&amp;cbuf);</span>
 3197     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3198     // Operand &#39;ds&#39; requires 4-alignment.
 3199     assert((Idisp &amp; 0x3) == 0, &quot;unaligned offset&quot;);
 3200     __ std($src$$Register, Idisp, $mem$$base$$Register);
 3201   %}
 3202 
 3203   enc_class enc_stfs(RegF src, memory mem) %{
 3204     // TODO: PPC port $archOpcode(ppc64Opcode_stfs);
<span class="line-modified"> 3205     MacroAssembler _masm(&amp;cbuf);</span>
 3206     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3207     __ stfs($src$$FloatRegister, Idisp, $mem$$base$$Register);
 3208   %}
 3209 
 3210   enc_class enc_stfd(RegF src, memory mem) %{
 3211     // TODO: PPC port $archOpcode(ppc64Opcode_stfd);
<span class="line-modified"> 3212     MacroAssembler _masm(&amp;cbuf);</span>
 3213     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3214     __ stfd($src$$FloatRegister, Idisp, $mem$$base$$Register);
 3215   %}
 3216 
 3217   // Use release_store for card-marking to ensure that previous
 3218   // oop-stores are visible before the card-mark change.
 3219   enc_class enc_cms_card_mark(memory mem, iRegLdst releaseFieldAddr, flagsReg crx) %{
 3220     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3221     // FIXME: Implement this as a cmove and use a fixed condition code
 3222     // register which is written on every transition to compiled code,
 3223     // e.g. in call-stub and when returning from runtime stubs.
 3224     //
 3225     // Proposed code sequence for the cmove implementation:
 3226     //
 3227     // Label skip_release;
 3228     // __ beq(CCRfixed, skip_release);
 3229     // __ release();
 3230     // __ bind(skip_release);
 3231     // __ stb(card mark);
 3232 
<span class="line-modified"> 3233     MacroAssembler _masm(&amp;cbuf);</span>
 3234     Label skip_storestore;
 3235 
 3236 #if 0 // TODO: PPC port
 3237     // Check CMSCollectorCardTableBarrierSetBSExt::_requires_release and do the
 3238     // StoreStore barrier conditionally.
 3239     __ lwz(R0, 0, $releaseFieldAddr$$Register);
 3240     __ cmpwi($crx$$CondRegister, R0, 0);
 3241     __ beq_predict_taken($crx$$CondRegister, skip_storestore);
 3242 #endif
 3243     __ li(R0, 0);
 3244     __ membar(Assembler::StoreStore);
 3245 #if 0 // TODO: PPC port
 3246     __ bind(skip_storestore);
 3247 #endif
 3248 
 3249     // Do the store.
 3250     if ($mem$$index == 0) {
 3251       __ stb(R0, $mem$$disp, $mem$$base$$Register);
 3252     } else {
 3253       assert(0 == $mem$$disp, &quot;no displacement possible with indexed load/stores on ppc&quot;);
</pre>
<hr />
<pre>
 3434     n1-&gt;_bottom_type = _bottom_type;
 3435 
 3436     decodeN_addNode *n2 = new decodeN_addNode();
 3437     n2-&gt;add_req(n_region, n1);
 3438     n2-&gt;_opnds[0] = op_dst;
 3439     n2-&gt;_opnds[1] = op_dst;
 3440     n2-&gt;_bottom_type = _bottom_type;
 3441     ra_-&gt;set_pair(n1-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3442     ra_-&gt;set_pair(n2-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3443 
 3444     assert(ra_-&gt;is_oop(this) == true, &quot;A decodeN node must produce an oop!&quot;);
 3445     ra_-&gt;set_oop(n2, true);
 3446 
 3447     nodes-&gt;push(n1);
 3448     nodes-&gt;push(n2);
 3449   %}
 3450 
 3451   enc_class enc_cmove_reg(iRegIdst dst, flagsRegSrc crx, iRegIsrc src, cmpOp cmp) %{
 3452     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3453 
<span class="line-modified"> 3454     MacroAssembler _masm(&amp;cbuf);</span>
 3455     int cc        = $cmp$$cmpcode;
 3456     int flags_reg = $crx$$reg;
 3457     Label done;
 3458     assert((Assembler::bcondCRbiIs1 &amp; ~Assembler::bcondCRbiIs0) == 8, &quot;check encoding&quot;);
 3459     // Branch if not (cmp crx).
 3460     __ bc(cc_to_inverse_boint(cc), cc_to_biint(cc, flags_reg), done);
 3461     __ mr($dst$$Register, $src$$Register);
 3462     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3463     __ bind(done);
 3464   %}
 3465 
 3466   enc_class enc_cmove_imm(iRegIdst dst, flagsRegSrc crx, immI16 src, cmpOp cmp) %{
 3467     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3468 
<span class="line-modified"> 3469     MacroAssembler _masm(&amp;cbuf);</span>
 3470     Label done;
 3471     assert((Assembler::bcondCRbiIs1 &amp; ~Assembler::bcondCRbiIs0) == 8, &quot;check encoding&quot;);
 3472     // Branch if not (cmp crx).
 3473     __ bc(cc_to_inverse_boint($cmp$$cmpcode), cc_to_biint($cmp$$cmpcode, $crx$$reg), done);
 3474     __ li($dst$$Register, $src$$constant);
 3475     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3476     __ bind(done);
 3477   %}
 3478 
 3479   // This enc_class is needed so that scheduler gets proper
 3480   // input mapping for latency computation.
 3481   enc_class enc_andc(iRegIdst dst, iRegIsrc src1, iRegIsrc src2) %{
 3482     // TODO: PPC port $archOpcode(ppc64Opcode_andc);
<span class="line-modified"> 3483     MacroAssembler _masm(&amp;cbuf);</span>
 3484     __ andc($dst$$Register, $src1$$Register, $src2$$Register);
 3485   %}
 3486 
 3487   enc_class enc_convI2B_regI__cmove(iRegIdst dst, iRegIsrc src, flagsReg crx, immI16 zero, immI16 notzero) %{
 3488     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3489 
<span class="line-modified"> 3490     MacroAssembler _masm(&amp;cbuf);</span>
 3491 
 3492     Label done;
 3493     __ cmpwi($crx$$CondRegister, $src$$Register, 0);
 3494     __ li($dst$$Register, $zero$$constant);
 3495     __ beq($crx$$CondRegister, done);
 3496     __ li($dst$$Register, $notzero$$constant);
 3497     __ bind(done);
 3498   %}
 3499 
 3500   enc_class enc_convP2B_regP__cmove(iRegIdst dst, iRegPsrc src, flagsReg crx, immI16 zero, immI16 notzero) %{
 3501     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3502 
<span class="line-modified"> 3503     MacroAssembler _masm(&amp;cbuf);</span>
 3504 
 3505     Label done;
 3506     __ cmpdi($crx$$CondRegister, $src$$Register, 0);
 3507     __ li($dst$$Register, $zero$$constant);
 3508     __ beq($crx$$CondRegister, done);
 3509     __ li($dst$$Register, $notzero$$constant);
 3510     __ bind(done);
 3511   %}
 3512 
 3513   enc_class enc_cmove_bso_stackSlotL(iRegLdst dst, flagsRegSrc crx, stackSlotL mem ) %{
 3514     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3515 
<span class="line-modified"> 3516     MacroAssembler _masm(&amp;cbuf);</span>
 3517     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3518     Label done;
 3519     __ bso($crx$$CondRegister, done);
 3520     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
 3521     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3522     __ bind(done);
 3523   %}
 3524 
 3525   enc_class enc_cmove_bso_reg(iRegLdst dst, flagsRegSrc crx, regD src) %{
 3526     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3527 
<span class="line-modified"> 3528     MacroAssembler _masm(&amp;cbuf);</span>
 3529     Label done;
 3530     __ bso($crx$$CondRegister, done);
 3531     __ mffprd($dst$$Register, $src$$FloatRegister);
 3532     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3533     __ bind(done);
 3534   %}
 3535 
 3536   enc_class enc_bc(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
 3537     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 3538 
<span class="line-modified"> 3539     MacroAssembler _masm(&amp;cbuf);</span>
 3540     Label d;   // dummy
 3541     __ bind(d);
 3542     Label* p = ($lbl$$label);
 3543     // `p&#39; is `NULL&#39; when this encoding class is used only to
 3544     // determine the size of the encoded instruction.
 3545     Label&amp; l = (NULL == p)? d : *(p);
 3546     int cc = $cmp$$cmpcode;
 3547     int flags_reg = $crx$$reg;
 3548     assert((Assembler::bcondCRbiIs1 &amp; ~Assembler::bcondCRbiIs0) == 8, &quot;check encoding&quot;);
 3549     int bhint = Assembler::bhintNoHint;
 3550 
 3551     if (UseStaticBranchPredictionForUncommonPathsPPC64) {
 3552       if (_prob &lt;= PROB_NEVER) {
 3553         bhint = Assembler::bhintIsNotTaken;
 3554       } else if (_prob &gt;= PROB_ALWAYS) {
 3555         bhint = Assembler::bhintIsTaken;
 3556       }
 3557     }
 3558 
 3559     __ bc(Assembler::add_bhint_to_boint(bhint, cc_to_boint(cc)),
 3560           cc_to_biint(cc, flags_reg),
 3561           l);
 3562   %}
 3563 
 3564   enc_class enc_bc_far(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
 3565     // The scheduler doesn&#39;t know about branch shortening, so we set the opcode
 3566     // to ppc64Opcode_bc in order to hide this detail from the scheduler.
 3567     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 3568 
<span class="line-modified"> 3569     MacroAssembler _masm(&amp;cbuf);</span>
 3570     Label d;    // dummy
 3571     __ bind(d);
 3572     Label* p = ($lbl$$label);
 3573     // `p&#39; is `NULL&#39; when this encoding class is used only to
 3574     // determine the size of the encoded instruction.
 3575     Label&amp; l = (NULL == p)? d : *(p);
 3576     int cc = $cmp$$cmpcode;
 3577     int flags_reg = $crx$$reg;
 3578     int bhint = Assembler::bhintNoHint;
 3579 
 3580     if (UseStaticBranchPredictionForUncommonPathsPPC64) {
 3581       if (_prob &lt;= PROB_NEVER) {
 3582         bhint = Assembler::bhintIsNotTaken;
 3583       } else if (_prob &gt;= PROB_ALWAYS) {
 3584         bhint = Assembler::bhintIsTaken;
 3585       }
 3586     }
 3587 
 3588     // Tell the conditional far branch to optimize itself when being relocated.
 3589     __ bc_far(Assembler::add_bhint_to_boint(bhint, cc_to_boint(cc)),
 3590                   cc_to_biint(cc, flags_reg),
 3591                   l,
 3592                   MacroAssembler::bc_far_optimize_on_relocate);
 3593   %}
 3594 
 3595   // Branch used with Power6 scheduling (can be shortened without changing the node).
 3596   enc_class enc_bc_short_far(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
 3597     // The scheduler doesn&#39;t know about branch shortening, so we set the opcode
 3598     // to ppc64Opcode_bc in order to hide this detail from the scheduler.
 3599     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 3600 
<span class="line-modified"> 3601     MacroAssembler _masm(&amp;cbuf);</span>
 3602     Label d;   // dummy
 3603     __ bind(d);
 3604     Label* p = ($lbl$$label);
 3605     // `p&#39; is `NULL&#39; when this encoding class is used only to
 3606     // determine the size of the encoded instruction.
 3607     Label&amp; l = (NULL == p)? d : *(p);
 3608     int cc = $cmp$$cmpcode;
 3609     int flags_reg = $crx$$reg;
 3610     int bhint = Assembler::bhintNoHint;
 3611 
 3612     if (UseStaticBranchPredictionForUncommonPathsPPC64) {
 3613       if (_prob &lt;= PROB_NEVER) {
 3614         bhint = Assembler::bhintIsNotTaken;
 3615       } else if (_prob &gt;= PROB_ALWAYS) {
 3616         bhint = Assembler::bhintIsTaken;
 3617       }
 3618     }
 3619 
 3620 #if 0 // TODO: PPC port
 3621     if (_size == 8) {
</pre>
<hr />
<pre>
 3666       loadConLReplicatedNodesTuple_create(C, ra_, n_toc, op_repl, op_dst, op_zero,
 3667                                 ra_-&gt;get_reg_second(n_tmp), ra_-&gt;get_reg_first(n_tmp),
 3668                                 ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3669 
 3670     // Push new nodes.
 3671     if (loadConLNodes._large_hi) { nodes-&gt;push(loadConLNodes._large_hi); }
 3672     if (loadConLNodes._large_lo) { nodes-&gt;push(loadConLNodes._large_lo); }
 3673     if (loadConLNodes._moved)    { nodes-&gt;push(loadConLNodes._moved); }
 3674     if (loadConLNodes._last)     { nodes-&gt;push(loadConLNodes._last); }
 3675 
 3676     assert(nodes-&gt;length() &gt;= 1, &quot;must have created at least 1 node&quot;);
 3677   %}
 3678 
 3679   // This enc_class is needed so that scheduler gets proper
 3680   // input mapping for latency computation.
 3681   enc_class enc_poll(immI dst, iRegLdst poll) %{
 3682     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
 3683     // Fake operand dst needed for PPC scheduler.
 3684     assert($dst$$constant == 0x0, &quot;dst must be 0x0&quot;);
 3685 
<span class="line-modified"> 3686     MacroAssembler _masm(&amp;cbuf);</span>
 3687     // Mark the code position where the load from the safepoint
 3688     // polling page was emitted as relocInfo::poll_type.
 3689     __ relocate(relocInfo::poll_type);
 3690     __ load_from_polling_page($poll$$Register);
 3691   %}
 3692 
 3693   // A Java static call or a runtime call.
 3694   //
 3695   // Branch-and-link relative to a trampoline.
 3696   // The trampoline loads the target address and does a long branch to there.
 3697   // In case we call java, the trampoline branches to a interpreter_stub
 3698   // which loads the inline cache and the real call target from the constant pool.
 3699   //
 3700   // This basically looks like this:
 3701   //
 3702   // &gt;&gt;&gt;&gt; consts      -+  -+
 3703   //                   |   |- offset1
 3704   // [call target1]    | &lt;-+
 3705   // [IC cache]        |- offset2
 3706   // [call target2] &lt;--+
</pre>
<hr />
<pre>
 3722   //   r1 = toc
 3723   //   ICreg = [r1 + IC_offset]         // Load IC from const section
 3724   //   r1    = [r1 + offset2]           // Load call target2 from const section
 3725   //   mtctr r1
 3726   //   bctr
 3727   //
 3728   // &lt;&lt;&lt;&lt; stubs
 3729   //
 3730   // The call instruction in the code either
 3731   // - Branches directly to a compiled method if the offset is encodable in instruction.
 3732   // - Branches to the trampoline stub if the offset to the compiled method is not encodable.
 3733   // - Branches to the compiled_to_interp stub if the target is interpreted.
 3734   //
 3735   // Further there are three relocations from the loads to the constants in
 3736   // the constant section.
 3737   //
 3738   // Usage of r1 and r2 in the stubs allows to distinguish them.
 3739   enc_class enc_java_static_call(method meth) %{
 3740     // TODO: PPC port $archOpcode(ppc64Opcode_bl);
 3741 
<span class="line-modified"> 3742     MacroAssembler _masm(&amp;cbuf);</span>
 3743     address entry_point = (address)$meth$$method;
 3744 
 3745     if (!_method) {
 3746       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3747       emit_call_with_trampoline_stub(_masm, entry_point, relocInfo::runtime_call_type);
 3748     } else {
 3749       // Remember the offset not the address.
 3750       const int start_offset = __ offset();
 3751 
 3752       // The trampoline stub.
 3753       // No entry point given, use the current pc.
 3754       // Make sure branch fits into
 3755       if (entry_point == 0) entry_point = __ pc();
 3756 
 3757       // Put the entry point as a constant into the constant pool.
 3758       const address entry_point_toc_addr = __ address_constant(entry_point, RelocationHolder::none);
 3759       if (entry_point_toc_addr == NULL) {
 3760         ciEnv::current()-&gt;record_out_of_memory_failure();
 3761         return;
 3762       }
</pre>
<hr />
<pre>
 3772       // The real call.
 3773       // Note: At this point we do not have the address of the trampoline
 3774       // stub, and the entry point might be too far away for bl, so __ pc()
 3775       // serves as dummy and the bl will be patched later.
 3776       cbuf.set_insts_mark();
 3777       __ bl(__ pc());  // Emits a relocation.
 3778 
 3779       // The stub for call to interpreter.
 3780       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3781       if (stub == NULL) {
 3782         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3783         return;
 3784       }
 3785     }
 3786   %}
 3787 
 3788   // Second node of expanded dynamic call - the call.
 3789   enc_class enc_java_dynamic_call_sched(method meth) %{
 3790     // TODO: PPC port $archOpcode(ppc64Opcode_bl);
 3791 
<span class="line-modified"> 3792     MacroAssembler _masm(&amp;cbuf);</span>
 3793 
<span class="line-modified"> 3794     if (!ra_-&gt;C-&gt;in_scratch_emit_size()) {</span>
 3795       // Create a call trampoline stub for the given method.
 3796       const address entry_point = !($meth$$method) ? 0 : (address)$meth$$method;
 3797       const address entry_point_const = __ address_constant(entry_point, RelocationHolder::none);
 3798       if (entry_point_const == NULL) {
 3799         ciEnv::current()-&gt;record_out_of_memory_failure();
 3800         return;
 3801       }
 3802       const int entry_point_const_toc_offset = __ offset_to_method_toc(entry_point_const);
 3803       CallStubImpl::emit_trampoline_stub(_masm, entry_point_const_toc_offset, __ offset());
 3804       if (ra_-&gt;C-&gt;env()-&gt;failing()) { return; } // Code cache may be full.
 3805 
 3806       // Build relocation at call site with ic position as data.
 3807       assert((_load_ic_hi_node != NULL &amp;&amp; _load_ic_node == NULL) ||
 3808              (_load_ic_hi_node == NULL &amp;&amp; _load_ic_node != NULL),
 3809              &quot;must have one, but can&#39;t have both&quot;);
 3810       assert((_load_ic_hi_node != NULL &amp;&amp; _load_ic_hi_node-&gt;_cbuf_insts_offset != -1) ||
 3811              (_load_ic_node != NULL    &amp;&amp; _load_ic_node-&gt;_cbuf_insts_offset != -1),
 3812              &quot;must contain instruction offset&quot;);
 3813       const int virtual_call_oop_addr_offset = _load_ic_hi_node != NULL
 3814         ? _load_ic_hi_node-&gt;_cbuf_insts_offset
</pre>
<hr />
<pre>
 3875     call-&gt;_load_ic_node    = loadConLNodes_IC._small;
 3876 
 3877     // Operands for new nodes.
 3878     call-&gt;_opnds[0] = _opnds[0];
 3879     call-&gt;_opnds[1] = _opnds[1];
 3880 
 3881     // Only the inline cache is associated with a register.
 3882     assert(Matcher::inline_cache_reg() == OptoReg::Name(R19_num), &quot;ic reg should be R19&quot;);
 3883 
 3884     // Push new nodes.
 3885     if (loadConLNodes_IC._large_hi) nodes-&gt;push(loadConLNodes_IC._large_hi);
 3886     if (loadConLNodes_IC._last)     nodes-&gt;push(loadConLNodes_IC._last);
 3887     nodes-&gt;push(call);
 3888   %}
 3889 
 3890   // Compound version of call dynamic
 3891   // Toc is only passed so that it can be used in ins_encode statement.
 3892   // In the code we have to use $constanttablebase.
 3893   enc_class enc_java_dynamic_call(method meth, iRegLdst toc) %{
 3894     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 3895     MacroAssembler _masm(&amp;cbuf);</span>
 3896     int start_offset = __ offset();
 3897 
 3898     Register Rtoc = (ra_) ? $constanttablebase : R2_TOC;
 3899 #if 0
 3900     int vtable_index = this-&gt;_vtable_index;
 3901     if (_vtable_index &lt; 0) {
 3902       // Must be invalid_vtable_index, not nonvirtual_vtable_index.
 3903       assert(_vtable_index == Method::invalid_vtable_index, &quot;correct sentinel value&quot;);
 3904       Register ic_reg = as_Register(Matcher::inline_cache_reg_encode());
 3905 
 3906       // Virtual call relocation will point to ic load.
 3907       address virtual_call_meta_addr = __ pc();
 3908       // Load a clear inline cache.
 3909       AddressLiteral empty_ic((address) Universe::non_oop_word());
 3910       bool success = __ load_const_from_method_toc(ic_reg, empty_ic, Rtoc, /*fixed_size*/ true);
 3911       if (!success) {
 3912         ciEnv::current()-&gt;record_out_of_memory_failure();
 3913         return;
 3914       }
 3915       // CALL to fixup routine.  Fixup routine uses ScopeDesc info
</pre>
<hr />
<pre>
 3934       // null. However it may very well end up in handle_wrong_method
 3935       // if the method is abstract for the particular class.
 3936       __ ld(R11_scratch1, in_bytes(Method::from_compiled_offset()), R19_method);
 3937       // Call target. Either compiled code or C2I adapter.
 3938       __ mtctr(R11_scratch1);
 3939       __ bctrl();
 3940       if (((MachCallDynamicJavaNode*)this)-&gt;ret_addr_offset() != __ offset() - start_offset) {
 3941         tty-&gt;print(&quot; %d, %d\n&quot;, ((MachCallDynamicJavaNode*)this)-&gt;ret_addr_offset(),__ offset() - start_offset);
 3942       }
 3943       assert(((MachCallDynamicJavaNode*)this)-&gt;ret_addr_offset() == __ offset() - start_offset,
 3944              &quot;Fix constant in ret_addr_offset()&quot;);
 3945     }
 3946 #endif
 3947     Unimplemented();  // ret_addr_offset not yet fixed. Depends on compressed oops (load klass!).
 3948   %}
 3949 
 3950   // a runtime call
 3951   enc_class enc_java_to_runtime_call (method meth) %{
 3952     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3953 
<span class="line-modified"> 3954     MacroAssembler _masm(&amp;cbuf);</span>
 3955     const address start_pc = __ pc();
 3956 
 3957 #if defined(ABI_ELFv2)
 3958     address entry= !($meth$$method) ? NULL : (address)$meth$$method;
 3959     __ call_c(entry, relocInfo::runtime_call_type);
 3960 #else
 3961     // The function we&#39;re going to call.
 3962     FunctionDescriptor fdtemp;
 3963     const FunctionDescriptor* fd = !($meth$$method) ? &amp;fdtemp : (FunctionDescriptor*)$meth$$method;
 3964 
 3965     Register Rtoc = R12_scratch2;
 3966     // Calculate the method&#39;s TOC.
 3967     __ calculate_address_from_global_toc(Rtoc, __ method_toc());
 3968     // Put entry, env, toc into the constant pool, this needs up to 3 constant
 3969     // pool entries; call_c_using_toc will optimize the call.
 3970     bool success = __ call_c_using_toc(fd, relocInfo::runtime_call_type, Rtoc);
 3971     if (!success) {
 3972       ciEnv::current()-&gt;record_out_of_memory_failure();
 3973       return;
 3974     }
 3975 #endif
 3976 
 3977     // Check the ret_addr_offset.
 3978     assert(((MachCallRuntimeNode*)this)-&gt;ret_addr_offset() ==  __ last_calls_return_pc() - start_pc,
 3979            &quot;Fix constant in ret_addr_offset()&quot;);
 3980   %}
 3981 
 3982   // Move to ctr for leaf call.
 3983   // This enc_class is needed so that scheduler gets proper
 3984   // input mapping for latency computation.
 3985   enc_class enc_leaf_call_mtctr(iRegLsrc src) %{
 3986     // TODO: PPC port $archOpcode(ppc64Opcode_mtctr);
<span class="line-modified"> 3987     MacroAssembler _masm(&amp;cbuf);</span>
 3988     __ mtctr($src$$Register);
 3989   %}
 3990 
 3991   // Postalloc expand emitter for runtime leaf calls.
 3992   enc_class postalloc_expand_java_to_runtime_call(method meth, iRegLdst toc) %{
 3993     loadConLNodesTuple loadConLNodes_Entry;
 3994 #if defined(ABI_ELFv2)
 3995     jlong entry_address = (jlong) this-&gt;entry_point();
 3996     assert(entry_address, &quot;need address here&quot;);
 3997     loadConLNodes_Entry = loadConLNodesTuple_create(ra_, n_toc, new immLOper(entry_address),
 3998                                                     OptoReg::Name(R12_H_num), OptoReg::Name(R12_num));
 3999 #else
 4000     // Get the struct that describes the function we are about to call.
 4001     FunctionDescriptor* fd = (FunctionDescriptor*) this-&gt;entry_point();
 4002     assert(fd, &quot;need fd here&quot;);
 4003     jlong entry_address = (jlong) fd-&gt;entry();
 4004     // new nodes
 4005     loadConLNodesTuple loadConLNodes_Env;
 4006     loadConLNodesTuple loadConLNodes_Toc;
 4007 
</pre>
<hr />
<pre>
 6268   ins_field_cbuf_insts_offset(int);
 6269 
 6270   format %{ &quot;ADDIS   $dst, $toc, offset \t// load long $src from TOC (hi)&quot; %}
 6271   size(4);
 6272   ins_encode( enc_load_long_constL_hi(dst, toc, src) );
 6273   ins_pipe(pipe_class_default);
 6274 %}
 6275 
 6276 // Expand node for constant pool load: large offset.
 6277 // No constant pool entries required.
 6278 instruct loadConL_lo(iRegLdst dst, immL src, iRegLdst base) %{
 6279   effect(DEF dst, USE src, USE base);
 6280   predicate(false);
 6281 
 6282   ins_field_const_toc_offset_hi_node(loadConL_hiNode*);
 6283 
 6284   format %{ &quot;LD      $dst, offset, $base \t// load long $src from TOC (lo)&quot; %}
 6285   size(4);
 6286   ins_encode %{
 6287     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
<span class="line-modified"> 6288     int offset = ra_-&gt;C-&gt;in_scratch_emit_size() ? 0 : _const_toc_offset_hi_node-&gt;_const_toc_offset;</span>
 6289     __ ld($dst$$Register, MacroAssembler::largeoffset_si16_si16_lo(offset), $base$$Register);
 6290   %}
 6291   ins_pipe(pipe_class_memory);
 6292 %}
 6293 
 6294 // Load long constant from constant table. Expand in case of
 6295 // offset &gt; 16 bit is needed.
 6296 // Adlc adds toc node MachConstantTableBase.
 6297 instruct loadConL_Ex(iRegLdst dst, immL src) %{
 6298   match(Set dst src);
 6299   ins_cost(MEMORY_REF_COST);
 6300 
 6301   format %{ &quot;LD      $dst, offset, $constanttablebase\t// load long $src from table, postalloc expanded&quot; %}
 6302   // We can not inline the enc_class for the expand as that does not support constanttablebase.
 6303   postalloc_expand( postalloc_expand_load_long_constant(dst, src, constanttablebase) );
 6304 %}
 6305 
 6306 // Load NULL as compressed oop.
 6307 instruct loadConN0(iRegNdst dst, immN_0 src) %{
 6308   match(Set dst src);
</pre>
<hr />
<pre>
 6553   ins_num_consts(1);
 6554   ins_field_const_toc_offset(int);
 6555 
 6556   format %{ &quot;ADDIS   $dst, $toc, offset \t// load ptr $src from TOC (hi)&quot; %}
 6557   size(4);
 6558   ins_encode( enc_load_long_constP_hi(dst, src, toc) );
 6559   ins_pipe(pipe_class_default);
 6560 %}
 6561 
 6562 // Expand node for constant pool load: large offset.
 6563 instruct loadConP_lo(iRegPdst dst, immP_NM src, iRegLdst base) %{
 6564   match(Set dst src);
 6565   effect(TEMP base);
 6566 
 6567   ins_field_const_toc_offset_hi_node(loadConP_hiNode*);
 6568 
 6569   format %{ &quot;LD      $dst, offset, $base \t// load ptr $src from TOC (lo)&quot; %}
 6570   size(4);
 6571   ins_encode %{
 6572     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
<span class="line-modified"> 6573     int offset = ra_-&gt;C-&gt;in_scratch_emit_size() ? 0 : _const_toc_offset_hi_node-&gt;_const_toc_offset;</span>
 6574     __ ld($dst$$Register, MacroAssembler::largeoffset_si16_si16_lo(offset), $base$$Register);
 6575   %}
 6576   ins_pipe(pipe_class_memory);
 6577 %}
 6578 
 6579 // Load pointer constant from constant table. Expand in case an
 6580 // offset &gt; 16 bit is needed.
 6581 // Adlc adds toc node MachConstantTableBase.
 6582 instruct loadConP_Ex(iRegPdst dst, immP src) %{
 6583   match(Set dst src);
 6584   ins_cost(MEMORY_REF_COST);
 6585 
 6586   // This rule does not use &quot;expand&quot; because then
 6587   // the result type is not known to be an Oop.  An ADLC
 6588   // enhancement will be needed to make that work - not worth it!
 6589 
 6590   // If this instruction rematerializes, it prolongs the live range
 6591   // of the toc node, causing illegal graphs.
 6592   // assert(edge_from_to(_reg_node[reg_lo],def)) fails in verify_good_schedule().
 6593   ins_cannot_rematerialize(true);
</pre>
</td>
<td>
<hr />
<pre>
    1 //
<span class="line-modified">    2 // Copyright (c) 2011, 2020, Oracle and/or its affiliates. All rights reserved.</span>
    3 // Copyright (c) 2012, 2019 SAP SE. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
</pre>
<hr />
<pre>
  965 // This is a block of C++ code which provides values, functions, and
  966 // definitions necessary in the rest of the architecture description.
  967 source_hpp %{
  968   // Header information of the source block.
  969   // Method declarations/definitions which are used outside
  970   // the ad-scope can conveniently be defined here.
  971   //
  972   // To keep related declarations/definitions/uses close together,
  973   // we switch between source %{ }% and source_hpp %{ }% freely as needed.
  974 
  975 #include &quot;opto/convertnode.hpp&quot;
  976 
  977   // Returns true if Node n is followed by a MemBar node that
  978   // will do an acquire. If so, this node must not do the acquire
  979   // operation.
  980   bool followed_by_acquire(const Node *n);
  981 %}
  982 
  983 source %{
  984 
<span class="line-added">  985 void PhaseOutput::pd_perform_mach_node_analysis() {</span>
<span class="line-added">  986 }</span>
<span class="line-added">  987 </span>
<span class="line-added">  988 int MachNode::pd_alignment_required() const {</span>
<span class="line-added">  989   return 1;</span>
<span class="line-added">  990 }</span>
<span class="line-added">  991 </span>
<span class="line-added">  992 int MachNode::compute_padding(int current_offset) const {</span>
<span class="line-added">  993   return 0;</span>
<span class="line-added">  994 }</span>
<span class="line-added">  995 </span>
<span class="line-added">  996 // Should the matcher clone input &#39;m&#39; of node &#39;n&#39;?</span>
<span class="line-added">  997 bool Matcher::pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {</span>
<span class="line-added">  998   return false;</span>
<span class="line-added">  999 }</span>
<span class="line-added"> 1000 </span>
 1001 // Should the Matcher clone shifts on addressing modes, expecting them
 1002 // to be subsumed into complex addressing expressions or compute them
 1003 // into registers?
<span class="line-modified"> 1004 bool Matcher::pd_clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {</span>
 1005   return clone_base_plus_offset_address(m, mstack, address_visited);
 1006 }
 1007 
 1008 void Compile::reshape_address(AddPNode* addp) {
 1009 }
 1010 
 1011 // Optimize load-acquire.
 1012 //
 1013 // Check if acquire is unnecessary due to following operation that does
 1014 // acquire anyways.
 1015 // Walk the pattern:
 1016 //
 1017 //      n: Load.acq
 1018 //           |
 1019 //      MemBarAcquire
 1020 //       |         |
 1021 //  Proj(ctrl)  Proj(mem)
 1022 //       |         |
 1023 //   MemBarRelease/Volatile
 1024 //
</pre>
<hr />
<pre>
 1143 //=============================================================================
 1144 
 1145 // Compute padding required for nodes which need alignment. The padding
 1146 // is the number of bytes (not instructions) which will be inserted before
 1147 // the instruction. The padding must match the size of a NOP instruction.
 1148 
 1149 // Currently not used on this platform.
 1150 
 1151 //=============================================================================
 1152 
 1153 // Indicate if the safepoint node needs the polling page as an input.
 1154 bool SafePointNode::needs_polling_address_input() {
 1155   // The address is loaded from thread by a seperate node.
 1156   return true;
 1157 }
 1158 
 1159 //=============================================================================
 1160 
 1161 // Emit an interrupt that is caught by the debugger (for debugging compiler).
 1162 void emit_break(CodeBuffer &amp;cbuf) {
<span class="line-modified"> 1163   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1164   __ illtrap();
 1165 }
 1166 
 1167 #ifndef PRODUCT
 1168 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1169   st-&gt;print(&quot;BREAKPOINT&quot;);
 1170 }
 1171 #endif
 1172 
 1173 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1174   emit_break(cbuf);
 1175 }
 1176 
 1177 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1178   return MachNode::size(ra_);
 1179 }
 1180 
 1181 //=============================================================================
 1182 
 1183 void emit_nop(CodeBuffer &amp;cbuf) {
<span class="line-modified"> 1184   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1185   __ nop();
 1186 }
 1187 
 1188 static inline void emit_long(CodeBuffer &amp;cbuf, int value) {
 1189   *((int*)(cbuf.insts_end())) = value;
 1190   cbuf.set_insts_end(cbuf.insts_end() + BytesPerInstWord);
 1191 }
 1192 
 1193 //=============================================================================
 1194 
 1195 %} // interrupt source
 1196 
 1197 source_hpp %{ // Header information of the source block.
 1198 
 1199 //--------------------------------------------------------------
 1200 //---&lt;  Used for optimization in Compile::Shorten_branches  &gt;---
 1201 //--------------------------------------------------------------
 1202 
<span class="line-added"> 1203 class C2_MacroAssembler;</span>
<span class="line-added"> 1204 </span>
 1205 class CallStubImpl {
 1206 
 1207  public:
 1208 
 1209   // Emit call stub, compiled java to interpreter.
<span class="line-modified"> 1210   static void emit_trampoline_stub(C2_MacroAssembler &amp;_masm, int destination_toc_offset, int insts_call_instruction_offset);</span>
 1211 
 1212   // Size of call trampoline stub.
 1213   // This doesn&#39;t need to be accurate to the byte, but it
 1214   // must be larger than or equal to the real size of the stub.
 1215   static uint size_call_trampoline() {
 1216     return MacroAssembler::trampoline_stub_size;
 1217   }
 1218 
 1219   // number of relocations needed by a call trampoline stub
 1220   static uint reloc_call_trampoline() {
 1221     return 5;
 1222   }
 1223 
 1224 };
 1225 
 1226 %} // end source_hpp
 1227 
 1228 source %{
 1229 
 1230 // Emit a trampoline stub for a call to a target which is too far away.
 1231 //
 1232 // code sequences:
 1233 //
 1234 // call-site:
 1235 //   branch-and-link to &lt;destination&gt; or &lt;trampoline stub&gt;
 1236 //
 1237 // Related trampoline stub for this call-site in the stub section:
 1238 //   load the call target from the constant pool
 1239 //   branch via CTR (LR/link still points to the call-site above)
 1240 
<span class="line-modified"> 1241 void CallStubImpl::emit_trampoline_stub(C2_MacroAssembler &amp;_masm, int destination_toc_offset, int insts_call_instruction_offset) {</span>
 1242   address stub = __ emit_trampoline_stub(destination_toc_offset, insts_call_instruction_offset);
 1243   if (stub == NULL) {
 1244     ciEnv::current()-&gt;record_out_of_memory_failure();
 1245   }
 1246 }
 1247 
 1248 //=============================================================================
 1249 
 1250 // Emit an inline branch-and-link call and a related trampoline stub.
 1251 //
 1252 // code sequences:
 1253 //
 1254 // call-site:
 1255 //   branch-and-link to &lt;destination&gt; or &lt;trampoline stub&gt;
 1256 //
 1257 // Related trampoline stub for this call-site in the stub section:
 1258 //   load the call target from the constant pool
 1259 //   branch via CTR (LR/link still points to the call-site above)
 1260 //
 1261 
 1262 typedef struct {
 1263   int insts_call_instruction_offset;
 1264   int ret_addr_offset;
 1265 } EmitCallOffsets;
 1266 
 1267 // Emit a branch-and-link instruction that branches to a trampoline.
 1268 // - Remember the offset of the branch-and-link instruction.
 1269 // - Add a relocation at the branch-and-link instruction.
 1270 // - Emit a branch-and-link.
 1271 // - Remember the return pc offset.
<span class="line-modified"> 1272 EmitCallOffsets emit_call_with_trampoline_stub(C2_MacroAssembler &amp;_masm, address entry_point, relocInfo::relocType rtype) {</span>
 1273   EmitCallOffsets offsets = { -1, -1 };
 1274   const int start_offset = __ offset();
 1275   offsets.insts_call_instruction_offset = __ offset();
 1276 
 1277   // No entry point given, use the current pc.
 1278   if (entry_point == NULL) entry_point = __ pc();
 1279 
 1280   // Put the entry point as a constant into the constant pool.
 1281   const address entry_point_toc_addr   = __ address_constant(entry_point, RelocationHolder::none);
 1282   if (entry_point_toc_addr == NULL) {
 1283     ciEnv::current()-&gt;record_out_of_memory_failure();
 1284     return offsets;
 1285   }
 1286   const int     entry_point_toc_offset = __ offset_to_method_toc(entry_point_toc_addr);
 1287 
 1288   // Emit the trampoline stub which will be related to the branch-and-link below.
 1289   CallStubImpl::emit_trampoline_stub(_masm, entry_point_toc_offset, offsets.insts_call_instruction_offset);
 1290   if (ciEnv::current()-&gt;failing()) { return offsets; } // Code cache may be full.
 1291   __ relocate(rtype);
 1292 
</pre>
<hr />
<pre>
 1298   offsets.ret_addr_offset = __ offset() - start_offset;
 1299 
 1300   return offsets;
 1301 }
 1302 
 1303 //=============================================================================
 1304 
 1305 // Factory for creating loadConL* nodes for large/small constant pool.
 1306 
 1307 static inline jlong replicate_immF(float con) {
 1308   // Replicate float con 2 times and pack into vector.
 1309   int val = *((int*)&amp;con);
 1310   jlong lval = val;
 1311   lval = (lval &lt;&lt; 32) | (lval &amp; 0xFFFFFFFFl);
 1312   return lval;
 1313 }
 1314 
 1315 //=============================================================================
 1316 
 1317 const RegMask&amp; MachConstantBaseNode::_out_RegMask = BITS64_CONSTANT_TABLE_BASE_mask();
<span class="line-modified"> 1318 int ConstantTable::calculate_table_base_offset() const {</span>
 1319   return 0;  // absolute addressing, no offset
 1320 }
 1321 
 1322 bool MachConstantBaseNode::requires_postalloc_expand() const { return true; }
 1323 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1324   iRegPdstOper *op_dst = new iRegPdstOper();
 1325   MachNode *m1 = new loadToc_hiNode();
 1326   MachNode *m2 = new loadToc_loNode();
 1327 
 1328   m1-&gt;add_req(NULL);
 1329   m2-&gt;add_req(NULL, m1);
 1330   m1-&gt;_opnds[0] = op_dst;
 1331   m2-&gt;_opnds[0] = op_dst;
 1332   m2-&gt;_opnds[1] = op_dst;
 1333   ra_-&gt;set_pair(m1-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 1334   ra_-&gt;set_pair(m2-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 1335   nodes-&gt;push(m1);
 1336   nodes-&gt;push(m2);
 1337 }
 1338 
 1339 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1340   // Is postalloc expanded.
 1341   ShouldNotReachHere();
 1342 }
 1343 
 1344 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1345   return 0;
 1346 }
 1347 
 1348 #ifndef PRODUCT
 1349 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1350   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1351 }
 1352 #endif
 1353 
 1354 //=============================================================================
 1355 
 1356 #ifndef PRODUCT
 1357 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1358   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1359   const long framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1360 
 1361   st-&gt;print(&quot;PROLOG\n\t&quot;);
<span class="line-modified"> 1362   if (C-&gt;output()-&gt;need_stack_bang(framesize)) {</span>
 1363     st-&gt;print(&quot;stack_overflow_check\n\t&quot;);
 1364   }
 1365 
 1366   if (!false /* TODO: PPC port C-&gt;is_frameless_method()*/) {
 1367     st-&gt;print(&quot;save return pc\n\t&quot;);
 1368     st-&gt;print(&quot;push frame %ld\n\t&quot;, -framesize);
 1369   }
 1370 }
 1371 #endif
 1372 
 1373 // Macro used instead of the common __ to emulate the pipes of PPC.
 1374 // Instead of e.g. __ ld(...) one hase to write ___(ld) ld(...) This enables the
 1375 // micro scheduler to cope with &quot;hand written&quot; assembler like in the prolog. Though
 1376 // still no scheduling of this code is possible, the micro scheduler is aware of the
 1377 // code and can update its internal data. The following mechanism is used to achieve this:
 1378 // The micro scheduler calls size() of each compound node during scheduling. size() does a
 1379 // dummy emit and only during this dummy emit C-&gt;hb_scheduling() is not NULL.
 1380 #if 0 // TODO: PPC port
 1381 #define ___(op) if (UsePower6SchedulerPPC64 &amp;&amp; C-&gt;hb_scheduling())                    \
 1382                   C-&gt;hb_scheduling()-&gt;_pdScheduling-&gt;PdEmulatePipe(ppc64Opcode_##op); \
 1383                 _masm.
 1384 #define ___stop if (UsePower6SchedulerPPC64 &amp;&amp; C-&gt;hb_scheduling())                    \
 1385                   C-&gt;hb_scheduling()-&gt;_pdScheduling-&gt;PdEmulatePipe(archOpcode_none)
 1386 #define ___advance if (UsePower6SchedulerPPC64 &amp;&amp; C-&gt;hb_scheduling())                 \
 1387                   C-&gt;hb_scheduling()-&gt;_pdScheduling-&gt;advance_offset
 1388 #else
 1389 #define ___(op) if (UsePower6SchedulerPPC64)                                          \
 1390                   Unimplemented();                                                    \
 1391                 _masm.
 1392 #define ___stop if (UsePower6SchedulerPPC64)                                          \
 1393                   Unimplemented()
 1394 #define ___advance if (UsePower6SchedulerPPC64)                                       \
 1395                   Unimplemented()
 1396 #endif
 1397 
 1398 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1399   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1400   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1401 
<span class="line-modified"> 1402   const long framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
 1403   assert(framesize % (2 * wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1404 
 1405   const bool method_is_frameless      = false /* TODO: PPC port C-&gt;is_frameless_method()*/;
 1406 
 1407   const Register return_pc            = R20; // Must match return_addr() in frame section.
 1408   const Register callers_sp           = R21;
 1409   const Register push_frame_temp      = R22;
 1410   const Register toc_temp             = R23;
 1411   assert_different_registers(R11, return_pc, callers_sp, push_frame_temp, toc_temp);
 1412 
 1413   if (method_is_frameless) {
 1414     // Add nop at beginning of all frameless methods to prevent any
 1415     // oop instructions from getting overwritten by make_not_entrant
 1416     // (patching attempt would fail).
 1417     ___(nop) nop();
 1418   } else {
 1419     // Get return pc.
 1420     ___(mflr) mflr(return_pc);
 1421   }
 1422 
</pre>
<hr />
<pre>
 1427     Register klass = toc_temp;
 1428 
 1429     // Notify OOP recorder (don&#39;t need the relocation)
 1430     AddressLiteral md = __ constant_metadata_address(C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1431     __ load_const_optimized(klass, md.value(), R0);
 1432     __ clinit_barrier(klass, R16_thread, &amp;L_skip_barrier /*L_fast_path*/);
 1433 
 1434     __ load_const_optimized(klass, SharedRuntime::get_handle_wrong_method_stub(), R0);
 1435     __ mtctr(klass);
 1436     __ bctr();
 1437 
 1438     __ bind(L_skip_barrier);
 1439   }
 1440 
 1441   // Calls to C2R adapters often do not accept exceptional returns.
 1442   // We require that their callers must bang for them. But be
 1443   // careful, because some VM calls (such as call site linkage) can
 1444   // use several kilobytes of stack. But the stack safety zone should
 1445   // account for that. See bugs 4446381, 4468289, 4497237.
 1446 
<span class="line-modified"> 1447   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();</span>
 1448   assert(bangsize &gt;= framesize || bangsize &lt;= 0, &quot;stack bang size incorrect&quot;);
<span class="line-modified"> 1449   if (C-&gt;output()-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging) {</span>
 1450     // Unfortunately we cannot use the function provided in
 1451     // assembler.cpp as we have to emulate the pipes. So I had to
 1452     // insert the code of generate_stack_overflow_check(), see
 1453     // assembler.cpp for some illuminative comments.
 1454     const int page_size = os::vm_page_size();
 1455     int bang_end = JavaThread::stack_shadow_zone_size();
 1456 
 1457     // This is how far the previous frame&#39;s stack banging extended.
 1458     const int bang_end_safe = bang_end;
 1459 
 1460     if (bangsize &gt; page_size) {
 1461       bang_end += bangsize;
 1462     }
 1463 
 1464     int bang_offset = bang_end_safe;
 1465 
 1466     while (bang_offset &lt;= bang_end) {
 1467       // Need at least one stack bang at end of shadow zone.
 1468 
 1469       // Again I had to copy code, this time from assembler_ppc.cpp,
</pre>
<hr />
<pre>
 1483         }
 1484       } else if (Assembler::is_simm(stdoffset, 31)) {
 1485         // Use largeoffset calculations for addis &amp; ld/std.
 1486         const int hi = MacroAssembler::largeoffset_si16_si16_hi(stdoffset);
 1487         const int lo = MacroAssembler::largeoffset_si16_si16_lo(stdoffset);
 1488 
 1489         Register tmp = R11;
 1490         ___(addis) addis(tmp, R1_SP, hi);
 1491         if (UseLoadInstructionsForStackBangingPPC64) {
 1492           ___(ld) ld(R0, lo, tmp);
 1493         } else {
 1494           ___(std) std(R0, lo, tmp);
 1495         }
 1496       } else {
 1497         ShouldNotReachHere();
 1498       }
 1499 
 1500       bang_offset += page_size;
 1501     }
 1502     // R11 trashed
<span class="line-modified"> 1503   } // C-&gt;output()-&gt;need_stack_bang(framesize) &amp;&amp; UseStackBanging</span>
 1504 
 1505   unsigned int bytes = (unsigned int)framesize;
 1506   long offset = Assembler::align_addr(bytes, frame::alignment_in_bytes);
 1507   ciMethod *currMethod = C-&gt;method();
 1508 
 1509   // Optimized version for most common case.
 1510   if (UsePower6SchedulerPPC64 &amp;&amp;
 1511       !method_is_frameless &amp;&amp; Assembler::is_simm((int)(-offset), 16) &amp;&amp;
 1512       !(false /* ConstantsALot TODO: PPC port*/)) {
 1513     ___(or) mr(callers_sp, R1_SP);
 1514     ___(std) std(return_pc, _abi(lr), R1_SP);
 1515     ___(stdu) stdu(R1_SP, -offset, R1_SP);
 1516     return;
 1517   }
 1518 
 1519   if (!method_is_frameless) {
 1520     // Get callers sp.
 1521     ___(or) mr(callers_sp, R1_SP);
 1522 
 1523     // Push method&#39;s frame, modifies SP.
</pre>
<hr />
<pre>
 1538       ___(ori)    ori( tmp, tmp, (x &amp; 0x0000ffff));
 1539 
 1540       ___(stdux) stdux(R1_SP, R1_SP, tmp);
 1541     }
 1542   }
 1543 #if 0 // TODO: PPC port
 1544   // For testing large constant pools, emit a lot of constants to constant pool.
 1545   // &quot;Randomize&quot; const_size.
 1546   if (ConstantsALot) {
 1547     const int num_consts = const_size();
 1548     for (int i = 0; i &lt; num_consts; i++) {
 1549       __ long_constant(0xB0B5B00BBABE);
 1550     }
 1551   }
 1552 #endif
 1553   if (!method_is_frameless) {
 1554     // Save return pc.
 1555     ___(std) std(return_pc, _abi(lr), callers_sp);
 1556   }
 1557 
<span class="line-modified"> 1558   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());</span>
 1559 }
 1560 #undef ___
 1561 #undef ___stop
 1562 #undef ___advance
 1563 
 1564 uint MachPrologNode::size(PhaseRegAlloc *ra_) const {
 1565   // Variable size. determine dynamically.
 1566   return MachNode::size(ra_);
 1567 }
 1568 
 1569 int MachPrologNode::reloc() const {
 1570   // Return number of relocatable values contained in this instruction.
 1571   return 1; // 1 reloc entry for load_const(toc).
 1572 }
 1573 
 1574 //=============================================================================
 1575 
 1576 #ifndef PRODUCT
 1577 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1578   Compile* C = ra_-&gt;C;
 1579 
 1580   st-&gt;print(&quot;EPILOG\n\t&quot;);
 1581   st-&gt;print(&quot;restore return pc\n\t&quot;);
 1582   st-&gt;print(&quot;pop frame\n\t&quot;);
 1583 
 1584   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1585     st-&gt;print(&quot;touch polling page\n\t&quot;);
 1586   }
 1587 }
 1588 #endif
 1589 
 1590 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1591   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1592   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1593 
<span class="line-modified"> 1594   const long framesize = ((long)C-&gt;output()-&gt;frame_slots()) &lt;&lt; LogBytesPerInt;</span>
 1595   assert(framesize &gt;= 0, &quot;negative frame-size?&quot;);
 1596 
 1597   const bool method_needs_polling = do_polling() &amp;&amp; C-&gt;is_method_compilation();
 1598   const bool method_is_frameless  = false /* TODO: PPC port C-&gt;is_frameless_method()*/;
 1599   const Register return_pc        = R31;  // Must survive C-call to enable_stack_reserved_zone().
 1600   const Register polling_page     = R12;
 1601 
 1602   if (!method_is_frameless) {
 1603     // Restore return pc relative to callers&#39; sp.
 1604     __ ld(return_pc, ((int)framesize) + _abi(lr), R1_SP);
 1605   }
 1606 
 1607   if (method_needs_polling) {
<span class="line-modified"> 1608     __ ld(polling_page, in_bytes(JavaThread::polling_page_offset()), R16_thread);</span>




 1609   }
 1610 
 1611   if (!method_is_frameless) {
 1612     // Move return pc to LR.
 1613     __ mtlr(return_pc);
 1614     // Pop frame (fixed frame-size).
 1615     __ addi(R1_SP, R1_SP, (int)framesize);
 1616   }
 1617 
 1618   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1619     __ reserved_stack_check(return_pc);
 1620   }
 1621 
 1622   if (method_needs_polling) {
 1623     // We need to mark the code position where the load from the safepoint
 1624     // polling page was emitted as relocInfo::poll_return_type here.
 1625     __ relocate(relocInfo::poll_return_type);
 1626     __ load_from_polling_page(polling_page);
 1627   }
 1628 }
 1629 
 1630 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1631   // Variable size. Determine dynamically.
 1632   return MachNode::size(ra_);
 1633 }
 1634 
 1635 int MachEpilogNode::reloc() const {
 1636   // Return number of relocatable values contained in this instruction.
 1637   return 1; // 1 for load_from_polling_page.
 1638 }
 1639 
 1640 const Pipeline * MachEpilogNode::pipeline() const {
 1641   return MachNode::pipeline_class();
 1642 }
 1643 








 1644 #if 0 // TODO: PPC port
 1645 void MachLoadPollAddrLateNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
<span class="line-modified"> 1646   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1647   if (LoadPollAddressFromThread) {
 1648     _masm.ld(R11, in_bytes(JavaThread::poll_address_offset()), R16_thread);
 1649   } else {
 1650     _masm.nop();
 1651   }
 1652 }
 1653 
 1654 uint MachLoadPollAddrLateNode::size(PhaseRegAlloc* ra_) const {
 1655   if (LoadPollAddressFromThread) {
 1656     return 4;
 1657   } else {
 1658     return 4;
 1659   }
 1660 }
 1661 
 1662 #ifndef PRODUCT
 1663 void MachLoadPollAddrLateNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1664   st-&gt;print_cr(&quot; LD R11, PollAddressOffset, R16_thread \t// LoadPollAddressFromThread&quot;);
 1665 }
 1666 #endif
</pre>
<hr />
<pre>
 1743   enum RC dst_hi_rc = rc_class(dst_hi);
 1744   enum RC dst_lo_rc = rc_class(dst_lo);
 1745 
 1746   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1747   if (src_hi != OptoReg::Bad)
 1748     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1749            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1750            &quot;expected aligned-adjacent pairs&quot;);
 1751   // Generate spill code!
 1752   int size = 0;
 1753 
 1754   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi)
 1755     return size;            // Self copy, no move.
 1756 
 1757   if (bottom_type()-&gt;isa_vect() != NULL &amp;&amp; ideal_reg() == Op_VecX) {
 1758     // Memory-&gt;Memory Spill.
 1759     if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1760       int src_offset = ra_-&gt;reg2offset(src_lo);
 1761       int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1762       if (cbuf) {
<span class="line-modified"> 1763         C2_MacroAssembler _masm(cbuf);</span>
 1764         __ ld(R0, src_offset, R1_SP);
 1765         __ std(R0, dst_offset, R1_SP);
 1766         __ ld(R0, src_offset+8, R1_SP);
 1767         __ std(R0, dst_offset+8, R1_SP);
 1768       }
 1769       size += 16;
 1770     }
 1771     // VectorSRegister-&gt;Memory Spill.
 1772     else if (src_lo_rc == rc_vs &amp;&amp; dst_lo_rc == rc_stack) {
 1773       VectorSRegister Rsrc = as_VectorSRegister(Matcher::_regEncode[src_lo]);
 1774       int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1775       if (cbuf) {
<span class="line-modified"> 1776         C2_MacroAssembler _masm(cbuf);</span>
 1777         __ addi(R0, R1_SP, dst_offset);
 1778         __ stxvd2x(Rsrc, R0);
 1779       }
 1780       size += 8;
 1781     }
 1782     // Memory-&gt;VectorSRegister Spill.
 1783     else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_vs) {
 1784       VectorSRegister Rdst = as_VectorSRegister(Matcher::_regEncode[dst_lo]);
 1785       int src_offset = ra_-&gt;reg2offset(src_lo);
 1786       if (cbuf) {
<span class="line-modified"> 1787         C2_MacroAssembler _masm(cbuf);</span>
 1788         __ addi(R0, R1_SP, src_offset);
 1789         __ lxvd2x(Rdst, R0);
 1790       }
 1791       size += 8;
 1792     }
 1793     // VectorSRegister-&gt;VectorSRegister.
 1794     else if (src_lo_rc == rc_vs &amp;&amp; dst_lo_rc == rc_vs) {
 1795       VectorSRegister Rsrc = as_VectorSRegister(Matcher::_regEncode[src_lo]);
 1796       VectorSRegister Rdst = as_VectorSRegister(Matcher::_regEncode[dst_lo]);
 1797       if (cbuf) {
<span class="line-modified"> 1798         C2_MacroAssembler _masm(cbuf);</span>
 1799         __ xxlor(Rdst, Rsrc, Rsrc);
 1800       }
 1801       size += 4;
 1802     }
 1803     else {
 1804       ShouldNotReachHere(); // No VSR spill.
 1805     }
 1806     return size;
 1807   }
 1808 
 1809   // --------------------------------------
 1810   // Memory-&gt;Memory Spill. Use R0 to hold the value.
 1811   if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1812     int src_offset = ra_-&gt;reg2offset(src_lo);
 1813     int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1814     if (src_hi != OptoReg::Bad) {
 1815       assert(src_hi_rc==rc_stack &amp;&amp; dst_hi_rc==rc_stack,
 1816              &quot;expected same type of move for high parts&quot;);
 1817       size += ld_st_helper(cbuf, &quot;LD  &quot;, Assembler::LD_OPCODE,  R0_num, src_offset, !do_size, C, st);
 1818       if (!cbuf &amp;&amp; !do_size) st-&gt;print(&quot;\n\t&quot;);
</pre>
<hr />
<pre>
 1822       if (!cbuf &amp;&amp; !do_size) st-&gt;print(&quot;\n\t&quot;);
 1823       size += ld_st_helper(cbuf, &quot;STW &quot;, Assembler::STW_OPCODE, R0_num, dst_offset, !do_size, C, st);
 1824     }
 1825     return size;
 1826   }
 1827 
 1828   // --------------------------------------
 1829   // Check for float-&gt;int copy; requires a trip through memory.
 1830   if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_int) {
 1831     Unimplemented();
 1832   }
 1833 
 1834   // --------------------------------------
 1835   // Check for integer reg-reg copy.
 1836   if (src_lo_rc == rc_int &amp;&amp; dst_lo_rc == rc_int) {
 1837       Register Rsrc = as_Register(Matcher::_regEncode[src_lo]);
 1838       Register Rdst = as_Register(Matcher::_regEncode[dst_lo]);
 1839       size = (Rsrc != Rdst) ? 4 : 0;
 1840 
 1841       if (cbuf) {
<span class="line-modified"> 1842         C2_MacroAssembler _masm(cbuf);</span>
 1843         if (size) {
 1844           __ mr(Rdst, Rsrc);
 1845         }
 1846       }
 1847 #ifndef PRODUCT
 1848       else if (!do_size) {
 1849         if (size) {
 1850           st-&gt;print(&quot;%-7s %s, %s \t// spill copy&quot;, &quot;MR&quot;, Matcher::regName[dst_lo], Matcher::regName[src_lo]);
 1851         } else {
 1852           st-&gt;print(&quot;%-7s %s, %s \t// spill copy&quot;, &quot;MR-NOP&quot;, Matcher::regName[dst_lo], Matcher::regName[src_lo]);
 1853         }
 1854       }
 1855 #endif
 1856       return size;
 1857   }
 1858 
 1859   // Check for integer store.
 1860   if (src_lo_rc == rc_int &amp;&amp; dst_lo_rc == rc_stack) {
 1861     int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1862     if (src_hi != OptoReg::Bad) {
</pre>
<hr />
<pre>
 1868     }
 1869     return size;
 1870   }
 1871 
 1872   // Check for integer load.
 1873   if (dst_lo_rc == rc_int &amp;&amp; src_lo_rc == rc_stack) {
 1874     int src_offset = ra_-&gt;reg2offset(src_lo);
 1875     if (src_hi != OptoReg::Bad) {
 1876       assert(dst_hi_rc==rc_int &amp;&amp; src_hi_rc==rc_stack,
 1877              &quot;expected same type of move for high parts&quot;);
 1878       size += ld_st_helper(cbuf, &quot;LD  &quot;, Assembler::LD_OPCODE, dst_lo, src_offset, !do_size, C, st);
 1879     } else {
 1880       size += ld_st_helper(cbuf, &quot;LWZ &quot;, Assembler::LWZ_OPCODE, dst_lo, src_offset, !do_size, C, st);
 1881     }
 1882     return size;
 1883   }
 1884 
 1885   // Check for float reg-reg copy.
 1886   if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1887     if (cbuf) {
<span class="line-modified"> 1888       C2_MacroAssembler _masm(cbuf);</span>
 1889       FloatRegister Rsrc = as_FloatRegister(Matcher::_regEncode[src_lo]);
 1890       FloatRegister Rdst = as_FloatRegister(Matcher::_regEncode[dst_lo]);
 1891       __ fmr(Rdst, Rsrc);
 1892     }
 1893 #ifndef PRODUCT
 1894     else if (!do_size) {
 1895       st-&gt;print(&quot;%-7s %s, %s \t// spill copy&quot;, &quot;FMR&quot;, Matcher::regName[dst_lo], Matcher::regName[src_lo]);
 1896     }
 1897 #endif
 1898     return 4;
 1899   }
 1900 
 1901   // Check for float store.
 1902   if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1903     int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1904     if (src_hi != OptoReg::Bad) {
 1905       assert(src_hi_rc==rc_float &amp;&amp; dst_hi_rc==rc_stack,
 1906              &quot;expected same type of move for high parts&quot;);
 1907       size += ld_st_helper(cbuf, &quot;STFD&quot;, Assembler::STFD_OPCODE, src_lo, dst_offset, !do_size, C, st);
 1908     } else {
</pre>
<hr />
<pre>
 2038 
 2039   // --------------------------------------------------------------------
 2040   // Check for hi bits still needing moving. Only happens for misaligned
 2041   // arguments to native calls.
 2042   if (src_hi == dst_hi) {
 2043     return ppc64Opcode_none;               // Self copy; no move.
 2044   }
 2045 
 2046   ShouldNotReachHere();
 2047   return ppc64Opcode_undefined;
 2048 }
 2049 #endif // PPC port
 2050 
 2051 #ifndef PRODUCT
 2052 void MachNopNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 2053   st-&gt;print(&quot;NOP \t// %d nops to pad for loops.&quot;, _count);
 2054 }
 2055 #endif
 2056 
 2057 void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *) const {
<span class="line-modified"> 2058   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2059   // _count contains the number of nops needed for padding.
 2060   for (int i = 0; i &lt; _count; i++) {
 2061     __ nop();
 2062   }
 2063 }
 2064 
 2065 uint MachNopNode::size(PhaseRegAlloc *ra_) const {
 2066   return _count * 4;
 2067 }
 2068 
 2069 #ifndef PRODUCT
 2070 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 2071   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 2072   char reg_str[128];
 2073   ra_-&gt;dump_register(this, reg_str);
 2074   st-&gt;print(&quot;ADDI    %s, SP, %d \t// box node&quot;, reg_str, offset);
 2075 }
 2076 #endif
 2077 
 2078 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
<span class="line-modified"> 2079   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2080 
 2081   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 2082   int reg    = ra_-&gt;get_encode(this);
 2083 
 2084   if (Assembler::is_simm(offset, 16)) {
 2085     __ addi(as_Register(reg), R1, offset);
 2086   } else {
 2087     ShouldNotReachHere();
 2088   }
 2089 }
 2090 
 2091 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 2092   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 2093   return 4;
 2094 }
 2095 
 2096 #ifndef PRODUCT
 2097 void MachUEPNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 2098   st-&gt;print_cr(&quot;---- MachUEPNode ----&quot;);
 2099   st-&gt;print_cr(&quot;...&quot;);
 2100 }
 2101 #endif
 2102 
 2103 void MachUEPNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 2104   // This is the unverified entry point.
<span class="line-modified"> 2105   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2106 
 2107   // Inline_cache contains a klass.
 2108   Register ic_klass       = as_Register(Matcher::inline_cache_reg_encode());
 2109   Register receiver_klass = R12_scratch2;  // tmp
 2110 
 2111   assert_different_registers(ic_klass, receiver_klass, R11_scratch1, R3_ARG1);
 2112   assert(R11_scratch1 == R11, &quot;need prologue scratch register&quot;);
 2113 
 2114   // Check for NULL argument if we don&#39;t have implicit null checks.
 2115   if (!ImplicitNullChecks || !os::zero_page_read_protected()) {
 2116     if (TrapBasedNullChecks) {
 2117       __ trap_null_check(R3_ARG1);
 2118     } else {
 2119       Label valid;
 2120       __ cmpdi(CCR0, R3_ARG1, 0);
 2121       __ bne_predict_taken(CCR0, valid);
 2122       // We have a null argument, branch to ic_miss_stub.
 2123       __ b64_patchable((address)SharedRuntime::get_ic_miss_stub(),
 2124                            relocInfo::runtime_call_type);
 2125       __ bind(valid);
</pre>
<hr />
<pre>
 2163 
 2164 class HandlerImpl {
 2165 
 2166  public:
 2167 
 2168   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 2169   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 2170 
 2171   static uint size_exception_handler() {
 2172     // The exception_handler is a b64_patchable.
 2173     return MacroAssembler::b64_patchable_size;
 2174   }
 2175 
 2176   static uint size_deopt_handler() {
 2177     // The deopt_handler is a bl64_patchable.
 2178     return MacroAssembler::bl64_patchable_size;
 2179   }
 2180 
 2181 };
 2182 
<span class="line-added"> 2183 class Node::PD {</span>
<span class="line-added"> 2184 public:</span>
<span class="line-added"> 2185   enum NodeFlags {</span>
<span class="line-added"> 2186     _last_flag = Node::_last_flag</span>
<span class="line-added"> 2187   };</span>
<span class="line-added"> 2188 };</span>
<span class="line-added"> 2189 </span>
 2190 %} // end source_hpp
 2191 
 2192 source %{
 2193 
 2194 int HandlerImpl::emit_exception_handler(CodeBuffer &amp;cbuf) {
<span class="line-modified"> 2195   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2196 
 2197   address base = __ start_a_stub(size_exception_handler());
 2198   if (base == NULL) return 0; // CodeBuffer::expand failed
 2199 
 2200   int offset = __ offset();
 2201   __ b64_patchable((address)OptoRuntime::exception_blob()-&gt;content_begin(),
 2202                        relocInfo::runtime_call_type);
 2203   assert(__ offset() - offset == (int)size_exception_handler(), &quot;must be fixed size&quot;);
 2204   __ end_a_stub();
 2205 
 2206   return offset;
 2207 }
 2208 
 2209 // The deopt_handler is like the exception handler, but it calls to
 2210 // the deoptimization blob instead of jumping to the exception blob.
 2211 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf) {
<span class="line-modified"> 2212   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2213 
 2214   address base = __ start_a_stub(size_deopt_handler());
 2215   if (base == NULL) return 0; // CodeBuffer::expand failed
 2216 
 2217   int offset = __ offset();
 2218   __ bl64_patchable((address)SharedRuntime::deopt_blob()-&gt;unpack(),
 2219                         relocInfo::runtime_call_type);
 2220   assert(__ offset() - offset == (int) size_deopt_handler(), &quot;must be fixed size&quot;);
 2221   __ end_a_stub();
 2222 
 2223   return offset;
 2224 }
 2225 
 2226 //=============================================================================
 2227 
 2228 // Use a frame slots bias for frameless methods if accessing the stack.
 2229 static int frame_slots_bias(int reg_enc, PhaseRegAlloc* ra_) {
 2230   if (as_Register(reg_enc) == R1_SP) {
 2231     return 0; // TODO: PPC port ra_-&gt;C-&gt;frame_slots_sp_bias_in_bytes();
 2232   }
</pre>
<hr />
<pre>
 2656 // operand to generate a function which returns its register number when
 2657 // queried. CONST_INTER causes an operand to generate a function which
 2658 // returns the value of the constant when queried. MEMORY_INTER causes an
 2659 // operand to generate four functions which return the Base Register, the
 2660 // Index Register, the Scale Value, and the Offset Value of the operand when
 2661 // queried. COND_INTER causes an operand to generate six functions which
 2662 // return the encoding code (ie - encoding bits for the instruction)
 2663 // associated with each basic boolean condition for a conditional instruction.
 2664 //
 2665 // Instructions specify two basic values for encoding. Again, a function
 2666 // is available to check if the constant displacement is an oop. They use the
 2667 // ins_encode keyword to specify their encoding classes (which must be
 2668 // a sequence of enc_class names, and their parameters, specified in
 2669 // the encoding block), and they use the
 2670 // opcode keyword to specify, in order, their primary, secondary, and
 2671 // tertiary opcode. Only the opcode sections which a particular instruction
 2672 // needs for encoding need to be specified.
 2673 encode %{
 2674   enc_class enc_unimplemented %{
 2675     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2676     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2677     __ unimplemented(&quot;Unimplemented mach node encoding in AD file.&quot;, 13);
 2678   %}
 2679 
 2680   enc_class enc_untested %{
 2681 #ifdef ASSERT
 2682     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2683     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2684     __ untested(&quot;Untested mach node encoding in AD file.&quot;);
 2685 #else
 2686     // TODO: PPC port $archOpcode(ppc64Opcode_none);
 2687 #endif
 2688   %}
 2689 
 2690   enc_class enc_lbz(iRegIdst dst, memory mem) %{
 2691     // TODO: PPC port $archOpcode(ppc64Opcode_lbz);
<span class="line-modified"> 2692     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2693     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2694     __ lbz($dst$$Register, Idisp, $mem$$base$$Register);
 2695   %}
 2696 
 2697   // Load acquire.
 2698   enc_class enc_lbz_ac(iRegIdst dst, memory mem) %{
 2699     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2700     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2701     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2702     __ lbz($dst$$Register, Idisp, $mem$$base$$Register);
 2703     __ twi_0($dst$$Register);
 2704     __ isync();
 2705   %}
 2706 
 2707   enc_class enc_lhz(iRegIdst dst, memory mem) %{
 2708     // TODO: PPC port $archOpcode(ppc64Opcode_lhz);
 2709 
<span class="line-modified"> 2710     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2711     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2712     __ lhz($dst$$Register, Idisp, $mem$$base$$Register);
 2713   %}
 2714 
 2715   // Load acquire.
 2716   enc_class enc_lhz_ac(iRegIdst dst, memory mem) %{
 2717     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 2718 
<span class="line-modified"> 2719     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2720     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2721     __ lhz($dst$$Register, Idisp, $mem$$base$$Register);
 2722     __ twi_0($dst$$Register);
 2723     __ isync();
 2724   %}
 2725 
 2726   enc_class enc_lwz(iRegIdst dst, memory mem) %{
 2727     // TODO: PPC port $archOpcode(ppc64Opcode_lwz);
 2728 
<span class="line-modified"> 2729     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2730     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2731     __ lwz($dst$$Register, Idisp, $mem$$base$$Register);
 2732   %}
 2733 
 2734   // Load acquire.
 2735   enc_class enc_lwz_ac(iRegIdst dst, memory mem) %{
 2736     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 2737 
<span class="line-modified"> 2738     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2739     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2740     __ lwz($dst$$Register, Idisp, $mem$$base$$Register);
 2741     __ twi_0($dst$$Register);
 2742     __ isync();
 2743   %}
 2744 
 2745   enc_class enc_ld(iRegLdst dst, memoryAlg4 mem) %{
 2746     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
<span class="line-modified"> 2747     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2748     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2749     // Operand &#39;ds&#39; requires 4-alignment.
 2750     assert((Idisp &amp; 0x3) == 0, &quot;unaligned offset&quot;);
 2751     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
 2752   %}
 2753 
 2754   // Load acquire.
 2755   enc_class enc_ld_ac(iRegLdst dst, memoryAlg4 mem) %{
 2756     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2757     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2758     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2759     // Operand &#39;ds&#39; requires 4-alignment.
 2760     assert((Idisp &amp; 0x3) == 0, &quot;unaligned offset&quot;);
 2761     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
 2762     __ twi_0($dst$$Register);
 2763     __ isync();
 2764   %}
 2765 
 2766   enc_class enc_lfd(RegF dst, memory mem) %{
 2767     // TODO: PPC port $archOpcode(ppc64Opcode_lfd);
<span class="line-modified"> 2768     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2769     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2770     __ lfd($dst$$FloatRegister, Idisp, $mem$$base$$Register);
 2771   %}
 2772 
 2773   enc_class enc_load_long_constL(iRegLdst dst, immL src, iRegLdst toc) %{
 2774     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
 2775 
<span class="line-modified"> 2776     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2777     int toc_offset = 0;
 2778 
 2779     address const_toc_addr;
 2780     // Create a non-oop constant, no relocation needed.
 2781     // If it is an IC, it has a virtual_call_Relocation.
 2782     const_toc_addr = __ long_constant((jlong)$src$$constant);
 2783     if (const_toc_addr == NULL) {
 2784       ciEnv::current()-&gt;record_out_of_memory_failure();
 2785       return;
 2786     }
 2787 
 2788     // Get the constant&#39;s TOC offset.
 2789     toc_offset = __ offset_to_method_toc(const_toc_addr);
 2790 
 2791     // Keep the current instruction offset in mind.
 2792     ((loadConLNode*)this)-&gt;_cbuf_insts_offset = __ offset();
 2793 
 2794     __ ld($dst$$Register, toc_offset, $toc$$Register);
 2795   %}
 2796 
 2797   enc_class enc_load_long_constL_hi(iRegLdst dst, iRegLdst toc, immL src) %{
 2798     // TODO: PPC port $archOpcode(ppc64Opcode_addis);
 2799 
<span class="line-modified"> 2800     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2801 
<span class="line-modified"> 2802     if (!ra_-&gt;C-&gt;output()-&gt;in_scratch_emit_size()) {</span>
 2803       address const_toc_addr;
 2804       // Create a non-oop constant, no relocation needed.
 2805       // If it is an IC, it has a virtual_call_Relocation.
 2806       const_toc_addr = __ long_constant((jlong)$src$$constant);
 2807       if (const_toc_addr == NULL) {
 2808         ciEnv::current()-&gt;record_out_of_memory_failure();
 2809         return;
 2810       }
 2811 
 2812       // Get the constant&#39;s TOC offset.
 2813       const int toc_offset = __ offset_to_method_toc(const_toc_addr);
 2814       // Store the toc offset of the constant.
 2815       ((loadConL_hiNode*)this)-&gt;_const_toc_offset = toc_offset;
 2816 
 2817       // Also keep the current instruction offset in mind.
 2818       ((loadConL_hiNode*)this)-&gt;_cbuf_insts_offset = __ offset();
 2819     }
 2820 
 2821     __ addis($dst$$Register, $toc$$Register, MacroAssembler::largeoffset_si16_si16_hi(_const_toc_offset));
 2822   %}
</pre>
<hr />
<pre>
 3015   // Enc_class needed as consttanttablebase is not supported by postalloc
 3016   // expand.
 3017   enc_class postalloc_expand_load_long_constant(iRegLdst dst, immL src, iRegLdst toc) %{
 3018     // Create new nodes.
 3019     loadConLNodesTuple loadConLNodes =
 3020       loadConLNodesTuple_create(ra_, n_toc, op_src,
 3021                                 ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3022 
 3023     // Push new nodes.
 3024     if (loadConLNodes._large_hi) nodes-&gt;push(loadConLNodes._large_hi);
 3025     if (loadConLNodes._last)     nodes-&gt;push(loadConLNodes._last);
 3026 
 3027     // some asserts
 3028     assert(nodes-&gt;length() &gt;= 1, &quot;must have created at least 1 node&quot;);
 3029     assert(loadConLNodes._last-&gt;bottom_type()-&gt;isa_long(), &quot;must be long&quot;);
 3030   %}
 3031 
 3032   enc_class enc_load_long_constP(iRegLdst dst, immP src, iRegLdst toc) %{
 3033     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
 3034 
<span class="line-modified"> 3035     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3036     int toc_offset = 0;
 3037 
 3038     intptr_t val = $src$$constant;
 3039     relocInfo::relocType constant_reloc = $src-&gt;constant_reloc();  // src
 3040     address const_toc_addr;
 3041     if (constant_reloc == relocInfo::oop_type) {
 3042       // Create an oop constant and a corresponding relocation.
 3043       AddressLiteral a = __ allocate_oop_address((jobject)val);
 3044       const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3045       __ relocate(a.rspec());
 3046     } else if (constant_reloc == relocInfo::metadata_type) {
 3047       AddressLiteral a = __ constant_metadata_address((Metadata *)val);
 3048       const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3049       __ relocate(a.rspec());
 3050     } else {
 3051       // Create a non-oop constant, no relocation needed.
 3052       const_toc_addr = __ long_constant((jlong)$src$$constant);
 3053     }
 3054 
 3055     if (const_toc_addr == NULL) {
 3056       ciEnv::current()-&gt;record_out_of_memory_failure();
 3057       return;
 3058     }
 3059     // Get the constant&#39;s TOC offset.
 3060     toc_offset = __ offset_to_method_toc(const_toc_addr);
 3061 
 3062     __ ld($dst$$Register, toc_offset, $toc$$Register);
 3063   %}
 3064 
 3065   enc_class enc_load_long_constP_hi(iRegLdst dst, immP src, iRegLdst toc) %{
 3066     // TODO: PPC port $archOpcode(ppc64Opcode_addis);
 3067 
<span class="line-modified"> 3068     C2_MacroAssembler _masm(&amp;cbuf);</span>
<span class="line-modified"> 3069     if (!ra_-&gt;C-&gt;output()-&gt;in_scratch_emit_size()) {</span>
 3070       intptr_t val = $src$$constant;
 3071       relocInfo::relocType constant_reloc = $src-&gt;constant_reloc();  // src
 3072       address const_toc_addr;
 3073       if (constant_reloc == relocInfo::oop_type) {
 3074         // Create an oop constant and a corresponding relocation.
 3075         AddressLiteral a = __ allocate_oop_address((jobject)val);
 3076         const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3077         __ relocate(a.rspec());
 3078       } else if (constant_reloc == relocInfo::metadata_type) {
 3079         AddressLiteral a = __ constant_metadata_address((Metadata *)val);
 3080         const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3081         __ relocate(a.rspec());
 3082       } else {  // non-oop pointers, e.g. card mark base, heap top
 3083         // Create a non-oop constant, no relocation needed.
 3084         const_toc_addr = __ long_constant((jlong)$src$$constant);
 3085       }
 3086 
 3087       if (const_toc_addr == NULL) {
 3088         ciEnv::current()-&gt;record_out_of_memory_failure();
 3089         return;
</pre>
<hr />
<pre>
 3182     if (large_constant_pool) {
 3183       m2 = new loadConDCompNode();
 3184     } else {
 3185       m2 = new loadConDNode();
 3186     }
 3187     // inputs for new nodes
 3188     m2-&gt;add_req(NULL, n_toc);
 3189 
 3190     // operands for new nodes
 3191     m2-&gt;_opnds[0] = op_dst;
 3192     m2-&gt;_opnds[1] = op_src;
 3193     m2-&gt;_opnds[2] = new iRegPdstOper(); // constanttablebase
 3194 
 3195     // register allocation for new nodes
 3196     ra_-&gt;set_pair(m2-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3197     nodes-&gt;push(m2);
 3198   %}
 3199 
 3200   enc_class enc_stw(iRegIsrc src, memory mem) %{
 3201     // TODO: PPC port $archOpcode(ppc64Opcode_stw);
<span class="line-modified"> 3202     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3203     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3204     __ stw($src$$Register, Idisp, $mem$$base$$Register);
 3205   %}
 3206 
 3207   enc_class enc_std(iRegIsrc src, memoryAlg4 mem) %{
 3208     // TODO: PPC port $archOpcode(ppc64Opcode_std);
<span class="line-modified"> 3209     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3210     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3211     // Operand &#39;ds&#39; requires 4-alignment.
 3212     assert((Idisp &amp; 0x3) == 0, &quot;unaligned offset&quot;);
 3213     __ std($src$$Register, Idisp, $mem$$base$$Register);
 3214   %}
 3215 
 3216   enc_class enc_stfs(RegF src, memory mem) %{
 3217     // TODO: PPC port $archOpcode(ppc64Opcode_stfs);
<span class="line-modified"> 3218     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3219     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3220     __ stfs($src$$FloatRegister, Idisp, $mem$$base$$Register);
 3221   %}
 3222 
 3223   enc_class enc_stfd(RegF src, memory mem) %{
 3224     // TODO: PPC port $archOpcode(ppc64Opcode_stfd);
<span class="line-modified"> 3225     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3226     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3227     __ stfd($src$$FloatRegister, Idisp, $mem$$base$$Register);
 3228   %}
 3229 
 3230   // Use release_store for card-marking to ensure that previous
 3231   // oop-stores are visible before the card-mark change.
 3232   enc_class enc_cms_card_mark(memory mem, iRegLdst releaseFieldAddr, flagsReg crx) %{
 3233     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3234     // FIXME: Implement this as a cmove and use a fixed condition code
 3235     // register which is written on every transition to compiled code,
 3236     // e.g. in call-stub and when returning from runtime stubs.
 3237     //
 3238     // Proposed code sequence for the cmove implementation:
 3239     //
 3240     // Label skip_release;
 3241     // __ beq(CCRfixed, skip_release);
 3242     // __ release();
 3243     // __ bind(skip_release);
 3244     // __ stb(card mark);
 3245 
<span class="line-modified"> 3246     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3247     Label skip_storestore;
 3248 
 3249 #if 0 // TODO: PPC port
 3250     // Check CMSCollectorCardTableBarrierSetBSExt::_requires_release and do the
 3251     // StoreStore barrier conditionally.
 3252     __ lwz(R0, 0, $releaseFieldAddr$$Register);
 3253     __ cmpwi($crx$$CondRegister, R0, 0);
 3254     __ beq_predict_taken($crx$$CondRegister, skip_storestore);
 3255 #endif
 3256     __ li(R0, 0);
 3257     __ membar(Assembler::StoreStore);
 3258 #if 0 // TODO: PPC port
 3259     __ bind(skip_storestore);
 3260 #endif
 3261 
 3262     // Do the store.
 3263     if ($mem$$index == 0) {
 3264       __ stb(R0, $mem$$disp, $mem$$base$$Register);
 3265     } else {
 3266       assert(0 == $mem$$disp, &quot;no displacement possible with indexed load/stores on ppc&quot;);
</pre>
<hr />
<pre>
 3447     n1-&gt;_bottom_type = _bottom_type;
 3448 
 3449     decodeN_addNode *n2 = new decodeN_addNode();
 3450     n2-&gt;add_req(n_region, n1);
 3451     n2-&gt;_opnds[0] = op_dst;
 3452     n2-&gt;_opnds[1] = op_dst;
 3453     n2-&gt;_bottom_type = _bottom_type;
 3454     ra_-&gt;set_pair(n1-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3455     ra_-&gt;set_pair(n2-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3456 
 3457     assert(ra_-&gt;is_oop(this) == true, &quot;A decodeN node must produce an oop!&quot;);
 3458     ra_-&gt;set_oop(n2, true);
 3459 
 3460     nodes-&gt;push(n1);
 3461     nodes-&gt;push(n2);
 3462   %}
 3463 
 3464   enc_class enc_cmove_reg(iRegIdst dst, flagsRegSrc crx, iRegIsrc src, cmpOp cmp) %{
 3465     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3466 
<span class="line-modified"> 3467     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3468     int cc        = $cmp$$cmpcode;
 3469     int flags_reg = $crx$$reg;
 3470     Label done;
 3471     assert((Assembler::bcondCRbiIs1 &amp; ~Assembler::bcondCRbiIs0) == 8, &quot;check encoding&quot;);
 3472     // Branch if not (cmp crx).
 3473     __ bc(cc_to_inverse_boint(cc), cc_to_biint(cc, flags_reg), done);
 3474     __ mr($dst$$Register, $src$$Register);
 3475     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3476     __ bind(done);
 3477   %}
 3478 
 3479   enc_class enc_cmove_imm(iRegIdst dst, flagsRegSrc crx, immI16 src, cmpOp cmp) %{
 3480     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3481 
<span class="line-modified"> 3482     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3483     Label done;
 3484     assert((Assembler::bcondCRbiIs1 &amp; ~Assembler::bcondCRbiIs0) == 8, &quot;check encoding&quot;);
 3485     // Branch if not (cmp crx).
 3486     __ bc(cc_to_inverse_boint($cmp$$cmpcode), cc_to_biint($cmp$$cmpcode, $crx$$reg), done);
 3487     __ li($dst$$Register, $src$$constant);
 3488     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3489     __ bind(done);
 3490   %}
 3491 
 3492   // This enc_class is needed so that scheduler gets proper
 3493   // input mapping for latency computation.
 3494   enc_class enc_andc(iRegIdst dst, iRegIsrc src1, iRegIsrc src2) %{
 3495     // TODO: PPC port $archOpcode(ppc64Opcode_andc);
<span class="line-modified"> 3496     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3497     __ andc($dst$$Register, $src1$$Register, $src2$$Register);
 3498   %}
 3499 
 3500   enc_class enc_convI2B_regI__cmove(iRegIdst dst, iRegIsrc src, flagsReg crx, immI16 zero, immI16 notzero) %{
 3501     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3502 
<span class="line-modified"> 3503     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3504 
 3505     Label done;
 3506     __ cmpwi($crx$$CondRegister, $src$$Register, 0);
 3507     __ li($dst$$Register, $zero$$constant);
 3508     __ beq($crx$$CondRegister, done);
 3509     __ li($dst$$Register, $notzero$$constant);
 3510     __ bind(done);
 3511   %}
 3512 
 3513   enc_class enc_convP2B_regP__cmove(iRegIdst dst, iRegPsrc src, flagsReg crx, immI16 zero, immI16 notzero) %{
 3514     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3515 
<span class="line-modified"> 3516     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3517 
 3518     Label done;
 3519     __ cmpdi($crx$$CondRegister, $src$$Register, 0);
 3520     __ li($dst$$Register, $zero$$constant);
 3521     __ beq($crx$$CondRegister, done);
 3522     __ li($dst$$Register, $notzero$$constant);
 3523     __ bind(done);
 3524   %}
 3525 
 3526   enc_class enc_cmove_bso_stackSlotL(iRegLdst dst, flagsRegSrc crx, stackSlotL mem ) %{
 3527     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3528 
<span class="line-modified"> 3529     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3530     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3531     Label done;
 3532     __ bso($crx$$CondRegister, done);
 3533     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
 3534     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3535     __ bind(done);
 3536   %}
 3537 
 3538   enc_class enc_cmove_bso_reg(iRegLdst dst, flagsRegSrc crx, regD src) %{
 3539     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3540 
<span class="line-modified"> 3541     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3542     Label done;
 3543     __ bso($crx$$CondRegister, done);
 3544     __ mffprd($dst$$Register, $src$$FloatRegister);
 3545     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3546     __ bind(done);
 3547   %}
 3548 
 3549   enc_class enc_bc(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
 3550     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 3551 
<span class="line-modified"> 3552     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3553     Label d;   // dummy
 3554     __ bind(d);
 3555     Label* p = ($lbl$$label);
 3556     // `p&#39; is `NULL&#39; when this encoding class is used only to
 3557     // determine the size of the encoded instruction.
 3558     Label&amp; l = (NULL == p)? d : *(p);
 3559     int cc = $cmp$$cmpcode;
 3560     int flags_reg = $crx$$reg;
 3561     assert((Assembler::bcondCRbiIs1 &amp; ~Assembler::bcondCRbiIs0) == 8, &quot;check encoding&quot;);
 3562     int bhint = Assembler::bhintNoHint;
 3563 
 3564     if (UseStaticBranchPredictionForUncommonPathsPPC64) {
 3565       if (_prob &lt;= PROB_NEVER) {
 3566         bhint = Assembler::bhintIsNotTaken;
 3567       } else if (_prob &gt;= PROB_ALWAYS) {
 3568         bhint = Assembler::bhintIsTaken;
 3569       }
 3570     }
 3571 
 3572     __ bc(Assembler::add_bhint_to_boint(bhint, cc_to_boint(cc)),
 3573           cc_to_biint(cc, flags_reg),
 3574           l);
 3575   %}
 3576 
 3577   enc_class enc_bc_far(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
 3578     // The scheduler doesn&#39;t know about branch shortening, so we set the opcode
 3579     // to ppc64Opcode_bc in order to hide this detail from the scheduler.
 3580     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 3581 
<span class="line-modified"> 3582     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3583     Label d;    // dummy
 3584     __ bind(d);
 3585     Label* p = ($lbl$$label);
 3586     // `p&#39; is `NULL&#39; when this encoding class is used only to
 3587     // determine the size of the encoded instruction.
 3588     Label&amp; l = (NULL == p)? d : *(p);
 3589     int cc = $cmp$$cmpcode;
 3590     int flags_reg = $crx$$reg;
 3591     int bhint = Assembler::bhintNoHint;
 3592 
 3593     if (UseStaticBranchPredictionForUncommonPathsPPC64) {
 3594       if (_prob &lt;= PROB_NEVER) {
 3595         bhint = Assembler::bhintIsNotTaken;
 3596       } else if (_prob &gt;= PROB_ALWAYS) {
 3597         bhint = Assembler::bhintIsTaken;
 3598       }
 3599     }
 3600 
 3601     // Tell the conditional far branch to optimize itself when being relocated.
 3602     __ bc_far(Assembler::add_bhint_to_boint(bhint, cc_to_boint(cc)),
 3603                   cc_to_biint(cc, flags_reg),
 3604                   l,
 3605                   MacroAssembler::bc_far_optimize_on_relocate);
 3606   %}
 3607 
 3608   // Branch used with Power6 scheduling (can be shortened without changing the node).
 3609   enc_class enc_bc_short_far(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
 3610     // The scheduler doesn&#39;t know about branch shortening, so we set the opcode
 3611     // to ppc64Opcode_bc in order to hide this detail from the scheduler.
 3612     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 3613 
<span class="line-modified"> 3614     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3615     Label d;   // dummy
 3616     __ bind(d);
 3617     Label* p = ($lbl$$label);
 3618     // `p&#39; is `NULL&#39; when this encoding class is used only to
 3619     // determine the size of the encoded instruction.
 3620     Label&amp; l = (NULL == p)? d : *(p);
 3621     int cc = $cmp$$cmpcode;
 3622     int flags_reg = $crx$$reg;
 3623     int bhint = Assembler::bhintNoHint;
 3624 
 3625     if (UseStaticBranchPredictionForUncommonPathsPPC64) {
 3626       if (_prob &lt;= PROB_NEVER) {
 3627         bhint = Assembler::bhintIsNotTaken;
 3628       } else if (_prob &gt;= PROB_ALWAYS) {
 3629         bhint = Assembler::bhintIsTaken;
 3630       }
 3631     }
 3632 
 3633 #if 0 // TODO: PPC port
 3634     if (_size == 8) {
</pre>
<hr />
<pre>
 3679       loadConLReplicatedNodesTuple_create(C, ra_, n_toc, op_repl, op_dst, op_zero,
 3680                                 ra_-&gt;get_reg_second(n_tmp), ra_-&gt;get_reg_first(n_tmp),
 3681                                 ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3682 
 3683     // Push new nodes.
 3684     if (loadConLNodes._large_hi) { nodes-&gt;push(loadConLNodes._large_hi); }
 3685     if (loadConLNodes._large_lo) { nodes-&gt;push(loadConLNodes._large_lo); }
 3686     if (loadConLNodes._moved)    { nodes-&gt;push(loadConLNodes._moved); }
 3687     if (loadConLNodes._last)     { nodes-&gt;push(loadConLNodes._last); }
 3688 
 3689     assert(nodes-&gt;length() &gt;= 1, &quot;must have created at least 1 node&quot;);
 3690   %}
 3691 
 3692   // This enc_class is needed so that scheduler gets proper
 3693   // input mapping for latency computation.
 3694   enc_class enc_poll(immI dst, iRegLdst poll) %{
 3695     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
 3696     // Fake operand dst needed for PPC scheduler.
 3697     assert($dst$$constant == 0x0, &quot;dst must be 0x0&quot;);
 3698 
<span class="line-modified"> 3699     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3700     // Mark the code position where the load from the safepoint
 3701     // polling page was emitted as relocInfo::poll_type.
 3702     __ relocate(relocInfo::poll_type);
 3703     __ load_from_polling_page($poll$$Register);
 3704   %}
 3705 
 3706   // A Java static call or a runtime call.
 3707   //
 3708   // Branch-and-link relative to a trampoline.
 3709   // The trampoline loads the target address and does a long branch to there.
 3710   // In case we call java, the trampoline branches to a interpreter_stub
 3711   // which loads the inline cache and the real call target from the constant pool.
 3712   //
 3713   // This basically looks like this:
 3714   //
 3715   // &gt;&gt;&gt;&gt; consts      -+  -+
 3716   //                   |   |- offset1
 3717   // [call target1]    | &lt;-+
 3718   // [IC cache]        |- offset2
 3719   // [call target2] &lt;--+
</pre>
<hr />
<pre>
 3735   //   r1 = toc
 3736   //   ICreg = [r1 + IC_offset]         // Load IC from const section
 3737   //   r1    = [r1 + offset2]           // Load call target2 from const section
 3738   //   mtctr r1
 3739   //   bctr
 3740   //
 3741   // &lt;&lt;&lt;&lt; stubs
 3742   //
 3743   // The call instruction in the code either
 3744   // - Branches directly to a compiled method if the offset is encodable in instruction.
 3745   // - Branches to the trampoline stub if the offset to the compiled method is not encodable.
 3746   // - Branches to the compiled_to_interp stub if the target is interpreted.
 3747   //
 3748   // Further there are three relocations from the loads to the constants in
 3749   // the constant section.
 3750   //
 3751   // Usage of r1 and r2 in the stubs allows to distinguish them.
 3752   enc_class enc_java_static_call(method meth) %{
 3753     // TODO: PPC port $archOpcode(ppc64Opcode_bl);
 3754 
<span class="line-modified"> 3755     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3756     address entry_point = (address)$meth$$method;
 3757 
 3758     if (!_method) {
 3759       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3760       emit_call_with_trampoline_stub(_masm, entry_point, relocInfo::runtime_call_type);
 3761     } else {
 3762       // Remember the offset not the address.
 3763       const int start_offset = __ offset();
 3764 
 3765       // The trampoline stub.
 3766       // No entry point given, use the current pc.
 3767       // Make sure branch fits into
 3768       if (entry_point == 0) entry_point = __ pc();
 3769 
 3770       // Put the entry point as a constant into the constant pool.
 3771       const address entry_point_toc_addr = __ address_constant(entry_point, RelocationHolder::none);
 3772       if (entry_point_toc_addr == NULL) {
 3773         ciEnv::current()-&gt;record_out_of_memory_failure();
 3774         return;
 3775       }
</pre>
<hr />
<pre>
 3785       // The real call.
 3786       // Note: At this point we do not have the address of the trampoline
 3787       // stub, and the entry point might be too far away for bl, so __ pc()
 3788       // serves as dummy and the bl will be patched later.
 3789       cbuf.set_insts_mark();
 3790       __ bl(__ pc());  // Emits a relocation.
 3791 
 3792       // The stub for call to interpreter.
 3793       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3794       if (stub == NULL) {
 3795         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3796         return;
 3797       }
 3798     }
 3799   %}
 3800 
 3801   // Second node of expanded dynamic call - the call.
 3802   enc_class enc_java_dynamic_call_sched(method meth) %{
 3803     // TODO: PPC port $archOpcode(ppc64Opcode_bl);
 3804 
<span class="line-modified"> 3805     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3806 
<span class="line-modified"> 3807     if (!ra_-&gt;C-&gt;output()-&gt;in_scratch_emit_size()) {</span>
 3808       // Create a call trampoline stub for the given method.
 3809       const address entry_point = !($meth$$method) ? 0 : (address)$meth$$method;
 3810       const address entry_point_const = __ address_constant(entry_point, RelocationHolder::none);
 3811       if (entry_point_const == NULL) {
 3812         ciEnv::current()-&gt;record_out_of_memory_failure();
 3813         return;
 3814       }
 3815       const int entry_point_const_toc_offset = __ offset_to_method_toc(entry_point_const);
 3816       CallStubImpl::emit_trampoline_stub(_masm, entry_point_const_toc_offset, __ offset());
 3817       if (ra_-&gt;C-&gt;env()-&gt;failing()) { return; } // Code cache may be full.
 3818 
 3819       // Build relocation at call site with ic position as data.
 3820       assert((_load_ic_hi_node != NULL &amp;&amp; _load_ic_node == NULL) ||
 3821              (_load_ic_hi_node == NULL &amp;&amp; _load_ic_node != NULL),
 3822              &quot;must have one, but can&#39;t have both&quot;);
 3823       assert((_load_ic_hi_node != NULL &amp;&amp; _load_ic_hi_node-&gt;_cbuf_insts_offset != -1) ||
 3824              (_load_ic_node != NULL    &amp;&amp; _load_ic_node-&gt;_cbuf_insts_offset != -1),
 3825              &quot;must contain instruction offset&quot;);
 3826       const int virtual_call_oop_addr_offset = _load_ic_hi_node != NULL
 3827         ? _load_ic_hi_node-&gt;_cbuf_insts_offset
</pre>
<hr />
<pre>
 3888     call-&gt;_load_ic_node    = loadConLNodes_IC._small;
 3889 
 3890     // Operands for new nodes.
 3891     call-&gt;_opnds[0] = _opnds[0];
 3892     call-&gt;_opnds[1] = _opnds[1];
 3893 
 3894     // Only the inline cache is associated with a register.
 3895     assert(Matcher::inline_cache_reg() == OptoReg::Name(R19_num), &quot;ic reg should be R19&quot;);
 3896 
 3897     // Push new nodes.
 3898     if (loadConLNodes_IC._large_hi) nodes-&gt;push(loadConLNodes_IC._large_hi);
 3899     if (loadConLNodes_IC._last)     nodes-&gt;push(loadConLNodes_IC._last);
 3900     nodes-&gt;push(call);
 3901   %}
 3902 
 3903   // Compound version of call dynamic
 3904   // Toc is only passed so that it can be used in ins_encode statement.
 3905   // In the code we have to use $constanttablebase.
 3906   enc_class enc_java_dynamic_call(method meth, iRegLdst toc) %{
 3907     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 3908     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3909     int start_offset = __ offset();
 3910 
 3911     Register Rtoc = (ra_) ? $constanttablebase : R2_TOC;
 3912 #if 0
 3913     int vtable_index = this-&gt;_vtable_index;
 3914     if (_vtable_index &lt; 0) {
 3915       // Must be invalid_vtable_index, not nonvirtual_vtable_index.
 3916       assert(_vtable_index == Method::invalid_vtable_index, &quot;correct sentinel value&quot;);
 3917       Register ic_reg = as_Register(Matcher::inline_cache_reg_encode());
 3918 
 3919       // Virtual call relocation will point to ic load.
 3920       address virtual_call_meta_addr = __ pc();
 3921       // Load a clear inline cache.
 3922       AddressLiteral empty_ic((address) Universe::non_oop_word());
 3923       bool success = __ load_const_from_method_toc(ic_reg, empty_ic, Rtoc, /*fixed_size*/ true);
 3924       if (!success) {
 3925         ciEnv::current()-&gt;record_out_of_memory_failure();
 3926         return;
 3927       }
 3928       // CALL to fixup routine.  Fixup routine uses ScopeDesc info
</pre>
<hr />
<pre>
 3947       // null. However it may very well end up in handle_wrong_method
 3948       // if the method is abstract for the particular class.
 3949       __ ld(R11_scratch1, in_bytes(Method::from_compiled_offset()), R19_method);
 3950       // Call target. Either compiled code or C2I adapter.
 3951       __ mtctr(R11_scratch1);
 3952       __ bctrl();
 3953       if (((MachCallDynamicJavaNode*)this)-&gt;ret_addr_offset() != __ offset() - start_offset) {
 3954         tty-&gt;print(&quot; %d, %d\n&quot;, ((MachCallDynamicJavaNode*)this)-&gt;ret_addr_offset(),__ offset() - start_offset);
 3955       }
 3956       assert(((MachCallDynamicJavaNode*)this)-&gt;ret_addr_offset() == __ offset() - start_offset,
 3957              &quot;Fix constant in ret_addr_offset()&quot;);
 3958     }
 3959 #endif
 3960     Unimplemented();  // ret_addr_offset not yet fixed. Depends on compressed oops (load klass!).
 3961   %}
 3962 
 3963   // a runtime call
 3964   enc_class enc_java_to_runtime_call (method meth) %{
 3965     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3966 
<span class="line-modified"> 3967     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3968     const address start_pc = __ pc();
 3969 
 3970 #if defined(ABI_ELFv2)
 3971     address entry= !($meth$$method) ? NULL : (address)$meth$$method;
 3972     __ call_c(entry, relocInfo::runtime_call_type);
 3973 #else
 3974     // The function we&#39;re going to call.
 3975     FunctionDescriptor fdtemp;
 3976     const FunctionDescriptor* fd = !($meth$$method) ? &amp;fdtemp : (FunctionDescriptor*)$meth$$method;
 3977 
 3978     Register Rtoc = R12_scratch2;
 3979     // Calculate the method&#39;s TOC.
 3980     __ calculate_address_from_global_toc(Rtoc, __ method_toc());
 3981     // Put entry, env, toc into the constant pool, this needs up to 3 constant
 3982     // pool entries; call_c_using_toc will optimize the call.
 3983     bool success = __ call_c_using_toc(fd, relocInfo::runtime_call_type, Rtoc);
 3984     if (!success) {
 3985       ciEnv::current()-&gt;record_out_of_memory_failure();
 3986       return;
 3987     }
 3988 #endif
 3989 
 3990     // Check the ret_addr_offset.
 3991     assert(((MachCallRuntimeNode*)this)-&gt;ret_addr_offset() ==  __ last_calls_return_pc() - start_pc,
 3992            &quot;Fix constant in ret_addr_offset()&quot;);
 3993   %}
 3994 
 3995   // Move to ctr for leaf call.
 3996   // This enc_class is needed so that scheduler gets proper
 3997   // input mapping for latency computation.
 3998   enc_class enc_leaf_call_mtctr(iRegLsrc src) %{
 3999     // TODO: PPC port $archOpcode(ppc64Opcode_mtctr);
<span class="line-modified"> 4000     C2_MacroAssembler _masm(&amp;cbuf);</span>
 4001     __ mtctr($src$$Register);
 4002   %}
 4003 
 4004   // Postalloc expand emitter for runtime leaf calls.
 4005   enc_class postalloc_expand_java_to_runtime_call(method meth, iRegLdst toc) %{
 4006     loadConLNodesTuple loadConLNodes_Entry;
 4007 #if defined(ABI_ELFv2)
 4008     jlong entry_address = (jlong) this-&gt;entry_point();
 4009     assert(entry_address, &quot;need address here&quot;);
 4010     loadConLNodes_Entry = loadConLNodesTuple_create(ra_, n_toc, new immLOper(entry_address),
 4011                                                     OptoReg::Name(R12_H_num), OptoReg::Name(R12_num));
 4012 #else
 4013     // Get the struct that describes the function we are about to call.
 4014     FunctionDescriptor* fd = (FunctionDescriptor*) this-&gt;entry_point();
 4015     assert(fd, &quot;need fd here&quot;);
 4016     jlong entry_address = (jlong) fd-&gt;entry();
 4017     // new nodes
 4018     loadConLNodesTuple loadConLNodes_Env;
 4019     loadConLNodesTuple loadConLNodes_Toc;
 4020 
</pre>
<hr />
<pre>
 6281   ins_field_cbuf_insts_offset(int);
 6282 
 6283   format %{ &quot;ADDIS   $dst, $toc, offset \t// load long $src from TOC (hi)&quot; %}
 6284   size(4);
 6285   ins_encode( enc_load_long_constL_hi(dst, toc, src) );
 6286   ins_pipe(pipe_class_default);
 6287 %}
 6288 
 6289 // Expand node for constant pool load: large offset.
 6290 // No constant pool entries required.
 6291 instruct loadConL_lo(iRegLdst dst, immL src, iRegLdst base) %{
 6292   effect(DEF dst, USE src, USE base);
 6293   predicate(false);
 6294 
 6295   ins_field_const_toc_offset_hi_node(loadConL_hiNode*);
 6296 
 6297   format %{ &quot;LD      $dst, offset, $base \t// load long $src from TOC (lo)&quot; %}
 6298   size(4);
 6299   ins_encode %{
 6300     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
<span class="line-modified"> 6301     int offset = ra_-&gt;C-&gt;output()-&gt;in_scratch_emit_size() ? 0 : _const_toc_offset_hi_node-&gt;_const_toc_offset;</span>
 6302     __ ld($dst$$Register, MacroAssembler::largeoffset_si16_si16_lo(offset), $base$$Register);
 6303   %}
 6304   ins_pipe(pipe_class_memory);
 6305 %}
 6306 
 6307 // Load long constant from constant table. Expand in case of
 6308 // offset &gt; 16 bit is needed.
 6309 // Adlc adds toc node MachConstantTableBase.
 6310 instruct loadConL_Ex(iRegLdst dst, immL src) %{
 6311   match(Set dst src);
 6312   ins_cost(MEMORY_REF_COST);
 6313 
 6314   format %{ &quot;LD      $dst, offset, $constanttablebase\t// load long $src from table, postalloc expanded&quot; %}
 6315   // We can not inline the enc_class for the expand as that does not support constanttablebase.
 6316   postalloc_expand( postalloc_expand_load_long_constant(dst, src, constanttablebase) );
 6317 %}
 6318 
 6319 // Load NULL as compressed oop.
 6320 instruct loadConN0(iRegNdst dst, immN_0 src) %{
 6321   match(Set dst src);
</pre>
<hr />
<pre>
 6566   ins_num_consts(1);
 6567   ins_field_const_toc_offset(int);
 6568 
 6569   format %{ &quot;ADDIS   $dst, $toc, offset \t// load ptr $src from TOC (hi)&quot; %}
 6570   size(4);
 6571   ins_encode( enc_load_long_constP_hi(dst, src, toc) );
 6572   ins_pipe(pipe_class_default);
 6573 %}
 6574 
 6575 // Expand node for constant pool load: large offset.
 6576 instruct loadConP_lo(iRegPdst dst, immP_NM src, iRegLdst base) %{
 6577   match(Set dst src);
 6578   effect(TEMP base);
 6579 
 6580   ins_field_const_toc_offset_hi_node(loadConP_hiNode*);
 6581 
 6582   format %{ &quot;LD      $dst, offset, $base \t// load ptr $src from TOC (lo)&quot; %}
 6583   size(4);
 6584   ins_encode %{
 6585     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
<span class="line-modified"> 6586     int offset = ra_-&gt;C-&gt;output()-&gt;in_scratch_emit_size() ? 0 : _const_toc_offset_hi_node-&gt;_const_toc_offset;</span>
 6587     __ ld($dst$$Register, MacroAssembler::largeoffset_si16_si16_lo(offset), $base$$Register);
 6588   %}
 6589   ins_pipe(pipe_class_memory);
 6590 %}
 6591 
 6592 // Load pointer constant from constant table. Expand in case an
 6593 // offset &gt; 16 bit is needed.
 6594 // Adlc adds toc node MachConstantTableBase.
 6595 instruct loadConP_Ex(iRegPdst dst, immP src) %{
 6596   match(Set dst src);
 6597   ins_cost(MEMORY_REF_COST);
 6598 
 6599   // This rule does not use &quot;expand&quot; because then
 6600   // the result type is not known to be an Oop.  An ADLC
 6601   // enhancement will be needed to make that work - not worth it!
 6602 
 6603   // If this instruction rematerializes, it prolongs the live range
 6604   // of the toc node, causing illegal graphs.
 6605   // assert(edge_from_to(_reg_node[reg_lo],def)) fails in verify_good_schedule().
 6606   ins_cannot_rematerialize(true);
</pre>
</td>
</tr>
</table>
<center><a href="nativeInst_ppc.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="sharedRuntime_ppc.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>