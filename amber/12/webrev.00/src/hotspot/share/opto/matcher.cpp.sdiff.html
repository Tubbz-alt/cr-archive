<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/matcher.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="macroArrayCopy.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="matcher.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/matcher.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
1342   // Set the mark for all locally allocated State objects.
1343   // When this call returns, the _states_arena arena will be reset
1344   // freeing all State objects.
1345   ResourceMark rm( &amp;_states_arena );
1346 
1347   LabelRootDepth = 0;
1348 
1349   // StoreNodes require their Memory input to match any LoadNodes
1350   Node *mem = n-&gt;is_Store() ? n-&gt;in(MemNode::Memory) : (Node*)1 ;
1351 #ifdef ASSERT
1352   Node* save_mem_node = _mem_node;
1353   _mem_node = n-&gt;is_Store() ? (Node*)n : NULL;
1354 #endif
1355   // State object for root node of match tree
1356   // Allocate it on _states_arena - stack allocation can cause stack overflow.
1357   State *s = new (&amp;_states_arena) State;
1358   s-&gt;_kids[0] = NULL;
1359   s-&gt;_kids[1] = NULL;
1360   s-&gt;_leaf = (Node*)n;
1361   // Label the input tree, allocating labels from top-level arena
<span class="line-modified">1362   Label_Root( n, s, n-&gt;in(0), mem );</span>

1363   if (C-&gt;failing())  return NULL;
1364 
1365   // The minimum cost match for the whole tree is found at the root State
1366   uint mincost = max_juint;
1367   uint cost = max_juint;
1368   uint i;
1369   for( i = 0; i &lt; NUM_OPERANDS; i++ ) {
1370     if( s-&gt;valid(i) &amp;&amp;                // valid entry and
1371         s-&gt;_cost[i] &lt; cost &amp;&amp;         // low cost and
1372         s-&gt;_rule[i] &gt;= NUM_OPERANDS ) // not an operand
1373       cost = s-&gt;_cost[mincost=i];
1374   }
1375   if (mincost == max_juint) {
1376 #ifndef PRODUCT
1377     tty-&gt;print(&quot;No matching rule for:&quot;);
1378     s-&gt;dump();
1379 #endif
1380     Matcher::soft_match_failure();
1381     return NULL;
1382   }
</pre>
<hr />
<pre>
1456       return false;
1457     }
1458   }
1459 
1460   // Not forceable cloning.  If shared, put it into a register.
1461   return shared;
1462 }
1463 
1464 
1465 //------------------------------Instruction Selection--------------------------
1466 // Label method walks a &quot;tree&quot; of nodes, using the ADLC generated DFA to match
1467 // ideal nodes to machine instructions.  Trees are delimited by shared Nodes,
1468 // things the Matcher does not match (e.g., Memory), and things with different
1469 // Controls (hence forced into different blocks).  We pass in the Control
1470 // selected for this entire State tree.
1471 
1472 // The Matcher works on Trees, but an Intel add-to-memory requires a DAG: the
1473 // Store and the Load must have identical Memories (as well as identical
1474 // pointers).  Since the Matcher does not have anything for Memory (and
1475 // does not handle DAGs), I have to match the Memory input myself.  If the
<span class="line-modified">1476 // Tree root is a Store, I require all Loads to have the identical memory.</span>
<span class="line-modified">1477 Node *Matcher::Label_Root( const Node *n, State *svec, Node *control, const Node *mem){</span>

1478   // Since Label_Root is a recursive function, its possible that we might run
1479   // out of stack space.  See bugs 6272980 &amp; 6227033 for more info.
1480   LabelRootDepth++;
1481   if (LabelRootDepth &gt; MaxLabelRootDepth) {
1482     C-&gt;record_method_not_compilable(&quot;Out of stack space, increase MaxLabelRootDepth&quot;);
1483     return NULL;
1484   }
1485   uint care = 0;                // Edges matcher cares about
1486   uint cnt = n-&gt;req();
1487   uint i = 0;
1488 
1489   // Examine children for memory state
1490   // Can only subsume a child into your match-tree if that child&#39;s memory state
1491   // is not modified along the path to another input.
1492   // It is unsafe even if the other inputs are separate roots.
1493   Node *input_mem = NULL;
1494   for( i = 1; i &lt; cnt; i++ ) {
1495     if( !n-&gt;match_edge(i) ) continue;
1496     Node *m = n-&gt;in(i);         // Get ith input
1497     assert( m, &quot;expect non-null children&quot; );
1498     if( m-&gt;is_Load() ) {
1499       if( input_mem == NULL ) {
1500         input_mem = m-&gt;in(MemNode::Memory);





1501       } else if( input_mem != m-&gt;in(MemNode::Memory) ) {
1502         input_mem = NodeSentinel;
1503       }
1504     }
1505   }
1506 
1507   for( i = 1; i &lt; cnt; i++ ){// For my children
1508     if( !n-&gt;match_edge(i) ) continue;
1509     Node *m = n-&gt;in(i);         // Get ith input
1510     // Allocate states out of a private arena
1511     State *s = new (&amp;_states_arena) State;
1512     svec-&gt;_kids[care++] = s;
1513     assert( care &lt;= 2, &quot;binary only for now&quot; );
1514 
1515     // Recursively label the State tree.
1516     s-&gt;_kids[0] = NULL;
1517     s-&gt;_kids[1] = NULL;
1518     s-&gt;_leaf = m;
1519 
1520     // Check for leaves of the State Tree; things that cannot be a part of
1521     // the current tree.  If it finds any, that value is matched as a
1522     // register operand.  If not, then the normal matching is used.
1523     if( match_into_reg(n, m, control, i, is_shared(m)) ||
<span class="line-modified">1524         //</span>
<span class="line-modified">1525         // Stop recursion if this is LoadNode and the root of this tree is a</span>
<span class="line-modified">1526         // StoreNode and the load &amp; store have different memories.</span>
1527         ((mem!=(Node*)1) &amp;&amp; m-&gt;is_Load() &amp;&amp; m-&gt;in(MemNode::Memory) != mem) ||
1528         // Can NOT include the match of a subtree when its memory state
1529         // is used by any of the other subtrees
1530         (input_mem == NodeSentinel) ) {
1531       // Print when we exclude matching due to different memory states at input-loads
1532       if (PrintOpto &amp;&amp; (Verbose &amp;&amp; WizardMode) &amp;&amp; (input_mem == NodeSentinel)
<span class="line-modified">1533         &amp;&amp; !((mem!=(Node*)1) &amp;&amp; m-&gt;is_Load() &amp;&amp; m-&gt;in(MemNode::Memory) != mem)) {</span>
1534         tty-&gt;print_cr(&quot;invalid input_mem&quot;);
1535       }
1536       // Switch to a register-only opcode; this value must be in a register
1537       // and cannot be subsumed as part of a larger instruction.
1538       s-&gt;DFA( m-&gt;ideal_reg(), m );
1539 
1540     } else {
1541       // If match tree has no control and we do, adopt it for entire tree
1542       if( control == NULL &amp;&amp; m-&gt;in(0) != NULL &amp;&amp; m-&gt;req() &gt; 1 )
1543         control = m-&gt;in(0);         // Pick up control
1544       // Else match as a normal part of the match tree.
<span class="line-modified">1545       control = Label_Root(m,s,control,mem);</span>
1546       if (C-&gt;failing()) return NULL;
1547     }
1548   }
1549 
1550 
1551   // Call DFA to match this node, and return
1552   svec-&gt;DFA( n-&gt;Opcode(), n );
1553 
1554 #ifdef ASSERT
1555   uint x;
1556   for( x = 0; x &lt; _LAST_MACH_OPER; x++ )
1557     if( svec-&gt;valid(x) )
1558       break;
1559 
1560   if (x &gt;= _LAST_MACH_OPER) {
1561     n-&gt;dump();
1562     svec-&gt;dump();
1563     assert( false, &quot;bad AD file&quot; );
1564   }
1565 #endif
</pre>
<hr />
<pre>
1894     }
1895   }
1896 }
1897 
1898 
1899 // -------------------------------------------------------------------------
1900 // Java-Java calling convention
1901 // (what you use when Java calls Java)
1902 
1903 //------------------------------find_receiver----------------------------------
1904 // For a given signature, return the OptoReg for parameter 0.
1905 OptoReg::Name Matcher::find_receiver( bool is_outgoing ) {
1906   VMRegPair regs;
1907   BasicType sig_bt = T_OBJECT;
1908   calling_convention(&amp;sig_bt, &amp;regs, 1, is_outgoing);
1909   // Return argument 0 register.  In the LP64 build pointers
1910   // take 2 registers, but the VM wants only the &#39;main&#39; name.
1911   return OptoReg::as_OptoReg(regs.first());
1912 }
1913 
<span class="line-removed">1914 // This function identifies sub-graphs in which a &#39;load&#39; node is</span>
<span class="line-removed">1915 // input to two different nodes, and such that it can be matched</span>
<span class="line-removed">1916 // with BMI instructions like blsi, blsr, etc.</span>
<span class="line-removed">1917 // Example : for b = -a[i] &amp; a[i] can be matched to blsi r32, m32.</span>
<span class="line-removed">1918 // The graph is (AndL (SubL Con0 LoadL*) LoadL*), where LoadL*</span>
<span class="line-removed">1919 // refers to the same node.</span>
<span class="line-removed">1920 #ifdef X86</span>
<span class="line-removed">1921 // Match the generic fused operations pattern (op1 (op2 Con{ConType} mop) mop)</span>
<span class="line-removed">1922 // This is a temporary solution until we make DAGs expressible in ADL.</span>
<span class="line-removed">1923 template&lt;typename ConType&gt;</span>
<span class="line-removed">1924 class FusedPatternMatcher {</span>
<span class="line-removed">1925   Node* _op1_node;</span>
<span class="line-removed">1926   Node* _mop_node;</span>
<span class="line-removed">1927   int _con_op;</span>
<span class="line-removed">1928 </span>
<span class="line-removed">1929   static int match_next(Node* n, int next_op, int next_op_idx) {</span>
<span class="line-removed">1930     if (n-&gt;in(1) == NULL || n-&gt;in(2) == NULL) {</span>
<span class="line-removed">1931       return -1;</span>
<span class="line-removed">1932     }</span>
<span class="line-removed">1933 </span>
<span class="line-removed">1934     if (next_op_idx == -1) { // n is commutative, try rotations</span>
<span class="line-removed">1935       if (n-&gt;in(1)-&gt;Opcode() == next_op) {</span>
<span class="line-removed">1936         return 1;</span>
<span class="line-removed">1937       } else if (n-&gt;in(2)-&gt;Opcode() == next_op) {</span>
<span class="line-removed">1938         return 2;</span>
<span class="line-removed">1939       }</span>
<span class="line-removed">1940     } else {</span>
<span class="line-removed">1941       assert(next_op_idx &gt; 0 &amp;&amp; next_op_idx &lt;= 2, &quot;Bad argument index&quot;);</span>
<span class="line-removed">1942       if (n-&gt;in(next_op_idx)-&gt;Opcode() == next_op) {</span>
<span class="line-removed">1943         return next_op_idx;</span>
<span class="line-removed">1944       }</span>
<span class="line-removed">1945     }</span>
<span class="line-removed">1946     return -1;</span>
<span class="line-removed">1947   }</span>
<span class="line-removed">1948 public:</span>
<span class="line-removed">1949   FusedPatternMatcher(Node* op1_node, Node *mop_node, int con_op) :</span>
<span class="line-removed">1950     _op1_node(op1_node), _mop_node(mop_node), _con_op(con_op) { }</span>
<span class="line-removed">1951 </span>
<span class="line-removed">1952   bool match(int op1, int op1_op2_idx,  // op1 and the index of the op1-&gt;op2 edge, -1 if op1 is commutative</span>
<span class="line-removed">1953              int op2, int op2_con_idx,  // op2 and the index of the op2-&gt;con edge, -1 if op2 is commutative</span>
<span class="line-removed">1954              typename ConType::NativeType con_value) {</span>
<span class="line-removed">1955     if (_op1_node-&gt;Opcode() != op1) {</span>
<span class="line-removed">1956       return false;</span>
<span class="line-removed">1957     }</span>
<span class="line-removed">1958     if (_mop_node-&gt;outcnt() &gt; 2) {</span>
<span class="line-removed">1959       return false;</span>
<span class="line-removed">1960     }</span>
<span class="line-removed">1961     op1_op2_idx = match_next(_op1_node, op2, op1_op2_idx);</span>
<span class="line-removed">1962     if (op1_op2_idx == -1) {</span>
<span class="line-removed">1963       return false;</span>
<span class="line-removed">1964     }</span>
<span class="line-removed">1965     // Memory operation must be the other edge</span>
<span class="line-removed">1966     int op1_mop_idx = (op1_op2_idx &amp; 1) + 1;</span>
<span class="line-removed">1967 </span>
<span class="line-removed">1968     // Check that the mop node is really what we want</span>
<span class="line-removed">1969     if (_op1_node-&gt;in(op1_mop_idx) == _mop_node) {</span>
<span class="line-removed">1970       Node *op2_node = _op1_node-&gt;in(op1_op2_idx);</span>
<span class="line-removed">1971       if (op2_node-&gt;outcnt() &gt; 1) {</span>
<span class="line-removed">1972         return false;</span>
<span class="line-removed">1973       }</span>
<span class="line-removed">1974       assert(op2_node-&gt;Opcode() == op2, &quot;Should be&quot;);</span>
<span class="line-removed">1975       op2_con_idx = match_next(op2_node, _con_op, op2_con_idx);</span>
<span class="line-removed">1976       if (op2_con_idx == -1) {</span>
<span class="line-removed">1977         return false;</span>
<span class="line-removed">1978       }</span>
<span class="line-removed">1979       // Memory operation must be the other edge</span>
<span class="line-removed">1980       int op2_mop_idx = (op2_con_idx &amp; 1) + 1;</span>
<span class="line-removed">1981       // Check that the memory operation is the same node</span>
<span class="line-removed">1982       if (op2_node-&gt;in(op2_mop_idx) == _mop_node) {</span>
<span class="line-removed">1983         // Now check the constant</span>
<span class="line-removed">1984         const Type* con_type = op2_node-&gt;in(op2_con_idx)-&gt;bottom_type();</span>
<span class="line-removed">1985         if (con_type != Type::TOP &amp;&amp; ConType::as_self(con_type)-&gt;get_con() == con_value) {</span>
<span class="line-removed">1986           return true;</span>
<span class="line-removed">1987         }</span>
<span class="line-removed">1988       }</span>
<span class="line-removed">1989     }</span>
<span class="line-removed">1990     return false;</span>
<span class="line-removed">1991   }</span>
<span class="line-removed">1992 };</span>
<span class="line-removed">1993 </span>
<span class="line-removed">1994 </span>
<span class="line-removed">1995 bool Matcher::is_bmi_pattern(Node *n, Node *m) {</span>
<span class="line-removed">1996   if (n != NULL &amp;&amp; m != NULL) {</span>
<span class="line-removed">1997     if (m-&gt;Opcode() == Op_LoadI) {</span>
<span class="line-removed">1998       FusedPatternMatcher&lt;TypeInt&gt; bmii(n, m, Op_ConI);</span>
<span class="line-removed">1999       return bmii.match(Op_AndI, -1, Op_SubI,  1,  0)  ||</span>
<span class="line-removed">2000              bmii.match(Op_AndI, -1, Op_AddI, -1, -1)  ||</span>
<span class="line-removed">2001              bmii.match(Op_XorI, -1, Op_AddI, -1, -1);</span>
<span class="line-removed">2002     } else if (m-&gt;Opcode() == Op_LoadL) {</span>
<span class="line-removed">2003       FusedPatternMatcher&lt;TypeLong&gt; bmil(n, m, Op_ConL);</span>
<span class="line-removed">2004       return bmil.match(Op_AndL, -1, Op_SubL,  1,  0) ||</span>
<span class="line-removed">2005              bmil.match(Op_AndL, -1, Op_AddL, -1, -1) ||</span>
<span class="line-removed">2006              bmil.match(Op_XorL, -1, Op_AddL, -1, -1);</span>
<span class="line-removed">2007     }</span>
<span class="line-removed">2008   }</span>
<span class="line-removed">2009   return false;</span>
<span class="line-removed">2010 }</span>
<span class="line-removed">2011 #endif // X86</span>
<span class="line-removed">2012 </span>
2013 bool Matcher::is_vshift_con_pattern(Node *n, Node *m) {
2014   if (n != NULL &amp;&amp; m != NULL) {
2015     return VectorNode::is_vector_shift(n) &amp;&amp;
2016            VectorNode::is_vector_shift_count(m) &amp;&amp; m-&gt;in(1)-&gt;is_Con();
2017   }
2018   return false;
2019 }
2020 
2021 














2022 bool Matcher::clone_base_plus_offset_address(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
2023   Node *off = m-&gt;in(AddPNode::Offset);
2024   if (off-&gt;is_Con()) {
2025     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
2026     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
2027     // Clone X+offset as it also folds into most addressing expressions
2028     mstack.push(off, Visit);
2029     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
2030     return true;
2031   }
2032   return false;
2033 }
2034 
2035 // A method-klass-holder may be passed in the inline_cache_reg
2036 // and then expanded into the inline_cache_reg and a method_oop register
2037 //   defined in ad_&lt;arch&gt;.cpp
2038 
2039 //------------------------------find_shared------------------------------------
2040 // Set bits if Node is shared or otherwise a root
<span class="line-modified">2041 void Matcher::find_shared( Node *n ) {</span>
2042   // Allocate stack of size C-&gt;live_nodes() * 2 to avoid frequent realloc
2043   MStack mstack(C-&gt;live_nodes() * 2);
2044   // Mark nodes as address_visited if they are inputs to an address expression
2045   VectorSet address_visited(Thread::current()-&gt;resource_area());
2046   mstack.push(n, Visit);     // Don&#39;t need to pre-visit root node
2047   while (mstack.is_nonempty()) {
2048     n = mstack.node();       // Leave node on stack
2049     Node_State nstate = mstack.state();
2050     uint nop = n-&gt;Opcode();
2051     if (nstate == Pre_Visit) {
2052       if (address_visited.test(n-&gt;_idx)) { // Visited in address already?
2053         // Flag as visited and shared now.
2054         set_visited(n);
2055       }
2056       if (is_visited(n)) {   // Visited already?
2057         // Node is shared and has no reason to clone.  Flag it as shared.
2058         // This causes it to match into a register for the sharing.
2059         set_shared(n);       // Flag as shared and
2060         if (n-&gt;is_DecodeNarrowPtr()) {
2061           // Oop field/array element loads must be shared but since
2062           // they are shared through a DecodeN they may appear to have
2063           // a single use so force sharing here.
2064           set_shared(n-&gt;in(1));
2065         }
2066         mstack.pop();        // remove node from stack
2067         continue;
2068       }
2069       nstate = Visit; // Not already visited; so visit now
2070     }
2071     if (nstate == Visit) {
2072       mstack.set_state(Post_Visit);
2073       set_visited(n);   // Flag as visited now
2074       bool mem_op = false;
2075       int mem_addr_idx = MemNode::Address;
2076       if (find_shared_visit(mstack, n, nop, mem_op, mem_addr_idx)) {
2077         continue;
2078       }
<span class="line-modified">2079       for(int i = n-&gt;req() - 1; i &gt;= 0; --i) { // For my children</span>
<span class="line-modified">2080         Node *m = n-&gt;in(i); // Get ith input</span>
<span class="line-modified">2081         if (m == NULL) continue;  // Ignore NULLs</span>
<span class="line-modified">2082         uint mop = m-&gt;Opcode();</span>
<span class="line-removed">2083 </span>
<span class="line-removed">2084         // Must clone all producers of flags, or we will not match correctly.</span>
<span class="line-removed">2085         // Suppose a compare setting int-flags is shared (e.g., a switch-tree)</span>
<span class="line-removed">2086         // then it will match into an ideal Op_RegFlags.  Alas, the fp-flags</span>
<span class="line-removed">2087         // are also there, so we may match a float-branch to int-flags and</span>
<span class="line-removed">2088         // expect the allocator to haul the flags from the int-side to the</span>
<span class="line-removed">2089         // fp-side.  No can do.</span>
<span class="line-removed">2090         if( _must_clone[mop] ) {</span>
<span class="line-removed">2091           mstack.push(m, Visit);</span>
<span class="line-removed">2092           continue; // for(int i = ...)</span>
2093         }
<span class="line-modified">2094 </span>
<span class="line-removed">2095         // if &#39;n&#39; and &#39;m&#39; are part of a graph for BMI instruction, clone this node.</span>
<span class="line-removed">2096 #ifdef X86</span>
<span class="line-removed">2097         if (UseBMI1Instructions &amp;&amp; is_bmi_pattern(n, m)) {</span>
<span class="line-removed">2098           mstack.push(m, Visit);</span>
<span class="line-removed">2099           continue;</span>
<span class="line-removed">2100         }</span>
<span class="line-removed">2101 #endif</span>
<span class="line-removed">2102         if (is_vshift_con_pattern(n, m)) {</span>
<span class="line-removed">2103           mstack.push(m, Visit);</span>
2104           continue;
2105         }
2106 
2107         // Clone addressing expressions as they are &quot;free&quot; in memory access instructions
<span class="line-modified">2108         if (mem_op &amp;&amp; i == mem_addr_idx &amp;&amp; mop == Op_AddP &amp;&amp;</span>
2109             // When there are other uses besides address expressions
2110             // put it on stack and mark as shared.
2111             !is_visited(m)) {
2112           // Some inputs for address expression are not put on stack
2113           // to avoid marking them as shared and forcing them into register
2114           // if they are used only in address expressions.
2115           // But they should be marked as shared if there are other uses
2116           // besides address expressions.
2117 
<span class="line-modified">2118           if (clone_address_expressions(m-&gt;as_AddP(), mstack, address_visited)) {</span>
2119             continue;
2120           }
2121         }   // if( mem_op &amp;&amp;
2122         mstack.push(m, Pre_Visit);
2123       }     // for(int i = ...)
2124     }
2125     else if (nstate == Alt_Post_Visit) {
2126       mstack.pop(); // Remove node from stack
2127       // We cannot remove the Cmp input from the Bool here, as the Bool may be
2128       // shared and all users of the Bool need to move the Cmp in parallel.
2129       // This leaves both the Bool and the If pointing at the Cmp.  To
2130       // prevent the Matcher from trying to Match the Cmp along both paths
2131       // BoolNode::match_edge always returns a zero.
2132 
2133       // We reorder the Op_If in a pre-order manner, so we can visit without
2134       // accidentally sharing the Cmp (the Bool and the If make 2 users).
2135       n-&gt;add_req( n-&gt;in(1)-&gt;in(1) ); // Add the Cmp next to the Bool
2136     }
2137     else if (nstate == Post_Visit) {
2138       mstack.pop(); // Remove node from stack
</pre>
<hr />
<pre>
2196     case Op_NeverBranch:
2197       set_dontcare(n);
2198       break;
2199     case Op_Jump:
2200       mstack.push(n-&gt;in(1), Pre_Visit);     // Switch Value (could be shared)
2201       mstack.push(n-&gt;in(0), Pre_Visit);     // Visit Control input
2202       return true;                             // while (mstack.is_nonempty())
2203     case Op_StrComp:
2204     case Op_StrEquals:
2205     case Op_StrIndexOf:
2206     case Op_StrIndexOfChar:
2207     case Op_AryEq:
2208     case Op_HasNegatives:
2209     case Op_StrInflatedCopy:
2210     case Op_StrCompressedCopy:
2211     case Op_EncodeISOArray:
2212     case Op_FmaD:
2213     case Op_FmaF:
2214     case Op_FmaVD:
2215     case Op_FmaVF:

2216       set_shared(n); // Force result into register (it will be anyways)
2217       break;
2218     case Op_ConP: {  // Convert pointers above the centerline to NUL
2219       TypeNode *tn = n-&gt;as_Type(); // Constants derive from type nodes
2220       const TypePtr* tp = tn-&gt;type()-&gt;is_ptr();
2221       if (tp-&gt;_ptr == TypePtr::AnyNull) {
2222         tn-&gt;set_type(TypePtr::NULL_PTR);
2223       }
2224       break;
2225     }
2226     case Op_ConN: {  // Convert narrow pointers above the centerline to NUL
2227       TypeNode *tn = n-&gt;as_Type(); // Constants derive from type nodes
2228       const TypePtr* tp = tn-&gt;type()-&gt;make_ptr();
2229       if (tp &amp;&amp; tp-&gt;_ptr == TypePtr::AnyNull) {
2230         tn-&gt;set_type(TypeNarrowOop::NULL_PTR);
2231       }
2232       break;
2233     }
2234     case Op_Binary:         // These are introduced in the Post_Visit state.
2235       ShouldNotReachHere();
</pre>
<hr />
<pre>
2289     }
2290     case Op_CMoveD:              // Convert trinary to binary-tree
2291     case Op_CMoveF:
2292     case Op_CMoveI:
2293     case Op_CMoveL:
2294     case Op_CMoveN:
2295     case Op_CMoveP:
2296     case Op_CMoveVF:
2297     case Op_CMoveVD:  {
2298       // Restructure into a binary tree for Matching.  It&#39;s possible that
2299       // we could move this code up next to the graph reshaping for IfNodes
2300       // or vice-versa, but I do not want to debug this for Ladybird.
2301       // 10/2/2000 CNC.
2302       Node* pair1 = new BinaryNode(n-&gt;in(1), n-&gt;in(1)-&gt;in(1));
2303       n-&gt;set_req(1, pair1);
2304       Node* pair2 = new BinaryNode(n-&gt;in(2), n-&gt;in(3));
2305       n-&gt;set_req(2, pair2);
2306       n-&gt;del_req(3);
2307       break;
2308     }









2309     case Op_LoopLimit: {
2310       Node* pair1 = new BinaryNode(n-&gt;in(1), n-&gt;in(2));
2311       n-&gt;set_req(1, pair1);
2312       n-&gt;set_req(2, n-&gt;in(3));
2313       n-&gt;del_req(3);
2314       break;
2315     }
2316     case Op_StrEquals:
2317     case Op_StrIndexOfChar: {
2318       Node* pair1 = new BinaryNode(n-&gt;in(2), n-&gt;in(3));
2319       n-&gt;set_req(2, pair1);
2320       n-&gt;set_req(3, n-&gt;in(4));
2321       n-&gt;del_req(4);
2322       break;
2323     }
2324     case Op_StrComp:
2325     case Op_StrIndexOf: {
2326       Node* pair1 = new BinaryNode(n-&gt;in(2), n-&gt;in(3));
2327       n-&gt;set_req(2, pair1);
2328       Node* pair2 = new BinaryNode(n-&gt;in(4),n-&gt;in(5));
</pre>
</td>
<td>
<hr />
<pre>
1342   // Set the mark for all locally allocated State objects.
1343   // When this call returns, the _states_arena arena will be reset
1344   // freeing all State objects.
1345   ResourceMark rm( &amp;_states_arena );
1346 
1347   LabelRootDepth = 0;
1348 
1349   // StoreNodes require their Memory input to match any LoadNodes
1350   Node *mem = n-&gt;is_Store() ? n-&gt;in(MemNode::Memory) : (Node*)1 ;
1351 #ifdef ASSERT
1352   Node* save_mem_node = _mem_node;
1353   _mem_node = n-&gt;is_Store() ? (Node*)n : NULL;
1354 #endif
1355   // State object for root node of match tree
1356   // Allocate it on _states_arena - stack allocation can cause stack overflow.
1357   State *s = new (&amp;_states_arena) State;
1358   s-&gt;_kids[0] = NULL;
1359   s-&gt;_kids[1] = NULL;
1360   s-&gt;_leaf = (Node*)n;
1361   // Label the input tree, allocating labels from top-level arena
<span class="line-modified">1362   Node* root_mem = mem;</span>
<span class="line-added">1363   Label_Root(n, s, n-&gt;in(0), root_mem);</span>
1364   if (C-&gt;failing())  return NULL;
1365 
1366   // The minimum cost match for the whole tree is found at the root State
1367   uint mincost = max_juint;
1368   uint cost = max_juint;
1369   uint i;
1370   for( i = 0; i &lt; NUM_OPERANDS; i++ ) {
1371     if( s-&gt;valid(i) &amp;&amp;                // valid entry and
1372         s-&gt;_cost[i] &lt; cost &amp;&amp;         // low cost and
1373         s-&gt;_rule[i] &gt;= NUM_OPERANDS ) // not an operand
1374       cost = s-&gt;_cost[mincost=i];
1375   }
1376   if (mincost == max_juint) {
1377 #ifndef PRODUCT
1378     tty-&gt;print(&quot;No matching rule for:&quot;);
1379     s-&gt;dump();
1380 #endif
1381     Matcher::soft_match_failure();
1382     return NULL;
1383   }
</pre>
<hr />
<pre>
1457       return false;
1458     }
1459   }
1460 
1461   // Not forceable cloning.  If shared, put it into a register.
1462   return shared;
1463 }
1464 
1465 
1466 //------------------------------Instruction Selection--------------------------
1467 // Label method walks a &quot;tree&quot; of nodes, using the ADLC generated DFA to match
1468 // ideal nodes to machine instructions.  Trees are delimited by shared Nodes,
1469 // things the Matcher does not match (e.g., Memory), and things with different
1470 // Controls (hence forced into different blocks).  We pass in the Control
1471 // selected for this entire State tree.
1472 
1473 // The Matcher works on Trees, but an Intel add-to-memory requires a DAG: the
1474 // Store and the Load must have identical Memories (as well as identical
1475 // pointers).  Since the Matcher does not have anything for Memory (and
1476 // does not handle DAGs), I have to match the Memory input myself.  If the
<span class="line-modified">1477 // Tree root is a Store or if there are multiple Loads in the tree, I require</span>
<span class="line-modified">1478 // all Loads to have the identical memory.</span>
<span class="line-added">1479 Node* Matcher::Label_Root(const Node* n, State* svec, Node* control, Node*&amp; mem) {</span>
1480   // Since Label_Root is a recursive function, its possible that we might run
1481   // out of stack space.  See bugs 6272980 &amp; 6227033 for more info.
1482   LabelRootDepth++;
1483   if (LabelRootDepth &gt; MaxLabelRootDepth) {
1484     C-&gt;record_method_not_compilable(&quot;Out of stack space, increase MaxLabelRootDepth&quot;);
1485     return NULL;
1486   }
1487   uint care = 0;                // Edges matcher cares about
1488   uint cnt = n-&gt;req();
1489   uint i = 0;
1490 
1491   // Examine children for memory state
1492   // Can only subsume a child into your match-tree if that child&#39;s memory state
1493   // is not modified along the path to another input.
1494   // It is unsafe even if the other inputs are separate roots.
1495   Node *input_mem = NULL;
1496   for( i = 1; i &lt; cnt; i++ ) {
1497     if( !n-&gt;match_edge(i) ) continue;
1498     Node *m = n-&gt;in(i);         // Get ith input
1499     assert( m, &quot;expect non-null children&quot; );
1500     if( m-&gt;is_Load() ) {
1501       if( input_mem == NULL ) {
1502         input_mem = m-&gt;in(MemNode::Memory);
<span class="line-added">1503         if (mem == (Node*)1) {</span>
<span class="line-added">1504           // Save this memory to bail out if there&#39;s another memory access</span>
<span class="line-added">1505           // to a different memory location in the same tree.</span>
<span class="line-added">1506           mem = input_mem;</span>
<span class="line-added">1507         }</span>
1508       } else if( input_mem != m-&gt;in(MemNode::Memory) ) {
1509         input_mem = NodeSentinel;
1510       }
1511     }
1512   }
1513 
1514   for( i = 1; i &lt; cnt; i++ ){// For my children
1515     if( !n-&gt;match_edge(i) ) continue;
1516     Node *m = n-&gt;in(i);         // Get ith input
1517     // Allocate states out of a private arena
1518     State *s = new (&amp;_states_arena) State;
1519     svec-&gt;_kids[care++] = s;
1520     assert( care &lt;= 2, &quot;binary only for now&quot; );
1521 
1522     // Recursively label the State tree.
1523     s-&gt;_kids[0] = NULL;
1524     s-&gt;_kids[1] = NULL;
1525     s-&gt;_leaf = m;
1526 
1527     // Check for leaves of the State Tree; things that cannot be a part of
1528     // the current tree.  If it finds any, that value is matched as a
1529     // register operand.  If not, then the normal matching is used.
1530     if( match_into_reg(n, m, control, i, is_shared(m)) ||
<span class="line-modified">1531         // Stop recursion if this is a LoadNode and there is another memory access</span>
<span class="line-modified">1532         // to a different memory location in the same tree (for example, a StoreNode</span>
<span class="line-modified">1533         // at the root of this tree or another LoadNode in one of the children).</span>
1534         ((mem!=(Node*)1) &amp;&amp; m-&gt;is_Load() &amp;&amp; m-&gt;in(MemNode::Memory) != mem) ||
1535         // Can NOT include the match of a subtree when its memory state
1536         // is used by any of the other subtrees
1537         (input_mem == NodeSentinel) ) {
1538       // Print when we exclude matching due to different memory states at input-loads
1539       if (PrintOpto &amp;&amp; (Verbose &amp;&amp; WizardMode) &amp;&amp; (input_mem == NodeSentinel)
<span class="line-modified">1540           &amp;&amp; !((mem!=(Node*)1) &amp;&amp; m-&gt;is_Load() &amp;&amp; m-&gt;in(MemNode::Memory) != mem)) {</span>
1541         tty-&gt;print_cr(&quot;invalid input_mem&quot;);
1542       }
1543       // Switch to a register-only opcode; this value must be in a register
1544       // and cannot be subsumed as part of a larger instruction.
1545       s-&gt;DFA( m-&gt;ideal_reg(), m );
1546 
1547     } else {
1548       // If match tree has no control and we do, adopt it for entire tree
1549       if( control == NULL &amp;&amp; m-&gt;in(0) != NULL &amp;&amp; m-&gt;req() &gt; 1 )
1550         control = m-&gt;in(0);         // Pick up control
1551       // Else match as a normal part of the match tree.
<span class="line-modified">1552       control = Label_Root(m, s, control, mem);</span>
1553       if (C-&gt;failing()) return NULL;
1554     }
1555   }
1556 
1557 
1558   // Call DFA to match this node, and return
1559   svec-&gt;DFA( n-&gt;Opcode(), n );
1560 
1561 #ifdef ASSERT
1562   uint x;
1563   for( x = 0; x &lt; _LAST_MACH_OPER; x++ )
1564     if( svec-&gt;valid(x) )
1565       break;
1566 
1567   if (x &gt;= _LAST_MACH_OPER) {
1568     n-&gt;dump();
1569     svec-&gt;dump();
1570     assert( false, &quot;bad AD file&quot; );
1571   }
1572 #endif
</pre>
<hr />
<pre>
1901     }
1902   }
1903 }
1904 
1905 
1906 // -------------------------------------------------------------------------
1907 // Java-Java calling convention
1908 // (what you use when Java calls Java)
1909 
1910 //------------------------------find_receiver----------------------------------
1911 // For a given signature, return the OptoReg for parameter 0.
1912 OptoReg::Name Matcher::find_receiver( bool is_outgoing ) {
1913   VMRegPair regs;
1914   BasicType sig_bt = T_OBJECT;
1915   calling_convention(&amp;sig_bt, &amp;regs, 1, is_outgoing);
1916   // Return argument 0 register.  In the LP64 build pointers
1917   // take 2 registers, but the VM wants only the &#39;main&#39; name.
1918   return OptoReg::as_OptoReg(regs.first());
1919 }
1920 



































































































1921 bool Matcher::is_vshift_con_pattern(Node *n, Node *m) {
1922   if (n != NULL &amp;&amp; m != NULL) {
1923     return VectorNode::is_vector_shift(n) &amp;&amp;
1924            VectorNode::is_vector_shift_count(m) &amp;&amp; m-&gt;in(1)-&gt;is_Con();
1925   }
1926   return false;
1927 }
1928 
1929 
<span class="line-added">1930 bool Matcher::clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {</span>
<span class="line-added">1931   // Must clone all producers of flags, or we will not match correctly.</span>
<span class="line-added">1932   // Suppose a compare setting int-flags is shared (e.g., a switch-tree)</span>
<span class="line-added">1933   // then it will match into an ideal Op_RegFlags.  Alas, the fp-flags</span>
<span class="line-added">1934   // are also there, so we may match a float-branch to int-flags and</span>
<span class="line-added">1935   // expect the allocator to haul the flags from the int-side to the</span>
<span class="line-added">1936   // fp-side.  No can do.</span>
<span class="line-added">1937   if (_must_clone[m-&gt;Opcode()]) {</span>
<span class="line-added">1938     mstack.push(m, Visit);</span>
<span class="line-added">1939     return true;</span>
<span class="line-added">1940   }</span>
<span class="line-added">1941   return pd_clone_node(n, m, mstack);</span>
<span class="line-added">1942 }</span>
<span class="line-added">1943 </span>
1944 bool Matcher::clone_base_plus_offset_address(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
1945   Node *off = m-&gt;in(AddPNode::Offset);
1946   if (off-&gt;is_Con()) {
1947     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
1948     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
1949     // Clone X+offset as it also folds into most addressing expressions
1950     mstack.push(off, Visit);
1951     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
1952     return true;
1953   }
1954   return false;
1955 }
1956 
1957 // A method-klass-holder may be passed in the inline_cache_reg
1958 // and then expanded into the inline_cache_reg and a method_oop register
1959 //   defined in ad_&lt;arch&gt;.cpp
1960 
1961 //------------------------------find_shared------------------------------------
1962 // Set bits if Node is shared or otherwise a root
<span class="line-modified">1963 void Matcher::find_shared(Node* n) {</span>
1964   // Allocate stack of size C-&gt;live_nodes() * 2 to avoid frequent realloc
1965   MStack mstack(C-&gt;live_nodes() * 2);
1966   // Mark nodes as address_visited if they are inputs to an address expression
1967   VectorSet address_visited(Thread::current()-&gt;resource_area());
1968   mstack.push(n, Visit);     // Don&#39;t need to pre-visit root node
1969   while (mstack.is_nonempty()) {
1970     n = mstack.node();       // Leave node on stack
1971     Node_State nstate = mstack.state();
1972     uint nop = n-&gt;Opcode();
1973     if (nstate == Pre_Visit) {
1974       if (address_visited.test(n-&gt;_idx)) { // Visited in address already?
1975         // Flag as visited and shared now.
1976         set_visited(n);
1977       }
1978       if (is_visited(n)) {   // Visited already?
1979         // Node is shared and has no reason to clone.  Flag it as shared.
1980         // This causes it to match into a register for the sharing.
1981         set_shared(n);       // Flag as shared and
1982         if (n-&gt;is_DecodeNarrowPtr()) {
1983           // Oop field/array element loads must be shared but since
1984           // they are shared through a DecodeN they may appear to have
1985           // a single use so force sharing here.
1986           set_shared(n-&gt;in(1));
1987         }
1988         mstack.pop();        // remove node from stack
1989         continue;
1990       }
1991       nstate = Visit; // Not already visited; so visit now
1992     }
1993     if (nstate == Visit) {
1994       mstack.set_state(Post_Visit);
1995       set_visited(n);   // Flag as visited now
1996       bool mem_op = false;
1997       int mem_addr_idx = MemNode::Address;
1998       if (find_shared_visit(mstack, n, nop, mem_op, mem_addr_idx)) {
1999         continue;
2000       }
<span class="line-modified">2001       for (int i = n-&gt;req() - 1; i &gt;= 0; --i) { // For my children</span>
<span class="line-modified">2002         Node* m = n-&gt;in(i); // Get ith input</span>
<span class="line-modified">2003         if (m == NULL) {</span>
<span class="line-modified">2004           continue;  // Ignore NULLs</span>










2005         }
<span class="line-modified">2006         if (clone_node(n, m, mstack)) {</span>









2007           continue;
2008         }
2009 
2010         // Clone addressing expressions as they are &quot;free&quot; in memory access instructions
<span class="line-modified">2011         if (mem_op &amp;&amp; i == mem_addr_idx &amp;&amp; m-&gt;is_AddP() &amp;&amp;</span>
2012             // When there are other uses besides address expressions
2013             // put it on stack and mark as shared.
2014             !is_visited(m)) {
2015           // Some inputs for address expression are not put on stack
2016           // to avoid marking them as shared and forcing them into register
2017           // if they are used only in address expressions.
2018           // But they should be marked as shared if there are other uses
2019           // besides address expressions.
2020 
<span class="line-modified">2021           if (pd_clone_address_expressions(m-&gt;as_AddP(), mstack, address_visited)) {</span>
2022             continue;
2023           }
2024         }   // if( mem_op &amp;&amp;
2025         mstack.push(m, Pre_Visit);
2026       }     // for(int i = ...)
2027     }
2028     else if (nstate == Alt_Post_Visit) {
2029       mstack.pop(); // Remove node from stack
2030       // We cannot remove the Cmp input from the Bool here, as the Bool may be
2031       // shared and all users of the Bool need to move the Cmp in parallel.
2032       // This leaves both the Bool and the If pointing at the Cmp.  To
2033       // prevent the Matcher from trying to Match the Cmp along both paths
2034       // BoolNode::match_edge always returns a zero.
2035 
2036       // We reorder the Op_If in a pre-order manner, so we can visit without
2037       // accidentally sharing the Cmp (the Bool and the If make 2 users).
2038       n-&gt;add_req( n-&gt;in(1)-&gt;in(1) ); // Add the Cmp next to the Bool
2039     }
2040     else if (nstate == Post_Visit) {
2041       mstack.pop(); // Remove node from stack
</pre>
<hr />
<pre>
2099     case Op_NeverBranch:
2100       set_dontcare(n);
2101       break;
2102     case Op_Jump:
2103       mstack.push(n-&gt;in(1), Pre_Visit);     // Switch Value (could be shared)
2104       mstack.push(n-&gt;in(0), Pre_Visit);     // Visit Control input
2105       return true;                             // while (mstack.is_nonempty())
2106     case Op_StrComp:
2107     case Op_StrEquals:
2108     case Op_StrIndexOf:
2109     case Op_StrIndexOfChar:
2110     case Op_AryEq:
2111     case Op_HasNegatives:
2112     case Op_StrInflatedCopy:
2113     case Op_StrCompressedCopy:
2114     case Op_EncodeISOArray:
2115     case Op_FmaD:
2116     case Op_FmaF:
2117     case Op_FmaVD:
2118     case Op_FmaVF:
<span class="line-added">2119     case Op_MacroLogicV:</span>
2120       set_shared(n); // Force result into register (it will be anyways)
2121       break;
2122     case Op_ConP: {  // Convert pointers above the centerline to NUL
2123       TypeNode *tn = n-&gt;as_Type(); // Constants derive from type nodes
2124       const TypePtr* tp = tn-&gt;type()-&gt;is_ptr();
2125       if (tp-&gt;_ptr == TypePtr::AnyNull) {
2126         tn-&gt;set_type(TypePtr::NULL_PTR);
2127       }
2128       break;
2129     }
2130     case Op_ConN: {  // Convert narrow pointers above the centerline to NUL
2131       TypeNode *tn = n-&gt;as_Type(); // Constants derive from type nodes
2132       const TypePtr* tp = tn-&gt;type()-&gt;make_ptr();
2133       if (tp &amp;&amp; tp-&gt;_ptr == TypePtr::AnyNull) {
2134         tn-&gt;set_type(TypeNarrowOop::NULL_PTR);
2135       }
2136       break;
2137     }
2138     case Op_Binary:         // These are introduced in the Post_Visit state.
2139       ShouldNotReachHere();
</pre>
<hr />
<pre>
2193     }
2194     case Op_CMoveD:              // Convert trinary to binary-tree
2195     case Op_CMoveF:
2196     case Op_CMoveI:
2197     case Op_CMoveL:
2198     case Op_CMoveN:
2199     case Op_CMoveP:
2200     case Op_CMoveVF:
2201     case Op_CMoveVD:  {
2202       // Restructure into a binary tree for Matching.  It&#39;s possible that
2203       // we could move this code up next to the graph reshaping for IfNodes
2204       // or vice-versa, but I do not want to debug this for Ladybird.
2205       // 10/2/2000 CNC.
2206       Node* pair1 = new BinaryNode(n-&gt;in(1), n-&gt;in(1)-&gt;in(1));
2207       n-&gt;set_req(1, pair1);
2208       Node* pair2 = new BinaryNode(n-&gt;in(2), n-&gt;in(3));
2209       n-&gt;set_req(2, pair2);
2210       n-&gt;del_req(3);
2211       break;
2212     }
<span class="line-added">2213     case Op_MacroLogicV: {</span>
<span class="line-added">2214       Node* pair1 = new BinaryNode(n-&gt;in(1), n-&gt;in(2));</span>
<span class="line-added">2215       Node* pair2 = new BinaryNode(n-&gt;in(3), n-&gt;in(4));</span>
<span class="line-added">2216       n-&gt;set_req(1, pair1);</span>
<span class="line-added">2217       n-&gt;set_req(2, pair2);</span>
<span class="line-added">2218       n-&gt;del_req(4);</span>
<span class="line-added">2219       n-&gt;del_req(3);</span>
<span class="line-added">2220       break;</span>
<span class="line-added">2221     }</span>
2222     case Op_LoopLimit: {
2223       Node* pair1 = new BinaryNode(n-&gt;in(1), n-&gt;in(2));
2224       n-&gt;set_req(1, pair1);
2225       n-&gt;set_req(2, n-&gt;in(3));
2226       n-&gt;del_req(3);
2227       break;
2228     }
2229     case Op_StrEquals:
2230     case Op_StrIndexOfChar: {
2231       Node* pair1 = new BinaryNode(n-&gt;in(2), n-&gt;in(3));
2232       n-&gt;set_req(2, pair1);
2233       n-&gt;set_req(3, n-&gt;in(4));
2234       n-&gt;del_req(4);
2235       break;
2236     }
2237     case Op_StrComp:
2238     case Op_StrIndexOf: {
2239       Node* pair1 = new BinaryNode(n-&gt;in(2), n-&gt;in(3));
2240       n-&gt;set_req(2, pair1);
2241       Node* pair2 = new BinaryNode(n-&gt;in(4),n-&gt;in(5));
</pre>
</td>
</tr>
</table>
<center><a href="macroArrayCopy.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="matcher.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>