<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/shared/referenceProcessor.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="jvmFlagConstraintsGC.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="threadLocalAllocBuffer.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shared/referenceProcessor.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 765   assert(total_refs == balanced_total_refs, &quot;Balancing was incomplete&quot;);
 766 #endif
 767 }
 768 
 769 bool ReferenceProcessor::is_mt_processing_set_up(AbstractRefProcTaskExecutor* task_executor) const {
 770   return task_executor != NULL &amp;&amp; _processing_is_mt;
 771 }
 772 
 773 void ReferenceProcessor::process_soft_ref_reconsider(BoolObjectClosure* is_alive,
 774                                                      OopClosure* keep_alive,
 775                                                      VoidClosure* complete_gc,
 776                                                      AbstractRefProcTaskExecutor* task_executor,
 777                                                      ReferenceProcessorPhaseTimes* phase_times) {
 778   assert(!_processing_is_mt || task_executor != NULL, &quot;Task executor must not be NULL when mt processing is set.&quot;);
 779 
 780   size_t const num_soft_refs = total_count(_discoveredSoftRefs);
 781   phase_times-&gt;set_ref_discovered(REF_SOFT, num_soft_refs);
 782 
 783   phase_times-&gt;set_processing_is_mt(_processing_is_mt);
 784 
<span class="line-modified"> 785   if (num_soft_refs == 0 || _current_soft_ref_policy == NULL) {</span>
<span class="line-modified"> 786     log_debug(gc, ref)(&quot;Skipped phase1 of Reference Processing due to unavailable references&quot;);</span>





 787     return;
 788   }
 789 
 790   RefProcMTDegreeAdjuster a(this, RefPhase1, num_soft_refs);
 791 
 792   if (_processing_is_mt) {
 793     RefProcBalanceQueuesTimeTracker tt(RefPhase1, phase_times);
 794     maybe_balance_queues(_discoveredSoftRefs);
 795   }
 796 
 797   RefProcPhaseTimeTracker tt(RefPhase1, phase_times);
 798 
<span class="line-modified"> 799   log_reflist(&quot;Phase1 Soft before&quot;, _discoveredSoftRefs, _max_num_queues);</span>
 800   if (_processing_is_mt) {
 801     RefProcPhase1Task phase1(*this, phase_times, _current_soft_ref_policy);
 802     task_executor-&gt;execute(phase1, num_queues());
 803   } else {
 804     size_t removed = 0;
 805 
 806     RefProcSubPhasesWorkerTimeTracker tt2(SoftRefSubPhase1, phase_times, 0);
 807     for (uint i = 0; i &lt; _max_num_queues; i++) {
 808       removed += process_soft_ref_reconsider_work(_discoveredSoftRefs[i], _current_soft_ref_policy,
 809                                                   is_alive, keep_alive, complete_gc);
 810     }
 811 
 812     phase_times-&gt;add_ref_cleared(REF_SOFT, removed);
 813   }
<span class="line-modified"> 814   log_reflist(&quot;Phase1 Soft after&quot;, _discoveredSoftRefs, _max_num_queues);</span>
 815 }
 816 
 817 void ReferenceProcessor::process_soft_weak_final_refs(BoolObjectClosure* is_alive,
 818                                                       OopClosure* keep_alive,
 819                                                       VoidClosure* complete_gc,
 820                                                       AbstractRefProcTaskExecutor*  task_executor,
 821                                                       ReferenceProcessorPhaseTimes* phase_times) {
 822   assert(!_processing_is_mt || task_executor != NULL, &quot;Task executor must not be NULL when mt processing is set.&quot;);
 823 
 824   size_t const num_soft_refs = total_count(_discoveredSoftRefs);
 825   size_t const num_weak_refs = total_count(_discoveredWeakRefs);
 826   size_t const num_final_refs = total_count(_discoveredFinalRefs);
 827   size_t const num_total_refs = num_soft_refs + num_weak_refs + num_final_refs;
 828   phase_times-&gt;set_ref_discovered(REF_WEAK, num_weak_refs);
 829   phase_times-&gt;set_ref_discovered(REF_FINAL, num_final_refs);
 830 
 831   phase_times-&gt;set_processing_is_mt(_processing_is_mt);
 832 
 833   if (num_total_refs == 0) {
<span class="line-modified"> 834     log_debug(gc, ref)(&quot;Skipped phase2 of Reference Processing due to unavailable references&quot;);</span>
 835     return;
 836   }
 837 
 838   RefProcMTDegreeAdjuster a(this, RefPhase2, num_total_refs);
 839 
 840   if (_processing_is_mt) {
 841     RefProcBalanceQueuesTimeTracker tt(RefPhase2, phase_times);
 842     maybe_balance_queues(_discoveredSoftRefs);
 843     maybe_balance_queues(_discoveredWeakRefs);
 844     maybe_balance_queues(_discoveredFinalRefs);
 845   }
 846 
 847   RefProcPhaseTimeTracker tt(RefPhase2, phase_times);
 848 
<span class="line-modified"> 849   log_reflist(&quot;Phase2 Soft before&quot;, _discoveredSoftRefs, _max_num_queues);</span>
<span class="line-modified"> 850   log_reflist(&quot;Phase2 Weak before&quot;, _discoveredWeakRefs, _max_num_queues);</span>
<span class="line-modified"> 851   log_reflist(&quot;Phase2 Final before&quot;, _discoveredFinalRefs, _max_num_queues);</span>
 852   if (_processing_is_mt) {
 853     RefProcPhase2Task phase2(*this, phase_times);
 854     task_executor-&gt;execute(phase2, num_queues());
 855   } else {
 856     RefProcWorkerTimeTracker t(phase_times-&gt;phase2_worker_time_sec(), 0);
 857     {
 858       size_t removed = 0;
 859 
 860       RefProcSubPhasesWorkerTimeTracker tt2(SoftRefSubPhase2, phase_times, 0);
 861       for (uint i = 0; i &lt; _max_num_queues; i++) {
 862         removed += process_soft_weak_final_refs_work(_discoveredSoftRefs[i], is_alive, keep_alive, true /* do_enqueue */);
 863       }
 864 
 865       phase_times-&gt;add_ref_cleared(REF_SOFT, removed);
 866     }
 867     {
 868       size_t removed = 0;
 869 
 870       RefProcSubPhasesWorkerTimeTracker tt2(WeakRefSubPhase2, phase_times, 0);
 871       for (uint i = 0; i &lt; _max_num_queues; i++) {
 872         removed += process_soft_weak_final_refs_work(_discoveredWeakRefs[i], is_alive, keep_alive, true /* do_enqueue */);
 873       }
 874 
 875       phase_times-&gt;add_ref_cleared(REF_WEAK, removed);
 876     }
 877     {
 878       size_t removed = 0;
 879 
 880       RefProcSubPhasesWorkerTimeTracker tt2(FinalRefSubPhase2, phase_times, 0);
 881       for (uint i = 0; i &lt; _max_num_queues; i++) {
 882         removed += process_soft_weak_final_refs_work(_discoveredFinalRefs[i], is_alive, keep_alive, false /* do_enqueue */);
 883       }
 884 
 885       phase_times-&gt;add_ref_cleared(REF_FINAL, removed);
 886     }
 887     complete_gc-&gt;do_void();
 888   }
 889   verify_total_count_zero(_discoveredSoftRefs, &quot;SoftReference&quot;);
 890   verify_total_count_zero(_discoveredWeakRefs, &quot;WeakReference&quot;);
<span class="line-modified"> 891   log_reflist(&quot;Phase2 Final after&quot;, _discoveredFinalRefs, _max_num_queues);</span>
 892 }
 893 
 894 void ReferenceProcessor::process_final_keep_alive(OopClosure* keep_alive,
 895                                                   VoidClosure* complete_gc,
 896                                                   AbstractRefProcTaskExecutor*  task_executor,
 897                                                   ReferenceProcessorPhaseTimes* phase_times) {
 898   assert(!_processing_is_mt || task_executor != NULL, &quot;Task executor must not be NULL when mt processing is set.&quot;);
 899 
 900   size_t const num_final_refs = total_count(_discoveredFinalRefs);
 901 
 902   phase_times-&gt;set_processing_is_mt(_processing_is_mt);
 903 
 904   if (num_final_refs == 0) {
<span class="line-modified"> 905     log_debug(gc, ref)(&quot;Skipped phase3 of Reference Processing due to unavailable references&quot;);</span>
 906     return;
 907   }
 908 
 909   RefProcMTDegreeAdjuster a(this, RefPhase3, num_final_refs);
 910 
 911   if (_processing_is_mt) {
 912     RefProcBalanceQueuesTimeTracker tt(RefPhase3, phase_times);
 913     maybe_balance_queues(_discoveredFinalRefs);
 914   }
 915 
 916   // Phase 3:
 917   // . Traverse referents of final references and keep them and followers alive.
 918   RefProcPhaseTimeTracker tt(RefPhase3, phase_times);
 919 
 920   if (_processing_is_mt) {
 921     RefProcPhase3Task phase3(*this, phase_times);
 922     task_executor-&gt;execute(phase3, num_queues());
 923   } else {
 924     RefProcSubPhasesWorkerTimeTracker tt2(FinalRefSubPhase3, phase_times, 0);
 925     for (uint i = 0; i &lt; _max_num_queues; i++) {
 926       process_final_keep_alive_work(_discoveredFinalRefs[i], keep_alive, complete_gc);
 927     }
 928   }
 929   verify_total_count_zero(_discoveredFinalRefs, &quot;FinalReference&quot;);
 930 }
 931 
 932 void ReferenceProcessor::process_phantom_refs(BoolObjectClosure* is_alive,
 933                                               OopClosure* keep_alive,
 934                                               VoidClosure* complete_gc,
 935                                               AbstractRefProcTaskExecutor* task_executor,
 936                                               ReferenceProcessorPhaseTimes* phase_times) {
 937   assert(!_processing_is_mt || task_executor != NULL, &quot;Task executor must not be NULL when mt processing is set.&quot;);
 938 
 939   size_t const num_phantom_refs = total_count(_discoveredPhantomRefs);
 940   phase_times-&gt;set_ref_discovered(REF_PHANTOM, num_phantom_refs);
 941 
 942   phase_times-&gt;set_processing_is_mt(_processing_is_mt);
 943 
 944   if (num_phantom_refs == 0) {
<span class="line-modified"> 945     log_debug(gc, ref)(&quot;Skipped phase4 of Reference Processing due to unavailable references&quot;);</span>
 946     return;
 947   }
 948 
 949   RefProcMTDegreeAdjuster a(this, RefPhase4, num_phantom_refs);
 950 
 951   if (_processing_is_mt) {
 952     RefProcBalanceQueuesTimeTracker tt(RefPhase4, phase_times);
 953     maybe_balance_queues(_discoveredPhantomRefs);
 954   }
 955 
 956   // Phase 4: Walk phantom references appropriately.
 957   RefProcPhaseTimeTracker tt(RefPhase4, phase_times);
 958 
<span class="line-modified"> 959   log_reflist(&quot;Phase4 Phantom before&quot;, _discoveredPhantomRefs, _max_num_queues);</span>
 960   if (_processing_is_mt) {
 961     RefProcPhase4Task phase4(*this, phase_times);
 962     task_executor-&gt;execute(phase4, num_queues());
 963   } else {
 964     size_t removed = 0;
 965 
 966     RefProcSubPhasesWorkerTimeTracker tt(PhantomRefSubPhase4, phase_times, 0);
 967     for (uint i = 0; i &lt; _max_num_queues; i++) {
 968       removed += process_phantom_refs_work(_discoveredPhantomRefs[i], is_alive, keep_alive, complete_gc);
 969     }
 970 
 971     phase_times-&gt;add_ref_cleared(REF_PHANTOM, removed);
 972   }
 973   verify_total_count_zero(_discoveredPhantomRefs, &quot;PhantomReference&quot;);
 974 }
 975 
 976 inline DiscoveredList* ReferenceProcessor::get_discovered_list(ReferenceType rt) {
 977   uint id = 0;
 978   // Determine the queue index to use for this object.
 979   if (_discovery_is_mt) {
</pre>
</td>
<td>
<hr />
<pre>
 765   assert(total_refs == balanced_total_refs, &quot;Balancing was incomplete&quot;);
 766 #endif
 767 }
 768 
 769 bool ReferenceProcessor::is_mt_processing_set_up(AbstractRefProcTaskExecutor* task_executor) const {
 770   return task_executor != NULL &amp;&amp; _processing_is_mt;
 771 }
 772 
 773 void ReferenceProcessor::process_soft_ref_reconsider(BoolObjectClosure* is_alive,
 774                                                      OopClosure* keep_alive,
 775                                                      VoidClosure* complete_gc,
 776                                                      AbstractRefProcTaskExecutor* task_executor,
 777                                                      ReferenceProcessorPhaseTimes* phase_times) {
 778   assert(!_processing_is_mt || task_executor != NULL, &quot;Task executor must not be NULL when mt processing is set.&quot;);
 779 
 780   size_t const num_soft_refs = total_count(_discoveredSoftRefs);
 781   phase_times-&gt;set_ref_discovered(REF_SOFT, num_soft_refs);
 782 
 783   phase_times-&gt;set_processing_is_mt(_processing_is_mt);
 784 
<span class="line-modified"> 785   if (num_soft_refs == 0) {</span>
<span class="line-modified"> 786     log_debug(gc, ref)(&quot;Skipped phase 1 of Reference Processing: no references&quot;);</span>
<span class="line-added"> 787     return;</span>
<span class="line-added"> 788   }</span>
<span class="line-added"> 789 </span>
<span class="line-added"> 790   if (_current_soft_ref_policy == NULL) {</span>
<span class="line-added"> 791     log_debug(gc, ref)(&quot;Skipped phase 1 of Reference Processing: no policy&quot;);</span>
 792     return;
 793   }
 794 
 795   RefProcMTDegreeAdjuster a(this, RefPhase1, num_soft_refs);
 796 
 797   if (_processing_is_mt) {
 798     RefProcBalanceQueuesTimeTracker tt(RefPhase1, phase_times);
 799     maybe_balance_queues(_discoveredSoftRefs);
 800   }
 801 
 802   RefProcPhaseTimeTracker tt(RefPhase1, phase_times);
 803 
<span class="line-modified"> 804   log_reflist(&quot;Phase 1 Soft before&quot;, _discoveredSoftRefs, _max_num_queues);</span>
 805   if (_processing_is_mt) {
 806     RefProcPhase1Task phase1(*this, phase_times, _current_soft_ref_policy);
 807     task_executor-&gt;execute(phase1, num_queues());
 808   } else {
 809     size_t removed = 0;
 810 
 811     RefProcSubPhasesWorkerTimeTracker tt2(SoftRefSubPhase1, phase_times, 0);
 812     for (uint i = 0; i &lt; _max_num_queues; i++) {
 813       removed += process_soft_ref_reconsider_work(_discoveredSoftRefs[i], _current_soft_ref_policy,
 814                                                   is_alive, keep_alive, complete_gc);
 815     }
 816 
 817     phase_times-&gt;add_ref_cleared(REF_SOFT, removed);
 818   }
<span class="line-modified"> 819   log_reflist(&quot;Phase 1 Soft after&quot;, _discoveredSoftRefs, _max_num_queues);</span>
 820 }
 821 
 822 void ReferenceProcessor::process_soft_weak_final_refs(BoolObjectClosure* is_alive,
 823                                                       OopClosure* keep_alive,
 824                                                       VoidClosure* complete_gc,
 825                                                       AbstractRefProcTaskExecutor*  task_executor,
 826                                                       ReferenceProcessorPhaseTimes* phase_times) {
 827   assert(!_processing_is_mt || task_executor != NULL, &quot;Task executor must not be NULL when mt processing is set.&quot;);
 828 
 829   size_t const num_soft_refs = total_count(_discoveredSoftRefs);
 830   size_t const num_weak_refs = total_count(_discoveredWeakRefs);
 831   size_t const num_final_refs = total_count(_discoveredFinalRefs);
 832   size_t const num_total_refs = num_soft_refs + num_weak_refs + num_final_refs;
 833   phase_times-&gt;set_ref_discovered(REF_WEAK, num_weak_refs);
 834   phase_times-&gt;set_ref_discovered(REF_FINAL, num_final_refs);
 835 
 836   phase_times-&gt;set_processing_is_mt(_processing_is_mt);
 837 
 838   if (num_total_refs == 0) {
<span class="line-modified"> 839     log_debug(gc, ref)(&quot;Skipped phase 2 of Reference Processing: no references&quot;);</span>
 840     return;
 841   }
 842 
 843   RefProcMTDegreeAdjuster a(this, RefPhase2, num_total_refs);
 844 
 845   if (_processing_is_mt) {
 846     RefProcBalanceQueuesTimeTracker tt(RefPhase2, phase_times);
 847     maybe_balance_queues(_discoveredSoftRefs);
 848     maybe_balance_queues(_discoveredWeakRefs);
 849     maybe_balance_queues(_discoveredFinalRefs);
 850   }
 851 
 852   RefProcPhaseTimeTracker tt(RefPhase2, phase_times);
 853 
<span class="line-modified"> 854   log_reflist(&quot;Phase 2 Soft before&quot;, _discoveredSoftRefs, _max_num_queues);</span>
<span class="line-modified"> 855   log_reflist(&quot;Phase 2 Weak before&quot;, _discoveredWeakRefs, _max_num_queues);</span>
<span class="line-modified"> 856   log_reflist(&quot;Phase 2 Final before&quot;, _discoveredFinalRefs, _max_num_queues);</span>
 857   if (_processing_is_mt) {
 858     RefProcPhase2Task phase2(*this, phase_times);
 859     task_executor-&gt;execute(phase2, num_queues());
 860   } else {
 861     RefProcWorkerTimeTracker t(phase_times-&gt;phase2_worker_time_sec(), 0);
 862     {
 863       size_t removed = 0;
 864 
 865       RefProcSubPhasesWorkerTimeTracker tt2(SoftRefSubPhase2, phase_times, 0);
 866       for (uint i = 0; i &lt; _max_num_queues; i++) {
 867         removed += process_soft_weak_final_refs_work(_discoveredSoftRefs[i], is_alive, keep_alive, true /* do_enqueue */);
 868       }
 869 
 870       phase_times-&gt;add_ref_cleared(REF_SOFT, removed);
 871     }
 872     {
 873       size_t removed = 0;
 874 
 875       RefProcSubPhasesWorkerTimeTracker tt2(WeakRefSubPhase2, phase_times, 0);
 876       for (uint i = 0; i &lt; _max_num_queues; i++) {
 877         removed += process_soft_weak_final_refs_work(_discoveredWeakRefs[i], is_alive, keep_alive, true /* do_enqueue */);
 878       }
 879 
 880       phase_times-&gt;add_ref_cleared(REF_WEAK, removed);
 881     }
 882     {
 883       size_t removed = 0;
 884 
 885       RefProcSubPhasesWorkerTimeTracker tt2(FinalRefSubPhase2, phase_times, 0);
 886       for (uint i = 0; i &lt; _max_num_queues; i++) {
 887         removed += process_soft_weak_final_refs_work(_discoveredFinalRefs[i], is_alive, keep_alive, false /* do_enqueue */);
 888       }
 889 
 890       phase_times-&gt;add_ref_cleared(REF_FINAL, removed);
 891     }
 892     complete_gc-&gt;do_void();
 893   }
 894   verify_total_count_zero(_discoveredSoftRefs, &quot;SoftReference&quot;);
 895   verify_total_count_zero(_discoveredWeakRefs, &quot;WeakReference&quot;);
<span class="line-modified"> 896   log_reflist(&quot;Phase 2 Final after&quot;, _discoveredFinalRefs, _max_num_queues);</span>
 897 }
 898 
 899 void ReferenceProcessor::process_final_keep_alive(OopClosure* keep_alive,
 900                                                   VoidClosure* complete_gc,
 901                                                   AbstractRefProcTaskExecutor*  task_executor,
 902                                                   ReferenceProcessorPhaseTimes* phase_times) {
 903   assert(!_processing_is_mt || task_executor != NULL, &quot;Task executor must not be NULL when mt processing is set.&quot;);
 904 
 905   size_t const num_final_refs = total_count(_discoveredFinalRefs);
 906 
 907   phase_times-&gt;set_processing_is_mt(_processing_is_mt);
 908 
 909   if (num_final_refs == 0) {
<span class="line-modified"> 910     log_debug(gc, ref)(&quot;Skipped phase 3 of Reference Processing: no references&quot;);</span>
 911     return;
 912   }
 913 
 914   RefProcMTDegreeAdjuster a(this, RefPhase3, num_final_refs);
 915 
 916   if (_processing_is_mt) {
 917     RefProcBalanceQueuesTimeTracker tt(RefPhase3, phase_times);
 918     maybe_balance_queues(_discoveredFinalRefs);
 919   }
 920 
 921   // Phase 3:
 922   // . Traverse referents of final references and keep them and followers alive.
 923   RefProcPhaseTimeTracker tt(RefPhase3, phase_times);
 924 
 925   if (_processing_is_mt) {
 926     RefProcPhase3Task phase3(*this, phase_times);
 927     task_executor-&gt;execute(phase3, num_queues());
 928   } else {
 929     RefProcSubPhasesWorkerTimeTracker tt2(FinalRefSubPhase3, phase_times, 0);
 930     for (uint i = 0; i &lt; _max_num_queues; i++) {
 931       process_final_keep_alive_work(_discoveredFinalRefs[i], keep_alive, complete_gc);
 932     }
 933   }
 934   verify_total_count_zero(_discoveredFinalRefs, &quot;FinalReference&quot;);
 935 }
 936 
 937 void ReferenceProcessor::process_phantom_refs(BoolObjectClosure* is_alive,
 938                                               OopClosure* keep_alive,
 939                                               VoidClosure* complete_gc,
 940                                               AbstractRefProcTaskExecutor* task_executor,
 941                                               ReferenceProcessorPhaseTimes* phase_times) {
 942   assert(!_processing_is_mt || task_executor != NULL, &quot;Task executor must not be NULL when mt processing is set.&quot;);
 943 
 944   size_t const num_phantom_refs = total_count(_discoveredPhantomRefs);
 945   phase_times-&gt;set_ref_discovered(REF_PHANTOM, num_phantom_refs);
 946 
 947   phase_times-&gt;set_processing_is_mt(_processing_is_mt);
 948 
 949   if (num_phantom_refs == 0) {
<span class="line-modified"> 950     log_debug(gc, ref)(&quot;Skipped phase 4 of Reference Processing: no references&quot;);</span>
 951     return;
 952   }
 953 
 954   RefProcMTDegreeAdjuster a(this, RefPhase4, num_phantom_refs);
 955 
 956   if (_processing_is_mt) {
 957     RefProcBalanceQueuesTimeTracker tt(RefPhase4, phase_times);
 958     maybe_balance_queues(_discoveredPhantomRefs);
 959   }
 960 
 961   // Phase 4: Walk phantom references appropriately.
 962   RefProcPhaseTimeTracker tt(RefPhase4, phase_times);
 963 
<span class="line-modified"> 964   log_reflist(&quot;Phase 4 Phantom before&quot;, _discoveredPhantomRefs, _max_num_queues);</span>
 965   if (_processing_is_mt) {
 966     RefProcPhase4Task phase4(*this, phase_times);
 967     task_executor-&gt;execute(phase4, num_queues());
 968   } else {
 969     size_t removed = 0;
 970 
 971     RefProcSubPhasesWorkerTimeTracker tt(PhantomRefSubPhase4, phase_times, 0);
 972     for (uint i = 0; i &lt; _max_num_queues; i++) {
 973       removed += process_phantom_refs_work(_discoveredPhantomRefs[i], is_alive, keep_alive, complete_gc);
 974     }
 975 
 976     phase_times-&gt;add_ref_cleared(REF_PHANTOM, removed);
 977   }
 978   verify_total_count_zero(_discoveredPhantomRefs, &quot;PhantomReference&quot;);
 979 }
 980 
 981 inline DiscoveredList* ReferenceProcessor::get_discovered_list(ReferenceType rt) {
 982   uint id = 0;
 983   // Determine the queue index to use for this object.
 984   if (_discovery_is_mt) {
</pre>
</td>
</tr>
</table>
<center><a href="jvmFlagConstraintsGC.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="threadLocalAllocBuffer.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>