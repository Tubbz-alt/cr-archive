<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/gc/shenandoah/shenandoahConcurrentMark.inline.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
    <script type="text/javascript" src="../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (c) 2015, 2019, Red Hat, Inc. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_GC_SHENANDOAH_SHENANDOAHCONCURRENTMARK_INLINE_HPP
 26 #define SHARE_GC_SHENANDOAH_SHENANDOAHCONCURRENTMARK_INLINE_HPP
 27 
 28 #include &quot;gc/shenandoah/shenandoahAsserts.hpp&quot;
 29 #include &quot;gc/shenandoah/shenandoahBarrierSet.inline.hpp&quot;
 30 #include &quot;gc/shenandoah/shenandoahConcurrentMark.hpp&quot;
 31 #include &quot;gc/shenandoah/shenandoahMarkingContext.inline.hpp&quot;
 32 #include &quot;gc/shenandoah/shenandoahStringDedup.inline.hpp&quot;
 33 #include &quot;gc/shenandoah/shenandoahTaskqueue.inline.hpp&quot;
 34 #include &quot;memory/iterator.inline.hpp&quot;
 35 #include &quot;oops/compressedOops.inline.hpp&quot;
 36 #include &quot;oops/oop.inline.hpp&quot;
 37 #include &quot;runtime/prefetch.inline.hpp&quot;
 38 
 39 template &lt;class T&gt;
<a name="1" id="anc1"></a><span class="line-modified"> 40 void ShenandoahConcurrentMark::do_task(ShenandoahObjToScanQueue* q, T* cl, jushort* live_data, ShenandoahMarkTask* task) {</span>
 41   oop obj = task-&gt;obj();
 42 
<a name="2" id="anc2"></a><span class="line-modified"> 43   shenandoah_assert_not_forwarded_except(NULL, obj, _heap-&gt;is_concurrent_traversal_in_progress() &amp;&amp; _heap-&gt;cancelled_gc());</span>
 44   shenandoah_assert_marked(NULL, obj);
 45   shenandoah_assert_not_in_cset_except(NULL, obj, _heap-&gt;cancelled_gc());
 46 
 47   if (task-&gt;is_not_chunked()) {
 48     if (obj-&gt;is_instance()) {
 49       // Case 1: Normal oop, process as usual.
 50       obj-&gt;oop_iterate(cl);
 51     } else if (obj-&gt;is_objArray()) {
 52       // Case 2: Object array instance and no chunk is set. Must be the first
 53       // time we visit it, start the chunked processing.
 54       do_chunked_array_start&lt;T&gt;(q, cl, obj);
 55     } else {
 56       // Case 3: Primitive array. Do nothing, no oops there. We use the same
 57       // performance tweak TypeArrayKlass::oop_oop_iterate_impl is using:
 58       // We skip iterating over the klass pointer since we know that
 59       // Universe::TypeArrayKlass never moves.
 60       assert (obj-&gt;is_typeArray(), &quot;should be type array&quot;);
 61     }
 62     // Count liveness the last: push the outstanding work to the queues first
 63     count_liveness(live_data, obj);
 64   } else {
 65     // Case 4: Array chunk, has sensible chunk id. Process it.
 66     do_chunked_array&lt;T&gt;(q, cl, obj, task-&gt;chunk(), task-&gt;pow());
 67   }
 68 }
 69 
<a name="3" id="anc3"></a><span class="line-modified"> 70 inline void ShenandoahConcurrentMark::count_liveness(jushort* live_data, oop obj) {</span>
 71   size_t region_idx = _heap-&gt;heap_region_index_containing(obj);
 72   ShenandoahHeapRegion* region = _heap-&gt;get_region(region_idx);
 73   size_t size = obj-&gt;size();
 74 
 75   if (!region-&gt;is_humongous_start()) {
 76     assert(!region-&gt;is_humongous(), &quot;Cannot have continuations here&quot;);
<a name="4" id="anc4"></a><span class="line-modified"> 77     size_t max = (1 &lt;&lt; (sizeof(jushort) * 8)) - 1;</span>
<span class="line-modified"> 78     if (size &gt;= max) {</span>
<span class="line-modified"> 79       // too big, add to region data directly</span>
<span class="line-modified"> 80       region-&gt;increase_live_data_gc_words(size);</span>


 81     } else {
<a name="5" id="anc5"></a><span class="line-modified"> 82       jushort cur = live_data[region_idx];</span>
<span class="line-modified"> 83       size_t new_val = cur + size;</span>
<span class="line-removed"> 84       if (new_val &gt;= max) {</span>
<span class="line-removed"> 85         // overflow, flush to region data</span>
<span class="line-removed"> 86         region-&gt;increase_live_data_gc_words(new_val);</span>
<span class="line-removed"> 87         live_data[region_idx] = 0;</span>
<span class="line-removed"> 88       } else {</span>
<span class="line-removed"> 89         // still good, remember in locals</span>
<span class="line-removed"> 90         live_data[region_idx] = (jushort) new_val;</span>
<span class="line-removed"> 91       }</span>
 92     }
 93   } else {
 94     shenandoah_assert_in_correct_region(NULL, obj);
 95     size_t num_regions = ShenandoahHeapRegion::required_regions(size * HeapWordSize);
 96 
 97     for (size_t i = region_idx; i &lt; region_idx + num_regions; i++) {
 98       ShenandoahHeapRegion* chain_reg = _heap-&gt;get_region(i);
 99       assert(chain_reg-&gt;is_humongous(), &quot;Expecting a humongous region&quot;);
100       chain_reg-&gt;increase_live_data_gc_words(chain_reg-&gt;used() &gt;&gt; LogHeapWordSize);
101     }
102   }
103 }
104 
105 template &lt;class T&gt;
106 inline void ShenandoahConcurrentMark::do_chunked_array_start(ShenandoahObjToScanQueue* q, T* cl, oop obj) {
107   assert(obj-&gt;is_objArray(), &quot;expect object array&quot;);
108   objArrayOop array = objArrayOop(obj);
109   int len = array-&gt;length();
110 
111   if (len &lt;= (int) ObjArrayMarkingStride*2) {
112     // A few slices only, process directly
113     array-&gt;oop_iterate_range(cl, 0, len);
114   } else {
115     int bits = log2_long((size_t) len);
116     // Compensate for non-power-of-two arrays, cover the array in excess:
117     if (len != (1 &lt;&lt; bits)) bits++;
118 
119     // Only allow full chunks on the queue. This frees do_chunked_array() from checking from/to
120     // boundaries against array-&gt;length(), touching the array header on every chunk.
121     //
122     // To do this, we cut the prefix in full-sized chunks, and submit them on the queue.
123     // If the array is not divided in chunk sizes, then there would be an irregular tail,
124     // which we will process separately.
125 
126     int last_idx = 0;
127 
128     int chunk = 1;
129     int pow = bits;
130 
131     // Handle overflow
132     if (pow &gt;= 31) {
133       assert (pow == 31, &quot;sanity&quot;);
134       pow--;
135       chunk = 2;
136       last_idx = (1 &lt;&lt; pow);
137       bool pushed = q-&gt;push(ShenandoahMarkTask(array, 1, pow));
138       assert(pushed, &quot;overflow queue should always succeed pushing&quot;);
139     }
140 
141     // Split out tasks, as suggested in ObjArrayChunkedTask docs. Record the last
142     // successful right boundary to figure out the irregular tail.
143     while ((1 &lt;&lt; pow) &gt; (int)ObjArrayMarkingStride &amp;&amp;
144            (chunk*2 &lt; ShenandoahMarkTask::chunk_size())) {
145       pow--;
146       int left_chunk = chunk*2 - 1;
147       int right_chunk = chunk*2;
148       int left_chunk_end = left_chunk * (1 &lt;&lt; pow);
149       if (left_chunk_end &lt; len) {
150         bool pushed = q-&gt;push(ShenandoahMarkTask(array, left_chunk, pow));
151         assert(pushed, &quot;overflow queue should always succeed pushing&quot;);
152         chunk = right_chunk;
153         last_idx = left_chunk_end;
154       } else {
155         chunk = left_chunk;
156       }
157     }
158 
159     // Process the irregular tail, if present
160     int from = last_idx;
161     if (from &lt; len) {
162       array-&gt;oop_iterate_range(cl, from, len);
163     }
164   }
165 }
166 
167 template &lt;class T&gt;
168 inline void ShenandoahConcurrentMark::do_chunked_array(ShenandoahObjToScanQueue* q, T* cl, oop obj, int chunk, int pow) {
169   assert(obj-&gt;is_objArray(), &quot;expect object array&quot;);
170   objArrayOop array = objArrayOop(obj);
171 
172   assert (ObjArrayMarkingStride &gt; 0, &quot;sanity&quot;);
173 
174   // Split out tasks, as suggested in ObjArrayChunkedTask docs. Avoid pushing tasks that
175   // are known to start beyond the array.
176   while ((1 &lt;&lt; pow) &gt; (int)ObjArrayMarkingStride &amp;&amp; (chunk*2 &lt; ShenandoahMarkTask::chunk_size())) {
177     pow--;
178     chunk *= 2;
179     bool pushed = q-&gt;push(ShenandoahMarkTask(array, chunk - 1, pow));
180     assert(pushed, &quot;overflow queue should always succeed pushing&quot;);
181   }
182 
183   int chunk_size = 1 &lt;&lt; pow;
184 
185   int from = (chunk - 1) * chunk_size;
186   int to = chunk * chunk_size;
187 
188 #ifdef ASSERT
189   int len = array-&gt;length();
190   assert (0 &lt;= from &amp;&amp; from &lt; len, &quot;from is sane: %d/%d&quot;, from, len);
191   assert (0 &lt; to &amp;&amp; to &lt;= len, &quot;to is sane: %d/%d&quot;, to, len);
192 #endif
193 
194   array-&gt;oop_iterate_range(cl, from, to);
195 }
196 
197 class ShenandoahSATBBufferClosure : public SATBBufferClosure {
198 private:
199   ShenandoahObjToScanQueue* _queue;
200   ShenandoahHeap* _heap;
201   ShenandoahMarkingContext* const _mark_context;
202 public:
203   ShenandoahSATBBufferClosure(ShenandoahObjToScanQueue* q) :
204     _queue(q),
205     _heap(ShenandoahHeap::heap()),
206     _mark_context(_heap-&gt;marking_context())
207   {
208   }
209 
210   void do_buffer(void **buffer, size_t size) {
211     if (_heap-&gt;has_forwarded_objects()) {
212       if (ShenandoahStringDedup::is_enabled()) {
213         do_buffer_impl&lt;RESOLVE, ENQUEUE_DEDUP&gt;(buffer, size);
214       } else {
215         do_buffer_impl&lt;RESOLVE, NO_DEDUP&gt;(buffer, size);
216       }
217     } else {
218       if (ShenandoahStringDedup::is_enabled()) {
219         do_buffer_impl&lt;NONE, ENQUEUE_DEDUP&gt;(buffer, size);
220       } else {
221         do_buffer_impl&lt;NONE, NO_DEDUP&gt;(buffer, size);
222       }
223     }
224   }
225 
226   template&lt;UpdateRefsMode UPDATE_REFS, StringDedupMode STRING_DEDUP&gt;
227   void do_buffer_impl(void **buffer, size_t size) {
228     for (size_t i = 0; i &lt; size; ++i) {
229       oop *p = (oop *) &amp;buffer[i];
230       ShenandoahConcurrentMark::mark_through_ref&lt;oop, UPDATE_REFS, STRING_DEDUP&gt;(p, _heap, _queue, _mark_context);
231     }
232   }
233 };
234 
235 template&lt;class T, UpdateRefsMode UPDATE_REFS, StringDedupMode STRING_DEDUP&gt;
236 inline void ShenandoahConcurrentMark::mark_through_ref(T *p, ShenandoahHeap* heap, ShenandoahObjToScanQueue* q, ShenandoahMarkingContext* const mark_context) {
237   T o = RawAccess&lt;&gt;::oop_load(p);
238   if (!CompressedOops::is_null(o)) {
239     oop obj = CompressedOops::decode_not_null(o);
240     switch (UPDATE_REFS) {
241     case NONE:
242       break;
243     case RESOLVE:
244       obj = ShenandoahBarrierSet::resolve_forwarded_not_null(obj);
245       break;
246     case SIMPLE:
247       // We piggy-back reference updating to the marking tasks.
248       obj = heap-&gt;update_with_forwarded_not_null(p, obj);
249       break;
250     case CONCURRENT:
251       obj = heap-&gt;maybe_update_with_forwarded_not_null(p, obj);
252       break;
253     default:
254       ShouldNotReachHere();
255     }
256 
257     // Note: Only when concurrently updating references can obj be different
258     // (that is, really different, not just different from-/to-space copies of the same)
259     // from the one we originally loaded. Mutator thread can beat us by writing something
260     // else into the location. In that case, we would mark through that updated value,
261     // on the off-chance it is not handled by other means (e.g. via SATB). However,
262     // if that write was NULL, we don&#39;t need to do anything else.
263     if (UPDATE_REFS != CONCURRENT || !CompressedOops::is_null(obj)) {
264       shenandoah_assert_not_forwarded(p, obj);
265       shenandoah_assert_not_in_cset_except(p, obj, heap-&gt;cancelled_gc());
266 
267       if (mark_context-&gt;mark(obj)) {
268         bool pushed = q-&gt;push(ShenandoahMarkTask(obj));
269         assert(pushed, &quot;overflow queue should always succeed pushing&quot;);
270 
271         if ((STRING_DEDUP == ENQUEUE_DEDUP) &amp;&amp; ShenandoahStringDedup::is_candidate(obj)) {
272           assert(ShenandoahStringDedup::is_enabled(), &quot;Must be enabled&quot;);
273           ShenandoahStringDedup::enqueue_candidate(obj);
274         }
275       }
276 
277       shenandoah_assert_marked(p, obj);
278     }
279   }
280 }
281 
282 #endif // SHARE_GC_SHENANDOAH_SHENANDOAHCONCURRENTMARK_INLINE_HPP
<a name="6" id="anc6"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="6" type="hidden" />
</body>
</html>