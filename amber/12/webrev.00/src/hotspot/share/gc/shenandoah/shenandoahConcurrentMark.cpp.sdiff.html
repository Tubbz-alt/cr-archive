<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/shenandoah/shenandoahConcurrentMark.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="shenandoahCollectionSet.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahConcurrentMark.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shenandoah/shenandoahConcurrentMark.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 
 27 #include &quot;classfile/symbolTable.hpp&quot;
 28 #include &quot;classfile/systemDictionary.hpp&quot;
 29 #include &quot;code/codeCache.hpp&quot;
 30 
 31 #include &quot;gc/shared/weakProcessor.inline.hpp&quot;
 32 #include &quot;gc/shared/gcTimer.hpp&quot;

 33 #include &quot;gc/shared/referenceProcessor.hpp&quot;
 34 #include &quot;gc/shared/referenceProcessorPhaseTimes.hpp&quot;
 35 #include &quot;gc/shared/strongRootsScope.hpp&quot;
 36 
 37 #include &quot;gc/shenandoah/shenandoahBarrierSet.inline.hpp&quot;
 38 #include &quot;gc/shenandoah/shenandoahClosures.inline.hpp&quot;
 39 #include &quot;gc/shenandoah/shenandoahConcurrentMark.inline.hpp&quot;
 40 #include &quot;gc/shenandoah/shenandoahMarkCompact.hpp&quot;
 41 #include &quot;gc/shenandoah/shenandoahHeap.inline.hpp&quot;
 42 #include &quot;gc/shenandoah/shenandoahRootProcessor.inline.hpp&quot;
 43 #include &quot;gc/shenandoah/shenandoahOopClosures.inline.hpp&quot;

 44 #include &quot;gc/shenandoah/shenandoahTaskqueue.inline.hpp&quot;
<span class="line-removed"> 45 #include &quot;gc/shenandoah/shenandoahTimingTracker.hpp&quot;</span>
 46 #include &quot;gc/shenandoah/shenandoahUtils.hpp&quot;
 47 
 48 #include &quot;memory/iterator.inline.hpp&quot;
 49 #include &quot;memory/metaspace.hpp&quot;
 50 #include &quot;memory/resourceArea.hpp&quot;
 51 #include &quot;oops/oop.inline.hpp&quot;
 52 #include &quot;runtime/handles.inline.hpp&quot;
 53 
 54 template&lt;UpdateRefsMode UPDATE_REFS&gt;
 55 class ShenandoahInitMarkRootsClosure : public OopClosure {
 56 private:
 57   ShenandoahObjToScanQueue* _queue;
 58   ShenandoahHeap* _heap;
 59   ShenandoahMarkingContext* const _mark_context;
 60 
 61   template &lt;class T&gt;
 62   inline void do_oop_work(T* p) {
 63     ShenandoahConcurrentMark::mark_through_ref&lt;T, UPDATE_REFS, NO_DEDUP&gt;(p, _heap, _queue, _mark_context);
 64   }
 65 
</pre>
<hr />
<pre>
 67   ShenandoahInitMarkRootsClosure(ShenandoahObjToScanQueue* q) :
 68     _queue(q),
 69     _heap(ShenandoahHeap::heap()),
 70     _mark_context(_heap-&gt;marking_context()) {};
 71 
 72   void do_oop(narrowOop* p) { do_oop_work(p); }
 73   void do_oop(oop* p)       { do_oop_work(p); }
 74 };
 75 
 76 ShenandoahMarkRefsSuperClosure::ShenandoahMarkRefsSuperClosure(ShenandoahObjToScanQueue* q, ReferenceProcessor* rp) :
 77   MetadataVisitingOopIterateClosure(rp),
 78   _queue(q),
 79   _heap(ShenandoahHeap::heap()),
 80   _mark_context(_heap-&gt;marking_context())
 81 { }
 82 
 83 template&lt;UpdateRefsMode UPDATE_REFS&gt;
 84 class ShenandoahInitMarkRootsTask : public AbstractGangTask {
 85 private:
 86   ShenandoahAllRootScanner* _rp;
<span class="line-removed"> 87   bool _process_refs;</span>
 88 public:
<span class="line-modified"> 89   ShenandoahInitMarkRootsTask(ShenandoahAllRootScanner* rp, bool process_refs) :</span>
 90     AbstractGangTask(&quot;Shenandoah init mark roots task&quot;),
<span class="line-modified"> 91     _rp(rp),</span>
<span class="line-removed"> 92     _process_refs(process_refs) {</span>
 93   }
 94 
 95   void work(uint worker_id) {
 96     assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Must be at a safepoint&quot;);
 97     ShenandoahParallelWorkerSession worker_session(worker_id);
 98 
 99     ShenandoahHeap* heap = ShenandoahHeap::heap();
100     ShenandoahObjToScanQueueSet* queues = heap-&gt;concurrent_mark()-&gt;task_queues();
101     assert(queues-&gt;get_reserved() &gt; worker_id, &quot;Queue has not been reserved for worker id: %d&quot;, worker_id);
102 
103     ShenandoahObjToScanQueue* q = queues-&gt;queue(worker_id);
104 
105     ShenandoahInitMarkRootsClosure&lt;UPDATE_REFS&gt; mark_cl(q);
106     do_work(heap, &amp;mark_cl, worker_id);
107   }
108 
109 private:
110   void do_work(ShenandoahHeap* heap, OopClosure* oops, uint worker_id) {
111     // The rationale for selecting the roots to scan is as follows:
112     //   a. With unload_classes = true, we only want to scan the actual strong roots from the
</pre>
<hr />
<pre>
165   void work(uint worker_id) {
166     ShenandoahHeap* heap = ShenandoahHeap::heap();
167     ShenandoahConcurrentWorkerSession worker_session(worker_id);
168     ShenandoahSuspendibleThreadSetJoiner stsj(ShenandoahSuspendibleWorkers);
169     ShenandoahObjToScanQueue* q = _cm-&gt;get_queue(worker_id);
170     ReferenceProcessor* rp;
171     if (heap-&gt;process_references()) {
172       rp = heap-&gt;ref_processor();
173       shenandoah_assert_rp_isalive_installed();
174     } else {
175       rp = NULL;
176     }
177 
178     _cm-&gt;concurrent_scan_code_roots(worker_id, rp);
179     _cm-&gt;mark_loop(worker_id, _terminator, rp,
180                    true, // cancellable
181                    ShenandoahStringDedup::is_enabled()); // perform string dedup
182   }
183 };
184 
<span class="line-modified">185 class ShenandoahSATBThreadsClosure : public ThreadClosure {</span>
186 private:
187   ShenandoahSATBBufferClosure* _satb_cl;


188   uintx _claim_token;
189 
190 public:
<span class="line-modified">191   ShenandoahSATBThreadsClosure(ShenandoahSATBBufferClosure* satb_cl) :</span>
<span class="line-modified">192     _satb_cl(satb_cl),</span>
193     _claim_token(Threads::thread_claim_token()) {}
194 
195   void do_thread(Thread* thread) {
196     if (thread-&gt;claim_threads_do(true, _claim_token)) {
197       ShenandoahThreadLocalData::satb_mark_queue(thread).apply_closure_and_empty(_satb_cl);















198     }
199   }
200 };
201 
202 class ShenandoahFinalMarkingTask : public AbstractGangTask {
203 private:
204   ShenandoahConcurrentMark* _cm;
205   TaskTerminator*           _terminator;
206   bool _dedup_string;
207 
208 public:
209   ShenandoahFinalMarkingTask(ShenandoahConcurrentMark* cm, TaskTerminator* terminator, bool dedup_string) :
210     AbstractGangTask(&quot;Shenandoah Final Marking&quot;), _cm(cm), _terminator(terminator), _dedup_string(dedup_string) {
211   }
212 
213   void work(uint worker_id) {
214     ShenandoahHeap* heap = ShenandoahHeap::heap();
215 
216     ShenandoahParallelWorkerSession worker_session(worker_id);








217     // First drain remaining SATB buffers.
218     // Notice that this is not strictly necessary for mark-compact. But since
219     // it requires a StrongRootsScope around the task, we need to claim the
220     // threads, and performance-wise it doesn&#39;t really matter. Adds about 1ms to
221     // full-gc.
222     {
223       ShenandoahObjToScanQueue* q = _cm-&gt;get_queue(worker_id);

224       ShenandoahSATBBufferClosure cl(q);
225       SATBMarkQueueSet&amp; satb_mq_set = ShenandoahBarrierSet::satb_mark_queue_set();
226       while (satb_mq_set.apply_closure_to_completed_buffer(&amp;cl));
<span class="line-modified">227       ShenandoahSATBThreadsClosure tc(&amp;cl);</span>
<span class="line-modified">228       Threads::threads_do(&amp;tc);</span>
<span class="line-modified">229     }</span>
<span class="line-modified">230 </span>
<span class="line-modified">231     ReferenceProcessor* rp;</span>
<span class="line-modified">232     if (heap-&gt;process_references()) {</span>
<span class="line-modified">233       rp = heap-&gt;ref_processor();</span>
<span class="line-modified">234       shenandoah_assert_rp_isalive_installed();</span>
<span class="line-modified">235     } else {</span>
<span class="line-modified">236       rp = NULL;</span>






237     }
238 
239     if (heap-&gt;is_degenerated_gc_in_progress()) {
240       // Degenerated cycle may bypass concurrent cycle, so code roots might not be scanned,
241       // let&#39;s check here.
242       _cm-&gt;concurrent_scan_code_roots(worker_id, rp);
243     }
244 
245     _cm-&gt;mark_loop(worker_id, _terminator, rp,
246                    false, // not cancellable
247                    _dedup_string);
248 
249     assert(_cm-&gt;task_queues()-&gt;is_empty(), &quot;Should be empty&quot;);
250   }
251 };
252 
253 void ShenandoahConcurrentMark::mark_roots(ShenandoahPhaseTimings::Phase root_phase) {
254   assert(Thread::current()-&gt;is_VM_thread(), &quot;can only do this in VMThread&quot;);
255   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Must be at a safepoint&quot;);
256 
257   ShenandoahHeap* heap = ShenandoahHeap::heap();
258 
259   ShenandoahGCPhase phase(root_phase);
260 
261   WorkGang* workers = heap-&gt;workers();
262   uint nworkers = workers-&gt;active_workers();
263 
264   assert(nworkers &lt;= task_queues()-&gt;size(), &quot;Just check&quot;);
265 
266   ShenandoahAllRootScanner root_proc(nworkers, root_phase);
267   TASKQUEUE_STATS_ONLY(task_queues()-&gt;reset_taskqueue_stats());
268   task_queues()-&gt;reserve(nworkers);
269 
270   if (heap-&gt;has_forwarded_objects()) {
<span class="line-modified">271     ShenandoahInitMarkRootsTask&lt;RESOLVE&gt; mark_roots(&amp;root_proc, _heap-&gt;process_references());</span>
272     workers-&gt;run_task(&amp;mark_roots);
273   } else {
274     // No need to update references, which means the heap is stable.
275     // Can save time not walking through forwarding pointers.
<span class="line-modified">276     ShenandoahInitMarkRootsTask&lt;NONE&gt; mark_roots(&amp;root_proc, _heap-&gt;process_references());</span>
277     workers-&gt;run_task(&amp;mark_roots);
278   }
279 
280   if (ShenandoahConcurrentScanCodeRoots) {
281     clear_claim_codecache();
282   }
283 }
284 
285 void ShenandoahConcurrentMark::update_roots(ShenandoahPhaseTimings::Phase root_phase) {
286   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Must be at a safepoint&quot;);
287   assert(root_phase == ShenandoahPhaseTimings::full_gc_roots ||
288          root_phase == ShenandoahPhaseTimings::degen_gc_update_roots,
289          &quot;Only for these phases&quot;);
290 
291   ShenandoahGCPhase phase(root_phase);
292 
293   bool check_alive = root_phase == ShenandoahPhaseTimings::degen_gc_update_roots;
294 
295 #if COMPILER2_OR_JVMCI
296   DerivedPointerTable::clear();
297 #endif
298 
299   uint nworkers = _heap-&gt;workers()-&gt;active_workers();
300 
301   ShenandoahRootUpdater root_updater(nworkers, root_phase);
302   ShenandoahUpdateRootsTask update_roots(&amp;root_updater, check_alive);
303   _heap-&gt;workers()-&gt;run_task(&amp;update_roots);
304 
305 #if COMPILER2_OR_JVMCI
306   DerivedPointerTable::update_pointers();
307 #endif
308 }
309 
310 class ShenandoahUpdateThreadRootsTask : public AbstractGangTask {
311 private:
312   ShenandoahThreadRoots           _thread_roots;
313   ShenandoahPhaseTimings::Phase   _phase;

314 public:
315   ShenandoahUpdateThreadRootsTask(bool is_par, ShenandoahPhaseTimings::Phase phase) :
316     AbstractGangTask(&quot;Shenandoah Update Thread Roots&quot;),
317     _thread_roots(is_par),
<span class="line-modified">318     _phase(phase) {</span>
<span class="line-modified">319     ShenandoahHeap::heap()-&gt;phase_timings()-&gt;record_workers_start(_phase);</span>
<span class="line-removed">320   }</span>
321 
<span class="line-removed">322   ~ShenandoahUpdateThreadRootsTask() {</span>
<span class="line-removed">323     ShenandoahHeap::heap()-&gt;phase_timings()-&gt;record_workers_end(_phase);</span>
<span class="line-removed">324   }</span>
325   void work(uint worker_id) {
326     ShenandoahUpdateRefsClosure cl;
327     _thread_roots.oops_do(&amp;cl, NULL, worker_id);
328   }
329 };
330 
331 void ShenandoahConcurrentMark::update_thread_roots(ShenandoahPhaseTimings::Phase root_phase) {
332   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Must be at a safepoint&quot;);
333 
334   ShenandoahGCPhase phase(root_phase);
335 
336 #if COMPILER2_OR_JVMCI
337   DerivedPointerTable::clear();
338 #endif
339 
340   WorkGang* workers = _heap-&gt;workers();
341   bool is_par = workers-&gt;active_workers() &gt; 1;
342 
343   ShenandoahUpdateThreadRootsTask task(is_par, root_phase);
344   workers-&gt;run_task(&amp;task);
</pre>
<hr />
<pre>
643 
644   assert(task_queues()-&gt;is_empty(), &quot;Should be empty&quot;);
645 
646   // complete_gc and keep_alive closures instantiated here are only needed for
647   // single-threaded path in RP. They share the queue 0 for tracking work, which
648   // simplifies implementation. Since RP may decide to call complete_gc several
649   // times, we need to be able to reuse the terminator.
650   uint serial_worker_id = 0;
651   TaskTerminator terminator(1, task_queues());
652   ShenandoahCMDrainMarkingStackClosure complete_gc(serial_worker_id, &amp;terminator, /* reset_terminator = */ true);
653 
654   ShenandoahRefProcTaskExecutor executor(workers);
655 
656   ReferenceProcessorPhaseTimes pt(_heap-&gt;gc_timer(), rp-&gt;num_queues());
657 
658   {
659     ShenandoahGCPhase phase(phase_process);
660 
661     if (_heap-&gt;has_forwarded_objects()) {
662       ShenandoahCMKeepAliveUpdateClosure keep_alive(get_queue(serial_worker_id));
<span class="line-modified">663       rp-&gt;process_discovered_references(is_alive.is_alive_closure(), &amp;keep_alive,</span>
<span class="line-modified">664                                         &amp;complete_gc, &amp;executor,</span>
<span class="line-modified">665                                         &amp;pt);</span>
<span class="line-modified">666 </span>

667     } else {
668       ShenandoahCMKeepAliveClosure keep_alive(get_queue(serial_worker_id));
<span class="line-modified">669       rp-&gt;process_discovered_references(is_alive.is_alive_closure(), &amp;keep_alive,</span>
<span class="line-modified">670                                         &amp;complete_gc, &amp;executor,</span>
<span class="line-modified">671                                         &amp;pt);</span>
<span class="line-modified">672 </span>

673     }
674 
675     pt.print_all_references();
676 
677     assert(task_queues()-&gt;is_empty(), &quot;Should be empty&quot;);
678   }
679 }
680 
681 class ShenandoahCancelledGCYieldClosure : public YieldClosure {
682 private:
683   ShenandoahHeap* const _heap;
684 public:
685   ShenandoahCancelledGCYieldClosure() : _heap(ShenandoahHeap::heap()) {};
686   virtual bool should_return() { return _heap-&gt;cancelled_gc(); }
687 };
688 
689 class ShenandoahPrecleanCompleteGCClosure : public VoidClosure {
690 public:
691   void do_void() {
692     ShenandoahHeap* sh = ShenandoahHeap::heap();
693     ShenandoahConcurrentMark* scm = sh-&gt;concurrent_mark();
694     assert(sh-&gt;process_references(), &quot;why else would we be here?&quot;);
695     TaskTerminator terminator(1, scm-&gt;task_queues());
696 
697     ReferenceProcessor* rp = sh-&gt;ref_processor();
698     shenandoah_assert_rp_isalive_installed();
699 
700     scm-&gt;mark_loop(0, &amp;terminator, rp,
701                    false, // not cancellable
702                    false); // do not do strdedup
703   }
704 };
705 
<span class="line-removed">706 class ShenandoahPrecleanKeepAliveUpdateClosure : public OopClosure {</span>
<span class="line-removed">707 private:</span>
<span class="line-removed">708   ShenandoahObjToScanQueue* _queue;</span>
<span class="line-removed">709   ShenandoahHeap* _heap;</span>
<span class="line-removed">710   ShenandoahMarkingContext* const _mark_context;</span>
<span class="line-removed">711 </span>
<span class="line-removed">712   template &lt;class T&gt;</span>
<span class="line-removed">713   inline void do_oop_work(T* p) {</span>
<span class="line-removed">714     ShenandoahConcurrentMark::mark_through_ref&lt;T, CONCURRENT, NO_DEDUP&gt;(p, _heap, _queue, _mark_context);</span>
<span class="line-removed">715   }</span>
<span class="line-removed">716 </span>
<span class="line-removed">717 public:</span>
<span class="line-removed">718   ShenandoahPrecleanKeepAliveUpdateClosure(ShenandoahObjToScanQueue* q) :</span>
<span class="line-removed">719     _queue(q),</span>
<span class="line-removed">720     _heap(ShenandoahHeap::heap()),</span>
<span class="line-removed">721     _mark_context(_heap-&gt;marking_context()) {}</span>
<span class="line-removed">722 </span>
<span class="line-removed">723   void do_oop(narrowOop* p) { do_oop_work(p); }</span>
<span class="line-removed">724   void do_oop(oop* p)       { do_oop_work(p); }</span>
<span class="line-removed">725 };</span>
<span class="line-removed">726 </span>
727 class ShenandoahPrecleanTask : public AbstractGangTask {
728 private:
729   ReferenceProcessor* _rp;
730 
731 public:
732   ShenandoahPrecleanTask(ReferenceProcessor* rp) :
733           AbstractGangTask(&quot;Precleaning task&quot;),
734           _rp(rp) {}
735 
736   void work(uint worker_id) {
737     assert(worker_id == 0, &quot;The code below is single-threaded, only one worker is expected&quot;);
738     ShenandoahParallelWorkerSession worker_session(worker_id);
739 
740     ShenandoahHeap* sh = ShenandoahHeap::heap();

741 
742     ShenandoahObjToScanQueue* q = sh-&gt;concurrent_mark()-&gt;get_queue(worker_id);
743 
744     ShenandoahCancelledGCYieldClosure yield;
745     ShenandoahPrecleanCompleteGCClosure complete_gc;
746 
<span class="line-modified">747     if (sh-&gt;has_forwarded_objects()) {</span>
<span class="line-modified">748       ShenandoahForwardedIsAliveClosure is_alive;</span>
<span class="line-modified">749       ShenandoahPrecleanKeepAliveUpdateClosure keep_alive(q);</span>
<span class="line-modified">750       ResourceMark rm;</span>
<span class="line-modified">751       _rp-&gt;preclean_discovered_references(&amp;is_alive, &amp;keep_alive,</span>
<span class="line-modified">752                                           &amp;complete_gc, &amp;yield,</span>
<span class="line-removed">753                                           NULL);</span>
<span class="line-removed">754     } else {</span>
<span class="line-removed">755       ShenandoahIsAliveClosure is_alive;</span>
<span class="line-removed">756       ShenandoahCMKeepAliveClosure keep_alive(q);</span>
<span class="line-removed">757       ResourceMark rm;</span>
<span class="line-removed">758       _rp-&gt;preclean_discovered_references(&amp;is_alive, &amp;keep_alive,</span>
<span class="line-removed">759                                           &amp;complete_gc, &amp;yield,</span>
<span class="line-removed">760                                           NULL);</span>
<span class="line-removed">761     }</span>
762   }
763 };
764 
765 void ShenandoahConcurrentMark::preclean_weak_refs() {
766   // Pre-cleaning weak references before diving into STW makes sense at the
767   // end of concurrent mark. This will filter out the references which referents
768   // are alive. Note that ReferenceProcessor already filters out these on reference
769   // discovery, and the bulk of work is done here. This phase processes leftovers
770   // that missed the initial filtering, i.e. when referent was marked alive after
771   // reference was discovered by RP.
772 
773   assert(_heap-&gt;process_references(), &quot;sanity&quot;);
774 
775   // Shortcut if no references were discovered to avoid winding up threads.
776   ReferenceProcessor* rp = _heap-&gt;ref_processor();
777   if (!rp-&gt;has_discovered_references()) {
778     return;
779   }
780 
781   assert(task_queues()-&gt;is_empty(), &quot;Should be empty&quot;);
</pre>
<hr />
<pre>
802 
803 void ShenandoahConcurrentMark::cancel() {
804   // Clean up marking stacks.
805   ShenandoahObjToScanQueueSet* queues = task_queues();
806   queues-&gt;clear();
807 
808   // Cancel SATB buffers.
809   ShenandoahBarrierSet::satb_mark_queue_set().abandon_partial_marking();
810 }
811 
812 ShenandoahObjToScanQueue* ShenandoahConcurrentMark::get_queue(uint worker_id) {
813   assert(task_queues()-&gt;get_reserved() &gt; worker_id, &quot;No reserved queue for worker id: %d&quot;, worker_id);
814   return _task_queues-&gt;queue(worker_id);
815 }
816 
817 template &lt;bool CANCELLABLE&gt;
818 void ShenandoahConcurrentMark::mark_loop_prework(uint w, TaskTerminator *t, ReferenceProcessor *rp,
819                                                  bool strdedup) {
820   ShenandoahObjToScanQueue* q = get_queue(w);
821 
<span class="line-modified">822   jushort* ld = _heap-&gt;get_liveness_cache(w);</span>
823 
824   // TODO: We can clean up this if we figure out how to do templated oop closures that
825   // play nice with specialized_oop_iterators.
826   if (_heap-&gt;unload_classes()) {
827     if (_heap-&gt;has_forwarded_objects()) {
828       if (strdedup) {
829         ShenandoahMarkUpdateRefsMetadataDedupClosure cl(q, rp);
830         mark_loop_work&lt;ShenandoahMarkUpdateRefsMetadataDedupClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
831       } else {
832         ShenandoahMarkUpdateRefsMetadataClosure cl(q, rp);
833         mark_loop_work&lt;ShenandoahMarkUpdateRefsMetadataClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
834       }
835     } else {
836       if (strdedup) {
837         ShenandoahMarkRefsMetadataDedupClosure cl(q, rp);
838         mark_loop_work&lt;ShenandoahMarkRefsMetadataDedupClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
839       } else {
840         ShenandoahMarkRefsMetadataClosure cl(q, rp);
841         mark_loop_work&lt;ShenandoahMarkRefsMetadataClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
842       }
</pre>
<hr />
<pre>
848         mark_loop_work&lt;ShenandoahMarkUpdateRefsDedupClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
849       } else {
850         ShenandoahMarkUpdateRefsClosure cl(q, rp);
851         mark_loop_work&lt;ShenandoahMarkUpdateRefsClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
852       }
853     } else {
854       if (strdedup) {
855         ShenandoahMarkRefsDedupClosure cl(q, rp);
856         mark_loop_work&lt;ShenandoahMarkRefsDedupClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
857       } else {
858         ShenandoahMarkRefsClosure cl(q, rp);
859         mark_loop_work&lt;ShenandoahMarkRefsClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
860       }
861     }
862   }
863 
864   _heap-&gt;flush_liveness_cache(w);
865 }
866 
867 template &lt;class T, bool CANCELLABLE&gt;
<span class="line-modified">868 void ShenandoahConcurrentMark::mark_loop_work(T* cl, jushort* live_data, uint worker_id, TaskTerminator *terminator) {</span>
869   uintx stride = ShenandoahMarkLoopStride;
870 
871   ShenandoahHeap* heap = ShenandoahHeap::heap();
872   ShenandoahObjToScanQueueSet* queues = task_queues();
873   ShenandoahObjToScanQueue* q;
874   ShenandoahMarkTask t;
875 
876   /*
877    * Process outstanding queues, if any.
878    *
879    * There can be more queues than workers. To deal with the imbalance, we claim
880    * extra queues first. Since marking can push new tasks into the queue associated
881    * with this worker id, we come back to process this queue in the normal loop.
882    */
883   assert(queues-&gt;get_reserved() == heap-&gt;workers()-&gt;active_workers(),
884          &quot;Need to reserve proper number of queues: reserved: %u, active: %u&quot;, queues-&gt;get_reserved(), heap-&gt;workers()-&gt;active_workers());
885 
886   q = queues-&gt;claim_next();
887   while (q != NULL) {
888     if (CANCELLABLE &amp;&amp; heap-&gt;check_cancelled_gc_and_yield()) {
</pre>
</td>
<td>
<hr />
<pre>
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 
 27 #include &quot;classfile/symbolTable.hpp&quot;
 28 #include &quot;classfile/systemDictionary.hpp&quot;
 29 #include &quot;code/codeCache.hpp&quot;
 30 
 31 #include &quot;gc/shared/weakProcessor.inline.hpp&quot;
 32 #include &quot;gc/shared/gcTimer.hpp&quot;
<span class="line-added"> 33 #include &quot;gc/shared/gcTrace.hpp&quot;</span>
 34 #include &quot;gc/shared/referenceProcessor.hpp&quot;
 35 #include &quot;gc/shared/referenceProcessorPhaseTimes.hpp&quot;
 36 #include &quot;gc/shared/strongRootsScope.hpp&quot;
 37 
 38 #include &quot;gc/shenandoah/shenandoahBarrierSet.inline.hpp&quot;
 39 #include &quot;gc/shenandoah/shenandoahClosures.inline.hpp&quot;
 40 #include &quot;gc/shenandoah/shenandoahConcurrentMark.inline.hpp&quot;
 41 #include &quot;gc/shenandoah/shenandoahMarkCompact.hpp&quot;
 42 #include &quot;gc/shenandoah/shenandoahHeap.inline.hpp&quot;
 43 #include &quot;gc/shenandoah/shenandoahRootProcessor.inline.hpp&quot;
 44 #include &quot;gc/shenandoah/shenandoahOopClosures.inline.hpp&quot;
<span class="line-added"> 45 #include &quot;gc/shenandoah/shenandoahPhaseTimings.hpp&quot;</span>
 46 #include &quot;gc/shenandoah/shenandoahTaskqueue.inline.hpp&quot;

 47 #include &quot;gc/shenandoah/shenandoahUtils.hpp&quot;
 48 
 49 #include &quot;memory/iterator.inline.hpp&quot;
 50 #include &quot;memory/metaspace.hpp&quot;
 51 #include &quot;memory/resourceArea.hpp&quot;
 52 #include &quot;oops/oop.inline.hpp&quot;
 53 #include &quot;runtime/handles.inline.hpp&quot;
 54 
 55 template&lt;UpdateRefsMode UPDATE_REFS&gt;
 56 class ShenandoahInitMarkRootsClosure : public OopClosure {
 57 private:
 58   ShenandoahObjToScanQueue* _queue;
 59   ShenandoahHeap* _heap;
 60   ShenandoahMarkingContext* const _mark_context;
 61 
 62   template &lt;class T&gt;
 63   inline void do_oop_work(T* p) {
 64     ShenandoahConcurrentMark::mark_through_ref&lt;T, UPDATE_REFS, NO_DEDUP&gt;(p, _heap, _queue, _mark_context);
 65   }
 66 
</pre>
<hr />
<pre>
 68   ShenandoahInitMarkRootsClosure(ShenandoahObjToScanQueue* q) :
 69     _queue(q),
 70     _heap(ShenandoahHeap::heap()),
 71     _mark_context(_heap-&gt;marking_context()) {};
 72 
 73   void do_oop(narrowOop* p) { do_oop_work(p); }
 74   void do_oop(oop* p)       { do_oop_work(p); }
 75 };
 76 
 77 ShenandoahMarkRefsSuperClosure::ShenandoahMarkRefsSuperClosure(ShenandoahObjToScanQueue* q, ReferenceProcessor* rp) :
 78   MetadataVisitingOopIterateClosure(rp),
 79   _queue(q),
 80   _heap(ShenandoahHeap::heap()),
 81   _mark_context(_heap-&gt;marking_context())
 82 { }
 83 
 84 template&lt;UpdateRefsMode UPDATE_REFS&gt;
 85 class ShenandoahInitMarkRootsTask : public AbstractGangTask {
 86 private:
 87   ShenandoahAllRootScanner* _rp;

 88 public:
<span class="line-modified"> 89   ShenandoahInitMarkRootsTask(ShenandoahAllRootScanner* rp) :</span>
 90     AbstractGangTask(&quot;Shenandoah init mark roots task&quot;),
<span class="line-modified"> 91     _rp(rp) {</span>

 92   }
 93 
 94   void work(uint worker_id) {
 95     assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Must be at a safepoint&quot;);
 96     ShenandoahParallelWorkerSession worker_session(worker_id);
 97 
 98     ShenandoahHeap* heap = ShenandoahHeap::heap();
 99     ShenandoahObjToScanQueueSet* queues = heap-&gt;concurrent_mark()-&gt;task_queues();
100     assert(queues-&gt;get_reserved() &gt; worker_id, &quot;Queue has not been reserved for worker id: %d&quot;, worker_id);
101 
102     ShenandoahObjToScanQueue* q = queues-&gt;queue(worker_id);
103 
104     ShenandoahInitMarkRootsClosure&lt;UPDATE_REFS&gt; mark_cl(q);
105     do_work(heap, &amp;mark_cl, worker_id);
106   }
107 
108 private:
109   void do_work(ShenandoahHeap* heap, OopClosure* oops, uint worker_id) {
110     // The rationale for selecting the roots to scan is as follows:
111     //   a. With unload_classes = true, we only want to scan the actual strong roots from the
</pre>
<hr />
<pre>
164   void work(uint worker_id) {
165     ShenandoahHeap* heap = ShenandoahHeap::heap();
166     ShenandoahConcurrentWorkerSession worker_session(worker_id);
167     ShenandoahSuspendibleThreadSetJoiner stsj(ShenandoahSuspendibleWorkers);
168     ShenandoahObjToScanQueue* q = _cm-&gt;get_queue(worker_id);
169     ReferenceProcessor* rp;
170     if (heap-&gt;process_references()) {
171       rp = heap-&gt;ref_processor();
172       shenandoah_assert_rp_isalive_installed();
173     } else {
174       rp = NULL;
175     }
176 
177     _cm-&gt;concurrent_scan_code_roots(worker_id, rp);
178     _cm-&gt;mark_loop(worker_id, _terminator, rp,
179                    true, // cancellable
180                    ShenandoahStringDedup::is_enabled()); // perform string dedup
181   }
182 };
183 
<span class="line-modified">184 class ShenandoahSATBAndRemarkCodeRootsThreadsClosure : public ThreadClosure {</span>
185 private:
186   ShenandoahSATBBufferClosure* _satb_cl;
<span class="line-added">187   OopClosure*            const _cl;</span>
<span class="line-added">188   MarkingCodeBlobClosure*      _code_cl;</span>
189   uintx _claim_token;
190 
191 public:
<span class="line-modified">192   ShenandoahSATBAndRemarkCodeRootsThreadsClosure(ShenandoahSATBBufferClosure* satb_cl, OopClosure* cl, MarkingCodeBlobClosure* code_cl) :</span>
<span class="line-modified">193     _satb_cl(satb_cl), _cl(cl), _code_cl(code_cl),</span>
194     _claim_token(Threads::thread_claim_token()) {}
195 
196   void do_thread(Thread* thread) {
197     if (thread-&gt;claim_threads_do(true, _claim_token)) {
198       ShenandoahThreadLocalData::satb_mark_queue(thread).apply_closure_and_empty(_satb_cl);
<span class="line-added">199       if (thread-&gt;is_Java_thread()) {</span>
<span class="line-added">200         if (_cl != NULL) {</span>
<span class="line-added">201           ResourceMark rm;</span>
<span class="line-added">202           thread-&gt;oops_do(_cl, _code_cl);</span>
<span class="line-added">203         } else if (_code_cl != NULL) {</span>
<span class="line-added">204           // In theory it should not be neccessary to explicitly walk the nmethods to find roots for concurrent marking</span>
<span class="line-added">205           // however the liveness of oops reachable from nmethods have very complex lifecycles:</span>
<span class="line-added">206           // * Alive if on the stack of an executing method</span>
<span class="line-added">207           // * Weakly reachable otherwise</span>
<span class="line-added">208           // Some objects reachable from nmethods, such as the class loader (or klass_holder) of the receiver should be</span>
<span class="line-added">209           // live by the SATB invariant but other oops recorded in nmethods may behave differently.</span>
<span class="line-added">210           JavaThread* jt = (JavaThread*)thread;</span>
<span class="line-added">211           jt-&gt;nmethods_do(_code_cl);</span>
<span class="line-added">212         }</span>
<span class="line-added">213       }</span>
214     }
215   }
216 };
217 
218 class ShenandoahFinalMarkingTask : public AbstractGangTask {
219 private:
220   ShenandoahConcurrentMark* _cm;
221   TaskTerminator*           _terminator;
222   bool _dedup_string;
223 
224 public:
225   ShenandoahFinalMarkingTask(ShenandoahConcurrentMark* cm, TaskTerminator* terminator, bool dedup_string) :
226     AbstractGangTask(&quot;Shenandoah Final Marking&quot;), _cm(cm), _terminator(terminator), _dedup_string(dedup_string) {
227   }
228 
229   void work(uint worker_id) {
230     ShenandoahHeap* heap = ShenandoahHeap::heap();
231 
232     ShenandoahParallelWorkerSession worker_session(worker_id);
<span class="line-added">233     ReferenceProcessor* rp;</span>
<span class="line-added">234     if (heap-&gt;process_references()) {</span>
<span class="line-added">235       rp = heap-&gt;ref_processor();</span>
<span class="line-added">236       shenandoah_assert_rp_isalive_installed();</span>
<span class="line-added">237     } else {</span>
<span class="line-added">238       rp = NULL;</span>
<span class="line-added">239     }</span>
<span class="line-added">240 </span>
241     // First drain remaining SATB buffers.
242     // Notice that this is not strictly necessary for mark-compact. But since
243     // it requires a StrongRootsScope around the task, we need to claim the
244     // threads, and performance-wise it doesn&#39;t really matter. Adds about 1ms to
245     // full-gc.
246     {
247       ShenandoahObjToScanQueue* q = _cm-&gt;get_queue(worker_id);
<span class="line-added">248 </span>
249       ShenandoahSATBBufferClosure cl(q);
250       SATBMarkQueueSet&amp; satb_mq_set = ShenandoahBarrierSet::satb_mark_queue_set();
251       while (satb_mq_set.apply_closure_to_completed_buffer(&amp;cl));
<span class="line-modified">252       bool do_nmethods = heap-&gt;unload_classes() &amp;&amp; !ShenandoahConcurrentRoots::can_do_concurrent_class_unloading();</span>
<span class="line-modified">253       if (heap-&gt;has_forwarded_objects()) {</span>
<span class="line-modified">254         ShenandoahMarkResolveRefsClosure resolve_mark_cl(q, rp);</span>
<span class="line-modified">255         MarkingCodeBlobClosure blobsCl(&amp;resolve_mark_cl, !CodeBlobToOopClosure::FixRelocations);</span>
<span class="line-modified">256         ShenandoahSATBAndRemarkCodeRootsThreadsClosure tc(&amp;cl,</span>
<span class="line-modified">257                                                           ShenandoahStoreValEnqueueBarrier ? &amp;resolve_mark_cl : NULL,</span>
<span class="line-modified">258                                                           do_nmethods ? &amp;blobsCl : NULL);</span>
<span class="line-modified">259         Threads::threads_do(&amp;tc);</span>
<span class="line-modified">260       } else {</span>
<span class="line-modified">261         ShenandoahMarkRefsClosure mark_cl(q, rp);</span>
<span class="line-added">262         MarkingCodeBlobClosure blobsCl(&amp;mark_cl, !CodeBlobToOopClosure::FixRelocations);</span>
<span class="line-added">263         ShenandoahSATBAndRemarkCodeRootsThreadsClosure tc(&amp;cl,</span>
<span class="line-added">264                                                           ShenandoahStoreValEnqueueBarrier ? &amp;mark_cl : NULL,</span>
<span class="line-added">265                                                           do_nmethods ? &amp;blobsCl : NULL);</span>
<span class="line-added">266         Threads::threads_do(&amp;tc);</span>
<span class="line-added">267       }</span>
268     }
269 
270     if (heap-&gt;is_degenerated_gc_in_progress()) {
271       // Degenerated cycle may bypass concurrent cycle, so code roots might not be scanned,
272       // let&#39;s check here.
273       _cm-&gt;concurrent_scan_code_roots(worker_id, rp);
274     }
275 
276     _cm-&gt;mark_loop(worker_id, _terminator, rp,
277                    false, // not cancellable
278                    _dedup_string);
279 
280     assert(_cm-&gt;task_queues()-&gt;is_empty(), &quot;Should be empty&quot;);
281   }
282 };
283 
284 void ShenandoahConcurrentMark::mark_roots(ShenandoahPhaseTimings::Phase root_phase) {
285   assert(Thread::current()-&gt;is_VM_thread(), &quot;can only do this in VMThread&quot;);
286   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Must be at a safepoint&quot;);
287 
288   ShenandoahHeap* heap = ShenandoahHeap::heap();
289 
290   ShenandoahGCPhase phase(root_phase);
291 
292   WorkGang* workers = heap-&gt;workers();
293   uint nworkers = workers-&gt;active_workers();
294 
295   assert(nworkers &lt;= task_queues()-&gt;size(), &quot;Just check&quot;);
296 
297   ShenandoahAllRootScanner root_proc(nworkers, root_phase);
298   TASKQUEUE_STATS_ONLY(task_queues()-&gt;reset_taskqueue_stats());
299   task_queues()-&gt;reserve(nworkers);
300 
301   if (heap-&gt;has_forwarded_objects()) {
<span class="line-modified">302     ShenandoahInitMarkRootsTask&lt;RESOLVE&gt; mark_roots(&amp;root_proc);</span>
303     workers-&gt;run_task(&amp;mark_roots);
304   } else {
305     // No need to update references, which means the heap is stable.
306     // Can save time not walking through forwarding pointers.
<span class="line-modified">307     ShenandoahInitMarkRootsTask&lt;NONE&gt; mark_roots(&amp;root_proc);</span>
308     workers-&gt;run_task(&amp;mark_roots);
309   }
310 
311   if (ShenandoahConcurrentScanCodeRoots) {
312     clear_claim_codecache();
313   }
314 }
315 
316 void ShenandoahConcurrentMark::update_roots(ShenandoahPhaseTimings::Phase root_phase) {
317   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Must be at a safepoint&quot;);
318   assert(root_phase == ShenandoahPhaseTimings::full_gc_roots ||
319          root_phase == ShenandoahPhaseTimings::degen_gc_update_roots,
320          &quot;Only for these phases&quot;);
321 
322   ShenandoahGCPhase phase(root_phase);
323 
324   bool check_alive = root_phase == ShenandoahPhaseTimings::degen_gc_update_roots;
325 
326 #if COMPILER2_OR_JVMCI
327   DerivedPointerTable::clear();
328 #endif
329 
330   uint nworkers = _heap-&gt;workers()-&gt;active_workers();
331 
332   ShenandoahRootUpdater root_updater(nworkers, root_phase);
333   ShenandoahUpdateRootsTask update_roots(&amp;root_updater, check_alive);
334   _heap-&gt;workers()-&gt;run_task(&amp;update_roots);
335 
336 #if COMPILER2_OR_JVMCI
337   DerivedPointerTable::update_pointers();
338 #endif
339 }
340 
341 class ShenandoahUpdateThreadRootsTask : public AbstractGangTask {
342 private:
343   ShenandoahThreadRoots           _thread_roots;
344   ShenandoahPhaseTimings::Phase   _phase;
<span class="line-added">345   ShenandoahGCWorkerPhase         _worker_phase;</span>
346 public:
347   ShenandoahUpdateThreadRootsTask(bool is_par, ShenandoahPhaseTimings::Phase phase) :
348     AbstractGangTask(&quot;Shenandoah Update Thread Roots&quot;),
349     _thread_roots(is_par),
<span class="line-modified">350     _phase(phase),</span>
<span class="line-modified">351     _worker_phase(phase) {}</span>

352 



353   void work(uint worker_id) {
354     ShenandoahUpdateRefsClosure cl;
355     _thread_roots.oops_do(&amp;cl, NULL, worker_id);
356   }
357 };
358 
359 void ShenandoahConcurrentMark::update_thread_roots(ShenandoahPhaseTimings::Phase root_phase) {
360   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Must be at a safepoint&quot;);
361 
362   ShenandoahGCPhase phase(root_phase);
363 
364 #if COMPILER2_OR_JVMCI
365   DerivedPointerTable::clear();
366 #endif
367 
368   WorkGang* workers = _heap-&gt;workers();
369   bool is_par = workers-&gt;active_workers() &gt; 1;
370 
371   ShenandoahUpdateThreadRootsTask task(is_par, root_phase);
372   workers-&gt;run_task(&amp;task);
</pre>
<hr />
<pre>
671 
672   assert(task_queues()-&gt;is_empty(), &quot;Should be empty&quot;);
673 
674   // complete_gc and keep_alive closures instantiated here are only needed for
675   // single-threaded path in RP. They share the queue 0 for tracking work, which
676   // simplifies implementation. Since RP may decide to call complete_gc several
677   // times, we need to be able to reuse the terminator.
678   uint serial_worker_id = 0;
679   TaskTerminator terminator(1, task_queues());
680   ShenandoahCMDrainMarkingStackClosure complete_gc(serial_worker_id, &amp;terminator, /* reset_terminator = */ true);
681 
682   ShenandoahRefProcTaskExecutor executor(workers);
683 
684   ReferenceProcessorPhaseTimes pt(_heap-&gt;gc_timer(), rp-&gt;num_queues());
685 
686   {
687     ShenandoahGCPhase phase(phase_process);
688 
689     if (_heap-&gt;has_forwarded_objects()) {
690       ShenandoahCMKeepAliveUpdateClosure keep_alive(get_queue(serial_worker_id));
<span class="line-modified">691       const ReferenceProcessorStats&amp; stats =</span>
<span class="line-modified">692         rp-&gt;process_discovered_references(is_alive.is_alive_closure(), &amp;keep_alive,</span>
<span class="line-modified">693                                           &amp;complete_gc, &amp;executor,</span>
<span class="line-modified">694                                           &amp;pt);</span>
<span class="line-added">695        _heap-&gt;tracer()-&gt;report_gc_reference_stats(stats);</span>
696     } else {
697       ShenandoahCMKeepAliveClosure keep_alive(get_queue(serial_worker_id));
<span class="line-modified">698       const ReferenceProcessorStats&amp; stats =</span>
<span class="line-modified">699         rp-&gt;process_discovered_references(is_alive.is_alive_closure(), &amp;keep_alive,</span>
<span class="line-modified">700                                           &amp;complete_gc, &amp;executor,</span>
<span class="line-modified">701                                           &amp;pt);</span>
<span class="line-added">702       _heap-&gt;tracer()-&gt;report_gc_reference_stats(stats);</span>
703     }
704 
705     pt.print_all_references();
706 
707     assert(task_queues()-&gt;is_empty(), &quot;Should be empty&quot;);
708   }
709 }
710 
711 class ShenandoahCancelledGCYieldClosure : public YieldClosure {
712 private:
713   ShenandoahHeap* const _heap;
714 public:
715   ShenandoahCancelledGCYieldClosure() : _heap(ShenandoahHeap::heap()) {};
716   virtual bool should_return() { return _heap-&gt;cancelled_gc(); }
717 };
718 
719 class ShenandoahPrecleanCompleteGCClosure : public VoidClosure {
720 public:
721   void do_void() {
722     ShenandoahHeap* sh = ShenandoahHeap::heap();
723     ShenandoahConcurrentMark* scm = sh-&gt;concurrent_mark();
724     assert(sh-&gt;process_references(), &quot;why else would we be here?&quot;);
725     TaskTerminator terminator(1, scm-&gt;task_queues());
726 
727     ReferenceProcessor* rp = sh-&gt;ref_processor();
728     shenandoah_assert_rp_isalive_installed();
729 
730     scm-&gt;mark_loop(0, &amp;terminator, rp,
731                    false, // not cancellable
732                    false); // do not do strdedup
733   }
734 };
735 





















736 class ShenandoahPrecleanTask : public AbstractGangTask {
737 private:
738   ReferenceProcessor* _rp;
739 
740 public:
741   ShenandoahPrecleanTask(ReferenceProcessor* rp) :
742           AbstractGangTask(&quot;Precleaning task&quot;),
743           _rp(rp) {}
744 
745   void work(uint worker_id) {
746     assert(worker_id == 0, &quot;The code below is single-threaded, only one worker is expected&quot;);
747     ShenandoahParallelWorkerSession worker_session(worker_id);
748 
749     ShenandoahHeap* sh = ShenandoahHeap::heap();
<span class="line-added">750     assert(!sh-&gt;has_forwarded_objects(), &quot;No forwarded objects expected here&quot;);</span>
751 
752     ShenandoahObjToScanQueue* q = sh-&gt;concurrent_mark()-&gt;get_queue(worker_id);
753 
754     ShenandoahCancelledGCYieldClosure yield;
755     ShenandoahPrecleanCompleteGCClosure complete_gc;
756 
<span class="line-modified">757     ShenandoahIsAliveClosure is_alive;</span>
<span class="line-modified">758     ShenandoahCMKeepAliveClosure keep_alive(q);</span>
<span class="line-modified">759     ResourceMark rm;</span>
<span class="line-modified">760     _rp-&gt;preclean_discovered_references(&amp;is_alive, &amp;keep_alive,</span>
<span class="line-modified">761                                         &amp;complete_gc, &amp;yield,</span>
<span class="line-modified">762                                         NULL);</span>









763   }
764 };
765 
766 void ShenandoahConcurrentMark::preclean_weak_refs() {
767   // Pre-cleaning weak references before diving into STW makes sense at the
768   // end of concurrent mark. This will filter out the references which referents
769   // are alive. Note that ReferenceProcessor already filters out these on reference
770   // discovery, and the bulk of work is done here. This phase processes leftovers
771   // that missed the initial filtering, i.e. when referent was marked alive after
772   // reference was discovered by RP.
773 
774   assert(_heap-&gt;process_references(), &quot;sanity&quot;);
775 
776   // Shortcut if no references were discovered to avoid winding up threads.
777   ReferenceProcessor* rp = _heap-&gt;ref_processor();
778   if (!rp-&gt;has_discovered_references()) {
779     return;
780   }
781 
782   assert(task_queues()-&gt;is_empty(), &quot;Should be empty&quot;);
</pre>
<hr />
<pre>
803 
804 void ShenandoahConcurrentMark::cancel() {
805   // Clean up marking stacks.
806   ShenandoahObjToScanQueueSet* queues = task_queues();
807   queues-&gt;clear();
808 
809   // Cancel SATB buffers.
810   ShenandoahBarrierSet::satb_mark_queue_set().abandon_partial_marking();
811 }
812 
813 ShenandoahObjToScanQueue* ShenandoahConcurrentMark::get_queue(uint worker_id) {
814   assert(task_queues()-&gt;get_reserved() &gt; worker_id, &quot;No reserved queue for worker id: %d&quot;, worker_id);
815   return _task_queues-&gt;queue(worker_id);
816 }
817 
818 template &lt;bool CANCELLABLE&gt;
819 void ShenandoahConcurrentMark::mark_loop_prework(uint w, TaskTerminator *t, ReferenceProcessor *rp,
820                                                  bool strdedup) {
821   ShenandoahObjToScanQueue* q = get_queue(w);
822 
<span class="line-modified">823   ShenandoahLiveData* ld = _heap-&gt;get_liveness_cache(w);</span>
824 
825   // TODO: We can clean up this if we figure out how to do templated oop closures that
826   // play nice with specialized_oop_iterators.
827   if (_heap-&gt;unload_classes()) {
828     if (_heap-&gt;has_forwarded_objects()) {
829       if (strdedup) {
830         ShenandoahMarkUpdateRefsMetadataDedupClosure cl(q, rp);
831         mark_loop_work&lt;ShenandoahMarkUpdateRefsMetadataDedupClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
832       } else {
833         ShenandoahMarkUpdateRefsMetadataClosure cl(q, rp);
834         mark_loop_work&lt;ShenandoahMarkUpdateRefsMetadataClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
835       }
836     } else {
837       if (strdedup) {
838         ShenandoahMarkRefsMetadataDedupClosure cl(q, rp);
839         mark_loop_work&lt;ShenandoahMarkRefsMetadataDedupClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
840       } else {
841         ShenandoahMarkRefsMetadataClosure cl(q, rp);
842         mark_loop_work&lt;ShenandoahMarkRefsMetadataClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
843       }
</pre>
<hr />
<pre>
849         mark_loop_work&lt;ShenandoahMarkUpdateRefsDedupClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
850       } else {
851         ShenandoahMarkUpdateRefsClosure cl(q, rp);
852         mark_loop_work&lt;ShenandoahMarkUpdateRefsClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
853       }
854     } else {
855       if (strdedup) {
856         ShenandoahMarkRefsDedupClosure cl(q, rp);
857         mark_loop_work&lt;ShenandoahMarkRefsDedupClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
858       } else {
859         ShenandoahMarkRefsClosure cl(q, rp);
860         mark_loop_work&lt;ShenandoahMarkRefsClosure, CANCELLABLE&gt;(&amp;cl, ld, w, t);
861       }
862     }
863   }
864 
865   _heap-&gt;flush_liveness_cache(w);
866 }
867 
868 template &lt;class T, bool CANCELLABLE&gt;
<span class="line-modified">869 void ShenandoahConcurrentMark::mark_loop_work(T* cl, ShenandoahLiveData* live_data, uint worker_id, TaskTerminator *terminator) {</span>
870   uintx stride = ShenandoahMarkLoopStride;
871 
872   ShenandoahHeap* heap = ShenandoahHeap::heap();
873   ShenandoahObjToScanQueueSet* queues = task_queues();
874   ShenandoahObjToScanQueue* q;
875   ShenandoahMarkTask t;
876 
877   /*
878    * Process outstanding queues, if any.
879    *
880    * There can be more queues than workers. To deal with the imbalance, we claim
881    * extra queues first. Since marking can push new tasks into the queue associated
882    * with this worker id, we come back to process this queue in the normal loop.
883    */
884   assert(queues-&gt;get_reserved() == heap-&gt;workers()-&gt;active_workers(),
885          &quot;Need to reserve proper number of queues: reserved: %u, active: %u&quot;, queues-&gt;get_reserved(), heap-&gt;workers()-&gt;active_workers());
886 
887   q = queues-&gt;claim_next();
888   while (q != NULL) {
889     if (CANCELLABLE &amp;&amp; heap-&gt;check_cancelled_gc_and_yield()) {
</pre>
</td>
</tr>
</table>
<center><a href="shenandoahCollectionSet.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahConcurrentMark.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>