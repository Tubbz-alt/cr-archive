<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/g1/heapRegionRemSet.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="heapRegionRemSet.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="heapRegionRemSet.inline.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/g1/heapRegionRemSet.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 64 //      other times).
 65 //   2) We find PRT&#39;s in an attempt to add entries.  If a PRT is deleted,
 66 //      it&#39;s _coarse_map bit is set, so the that we were attempting to add
 67 //      is represented.  If a deleted PRT is re-used, a thread adding a bit,
 68 //      thinking the PRT is for a different region, does no harm.
 69 
 70 class OtherRegionsTable {
 71   G1CollectedHeap* _g1h;
 72   Mutex*           _m;
 73 
 74   size_t volatile _num_occupied;
 75 
 76   // These are protected by &quot;_m&quot;.
 77   CHeapBitMap _coarse_map;
 78   size_t      _n_coarse_entries;
 79   static jint _n_coarsenings;
 80 
 81   PerRegionTable** _fine_grain_regions;
 82   size_t           _n_fine_entries;
 83 
<span class="line-modified"> 84   // The fine grain remembered sets are doubly linked together using</span>
<span class="line-modified"> 85   // their &#39;next&#39; and &#39;prev&#39; fields.</span>
 86   // This allows fast bulk freeing of all the fine grain remembered
 87   // set entries, and fast finding of all of them without iterating
 88   // over the _fine_grain_regions table.
 89   PerRegionTable * _first_all_fine_prts;
 90   PerRegionTable * _last_all_fine_prts;
 91 
 92   // Used to sample a subset of the fine grain PRTs to determine which
 93   // PRT to evict and coarsen.
 94   size_t        _fine_eviction_start;
 95   static size_t _fine_eviction_stride;
 96   static size_t _fine_eviction_sample_size;
 97 
 98   SparsePRT   _sparse_table;
 99 
100   // These are static after init.
101   static size_t _max_fine_entries;
102   static size_t _mod_max_fine_entries_mask;
103 
104   // Requires &quot;prt&quot; to be the first element of the bucket list appropriate
105   // for &quot;hr&quot;.  If this list contains an entry for &quot;hr&quot;, return it,
106   // otherwise return &quot;NULL&quot;.
107   PerRegionTable* find_region_table(size_t ind, HeapRegion* hr) const;
108 
109   // Find, delete, and return a candidate PerRegionTable, if any exists,
110   // adding the deleted region to the coarse bitmap.  Requires the caller
111   // to hold _m, and the fine-grain table to be full.
112   PerRegionTable* delete_region_table(size_t&amp; added_by_deleted);
113 
114   // link/add the given fine grain remembered set into the &quot;all&quot; list
115   void link_to_all(PerRegionTable * prt);
<span class="line-removed">116   // unlink/remove the given fine grain remembered set into the &quot;all&quot; list</span>
<span class="line-removed">117   void unlink_from_all(PerRegionTable * prt);</span>
118 
119   bool contains_reference_locked(OopOrNarrowOopStar from) const;
120 
121 public:
122   // Create a new remembered set. The given mutex is used to ensure consistency.
123   OtherRegionsTable(Mutex* m);
124 
125   template &lt;class Closure&gt;
126   void iterate(Closure&amp; v);
127 
128   // Returns the card index of the given within_region pointer relative to the bottom
129   // of the given heap region.
130   static CardIdx_t card_within_region(OopOrNarrowOopStar within_region, HeapRegion* hr);
131   // Adds the reference from &quot;from to this remembered set.
132   void add_reference(OopOrNarrowOopStar from, uint tid);
133 
134   // Returns whether the remembered set contains the given reference.
135   bool contains_reference(OopOrNarrowOopStar from) const;
136 
137   // Returns whether this remembered set (and all sub-sets) have an occupancy
138   // that is less or equal than the given occupancy.
139   bool occupancy_less_or_equal_than(size_t limit) const;
140 
141   // Returns whether this remembered set (and all sub-sets) does not contain any entry.
142   bool is_empty() const;
143 
144   // Returns the number of cards contained in this remembered set.
145   size_t occupied() const;
146 
147   static jint n_coarsenings() { return _n_coarsenings; }
148 
149   // Returns size of the actual remembered set containers in bytes.
150   size_t mem_size() const;
151   // Returns the size of static data in bytes.
152   static size_t static_mem_size();
153   // Returns the size of the free list content in bytes.
154   static size_t fl_mem_size();
155 
156   // Clear the entire contents of this remembered set.
157   void clear();



158 };
159 
160 class PerRegionTable: public CHeapObj&lt;mtGC&gt; {
161   friend class OtherRegionsTable;
162 
163   HeapRegion*     _hr;
164   CHeapBitMap     _bm;
165   jint            _occupied;
166 
167   // next pointer for free/allocated &#39;all&#39; list
168   PerRegionTable* _next;
169 
<span class="line-removed">170   // prev pointer for the allocated &#39;all&#39; list</span>
<span class="line-removed">171   PerRegionTable* _prev;</span>
<span class="line-removed">172 </span>
173   // next pointer in collision list
174   PerRegionTable * _collision_list_next;
175 
176   // Global free list of PRTs
177   static PerRegionTable* volatile _free_list;
178 
179 protected:
180   PerRegionTable(HeapRegion* hr) :
181     _hr(hr),
182     _bm(HeapRegion::CardsPerRegion, mtGC),
183     _occupied(0),
<span class="line-modified">184     _next(NULL), _prev(NULL),</span>
185     _collision_list_next(NULL)
186   {}
187 
188 public:
189   // We need access in order to union things into the base table.
190   BitMap* bm() { return &amp;_bm; }
191 
192   HeapRegion* hr() const { return Atomic::load_acquire(&amp;_hr); }
193 
194   jint occupied() const {
195     return _occupied;
196   }
197 
198   void init(HeapRegion* hr, bool clear_links_to_all_list);
199 
200   inline bool add_reference(OopOrNarrowOopStar from);
201 
202   inline bool add_card(CardIdx_t from_card_index);
203 
204   // (Destructively) union the bitmap of the current table into the given
</pre>
<hr />
<pre>
226     while (true) {
227       PerRegionTable* fl = _free_list;
228       last-&gt;set_next(fl);
229       PerRegionTable* res = Atomic::cmpxchg(&amp;_free_list, fl, prt);
230       if (res == fl) {
231         return;
232       }
233     }
234     ShouldNotReachHere();
235   }
236 
237   static void free(PerRegionTable* prt) {
238     bulk_free(prt, prt);
239   }
240 
241   // Returns an initialized PerRegionTable instance.
242   static PerRegionTable* alloc(HeapRegion* hr);
243 
244   PerRegionTable* next() const { return _next; }
245   void set_next(PerRegionTable* next) { _next = next; }
<span class="line-removed">246   PerRegionTable* prev() const { return _prev; }</span>
<span class="line-removed">247   void set_prev(PerRegionTable* prev) { _prev = prev; }</span>
248 
249   // Accessor and Modification routines for the pointer for the
250   // singly linked collision list that links the PRTs within the
251   // OtherRegionsTable::_fine_grain_regions hash table.
252   //
<span class="line-removed">253   // It might be useful to also make the collision list doubly linked</span>
<span class="line-removed">254   // to avoid iteration over the collisions list during scrubbing/deletion.</span>
<span class="line-removed">255   // OTOH there might not be many collisions.</span>
256 
257   PerRegionTable* collision_list_next() const {
258     return _collision_list_next;
259   }
260 
261   void set_collision_list_next(PerRegionTable* next) {
262     _collision_list_next = next;
263   }
264 
265   PerRegionTable** collision_list_next_addr() {
266     return &amp;_collision_list_next;
267   }
268 
269   static size_t fl_mem_size() {
270     PerRegionTable* cur = _free_list;
271     size_t res = 0;
272     while (cur != NULL) {
273       res += cur-&gt;mem_size();
274       cur = cur-&gt;next();
275     }
</pre>
</td>
<td>
<hr />
<pre>
 64 //      other times).
 65 //   2) We find PRT&#39;s in an attempt to add entries.  If a PRT is deleted,
 66 //      it&#39;s _coarse_map bit is set, so the that we were attempting to add
 67 //      is represented.  If a deleted PRT is re-used, a thread adding a bit,
 68 //      thinking the PRT is for a different region, does no harm.
 69 
 70 class OtherRegionsTable {
 71   G1CollectedHeap* _g1h;
 72   Mutex*           _m;
 73 
 74   size_t volatile _num_occupied;
 75 
 76   // These are protected by &quot;_m&quot;.
 77   CHeapBitMap _coarse_map;
 78   size_t      _n_coarse_entries;
 79   static jint _n_coarsenings;
 80 
 81   PerRegionTable** _fine_grain_regions;
 82   size_t           _n_fine_entries;
 83 
<span class="line-modified"> 84   // The fine grain remembered sets are linked together using</span>
<span class="line-modified"> 85   // their &#39;next&#39; fields.</span>
 86   // This allows fast bulk freeing of all the fine grain remembered
 87   // set entries, and fast finding of all of them without iterating
 88   // over the _fine_grain_regions table.
 89   PerRegionTable * _first_all_fine_prts;
 90   PerRegionTable * _last_all_fine_prts;
 91 
 92   // Used to sample a subset of the fine grain PRTs to determine which
 93   // PRT to evict and coarsen.
 94   size_t        _fine_eviction_start;
 95   static size_t _fine_eviction_stride;
 96   static size_t _fine_eviction_sample_size;
 97 
 98   SparsePRT   _sparse_table;
 99 
100   // These are static after init.
101   static size_t _max_fine_entries;
102   static size_t _mod_max_fine_entries_mask;
103 
104   // Requires &quot;prt&quot; to be the first element of the bucket list appropriate
105   // for &quot;hr&quot;.  If this list contains an entry for &quot;hr&quot;, return it,
106   // otherwise return &quot;NULL&quot;.
107   PerRegionTable* find_region_table(size_t ind, HeapRegion* hr) const;
108 
109   // Find, delete, and return a candidate PerRegionTable, if any exists,
110   // adding the deleted region to the coarse bitmap.  Requires the caller
111   // to hold _m, and the fine-grain table to be full.
112   PerRegionTable* delete_region_table(size_t&amp; added_by_deleted);
113 
114   // link/add the given fine grain remembered set into the &quot;all&quot; list
115   void link_to_all(PerRegionTable * prt);


116 
117   bool contains_reference_locked(OopOrNarrowOopStar from) const;
118 
119 public:
120   // Create a new remembered set. The given mutex is used to ensure consistency.
121   OtherRegionsTable(Mutex* m);
122 
123   template &lt;class Closure&gt;
124   void iterate(Closure&amp; v);
125 
126   // Returns the card index of the given within_region pointer relative to the bottom
127   // of the given heap region.
128   static CardIdx_t card_within_region(OopOrNarrowOopStar within_region, HeapRegion* hr);
129   // Adds the reference from &quot;from to this remembered set.
130   void add_reference(OopOrNarrowOopStar from, uint tid);
131 
132   // Returns whether the remembered set contains the given reference.
133   bool contains_reference(OopOrNarrowOopStar from) const;
134 
135   // Returns whether this remembered set (and all sub-sets) have an occupancy
136   // that is less or equal than the given occupancy.
137   bool occupancy_less_or_equal_than(size_t limit) const;
138 
139   // Returns whether this remembered set (and all sub-sets) does not contain any entry.
140   bool is_empty() const;
141 
142   // Returns the number of cards contained in this remembered set.
143   size_t occupied() const;
144 
145   static jint n_coarsenings() { return _n_coarsenings; }
146 
147   // Returns size of the actual remembered set containers in bytes.
148   size_t mem_size() const;
149   // Returns the size of static data in bytes.
150   static size_t static_mem_size();
151   // Returns the size of the free list content in bytes.
152   static size_t fl_mem_size();
153 
154   // Clear the entire contents of this remembered set.
155   void clear();
<span class="line-added">156 </span>
<span class="line-added">157   // Safe for use by concurrent readers outside _m</span>
<span class="line-added">158   bool is_region_coarsened(RegionIdx_t from_hrm_ind) const;</span>
159 };
160 
161 class PerRegionTable: public CHeapObj&lt;mtGC&gt; {
162   friend class OtherRegionsTable;
163 
164   HeapRegion*     _hr;
165   CHeapBitMap     _bm;
166   jint            _occupied;
167 
168   // next pointer for free/allocated &#39;all&#39; list
169   PerRegionTable* _next;
170 



171   // next pointer in collision list
172   PerRegionTable * _collision_list_next;
173 
174   // Global free list of PRTs
175   static PerRegionTable* volatile _free_list;
176 
177 protected:
178   PerRegionTable(HeapRegion* hr) :
179     _hr(hr),
180     _bm(HeapRegion::CardsPerRegion, mtGC),
181     _occupied(0),
<span class="line-modified">182     _next(NULL),</span>
183     _collision_list_next(NULL)
184   {}
185 
186 public:
187   // We need access in order to union things into the base table.
188   BitMap* bm() { return &amp;_bm; }
189 
190   HeapRegion* hr() const { return Atomic::load_acquire(&amp;_hr); }
191 
192   jint occupied() const {
193     return _occupied;
194   }
195 
196   void init(HeapRegion* hr, bool clear_links_to_all_list);
197 
198   inline bool add_reference(OopOrNarrowOopStar from);
199 
200   inline bool add_card(CardIdx_t from_card_index);
201 
202   // (Destructively) union the bitmap of the current table into the given
</pre>
<hr />
<pre>
224     while (true) {
225       PerRegionTable* fl = _free_list;
226       last-&gt;set_next(fl);
227       PerRegionTable* res = Atomic::cmpxchg(&amp;_free_list, fl, prt);
228       if (res == fl) {
229         return;
230       }
231     }
232     ShouldNotReachHere();
233   }
234 
235   static void free(PerRegionTable* prt) {
236     bulk_free(prt, prt);
237   }
238 
239   // Returns an initialized PerRegionTable instance.
240   static PerRegionTable* alloc(HeapRegion* hr);
241 
242   PerRegionTable* next() const { return _next; }
243   void set_next(PerRegionTable* next) { _next = next; }


244 
245   // Accessor and Modification routines for the pointer for the
246   // singly linked collision list that links the PRTs within the
247   // OtherRegionsTable::_fine_grain_regions hash table.
248   //



249 
250   PerRegionTable* collision_list_next() const {
251     return _collision_list_next;
252   }
253 
254   void set_collision_list_next(PerRegionTable* next) {
255     _collision_list_next = next;
256   }
257 
258   PerRegionTable** collision_list_next_addr() {
259     return &amp;_collision_list_next;
260   }
261 
262   static size_t fl_mem_size() {
263     PerRegionTable* cur = _free_list;
264     size_t res = 0;
265     while (cur != NULL) {
266       res += cur-&gt;mem_size();
267       cur = cur-&gt;next();
268     }
</pre>
</td>
</tr>
</table>
<center><a href="heapRegionRemSet.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="heapRegionRemSet.inline.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>