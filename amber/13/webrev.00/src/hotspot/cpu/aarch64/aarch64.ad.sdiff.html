<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../../../demo/share/jfc/TableExample/TableSorter.java.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="assembler_aarch64.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/aarch64.ad</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 







 1030  bool is_CAS(int opcode, bool maybe_volatile);
 1031 
 1032   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1033 
 1034   bool unnecessary_acquire(const Node *barrier);
 1035   bool needs_acquiring_load(const Node *load);
 1036 
 1037   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1038 
 1039   bool unnecessary_release(const Node *barrier);
 1040   bool unnecessary_volatile(const Node *barrier);
 1041   bool needs_releasing_store(const Node *store);
 1042 
 1043   // predicate controlling translation of CompareAndSwapX
 1044   bool needs_acquiring_load_exclusive(const Node *load);
 1045 
 1046   // predicate controlling addressing modes
 1047   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1048 %}
 1049 
 1050 source %{
 1051 
 1052   // Derived RegMask with conditionally allocatable registers
 1053 











 1054   RegMask _ANY_REG32_mask;
 1055   RegMask _ANY_REG_mask;
 1056   RegMask _PTR_REG_mask;
 1057   RegMask _NO_SPECIAL_REG32_mask;
 1058   RegMask _NO_SPECIAL_REG_mask;
 1059   RegMask _NO_SPECIAL_PTR_REG_mask;
 1060 
 1061   void reg_mask_init() {
 1062     // We derive below RegMask(s) from the ones which are auto-generated from
 1063     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1064     // registers conditionally reserved.
 1065 
 1066     _ANY_REG32_mask = _ALL_REG32_mask;
 1067     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1068 
 1069     _ANY_REG_mask = _ALL_REG_mask;
 1070 
 1071     _PTR_REG_mask = _ALL_REG_mask;
 1072 
 1073     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
</pre>
<hr />
<pre>
 1528 // code for the safepoint node and that needs ot be at the load
 1529 // instruction itself. so we cannot plant a mov of the safepoint poll
 1530 // address followed by a load. setting this to true means the mov is
 1531 // scheduled as a prior instruction. that&#39;s better for scheduling
 1532 // anyway.
 1533 
 1534 bool SafePointNode::needs_polling_address_input()
 1535 {
 1536   return true;
 1537 }
 1538 
 1539 //=============================================================================
 1540 
 1541 #ifndef PRODUCT
 1542 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1543   st-&gt;print(&quot;BREAKPOINT&quot;);
 1544 }
 1545 #endif
 1546 
 1547 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
<span class="line-modified"> 1548   MacroAssembler _masm(&amp;cbuf);</span>
 1549   __ brk(0);
 1550 }
 1551 
 1552 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1553   return MachNode::size(ra_);
 1554 }
 1555 
 1556 //=============================================================================
 1557 
 1558 #ifndef PRODUCT
 1559   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1560     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1561   }
 1562 #endif
 1563 
 1564   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
<span class="line-modified"> 1565     MacroAssembler _masm(&amp;cbuf);</span>
 1566     for (int i = 0; i &lt; _count; i++) {
 1567       __ nop();
 1568     }
 1569   }
 1570 
 1571   uint MachNopNode::size(PhaseRegAlloc*) const {
 1572     return _count * NativeInstruction::instruction_size;
 1573   }
 1574 
 1575 //=============================================================================
 1576 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1577 
<span class="line-modified"> 1578 int Compile::ConstantTable::calculate_table_base_offset() const {</span>
 1579   return 0;  // absolute addressing, no offset
 1580 }
 1581 
 1582 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1583 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1584   ShouldNotReachHere();
 1585 }
 1586 
 1587 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1588   // Empty encoding
 1589 }
 1590 
 1591 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1592   return 0;
 1593 }
 1594 
 1595 #ifndef PRODUCT
 1596 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1597   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1598 }
 1599 #endif
 1600 
 1601 #ifndef PRODUCT
 1602 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1603   Compile* C = ra_-&gt;C;
 1604 
<span class="line-modified"> 1605   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1606 
<span class="line-modified"> 1607   if (C-&gt;need_stack_bang(framesize))</span>
 1608     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1609 
 1610   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1611     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1612     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1613     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1614   } else {
 1615     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1616     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1617     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1618     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1619   }
 1620 }
 1621 #endif
 1622 
 1623 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1624   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1625   MacroAssembler _masm(&amp;cbuf);</span>
 1626 
 1627   // n.b. frame size includes space for return pc and rfp
<span class="line-modified"> 1628   const long framesize = C-&gt;frame_size_in_bytes();</span>
 1629   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1630 
 1631   // insert a nop at the start of the prolog so we can patch in a
 1632   // branch if we need to invalidate the method later
 1633   __ nop();
 1634 
 1635   if (C-&gt;clinit_barrier_on_entry()) {
 1636     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);
 1637 
 1638     Label L_skip_barrier;
 1639 
 1640     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1641     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 1642     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 1643     __ bind(L_skip_barrier);
 1644   }
 1645 
<span class="line-modified"> 1646   int bangsize = C-&gt;bang_size_in_bytes();</span>
<span class="line-modified"> 1647   if (C-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)</span>
 1648     __ generate_stack_overflow_check(bangsize);
 1649 
 1650   __ build_frame(framesize);
 1651 
 1652   if (VerifyStackAtCalls) {
 1653     Unimplemented();
 1654   }
 1655 
<span class="line-modified"> 1656   C-&gt;set_frame_complete(cbuf.insts_size());</span>
 1657 
 1658   if (C-&gt;has_mach_constant_base_node()) {
 1659     // NOTE: We set the table base offset here because users might be
 1660     // emitted before MachConstantBaseNode.
<span class="line-modified"> 1661     Compile::ConstantTable&amp; constant_table = C-&gt;constant_table();</span>
 1662     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1663   }
 1664 }
 1665 
 1666 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1667 {
 1668   return MachNode::size(ra_); // too many variables; just compute it
 1669                               // the hard way
 1670 }
 1671 
 1672 int MachPrologNode::reloc() const
 1673 {
 1674   return 0;
 1675 }
 1676 
 1677 //=============================================================================
 1678 
 1679 #ifndef PRODUCT
 1680 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1681   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1682   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1683 
 1684   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1685 
 1686   if (framesize == 0) {
 1687     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1688   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1689     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1690     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1691   } else {
 1692     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1693     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1694     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1695   }
 1696 
 1697   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1698     st-&gt;print(&quot;# touch polling page\n\t&quot;);
<span class="line-modified"> 1699     st-&gt;print(&quot;mov  rscratch1, #0x%lx\n\t&quot;, p2i(os::get_polling_page()));</span>
 1700     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1701   }
 1702 }
 1703 #endif
 1704 
 1705 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1706   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1707   MacroAssembler _masm(&amp;cbuf);</span>
<span class="line-modified"> 1708   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1709 
 1710   __ remove_frame(framesize);
 1711 
 1712   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1713     __ reserved_stack_check();
 1714   }
 1715 
 1716   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
<span class="line-modified"> 1717     __ read_polling_page(rscratch1, os::get_polling_page(), relocInfo::poll_return_type);</span>
 1718   }
 1719 }
 1720 
 1721 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1722   // Variable size. Determine dynamically.
 1723   return MachNode::size(ra_);
 1724 }
 1725 
 1726 int MachEpilogNode::reloc() const {
 1727   // Return number of relocatable values contained in this instruction.
 1728   return 1; // 1 for polling page.
 1729 }
 1730 
 1731 const Pipeline * MachEpilogNode::pipeline() const {
 1732   return MachNode::pipeline_class();
 1733 }
 1734 
<span class="line-removed"> 1735 // This method seems to be obsolete. It is declared in machnode.hpp</span>
<span class="line-removed"> 1736 // and defined in all *.ad files, but it is never called. Should we</span>
<span class="line-removed"> 1737 // get rid of it?</span>
<span class="line-removed"> 1738 int MachEpilogNode::safepoint_offset() const {</span>
<span class="line-removed"> 1739   assert(do_polling(), &quot;no return for this epilog node&quot;);</span>
<span class="line-removed"> 1740   return 4;</span>
<span class="line-removed"> 1741 }</span>
<span class="line-removed"> 1742 </span>
 1743 //=============================================================================
 1744 
 1745 // Figure out which register class each belongs in: rc_int, rc_float or
 1746 // rc_stack.
 1747 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1748 
 1749 static enum RC rc_class(OptoReg::Name reg) {
 1750 
 1751   if (reg == OptoReg::Bad) {
 1752     return rc_bad;
 1753   }
 1754 
 1755   // we have 30 int registers * 2 halves
 1756   // (rscratch1 and rscratch2 are omitted)
 1757   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1758 
 1759   if (reg &lt; slots_of_int_registers) {
 1760     return rc_int;
 1761   }
 1762 
</pre>
<hr />
<pre>
 1789 
 1790   if (src_hi != OptoReg::Bad) {
 1791     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1792            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1793            &quot;expected aligned-adjacent pairs&quot;);
 1794   }
 1795 
 1796   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1797     return 0;            // Self copy, no move.
 1798   }
 1799 
 1800   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1801               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1802   int src_offset = ra_-&gt;reg2offset(src_lo);
 1803   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1804 
 1805   if (bottom_type()-&gt;isa_vect() != NULL) {
 1806     uint ireg = ideal_reg();
 1807     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1808     if (cbuf) {
<span class="line-modified"> 1809       MacroAssembler _masm(cbuf);</span>
 1810       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1811       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1812         // stack-&gt;stack
 1813         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1814         if (ireg == Op_VecD) {
 1815           __ unspill(rscratch1, true, src_offset);
 1816           __ spill(rscratch1, true, dst_offset);
 1817         } else {
 1818           __ spill_copy128(src_offset, dst_offset);
 1819         }
 1820       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1821         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1822                ireg == Op_VecD ? __ T8B : __ T16B,
 1823                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1824       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1825         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1826                        ireg == Op_VecD ? __ D : __ Q,
 1827                        ra_-&gt;reg2offset(dst_lo));
 1828       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1829         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1830                        ireg == Op_VecD ? __ D : __ Q,
 1831                        ra_-&gt;reg2offset(src_lo));
 1832       } else {
 1833         ShouldNotReachHere();
 1834       }
 1835     }
 1836   } else if (cbuf) {
<span class="line-modified"> 1837     MacroAssembler _masm(cbuf);</span>
 1838     switch (src_lo_rc) {
 1839     case rc_int:
 1840       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1841         if (is64) {
 1842             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1843                    as_Register(Matcher::_regEncode[src_lo]));
 1844         } else {
<span class="line-modified"> 1845             MacroAssembler _masm(cbuf);</span>
 1846             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1847                     as_Register(Matcher::_regEncode[src_lo]));
 1848         }
 1849       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1850         if (is64) {
 1851             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1852                      as_Register(Matcher::_regEncode[src_lo]));
 1853         } else {
 1854             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1855                      as_Register(Matcher::_regEncode[src_lo]));
 1856         }
 1857       } else {                    // gpr --&gt; stack spill
 1858         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1859         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1860       }
 1861       break;
 1862     case rc_float:
 1863       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1864         if (is64) {
 1865             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
</pre>
<hr />
<pre>
 1935 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1936   implementation(&amp;cbuf, ra_, false, NULL);
 1937 }
 1938 
 1939 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1940   return MachNode::size(ra_);
 1941 }
 1942 
 1943 //=============================================================================
 1944 
 1945 #ifndef PRODUCT
 1946 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1947   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1948   int reg = ra_-&gt;get_reg_first(this);
 1949   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1950             Matcher::regName[reg], offset);
 1951 }
 1952 #endif
 1953 
 1954 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
<span class="line-modified"> 1955   MacroAssembler _masm(&amp;cbuf);</span>
 1956 
 1957   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1958   int reg    = ra_-&gt;get_encode(this);
 1959 
 1960   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1961     __ add(as_Register(reg), sp, offset);
 1962   } else {
 1963     ShouldNotReachHere();
 1964   }
 1965 }
 1966 
 1967 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1968   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1969   return 4;
 1970 }
 1971 
 1972 //=============================================================================
 1973 
 1974 #ifndef PRODUCT
 1975 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1976 {
 1977   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1978   if (UseCompressedClassPointers) {
 1979     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1980     if (CompressedKlassPointers::shift() != 0) {
 1981       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1982     }
 1983   } else {
 1984    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1985   }
 1986   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1987   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 1988 }
 1989 #endif
 1990 
 1991 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 1992 {
 1993   // This is the unverified entry point.
<span class="line-modified"> 1994   MacroAssembler _masm(&amp;cbuf);</span>
 1995 
 1996   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 1997   Label skip;
 1998   // TODO
 1999   // can we avoid this skip and still use a reloc?
 2000   __ br(Assembler::EQ, skip);
 2001   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2002   __ bind(skip);
 2003 }
 2004 
 2005 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2006 {
 2007   return MachNode::size(ra_);
 2008 }
 2009 
 2010 // REQUIRED EMIT CODE
 2011 
 2012 //=============================================================================
 2013 
 2014 // Emit exception handler code.
 2015 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2016 {
 2017   // mov rscratch1 #exception_blob_entry_point
 2018   // br rscratch1
 2019   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2020   // That&#39;s why we must use the macroassembler to generate a handler.
<span class="line-modified"> 2021   MacroAssembler _masm(&amp;cbuf);</span>
 2022   address base = __ start_a_stub(size_exception_handler());
 2023   if (base == NULL) {
 2024     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2025     return 0;  // CodeBuffer::expand failed
 2026   }
 2027   int offset = __ offset();
 2028   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2029   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2030   __ end_a_stub();
 2031   return offset;
 2032 }
 2033 
 2034 // Emit deopt handler code.
 2035 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2036 {
 2037   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2038   // That&#39;s why we must use the macroassembler to generate a handler.
<span class="line-modified"> 2039   MacroAssembler _masm(&amp;cbuf);</span>
 2040   address base = __ start_a_stub(size_deopt_handler());
 2041   if (base == NULL) {
 2042     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2043     return 0;  // CodeBuffer::expand failed
 2044   }
 2045   int offset = __ offset();
 2046 
 2047   __ adr(lr, __ pc());
 2048   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2049 
 2050   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2051   __ end_a_stub();
 2052   return offset;
 2053 }
 2054 
 2055 // REQUIRED MATCHER CODE
 2056 
 2057 //=============================================================================
 2058 
 2059 const bool Matcher::match_rule_supported(int opcode) {
</pre>
<hr />
<pre>
 2340 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2341   return FP_REG_mask();
 2342 }
 2343 
 2344 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2345   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2346     Node* u = addp-&gt;fast_out(i);
 2347     if (u-&gt;is_Mem()) {
 2348       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2349       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2350       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2351         return false;
 2352       }
 2353     }
 2354   }
 2355   return true;
 2356 }
 2357 
 2358 const bool Matcher::convi2l_type_required = false;
 2359 









 2360 // Should the Matcher clone shifts on addressing modes, expecting them
 2361 // to be subsumed into complex addressing expressions or compute them
 2362 // into registers?
<span class="line-modified"> 2363 bool Matcher::clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {</span>
 2364   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2365     return true;
 2366   }
 2367 
 2368   Node *off = m-&gt;in(AddPNode::Offset);
 2369   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2370       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2371       // Are there other uses besides address expressions?
 2372       !is_visited(off)) {
 2373     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2374     mstack.push(off-&gt;in(2), Visit);
 2375     Node *conv = off-&gt;in(1);
 2376     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2377         // Are there other uses besides address expressions?
 2378         !is_visited(conv)) {
 2379       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2380       mstack.push(conv-&gt;in(1), Pre_Visit);
 2381     } else {
 2382       mstack.push(conv, Pre_Visit);
 2383     }
</pre>
<hr />
<pre>
 2386     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2387     return true;
 2388   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2389              // Are there other uses besides address expressions?
 2390              !is_visited(off)) {
 2391     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2392     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2393     mstack.push(off-&gt;in(1), Pre_Visit);
 2394     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2395     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2396     return true;
 2397   }
 2398   return false;
 2399 }
 2400 
 2401 void Compile::reshape_address(AddPNode* addp) {
 2402 }
 2403 
 2404 
 2405 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
<span class="line-modified"> 2406   MacroAssembler _masm(&amp;cbuf);                                          \</span>
 2407   {                                                                     \
 2408     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2409     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2410     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2411     __ INSN(REG, as_Register(BASE));                                    \
 2412   }
 2413 
 2414 
 2415 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2416   {
 2417     Address::extend scale;
 2418 
 2419     // Hooboy, this is fugly.  We need a way to communicate to the
 2420     // encoder that the index needs to be sign extended, so we have to
 2421     // enumerate all the cases.
 2422     switch (opcode) {
 2423     case INDINDEXSCALEDI2L:
 2424     case INDINDEXSCALEDI2LN:
 2425     case INDINDEXI2L:
 2426     case INDINDEXI2LN:
</pre>
<hr />
<pre>
 2431     }
 2432 
 2433     if (index == -1) {
 2434       return Address(base, disp);
 2435     } else {
 2436       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2437       return Address(base, as_Register(index), scale);
 2438     }
 2439   }
 2440 
 2441 
 2442 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2443 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2444 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2445 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2446                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2447 
 2448   // Used for all non-volatile memory accesses.  The use of
 2449   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2450   // offsets is something of a kludge.
<span class="line-modified"> 2451   static void loadStore(MacroAssembler masm, mem_insn insn,</span>
 2452                         Register reg, int opcode,
 2453                         Register base, int index, int scale, int disp,
 2454                         int size_in_memory)
 2455   {
 2456     Address addr = mem2address(opcode, base, index, scale, disp);
 2457     if (addr.getMode() == Address::base_plus_offset) {
 2458       /* If we get an out-of-range offset it is a bug in the compiler,
 2459          so we assert here. */
 2460       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2461              &quot;c2 compiler bug&quot;);
 2462       /* Fix up any out-of-range offsets. */
 2463       assert_different_registers(rscratch1, base);
 2464       assert_different_registers(rscratch1, reg);
 2465       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2466     }
 2467     (masm.*insn)(reg, addr);
 2468   }
 2469 
<span class="line-modified"> 2470   static void loadStore(MacroAssembler masm, mem_float_insn insn,</span>
 2471                         FloatRegister reg, int opcode,
 2472                         Register base, int index, int size, int disp,
 2473                         int size_in_memory)
 2474   {
 2475     Address::extend scale;
 2476 
 2477     switch (opcode) {
 2478     case INDINDEXSCALEDI2L:
 2479     case INDINDEXSCALEDI2LN:
 2480       scale = Address::sxtw(size);
 2481       break;
 2482     default:
 2483       scale = Address::lsl(size);
 2484     }
 2485 
 2486     if (index == -1) {
 2487       /* If we get an out-of-range offset it is a bug in the compiler,
 2488          so we assert here. */
 2489       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2490       /* Fix up any out-of-range offsets. */
 2491       assert_different_registers(rscratch1, base);
 2492       Address addr = Address(base, disp);
 2493       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2494       (masm.*insn)(reg, addr);
 2495     } else {
 2496       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2497       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2498     }
 2499   }
 2500 
<span class="line-modified"> 2501   static void loadStore(MacroAssembler masm, mem_vector_insn insn,</span>
 2502                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2503                         int opcode, Register base, int index, int size, int disp)
 2504   {
 2505     if (index == -1) {
 2506       (masm.*insn)(reg, T, Address(base, disp));
 2507     } else {
 2508       assert(disp == 0, &quot;unsupported address mode&quot;);
 2509       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2510     }
 2511   }
 2512 
 2513 %}
 2514 
 2515 
 2516 
 2517 //----------ENCODING BLOCK-----------------------------------------------------
 2518 // This block specifies the encoding classes used by the compiler to
 2519 // output byte streams.  Encoding classes are parameterized macros
 2520 // used by Machine Instruction Nodes in order to generate the bit
 2521 // encoding of the instruction.  Operands specify their base encoding
</pre>
<hr />
<pre>
 2534 //
 2535 // Instructions specify two basic values for encoding.  Again, a
 2536 // function is available to check if the constant displacement is an
 2537 // oop. They use the ins_encode keyword to specify their encoding
 2538 // classes (which must be a sequence of enc_class names, and their
 2539 // parameters, specified in the encoding block), and they use the
 2540 // opcode keyword to specify, in order, their primary, secondary, and
 2541 // tertiary opcode.  Only the opcode sections which a particular
 2542 // instruction needs for encoding need to be specified.
 2543 encode %{
 2544   // Build emit functions for each basic byte or larger field in the
 2545   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2546   // from C++ code in the enc_class source block.  Emit functions will
 2547   // live in the main source block for now.  In future, we can
 2548   // generalize this by adding a syntax that specifies the sizes of
 2549   // fields in an order, so that the adlc can build the emit functions
 2550   // automagically
 2551 
 2552   // catch all for unimplemented encodings
 2553   enc_class enc_unimplemented %{
<span class="line-modified"> 2554     MacroAssembler _masm(&amp;cbuf);</span>
 2555     __ unimplemented(&quot;C2 catch all&quot;);
 2556   %}
 2557 
 2558   // BEGIN Non-volatile memory access
 2559 
 2560   // This encoding class is generated automatically from ad_encode.m4.
 2561   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2562   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2563     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2564     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),</span>
 2565                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2566   %}
 2567 
 2568   // This encoding class is generated automatically from ad_encode.m4.
 2569   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2570   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2571     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2572     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),</span>
 2573                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2574   %}
 2575 
 2576   // This encoding class is generated automatically from ad_encode.m4.
 2577   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2578   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2579     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2580     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),</span>
 2581                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2582   %}
 2583 
 2584   // This encoding class is generated automatically from ad_encode.m4.
 2585   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2586   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2587     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2588     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),</span>
 2589                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2590   %}
 2591 
 2592   // This encoding class is generated automatically from ad_encode.m4.
 2593   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2594   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2595     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2596     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),</span>
 2597                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2598   %}
 2599 
 2600   // This encoding class is generated automatically from ad_encode.m4.
 2601   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2602   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2603     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2604     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),</span>
 2605                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2606   %}
 2607 
 2608   // This encoding class is generated automatically from ad_encode.m4.
 2609   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2610   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2611     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2612     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),</span>
 2613                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2614   %}
 2615 
 2616   // This encoding class is generated automatically from ad_encode.m4.
 2617   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2618   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2619     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2620     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),</span>
 2621                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2622   %}
 2623 
 2624   // This encoding class is generated automatically from ad_encode.m4.
 2625   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2626   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2627     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2628     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),</span>
 2629                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2630   %}
 2631 
 2632   // This encoding class is generated automatically from ad_encode.m4.
 2633   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2634   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2635     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2636     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),</span>
 2637                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2638   %}
 2639 
 2640   // This encoding class is generated automatically from ad_encode.m4.
 2641   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2642   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2643     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2644     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),</span>
 2645                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2646   %}
 2647 
 2648   // This encoding class is generated automatically from ad_encode.m4.
 2649   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2650   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2651     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2652     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),</span>
 2653                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2654   %}
 2655 
 2656   // This encoding class is generated automatically from ad_encode.m4.
 2657   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2658   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2659     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2660     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),</span>
 2661                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2662   %}
 2663 
 2664   // This encoding class is generated automatically from ad_encode.m4.
 2665   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2666   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2667     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2668     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),</span>
 2669                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2670   %}
 2671 
 2672   // This encoding class is generated automatically from ad_encode.m4.
 2673   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2674   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2675     Register src_reg = as_Register($src$$reg);
<span class="line-modified"> 2676     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),</span>
 2677                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2678   %}
 2679 
 2680   // This encoding class is generated automatically from ad_encode.m4.
 2681   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2682   enc_class aarch64_enc_strb0(memory1 mem) %{
<span class="line-modified"> 2683     MacroAssembler _masm(&amp;cbuf);</span>
 2684     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2685                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2686   %}
 2687 
 2688   // This encoding class is generated automatically from ad_encode.m4.
 2689   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2690   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2691     Register src_reg = as_Register($src$$reg);
<span class="line-modified"> 2692     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),</span>
 2693                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2694   %}
 2695 
 2696   // This encoding class is generated automatically from ad_encode.m4.
 2697   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2698   enc_class aarch64_enc_strh0(memory2 mem) %{
<span class="line-modified"> 2699     MacroAssembler _masm(&amp;cbuf);</span>
 2700     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2701                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2702   %}
 2703 
 2704   // This encoding class is generated automatically from ad_encode.m4.
 2705   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2706   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2707     Register src_reg = as_Register($src$$reg);
<span class="line-modified"> 2708     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),</span>
 2709                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2710   %}
 2711 
 2712   // This encoding class is generated automatically from ad_encode.m4.
 2713   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2714   enc_class aarch64_enc_strw0(memory4 mem) %{
<span class="line-modified"> 2715     MacroAssembler _masm(&amp;cbuf);</span>
 2716     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2717                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2718   %}
 2719 
 2720   // This encoding class is generated automatically from ad_encode.m4.
 2721   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2722   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2723     Register src_reg = as_Register($src$$reg);
 2724     // we sometimes get asked to store the stack pointer into the
 2725     // current thread -- we cannot do that directly on AArch64
 2726     if (src_reg == r31_sp) {
<span class="line-modified"> 2727       MacroAssembler _masm(&amp;cbuf);</span>
 2728       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2729       __ mov(rscratch2, sp);
 2730       src_reg = rscratch2;
 2731     }
<span class="line-modified"> 2732     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),</span>
 2733                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2734   %}
 2735 
 2736   // This encoding class is generated automatically from ad_encode.m4.
 2737   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2738   enc_class aarch64_enc_str0(memory8 mem) %{
<span class="line-modified"> 2739     MacroAssembler _masm(&amp;cbuf);</span>
 2740     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2741                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2742   %}
 2743 
 2744   // This encoding class is generated automatically from ad_encode.m4.
 2745   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2746   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2747     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2748     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),</span>
 2749                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2750   %}
 2751 
 2752   // This encoding class is generated automatically from ad_encode.m4.
 2753   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2754   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2755     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2756     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),</span>
 2757                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2758   %}
 2759 
 2760   // This encoding class is generated automatically from ad_encode.m4.
 2761   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2762   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
<span class="line-modified"> 2763     MacroAssembler _masm(&amp;cbuf);</span>
 2764     address con = (address)$src$$constant;
 2765     // need to do this the hard way until we can manage relocs
 2766     // for 32 bit constants
 2767     __ movoop(rscratch2, (jobject)con);
 2768     if (con) __ encode_heap_oop_not_null(rscratch2);
 2769     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2770                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2771   %}
 2772 
 2773   // This encoding class is generated automatically from ad_encode.m4.
 2774   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2775   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
<span class="line-modified"> 2776     MacroAssembler _masm(&amp;cbuf);</span>
 2777     address con = (address)$src$$constant;
 2778     // need to do this the hard way until we can manage relocs
 2779     // for 32 bit constants
 2780     __ movoop(rscratch2, (jobject)con);
 2781     __ encode_klass_not_null(rscratch2);
 2782     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2783                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2784   %}
 2785 
 2786   // This encoding class is generated automatically from ad_encode.m4.
 2787   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2788   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
<span class="line-modified"> 2789       MacroAssembler _masm(&amp;cbuf);</span>
 2790       __ membar(Assembler::StoreStore);
 2791       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2792                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2793   %}
 2794 
 2795   // END Non-volatile memory access
 2796 
 2797   // Vector loads and stores
 2798   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2799     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2800     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,</span>
 2801        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2802   %}
 2803 
 2804   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2805     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2806     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,</span>
 2807        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2808   %}
 2809 
 2810   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2811     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2812     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,</span>
 2813        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2814   %}
 2815 
 2816   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2817     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2818     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,</span>
 2819        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2820   %}
 2821 
 2822   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2823     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2824     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,</span>
 2825        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2826   %}
 2827 
 2828   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2829     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2830     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,</span>
 2831        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2832   %}
 2833 
 2834   // volatile loads and stores
 2835 
 2836   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2837     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2838                  rscratch1, stlrb);
 2839   %}
 2840 
 2841   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2842     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2843                  rscratch1, stlrh);
 2844   %}
 2845 
 2846   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2847     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2848                  rscratch1, stlrw);
 2849   %}
 2850 
</pre>
<hr />
<pre>
 2912              rscratch1, ldar);
 2913   %}
 2914 
 2915   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2916     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2917              rscratch1, ldarw);
 2918     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2919   %}
 2920 
 2921   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2922     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2923              rscratch1, ldar);
 2924     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2925   %}
 2926 
 2927   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2928     Register src_reg = as_Register($src$$reg);
 2929     // we sometimes get asked to store the stack pointer into the
 2930     // current thread -- we cannot do that directly on AArch64
 2931     if (src_reg == r31_sp) {
<span class="line-modified"> 2932         MacroAssembler _masm(&amp;cbuf);</span>
 2933       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2934       __ mov(rscratch2, sp);
 2935       src_reg = rscratch2;
 2936     }
 2937     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2938                  rscratch1, stlr);
 2939   %}
 2940 
 2941   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2942     {
<span class="line-modified"> 2943       MacroAssembler _masm(&amp;cbuf);</span>
 2944       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2945       __ fmovs(rscratch2, src_reg);
 2946     }
 2947     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2948                  rscratch1, stlrw);
 2949   %}
 2950 
 2951   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2952     {
<span class="line-modified"> 2953       MacroAssembler _masm(&amp;cbuf);</span>
 2954       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2955       __ fmovd(rscratch2, src_reg);
 2956     }
 2957     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2958                  rscratch1, stlr);
 2959   %}
 2960 
 2961   // synchronized read/update encodings
 2962 
 2963   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
<span class="line-modified"> 2964     MacroAssembler _masm(&amp;cbuf);</span>
 2965     Register dst_reg = as_Register($dst$$reg);
 2966     Register base = as_Register($mem$$base);
 2967     int index = $mem$$index;
 2968     int scale = $mem$$scale;
 2969     int disp = $mem$$disp;
 2970     if (index == -1) {
 2971        if (disp != 0) {
 2972         __ lea(rscratch1, Address(base, disp));
 2973         __ ldaxr(dst_reg, rscratch1);
 2974       } else {
 2975         // TODO
 2976         // should we ever get anything other than this case?
 2977         __ ldaxr(dst_reg, base);
 2978       }
 2979     } else {
 2980       Register index_reg = as_Register(index);
 2981       if (disp == 0) {
 2982         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 2983         __ ldaxr(dst_reg, rscratch1);
 2984       } else {
 2985         __ lea(rscratch1, Address(base, disp));
 2986         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 2987         __ ldaxr(dst_reg, rscratch1);
 2988       }
 2989     }
 2990   %}
 2991 
 2992   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
<span class="line-modified"> 2993     MacroAssembler _masm(&amp;cbuf);</span>
 2994     Register src_reg = as_Register($src$$reg);
 2995     Register base = as_Register($mem$$base);
 2996     int index = $mem$$index;
 2997     int scale = $mem$$scale;
 2998     int disp = $mem$$disp;
 2999     if (index == -1) {
 3000        if (disp != 0) {
 3001         __ lea(rscratch2, Address(base, disp));
 3002         __ stlxr(rscratch1, src_reg, rscratch2);
 3003       } else {
 3004         // TODO
 3005         // should we ever get anything other than this case?
 3006         __ stlxr(rscratch1, src_reg, base);
 3007       }
 3008     } else {
 3009       Register index_reg = as_Register(index);
 3010       if (disp == 0) {
 3011         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3012         __ stlxr(rscratch1, src_reg, rscratch2);
 3013       } else {
 3014         __ lea(rscratch2, Address(base, disp));
 3015         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3016         __ stlxr(rscratch1, src_reg, rscratch2);
 3017       }
 3018     }
 3019     __ cmpw(rscratch1, zr);
 3020   %}
 3021 
 3022   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
<span class="line-modified"> 3023     MacroAssembler _masm(&amp;cbuf);</span>
 3024     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3025     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3026                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3027                /*weak*/ false, noreg);
 3028   %}
 3029 
 3030   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3031     MacroAssembler _masm(&amp;cbuf);</span>
 3032     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3033     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3034                Assembler::word, /*acquire*/ false, /*release*/ true,
 3035                /*weak*/ false, noreg);
 3036   %}
 3037 
 3038   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3039     MacroAssembler _masm(&amp;cbuf);</span>
 3040     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3041     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3042                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3043                /*weak*/ false, noreg);
 3044   %}
 3045 
 3046   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3047     MacroAssembler _masm(&amp;cbuf);</span>
 3048     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3049     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3050                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3051                /*weak*/ false, noreg);
 3052   %}
 3053 
 3054 
 3055   // The only difference between aarch64_enc_cmpxchg and
 3056   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3057   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3058   // lock.
 3059   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
<span class="line-modified"> 3060     MacroAssembler _masm(&amp;cbuf);</span>
 3061     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3062     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3063                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3064                /*weak*/ false, noreg);
 3065   %}
 3066 
 3067   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3068     MacroAssembler _masm(&amp;cbuf);</span>
 3069     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3070     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3071                Assembler::word, /*acquire*/ true, /*release*/ true,
 3072                /*weak*/ false, noreg);
 3073   %}
 3074 
 3075   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3076     MacroAssembler _masm(&amp;cbuf);</span>
 3077     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3078     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3079                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3080                /*weak*/ false, noreg);
 3081   %}
 3082 
 3083   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3084     MacroAssembler _masm(&amp;cbuf);</span>
 3085     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3086     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3087                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3088                /*weak*/ false, noreg);
 3089   %}
 3090 
 3091   // auxiliary used for CompareAndSwapX to set result register
 3092   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
<span class="line-modified"> 3093     MacroAssembler _masm(&amp;cbuf);</span>
 3094     Register res_reg = as_Register($res$$reg);
 3095     __ cset(res_reg, Assembler::EQ);
 3096   %}
 3097 
 3098   // prefetch encodings
 3099 
 3100   enc_class aarch64_enc_prefetchw(memory mem) %{
<span class="line-modified"> 3101     MacroAssembler _masm(&amp;cbuf);</span>
 3102     Register base = as_Register($mem$$base);
 3103     int index = $mem$$index;
 3104     int scale = $mem$$scale;
 3105     int disp = $mem$$disp;
 3106     if (index == -1) {
 3107       __ prfm(Address(base, disp), PSTL1KEEP);
 3108     } else {
 3109       Register index_reg = as_Register(index);
 3110       if (disp == 0) {
 3111         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3112       } else {
 3113         __ lea(rscratch1, Address(base, disp));
 3114 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3115       }
 3116     }
 3117   %}
 3118 
 3119   /// mov envcodings
 3120 
 3121   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
<span class="line-modified"> 3122     MacroAssembler _masm(&amp;cbuf);</span>
 3123     u_int32_t con = (u_int32_t)$src$$constant;
 3124     Register dst_reg = as_Register($dst$$reg);
 3125     if (con == 0) {
 3126       __ movw(dst_reg, zr);
 3127     } else {
 3128       __ movw(dst_reg, con);
 3129     }
 3130   %}
 3131 
 3132   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
<span class="line-modified"> 3133     MacroAssembler _masm(&amp;cbuf);</span>
 3134     Register dst_reg = as_Register($dst$$reg);
 3135     u_int64_t con = (u_int64_t)$src$$constant;
 3136     if (con == 0) {
 3137       __ mov(dst_reg, zr);
 3138     } else {
 3139       __ mov(dst_reg, con);
 3140     }
 3141   %}
 3142 
 3143   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
<span class="line-modified"> 3144     MacroAssembler _masm(&amp;cbuf);</span>
 3145     Register dst_reg = as_Register($dst$$reg);
 3146     address con = (address)$src$$constant;
 3147     if (con == NULL || con == (address)1) {
 3148       ShouldNotReachHere();
 3149     } else {
 3150       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3151       if (rtype == relocInfo::oop_type) {
 3152         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3153       } else if (rtype == relocInfo::metadata_type) {
 3154         __ mov_metadata(dst_reg, (Metadata*)con);
 3155       } else {
 3156         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3157         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3158           __ mov(dst_reg, con);
 3159         } else {
 3160           unsigned long offset;
 3161           __ adrp(dst_reg, con, offset);
 3162           __ add(dst_reg, dst_reg, offset);
 3163         }
 3164       }
 3165     }
 3166   %}
 3167 
 3168   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
<span class="line-modified"> 3169     MacroAssembler _masm(&amp;cbuf);</span>
 3170     Register dst_reg = as_Register($dst$$reg);
 3171     __ mov(dst_reg, zr);
 3172   %}
 3173 
 3174   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
<span class="line-modified"> 3175     MacroAssembler _masm(&amp;cbuf);</span>
 3176     Register dst_reg = as_Register($dst$$reg);
 3177     __ mov(dst_reg, (u_int64_t)1);
 3178   %}
 3179 
<span class="line-removed"> 3180   enc_class aarch64_enc_mov_poll_page(iRegP dst, immPollPage src) %{</span>
<span class="line-removed"> 3181     MacroAssembler _masm(&amp;cbuf);</span>
<span class="line-removed"> 3182     address page = (address)$src$$constant;</span>
<span class="line-removed"> 3183     Register dst_reg = as_Register($dst$$reg);</span>
<span class="line-removed"> 3184     unsigned long off;</span>
<span class="line-removed"> 3185     __ adrp(dst_reg, Address(page, relocInfo::poll_type), off);</span>
<span class="line-removed"> 3186     assert(off == 0, &quot;assumed offset == 0&quot;);</span>
<span class="line-removed"> 3187   %}</span>
<span class="line-removed"> 3188 </span>
 3189   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
<span class="line-modified"> 3190     MacroAssembler _masm(&amp;cbuf);</span>
 3191     __ load_byte_map_base($dst$$Register);
 3192   %}
 3193 
 3194   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
<span class="line-modified"> 3195     MacroAssembler _masm(&amp;cbuf);</span>
 3196     Register dst_reg = as_Register($dst$$reg);
 3197     address con = (address)$src$$constant;
 3198     if (con == NULL) {
 3199       ShouldNotReachHere();
 3200     } else {
 3201       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3202       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3203       __ set_narrow_oop(dst_reg, (jobject)con);
 3204     }
 3205   %}
 3206 
 3207   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
<span class="line-modified"> 3208     MacroAssembler _masm(&amp;cbuf);</span>
 3209     Register dst_reg = as_Register($dst$$reg);
 3210     __ mov(dst_reg, zr);
 3211   %}
 3212 
 3213   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
<span class="line-modified"> 3214     MacroAssembler _masm(&amp;cbuf);</span>
 3215     Register dst_reg = as_Register($dst$$reg);
 3216     address con = (address)$src$$constant;
 3217     if (con == NULL) {
 3218       ShouldNotReachHere();
 3219     } else {
 3220       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3221       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3222       __ set_narrow_klass(dst_reg, (Klass *)con);
 3223     }
 3224   %}
 3225 
 3226   // arithmetic encodings
 3227 
 3228   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
<span class="line-modified"> 3229     MacroAssembler _masm(&amp;cbuf);</span>
 3230     Register dst_reg = as_Register($dst$$reg);
 3231     Register src_reg = as_Register($src1$$reg);
 3232     int32_t con = (int32_t)$src2$$constant;
 3233     // add has primary == 0, subtract has primary == 1
 3234     if ($primary) { con = -con; }
 3235     if (con &lt; 0) {
 3236       __ subw(dst_reg, src_reg, -con);
 3237     } else {
 3238       __ addw(dst_reg, src_reg, con);
 3239     }
 3240   %}
 3241 
 3242   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
<span class="line-modified"> 3243     MacroAssembler _masm(&amp;cbuf);</span>
 3244     Register dst_reg = as_Register($dst$$reg);
 3245     Register src_reg = as_Register($src1$$reg);
 3246     int32_t con = (int32_t)$src2$$constant;
 3247     // add has primary == 0, subtract has primary == 1
 3248     if ($primary) { con = -con; }
 3249     if (con &lt; 0) {
 3250       __ sub(dst_reg, src_reg, -con);
 3251     } else {
 3252       __ add(dst_reg, src_reg, con);
 3253     }
 3254   %}
 3255 
 3256   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3257     MacroAssembler _masm(&amp;cbuf);</span>
 3258    Register dst_reg = as_Register($dst$$reg);
 3259    Register src1_reg = as_Register($src1$$reg);
 3260    Register src2_reg = as_Register($src2$$reg);
 3261     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3262   %}
 3263 
 3264   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3265     MacroAssembler _masm(&amp;cbuf);</span>
 3266    Register dst_reg = as_Register($dst$$reg);
 3267    Register src1_reg = as_Register($src1$$reg);
 3268    Register src2_reg = as_Register($src2$$reg);
 3269     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3270   %}
 3271 
 3272   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3273     MacroAssembler _masm(&amp;cbuf);</span>
 3274    Register dst_reg = as_Register($dst$$reg);
 3275    Register src1_reg = as_Register($src1$$reg);
 3276    Register src2_reg = as_Register($src2$$reg);
 3277     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3278   %}
 3279 
 3280   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3281     MacroAssembler _masm(&amp;cbuf);</span>
 3282    Register dst_reg = as_Register($dst$$reg);
 3283    Register src1_reg = as_Register($src1$$reg);
 3284    Register src2_reg = as_Register($src2$$reg);
 3285     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3286   %}
 3287 
 3288   // compare instruction encodings
 3289 
 3290   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
<span class="line-modified"> 3291     MacroAssembler _masm(&amp;cbuf);</span>
 3292     Register reg1 = as_Register($src1$$reg);
 3293     Register reg2 = as_Register($src2$$reg);
 3294     __ cmpw(reg1, reg2);
 3295   %}
 3296 
 3297   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
<span class="line-modified"> 3298     MacroAssembler _masm(&amp;cbuf);</span>
 3299     Register reg = as_Register($src1$$reg);
 3300     int32_t val = $src2$$constant;
 3301     if (val &gt;= 0) {
 3302       __ subsw(zr, reg, val);
 3303     } else {
 3304       __ addsw(zr, reg, -val);
 3305     }
 3306   %}
 3307 
 3308   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
<span class="line-modified"> 3309     MacroAssembler _masm(&amp;cbuf);</span>
 3310     Register reg1 = as_Register($src1$$reg);
 3311     u_int32_t val = (u_int32_t)$src2$$constant;
 3312     __ movw(rscratch1, val);
 3313     __ cmpw(reg1, rscratch1);
 3314   %}
 3315 
 3316   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
<span class="line-modified"> 3317     MacroAssembler _masm(&amp;cbuf);</span>
 3318     Register reg1 = as_Register($src1$$reg);
 3319     Register reg2 = as_Register($src2$$reg);
 3320     __ cmp(reg1, reg2);
 3321   %}
 3322 
 3323   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
<span class="line-modified"> 3324     MacroAssembler _masm(&amp;cbuf);</span>
 3325     Register reg = as_Register($src1$$reg);
 3326     int64_t val = $src2$$constant;
 3327     if (val &gt;= 0) {
 3328       __ subs(zr, reg, val);
 3329     } else if (val != -val) {
 3330       __ adds(zr, reg, -val);
 3331     } else {
 3332     // aargh, Long.MIN_VALUE is a special case
 3333       __ orr(rscratch1, zr, (u_int64_t)val);
 3334       __ subs(zr, reg, rscratch1);
 3335     }
 3336   %}
 3337 
 3338   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
<span class="line-modified"> 3339     MacroAssembler _masm(&amp;cbuf);</span>
 3340     Register reg1 = as_Register($src1$$reg);
 3341     u_int64_t val = (u_int64_t)$src2$$constant;
 3342     __ mov(rscratch1, val);
 3343     __ cmp(reg1, rscratch1);
 3344   %}
 3345 
 3346   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
<span class="line-modified"> 3347     MacroAssembler _masm(&amp;cbuf);</span>
 3348     Register reg1 = as_Register($src1$$reg);
 3349     Register reg2 = as_Register($src2$$reg);
 3350     __ cmp(reg1, reg2);
 3351   %}
 3352 
 3353   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
<span class="line-modified"> 3354     MacroAssembler _masm(&amp;cbuf);</span>
 3355     Register reg1 = as_Register($src1$$reg);
 3356     Register reg2 = as_Register($src2$$reg);
 3357     __ cmpw(reg1, reg2);
 3358   %}
 3359 
 3360   enc_class aarch64_enc_testp(iRegP src) %{
<span class="line-modified"> 3361     MacroAssembler _masm(&amp;cbuf);</span>
 3362     Register reg = as_Register($src$$reg);
 3363     __ cmp(reg, zr);
 3364   %}
 3365 
 3366   enc_class aarch64_enc_testn(iRegN src) %{
<span class="line-modified"> 3367     MacroAssembler _masm(&amp;cbuf);</span>
 3368     Register reg = as_Register($src$$reg);
 3369     __ cmpw(reg, zr);
 3370   %}
 3371 
 3372   enc_class aarch64_enc_b(label lbl) %{
<span class="line-modified"> 3373     MacroAssembler _masm(&amp;cbuf);</span>
 3374     Label *L = $lbl$$label;
 3375     __ b(*L);
 3376   %}
 3377 
 3378   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
<span class="line-modified"> 3379     MacroAssembler _masm(&amp;cbuf);</span>
 3380     Label *L = $lbl$$label;
 3381     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3382   %}
 3383 
 3384   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
<span class="line-modified"> 3385     MacroAssembler _masm(&amp;cbuf);</span>
 3386     Label *L = $lbl$$label;
 3387     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3388   %}
 3389 
 3390   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3391   %{
 3392      Register sub_reg = as_Register($sub$$reg);
 3393      Register super_reg = as_Register($super$$reg);
 3394      Register temp_reg = as_Register($temp$$reg);
 3395      Register result_reg = as_Register($result$$reg);
 3396 
 3397      Label miss;
<span class="line-modified"> 3398      MacroAssembler _masm(&amp;cbuf);</span>
 3399      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3400                                      NULL, &amp;miss,
 3401                                      /*set_cond_codes:*/ true);
 3402      if ($primary) {
 3403        __ mov(result_reg, zr);
 3404      }
 3405      __ bind(miss);
 3406   %}
 3407 
 3408   enc_class aarch64_enc_java_static_call(method meth) %{
<span class="line-modified"> 3409     MacroAssembler _masm(&amp;cbuf);</span>
 3410 
 3411     address addr = (address)$meth$$method;
 3412     address call;
 3413     if (!_method) {
 3414       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3415       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3416     } else {
 3417       int method_index = resolved_method_index(cbuf);
 3418       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3419                                                   : static_call_Relocation::spec(method_index);
 3420       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3421 
 3422       // Emit stub for static call
 3423       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3424       if (stub == NULL) {
 3425         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3426         return;
 3427       }
 3428     }
 3429     if (call == NULL) {
 3430       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3431       return;
 3432     }
 3433   %}
 3434 
 3435   enc_class aarch64_enc_java_dynamic_call(method meth) %{
<span class="line-modified"> 3436     MacroAssembler _masm(&amp;cbuf);</span>
 3437     int method_index = resolved_method_index(cbuf);
 3438     address call = __ ic_call((address)$meth$$method, method_index);
 3439     if (call == NULL) {
 3440       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3441       return;
 3442     }
 3443   %}
 3444 
 3445   enc_class aarch64_enc_call_epilog() %{
<span class="line-modified"> 3446     MacroAssembler _masm(&amp;cbuf);</span>
 3447     if (VerifyStackAtCalls) {
 3448       // Check that stack depth is unchanged: find majik cookie on stack
 3449       __ call_Unimplemented();
 3450     }
 3451   %}
 3452 
 3453   enc_class aarch64_enc_java_to_runtime(method meth) %{
<span class="line-modified"> 3454     MacroAssembler _masm(&amp;cbuf);</span>
 3455 
 3456     // some calls to generated routines (arraycopy code) are scheduled
 3457     // by C2 as runtime calls. if so we can call them using a br (they
 3458     // will be in a reachable segment) otherwise we have to use a blr
 3459     // which loads the absolute address into a register.
 3460     address entry = (address)$meth$$method;
 3461     CodeBlob *cb = CodeCache::find_blob(entry);
 3462     if (cb) {
 3463       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3464       if (call == NULL) {
 3465         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3466         return;
 3467       }
 3468     } else {
 3469       Label retaddr;
 3470       __ adr(rscratch2, retaddr);
 3471       __ lea(rscratch1, RuntimeAddress(entry));
 3472       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3473       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3474       __ blr(rscratch1);
 3475       __ bind(retaddr);
 3476       __ add(sp, sp, 2 * wordSize);
 3477     }
 3478   %}
 3479 
 3480   enc_class aarch64_enc_rethrow() %{
<span class="line-modified"> 3481     MacroAssembler _masm(&amp;cbuf);</span>
 3482     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3483   %}
 3484 
 3485   enc_class aarch64_enc_ret() %{
<span class="line-modified"> 3486     MacroAssembler _masm(&amp;cbuf);</span>
 3487     __ ret(lr);
 3488   %}
 3489 
 3490   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
<span class="line-modified"> 3491     MacroAssembler _masm(&amp;cbuf);</span>
 3492     Register target_reg = as_Register($jump_target$$reg);
 3493     __ br(target_reg);
 3494   %}
 3495 
 3496   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
<span class="line-modified"> 3497     MacroAssembler _masm(&amp;cbuf);</span>
 3498     Register target_reg = as_Register($jump_target$$reg);
 3499     // exception oop should be in r0
 3500     // ret addr has been popped into lr
 3501     // callee expects it in r3
 3502     __ mov(r3, lr);
 3503     __ br(target_reg);
 3504   %}
 3505 
 3506   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
<span class="line-modified"> 3507     MacroAssembler _masm(&amp;cbuf);</span>
 3508     Register oop = as_Register($object$$reg);
 3509     Register box = as_Register($box$$reg);
 3510     Register disp_hdr = as_Register($tmp$$reg);
 3511     Register tmp = as_Register($tmp2$$reg);
 3512     Label cont;
 3513     Label object_has_monitor;
 3514     Label cas_failed;
 3515 
 3516     assert_different_registers(oop, box, tmp, disp_hdr);
 3517 
 3518     // Load markWord from object into displaced_header.
 3519     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3520 
 3521     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3522       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3523     }
 3524 
 3525     // Check for existing monitor
 3526     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3527 
</pre>
<hr />
<pre>
 3565     // otherwise m-&gt;owner may contain a thread or a stack address.
 3566     //
 3567     // Try to CAS m-&gt;owner from NULL to current thread.
 3568     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3569     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3570                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3571 
 3572     // Store a non-null value into the box to avoid looking like a re-entrant
 3573     // lock. The fast-path monitor unlock code checks for
 3574     // markWord::monitor_value so use markWord::unused_mark which has the
 3575     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3576     __ mov(tmp, (address)markWord::unused_mark().value());
 3577     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3578 
 3579     __ bind(cont);
 3580     // flag == EQ indicates success
 3581     // flag == NE indicates failure
 3582   %}
 3583 
 3584   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
<span class="line-modified"> 3585     MacroAssembler _masm(&amp;cbuf);</span>
 3586     Register oop = as_Register($object$$reg);
 3587     Register box = as_Register($box$$reg);
 3588     Register disp_hdr = as_Register($tmp$$reg);
 3589     Register tmp = as_Register($tmp2$$reg);
 3590     Label cont;
 3591     Label object_has_monitor;
 3592 
 3593     assert_different_registers(oop, box, tmp, disp_hdr);
 3594 
 3595     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3596       __ biased_locking_exit(oop, tmp, cont);
 3597     }
 3598 
 3599     // Find the lock address and load the displaced header from the stack.
 3600     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3601 
 3602     // If the displaced header is 0, we have a recursive unlock.
 3603     __ cmp(disp_hdr, zr);
 3604     __ br(Assembler::EQ, cont);
 3605 
</pre>
<hr />
<pre>
 4361   predicate(n-&gt;get_ptr() == 0);
 4362   match(ConP);
 4363 
 4364   op_cost(0);
 4365   format %{ %}
 4366   interface(CONST_INTER);
 4367 %}
 4368 
 4369 // Pointer Immediate One
 4370 // this is used in object initialization (initial object header)
 4371 operand immP_1()
 4372 %{
 4373   predicate(n-&gt;get_ptr() == 1);
 4374   match(ConP);
 4375 
 4376   op_cost(0);
 4377   format %{ %}
 4378   interface(CONST_INTER);
 4379 %}
 4380 
<span class="line-removed"> 4381 // Polling Page Pointer Immediate</span>
<span class="line-removed"> 4382 operand immPollPage()</span>
<span class="line-removed"> 4383 %{</span>
<span class="line-removed"> 4384   predicate((address)n-&gt;get_ptr() == os::get_polling_page());</span>
<span class="line-removed"> 4385   match(ConP);</span>
<span class="line-removed"> 4386 </span>
<span class="line-removed"> 4387   op_cost(0);</span>
<span class="line-removed"> 4388   format %{ %}</span>
<span class="line-removed"> 4389   interface(CONST_INTER);</span>
<span class="line-removed"> 4390 %}</span>
<span class="line-removed"> 4391 </span>
 4392 // Card Table Byte Map Base
 4393 operand immByteMapBase()
 4394 %{
 4395   // Get base of card map
 4396   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4397             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4398   match(ConP);
 4399 
 4400   op_cost(0);
 4401   format %{ %}
 4402   interface(CONST_INTER);
 4403 %}
 4404 
 4405 // Pointer Immediate Minus One
 4406 // this is used when we want to write the current PC to the thread anchor
 4407 operand immP_M1()
 4408 %{
 4409   predicate(n-&gt;get_ptr() == -1);
 4410   match(ConP);
 4411 
</pre>
<hr />
<pre>
 7168 
 7169   ins_encode(aarch64_enc_mov_p0(dst, con));
 7170 
 7171   ins_pipe(ialu_imm);
 7172 %}
 7173 
 7174 // Load Pointer Constant One
 7175 
 7176 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7177 %{
 7178   match(Set dst con);
 7179 
 7180   ins_cost(INSN_COST);
 7181   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7182 
 7183   ins_encode(aarch64_enc_mov_p1(dst, con));
 7184 
 7185   ins_pipe(ialu_imm);
 7186 %}
 7187 
<span class="line-removed"> 7188 // Load Poll Page Constant</span>
<span class="line-removed"> 7189 </span>
<span class="line-removed"> 7190 instruct loadConPollPage(iRegPNoSp dst, immPollPage con)</span>
<span class="line-removed"> 7191 %{</span>
<span class="line-removed"> 7192   match(Set dst con);</span>
<span class="line-removed"> 7193 </span>
<span class="line-removed"> 7194   ins_cost(INSN_COST);</span>
<span class="line-removed"> 7195   format %{ &quot;adr  $dst, $con\t# Poll Page Ptr&quot; %}</span>
<span class="line-removed"> 7196 </span>
<span class="line-removed"> 7197   ins_encode(aarch64_enc_mov_poll_page(dst, con));</span>
<span class="line-removed"> 7198 </span>
<span class="line-removed"> 7199   ins_pipe(ialu_imm);</span>
<span class="line-removed"> 7200 %}</span>
<span class="line-removed"> 7201 </span>
 7202 // Load Byte Map Base Constant
 7203 
 7204 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7205 %{
 7206   match(Set dst con);
 7207 
 7208   ins_cost(INSN_COST);
 7209   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7210 
 7211   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7212 
 7213   ins_pipe(ialu_imm);
 7214 %}
 7215 
 7216 // Load Narrow Pointer Constant
 7217 
 7218 instruct loadConN(iRegNNoSp dst, immN con)
 7219 %{
 7220   match(Set dst con);
 7221 
</pre>
<hr />
<pre>
 8058     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8059     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8060     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8061   %}
 8062 
 8063   ins_pipe(pipe_class_default);
 8064 %}
 8065 
 8066 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8067   predicate(UsePopCountInstruction);
 8068   match(Set dst (PopCountI (LoadI mem)));
 8069   effect(TEMP tmp);
 8070   ins_cost(INSN_COST * 13);
 8071 
 8072   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8073             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8074             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8075             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8076   ins_encode %{
 8077     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
<span class="line-modified"> 8078     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),</span>
 8079               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8080     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8081     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8082     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8083   %}
 8084 
 8085   ins_pipe(pipe_class_default);
 8086 %}
 8087 
 8088 // Note: Long.bitCount(long) returns an int.
 8089 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8090   predicate(UsePopCountInstruction);
 8091   match(Set dst (PopCountL src));
 8092   effect(TEMP tmp);
 8093   ins_cost(INSN_COST * 13);
 8094 
 8095   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8096             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8097             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8098             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
</pre>
<hr />
<pre>
 8101     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8102     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8103     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8104   %}
 8105 
 8106   ins_pipe(pipe_class_default);
 8107 %}
 8108 
 8109 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8110   predicate(UsePopCountInstruction);
 8111   match(Set dst (PopCountL (LoadL mem)));
 8112   effect(TEMP tmp);
 8113   ins_cost(INSN_COST * 13);
 8114 
 8115   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8116             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8117             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8118             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8119   ins_encode %{
 8120     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
<span class="line-modified"> 8121     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),</span>
 8122               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8123     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8124     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8125     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8126   %}
 8127 
 8128   ins_pipe(pipe_class_default);
 8129 %}
 8130 
 8131 // ============================================================================
 8132 // MemBar Instruction
 8133 
 8134 instruct load_fence() %{
 8135   match(LoadFence);
 8136   ins_cost(VOLATILE_REF_COST);
 8137 
 8138   format %{ &quot;load_fence&quot; %}
 8139 
 8140   ins_encode %{
 8141     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
</pre>
<hr />
<pre>
14919 %}
14920 
14921 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14922   match(If cmp (CmpI op1 op2));
14923   effect(USE labl);
14924 
14925   ins_cost(BRANCH_COST);
14926   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14927   ins_encode %{
14928     Label* L = $labl$$label;
14929     Assembler::Condition cond =
14930       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14931     __ tbr(cond, $op1$$Register, 31, *L);
14932   %}
14933   ins_pipe(pipe_cmp_branch);
14934   ins_short_branch(1);
14935 %}
14936 
14937 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14938   match(If cmp (CmpL (AndL op1 op2) op3));
<span class="line-modified">14939   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));</span>
14940   effect(USE labl);
14941 
14942   ins_cost(BRANCH_COST);
14943   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14944   ins_encode %{
14945     Label* L = $labl$$label;
14946     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">14947     int bit = exact_log2($op2$$constant);</span>
14948     __ tbr(cond, $op1$$Register, bit, *L);
14949   %}
14950   ins_pipe(pipe_cmp_branch);
14951   ins_short_branch(1);
14952 %}
14953 
14954 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14955   match(If cmp (CmpI (AndI op1 op2) op3));
<span class="line-modified">14956   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));</span>
14957   effect(USE labl);
14958 
14959   ins_cost(BRANCH_COST);
14960   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14961   ins_encode %{
14962     Label* L = $labl$$label;
14963     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">14964     int bit = exact_log2($op2$$constant);</span>
14965     __ tbr(cond, $op1$$Register, bit, *L);
14966   %}
14967   ins_pipe(pipe_cmp_branch);
14968   ins_short_branch(1);
14969 %}
14970 
14971 // And far variants
14972 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14973   match(If cmp (CmpL op1 op2));
14974   effect(USE labl);
14975 
14976   ins_cost(BRANCH_COST);
14977   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14978   ins_encode %{
14979     Label* L = $labl$$label;
14980     Assembler::Condition cond =
14981       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14982     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
14983   %}
14984   ins_pipe(pipe_cmp_branch);
14985 %}
14986 
14987 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14988   match(If cmp (CmpI op1 op2));
14989   effect(USE labl);
14990 
14991   ins_cost(BRANCH_COST);
14992   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14993   ins_encode %{
14994     Label* L = $labl$$label;
14995     Assembler::Condition cond =
14996       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14997     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
14998   %}
14999   ins_pipe(pipe_cmp_branch);
15000 %}
15001 
15002 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
15003   match(If cmp (CmpL (AndL op1 op2) op3));
<span class="line-modified">15004   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));</span>
15005   effect(USE labl);
15006 
15007   ins_cost(BRANCH_COST);
15008   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15009   ins_encode %{
15010     Label* L = $labl$$label;
15011     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">15012     int bit = exact_log2($op2$$constant);</span>
15013     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15014   %}
15015   ins_pipe(pipe_cmp_branch);
15016 %}
15017 
15018 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15019   match(If cmp (CmpI (AndI op1 op2) op3));
<span class="line-modified">15020   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));</span>
15021   effect(USE labl);
15022 
15023   ins_cost(BRANCH_COST);
15024   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15025   ins_encode %{
15026     Label* L = $labl$$label;
15027     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">15028     int bit = exact_log2($op2$$constant);</span>
15029     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15030   %}
15031   ins_pipe(pipe_cmp_branch);
15032 %}
15033 
15034 // Test bits
15035 
15036 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15037   match(Set cr (CmpL (AndL op1 op2) op3));
15038   predicate(Assembler::operand_valid_for_logical_immediate
15039             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15040 
15041   ins_cost(INSN_COST);
15042   format %{ &quot;tst $op1, $op2 # long&quot; %}
15043   ins_encode %{
15044     __ tst($op1$$Register, $op2$$constant);
15045   %}
15046   ins_pipe(ialu_reg_reg);
15047 %}
15048 
</pre>
<hr />
<pre>
16038   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16039   match(Set dst (ReplicateD src));
16040   ins_cost(INSN_COST);
16041   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16042   ins_encode %{
16043     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16044            as_FloatRegister($src$$reg));
16045   %}
16046   ins_pipe(vdup_reg_dreg128);
16047 %}
16048 
16049 // ====================REDUCTION ARITHMETIC====================================
16050 
16051 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp, iRegINoSp tmp2)
16052 %{
16053   match(Set dst (AddReductionVI src1 src2));
16054   ins_cost(INSN_COST);
16055   effect(TEMP tmp, TEMP tmp2);
16056   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16057             &quot;umov  $tmp2, $src2, S, 1\n\t&quot;
<span class="line-modified">16058             &quot;addw  $dst, $src1, $tmp\n\t&quot;</span>
<span class="line-modified">16059             &quot;addw  $dst, $dst, $tmp2\t add reduction2i&quot;</span>
16060   %}
16061   ins_encode %{
16062     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16063     __ umov($tmp2$$Register, as_FloatRegister($src2$$reg), __ S, 1);
<span class="line-modified">16064     __ addw($dst$$Register, $src1$$Register, $tmp$$Register);</span>
<span class="line-modified">16065     __ addw($dst$$Register, $dst$$Register, $tmp2$$Register);</span>
16066   %}
16067   ins_pipe(pipe_class_default);
16068 %}
16069 
16070 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16071 %{
16072   match(Set dst (AddReductionVI src1 src2));
16073   ins_cost(INSN_COST);
16074   effect(TEMP tmp, TEMP tmp2);
16075   format %{ &quot;addv  $tmp, T4S, $src2\n\t&quot;
16076             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
<span class="line-modified">16077             &quot;addw  $dst, $tmp2, $src1\t add reduction4i&quot;</span>
16078   %}
16079   ins_encode %{
16080     __ addv(as_FloatRegister($tmp$$reg), __ T4S,
16081             as_FloatRegister($src2$$reg));
16082     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16083     __ addw($dst$$Register, $tmp2$$Register, $src1$$Register);
16084   %}
16085   ins_pipe(pipe_class_default);
16086 %}
16087 
16088 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp)
16089 %{
16090   match(Set dst (MulReductionVI src1 src2));
16091   ins_cost(INSN_COST);
16092   effect(TEMP tmp, TEMP dst);
16093   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16094             &quot;mul   $dst, $tmp, $src1\n\t&quot;
16095             &quot;umov  $tmp, $src2, S, 1\n\t&quot;
<span class="line-modified">16096             &quot;mul   $dst, $tmp, $dst\t mul reduction2i\n\t&quot;</span>
16097   %}
16098   ins_encode %{
16099     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16100     __ mul($dst$$Register, $tmp$$Register, $src1$$Register);
16101     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16102     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16103   %}
16104   ins_pipe(pipe_class_default);
16105 %}
16106 
16107 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16108 %{
16109   match(Set dst (MulReductionVI src1 src2));
16110   ins_cost(INSN_COST);
16111   effect(TEMP tmp, TEMP tmp2, TEMP dst);
16112   format %{ &quot;ins   $tmp, $src2, 0, 1\n\t&quot;
16113             &quot;mul   $tmp, $tmp, $src2\n\t&quot;
16114             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16115             &quot;mul   $dst, $tmp2, $src1\n\t&quot;
16116             &quot;umov  $tmp2, $tmp, S, 1\n\t&quot;
<span class="line-modified">16117             &quot;mul   $dst, $tmp2, $dst\t mul reduction4i\n\t&quot;</span>
16118   %}
16119   ins_encode %{
16120     __ ins(as_FloatRegister($tmp$$reg), __ D,
16121            as_FloatRegister($src2$$reg), 0, 1);
16122     __ mulv(as_FloatRegister($tmp$$reg), __ T2S,
16123            as_FloatRegister($tmp$$reg), as_FloatRegister($src2$$reg));
16124     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16125     __ mul($dst$$Register, $tmp2$$Register, $src1$$Register);
16126     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 1);
16127     __ mul($dst$$Register, $tmp2$$Register, $dst$$Register);
16128   %}
16129   ins_pipe(pipe_class_default);
16130 %}
16131 
16132 instruct reduce_add2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16133 %{
16134   match(Set dst (AddReductionVF src1 src2));
16135   ins_cost(INSN_COST);
16136   effect(TEMP tmp, TEMP dst);
16137   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16138             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
<span class="line-modified">16139             &quot;fadds $dst, $dst, $tmp\t add reduction2f&quot;</span>
16140   %}
16141   ins_encode %{
16142     __ fadds(as_FloatRegister($dst$$reg),
16143              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16144     __ ins(as_FloatRegister($tmp$$reg), __ S,
16145            as_FloatRegister($src2$$reg), 0, 1);
16146     __ fadds(as_FloatRegister($dst$$reg),
16147              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16148   %}
16149   ins_pipe(pipe_class_default);
16150 %}
16151 
16152 instruct reduce_add4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16153 %{
16154   match(Set dst (AddReductionVF src1 src2));
16155   ins_cost(INSN_COST);
16156   effect(TEMP tmp, TEMP dst);
16157   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16158             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16159             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16160             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16161             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16162             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
<span class="line-modified">16163             &quot;fadds $dst, $dst, $tmp\t add reduction4f&quot;</span>
16164   %}
16165   ins_encode %{
16166     __ fadds(as_FloatRegister($dst$$reg),
16167              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16168     __ ins(as_FloatRegister($tmp$$reg), __ S,
16169            as_FloatRegister($src2$$reg), 0, 1);
16170     __ fadds(as_FloatRegister($dst$$reg),
16171              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16172     __ ins(as_FloatRegister($tmp$$reg), __ S,
16173            as_FloatRegister($src2$$reg), 0, 2);
16174     __ fadds(as_FloatRegister($dst$$reg),
16175              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16176     __ ins(as_FloatRegister($tmp$$reg), __ S,
16177            as_FloatRegister($src2$$reg), 0, 3);
16178     __ fadds(as_FloatRegister($dst$$reg),
16179              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16180   %}
16181   ins_pipe(pipe_class_default);
16182 %}
16183 
16184 instruct reduce_mul2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16185 %{
16186   match(Set dst (MulReductionVF src1 src2));
16187   ins_cost(INSN_COST);
16188   effect(TEMP tmp, TEMP dst);
16189   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16190             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
<span class="line-modified">16191             &quot;fmuls $dst, $dst, $tmp\t add reduction4f&quot;</span>
16192   %}
16193   ins_encode %{
16194     __ fmuls(as_FloatRegister($dst$$reg),
16195              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16196     __ ins(as_FloatRegister($tmp$$reg), __ S,
16197            as_FloatRegister($src2$$reg), 0, 1);
16198     __ fmuls(as_FloatRegister($dst$$reg),
16199              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16200   %}
16201   ins_pipe(pipe_class_default);
16202 %}
16203 
16204 instruct reduce_mul4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16205 %{
16206   match(Set dst (MulReductionVF src1 src2));
16207   ins_cost(INSN_COST);
16208   effect(TEMP tmp, TEMP dst);
16209   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16210             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16211             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16212             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16213             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16214             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
<span class="line-modified">16215             &quot;fmuls $dst, $dst, $tmp\t add reduction4f&quot;</span>
16216   %}
16217   ins_encode %{
16218     __ fmuls(as_FloatRegister($dst$$reg),
16219              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16220     __ ins(as_FloatRegister($tmp$$reg), __ S,
16221            as_FloatRegister($src2$$reg), 0, 1);
16222     __ fmuls(as_FloatRegister($dst$$reg),
16223              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16224     __ ins(as_FloatRegister($tmp$$reg), __ S,
16225            as_FloatRegister($src2$$reg), 0, 2);
16226     __ fmuls(as_FloatRegister($dst$$reg),
16227              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16228     __ ins(as_FloatRegister($tmp$$reg), __ S,
16229            as_FloatRegister($src2$$reg), 0, 3);
16230     __ fmuls(as_FloatRegister($dst$$reg),
16231              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16232   %}
16233   ins_pipe(pipe_class_default);
16234 %}
16235 
16236 instruct reduce_add2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16237 %{
16238   match(Set dst (AddReductionVD src1 src2));
16239   ins_cost(INSN_COST);
16240   effect(TEMP tmp, TEMP dst);
16241   format %{ &quot;faddd $dst, $src1, $src2\n\t&quot;
16242             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
<span class="line-modified">16243             &quot;faddd $dst, $dst, $tmp\t add reduction2d&quot;</span>
16244   %}
16245   ins_encode %{
16246     __ faddd(as_FloatRegister($dst$$reg),
16247              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16248     __ ins(as_FloatRegister($tmp$$reg), __ D,
16249            as_FloatRegister($src2$$reg), 0, 1);
16250     __ faddd(as_FloatRegister($dst$$reg),
16251              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16252   %}
16253   ins_pipe(pipe_class_default);
16254 %}
16255 
16256 instruct reduce_mul2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16257 %{
16258   match(Set dst (MulReductionVD src1 src2));
16259   ins_cost(INSN_COST);
16260   effect(TEMP tmp, TEMP dst);
16261   format %{ &quot;fmuld $dst, $src1, $src2\n\t&quot;
16262             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
<span class="line-modified">16263             &quot;fmuld $dst, $dst, $tmp\t add reduction2d&quot;</span>
16264   %}
16265   ins_encode %{
16266     __ fmuld(as_FloatRegister($dst$$reg),
16267              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16268     __ ins(as_FloatRegister($tmp$$reg), __ D,
16269            as_FloatRegister($src2$$reg), 0, 1);
16270     __ fmuld(as_FloatRegister($dst$$reg),
16271              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16272   %}
16273   ins_pipe(pipe_class_default);
16274 %}
16275 
16276 instruct reduce_max2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16277   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16278   match(Set dst (MaxReductionV src1 src2));
16279   ins_cost(INSN_COST);
16280   effect(TEMP_DEF dst, TEMP tmp);
16281   format %{ &quot;fmaxs $dst, $src1, $src2\n\t&quot;
16282             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
<span class="line-modified">16283             &quot;fmaxs $dst, $dst, $tmp\t max reduction2F&quot; %}</span>
16284   ins_encode %{
16285     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16286     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16287     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16288   %}
16289   ins_pipe(pipe_class_default);
16290 %}
16291 
16292 instruct reduce_max4F(vRegF dst, vRegF src1, vecX src2) %{
16293   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16294   match(Set dst (MaxReductionV src1 src2));
16295   ins_cost(INSN_COST);
16296   effect(TEMP_DEF dst);
16297   format %{ &quot;fmaxv $dst, T4S, $src2\n\t&quot;
<span class="line-modified">16298             &quot;fmaxs $dst, $dst, $src1\t max reduction4F&quot; %}</span>
16299   ins_encode %{
16300     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16301     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16302   %}
16303   ins_pipe(pipe_class_default);
16304 %}
16305 
16306 instruct reduce_max2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16307   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16308   match(Set dst (MaxReductionV src1 src2));
16309   ins_cost(INSN_COST);
16310   effect(TEMP_DEF dst, TEMP tmp);
16311   format %{ &quot;fmaxd $dst, $src1, $src2\n\t&quot;
16312             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
<span class="line-modified">16313             &quot;fmaxd $dst, $dst, $tmp\t max reduction2D&quot; %}</span>
16314   ins_encode %{
16315     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16316     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16317     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16318   %}
16319   ins_pipe(pipe_class_default);
16320 %}
16321 
16322 instruct reduce_min2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16323   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16324   match(Set dst (MinReductionV src1 src2));
16325   ins_cost(INSN_COST);
16326   effect(TEMP_DEF dst, TEMP tmp);
16327   format %{ &quot;fmins $dst, $src1, $src2\n\t&quot;
16328             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
<span class="line-modified">16329             &quot;fmins $dst, $dst, $tmp\t min reduction2F&quot; %}</span>
16330   ins_encode %{
16331     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16332     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16333     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16334   %}
16335   ins_pipe(pipe_class_default);
16336 %}
16337 
16338 instruct reduce_min4F(vRegF dst, vRegF src1, vecX src2) %{
16339   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16340   match(Set dst (MinReductionV src1 src2));
16341   ins_cost(INSN_COST);
16342   effect(TEMP_DEF dst);
16343   format %{ &quot;fminv $dst, T4S, $src2\n\t&quot;
<span class="line-modified">16344             &quot;fmins $dst, $dst, $src1\t min reduction4F&quot; %}</span>
16345   ins_encode %{
16346     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16347     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16348   %}
16349   ins_pipe(pipe_class_default);
16350 %}
16351 
16352 instruct reduce_min2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16353   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16354   match(Set dst (MinReductionV src1 src2));
16355   ins_cost(INSN_COST);
16356   effect(TEMP_DEF dst, TEMP tmp);
16357   format %{ &quot;fmind $dst, $src1, $src2\n\t&quot;
16358             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
<span class="line-modified">16359             &quot;fmind $dst, $dst, $tmp\t min reduction2D&quot; %}</span>
16360   ins_encode %{
16361     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16362     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16363     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16364   %}
16365   ins_pipe(pipe_class_default);
16366 %}
16367 
16368 // ====================VECTOR ARITHMETIC=======================================
16369 
16370 // --------------------------------- ADD --------------------------------------
16371 
16372 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16373 %{
16374   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16375             n-&gt;as_Vector()-&gt;length() == 8);
16376   match(Set dst (AddVB src1 src2));
16377   ins_cost(INSN_COST);
16378   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16379   ins_encode %{
</pre>
<hr />
<pre>
16949 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16950   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16951   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16952   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16953   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16954   ins_cost(INSN_COST);
16955   ins_encode %{
16956     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16957             as_FloatRegister($src1$$reg),
16958             as_FloatRegister($src2$$reg));
16959   %}
16960   ins_pipe(vmuldiv_fp128);
16961 %}
16962 
16963 // --------------- Vector Multiply-Add Shorts into Integer --------------------
16964 
16965 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
16966   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
16967   match(Set dst (MulAddVS2VI src1 src2));
16968   ins_cost(INSN_COST);
<span class="line-modified">16969   effect(TEMP tmp);</span>
16970   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
16971             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
16972             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
16973   ins_encode %{
16974     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
16975               as_FloatRegister($src1$$reg),
16976               as_FloatRegister($src2$$reg));
16977     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
16978               as_FloatRegister($src1$$reg),
16979               as_FloatRegister($src2$$reg));
16980     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
16981              as_FloatRegister($tmp$$reg),
16982              as_FloatRegister($dst$$reg));
16983   %}
16984   ins_pipe(vmuldiv_fp128);
16985 %}
16986 
16987 // --------------------------------- DIV --------------------------------------
16988 
16989 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
</pre>
<hr />
<pre>
18017   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18018   ins_encode %{
18019     switch ($rmode$$constant) {
18020       case RoundDoubleModeNode::rmode_rint:
18021         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18022                   as_FloatRegister($src$$reg));
18023         break;
18024       case RoundDoubleModeNode::rmode_floor:
18025         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18026                   as_FloatRegister($src$$reg));
18027         break;
18028       case RoundDoubleModeNode::rmode_ceil:
18029         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18030                   as_FloatRegister($src$$reg));
18031         break;
18032     }
18033   %}
18034   ins_pipe(vdop_fp128);
18035 %}
18036 






































18037 //----------PEEPHOLE RULES-----------------------------------------------------
18038 // These must follow all instruction definitions as they use the names
18039 // defined in the instructions definitions.
18040 //
18041 // peepmatch ( root_instr_name [preceding_instruction]* );
18042 //
18043 // peepconstraint %{
18044 // (instruction_number.operand_name relational_op instruction_number.operand_name
18045 //  [, ...] );
18046 // // instruction numbers are zero-based using left to right order in peepmatch
18047 //
18048 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18049 // // provide an instruction_number.operand_name for each operand that appears
18050 // // in the replacement instruction&#39;s match rule
18051 //
18052 // ---------VM FLAGS---------------------------------------------------------
18053 //
18054 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18055 //
18056 // Each peephole rule is given an identifying number starting with zero and
</pre>
</td>
<td>
<hr />
<pre>
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
<span class="line-added"> 1030 class Node::PD {</span>
<span class="line-added"> 1031 public:</span>
<span class="line-added"> 1032   enum NodeFlags {</span>
<span class="line-added"> 1033     _last_flag = Node::_last_flag</span>
<span class="line-added"> 1034   };</span>
<span class="line-added"> 1035 };</span>
<span class="line-added"> 1036 </span>
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
<span class="line-added"> 1061   void PhaseOutput::pd_perform_mach_node_analysis() {</span>
<span class="line-added"> 1062   }</span>
<span class="line-added"> 1063 </span>
<span class="line-added"> 1064   int MachNode::pd_alignment_required() const {</span>
<span class="line-added"> 1065     return 1;</span>
<span class="line-added"> 1066   }</span>
<span class="line-added"> 1067 </span>
<span class="line-added"> 1068   int MachNode::compute_padding(int current_offset) const {</span>
<span class="line-added"> 1069     return 0;</span>
<span class="line-added"> 1070   }</span>
<span class="line-added"> 1071 </span>
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
</pre>
<hr />
<pre>
 1546 // code for the safepoint node and that needs ot be at the load
 1547 // instruction itself. so we cannot plant a mov of the safepoint poll
 1548 // address followed by a load. setting this to true means the mov is
 1549 // scheduled as a prior instruction. that&#39;s better for scheduling
 1550 // anyway.
 1551 
 1552 bool SafePointNode::needs_polling_address_input()
 1553 {
 1554   return true;
 1555 }
 1556 
 1557 //=============================================================================
 1558 
 1559 #ifndef PRODUCT
 1560 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1561   st-&gt;print(&quot;BREAKPOINT&quot;);
 1562 }
 1563 #endif
 1564 
 1565 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
<span class="line-modified"> 1566   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1567   __ brk(0);
 1568 }
 1569 
 1570 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1571   return MachNode::size(ra_);
 1572 }
 1573 
 1574 //=============================================================================
 1575 
 1576 #ifndef PRODUCT
 1577   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1578     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1579   }
 1580 #endif
 1581 
 1582   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
<span class="line-modified"> 1583     C2_MacroAssembler _masm(&amp;cbuf);</span>
 1584     for (int i = 0; i &lt; _count; i++) {
 1585       __ nop();
 1586     }
 1587   }
 1588 
 1589   uint MachNopNode::size(PhaseRegAlloc*) const {
 1590     return _count * NativeInstruction::instruction_size;
 1591   }
 1592 
 1593 //=============================================================================
 1594 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1595 
<span class="line-modified"> 1596 int ConstantTable::calculate_table_base_offset() const {</span>
 1597   return 0;  // absolute addressing, no offset
 1598 }
 1599 
 1600 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1601 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1602   ShouldNotReachHere();
 1603 }
 1604 
 1605 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1606   // Empty encoding
 1607 }
 1608 
 1609 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1610   return 0;
 1611 }
 1612 
 1613 #ifndef PRODUCT
 1614 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1615   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1616 }
 1617 #endif
 1618 
 1619 #ifndef PRODUCT
 1620 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1621   Compile* C = ra_-&gt;C;
 1622 
<span class="line-modified"> 1623   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1624 
<span class="line-modified"> 1625   if (C-&gt;output()-&gt;need_stack_bang(framesize))</span>
 1626     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1627 
 1628   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1629     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1630     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1631     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1632   } else {
 1633     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1634     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1635     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1636     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1637   }
 1638 }
 1639 #endif
 1640 
 1641 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1642   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1643   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1644 
 1645   // n.b. frame size includes space for return pc and rfp
<span class="line-modified"> 1646   const long framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
 1647   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1648 
 1649   // insert a nop at the start of the prolog so we can patch in a
 1650   // branch if we need to invalidate the method later
 1651   __ nop();
 1652 
 1653   if (C-&gt;clinit_barrier_on_entry()) {
 1654     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);
 1655 
 1656     Label L_skip_barrier;
 1657 
 1658     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1659     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 1660     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 1661     __ bind(L_skip_barrier);
 1662   }
 1663 
<span class="line-modified"> 1664   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();</span>
<span class="line-modified"> 1665   if (C-&gt;output()-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)</span>
 1666     __ generate_stack_overflow_check(bangsize);
 1667 
 1668   __ build_frame(framesize);
 1669 
 1670   if (VerifyStackAtCalls) {
 1671     Unimplemented();
 1672   }
 1673 
<span class="line-modified"> 1674   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());</span>
 1675 
 1676   if (C-&gt;has_mach_constant_base_node()) {
 1677     // NOTE: We set the table base offset here because users might be
 1678     // emitted before MachConstantBaseNode.
<span class="line-modified"> 1679     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();</span>
 1680     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1681   }
 1682 }
 1683 
 1684 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1685 {
 1686   return MachNode::size(ra_); // too many variables; just compute it
 1687                               // the hard way
 1688 }
 1689 
 1690 int MachPrologNode::reloc() const
 1691 {
 1692   return 0;
 1693 }
 1694 
 1695 //=============================================================================
 1696 
 1697 #ifndef PRODUCT
 1698 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1699   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1700   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1701 
 1702   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1703 
 1704   if (framesize == 0) {
 1705     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1706   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1707     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1708     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1709   } else {
 1710     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1711     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1712     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1713   }
 1714 
 1715   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1716     st-&gt;print(&quot;# touch polling page\n\t&quot;);
<span class="line-modified"> 1717     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);</span>
 1718     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1719   }
 1720 }
 1721 #endif
 1722 
 1723 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1724   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1725   C2_MacroAssembler _masm(&amp;cbuf);</span>
<span class="line-modified"> 1726   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1727 
 1728   __ remove_frame(framesize);
 1729 
 1730   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1731     __ reserved_stack_check();
 1732   }
 1733 
 1734   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
<span class="line-modified"> 1735     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);</span>
 1736   }
 1737 }
 1738 
 1739 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1740   // Variable size. Determine dynamically.
 1741   return MachNode::size(ra_);
 1742 }
 1743 
 1744 int MachEpilogNode::reloc() const {
 1745   // Return number of relocatable values contained in this instruction.
 1746   return 1; // 1 for polling page.
 1747 }
 1748 
 1749 const Pipeline * MachEpilogNode::pipeline() const {
 1750   return MachNode::pipeline_class();
 1751 }
 1752 








 1753 //=============================================================================
 1754 
 1755 // Figure out which register class each belongs in: rc_int, rc_float or
 1756 // rc_stack.
 1757 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1758 
 1759 static enum RC rc_class(OptoReg::Name reg) {
 1760 
 1761   if (reg == OptoReg::Bad) {
 1762     return rc_bad;
 1763   }
 1764 
 1765   // we have 30 int registers * 2 halves
 1766   // (rscratch1 and rscratch2 are omitted)
 1767   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1768 
 1769   if (reg &lt; slots_of_int_registers) {
 1770     return rc_int;
 1771   }
 1772 
</pre>
<hr />
<pre>
 1799 
 1800   if (src_hi != OptoReg::Bad) {
 1801     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1802            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1803            &quot;expected aligned-adjacent pairs&quot;);
 1804   }
 1805 
 1806   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1807     return 0;            // Self copy, no move.
 1808   }
 1809 
 1810   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1811               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1812   int src_offset = ra_-&gt;reg2offset(src_lo);
 1813   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1814 
 1815   if (bottom_type()-&gt;isa_vect() != NULL) {
 1816     uint ireg = ideal_reg();
 1817     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1818     if (cbuf) {
<span class="line-modified"> 1819       C2_MacroAssembler _masm(cbuf);</span>
 1820       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1821       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1822         // stack-&gt;stack
 1823         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1824         if (ireg == Op_VecD) {
 1825           __ unspill(rscratch1, true, src_offset);
 1826           __ spill(rscratch1, true, dst_offset);
 1827         } else {
 1828           __ spill_copy128(src_offset, dst_offset);
 1829         }
 1830       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1831         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1832                ireg == Op_VecD ? __ T8B : __ T16B,
 1833                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1834       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1835         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1836                        ireg == Op_VecD ? __ D : __ Q,
 1837                        ra_-&gt;reg2offset(dst_lo));
 1838       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1839         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1840                        ireg == Op_VecD ? __ D : __ Q,
 1841                        ra_-&gt;reg2offset(src_lo));
 1842       } else {
 1843         ShouldNotReachHere();
 1844       }
 1845     }
 1846   } else if (cbuf) {
<span class="line-modified"> 1847     C2_MacroAssembler _masm(cbuf);</span>
 1848     switch (src_lo_rc) {
 1849     case rc_int:
 1850       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1851         if (is64) {
 1852             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1853                    as_Register(Matcher::_regEncode[src_lo]));
 1854         } else {
<span class="line-modified"> 1855             C2_MacroAssembler _masm(cbuf);</span>
 1856             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1857                     as_Register(Matcher::_regEncode[src_lo]));
 1858         }
 1859       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1860         if (is64) {
 1861             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1862                      as_Register(Matcher::_regEncode[src_lo]));
 1863         } else {
 1864             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1865                      as_Register(Matcher::_regEncode[src_lo]));
 1866         }
 1867       } else {                    // gpr --&gt; stack spill
 1868         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1869         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1870       }
 1871       break;
 1872     case rc_float:
 1873       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1874         if (is64) {
 1875             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
</pre>
<hr />
<pre>
 1945 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1946   implementation(&amp;cbuf, ra_, false, NULL);
 1947 }
 1948 
 1949 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1950   return MachNode::size(ra_);
 1951 }
 1952 
 1953 //=============================================================================
 1954 
 1955 #ifndef PRODUCT
 1956 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1957   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1958   int reg = ra_-&gt;get_reg_first(this);
 1959   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1960             Matcher::regName[reg], offset);
 1961 }
 1962 #endif
 1963 
 1964 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
<span class="line-modified"> 1965   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1966 
 1967   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1968   int reg    = ra_-&gt;get_encode(this);
 1969 
 1970   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1971     __ add(as_Register(reg), sp, offset);
 1972   } else {
 1973     ShouldNotReachHere();
 1974   }
 1975 }
 1976 
 1977 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1978   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1979   return 4;
 1980 }
 1981 
 1982 //=============================================================================
 1983 
 1984 #ifndef PRODUCT
 1985 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1986 {
 1987   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1988   if (UseCompressedClassPointers) {
 1989     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1990     if (CompressedKlassPointers::shift() != 0) {
 1991       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1992     }
 1993   } else {
 1994    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1995   }
 1996   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1997   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 1998 }
 1999 #endif
 2000 
 2001 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 2002 {
 2003   // This is the unverified entry point.
<span class="line-modified"> 2004   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2005 
 2006   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 2007   Label skip;
 2008   // TODO
 2009   // can we avoid this skip and still use a reloc?
 2010   __ br(Assembler::EQ, skip);
 2011   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2012   __ bind(skip);
 2013 }
 2014 
 2015 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2016 {
 2017   return MachNode::size(ra_);
 2018 }
 2019 
 2020 // REQUIRED EMIT CODE
 2021 
 2022 //=============================================================================
 2023 
 2024 // Emit exception handler code.
 2025 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2026 {
 2027   // mov rscratch1 #exception_blob_entry_point
 2028   // br rscratch1
 2029   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2030   // That&#39;s why we must use the macroassembler to generate a handler.
<span class="line-modified"> 2031   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2032   address base = __ start_a_stub(size_exception_handler());
 2033   if (base == NULL) {
 2034     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2035     return 0;  // CodeBuffer::expand failed
 2036   }
 2037   int offset = __ offset();
 2038   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2039   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2040   __ end_a_stub();
 2041   return offset;
 2042 }
 2043 
 2044 // Emit deopt handler code.
 2045 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2046 {
 2047   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2048   // That&#39;s why we must use the macroassembler to generate a handler.
<span class="line-modified"> 2049   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2050   address base = __ start_a_stub(size_deopt_handler());
 2051   if (base == NULL) {
 2052     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2053     return 0;  // CodeBuffer::expand failed
 2054   }
 2055   int offset = __ offset();
 2056 
 2057   __ adr(lr, __ pc());
 2058   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2059 
 2060   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2061   __ end_a_stub();
 2062   return offset;
 2063 }
 2064 
 2065 // REQUIRED MATCHER CODE
 2066 
 2067 //=============================================================================
 2068 
 2069 const bool Matcher::match_rule_supported(int opcode) {
</pre>
<hr />
<pre>
 2350 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2351   return FP_REG_mask();
 2352 }
 2353 
 2354 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2355   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2356     Node* u = addp-&gt;fast_out(i);
 2357     if (u-&gt;is_Mem()) {
 2358       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2359       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2360       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2361         return false;
 2362       }
 2363     }
 2364   }
 2365   return true;
 2366 }
 2367 
 2368 const bool Matcher::convi2l_type_required = false;
 2369 
<span class="line-added"> 2370 // Should the matcher clone input &#39;m&#39; of node &#39;n&#39;?</span>
<span class="line-added"> 2371 bool Matcher::pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {</span>
<span class="line-added"> 2372   if (is_vshift_con_pattern(n, m)) { // ShiftV src (ShiftCntV con)</span>
<span class="line-added"> 2373     mstack.push(m, Visit);           // m = ShiftCntV</span>
<span class="line-added"> 2374     return true;</span>
<span class="line-added"> 2375   }</span>
<span class="line-added"> 2376   return false;</span>
<span class="line-added"> 2377 }</span>
<span class="line-added"> 2378 </span>
 2379 // Should the Matcher clone shifts on addressing modes, expecting them
 2380 // to be subsumed into complex addressing expressions or compute them
 2381 // into registers?
<span class="line-modified"> 2382 bool Matcher::pd_clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {</span>
 2383   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2384     return true;
 2385   }
 2386 
 2387   Node *off = m-&gt;in(AddPNode::Offset);
 2388   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2389       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2390       // Are there other uses besides address expressions?
 2391       !is_visited(off)) {
 2392     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2393     mstack.push(off-&gt;in(2), Visit);
 2394     Node *conv = off-&gt;in(1);
 2395     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2396         // Are there other uses besides address expressions?
 2397         !is_visited(conv)) {
 2398       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2399       mstack.push(conv-&gt;in(1), Pre_Visit);
 2400     } else {
 2401       mstack.push(conv, Pre_Visit);
 2402     }
</pre>
<hr />
<pre>
 2405     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2406     return true;
 2407   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2408              // Are there other uses besides address expressions?
 2409              !is_visited(off)) {
 2410     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2411     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2412     mstack.push(off-&gt;in(1), Pre_Visit);
 2413     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2414     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2415     return true;
 2416   }
 2417   return false;
 2418 }
 2419 
 2420 void Compile::reshape_address(AddPNode* addp) {
 2421 }
 2422 
 2423 
 2424 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
<span class="line-modified"> 2425   C2_MacroAssembler _masm(&amp;cbuf);                                       \</span>
 2426   {                                                                     \
 2427     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2428     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2429     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2430     __ INSN(REG, as_Register(BASE));                                    \
 2431   }
 2432 
 2433 
 2434 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2435   {
 2436     Address::extend scale;
 2437 
 2438     // Hooboy, this is fugly.  We need a way to communicate to the
 2439     // encoder that the index needs to be sign extended, so we have to
 2440     // enumerate all the cases.
 2441     switch (opcode) {
 2442     case INDINDEXSCALEDI2L:
 2443     case INDINDEXSCALEDI2LN:
 2444     case INDINDEXI2L:
 2445     case INDINDEXI2LN:
</pre>
<hr />
<pre>
 2450     }
 2451 
 2452     if (index == -1) {
 2453       return Address(base, disp);
 2454     } else {
 2455       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2456       return Address(base, as_Register(index), scale);
 2457     }
 2458   }
 2459 
 2460 
 2461 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2462 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2463 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2464 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2465                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2466 
 2467   // Used for all non-volatile memory accesses.  The use of
 2468   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2469   // offsets is something of a kludge.
<span class="line-modified"> 2470   static void loadStore(C2_MacroAssembler masm, mem_insn insn,</span>
 2471                         Register reg, int opcode,
 2472                         Register base, int index, int scale, int disp,
 2473                         int size_in_memory)
 2474   {
 2475     Address addr = mem2address(opcode, base, index, scale, disp);
 2476     if (addr.getMode() == Address::base_plus_offset) {
 2477       /* If we get an out-of-range offset it is a bug in the compiler,
 2478          so we assert here. */
 2479       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2480              &quot;c2 compiler bug&quot;);
 2481       /* Fix up any out-of-range offsets. */
 2482       assert_different_registers(rscratch1, base);
 2483       assert_different_registers(rscratch1, reg);
 2484       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2485     }
 2486     (masm.*insn)(reg, addr);
 2487   }
 2488 
<span class="line-modified"> 2489   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,</span>
 2490                         FloatRegister reg, int opcode,
 2491                         Register base, int index, int size, int disp,
 2492                         int size_in_memory)
 2493   {
 2494     Address::extend scale;
 2495 
 2496     switch (opcode) {
 2497     case INDINDEXSCALEDI2L:
 2498     case INDINDEXSCALEDI2LN:
 2499       scale = Address::sxtw(size);
 2500       break;
 2501     default:
 2502       scale = Address::lsl(size);
 2503     }
 2504 
 2505     if (index == -1) {
 2506       /* If we get an out-of-range offset it is a bug in the compiler,
 2507          so we assert here. */
 2508       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2509       /* Fix up any out-of-range offsets. */
 2510       assert_different_registers(rscratch1, base);
 2511       Address addr = Address(base, disp);
 2512       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2513       (masm.*insn)(reg, addr);
 2514     } else {
 2515       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2516       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2517     }
 2518   }
 2519 
<span class="line-modified"> 2520   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,</span>
 2521                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2522                         int opcode, Register base, int index, int size, int disp)
 2523   {
 2524     if (index == -1) {
 2525       (masm.*insn)(reg, T, Address(base, disp));
 2526     } else {
 2527       assert(disp == 0, &quot;unsupported address mode&quot;);
 2528       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2529     }
 2530   }
 2531 
 2532 %}
 2533 
 2534 
 2535 
 2536 //----------ENCODING BLOCK-----------------------------------------------------
 2537 // This block specifies the encoding classes used by the compiler to
 2538 // output byte streams.  Encoding classes are parameterized macros
 2539 // used by Machine Instruction Nodes in order to generate the bit
 2540 // encoding of the instruction.  Operands specify their base encoding
</pre>
<hr />
<pre>
 2553 //
 2554 // Instructions specify two basic values for encoding.  Again, a
 2555 // function is available to check if the constant displacement is an
 2556 // oop. They use the ins_encode keyword to specify their encoding
 2557 // classes (which must be a sequence of enc_class names, and their
 2558 // parameters, specified in the encoding block), and they use the
 2559 // opcode keyword to specify, in order, their primary, secondary, and
 2560 // tertiary opcode.  Only the opcode sections which a particular
 2561 // instruction needs for encoding need to be specified.
 2562 encode %{
 2563   // Build emit functions for each basic byte or larger field in the
 2564   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2565   // from C++ code in the enc_class source block.  Emit functions will
 2566   // live in the main source block for now.  In future, we can
 2567   // generalize this by adding a syntax that specifies the sizes of
 2568   // fields in an order, so that the adlc can build the emit functions
 2569   // automagically
 2570 
 2571   // catch all for unimplemented encodings
 2572   enc_class enc_unimplemented %{
<span class="line-modified"> 2573     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2574     __ unimplemented(&quot;C2 catch all&quot;);
 2575   %}
 2576 
 2577   // BEGIN Non-volatile memory access
 2578 
 2579   // This encoding class is generated automatically from ad_encode.m4.
 2580   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2581   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2582     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2583     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),</span>
 2584                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2585   %}
 2586 
 2587   // This encoding class is generated automatically from ad_encode.m4.
 2588   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2589   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2590     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2591     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),</span>
 2592                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2593   %}
 2594 
 2595   // This encoding class is generated automatically from ad_encode.m4.
 2596   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2597   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2598     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2599     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),</span>
 2600                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2601   %}
 2602 
 2603   // This encoding class is generated automatically from ad_encode.m4.
 2604   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2605   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2606     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2607     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),</span>
 2608                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2609   %}
 2610 
 2611   // This encoding class is generated automatically from ad_encode.m4.
 2612   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2613   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2614     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2615     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),</span>
 2616                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2617   %}
 2618 
 2619   // This encoding class is generated automatically from ad_encode.m4.
 2620   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2621   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2622     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2623     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),</span>
 2624                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2625   %}
 2626 
 2627   // This encoding class is generated automatically from ad_encode.m4.
 2628   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2629   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2630     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2631     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),</span>
 2632                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2633   %}
 2634 
 2635   // This encoding class is generated automatically from ad_encode.m4.
 2636   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2637   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2638     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2639     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),</span>
 2640                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2641   %}
 2642 
 2643   // This encoding class is generated automatically from ad_encode.m4.
 2644   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2645   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2646     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2647     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),</span>
 2648                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2649   %}
 2650 
 2651   // This encoding class is generated automatically from ad_encode.m4.
 2652   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2653   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2654     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2655     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),</span>
 2656                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2657   %}
 2658 
 2659   // This encoding class is generated automatically from ad_encode.m4.
 2660   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2661   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2662     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2663     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),</span>
 2664                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2665   %}
 2666 
 2667   // This encoding class is generated automatically from ad_encode.m4.
 2668   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2669   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2670     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2671     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),</span>
 2672                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2673   %}
 2674 
 2675   // This encoding class is generated automatically from ad_encode.m4.
 2676   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2677   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2678     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2679     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),</span>
 2680                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2681   %}
 2682 
 2683   // This encoding class is generated automatically from ad_encode.m4.
 2684   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2685   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2686     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2687     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),</span>
 2688                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2689   %}
 2690 
 2691   // This encoding class is generated automatically from ad_encode.m4.
 2692   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2693   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2694     Register src_reg = as_Register($src$$reg);
<span class="line-modified"> 2695     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),</span>
 2696                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2697   %}
 2698 
 2699   // This encoding class is generated automatically from ad_encode.m4.
 2700   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2701   enc_class aarch64_enc_strb0(memory1 mem) %{
<span class="line-modified"> 2702     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2703     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2704                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2705   %}
 2706 
 2707   // This encoding class is generated automatically from ad_encode.m4.
 2708   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2709   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2710     Register src_reg = as_Register($src$$reg);
<span class="line-modified"> 2711     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),</span>
 2712                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2713   %}
 2714 
 2715   // This encoding class is generated automatically from ad_encode.m4.
 2716   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2717   enc_class aarch64_enc_strh0(memory2 mem) %{
<span class="line-modified"> 2718     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2719     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2720                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2721   %}
 2722 
 2723   // This encoding class is generated automatically from ad_encode.m4.
 2724   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2725   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2726     Register src_reg = as_Register($src$$reg);
<span class="line-modified"> 2727     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),</span>
 2728                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2729   %}
 2730 
 2731   // This encoding class is generated automatically from ad_encode.m4.
 2732   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2733   enc_class aarch64_enc_strw0(memory4 mem) %{
<span class="line-modified"> 2734     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2735     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2736                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2737   %}
 2738 
 2739   // This encoding class is generated automatically from ad_encode.m4.
 2740   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2741   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2742     Register src_reg = as_Register($src$$reg);
 2743     // we sometimes get asked to store the stack pointer into the
 2744     // current thread -- we cannot do that directly on AArch64
 2745     if (src_reg == r31_sp) {
<span class="line-modified"> 2746       C2_MacroAssembler _masm(&amp;cbuf);</span>
 2747       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2748       __ mov(rscratch2, sp);
 2749       src_reg = rscratch2;
 2750     }
<span class="line-modified"> 2751     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),</span>
 2752                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2753   %}
 2754 
 2755   // This encoding class is generated automatically from ad_encode.m4.
 2756   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2757   enc_class aarch64_enc_str0(memory8 mem) %{
<span class="line-modified"> 2758     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2759     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2760                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2761   %}
 2762 
 2763   // This encoding class is generated automatically from ad_encode.m4.
 2764   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2765   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2766     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2767     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),</span>
 2768                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2769   %}
 2770 
 2771   // This encoding class is generated automatically from ad_encode.m4.
 2772   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2773   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2774     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2775     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),</span>
 2776                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2777   %}
 2778 
 2779   // This encoding class is generated automatically from ad_encode.m4.
 2780   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2781   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
<span class="line-modified"> 2782     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2783     address con = (address)$src$$constant;
 2784     // need to do this the hard way until we can manage relocs
 2785     // for 32 bit constants
 2786     __ movoop(rscratch2, (jobject)con);
 2787     if (con) __ encode_heap_oop_not_null(rscratch2);
 2788     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2789                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2790   %}
 2791 
 2792   // This encoding class is generated automatically from ad_encode.m4.
 2793   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2794   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
<span class="line-modified"> 2795     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2796     address con = (address)$src$$constant;
 2797     // need to do this the hard way until we can manage relocs
 2798     // for 32 bit constants
 2799     __ movoop(rscratch2, (jobject)con);
 2800     __ encode_klass_not_null(rscratch2);
 2801     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2802                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2803   %}
 2804 
 2805   // This encoding class is generated automatically from ad_encode.m4.
 2806   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2807   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
<span class="line-modified"> 2808       C2_MacroAssembler _masm(&amp;cbuf);</span>
 2809       __ membar(Assembler::StoreStore);
 2810       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2811                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2812   %}
 2813 
 2814   // END Non-volatile memory access
 2815 
 2816   // Vector loads and stores
 2817   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2818     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2819     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,</span>
 2820        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2821   %}
 2822 
 2823   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2824     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2825     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,</span>
 2826        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2827   %}
 2828 
 2829   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2830     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2831     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,</span>
 2832        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2833   %}
 2834 
 2835   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2836     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2837     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,</span>
 2838        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2839   %}
 2840 
 2841   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2842     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2843     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,</span>
 2844        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2845   %}
 2846 
 2847   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2848     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2849     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,</span>
 2850        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2851   %}
 2852 
 2853   // volatile loads and stores
 2854 
 2855   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2856     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2857                  rscratch1, stlrb);
 2858   %}
 2859 
 2860   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2861     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2862                  rscratch1, stlrh);
 2863   %}
 2864 
 2865   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2866     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2867                  rscratch1, stlrw);
 2868   %}
 2869 
</pre>
<hr />
<pre>
 2931              rscratch1, ldar);
 2932   %}
 2933 
 2934   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2935     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2936              rscratch1, ldarw);
 2937     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2938   %}
 2939 
 2940   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2941     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2942              rscratch1, ldar);
 2943     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2944   %}
 2945 
 2946   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2947     Register src_reg = as_Register($src$$reg);
 2948     // we sometimes get asked to store the stack pointer into the
 2949     // current thread -- we cannot do that directly on AArch64
 2950     if (src_reg == r31_sp) {
<span class="line-modified"> 2951       C2_MacroAssembler _masm(&amp;cbuf);</span>
 2952       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2953       __ mov(rscratch2, sp);
 2954       src_reg = rscratch2;
 2955     }
 2956     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2957                  rscratch1, stlr);
 2958   %}
 2959 
 2960   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2961     {
<span class="line-modified"> 2962       C2_MacroAssembler _masm(&amp;cbuf);</span>
 2963       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2964       __ fmovs(rscratch2, src_reg);
 2965     }
 2966     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2967                  rscratch1, stlrw);
 2968   %}
 2969 
 2970   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2971     {
<span class="line-modified"> 2972       C2_MacroAssembler _masm(&amp;cbuf);</span>
 2973       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2974       __ fmovd(rscratch2, src_reg);
 2975     }
 2976     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2977                  rscratch1, stlr);
 2978   %}
 2979 
 2980   // synchronized read/update encodings
 2981 
 2982   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
<span class="line-modified"> 2983     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2984     Register dst_reg = as_Register($dst$$reg);
 2985     Register base = as_Register($mem$$base);
 2986     int index = $mem$$index;
 2987     int scale = $mem$$scale;
 2988     int disp = $mem$$disp;
 2989     if (index == -1) {
 2990        if (disp != 0) {
 2991         __ lea(rscratch1, Address(base, disp));
 2992         __ ldaxr(dst_reg, rscratch1);
 2993       } else {
 2994         // TODO
 2995         // should we ever get anything other than this case?
 2996         __ ldaxr(dst_reg, base);
 2997       }
 2998     } else {
 2999       Register index_reg = as_Register(index);
 3000       if (disp == 0) {
 3001         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 3002         __ ldaxr(dst_reg, rscratch1);
 3003       } else {
 3004         __ lea(rscratch1, Address(base, disp));
 3005         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 3006         __ ldaxr(dst_reg, rscratch1);
 3007       }
 3008     }
 3009   %}
 3010 
 3011   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
<span class="line-modified"> 3012     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3013     Register src_reg = as_Register($src$$reg);
 3014     Register base = as_Register($mem$$base);
 3015     int index = $mem$$index;
 3016     int scale = $mem$$scale;
 3017     int disp = $mem$$disp;
 3018     if (index == -1) {
 3019        if (disp != 0) {
 3020         __ lea(rscratch2, Address(base, disp));
 3021         __ stlxr(rscratch1, src_reg, rscratch2);
 3022       } else {
 3023         // TODO
 3024         // should we ever get anything other than this case?
 3025         __ stlxr(rscratch1, src_reg, base);
 3026       }
 3027     } else {
 3028       Register index_reg = as_Register(index);
 3029       if (disp == 0) {
 3030         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3031         __ stlxr(rscratch1, src_reg, rscratch2);
 3032       } else {
 3033         __ lea(rscratch2, Address(base, disp));
 3034         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3035         __ stlxr(rscratch1, src_reg, rscratch2);
 3036       }
 3037     }
 3038     __ cmpw(rscratch1, zr);
 3039   %}
 3040 
 3041   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
<span class="line-modified"> 3042     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3043     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3044     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3045                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3046                /*weak*/ false, noreg);
 3047   %}
 3048 
 3049   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3050     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3051     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3052     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3053                Assembler::word, /*acquire*/ false, /*release*/ true,
 3054                /*weak*/ false, noreg);
 3055   %}
 3056 
 3057   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3058     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3059     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3060     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3061                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3062                /*weak*/ false, noreg);
 3063   %}
 3064 
 3065   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3066     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3067     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3068     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3069                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3070                /*weak*/ false, noreg);
 3071   %}
 3072 
 3073 
 3074   // The only difference between aarch64_enc_cmpxchg and
 3075   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3076   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3077   // lock.
 3078   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
<span class="line-modified"> 3079     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3080     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3081     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3082                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3083                /*weak*/ false, noreg);
 3084   %}
 3085 
 3086   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3087     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3088     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3089     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3090                Assembler::word, /*acquire*/ true, /*release*/ true,
 3091                /*weak*/ false, noreg);
 3092   %}
 3093 
 3094   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3095     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3096     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3097     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3098                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3099                /*weak*/ false, noreg);
 3100   %}
 3101 
 3102   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3103     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3104     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3105     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3106                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3107                /*weak*/ false, noreg);
 3108   %}
 3109 
 3110   // auxiliary used for CompareAndSwapX to set result register
 3111   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
<span class="line-modified"> 3112     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3113     Register res_reg = as_Register($res$$reg);
 3114     __ cset(res_reg, Assembler::EQ);
 3115   %}
 3116 
 3117   // prefetch encodings
 3118 
 3119   enc_class aarch64_enc_prefetchw(memory mem) %{
<span class="line-modified"> 3120     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3121     Register base = as_Register($mem$$base);
 3122     int index = $mem$$index;
 3123     int scale = $mem$$scale;
 3124     int disp = $mem$$disp;
 3125     if (index == -1) {
 3126       __ prfm(Address(base, disp), PSTL1KEEP);
 3127     } else {
 3128       Register index_reg = as_Register(index);
 3129       if (disp == 0) {
 3130         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3131       } else {
 3132         __ lea(rscratch1, Address(base, disp));
 3133 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3134       }
 3135     }
 3136   %}
 3137 
 3138   /// mov envcodings
 3139 
 3140   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
<span class="line-modified"> 3141     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3142     u_int32_t con = (u_int32_t)$src$$constant;
 3143     Register dst_reg = as_Register($dst$$reg);
 3144     if (con == 0) {
 3145       __ movw(dst_reg, zr);
 3146     } else {
 3147       __ movw(dst_reg, con);
 3148     }
 3149   %}
 3150 
 3151   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
<span class="line-modified"> 3152     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3153     Register dst_reg = as_Register($dst$$reg);
 3154     u_int64_t con = (u_int64_t)$src$$constant;
 3155     if (con == 0) {
 3156       __ mov(dst_reg, zr);
 3157     } else {
 3158       __ mov(dst_reg, con);
 3159     }
 3160   %}
 3161 
 3162   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
<span class="line-modified"> 3163     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3164     Register dst_reg = as_Register($dst$$reg);
 3165     address con = (address)$src$$constant;
 3166     if (con == NULL || con == (address)1) {
 3167       ShouldNotReachHere();
 3168     } else {
 3169       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3170       if (rtype == relocInfo::oop_type) {
 3171         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3172       } else if (rtype == relocInfo::metadata_type) {
 3173         __ mov_metadata(dst_reg, (Metadata*)con);
 3174       } else {
 3175         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3176         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3177           __ mov(dst_reg, con);
 3178         } else {
 3179           unsigned long offset;
 3180           __ adrp(dst_reg, con, offset);
 3181           __ add(dst_reg, dst_reg, offset);
 3182         }
 3183       }
 3184     }
 3185   %}
 3186 
 3187   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
<span class="line-modified"> 3188     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3189     Register dst_reg = as_Register($dst$$reg);
 3190     __ mov(dst_reg, zr);
 3191   %}
 3192 
 3193   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
<span class="line-modified"> 3194     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3195     Register dst_reg = as_Register($dst$$reg);
 3196     __ mov(dst_reg, (u_int64_t)1);
 3197   %}
 3198 









 3199   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
<span class="line-modified"> 3200     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3201     __ load_byte_map_base($dst$$Register);
 3202   %}
 3203 
 3204   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
<span class="line-modified"> 3205     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3206     Register dst_reg = as_Register($dst$$reg);
 3207     address con = (address)$src$$constant;
 3208     if (con == NULL) {
 3209       ShouldNotReachHere();
 3210     } else {
 3211       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3212       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3213       __ set_narrow_oop(dst_reg, (jobject)con);
 3214     }
 3215   %}
 3216 
 3217   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
<span class="line-modified"> 3218     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3219     Register dst_reg = as_Register($dst$$reg);
 3220     __ mov(dst_reg, zr);
 3221   %}
 3222 
 3223   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
<span class="line-modified"> 3224     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3225     Register dst_reg = as_Register($dst$$reg);
 3226     address con = (address)$src$$constant;
 3227     if (con == NULL) {
 3228       ShouldNotReachHere();
 3229     } else {
 3230       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3231       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3232       __ set_narrow_klass(dst_reg, (Klass *)con);
 3233     }
 3234   %}
 3235 
 3236   // arithmetic encodings
 3237 
 3238   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
<span class="line-modified"> 3239     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3240     Register dst_reg = as_Register($dst$$reg);
 3241     Register src_reg = as_Register($src1$$reg);
 3242     int32_t con = (int32_t)$src2$$constant;
 3243     // add has primary == 0, subtract has primary == 1
 3244     if ($primary) { con = -con; }
 3245     if (con &lt; 0) {
 3246       __ subw(dst_reg, src_reg, -con);
 3247     } else {
 3248       __ addw(dst_reg, src_reg, con);
 3249     }
 3250   %}
 3251 
 3252   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
<span class="line-modified"> 3253     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3254     Register dst_reg = as_Register($dst$$reg);
 3255     Register src_reg = as_Register($src1$$reg);
 3256     int32_t con = (int32_t)$src2$$constant;
 3257     // add has primary == 0, subtract has primary == 1
 3258     if ($primary) { con = -con; }
 3259     if (con &lt; 0) {
 3260       __ sub(dst_reg, src_reg, -con);
 3261     } else {
 3262       __ add(dst_reg, src_reg, con);
 3263     }
 3264   %}
 3265 
 3266   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3267     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3268    Register dst_reg = as_Register($dst$$reg);
 3269    Register src1_reg = as_Register($src1$$reg);
 3270    Register src2_reg = as_Register($src2$$reg);
 3271     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3272   %}
 3273 
 3274   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3275     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3276    Register dst_reg = as_Register($dst$$reg);
 3277    Register src1_reg = as_Register($src1$$reg);
 3278    Register src2_reg = as_Register($src2$$reg);
 3279     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3280   %}
 3281 
 3282   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3283     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3284    Register dst_reg = as_Register($dst$$reg);
 3285    Register src1_reg = as_Register($src1$$reg);
 3286    Register src2_reg = as_Register($src2$$reg);
 3287     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3288   %}
 3289 
 3290   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3291     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3292    Register dst_reg = as_Register($dst$$reg);
 3293    Register src1_reg = as_Register($src1$$reg);
 3294    Register src2_reg = as_Register($src2$$reg);
 3295     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3296   %}
 3297 
 3298   // compare instruction encodings
 3299 
 3300   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
<span class="line-modified"> 3301     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3302     Register reg1 = as_Register($src1$$reg);
 3303     Register reg2 = as_Register($src2$$reg);
 3304     __ cmpw(reg1, reg2);
 3305   %}
 3306 
 3307   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
<span class="line-modified"> 3308     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3309     Register reg = as_Register($src1$$reg);
 3310     int32_t val = $src2$$constant;
 3311     if (val &gt;= 0) {
 3312       __ subsw(zr, reg, val);
 3313     } else {
 3314       __ addsw(zr, reg, -val);
 3315     }
 3316   %}
 3317 
 3318   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
<span class="line-modified"> 3319     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3320     Register reg1 = as_Register($src1$$reg);
 3321     u_int32_t val = (u_int32_t)$src2$$constant;
 3322     __ movw(rscratch1, val);
 3323     __ cmpw(reg1, rscratch1);
 3324   %}
 3325 
 3326   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
<span class="line-modified"> 3327     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3328     Register reg1 = as_Register($src1$$reg);
 3329     Register reg2 = as_Register($src2$$reg);
 3330     __ cmp(reg1, reg2);
 3331   %}
 3332 
 3333   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
<span class="line-modified"> 3334     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3335     Register reg = as_Register($src1$$reg);
 3336     int64_t val = $src2$$constant;
 3337     if (val &gt;= 0) {
 3338       __ subs(zr, reg, val);
 3339     } else if (val != -val) {
 3340       __ adds(zr, reg, -val);
 3341     } else {
 3342     // aargh, Long.MIN_VALUE is a special case
 3343       __ orr(rscratch1, zr, (u_int64_t)val);
 3344       __ subs(zr, reg, rscratch1);
 3345     }
 3346   %}
 3347 
 3348   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
<span class="line-modified"> 3349     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3350     Register reg1 = as_Register($src1$$reg);
 3351     u_int64_t val = (u_int64_t)$src2$$constant;
 3352     __ mov(rscratch1, val);
 3353     __ cmp(reg1, rscratch1);
 3354   %}
 3355 
 3356   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
<span class="line-modified"> 3357     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3358     Register reg1 = as_Register($src1$$reg);
 3359     Register reg2 = as_Register($src2$$reg);
 3360     __ cmp(reg1, reg2);
 3361   %}
 3362 
 3363   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
<span class="line-modified"> 3364     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3365     Register reg1 = as_Register($src1$$reg);
 3366     Register reg2 = as_Register($src2$$reg);
 3367     __ cmpw(reg1, reg2);
 3368   %}
 3369 
 3370   enc_class aarch64_enc_testp(iRegP src) %{
<span class="line-modified"> 3371     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3372     Register reg = as_Register($src$$reg);
 3373     __ cmp(reg, zr);
 3374   %}
 3375 
 3376   enc_class aarch64_enc_testn(iRegN src) %{
<span class="line-modified"> 3377     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3378     Register reg = as_Register($src$$reg);
 3379     __ cmpw(reg, zr);
 3380   %}
 3381 
 3382   enc_class aarch64_enc_b(label lbl) %{
<span class="line-modified"> 3383     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3384     Label *L = $lbl$$label;
 3385     __ b(*L);
 3386   %}
 3387 
 3388   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
<span class="line-modified"> 3389     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3390     Label *L = $lbl$$label;
 3391     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3392   %}
 3393 
 3394   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
<span class="line-modified"> 3395     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3396     Label *L = $lbl$$label;
 3397     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3398   %}
 3399 
 3400   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3401   %{
 3402      Register sub_reg = as_Register($sub$$reg);
 3403      Register super_reg = as_Register($super$$reg);
 3404      Register temp_reg = as_Register($temp$$reg);
 3405      Register result_reg = as_Register($result$$reg);
 3406 
 3407      Label miss;
<span class="line-modified"> 3408      C2_MacroAssembler _masm(&amp;cbuf);</span>
 3409      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3410                                      NULL, &amp;miss,
 3411                                      /*set_cond_codes:*/ true);
 3412      if ($primary) {
 3413        __ mov(result_reg, zr);
 3414      }
 3415      __ bind(miss);
 3416   %}
 3417 
 3418   enc_class aarch64_enc_java_static_call(method meth) %{
<span class="line-modified"> 3419     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3420 
 3421     address addr = (address)$meth$$method;
 3422     address call;
 3423     if (!_method) {
 3424       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3425       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3426     } else {
 3427       int method_index = resolved_method_index(cbuf);
 3428       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3429                                                   : static_call_Relocation::spec(method_index);
 3430       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3431 
 3432       // Emit stub for static call
 3433       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3434       if (stub == NULL) {
 3435         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3436         return;
 3437       }
 3438     }
 3439     if (call == NULL) {
 3440       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3441       return;
 3442     }
 3443   %}
 3444 
 3445   enc_class aarch64_enc_java_dynamic_call(method meth) %{
<span class="line-modified"> 3446     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3447     int method_index = resolved_method_index(cbuf);
 3448     address call = __ ic_call((address)$meth$$method, method_index);
 3449     if (call == NULL) {
 3450       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3451       return;
 3452     }
 3453   %}
 3454 
 3455   enc_class aarch64_enc_call_epilog() %{
<span class="line-modified"> 3456     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3457     if (VerifyStackAtCalls) {
 3458       // Check that stack depth is unchanged: find majik cookie on stack
 3459       __ call_Unimplemented();
 3460     }
 3461   %}
 3462 
 3463   enc_class aarch64_enc_java_to_runtime(method meth) %{
<span class="line-modified"> 3464     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3465 
 3466     // some calls to generated routines (arraycopy code) are scheduled
 3467     // by C2 as runtime calls. if so we can call them using a br (they
 3468     // will be in a reachable segment) otherwise we have to use a blr
 3469     // which loads the absolute address into a register.
 3470     address entry = (address)$meth$$method;
 3471     CodeBlob *cb = CodeCache::find_blob(entry);
 3472     if (cb) {
 3473       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3474       if (call == NULL) {
 3475         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3476         return;
 3477       }
 3478     } else {
 3479       Label retaddr;
 3480       __ adr(rscratch2, retaddr);
 3481       __ lea(rscratch1, RuntimeAddress(entry));
 3482       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3483       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3484       __ blr(rscratch1);
 3485       __ bind(retaddr);
 3486       __ add(sp, sp, 2 * wordSize);
 3487     }
 3488   %}
 3489 
 3490   enc_class aarch64_enc_rethrow() %{
<span class="line-modified"> 3491     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3492     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3493   %}
 3494 
 3495   enc_class aarch64_enc_ret() %{
<span class="line-modified"> 3496     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3497     __ ret(lr);
 3498   %}
 3499 
 3500   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
<span class="line-modified"> 3501     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3502     Register target_reg = as_Register($jump_target$$reg);
 3503     __ br(target_reg);
 3504   %}
 3505 
 3506   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
<span class="line-modified"> 3507     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3508     Register target_reg = as_Register($jump_target$$reg);
 3509     // exception oop should be in r0
 3510     // ret addr has been popped into lr
 3511     // callee expects it in r3
 3512     __ mov(r3, lr);
 3513     __ br(target_reg);
 3514   %}
 3515 
 3516   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
<span class="line-modified"> 3517     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3518     Register oop = as_Register($object$$reg);
 3519     Register box = as_Register($box$$reg);
 3520     Register disp_hdr = as_Register($tmp$$reg);
 3521     Register tmp = as_Register($tmp2$$reg);
 3522     Label cont;
 3523     Label object_has_monitor;
 3524     Label cas_failed;
 3525 
 3526     assert_different_registers(oop, box, tmp, disp_hdr);
 3527 
 3528     // Load markWord from object into displaced_header.
 3529     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3530 
 3531     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3532       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3533     }
 3534 
 3535     // Check for existing monitor
 3536     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3537 
</pre>
<hr />
<pre>
 3575     // otherwise m-&gt;owner may contain a thread or a stack address.
 3576     //
 3577     // Try to CAS m-&gt;owner from NULL to current thread.
 3578     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3579     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3580                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3581 
 3582     // Store a non-null value into the box to avoid looking like a re-entrant
 3583     // lock. The fast-path monitor unlock code checks for
 3584     // markWord::monitor_value so use markWord::unused_mark which has the
 3585     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3586     __ mov(tmp, (address)markWord::unused_mark().value());
 3587     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3588 
 3589     __ bind(cont);
 3590     // flag == EQ indicates success
 3591     // flag == NE indicates failure
 3592   %}
 3593 
 3594   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
<span class="line-modified"> 3595     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3596     Register oop = as_Register($object$$reg);
 3597     Register box = as_Register($box$$reg);
 3598     Register disp_hdr = as_Register($tmp$$reg);
 3599     Register tmp = as_Register($tmp2$$reg);
 3600     Label cont;
 3601     Label object_has_monitor;
 3602 
 3603     assert_different_registers(oop, box, tmp, disp_hdr);
 3604 
 3605     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3606       __ biased_locking_exit(oop, tmp, cont);
 3607     }
 3608 
 3609     // Find the lock address and load the displaced header from the stack.
 3610     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3611 
 3612     // If the displaced header is 0, we have a recursive unlock.
 3613     __ cmp(disp_hdr, zr);
 3614     __ br(Assembler::EQ, cont);
 3615 
</pre>
<hr />
<pre>
 4371   predicate(n-&gt;get_ptr() == 0);
 4372   match(ConP);
 4373 
 4374   op_cost(0);
 4375   format %{ %}
 4376   interface(CONST_INTER);
 4377 %}
 4378 
 4379 // Pointer Immediate One
 4380 // this is used in object initialization (initial object header)
 4381 operand immP_1()
 4382 %{
 4383   predicate(n-&gt;get_ptr() == 1);
 4384   match(ConP);
 4385 
 4386   op_cost(0);
 4387   format %{ %}
 4388   interface(CONST_INTER);
 4389 %}
 4390 











 4391 // Card Table Byte Map Base
 4392 operand immByteMapBase()
 4393 %{
 4394   // Get base of card map
 4395   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4396             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4397   match(ConP);
 4398 
 4399   op_cost(0);
 4400   format %{ %}
 4401   interface(CONST_INTER);
 4402 %}
 4403 
 4404 // Pointer Immediate Minus One
 4405 // this is used when we want to write the current PC to the thread anchor
 4406 operand immP_M1()
 4407 %{
 4408   predicate(n-&gt;get_ptr() == -1);
 4409   match(ConP);
 4410 
</pre>
<hr />
<pre>
 7167 
 7168   ins_encode(aarch64_enc_mov_p0(dst, con));
 7169 
 7170   ins_pipe(ialu_imm);
 7171 %}
 7172 
 7173 // Load Pointer Constant One
 7174 
 7175 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7176 %{
 7177   match(Set dst con);
 7178 
 7179   ins_cost(INSN_COST);
 7180   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7181 
 7182   ins_encode(aarch64_enc_mov_p1(dst, con));
 7183 
 7184   ins_pipe(ialu_imm);
 7185 %}
 7186 














 7187 // Load Byte Map Base Constant
 7188 
 7189 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7190 %{
 7191   match(Set dst con);
 7192 
 7193   ins_cost(INSN_COST);
 7194   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7195 
 7196   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7197 
 7198   ins_pipe(ialu_imm);
 7199 %}
 7200 
 7201 // Load Narrow Pointer Constant
 7202 
 7203 instruct loadConN(iRegNNoSp dst, immN con)
 7204 %{
 7205   match(Set dst con);
 7206 
</pre>
<hr />
<pre>
 8043     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8044     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8045     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8046   %}
 8047 
 8048   ins_pipe(pipe_class_default);
 8049 %}
 8050 
 8051 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8052   predicate(UsePopCountInstruction);
 8053   match(Set dst (PopCountI (LoadI mem)));
 8054   effect(TEMP tmp);
 8055   ins_cost(INSN_COST * 13);
 8056 
 8057   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8058             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8059             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8060             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8061   ins_encode %{
 8062     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
<span class="line-modified"> 8063     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),</span>
 8064               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8065     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8066     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8067     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8068   %}
 8069 
 8070   ins_pipe(pipe_class_default);
 8071 %}
 8072 
 8073 // Note: Long.bitCount(long) returns an int.
 8074 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8075   predicate(UsePopCountInstruction);
 8076   match(Set dst (PopCountL src));
 8077   effect(TEMP tmp);
 8078   ins_cost(INSN_COST * 13);
 8079 
 8080   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8081             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8082             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8083             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
</pre>
<hr />
<pre>
 8086     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8087     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8088     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8089   %}
 8090 
 8091   ins_pipe(pipe_class_default);
 8092 %}
 8093 
 8094 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8095   predicate(UsePopCountInstruction);
 8096   match(Set dst (PopCountL (LoadL mem)));
 8097   effect(TEMP tmp);
 8098   ins_cost(INSN_COST * 13);
 8099 
 8100   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8101             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8102             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8103             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8104   ins_encode %{
 8105     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
<span class="line-modified"> 8106     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),</span>
 8107               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8108     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8109     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8110     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8111   %}
 8112 
 8113   ins_pipe(pipe_class_default);
 8114 %}
 8115 
 8116 // ============================================================================
 8117 // MemBar Instruction
 8118 
 8119 instruct load_fence() %{
 8120   match(LoadFence);
 8121   ins_cost(VOLATILE_REF_COST);
 8122 
 8123   format %{ &quot;load_fence&quot; %}
 8124 
 8125   ins_encode %{
 8126     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
</pre>
<hr />
<pre>
14904 %}
14905 
14906 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14907   match(If cmp (CmpI op1 op2));
14908   effect(USE labl);
14909 
14910   ins_cost(BRANCH_COST);
14911   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14912   ins_encode %{
14913     Label* L = $labl$$label;
14914     Assembler::Condition cond =
14915       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14916     __ tbr(cond, $op1$$Register, 31, *L);
14917   %}
14918   ins_pipe(pipe_cmp_branch);
14919   ins_short_branch(1);
14920 %}
14921 
14922 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14923   match(If cmp (CmpL (AndL op1 op2) op3));
<span class="line-modified">14924   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));</span>
14925   effect(USE labl);
14926 
14927   ins_cost(BRANCH_COST);
14928   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14929   ins_encode %{
14930     Label* L = $labl$$label;
14931     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">14932     int bit = exact_log2_long($op2$$constant);</span>
14933     __ tbr(cond, $op1$$Register, bit, *L);
14934   %}
14935   ins_pipe(pipe_cmp_branch);
14936   ins_short_branch(1);
14937 %}
14938 
14939 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14940   match(If cmp (CmpI (AndI op1 op2) op3));
<span class="line-modified">14941   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));</span>
14942   effect(USE labl);
14943 
14944   ins_cost(BRANCH_COST);
14945   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14946   ins_encode %{
14947     Label* L = $labl$$label;
14948     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">14949     int bit = exact_log2((juint)$op2$$constant);</span>
14950     __ tbr(cond, $op1$$Register, bit, *L);
14951   %}
14952   ins_pipe(pipe_cmp_branch);
14953   ins_short_branch(1);
14954 %}
14955 
14956 // And far variants
14957 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14958   match(If cmp (CmpL op1 op2));
14959   effect(USE labl);
14960 
14961   ins_cost(BRANCH_COST);
14962   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14963   ins_encode %{
14964     Label* L = $labl$$label;
14965     Assembler::Condition cond =
14966       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14967     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
14968   %}
14969   ins_pipe(pipe_cmp_branch);
14970 %}
14971 
14972 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14973   match(If cmp (CmpI op1 op2));
14974   effect(USE labl);
14975 
14976   ins_cost(BRANCH_COST);
14977   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14978   ins_encode %{
14979     Label* L = $labl$$label;
14980     Assembler::Condition cond =
14981       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14982     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
14983   %}
14984   ins_pipe(pipe_cmp_branch);
14985 %}
14986 
14987 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14988   match(If cmp (CmpL (AndL op1 op2) op3));
<span class="line-modified">14989   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));</span>
14990   effect(USE labl);
14991 
14992   ins_cost(BRANCH_COST);
14993   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14994   ins_encode %{
14995     Label* L = $labl$$label;
14996     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">14997     int bit = exact_log2_long($op2$$constant);</span>
14998     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
14999   %}
15000   ins_pipe(pipe_cmp_branch);
15001 %}
15002 
15003 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15004   match(If cmp (CmpI (AndI op1 op2) op3));
<span class="line-modified">15005   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));</span>
15006   effect(USE labl);
15007 
15008   ins_cost(BRANCH_COST);
15009   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15010   ins_encode %{
15011     Label* L = $labl$$label;
15012     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">15013     int bit = exact_log2((juint)$op2$$constant);</span>
15014     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15015   %}
15016   ins_pipe(pipe_cmp_branch);
15017 %}
15018 
15019 // Test bits
15020 
15021 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15022   match(Set cr (CmpL (AndL op1 op2) op3));
15023   predicate(Assembler::operand_valid_for_logical_immediate
15024             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15025 
15026   ins_cost(INSN_COST);
15027   format %{ &quot;tst $op1, $op2 # long&quot; %}
15028   ins_encode %{
15029     __ tst($op1$$Register, $op2$$constant);
15030   %}
15031   ins_pipe(ialu_reg_reg);
15032 %}
15033 
</pre>
<hr />
<pre>
16023   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16024   match(Set dst (ReplicateD src));
16025   ins_cost(INSN_COST);
16026   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16027   ins_encode %{
16028     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16029            as_FloatRegister($src$$reg));
16030   %}
16031   ins_pipe(vdup_reg_dreg128);
16032 %}
16033 
16034 // ====================REDUCTION ARITHMETIC====================================
16035 
16036 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp, iRegINoSp tmp2)
16037 %{
16038   match(Set dst (AddReductionVI src1 src2));
16039   ins_cost(INSN_COST);
16040   effect(TEMP tmp, TEMP tmp2);
16041   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16042             &quot;umov  $tmp2, $src2, S, 1\n\t&quot;
<span class="line-modified">16043             &quot;addw  $tmp, $src1, $tmp\n\t&quot;</span>
<span class="line-modified">16044             &quot;addw  $dst, $tmp, $tmp2\t# add reduction2I&quot;</span>
16045   %}
16046   ins_encode %{
16047     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16048     __ umov($tmp2$$Register, as_FloatRegister($src2$$reg), __ S, 1);
<span class="line-modified">16049     __ addw($tmp$$Register, $src1$$Register, $tmp$$Register);</span>
<span class="line-modified">16050     __ addw($dst$$Register, $tmp$$Register, $tmp2$$Register);</span>
16051   %}
16052   ins_pipe(pipe_class_default);
16053 %}
16054 
16055 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16056 %{
16057   match(Set dst (AddReductionVI src1 src2));
16058   ins_cost(INSN_COST);
16059   effect(TEMP tmp, TEMP tmp2);
16060   format %{ &quot;addv  $tmp, T4S, $src2\n\t&quot;
16061             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
<span class="line-modified">16062             &quot;addw  $dst, $tmp2, $src1\t# add reduction4I&quot;</span>
16063   %}
16064   ins_encode %{
16065     __ addv(as_FloatRegister($tmp$$reg), __ T4S,
16066             as_FloatRegister($src2$$reg));
16067     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16068     __ addw($dst$$Register, $tmp2$$Register, $src1$$Register);
16069   %}
16070   ins_pipe(pipe_class_default);
16071 %}
16072 
16073 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp)
16074 %{
16075   match(Set dst (MulReductionVI src1 src2));
16076   ins_cost(INSN_COST);
16077   effect(TEMP tmp, TEMP dst);
16078   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16079             &quot;mul   $dst, $tmp, $src1\n\t&quot;
16080             &quot;umov  $tmp, $src2, S, 1\n\t&quot;
<span class="line-modified">16081             &quot;mul   $dst, $tmp, $dst\t# mul reduction2I&quot;</span>
16082   %}
16083   ins_encode %{
16084     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16085     __ mul($dst$$Register, $tmp$$Register, $src1$$Register);
16086     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16087     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16088   %}
16089   ins_pipe(pipe_class_default);
16090 %}
16091 
16092 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16093 %{
16094   match(Set dst (MulReductionVI src1 src2));
16095   ins_cost(INSN_COST);
16096   effect(TEMP tmp, TEMP tmp2, TEMP dst);
16097   format %{ &quot;ins   $tmp, $src2, 0, 1\n\t&quot;
16098             &quot;mul   $tmp, $tmp, $src2\n\t&quot;
16099             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16100             &quot;mul   $dst, $tmp2, $src1\n\t&quot;
16101             &quot;umov  $tmp2, $tmp, S, 1\n\t&quot;
<span class="line-modified">16102             &quot;mul   $dst, $tmp2, $dst\t# mul reduction4I&quot;</span>
16103   %}
16104   ins_encode %{
16105     __ ins(as_FloatRegister($tmp$$reg), __ D,
16106            as_FloatRegister($src2$$reg), 0, 1);
16107     __ mulv(as_FloatRegister($tmp$$reg), __ T2S,
16108            as_FloatRegister($tmp$$reg), as_FloatRegister($src2$$reg));
16109     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16110     __ mul($dst$$Register, $tmp2$$Register, $src1$$Register);
16111     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 1);
16112     __ mul($dst$$Register, $tmp2$$Register, $dst$$Register);
16113   %}
16114   ins_pipe(pipe_class_default);
16115 %}
16116 
16117 instruct reduce_add2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16118 %{
16119   match(Set dst (AddReductionVF src1 src2));
16120   ins_cost(INSN_COST);
16121   effect(TEMP tmp, TEMP dst);
16122   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16123             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
<span class="line-modified">16124             &quot;fadds $dst, $dst, $tmp\t# add reduction2F&quot;</span>
16125   %}
16126   ins_encode %{
16127     __ fadds(as_FloatRegister($dst$$reg),
16128              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16129     __ ins(as_FloatRegister($tmp$$reg), __ S,
16130            as_FloatRegister($src2$$reg), 0, 1);
16131     __ fadds(as_FloatRegister($dst$$reg),
16132              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16133   %}
16134   ins_pipe(pipe_class_default);
16135 %}
16136 
16137 instruct reduce_add4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16138 %{
16139   match(Set dst (AddReductionVF src1 src2));
16140   ins_cost(INSN_COST);
16141   effect(TEMP tmp, TEMP dst);
16142   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16143             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16144             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16145             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16146             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16147             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
<span class="line-modified">16148             &quot;fadds $dst, $dst, $tmp\t# add reduction4F&quot;</span>
16149   %}
16150   ins_encode %{
16151     __ fadds(as_FloatRegister($dst$$reg),
16152              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16153     __ ins(as_FloatRegister($tmp$$reg), __ S,
16154            as_FloatRegister($src2$$reg), 0, 1);
16155     __ fadds(as_FloatRegister($dst$$reg),
16156              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16157     __ ins(as_FloatRegister($tmp$$reg), __ S,
16158            as_FloatRegister($src2$$reg), 0, 2);
16159     __ fadds(as_FloatRegister($dst$$reg),
16160              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16161     __ ins(as_FloatRegister($tmp$$reg), __ S,
16162            as_FloatRegister($src2$$reg), 0, 3);
16163     __ fadds(as_FloatRegister($dst$$reg),
16164              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16165   %}
16166   ins_pipe(pipe_class_default);
16167 %}
16168 
16169 instruct reduce_mul2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16170 %{
16171   match(Set dst (MulReductionVF src1 src2));
16172   ins_cost(INSN_COST);
16173   effect(TEMP tmp, TEMP dst);
16174   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16175             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
<span class="line-modified">16176             &quot;fmuls $dst, $dst, $tmp\t# mul reduction2F&quot;</span>
16177   %}
16178   ins_encode %{
16179     __ fmuls(as_FloatRegister($dst$$reg),
16180              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16181     __ ins(as_FloatRegister($tmp$$reg), __ S,
16182            as_FloatRegister($src2$$reg), 0, 1);
16183     __ fmuls(as_FloatRegister($dst$$reg),
16184              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16185   %}
16186   ins_pipe(pipe_class_default);
16187 %}
16188 
16189 instruct reduce_mul4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16190 %{
16191   match(Set dst (MulReductionVF src1 src2));
16192   ins_cost(INSN_COST);
16193   effect(TEMP tmp, TEMP dst);
16194   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16195             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16196             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16197             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16198             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16199             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
<span class="line-modified">16200             &quot;fmuls $dst, $dst, $tmp\t# mul reduction4F&quot;</span>
16201   %}
16202   ins_encode %{
16203     __ fmuls(as_FloatRegister($dst$$reg),
16204              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16205     __ ins(as_FloatRegister($tmp$$reg), __ S,
16206            as_FloatRegister($src2$$reg), 0, 1);
16207     __ fmuls(as_FloatRegister($dst$$reg),
16208              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16209     __ ins(as_FloatRegister($tmp$$reg), __ S,
16210            as_FloatRegister($src2$$reg), 0, 2);
16211     __ fmuls(as_FloatRegister($dst$$reg),
16212              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16213     __ ins(as_FloatRegister($tmp$$reg), __ S,
16214            as_FloatRegister($src2$$reg), 0, 3);
16215     __ fmuls(as_FloatRegister($dst$$reg),
16216              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16217   %}
16218   ins_pipe(pipe_class_default);
16219 %}
16220 
16221 instruct reduce_add2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16222 %{
16223   match(Set dst (AddReductionVD src1 src2));
16224   ins_cost(INSN_COST);
16225   effect(TEMP tmp, TEMP dst);
16226   format %{ &quot;faddd $dst, $src1, $src2\n\t&quot;
16227             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
<span class="line-modified">16228             &quot;faddd $dst, $dst, $tmp\t# add reduction2D&quot;</span>
16229   %}
16230   ins_encode %{
16231     __ faddd(as_FloatRegister($dst$$reg),
16232              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16233     __ ins(as_FloatRegister($tmp$$reg), __ D,
16234            as_FloatRegister($src2$$reg), 0, 1);
16235     __ faddd(as_FloatRegister($dst$$reg),
16236              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16237   %}
16238   ins_pipe(pipe_class_default);
16239 %}
16240 
16241 instruct reduce_mul2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16242 %{
16243   match(Set dst (MulReductionVD src1 src2));
16244   ins_cost(INSN_COST);
16245   effect(TEMP tmp, TEMP dst);
16246   format %{ &quot;fmuld $dst, $src1, $src2\n\t&quot;
16247             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
<span class="line-modified">16248             &quot;fmuld $dst, $dst, $tmp\t# mul reduction2D&quot;</span>
16249   %}
16250   ins_encode %{
16251     __ fmuld(as_FloatRegister($dst$$reg),
16252              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16253     __ ins(as_FloatRegister($tmp$$reg), __ D,
16254            as_FloatRegister($src2$$reg), 0, 1);
16255     __ fmuld(as_FloatRegister($dst$$reg),
16256              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16257   %}
16258   ins_pipe(pipe_class_default);
16259 %}
16260 
16261 instruct reduce_max2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16262   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16263   match(Set dst (MaxReductionV src1 src2));
16264   ins_cost(INSN_COST);
16265   effect(TEMP_DEF dst, TEMP tmp);
16266   format %{ &quot;fmaxs $dst, $src1, $src2\n\t&quot;
16267             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
<span class="line-modified">16268             &quot;fmaxs $dst, $dst, $tmp\t# max reduction2F&quot; %}</span>
16269   ins_encode %{
16270     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16271     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16272     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16273   %}
16274   ins_pipe(pipe_class_default);
16275 %}
16276 
16277 instruct reduce_max4F(vRegF dst, vRegF src1, vecX src2) %{
16278   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16279   match(Set dst (MaxReductionV src1 src2));
16280   ins_cost(INSN_COST);
16281   effect(TEMP_DEF dst);
16282   format %{ &quot;fmaxv $dst, T4S, $src2\n\t&quot;
<span class="line-modified">16283             &quot;fmaxs $dst, $dst, $src1\t# max reduction4F&quot; %}</span>
16284   ins_encode %{
16285     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16286     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16287   %}
16288   ins_pipe(pipe_class_default);
16289 %}
16290 
16291 instruct reduce_max2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16292   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16293   match(Set dst (MaxReductionV src1 src2));
16294   ins_cost(INSN_COST);
16295   effect(TEMP_DEF dst, TEMP tmp);
16296   format %{ &quot;fmaxd $dst, $src1, $src2\n\t&quot;
16297             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
<span class="line-modified">16298             &quot;fmaxd $dst, $dst, $tmp\t# max reduction2D&quot; %}</span>
16299   ins_encode %{
16300     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16301     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16302     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16303   %}
16304   ins_pipe(pipe_class_default);
16305 %}
16306 
16307 instruct reduce_min2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16308   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16309   match(Set dst (MinReductionV src1 src2));
16310   ins_cost(INSN_COST);
16311   effect(TEMP_DEF dst, TEMP tmp);
16312   format %{ &quot;fmins $dst, $src1, $src2\n\t&quot;
16313             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
<span class="line-modified">16314             &quot;fmins $dst, $dst, $tmp\t# min reduction2F&quot; %}</span>
16315   ins_encode %{
16316     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16317     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16318     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16319   %}
16320   ins_pipe(pipe_class_default);
16321 %}
16322 
16323 instruct reduce_min4F(vRegF dst, vRegF src1, vecX src2) %{
16324   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16325   match(Set dst (MinReductionV src1 src2));
16326   ins_cost(INSN_COST);
16327   effect(TEMP_DEF dst);
16328   format %{ &quot;fminv $dst, T4S, $src2\n\t&quot;
<span class="line-modified">16329             &quot;fmins $dst, $dst, $src1\t# min reduction4F&quot; %}</span>
16330   ins_encode %{
16331     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16332     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16333   %}
16334   ins_pipe(pipe_class_default);
16335 %}
16336 
16337 instruct reduce_min2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16338   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16339   match(Set dst (MinReductionV src1 src2));
16340   ins_cost(INSN_COST);
16341   effect(TEMP_DEF dst, TEMP tmp);
16342   format %{ &quot;fmind $dst, $src1, $src2\n\t&quot;
16343             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
<span class="line-modified">16344             &quot;fmind $dst, $dst, $tmp\t# min reduction2D&quot; %}</span>
16345   ins_encode %{
16346     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16347     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16348     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16349   %}
16350   ins_pipe(pipe_class_default);
16351 %}
16352 
16353 // ====================VECTOR ARITHMETIC=======================================
16354 
16355 // --------------------------------- ADD --------------------------------------
16356 
16357 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16358 %{
16359   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16360             n-&gt;as_Vector()-&gt;length() == 8);
16361   match(Set dst (AddVB src1 src2));
16362   ins_cost(INSN_COST);
16363   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16364   ins_encode %{
</pre>
<hr />
<pre>
16934 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16935   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16936   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16937   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16938   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16939   ins_cost(INSN_COST);
16940   ins_encode %{
16941     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16942             as_FloatRegister($src1$$reg),
16943             as_FloatRegister($src2$$reg));
16944   %}
16945   ins_pipe(vmuldiv_fp128);
16946 %}
16947 
16948 // --------------- Vector Multiply-Add Shorts into Integer --------------------
16949 
16950 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
16951   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
16952   match(Set dst (MulAddVS2VI src1 src2));
16953   ins_cost(INSN_COST);
<span class="line-modified">16954   effect(TEMP_DEF dst, TEMP tmp);</span>
16955   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
16956             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
16957             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
16958   ins_encode %{
16959     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
16960               as_FloatRegister($src1$$reg),
16961               as_FloatRegister($src2$$reg));
16962     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
16963               as_FloatRegister($src1$$reg),
16964               as_FloatRegister($src2$$reg));
16965     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
16966              as_FloatRegister($tmp$$reg),
16967              as_FloatRegister($dst$$reg));
16968   %}
16969   ins_pipe(vmuldiv_fp128);
16970 %}
16971 
16972 // --------------------------------- DIV --------------------------------------
16973 
16974 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
</pre>
<hr />
<pre>
18002   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18003   ins_encode %{
18004     switch ($rmode$$constant) {
18005       case RoundDoubleModeNode::rmode_rint:
18006         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18007                   as_FloatRegister($src$$reg));
18008         break;
18009       case RoundDoubleModeNode::rmode_floor:
18010         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18011                   as_FloatRegister($src$$reg));
18012         break;
18013       case RoundDoubleModeNode::rmode_ceil:
18014         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18015                   as_FloatRegister($src$$reg));
18016         break;
18017     }
18018   %}
18019   ins_pipe(vdop_fp128);
18020 %}
18021 
<span class="line-added">18022 instruct vpopcount4I(vecX dst, vecX src) %{</span>
<span class="line-added">18023   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-added">18024   match(Set dst (PopCountVI src));</span>
<span class="line-added">18025   format %{</span>
<span class="line-added">18026     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;</span>
<span class="line-added">18027     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;</span>
<span class="line-added">18028     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;</span>
<span class="line-added">18029   %}</span>
<span class="line-added">18030   ins_encode %{</span>
<span class="line-added">18031      __ cnt(as_FloatRegister($dst$$reg), __ T16B,</span>
<span class="line-added">18032             as_FloatRegister($src$$reg));</span>
<span class="line-added">18033      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,</span>
<span class="line-added">18034                as_FloatRegister($dst$$reg));</span>
<span class="line-added">18035      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,</span>
<span class="line-added">18036                as_FloatRegister($dst$$reg));</span>
<span class="line-added">18037   %}</span>
<span class="line-added">18038   ins_pipe(pipe_class_default);</span>
<span class="line-added">18039 %}</span>
<span class="line-added">18040 </span>
<span class="line-added">18041 instruct vpopcount2I(vecD dst, vecD src) %{</span>
<span class="line-added">18042   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-added">18043   match(Set dst (PopCountVI src));</span>
<span class="line-added">18044   format %{</span>
<span class="line-added">18045     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;</span>
<span class="line-added">18046     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;</span>
<span class="line-added">18047     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;</span>
<span class="line-added">18048   %}</span>
<span class="line-added">18049   ins_encode %{</span>
<span class="line-added">18050      __ cnt(as_FloatRegister($dst$$reg), __ T8B,</span>
<span class="line-added">18051             as_FloatRegister($src$$reg));</span>
<span class="line-added">18052      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,</span>
<span class="line-added">18053                as_FloatRegister($dst$$reg));</span>
<span class="line-added">18054      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,</span>
<span class="line-added">18055                as_FloatRegister($dst$$reg));</span>
<span class="line-added">18056   %}</span>
<span class="line-added">18057   ins_pipe(pipe_class_default);</span>
<span class="line-added">18058 %}</span>
<span class="line-added">18059 </span>
18060 //----------PEEPHOLE RULES-----------------------------------------------------
18061 // These must follow all instruction definitions as they use the names
18062 // defined in the instructions definitions.
18063 //
18064 // peepmatch ( root_instr_name [preceding_instruction]* );
18065 //
18066 // peepconstraint %{
18067 // (instruction_number.operand_name relational_op instruction_number.operand_name
18068 //  [, ...] );
18069 // // instruction numbers are zero-based using left to right order in peepmatch
18070 //
18071 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18072 // // provide an instruction_number.operand_name for each operand that appears
18073 // // in the replacement instruction&#39;s match rule
18074 //
18075 // ---------VM FLAGS---------------------------------------------------------
18076 //
18077 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18078 //
18079 // Each peephole rule is given an identifying number starting with zero and
</pre>
</td>
</tr>
</table>
<center><a href="../../../demo/share/jfc/TableExample/TableSorter.java.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="assembler_aarch64.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>