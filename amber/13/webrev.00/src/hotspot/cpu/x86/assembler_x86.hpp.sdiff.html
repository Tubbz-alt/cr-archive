<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/assembler_x86.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="assembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRAssembler_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/assembler_x86.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
</pre>
<hr />
<pre>
 322 #endif // ASSERT
 323 
 324   // accessors
 325   bool        uses(Register reg) const { return _base == reg || _index == reg; }
 326   Register    base()             const { return _base;  }
 327   Register    index()            const { return _index; }
 328   XMMRegister xmmindex()         const { return _xmmindex; }
 329   ScaleFactor scale()            const { return _scale; }
 330   int         disp()             const { return _disp;  }
 331   bool        isxmmindex()       const { return _isxmmindex; }
 332 
 333   // Convert the raw encoding form into the form expected by the constructor for
 334   // Address.  An index of 4 (rsp) corresponds to having no index, so convert
 335   // that to noreg for the Address constructor.
 336   static Address make_raw(int base, int index, int scale, int disp, relocInfo::relocType disp_reloc);
 337 
 338   static Address make_array(ArrayAddress);
 339 
 340  private:
 341   bool base_needs_rex() const {
<span class="line-modified"> 342     return _base != noreg &amp;&amp; _base-&gt;encoding() &gt;= 8;</span>
 343   }
 344 
 345   bool index_needs_rex() const {
<span class="line-modified"> 346     return _index != noreg &amp;&amp;_index-&gt;encoding() &gt;= 8;</span>
 347   }
 348 
 349   bool xmmindex_needs_rex() const {
<span class="line-modified"> 350     return _xmmindex != xnoreg &amp;&amp; _xmmindex-&gt;encoding() &gt;= 8;</span>
 351   }
 352 
 353   relocInfo::relocType reloc() const { return _rspec.type(); }
 354 
 355   friend class Assembler;
 356   friend class MacroAssembler;
 357   friend class LIR_Assembler; // base/index/scale/disp
 358 };
 359 
 360 //
 361 // AddressLiteral has been split out from Address because operands of this type
 362 // need to be treated specially on 32bit vs. 64bit platforms. By splitting it out
 363 // the few instructions that need to deal with address literals are unique and the
 364 // MacroAssembler does not have to implement every instruction in the Assembler
 365 // in order to search for address literals that may need special handling depending
 366 // on the instruction and the platform. As small step on the way to merging i486/amd64
 367 // directories.
 368 //
 369 class AddressLiteral {
 370   friend class ArrayAddress;
</pre>
<hr />
<pre>
 642   // We could use a &quot;safe enough&quot; estimate (15), but just default to
 643   // instruction length guess from above.
 644   static unsigned int instr_maxlen() { return 4; }
 645 
 646   // NOTE: The general philopsophy of the declarations here is that 64bit versions
 647   // of instructions are freely declared without the need for wrapping them an ifdef.
 648   // (Some dangerous instructions are ifdef&#39;s out of inappropriate jvm&#39;s.)
 649   // In the .cpp file the implementations are wrapped so that they are dropped out
 650   // of the resulting jvm. This is done mostly to keep the footprint of MINIMAL
 651   // to the size it was prior to merging up the 32bit and 64bit assemblers.
 652   //
 653   // This does mean you&#39;ll get a linker/runtime error if you use a 64bit only instruction
 654   // in a 32bit vm. This is somewhat unfortunate but keeps the ifdef noise down.
 655 
 656 private:
 657 
 658   bool _legacy_mode_bw;
 659   bool _legacy_mode_dq;
 660   bool _legacy_mode_vl;
 661   bool _legacy_mode_vlbw;
<span class="line-modified"> 662   bool _is_managed;</span>
 663 
 664   class InstructionAttr *_attributes;
 665 
 666   // 64bit prefixes
<span class="line-modified"> 667   int prefix_and_encode(int reg_enc, bool byteinst = false);</span>
<span class="line-modified"> 668   int prefixq_and_encode(int reg_enc);</span>

 669 





 670   int prefix_and_encode(int dst_enc, int src_enc) {
 671     return prefix_and_encode(dst_enc, false, src_enc, false);
 672   }
 673   int prefix_and_encode(int dst_enc, bool dst_is_byte, int src_enc, bool src_is_byte);
<span class="line-removed"> 674   int prefixq_and_encode(int dst_enc, int src_enc);</span>
 675 
<span class="line-modified"> 676   void prefix(Register reg);</span>
<span class="line-modified"> 677   void prefix(Register dst, Register src, Prefix p);</span>
<span class="line-modified"> 678   void prefix(Register dst, Address adr, Prefix p);</span>
<span class="line-modified"> 679   void prefix(Address adr);</span>
<span class="line-modified"> 680   void prefixq(Address adr);</span>
 681 
<span class="line-modified"> 682   void prefix(Address adr, Register reg,  bool byteinst = false);</span>
<span class="line-removed"> 683   void prefix(Address adr, XMMRegister reg);</span>
 684   void prefixq(Address adr, Register reg);
 685   void prefixq(Address adr, XMMRegister reg);
 686 
<span class="line-modified"> 687   void prefetch_prefix(Address src);</span>

 688 
 689   void rex_prefix(Address adr, XMMRegister xreg,
 690                   VexSimdPrefix pre, VexOpcode opc, bool rex_w);
 691   int  rex_prefix_and_encode(int dst_enc, int src_enc,
 692                              VexSimdPrefix pre, VexOpcode opc, bool rex_w);
 693 
 694   void vex_prefix(bool vex_r, bool vex_b, bool vex_x, int nds_enc, VexSimdPrefix pre, VexOpcode opc);
 695 
 696   void evex_prefix(bool vex_r, bool vex_b, bool vex_x, bool evex_r, bool evex_v,
 697                    int nds_enc, VexSimdPrefix pre, VexOpcode opc);
 698 
 699   void vex_prefix(Address adr, int nds_enc, int xreg_enc,
 700                   VexSimdPrefix pre, VexOpcode opc,
 701                   InstructionAttr *attributes);
 702 
 703   int  vex_prefix_and_encode(int dst_enc, int nds_enc, int src_enc,
 704                              VexSimdPrefix pre, VexOpcode opc,
 705                              InstructionAttr *attributes);
 706 
 707   void simd_prefix(XMMRegister xreg, XMMRegister nds, Address adr, VexSimdPrefix pre,
 708                    VexOpcode opc, InstructionAttr *attributes);
 709 
 710   int simd_prefix_and_encode(XMMRegister dst, XMMRegister nds, XMMRegister src, VexSimdPrefix pre,
 711                              VexOpcode opc, InstructionAttr *attributes);
 712 
 713   // Helper functions for groups of instructions
 714   void emit_arith_b(int op1, int op2, Register dst, int imm8);
 715 
 716   void emit_arith(int op1, int op2, Register dst, int32_t imm32);
 717   // Force generation of a 4 byte immediate value even if it fits into 8bit
 718   void emit_arith_imm32(int op1, int op2, Register dst, int32_t imm32);
 719   void emit_arith(int op1, int op2, Register dst, Register src);
 720 
 721   bool emit_compressed_disp_byte(int &amp;disp);
 722 















 723   void emit_operand(Register reg,
 724                     Register base, Register index, Address::ScaleFactor scale,
 725                     int disp,
 726                     RelocationHolder const&amp; rspec,
 727                     int rip_relative_correction = 0);
 728 
<span class="line-modified"> 729   void emit_operand(XMMRegister reg, Register base, XMMRegister index,</span>
<span class="line-modified"> 730                     Address::ScaleFactor scale,</span>
<span class="line-modified"> 731                     int disp, RelocationHolder const&amp; rspec);</span>

 732 
<span class="line-modified"> 733   void emit_operand(Register reg, Address adr, int rip_relative_correction = 0);</span>



 734 
<span class="line-modified"> 735   // operands that only take the original 32bit registers</span>
<span class="line-modified"> 736   void emit_operand32(Register reg, Address adr);</span>
 737 
 738   void emit_operand(XMMRegister reg,
 739                     Register base, Register index, Address::ScaleFactor scale,
 740                     int disp,
 741                     RelocationHolder const&amp; rspec);
 742 
 743   void emit_operand(XMMRegister reg, Address adr);
 744 
<span class="line-removed"> 745   void emit_operand(MMXRegister reg, Address adr);</span>
<span class="line-removed"> 746 </span>
<span class="line-removed"> 747   // workaround gcc (3.2.1-7) bug</span>
<span class="line-removed"> 748   void emit_operand(Address adr, MMXRegister reg);</span>
<span class="line-removed"> 749 </span>
<span class="line-removed"> 750 </span>
 751   // Immediate-to-memory forms
 752   void emit_arith_operand(int op1, Register rm, Address adr, int32_t imm32);
 753 
<span class="line-removed"> 754   void emit_farith(int b1, int b2, int i);</span>
<span class="line-removed"> 755 </span>
<span class="line-removed"> 756 </span>
 757  protected:
 758   #ifdef ASSERT
 759   void check_relocation(RelocationHolder const&amp; rspec, int format);
 760   #endif
 761 
 762   void emit_data(jint data, relocInfo::relocType    rtype, int format);
 763   void emit_data(jint data, RelocationHolder const&amp; rspec, int format);
 764   void emit_data64(jlong data, relocInfo::relocType rtype, int format = 0);
 765   void emit_data64(jlong data, RelocationHolder const&amp; rspec, int format = 0);
 766 
 767   bool reachable(AddressLiteral adr) NOT_LP64({ return true;});
 768 
 769   // These are all easily abused and hence protected
 770 
 771   // 32BIT ONLY SECTION
 772 #ifndef _LP64
 773   // Make these disappear in 64bit mode since they would never be correct
 774   void cmp_literal32(Register src1, int32_t imm32, RelocationHolder const&amp; rspec);   // 32BIT ONLY
 775   void cmp_literal32(Address src1, int32_t imm32, RelocationHolder const&amp; rspec);    // 32BIT ONLY
 776 
</pre>
<hr />
<pre>
 840   void movapd(XMMRegister dst, XMMRegister src);
 841 
 842   // End avoid using directly
 843 
 844 
 845   // Instruction prefixes
 846   void prefix(Prefix p);
 847 
 848   public:
 849 
 850   // Creation
 851   Assembler(CodeBuffer* code) : AbstractAssembler(code) {
 852     init_attributes();
 853   }
 854 
 855   // Decoding
 856   static address locate_operand(address inst, WhichOperand which);
 857   static address locate_next_instruction(address inst);
 858 
 859   // Utilities
<span class="line-removed"> 860   static bool is_polling_page_far() NOT_LP64({ return false;});</span>
 861   static bool query_compressed_disp_byte(int disp, bool is_evex_inst, int vector_len,
 862                                          int cur_tuple_type, int in_size_in_bits, int cur_encoding);
 863 
 864   // Generic instructions
 865   // Does 32bit or 64bit as needed for the platform. In some sense these
 866   // belong in macro assembler but there is no need for both varieties to exist
 867 
 868   void init_attributes(void) {
 869     _legacy_mode_bw = (VM_Version::supports_avx512bw() == false);
 870     _legacy_mode_dq = (VM_Version::supports_avx512dq() == false);
 871     _legacy_mode_vl = (VM_Version::supports_avx512vl() == false);
 872     _legacy_mode_vlbw = (VM_Version::supports_avx512vlbw() == false);
<span class="line-modified"> 873     _is_managed = false;</span>
 874     _attributes = NULL;
 875   }
 876 
 877   void set_attributes(InstructionAttr *attributes) { _attributes = attributes; }
 878   void clear_attributes(void) { _attributes = NULL; }
 879 
<span class="line-modified"> 880   void set_managed(void) { _is_managed = true; }</span>
<span class="line-modified"> 881   void clear_managed(void) { _is_managed = false; }</span>
<span class="line-modified"> 882   bool is_managed(void) { return _is_managed; }</span>


 883 
 884   void lea(Register dst, Address src);
 885 
 886   void mov(Register dst, Register src);
 887 











 888   void pusha();
 889   void popa();
 890 
 891   void pushf();
 892   void popf();
 893 
 894   void push(int32_t imm32);
 895 
 896   void push(Register src);
 897 
 898   void pop(Register dst);
 899 
 900   // These are dummies to prevent surprise implicit conversions to Register
 901   void push(void* v);
 902   void pop(void* v);
 903 
 904   // These do register sized moves/scans
 905   void rep_mov();
 906   void rep_stos();
 907   void rep_stosb();
</pre>
<hr />
<pre>
1118 
1119   void cvttpd2dq(XMMRegister dst, XMMRegister src);
1120 
1121   //Abs of packed Integer values
1122   void pabsb(XMMRegister dst, XMMRegister src);
1123   void pabsw(XMMRegister dst, XMMRegister src);
1124   void pabsd(XMMRegister dst, XMMRegister src);
1125   void vpabsb(XMMRegister dst, XMMRegister src, int vector_len);
1126   void vpabsw(XMMRegister dst, XMMRegister src, int vector_len);
1127   void vpabsd(XMMRegister dst, XMMRegister src, int vector_len);
1128   void evpabsq(XMMRegister dst, XMMRegister src, int vector_len);
1129 
1130   // Divide Scalar Double-Precision Floating-Point Values
1131   void divsd(XMMRegister dst, Address src);
1132   void divsd(XMMRegister dst, XMMRegister src);
1133 
1134   // Divide Scalar Single-Precision Floating-Point Values
1135   void divss(XMMRegister dst, Address src);
1136   void divss(XMMRegister dst, XMMRegister src);
1137 
<span class="line-removed">1138   void emms();</span>
1139 
1140 #ifndef _LP64









1141   void fabs();
1142 
1143   void fadd(int i);
1144 
1145   void fadd_d(Address src);
1146   void fadd_s(Address src);
1147 
1148   // &quot;Alternate&quot; versions of x87 instructions place result down in FPU
1149   // stack instead of on TOS
1150 
1151   void fadda(int i); // &quot;alternate&quot; fadd
1152   void faddp(int i = 1);
1153 
1154   void fchs();
1155 
1156   void fcom(int i);
1157 
1158   void fcomp(int i = 1);
1159   void fcomp_d(Address src);
1160   void fcomp_s(Address src);
</pre>
<hr />
<pre>
1486 
1487   // Move lower 64bit to high 64bit in 128bit register
1488   void movlhps(XMMRegister dst, XMMRegister src);
1489 
1490   void movl(Register dst, int32_t imm32);
1491   void movl(Address dst, int32_t imm32);
1492   void movl(Register dst, Register src);
1493   void movl(Register dst, Address src);
1494   void movl(Address dst, Register src);
1495 
1496   // These dummies prevent using movl from converting a zero (like NULL) into Register
1497   // by giving the compiler two choices it can&#39;t resolve
1498 
1499   void movl(Address  dst, void* junk);
1500   void movl(Register dst, void* junk);
1501 
1502 #ifdef _LP64
1503   void movq(Register dst, Register src);
1504   void movq(Register dst, Address src);
1505   void movq(Address  dst, Register src);
<span class="line-removed">1506 #endif</span>
<span class="line-removed">1507 </span>
<span class="line-removed">1508   void movq(Address     dst, MMXRegister src );</span>
<span class="line-removed">1509   void movq(MMXRegister dst, Address src );</span>
1510 
<span class="line-removed">1511 #ifdef _LP64</span>
1512   // These dummies prevent using movq from converting a zero (like NULL) into Register
1513   // by giving the compiler two choices it can&#39;t resolve
1514 
1515   void movq(Address  dst, void* dummy);
1516   void movq(Register dst, void* dummy);
1517 #endif
1518 
1519   // Move Quadword
1520   void movq(Address     dst, XMMRegister src);
1521   void movq(XMMRegister dst, Address src);
1522 
1523   void movsbl(Register dst, Address src);
1524   void movsbl(Register dst, Register src);
1525 
1526 #ifdef _LP64
1527   void movsbq(Register dst, Address src);
1528   void movsbq(Register dst, Register src);
1529 
1530   // Move signed 32bit immediate to 64bit extending sign
1531   void movslq(Address  dst, int32_t imm64);
</pre>
<hr />
<pre>
2151   void vpand(XMMRegister dst, XMMRegister nds, Address src, int vector_len);
2152   void vpandq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);
2153 
2154   // Andn packed integers
2155   void pandn(XMMRegister dst, XMMRegister src);
2156   void vpandn(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);
2157 
2158   // Or packed integers
2159   void por(XMMRegister dst, XMMRegister src);
2160   void vpor(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);
2161   void vpor(XMMRegister dst, XMMRegister nds, Address src, int vector_len);
2162   void vporq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);
2163 
2164   // Xor packed integers
2165   void pxor(XMMRegister dst, XMMRegister src);
2166   void vpxor(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);
2167   void vpxor(XMMRegister dst, XMMRegister nds, Address src, int vector_len);
2168   void evpxorq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);
2169   void evpxorq(XMMRegister dst, XMMRegister nds, Address src, int vector_len);
2170 



2171 
2172   // vinserti forms
2173   void vinserti128(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8);
2174   void vinserti128(XMMRegister dst, XMMRegister nds, Address src, uint8_t imm8);
2175   void vinserti32x4(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8);
2176   void vinserti32x4(XMMRegister dst, XMMRegister nds, Address src, uint8_t imm8);
2177   void vinserti64x4(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8);
2178 
2179   // vinsertf forms
2180   void vinsertf128(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8);
2181   void vinsertf128(XMMRegister dst, XMMRegister nds, Address src, uint8_t imm8);
2182   void vinsertf32x4(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8);
2183   void vinsertf32x4(XMMRegister dst, XMMRegister nds, Address src, uint8_t imm8);
2184   void vinsertf64x4(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8);
2185   void vinsertf64x4(XMMRegister dst, XMMRegister nds, Address src, uint8_t imm8);
2186 
2187   // vextracti forms
2188   void vextracti128(XMMRegister dst, XMMRegister src, uint8_t imm8);
2189   void vextracti128(Address dst, XMMRegister src, uint8_t imm8);
2190   void vextracti32x4(XMMRegister dst, XMMRegister src, uint8_t imm8);
</pre>
<hr />
<pre>
2252   // They should be called only from corresponding MacroAssembler instructions.
2253   void andpd(XMMRegister dst, Address src);
2254   void andps(XMMRegister dst, Address src);
2255   void xorpd(XMMRegister dst, Address src);
2256   void xorps(XMMRegister dst, Address src);
2257 
2258 };
2259 
2260 // The Intel x86/Amd64 Assembler attributes: All fields enclosed here are to guide encoding level decisions.
2261 // Specific set functions are for specialized use, else defaults or whatever was supplied to object construction
2262 // are applied.
2263 class InstructionAttr {
2264 public:
2265   InstructionAttr(
2266     int vector_len,     // The length of vector to be applied in encoding - for both AVX and EVEX
2267     bool rex_vex_w,     // Width of data: if 32-bits or less, false, else if 64-bit or specially defined, true
2268     bool legacy_mode,   // Details if either this instruction is conditionally encoded to AVX or earlier if true else possibly EVEX
2269     bool no_reg_mask,   // when true, k0 is used when EVEX encoding is chosen, else embedded_opmask_register_specifier is used
2270     bool uses_vl)       // This instruction may have legacy constraints based on vector length for EVEX
2271     :
<span class="line-removed">2272       _avx_vector_len(vector_len),</span>
2273       _rex_vex_w(rex_vex_w),
<span class="line-modified">2274       _rex_vex_w_reverted(false),</span>
<span class="line-removed">2275       _legacy_mode(legacy_mode),</span>
2276       _no_reg_mask(no_reg_mask),
2277       _uses_vl(uses_vl),
<span class="line-modified">2278       _tuple_type(Assembler::EVEX_ETUP),</span>
<span class="line-removed">2279       _input_size_in_bits(Assembler::EVEX_NObit),</span>
2280       _is_evex_instruction(false),
<span class="line-removed">2281       _evex_encoding(0),</span>
2282       _is_clear_context(true),
2283       _is_extended_context(false),




2284       _embedded_opmask_register_specifier(0), // hard code k0
<span class="line-modified">2285       _current_assembler(NULL) {</span>
<span class="line-removed">2286     if (UseAVX &lt; 3) _legacy_mode = true;</span>
<span class="line-removed">2287   }</span>
2288 
2289   ~InstructionAttr() {
2290     if (_current_assembler != NULL) {
2291       _current_assembler-&gt;clear_attributes();
2292     }
2293     _current_assembler = NULL;
2294   }
2295 
2296 private:
<span class="line-removed">2297   int  _avx_vector_len;</span>
2298   bool _rex_vex_w;
<span class="line-removed">2299   bool _rex_vex_w_reverted;</span>
2300   bool _legacy_mode;
2301   bool _no_reg_mask;
2302   bool _uses_vl;
<span class="line-modified">2303   int  _tuple_type;</span>
<span class="line-removed">2304   int  _input_size_in_bits;</span>
2305   bool _is_evex_instruction;
<span class="line-removed">2306   int  _evex_encoding;</span>
2307   bool _is_clear_context;
2308   bool _is_extended_context;




2309   int _embedded_opmask_register_specifier;
2310 
2311   Assembler *_current_assembler;
2312 
2313 public:
2314   // query functions for field accessors
<span class="line-removed">2315   int  get_vector_len(void) const { return _avx_vector_len; }</span>
2316   bool is_rex_vex_w(void) const { return _rex_vex_w; }
<span class="line-removed">2317   bool is_rex_vex_w_reverted(void) { return _rex_vex_w_reverted; }</span>
2318   bool is_legacy_mode(void) const { return _legacy_mode; }
2319   bool is_no_reg_mask(void) const { return _no_reg_mask; }
2320   bool uses_vl(void) const { return _uses_vl; }





2321   int  get_tuple_type(void) const { return _tuple_type; }
2322   int  get_input_size(void) const { return _input_size_in_bits; }
<span class="line-removed">2323   int  is_evex_instruction(void) const { return _is_evex_instruction; }</span>
2324   int  get_evex_encoding(void) const { return _evex_encoding; }
<span class="line-modified">2325   bool is_clear_context(void) const { return _is_clear_context; }</span>
<span class="line-removed">2326   bool is_extended_context(void) const { return _is_extended_context; }</span>
<span class="line-removed">2327   int get_embedded_opmask_register_specifier(void) const { return _embedded_opmask_register_specifier; }</span>
2328 
2329   // Set the vector len manually
2330   void set_vector_len(int vector_len) { _avx_vector_len = vector_len; }
2331 
2332   // Set revert rex_vex_w for avx encoding
2333   void set_rex_vex_w_reverted(void) { _rex_vex_w_reverted = true; }
2334 
2335   // Set rex_vex_w based on state
2336   void set_rex_vex_w(bool state) { _rex_vex_w = state; }
2337 
2338   // Set the instruction to be encoded in AVX mode
2339   void set_is_legacy_mode(void) { _legacy_mode = true; }
2340 
2341   // Set the current instuction to be encoded as an EVEX instuction
2342   void set_is_evex_instruction(void) { _is_evex_instruction = true; }
2343 
2344   // Internal encoding data used in compressed immediate offset programming
2345   void set_evex_encoding(int value) { _evex_encoding = value; }
2346 
2347   // Set the Evex.Z field to be used to clear all non directed XMM/YMM/ZMM components
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
</pre>
<hr />
<pre>
 322 #endif // ASSERT
 323 
 324   // accessors
 325   bool        uses(Register reg) const { return _base == reg || _index == reg; }
 326   Register    base()             const { return _base;  }
 327   Register    index()            const { return _index; }
 328   XMMRegister xmmindex()         const { return _xmmindex; }
 329   ScaleFactor scale()            const { return _scale; }
 330   int         disp()             const { return _disp;  }
 331   bool        isxmmindex()       const { return _isxmmindex; }
 332 
 333   // Convert the raw encoding form into the form expected by the constructor for
 334   // Address.  An index of 4 (rsp) corresponds to having no index, so convert
 335   // that to noreg for the Address constructor.
 336   static Address make_raw(int base, int index, int scale, int disp, relocInfo::relocType disp_reloc);
 337 
 338   static Address make_array(ArrayAddress);
 339 
 340  private:
 341   bool base_needs_rex() const {
<span class="line-modified"> 342     return _base-&gt;is_valid() &amp;&amp; _base-&gt;encoding() &gt;= 8;</span>
 343   }
 344 
 345   bool index_needs_rex() const {
<span class="line-modified"> 346     return _index-&gt;is_valid() &amp;&amp;_index-&gt;encoding() &gt;= 8;</span>
 347   }
 348 
 349   bool xmmindex_needs_rex() const {
<span class="line-modified"> 350     return _xmmindex-&gt;is_valid() &amp;&amp; _xmmindex-&gt;encoding() &gt;= 8;</span>
 351   }
 352 
 353   relocInfo::relocType reloc() const { return _rspec.type(); }
 354 
 355   friend class Assembler;
 356   friend class MacroAssembler;
 357   friend class LIR_Assembler; // base/index/scale/disp
 358 };
 359 
 360 //
 361 // AddressLiteral has been split out from Address because operands of this type
 362 // need to be treated specially on 32bit vs. 64bit platforms. By splitting it out
 363 // the few instructions that need to deal with address literals are unique and the
 364 // MacroAssembler does not have to implement every instruction in the Assembler
 365 // in order to search for address literals that may need special handling depending
 366 // on the instruction and the platform. As small step on the way to merging i486/amd64
 367 // directories.
 368 //
 369 class AddressLiteral {
 370   friend class ArrayAddress;
</pre>
<hr />
<pre>
 642   // We could use a &quot;safe enough&quot; estimate (15), but just default to
 643   // instruction length guess from above.
 644   static unsigned int instr_maxlen() { return 4; }
 645 
 646   // NOTE: The general philopsophy of the declarations here is that 64bit versions
 647   // of instructions are freely declared without the need for wrapping them an ifdef.
 648   // (Some dangerous instructions are ifdef&#39;s out of inappropriate jvm&#39;s.)
 649   // In the .cpp file the implementations are wrapped so that they are dropped out
 650   // of the resulting jvm. This is done mostly to keep the footprint of MINIMAL
 651   // to the size it was prior to merging up the 32bit and 64bit assemblers.
 652   //
 653   // This does mean you&#39;ll get a linker/runtime error if you use a 64bit only instruction
 654   // in a 32bit vm. This is somewhat unfortunate but keeps the ifdef noise down.
 655 
 656 private:
 657 
 658   bool _legacy_mode_bw;
 659   bool _legacy_mode_dq;
 660   bool _legacy_mode_vl;
 661   bool _legacy_mode_vlbw;
<span class="line-modified"> 662   NOT_LP64(bool _is_managed;)</span>
 663 
 664   class InstructionAttr *_attributes;
 665 
 666   // 64bit prefixes
<span class="line-modified"> 667   void prefix(Register reg);</span>
<span class="line-modified"> 668   void prefix(Register dst, Register src, Prefix p);</span>
<span class="line-added"> 669   void prefix(Register dst, Address adr, Prefix p);</span>
 670 
<span class="line-added"> 671   void prefix(Address adr);</span>
<span class="line-added"> 672   void prefix(Address adr, Register reg,  bool byteinst = false);</span>
<span class="line-added"> 673   void prefix(Address adr, XMMRegister reg);</span>
<span class="line-added"> 674 </span>
<span class="line-added"> 675   int prefix_and_encode(int reg_enc, bool byteinst = false);</span>
 676   int prefix_and_encode(int dst_enc, int src_enc) {
 677     return prefix_and_encode(dst_enc, false, src_enc, false);
 678   }
 679   int prefix_and_encode(int dst_enc, bool dst_is_byte, int src_enc, bool src_is_byte);

 680 
<span class="line-modified"> 681   // Some prefixq variants always emit exactly one prefix byte, so besides a</span>
<span class="line-modified"> 682   // prefix-emitting method we provide a method to get the prefix byte to emit,</span>
<span class="line-modified"> 683   // which can then be folded into a byte stream.</span>
<span class="line-modified"> 684   int8_t get_prefixq(Address adr);</span>
<span class="line-modified"> 685   int8_t get_prefixq(Address adr, Register reg);</span>
 686 
<span class="line-modified"> 687   void prefixq(Address adr);</span>

 688   void prefixq(Address adr, Register reg);
 689   void prefixq(Address adr, XMMRegister reg);
 690 
<span class="line-modified"> 691   int prefixq_and_encode(int reg_enc);</span>
<span class="line-added"> 692   int prefixq_and_encode(int dst_enc, int src_enc);</span>
 693 
 694   void rex_prefix(Address adr, XMMRegister xreg,
 695                   VexSimdPrefix pre, VexOpcode opc, bool rex_w);
 696   int  rex_prefix_and_encode(int dst_enc, int src_enc,
 697                              VexSimdPrefix pre, VexOpcode opc, bool rex_w);
 698 
 699   void vex_prefix(bool vex_r, bool vex_b, bool vex_x, int nds_enc, VexSimdPrefix pre, VexOpcode opc);
 700 
 701   void evex_prefix(bool vex_r, bool vex_b, bool vex_x, bool evex_r, bool evex_v,
 702                    int nds_enc, VexSimdPrefix pre, VexOpcode opc);
 703 
 704   void vex_prefix(Address adr, int nds_enc, int xreg_enc,
 705                   VexSimdPrefix pre, VexOpcode opc,
 706                   InstructionAttr *attributes);
 707 
 708   int  vex_prefix_and_encode(int dst_enc, int nds_enc, int src_enc,
 709                              VexSimdPrefix pre, VexOpcode opc,
 710                              InstructionAttr *attributes);
 711 
 712   void simd_prefix(XMMRegister xreg, XMMRegister nds, Address adr, VexSimdPrefix pre,
 713                    VexOpcode opc, InstructionAttr *attributes);
 714 
 715   int simd_prefix_and_encode(XMMRegister dst, XMMRegister nds, XMMRegister src, VexSimdPrefix pre,
 716                              VexOpcode opc, InstructionAttr *attributes);
 717 
 718   // Helper functions for groups of instructions
 719   void emit_arith_b(int op1, int op2, Register dst, int imm8);
 720 
 721   void emit_arith(int op1, int op2, Register dst, int32_t imm32);
 722   // Force generation of a 4 byte immediate value even if it fits into 8bit
 723   void emit_arith_imm32(int op1, int op2, Register dst, int32_t imm32);
 724   void emit_arith(int op1, int op2, Register dst, Register src);
 725 
 726   bool emit_compressed_disp_byte(int &amp;disp);
 727 
<span class="line-added"> 728   void emit_modrm(int mod, int dst_enc, int src_enc);</span>
<span class="line-added"> 729   void emit_modrm_disp8(int mod, int dst_enc, int src_enc,</span>
<span class="line-added"> 730                         int disp);</span>
<span class="line-added"> 731   void emit_modrm_sib(int mod, int dst_enc, int src_enc,</span>
<span class="line-added"> 732                       Address::ScaleFactor scale, int index_enc, int base_enc);</span>
<span class="line-added"> 733   void emit_modrm_sib_disp8(int mod, int dst_enc, int src_enc,</span>
<span class="line-added"> 734                             Address::ScaleFactor scale, int index_enc, int base_enc,</span>
<span class="line-added"> 735                             int disp);</span>
<span class="line-added"> 736 </span>
<span class="line-added"> 737   void emit_operand_helper(int reg_enc,</span>
<span class="line-added"> 738                            int base_enc, int index_enc, Address::ScaleFactor scale,</span>
<span class="line-added"> 739                            int disp,</span>
<span class="line-added"> 740                            RelocationHolder const&amp; rspec,</span>
<span class="line-added"> 741                            int rip_relative_correction = 0);</span>
<span class="line-added"> 742 </span>
 743   void emit_operand(Register reg,
 744                     Register base, Register index, Address::ScaleFactor scale,
 745                     int disp,
 746                     RelocationHolder const&amp; rspec,
 747                     int rip_relative_correction = 0);
 748 
<span class="line-modified"> 749   void emit_operand(Register reg,</span>
<span class="line-modified"> 750                     Register base, XMMRegister index, Address::ScaleFactor scale,</span>
<span class="line-modified"> 751                     int disp,</span>
<span class="line-added"> 752                     RelocationHolder const&amp; rspec);</span>
 753 
<span class="line-modified"> 754   void emit_operand(XMMRegister xreg,</span>
<span class="line-added"> 755                     Register base, XMMRegister xindex, Address::ScaleFactor scale,</span>
<span class="line-added"> 756                     int disp,</span>
<span class="line-added"> 757                     RelocationHolder const&amp; rspec);</span>
 758 
<span class="line-modified"> 759   void emit_operand(Register reg, Address adr,</span>
<span class="line-modified"> 760                     int rip_relative_correction = 0);</span>
 761 
 762   void emit_operand(XMMRegister reg,
 763                     Register base, Register index, Address::ScaleFactor scale,
 764                     int disp,
 765                     RelocationHolder const&amp; rspec);
 766 
 767   void emit_operand(XMMRegister reg, Address adr);
 768 






 769   // Immediate-to-memory forms
 770   void emit_arith_operand(int op1, Register rm, Address adr, int32_t imm32);
 771 



 772  protected:
 773   #ifdef ASSERT
 774   void check_relocation(RelocationHolder const&amp; rspec, int format);
 775   #endif
 776 
 777   void emit_data(jint data, relocInfo::relocType    rtype, int format);
 778   void emit_data(jint data, RelocationHolder const&amp; rspec, int format);
 779   void emit_data64(jlong data, relocInfo::relocType rtype, int format = 0);
 780   void emit_data64(jlong data, RelocationHolder const&amp; rspec, int format = 0);
 781 
 782   bool reachable(AddressLiteral adr) NOT_LP64({ return true;});
 783 
 784   // These are all easily abused and hence protected
 785 
 786   // 32BIT ONLY SECTION
 787 #ifndef _LP64
 788   // Make these disappear in 64bit mode since they would never be correct
 789   void cmp_literal32(Register src1, int32_t imm32, RelocationHolder const&amp; rspec);   // 32BIT ONLY
 790   void cmp_literal32(Address src1, int32_t imm32, RelocationHolder const&amp; rspec);    // 32BIT ONLY
 791 
</pre>
<hr />
<pre>
 855   void movapd(XMMRegister dst, XMMRegister src);
 856 
 857   // End avoid using directly
 858 
 859 
 860   // Instruction prefixes
 861   void prefix(Prefix p);
 862 
 863   public:
 864 
 865   // Creation
 866   Assembler(CodeBuffer* code) : AbstractAssembler(code) {
 867     init_attributes();
 868   }
 869 
 870   // Decoding
 871   static address locate_operand(address inst, WhichOperand which);
 872   static address locate_next_instruction(address inst);
 873 
 874   // Utilities

 875   static bool query_compressed_disp_byte(int disp, bool is_evex_inst, int vector_len,
 876                                          int cur_tuple_type, int in_size_in_bits, int cur_encoding);
 877 
 878   // Generic instructions
 879   // Does 32bit or 64bit as needed for the platform. In some sense these
 880   // belong in macro assembler but there is no need for both varieties to exist
 881 
 882   void init_attributes(void) {
 883     _legacy_mode_bw = (VM_Version::supports_avx512bw() == false);
 884     _legacy_mode_dq = (VM_Version::supports_avx512dq() == false);
 885     _legacy_mode_vl = (VM_Version::supports_avx512vl() == false);
 886     _legacy_mode_vlbw = (VM_Version::supports_avx512vlbw() == false);
<span class="line-modified"> 887     NOT_LP64(_is_managed = false;)</span>
 888     _attributes = NULL;
 889   }
 890 
 891   void set_attributes(InstructionAttr *attributes) { _attributes = attributes; }
 892   void clear_attributes(void) { _attributes = NULL; }
 893 
<span class="line-modified"> 894   void set_managed(void) { NOT_LP64(_is_managed = true;) }</span>
<span class="line-modified"> 895   void clear_managed(void) { NOT_LP64(_is_managed = false;) }</span>
<span class="line-modified"> 896   bool is_managed(void) {</span>
<span class="line-added"> 897     NOT_LP64(return _is_managed;)</span>
<span class="line-added"> 898     LP64_ONLY(return false;) }</span>
 899 
 900   void lea(Register dst, Address src);
 901 
 902   void mov(Register dst, Register src);
 903 
<span class="line-added"> 904 #ifdef _LP64</span>
<span class="line-added"> 905   // support caching the result of some routines</span>
<span class="line-added"> 906 </span>
<span class="line-added"> 907   // must be called before pusha(), popa(), vzeroupper() - checked with asserts</span>
<span class="line-added"> 908   static void precompute_instructions();</span>
<span class="line-added"> 909 </span>
<span class="line-added"> 910   void pusha_uncached();</span>
<span class="line-added"> 911   void popa_uncached();</span>
<span class="line-added"> 912 #endif</span>
<span class="line-added"> 913   void vzeroupper_uncached();</span>
<span class="line-added"> 914 </span>
 915   void pusha();
 916   void popa();
 917 
 918   void pushf();
 919   void popf();
 920 
 921   void push(int32_t imm32);
 922 
 923   void push(Register src);
 924 
 925   void pop(Register dst);
 926 
 927   // These are dummies to prevent surprise implicit conversions to Register
 928   void push(void* v);
 929   void pop(void* v);
 930 
 931   // These do register sized moves/scans
 932   void rep_mov();
 933   void rep_stos();
 934   void rep_stosb();
</pre>
<hr />
<pre>
1145 
1146   void cvttpd2dq(XMMRegister dst, XMMRegister src);
1147 
1148   //Abs of packed Integer values
1149   void pabsb(XMMRegister dst, XMMRegister src);
1150   void pabsw(XMMRegister dst, XMMRegister src);
1151   void pabsd(XMMRegister dst, XMMRegister src);
1152   void vpabsb(XMMRegister dst, XMMRegister src, int vector_len);
1153   void vpabsw(XMMRegister dst, XMMRegister src, int vector_len);
1154   void vpabsd(XMMRegister dst, XMMRegister src, int vector_len);
1155   void evpabsq(XMMRegister dst, XMMRegister src, int vector_len);
1156 
1157   // Divide Scalar Double-Precision Floating-Point Values
1158   void divsd(XMMRegister dst, Address src);
1159   void divsd(XMMRegister dst, XMMRegister src);
1160 
1161   // Divide Scalar Single-Precision Floating-Point Values
1162   void divss(XMMRegister dst, Address src);
1163   void divss(XMMRegister dst, XMMRegister src);
1164 

1165 
1166 #ifndef _LP64
<span class="line-added">1167  private:</span>
<span class="line-added">1168   // operands that only take the original 32bit registers</span>
<span class="line-added">1169   void emit_operand32(Register reg, Address adr);</span>
<span class="line-added">1170 </span>
<span class="line-added">1171   void emit_farith(int b1, int b2, int i);</span>
<span class="line-added">1172 </span>
<span class="line-added">1173  public:</span>
<span class="line-added">1174   void emms();</span>
<span class="line-added">1175 </span>
1176   void fabs();
1177 
1178   void fadd(int i);
1179 
1180   void fadd_d(Address src);
1181   void fadd_s(Address src);
1182 
1183   // &quot;Alternate&quot; versions of x87 instructions place result down in FPU
1184   // stack instead of on TOS
1185 
1186   void fadda(int i); // &quot;alternate&quot; fadd
1187   void faddp(int i = 1);
1188 
1189   void fchs();
1190 
1191   void fcom(int i);
1192 
1193   void fcomp(int i = 1);
1194   void fcomp_d(Address src);
1195   void fcomp_s(Address src);
</pre>
<hr />
<pre>
1521 
1522   // Move lower 64bit to high 64bit in 128bit register
1523   void movlhps(XMMRegister dst, XMMRegister src);
1524 
1525   void movl(Register dst, int32_t imm32);
1526   void movl(Address dst, int32_t imm32);
1527   void movl(Register dst, Register src);
1528   void movl(Register dst, Address src);
1529   void movl(Address dst, Register src);
1530 
1531   // These dummies prevent using movl from converting a zero (like NULL) into Register
1532   // by giving the compiler two choices it can&#39;t resolve
1533 
1534   void movl(Address  dst, void* junk);
1535   void movl(Register dst, void* junk);
1536 
1537 #ifdef _LP64
1538   void movq(Register dst, Register src);
1539   void movq(Register dst, Address src);
1540   void movq(Address  dst, Register src);




1541 

1542   // These dummies prevent using movq from converting a zero (like NULL) into Register
1543   // by giving the compiler two choices it can&#39;t resolve
1544 
1545   void movq(Address  dst, void* dummy);
1546   void movq(Register dst, void* dummy);
1547 #endif
1548 
1549   // Move Quadword
1550   void movq(Address     dst, XMMRegister src);
1551   void movq(XMMRegister dst, Address src);
1552 
1553   void movsbl(Register dst, Address src);
1554   void movsbl(Register dst, Register src);
1555 
1556 #ifdef _LP64
1557   void movsbq(Register dst, Address src);
1558   void movsbq(Register dst, Register src);
1559 
1560   // Move signed 32bit immediate to 64bit extending sign
1561   void movslq(Address  dst, int32_t imm64);
</pre>
<hr />
<pre>
2181   void vpand(XMMRegister dst, XMMRegister nds, Address src, int vector_len);
2182   void vpandq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);
2183 
2184   // Andn packed integers
2185   void pandn(XMMRegister dst, XMMRegister src);
2186   void vpandn(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);
2187 
2188   // Or packed integers
2189   void por(XMMRegister dst, XMMRegister src);
2190   void vpor(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);
2191   void vpor(XMMRegister dst, XMMRegister nds, Address src, int vector_len);
2192   void vporq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);
2193 
2194   // Xor packed integers
2195   void pxor(XMMRegister dst, XMMRegister src);
2196   void vpxor(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);
2197   void vpxor(XMMRegister dst, XMMRegister nds, Address src, int vector_len);
2198   void evpxorq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);
2199   void evpxorq(XMMRegister dst, XMMRegister nds, Address src, int vector_len);
2200 
<span class="line-added">2201   // Ternary logic instruction.</span>
<span class="line-added">2202   void vpternlogd(XMMRegister dst, int imm8, XMMRegister src2, XMMRegister src3, int vector_len);</span>
<span class="line-added">2203   void vpternlogd(XMMRegister dst, int imm8, XMMRegister src2, Address     src3, int vector_len);</span>
2204 
2205   // vinserti forms
2206   void vinserti128(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8);
2207   void vinserti128(XMMRegister dst, XMMRegister nds, Address src, uint8_t imm8);
2208   void vinserti32x4(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8);
2209   void vinserti32x4(XMMRegister dst, XMMRegister nds, Address src, uint8_t imm8);
2210   void vinserti64x4(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8);
2211 
2212   // vinsertf forms
2213   void vinsertf128(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8);
2214   void vinsertf128(XMMRegister dst, XMMRegister nds, Address src, uint8_t imm8);
2215   void vinsertf32x4(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8);
2216   void vinsertf32x4(XMMRegister dst, XMMRegister nds, Address src, uint8_t imm8);
2217   void vinsertf64x4(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8);
2218   void vinsertf64x4(XMMRegister dst, XMMRegister nds, Address src, uint8_t imm8);
2219 
2220   // vextracti forms
2221   void vextracti128(XMMRegister dst, XMMRegister src, uint8_t imm8);
2222   void vextracti128(Address dst, XMMRegister src, uint8_t imm8);
2223   void vextracti32x4(XMMRegister dst, XMMRegister src, uint8_t imm8);
</pre>
<hr />
<pre>
2285   // They should be called only from corresponding MacroAssembler instructions.
2286   void andpd(XMMRegister dst, Address src);
2287   void andps(XMMRegister dst, Address src);
2288   void xorpd(XMMRegister dst, Address src);
2289   void xorps(XMMRegister dst, Address src);
2290 
2291 };
2292 
2293 // The Intel x86/Amd64 Assembler attributes: All fields enclosed here are to guide encoding level decisions.
2294 // Specific set functions are for specialized use, else defaults or whatever was supplied to object construction
2295 // are applied.
2296 class InstructionAttr {
2297 public:
2298   InstructionAttr(
2299     int vector_len,     // The length of vector to be applied in encoding - for both AVX and EVEX
2300     bool rex_vex_w,     // Width of data: if 32-bits or less, false, else if 64-bit or specially defined, true
2301     bool legacy_mode,   // Details if either this instruction is conditionally encoded to AVX or earlier if true else possibly EVEX
2302     bool no_reg_mask,   // when true, k0 is used when EVEX encoding is chosen, else embedded_opmask_register_specifier is used
2303     bool uses_vl)       // This instruction may have legacy constraints based on vector length for EVEX
2304     :

2305       _rex_vex_w(rex_vex_w),
<span class="line-modified">2306       _legacy_mode(legacy_mode || UseAVX &lt; 3),</span>

2307       _no_reg_mask(no_reg_mask),
2308       _uses_vl(uses_vl),
<span class="line-modified">2309       _rex_vex_w_reverted(false),</span>

2310       _is_evex_instruction(false),

2311       _is_clear_context(true),
2312       _is_extended_context(false),
<span class="line-added">2313       _avx_vector_len(vector_len),</span>
<span class="line-added">2314       _tuple_type(Assembler::EVEX_ETUP),</span>
<span class="line-added">2315       _input_size_in_bits(Assembler::EVEX_NObit),</span>
<span class="line-added">2316       _evex_encoding(0),</span>
2317       _embedded_opmask_register_specifier(0), // hard code k0
<span class="line-modified">2318       _current_assembler(NULL) { }</span>


2319 
2320   ~InstructionAttr() {
2321     if (_current_assembler != NULL) {
2322       _current_assembler-&gt;clear_attributes();
2323     }
2324     _current_assembler = NULL;
2325   }
2326 
2327 private:

2328   bool _rex_vex_w;

2329   bool _legacy_mode;
2330   bool _no_reg_mask;
2331   bool _uses_vl;
<span class="line-modified">2332   bool _rex_vex_w_reverted;</span>

2333   bool _is_evex_instruction;

2334   bool _is_clear_context;
2335   bool _is_extended_context;
<span class="line-added">2336   int  _avx_vector_len;</span>
<span class="line-added">2337   int  _tuple_type;</span>
<span class="line-added">2338   int  _input_size_in_bits;</span>
<span class="line-added">2339   int  _evex_encoding;</span>
2340   int _embedded_opmask_register_specifier;
2341 
2342   Assembler *_current_assembler;
2343 
2344 public:
2345   // query functions for field accessors

2346   bool is_rex_vex_w(void) const { return _rex_vex_w; }

2347   bool is_legacy_mode(void) const { return _legacy_mode; }
2348   bool is_no_reg_mask(void) const { return _no_reg_mask; }
2349   bool uses_vl(void) const { return _uses_vl; }
<span class="line-added">2350   bool is_rex_vex_w_reverted(void) { return _rex_vex_w_reverted; }</span>
<span class="line-added">2351   bool is_evex_instruction(void) const { return _is_evex_instruction; }</span>
<span class="line-added">2352   bool is_clear_context(void) const { return _is_clear_context; }</span>
<span class="line-added">2353   bool is_extended_context(void) const { return _is_extended_context; }</span>
<span class="line-added">2354   int  get_vector_len(void) const { return _avx_vector_len; }</span>
2355   int  get_tuple_type(void) const { return _tuple_type; }
2356   int  get_input_size(void) const { return _input_size_in_bits; }

2357   int  get_evex_encoding(void) const { return _evex_encoding; }
<span class="line-modified">2358   int  get_embedded_opmask_register_specifier(void) const { return _embedded_opmask_register_specifier; }</span>


2359 
2360   // Set the vector len manually
2361   void set_vector_len(int vector_len) { _avx_vector_len = vector_len; }
2362 
2363   // Set revert rex_vex_w for avx encoding
2364   void set_rex_vex_w_reverted(void) { _rex_vex_w_reverted = true; }
2365 
2366   // Set rex_vex_w based on state
2367   void set_rex_vex_w(bool state) { _rex_vex_w = state; }
2368 
2369   // Set the instruction to be encoded in AVX mode
2370   void set_is_legacy_mode(void) { _legacy_mode = true; }
2371 
2372   // Set the current instuction to be encoded as an EVEX instuction
2373   void set_is_evex_instruction(void) { _is_evex_instruction = true; }
2374 
2375   // Internal encoding data used in compressed immediate offset programming
2376   void set_evex_encoding(int value) { _evex_encoding = value; }
2377 
2378   // Set the Evex.Z field to be used to clear all non directed XMM/YMM/ZMM components
</pre>
</td>
</tr>
</table>
<center><a href="assembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRAssembler_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>