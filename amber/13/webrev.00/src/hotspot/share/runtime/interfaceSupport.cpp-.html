<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/runtime/interfaceSupport.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;gc/shared/collectedHeap.hpp&quot;
 27 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
 28 #include &quot;logging/log.hpp&quot;
 29 #include &quot;memory/resourceArea.hpp&quot;
 30 #include &quot;memory/universe.hpp&quot;
 31 #include &quot;runtime/atomic.hpp&quot;
 32 #include &quot;runtime/frame.inline.hpp&quot;
 33 #include &quot;runtime/handles.inline.hpp&quot;
 34 #include &quot;runtime/init.hpp&quot;
 35 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
 36 #include &quot;runtime/os.inline.hpp&quot;
 37 #include &quot;runtime/thread.inline.hpp&quot;
 38 #include &quot;runtime/safepointVerifiers.hpp&quot;
 39 #include &quot;runtime/vframe.hpp&quot;
 40 #include &quot;runtime/vmThread.hpp&quot;
 41 #include &quot;utilities/preserveException.hpp&quot;
 42 
 43 // Implementation of InterfaceSupport
 44 
 45 #ifdef ASSERT
 46 VMEntryWrapper::VMEntryWrapper() {
 47   if (VerifyLastFrame) {
 48     InterfaceSupport::verify_last_frame();
 49   }
 50 }
 51 
 52 VMEntryWrapper::~VMEntryWrapper() {
 53   InterfaceSupport::check_gc_alot();
 54   if (WalkStackALot) {
 55     InterfaceSupport::walk_stack();
 56   }
 57   if (DeoptimizeALot || DeoptimizeRandom) {
 58     InterfaceSupport::deoptimizeAll();
 59   }
 60   if (ZombieALot) {
 61     InterfaceSupport::zombieAll();
 62   }
 63   // do verification AFTER potential deoptimization
 64   if (VerifyStack) {
 65     InterfaceSupport::verify_stack();
 66   }
 67 }
 68 
 69 VMNativeEntryWrapper::VMNativeEntryWrapper() {
 70   if (GCALotAtAllSafepoints) InterfaceSupport::check_gc_alot();
 71 }
 72 
 73 VMNativeEntryWrapper::~VMNativeEntryWrapper() {
 74   if (GCALotAtAllSafepoints) InterfaceSupport::check_gc_alot();
 75 }
 76 
 77 long InterfaceSupport::_number_of_calls       = 0;
 78 long InterfaceSupport::_scavenge_alot_counter = 1;
 79 long InterfaceSupport::_fullgc_alot_counter   = 1;
 80 long InterfaceSupport::_fullgc_alot_invocation = 0;
 81 
 82 Histogram* RuntimeHistogram;
 83 
 84 RuntimeHistogramElement::RuntimeHistogramElement(const char* elementName) {
 85   static volatile int RuntimeHistogram_lock = 0;
 86   _name = elementName;
 87   uintx count = 0;
 88 
 89   while (Atomic::cmpxchg(&amp;RuntimeHistogram_lock, 0, 1) != 0) {
 90     while (Atomic::load_acquire(&amp;RuntimeHistogram_lock) != 0) {
 91       count +=1;
 92       if ( (WarnOnStalledSpinLock &gt; 0)
 93         &amp;&amp; (count % WarnOnStalledSpinLock == 0)) {
 94         warning(&quot;RuntimeHistogram_lock seems to be stalled&quot;);
 95       }
 96     }
 97   }
 98 
 99   if (RuntimeHistogram == NULL) {
100     RuntimeHistogram = new Histogram(&quot;VM Runtime Call Counts&quot;,200);
101   }
102 
103   RuntimeHistogram-&gt;add_element(this);
104   Atomic::dec(&amp;RuntimeHistogram_lock);
105 }
106 
107 void InterfaceSupport::gc_alot() {
108   Thread *thread = Thread::current();
109   if (!thread-&gt;is_Java_thread()) return; // Avoid concurrent calls
110   // Check for new, not quite initialized thread. A thread in new mode cannot initiate a GC.
111   JavaThread *current_thread = (JavaThread *)thread;
112   if (current_thread-&gt;active_handles() == NULL) return;
113 
114   // Short-circuit any possible re-entrant gc-a-lot attempt
115   if (thread-&gt;skip_gcalot()) return;
116 
117   if (Threads::is_vm_complete()) {
118 
119     if (++_fullgc_alot_invocation &lt; FullGCALotStart) {
120       return;
121     }
122 
123     // Use this line if you want to block at a specific point,
124     // e.g. one number_of_calls/scavenge/gc before you got into problems
125     if (FullGCALot) _fullgc_alot_counter--;
126 
127     // Check if we should force a full gc
128     if (_fullgc_alot_counter == 0) {
129       // Release dummy so objects are forced to move
130       if (!Universe::release_fullgc_alot_dummy()) {
131         warning(&quot;FullGCALot: Unable to release more dummies at bottom of heap&quot;);
132       }
133       HandleMark hm(thread);
134       Universe::heap()-&gt;collect(GCCause::_full_gc_alot);
135       unsigned int invocations = Universe::heap()-&gt;total_full_collections();
136       // Compute new interval
137       if (FullGCALotInterval &gt; 1) {
138         _fullgc_alot_counter = 1+(long)((double)FullGCALotInterval*os::random()/(max_jint+1.0));
139         log_trace(gc)(&quot;Full gc no: %u\tInterval: %ld&quot;, invocations, _fullgc_alot_counter);
140       } else {
141         _fullgc_alot_counter = 1;
142       }
143       // Print progress message
144       if (invocations % 100 == 0) {
145         log_trace(gc)(&quot;Full gc no: %u&quot;, invocations);
146       }
147     } else {
148       if (ScavengeALot) _scavenge_alot_counter--;
149       // Check if we should force a scavenge
150       if (_scavenge_alot_counter == 0) {
151         HandleMark hm(thread);
152         Universe::heap()-&gt;collect(GCCause::_scavenge_alot);
153         unsigned int invocations = Universe::heap()-&gt;total_collections() - Universe::heap()-&gt;total_full_collections();
154         // Compute new interval
155         if (ScavengeALotInterval &gt; 1) {
156           _scavenge_alot_counter = 1+(long)((double)ScavengeALotInterval*os::random()/(max_jint+1.0));
157           log_trace(gc)(&quot;Scavenge no: %u\tInterval: %ld&quot;, invocations, _scavenge_alot_counter);
158         } else {
159           _scavenge_alot_counter = 1;
160         }
161         // Print progress message
162         if (invocations % 1000 == 0) {
163           log_trace(gc)(&quot;Scavenge no: %u&quot;, invocations);
164         }
165       }
166     }
167   }
168 }
169 
170 
171 vframe* vframe_array[50];
172 int walk_stack_counter = 0;
173 
174 void InterfaceSupport::walk_stack_from(vframe* start_vf) {
175   // walk
176   int i = 0;
177   for (vframe* f = start_vf; f; f = f-&gt;sender() ) {
178     if (i &lt; 50) vframe_array[i++] = f;
179   }
180 }
181 
182 
183 void InterfaceSupport::walk_stack() {
184   JavaThread* thread = JavaThread::current();
185   walk_stack_counter++;
186   if (!thread-&gt;has_last_Java_frame()) return;
187   ResourceMark rm(thread);
188   RegisterMap reg_map(thread);
189   walk_stack_from(thread-&gt;last_java_vframe(&amp;reg_map));
190 }
191 
192 // invocation counter for InterfaceSupport::deoptimizeAll/zombieAll functions
193 int deoptimizeAllCounter = 0;
194 int zombieAllCounter = 0;
195 
196 void InterfaceSupport::zombieAll() {
197   // This method is called by all threads when a thread make
198   // transition to VM state (for example, runtime calls).
199   // Divide number of calls by number of threads to avoid
200   // dependence of ZombieAll events frequency on number of threads.
201   int value = zombieAllCounter / Threads::number_of_threads();
202   if (is_init_completed() &amp;&amp; value &gt; ZombieALotInterval) {
203     zombieAllCounter = 0;
204     VM_ZombieAll op;
205     VMThread::execute(&amp;op);
206   }
207   zombieAllCounter++;
208 }
209 
210 void InterfaceSupport::deoptimizeAll() {
211   // This method is called by all threads when a thread make
212   // transition to VM state (for example, runtime calls).
213   // Divide number of calls by number of threads to avoid
214   // dependence of DeoptimizeAll events frequency on number of threads.
215   int value = deoptimizeAllCounter / Threads::number_of_threads();
216   if (is_init_completed()) {
217     if (DeoptimizeALot &amp;&amp; value &gt; DeoptimizeALotInterval) {
218       deoptimizeAllCounter = 0;
219       VM_DeoptimizeAll op;
220       VMThread::execute(&amp;op);
221     } else if (DeoptimizeRandom &amp;&amp; (value &amp; 0x1F) == (os::random() &amp; 0x1F)) {
222       VM_DeoptimizeAll op;
223       VMThread::execute(&amp;op);
224     }
225   }
226   deoptimizeAllCounter++;
227 }
228 
229 
230 void InterfaceSupport::verify_stack() {
231   JavaThread* thread = JavaThread::current();
232   ResourceMark rm(thread);
233   // disabled because it throws warnings that oop maps should only be accessed
234   // in VM thread or during debugging
235 
236   if (!thread-&gt;has_pending_exception()) {
237     // verification does not work if there are pending exceptions
238     StackFrameStream sfs(thread);
239     CodeBlob* cb = sfs.current()-&gt;cb();
240       // In case of exceptions we might not have a runtime_stub on
241       // top of stack, hence, all callee-saved registers are not going
242       // to be setup correctly, hence, we cannot do stack verify
243     if (cb != NULL &amp;&amp; !(cb-&gt;is_runtime_stub() || cb-&gt;is_uncommon_trap_stub())) return;
244 
245     for (; !sfs.is_done(); sfs.next()) {
246       sfs.current()-&gt;verify(sfs.register_map());
247     }
248   }
249 }
250 
251 
252 void InterfaceSupport::verify_last_frame() {
253   JavaThread* thread = JavaThread::current();
254   ResourceMark rm(thread);
255   RegisterMap reg_map(thread);
256   frame fr = thread-&gt;last_frame();
257   fr.verify(&amp;reg_map);
258 }
259 
260 
261 #endif // ASSERT
262 
263 
264 void InterfaceSupport_init() {
265 #ifdef ASSERT
266   if (ScavengeALot || FullGCALot) {
267     srand(ScavengeALotInterval * FullGCALotInterval);
268   }
269 #endif
270 }
    </pre>
  </body>
</html>