<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/matcher.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="matcher.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="memnode.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/matcher.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
104   const int *_rightOp;
105 
106   // Map dense opcode number to info on when rule is swallowed constant.
107   const bool *_swallowed;
108 
109   // Map dense rule number to determine if this is an instruction chain rule
110   const uint _begin_inst_chain_rule;
111   const uint _end_inst_chain_rule;
112 
113   // We want to clone constants and possible CmpI-variants.
114   // If we do not clone CmpI, then we can have many instances of
115   // condition codes alive at once.  This is OK on some chips and
116   // bad on others.  Hence the machine-dependent table lookup.
117   const char *_must_clone;
118 
119   // Find shared Nodes, or Nodes that otherwise are Matcher roots
120   void find_shared( Node *n );
121   bool find_shared_visit(MStack&amp; mstack, Node* n, uint opcode, bool&amp; mem_op, int&amp; mem_addr_idx);
122   void find_shared_post_visit(Node* n, uint opcode);
123 
<span class="line-removed">124 #ifdef X86</span>
<span class="line-removed">125   bool is_bmi_pattern(Node *n, Node *m);</span>
<span class="line-removed">126 #endif</span>
<span class="line-removed">127 </span>
128   bool is_vshift_con_pattern(Node *n, Node *m);
129 
130   // Debug and profile information for nodes in old space:
131   GrowableArray&lt;Node_Notes*&gt;* _old_node_note_array;
132 
133   // Node labeling iterator for instruction selection
<span class="line-modified">134   Node *Label_Root( const Node *n, State *svec, Node *control, const Node *mem );</span>
135 
136   Node *transform( Node *dummy );
137 
138   Node_List _projection_list;        // For Machine nodes killing many values
139 
140   Node_Array _shared_nodes;
141 
142   debug_only(Node_Array _old2new_map;)   // Map roots of ideal-trees to machine-roots
143   debug_only(Node_Array _new2old_map;)   // Maps machine nodes back to ideal
144 
145   // Accessors for the inherited field PhaseTransform::_nodes:
146   void   grow_new_node_array(uint idx_limit) {
147     _nodes.map(idx_limit-1, NULL);
148   }
149   bool    has_new_node(const Node* n) const {
150     return _nodes.at(n-&gt;_idx) != NULL;
151   }
152   Node*       new_node(const Node* n) const {
153     assert(has_new_node(n), &quot;set before get&quot;);
154     return _nodes.at(n-&gt;_idx);
</pre>
<hr />
<pre>
435   // and so is probably the stack pointer for most machines.  On Intel
436   // it is ESP.  On the PowerPC it is R1.  On Sparc it is SP.
437   OptoReg::Name  c_frame_pointer() const;
438   static RegMask c_frame_ptr_mask;
439 
440   // !!!!! Special stuff for building ScopeDescs
441   virtual int      regnum_to_fpu_offset(int regnum);
442 
443   // Is this branch offset small enough to be addressed by a short branch?
444   bool is_short_branch_offset(int rule, int br_size, int offset);
445 
446   // Optional scaling for the parameter to the ClearArray/CopyArray node.
447   static const bool init_array_count_is_in_bytes;
448 
449   // Some hardware needs 2 CMOV&#39;s for longs.
450   static const int long_cmove_cost();
451 
452   // Some hardware have expensive CMOV for float and double.
453   static const int float_cmove_cost();
454 





455   // Should the Matcher clone shifts on addressing modes, expecting them to
456   // be subsumed into complex addressing expressions or compute them into
457   // registers?  True for Intel but false for most RISCs
<span class="line-modified">458   bool clone_address_expressions(AddPNode* m, MStack&amp; mstack, VectorSet&amp; address_visited);</span>
459   // Clone base + offset address expression
460   bool clone_base_plus_offset_address(AddPNode* m, MStack&amp; mstack, VectorSet&amp; address_visited);
461 
462   static bool narrow_oop_use_complex_address();
463   static bool narrow_klass_use_complex_address();
464 
465   static bool const_oop_prefer_decode();
466   static bool const_klass_prefer_decode();
467 
468   // Generate implicit null check for narrow oops if it can fold
469   // into address expression (x64).
470   //
471   // [R12 + narrow_oop_reg&lt;&lt;3 + offset] // fold into address expression
472   // NullCheck narrow_oop_reg
473   //
474   // When narrow oops can&#39;t fold into address expression (Sparc) and
475   // base is not null use decode_not_null and normal implicit null check.
476   // Note, decode_not_null node can be used here since it is referenced
477   // only on non null path but it requires special handling, see
478   // collect_null_checks():
</pre>
</td>
<td>
<hr />
<pre>
104   const int *_rightOp;
105 
106   // Map dense opcode number to info on when rule is swallowed constant.
107   const bool *_swallowed;
108 
109   // Map dense rule number to determine if this is an instruction chain rule
110   const uint _begin_inst_chain_rule;
111   const uint _end_inst_chain_rule;
112 
113   // We want to clone constants and possible CmpI-variants.
114   // If we do not clone CmpI, then we can have many instances of
115   // condition codes alive at once.  This is OK on some chips and
116   // bad on others.  Hence the machine-dependent table lookup.
117   const char *_must_clone;
118 
119   // Find shared Nodes, or Nodes that otherwise are Matcher roots
120   void find_shared( Node *n );
121   bool find_shared_visit(MStack&amp; mstack, Node* n, uint opcode, bool&amp; mem_op, int&amp; mem_addr_idx);
122   void find_shared_post_visit(Node* n, uint opcode);
123 




124   bool is_vshift_con_pattern(Node *n, Node *m);
125 
126   // Debug and profile information for nodes in old space:
127   GrowableArray&lt;Node_Notes*&gt;* _old_node_note_array;
128 
129   // Node labeling iterator for instruction selection
<span class="line-modified">130   Node* Label_Root(const Node* n, State* svec, Node* control, Node*&amp; mem);</span>
131 
132   Node *transform( Node *dummy );
133 
134   Node_List _projection_list;        // For Machine nodes killing many values
135 
136   Node_Array _shared_nodes;
137 
138   debug_only(Node_Array _old2new_map;)   // Map roots of ideal-trees to machine-roots
139   debug_only(Node_Array _new2old_map;)   // Maps machine nodes back to ideal
140 
141   // Accessors for the inherited field PhaseTransform::_nodes:
142   void   grow_new_node_array(uint idx_limit) {
143     _nodes.map(idx_limit-1, NULL);
144   }
145   bool    has_new_node(const Node* n) const {
146     return _nodes.at(n-&gt;_idx) != NULL;
147   }
148   Node*       new_node(const Node* n) const {
149     assert(has_new_node(n), &quot;set before get&quot;);
150     return _nodes.at(n-&gt;_idx);
</pre>
<hr />
<pre>
431   // and so is probably the stack pointer for most machines.  On Intel
432   // it is ESP.  On the PowerPC it is R1.  On Sparc it is SP.
433   OptoReg::Name  c_frame_pointer() const;
434   static RegMask c_frame_ptr_mask;
435 
436   // !!!!! Special stuff for building ScopeDescs
437   virtual int      regnum_to_fpu_offset(int regnum);
438 
439   // Is this branch offset small enough to be addressed by a short branch?
440   bool is_short_branch_offset(int rule, int br_size, int offset);
441 
442   // Optional scaling for the parameter to the ClearArray/CopyArray node.
443   static const bool init_array_count_is_in_bytes;
444 
445   // Some hardware needs 2 CMOV&#39;s for longs.
446   static const int long_cmove_cost();
447 
448   // Some hardware have expensive CMOV for float and double.
449   static const int float_cmove_cost();
450 
<span class="line-added">451   // Should the input &#39;m&#39; of node &#39;n&#39; be cloned during matching?</span>
<span class="line-added">452   // Reports back whether the node was cloned or not.</span>
<span class="line-added">453   bool    clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack);</span>
<span class="line-added">454   bool pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack);</span>
<span class="line-added">455 </span>
456   // Should the Matcher clone shifts on addressing modes, expecting them to
457   // be subsumed into complex addressing expressions or compute them into
458   // registers?  True for Intel but false for most RISCs
<span class="line-modified">459   bool pd_clone_address_expressions(AddPNode* m, MStack&amp; mstack, VectorSet&amp; address_visited);</span>
460   // Clone base + offset address expression
461   bool clone_base_plus_offset_address(AddPNode* m, MStack&amp; mstack, VectorSet&amp; address_visited);
462 
463   static bool narrow_oop_use_complex_address();
464   static bool narrow_klass_use_complex_address();
465 
466   static bool const_oop_prefer_decode();
467   static bool const_klass_prefer_decode();
468 
469   // Generate implicit null check for narrow oops if it can fold
470   // into address expression (x64).
471   //
472   // [R12 + narrow_oop_reg&lt;&lt;3 + offset] // fold into address expression
473   // NullCheck narrow_oop_reg
474   //
475   // When narrow oops can&#39;t fold into address expression (Sparc) and
476   // base is not null use decode_not_null and normal implicit null check.
477   // Note, decode_not_null node can be used here since it is referenced
478   // only on non null path but it requires special handling, see
479   // collect_null_checks():
</pre>
</td>
</tr>
</table>
<center><a href="matcher.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="memnode.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>