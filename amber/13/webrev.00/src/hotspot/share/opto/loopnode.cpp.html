<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/opto/loopnode.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;ci/ciMethodData.hpp&quot;
  27 #include &quot;compiler/compileLog.hpp&quot;
  28 #include &quot;gc/shared/barrierSet.hpp&quot;
  29 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
  30 #include &quot;libadt/vectset.hpp&quot;
  31 #include &quot;memory/allocation.inline.hpp&quot;
  32 #include &quot;memory/resourceArea.hpp&quot;
  33 #include &quot;opto/addnode.hpp&quot;
  34 #include &quot;opto/arraycopynode.hpp&quot;
  35 #include &quot;opto/callnode.hpp&quot;
  36 #include &quot;opto/connode.hpp&quot;
  37 #include &quot;opto/convertnode.hpp&quot;
  38 #include &quot;opto/divnode.hpp&quot;
  39 #include &quot;opto/idealGraphPrinter.hpp&quot;
  40 #include &quot;opto/loopnode.hpp&quot;
  41 #include &quot;opto/movenode.hpp&quot;
  42 #include &quot;opto/mulnode.hpp&quot;
  43 #include &quot;opto/rootnode.hpp&quot;
  44 #include &quot;opto/superword.hpp&quot;
  45 #include &quot;utilities/powerOfTwo.hpp&quot;
  46 
  47 //=============================================================================
  48 //--------------------------is_cloop_ind_var-----------------------------------
  49 // Determine if a node is a counted loop induction variable.
  50 // NOTE: The method is declared in &quot;node.hpp&quot;.
  51 bool Node::is_cloop_ind_var() const {
  52   return (is_Phi() &amp;&amp; !as_Phi()-&gt;is_copy() &amp;&amp;
  53           as_Phi()-&gt;region()-&gt;is_CountedLoop() &amp;&amp;
  54           as_Phi()-&gt;region()-&gt;as_CountedLoop()-&gt;phi() == this);
  55 }
  56 
  57 //=============================================================================
  58 //------------------------------dump_spec--------------------------------------
  59 // Dump special per-node info
  60 #ifndef PRODUCT
  61 void LoopNode::dump_spec(outputStream *st) const {
  62   if (is_inner_loop()) st-&gt;print( &quot;inner &quot; );
  63   if (is_partial_peel_loop()) st-&gt;print( &quot;partial_peel &quot; );
  64   if (partial_peel_has_failed()) st-&gt;print( &quot;partial_peel_failed &quot; );
  65 }
  66 #endif
  67 
  68 //------------------------------is_valid_counted_loop-------------------------
  69 bool LoopNode::is_valid_counted_loop() const {
  70   if (is_CountedLoop()) {
  71     CountedLoopNode*    l  = as_CountedLoop();
  72     CountedLoopEndNode* le = l-&gt;loopexit_or_null();
  73     if (le != NULL &amp;&amp;
  74         le-&gt;proj_out_or_null(1 /* true */) == l-&gt;in(LoopNode::LoopBackControl)) {
  75       Node* phi  = l-&gt;phi();
  76       Node* exit = le-&gt;proj_out_or_null(0 /* false */);
  77       if (exit != NULL &amp;&amp; exit-&gt;Opcode() == Op_IfFalse &amp;&amp;
  78           phi != NULL &amp;&amp; phi-&gt;is_Phi() &amp;&amp;
  79           phi-&gt;in(LoopNode::LoopBackControl) == l-&gt;incr() &amp;&amp;
  80           le-&gt;loopnode() == l &amp;&amp; le-&gt;stride_is_con()) {
  81         return true;
  82       }
  83     }
  84   }
  85   return false;
  86 }
  87 
  88 //------------------------------get_early_ctrl---------------------------------
  89 // Compute earliest legal control
  90 Node *PhaseIdealLoop::get_early_ctrl( Node *n ) {
  91   assert( !n-&gt;is_Phi() &amp;&amp; !n-&gt;is_CFG(), &quot;this code only handles data nodes&quot; );
  92   uint i;
  93   Node *early;
  94   if (n-&gt;in(0) &amp;&amp; !n-&gt;is_expensive()) {
  95     early = n-&gt;in(0);
  96     if (!early-&gt;is_CFG()) // Might be a non-CFG multi-def
  97       early = get_ctrl(early);        // So treat input as a straight data input
  98     i = 1;
  99   } else {
 100     early = get_ctrl(n-&gt;in(1));
 101     i = 2;
 102   }
 103   uint e_d = dom_depth(early);
 104   assert( early, &quot;&quot; );
 105   for (; i &lt; n-&gt;req(); i++) {
 106     Node *cin = get_ctrl(n-&gt;in(i));
 107     assert( cin, &quot;&quot; );
 108     // Keep deepest dominator depth
 109     uint c_d = dom_depth(cin);
 110     if (c_d &gt; e_d) {           // Deeper guy?
 111       early = cin;              // Keep deepest found so far
 112       e_d = c_d;
 113     } else if (c_d == e_d &amp;&amp;    // Same depth?
 114                early != cin) { // If not equal, must use slower algorithm
 115       // If same depth but not equal, one _must_ dominate the other
 116       // and we want the deeper (i.e., dominated) guy.
 117       Node *n1 = early;
 118       Node *n2 = cin;
 119       while (1) {
 120         n1 = idom(n1);          // Walk up until break cycle
 121         n2 = idom(n2);
 122         if (n1 == cin ||        // Walked early up to cin
 123             dom_depth(n2) &lt; c_d)
 124           break;                // early is deeper; keep him
 125         if (n2 == early ||      // Walked cin up to early
 126             dom_depth(n1) &lt; c_d) {
 127           early = cin;          // cin is deeper; keep him
 128           break;
 129         }
 130       }
 131       e_d = dom_depth(early);   // Reset depth register cache
 132     }
 133   }
 134 
 135   // Return earliest legal location
 136   assert(early == find_non_split_ctrl(early), &quot;unexpected early control&quot;);
 137 
 138   if (n-&gt;is_expensive() &amp;&amp; !_verify_only &amp;&amp; !_verify_me) {
 139     assert(n-&gt;in(0), &quot;should have control input&quot;);
 140     early = get_early_ctrl_for_expensive(n, early);
 141   }
 142 
 143   return early;
 144 }
 145 
 146 //------------------------------get_early_ctrl_for_expensive---------------------------------
 147 // Move node up the dominator tree as high as legal while still beneficial
 148 Node *PhaseIdealLoop::get_early_ctrl_for_expensive(Node *n, Node* earliest) {
 149   assert(n-&gt;in(0) &amp;&amp; n-&gt;is_expensive(), &quot;expensive node with control input here&quot;);
 150   assert(OptimizeExpensiveOps, &quot;optimization off?&quot;);
 151 
 152   Node* ctl = n-&gt;in(0);
 153   assert(ctl-&gt;is_CFG(), &quot;expensive input 0 must be cfg&quot;);
 154   uint min_dom_depth = dom_depth(earliest);
 155 #ifdef ASSERT
 156   if (!is_dominator(ctl, earliest) &amp;&amp; !is_dominator(earliest, ctl)) {
 157     dump_bad_graph(&quot;Bad graph detected in get_early_ctrl_for_expensive&quot;, n, earliest, ctl);
 158     assert(false, &quot;Bad graph detected in get_early_ctrl_for_expensive&quot;);
 159   }
 160 #endif
 161   if (dom_depth(ctl) &lt; min_dom_depth) {
 162     return earliest;
 163   }
 164 
 165   while (1) {
 166     Node *next = ctl;
 167     // Moving the node out of a loop on the projection of a If
 168     // confuses loop predication. So once we hit a Loop in a If branch
 169     // that doesn&#39;t branch to an UNC, we stop. The code that process
 170     // expensive nodes will notice the loop and skip over it to try to
 171     // move the node further up.
 172     if (ctl-&gt;is_CountedLoop() &amp;&amp; ctl-&gt;in(1) != NULL &amp;&amp; ctl-&gt;in(1)-&gt;in(0) != NULL &amp;&amp; ctl-&gt;in(1)-&gt;in(0)-&gt;is_If()) {
 173       if (!ctl-&gt;in(1)-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none)) {
 174         break;
 175       }
 176       next = idom(ctl-&gt;in(1)-&gt;in(0));
 177     } else if (ctl-&gt;is_Proj()) {
 178       // We only move it up along a projection if the projection is
 179       // the single control projection for its parent: same code path,
 180       // if it&#39;s a If with UNC or fallthrough of a call.
 181       Node* parent_ctl = ctl-&gt;in(0);
 182       if (parent_ctl == NULL) {
 183         break;
 184       } else if (parent_ctl-&gt;is_CountedLoopEnd() &amp;&amp; parent_ctl-&gt;as_CountedLoopEnd()-&gt;loopnode() != NULL) {
 185         next = parent_ctl-&gt;as_CountedLoopEnd()-&gt;loopnode()-&gt;init_control();
 186       } else if (parent_ctl-&gt;is_If()) {
 187         if (!ctl-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none)) {
 188           break;
 189         }
 190         assert(idom(ctl) == parent_ctl, &quot;strange&quot;);
 191         next = idom(parent_ctl);
 192       } else if (ctl-&gt;is_CatchProj()) {
 193         if (ctl-&gt;as_Proj()-&gt;_con != CatchProjNode::fall_through_index) {
 194           break;
 195         }
 196         assert(parent_ctl-&gt;in(0)-&gt;in(0)-&gt;is_Call(), &quot;strange graph&quot;);
 197         next = parent_ctl-&gt;in(0)-&gt;in(0)-&gt;in(0);
 198       } else {
 199         // Check if parent control has a single projection (this
 200         // control is the only possible successor of the parent
 201         // control). If so, we can try to move the node above the
 202         // parent control.
 203         int nb_ctl_proj = 0;
 204         for (DUIterator_Fast imax, i = parent_ctl-&gt;fast_outs(imax); i &lt; imax; i++) {
 205           Node *p = parent_ctl-&gt;fast_out(i);
 206           if (p-&gt;is_Proj() &amp;&amp; p-&gt;is_CFG()) {
 207             nb_ctl_proj++;
 208             if (nb_ctl_proj &gt; 1) {
 209               break;
 210             }
 211           }
 212         }
 213 
 214         if (nb_ctl_proj &gt; 1) {
 215           break;
 216         }
 217         assert(parent_ctl-&gt;is_Start() || parent_ctl-&gt;is_MemBar() || parent_ctl-&gt;is_Call() ||
 218                BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;is_gc_barrier_node(parent_ctl), &quot;unexpected node&quot;);
 219         assert(idom(ctl) == parent_ctl, &quot;strange&quot;);
 220         next = idom(parent_ctl);
 221       }
 222     } else {
 223       next = idom(ctl);
 224     }
 225     if (next-&gt;is_Root() || next-&gt;is_Start() || dom_depth(next) &lt; min_dom_depth) {
 226       break;
 227     }
 228     ctl = next;
 229   }
 230 
 231   if (ctl != n-&gt;in(0)) {
 232     _igvn.replace_input_of(n, 0, ctl);
 233     _igvn.hash_insert(n);
 234   }
 235 
 236   return ctl;
 237 }
 238 
 239 
 240 //------------------------------set_early_ctrl---------------------------------
 241 // Set earliest legal control
 242 void PhaseIdealLoop::set_early_ctrl( Node *n ) {
 243   Node *early = get_early_ctrl(n);
 244 
 245   // Record earliest legal location
 246   set_ctrl(n, early);
 247 }
 248 
 249 //------------------------------set_subtree_ctrl-------------------------------
 250 // set missing _ctrl entries on new nodes
 251 void PhaseIdealLoop::set_subtree_ctrl( Node *n ) {
 252   // Already set?  Get out.
 253   if( _nodes[n-&gt;_idx] ) return;
 254   // Recursively set _nodes array to indicate where the Node goes
 255   uint i;
 256   for( i = 0; i &lt; n-&gt;req(); ++i ) {
 257     Node *m = n-&gt;in(i);
 258     if( m &amp;&amp; m != C-&gt;root() )
 259       set_subtree_ctrl( m );
 260   }
 261 
 262   // Fixup self
 263   set_early_ctrl( n );
 264 }
 265 
 266 // Create a skeleton strip mined outer loop: a Loop head before the
 267 // inner strip mined loop, a safepoint and an exit condition guarded
 268 // by an opaque node after the inner strip mined loop with a backedge
 269 // to the loop head. The inner strip mined loop is left as it is. Only
 270 // once loop optimizations are over, do we adjust the inner loop exit
 271 // condition to limit its number of iterations, set the outer loop
 272 // exit condition and add Phis to the outer loop head. Some loop
 273 // optimizations that operate on the inner strip mined loop need to be
 274 // aware of the outer strip mined loop: loop unswitching needs to
 275 // clone the outer loop as well as the inner, unrolling needs to only
 276 // clone the inner loop etc. No optimizations need to change the outer
 277 // strip mined loop as it is only a skeleton.
 278 IdealLoopTree* PhaseIdealLoop::create_outer_strip_mined_loop(BoolNode *test, Node *cmp, Node *init_control,
 279                                                              IdealLoopTree* loop, float cl_prob, float le_fcnt,
 280                                                              Node*&amp; entry_control, Node*&amp; iffalse) {
 281   Node* outer_test = _igvn.intcon(0);
 282   set_ctrl(outer_test, C-&gt;root());
 283   Node *orig = iffalse;
 284   iffalse = iffalse-&gt;clone();
 285   _igvn.register_new_node_with_optimizer(iffalse);
 286   set_idom(iffalse, idom(orig), dom_depth(orig));
 287 
 288   IfNode *outer_le = new OuterStripMinedLoopEndNode(iffalse, outer_test, cl_prob, le_fcnt);
 289   Node *outer_ift = new IfTrueNode (outer_le);
 290   Node* outer_iff = orig;
 291   _igvn.replace_input_of(outer_iff, 0, outer_le);
 292 
 293   LoopNode *outer_l = new OuterStripMinedLoopNode(C, init_control, outer_ift);
 294   entry_control = outer_l;
 295 
 296   IdealLoopTree* outer_ilt = new IdealLoopTree(this, outer_l, outer_ift);
 297   IdealLoopTree* parent = loop-&gt;_parent;
 298   IdealLoopTree* sibling = parent-&gt;_child;
 299   if (sibling == loop) {
 300     parent-&gt;_child = outer_ilt;
 301   } else {
 302     while (sibling-&gt;_next != loop) {
 303       sibling = sibling-&gt;_next;
 304     }
 305     sibling-&gt;_next = outer_ilt;
 306   }
 307   outer_ilt-&gt;_next = loop-&gt;_next;
 308   outer_ilt-&gt;_parent = parent;
 309   outer_ilt-&gt;_child = loop;
 310   outer_ilt-&gt;_nest = loop-&gt;_nest;
 311   loop-&gt;_parent = outer_ilt;
 312   loop-&gt;_next = NULL;
 313   loop-&gt;_nest++;
 314 
 315   set_loop(iffalse, outer_ilt);
 316   register_control(outer_le, outer_ilt, iffalse);
 317   register_control(outer_ift, outer_ilt, outer_le);
 318   set_idom(outer_iff, outer_le, dom_depth(outer_le));
 319   _igvn.register_new_node_with_optimizer(outer_l);
 320   set_loop(outer_l, outer_ilt);
 321   set_idom(outer_l, init_control, dom_depth(init_control)+1);
 322 
 323   return outer_ilt;
 324 }
 325 
 326 void PhaseIdealLoop::insert_loop_limit_check(ProjNode* limit_check_proj, Node* cmp_limit, Node* bol) {
 327   Node* new_predicate_proj = create_new_if_for_predicate(limit_check_proj, NULL,
 328                                                          Deoptimization::Reason_loop_limit_check,
 329                                                          Op_If);
 330   Node* iff = new_predicate_proj-&gt;in(0);
 331   assert(iff-&gt;Opcode() == Op_If, &quot;bad graph shape&quot;);
 332   Node* conv = iff-&gt;in(1);
 333   assert(conv-&gt;Opcode() == Op_Conv2B, &quot;bad graph shape&quot;);
 334   Node* opaq = conv-&gt;in(1);
 335   assert(opaq-&gt;Opcode() == Op_Opaque1, &quot;bad graph shape&quot;);
 336   cmp_limit = _igvn.register_new_node_with_optimizer(cmp_limit);
 337   bol = _igvn.register_new_node_with_optimizer(bol);
 338   set_subtree_ctrl(bol);
 339   _igvn.replace_input_of(iff, 1, bol);
 340 
 341 #ifndef PRODUCT
 342   // report that the loop predication has been actually performed
 343   // for this loop
 344   if (TraceLoopLimitCheck) {
 345     tty-&gt;print_cr(&quot;Counted Loop Limit Check generated:&quot;);
 346     debug_only( bol-&gt;dump(2); )
 347   }
 348 #endif
 349 }
 350 
 351 //------------------------------is_counted_loop--------------------------------
 352 bool PhaseIdealLoop::is_counted_loop(Node* x, IdealLoopTree*&amp; loop) {
 353   PhaseGVN *gvn = &amp;_igvn;
 354 
 355   // Counted loop head must be a good RegionNode with only 3 not NULL
 356   // control input edges: Self, Entry, LoopBack.
 357   if (x-&gt;in(LoopNode::Self) == NULL || x-&gt;req() != 3 || loop-&gt;_irreducible) {
 358     return false;
 359   }
 360   Node *init_control = x-&gt;in(LoopNode::EntryControl);
 361   Node *back_control = x-&gt;in(LoopNode::LoopBackControl);
 362   if (init_control == NULL || back_control == NULL)    // Partially dead
 363     return false;
 364   // Must also check for TOP when looking for a dead loop
 365   if (init_control-&gt;is_top() || back_control-&gt;is_top())
 366     return false;
 367 
 368   // Allow funny placement of Safepoint
 369   if (back_control-&gt;Opcode() == Op_SafePoint) {
 370     if (LoopStripMiningIter != 0) {
 371       // Leaving the safepoint on the backedge and creating a
 372       // CountedLoop will confuse optimizations. We can&#39;t move the
 373       // safepoint around because its jvm state wouldn&#39;t match a new
 374       // location. Give up on that loop.
 375       return false;
 376     }
 377     back_control = back_control-&gt;in(TypeFunc::Control);
 378   }
 379 
 380   // Controlling test for loop
 381   Node *iftrue = back_control;
 382   uint iftrue_op = iftrue-&gt;Opcode();
 383   if (iftrue_op != Op_IfTrue &amp;&amp;
 384       iftrue_op != Op_IfFalse)
 385     // I have a weird back-control.  Probably the loop-exit test is in
 386     // the middle of the loop and I am looking at some trailing control-flow
 387     // merge point.  To fix this I would have to partially peel the loop.
 388     return false; // Obscure back-control
 389 
 390   // Get boolean guarding loop-back test
 391   Node *iff = iftrue-&gt;in(0);
 392   if (get_loop(iff) != loop || !iff-&gt;in(1)-&gt;is_Bool())
 393     return false;
 394   BoolNode *test = iff-&gt;in(1)-&gt;as_Bool();
 395   BoolTest::mask bt = test-&gt;_test._test;
 396   float cl_prob = iff-&gt;as_If()-&gt;_prob;
 397   if (iftrue_op == Op_IfFalse) {
 398     bt = BoolTest(bt).negate();
 399     cl_prob = 1.0 - cl_prob;
 400   }
 401   // Get backedge compare
 402   Node *cmp = test-&gt;in(1);
 403   int cmp_op = cmp-&gt;Opcode();
 404   if (cmp_op != Op_CmpI)
 405     return false;                // Avoid pointer &amp; float compares
 406 
 407   // Find the trip-counter increment &amp; limit.  Limit must be loop invariant.
 408   Node *incr  = cmp-&gt;in(1);
 409   Node *limit = cmp-&gt;in(2);
 410 
 411   // ---------
 412   // need &#39;loop()&#39; test to tell if limit is loop invariant
 413   // ---------
 414 
 415   if (!is_member(loop, get_ctrl(incr))) { // Swapped trip counter and limit?
 416     Node *tmp = incr;            // Then reverse order into the CmpI
 417     incr = limit;
 418     limit = tmp;
 419     bt = BoolTest(bt).commute(); // And commute the exit test
 420   }
 421   if (is_member(loop, get_ctrl(limit))) // Limit must be loop-invariant
 422     return false;
 423   if (!is_member(loop, get_ctrl(incr))) // Trip counter must be loop-variant
 424     return false;
 425 
 426   Node* phi_incr = NULL;
 427   // Trip-counter increment must be commutative &amp; associative.
 428   if (incr-&gt;Opcode() == Op_CastII) {
 429     incr = incr-&gt;in(1);
 430   }
 431   if (incr-&gt;is_Phi()) {
 432     if (incr-&gt;as_Phi()-&gt;region() != x || incr-&gt;req() != 3)
 433       return false; // Not simple trip counter expression
 434     phi_incr = incr;
 435     incr = phi_incr-&gt;in(LoopNode::LoopBackControl); // Assume incr is on backedge of Phi
 436     if (!is_member(loop, get_ctrl(incr))) // Trip counter must be loop-variant
 437       return false;
 438   }
 439 
 440   Node* trunc1 = NULL;
 441   Node* trunc2 = NULL;
 442   const TypeInt* iv_trunc_t = NULL;
 443   Node* orig_incr = incr;
 444   if (!(incr = CountedLoopNode::match_incr_with_optional_truncation(incr, &amp;trunc1, &amp;trunc2, &amp;iv_trunc_t))) {
 445     return false; // Funny increment opcode
 446   }
 447   assert(incr-&gt;Opcode() == Op_AddI, &quot;wrong increment code&quot;);
 448 
 449   const TypeInt* limit_t = gvn-&gt;type(limit)-&gt;is_int();
 450   if (trunc1 != NULL) {
 451     // When there is a truncation, we must be sure that after the truncation
 452     // the trip counter will end up higher than the limit, otherwise we are looking
 453     // at an endless loop. Can happen with range checks.
 454 
 455     // Example:
 456     // int i = 0;
 457     // while (true)
 458     //    sum + = array[i];
 459     //    i++;
 460     //    i = i &amp;&amp; 0x7fff;
 461     //  }
 462     //
 463     // If the array is shorter than 0x8000 this exits through a AIOOB
 464     //  - Counted loop transformation is ok
 465     // If the array is longer then this is an endless loop
 466     //  - No transformation can be done.
 467 
 468     const TypeInt* incr_t = gvn-&gt;type(orig_incr)-&gt;is_int();
 469     if (limit_t-&gt;_hi &gt; incr_t-&gt;_hi) {
 470       // if the limit can have a higher value than the increment (before the phi)
 471       return false;
 472     }
 473   }
 474 
 475   // Get merge point
 476   Node *xphi = incr-&gt;in(1);
 477   Node *stride = incr-&gt;in(2);
 478   if (!stride-&gt;is_Con()) {     // Oops, swap these
 479     if (!xphi-&gt;is_Con())       // Is the other guy a constant?
 480       return false;             // Nope, unknown stride, bail out
 481     Node *tmp = xphi;           // &#39;incr&#39; is commutative, so ok to swap
 482     xphi = stride;
 483     stride = tmp;
 484   }
 485   if (xphi-&gt;Opcode() == Op_CastII) {
 486     xphi = xphi-&gt;in(1);
 487   }
 488   // Stride must be constant
 489   int stride_con = stride-&gt;get_int();
 490   if (stride_con == 0)
 491     return false; // missed some peephole opt
 492 
 493   if (!xphi-&gt;is_Phi())
 494     return false; // Too much math on the trip counter
 495   if (phi_incr != NULL &amp;&amp; phi_incr != xphi)
 496     return false;
 497   PhiNode *phi = xphi-&gt;as_Phi();
 498 
 499   // Phi must be of loop header; backedge must wrap to increment
 500   if (phi-&gt;region() != x)
 501     return false;
 502   if ((trunc1 == NULL &amp;&amp; phi-&gt;in(LoopNode::LoopBackControl) != incr) ||
 503       (trunc1 != NULL &amp;&amp; phi-&gt;in(LoopNode::LoopBackControl) != trunc1)) {
 504     return false;
 505   }
 506   Node *init_trip = phi-&gt;in(LoopNode::EntryControl);
 507 
 508   // If iv trunc type is smaller than int, check for possible wrap.
 509   if (!TypeInt::INT-&gt;higher_equal(iv_trunc_t)) {
 510     assert(trunc1 != NULL, &quot;must have found some truncation&quot;);
 511 
 512     // Get a better type for the phi (filtered thru if&#39;s)
 513     const TypeInt* phi_ft = filtered_type(phi);
 514 
 515     // Can iv take on a value that will wrap?
 516     //
 517     // Ensure iv&#39;s limit is not within &quot;stride&quot; of the wrap value.
 518     //
 519     // Example for &quot;short&quot; type
 520     //    Truncation ensures value is in the range -32768..32767 (iv_trunc_t)
 521     //    If the stride is +10, then the last value of the induction
 522     //    variable before the increment (phi_ft-&gt;_hi) must be
 523     //    &lt;= 32767 - 10 and (phi_ft-&gt;_lo) must be &gt;= -32768 to
 524     //    ensure no truncation occurs after the increment.
 525 
 526     if (stride_con &gt; 0) {
 527       if (iv_trunc_t-&gt;_hi - phi_ft-&gt;_hi &lt; stride_con ||
 528           iv_trunc_t-&gt;_lo &gt; phi_ft-&gt;_lo) {
 529         return false;  // truncation may occur
 530       }
 531     } else if (stride_con &lt; 0) {
 532       if (iv_trunc_t-&gt;_lo - phi_ft-&gt;_lo &gt; stride_con ||
 533           iv_trunc_t-&gt;_hi &lt; phi_ft-&gt;_hi) {
 534         return false;  // truncation may occur
 535       }
 536     }
 537     // No possibility of wrap so truncation can be discarded
 538     // Promote iv type to Int
 539   } else {
 540     assert(trunc1 == NULL &amp;&amp; trunc2 == NULL, &quot;no truncation for int&quot;);
 541   }
 542 
 543   // If the condition is inverted and we will be rolling
 544   // through MININT to MAXINT, then bail out.
 545   if (bt == BoolTest::eq || // Bail out, but this loop trips at most twice!
 546       // Odd stride
 547       (bt == BoolTest::ne &amp;&amp; stride_con != 1 &amp;&amp; stride_con != -1) ||
 548       // Count down loop rolls through MAXINT
 549       ((bt == BoolTest::le || bt == BoolTest::lt) &amp;&amp; stride_con &lt; 0) ||
 550       // Count up loop rolls through MININT
 551       ((bt == BoolTest::ge || bt == BoolTest::gt) &amp;&amp; stride_con &gt; 0)) {
 552     return false; // Bail out
 553   }
 554 
 555   const TypeInt* init_t = gvn-&gt;type(init_trip)-&gt;is_int();
 556 
 557   if (stride_con &gt; 0) {
 558     jlong init_p = (jlong)init_t-&gt;_lo + stride_con;
 559     if (init_p &gt; (jlong)max_jint || init_p &gt; (jlong)limit_t-&gt;_hi)
 560       return false; // cyclic loop or this loop trips only once
 561   } else {
 562     jlong init_p = (jlong)init_t-&gt;_hi + stride_con;
 563     if (init_p &lt; (jlong)min_jint || init_p &lt; (jlong)limit_t-&gt;_lo)
 564       return false; // cyclic loop or this loop trips only once
 565   }
 566 
 567   if (phi_incr != NULL &amp;&amp; bt != BoolTest::ne) {
 568     // check if there is a possiblity of IV overflowing after the first increment
 569     if (stride_con &gt; 0) {
 570       if (init_t-&gt;_hi &gt; max_jint - stride_con) {
 571         return false;
 572       }
 573     } else {
 574       if (init_t-&gt;_lo &lt; min_jint - stride_con) {
 575         return false;
 576       }
 577     }
 578   }
 579 
 580   // =================================================
 581   // ---- SUCCESS!   Found A Trip-Counted Loop!  -----
 582   //
 583   assert(x-&gt;Opcode() == Op_Loop, &quot;regular loops only&quot;);
 584   C-&gt;print_method(PHASE_BEFORE_CLOOPS, 3);
 585 
 586   Node *hook = new Node(6);
 587 
 588   // ===================================================
 589   // Generate loop limit check to avoid integer overflow
 590   // in cases like next (cyclic loops):
 591   //
 592   // for (i=0; i &lt;= max_jint; i++) {}
 593   // for (i=0; i &lt;  max_jint; i+=2) {}
 594   //
 595   //
 596   // Limit check predicate depends on the loop test:
 597   //
 598   // for(;i != limit; i++)       --&gt; limit &lt;= (max_jint)
 599   // for(;i &lt;  limit; i+=stride) --&gt; limit &lt;= (max_jint - stride + 1)
 600   // for(;i &lt;= limit; i+=stride) --&gt; limit &lt;= (max_jint - stride    )
 601   //
 602 
 603   // Check if limit is excluded to do more precise int overflow check.
 604   bool incl_limit = (bt == BoolTest::le || bt == BoolTest::ge);
 605   int stride_m  = stride_con - (incl_limit ? 0 : (stride_con &gt; 0 ? 1 : -1));
 606 
 607   // If compare points directly to the phi we need to adjust
 608   // the compare so that it points to the incr. Limit have
 609   // to be adjusted to keep trip count the same and the
 610   // adjusted limit should be checked for int overflow.
 611   if (phi_incr != NULL) {
 612     stride_m  += stride_con;
 613   }
 614 
 615   if (limit-&gt;is_Con()) {
 616     int limit_con = limit-&gt;get_int();
 617     if ((stride_con &gt; 0 &amp;&amp; limit_con &gt; (max_jint - stride_m)) ||
 618         (stride_con &lt; 0 &amp;&amp; limit_con &lt; (min_jint - stride_m))) {
 619       // Bailout: it could be integer overflow.
 620       return false;
 621     }
 622   } else if ((stride_con &gt; 0 &amp;&amp; limit_t-&gt;_hi &lt;= (max_jint - stride_m)) ||
 623              (stride_con &lt; 0 &amp;&amp; limit_t-&gt;_lo &gt;= (min_jint - stride_m))) {
 624       // Limit&#39;s type may satisfy the condition, for example,
 625       // when it is an array length.
 626   } else {
 627     // Generate loop&#39;s limit check.
 628     // Loop limit check predicate should be near the loop.
 629     ProjNode *limit_check_proj = find_predicate_insertion_point(init_control, Deoptimization::Reason_loop_limit_check);
 630     if (!limit_check_proj) {
 631       // The limit check predicate is not generated if this method trapped here before.
 632 #ifdef ASSERT
 633       if (TraceLoopLimitCheck) {
 634         tty-&gt;print(&quot;missing loop limit check:&quot;);
 635         loop-&gt;dump_head();
 636         x-&gt;dump(1);
 637       }
 638 #endif
 639       return false;
 640     }
 641 
 642     IfNode* check_iff = limit_check_proj-&gt;in(0)-&gt;as_If();
 643 
 644     if (!is_dominator(get_ctrl(limit), check_iff-&gt;in(0))) {
 645       return false;
 646     }
 647 
 648     Node* cmp_limit;
 649     Node* bol;
 650 
 651     if (stride_con &gt; 0) {
 652       cmp_limit = new CmpINode(limit, _igvn.intcon(max_jint - stride_m));
 653       bol = new BoolNode(cmp_limit, BoolTest::le);
 654     } else {
 655       cmp_limit = new CmpINode(limit, _igvn.intcon(min_jint - stride_m));
 656       bol = new BoolNode(cmp_limit, BoolTest::ge);
 657     }
 658 
 659     insert_loop_limit_check(limit_check_proj, cmp_limit, bol);
 660   }
 661 
 662   // Now we need to canonicalize loop condition.
 663   if (bt == BoolTest::ne) {
 664     assert(stride_con == 1 || stride_con == -1, &quot;simple increment only&quot;);
 665     if (stride_con &gt; 0 &amp;&amp; init_t-&gt;_hi &lt; limit_t-&gt;_lo) {
 666       // &#39;ne&#39; can be replaced with &#39;lt&#39; only when init &lt; limit.
 667       bt = BoolTest::lt;
 668     } else if (stride_con &lt; 0 &amp;&amp; init_t-&gt;_lo &gt; limit_t-&gt;_hi) {
 669       // &#39;ne&#39; can be replaced with &#39;gt&#39; only when init &gt; limit.
 670       bt = BoolTest::gt;
 671     } else {
 672       ProjNode *limit_check_proj = find_predicate_insertion_point(init_control, Deoptimization::Reason_loop_limit_check);
 673       if (!limit_check_proj) {
 674         // The limit check predicate is not generated if this method trapped here before.
 675 #ifdef ASSERT
 676         if (TraceLoopLimitCheck) {
 677           tty-&gt;print(&quot;missing loop limit check:&quot;);
 678           loop-&gt;dump_head();
 679           x-&gt;dump(1);
 680         }
 681 #endif
 682         return false;
 683       }
 684       IfNode* check_iff = limit_check_proj-&gt;in(0)-&gt;as_If();
 685 
 686       if (!is_dominator(get_ctrl(limit), check_iff-&gt;in(0)) ||
 687           !is_dominator(get_ctrl(init_trip), check_iff-&gt;in(0))) {
 688         return false;
 689       }
 690 
 691       Node* cmp_limit;
 692       Node* bol;
 693 
 694       if (stride_con &gt; 0) {
 695         cmp_limit = new CmpINode(init_trip, limit);
 696         bol = new BoolNode(cmp_limit, BoolTest::lt);
 697       } else {
 698         cmp_limit = new CmpINode(init_trip, limit);
 699         bol = new BoolNode(cmp_limit, BoolTest::gt);
 700       }
 701 
 702       insert_loop_limit_check(limit_check_proj, cmp_limit, bol);
 703 
 704       if (stride_con &gt; 0) {
 705         // &#39;ne&#39; can be replaced with &#39;lt&#39; only when init &lt; limit.
 706         bt = BoolTest::lt;
 707       } else if (stride_con &lt; 0) {
 708         // &#39;ne&#39; can be replaced with &#39;gt&#39; only when init &gt; limit.
 709         bt = BoolTest::gt;
 710       }
 711     }
 712   }
 713 
 714   if (phi_incr != NULL) {
 715     // If compare points directly to the phi we need to adjust
 716     // the compare so that it points to the incr. Limit have
 717     // to be adjusted to keep trip count the same and we
 718     // should avoid int overflow.
 719     //
 720     //   i = init; do {} while(i++ &lt; limit);
 721     // is converted to
 722     //   i = init; do {} while(++i &lt; limit+1);
 723     //
 724     limit = gvn-&gt;transform(new AddINode(limit, stride));
 725   }
 726 
 727   if (incl_limit) {
 728     // The limit check guaranties that &#39;limit &lt;= (max_jint - stride)&#39; so
 729     // we can convert &#39;i &lt;= limit&#39; to &#39;i &lt; limit+1&#39; since stride != 0.
 730     //
 731     Node* one = (stride_con &gt; 0) ? gvn-&gt;intcon( 1) : gvn-&gt;intcon(-1);
 732     limit = gvn-&gt;transform(new AddINode(limit, one));
 733     if (bt == BoolTest::le)
 734       bt = BoolTest::lt;
 735     else if (bt == BoolTest::ge)
 736       bt = BoolTest::gt;
 737     else
 738       ShouldNotReachHere();
 739   }
 740   set_subtree_ctrl( limit );
 741 
 742   if (LoopStripMiningIter == 0) {
 743     // Check for SafePoint on backedge and remove
 744     Node *sfpt = x-&gt;in(LoopNode::LoopBackControl);
 745     if (sfpt-&gt;Opcode() == Op_SafePoint &amp;&amp; is_deleteable_safept(sfpt)) {
 746       lazy_replace( sfpt, iftrue );
 747       if (loop-&gt;_safepts != NULL) {
 748         loop-&gt;_safepts-&gt;yank(sfpt);
 749       }
 750       loop-&gt;_tail = iftrue;
 751     }
 752   }
 753 
 754   // Build a canonical trip test.
 755   // Clone code, as old values may be in use.
 756   incr = incr-&gt;clone();
 757   incr-&gt;set_req(1,phi);
 758   incr-&gt;set_req(2,stride);
 759   incr = _igvn.register_new_node_with_optimizer(incr);
 760   set_early_ctrl( incr );
 761   _igvn.rehash_node_delayed(phi);
 762   phi-&gt;set_req_X( LoopNode::LoopBackControl, incr, &amp;_igvn );
 763 
 764   // If phi type is more restrictive than Int, raise to
 765   // Int to prevent (almost) infinite recursion in igvn
 766   // which can only handle integer types for constants or minint..maxint.
 767   if (!TypeInt::INT-&gt;higher_equal(phi-&gt;bottom_type())) {
 768     Node* nphi = PhiNode::make(phi-&gt;in(0), phi-&gt;in(LoopNode::EntryControl), TypeInt::INT);
 769     nphi-&gt;set_req(LoopNode::LoopBackControl, phi-&gt;in(LoopNode::LoopBackControl));
 770     nphi = _igvn.register_new_node_with_optimizer(nphi);
 771     set_ctrl(nphi, get_ctrl(phi));
 772     _igvn.replace_node(phi, nphi);
 773     phi = nphi-&gt;as_Phi();
 774   }
 775   cmp = cmp-&gt;clone();
 776   cmp-&gt;set_req(1,incr);
 777   cmp-&gt;set_req(2,limit);
 778   cmp = _igvn.register_new_node_with_optimizer(cmp);
 779   set_ctrl(cmp, iff-&gt;in(0));
 780 
 781   test = test-&gt;clone()-&gt;as_Bool();
 782   (*(BoolTest*)&amp;test-&gt;_test)._test = bt;
 783   test-&gt;set_req(1,cmp);
 784   _igvn.register_new_node_with_optimizer(test);
 785   set_ctrl(test, iff-&gt;in(0));
 786 
 787   // Replace the old IfNode with a new LoopEndNode
 788   Node *lex = _igvn.register_new_node_with_optimizer(new CountedLoopEndNode( iff-&gt;in(0), test, cl_prob, iff-&gt;as_If()-&gt;_fcnt ));
 789   IfNode *le = lex-&gt;as_If();
 790   uint dd = dom_depth(iff);
 791   set_idom(le, le-&gt;in(0), dd); // Update dominance for loop exit
 792   set_loop(le, loop);
 793 
 794   // Get the loop-exit control
 795   Node *iffalse = iff-&gt;as_If()-&gt;proj_out(!(iftrue_op == Op_IfTrue));
 796 
 797   // Need to swap loop-exit and loop-back control?
 798   if (iftrue_op == Op_IfFalse) {
 799     Node *ift2=_igvn.register_new_node_with_optimizer(new IfTrueNode (le));
 800     Node *iff2=_igvn.register_new_node_with_optimizer(new IfFalseNode(le));
 801 
 802     loop-&gt;_tail = back_control = ift2;
 803     set_loop(ift2, loop);
 804     set_loop(iff2, get_loop(iffalse));
 805 
 806     // Lazy update of &#39;get_ctrl&#39; mechanism.
 807     lazy_replace(iffalse, iff2);
 808     lazy_replace(iftrue,  ift2);
 809 
 810     // Swap names
 811     iffalse = iff2;
 812     iftrue  = ift2;
 813   } else {
 814     _igvn.rehash_node_delayed(iffalse);
 815     _igvn.rehash_node_delayed(iftrue);
 816     iffalse-&gt;set_req_X( 0, le, &amp;_igvn );
 817     iftrue -&gt;set_req_X( 0, le, &amp;_igvn );
 818   }
 819 
 820   set_idom(iftrue,  le, dd+1);
 821   set_idom(iffalse, le, dd+1);
 822   assert(iff-&gt;outcnt() == 0, &quot;should be dead now&quot;);
 823   lazy_replace( iff, le ); // fix &#39;get_ctrl&#39;
 824 
 825   Node *sfpt2 = le-&gt;in(0);
 826 
 827   Node* entry_control = init_control;
 828   bool strip_mine_loop = LoopStripMiningIter &gt; 1 &amp;&amp; loop-&gt;_child == NULL &amp;&amp;
 829     sfpt2-&gt;Opcode() == Op_SafePoint &amp;&amp; !loop-&gt;_has_call;
 830   IdealLoopTree* outer_ilt = NULL;
 831   if (strip_mine_loop) {
 832     outer_ilt = create_outer_strip_mined_loop(test, cmp, init_control, loop,
 833                                               cl_prob, le-&gt;_fcnt, entry_control,
 834                                               iffalse);
 835   }
 836 
 837   // Now setup a new CountedLoopNode to replace the existing LoopNode
 838   CountedLoopNode *l = new CountedLoopNode(entry_control, back_control);
 839   l-&gt;set_unswitch_count(x-&gt;as_Loop()-&gt;unswitch_count()); // Preserve
 840   // The following assert is approximately true, and defines the intention
 841   // of can_be_counted_loop.  It fails, however, because phase-&gt;type
 842   // is not yet initialized for this loop and its parts.
 843   //assert(l-&gt;can_be_counted_loop(this), &quot;sanity&quot;);
 844   _igvn.register_new_node_with_optimizer(l);
 845   set_loop(l, loop);
 846   loop-&gt;_head = l;
 847   // Fix all data nodes placed at the old loop head.
 848   // Uses the lazy-update mechanism of &#39;get_ctrl&#39;.
 849   lazy_replace( x, l );
 850   set_idom(l, entry_control, dom_depth(entry_control) + 1);
 851 
 852   if (LoopStripMiningIter == 0 || strip_mine_loop) {
 853     // Check for immediately preceding SafePoint and remove
 854     if (sfpt2-&gt;Opcode() == Op_SafePoint &amp;&amp; (LoopStripMiningIter != 0 || is_deleteable_safept(sfpt2))) {
 855       if (strip_mine_loop) {
 856         Node* outer_le = outer_ilt-&gt;_tail-&gt;in(0);
 857         Node* sfpt = sfpt2-&gt;clone();
 858         sfpt-&gt;set_req(0, iffalse);
 859         outer_le-&gt;set_req(0, sfpt);
 860         register_control(sfpt, outer_ilt, iffalse);
 861         set_idom(outer_le, sfpt, dom_depth(sfpt));
 862       }
 863       lazy_replace( sfpt2, sfpt2-&gt;in(TypeFunc::Control));
 864       if (loop-&gt;_safepts != NULL) {
 865         loop-&gt;_safepts-&gt;yank(sfpt2);
 866       }
 867     }
 868   }
 869 
 870   // Free up intermediate goo
 871   _igvn.remove_dead_node(hook);
 872 
 873 #ifdef ASSERT
 874   assert(l-&gt;is_valid_counted_loop(), &quot;counted loop shape is messed up&quot;);
 875   assert(l == loop-&gt;_head &amp;&amp; l-&gt;phi() == phi &amp;&amp; l-&gt;loopexit_or_null() == lex, &quot;&quot; );
 876 #endif
 877 #ifndef PRODUCT
 878   if (TraceLoopOpts) {
 879     tty-&gt;print(&quot;Counted      &quot;);
 880     loop-&gt;dump_head();
 881   }
 882 #endif
 883 
 884   C-&gt;print_method(PHASE_AFTER_CLOOPS, 3);
 885 
 886   // Capture bounds of the loop in the induction variable Phi before
 887   // subsequent transformation (iteration splitting) obscures the
 888   // bounds
 889   l-&gt;phi()-&gt;as_Phi()-&gt;set_type(l-&gt;phi()-&gt;Value(&amp;_igvn));
 890 
 891   if (strip_mine_loop) {
 892     l-&gt;mark_strip_mined();
 893     l-&gt;verify_strip_mined(1);
 894     outer_ilt-&gt;_head-&gt;as_Loop()-&gt;verify_strip_mined(1);
 895     loop = outer_ilt;
 896   }
 897 
 898   return true;
 899 }
 900 
 901 //----------------------exact_limit-------------------------------------------
 902 Node* PhaseIdealLoop::exact_limit( IdealLoopTree *loop ) {
 903   assert(loop-&gt;_head-&gt;is_CountedLoop(), &quot;&quot;);
 904   CountedLoopNode *cl = loop-&gt;_head-&gt;as_CountedLoop();
 905   assert(cl-&gt;is_valid_counted_loop(), &quot;&quot;);
 906 
 907   if (ABS(cl-&gt;stride_con()) == 1 ||
 908       cl-&gt;limit()-&gt;Opcode() == Op_LoopLimit) {
 909     // Old code has exact limit (it could be incorrect in case of int overflow).
 910     // Loop limit is exact with stride == 1. And loop may already have exact limit.
 911     return cl-&gt;limit();
 912   }
 913   Node *limit = NULL;
 914 #ifdef ASSERT
 915   BoolTest::mask bt = cl-&gt;loopexit()-&gt;test_trip();
 916   assert(bt == BoolTest::lt || bt == BoolTest::gt, &quot;canonical test is expected&quot;);
 917 #endif
 918   if (cl-&gt;has_exact_trip_count()) {
 919     // Simple case: loop has constant boundaries.
 920     // Use jlongs to avoid integer overflow.
 921     int stride_con = cl-&gt;stride_con();
 922     jlong  init_con = cl-&gt;init_trip()-&gt;get_int();
 923     jlong limit_con = cl-&gt;limit()-&gt;get_int();
 924     julong trip_cnt = cl-&gt;trip_count();
 925     jlong final_con = init_con + trip_cnt*stride_con;
 926     int final_int = (int)final_con;
 927     // The final value should be in integer range since the loop
 928     // is counted and the limit was checked for overflow.
 929     assert(final_con == (jlong)final_int, &quot;final value should be integer&quot;);
 930     limit = _igvn.intcon(final_int);
 931   } else {
 932     // Create new LoopLimit node to get exact limit (final iv value).
 933     limit = new LoopLimitNode(C, cl-&gt;init_trip(), cl-&gt;limit(), cl-&gt;stride());
 934     register_new_node(limit, cl-&gt;in(LoopNode::EntryControl));
 935   }
 936   assert(limit != NULL, &quot;sanity&quot;);
 937   return limit;
 938 }
 939 
 940 //------------------------------Ideal------------------------------------------
 941 // Return a node which is more &quot;ideal&quot; than the current node.
 942 // Attempt to convert into a counted-loop.
 943 Node *LoopNode::Ideal(PhaseGVN *phase, bool can_reshape) {
 944   if (!can_be_counted_loop(phase) &amp;&amp; !is_OuterStripMinedLoop()) {
 945     phase-&gt;C-&gt;set_major_progress();
 946   }
 947   return RegionNode::Ideal(phase, can_reshape);
 948 }
 949 
 950 #ifdef ASSERT
 951 void LoopNode::verify_strip_mined(int expect_skeleton) const {
 952   const OuterStripMinedLoopNode* outer = NULL;
 953   const CountedLoopNode* inner = NULL;
 954   if (is_strip_mined()) {
 955     if (!is_valid_counted_loop()) {
 956       return; // Skip malformed counted loop
 957     }
 958     assert(is_CountedLoop(), &quot;no Loop should be marked strip mined&quot;);
 959     inner = as_CountedLoop();
 960     outer = inner-&gt;in(LoopNode::EntryControl)-&gt;as_OuterStripMinedLoop();
 961   } else if (is_OuterStripMinedLoop()) {
 962     outer = this-&gt;as_OuterStripMinedLoop();
 963     inner = outer-&gt;unique_ctrl_out()-&gt;as_CountedLoop();
 964     assert(inner-&gt;is_valid_counted_loop() &amp;&amp; inner-&gt;is_strip_mined(), &quot;OuterStripMinedLoop should have been removed&quot;);
 965     assert(!is_strip_mined(), &quot;outer loop shouldn&#39;t be marked strip mined&quot;);
 966   }
 967   if (inner != NULL || outer != NULL) {
 968     assert(inner != NULL &amp;&amp; outer != NULL, &quot;missing loop in strip mined nest&quot;);
 969     Node* outer_tail = outer-&gt;in(LoopNode::LoopBackControl);
 970     Node* outer_le = outer_tail-&gt;in(0);
 971     assert(outer_le-&gt;Opcode() == Op_OuterStripMinedLoopEnd, &quot;tail of outer loop should be an If&quot;);
 972     Node* sfpt = outer_le-&gt;in(0);
 973     assert(sfpt-&gt;Opcode() == Op_SafePoint, &quot;where&#39;s the safepoint?&quot;);
 974     Node* inner_out = sfpt-&gt;in(0);
 975     if (inner_out-&gt;outcnt() != 1) {
 976       ResourceMark rm;
 977       Unique_Node_List wq;
 978 
 979       for (DUIterator_Fast imax, i = inner_out-&gt;fast_outs(imax); i &lt; imax; i++) {
 980         Node* u = inner_out-&gt;fast_out(i);
 981         if (u == sfpt) {
 982           continue;
 983         }
 984         wq.clear();
 985         wq.push(u);
 986         bool found_sfpt = false;
 987         for (uint next = 0; next &lt; wq.size() &amp;&amp; !found_sfpt; next++) {
 988           Node* n = wq.at(next);
 989           for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax &amp;&amp; !found_sfpt; i++) {
 990             Node* u = n-&gt;fast_out(i);
 991             if (u == sfpt) {
 992               found_sfpt = true;
 993             }
 994             if (!u-&gt;is_CFG()) {
 995               wq.push(u);
 996             }
 997           }
 998         }
 999         assert(found_sfpt, &quot;no node in loop that&#39;s not input to safepoint&quot;);
1000       }
1001     }
1002 
1003     CountedLoopEndNode* cle = inner_out-&gt;in(0)-&gt;as_CountedLoopEnd();
1004     assert(cle == inner-&gt;loopexit_or_null(), &quot;mismatch&quot;);
1005     bool has_skeleton = outer_le-&gt;in(1)-&gt;bottom_type()-&gt;singleton() &amp;&amp; outer_le-&gt;in(1)-&gt;bottom_type()-&gt;is_int()-&gt;get_con() == 0;
1006     if (has_skeleton) {
1007       assert(expect_skeleton == 1 || expect_skeleton == -1, &quot;unexpected skeleton node&quot;);
1008       assert(outer-&gt;outcnt() == 2, &quot;only phis&quot;);
1009     } else {
1010       assert(expect_skeleton == 0 || expect_skeleton == -1, &quot;no skeleton node?&quot;);
1011       uint phis = 0;
1012       for (DUIterator_Fast imax, i = inner-&gt;fast_outs(imax); i &lt; imax; i++) {
1013         Node* u = inner-&gt;fast_out(i);
1014         if (u-&gt;is_Phi()) {
1015           phis++;
1016         }
1017       }
1018       for (DUIterator_Fast imax, i = outer-&gt;fast_outs(imax); i &lt; imax; i++) {
1019         Node* u = outer-&gt;fast_out(i);
1020         assert(u == outer || u == inner || u-&gt;is_Phi(), &quot;nothing between inner and outer loop&quot;);
1021       }
1022       uint stores = 0;
1023       for (DUIterator_Fast imax, i = inner_out-&gt;fast_outs(imax); i &lt; imax; i++) {
1024         Node* u = inner_out-&gt;fast_out(i);
1025         if (u-&gt;is_Store()) {
1026           stores++;
1027         }
1028       }
1029       assert(outer-&gt;outcnt() &gt;= phis + 2 &amp;&amp; outer-&gt;outcnt() &lt;= phis + 2 + stores + 1, &quot;only phis&quot;);
1030     }
1031     assert(sfpt-&gt;outcnt() == 1, &quot;no data node&quot;);
1032     assert(outer_tail-&gt;outcnt() == 1 || !has_skeleton, &quot;no data node&quot;);
1033   }
1034 }
1035 #endif
1036 
1037 //=============================================================================
1038 //------------------------------Ideal------------------------------------------
1039 // Return a node which is more &quot;ideal&quot; than the current node.
1040 // Attempt to convert into a counted-loop.
1041 Node *CountedLoopNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1042   return RegionNode::Ideal(phase, can_reshape);
1043 }
1044 
1045 //------------------------------dump_spec--------------------------------------
1046 // Dump special per-node info
1047 #ifndef PRODUCT
1048 void CountedLoopNode::dump_spec(outputStream *st) const {
1049   LoopNode::dump_spec(st);
1050   if (stride_is_con()) {
1051     st-&gt;print(&quot;stride: %d &quot;,stride_con());
1052   }
1053   if (is_pre_loop ()) st-&gt;print(&quot;pre of N%d&quot; , _main_idx);
1054   if (is_main_loop()) st-&gt;print(&quot;main of N%d&quot;, _idx);
1055   if (is_post_loop()) st-&gt;print(&quot;post of N%d&quot;, _main_idx);
1056   if (is_strip_mined()) st-&gt;print(&quot; strip mined&quot;);
1057 }
1058 #endif
1059 
1060 //=============================================================================
1061 int CountedLoopEndNode::stride_con() const {
1062   return stride()-&gt;bottom_type()-&gt;is_int()-&gt;get_con();
1063 }
1064 
1065 //=============================================================================
1066 //------------------------------Value-----------------------------------------
1067 const Type* LoopLimitNode::Value(PhaseGVN* phase) const {
1068   const Type* init_t   = phase-&gt;type(in(Init));
1069   const Type* limit_t  = phase-&gt;type(in(Limit));
1070   const Type* stride_t = phase-&gt;type(in(Stride));
1071   // Either input is TOP ==&gt; the result is TOP
1072   if (init_t   == Type::TOP) return Type::TOP;
1073   if (limit_t  == Type::TOP) return Type::TOP;
1074   if (stride_t == Type::TOP) return Type::TOP;
1075 
1076   int stride_con = stride_t-&gt;is_int()-&gt;get_con();
1077   if (stride_con == 1)
1078     return NULL;  // Identity
1079 
1080   if (init_t-&gt;is_int()-&gt;is_con() &amp;&amp; limit_t-&gt;is_int()-&gt;is_con()) {
1081     // Use jlongs to avoid integer overflow.
1082     jlong init_con   =  init_t-&gt;is_int()-&gt;get_con();
1083     jlong limit_con  = limit_t-&gt;is_int()-&gt;get_con();
1084     int  stride_m   = stride_con - (stride_con &gt; 0 ? 1 : -1);
1085     jlong trip_count = (limit_con - init_con + stride_m)/stride_con;
1086     jlong final_con  = init_con + stride_con*trip_count;
1087     int final_int = (int)final_con;
1088     // The final value should be in integer range since the loop
1089     // is counted and the limit was checked for overflow.
1090     assert(final_con == (jlong)final_int, &quot;final value should be integer&quot;);
1091     return TypeInt::make(final_int);
1092   }
1093 
1094   return bottom_type(); // TypeInt::INT
1095 }
1096 
1097 //------------------------------Ideal------------------------------------------
1098 // Return a node which is more &quot;ideal&quot; than the current node.
1099 Node *LoopLimitNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1100   if (phase-&gt;type(in(Init))   == Type::TOP ||
1101       phase-&gt;type(in(Limit))  == Type::TOP ||
1102       phase-&gt;type(in(Stride)) == Type::TOP)
1103     return NULL;  // Dead
1104 
1105   int stride_con = phase-&gt;type(in(Stride))-&gt;is_int()-&gt;get_con();
1106   if (stride_con == 1)
1107     return NULL;  // Identity
1108 
1109   if (in(Init)-&gt;is_Con() &amp;&amp; in(Limit)-&gt;is_Con())
1110     return NULL;  // Value
1111 
1112   // Delay following optimizations until all loop optimizations
1113   // done to keep Ideal graph simple.
1114   if (!can_reshape || phase-&gt;C-&gt;major_progress())
1115     return NULL;
1116 
1117   const TypeInt* init_t  = phase-&gt;type(in(Init) )-&gt;is_int();
1118   const TypeInt* limit_t = phase-&gt;type(in(Limit))-&gt;is_int();
1119   int stride_p;
1120   jlong lim, ini;
1121   julong max;
1122   if (stride_con &gt; 0) {
1123     stride_p = stride_con;
1124     lim = limit_t-&gt;_hi;
1125     ini = init_t-&gt;_lo;
1126     max = (julong)max_jint;
1127   } else {
1128     stride_p = -stride_con;
1129     lim = init_t-&gt;_hi;
1130     ini = limit_t-&gt;_lo;
1131     max = (julong)min_jint;
1132   }
1133   julong range = lim - ini + stride_p;
1134   if (range &lt;= max) {
1135     // Convert to integer expression if it is not overflow.
1136     Node* stride_m = phase-&gt;intcon(stride_con - (stride_con &gt; 0 ? 1 : -1));
1137     Node *range = phase-&gt;transform(new SubINode(in(Limit), in(Init)));
1138     Node *bias  = phase-&gt;transform(new AddINode(range, stride_m));
1139     Node *trip  = phase-&gt;transform(new DivINode(0, bias, in(Stride)));
1140     Node *span  = phase-&gt;transform(new MulINode(trip, in(Stride)));
1141     return new AddINode(span, in(Init)); // exact limit
1142   }
1143 
1144   if (is_power_of_2(stride_p) ||                // divisor is 2^n
1145       !Matcher::has_match_rule(Op_LoopLimit)) { // or no specialized Mach node?
1146     // Convert to long expression to avoid integer overflow
1147     // and let igvn optimizer convert this division.
1148     //
1149     Node*   init   = phase-&gt;transform( new ConvI2LNode(in(Init)));
1150     Node*  limit   = phase-&gt;transform( new ConvI2LNode(in(Limit)));
1151     Node* stride   = phase-&gt;longcon(stride_con);
1152     Node* stride_m = phase-&gt;longcon(stride_con - (stride_con &gt; 0 ? 1 : -1));
1153 
1154     Node *range = phase-&gt;transform(new SubLNode(limit, init));
1155     Node *bias  = phase-&gt;transform(new AddLNode(range, stride_m));
1156     Node *span;
1157     if (stride_con &gt; 0 &amp;&amp; is_power_of_2(stride_p)) {
1158       // bias &gt;= 0 if stride &gt;0, so if stride is 2^n we can use &amp;(-stride)
1159       // and avoid generating rounding for division. Zero trip guard should
1160       // guarantee that init &lt; limit but sometimes the guard is missing and
1161       // we can get situation when init &gt; limit. Note, for the empty loop
1162       // optimization zero trip guard is generated explicitly which leaves
1163       // only RCE predicate where exact limit is used and the predicate
1164       // will simply fail forcing recompilation.
1165       Node* neg_stride   = phase-&gt;longcon(-stride_con);
1166       span = phase-&gt;transform(new AndLNode(bias, neg_stride));
1167     } else {
1168       Node *trip  = phase-&gt;transform(new DivLNode(0, bias, stride));
1169       span = phase-&gt;transform(new MulLNode(trip, stride));
1170     }
1171     // Convert back to int
1172     Node *span_int = phase-&gt;transform(new ConvL2INode(span));
1173     return new AddINode(span_int, in(Init)); // exact limit
1174   }
1175 
1176   return NULL;    // No progress
1177 }
1178 
1179 //------------------------------Identity---------------------------------------
1180 // If stride == 1 return limit node.
1181 Node* LoopLimitNode::Identity(PhaseGVN* phase) {
1182   int stride_con = phase-&gt;type(in(Stride))-&gt;is_int()-&gt;get_con();
1183   if (stride_con == 1 || stride_con == -1)
1184     return in(Limit);
1185   return this;
1186 }
1187 
1188 //=============================================================================
1189 //----------------------match_incr_with_optional_truncation--------------------
1190 // Match increment with optional truncation:
1191 // CHAR: (i+1)&amp;0x7fff, BYTE: ((i+1)&lt;&lt;8)&gt;&gt;8, or SHORT: ((i+1)&lt;&lt;16)&gt;&gt;16
1192 // Return NULL for failure. Success returns the increment node.
1193 Node* CountedLoopNode::match_incr_with_optional_truncation(
1194                       Node* expr, Node** trunc1, Node** trunc2, const TypeInt** trunc_type) {
1195   // Quick cutouts:
1196   if (expr == NULL || expr-&gt;req() != 3)  return NULL;
1197 
1198   Node *t1 = NULL;
1199   Node *t2 = NULL;
1200   const TypeInt* trunc_t = TypeInt::INT;
1201   Node* n1 = expr;
1202   int   n1op = n1-&gt;Opcode();
1203 
1204   // Try to strip (n1 &amp; M) or (n1 &lt;&lt; N &gt;&gt; N) from n1.
1205   if (n1op == Op_AndI &amp;&amp;
1206       n1-&gt;in(2)-&gt;is_Con() &amp;&amp;
1207       n1-&gt;in(2)-&gt;bottom_type()-&gt;is_int()-&gt;get_con() == 0x7fff) {
1208     // %%% This check should match any mask of 2**K-1.
1209     t1 = n1;
1210     n1 = t1-&gt;in(1);
1211     n1op = n1-&gt;Opcode();
1212     trunc_t = TypeInt::CHAR;
1213   } else if (n1op == Op_RShiftI &amp;&amp;
1214              n1-&gt;in(1) != NULL &amp;&amp;
1215              n1-&gt;in(1)-&gt;Opcode() == Op_LShiftI &amp;&amp;
1216              n1-&gt;in(2) == n1-&gt;in(1)-&gt;in(2) &amp;&amp;
1217              n1-&gt;in(2)-&gt;is_Con()) {
1218     jint shift = n1-&gt;in(2)-&gt;bottom_type()-&gt;is_int()-&gt;get_con();
1219     // %%% This check should match any shift in [1..31].
1220     if (shift == 16 || shift == 8) {
1221       t1 = n1;
1222       t2 = t1-&gt;in(1);
1223       n1 = t2-&gt;in(1);
1224       n1op = n1-&gt;Opcode();
1225       if (shift == 16) {
1226         trunc_t = TypeInt::SHORT;
1227       } else if (shift == 8) {
1228         trunc_t = TypeInt::BYTE;
1229       }
1230     }
1231   }
1232 
1233   // If (maybe after stripping) it is an AddI, we won:
1234   if (n1op == Op_AddI) {
1235     *trunc1 = t1;
1236     *trunc2 = t2;
1237     *trunc_type = trunc_t;
1238     return n1;
1239   }
1240 
1241   // failed
1242   return NULL;
1243 }
1244 
1245 LoopNode* CountedLoopNode::skip_strip_mined(int expect_skeleton) {
1246   if (is_strip_mined() &amp;&amp; is_valid_counted_loop()) {
1247     verify_strip_mined(expect_skeleton);
1248     return in(EntryControl)-&gt;as_Loop();
1249   }
1250   return this;
1251 }
1252 
1253 OuterStripMinedLoopNode* CountedLoopNode::outer_loop() const {
1254   assert(is_strip_mined(), &quot;not a strip mined loop&quot;);
1255   Node* c = in(EntryControl);
1256   if (c == NULL || c-&gt;is_top() || !c-&gt;is_OuterStripMinedLoop()) {
1257     return NULL;
1258   }
1259   return c-&gt;as_OuterStripMinedLoop();
1260 }
1261 
1262 IfTrueNode* OuterStripMinedLoopNode::outer_loop_tail() const {
1263   Node* c = in(LoopBackControl);
1264   if (c == NULL || c-&gt;is_top()) {
1265     return NULL;
1266   }
1267   return c-&gt;as_IfTrue();
1268 }
1269 
1270 IfTrueNode* CountedLoopNode::outer_loop_tail() const {
1271   LoopNode* l = outer_loop();
1272   if (l == NULL) {
1273     return NULL;
1274   }
1275   return l-&gt;outer_loop_tail();
1276 }
1277 
1278 OuterStripMinedLoopEndNode* OuterStripMinedLoopNode::outer_loop_end() const {
1279   IfTrueNode* proj = outer_loop_tail();
1280   if (proj == NULL) {
1281     return NULL;
1282   }
1283   Node* c = proj-&gt;in(0);
1284   if (c == NULL || c-&gt;is_top() || c-&gt;outcnt() != 2) {
1285     return NULL;
1286   }
1287   return c-&gt;as_OuterStripMinedLoopEnd();
1288 }
1289 
1290 OuterStripMinedLoopEndNode* CountedLoopNode::outer_loop_end() const {
1291   LoopNode* l = outer_loop();
1292   if (l == NULL) {
1293     return NULL;
1294   }
1295   return l-&gt;outer_loop_end();
1296 }
1297 
1298 IfFalseNode* OuterStripMinedLoopNode::outer_loop_exit() const {
1299   IfNode* le = outer_loop_end();
1300   if (le == NULL) {
1301     return NULL;
1302   }
1303   Node* c = le-&gt;proj_out_or_null(false);
1304   if (c == NULL) {
1305     return NULL;
1306   }
1307   return c-&gt;as_IfFalse();
1308 }
1309 
1310 IfFalseNode* CountedLoopNode::outer_loop_exit() const {
1311   LoopNode* l = outer_loop();
1312   if (l == NULL) {
1313     return NULL;
1314   }
1315   return l-&gt;outer_loop_exit();
1316 }
1317 
1318 SafePointNode* OuterStripMinedLoopNode::outer_safepoint() const {
1319   IfNode* le = outer_loop_end();
1320   if (le == NULL) {
1321     return NULL;
1322   }
1323   Node* c = le-&gt;in(0);
1324   if (c == NULL || c-&gt;is_top()) {
1325     return NULL;
1326   }
1327   assert(c-&gt;Opcode() == Op_SafePoint, &quot;broken outer loop&quot;);
1328   return c-&gt;as_SafePoint();
1329 }
1330 
1331 SafePointNode* CountedLoopNode::outer_safepoint() const {
1332   LoopNode* l = outer_loop();
1333   if (l == NULL) {
1334     return NULL;
1335   }
1336   return l-&gt;outer_safepoint();
1337 }
1338 
1339 Node* CountedLoopNode::skip_predicates_from_entry(Node* ctrl) {
1340     while (ctrl != NULL &amp;&amp; ctrl-&gt;is_Proj() &amp;&amp; ctrl-&gt;in(0)-&gt;is_If() &amp;&amp;
1341            ctrl-&gt;in(0)-&gt;as_If()-&gt;proj_out(1-ctrl-&gt;as_Proj()-&gt;_con)-&gt;outcnt() == 1 &amp;&amp;
1342            ctrl-&gt;in(0)-&gt;as_If()-&gt;proj_out(1-ctrl-&gt;as_Proj()-&gt;_con)-&gt;unique_out()-&gt;Opcode() == Op_Halt) {
1343       ctrl = ctrl-&gt;in(0)-&gt;in(0);
1344     }
1345 
1346     return ctrl;
1347   }
1348 
1349 Node* CountedLoopNode::skip_predicates() {
1350   if (is_main_loop()) {
1351     Node* ctrl = skip_strip_mined()-&gt;in(LoopNode::EntryControl);
1352 
1353     return skip_predicates_from_entry(ctrl);
1354   }
1355   return in(LoopNode::EntryControl);
1356 }
1357 
1358 void OuterStripMinedLoopNode::adjust_strip_mined_loop(PhaseIterGVN* igvn) {
1359   // Look for the outer &amp; inner strip mined loop, reduce number of
1360   // iterations of the inner loop, set exit condition of outer loop,
1361   // construct required phi nodes for outer loop.
1362   CountedLoopNode* inner_cl = unique_ctrl_out()-&gt;as_CountedLoop();
1363   assert(inner_cl-&gt;is_strip_mined(), &quot;inner loop should be strip mined&quot;);
1364   Node* inner_iv_phi = inner_cl-&gt;phi();
1365   if (inner_iv_phi == NULL) {
1366     IfNode* outer_le = outer_loop_end();
1367     Node* iff = igvn-&gt;transform(new IfNode(outer_le-&gt;in(0), outer_le-&gt;in(1), outer_le-&gt;_prob, outer_le-&gt;_fcnt));
1368     igvn-&gt;replace_node(outer_le, iff);
1369     inner_cl-&gt;clear_strip_mined();
1370     return;
1371   }
1372   CountedLoopEndNode* inner_cle = inner_cl-&gt;loopexit();
1373 
1374   int stride = inner_cl-&gt;stride_con();
1375   jlong scaled_iters_long = ((jlong)LoopStripMiningIter) * ABS(stride);
1376   int scaled_iters = (int)scaled_iters_long;
1377   int short_scaled_iters = LoopStripMiningIterShortLoop* ABS(stride);
1378   const TypeInt* inner_iv_t = igvn-&gt;type(inner_iv_phi)-&gt;is_int();
1379   jlong iter_estimate = (jlong)inner_iv_t-&gt;_hi - (jlong)inner_iv_t-&gt;_lo;
1380   assert(iter_estimate &gt; 0, &quot;broken&quot;);
1381   if ((jlong)scaled_iters != scaled_iters_long || iter_estimate &lt;= short_scaled_iters) {
1382     // Remove outer loop and safepoint (too few iterations)
1383     Node* outer_sfpt = outer_safepoint();
1384     Node* outer_out = outer_loop_exit();
1385     igvn-&gt;replace_node(outer_out, outer_sfpt-&gt;in(0));
1386     igvn-&gt;replace_input_of(outer_sfpt, 0, igvn-&gt;C-&gt;top());
1387     inner_cl-&gt;clear_strip_mined();
1388     return;
1389   }
1390   if (iter_estimate &lt;= scaled_iters_long) {
1391     // We would only go through one iteration of
1392     // the outer loop: drop the outer loop but
1393     // keep the safepoint so we don&#39;t run for
1394     // too long without a safepoint
1395     IfNode* outer_le = outer_loop_end();
1396     Node* iff = igvn-&gt;transform(new IfNode(outer_le-&gt;in(0), outer_le-&gt;in(1), outer_le-&gt;_prob, outer_le-&gt;_fcnt));
1397     igvn-&gt;replace_node(outer_le, iff);
1398     inner_cl-&gt;clear_strip_mined();
1399     return;
1400   }
1401 
1402   Node* cle_tail = inner_cle-&gt;proj_out(true);
1403   ResourceMark rm;
1404   Node_List old_new;
1405   if (cle_tail-&gt;outcnt() &gt; 1) {
1406     // Look for nodes on backedge of inner loop and clone them
1407     Unique_Node_List backedge_nodes;
1408     for (DUIterator_Fast imax, i = cle_tail-&gt;fast_outs(imax); i &lt; imax; i++) {
1409       Node* u = cle_tail-&gt;fast_out(i);
1410       if (u != inner_cl) {
1411         assert(!u-&gt;is_CFG(), &quot;control flow on the backedge?&quot;);
1412         backedge_nodes.push(u);
1413       }
1414     }
1415     uint last = igvn-&gt;C-&gt;unique();
1416     for (uint next = 0; next &lt; backedge_nodes.size(); next++) {
1417       Node* n = backedge_nodes.at(next);
1418       old_new.map(n-&gt;_idx, n-&gt;clone());
1419       for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
1420         Node* u = n-&gt;fast_out(i);
1421         assert(!u-&gt;is_CFG(), &quot;broken&quot;);
1422         if (u-&gt;_idx &gt;= last) {
1423           continue;
1424         }
1425         if (!u-&gt;is_Phi()) {
1426           backedge_nodes.push(u);
1427         } else {
1428           assert(u-&gt;in(0) == inner_cl, &quot;strange phi on the backedge&quot;);
1429         }
1430       }
1431     }
1432     // Put the clones on the outer loop backedge
1433     Node* le_tail = outer_loop_tail();
1434     for (uint next = 0; next &lt; backedge_nodes.size(); next++) {
1435       Node *n = old_new[backedge_nodes.at(next)-&gt;_idx];
1436       for (uint i = 1; i &lt; n-&gt;req(); i++) {
1437         if (n-&gt;in(i) != NULL &amp;&amp; old_new[n-&gt;in(i)-&gt;_idx] != NULL) {
1438           n-&gt;set_req(i, old_new[n-&gt;in(i)-&gt;_idx]);
1439         }
1440       }
1441       if (n-&gt;in(0) != NULL &amp;&amp; n-&gt;in(0) == cle_tail) {
1442         n-&gt;set_req(0, le_tail);
1443       }
1444       igvn-&gt;register_new_node_with_optimizer(n);
1445     }
1446   }
1447 
1448   Node* iv_phi = NULL;
1449   // Make a clone of each phi in the inner loop
1450   // for the outer loop
1451   for (uint i = 0; i &lt; inner_cl-&gt;outcnt(); i++) {
1452     Node* u = inner_cl-&gt;raw_out(i);
1453     if (u-&gt;is_Phi()) {
1454       assert(u-&gt;in(0) == inner_cl, &quot;inconsistent&quot;);
1455       Node* phi = u-&gt;clone();
1456       phi-&gt;set_req(0, this);
1457       Node* be = old_new[phi-&gt;in(LoopNode::LoopBackControl)-&gt;_idx];
1458       if (be != NULL) {
1459         phi-&gt;set_req(LoopNode::LoopBackControl, be);
1460       }
1461       phi = igvn-&gt;transform(phi);
1462       igvn-&gt;replace_input_of(u, LoopNode::EntryControl, phi);
1463       if (u == inner_iv_phi) {
1464         iv_phi = phi;
1465       }
1466     }
1467   }
1468   Node* cle_out = inner_cle-&gt;proj_out(false);
1469   if (cle_out-&gt;outcnt() &gt; 1) {
1470     // Look for chains of stores that were sunk
1471     // out of the inner loop and are in the outer loop
1472     for (DUIterator_Fast imax, i = cle_out-&gt;fast_outs(imax); i &lt; imax; i++) {
1473       Node* u = cle_out-&gt;fast_out(i);
1474       if (u-&gt;is_Store()) {
1475         Node* first = u;
1476         for(;;) {
1477           Node* next = first-&gt;in(MemNode::Memory);
1478           if (!next-&gt;is_Store() || next-&gt;in(0) != cle_out) {
1479             break;
1480           }
1481           first = next;
1482         }
1483         Node* last = u;
1484         for(;;) {
1485           Node* next = NULL;
1486           for (DUIterator_Fast jmax, j = last-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1487             Node* uu = last-&gt;fast_out(j);
1488             if (uu-&gt;is_Store() &amp;&amp; uu-&gt;in(0) == cle_out) {
1489               assert(next == NULL, &quot;only one in the outer loop&quot;);
1490               next = uu;
1491             }
1492           }
1493           if (next == NULL) {
1494             break;
1495           }
1496           last = next;
1497         }
1498         Node* phi = NULL;
1499         for (DUIterator_Fast jmax, j = fast_outs(jmax); j &lt; jmax; j++) {
1500           Node* uu = fast_out(j);
1501           if (uu-&gt;is_Phi()) {
1502             Node* be = uu-&gt;in(LoopNode::LoopBackControl);
1503             if (be-&gt;is_Store() &amp;&amp; old_new[be-&gt;_idx] != NULL) {
1504               assert(false, &quot;store on the backedge + sunk stores: unsupported&quot;);
1505               // drop outer loop
1506               IfNode* outer_le = outer_loop_end();
1507               Node* iff = igvn-&gt;transform(new IfNode(outer_le-&gt;in(0), outer_le-&gt;in(1), outer_le-&gt;_prob, outer_le-&gt;_fcnt));
1508               igvn-&gt;replace_node(outer_le, iff);
1509               inner_cl-&gt;clear_strip_mined();
1510               return;
1511             }
1512             if (be == last || be == first-&gt;in(MemNode::Memory)) {
1513               assert(phi == NULL, &quot;only one phi&quot;);
1514               phi = uu;
1515             }
1516           }
1517         }
1518 #ifdef ASSERT
1519         for (DUIterator_Fast jmax, j = fast_outs(jmax); j &lt; jmax; j++) {
1520           Node* uu = fast_out(j);
1521           if (uu-&gt;is_Phi() &amp;&amp; uu-&gt;bottom_type() == Type::MEMORY) {
1522             if (uu-&gt;adr_type() == igvn-&gt;C-&gt;get_adr_type(igvn-&gt;C-&gt;get_alias_index(u-&gt;adr_type()))) {
1523               assert(phi == uu, &quot;what&#39;s that phi?&quot;);
1524             } else if (uu-&gt;adr_type() == TypePtr::BOTTOM) {
1525               Node* n = uu-&gt;in(LoopNode::LoopBackControl);
1526               uint limit = igvn-&gt;C-&gt;live_nodes();
1527               uint i = 0;
1528               while (n != uu) {
1529                 i++;
1530                 assert(i &lt; limit, &quot;infinite loop&quot;);
1531                 if (n-&gt;is_Proj()) {
1532                   n = n-&gt;in(0);
1533                 } else if (n-&gt;is_SafePoint() || n-&gt;is_MemBar()) {
1534                   n = n-&gt;in(TypeFunc::Memory);
1535                 } else if (n-&gt;is_Phi()) {
1536                   n = n-&gt;in(1);
1537                 } else if (n-&gt;is_MergeMem()) {
1538                   n = n-&gt;as_MergeMem()-&gt;memory_at(igvn-&gt;C-&gt;get_alias_index(u-&gt;adr_type()));
1539                 } else if (n-&gt;is_Store() || n-&gt;is_LoadStore() || n-&gt;is_ClearArray()) {
1540                   n = n-&gt;in(MemNode::Memory);
1541                 } else {
1542                   n-&gt;dump();
1543                   ShouldNotReachHere();
1544                 }
1545               }
1546             }
1547           }
1548         }
1549 #endif
1550         if (phi == NULL) {
1551           // If the an entire chains was sunk, the
1552           // inner loop has no phi for that memory
1553           // slice, create one for the outer loop
1554           phi = PhiNode::make(this, first-&gt;in(MemNode::Memory), Type::MEMORY,
1555                               igvn-&gt;C-&gt;get_adr_type(igvn-&gt;C-&gt;get_alias_index(u-&gt;adr_type())));
1556           phi-&gt;set_req(LoopNode::LoopBackControl, last);
1557           phi = igvn-&gt;transform(phi);
1558           igvn-&gt;replace_input_of(first, MemNode::Memory, phi);
1559         } else {
1560           // Or fix the outer loop fix to include
1561           // that chain of stores.
1562           Node* be = phi-&gt;in(LoopNode::LoopBackControl);
1563           assert(!(be-&gt;is_Store() &amp;&amp; old_new[be-&gt;_idx] != NULL), &quot;store on the backedge + sunk stores: unsupported&quot;);
1564           if (be == first-&gt;in(MemNode::Memory)) {
1565             if (be == phi-&gt;in(LoopNode::LoopBackControl)) {
1566               igvn-&gt;replace_input_of(phi, LoopNode::LoopBackControl, last);
1567             } else {
1568               igvn-&gt;replace_input_of(be, MemNode::Memory, last);
1569             }
1570           } else {
1571 #ifdef ASSERT
1572             if (be == phi-&gt;in(LoopNode::LoopBackControl)) {
1573               assert(phi-&gt;in(LoopNode::LoopBackControl) == last, &quot;&quot;);
1574             } else {
1575               assert(be-&gt;in(MemNode::Memory) == last, &quot;&quot;);
1576             }
1577 #endif
1578           }
1579         }
1580       }
1581     }
1582   }
1583 
1584   if (iv_phi != NULL) {
1585     // Now adjust the inner loop&#39;s exit condition
1586     Node* limit = inner_cl-&gt;limit();
1587     Node* sub = NULL;
1588     if (stride &gt; 0) {
1589       sub = igvn-&gt;transform(new SubINode(limit, iv_phi));
1590     } else {
1591       sub = igvn-&gt;transform(new SubINode(iv_phi, limit));
1592     }
1593     // sub is positive and can be larger than the max signed int
1594     // value. Use an unsigned min.
1595     Node* const_iters = igvn-&gt;intcon(scaled_iters);
1596     Node* cmp = igvn-&gt;transform(new CmpUNode(sub, const_iters));
1597     Node* bol = igvn-&gt;transform(new BoolNode(cmp, BoolTest::lt));
1598     Node* min = igvn-&gt;transform(new CMoveINode(bol, const_iters, sub, TypeInt::make(0, scaled_iters, Type::WidenMin)));
1599 
1600     Node* new_limit = NULL;
1601     if (stride &gt; 0) {
1602       new_limit = igvn-&gt;transform(new AddINode(min, iv_phi));
1603     } else {
1604       new_limit = igvn-&gt;transform(new SubINode(iv_phi, min));
1605     }
1606     Node* inner_cmp = inner_cle-&gt;cmp_node();
1607     Node* inner_bol = inner_cle-&gt;in(CountedLoopEndNode::TestValue);
1608     Node* outer_bol = inner_bol;
1609     // cmp node for inner loop may be shared
1610     inner_cmp = inner_cmp-&gt;clone();
1611     inner_cmp-&gt;set_req(2, new_limit);
1612     inner_bol = inner_bol-&gt;clone();
1613     inner_bol-&gt;set_req(1, igvn-&gt;transform(inner_cmp));
1614     igvn-&gt;replace_input_of(inner_cle, CountedLoopEndNode::TestValue, igvn-&gt;transform(inner_bol));
1615     // Set the outer loop&#39;s exit condition too
1616     igvn-&gt;replace_input_of(outer_loop_end(), 1, outer_bol);
1617   } else {
1618     assert(false, &quot;should be able to adjust outer loop&quot;);
1619     IfNode* outer_le = outer_loop_end();
1620     Node* iff = igvn-&gt;transform(new IfNode(outer_le-&gt;in(0), outer_le-&gt;in(1), outer_le-&gt;_prob, outer_le-&gt;_fcnt));
1621     igvn-&gt;replace_node(outer_le, iff);
1622     inner_cl-&gt;clear_strip_mined();
1623   }
1624 }
1625 
1626 const Type* OuterStripMinedLoopEndNode::Value(PhaseGVN* phase) const {
1627   if (!in(0)) return Type::TOP;
1628   if (phase-&gt;type(in(0)) == Type::TOP)
1629     return Type::TOP;
1630 
1631   return TypeTuple::IFBOTH;
1632 }
1633 
1634 Node *OuterStripMinedLoopEndNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1635   if (remove_dead_region(phase, can_reshape))  return this;
1636 
1637   return NULL;
1638 }
1639 
1640 //------------------------------filtered_type--------------------------------
1641 // Return a type based on condition control flow
1642 // A successful return will be a type that is restricted due
1643 // to a series of dominating if-tests, such as:
1644 //    if (i &lt; 10) {
1645 //       if (i &gt; 0) {
1646 //          here: &quot;i&quot; type is [1..10)
1647 //       }
1648 //    }
1649 // or a control flow merge
1650 //    if (i &lt; 10) {
1651 //       do {
1652 //          phi( , ) -- at top of loop type is [min_int..10)
1653 //         i = ?
1654 //       } while ( i &lt; 10)
1655 //
1656 const TypeInt* PhaseIdealLoop::filtered_type( Node *n, Node* n_ctrl) {
1657   assert(n &amp;&amp; n-&gt;bottom_type()-&gt;is_int(), &quot;must be int&quot;);
1658   const TypeInt* filtered_t = NULL;
1659   if (!n-&gt;is_Phi()) {
1660     assert(n_ctrl != NULL || n_ctrl == C-&gt;top(), &quot;valid control&quot;);
1661     filtered_t = filtered_type_from_dominators(n, n_ctrl);
1662 
1663   } else {
1664     Node* phi    = n-&gt;as_Phi();
1665     Node* region = phi-&gt;in(0);
1666     assert(n_ctrl == NULL || n_ctrl == region, &quot;ctrl parameter must be region&quot;);
1667     if (region &amp;&amp; region != C-&gt;top()) {
1668       for (uint i = 1; i &lt; phi-&gt;req(); i++) {
1669         Node* val   = phi-&gt;in(i);
1670         Node* use_c = region-&gt;in(i);
1671         const TypeInt* val_t = filtered_type_from_dominators(val, use_c);
1672         if (val_t != NULL) {
1673           if (filtered_t == NULL) {
1674             filtered_t = val_t;
1675           } else {
1676             filtered_t = filtered_t-&gt;meet(val_t)-&gt;is_int();
1677           }
1678         }
1679       }
1680     }
1681   }
1682   const TypeInt* n_t = _igvn.type(n)-&gt;is_int();
1683   if (filtered_t != NULL) {
1684     n_t = n_t-&gt;join(filtered_t)-&gt;is_int();
1685   }
1686   return n_t;
1687 }
1688 
1689 
1690 //------------------------------filtered_type_from_dominators--------------------------------
1691 // Return a possibly more restrictive type for val based on condition control flow of dominators
1692 const TypeInt* PhaseIdealLoop::filtered_type_from_dominators( Node* val, Node *use_ctrl) {
1693   if (val-&gt;is_Con()) {
1694      return val-&gt;bottom_type()-&gt;is_int();
1695   }
1696   uint if_limit = 10; // Max number of dominating if&#39;s visited
1697   const TypeInt* rtn_t = NULL;
1698 
1699   if (use_ctrl &amp;&amp; use_ctrl != C-&gt;top()) {
1700     Node* val_ctrl = get_ctrl(val);
1701     uint val_dom_depth = dom_depth(val_ctrl);
1702     Node* pred = use_ctrl;
1703     uint if_cnt = 0;
1704     while (if_cnt &lt; if_limit) {
1705       if ((pred-&gt;Opcode() == Op_IfTrue || pred-&gt;Opcode() == Op_IfFalse)) {
1706         if_cnt++;
1707         const TypeInt* if_t = IfNode::filtered_int_type(&amp;_igvn, val, pred);
1708         if (if_t != NULL) {
1709           if (rtn_t == NULL) {
1710             rtn_t = if_t;
1711           } else {
1712             rtn_t = rtn_t-&gt;join(if_t)-&gt;is_int();
1713           }
1714         }
1715       }
1716       pred = idom(pred);
1717       if (pred == NULL || pred == C-&gt;top()) {
1718         break;
1719       }
1720       // Stop if going beyond definition block of val
1721       if (dom_depth(pred) &lt; val_dom_depth) {
1722         break;
1723       }
1724     }
1725   }
1726   return rtn_t;
1727 }
1728 
1729 
1730 //------------------------------dump_spec--------------------------------------
1731 // Dump special per-node info
1732 #ifndef PRODUCT
1733 void CountedLoopEndNode::dump_spec(outputStream *st) const {
1734   if( in(TestValue) != NULL &amp;&amp; in(TestValue)-&gt;is_Bool() ) {
1735     BoolTest bt( test_trip()); // Added this for g++.
1736 
1737     st-&gt;print(&quot;[&quot;);
1738     bt.dump_on(st);
1739     st-&gt;print(&quot;]&quot;);
1740   }
1741   st-&gt;print(&quot; &quot;);
1742   IfNode::dump_spec(st);
1743 }
1744 #endif
1745 
1746 //=============================================================================
1747 //------------------------------is_member--------------------------------------
1748 // Is &#39;l&#39; a member of &#39;this&#39;?
1749 bool IdealLoopTree::is_member(const IdealLoopTree *l) const {
1750   while( l-&gt;_nest &gt; _nest ) l = l-&gt;_parent;
1751   return l == this;
1752 }
1753 
1754 //------------------------------set_nest---------------------------------------
1755 // Set loop tree nesting depth.  Accumulate _has_call bits.
1756 int IdealLoopTree::set_nest( uint depth ) {
1757   _nest = depth;
1758   int bits = _has_call;
1759   if( _child ) bits |= _child-&gt;set_nest(depth+1);
1760   if( bits ) _has_call = 1;
1761   if( _next  ) bits |= _next -&gt;set_nest(depth  );
1762   return bits;
1763 }
1764 
1765 //------------------------------split_fall_in----------------------------------
1766 // Split out multiple fall-in edges from the loop header.  Move them to a
1767 // private RegionNode before the loop.  This becomes the loop landing pad.
1768 void IdealLoopTree::split_fall_in( PhaseIdealLoop *phase, int fall_in_cnt ) {
1769   PhaseIterGVN &amp;igvn = phase-&gt;_igvn;
1770   uint i;
1771 
1772   // Make a new RegionNode to be the landing pad.
1773   Node *landing_pad = new RegionNode( fall_in_cnt+1 );
1774   phase-&gt;set_loop(landing_pad,_parent);
1775   // Gather all the fall-in control paths into the landing pad
1776   uint icnt = fall_in_cnt;
1777   uint oreq = _head-&gt;req();
1778   for( i = oreq-1; i&gt;0; i-- )
1779     if( !phase-&gt;is_member( this, _head-&gt;in(i) ) )
1780       landing_pad-&gt;set_req(icnt--,_head-&gt;in(i));
1781 
1782   // Peel off PhiNode edges as well
1783   for (DUIterator_Fast jmax, j = _head-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1784     Node *oj = _head-&gt;fast_out(j);
1785     if( oj-&gt;is_Phi() ) {
1786       PhiNode* old_phi = oj-&gt;as_Phi();
1787       assert( old_phi-&gt;region() == _head, &quot;&quot; );
1788       igvn.hash_delete(old_phi);   // Yank from hash before hacking edges
1789       Node *p = PhiNode::make_blank(landing_pad, old_phi);
1790       uint icnt = fall_in_cnt;
1791       for( i = oreq-1; i&gt;0; i-- ) {
1792         if( !phase-&gt;is_member( this, _head-&gt;in(i) ) ) {
1793           p-&gt;init_req(icnt--, old_phi-&gt;in(i));
1794           // Go ahead and clean out old edges from old phi
1795           old_phi-&gt;del_req(i);
1796         }
1797       }
1798       // Search for CSE&#39;s here, because ZKM.jar does a lot of
1799       // loop hackery and we need to be a little incremental
1800       // with the CSE to avoid O(N^2) node blow-up.
1801       Node *p2 = igvn.hash_find_insert(p); // Look for a CSE
1802       if( p2 ) {                // Found CSE
1803         p-&gt;destruct();          // Recover useless new node
1804         p = p2;                 // Use old node
1805       } else {
1806         igvn.register_new_node_with_optimizer(p, old_phi);
1807       }
1808       // Make old Phi refer to new Phi.
1809       old_phi-&gt;add_req(p);
1810       // Check for the special case of making the old phi useless and
1811       // disappear it.  In JavaGrande I have a case where this useless
1812       // Phi is the loop limit and prevents recognizing a CountedLoop
1813       // which in turn prevents removing an empty loop.
1814       Node *id_old_phi = old_phi-&gt;Identity(&amp;igvn);
1815       if( id_old_phi != old_phi ) { // Found a simple identity?
1816         // Note that I cannot call &#39;replace_node&#39; here, because
1817         // that will yank the edge from old_phi to the Region and
1818         // I&#39;m mid-iteration over the Region&#39;s uses.
1819         for (DUIterator_Last imin, i = old_phi-&gt;last_outs(imin); i &gt;= imin; ) {
1820           Node* use = old_phi-&gt;last_out(i);
1821           igvn.rehash_node_delayed(use);
1822           uint uses_found = 0;
1823           for (uint j = 0; j &lt; use-&gt;len(); j++) {
1824             if (use-&gt;in(j) == old_phi) {
1825               if (j &lt; use-&gt;req()) use-&gt;set_req (j, id_old_phi);
1826               else                use-&gt;set_prec(j, id_old_phi);
1827               uses_found++;
1828             }
1829           }
1830           i -= uses_found;    // we deleted 1 or more copies of this edge
1831         }
1832       }
1833       igvn._worklist.push(old_phi);
1834     }
1835   }
1836   // Finally clean out the fall-in edges from the RegionNode
1837   for( i = oreq-1; i&gt;0; i-- ) {
1838     if( !phase-&gt;is_member( this, _head-&gt;in(i) ) ) {
1839       _head-&gt;del_req(i);
1840     }
1841   }
1842   igvn.rehash_node_delayed(_head);
1843   // Transform landing pad
1844   igvn.register_new_node_with_optimizer(landing_pad, _head);
1845   // Insert landing pad into the header
1846   _head-&gt;add_req(landing_pad);
1847 }
1848 
1849 //------------------------------split_outer_loop-------------------------------
1850 // Split out the outermost loop from this shared header.
1851 void IdealLoopTree::split_outer_loop( PhaseIdealLoop *phase ) {
1852   PhaseIterGVN &amp;igvn = phase-&gt;_igvn;
1853 
1854   // Find index of outermost loop; it should also be my tail.
1855   uint outer_idx = 1;
1856   while( _head-&gt;in(outer_idx) != _tail ) outer_idx++;
1857 
1858   // Make a LoopNode for the outermost loop.
1859   Node *ctl = _head-&gt;in(LoopNode::EntryControl);
1860   Node *outer = new LoopNode( ctl, _head-&gt;in(outer_idx) );
1861   outer = igvn.register_new_node_with_optimizer(outer, _head);
1862   phase-&gt;set_created_loop_node();
1863 
1864   // Outermost loop falls into &#39;_head&#39; loop
1865   _head-&gt;set_req(LoopNode::EntryControl, outer);
1866   _head-&gt;del_req(outer_idx);
1867   // Split all the Phis up between &#39;_head&#39; loop and &#39;outer&#39; loop.
1868   for (DUIterator_Fast jmax, j = _head-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1869     Node *out = _head-&gt;fast_out(j);
1870     if( out-&gt;is_Phi() ) {
1871       PhiNode *old_phi = out-&gt;as_Phi();
1872       assert( old_phi-&gt;region() == _head, &quot;&quot; );
1873       Node *phi = PhiNode::make_blank(outer, old_phi);
1874       phi-&gt;init_req(LoopNode::EntryControl,    old_phi-&gt;in(LoopNode::EntryControl));
1875       phi-&gt;init_req(LoopNode::LoopBackControl, old_phi-&gt;in(outer_idx));
1876       phi = igvn.register_new_node_with_optimizer(phi, old_phi);
1877       // Make old Phi point to new Phi on the fall-in path
1878       igvn.replace_input_of(old_phi, LoopNode::EntryControl, phi);
1879       old_phi-&gt;del_req(outer_idx);
1880     }
1881   }
1882 
1883   // Use the new loop head instead of the old shared one
1884   _head = outer;
1885   phase-&gt;set_loop(_head, this);
1886 }
1887 
1888 //------------------------------fix_parent-------------------------------------
1889 static void fix_parent( IdealLoopTree *loop, IdealLoopTree *parent ) {
1890   loop-&gt;_parent = parent;
1891   if( loop-&gt;_child ) fix_parent( loop-&gt;_child, loop   );
1892   if( loop-&gt;_next  ) fix_parent( loop-&gt;_next , parent );
1893 }
1894 
1895 //------------------------------estimate_path_freq-----------------------------
1896 static float estimate_path_freq( Node *n ) {
1897   // Try to extract some path frequency info
1898   IfNode *iff;
1899   for( int i = 0; i &lt; 50; i++ ) { // Skip through a bunch of uncommon tests
1900     uint nop = n-&gt;Opcode();
1901     if( nop == Op_SafePoint ) {   // Skip any safepoint
1902       n = n-&gt;in(0);
1903       continue;
1904     }
1905     if( nop == Op_CatchProj ) {   // Get count from a prior call
1906       // Assume call does not always throw exceptions: means the call-site
1907       // count is also the frequency of the fall-through path.
1908       assert( n-&gt;is_CatchProj(), &quot;&quot; );
1909       if( ((CatchProjNode*)n)-&gt;_con != CatchProjNode::fall_through_index )
1910         return 0.0f;            // Assume call exception path is rare
1911       Node *call = n-&gt;in(0)-&gt;in(0)-&gt;in(0);
1912       assert( call-&gt;is_Call(), &quot;expect a call here&quot; );
1913       const JVMState *jvms = ((CallNode*)call)-&gt;jvms();
1914       ciMethodData* methodData = jvms-&gt;method()-&gt;method_data();
1915       if (!methodData-&gt;is_mature())  return 0.0f; // No call-site data
1916       ciProfileData* data = methodData-&gt;bci_to_data(jvms-&gt;bci());
1917       if ((data == NULL) || !data-&gt;is_CounterData()) {
1918         // no call profile available, try call&#39;s control input
1919         n = n-&gt;in(0);
1920         continue;
1921       }
1922       return data-&gt;as_CounterData()-&gt;count()/FreqCountInvocations;
1923     }
1924     // See if there&#39;s a gating IF test
1925     Node *n_c = n-&gt;in(0);
1926     if( !n_c-&gt;is_If() ) break;       // No estimate available
1927     iff = n_c-&gt;as_If();
1928     if( iff-&gt;_fcnt != COUNT_UNKNOWN )   // Have a valid count?
1929       // Compute how much count comes on this path
1930       return ((nop == Op_IfTrue) ? iff-&gt;_prob : 1.0f - iff-&gt;_prob) * iff-&gt;_fcnt;
1931     // Have no count info.  Skip dull uncommon-trap like branches.
1932     if( (nop == Op_IfTrue  &amp;&amp; iff-&gt;_prob &lt; PROB_LIKELY_MAG(5)) ||
1933         (nop == Op_IfFalse &amp;&amp; iff-&gt;_prob &gt; PROB_UNLIKELY_MAG(5)) )
1934       break;
1935     // Skip through never-taken branch; look for a real loop exit.
1936     n = iff-&gt;in(0);
1937   }
1938   return 0.0f;                  // No estimate available
1939 }
1940 
1941 //------------------------------merge_many_backedges---------------------------
1942 // Merge all the backedges from the shared header into a private Region.
1943 // Feed that region as the one backedge to this loop.
1944 void IdealLoopTree::merge_many_backedges( PhaseIdealLoop *phase ) {
1945   uint i;
1946 
1947   // Scan for the top 2 hottest backedges
1948   float hotcnt = 0.0f;
1949   float warmcnt = 0.0f;
1950   uint hot_idx = 0;
1951   // Loop starts at 2 because slot 1 is the fall-in path
1952   for( i = 2; i &lt; _head-&gt;req(); i++ ) {
1953     float cnt = estimate_path_freq(_head-&gt;in(i));
1954     if( cnt &gt; hotcnt ) {       // Grab hottest path
1955       warmcnt = hotcnt;
1956       hotcnt = cnt;
1957       hot_idx = i;
1958     } else if( cnt &gt; warmcnt ) { // And 2nd hottest path
1959       warmcnt = cnt;
1960     }
1961   }
1962 
1963   // See if the hottest backedge is worthy of being an inner loop
1964   // by being much hotter than the next hottest backedge.
1965   if( hotcnt &lt;= 0.0001 ||
1966       hotcnt &lt; 2.0*warmcnt ) hot_idx = 0;// No hot backedge
1967 
1968   // Peel out the backedges into a private merge point; peel
1969   // them all except optionally hot_idx.
1970   PhaseIterGVN &amp;igvn = phase-&gt;_igvn;
1971 
1972   Node *hot_tail = NULL;
1973   // Make a Region for the merge point
1974   Node *r = new RegionNode(1);
1975   for( i = 2; i &lt; _head-&gt;req(); i++ ) {
1976     if( i != hot_idx )
1977       r-&gt;add_req( _head-&gt;in(i) );
1978     else hot_tail = _head-&gt;in(i);
1979   }
1980   igvn.register_new_node_with_optimizer(r, _head);
1981   // Plug region into end of loop _head, followed by hot_tail
1982   while( _head-&gt;req() &gt; 3 ) _head-&gt;del_req( _head-&gt;req()-1 );
1983   igvn.replace_input_of(_head, 2, r);
1984   if( hot_idx ) _head-&gt;add_req(hot_tail);
1985 
1986   // Split all the Phis up between &#39;_head&#39; loop and the Region &#39;r&#39;
1987   for (DUIterator_Fast jmax, j = _head-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1988     Node *out = _head-&gt;fast_out(j);
1989     if( out-&gt;is_Phi() ) {
1990       PhiNode* n = out-&gt;as_Phi();
1991       igvn.hash_delete(n);      // Delete from hash before hacking edges
1992       Node *hot_phi = NULL;
1993       Node *phi = new PhiNode(r, n-&gt;type(), n-&gt;adr_type());
1994       // Check all inputs for the ones to peel out
1995       uint j = 1;
1996       for( uint i = 2; i &lt; n-&gt;req(); i++ ) {
1997         if( i != hot_idx )
1998           phi-&gt;set_req( j++, n-&gt;in(i) );
1999         else hot_phi = n-&gt;in(i);
2000       }
2001       // Register the phi but do not transform until whole place transforms
2002       igvn.register_new_node_with_optimizer(phi, n);
2003       // Add the merge phi to the old Phi
2004       while( n-&gt;req() &gt; 3 ) n-&gt;del_req( n-&gt;req()-1 );
2005       igvn.replace_input_of(n, 2, phi);
2006       if( hot_idx ) n-&gt;add_req(hot_phi);
2007     }
2008   }
2009 
2010 
2011   // Insert a new IdealLoopTree inserted below me.  Turn it into a clone
2012   // of self loop tree.  Turn self into a loop headed by _head and with
2013   // tail being the new merge point.
2014   IdealLoopTree *ilt = new IdealLoopTree( phase, _head, _tail );
2015   phase-&gt;set_loop(_tail,ilt);   // Adjust tail
2016   _tail = r;                    // Self&#39;s tail is new merge point
2017   phase-&gt;set_loop(r,this);
2018   ilt-&gt;_child = _child;         // New guy has my children
2019   _child = ilt;                 // Self has new guy as only child
2020   ilt-&gt;_parent = this;          // new guy has self for parent
2021   ilt-&gt;_nest = _nest;           // Same nesting depth (for now)
2022 
2023   // Starting with &#39;ilt&#39;, look for child loop trees using the same shared
2024   // header.  Flatten these out; they will no longer be loops in the end.
2025   IdealLoopTree **pilt = &amp;_child;
2026   while( ilt ) {
2027     if( ilt-&gt;_head == _head ) {
2028       uint i;
2029       for( i = 2; i &lt; _head-&gt;req(); i++ )
2030         if( _head-&gt;in(i) == ilt-&gt;_tail )
2031           break;                // Still a loop
2032       if( i == _head-&gt;req() ) { // No longer a loop
2033         // Flatten ilt.  Hang ilt&#39;s &quot;_next&quot; list from the end of
2034         // ilt&#39;s &#39;_child&#39; list.  Move the ilt&#39;s _child up to replace ilt.
2035         IdealLoopTree **cp = &amp;ilt-&gt;_child;
2036         while( *cp ) cp = &amp;(*cp)-&gt;_next;   // Find end of child list
2037         *cp = ilt-&gt;_next;       // Hang next list at end of child list
2038         *pilt = ilt-&gt;_child;    // Move child up to replace ilt
2039         ilt-&gt;_head = NULL;      // Flag as a loop UNIONED into parent
2040         ilt = ilt-&gt;_child;      // Repeat using new ilt
2041         continue;               // do not advance over ilt-&gt;_child
2042       }
2043       assert( ilt-&gt;_tail == hot_tail, &quot;expected to only find the hot inner loop here&quot; );
2044       phase-&gt;set_loop(_head,ilt);
2045     }
2046     pilt = &amp;ilt-&gt;_child;        // Advance to next
2047     ilt = *pilt;
2048   }
2049 
2050   if( _child ) fix_parent( _child, this );
2051 }
2052 
2053 //------------------------------beautify_loops---------------------------------
2054 // Split shared headers and insert loop landing pads.
2055 // Insert a LoopNode to replace the RegionNode.
2056 // Return TRUE if loop tree is structurally changed.
2057 bool IdealLoopTree::beautify_loops( PhaseIdealLoop *phase ) {
2058   bool result = false;
2059   // Cache parts in locals for easy
2060   PhaseIterGVN &amp;igvn = phase-&gt;_igvn;
2061 
2062   igvn.hash_delete(_head);      // Yank from hash before hacking edges
2063 
2064   // Check for multiple fall-in paths.  Peel off a landing pad if need be.
2065   int fall_in_cnt = 0;
2066   for( uint i = 1; i &lt; _head-&gt;req(); i++ )
2067     if( !phase-&gt;is_member( this, _head-&gt;in(i) ) )
2068       fall_in_cnt++;
2069   assert( fall_in_cnt, &quot;at least 1 fall-in path&quot; );
2070   if( fall_in_cnt &gt; 1 )         // Need a loop landing pad to merge fall-ins
2071     split_fall_in( phase, fall_in_cnt );
2072 
2073   // Swap inputs to the _head and all Phis to move the fall-in edge to
2074   // the left.
2075   fall_in_cnt = 1;
2076   while( phase-&gt;is_member( this, _head-&gt;in(fall_in_cnt) ) )
2077     fall_in_cnt++;
2078   if( fall_in_cnt &gt; 1 ) {
2079     // Since I am just swapping inputs I do not need to update def-use info
2080     Node *tmp = _head-&gt;in(1);
2081     igvn.rehash_node_delayed(_head);
2082     _head-&gt;set_req( 1, _head-&gt;in(fall_in_cnt) );
2083     _head-&gt;set_req( fall_in_cnt, tmp );
2084     // Swap also all Phis
2085     for (DUIterator_Fast imax, i = _head-&gt;fast_outs(imax); i &lt; imax; i++) {
2086       Node* phi = _head-&gt;fast_out(i);
2087       if( phi-&gt;is_Phi() ) {
2088         igvn.rehash_node_delayed(phi); // Yank from hash before hacking edges
2089         tmp = phi-&gt;in(1);
2090         phi-&gt;set_req( 1, phi-&gt;in(fall_in_cnt) );
2091         phi-&gt;set_req( fall_in_cnt, tmp );
2092       }
2093     }
2094   }
2095   assert( !phase-&gt;is_member( this, _head-&gt;in(1) ), &quot;left edge is fall-in&quot; );
2096   assert(  phase-&gt;is_member( this, _head-&gt;in(2) ), &quot;right edge is loop&quot; );
2097 
2098   // If I am a shared header (multiple backedges), peel off the many
2099   // backedges into a private merge point and use the merge point as
2100   // the one true backedge.
2101   if (_head-&gt;req() &gt; 3 &amp;&amp; !_irreducible) {
2102     // Merge the many backedges into a single backedge but leave
2103     // the hottest backedge as separate edge for the following peel.
2104     merge_many_backedges( phase );
2105     result = true;
2106   }
2107 
2108   // If I have one hot backedge, peel off myself loop.
2109   // I better be the outermost loop.
2110   if (_head-&gt;req() &gt; 3 &amp;&amp; !_irreducible) {
2111     split_outer_loop( phase );
2112     result = true;
2113 
2114   } else if (!_head-&gt;is_Loop() &amp;&amp; !_irreducible) {
2115     // Make a new LoopNode to replace the old loop head
2116     Node *l = new LoopNode( _head-&gt;in(1), _head-&gt;in(2) );
2117     l = igvn.register_new_node_with_optimizer(l, _head);
2118     phase-&gt;set_created_loop_node();
2119     // Go ahead and replace _head
2120     phase-&gt;_igvn.replace_node( _head, l );
2121     _head = l;
2122     phase-&gt;set_loop(_head, this);
2123   }
2124 
2125   // Now recursively beautify nested loops
2126   if( _child ) result |= _child-&gt;beautify_loops( phase );
2127   if( _next  ) result |= _next -&gt;beautify_loops( phase );
2128   return result;
2129 }
2130 
2131 //------------------------------allpaths_check_safepts----------------------------
2132 // Allpaths backwards scan from loop tail, terminating each path at first safepoint
2133 // encountered.  Helper for check_safepts.
2134 void IdealLoopTree::allpaths_check_safepts(VectorSet &amp;visited, Node_List &amp;stack) {
2135   assert(stack.size() == 0, &quot;empty stack&quot;);
2136   stack.push(_tail);
2137   visited.clear();
2138   visited.set(_tail-&gt;_idx);
2139   while (stack.size() &gt; 0) {
2140     Node* n = stack.pop();
2141     if (n-&gt;is_Call() &amp;&amp; n-&gt;as_Call()-&gt;guaranteed_safepoint()) {
2142       // Terminate this path
2143     } else if (n-&gt;Opcode() == Op_SafePoint) {
2144       if (_phase-&gt;get_loop(n) != this) {
2145         if (_required_safept == NULL) _required_safept = new Node_List();
2146         _required_safept-&gt;push(n);  // save the one closest to the tail
2147       }
2148       // Terminate this path
2149     } else {
2150       uint start = n-&gt;is_Region() ? 1 : 0;
2151       uint end   = n-&gt;is_Region() &amp;&amp; !n-&gt;is_Loop() ? n-&gt;req() : start + 1;
2152       for (uint i = start; i &lt; end; i++) {
2153         Node* in = n-&gt;in(i);
2154         assert(in-&gt;is_CFG(), &quot;must be&quot;);
2155         if (!visited.test_set(in-&gt;_idx) &amp;&amp; is_member(_phase-&gt;get_loop(in))) {
2156           stack.push(in);
2157         }
2158       }
2159     }
2160   }
2161 }
2162 
2163 //------------------------------check_safepts----------------------------
2164 // Given dominators, try to find loops with calls that must always be
2165 // executed (call dominates loop tail).  These loops do not need non-call
2166 // safepoints (ncsfpt).
2167 //
2168 // A complication is that a safepoint in a inner loop may be needed
2169 // by an outer loop. In the following, the inner loop sees it has a
2170 // call (block 3) on every path from the head (block 2) to the
2171 // backedge (arc 3-&gt;2).  So it deletes the ncsfpt (non-call safepoint)
2172 // in block 2, _but_ this leaves the outer loop without a safepoint.
2173 //
2174 //          entry  0
2175 //                 |
2176 //                 v
2177 // outer 1,2    +-&gt;1
2178 //              |  |
2179 //              |  v
2180 //              |  2&lt;---+  ncsfpt in 2
2181 //              |_/|\   |
2182 //                 | v  |
2183 // inner 2,3      /  3  |  call in 3
2184 //               /   |  |
2185 //              v    +--+
2186 //        exit  4
2187 //
2188 //
2189 // This method creates a list (_required_safept) of ncsfpt nodes that must
2190 // be protected is created for each loop. When a ncsfpt maybe deleted, it
2191 // is first looked for in the lists for the outer loops of the current loop.
2192 //
2193 // The insights into the problem:
2194 //  A) counted loops are okay
2195 //  B) innermost loops are okay (only an inner loop can delete
2196 //     a ncsfpt needed by an outer loop)
2197 //  C) a loop is immune from an inner loop deleting a safepoint
2198 //     if the loop has a call on the idom-path
2199 //  D) a loop is also immune if it has a ncsfpt (non-call safepoint) on the
2200 //     idom-path that is not in a nested loop
2201 //  E) otherwise, an ncsfpt on the idom-path that is nested in an inner
2202 //     loop needs to be prevented from deletion by an inner loop
2203 //
2204 // There are two analyses:
2205 //  1) The first, and cheaper one, scans the loop body from
2206 //     tail to head following the idom (immediate dominator)
2207 //     chain, looking for the cases (C,D,E) above.
2208 //     Since inner loops are scanned before outer loops, there is summary
2209 //     information about inner loops.  Inner loops can be skipped over
2210 //     when the tail of an inner loop is encountered.
2211 //
2212 //  2) The second, invoked if the first fails to find a call or ncsfpt on
2213 //     the idom path (which is rare), scans all predecessor control paths
2214 //     from the tail to the head, terminating a path when a call or sfpt
2215 //     is encountered, to find the ncsfpt&#39;s that are closest to the tail.
2216 //
2217 void IdealLoopTree::check_safepts(VectorSet &amp;visited, Node_List &amp;stack) {
2218   // Bottom up traversal
2219   IdealLoopTree* ch = _child;
2220   if (_child) _child-&gt;check_safepts(visited, stack);
2221   if (_next)  _next -&gt;check_safepts(visited, stack);
2222 
2223   if (!_head-&gt;is_CountedLoop() &amp;&amp; !_has_sfpt &amp;&amp; _parent != NULL &amp;&amp; !_irreducible) {
2224     bool  has_call         = false; // call on dom-path
2225     bool  has_local_ncsfpt = false; // ncsfpt on dom-path at this loop depth
2226     Node* nonlocal_ncsfpt  = NULL;  // ncsfpt on dom-path at a deeper depth
2227     // Scan the dom-path nodes from tail to head
2228     for (Node* n = tail(); n != _head; n = _phase-&gt;idom(n)) {
2229       if (n-&gt;is_Call() &amp;&amp; n-&gt;as_Call()-&gt;guaranteed_safepoint()) {
2230         has_call = true;
2231         _has_sfpt = 1;          // Then no need for a safept!
2232         break;
2233       } else if (n-&gt;Opcode() == Op_SafePoint) {
2234         if (_phase-&gt;get_loop(n) == this) {
2235           has_local_ncsfpt = true;
2236           break;
2237         }
2238         if (nonlocal_ncsfpt == NULL) {
2239           nonlocal_ncsfpt = n; // save the one closest to the tail
2240         }
2241       } else {
2242         IdealLoopTree* nlpt = _phase-&gt;get_loop(n);
2243         if (this != nlpt) {
2244           // If at an inner loop tail, see if the inner loop has already
2245           // recorded seeing a call on the dom-path (and stop.)  If not,
2246           // jump to the head of the inner loop.
2247           assert(is_member(nlpt), &quot;nested loop&quot;);
2248           Node* tail = nlpt-&gt;_tail;
2249           if (tail-&gt;in(0)-&gt;is_If()) tail = tail-&gt;in(0);
2250           if (n == tail) {
2251             // If inner loop has call on dom-path, so does outer loop
2252             if (nlpt-&gt;_has_sfpt) {
2253               has_call = true;
2254               _has_sfpt = 1;
2255               break;
2256             }
2257             // Skip to head of inner loop
2258             assert(_phase-&gt;is_dominator(_head, nlpt-&gt;_head), &quot;inner head dominated by outer head&quot;);
2259             n = nlpt-&gt;_head;
2260           }
2261         }
2262       }
2263     }
2264     // Record safept&#39;s that this loop needs preserved when an
2265     // inner loop attempts to delete it&#39;s safepoints.
2266     if (_child != NULL &amp;&amp; !has_call &amp;&amp; !has_local_ncsfpt) {
2267       if (nonlocal_ncsfpt != NULL) {
2268         if (_required_safept == NULL) _required_safept = new Node_List();
2269         _required_safept-&gt;push(nonlocal_ncsfpt);
2270       } else {
2271         // Failed to find a suitable safept on the dom-path.  Now use
2272         // an all paths walk from tail to head, looking for safepoints to preserve.
2273         allpaths_check_safepts(visited, stack);
2274       }
2275     }
2276   }
2277 }
2278 
2279 //---------------------------is_deleteable_safept----------------------------
2280 // Is safept not required by an outer loop?
2281 bool PhaseIdealLoop::is_deleteable_safept(Node* sfpt) {
2282   assert(sfpt-&gt;Opcode() == Op_SafePoint, &quot;&quot;);
2283   IdealLoopTree* lp = get_loop(sfpt)-&gt;_parent;
2284   while (lp != NULL) {
2285     Node_List* sfpts = lp-&gt;_required_safept;
2286     if (sfpts != NULL) {
2287       for (uint i = 0; i &lt; sfpts-&gt;size(); i++) {
2288         if (sfpt == sfpts-&gt;at(i))
2289           return false;
2290       }
2291     }
2292     lp = lp-&gt;_parent;
2293   }
2294   return true;
2295 }
2296 
2297 //---------------------------replace_parallel_iv-------------------------------
2298 // Replace parallel induction variable (parallel to trip counter)
2299 void PhaseIdealLoop::replace_parallel_iv(IdealLoopTree *loop) {
2300   assert(loop-&gt;_head-&gt;is_CountedLoop(), &quot;&quot;);
2301   CountedLoopNode *cl = loop-&gt;_head-&gt;as_CountedLoop();
2302   if (!cl-&gt;is_valid_counted_loop())
2303     return;         // skip malformed counted loop
2304   Node *incr = cl-&gt;incr();
2305   if (incr == NULL)
2306     return;         // Dead loop?
2307   Node *init = cl-&gt;init_trip();
2308   Node *phi  = cl-&gt;phi();
2309   int stride_con = cl-&gt;stride_con();
2310 
2311   // Visit all children, looking for Phis
2312   for (DUIterator i = cl-&gt;outs(); cl-&gt;has_out(i); i++) {
2313     Node *out = cl-&gt;out(i);
2314     // Look for other phis (secondary IVs). Skip dead ones
2315     if (!out-&gt;is_Phi() || out == phi || !has_node(out))
2316       continue;
2317     PhiNode* phi2 = out-&gt;as_Phi();
2318     Node *incr2 = phi2-&gt;in( LoopNode::LoopBackControl );
2319     // Look for induction variables of the form:  X += constant
2320     if (phi2-&gt;region() != loop-&gt;_head ||
2321         incr2-&gt;req() != 3 ||
2322         incr2-&gt;in(1) != phi2 ||
2323         incr2 == incr ||
2324         incr2-&gt;Opcode() != Op_AddI ||
2325         !incr2-&gt;in(2)-&gt;is_Con())
2326       continue;
2327 
2328     // Check for parallel induction variable (parallel to trip counter)
2329     // via an affine function.  In particular, count-down loops with
2330     // count-up array indices are common. We only RCE references off
2331     // the trip-counter, so we need to convert all these to trip-counter
2332     // expressions.
2333     Node *init2 = phi2-&gt;in( LoopNode::EntryControl );
2334     int stride_con2 = incr2-&gt;in(2)-&gt;get_int();
2335 
2336     // The ratio of the two strides cannot be represented as an int
2337     // if stride_con2 is min_int and stride_con is -1.
2338     if (stride_con2 == min_jint &amp;&amp; stride_con == -1) {
2339       continue;
2340     }
2341 
2342     // The general case here gets a little tricky.  We want to find the
2343     // GCD of all possible parallel IV&#39;s and make a new IV using this
2344     // GCD for the loop.  Then all possible IVs are simple multiples of
2345     // the GCD.  In practice, this will cover very few extra loops.
2346     // Instead we require &#39;stride_con2&#39; to be a multiple of &#39;stride_con&#39;,
2347     // where +/-1 is the common case, but other integer multiples are
2348     // also easy to handle.
2349     int ratio_con = stride_con2/stride_con;
2350 
2351     if ((ratio_con * stride_con) == stride_con2) { // Check for exact
2352 #ifndef PRODUCT
2353       if (TraceLoopOpts) {
2354         tty-&gt;print(&quot;Parallel IV: %d &quot;, phi2-&gt;_idx);
2355         loop-&gt;dump_head();
2356       }
2357 #endif
2358       // Convert to using the trip counter.  The parallel induction
2359       // variable differs from the trip counter by a loop-invariant
2360       // amount, the difference between their respective initial values.
2361       // It is scaled by the &#39;ratio_con&#39;.
2362       Node* ratio = _igvn.intcon(ratio_con);
2363       set_ctrl(ratio, C-&gt;root());
2364       Node* ratio_init = new MulINode(init, ratio);
2365       _igvn.register_new_node_with_optimizer(ratio_init, init);
2366       set_early_ctrl(ratio_init);
2367       Node* diff = new SubINode(init2, ratio_init);
2368       _igvn.register_new_node_with_optimizer(diff, init2);
2369       set_early_ctrl(diff);
2370       Node* ratio_idx = new MulINode(phi, ratio);
2371       _igvn.register_new_node_with_optimizer(ratio_idx, phi);
2372       set_ctrl(ratio_idx, cl);
2373       Node* add = new AddINode(ratio_idx, diff);
2374       _igvn.register_new_node_with_optimizer(add);
2375       set_ctrl(add, cl);
2376       _igvn.replace_node( phi2, add );
2377       // Sometimes an induction variable is unused
2378       if (add-&gt;outcnt() == 0) {
2379         _igvn.remove_dead_node(add);
2380       }
2381       --i; // deleted this phi; rescan starting with next position
2382       continue;
2383     }
2384   }
2385 }
2386 
2387 void IdealLoopTree::remove_safepoints(PhaseIdealLoop* phase, bool keep_one) {
2388   Node* keep = NULL;
2389   if (keep_one) {
2390     // Look for a safepoint on the idom-path.
2391     for (Node* i = tail(); i != _head; i = phase-&gt;idom(i)) {
2392       if (i-&gt;Opcode() == Op_SafePoint &amp;&amp; phase-&gt;get_loop(i) == this) {
2393         keep = i;
2394         break; // Found one
2395       }
2396     }
2397   }
2398 
2399   // Don&#39;t remove any safepoints if it is requested to keep a single safepoint and
2400   // no safepoint was found on idom-path. It is not safe to remove any safepoint
2401   // in this case since there&#39;s no safepoint dominating all paths in the loop body.
2402   bool prune = !keep_one || keep != NULL;
2403 
2404   // Delete other safepoints in this loop.
2405   Node_List* sfpts = _safepts;
2406   if (prune &amp;&amp; sfpts != NULL) {
2407     assert(keep == NULL || keep-&gt;Opcode() == Op_SafePoint, &quot;not safepoint&quot;);
2408     for (uint i = 0; i &lt; sfpts-&gt;size(); i++) {
2409       Node* n = sfpts-&gt;at(i);
2410       assert(phase-&gt;get_loop(n) == this, &quot;&quot;);
2411       if (n != keep &amp;&amp; phase-&gt;is_deleteable_safept(n)) {
2412         phase-&gt;lazy_replace(n, n-&gt;in(TypeFunc::Control));
2413       }
2414     }
2415   }
2416 }
2417 
2418 //------------------------------counted_loop-----------------------------------
2419 // Convert to counted loops where possible
2420 void IdealLoopTree::counted_loop( PhaseIdealLoop *phase ) {
2421 
2422   // For grins, set the inner-loop flag here
2423   if (!_child) {
2424     if (_head-&gt;is_Loop()) _head-&gt;as_Loop()-&gt;set_inner_loop();
2425   }
2426 
2427   IdealLoopTree* loop = this;
2428   if (_head-&gt;is_CountedLoop() ||
2429       phase-&gt;is_counted_loop(_head, loop)) {
2430 
2431     if (LoopStripMiningIter == 0 || (LoopStripMiningIter &gt; 1 &amp;&amp; _child == NULL)) {
2432       // Indicate we do not need a safepoint here
2433       _has_sfpt = 1;
2434     }
2435 
2436     // Remove safepoints
2437     bool keep_one_sfpt = !(_has_call || _has_sfpt);
2438     remove_safepoints(phase, keep_one_sfpt);
2439 
2440     // Look for induction variables
2441     phase-&gt;replace_parallel_iv(this);
2442 
2443   } else if (_parent != NULL &amp;&amp; !_irreducible) {
2444     // Not a counted loop. Keep one safepoint.
2445     bool keep_one_sfpt = true;
2446     remove_safepoints(phase, keep_one_sfpt);
2447   }
2448 
2449   // Recursively
2450   assert(loop-&gt;_child != this || (loop-&gt;_head-&gt;as_Loop()-&gt;is_OuterStripMinedLoop() &amp;&amp; _head-&gt;as_CountedLoop()-&gt;is_strip_mined()), &quot;what kind of loop was added?&quot;);
2451   assert(loop-&gt;_child != this || (loop-&gt;_child-&gt;_child == NULL &amp;&amp; loop-&gt;_child-&gt;_next == NULL), &quot;would miss some loops&quot;);
2452   if (loop-&gt;_child &amp;&amp; loop-&gt;_child != this) loop-&gt;_child-&gt;counted_loop(phase);
2453   if (loop-&gt;_next)  loop-&gt;_next -&gt;counted_loop(phase);
2454 }
2455 
2456 
2457 // The Estimated Loop Clone Size:
2458 //   CloneFactor * (~112% * BodySize + BC) + CC + FanOutTerm,
2459 // where  BC and  CC are  totally ad-hoc/magic  &quot;body&quot; and &quot;clone&quot; constants,
2460 // respectively, used to ensure that the node usage estimates made are on the
2461 // safe side, for the most part. The FanOutTerm is an attempt to estimate the
2462 // possible additional/excessive nodes generated due to data and control flow
2463 // merging, for edges reaching outside the loop.
2464 uint IdealLoopTree::est_loop_clone_sz(uint factor) const {
2465 
2466   precond(0 &lt; factor &amp;&amp; factor &lt; 16);
2467 
2468   uint const bc = 13;
2469   uint const cc = 17;
2470   uint const sz = _body.size() + (_body.size() + 7) / 8;
2471   uint estimate = factor * (sz + bc) + cc;
2472 
2473   assert((estimate - cc) / factor == sz + bc, &quot;overflow&quot;);
2474 
2475   return estimate + est_loop_flow_merge_sz();
2476 }
2477 
2478 // The Estimated Loop (full-) Unroll Size:
2479 //   UnrollFactor * (~106% * BodySize) + CC + FanOutTerm,
2480 // where CC is a (totally) ad-hoc/magic &quot;clone&quot; constant, used to ensure that
2481 // node usage estimates made are on the safe side, for the most part. This is
2482 // a &quot;light&quot; version of the loop clone size calculation (above), based on the
2483 // assumption that most of the loop-construct overhead will be unraveled when
2484 // (fully) unrolled. Defined for unroll factors larger or equal to one (&gt;=1),
2485 // including an overflow check and returning UINT_MAX in case of an overflow.
2486 uint IdealLoopTree::est_loop_unroll_sz(uint factor) const {
2487 
2488   precond(factor &gt; 0);
2489 
2490   // Take into account that after unroll conjoined heads and tails will fold.
2491   uint const b0 = _body.size() - EMPTY_LOOP_SIZE;
2492   uint const cc = 7;
2493   uint const sz = b0 + (b0 + 15) / 16;
2494   uint estimate = factor * sz + cc;
2495 
2496   if ((estimate - cc) / factor != sz) {
2497     return UINT_MAX;
2498   }
2499 
2500   return estimate + est_loop_flow_merge_sz();
2501 }
2502 
2503 // Estimate the growth effect (in nodes) of merging control and data flow when
2504 // cloning a loop body, based on the amount of  control and data flow reaching
2505 // outside of the (current) loop body.
2506 uint IdealLoopTree::est_loop_flow_merge_sz() const {
2507 
2508   uint ctrl_edge_out_cnt = 0;
2509   uint data_edge_out_cnt = 0;
2510 
2511   for (uint i = 0; i &lt; _body.size(); i++) {
2512     Node* node = _body.at(i);
2513     uint outcnt = node-&gt;outcnt();
2514 
2515     for (uint k = 0; k &lt; outcnt; k++) {
2516       Node* out = node-&gt;raw_out(k);
2517       if (out == NULL) continue;
2518       if (out-&gt;is_CFG()) {
2519         if (!is_member(_phase-&gt;get_loop(out))) {
2520           ctrl_edge_out_cnt++;
2521         }
2522       } else if (_phase-&gt;has_ctrl(out)) {
2523         Node* ctrl = _phase-&gt;get_ctrl(out);
2524         assert(ctrl != NULL, &quot;must be&quot;);
2525         assert(ctrl-&gt;is_CFG(), &quot;must be&quot;);
2526         if (!is_member(_phase-&gt;get_loop(ctrl))) {
2527           data_edge_out_cnt++;
2528         }
2529       }
2530     }
2531   }
2532   // Use data and control count (x2.0) in estimate iff both are &gt; 0. This is
2533   // a rather pessimistic estimate for the most part, in particular for some
2534   // complex loops, but still not enough to capture all loops.
2535   if (ctrl_edge_out_cnt &gt; 0 &amp;&amp; data_edge_out_cnt &gt; 0) {
2536     return 2 * (ctrl_edge_out_cnt + data_edge_out_cnt);
2537   }
2538   return 0;
2539 }
2540 
2541 #ifndef PRODUCT
2542 //------------------------------dump_head--------------------------------------
2543 // Dump 1 liner for loop header info
2544 void IdealLoopTree::dump_head() const {
2545   tty-&gt;sp(2 * _nest);
2546   tty-&gt;print(&quot;Loop: N%d/N%d &quot;, _head-&gt;_idx, _tail-&gt;_idx);
2547   if (_irreducible) tty-&gt;print(&quot; IRREDUCIBLE&quot;);
2548   Node* entry = _head-&gt;is_Loop() ? _head-&gt;as_Loop()-&gt;skip_strip_mined(-1)-&gt;in(LoopNode::EntryControl) : _head-&gt;in(LoopNode::EntryControl);
2549   Node* predicate = PhaseIdealLoop::find_predicate_insertion_point(entry, Deoptimization::Reason_loop_limit_check);
2550   if (predicate != NULL ) {
2551     tty-&gt;print(&quot; limit_check&quot;);
2552     entry = PhaseIdealLoop::skip_loop_predicates(entry);
2553   }
2554   if (UseProfiledLoopPredicate) {
2555     predicate = PhaseIdealLoop::find_predicate_insertion_point(entry, Deoptimization::Reason_profile_predicate);
2556     if (predicate != NULL) {
2557       tty-&gt;print(&quot; profile_predicated&quot;);
2558       entry = PhaseIdealLoop::skip_loop_predicates(entry);
2559     }
2560   }
2561   if (UseLoopPredicate) {
2562     predicate = PhaseIdealLoop::find_predicate_insertion_point(entry, Deoptimization::Reason_predicate);
2563     if (predicate != NULL) {
2564       tty-&gt;print(&quot; predicated&quot;);
2565     }
2566   }
2567   if (_head-&gt;is_CountedLoop()) {
2568     CountedLoopNode *cl = _head-&gt;as_CountedLoop();
2569     tty-&gt;print(&quot; counted&quot;);
2570 
2571     Node* init_n = cl-&gt;init_trip();
2572     if (init_n  != NULL &amp;&amp;  init_n-&gt;is_Con())
2573       tty-&gt;print(&quot; [%d,&quot;, cl-&gt;init_trip()-&gt;get_int());
2574     else
2575       tty-&gt;print(&quot; [int,&quot;);
2576     Node* limit_n = cl-&gt;limit();
2577     if (limit_n  != NULL &amp;&amp;  limit_n-&gt;is_Con())
2578       tty-&gt;print(&quot;%d),&quot;, cl-&gt;limit()-&gt;get_int());
2579     else
2580       tty-&gt;print(&quot;int),&quot;);
2581     int stride_con  = cl-&gt;stride_con();
2582     if (stride_con &gt; 0) tty-&gt;print(&quot;+&quot;);
2583     tty-&gt;print(&quot;%d&quot;, stride_con);
2584 
2585     tty-&gt;print(&quot; (%0.f iters) &quot;, cl-&gt;profile_trip_cnt());
2586 
2587     if (cl-&gt;is_pre_loop ()) tty-&gt;print(&quot; pre&quot; );
2588     if (cl-&gt;is_main_loop()) tty-&gt;print(&quot; main&quot;);
2589     if (cl-&gt;is_post_loop()) tty-&gt;print(&quot; post&quot;);
2590     if (cl-&gt;is_vectorized_loop()) tty-&gt;print(&quot; vector&quot;);
2591     if (cl-&gt;range_checks_present()) tty-&gt;print(&quot; rc &quot;);
2592     if (cl-&gt;is_multiversioned()) tty-&gt;print(&quot; multi &quot;);
2593   }
2594   if (_has_call) tty-&gt;print(&quot; has_call&quot;);
2595   if (_has_sfpt) tty-&gt;print(&quot; has_sfpt&quot;);
2596   if (_rce_candidate) tty-&gt;print(&quot; rce&quot;);
2597   if (_safepts != NULL &amp;&amp; _safepts-&gt;size() &gt; 0) {
2598     tty-&gt;print(&quot; sfpts={&quot;); _safepts-&gt;dump_simple(); tty-&gt;print(&quot; }&quot;);
2599   }
2600   if (_required_safept != NULL &amp;&amp; _required_safept-&gt;size() &gt; 0) {
2601     tty-&gt;print(&quot; req={&quot;); _required_safept-&gt;dump_simple(); tty-&gt;print(&quot; }&quot;);
2602   }
2603   if (Verbose) {
2604     tty-&gt;print(&quot; body={&quot;); _body.dump_simple(); tty-&gt;print(&quot; }&quot;);
2605   }
2606   if (_head-&gt;is_Loop() &amp;&amp; _head-&gt;as_Loop()-&gt;is_strip_mined()) {
2607     tty-&gt;print(&quot; strip_mined&quot;);
2608   }
2609   tty-&gt;cr();
2610 }
2611 
2612 //------------------------------dump-------------------------------------------
2613 // Dump loops by loop tree
2614 void IdealLoopTree::dump() const {
2615   dump_head();
2616   if (_child) _child-&gt;dump();
2617   if (_next)  _next -&gt;dump();
2618 }
2619 
2620 #endif
2621 
2622 static void log_loop_tree(IdealLoopTree* root, IdealLoopTree* loop, CompileLog* log) {
2623   if (loop == root) {
2624     if (loop-&gt;_child != NULL) {
2625       log-&gt;begin_head(&quot;loop_tree&quot;);
2626       log-&gt;end_head();
2627       if( loop-&gt;_child ) log_loop_tree(root, loop-&gt;_child, log);
2628       log-&gt;tail(&quot;loop_tree&quot;);
2629       assert(loop-&gt;_next == NULL, &quot;what?&quot;);
2630     }
2631   } else {
2632     Node* head = loop-&gt;_head;
2633     log-&gt;begin_head(&quot;loop&quot;);
2634     log-&gt;print(&quot; idx=&#39;%d&#39; &quot;, head-&gt;_idx);
2635     if (loop-&gt;_irreducible) log-&gt;print(&quot;irreducible=&#39;1&#39; &quot;);
2636     if (head-&gt;is_Loop()) {
2637       if (head-&gt;as_Loop()-&gt;is_inner_loop()) log-&gt;print(&quot;inner_loop=&#39;1&#39; &quot;);
2638       if (head-&gt;as_Loop()-&gt;is_partial_peel_loop()) log-&gt;print(&quot;partial_peel_loop=&#39;1&#39; &quot;);
2639     }
2640     if (head-&gt;is_CountedLoop()) {
2641       CountedLoopNode* cl = head-&gt;as_CountedLoop();
2642       if (cl-&gt;is_pre_loop())  log-&gt;print(&quot;pre_loop=&#39;%d&#39; &quot;,  cl-&gt;main_idx());
2643       if (cl-&gt;is_main_loop()) log-&gt;print(&quot;main_loop=&#39;%d&#39; &quot;, cl-&gt;_idx);
2644       if (cl-&gt;is_post_loop()) log-&gt;print(&quot;post_loop=&#39;%d&#39; &quot;,  cl-&gt;main_idx());
2645     }
2646     log-&gt;end_head();
2647     if( loop-&gt;_child ) log_loop_tree(root, loop-&gt;_child, log);
2648     log-&gt;tail(&quot;loop&quot;);
2649     if( loop-&gt;_next  ) log_loop_tree(root, loop-&gt;_next, log);
2650   }
2651 }
2652 
2653 //---------------------collect_potentially_useful_predicates-----------------------
2654 // Helper function to collect potentially useful predicates to prevent them from
2655 // being eliminated by PhaseIdealLoop::eliminate_useless_predicates
2656 void PhaseIdealLoop::collect_potentially_useful_predicates(
2657                          IdealLoopTree * loop, Unique_Node_List &amp;useful_predicates) {
2658   if (loop-&gt;_child) { // child
2659     collect_potentially_useful_predicates(loop-&gt;_child, useful_predicates);
2660   }
2661 
2662   // self (only loops that we can apply loop predication may use their predicates)
2663   if (loop-&gt;_head-&gt;is_Loop() &amp;&amp;
2664       !loop-&gt;_irreducible    &amp;&amp;
2665       !loop-&gt;tail()-&gt;is_top()) {
2666     LoopNode* lpn = loop-&gt;_head-&gt;as_Loop();
2667     Node* entry = lpn-&gt;in(LoopNode::EntryControl);
2668     Node* predicate_proj = find_predicate(entry); // loop_limit_check first
2669     if (predicate_proj != NULL) { // right pattern that can be used by loop predication
2670       assert(entry-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;Opcode() == Op_Opaque1, &quot;must be&quot;);
2671       useful_predicates.push(entry-&gt;in(0)-&gt;in(1)-&gt;in(1)); // good one
2672       entry = skip_loop_predicates(entry);
2673     }
2674     if (UseProfiledLoopPredicate) {
2675       predicate_proj = find_predicate(entry); // Predicate
2676       if (predicate_proj != NULL) {
2677         useful_predicates.push(entry-&gt;in(0)-&gt;in(1)-&gt;in(1)); // good one
2678         entry = skip_loop_predicates(entry);
2679       }
2680     }
2681     predicate_proj = find_predicate(entry); // Predicate
2682     if (predicate_proj != NULL) {
2683       useful_predicates.push(entry-&gt;in(0)-&gt;in(1)-&gt;in(1)); // good one
2684     }
2685   }
2686 
2687   if (loop-&gt;_next) { // sibling
2688     collect_potentially_useful_predicates(loop-&gt;_next, useful_predicates);
2689   }
2690 }
2691 
2692 //------------------------eliminate_useless_predicates-----------------------------
2693 // Eliminate all inserted predicates if they could not be used by loop predication.
2694 // Note: it will also eliminates loop limits check predicate since it also uses
2695 // Opaque1 node (see Parse::add_predicate()).
2696 void PhaseIdealLoop::eliminate_useless_predicates() {
2697   if (C-&gt;predicate_count() == 0)
2698     return; // no predicate left
2699 
2700   Unique_Node_List useful_predicates; // to store useful predicates
2701   if (C-&gt;has_loops()) {
2702     collect_potentially_useful_predicates(_ltree_root-&gt;_child, useful_predicates);
2703   }
2704 
2705   for (int i = C-&gt;predicate_count(); i &gt; 0; i--) {
2706      Node * n = C-&gt;predicate_opaque1_node(i-1);
2707      assert(n-&gt;Opcode() == Op_Opaque1, &quot;must be&quot;);
2708      if (!useful_predicates.member(n)) { // not in the useful list
2709        _igvn.replace_node(n, n-&gt;in(1));
2710      }
2711   }
2712 }
2713 
2714 //------------------------process_expensive_nodes-----------------------------
2715 // Expensive nodes have their control input set to prevent the GVN
2716 // from commoning them and as a result forcing the resulting node to
2717 // be in a more frequent path. Use CFG information here, to change the
2718 // control inputs so that some expensive nodes can be commoned while
2719 // not executed more frequently.
2720 bool PhaseIdealLoop::process_expensive_nodes() {
2721   assert(OptimizeExpensiveOps, &quot;optimization off?&quot;);
2722 
2723   // Sort nodes to bring similar nodes together
2724   C-&gt;sort_expensive_nodes();
2725 
2726   bool progress = false;
2727 
2728   for (int i = 0; i &lt; C-&gt;expensive_count(); ) {
2729     Node* n = C-&gt;expensive_node(i);
2730     int start = i;
2731     // Find nodes similar to n
2732     i++;
2733     for (; i &lt; C-&gt;expensive_count() &amp;&amp; Compile::cmp_expensive_nodes(n, C-&gt;expensive_node(i)) == 0; i++);
2734     int end = i;
2735     // And compare them two by two
2736     for (int j = start; j &lt; end; j++) {
2737       Node* n1 = C-&gt;expensive_node(j);
2738       if (is_node_unreachable(n1)) {
2739         continue;
2740       }
2741       for (int k = j+1; k &lt; end; k++) {
2742         Node* n2 = C-&gt;expensive_node(k);
2743         if (is_node_unreachable(n2)) {
2744           continue;
2745         }
2746 
2747         assert(n1 != n2, &quot;should be pair of nodes&quot;);
2748 
2749         Node* c1 = n1-&gt;in(0);
2750         Node* c2 = n2-&gt;in(0);
2751 
2752         Node* parent_c1 = c1;
2753         Node* parent_c2 = c2;
2754 
2755         // The call to get_early_ctrl_for_expensive() moves the
2756         // expensive nodes up but stops at loops that are in a if
2757         // branch. See whether we can exit the loop and move above the
2758         // If.
2759         if (c1-&gt;is_Loop()) {
2760           parent_c1 = c1-&gt;in(1);
2761         }
2762         if (c2-&gt;is_Loop()) {
2763           parent_c2 = c2-&gt;in(1);
2764         }
2765 
2766         if (parent_c1 == parent_c2) {
2767           _igvn._worklist.push(n1);
2768           _igvn._worklist.push(n2);
2769           continue;
2770         }
2771 
2772         // Look for identical expensive node up the dominator chain.
2773         if (is_dominator(c1, c2)) {
2774           c2 = c1;
2775         } else if (is_dominator(c2, c1)) {
2776           c1 = c2;
2777         } else if (parent_c1-&gt;is_Proj() &amp;&amp; parent_c1-&gt;in(0)-&gt;is_If() &amp;&amp;
2778                    parent_c2-&gt;is_Proj() &amp;&amp; parent_c1-&gt;in(0) == parent_c2-&gt;in(0)) {
2779           // Both branches have the same expensive node so move it up
2780           // before the if.
2781           c1 = c2 = idom(parent_c1-&gt;in(0));
2782         }
2783         // Do the actual moves
2784         if (n1-&gt;in(0) != c1) {
2785           _igvn.hash_delete(n1);
2786           n1-&gt;set_req(0, c1);
2787           _igvn.hash_insert(n1);
2788           _igvn._worklist.push(n1);
2789           progress = true;
2790         }
2791         if (n2-&gt;in(0) != c2) {
2792           _igvn.hash_delete(n2);
2793           n2-&gt;set_req(0, c2);
2794           _igvn.hash_insert(n2);
2795           _igvn._worklist.push(n2);
2796           progress = true;
2797         }
2798       }
2799     }
2800   }
2801 
2802   return progress;
2803 }
2804 
2805 
2806 //=============================================================================
2807 //----------------------------build_and_optimize-------------------------------
2808 // Create a PhaseLoop.  Build the ideal Loop tree.  Map each Ideal Node to
2809 // its corresponding LoopNode.  If &#39;optimize&#39; is true, do some loop cleanups.
2810 void PhaseIdealLoop::build_and_optimize(LoopOptsMode mode) {
2811   bool do_split_ifs = (mode == LoopOptsDefault);
2812   bool skip_loop_opts = (mode == LoopOptsNone);
2813 
2814   int old_progress = C-&gt;major_progress();
2815   uint orig_worklist_size = _igvn._worklist.size();
2816 
2817   // Reset major-progress flag for the driver&#39;s heuristics
2818   C-&gt;clear_major_progress();
2819 
2820 #ifndef PRODUCT
2821   // Capture for later assert
2822   uint unique = C-&gt;unique();
2823   _loop_invokes++;
2824   _loop_work += unique;
2825 #endif
2826 
2827   // True if the method has at least 1 irreducible loop
2828   _has_irreducible_loops = false;
2829 
2830   _created_loop_node = false;
2831 
2832   Arena *a = Thread::current()-&gt;resource_area();
2833   VectorSet visited(a);
2834   // Pre-grow the mapping from Nodes to IdealLoopTrees.
2835   _nodes.map(C-&gt;unique(), NULL);
2836   memset(_nodes.adr(), 0, wordSize * C-&gt;unique());
2837 
2838   // Pre-build the top-level outermost loop tree entry
2839   _ltree_root = new IdealLoopTree( this, C-&gt;root(), C-&gt;root() );
2840   // Do not need a safepoint at the top level
2841   _ltree_root-&gt;_has_sfpt = 1;
2842 
2843   // Initialize Dominators.
2844   // Checked in clone_loop_predicate() during beautify_loops().
2845   _idom_size = 0;
2846   _idom      = NULL;
2847   _dom_depth = NULL;
2848   _dom_stk   = NULL;
2849 
2850   // Empty pre-order array
2851   allocate_preorders();
2852 
2853   // Build a loop tree on the fly.  Build a mapping from CFG nodes to
2854   // IdealLoopTree entries.  Data nodes are NOT walked.
2855   build_loop_tree();
2856   // Check for bailout, and return
2857   if (C-&gt;failing()) {
2858     return;
2859   }
2860 
2861   // No loops after all
2862   if( !_ltree_root-&gt;_child &amp;&amp; !_verify_only ) C-&gt;set_has_loops(false);
2863 
2864   // There should always be an outer loop containing the Root and Return nodes.
2865   // If not, we have a degenerate empty program.  Bail out in this case.
2866   if (!has_node(C-&gt;root())) {
2867     if (!_verify_only) {
2868       C-&gt;clear_major_progress();
2869       C-&gt;record_method_not_compilable(&quot;empty program detected during loop optimization&quot;);
2870     }
2871     return;
2872   }
2873 
2874   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
2875   // Nothing to do, so get out
2876   bool stop_early = !C-&gt;has_loops() &amp;&amp; !skip_loop_opts &amp;&amp; !do_split_ifs &amp;&amp; !_verify_me &amp;&amp; !_verify_only &amp;&amp;
2877     !bs-&gt;is_gc_specific_loop_opts_pass(mode);
2878   bool do_expensive_nodes = C-&gt;should_optimize_expensive_nodes(_igvn);
2879   bool strip_mined_loops_expanded = bs-&gt;strip_mined_loops_expanded(mode);
2880   if (stop_early &amp;&amp; !do_expensive_nodes) {
2881     _igvn.optimize();           // Cleanup NeverBranches
2882     return;
2883   }
2884 
2885   // Set loop nesting depth
2886   _ltree_root-&gt;set_nest( 0 );
2887 
2888   // Split shared headers and insert loop landing pads.
2889   // Do not bother doing this on the Root loop of course.
2890   if( !_verify_me &amp;&amp; !_verify_only &amp;&amp; _ltree_root-&gt;_child ) {
2891     C-&gt;print_method(PHASE_BEFORE_BEAUTIFY_LOOPS, 3);
2892     if( _ltree_root-&gt;_child-&gt;beautify_loops( this ) ) {
2893       // Re-build loop tree!
2894       _ltree_root-&gt;_child = NULL;
2895       _nodes.clear();
2896       reallocate_preorders();
2897       build_loop_tree();
2898       // Check for bailout, and return
2899       if (C-&gt;failing()) {
2900         return;
2901       }
2902       // Reset loop nesting depth
2903       _ltree_root-&gt;set_nest( 0 );
2904 
2905       C-&gt;print_method(PHASE_AFTER_BEAUTIFY_LOOPS, 3);
2906     }
2907   }
2908 
2909   // Build Dominators for elision of NULL checks &amp; loop finding.
2910   // Since nodes do not have a slot for immediate dominator, make
2911   // a persistent side array for that info indexed on node-&gt;_idx.
2912   _idom_size = C-&gt;unique();
2913   _idom      = NEW_RESOURCE_ARRAY( Node*, _idom_size );
2914   _dom_depth = NEW_RESOURCE_ARRAY( uint,  _idom_size );
2915   _dom_stk   = NULL; // Allocated on demand in recompute_dom_depth
2916   memset( _dom_depth, 0, _idom_size * sizeof(uint) );
2917 
2918   Dominators();
2919 
2920   if (!_verify_only) {
2921     // As a side effect, Dominators removed any unreachable CFG paths
2922     // into RegionNodes.  It doesn&#39;t do this test against Root, so
2923     // we do it here.
2924     for( uint i = 1; i &lt; C-&gt;root()-&gt;req(); i++ ) {
2925       if( !_nodes[C-&gt;root()-&gt;in(i)-&gt;_idx] ) {    // Dead path into Root?
2926         _igvn.delete_input_of(C-&gt;root(), i);
2927         i--;                      // Rerun same iteration on compressed edges
2928       }
2929     }
2930 
2931     // Given dominators, try to find inner loops with calls that must
2932     // always be executed (call dominates loop tail).  These loops do
2933     // not need a separate safepoint.
2934     Node_List cisstack(a);
2935     _ltree_root-&gt;check_safepts(visited, cisstack);
2936   }
2937 
2938   // Walk the DATA nodes and place into loops.  Find earliest control
2939   // node.  For CFG nodes, the _nodes array starts out and remains
2940   // holding the associated IdealLoopTree pointer.  For DATA nodes, the
2941   // _nodes array holds the earliest legal controlling CFG node.
2942 
2943   // Allocate stack with enough space to avoid frequent realloc
2944   int stack_size = (C-&gt;live_nodes() &gt;&gt; 1) + 16; // (live_nodes&gt;&gt;1)+16 from Java2D stats
2945   Node_Stack nstack( a, stack_size );
2946 
2947   visited.clear();
2948   Node_List worklist(a);
2949   // Don&#39;t need C-&gt;root() on worklist since
2950   // it will be processed among C-&gt;top() inputs
2951   worklist.push(C-&gt;top());
2952   visited.set(C-&gt;top()-&gt;_idx); // Set C-&gt;top() as visited now
2953   build_loop_early( visited, worklist, nstack );
2954 
2955   // Given early legal placement, try finding counted loops.  This placement
2956   // is good enough to discover most loop invariants.
2957   if (!_verify_me &amp;&amp; !_verify_only &amp;&amp; !strip_mined_loops_expanded) {
2958     _ltree_root-&gt;counted_loop( this );
2959   }
2960 
2961   // Find latest loop placement.  Find ideal loop placement.
2962   visited.clear();
2963   init_dom_lca_tags();
2964   // Need C-&gt;root() on worklist when processing outs
2965   worklist.push(C-&gt;root());
2966   NOT_PRODUCT( C-&gt;verify_graph_edges(); )
2967   worklist.push(C-&gt;top());
2968   build_loop_late( visited, worklist, nstack );
2969 
2970   if (_verify_only) {
2971     C-&gt;restore_major_progress(old_progress);
2972     assert(C-&gt;unique() == unique, &quot;verification mode made Nodes? ? ?&quot;);
2973     assert(_igvn._worklist.size() == orig_worklist_size, &quot;shouldn&#39;t push anything&quot;);
2974     return;
2975   }
2976 
2977   // clear out the dead code after build_loop_late
2978   while (_deadlist.size()) {
2979     _igvn.remove_globally_dead_node(_deadlist.pop());
2980   }
2981 
2982   if (stop_early) {
2983     assert(do_expensive_nodes, &quot;why are we here?&quot;);
2984     if (process_expensive_nodes()) {
2985       // If we made some progress when processing expensive nodes then
2986       // the IGVN may modify the graph in a way that will allow us to
2987       // make some more progress: we need to try processing expensive
2988       // nodes again.
2989       C-&gt;set_major_progress();
2990     }
2991     _igvn.optimize();
2992     return;
2993   }
2994 
2995   // Some parser-inserted loop predicates could never be used by loop
2996   // predication or they were moved away from loop during some optimizations.
2997   // For example, peeling. Eliminate them before next loop optimizations.
2998   eliminate_useless_predicates();
2999 
3000 #ifndef PRODUCT
3001   C-&gt;verify_graph_edges();
3002   if (_verify_me) {             // Nested verify pass?
3003     // Check to see if the verify mode is broken
3004     assert(C-&gt;unique() == unique, &quot;non-optimize mode made Nodes? ? ?&quot;);
3005     return;
3006   }
3007   if (VerifyLoopOptimizations) verify();
3008   if (TraceLoopOpts &amp;&amp; C-&gt;has_loops()) {
3009     _ltree_root-&gt;dump();
3010   }
3011 #endif
3012 
3013   if (skip_loop_opts) {
3014     // restore major progress flag
3015     C-&gt;restore_major_progress(old_progress);
3016 
3017     // Cleanup any modified bits
3018     _igvn.optimize();
3019 
3020     if (C-&gt;log() != NULL) {
3021       log_loop_tree(_ltree_root, _ltree_root, C-&gt;log());
3022     }
3023     return;
3024   }
3025 
3026   if (mode == LoopOptsMaxUnroll) {
3027     for (LoopTreeIterator iter(_ltree_root); !iter.done(); iter.next()) {
3028       IdealLoopTree* lpt = iter.current();
3029       if (lpt-&gt;is_innermost() &amp;&amp; lpt-&gt;_allow_optimizations &amp;&amp; !lpt-&gt;_has_call &amp;&amp; lpt-&gt;is_counted()) {
3030         lpt-&gt;compute_trip_count(this);
3031         if (!lpt-&gt;do_one_iteration_loop(this) &amp;&amp;
3032             !lpt-&gt;do_remove_empty_loop(this)) {
3033           AutoNodeBudget node_budget(this);
3034           if (lpt-&gt;_head-&gt;as_CountedLoop()-&gt;is_normal_loop() &amp;&amp;
3035               lpt-&gt;policy_maximally_unroll(this)) {
3036             memset( worklist.adr(), 0, worklist.Size()*sizeof(Node*) );
3037             do_maximally_unroll(lpt, worklist);
3038           }
3039         }
3040       }
3041     }
3042 
3043     C-&gt;restore_major_progress(old_progress);
3044 
3045     _igvn.optimize();
3046 
3047     if (C-&gt;log() != NULL) {
3048       log_loop_tree(_ltree_root, _ltree_root, C-&gt;log());
3049     }
3050     return;
3051   }
3052 
3053   if (bs-&gt;optimize_loops(this, mode, visited, nstack, worklist)) {
3054     _igvn.optimize();
3055     if (C-&gt;log() != NULL) {
3056       log_loop_tree(_ltree_root, _ltree_root, C-&gt;log());
3057     }
3058     return;
3059   }
3060 
3061   if (ReassociateInvariants) {
3062     // Reassociate invariants and prep for split_thru_phi
3063     for (LoopTreeIterator iter(_ltree_root); !iter.done(); iter.next()) {
3064       IdealLoopTree* lpt = iter.current();
3065       bool is_counted = lpt-&gt;is_counted();
3066       if (!is_counted || !lpt-&gt;is_innermost()) continue;
3067 
3068       // check for vectorized loops, any reassociation of invariants was already done
3069       if (is_counted &amp;&amp; lpt-&gt;_head-&gt;as_CountedLoop()-&gt;is_unroll_only()) {
3070         continue;
3071       } else {
3072         AutoNodeBudget node_budget(this);
3073         lpt-&gt;reassociate_invariants(this);
3074       }
3075       // Because RCE opportunities can be masked by split_thru_phi,
3076       // look for RCE candidates and inhibit split_thru_phi
3077       // on just their loop-phi&#39;s for this pass of loop opts
3078       if (SplitIfBlocks &amp;&amp; do_split_ifs) {
3079         AutoNodeBudget node_budget(this, AutoNodeBudget::NO_BUDGET_CHECK);
3080         if (lpt-&gt;policy_range_check(this)) {
3081           lpt-&gt;_rce_candidate = 1; // = true
3082         }
3083       }
3084     }
3085   }
3086 
3087   // Check for aggressive application of split-if and other transforms
3088   // that require basic-block info (like cloning through Phi&#39;s)
3089   if( SplitIfBlocks &amp;&amp; do_split_ifs ) {
3090     visited.clear();
3091     split_if_with_blocks( visited, nstack);
3092     NOT_PRODUCT( if( VerifyLoopOptimizations ) verify(); );
3093   }
3094 
3095   if (!C-&gt;major_progress() &amp;&amp; do_expensive_nodes &amp;&amp; process_expensive_nodes()) {
3096     C-&gt;set_major_progress();
3097   }
3098 
3099   // Perform loop predication before iteration splitting
3100   if (C-&gt;has_loops() &amp;&amp; !C-&gt;major_progress() &amp;&amp; (C-&gt;predicate_count() &gt; 0)) {
3101     _ltree_root-&gt;_child-&gt;loop_predication(this);
3102   }
3103 
3104   if (OptimizeFill &amp;&amp; UseLoopPredicate &amp;&amp; C-&gt;has_loops() &amp;&amp; !C-&gt;major_progress()) {
3105     if (do_intrinsify_fill()) {
3106       C-&gt;set_major_progress();
3107     }
3108   }
3109 
3110   // Perform iteration-splitting on inner loops.  Split iterations to avoid
3111   // range checks or one-shot null checks.
3112 
3113   // If split-if&#39;s didn&#39;t hack the graph too bad (no CFG changes)
3114   // then do loop opts.
3115   if (C-&gt;has_loops() &amp;&amp; !C-&gt;major_progress()) {
3116     memset( worklist.adr(), 0, worklist.Size()*sizeof(Node*) );
3117     _ltree_root-&gt;_child-&gt;iteration_split( this, worklist );
3118     // No verify after peeling!  GCM has hoisted code out of the loop.
3119     // After peeling, the hoisted code could sink inside the peeled area.
3120     // The peeling code does not try to recompute the best location for
3121     // all the code before the peeled area, so the verify pass will always
3122     // complain about it.
3123   }
3124   // Do verify graph edges in any case
3125   NOT_PRODUCT( C-&gt;verify_graph_edges(); );
3126 
3127   if (!do_split_ifs) {
3128     // We saw major progress in Split-If to get here.  We forced a
3129     // pass with unrolling and not split-if, however more split-if&#39;s
3130     // might make progress.  If the unrolling didn&#39;t make progress
3131     // then the major-progress flag got cleared and we won&#39;t try
3132     // another round of Split-If.  In particular the ever-common
3133     // instance-of/check-cast pattern requires at least 2 rounds of
3134     // Split-If to clear out.
3135     C-&gt;set_major_progress();
3136   }
3137 
3138   // Repeat loop optimizations if new loops were seen
3139   if (created_loop_node()) {
3140     C-&gt;set_major_progress();
3141   }
3142 
3143   // Keep loop predicates and perform optimizations with them
3144   // until no more loop optimizations could be done.
3145   // After that switch predicates off and do more loop optimizations.
3146   if (!C-&gt;major_progress() &amp;&amp; (C-&gt;predicate_count() &gt; 0)) {
3147      C-&gt;cleanup_loop_predicates(_igvn);
3148      if (TraceLoopOpts) {
3149        tty-&gt;print_cr(&quot;PredicatesOff&quot;);
3150      }
3151      C-&gt;set_major_progress();
3152   }
3153 
3154   // Convert scalar to superword operations at the end of all loop opts.
3155   if (UseSuperWord &amp;&amp; C-&gt;has_loops() &amp;&amp; !C-&gt;major_progress()) {
3156     // SuperWord transform
3157     SuperWord sw(this);
3158     for (LoopTreeIterator iter(_ltree_root); !iter.done(); iter.next()) {
3159       IdealLoopTree* lpt = iter.current();
3160       if (lpt-&gt;is_counted()) {
3161         CountedLoopNode *cl = lpt-&gt;_head-&gt;as_CountedLoop();
3162 
3163         if (PostLoopMultiversioning &amp;&amp; cl-&gt;is_rce_post_loop() &amp;&amp; !cl-&gt;is_vectorized_loop()) {
3164           // Check that the rce&#39;d post loop is encountered first, multiversion after all
3165           // major main loop optimization are concluded
3166           if (!C-&gt;major_progress()) {
3167             IdealLoopTree *lpt_next = lpt-&gt;_next;
3168             if (lpt_next &amp;&amp; lpt_next-&gt;is_counted()) {
3169               CountedLoopNode *cl = lpt_next-&gt;_head-&gt;as_CountedLoop();
3170               has_range_checks(lpt_next);
3171               if (cl-&gt;is_post_loop() &amp;&amp; cl-&gt;range_checks_present()) {
3172                 if (!cl-&gt;is_multiversioned()) {
3173                   if (multi_version_post_loops(lpt, lpt_next) == false) {
3174                     // Cause the rce loop to be optimized away if we fail
3175                     cl-&gt;mark_is_multiversioned();
3176                     cl-&gt;set_slp_max_unroll(0);
3177                     poison_rce_post_loop(lpt);
3178                   }
3179                 }
3180               }
3181             }
3182             sw.transform_loop(lpt, true);
3183           }
3184         } else if (cl-&gt;is_main_loop()) {
3185           sw.transform_loop(lpt, true);
3186         }
3187       }
3188     }
3189   }
3190 
3191   // Cleanup any modified bits
3192   _igvn.optimize();
3193 
3194   // disable assert until issue with split_flow_path is resolved (6742111)
3195   // assert(!_has_irreducible_loops || C-&gt;parsed_irreducible_loop() || C-&gt;is_osr_compilation(),
3196   //        &quot;shouldn&#39;t introduce irreducible loops&quot;);
3197 
3198   if (C-&gt;log() != NULL) {
3199     log_loop_tree(_ltree_root, _ltree_root, C-&gt;log());
3200   }
3201 }
3202 
3203 #ifndef PRODUCT
3204 //------------------------------print_statistics-------------------------------
3205 int PhaseIdealLoop::_loop_invokes=0;// Count of PhaseIdealLoop invokes
3206 int PhaseIdealLoop::_loop_work=0; // Sum of PhaseIdealLoop x unique
3207 void PhaseIdealLoop::print_statistics() {
3208   tty-&gt;print_cr(&quot;PhaseIdealLoop=%d, sum _unique=%d&quot;, _loop_invokes, _loop_work);
3209 }
3210 
3211 //------------------------------verify-----------------------------------------
3212 // Build a verify-only PhaseIdealLoop, and see that it agrees with me.
3213 static int fail;                // debug only, so its multi-thread dont care
3214 void PhaseIdealLoop::verify() const {
3215   int old_progress = C-&gt;major_progress();
3216   ResourceMark rm;
3217   PhaseIdealLoop loop_verify( _igvn, this );
3218   VectorSet visited(Thread::current()-&gt;resource_area());
3219 
3220   fail = 0;
3221   verify_compare( C-&gt;root(), &amp;loop_verify, visited );
3222   assert( fail == 0, &quot;verify loops failed&quot; );
3223   // Verify loop structure is the same
3224   _ltree_root-&gt;verify_tree(loop_verify._ltree_root, NULL);
3225   // Reset major-progress.  It was cleared by creating a verify version of
3226   // PhaseIdealLoop.
3227   C-&gt;restore_major_progress(old_progress);
3228 }
3229 
3230 //------------------------------verify_compare---------------------------------
3231 // Make sure me and the given PhaseIdealLoop agree on key data structures
3232 void PhaseIdealLoop::verify_compare( Node *n, const PhaseIdealLoop *loop_verify, VectorSet &amp;visited ) const {
3233   if( !n ) return;
3234   if( visited.test_set( n-&gt;_idx ) ) return;
3235   if( !_nodes[n-&gt;_idx] ) {      // Unreachable
3236     assert( !loop_verify-&gt;_nodes[n-&gt;_idx], &quot;both should be unreachable&quot; );
3237     return;
3238   }
3239 
3240   uint i;
3241   for( i = 0; i &lt; n-&gt;req(); i++ )
3242     verify_compare( n-&gt;in(i), loop_verify, visited );
3243 
3244   // Check the &#39;_nodes&#39; block/loop structure
3245   i = n-&gt;_idx;
3246   if( has_ctrl(n) ) {           // We have control; verify has loop or ctrl
3247     if( _nodes[i] != loop_verify-&gt;_nodes[i] &amp;&amp;
3248         get_ctrl_no_update(n) != loop_verify-&gt;get_ctrl_no_update(n) ) {
3249       tty-&gt;print(&quot;Mismatched control setting for: &quot;);
3250       n-&gt;dump();
3251       if( fail++ &gt; 10 ) return;
3252       Node *c = get_ctrl_no_update(n);
3253       tty-&gt;print(&quot;We have it as: &quot;);
3254       if( c-&gt;in(0) ) c-&gt;dump();
3255         else tty-&gt;print_cr(&quot;N%d&quot;,c-&gt;_idx);
3256       tty-&gt;print(&quot;Verify thinks: &quot;);
3257       if( loop_verify-&gt;has_ctrl(n) )
3258         loop_verify-&gt;get_ctrl_no_update(n)-&gt;dump();
3259       else
3260         loop_verify-&gt;get_loop_idx(n)-&gt;dump();
3261       tty-&gt;cr();
3262     }
3263   } else {                    // We have a loop
3264     IdealLoopTree *us = get_loop_idx(n);
3265     if( loop_verify-&gt;has_ctrl(n) ) {
3266       tty-&gt;print(&quot;Mismatched loop setting for: &quot;);
3267       n-&gt;dump();
3268       if( fail++ &gt; 10 ) return;
3269       tty-&gt;print(&quot;We have it as: &quot;);
3270       us-&gt;dump();
3271       tty-&gt;print(&quot;Verify thinks: &quot;);
3272       loop_verify-&gt;get_ctrl_no_update(n)-&gt;dump();
3273       tty-&gt;cr();
3274     } else if (!C-&gt;major_progress()) {
3275       // Loop selection can be messed up if we did a major progress
3276       // operation, like split-if.  Do not verify in that case.
3277       IdealLoopTree *them = loop_verify-&gt;get_loop_idx(n);
3278       if( us-&gt;_head != them-&gt;_head ||  us-&gt;_tail != them-&gt;_tail ) {
3279         tty-&gt;print(&quot;Unequals loops for: &quot;);
3280         n-&gt;dump();
3281         if( fail++ &gt; 10 ) return;
3282         tty-&gt;print(&quot;We have it as: &quot;);
3283         us-&gt;dump();
3284         tty-&gt;print(&quot;Verify thinks: &quot;);
3285         them-&gt;dump();
3286         tty-&gt;cr();
3287       }
3288     }
3289   }
3290 
3291   // Check for immediate dominators being equal
3292   if( i &gt;= _idom_size ) {
3293     if( !n-&gt;is_CFG() ) return;
3294     tty-&gt;print(&quot;CFG Node with no idom: &quot;);
3295     n-&gt;dump();
3296     return;
3297   }
3298   if( !n-&gt;is_CFG() ) return;
3299   if( n == C-&gt;root() ) return; // No IDOM here
3300 
3301   assert(n-&gt;_idx == i, &quot;sanity&quot;);
3302   Node *id = idom_no_update(n);
3303   if( id != loop_verify-&gt;idom_no_update(n) ) {
3304     tty-&gt;print(&quot;Unequals idoms for: &quot;);
3305     n-&gt;dump();
3306     if( fail++ &gt; 10 ) return;
3307     tty-&gt;print(&quot;We have it as: &quot;);
3308     id-&gt;dump();
3309     tty-&gt;print(&quot;Verify thinks: &quot;);
3310     loop_verify-&gt;idom_no_update(n)-&gt;dump();
3311     tty-&gt;cr();
3312   }
3313 
3314 }
3315 
3316 //------------------------------verify_tree------------------------------------
3317 // Verify that tree structures match.  Because the CFG can change, siblings
3318 // within the loop tree can be reordered.  We attempt to deal with that by
3319 // reordering the verify&#39;s loop tree if possible.
3320 void IdealLoopTree::verify_tree(IdealLoopTree *loop, const IdealLoopTree *parent) const {
3321   assert( _parent == parent, &quot;Badly formed loop tree&quot; );
3322 
3323   // Siblings not in same order?  Attempt to re-order.
3324   if( _head != loop-&gt;_head ) {
3325     // Find _next pointer to update
3326     IdealLoopTree **pp = &amp;loop-&gt;_parent-&gt;_child;
3327     while( *pp != loop )
3328       pp = &amp;((*pp)-&gt;_next);
3329     // Find proper sibling to be next
3330     IdealLoopTree **nn = &amp;loop-&gt;_next;
3331     while( (*nn) &amp;&amp; (*nn)-&gt;_head != _head )
3332       nn = &amp;((*nn)-&gt;_next);
3333 
3334     // Check for no match.
3335     if( !(*nn) ) {
3336       // Annoyingly, irreducible loops can pick different headers
3337       // after a major_progress operation, so the rest of the loop
3338       // tree cannot be matched.
3339       if (_irreducible &amp;&amp; Compile::current()-&gt;major_progress())  return;
3340       assert( 0, &quot;failed to match loop tree&quot; );
3341     }
3342 
3343     // Move (*nn) to (*pp)
3344     IdealLoopTree *hit = *nn;
3345     *nn = hit-&gt;_next;
3346     hit-&gt;_next = loop;
3347     *pp = loop;
3348     loop = hit;
3349     // Now try again to verify
3350   }
3351 
3352   assert( _head  == loop-&gt;_head , &quot;mismatched loop head&quot; );
3353   Node *tail = _tail;           // Inline a non-updating version of
3354   while( !tail-&gt;in(0) )         // the &#39;tail()&#39; call.
3355     tail = tail-&gt;in(1);
3356   assert( tail == loop-&gt;_tail, &quot;mismatched loop tail&quot; );
3357 
3358   // Counted loops that are guarded should be able to find their guards
3359   if( _head-&gt;is_CountedLoop() &amp;&amp; _head-&gt;as_CountedLoop()-&gt;is_main_loop() ) {
3360     CountedLoopNode *cl = _head-&gt;as_CountedLoop();
3361     Node *init = cl-&gt;init_trip();
3362     Node *ctrl = cl-&gt;in(LoopNode::EntryControl);
3363     assert( ctrl-&gt;Opcode() == Op_IfTrue || ctrl-&gt;Opcode() == Op_IfFalse, &quot;&quot; );
3364     Node *iff  = ctrl-&gt;in(0);
3365     assert( iff-&gt;Opcode() == Op_If, &quot;&quot; );
3366     Node *bol  = iff-&gt;in(1);
3367     assert( bol-&gt;Opcode() == Op_Bool, &quot;&quot; );
3368     Node *cmp  = bol-&gt;in(1);
3369     assert( cmp-&gt;Opcode() == Op_CmpI, &quot;&quot; );
3370     Node *add  = cmp-&gt;in(1);
3371     Node *opaq;
3372     if( add-&gt;Opcode() == Op_Opaque1 ) {
3373       opaq = add;
3374     } else {
3375       assert( add-&gt;Opcode() == Op_AddI || add-&gt;Opcode() == Op_ConI , &quot;&quot; );
3376       assert( add == init, &quot;&quot; );
3377       opaq = cmp-&gt;in(2);
3378     }
3379     assert( opaq-&gt;Opcode() == Op_Opaque1, &quot;&quot; );
3380 
3381   }
3382 
3383   if (_child != NULL)  _child-&gt;verify_tree(loop-&gt;_child, this);
3384   if (_next  != NULL)  _next -&gt;verify_tree(loop-&gt;_next,  parent);
3385   // Innermost loops need to verify loop bodies,
3386   // but only if no &#39;major_progress&#39;
3387   int fail = 0;
3388   if (!Compile::current()-&gt;major_progress() &amp;&amp; _child == NULL) {
3389     for( uint i = 0; i &lt; _body.size(); i++ ) {
3390       Node *n = _body.at(i);
3391       if (n-&gt;outcnt() == 0)  continue; // Ignore dead
3392       uint j;
3393       for( j = 0; j &lt; loop-&gt;_body.size(); j++ )
3394         if( loop-&gt;_body.at(j) == n )
3395           break;
3396       if( j == loop-&gt;_body.size() ) { // Not found in loop body
3397         // Last ditch effort to avoid assertion: Its possible that we
3398         // have some users (so outcnt not zero) but are still dead.
3399         // Try to find from root.
3400         if (Compile::current()-&gt;root()-&gt;find(n-&gt;_idx)) {
3401           fail++;
3402           tty-&gt;print(&quot;We have that verify does not: &quot;);
3403           n-&gt;dump();
3404         }
3405       }
3406     }
3407     for( uint i2 = 0; i2 &lt; loop-&gt;_body.size(); i2++ ) {
3408       Node *n = loop-&gt;_body.at(i2);
3409       if (n-&gt;outcnt() == 0)  continue; // Ignore dead
3410       uint j;
3411       for( j = 0; j &lt; _body.size(); j++ )
3412         if( _body.at(j) == n )
3413           break;
3414       if( j == _body.size() ) { // Not found in loop body
3415         // Last ditch effort to avoid assertion: Its possible that we
3416         // have some users (so outcnt not zero) but are still dead.
3417         // Try to find from root.
3418         if (Compile::current()-&gt;root()-&gt;find(n-&gt;_idx)) {
3419           fail++;
3420           tty-&gt;print(&quot;Verify has that we do not: &quot;);
3421           n-&gt;dump();
3422         }
3423       }
3424     }
3425     assert( !fail, &quot;loop body mismatch&quot; );
3426   }
3427 }
3428 
3429 #endif
3430 
3431 //------------------------------set_idom---------------------------------------
3432 void PhaseIdealLoop::set_idom(Node* d, Node* n, uint dom_depth) {
3433   uint idx = d-&gt;_idx;
3434   if (idx &gt;= _idom_size) {
3435     uint newsize = next_power_of_2(idx);
3436     _idom      = REALLOC_RESOURCE_ARRAY( Node*,     _idom,_idom_size,newsize);
3437     _dom_depth = REALLOC_RESOURCE_ARRAY( uint, _dom_depth,_idom_size,newsize);
3438     memset( _dom_depth + _idom_size, 0, (newsize - _idom_size) * sizeof(uint) );
3439     _idom_size = newsize;
3440   }
3441   _idom[idx] = n;
3442   _dom_depth[idx] = dom_depth;
3443 }
3444 
3445 //------------------------------recompute_dom_depth---------------------------------------
3446 // The dominator tree is constructed with only parent pointers.
3447 // This recomputes the depth in the tree by first tagging all
3448 // nodes as &quot;no depth yet&quot; marker.  The next pass then runs up
3449 // the dom tree from each node marked &quot;no depth yet&quot;, and computes
3450 // the depth on the way back down.
3451 void PhaseIdealLoop::recompute_dom_depth() {
3452   uint no_depth_marker = C-&gt;unique();
3453   uint i;
3454   // Initialize depth to &quot;no depth yet&quot; and realize all lazy updates
3455   for (i = 0; i &lt; _idom_size; i++) {
3456     // Only indices with a _dom_depth has a Node* or NULL (otherwise uninitalized).
3457     if (_dom_depth[i] &gt; 0 &amp;&amp; _idom[i] != NULL) {
3458       _dom_depth[i] = no_depth_marker;
3459 
3460       // heal _idom if it has a fwd mapping in _nodes
3461       if (_idom[i]-&gt;in(0) == NULL) {
3462         idom(i);
3463       }
3464     }
3465   }
3466   if (_dom_stk == NULL) {
3467     uint init_size = C-&gt;live_nodes() / 100; // Guess that 1/100 is a reasonable initial size.
3468     if (init_size &lt; 10) init_size = 10;
3469     _dom_stk = new GrowableArray&lt;uint&gt;(init_size);
3470   }
3471   // Compute new depth for each node.
3472   for (i = 0; i &lt; _idom_size; i++) {
3473     uint j = i;
3474     // Run up the dom tree to find a node with a depth
3475     while (_dom_depth[j] == no_depth_marker) {
3476       _dom_stk-&gt;push(j);
3477       j = _idom[j]-&gt;_idx;
3478     }
3479     // Compute the depth on the way back down this tree branch
3480     uint dd = _dom_depth[j] + 1;
3481     while (_dom_stk-&gt;length() &gt; 0) {
3482       uint j = _dom_stk-&gt;pop();
3483       _dom_depth[j] = dd;
3484       dd++;
3485     }
3486   }
3487 }
3488 
3489 //------------------------------sort-------------------------------------------
3490 // Insert &#39;loop&#39; into the existing loop tree.  &#39;innermost&#39; is a leaf of the
3491 // loop tree, not the root.
3492 IdealLoopTree *PhaseIdealLoop::sort( IdealLoopTree *loop, IdealLoopTree *innermost ) {
3493   if( !innermost ) return loop; // New innermost loop
3494 
3495   int loop_preorder = get_preorder(loop-&gt;_head); // Cache pre-order number
3496   assert( loop_preorder, &quot;not yet post-walked loop&quot; );
3497   IdealLoopTree **pp = &amp;innermost;      // Pointer to previous next-pointer
3498   IdealLoopTree *l = *pp;               // Do I go before or after &#39;l&#39;?
3499 
3500   // Insert at start of list
3501   while( l ) {                  // Insertion sort based on pre-order
3502     if( l == loop ) return innermost; // Already on list!
3503     int l_preorder = get_preorder(l-&gt;_head); // Cache pre-order number
3504     assert( l_preorder, &quot;not yet post-walked l&quot; );
3505     // Check header pre-order number to figure proper nesting
3506     if( loop_preorder &gt; l_preorder )
3507       break;                    // End of insertion
3508     // If headers tie (e.g., shared headers) check tail pre-order numbers.
3509     // Since I split shared headers, you&#39;d think this could not happen.
3510     // BUT: I must first do the preorder numbering before I can discover I
3511     // have shared headers, so the split headers all get the same preorder
3512     // number as the RegionNode they split from.
3513     if( loop_preorder == l_preorder &amp;&amp;
3514         get_preorder(loop-&gt;_tail) &lt; get_preorder(l-&gt;_tail) )
3515       break;                    // Also check for shared headers (same pre#)
3516     pp = &amp;l-&gt;_parent;           // Chain up list
3517     l = *pp;
3518   }
3519   // Link into list
3520   // Point predecessor to me
3521   *pp = loop;
3522   // Point me to successor
3523   IdealLoopTree *p = loop-&gt;_parent;
3524   loop-&gt;_parent = l;            // Point me to successor
3525   if( p ) sort( p, innermost ); // Insert my parents into list as well
3526   return innermost;
3527 }
3528 
3529 //------------------------------build_loop_tree--------------------------------
3530 // I use a modified Vick/Tarjan algorithm.  I need pre- and a post- visit
3531 // bits.  The _nodes[] array is mapped by Node index and holds a NULL for
3532 // not-yet-pre-walked, pre-order # for pre-but-not-post-walked and holds the
3533 // tightest enclosing IdealLoopTree for post-walked.
3534 //
3535 // During my forward walk I do a short 1-layer lookahead to see if I can find
3536 // a loop backedge with that doesn&#39;t have any work on the backedge.  This
3537 // helps me construct nested loops with shared headers better.
3538 //
3539 // Once I&#39;ve done the forward recursion, I do the post-work.  For each child
3540 // I check to see if there is a backedge.  Backedges define a loop!  I
3541 // insert an IdealLoopTree at the target of the backedge.
3542 //
3543 // During the post-work I also check to see if I have several children
3544 // belonging to different loops.  If so, then this Node is a decision point
3545 // where control flow can choose to change loop nests.  It is at this
3546 // decision point where I can figure out how loops are nested.  At this
3547 // time I can properly order the different loop nests from my children.
3548 // Note that there may not be any backedges at the decision point!
3549 //
3550 // Since the decision point can be far removed from the backedges, I can&#39;t
3551 // order my loops at the time I discover them.  Thus at the decision point
3552 // I need to inspect loop header pre-order numbers to properly nest my
3553 // loops.  This means I need to sort my childrens&#39; loops by pre-order.
3554 // The sort is of size number-of-control-children, which generally limits
3555 // it to size 2 (i.e., I just choose between my 2 target loops).
3556 void PhaseIdealLoop::build_loop_tree() {
3557   // Allocate stack of size C-&gt;live_nodes()/2 to avoid frequent realloc
3558   GrowableArray &lt;Node *&gt; bltstack(C-&gt;live_nodes() &gt;&gt; 1);
3559   Node *n = C-&gt;root();
3560   bltstack.push(n);
3561   int pre_order = 1;
3562   int stack_size;
3563 
3564   while ( ( stack_size = bltstack.length() ) != 0 ) {
3565     n = bltstack.top(); // Leave node on stack
3566     if ( !is_visited(n) ) {
3567       // ---- Pre-pass Work ----
3568       // Pre-walked but not post-walked nodes need a pre_order number.
3569 
3570       set_preorder_visited( n, pre_order ); // set as visited
3571 
3572       // ---- Scan over children ----
3573       // Scan first over control projections that lead to loop headers.
3574       // This helps us find inner-to-outer loops with shared headers better.
3575 
3576       // Scan children&#39;s children for loop headers.
3577       for ( int i = n-&gt;outcnt() - 1; i &gt;= 0; --i ) {
3578         Node* m = n-&gt;raw_out(i);       // Child
3579         if( m-&gt;is_CFG() &amp;&amp; !is_visited(m) ) { // Only for CFG children
3580           // Scan over children&#39;s children to find loop
3581           for (DUIterator_Fast jmax, j = m-&gt;fast_outs(jmax); j &lt; jmax; j++) {
3582             Node* l = m-&gt;fast_out(j);
3583             if( is_visited(l) &amp;&amp;       // Been visited?
3584                 !is_postvisited(l) &amp;&amp;  // But not post-visited
3585                 get_preorder(l) &lt; pre_order ) { // And smaller pre-order
3586               // Found!  Scan the DFS down this path before doing other paths
3587               bltstack.push(m);
3588               break;
3589             }
3590           }
3591         }
3592       }
3593       pre_order++;
3594     }
3595     else if ( !is_postvisited(n) ) {
3596       // Note: build_loop_tree_impl() adds out edges on rare occasions,
3597       // such as com.sun.rsasign.am::a.
3598       // For non-recursive version, first, process current children.
3599       // On next iteration, check if additional children were added.
3600       for ( int k = n-&gt;outcnt() - 1; k &gt;= 0; --k ) {
3601         Node* u = n-&gt;raw_out(k);
3602         if ( u-&gt;is_CFG() &amp;&amp; !is_visited(u) ) {
3603           bltstack.push(u);
3604         }
3605       }
3606       if ( bltstack.length() == stack_size ) {
3607         // There were no additional children, post visit node now
3608         (void)bltstack.pop(); // Remove node from stack
3609         pre_order = build_loop_tree_impl( n, pre_order );
3610         // Check for bailout
3611         if (C-&gt;failing()) {
3612           return;
3613         }
3614         // Check to grow _preorders[] array for the case when
3615         // build_loop_tree_impl() adds new nodes.
3616         check_grow_preorders();
3617       }
3618     }
3619     else {
3620       (void)bltstack.pop(); // Remove post-visited node from stack
3621     }
3622   }
3623 }
3624 
3625 //------------------------------build_loop_tree_impl---------------------------
3626 int PhaseIdealLoop::build_loop_tree_impl( Node *n, int pre_order ) {
3627   // ---- Post-pass Work ----
3628   // Pre-walked but not post-walked nodes need a pre_order number.
3629 
3630   // Tightest enclosing loop for this Node
3631   IdealLoopTree *innermost = NULL;
3632 
3633   // For all children, see if any edge is a backedge.  If so, make a loop
3634   // for it.  Then find the tightest enclosing loop for the self Node.
3635   for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
3636     Node* m = n-&gt;fast_out(i);   // Child
3637     if( n == m ) continue;      // Ignore control self-cycles
3638     if( !m-&gt;is_CFG() ) continue;// Ignore non-CFG edges
3639 
3640     IdealLoopTree *l;           // Child&#39;s loop
3641     if( !is_postvisited(m) ) {  // Child visited but not post-visited?
3642       // Found a backedge
3643       assert( get_preorder(m) &lt; pre_order, &quot;should be backedge&quot; );
3644       // Check for the RootNode, which is already a LoopNode and is allowed
3645       // to have multiple &quot;backedges&quot;.
3646       if( m == C-&gt;root()) {     // Found the root?
3647         l = _ltree_root;        // Root is the outermost LoopNode
3648       } else {                  // Else found a nested loop
3649         // Insert a LoopNode to mark this loop.
3650         l = new IdealLoopTree(this, m, n);
3651       } // End of Else found a nested loop
3652       if( !has_loop(m) )        // If &#39;m&#39; does not already have a loop set
3653         set_loop(m, l);         // Set loop header to loop now
3654 
3655     } else {                    // Else not a nested loop
3656       if( !_nodes[m-&gt;_idx] ) continue; // Dead code has no loop
3657       l = get_loop(m);          // Get previously determined loop
3658       // If successor is header of a loop (nest), move up-loop till it
3659       // is a member of some outer enclosing loop.  Since there are no
3660       // shared headers (I&#39;ve split them already) I only need to go up
3661       // at most 1 level.
3662       while( l &amp;&amp; l-&gt;_head == m ) // Successor heads loop?
3663         l = l-&gt;_parent;         // Move up 1 for me
3664       // If this loop is not properly parented, then this loop
3665       // has no exit path out, i.e. its an infinite loop.
3666       if( !l ) {
3667         // Make loop &quot;reachable&quot; from root so the CFG is reachable.  Basically
3668         // insert a bogus loop exit that is never taken.  &#39;m&#39;, the loop head,
3669         // points to &#39;n&#39;, one (of possibly many) fall-in paths.  There may be
3670         // many backedges as well.
3671 
3672         // Here I set the loop to be the root loop.  I could have, after
3673         // inserting a bogus loop exit, restarted the recursion and found my
3674         // new loop exit.  This would make the infinite loop a first-class
3675         // loop and it would then get properly optimized.  What&#39;s the use of
3676         // optimizing an infinite loop?
3677         l = _ltree_root;        // Oops, found infinite loop
3678 
3679         if (!_verify_only) {
3680           // Insert the NeverBranch between &#39;m&#39; and it&#39;s control user.
3681           NeverBranchNode *iff = new NeverBranchNode( m );
3682           _igvn.register_new_node_with_optimizer(iff);
3683           set_loop(iff, l);
3684           Node *if_t = new CProjNode( iff, 0 );
3685           _igvn.register_new_node_with_optimizer(if_t);
3686           set_loop(if_t, l);
3687 
3688           Node* cfg = NULL;       // Find the One True Control User of m
3689           for (DUIterator_Fast jmax, j = m-&gt;fast_outs(jmax); j &lt; jmax; j++) {
3690             Node* x = m-&gt;fast_out(j);
3691             if (x-&gt;is_CFG() &amp;&amp; x != m &amp;&amp; x != iff)
3692               { cfg = x; break; }
3693           }
3694           assert(cfg != NULL, &quot;must find the control user of m&quot;);
3695           uint k = 0;             // Probably cfg-&gt;in(0)
3696           while( cfg-&gt;in(k) != m ) k++; // But check incase cfg is a Region
3697           cfg-&gt;set_req( k, if_t ); // Now point to NeverBranch
3698           _igvn._worklist.push(cfg);
3699 
3700           // Now create the never-taken loop exit
3701           Node *if_f = new CProjNode( iff, 1 );
3702           _igvn.register_new_node_with_optimizer(if_f);
3703           set_loop(if_f, l);
3704           // Find frame ptr for Halt.  Relies on the optimizer
3705           // V-N&#39;ing.  Easier and quicker than searching through
3706           // the program structure.
3707           Node *frame = new ParmNode( C-&gt;start(), TypeFunc::FramePtr );
3708           _igvn.register_new_node_with_optimizer(frame);
3709           // Halt &amp; Catch Fire
3710           Node* halt = new HaltNode(if_f, frame, &quot;never-taken loop exit reached&quot;);
3711           _igvn.register_new_node_with_optimizer(halt);
3712           set_loop(halt, l);
3713           C-&gt;root()-&gt;add_req(halt);
3714         }
3715         set_loop(C-&gt;root(), _ltree_root);
3716       }
3717     }
3718     // Weeny check for irreducible.  This child was already visited (this
3719     // IS the post-work phase).  Is this child&#39;s loop header post-visited
3720     // as well?  If so, then I found another entry into the loop.
3721     if (!_verify_only) {
3722       while( is_postvisited(l-&gt;_head) ) {
3723         // found irreducible
3724         l-&gt;_irreducible = 1; // = true
3725         l = l-&gt;_parent;
3726         _has_irreducible_loops = true;
3727         // Check for bad CFG here to prevent crash, and bailout of compile
3728         if (l == NULL) {
3729           C-&gt;record_method_not_compilable(&quot;unhandled CFG detected during loop optimization&quot;);
3730           return pre_order;
3731         }
3732       }
3733       C-&gt;set_has_irreducible_loop(_has_irreducible_loops);
3734     }
3735 
3736     // This Node might be a decision point for loops.  It is only if
3737     // it&#39;s children belong to several different loops.  The sort call
3738     // does a trivial amount of work if there is only 1 child or all
3739     // children belong to the same loop.  If however, the children
3740     // belong to different loops, the sort call will properly set the
3741     // _parent pointers to show how the loops nest.
3742     //
3743     // In any case, it returns the tightest enclosing loop.
3744     innermost = sort( l, innermost );
3745   }
3746 
3747   // Def-use info will have some dead stuff; dead stuff will have no
3748   // loop decided on.
3749 
3750   // Am I a loop header?  If so fix up my parent&#39;s child and next ptrs.
3751   if( innermost &amp;&amp; innermost-&gt;_head == n ) {
3752     assert( get_loop(n) == innermost, &quot;&quot; );
3753     IdealLoopTree *p = innermost-&gt;_parent;
3754     IdealLoopTree *l = innermost;
3755     while( p &amp;&amp; l-&gt;_head == n ) {
3756       l-&gt;_next = p-&gt;_child;     // Put self on parents &#39;next child&#39;
3757       p-&gt;_child = l;            // Make self as first child of parent
3758       l = p;                    // Now walk up the parent chain
3759       p = l-&gt;_parent;
3760     }
3761   } else {
3762     // Note that it is possible for a LoopNode to reach here, if the
3763     // backedge has been made unreachable (hence the LoopNode no longer
3764     // denotes a Loop, and will eventually be removed).
3765 
3766     // Record tightest enclosing loop for self.  Mark as post-visited.
3767     set_loop(n, innermost);
3768     // Also record has_call flag early on
3769     if( innermost ) {
3770       if( n-&gt;is_Call() &amp;&amp; !n-&gt;is_CallLeaf() &amp;&amp; !n-&gt;is_macro() ) {
3771         // Do not count uncommon calls
3772         if( !n-&gt;is_CallStaticJava() || !n-&gt;as_CallStaticJava()-&gt;_name ) {
3773           Node *iff = n-&gt;in(0)-&gt;in(0);
3774           // No any calls for vectorized loops.
3775           if( UseSuperWord || !iff-&gt;is_If() ||
3776               (n-&gt;in(0)-&gt;Opcode() == Op_IfFalse &amp;&amp;
3777                (1.0 - iff-&gt;as_If()-&gt;_prob) &gt;= 0.01) ||
3778               (iff-&gt;as_If()-&gt;_prob &gt;= 0.01) )
3779             innermost-&gt;_has_call = 1;
3780         }
3781       } else if( n-&gt;is_Allocate() &amp;&amp; n-&gt;as_Allocate()-&gt;_is_scalar_replaceable ) {
3782         // Disable loop optimizations if the loop has a scalar replaceable
3783         // allocation. This disabling may cause a potential performance lost
3784         // if the allocation is not eliminated for some reason.
3785         innermost-&gt;_allow_optimizations = false;
3786         innermost-&gt;_has_call = 1; // = true
3787       } else if (n-&gt;Opcode() == Op_SafePoint) {
3788         // Record all safepoints in this loop.
3789         if (innermost-&gt;_safepts == NULL) innermost-&gt;_safepts = new Node_List();
3790         innermost-&gt;_safepts-&gt;push(n);
3791       }
3792     }
3793   }
3794 
3795   // Flag as post-visited now
3796   set_postvisited(n);
3797   return pre_order;
3798 }
3799 
3800 
3801 //------------------------------build_loop_early-------------------------------
3802 // Put Data nodes into some loop nest, by setting the _nodes[]-&gt;loop mapping.
3803 // First pass computes the earliest controlling node possible.  This is the
3804 // controlling input with the deepest dominating depth.
3805 void PhaseIdealLoop::build_loop_early( VectorSet &amp;visited, Node_List &amp;worklist, Node_Stack &amp;nstack ) {
3806   while (worklist.size() != 0) {
3807     // Use local variables nstack_top_n &amp; nstack_top_i to cache values
3808     // on nstack&#39;s top.
3809     Node *nstack_top_n = worklist.pop();
3810     uint  nstack_top_i = 0;
3811 //while_nstack_nonempty:
3812     while (true) {
3813       // Get parent node and next input&#39;s index from stack&#39;s top.
3814       Node  *n = nstack_top_n;
3815       uint   i = nstack_top_i;
3816       uint cnt = n-&gt;req(); // Count of inputs
3817       if (i == 0) {        // Pre-process the node.
3818         if( has_node(n) &amp;&amp;            // Have either loop or control already?
3819             !has_ctrl(n) ) {          // Have loop picked out already?
3820           // During &quot;merge_many_backedges&quot; we fold up several nested loops
3821           // into a single loop.  This makes the members of the original
3822           // loop bodies pointing to dead loops; they need to move up
3823           // to the new UNION&#39;d larger loop.  I set the _head field of these
3824           // dead loops to NULL and the _parent field points to the owning
3825           // loop.  Shades of UNION-FIND algorithm.
3826           IdealLoopTree *ilt;
3827           while( !(ilt = get_loop(n))-&gt;_head ) {
3828             // Normally I would use a set_loop here.  But in this one special
3829             // case, it is legal (and expected) to change what loop a Node
3830             // belongs to.
3831             _nodes.map(n-&gt;_idx, (Node*)(ilt-&gt;_parent) );
3832           }
3833           // Remove safepoints ONLY if I&#39;ve already seen I don&#39;t need one.
3834           // (the old code here would yank a 2nd safepoint after seeing a
3835           // first one, even though the 1st did not dominate in the loop body
3836           // and thus could be avoided indefinitely)
3837           if( !_verify_only &amp;&amp; !_verify_me &amp;&amp; ilt-&gt;_has_sfpt &amp;&amp; n-&gt;Opcode() == Op_SafePoint &amp;&amp;
3838               is_deleteable_safept(n)) {
3839             Node *in = n-&gt;in(TypeFunc::Control);
3840             lazy_replace(n,in);       // Pull safepoint now
3841             if (ilt-&gt;_safepts != NULL) {
3842               ilt-&gt;_safepts-&gt;yank(n);
3843             }
3844             // Carry on with the recursion &quot;as if&quot; we are walking
3845             // only the control input
3846             if( !visited.test_set( in-&gt;_idx ) ) {
3847               worklist.push(in);      // Visit this guy later, using worklist
3848             }
3849             // Get next node from nstack:
3850             // - skip n&#39;s inputs processing by setting i &gt; cnt;
3851             // - we also will not call set_early_ctrl(n) since
3852             //   has_node(n) == true (see the condition above).
3853             i = cnt + 1;
3854           }
3855         }
3856       } // if (i == 0)
3857 
3858       // Visit all inputs
3859       bool done = true;       // Assume all n&#39;s inputs will be processed
3860       while (i &lt; cnt) {
3861         Node *in = n-&gt;in(i);
3862         ++i;
3863         if (in == NULL) continue;
3864         if (in-&gt;pinned() &amp;&amp; !in-&gt;is_CFG())
3865           set_ctrl(in, in-&gt;in(0));
3866         int is_visited = visited.test_set( in-&gt;_idx );
3867         if (!has_node(in)) {  // No controlling input yet?
3868           assert( !in-&gt;is_CFG(), &quot;CFG Node with no controlling input?&quot; );
3869           assert( !is_visited, &quot;visit only once&quot; );
3870           nstack.push(n, i);  // Save parent node and next input&#39;s index.
3871           nstack_top_n = in;  // Process current input now.
3872           nstack_top_i = 0;
3873           done = false;       // Not all n&#39;s inputs processed.
3874           break; // continue while_nstack_nonempty;
3875         } else if (!is_visited) {
3876           // This guy has a location picked out for him, but has not yet
3877           // been visited.  Happens to all CFG nodes, for instance.
3878           // Visit him using the worklist instead of recursion, to break
3879           // cycles.  Since he has a location already we do not need to
3880           // find his location before proceeding with the current Node.
3881           worklist.push(in);  // Visit this guy later, using worklist
3882         }
3883       }
3884       if (done) {
3885         // All of n&#39;s inputs have been processed, complete post-processing.
3886 
3887         // Compute earliest point this Node can go.
3888         // CFG, Phi, pinned nodes already know their controlling input.
3889         if (!has_node(n)) {
3890           // Record earliest legal location
3891           set_early_ctrl( n );
3892         }
3893         if (nstack.is_empty()) {
3894           // Finished all nodes on stack.
3895           // Process next node on the worklist.
3896           break;
3897         }
3898         // Get saved parent node and next input&#39;s index.
3899         nstack_top_n = nstack.node();
3900         nstack_top_i = nstack.index();
3901         nstack.pop();
3902       }
3903     } // while (true)
3904   }
3905 }
3906 
3907 //------------------------------dom_lca_internal--------------------------------
3908 // Pair-wise LCA
3909 Node *PhaseIdealLoop::dom_lca_internal( Node *n1, Node *n2 ) const {
3910   if( !n1 ) return n2;          // Handle NULL original LCA
3911   assert( n1-&gt;is_CFG(), &quot;&quot; );
3912   assert( n2-&gt;is_CFG(), &quot;&quot; );
3913   // find LCA of all uses
3914   uint d1 = dom_depth(n1);
3915   uint d2 = dom_depth(n2);
3916   while (n1 != n2) {
3917     if (d1 &gt; d2) {
3918       n1 =      idom(n1);
3919       d1 = dom_depth(n1);
3920     } else if (d1 &lt; d2) {
3921       n2 =      idom(n2);
3922       d2 = dom_depth(n2);
3923     } else {
3924       // Here d1 == d2.  Due to edits of the dominator-tree, sections
3925       // of the tree might have the same depth.  These sections have
3926       // to be searched more carefully.
3927 
3928       // Scan up all the n1&#39;s with equal depth, looking for n2.
3929       Node *t1 = idom(n1);
3930       while (dom_depth(t1) == d1) {
3931         if (t1 == n2)  return n2;
3932         t1 = idom(t1);
3933       }
3934       // Scan up all the n2&#39;s with equal depth, looking for n1.
3935       Node *t2 = idom(n2);
3936       while (dom_depth(t2) == d2) {
3937         if (t2 == n1)  return n1;
3938         t2 = idom(t2);
3939       }
3940       // Move up to a new dominator-depth value as well as up the dom-tree.
3941       n1 = t1;
3942       n2 = t2;
3943       d1 = dom_depth(n1);
3944       d2 = dom_depth(n2);
3945     }
3946   }
3947   return n1;
3948 }
3949 
3950 //------------------------------compute_idom-----------------------------------
3951 // Locally compute IDOM using dom_lca call.  Correct only if the incoming
3952 // IDOMs are correct.
3953 Node *PhaseIdealLoop::compute_idom( Node *region ) const {
3954   assert( region-&gt;is_Region(), &quot;&quot; );
3955   Node *LCA = NULL;
3956   for( uint i = 1; i &lt; region-&gt;req(); i++ ) {
3957     if( region-&gt;in(i) != C-&gt;top() )
3958       LCA = dom_lca( LCA, region-&gt;in(i) );
3959   }
3960   return LCA;
3961 }
3962 
3963 bool PhaseIdealLoop::verify_dominance(Node* n, Node* use, Node* LCA, Node* early) {
3964   bool had_error = false;
3965 #ifdef ASSERT
3966   if (early != C-&gt;root()) {
3967     // Make sure that there&#39;s a dominance path from LCA to early
3968     Node* d = LCA;
3969     while (d != early) {
3970       if (d == C-&gt;root()) {
3971         dump_bad_graph(&quot;Bad graph detected in compute_lca_of_uses&quot;, n, early, LCA);
3972         tty-&gt;print_cr(&quot;*** Use %d isn&#39;t dominated by def %d ***&quot;, use-&gt;_idx, n-&gt;_idx);
3973         had_error = true;
3974         break;
3975       }
3976       d = idom(d);
3977     }
3978   }
3979 #endif
3980   return had_error;
3981 }
3982 
3983 
3984 Node* PhaseIdealLoop::compute_lca_of_uses(Node* n, Node* early, bool verify) {
3985   // Compute LCA over list of uses
3986   bool had_error = false;
3987   Node *LCA = NULL;
3988   for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax &amp;&amp; LCA != early; i++) {
3989     Node* c = n-&gt;fast_out(i);
3990     if (_nodes[c-&gt;_idx] == NULL)
3991       continue;                 // Skip the occasional dead node
3992     if( c-&gt;is_Phi() ) {         // For Phis, we must land above on the path
3993       for( uint j=1; j&lt;c-&gt;req(); j++ ) {// For all inputs
3994         if( c-&gt;in(j) == n ) {   // Found matching input?
3995           Node *use = c-&gt;in(0)-&gt;in(j);
3996           if (_verify_only &amp;&amp; use-&gt;is_top()) continue;
3997           LCA = dom_lca_for_get_late_ctrl( LCA, use, n );
3998           if (verify) had_error = verify_dominance(n, use, LCA, early) || had_error;
3999         }
4000       }
4001     } else {
4002       // For CFG data-users, use is in the block just prior
4003       Node *use = has_ctrl(c) ? get_ctrl(c) : c-&gt;in(0);
4004       LCA = dom_lca_for_get_late_ctrl( LCA, use, n );
4005       if (verify) had_error = verify_dominance(n, use, LCA, early) || had_error;
4006     }
4007   }
4008   assert(!had_error, &quot;bad dominance&quot;);
4009   return LCA;
4010 }
4011 
4012 // Check the shape of the graph at the loop entry. In some cases,
4013 // the shape of the graph does not match the shape outlined below.
4014 // That is caused by the Opaque1 node &quot;protecting&quot; the shape of
4015 // the graph being removed by, for example, the IGVN performed
4016 // in PhaseIdealLoop::build_and_optimize().
4017 //
4018 // After the Opaque1 node has been removed, optimizations (e.g., split-if,
4019 // loop unswitching, and IGVN, or a combination of them) can freely change
4020 // the graph&#39;s shape. As a result, the graph shape outlined below cannot
4021 // be guaranteed anymore.
4022 bool PhaseIdealLoop::is_canonical_loop_entry(CountedLoopNode* cl) {
4023   if (!cl-&gt;is_main_loop() &amp;&amp; !cl-&gt;is_post_loop()) {
4024     return false;
4025   }
4026   Node* ctrl = cl-&gt;skip_predicates();
4027 
4028   if (ctrl == NULL || (!ctrl-&gt;is_IfTrue() &amp;&amp; !ctrl-&gt;is_IfFalse())) {
4029     return false;
4030   }
4031   Node* iffm = ctrl-&gt;in(0);
4032   if (iffm == NULL || !iffm-&gt;is_If()) {
4033     return false;
4034   }
4035   Node* bolzm = iffm-&gt;in(1);
4036   if (bolzm == NULL || !bolzm-&gt;is_Bool()) {
4037     return false;
4038   }
4039   Node* cmpzm = bolzm-&gt;in(1);
4040   if (cmpzm == NULL || !cmpzm-&gt;is_Cmp()) {
4041     return false;
4042   }
4043   // compares can get conditionally flipped
4044   bool found_opaque = false;
4045   for (uint i = 1; i &lt; cmpzm-&gt;req(); i++) {
4046     Node* opnd = cmpzm-&gt;in(i);
4047     if (opnd &amp;&amp; opnd-&gt;Opcode() == Op_Opaque1) {
4048       found_opaque = true;
4049       break;
4050     }
4051   }
4052   if (!found_opaque) {
4053     return false;
4054   }
4055   return true;
4056 }
4057 
4058 //------------------------------get_late_ctrl----------------------------------
4059 // Compute latest legal control.
4060 Node *PhaseIdealLoop::get_late_ctrl( Node *n, Node *early ) {
4061   assert(early != NULL, &quot;early control should not be NULL&quot;);
4062 
4063   Node* LCA = compute_lca_of_uses(n, early);
4064 #ifdef ASSERT
4065   if (LCA == C-&gt;root() &amp;&amp; LCA != early) {
4066     // def doesn&#39;t dominate uses so print some useful debugging output
4067     compute_lca_of_uses(n, early, true);
4068   }
4069 #endif
4070 
4071   // if this is a load, check for anti-dependent stores
4072   // We use a conservative algorithm to identify potential interfering
4073   // instructions and for rescheduling the load.  The users of the memory
4074   // input of this load are examined.  Any use which is not a load and is
4075   // dominated by early is considered a potentially interfering store.
4076   // This can produce false positives.
4077   if (n-&gt;is_Load() &amp;&amp; LCA != early) {
4078     int load_alias_idx = C-&gt;get_alias_index(n-&gt;adr_type());
4079     if (C-&gt;alias_type(load_alias_idx)-&gt;is_rewritable()) {
4080 
4081       Node_List worklist;
4082 
4083       Node *mem = n-&gt;in(MemNode::Memory);
4084       for (DUIterator_Fast imax, i = mem-&gt;fast_outs(imax); i &lt; imax; i++) {
4085         Node* s = mem-&gt;fast_out(i);
4086         worklist.push(s);
4087       }
4088       while(worklist.size() != 0 &amp;&amp; LCA != early) {
4089         Node* s = worklist.pop();
4090         if (s-&gt;is_Load() || s-&gt;Opcode() == Op_SafePoint ||
4091             (s-&gt;is_CallStaticJava() &amp;&amp; s-&gt;as_CallStaticJava()-&gt;uncommon_trap_request() != 0)) {
4092           continue;
4093         } else if (s-&gt;is_MergeMem()) {
4094           for (DUIterator_Fast imax, i = s-&gt;fast_outs(imax); i &lt; imax; i++) {
4095             Node* s1 = s-&gt;fast_out(i);
4096             worklist.push(s1);
4097           }
4098         } else {
4099           Node *sctrl = has_ctrl(s) ? get_ctrl(s) : s-&gt;in(0);
4100           const TypePtr* adr_type = s-&gt;adr_type();
4101           if (s-&gt;is_ArrayCopy()) {
4102             // Copy to known instance needs destination type to test for aliasing
4103             const TypePtr* dest_type = s-&gt;as_ArrayCopy()-&gt;_dest_type;
4104             if (dest_type != TypeOopPtr::BOTTOM) {
4105               adr_type = dest_type;
4106             }
4107           }
4108           assert(sctrl != NULL || !s-&gt;is_reachable_from_root(), &quot;must have control&quot;);
4109           if (sctrl != NULL &amp;&amp; !sctrl-&gt;is_top() &amp;&amp; C-&gt;can_alias(adr_type, load_alias_idx) &amp;&amp; is_dominator(early, sctrl)) {
4110             LCA = dom_lca_for_get_late_ctrl(LCA, sctrl, n);
4111           }
4112         }
4113       }
4114     }
4115   }
4116 
4117   assert(LCA == find_non_split_ctrl(LCA), &quot;unexpected late control&quot;);
4118   return LCA;
4119 }
4120 
4121 // true if CFG node d dominates CFG node n
4122 bool PhaseIdealLoop::is_dominator(Node *d, Node *n) {
4123   if (d == n)
4124     return true;
4125   assert(d-&gt;is_CFG() &amp;&amp; n-&gt;is_CFG(), &quot;must have CFG nodes&quot;);
4126   uint dd = dom_depth(d);
4127   while (dom_depth(n) &gt;= dd) {
4128     if (n == d)
4129       return true;
4130     n = idom(n);
4131   }
4132   return false;
4133 }
4134 
4135 //------------------------------dom_lca_for_get_late_ctrl_internal-------------
4136 // Pair-wise LCA with tags.
4137 // Tag each index with the node &#39;tag&#39; currently being processed
4138 // before advancing up the dominator chain using idom().
4139 // Later calls that find a match to &#39;tag&#39; know that this path has already
4140 // been considered in the current LCA (which is input &#39;n1&#39; by convention).
4141 // Since get_late_ctrl() is only called once for each node, the tag array
4142 // does not need to be cleared between calls to get_late_ctrl().
4143 // Algorithm trades a larger constant factor for better asymptotic behavior
4144 //
4145 Node *PhaseIdealLoop::dom_lca_for_get_late_ctrl_internal( Node *n1, Node *n2, Node *tag ) {
4146   uint d1 = dom_depth(n1);
4147   uint d2 = dom_depth(n2);
4148 
4149   do {
4150     if (d1 &gt; d2) {
4151       // current lca is deeper than n2
4152       _dom_lca_tags.map(n1-&gt;_idx, tag);
4153       n1 =      idom(n1);
4154       d1 = dom_depth(n1);
4155     } else if (d1 &lt; d2) {
4156       // n2 is deeper than current lca
4157       Node *memo = _dom_lca_tags[n2-&gt;_idx];
4158       if( memo == tag ) {
4159         return n1;    // Return the current LCA
4160       }
4161       _dom_lca_tags.map(n2-&gt;_idx, tag);
4162       n2 =      idom(n2);
4163       d2 = dom_depth(n2);
4164     } else {
4165       // Here d1 == d2.  Due to edits of the dominator-tree, sections
4166       // of the tree might have the same depth.  These sections have
4167       // to be searched more carefully.
4168 
4169       // Scan up all the n1&#39;s with equal depth, looking for n2.
4170       _dom_lca_tags.map(n1-&gt;_idx, tag);
4171       Node *t1 = idom(n1);
4172       while (dom_depth(t1) == d1) {
4173         if (t1 == n2)  return n2;
4174         _dom_lca_tags.map(t1-&gt;_idx, tag);
4175         t1 = idom(t1);
4176       }
4177       // Scan up all the n2&#39;s with equal depth, looking for n1.
4178       _dom_lca_tags.map(n2-&gt;_idx, tag);
4179       Node *t2 = idom(n2);
4180       while (dom_depth(t2) == d2) {
4181         if (t2 == n1)  return n1;
4182         _dom_lca_tags.map(t2-&gt;_idx, tag);
4183         t2 = idom(t2);
4184       }
4185       // Move up to a new dominator-depth value as well as up the dom-tree.
4186       n1 = t1;
4187       n2 = t2;
4188       d1 = dom_depth(n1);
4189       d2 = dom_depth(n2);
4190     }
4191   } while (n1 != n2);
4192   return n1;
4193 }
4194 
4195 //------------------------------init_dom_lca_tags------------------------------
4196 // Tag could be a node&#39;s integer index, 32bits instead of 64bits in some cases
4197 // Intended use does not involve any growth for the array, so it could
4198 // be of fixed size.
4199 void PhaseIdealLoop::init_dom_lca_tags() {
4200   uint limit = C-&gt;unique() + 1;
4201   _dom_lca_tags.map( limit, NULL );
4202 #ifdef ASSERT
4203   for( uint i = 0; i &lt; limit; ++i ) {
4204     assert(_dom_lca_tags[i] == NULL, &quot;Must be distinct from each node pointer&quot;);
4205   }
4206 #endif // ASSERT
4207 }
4208 
4209 //------------------------------clear_dom_lca_tags------------------------------
4210 // Tag could be a node&#39;s integer index, 32bits instead of 64bits in some cases
4211 // Intended use does not involve any growth for the array, so it could
4212 // be of fixed size.
4213 void PhaseIdealLoop::clear_dom_lca_tags() {
4214   uint limit = C-&gt;unique() + 1;
4215   _dom_lca_tags.map( limit, NULL );
4216   _dom_lca_tags.clear();
4217 #ifdef ASSERT
4218   for( uint i = 0; i &lt; limit; ++i ) {
4219     assert(_dom_lca_tags[i] == NULL, &quot;Must be distinct from each node pointer&quot;);
4220   }
4221 #endif // ASSERT
4222 }
4223 
4224 //------------------------------build_loop_late--------------------------------
4225 // Put Data nodes into some loop nest, by setting the _nodes[]-&gt;loop mapping.
4226 // Second pass finds latest legal placement, and ideal loop placement.
4227 void PhaseIdealLoop::build_loop_late( VectorSet &amp;visited, Node_List &amp;worklist, Node_Stack &amp;nstack ) {
4228   while (worklist.size() != 0) {
4229     Node *n = worklist.pop();
4230     // Only visit once
4231     if (visited.test_set(n-&gt;_idx)) continue;
4232     uint cnt = n-&gt;outcnt();
4233     uint   i = 0;
4234     while (true) {
4235       assert( _nodes[n-&gt;_idx], &quot;no dead nodes&quot; );
4236       // Visit all children
4237       if (i &lt; cnt) {
4238         Node* use = n-&gt;raw_out(i);
4239         ++i;
4240         // Check for dead uses.  Aggressively prune such junk.  It might be
4241         // dead in the global sense, but still have local uses so I cannot
4242         // easily call &#39;remove_dead_node&#39;.
4243         if( _nodes[use-&gt;_idx] != NULL || use-&gt;is_top() ) { // Not dead?
4244           // Due to cycles, we might not hit the same fixed point in the verify
4245           // pass as we do in the regular pass.  Instead, visit such phis as
4246           // simple uses of the loop head.
4247           if( use-&gt;in(0) &amp;&amp; (use-&gt;is_CFG() || use-&gt;is_Phi()) ) {
4248             if( !visited.test(use-&gt;_idx) )
4249               worklist.push(use);
4250           } else if( !visited.test_set(use-&gt;_idx) ) {
4251             nstack.push(n, i); // Save parent and next use&#39;s index.
4252             n   = use;         // Process all children of current use.
4253             cnt = use-&gt;outcnt();
4254             i   = 0;
4255           }
4256         } else {
4257           // Do not visit around the backedge of loops via data edges.
4258           // push dead code onto a worklist
4259           _deadlist.push(use);
4260         }
4261       } else {
4262         // All of n&#39;s children have been processed, complete post-processing.
4263         build_loop_late_post(n);
4264         if (nstack.is_empty()) {
4265           // Finished all nodes on stack.
4266           // Process next node on the worklist.
4267           break;
4268         }
4269         // Get saved parent node and next use&#39;s index. Visit the rest of uses.
4270         n   = nstack.node();
4271         cnt = n-&gt;outcnt();
4272         i   = nstack.index();
4273         nstack.pop();
4274       }
4275     }
4276   }
4277 }
4278 
4279 // Verify that no data node is scheduled in the outer loop of a strip
4280 // mined loop.
4281 void PhaseIdealLoop::verify_strip_mined_scheduling(Node *n, Node* least) {
4282 #ifdef ASSERT
4283   if (get_loop(least)-&gt;_nest == 0) {
4284     return;
4285   }
4286   IdealLoopTree* loop = get_loop(least);
4287   Node* head = loop-&gt;_head;
4288   if (head-&gt;is_OuterStripMinedLoop() &amp;&amp;
4289       // Verification can&#39;t be applied to fully built strip mined loops
4290       head-&gt;as_Loop()-&gt;outer_loop_end()-&gt;in(1)-&gt;find_int_con(-1) == 0) {
4291     Node* sfpt = head-&gt;as_Loop()-&gt;outer_safepoint();
4292     ResourceMark rm;
4293     Unique_Node_List wq;
4294     wq.push(sfpt);
4295     for (uint i = 0; i &lt; wq.size(); i++) {
4296       Node *m = wq.at(i);
4297       for (uint i = 1; i &lt; m-&gt;req(); i++) {
4298         Node* nn = m-&gt;in(i);
4299         if (nn == n) {
4300           return;
4301         }
4302         if (nn != NULL &amp;&amp; has_ctrl(nn) &amp;&amp; get_loop(get_ctrl(nn)) == loop) {
4303           wq.push(nn);
4304         }
4305       }
4306     }
4307     ShouldNotReachHere();
4308   }
4309 #endif
4310 }
4311 
4312 
4313 //------------------------------build_loop_late_post---------------------------
4314 // Put Data nodes into some loop nest, by setting the _nodes[]-&gt;loop mapping.
4315 // Second pass finds latest legal placement, and ideal loop placement.
4316 void PhaseIdealLoop::build_loop_late_post(Node *n) {
4317   build_loop_late_post_work(n, true);
4318 }
4319 
4320 void PhaseIdealLoop::build_loop_late_post_work(Node *n, bool pinned) {
4321 
4322   if (n-&gt;req() == 2 &amp;&amp; (n-&gt;Opcode() == Op_ConvI2L || n-&gt;Opcode() == Op_CastII) &amp;&amp; !C-&gt;major_progress() &amp;&amp; !_verify_only) {
4323     _igvn._worklist.push(n);  // Maybe we&#39;ll normalize it, if no more loops.
4324   }
4325 
4326 #ifdef ASSERT
4327   if (_verify_only &amp;&amp; !n-&gt;is_CFG()) {
4328     // Check def-use domination.
4329     compute_lca_of_uses(n, get_ctrl(n), true /* verify */);
4330   }
4331 #endif
4332 
4333   // CFG and pinned nodes already handled
4334   if( n-&gt;in(0) ) {
4335     if( n-&gt;in(0)-&gt;is_top() ) return; // Dead?
4336 
4337     // We&#39;d like +VerifyLoopOptimizations to not believe that Mod&#39;s/Loads
4338     // _must_ be pinned (they have to observe their control edge of course).
4339     // Unlike Stores (which modify an unallocable resource, the memory
4340     // state), Mods/Loads can float around.  So free them up.
4341     switch( n-&gt;Opcode() ) {
4342     case Op_DivI:
4343     case Op_DivF:
4344     case Op_DivD:
4345     case Op_ModI:
4346     case Op_ModF:
4347     case Op_ModD:
4348     case Op_LoadB:              // Same with Loads; they can sink
4349     case Op_LoadUB:             // during loop optimizations.
4350     case Op_LoadUS:
4351     case Op_LoadD:
4352     case Op_LoadF:
4353     case Op_LoadI:
4354     case Op_LoadKlass:
4355     case Op_LoadNKlass:
4356     case Op_LoadL:
4357     case Op_LoadS:
4358     case Op_LoadP:
4359     case Op_LoadN:
4360     case Op_LoadRange:
4361     case Op_LoadD_unaligned:
4362     case Op_LoadL_unaligned:
4363     case Op_StrComp:            // Does a bunch of load-like effects
4364     case Op_StrEquals:
4365     case Op_StrIndexOf:
4366     case Op_StrIndexOfChar:
4367     case Op_AryEq:
4368     case Op_HasNegatives:
4369       pinned = false;
4370     }
4371     if (n-&gt;is_CMove()) {
4372       pinned = false;
4373     }
4374     if( pinned ) {
4375       IdealLoopTree *chosen_loop = get_loop(n-&gt;is_CFG() ? n : get_ctrl(n));
4376       if( !chosen_loop-&gt;_child )       // Inner loop?
4377         chosen_loop-&gt;_body.push(n); // Collect inner loops
4378       return;
4379     }
4380   } else {                      // No slot zero
4381     if( n-&gt;is_CFG() ) {         // CFG with no slot 0 is dead
4382       _nodes.map(n-&gt;_idx,0);    // No block setting, it&#39;s globally dead
4383       return;
4384     }
4385     assert(!n-&gt;is_CFG() || n-&gt;outcnt() == 0, &quot;&quot;);
4386   }
4387 
4388   // Do I have a &quot;safe range&quot; I can select over?
4389   Node *early = get_ctrl(n);// Early location already computed
4390 
4391   // Compute latest point this Node can go
4392   Node *LCA = get_late_ctrl( n, early );
4393   // LCA is NULL due to uses being dead
4394   if( LCA == NULL ) {
4395 #ifdef ASSERT
4396     for (DUIterator i1 = n-&gt;outs(); n-&gt;has_out(i1); i1++) {
4397       assert( _nodes[n-&gt;out(i1)-&gt;_idx] == NULL, &quot;all uses must also be dead&quot;);
4398     }
4399 #endif
4400     _nodes.map(n-&gt;_idx, 0);     // This node is useless
4401     _deadlist.push(n);
4402     return;
4403   }
4404   assert(LCA != NULL &amp;&amp; !LCA-&gt;is_top(), &quot;no dead nodes&quot;);
4405 
4406   Node *legal = LCA;            // Walk &#39;legal&#39; up the IDOM chain
4407   Node *least = legal;          // Best legal position so far
4408   while( early != legal ) {     // While not at earliest legal
4409 #ifdef ASSERT
4410     if (legal-&gt;is_Start() &amp;&amp; !early-&gt;is_Root()) {
4411       // Bad graph. Print idom path and fail.
4412       dump_bad_graph(&quot;Bad graph detected in build_loop_late&quot;, n, early, LCA);
4413       assert(false, &quot;Bad graph detected in build_loop_late&quot;);
4414     }
4415 #endif
4416     // Find least loop nesting depth
4417     legal = idom(legal);        // Bump up the IDOM tree
4418     // Check for lower nesting depth
4419     if( get_loop(legal)-&gt;_nest &lt; get_loop(least)-&gt;_nest )
4420       least = legal;
4421   }
4422   assert(early == legal || legal != C-&gt;root(), &quot;bad dominance of inputs&quot;);
4423 
4424   // Try not to place code on a loop entry projection
4425   // which can inhibit range check elimination.
4426   if (least != early) {
4427     Node* ctrl_out = least-&gt;unique_ctrl_out();
4428     if (ctrl_out &amp;&amp; ctrl_out-&gt;is_Loop() &amp;&amp;
4429         least == ctrl_out-&gt;in(LoopNode::EntryControl)) {
4430       // Move the node above predicates as far up as possible so a
4431       // following pass of loop predication doesn&#39;t hoist a predicate
4432       // that depends on it above that node.
4433       Node* new_ctrl = least;
4434       for (;;) {
4435         if (!new_ctrl-&gt;is_Proj()) {
4436           break;
4437         }
4438         CallStaticJavaNode* call = new_ctrl-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none);
4439         if (call == NULL) {
4440           break;
4441         }
4442         int req = call-&gt;uncommon_trap_request();
4443         Deoptimization::DeoptReason trap_reason = Deoptimization::trap_request_reason(req);
4444         if (trap_reason != Deoptimization::Reason_loop_limit_check &amp;&amp;
4445             trap_reason != Deoptimization::Reason_predicate &amp;&amp;
4446             trap_reason != Deoptimization::Reason_profile_predicate) {
4447           break;
4448         }
4449         Node* c = new_ctrl-&gt;in(0)-&gt;in(0);
4450         if (is_dominator(c, early) &amp;&amp; c != early) {
4451           break;
4452         }
4453         new_ctrl = c;
4454       }
4455       least = new_ctrl;
4456     }
4457   }
4458 
4459 #ifdef ASSERT
4460   // If verifying, verify that &#39;verify_me&#39; has a legal location
4461   // and choose it as our location.
4462   if( _verify_me ) {
4463     Node *v_ctrl = _verify_me-&gt;get_ctrl_no_update(n);
4464     Node *legal = LCA;
4465     while( early != legal ) {   // While not at earliest legal
4466       if( legal == v_ctrl ) break;  // Check for prior good location
4467       legal = idom(legal)      ;// Bump up the IDOM tree
4468     }
4469     // Check for prior good location
4470     if( legal == v_ctrl ) least = legal; // Keep prior if found
4471   }
4472 #endif
4473 
4474   // Assign discovered &quot;here or above&quot; point
4475   least = find_non_split_ctrl(least);
4476   verify_strip_mined_scheduling(n, least);
4477   set_ctrl(n, least);
4478 
4479   // Collect inner loop bodies
4480   IdealLoopTree *chosen_loop = get_loop(least);
4481   if( !chosen_loop-&gt;_child )   // Inner loop?
4482     chosen_loop-&gt;_body.push(n);// Collect inner loops
4483 }
4484 
4485 #ifdef ASSERT
4486 void PhaseIdealLoop::dump_bad_graph(const char* msg, Node* n, Node* early, Node* LCA) {
4487   tty-&gt;print_cr(&quot;%s&quot;, msg);
4488   tty-&gt;print(&quot;n: &quot;); n-&gt;dump();
4489   tty-&gt;print(&quot;early(n): &quot;); early-&gt;dump();
4490   if (n-&gt;in(0) != NULL  &amp;&amp; !n-&gt;in(0)-&gt;is_top() &amp;&amp;
4491       n-&gt;in(0) != early &amp;&amp; !n-&gt;in(0)-&gt;is_Root()) {
4492     tty-&gt;print(&quot;n-&gt;in(0): &quot;); n-&gt;in(0)-&gt;dump();
4493   }
4494   for (uint i = 1; i &lt; n-&gt;req(); i++) {
4495     Node* in1 = n-&gt;in(i);
4496     if (in1 != NULL &amp;&amp; in1 != n &amp;&amp; !in1-&gt;is_top()) {
4497       tty-&gt;print(&quot;n-&gt;in(%d): &quot;, i); in1-&gt;dump();
4498       Node* in1_early = get_ctrl(in1);
4499       tty-&gt;print(&quot;early(n-&gt;in(%d)): &quot;, i); in1_early-&gt;dump();
4500       if (in1-&gt;in(0) != NULL     &amp;&amp; !in1-&gt;in(0)-&gt;is_top() &amp;&amp;
4501           in1-&gt;in(0) != in1_early &amp;&amp; !in1-&gt;in(0)-&gt;is_Root()) {
4502         tty-&gt;print(&quot;n-&gt;in(%d)-&gt;in(0): &quot;, i); in1-&gt;in(0)-&gt;dump();
4503       }
4504       for (uint j = 1; j &lt; in1-&gt;req(); j++) {
4505         Node* in2 = in1-&gt;in(j);
4506         if (in2 != NULL &amp;&amp; in2 != n &amp;&amp; in2 != in1 &amp;&amp; !in2-&gt;is_top()) {
4507           tty-&gt;print(&quot;n-&gt;in(%d)-&gt;in(%d): &quot;, i, j); in2-&gt;dump();
4508           Node* in2_early = get_ctrl(in2);
4509           tty-&gt;print(&quot;early(n-&gt;in(%d)-&gt;in(%d)): &quot;, i, j); in2_early-&gt;dump();
4510           if (in2-&gt;in(0) != NULL     &amp;&amp; !in2-&gt;in(0)-&gt;is_top() &amp;&amp;
4511               in2-&gt;in(0) != in2_early &amp;&amp; !in2-&gt;in(0)-&gt;is_Root()) {
4512             tty-&gt;print(&quot;n-&gt;in(%d)-&gt;in(%d)-&gt;in(0): &quot;, i, j); in2-&gt;in(0)-&gt;dump();
4513           }
4514         }
4515       }
4516     }
4517   }
4518   tty-&gt;cr();
4519   tty-&gt;print(&quot;LCA(n): &quot;); LCA-&gt;dump();
4520   for (uint i = 0; i &lt; n-&gt;outcnt(); i++) {
4521     Node* u1 = n-&gt;raw_out(i);
4522     if (u1 == n)
4523       continue;
4524     tty-&gt;print(&quot;n-&gt;out(%d): &quot;, i); u1-&gt;dump();
4525     if (u1-&gt;is_CFG()) {
4526       for (uint j = 0; j &lt; u1-&gt;outcnt(); j++) {
4527         Node* u2 = u1-&gt;raw_out(j);
4528         if (u2 != u1 &amp;&amp; u2 != n &amp;&amp; u2-&gt;is_CFG()) {
4529           tty-&gt;print(&quot;n-&gt;out(%d)-&gt;out(%d): &quot;, i, j); u2-&gt;dump();
4530         }
4531       }
4532     } else {
4533       Node* u1_later = get_ctrl(u1);
4534       tty-&gt;print(&quot;later(n-&gt;out(%d)): &quot;, i); u1_later-&gt;dump();
4535       if (u1-&gt;in(0) != NULL     &amp;&amp; !u1-&gt;in(0)-&gt;is_top() &amp;&amp;
4536           u1-&gt;in(0) != u1_later &amp;&amp; !u1-&gt;in(0)-&gt;is_Root()) {
4537         tty-&gt;print(&quot;n-&gt;out(%d)-&gt;in(0): &quot;, i); u1-&gt;in(0)-&gt;dump();
4538       }
4539       for (uint j = 0; j &lt; u1-&gt;outcnt(); j++) {
4540         Node* u2 = u1-&gt;raw_out(j);
4541         if (u2 == n || u2 == u1)
4542           continue;
4543         tty-&gt;print(&quot;n-&gt;out(%d)-&gt;out(%d): &quot;, i, j); u2-&gt;dump();
4544         if (!u2-&gt;is_CFG()) {
4545           Node* u2_later = get_ctrl(u2);
4546           tty-&gt;print(&quot;later(n-&gt;out(%d)-&gt;out(%d)): &quot;, i, j); u2_later-&gt;dump();
4547           if (u2-&gt;in(0) != NULL     &amp;&amp; !u2-&gt;in(0)-&gt;is_top() &amp;&amp;
4548               u2-&gt;in(0) != u2_later &amp;&amp; !u2-&gt;in(0)-&gt;is_Root()) {
4549             tty-&gt;print(&quot;n-&gt;out(%d)-&gt;in(0): &quot;, i); u2-&gt;in(0)-&gt;dump();
4550           }
4551         }
4552       }
4553     }
4554   }
4555   tty-&gt;cr();
4556   int ct = 0;
4557   Node *dbg_legal = LCA;
4558   while(!dbg_legal-&gt;is_Start() &amp;&amp; ct &lt; 100) {
4559     tty-&gt;print(&quot;idom[%d] &quot;,ct); dbg_legal-&gt;dump();
4560     ct++;
4561     dbg_legal = idom(dbg_legal);
4562   }
4563   tty-&gt;cr();
4564 }
4565 #endif
4566 
4567 #ifndef PRODUCT
4568 //------------------------------dump-------------------------------------------
4569 void PhaseIdealLoop::dump() const {
4570   ResourceMark rm;
4571   Arena* arena = Thread::current()-&gt;resource_area();
4572   Node_Stack stack(arena, C-&gt;live_nodes() &gt;&gt; 2);
4573   Node_List rpo_list;
4574   VectorSet visited(arena);
4575   visited.set(C-&gt;top()-&gt;_idx);
4576   rpo(C-&gt;root(), stack, visited, rpo_list);
4577   // Dump root loop indexed by last element in PO order
4578   dump(_ltree_root, rpo_list.size(), rpo_list);
4579 }
4580 
4581 void PhaseIdealLoop::dump(IdealLoopTree* loop, uint idx, Node_List &amp;rpo_list) const {
4582   loop-&gt;dump_head();
4583 
4584   // Now scan for CFG nodes in the same loop
4585   for (uint j = idx; j &gt; 0; j--) {
4586     Node* n = rpo_list[j-1];
4587     if (!_nodes[n-&gt;_idx])      // Skip dead nodes
4588       continue;
4589 
4590     if (get_loop(n) != loop) { // Wrong loop nest
4591       if (get_loop(n)-&gt;_head == n &amp;&amp;    // Found nested loop?
4592           get_loop(n)-&gt;_parent == loop)
4593         dump(get_loop(n), rpo_list.size(), rpo_list);     // Print it nested-ly
4594       continue;
4595     }
4596 
4597     // Dump controlling node
4598     tty-&gt;sp(2 * loop-&gt;_nest);
4599     tty-&gt;print(&quot;C&quot;);
4600     if (n == C-&gt;root()) {
4601       n-&gt;dump();
4602     } else {
4603       Node* cached_idom   = idom_no_update(n);
4604       Node* computed_idom = n-&gt;in(0);
4605       if (n-&gt;is_Region()) {
4606         computed_idom = compute_idom(n);
4607         // computed_idom() will return n-&gt;in(0) when idom(n) is an IfNode (or
4608         // any MultiBranch ctrl node), so apply a similar transform to
4609         // the cached idom returned from idom_no_update.
4610         cached_idom = find_non_split_ctrl(cached_idom);
4611       }
4612       tty-&gt;print(&quot; ID:%d&quot;, computed_idom-&gt;_idx);
4613       n-&gt;dump();
4614       if (cached_idom != computed_idom) {
4615         tty-&gt;print_cr(&quot;*** BROKEN IDOM!  Computed as: %d, cached as: %d&quot;,
4616                       computed_idom-&gt;_idx, cached_idom-&gt;_idx);
4617       }
4618     }
4619     // Dump nodes it controls
4620     for (uint k = 0; k &lt; _nodes.Size(); k++) {
4621       // (k &lt; C-&gt;unique() &amp;&amp; get_ctrl(find(k)) == n)
4622       if (k &lt; C-&gt;unique() &amp;&amp; _nodes[k] == (Node*)((intptr_t)n + 1)) {
4623         Node* m = C-&gt;root()-&gt;find(k);
4624         if (m &amp;&amp; m-&gt;outcnt() &gt; 0) {
4625           if (!(has_ctrl(m) &amp;&amp; get_ctrl_no_update(m) == n)) {
4626             tty-&gt;print_cr(&quot;*** BROKEN CTRL ACCESSOR!  _nodes[k] is %p, ctrl is %p&quot;,
4627                           _nodes[k], has_ctrl(m) ? get_ctrl_no_update(m) : NULL);
4628           }
4629           tty-&gt;sp(2 * loop-&gt;_nest + 1);
4630           m-&gt;dump();
4631         }
4632       }
4633     }
4634   }
4635 }
4636 #endif
4637 
4638 // Collect a R-P-O for the whole CFG.
4639 // Result list is in post-order (scan backwards for RPO)
4640 void PhaseIdealLoop::rpo(Node* start, Node_Stack &amp;stk, VectorSet &amp;visited, Node_List &amp;rpo_list) const {
4641   stk.push(start, 0);
4642   visited.set(start-&gt;_idx);
4643 
4644   while (stk.is_nonempty()) {
4645     Node* m   = stk.node();
4646     uint  idx = stk.index();
4647     if (idx &lt; m-&gt;outcnt()) {
4648       stk.set_index(idx + 1);
4649       Node* n = m-&gt;raw_out(idx);
4650       if (n-&gt;is_CFG() &amp;&amp; !visited.test_set(n-&gt;_idx)) {
4651         stk.push(n, 0);
4652       }
4653     } else {
4654       rpo_list.push(m);
4655       stk.pop();
4656     }
4657   }
4658 }
4659 
4660 
4661 //=============================================================================
4662 //------------------------------LoopTreeIterator-------------------------------
4663 
4664 // Advance to next loop tree using a preorder, left-to-right traversal.
4665 void LoopTreeIterator::next() {
4666   assert(!done(), &quot;must not be done.&quot;);
4667   if (_curnt-&gt;_child != NULL) {
4668     _curnt = _curnt-&gt;_child;
4669   } else if (_curnt-&gt;_next != NULL) {
4670     _curnt = _curnt-&gt;_next;
4671   } else {
4672     while (_curnt != _root &amp;&amp; _curnt-&gt;_next == NULL) {
4673       _curnt = _curnt-&gt;_parent;
4674     }
4675     if (_curnt == _root) {
4676       _curnt = NULL;
4677       assert(done(), &quot;must be done.&quot;);
4678     } else {
4679       assert(_curnt-&gt;_next != NULL, &quot;must be more to do&quot;);
4680       _curnt = _curnt-&gt;_next;
4681     }
4682   }
4683 }
    </pre>
  </body>
</html>