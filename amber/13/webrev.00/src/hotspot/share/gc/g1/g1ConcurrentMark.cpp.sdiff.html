<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/g1/g1ConcurrentMark.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="g1CollectedHeap.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1ConcurrentMark.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/g1/g1ConcurrentMark.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 252   add_chunk_to_free_list(cur);
 253   return true;
 254 }
 255 
 256 void G1CMMarkStack::set_empty() {
 257   _chunks_in_chunk_list = 0;
 258   _hwm = 0;
 259   _chunk_list = NULL;
 260   _free_list = NULL;
 261 }
 262 
 263 G1CMRootMemRegions::G1CMRootMemRegions(uint const max_regions) :
 264     _root_regions(MemRegion::create_array(max_regions, mtGC)),
 265     _max_regions(max_regions),
 266     _num_root_regions(0),
 267     _claimed_root_regions(0),
 268     _scan_in_progress(false),
 269     _should_abort(false) { }
 270 
 271 G1CMRootMemRegions::~G1CMRootMemRegions() {
<span class="line-modified"> 272   FREE_C_HEAP_ARRAY(MemRegion, _root_regions);</span>
 273 }
 274 
 275 void G1CMRootMemRegions::reset() {
 276   _num_root_regions = 0;
 277 }
 278 
 279 void G1CMRootMemRegions::add(HeapWord* start, HeapWord* end) {
 280   assert_at_safepoint();
 281   size_t idx = Atomic::fetch_and_add(&amp;_num_root_regions, 1u);
 282   assert(idx &lt; _max_regions, &quot;Trying to add more root MemRegions than there is space &quot; SIZE_FORMAT, _max_regions);
 283   assert(start != NULL &amp;&amp; end != NULL &amp;&amp; start &lt;= end, &quot;Start (&quot; PTR_FORMAT &quot;) should be less or equal to &quot;
 284          &quot;end (&quot; PTR_FORMAT &quot;)&quot;, p2i(start), p2i(end));
 285   _root_regions[idx].set_start(start);
 286   _root_regions[idx].set_end(end);
 287 }
 288 
 289 void G1CMRootMemRegions::prepare_for_scan() {
 290   assert(!scan_in_progress(), &quot;pre-condition&quot;);
 291 
 292   _scan_in_progress = _num_root_regions &gt; 0;
</pre>
<hr />
<pre>
 336            _claimed_root_regions, num_root_regions());
 337   }
 338 
 339   notify_scan_done();
 340 }
 341 
 342 bool G1CMRootMemRegions::wait_until_scan_finished() {
 343   if (!scan_in_progress()) {
 344     return false;
 345   }
 346 
 347   {
 348     MonitorLocker ml(RootRegionScan_lock, Mutex::_no_safepoint_check_flag);
 349     while (scan_in_progress()) {
 350       ml.wait();
 351     }
 352   }
 353   return true;
 354 }
 355 
<span class="line-removed"> 356 // Returns the maximum number of workers to be used in a concurrent</span>
<span class="line-removed"> 357 // phase based on the number of GC workers being used in a STW</span>
<span class="line-removed"> 358 // phase.</span>
<span class="line-removed"> 359 static uint scale_concurrent_worker_threads(uint num_gc_workers) {</span>
<span class="line-removed"> 360   return MAX2((num_gc_workers + 2) / 4, 1U);</span>
<span class="line-removed"> 361 }</span>
<span class="line-removed"> 362 </span>
 363 G1ConcurrentMark::G1ConcurrentMark(G1CollectedHeap* g1h,
 364                                    G1RegionToSpaceMapper* prev_bitmap_storage,
 365                                    G1RegionToSpaceMapper* next_bitmap_storage) :
 366   // _cm_thread set inside the constructor
 367   _g1h(g1h),
<span class="line-removed"> 368   _completed_initialization(false),</span>
 369 
 370   _mark_bitmap_1(),
 371   _mark_bitmap_2(),
 372   _prev_mark_bitmap(&amp;_mark_bitmap_1),
 373   _next_mark_bitmap(&amp;_mark_bitmap_2),
 374 
 375   _heap(_g1h-&gt;reserved_region()),
 376 
 377   _root_regions(_g1h-&gt;max_regions()),
 378 
 379   _global_mark_stack(),
 380 
 381   // _finger set in set_non_marking_state
 382 
 383   _worker_id_offset(G1DirtyCardQueueSet::num_par_ids() + G1ConcRefinementThreads),
 384   _max_num_tasks(ParallelGCThreads),
 385   // _num_active_tasks set in set_non_marking_state()
 386   // _tasks set inside the constructor
 387 
 388   _task_queues(new G1CMTaskQueueSet((int) _max_num_tasks)),
</pre>
<hr />
<pre>
 399   _gc_tracer_cm(new (ResourceObj::C_HEAP, mtGC) G1OldTracer()),
 400 
 401   // _verbose_level set below
 402 
 403   _init_times(),
 404   _remark_times(),
 405   _remark_mark_times(),
 406   _remark_weak_ref_times(),
 407   _cleanup_times(),
 408   _total_cleanup_time(0.0),
 409 
 410   _accum_task_vtime(NULL),
 411 
 412   _concurrent_workers(NULL),
 413   _num_concurrent_workers(0),
 414   _max_concurrent_workers(0),
 415 
 416   _region_mark_stats(NEW_C_HEAP_ARRAY(G1RegionMarkStats, _g1h-&gt;max_regions(), mtGC)),
 417   _top_at_rebuild_starts(NEW_C_HEAP_ARRAY(HeapWord*, _g1h-&gt;max_regions(), mtGC))
 418 {


 419   _mark_bitmap_1.initialize(g1h-&gt;reserved_region(), prev_bitmap_storage);
 420   _mark_bitmap_2.initialize(g1h-&gt;reserved_region(), next_bitmap_storage);
 421 
 422   // Create &amp; start ConcurrentMark thread.
 423   _cm_thread = new G1ConcurrentMarkThread(this);
 424   if (_cm_thread-&gt;osthread() == NULL) {
 425     vm_shutdown_during_initialization(&quot;Could not create ConcurrentMarkThread&quot;);
 426   }
 427 
<span class="line-removed"> 428   assert(CGC_lock != NULL, &quot;CGC_lock must be initialized&quot;);</span>
<span class="line-removed"> 429 </span>
<span class="line-removed"> 430   if (FLAG_IS_DEFAULT(ConcGCThreads) || ConcGCThreads == 0) {</span>
<span class="line-removed"> 431     // Calculate the number of concurrent worker threads by scaling</span>
<span class="line-removed"> 432     // the number of parallel GC threads.</span>
<span class="line-removed"> 433     uint marking_thread_num = scale_concurrent_worker_threads(ParallelGCThreads);</span>
<span class="line-removed"> 434     FLAG_SET_ERGO(ConcGCThreads, marking_thread_num);</span>
<span class="line-removed"> 435   }</span>
<span class="line-removed"> 436 </span>
<span class="line-removed"> 437   assert(ConcGCThreads &gt; 0, &quot;ConcGCThreads have been set.&quot;);</span>
<span class="line-removed"> 438   if (ConcGCThreads &gt; ParallelGCThreads) {</span>
<span class="line-removed"> 439     log_warning(gc)(&quot;More ConcGCThreads (%u) than ParallelGCThreads (%u).&quot;,</span>
<span class="line-removed"> 440                     ConcGCThreads, ParallelGCThreads);</span>
<span class="line-removed"> 441     return;</span>
<span class="line-removed"> 442   }</span>
<span class="line-removed"> 443 </span>
 444   log_debug(gc)(&quot;ConcGCThreads: %u offset %u&quot;, ConcGCThreads, _worker_id_offset);
 445   log_debug(gc)(&quot;ParallelGCThreads: %u&quot;, ParallelGCThreads);
 446 
 447   _num_concurrent_workers = ConcGCThreads;
 448   _max_concurrent_workers = _num_concurrent_workers;
 449 
 450   _concurrent_workers = new WorkGang(&quot;G1 Conc&quot;, _max_concurrent_workers, false, true);
 451   _concurrent_workers-&gt;initialize_workers();
 452 
<span class="line-removed"> 453   if (FLAG_IS_DEFAULT(MarkStackSize)) {</span>
<span class="line-removed"> 454     size_t mark_stack_size =</span>
<span class="line-removed"> 455       MIN2(MarkStackSizeMax,</span>
<span class="line-removed"> 456           MAX2(MarkStackSize, (size_t) (_max_concurrent_workers * TASKQUEUE_SIZE)));</span>
<span class="line-removed"> 457     // Verify that the calculated value for MarkStackSize is in range.</span>
<span class="line-removed"> 458     // It would be nice to use the private utility routine from Arguments.</span>
<span class="line-removed"> 459     if (!(mark_stack_size &gt;= 1 &amp;&amp; mark_stack_size &lt;= MarkStackSizeMax)) {</span>
<span class="line-removed"> 460       log_warning(gc)(&quot;Invalid value calculated for MarkStackSize (&quot; SIZE_FORMAT &quot;): &quot;</span>
<span class="line-removed"> 461                       &quot;must be between 1 and &quot; SIZE_FORMAT,</span>
<span class="line-removed"> 462                       mark_stack_size, MarkStackSizeMax);</span>
<span class="line-removed"> 463       return;</span>
<span class="line-removed"> 464     }</span>
<span class="line-removed"> 465     FLAG_SET_ERGO(MarkStackSize, mark_stack_size);</span>
<span class="line-removed"> 466   } else {</span>
<span class="line-removed"> 467     // Verify MarkStackSize is in range.</span>
<span class="line-removed"> 468     if (FLAG_IS_CMDLINE(MarkStackSize)) {</span>
<span class="line-removed"> 469       if (FLAG_IS_DEFAULT(MarkStackSizeMax)) {</span>
<span class="line-removed"> 470         if (!(MarkStackSize &gt;= 1 &amp;&amp; MarkStackSize &lt;= MarkStackSizeMax)) {</span>
<span class="line-removed"> 471           log_warning(gc)(&quot;Invalid value specified for MarkStackSize (&quot; SIZE_FORMAT &quot;): &quot;</span>
<span class="line-removed"> 472                           &quot;must be between 1 and &quot; SIZE_FORMAT,</span>
<span class="line-removed"> 473                           MarkStackSize, MarkStackSizeMax);</span>
<span class="line-removed"> 474           return;</span>
<span class="line-removed"> 475         }</span>
<span class="line-removed"> 476       } else if (FLAG_IS_CMDLINE(MarkStackSizeMax)) {</span>
<span class="line-removed"> 477         if (!(MarkStackSize &gt;= 1 &amp;&amp; MarkStackSize &lt;= MarkStackSizeMax)) {</span>
<span class="line-removed"> 478           log_warning(gc)(&quot;Invalid value specified for MarkStackSize (&quot; SIZE_FORMAT &quot;)&quot;</span>
<span class="line-removed"> 479                           &quot; or for MarkStackSizeMax (&quot; SIZE_FORMAT &quot;)&quot;,</span>
<span class="line-removed"> 480                           MarkStackSize, MarkStackSizeMax);</span>
<span class="line-removed"> 481           return;</span>
<span class="line-removed"> 482         }</span>
<span class="line-removed"> 483       }</span>
<span class="line-removed"> 484     }</span>
<span class="line-removed"> 485   }</span>
<span class="line-removed"> 486 </span>
 487   if (!_global_mark_stack.initialize(MarkStackSize, MarkStackSizeMax)) {
 488     vm_exit_during_initialization(&quot;Failed to allocate initial concurrent mark overflow mark stack.&quot;);
 489   }
 490 
 491   _tasks = NEW_C_HEAP_ARRAY(G1CMTask*, _max_num_tasks, mtGC);
 492   _accum_task_vtime = NEW_C_HEAP_ARRAY(double, _max_num_tasks, mtGC);
 493 
 494   // so that the assertion in MarkingTaskQueue::task_queue doesn&#39;t fail
 495   _num_active_tasks = _max_num_tasks;
 496 
 497   for (uint i = 0; i &lt; _max_num_tasks; ++i) {
 498     G1CMTaskQueue* task_queue = new G1CMTaskQueue();
 499     task_queue-&gt;initialize();
 500     _task_queues-&gt;register_queue(i, task_queue);
 501 
 502     _tasks[i] = new G1CMTask(i, this, task_queue, _region_mark_stats, _g1h-&gt;max_regions());
 503 
 504     _accum_task_vtime[i] = 0.0;
 505   }
 506 
 507   reset_at_marking_complete();
<span class="line-removed"> 508   _completed_initialization = true;</span>
 509 }
 510 
 511 void G1ConcurrentMark::reset() {
 512   _has_aborted = false;
 513 
 514   reset_marking_for_restart();
 515 
 516   // Reset all tasks, since different phases will use different number of active
 517   // threads. So, it&#39;s easiest to have all of them ready.
 518   for (uint i = 0; i &lt; _max_num_tasks; ++i) {
 519     _tasks[i]-&gt;reset(_next_mark_bitmap);
 520   }
 521 
 522   uint max_regions = _g1h-&gt;max_regions();
 523   for (uint i = 0; i &lt; max_regions; i++) {
 524     _top_at_rebuild_starts[i] = NULL;
 525     _region_mark_stats[i].clear();
 526   }
 527 }
 528 
</pre>
<hr />
<pre>
 845 
 846           _cm-&gt;do_yield_check();
 847         } while (!_cm-&gt;has_aborted() &amp;&amp; task-&gt;has_aborted());
 848       }
 849       task-&gt;record_end_time();
 850       guarantee(!task-&gt;has_aborted() || _cm-&gt;has_aborted(), &quot;invariant&quot;);
 851     }
 852 
 853     double end_vtime = os::elapsedVTime();
 854     _cm-&gt;update_accum_task_vtime(worker_id, end_vtime - start_vtime);
 855   }
 856 
 857   G1CMConcurrentMarkingTask(G1ConcurrentMark* cm) :
 858       AbstractGangTask(&quot;Concurrent Mark&quot;), _cm(cm) { }
 859 
 860   ~G1CMConcurrentMarkingTask() { }
 861 };
 862 
 863 uint G1ConcurrentMark::calc_active_marking_workers() {
 864   uint result = 0;
<span class="line-modified"> 865   if (!UseDynamicNumberOfGCThreads ||</span>
<span class="line-removed"> 866       (!FLAG_IS_DEFAULT(ConcGCThreads) &amp;&amp;</span>
<span class="line-removed"> 867        !ForceDynamicNumberOfGCThreads)) {</span>
 868     result = _max_concurrent_workers;
 869   } else {
 870     result =
 871       WorkerPolicy::calc_default_active_workers(_max_concurrent_workers,
 872                                                 1, /* Minimum workers */
 873                                                 _num_concurrent_workers,
 874                                                 Threads::number_of_non_daemon_threads());
 875     // Don&#39;t scale the result down by scale_concurrent_workers() because
 876     // that scaling has already gone into &quot;_max_concurrent_workers&quot;.
 877   }
 878   assert(result &gt; 0 &amp;&amp; result &lt;= _max_concurrent_workers,
 879          &quot;Calculated number of marking workers must be larger than zero and at most the maximum %u, but is %u&quot;,
 880          _max_concurrent_workers, result);
 881   return result;
 882 }
 883 
 884 void G1ConcurrentMark::scan_root_region(const MemRegion* region, uint worker_id) {
 885 #ifdef ASSERT
 886   HeapWord* last = region-&gt;last();
 887   HeapRegion* hr = _g1h-&gt;heap_region_containing(last);
</pre>
</td>
<td>
<hr />
<pre>
 252   add_chunk_to_free_list(cur);
 253   return true;
 254 }
 255 
 256 void G1CMMarkStack::set_empty() {
 257   _chunks_in_chunk_list = 0;
 258   _hwm = 0;
 259   _chunk_list = NULL;
 260   _free_list = NULL;
 261 }
 262 
 263 G1CMRootMemRegions::G1CMRootMemRegions(uint const max_regions) :
 264     _root_regions(MemRegion::create_array(max_regions, mtGC)),
 265     _max_regions(max_regions),
 266     _num_root_regions(0),
 267     _claimed_root_regions(0),
 268     _scan_in_progress(false),
 269     _should_abort(false) { }
 270 
 271 G1CMRootMemRegions::~G1CMRootMemRegions() {
<span class="line-modified"> 272   MemRegion::destroy_array(_root_regions, _max_regions);</span>
 273 }
 274 
 275 void G1CMRootMemRegions::reset() {
 276   _num_root_regions = 0;
 277 }
 278 
 279 void G1CMRootMemRegions::add(HeapWord* start, HeapWord* end) {
 280   assert_at_safepoint();
 281   size_t idx = Atomic::fetch_and_add(&amp;_num_root_regions, 1u);
 282   assert(idx &lt; _max_regions, &quot;Trying to add more root MemRegions than there is space &quot; SIZE_FORMAT, _max_regions);
 283   assert(start != NULL &amp;&amp; end != NULL &amp;&amp; start &lt;= end, &quot;Start (&quot; PTR_FORMAT &quot;) should be less or equal to &quot;
 284          &quot;end (&quot; PTR_FORMAT &quot;)&quot;, p2i(start), p2i(end));
 285   _root_regions[idx].set_start(start);
 286   _root_regions[idx].set_end(end);
 287 }
 288 
 289 void G1CMRootMemRegions::prepare_for_scan() {
 290   assert(!scan_in_progress(), &quot;pre-condition&quot;);
 291 
 292   _scan_in_progress = _num_root_regions &gt; 0;
</pre>
<hr />
<pre>
 336            _claimed_root_regions, num_root_regions());
 337   }
 338 
 339   notify_scan_done();
 340 }
 341 
 342 bool G1CMRootMemRegions::wait_until_scan_finished() {
 343   if (!scan_in_progress()) {
 344     return false;
 345   }
 346 
 347   {
 348     MonitorLocker ml(RootRegionScan_lock, Mutex::_no_safepoint_check_flag);
 349     while (scan_in_progress()) {
 350       ml.wait();
 351     }
 352   }
 353   return true;
 354 }
 355 







 356 G1ConcurrentMark::G1ConcurrentMark(G1CollectedHeap* g1h,
 357                                    G1RegionToSpaceMapper* prev_bitmap_storage,
 358                                    G1RegionToSpaceMapper* next_bitmap_storage) :
 359   // _cm_thread set inside the constructor
 360   _g1h(g1h),

 361 
 362   _mark_bitmap_1(),
 363   _mark_bitmap_2(),
 364   _prev_mark_bitmap(&amp;_mark_bitmap_1),
 365   _next_mark_bitmap(&amp;_mark_bitmap_2),
 366 
 367   _heap(_g1h-&gt;reserved_region()),
 368 
 369   _root_regions(_g1h-&gt;max_regions()),
 370 
 371   _global_mark_stack(),
 372 
 373   // _finger set in set_non_marking_state
 374 
 375   _worker_id_offset(G1DirtyCardQueueSet::num_par_ids() + G1ConcRefinementThreads),
 376   _max_num_tasks(ParallelGCThreads),
 377   // _num_active_tasks set in set_non_marking_state()
 378   // _tasks set inside the constructor
 379 
 380   _task_queues(new G1CMTaskQueueSet((int) _max_num_tasks)),
</pre>
<hr />
<pre>
 391   _gc_tracer_cm(new (ResourceObj::C_HEAP, mtGC) G1OldTracer()),
 392 
 393   // _verbose_level set below
 394 
 395   _init_times(),
 396   _remark_times(),
 397   _remark_mark_times(),
 398   _remark_weak_ref_times(),
 399   _cleanup_times(),
 400   _total_cleanup_time(0.0),
 401 
 402   _accum_task_vtime(NULL),
 403 
 404   _concurrent_workers(NULL),
 405   _num_concurrent_workers(0),
 406   _max_concurrent_workers(0),
 407 
 408   _region_mark_stats(NEW_C_HEAP_ARRAY(G1RegionMarkStats, _g1h-&gt;max_regions(), mtGC)),
 409   _top_at_rebuild_starts(NEW_C_HEAP_ARRAY(HeapWord*, _g1h-&gt;max_regions(), mtGC))
 410 {
<span class="line-added"> 411   assert(CGC_lock != NULL, &quot;CGC_lock must be initialized&quot;);</span>
<span class="line-added"> 412 </span>
 413   _mark_bitmap_1.initialize(g1h-&gt;reserved_region(), prev_bitmap_storage);
 414   _mark_bitmap_2.initialize(g1h-&gt;reserved_region(), next_bitmap_storage);
 415 
 416   // Create &amp; start ConcurrentMark thread.
 417   _cm_thread = new G1ConcurrentMarkThread(this);
 418   if (_cm_thread-&gt;osthread() == NULL) {
 419     vm_shutdown_during_initialization(&quot;Could not create ConcurrentMarkThread&quot;);
 420   }
 421 
















 422   log_debug(gc)(&quot;ConcGCThreads: %u offset %u&quot;, ConcGCThreads, _worker_id_offset);
 423   log_debug(gc)(&quot;ParallelGCThreads: %u&quot;, ParallelGCThreads);
 424 
 425   _num_concurrent_workers = ConcGCThreads;
 426   _max_concurrent_workers = _num_concurrent_workers;
 427 
 428   _concurrent_workers = new WorkGang(&quot;G1 Conc&quot;, _max_concurrent_workers, false, true);
 429   _concurrent_workers-&gt;initialize_workers();
 430 


































 431   if (!_global_mark_stack.initialize(MarkStackSize, MarkStackSizeMax)) {
 432     vm_exit_during_initialization(&quot;Failed to allocate initial concurrent mark overflow mark stack.&quot;);
 433   }
 434 
 435   _tasks = NEW_C_HEAP_ARRAY(G1CMTask*, _max_num_tasks, mtGC);
 436   _accum_task_vtime = NEW_C_HEAP_ARRAY(double, _max_num_tasks, mtGC);
 437 
 438   // so that the assertion in MarkingTaskQueue::task_queue doesn&#39;t fail
 439   _num_active_tasks = _max_num_tasks;
 440 
 441   for (uint i = 0; i &lt; _max_num_tasks; ++i) {
 442     G1CMTaskQueue* task_queue = new G1CMTaskQueue();
 443     task_queue-&gt;initialize();
 444     _task_queues-&gt;register_queue(i, task_queue);
 445 
 446     _tasks[i] = new G1CMTask(i, this, task_queue, _region_mark_stats, _g1h-&gt;max_regions());
 447 
 448     _accum_task_vtime[i] = 0.0;
 449   }
 450 
 451   reset_at_marking_complete();

 452 }
 453 
 454 void G1ConcurrentMark::reset() {
 455   _has_aborted = false;
 456 
 457   reset_marking_for_restart();
 458 
 459   // Reset all tasks, since different phases will use different number of active
 460   // threads. So, it&#39;s easiest to have all of them ready.
 461   for (uint i = 0; i &lt; _max_num_tasks; ++i) {
 462     _tasks[i]-&gt;reset(_next_mark_bitmap);
 463   }
 464 
 465   uint max_regions = _g1h-&gt;max_regions();
 466   for (uint i = 0; i &lt; max_regions; i++) {
 467     _top_at_rebuild_starts[i] = NULL;
 468     _region_mark_stats[i].clear();
 469   }
 470 }
 471 
</pre>
<hr />
<pre>
 788 
 789           _cm-&gt;do_yield_check();
 790         } while (!_cm-&gt;has_aborted() &amp;&amp; task-&gt;has_aborted());
 791       }
 792       task-&gt;record_end_time();
 793       guarantee(!task-&gt;has_aborted() || _cm-&gt;has_aborted(), &quot;invariant&quot;);
 794     }
 795 
 796     double end_vtime = os::elapsedVTime();
 797     _cm-&gt;update_accum_task_vtime(worker_id, end_vtime - start_vtime);
 798   }
 799 
 800   G1CMConcurrentMarkingTask(G1ConcurrentMark* cm) :
 801       AbstractGangTask(&quot;Concurrent Mark&quot;), _cm(cm) { }
 802 
 803   ~G1CMConcurrentMarkingTask() { }
 804 };
 805 
 806 uint G1ConcurrentMark::calc_active_marking_workers() {
 807   uint result = 0;
<span class="line-modified"> 808   if (!UseDynamicNumberOfGCThreads || !FLAG_IS_DEFAULT(ConcGCThreads)) {</span>


 809     result = _max_concurrent_workers;
 810   } else {
 811     result =
 812       WorkerPolicy::calc_default_active_workers(_max_concurrent_workers,
 813                                                 1, /* Minimum workers */
 814                                                 _num_concurrent_workers,
 815                                                 Threads::number_of_non_daemon_threads());
 816     // Don&#39;t scale the result down by scale_concurrent_workers() because
 817     // that scaling has already gone into &quot;_max_concurrent_workers&quot;.
 818   }
 819   assert(result &gt; 0 &amp;&amp; result &lt;= _max_concurrent_workers,
 820          &quot;Calculated number of marking workers must be larger than zero and at most the maximum %u, but is %u&quot;,
 821          _max_concurrent_workers, result);
 822   return result;
 823 }
 824 
 825 void G1ConcurrentMark::scan_root_region(const MemRegion* region, uint worker_id) {
 826 #ifdef ASSERT
 827   HeapWord* last = region-&gt;last();
 828   HeapRegion* hr = _g1h-&gt;heap_region_containing(last);
</pre>
</td>
</tr>
</table>
<center><a href="g1CollectedHeap.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1ConcurrentMark.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>