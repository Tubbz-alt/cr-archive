<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/shenandoah/shenandoahHeap.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="shenandoahFreeSet.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahHeap.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shenandoah/shenandoahHeap.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;memory/allocation.hpp&quot;
  27 #include &quot;memory/universe.hpp&quot;
  28 
  29 #include &quot;gc/shared/gcArguments.hpp&quot;
  30 #include &quot;gc/shared/gcTimer.hpp&quot;
  31 #include &quot;gc/shared/gcTraceTime.inline.hpp&quot;
  32 #include &quot;gc/shared/locationPrinter.inline.hpp&quot;
  33 #include &quot;gc/shared/memAllocator.hpp&quot;
  34 #include &quot;gc/shared/oopStorageSet.hpp&quot;
  35 #include &quot;gc/shared/plab.hpp&quot;
  36 
<span class="line-removed">  37 #include &quot;gc/shenandoah/shenandoahAllocTracker.hpp&quot;</span>
  38 #include &quot;gc/shenandoah/shenandoahBarrierSet.hpp&quot;
  39 #include &quot;gc/shenandoah/shenandoahClosures.inline.hpp&quot;
  40 #include &quot;gc/shenandoah/shenandoahCollectionSet.hpp&quot;
  41 #include &quot;gc/shenandoah/shenandoahCollectorPolicy.hpp&quot;
  42 #include &quot;gc/shenandoah/shenandoahConcurrentMark.inline.hpp&quot;
  43 #include &quot;gc/shenandoah/shenandoahConcurrentRoots.hpp&quot;
  44 #include &quot;gc/shenandoah/shenandoahControlThread.hpp&quot;
  45 #include &quot;gc/shenandoah/shenandoahFreeSet.hpp&quot;
  46 #include &quot;gc/shenandoah/shenandoahPhaseTimings.hpp&quot;
  47 #include &quot;gc/shenandoah/shenandoahHeap.inline.hpp&quot;
<span class="line-modified">  48 #include &quot;gc/shenandoah/shenandoahHeapRegion.hpp&quot;</span>
  49 #include &quot;gc/shenandoah/shenandoahHeapRegionSet.hpp&quot;

  50 #include &quot;gc/shenandoah/shenandoahMarkCompact.hpp&quot;
  51 #include &quot;gc/shenandoah/shenandoahMarkingContext.inline.hpp&quot;
  52 #include &quot;gc/shenandoah/shenandoahMemoryPool.hpp&quot;
  53 #include &quot;gc/shenandoah/shenandoahMetrics.hpp&quot;
  54 #include &quot;gc/shenandoah/shenandoahMonitoringSupport.hpp&quot;
  55 #include &quot;gc/shenandoah/shenandoahNormalMode.hpp&quot;
  56 #include &quot;gc/shenandoah/shenandoahOopClosures.inline.hpp&quot;
  57 #include &quot;gc/shenandoah/shenandoahPacer.inline.hpp&quot;

  58 #include &quot;gc/shenandoah/shenandoahParallelCleaning.inline.hpp&quot;
  59 #include &quot;gc/shenandoah/shenandoahPassiveMode.hpp&quot;
  60 #include &quot;gc/shenandoah/shenandoahRootProcessor.inline.hpp&quot;
  61 #include &quot;gc/shenandoah/shenandoahStringDedup.hpp&quot;
  62 #include &quot;gc/shenandoah/shenandoahTaskqueue.hpp&quot;
<span class="line-removed">  63 #include &quot;gc/shenandoah/shenandoahTraversalMode.hpp&quot;</span>
  64 #include &quot;gc/shenandoah/shenandoahUtils.hpp&quot;
  65 #include &quot;gc/shenandoah/shenandoahVerifier.hpp&quot;
  66 #include &quot;gc/shenandoah/shenandoahCodeRoots.hpp&quot;
  67 #include &quot;gc/shenandoah/shenandoahVMOperations.hpp&quot;
  68 #include &quot;gc/shenandoah/shenandoahWorkGroup.hpp&quot;
  69 #include &quot;gc/shenandoah/shenandoahWorkerPolicy.hpp&quot;
  70 #if INCLUDE_JFR
  71 #include &quot;gc/shenandoah/shenandoahJfrSupport.hpp&quot;
  72 #endif
  73 
  74 #include &quot;memory/metaspace.hpp&quot;
  75 #include &quot;oops/compressedOops.inline.hpp&quot;
  76 #include &quot;runtime/atomic.hpp&quot;
  77 #include &quot;runtime/globals.hpp&quot;
  78 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  79 #include &quot;runtime/orderAccess.hpp&quot;
  80 #include &quot;runtime/safepointMechanism.hpp&quot;
  81 #include &quot;runtime/vmThread.hpp&quot;
  82 #include &quot;services/mallocTracker.hpp&quot;
  83 #include &quot;utilities/powerOfTwo.hpp&quot;
  84 


  85 #ifdef ASSERT
  86 template &lt;class T&gt;
  87 void ShenandoahAssertToSpaceClosure::do_oop_work(T* p) {
  88   T o = RawAccess&lt;&gt;::oop_load(p);
  89   if (! CompressedOops::is_null(o)) {
  90     oop obj = CompressedOops::decode_not_null(o);
  91     shenandoah_assert_not_forwarded(p, obj);
  92   }
  93 }
  94 
  95 void ShenandoahAssertToSpaceClosure::do_oop(narrowOop* p) { do_oop_work(p); }
  96 void ShenandoahAssertToSpaceClosure::do_oop(oop* p)       { do_oop_work(p); }
  97 #endif
  98 
  99 class ShenandoahPretouchHeapTask : public AbstractGangTask {
 100 private:
 101   ShenandoahRegionIterator _regions;
 102   const size_t _page_size;
 103 public:
 104   ShenandoahPretouchHeapTask(size_t page_size) :
</pre>
<hr />
<pre>
 113     }
 114   }
 115 };
 116 
 117 class ShenandoahPretouchBitmapTask : public AbstractGangTask {
 118 private:
 119   ShenandoahRegionIterator _regions;
 120   char* _bitmap_base;
 121   const size_t _bitmap_size;
 122   const size_t _page_size;
 123 public:
 124   ShenandoahPretouchBitmapTask(char* bitmap_base, size_t bitmap_size, size_t page_size) :
 125     AbstractGangTask(&quot;Shenandoah Pretouch Bitmap&quot;),
 126     _bitmap_base(bitmap_base),
 127     _bitmap_size(bitmap_size),
 128     _page_size(page_size) {}
 129 
 130   virtual void work(uint worker_id) {
 131     ShenandoahHeapRegion* r = _regions.next();
 132     while (r != NULL) {
<span class="line-modified"> 133       size_t start = r-&gt;region_number()       * ShenandoahHeapRegion::region_size_bytes() / MarkBitMap::heap_map_factor();</span>
<span class="line-modified"> 134       size_t end   = (r-&gt;region_number() + 1) * ShenandoahHeapRegion::region_size_bytes() / MarkBitMap::heap_map_factor();</span>
 135       assert (end &lt;= _bitmap_size, &quot;end is sane: &quot; SIZE_FORMAT &quot; &lt; &quot; SIZE_FORMAT, end, _bitmap_size);
 136 
 137       os::pretouch_memory(_bitmap_base + start, _bitmap_base + end, _page_size);
 138 
 139       r = _regions.next();
 140     }
 141   }
 142 };
 143 
 144 jint ShenandoahHeap::initialize() {
<span class="line-removed"> 145   initialize_heuristics();</span>
<span class="line-removed"> 146 </span>
 147   //
 148   // Figure out heap sizing
 149   //
 150 
 151   size_t init_byte_size = InitialHeapSize;
 152   size_t min_byte_size  = MinHeapSize;
 153   size_t max_byte_size  = MaxHeapSize;
 154   size_t heap_alignment = HeapAlignment;
 155 
 156   size_t reg_size_bytes = ShenandoahHeapRegion::region_size_bytes();
 157 
 158   if (ShenandoahAlwaysPreTouch) {
 159     // Enabled pre-touch means the entire heap is committed right away.
 160     init_byte_size = max_byte_size;
 161   }
 162 
 163   Universe::check_alignment(max_byte_size,  reg_size_bytes, &quot;Shenandoah heap&quot;);
 164   Universe::check_alignment(init_byte_size, reg_size_bytes, &quot;Shenandoah heap&quot;);
 165 
 166   _num_regions = ShenandoahHeapRegion::region_count();
 167 



 168   size_t num_committed_regions = init_byte_size / reg_size_bytes;
 169   num_committed_regions = MIN2(num_committed_regions, _num_regions);
 170   assert(num_committed_regions &lt;= _num_regions, &quot;sanity&quot;);
 171   _initial_size = num_committed_regions * reg_size_bytes;
 172 
 173   size_t num_min_regions = min_byte_size / reg_size_bytes;
 174   num_min_regions = MIN2(num_min_regions, _num_regions);
 175   assert(num_min_regions &lt;= _num_regions, &quot;sanity&quot;);
 176   _minimum_size = num_min_regions * reg_size_bytes;
 177 
 178   _committed = _initial_size;
 179 
 180   size_t heap_page_size   = UseLargePages ? (size_t)os::large_page_size() : (size_t)os::vm_page_size();
 181   size_t bitmap_page_size = UseLargePages ? (size_t)os::large_page_size() : (size_t)os::vm_page_size();

 182 
 183   //
 184   // Reserve and commit memory for heap
 185   //
 186 
 187   ReservedHeapSpace heap_rs = Universe::reserve_heap(max_byte_size, heap_alignment);
 188   initialize_reserved_region(heap_rs);
 189   _heap_region = MemRegion((HeapWord*)heap_rs.base(), heap_rs.size() / HeapWordSize);
 190   _heap_region_special = heap_rs.special();
 191 
 192   assert((((size_t) base()) &amp; ShenandoahHeapRegion::region_size_bytes_mask()) == 0,
 193          &quot;Misaligned heap: &quot; PTR_FORMAT, p2i(base()));
 194 
 195 #if SHENANDOAH_OPTIMIZED_OBJTASK
 196   // The optimized ObjArrayChunkedTask takes some bits away from the full object bits.
 197   // Fail if we ever attempt to address more than we can.
 198   if ((uintptr_t)heap_rs.end() &gt;= ObjArrayChunkedTask::max_addressable()) {
 199     FormatBuffer&lt;512&gt; buf(&quot;Shenandoah reserved [&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT&quot;) for the heap, \n&quot;
 200                           &quot;but max object address is &quot; PTR_FORMAT &quot;. Try to reduce heap size, or try other \n&quot;
 201                           &quot;VM options that allocate heap at lower addresses (HeapBaseMinAddress, AllocateHeapAt, etc).&quot;,
</pre>
<hr />
<pre>
 260     if (!verify_bitmap.special()) {
 261       os::commit_memory_or_exit(verify_bitmap.base(), verify_bitmap.size(), bitmap_page_size, false,
 262                                 &quot;Cannot commit verification bitmap memory&quot;);
 263     }
 264     MemTracker::record_virtual_memory_type(verify_bitmap.base(), mtGC);
 265     MemRegion verify_bitmap_region = MemRegion((HeapWord *) verify_bitmap.base(), verify_bitmap.size() / HeapWordSize);
 266     _verification_bit_map.initialize(_heap_region, verify_bitmap_region);
 267     _verifier = new ShenandoahVerifier(this, &amp;_verification_bit_map);
 268   }
 269 
 270   // Reserve aux bitmap for use in object_iterate(). We don&#39;t commit it here.
 271   ReservedSpace aux_bitmap(_bitmap_size, bitmap_page_size);
 272   MemTracker::record_virtual_memory_type(aux_bitmap.base(), mtGC);
 273   _aux_bitmap_region = MemRegion((HeapWord*) aux_bitmap.base(), aux_bitmap.size() / HeapWordSize);
 274   _aux_bitmap_region_special = aux_bitmap.special();
 275   _aux_bit_map.initialize(_heap_region, _aux_bitmap_region);
 276 
 277   //
 278   // Create regions and region sets
 279   //










 280 
 281   _regions = NEW_C_HEAP_ARRAY(ShenandoahHeapRegion*, _num_regions, mtGC);
 282   _free_set = new ShenandoahFreeSet(this, _num_regions);
 283   _collection_set = new ShenandoahCollectionSet(this, sh_rs.base(), sh_rs.size());
 284 
 285   {
 286     ShenandoahHeapLocker locker(lock());
 287 
<span class="line-removed"> 288     size_t size_words = ShenandoahHeapRegion::region_size_words();</span>
<span class="line-removed"> 289 </span>
 290     for (size_t i = 0; i &lt; _num_regions; i++) {
<span class="line-modified"> 291       HeapWord* start = (HeapWord*)sh_rs.base() + size_words * i;</span>
 292       bool is_committed = i &lt; num_committed_regions;
<span class="line-modified"> 293       ShenandoahHeapRegion* r = new ShenandoahHeapRegion(this, start, size_words, i, is_committed);</span>



 294 
 295       _marking_context-&gt;initialize_top_at_mark_start(r);
 296       _regions[i] = r;
 297       assert(!collection_set()-&gt;is_in(i), &quot;New region should not be in collection set&quot;);
 298     }
 299 
 300     // Initialize to complete
 301     _marking_context-&gt;mark_complete();
 302 
 303     _free_set-&gt;rebuild();
 304   }
 305 
 306   if (ShenandoahAlwaysPreTouch) {
 307     assert(!AlwaysPreTouch, &quot;Should have been overridden&quot;);
 308 
 309     // For NUMA, it is important to pre-touch the storage under bitmaps with worker threads,
 310     // before initialize() below zeroes it with initializing thread. For any given region,
 311     // we touch the region and the corresponding bitmaps from the same thread.
 312     ShenandoahPushWorkerScope scope(workers(), _max_workers, false);
 313 
</pre>
<hr />
<pre>
 325 #endif
 326 
 327     // OS memory managers may want to coalesce back-to-back pages. Make their jobs
 328     // simpler by pre-touching continuous spaces (heap and bitmap) separately.
 329 
 330     log_info(gc, init)(&quot;Pretouch bitmap: &quot; SIZE_FORMAT &quot; regions, &quot; SIZE_FORMAT &quot; bytes page&quot;,
 331                        _num_regions, pretouch_bitmap_page_size);
 332     ShenandoahPretouchBitmapTask bcl(bitmap.base(), _bitmap_size, pretouch_bitmap_page_size);
 333     _workers-&gt;run_task(&amp;bcl);
 334 
 335     log_info(gc, init)(&quot;Pretouch heap: &quot; SIZE_FORMAT &quot; regions, &quot; SIZE_FORMAT &quot; bytes page&quot;,
 336                        _num_regions, pretouch_heap_page_size);
 337     ShenandoahPretouchHeapTask hcl(pretouch_heap_page_size);
 338     _workers-&gt;run_task(&amp;hcl);
 339   }
 340 
 341   //
 342   // Initialize the rest of GC subsystems
 343   //
 344 
<span class="line-modified"> 345   _liveness_cache = NEW_C_HEAP_ARRAY(jushort*, _max_workers, mtGC);</span>
 346   for (uint worker = 0; worker &lt; _max_workers; worker++) {
<span class="line-modified"> 347     _liveness_cache[worker] = NEW_C_HEAP_ARRAY(jushort, _num_regions, mtGC);</span>
<span class="line-modified"> 348     Copy::fill_to_bytes(_liveness_cache[worker], _num_regions * sizeof(jushort));</span>
 349   }
 350 
 351   // There should probably be Shenandoah-specific options for these,
 352   // just as there are G1-specific options.
 353   {
 354     ShenandoahSATBMarkQueueSet&amp; satbqs = ShenandoahBarrierSet::satb_mark_queue_set();
 355     satbqs.set_process_completed_buffers_threshold(20); // G1SATBProcessCompletedThreshold
 356     satbqs.set_buffer_enqueue_threshold_percentage(60); // G1SATBBufferEnqueueingThresholdPercent
 357   }
 358 
 359   _monitoring_support = new ShenandoahMonitoringSupport(this);
 360   _phase_timings = new ShenandoahPhaseTimings();
 361   ShenandoahStringDedup::initialize();
 362   ShenandoahCodeRoots::initialize();
 363 
 364   if (ShenandoahPacing) {
 365     _pacer = new ShenandoahPacer(this);
 366     _pacer-&gt;setup_for_idle();
 367   } else {
 368     _pacer = NULL;
 369   }
 370 
<span class="line-removed"> 371   _traversal_gc = strcmp(ShenandoahGCMode, &quot;traversal&quot;) == 0 ?</span>
<span class="line-removed"> 372                   new ShenandoahTraversalGC(this, _num_regions) :</span>
<span class="line-removed"> 373                   NULL;</span>
<span class="line-removed"> 374 </span>
 375   _control_thread = new ShenandoahControlThread();
 376 
 377   log_info(gc, init)(&quot;Initialize Shenandoah heap: &quot; SIZE_FORMAT &quot;%s initial, &quot; SIZE_FORMAT &quot;%s min, &quot; SIZE_FORMAT &quot;%s max&quot;,
 378                      byte_size_in_proper_unit(_initial_size),  proper_unit_for_byte_size(_initial_size),
 379                      byte_size_in_proper_unit(_minimum_size),  proper_unit_for_byte_size(_minimum_size),
 380                      byte_size_in_proper_unit(max_capacity()), proper_unit_for_byte_size(max_capacity())
 381   );
 382 
<span class="line-modified"> 383   log_info(gc, init)(&quot;Safepointing mechanism: %s&quot;,</span>
<span class="line-removed"> 384                      SafepointMechanism::uses_thread_local_poll() ? &quot;thread-local poll&quot; :</span>
<span class="line-removed"> 385                      (SafepointMechanism::uses_global_page_poll() ? &quot;global-page poll&quot; : &quot;unknown&quot;));</span>
 386 
 387   return JNI_OK;
 388 }
 389 
 390 void ShenandoahHeap::initialize_heuristics() {
 391   if (ShenandoahGCMode != NULL) {
<span class="line-modified"> 392     if (strcmp(ShenandoahGCMode, &quot;traversal&quot;) == 0) {</span>
<span class="line-removed"> 393       _gc_mode = new ShenandoahTraversalMode();</span>
<span class="line-removed"> 394     } else if (strcmp(ShenandoahGCMode, &quot;normal&quot;) == 0) {</span>
 395       _gc_mode = new ShenandoahNormalMode();


 396     } else if (strcmp(ShenandoahGCMode, &quot;passive&quot;) == 0) {
 397       _gc_mode = new ShenandoahPassiveMode();
 398     } else {
 399       vm_exit_during_initialization(&quot;Unknown -XX:ShenandoahGCMode option&quot;);
 400     }
 401   } else {
 402     ShouldNotReachHere();
 403   }
 404   _gc_mode-&gt;initialize_flags();













 405   _heuristics = _gc_mode-&gt;initialize_heuristics();
 406 
 407   if (_heuristics-&gt;is_diagnostic() &amp;&amp; !UnlockDiagnosticVMOptions) {
 408     vm_exit_during_initialization(
 409             err_msg(&quot;Heuristics \&quot;%s\&quot; is diagnostic, and must be enabled via -XX:+UnlockDiagnosticVMOptions.&quot;,
 410                     _heuristics-&gt;name()));
 411   }
 412   if (_heuristics-&gt;is_experimental() &amp;&amp; !UnlockExperimentalVMOptions) {
 413     vm_exit_during_initialization(
 414             err_msg(&quot;Heuristics \&quot;%s\&quot; is experimental, and must be enabled via -XX:+UnlockExperimentalVMOptions.&quot;,
 415                     _heuristics-&gt;name()));
 416   }
 417   log_info(gc, init)(&quot;Shenandoah heuristics: %s&quot;,
 418                      _heuristics-&gt;name());
 419 }
 420 
 421 #ifdef _MSC_VER
 422 #pragma warning( push )
 423 #pragma warning( disable:4355 ) // &#39;this&#39; : used in base member initializer list
 424 #endif
 425 
 426 ShenandoahHeap::ShenandoahHeap(ShenandoahCollectorPolicy* policy) :
 427   CollectedHeap(),
 428   _initial_size(0),
 429   _used(0),
 430   _committed(0),
 431   _bytes_allocated_since_gc_start(0),
 432   _max_workers(MAX2(ConcGCThreads, ParallelGCThreads)),
 433   _workers(NULL),
 434   _safepoint_workers(NULL),
 435   _heap_region_special(false),
 436   _num_regions(0),
 437   _regions(NULL),
 438   _update_refs_iterator(this),
 439   _control_thread(NULL),
 440   _shenandoah_policy(policy),
 441   _heuristics(NULL),
 442   _free_set(NULL),
 443   _scm(new ShenandoahConcurrentMark()),
<span class="line-removed"> 444   _traversal_gc(NULL),</span>
 445   _full_gc(new ShenandoahMarkCompact()),
 446   _pacer(NULL),
 447   _verifier(NULL),
 448   _phase_timings(NULL),
 449   _monitoring_support(NULL),
 450   _memory_pool(NULL),
 451   _stw_memory_manager(&quot;Shenandoah Pauses&quot;, &quot;end of GC pause&quot;),
 452   _cycle_memory_manager(&quot;Shenandoah Cycles&quot;, &quot;end of GC cycle&quot;),
 453   _gc_timer(new (ResourceObj::C_HEAP, mtGC) ConcurrentGCTimer()),
 454   _soft_ref_policy(),
 455   _log_min_obj_alignment_in_bytes(LogMinObjAlignmentInBytes),
 456   _ref_processor(NULL),
 457   _marking_context(NULL),
 458   _bitmap_size(0),
 459   _bitmap_regions_per_slice(0),
 460   _bitmap_bytes_per_slice(0),
 461   _bitmap_region_special(false),
 462   _aux_bitmap_region_special(false),
 463   _liveness_cache(NULL),
 464   _collection_set(NULL)
 465 {


 466   log_info(gc, init)(&quot;GC threads: &quot; UINT32_FORMAT &quot; parallel, &quot; UINT32_FORMAT &quot; concurrent&quot;, ParallelGCThreads, ConcGCThreads);
 467   log_info(gc, init)(&quot;Reference processing: %s&quot;, ParallelRefProcEnabled ? &quot;parallel&quot; : &quot;serial&quot;);
 468 
 469   BarrierSet::set_barrier_set(new ShenandoahBarrierSet(this));
 470 
 471   _max_workers = MAX2(_max_workers, 1U);
 472   _workers = new ShenandoahWorkGang(&quot;Shenandoah GC Threads&quot;, _max_workers,
 473                             /* are_GC_task_threads */ true,
 474                             /* are_ConcurrentGC_threads */ true);
 475   if (_workers == NULL) {
 476     vm_exit_during_initialization(&quot;Failed necessary allocation.&quot;);
 477   } else {
 478     _workers-&gt;initialize_workers();
 479   }
 480 
 481   if (ParallelGCThreads &gt; 1) {
 482     _safepoint_workers = new ShenandoahWorkGang(&quot;Safepoint Cleanup Thread&quot;,
 483                                                 ParallelGCThreads,
 484                       /* are_GC_task_threads */ false,
 485                  /* are_ConcurrentGC_threads */ false);
</pre>
<hr />
<pre>
 519   ShenandoahResetBitmapTask task;
 520   _workers-&gt;run_task(&amp;task);
 521 }
 522 
 523 void ShenandoahHeap::print_on(outputStream* st) const {
 524   st-&gt;print_cr(&quot;Shenandoah Heap&quot;);
 525   st-&gt;print_cr(&quot; &quot; SIZE_FORMAT &quot;%s total, &quot; SIZE_FORMAT &quot;%s committed, &quot; SIZE_FORMAT &quot;%s used&quot;,
 526                byte_size_in_proper_unit(max_capacity()), proper_unit_for_byte_size(max_capacity()),
 527                byte_size_in_proper_unit(committed()),    proper_unit_for_byte_size(committed()),
 528                byte_size_in_proper_unit(used()),         proper_unit_for_byte_size(used()));
 529   st-&gt;print_cr(&quot; &quot; SIZE_FORMAT &quot; x &quot; SIZE_FORMAT&quot;%s regions&quot;,
 530                num_regions(),
 531                byte_size_in_proper_unit(ShenandoahHeapRegion::region_size_bytes()),
 532                proper_unit_for_byte_size(ShenandoahHeapRegion::region_size_bytes()));
 533 
 534   st-&gt;print(&quot;Status: &quot;);
 535   if (has_forwarded_objects())               st-&gt;print(&quot;has forwarded objects, &quot;);
 536   if (is_concurrent_mark_in_progress())      st-&gt;print(&quot;marking, &quot;);
 537   if (is_evacuation_in_progress())           st-&gt;print(&quot;evacuating, &quot;);
 538   if (is_update_refs_in_progress())          st-&gt;print(&quot;updating refs, &quot;);
<span class="line-removed"> 539   if (is_concurrent_traversal_in_progress()) st-&gt;print(&quot;traversal, &quot;);</span>
 540   if (is_degenerated_gc_in_progress())       st-&gt;print(&quot;degenerated gc, &quot;);
 541   if (is_full_gc_in_progress())              st-&gt;print(&quot;full gc, &quot;);
 542   if (is_full_gc_move_in_progress())         st-&gt;print(&quot;full gc move, &quot;);
 543   if (is_concurrent_root_in_progress())      st-&gt;print(&quot;concurrent roots, &quot;);
 544 
 545   if (cancelled_gc()) {
 546     st-&gt;print(&quot;cancelled&quot;);
 547   } else {
 548     st-&gt;print(&quot;not cancelled&quot;);
 549   }
 550   st-&gt;cr();
 551 
 552   st-&gt;print_cr(&quot;Reserved region:&quot;);
 553   st-&gt;print_cr(&quot; - [&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT &quot;) &quot;,
 554                p2i(reserved_region().start()),
 555                p2i(reserved_region().end()));
 556 
 557   ShenandoahCollectionSet* cset = collection_set();
 558   st-&gt;print_cr(&quot;Collection set:&quot;);
 559   if (cset != NULL) {
</pre>
<hr />
<pre>
 594   _scm-&gt;initialize(_max_workers);
 595   _full_gc-&gt;initialize(_gc_timer);
 596 
 597   ref_processing_init();
 598 
 599   _heuristics-&gt;initialize();
 600 
 601   JFR_ONLY(ShenandoahJFRSupport::register_jfr_type_serializers());
 602 }
 603 
 604 size_t ShenandoahHeap::used() const {
 605   return Atomic::load_acquire(&amp;_used);
 606 }
 607 
 608 size_t ShenandoahHeap::committed() const {
 609   OrderAccess::acquire();
 610   return _committed;
 611 }
 612 
 613 void ShenandoahHeap::increase_committed(size_t bytes) {
<span class="line-modified"> 614   assert_heaplock_or_safepoint();</span>
 615   _committed += bytes;
 616 }
 617 
 618 void ShenandoahHeap::decrease_committed(size_t bytes) {
<span class="line-modified"> 619   assert_heaplock_or_safepoint();</span>
 620   _committed -= bytes;
 621 }
 622 
 623 void ShenandoahHeap::increase_used(size_t bytes) {
 624   Atomic::add(&amp;_used, bytes);
 625 }
 626 
 627 void ShenandoahHeap::set_used(size_t bytes) {
 628   Atomic::release_store_fence(&amp;_used, bytes);
 629 }
 630 
 631 void ShenandoahHeap::decrease_used(size_t bytes) {
 632   assert(used() &gt;= bytes, &quot;never decrease heap size by more than we&#39;ve left&quot;);
 633   Atomic::sub(&amp;_used, bytes);
 634 }
 635 
 636 void ShenandoahHeap::increase_allocated(size_t bytes) {
 637   Atomic::add(&amp;_bytes_allocated_since_gc_start, bytes);
 638 }
 639 
</pre>
<hr />
<pre>
 762     *actual_size = req.actual_size();
 763   } else {
 764     *actual_size = 0;
 765   }
 766   return res;
 767 }
 768 
 769 HeapWord* ShenandoahHeap::allocate_new_gclab(size_t min_size,
 770                                              size_t word_size,
 771                                              size_t* actual_size) {
 772   ShenandoahAllocRequest req = ShenandoahAllocRequest::for_gclab(min_size, word_size);
 773   HeapWord* res = allocate_memory(req);
 774   if (res != NULL) {
 775     *actual_size = req.actual_size();
 776   } else {
 777     *actual_size = 0;
 778   }
 779   return res;
 780 }
 781 
<span class="line-removed"> 782 ShenandoahHeap* ShenandoahHeap::heap() {</span>
<span class="line-removed"> 783   CollectedHeap* heap = Universe::heap();</span>
<span class="line-removed"> 784   assert(heap != NULL, &quot;Unitialized access to ShenandoahHeap::heap()&quot;);</span>
<span class="line-removed"> 785   assert(heap-&gt;kind() == CollectedHeap::Shenandoah, &quot;not a shenandoah heap&quot;);</span>
<span class="line-removed"> 786   return (ShenandoahHeap*) heap;</span>
<span class="line-removed"> 787 }</span>
<span class="line-removed"> 788 </span>
<span class="line-removed"> 789 ShenandoahHeap* ShenandoahHeap::heap_no_check() {</span>
<span class="line-removed"> 790   CollectedHeap* heap = Universe::heap();</span>
<span class="line-removed"> 791   return (ShenandoahHeap*) heap;</span>
<span class="line-removed"> 792 }</span>
<span class="line-removed"> 793 </span>
 794 HeapWord* ShenandoahHeap::allocate_memory(ShenandoahAllocRequest&amp; req) {
 795   intptr_t pacer_epoch = 0;
 796   bool in_new_region = false;
 797   HeapWord* result = NULL;
 798 
 799   if (req.is_mutator_alloc()) {
 800     if (ShenandoahPacing) {
 801       pacer()-&gt;pace_for_alloc(req.size());
 802       pacer_epoch = pacer()-&gt;epoch();
 803     }
 804 
 805     if (!ShenandoahAllocFailureALot || !should_inject_alloc_failure()) {
 806       result = allocate_memory_under_lock(req, in_new_region);
 807     }
 808 
 809     // Allocation failed, block until control thread reacted, then retry allocation.
 810     //
 811     // It might happen that one of the threads requesting allocation would unblock
 812     // way later after GC happened, only to fail the second allocation, because
 813     // other threads have already depleted the free storage. In this case, a better
 814     // strategy is to try again, as long as GC makes progress.
 815     //
 816     // Then, we need to make sure the allocation was retried after at least one
 817     // Full GC, which means we want to try more than ShenandoahFullGCThreshold times.
 818 
 819     size_t tries = 0;
 820 
 821     while (result == NULL &amp;&amp; _progress_last_gc.is_set()) {
 822       tries++;
<span class="line-modified"> 823       control_thread()-&gt;handle_alloc_failure(req.size());</span>
 824       result = allocate_memory_under_lock(req, in_new_region);
 825     }
 826 
 827     while (result == NULL &amp;&amp; tries &lt;= ShenandoahFullGCThreshold) {
 828       tries++;
<span class="line-modified"> 829       control_thread()-&gt;handle_alloc_failure(req.size());</span>
 830       result = allocate_memory_under_lock(req, in_new_region);
 831     }
 832 
 833   } else {
 834     assert(req.is_gc_alloc(), &quot;Can only accept GC allocs here&quot;);
 835     result = allocate_memory_under_lock(req, in_new_region);
 836     // Do not call handle_alloc_failure() here, because we cannot block.
 837     // The allocation failure would be handled by the LRB slowpath with handle_alloc_failure_evac().
 838   }
 839 
 840   if (in_new_region) {
 841     control_thread()-&gt;notify_heap_changed();
 842   }
 843 
 844   if (result != NULL) {
 845     size_t requested = req.size();
 846     size_t actual = req.actual_size();
 847 
 848     assert (req.is_lab_alloc() || (requested == actual),
 849             &quot;Only LAB allocations are elastic: %s, requested = &quot; SIZE_FORMAT &quot;, actual = &quot; SIZE_FORMAT,
</pre>
<hr />
<pre>
 945   {}
 946 
 947   void work(uint worker_id) {
 948     if (_concurrent) {
 949       ShenandoahConcurrentWorkerSession worker_session(worker_id);
 950       ShenandoahSuspendibleThreadSetJoiner stsj(ShenandoahSuspendibleWorkers);
 951       ShenandoahEvacOOMScope oom_evac_scope;
 952       do_work();
 953     } else {
 954       ShenandoahParallelWorkerSession worker_session(worker_id);
 955       ShenandoahEvacOOMScope oom_evac_scope;
 956       do_work();
 957     }
 958   }
 959 
 960 private:
 961   void do_work() {
 962     ShenandoahConcurrentEvacuateRegionObjectClosure cl(_sh);
 963     ShenandoahHeapRegion* r;
 964     while ((r =_cs-&gt;claim_next()) != NULL) {
<span class="line-modified"> 965       assert(r-&gt;has_live(), &quot;Region &quot; SIZE_FORMAT &quot; should have been reclaimed early&quot;, r-&gt;region_number());</span>
 966       _sh-&gt;marked_object_iterate(r, &amp;cl);
 967 
 968       if (ShenandoahPacing) {
 969         _sh-&gt;pacer()-&gt;report_evac(r-&gt;used() &gt;&gt; LogHeapWordSize);
 970       }
 971 
 972       if (_sh-&gt;check_cancelled_gc_and_yield(_concurrent)) {
 973         break;
 974       }
 975     }
 976   }
 977 };
 978 
 979 void ShenandoahHeap::trash_cset_regions() {
 980   ShenandoahHeapLocker locker(lock());
 981 
 982   ShenandoahCollectionSet* set = collection_set();
 983   ShenandoahHeapRegion* r;
 984   set-&gt;clear_current_index();
 985   while ((r = set-&gt;next()) != NULL) {
 986     r-&gt;make_trash();
 987   }
 988   collection_set()-&gt;clear();
 989 }
 990 
 991 void ShenandoahHeap::print_heap_regions_on(outputStream* st) const {
 992   st-&gt;print_cr(&quot;Heap Regions:&quot;);
 993   st-&gt;print_cr(&quot;EU=empty-uncommitted, EC=empty-committed, R=regular, H=humongous start, HC=humongous continuation, CS=collection set, T=trash, P=pinned&quot;);
 994   st-&gt;print_cr(&quot;BTE=bottom/top/end, U=used, T=TLAB allocs, G=GCLAB allocs, S=shared allocs, L=live data&quot;);
<span class="line-modified"> 995   st-&gt;print_cr(&quot;R=root, CP=critical pins, TAMS=top-at-mark-start (previous, next)&quot;);</span>
<span class="line-modified"> 996   st-&gt;print_cr(&quot;SN=alloc sequence numbers (first mutator, last mutator, first gc, last gc)&quot;);</span>
 997 
 998   for (size_t i = 0; i &lt; num_regions(); i++) {
 999     get_region(i)-&gt;print_on(st);
1000   }
1001 }
1002 
1003 void ShenandoahHeap::trash_humongous_region_at(ShenandoahHeapRegion* start) {
1004   assert(start-&gt;is_humongous_start(), &quot;reclaim regions starting with the first one&quot;);
1005 
1006   oop humongous_obj = oop(start-&gt;bottom());
1007   size_t size = humongous_obj-&gt;size();
1008   size_t required_regions = ShenandoahHeapRegion::required_regions(size * HeapWordSize);
<span class="line-modified">1009   size_t index = start-&gt;region_number() + required_regions - 1;</span>
1010 
1011   assert(!start-&gt;has_live(), &quot;liveness must be zero&quot;);
1012 
1013   for(size_t i = 0; i &lt; required_regions; i++) {
1014     // Reclaim from tail. Otherwise, assertion fails when printing region to trace log,
1015     // as it expects that every region belongs to a humongous region starting with a humongous start region.
1016     ShenandoahHeapRegion* region = get_region(index --);
1017 
1018     assert(region-&gt;is_humongous(), &quot;expect correct humongous start or continuation&quot;);
1019     assert(!region-&gt;is_cset(), &quot;Humongous region should not be in collection set&quot;);
1020 
1021     region-&gt;make_trash_immediate();
1022   }
1023 }
1024 
1025 class ShenandoahRetireGCLABClosure : public ThreadClosure {
1026 public:
1027   void do_thread(Thread* thread) {
1028     PLAB* gclab = ShenandoahThreadLocalData::gclab(thread);
1029     assert(gclab != NULL, &quot;GCLAB should be initialized for %s&quot;, thread-&gt;name());
</pre>
<hr />
<pre>
1111   }
1112 };
1113 
1114 void ShenandoahHeap::retire_and_reset_gclabs() {
1115   ShenandoahRetireAndResetGCLABClosure cl;
1116   for (JavaThreadIteratorWithHandle jtiwh; JavaThread *t = jtiwh.next(); ) {
1117     cl.do_thread(t);
1118   }
1119   workers()-&gt;threads_do(&amp;cl);
1120 }
1121 
1122 void ShenandoahHeap::collect(GCCause::Cause cause) {
1123   control_thread()-&gt;request_gc(cause);
1124 }
1125 
1126 void ShenandoahHeap::do_full_collection(bool clear_all_soft_refs) {
1127   //assert(false, &quot;Shouldn&#39;t need to do full collections&quot;);
1128 }
1129 
1130 HeapWord* ShenandoahHeap::block_start(const void* addr) const {
<span class="line-modified">1131   Space* sp = heap_region_containing(addr);</span>
<span class="line-modified">1132   if (sp != NULL) {</span>
<span class="line-modified">1133     return sp-&gt;block_start(addr);</span>
1134   }
1135   return NULL;
1136 }
1137 
1138 bool ShenandoahHeap::block_is_obj(const HeapWord* addr) const {
<span class="line-modified">1139   Space* sp = heap_region_containing(addr);</span>
<span class="line-modified">1140   return sp-&gt;block_is_obj(addr);</span>
1141 }
1142 
1143 bool ShenandoahHeap::print_location(outputStream* st, void* addr) const {
1144   return BlockLocationPrinter&lt;ShenandoahHeap&gt;::print_location(st, addr);
1145 }
1146 
1147 jlong ShenandoahHeap::millis_since_last_gc() {
1148   double v = heuristics()-&gt;time_since_last_gc() * 1000;
1149   assert(0 &lt;= v &amp;&amp; v &lt;= max_jlong, &quot;value should fit: %f&quot;, v);
1150   return (jlong)v;
1151 }
1152 
1153 void ShenandoahHeap::prepare_for_verify() {
1154   if (SafepointSynchronize::is_at_safepoint() || ! UseTLAB) {
1155     make_parsable(false);
1156   }
1157 }
1158 
1159 void ShenandoahHeap::print_gc_threads_on(outputStream* st) const {
1160   workers()-&gt;print_worker_threads_on(st);
</pre>
<hr />
<pre>
1305 
1306 // Keep alive an object that was loaded with AS_NO_KEEPALIVE.
1307 void ShenandoahHeap::keep_alive(oop obj) {
1308   if (is_concurrent_mark_in_progress()) {
1309     ShenandoahBarrierSet::barrier_set()-&gt;enqueue(obj);
1310   }
1311 }
1312 
1313 void ShenandoahHeap::heap_region_iterate(ShenandoahHeapRegionClosure* blk) const {
1314   for (size_t i = 0; i &lt; num_regions(); i++) {
1315     ShenandoahHeapRegion* current = get_region(i);
1316     blk-&gt;heap_region_do(current);
1317   }
1318 }
1319 
1320 class ShenandoahParallelHeapRegionTask : public AbstractGangTask {
1321 private:
1322   ShenandoahHeap* const _heap;
1323   ShenandoahHeapRegionClosure* const _blk;
1324 
<span class="line-modified">1325   DEFINE_PAD_MINUS_SIZE(0, DEFAULT_CACHE_LINE_SIZE, sizeof(volatile size_t));</span>
1326   volatile size_t _index;
<span class="line-modified">1327   DEFINE_PAD_MINUS_SIZE(1, DEFAULT_CACHE_LINE_SIZE, 0);</span>
1328 
1329 public:
1330   ShenandoahParallelHeapRegionTask(ShenandoahHeapRegionClosure* blk) :
1331           AbstractGangTask(&quot;Parallel Region Task&quot;),
1332           _heap(ShenandoahHeap::heap()), _blk(blk), _index(0) {}
1333 
1334   void work(uint worker_id) {
1335     size_t stride = ShenandoahParallelRegionStride;
1336 
1337     size_t max = _heap-&gt;num_regions();
1338     while (_index &lt; max) {
1339       size_t cur = Atomic::fetch_and_add(&amp;_index, stride);
1340       size_t start = cur;
1341       size_t end = MIN2(cur + stride, max);
1342       if (start &gt;= max) break;
1343 
1344       for (size_t i = cur; i &lt; end; i++) {
1345         ShenandoahHeapRegion* current = _heap-&gt;get_region(i);
1346         _blk-&gt;heap_region_do(current);
1347       }
1348     }
1349   }
1350 };
1351 
1352 void ShenandoahHeap::parallel_heap_region_iterate(ShenandoahHeapRegionClosure* blk) const {
1353   assert(blk-&gt;is_thread_safe(), &quot;Only thread-safe closures here&quot;);
1354   if (num_regions() &gt; ShenandoahParallelRegionStride) {
1355     ShenandoahParallelHeapRegionTask task(blk);
1356     workers()-&gt;run_task(&amp;task);
1357   } else {
1358     heap_region_iterate(blk);
1359   }
1360 }
1361 
<span class="line-modified">1362 class ShenandoahClearLivenessClosure : public ShenandoahHeapRegionClosure {</span>
1363 private:
1364   ShenandoahMarkingContext* const _ctx;
1365 public:
<span class="line-modified">1366   ShenandoahClearLivenessClosure() : _ctx(ShenandoahHeap::heap()-&gt;marking_context()) {}</span>
1367 
1368   void heap_region_do(ShenandoahHeapRegion* r) {
1369     if (r-&gt;is_active()) {
1370       r-&gt;clear_live_data();
1371       _ctx-&gt;capture_top_at_mark_start(r);
1372     } else {
<span class="line-modified">1373       assert(!r-&gt;has_live(), &quot;Region &quot; SIZE_FORMAT &quot; should have no live data&quot;, r-&gt;region_number());</span>
1374       assert(_ctx-&gt;top_at_mark_start(r) == r-&gt;top(),
<span class="line-modified">1375              &quot;Region &quot; SIZE_FORMAT &quot; should already have correct TAMS&quot;, r-&gt;region_number());</span>
1376     }
1377   }
1378 
1379   bool is_thread_safe() { return true; }
1380 };
1381 
1382 void ShenandoahHeap::op_init_mark() {
1383   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should be at safepoint&quot;);
1384   assert(Thread::current()-&gt;is_VM_thread(), &quot;can only do this in VMThread&quot;);
1385 
1386   assert(marking_context()-&gt;is_bitmap_clear(), &quot;need clear marking bitmap&quot;);
1387   assert(!marking_context()-&gt;is_complete(), &quot;should not be complete&quot;);

1388 
1389   if (ShenandoahVerify) {
1390     verifier()-&gt;verify_before_concmark();
1391   }
1392 
1393   if (VerifyBeforeGC) {
1394     Universe::verify();
1395   }
1396 
1397   set_concurrent_mark_in_progress(true);
1398   // We need to reset all TLABs because we&#39;d lose marks on all objects allocated in them.
1399   {
<span class="line-modified">1400     ShenandoahGCPhase phase(ShenandoahPhaseTimings::make_parsable);</span>
1401     make_parsable(true);
1402   }
1403 
1404   {
<span class="line-modified">1405     ShenandoahGCPhase phase(ShenandoahPhaseTimings::clear_liveness);</span>
<span class="line-modified">1406     ShenandoahClearLivenessClosure clc;</span>
<span class="line-modified">1407     parallel_heap_region_iterate(&amp;clc);</span>
1408   }
1409 
1410   // Make above changes visible to worker threads
1411   OrderAccess::fence();
1412 
1413   concurrent_mark()-&gt;mark_roots(ShenandoahPhaseTimings::scan_roots);
1414 
1415   if (UseTLAB) {
<span class="line-modified">1416     ShenandoahGCPhase phase(ShenandoahPhaseTimings::resize_tlabs);</span>
1417     resize_tlabs();
1418   }
1419 
1420   if (ShenandoahPacing) {
1421     pacer()-&gt;setup_for_mark();
1422   }







1423 }
1424 
1425 void ShenandoahHeap::op_mark() {
1426   concurrent_mark()-&gt;mark_from_roots();
1427 }
1428 
<span class="line-modified">1429 class ShenandoahCompleteLivenessClosure : public ShenandoahHeapRegionClosure {</span>
1430 private:
1431   ShenandoahMarkingContext* const _ctx;


1432 public:
<span class="line-modified">1433   ShenandoahCompleteLivenessClosure() : _ctx(ShenandoahHeap::heap()-&gt;complete_marking_context()) {}</span>

1434 
1435   void heap_region_do(ShenandoahHeapRegion* r) {
1436     if (r-&gt;is_active()) {


1437       HeapWord *tams = _ctx-&gt;top_at_mark_start(r);
1438       HeapWord *top = r-&gt;top();
1439       if (top &gt; tams) {
1440         r-&gt;increase_live_data_alloc_words(pointer_delta(top, tams));
1441       }



















1442     } else {
<span class="line-modified">1443       assert(!r-&gt;has_live(), &quot;Region &quot; SIZE_FORMAT &quot; should have no live data&quot;, r-&gt;region_number());</span>
1444       assert(_ctx-&gt;top_at_mark_start(r) == r-&gt;top(),
<span class="line-modified">1445              &quot;Region &quot; SIZE_FORMAT &quot; should have correct TAMS&quot;, r-&gt;region_number());</span>
1446     }
1447   }
1448 
1449   bool is_thread_safe() { return true; }
1450 };
1451 
1452 void ShenandoahHeap::op_final_mark() {
1453   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should be at safepoint&quot;);

1454 
1455   // It is critical that we
1456   // evacuate roots right after finishing marking, so that we don&#39;t
1457   // get unmarked objects in the roots.
1458 
1459   if (!cancelled_gc()) {
1460     concurrent_mark()-&gt;finish_mark_from_roots(/* full_gc = */ false);
1461 
1462     // Marking is completed, deactivate SATB barrier
1463     set_concurrent_mark_in_progress(false);
1464     mark_complete_marking_context();
1465 
1466     parallel_cleaning(false /* full gc*/);
1467 
<span class="line-removed">1468     if (has_forwarded_objects()) {</span>
<span class="line-removed">1469       // Degen may be caused by failed evacuation of roots</span>
<span class="line-removed">1470       if (is_degenerated_gc_in_progress()) {</span>
<span class="line-removed">1471         concurrent_mark()-&gt;update_roots(ShenandoahPhaseTimings::degen_gc_update_roots);</span>
<span class="line-removed">1472       } else {</span>
<span class="line-removed">1473         concurrent_mark()-&gt;update_thread_roots(ShenandoahPhaseTimings::update_roots);</span>
<span class="line-removed">1474       }</span>
<span class="line-removed">1475       set_has_forwarded_objects(false);</span>
<span class="line-removed">1476    }</span>
<span class="line-removed">1477 </span>
1478     if (ShenandoahVerify) {
1479       verifier()-&gt;verify_roots_no_forwarded();
1480     }
<span class="line-modified">1481     // All allocations past TAMS are implicitly live, adjust the region data.</span>
<span class="line-removed">1482     // Bitmaps/TAMS are swapped at this point, so we need to poll complete bitmap.</span>
1483     {
<span class="line-modified">1484       ShenandoahGCPhase phase(ShenandoahPhaseTimings::complete_liveness);</span>
<span class="line-modified">1485       ShenandoahCompleteLivenessClosure cl;</span>
1486       parallel_heap_region_iterate(&amp;cl);


1487     }
1488 
1489     // Force the threads to reacquire their TLABs outside the collection set.
1490     {
<span class="line-modified">1491       ShenandoahGCPhase phase(ShenandoahPhaseTimings::retire_tlabs);</span>
1492       make_parsable(true);
1493     }
1494 
<span class="line-removed">1495     // We are about to select the collection set, make sure it knows about</span>
<span class="line-removed">1496     // current pinning status. Also, this allows trashing more regions that</span>
<span class="line-removed">1497     // now have their pinning status dropped.</span>
<span class="line-removed">1498     {</span>
<span class="line-removed">1499       ShenandoahGCPhase phase(ShenandoahPhaseTimings::sync_pinned);</span>
<span class="line-removed">1500       sync_pinned_region_status();</span>
<span class="line-removed">1501     }</span>
<span class="line-removed">1502 </span>
<span class="line-removed">1503     // Trash the collection set left over from previous cycle, if any.</span>
<span class="line-removed">1504     {</span>
<span class="line-removed">1505       ShenandoahGCPhase phase(ShenandoahPhaseTimings::trash_cset);</span>
<span class="line-removed">1506       trash_cset_regions();</span>
<span class="line-removed">1507     }</span>
<span class="line-removed">1508 </span>
1509     {
<span class="line-modified">1510       ShenandoahGCPhase phase(ShenandoahPhaseTimings::prepare_evac);</span>
<span class="line-removed">1511 </span>
1512       ShenandoahHeapLocker locker(lock());
1513       _collection_set-&gt;clear();
<span class="line-removed">1514       _free_set-&gt;clear();</span>
<span class="line-removed">1515 </span>
1516       heuristics()-&gt;choose_collection_set(_collection_set);

1517 



1518       _free_set-&gt;rebuild();
1519     }
1520 
1521     if (!is_degenerated_gc_in_progress()) {
1522       prepare_concurrent_roots();
1523       prepare_concurrent_unloading();
1524     }
1525 
1526     // If collection set has candidates, start evacuation.
1527     // Otherwise, bypass the rest of the cycle.
1528     if (!collection_set()-&gt;is_empty()) {
<span class="line-modified">1529       ShenandoahGCPhase init_evac(ShenandoahPhaseTimings::init_evac);</span>
1530 
1531       if (ShenandoahVerify) {
1532         verifier()-&gt;verify_before_evacuation();
1533       }
1534 
1535       set_evacuation_in_progress(true);
1536       // From here on, we need to update references.
1537       set_has_forwarded_objects(true);
1538 
1539       if (!is_degenerated_gc_in_progress()) {
1540         if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
1541           ShenandoahCodeRoots::arm_nmethods();
1542         }
1543         evacuate_and_update_roots();
1544       }
1545 
1546       if (ShenandoahPacing) {
1547         pacer()-&gt;setup_for_evac();
1548       }
1549 
</pre>
<hr />
<pre>
1570         Universe::verify();
1571       }
1572     }
1573 
1574   } else {
1575     // If this cycle was updating references, we need to keep the has_forwarded_objects
1576     // flag on, for subsequent phases to deal with it.
1577     concurrent_mark()-&gt;cancel();
1578     set_concurrent_mark_in_progress(false);
1579 
1580     if (process_references()) {
1581       // Abandon reference processing right away: pre-cleaning must have failed.
1582       ReferenceProcessor *rp = ref_processor();
1583       rp-&gt;disable_discovery();
1584       rp-&gt;abandon_partial_discovery();
1585       rp-&gt;verify_no_references_recorded();
1586     }
1587   }
1588 }
1589 
<span class="line-removed">1590 void ShenandoahHeap::op_final_evac() {</span>
<span class="line-removed">1591   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should be at safepoint&quot;);</span>
<span class="line-removed">1592 </span>
<span class="line-removed">1593   set_evacuation_in_progress(false);</span>
<span class="line-removed">1594 </span>
<span class="line-removed">1595   {</span>
<span class="line-removed">1596     ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_evac_retire_gclabs);</span>
<span class="line-removed">1597     retire_and_reset_gclabs();</span>
<span class="line-removed">1598   }</span>
<span class="line-removed">1599 </span>
<span class="line-removed">1600   if (ShenandoahVerify) {</span>
<span class="line-removed">1601     verifier()-&gt;verify_after_evacuation();</span>
<span class="line-removed">1602   }</span>
<span class="line-removed">1603 </span>
<span class="line-removed">1604   if (VerifyAfterGC) {</span>
<span class="line-removed">1605     Universe::verify();</span>
<span class="line-removed">1606   }</span>
<span class="line-removed">1607 }</span>
<span class="line-removed">1608 </span>
1609 void ShenandoahHeap::op_conc_evac() {
1610   ShenandoahEvacuationTask task(this, _collection_set, true);
1611   workers()-&gt;run_task(&amp;task);
1612 }
1613 
1614 void ShenandoahHeap::op_stw_evac() {
1615   ShenandoahEvacuationTask task(this, _collection_set, false);
1616   workers()-&gt;run_task(&amp;task);
1617 }
1618 
1619 void ShenandoahHeap::op_updaterefs() {
1620   update_heap_references(true);
1621 }
1622 
1623 void ShenandoahHeap::op_cleanup() {
1624   free_set()-&gt;recycle_trash();
1625 }
1626 
1627 class ShenandoahConcurrentRootsEvacUpdateTask : public AbstractGangTask {
1628 private:
</pre>
<hr />
<pre>
1783     }
1784   }
1785 
1786   set_concurrent_root_in_progress(false);
1787 }
1788 
1789 void ShenandoahHeap::op_reset() {
1790   if (ShenandoahPacing) {
1791     pacer()-&gt;setup_for_reset();
1792   }
1793   reset_mark_bitmap();
1794 }
1795 
1796 void ShenandoahHeap::op_preclean() {
1797   if (ShenandoahPacing) {
1798     pacer()-&gt;setup_for_preclean();
1799   }
1800   concurrent_mark()-&gt;preclean_weak_refs();
1801 }
1802 
<span class="line-removed">1803 void ShenandoahHeap::op_init_traversal() {</span>
<span class="line-removed">1804   traversal_gc()-&gt;init_traversal_collection();</span>
<span class="line-removed">1805 }</span>
<span class="line-removed">1806 </span>
<span class="line-removed">1807 void ShenandoahHeap::op_traversal() {</span>
<span class="line-removed">1808   traversal_gc()-&gt;concurrent_traversal_collection();</span>
<span class="line-removed">1809 }</span>
<span class="line-removed">1810 </span>
<span class="line-removed">1811 void ShenandoahHeap::op_final_traversal() {</span>
<span class="line-removed">1812   traversal_gc()-&gt;final_traversal_collection();</span>
<span class="line-removed">1813 }</span>
<span class="line-removed">1814 </span>
1815 void ShenandoahHeap::op_full(GCCause::Cause cause) {
1816   ShenandoahMetricsSnapshot metrics;
1817   metrics.snap_before();
1818 
1819   full_gc()-&gt;do_it(cause);
1820   if (UseTLAB) {
<span class="line-modified">1821     ShenandoahGCPhase phase(ShenandoahPhaseTimings::full_gc_resize_tlabs);</span>
1822     resize_all_tlabs();
1823   }
1824 
1825   metrics.snap_after();
1826 
1827   if (metrics.is_good_progress()) {
1828     _progress_last_gc.set();
1829   } else {
1830     // Nothing to do. Tell the allocation path that we have failed to make
1831     // progress, and it can finally fail.
1832     _progress_last_gc.unset();
1833   }
1834 }
1835 
1836 void ShenandoahHeap::op_degenerated(ShenandoahDegenPoint point) {
1837   // Degenerated GC is STW, but it can also fail. Current mechanics communicates
1838   // GC failure via cancelled_concgc() flag. So, if we detect the failure after
1839   // some phase, we have to upgrade the Degenerate GC to Full GC.
1840 
1841   clear_cancelled_gc();
1842 
1843   ShenandoahMetricsSnapshot metrics;
1844   metrics.snap_before();
1845 
1846   switch (point) {
<span class="line-removed">1847     case _degenerated_traversal:</span>
<span class="line-removed">1848       {</span>
<span class="line-removed">1849         // Drop the collection set. Note: this leaves some already forwarded objects</span>
<span class="line-removed">1850         // behind, which may be problematic, see comments for ShenandoahEvacAssist</span>
<span class="line-removed">1851         // workarounds in ShenandoahTraversalHeuristics.</span>
<span class="line-removed">1852 </span>
<span class="line-removed">1853         ShenandoahHeapLocker locker(lock());</span>
<span class="line-removed">1854         collection_set()-&gt;clear_current_index();</span>
<span class="line-removed">1855         for (size_t i = 0; i &lt; collection_set()-&gt;count(); i++) {</span>
<span class="line-removed">1856           ShenandoahHeapRegion* r = collection_set()-&gt;next();</span>
<span class="line-removed">1857           r-&gt;make_regular_bypass();</span>
<span class="line-removed">1858         }</span>
<span class="line-removed">1859         collection_set()-&gt;clear();</span>
<span class="line-removed">1860       }</span>
<span class="line-removed">1861       op_final_traversal();</span>
<span class="line-removed">1862       op_cleanup();</span>
<span class="line-removed">1863       return;</span>
<span class="line-removed">1864 </span>
1865     // The cases below form the Duff&#39;s-like device: it describes the actual GC cycle,
1866     // but enters it at different points, depending on which concurrent phase had
1867     // degenerated.
1868 
1869     case _degenerated_outside_cycle:
1870       // We have degenerated from outside the cycle, which means something is bad with
1871       // the heap, most probably heavy humongous fragmentation, or we are very low on free
1872       // space. It makes little sense to wait for Full GC to reclaim as much as it can, when
1873       // we can do the most aggressive degen cycle, which includes processing references and
1874       // class unloading, unless those features are explicitly disabled.
1875       //
1876       // Note that we can only do this for &quot;outside-cycle&quot; degens, otherwise we would risk
1877       // changing the cycle parameters mid-cycle during concurrent -&gt; degenerated handover.
1878       set_process_references(heuristics()-&gt;can_process_references());
1879       set_unload_classes(heuristics()-&gt;can_unload_classes());
1880 
<span class="line-removed">1881       if (is_traversal_mode()) {</span>
<span class="line-removed">1882         // Not possible to degenerate from here, upgrade to Full GC right away.</span>
<span class="line-removed">1883         cancel_gc(GCCause::_shenandoah_upgrade_to_full_gc);</span>
<span class="line-removed">1884         op_degenerated_fail();</span>
<span class="line-removed">1885         return;</span>
<span class="line-removed">1886       }</span>
<span class="line-removed">1887 </span>
1888       op_reset();
1889 
1890       op_init_mark();
1891       if (cancelled_gc()) {
1892         op_degenerated_fail();
1893         return;
1894       }
1895 
1896     case _degenerated_mark:
1897       op_final_mark();
1898       if (cancelled_gc()) {
1899         op_degenerated_fail();
1900         return;
1901       }
1902 







1903       op_cleanup();
1904 
1905     case _degenerated_evac:
1906       // If heuristics thinks we should do the cycle, this flag would be set,
1907       // and we can do evacuation. Otherwise, it would be the shortcut cycle.
1908       if (is_evacuation_in_progress()) {
1909 
1910         // Degeneration under oom-evac protocol might have left some objects in
1911         // collection set un-evacuated. Restart evacuation from the beginning to
1912         // capture all objects. For all the objects that are already evacuated,
1913         // it would be a simple check, which is supposed to be fast. This is also
1914         // safe to do even without degeneration, as CSet iterator is at beginning
1915         // in preparation for evacuation anyway.
1916         //
1917         // Before doing that, we need to make sure we never had any cset-pinned
1918         // regions. This may happen if allocation failure happened when evacuating
1919         // the about-to-be-pinned object, oom-evac protocol left the object in
1920         // the collection set, and then the pin reached the cset region. If we continue
1921         // the cycle here, we would trash the cset and alive objects in it. To avoid
1922         // it, we fail degeneration right away and slide into Full GC to recover.
</pre>
<hr />
<pre>
1986     _progress_last_gc.unset();
1987     cancel_gc(GCCause::_shenandoah_upgrade_to_full_gc);
1988     op_degenerated_futile();
1989   } else {
1990     _progress_last_gc.set();
1991   }
1992 }
1993 
1994 void ShenandoahHeap::op_degenerated_fail() {
1995   log_info(gc)(&quot;Cannot finish degeneration, upgrading to Full GC&quot;);
1996   shenandoah_policy()-&gt;record_degenerated_upgrade_to_full();
1997   op_full(GCCause::_shenandoah_upgrade_to_full_gc);
1998 }
1999 
2000 void ShenandoahHeap::op_degenerated_futile() {
2001   shenandoah_policy()-&gt;record_degenerated_upgrade_to_full();
2002   op_full(GCCause::_shenandoah_upgrade_to_full_gc);
2003 }
2004 
2005 void ShenandoahHeap::force_satb_flush_all_threads() {
<span class="line-modified">2006   if (!is_concurrent_mark_in_progress() &amp;&amp; !is_concurrent_traversal_in_progress()) {</span>
2007     // No need to flush SATBs
2008     return;
2009   }
2010 
2011   for (JavaThreadIteratorWithHandle jtiwh; JavaThread *t = jtiwh.next(); ) {
2012     ShenandoahThreadLocalData::set_force_satb_flush(t, true);
2013   }
2014   // The threads are not &quot;acquiring&quot; their thread-local data, but it does not
2015   // hurt to &quot;release&quot; the updates here anyway.
2016   OrderAccess::fence();
2017 }
2018 
2019 void ShenandoahHeap::set_gc_state_all_threads(char state) {
2020   for (JavaThreadIteratorWithHandle jtiwh; JavaThread *t = jtiwh.next(); ) {
2021     ShenandoahThreadLocalData::set_gc_state(t, state);
2022   }
2023 }
2024 
2025 void ShenandoahHeap::set_gc_state_mask(uint mask, bool value) {
2026   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should really be Shenandoah safepoint&quot;);
2027   _gc_state.set_cond(mask, value);
2028   set_gc_state_all_threads(_gc_state.raw_value());
2029 }
2030 
2031 void ShenandoahHeap::set_concurrent_mark_in_progress(bool in_progress) {
2032   if (has_forwarded_objects()) {
2033     set_gc_state_mask(MARKING | UPDATEREFS, in_progress);
2034   } else {
2035     set_gc_state_mask(MARKING, in_progress);
2036   }
2037   ShenandoahBarrierSet::satb_mark_queue_set().set_active_all_threads(in_progress, !in_progress);
2038 }
2039 
<span class="line-removed">2040 void ShenandoahHeap::set_concurrent_traversal_in_progress(bool in_progress) {</span>
<span class="line-removed">2041    set_gc_state_mask(TRAVERSAL, in_progress);</span>
<span class="line-removed">2042    ShenandoahBarrierSet::satb_mark_queue_set().set_active_all_threads(in_progress, !in_progress);</span>
<span class="line-removed">2043 }</span>
<span class="line-removed">2044 </span>
2045 void ShenandoahHeap::set_evacuation_in_progress(bool in_progress) {
2046   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Only call this at safepoint&quot;);
2047   set_gc_state_mask(EVACUATION, in_progress);
2048 }
2049 
2050 void ShenandoahHeap::set_concurrent_root_in_progress(bool in_progress) {
2051   assert(ShenandoahConcurrentRoots::can_do_concurrent_roots(), &quot;Why set the flag?&quot;);
2052   if (in_progress) {
2053     _concurrent_root_in_progress.set();
2054   } else {
2055     _concurrent_root_in_progress.unset();
2056   }
2057 }
2058 
2059 void ShenandoahHeap::ref_processing_init() {
2060   assert(_max_workers &gt; 0, &quot;Sanity&quot;);
2061 
2062   _ref_processor =
2063     new ReferenceProcessor(&amp;_subject_to_discovery,  // is_subject_to_discovery
2064                            ParallelRefProcEnabled,  // MT processing
</pre>
<hr />
<pre>
2120   control_thread()-&gt;prepare_for_graceful_shutdown();
2121 
2122   // Step 2. Notify GC workers that we are cancelling GC.
2123   cancel_gc(GCCause::_shenandoah_stop_vm);
2124 
2125   // Step 3. Wait until GC worker exits normally.
2126   control_thread()-&gt;stop();
2127 
2128   // Step 4. Stop String Dedup thread if it is active
2129   if (ShenandoahStringDedup::is_enabled()) {
2130     ShenandoahStringDedup::stop();
2131   }
2132 }
2133 
2134 void ShenandoahHeap::stw_unload_classes(bool full_gc) {
2135   if (!unload_classes()) return;
2136   bool purged_class;
2137 
2138   // Unload classes and purge SystemDictionary.
2139   {
<span class="line-modified">2140     ShenandoahGCPhase phase(full_gc ?</span>
<span class="line-modified">2141                             ShenandoahPhaseTimings::full_gc_purge_class_unload :</span>
<span class="line-modified">2142                             ShenandoahPhaseTimings::purge_class_unload);</span>
2143     purged_class = SystemDictionary::do_unloading(gc_timer());
2144   }
2145 
2146   {
<span class="line-modified">2147     ShenandoahGCPhase phase(full_gc ?</span>
<span class="line-modified">2148                             ShenandoahPhaseTimings::full_gc_purge_par :</span>
<span class="line-modified">2149                             ShenandoahPhaseTimings::purge_par);</span>
2150     ShenandoahIsAliveSelector is_alive;
2151     uint num_workers = _workers-&gt;active_workers();
2152     ShenandoahClassUnloadingTask unlink_task(is_alive.is_alive_closure(), num_workers, purged_class);
2153     _workers-&gt;run_task(&amp;unlink_task);
2154   }
2155 
2156   {
<span class="line-modified">2157     ShenandoahGCPhase phase(full_gc ?</span>
<span class="line-modified">2158                             ShenandoahPhaseTimings::full_gc_purge_cldg :</span>
<span class="line-modified">2159                             ShenandoahPhaseTimings::purge_cldg);</span>
2160     ClassLoaderDataGraph::purge();
2161   }
2162   // Resize and verify metaspace
2163   MetaspaceGC::compute_new_size();
2164   MetaspaceUtils::verify_metrics();
2165 }
2166 
2167 // Weak roots are either pre-evacuated (final mark) or updated (final updaterefs),
2168 // so they should not have forwarded oops.
2169 // However, we do need to &quot;null&quot; dead oops in the roots, if can not be done
2170 // in concurrent cycles.
2171 void ShenandoahHeap::stw_process_weak_roots(bool full_gc) {
<span class="line-modified">2172   ShenandoahGCPhase root_phase(full_gc ?</span>
<span class="line-modified">2173                                ShenandoahPhaseTimings::full_gc_purge :</span>
<span class="line-modified">2174                                ShenandoahPhaseTimings::purge);</span>
2175   uint num_workers = _workers-&gt;active_workers();
2176   ShenandoahPhaseTimings::Phase timing_phase = full_gc ?
2177                                                ShenandoahPhaseTimings::full_gc_purge_par :
2178                                                ShenandoahPhaseTimings::purge_par;



2179   // Cleanup weak roots
<span class="line-removed">2180   ShenandoahGCPhase phase(timing_phase);</span>
<span class="line-removed">2181   phase_timings()-&gt;record_workers_start(timing_phase);</span>
2182   if (has_forwarded_objects()) {
<span class="line-modified">2183     if (is_traversal_mode()) {</span>
<span class="line-modified">2184       ShenandoahForwardedIsAliveClosure is_alive;</span>
<span class="line-modified">2185       ShenandoahTraversalUpdateRefsClosure keep_alive;</span>
<span class="line-modified">2186       ShenandoahParallelWeakRootsCleaningTask&lt;ShenandoahForwardedIsAliveClosure, ShenandoahTraversalUpdateRefsClosure&gt;</span>
<span class="line-modified">2187         cleaning_task(&amp;is_alive, &amp;keep_alive, num_workers, !ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());</span>
<span class="line-removed">2188       _workers-&gt;run_task(&amp;cleaning_task);</span>
<span class="line-removed">2189     } else {</span>
<span class="line-removed">2190       ShenandoahForwardedIsAliveClosure is_alive;</span>
<span class="line-removed">2191       ShenandoahUpdateRefsClosure keep_alive;</span>
<span class="line-removed">2192       ShenandoahParallelWeakRootsCleaningTask&lt;ShenandoahForwardedIsAliveClosure, ShenandoahUpdateRefsClosure&gt;</span>
<span class="line-removed">2193         cleaning_task(&amp;is_alive, &amp;keep_alive, num_workers, !ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());</span>
<span class="line-removed">2194       _workers-&gt;run_task(&amp;cleaning_task);</span>
<span class="line-removed">2195     }</span>
2196   } else {
2197     ShenandoahIsAliveClosure is_alive;
2198 #ifdef ASSERT
2199     ShenandoahAssertNotForwardedClosure verify_cl;
2200     ShenandoahParallelWeakRootsCleaningTask&lt;ShenandoahIsAliveClosure, ShenandoahAssertNotForwardedClosure&gt;
2201       cleaning_task(&amp;is_alive, &amp;verify_cl, num_workers, !ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());
2202 #else
2203     ShenandoahParallelWeakRootsCleaningTask&lt;ShenandoahIsAliveClosure, DoNothingClosure&gt;
2204       cleaning_task(&amp;is_alive, &amp;do_nothing_cl, num_workers, !ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());
2205 #endif
2206     _workers-&gt;run_task(&amp;cleaning_task);
2207   }
<span class="line-removed">2208   phase_timings()-&gt;record_workers_end(timing_phase);</span>
2209 }
2210 
2211 void ShenandoahHeap::parallel_cleaning(bool full_gc) {
2212   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2213   stw_process_weak_roots(full_gc);
2214   if (!ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2215     stw_unload_classes(full_gc);
2216   }
2217 }
2218 
2219 void ShenandoahHeap::set_has_forwarded_objects(bool cond) {
<span class="line-modified">2220   if (is_traversal_mode()) {</span>
<span class="line-removed">2221     set_gc_state_mask(HAS_FORWARDED | UPDATEREFS, cond);</span>
<span class="line-removed">2222   } else {</span>
<span class="line-removed">2223     set_gc_state_mask(HAS_FORWARDED, cond);</span>
<span class="line-removed">2224   }</span>
<span class="line-removed">2225 </span>
2226 }
2227 
2228 void ShenandoahHeap::set_process_references(bool pr) {
2229   _process_references.set_cond(pr);
2230 }
2231 
2232 void ShenandoahHeap::set_unload_classes(bool uc) {
2233   _unload_classes.set_cond(uc);
2234 }
2235 
2236 bool ShenandoahHeap::process_references() const {
2237   return _process_references.is_set();
2238 }
2239 
2240 bool ShenandoahHeap::unload_classes() const {
2241   return _unload_classes.is_set();
2242 }
2243 
2244 address ShenandoahHeap::in_cset_fast_test_addr() {
2245   ShenandoahHeap* heap = ShenandoahHeap::heap();
</pre>
<hr />
<pre>
2315         if (r-&gt;pin_count() &gt; 0) {
2316           r-&gt;make_pinned();
2317         }
2318       }
2319     }
2320   }
2321 
2322   assert_pinned_region_status();
2323 }
2324 
2325 #ifdef ASSERT
2326 void ShenandoahHeap::assert_pinned_region_status() {
2327   for (size_t i = 0; i &lt; num_regions(); i++) {
2328     ShenandoahHeapRegion* r = get_region(i);
2329     assert((r-&gt;is_pinned() &amp;&amp; r-&gt;pin_count() &gt; 0) || (!r-&gt;is_pinned() &amp;&amp; r-&gt;pin_count() == 0),
2330            &quot;Region &quot; SIZE_FORMAT &quot; pinning status is inconsistent&quot;, i);
2331   }
2332 }
2333 #endif
2334 
<span class="line-modified">2335 GCTimer* ShenandoahHeap::gc_timer() const {</span>
2336   return _gc_timer;
2337 }
2338 
2339 void ShenandoahHeap::prepare_concurrent_roots() {
2340   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2341   if (ShenandoahConcurrentRoots::should_do_concurrent_roots()) {
2342     set_concurrent_root_in_progress(true);
2343   }
2344 }
2345 
2346 void ShenandoahHeap::prepare_concurrent_unloading() {
2347   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2348   if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2349     _unloader.prepare();
2350   }
2351 }
2352 
2353 void ShenandoahHeap::finish_concurrent_unloading() {
2354   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2355   if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2356     _unloader.finish();
2357   }
2358 }
2359 
2360 #ifdef ASSERT
2361 void ShenandoahHeap::assert_gc_workers(uint nworkers) {
2362   assert(nworkers &gt; 0 &amp;&amp; nworkers &lt;= max_workers(), &quot;Sanity&quot;);
2363 
2364   if (ShenandoahSafepoint::is_at_shenandoah_safepoint()) {
<span class="line-modified">2365     if (UseDynamicNumberOfGCThreads ||</span>
<span class="line-removed">2366         (FLAG_IS_DEFAULT(ParallelGCThreads) &amp;&amp; ForceDynamicNumberOfGCThreads)) {</span>
2367       assert(nworkers &lt;= ParallelGCThreads, &quot;Cannot use more than it has&quot;);
2368     } else {
2369       // Use ParallelGCThreads inside safepoints
<span class="line-modified">2370       assert(nworkers == ParallelGCThreads, &quot;Use ParalleGCThreads within safepoints&quot;);</span>
2371     }
2372   } else {
<span class="line-modified">2373     if (UseDynamicNumberOfGCThreads ||</span>
<span class="line-removed">2374         (FLAG_IS_DEFAULT(ConcGCThreads) &amp;&amp; ForceDynamicNumberOfGCThreads)) {</span>
2375       assert(nworkers &lt;= ConcGCThreads, &quot;Cannot use more than it has&quot;);
2376     } else {
2377       // Use ConcGCThreads outside safepoints
2378       assert(nworkers == ConcGCThreads, &quot;Use ConcGCThreads outside safepoints&quot;);
2379     }
2380   }
2381 }
2382 #endif
2383 
2384 ShenandoahVerifier* ShenandoahHeap::verifier() {
2385   guarantee(ShenandoahVerify, &quot;Should be enabled&quot;);
2386   assert (_verifier != NULL, &quot;sanity&quot;);
2387   return _verifier;
2388 }
2389 
2390 template&lt;class T&gt;
2391 class ShenandoahUpdateHeapRefsTask : public AbstractGangTask {
2392 private:
2393   T cl;
2394   ShenandoahHeap* _heap;
</pre>
<hr />
<pre>
2402     _regions(regions),
2403     _concurrent(concurrent) {
2404   }
2405 
2406   void work(uint worker_id) {
2407     if (_concurrent) {
2408       ShenandoahConcurrentWorkerSession worker_session(worker_id);
2409       ShenandoahSuspendibleThreadSetJoiner stsj(ShenandoahSuspendibleWorkers);
2410       do_work();
2411     } else {
2412       ShenandoahParallelWorkerSession worker_session(worker_id);
2413       do_work();
2414     }
2415   }
2416 
2417 private:
2418   void do_work() {
2419     ShenandoahHeapRegion* r = _regions-&gt;next();
2420     ShenandoahMarkingContext* const ctx = _heap-&gt;complete_marking_context();
2421     while (r != NULL) {
<span class="line-modified">2422       HeapWord* top_at_start_ur = r-&gt;concurrent_iteration_safe_limit();</span>
<span class="line-modified">2423       assert (top_at_start_ur &gt;= r-&gt;bottom(), &quot;sanity&quot;);</span>
2424       if (r-&gt;is_active() &amp;&amp; !r-&gt;is_cset()) {
<span class="line-modified">2425         _heap-&gt;marked_object_oop_iterate(r, &amp;cl, top_at_start_ur);</span>
2426       }
2427       if (ShenandoahPacing) {
<span class="line-modified">2428         _heap-&gt;pacer()-&gt;report_updaterefs(pointer_delta(top_at_start_ur, r-&gt;bottom()));</span>
2429       }
2430       if (_heap-&gt;check_cancelled_gc_and_yield(_concurrent)) {
2431         return;
2432       }
2433       r = _regions-&gt;next();
2434     }
2435   }
2436 };
2437 
2438 void ShenandoahHeap::update_heap_references(bool concurrent) {
2439   ShenandoahUpdateHeapRefsTask&lt;ShenandoahUpdateHeapRefsClosure&gt; task(&amp;_update_refs_iterator, concurrent);
2440   workers()-&gt;run_task(&amp;task);
2441 }
2442 
2443 void ShenandoahHeap::op_init_updaterefs() {
2444   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;must be at safepoint&quot;);
2445 
2446   set_evacuation_in_progress(false);
2447 
2448   {
<span class="line-modified">2449     ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_refs_retire_gclabs);</span>
2450     retire_and_reset_gclabs();
2451   }
2452 
2453   if (ShenandoahVerify) {
2454     if (!is_degenerated_gc_in_progress()) {
2455       verifier()-&gt;verify_roots_in_to_space_except(ShenandoahRootVerifier::ThreadRoots);
2456     }
2457     verifier()-&gt;verify_before_updaterefs();
2458   }
2459 
2460   set_update_refs_in_progress(true);
2461 
2462   {
<span class="line-modified">2463     ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_refs_prepare);</span>
2464 
2465     make_parsable(true);
<span class="line-removed">2466     for (uint i = 0; i &lt; num_regions(); i++) {</span>
<span class="line-removed">2467       ShenandoahHeapRegion* r = get_region(i);</span>
<span class="line-removed">2468       r-&gt;set_concurrent_iteration_safe_limit(r-&gt;top());</span>
<span class="line-removed">2469     }</span>
2470 
2471     // Reset iterator.
2472     _update_refs_iterator.reset();
2473   }
2474 
2475   if (ShenandoahPacing) {
2476     pacer()-&gt;setup_for_updaterefs();
2477   }
2478 }
2479 





























2480 void ShenandoahHeap::op_final_updaterefs() {
2481   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;must be at safepoint&quot;);
2482 
2483   finish_concurrent_unloading();
2484 
2485   // Check if there is left-over work, and finish it
2486   if (_update_refs_iterator.has_next()) {
<span class="line-modified">2487     ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs_finish_work);</span>
2488 
2489     // Finish updating references where we left off.
2490     clear_cancelled_gc();
2491     update_heap_references(false);
2492   }
2493 
2494   // Clear cancelled GC, if set. On cancellation path, the block before would handle
2495   // everything. On degenerated paths, cancelled gc would not be set anyway.
2496   if (cancelled_gc()) {
2497     clear_cancelled_gc();
2498   }
2499   assert(!cancelled_gc(), &quot;Should have been done right before&quot;);
2500 
2501   if (ShenandoahVerify &amp;&amp; !is_degenerated_gc_in_progress()) {
2502     verifier()-&gt;verify_roots_in_to_space_except(ShenandoahRootVerifier::ThreadRoots);
2503   }
2504 
2505   if (is_degenerated_gc_in_progress()) {
2506     concurrent_mark()-&gt;update_roots(ShenandoahPhaseTimings::degen_gc_update_roots);
2507   } else {
2508     concurrent_mark()-&gt;update_thread_roots(ShenandoahPhaseTimings::final_update_refs_roots);
2509   }
2510 
2511   // Has to be done before cset is clear
2512   if (ShenandoahVerify) {
2513     verifier()-&gt;verify_roots_in_to_space();
2514   }
2515 
<span class="line-removed">2516   // Drop unnecessary &quot;pinned&quot; state from regions that does not have CP marks</span>
<span class="line-removed">2517   // anymore, as this would allow trashing them below.</span>
2518   {
<span class="line-modified">2519     ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs_sync_pinned);</span>
<span class="line-modified">2520     sync_pinned_region_status();</span>



2521   }
2522 
2523   {
<span class="line-modified">2524     ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs_trash_cset);</span>
2525     trash_cset_regions();
2526   }
2527 
2528   set_has_forwarded_objects(false);
2529   set_update_refs_in_progress(false);
2530 
2531   if (ShenandoahVerify) {
2532     verifier()-&gt;verify_after_updaterefs();
2533   }
2534 
2535   if (VerifyAfterGC) {
2536     Universe::verify();
2537   }
2538 
2539   {

2540     ShenandoahHeapLocker locker(lock());
2541     _free_set-&gt;rebuild();
2542   }
2543 }
2544 
<span class="line-removed">2545 #ifdef ASSERT</span>
<span class="line-removed">2546 void ShenandoahHeap::assert_heaplock_owned_by_current_thread() {</span>
<span class="line-removed">2547   _lock.assert_owned_by_current_thread();</span>
<span class="line-removed">2548 }</span>
<span class="line-removed">2549 </span>
<span class="line-removed">2550 void ShenandoahHeap::assert_heaplock_not_owned_by_current_thread() {</span>
<span class="line-removed">2551   _lock.assert_not_owned_by_current_thread();</span>
<span class="line-removed">2552 }</span>
<span class="line-removed">2553 </span>
<span class="line-removed">2554 void ShenandoahHeap::assert_heaplock_or_safepoint() {</span>
<span class="line-removed">2555   _lock.assert_owned_by_current_thread_or_safepoint();</span>
<span class="line-removed">2556 }</span>
<span class="line-removed">2557 #endif</span>
<span class="line-removed">2558 </span>
2559 void ShenandoahHeap::print_extended_on(outputStream *st) const {
2560   print_on(st);
2561   print_heap_regions_on(st);
2562 }
2563 
2564 bool ShenandoahHeap::is_bitmap_slice_committed(ShenandoahHeapRegion* r, bool skip_self) {
<span class="line-modified">2565   size_t slice = r-&gt;region_number() / _bitmap_regions_per_slice;</span>
2566 
2567   size_t regions_from = _bitmap_regions_per_slice * slice;
2568   size_t regions_to   = MIN2(num_regions(), _bitmap_regions_per_slice * (slice + 1));
2569   for (size_t g = regions_from; g &lt; regions_to; g++) {
2570     assert (g / _bitmap_regions_per_slice == slice, &quot;same slice&quot;);
<span class="line-modified">2571     if (skip_self &amp;&amp; g == r-&gt;region_number()) continue;</span>
2572     if (get_region(g)-&gt;is_committed()) {
2573       return true;
2574     }
2575   }
2576   return false;
2577 }
2578 
2579 bool ShenandoahHeap::commit_bitmap_slice(ShenandoahHeapRegion* r) {
<span class="line-modified">2580   assert_heaplock_owned_by_current_thread();</span>
2581 
2582   // Bitmaps in special regions do not need commits
2583   if (_bitmap_region_special) {
2584     return true;
2585   }
2586 
2587   if (is_bitmap_slice_committed(r, true)) {
2588     // Some other region from the group is already committed, meaning the bitmap
2589     // slice is already committed, we exit right away.
2590     return true;
2591   }
2592 
2593   // Commit the bitmap slice:
<span class="line-modified">2594   size_t slice = r-&gt;region_number() / _bitmap_regions_per_slice;</span>
2595   size_t off = _bitmap_bytes_per_slice * slice;
2596   size_t len = _bitmap_bytes_per_slice;
2597   if (!os::commit_memory((char*)_bitmap_region.start() + off, len, false)) {
2598     return false;
2599   }
2600   return true;
2601 }
2602 
2603 bool ShenandoahHeap::uncommit_bitmap_slice(ShenandoahHeapRegion *r) {
<span class="line-modified">2604   assert_heaplock_owned_by_current_thread();</span>
2605 
2606   // Bitmaps in special regions do not need uncommits
2607   if (_bitmap_region_special) {
2608     return true;
2609   }
2610 
2611   if (is_bitmap_slice_committed(r, true)) {
2612     // Some other region from the group is still committed, meaning the bitmap
2613     // slice is should stay committed, exit right away.
2614     return true;
2615   }
2616 
2617   // Uncommit the bitmap slice:
<span class="line-modified">2618   size_t slice = r-&gt;region_number() / _bitmap_regions_per_slice;</span>
2619   size_t off = _bitmap_bytes_per_slice * slice;
2620   size_t len = _bitmap_bytes_per_slice;
2621   if (!os::uncommit_memory((char*)_bitmap_region.start() + off, len)) {
2622     return false;
2623   }
2624   return true;
2625 }
2626 
2627 void ShenandoahHeap::safepoint_synchronize_begin() {
2628   if (ShenandoahSuspendibleWorkers || UseStringDeduplication) {
2629     SuspendibleThreadSet::synchronize();
2630   }
2631 }
2632 
2633 void ShenandoahHeap::safepoint_synchronize_end() {
2634   if (ShenandoahSuspendibleWorkers || UseStringDeduplication) {
2635     SuspendibleThreadSet::desynchronize();
2636   }
2637 }
2638 
2639 void ShenandoahHeap::vmop_entry_init_mark() {
2640   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2641   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2642   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_mark_gross);
2643 
2644   try_inject_alloc_failure();
2645   VM_ShenandoahInitMark op;
2646   VMThread::execute(&amp;op); // jump to entry_init_mark() under safepoint
2647 }
2648 
2649 void ShenandoahHeap::vmop_entry_final_mark() {
2650   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2651   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2652   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_mark_gross);
2653 
2654   try_inject_alloc_failure();
2655   VM_ShenandoahFinalMarkStartEvac op;
2656   VMThread::execute(&amp;op); // jump to entry_final_mark under safepoint
2657 }
2658 
<span class="line-removed">2659 void ShenandoahHeap::vmop_entry_final_evac() {</span>
<span class="line-removed">2660   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());</span>
<span class="line-removed">2661   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);</span>
<span class="line-removed">2662   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_evac_gross);</span>
<span class="line-removed">2663 </span>
<span class="line-removed">2664   VM_ShenandoahFinalEvac op;</span>
<span class="line-removed">2665   VMThread::execute(&amp;op); // jump to entry_final_evac under safepoint</span>
<span class="line-removed">2666 }</span>
<span class="line-removed">2667 </span>
2668 void ShenandoahHeap::vmop_entry_init_updaterefs() {
2669   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2670   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2671   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_refs_gross);
2672 
2673   try_inject_alloc_failure();
2674   VM_ShenandoahInitUpdateRefs op;
2675   VMThread::execute(&amp;op);
2676 }
2677 
2678 void ShenandoahHeap::vmop_entry_final_updaterefs() {
2679   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2680   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2681   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs_gross);
2682 
2683   try_inject_alloc_failure();
2684   VM_ShenandoahFinalUpdateRefs op;
2685   VMThread::execute(&amp;op);
2686 }
2687 
<span class="line-removed">2688 void ShenandoahHeap::vmop_entry_init_traversal() {</span>
<span class="line-removed">2689   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());</span>
<span class="line-removed">2690   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);</span>
<span class="line-removed">2691   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_traversal_gc_gross);</span>
<span class="line-removed">2692 </span>
<span class="line-removed">2693   try_inject_alloc_failure();</span>
<span class="line-removed">2694   VM_ShenandoahInitTraversalGC op;</span>
<span class="line-removed">2695   VMThread::execute(&amp;op);</span>
<span class="line-removed">2696 }</span>
<span class="line-removed">2697 </span>
<span class="line-removed">2698 void ShenandoahHeap::vmop_entry_final_traversal() {</span>
<span class="line-removed">2699   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());</span>
<span class="line-removed">2700   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);</span>
<span class="line-removed">2701   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_traversal_gc_gross);</span>
<span class="line-removed">2702 </span>
<span class="line-removed">2703   try_inject_alloc_failure();</span>
<span class="line-removed">2704   VM_ShenandoahFinalTraversalGC op;</span>
<span class="line-removed">2705   VMThread::execute(&amp;op);</span>
<span class="line-removed">2706 }</span>
<span class="line-removed">2707 </span>
2708 void ShenandoahHeap::vmop_entry_full(GCCause::Cause cause) {
2709   TraceCollectorStats tcs(monitoring_support()-&gt;full_stw_collection_counters());
2710   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2711   ShenandoahGCPhase phase(ShenandoahPhaseTimings::full_gc_gross);
2712 
2713   try_inject_alloc_failure();
2714   VM_ShenandoahFullGC op(cause);
2715   VMThread::execute(&amp;op);
2716 }
2717 
2718 void ShenandoahHeap::vmop_degenerated(ShenandoahDegenPoint point) {
2719   TraceCollectorStats tcs(monitoring_support()-&gt;full_stw_collection_counters());
2720   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2721   ShenandoahGCPhase phase(ShenandoahPhaseTimings::degen_gc_gross);
2722 
2723   VM_ShenandoahDegeneratedGC degenerated_gc((int)point);
2724   VMThread::execute(&amp;degenerated_gc);
2725 }
2726 
2727 void ShenandoahHeap::entry_init_mark() {
<span class="line-removed">2728   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);</span>
<span class="line-removed">2729   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_mark);</span>
2730   const char* msg = init_mark_event_message();
<span class="line-modified">2731   GCTraceTime(Info, gc) time(msg, gc_timer());</span>
2732   EventMark em(&quot;%s&quot;, msg);
2733 



2734   ShenandoahWorkerScope scope(workers(),
2735                               ShenandoahWorkerPolicy::calc_workers_for_init_marking(),
2736                               &quot;init marking&quot;);
2737 
2738   op_init_mark();
2739 }
2740 
2741 void ShenandoahHeap::entry_final_mark() {
<span class="line-removed">2742   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);</span>
<span class="line-removed">2743   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_mark);</span>
2744   const char* msg = final_mark_event_message();
<span class="line-modified">2745   GCTraceTime(Info, gc) time(msg, gc_timer());</span>
2746   EventMark em(&quot;%s&quot;, msg);
2747 



2748   ShenandoahWorkerScope scope(workers(),
2749                               ShenandoahWorkerPolicy::calc_workers_for_final_marking(),
2750                               &quot;final marking&quot;);
2751 
2752   op_final_mark();
2753 }
2754 
<span class="line-modified">2755 void ShenandoahHeap::entry_final_evac() {</span>
<span class="line-modified">2756   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);</span>
<span class="line-modified">2757   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_evac);</span>
<span class="line-removed">2758   static const char* msg = &quot;Pause Final Evac&quot;;</span>
<span class="line-removed">2759   GCTraceTime(Info, gc) time(msg, gc_timer());</span>
2760   EventMark em(&quot;%s&quot;, msg);
2761 
<span class="line-removed">2762   op_final_evac();</span>
<span class="line-removed">2763 }</span>
<span class="line-removed">2764 </span>
<span class="line-removed">2765 void ShenandoahHeap::entry_init_updaterefs() {</span>
2766   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2767   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_refs);
2768 
<span class="line-removed">2769   static const char* msg = &quot;Pause Init Update Refs&quot;;</span>
<span class="line-removed">2770   GCTraceTime(Info, gc) time(msg, gc_timer());</span>
<span class="line-removed">2771   EventMark em(&quot;%s&quot;, msg);</span>
<span class="line-removed">2772 </span>
2773   // No workers used in this phase, no setup required
2774 
2775   op_init_updaterefs();
2776 }
2777 
2778 void ShenandoahHeap::entry_final_updaterefs() {
<span class="line-removed">2779   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);</span>
<span class="line-removed">2780   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs);</span>
<span class="line-removed">2781 </span>
2782   static const char* msg = &quot;Pause Final Update Refs&quot;;
<span class="line-modified">2783   GCTraceTime(Info, gc) time(msg, gc_timer());</span>
2784   EventMark em(&quot;%s&quot;, msg);
2785 



2786   ShenandoahWorkerScope scope(workers(),
2787                               ShenandoahWorkerPolicy::calc_workers_for_final_update_ref(),
2788                               &quot;final reference update&quot;);
2789 
2790   op_final_updaterefs();
2791 }
2792 
<span class="line-modified">2793 void ShenandoahHeap::entry_init_traversal() {</span>
<span class="line-modified">2794   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);</span>
<span class="line-modified">2795   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_traversal_gc);</span>
<span class="line-removed">2796 </span>
<span class="line-removed">2797   static const char* msg = init_traversal_event_message();</span>
<span class="line-removed">2798   GCTraceTime(Info, gc) time(msg, gc_timer());</span>
<span class="line-removed">2799   EventMark em(&quot;%s&quot;, msg);</span>
<span class="line-removed">2800 </span>
<span class="line-removed">2801   ShenandoahWorkerScope scope(workers(),</span>
<span class="line-removed">2802                               ShenandoahWorkerPolicy::calc_workers_for_stw_traversal(),</span>
<span class="line-removed">2803                               &quot;init traversal&quot;);</span>
<span class="line-removed">2804 </span>
<span class="line-removed">2805   op_init_traversal();</span>
<span class="line-removed">2806 }</span>
<span class="line-removed">2807 </span>
<span class="line-removed">2808 void ShenandoahHeap::entry_final_traversal() {</span>
<span class="line-removed">2809   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);</span>
<span class="line-removed">2810   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_traversal_gc);</span>
<span class="line-removed">2811 </span>
<span class="line-removed">2812   static const char* msg = final_traversal_event_message();</span>
<span class="line-removed">2813   GCTraceTime(Info, gc) time(msg, gc_timer());</span>
2814   EventMark em(&quot;%s&quot;, msg);
2815 
<span class="line-removed">2816   ShenandoahWorkerScope scope(workers(),</span>
<span class="line-removed">2817                               ShenandoahWorkerPolicy::calc_workers_for_stw_traversal(),</span>
<span class="line-removed">2818                               &quot;final traversal&quot;);</span>
<span class="line-removed">2819 </span>
<span class="line-removed">2820   op_final_traversal();</span>
<span class="line-removed">2821 }</span>
<span class="line-removed">2822 </span>
<span class="line-removed">2823 void ShenandoahHeap::entry_full(GCCause::Cause cause) {</span>
2824   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2825   ShenandoahGCPhase phase(ShenandoahPhaseTimings::full_gc);
2826 
<span class="line-removed">2827   static const char* msg = &quot;Pause Full&quot;;</span>
<span class="line-removed">2828   GCTraceTime(Info, gc) time(msg, gc_timer(), cause, true);</span>
<span class="line-removed">2829   EventMark em(&quot;%s&quot;, msg);</span>
<span class="line-removed">2830 </span>
2831   ShenandoahWorkerScope scope(workers(),
2832                               ShenandoahWorkerPolicy::calc_workers_for_fullgc(),
2833                               &quot;full gc&quot;);
2834 
2835   op_full(cause);
2836 }
2837 
2838 void ShenandoahHeap::entry_degenerated(int point) {
<span class="line-removed">2839   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);</span>
<span class="line-removed">2840   ShenandoahGCPhase phase(ShenandoahPhaseTimings::degen_gc);</span>
<span class="line-removed">2841 </span>
2842   ShenandoahDegenPoint dpoint = (ShenandoahDegenPoint)point;
2843   const char* msg = degen_event_message(dpoint);
<span class="line-modified">2844   GCTraceTime(Info, gc) time(msg, NULL, GCCause::_no_gc, true);</span>
2845   EventMark em(&quot;%s&quot;, msg);
2846 



2847   ShenandoahWorkerScope scope(workers(),
2848                               ShenandoahWorkerPolicy::calc_workers_for_stw_degenerated(),
2849                               &quot;stw degenerated gc&quot;);
2850 
2851   set_degenerated_gc_in_progress(true);
2852   op_degenerated(dpoint);
2853   set_degenerated_gc_in_progress(false);
2854 }
2855 
2856 void ShenandoahHeap::entry_mark() {
2857   TraceCollectorStats tcs(monitoring_support()-&gt;concurrent_collection_counters());
2858 
2859   const char* msg = conc_mark_event_message();
<span class="line-modified">2860   GCTraceTime(Info, gc) time(msg, NULL, GCCause::_no_gc, true);</span>
2861   EventMark em(&quot;%s&quot;, msg);
2862 


2863   ShenandoahWorkerScope scope(workers(),
2864                               ShenandoahWorkerPolicy::calc_workers_for_conc_marking(),
2865                               &quot;concurrent marking&quot;);
2866 
2867   try_inject_alloc_failure();
2868   op_mark();
2869 }
2870 
2871 void ShenandoahHeap::entry_evac() {
<span class="line-removed">2872   ShenandoahGCPhase conc_evac_phase(ShenandoahPhaseTimings::conc_evac);</span>
2873   TraceCollectorStats tcs(monitoring_support()-&gt;concurrent_collection_counters());
2874 
2875   static const char* msg = &quot;Concurrent evacuation&quot;;
<span class="line-modified">2876   GCTraceTime(Info, gc) time(msg, NULL, GCCause::_no_gc, true);</span>
2877   EventMark em(&quot;%s&quot;, msg);
2878 


2879   ShenandoahWorkerScope scope(workers(),
2880                               ShenandoahWorkerPolicy::calc_workers_for_conc_evac(),
2881                               &quot;concurrent evacuation&quot;);
2882 
2883   try_inject_alloc_failure();
2884   op_conc_evac();
2885 }
2886 
2887 void ShenandoahHeap::entry_updaterefs() {
<span class="line-removed">2888   ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_update_refs);</span>
<span class="line-removed">2889 </span>
2890   static const char* msg = &quot;Concurrent update references&quot;;
<span class="line-modified">2891   GCTraceTime(Info, gc) time(msg, NULL, GCCause::_no_gc, true);</span>
2892   EventMark em(&quot;%s&quot;, msg);
2893 


2894   ShenandoahWorkerScope scope(workers(),
2895                               ShenandoahWorkerPolicy::calc_workers_for_conc_update_ref(),
2896                               &quot;concurrent reference update&quot;);
2897 
2898   try_inject_alloc_failure();
2899   op_updaterefs();
2900 }
2901 
2902 void ShenandoahHeap::entry_roots() {
<span class="line-removed">2903   ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_roots);</span>
<span class="line-removed">2904 </span>
2905   static const char* msg = &quot;Concurrent roots processing&quot;;
<span class="line-modified">2906   GCTraceTime(Info, gc) time(msg, NULL, GCCause::_no_gc, true);</span>
2907   EventMark em(&quot;%s&quot;, msg);
2908 


2909   ShenandoahWorkerScope scope(workers(),
2910                               ShenandoahWorkerPolicy::calc_workers_for_conc_root_processing(),
2911                               &quot;concurrent root processing&quot;);
2912 
2913   try_inject_alloc_failure();
2914   op_roots();
2915 }
2916 
2917 void ShenandoahHeap::entry_cleanup() {
<span class="line-removed">2918   ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_cleanup);</span>
<span class="line-removed">2919 </span>
2920   static const char* msg = &quot;Concurrent cleanup&quot;;
<span class="line-modified">2921   GCTraceTime(Info, gc) time(msg, NULL, GCCause::_no_gc, true);</span>
2922   EventMark em(&quot;%s&quot;, msg);
2923 


2924   // This phase does not use workers, no need for setup
2925 
2926   try_inject_alloc_failure();
2927   op_cleanup();
2928 }
2929 
2930 void ShenandoahHeap::entry_reset() {
<span class="line-removed">2931   ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_reset);</span>
<span class="line-removed">2932 </span>
2933   static const char* msg = &quot;Concurrent reset&quot;;
<span class="line-modified">2934   GCTraceTime(Info, gc) time(msg, NULL, GCCause::_no_gc, true);</span>
2935   EventMark em(&quot;%s&quot;, msg);
2936 


2937   ShenandoahWorkerScope scope(workers(),
2938                               ShenandoahWorkerPolicy::calc_workers_for_conc_reset(),
2939                               &quot;concurrent reset&quot;);
2940 
2941   try_inject_alloc_failure();
2942   op_reset();
2943 }
2944 
2945 void ShenandoahHeap::entry_preclean() {
2946   if (ShenandoahPreclean &amp;&amp; process_references()) {
2947     static const char* msg = &quot;Concurrent precleaning&quot;;
<span class="line-modified">2948     GCTraceTime(Info, gc) time(msg, NULL, GCCause::_no_gc, true);</span>
2949     EventMark em(&quot;%s&quot;, msg);
2950 
<span class="line-modified">2951     ShenandoahGCPhase conc_preclean(ShenandoahPhaseTimings::conc_preclean);</span>
2952 
2953     ShenandoahWorkerScope scope(workers(),
2954                                 ShenandoahWorkerPolicy::calc_workers_for_conc_preclean(),
2955                                 &quot;concurrent preclean&quot;,
2956                                 /* check_workers = */ false);
2957 
2958     try_inject_alloc_failure();
2959     op_preclean();
2960   }
2961 }
2962 
<span class="line-removed">2963 void ShenandoahHeap::entry_traversal() {</span>
<span class="line-removed">2964   static const char* msg = conc_traversal_event_message();</span>
<span class="line-removed">2965   GCTraceTime(Info, gc) time(msg, NULL, GCCause::_no_gc, true);</span>
<span class="line-removed">2966   EventMark em(&quot;%s&quot;, msg);</span>
<span class="line-removed">2967 </span>
<span class="line-removed">2968   TraceCollectorStats tcs(monitoring_support()-&gt;concurrent_collection_counters());</span>
<span class="line-removed">2969 </span>
<span class="line-removed">2970   ShenandoahWorkerScope scope(workers(),</span>
<span class="line-removed">2971                               ShenandoahWorkerPolicy::calc_workers_for_conc_traversal(),</span>
<span class="line-removed">2972                               &quot;concurrent traversal&quot;);</span>
<span class="line-removed">2973 </span>
<span class="line-removed">2974   try_inject_alloc_failure();</span>
<span class="line-removed">2975   op_traversal();</span>
<span class="line-removed">2976 }</span>
<span class="line-removed">2977 </span>
2978 void ShenandoahHeap::entry_uncommit(double shrink_before) {
2979   static const char *msg = &quot;Concurrent uncommit&quot;;
<span class="line-modified">2980   GCTraceTime(Info, gc) time(msg, NULL, GCCause::_no_gc, true);</span>
2981   EventMark em(&quot;%s&quot;, msg);
2982 
<span class="line-modified">2983   ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_uncommit);</span>
2984 
2985   op_uncommit(shrink_before);
2986 }
2987 
2988 void ShenandoahHeap::try_inject_alloc_failure() {
2989   if (ShenandoahAllocFailureALot &amp;&amp; !cancelled_gc() &amp;&amp; ((os::random() % 1000) &gt; 950)) {
2990     _inject_alloc_failure.set();
2991     os::naked_short_sleep(1);
2992     if (cancelled_gc()) {
2993       log_info(gc)(&quot;Allocation failure was successfully injected&quot;);
2994     }
2995   }
2996 }
2997 
2998 bool ShenandoahHeap::should_inject_alloc_failure() {
2999   return _inject_alloc_failure.is_set() &amp;&amp; _inject_alloc_failure.try_unset();
3000 }
3001 
3002 void ShenandoahHeap::initialize_serviceability() {
3003   _memory_pool = new ShenandoahMemoryPool(this);
</pre>
<hr />
<pre>
3042   _index = 0;
3043 }
3044 
3045 bool ShenandoahRegionIterator::has_next() const {
3046   return _index &lt; _heap-&gt;num_regions();
3047 }
3048 
3049 char ShenandoahHeap::gc_state() const {
3050   return _gc_state.raw_value();
3051 }
3052 
3053 void ShenandoahHeap::deduplicate_string(oop str) {
3054   assert(java_lang_String::is_instance(str), &quot;invariant&quot;);
3055 
3056   if (ShenandoahStringDedup::is_enabled()) {
3057     ShenandoahStringDedup::deduplicate(str);
3058   }
3059 }
3060 
3061 const char* ShenandoahHeap::init_mark_event_message() const {
<span class="line-modified">3062   bool update_refs = has_forwarded_objects();</span>

3063   bool proc_refs = process_references();
3064   bool unload_cls = unload_classes();
3065 
<span class="line-modified">3066   if (update_refs &amp;&amp; proc_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3067     return &quot;Pause Init Mark (update refs) (process weakrefs) (unload classes)&quot;;</span>
<span class="line-removed">3068   } else if (update_refs &amp;&amp; proc_refs) {</span>
<span class="line-removed">3069     return &quot;Pause Init Mark (update refs) (process weakrefs)&quot;;</span>
<span class="line-removed">3070   } else if (update_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3071     return &quot;Pause Init Mark (update refs) (unload classes)&quot;;</span>
<span class="line-removed">3072   } else if (proc_refs &amp;&amp; unload_cls) {</span>
3073     return &quot;Pause Init Mark (process weakrefs) (unload classes)&quot;;
<span class="line-removed">3074   } else if (update_refs) {</span>
<span class="line-removed">3075     return &quot;Pause Init Mark (update refs)&quot;;</span>
3076   } else if (proc_refs) {
3077     return &quot;Pause Init Mark (process weakrefs)&quot;;
3078   } else if (unload_cls) {
3079     return &quot;Pause Init Mark (unload classes)&quot;;
3080   } else {
3081     return &quot;Pause Init Mark&quot;;
3082   }
3083 }
3084 
3085 const char* ShenandoahHeap::final_mark_event_message() const {
<span class="line-modified">3086   bool update_refs = has_forwarded_objects();</span>

3087   bool proc_refs = process_references();
3088   bool unload_cls = unload_classes();
3089 
<span class="line-modified">3090   if (update_refs &amp;&amp; proc_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3091     return &quot;Pause Final Mark (update refs) (process weakrefs) (unload classes)&quot;;</span>
<span class="line-removed">3092   } else if (update_refs &amp;&amp; proc_refs) {</span>
<span class="line-removed">3093     return &quot;Pause Final Mark (update refs) (process weakrefs)&quot;;</span>
<span class="line-removed">3094   } else if (update_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3095     return &quot;Pause Final Mark (update refs) (unload classes)&quot;;</span>
<span class="line-removed">3096   } else if (proc_refs &amp;&amp; unload_cls) {</span>
3097     return &quot;Pause Final Mark (process weakrefs) (unload classes)&quot;;
<span class="line-removed">3098   } else if (update_refs) {</span>
<span class="line-removed">3099     return &quot;Pause Final Mark (update refs)&quot;;</span>
3100   } else if (proc_refs) {
3101     return &quot;Pause Final Mark (process weakrefs)&quot;;
3102   } else if (unload_cls) {
3103     return &quot;Pause Final Mark (unload classes)&quot;;
3104   } else {
3105     return &quot;Pause Final Mark&quot;;
3106   }
3107 }
3108 
3109 const char* ShenandoahHeap::conc_mark_event_message() const {
<span class="line-modified">3110   bool update_refs = has_forwarded_objects();</span>

3111   bool proc_refs = process_references();
3112   bool unload_cls = unload_classes();
3113 
<span class="line-modified">3114   if (update_refs &amp;&amp; proc_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3115     return &quot;Concurrent marking (update refs) (process weakrefs) (unload classes)&quot;;</span>
<span class="line-removed">3116   } else if (update_refs &amp;&amp; proc_refs) {</span>
<span class="line-removed">3117     return &quot;Concurrent marking (update refs) (process weakrefs)&quot;;</span>
<span class="line-removed">3118   } else if (update_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3119     return &quot;Concurrent marking (update refs) (unload classes)&quot;;</span>
<span class="line-removed">3120   } else if (proc_refs &amp;&amp; unload_cls) {</span>
3121     return &quot;Concurrent marking (process weakrefs) (unload classes)&quot;;
<span class="line-removed">3122   } else if (update_refs) {</span>
<span class="line-removed">3123     return &quot;Concurrent marking (update refs)&quot;;</span>
3124   } else if (proc_refs) {
3125     return &quot;Concurrent marking (process weakrefs)&quot;;
3126   } else if (unload_cls) {
3127     return &quot;Concurrent marking (unload classes)&quot;;
3128   } else {
3129     return &quot;Concurrent marking&quot;;
3130   }
3131 }
3132 
<span class="line-removed">3133 const char* ShenandoahHeap::init_traversal_event_message() const {</span>
<span class="line-removed">3134   bool proc_refs = process_references();</span>
<span class="line-removed">3135   bool unload_cls = unload_classes();</span>
<span class="line-removed">3136 </span>
<span class="line-removed">3137   if (proc_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3138     return &quot;Pause Init Traversal (process weakrefs) (unload classes)&quot;;</span>
<span class="line-removed">3139   } else if (proc_refs) {</span>
<span class="line-removed">3140     return &quot;Pause Init Traversal (process weakrefs)&quot;;</span>
<span class="line-removed">3141   } else if (unload_cls) {</span>
<span class="line-removed">3142     return &quot;Pause Init Traversal (unload classes)&quot;;</span>
<span class="line-removed">3143   } else {</span>
<span class="line-removed">3144     return &quot;Pause Init Traversal&quot;;</span>
<span class="line-removed">3145   }</span>
<span class="line-removed">3146 }</span>
<span class="line-removed">3147 </span>
<span class="line-removed">3148 const char* ShenandoahHeap::final_traversal_event_message() const {</span>
<span class="line-removed">3149   bool proc_refs = process_references();</span>
<span class="line-removed">3150   bool unload_cls = unload_classes();</span>
<span class="line-removed">3151 </span>
<span class="line-removed">3152   if (proc_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3153     return &quot;Pause Final Traversal (process weakrefs) (unload classes)&quot;;</span>
<span class="line-removed">3154   } else if (proc_refs) {</span>
<span class="line-removed">3155     return &quot;Pause Final Traversal (process weakrefs)&quot;;</span>
<span class="line-removed">3156   } else if (unload_cls) {</span>
<span class="line-removed">3157     return &quot;Pause Final Traversal (unload classes)&quot;;</span>
<span class="line-removed">3158   } else {</span>
<span class="line-removed">3159     return &quot;Pause Final Traversal&quot;;</span>
<span class="line-removed">3160   }</span>
<span class="line-removed">3161 }</span>
<span class="line-removed">3162 </span>
<span class="line-removed">3163 const char* ShenandoahHeap::conc_traversal_event_message() const {</span>
<span class="line-removed">3164   bool proc_refs = process_references();</span>
<span class="line-removed">3165   bool unload_cls = unload_classes();</span>
<span class="line-removed">3166 </span>
<span class="line-removed">3167   if (proc_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3168     return &quot;Concurrent Traversal (process weakrefs) (unload classes)&quot;;</span>
<span class="line-removed">3169   } else if (proc_refs) {</span>
<span class="line-removed">3170     return &quot;Concurrent Traversal (process weakrefs)&quot;;</span>
<span class="line-removed">3171   } else if (unload_cls) {</span>
<span class="line-removed">3172     return &quot;Concurrent Traversal (unload classes)&quot;;</span>
<span class="line-removed">3173   } else {</span>
<span class="line-removed">3174     return &quot;Concurrent Traversal&quot;;</span>
<span class="line-removed">3175   }</span>
<span class="line-removed">3176 }</span>
<span class="line-removed">3177 </span>
3178 const char* ShenandoahHeap::degen_event_message(ShenandoahDegenPoint point) const {
3179   switch (point) {
3180     case _degenerated_unset:
3181       return &quot;Pause Degenerated GC (&lt;UNSET&gt;)&quot;;
<span class="line-removed">3182     case _degenerated_traversal:</span>
<span class="line-removed">3183       return &quot;Pause Degenerated GC (Traversal)&quot;;</span>
3184     case _degenerated_outside_cycle:
3185       return &quot;Pause Degenerated GC (Outside of Cycle)&quot;;
3186     case _degenerated_mark:
3187       return &quot;Pause Degenerated GC (Mark)&quot;;
3188     case _degenerated_evac:
3189       return &quot;Pause Degenerated GC (Evacuation)&quot;;
3190     case _degenerated_updaterefs:
3191       return &quot;Pause Degenerated GC (Update Refs)&quot;;
3192     default:
3193       ShouldNotReachHere();
3194       return &quot;ERROR&quot;;
3195   }
3196 }
3197 
<span class="line-modified">3198 jushort* ShenandoahHeap::get_liveness_cache(uint worker_id) {</span>
3199 #ifdef ASSERT
3200   assert(_liveness_cache != NULL, &quot;sanity&quot;);
3201   assert(worker_id &lt; _max_workers, &quot;sanity&quot;);
3202   for (uint i = 0; i &lt; num_regions(); i++) {
3203     assert(_liveness_cache[worker_id][i] == 0, &quot;liveness cache should be empty&quot;);
3204   }
3205 #endif
3206   return _liveness_cache[worker_id];
3207 }
3208 
3209 void ShenandoahHeap::flush_liveness_cache(uint worker_id) {
3210   assert(worker_id &lt; _max_workers, &quot;sanity&quot;);
3211   assert(_liveness_cache != NULL, &quot;sanity&quot;);
<span class="line-modified">3212   jushort* ld = _liveness_cache[worker_id];</span>
3213   for (uint i = 0; i &lt; num_regions(); i++) {
<span class="line-modified">3214     ShenandoahHeapRegion* r = get_region(i);</span>
<span class="line-removed">3215     jushort live = ld[i];</span>
3216     if (live &gt; 0) {

3217       r-&gt;increase_live_data_gc_words(live);
3218       ld[i] = 0;
3219     }
3220   }
3221 }
</pre>
</td>
<td>
<hr />
<pre>
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;memory/allocation.hpp&quot;
  27 #include &quot;memory/universe.hpp&quot;
  28 
  29 #include &quot;gc/shared/gcArguments.hpp&quot;
  30 #include &quot;gc/shared/gcTimer.hpp&quot;
  31 #include &quot;gc/shared/gcTraceTime.inline.hpp&quot;
  32 #include &quot;gc/shared/locationPrinter.inline.hpp&quot;
  33 #include &quot;gc/shared/memAllocator.hpp&quot;
  34 #include &quot;gc/shared/oopStorageSet.hpp&quot;
  35 #include &quot;gc/shared/plab.hpp&quot;
  36 

  37 #include &quot;gc/shenandoah/shenandoahBarrierSet.hpp&quot;
  38 #include &quot;gc/shenandoah/shenandoahClosures.inline.hpp&quot;
  39 #include &quot;gc/shenandoah/shenandoahCollectionSet.hpp&quot;
  40 #include &quot;gc/shenandoah/shenandoahCollectorPolicy.hpp&quot;
  41 #include &quot;gc/shenandoah/shenandoahConcurrentMark.inline.hpp&quot;
  42 #include &quot;gc/shenandoah/shenandoahConcurrentRoots.hpp&quot;
  43 #include &quot;gc/shenandoah/shenandoahControlThread.hpp&quot;
  44 #include &quot;gc/shenandoah/shenandoahFreeSet.hpp&quot;
  45 #include &quot;gc/shenandoah/shenandoahPhaseTimings.hpp&quot;
  46 #include &quot;gc/shenandoah/shenandoahHeap.inline.hpp&quot;
<span class="line-modified">  47 #include &quot;gc/shenandoah/shenandoahHeapRegion.inline.hpp&quot;</span>
  48 #include &quot;gc/shenandoah/shenandoahHeapRegionSet.hpp&quot;
<span class="line-added">  49 #include &quot;gc/shenandoah/shenandoahIUMode.hpp&quot;</span>
  50 #include &quot;gc/shenandoah/shenandoahMarkCompact.hpp&quot;
  51 #include &quot;gc/shenandoah/shenandoahMarkingContext.inline.hpp&quot;
  52 #include &quot;gc/shenandoah/shenandoahMemoryPool.hpp&quot;
  53 #include &quot;gc/shenandoah/shenandoahMetrics.hpp&quot;
  54 #include &quot;gc/shenandoah/shenandoahMonitoringSupport.hpp&quot;
  55 #include &quot;gc/shenandoah/shenandoahNormalMode.hpp&quot;
  56 #include &quot;gc/shenandoah/shenandoahOopClosures.inline.hpp&quot;
  57 #include &quot;gc/shenandoah/shenandoahPacer.inline.hpp&quot;
<span class="line-added">  58 #include &quot;gc/shenandoah/shenandoahPadding.hpp&quot;</span>
  59 #include &quot;gc/shenandoah/shenandoahParallelCleaning.inline.hpp&quot;
  60 #include &quot;gc/shenandoah/shenandoahPassiveMode.hpp&quot;
  61 #include &quot;gc/shenandoah/shenandoahRootProcessor.inline.hpp&quot;
  62 #include &quot;gc/shenandoah/shenandoahStringDedup.hpp&quot;
  63 #include &quot;gc/shenandoah/shenandoahTaskqueue.hpp&quot;

  64 #include &quot;gc/shenandoah/shenandoahUtils.hpp&quot;
  65 #include &quot;gc/shenandoah/shenandoahVerifier.hpp&quot;
  66 #include &quot;gc/shenandoah/shenandoahCodeRoots.hpp&quot;
  67 #include &quot;gc/shenandoah/shenandoahVMOperations.hpp&quot;
  68 #include &quot;gc/shenandoah/shenandoahWorkGroup.hpp&quot;
  69 #include &quot;gc/shenandoah/shenandoahWorkerPolicy.hpp&quot;
  70 #if INCLUDE_JFR
  71 #include &quot;gc/shenandoah/shenandoahJfrSupport.hpp&quot;
  72 #endif
  73 
  74 #include &quot;memory/metaspace.hpp&quot;
  75 #include &quot;oops/compressedOops.inline.hpp&quot;
  76 #include &quot;runtime/atomic.hpp&quot;
  77 #include &quot;runtime/globals.hpp&quot;
  78 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  79 #include &quot;runtime/orderAccess.hpp&quot;
  80 #include &quot;runtime/safepointMechanism.hpp&quot;
  81 #include &quot;runtime/vmThread.hpp&quot;
  82 #include &quot;services/mallocTracker.hpp&quot;
  83 #include &quot;utilities/powerOfTwo.hpp&quot;
  84 
<span class="line-added">  85 ShenandoahHeap* ShenandoahHeap::_heap = NULL;</span>
<span class="line-added">  86 </span>
  87 #ifdef ASSERT
  88 template &lt;class T&gt;
  89 void ShenandoahAssertToSpaceClosure::do_oop_work(T* p) {
  90   T o = RawAccess&lt;&gt;::oop_load(p);
  91   if (! CompressedOops::is_null(o)) {
  92     oop obj = CompressedOops::decode_not_null(o);
  93     shenandoah_assert_not_forwarded(p, obj);
  94   }
  95 }
  96 
  97 void ShenandoahAssertToSpaceClosure::do_oop(narrowOop* p) { do_oop_work(p); }
  98 void ShenandoahAssertToSpaceClosure::do_oop(oop* p)       { do_oop_work(p); }
  99 #endif
 100 
 101 class ShenandoahPretouchHeapTask : public AbstractGangTask {
 102 private:
 103   ShenandoahRegionIterator _regions;
 104   const size_t _page_size;
 105 public:
 106   ShenandoahPretouchHeapTask(size_t page_size) :
</pre>
<hr />
<pre>
 115     }
 116   }
 117 };
 118 
 119 class ShenandoahPretouchBitmapTask : public AbstractGangTask {
 120 private:
 121   ShenandoahRegionIterator _regions;
 122   char* _bitmap_base;
 123   const size_t _bitmap_size;
 124   const size_t _page_size;
 125 public:
 126   ShenandoahPretouchBitmapTask(char* bitmap_base, size_t bitmap_size, size_t page_size) :
 127     AbstractGangTask(&quot;Shenandoah Pretouch Bitmap&quot;),
 128     _bitmap_base(bitmap_base),
 129     _bitmap_size(bitmap_size),
 130     _page_size(page_size) {}
 131 
 132   virtual void work(uint worker_id) {
 133     ShenandoahHeapRegion* r = _regions.next();
 134     while (r != NULL) {
<span class="line-modified"> 135       size_t start = r-&gt;index()       * ShenandoahHeapRegion::region_size_bytes() / MarkBitMap::heap_map_factor();</span>
<span class="line-modified"> 136       size_t end   = (r-&gt;index() + 1) * ShenandoahHeapRegion::region_size_bytes() / MarkBitMap::heap_map_factor();</span>
 137       assert (end &lt;= _bitmap_size, &quot;end is sane: &quot; SIZE_FORMAT &quot; &lt; &quot; SIZE_FORMAT, end, _bitmap_size);
 138 
 139       os::pretouch_memory(_bitmap_base + start, _bitmap_base + end, _page_size);
 140 
 141       r = _regions.next();
 142     }
 143   }
 144 };
 145 
 146 jint ShenandoahHeap::initialize() {


 147   //
 148   // Figure out heap sizing
 149   //
 150 
 151   size_t init_byte_size = InitialHeapSize;
 152   size_t min_byte_size  = MinHeapSize;
 153   size_t max_byte_size  = MaxHeapSize;
 154   size_t heap_alignment = HeapAlignment;
 155 
 156   size_t reg_size_bytes = ShenandoahHeapRegion::region_size_bytes();
 157 
 158   if (ShenandoahAlwaysPreTouch) {
 159     // Enabled pre-touch means the entire heap is committed right away.
 160     init_byte_size = max_byte_size;
 161   }
 162 
 163   Universe::check_alignment(max_byte_size,  reg_size_bytes, &quot;Shenandoah heap&quot;);
 164   Universe::check_alignment(init_byte_size, reg_size_bytes, &quot;Shenandoah heap&quot;);
 165 
 166   _num_regions = ShenandoahHeapRegion::region_count();
 167 
<span class="line-added"> 168   // Now we know the number of regions, initialize the heuristics.</span>
<span class="line-added"> 169   initialize_heuristics();</span>
<span class="line-added"> 170 </span>
 171   size_t num_committed_regions = init_byte_size / reg_size_bytes;
 172   num_committed_regions = MIN2(num_committed_regions, _num_regions);
 173   assert(num_committed_regions &lt;= _num_regions, &quot;sanity&quot;);
 174   _initial_size = num_committed_regions * reg_size_bytes;
 175 
 176   size_t num_min_regions = min_byte_size / reg_size_bytes;
 177   num_min_regions = MIN2(num_min_regions, _num_regions);
 178   assert(num_min_regions &lt;= _num_regions, &quot;sanity&quot;);
 179   _minimum_size = num_min_regions * reg_size_bytes;
 180 
 181   _committed = _initial_size;
 182 
 183   size_t heap_page_size   = UseLargePages ? (size_t)os::large_page_size() : (size_t)os::vm_page_size();
 184   size_t bitmap_page_size = UseLargePages ? (size_t)os::large_page_size() : (size_t)os::vm_page_size();
<span class="line-added"> 185   size_t region_page_size = UseLargePages ? (size_t)os::large_page_size() : (size_t)os::vm_page_size();</span>
 186 
 187   //
 188   // Reserve and commit memory for heap
 189   //
 190 
 191   ReservedHeapSpace heap_rs = Universe::reserve_heap(max_byte_size, heap_alignment);
 192   initialize_reserved_region(heap_rs);
 193   _heap_region = MemRegion((HeapWord*)heap_rs.base(), heap_rs.size() / HeapWordSize);
 194   _heap_region_special = heap_rs.special();
 195 
 196   assert((((size_t) base()) &amp; ShenandoahHeapRegion::region_size_bytes_mask()) == 0,
 197          &quot;Misaligned heap: &quot; PTR_FORMAT, p2i(base()));
 198 
 199 #if SHENANDOAH_OPTIMIZED_OBJTASK
 200   // The optimized ObjArrayChunkedTask takes some bits away from the full object bits.
 201   // Fail if we ever attempt to address more than we can.
 202   if ((uintptr_t)heap_rs.end() &gt;= ObjArrayChunkedTask::max_addressable()) {
 203     FormatBuffer&lt;512&gt; buf(&quot;Shenandoah reserved [&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT&quot;) for the heap, \n&quot;
 204                           &quot;but max object address is &quot; PTR_FORMAT &quot;. Try to reduce heap size, or try other \n&quot;
 205                           &quot;VM options that allocate heap at lower addresses (HeapBaseMinAddress, AllocateHeapAt, etc).&quot;,
</pre>
<hr />
<pre>
 264     if (!verify_bitmap.special()) {
 265       os::commit_memory_or_exit(verify_bitmap.base(), verify_bitmap.size(), bitmap_page_size, false,
 266                                 &quot;Cannot commit verification bitmap memory&quot;);
 267     }
 268     MemTracker::record_virtual_memory_type(verify_bitmap.base(), mtGC);
 269     MemRegion verify_bitmap_region = MemRegion((HeapWord *) verify_bitmap.base(), verify_bitmap.size() / HeapWordSize);
 270     _verification_bit_map.initialize(_heap_region, verify_bitmap_region);
 271     _verifier = new ShenandoahVerifier(this, &amp;_verification_bit_map);
 272   }
 273 
 274   // Reserve aux bitmap for use in object_iterate(). We don&#39;t commit it here.
 275   ReservedSpace aux_bitmap(_bitmap_size, bitmap_page_size);
 276   MemTracker::record_virtual_memory_type(aux_bitmap.base(), mtGC);
 277   _aux_bitmap_region = MemRegion((HeapWord*) aux_bitmap.base(), aux_bitmap.size() / HeapWordSize);
 278   _aux_bitmap_region_special = aux_bitmap.special();
 279   _aux_bit_map.initialize(_heap_region, _aux_bitmap_region);
 280 
 281   //
 282   // Create regions and region sets
 283   //
<span class="line-added"> 284   size_t region_align = align_up(sizeof(ShenandoahHeapRegion), SHENANDOAH_CACHE_LINE_SIZE);</span>
<span class="line-added"> 285   size_t region_storage_size = align_up(region_align * _num_regions, region_page_size);</span>
<span class="line-added"> 286   region_storage_size = align_up(region_storage_size, os::vm_allocation_granularity());</span>
<span class="line-added"> 287 </span>
<span class="line-added"> 288   ReservedSpace region_storage(region_storage_size, region_page_size);</span>
<span class="line-added"> 289   MemTracker::record_virtual_memory_type(region_storage.base(), mtGC);</span>
<span class="line-added"> 290   if (!region_storage.special()) {</span>
<span class="line-added"> 291     os::commit_memory_or_exit(region_storage.base(), region_storage_size, region_page_size, false,</span>
<span class="line-added"> 292                               &quot;Cannot commit region memory&quot;);</span>
<span class="line-added"> 293   }</span>
 294 
 295   _regions = NEW_C_HEAP_ARRAY(ShenandoahHeapRegion*, _num_regions, mtGC);
 296   _free_set = new ShenandoahFreeSet(this, _num_regions);
 297   _collection_set = new ShenandoahCollectionSet(this, sh_rs.base(), sh_rs.size());
 298 
 299   {
 300     ShenandoahHeapLocker locker(lock());
 301 


 302     for (size_t i = 0; i &lt; _num_regions; i++) {
<span class="line-modified"> 303       HeapWord* start = (HeapWord*)sh_rs.base() + ShenandoahHeapRegion::region_size_words() * i;</span>
 304       bool is_committed = i &lt; num_committed_regions;
<span class="line-modified"> 305       void* loc = region_storage.base() + i * region_align;</span>
<span class="line-added"> 306 </span>
<span class="line-added"> 307       ShenandoahHeapRegion* r = new (loc) ShenandoahHeapRegion(start, i, is_committed);</span>
<span class="line-added"> 308       assert(is_aligned(r, SHENANDOAH_CACHE_LINE_SIZE), &quot;Sanity&quot;);</span>
 309 
 310       _marking_context-&gt;initialize_top_at_mark_start(r);
 311       _regions[i] = r;
 312       assert(!collection_set()-&gt;is_in(i), &quot;New region should not be in collection set&quot;);
 313     }
 314 
 315     // Initialize to complete
 316     _marking_context-&gt;mark_complete();
 317 
 318     _free_set-&gt;rebuild();
 319   }
 320 
 321   if (ShenandoahAlwaysPreTouch) {
 322     assert(!AlwaysPreTouch, &quot;Should have been overridden&quot;);
 323 
 324     // For NUMA, it is important to pre-touch the storage under bitmaps with worker threads,
 325     // before initialize() below zeroes it with initializing thread. For any given region,
 326     // we touch the region and the corresponding bitmaps from the same thread.
 327     ShenandoahPushWorkerScope scope(workers(), _max_workers, false);
 328 
</pre>
<hr />
<pre>
 340 #endif
 341 
 342     // OS memory managers may want to coalesce back-to-back pages. Make their jobs
 343     // simpler by pre-touching continuous spaces (heap and bitmap) separately.
 344 
 345     log_info(gc, init)(&quot;Pretouch bitmap: &quot; SIZE_FORMAT &quot; regions, &quot; SIZE_FORMAT &quot; bytes page&quot;,
 346                        _num_regions, pretouch_bitmap_page_size);
 347     ShenandoahPretouchBitmapTask bcl(bitmap.base(), _bitmap_size, pretouch_bitmap_page_size);
 348     _workers-&gt;run_task(&amp;bcl);
 349 
 350     log_info(gc, init)(&quot;Pretouch heap: &quot; SIZE_FORMAT &quot; regions, &quot; SIZE_FORMAT &quot; bytes page&quot;,
 351                        _num_regions, pretouch_heap_page_size);
 352     ShenandoahPretouchHeapTask hcl(pretouch_heap_page_size);
 353     _workers-&gt;run_task(&amp;hcl);
 354   }
 355 
 356   //
 357   // Initialize the rest of GC subsystems
 358   //
 359 
<span class="line-modified"> 360   _liveness_cache = NEW_C_HEAP_ARRAY(ShenandoahLiveData*, _max_workers, mtGC);</span>
 361   for (uint worker = 0; worker &lt; _max_workers; worker++) {
<span class="line-modified"> 362     _liveness_cache[worker] = NEW_C_HEAP_ARRAY(ShenandoahLiveData, _num_regions, mtGC);</span>
<span class="line-modified"> 363     Copy::fill_to_bytes(_liveness_cache[worker], _num_regions * sizeof(ShenandoahLiveData));</span>
 364   }
 365 
 366   // There should probably be Shenandoah-specific options for these,
 367   // just as there are G1-specific options.
 368   {
 369     ShenandoahSATBMarkQueueSet&amp; satbqs = ShenandoahBarrierSet::satb_mark_queue_set();
 370     satbqs.set_process_completed_buffers_threshold(20); // G1SATBProcessCompletedThreshold
 371     satbqs.set_buffer_enqueue_threshold_percentage(60); // G1SATBBufferEnqueueingThresholdPercent
 372   }
 373 
 374   _monitoring_support = new ShenandoahMonitoringSupport(this);
 375   _phase_timings = new ShenandoahPhaseTimings();
 376   ShenandoahStringDedup::initialize();
 377   ShenandoahCodeRoots::initialize();
 378 
 379   if (ShenandoahPacing) {
 380     _pacer = new ShenandoahPacer(this);
 381     _pacer-&gt;setup_for_idle();
 382   } else {
 383     _pacer = NULL;
 384   }
 385 




 386   _control_thread = new ShenandoahControlThread();
 387 
 388   log_info(gc, init)(&quot;Initialize Shenandoah heap: &quot; SIZE_FORMAT &quot;%s initial, &quot; SIZE_FORMAT &quot;%s min, &quot; SIZE_FORMAT &quot;%s max&quot;,
 389                      byte_size_in_proper_unit(_initial_size),  proper_unit_for_byte_size(_initial_size),
 390                      byte_size_in_proper_unit(_minimum_size),  proper_unit_for_byte_size(_minimum_size),
 391                      byte_size_in_proper_unit(max_capacity()), proper_unit_for_byte_size(max_capacity())
 392   );
 393 
<span class="line-modified"> 394   log_info(gc, init)(&quot;Safepointing mechanism: thread-local poll&quot;);</span>


 395 
 396   return JNI_OK;
 397 }
 398 
 399 void ShenandoahHeap::initialize_heuristics() {
 400   if (ShenandoahGCMode != NULL) {
<span class="line-modified"> 401     if (strcmp(ShenandoahGCMode, &quot;normal&quot;) == 0) {</span>


 402       _gc_mode = new ShenandoahNormalMode();
<span class="line-added"> 403     } else if (strcmp(ShenandoahGCMode, &quot;iu&quot;) == 0) {</span>
<span class="line-added"> 404       _gc_mode = new ShenandoahIUMode();</span>
 405     } else if (strcmp(ShenandoahGCMode, &quot;passive&quot;) == 0) {
 406       _gc_mode = new ShenandoahPassiveMode();
 407     } else {
 408       vm_exit_during_initialization(&quot;Unknown -XX:ShenandoahGCMode option&quot;);
 409     }
 410   } else {
 411     ShouldNotReachHere();
 412   }
 413   _gc_mode-&gt;initialize_flags();
<span class="line-added"> 414   if (_gc_mode-&gt;is_diagnostic() &amp;&amp; !UnlockDiagnosticVMOptions) {</span>
<span class="line-added"> 415     vm_exit_during_initialization(</span>
<span class="line-added"> 416             err_msg(&quot;GC mode \&quot;%s\&quot; is diagnostic, and must be enabled via -XX:+UnlockDiagnosticVMOptions.&quot;,</span>
<span class="line-added"> 417                     _gc_mode-&gt;name()));</span>
<span class="line-added"> 418   }</span>
<span class="line-added"> 419   if (_gc_mode-&gt;is_experimental() &amp;&amp; !UnlockExperimentalVMOptions) {</span>
<span class="line-added"> 420     vm_exit_during_initialization(</span>
<span class="line-added"> 421             err_msg(&quot;GC mode \&quot;%s\&quot; is experimental, and must be enabled via -XX:+UnlockExperimentalVMOptions.&quot;,</span>
<span class="line-added"> 422                     _gc_mode-&gt;name()));</span>
<span class="line-added"> 423   }</span>
<span class="line-added"> 424   log_info(gc, init)(&quot;Shenandoah GC mode: %s&quot;,</span>
<span class="line-added"> 425                      _gc_mode-&gt;name());</span>
<span class="line-added"> 426 </span>
 427   _heuristics = _gc_mode-&gt;initialize_heuristics();
 428 
 429   if (_heuristics-&gt;is_diagnostic() &amp;&amp; !UnlockDiagnosticVMOptions) {
 430     vm_exit_during_initialization(
 431             err_msg(&quot;Heuristics \&quot;%s\&quot; is diagnostic, and must be enabled via -XX:+UnlockDiagnosticVMOptions.&quot;,
 432                     _heuristics-&gt;name()));
 433   }
 434   if (_heuristics-&gt;is_experimental() &amp;&amp; !UnlockExperimentalVMOptions) {
 435     vm_exit_during_initialization(
 436             err_msg(&quot;Heuristics \&quot;%s\&quot; is experimental, and must be enabled via -XX:+UnlockExperimentalVMOptions.&quot;,
 437                     _heuristics-&gt;name()));
 438   }
 439   log_info(gc, init)(&quot;Shenandoah heuristics: %s&quot;,
 440                      _heuristics-&gt;name());
 441 }
 442 
 443 #ifdef _MSC_VER
 444 #pragma warning( push )
 445 #pragma warning( disable:4355 ) // &#39;this&#39; : used in base member initializer list
 446 #endif
 447 
 448 ShenandoahHeap::ShenandoahHeap(ShenandoahCollectorPolicy* policy) :
 449   CollectedHeap(),
 450   _initial_size(0),
 451   _used(0),
 452   _committed(0),
 453   _bytes_allocated_since_gc_start(0),
 454   _max_workers(MAX2(ConcGCThreads, ParallelGCThreads)),
 455   _workers(NULL),
 456   _safepoint_workers(NULL),
 457   _heap_region_special(false),
 458   _num_regions(0),
 459   _regions(NULL),
 460   _update_refs_iterator(this),
 461   _control_thread(NULL),
 462   _shenandoah_policy(policy),
 463   _heuristics(NULL),
 464   _free_set(NULL),
 465   _scm(new ShenandoahConcurrentMark()),

 466   _full_gc(new ShenandoahMarkCompact()),
 467   _pacer(NULL),
 468   _verifier(NULL),
 469   _phase_timings(NULL),
 470   _monitoring_support(NULL),
 471   _memory_pool(NULL),
 472   _stw_memory_manager(&quot;Shenandoah Pauses&quot;, &quot;end of GC pause&quot;),
 473   _cycle_memory_manager(&quot;Shenandoah Cycles&quot;, &quot;end of GC cycle&quot;),
 474   _gc_timer(new (ResourceObj::C_HEAP, mtGC) ConcurrentGCTimer()),
 475   _soft_ref_policy(),
 476   _log_min_obj_alignment_in_bytes(LogMinObjAlignmentInBytes),
 477   _ref_processor(NULL),
 478   _marking_context(NULL),
 479   _bitmap_size(0),
 480   _bitmap_regions_per_slice(0),
 481   _bitmap_bytes_per_slice(0),
 482   _bitmap_region_special(false),
 483   _aux_bitmap_region_special(false),
 484   _liveness_cache(NULL),
 485   _collection_set(NULL)
 486 {
<span class="line-added"> 487   _heap = this;</span>
<span class="line-added"> 488 </span>
 489   log_info(gc, init)(&quot;GC threads: &quot; UINT32_FORMAT &quot; parallel, &quot; UINT32_FORMAT &quot; concurrent&quot;, ParallelGCThreads, ConcGCThreads);
 490   log_info(gc, init)(&quot;Reference processing: %s&quot;, ParallelRefProcEnabled ? &quot;parallel&quot; : &quot;serial&quot;);
 491 
 492   BarrierSet::set_barrier_set(new ShenandoahBarrierSet(this));
 493 
 494   _max_workers = MAX2(_max_workers, 1U);
 495   _workers = new ShenandoahWorkGang(&quot;Shenandoah GC Threads&quot;, _max_workers,
 496                             /* are_GC_task_threads */ true,
 497                             /* are_ConcurrentGC_threads */ true);
 498   if (_workers == NULL) {
 499     vm_exit_during_initialization(&quot;Failed necessary allocation.&quot;);
 500   } else {
 501     _workers-&gt;initialize_workers();
 502   }
 503 
 504   if (ParallelGCThreads &gt; 1) {
 505     _safepoint_workers = new ShenandoahWorkGang(&quot;Safepoint Cleanup Thread&quot;,
 506                                                 ParallelGCThreads,
 507                       /* are_GC_task_threads */ false,
 508                  /* are_ConcurrentGC_threads */ false);
</pre>
<hr />
<pre>
 542   ShenandoahResetBitmapTask task;
 543   _workers-&gt;run_task(&amp;task);
 544 }
 545 
 546 void ShenandoahHeap::print_on(outputStream* st) const {
 547   st-&gt;print_cr(&quot;Shenandoah Heap&quot;);
 548   st-&gt;print_cr(&quot; &quot; SIZE_FORMAT &quot;%s total, &quot; SIZE_FORMAT &quot;%s committed, &quot; SIZE_FORMAT &quot;%s used&quot;,
 549                byte_size_in_proper_unit(max_capacity()), proper_unit_for_byte_size(max_capacity()),
 550                byte_size_in_proper_unit(committed()),    proper_unit_for_byte_size(committed()),
 551                byte_size_in_proper_unit(used()),         proper_unit_for_byte_size(used()));
 552   st-&gt;print_cr(&quot; &quot; SIZE_FORMAT &quot; x &quot; SIZE_FORMAT&quot;%s regions&quot;,
 553                num_regions(),
 554                byte_size_in_proper_unit(ShenandoahHeapRegion::region_size_bytes()),
 555                proper_unit_for_byte_size(ShenandoahHeapRegion::region_size_bytes()));
 556 
 557   st-&gt;print(&quot;Status: &quot;);
 558   if (has_forwarded_objects())               st-&gt;print(&quot;has forwarded objects, &quot;);
 559   if (is_concurrent_mark_in_progress())      st-&gt;print(&quot;marking, &quot;);
 560   if (is_evacuation_in_progress())           st-&gt;print(&quot;evacuating, &quot;);
 561   if (is_update_refs_in_progress())          st-&gt;print(&quot;updating refs, &quot;);

 562   if (is_degenerated_gc_in_progress())       st-&gt;print(&quot;degenerated gc, &quot;);
 563   if (is_full_gc_in_progress())              st-&gt;print(&quot;full gc, &quot;);
 564   if (is_full_gc_move_in_progress())         st-&gt;print(&quot;full gc move, &quot;);
 565   if (is_concurrent_root_in_progress())      st-&gt;print(&quot;concurrent roots, &quot;);
 566 
 567   if (cancelled_gc()) {
 568     st-&gt;print(&quot;cancelled&quot;);
 569   } else {
 570     st-&gt;print(&quot;not cancelled&quot;);
 571   }
 572   st-&gt;cr();
 573 
 574   st-&gt;print_cr(&quot;Reserved region:&quot;);
 575   st-&gt;print_cr(&quot; - [&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT &quot;) &quot;,
 576                p2i(reserved_region().start()),
 577                p2i(reserved_region().end()));
 578 
 579   ShenandoahCollectionSet* cset = collection_set();
 580   st-&gt;print_cr(&quot;Collection set:&quot;);
 581   if (cset != NULL) {
</pre>
<hr />
<pre>
 616   _scm-&gt;initialize(_max_workers);
 617   _full_gc-&gt;initialize(_gc_timer);
 618 
 619   ref_processing_init();
 620 
 621   _heuristics-&gt;initialize();
 622 
 623   JFR_ONLY(ShenandoahJFRSupport::register_jfr_type_serializers());
 624 }
 625 
 626 size_t ShenandoahHeap::used() const {
 627   return Atomic::load_acquire(&amp;_used);
 628 }
 629 
 630 size_t ShenandoahHeap::committed() const {
 631   OrderAccess::acquire();
 632   return _committed;
 633 }
 634 
 635 void ShenandoahHeap::increase_committed(size_t bytes) {
<span class="line-modified"> 636   shenandoah_assert_heaplocked_or_safepoint();</span>
 637   _committed += bytes;
 638 }
 639 
 640 void ShenandoahHeap::decrease_committed(size_t bytes) {
<span class="line-modified"> 641   shenandoah_assert_heaplocked_or_safepoint();</span>
 642   _committed -= bytes;
 643 }
 644 
 645 void ShenandoahHeap::increase_used(size_t bytes) {
 646   Atomic::add(&amp;_used, bytes);
 647 }
 648 
 649 void ShenandoahHeap::set_used(size_t bytes) {
 650   Atomic::release_store_fence(&amp;_used, bytes);
 651 }
 652 
 653 void ShenandoahHeap::decrease_used(size_t bytes) {
 654   assert(used() &gt;= bytes, &quot;never decrease heap size by more than we&#39;ve left&quot;);
 655   Atomic::sub(&amp;_used, bytes);
 656 }
 657 
 658 void ShenandoahHeap::increase_allocated(size_t bytes) {
 659   Atomic::add(&amp;_bytes_allocated_since_gc_start, bytes);
 660 }
 661 
</pre>
<hr />
<pre>
 784     *actual_size = req.actual_size();
 785   } else {
 786     *actual_size = 0;
 787   }
 788   return res;
 789 }
 790 
 791 HeapWord* ShenandoahHeap::allocate_new_gclab(size_t min_size,
 792                                              size_t word_size,
 793                                              size_t* actual_size) {
 794   ShenandoahAllocRequest req = ShenandoahAllocRequest::for_gclab(min_size, word_size);
 795   HeapWord* res = allocate_memory(req);
 796   if (res != NULL) {
 797     *actual_size = req.actual_size();
 798   } else {
 799     *actual_size = 0;
 800   }
 801   return res;
 802 }
 803 












 804 HeapWord* ShenandoahHeap::allocate_memory(ShenandoahAllocRequest&amp; req) {
 805   intptr_t pacer_epoch = 0;
 806   bool in_new_region = false;
 807   HeapWord* result = NULL;
 808 
 809   if (req.is_mutator_alloc()) {
 810     if (ShenandoahPacing) {
 811       pacer()-&gt;pace_for_alloc(req.size());
 812       pacer_epoch = pacer()-&gt;epoch();
 813     }
 814 
 815     if (!ShenandoahAllocFailureALot || !should_inject_alloc_failure()) {
 816       result = allocate_memory_under_lock(req, in_new_region);
 817     }
 818 
 819     // Allocation failed, block until control thread reacted, then retry allocation.
 820     //
 821     // It might happen that one of the threads requesting allocation would unblock
 822     // way later after GC happened, only to fail the second allocation, because
 823     // other threads have already depleted the free storage. In this case, a better
 824     // strategy is to try again, as long as GC makes progress.
 825     //
 826     // Then, we need to make sure the allocation was retried after at least one
 827     // Full GC, which means we want to try more than ShenandoahFullGCThreshold times.
 828 
 829     size_t tries = 0;
 830 
 831     while (result == NULL &amp;&amp; _progress_last_gc.is_set()) {
 832       tries++;
<span class="line-modified"> 833       control_thread()-&gt;handle_alloc_failure(req);</span>
 834       result = allocate_memory_under_lock(req, in_new_region);
 835     }
 836 
 837     while (result == NULL &amp;&amp; tries &lt;= ShenandoahFullGCThreshold) {
 838       tries++;
<span class="line-modified"> 839       control_thread()-&gt;handle_alloc_failure(req);</span>
 840       result = allocate_memory_under_lock(req, in_new_region);
 841     }
 842 
 843   } else {
 844     assert(req.is_gc_alloc(), &quot;Can only accept GC allocs here&quot;);
 845     result = allocate_memory_under_lock(req, in_new_region);
 846     // Do not call handle_alloc_failure() here, because we cannot block.
 847     // The allocation failure would be handled by the LRB slowpath with handle_alloc_failure_evac().
 848   }
 849 
 850   if (in_new_region) {
 851     control_thread()-&gt;notify_heap_changed();
 852   }
 853 
 854   if (result != NULL) {
 855     size_t requested = req.size();
 856     size_t actual = req.actual_size();
 857 
 858     assert (req.is_lab_alloc() || (requested == actual),
 859             &quot;Only LAB allocations are elastic: %s, requested = &quot; SIZE_FORMAT &quot;, actual = &quot; SIZE_FORMAT,
</pre>
<hr />
<pre>
 955   {}
 956 
 957   void work(uint worker_id) {
 958     if (_concurrent) {
 959       ShenandoahConcurrentWorkerSession worker_session(worker_id);
 960       ShenandoahSuspendibleThreadSetJoiner stsj(ShenandoahSuspendibleWorkers);
 961       ShenandoahEvacOOMScope oom_evac_scope;
 962       do_work();
 963     } else {
 964       ShenandoahParallelWorkerSession worker_session(worker_id);
 965       ShenandoahEvacOOMScope oom_evac_scope;
 966       do_work();
 967     }
 968   }
 969 
 970 private:
 971   void do_work() {
 972     ShenandoahConcurrentEvacuateRegionObjectClosure cl(_sh);
 973     ShenandoahHeapRegion* r;
 974     while ((r =_cs-&gt;claim_next()) != NULL) {
<span class="line-modified"> 975       assert(r-&gt;has_live(), &quot;Region &quot; SIZE_FORMAT &quot; should have been reclaimed early&quot;, r-&gt;index());</span>
 976       _sh-&gt;marked_object_iterate(r, &amp;cl);
 977 
 978       if (ShenandoahPacing) {
 979         _sh-&gt;pacer()-&gt;report_evac(r-&gt;used() &gt;&gt; LogHeapWordSize);
 980       }
 981 
 982       if (_sh-&gt;check_cancelled_gc_and_yield(_concurrent)) {
 983         break;
 984       }
 985     }
 986   }
 987 };
 988 
 989 void ShenandoahHeap::trash_cset_regions() {
 990   ShenandoahHeapLocker locker(lock());
 991 
 992   ShenandoahCollectionSet* set = collection_set();
 993   ShenandoahHeapRegion* r;
 994   set-&gt;clear_current_index();
 995   while ((r = set-&gt;next()) != NULL) {
 996     r-&gt;make_trash();
 997   }
 998   collection_set()-&gt;clear();
 999 }
1000 
1001 void ShenandoahHeap::print_heap_regions_on(outputStream* st) const {
1002   st-&gt;print_cr(&quot;Heap Regions:&quot;);
1003   st-&gt;print_cr(&quot;EU=empty-uncommitted, EC=empty-committed, R=regular, H=humongous start, HC=humongous continuation, CS=collection set, T=trash, P=pinned&quot;);
1004   st-&gt;print_cr(&quot;BTE=bottom/top/end, U=used, T=TLAB allocs, G=GCLAB allocs, S=shared allocs, L=live data&quot;);
<span class="line-modified">1005   st-&gt;print_cr(&quot;R=root, CP=critical pins, TAMS=top-at-mark-start, UWM=update watermark&quot;);</span>
<span class="line-modified">1006   st-&gt;print_cr(&quot;SN=alloc sequence number&quot;);</span>
1007 
1008   for (size_t i = 0; i &lt; num_regions(); i++) {
1009     get_region(i)-&gt;print_on(st);
1010   }
1011 }
1012 
1013 void ShenandoahHeap::trash_humongous_region_at(ShenandoahHeapRegion* start) {
1014   assert(start-&gt;is_humongous_start(), &quot;reclaim regions starting with the first one&quot;);
1015 
1016   oop humongous_obj = oop(start-&gt;bottom());
1017   size_t size = humongous_obj-&gt;size();
1018   size_t required_regions = ShenandoahHeapRegion::required_regions(size * HeapWordSize);
<span class="line-modified">1019   size_t index = start-&gt;index() + required_regions - 1;</span>
1020 
1021   assert(!start-&gt;has_live(), &quot;liveness must be zero&quot;);
1022 
1023   for(size_t i = 0; i &lt; required_regions; i++) {
1024     // Reclaim from tail. Otherwise, assertion fails when printing region to trace log,
1025     // as it expects that every region belongs to a humongous region starting with a humongous start region.
1026     ShenandoahHeapRegion* region = get_region(index --);
1027 
1028     assert(region-&gt;is_humongous(), &quot;expect correct humongous start or continuation&quot;);
1029     assert(!region-&gt;is_cset(), &quot;Humongous region should not be in collection set&quot;);
1030 
1031     region-&gt;make_trash_immediate();
1032   }
1033 }
1034 
1035 class ShenandoahRetireGCLABClosure : public ThreadClosure {
1036 public:
1037   void do_thread(Thread* thread) {
1038     PLAB* gclab = ShenandoahThreadLocalData::gclab(thread);
1039     assert(gclab != NULL, &quot;GCLAB should be initialized for %s&quot;, thread-&gt;name());
</pre>
<hr />
<pre>
1121   }
1122 };
1123 
1124 void ShenandoahHeap::retire_and_reset_gclabs() {
1125   ShenandoahRetireAndResetGCLABClosure cl;
1126   for (JavaThreadIteratorWithHandle jtiwh; JavaThread *t = jtiwh.next(); ) {
1127     cl.do_thread(t);
1128   }
1129   workers()-&gt;threads_do(&amp;cl);
1130 }
1131 
1132 void ShenandoahHeap::collect(GCCause::Cause cause) {
1133   control_thread()-&gt;request_gc(cause);
1134 }
1135 
1136 void ShenandoahHeap::do_full_collection(bool clear_all_soft_refs) {
1137   //assert(false, &quot;Shouldn&#39;t need to do full collections&quot;);
1138 }
1139 
1140 HeapWord* ShenandoahHeap::block_start(const void* addr) const {
<span class="line-modified">1141   ShenandoahHeapRegion* r = heap_region_containing(addr);</span>
<span class="line-modified">1142   if (r != NULL) {</span>
<span class="line-modified">1143     return r-&gt;block_start(addr);</span>
1144   }
1145   return NULL;
1146 }
1147 
1148 bool ShenandoahHeap::block_is_obj(const HeapWord* addr) const {
<span class="line-modified">1149   ShenandoahHeapRegion* r = heap_region_containing(addr);</span>
<span class="line-modified">1150   return r-&gt;block_is_obj(addr);</span>
1151 }
1152 
1153 bool ShenandoahHeap::print_location(outputStream* st, void* addr) const {
1154   return BlockLocationPrinter&lt;ShenandoahHeap&gt;::print_location(st, addr);
1155 }
1156 
1157 jlong ShenandoahHeap::millis_since_last_gc() {
1158   double v = heuristics()-&gt;time_since_last_gc() * 1000;
1159   assert(0 &lt;= v &amp;&amp; v &lt;= max_jlong, &quot;value should fit: %f&quot;, v);
1160   return (jlong)v;
1161 }
1162 
1163 void ShenandoahHeap::prepare_for_verify() {
1164   if (SafepointSynchronize::is_at_safepoint() || ! UseTLAB) {
1165     make_parsable(false);
1166   }
1167 }
1168 
1169 void ShenandoahHeap::print_gc_threads_on(outputStream* st) const {
1170   workers()-&gt;print_worker_threads_on(st);
</pre>
<hr />
<pre>
1315 
1316 // Keep alive an object that was loaded with AS_NO_KEEPALIVE.
1317 void ShenandoahHeap::keep_alive(oop obj) {
1318   if (is_concurrent_mark_in_progress()) {
1319     ShenandoahBarrierSet::barrier_set()-&gt;enqueue(obj);
1320   }
1321 }
1322 
1323 void ShenandoahHeap::heap_region_iterate(ShenandoahHeapRegionClosure* blk) const {
1324   for (size_t i = 0; i &lt; num_regions(); i++) {
1325     ShenandoahHeapRegion* current = get_region(i);
1326     blk-&gt;heap_region_do(current);
1327   }
1328 }
1329 
1330 class ShenandoahParallelHeapRegionTask : public AbstractGangTask {
1331 private:
1332   ShenandoahHeap* const _heap;
1333   ShenandoahHeapRegionClosure* const _blk;
1334 
<span class="line-modified">1335   shenandoah_padding(0);</span>
1336   volatile size_t _index;
<span class="line-modified">1337   shenandoah_padding(1);</span>
1338 
1339 public:
1340   ShenandoahParallelHeapRegionTask(ShenandoahHeapRegionClosure* blk) :
1341           AbstractGangTask(&quot;Parallel Region Task&quot;),
1342           _heap(ShenandoahHeap::heap()), _blk(blk), _index(0) {}
1343 
1344   void work(uint worker_id) {
1345     size_t stride = ShenandoahParallelRegionStride;
1346 
1347     size_t max = _heap-&gt;num_regions();
1348     while (_index &lt; max) {
1349       size_t cur = Atomic::fetch_and_add(&amp;_index, stride);
1350       size_t start = cur;
1351       size_t end = MIN2(cur + stride, max);
1352       if (start &gt;= max) break;
1353 
1354       for (size_t i = cur; i &lt; end; i++) {
1355         ShenandoahHeapRegion* current = _heap-&gt;get_region(i);
1356         _blk-&gt;heap_region_do(current);
1357       }
1358     }
1359   }
1360 };
1361 
1362 void ShenandoahHeap::parallel_heap_region_iterate(ShenandoahHeapRegionClosure* blk) const {
1363   assert(blk-&gt;is_thread_safe(), &quot;Only thread-safe closures here&quot;);
1364   if (num_regions() &gt; ShenandoahParallelRegionStride) {
1365     ShenandoahParallelHeapRegionTask task(blk);
1366     workers()-&gt;run_task(&amp;task);
1367   } else {
1368     heap_region_iterate(blk);
1369   }
1370 }
1371 
<span class="line-modified">1372 class ShenandoahInitMarkUpdateRegionStateClosure : public ShenandoahHeapRegionClosure {</span>
1373 private:
1374   ShenandoahMarkingContext* const _ctx;
1375 public:
<span class="line-modified">1376   ShenandoahInitMarkUpdateRegionStateClosure() : _ctx(ShenandoahHeap::heap()-&gt;marking_context()) {}</span>
1377 
1378   void heap_region_do(ShenandoahHeapRegion* r) {
1379     if (r-&gt;is_active()) {
1380       r-&gt;clear_live_data();
1381       _ctx-&gt;capture_top_at_mark_start(r);
1382     } else {
<span class="line-modified">1383       assert(!r-&gt;has_live(), &quot;Region &quot; SIZE_FORMAT &quot; should have no live data&quot;, r-&gt;index());</span>
1384       assert(_ctx-&gt;top_at_mark_start(r) == r-&gt;top(),
<span class="line-modified">1385              &quot;Region &quot; SIZE_FORMAT &quot; should already have correct TAMS&quot;, r-&gt;index());</span>
1386     }
1387   }
1388 
1389   bool is_thread_safe() { return true; }
1390 };
1391 
1392 void ShenandoahHeap::op_init_mark() {
1393   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should be at safepoint&quot;);
1394   assert(Thread::current()-&gt;is_VM_thread(), &quot;can only do this in VMThread&quot;);
1395 
1396   assert(marking_context()-&gt;is_bitmap_clear(), &quot;need clear marking bitmap&quot;);
1397   assert(!marking_context()-&gt;is_complete(), &quot;should not be complete&quot;);
<span class="line-added">1398   assert(!has_forwarded_objects(), &quot;No forwarded objects on this path&quot;);</span>
1399 
1400   if (ShenandoahVerify) {
1401     verifier()-&gt;verify_before_concmark();
1402   }
1403 
1404   if (VerifyBeforeGC) {
1405     Universe::verify();
1406   }
1407 
1408   set_concurrent_mark_in_progress(true);
1409   // We need to reset all TLABs because we&#39;d lose marks on all objects allocated in them.
1410   {
<span class="line-modified">1411     ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::make_parsable);</span>
1412     make_parsable(true);
1413   }
1414 
1415   {
<span class="line-modified">1416     ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::init_update_region_states);</span>
<span class="line-modified">1417     ShenandoahInitMarkUpdateRegionStateClosure cl;</span>
<span class="line-modified">1418     parallel_heap_region_iterate(&amp;cl);</span>
1419   }
1420 
1421   // Make above changes visible to worker threads
1422   OrderAccess::fence();
1423 
1424   concurrent_mark()-&gt;mark_roots(ShenandoahPhaseTimings::scan_roots);
1425 
1426   if (UseTLAB) {
<span class="line-modified">1427     ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::resize_tlabs);</span>
1428     resize_tlabs();
1429   }
1430 
1431   if (ShenandoahPacing) {
1432     pacer()-&gt;setup_for_mark();
1433   }
<span class="line-added">1434 </span>
<span class="line-added">1435   // Arm nmethods for concurrent marking. When a nmethod is about to be executed,</span>
<span class="line-added">1436   // we need to make sure that all its metadata are marked. alternative is to remark</span>
<span class="line-added">1437   // thread roots at final mark pause, but it can be potential latency killer.</span>
<span class="line-added">1438   if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {</span>
<span class="line-added">1439     ShenandoahCodeRoots::arm_nmethods();</span>
<span class="line-added">1440   }</span>
1441 }
1442 
1443 void ShenandoahHeap::op_mark() {
1444   concurrent_mark()-&gt;mark_from_roots();
1445 }
1446 
<span class="line-modified">1447 class ShenandoahFinalMarkUpdateRegionStateClosure : public ShenandoahHeapRegionClosure {</span>
1448 private:
1449   ShenandoahMarkingContext* const _ctx;
<span class="line-added">1450   ShenandoahHeapLock* const _lock;</span>
<span class="line-added">1451 </span>
1452 public:
<span class="line-modified">1453   ShenandoahFinalMarkUpdateRegionStateClosure() :</span>
<span class="line-added">1454     _ctx(ShenandoahHeap::heap()-&gt;complete_marking_context()), _lock(ShenandoahHeap::heap()-&gt;lock()) {}</span>
1455 
1456   void heap_region_do(ShenandoahHeapRegion* r) {
1457     if (r-&gt;is_active()) {
<span class="line-added">1458       // All allocations past TAMS are implicitly live, adjust the region data.</span>
<span class="line-added">1459       // Bitmaps/TAMS are swapped at this point, so we need to poll complete bitmap.</span>
1460       HeapWord *tams = _ctx-&gt;top_at_mark_start(r);
1461       HeapWord *top = r-&gt;top();
1462       if (top &gt; tams) {
1463         r-&gt;increase_live_data_alloc_words(pointer_delta(top, tams));
1464       }
<span class="line-added">1465 </span>
<span class="line-added">1466       // We are about to select the collection set, make sure it knows about</span>
<span class="line-added">1467       // current pinning status. Also, this allows trashing more regions that</span>
<span class="line-added">1468       // now have their pinning status dropped.</span>
<span class="line-added">1469       if (r-&gt;is_pinned()) {</span>
<span class="line-added">1470         if (r-&gt;pin_count() == 0) {</span>
<span class="line-added">1471           ShenandoahHeapLocker locker(_lock);</span>
<span class="line-added">1472           r-&gt;make_unpinned();</span>
<span class="line-added">1473         }</span>
<span class="line-added">1474       } else {</span>
<span class="line-added">1475         if (r-&gt;pin_count() &gt; 0) {</span>
<span class="line-added">1476           ShenandoahHeapLocker locker(_lock);</span>
<span class="line-added">1477           r-&gt;make_pinned();</span>
<span class="line-added">1478         }</span>
<span class="line-added">1479       }</span>
<span class="line-added">1480 </span>
<span class="line-added">1481       // Remember limit for updating refs. It&#39;s guaranteed that we get no</span>
<span class="line-added">1482       // from-space-refs written from here on.</span>
<span class="line-added">1483       r-&gt;set_update_watermark(r-&gt;top());</span>
1484     } else {
<span class="line-modified">1485       assert(!r-&gt;has_live(), &quot;Region &quot; SIZE_FORMAT &quot; should have no live data&quot;, r-&gt;index());</span>
1486       assert(_ctx-&gt;top_at_mark_start(r) == r-&gt;top(),
<span class="line-modified">1487              &quot;Region &quot; SIZE_FORMAT &quot; should have correct TAMS&quot;, r-&gt;index());</span>
1488     }
1489   }
1490 
1491   bool is_thread_safe() { return true; }
1492 };
1493 
1494 void ShenandoahHeap::op_final_mark() {
1495   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should be at safepoint&quot;);
<span class="line-added">1496   assert(!has_forwarded_objects(), &quot;No forwarded objects on this path&quot;);</span>
1497 
1498   // It is critical that we
1499   // evacuate roots right after finishing marking, so that we don&#39;t
1500   // get unmarked objects in the roots.
1501 
1502   if (!cancelled_gc()) {
1503     concurrent_mark()-&gt;finish_mark_from_roots(/* full_gc = */ false);
1504 
1505     // Marking is completed, deactivate SATB barrier
1506     set_concurrent_mark_in_progress(false);
1507     mark_complete_marking_context();
1508 
1509     parallel_cleaning(false /* full gc*/);
1510 










1511     if (ShenandoahVerify) {
1512       verifier()-&gt;verify_roots_no_forwarded();
1513     }
<span class="line-modified">1514 </span>

1515     {
<span class="line-modified">1516       ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::final_update_region_states);</span>
<span class="line-modified">1517       ShenandoahFinalMarkUpdateRegionStateClosure cl;</span>
1518       parallel_heap_region_iterate(&amp;cl);
<span class="line-added">1519 </span>
<span class="line-added">1520       assert_pinned_region_status();</span>
1521     }
1522 
1523     // Force the threads to reacquire their TLABs outside the collection set.
1524     {
<span class="line-modified">1525       ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::retire_tlabs);</span>
1526       make_parsable(true);
1527     }
1528 














1529     {
<span class="line-modified">1530       ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::choose_cset);</span>

1531       ShenandoahHeapLocker locker(lock());
1532       _collection_set-&gt;clear();


1533       heuristics()-&gt;choose_collection_set(_collection_set);
<span class="line-added">1534     }</span>
1535 
<span class="line-added">1536     {</span>
<span class="line-added">1537       ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::final_rebuild_freeset);</span>
<span class="line-added">1538       ShenandoahHeapLocker locker(lock());</span>
1539       _free_set-&gt;rebuild();
1540     }
1541 
1542     if (!is_degenerated_gc_in_progress()) {
1543       prepare_concurrent_roots();
1544       prepare_concurrent_unloading();
1545     }
1546 
1547     // If collection set has candidates, start evacuation.
1548     // Otherwise, bypass the rest of the cycle.
1549     if (!collection_set()-&gt;is_empty()) {
<span class="line-modified">1550       ShenandoahGCSubPhase init_evac(ShenandoahPhaseTimings::init_evac);</span>
1551 
1552       if (ShenandoahVerify) {
1553         verifier()-&gt;verify_before_evacuation();
1554       }
1555 
1556       set_evacuation_in_progress(true);
1557       // From here on, we need to update references.
1558       set_has_forwarded_objects(true);
1559 
1560       if (!is_degenerated_gc_in_progress()) {
1561         if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
1562           ShenandoahCodeRoots::arm_nmethods();
1563         }
1564         evacuate_and_update_roots();
1565       }
1566 
1567       if (ShenandoahPacing) {
1568         pacer()-&gt;setup_for_evac();
1569       }
1570 
</pre>
<hr />
<pre>
1591         Universe::verify();
1592       }
1593     }
1594 
1595   } else {
1596     // If this cycle was updating references, we need to keep the has_forwarded_objects
1597     // flag on, for subsequent phases to deal with it.
1598     concurrent_mark()-&gt;cancel();
1599     set_concurrent_mark_in_progress(false);
1600 
1601     if (process_references()) {
1602       // Abandon reference processing right away: pre-cleaning must have failed.
1603       ReferenceProcessor *rp = ref_processor();
1604       rp-&gt;disable_discovery();
1605       rp-&gt;abandon_partial_discovery();
1606       rp-&gt;verify_no_references_recorded();
1607     }
1608   }
1609 }
1610 



















1611 void ShenandoahHeap::op_conc_evac() {
1612   ShenandoahEvacuationTask task(this, _collection_set, true);
1613   workers()-&gt;run_task(&amp;task);
1614 }
1615 
1616 void ShenandoahHeap::op_stw_evac() {
1617   ShenandoahEvacuationTask task(this, _collection_set, false);
1618   workers()-&gt;run_task(&amp;task);
1619 }
1620 
1621 void ShenandoahHeap::op_updaterefs() {
1622   update_heap_references(true);
1623 }
1624 
1625 void ShenandoahHeap::op_cleanup() {
1626   free_set()-&gt;recycle_trash();
1627 }
1628 
1629 class ShenandoahConcurrentRootsEvacUpdateTask : public AbstractGangTask {
1630 private:
</pre>
<hr />
<pre>
1785     }
1786   }
1787 
1788   set_concurrent_root_in_progress(false);
1789 }
1790 
1791 void ShenandoahHeap::op_reset() {
1792   if (ShenandoahPacing) {
1793     pacer()-&gt;setup_for_reset();
1794   }
1795   reset_mark_bitmap();
1796 }
1797 
1798 void ShenandoahHeap::op_preclean() {
1799   if (ShenandoahPacing) {
1800     pacer()-&gt;setup_for_preclean();
1801   }
1802   concurrent_mark()-&gt;preclean_weak_refs();
1803 }
1804 












1805 void ShenandoahHeap::op_full(GCCause::Cause cause) {
1806   ShenandoahMetricsSnapshot metrics;
1807   metrics.snap_before();
1808 
1809   full_gc()-&gt;do_it(cause);
1810   if (UseTLAB) {
<span class="line-modified">1811     ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::full_gc_resize_tlabs);</span>
1812     resize_all_tlabs();
1813   }
1814 
1815   metrics.snap_after();
1816 
1817   if (metrics.is_good_progress()) {
1818     _progress_last_gc.set();
1819   } else {
1820     // Nothing to do. Tell the allocation path that we have failed to make
1821     // progress, and it can finally fail.
1822     _progress_last_gc.unset();
1823   }
1824 }
1825 
1826 void ShenandoahHeap::op_degenerated(ShenandoahDegenPoint point) {
1827   // Degenerated GC is STW, but it can also fail. Current mechanics communicates
1828   // GC failure via cancelled_concgc() flag. So, if we detect the failure after
1829   // some phase, we have to upgrade the Degenerate GC to Full GC.
1830 
1831   clear_cancelled_gc();
1832 
1833   ShenandoahMetricsSnapshot metrics;
1834   metrics.snap_before();
1835 
1836   switch (point) {


















1837     // The cases below form the Duff&#39;s-like device: it describes the actual GC cycle,
1838     // but enters it at different points, depending on which concurrent phase had
1839     // degenerated.
1840 
1841     case _degenerated_outside_cycle:
1842       // We have degenerated from outside the cycle, which means something is bad with
1843       // the heap, most probably heavy humongous fragmentation, or we are very low on free
1844       // space. It makes little sense to wait for Full GC to reclaim as much as it can, when
1845       // we can do the most aggressive degen cycle, which includes processing references and
1846       // class unloading, unless those features are explicitly disabled.
1847       //
1848       // Note that we can only do this for &quot;outside-cycle&quot; degens, otherwise we would risk
1849       // changing the cycle parameters mid-cycle during concurrent -&gt; degenerated handover.
1850       set_process_references(heuristics()-&gt;can_process_references());
1851       set_unload_classes(heuristics()-&gt;can_unload_classes());
1852 







1853       op_reset();
1854 
1855       op_init_mark();
1856       if (cancelled_gc()) {
1857         op_degenerated_fail();
1858         return;
1859       }
1860 
1861     case _degenerated_mark:
1862       op_final_mark();
1863       if (cancelled_gc()) {
1864         op_degenerated_fail();
1865         return;
1866       }
1867 
<span class="line-added">1868       if (!has_forwarded_objects() &amp;&amp; ShenandoahConcurrentRoots::can_do_concurrent_class_unloading()) {</span>
<span class="line-added">1869         // Disarm nmethods that armed for concurrent mark. On normal cycle, it would</span>
<span class="line-added">1870         // be disarmed while conc-roots phase is running.</span>
<span class="line-added">1871         // TODO: Call op_conc_roots() here instead</span>
<span class="line-added">1872         ShenandoahCodeRoots::disarm_nmethods();</span>
<span class="line-added">1873       }</span>
<span class="line-added">1874 </span>
1875       op_cleanup();
1876 
1877     case _degenerated_evac:
1878       // If heuristics thinks we should do the cycle, this flag would be set,
1879       // and we can do evacuation. Otherwise, it would be the shortcut cycle.
1880       if (is_evacuation_in_progress()) {
1881 
1882         // Degeneration under oom-evac protocol might have left some objects in
1883         // collection set un-evacuated. Restart evacuation from the beginning to
1884         // capture all objects. For all the objects that are already evacuated,
1885         // it would be a simple check, which is supposed to be fast. This is also
1886         // safe to do even without degeneration, as CSet iterator is at beginning
1887         // in preparation for evacuation anyway.
1888         //
1889         // Before doing that, we need to make sure we never had any cset-pinned
1890         // regions. This may happen if allocation failure happened when evacuating
1891         // the about-to-be-pinned object, oom-evac protocol left the object in
1892         // the collection set, and then the pin reached the cset region. If we continue
1893         // the cycle here, we would trash the cset and alive objects in it. To avoid
1894         // it, we fail degeneration right away and slide into Full GC to recover.
</pre>
<hr />
<pre>
1958     _progress_last_gc.unset();
1959     cancel_gc(GCCause::_shenandoah_upgrade_to_full_gc);
1960     op_degenerated_futile();
1961   } else {
1962     _progress_last_gc.set();
1963   }
1964 }
1965 
1966 void ShenandoahHeap::op_degenerated_fail() {
1967   log_info(gc)(&quot;Cannot finish degeneration, upgrading to Full GC&quot;);
1968   shenandoah_policy()-&gt;record_degenerated_upgrade_to_full();
1969   op_full(GCCause::_shenandoah_upgrade_to_full_gc);
1970 }
1971 
1972 void ShenandoahHeap::op_degenerated_futile() {
1973   shenandoah_policy()-&gt;record_degenerated_upgrade_to_full();
1974   op_full(GCCause::_shenandoah_upgrade_to_full_gc);
1975 }
1976 
1977 void ShenandoahHeap::force_satb_flush_all_threads() {
<span class="line-modified">1978   if (!is_concurrent_mark_in_progress()) {</span>
1979     // No need to flush SATBs
1980     return;
1981   }
1982 
1983   for (JavaThreadIteratorWithHandle jtiwh; JavaThread *t = jtiwh.next(); ) {
1984     ShenandoahThreadLocalData::set_force_satb_flush(t, true);
1985   }
1986   // The threads are not &quot;acquiring&quot; their thread-local data, but it does not
1987   // hurt to &quot;release&quot; the updates here anyway.
1988   OrderAccess::fence();
1989 }
1990 
1991 void ShenandoahHeap::set_gc_state_all_threads(char state) {
1992   for (JavaThreadIteratorWithHandle jtiwh; JavaThread *t = jtiwh.next(); ) {
1993     ShenandoahThreadLocalData::set_gc_state(t, state);
1994   }
1995 }
1996 
1997 void ShenandoahHeap::set_gc_state_mask(uint mask, bool value) {
1998   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should really be Shenandoah safepoint&quot;);
1999   _gc_state.set_cond(mask, value);
2000   set_gc_state_all_threads(_gc_state.raw_value());
2001 }
2002 
2003 void ShenandoahHeap::set_concurrent_mark_in_progress(bool in_progress) {
2004   if (has_forwarded_objects()) {
2005     set_gc_state_mask(MARKING | UPDATEREFS, in_progress);
2006   } else {
2007     set_gc_state_mask(MARKING, in_progress);
2008   }
2009   ShenandoahBarrierSet::satb_mark_queue_set().set_active_all_threads(in_progress, !in_progress);
2010 }
2011 





2012 void ShenandoahHeap::set_evacuation_in_progress(bool in_progress) {
2013   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Only call this at safepoint&quot;);
2014   set_gc_state_mask(EVACUATION, in_progress);
2015 }
2016 
2017 void ShenandoahHeap::set_concurrent_root_in_progress(bool in_progress) {
2018   assert(ShenandoahConcurrentRoots::can_do_concurrent_roots(), &quot;Why set the flag?&quot;);
2019   if (in_progress) {
2020     _concurrent_root_in_progress.set();
2021   } else {
2022     _concurrent_root_in_progress.unset();
2023   }
2024 }
2025 
2026 void ShenandoahHeap::ref_processing_init() {
2027   assert(_max_workers &gt; 0, &quot;Sanity&quot;);
2028 
2029   _ref_processor =
2030     new ReferenceProcessor(&amp;_subject_to_discovery,  // is_subject_to_discovery
2031                            ParallelRefProcEnabled,  // MT processing
</pre>
<hr />
<pre>
2087   control_thread()-&gt;prepare_for_graceful_shutdown();
2088 
2089   // Step 2. Notify GC workers that we are cancelling GC.
2090   cancel_gc(GCCause::_shenandoah_stop_vm);
2091 
2092   // Step 3. Wait until GC worker exits normally.
2093   control_thread()-&gt;stop();
2094 
2095   // Step 4. Stop String Dedup thread if it is active
2096   if (ShenandoahStringDedup::is_enabled()) {
2097     ShenandoahStringDedup::stop();
2098   }
2099 }
2100 
2101 void ShenandoahHeap::stw_unload_classes(bool full_gc) {
2102   if (!unload_classes()) return;
2103   bool purged_class;
2104 
2105   // Unload classes and purge SystemDictionary.
2106   {
<span class="line-modified">2107     ShenandoahGCSubPhase phase(full_gc ?</span>
<span class="line-modified">2108                                ShenandoahPhaseTimings::full_gc_purge_class_unload :</span>
<span class="line-modified">2109                                ShenandoahPhaseTimings::purge_class_unload);</span>
2110     purged_class = SystemDictionary::do_unloading(gc_timer());
2111   }
2112 
2113   {
<span class="line-modified">2114     ShenandoahGCSubPhase phase(full_gc ?</span>
<span class="line-modified">2115                                ShenandoahPhaseTimings::full_gc_purge_par :</span>
<span class="line-modified">2116                                ShenandoahPhaseTimings::purge_par);</span>
2117     ShenandoahIsAliveSelector is_alive;
2118     uint num_workers = _workers-&gt;active_workers();
2119     ShenandoahClassUnloadingTask unlink_task(is_alive.is_alive_closure(), num_workers, purged_class);
2120     _workers-&gt;run_task(&amp;unlink_task);
2121   }
2122 
2123   {
<span class="line-modified">2124     ShenandoahGCSubPhase phase(full_gc ?</span>
<span class="line-modified">2125                                ShenandoahPhaseTimings::full_gc_purge_cldg :</span>
<span class="line-modified">2126                                ShenandoahPhaseTimings::purge_cldg);</span>
2127     ClassLoaderDataGraph::purge();
2128   }
2129   // Resize and verify metaspace
2130   MetaspaceGC::compute_new_size();
2131   MetaspaceUtils::verify_metrics();
2132 }
2133 
2134 // Weak roots are either pre-evacuated (final mark) or updated (final updaterefs),
2135 // so they should not have forwarded oops.
2136 // However, we do need to &quot;null&quot; dead oops in the roots, if can not be done
2137 // in concurrent cycles.
2138 void ShenandoahHeap::stw_process_weak_roots(bool full_gc) {
<span class="line-modified">2139   ShenandoahGCSubPhase root_phase(full_gc ?</span>
<span class="line-modified">2140                                   ShenandoahPhaseTimings::full_gc_purge :</span>
<span class="line-modified">2141                                   ShenandoahPhaseTimings::purge);</span>
2142   uint num_workers = _workers-&gt;active_workers();
2143   ShenandoahPhaseTimings::Phase timing_phase = full_gc ?
2144                                                ShenandoahPhaseTimings::full_gc_purge_par :
2145                                                ShenandoahPhaseTimings::purge_par;
<span class="line-added">2146   ShenandoahGCSubPhase phase(timing_phase);</span>
<span class="line-added">2147   ShenandoahGCWorkerPhase worker_phase(timing_phase);</span>
<span class="line-added">2148 </span>
2149   // Cleanup weak roots


2150   if (has_forwarded_objects()) {
<span class="line-modified">2151     ShenandoahForwardedIsAliveClosure is_alive;</span>
<span class="line-modified">2152     ShenandoahUpdateRefsClosure keep_alive;</span>
<span class="line-modified">2153     ShenandoahParallelWeakRootsCleaningTask&lt;ShenandoahForwardedIsAliveClosure, ShenandoahUpdateRefsClosure&gt;</span>
<span class="line-modified">2154       cleaning_task(&amp;is_alive, &amp;keep_alive, num_workers, !ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());</span>
<span class="line-modified">2155     _workers-&gt;run_task(&amp;cleaning_task);</span>








2156   } else {
2157     ShenandoahIsAliveClosure is_alive;
2158 #ifdef ASSERT
2159     ShenandoahAssertNotForwardedClosure verify_cl;
2160     ShenandoahParallelWeakRootsCleaningTask&lt;ShenandoahIsAliveClosure, ShenandoahAssertNotForwardedClosure&gt;
2161       cleaning_task(&amp;is_alive, &amp;verify_cl, num_workers, !ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());
2162 #else
2163     ShenandoahParallelWeakRootsCleaningTask&lt;ShenandoahIsAliveClosure, DoNothingClosure&gt;
2164       cleaning_task(&amp;is_alive, &amp;do_nothing_cl, num_workers, !ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());
2165 #endif
2166     _workers-&gt;run_task(&amp;cleaning_task);
2167   }

2168 }
2169 
2170 void ShenandoahHeap::parallel_cleaning(bool full_gc) {
2171   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2172   stw_process_weak_roots(full_gc);
2173   if (!ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2174     stw_unload_classes(full_gc);
2175   }
2176 }
2177 
2178 void ShenandoahHeap::set_has_forwarded_objects(bool cond) {
<span class="line-modified">2179   set_gc_state_mask(HAS_FORWARDED, cond);</span>





2180 }
2181 
2182 void ShenandoahHeap::set_process_references(bool pr) {
2183   _process_references.set_cond(pr);
2184 }
2185 
2186 void ShenandoahHeap::set_unload_classes(bool uc) {
2187   _unload_classes.set_cond(uc);
2188 }
2189 
2190 bool ShenandoahHeap::process_references() const {
2191   return _process_references.is_set();
2192 }
2193 
2194 bool ShenandoahHeap::unload_classes() const {
2195   return _unload_classes.is_set();
2196 }
2197 
2198 address ShenandoahHeap::in_cset_fast_test_addr() {
2199   ShenandoahHeap* heap = ShenandoahHeap::heap();
</pre>
<hr />
<pre>
2269         if (r-&gt;pin_count() &gt; 0) {
2270           r-&gt;make_pinned();
2271         }
2272       }
2273     }
2274   }
2275 
2276   assert_pinned_region_status();
2277 }
2278 
2279 #ifdef ASSERT
2280 void ShenandoahHeap::assert_pinned_region_status() {
2281   for (size_t i = 0; i &lt; num_regions(); i++) {
2282     ShenandoahHeapRegion* r = get_region(i);
2283     assert((r-&gt;is_pinned() &amp;&amp; r-&gt;pin_count() &gt; 0) || (!r-&gt;is_pinned() &amp;&amp; r-&gt;pin_count() == 0),
2284            &quot;Region &quot; SIZE_FORMAT &quot; pinning status is inconsistent&quot;, i);
2285   }
2286 }
2287 #endif
2288 
<span class="line-modified">2289 ConcurrentGCTimer* ShenandoahHeap::gc_timer() const {</span>
2290   return _gc_timer;
2291 }
2292 
2293 void ShenandoahHeap::prepare_concurrent_roots() {
2294   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2295   if (ShenandoahConcurrentRoots::should_do_concurrent_roots()) {
2296     set_concurrent_root_in_progress(true);
2297   }
2298 }
2299 
2300 void ShenandoahHeap::prepare_concurrent_unloading() {
2301   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2302   if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2303     _unloader.prepare();
2304   }
2305 }
2306 
2307 void ShenandoahHeap::finish_concurrent_unloading() {
2308   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2309   if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2310     _unloader.finish();
2311   }
2312 }
2313 
2314 #ifdef ASSERT
2315 void ShenandoahHeap::assert_gc_workers(uint nworkers) {
2316   assert(nworkers &gt; 0 &amp;&amp; nworkers &lt;= max_workers(), &quot;Sanity&quot;);
2317 
2318   if (ShenandoahSafepoint::is_at_shenandoah_safepoint()) {
<span class="line-modified">2319     if (UseDynamicNumberOfGCThreads) {</span>

2320       assert(nworkers &lt;= ParallelGCThreads, &quot;Cannot use more than it has&quot;);
2321     } else {
2322       // Use ParallelGCThreads inside safepoints
<span class="line-modified">2323       assert(nworkers == ParallelGCThreads, &quot;Use ParallelGCThreads within safepoints&quot;);</span>
2324     }
2325   } else {
<span class="line-modified">2326     if (UseDynamicNumberOfGCThreads) {</span>

2327       assert(nworkers &lt;= ConcGCThreads, &quot;Cannot use more than it has&quot;);
2328     } else {
2329       // Use ConcGCThreads outside safepoints
2330       assert(nworkers == ConcGCThreads, &quot;Use ConcGCThreads outside safepoints&quot;);
2331     }
2332   }
2333 }
2334 #endif
2335 
2336 ShenandoahVerifier* ShenandoahHeap::verifier() {
2337   guarantee(ShenandoahVerify, &quot;Should be enabled&quot;);
2338   assert (_verifier != NULL, &quot;sanity&quot;);
2339   return _verifier;
2340 }
2341 
2342 template&lt;class T&gt;
2343 class ShenandoahUpdateHeapRefsTask : public AbstractGangTask {
2344 private:
2345   T cl;
2346   ShenandoahHeap* _heap;
</pre>
<hr />
<pre>
2354     _regions(regions),
2355     _concurrent(concurrent) {
2356   }
2357 
2358   void work(uint worker_id) {
2359     if (_concurrent) {
2360       ShenandoahConcurrentWorkerSession worker_session(worker_id);
2361       ShenandoahSuspendibleThreadSetJoiner stsj(ShenandoahSuspendibleWorkers);
2362       do_work();
2363     } else {
2364       ShenandoahParallelWorkerSession worker_session(worker_id);
2365       do_work();
2366     }
2367   }
2368 
2369 private:
2370   void do_work() {
2371     ShenandoahHeapRegion* r = _regions-&gt;next();
2372     ShenandoahMarkingContext* const ctx = _heap-&gt;complete_marking_context();
2373     while (r != NULL) {
<span class="line-modified">2374       HeapWord* update_watermark = r-&gt;get_update_watermark();</span>
<span class="line-modified">2375       assert (update_watermark &gt;= r-&gt;bottom(), &quot;sanity&quot;);</span>
2376       if (r-&gt;is_active() &amp;&amp; !r-&gt;is_cset()) {
<span class="line-modified">2377         _heap-&gt;marked_object_oop_iterate(r, &amp;cl, update_watermark);</span>
2378       }
2379       if (ShenandoahPacing) {
<span class="line-modified">2380         _heap-&gt;pacer()-&gt;report_updaterefs(pointer_delta(update_watermark, r-&gt;bottom()));</span>
2381       }
2382       if (_heap-&gt;check_cancelled_gc_and_yield(_concurrent)) {
2383         return;
2384       }
2385       r = _regions-&gt;next();
2386     }
2387   }
2388 };
2389 
2390 void ShenandoahHeap::update_heap_references(bool concurrent) {
2391   ShenandoahUpdateHeapRefsTask&lt;ShenandoahUpdateHeapRefsClosure&gt; task(&amp;_update_refs_iterator, concurrent);
2392   workers()-&gt;run_task(&amp;task);
2393 }
2394 
2395 void ShenandoahHeap::op_init_updaterefs() {
2396   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;must be at safepoint&quot;);
2397 
2398   set_evacuation_in_progress(false);
2399 
2400   {
<span class="line-modified">2401     ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::init_update_refs_retire_gclabs);</span>
2402     retire_and_reset_gclabs();
2403   }
2404 
2405   if (ShenandoahVerify) {
2406     if (!is_degenerated_gc_in_progress()) {
2407       verifier()-&gt;verify_roots_in_to_space_except(ShenandoahRootVerifier::ThreadRoots);
2408     }
2409     verifier()-&gt;verify_before_updaterefs();
2410   }
2411 
2412   set_update_refs_in_progress(true);
2413 
2414   {
<span class="line-modified">2415     ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::init_update_refs_prepare);</span>
2416 
2417     make_parsable(true);




2418 
2419     // Reset iterator.
2420     _update_refs_iterator.reset();
2421   }
2422 
2423   if (ShenandoahPacing) {
2424     pacer()-&gt;setup_for_updaterefs();
2425   }
2426 }
2427 
<span class="line-added">2428 class ShenandoahFinalUpdateRefsUpdateRegionStateClosure : public ShenandoahHeapRegionClosure {</span>
<span class="line-added">2429 private:</span>
<span class="line-added">2430   ShenandoahHeapLock* const _lock;</span>
<span class="line-added">2431 </span>
<span class="line-added">2432 public:</span>
<span class="line-added">2433   ShenandoahFinalUpdateRefsUpdateRegionStateClosure() : _lock(ShenandoahHeap::heap()-&gt;lock()) {}</span>
<span class="line-added">2434 </span>
<span class="line-added">2435   void heap_region_do(ShenandoahHeapRegion* r) {</span>
<span class="line-added">2436     // Drop unnecessary &quot;pinned&quot; state from regions that does not have CP marks</span>
<span class="line-added">2437     // anymore, as this would allow trashing them.</span>
<span class="line-added">2438 </span>
<span class="line-added">2439     if (r-&gt;is_active()) {</span>
<span class="line-added">2440       if (r-&gt;is_pinned()) {</span>
<span class="line-added">2441         if (r-&gt;pin_count() == 0) {</span>
<span class="line-added">2442           ShenandoahHeapLocker locker(_lock);</span>
<span class="line-added">2443           r-&gt;make_unpinned();</span>
<span class="line-added">2444         }</span>
<span class="line-added">2445       } else {</span>
<span class="line-added">2446         if (r-&gt;pin_count() &gt; 0) {</span>
<span class="line-added">2447           ShenandoahHeapLocker locker(_lock);</span>
<span class="line-added">2448           r-&gt;make_pinned();</span>
<span class="line-added">2449         }</span>
<span class="line-added">2450       }</span>
<span class="line-added">2451     }</span>
<span class="line-added">2452   }</span>
<span class="line-added">2453 </span>
<span class="line-added">2454   bool is_thread_safe() { return true; }</span>
<span class="line-added">2455 };</span>
<span class="line-added">2456 </span>
2457 void ShenandoahHeap::op_final_updaterefs() {
2458   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;must be at safepoint&quot;);
2459 
2460   finish_concurrent_unloading();
2461 
2462   // Check if there is left-over work, and finish it
2463   if (_update_refs_iterator.has_next()) {
<span class="line-modified">2464     ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::final_update_refs_finish_work);</span>
2465 
2466     // Finish updating references where we left off.
2467     clear_cancelled_gc();
2468     update_heap_references(false);
2469   }
2470 
2471   // Clear cancelled GC, if set. On cancellation path, the block before would handle
2472   // everything. On degenerated paths, cancelled gc would not be set anyway.
2473   if (cancelled_gc()) {
2474     clear_cancelled_gc();
2475   }
2476   assert(!cancelled_gc(), &quot;Should have been done right before&quot;);
2477 
2478   if (ShenandoahVerify &amp;&amp; !is_degenerated_gc_in_progress()) {
2479     verifier()-&gt;verify_roots_in_to_space_except(ShenandoahRootVerifier::ThreadRoots);
2480   }
2481 
2482   if (is_degenerated_gc_in_progress()) {
2483     concurrent_mark()-&gt;update_roots(ShenandoahPhaseTimings::degen_gc_update_roots);
2484   } else {
2485     concurrent_mark()-&gt;update_thread_roots(ShenandoahPhaseTimings::final_update_refs_roots);
2486   }
2487 
2488   // Has to be done before cset is clear
2489   if (ShenandoahVerify) {
2490     verifier()-&gt;verify_roots_in_to_space();
2491   }
2492 


2493   {
<span class="line-modified">2494     ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::final_update_refs_update_region_states);</span>
<span class="line-modified">2495     ShenandoahFinalUpdateRefsUpdateRegionStateClosure cl;</span>
<span class="line-added">2496     parallel_heap_region_iterate(&amp;cl);</span>
<span class="line-added">2497 </span>
<span class="line-added">2498     assert_pinned_region_status();</span>
2499   }
2500 
2501   {
<span class="line-modified">2502     ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::final_update_refs_trash_cset);</span>
2503     trash_cset_regions();
2504   }
2505 
2506   set_has_forwarded_objects(false);
2507   set_update_refs_in_progress(false);
2508 
2509   if (ShenandoahVerify) {
2510     verifier()-&gt;verify_after_updaterefs();
2511   }
2512 
2513   if (VerifyAfterGC) {
2514     Universe::verify();
2515   }
2516 
2517   {
<span class="line-added">2518     ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::final_update_refs_rebuild_freeset);</span>
2519     ShenandoahHeapLocker locker(lock());
2520     _free_set-&gt;rebuild();
2521   }
2522 }
2523 














2524 void ShenandoahHeap::print_extended_on(outputStream *st) const {
2525   print_on(st);
2526   print_heap_regions_on(st);
2527 }
2528 
2529 bool ShenandoahHeap::is_bitmap_slice_committed(ShenandoahHeapRegion* r, bool skip_self) {
<span class="line-modified">2530   size_t slice = r-&gt;index() / _bitmap_regions_per_slice;</span>
2531 
2532   size_t regions_from = _bitmap_regions_per_slice * slice;
2533   size_t regions_to   = MIN2(num_regions(), _bitmap_regions_per_slice * (slice + 1));
2534   for (size_t g = regions_from; g &lt; regions_to; g++) {
2535     assert (g / _bitmap_regions_per_slice == slice, &quot;same slice&quot;);
<span class="line-modified">2536     if (skip_self &amp;&amp; g == r-&gt;index()) continue;</span>
2537     if (get_region(g)-&gt;is_committed()) {
2538       return true;
2539     }
2540   }
2541   return false;
2542 }
2543 
2544 bool ShenandoahHeap::commit_bitmap_slice(ShenandoahHeapRegion* r) {
<span class="line-modified">2545   shenandoah_assert_heaplocked();</span>
2546 
2547   // Bitmaps in special regions do not need commits
2548   if (_bitmap_region_special) {
2549     return true;
2550   }
2551 
2552   if (is_bitmap_slice_committed(r, true)) {
2553     // Some other region from the group is already committed, meaning the bitmap
2554     // slice is already committed, we exit right away.
2555     return true;
2556   }
2557 
2558   // Commit the bitmap slice:
<span class="line-modified">2559   size_t slice = r-&gt;index() / _bitmap_regions_per_slice;</span>
2560   size_t off = _bitmap_bytes_per_slice * slice;
2561   size_t len = _bitmap_bytes_per_slice;
2562   if (!os::commit_memory((char*)_bitmap_region.start() + off, len, false)) {
2563     return false;
2564   }
2565   return true;
2566 }
2567 
2568 bool ShenandoahHeap::uncommit_bitmap_slice(ShenandoahHeapRegion *r) {
<span class="line-modified">2569   shenandoah_assert_heaplocked();</span>
2570 
2571   // Bitmaps in special regions do not need uncommits
2572   if (_bitmap_region_special) {
2573     return true;
2574   }
2575 
2576   if (is_bitmap_slice_committed(r, true)) {
2577     // Some other region from the group is still committed, meaning the bitmap
2578     // slice is should stay committed, exit right away.
2579     return true;
2580   }
2581 
2582   // Uncommit the bitmap slice:
<span class="line-modified">2583   size_t slice = r-&gt;index() / _bitmap_regions_per_slice;</span>
2584   size_t off = _bitmap_bytes_per_slice * slice;
2585   size_t len = _bitmap_bytes_per_slice;
2586   if (!os::uncommit_memory((char*)_bitmap_region.start() + off, len)) {
2587     return false;
2588   }
2589   return true;
2590 }
2591 
2592 void ShenandoahHeap::safepoint_synchronize_begin() {
2593   if (ShenandoahSuspendibleWorkers || UseStringDeduplication) {
2594     SuspendibleThreadSet::synchronize();
2595   }
2596 }
2597 
2598 void ShenandoahHeap::safepoint_synchronize_end() {
2599   if (ShenandoahSuspendibleWorkers || UseStringDeduplication) {
2600     SuspendibleThreadSet::desynchronize();
2601   }
2602 }
2603 
2604 void ShenandoahHeap::vmop_entry_init_mark() {
2605   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2606   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2607   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_mark_gross);
2608 
2609   try_inject_alloc_failure();
2610   VM_ShenandoahInitMark op;
2611   VMThread::execute(&amp;op); // jump to entry_init_mark() under safepoint
2612 }
2613 
2614 void ShenandoahHeap::vmop_entry_final_mark() {
2615   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2616   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2617   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_mark_gross);
2618 
2619   try_inject_alloc_failure();
2620   VM_ShenandoahFinalMarkStartEvac op;
2621   VMThread::execute(&amp;op); // jump to entry_final_mark under safepoint
2622 }
2623 









2624 void ShenandoahHeap::vmop_entry_init_updaterefs() {
2625   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2626   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2627   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_refs_gross);
2628 
2629   try_inject_alloc_failure();
2630   VM_ShenandoahInitUpdateRefs op;
2631   VMThread::execute(&amp;op);
2632 }
2633 
2634 void ShenandoahHeap::vmop_entry_final_updaterefs() {
2635   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2636   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2637   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs_gross);
2638 
2639   try_inject_alloc_failure();
2640   VM_ShenandoahFinalUpdateRefs op;
2641   VMThread::execute(&amp;op);
2642 }
2643 




















2644 void ShenandoahHeap::vmop_entry_full(GCCause::Cause cause) {
2645   TraceCollectorStats tcs(monitoring_support()-&gt;full_stw_collection_counters());
2646   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2647   ShenandoahGCPhase phase(ShenandoahPhaseTimings::full_gc_gross);
2648 
2649   try_inject_alloc_failure();
2650   VM_ShenandoahFullGC op(cause);
2651   VMThread::execute(&amp;op);
2652 }
2653 
2654 void ShenandoahHeap::vmop_degenerated(ShenandoahDegenPoint point) {
2655   TraceCollectorStats tcs(monitoring_support()-&gt;full_stw_collection_counters());
2656   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2657   ShenandoahGCPhase phase(ShenandoahPhaseTimings::degen_gc_gross);
2658 
2659   VM_ShenandoahDegeneratedGC degenerated_gc((int)point);
2660   VMThread::execute(&amp;degenerated_gc);
2661 }
2662 
2663 void ShenandoahHeap::entry_init_mark() {


2664   const char* msg = init_mark_event_message();
<span class="line-modified">2665   ShenandoahPausePhase gc_phase(msg);</span>
2666   EventMark em(&quot;%s&quot;, msg);
2667 
<span class="line-added">2668   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);</span>
<span class="line-added">2669   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_mark);</span>
<span class="line-added">2670 </span>
2671   ShenandoahWorkerScope scope(workers(),
2672                               ShenandoahWorkerPolicy::calc_workers_for_init_marking(),
2673                               &quot;init marking&quot;);
2674 
2675   op_init_mark();
2676 }
2677 
2678 void ShenandoahHeap::entry_final_mark() {


2679   const char* msg = final_mark_event_message();
<span class="line-modified">2680   ShenandoahPausePhase gc_phase(msg);</span>
2681   EventMark em(&quot;%s&quot;, msg);
2682 
<span class="line-added">2683   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);</span>
<span class="line-added">2684   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_mark);</span>
<span class="line-added">2685 </span>
2686   ShenandoahWorkerScope scope(workers(),
2687                               ShenandoahWorkerPolicy::calc_workers_for_final_marking(),
2688                               &quot;final marking&quot;);
2689 
2690   op_final_mark();
2691 }
2692 
<span class="line-modified">2693 void ShenandoahHeap::entry_init_updaterefs() {</span>
<span class="line-modified">2694   static const char* msg = &quot;Pause Init Update Refs&quot;;</span>
<span class="line-modified">2695   ShenandoahPausePhase gc_phase(msg);</span>


2696   EventMark em(&quot;%s&quot;, msg);
2697 




2698   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2699   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_refs);
2700 




2701   // No workers used in this phase, no setup required
2702 
2703   op_init_updaterefs();
2704 }
2705 
2706 void ShenandoahHeap::entry_final_updaterefs() {



2707   static const char* msg = &quot;Pause Final Update Refs&quot;;
<span class="line-modified">2708   ShenandoahPausePhase gc_phase(msg);</span>
2709   EventMark em(&quot;%s&quot;, msg);
2710 
<span class="line-added">2711   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);</span>
<span class="line-added">2712   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs);</span>
<span class="line-added">2713 </span>
2714   ShenandoahWorkerScope scope(workers(),
2715                               ShenandoahWorkerPolicy::calc_workers_for_final_update_ref(),
2716                               &quot;final reference update&quot;);
2717 
2718   op_final_updaterefs();
2719 }
2720 
<span class="line-modified">2721 void ShenandoahHeap::entry_full(GCCause::Cause cause) {</span>
<span class="line-modified">2722   static const char* msg = &quot;Pause Full&quot;;</span>
<span class="line-modified">2723   ShenandoahPausePhase gc_phase(msg);</span>


















2724   EventMark em(&quot;%s&quot;, msg);
2725 








2726   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2727   ShenandoahGCPhase phase(ShenandoahPhaseTimings::full_gc);
2728 




2729   ShenandoahWorkerScope scope(workers(),
2730                               ShenandoahWorkerPolicy::calc_workers_for_fullgc(),
2731                               &quot;full gc&quot;);
2732 
2733   op_full(cause);
2734 }
2735 
2736 void ShenandoahHeap::entry_degenerated(int point) {



2737   ShenandoahDegenPoint dpoint = (ShenandoahDegenPoint)point;
2738   const char* msg = degen_event_message(dpoint);
<span class="line-modified">2739   ShenandoahPausePhase gc_phase(msg);</span>
2740   EventMark em(&quot;%s&quot;, msg);
2741 
<span class="line-added">2742   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);</span>
<span class="line-added">2743   ShenandoahGCPhase phase(ShenandoahPhaseTimings::degen_gc);</span>
<span class="line-added">2744 </span>
2745   ShenandoahWorkerScope scope(workers(),
2746                               ShenandoahWorkerPolicy::calc_workers_for_stw_degenerated(),
2747                               &quot;stw degenerated gc&quot;);
2748 
2749   set_degenerated_gc_in_progress(true);
2750   op_degenerated(dpoint);
2751   set_degenerated_gc_in_progress(false);
2752 }
2753 
2754 void ShenandoahHeap::entry_mark() {
2755   TraceCollectorStats tcs(monitoring_support()-&gt;concurrent_collection_counters());
2756 
2757   const char* msg = conc_mark_event_message();
<span class="line-modified">2758   ShenandoahConcurrentPhase gc_phase(msg);</span>
2759   EventMark em(&quot;%s&quot;, msg);
2760 
<span class="line-added">2761   ShenandoahGCPhase conc_mark_phase(ShenandoahPhaseTimings::conc_mark);</span>
<span class="line-added">2762 </span>
2763   ShenandoahWorkerScope scope(workers(),
2764                               ShenandoahWorkerPolicy::calc_workers_for_conc_marking(),
2765                               &quot;concurrent marking&quot;);
2766 
2767   try_inject_alloc_failure();
2768   op_mark();
2769 }
2770 
2771 void ShenandoahHeap::entry_evac() {

2772   TraceCollectorStats tcs(monitoring_support()-&gt;concurrent_collection_counters());
2773 
2774   static const char* msg = &quot;Concurrent evacuation&quot;;
<span class="line-modified">2775   ShenandoahConcurrentPhase gc_phase(msg);</span>
2776   EventMark em(&quot;%s&quot;, msg);
2777 
<span class="line-added">2778   ShenandoahGCPhase conc_evac_phase(ShenandoahPhaseTimings::conc_evac);</span>
<span class="line-added">2779 </span>
2780   ShenandoahWorkerScope scope(workers(),
2781                               ShenandoahWorkerPolicy::calc_workers_for_conc_evac(),
2782                               &quot;concurrent evacuation&quot;);
2783 
2784   try_inject_alloc_failure();
2785   op_conc_evac();
2786 }
2787 
2788 void ShenandoahHeap::entry_updaterefs() {


2789   static const char* msg = &quot;Concurrent update references&quot;;
<span class="line-modified">2790   ShenandoahConcurrentPhase gc_phase(msg);</span>
2791   EventMark em(&quot;%s&quot;, msg);
2792 
<span class="line-added">2793   ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_update_refs);</span>
<span class="line-added">2794 </span>
2795   ShenandoahWorkerScope scope(workers(),
2796                               ShenandoahWorkerPolicy::calc_workers_for_conc_update_ref(),
2797                               &quot;concurrent reference update&quot;);
2798 
2799   try_inject_alloc_failure();
2800   op_updaterefs();
2801 }
2802 
2803 void ShenandoahHeap::entry_roots() {


2804   static const char* msg = &quot;Concurrent roots processing&quot;;
<span class="line-modified">2805   ShenandoahConcurrentPhase gc_phase(msg);</span>
2806   EventMark em(&quot;%s&quot;, msg);
2807 
<span class="line-added">2808   ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_roots);</span>
<span class="line-added">2809 </span>
2810   ShenandoahWorkerScope scope(workers(),
2811                               ShenandoahWorkerPolicy::calc_workers_for_conc_root_processing(),
2812                               &quot;concurrent root processing&quot;);
2813 
2814   try_inject_alloc_failure();
2815   op_roots();
2816 }
2817 
2818 void ShenandoahHeap::entry_cleanup() {


2819   static const char* msg = &quot;Concurrent cleanup&quot;;
<span class="line-modified">2820   ShenandoahConcurrentPhase gc_phase(msg,  true /* log_heap_usage */);</span>
2821   EventMark em(&quot;%s&quot;, msg);
2822 
<span class="line-added">2823   ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::conc_cleanup);</span>
<span class="line-added">2824 </span>
2825   // This phase does not use workers, no need for setup
2826 
2827   try_inject_alloc_failure();
2828   op_cleanup();
2829 }
2830 
2831 void ShenandoahHeap::entry_reset() {


2832   static const char* msg = &quot;Concurrent reset&quot;;
<span class="line-modified">2833   ShenandoahConcurrentPhase gc_phase(msg);</span>
2834   EventMark em(&quot;%s&quot;, msg);
2835 
<span class="line-added">2836   ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::conc_reset);</span>
<span class="line-added">2837 </span>
2838   ShenandoahWorkerScope scope(workers(),
2839                               ShenandoahWorkerPolicy::calc_workers_for_conc_reset(),
2840                               &quot;concurrent reset&quot;);
2841 
2842   try_inject_alloc_failure();
2843   op_reset();
2844 }
2845 
2846 void ShenandoahHeap::entry_preclean() {
2847   if (ShenandoahPreclean &amp;&amp; process_references()) {
2848     static const char* msg = &quot;Concurrent precleaning&quot;;
<span class="line-modified">2849     ShenandoahConcurrentPhase gc_phase(msg);</span>
2850     EventMark em(&quot;%s&quot;, msg);
2851 
<span class="line-modified">2852     ShenandoahGCSubPhase conc_preclean(ShenandoahPhaseTimings::conc_preclean);</span>
2853 
2854     ShenandoahWorkerScope scope(workers(),
2855                                 ShenandoahWorkerPolicy::calc_workers_for_conc_preclean(),
2856                                 &quot;concurrent preclean&quot;,
2857                                 /* check_workers = */ false);
2858 
2859     try_inject_alloc_failure();
2860     op_preclean();
2861   }
2862 }
2863 















2864 void ShenandoahHeap::entry_uncommit(double shrink_before) {
2865   static const char *msg = &quot;Concurrent uncommit&quot;;
<span class="line-modified">2866   ShenandoahConcurrentPhase gc_phase(msg);</span>
2867   EventMark em(&quot;%s&quot;, msg);
2868 
<span class="line-modified">2869   ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::conc_uncommit);</span>
2870 
2871   op_uncommit(shrink_before);
2872 }
2873 
2874 void ShenandoahHeap::try_inject_alloc_failure() {
2875   if (ShenandoahAllocFailureALot &amp;&amp; !cancelled_gc() &amp;&amp; ((os::random() % 1000) &gt; 950)) {
2876     _inject_alloc_failure.set();
2877     os::naked_short_sleep(1);
2878     if (cancelled_gc()) {
2879       log_info(gc)(&quot;Allocation failure was successfully injected&quot;);
2880     }
2881   }
2882 }
2883 
2884 bool ShenandoahHeap::should_inject_alloc_failure() {
2885   return _inject_alloc_failure.is_set() &amp;&amp; _inject_alloc_failure.try_unset();
2886 }
2887 
2888 void ShenandoahHeap::initialize_serviceability() {
2889   _memory_pool = new ShenandoahMemoryPool(this);
</pre>
<hr />
<pre>
2928   _index = 0;
2929 }
2930 
2931 bool ShenandoahRegionIterator::has_next() const {
2932   return _index &lt; _heap-&gt;num_regions();
2933 }
2934 
2935 char ShenandoahHeap::gc_state() const {
2936   return _gc_state.raw_value();
2937 }
2938 
2939 void ShenandoahHeap::deduplicate_string(oop str) {
2940   assert(java_lang_String::is_instance(str), &quot;invariant&quot;);
2941 
2942   if (ShenandoahStringDedup::is_enabled()) {
2943     ShenandoahStringDedup::deduplicate(str);
2944   }
2945 }
2946 
2947 const char* ShenandoahHeap::init_mark_event_message() const {
<span class="line-modified">2948   assert(!has_forwarded_objects(), &quot;Should not have forwarded objects here&quot;);</span>
<span class="line-added">2949 </span>
2950   bool proc_refs = process_references();
2951   bool unload_cls = unload_classes();
2952 
<span class="line-modified">2953   if (proc_refs &amp;&amp; unload_cls) {</span>






2954     return &quot;Pause Init Mark (process weakrefs) (unload classes)&quot;;


2955   } else if (proc_refs) {
2956     return &quot;Pause Init Mark (process weakrefs)&quot;;
2957   } else if (unload_cls) {
2958     return &quot;Pause Init Mark (unload classes)&quot;;
2959   } else {
2960     return &quot;Pause Init Mark&quot;;
2961   }
2962 }
2963 
2964 const char* ShenandoahHeap::final_mark_event_message() const {
<span class="line-modified">2965   assert(!has_forwarded_objects(), &quot;Should not have forwarded objects here&quot;);</span>
<span class="line-added">2966 </span>
2967   bool proc_refs = process_references();
2968   bool unload_cls = unload_classes();
2969 
<span class="line-modified">2970   if (proc_refs &amp;&amp; unload_cls) {</span>






2971     return &quot;Pause Final Mark (process weakrefs) (unload classes)&quot;;


2972   } else if (proc_refs) {
2973     return &quot;Pause Final Mark (process weakrefs)&quot;;
2974   } else if (unload_cls) {
2975     return &quot;Pause Final Mark (unload classes)&quot;;
2976   } else {
2977     return &quot;Pause Final Mark&quot;;
2978   }
2979 }
2980 
2981 const char* ShenandoahHeap::conc_mark_event_message() const {
<span class="line-modified">2982   assert(!has_forwarded_objects(), &quot;Should not have forwarded objects here&quot;);</span>
<span class="line-added">2983 </span>
2984   bool proc_refs = process_references();
2985   bool unload_cls = unload_classes();
2986 
<span class="line-modified">2987   if (proc_refs &amp;&amp; unload_cls) {</span>






2988     return &quot;Concurrent marking (process weakrefs) (unload classes)&quot;;


2989   } else if (proc_refs) {
2990     return &quot;Concurrent marking (process weakrefs)&quot;;
2991   } else if (unload_cls) {
2992     return &quot;Concurrent marking (unload classes)&quot;;
2993   } else {
2994     return &quot;Concurrent marking&quot;;
2995   }
2996 }
2997 













































2998 const char* ShenandoahHeap::degen_event_message(ShenandoahDegenPoint point) const {
2999   switch (point) {
3000     case _degenerated_unset:
3001       return &quot;Pause Degenerated GC (&lt;UNSET&gt;)&quot;;


3002     case _degenerated_outside_cycle:
3003       return &quot;Pause Degenerated GC (Outside of Cycle)&quot;;
3004     case _degenerated_mark:
3005       return &quot;Pause Degenerated GC (Mark)&quot;;
3006     case _degenerated_evac:
3007       return &quot;Pause Degenerated GC (Evacuation)&quot;;
3008     case _degenerated_updaterefs:
3009       return &quot;Pause Degenerated GC (Update Refs)&quot;;
3010     default:
3011       ShouldNotReachHere();
3012       return &quot;ERROR&quot;;
3013   }
3014 }
3015 
<span class="line-modified">3016 ShenandoahLiveData* ShenandoahHeap::get_liveness_cache(uint worker_id) {</span>
3017 #ifdef ASSERT
3018   assert(_liveness_cache != NULL, &quot;sanity&quot;);
3019   assert(worker_id &lt; _max_workers, &quot;sanity&quot;);
3020   for (uint i = 0; i &lt; num_regions(); i++) {
3021     assert(_liveness_cache[worker_id][i] == 0, &quot;liveness cache should be empty&quot;);
3022   }
3023 #endif
3024   return _liveness_cache[worker_id];
3025 }
3026 
3027 void ShenandoahHeap::flush_liveness_cache(uint worker_id) {
3028   assert(worker_id &lt; _max_workers, &quot;sanity&quot;);
3029   assert(_liveness_cache != NULL, &quot;sanity&quot;);
<span class="line-modified">3030   ShenandoahLiveData* ld = _liveness_cache[worker_id];</span>
3031   for (uint i = 0; i &lt; num_regions(); i++) {
<span class="line-modified">3032     ShenandoahLiveData live = ld[i];</span>

3033     if (live &gt; 0) {
<span class="line-added">3034       ShenandoahHeapRegion* r = get_region(i);</span>
3035       r-&gt;increase_live_data_gc_words(live);
3036       ld[i] = 0;
3037     }
3038   }
3039 }
</pre>
</td>
</tr>
</table>
<center><a href="shenandoahFreeSet.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahHeap.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>