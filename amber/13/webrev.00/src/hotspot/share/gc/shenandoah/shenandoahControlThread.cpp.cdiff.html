<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff src/hotspot/share/gc/shenandoah/shenandoahControlThread.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="shenandoahConcurrentRoots.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahControlThread.hpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shenandoah/shenandoahControlThread.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 30,11 ***</span>
  #include &quot;gc/shenandoah/shenandoahPhaseTimings.hpp&quot;
  #include &quot;gc/shenandoah/shenandoahHeap.inline.hpp&quot;
  #include &quot;gc/shenandoah/shenandoahHeuristics.hpp&quot;
  #include &quot;gc/shenandoah/shenandoahMonitoringSupport.hpp&quot;
  #include &quot;gc/shenandoah/shenandoahControlThread.hpp&quot;
<span class="line-removed">- #include &quot;gc/shenandoah/shenandoahTraversalGC.hpp&quot;</span>
  #include &quot;gc/shenandoah/shenandoahUtils.hpp&quot;
  #include &quot;gc/shenandoah/shenandoahVMOperations.hpp&quot;
  #include &quot;gc/shenandoah/shenandoahWorkerPolicy.hpp&quot;
  #include &quot;memory/iterator.hpp&quot;
  #include &quot;memory/universe.hpp&quot;
<span class="line-new-header">--- 30,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 68,14 ***</span>
  }
  
  void ShenandoahControlThread::run_service() {
    ShenandoahHeap* heap = ShenandoahHeap::heap();
  
<span class="line-modified">!   GCMode default_mode = heap-&gt;is_traversal_mode() ?</span>
<span class="line-modified">!                            concurrent_traversal : concurrent_normal;</span>
<span class="line-removed">-   GCCause::Cause default_cause = heap-&gt;is_traversal_mode() ?</span>
<span class="line-removed">-                            GCCause::_shenandoah_traversal_gc : GCCause::_shenandoah_concurrent_gc;</span>
    int sleep = ShenandoahControlIntervalMin;
  
    double last_shrink_time = os::elapsedTime();
    double last_sleep_adjust_time = os::elapsedTime();
  
<span class="line-new-header">--- 67,12 ---</span>
  }
  
  void ShenandoahControlThread::run_service() {
    ShenandoahHeap* heap = ShenandoahHeap::heap();
  
<span class="line-modified">!   GCMode default_mode = concurrent_normal;</span>
<span class="line-modified">!   GCCause::Cause default_cause = GCCause::_shenandoah_concurrent_gc;</span>
    int sleep = ShenandoahControlIntervalMin;
  
    double last_shrink_time = os::elapsedTime();
    double last_sleep_adjust_time = os::elapsedTime();
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 176,41 ***</span>
      assert (!gc_requested || cause != GCCause::_last_gc_cause, &quot;GC cause should be set&quot;);
  
      if (gc_requested) {
        heap-&gt;reset_bytes_allocated_since_gc_start();
  
        // If GC was requested, we are sampling the counters even without actual triggers
        // from allocation machinery. This captures GC phases more accurately.
        set_forced_counters_update(true);
  
        // If GC was requested, we better dump freeset data for performance debugging
        {
          ShenandoahHeapLocker locker(heap-&gt;lock());
          heap-&gt;free_set()-&gt;log_status();
        }
<span class="line-removed">-     }</span>
  
<span class="line-modified">!     switch (mode) {</span>
<span class="line-modified">!       case none:</span>
<span class="line-modified">!         break;</span>
<span class="line-modified">!       case concurrent_traversal:</span>
<span class="line-modified">!         service_concurrent_traversal_cycle(cause);</span>
<span class="line-modified">!         break;</span>
<span class="line-modified">!       case concurrent_normal:</span>
<span class="line-modified">!         service_concurrent_normal_cycle(cause);</span>
<span class="line-modified">!         break;</span>
<span class="line-modified">!       case stw_degenerated:</span>
<span class="line-modified">!         service_stw_degenerated_cycle(cause, degen_point);</span>
<span class="line-modified">!         break;</span>
<span class="line-modified">!       case stw_full:</span>
<span class="line-removed">-         service_stw_full_cycle(cause);</span>
<span class="line-removed">-         break;</span>
<span class="line-removed">-       default:</span>
<span class="line-removed">-         ShouldNotReachHere();</span>
<span class="line-removed">-     }</span>
  
<span class="line-removed">-     if (gc_requested) {</span>
        // If this was the requested GC cycle, notify waiters about it
        if (explicit_gc_requested || implicit_gc_requested) {
          notify_gc_waiters();
        }
  
<span class="line-new-header">--- 173,37 ---</span>
      assert (!gc_requested || cause != GCCause::_last_gc_cause, &quot;GC cause should be set&quot;);
  
      if (gc_requested) {
        heap-&gt;reset_bytes_allocated_since_gc_start();
  
<span class="line-added">+       // Use default constructor to snapshot the Metaspace state before GC.</span>
<span class="line-added">+       metaspace::MetaspaceSizesSnapshot meta_sizes;</span>
<span class="line-added">+ </span>
        // If GC was requested, we are sampling the counters even without actual triggers
        // from allocation machinery. This captures GC phases more accurately.
        set_forced_counters_update(true);
  
        // If GC was requested, we better dump freeset data for performance debugging
        {
          ShenandoahHeapLocker locker(heap-&gt;lock());
          heap-&gt;free_set()-&gt;log_status();
        }
  
<span class="line-modified">!       switch (mode) {</span>
<span class="line-modified">!         case concurrent_normal:</span>
<span class="line-modified">!           service_concurrent_normal_cycle(cause);</span>
<span class="line-modified">!           break;</span>
<span class="line-modified">!         case stw_degenerated:</span>
<span class="line-modified">!           service_stw_degenerated_cycle(cause, degen_point);</span>
<span class="line-modified">!           break;</span>
<span class="line-modified">!         case stw_full:</span>
<span class="line-modified">!           service_stw_full_cycle(cause);</span>
<span class="line-modified">!           break;</span>
<span class="line-modified">!         default:</span>
<span class="line-modified">!           ShouldNotReachHere();</span>
<span class="line-modified">!       }</span>
  
        // If this was the requested GC cycle, notify waiters about it
        if (explicit_gc_requested || implicit_gc_requested) {
          notify_gc_waiters();
        }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 242,10 ***</span>
<span class="line-new-header">--- 235,13 ---</span>
        // Clear metaspace oom flag, if current cycle unloaded classes
        if (heap-&gt;unload_classes()) {
          heuristics-&gt;clear_metaspace_oom();
        }
  
<span class="line-added">+       // Print Metaspace change following GC (if logging is enabled).</span>
<span class="line-added">+       MetaspaceUtils::print_metaspace_change(meta_sizes);</span>
<span class="line-added">+ </span>
        // GC is over, we are at idle now
        if (ShenandoahPacing) {
          heap-&gt;pacer()-&gt;setup_for_idle();
        }
      } else {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 283,54 ***</span>
    while (!should_terminate()) {
      os::naked_short_sleep(ShenandoahControlIntervalMin);
    }
  }
  
<span class="line-removed">- void ShenandoahControlThread::service_concurrent_traversal_cycle(GCCause::Cause cause) {</span>
<span class="line-removed">-   GCIdMark gc_id_mark;</span>
<span class="line-removed">-   ShenandoahGCSession session(cause);</span>
<span class="line-removed">- </span>
<span class="line-removed">-   ShenandoahHeap* heap = ShenandoahHeap::heap();</span>
<span class="line-removed">-   TraceCollectorStats tcs(heap-&gt;monitoring_support()-&gt;concurrent_collection_counters());</span>
<span class="line-removed">- </span>
<span class="line-removed">-   // Reset for upcoming cycle</span>
<span class="line-removed">-   heap-&gt;entry_reset();</span>
<span class="line-removed">- </span>
<span class="line-removed">-   heap-&gt;vmop_entry_init_traversal();</span>
<span class="line-removed">- </span>
<span class="line-removed">-   if (check_cancellation_or_degen(ShenandoahHeap::_degenerated_traversal)) return;</span>
<span class="line-removed">- </span>
<span class="line-removed">-   heap-&gt;entry_traversal();</span>
<span class="line-removed">-   if (check_cancellation_or_degen(ShenandoahHeap::_degenerated_traversal)) return;</span>
<span class="line-removed">- </span>
<span class="line-removed">-   heap-&gt;vmop_entry_final_traversal();</span>
<span class="line-removed">- </span>
<span class="line-removed">-   heap-&gt;entry_cleanup();</span>
<span class="line-removed">- </span>
<span class="line-removed">-   heap-&gt;heuristics()-&gt;record_success_concurrent();</span>
<span class="line-removed">-   heap-&gt;shenandoah_policy()-&gt;record_success_concurrent();</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
  void ShenandoahControlThread::service_concurrent_normal_cycle(GCCause::Cause cause) {
    // Normal cycle goes via all concurrent phases. If allocation failure (af) happens during
    // any of the concurrent phases, it first degrades to Degenerated GC and completes GC there.
    // If second allocation failure happens during Degenerated GC cycle (for example, when GC
    // tries to evac something and no memory is available), cycle degrades to Full GC.
    //
<span class="line-modified">!   // There are also two shortcuts through the normal cycle: a) immediate garbage shortcut, when</span>
    // heuristics says there are no regions to compact, and all the collection comes from immediately
<span class="line-modified">!   // reclaimable regions; b) coalesced UR shortcut, when heuristics decides to coalesce UR with the</span>
<span class="line-removed">-   // mark from the next cycle.</span>
    //
    // ................................................................................................
    //
    //                                    (immediate garbage shortcut)                Concurrent GC
    //                             /-------------------------------------------\
<span class="line-modified">!   //                             |                       (coalesced UR)      v</span>
<span class="line-modified">!   //                             |                  /-----------------------&gt;o</span>
<span class="line-modified">!   //                             |                  |                        |</span>
<span class="line-modified">!   //                             |                  |                        v</span>
    // [START] ----&gt; Conc Mark ----o----&gt; Conc Evac --o--&gt; Conc Update-Refs ---o----&gt; [END]
    //                   |                    |                 |              ^
    //                   | (af)               | (af)            | (af)         |
    // ..................|....................|.................|..............|.......................
    //                   |                    |                 |              |
<span class="line-new-header">--- 279,28 ---</span>
    while (!should_terminate()) {
      os::naked_short_sleep(ShenandoahControlIntervalMin);
    }
  }
  
  void ShenandoahControlThread::service_concurrent_normal_cycle(GCCause::Cause cause) {
    // Normal cycle goes via all concurrent phases. If allocation failure (af) happens during
    // any of the concurrent phases, it first degrades to Degenerated GC and completes GC there.
    // If second allocation failure happens during Degenerated GC cycle (for example, when GC
    // tries to evac something and no memory is available), cycle degrades to Full GC.
    //
<span class="line-modified">!   // There are also a shortcut through the normal cycle: immediate garbage shortcut, when</span>
    // heuristics says there are no regions to compact, and all the collection comes from immediately
<span class="line-modified">!   // reclaimable regions.</span>
    //
    // ................................................................................................
    //
    //                                    (immediate garbage shortcut)                Concurrent GC
    //                             /-------------------------------------------\
<span class="line-modified">!   //                             |                                           |</span>
<span class="line-modified">!   //                             |                                           |</span>
<span class="line-modified">!   //                             |                                           |</span>
<span class="line-modified">!   //                             |                                           v</span>
    // [START] ----&gt; Conc Mark ----o----&gt; Conc Evac --o--&gt; Conc Update-Refs ---o----&gt; [END]
    //                   |                    |                 |              ^
    //                   | (af)               | (af)            | (af)         |
    // ..................|....................|.................|..............|.......................
    //                   |                    |                 |              |
</pre>
<hr />
<pre>
<span class="line-old-header">*** 390,26 ***</span>
    if (heap-&gt;is_evacuation_in_progress()) {
      // Concurrently evacuate
      heap-&gt;entry_evac();
      if (check_cancellation_or_degen(ShenandoahHeap::_degenerated_evac)) return;
  
<span class="line-modified">!     // Perform update-refs phase, if required. This phase can be skipped if heuristics</span>
<span class="line-modified">!     // decides to piggy-back the update-refs on the next marking cycle. On either path,</span>
<span class="line-modified">!     // we need to turn off evacuation: either in init-update-refs, or in final-evac.</span>
<span class="line-modified">!     if (heap-&gt;heuristics()-&gt;should_start_update_refs()) {</span>
<span class="line-removed">-       heap-&gt;vmop_entry_init_updaterefs();</span>
<span class="line-removed">-       heap-&gt;entry_updaterefs();</span>
<span class="line-removed">-       if (check_cancellation_or_degen(ShenandoahHeap::_degenerated_updaterefs)) return;</span>
<span class="line-removed">- </span>
<span class="line-removed">-       heap-&gt;vmop_entry_final_updaterefs();</span>
  
<span class="line-modified">!       // Update references freed up collection set, kick the cleanup to reclaim the space.</span>
<span class="line-removed">-       heap-&gt;entry_cleanup();</span>
  
<span class="line-modified">!     } else {</span>
<span class="line-modified">!       heap-&gt;vmop_entry_final_evac();</span>
<span class="line-removed">-     }</span>
    }
  
    // Cycle is complete
    heap-&gt;heuristics()-&gt;record_success_concurrent();
    heap-&gt;shenandoah_policy()-&gt;record_success_concurrent();
<span class="line-new-header">--- 360,19 ---</span>
    if (heap-&gt;is_evacuation_in_progress()) {
      // Concurrently evacuate
      heap-&gt;entry_evac();
      if (check_cancellation_or_degen(ShenandoahHeap::_degenerated_evac)) return;
  
<span class="line-modified">!     // Perform update-refs phase.</span>
<span class="line-modified">!     heap-&gt;vmop_entry_init_updaterefs();</span>
<span class="line-modified">!     heap-&gt;entry_updaterefs();</span>
<span class="line-modified">!     if (check_cancellation_or_degen(ShenandoahHeap::_degenerated_updaterefs)) return;</span>
  
<span class="line-modified">!     heap-&gt;vmop_entry_final_updaterefs();</span>
  
<span class="line-modified">!     // Update references freed up collection set, kick the cleanup to reclaim the space.</span>
<span class="line-modified">!     heap-&gt;entry_cleanup();</span>
    }
  
    // Cycle is complete
    heap-&gt;heuristics()-&gt;record_success_concurrent();
    heap-&gt;shenandoah_policy()-&gt;record_success_concurrent();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 510,19 ***</span>
    while (_gc_requested.is_set()) {
      ml.wait();
    }
  }
  
<span class="line-modified">! void ShenandoahControlThread::handle_alloc_failure(size_t words) {</span>
    ShenandoahHeap* heap = ShenandoahHeap::heap();
  
    assert(current()-&gt;is_Java_thread(), &quot;expect Java thread here&quot;);
  
    if (try_set_alloc_failure_gc()) {
      // Only report the first allocation failure
<span class="line-modified">!     log_info(gc)(&quot;Failed to allocate &quot; SIZE_FORMAT &quot;%s&quot;,</span>
<span class="line-modified">!                  byte_size_in_proper_unit(words * HeapWordSize), proper_unit_for_byte_size(words * HeapWordSize));</span>
  
      // Now that alloc failure GC is scheduled, we can abort everything else
      heap-&gt;cancel_gc(GCCause::_allocation_failure);
    }
  
<span class="line-new-header">--- 473,20 ---</span>
    while (_gc_requested.is_set()) {
      ml.wait();
    }
  }
  
<span class="line-modified">! void ShenandoahControlThread::handle_alloc_failure(ShenandoahAllocRequest&amp; req) {</span>
    ShenandoahHeap* heap = ShenandoahHeap::heap();
  
    assert(current()-&gt;is_Java_thread(), &quot;expect Java thread here&quot;);
  
    if (try_set_alloc_failure_gc()) {
      // Only report the first allocation failure
<span class="line-modified">!     log_info(gc)(&quot;Failed to allocate %s, &quot; SIZE_FORMAT &quot;%s&quot;,</span>
<span class="line-modified">!                  req.type_string(),</span>
<span class="line-added">+                  byte_size_in_proper_unit(req.size() * HeapWordSize), proper_unit_for_byte_size(req.size() * HeapWordSize));</span>
  
      // Now that alloc failure GC is scheduled, we can abort everything else
      heap-&gt;cancel_gc(GCCause::_allocation_failure);
    }
  
</pre>
<center><a href="shenandoahConcurrentRoots.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahControlThread.hpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>