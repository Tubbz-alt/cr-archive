<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/templateTable_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center>&lt; prev <a href="../../../../index.html" target="_top">index</a> <a href="../../share/interpreter/templateTable.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/templateTable_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 738   // check index
 739   Register length = rscratch1;
 740   __ ldrw(length, Address(array, arrayOopDesc::length_offset_in_bytes()));
 741   __ cmpw(index, length);
 742   if (index != r1) {
 743     // ??? convention: move aberrant index into r1 for exception message
 744     assert(r1 != array, &quot;different registers&quot;);
 745     __ mov(r1, index);
 746   }
 747   Label ok;
 748   __ br(Assembler::LO, ok);
 749     // ??? convention: move array into r3 for exception message
 750   __ mov(r3, array);
 751   __ mov(rscratch1, Interpreter::_throw_ArrayIndexOutOfBoundsException_entry);
 752   __ br(rscratch1);
 753   __ bind(ok);
 754 }
 755 
 756 #if INCLUDE_TSAN
 757 

















 758 void TemplateTable::tsan_observe_get_or_put(const Address &amp;field,
 759                                             Register flags,
 760                                             TsanMemoryReadWriteFunction tsan_function,
 761                                             TosState tos) {
 762   assert(ThreadSanitizer, &quot;ThreadSanitizer should be set&quot;);
 763 
 764   TsanMemoryReleaseAcquireFunction releaseAcquireFunction =
 765       tsan_release_acquire_method(tsan_function);
 766 
 767   Label done, notAcquireRelease;
 768 
 769   // We could save some instructions by only saving the registers we need.
 770   __ pusha();
 771   // pusha() doesn&#39;t save v0, which tsan_function clobbers and the
 772   // interpreter still needs.
 773   // This really only needs to be done for some of the float/double accesses,
 774   // but it&#39;s here because it&#39;s cleaner.
 775   __ push_d(v0);
 776   // For volatile reads/writes use an acquire/release.
 777   // If a reference is annotated to be ignored, assume it&#39;s safe to
 778   // access the object it&#39;s referring to and create a happens-before relation
 779   // between the accesses to this reference.
 780   if (tos == atos) {
 781     int32_t acquire_release_mask = 1 &lt;&lt; ConstantPoolCacheEntry::is_volatile_shift |
 782       1 &lt;&lt; ConstantPoolCacheEntry::is_tsan_ignore_shift;


 783     __ mov(rscratch1, acquire_release_mask);
 784     __ tst(flags, rscratch1);
 785     __ br(Assembler::EQ, notAcquireRelease);
 786   } else {
 787     __ tbz(flags, ConstantPoolCacheEntry::is_volatile_shift, notAcquireRelease);
 788   }
 789 
 790   __ lea(c_rarg0, field);
 791   __ call_VM_leaf(CAST_FROM_FN_PTR(address, releaseAcquireFunction), c_rarg0);
 792   if (ThreadSanitizerJavaMemory) {
 793     __ b(done);
 794     __ bind(notAcquireRelease);
 795 
 796     // Ignore reads/writes to final fields. They can&#39;t be racy.
 797     __ tbnz(flags, ConstantPoolCacheEntry::is_final_shift, done);
 798 
 799     // Don&#39;t report races on tsan ignored fields.
 800     __ tbnz(flags, ConstantPoolCacheEntry::is_tsan_ignore_shift, done);
 801 
 802     __ lea(c_rarg0, field);
</pre>
<hr />
<pre>
 807     __ bind(done);
 808   } else {
 809     __ bind(notAcquireRelease);
 810   }
 811   __ pop_d(v0);
 812   __ popa();
 813 }
 814 
 815 
 816 #endif
 817 
 818 void TemplateTable::iaload()
 819 {
 820   transition(itos, itos);
 821   __ mov(r1, r0);
 822   __ pop_ptr(r0);
 823   // r0: array
 824   // r1: index
 825   index_check(r0, r1); // leaves index in r1, kills rscratch1
 826   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_INT) &gt;&gt; 2);
<span class="line-modified"> 827   __ access_load_at(T_INT, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(2)), noreg, noreg);</span>


 828 }
 829 
 830 void TemplateTable::laload()
 831 {
 832   transition(itos, ltos);
 833   __ mov(r1, r0);
 834   __ pop_ptr(r0);
 835   // r0: array
 836   // r1: index
 837   index_check(r0, r1); // leaves index in r1, kills rscratch1
 838   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_LONG) &gt;&gt; 3);
<span class="line-modified"> 839   __ access_load_at(T_LONG, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(3)), noreg, noreg);</span>


 840 }
 841 
 842 void TemplateTable::faload()
 843 {
 844   transition(itos, ftos);
 845   __ mov(r1, r0);
 846   __ pop_ptr(r0);
 847   // r0: array
 848   // r1: index
 849   index_check(r0, r1); // leaves index in r1, kills rscratch1
 850   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_FLOAT) &gt;&gt; 2);
<span class="line-modified"> 851   __ access_load_at(T_FLOAT, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(2)), noreg, noreg);</span>


 852 }
 853 
 854 void TemplateTable::daload()
 855 {
 856   transition(itos, dtos);
 857   __ mov(r1, r0);
 858   __ pop_ptr(r0);
 859   // r0: array
 860   // r1: index
 861   index_check(r0, r1); // leaves index in r1, kills rscratch1
 862   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_DOUBLE) &gt;&gt; 3);
<span class="line-modified"> 863   __ access_load_at(T_DOUBLE, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(3)), noreg, noreg);</span>


 864 }
 865 
 866 void TemplateTable::aaload()
 867 {
 868   transition(itos, atos);
 869   __ mov(r1, r0);
 870   __ pop_ptr(r0);
 871   // r0: array
 872   // r1: index
 873   index_check(r0, r1); // leaves index in r1, kills rscratch1
 874   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_OBJECT) &gt;&gt; LogBytesPerHeapOop);
<span class="line-modified"> 875   do_oop_load(_masm,</span>
<span class="line-modified"> 876               Address(r0, r1, Address::uxtw(LogBytesPerHeapOop)),</span>
<span class="line-modified"> 877               r0,</span>
<span class="line-modified"> 878               IS_ARRAY);</span>
 879 }
 880 
 881 void TemplateTable::baload()
 882 {
 883   transition(itos, itos);
 884   __ mov(r1, r0);
 885   __ pop_ptr(r0);
 886   // r0: array
 887   // r1: index
 888   index_check(r0, r1); // leaves index in r1, kills rscratch1
 889   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_BYTE) &gt;&gt; 0);
<span class="line-modified"> 890   __ access_load_at(T_BYTE, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(0)), noreg, noreg);</span>


 891 }
 892 
 893 void TemplateTable::caload()
 894 {
 895   transition(itos, itos);
 896   __ mov(r1, r0);
 897   __ pop_ptr(r0);
 898   // r0: array
 899   // r1: index
 900   index_check(r0, r1); // leaves index in r1, kills rscratch1
 901   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_CHAR) &gt;&gt; 1);
<span class="line-modified"> 902   __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(1)), noreg, noreg);</span>


 903 }
 904 
 905 // iload followed by caload frequent pair
 906 void TemplateTable::fast_icaload()
 907 {



 908   transition(vtos, itos);
 909   // load index out of locals
 910   locals_index(r2);
 911   __ ldr(r1, iaddress(r2));
 912 
 913   __ pop_ptr(r0);
 914 
 915   // r0: array
 916   // r1: index
 917   index_check(r0, r1); // leaves index in r1, kills rscratch1
 918   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_CHAR) &gt;&gt; 1);
 919   __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(1)), noreg, noreg);
 920 }
 921 
 922 void TemplateTable::saload()
 923 {
 924   transition(itos, itos);
 925   __ mov(r1, r0);
 926   __ pop_ptr(r0);
 927   // r0: array
 928   // r1: index
 929   index_check(r0, r1); // leaves index in r1, kills rscratch1
 930   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_SHORT) &gt;&gt; 1);
<span class="line-modified"> 931   __ access_load_at(T_SHORT, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(1)), noreg, noreg);</span>


 932 }
 933 
 934 void TemplateTable::iload(int n)
 935 {
 936   transition(vtos, itos);
 937   __ ldr(r0, iaddress(n));
 938 }
 939 
 940 void TemplateTable::lload(int n)
 941 {
 942   transition(vtos, ltos);
 943   __ ldr(r0, laddress(n));
 944 }
 945 
 946 void TemplateTable::fload(int n)
 947 {
 948   transition(vtos, ftos);
 949   __ ldrs(v0, faddress(n));
 950 }
 951 
</pre>
<hr />
<pre>
1105   locals_index_wide(r1);
1106   __ strd(v0, daddress(r1, rscratch1, _masm));
1107 }
1108 
1109 void TemplateTable::wide_astore() {
1110   transition(vtos, vtos);
1111   __ pop_ptr(r0);
1112   locals_index_wide(r1);
1113   __ str(r0, aaddress(r1));
1114 }
1115 
1116 void TemplateTable::iastore() {
1117   transition(itos, vtos);
1118   __ pop_i(r1);
1119   __ pop_ptr(r3);
1120   // r0: value
1121   // r1: index
1122   // r3: array
1123   index_check(r3, r1); // prefer index in r1
1124   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_INT) &gt;&gt; 2);
<span class="line-modified">1125   __ access_store_at(T_INT, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(2)), r0, noreg, noreg);</span>


1126 }
1127 
1128 void TemplateTable::lastore() {
1129   transition(ltos, vtos);
1130   __ pop_i(r1);
1131   __ pop_ptr(r3);
1132   // r0: value
1133   // r1: index
1134   // r3: array
1135   index_check(r3, r1); // prefer index in r1
1136   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_LONG) &gt;&gt; 3);
<span class="line-modified">1137   __ access_store_at(T_LONG, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(3)), r0, noreg, noreg);</span>


1138 }
1139 
1140 void TemplateTable::fastore() {
1141   transition(ftos, vtos);
1142   __ pop_i(r1);
1143   __ pop_ptr(r3);
1144   // v0: value
1145   // r1:  index
1146   // r3:  array
1147   index_check(r3, r1); // prefer index in r1
1148   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_FLOAT) &gt;&gt; 2);
<span class="line-modified">1149   __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(2)), noreg /* ftos */, noreg, noreg);</span>


1150 }
1151 
1152 void TemplateTable::dastore() {
1153   transition(dtos, vtos);
1154   __ pop_i(r1);
1155   __ pop_ptr(r3);
1156   // v0: value
1157   // r1:  index
1158   // r3:  array
1159   index_check(r3, r1); // prefer index in r1
1160   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_DOUBLE) &gt;&gt; 3);
<span class="line-modified">1161   __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(3)), noreg /* dtos */, noreg, noreg);</span>


1162 }
1163 
1164 void TemplateTable::aastore() {
1165   Label is_null, ok_is_subtype, done;
1166   transition(vtos, vtos);
1167   // stack: ..., array, index, value
1168   __ ldr(r0, at_tos());    // value
1169   __ ldr(r2, at_tos_p1()); // index
1170   __ ldr(r3, at_tos_p2()); // array
1171 
1172   Address element_address(r3, r4, Address::uxtw(LogBytesPerHeapOop));
1173 
1174   index_check(r3, r2);     // kills r1
1175   __ add(r4, r2, arrayOopDesc::base_offset_in_bytes(T_OBJECT) &gt;&gt; LogBytesPerHeapOop);
<span class="line-modified">1176 </span>


1177   // do array store check - check for NULL value first
1178   __ cbz(r0, is_null);
1179 
1180   // Move subklass into r1
1181   __ load_klass(r1, r0);
1182   // Move superklass into r0
1183   __ load_klass(r0, r3);
1184   __ ldr(r0, Address(r0,
1185                      ObjArrayKlass::element_klass_offset()));
1186   // Compress array + index*oopSize + 12 into a single register.  Frees r2.
1187 
1188   // Generate subtype check.  Blows r2, r5
1189   // Superklass in r0.  Subklass in r1.
1190   __ gen_subtype_check(r1, ok_is_subtype);
1191 
1192   // Come here on failure
1193   // object is at TOS
1194   __ b(Interpreter::_throw_ArrayStoreException_entry);
1195 
1196   // Come here on success
</pre>
<hr />
<pre>
1218 {
1219   transition(itos, vtos);
1220   __ pop_i(r1);
1221   __ pop_ptr(r3);
1222   // r0: value
1223   // r1: index
1224   // r3: array
1225   index_check(r3, r1); // prefer index in r1
1226 
1227   // Need to check whether array is boolean or byte
1228   // since both types share the bastore bytecode.
1229   __ load_klass(r2, r3);
1230   __ ldrw(r2, Address(r2, Klass::layout_helper_offset()));
1231   int diffbit_index = exact_log2(Klass::layout_helper_boolean_diffbit());
1232   Label L_skip;
1233   __ tbz(r2, diffbit_index, L_skip);
1234   __ andw(r0, r0, 1);  // if it is a T_BOOLEAN array, mask the stored value to 0/1
1235   __ bind(L_skip);
1236 
1237   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_BYTE) &gt;&gt; 0);
<span class="line-modified">1238   __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(0)), r0, noreg, noreg);</span>


1239 }
1240 
1241 void TemplateTable::castore()
1242 {
1243   transition(itos, vtos);
1244   __ pop_i(r1);
1245   __ pop_ptr(r3);
1246   // r0: value
1247   // r1: index
1248   // r3: array
1249   index_check(r3, r1); // prefer index in r1
1250   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_CHAR) &gt;&gt; 1);
<span class="line-modified">1251   __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(1)), r0, noreg, noreg);</span>


1252 }
1253 
1254 void TemplateTable::sastore()
1255 {
1256   castore();
1257 }
1258 
1259 void TemplateTable::istore(int n)
1260 {
1261   transition(itos, vtos);
1262   __ str(r0, iaddress(n));
1263 }
1264 
1265 void TemplateTable::lstore(int n)
1266 {
1267   transition(ltos, vtos);
1268   __ str(r0, laddress(n));
1269 }
1270 
1271 void TemplateTable::fstore(int n)
</pre>
<hr />
<pre>
3132     __ access_store_at(T_FLOAT, IN_HEAP, field, noreg /* ftos */, noreg, noreg);
3133     break;
3134   case Bytecodes::_fast_dputfield:
3135     __ access_store_at(T_DOUBLE, IN_HEAP, field, noreg /* dtos */, noreg, noreg);
3136     break;
3137   default:
3138     ShouldNotReachHere();
3139   }
3140 
3141   {
3142     Label notVolatile;
3143     __ tbz(r3, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
3144     __ membar(MacroAssembler::StoreLoad | MacroAssembler::StoreStore);
3145     __ bind(notVolatile);
3146   }
3147 }
3148 
3149 
3150 void TemplateTable::fast_accessfield(TosState state)
3151 {



3152   transition(atos, state);
3153   // Do the JVMTI work here to avoid disturbing the register state below
3154   if (JvmtiExport::can_post_field_access()) {
3155     // Check to see if a field access watch has been set before we
3156     // take the time to call into the VM.
3157     Label L1;
3158     __ lea(rscratch1, ExternalAddress((address) JvmtiExport::get_field_access_count_addr()));
3159     __ ldrw(r2, Address(rscratch1));
3160     __ cbzw(r2, L1);
3161     // access constant pool cache entry
3162     __ get_cache_entry_pointer_at_bcp(c_rarg2, rscratch2, 1);
3163     __ verify_oop(r0);
3164     __ push_ptr(r0);  // save object pointer before call_VM() clobbers it
3165     __ mov(c_rarg1, r0);
3166     // c_rarg1: object pointer copied above
3167     // c_rarg2: cache entry pointer
3168     __ call_VM(noreg,
3169                CAST_FROM_FN_PTR(address,
3170                                 InterpreterRuntime::post_field_access),
3171                c_rarg1, c_rarg2);
</pre>
<hr />
<pre>
3221     break;
3222   case Bytecodes::_fast_fgetfield:
3223     __ access_load_at(T_FLOAT, IN_HEAP, noreg /* ftos */, field, noreg, noreg);
3224     break;
3225   case Bytecodes::_fast_dgetfield:
3226     __ access_load_at(T_DOUBLE, IN_HEAP, noreg /* dtos */, field, noreg, noreg);
3227     break;
3228   default:
3229     ShouldNotReachHere();
3230   }
3231   {
3232     Label notVolatile;
3233     __ tbz(r3, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
3234     __ membar(MacroAssembler::LoadLoad | MacroAssembler::LoadStore);
3235     __ bind(notVolatile);
3236   }
3237 }
3238 
3239 void TemplateTable::fast_xaccess(TosState state)
3240 {



3241   transition(vtos, state);
3242 
3243   // get receiver
3244   __ ldr(r0, aaddress(0));
3245   // access constant pool cache
3246   __ get_cache_and_index_at_bcp(r2, r3, 2);
3247   __ ldr(r1, Address(r2, in_bytes(ConstantPoolCache::base_offset() +
3248                                   ConstantPoolCacheEntry::f2_offset())));
3249 
3250   // 8179954: We need to make sure that the code generated for
3251   // volatile accesses forms a sequentially-consistent set of
3252   // operations when combined with STLR and LDAR.  Without a leading
3253   // membar it&#39;s possible for a simple Dekker test to fail if loads
3254   // use LDR;DMB but stores use STLR.  This can happen if C2 compiles
3255   // the stores in one method and we interpret the loads in another.
3256   if (! UseBarriersForVolatile) {
3257     Label notVolatile;
3258     __ ldrw(r3, Address(r2, in_bytes(ConstantPoolCache::base_offset() +
3259                                      ConstantPoolCacheEntry::flags_offset())));
3260     __ tbz(r3, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
</pre>
</td>
<td>
<hr />
<pre>
 738   // check index
 739   Register length = rscratch1;
 740   __ ldrw(length, Address(array, arrayOopDesc::length_offset_in_bytes()));
 741   __ cmpw(index, length);
 742   if (index != r1) {
 743     // ??? convention: move aberrant index into r1 for exception message
 744     assert(r1 != array, &quot;different registers&quot;);
 745     __ mov(r1, index);
 746   }
 747   Label ok;
 748   __ br(Assembler::LO, ok);
 749     // ??? convention: move array into r3 for exception message
 750   __ mov(r3, array);
 751   __ mov(rscratch1, Interpreter::_throw_ArrayIndexOutOfBoundsException_entry);
 752   __ br(rscratch1);
 753   __ bind(ok);
 754 }
 755 
 756 #if INCLUDE_TSAN
 757 
<span class="line-added"> 758 void TemplateTable::tsan_observe_load_or_store(const Address&amp; field,</span>
<span class="line-added"> 759                                                TsanMemoryReadWriteFunction tsan_function) {</span>
<span class="line-added"> 760   assert(ThreadSanitizer, &quot;ThreadSanitizer should be set&quot;);</span>
<span class="line-added"> 761   if (!ThreadSanitizerJavaMemory) {</span>
<span class="line-added"> 762     return;</span>
<span class="line-added"> 763   }</span>
<span class="line-added"> 764 </span>
<span class="line-added"> 765   __ pusha();</span>
<span class="line-added"> 766   __ push_d(v0);</span>
<span class="line-added"> 767   __ lea(c_rarg0, field);</span>
<span class="line-added"> 768   __ get_method(c_rarg1);</span>
<span class="line-added"> 769   __ call_VM_leaf(CAST_FROM_FN_PTR(address, tsan_function),</span>
<span class="line-added"> 770                   c_rarg0 /* addr */, c_rarg1 /* method */, rbcp /* bcp */);</span>
<span class="line-added"> 771   __ pop_d(v0);</span>
<span class="line-added"> 772   __ popa();</span>
<span class="line-added"> 773 }</span>
<span class="line-added"> 774 </span>
 775 void TemplateTable::tsan_observe_get_or_put(const Address &amp;field,
 776                                             Register flags,
 777                                             TsanMemoryReadWriteFunction tsan_function,
 778                                             TosState tos) {
 779   assert(ThreadSanitizer, &quot;ThreadSanitizer should be set&quot;);
 780 
 781   TsanMemoryReleaseAcquireFunction releaseAcquireFunction =
 782       tsan_release_acquire_method(tsan_function);
 783 
 784   Label done, notAcquireRelease;
 785 
 786   // We could save some instructions by only saving the registers we need.
 787   __ pusha();
 788   // pusha() doesn&#39;t save v0, which tsan_function clobbers and the
 789   // interpreter still needs.
 790   // This really only needs to be done for some of the float/double accesses,
 791   // but it&#39;s here because it&#39;s cleaner.
 792   __ push_d(v0);
 793   // For volatile reads/writes use an acquire/release.
 794   // If a reference is annotated to be ignored, assume it&#39;s safe to
 795   // access the object it&#39;s referring to and create a happens-before relation
 796   // between the accesses to this reference.
 797   if (tos == atos) {
 798     int32_t acquire_release_mask = 1 &lt;&lt; ConstantPoolCacheEntry::is_volatile_shift |
 799       1 &lt;&lt; ConstantPoolCacheEntry::is_tsan_ignore_shift;
<span class="line-added"> 800     // acquire_release_mask (0x8200000) can not be encoded into &#39;tst&#39;, but it can be</span>
<span class="line-added"> 801     // encoded into just one &#39;mov&#39; instruction.</span>
 802     __ mov(rscratch1, acquire_release_mask);
 803     __ tst(flags, rscratch1);
 804     __ br(Assembler::EQ, notAcquireRelease);
 805   } else {
 806     __ tbz(flags, ConstantPoolCacheEntry::is_volatile_shift, notAcquireRelease);
 807   }
 808 
 809   __ lea(c_rarg0, field);
 810   __ call_VM_leaf(CAST_FROM_FN_PTR(address, releaseAcquireFunction), c_rarg0);
 811   if (ThreadSanitizerJavaMemory) {
 812     __ b(done);
 813     __ bind(notAcquireRelease);
 814 
 815     // Ignore reads/writes to final fields. They can&#39;t be racy.
 816     __ tbnz(flags, ConstantPoolCacheEntry::is_final_shift, done);
 817 
 818     // Don&#39;t report races on tsan ignored fields.
 819     __ tbnz(flags, ConstantPoolCacheEntry::is_tsan_ignore_shift, done);
 820 
 821     __ lea(c_rarg0, field);
</pre>
<hr />
<pre>
 826     __ bind(done);
 827   } else {
 828     __ bind(notAcquireRelease);
 829   }
 830   __ pop_d(v0);
 831   __ popa();
 832 }
 833 
 834 
 835 #endif
 836 
 837 void TemplateTable::iaload()
 838 {
 839   transition(itos, itos);
 840   __ mov(r1, r0);
 841   __ pop_ptr(r0);
 842   // r0: array
 843   // r1: index
 844   index_check(r0, r1); // leaves index in r1, kills rscratch1
 845   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_INT) &gt;&gt; 2);
<span class="line-modified"> 846   Address addr(r0, r1, Address::uxtw(2));</span>
<span class="line-added"> 847   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read4));</span>
<span class="line-added"> 848   __ access_load_at(T_INT, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);</span>
 849 }
 850 
 851 void TemplateTable::laload()
 852 {
 853   transition(itos, ltos);
 854   __ mov(r1, r0);
 855   __ pop_ptr(r0);
 856   // r0: array
 857   // r1: index
 858   index_check(r0, r1); // leaves index in r1, kills rscratch1
 859   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_LONG) &gt;&gt; 3);
<span class="line-modified"> 860   Address addr(r0, r1, Address::uxtw(3));</span>
<span class="line-added"> 861   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read8));</span>
<span class="line-added"> 862   __ access_load_at(T_LONG, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);</span>
 863 }
 864 
 865 void TemplateTable::faload()
 866 {
 867   transition(itos, ftos);
 868   __ mov(r1, r0);
 869   __ pop_ptr(r0);
 870   // r0: array
 871   // r1: index
 872   index_check(r0, r1); // leaves index in r1, kills rscratch1
 873   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_FLOAT) &gt;&gt; 2);
<span class="line-modified"> 874   Address addr(r0, r1, Address::uxtw(2));</span>
<span class="line-added"> 875   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read4));</span>
<span class="line-added"> 876   __ access_load_at(T_FLOAT, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);</span>
 877 }
 878 
 879 void TemplateTable::daload()
 880 {
 881   transition(itos, dtos);
 882   __ mov(r1, r0);
 883   __ pop_ptr(r0);
 884   // r0: array
 885   // r1: index
 886   index_check(r0, r1); // leaves index in r1, kills rscratch1
 887   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_DOUBLE) &gt;&gt; 3);
<span class="line-modified"> 888   Address addr(r0, r1, Address::uxtw(3));</span>
<span class="line-added"> 889   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read8));</span>
<span class="line-added"> 890   __ access_load_at(T_DOUBLE, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);</span>
 891 }
 892 
 893 void TemplateTable::aaload()
 894 {
 895   transition(itos, atos);
 896   __ mov(r1, r0);
 897   __ pop_ptr(r0);
 898   // r0: array
 899   // r1: index
 900   index_check(r0, r1); // leaves index in r1, kills rscratch1
 901   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_OBJECT) &gt;&gt; LogBytesPerHeapOop);
<span class="line-modified"> 902   Address addr(r0, r1, Address::uxtw(LogBytesPerHeapOop));</span>
<span class="line-modified"> 903   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, UseCompressedOops ? SharedRuntime::tsan_read4</span>
<span class="line-modified"> 904                                                                        : SharedRuntime::tsan_read8));</span>
<span class="line-modified"> 905   do_oop_load(_masm, addr, r0, IS_ARRAY);</span>
 906 }
 907 
 908 void TemplateTable::baload()
 909 {
 910   transition(itos, itos);
 911   __ mov(r1, r0);
 912   __ pop_ptr(r0);
 913   // r0: array
 914   // r1: index
 915   index_check(r0, r1); // leaves index in r1, kills rscratch1
 916   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_BYTE) &gt;&gt; 0);
<span class="line-modified"> 917   Address addr(r0, r1, Address::uxtw(0));</span>
<span class="line-added"> 918   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read1));</span>
<span class="line-added"> 919   __ access_load_at(T_BYTE, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);</span>
 920 }
 921 
 922 void TemplateTable::caload()
 923 {
 924   transition(itos, itos);
 925   __ mov(r1, r0);
 926   __ pop_ptr(r0);
 927   // r0: array
 928   // r1: index
 929   index_check(r0, r1); // leaves index in r1, kills rscratch1
 930   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_CHAR) &gt;&gt; 1);
<span class="line-modified"> 931   Address addr(r0, r1, Address::uxtw(1));</span>
<span class="line-added"> 932   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read2));</span>
<span class="line-added"> 933   __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);</span>
 934 }
 935 
 936 // iload followed by caload frequent pair
 937 void TemplateTable::fast_icaload()
 938 {
<span class="line-added"> 939 #ifdef ASSERT</span>
<span class="line-added"> 940   TSAN_RUNTIME_ONLY(__ stop(&quot;bytecode rewrite should have been disabled in TSAN&quot;););</span>
<span class="line-added"> 941 #endif</span>
 942   transition(vtos, itos);
 943   // load index out of locals
 944   locals_index(r2);
 945   __ ldr(r1, iaddress(r2));
 946 
 947   __ pop_ptr(r0);
 948 
 949   // r0: array
 950   // r1: index
 951   index_check(r0, r1); // leaves index in r1, kills rscratch1
 952   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_CHAR) &gt;&gt; 1);
 953   __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(1)), noreg, noreg);
 954 }
 955 
 956 void TemplateTable::saload()
 957 {
 958   transition(itos, itos);
 959   __ mov(r1, r0);
 960   __ pop_ptr(r0);
 961   // r0: array
 962   // r1: index
 963   index_check(r0, r1); // leaves index in r1, kills rscratch1
 964   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_SHORT) &gt;&gt; 1);
<span class="line-modified"> 965   Address addr(r0, r1, Address::uxtw(1));</span>
<span class="line-added"> 966   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read2));</span>
<span class="line-added"> 967   __ access_load_at(T_SHORT, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);</span>
 968 }
 969 
 970 void TemplateTable::iload(int n)
 971 {
 972   transition(vtos, itos);
 973   __ ldr(r0, iaddress(n));
 974 }
 975 
 976 void TemplateTable::lload(int n)
 977 {
 978   transition(vtos, ltos);
 979   __ ldr(r0, laddress(n));
 980 }
 981 
 982 void TemplateTable::fload(int n)
 983 {
 984   transition(vtos, ftos);
 985   __ ldrs(v0, faddress(n));
 986 }
 987 
</pre>
<hr />
<pre>
1141   locals_index_wide(r1);
1142   __ strd(v0, daddress(r1, rscratch1, _masm));
1143 }
1144 
1145 void TemplateTable::wide_astore() {
1146   transition(vtos, vtos);
1147   __ pop_ptr(r0);
1148   locals_index_wide(r1);
1149   __ str(r0, aaddress(r1));
1150 }
1151 
1152 void TemplateTable::iastore() {
1153   transition(itos, vtos);
1154   __ pop_i(r1);
1155   __ pop_ptr(r3);
1156   // r0: value
1157   // r1: index
1158   // r3: array
1159   index_check(r3, r1); // prefer index in r1
1160   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_INT) &gt;&gt; 2);
<span class="line-modified">1161   Address addr(r3, r1, Address::uxtw(2));</span>
<span class="line-added">1162   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write4));</span>
<span class="line-added">1163   __ access_store_at(T_INT, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);</span>
1164 }
1165 
1166 void TemplateTable::lastore() {
1167   transition(ltos, vtos);
1168   __ pop_i(r1);
1169   __ pop_ptr(r3);
1170   // r0: value
1171   // r1: index
1172   // r3: array
1173   index_check(r3, r1); // prefer index in r1
1174   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_LONG) &gt;&gt; 3);
<span class="line-modified">1175   Address addr(r3, r1, Address::uxtw(3));</span>
<span class="line-added">1176   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write8));</span>
<span class="line-added">1177   __ access_store_at(T_LONG, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);</span>
1178 }
1179 
1180 void TemplateTable::fastore() {
1181   transition(ftos, vtos);
1182   __ pop_i(r1);
1183   __ pop_ptr(r3);
1184   // v0: value
1185   // r1:  index
1186   // r3:  array
1187   index_check(r3, r1); // prefer index in r1
1188   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_FLOAT) &gt;&gt; 2);
<span class="line-modified">1189   Address addr(r3, r1, Address::uxtw(2));</span>
<span class="line-added">1190   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write4));</span>
<span class="line-added">1191   __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY, addr, noreg /* ftos */, noreg, noreg);</span>
1192 }
1193 
1194 void TemplateTable::dastore() {
1195   transition(dtos, vtos);
1196   __ pop_i(r1);
1197   __ pop_ptr(r3);
1198   // v0: value
1199   // r1:  index
1200   // r3:  array
1201   index_check(r3, r1); // prefer index in r1
1202   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_DOUBLE) &gt;&gt; 3);
<span class="line-modified">1203   Address addr(r3, r1, Address::uxtw(3));</span>
<span class="line-added">1204   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write8));</span>
<span class="line-added">1205   __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY, addr, noreg /* dtos */, noreg, noreg);</span>
1206 }
1207 
1208 void TemplateTable::aastore() {
1209   Label is_null, ok_is_subtype, done;
1210   transition(vtos, vtos);
1211   // stack: ..., array, index, value
1212   __ ldr(r0, at_tos());    // value
1213   __ ldr(r2, at_tos_p1()); // index
1214   __ ldr(r3, at_tos_p2()); // array
1215 
1216   Address element_address(r3, r4, Address::uxtw(LogBytesPerHeapOop));
1217 
1218   index_check(r3, r2);     // kills r1
1219   __ add(r4, r2, arrayOopDesc::base_offset_in_bytes(T_OBJECT) &gt;&gt; LogBytesPerHeapOop);
<span class="line-modified">1220   // do tsan write after r4 has been defined.</span>
<span class="line-added">1221   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(element_address, UseCompressedOops ? SharedRuntime::tsan_write4</span>
<span class="line-added">1222                                                                                   : SharedRuntime::tsan_write8));</span>
1223   // do array store check - check for NULL value first
1224   __ cbz(r0, is_null);
1225 
1226   // Move subklass into r1
1227   __ load_klass(r1, r0);
1228   // Move superklass into r0
1229   __ load_klass(r0, r3);
1230   __ ldr(r0, Address(r0,
1231                      ObjArrayKlass::element_klass_offset()));
1232   // Compress array + index*oopSize + 12 into a single register.  Frees r2.
1233 
1234   // Generate subtype check.  Blows r2, r5
1235   // Superklass in r0.  Subklass in r1.
1236   __ gen_subtype_check(r1, ok_is_subtype);
1237 
1238   // Come here on failure
1239   // object is at TOS
1240   __ b(Interpreter::_throw_ArrayStoreException_entry);
1241 
1242   // Come here on success
</pre>
<hr />
<pre>
1264 {
1265   transition(itos, vtos);
1266   __ pop_i(r1);
1267   __ pop_ptr(r3);
1268   // r0: value
1269   // r1: index
1270   // r3: array
1271   index_check(r3, r1); // prefer index in r1
1272 
1273   // Need to check whether array is boolean or byte
1274   // since both types share the bastore bytecode.
1275   __ load_klass(r2, r3);
1276   __ ldrw(r2, Address(r2, Klass::layout_helper_offset()));
1277   int diffbit_index = exact_log2(Klass::layout_helper_boolean_diffbit());
1278   Label L_skip;
1279   __ tbz(r2, diffbit_index, L_skip);
1280   __ andw(r0, r0, 1);  // if it is a T_BOOLEAN array, mask the stored value to 0/1
1281   __ bind(L_skip);
1282 
1283   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_BYTE) &gt;&gt; 0);
<span class="line-modified">1284   Address addr(r3, r1, Address::uxtw(0));</span>
<span class="line-added">1285   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write1));</span>
<span class="line-added">1286   __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);</span>
1287 }
1288 
1289 void TemplateTable::castore()
1290 {
1291   transition(itos, vtos);
1292   __ pop_i(r1);
1293   __ pop_ptr(r3);
1294   // r0: value
1295   // r1: index
1296   // r3: array
1297   index_check(r3, r1); // prefer index in r1
1298   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_CHAR) &gt;&gt; 1);
<span class="line-modified">1299   Address addr(r3, r1, Address::uxtw(1));</span>
<span class="line-added">1300   TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write2));</span>
<span class="line-added">1301   __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);</span>
1302 }
1303 
1304 void TemplateTable::sastore()
1305 {
1306   castore();
1307 }
1308 
1309 void TemplateTable::istore(int n)
1310 {
1311   transition(itos, vtos);
1312   __ str(r0, iaddress(n));
1313 }
1314 
1315 void TemplateTable::lstore(int n)
1316 {
1317   transition(ltos, vtos);
1318   __ str(r0, laddress(n));
1319 }
1320 
1321 void TemplateTable::fstore(int n)
</pre>
<hr />
<pre>
3182     __ access_store_at(T_FLOAT, IN_HEAP, field, noreg /* ftos */, noreg, noreg);
3183     break;
3184   case Bytecodes::_fast_dputfield:
3185     __ access_store_at(T_DOUBLE, IN_HEAP, field, noreg /* dtos */, noreg, noreg);
3186     break;
3187   default:
3188     ShouldNotReachHere();
3189   }
3190 
3191   {
3192     Label notVolatile;
3193     __ tbz(r3, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
3194     __ membar(MacroAssembler::StoreLoad | MacroAssembler::StoreStore);
3195     __ bind(notVolatile);
3196   }
3197 }
3198 
3199 
3200 void TemplateTable::fast_accessfield(TosState state)
3201 {
<span class="line-added">3202 #ifdef ASSERT</span>
<span class="line-added">3203   TSAN_RUNTIME_ONLY(__ stop(&quot;bytecode rewrite should have been disabled in TSAN&quot;););</span>
<span class="line-added">3204 #endif</span>
3205   transition(atos, state);
3206   // Do the JVMTI work here to avoid disturbing the register state below
3207   if (JvmtiExport::can_post_field_access()) {
3208     // Check to see if a field access watch has been set before we
3209     // take the time to call into the VM.
3210     Label L1;
3211     __ lea(rscratch1, ExternalAddress((address) JvmtiExport::get_field_access_count_addr()));
3212     __ ldrw(r2, Address(rscratch1));
3213     __ cbzw(r2, L1);
3214     // access constant pool cache entry
3215     __ get_cache_entry_pointer_at_bcp(c_rarg2, rscratch2, 1);
3216     __ verify_oop(r0);
3217     __ push_ptr(r0);  // save object pointer before call_VM() clobbers it
3218     __ mov(c_rarg1, r0);
3219     // c_rarg1: object pointer copied above
3220     // c_rarg2: cache entry pointer
3221     __ call_VM(noreg,
3222                CAST_FROM_FN_PTR(address,
3223                                 InterpreterRuntime::post_field_access),
3224                c_rarg1, c_rarg2);
</pre>
<hr />
<pre>
3274     break;
3275   case Bytecodes::_fast_fgetfield:
3276     __ access_load_at(T_FLOAT, IN_HEAP, noreg /* ftos */, field, noreg, noreg);
3277     break;
3278   case Bytecodes::_fast_dgetfield:
3279     __ access_load_at(T_DOUBLE, IN_HEAP, noreg /* dtos */, field, noreg, noreg);
3280     break;
3281   default:
3282     ShouldNotReachHere();
3283   }
3284   {
3285     Label notVolatile;
3286     __ tbz(r3, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
3287     __ membar(MacroAssembler::LoadLoad | MacroAssembler::LoadStore);
3288     __ bind(notVolatile);
3289   }
3290 }
3291 
3292 void TemplateTable::fast_xaccess(TosState state)
3293 {
<span class="line-added">3294 #ifdef ASSERT</span>
<span class="line-added">3295   TSAN_RUNTIME_ONLY(__ stop(&quot;bytecode rewrite should have been disabled in TSAN&quot;););</span>
<span class="line-added">3296 #endif</span>
3297   transition(vtos, state);
3298 
3299   // get receiver
3300   __ ldr(r0, aaddress(0));
3301   // access constant pool cache
3302   __ get_cache_and_index_at_bcp(r2, r3, 2);
3303   __ ldr(r1, Address(r2, in_bytes(ConstantPoolCache::base_offset() +
3304                                   ConstantPoolCacheEntry::f2_offset())));
3305 
3306   // 8179954: We need to make sure that the code generated for
3307   // volatile accesses forms a sequentially-consistent set of
3308   // operations when combined with STLR and LDAR.  Without a leading
3309   // membar it&#39;s possible for a simple Dekker test to fail if loads
3310   // use LDR;DMB but stores use STLR.  This can happen if C2 compiles
3311   // the stores in one method and we interpret the loads in another.
3312   if (! UseBarriersForVolatile) {
3313     Label notVolatile;
3314     __ ldrw(r3, Address(r2, in_bytes(ConstantPoolCache::base_offset() +
3315                                      ConstantPoolCacheEntry::flags_offset())));
3316     __ tbz(r3, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
</pre>
</td>
</tr>
</table>
<center>&lt; prev <a href="../../../../index.html" target="_top">index</a> <a href="../../share/interpreter/templateTable.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>