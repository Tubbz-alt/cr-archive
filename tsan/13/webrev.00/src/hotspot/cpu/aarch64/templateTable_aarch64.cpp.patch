diff a/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp b/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
@@ -753,10 +753,27 @@
   __ bind(ok);
 }
 
 #if INCLUDE_TSAN
 
+void TemplateTable::tsan_observe_load_or_store(const Address& field,
+                                               TsanMemoryReadWriteFunction tsan_function) {
+  assert(ThreadSanitizer, "ThreadSanitizer should be set");
+  if (!ThreadSanitizerJavaMemory) {
+    return;
+  }
+
+  __ pusha();
+  __ push_d(v0);
+  __ lea(c_rarg0, field);
+  __ get_method(c_rarg1);
+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, tsan_function),
+                  c_rarg0 /* addr */, c_rarg1 /* method */, rbcp /* bcp */);
+  __ pop_d(v0);
+  __ popa();
+}
+
 void TemplateTable::tsan_observe_get_or_put(const Address &field,
                                             Register flags,
                                             TsanMemoryReadWriteFunction tsan_function,
                                             TosState tos) {
   assert(ThreadSanitizer, "ThreadSanitizer should be set");
@@ -778,10 +795,12 @@
   // access the object it's referring to and create a happens-before relation
   // between the accesses to this reference.
   if (tos == atos) {
     int32_t acquire_release_mask = 1 << ConstantPoolCacheEntry::is_volatile_shift |
       1 << ConstantPoolCacheEntry::is_tsan_ignore_shift;
+    // acquire_release_mask (0x8200000) can not be encoded into 'tst', but it can be
+    // encoded into just one 'mov' instruction.
     __ mov(rscratch1, acquire_release_mask);
     __ tst(flags, rscratch1);
     __ br(Assembler::EQ, notAcquireRelease);
   } else {
     __ tbz(flags, ConstantPoolCacheEntry::is_volatile_shift, notAcquireRelease);
@@ -822,11 +841,13 @@
   __ pop_ptr(r0);
   // r0: array
   // r1: index
   index_check(r0, r1); // leaves index in r1, kills rscratch1
   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_INT) >> 2);
-  __ access_load_at(T_INT, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(2)), noreg, noreg);
+  Address addr(r0, r1, Address::uxtw(2));
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read4));
+  __ access_load_at(T_INT, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);
 }
 
 void TemplateTable::laload()
 {
   transition(itos, ltos);
@@ -834,11 +855,13 @@
   __ pop_ptr(r0);
   // r0: array
   // r1: index
   index_check(r0, r1); // leaves index in r1, kills rscratch1
   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_LONG) >> 3);
-  __ access_load_at(T_LONG, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(3)), noreg, noreg);
+  Address addr(r0, r1, Address::uxtw(3));
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read8));
+  __ access_load_at(T_LONG, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);
 }
 
 void TemplateTable::faload()
 {
   transition(itos, ftos);
@@ -846,11 +869,13 @@
   __ pop_ptr(r0);
   // r0: array
   // r1: index
   index_check(r0, r1); // leaves index in r1, kills rscratch1
   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_FLOAT) >> 2);
-  __ access_load_at(T_FLOAT, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(2)), noreg, noreg);
+  Address addr(r0, r1, Address::uxtw(2));
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read4));
+  __ access_load_at(T_FLOAT, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);
 }
 
 void TemplateTable::daload()
 {
   transition(itos, dtos);
@@ -858,11 +883,13 @@
   __ pop_ptr(r0);
   // r0: array
   // r1: index
   index_check(r0, r1); // leaves index in r1, kills rscratch1
   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_DOUBLE) >> 3);
-  __ access_load_at(T_DOUBLE, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(3)), noreg, noreg);
+  Address addr(r0, r1, Address::uxtw(3));
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read8));
+  __ access_load_at(T_DOUBLE, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);
 }
 
 void TemplateTable::aaload()
 {
   transition(itos, atos);
@@ -870,14 +897,14 @@
   __ pop_ptr(r0);
   // r0: array
   // r1: index
   index_check(r0, r1); // leaves index in r1, kills rscratch1
   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_OBJECT) >> LogBytesPerHeapOop);
-  do_oop_load(_masm,
-              Address(r0, r1, Address::uxtw(LogBytesPerHeapOop)),
-              r0,
-              IS_ARRAY);
+  Address addr(r0, r1, Address::uxtw(LogBytesPerHeapOop));
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, UseCompressedOops ? SharedRuntime::tsan_read4
+                                                                       : SharedRuntime::tsan_read8));
+  do_oop_load(_masm, addr, r0, IS_ARRAY);
 }
 
 void TemplateTable::baload()
 {
   transition(itos, itos);
@@ -885,11 +912,13 @@
   __ pop_ptr(r0);
   // r0: array
   // r1: index
   index_check(r0, r1); // leaves index in r1, kills rscratch1
   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_BYTE) >> 0);
-  __ access_load_at(T_BYTE, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(0)), noreg, noreg);
+  Address addr(r0, r1, Address::uxtw(0));
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read1));
+  __ access_load_at(T_BYTE, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);
 }
 
 void TemplateTable::caload()
 {
   transition(itos, itos);
@@ -897,16 +926,21 @@
   __ pop_ptr(r0);
   // r0: array
   // r1: index
   index_check(r0, r1); // leaves index in r1, kills rscratch1
   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_CHAR) >> 1);
-  __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(1)), noreg, noreg);
+  Address addr(r0, r1, Address::uxtw(1));
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read2));
+  __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);
 }
 
 // iload followed by caload frequent pair
 void TemplateTable::fast_icaload()
 {
+#ifdef ASSERT
+  TSAN_RUNTIME_ONLY(__ stop("bytecode rewrite should have been disabled in TSAN"););
+#endif
   transition(vtos, itos);
   // load index out of locals
   locals_index(r2);
   __ ldr(r1, iaddress(r2));
 
@@ -926,11 +960,13 @@
   __ pop_ptr(r0);
   // r0: array
   // r1: index
   index_check(r0, r1); // leaves index in r1, kills rscratch1
   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_SHORT) >> 1);
-  __ access_load_at(T_SHORT, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(1)), noreg, noreg);
+  Address addr(r0, r1, Address::uxtw(1));
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_read2));
+  __ access_load_at(T_SHORT, IN_HEAP | IS_ARRAY, r0, addr, noreg, noreg);
 }
 
 void TemplateTable::iload(int n)
 {
   transition(vtos, itos);
@@ -1120,11 +1156,13 @@
   // r0: value
   // r1: index
   // r3: array
   index_check(r3, r1); // prefer index in r1
   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_INT) >> 2);
-  __ access_store_at(T_INT, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(2)), r0, noreg, noreg);
+  Address addr(r3, r1, Address::uxtw(2));
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write4));
+  __ access_store_at(T_INT, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);
 }
 
 void TemplateTable::lastore() {
   transition(ltos, vtos);
   __ pop_i(r1);
@@ -1132,11 +1170,13 @@
   // r0: value
   // r1: index
   // r3: array
   index_check(r3, r1); // prefer index in r1
   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_LONG) >> 3);
-  __ access_store_at(T_LONG, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(3)), r0, noreg, noreg);
+  Address addr(r3, r1, Address::uxtw(3));
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write8));
+  __ access_store_at(T_LONG, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);
 }
 
 void TemplateTable::fastore() {
   transition(ftos, vtos);
   __ pop_i(r1);
@@ -1144,11 +1184,13 @@
   // v0: value
   // r1:  index
   // r3:  array
   index_check(r3, r1); // prefer index in r1
   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_FLOAT) >> 2);
-  __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(2)), noreg /* ftos */, noreg, noreg);
+  Address addr(r3, r1, Address::uxtw(2));
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write4));
+  __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY, addr, noreg /* ftos */, noreg, noreg);
 }
 
 void TemplateTable::dastore() {
   transition(dtos, vtos);
   __ pop_i(r1);
@@ -1156,11 +1198,13 @@
   // v0: value
   // r1:  index
   // r3:  array
   index_check(r3, r1); // prefer index in r1
   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_DOUBLE) >> 3);
-  __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(3)), noreg /* dtos */, noreg, noreg);
+  Address addr(r3, r1, Address::uxtw(3));
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write8));
+  __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY, addr, noreg /* dtos */, noreg, noreg);
 }
 
 void TemplateTable::aastore() {
   Label is_null, ok_is_subtype, done;
   transition(vtos, vtos);
@@ -1171,11 +1215,13 @@
 
   Address element_address(r3, r4, Address::uxtw(LogBytesPerHeapOop));
 
   index_check(r3, r2);     // kills r1
   __ add(r4, r2, arrayOopDesc::base_offset_in_bytes(T_OBJECT) >> LogBytesPerHeapOop);
-
+  // do tsan write after r4 has been defined.
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(element_address, UseCompressedOops ? SharedRuntime::tsan_write4
+                                                                                  : SharedRuntime::tsan_write8));
   // do array store check - check for NULL value first
   __ cbz(r0, is_null);
 
   // Move subklass into r1
   __ load_klass(r1, r0);
@@ -1233,11 +1279,13 @@
   __ tbz(r2, diffbit_index, L_skip);
   __ andw(r0, r0, 1);  // if it is a T_BOOLEAN array, mask the stored value to 0/1
   __ bind(L_skip);
 
   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_BYTE) >> 0);
-  __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(0)), r0, noreg, noreg);
+  Address addr(r3, r1, Address::uxtw(0));
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write1));
+  __ access_store_at(T_BYTE, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);
 }
 
 void TemplateTable::castore()
 {
   transition(itos, vtos);
@@ -1246,11 +1294,13 @@
   // r0: value
   // r1: index
   // r3: array
   index_check(r3, r1); // prefer index in r1
   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_CHAR) >> 1);
-  __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY, Address(r3, r1, Address::uxtw(1)), r0, noreg, noreg);
+  Address addr(r3, r1, Address::uxtw(1));
+  TSAN_RUNTIME_ONLY(tsan_observe_load_or_store(addr, SharedRuntime::tsan_write2));
+  __ access_store_at(T_CHAR, IN_HEAP | IS_ARRAY, addr, r0, noreg, noreg);
 }
 
 void TemplateTable::sastore()
 {
   castore();
@@ -3147,10 +3197,13 @@
 }
 
 
 void TemplateTable::fast_accessfield(TosState state)
 {
+#ifdef ASSERT
+  TSAN_RUNTIME_ONLY(__ stop("bytecode rewrite should have been disabled in TSAN"););
+#endif
   transition(atos, state);
   // Do the JVMTI work here to avoid disturbing the register state below
   if (JvmtiExport::can_post_field_access()) {
     // Check to see if a field access watch has been set before we
     // take the time to call into the VM.
@@ -3236,10 +3289,13 @@
   }
 }
 
 void TemplateTable::fast_xaccess(TosState state)
 {
+#ifdef ASSERT
+  TSAN_RUNTIME_ONLY(__ stop("bytecode rewrite should have been disabled in TSAN"););
+#endif
   transition(vtos, state);
 
   // get receiver
   __ ldr(r0, aaddress(0));
   // access constant pool cache
