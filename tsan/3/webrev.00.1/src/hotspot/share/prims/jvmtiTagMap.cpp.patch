diff a/src/hotspot/share/prims/jvmtiTagMap.cpp b/src/hotspot/share/prims/jvmtiTagMap.cpp
--- a/src/hotspot/share/prims/jvmtiTagMap.cpp
+++ b/src/hotspot/share/prims/jvmtiTagMap.cpp
@@ -57,10 +57,13 @@
 #include "runtime/thread.inline.hpp"
 #include "runtime/threadSMR.hpp"
 #include "runtime/vframe.hpp"
 #include "runtime/vmThread.hpp"
 #include "runtime/vmOperations.hpp"
+#if INCLUDE_TSAN
+#include "tsan/tsan.hpp"
+#endif  // INCLUDE_TSAN
 #include "utilities/macros.hpp"
 #if INCLUDE_ZGC
 #include "gc/z/zGlobals.hpp"
 #endif
 
@@ -375,10 +378,26 @@
 
   // iterate over all entries in the hashmap
   void entry_iterate(JvmtiTagHashmapEntryClosure* closure);
 };
 
+// Tsan should know that the JVMTI TagMap is protected by a mutex.
+class TsanMutexScope : public StackObj {
+ private:
+  Mutex *_lock;  // Keep my own reference, for destructor.
+
+ public:
+  // Don't actually lock it, just tell tsan we did.
+  TsanMutexScope(Mutex* mutex) : _lock(mutex) {
+    TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(_lock));
+  }
+
+  ~TsanMutexScope() {
+    TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_RELEASED(_lock));
+  }
+};
+
 // possible hashmap sizes - odd primes that roughly double in size.
 // To avoid excessive resizing the odd primes from 4801-76831 and
 // 76831-307261 have been removed. The list must be terminated by -1.
 int JvmtiTagHashmap::_sizes[] =  { 4801, 76831, 307261, 614563, 1228891,
     2457733, 4915219, 9830479, 19660831, 39321619, 78643219, -1 };
@@ -443,20 +462,37 @@
   _free_entries_count(0)
 {
   assert(JvmtiThreadState_lock->is_locked(), "sanity check");
   assert(((JvmtiEnvBase *)env)->tag_map() == NULL, "tag map already exists for environment");
 
+  // TSAN Note: we cannot tell TSAN about the creation of this lock due to
+  // this being seen as racy though is not really.
+  //
+  // The JvmtiTagMap gets created by the first thread to call tag_map_for; which
+  // uses a lock to create it if need be.
+  //
+  // This means that this lock is created under a mutex but then,
+  // subsequent uses do not have a lock to protect it (because not
+  // needed in this case), however TSAN sees it as being needed because:
+  //  - Another thread can come and get the newly created JvmtiTagMap without a
+  //  lock and acquire the lock.
+  //  - This provokes a race for TSAN on the lock itself, though there is no
+  //  real issue.
+  //
+  //  Not creating the lock or having a fence mechanism to tell TSAN this is
+  //  safe (a fake lock around this lock for example) seem to be the only
+  //  solutions.
+
   _hashmap = new JvmtiTagHashmap();
 
   // finally add us to the environment
   ((JvmtiEnvBase *)env)->release_set_tag_map(this);
 }
 
 
 // destroy a JvmtiTagMap
 JvmtiTagMap::~JvmtiTagMap() {
-
   // no lock acquired as we assume the enclosing environment is
   // also being destroryed.
   ((JvmtiEnvBase *)_env)->set_tag_map(NULL);
 
   JvmtiTagHashmapEntry** table = _hashmap->table();
@@ -479,10 +515,12 @@
     JvmtiTagHashmapEntry* next = entry->next();
     delete entry;
     entry = next;
   }
   _free_entries = NULL;
+
+  // TSAN Note: see above for the Tsan creation note.
 }
 
 // create a hashmap entry
 // - if there's an entry on the (per-environment) free list then this
 // is returned. Otherwise an new entry is allocated.
@@ -730,10 +768,11 @@
 // This function is performance critical. If many threads attempt to tag objects
 // around the same time then it's possible that the Mutex associated with the
 // tag map will be a hot lock.
 void JvmtiTagMap::set_tag(jobject object, jlong tag) {
   MutexLocker ml(lock());
+  TSAN_ONLY(TsanMutexScope tms(lock()));
 
   // resolve the object
   oop o = JNIHandles::resolve_non_null(object);
 
   // see if the object is already tagged
@@ -762,10 +801,11 @@
 }
 
 // get the tag for an object
 jlong JvmtiTagMap::get_tag(jobject object) {
   MutexLocker ml(lock());
+  TSAN_ONLY(TsanMutexScope tms(lock()));
 
   // resolve the object
   oop o = JNIHandles::resolve_non_null(object);
 
   return tag_for(this, o);
@@ -1261,15 +1301,26 @@
 // VM operation to iterate over all objects in the heap (both reachable
 // and unreachable)
 class VM_HeapIterateOperation: public VM_Operation {
  private:
   ObjectClosure* _blk;
+  JvmtiTagMap* _tag_map;
+
  public:
-  VM_HeapIterateOperation(ObjectClosure* blk) { _blk = blk; }
+  VM_HeapIterateOperation(ObjectClosure* blk, JvmtiTagMap* tag_map) {
+    _blk = blk;
+    _tag_map = tag_map;
+  }
 
   VMOp_Type type() const { return VMOp_HeapIterateOperation; }
   void doit() {
+    // Simulates barrier synchronization on safepoint.
+    // This annotation is reasonably minimal in number of tsan callbacks.
+    // By passing the lock directly, we are not actually locking it, just
+    // telling TSAN we are to "simulate" the lock.
+    TSAN_ONLY(TsanMutexScope tms(_tag_map->lock()));
+
     // allows class files maps to be cached during iteration
     ClassFieldMapCacheMark cm;
 
     // make sure that heap is parsable (fills TLABs with filler objects)
     Universe::heap()->ensure_parsability(false);  // no need to retire TLABs
@@ -1492,11 +1543,11 @@
   IterateOverHeapObjectClosure blk(this,
                                    klass,
                                    object_filter,
                                    heap_object_callback,
                                    user_data);
-  VM_HeapIterateOperation op(&blk);
+  VM_HeapIterateOperation op(&blk, this);
   VMThread::execute(&op);
 }
 
 
 // Iterates over all objects in the heap
@@ -1509,11 +1560,11 @@
   IterateThroughHeapObjectClosure blk(this,
                                       klass,
                                       heap_filter,
                                       callbacks,
                                       user_data);
-  VM_HeapIterateOperation op(&blk);
+  VM_HeapIterateOperation op(&blk, this);
   VMThread::execute(&op);
 }
 
 // support class for get_objects_with_tags
 
@@ -1605,10 +1656,11 @@
 
   TagObjectCollector collector(env(), tags, count);
   {
     // iterate over all tagged objects
     MutexLocker ml(lock());
+    TSAN_ONLY(TsanMutexScope tms(lock()));
     entry_iterate(&collector);
   }
   return collector.result(count_ptr, object_result_ptr, tag_result_ptr);
 }
 
@@ -3220,10 +3272,15 @@
 
   return true;
 }
 
 void VM_HeapWalkOperation::doit() {
+  // This annotation is reasonably minimal in number of tsan callbacks.
+  // By passing the lock directly, we are not actually locking it, just
+  // telling TSAN we are to "simulate" the lock.
+  TSAN_ONLY(TsanMutexScope tms(_tag_map->lock()));
+
   ResourceMark rm;
   ObjectMarkerController marker;
   ClassFieldMapCacheMark cm;
 
   assert(visit_stack()->is_empty(), "visit stack must be empty");
