<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="interp_masm_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="templateTable_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2003, 2018, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #ifndef _WINDOWS
  27 #include &quot;alloca.h&quot;
  28 #endif
  29 #include &quot;asm/macroAssembler.hpp&quot;
  30 #include &quot;asm/macroAssembler.inline.hpp&quot;
  31 #include &quot;code/debugInfoRec.hpp&quot;
  32 #include &quot;code/icBuffer.hpp&quot;
  33 #include &quot;code/nativeInst.hpp&quot;
  34 #include &quot;code/vtableStubs.hpp&quot;
  35 #include &quot;gc/shared/collectedHeap.hpp&quot;
  36 #include &quot;gc/shared/gcLocker.hpp&quot;
  37 #include &quot;gc/shared/barrierSet.hpp&quot;
  38 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  39 #include &quot;interpreter/interpreter.hpp&quot;
  40 #include &quot;logging/log.hpp&quot;
  41 #include &quot;memory/resourceArea.hpp&quot;

  42 #include &quot;oops/compiledICHolder.hpp&quot;

  43 #include &quot;runtime/safepointMechanism.hpp&quot;
  44 #include &quot;runtime/sharedRuntime.hpp&quot;
  45 #include &quot;runtime/vframeArray.hpp&quot;

  46 #include &quot;utilities/align.hpp&quot;
  47 #include &quot;utilities/formatBuffer.hpp&quot;
<span class="line-removed">  48 #include &quot;vm_version_x86.hpp&quot;</span>
  49 #include &quot;vmreg_x86.inline.hpp&quot;
  50 #ifdef COMPILER1
  51 #include &quot;c1/c1_Runtime1.hpp&quot;
  52 #endif
  53 #ifdef COMPILER2
  54 #include &quot;opto/runtime.hpp&quot;
  55 #endif
  56 #if INCLUDE_JVMCI
  57 #include &quot;jvmci/jvmciJavaClasses.hpp&quot;
  58 #endif
  59 
  60 #define __ masm-&gt;
  61 
  62 const int StackAlignmentInSlots = StackAlignmentInBytes / VMRegImpl::stack_slot_size;
  63 
  64 class SimpleRuntimeFrame {
  65 
  66   public:
  67 
  68   // Most of the runtime stubs have this simple frame layout.
</pre>
<hr />
<pre>
 953   Register temp = rbx;
 954 
 955   {
 956     __ load_klass(temp, receiver);
 957     __ cmpptr(temp, Address(holder, CompiledICHolder::holder_klass_offset()));
 958     __ movptr(rbx, Address(holder, CompiledICHolder::holder_metadata_offset()));
 959     __ jcc(Assembler::equal, ok);
 960     __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 961 
 962     __ bind(ok);
 963     // Method might have been compiled since the call site was patched to
 964     // interpreted if that is the case treat it as a miss so we can get
 965     // the call site corrected.
 966     __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), (int32_t)NULL_WORD);
 967     __ jcc(Assembler::equal, skip_fixup);
 968     __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 969   }
 970 
 971   address c2i_entry = __ pc();
 972 


























 973   gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);
 974 
 975   __ flush();
<span class="line-modified"> 976   return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry);</span>
 977 }
 978 
 979 int SharedRuntime::c_calling_convention(const BasicType *sig_bt,
 980                                          VMRegPair *regs,
 981                                          VMRegPair *regs2,
 982                                          int total_args_passed) {
 983   assert(regs2 == NULL, &quot;not needed on x86&quot;);
 984 // We return the amount of VMRegImpl stack slots we need to reserve for all
 985 // the arguments NOT counting out_preserve_stack_slots.
 986 
 987 // NOTE: These arrays will have to change when c1 is ported
 988 #ifdef _WIN64
 989     static const Register INT_ArgReg[Argument::n_int_register_parameters_c] = {
 990       c_rarg0, c_rarg1, c_rarg2, c_rarg3
 991     };
 992     static const XMMRegister FP_ArgReg[Argument::n_float_register_parameters_c] = {
 993       c_farg0, c_farg1, c_farg2, c_farg3
 994     };
 995 #else
 996     static const Register INT_ArgReg[Argument::n_int_register_parameters_c] = {
</pre>
<hr />
<pre>
1772         }
1773         // walk the chain forward inserting to store list
1774         while (start != NULL) {
1775           stores-&gt;append(start);
1776           start-&gt;set_processed();
1777           start = start-&gt;next();
1778         }
1779       }
1780     }
1781     return stores;
1782   }
1783 };
1784 
1785 static void verify_oop_args(MacroAssembler* masm,
1786                             const methodHandle&amp; method,
1787                             const BasicType* sig_bt,
1788                             const VMRegPair* regs) {
1789   Register temp_reg = rbx;  // not part of any compiled calling seq
1790   if (VerifyOops) {
1791     for (int i = 0; i &lt; method-&gt;size_of_parameters(); i++) {
<span class="line-modified">1792       if (sig_bt[i] == T_OBJECT ||</span>
<span class="line-removed">1793           sig_bt[i] == T_ARRAY) {</span>
1794         VMReg r = regs[i].first();
1795         assert(r-&gt;is_valid(), &quot;bad oop arg&quot;);
1796         if (r-&gt;is_stack()) {
1797           __ movptr(temp_reg, Address(rsp, r-&gt;reg2stack() * VMRegImpl::stack_slot_size + wordSize));
1798           __ verify_oop(temp_reg);
1799         } else {
1800           __ verify_oop(r-&gt;as_Register());
1801         }
1802       }
1803     }
1804   }
1805 }
1806 
1807 static void gen_special_dispatch(MacroAssembler* masm,
1808                                  const methodHandle&amp; method,
1809                                  const BasicType* sig_bt,
1810                                  const VMRegPair* regs) {
1811   verify_oop_args(masm, method, sig_bt, regs);
1812   vmIntrinsics::ID iid = method-&gt;intrinsic_id();
1813 
</pre>
<hr />
<pre>
1880 // block and the check for pending exceptions it&#39;s impossible for them
1881 // to be thrown.
1882 //
1883 // They are roughly structured like this:
1884 //    if (GCLocker::needs_gc())
1885 //      SharedRuntime::block_for_jni_critical();
1886 //    tranistion to thread_in_native
1887 //    unpack arrray arguments and call native entry point
1888 //    check for safepoint in progress
1889 //    check if any thread suspend flags are set
1890 //      call into JVM and possible unlock the JNI critical
1891 //      if a GC was suppressed while in the critical native.
1892 //    transition back to thread_in_Java
1893 //    return to caller
1894 //
1895 nmethod* SharedRuntime::generate_native_wrapper(MacroAssembler* masm,
1896                                                 const methodHandle&amp; method,
1897                                                 int compile_id,
1898                                                 BasicType* in_sig_bt,
1899                                                 VMRegPair* in_regs,
<span class="line-modified">1900                                                 BasicType ret_type) {</span>

1901   if (method-&gt;is_method_handle_intrinsic()) {
1902     vmIntrinsics::ID iid = method-&gt;intrinsic_id();
1903     intptr_t start = (intptr_t)__ pc();
1904     int vep_offset = ((intptr_t)__ pc()) - start;
1905     gen_special_dispatch(masm,
1906                          method,
1907                          in_sig_bt,
1908                          in_regs);
1909     int frame_complete = ((intptr_t)__ pc()) - start;  // not complete, period
1910     __ flush();
1911     int stack_slots = SharedRuntime::out_preserve_stack_slots();  // no out slots at all, actually
1912     return nmethod::new_native_nmethod(method,
1913                                        compile_id,
1914                                        masm-&gt;code(),
1915                                        vep_offset,
1916                                        frame_complete,
1917                                        stack_slots / VMRegImpl::slots_per_word,
1918                                        in_ByteSize(-1),
1919                                        in_ByteSize(-1),
1920                                        (OopMapSet*)NULL);
1921   }
1922   bool is_critical_native = true;
<span class="line-modified">1923   address native_func = method-&gt;critical_native_function();</span>
1924   if (native_func == NULL) {
1925     native_func = method-&gt;native_function();
1926     is_critical_native = false;
1927   }
1928   assert(native_func != NULL, &quot;must have function&quot;);
1929 
1930   // An OopMap for lock (and class if static)
1931   OopMapSet *oop_maps = new OopMapSet();
1932   intptr_t start = (intptr_t)__ pc();
1933 
1934   // We have received a description of where all the java arg are located
1935   // on entry to the wrapper. We need to convert these args to where
1936   // the jni function will expect them. To figure out where they go
1937   // we convert the java signature to a C signature by inserting
1938   // the hidden arguments as arg[0] and possibly arg[1] (static method)
1939 
1940   const int total_in_args = method-&gt;size_of_parameters();
1941   int total_c_args = total_in_args;
1942   if (!is_critical_native) {
1943     total_c_args += 1;
</pre>
<hr />
<pre>
1950         total_c_args++;
1951       }
1952     }
1953   }
1954 
1955   BasicType* out_sig_bt = NEW_RESOURCE_ARRAY(BasicType, total_c_args);
1956   VMRegPair* out_regs   = NEW_RESOURCE_ARRAY(VMRegPair, total_c_args);
1957   BasicType* in_elem_bt = NULL;
1958 
1959   int argc = 0;
1960   if (!is_critical_native) {
1961     out_sig_bt[argc++] = T_ADDRESS;
1962     if (method-&gt;is_static()) {
1963       out_sig_bt[argc++] = T_OBJECT;
1964     }
1965 
1966     for (int i = 0; i &lt; total_in_args ; i++ ) {
1967       out_sig_bt[argc++] = in_sig_bt[i];
1968     }
1969   } else {
<span class="line-removed">1970     Thread* THREAD = Thread::current();</span>
1971     in_elem_bt = NEW_RESOURCE_ARRAY(BasicType, total_in_args);
1972     SignatureStream ss(method-&gt;signature());
1973     for (int i = 0; i &lt; total_in_args ; i++ ) {
1974       if (in_sig_bt[i] == T_ARRAY) {
1975         // Arrays are passed as int, elem* pair
1976         out_sig_bt[argc++] = T_INT;
1977         out_sig_bt[argc++] = T_ADDRESS;
<span class="line-modified">1978         Symbol* atype = ss.as_symbol(CHECK_NULL);</span>
<span class="line-modified">1979         const char* at = atype-&gt;as_C_string();</span>
<span class="line-modified">1980         if (strlen(at) == 2) {</span>
<span class="line-removed">1981           assert(at[0] == &#39;[&#39;, &quot;must be&quot;);</span>
<span class="line-removed">1982           switch (at[1]) {</span>
<span class="line-removed">1983             case &#39;B&#39;: in_elem_bt[i]  = T_BYTE; break;</span>
<span class="line-removed">1984             case &#39;C&#39;: in_elem_bt[i]  = T_CHAR; break;</span>
<span class="line-removed">1985             case &#39;D&#39;: in_elem_bt[i]  = T_DOUBLE; break;</span>
<span class="line-removed">1986             case &#39;F&#39;: in_elem_bt[i]  = T_FLOAT; break;</span>
<span class="line-removed">1987             case &#39;I&#39;: in_elem_bt[i]  = T_INT; break;</span>
<span class="line-removed">1988             case &#39;J&#39;: in_elem_bt[i]  = T_LONG; break;</span>
<span class="line-removed">1989             case &#39;S&#39;: in_elem_bt[i]  = T_SHORT; break;</span>
<span class="line-removed">1990             case &#39;Z&#39;: in_elem_bt[i]  = T_BOOLEAN; break;</span>
<span class="line-removed">1991             default: ShouldNotReachHere();</span>
<span class="line-removed">1992           }</span>
<span class="line-removed">1993         }</span>
1994       } else {
1995         out_sig_bt[argc++] = in_sig_bt[i];
1996         in_elem_bt[i] = T_VOID;
1997       }
1998       if (in_sig_bt[i] != T_VOID) {
<span class="line-modified">1999         assert(in_sig_bt[i] == ss.type(), &quot;must match&quot;);</span>

2000         ss.next();
2001       }
2002     }
2003   }
2004 
2005   // Now figure out where the args must be stored and how much stack space
2006   // they require.
2007   int out_arg_slots;
2008   out_arg_slots = c_calling_convention(out_sig_bt, out_regs, NULL, total_c_args);
2009 
2010   // Compute framesize for the wrapper.  We need to handlize all oops in
2011   // incoming registers
2012 
2013   // Calculate the total number of stack slots we will need.
2014 
2015   // First count the abi requirement plus all of the outgoing args
2016   int stack_slots = SharedRuntime::out_preserve_stack_slots() + out_arg_slots;
2017 
2018   // Now the space for the inbound oop handle area
2019   int total_save_slots = 6 * VMRegImpl::slots_per_word;  // 6 arguments passed in registers
</pre>
<hr />
<pre>
2120   const Register receiver = j_rarg0;
2121 
2122   Label hit;
2123   Label exception_pending;
2124 
2125   assert_different_registers(ic_reg, receiver, rscratch1);
2126   __ verify_oop(receiver);
2127   __ load_klass(rscratch1, receiver);
2128   __ cmpq(ic_reg, rscratch1);
2129   __ jcc(Assembler::equal, hit);
2130 
2131   __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
2132 
2133   // Verified entry point must be aligned
2134   __ align(8);
2135 
2136   __ bind(hit);
2137 
2138   int vep_offset = ((intptr_t)__ pc()) - start;
2139 











2140 #ifdef COMPILER1
2141   // For Object.hashCode, System.identityHashCode try to pull hashCode from object header if available.
2142   if ((InlineObjectHash &amp;&amp; method-&gt;intrinsic_id() == vmIntrinsics::_hashCode) || (method-&gt;intrinsic_id() == vmIntrinsics::_identityHashCode)) {
2143     inline_check_hashcode_from_object_header(masm, method, j_rarg0 /*obj_reg*/, rax /*result*/);
2144   }
2145 #endif // COMPILER1
2146 
2147   // The instruction at the verified entry point must be 5 bytes or longer
2148   // because it can be patched on the fly by make_non_entrant. The stack bang
2149   // instruction fits that requirement.
2150 
2151   // Generate stack overflow check
2152 
2153   if (UseStackBanging) {
2154     __ bang_stack_with_offset((int)JavaThread::stack_shadow_zone_size());
2155   } else {
2156     // need a 5 byte instruction to allow MT safe patching to non-entrant
2157     __ fat_nop();
2158   }
2159 
</pre>
<hr />
<pre>
2695   TSAN_RUNTIME_ONLY(
2696     save_native_result(masm, ret_type, stack_slots);
2697     __ call_VM_leaf(
2698          CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_method_exit));
2699     restore_native_result(masm, ret_type, stack_slots);
2700   );
2701 
2702   {
2703     SkipIfEqual skip(masm, &amp;DTraceMethodProbes, false);
2704     save_native_result(masm, ret_type, stack_slots);
2705     __ mov_metadata(c_rarg1, method());
2706     __ call_VM_leaf(
2707          CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_method_exit),
2708          r15_thread, c_rarg1);
2709     restore_native_result(masm, ret_type, stack_slots);
2710   }
2711 
2712   __ reset_last_Java_frame(false);
2713 
2714   // Unbox oop result, e.g. JNIHandles::resolve value.
<span class="line-modified">2715   if (ret_type == T_OBJECT || ret_type == T_ARRAY) {</span>
2716     __ resolve_jobject(rax /* value */,
2717                        r15_thread /* thread */,
2718                        rcx /* tmp */);
2719   }
2720 
2721   if (CheckJNICalls) {
2722     // clear_pending_jni_exception_check
2723     __ movptr(Address(r15_thread, JavaThread::pending_jni_exception_check_fn_offset()), NULL_WORD);
2724   }
2725 
2726   if (!is_critical_native) {
2727     // reset handle block
2728     __ movptr(rcx, Address(r15_thread, JavaThread::active_handles_offset()));
2729     __ movl(Address(rcx, JNIHandleBlock::top_offset_in_bytes()), (int32_t)NULL_WORD);
2730   }
2731 
2732   // pop our frame
2733 
2734   __ leave();
2735 
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #ifndef _WINDOWS
  27 #include &quot;alloca.h&quot;
  28 #endif
  29 #include &quot;asm/macroAssembler.hpp&quot;
  30 #include &quot;asm/macroAssembler.inline.hpp&quot;
  31 #include &quot;code/debugInfoRec.hpp&quot;
  32 #include &quot;code/icBuffer.hpp&quot;
  33 #include &quot;code/nativeInst.hpp&quot;
  34 #include &quot;code/vtableStubs.hpp&quot;
  35 #include &quot;gc/shared/collectedHeap.hpp&quot;
  36 #include &quot;gc/shared/gcLocker.hpp&quot;
  37 #include &quot;gc/shared/barrierSet.hpp&quot;
  38 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  39 #include &quot;interpreter/interpreter.hpp&quot;
  40 #include &quot;logging/log.hpp&quot;
  41 #include &quot;memory/resourceArea.hpp&quot;
<span class="line-added">  42 #include &quot;memory/universe.hpp&quot;</span>
  43 #include &quot;oops/compiledICHolder.hpp&quot;
<span class="line-added">  44 #include &quot;oops/klass.inline.hpp&quot;</span>
  45 #include &quot;runtime/safepointMechanism.hpp&quot;
  46 #include &quot;runtime/sharedRuntime.hpp&quot;
  47 #include &quot;runtime/vframeArray.hpp&quot;
<span class="line-added">  48 #include &quot;runtime/vm_version.hpp&quot;</span>
  49 #include &quot;utilities/align.hpp&quot;
  50 #include &quot;utilities/formatBuffer.hpp&quot;

  51 #include &quot;vmreg_x86.inline.hpp&quot;
  52 #ifdef COMPILER1
  53 #include &quot;c1/c1_Runtime1.hpp&quot;
  54 #endif
  55 #ifdef COMPILER2
  56 #include &quot;opto/runtime.hpp&quot;
  57 #endif
  58 #if INCLUDE_JVMCI
  59 #include &quot;jvmci/jvmciJavaClasses.hpp&quot;
  60 #endif
  61 
  62 #define __ masm-&gt;
  63 
  64 const int StackAlignmentInSlots = StackAlignmentInBytes / VMRegImpl::stack_slot_size;
  65 
  66 class SimpleRuntimeFrame {
  67 
  68   public:
  69 
  70   // Most of the runtime stubs have this simple frame layout.
</pre>
<hr />
<pre>
 955   Register temp = rbx;
 956 
 957   {
 958     __ load_klass(temp, receiver);
 959     __ cmpptr(temp, Address(holder, CompiledICHolder::holder_klass_offset()));
 960     __ movptr(rbx, Address(holder, CompiledICHolder::holder_metadata_offset()));
 961     __ jcc(Assembler::equal, ok);
 962     __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 963 
 964     __ bind(ok);
 965     // Method might have been compiled since the call site was patched to
 966     // interpreted if that is the case treat it as a miss so we can get
 967     // the call site corrected.
 968     __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), (int32_t)NULL_WORD);
 969     __ jcc(Assembler::equal, skip_fixup);
 970     __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 971   }
 972 
 973   address c2i_entry = __ pc();
 974 
<span class="line-added"> 975   // Class initialization barrier for static methods</span>
<span class="line-added"> 976   address c2i_no_clinit_check_entry = NULL;</span>
<span class="line-added"> 977   if (VM_Version::supports_fast_class_init_checks()) {</span>
<span class="line-added"> 978     Label L_skip_barrier;</span>
<span class="line-added"> 979     Register method = rbx;</span>
<span class="line-added"> 980 </span>
<span class="line-added"> 981     { // Bypass the barrier for non-static methods</span>
<span class="line-added"> 982       Register flags  = rscratch1;</span>
<span class="line-added"> 983       __ movl(flags, Address(method, Method::access_flags_offset()));</span>
<span class="line-added"> 984       __ testl(flags, JVM_ACC_STATIC);</span>
<span class="line-added"> 985       __ jcc(Assembler::zero, L_skip_barrier); // non-static</span>
<span class="line-added"> 986     }</span>
<span class="line-added"> 987 </span>
<span class="line-added"> 988     Register klass = rscratch1;</span>
<span class="line-added"> 989     __ load_method_holder(klass, method);</span>
<span class="line-added"> 990     __ clinit_barrier(klass, r15_thread, &amp;L_skip_barrier /*L_fast_path*/);</span>
<span class="line-added"> 991 </span>
<span class="line-added"> 992     __ jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub())); // slow path</span>
<span class="line-added"> 993 </span>
<span class="line-added"> 994     __ bind(L_skip_barrier);</span>
<span class="line-added"> 995     c2i_no_clinit_check_entry = __ pc();</span>
<span class="line-added"> 996   }</span>
<span class="line-added"> 997 </span>
<span class="line-added"> 998   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="line-added"> 999   bs-&gt;c2i_entry_barrier(masm);</span>
<span class="line-added">1000 </span>
1001   gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);
1002 
1003   __ flush();
<span class="line-modified">1004   return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);</span>
1005 }
1006 
1007 int SharedRuntime::c_calling_convention(const BasicType *sig_bt,
1008                                          VMRegPair *regs,
1009                                          VMRegPair *regs2,
1010                                          int total_args_passed) {
1011   assert(regs2 == NULL, &quot;not needed on x86&quot;);
1012 // We return the amount of VMRegImpl stack slots we need to reserve for all
1013 // the arguments NOT counting out_preserve_stack_slots.
1014 
1015 // NOTE: These arrays will have to change when c1 is ported
1016 #ifdef _WIN64
1017     static const Register INT_ArgReg[Argument::n_int_register_parameters_c] = {
1018       c_rarg0, c_rarg1, c_rarg2, c_rarg3
1019     };
1020     static const XMMRegister FP_ArgReg[Argument::n_float_register_parameters_c] = {
1021       c_farg0, c_farg1, c_farg2, c_farg3
1022     };
1023 #else
1024     static const Register INT_ArgReg[Argument::n_int_register_parameters_c] = {
</pre>
<hr />
<pre>
1800         }
1801         // walk the chain forward inserting to store list
1802         while (start != NULL) {
1803           stores-&gt;append(start);
1804           start-&gt;set_processed();
1805           start = start-&gt;next();
1806         }
1807       }
1808     }
1809     return stores;
1810   }
1811 };
1812 
1813 static void verify_oop_args(MacroAssembler* masm,
1814                             const methodHandle&amp; method,
1815                             const BasicType* sig_bt,
1816                             const VMRegPair* regs) {
1817   Register temp_reg = rbx;  // not part of any compiled calling seq
1818   if (VerifyOops) {
1819     for (int i = 0; i &lt; method-&gt;size_of_parameters(); i++) {
<span class="line-modified">1820       if (is_reference_type(sig_bt[i])) {</span>

1821         VMReg r = regs[i].first();
1822         assert(r-&gt;is_valid(), &quot;bad oop arg&quot;);
1823         if (r-&gt;is_stack()) {
1824           __ movptr(temp_reg, Address(rsp, r-&gt;reg2stack() * VMRegImpl::stack_slot_size + wordSize));
1825           __ verify_oop(temp_reg);
1826         } else {
1827           __ verify_oop(r-&gt;as_Register());
1828         }
1829       }
1830     }
1831   }
1832 }
1833 
1834 static void gen_special_dispatch(MacroAssembler* masm,
1835                                  const methodHandle&amp; method,
1836                                  const BasicType* sig_bt,
1837                                  const VMRegPair* regs) {
1838   verify_oop_args(masm, method, sig_bt, regs);
1839   vmIntrinsics::ID iid = method-&gt;intrinsic_id();
1840 
</pre>
<hr />
<pre>
1907 // block and the check for pending exceptions it&#39;s impossible for them
1908 // to be thrown.
1909 //
1910 // They are roughly structured like this:
1911 //    if (GCLocker::needs_gc())
1912 //      SharedRuntime::block_for_jni_critical();
1913 //    tranistion to thread_in_native
1914 //    unpack arrray arguments and call native entry point
1915 //    check for safepoint in progress
1916 //    check if any thread suspend flags are set
1917 //      call into JVM and possible unlock the JNI critical
1918 //      if a GC was suppressed while in the critical native.
1919 //    transition back to thread_in_Java
1920 //    return to caller
1921 //
1922 nmethod* SharedRuntime::generate_native_wrapper(MacroAssembler* masm,
1923                                                 const methodHandle&amp; method,
1924                                                 int compile_id,
1925                                                 BasicType* in_sig_bt,
1926                                                 VMRegPair* in_regs,
<span class="line-modified">1927                                                 BasicType ret_type,</span>
<span class="line-added">1928                                                 address critical_entry) {</span>
1929   if (method-&gt;is_method_handle_intrinsic()) {
1930     vmIntrinsics::ID iid = method-&gt;intrinsic_id();
1931     intptr_t start = (intptr_t)__ pc();
1932     int vep_offset = ((intptr_t)__ pc()) - start;
1933     gen_special_dispatch(masm,
1934                          method,
1935                          in_sig_bt,
1936                          in_regs);
1937     int frame_complete = ((intptr_t)__ pc()) - start;  // not complete, period
1938     __ flush();
1939     int stack_slots = SharedRuntime::out_preserve_stack_slots();  // no out slots at all, actually
1940     return nmethod::new_native_nmethod(method,
1941                                        compile_id,
1942                                        masm-&gt;code(),
1943                                        vep_offset,
1944                                        frame_complete,
1945                                        stack_slots / VMRegImpl::slots_per_word,
1946                                        in_ByteSize(-1),
1947                                        in_ByteSize(-1),
1948                                        (OopMapSet*)NULL);
1949   }
1950   bool is_critical_native = true;
<span class="line-modified">1951   address native_func = critical_entry;</span>
1952   if (native_func == NULL) {
1953     native_func = method-&gt;native_function();
1954     is_critical_native = false;
1955   }
1956   assert(native_func != NULL, &quot;must have function&quot;);
1957 
1958   // An OopMap for lock (and class if static)
1959   OopMapSet *oop_maps = new OopMapSet();
1960   intptr_t start = (intptr_t)__ pc();
1961 
1962   // We have received a description of where all the java arg are located
1963   // on entry to the wrapper. We need to convert these args to where
1964   // the jni function will expect them. To figure out where they go
1965   // we convert the java signature to a C signature by inserting
1966   // the hidden arguments as arg[0] and possibly arg[1] (static method)
1967 
1968   const int total_in_args = method-&gt;size_of_parameters();
1969   int total_c_args = total_in_args;
1970   if (!is_critical_native) {
1971     total_c_args += 1;
</pre>
<hr />
<pre>
1978         total_c_args++;
1979       }
1980     }
1981   }
1982 
1983   BasicType* out_sig_bt = NEW_RESOURCE_ARRAY(BasicType, total_c_args);
1984   VMRegPair* out_regs   = NEW_RESOURCE_ARRAY(VMRegPair, total_c_args);
1985   BasicType* in_elem_bt = NULL;
1986 
1987   int argc = 0;
1988   if (!is_critical_native) {
1989     out_sig_bt[argc++] = T_ADDRESS;
1990     if (method-&gt;is_static()) {
1991       out_sig_bt[argc++] = T_OBJECT;
1992     }
1993 
1994     for (int i = 0; i &lt; total_in_args ; i++ ) {
1995       out_sig_bt[argc++] = in_sig_bt[i];
1996     }
1997   } else {

1998     in_elem_bt = NEW_RESOURCE_ARRAY(BasicType, total_in_args);
1999     SignatureStream ss(method-&gt;signature());
2000     for (int i = 0; i &lt; total_in_args ; i++ ) {
2001       if (in_sig_bt[i] == T_ARRAY) {
2002         // Arrays are passed as int, elem* pair
2003         out_sig_bt[argc++] = T_INT;
2004         out_sig_bt[argc++] = T_ADDRESS;
<span class="line-modified">2005         ss.skip_array_prefix(1);  // skip one &#39;[&#39;</span>
<span class="line-modified">2006         assert(ss.is_primitive(), &quot;primitive type expected&quot;);</span>
<span class="line-modified">2007         in_elem_bt[i] = ss.type();</span>













2008       } else {
2009         out_sig_bt[argc++] = in_sig_bt[i];
2010         in_elem_bt[i] = T_VOID;
2011       }
2012       if (in_sig_bt[i] != T_VOID) {
<span class="line-modified">2013         assert(in_sig_bt[i] == ss.type() ||</span>
<span class="line-added">2014                in_sig_bt[i] == T_ARRAY, &quot;must match&quot;);</span>
2015         ss.next();
2016       }
2017     }
2018   }
2019 
2020   // Now figure out where the args must be stored and how much stack space
2021   // they require.
2022   int out_arg_slots;
2023   out_arg_slots = c_calling_convention(out_sig_bt, out_regs, NULL, total_c_args);
2024 
2025   // Compute framesize for the wrapper.  We need to handlize all oops in
2026   // incoming registers
2027 
2028   // Calculate the total number of stack slots we will need.
2029 
2030   // First count the abi requirement plus all of the outgoing args
2031   int stack_slots = SharedRuntime::out_preserve_stack_slots() + out_arg_slots;
2032 
2033   // Now the space for the inbound oop handle area
2034   int total_save_slots = 6 * VMRegImpl::slots_per_word;  // 6 arguments passed in registers
</pre>
<hr />
<pre>
2135   const Register receiver = j_rarg0;
2136 
2137   Label hit;
2138   Label exception_pending;
2139 
2140   assert_different_registers(ic_reg, receiver, rscratch1);
2141   __ verify_oop(receiver);
2142   __ load_klass(rscratch1, receiver);
2143   __ cmpq(ic_reg, rscratch1);
2144   __ jcc(Assembler::equal, hit);
2145 
2146   __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
2147 
2148   // Verified entry point must be aligned
2149   __ align(8);
2150 
2151   __ bind(hit);
2152 
2153   int vep_offset = ((intptr_t)__ pc()) - start;
2154 
<span class="line-added">2155   if (VM_Version::supports_fast_class_init_checks() &amp;&amp; method-&gt;needs_clinit_barrier()) {</span>
<span class="line-added">2156     Label L_skip_barrier;</span>
<span class="line-added">2157     Register klass = r10;</span>
<span class="line-added">2158     __ mov_metadata(klass, method-&gt;method_holder()); // InstanceKlass*</span>
<span class="line-added">2159     __ clinit_barrier(klass, r15_thread, &amp;L_skip_barrier /*L_fast_path*/);</span>
<span class="line-added">2160 </span>
<span class="line-added">2161     __ jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub())); // slow path</span>
<span class="line-added">2162 </span>
<span class="line-added">2163     __ bind(L_skip_barrier);</span>
<span class="line-added">2164   }</span>
<span class="line-added">2165 </span>
2166 #ifdef COMPILER1
2167   // For Object.hashCode, System.identityHashCode try to pull hashCode from object header if available.
2168   if ((InlineObjectHash &amp;&amp; method-&gt;intrinsic_id() == vmIntrinsics::_hashCode) || (method-&gt;intrinsic_id() == vmIntrinsics::_identityHashCode)) {
2169     inline_check_hashcode_from_object_header(masm, method, j_rarg0 /*obj_reg*/, rax /*result*/);
2170   }
2171 #endif // COMPILER1
2172 
2173   // The instruction at the verified entry point must be 5 bytes or longer
2174   // because it can be patched on the fly by make_non_entrant. The stack bang
2175   // instruction fits that requirement.
2176 
2177   // Generate stack overflow check
2178 
2179   if (UseStackBanging) {
2180     __ bang_stack_with_offset((int)JavaThread::stack_shadow_zone_size());
2181   } else {
2182     // need a 5 byte instruction to allow MT safe patching to non-entrant
2183     __ fat_nop();
2184   }
2185 
</pre>
<hr />
<pre>
2721   TSAN_RUNTIME_ONLY(
2722     save_native_result(masm, ret_type, stack_slots);
2723     __ call_VM_leaf(
2724          CAST_FROM_FN_PTR(address, SharedRuntime::tsan_interp_method_exit));
2725     restore_native_result(masm, ret_type, stack_slots);
2726   );
2727 
2728   {
2729     SkipIfEqual skip(masm, &amp;DTraceMethodProbes, false);
2730     save_native_result(masm, ret_type, stack_slots);
2731     __ mov_metadata(c_rarg1, method());
2732     __ call_VM_leaf(
2733          CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_method_exit),
2734          r15_thread, c_rarg1);
2735     restore_native_result(masm, ret_type, stack_slots);
2736   }
2737 
2738   __ reset_last_Java_frame(false);
2739 
2740   // Unbox oop result, e.g. JNIHandles::resolve value.
<span class="line-modified">2741   if (is_reference_type(ret_type)) {</span>
2742     __ resolve_jobject(rax /* value */,
2743                        r15_thread /* thread */,
2744                        rcx /* tmp */);
2745   }
2746 
2747   if (CheckJNICalls) {
2748     // clear_pending_jni_exception_check
2749     __ movptr(Address(r15_thread, JavaThread::pending_jni_exception_check_fn_offset()), NULL_WORD);
2750   }
2751 
2752   if (!is_critical_native) {
2753     // reset handle block
2754     __ movptr(rcx, Address(r15_thread, JavaThread::active_handles_offset()));
2755     __ movl(Address(rcx, JNIHandleBlock::top_offset_in_bytes()), (int32_t)NULL_WORD);
2756   }
2757 
2758   // pop our frame
2759 
2760   __ leave();
2761 
</pre>
</td>
</tr>
</table>
<center><a href="interp_masm_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="templateTable_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>