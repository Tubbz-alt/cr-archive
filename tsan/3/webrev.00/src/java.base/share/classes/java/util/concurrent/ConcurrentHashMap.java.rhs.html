<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/java.base/share/classes/java/util/concurrent/ConcurrentHashMap.java</title>
    <link rel="stylesheet" href="../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
   2  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   3  *
   4  * This code is free software; you can redistribute it and/or modify it
   5  * under the terms of the GNU General Public License version 2 only, as
   6  * published by the Free Software Foundation.  Oracle designates this
   7  * particular file as subject to the &quot;Classpath&quot; exception as provided
   8  * by Oracle in the LICENSE file that accompanied this code.
   9  *
  10  * This code is distributed in the hope that it will be useful, but WITHOUT
  11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  */
  24 
  25 /*
  26  * This file is available under and governed by the GNU General Public
  27  * License version 2 only, as published by the Free Software Foundation.
  28  * However, the following notice accompanied the original version of this
  29  * file:
  30  *
  31  * Written by Doug Lea with assistance from members of JCP JSR-166
  32  * Expert Group and released to the public domain, as explained at
  33  * http://creativecommons.org/publicdomain/zero/1.0/
  34  */
  35 
  36 package java.util.concurrent;
  37 
  38 import java.io.ObjectStreamField;
  39 import java.io.Serializable;
  40 import java.lang.reflect.ParameterizedType;
  41 import java.lang.reflect.Type;
  42 import java.util.AbstractMap;
  43 import java.util.Arrays;
  44 import java.util.Collection;
  45 import java.util.Enumeration;
  46 import java.util.HashMap;
  47 import java.util.Hashtable;
  48 import java.util.Iterator;
  49 import java.util.Map;
  50 import java.util.NoSuchElementException;
  51 import java.util.Set;
  52 import java.util.Spliterator;
  53 import java.util.concurrent.atomic.AtomicReference;
  54 import java.util.concurrent.locks.LockSupport;
  55 import java.util.concurrent.locks.ReentrantLock;
  56 import java.util.function.BiConsumer;
  57 import java.util.function.BiFunction;
  58 import java.util.function.Consumer;
  59 import java.util.function.DoubleBinaryOperator;
  60 import java.util.function.Function;
  61 import java.util.function.IntBinaryOperator;
  62 import java.util.function.LongBinaryOperator;
  63 import java.util.function.Predicate;
  64 import java.util.function.ToDoubleBiFunction;
  65 import java.util.function.ToDoubleFunction;
  66 import java.util.function.ToIntBiFunction;
  67 import java.util.function.ToIntFunction;
  68 import java.util.function.ToLongBiFunction;
  69 import java.util.function.ToLongFunction;
  70 import java.util.stream.Stream;
  71 import jdk.internal.misc.Unsafe;
  72 
  73 /**
  74  * A hash table supporting full concurrency of retrievals and
  75  * high expected concurrency for updates. This class obeys the
  76  * same functional specification as {@link java.util.Hashtable}, and
  77  * includes versions of methods corresponding to each method of
  78  * {@code Hashtable}. However, even though all operations are
  79  * thread-safe, retrieval operations do &lt;em&gt;not&lt;/em&gt; entail locking,
  80  * and there is &lt;em&gt;not&lt;/em&gt; any support for locking the entire table
  81  * in a way that prevents all access.  This class is fully
  82  * interoperable with {@code Hashtable} in programs that rely on its
  83  * thread safety but not on its synchronization details.
  84  *
  85  * &lt;p&gt;Retrieval operations (including {@code get}) generally do not
  86  * block, so may overlap with update operations (including {@code put}
  87  * and {@code remove}). Retrievals reflect the results of the most
  88  * recently &lt;em&gt;completed&lt;/em&gt; update operations holding upon their
  89  * onset. (More formally, an update operation for a given key bears a
  90  * &lt;em&gt;happens-before&lt;/em&gt; relation with any (non-null) retrieval for
  91  * that key reporting the updated value.)  For aggregate operations
  92  * such as {@code putAll} and {@code clear}, concurrent retrievals may
  93  * reflect insertion or removal of only some entries.  Similarly,
  94  * Iterators, Spliterators and Enumerations return elements reflecting the
  95  * state of the hash table at some point at or since the creation of the
  96  * iterator/enumeration.  They do &lt;em&gt;not&lt;/em&gt; throw {@link
  97  * java.util.ConcurrentModificationException ConcurrentModificationException}.
  98  * However, iterators are designed to be used by only one thread at a time.
  99  * Bear in mind that the results of aggregate status methods including
 100  * {@code size}, {@code isEmpty}, and {@code containsValue} are typically
 101  * useful only when a map is not undergoing concurrent updates in other threads.
 102  * Otherwise the results of these methods reflect transient states
 103  * that may be adequate for monitoring or estimation purposes, but not
 104  * for program control.
 105  *
 106  * &lt;p&gt;The table is dynamically expanded when there are too many
 107  * collisions (i.e., keys that have distinct hash codes but fall into
 108  * the same slot modulo the table size), with the expected average
 109  * effect of maintaining roughly two bins per mapping (corresponding
 110  * to a 0.75 load factor threshold for resizing). There may be much
 111  * variance around this average as mappings are added and removed, but
 112  * overall, this maintains a commonly accepted time/space tradeoff for
 113  * hash tables.  However, resizing this or any other kind of hash
 114  * table may be a relatively slow operation. When possible, it is a
 115  * good idea to provide a size estimate as an optional {@code
 116  * initialCapacity} constructor argument. An additional optional
 117  * {@code loadFactor} constructor argument provides a further means of
 118  * customizing initial table capacity by specifying the table density
 119  * to be used in calculating the amount of space to allocate for the
 120  * given number of elements.  Also, for compatibility with previous
 121  * versions of this class, constructors may optionally specify an
 122  * expected {@code concurrencyLevel} as an additional hint for
 123  * internal sizing.  Note that using many keys with exactly the same
 124  * {@code hashCode()} is a sure way to slow down performance of any
 125  * hash table. To ameliorate impact, when keys are {@link Comparable},
 126  * this class may use comparison order among keys to help break ties.
 127  *
 128  * &lt;p&gt;A {@link Set} projection of a ConcurrentHashMap may be created
 129  * (using {@link #newKeySet()} or {@link #newKeySet(int)}), or viewed
 130  * (using {@link #keySet(Object)} when only keys are of interest, and the
 131  * mapped values are (perhaps transiently) not used or all take the
 132  * same mapping value.
 133  *
 134  * &lt;p&gt;A ConcurrentHashMap can be used as a scalable frequency map (a
 135  * form of histogram or multiset) by using {@link
 136  * java.util.concurrent.atomic.LongAdder} values and initializing via
 137  * {@link #computeIfAbsent computeIfAbsent}. For example, to add a count
 138  * to a {@code ConcurrentHashMap&lt;String,LongAdder&gt; freqs}, you can use
 139  * {@code freqs.computeIfAbsent(key, k -&gt; new LongAdder()).increment();}
 140  *
 141  * &lt;p&gt;This class and its views and iterators implement all of the
 142  * &lt;em&gt;optional&lt;/em&gt; methods of the {@link Map} and {@link Iterator}
 143  * interfaces.
 144  *
 145  * &lt;p&gt;Like {@link Hashtable} but unlike {@link HashMap}, this class
 146  * does &lt;em&gt;not&lt;/em&gt; allow {@code null} to be used as a key or value.
 147  *
 148  * &lt;p&gt;ConcurrentHashMaps support a set of sequential and parallel bulk
 149  * operations that, unlike most {@link Stream} methods, are designed
 150  * to be safely, and often sensibly, applied even with maps that are
 151  * being concurrently updated by other threads; for example, when
 152  * computing a snapshot summary of the values in a shared registry.
 153  * There are three kinds of operation, each with four forms, accepting
 154  * functions with keys, values, entries, and (key, value) pairs as
 155  * arguments and/or return values. Because the elements of a
 156  * ConcurrentHashMap are not ordered in any particular way, and may be
 157  * processed in different orders in different parallel executions, the
 158  * correctness of supplied functions should not depend on any
 159  * ordering, or on any other objects or values that may transiently
 160  * change while computation is in progress; and except for forEach
 161  * actions, should ideally be side-effect-free. Bulk operations on
 162  * {@link Map.Entry} objects do not support method {@code setValue}.
 163  *
 164  * &lt;ul&gt;
 165  * &lt;li&gt;forEach: Performs a given action on each element.
 166  * A variant form applies a given transformation on each element
 167  * before performing the action.
 168  *
 169  * &lt;li&gt;search: Returns the first available non-null result of
 170  * applying a given function on each element; skipping further
 171  * search when a result is found.
 172  *
 173  * &lt;li&gt;reduce: Accumulates each element.  The supplied reduction
 174  * function cannot rely on ordering (more formally, it should be
 175  * both associative and commutative).  There are five variants:
 176  *
 177  * &lt;ul&gt;
 178  *
 179  * &lt;li&gt;Plain reductions. (There is not a form of this method for
 180  * (key, value) function arguments since there is no corresponding
 181  * return type.)
 182  *
 183  * &lt;li&gt;Mapped reductions that accumulate the results of a given
 184  * function applied to each element.
 185  *
 186  * &lt;li&gt;Reductions to scalar doubles, longs, and ints, using a
 187  * given basis value.
 188  *
 189  * &lt;/ul&gt;
 190  * &lt;/ul&gt;
 191  *
 192  * &lt;p&gt;These bulk operations accept a {@code parallelismThreshold}
 193  * argument. Methods proceed sequentially if the current map size is
 194  * estimated to be less than the given threshold. Using a value of
 195  * {@code Long.MAX_VALUE} suppresses all parallelism.  Using a value
 196  * of {@code 1} results in maximal parallelism by partitioning into
 197  * enough subtasks to fully utilize the {@link
 198  * ForkJoinPool#commonPool()} that is used for all parallel
 199  * computations. Normally, you would initially choose one of these
 200  * extreme values, and then measure performance of using in-between
 201  * values that trade off overhead versus throughput.
 202  *
 203  * &lt;p&gt;The concurrency properties of bulk operations follow
 204  * from those of ConcurrentHashMap: Any non-null result returned
 205  * from {@code get(key)} and related access methods bears a
 206  * happens-before relation with the associated insertion or
 207  * update.  The result of any bulk operation reflects the
 208  * composition of these per-element relations (but is not
 209  * necessarily atomic with respect to the map as a whole unless it
 210  * is somehow known to be quiescent).  Conversely, because keys
 211  * and values in the map are never null, null serves as a reliable
 212  * atomic indicator of the current lack of any result.  To
 213  * maintain this property, null serves as an implicit basis for
 214  * all non-scalar reduction operations. For the double, long, and
 215  * int versions, the basis should be one that, when combined with
 216  * any other value, returns that other value (more formally, it
 217  * should be the identity element for the reduction). Most common
 218  * reductions have these properties; for example, computing a sum
 219  * with basis 0 or a minimum with basis MAX_VALUE.
 220  *
 221  * &lt;p&gt;Search and transformation functions provided as arguments
 222  * should similarly return null to indicate the lack of any result
 223  * (in which case it is not used). In the case of mapped
 224  * reductions, this also enables transformations to serve as
 225  * filters, returning null (or, in the case of primitive
 226  * specializations, the identity basis) if the element should not
 227  * be combined. You can create compound transformations and
 228  * filterings by composing them yourself under this &quot;null means
 229  * there is nothing there now&quot; rule before using them in search or
 230  * reduce operations.
 231  *
 232  * &lt;p&gt;Methods accepting and/or returning Entry arguments maintain
 233  * key-value associations. They may be useful for example when
 234  * finding the key for the greatest value. Note that &quot;plain&quot; Entry
 235  * arguments can be supplied using {@code new
 236  * AbstractMap.SimpleEntry(k,v)}.
 237  *
 238  * &lt;p&gt;Bulk operations may complete abruptly, throwing an
 239  * exception encountered in the application of a supplied
 240  * function. Bear in mind when handling such exceptions that other
 241  * concurrently executing functions could also have thrown
 242  * exceptions, or would have done so if the first exception had
 243  * not occurred.
 244  *
 245  * &lt;p&gt;Speedups for parallel compared to sequential forms are common
 246  * but not guaranteed.  Parallel operations involving brief functions
 247  * on small maps may execute more slowly than sequential forms if the
 248  * underlying work to parallelize the computation is more expensive
 249  * than the computation itself.  Similarly, parallelization may not
 250  * lead to much actual parallelism if all processors are busy
 251  * performing unrelated tasks.
 252  *
 253  * &lt;p&gt;All arguments to all task methods must be non-null.
 254  *
 255  * &lt;p&gt;This class is a member of the
 256  * &lt;a href=&quot;{@docRoot}/java.base/java/util/package-summary.html#CollectionsFramework&quot;&gt;
 257  * Java Collections Framework&lt;/a&gt;.
 258  *
 259  * @since 1.5
 260  * @author Doug Lea
 261  * @param &lt;K&gt; the type of keys maintained by this map
 262  * @param &lt;V&gt; the type of mapped values
 263  */
 264 public class ConcurrentHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt;
 265     implements ConcurrentMap&lt;K,V&gt;, Serializable {
 266     private static final long serialVersionUID = 7249069246763182397L;
 267 
 268     /*
 269      * Overview:
 270      *
 271      * The primary design goal of this hash table is to maintain
 272      * concurrent readability (typically method get(), but also
 273      * iterators and related methods) while minimizing update
 274      * contention. Secondary goals are to keep space consumption about
 275      * the same or better than java.util.HashMap, and to support high
 276      * initial insertion rates on an empty table by many threads.
 277      *
 278      * This map usually acts as a binned (bucketed) hash table.  Each
 279      * key-value mapping is held in a Node.  Most nodes are instances
 280      * of the basic Node class with hash, key, value, and next
 281      * fields. However, various subclasses exist: TreeNodes are
 282      * arranged in balanced trees, not lists.  TreeBins hold the roots
 283      * of sets of TreeNodes. ForwardingNodes are placed at the heads
 284      * of bins during resizing. ReservationNodes are used as
 285      * placeholders while establishing values in computeIfAbsent and
 286      * related methods.  The types TreeBin, ForwardingNode, and
 287      * ReservationNode do not hold normal user keys, values, or
 288      * hashes, and are readily distinguishable during search etc
 289      * because they have negative hash fields and null key and value
 290      * fields. (These special nodes are either uncommon or transient,
 291      * so the impact of carrying around some unused fields is
 292      * insignificant.)
 293      *
 294      * The table is lazily initialized to a power-of-two size upon the
 295      * first insertion.  Each bin in the table normally contains a
 296      * list of Nodes (most often, the list has only zero or one Node).
 297      * Table accesses require volatile/atomic reads, writes, and
 298      * CASes.  Because there is no other way to arrange this without
 299      * adding further indirections, we use intrinsics
 300      * (jdk.internal.misc.Unsafe) operations.
 301      *
 302      * We use the top (sign) bit of Node hash fields for control
 303      * purposes -- it is available anyway because of addressing
 304      * constraints.  Nodes with negative hash fields are specially
 305      * handled or ignored in map methods.
 306      *
 307      * Insertion (via put or its variants) of the first node in an
 308      * empty bin is performed by just CASing it to the bin.  This is
 309      * by far the most common case for put operations under most
 310      * key/hash distributions.  Other update operations (insert,
 311      * delete, and replace) require locks.  We do not want to waste
 312      * the space required to associate a distinct lock object with
 313      * each bin, so instead use the first node of a bin list itself as
 314      * a lock. Locking support for these locks relies on builtin
 315      * &quot;synchronized&quot; monitors.
 316      *
 317      * Using the first node of a list as a lock does not by itself
 318      * suffice though: When a node is locked, any update must first
 319      * validate that it is still the first node after locking it, and
 320      * retry if not. Because new nodes are always appended to lists,
 321      * once a node is first in a bin, it remains first until deleted
 322      * or the bin becomes invalidated (upon resizing).
 323      *
 324      * The main disadvantage of per-bin locks is that other update
 325      * operations on other nodes in a bin list protected by the same
 326      * lock can stall, for example when user equals() or mapping
 327      * functions take a long time.  However, statistically, under
 328      * random hash codes, this is not a common problem.  Ideally, the
 329      * frequency of nodes in bins follows a Poisson distribution
 330      * (http://en.wikipedia.org/wiki/Poisson_distribution) with a
 331      * parameter of about 0.5 on average, given the resizing threshold
 332      * of 0.75, although with a large variance because of resizing
 333      * granularity. Ignoring variance, the expected occurrences of
 334      * list size k are (exp(-0.5) * pow(0.5, k) / factorial(k)). The
 335      * first values are:
 336      *
 337      * 0:    0.60653066
 338      * 1:    0.30326533
 339      * 2:    0.07581633
 340      * 3:    0.01263606
 341      * 4:    0.00157952
 342      * 5:    0.00015795
 343      * 6:    0.00001316
 344      * 7:    0.00000094
 345      * 8:    0.00000006
 346      * more: less than 1 in ten million
 347      *
 348      * Lock contention probability for two threads accessing distinct
 349      * elements is roughly 1 / (8 * #elements) under random hashes.
 350      *
 351      * Actual hash code distributions encountered in practice
 352      * sometimes deviate significantly from uniform randomness.  This
 353      * includes the case when N &gt; (1&lt;&lt;30), so some keys MUST collide.
 354      * Similarly for dumb or hostile usages in which multiple keys are
 355      * designed to have identical hash codes or ones that differs only
 356      * in masked-out high bits. So we use a secondary strategy that
 357      * applies when the number of nodes in a bin exceeds a
 358      * threshold. These TreeBins use a balanced tree to hold nodes (a
 359      * specialized form of red-black trees), bounding search time to
 360      * O(log N).  Each search step in a TreeBin is at least twice as
 361      * slow as in a regular list, but given that N cannot exceed
 362      * (1&lt;&lt;64) (before running out of addresses) this bounds search
 363      * steps, lock hold times, etc, to reasonable constants (roughly
 364      * 100 nodes inspected per operation worst case) so long as keys
 365      * are Comparable (which is very common -- String, Long, etc).
 366      * TreeBin nodes (TreeNodes) also maintain the same &quot;next&quot;
 367      * traversal pointers as regular nodes, so can be traversed in
 368      * iterators in the same way.
 369      *
 370      * The table is resized when occupancy exceeds a percentage
 371      * threshold (nominally, 0.75, but see below).  Any thread
 372      * noticing an overfull bin may assist in resizing after the
 373      * initiating thread allocates and sets up the replacement array.
 374      * However, rather than stalling, these other threads may proceed
 375      * with insertions etc.  The use of TreeBins shields us from the
 376      * worst case effects of overfilling while resizes are in
 377      * progress.  Resizing proceeds by transferring bins, one by one,
 378      * from the table to the next table. However, threads claim small
 379      * blocks of indices to transfer (via field transferIndex) before
 380      * doing so, reducing contention.  A generation stamp in field
 381      * sizeCtl ensures that resizings do not overlap. Because we are
 382      * using power-of-two expansion, the elements from each bin must
 383      * either stay at same index, or move with a power of two
 384      * offset. We eliminate unnecessary node creation by catching
 385      * cases where old nodes can be reused because their next fields
 386      * won&#39;t change.  On average, only about one-sixth of them need
 387      * cloning when a table doubles. The nodes they replace will be
<a name="1" id="anc1"></a><span class="line-modified"> 388      * garbage collectible as soon as they are no longer referenced by</span>
 389      * any reader thread that may be in the midst of concurrently
 390      * traversing table.  Upon transfer, the old table bin contains
 391      * only a special forwarding node (with hash field &quot;MOVED&quot;) that
 392      * contains the next table as its key. On encountering a
 393      * forwarding node, access and update operations restart, using
 394      * the new table.
 395      *
 396      * Each bin transfer requires its bin lock, which can stall
 397      * waiting for locks while resizing. However, because other
 398      * threads can join in and help resize rather than contend for
 399      * locks, average aggregate waits become shorter as resizing
 400      * progresses.  The transfer operation must also ensure that all
 401      * accessible bins in both the old and new table are usable by any
 402      * traversal.  This is arranged in part by proceeding from the
 403      * last bin (table.length - 1) up towards the first.  Upon seeing
 404      * a forwarding node, traversals (see class Traverser) arrange to
 405      * move to the new table without revisiting nodes.  To ensure that
 406      * no intervening nodes are skipped even when moved out of order,
 407      * a stack (see class TableStack) is created on first encounter of
 408      * a forwarding node during a traversal, to maintain its place if
 409      * later processing the current table. The need for these
 410      * save/restore mechanics is relatively rare, but when one
 411      * forwarding node is encountered, typically many more will be.
 412      * So Traversers use a simple caching scheme to avoid creating so
 413      * many new TableStack nodes. (Thanks to Peter Levart for
 414      * suggesting use of a stack here.)
 415      *
 416      * The traversal scheme also applies to partial traversals of
 417      * ranges of bins (via an alternate Traverser constructor)
 418      * to support partitioned aggregate operations.  Also, read-only
 419      * operations give up if ever forwarded to a null table, which
 420      * provides support for shutdown-style clearing, which is also not
 421      * currently implemented.
 422      *
 423      * Lazy table initialization minimizes footprint until first use,
 424      * and also avoids resizings when the first operation is from a
 425      * putAll, constructor with map argument, or deserialization.
 426      * These cases attempt to override the initial capacity settings,
 427      * but harmlessly fail to take effect in cases of races.
 428      *
 429      * The element count is maintained using a specialization of
 430      * LongAdder. We need to incorporate a specialization rather than
 431      * just use a LongAdder in order to access implicit
 432      * contention-sensing that leads to creation of multiple
 433      * CounterCells.  The counter mechanics avoid contention on
 434      * updates but can encounter cache thrashing if read too
 435      * frequently during concurrent access. To avoid reading so often,
 436      * resizing under contention is attempted only upon adding to a
 437      * bin already holding two or more nodes. Under uniform hash
 438      * distributions, the probability of this occurring at threshold
 439      * is around 13%, meaning that only about 1 in 8 puts check
 440      * threshold (and after resizing, many fewer do so).
 441      *
 442      * TreeBins use a special form of comparison for search and
 443      * related operations (which is the main reason we cannot use
 444      * existing collections such as TreeMaps). TreeBins contain
 445      * Comparable elements, but may contain others, as well as
 446      * elements that are Comparable but not necessarily Comparable for
 447      * the same T, so we cannot invoke compareTo among them. To handle
 448      * this, the tree is ordered primarily by hash value, then by
 449      * Comparable.compareTo order if applicable.  On lookup at a node,
 450      * if elements are not comparable or compare as 0 then both left
 451      * and right children may need to be searched in the case of tied
 452      * hash values. (This corresponds to the full list search that
 453      * would be necessary if all elements were non-Comparable and had
 454      * tied hashes.) On insertion, to keep a total ordering (or as
 455      * close as is required here) across rebalancings, we compare
 456      * classes and identityHashCodes as tie-breakers. The red-black
 457      * balancing code is updated from pre-jdk-collections
 458      * (http://gee.cs.oswego.edu/dl/classes/collections/RBCell.java)
 459      * based in turn on Cormen, Leiserson, and Rivest &quot;Introduction to
 460      * Algorithms&quot; (CLR).
 461      *
 462      * TreeBins also require an additional locking mechanism.  While
 463      * list traversal is always possible by readers even during
 464      * updates, tree traversal is not, mainly because of tree-rotations
 465      * that may change the root node and/or its linkages.  TreeBins
 466      * include a simple read-write lock mechanism parasitic on the
 467      * main bin-synchronization strategy: Structural adjustments
 468      * associated with an insertion or removal are already bin-locked
 469      * (and so cannot conflict with other writers) but must wait for
 470      * ongoing readers to finish. Since there can be only one such
 471      * waiter, we use a simple scheme using a single &quot;waiter&quot; field to
 472      * block writers.  However, readers need never block.  If the root
 473      * lock is held, they proceed along the slow traversal path (via
 474      * next-pointers) until the lock becomes available or the list is
 475      * exhausted, whichever comes first. These cases are not fast, but
 476      * maximize aggregate expected throughput.
 477      *
 478      * Maintaining API and serialization compatibility with previous
 479      * versions of this class introduces several oddities. Mainly: We
 480      * leave untouched but unused constructor arguments referring to
 481      * concurrencyLevel. We accept a loadFactor constructor argument,
 482      * but apply it only to initial table capacity (which is the only
 483      * time that we can guarantee to honor it.) We also declare an
 484      * unused &quot;Segment&quot; class that is instantiated in minimal form
 485      * only when serializing.
 486      *
 487      * Also, solely for compatibility with previous versions of this
 488      * class, it extends AbstractMap, even though all of its methods
 489      * are overridden, so it is just useless baggage.
 490      *
 491      * This file is organized to make things a little easier to follow
 492      * while reading than they might otherwise: First the main static
 493      * declarations and utilities, then fields, then main public
 494      * methods (with a few factorings of multiple public methods into
 495      * internal ones), then sizing methods, trees, traversers, and
 496      * bulk operations.
 497      */
 498 
 499     /* ---------------- Constants -------------- */
 500 
 501     /**
 502      * The largest possible table capacity.  This value must be
 503      * exactly 1&lt;&lt;30 to stay within Java array allocation and indexing
 504      * bounds for power of two table sizes, and is further required
 505      * because the top two bits of 32bit hash fields are used for
 506      * control purposes.
 507      */
 508     private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;
 509 
 510     /**
 511      * The default initial table capacity.  Must be a power of 2
 512      * (i.e., at least 1) and at most MAXIMUM_CAPACITY.
 513      */
 514     private static final int DEFAULT_CAPACITY = 16;
 515 
 516     /**
 517      * The largest possible (non-power of two) array size.
 518      * Needed by toArray and related methods.
 519      */
 520     static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;
 521 
 522     /**
 523      * The default concurrency level for this table. Unused but
 524      * defined for compatibility with previous versions of this class.
 525      */
 526     private static final int DEFAULT_CONCURRENCY_LEVEL = 16;
 527 
 528     /**
 529      * The load factor for this table. Overrides of this value in
 530      * constructors affect only the initial table capacity.  The
 531      * actual floating point value isn&#39;t normally used -- it is
 532      * simpler to use expressions such as {@code n - (n &gt;&gt;&gt; 2)} for
 533      * the associated resizing threshold.
 534      */
 535     private static final float LOAD_FACTOR = 0.75f;
 536 
 537     /**
 538      * The bin count threshold for using a tree rather than list for a
 539      * bin.  Bins are converted to trees when adding an element to a
 540      * bin with at least this many nodes. The value must be greater
 541      * than 2, and should be at least 8 to mesh with assumptions in
 542      * tree removal about conversion back to plain bins upon
 543      * shrinkage.
 544      */
 545     static final int TREEIFY_THRESHOLD = 8;
 546 
 547     /**
 548      * The bin count threshold for untreeifying a (split) bin during a
 549      * resize operation. Should be less than TREEIFY_THRESHOLD, and at
 550      * most 6 to mesh with shrinkage detection under removal.
 551      */
 552     static final int UNTREEIFY_THRESHOLD = 6;
 553 
 554     /**
 555      * The smallest table capacity for which bins may be treeified.
 556      * (Otherwise the table is resized if too many nodes in a bin.)
 557      * The value should be at least 4 * TREEIFY_THRESHOLD to avoid
 558      * conflicts between resizing and treeification thresholds.
 559      */
 560     static final int MIN_TREEIFY_CAPACITY = 64;
 561 
 562     /**
 563      * Minimum number of rebinnings per transfer step. Ranges are
 564      * subdivided to allow multiple resizer threads.  This value
 565      * serves as a lower bound to avoid resizers encountering
 566      * excessive memory contention.  The value should be at least
 567      * DEFAULT_CAPACITY.
 568      */
 569     private static final int MIN_TRANSFER_STRIDE = 16;
 570 
 571     /**
 572      * The number of bits used for generation stamp in sizeCtl.
 573      * Must be at least 6 for 32bit arrays.
 574      */
 575     private static final int RESIZE_STAMP_BITS = 16;
 576 
 577     /**
 578      * The maximum number of threads that can help resize.
 579      * Must fit in 32 - RESIZE_STAMP_BITS bits.
 580      */
 581     private static final int MAX_RESIZERS = (1 &lt;&lt; (32 - RESIZE_STAMP_BITS)) - 1;
 582 
 583     /**
 584      * The bit shift for recording size stamp in sizeCtl.
 585      */
 586     private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;
 587 
 588     /*
 589      * Encodings for Node hash fields. See above for explanation.
 590      */
 591     static final int MOVED     = -1; // hash for forwarding nodes
 592     static final int TREEBIN   = -2; // hash for roots of trees
 593     static final int RESERVED  = -3; // hash for transient reservations
 594     static final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash
 595 
 596     /** Number of CPUS, to place bounds on some sizings */
 597     static final int NCPU = Runtime.getRuntime().availableProcessors();
 598 
 599     /**
 600      * Serialized pseudo-fields, provided only for jdk7 compatibility.
 601      * @serialField segments Segment[]
 602      *   The segments, each of which is a specialized hash table.
 603      * @serialField segmentMask int
 604      *   Mask value for indexing into segments. The upper bits of a
 605      *   key&#39;s hash code are used to choose the segment.
 606      * @serialField segmentShift int
 607      *   Shift value for indexing within segments.
 608      */
 609     private static final ObjectStreamField[] serialPersistentFields = {
 610         new ObjectStreamField(&quot;segments&quot;, Segment[].class),
 611         new ObjectStreamField(&quot;segmentMask&quot;, Integer.TYPE),
 612         new ObjectStreamField(&quot;segmentShift&quot;, Integer.TYPE),
 613     };
 614 
 615     /* ---------------- Nodes -------------- */
 616 
 617     /**
 618      * Key-value entry.  This class is never exported out as a
 619      * user-mutable Map.Entry (i.e., one supporting setValue; see
 620      * MapEntry below), but can be used for read-only traversals used
 621      * in bulk tasks.  Subclasses of Node with a negative hash field
 622      * are special, and contain null keys and values (but are never
 623      * exported).  Otherwise, keys and vals are never null.
 624      */
 625     static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {
 626         final int hash;
 627         final K key;
 628         volatile V val;
 629         volatile Node&lt;K,V&gt; next;
 630 
 631         Node(int hash, K key, V val) {
 632             this.hash = hash;
 633             this.key = key;
 634             this.val = val;
 635         }
 636 
 637         Node(int hash, K key, V val, Node&lt;K,V&gt; next) {
 638             this(hash, key, val);
 639             this.next = next;
 640         }
 641 
 642         public final K getKey()     { return key; }
 643         public final V getValue()   { return val; }
 644         public final int hashCode() { return key.hashCode() ^ val.hashCode(); }
 645         public final String toString() {
 646             return Helpers.mapEntryToString(key, val);
 647         }
 648         public final V setValue(V value) {
 649             throw new UnsupportedOperationException();
 650         }
 651 
 652         public final boolean equals(Object o) {
 653             Object k, v, u; Map.Entry&lt;?,?&gt; e;
 654             return ((o instanceof Map.Entry) &amp;&amp;
 655                     (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != null &amp;&amp;
 656                     (v = e.getValue()) != null &amp;&amp;
 657                     (k == key || k.equals(key)) &amp;&amp;
 658                     (v == (u = val) || v.equals(u)));
 659         }
 660 
 661         /**
 662          * Virtualized support for map.get(); overridden in subclasses.
 663          */
 664         Node&lt;K,V&gt; find(int h, Object k) {
 665             Node&lt;K,V&gt; e = this;
 666             if (k != null) {
 667                 do {
 668                     K ek;
 669                     if (e.hash == h &amp;&amp;
 670                         ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek))))
 671                         return e;
 672                 } while ((e = e.next) != null);
 673             }
 674             return null;
 675         }
 676     }
 677 
 678     /* ---------------- Static utilities -------------- */
 679 
 680     /**
 681      * Spreads (XORs) higher bits of hash to lower and also forces top
 682      * bit to 0. Because the table uses power-of-two masking, sets of
 683      * hashes that vary only in bits above the current mask will
 684      * always collide. (Among known examples are sets of Float keys
 685      * holding consecutive whole numbers in small tables.)  So we
 686      * apply a transform that spreads the impact of higher bits
 687      * downward. There is a tradeoff between speed, utility, and
 688      * quality of bit-spreading. Because many common sets of hashes
 689      * are already reasonably distributed (so don&#39;t benefit from
 690      * spreading), and because we use trees to handle large sets of
 691      * collisions in bins, we just XOR some shifted bits in the
 692      * cheapest possible way to reduce systematic lossage, as well as
 693      * to incorporate impact of the highest bits that would otherwise
 694      * never be used in index calculations because of table bounds.
 695      */
 696     static final int spread(int h) {
 697         return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;
 698     }
 699 
 700     /**
 701      * Returns a power of two table size for the given desired capacity.
 702      * See Hackers Delight, sec 3.2
 703      */
 704     private static final int tableSizeFor(int c) {
 705         int n = -1 &gt;&gt;&gt; Integer.numberOfLeadingZeros(c - 1);
 706         return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
 707     }
 708 
 709     /**
 710      * Returns x&#39;s Class if it is of the form &quot;class C implements
 711      * Comparable&lt;C&gt;&quot;, else null.
 712      */
 713     static Class&lt;?&gt; comparableClassFor(Object x) {
 714         if (x instanceof Comparable) {
 715             Class&lt;?&gt; c; Type[] ts, as; ParameterizedType p;
 716             if ((c = x.getClass()) == String.class) // bypass checks
 717                 return c;
 718             if ((ts = c.getGenericInterfaces()) != null) {
 719                 for (Type t : ts) {
 720                     if ((t instanceof ParameterizedType) &amp;&amp;
 721                         ((p = (ParameterizedType)t).getRawType() ==
 722                          Comparable.class) &amp;&amp;
 723                         (as = p.getActualTypeArguments()) != null &amp;&amp;
 724                         as.length == 1 &amp;&amp; as[0] == c) // type arg is c
 725                         return c;
 726                 }
 727             }
 728         }
 729         return null;
 730     }
 731 
 732     /**
 733      * Returns k.compareTo(x) if x matches kc (k&#39;s screened comparable
 734      * class), else 0.
 735      */
 736     @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) // for cast to Comparable
 737     static int compareComparables(Class&lt;?&gt; kc, Object k, Object x) {
 738         return (x == null || x.getClass() != kc ? 0 :
 739                 ((Comparable)k).compareTo(x));
 740     }
 741 
 742     /* ---------------- Table element access -------------- */
 743 
 744     /*
 745      * Atomic access methods are used for table elements as well as
 746      * elements of in-progress next table while resizing.  All uses of
 747      * the tab arguments must be null checked by callers.  All callers
 748      * also paranoically precheck that tab&#39;s length is not zero (or an
 749      * equivalent check), thus ensuring that any index argument taking
 750      * the form of a hash value anded with (length - 1) is a valid
 751      * index.  Note that, to be correct wrt arbitrary concurrency
 752      * errors by users, these checks must operate on local variables,
 753      * which accounts for some odd-looking inline assignments below.
 754      * Note that calls to setTabAt always occur within locked regions,
 755      * and so require only release ordering.
 756      */
 757 
 758     @SuppressWarnings(&quot;unchecked&quot;)
 759     static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) {
 760         return (Node&lt;K,V&gt;)U.getReferenceAcquire(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);
 761     }
 762 
 763     static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i,
 764                                         Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) {
 765         return U.compareAndSetReference(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);
 766     }
 767 
 768     static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) {
 769         U.putReferenceRelease(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v);
 770     }
 771 
 772     /* ---------------- Fields -------------- */
 773 
 774     /**
 775      * The array of bins. Lazily initialized upon first insertion.
 776      * Size is always a power of two. Accessed directly by iterators.
 777      */
 778     transient volatile Node&lt;K,V&gt;[] table;
 779 
 780     /**
 781      * The next table to use; non-null only while resizing.
 782      */
 783     private transient volatile Node&lt;K,V&gt;[] nextTable;
 784 
 785     /**
 786      * Base counter value, used mainly when there is no contention,
 787      * but also as a fallback during table initialization
 788      * races. Updated via CAS.
 789      */
 790     private transient volatile long baseCount;
 791 
 792     /**
 793      * Table initialization and resizing control.  When negative, the
 794      * table is being initialized or resized: -1 for initialization,
 795      * else -(1 + the number of active resizing threads).  Otherwise,
 796      * when table is null, holds the initial table size to use upon
 797      * creation, or 0 for default. After initialization, holds the
 798      * next element count value upon which to resize the table.
 799      */
 800     private transient volatile int sizeCtl;
 801 
 802     /**
 803      * The next table index (plus one) to split while resizing.
 804      */
 805     private transient volatile int transferIndex;
 806 
 807     /**
 808      * Spinlock (locked via CAS) used when resizing and/or creating CounterCells.
 809      */
 810     private transient volatile int cellsBusy;
 811 
 812     /**
 813      * Table of counter cells. When non-null, size is a power of 2.
 814      */
 815     private transient volatile CounterCell[] counterCells;
 816 
 817     // views
 818     private transient KeySetView&lt;K,V&gt; keySet;
 819     private transient ValuesView&lt;K,V&gt; values;
 820     private transient EntrySetView&lt;K,V&gt; entrySet;
 821 
 822 
 823     /* ---------------- Public operations -------------- */
 824 
 825     /**
 826      * Creates a new, empty map with the default initial table size (16).
 827      */
 828     public ConcurrentHashMap() {
 829     }
 830 
 831     /**
 832      * Creates a new, empty map with an initial table size
 833      * accommodating the specified number of elements without the need
 834      * to dynamically resize.
 835      *
 836      * @param initialCapacity The implementation performs internal
 837      * sizing to accommodate this many elements.
 838      * @throws IllegalArgumentException if the initial capacity of
 839      * elements is negative
 840      */
 841     public ConcurrentHashMap(int initialCapacity) {
 842         this(initialCapacity, LOAD_FACTOR, 1);
 843     }
 844 
 845     /**
 846      * Creates a new map with the same mappings as the given map.
 847      *
 848      * @param m the map
 849      */
 850     public ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) {
 851         this.sizeCtl = DEFAULT_CAPACITY;
 852         putAll(m);
 853     }
 854 
 855     /**
 856      * Creates a new, empty map with an initial table size based on
 857      * the given number of elements ({@code initialCapacity}) and
 858      * initial table density ({@code loadFactor}).
 859      *
 860      * @param initialCapacity the initial capacity. The implementation
 861      * performs internal sizing to accommodate this many elements,
 862      * given the specified load factor.
 863      * @param loadFactor the load factor (table density) for
 864      * establishing the initial table size
 865      * @throws IllegalArgumentException if the initial capacity of
 866      * elements is negative or the load factor is nonpositive
 867      *
 868      * @since 1.6
 869      */
 870     public ConcurrentHashMap(int initialCapacity, float loadFactor) {
 871         this(initialCapacity, loadFactor, 1);
 872     }
 873 
 874     /**
 875      * Creates a new, empty map with an initial table size based on
 876      * the given number of elements ({@code initialCapacity}), initial
 877      * table density ({@code loadFactor}), and number of concurrently
 878      * updating threads ({@code concurrencyLevel}).
 879      *
 880      * @param initialCapacity the initial capacity. The implementation
 881      * performs internal sizing to accommodate this many elements,
 882      * given the specified load factor.
 883      * @param loadFactor the load factor (table density) for
 884      * establishing the initial table size
 885      * @param concurrencyLevel the estimated number of concurrently
 886      * updating threads. The implementation may use this value as
 887      * a sizing hint.
 888      * @throws IllegalArgumentException if the initial capacity is
 889      * negative or the load factor or concurrencyLevel are
 890      * nonpositive
 891      */
 892     public ConcurrentHashMap(int initialCapacity,
 893                              float loadFactor, int concurrencyLevel) {
 894         if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0)
 895             throw new IllegalArgumentException();
 896         if (initialCapacity &lt; concurrencyLevel)   // Use at least as many bins
 897             initialCapacity = concurrencyLevel;   // as estimated threads
 898         long size = (long)(1.0 + (long)initialCapacity / loadFactor);
 899         int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ?
 900             MAXIMUM_CAPACITY : tableSizeFor((int)size);
 901         this.sizeCtl = cap;
 902     }
 903 
 904     // Original (since JDK1.2) Map methods
 905 
 906     /**
 907      * {@inheritDoc}
 908      */
 909     public int size() {
 910         long n = sumCount();
 911         return ((n &lt; 0L) ? 0 :
 912                 (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE :
 913                 (int)n);
 914     }
 915 
 916     /**
 917      * {@inheritDoc}
 918      */
 919     public boolean isEmpty() {
 920         return sumCount() &lt;= 0L; // ignore transient negative values
 921     }
 922 
 923     /**
 924      * Returns the value to which the specified key is mapped,
 925      * or {@code null} if this map contains no mapping for the key.
 926      *
 927      * &lt;p&gt;More formally, if this map contains a mapping from a key
 928      * {@code k} to a value {@code v} such that {@code key.equals(k)},
 929      * then this method returns {@code v}; otherwise it returns
 930      * {@code null}.  (There can be at most one such mapping.)
 931      *
 932      * @throws NullPointerException if the specified key is null
 933      */
 934     public V get(Object key) {
 935         Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek;
 936         int h = spread(key.hashCode());
 937         if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;
 938             (e = tabAt(tab, (n - 1) &amp; h)) != null) {
 939             if ((eh = e.hash) == h) {
 940                 if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))
 941                     return e.val;
 942             }
 943             else if (eh &lt; 0)
 944                 return (p = e.find(h, key)) != null ? p.val : null;
 945             while ((e = e.next) != null) {
 946                 if (e.hash == h &amp;&amp;
 947                     ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))))
 948                     return e.val;
 949             }
 950         }
 951         return null;
 952     }
 953 
 954     /**
 955      * Tests if the specified object is a key in this table.
 956      *
 957      * @param  key possible key
 958      * @return {@code true} if and only if the specified object
 959      *         is a key in this table, as determined by the
 960      *         {@code equals} method; {@code false} otherwise
 961      * @throws NullPointerException if the specified key is null
 962      */
 963     public boolean containsKey(Object key) {
 964         return get(key) != null;
 965     }
 966 
 967     /**
 968      * Returns {@code true} if this map maps one or more keys to the
 969      * specified value. Note: This method may require a full traversal
 970      * of the map, and is much slower than method {@code containsKey}.
 971      *
 972      * @param value value whose presence in this map is to be tested
 973      * @return {@code true} if this map maps one or more keys to the
 974      *         specified value
 975      * @throws NullPointerException if the specified value is null
 976      */
 977     public boolean containsValue(Object value) {
 978         if (value == null)
 979             throw new NullPointerException();
 980         Node&lt;K,V&gt;[] t;
 981         if ((t = table) != null) {
 982             Traverser&lt;K,V&gt; it = new Traverser&lt;K,V&gt;(t, t.length, 0, t.length);
 983             for (Node&lt;K,V&gt; p; (p = it.advance()) != null; ) {
 984                 V v;
 985                 if ((v = p.val) == value || (v != null &amp;&amp; value.equals(v)))
 986                     return true;
 987             }
 988         }
 989         return false;
 990     }
 991 
 992     /**
 993      * Maps the specified key to the specified value in this table.
 994      * Neither the key nor the value can be null.
 995      *
 996      * &lt;p&gt;The value can be retrieved by calling the {@code get} method
 997      * with a key that is equal to the original key.
 998      *
 999      * @param key key with which the specified value is to be associated
1000      * @param value value to be associated with the specified key
1001      * @return the previous value associated with {@code key}, or
1002      *         {@code null} if there was no mapping for {@code key}
1003      * @throws NullPointerException if the specified key or value is null
1004      */
1005     public V put(K key, V value) {
1006         return putVal(key, value, false);
1007     }
1008 
1009     /** Implementation for put and putIfAbsent */
1010     final V putVal(K key, V value, boolean onlyIfAbsent) {
1011         if (key == null || value == null) throw new NullPointerException();
1012         int hash = spread(key.hashCode());
1013         int binCount = 0;
1014         for (Node&lt;K,V&gt;[] tab = table;;) {
1015             Node&lt;K,V&gt; f; int n, i, fh; K fk; V fv;
1016             if (tab == null || (n = tab.length) == 0)
1017                 tab = initTable();
1018             else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) {
1019                 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value)))
1020                     break;                   // no lock when adding to empty bin
1021             }
1022             else if ((fh = f.hash) == MOVED)
1023                 tab = helpTransfer(tab, f);
1024             else if (onlyIfAbsent // check first node without acquiring lock
1025                      &amp;&amp; fh == hash
1026                      &amp;&amp; ((fk = f.key) == key || (fk != null &amp;&amp; key.equals(fk)))
1027                      &amp;&amp; (fv = f.val) != null)
1028                 return fv;
1029             else {
1030                 V oldVal = null;
1031                 synchronized (f) {
1032                     if (tabAt(tab, i) == f) {
1033                         if (fh &gt;= 0) {
1034                             binCount = 1;
1035                             for (Node&lt;K,V&gt; e = f;; ++binCount) {
1036                                 K ek;
1037                                 if (e.hash == hash &amp;&amp;
1038                                     ((ek = e.key) == key ||
1039                                      (ek != null &amp;&amp; key.equals(ek)))) {
1040                                     oldVal = e.val;
1041                                     if (!onlyIfAbsent)
1042                                         e.val = value;
1043                                     break;
1044                                 }
1045                                 Node&lt;K,V&gt; pred = e;
1046                                 if ((e = e.next) == null) {
1047                                     pred.next = new Node&lt;K,V&gt;(hash, key, value);
1048                                     break;
1049                                 }
1050                             }
1051                         }
1052                         else if (f instanceof TreeBin) {
1053                             Node&lt;K,V&gt; p;
1054                             binCount = 2;
1055                             if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,
1056                                                            value)) != null) {
1057                                 oldVal = p.val;
1058                                 if (!onlyIfAbsent)
1059                                     p.val = value;
1060                             }
1061                         }
1062                         else if (f instanceof ReservationNode)
1063                             throw new IllegalStateException(&quot;Recursive update&quot;);
1064                     }
1065                 }
1066                 if (binCount != 0) {
1067                     if (binCount &gt;= TREEIFY_THRESHOLD)
1068                         treeifyBin(tab, i);
1069                     if (oldVal != null)
1070                         return oldVal;
1071                     break;
1072                 }
1073             }
1074         }
1075         addCount(1L, binCount);
1076         return null;
1077     }
1078 
1079     /**
1080      * Copies all of the mappings from the specified map to this one.
1081      * These mappings replace any mappings that this map had for any of the
1082      * keys currently in the specified map.
1083      *
1084      * @param m mappings to be stored in this map
1085      */
1086     public void putAll(Map&lt;? extends K, ? extends V&gt; m) {
1087         tryPresize(m.size());
1088         for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet())
1089             putVal(e.getKey(), e.getValue(), false);
1090     }
1091 
1092     /**
1093      * Removes the key (and its corresponding value) from this map.
1094      * This method does nothing if the key is not in the map.
1095      *
1096      * @param  key the key that needs to be removed
1097      * @return the previous value associated with {@code key}, or
1098      *         {@code null} if there was no mapping for {@code key}
1099      * @throws NullPointerException if the specified key is null
1100      */
1101     public V remove(Object key) {
1102         return replaceNode(key, null, null);
1103     }
1104 
1105     /**
1106      * Implementation for the four public remove/replace methods:
1107      * Replaces node value with v, conditional upon match of cv if
1108      * non-null.  If resulting value is null, delete.
1109      */
1110     final V replaceNode(Object key, V value, Object cv) {
1111         int hash = spread(key.hashCode());
1112         for (Node&lt;K,V&gt;[] tab = table;;) {
1113             Node&lt;K,V&gt; f; int n, i, fh;
1114             if (tab == null || (n = tab.length) == 0 ||
1115                 (f = tabAt(tab, i = (n - 1) &amp; hash)) == null)
1116                 break;
1117             else if ((fh = f.hash) == MOVED)
1118                 tab = helpTransfer(tab, f);
1119             else {
1120                 V oldVal = null;
1121                 boolean validated = false;
1122                 synchronized (f) {
1123                     if (tabAt(tab, i) == f) {
1124                         if (fh &gt;= 0) {
1125                             validated = true;
1126                             for (Node&lt;K,V&gt; e = f, pred = null;;) {
1127                                 K ek;
1128                                 if (e.hash == hash &amp;&amp;
1129                                     ((ek = e.key) == key ||
1130                                      (ek != null &amp;&amp; key.equals(ek)))) {
1131                                     V ev = e.val;
1132                                     if (cv == null || cv == ev ||
1133                                         (ev != null &amp;&amp; cv.equals(ev))) {
1134                                         oldVal = ev;
1135                                         if (value != null)
1136                                             e.val = value;
1137                                         else if (pred != null)
1138                                             pred.next = e.next;
1139                                         else
1140                                             setTabAt(tab, i, e.next);
1141                                     }
1142                                     break;
1143                                 }
1144                                 pred = e;
1145                                 if ((e = e.next) == null)
1146                                     break;
1147                             }
1148                         }
1149                         else if (f instanceof TreeBin) {
1150                             validated = true;
1151                             TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;
1152                             TreeNode&lt;K,V&gt; r, p;
1153                             if ((r = t.root) != null &amp;&amp;
1154                                 (p = r.findTreeNode(hash, key, null)) != null) {
1155                                 V pv = p.val;
1156                                 if (cv == null || cv == pv ||
1157                                     (pv != null &amp;&amp; cv.equals(pv))) {
1158                                     oldVal = pv;
1159                                     if (value != null)
1160                                         p.val = value;
1161                                     else if (t.removeTreeNode(p))
1162                                         setTabAt(tab, i, untreeify(t.first));
1163                                 }
1164                             }
1165                         }
1166                         else if (f instanceof ReservationNode)
1167                             throw new IllegalStateException(&quot;Recursive update&quot;);
1168                     }
1169                 }
1170                 if (validated) {
1171                     if (oldVal != null) {
1172                         if (value == null)
1173                             addCount(-1L, -1);
1174                         return oldVal;
1175                     }
1176                     break;
1177                 }
1178             }
1179         }
1180         return null;
1181     }
1182 
1183     /**
1184      * Removes all of the mappings from this map.
1185      */
1186     public void clear() {
1187         long delta = 0L; // negative number of deletions
1188         int i = 0;
1189         Node&lt;K,V&gt;[] tab = table;
1190         while (tab != null &amp;&amp; i &lt; tab.length) {
1191             int fh;
1192             Node&lt;K,V&gt; f = tabAt(tab, i);
1193             if (f == null)
1194                 ++i;
1195             else if ((fh = f.hash) == MOVED) {
1196                 tab = helpTransfer(tab, f);
1197                 i = 0; // restart
1198             }
1199             else {
1200                 synchronized (f) {
1201                     if (tabAt(tab, i) == f) {
1202                         Node&lt;K,V&gt; p = (fh &gt;= 0 ? f :
1203                                        (f instanceof TreeBin) ?
1204                                        ((TreeBin&lt;K,V&gt;)f).first : null);
1205                         while (p != null) {
1206                             --delta;
1207                             p = p.next;
1208                         }
1209                         setTabAt(tab, i++, null);
1210                     }
1211                 }
1212             }
1213         }
1214         if (delta != 0L)
1215             addCount(delta, -1);
1216     }
1217 
1218     /**
1219      * Returns a {@link Set} view of the keys contained in this map.
1220      * The set is backed by the map, so changes to the map are
1221      * reflected in the set, and vice-versa. The set supports element
1222      * removal, which removes the corresponding mapping from this map,
1223      * via the {@code Iterator.remove}, {@code Set.remove},
1224      * {@code removeAll}, {@code retainAll}, and {@code clear}
1225      * operations.  It does not support the {@code add} or
1226      * {@code addAll} operations.
1227      *
1228      * &lt;p&gt;The view&#39;s iterators and spliterators are
1229      * &lt;a href=&quot;package-summary.html#Weakly&quot;&gt;&lt;i&gt;weakly consistent&lt;/i&gt;&lt;/a&gt;.
1230      *
1231      * &lt;p&gt;The view&#39;s {@code spliterator} reports {@link Spliterator#CONCURRENT},
1232      * {@link Spliterator#DISTINCT}, and {@link Spliterator#NONNULL}.
1233      *
1234      * @return the set view
1235      */
1236     public KeySetView&lt;K,V&gt; keySet() {
1237         KeySetView&lt;K,V&gt; ks;
1238         if ((ks = keySet) != null) return ks;
1239         return keySet = new KeySetView&lt;K,V&gt;(this, null);
1240     }
1241 
1242     /**
1243      * Returns a {@link Collection} view of the values contained in this map.
1244      * The collection is backed by the map, so changes to the map are
1245      * reflected in the collection, and vice-versa.  The collection
1246      * supports element removal, which removes the corresponding
1247      * mapping from this map, via the {@code Iterator.remove},
1248      * {@code Collection.remove}, {@code removeAll},
1249      * {@code retainAll}, and {@code clear} operations.  It does not
1250      * support the {@code add} or {@code addAll} operations.
1251      *
1252      * &lt;p&gt;The view&#39;s iterators and spliterators are
1253      * &lt;a href=&quot;package-summary.html#Weakly&quot;&gt;&lt;i&gt;weakly consistent&lt;/i&gt;&lt;/a&gt;.
1254      *
1255      * &lt;p&gt;The view&#39;s {@code spliterator} reports {@link Spliterator#CONCURRENT}
1256      * and {@link Spliterator#NONNULL}.
1257      *
1258      * @return the collection view
1259      */
1260     public Collection&lt;V&gt; values() {
1261         ValuesView&lt;K,V&gt; vs;
1262         if ((vs = values) != null) return vs;
1263         return values = new ValuesView&lt;K,V&gt;(this);
1264     }
1265 
1266     /**
1267      * Returns a {@link Set} view of the mappings contained in this map.
1268      * The set is backed by the map, so changes to the map are
1269      * reflected in the set, and vice-versa.  The set supports element
1270      * removal, which removes the corresponding mapping from the map,
1271      * via the {@code Iterator.remove}, {@code Set.remove},
1272      * {@code removeAll}, {@code retainAll}, and {@code clear}
1273      * operations.
1274      *
1275      * &lt;p&gt;The view&#39;s iterators and spliterators are
1276      * &lt;a href=&quot;package-summary.html#Weakly&quot;&gt;&lt;i&gt;weakly consistent&lt;/i&gt;&lt;/a&gt;.
1277      *
1278      * &lt;p&gt;The view&#39;s {@code spliterator} reports {@link Spliterator#CONCURRENT},
1279      * {@link Spliterator#DISTINCT}, and {@link Spliterator#NONNULL}.
1280      *
1281      * @return the set view
1282      */
1283     public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() {
1284         EntrySetView&lt;K,V&gt; es;
1285         if ((es = entrySet) != null) return es;
1286         return entrySet = new EntrySetView&lt;K,V&gt;(this);
1287     }
1288 
1289     /**
1290      * Returns the hash code value for this {@link Map}, i.e.,
1291      * the sum of, for each key-value pair in the map,
1292      * {@code key.hashCode() ^ value.hashCode()}.
1293      *
1294      * @return the hash code value for this map
1295      */
1296     public int hashCode() {
1297         int h = 0;
1298         Node&lt;K,V&gt;[] t;
1299         if ((t = table) != null) {
1300             Traverser&lt;K,V&gt; it = new Traverser&lt;K,V&gt;(t, t.length, 0, t.length);
1301             for (Node&lt;K,V&gt; p; (p = it.advance()) != null; )
1302                 h += p.key.hashCode() ^ p.val.hashCode();
1303         }
1304         return h;
1305     }
1306 
1307     /**
1308      * Returns a string representation of this map.  The string
1309      * representation consists of a list of key-value mappings (in no
1310      * particular order) enclosed in braces (&quot;{@code {}}&quot;).  Adjacent
1311      * mappings are separated by the characters {@code &quot;, &quot;} (comma
1312      * and space).  Each key-value mapping is rendered as the key
1313      * followed by an equals sign (&quot;{@code =}&quot;) followed by the
1314      * associated value.
1315      *
1316      * @return a string representation of this map
1317      */
1318     public String toString() {
1319         Node&lt;K,V&gt;[] t;
1320         int f = (t = table) == null ? 0 : t.length;
1321         Traverser&lt;K,V&gt; it = new Traverser&lt;K,V&gt;(t, f, 0, f);
1322         StringBuilder sb = new StringBuilder();
1323         sb.append(&#39;{&#39;);
1324         Node&lt;K,V&gt; p;
1325         if ((p = it.advance()) != null) {
1326             for (;;) {
1327                 K k = p.key;
1328                 V v = p.val;
1329                 sb.append(k == this ? &quot;(this Map)&quot; : k);
1330                 sb.append(&#39;=&#39;);
1331                 sb.append(v == this ? &quot;(this Map)&quot; : v);
1332                 if ((p = it.advance()) == null)
1333                     break;
1334                 sb.append(&#39;,&#39;).append(&#39; &#39;);
1335             }
1336         }
1337         return sb.append(&#39;}&#39;).toString();
1338     }
1339 
1340     /**
1341      * Compares the specified object with this map for equality.
1342      * Returns {@code true} if the given object is a map with the same
1343      * mappings as this map.  This operation may return misleading
1344      * results if either map is concurrently modified during execution
1345      * of this method.
1346      *
1347      * @param o object to be compared for equality with this map
1348      * @return {@code true} if the specified object is equal to this map
1349      */
1350     public boolean equals(Object o) {
1351         if (o != this) {
1352             if (!(o instanceof Map))
1353                 return false;
1354             Map&lt;?,?&gt; m = (Map&lt;?,?&gt;) o;
1355             Node&lt;K,V&gt;[] t;
1356             int f = (t = table) == null ? 0 : t.length;
1357             Traverser&lt;K,V&gt; it = new Traverser&lt;K,V&gt;(t, f, 0, f);
1358             for (Node&lt;K,V&gt; p; (p = it.advance()) != null; ) {
1359                 V val = p.val;
1360                 Object v = m.get(p.key);
1361                 if (v == null || (v != val &amp;&amp; !v.equals(val)))
1362                     return false;
1363             }
1364             for (Map.Entry&lt;?,?&gt; e : m.entrySet()) {
1365                 Object mk, mv, v;
1366                 if ((mk = e.getKey()) == null ||
1367                     (mv = e.getValue()) == null ||
1368                     (v = get(mk)) == null ||
1369                     (mv != v &amp;&amp; !mv.equals(v)))
1370                     return false;
1371             }
1372         }
1373         return true;
1374     }
1375 
1376     /**
1377      * Stripped-down version of helper class used in previous version,
1378      * declared for the sake of serialization compatibility.
1379      */
1380     static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable {
1381         private static final long serialVersionUID = 2249069246763182397L;
1382         final float loadFactor;
1383         Segment(float lf) { this.loadFactor = lf; }
1384     }
1385 
1386     /**
1387      * Saves this map to a stream (that is, serializes it).
1388      *
1389      * @param s the stream
1390      * @throws java.io.IOException if an I/O error occurs
1391      * @serialData
1392      * the serialized fields, followed by the key (Object) and value
1393      * (Object) for each key-value mapping, followed by a null pair.
1394      * The key-value mappings are emitted in no particular order.
1395      */
1396     private void writeObject(java.io.ObjectOutputStream s)
1397         throws java.io.IOException {
1398         // For serialization compatibility
1399         // Emulate segment calculation from previous version of this class
1400         int sshift = 0;
1401         int ssize = 1;
1402         while (ssize &lt; DEFAULT_CONCURRENCY_LEVEL) {
1403             ++sshift;
1404             ssize &lt;&lt;= 1;
1405         }
1406         int segmentShift = 32 - sshift;
1407         int segmentMask = ssize - 1;
1408         @SuppressWarnings(&quot;unchecked&quot;)
1409         Segment&lt;K,V&gt;[] segments = (Segment&lt;K,V&gt;[])
1410             new Segment&lt;?,?&gt;[DEFAULT_CONCURRENCY_LEVEL];
1411         for (int i = 0; i &lt; segments.length; ++i)
1412             segments[i] = new Segment&lt;K,V&gt;(LOAD_FACTOR);
1413         java.io.ObjectOutputStream.PutField streamFields = s.putFields();
1414         streamFields.put(&quot;segments&quot;, segments);
1415         streamFields.put(&quot;segmentShift&quot;, segmentShift);
1416         streamFields.put(&quot;segmentMask&quot;, segmentMask);
1417         s.writeFields();
1418 
1419         Node&lt;K,V&gt;[] t;
1420         if ((t = table) != null) {
1421             Traverser&lt;K,V&gt; it = new Traverser&lt;K,V&gt;(t, t.length, 0, t.length);
1422             for (Node&lt;K,V&gt; p; (p = it.advance()) != null; ) {
1423                 s.writeObject(p.key);
1424                 s.writeObject(p.val);
1425             }
1426         }
1427         s.writeObject(null);
1428         s.writeObject(null);
1429     }
1430 
1431     /**
1432      * Reconstitutes this map from a stream (that is, deserializes it).
1433      * @param s the stream
1434      * @throws ClassNotFoundException if the class of a serialized object
1435      *         could not be found
1436      * @throws java.io.IOException if an I/O error occurs
1437      */
1438     private void readObject(java.io.ObjectInputStream s)
1439         throws java.io.IOException, ClassNotFoundException {
1440         /*
1441          * To improve performance in typical cases, we create nodes
1442          * while reading, then place in table once size is known.
1443          * However, we must also validate uniqueness and deal with
1444          * overpopulated bins while doing so, which requires
1445          * specialized versions of putVal mechanics.
1446          */
1447         sizeCtl = -1; // force exclusion for table construction
1448         s.defaultReadObject();
1449         long size = 0L;
1450         Node&lt;K,V&gt; p = null;
1451         for (;;) {
1452             @SuppressWarnings(&quot;unchecked&quot;)
1453             K k = (K) s.readObject();
1454             @SuppressWarnings(&quot;unchecked&quot;)
1455             V v = (V) s.readObject();
1456             if (k != null &amp;&amp; v != null) {
1457                 p = new Node&lt;K,V&gt;(spread(k.hashCode()), k, v, p);
1458                 ++size;
1459             }
1460             else
1461                 break;
1462         }
1463         if (size == 0L)
1464             sizeCtl = 0;
1465         else {
1466             long ts = (long)(1.0 + size / LOAD_FACTOR);
1467             int n = (ts &gt;= (long)MAXIMUM_CAPACITY) ?
1468                 MAXIMUM_CAPACITY : tableSizeFor((int)ts);
1469             @SuppressWarnings(&quot;unchecked&quot;)
1470             Node&lt;K,V&gt;[] tab = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];
1471             int mask = n - 1;
1472             long added = 0L;
1473             while (p != null) {
1474                 boolean insertAtFront;
1475                 Node&lt;K,V&gt; next = p.next, first;
1476                 int h = p.hash, j = h &amp; mask;
1477                 if ((first = tabAt(tab, j)) == null)
1478                     insertAtFront = true;
1479                 else {
1480                     K k = p.key;
1481                     if (first.hash &lt; 0) {
1482                         TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)first;
1483                         if (t.putTreeVal(h, k, p.val) == null)
1484                             ++added;
1485                         insertAtFront = false;
1486                     }
1487                     else {
1488                         int binCount = 0;
1489                         insertAtFront = true;
1490                         Node&lt;K,V&gt; q; K qk;
1491                         for (q = first; q != null; q = q.next) {
1492                             if (q.hash == h &amp;&amp;
1493                                 ((qk = q.key) == k ||
1494                                  (qk != null &amp;&amp; k.equals(qk)))) {
1495                                 insertAtFront = false;
1496                                 break;
1497                             }
1498                             ++binCount;
1499                         }
1500                         if (insertAtFront &amp;&amp; binCount &gt;= TREEIFY_THRESHOLD) {
1501                             insertAtFront = false;
1502                             ++added;
1503                             p.next = first;
1504                             TreeNode&lt;K,V&gt; hd = null, tl = null;
1505                             for (q = p; q != null; q = q.next) {
1506                                 TreeNode&lt;K,V&gt; t = new TreeNode&lt;K,V&gt;
1507                                     (q.hash, q.key, q.val, null, null);
1508                                 if ((t.prev = tl) == null)
1509                                     hd = t;
1510                                 else
1511                                     tl.next = t;
1512                                 tl = t;
1513                             }
1514                             setTabAt(tab, j, new TreeBin&lt;K,V&gt;(hd));
1515                         }
1516                     }
1517                 }
1518                 if (insertAtFront) {
1519                     ++added;
1520                     p.next = first;
1521                     setTabAt(tab, j, p);
1522                 }
1523                 p = next;
1524             }
1525             table = tab;
1526             sizeCtl = n - (n &gt;&gt;&gt; 2);
1527             baseCount = added;
1528         }
1529     }
1530 
1531     // ConcurrentMap methods
1532 
1533     /**
1534      * {@inheritDoc}
1535      *
1536      * @return the previous value associated with the specified key,
1537      *         or {@code null} if there was no mapping for the key
1538      * @throws NullPointerException if the specified key or value is null
1539      */
1540     public V putIfAbsent(K key, V value) {
1541         return putVal(key, value, true);
1542     }
1543 
1544     /**
1545      * {@inheritDoc}
1546      *
1547      * @throws NullPointerException if the specified key is null
1548      */
1549     public boolean remove(Object key, Object value) {
1550         if (key == null)
1551             throw new NullPointerException();
1552         return value != null &amp;&amp; replaceNode(key, null, value) != null;
1553     }
1554 
1555     /**
1556      * {@inheritDoc}
1557      *
1558      * @throws NullPointerException if any of the arguments are null
1559      */
1560     public boolean replace(K key, V oldValue, V newValue) {
1561         if (key == null || oldValue == null || newValue == null)
1562             throw new NullPointerException();
1563         return replaceNode(key, newValue, oldValue) != null;
1564     }
1565 
1566     /**
1567      * {@inheritDoc}
1568      *
1569      * @return the previous value associated with the specified key,
1570      *         or {@code null} if there was no mapping for the key
1571      * @throws NullPointerException if the specified key or value is null
1572      */
1573     public V replace(K key, V value) {
1574         if (key == null || value == null)
1575             throw new NullPointerException();
1576         return replaceNode(key, value, null);
1577     }
1578 
1579     // Overrides of JDK8+ Map extension method defaults
1580 
1581     /**
1582      * Returns the value to which the specified key is mapped, or the
1583      * given default value if this map contains no mapping for the
1584      * key.
1585      *
1586      * @param key the key whose associated value is to be returned
1587      * @param defaultValue the value to return if this map contains
1588      * no mapping for the given key
1589      * @return the mapping for the key, if present; else the default value
1590      * @throws NullPointerException if the specified key is null
1591      */
1592     public V getOrDefault(Object key, V defaultValue) {
1593         V v;
1594         return (v = get(key)) == null ? defaultValue : v;
1595     }
1596 
1597     public void forEach(BiConsumer&lt;? super K, ? super V&gt; action) {
1598         if (action == null) throw new NullPointerException();
1599         Node&lt;K,V&gt;[] t;
1600         if ((t = table) != null) {
1601             Traverser&lt;K,V&gt; it = new Traverser&lt;K,V&gt;(t, t.length, 0, t.length);
1602             for (Node&lt;K,V&gt; p; (p = it.advance()) != null; ) {
1603                 action.accept(p.key, p.val);
1604             }
1605         }
1606     }
1607 
1608     public void replaceAll(BiFunction&lt;? super K, ? super V, ? extends V&gt; function) {
1609         if (function == null) throw new NullPointerException();
1610         Node&lt;K,V&gt;[] t;
1611         if ((t = table) != null) {
1612             Traverser&lt;K,V&gt; it = new Traverser&lt;K,V&gt;(t, t.length, 0, t.length);
1613             for (Node&lt;K,V&gt; p; (p = it.advance()) != null; ) {
1614                 V oldValue = p.val;
1615                 for (K key = p.key;;) {
1616                     V newValue = function.apply(key, oldValue);
1617                     if (newValue == null)
1618                         throw new NullPointerException();
1619                     if (replaceNode(key, newValue, oldValue) != null ||
1620                         (oldValue = get(key)) == null)
1621                         break;
1622                 }
1623             }
1624         }
1625     }
1626 
1627     /**
1628      * Helper method for EntrySetView.removeIf.
1629      */
1630     boolean removeEntryIf(Predicate&lt;? super Entry&lt;K,V&gt;&gt; function) {
1631         if (function == null) throw new NullPointerException();
1632         Node&lt;K,V&gt;[] t;
1633         boolean removed = false;
1634         if ((t = table) != null) {
1635             Traverser&lt;K,V&gt; it = new Traverser&lt;K,V&gt;(t, t.length, 0, t.length);
1636             for (Node&lt;K,V&gt; p; (p = it.advance()) != null; ) {
1637                 K k = p.key;
1638                 V v = p.val;
1639                 Map.Entry&lt;K,V&gt; e = new AbstractMap.SimpleImmutableEntry&lt;&gt;(k, v);
1640                 if (function.test(e) &amp;&amp; replaceNode(k, null, v) != null)
1641                     removed = true;
1642             }
1643         }
1644         return removed;
1645     }
1646 
1647     /**
1648      * Helper method for ValuesView.removeIf.
1649      */
1650     boolean removeValueIf(Predicate&lt;? super V&gt; function) {
1651         if (function == null) throw new NullPointerException();
1652         Node&lt;K,V&gt;[] t;
1653         boolean removed = false;
1654         if ((t = table) != null) {
1655             Traverser&lt;K,V&gt; it = new Traverser&lt;K,V&gt;(t, t.length, 0, t.length);
1656             for (Node&lt;K,V&gt; p; (p = it.advance()) != null; ) {
1657                 K k = p.key;
1658                 V v = p.val;
1659                 if (function.test(v) &amp;&amp; replaceNode(k, null, v) != null)
1660                     removed = true;
1661             }
1662         }
1663         return removed;
1664     }
1665 
1666     /**
1667      * If the specified key is not already associated with a value,
1668      * attempts to compute its value using the given mapping function
1669      * and enters it into this map unless {@code null}.  The entire
<a name="2" id="anc2"></a><span class="line-modified">1670      * method invocation is performed atomically.  The supplied</span>
<span class="line-modified">1671      * function is invoked exactly once per invocation of this method</span>
<span class="line-modified">1672      * if the key is absent, else not at all.  Some attempted update</span>
<span class="line-modified">1673      * operations on this map by other threads may be blocked while</span>
<span class="line-modified">1674      * computation is in progress, so the computation should be short</span>
<span class="line-added">1675      * and simple.</span>
<span class="line-added">1676      *</span>
<span class="line-added">1677      * &lt;p&gt;The mapping function must not modify this map during computation.</span>
1678      *
1679      * @param key key with which the specified value is to be associated
1680      * @param mappingFunction the function to compute a value
1681      * @return the current (existing or computed) value associated with
1682      *         the specified key, or null if the computed value is null
1683      * @throws NullPointerException if the specified key or mappingFunction
1684      *         is null
1685      * @throws IllegalStateException if the computation detectably
1686      *         attempts a recursive update to this map that would
1687      *         otherwise never complete
1688      * @throws RuntimeException or Error if the mappingFunction does so,
1689      *         in which case the mapping is left unestablished
1690      */
1691     public V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction) {
1692         if (key == null || mappingFunction == null)
1693             throw new NullPointerException();
1694         int h = spread(key.hashCode());
1695         V val = null;
1696         int binCount = 0;
1697         for (Node&lt;K,V&gt;[] tab = table;;) {
1698             Node&lt;K,V&gt; f; int n, i, fh; K fk; V fv;
1699             if (tab == null || (n = tab.length) == 0)
1700                 tab = initTable();
1701             else if ((f = tabAt(tab, i = (n - 1) &amp; h)) == null) {
1702                 Node&lt;K,V&gt; r = new ReservationNode&lt;K,V&gt;();
1703                 synchronized (r) {
1704                     if (casTabAt(tab, i, null, r)) {
1705                         binCount = 1;
1706                         Node&lt;K,V&gt; node = null;
1707                         try {
1708                             if ((val = mappingFunction.apply(key)) != null)
1709                                 node = new Node&lt;K,V&gt;(h, key, val);
1710                         } finally {
1711                             setTabAt(tab, i, node);
1712                         }
1713                     }
1714                 }
1715                 if (binCount != 0)
1716                     break;
1717             }
1718             else if ((fh = f.hash) == MOVED)
1719                 tab = helpTransfer(tab, f);
1720             else if (fh == h    // check first node without acquiring lock
1721                      &amp;&amp; ((fk = f.key) == key || (fk != null &amp;&amp; key.equals(fk)))
1722                      &amp;&amp; (fv = f.val) != null)
1723                 return fv;
1724             else {
1725                 boolean added = false;
1726                 synchronized (f) {
1727                     if (tabAt(tab, i) == f) {
1728                         if (fh &gt;= 0) {
1729                             binCount = 1;
1730                             for (Node&lt;K,V&gt; e = f;; ++binCount) {
1731                                 K ek;
1732                                 if (e.hash == h &amp;&amp;
1733                                     ((ek = e.key) == key ||
1734                                      (ek != null &amp;&amp; key.equals(ek)))) {
1735                                     val = e.val;
1736                                     break;
1737                                 }
1738                                 Node&lt;K,V&gt; pred = e;
1739                                 if ((e = e.next) == null) {
1740                                     if ((val = mappingFunction.apply(key)) != null) {
1741                                         if (pred.next != null)
1742                                             throw new IllegalStateException(&quot;Recursive update&quot;);
1743                                         added = true;
1744                                         pred.next = new Node&lt;K,V&gt;(h, key, val);
1745                                     }
1746                                     break;
1747                                 }
1748                             }
1749                         }
1750                         else if (f instanceof TreeBin) {
1751                             binCount = 2;
1752                             TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;
1753                             TreeNode&lt;K,V&gt; r, p;
1754                             if ((r = t.root) != null &amp;&amp;
1755                                 (p = r.findTreeNode(h, key, null)) != null)
1756                                 val = p.val;
1757                             else if ((val = mappingFunction.apply(key)) != null) {
1758                                 added = true;
1759                                 t.putTreeVal(h, key, val);
1760                             }
1761                         }
1762                         else if (f instanceof ReservationNode)
1763                             throw new IllegalStateException(&quot;Recursive update&quot;);
1764                     }
1765                 }
1766                 if (binCount != 0) {
1767                     if (binCount &gt;= TREEIFY_THRESHOLD)
1768                         treeifyBin(tab, i);
1769                     if (!added)
1770                         return val;
1771                     break;
1772                 }
1773             }
1774         }
1775         if (val != null)
1776             addCount(1L, binCount);
1777         return val;
1778     }
1779 
1780     /**
1781      * If the value for the specified key is present, attempts to
1782      * compute a new mapping given the key and its current mapped
1783      * value.  The entire method invocation is performed atomically.
<a name="3" id="anc3"></a><span class="line-modified">1784      * The supplied function is invoked exactly once per invocation of</span>
<span class="line-modified">1785      * this method if the key is present, else not at all.  Some</span>
<span class="line-modified">1786      * attempted update operations on this map by other threads may be</span>
<span class="line-modified">1787      * blocked while computation is in progress, so the computation</span>
<span class="line-added">1788      * should be short and simple.</span>
<span class="line-added">1789      *</span>
<span class="line-added">1790      * &lt;p&gt;The remapping function must not modify this map during computation.</span>
1791      *
1792      * @param key key with which a value may be associated
1793      * @param remappingFunction the function to compute a value
1794      * @return the new value associated with the specified key, or null if none
1795      * @throws NullPointerException if the specified key or remappingFunction
1796      *         is null
1797      * @throws IllegalStateException if the computation detectably
1798      *         attempts a recursive update to this map that would
1799      *         otherwise never complete
1800      * @throws RuntimeException or Error if the remappingFunction does so,
1801      *         in which case the mapping is unchanged
1802      */
1803     public V computeIfPresent(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) {
1804         if (key == null || remappingFunction == null)
1805             throw new NullPointerException();
1806         int h = spread(key.hashCode());
1807         V val = null;
1808         int delta = 0;
1809         int binCount = 0;
1810         for (Node&lt;K,V&gt;[] tab = table;;) {
1811             Node&lt;K,V&gt; f; int n, i, fh;
1812             if (tab == null || (n = tab.length) == 0)
1813                 tab = initTable();
1814             else if ((f = tabAt(tab, i = (n - 1) &amp; h)) == null)
1815                 break;
1816             else if ((fh = f.hash) == MOVED)
1817                 tab = helpTransfer(tab, f);
1818             else {
1819                 synchronized (f) {
1820                     if (tabAt(tab, i) == f) {
1821                         if (fh &gt;= 0) {
1822                             binCount = 1;
1823                             for (Node&lt;K,V&gt; e = f, pred = null;; ++binCount) {
1824                                 K ek;
1825                                 if (e.hash == h &amp;&amp;
1826                                     ((ek = e.key) == key ||
1827                                      (ek != null &amp;&amp; key.equals(ek)))) {
1828                                     val = remappingFunction.apply(key, e.val);
1829                                     if (val != null)
1830                                         e.val = val;
1831                                     else {
1832                                         delta = -1;
1833                                         Node&lt;K,V&gt; en = e.next;
1834                                         if (pred != null)
1835                                             pred.next = en;
1836                                         else
1837                                             setTabAt(tab, i, en);
1838                                     }
1839                                     break;
1840                                 }
1841                                 pred = e;
1842                                 if ((e = e.next) == null)
1843                                     break;
1844                             }
1845                         }
1846                         else if (f instanceof TreeBin) {
1847                             binCount = 2;
1848                             TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;
1849                             TreeNode&lt;K,V&gt; r, p;
1850                             if ((r = t.root) != null &amp;&amp;
1851                                 (p = r.findTreeNode(h, key, null)) != null) {
1852                                 val = remappingFunction.apply(key, p.val);
1853                                 if (val != null)
1854                                     p.val = val;
1855                                 else {
1856                                     delta = -1;
1857                                     if (t.removeTreeNode(p))
1858                                         setTabAt(tab, i, untreeify(t.first));
1859                                 }
1860                             }
1861                         }
1862                         else if (f instanceof ReservationNode)
1863                             throw new IllegalStateException(&quot;Recursive update&quot;);
1864                     }
1865                 }
1866                 if (binCount != 0)
1867                     break;
1868             }
1869         }
1870         if (delta != 0)
1871             addCount((long)delta, binCount);
1872         return val;
1873     }
1874 
1875     /**
1876      * Attempts to compute a mapping for the specified key and its
1877      * current mapped value (or {@code null} if there is no current
1878      * mapping). The entire method invocation is performed atomically.
<a name="4" id="anc4"></a><span class="line-modified">1879      * The supplied function is invoked exactly once per invocation of</span>
<span class="line-modified">1880      * this method.  Some attempted update operations on this map by</span>
<span class="line-modified">1881      * other threads may be blocked while computation is in progress,</span>
<span class="line-modified">1882      * so the computation should be short and simple.</span>
<span class="line-added">1883      *</span>
<span class="line-added">1884      * &lt;p&gt;The remapping function must not modify this map during computation.</span>
1885      *
1886      * @param key key with which the specified value is to be associated
1887      * @param remappingFunction the function to compute a value
1888      * @return the new value associated with the specified key, or null if none
1889      * @throws NullPointerException if the specified key or remappingFunction
1890      *         is null
1891      * @throws IllegalStateException if the computation detectably
1892      *         attempts a recursive update to this map that would
1893      *         otherwise never complete
1894      * @throws RuntimeException or Error if the remappingFunction does so,
1895      *         in which case the mapping is unchanged
1896      */
1897     public V compute(K key,
1898                      BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) {
1899         if (key == null || remappingFunction == null)
1900             throw new NullPointerException();
1901         int h = spread(key.hashCode());
1902         V val = null;
1903         int delta = 0;
1904         int binCount = 0;
1905         for (Node&lt;K,V&gt;[] tab = table;;) {
1906             Node&lt;K,V&gt; f; int n, i, fh;
1907             if (tab == null || (n = tab.length) == 0)
1908                 tab = initTable();
1909             else if ((f = tabAt(tab, i = (n - 1) &amp; h)) == null) {
1910                 Node&lt;K,V&gt; r = new ReservationNode&lt;K,V&gt;();
1911                 synchronized (r) {
1912                     if (casTabAt(tab, i, null, r)) {
1913                         binCount = 1;
1914                         Node&lt;K,V&gt; node = null;
1915                         try {
1916                             if ((val = remappingFunction.apply(key, null)) != null) {
1917                                 delta = 1;
1918                                 node = new Node&lt;K,V&gt;(h, key, val);
1919                             }
1920                         } finally {
1921                             setTabAt(tab, i, node);
1922                         }
1923                     }
1924                 }
1925                 if (binCount != 0)
1926                     break;
1927             }
1928             else if ((fh = f.hash) == MOVED)
1929                 tab = helpTransfer(tab, f);
1930             else {
1931                 synchronized (f) {
1932                     if (tabAt(tab, i) == f) {
1933                         if (fh &gt;= 0) {
1934                             binCount = 1;
1935                             for (Node&lt;K,V&gt; e = f, pred = null;; ++binCount) {
1936                                 K ek;
1937                                 if (e.hash == h &amp;&amp;
1938                                     ((ek = e.key) == key ||
1939                                      (ek != null &amp;&amp; key.equals(ek)))) {
1940                                     val = remappingFunction.apply(key, e.val);
1941                                     if (val != null)
1942                                         e.val = val;
1943                                     else {
1944                                         delta = -1;
1945                                         Node&lt;K,V&gt; en = e.next;
1946                                         if (pred != null)
1947                                             pred.next = en;
1948                                         else
1949                                             setTabAt(tab, i, en);
1950                                     }
1951                                     break;
1952                                 }
1953                                 pred = e;
1954                                 if ((e = e.next) == null) {
1955                                     val = remappingFunction.apply(key, null);
1956                                     if (val != null) {
1957                                         if (pred.next != null)
1958                                             throw new IllegalStateException(&quot;Recursive update&quot;);
1959                                         delta = 1;
1960                                         pred.next = new Node&lt;K,V&gt;(h, key, val);
1961                                     }
1962                                     break;
1963                                 }
1964                             }
1965                         }
1966                         else if (f instanceof TreeBin) {
1967                             binCount = 1;
1968                             TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;
1969                             TreeNode&lt;K,V&gt; r, p;
1970                             if ((r = t.root) != null)
1971                                 p = r.findTreeNode(h, key, null);
1972                             else
1973                                 p = null;
1974                             V pv = (p == null) ? null : p.val;
1975                             val = remappingFunction.apply(key, pv);
1976                             if (val != null) {
1977                                 if (p != null)
1978                                     p.val = val;
1979                                 else {
1980                                     delta = 1;
1981                                     t.putTreeVal(h, key, val);
1982                                 }
1983                             }
1984                             else if (p != null) {
1985                                 delta = -1;
1986                                 if (t.removeTreeNode(p))
1987                                     setTabAt(tab, i, untreeify(t.first));
1988                             }
1989                         }
1990                         else if (f instanceof ReservationNode)
1991                             throw new IllegalStateException(&quot;Recursive update&quot;);
1992                     }
1993                 }
1994                 if (binCount != 0) {
1995                     if (binCount &gt;= TREEIFY_THRESHOLD)
1996                         treeifyBin(tab, i);
1997                     break;
1998                 }
1999             }
2000         }
2001         if (delta != 0)
2002             addCount((long)delta, binCount);
2003         return val;
2004     }
2005 
2006     /**
2007      * If the specified key is not already associated with a
2008      * (non-null) value, associates it with the given value.
2009      * Otherwise, replaces the value with the results of the given
2010      * remapping function, or removes if {@code null}. The entire
2011      * method invocation is performed atomically.  Some attempted
2012      * update operations on this map by other threads may be blocked
2013      * while computation is in progress, so the computation should be
2014      * short and simple, and must not attempt to update any other
2015      * mappings of this Map.
2016      *
2017      * @param key key with which the specified value is to be associated
2018      * @param value the value to use if absent
2019      * @param remappingFunction the function to recompute a value if present
2020      * @return the new value associated with the specified key, or null if none
2021      * @throws NullPointerException if the specified key or the
2022      *         remappingFunction is null
2023      * @throws RuntimeException or Error if the remappingFunction does so,
2024      *         in which case the mapping is unchanged
2025      */
2026     public V merge(K key, V value, BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) {
2027         if (key == null || value == null || remappingFunction == null)
2028             throw new NullPointerException();
2029         int h = spread(key.hashCode());
2030         V val = null;
2031         int delta = 0;
2032         int binCount = 0;
2033         for (Node&lt;K,V&gt;[] tab = table;;) {
2034             Node&lt;K,V&gt; f; int n, i, fh;
2035             if (tab == null || (n = tab.length) == 0)
2036                 tab = initTable();
2037             else if ((f = tabAt(tab, i = (n - 1) &amp; h)) == null) {
2038                 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(h, key, value))) {
2039                     delta = 1;
2040                     val = value;
2041                     break;
2042                 }
2043             }
2044             else if ((fh = f.hash) == MOVED)
2045                 tab = helpTransfer(tab, f);
2046             else {
2047                 synchronized (f) {
2048                     if (tabAt(tab, i) == f) {
2049                         if (fh &gt;= 0) {
2050                             binCount = 1;
2051                             for (Node&lt;K,V&gt; e = f, pred = null;; ++binCount) {
2052                                 K ek;
2053                                 if (e.hash == h &amp;&amp;
2054                                     ((ek = e.key) == key ||
2055                                      (ek != null &amp;&amp; key.equals(ek)))) {
2056                                     val = remappingFunction.apply(e.val, value);
2057                                     if (val != null)
2058                                         e.val = val;
2059                                     else {
2060                                         delta = -1;
2061                                         Node&lt;K,V&gt; en = e.next;
2062                                         if (pred != null)
2063                                             pred.next = en;
2064                                         else
2065                                             setTabAt(tab, i, en);
2066                                     }
2067                                     break;
2068                                 }
2069                                 pred = e;
2070                                 if ((e = e.next) == null) {
2071                                     delta = 1;
2072                                     val = value;
2073                                     pred.next = new Node&lt;K,V&gt;(h, key, val);
2074                                     break;
2075                                 }
2076                             }
2077                         }
2078                         else if (f instanceof TreeBin) {
2079                             binCount = 2;
2080                             TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;
2081                             TreeNode&lt;K,V&gt; r = t.root;
2082                             TreeNode&lt;K,V&gt; p = (r == null) ? null :
2083                                 r.findTreeNode(h, key, null);
2084                             val = (p == null) ? value :
2085                                 remappingFunction.apply(p.val, value);
2086                             if (val != null) {
2087                                 if (p != null)
2088                                     p.val = val;
2089                                 else {
2090                                     delta = 1;
2091                                     t.putTreeVal(h, key, val);
2092                                 }
2093                             }
2094                             else if (p != null) {
2095                                 delta = -1;
2096                                 if (t.removeTreeNode(p))
2097                                     setTabAt(tab, i, untreeify(t.first));
2098                             }
2099                         }
2100                         else if (f instanceof ReservationNode)
2101                             throw new IllegalStateException(&quot;Recursive update&quot;);
2102                     }
2103                 }
2104                 if (binCount != 0) {
2105                     if (binCount &gt;= TREEIFY_THRESHOLD)
2106                         treeifyBin(tab, i);
2107                     break;
2108                 }
2109             }
2110         }
2111         if (delta != 0)
2112             addCount((long)delta, binCount);
2113         return val;
2114     }
2115 
2116     // Hashtable legacy methods
2117 
2118     /**
2119      * Tests if some key maps into the specified value in this table.
2120      *
2121      * &lt;p&gt;Note that this method is identical in functionality to
2122      * {@link #containsValue(Object)}, and exists solely to ensure
2123      * full compatibility with class {@link java.util.Hashtable},
2124      * which supported this method prior to introduction of the
2125      * Java Collections Framework.
2126      *
2127      * @param  value a value to search for
2128      * @return {@code true} if and only if some key maps to the
2129      *         {@code value} argument in this table as
2130      *         determined by the {@code equals} method;
2131      *         {@code false} otherwise
2132      * @throws NullPointerException if the specified value is null
2133      */
2134     public boolean contains(Object value) {
2135         return containsValue(value);
2136     }
2137 
2138     /**
2139      * Returns an enumeration of the keys in this table.
2140      *
2141      * @return an enumeration of the keys in this table
2142      * @see #keySet()
2143      */
2144     public Enumeration&lt;K&gt; keys() {
2145         Node&lt;K,V&gt;[] t;
2146         int f = (t = table) == null ? 0 : t.length;
2147         return new KeyIterator&lt;K,V&gt;(t, f, 0, f, this);
2148     }
2149 
2150     /**
2151      * Returns an enumeration of the values in this table.
2152      *
2153      * @return an enumeration of the values in this table
2154      * @see #values()
2155      */
2156     public Enumeration&lt;V&gt; elements() {
2157         Node&lt;K,V&gt;[] t;
2158         int f = (t = table) == null ? 0 : t.length;
2159         return new ValueIterator&lt;K,V&gt;(t, f, 0, f, this);
2160     }
2161 
2162     // ConcurrentHashMap-only methods
2163 
2164     /**
2165      * Returns the number of mappings. This method should be used
2166      * instead of {@link #size} because a ConcurrentHashMap may
2167      * contain more mappings than can be represented as an int. The
2168      * value returned is an estimate; the actual count may differ if
2169      * there are concurrent insertions or removals.
2170      *
2171      * @return the number of mappings
2172      * @since 1.8
2173      */
2174     public long mappingCount() {
2175         long n = sumCount();
2176         return (n &lt; 0L) ? 0L : n; // ignore transient negative values
2177     }
2178 
2179     /**
2180      * Creates a new {@link Set} backed by a ConcurrentHashMap
2181      * from the given type to {@code Boolean.TRUE}.
2182      *
2183      * @param &lt;K&gt; the element type of the returned set
2184      * @return the new set
2185      * @since 1.8
2186      */
2187     public static &lt;K&gt; KeySetView&lt;K,Boolean&gt; newKeySet() {
2188         return new KeySetView&lt;K,Boolean&gt;
2189             (new ConcurrentHashMap&lt;K,Boolean&gt;(), Boolean.TRUE);
2190     }
2191 
2192     /**
2193      * Creates a new {@link Set} backed by a ConcurrentHashMap
2194      * from the given type to {@code Boolean.TRUE}.
2195      *
2196      * @param initialCapacity The implementation performs internal
2197      * sizing to accommodate this many elements.
2198      * @param &lt;K&gt; the element type of the returned set
2199      * @return the new set
2200      * @throws IllegalArgumentException if the initial capacity of
2201      * elements is negative
2202      * @since 1.8
2203      */
2204     public static &lt;K&gt; KeySetView&lt;K,Boolean&gt; newKeySet(int initialCapacity) {
2205         return new KeySetView&lt;K,Boolean&gt;
2206             (new ConcurrentHashMap&lt;K,Boolean&gt;(initialCapacity), Boolean.TRUE);
2207     }
2208 
2209     /**
2210      * Returns a {@link Set} view of the keys in this map, using the
2211      * given common mapped value for any additions (i.e., {@link
2212      * Collection#add} and {@link Collection#addAll(Collection)}).
2213      * This is of course only appropriate if it is acceptable to use
2214      * the same value for all additions from this view.
2215      *
2216      * @param mappedValue the mapped value to use for any additions
2217      * @return the set view
2218      * @throws NullPointerException if the mappedValue is null
2219      */
2220     public KeySetView&lt;K,V&gt; keySet(V mappedValue) {
2221         if (mappedValue == null)
2222             throw new NullPointerException();
2223         return new KeySetView&lt;K,V&gt;(this, mappedValue);
2224     }
2225 
2226     /* ---------------- Special Nodes -------------- */
2227 
2228     /**
2229      * A node inserted at head of bins during transfer operations.
2230      */
2231     static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; {
2232         final Node&lt;K,V&gt;[] nextTable;
2233         ForwardingNode(Node&lt;K,V&gt;[] tab) {
2234             super(MOVED, null, null);
2235             this.nextTable = tab;
2236         }
2237 
2238         Node&lt;K,V&gt; find(int h, Object k) {
2239             // loop to avoid arbitrarily deep recursion on forwarding nodes
2240             outer: for (Node&lt;K,V&gt;[] tab = nextTable;;) {
2241                 Node&lt;K,V&gt; e; int n;
2242                 if (k == null || tab == null || (n = tab.length) == 0 ||
2243                     (e = tabAt(tab, (n - 1) &amp; h)) == null)
2244                     return null;
2245                 for (;;) {
2246                     int eh; K ek;
2247                     if ((eh = e.hash) == h &amp;&amp;
2248                         ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek))))
2249                         return e;
2250                     if (eh &lt; 0) {
2251                         if (e instanceof ForwardingNode) {
2252                             tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable;
2253                             continue outer;
2254                         }
2255                         else
2256                             return e.find(h, k);
2257                     }
2258                     if ((e = e.next) == null)
2259                         return null;
2260                 }
2261             }
2262         }
2263     }
2264 
2265     /**
2266      * A place-holder node used in computeIfAbsent and compute.
2267      */
2268     static final class ReservationNode&lt;K,V&gt; extends Node&lt;K,V&gt; {
2269         ReservationNode() {
2270             super(RESERVED, null, null);
2271         }
2272 
2273         Node&lt;K,V&gt; find(int h, Object k) {
2274             return null;
2275         }
2276     }
2277 
2278     /* ---------------- Table Initialization and Resizing -------------- */
2279 
2280     /**
2281      * Returns the stamp bits for resizing a table of size n.
2282      * Must be negative when shifted left by RESIZE_STAMP_SHIFT.
2283      */
2284     static final int resizeStamp(int n) {
2285         return Integer.numberOfLeadingZeros(n) | (1 &lt;&lt; (RESIZE_STAMP_BITS - 1));
2286     }
2287 
2288     /**
2289      * Initializes table, using the size recorded in sizeCtl.
2290      */
2291     private final Node&lt;K,V&gt;[] initTable() {
2292         Node&lt;K,V&gt;[] tab; int sc;
2293         while ((tab = table) == null || tab.length == 0) {
2294             if ((sc = sizeCtl) &lt; 0)
2295                 Thread.yield(); // lost initialization race; just spin
2296             else if (U.compareAndSetInt(this, SIZECTL, sc, -1)) {
2297                 try {
2298                     if ((tab = table) == null || tab.length == 0) {
2299                         int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY;
2300                         @SuppressWarnings(&quot;unchecked&quot;)
2301                         Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];
2302                         table = tab = nt;
2303                         sc = n - (n &gt;&gt;&gt; 2);
2304                     }
2305                 } finally {
2306                     sizeCtl = sc;
2307                 }
2308                 break;
2309             }
2310         }
2311         return tab;
2312     }
2313 
2314     /**
2315      * Adds to count, and if table is too small and not already
2316      * resizing, initiates transfer. If already resizing, helps
2317      * perform transfer if work is available.  Rechecks occupancy
2318      * after a transfer to see if another resize is already needed
2319      * because resizings are lagging additions.
2320      *
2321      * @param x the count to add
2322      * @param check if &lt;0, don&#39;t check resize, if &lt;= 1 only check if uncontended
2323      */
2324     private final void addCount(long x, int check) {
2325         CounterCell[] cs; long b, s;
2326         if ((cs = counterCells) != null ||
2327             !U.compareAndSetLong(this, BASECOUNT, b = baseCount, s = b + x)) {
2328             CounterCell c; long v; int m;
2329             boolean uncontended = true;
2330             if (cs == null || (m = cs.length - 1) &lt; 0 ||
2331                 (c = cs[ThreadLocalRandom.getProbe() &amp; m]) == null ||
2332                 !(uncontended =
2333                   U.compareAndSetLong(c, CELLVALUE, v = c.value, v + x))) {
2334                 fullAddCount(x, uncontended);
2335                 return;
2336             }
2337             if (check &lt;= 1)
2338                 return;
2339             s = sumCount();
2340         }
2341         if (check &gt;= 0) {
2342             Node&lt;K,V&gt;[] tab, nt; int n, sc;
2343             while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp;
2344                    (n = tab.length) &lt; MAXIMUM_CAPACITY) {
2345                 int rs = resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT;
2346                 if (sc &lt; 0) {
2347                     if (sc == rs + MAX_RESIZERS || sc == rs + 1 ||
2348                         (nt = nextTable) == null || transferIndex &lt;= 0)
2349                         break;
2350                     if (U.compareAndSetInt(this, SIZECTL, sc, sc + 1))
2351                         transfer(tab, nt);
2352                 }
2353                 else if (U.compareAndSetInt(this, SIZECTL, sc, rs + 2))
2354                     transfer(tab, null);
2355                 s = sumCount();
2356             }
2357         }
2358     }
2359 
2360     /**
2361      * Helps transfer if a resize is in progress.
2362      */
2363     final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) {
2364         Node&lt;K,V&gt;[] nextTab; int sc;
2365         if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp;
2366             (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) {
2367             int rs = resizeStamp(tab.length) &lt;&lt; RESIZE_STAMP_SHIFT;
2368             while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp;
2369                    (sc = sizeCtl) &lt; 0) {
2370                 if (sc == rs + MAX_RESIZERS || sc == rs + 1 ||
2371                     transferIndex &lt;= 0)
2372                     break;
2373                 if (U.compareAndSetInt(this, SIZECTL, sc, sc + 1)) {
2374                     transfer(tab, nextTab);
2375                     break;
2376                 }
2377             }
2378             return nextTab;
2379         }
2380         return table;
2381     }
2382 
2383     /**
2384      * Tries to presize table to accommodate the given number of elements.
2385      *
2386      * @param size number of elements (doesn&#39;t need to be perfectly accurate)
2387      */
2388     private final void tryPresize(int size) {
2389         int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY :
2390             tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1);
2391         int sc;
2392         while ((sc = sizeCtl) &gt;= 0) {
2393             Node&lt;K,V&gt;[] tab = table; int n;
2394             if (tab == null || (n = tab.length) == 0) {
2395                 n = (sc &gt; c) ? sc : c;
2396                 if (U.compareAndSetInt(this, SIZECTL, sc, -1)) {
2397                     try {
2398                         if (table == tab) {
2399                             @SuppressWarnings(&quot;unchecked&quot;)
2400                             Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];
2401                             table = nt;
2402                             sc = n - (n &gt;&gt;&gt; 2);
2403                         }
2404                     } finally {
2405                         sizeCtl = sc;
2406                     }
2407                 }
2408             }
2409             else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY)
2410                 break;
2411             else if (tab == table) {
2412                 int rs = resizeStamp(n);
2413                 if (U.compareAndSetInt(this, SIZECTL, sc,
2414                                         (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2))
2415                     transfer(tab, null);
2416             }
2417         }
2418     }
2419 
2420     /**
2421      * Moves and/or copies the nodes in each bin to new table. See
2422      * above for explanation.
2423      */
2424     private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) {
2425         int n = tab.length, stride;
2426         if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE)
2427             stride = MIN_TRANSFER_STRIDE; // subdivide range
2428         if (nextTab == null) {            // initiating
2429             try {
2430                 @SuppressWarnings(&quot;unchecked&quot;)
2431                 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1];
2432                 nextTab = nt;
2433             } catch (Throwable ex) {      // try to cope with OOME
2434                 sizeCtl = Integer.MAX_VALUE;
2435                 return;
2436             }
2437             nextTable = nextTab;
2438             transferIndex = n;
2439         }
2440         int nextn = nextTab.length;
2441         ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab);
2442         boolean advance = true;
2443         boolean finishing = false; // to ensure sweep before committing nextTab
2444         for (int i = 0, bound = 0;;) {
2445             Node&lt;K,V&gt; f; int fh;
2446             while (advance) {
2447                 int nextIndex, nextBound;
2448                 if (--i &gt;= bound || finishing)
2449                     advance = false;
2450                 else if ((nextIndex = transferIndex) &lt;= 0) {
2451                     i = -1;
2452                     advance = false;
2453                 }
2454                 else if (U.compareAndSetInt
2455                          (this, TRANSFERINDEX, nextIndex,
2456                           nextBound = (nextIndex &gt; stride ?
2457                                        nextIndex - stride : 0))) {
2458                     bound = nextBound;
2459                     i = nextIndex - 1;
2460                     advance = false;
2461                 }
2462             }
2463             if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) {
2464                 int sc;
2465                 if (finishing) {
2466                     nextTable = null;
2467                     table = nextTab;
2468                     sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1);
2469                     return;
2470                 }
2471                 if (U.compareAndSetInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
2472                     if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT)
2473                         return;
2474                     finishing = advance = true;
2475                     i = n; // recheck before commit
2476                 }
2477             }
2478             else if ((f = tabAt(tab, i)) == null)
2479                 advance = casTabAt(tab, i, null, fwd);
2480             else if ((fh = f.hash) == MOVED)
2481                 advance = true; // already processed
2482             else {
2483                 synchronized (f) {
2484                     if (tabAt(tab, i) == f) {
2485                         Node&lt;K,V&gt; ln, hn;
2486                         if (fh &gt;= 0) {
2487                             int runBit = fh &amp; n;
2488                             Node&lt;K,V&gt; lastRun = f;
2489                             for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) {
2490                                 int b = p.hash &amp; n;
2491                                 if (b != runBit) {
2492                                     runBit = b;
2493                                     lastRun = p;
2494                                 }
2495                             }
2496                             if (runBit == 0) {
2497                                 ln = lastRun;
2498                                 hn = null;
2499                             }
2500                             else {
2501                                 hn = lastRun;
2502                                 ln = null;
2503                             }
2504                             for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) {
2505                                 int ph = p.hash; K pk = p.key; V pv = p.val;
2506                                 if ((ph &amp; n) == 0)
2507                                     ln = new Node&lt;K,V&gt;(ph, pk, pv, ln);
2508                                 else
2509                                     hn = new Node&lt;K,V&gt;(ph, pk, pv, hn);
2510                             }
2511                             setTabAt(nextTab, i, ln);
2512                             setTabAt(nextTab, i + n, hn);
2513                             setTabAt(tab, i, fwd);
2514                             advance = true;
2515                         }
2516                         else if (f instanceof TreeBin) {
2517                             TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;
2518                             TreeNode&lt;K,V&gt; lo = null, loTail = null;
2519                             TreeNode&lt;K,V&gt; hi = null, hiTail = null;
2520                             int lc = 0, hc = 0;
2521                             for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) {
2522                                 int h = e.hash;
2523                                 TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;
2524                                     (h, e.key, e.val, null, null);
2525                                 if ((h &amp; n) == 0) {
2526                                     if ((p.prev = loTail) == null)
2527                                         lo = p;
2528                                     else
2529                                         loTail.next = p;
2530                                     loTail = p;
2531                                     ++lc;
2532                                 }
2533                                 else {
2534                                     if ((p.prev = hiTail) == null)
2535                                         hi = p;
2536                                     else
2537                                         hiTail.next = p;
2538                                     hiTail = p;
2539                                     ++hc;
2540                                 }
2541                             }
2542                             ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
2543                                 (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t;
2544                             hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
2545                                 (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t;
2546                             setTabAt(nextTab, i, ln);
2547                             setTabAt(nextTab, i + n, hn);
2548                             setTabAt(tab, i, fwd);
2549                             advance = true;
2550                         }
2551                         else if (f instanceof ReservationNode)
2552                             throw new IllegalStateException(&quot;Recursive update&quot;);
2553                     }
2554                 }
2555             }
2556         }
2557     }
2558 
2559     /* ---------------- Counter support -------------- */
2560 
2561     /**
2562      * A padded cell for distributing counts.  Adapted from LongAdder
2563      * and Striped64.  See their internal docs for explanation.
2564      */
2565     @jdk.internal.vm.annotation.Contended static final class CounterCell {
2566         volatile long value;
2567         CounterCell(long x) { value = x; }
2568     }
2569 
2570     final long sumCount() {
2571         CounterCell[] cs = counterCells;
2572         long sum = baseCount;
2573         if (cs != null) {
2574             for (CounterCell c : cs)
2575                 if (c != null)
2576                     sum += c.value;
2577         }
2578         return sum;
2579     }
2580 
2581     // See LongAdder version for explanation
2582     private final void fullAddCount(long x, boolean wasUncontended) {
2583         int h;
2584         if ((h = ThreadLocalRandom.getProbe()) == 0) {
2585             ThreadLocalRandom.localInit();      // force initialization
2586             h = ThreadLocalRandom.getProbe();
2587             wasUncontended = true;
2588         }
2589         boolean collide = false;                // True if last slot nonempty
2590         for (;;) {
2591             CounterCell[] cs; CounterCell c; int n; long v;
2592             if ((cs = counterCells) != null &amp;&amp; (n = cs.length) &gt; 0) {
2593                 if ((c = cs[(n - 1) &amp; h]) == null) {
2594                     if (cellsBusy == 0) {            // Try to attach new Cell
2595                         CounterCell r = new CounterCell(x); // Optimistic create
2596                         if (cellsBusy == 0 &amp;&amp;
2597                             U.compareAndSetInt(this, CELLSBUSY, 0, 1)) {
2598                             boolean created = false;
2599                             try {               // Recheck under lock
2600                                 CounterCell[] rs; int m, j;
2601                                 if ((rs = counterCells) != null &amp;&amp;
2602                                     (m = rs.length) &gt; 0 &amp;&amp;
2603                                     rs[j = (m - 1) &amp; h] == null) {
2604                                     rs[j] = r;
2605                                     created = true;
2606                                 }
2607                             } finally {
2608                                 cellsBusy = 0;
2609                             }
2610                             if (created)
2611                                 break;
2612                             continue;           // Slot is now non-empty
2613                         }
2614                     }
2615                     collide = false;
2616                 }
2617                 else if (!wasUncontended)       // CAS already known to fail
2618                     wasUncontended = true;      // Continue after rehash
2619                 else if (U.compareAndSetLong(c, CELLVALUE, v = c.value, v + x))
2620                     break;
2621                 else if (counterCells != cs || n &gt;= NCPU)
2622                     collide = false;            // At max size or stale
2623                 else if (!collide)
2624                     collide = true;
2625                 else if (cellsBusy == 0 &amp;&amp;
2626                          U.compareAndSetInt(this, CELLSBUSY, 0, 1)) {
2627                     try {
2628                         if (counterCells == cs) // Expand table unless stale
2629                             counterCells = Arrays.copyOf(cs, n &lt;&lt; 1);
2630                     } finally {
2631                         cellsBusy = 0;
2632                     }
2633                     collide = false;
2634                     continue;                   // Retry with expanded table
2635                 }
2636                 h = ThreadLocalRandom.advanceProbe(h);
2637             }
2638             else if (cellsBusy == 0 &amp;&amp; counterCells == cs &amp;&amp;
2639                      U.compareAndSetInt(this, CELLSBUSY, 0, 1)) {
2640                 boolean init = false;
2641                 try {                           // Initialize table
2642                     if (counterCells == cs) {
2643                         CounterCell[] rs = new CounterCell[2];
2644                         rs[h &amp; 1] = new CounterCell(x);
2645                         counterCells = rs;
2646                         init = true;
2647                     }
2648                 } finally {
2649                     cellsBusy = 0;
2650                 }
2651                 if (init)
2652                     break;
2653             }
2654             else if (U.compareAndSetLong(this, BASECOUNT, v = baseCount, v + x))
2655                 break;                          // Fall back on using base
2656         }
2657     }
2658 
2659     /* ---------------- Conversion from/to TreeBins -------------- */
2660 
2661     /**
2662      * Replaces all linked nodes in bin at given index unless table is
2663      * too small, in which case resizes instead.
2664      */
2665     private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) {
2666         Node&lt;K,V&gt; b; int n;
2667         if (tab != null) {
2668             if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY)
2669                 tryPresize(n &lt;&lt; 1);
2670             else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) {
2671                 synchronized (b) {
2672                     if (tabAt(tab, index) == b) {
2673                         TreeNode&lt;K,V&gt; hd = null, tl = null;
2674                         for (Node&lt;K,V&gt; e = b; e != null; e = e.next) {
2675                             TreeNode&lt;K,V&gt; p =
2676                                 new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val,
2677                                                   null, null);
2678                             if ((p.prev = tl) == null)
2679                                 hd = p;
2680                             else
2681                                 tl.next = p;
2682                             tl = p;
2683                         }
2684                         setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd));
2685                     }
2686                 }
2687             }
2688         }
2689     }
2690 
2691     /**
2692      * Returns a list of non-TreeNodes replacing those in given list.
2693      */
2694     static &lt;K,V&gt; Node&lt;K,V&gt; untreeify(Node&lt;K,V&gt; b) {
2695         Node&lt;K,V&gt; hd = null, tl = null;
2696         for (Node&lt;K,V&gt; q = b; q != null; q = q.next) {
2697             Node&lt;K,V&gt; p = new Node&lt;K,V&gt;(q.hash, q.key, q.val);
2698             if (tl == null)
2699                 hd = p;
2700             else
2701                 tl.next = p;
2702             tl = p;
2703         }
2704         return hd;
2705     }
2706 
2707     /* ---------------- TreeNodes -------------- */
2708 
2709     /**
2710      * Nodes for use in TreeBins.
2711      */
2712     static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; {
2713         TreeNode&lt;K,V&gt; parent;  // red-black tree links
2714         TreeNode&lt;K,V&gt; left;
2715         TreeNode&lt;K,V&gt; right;
2716         TreeNode&lt;K,V&gt; prev;    // needed to unlink next upon deletion
2717         boolean red;
2718 
2719         TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next,
2720                  TreeNode&lt;K,V&gt; parent) {
2721             super(hash, key, val, next);
2722             this.parent = parent;
2723         }
2724 
2725         Node&lt;K,V&gt; find(int h, Object k) {
2726             return findTreeNode(h, k, null);
2727         }
2728 
2729         /**
2730          * Returns the TreeNode (or null if not found) for the given key
2731          * starting at given root.
2732          */
2733         final TreeNode&lt;K,V&gt; findTreeNode(int h, Object k, Class&lt;?&gt; kc) {
2734             if (k != null) {
2735                 TreeNode&lt;K,V&gt; p = this;
2736                 do {
2737                     int ph, dir; K pk; TreeNode&lt;K,V&gt; q;
2738                     TreeNode&lt;K,V&gt; pl = p.left, pr = p.right;
2739                     if ((ph = p.hash) &gt; h)
2740                         p = pl;
2741                     else if (ph &lt; h)
2742                         p = pr;
2743                     else if ((pk = p.key) == k || (pk != null &amp;&amp; k.equals(pk)))
2744                         return p;
2745                     else if (pl == null)
2746                         p = pr;
2747                     else if (pr == null)
2748                         p = pl;
2749                     else if ((kc != null ||
2750                               (kc = comparableClassFor(k)) != null) &amp;&amp;
2751                              (dir = compareComparables(kc, k, pk)) != 0)
2752                         p = (dir &lt; 0) ? pl : pr;
2753                     else if ((q = pr.findTreeNode(h, k, kc)) != null)
2754                         return q;
2755                     else
2756                         p = pl;
2757                 } while (p != null);
2758             }
2759             return null;
2760         }
2761     }
2762 
2763     /* ---------------- TreeBins -------------- */
2764 
2765     /**
2766      * TreeNodes used at the heads of bins. TreeBins do not hold user
2767      * keys or values, but instead point to list of TreeNodes and
2768      * their root. They also maintain a parasitic read-write lock
2769      * forcing writers (who hold bin lock) to wait for readers (who do
2770      * not) to complete before tree restructuring operations.
2771      */
2772     static final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; {
2773         TreeNode&lt;K,V&gt; root;
2774         volatile TreeNode&lt;K,V&gt; first;
2775         volatile Thread waiter;
2776         volatile int lockState;
2777         // values for lockState
2778         static final int WRITER = 1; // set while holding write lock
2779         static final int WAITER = 2; // set when waiting for write lock
2780         static final int READER = 4; // increment value for setting read lock
2781 
2782         /**
2783          * Tie-breaking utility for ordering insertions when equal
2784          * hashCodes and non-comparable. We don&#39;t require a total
2785          * order, just a consistent insertion rule to maintain
2786          * equivalence across rebalancings. Tie-breaking further than
2787          * necessary simplifies testing a bit.
2788          */
2789         static int tieBreakOrder(Object a, Object b) {
2790             int d;
2791             if (a == null || b == null ||
2792                 (d = a.getClass().getName().
2793                  compareTo(b.getClass().getName())) == 0)
2794                 d = (System.identityHashCode(a) &lt;= System.identityHashCode(b) ?
2795                      -1 : 1);
2796             return d;
2797         }
2798 
2799         /**
2800          * Creates bin with initial set of nodes headed by b.
2801          */
2802         TreeBin(TreeNode&lt;K,V&gt; b) {
2803             super(TREEBIN, null, null);
2804             this.first = b;
2805             TreeNode&lt;K,V&gt; r = null;
2806             for (TreeNode&lt;K,V&gt; x = b, next; x != null; x = next) {
2807                 next = (TreeNode&lt;K,V&gt;)x.next;
2808                 x.left = x.right = null;
2809                 if (r == null) {
2810                     x.parent = null;
2811                     x.red = false;
2812                     r = x;
2813                 }
2814                 else {
2815                     K k = x.key;
2816                     int h = x.hash;
2817                     Class&lt;?&gt; kc = null;
2818                     for (TreeNode&lt;K,V&gt; p = r;;) {
2819                         int dir, ph;
2820                         K pk = p.key;
2821                         if ((ph = p.hash) &gt; h)
2822                             dir = -1;
2823                         else if (ph &lt; h)
2824                             dir = 1;
2825                         else if ((kc == null &amp;&amp;
2826                                   (kc = comparableClassFor(k)) == null) ||
2827                                  (dir = compareComparables(kc, k, pk)) == 0)
2828                             dir = tieBreakOrder(k, pk);
2829                         TreeNode&lt;K,V&gt; xp = p;
2830                         if ((p = (dir &lt;= 0) ? p.left : p.right) == null) {
2831                             x.parent = xp;
2832                             if (dir &lt;= 0)
2833                                 xp.left = x;
2834                             else
2835                                 xp.right = x;
2836                             r = balanceInsertion(r, x);
2837                             break;
2838                         }
2839                     }
2840                 }
2841             }
2842             this.root = r;
2843             assert checkInvariants(root);
2844         }
2845 
2846         /**
2847          * Acquires write lock for tree restructuring.
2848          */
2849         private final void lockRoot() {
2850             if (!U.compareAndSetInt(this, LOCKSTATE, 0, WRITER))
2851                 contendedLock(); // offload to separate method
2852         }
2853 
2854         /**
2855          * Releases write lock for tree restructuring.
2856          */
2857         private final void unlockRoot() {
2858             lockState = 0;
2859         }
2860 
2861         /**
2862          * Possibly blocks awaiting root lock.
2863          */
2864         private final void contendedLock() {
2865             boolean waiting = false;
2866             for (int s;;) {
2867                 if (((s = lockState) &amp; ~WAITER) == 0) {
2868                     if (U.compareAndSetInt(this, LOCKSTATE, s, WRITER)) {
2869                         if (waiting)
2870                             waiter = null;
2871                         return;
2872                     }
2873                 }
2874                 else if ((s &amp; WAITER) == 0) {
2875                     if (U.compareAndSetInt(this, LOCKSTATE, s, s | WAITER)) {
2876                         waiting = true;
2877                         waiter = Thread.currentThread();
2878                     }
2879                 }
2880                 else if (waiting)
2881                     LockSupport.park(this);
2882             }
2883         }
2884 
2885         /**
2886          * Returns matching node or null if none. Tries to search
2887          * using tree comparisons from root, but continues linear
2888          * search when lock not available.
2889          */
2890         final Node&lt;K,V&gt; find(int h, Object k) {
2891             if (k != null) {
2892                 for (Node&lt;K,V&gt; e = first; e != null; ) {
2893                     int s; K ek;
2894                     if (((s = lockState) &amp; (WAITER|WRITER)) != 0) {
2895                         if (e.hash == h &amp;&amp;
2896                             ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek))))
2897                             return e;
2898                         e = e.next;
2899                     }
2900                     else if (U.compareAndSetInt(this, LOCKSTATE, s,
2901                                                  s + READER)) {
2902                         TreeNode&lt;K,V&gt; r, p;
2903                         try {
2904                             p = ((r = root) == null ? null :
2905                                  r.findTreeNode(h, k, null));
2906                         } finally {
2907                             Thread w;
2908                             if (U.getAndAddInt(this, LOCKSTATE, -READER) ==
2909                                 (READER|WAITER) &amp;&amp; (w = waiter) != null)
2910                                 LockSupport.unpark(w);
2911                         }
2912                         return p;
2913                     }
2914                 }
2915             }
2916             return null;
2917         }
2918 
2919         /**
2920          * Finds or adds a node.
2921          * @return null if added
2922          */
2923         final TreeNode&lt;K,V&gt; putTreeVal(int h, K k, V v) {
2924             Class&lt;?&gt; kc = null;
2925             boolean searched = false;
2926             for (TreeNode&lt;K,V&gt; p = root;;) {
2927                 int dir, ph; K pk;
2928                 if (p == null) {
2929                     first = root = new TreeNode&lt;K,V&gt;(h, k, v, null, null);
2930                     break;
2931                 }
2932                 else if ((ph = p.hash) &gt; h)
2933                     dir = -1;
2934                 else if (ph &lt; h)
2935                     dir = 1;
2936                 else if ((pk = p.key) == k || (pk != null &amp;&amp; k.equals(pk)))
2937                     return p;
2938                 else if ((kc == null &amp;&amp;
2939                           (kc = comparableClassFor(k)) == null) ||
2940                          (dir = compareComparables(kc, k, pk)) == 0) {
2941                     if (!searched) {
2942                         TreeNode&lt;K,V&gt; q, ch;
2943                         searched = true;
2944                         if (((ch = p.left) != null &amp;&amp;
2945                              (q = ch.findTreeNode(h, k, kc)) != null) ||
2946                             ((ch = p.right) != null &amp;&amp;
2947                              (q = ch.findTreeNode(h, k, kc)) != null))
2948                             return q;
2949                     }
2950                     dir = tieBreakOrder(k, pk);
2951                 }
2952 
2953                 TreeNode&lt;K,V&gt; xp = p;
2954                 if ((p = (dir &lt;= 0) ? p.left : p.right) == null) {
2955                     TreeNode&lt;K,V&gt; x, f = first;
2956                     first = x = new TreeNode&lt;K,V&gt;(h, k, v, f, xp);
2957                     if (f != null)
2958                         f.prev = x;
2959                     if (dir &lt;= 0)
2960                         xp.left = x;
2961                     else
2962                         xp.right = x;
2963                     if (!xp.red)
2964                         x.red = true;
2965                     else {
2966                         lockRoot();
2967                         try {
2968                             root = balanceInsertion(root, x);
2969                         } finally {
2970                             unlockRoot();
2971                         }
2972                     }
2973                     break;
2974                 }
2975             }
2976             assert checkInvariants(root);
2977             return null;
2978         }
2979 
2980         /**
2981          * Removes the given node, that must be present before this
2982          * call.  This is messier than typical red-black deletion code
2983          * because we cannot swap the contents of an interior node
2984          * with a leaf successor that is pinned by &quot;next&quot; pointers
2985          * that are accessible independently of lock. So instead we
2986          * swap the tree linkages.
2987          *
2988          * @return true if now too small, so should be untreeified
2989          */
2990         final boolean removeTreeNode(TreeNode&lt;K,V&gt; p) {
2991             TreeNode&lt;K,V&gt; next = (TreeNode&lt;K,V&gt;)p.next;
2992             TreeNode&lt;K,V&gt; pred = p.prev;  // unlink traversal pointers
2993             TreeNode&lt;K,V&gt; r, rl;
2994             if (pred == null)
2995                 first = next;
2996             else
2997                 pred.next = next;
2998             if (next != null)
2999                 next.prev = pred;
3000             if (first == null) {
3001                 root = null;
3002                 return true;
3003             }
3004             if ((r = root) == null || r.right == null || // too small
3005                 (rl = r.left) == null || rl.left == null)
3006                 return true;
3007             lockRoot();
3008             try {
3009                 TreeNode&lt;K,V&gt; replacement;
3010                 TreeNode&lt;K,V&gt; pl = p.left;
3011                 TreeNode&lt;K,V&gt; pr = p.right;
3012                 if (pl != null &amp;&amp; pr != null) {
3013                     TreeNode&lt;K,V&gt; s = pr, sl;
3014                     while ((sl = s.left) != null) // find successor
3015                         s = sl;
3016                     boolean c = s.red; s.red = p.red; p.red = c; // swap colors
3017                     TreeNode&lt;K,V&gt; sr = s.right;
3018                     TreeNode&lt;K,V&gt; pp = p.parent;
3019                     if (s == pr) { // p was s&#39;s direct parent
3020                         p.parent = s;
3021                         s.right = p;
3022                     }
3023                     else {
3024                         TreeNode&lt;K,V&gt; sp = s.parent;
3025                         if ((p.parent = sp) != null) {
3026                             if (s == sp.left)
3027                                 sp.left = p;
3028                             else
3029                                 sp.right = p;
3030                         }
3031                         if ((s.right = pr) != null)
3032                             pr.parent = s;
3033                     }
3034                     p.left = null;
3035                     if ((p.right = sr) != null)
3036                         sr.parent = p;
3037                     if ((s.left = pl) != null)
3038                         pl.parent = s;
3039                     if ((s.parent = pp) == null)
3040                         r = s;
3041                     else if (p == pp.left)
3042                         pp.left = s;
3043                     else
3044                         pp.right = s;
3045                     if (sr != null)
3046                         replacement = sr;
3047                     else
3048                         replacement = p;
3049                 }
3050                 else if (pl != null)
3051                     replacement = pl;
3052                 else if (pr != null)
3053                     replacement = pr;
3054                 else
3055                     replacement = p;
3056                 if (replacement != p) {
3057                     TreeNode&lt;K,V&gt; pp = replacement.parent = p.parent;
3058                     if (pp == null)
3059                         r = replacement;
3060                     else if (p == pp.left)
3061                         pp.left = replacement;
3062                     else
3063                         pp.right = replacement;
3064                     p.left = p.right = p.parent = null;
3065                 }
3066 
3067                 root = (p.red) ? r : balanceDeletion(r, replacement);
3068 
3069                 if (p == replacement) {  // detach pointers
3070                     TreeNode&lt;K,V&gt; pp;
3071                     if ((pp = p.parent) != null) {
3072                         if (p == pp.left)
3073                             pp.left = null;
3074                         else if (p == pp.right)
3075                             pp.right = null;
3076                         p.parent = null;
3077                     }
3078                 }
3079             } finally {
3080                 unlockRoot();
3081             }
3082             assert checkInvariants(root);
3083             return false;
3084         }
3085 
3086         /* ------------------------------------------------------------ */
3087         // Red-black tree methods, all adapted from CLR
3088 
3089         static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateLeft(TreeNode&lt;K,V&gt; root,
3090                                               TreeNode&lt;K,V&gt; p) {
3091             TreeNode&lt;K,V&gt; r, pp, rl;
3092             if (p != null &amp;&amp; (r = p.right) != null) {
3093                 if ((rl = p.right = r.left) != null)
3094                     rl.parent = p;
3095                 if ((pp = r.parent = p.parent) == null)
3096                     (root = r).red = false;
3097                 else if (pp.left == p)
3098                     pp.left = r;
3099                 else
3100                     pp.right = r;
3101                 r.left = p;
3102                 p.parent = r;
3103             }
3104             return root;
3105         }
3106 
3107         static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateRight(TreeNode&lt;K,V&gt; root,
3108                                                TreeNode&lt;K,V&gt; p) {
3109             TreeNode&lt;K,V&gt; l, pp, lr;
3110             if (p != null &amp;&amp; (l = p.left) != null) {
3111                 if ((lr = p.left = l.right) != null)
3112                     lr.parent = p;
3113                 if ((pp = l.parent = p.parent) == null)
3114                     (root = l).red = false;
3115                 else if (pp.right == p)
3116                     pp.right = l;
3117                 else
3118                     pp.left = l;
3119                 l.right = p;
3120                 p.parent = l;
3121             }
3122             return root;
3123         }
3124 
3125         static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceInsertion(TreeNode&lt;K,V&gt; root,
3126                                                     TreeNode&lt;K,V&gt; x) {
3127             x.red = true;
3128             for (TreeNode&lt;K,V&gt; xp, xpp, xppl, xppr;;) {
3129                 if ((xp = x.parent) == null) {
3130                     x.red = false;
3131                     return x;
3132                 }
3133                 else if (!xp.red || (xpp = xp.parent) == null)
3134                     return root;
3135                 if (xp == (xppl = xpp.left)) {
3136                     if ((xppr = xpp.right) != null &amp;&amp; xppr.red) {
3137                         xppr.red = false;
3138                         xp.red = false;
3139                         xpp.red = true;
3140                         x = xpp;
3141                     }
3142                     else {
3143                         if (x == xp.right) {
3144                             root = rotateLeft(root, x = xp);
3145                             xpp = (xp = x.parent) == null ? null : xp.parent;
3146                         }
3147                         if (xp != null) {
3148                             xp.red = false;
3149                             if (xpp != null) {
3150                                 xpp.red = true;
3151                                 root = rotateRight(root, xpp);
3152                             }
3153                         }
3154                     }
3155                 }
3156                 else {
3157                     if (xppl != null &amp;&amp; xppl.red) {
3158                         xppl.red = false;
3159                         xp.red = false;
3160                         xpp.red = true;
3161                         x = xpp;
3162                     }
3163                     else {
3164                         if (x == xp.left) {
3165                             root = rotateRight(root, x = xp);
3166                             xpp = (xp = x.parent) == null ? null : xp.parent;
3167                         }
3168                         if (xp != null) {
3169                             xp.red = false;
3170                             if (xpp != null) {
3171                                 xpp.red = true;
3172                                 root = rotateLeft(root, xpp);
3173                             }
3174                         }
3175                     }
3176                 }
3177             }
3178         }
3179 
3180         static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceDeletion(TreeNode&lt;K,V&gt; root,
3181                                                    TreeNode&lt;K,V&gt; x) {
3182             for (TreeNode&lt;K,V&gt; xp, xpl, xpr;;) {
3183                 if (x == null || x == root)
3184                     return root;
3185                 else if ((xp = x.parent) == null) {
3186                     x.red = false;
3187                     return x;
3188                 }
3189                 else if (x.red) {
3190                     x.red = false;
3191                     return root;
3192                 }
3193                 else if ((xpl = xp.left) == x) {
3194                     if ((xpr = xp.right) != null &amp;&amp; xpr.red) {
3195                         xpr.red = false;
3196                         xp.red = true;
3197                         root = rotateLeft(root, xp);
3198                         xpr = (xp = x.parent) == null ? null : xp.right;
3199                     }
3200                     if (xpr == null)
3201                         x = xp;
3202                     else {
3203                         TreeNode&lt;K,V&gt; sl = xpr.left, sr = xpr.right;
3204                         if ((sr == null || !sr.red) &amp;&amp;
3205                             (sl == null || !sl.red)) {
3206                             xpr.red = true;
3207                             x = xp;
3208                         }
3209                         else {
3210                             if (sr == null || !sr.red) {
3211                                 if (sl != null)
3212                                     sl.red = false;
3213                                 xpr.red = true;
3214                                 root = rotateRight(root, xpr);
3215                                 xpr = (xp = x.parent) == null ?
3216                                     null : xp.right;
3217                             }
3218                             if (xpr != null) {
3219                                 xpr.red = (xp == null) ? false : xp.red;
3220                                 if ((sr = xpr.right) != null)
3221                                     sr.red = false;
3222                             }
3223                             if (xp != null) {
3224                                 xp.red = false;
3225                                 root = rotateLeft(root, xp);
3226                             }
3227                             x = root;
3228                         }
3229                     }
3230                 }
3231                 else { // symmetric
3232                     if (xpl != null &amp;&amp; xpl.red) {
3233                         xpl.red = false;
3234                         xp.red = true;
3235                         root = rotateRight(root, xp);
3236                         xpl = (xp = x.parent) == null ? null : xp.left;
3237                     }
3238                     if (xpl == null)
3239                         x = xp;
3240                     else {
3241                         TreeNode&lt;K,V&gt; sl = xpl.left, sr = xpl.right;
3242                         if ((sl == null || !sl.red) &amp;&amp;
3243                             (sr == null || !sr.red)) {
3244                             xpl.red = true;
3245                             x = xp;
3246                         }
3247                         else {
3248                             if (sl == null || !sl.red) {
3249                                 if (sr != null)
3250                                     sr.red = false;
3251                                 xpl.red = true;
3252                                 root = rotateLeft(root, xpl);
3253                                 xpl = (xp = x.parent) == null ?
3254                                     null : xp.left;
3255                             }
3256                             if (xpl != null) {
3257                                 xpl.red = (xp == null) ? false : xp.red;
3258                                 if ((sl = xpl.left) != null)
3259                                     sl.red = false;
3260                             }
3261                             if (xp != null) {
3262                                 xp.red = false;
3263                                 root = rotateRight(root, xp);
3264                             }
3265                             x = root;
3266                         }
3267                     }
3268                 }
3269             }
3270         }
3271 
3272         /**
3273          * Checks invariants recursively for the tree of Nodes rooted at t.
3274          */
3275         static &lt;K,V&gt; boolean checkInvariants(TreeNode&lt;K,V&gt; t) {
3276             TreeNode&lt;K,V&gt; tp = t.parent, tl = t.left, tr = t.right,
3277                 tb = t.prev, tn = (TreeNode&lt;K,V&gt;)t.next;
3278             if (tb != null &amp;&amp; tb.next != t)
3279                 return false;
3280             if (tn != null &amp;&amp; tn.prev != t)
3281                 return false;
3282             if (tp != null &amp;&amp; t != tp.left &amp;&amp; t != tp.right)
3283                 return false;
3284             if (tl != null &amp;&amp; (tl.parent != t || tl.hash &gt; t.hash))
3285                 return false;
3286             if (tr != null &amp;&amp; (tr.parent != t || tr.hash &lt; t.hash))
3287                 return false;
3288             if (t.red &amp;&amp; tl != null &amp;&amp; tl.red &amp;&amp; tr != null &amp;&amp; tr.red)
3289                 return false;
3290             if (tl != null &amp;&amp; !checkInvariants(tl))
3291                 return false;
3292             if (tr != null &amp;&amp; !checkInvariants(tr))
3293                 return false;
3294             return true;
3295         }
3296 
<a name="5" id="anc5"></a>
3297         private static final long LOCKSTATE
<a name="6" id="anc6"></a><span class="line-modified">3298             = U.objectFieldOffset(TreeBin.class, &quot;lockState&quot;);</span>
3299     }
3300 
3301     /* ----------------Table Traversal -------------- */
3302 
3303     /**
3304      * Records the table, its length, and current traversal index for a
3305      * traverser that must process a region of a forwarded table before
3306      * proceeding with current table.
3307      */
3308     static final class TableStack&lt;K,V&gt; {
3309         int length;
3310         int index;
3311         Node&lt;K,V&gt;[] tab;
3312         TableStack&lt;K,V&gt; next;
3313     }
3314 
3315     /**
3316      * Encapsulates traversal for methods such as containsValue; also
3317      * serves as a base class for other iterators and spliterators.
3318      *
3319      * Method advance visits once each still-valid node that was
3320      * reachable upon iterator construction. It might miss some that
3321      * were added to a bin after the bin was visited, which is OK wrt
3322      * consistency guarantees. Maintaining this property in the face
3323      * of possible ongoing resizes requires a fair amount of
3324      * bookkeeping state that is difficult to optimize away amidst
3325      * volatile accesses.  Even so, traversal maintains reasonable
3326      * throughput.
3327      *
3328      * Normally, iteration proceeds bin-by-bin traversing lists.
3329      * However, if the table has been resized, then all future steps
3330      * must traverse both the bin at the current index as well as at
3331      * (index + baseSize); and so on for further resizings. To
3332      * paranoically cope with potential sharing by users of iterators
3333      * across threads, iteration terminates if a bounds checks fails
3334      * for a table read.
3335      */
3336     static class Traverser&lt;K,V&gt; {
3337         Node&lt;K,V&gt;[] tab;        // current table; updated if resized
3338         Node&lt;K,V&gt; next;         // the next entry to use
3339         TableStack&lt;K,V&gt; stack, spare; // to save/restore on ForwardingNodes
3340         int index;              // index of bin to use next
3341         int baseIndex;          // current index of initial table
3342         int baseLimit;          // index bound for initial table
3343         final int baseSize;     // initial table size
3344 
3345         Traverser(Node&lt;K,V&gt;[] tab, int size, int index, int limit) {
3346             this.tab = tab;
3347             this.baseSize = size;
3348             this.baseIndex = this.index = index;
3349             this.baseLimit = limit;
3350             this.next = null;
3351         }
3352 
3353         /**
3354          * Advances if possible, returning next valid node, or null if none.
3355          */
3356         final Node&lt;K,V&gt; advance() {
3357             Node&lt;K,V&gt; e;
3358             if ((e = next) != null)
3359                 e = e.next;
3360             for (;;) {
3361                 Node&lt;K,V&gt;[] t; int i, n;  // must use locals in checks
3362                 if (e != null)
3363                     return next = e;
3364                 if (baseIndex &gt;= baseLimit || (t = tab) == null ||
3365                     (n = t.length) &lt;= (i = index) || i &lt; 0)
3366                     return next = null;
3367                 if ((e = tabAt(t, i)) != null &amp;&amp; e.hash &lt; 0) {
3368                     if (e instanceof ForwardingNode) {
3369                         tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable;
3370                         e = null;
3371                         pushState(t, i, n);
3372                         continue;
3373                     }
3374                     else if (e instanceof TreeBin)
3375                         e = ((TreeBin&lt;K,V&gt;)e).first;
3376                     else
3377                         e = null;
3378                 }
3379                 if (stack != null)
3380                     recoverState(n);
3381                 else if ((index = i + baseSize) &gt;= n)
3382                     index = ++baseIndex; // visit upper slots if present
3383             }
3384         }
3385 
3386         /**
3387          * Saves traversal state upon encountering a forwarding node.
3388          */
3389         private void pushState(Node&lt;K,V&gt;[] t, int i, int n) {
3390             TableStack&lt;K,V&gt; s = spare;  // reuse if possible
3391             if (s != null)
3392                 spare = s.next;
3393             else
3394                 s = new TableStack&lt;K,V&gt;();
3395             s.tab = t;
3396             s.length = n;
3397             s.index = i;
3398             s.next = stack;
3399             stack = s;
3400         }
3401 
3402         /**
3403          * Possibly pops traversal state.
3404          *
3405          * @param n length of current table
3406          */
3407         private void recoverState(int n) {
3408             TableStack&lt;K,V&gt; s; int len;
3409             while ((s = stack) != null &amp;&amp; (index += (len = s.length)) &gt;= n) {
3410                 n = len;
3411                 index = s.index;
3412                 tab = s.tab;
3413                 s.tab = null;
3414                 TableStack&lt;K,V&gt; next = s.next;
3415                 s.next = spare; // save for reuse
3416                 stack = next;
3417                 spare = s;
3418             }
3419             if (s == null &amp;&amp; (index += baseSize) &gt;= n)
3420                 index = ++baseIndex;
3421         }
3422     }
3423 
3424     /**
3425      * Base of key, value, and entry Iterators. Adds fields to
3426      * Traverser to support iterator.remove.
3427      */
3428     static class BaseIterator&lt;K,V&gt; extends Traverser&lt;K,V&gt; {
3429         final ConcurrentHashMap&lt;K,V&gt; map;
3430         Node&lt;K,V&gt; lastReturned;
3431         BaseIterator(Node&lt;K,V&gt;[] tab, int size, int index, int limit,
3432                     ConcurrentHashMap&lt;K,V&gt; map) {
3433             super(tab, size, index, limit);
3434             this.map = map;
3435             advance();
3436         }
3437 
3438         public final boolean hasNext() { return next != null; }
3439         public final boolean hasMoreElements() { return next != null; }
3440 
3441         public final void remove() {
3442             Node&lt;K,V&gt; p;
3443             if ((p = lastReturned) == null)
3444                 throw new IllegalStateException();
3445             lastReturned = null;
3446             map.replaceNode(p.key, null, null);
3447         }
3448     }
3449 
3450     static final class KeyIterator&lt;K,V&gt; extends BaseIterator&lt;K,V&gt;
3451         implements Iterator&lt;K&gt;, Enumeration&lt;K&gt; {
3452         KeyIterator(Node&lt;K,V&gt;[] tab, int size, int index, int limit,
3453                     ConcurrentHashMap&lt;K,V&gt; map) {
3454             super(tab, size, index, limit, map);
3455         }
3456 
3457         public final K next() {
3458             Node&lt;K,V&gt; p;
3459             if ((p = next) == null)
3460                 throw new NoSuchElementException();
3461             K k = p.key;
3462             lastReturned = p;
3463             advance();
3464             return k;
3465         }
3466 
3467         public final K nextElement() { return next(); }
3468     }
3469 
3470     static final class ValueIterator&lt;K,V&gt; extends BaseIterator&lt;K,V&gt;
3471         implements Iterator&lt;V&gt;, Enumeration&lt;V&gt; {
3472         ValueIterator(Node&lt;K,V&gt;[] tab, int size, int index, int limit,
3473                       ConcurrentHashMap&lt;K,V&gt; map) {
3474             super(tab, size, index, limit, map);
3475         }
3476 
3477         public final V next() {
3478             Node&lt;K,V&gt; p;
3479             if ((p = next) == null)
3480                 throw new NoSuchElementException();
3481             V v = p.val;
3482             lastReturned = p;
3483             advance();
3484             return v;
3485         }
3486 
3487         public final V nextElement() { return next(); }
3488     }
3489 
3490     static final class EntryIterator&lt;K,V&gt; extends BaseIterator&lt;K,V&gt;
3491         implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; {
3492         EntryIterator(Node&lt;K,V&gt;[] tab, int size, int index, int limit,
3493                       ConcurrentHashMap&lt;K,V&gt; map) {
3494             super(tab, size, index, limit, map);
3495         }
3496 
3497         public final Map.Entry&lt;K,V&gt; next() {
3498             Node&lt;K,V&gt; p;
3499             if ((p = next) == null)
3500                 throw new NoSuchElementException();
3501             K k = p.key;
3502             V v = p.val;
3503             lastReturned = p;
3504             advance();
3505             return new MapEntry&lt;K,V&gt;(k, v, map);
3506         }
3507     }
3508 
3509     /**
3510      * Exported Entry for EntryIterator.
3511      */
3512     static final class MapEntry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {
3513         final K key; // non-null
3514         V val;       // non-null
3515         final ConcurrentHashMap&lt;K,V&gt; map;
3516         MapEntry(K key, V val, ConcurrentHashMap&lt;K,V&gt; map) {
3517             this.key = key;
3518             this.val = val;
3519             this.map = map;
3520         }
3521         public K getKey()        { return key; }
3522         public V getValue()      { return val; }
3523         public int hashCode()    { return key.hashCode() ^ val.hashCode(); }
3524         public String toString() {
3525             return Helpers.mapEntryToString(key, val);
3526         }
3527 
3528         public boolean equals(Object o) {
3529             Object k, v; Map.Entry&lt;?,?&gt; e;
3530             return ((o instanceof Map.Entry) &amp;&amp;
3531                     (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != null &amp;&amp;
3532                     (v = e.getValue()) != null &amp;&amp;
3533                     (k == key || k.equals(key)) &amp;&amp;
3534                     (v == val || v.equals(val)));
3535         }
3536 
3537         /**
3538          * Sets our entry&#39;s value and writes through to the map. The
3539          * value to return is somewhat arbitrary here. Since we do not
3540          * necessarily track asynchronous changes, the most recent
3541          * &quot;previous&quot; value could be different from what we return (or
3542          * could even have been removed, in which case the put will
3543          * re-establish). We do not and cannot guarantee more.
3544          */
3545         public V setValue(V value) {
3546             if (value == null) throw new NullPointerException();
3547             V v = val;
3548             val = value;
3549             map.put(key, value);
3550             return v;
3551         }
3552     }
3553 
3554     static final class KeySpliterator&lt;K,V&gt; extends Traverser&lt;K,V&gt;
3555         implements Spliterator&lt;K&gt; {
3556         long est;               // size estimate
3557         KeySpliterator(Node&lt;K,V&gt;[] tab, int size, int index, int limit,
3558                        long est) {
3559             super(tab, size, index, limit);
3560             this.est = est;
3561         }
3562 
3563         public KeySpliterator&lt;K,V&gt; trySplit() {
3564             int i, f, h;
3565             return (h = ((i = baseIndex) + (f = baseLimit)) &gt;&gt;&gt; 1) &lt;= i ? null :
3566                 new KeySpliterator&lt;K,V&gt;(tab, baseSize, baseLimit = h,
3567                                         f, est &gt;&gt;&gt;= 1);
3568         }
3569 
3570         public void forEachRemaining(Consumer&lt;? super K&gt; action) {
3571             if (action == null) throw new NullPointerException();
3572             for (Node&lt;K,V&gt; p; (p = advance()) != null;)
3573                 action.accept(p.key);
3574         }
3575 
3576         public boolean tryAdvance(Consumer&lt;? super K&gt; action) {
3577             if (action == null) throw new NullPointerException();
3578             Node&lt;K,V&gt; p;
3579             if ((p = advance()) == null)
3580                 return false;
3581             action.accept(p.key);
3582             return true;
3583         }
3584 
3585         public long estimateSize() { return est; }
3586 
3587         public int characteristics() {
3588             return Spliterator.DISTINCT | Spliterator.CONCURRENT |
3589                 Spliterator.NONNULL;
3590         }
3591     }
3592 
3593     static final class ValueSpliterator&lt;K,V&gt; extends Traverser&lt;K,V&gt;
3594         implements Spliterator&lt;V&gt; {
3595         long est;               // size estimate
3596         ValueSpliterator(Node&lt;K,V&gt;[] tab, int size, int index, int limit,
3597                          long est) {
3598             super(tab, size, index, limit);
3599             this.est = est;
3600         }
3601 
3602         public ValueSpliterator&lt;K,V&gt; trySplit() {
3603             int i, f, h;
3604             return (h = ((i = baseIndex) + (f = baseLimit)) &gt;&gt;&gt; 1) &lt;= i ? null :
3605                 new ValueSpliterator&lt;K,V&gt;(tab, baseSize, baseLimit = h,
3606                                           f, est &gt;&gt;&gt;= 1);
3607         }
3608 
3609         public void forEachRemaining(Consumer&lt;? super V&gt; action) {
3610             if (action == null) throw new NullPointerException();
3611             for (Node&lt;K,V&gt; p; (p = advance()) != null;)
3612                 action.accept(p.val);
3613         }
3614 
3615         public boolean tryAdvance(Consumer&lt;? super V&gt; action) {
3616             if (action == null) throw new NullPointerException();
3617             Node&lt;K,V&gt; p;
3618             if ((p = advance()) == null)
3619                 return false;
3620             action.accept(p.val);
3621             return true;
3622         }
3623 
3624         public long estimateSize() { return est; }
3625 
3626         public int characteristics() {
3627             return Spliterator.CONCURRENT | Spliterator.NONNULL;
3628         }
3629     }
3630 
3631     static final class EntrySpliterator&lt;K,V&gt; extends Traverser&lt;K,V&gt;
3632         implements Spliterator&lt;Map.Entry&lt;K,V&gt;&gt; {
3633         final ConcurrentHashMap&lt;K,V&gt; map; // To export MapEntry
3634         long est;               // size estimate
3635         EntrySpliterator(Node&lt;K,V&gt;[] tab, int size, int index, int limit,
3636                          long est, ConcurrentHashMap&lt;K,V&gt; map) {
3637             super(tab, size, index, limit);
3638             this.map = map;
3639             this.est = est;
3640         }
3641 
3642         public EntrySpliterator&lt;K,V&gt; trySplit() {
3643             int i, f, h;
3644             return (h = ((i = baseIndex) + (f = baseLimit)) &gt;&gt;&gt; 1) &lt;= i ? null :
3645                 new EntrySpliterator&lt;K,V&gt;(tab, baseSize, baseLimit = h,
3646                                           f, est &gt;&gt;&gt;= 1, map);
3647         }
3648 
3649         public void forEachRemaining(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) {
3650             if (action == null) throw new NullPointerException();
3651             for (Node&lt;K,V&gt; p; (p = advance()) != null; )
3652                 action.accept(new MapEntry&lt;K,V&gt;(p.key, p.val, map));
3653         }
3654 
3655         public boolean tryAdvance(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) {
3656             if (action == null) throw new NullPointerException();
3657             Node&lt;K,V&gt; p;
3658             if ((p = advance()) == null)
3659                 return false;
3660             action.accept(new MapEntry&lt;K,V&gt;(p.key, p.val, map));
3661             return true;
3662         }
3663 
3664         public long estimateSize() { return est; }
3665 
3666         public int characteristics() {
3667             return Spliterator.DISTINCT | Spliterator.CONCURRENT |
3668                 Spliterator.NONNULL;
3669         }
3670     }
3671 
3672     // Parallel bulk operations
3673 
3674     /**
3675      * Computes initial batch value for bulk tasks. The returned value
3676      * is approximately exp2 of the number of times (minus one) to
3677      * split task by two before executing leaf action. This value is
3678      * faster to compute and more convenient to use as a guide to
3679      * splitting than is the depth, since it is used while dividing by
3680      * two anyway.
3681      */
3682     final int batchFor(long b) {
3683         long n;
3684         if (b == Long.MAX_VALUE || (n = sumCount()) &lt;= 1L || n &lt; b)
3685             return 0;
3686         int sp = ForkJoinPool.getCommonPoolParallelism() &lt;&lt; 2; // slack of 4
3687         return (b &lt;= 0L || (n /= b) &gt;= sp) ? sp : (int)n;
3688     }
3689 
3690     /**
3691      * Performs the given action for each (key, value).
3692      *
3693      * @param parallelismThreshold the (estimated) number of elements
3694      * needed for this operation to be executed in parallel
3695      * @param action the action
3696      * @since 1.8
3697      */
3698     public void forEach(long parallelismThreshold,
3699                         BiConsumer&lt;? super K,? super V&gt; action) {
3700         if (action == null) throw new NullPointerException();
3701         new ForEachMappingTask&lt;K,V&gt;
3702             (null, batchFor(parallelismThreshold), 0, 0, table,
3703              action).invoke();
3704     }
3705 
3706     /**
3707      * Performs the given action for each non-null transformation
3708      * of each (key, value).
3709      *
3710      * @param parallelismThreshold the (estimated) number of elements
3711      * needed for this operation to be executed in parallel
3712      * @param transformer a function returning the transformation
3713      * for an element, or null if there is no transformation (in
3714      * which case the action is not applied)
3715      * @param action the action
3716      * @param &lt;U&gt; the return type of the transformer
3717      * @since 1.8
3718      */
3719     public &lt;U&gt; void forEach(long parallelismThreshold,
3720                             BiFunction&lt;? super K, ? super V, ? extends U&gt; transformer,
3721                             Consumer&lt;? super U&gt; action) {
3722         if (transformer == null || action == null)
3723             throw new NullPointerException();
3724         new ForEachTransformedMappingTask&lt;K,V,U&gt;
3725             (null, batchFor(parallelismThreshold), 0, 0, table,
3726              transformer, action).invoke();
3727     }
3728 
3729     /**
3730      * Returns a non-null result from applying the given search
3731      * function on each (key, value), or null if none.  Upon
3732      * success, further element processing is suppressed and the
3733      * results of any other parallel invocations of the search
3734      * function are ignored.
3735      *
3736      * @param parallelismThreshold the (estimated) number of elements
3737      * needed for this operation to be executed in parallel
3738      * @param searchFunction a function returning a non-null
3739      * result on success, else null
3740      * @param &lt;U&gt; the return type of the search function
3741      * @return a non-null result from applying the given search
3742      * function on each (key, value), or null if none
3743      * @since 1.8
3744      */
3745     public &lt;U&gt; U search(long parallelismThreshold,
3746                         BiFunction&lt;? super K, ? super V, ? extends U&gt; searchFunction) {
3747         if (searchFunction == null) throw new NullPointerException();
3748         return new SearchMappingsTask&lt;K,V,U&gt;
3749             (null, batchFor(parallelismThreshold), 0, 0, table,
3750              searchFunction, new AtomicReference&lt;U&gt;()).invoke();
3751     }
3752 
3753     /**
3754      * Returns the result of accumulating the given transformation
3755      * of all (key, value) pairs using the given reducer to
3756      * combine values, or null if none.
3757      *
3758      * @param parallelismThreshold the (estimated) number of elements
3759      * needed for this operation to be executed in parallel
3760      * @param transformer a function returning the transformation
3761      * for an element, or null if there is no transformation (in
3762      * which case it is not combined)
3763      * @param reducer a commutative associative combining function
3764      * @param &lt;U&gt; the return type of the transformer
3765      * @return the result of accumulating the given transformation
3766      * of all (key, value) pairs
3767      * @since 1.8
3768      */
3769     public &lt;U&gt; U reduce(long parallelismThreshold,
3770                         BiFunction&lt;? super K, ? super V, ? extends U&gt; transformer,
3771                         BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer) {
3772         if (transformer == null || reducer == null)
3773             throw new NullPointerException();
3774         return new MapReduceMappingsTask&lt;K,V,U&gt;
3775             (null, batchFor(parallelismThreshold), 0, 0, table,
3776              null, transformer, reducer).invoke();
3777     }
3778 
3779     /**
3780      * Returns the result of accumulating the given transformation
3781      * of all (key, value) pairs using the given reducer to
3782      * combine values, and the given basis as an identity value.
3783      *
3784      * @param parallelismThreshold the (estimated) number of elements
3785      * needed for this operation to be executed in parallel
3786      * @param transformer a function returning the transformation
3787      * for an element
3788      * @param basis the identity (initial default value) for the reduction
3789      * @param reducer a commutative associative combining function
3790      * @return the result of accumulating the given transformation
3791      * of all (key, value) pairs
3792      * @since 1.8
3793      */
3794     public double reduceToDouble(long parallelismThreshold,
3795                                  ToDoubleBiFunction&lt;? super K, ? super V&gt; transformer,
3796                                  double basis,
3797                                  DoubleBinaryOperator reducer) {
3798         if (transformer == null || reducer == null)
3799             throw new NullPointerException();
3800         return new MapReduceMappingsToDoubleTask&lt;K,V&gt;
3801             (null, batchFor(parallelismThreshold), 0, 0, table,
3802              null, transformer, basis, reducer).invoke();
3803     }
3804 
3805     /**
3806      * Returns the result of accumulating the given transformation
3807      * of all (key, value) pairs using the given reducer to
3808      * combine values, and the given basis as an identity value.
3809      *
3810      * @param parallelismThreshold the (estimated) number of elements
3811      * needed for this operation to be executed in parallel
3812      * @param transformer a function returning the transformation
3813      * for an element
3814      * @param basis the identity (initial default value) for the reduction
3815      * @param reducer a commutative associative combining function
3816      * @return the result of accumulating the given transformation
3817      * of all (key, value) pairs
3818      * @since 1.8
3819      */
3820     public long reduceToLong(long parallelismThreshold,
3821                              ToLongBiFunction&lt;? super K, ? super V&gt; transformer,
3822                              long basis,
3823                              LongBinaryOperator reducer) {
3824         if (transformer == null || reducer == null)
3825             throw new NullPointerException();
3826         return new MapReduceMappingsToLongTask&lt;K,V&gt;
3827             (null, batchFor(parallelismThreshold), 0, 0, table,
3828              null, transformer, basis, reducer).invoke();
3829     }
3830 
3831     /**
3832      * Returns the result of accumulating the given transformation
3833      * of all (key, value) pairs using the given reducer to
3834      * combine values, and the given basis as an identity value.
3835      *
3836      * @param parallelismThreshold the (estimated) number of elements
3837      * needed for this operation to be executed in parallel
3838      * @param transformer a function returning the transformation
3839      * for an element
3840      * @param basis the identity (initial default value) for the reduction
3841      * @param reducer a commutative associative combining function
3842      * @return the result of accumulating the given transformation
3843      * of all (key, value) pairs
3844      * @since 1.8
3845      */
3846     public int reduceToInt(long parallelismThreshold,
3847                            ToIntBiFunction&lt;? super K, ? super V&gt; transformer,
3848                            int basis,
3849                            IntBinaryOperator reducer) {
3850         if (transformer == null || reducer == null)
3851             throw new NullPointerException();
3852         return new MapReduceMappingsToIntTask&lt;K,V&gt;
3853             (null, batchFor(parallelismThreshold), 0, 0, table,
3854              null, transformer, basis, reducer).invoke();
3855     }
3856 
3857     /**
3858      * Performs the given action for each key.
3859      *
3860      * @param parallelismThreshold the (estimated) number of elements
3861      * needed for this operation to be executed in parallel
3862      * @param action the action
3863      * @since 1.8
3864      */
3865     public void forEachKey(long parallelismThreshold,
3866                            Consumer&lt;? super K&gt; action) {
3867         if (action == null) throw new NullPointerException();
3868         new ForEachKeyTask&lt;K,V&gt;
3869             (null, batchFor(parallelismThreshold), 0, 0, table,
3870              action).invoke();
3871     }
3872 
3873     /**
3874      * Performs the given action for each non-null transformation
3875      * of each key.
3876      *
3877      * @param parallelismThreshold the (estimated) number of elements
3878      * needed for this operation to be executed in parallel
3879      * @param transformer a function returning the transformation
3880      * for an element, or null if there is no transformation (in
3881      * which case the action is not applied)
3882      * @param action the action
3883      * @param &lt;U&gt; the return type of the transformer
3884      * @since 1.8
3885      */
3886     public &lt;U&gt; void forEachKey(long parallelismThreshold,
3887                                Function&lt;? super K, ? extends U&gt; transformer,
3888                                Consumer&lt;? super U&gt; action) {
3889         if (transformer == null || action == null)
3890             throw new NullPointerException();
3891         new ForEachTransformedKeyTask&lt;K,V,U&gt;
3892             (null, batchFor(parallelismThreshold), 0, 0, table,
3893              transformer, action).invoke();
3894     }
3895 
3896     /**
3897      * Returns a non-null result from applying the given search
3898      * function on each key, or null if none. Upon success,
3899      * further element processing is suppressed and the results of
3900      * any other parallel invocations of the search function are
3901      * ignored.
3902      *
3903      * @param parallelismThreshold the (estimated) number of elements
3904      * needed for this operation to be executed in parallel
3905      * @param searchFunction a function returning a non-null
3906      * result on success, else null
3907      * @param &lt;U&gt; the return type of the search function
3908      * @return a non-null result from applying the given search
3909      * function on each key, or null if none
3910      * @since 1.8
3911      */
3912     public &lt;U&gt; U searchKeys(long parallelismThreshold,
3913                             Function&lt;? super K, ? extends U&gt; searchFunction) {
3914         if (searchFunction == null) throw new NullPointerException();
3915         return new SearchKeysTask&lt;K,V,U&gt;
3916             (null, batchFor(parallelismThreshold), 0, 0, table,
3917              searchFunction, new AtomicReference&lt;U&gt;()).invoke();
3918     }
3919 
3920     /**
3921      * Returns the result of accumulating all keys using the given
3922      * reducer to combine values, or null if none.
3923      *
3924      * @param parallelismThreshold the (estimated) number of elements
3925      * needed for this operation to be executed in parallel
3926      * @param reducer a commutative associative combining function
3927      * @return the result of accumulating all keys using the given
3928      * reducer to combine values, or null if none
3929      * @since 1.8
3930      */
3931     public K reduceKeys(long parallelismThreshold,
3932                         BiFunction&lt;? super K, ? super K, ? extends K&gt; reducer) {
3933         if (reducer == null) throw new NullPointerException();
3934         return new ReduceKeysTask&lt;K,V&gt;
3935             (null, batchFor(parallelismThreshold), 0, 0, table,
3936              null, reducer).invoke();
3937     }
3938 
3939     /**
3940      * Returns the result of accumulating the given transformation
3941      * of all keys using the given reducer to combine values, or
3942      * null if none.
3943      *
3944      * @param parallelismThreshold the (estimated) number of elements
3945      * needed for this operation to be executed in parallel
3946      * @param transformer a function returning the transformation
3947      * for an element, or null if there is no transformation (in
3948      * which case it is not combined)
3949      * @param reducer a commutative associative combining function
3950      * @param &lt;U&gt; the return type of the transformer
3951      * @return the result of accumulating the given transformation
3952      * of all keys
3953      * @since 1.8
3954      */
3955     public &lt;U&gt; U reduceKeys(long parallelismThreshold,
3956                             Function&lt;? super K, ? extends U&gt; transformer,
3957          BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer) {
3958         if (transformer == null || reducer == null)
3959             throw new NullPointerException();
3960         return new MapReduceKeysTask&lt;K,V,U&gt;
3961             (null, batchFor(parallelismThreshold), 0, 0, table,
3962              null, transformer, reducer).invoke();
3963     }
3964 
3965     /**
3966      * Returns the result of accumulating the given transformation
3967      * of all keys using the given reducer to combine values, and
3968      * the given basis as an identity value.
3969      *
3970      * @param parallelismThreshold the (estimated) number of elements
3971      * needed for this operation to be executed in parallel
3972      * @param transformer a function returning the transformation
3973      * for an element
3974      * @param basis the identity (initial default value) for the reduction
3975      * @param reducer a commutative associative combining function
3976      * @return the result of accumulating the given transformation
3977      * of all keys
3978      * @since 1.8
3979      */
3980     public double reduceKeysToDouble(long parallelismThreshold,
3981                                      ToDoubleFunction&lt;? super K&gt; transformer,
3982                                      double basis,
3983                                      DoubleBinaryOperator reducer) {
3984         if (transformer == null || reducer == null)
3985             throw new NullPointerException();
3986         return new MapReduceKeysToDoubleTask&lt;K,V&gt;
3987             (null, batchFor(parallelismThreshold), 0, 0, table,
3988              null, transformer, basis, reducer).invoke();
3989     }
3990 
3991     /**
3992      * Returns the result of accumulating the given transformation
3993      * of all keys using the given reducer to combine values, and
3994      * the given basis as an identity value.
3995      *
3996      * @param parallelismThreshold the (estimated) number of elements
3997      * needed for this operation to be executed in parallel
3998      * @param transformer a function returning the transformation
3999      * for an element
4000      * @param basis the identity (initial default value) for the reduction
4001      * @param reducer a commutative associative combining function
4002      * @return the result of accumulating the given transformation
4003      * of all keys
4004      * @since 1.8
4005      */
4006     public long reduceKeysToLong(long parallelismThreshold,
4007                                  ToLongFunction&lt;? super K&gt; transformer,
4008                                  long basis,
4009                                  LongBinaryOperator reducer) {
4010         if (transformer == null || reducer == null)
4011             throw new NullPointerException();
4012         return new MapReduceKeysToLongTask&lt;K,V&gt;
4013             (null, batchFor(parallelismThreshold), 0, 0, table,
4014              null, transformer, basis, reducer).invoke();
4015     }
4016 
4017     /**
4018      * Returns the result of accumulating the given transformation
4019      * of all keys using the given reducer to combine values, and
4020      * the given basis as an identity value.
4021      *
4022      * @param parallelismThreshold the (estimated) number of elements
4023      * needed for this operation to be executed in parallel
4024      * @param transformer a function returning the transformation
4025      * for an element
4026      * @param basis the identity (initial default value) for the reduction
4027      * @param reducer a commutative associative combining function
4028      * @return the result of accumulating the given transformation
4029      * of all keys
4030      * @since 1.8
4031      */
4032     public int reduceKeysToInt(long parallelismThreshold,
4033                                ToIntFunction&lt;? super K&gt; transformer,
4034                                int basis,
4035                                IntBinaryOperator reducer) {
4036         if (transformer == null || reducer == null)
4037             throw new NullPointerException();
4038         return new MapReduceKeysToIntTask&lt;K,V&gt;
4039             (null, batchFor(parallelismThreshold), 0, 0, table,
4040              null, transformer, basis, reducer).invoke();
4041     }
4042 
4043     /**
4044      * Performs the given action for each value.
4045      *
4046      * @param parallelismThreshold the (estimated) number of elements
4047      * needed for this operation to be executed in parallel
4048      * @param action the action
4049      * @since 1.8
4050      */
4051     public void forEachValue(long parallelismThreshold,
4052                              Consumer&lt;? super V&gt; action) {
4053         if (action == null)
4054             throw new NullPointerException();
4055         new ForEachValueTask&lt;K,V&gt;
4056             (null, batchFor(parallelismThreshold), 0, 0, table,
4057              action).invoke();
4058     }
4059 
4060     /**
4061      * Performs the given action for each non-null transformation
4062      * of each value.
4063      *
4064      * @param parallelismThreshold the (estimated) number of elements
4065      * needed for this operation to be executed in parallel
4066      * @param transformer a function returning the transformation
4067      * for an element, or null if there is no transformation (in
4068      * which case the action is not applied)
4069      * @param action the action
4070      * @param &lt;U&gt; the return type of the transformer
4071      * @since 1.8
4072      */
4073     public &lt;U&gt; void forEachValue(long parallelismThreshold,
4074                                  Function&lt;? super V, ? extends U&gt; transformer,
4075                                  Consumer&lt;? super U&gt; action) {
4076         if (transformer == null || action == null)
4077             throw new NullPointerException();
4078         new ForEachTransformedValueTask&lt;K,V,U&gt;
4079             (null, batchFor(parallelismThreshold), 0, 0, table,
4080              transformer, action).invoke();
4081     }
4082 
4083     /**
4084      * Returns a non-null result from applying the given search
4085      * function on each value, or null if none.  Upon success,
4086      * further element processing is suppressed and the results of
4087      * any other parallel invocations of the search function are
4088      * ignored.
4089      *
4090      * @param parallelismThreshold the (estimated) number of elements
4091      * needed for this operation to be executed in parallel
4092      * @param searchFunction a function returning a non-null
4093      * result on success, else null
4094      * @param &lt;U&gt; the return type of the search function
4095      * @return a non-null result from applying the given search
4096      * function on each value, or null if none
4097      * @since 1.8
4098      */
4099     public &lt;U&gt; U searchValues(long parallelismThreshold,
4100                               Function&lt;? super V, ? extends U&gt; searchFunction) {
4101         if (searchFunction == null) throw new NullPointerException();
4102         return new SearchValuesTask&lt;K,V,U&gt;
4103             (null, batchFor(parallelismThreshold), 0, 0, table,
4104              searchFunction, new AtomicReference&lt;U&gt;()).invoke();
4105     }
4106 
4107     /**
4108      * Returns the result of accumulating all values using the
4109      * given reducer to combine values, or null if none.
4110      *
4111      * @param parallelismThreshold the (estimated) number of elements
4112      * needed for this operation to be executed in parallel
4113      * @param reducer a commutative associative combining function
4114      * @return the result of accumulating all values
4115      * @since 1.8
4116      */
4117     public V reduceValues(long parallelismThreshold,
4118                           BiFunction&lt;? super V, ? super V, ? extends V&gt; reducer) {
4119         if (reducer == null) throw new NullPointerException();
4120         return new ReduceValuesTask&lt;K,V&gt;
4121             (null, batchFor(parallelismThreshold), 0, 0, table,
4122              null, reducer).invoke();
4123     }
4124 
4125     /**
4126      * Returns the result of accumulating the given transformation
4127      * of all values using the given reducer to combine values, or
4128      * null if none.
4129      *
4130      * @param parallelismThreshold the (estimated) number of elements
4131      * needed for this operation to be executed in parallel
4132      * @param transformer a function returning the transformation
4133      * for an element, or null if there is no transformation (in
4134      * which case it is not combined)
4135      * @param reducer a commutative associative combining function
4136      * @param &lt;U&gt; the return type of the transformer
4137      * @return the result of accumulating the given transformation
4138      * of all values
4139      * @since 1.8
4140      */
4141     public &lt;U&gt; U reduceValues(long parallelismThreshold,
4142                               Function&lt;? super V, ? extends U&gt; transformer,
4143                               BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer) {
4144         if (transformer == null || reducer == null)
4145             throw new NullPointerException();
4146         return new MapReduceValuesTask&lt;K,V,U&gt;
4147             (null, batchFor(parallelismThreshold), 0, 0, table,
4148              null, transformer, reducer).invoke();
4149     }
4150 
4151     /**
4152      * Returns the result of accumulating the given transformation
4153      * of all values using the given reducer to combine values,
4154      * and the given basis as an identity value.
4155      *
4156      * @param parallelismThreshold the (estimated) number of elements
4157      * needed for this operation to be executed in parallel
4158      * @param transformer a function returning the transformation
4159      * for an element
4160      * @param basis the identity (initial default value) for the reduction
4161      * @param reducer a commutative associative combining function
4162      * @return the result of accumulating the given transformation
4163      * of all values
4164      * @since 1.8
4165      */
4166     public double reduceValuesToDouble(long parallelismThreshold,
4167                                        ToDoubleFunction&lt;? super V&gt; transformer,
4168                                        double basis,
4169                                        DoubleBinaryOperator reducer) {
4170         if (transformer == null || reducer == null)
4171             throw new NullPointerException();
4172         return new MapReduceValuesToDoubleTask&lt;K,V&gt;
4173             (null, batchFor(parallelismThreshold), 0, 0, table,
4174              null, transformer, basis, reducer).invoke();
4175     }
4176 
4177     /**
4178      * Returns the result of accumulating the given transformation
4179      * of all values using the given reducer to combine values,
4180      * and the given basis as an identity value.
4181      *
4182      * @param parallelismThreshold the (estimated) number of elements
4183      * needed for this operation to be executed in parallel
4184      * @param transformer a function returning the transformation
4185      * for an element
4186      * @param basis the identity (initial default value) for the reduction
4187      * @param reducer a commutative associative combining function
4188      * @return the result of accumulating the given transformation
4189      * of all values
4190      * @since 1.8
4191      */
4192     public long reduceValuesToLong(long parallelismThreshold,
4193                                    ToLongFunction&lt;? super V&gt; transformer,
4194                                    long basis,
4195                                    LongBinaryOperator reducer) {
4196         if (transformer == null || reducer == null)
4197             throw new NullPointerException();
4198         return new MapReduceValuesToLongTask&lt;K,V&gt;
4199             (null, batchFor(parallelismThreshold), 0, 0, table,
4200              null, transformer, basis, reducer).invoke();
4201     }
4202 
4203     /**
4204      * Returns the result of accumulating the given transformation
4205      * of all values using the given reducer to combine values,
4206      * and the given basis as an identity value.
4207      *
4208      * @param parallelismThreshold the (estimated) number of elements
4209      * needed for this operation to be executed in parallel
4210      * @param transformer a function returning the transformation
4211      * for an element
4212      * @param basis the identity (initial default value) for the reduction
4213      * @param reducer a commutative associative combining function
4214      * @return the result of accumulating the given transformation
4215      * of all values
4216      * @since 1.8
4217      */
4218     public int reduceValuesToInt(long parallelismThreshold,
4219                                  ToIntFunction&lt;? super V&gt; transformer,
4220                                  int basis,
4221                                  IntBinaryOperator reducer) {
4222         if (transformer == null || reducer == null)
4223             throw new NullPointerException();
4224         return new MapReduceValuesToIntTask&lt;K,V&gt;
4225             (null, batchFor(parallelismThreshold), 0, 0, table,
4226              null, transformer, basis, reducer).invoke();
4227     }
4228 
4229     /**
4230      * Performs the given action for each entry.
4231      *
4232      * @param parallelismThreshold the (estimated) number of elements
4233      * needed for this operation to be executed in parallel
4234      * @param action the action
4235      * @since 1.8
4236      */
4237     public void forEachEntry(long parallelismThreshold,
4238                              Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) {
4239         if (action == null) throw new NullPointerException();
4240         new ForEachEntryTask&lt;K,V&gt;(null, batchFor(parallelismThreshold), 0, 0, table,
4241                                   action).invoke();
4242     }
4243 
4244     /**
4245      * Performs the given action for each non-null transformation
4246      * of each entry.
4247      *
4248      * @param parallelismThreshold the (estimated) number of elements
4249      * needed for this operation to be executed in parallel
4250      * @param transformer a function returning the transformation
4251      * for an element, or null if there is no transformation (in
4252      * which case the action is not applied)
4253      * @param action the action
4254      * @param &lt;U&gt; the return type of the transformer
4255      * @since 1.8
4256      */
4257     public &lt;U&gt; void forEachEntry(long parallelismThreshold,
4258                                  Function&lt;Map.Entry&lt;K,V&gt;, ? extends U&gt; transformer,
4259                                  Consumer&lt;? super U&gt; action) {
4260         if (transformer == null || action == null)
4261             throw new NullPointerException();
4262         new ForEachTransformedEntryTask&lt;K,V,U&gt;
4263             (null, batchFor(parallelismThreshold), 0, 0, table,
4264              transformer, action).invoke();
4265     }
4266 
4267     /**
4268      * Returns a non-null result from applying the given search
4269      * function on each entry, or null if none.  Upon success,
4270      * further element processing is suppressed and the results of
4271      * any other parallel invocations of the search function are
4272      * ignored.
4273      *
4274      * @param parallelismThreshold the (estimated) number of elements
4275      * needed for this operation to be executed in parallel
4276      * @param searchFunction a function returning a non-null
4277      * result on success, else null
4278      * @param &lt;U&gt; the return type of the search function
4279      * @return a non-null result from applying the given search
4280      * function on each entry, or null if none
4281      * @since 1.8
4282      */
4283     public &lt;U&gt; U searchEntries(long parallelismThreshold,
4284                                Function&lt;Map.Entry&lt;K,V&gt;, ? extends U&gt; searchFunction) {
4285         if (searchFunction == null) throw new NullPointerException();
4286         return new SearchEntriesTask&lt;K,V,U&gt;
4287             (null, batchFor(parallelismThreshold), 0, 0, table,
4288              searchFunction, new AtomicReference&lt;U&gt;()).invoke();
4289     }
4290 
4291     /**
4292      * Returns the result of accumulating all entries using the
4293      * given reducer to combine values, or null if none.
4294      *
4295      * @param parallelismThreshold the (estimated) number of elements
4296      * needed for this operation to be executed in parallel
4297      * @param reducer a commutative associative combining function
4298      * @return the result of accumulating all entries
4299      * @since 1.8
4300      */
4301     public Map.Entry&lt;K,V&gt; reduceEntries(long parallelismThreshold,
4302                                         BiFunction&lt;Map.Entry&lt;K,V&gt;, Map.Entry&lt;K,V&gt;, ? extends Map.Entry&lt;K,V&gt;&gt; reducer) {
4303         if (reducer == null) throw new NullPointerException();
4304         return new ReduceEntriesTask&lt;K,V&gt;
4305             (null, batchFor(parallelismThreshold), 0, 0, table,
4306              null, reducer).invoke();
4307     }
4308 
4309     /**
4310      * Returns the result of accumulating the given transformation
4311      * of all entries using the given reducer to combine values,
4312      * or null if none.
4313      *
4314      * @param parallelismThreshold the (estimated) number of elements
4315      * needed for this operation to be executed in parallel
4316      * @param transformer a function returning the transformation
4317      * for an element, or null if there is no transformation (in
4318      * which case it is not combined)
4319      * @param reducer a commutative associative combining function
4320      * @param &lt;U&gt; the return type of the transformer
4321      * @return the result of accumulating the given transformation
4322      * of all entries
4323      * @since 1.8
4324      */
4325     public &lt;U&gt; U reduceEntries(long parallelismThreshold,
4326                                Function&lt;Map.Entry&lt;K,V&gt;, ? extends U&gt; transformer,
4327                                BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer) {
4328         if (transformer == null || reducer == null)
4329             throw new NullPointerException();
4330         return new MapReduceEntriesTask&lt;K,V,U&gt;
4331             (null, batchFor(parallelismThreshold), 0, 0, table,
4332              null, transformer, reducer).invoke();
4333     }
4334 
4335     /**
4336      * Returns the result of accumulating the given transformation
4337      * of all entries using the given reducer to combine values,
4338      * and the given basis as an identity value.
4339      *
4340      * @param parallelismThreshold the (estimated) number of elements
4341      * needed for this operation to be executed in parallel
4342      * @param transformer a function returning the transformation
4343      * for an element
4344      * @param basis the identity (initial default value) for the reduction
4345      * @param reducer a commutative associative combining function
4346      * @return the result of accumulating the given transformation
4347      * of all entries
4348      * @since 1.8
4349      */
4350     public double reduceEntriesToDouble(long parallelismThreshold,
4351                                         ToDoubleFunction&lt;Map.Entry&lt;K,V&gt;&gt; transformer,
4352                                         double basis,
4353                                         DoubleBinaryOperator reducer) {
4354         if (transformer == null || reducer == null)
4355             throw new NullPointerException();
4356         return new MapReduceEntriesToDoubleTask&lt;K,V&gt;
4357             (null, batchFor(parallelismThreshold), 0, 0, table,
4358              null, transformer, basis, reducer).invoke();
4359     }
4360 
4361     /**
4362      * Returns the result of accumulating the given transformation
4363      * of all entries using the given reducer to combine values,
4364      * and the given basis as an identity value.
4365      *
4366      * @param parallelismThreshold the (estimated) number of elements
4367      * needed for this operation to be executed in parallel
4368      * @param transformer a function returning the transformation
4369      * for an element
4370      * @param basis the identity (initial default value) for the reduction
4371      * @param reducer a commutative associative combining function
4372      * @return the result of accumulating the given transformation
4373      * of all entries
4374      * @since 1.8
4375      */
4376     public long reduceEntriesToLong(long parallelismThreshold,
4377                                     ToLongFunction&lt;Map.Entry&lt;K,V&gt;&gt; transformer,
4378                                     long basis,
4379                                     LongBinaryOperator reducer) {
4380         if (transformer == null || reducer == null)
4381             throw new NullPointerException();
4382         return new MapReduceEntriesToLongTask&lt;K,V&gt;
4383             (null, batchFor(parallelismThreshold), 0, 0, table,
4384              null, transformer, basis, reducer).invoke();
4385     }
4386 
4387     /**
4388      * Returns the result of accumulating the given transformation
4389      * of all entries using the given reducer to combine values,
4390      * and the given basis as an identity value.
4391      *
4392      * @param parallelismThreshold the (estimated) number of elements
4393      * needed for this operation to be executed in parallel
4394      * @param transformer a function returning the transformation
4395      * for an element
4396      * @param basis the identity (initial default value) for the reduction
4397      * @param reducer a commutative associative combining function
4398      * @return the result of accumulating the given transformation
4399      * of all entries
4400      * @since 1.8
4401      */
4402     public int reduceEntriesToInt(long parallelismThreshold,
4403                                   ToIntFunction&lt;Map.Entry&lt;K,V&gt;&gt; transformer,
4404                                   int basis,
4405                                   IntBinaryOperator reducer) {
4406         if (transformer == null || reducer == null)
4407             throw new NullPointerException();
4408         return new MapReduceEntriesToIntTask&lt;K,V&gt;
4409             (null, batchFor(parallelismThreshold), 0, 0, table,
4410              null, transformer, basis, reducer).invoke();
4411     }
4412 
4413 
4414     /* ----------------Views -------------- */
4415 
4416     /**
4417      * Base class for views.
4418      */
4419     abstract static class CollectionView&lt;K,V,E&gt;
4420         implements Collection&lt;E&gt;, java.io.Serializable {
4421         private static final long serialVersionUID = 7249069246763182397L;
4422         final ConcurrentHashMap&lt;K,V&gt; map;
4423         CollectionView(ConcurrentHashMap&lt;K,V&gt; map)  { this.map = map; }
4424 
4425         /**
4426          * Returns the map backing this view.
4427          *
4428          * @return the map backing this view
4429          */
4430         public ConcurrentHashMap&lt;K,V&gt; getMap() { return map; }
4431 
4432         /**
4433          * Removes all of the elements from this view, by removing all
4434          * the mappings from the map backing this view.
4435          */
4436         public final void clear()      { map.clear(); }
4437         public final int size()        { return map.size(); }
4438         public final boolean isEmpty() { return map.isEmpty(); }
4439 
4440         // implementations below rely on concrete classes supplying these
4441         // abstract methods
4442         /**
4443          * Returns an iterator over the elements in this collection.
4444          *
4445          * &lt;p&gt;The returned iterator is
4446          * &lt;a href=&quot;package-summary.html#Weakly&quot;&gt;&lt;i&gt;weakly consistent&lt;/i&gt;&lt;/a&gt;.
4447          *
4448          * @return an iterator over the elements in this collection
4449          */
4450         public abstract Iterator&lt;E&gt; iterator();
4451         public abstract boolean contains(Object o);
4452         public abstract boolean remove(Object o);
4453 
4454         private static final String OOME_MSG = &quot;Required array size too large&quot;;
4455 
4456         public final Object[] toArray() {
4457             long sz = map.mappingCount();
4458             if (sz &gt; MAX_ARRAY_SIZE)
4459                 throw new OutOfMemoryError(OOME_MSG);
4460             int n = (int)sz;
4461             Object[] r = new Object[n];
4462             int i = 0;
4463             for (E e : this) {
4464                 if (i == n) {
4465                     if (n &gt;= MAX_ARRAY_SIZE)
4466                         throw new OutOfMemoryError(OOME_MSG);
4467                     if (n &gt;= MAX_ARRAY_SIZE - (MAX_ARRAY_SIZE &gt;&gt;&gt; 1) - 1)
4468                         n = MAX_ARRAY_SIZE;
4469                     else
4470                         n += (n &gt;&gt;&gt; 1) + 1;
4471                     r = Arrays.copyOf(r, n);
4472                 }
4473                 r[i++] = e;
4474             }
4475             return (i == n) ? r : Arrays.copyOf(r, i);
4476         }
4477 
4478         @SuppressWarnings(&quot;unchecked&quot;)
4479         public final &lt;T&gt; T[] toArray(T[] a) {
4480             long sz = map.mappingCount();
4481             if (sz &gt; MAX_ARRAY_SIZE)
4482                 throw new OutOfMemoryError(OOME_MSG);
4483             int m = (int)sz;
4484             T[] r = (a.length &gt;= m) ? a :
4485                 (T[])java.lang.reflect.Array
4486                 .newInstance(a.getClass().getComponentType(), m);
4487             int n = r.length;
4488             int i = 0;
4489             for (E e : this) {
4490                 if (i == n) {
4491                     if (n &gt;= MAX_ARRAY_SIZE)
4492                         throw new OutOfMemoryError(OOME_MSG);
4493                     if (n &gt;= MAX_ARRAY_SIZE - (MAX_ARRAY_SIZE &gt;&gt;&gt; 1) - 1)
4494                         n = MAX_ARRAY_SIZE;
4495                     else
4496                         n += (n &gt;&gt;&gt; 1) + 1;
4497                     r = Arrays.copyOf(r, n);
4498                 }
4499                 r[i++] = (T)e;
4500             }
4501             if (a == r &amp;&amp; i &lt; n) {
4502                 r[i] = null; // null-terminate
4503                 return r;
4504             }
4505             return (i == n) ? r : Arrays.copyOf(r, i);
4506         }
4507 
4508         /**
4509          * Returns a string representation of this collection.
4510          * The string representation consists of the string representations
4511          * of the collection&#39;s elements in the order they are returned by
4512          * its iterator, enclosed in square brackets ({@code &quot;[]&quot;}).
4513          * Adjacent elements are separated by the characters {@code &quot;, &quot;}
4514          * (comma and space).  Elements are converted to strings as by
4515          * {@link String#valueOf(Object)}.
4516          *
4517          * @return a string representation of this collection
4518          */
4519         public final String toString() {
4520             StringBuilder sb = new StringBuilder();
4521             sb.append(&#39;[&#39;);
4522             Iterator&lt;E&gt; it = iterator();
4523             if (it.hasNext()) {
4524                 for (;;) {
4525                     Object e = it.next();
4526                     sb.append(e == this ? &quot;(this Collection)&quot; : e);
4527                     if (!it.hasNext())
4528                         break;
4529                     sb.append(&#39;,&#39;).append(&#39; &#39;);
4530                 }
4531             }
4532             return sb.append(&#39;]&#39;).toString();
4533         }
4534 
4535         public final boolean containsAll(Collection&lt;?&gt; c) {
4536             if (c != this) {
4537                 for (Object e : c) {
4538                     if (e == null || !contains(e))
4539                         return false;
4540                 }
4541             }
4542             return true;
4543         }
4544 
4545         public boolean removeAll(Collection&lt;?&gt; c) {
4546             if (c == null) throw new NullPointerException();
4547             boolean modified = false;
4548             // Use (c instanceof Set) as a hint that lookup in c is as
4549             // efficient as this view
4550             Node&lt;K,V&gt;[] t;
4551             if ((t = map.table) == null) {
4552                 return false;
4553             } else if (c instanceof Set&lt;?&gt; &amp;&amp; c.size() &gt; t.length) {
4554                 for (Iterator&lt;?&gt; it = iterator(); it.hasNext(); ) {
4555                     if (c.contains(it.next())) {
4556                         it.remove();
4557                         modified = true;
4558                     }
4559                 }
4560             } else {
4561                 for (Object e : c)
4562                     modified |= remove(e);
4563             }
4564             return modified;
4565         }
4566 
4567         public final boolean retainAll(Collection&lt;?&gt; c) {
4568             if (c == null) throw new NullPointerException();
4569             boolean modified = false;
4570             for (Iterator&lt;E&gt; it = iterator(); it.hasNext();) {
4571                 if (!c.contains(it.next())) {
4572                     it.remove();
4573                     modified = true;
4574                 }
4575             }
4576             return modified;
4577         }
4578 
4579     }
4580 
4581     /**
4582      * A view of a ConcurrentHashMap as a {@link Set} of keys, in
4583      * which additions may optionally be enabled by mapping to a
4584      * common value.  This class cannot be directly instantiated.
4585      * See {@link #keySet() keySet()},
4586      * {@link #keySet(Object) keySet(V)},
4587      * {@link #newKeySet() newKeySet()},
4588      * {@link #newKeySet(int) newKeySet(int)}.
4589      *
4590      * @since 1.8
4591      */
4592     public static class KeySetView&lt;K,V&gt; extends CollectionView&lt;K,V,K&gt;
4593         implements Set&lt;K&gt;, java.io.Serializable {
4594         private static final long serialVersionUID = 7249069246763182397L;
<a name="7" id="anc7"></a><span class="line-added">4595         @SuppressWarnings(&quot;serial&quot;) // Conditionally serializable</span>
4596         private final V value;
4597         KeySetView(ConcurrentHashMap&lt;K,V&gt; map, V value) {  // non-public
4598             super(map);
4599             this.value = value;
4600         }
4601 
4602         /**
4603          * Returns the default mapped value for additions,
4604          * or {@code null} if additions are not supported.
4605          *
4606          * @return the default mapped value for additions, or {@code null}
4607          * if not supported
4608          */
4609         public V getMappedValue() { return value; }
4610 
4611         /**
4612          * {@inheritDoc}
4613          * @throws NullPointerException if the specified key is null
4614          */
4615         public boolean contains(Object o) { return map.containsKey(o); }
4616 
4617         /**
4618          * Removes the key from this map view, by removing the key (and its
4619          * corresponding value) from the backing map.  This method does
4620          * nothing if the key is not in the map.
4621          *
4622          * @param  o the key to be removed from the backing map
4623          * @return {@code true} if the backing map contained the specified key
4624          * @throws NullPointerException if the specified key is null
4625          */
4626         public boolean remove(Object o) { return map.remove(o) != null; }
4627 
4628         /**
4629          * @return an iterator over the keys of the backing map
4630          */
4631         public Iterator&lt;K&gt; iterator() {
4632             Node&lt;K,V&gt;[] t;
4633             ConcurrentHashMap&lt;K,V&gt; m = map;
4634             int f = (t = m.table) == null ? 0 : t.length;
4635             return new KeyIterator&lt;K,V&gt;(t, f, 0, f, m);
4636         }
4637 
4638         /**
4639          * Adds the specified key to this set view by mapping the key to
4640          * the default mapped value in the backing map, if defined.
4641          *
4642          * @param e key to be added
4643          * @return {@code true} if this set changed as a result of the call
4644          * @throws NullPointerException if the specified key is null
4645          * @throws UnsupportedOperationException if no default mapped value
4646          * for additions was provided
4647          */
4648         public boolean add(K e) {
4649             V v;
4650             if ((v = value) == null)
4651                 throw new UnsupportedOperationException();
4652             return map.putVal(e, v, true) == null;
4653         }
4654 
4655         /**
4656          * Adds all of the elements in the specified collection to this set,
4657          * as if by calling {@link #add} on each one.
4658          *
4659          * @param c the elements to be inserted into this set
4660          * @return {@code true} if this set changed as a result of the call
4661          * @throws NullPointerException if the collection or any of its
4662          * elements are {@code null}
4663          * @throws UnsupportedOperationException if no default mapped value
4664          * for additions was provided
4665          */
4666         public boolean addAll(Collection&lt;? extends K&gt; c) {
4667             boolean added = false;
4668             V v;
4669             if ((v = value) == null)
4670                 throw new UnsupportedOperationException();
4671             for (K e : c) {
4672                 if (map.putVal(e, v, true) == null)
4673                     added = true;
4674             }
4675             return added;
4676         }
4677 
4678         public int hashCode() {
4679             int h = 0;
4680             for (K e : this)
4681                 h += e.hashCode();
4682             return h;
4683         }
4684 
4685         public boolean equals(Object o) {
4686             Set&lt;?&gt; c;
4687             return ((o instanceof Set) &amp;&amp;
4688                     ((c = (Set&lt;?&gt;)o) == this ||
4689                      (containsAll(c) &amp;&amp; c.containsAll(this))));
4690         }
4691 
4692         public Spliterator&lt;K&gt; spliterator() {
4693             Node&lt;K,V&gt;[] t;
4694             ConcurrentHashMap&lt;K,V&gt; m = map;
4695             long n = m.sumCount();
4696             int f = (t = m.table) == null ? 0 : t.length;
4697             return new KeySpliterator&lt;K,V&gt;(t, f, 0, f, n &lt; 0L ? 0L : n);
4698         }
4699 
4700         public void forEach(Consumer&lt;? super K&gt; action) {
4701             if (action == null) throw new NullPointerException();
4702             Node&lt;K,V&gt;[] t;
4703             if ((t = map.table) != null) {
4704                 Traverser&lt;K,V&gt; it = new Traverser&lt;K,V&gt;(t, t.length, 0, t.length);
4705                 for (Node&lt;K,V&gt; p; (p = it.advance()) != null; )
4706                     action.accept(p.key);
4707             }
4708         }
4709     }
4710 
4711     /**
4712      * A view of a ConcurrentHashMap as a {@link Collection} of
4713      * values, in which additions are disabled. This class cannot be
4714      * directly instantiated. See {@link #values()}.
4715      */
4716     static final class ValuesView&lt;K,V&gt; extends CollectionView&lt;K,V,V&gt;
4717         implements Collection&lt;V&gt;, java.io.Serializable {
4718         private static final long serialVersionUID = 2249069246763182397L;
4719         ValuesView(ConcurrentHashMap&lt;K,V&gt; map) { super(map); }
4720         public final boolean contains(Object o) {
4721             return map.containsValue(o);
4722         }
4723 
4724         public final boolean remove(Object o) {
4725             if (o != null) {
4726                 for (Iterator&lt;V&gt; it = iterator(); it.hasNext();) {
4727                     if (o.equals(it.next())) {
4728                         it.remove();
4729                         return true;
4730                     }
4731                 }
4732             }
4733             return false;
4734         }
4735 
4736         public final Iterator&lt;V&gt; iterator() {
4737             ConcurrentHashMap&lt;K,V&gt; m = map;
4738             Node&lt;K,V&gt;[] t;
4739             int f = (t = m.table) == null ? 0 : t.length;
4740             return new ValueIterator&lt;K,V&gt;(t, f, 0, f, m);
4741         }
4742 
4743         public final boolean add(V e) {
4744             throw new UnsupportedOperationException();
4745         }
4746         public final boolean addAll(Collection&lt;? extends V&gt; c) {
4747             throw new UnsupportedOperationException();
4748         }
4749 
4750         @Override public boolean removeAll(Collection&lt;?&gt; c) {
4751             if (c == null) throw new NullPointerException();
4752             boolean modified = false;
4753             for (Iterator&lt;V&gt; it = iterator(); it.hasNext();) {
4754                 if (c.contains(it.next())) {
4755                     it.remove();
4756                     modified = true;
4757                 }
4758             }
4759             return modified;
4760         }
4761 
4762         public boolean removeIf(Predicate&lt;? super V&gt; filter) {
4763             return map.removeValueIf(filter);
4764         }
4765 
4766         public Spliterator&lt;V&gt; spliterator() {
4767             Node&lt;K,V&gt;[] t;
4768             ConcurrentHashMap&lt;K,V&gt; m = map;
4769             long n = m.sumCount();
4770             int f = (t = m.table) == null ? 0 : t.length;
4771             return new ValueSpliterator&lt;K,V&gt;(t, f, 0, f, n &lt; 0L ? 0L : n);
4772         }
4773 
4774         public void forEach(Consumer&lt;? super V&gt; action) {
4775             if (action == null) throw new NullPointerException();
4776             Node&lt;K,V&gt;[] t;
4777             if ((t = map.table) != null) {
4778                 Traverser&lt;K,V&gt; it = new Traverser&lt;K,V&gt;(t, t.length, 0, t.length);
4779                 for (Node&lt;K,V&gt; p; (p = it.advance()) != null; )
4780                     action.accept(p.val);
4781             }
4782         }
4783     }
4784 
4785     /**
4786      * A view of a ConcurrentHashMap as a {@link Set} of (key, value)
4787      * entries.  This class cannot be directly instantiated. See
4788      * {@link #entrySet()}.
4789      */
4790     static final class EntrySetView&lt;K,V&gt; extends CollectionView&lt;K,V,Map.Entry&lt;K,V&gt;&gt;
4791         implements Set&lt;Map.Entry&lt;K,V&gt;&gt;, java.io.Serializable {
4792         private static final long serialVersionUID = 2249069246763182397L;
4793         EntrySetView(ConcurrentHashMap&lt;K,V&gt; map) { super(map); }
4794 
4795         public boolean contains(Object o) {
4796             Object k, v, r; Map.Entry&lt;?,?&gt; e;
4797             return ((o instanceof Map.Entry) &amp;&amp;
4798                     (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != null &amp;&amp;
4799                     (r = map.get(k)) != null &amp;&amp;
4800                     (v = e.getValue()) != null &amp;&amp;
4801                     (v == r || v.equals(r)));
4802         }
4803 
4804         public boolean remove(Object o) {
4805             Object k, v; Map.Entry&lt;?,?&gt; e;
4806             return ((o instanceof Map.Entry) &amp;&amp;
4807                     (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != null &amp;&amp;
4808                     (v = e.getValue()) != null &amp;&amp;
4809                     map.remove(k, v));
4810         }
4811 
4812         /**
4813          * @return an iterator over the entries of the backing map
4814          */
4815         public Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() {
4816             ConcurrentHashMap&lt;K,V&gt; m = map;
4817             Node&lt;K,V&gt;[] t;
4818             int f = (t = m.table) == null ? 0 : t.length;
4819             return new EntryIterator&lt;K,V&gt;(t, f, 0, f, m);
4820         }
4821 
4822         public boolean add(Entry&lt;K,V&gt; e) {
4823             return map.putVal(e.getKey(), e.getValue(), false) == null;
4824         }
4825 
4826         public boolean addAll(Collection&lt;? extends Entry&lt;K,V&gt;&gt; c) {
4827             boolean added = false;
4828             for (Entry&lt;K,V&gt; e : c) {
4829                 if (add(e))
4830                     added = true;
4831             }
4832             return added;
4833         }
4834 
4835         public boolean removeIf(Predicate&lt;? super Entry&lt;K,V&gt;&gt; filter) {
4836             return map.removeEntryIf(filter);
4837         }
4838 
4839         public final int hashCode() {
4840             int h = 0;
4841             Node&lt;K,V&gt;[] t;
4842             if ((t = map.table) != null) {
4843                 Traverser&lt;K,V&gt; it = new Traverser&lt;K,V&gt;(t, t.length, 0, t.length);
4844                 for (Node&lt;K,V&gt; p; (p = it.advance()) != null; ) {
4845                     h += p.hashCode();
4846                 }
4847             }
4848             return h;
4849         }
4850 
4851         public final boolean equals(Object o) {
4852             Set&lt;?&gt; c;
4853             return ((o instanceof Set) &amp;&amp;
4854                     ((c = (Set&lt;?&gt;)o) == this ||
4855                      (containsAll(c) &amp;&amp; c.containsAll(this))));
4856         }
4857 
4858         public Spliterator&lt;Map.Entry&lt;K,V&gt;&gt; spliterator() {
4859             Node&lt;K,V&gt;[] t;
4860             ConcurrentHashMap&lt;K,V&gt; m = map;
4861             long n = m.sumCount();
4862             int f = (t = m.table) == null ? 0 : t.length;
4863             return new EntrySpliterator&lt;K,V&gt;(t, f, 0, f, n &lt; 0L ? 0L : n, m);
4864         }
4865 
4866         public void forEach(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) {
4867             if (action == null) throw new NullPointerException();
4868             Node&lt;K,V&gt;[] t;
4869             if ((t = map.table) != null) {
4870                 Traverser&lt;K,V&gt; it = new Traverser&lt;K,V&gt;(t, t.length, 0, t.length);
4871                 for (Node&lt;K,V&gt; p; (p = it.advance()) != null; )
4872                     action.accept(new MapEntry&lt;K,V&gt;(p.key, p.val, map));
4873             }
4874         }
4875 
4876     }
4877 
4878     // -------------------------------------------------------
4879 
4880     /**
4881      * Base class for bulk tasks. Repeats some fields and code from
4882      * class Traverser, because we need to subclass CountedCompleter.
4883      */
4884     @SuppressWarnings(&quot;serial&quot;)
4885     abstract static class BulkTask&lt;K,V,R&gt; extends CountedCompleter&lt;R&gt; {
4886         Node&lt;K,V&gt;[] tab;        // same as Traverser
4887         Node&lt;K,V&gt; next;
4888         TableStack&lt;K,V&gt; stack, spare;
4889         int index;
4890         int baseIndex;
4891         int baseLimit;
4892         final int baseSize;
4893         int batch;              // split control
4894 
4895         BulkTask(BulkTask&lt;K,V,?&gt; par, int b, int i, int f, Node&lt;K,V&gt;[] t) {
4896             super(par);
4897             this.batch = b;
4898             this.index = this.baseIndex = i;
4899             if ((this.tab = t) == null)
4900                 this.baseSize = this.baseLimit = 0;
4901             else if (par == null)
4902                 this.baseSize = this.baseLimit = t.length;
4903             else {
4904                 this.baseLimit = f;
4905                 this.baseSize = par.baseSize;
4906             }
4907         }
4908 
4909         /**
4910          * Same as Traverser version.
4911          */
4912         final Node&lt;K,V&gt; advance() {
4913             Node&lt;K,V&gt; e;
4914             if ((e = next) != null)
4915                 e = e.next;
4916             for (;;) {
4917                 Node&lt;K,V&gt;[] t; int i, n;
4918                 if (e != null)
4919                     return next = e;
4920                 if (baseIndex &gt;= baseLimit || (t = tab) == null ||
4921                     (n = t.length) &lt;= (i = index) || i &lt; 0)
4922                     return next = null;
4923                 if ((e = tabAt(t, i)) != null &amp;&amp; e.hash &lt; 0) {
4924                     if (e instanceof ForwardingNode) {
4925                         tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable;
4926                         e = null;
4927                         pushState(t, i, n);
4928                         continue;
4929                     }
4930                     else if (e instanceof TreeBin)
4931                         e = ((TreeBin&lt;K,V&gt;)e).first;
4932                     else
4933                         e = null;
4934                 }
4935                 if (stack != null)
4936                     recoverState(n);
4937                 else if ((index = i + baseSize) &gt;= n)
4938                     index = ++baseIndex;
4939             }
4940         }
4941 
4942         private void pushState(Node&lt;K,V&gt;[] t, int i, int n) {
4943             TableStack&lt;K,V&gt; s = spare;
4944             if (s != null)
4945                 spare = s.next;
4946             else
4947                 s = new TableStack&lt;K,V&gt;();
4948             s.tab = t;
4949             s.length = n;
4950             s.index = i;
4951             s.next = stack;
4952             stack = s;
4953         }
4954 
4955         private void recoverState(int n) {
4956             TableStack&lt;K,V&gt; s; int len;
4957             while ((s = stack) != null &amp;&amp; (index += (len = s.length)) &gt;= n) {
4958                 n = len;
4959                 index = s.index;
4960                 tab = s.tab;
4961                 s.tab = null;
4962                 TableStack&lt;K,V&gt; next = s.next;
4963                 s.next = spare; // save for reuse
4964                 stack = next;
4965                 spare = s;
4966             }
4967             if (s == null &amp;&amp; (index += baseSize) &gt;= n)
4968                 index = ++baseIndex;
4969         }
4970     }
4971 
4972     /*
4973      * Task classes. Coded in a regular but ugly format/style to
4974      * simplify checks that each variant differs in the right way from
4975      * others. The null screenings exist because compilers cannot tell
4976      * that we&#39;ve already null-checked task arguments, so we force
4977      * simplest hoisted bypass to help avoid convoluted traps.
4978      */
4979     @SuppressWarnings(&quot;serial&quot;)
4980     static final class ForEachKeyTask&lt;K,V&gt;
4981         extends BulkTask&lt;K,V,Void&gt; {
4982         final Consumer&lt;? super K&gt; action;
4983         ForEachKeyTask
4984             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
4985              Consumer&lt;? super K&gt; action) {
4986             super(p, b, i, f, t);
4987             this.action = action;
4988         }
4989         public final void compute() {
4990             final Consumer&lt;? super K&gt; action;
4991             if ((action = this.action) != null) {
4992                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
4993                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
4994                     addToPendingCount(1);
4995                     new ForEachKeyTask&lt;K,V&gt;
4996                         (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
4997                          action).fork();
4998                 }
4999                 for (Node&lt;K,V&gt; p; (p = advance()) != null;)
5000                     action.accept(p.key);
5001                 propagateCompletion();
5002             }
5003         }
5004     }
5005 
5006     @SuppressWarnings(&quot;serial&quot;)
5007     static final class ForEachValueTask&lt;K,V&gt;
5008         extends BulkTask&lt;K,V,Void&gt; {
5009         final Consumer&lt;? super V&gt; action;
5010         ForEachValueTask
5011             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5012              Consumer&lt;? super V&gt; action) {
5013             super(p, b, i, f, t);
5014             this.action = action;
5015         }
5016         public final void compute() {
5017             final Consumer&lt;? super V&gt; action;
5018             if ((action = this.action) != null) {
5019                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5020                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5021                     addToPendingCount(1);
5022                     new ForEachValueTask&lt;K,V&gt;
5023                         (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5024                          action).fork();
5025                 }
5026                 for (Node&lt;K,V&gt; p; (p = advance()) != null;)
5027                     action.accept(p.val);
5028                 propagateCompletion();
5029             }
5030         }
5031     }
5032 
5033     @SuppressWarnings(&quot;serial&quot;)
5034     static final class ForEachEntryTask&lt;K,V&gt;
5035         extends BulkTask&lt;K,V,Void&gt; {
5036         final Consumer&lt;? super Entry&lt;K,V&gt;&gt; action;
5037         ForEachEntryTask
5038             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5039              Consumer&lt;? super Entry&lt;K,V&gt;&gt; action) {
5040             super(p, b, i, f, t);
5041             this.action = action;
5042         }
5043         public final void compute() {
5044             final Consumer&lt;? super Entry&lt;K,V&gt;&gt; action;
5045             if ((action = this.action) != null) {
5046                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5047                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5048                     addToPendingCount(1);
5049                     new ForEachEntryTask&lt;K,V&gt;
5050                         (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5051                          action).fork();
5052                 }
5053                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
5054                     action.accept(p);
5055                 propagateCompletion();
5056             }
5057         }
5058     }
5059 
5060     @SuppressWarnings(&quot;serial&quot;)
5061     static final class ForEachMappingTask&lt;K,V&gt;
5062         extends BulkTask&lt;K,V,Void&gt; {
5063         final BiConsumer&lt;? super K, ? super V&gt; action;
5064         ForEachMappingTask
5065             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5066              BiConsumer&lt;? super K,? super V&gt; action) {
5067             super(p, b, i, f, t);
5068             this.action = action;
5069         }
5070         public final void compute() {
5071             final BiConsumer&lt;? super K, ? super V&gt; action;
5072             if ((action = this.action) != null) {
5073                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5074                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5075                     addToPendingCount(1);
5076                     new ForEachMappingTask&lt;K,V&gt;
5077                         (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5078                          action).fork();
5079                 }
5080                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
5081                     action.accept(p.key, p.val);
5082                 propagateCompletion();
5083             }
5084         }
5085     }
5086 
5087     @SuppressWarnings(&quot;serial&quot;)
5088     static final class ForEachTransformedKeyTask&lt;K,V,U&gt;
5089         extends BulkTask&lt;K,V,Void&gt; {
5090         final Function&lt;? super K, ? extends U&gt; transformer;
5091         final Consumer&lt;? super U&gt; action;
5092         ForEachTransformedKeyTask
5093             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5094              Function&lt;? super K, ? extends U&gt; transformer, Consumer&lt;? super U&gt; action) {
5095             super(p, b, i, f, t);
5096             this.transformer = transformer; this.action = action;
5097         }
5098         public final void compute() {
5099             final Function&lt;? super K, ? extends U&gt; transformer;
5100             final Consumer&lt;? super U&gt; action;
5101             if ((transformer = this.transformer) != null &amp;&amp;
5102                 (action = this.action) != null) {
5103                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5104                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5105                     addToPendingCount(1);
5106                     new ForEachTransformedKeyTask&lt;K,V,U&gt;
5107                         (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5108                          transformer, action).fork();
5109                 }
5110                 for (Node&lt;K,V&gt; p; (p = advance()) != null; ) {
5111                     U u;
5112                     if ((u = transformer.apply(p.key)) != null)
5113                         action.accept(u);
5114                 }
5115                 propagateCompletion();
5116             }
5117         }
5118     }
5119 
5120     @SuppressWarnings(&quot;serial&quot;)
5121     static final class ForEachTransformedValueTask&lt;K,V,U&gt;
5122         extends BulkTask&lt;K,V,Void&gt; {
5123         final Function&lt;? super V, ? extends U&gt; transformer;
5124         final Consumer&lt;? super U&gt; action;
5125         ForEachTransformedValueTask
5126             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5127              Function&lt;? super V, ? extends U&gt; transformer, Consumer&lt;? super U&gt; action) {
5128             super(p, b, i, f, t);
5129             this.transformer = transformer; this.action = action;
5130         }
5131         public final void compute() {
5132             final Function&lt;? super V, ? extends U&gt; transformer;
5133             final Consumer&lt;? super U&gt; action;
5134             if ((transformer = this.transformer) != null &amp;&amp;
5135                 (action = this.action) != null) {
5136                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5137                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5138                     addToPendingCount(1);
5139                     new ForEachTransformedValueTask&lt;K,V,U&gt;
5140                         (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5141                          transformer, action).fork();
5142                 }
5143                 for (Node&lt;K,V&gt; p; (p = advance()) != null; ) {
5144                     U u;
5145                     if ((u = transformer.apply(p.val)) != null)
5146                         action.accept(u);
5147                 }
5148                 propagateCompletion();
5149             }
5150         }
5151     }
5152 
5153     @SuppressWarnings(&quot;serial&quot;)
5154     static final class ForEachTransformedEntryTask&lt;K,V,U&gt;
5155         extends BulkTask&lt;K,V,Void&gt; {
5156         final Function&lt;Map.Entry&lt;K,V&gt;, ? extends U&gt; transformer;
5157         final Consumer&lt;? super U&gt; action;
5158         ForEachTransformedEntryTask
5159             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5160              Function&lt;Map.Entry&lt;K,V&gt;, ? extends U&gt; transformer, Consumer&lt;? super U&gt; action) {
5161             super(p, b, i, f, t);
5162             this.transformer = transformer; this.action = action;
5163         }
5164         public final void compute() {
5165             final Function&lt;Map.Entry&lt;K,V&gt;, ? extends U&gt; transformer;
5166             final Consumer&lt;? super U&gt; action;
5167             if ((transformer = this.transformer) != null &amp;&amp;
5168                 (action = this.action) != null) {
5169                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5170                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5171                     addToPendingCount(1);
5172                     new ForEachTransformedEntryTask&lt;K,V,U&gt;
5173                         (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5174                          transformer, action).fork();
5175                 }
5176                 for (Node&lt;K,V&gt; p; (p = advance()) != null; ) {
5177                     U u;
5178                     if ((u = transformer.apply(p)) != null)
5179                         action.accept(u);
5180                 }
5181                 propagateCompletion();
5182             }
5183         }
5184     }
5185 
5186     @SuppressWarnings(&quot;serial&quot;)
5187     static final class ForEachTransformedMappingTask&lt;K,V,U&gt;
5188         extends BulkTask&lt;K,V,Void&gt; {
5189         final BiFunction&lt;? super K, ? super V, ? extends U&gt; transformer;
5190         final Consumer&lt;? super U&gt; action;
5191         ForEachTransformedMappingTask
5192             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5193              BiFunction&lt;? super K, ? super V, ? extends U&gt; transformer,
5194              Consumer&lt;? super U&gt; action) {
5195             super(p, b, i, f, t);
5196             this.transformer = transformer; this.action = action;
5197         }
5198         public final void compute() {
5199             final BiFunction&lt;? super K, ? super V, ? extends U&gt; transformer;
5200             final Consumer&lt;? super U&gt; action;
5201             if ((transformer = this.transformer) != null &amp;&amp;
5202                 (action = this.action) != null) {
5203                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5204                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5205                     addToPendingCount(1);
5206                     new ForEachTransformedMappingTask&lt;K,V,U&gt;
5207                         (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5208                          transformer, action).fork();
5209                 }
5210                 for (Node&lt;K,V&gt; p; (p = advance()) != null; ) {
5211                     U u;
5212                     if ((u = transformer.apply(p.key, p.val)) != null)
5213                         action.accept(u);
5214                 }
5215                 propagateCompletion();
5216             }
5217         }
5218     }
5219 
5220     @SuppressWarnings(&quot;serial&quot;)
5221     static final class SearchKeysTask&lt;K,V,U&gt;
5222         extends BulkTask&lt;K,V,U&gt; {
5223         final Function&lt;? super K, ? extends U&gt; searchFunction;
5224         final AtomicReference&lt;U&gt; result;
5225         SearchKeysTask
5226             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5227              Function&lt;? super K, ? extends U&gt; searchFunction,
5228              AtomicReference&lt;U&gt; result) {
5229             super(p, b, i, f, t);
5230             this.searchFunction = searchFunction; this.result = result;
5231         }
5232         public final U getRawResult() { return result.get(); }
5233         public final void compute() {
5234             final Function&lt;? super K, ? extends U&gt; searchFunction;
5235             final AtomicReference&lt;U&gt; result;
5236             if ((searchFunction = this.searchFunction) != null &amp;&amp;
5237                 (result = this.result) != null) {
5238                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5239                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5240                     if (result.get() != null)
5241                         return;
5242                     addToPendingCount(1);
5243                     new SearchKeysTask&lt;K,V,U&gt;
5244                         (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5245                          searchFunction, result).fork();
5246                 }
5247                 while (result.get() == null) {
5248                     U u;
5249                     Node&lt;K,V&gt; p;
5250                     if ((p = advance()) == null) {
5251                         propagateCompletion();
5252                         break;
5253                     }
5254                     if ((u = searchFunction.apply(p.key)) != null) {
5255                         if (result.compareAndSet(null, u))
5256                             quietlyCompleteRoot();
5257                         break;
5258                     }
5259                 }
5260             }
5261         }
5262     }
5263 
5264     @SuppressWarnings(&quot;serial&quot;)
5265     static final class SearchValuesTask&lt;K,V,U&gt;
5266         extends BulkTask&lt;K,V,U&gt; {
5267         final Function&lt;? super V, ? extends U&gt; searchFunction;
5268         final AtomicReference&lt;U&gt; result;
5269         SearchValuesTask
5270             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5271              Function&lt;? super V, ? extends U&gt; searchFunction,
5272              AtomicReference&lt;U&gt; result) {
5273             super(p, b, i, f, t);
5274             this.searchFunction = searchFunction; this.result = result;
5275         }
5276         public final U getRawResult() { return result.get(); }
5277         public final void compute() {
5278             final Function&lt;? super V, ? extends U&gt; searchFunction;
5279             final AtomicReference&lt;U&gt; result;
5280             if ((searchFunction = this.searchFunction) != null &amp;&amp;
5281                 (result = this.result) != null) {
5282                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5283                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5284                     if (result.get() != null)
5285                         return;
5286                     addToPendingCount(1);
5287                     new SearchValuesTask&lt;K,V,U&gt;
5288                         (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5289                          searchFunction, result).fork();
5290                 }
5291                 while (result.get() == null) {
5292                     U u;
5293                     Node&lt;K,V&gt; p;
5294                     if ((p = advance()) == null) {
5295                         propagateCompletion();
5296                         break;
5297                     }
5298                     if ((u = searchFunction.apply(p.val)) != null) {
5299                         if (result.compareAndSet(null, u))
5300                             quietlyCompleteRoot();
5301                         break;
5302                     }
5303                 }
5304             }
5305         }
5306     }
5307 
5308     @SuppressWarnings(&quot;serial&quot;)
5309     static final class SearchEntriesTask&lt;K,V,U&gt;
5310         extends BulkTask&lt;K,V,U&gt; {
5311         final Function&lt;Entry&lt;K,V&gt;, ? extends U&gt; searchFunction;
5312         final AtomicReference&lt;U&gt; result;
5313         SearchEntriesTask
5314             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5315              Function&lt;Entry&lt;K,V&gt;, ? extends U&gt; searchFunction,
5316              AtomicReference&lt;U&gt; result) {
5317             super(p, b, i, f, t);
5318             this.searchFunction = searchFunction; this.result = result;
5319         }
5320         public final U getRawResult() { return result.get(); }
5321         public final void compute() {
5322             final Function&lt;Entry&lt;K,V&gt;, ? extends U&gt; searchFunction;
5323             final AtomicReference&lt;U&gt; result;
5324             if ((searchFunction = this.searchFunction) != null &amp;&amp;
5325                 (result = this.result) != null) {
5326                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5327                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5328                     if (result.get() != null)
5329                         return;
5330                     addToPendingCount(1);
5331                     new SearchEntriesTask&lt;K,V,U&gt;
5332                         (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5333                          searchFunction, result).fork();
5334                 }
5335                 while (result.get() == null) {
5336                     U u;
5337                     Node&lt;K,V&gt; p;
5338                     if ((p = advance()) == null) {
5339                         propagateCompletion();
5340                         break;
5341                     }
5342                     if ((u = searchFunction.apply(p)) != null) {
5343                         if (result.compareAndSet(null, u))
5344                             quietlyCompleteRoot();
5345                         return;
5346                     }
5347                 }
5348             }
5349         }
5350     }
5351 
5352     @SuppressWarnings(&quot;serial&quot;)
5353     static final class SearchMappingsTask&lt;K,V,U&gt;
5354         extends BulkTask&lt;K,V,U&gt; {
5355         final BiFunction&lt;? super K, ? super V, ? extends U&gt; searchFunction;
5356         final AtomicReference&lt;U&gt; result;
5357         SearchMappingsTask
5358             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5359              BiFunction&lt;? super K, ? super V, ? extends U&gt; searchFunction,
5360              AtomicReference&lt;U&gt; result) {
5361             super(p, b, i, f, t);
5362             this.searchFunction = searchFunction; this.result = result;
5363         }
5364         public final U getRawResult() { return result.get(); }
5365         public final void compute() {
5366             final BiFunction&lt;? super K, ? super V, ? extends U&gt; searchFunction;
5367             final AtomicReference&lt;U&gt; result;
5368             if ((searchFunction = this.searchFunction) != null &amp;&amp;
5369                 (result = this.result) != null) {
5370                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5371                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5372                     if (result.get() != null)
5373                         return;
5374                     addToPendingCount(1);
5375                     new SearchMappingsTask&lt;K,V,U&gt;
5376                         (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5377                          searchFunction, result).fork();
5378                 }
5379                 while (result.get() == null) {
5380                     U u;
5381                     Node&lt;K,V&gt; p;
5382                     if ((p = advance()) == null) {
5383                         propagateCompletion();
5384                         break;
5385                     }
5386                     if ((u = searchFunction.apply(p.key, p.val)) != null) {
5387                         if (result.compareAndSet(null, u))
5388                             quietlyCompleteRoot();
5389                         break;
5390                     }
5391                 }
5392             }
5393         }
5394     }
5395 
5396     @SuppressWarnings(&quot;serial&quot;)
5397     static final class ReduceKeysTask&lt;K,V&gt;
5398         extends BulkTask&lt;K,V,K&gt; {
5399         final BiFunction&lt;? super K, ? super K, ? extends K&gt; reducer;
5400         K result;
5401         ReduceKeysTask&lt;K,V&gt; rights, nextRight;
5402         ReduceKeysTask
5403             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5404              ReduceKeysTask&lt;K,V&gt; nextRight,
5405              BiFunction&lt;? super K, ? super K, ? extends K&gt; reducer) {
5406             super(p, b, i, f, t); this.nextRight = nextRight;
5407             this.reducer = reducer;
5408         }
5409         public final K getRawResult() { return result; }
5410         public final void compute() {
5411             final BiFunction&lt;? super K, ? super K, ? extends K&gt; reducer;
5412             if ((reducer = this.reducer) != null) {
5413                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5414                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5415                     addToPendingCount(1);
5416                     (rights = new ReduceKeysTask&lt;K,V&gt;
5417                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5418                       rights, reducer)).fork();
5419                 }
5420                 K r = null;
5421                 for (Node&lt;K,V&gt; p; (p = advance()) != null; ) {
5422                     K u = p.key;
5423                     r = (r == null) ? u : u == null ? r : reducer.apply(r, u);
5424                 }
5425                 result = r;
5426                 CountedCompleter&lt;?&gt; c;
5427                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
5428                     @SuppressWarnings(&quot;unchecked&quot;)
5429                     ReduceKeysTask&lt;K,V&gt;
5430                         t = (ReduceKeysTask&lt;K,V&gt;)c,
5431                         s = t.rights;
5432                     while (s != null) {
5433                         K tr, sr;
5434                         if ((sr = s.result) != null)
5435                             t.result = (((tr = t.result) == null) ? sr :
5436                                         reducer.apply(tr, sr));
5437                         s = t.rights = s.nextRight;
5438                     }
5439                 }
5440             }
5441         }
5442     }
5443 
5444     @SuppressWarnings(&quot;serial&quot;)
5445     static final class ReduceValuesTask&lt;K,V&gt;
5446         extends BulkTask&lt;K,V,V&gt; {
5447         final BiFunction&lt;? super V, ? super V, ? extends V&gt; reducer;
5448         V result;
5449         ReduceValuesTask&lt;K,V&gt; rights, nextRight;
5450         ReduceValuesTask
5451             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5452              ReduceValuesTask&lt;K,V&gt; nextRight,
5453              BiFunction&lt;? super V, ? super V, ? extends V&gt; reducer) {
5454             super(p, b, i, f, t); this.nextRight = nextRight;
5455             this.reducer = reducer;
5456         }
5457         public final V getRawResult() { return result; }
5458         public final void compute() {
5459             final BiFunction&lt;? super V, ? super V, ? extends V&gt; reducer;
5460             if ((reducer = this.reducer) != null) {
5461                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5462                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5463                     addToPendingCount(1);
5464                     (rights = new ReduceValuesTask&lt;K,V&gt;
5465                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5466                       rights, reducer)).fork();
5467                 }
5468                 V r = null;
5469                 for (Node&lt;K,V&gt; p; (p = advance()) != null; ) {
5470                     V v = p.val;
5471                     r = (r == null) ? v : reducer.apply(r, v);
5472                 }
5473                 result = r;
5474                 CountedCompleter&lt;?&gt; c;
5475                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
5476                     @SuppressWarnings(&quot;unchecked&quot;)
5477                     ReduceValuesTask&lt;K,V&gt;
5478                         t = (ReduceValuesTask&lt;K,V&gt;)c,
5479                         s = t.rights;
5480                     while (s != null) {
5481                         V tr, sr;
5482                         if ((sr = s.result) != null)
5483                             t.result = (((tr = t.result) == null) ? sr :
5484                                         reducer.apply(tr, sr));
5485                         s = t.rights = s.nextRight;
5486                     }
5487                 }
5488             }
5489         }
5490     }
5491 
5492     @SuppressWarnings(&quot;serial&quot;)
5493     static final class ReduceEntriesTask&lt;K,V&gt;
5494         extends BulkTask&lt;K,V,Map.Entry&lt;K,V&gt;&gt; {
5495         final BiFunction&lt;Map.Entry&lt;K,V&gt;, Map.Entry&lt;K,V&gt;, ? extends Map.Entry&lt;K,V&gt;&gt; reducer;
5496         Map.Entry&lt;K,V&gt; result;
5497         ReduceEntriesTask&lt;K,V&gt; rights, nextRight;
5498         ReduceEntriesTask
5499             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5500              ReduceEntriesTask&lt;K,V&gt; nextRight,
5501              BiFunction&lt;Entry&lt;K,V&gt;, Map.Entry&lt;K,V&gt;, ? extends Map.Entry&lt;K,V&gt;&gt; reducer) {
5502             super(p, b, i, f, t); this.nextRight = nextRight;
5503             this.reducer = reducer;
5504         }
5505         public final Map.Entry&lt;K,V&gt; getRawResult() { return result; }
5506         public final void compute() {
5507             final BiFunction&lt;Map.Entry&lt;K,V&gt;, Map.Entry&lt;K,V&gt;, ? extends Map.Entry&lt;K,V&gt;&gt; reducer;
5508             if ((reducer = this.reducer) != null) {
5509                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5510                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5511                     addToPendingCount(1);
5512                     (rights = new ReduceEntriesTask&lt;K,V&gt;
5513                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5514                       rights, reducer)).fork();
5515                 }
5516                 Map.Entry&lt;K,V&gt; r = null;
5517                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
5518                     r = (r == null) ? p : reducer.apply(r, p);
5519                 result = r;
5520                 CountedCompleter&lt;?&gt; c;
5521                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
5522                     @SuppressWarnings(&quot;unchecked&quot;)
5523                     ReduceEntriesTask&lt;K,V&gt;
5524                         t = (ReduceEntriesTask&lt;K,V&gt;)c,
5525                         s = t.rights;
5526                     while (s != null) {
5527                         Map.Entry&lt;K,V&gt; tr, sr;
5528                         if ((sr = s.result) != null)
5529                             t.result = (((tr = t.result) == null) ? sr :
5530                                         reducer.apply(tr, sr));
5531                         s = t.rights = s.nextRight;
5532                     }
5533                 }
5534             }
5535         }
5536     }
5537 
5538     @SuppressWarnings(&quot;serial&quot;)
5539     static final class MapReduceKeysTask&lt;K,V,U&gt;
5540         extends BulkTask&lt;K,V,U&gt; {
5541         final Function&lt;? super K, ? extends U&gt; transformer;
5542         final BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer;
5543         U result;
5544         MapReduceKeysTask&lt;K,V,U&gt; rights, nextRight;
5545         MapReduceKeysTask
5546             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5547              MapReduceKeysTask&lt;K,V,U&gt; nextRight,
5548              Function&lt;? super K, ? extends U&gt; transformer,
5549              BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer) {
5550             super(p, b, i, f, t); this.nextRight = nextRight;
5551             this.transformer = transformer;
5552             this.reducer = reducer;
5553         }
5554         public final U getRawResult() { return result; }
5555         public final void compute() {
5556             final Function&lt;? super K, ? extends U&gt; transformer;
5557             final BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer;
5558             if ((transformer = this.transformer) != null &amp;&amp;
5559                 (reducer = this.reducer) != null) {
5560                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5561                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5562                     addToPendingCount(1);
5563                     (rights = new MapReduceKeysTask&lt;K,V,U&gt;
5564                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5565                       rights, transformer, reducer)).fork();
5566                 }
5567                 U r = null;
5568                 for (Node&lt;K,V&gt; p; (p = advance()) != null; ) {
5569                     U u;
5570                     if ((u = transformer.apply(p.key)) != null)
5571                         r = (r == null) ? u : reducer.apply(r, u);
5572                 }
5573                 result = r;
5574                 CountedCompleter&lt;?&gt; c;
5575                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
5576                     @SuppressWarnings(&quot;unchecked&quot;)
5577                     MapReduceKeysTask&lt;K,V,U&gt;
5578                         t = (MapReduceKeysTask&lt;K,V,U&gt;)c,
5579                         s = t.rights;
5580                     while (s != null) {
5581                         U tr, sr;
5582                         if ((sr = s.result) != null)
5583                             t.result = (((tr = t.result) == null) ? sr :
5584                                         reducer.apply(tr, sr));
5585                         s = t.rights = s.nextRight;
5586                     }
5587                 }
5588             }
5589         }
5590     }
5591 
5592     @SuppressWarnings(&quot;serial&quot;)
5593     static final class MapReduceValuesTask&lt;K,V,U&gt;
5594         extends BulkTask&lt;K,V,U&gt; {
5595         final Function&lt;? super V, ? extends U&gt; transformer;
5596         final BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer;
5597         U result;
5598         MapReduceValuesTask&lt;K,V,U&gt; rights, nextRight;
5599         MapReduceValuesTask
5600             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5601              MapReduceValuesTask&lt;K,V,U&gt; nextRight,
5602              Function&lt;? super V, ? extends U&gt; transformer,
5603              BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer) {
5604             super(p, b, i, f, t); this.nextRight = nextRight;
5605             this.transformer = transformer;
5606             this.reducer = reducer;
5607         }
5608         public final U getRawResult() { return result; }
5609         public final void compute() {
5610             final Function&lt;? super V, ? extends U&gt; transformer;
5611             final BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer;
5612             if ((transformer = this.transformer) != null &amp;&amp;
5613                 (reducer = this.reducer) != null) {
5614                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5615                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5616                     addToPendingCount(1);
5617                     (rights = new MapReduceValuesTask&lt;K,V,U&gt;
5618                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5619                       rights, transformer, reducer)).fork();
5620                 }
5621                 U r = null;
5622                 for (Node&lt;K,V&gt; p; (p = advance()) != null; ) {
5623                     U u;
5624                     if ((u = transformer.apply(p.val)) != null)
5625                         r = (r == null) ? u : reducer.apply(r, u);
5626                 }
5627                 result = r;
5628                 CountedCompleter&lt;?&gt; c;
5629                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
5630                     @SuppressWarnings(&quot;unchecked&quot;)
5631                     MapReduceValuesTask&lt;K,V,U&gt;
5632                         t = (MapReduceValuesTask&lt;K,V,U&gt;)c,
5633                         s = t.rights;
5634                     while (s != null) {
5635                         U tr, sr;
5636                         if ((sr = s.result) != null)
5637                             t.result = (((tr = t.result) == null) ? sr :
5638                                         reducer.apply(tr, sr));
5639                         s = t.rights = s.nextRight;
5640                     }
5641                 }
5642             }
5643         }
5644     }
5645 
5646     @SuppressWarnings(&quot;serial&quot;)
5647     static final class MapReduceEntriesTask&lt;K,V,U&gt;
5648         extends BulkTask&lt;K,V,U&gt; {
5649         final Function&lt;Map.Entry&lt;K,V&gt;, ? extends U&gt; transformer;
5650         final BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer;
5651         U result;
5652         MapReduceEntriesTask&lt;K,V,U&gt; rights, nextRight;
5653         MapReduceEntriesTask
5654             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5655              MapReduceEntriesTask&lt;K,V,U&gt; nextRight,
5656              Function&lt;Map.Entry&lt;K,V&gt;, ? extends U&gt; transformer,
5657              BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer) {
5658             super(p, b, i, f, t); this.nextRight = nextRight;
5659             this.transformer = transformer;
5660             this.reducer = reducer;
5661         }
5662         public final U getRawResult() { return result; }
5663         public final void compute() {
5664             final Function&lt;Map.Entry&lt;K,V&gt;, ? extends U&gt; transformer;
5665             final BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer;
5666             if ((transformer = this.transformer) != null &amp;&amp;
5667                 (reducer = this.reducer) != null) {
5668                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5669                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5670                     addToPendingCount(1);
5671                     (rights = new MapReduceEntriesTask&lt;K,V,U&gt;
5672                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5673                       rights, transformer, reducer)).fork();
5674                 }
5675                 U r = null;
5676                 for (Node&lt;K,V&gt; p; (p = advance()) != null; ) {
5677                     U u;
5678                     if ((u = transformer.apply(p)) != null)
5679                         r = (r == null) ? u : reducer.apply(r, u);
5680                 }
5681                 result = r;
5682                 CountedCompleter&lt;?&gt; c;
5683                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
5684                     @SuppressWarnings(&quot;unchecked&quot;)
5685                     MapReduceEntriesTask&lt;K,V,U&gt;
5686                         t = (MapReduceEntriesTask&lt;K,V,U&gt;)c,
5687                         s = t.rights;
5688                     while (s != null) {
5689                         U tr, sr;
5690                         if ((sr = s.result) != null)
5691                             t.result = (((tr = t.result) == null) ? sr :
5692                                         reducer.apply(tr, sr));
5693                         s = t.rights = s.nextRight;
5694                     }
5695                 }
5696             }
5697         }
5698     }
5699 
5700     @SuppressWarnings(&quot;serial&quot;)
5701     static final class MapReduceMappingsTask&lt;K,V,U&gt;
5702         extends BulkTask&lt;K,V,U&gt; {
5703         final BiFunction&lt;? super K, ? super V, ? extends U&gt; transformer;
5704         final BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer;
5705         U result;
5706         MapReduceMappingsTask&lt;K,V,U&gt; rights, nextRight;
5707         MapReduceMappingsTask
5708             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5709              MapReduceMappingsTask&lt;K,V,U&gt; nextRight,
5710              BiFunction&lt;? super K, ? super V, ? extends U&gt; transformer,
5711              BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer) {
5712             super(p, b, i, f, t); this.nextRight = nextRight;
5713             this.transformer = transformer;
5714             this.reducer = reducer;
5715         }
5716         public final U getRawResult() { return result; }
5717         public final void compute() {
5718             final BiFunction&lt;? super K, ? super V, ? extends U&gt; transformer;
5719             final BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer;
5720             if ((transformer = this.transformer) != null &amp;&amp;
5721                 (reducer = this.reducer) != null) {
5722                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5723                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5724                     addToPendingCount(1);
5725                     (rights = new MapReduceMappingsTask&lt;K,V,U&gt;
5726                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5727                       rights, transformer, reducer)).fork();
5728                 }
5729                 U r = null;
5730                 for (Node&lt;K,V&gt; p; (p = advance()) != null; ) {
5731                     U u;
5732                     if ((u = transformer.apply(p.key, p.val)) != null)
5733                         r = (r == null) ? u : reducer.apply(r, u);
5734                 }
5735                 result = r;
5736                 CountedCompleter&lt;?&gt; c;
5737                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
5738                     @SuppressWarnings(&quot;unchecked&quot;)
5739                     MapReduceMappingsTask&lt;K,V,U&gt;
5740                         t = (MapReduceMappingsTask&lt;K,V,U&gt;)c,
5741                         s = t.rights;
5742                     while (s != null) {
5743                         U tr, sr;
5744                         if ((sr = s.result) != null)
5745                             t.result = (((tr = t.result) == null) ? sr :
5746                                         reducer.apply(tr, sr));
5747                         s = t.rights = s.nextRight;
5748                     }
5749                 }
5750             }
5751         }
5752     }
5753 
5754     @SuppressWarnings(&quot;serial&quot;)
5755     static final class MapReduceKeysToDoubleTask&lt;K,V&gt;
5756         extends BulkTask&lt;K,V,Double&gt; {
5757         final ToDoubleFunction&lt;? super K&gt; transformer;
5758         final DoubleBinaryOperator reducer;
5759         final double basis;
5760         double result;
5761         MapReduceKeysToDoubleTask&lt;K,V&gt; rights, nextRight;
5762         MapReduceKeysToDoubleTask
5763             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5764              MapReduceKeysToDoubleTask&lt;K,V&gt; nextRight,
5765              ToDoubleFunction&lt;? super K&gt; transformer,
5766              double basis,
5767              DoubleBinaryOperator reducer) {
5768             super(p, b, i, f, t); this.nextRight = nextRight;
5769             this.transformer = transformer;
5770             this.basis = basis; this.reducer = reducer;
5771         }
5772         public final Double getRawResult() { return result; }
5773         public final void compute() {
5774             final ToDoubleFunction&lt;? super K&gt; transformer;
5775             final DoubleBinaryOperator reducer;
5776             if ((transformer = this.transformer) != null &amp;&amp;
5777                 (reducer = this.reducer) != null) {
5778                 double r = this.basis;
5779                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5780                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5781                     addToPendingCount(1);
5782                     (rights = new MapReduceKeysToDoubleTask&lt;K,V&gt;
5783                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5784                       rights, transformer, r, reducer)).fork();
5785                 }
5786                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
5787                     r = reducer.applyAsDouble(r, transformer.applyAsDouble(p.key));
5788                 result = r;
5789                 CountedCompleter&lt;?&gt; c;
5790                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
5791                     @SuppressWarnings(&quot;unchecked&quot;)
5792                     MapReduceKeysToDoubleTask&lt;K,V&gt;
5793                         t = (MapReduceKeysToDoubleTask&lt;K,V&gt;)c,
5794                         s = t.rights;
5795                     while (s != null) {
5796                         t.result = reducer.applyAsDouble(t.result, s.result);
5797                         s = t.rights = s.nextRight;
5798                     }
5799                 }
5800             }
5801         }
5802     }
5803 
5804     @SuppressWarnings(&quot;serial&quot;)
5805     static final class MapReduceValuesToDoubleTask&lt;K,V&gt;
5806         extends BulkTask&lt;K,V,Double&gt; {
5807         final ToDoubleFunction&lt;? super V&gt; transformer;
5808         final DoubleBinaryOperator reducer;
5809         final double basis;
5810         double result;
5811         MapReduceValuesToDoubleTask&lt;K,V&gt; rights, nextRight;
5812         MapReduceValuesToDoubleTask
5813             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5814              MapReduceValuesToDoubleTask&lt;K,V&gt; nextRight,
5815              ToDoubleFunction&lt;? super V&gt; transformer,
5816              double basis,
5817              DoubleBinaryOperator reducer) {
5818             super(p, b, i, f, t); this.nextRight = nextRight;
5819             this.transformer = transformer;
5820             this.basis = basis; this.reducer = reducer;
5821         }
5822         public final Double getRawResult() { return result; }
5823         public final void compute() {
5824             final ToDoubleFunction&lt;? super V&gt; transformer;
5825             final DoubleBinaryOperator reducer;
5826             if ((transformer = this.transformer) != null &amp;&amp;
5827                 (reducer = this.reducer) != null) {
5828                 double r = this.basis;
5829                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5830                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5831                     addToPendingCount(1);
5832                     (rights = new MapReduceValuesToDoubleTask&lt;K,V&gt;
5833                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5834                       rights, transformer, r, reducer)).fork();
5835                 }
5836                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
5837                     r = reducer.applyAsDouble(r, transformer.applyAsDouble(p.val));
5838                 result = r;
5839                 CountedCompleter&lt;?&gt; c;
5840                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
5841                     @SuppressWarnings(&quot;unchecked&quot;)
5842                     MapReduceValuesToDoubleTask&lt;K,V&gt;
5843                         t = (MapReduceValuesToDoubleTask&lt;K,V&gt;)c,
5844                         s = t.rights;
5845                     while (s != null) {
5846                         t.result = reducer.applyAsDouble(t.result, s.result);
5847                         s = t.rights = s.nextRight;
5848                     }
5849                 }
5850             }
5851         }
5852     }
5853 
5854     @SuppressWarnings(&quot;serial&quot;)
5855     static final class MapReduceEntriesToDoubleTask&lt;K,V&gt;
5856         extends BulkTask&lt;K,V,Double&gt; {
5857         final ToDoubleFunction&lt;Map.Entry&lt;K,V&gt;&gt; transformer;
5858         final DoubleBinaryOperator reducer;
5859         final double basis;
5860         double result;
5861         MapReduceEntriesToDoubleTask&lt;K,V&gt; rights, nextRight;
5862         MapReduceEntriesToDoubleTask
5863             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5864              MapReduceEntriesToDoubleTask&lt;K,V&gt; nextRight,
5865              ToDoubleFunction&lt;Map.Entry&lt;K,V&gt;&gt; transformer,
5866              double basis,
5867              DoubleBinaryOperator reducer) {
5868             super(p, b, i, f, t); this.nextRight = nextRight;
5869             this.transformer = transformer;
5870             this.basis = basis; this.reducer = reducer;
5871         }
5872         public final Double getRawResult() { return result; }
5873         public final void compute() {
5874             final ToDoubleFunction&lt;Map.Entry&lt;K,V&gt;&gt; transformer;
5875             final DoubleBinaryOperator reducer;
5876             if ((transformer = this.transformer) != null &amp;&amp;
5877                 (reducer = this.reducer) != null) {
5878                 double r = this.basis;
5879                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5880                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5881                     addToPendingCount(1);
5882                     (rights = new MapReduceEntriesToDoubleTask&lt;K,V&gt;
5883                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5884                       rights, transformer, r, reducer)).fork();
5885                 }
5886                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
5887                     r = reducer.applyAsDouble(r, transformer.applyAsDouble(p));
5888                 result = r;
5889                 CountedCompleter&lt;?&gt; c;
5890                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
5891                     @SuppressWarnings(&quot;unchecked&quot;)
5892                     MapReduceEntriesToDoubleTask&lt;K,V&gt;
5893                         t = (MapReduceEntriesToDoubleTask&lt;K,V&gt;)c,
5894                         s = t.rights;
5895                     while (s != null) {
5896                         t.result = reducer.applyAsDouble(t.result, s.result);
5897                         s = t.rights = s.nextRight;
5898                     }
5899                 }
5900             }
5901         }
5902     }
5903 
5904     @SuppressWarnings(&quot;serial&quot;)
5905     static final class MapReduceMappingsToDoubleTask&lt;K,V&gt;
5906         extends BulkTask&lt;K,V,Double&gt; {
5907         final ToDoubleBiFunction&lt;? super K, ? super V&gt; transformer;
5908         final DoubleBinaryOperator reducer;
5909         final double basis;
5910         double result;
5911         MapReduceMappingsToDoubleTask&lt;K,V&gt; rights, nextRight;
5912         MapReduceMappingsToDoubleTask
5913             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5914              MapReduceMappingsToDoubleTask&lt;K,V&gt; nextRight,
5915              ToDoubleBiFunction&lt;? super K, ? super V&gt; transformer,
5916              double basis,
5917              DoubleBinaryOperator reducer) {
5918             super(p, b, i, f, t); this.nextRight = nextRight;
5919             this.transformer = transformer;
5920             this.basis = basis; this.reducer = reducer;
5921         }
5922         public final Double getRawResult() { return result; }
5923         public final void compute() {
5924             final ToDoubleBiFunction&lt;? super K, ? super V&gt; transformer;
5925             final DoubleBinaryOperator reducer;
5926             if ((transformer = this.transformer) != null &amp;&amp;
5927                 (reducer = this.reducer) != null) {
5928                 double r = this.basis;
5929                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5930                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5931                     addToPendingCount(1);
5932                     (rights = new MapReduceMappingsToDoubleTask&lt;K,V&gt;
5933                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5934                       rights, transformer, r, reducer)).fork();
5935                 }
5936                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
5937                     r = reducer.applyAsDouble(r, transformer.applyAsDouble(p.key, p.val));
5938                 result = r;
5939                 CountedCompleter&lt;?&gt; c;
5940                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
5941                     @SuppressWarnings(&quot;unchecked&quot;)
5942                     MapReduceMappingsToDoubleTask&lt;K,V&gt;
5943                         t = (MapReduceMappingsToDoubleTask&lt;K,V&gt;)c,
5944                         s = t.rights;
5945                     while (s != null) {
5946                         t.result = reducer.applyAsDouble(t.result, s.result);
5947                         s = t.rights = s.nextRight;
5948                     }
5949                 }
5950             }
5951         }
5952     }
5953 
5954     @SuppressWarnings(&quot;serial&quot;)
5955     static final class MapReduceKeysToLongTask&lt;K,V&gt;
5956         extends BulkTask&lt;K,V,Long&gt; {
5957         final ToLongFunction&lt;? super K&gt; transformer;
5958         final LongBinaryOperator reducer;
5959         final long basis;
5960         long result;
5961         MapReduceKeysToLongTask&lt;K,V&gt; rights, nextRight;
5962         MapReduceKeysToLongTask
5963             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
5964              MapReduceKeysToLongTask&lt;K,V&gt; nextRight,
5965              ToLongFunction&lt;? super K&gt; transformer,
5966              long basis,
5967              LongBinaryOperator reducer) {
5968             super(p, b, i, f, t); this.nextRight = nextRight;
5969             this.transformer = transformer;
5970             this.basis = basis; this.reducer = reducer;
5971         }
5972         public final Long getRawResult() { return result; }
5973         public final void compute() {
5974             final ToLongFunction&lt;? super K&gt; transformer;
5975             final LongBinaryOperator reducer;
5976             if ((transformer = this.transformer) != null &amp;&amp;
5977                 (reducer = this.reducer) != null) {
5978                 long r = this.basis;
5979                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
5980                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
5981                     addToPendingCount(1);
5982                     (rights = new MapReduceKeysToLongTask&lt;K,V&gt;
5983                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
5984                       rights, transformer, r, reducer)).fork();
5985                 }
5986                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
5987                     r = reducer.applyAsLong(r, transformer.applyAsLong(p.key));
5988                 result = r;
5989                 CountedCompleter&lt;?&gt; c;
5990                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
5991                     @SuppressWarnings(&quot;unchecked&quot;)
5992                     MapReduceKeysToLongTask&lt;K,V&gt;
5993                         t = (MapReduceKeysToLongTask&lt;K,V&gt;)c,
5994                         s = t.rights;
5995                     while (s != null) {
5996                         t.result = reducer.applyAsLong(t.result, s.result);
5997                         s = t.rights = s.nextRight;
5998                     }
5999                 }
6000             }
6001         }
6002     }
6003 
6004     @SuppressWarnings(&quot;serial&quot;)
6005     static final class MapReduceValuesToLongTask&lt;K,V&gt;
6006         extends BulkTask&lt;K,V,Long&gt; {
6007         final ToLongFunction&lt;? super V&gt; transformer;
6008         final LongBinaryOperator reducer;
6009         final long basis;
6010         long result;
6011         MapReduceValuesToLongTask&lt;K,V&gt; rights, nextRight;
6012         MapReduceValuesToLongTask
6013             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
6014              MapReduceValuesToLongTask&lt;K,V&gt; nextRight,
6015              ToLongFunction&lt;? super V&gt; transformer,
6016              long basis,
6017              LongBinaryOperator reducer) {
6018             super(p, b, i, f, t); this.nextRight = nextRight;
6019             this.transformer = transformer;
6020             this.basis = basis; this.reducer = reducer;
6021         }
6022         public final Long getRawResult() { return result; }
6023         public final void compute() {
6024             final ToLongFunction&lt;? super V&gt; transformer;
6025             final LongBinaryOperator reducer;
6026             if ((transformer = this.transformer) != null &amp;&amp;
6027                 (reducer = this.reducer) != null) {
6028                 long r = this.basis;
6029                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
6030                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
6031                     addToPendingCount(1);
6032                     (rights = new MapReduceValuesToLongTask&lt;K,V&gt;
6033                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
6034                       rights, transformer, r, reducer)).fork();
6035                 }
6036                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
6037                     r = reducer.applyAsLong(r, transformer.applyAsLong(p.val));
6038                 result = r;
6039                 CountedCompleter&lt;?&gt; c;
6040                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
6041                     @SuppressWarnings(&quot;unchecked&quot;)
6042                     MapReduceValuesToLongTask&lt;K,V&gt;
6043                         t = (MapReduceValuesToLongTask&lt;K,V&gt;)c,
6044                         s = t.rights;
6045                     while (s != null) {
6046                         t.result = reducer.applyAsLong(t.result, s.result);
6047                         s = t.rights = s.nextRight;
6048                     }
6049                 }
6050             }
6051         }
6052     }
6053 
6054     @SuppressWarnings(&quot;serial&quot;)
6055     static final class MapReduceEntriesToLongTask&lt;K,V&gt;
6056         extends BulkTask&lt;K,V,Long&gt; {
6057         final ToLongFunction&lt;Map.Entry&lt;K,V&gt;&gt; transformer;
6058         final LongBinaryOperator reducer;
6059         final long basis;
6060         long result;
6061         MapReduceEntriesToLongTask&lt;K,V&gt; rights, nextRight;
6062         MapReduceEntriesToLongTask
6063             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
6064              MapReduceEntriesToLongTask&lt;K,V&gt; nextRight,
6065              ToLongFunction&lt;Map.Entry&lt;K,V&gt;&gt; transformer,
6066              long basis,
6067              LongBinaryOperator reducer) {
6068             super(p, b, i, f, t); this.nextRight = nextRight;
6069             this.transformer = transformer;
6070             this.basis = basis; this.reducer = reducer;
6071         }
6072         public final Long getRawResult() { return result; }
6073         public final void compute() {
6074             final ToLongFunction&lt;Map.Entry&lt;K,V&gt;&gt; transformer;
6075             final LongBinaryOperator reducer;
6076             if ((transformer = this.transformer) != null &amp;&amp;
6077                 (reducer = this.reducer) != null) {
6078                 long r = this.basis;
6079                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
6080                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
6081                     addToPendingCount(1);
6082                     (rights = new MapReduceEntriesToLongTask&lt;K,V&gt;
6083                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
6084                       rights, transformer, r, reducer)).fork();
6085                 }
6086                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
6087                     r = reducer.applyAsLong(r, transformer.applyAsLong(p));
6088                 result = r;
6089                 CountedCompleter&lt;?&gt; c;
6090                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
6091                     @SuppressWarnings(&quot;unchecked&quot;)
6092                     MapReduceEntriesToLongTask&lt;K,V&gt;
6093                         t = (MapReduceEntriesToLongTask&lt;K,V&gt;)c,
6094                         s = t.rights;
6095                     while (s != null) {
6096                         t.result = reducer.applyAsLong(t.result, s.result);
6097                         s = t.rights = s.nextRight;
6098                     }
6099                 }
6100             }
6101         }
6102     }
6103 
6104     @SuppressWarnings(&quot;serial&quot;)
6105     static final class MapReduceMappingsToLongTask&lt;K,V&gt;
6106         extends BulkTask&lt;K,V,Long&gt; {
6107         final ToLongBiFunction&lt;? super K, ? super V&gt; transformer;
6108         final LongBinaryOperator reducer;
6109         final long basis;
6110         long result;
6111         MapReduceMappingsToLongTask&lt;K,V&gt; rights, nextRight;
6112         MapReduceMappingsToLongTask
6113             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
6114              MapReduceMappingsToLongTask&lt;K,V&gt; nextRight,
6115              ToLongBiFunction&lt;? super K, ? super V&gt; transformer,
6116              long basis,
6117              LongBinaryOperator reducer) {
6118             super(p, b, i, f, t); this.nextRight = nextRight;
6119             this.transformer = transformer;
6120             this.basis = basis; this.reducer = reducer;
6121         }
6122         public final Long getRawResult() { return result; }
6123         public final void compute() {
6124             final ToLongBiFunction&lt;? super K, ? super V&gt; transformer;
6125             final LongBinaryOperator reducer;
6126             if ((transformer = this.transformer) != null &amp;&amp;
6127                 (reducer = this.reducer) != null) {
6128                 long r = this.basis;
6129                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
6130                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
6131                     addToPendingCount(1);
6132                     (rights = new MapReduceMappingsToLongTask&lt;K,V&gt;
6133                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
6134                       rights, transformer, r, reducer)).fork();
6135                 }
6136                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
6137                     r = reducer.applyAsLong(r, transformer.applyAsLong(p.key, p.val));
6138                 result = r;
6139                 CountedCompleter&lt;?&gt; c;
6140                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
6141                     @SuppressWarnings(&quot;unchecked&quot;)
6142                     MapReduceMappingsToLongTask&lt;K,V&gt;
6143                         t = (MapReduceMappingsToLongTask&lt;K,V&gt;)c,
6144                         s = t.rights;
6145                     while (s != null) {
6146                         t.result = reducer.applyAsLong(t.result, s.result);
6147                         s = t.rights = s.nextRight;
6148                     }
6149                 }
6150             }
6151         }
6152     }
6153 
6154     @SuppressWarnings(&quot;serial&quot;)
6155     static final class MapReduceKeysToIntTask&lt;K,V&gt;
6156         extends BulkTask&lt;K,V,Integer&gt; {
6157         final ToIntFunction&lt;? super K&gt; transformer;
6158         final IntBinaryOperator reducer;
6159         final int basis;
6160         int result;
6161         MapReduceKeysToIntTask&lt;K,V&gt; rights, nextRight;
6162         MapReduceKeysToIntTask
6163             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
6164              MapReduceKeysToIntTask&lt;K,V&gt; nextRight,
6165              ToIntFunction&lt;? super K&gt; transformer,
6166              int basis,
6167              IntBinaryOperator reducer) {
6168             super(p, b, i, f, t); this.nextRight = nextRight;
6169             this.transformer = transformer;
6170             this.basis = basis; this.reducer = reducer;
6171         }
6172         public final Integer getRawResult() { return result; }
6173         public final void compute() {
6174             final ToIntFunction&lt;? super K&gt; transformer;
6175             final IntBinaryOperator reducer;
6176             if ((transformer = this.transformer) != null &amp;&amp;
6177                 (reducer = this.reducer) != null) {
6178                 int r = this.basis;
6179                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
6180                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
6181                     addToPendingCount(1);
6182                     (rights = new MapReduceKeysToIntTask&lt;K,V&gt;
6183                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
6184                       rights, transformer, r, reducer)).fork();
6185                 }
6186                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
6187                     r = reducer.applyAsInt(r, transformer.applyAsInt(p.key));
6188                 result = r;
6189                 CountedCompleter&lt;?&gt; c;
6190                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
6191                     @SuppressWarnings(&quot;unchecked&quot;)
6192                     MapReduceKeysToIntTask&lt;K,V&gt;
6193                         t = (MapReduceKeysToIntTask&lt;K,V&gt;)c,
6194                         s = t.rights;
6195                     while (s != null) {
6196                         t.result = reducer.applyAsInt(t.result, s.result);
6197                         s = t.rights = s.nextRight;
6198                     }
6199                 }
6200             }
6201         }
6202     }
6203 
6204     @SuppressWarnings(&quot;serial&quot;)
6205     static final class MapReduceValuesToIntTask&lt;K,V&gt;
6206         extends BulkTask&lt;K,V,Integer&gt; {
6207         final ToIntFunction&lt;? super V&gt; transformer;
6208         final IntBinaryOperator reducer;
6209         final int basis;
6210         int result;
6211         MapReduceValuesToIntTask&lt;K,V&gt; rights, nextRight;
6212         MapReduceValuesToIntTask
6213             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
6214              MapReduceValuesToIntTask&lt;K,V&gt; nextRight,
6215              ToIntFunction&lt;? super V&gt; transformer,
6216              int basis,
6217              IntBinaryOperator reducer) {
6218             super(p, b, i, f, t); this.nextRight = nextRight;
6219             this.transformer = transformer;
6220             this.basis = basis; this.reducer = reducer;
6221         }
6222         public final Integer getRawResult() { return result; }
6223         public final void compute() {
6224             final ToIntFunction&lt;? super V&gt; transformer;
6225             final IntBinaryOperator reducer;
6226             if ((transformer = this.transformer) != null &amp;&amp;
6227                 (reducer = this.reducer) != null) {
6228                 int r = this.basis;
6229                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
6230                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
6231                     addToPendingCount(1);
6232                     (rights = new MapReduceValuesToIntTask&lt;K,V&gt;
6233                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
6234                       rights, transformer, r, reducer)).fork();
6235                 }
6236                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
6237                     r = reducer.applyAsInt(r, transformer.applyAsInt(p.val));
6238                 result = r;
6239                 CountedCompleter&lt;?&gt; c;
6240                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
6241                     @SuppressWarnings(&quot;unchecked&quot;)
6242                     MapReduceValuesToIntTask&lt;K,V&gt;
6243                         t = (MapReduceValuesToIntTask&lt;K,V&gt;)c,
6244                         s = t.rights;
6245                     while (s != null) {
6246                         t.result = reducer.applyAsInt(t.result, s.result);
6247                         s = t.rights = s.nextRight;
6248                     }
6249                 }
6250             }
6251         }
6252     }
6253 
6254     @SuppressWarnings(&quot;serial&quot;)
6255     static final class MapReduceEntriesToIntTask&lt;K,V&gt;
6256         extends BulkTask&lt;K,V,Integer&gt; {
6257         final ToIntFunction&lt;Map.Entry&lt;K,V&gt;&gt; transformer;
6258         final IntBinaryOperator reducer;
6259         final int basis;
6260         int result;
6261         MapReduceEntriesToIntTask&lt;K,V&gt; rights, nextRight;
6262         MapReduceEntriesToIntTask
6263             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
6264              MapReduceEntriesToIntTask&lt;K,V&gt; nextRight,
6265              ToIntFunction&lt;Map.Entry&lt;K,V&gt;&gt; transformer,
6266              int basis,
6267              IntBinaryOperator reducer) {
6268             super(p, b, i, f, t); this.nextRight = nextRight;
6269             this.transformer = transformer;
6270             this.basis = basis; this.reducer = reducer;
6271         }
6272         public final Integer getRawResult() { return result; }
6273         public final void compute() {
6274             final ToIntFunction&lt;Map.Entry&lt;K,V&gt;&gt; transformer;
6275             final IntBinaryOperator reducer;
6276             if ((transformer = this.transformer) != null &amp;&amp;
6277                 (reducer = this.reducer) != null) {
6278                 int r = this.basis;
6279                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
6280                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
6281                     addToPendingCount(1);
6282                     (rights = new MapReduceEntriesToIntTask&lt;K,V&gt;
6283                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
6284                       rights, transformer, r, reducer)).fork();
6285                 }
6286                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
6287                     r = reducer.applyAsInt(r, transformer.applyAsInt(p));
6288                 result = r;
6289                 CountedCompleter&lt;?&gt; c;
6290                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
6291                     @SuppressWarnings(&quot;unchecked&quot;)
6292                     MapReduceEntriesToIntTask&lt;K,V&gt;
6293                         t = (MapReduceEntriesToIntTask&lt;K,V&gt;)c,
6294                         s = t.rights;
6295                     while (s != null) {
6296                         t.result = reducer.applyAsInt(t.result, s.result);
6297                         s = t.rights = s.nextRight;
6298                     }
6299                 }
6300             }
6301         }
6302     }
6303 
6304     @SuppressWarnings(&quot;serial&quot;)
6305     static final class MapReduceMappingsToIntTask&lt;K,V&gt;
6306         extends BulkTask&lt;K,V,Integer&gt; {
6307         final ToIntBiFunction&lt;? super K, ? super V&gt; transformer;
6308         final IntBinaryOperator reducer;
6309         final int basis;
6310         int result;
6311         MapReduceMappingsToIntTask&lt;K,V&gt; rights, nextRight;
6312         MapReduceMappingsToIntTask
6313             (BulkTask&lt;K,V,?&gt; p, int b, int i, int f, Node&lt;K,V&gt;[] t,
6314              MapReduceMappingsToIntTask&lt;K,V&gt; nextRight,
6315              ToIntBiFunction&lt;? super K, ? super V&gt; transformer,
6316              int basis,
6317              IntBinaryOperator reducer) {
6318             super(p, b, i, f, t); this.nextRight = nextRight;
6319             this.transformer = transformer;
6320             this.basis = basis; this.reducer = reducer;
6321         }
6322         public final Integer getRawResult() { return result; }
6323         public final void compute() {
6324             final ToIntBiFunction&lt;? super K, ? super V&gt; transformer;
6325             final IntBinaryOperator reducer;
6326             if ((transformer = this.transformer) != null &amp;&amp;
6327                 (reducer = this.reducer) != null) {
6328                 int r = this.basis;
6329                 for (int i = baseIndex, f, h; batch &gt; 0 &amp;&amp;
6330                          (h = ((f = baseLimit) + i) &gt;&gt;&gt; 1) &gt; i;) {
6331                     addToPendingCount(1);
6332                     (rights = new MapReduceMappingsToIntTask&lt;K,V&gt;
6333                      (this, batch &gt;&gt;&gt;= 1, baseLimit = h, f, tab,
6334                       rights, transformer, r, reducer)).fork();
6335                 }
6336                 for (Node&lt;K,V&gt; p; (p = advance()) != null; )
6337                     r = reducer.applyAsInt(r, transformer.applyAsInt(p.key, p.val));
6338                 result = r;
6339                 CountedCompleter&lt;?&gt; c;
6340                 for (c = firstComplete(); c != null; c = c.nextComplete()) {
6341                     @SuppressWarnings(&quot;unchecked&quot;)
6342                     MapReduceMappingsToIntTask&lt;K,V&gt;
6343                         t = (MapReduceMappingsToIntTask&lt;K,V&gt;)c,
6344                         s = t.rights;
6345                     while (s != null) {
6346                         t.result = reducer.applyAsInt(t.result, s.result);
6347                         s = t.rights = s.nextRight;
6348                     }
6349                 }
6350             }
6351         }
6352     }
6353 
6354     // Unsafe mechanics
6355     private static final Unsafe U = Unsafe.getUnsafe();
<a name="8" id="anc8"></a><span class="line-modified">6356     private static final long SIZECTL</span>
<span class="line-modified">6357         = U.objectFieldOffset(ConcurrentHashMap.class, &quot;sizeCtl&quot;);</span>
<span class="line-modified">6358     private static final long TRANSFERINDEX</span>
<span class="line-modified">6359         = U.objectFieldOffset(ConcurrentHashMap.class, &quot;transferIndex&quot;);</span>
<span class="line-modified">6360     private static final long BASECOUNT</span>
<span class="line-modified">6361         = U.objectFieldOffset(ConcurrentHashMap.class, &quot;baseCount&quot;);</span>
<span class="line-added">6362     private static final long CELLSBUSY</span>
<span class="line-added">6363         = U.objectFieldOffset(ConcurrentHashMap.class, &quot;cellsBusy&quot;);</span>
<span class="line-added">6364     private static final long CELLVALUE</span>
<span class="line-added">6365         = U.objectFieldOffset(CounterCell.class, &quot;value&quot;);</span>
<span class="line-added">6366     private static final int ABASE = U.arrayBaseOffset(Node[].class);</span>
6367     private static final int ASHIFT;
6368 
6369     static {
<a name="9" id="anc9"></a>












6370         int scale = U.arrayIndexScale(Node[].class);
6371         if ((scale &amp; (scale - 1)) != 0)
6372             throw new ExceptionInInitializerError(&quot;array index scale not a power of two&quot;);
6373         ASHIFT = 31 - Integer.numberOfLeadingZeros(scale);
6374 
6375         // Reduce the risk of rare disastrous classloading in first call to
6376         // LockSupport.park: https://bugs.openjdk.java.net/browse/JDK-8074773
6377         Class&lt;?&gt; ensureLoaded = LockSupport.class;
6378 
6379         // Eager class load observed to help JIT during startup
6380         ensureLoaded = ReservationNode.class;
6381     }
6382 }
<a name="10" id="anc10"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="10" type="hidden" />
</body>
</html>