<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030  bool is_CAS(int opcode, bool maybe_volatile);
 1031 
 1032   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1033 
 1034   bool unnecessary_acquire(const Node *barrier);
 1035   bool needs_acquiring_load(const Node *load);
 1036 
 1037   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1038 
 1039   bool unnecessary_release(const Node *barrier);
 1040   bool unnecessary_volatile(const Node *barrier);
 1041   bool needs_releasing_store(const Node *store);
 1042 
 1043   // predicate controlling translation of CompareAndSwapX
 1044   bool needs_acquiring_load_exclusive(const Node *load);
 1045 
 1046   // predicate controlling addressing modes
 1047   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1048 %}
 1049 
 1050 source %{
 1051 
 1052   // Derived RegMask with conditionally allocatable registers
 1053 
 1054   RegMask _ANY_REG32_mask;
 1055   RegMask _ANY_REG_mask;
 1056   RegMask _PTR_REG_mask;
 1057   RegMask _NO_SPECIAL_REG32_mask;
 1058   RegMask _NO_SPECIAL_REG_mask;
 1059   RegMask _NO_SPECIAL_PTR_REG_mask;
 1060 
 1061   void reg_mask_init() {
 1062     // We derive below RegMask(s) from the ones which are auto-generated from
 1063     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1064     // registers conditionally reserved.
 1065 
 1066     _ANY_REG32_mask = _ALL_REG32_mask;
 1067     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1068 
 1069     _ANY_REG_mask = _ALL_REG_mask;
 1070 
 1071     _PTR_REG_mask = _ALL_REG_mask;
 1072 
 1073     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1074     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1075 
 1076     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1077     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1078 
 1079     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1080     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1081 
 1082     // r27 is not allocatable when compressed oops is on, compressed klass
 1083     // pointers doesn&#39;t use r27 after JDK-8234794
 1084     if (UseCompressedOops) {
 1085       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1086       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1087       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1088     }
 1089 
 1090     // r29 is not allocatable when PreserveFramePointer is on
 1091     if (PreserveFramePointer) {
 1092       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1093       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1094       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1095     }
 1096   }
 1097 
 1098   // Optimizaton of volatile gets and puts
 1099   // -------------------------------------
 1100   //
 1101   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1102   // use to implement volatile reads and writes. For a volatile read
 1103   // we simply need
 1104   //
 1105   //   ldar&lt;x&gt;
 1106   //
 1107   // and for a volatile write we need
 1108   //
 1109   //   stlr&lt;x&gt;
 1110   //
 1111   // Alternatively, we can implement them by pairing a normal
 1112   // load/store with a memory barrier. For a volatile read we need
 1113   //
 1114   //   ldr&lt;x&gt;
 1115   //   dmb ishld
 1116   //
 1117   // for a volatile write
 1118   //
 1119   //   dmb ish
 1120   //   str&lt;x&gt;
 1121   //   dmb ish
 1122   //
 1123   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1124   // sequences. These are normally translated to an instruction
 1125   // sequence like the following
 1126   //
 1127   //   dmb      ish
 1128   // retry:
 1129   //   ldxr&lt;x&gt;   rval raddr
 1130   //   cmp       rval rold
 1131   //   b.ne done
 1132   //   stlxr&lt;x&gt;  rval, rnew, rold
 1133   //   cbnz      rval retry
 1134   // done:
 1135   //   cset      r0, eq
 1136   //   dmb ishld
 1137   //
 1138   // Note that the exclusive store is already using an stlxr
 1139   // instruction. That is required to ensure visibility to other
 1140   // threads of the exclusive write (assuming it succeeds) before that
 1141   // of any subsequent writes.
 1142   //
 1143   // The following instruction sequence is an improvement on the above
 1144   //
 1145   // retry:
 1146   //   ldaxr&lt;x&gt;  rval raddr
 1147   //   cmp       rval rold
 1148   //   b.ne done
 1149   //   stlxr&lt;x&gt;  rval, rnew, rold
 1150   //   cbnz      rval retry
 1151   // done:
 1152   //   cset      r0, eq
 1153   //
 1154   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1155   // visibility of prior writes in the case that the swap is
 1156   // successful. Crucially we don&#39;t have to worry about the case where
 1157   // the swap is not successful since no valid program should be
 1158   // relying on visibility of prior changes by the attempting thread
 1159   // in the case where the CAS fails.
 1160   //
 1161   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1162   // an ldaxr instruction since that will provide all the guarantees we
 1163   // require regarding observation of changes made by other threads
 1164   // before any change to the CAS address observed by the load.
 1165   //
 1166   // In order to generate the desired instruction sequence we need to
 1167   // be able to identify specific &#39;signature&#39; ideal graph node
 1168   // sequences which i) occur as a translation of a volatile reads or
 1169   // writes or CAS operations and ii) do not occur through any other
 1170   // translation or graph transformation. We can then provide
 1171   // alternative aldc matching rules which translate these node
 1172   // sequences to the desired machine code sequences. Selection of the
 1173   // alternative rules can be implemented by predicates which identify
 1174   // the relevant node sequences.
 1175   //
 1176   // The ideal graph generator translates a volatile read to the node
 1177   // sequence
 1178   //
 1179   //   LoadX[mo_acquire]
 1180   //   MemBarAcquire
 1181   //
 1182   // As a special case when using the compressed oops optimization we
 1183   // may also see this variant
 1184   //
 1185   //   LoadN[mo_acquire]
 1186   //   DecodeN
 1187   //   MemBarAcquire
 1188   //
 1189   // A volatile write is translated to the node sequence
 1190   //
 1191   //   MemBarRelease
 1192   //   StoreX[mo_release] {CardMark}-optional
 1193   //   MemBarVolatile
 1194   //
 1195   // n.b. the above node patterns are generated with a strict
 1196   // &#39;signature&#39; configuration of input and output dependencies (see
 1197   // the predicates below for exact details). The card mark may be as
 1198   // simple as a few extra nodes or, in a few GC configurations, may
 1199   // include more complex control flow between the leading and
 1200   // trailing memory barriers. However, whatever the card mark
 1201   // configuration these signatures are unique to translated volatile
 1202   // reads/stores -- they will not appear as a result of any other
 1203   // bytecode translation or inlining nor as a consequence of
 1204   // optimizing transforms.
 1205   //
 1206   // We also want to catch inlined unsafe volatile gets and puts and
 1207   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1208   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1209   //
 1210   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1211   // normal volatile put node sequence containing an extra cpuorder
 1212   // membar
 1213   //
 1214   //   MemBarRelease
 1215   //   MemBarCPUOrder
 1216   //   StoreX[mo_release] {CardMark}-optional
 1217   //   MemBarCPUOrder
 1218   //   MemBarVolatile
 1219   //
 1220   // n.b. as an aside, a cpuorder membar is not itself subject to
 1221   // matching and translation by adlc rules.  However, the rule
 1222   // predicates need to detect its presence in order to correctly
 1223   // select the desired adlc rules.
 1224   //
 1225   // Inlined unsafe volatile gets manifest as a slightly different
 1226   // node sequence to a normal volatile get because of the
 1227   // introduction of some CPUOrder memory barriers to bracket the
 1228   // Load. However, but the same basic skeleton of a LoadX feeding a
 1229   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1230   // present
 1231   //
 1232   //   MemBarCPUOrder
 1233   //        ||       \\
 1234   //   MemBarCPUOrder LoadX[mo_acquire]
 1235   //        ||            |
 1236   //        ||       {DecodeN} optional
 1237   //        ||       /
 1238   //     MemBarAcquire
 1239   //
 1240   // In this case the acquire membar does not directly depend on the
 1241   // load. However, we can be sure that the load is generated from an
 1242   // inlined unsafe volatile get if we see it dependent on this unique
 1243   // sequence of membar nodes. Similarly, given an acquire membar we
 1244   // can know that it was added because of an inlined unsafe volatile
 1245   // get if it is fed and feeds a cpuorder membar and if its feed
 1246   // membar also feeds an acquiring load.
 1247   //
 1248   // Finally an inlined (Unsafe) CAS operation is translated to the
 1249   // following ideal graph
 1250   //
 1251   //   MemBarRelease
 1252   //   MemBarCPUOrder
 1253   //   CompareAndSwapX {CardMark}-optional
 1254   //   MemBarCPUOrder
 1255   //   MemBarAcquire
 1256   //
 1257   // So, where we can identify these volatile read and write
 1258   // signatures we can choose to plant either of the above two code
 1259   // sequences. For a volatile read we can simply plant a normal
 1260   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1261   // also choose to inhibit translation of the MemBarAcquire and
 1262   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1263   //
 1264   // When we recognise a volatile store signature we can choose to
 1265   // plant at a dmb ish as a translation for the MemBarRelease, a
 1266   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1267   // Alternatively, we can inhibit translation of the MemBarRelease
 1268   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1269   // instruction.
 1270   //
 1271   // when we recognise a CAS signature we can choose to plant a dmb
 1272   // ish as a translation for the MemBarRelease, the conventional
 1273   // macro-instruction sequence for the CompareAndSwap node (which
 1274   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1275   // Alternatively, we can elide generation of the dmb instructions
 1276   // and plant the alternative CompareAndSwap macro-instruction
 1277   // sequence (which uses ldaxr&lt;x&gt;).
 1278   //
 1279   // Of course, the above only applies when we see these signature
 1280   // configurations. We still want to plant dmb instructions in any
 1281   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1282   // MemBarVolatile. For example, at the end of a constructor which
 1283   // writes final/volatile fields we will see a MemBarRelease
 1284   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1285   // constructed object being visible without making the
 1286   // final/volatile field writes visible.
 1287   //
 1288   // n.b. the translation rules below which rely on detection of the
 1289   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1290   // If we see anything other than the signature configurations we
 1291   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1292   // and translate acquire, release and volatile membars to the
 1293   // relevant dmb instructions.
 1294   //
 1295 
 1296   // is_CAS(int opcode, bool maybe_volatile)
 1297   //
 1298   // return true if opcode is one of the possible CompareAndSwapX
 1299   // values otherwise false.
 1300 
 1301   bool is_CAS(int opcode, bool maybe_volatile)
 1302   {
 1303     switch(opcode) {
 1304       // We handle these
 1305     case Op_CompareAndSwapI:
 1306     case Op_CompareAndSwapL:
 1307     case Op_CompareAndSwapP:
 1308     case Op_CompareAndSwapN:
 1309     case Op_ShenandoahCompareAndSwapP:
 1310     case Op_ShenandoahCompareAndSwapN:
 1311     case Op_CompareAndSwapB:
 1312     case Op_CompareAndSwapS:
 1313     case Op_GetAndSetI:
 1314     case Op_GetAndSetL:
 1315     case Op_GetAndSetP:
 1316     case Op_GetAndSetN:
 1317     case Op_GetAndAddI:
 1318     case Op_GetAndAddL:
 1319       return true;
 1320     case Op_CompareAndExchangeI:
 1321     case Op_CompareAndExchangeN:
 1322     case Op_CompareAndExchangeB:
 1323     case Op_CompareAndExchangeS:
 1324     case Op_CompareAndExchangeL:
 1325     case Op_CompareAndExchangeP:
 1326     case Op_WeakCompareAndSwapB:
 1327     case Op_WeakCompareAndSwapS:
 1328     case Op_WeakCompareAndSwapI:
 1329     case Op_WeakCompareAndSwapL:
 1330     case Op_WeakCompareAndSwapP:
 1331     case Op_WeakCompareAndSwapN:
 1332     case Op_ShenandoahWeakCompareAndSwapP:
 1333     case Op_ShenandoahWeakCompareAndSwapN:
 1334     case Op_ShenandoahCompareAndExchangeP:
 1335     case Op_ShenandoahCompareAndExchangeN:
 1336       return maybe_volatile;
 1337     default:
 1338       return false;
 1339     }
 1340   }
 1341 
 1342   // helper to determine the maximum number of Phi nodes we may need to
 1343   // traverse when searching from a card mark membar for the merge mem
 1344   // feeding a trailing membar or vice versa
 1345 
 1346 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1347 
 1348 bool unnecessary_acquire(const Node *barrier)
 1349 {
 1350   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1351 
 1352   if (UseBarriersForVolatile) {
 1353     // we need to plant a dmb
 1354     return false;
 1355   }
 1356 
 1357   MemBarNode* mb = barrier-&gt;as_MemBar();
 1358 
 1359   if (mb-&gt;trailing_load()) {
 1360     return true;
 1361   }
 1362 
 1363   if (mb-&gt;trailing_load_store()) {
 1364     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1365     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1366     return is_CAS(load_store-&gt;Opcode(), true);
 1367   }
 1368 
 1369   return false;
 1370 }
 1371 
 1372 bool needs_acquiring_load(const Node *n)
 1373 {
 1374   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1375   if (UseBarriersForVolatile) {
 1376     // we use a normal load and a dmb
 1377     return false;
 1378   }
 1379 
 1380   LoadNode *ld = n-&gt;as_Load();
 1381 
 1382   return ld-&gt;is_acquire();
 1383 }
 1384 
 1385 bool unnecessary_release(const Node *n)
 1386 {
 1387   assert((n-&gt;is_MemBar() &amp;&amp;
 1388 	  n-&gt;Opcode() == Op_MemBarRelease),
 1389 	 &quot;expecting a release membar&quot;);
 1390 
 1391   if (UseBarriersForVolatile) {
 1392     // we need to plant a dmb
 1393     return false;
 1394   }
 1395 
 1396   MemBarNode *barrier = n-&gt;as_MemBar();
 1397   if (!barrier-&gt;leading()) {
 1398     return false;
 1399   } else {
 1400     Node* trailing = barrier-&gt;trailing_membar();
 1401     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1402     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1403     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1404 
 1405     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1406     if (mem-&gt;is_Store()) {
 1407       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1408       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1409       return true;
 1410     } else {
 1411       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1412       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1413       return is_CAS(mem-&gt;Opcode(), true);
 1414     }
 1415   }
 1416   return false;
 1417 }
 1418 
 1419 bool unnecessary_volatile(const Node *n)
 1420 {
 1421   // assert n-&gt;is_MemBar();
 1422   if (UseBarriersForVolatile) {
 1423     // we need to plant a dmb
 1424     return false;
 1425   }
 1426 
 1427   MemBarNode *mbvol = n-&gt;as_MemBar();
 1428 
 1429   bool release = mbvol-&gt;trailing_store();
 1430   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1431 #ifdef ASSERT
 1432   if (release) {
 1433     Node* leading = mbvol-&gt;leading_membar();
 1434     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1435     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1436     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1437   }
 1438 #endif
 1439 
 1440   return release;
 1441 }
 1442 
 1443 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1444 
 1445 bool needs_releasing_store(const Node *n)
 1446 {
 1447   // assert n-&gt;is_Store();
 1448   if (UseBarriersForVolatile) {
 1449     // we use a normal store and dmb combination
 1450     return false;
 1451   }
 1452 
 1453   StoreNode *st = n-&gt;as_Store();
 1454 
 1455   return st-&gt;trailing_membar() != NULL;
 1456 }
 1457 
 1458 // predicate controlling translation of CAS
 1459 //
 1460 // returns true if CAS needs to use an acquiring load otherwise false
 1461 
 1462 bool needs_acquiring_load_exclusive(const Node *n)
 1463 {
 1464   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1465   if (UseBarriersForVolatile) {
 1466     return false;
 1467   }
 1468 
 1469   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1470   if (is_CAS(n-&gt;Opcode(), false)) {
 1471     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1472   } else {
 1473     return ldst-&gt;trailing_membar() != NULL;
 1474   }
 1475 
 1476   // so we can just return true here
 1477   return true;
 1478 }
 1479 
 1480 #define __ _masm.
 1481 
 1482 // advance declarations for helper functions to convert register
 1483 // indices to register objects
 1484 
 1485 // the ad file has to provide implementations of certain methods
 1486 // expected by the generic code
 1487 //
 1488 // REQUIRED FUNCTIONALITY
 1489 
 1490 //=============================================================================
 1491 
 1492 // !!!!! Special hack to get all types of calls to specify the byte offset
 1493 //       from the start of the call to the point where the return address
 1494 //       will point.
 1495 
 1496 int MachCallStaticJavaNode::ret_addr_offset()
 1497 {
 1498   // call should be a simple bl
 1499   int off = 4;
 1500   return off;
 1501 }
 1502 
 1503 int MachCallDynamicJavaNode::ret_addr_offset()
 1504 {
 1505   return 16; // movz, movk, movk, bl
 1506 }
 1507 
 1508 int MachCallRuntimeNode::ret_addr_offset() {
 1509   // for generated stubs the call will be
 1510   //   far_call(addr)
 1511   // for real runtime callouts it will be six instructions
 1512   // see aarch64_enc_java_to_runtime
 1513   //   adr(rscratch2, retaddr)
 1514   //   lea(rscratch1, RuntimeAddress(addr)
 1515   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1516   //   blr(rscratch1)
 1517   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1518   if (cb) {
 1519     return MacroAssembler::far_branch_size();
 1520   } else {
 1521     return 6 * NativeInstruction::instruction_size;
 1522   }
 1523 }
 1524 
 1525 // Indicate if the safepoint node needs the polling page as an input
 1526 
 1527 // the shared code plants the oop data at the start of the generated
 1528 // code for the safepoint node and that needs ot be at the load
 1529 // instruction itself. so we cannot plant a mov of the safepoint poll
 1530 // address followed by a load. setting this to true means the mov is
 1531 // scheduled as a prior instruction. that&#39;s better for scheduling
 1532 // anyway.
 1533 
 1534 bool SafePointNode::needs_polling_address_input()
 1535 {
 1536   return true;
 1537 }
 1538 
 1539 //=============================================================================
 1540 
 1541 #ifndef PRODUCT
 1542 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1543   st-&gt;print(&quot;BREAKPOINT&quot;);
 1544 }
 1545 #endif
 1546 
 1547 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1548   MacroAssembler _masm(&amp;cbuf);
 1549   __ brk(0);
 1550 }
 1551 
 1552 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1553   return MachNode::size(ra_);
 1554 }
 1555 
 1556 //=============================================================================
 1557 
 1558 #ifndef PRODUCT
 1559   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1560     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1561   }
 1562 #endif
 1563 
 1564   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1565     MacroAssembler _masm(&amp;cbuf);
 1566     for (int i = 0; i &lt; _count; i++) {
 1567       __ nop();
 1568     }
 1569   }
 1570 
 1571   uint MachNopNode::size(PhaseRegAlloc*) const {
 1572     return _count * NativeInstruction::instruction_size;
 1573   }
 1574 
 1575 //=============================================================================
 1576 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1577 
 1578 int Compile::ConstantTable::calculate_table_base_offset() const {
 1579   return 0;  // absolute addressing, no offset
 1580 }
 1581 
 1582 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1583 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1584   ShouldNotReachHere();
 1585 }
 1586 
 1587 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1588   // Empty encoding
 1589 }
 1590 
 1591 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1592   return 0;
 1593 }
 1594 
 1595 #ifndef PRODUCT
 1596 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1597   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1598 }
 1599 #endif
 1600 
 1601 #ifndef PRODUCT
 1602 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1603   Compile* C = ra_-&gt;C;
 1604 
 1605   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1606 
 1607   if (C-&gt;need_stack_bang(framesize))
 1608     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1609 
 1610   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1611     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1612     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1613     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1614   } else {
 1615     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1616     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1617     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1618     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1619   }
 1620 }
 1621 #endif
 1622 
 1623 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1624   Compile* C = ra_-&gt;C;
 1625   MacroAssembler _masm(&amp;cbuf);
 1626 
 1627   // n.b. frame size includes space for return pc and rfp
 1628   const long framesize = C-&gt;frame_size_in_bytes();
 1629   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1630 
 1631   // insert a nop at the start of the prolog so we can patch in a
 1632   // branch if we need to invalidate the method later
 1633   __ nop();
 1634 
 1635   if (C-&gt;clinit_barrier_on_entry()) {
 1636     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);
 1637 
 1638     Label L_skip_barrier;
 1639 
 1640     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1641     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 1642     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 1643     __ bind(L_skip_barrier);
 1644   }
 1645 
 1646   int bangsize = C-&gt;bang_size_in_bytes();
 1647   if (C-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)
 1648     __ generate_stack_overflow_check(bangsize);
 1649 
 1650   __ build_frame(framesize);
 1651 
 1652   if (VerifyStackAtCalls) {
 1653     Unimplemented();
 1654   }
 1655 
 1656   C-&gt;set_frame_complete(cbuf.insts_size());
 1657 
 1658   if (C-&gt;has_mach_constant_base_node()) {
 1659     // NOTE: We set the table base offset here because users might be
 1660     // emitted before MachConstantBaseNode.
 1661     Compile::ConstantTable&amp; constant_table = C-&gt;constant_table();
 1662     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1663   }
 1664 }
 1665 
 1666 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1667 {
 1668   return MachNode::size(ra_); // too many variables; just compute it
 1669                               // the hard way
 1670 }
 1671 
 1672 int MachPrologNode::reloc() const
 1673 {
 1674   return 0;
 1675 }
 1676 
 1677 //=============================================================================
 1678 
 1679 #ifndef PRODUCT
 1680 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1681   Compile* C = ra_-&gt;C;
 1682   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1683 
 1684   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1685 
 1686   if (framesize == 0) {
 1687     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1688   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1689     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1690     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1691   } else {
 1692     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1693     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1694     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1695   }
 1696 
 1697   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1698     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1699     st-&gt;print(&quot;mov  rscratch1, #0x%lx\n\t&quot;, p2i(os::get_polling_page()));
 1700     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1701   }
 1702 }
 1703 #endif
 1704 
 1705 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1706   Compile* C = ra_-&gt;C;
 1707   MacroAssembler _masm(&amp;cbuf);
 1708   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1709 
 1710   __ remove_frame(framesize);
 1711 
 1712   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1713     __ reserved_stack_check();
 1714   }
 1715 
 1716   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1717     __ read_polling_page(rscratch1, os::get_polling_page(), relocInfo::poll_return_type);
 1718   }
 1719 }
 1720 
 1721 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1722   // Variable size. Determine dynamically.
 1723   return MachNode::size(ra_);
 1724 }
 1725 
 1726 int MachEpilogNode::reloc() const {
 1727   // Return number of relocatable values contained in this instruction.
 1728   return 1; // 1 for polling page.
 1729 }
 1730 
 1731 const Pipeline * MachEpilogNode::pipeline() const {
 1732   return MachNode::pipeline_class();
 1733 }
 1734 
 1735 // This method seems to be obsolete. It is declared in machnode.hpp
 1736 // and defined in all *.ad files, but it is never called. Should we
 1737 // get rid of it?
 1738 int MachEpilogNode::safepoint_offset() const {
 1739   assert(do_polling(), &quot;no return for this epilog node&quot;);
 1740   return 4;
 1741 }
 1742 
 1743 //=============================================================================
 1744 
 1745 // Figure out which register class each belongs in: rc_int, rc_float or
 1746 // rc_stack.
 1747 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1748 
 1749 static enum RC rc_class(OptoReg::Name reg) {
 1750 
 1751   if (reg == OptoReg::Bad) {
 1752     return rc_bad;
 1753   }
 1754 
 1755   // we have 30 int registers * 2 halves
 1756   // (rscratch1 and rscratch2 are omitted)
 1757   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1758 
 1759   if (reg &lt; slots_of_int_registers) {
 1760     return rc_int;
 1761   }
 1762 
 1763   // we have 32 float register * 4 halves
 1764   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1765     return rc_float;
 1766   }
 1767 
 1768   // Between float regs &amp; stack is the flags regs.
 1769   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1770 
 1771   return rc_stack;
 1772 }
 1773 
 1774 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1775   Compile* C = ra_-&gt;C;
 1776 
 1777   // Get registers to move.
 1778   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1779   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1780   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1781   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1782 
 1783   enum RC src_hi_rc = rc_class(src_hi);
 1784   enum RC src_lo_rc = rc_class(src_lo);
 1785   enum RC dst_hi_rc = rc_class(dst_hi);
 1786   enum RC dst_lo_rc = rc_class(dst_lo);
 1787 
 1788   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1789 
 1790   if (src_hi != OptoReg::Bad) {
 1791     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1792            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1793            &quot;expected aligned-adjacent pairs&quot;);
 1794   }
 1795 
 1796   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1797     return 0;            // Self copy, no move.
 1798   }
 1799 
 1800   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1801               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1802   int src_offset = ra_-&gt;reg2offset(src_lo);
 1803   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1804 
 1805   if (bottom_type()-&gt;isa_vect() != NULL) {
 1806     uint ireg = ideal_reg();
 1807     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1808     if (cbuf) {
 1809       MacroAssembler _masm(cbuf);
 1810       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1811       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1812         // stack-&gt;stack
 1813         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1814         if (ireg == Op_VecD) {
 1815           __ unspill(rscratch1, true, src_offset);
 1816           __ spill(rscratch1, true, dst_offset);
 1817         } else {
 1818           __ spill_copy128(src_offset, dst_offset);
 1819         }
 1820       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1821         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1822                ireg == Op_VecD ? __ T8B : __ T16B,
 1823                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1824       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1825         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1826                        ireg == Op_VecD ? __ D : __ Q,
 1827                        ra_-&gt;reg2offset(dst_lo));
 1828       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1829         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1830                        ireg == Op_VecD ? __ D : __ Q,
 1831                        ra_-&gt;reg2offset(src_lo));
 1832       } else {
 1833         ShouldNotReachHere();
 1834       }
 1835     }
 1836   } else if (cbuf) {
 1837     MacroAssembler _masm(cbuf);
 1838     switch (src_lo_rc) {
 1839     case rc_int:
 1840       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1841         if (is64) {
 1842             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1843                    as_Register(Matcher::_regEncode[src_lo]));
 1844         } else {
 1845             MacroAssembler _masm(cbuf);
 1846             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1847                     as_Register(Matcher::_regEncode[src_lo]));
 1848         }
 1849       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1850         if (is64) {
 1851             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1852                      as_Register(Matcher::_regEncode[src_lo]));
 1853         } else {
 1854             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1855                      as_Register(Matcher::_regEncode[src_lo]));
 1856         }
 1857       } else {                    // gpr --&gt; stack spill
 1858         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1859         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1860       }
 1861       break;
 1862     case rc_float:
 1863       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1864         if (is64) {
 1865             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1866                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1867         } else {
 1868             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1869                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1870         }
 1871       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1872           if (cbuf) {
 1873             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1874                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1875         } else {
 1876             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1877                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1878         }
 1879       } else {                    // fpr --&gt; stack spill
 1880         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1881         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1882                  is64 ? __ D : __ S, dst_offset);
 1883       }
 1884       break;
 1885     case rc_stack:
 1886       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1887         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1888       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1889         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1890                    is64 ? __ D : __ S, src_offset);
 1891       } else {                    // stack --&gt; stack copy
 1892         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1893         __ unspill(rscratch1, is64, src_offset);
 1894         __ spill(rscratch1, is64, dst_offset);
 1895       }
 1896       break;
 1897     default:
 1898       assert(false, &quot;bad rc_class for spill&quot;);
 1899       ShouldNotReachHere();
 1900     }
 1901   }
 1902 
 1903   if (st) {
 1904     st-&gt;print(&quot;spill &quot;);
 1905     if (src_lo_rc == rc_stack) {
 1906       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1907     } else {
 1908       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1909     }
 1910     if (dst_lo_rc == rc_stack) {
 1911       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1912     } else {
 1913       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1914     }
 1915     if (bottom_type()-&gt;isa_vect() != NULL) {
 1916       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1917     } else {
 1918       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1919     }
 1920   }
 1921 
 1922   return 0;
 1923 
 1924 }
 1925 
 1926 #ifndef PRODUCT
 1927 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1928   if (!ra_)
 1929     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1930   else
 1931     implementation(NULL, ra_, false, st);
 1932 }
 1933 #endif
 1934 
 1935 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1936   implementation(&amp;cbuf, ra_, false, NULL);
 1937 }
 1938 
 1939 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1940   return MachNode::size(ra_);
 1941 }
 1942 
 1943 //=============================================================================
 1944 
 1945 #ifndef PRODUCT
 1946 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1947   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1948   int reg = ra_-&gt;get_reg_first(this);
 1949   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1950             Matcher::regName[reg], offset);
 1951 }
 1952 #endif
 1953 
 1954 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1955   MacroAssembler _masm(&amp;cbuf);
 1956 
 1957   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1958   int reg    = ra_-&gt;get_encode(this);
 1959 
 1960   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1961     __ add(as_Register(reg), sp, offset);
 1962   } else {
 1963     ShouldNotReachHere();
 1964   }
 1965 }
 1966 
 1967 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1968   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1969   return 4;
 1970 }
 1971 
 1972 //=============================================================================
 1973 
 1974 #ifndef PRODUCT
 1975 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1976 {
 1977   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1978   if (UseCompressedClassPointers) {
 1979     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1980     if (CompressedKlassPointers::shift() != 0) {
 1981       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1982     }
 1983   } else {
 1984    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1985   }
 1986   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1987   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 1988 }
 1989 #endif
 1990 
 1991 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 1992 {
 1993   // This is the unverified entry point.
 1994   MacroAssembler _masm(&amp;cbuf);
 1995 
 1996   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 1997   Label skip;
 1998   // TODO
 1999   // can we avoid this skip and still use a reloc?
 2000   __ br(Assembler::EQ, skip);
 2001   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2002   __ bind(skip);
 2003 }
 2004 
 2005 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2006 {
 2007   return MachNode::size(ra_);
 2008 }
 2009 
 2010 // REQUIRED EMIT CODE
 2011 
 2012 //=============================================================================
 2013 
 2014 // Emit exception handler code.
 2015 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2016 {
 2017   // mov rscratch1 #exception_blob_entry_point
 2018   // br rscratch1
 2019   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2020   // That&#39;s why we must use the macroassembler to generate a handler.
 2021   MacroAssembler _masm(&amp;cbuf);
 2022   address base = __ start_a_stub(size_exception_handler());
 2023   if (base == NULL) {
 2024     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2025     return 0;  // CodeBuffer::expand failed
 2026   }
 2027   int offset = __ offset();
 2028   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2029   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2030   __ end_a_stub();
 2031   return offset;
 2032 }
 2033 
 2034 // Emit deopt handler code.
 2035 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2036 {
 2037   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2038   // That&#39;s why we must use the macroassembler to generate a handler.
 2039   MacroAssembler _masm(&amp;cbuf);
 2040   address base = __ start_a_stub(size_deopt_handler());
 2041   if (base == NULL) {
 2042     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2043     return 0;  // CodeBuffer::expand failed
 2044   }
 2045   int offset = __ offset();
 2046 
 2047   __ adr(lr, __ pc());
 2048   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2049 
 2050   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2051   __ end_a_stub();
 2052   return offset;
 2053 }
 2054 
 2055 // REQUIRED MATCHER CODE
 2056 
 2057 //=============================================================================
 2058 
 2059 const bool Matcher::match_rule_supported(int opcode) {
 2060   if (!has_match_rule(opcode))
 2061     return false;
 2062 
 2063   bool ret_value = true;
 2064   switch (opcode) {
 2065     case Op_CacheWB:
 2066     case Op_CacheWBPreSync:
 2067     case Op_CacheWBPostSync:
 2068       if (!VM_Version::supports_data_cache_line_flush()) {
 2069         ret_value = false;
 2070       }
 2071       break;
 2072   }
 2073 
 2074   return ret_value; // Per default match rules are supported.
 2075 }
 2076 
 2077 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2078 
 2079   // TODO
 2080   // identify extra cases that we might want to provide match rules for
 2081   // e.g. Op_ vector nodes and other intrinsics while guarding with vlen
 2082   bool ret_value = match_rule_supported(opcode);
 2083   // Add rules here.
 2084 
 2085   return ret_value;  // Per default match rules are supported.
 2086 }
 2087 
 2088 const bool Matcher::has_predicated_vectors(void) {
 2089   return false;
 2090 }
 2091 
 2092 const int Matcher::float_pressure(int default_pressure_threshold) {
 2093   return default_pressure_threshold;
 2094 }
 2095 
 2096 int Matcher::regnum_to_fpu_offset(int regnum)
 2097 {
 2098   Unimplemented();
 2099   return 0;
 2100 }
 2101 
 2102 // Is this branch offset short enough that a short branch can be used?
 2103 //
 2104 // NOTE: If the platform does not provide any short branch variants, then
 2105 //       this method should return false for offset 0.
 2106 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2107   // The passed offset is relative to address of the branch.
 2108 
 2109   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2110 }
 2111 
 2112 const bool Matcher::isSimpleConstant64(jlong value) {
 2113   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2114   // Probably always true, even if a temp register is required.
 2115   return true;
 2116 }
 2117 
 2118 // true just means we have fast l2f conversion
 2119 const bool Matcher::convL2FSupported(void) {
 2120   return true;
 2121 }
 2122 
 2123 // Vector width in bytes.
 2124 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2125   int size = MIN2(16,(int)MaxVectorSize);
 2126   // Minimum 2 values in vector
 2127   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2128   // But never &lt; 4
 2129   if (size &lt; 4) size = 0;
 2130   return size;
 2131 }
 2132 
 2133 // Limits on vector size (number of elements) loaded into vector.
 2134 const int Matcher::max_vector_size(const BasicType bt) {
 2135   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2136 }
 2137 const int Matcher::min_vector_size(const BasicType bt) {
 2138 //  For the moment limit the vector size to 8 bytes
 2139     int size = 8 / type2aelembytes(bt);
 2140     if (size &lt; 2) size = 2;
 2141     return size;
 2142 }
 2143 
 2144 // Vector ideal reg.
 2145 const uint Matcher::vector_ideal_reg(int len) {
 2146   switch(len) {
 2147     case  8: return Op_VecD;
 2148     case 16: return Op_VecX;
 2149   }
 2150   ShouldNotReachHere();
 2151   return 0;
 2152 }
 2153 
 2154 const uint Matcher::vector_shift_count_ideal_reg(int size) {
 2155   switch(size) {
 2156     case  8: return Op_VecD;
 2157     case 16: return Op_VecX;
 2158   }
 2159   ShouldNotReachHere();
 2160   return 0;
 2161 }
 2162 
 2163 // AES support not yet implemented
 2164 const bool Matcher::pass_original_key_for_aes() {
 2165   return false;
 2166 }
 2167 
 2168 // aarch64 supports misaligned vectors store/load.
 2169 const bool Matcher::misaligned_vectors_ok() {
 2170   return true;
 2171 }
 2172 
 2173 // false =&gt; size gets scaled to BytesPerLong, ok.
 2174 const bool Matcher::init_array_count_is_in_bytes = false;
 2175 
 2176 // Use conditional move (CMOVL)
 2177 const int Matcher::long_cmove_cost() {
 2178   // long cmoves are no more expensive than int cmoves
 2179   return 0;
 2180 }
 2181 
 2182 const int Matcher::float_cmove_cost() {
 2183   // float cmoves are no more expensive than int cmoves
 2184   return 0;
 2185 }
 2186 
 2187 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2188 const bool Matcher::require_postalloc_expand = false;
 2189 
 2190 // Do we need to mask the count passed to shift instructions or does
 2191 // the cpu only look at the lower 5/6 bits anyway?
 2192 const bool Matcher::need_masked_shift_count = false;
 2193 
 2194 // No support for generic vector operands.
 2195 const bool Matcher::supports_generic_vector_operands  = false;
 2196 
 2197 MachOper* Matcher::specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2198   ShouldNotReachHere(); // generic vector operands not supported
 2199   return NULL;
 2200 }
 2201 
 2202 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2203   ShouldNotReachHere();  // generic vector operands not supported
 2204   return false;
 2205 }
 2206 
 2207 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2208   ShouldNotReachHere();  // generic vector operands not supported
 2209   return false;
 2210 }
 2211 
 2212 // This affects two different things:
 2213 //  - how Decode nodes are matched
 2214 //  - how ImplicitNullCheck opportunities are recognized
 2215 // If true, the matcher will try to remove all Decodes and match them
 2216 // (as operands) into nodes. NullChecks are not prepared to deal with
 2217 // Decodes by final_graph_reshaping().
 2218 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2219 // for a NullCheck. The matcher matches the Decode node into a register.
 2220 // Implicit_null_check optimization moves the Decode along with the
 2221 // memory operation back up before the NullCheck.
 2222 bool Matcher::narrow_oop_use_complex_address() {
 2223   return CompressedOops::shift() == 0;
 2224 }
 2225 
 2226 bool Matcher::narrow_klass_use_complex_address() {
 2227 // TODO
 2228 // decide whether we need to set this to true
 2229   return false;
 2230 }
 2231 
 2232 bool Matcher::const_oop_prefer_decode() {
 2233   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2234   return CompressedOops::base() == NULL;
 2235 }
 2236 
 2237 bool Matcher::const_klass_prefer_decode() {
 2238   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2239   return CompressedKlassPointers::base() == NULL;
 2240 }
 2241 
 2242 // Is it better to copy float constants, or load them directly from
 2243 // memory?  Intel can load a float constant from a direct address,
 2244 // requiring no extra registers.  Most RISCs will have to materialize
 2245 // an address into a register first, so they would do better to copy
 2246 // the constant from stack.
 2247 const bool Matcher::rematerialize_float_constants = false;
 2248 
 2249 // If CPU can load and store mis-aligned doubles directly then no
 2250 // fixup is needed.  Else we split the double into 2 integer pieces
 2251 // and move it piece-by-piece.  Only happens when passing doubles into
 2252 // C code as the Java calling convention forces doubles to be aligned.
 2253 const bool Matcher::misaligned_doubles_ok = true;
 2254 
 2255 // No-op on amd64
 2256 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2257   Unimplemented();
 2258 }
 2259 
 2260 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2261 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2262 
 2263 // Are floats converted to double when stored to stack during
 2264 // deoptimization?
 2265 bool Matcher::float_in_double() { return false; }
 2266 
 2267 // Do ints take an entire long register or just half?
 2268 // The relevant question is how the int is callee-saved:
 2269 // the whole long is written but de-opt&#39;ing will have to extract
 2270 // the relevant 32 bits.
 2271 const bool Matcher::int_in_long = true;
 2272 
 2273 // Return whether or not this register is ever used as an argument.
 2274 // This function is used on startup to build the trampoline stubs in
 2275 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2276 // call in the trampoline, and arguments in those registers not be
 2277 // available to the callee.
 2278 bool Matcher::can_be_java_arg(int reg)
 2279 {
 2280   return
 2281     reg ==  R0_num || reg == R0_H_num ||
 2282     reg ==  R1_num || reg == R1_H_num ||
 2283     reg ==  R2_num || reg == R2_H_num ||
 2284     reg ==  R3_num || reg == R3_H_num ||
 2285     reg ==  R4_num || reg == R4_H_num ||
 2286     reg ==  R5_num || reg == R5_H_num ||
 2287     reg ==  R6_num || reg == R6_H_num ||
 2288     reg ==  R7_num || reg == R7_H_num ||
 2289     reg ==  V0_num || reg == V0_H_num ||
 2290     reg ==  V1_num || reg == V1_H_num ||
 2291     reg ==  V2_num || reg == V2_H_num ||
 2292     reg ==  V3_num || reg == V3_H_num ||
 2293     reg ==  V4_num || reg == V4_H_num ||
 2294     reg ==  V5_num || reg == V5_H_num ||
 2295     reg ==  V6_num || reg == V6_H_num ||
 2296     reg ==  V7_num || reg == V7_H_num;
 2297 }
 2298 
 2299 bool Matcher::is_spillable_arg(int reg)
 2300 {
 2301   return can_be_java_arg(reg);
 2302 }
 2303 
 2304 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2305   return false;
 2306 }
 2307 
 2308 RegMask Matcher::divI_proj_mask() {
 2309   ShouldNotReachHere();
 2310   return RegMask();
 2311 }
 2312 
 2313 // Register for MODI projection of divmodI.
 2314 RegMask Matcher::modI_proj_mask() {
 2315   ShouldNotReachHere();
 2316   return RegMask();
 2317 }
 2318 
 2319 // Register for DIVL projection of divmodL.
 2320 RegMask Matcher::divL_proj_mask() {
 2321   ShouldNotReachHere();
 2322   return RegMask();
 2323 }
 2324 
 2325 // Register for MODL projection of divmodL.
 2326 RegMask Matcher::modL_proj_mask() {
 2327   ShouldNotReachHere();
 2328   return RegMask();
 2329 }
 2330 
 2331 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2332   return FP_REG_mask();
 2333 }
 2334 
 2335 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2336   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2337     Node* u = addp-&gt;fast_out(i);
 2338     if (u-&gt;is_Mem()) {
 2339       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2340       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2341       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2342         return false;
 2343       }
 2344     }
 2345   }
 2346   return true;
 2347 }
 2348 
 2349 const bool Matcher::convi2l_type_required = false;
 2350 
 2351 // Should the Matcher clone shifts on addressing modes, expecting them
 2352 // to be subsumed into complex addressing expressions or compute them
 2353 // into registers?
 2354 bool Matcher::clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2355   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2356     return true;
 2357   }
 2358 
 2359   Node *off = m-&gt;in(AddPNode::Offset);
 2360   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2361       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2362       // Are there other uses besides address expressions?
 2363       !is_visited(off)) {
 2364     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2365     mstack.push(off-&gt;in(2), Visit);
 2366     Node *conv = off-&gt;in(1);
 2367     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2368         // Are there other uses besides address expressions?
 2369         !is_visited(conv)) {
 2370       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2371       mstack.push(conv-&gt;in(1), Pre_Visit);
 2372     } else {
 2373       mstack.push(conv, Pre_Visit);
 2374     }
 2375     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2376     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2377     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2378     return true;
 2379   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2380              // Are there other uses besides address expressions?
 2381              !is_visited(off)) {
 2382     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2383     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2384     mstack.push(off-&gt;in(1), Pre_Visit);
 2385     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2386     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2387     return true;
 2388   }
 2389   return false;
 2390 }
 2391 
 2392 void Compile::reshape_address(AddPNode* addp) {
 2393 }
 2394 
 2395 
 2396 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2397   MacroAssembler _masm(&amp;cbuf);                                          \
 2398   {                                                                     \
 2399     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2400     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2401     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2402     __ INSN(REG, as_Register(BASE));                                    \
 2403   }
 2404 
 2405 
 2406 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2407   {
 2408     Address::extend scale;
 2409 
 2410     // Hooboy, this is fugly.  We need a way to communicate to the
 2411     // encoder that the index needs to be sign extended, so we have to
 2412     // enumerate all the cases.
 2413     switch (opcode) {
 2414     case INDINDEXSCALEDI2L:
 2415     case INDINDEXSCALEDI2LN:
 2416     case INDINDEXI2L:
 2417     case INDINDEXI2LN:
 2418       scale = Address::sxtw(size);
 2419       break;
 2420     default:
 2421       scale = Address::lsl(size);
 2422     }
 2423 
 2424     if (index == -1) {
 2425       return Address(base, disp);
 2426     } else {
 2427       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2428       return Address(base, as_Register(index), scale);
 2429     }
 2430   }
 2431 
 2432 
 2433 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2434 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2435 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2436 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2437                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2438 
 2439   // Used for all non-volatile memory accesses.  The use of
 2440   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2441   // offsets is something of a kludge.
 2442   static void loadStore(MacroAssembler masm, mem_insn insn,
 2443                         Register reg, int opcode,
 2444                         Register base, int index, int scale, int disp,
 2445                         int size_in_memory)
 2446   {
 2447     Address addr = mem2address(opcode, base, index, scale, disp);
 2448     if (addr.getMode() == Address::base_plus_offset) {
 2449       /* If we get an out-of-range offset it is a bug in the compiler,
 2450          so we assert here. */
 2451       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2452              &quot;c2 compiler bug&quot;);
 2453       /* Fix up any out-of-range offsets. */
 2454       assert_different_registers(rscratch1, base);
 2455       assert_different_registers(rscratch1, reg);
 2456       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2457     }
 2458     (masm.*insn)(reg, addr);
 2459   }
 2460 
 2461   static void loadStore(MacroAssembler masm, mem_float_insn insn,
 2462                         FloatRegister reg, int opcode,
 2463                         Register base, int index, int size, int disp,
 2464                         int size_in_memory)
 2465   {
 2466     Address::extend scale;
 2467 
 2468     switch (opcode) {
 2469     case INDINDEXSCALEDI2L:
 2470     case INDINDEXSCALEDI2LN:
 2471       scale = Address::sxtw(size);
 2472       break;
 2473     default:
 2474       scale = Address::lsl(size);
 2475     }
 2476 
 2477     if (index == -1) {
 2478       /* If we get an out-of-range offset it is a bug in the compiler,
 2479          so we assert here. */
 2480       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2481       /* Fix up any out-of-range offsets. */
 2482       assert_different_registers(rscratch1, base);
 2483       Address addr = Address(base, disp);
 2484       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2485       (masm.*insn)(reg, addr);
 2486     } else {
 2487       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2488       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2489     }
 2490   }
 2491 
 2492   static void loadStore(MacroAssembler masm, mem_vector_insn insn,
 2493                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2494                         int opcode, Register base, int index, int size, int disp)
 2495   {
 2496     if (index == -1) {
 2497       (masm.*insn)(reg, T, Address(base, disp));
 2498     } else {
 2499       assert(disp == 0, &quot;unsupported address mode&quot;);
 2500       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2501     }
 2502   }
 2503 
 2504 %}
 2505 
 2506 
 2507 
 2508 //----------ENCODING BLOCK-----------------------------------------------------
 2509 // This block specifies the encoding classes used by the compiler to
 2510 // output byte streams.  Encoding classes are parameterized macros
 2511 // used by Machine Instruction Nodes in order to generate the bit
 2512 // encoding of the instruction.  Operands specify their base encoding
 2513 // interface with the interface keyword.  There are currently
 2514 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2515 // COND_INTER.  REG_INTER causes an operand to generate a function
 2516 // which returns its register number when queried.  CONST_INTER causes
 2517 // an operand to generate a function which returns the value of the
 2518 // constant when queried.  MEMORY_INTER causes an operand to generate
 2519 // four functions which return the Base Register, the Index Register,
 2520 // the Scale Value, and the Offset Value of the operand when queried.
 2521 // COND_INTER causes an operand to generate six functions which return
 2522 // the encoding code (ie - encoding bits for the instruction)
 2523 // associated with each basic boolean condition for a conditional
 2524 // instruction.
 2525 //
 2526 // Instructions specify two basic values for encoding.  Again, a
 2527 // function is available to check if the constant displacement is an
 2528 // oop. They use the ins_encode keyword to specify their encoding
 2529 // classes (which must be a sequence of enc_class names, and their
 2530 // parameters, specified in the encoding block), and they use the
 2531 // opcode keyword to specify, in order, their primary, secondary, and
 2532 // tertiary opcode.  Only the opcode sections which a particular
 2533 // instruction needs for encoding need to be specified.
 2534 encode %{
 2535   // Build emit functions for each basic byte or larger field in the
 2536   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2537   // from C++ code in the enc_class source block.  Emit functions will
 2538   // live in the main source block for now.  In future, we can
 2539   // generalize this by adding a syntax that specifies the sizes of
 2540   // fields in an order, so that the adlc can build the emit functions
 2541   // automagically
 2542 
 2543   // catch all for unimplemented encodings
 2544   enc_class enc_unimplemented %{
 2545     MacroAssembler _masm(&amp;cbuf);
 2546     __ unimplemented(&quot;C2 catch all&quot;);
 2547   %}
 2548 
 2549   // BEGIN Non-volatile memory access
 2550 
 2551   // This encoding class is generated automatically from ad_encode.m4.
 2552   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2553   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2554     Register dst_reg = as_Register($dst$$reg);
 2555     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2556                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2557   %}
 2558 
 2559   // This encoding class is generated automatically from ad_encode.m4.
 2560   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2561   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2562     Register dst_reg = as_Register($dst$$reg);
 2563     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2564                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2565   %}
 2566 
 2567   // This encoding class is generated automatically from ad_encode.m4.
 2568   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2569   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2570     Register dst_reg = as_Register($dst$$reg);
 2571     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2572                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2573   %}
 2574 
 2575   // This encoding class is generated automatically from ad_encode.m4.
 2576   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2577   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2578     Register dst_reg = as_Register($dst$$reg);
 2579     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2580                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2581   %}
 2582 
 2583   // This encoding class is generated automatically from ad_encode.m4.
 2584   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2585   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2586     Register dst_reg = as_Register($dst$$reg);
 2587     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2588                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2589   %}
 2590 
 2591   // This encoding class is generated automatically from ad_encode.m4.
 2592   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2593   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2594     Register dst_reg = as_Register($dst$$reg);
 2595     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2596                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2597   %}
 2598 
 2599   // This encoding class is generated automatically from ad_encode.m4.
 2600   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2601   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2602     Register dst_reg = as_Register($dst$$reg);
 2603     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2604                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2605   %}
 2606 
 2607   // This encoding class is generated automatically from ad_encode.m4.
 2608   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2609   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2610     Register dst_reg = as_Register($dst$$reg);
 2611     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2612                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2613   %}
 2614 
 2615   // This encoding class is generated automatically from ad_encode.m4.
 2616   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2617   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2618     Register dst_reg = as_Register($dst$$reg);
 2619     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2620                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2621   %}
 2622 
 2623   // This encoding class is generated automatically from ad_encode.m4.
 2624   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2625   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2626     Register dst_reg = as_Register($dst$$reg);
 2627     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2628                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2629   %}
 2630 
 2631   // This encoding class is generated automatically from ad_encode.m4.
 2632   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2633   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2634     Register dst_reg = as_Register($dst$$reg);
 2635     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2636                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2637   %}
 2638 
 2639   // This encoding class is generated automatically from ad_encode.m4.
 2640   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2641   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2642     Register dst_reg = as_Register($dst$$reg);
 2643     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2644                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2645   %}
 2646 
 2647   // This encoding class is generated automatically from ad_encode.m4.
 2648   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2649   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2650     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2651     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2652                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2653   %}
 2654 
 2655   // This encoding class is generated automatically from ad_encode.m4.
 2656   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2657   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2658     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2659     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2660                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2661   %}
 2662 
 2663   // This encoding class is generated automatically from ad_encode.m4.
 2664   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2665   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2666     Register src_reg = as_Register($src$$reg);
 2667     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2668                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2669   %}
 2670 
 2671   // This encoding class is generated automatically from ad_encode.m4.
 2672   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2673   enc_class aarch64_enc_strb0(memory1 mem) %{
 2674     MacroAssembler _masm(&amp;cbuf);
 2675     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2676                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2677   %}
 2678 
 2679   // This encoding class is generated automatically from ad_encode.m4.
 2680   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2681   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2682     Register src_reg = as_Register($src$$reg);
 2683     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2684                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2685   %}
 2686 
 2687   // This encoding class is generated automatically from ad_encode.m4.
 2688   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2689   enc_class aarch64_enc_strh0(memory2 mem) %{
 2690     MacroAssembler _masm(&amp;cbuf);
 2691     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2692                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2693   %}
 2694 
 2695   // This encoding class is generated automatically from ad_encode.m4.
 2696   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2697   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2698     Register src_reg = as_Register($src$$reg);
 2699     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2700                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2701   %}
 2702 
 2703   // This encoding class is generated automatically from ad_encode.m4.
 2704   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2705   enc_class aarch64_enc_strw0(memory4 mem) %{
 2706     MacroAssembler _masm(&amp;cbuf);
 2707     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2708                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2709   %}
 2710 
 2711   // This encoding class is generated automatically from ad_encode.m4.
 2712   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2713   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2714     Register src_reg = as_Register($src$$reg);
 2715     // we sometimes get asked to store the stack pointer into the
 2716     // current thread -- we cannot do that directly on AArch64
 2717     if (src_reg == r31_sp) {
 2718       MacroAssembler _masm(&amp;cbuf);
 2719       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2720       __ mov(rscratch2, sp);
 2721       src_reg = rscratch2;
 2722     }
 2723     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2724                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2725   %}
 2726 
 2727   // This encoding class is generated automatically from ad_encode.m4.
 2728   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2729   enc_class aarch64_enc_str0(memory8 mem) %{
 2730     MacroAssembler _masm(&amp;cbuf);
 2731     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2732                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2733   %}
 2734 
 2735   // This encoding class is generated automatically from ad_encode.m4.
 2736   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2737   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2738     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2739     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2740                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2741   %}
 2742 
 2743   // This encoding class is generated automatically from ad_encode.m4.
 2744   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2745   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2746     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2747     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2748                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2749   %}
 2750 
 2751   // This encoding class is generated automatically from ad_encode.m4.
 2752   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2753   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2754     MacroAssembler _masm(&amp;cbuf);
 2755     address con = (address)$src$$constant;
 2756     // need to do this the hard way until we can manage relocs
 2757     // for 32 bit constants
 2758     __ movoop(rscratch2, (jobject)con);
 2759     if (con) __ encode_heap_oop_not_null(rscratch2);
 2760     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2761                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2762   %}
 2763 
 2764   // This encoding class is generated automatically from ad_encode.m4.
 2765   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2766   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2767     MacroAssembler _masm(&amp;cbuf);
 2768     address con = (address)$src$$constant;
 2769     // need to do this the hard way until we can manage relocs
 2770     // for 32 bit constants
 2771     __ movoop(rscratch2, (jobject)con);
 2772     __ encode_klass_not_null(rscratch2);
 2773     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2774                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2775   %}
 2776 
 2777   // This encoding class is generated automatically from ad_encode.m4.
 2778   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2779   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2780       MacroAssembler _masm(&amp;cbuf);
 2781       __ membar(Assembler::StoreStore);
 2782       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2783                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2784   %}
 2785 
 2786   // END Non-volatile memory access
 2787 
 2788   // Vector loads and stores
 2789   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2790     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2791     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2792        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2793   %}
 2794 
 2795   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2796     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2797     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2798        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2799   %}
 2800 
 2801   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2802     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2803     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2804        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2805   %}
 2806 
 2807   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2808     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2809     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2810        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2811   %}
 2812 
 2813   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2814     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2815     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2816        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2817   %}
 2818 
 2819   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2820     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2821     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2822        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2823   %}
 2824 
 2825   // volatile loads and stores
 2826 
 2827   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2828     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2829                  rscratch1, stlrb);
 2830   %}
 2831 
 2832   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2833     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2834                  rscratch1, stlrh);
 2835   %}
 2836 
 2837   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2838     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2839                  rscratch1, stlrw);
 2840   %}
 2841 
 2842 
 2843   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2844     Register dst_reg = as_Register($dst$$reg);
 2845     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2846              rscratch1, ldarb);
 2847     __ sxtbw(dst_reg, dst_reg);
 2848   %}
 2849 
 2850   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2851     Register dst_reg = as_Register($dst$$reg);
 2852     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2853              rscratch1, ldarb);
 2854     __ sxtb(dst_reg, dst_reg);
 2855   %}
 2856 
 2857   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2858     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2859              rscratch1, ldarb);
 2860   %}
 2861 
 2862   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2863     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2864              rscratch1, ldarb);
 2865   %}
 2866 
 2867   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2868     Register dst_reg = as_Register($dst$$reg);
 2869     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2870              rscratch1, ldarh);
 2871     __ sxthw(dst_reg, dst_reg);
 2872   %}
 2873 
 2874   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2875     Register dst_reg = as_Register($dst$$reg);
 2876     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2877              rscratch1, ldarh);
 2878     __ sxth(dst_reg, dst_reg);
 2879   %}
 2880 
 2881   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2882     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2883              rscratch1, ldarh);
 2884   %}
 2885 
 2886   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2887     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2888              rscratch1, ldarh);
 2889   %}
 2890 
 2891   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2892     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2893              rscratch1, ldarw);
 2894   %}
 2895 
 2896   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2897     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2898              rscratch1, ldarw);
 2899   %}
 2900 
 2901   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2902     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2903              rscratch1, ldar);
 2904   %}
 2905 
 2906   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2907     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2908              rscratch1, ldarw);
 2909     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2910   %}
 2911 
 2912   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2913     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2914              rscratch1, ldar);
 2915     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2916   %}
 2917 
 2918   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2919     Register src_reg = as_Register($src$$reg);
 2920     // we sometimes get asked to store the stack pointer into the
 2921     // current thread -- we cannot do that directly on AArch64
 2922     if (src_reg == r31_sp) {
 2923         MacroAssembler _masm(&amp;cbuf);
 2924       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2925       __ mov(rscratch2, sp);
 2926       src_reg = rscratch2;
 2927     }
 2928     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2929                  rscratch1, stlr);
 2930   %}
 2931 
 2932   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2933     {
 2934       MacroAssembler _masm(&amp;cbuf);
 2935       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2936       __ fmovs(rscratch2, src_reg);
 2937     }
 2938     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2939                  rscratch1, stlrw);
 2940   %}
 2941 
 2942   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2943     {
 2944       MacroAssembler _masm(&amp;cbuf);
 2945       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2946       __ fmovd(rscratch2, src_reg);
 2947     }
 2948     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2949                  rscratch1, stlr);
 2950   %}
 2951 
 2952   // synchronized read/update encodings
 2953 
 2954   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 2955     MacroAssembler _masm(&amp;cbuf);
 2956     Register dst_reg = as_Register($dst$$reg);
 2957     Register base = as_Register($mem$$base);
 2958     int index = $mem$$index;
 2959     int scale = $mem$$scale;
 2960     int disp = $mem$$disp;
 2961     if (index == -1) {
 2962        if (disp != 0) {
 2963         __ lea(rscratch1, Address(base, disp));
 2964         __ ldaxr(dst_reg, rscratch1);
 2965       } else {
 2966         // TODO
 2967         // should we ever get anything other than this case?
 2968         __ ldaxr(dst_reg, base);
 2969       }
 2970     } else {
 2971       Register index_reg = as_Register(index);
 2972       if (disp == 0) {
 2973         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 2974         __ ldaxr(dst_reg, rscratch1);
 2975       } else {
 2976         __ lea(rscratch1, Address(base, disp));
 2977         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 2978         __ ldaxr(dst_reg, rscratch1);
 2979       }
 2980     }
 2981   %}
 2982 
 2983   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 2984     MacroAssembler _masm(&amp;cbuf);
 2985     Register src_reg = as_Register($src$$reg);
 2986     Register base = as_Register($mem$$base);
 2987     int index = $mem$$index;
 2988     int scale = $mem$$scale;
 2989     int disp = $mem$$disp;
 2990     if (index == -1) {
 2991        if (disp != 0) {
 2992         __ lea(rscratch2, Address(base, disp));
 2993         __ stlxr(rscratch1, src_reg, rscratch2);
 2994       } else {
 2995         // TODO
 2996         // should we ever get anything other than this case?
 2997         __ stlxr(rscratch1, src_reg, base);
 2998       }
 2999     } else {
 3000       Register index_reg = as_Register(index);
 3001       if (disp == 0) {
 3002         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3003         __ stlxr(rscratch1, src_reg, rscratch2);
 3004       } else {
 3005         __ lea(rscratch2, Address(base, disp));
 3006         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3007         __ stlxr(rscratch1, src_reg, rscratch2);
 3008       }
 3009     }
 3010     __ cmpw(rscratch1, zr);
 3011   %}
 3012 
 3013   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3014     MacroAssembler _masm(&amp;cbuf);
 3015     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3016     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3017                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3018                /*weak*/ false, noreg);
 3019   %}
 3020 
 3021   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3022     MacroAssembler _masm(&amp;cbuf);
 3023     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3024     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3025                Assembler::word, /*acquire*/ false, /*release*/ true,
 3026                /*weak*/ false, noreg);
 3027   %}
 3028 
 3029   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3030     MacroAssembler _masm(&amp;cbuf);
 3031     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3032     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3033                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3034                /*weak*/ false, noreg);
 3035   %}
 3036 
 3037   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3038     MacroAssembler _masm(&amp;cbuf);
 3039     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3040     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3041                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3042                /*weak*/ false, noreg);
 3043   %}
 3044 
 3045 
 3046   // The only difference between aarch64_enc_cmpxchg and
 3047   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3048   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3049   // lock.
 3050   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3051     MacroAssembler _masm(&amp;cbuf);
 3052     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3053     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3054                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3055                /*weak*/ false, noreg);
 3056   %}
 3057 
 3058   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3059     MacroAssembler _masm(&amp;cbuf);
 3060     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3061     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3062                Assembler::word, /*acquire*/ true, /*release*/ true,
 3063                /*weak*/ false, noreg);
 3064   %}
 3065 
 3066   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3067     MacroAssembler _masm(&amp;cbuf);
 3068     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3069     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3070                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3071                /*weak*/ false, noreg);
 3072   %}
 3073 
 3074   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3075     MacroAssembler _masm(&amp;cbuf);
 3076     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3077     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3078                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3079                /*weak*/ false, noreg);
 3080   %}
 3081 
 3082   // auxiliary used for CompareAndSwapX to set result register
 3083   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3084     MacroAssembler _masm(&amp;cbuf);
 3085     Register res_reg = as_Register($res$$reg);
 3086     __ cset(res_reg, Assembler::EQ);
 3087   %}
 3088 
 3089   // prefetch encodings
 3090 
 3091   enc_class aarch64_enc_prefetchw(memory mem) %{
 3092     MacroAssembler _masm(&amp;cbuf);
 3093     Register base = as_Register($mem$$base);
 3094     int index = $mem$$index;
 3095     int scale = $mem$$scale;
 3096     int disp = $mem$$disp;
 3097     if (index == -1) {
 3098       __ prfm(Address(base, disp), PSTL1KEEP);
 3099     } else {
 3100       Register index_reg = as_Register(index);
 3101       if (disp == 0) {
 3102         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3103       } else {
 3104         __ lea(rscratch1, Address(base, disp));
 3105 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3106       }
 3107     }
 3108   %}
 3109 
 3110   /// mov envcodings
 3111 
 3112   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3113     MacroAssembler _masm(&amp;cbuf);
 3114     u_int32_t con = (u_int32_t)$src$$constant;
 3115     Register dst_reg = as_Register($dst$$reg);
 3116     if (con == 0) {
 3117       __ movw(dst_reg, zr);
 3118     } else {
 3119       __ movw(dst_reg, con);
 3120     }
 3121   %}
 3122 
 3123   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3124     MacroAssembler _masm(&amp;cbuf);
 3125     Register dst_reg = as_Register($dst$$reg);
 3126     u_int64_t con = (u_int64_t)$src$$constant;
 3127     if (con == 0) {
 3128       __ mov(dst_reg, zr);
 3129     } else {
 3130       __ mov(dst_reg, con);
 3131     }
 3132   %}
 3133 
 3134   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3135     MacroAssembler _masm(&amp;cbuf);
 3136     Register dst_reg = as_Register($dst$$reg);
 3137     address con = (address)$src$$constant;
 3138     if (con == NULL || con == (address)1) {
 3139       ShouldNotReachHere();
 3140     } else {
 3141       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3142       if (rtype == relocInfo::oop_type) {
 3143         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3144       } else if (rtype == relocInfo::metadata_type) {
 3145         __ mov_metadata(dst_reg, (Metadata*)con);
 3146       } else {
 3147         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3148         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3149           __ mov(dst_reg, con);
 3150         } else {
 3151           unsigned long offset;
 3152           __ adrp(dst_reg, con, offset);
 3153           __ add(dst_reg, dst_reg, offset);
 3154         }
 3155       }
 3156     }
 3157   %}
 3158 
 3159   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3160     MacroAssembler _masm(&amp;cbuf);
 3161     Register dst_reg = as_Register($dst$$reg);
 3162     __ mov(dst_reg, zr);
 3163   %}
 3164 
 3165   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3166     MacroAssembler _masm(&amp;cbuf);
 3167     Register dst_reg = as_Register($dst$$reg);
 3168     __ mov(dst_reg, (u_int64_t)1);
 3169   %}
 3170 
 3171   enc_class aarch64_enc_mov_poll_page(iRegP dst, immPollPage src) %{
 3172     MacroAssembler _masm(&amp;cbuf);
 3173     address page = (address)$src$$constant;
 3174     Register dst_reg = as_Register($dst$$reg);
 3175     unsigned long off;
 3176     __ adrp(dst_reg, Address(page, relocInfo::poll_type), off);
 3177     assert(off == 0, &quot;assumed offset == 0&quot;);
 3178   %}
 3179 
 3180   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3181     MacroAssembler _masm(&amp;cbuf);
 3182     __ load_byte_map_base($dst$$Register);
 3183   %}
 3184 
 3185   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3186     MacroAssembler _masm(&amp;cbuf);
 3187     Register dst_reg = as_Register($dst$$reg);
 3188     address con = (address)$src$$constant;
 3189     if (con == NULL) {
 3190       ShouldNotReachHere();
 3191     } else {
 3192       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3193       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3194       __ set_narrow_oop(dst_reg, (jobject)con);
 3195     }
 3196   %}
 3197 
 3198   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3199     MacroAssembler _masm(&amp;cbuf);
 3200     Register dst_reg = as_Register($dst$$reg);
 3201     __ mov(dst_reg, zr);
 3202   %}
 3203 
 3204   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3205     MacroAssembler _masm(&amp;cbuf);
 3206     Register dst_reg = as_Register($dst$$reg);
 3207     address con = (address)$src$$constant;
 3208     if (con == NULL) {
 3209       ShouldNotReachHere();
 3210     } else {
 3211       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3212       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3213       __ set_narrow_klass(dst_reg, (Klass *)con);
 3214     }
 3215   %}
 3216 
 3217   // arithmetic encodings
 3218 
 3219   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3220     MacroAssembler _masm(&amp;cbuf);
 3221     Register dst_reg = as_Register($dst$$reg);
 3222     Register src_reg = as_Register($src1$$reg);
 3223     int32_t con = (int32_t)$src2$$constant;
 3224     // add has primary == 0, subtract has primary == 1
 3225     if ($primary) { con = -con; }
 3226     if (con &lt; 0) {
 3227       __ subw(dst_reg, src_reg, -con);
 3228     } else {
 3229       __ addw(dst_reg, src_reg, con);
 3230     }
 3231   %}
 3232 
 3233   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3234     MacroAssembler _masm(&amp;cbuf);
 3235     Register dst_reg = as_Register($dst$$reg);
 3236     Register src_reg = as_Register($src1$$reg);
 3237     int32_t con = (int32_t)$src2$$constant;
 3238     // add has primary == 0, subtract has primary == 1
 3239     if ($primary) { con = -con; }
 3240     if (con &lt; 0) {
 3241       __ sub(dst_reg, src_reg, -con);
 3242     } else {
 3243       __ add(dst_reg, src_reg, con);
 3244     }
 3245   %}
 3246 
 3247   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3248     MacroAssembler _masm(&amp;cbuf);
 3249    Register dst_reg = as_Register($dst$$reg);
 3250    Register src1_reg = as_Register($src1$$reg);
 3251    Register src2_reg = as_Register($src2$$reg);
 3252     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3253   %}
 3254 
 3255   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3256     MacroAssembler _masm(&amp;cbuf);
 3257    Register dst_reg = as_Register($dst$$reg);
 3258    Register src1_reg = as_Register($src1$$reg);
 3259    Register src2_reg = as_Register($src2$$reg);
 3260     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3261   %}
 3262 
 3263   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3264     MacroAssembler _masm(&amp;cbuf);
 3265    Register dst_reg = as_Register($dst$$reg);
 3266    Register src1_reg = as_Register($src1$$reg);
 3267    Register src2_reg = as_Register($src2$$reg);
 3268     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3269   %}
 3270 
 3271   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3272     MacroAssembler _masm(&amp;cbuf);
 3273    Register dst_reg = as_Register($dst$$reg);
 3274    Register src1_reg = as_Register($src1$$reg);
 3275    Register src2_reg = as_Register($src2$$reg);
 3276     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3277   %}
 3278 
 3279   // compare instruction encodings
 3280 
 3281   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3282     MacroAssembler _masm(&amp;cbuf);
 3283     Register reg1 = as_Register($src1$$reg);
 3284     Register reg2 = as_Register($src2$$reg);
 3285     __ cmpw(reg1, reg2);
 3286   %}
 3287 
 3288   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3289     MacroAssembler _masm(&amp;cbuf);
 3290     Register reg = as_Register($src1$$reg);
 3291     int32_t val = $src2$$constant;
 3292     if (val &gt;= 0) {
 3293       __ subsw(zr, reg, val);
 3294     } else {
 3295       __ addsw(zr, reg, -val);
 3296     }
 3297   %}
 3298 
 3299   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3300     MacroAssembler _masm(&amp;cbuf);
 3301     Register reg1 = as_Register($src1$$reg);
 3302     u_int32_t val = (u_int32_t)$src2$$constant;
 3303     __ movw(rscratch1, val);
 3304     __ cmpw(reg1, rscratch1);
 3305   %}
 3306 
 3307   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3308     MacroAssembler _masm(&amp;cbuf);
 3309     Register reg1 = as_Register($src1$$reg);
 3310     Register reg2 = as_Register($src2$$reg);
 3311     __ cmp(reg1, reg2);
 3312   %}
 3313 
 3314   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3315     MacroAssembler _masm(&amp;cbuf);
 3316     Register reg = as_Register($src1$$reg);
 3317     int64_t val = $src2$$constant;
 3318     if (val &gt;= 0) {
 3319       __ subs(zr, reg, val);
 3320     } else if (val != -val) {
 3321       __ adds(zr, reg, -val);
 3322     } else {
 3323     // aargh, Long.MIN_VALUE is a special case
 3324       __ orr(rscratch1, zr, (u_int64_t)val);
 3325       __ subs(zr, reg, rscratch1);
 3326     }
 3327   %}
 3328 
 3329   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3330     MacroAssembler _masm(&amp;cbuf);
 3331     Register reg1 = as_Register($src1$$reg);
 3332     u_int64_t val = (u_int64_t)$src2$$constant;
 3333     __ mov(rscratch1, val);
 3334     __ cmp(reg1, rscratch1);
 3335   %}
 3336 
 3337   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3338     MacroAssembler _masm(&amp;cbuf);
 3339     Register reg1 = as_Register($src1$$reg);
 3340     Register reg2 = as_Register($src2$$reg);
 3341     __ cmp(reg1, reg2);
 3342   %}
 3343 
 3344   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3345     MacroAssembler _masm(&amp;cbuf);
 3346     Register reg1 = as_Register($src1$$reg);
 3347     Register reg2 = as_Register($src2$$reg);
 3348     __ cmpw(reg1, reg2);
 3349   %}
 3350 
 3351   enc_class aarch64_enc_testp(iRegP src) %{
 3352     MacroAssembler _masm(&amp;cbuf);
 3353     Register reg = as_Register($src$$reg);
 3354     __ cmp(reg, zr);
 3355   %}
 3356 
 3357   enc_class aarch64_enc_testn(iRegN src) %{
 3358     MacroAssembler _masm(&amp;cbuf);
 3359     Register reg = as_Register($src$$reg);
 3360     __ cmpw(reg, zr);
 3361   %}
 3362 
 3363   enc_class aarch64_enc_b(label lbl) %{
 3364     MacroAssembler _masm(&amp;cbuf);
 3365     Label *L = $lbl$$label;
 3366     __ b(*L);
 3367   %}
 3368 
 3369   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3370     MacroAssembler _masm(&amp;cbuf);
 3371     Label *L = $lbl$$label;
 3372     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3373   %}
 3374 
 3375   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3376     MacroAssembler _masm(&amp;cbuf);
 3377     Label *L = $lbl$$label;
 3378     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3379   %}
 3380 
 3381   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3382   %{
 3383      Register sub_reg = as_Register($sub$$reg);
 3384      Register super_reg = as_Register($super$$reg);
 3385      Register temp_reg = as_Register($temp$$reg);
 3386      Register result_reg = as_Register($result$$reg);
 3387 
 3388      Label miss;
 3389      MacroAssembler _masm(&amp;cbuf);
 3390      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3391                                      NULL, &amp;miss,
 3392                                      /*set_cond_codes:*/ true);
 3393      if ($primary) {
 3394        __ mov(result_reg, zr);
 3395      }
 3396      __ bind(miss);
 3397   %}
 3398 
 3399   enc_class aarch64_enc_java_static_call(method meth) %{
 3400     MacroAssembler _masm(&amp;cbuf);
 3401 
 3402     address addr = (address)$meth$$method;
 3403     address call;
 3404     if (!_method) {
 3405       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3406       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3407     } else {
 3408       int method_index = resolved_method_index(cbuf);
 3409       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3410                                                   : static_call_Relocation::spec(method_index);
 3411       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3412 
 3413       // Emit stub for static call
 3414       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3415       if (stub == NULL) {
 3416         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3417         return;
 3418       }
 3419     }
 3420     if (call == NULL) {
 3421       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3422       return;
 3423     }
 3424   %}
 3425 
 3426   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3427     MacroAssembler _masm(&amp;cbuf);
 3428     int method_index = resolved_method_index(cbuf);
 3429     address call = __ ic_call((address)$meth$$method, method_index);
 3430     if (call == NULL) {
 3431       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3432       return;
 3433     }
 3434   %}
 3435 
 3436   enc_class aarch64_enc_call_epilog() %{
 3437     MacroAssembler _masm(&amp;cbuf);
 3438     if (VerifyStackAtCalls) {
 3439       // Check that stack depth is unchanged: find majik cookie on stack
 3440       __ call_Unimplemented();
 3441     }
 3442   %}
 3443 
 3444   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3445     MacroAssembler _masm(&amp;cbuf);
 3446 
 3447     // some calls to generated routines (arraycopy code) are scheduled
 3448     // by C2 as runtime calls. if so we can call them using a br (they
 3449     // will be in a reachable segment) otherwise we have to use a blr
 3450     // which loads the absolute address into a register.
 3451     address entry = (address)$meth$$method;
 3452     CodeBlob *cb = CodeCache::find_blob(entry);
 3453     if (cb) {
 3454       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3455       if (call == NULL) {
 3456         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3457         return;
 3458       }
 3459     } else {
 3460       Label retaddr;
 3461       __ adr(rscratch2, retaddr);
 3462       __ lea(rscratch1, RuntimeAddress(entry));
 3463       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3464       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3465       __ blr(rscratch1);
 3466       __ bind(retaddr);
 3467       __ add(sp, sp, 2 * wordSize);
 3468     }
 3469   %}
 3470 
 3471   enc_class aarch64_enc_rethrow() %{
 3472     MacroAssembler _masm(&amp;cbuf);
 3473     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3474   %}
 3475 
 3476   enc_class aarch64_enc_ret() %{
 3477     MacroAssembler _masm(&amp;cbuf);
 3478     __ ret(lr);
 3479   %}
 3480 
 3481   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3482     MacroAssembler _masm(&amp;cbuf);
 3483     Register target_reg = as_Register($jump_target$$reg);
 3484     __ br(target_reg);
 3485   %}
 3486 
 3487   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3488     MacroAssembler _masm(&amp;cbuf);
 3489     Register target_reg = as_Register($jump_target$$reg);
 3490     // exception oop should be in r0
 3491     // ret addr has been popped into lr
 3492     // callee expects it in r3
 3493     __ mov(r3, lr);
 3494     __ br(target_reg);
 3495   %}
 3496 
 3497   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3498     MacroAssembler _masm(&amp;cbuf);
 3499     Register oop = as_Register($object$$reg);
 3500     Register box = as_Register($box$$reg);
 3501     Register disp_hdr = as_Register($tmp$$reg);
 3502     Register tmp = as_Register($tmp2$$reg);
 3503     Label cont;
 3504     Label object_has_monitor;
 3505     Label cas_failed;
 3506 
 3507     assert_different_registers(oop, box, tmp, disp_hdr);
 3508 
 3509     // Load markWord from object into displaced_header.
 3510     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3511 
 3512     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3513       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3514     }
 3515 
 3516     // Check for existing monitor
 3517     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3518 
 3519     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3520     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3521 
 3522     // Initialize the box. (Must happen before we update the object mark!)
 3523     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3524 
 3525     // Compare object markWord with an unlocked value (tmp) and if
 3526     // equal exchange the stack address of our box with object markWord.
 3527     // On failure disp_hdr contains the possibly locked markWord.
 3528     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3529                /*release*/ true, /*weak*/ false, disp_hdr);
 3530     __ br(Assembler::EQ, cont);
 3531 
 3532     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3533 
 3534     // If the compare-and-exchange succeeded, then we found an unlocked
 3535     // object, will have now locked it will continue at label cont
 3536 
 3537     __ bind(cas_failed);
 3538     // We did not see an unlocked object so try the fast recursive case.
 3539 
 3540     // Check if the owner is self by comparing the value in the
 3541     // markWord of object (disp_hdr) with the stack pointer.
 3542     __ mov(rscratch1, sp);
 3543     __ sub(disp_hdr, disp_hdr, rscratch1);
 3544     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3545     // If condition is true we are cont and hence we can store 0 as the
 3546     // displaced header in the box, which indicates that it is a recursive lock.
 3547     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3548     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3549 
 3550     __ b(cont);
 3551 
 3552     // Handle existing monitor.
 3553     __ bind(object_has_monitor);
 3554 
 3555     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3556     // otherwise m-&gt;owner may contain a thread or a stack address.
 3557     //
 3558     // Try to CAS m-&gt;owner from NULL to current thread.
 3559     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3560     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3561                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3562 
 3563     // Store a non-null value into the box to avoid looking like a re-entrant
 3564     // lock. The fast-path monitor unlock code checks for
 3565     // markWord::monitor_value so use markWord::unused_mark which has the
 3566     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3567     __ mov(tmp, (address)markWord::unused_mark().value());
 3568     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3569 
 3570     __ bind(cont);
 3571     // flag == EQ indicates success
 3572     // flag == NE indicates failure
 3573   %}
 3574 
 3575   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3576     MacroAssembler _masm(&amp;cbuf);
 3577     Register oop = as_Register($object$$reg);
 3578     Register box = as_Register($box$$reg);
 3579     Register disp_hdr = as_Register($tmp$$reg);
 3580     Register tmp = as_Register($tmp2$$reg);
 3581     Label cont;
 3582     Label object_has_monitor;
 3583 
 3584     assert_different_registers(oop, box, tmp, disp_hdr);
 3585 
 3586     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3587       __ biased_locking_exit(oop, tmp, cont);
 3588     }
 3589 
 3590     // Find the lock address and load the displaced header from the stack.
 3591     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3592 
 3593     // If the displaced header is 0, we have a recursive unlock.
 3594     __ cmp(disp_hdr, zr);
 3595     __ br(Assembler::EQ, cont);
 3596 
 3597     // Handle existing monitor.
 3598     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3599     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3600 
 3601     // Check if it is still a light weight lock, this is is true if we
 3602     // see the stack address of the basicLock in the markWord of the
 3603     // object.
 3604 
 3605     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3606                /*release*/ true, /*weak*/ false, tmp);
 3607     __ b(cont);
 3608 
 3609     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3610 
 3611     // Handle existing monitor.
 3612     __ bind(object_has_monitor);
 3613     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3614     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3615     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3616     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3617     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3618     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3619     __ cmp(rscratch1, zr); // Sets flags for result
 3620     __ br(Assembler::NE, cont);
 3621 
 3622     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3623     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3624     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3625     __ cmp(rscratch1, zr); // Sets flags for result
 3626     __ cbnz(rscratch1, cont);
 3627     // need a release store here
 3628     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3629     __ stlr(zr, tmp); // set unowned
 3630 
 3631     __ bind(cont);
 3632     // flag == EQ indicates success
 3633     // flag == NE indicates failure
 3634   %}
 3635 
 3636 %}
 3637 
 3638 //----------FRAME--------------------------------------------------------------
 3639 // Definition of frame structure and management information.
 3640 //
 3641 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3642 //                             |   (to get allocators register number
 3643 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3644 //  r   CALLER     |        |
 3645 //  o     |        +--------+      pad to even-align allocators stack-slot
 3646 //  w     V        |  pad0  |        numbers; owned by CALLER
 3647 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3648 //  h     ^        |   in   |  5
 3649 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3650 //  |     |        |        |  3
 3651 //  |     |        +--------+
 3652 //  V     |        | old out|      Empty on Intel, window on Sparc
 3653 //        |    old |preserve|      Must be even aligned.
 3654 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3655 //        |        |   in   |  3   area for Intel ret address
 3656 //     Owned by    |preserve|      Empty on Sparc.
 3657 //       SELF      +--------+
 3658 //        |        |  pad2  |  2   pad to align old SP
 3659 //        |        +--------+  1
 3660 //        |        | locks  |  0
 3661 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3662 //        |        |  pad1  | 11   pad to align new SP
 3663 //        |        +--------+
 3664 //        |        |        | 10
 3665 //        |        | spills |  9   spills
 3666 //        V        |        |  8   (pad0 slot for callee)
 3667 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3668 //        ^        |  out   |  7
 3669 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3670 //     Owned by    +--------+
 3671 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3672 //        |    new |preserve|      Must be even-aligned.
 3673 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3674 //        |        |        |
 3675 //
 3676 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3677 //         known from SELF&#39;s arguments and the Java calling convention.
 3678 //         Region 6-7 is determined per call site.
 3679 // Note 2: If the calling convention leaves holes in the incoming argument
 3680 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3681 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3682 //         incoming area, as the Java calling convention is completely under
 3683 //         the control of the AD file.  Doubles can be sorted and packed to
 3684 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3685 //         varargs C calling conventions.
 3686 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3687 //         even aligned with pad0 as needed.
 3688 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3689 //           (the latter is true on Intel but is it false on AArch64?)
 3690 //         region 6-11 is even aligned; it may be padded out more so that
 3691 //         the region from SP to FP meets the minimum stack alignment.
 3692 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3693 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3694 //         SP meets the minimum alignment.
 3695 
 3696 frame %{
 3697   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3698   stack_direction(TOWARDS_LOW);
 3699 
 3700   // These three registers define part of the calling convention
 3701   // between compiled code and the interpreter.
 3702 
 3703   // Inline Cache Register or methodOop for I2C.
 3704   inline_cache_reg(R12);
 3705 
 3706   // Method Oop Register when calling interpreter.
 3707   interpreter_method_oop_reg(R12);
 3708 
 3709   // Number of stack slots consumed by locking an object
 3710   sync_stack_slots(2);
 3711 
 3712   // Compiled code&#39;s Frame Pointer
 3713   frame_pointer(R31);
 3714 
 3715   // Interpreter stores its frame pointer in a register which is
 3716   // stored to the stack by I2CAdaptors.
 3717   // I2CAdaptors convert from interpreted java to compiled java.
 3718   interpreter_frame_pointer(R29);
 3719 
 3720   // Stack alignment requirement
 3721   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3722 
 3723   // Number of stack slots between incoming argument block and the start of
 3724   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3725   // EPILOG must remove this many slots. aarch64 needs two slots for
 3726   // return address and fp.
 3727   // TODO think this is correct but check
 3728   in_preserve_stack_slots(4);
 3729 
 3730   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3731   // for calls to C.  Supports the var-args backing area for register parms.
 3732   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3733 
 3734   // The after-PROLOG location of the return address.  Location of
 3735   // return address specifies a type (REG or STACK) and a number
 3736   // representing the register number (i.e. - use a register name) or
 3737   // stack slot.
 3738   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3739   // Otherwise, it is above the locks and verification slot and alignment word
 3740   // TODO this may well be correct but need to check why that - 2 is there
 3741   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3742   // which folds in the space used for monitors
 3743   return_addr(STACK - 2 +
 3744               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3745                         Compile::current()-&gt;fixed_slots()),
 3746                        stack_alignment_in_slots()));
 3747 
 3748   // Body of function which returns an integer array locating
 3749   // arguments either in registers or in stack slots.  Passed an array
 3750   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3751   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3752   // arguments for a CALLEE.  Incoming stack arguments are
 3753   // automatically biased by the preserve_stack_slots field above.
 3754 
 3755   calling_convention
 3756   %{
 3757     // No difference between ingoing/outgoing just pass false
 3758     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3759   %}
 3760 
 3761   c_calling_convention
 3762   %{
 3763     // This is obviously always outgoing
 3764     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3765   %}
 3766 
 3767   // Location of compiled Java return values.  Same as C for now.
 3768   return_value
 3769   %{
 3770     // TODO do we allow ideal_reg == Op_RegN???
 3771     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3772            &quot;only return normal values&quot;);
 3773 
 3774     static const int lo[Op_RegL + 1] = { // enum name
 3775       0,                                 // Op_Node
 3776       0,                                 // Op_Set
 3777       R0_num,                            // Op_RegN
 3778       R0_num,                            // Op_RegI
 3779       R0_num,                            // Op_RegP
 3780       V0_num,                            // Op_RegF
 3781       V0_num,                            // Op_RegD
 3782       R0_num                             // Op_RegL
 3783     };
 3784 
 3785     static const int hi[Op_RegL + 1] = { // enum name
 3786       0,                                 // Op_Node
 3787       0,                                 // Op_Set
 3788       OptoReg::Bad,                      // Op_RegN
 3789       OptoReg::Bad,                      // Op_RegI
 3790       R0_H_num,                          // Op_RegP
 3791       OptoReg::Bad,                      // Op_RegF
 3792       V0_H_num,                          // Op_RegD
 3793       R0_H_num                           // Op_RegL
 3794     };
 3795 
 3796     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3797   %}
 3798 %}
 3799 
 3800 //----------ATTRIBUTES---------------------------------------------------------
 3801 //----------Operand Attributes-------------------------------------------------
 3802 op_attrib op_cost(1);        // Required cost attribute
 3803 
 3804 //----------Instruction Attributes---------------------------------------------
 3805 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3806 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3807 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3808                                 // a non-matching short branch variant
 3809                                 // of some long branch?
 3810 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3811                                 // be a power of 2) specifies the
 3812                                 // alignment that some part of the
 3813                                 // instruction (not necessarily the
 3814                                 // start) requires.  If &gt; 1, a
 3815                                 // compute_padding() function must be
 3816                                 // provided for the instruction
 3817 
 3818 //----------OPERANDS-----------------------------------------------------------
 3819 // Operand definitions must precede instruction definitions for correct parsing
 3820 // in the ADLC because operands constitute user defined types which are used in
 3821 // instruction definitions.
 3822 
 3823 //----------Simple Operands----------------------------------------------------
 3824 
 3825 // Integer operands 32 bit
 3826 // 32 bit immediate
 3827 operand immI()
 3828 %{
 3829   match(ConI);
 3830 
 3831   op_cost(0);
 3832   format %{ %}
 3833   interface(CONST_INTER);
 3834 %}
 3835 
 3836 // 32 bit zero
 3837 operand immI0()
 3838 %{
 3839   predicate(n-&gt;get_int() == 0);
 3840   match(ConI);
 3841 
 3842   op_cost(0);
 3843   format %{ %}
 3844   interface(CONST_INTER);
 3845 %}
 3846 
 3847 // 32 bit unit increment
 3848 operand immI_1()
 3849 %{
 3850   predicate(n-&gt;get_int() == 1);
 3851   match(ConI);
 3852 
 3853   op_cost(0);
 3854   format %{ %}
 3855   interface(CONST_INTER);
 3856 %}
 3857 
 3858 // 32 bit unit decrement
 3859 operand immI_M1()
 3860 %{
 3861   predicate(n-&gt;get_int() == -1);
 3862   match(ConI);
 3863 
 3864   op_cost(0);
 3865   format %{ %}
 3866   interface(CONST_INTER);
 3867 %}
 3868 
 3869 // Shift values for add/sub extension shift
 3870 operand immIExt()
 3871 %{
 3872   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3873   match(ConI);
 3874 
 3875   op_cost(0);
 3876   format %{ %}
 3877   interface(CONST_INTER);
 3878 %}
 3879 
 3880 operand immI_le_4()
 3881 %{
 3882   predicate(n-&gt;get_int() &lt;= 4);
 3883   match(ConI);
 3884 
 3885   op_cost(0);
 3886   format %{ %}
 3887   interface(CONST_INTER);
 3888 %}
 3889 
 3890 operand immI_31()
 3891 %{
 3892   predicate(n-&gt;get_int() == 31);
 3893   match(ConI);
 3894 
 3895   op_cost(0);
 3896   format %{ %}
 3897   interface(CONST_INTER);
 3898 %}
 3899 
 3900 operand immI_8()
 3901 %{
 3902   predicate(n-&gt;get_int() == 8);
 3903   match(ConI);
 3904 
 3905   op_cost(0);
 3906   format %{ %}
 3907   interface(CONST_INTER);
 3908 %}
 3909 
 3910 operand immI_16()
 3911 %{
 3912   predicate(n-&gt;get_int() == 16);
 3913   match(ConI);
 3914 
 3915   op_cost(0);
 3916   format %{ %}
 3917   interface(CONST_INTER);
 3918 %}
 3919 
 3920 operand immI_24()
 3921 %{
 3922   predicate(n-&gt;get_int() == 24);
 3923   match(ConI);
 3924 
 3925   op_cost(0);
 3926   format %{ %}
 3927   interface(CONST_INTER);
 3928 %}
 3929 
 3930 operand immI_32()
 3931 %{
 3932   predicate(n-&gt;get_int() == 32);
 3933   match(ConI);
 3934 
 3935   op_cost(0);
 3936   format %{ %}
 3937   interface(CONST_INTER);
 3938 %}
 3939 
 3940 operand immI_48()
 3941 %{
 3942   predicate(n-&gt;get_int() == 48);
 3943   match(ConI);
 3944 
 3945   op_cost(0);
 3946   format %{ %}
 3947   interface(CONST_INTER);
 3948 %}
 3949 
 3950 operand immI_56()
 3951 %{
 3952   predicate(n-&gt;get_int() == 56);
 3953   match(ConI);
 3954 
 3955   op_cost(0);
 3956   format %{ %}
 3957   interface(CONST_INTER);
 3958 %}
 3959 
 3960 operand immI_63()
 3961 %{
 3962   predicate(n-&gt;get_int() == 63);
 3963   match(ConI);
 3964 
 3965   op_cost(0);
 3966   format %{ %}
 3967   interface(CONST_INTER);
 3968 %}
 3969 
 3970 operand immI_64()
 3971 %{
 3972   predicate(n-&gt;get_int() == 64);
 3973   match(ConI);
 3974 
 3975   op_cost(0);
 3976   format %{ %}
 3977   interface(CONST_INTER);
 3978 %}
 3979 
 3980 operand immI_255()
 3981 %{
 3982   predicate(n-&gt;get_int() == 255);
 3983   match(ConI);
 3984 
 3985   op_cost(0);
 3986   format %{ %}
 3987   interface(CONST_INTER);
 3988 %}
 3989 
 3990 operand immI_65535()
 3991 %{
 3992   predicate(n-&gt;get_int() == 65535);
 3993   match(ConI);
 3994 
 3995   op_cost(0);
 3996   format %{ %}
 3997   interface(CONST_INTER);
 3998 %}
 3999 
 4000 operand immL_255()
 4001 %{
 4002   predicate(n-&gt;get_long() == 255L);
 4003   match(ConL);
 4004 
 4005   op_cost(0);
 4006   format %{ %}
 4007   interface(CONST_INTER);
 4008 %}
 4009 
 4010 operand immL_65535()
 4011 %{
 4012   predicate(n-&gt;get_long() == 65535L);
 4013   match(ConL);
 4014 
 4015   op_cost(0);
 4016   format %{ %}
 4017   interface(CONST_INTER);
 4018 %}
 4019 
 4020 operand immL_4294967295()
 4021 %{
 4022   predicate(n-&gt;get_long() == 4294967295L);
 4023   match(ConL);
 4024 
 4025   op_cost(0);
 4026   format %{ %}
 4027   interface(CONST_INTER);
 4028 %}
 4029 
 4030 operand immL_bitmask()
 4031 %{
 4032   predicate((n-&gt;get_long() != 0)
 4033             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4034             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4035   match(ConL);
 4036 
 4037   op_cost(0);
 4038   format %{ %}
 4039   interface(CONST_INTER);
 4040 %}
 4041 
 4042 operand immI_bitmask()
 4043 %{
 4044   predicate((n-&gt;get_int() != 0)
 4045             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4046             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4047   match(ConI);
 4048 
 4049   op_cost(0);
 4050   format %{ %}
 4051   interface(CONST_INTER);
 4052 %}
 4053 
 4054 // Scale values for scaled offset addressing modes (up to long but not quad)
 4055 operand immIScale()
 4056 %{
 4057   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4058   match(ConI);
 4059 
 4060   op_cost(0);
 4061   format %{ %}
 4062   interface(CONST_INTER);
 4063 %}
 4064 
 4065 // 26 bit signed offset -- for pc-relative branches
 4066 operand immI26()
 4067 %{
 4068   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4069   match(ConI);
 4070 
 4071   op_cost(0);
 4072   format %{ %}
 4073   interface(CONST_INTER);
 4074 %}
 4075 
 4076 // 19 bit signed offset -- for pc-relative loads
 4077 operand immI19()
 4078 %{
 4079   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4080   match(ConI);
 4081 
 4082   op_cost(0);
 4083   format %{ %}
 4084   interface(CONST_INTER);
 4085 %}
 4086 
 4087 // 12 bit unsigned offset -- for base plus immediate loads
 4088 operand immIU12()
 4089 %{
 4090   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4091   match(ConI);
 4092 
 4093   op_cost(0);
 4094   format %{ %}
 4095   interface(CONST_INTER);
 4096 %}
 4097 
 4098 operand immLU12()
 4099 %{
 4100   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4101   match(ConL);
 4102 
 4103   op_cost(0);
 4104   format %{ %}
 4105   interface(CONST_INTER);
 4106 %}
 4107 
 4108 // Offset for scaled or unscaled immediate loads and stores
 4109 operand immIOffset()
 4110 %{
 4111   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4112   match(ConI);
 4113 
 4114   op_cost(0);
 4115   format %{ %}
 4116   interface(CONST_INTER);
 4117 %}
 4118 
 4119 operand immIOffset1()
 4120 %{
 4121   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4122   match(ConI);
 4123 
 4124   op_cost(0);
 4125   format %{ %}
 4126   interface(CONST_INTER);
 4127 %}
 4128 
 4129 operand immIOffset2()
 4130 %{
 4131   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4132   match(ConI);
 4133 
 4134   op_cost(0);
 4135   format %{ %}
 4136   interface(CONST_INTER);
 4137 %}
 4138 
 4139 operand immIOffset4()
 4140 %{
 4141   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4142   match(ConI);
 4143 
 4144   op_cost(0);
 4145   format %{ %}
 4146   interface(CONST_INTER);
 4147 %}
 4148 
 4149 operand immIOffset8()
 4150 %{
 4151   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4152   match(ConI);
 4153 
 4154   op_cost(0);
 4155   format %{ %}
 4156   interface(CONST_INTER);
 4157 %}
 4158 
 4159 operand immIOffset16()
 4160 %{
 4161   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4162   match(ConI);
 4163 
 4164   op_cost(0);
 4165   format %{ %}
 4166   interface(CONST_INTER);
 4167 %}
 4168 
 4169 operand immLoffset()
 4170 %{
 4171   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4172   match(ConL);
 4173 
 4174   op_cost(0);
 4175   format %{ %}
 4176   interface(CONST_INTER);
 4177 %}
 4178 
 4179 operand immLoffset1()
 4180 %{
 4181   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4182   match(ConL);
 4183 
 4184   op_cost(0);
 4185   format %{ %}
 4186   interface(CONST_INTER);
 4187 %}
 4188 
 4189 operand immLoffset2()
 4190 %{
 4191   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4192   match(ConL);
 4193 
 4194   op_cost(0);
 4195   format %{ %}
 4196   interface(CONST_INTER);
 4197 %}
 4198 
 4199 operand immLoffset4()
 4200 %{
 4201   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4202   match(ConL);
 4203 
 4204   op_cost(0);
 4205   format %{ %}
 4206   interface(CONST_INTER);
 4207 %}
 4208 
 4209 operand immLoffset8()
 4210 %{
 4211   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4212   match(ConL);
 4213 
 4214   op_cost(0);
 4215   format %{ %}
 4216   interface(CONST_INTER);
 4217 %}
 4218 
 4219 operand immLoffset16()
 4220 %{
 4221   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4222   match(ConL);
 4223 
 4224   op_cost(0);
 4225   format %{ %}
 4226   interface(CONST_INTER);
 4227 %}
 4228 
 4229 // 32 bit integer valid for add sub immediate
 4230 operand immIAddSub()
 4231 %{
 4232   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4233   match(ConI);
 4234   op_cost(0);
 4235   format %{ %}
 4236   interface(CONST_INTER);
 4237 %}
 4238 
 4239 // 32 bit unsigned integer valid for logical immediate
 4240 // TODO -- check this is right when e.g the mask is 0x80000000
 4241 operand immILog()
 4242 %{
 4243   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4244   match(ConI);
 4245 
 4246   op_cost(0);
 4247   format %{ %}
 4248   interface(CONST_INTER);
 4249 %}
 4250 
 4251 // Integer operands 64 bit
 4252 // 64 bit immediate
 4253 operand immL()
 4254 %{
 4255   match(ConL);
 4256 
 4257   op_cost(0);
 4258   format %{ %}
 4259   interface(CONST_INTER);
 4260 %}
 4261 
 4262 // 64 bit zero
 4263 operand immL0()
 4264 %{
 4265   predicate(n-&gt;get_long() == 0);
 4266   match(ConL);
 4267 
 4268   op_cost(0);
 4269   format %{ %}
 4270   interface(CONST_INTER);
 4271 %}
 4272 
 4273 // 64 bit unit increment
 4274 operand immL_1()
 4275 %{
 4276   predicate(n-&gt;get_long() == 1);
 4277   match(ConL);
 4278 
 4279   op_cost(0);
 4280   format %{ %}
 4281   interface(CONST_INTER);
 4282 %}
 4283 
 4284 // 64 bit unit decrement
 4285 operand immL_M1()
 4286 %{
 4287   predicate(n-&gt;get_long() == -1);
 4288   match(ConL);
 4289 
 4290   op_cost(0);
 4291   format %{ %}
 4292   interface(CONST_INTER);
 4293 %}
 4294 
 4295 // 32 bit offset of pc in thread anchor
 4296 
 4297 operand immL_pc_off()
 4298 %{
 4299   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4300                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4301   match(ConL);
 4302 
 4303   op_cost(0);
 4304   format %{ %}
 4305   interface(CONST_INTER);
 4306 %}
 4307 
 4308 // 64 bit integer valid for add sub immediate
 4309 operand immLAddSub()
 4310 %{
 4311   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4312   match(ConL);
 4313   op_cost(0);
 4314   format %{ %}
 4315   interface(CONST_INTER);
 4316 %}
 4317 
 4318 // 64 bit integer valid for logical immediate
 4319 operand immLLog()
 4320 %{
 4321   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4322   match(ConL);
 4323   op_cost(0);
 4324   format %{ %}
 4325   interface(CONST_INTER);
 4326 %}
 4327 
 4328 // Long Immediate: low 32-bit mask
 4329 operand immL_32bits()
 4330 %{
 4331   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4332   match(ConL);
 4333   op_cost(0);
 4334   format %{ %}
 4335   interface(CONST_INTER);
 4336 %}
 4337 
 4338 // Pointer operands
 4339 // Pointer Immediate
 4340 operand immP()
 4341 %{
 4342   match(ConP);
 4343 
 4344   op_cost(0);
 4345   format %{ %}
 4346   interface(CONST_INTER);
 4347 %}
 4348 
 4349 // NULL Pointer Immediate
 4350 operand immP0()
 4351 %{
 4352   predicate(n-&gt;get_ptr() == 0);
 4353   match(ConP);
 4354 
 4355   op_cost(0);
 4356   format %{ %}
 4357   interface(CONST_INTER);
 4358 %}
 4359 
 4360 // Pointer Immediate One
 4361 // this is used in object initialization (initial object header)
 4362 operand immP_1()
 4363 %{
 4364   predicate(n-&gt;get_ptr() == 1);
 4365   match(ConP);
 4366 
 4367   op_cost(0);
 4368   format %{ %}
 4369   interface(CONST_INTER);
 4370 %}
 4371 
 4372 // Polling Page Pointer Immediate
 4373 operand immPollPage()
 4374 %{
 4375   predicate((address)n-&gt;get_ptr() == os::get_polling_page());
 4376   match(ConP);
 4377 
 4378   op_cost(0);
 4379   format %{ %}
 4380   interface(CONST_INTER);
 4381 %}
 4382 
 4383 // Card Table Byte Map Base
 4384 operand immByteMapBase()
 4385 %{
 4386   // Get base of card map
 4387   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4388             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4389   match(ConP);
 4390 
 4391   op_cost(0);
 4392   format %{ %}
 4393   interface(CONST_INTER);
 4394 %}
 4395 
 4396 // Pointer Immediate Minus One
 4397 // this is used when we want to write the current PC to the thread anchor
 4398 operand immP_M1()
 4399 %{
 4400   predicate(n-&gt;get_ptr() == -1);
 4401   match(ConP);
 4402 
 4403   op_cost(0);
 4404   format %{ %}
 4405   interface(CONST_INTER);
 4406 %}
 4407 
 4408 // Pointer Immediate Minus Two
 4409 // this is used when we want to write the current PC to the thread anchor
 4410 operand immP_M2()
 4411 %{
 4412   predicate(n-&gt;get_ptr() == -2);
 4413   match(ConP);
 4414 
 4415   op_cost(0);
 4416   format %{ %}
 4417   interface(CONST_INTER);
 4418 %}
 4419 
 4420 // Float and Double operands
 4421 // Double Immediate
 4422 operand immD()
 4423 %{
 4424   match(ConD);
 4425   op_cost(0);
 4426   format %{ %}
 4427   interface(CONST_INTER);
 4428 %}
 4429 
 4430 // Double Immediate: +0.0d
 4431 operand immD0()
 4432 %{
 4433   predicate(jlong_cast(n-&gt;getd()) == 0);
 4434   match(ConD);
 4435 
 4436   op_cost(0);
 4437   format %{ %}
 4438   interface(CONST_INTER);
 4439 %}
 4440 
 4441 // constant &#39;double +0.0&#39;.
 4442 operand immDPacked()
 4443 %{
 4444   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4445   match(ConD);
 4446   op_cost(0);
 4447   format %{ %}
 4448   interface(CONST_INTER);
 4449 %}
 4450 
 4451 // Float Immediate
 4452 operand immF()
 4453 %{
 4454   match(ConF);
 4455   op_cost(0);
 4456   format %{ %}
 4457   interface(CONST_INTER);
 4458 %}
 4459 
 4460 // Float Immediate: +0.0f.
 4461 operand immF0()
 4462 %{
 4463   predicate(jint_cast(n-&gt;getf()) == 0);
 4464   match(ConF);
 4465 
 4466   op_cost(0);
 4467   format %{ %}
 4468   interface(CONST_INTER);
 4469 %}
 4470 
 4471 //
 4472 operand immFPacked()
 4473 %{
 4474   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4475   match(ConF);
 4476   op_cost(0);
 4477   format %{ %}
 4478   interface(CONST_INTER);
 4479 %}
 4480 
 4481 // Narrow pointer operands
 4482 // Narrow Pointer Immediate
 4483 operand immN()
 4484 %{
 4485   match(ConN);
 4486 
 4487   op_cost(0);
 4488   format %{ %}
 4489   interface(CONST_INTER);
 4490 %}
 4491 
 4492 // Narrow NULL Pointer Immediate
 4493 operand immN0()
 4494 %{
 4495   predicate(n-&gt;get_narrowcon() == 0);
 4496   match(ConN);
 4497 
 4498   op_cost(0);
 4499   format %{ %}
 4500   interface(CONST_INTER);
 4501 %}
 4502 
 4503 operand immNKlass()
 4504 %{
 4505   match(ConNKlass);
 4506 
 4507   op_cost(0);
 4508   format %{ %}
 4509   interface(CONST_INTER);
 4510 %}
 4511 
 4512 // Integer 32 bit Register Operands
 4513 // Integer 32 bitRegister (excludes SP)
 4514 operand iRegI()
 4515 %{
 4516   constraint(ALLOC_IN_RC(any_reg32));
 4517   match(RegI);
 4518   match(iRegINoSp);
 4519   op_cost(0);
 4520   format %{ %}
 4521   interface(REG_INTER);
 4522 %}
 4523 
 4524 // Integer 32 bit Register not Special
 4525 operand iRegINoSp()
 4526 %{
 4527   constraint(ALLOC_IN_RC(no_special_reg32));
 4528   match(RegI);
 4529   op_cost(0);
 4530   format %{ %}
 4531   interface(REG_INTER);
 4532 %}
 4533 
 4534 // Integer 64 bit Register Operands
 4535 // Integer 64 bit Register (includes SP)
 4536 operand iRegL()
 4537 %{
 4538   constraint(ALLOC_IN_RC(any_reg));
 4539   match(RegL);
 4540   match(iRegLNoSp);
 4541   op_cost(0);
 4542   format %{ %}
 4543   interface(REG_INTER);
 4544 %}
 4545 
 4546 // Integer 64 bit Register not Special
 4547 operand iRegLNoSp()
 4548 %{
 4549   constraint(ALLOC_IN_RC(no_special_reg));
 4550   match(RegL);
 4551   match(iRegL_R0);
 4552   format %{ %}
 4553   interface(REG_INTER);
 4554 %}
 4555 
 4556 // Pointer Register Operands
 4557 // Pointer Register
 4558 operand iRegP()
 4559 %{
 4560   constraint(ALLOC_IN_RC(ptr_reg));
 4561   match(RegP);
 4562   match(iRegPNoSp);
 4563   match(iRegP_R0);
 4564   //match(iRegP_R2);
 4565   //match(iRegP_R4);
 4566   //match(iRegP_R5);
 4567   match(thread_RegP);
 4568   op_cost(0);
 4569   format %{ %}
 4570   interface(REG_INTER);
 4571 %}
 4572 
 4573 // Pointer 64 bit Register not Special
 4574 operand iRegPNoSp()
 4575 %{
 4576   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4577   match(RegP);
 4578   // match(iRegP);
 4579   // match(iRegP_R0);
 4580   // match(iRegP_R2);
 4581   // match(iRegP_R4);
 4582   // match(iRegP_R5);
 4583   // match(thread_RegP);
 4584   op_cost(0);
 4585   format %{ %}
 4586   interface(REG_INTER);
 4587 %}
 4588 
 4589 // Pointer 64 bit Register R0 only
 4590 operand iRegP_R0()
 4591 %{
 4592   constraint(ALLOC_IN_RC(r0_reg));
 4593   match(RegP);
 4594   // match(iRegP);
 4595   match(iRegPNoSp);
 4596   op_cost(0);
 4597   format %{ %}
 4598   interface(REG_INTER);
 4599 %}
 4600 
 4601 // Pointer 64 bit Register R1 only
 4602 operand iRegP_R1()
 4603 %{
 4604   constraint(ALLOC_IN_RC(r1_reg));
 4605   match(RegP);
 4606   // match(iRegP);
 4607   match(iRegPNoSp);
 4608   op_cost(0);
 4609   format %{ %}
 4610   interface(REG_INTER);
 4611 %}
 4612 
 4613 // Pointer 64 bit Register R2 only
 4614 operand iRegP_R2()
 4615 %{
 4616   constraint(ALLOC_IN_RC(r2_reg));
 4617   match(RegP);
 4618   // match(iRegP);
 4619   match(iRegPNoSp);
 4620   op_cost(0);
 4621   format %{ %}
 4622   interface(REG_INTER);
 4623 %}
 4624 
 4625 // Pointer 64 bit Register R3 only
 4626 operand iRegP_R3()
 4627 %{
 4628   constraint(ALLOC_IN_RC(r3_reg));
 4629   match(RegP);
 4630   // match(iRegP);
 4631   match(iRegPNoSp);
 4632   op_cost(0);
 4633   format %{ %}
 4634   interface(REG_INTER);
 4635 %}
 4636 
 4637 // Pointer 64 bit Register R4 only
 4638 operand iRegP_R4()
 4639 %{
 4640   constraint(ALLOC_IN_RC(r4_reg));
 4641   match(RegP);
 4642   // match(iRegP);
 4643   match(iRegPNoSp);
 4644   op_cost(0);
 4645   format %{ %}
 4646   interface(REG_INTER);
 4647 %}
 4648 
 4649 // Pointer 64 bit Register R5 only
 4650 operand iRegP_R5()
 4651 %{
 4652   constraint(ALLOC_IN_RC(r5_reg));
 4653   match(RegP);
 4654   // match(iRegP);
 4655   match(iRegPNoSp);
 4656   op_cost(0);
 4657   format %{ %}
 4658   interface(REG_INTER);
 4659 %}
 4660 
 4661 // Pointer 64 bit Register R10 only
 4662 operand iRegP_R10()
 4663 %{
 4664   constraint(ALLOC_IN_RC(r10_reg));
 4665   match(RegP);
 4666   // match(iRegP);
 4667   match(iRegPNoSp);
 4668   op_cost(0);
 4669   format %{ %}
 4670   interface(REG_INTER);
 4671 %}
 4672 
 4673 // Long 64 bit Register R0 only
 4674 operand iRegL_R0()
 4675 %{
 4676   constraint(ALLOC_IN_RC(r0_reg));
 4677   match(RegL);
 4678   match(iRegLNoSp);
 4679   op_cost(0);
 4680   format %{ %}
 4681   interface(REG_INTER);
 4682 %}
 4683 
 4684 // Long 64 bit Register R2 only
 4685 operand iRegL_R2()
 4686 %{
 4687   constraint(ALLOC_IN_RC(r2_reg));
 4688   match(RegL);
 4689   match(iRegLNoSp);
 4690   op_cost(0);
 4691   format %{ %}
 4692   interface(REG_INTER);
 4693 %}
 4694 
 4695 // Long 64 bit Register R3 only
 4696 operand iRegL_R3()
 4697 %{
 4698   constraint(ALLOC_IN_RC(r3_reg));
 4699   match(RegL);
 4700   match(iRegLNoSp);
 4701   op_cost(0);
 4702   format %{ %}
 4703   interface(REG_INTER);
 4704 %}
 4705 
 4706 // Long 64 bit Register R11 only
 4707 operand iRegL_R11()
 4708 %{
 4709   constraint(ALLOC_IN_RC(r11_reg));
 4710   match(RegL);
 4711   match(iRegLNoSp);
 4712   op_cost(0);
 4713   format %{ %}
 4714   interface(REG_INTER);
 4715 %}
 4716 
 4717 // Pointer 64 bit Register FP only
 4718 operand iRegP_FP()
 4719 %{
 4720   constraint(ALLOC_IN_RC(fp_reg));
 4721   match(RegP);
 4722   // match(iRegP);
 4723   op_cost(0);
 4724   format %{ %}
 4725   interface(REG_INTER);
 4726 %}
 4727 
 4728 // Register R0 only
 4729 operand iRegI_R0()
 4730 %{
 4731   constraint(ALLOC_IN_RC(int_r0_reg));
 4732   match(RegI);
 4733   match(iRegINoSp);
 4734   op_cost(0);
 4735   format %{ %}
 4736   interface(REG_INTER);
 4737 %}
 4738 
 4739 // Register R2 only
 4740 operand iRegI_R2()
 4741 %{
 4742   constraint(ALLOC_IN_RC(int_r2_reg));
 4743   match(RegI);
 4744   match(iRegINoSp);
 4745   op_cost(0);
 4746   format %{ %}
 4747   interface(REG_INTER);
 4748 %}
 4749 
 4750 // Register R3 only
 4751 operand iRegI_R3()
 4752 %{
 4753   constraint(ALLOC_IN_RC(int_r3_reg));
 4754   match(RegI);
 4755   match(iRegINoSp);
 4756   op_cost(0);
 4757   format %{ %}
 4758   interface(REG_INTER);
 4759 %}
 4760 
 4761 
 4762 // Register R4 only
 4763 operand iRegI_R4()
 4764 %{
 4765   constraint(ALLOC_IN_RC(int_r4_reg));
 4766   match(RegI);
 4767   match(iRegINoSp);
 4768   op_cost(0);
 4769   format %{ %}
 4770   interface(REG_INTER);
 4771 %}
 4772 
 4773 
 4774 // Pointer Register Operands
 4775 // Narrow Pointer Register
 4776 operand iRegN()
 4777 %{
 4778   constraint(ALLOC_IN_RC(any_reg32));
 4779   match(RegN);
 4780   match(iRegNNoSp);
 4781   op_cost(0);
 4782   format %{ %}
 4783   interface(REG_INTER);
 4784 %}
 4785 
 4786 operand iRegN_R0()
 4787 %{
 4788   constraint(ALLOC_IN_RC(r0_reg));
 4789   match(iRegN);
 4790   op_cost(0);
 4791   format %{ %}
 4792   interface(REG_INTER);
 4793 %}
 4794 
 4795 operand iRegN_R2()
 4796 %{
 4797   constraint(ALLOC_IN_RC(r2_reg));
 4798   match(iRegN);
 4799   op_cost(0);
 4800   format %{ %}
 4801   interface(REG_INTER);
 4802 %}
 4803 
 4804 operand iRegN_R3()
 4805 %{
 4806   constraint(ALLOC_IN_RC(r3_reg));
 4807   match(iRegN);
 4808   op_cost(0);
 4809   format %{ %}
 4810   interface(REG_INTER);
 4811 %}
 4812 
 4813 // Integer 64 bit Register not Special
 4814 operand iRegNNoSp()
 4815 %{
 4816   constraint(ALLOC_IN_RC(no_special_reg32));
 4817   match(RegN);
 4818   op_cost(0);
 4819   format %{ %}
 4820   interface(REG_INTER);
 4821 %}
 4822 
 4823 // heap base register -- used for encoding immN0
 4824 
 4825 operand iRegIHeapbase()
 4826 %{
 4827   constraint(ALLOC_IN_RC(heapbase_reg));
 4828   match(RegI);
 4829   op_cost(0);
 4830   format %{ %}
 4831   interface(REG_INTER);
 4832 %}
 4833 
 4834 // Float Register
 4835 // Float register operands
 4836 operand vRegF()
 4837 %{
 4838   constraint(ALLOC_IN_RC(float_reg));
 4839   match(RegF);
 4840 
 4841   op_cost(0);
 4842   format %{ %}
 4843   interface(REG_INTER);
 4844 %}
 4845 
 4846 // Double Register
 4847 // Double register operands
 4848 operand vRegD()
 4849 %{
 4850   constraint(ALLOC_IN_RC(double_reg));
 4851   match(RegD);
 4852 
 4853   op_cost(0);
 4854   format %{ %}
 4855   interface(REG_INTER);
 4856 %}
 4857 
 4858 operand vecD()
 4859 %{
 4860   constraint(ALLOC_IN_RC(vectord_reg));
 4861   match(VecD);
 4862 
 4863   op_cost(0);
 4864   format %{ %}
 4865   interface(REG_INTER);
 4866 %}
 4867 
 4868 operand vecX()
 4869 %{
 4870   constraint(ALLOC_IN_RC(vectorx_reg));
 4871   match(VecX);
 4872 
 4873   op_cost(0);
 4874   format %{ %}
 4875   interface(REG_INTER);
 4876 %}
 4877 
 4878 operand vRegD_V0()
 4879 %{
 4880   constraint(ALLOC_IN_RC(v0_reg));
 4881   match(RegD);
 4882   op_cost(0);
 4883   format %{ %}
 4884   interface(REG_INTER);
 4885 %}
 4886 
 4887 operand vRegD_V1()
 4888 %{
 4889   constraint(ALLOC_IN_RC(v1_reg));
 4890   match(RegD);
 4891   op_cost(0);
 4892   format %{ %}
 4893   interface(REG_INTER);
 4894 %}
 4895 
 4896 operand vRegD_V2()
 4897 %{
 4898   constraint(ALLOC_IN_RC(v2_reg));
 4899   match(RegD);
 4900   op_cost(0);
 4901   format %{ %}
 4902   interface(REG_INTER);
 4903 %}
 4904 
 4905 operand vRegD_V3()
 4906 %{
 4907   constraint(ALLOC_IN_RC(v3_reg));
 4908   match(RegD);
 4909   op_cost(0);
 4910   format %{ %}
 4911   interface(REG_INTER);
 4912 %}
 4913 
 4914 operand vRegD_V4()
 4915 %{
 4916   constraint(ALLOC_IN_RC(v4_reg));
 4917   match(RegD);
 4918   op_cost(0);
 4919   format %{ %}
 4920   interface(REG_INTER);
 4921 %}
 4922 
 4923 operand vRegD_V5()
 4924 %{
 4925   constraint(ALLOC_IN_RC(v5_reg));
 4926   match(RegD);
 4927   op_cost(0);
 4928   format %{ %}
 4929   interface(REG_INTER);
 4930 %}
 4931 
 4932 operand vRegD_V6()
 4933 %{
 4934   constraint(ALLOC_IN_RC(v6_reg));
 4935   match(RegD);
 4936   op_cost(0);
 4937   format %{ %}
 4938   interface(REG_INTER);
 4939 %}
 4940 
 4941 operand vRegD_V7()
 4942 %{
 4943   constraint(ALLOC_IN_RC(v7_reg));
 4944   match(RegD);
 4945   op_cost(0);
 4946   format %{ %}
 4947   interface(REG_INTER);
 4948 %}
 4949 
 4950 operand vRegD_V8()
 4951 %{
 4952   constraint(ALLOC_IN_RC(v8_reg));
 4953   match(RegD);
 4954   op_cost(0);
 4955   format %{ %}
 4956   interface(REG_INTER);
 4957 %}
 4958 
 4959 operand vRegD_V9()
 4960 %{
 4961   constraint(ALLOC_IN_RC(v9_reg));
 4962   match(RegD);
 4963   op_cost(0);
 4964   format %{ %}
 4965   interface(REG_INTER);
 4966 %}
 4967 
 4968 operand vRegD_V10()
 4969 %{
 4970   constraint(ALLOC_IN_RC(v10_reg));
 4971   match(RegD);
 4972   op_cost(0);
 4973   format %{ %}
 4974   interface(REG_INTER);
 4975 %}
 4976 
 4977 operand vRegD_V11()
 4978 %{
 4979   constraint(ALLOC_IN_RC(v11_reg));
 4980   match(RegD);
 4981   op_cost(0);
 4982   format %{ %}
 4983   interface(REG_INTER);
 4984 %}
 4985 
 4986 operand vRegD_V12()
 4987 %{
 4988   constraint(ALLOC_IN_RC(v12_reg));
 4989   match(RegD);
 4990   op_cost(0);
 4991   format %{ %}
 4992   interface(REG_INTER);
 4993 %}
 4994 
 4995 operand vRegD_V13()
 4996 %{
 4997   constraint(ALLOC_IN_RC(v13_reg));
 4998   match(RegD);
 4999   op_cost(0);
 5000   format %{ %}
 5001   interface(REG_INTER);
 5002 %}
 5003 
 5004 operand vRegD_V14()
 5005 %{
 5006   constraint(ALLOC_IN_RC(v14_reg));
 5007   match(RegD);
 5008   op_cost(0);
 5009   format %{ %}
 5010   interface(REG_INTER);
 5011 %}
 5012 
 5013 operand vRegD_V15()
 5014 %{
 5015   constraint(ALLOC_IN_RC(v15_reg));
 5016   match(RegD);
 5017   op_cost(0);
 5018   format %{ %}
 5019   interface(REG_INTER);
 5020 %}
 5021 
 5022 operand vRegD_V16()
 5023 %{
 5024   constraint(ALLOC_IN_RC(v16_reg));
 5025   match(RegD);
 5026   op_cost(0);
 5027   format %{ %}
 5028   interface(REG_INTER);
 5029 %}
 5030 
 5031 operand vRegD_V17()
 5032 %{
 5033   constraint(ALLOC_IN_RC(v17_reg));
 5034   match(RegD);
 5035   op_cost(0);
 5036   format %{ %}
 5037   interface(REG_INTER);
 5038 %}
 5039 
 5040 operand vRegD_V18()
 5041 %{
 5042   constraint(ALLOC_IN_RC(v18_reg));
 5043   match(RegD);
 5044   op_cost(0);
 5045   format %{ %}
 5046   interface(REG_INTER);
 5047 %}
 5048 
 5049 operand vRegD_V19()
 5050 %{
 5051   constraint(ALLOC_IN_RC(v19_reg));
 5052   match(RegD);
 5053   op_cost(0);
 5054   format %{ %}
 5055   interface(REG_INTER);
 5056 %}
 5057 
 5058 operand vRegD_V20()
 5059 %{
 5060   constraint(ALLOC_IN_RC(v20_reg));
 5061   match(RegD);
 5062   op_cost(0);
 5063   format %{ %}
 5064   interface(REG_INTER);
 5065 %}
 5066 
 5067 operand vRegD_V21()
 5068 %{
 5069   constraint(ALLOC_IN_RC(v21_reg));
 5070   match(RegD);
 5071   op_cost(0);
 5072   format %{ %}
 5073   interface(REG_INTER);
 5074 %}
 5075 
 5076 operand vRegD_V22()
 5077 %{
 5078   constraint(ALLOC_IN_RC(v22_reg));
 5079   match(RegD);
 5080   op_cost(0);
 5081   format %{ %}
 5082   interface(REG_INTER);
 5083 %}
 5084 
 5085 operand vRegD_V23()
 5086 %{
 5087   constraint(ALLOC_IN_RC(v23_reg));
 5088   match(RegD);
 5089   op_cost(0);
 5090   format %{ %}
 5091   interface(REG_INTER);
 5092 %}
 5093 
 5094 operand vRegD_V24()
 5095 %{
 5096   constraint(ALLOC_IN_RC(v24_reg));
 5097   match(RegD);
 5098   op_cost(0);
 5099   format %{ %}
 5100   interface(REG_INTER);
 5101 %}
 5102 
 5103 operand vRegD_V25()
 5104 %{
 5105   constraint(ALLOC_IN_RC(v25_reg));
 5106   match(RegD);
 5107   op_cost(0);
 5108   format %{ %}
 5109   interface(REG_INTER);
 5110 %}
 5111 
 5112 operand vRegD_V26()
 5113 %{
 5114   constraint(ALLOC_IN_RC(v26_reg));
 5115   match(RegD);
 5116   op_cost(0);
 5117   format %{ %}
 5118   interface(REG_INTER);
 5119 %}
 5120 
 5121 operand vRegD_V27()
 5122 %{
 5123   constraint(ALLOC_IN_RC(v27_reg));
 5124   match(RegD);
 5125   op_cost(0);
 5126   format %{ %}
 5127   interface(REG_INTER);
 5128 %}
 5129 
 5130 operand vRegD_V28()
 5131 %{
 5132   constraint(ALLOC_IN_RC(v28_reg));
 5133   match(RegD);
 5134   op_cost(0);
 5135   format %{ %}
 5136   interface(REG_INTER);
 5137 %}
 5138 
 5139 operand vRegD_V29()
 5140 %{
 5141   constraint(ALLOC_IN_RC(v29_reg));
 5142   match(RegD);
 5143   op_cost(0);
 5144   format %{ %}
 5145   interface(REG_INTER);
 5146 %}
 5147 
 5148 operand vRegD_V30()
 5149 %{
 5150   constraint(ALLOC_IN_RC(v30_reg));
 5151   match(RegD);
 5152   op_cost(0);
 5153   format %{ %}
 5154   interface(REG_INTER);
 5155 %}
 5156 
 5157 operand vRegD_V31()
 5158 %{
 5159   constraint(ALLOC_IN_RC(v31_reg));
 5160   match(RegD);
 5161   op_cost(0);
 5162   format %{ %}
 5163   interface(REG_INTER);
 5164 %}
 5165 
 5166 // Flags register, used as output of signed compare instructions
 5167 
 5168 // note that on AArch64 we also use this register as the output for
 5169 // for floating point compare instructions (CmpF CmpD). this ensures
 5170 // that ordered inequality tests use GT, GE, LT or LE none of which
 5171 // pass through cases where the result is unordered i.e. one or both
 5172 // inputs to the compare is a NaN. this means that the ideal code can
 5173 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5174 // (where the comparison should always fail). EQ and NE tests are
 5175 // always generated in ideal code so that unordered folds into the NE
 5176 // case, matching the behaviour of AArch64 NE.
 5177 //
 5178 // This differs from x86 where the outputs of FP compares use a
 5179 // special FP flags registers and where compares based on this
 5180 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5181 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5182 // to explicitly handle the unordered case in branches. x86 also has
 5183 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5184 
 5185 operand rFlagsReg()
 5186 %{
 5187   constraint(ALLOC_IN_RC(int_flags));
 5188   match(RegFlags);
 5189 
 5190   op_cost(0);
 5191   format %{ &quot;RFLAGS&quot; %}
 5192   interface(REG_INTER);
 5193 %}
 5194 
 5195 // Flags register, used as output of unsigned compare instructions
 5196 operand rFlagsRegU()
 5197 %{
 5198   constraint(ALLOC_IN_RC(int_flags));
 5199   match(RegFlags);
 5200 
 5201   op_cost(0);
 5202   format %{ &quot;RFLAGSU&quot; %}
 5203   interface(REG_INTER);
 5204 %}
 5205 
 5206 // Special Registers
 5207 
 5208 // Method Register
 5209 operand inline_cache_RegP(iRegP reg)
 5210 %{
 5211   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5212   match(reg);
 5213   match(iRegPNoSp);
 5214   op_cost(0);
 5215   format %{ %}
 5216   interface(REG_INTER);
 5217 %}
 5218 
 5219 operand interpreter_method_oop_RegP(iRegP reg)
 5220 %{
 5221   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5222   match(reg);
 5223   match(iRegPNoSp);
 5224   op_cost(0);
 5225   format %{ %}
 5226   interface(REG_INTER);
 5227 %}
 5228 
 5229 // Thread Register
 5230 operand thread_RegP(iRegP reg)
 5231 %{
 5232   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5233   match(reg);
 5234   op_cost(0);
 5235   format %{ %}
 5236   interface(REG_INTER);
 5237 %}
 5238 
 5239 operand lr_RegP(iRegP reg)
 5240 %{
 5241   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5242   match(reg);
 5243   op_cost(0);
 5244   format %{ %}
 5245   interface(REG_INTER);
 5246 %}
 5247 
 5248 //----------Memory Operands----------------------------------------------------
 5249 
 5250 operand indirect(iRegP reg)
 5251 %{
 5252   constraint(ALLOC_IN_RC(ptr_reg));
 5253   match(reg);
 5254   op_cost(0);
 5255   format %{ &quot;[$reg]&quot; %}
 5256   interface(MEMORY_INTER) %{
 5257     base($reg);
 5258     index(0xffffffff);
 5259     scale(0x0);
 5260     disp(0x0);
 5261   %}
 5262 %}
 5263 
 5264 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5265 %{
 5266   constraint(ALLOC_IN_RC(ptr_reg));
 5267   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5268   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5269   op_cost(0);
 5270   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5271   interface(MEMORY_INTER) %{
 5272     base($reg);
 5273     index($ireg);
 5274     scale($scale);
 5275     disp(0x0);
 5276   %}
 5277 %}
 5278 
 5279 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5280 %{
 5281   constraint(ALLOC_IN_RC(ptr_reg));
 5282   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5283   match(AddP reg (LShiftL lreg scale));
 5284   op_cost(0);
 5285   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5286   interface(MEMORY_INTER) %{
 5287     base($reg);
 5288     index($lreg);
 5289     scale($scale);
 5290     disp(0x0);
 5291   %}
 5292 %}
 5293 
 5294 operand indIndexI2L(iRegP reg, iRegI ireg)
 5295 %{
 5296   constraint(ALLOC_IN_RC(ptr_reg));
 5297   match(AddP reg (ConvI2L ireg));
 5298   op_cost(0);
 5299   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5300   interface(MEMORY_INTER) %{
 5301     base($reg);
 5302     index($ireg);
 5303     scale(0x0);
 5304     disp(0x0);
 5305   %}
 5306 %}
 5307 
 5308 operand indIndex(iRegP reg, iRegL lreg)
 5309 %{
 5310   constraint(ALLOC_IN_RC(ptr_reg));
 5311   match(AddP reg lreg);
 5312   op_cost(0);
 5313   format %{ &quot;$reg, $lreg&quot; %}
 5314   interface(MEMORY_INTER) %{
 5315     base($reg);
 5316     index($lreg);
 5317     scale(0x0);
 5318     disp(0x0);
 5319   %}
 5320 %}
 5321 
 5322 operand indOffI(iRegP reg, immIOffset off)
 5323 %{
 5324   constraint(ALLOC_IN_RC(ptr_reg));
 5325   match(AddP reg off);
 5326   op_cost(0);
 5327   format %{ &quot;[$reg, $off]&quot; %}
 5328   interface(MEMORY_INTER) %{
 5329     base($reg);
 5330     index(0xffffffff);
 5331     scale(0x0);
 5332     disp($off);
 5333   %}
 5334 %}
 5335 
 5336 operand indOffI1(iRegP reg, immIOffset1 off)
 5337 %{
 5338   constraint(ALLOC_IN_RC(ptr_reg));
 5339   match(AddP reg off);
 5340   op_cost(0);
 5341   format %{ &quot;[$reg, $off]&quot; %}
 5342   interface(MEMORY_INTER) %{
 5343     base($reg);
 5344     index(0xffffffff);
 5345     scale(0x0);
 5346     disp($off);
 5347   %}
 5348 %}
 5349 
 5350 operand indOffI2(iRegP reg, immIOffset2 off)
 5351 %{
 5352   constraint(ALLOC_IN_RC(ptr_reg));
 5353   match(AddP reg off);
 5354   op_cost(0);
 5355   format %{ &quot;[$reg, $off]&quot; %}
 5356   interface(MEMORY_INTER) %{
 5357     base($reg);
 5358     index(0xffffffff);
 5359     scale(0x0);
 5360     disp($off);
 5361   %}
 5362 %}
 5363 
 5364 operand indOffI4(iRegP reg, immIOffset4 off)
 5365 %{
 5366   constraint(ALLOC_IN_RC(ptr_reg));
 5367   match(AddP reg off);
 5368   op_cost(0);
 5369   format %{ &quot;[$reg, $off]&quot; %}
 5370   interface(MEMORY_INTER) %{
 5371     base($reg);
 5372     index(0xffffffff);
 5373     scale(0x0);
 5374     disp($off);
 5375   %}
 5376 %}
 5377 
 5378 operand indOffI8(iRegP reg, immIOffset8 off)
 5379 %{
 5380   constraint(ALLOC_IN_RC(ptr_reg));
 5381   match(AddP reg off);
 5382   op_cost(0);
 5383   format %{ &quot;[$reg, $off]&quot; %}
 5384   interface(MEMORY_INTER) %{
 5385     base($reg);
 5386     index(0xffffffff);
 5387     scale(0x0);
 5388     disp($off);
 5389   %}
 5390 %}
 5391 
 5392 operand indOffI16(iRegP reg, immIOffset16 off)
 5393 %{
 5394   constraint(ALLOC_IN_RC(ptr_reg));
 5395   match(AddP reg off);
 5396   op_cost(0);
 5397   format %{ &quot;[$reg, $off]&quot; %}
 5398   interface(MEMORY_INTER) %{
 5399     base($reg);
 5400     index(0xffffffff);
 5401     scale(0x0);
 5402     disp($off);
 5403   %}
 5404 %}
 5405 
 5406 operand indOffL(iRegP reg, immLoffset off)
 5407 %{
 5408   constraint(ALLOC_IN_RC(ptr_reg));
 5409   match(AddP reg off);
 5410   op_cost(0);
 5411   format %{ &quot;[$reg, $off]&quot; %}
 5412   interface(MEMORY_INTER) %{
 5413     base($reg);
 5414     index(0xffffffff);
 5415     scale(0x0);
 5416     disp($off);
 5417   %}
 5418 %}
 5419 
 5420 operand indOffL1(iRegP reg, immLoffset1 off)
 5421 %{
 5422   constraint(ALLOC_IN_RC(ptr_reg));
 5423   match(AddP reg off);
 5424   op_cost(0);
 5425   format %{ &quot;[$reg, $off]&quot; %}
 5426   interface(MEMORY_INTER) %{
 5427     base($reg);
 5428     index(0xffffffff);
 5429     scale(0x0);
 5430     disp($off);
 5431   %}
 5432 %}
 5433 
 5434 operand indOffL2(iRegP reg, immLoffset2 off)
 5435 %{
 5436   constraint(ALLOC_IN_RC(ptr_reg));
 5437   match(AddP reg off);
 5438   op_cost(0);
 5439   format %{ &quot;[$reg, $off]&quot; %}
 5440   interface(MEMORY_INTER) %{
 5441     base($reg);
 5442     index(0xffffffff);
 5443     scale(0x0);
 5444     disp($off);
 5445   %}
 5446 %}
 5447 
 5448 operand indOffL4(iRegP reg, immLoffset4 off)
 5449 %{
 5450   constraint(ALLOC_IN_RC(ptr_reg));
 5451   match(AddP reg off);
 5452   op_cost(0);
 5453   format %{ &quot;[$reg, $off]&quot; %}
 5454   interface(MEMORY_INTER) %{
 5455     base($reg);
 5456     index(0xffffffff);
 5457     scale(0x0);
 5458     disp($off);
 5459   %}
 5460 %}
 5461 
 5462 operand indOffL8(iRegP reg, immLoffset8 off)
 5463 %{
 5464   constraint(ALLOC_IN_RC(ptr_reg));
 5465   match(AddP reg off);
 5466   op_cost(0);
 5467   format %{ &quot;[$reg, $off]&quot; %}
 5468   interface(MEMORY_INTER) %{
 5469     base($reg);
 5470     index(0xffffffff);
 5471     scale(0x0);
 5472     disp($off);
 5473   %}
 5474 %}
 5475 
 5476 operand indOffL16(iRegP reg, immLoffset16 off)
 5477 %{
 5478   constraint(ALLOC_IN_RC(ptr_reg));
 5479   match(AddP reg off);
 5480   op_cost(0);
 5481   format %{ &quot;[$reg, $off]&quot; %}
 5482   interface(MEMORY_INTER) %{
 5483     base($reg);
 5484     index(0xffffffff);
 5485     scale(0x0);
 5486     disp($off);
 5487   %}
 5488 %}
 5489 
 5490 operand indirectN(iRegN reg)
 5491 %{
 5492   predicate(CompressedOops::shift() == 0);
 5493   constraint(ALLOC_IN_RC(ptr_reg));
 5494   match(DecodeN reg);
 5495   op_cost(0);
 5496   format %{ &quot;[$reg]\t# narrow&quot; %}
 5497   interface(MEMORY_INTER) %{
 5498     base($reg);
 5499     index(0xffffffff);
 5500     scale(0x0);
 5501     disp(0x0);
 5502   %}
 5503 %}
 5504 
 5505 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5506 %{
 5507   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5508   constraint(ALLOC_IN_RC(ptr_reg));
 5509   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5510   op_cost(0);
 5511   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5512   interface(MEMORY_INTER) %{
 5513     base($reg);
 5514     index($ireg);
 5515     scale($scale);
 5516     disp(0x0);
 5517   %}
 5518 %}
 5519 
 5520 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5521 %{
 5522   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5523   constraint(ALLOC_IN_RC(ptr_reg));
 5524   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5525   op_cost(0);
 5526   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5527   interface(MEMORY_INTER) %{
 5528     base($reg);
 5529     index($lreg);
 5530     scale($scale);
 5531     disp(0x0);
 5532   %}
 5533 %}
 5534 
 5535 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5536 %{
 5537   predicate(CompressedOops::shift() == 0);
 5538   constraint(ALLOC_IN_RC(ptr_reg));
 5539   match(AddP (DecodeN reg) (ConvI2L ireg));
 5540   op_cost(0);
 5541   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5542   interface(MEMORY_INTER) %{
 5543     base($reg);
 5544     index($ireg);
 5545     scale(0x0);
 5546     disp(0x0);
 5547   %}
 5548 %}
 5549 
 5550 operand indIndexN(iRegN reg, iRegL lreg)
 5551 %{
 5552   predicate(CompressedOops::shift() == 0);
 5553   constraint(ALLOC_IN_RC(ptr_reg));
 5554   match(AddP (DecodeN reg) lreg);
 5555   op_cost(0);
 5556   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5557   interface(MEMORY_INTER) %{
 5558     base($reg);
 5559     index($lreg);
 5560     scale(0x0);
 5561     disp(0x0);
 5562   %}
 5563 %}
 5564 
 5565 operand indOffIN(iRegN reg, immIOffset off)
 5566 %{
 5567   predicate(CompressedOops::shift() == 0);
 5568   constraint(ALLOC_IN_RC(ptr_reg));
 5569   match(AddP (DecodeN reg) off);
 5570   op_cost(0);
 5571   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5572   interface(MEMORY_INTER) %{
 5573     base($reg);
 5574     index(0xffffffff);
 5575     scale(0x0);
 5576     disp($off);
 5577   %}
 5578 %}
 5579 
 5580 operand indOffLN(iRegN reg, immLoffset off)
 5581 %{
 5582   predicate(CompressedOops::shift() == 0);
 5583   constraint(ALLOC_IN_RC(ptr_reg));
 5584   match(AddP (DecodeN reg) off);
 5585   op_cost(0);
 5586   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5587   interface(MEMORY_INTER) %{
 5588     base($reg);
 5589     index(0xffffffff);
 5590     scale(0x0);
 5591     disp($off);
 5592   %}
 5593 %}
 5594 
 5595 
 5596 
 5597 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5598 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5599 %{
 5600   constraint(ALLOC_IN_RC(ptr_reg));
 5601   match(AddP reg off);
 5602   op_cost(0);
 5603   format %{ &quot;[$reg, $off]&quot; %}
 5604   interface(MEMORY_INTER) %{
 5605     base($reg);
 5606     index(0xffffffff);
 5607     scale(0x0);
 5608     disp($off);
 5609   %}
 5610 %}
 5611 
 5612 //----------Special Memory Operands--------------------------------------------
 5613 // Stack Slot Operand - This operand is used for loading and storing temporary
 5614 //                      values on the stack where a match requires a value to
 5615 //                      flow through memory.
 5616 operand stackSlotP(sRegP reg)
 5617 %{
 5618   constraint(ALLOC_IN_RC(stack_slots));
 5619   op_cost(100);
 5620   // No match rule because this operand is only generated in matching
 5621   // match(RegP);
 5622   format %{ &quot;[$reg]&quot; %}
 5623   interface(MEMORY_INTER) %{
 5624     base(0x1e);  // RSP
 5625     index(0x0);  // No Index
 5626     scale(0x0);  // No Scale
 5627     disp($reg);  // Stack Offset
 5628   %}
 5629 %}
 5630 
 5631 operand stackSlotI(sRegI reg)
 5632 %{
 5633   constraint(ALLOC_IN_RC(stack_slots));
 5634   // No match rule because this operand is only generated in matching
 5635   // match(RegI);
 5636   format %{ &quot;[$reg]&quot; %}
 5637   interface(MEMORY_INTER) %{
 5638     base(0x1e);  // RSP
 5639     index(0x0);  // No Index
 5640     scale(0x0);  // No Scale
 5641     disp($reg);  // Stack Offset
 5642   %}
 5643 %}
 5644 
 5645 operand stackSlotF(sRegF reg)
 5646 %{
 5647   constraint(ALLOC_IN_RC(stack_slots));
 5648   // No match rule because this operand is only generated in matching
 5649   // match(RegF);
 5650   format %{ &quot;[$reg]&quot; %}
 5651   interface(MEMORY_INTER) %{
 5652     base(0x1e);  // RSP
 5653     index(0x0);  // No Index
 5654     scale(0x0);  // No Scale
 5655     disp($reg);  // Stack Offset
 5656   %}
 5657 %}
 5658 
 5659 operand stackSlotD(sRegD reg)
 5660 %{
 5661   constraint(ALLOC_IN_RC(stack_slots));
 5662   // No match rule because this operand is only generated in matching
 5663   // match(RegD);
 5664   format %{ &quot;[$reg]&quot; %}
 5665   interface(MEMORY_INTER) %{
 5666     base(0x1e);  // RSP
 5667     index(0x0);  // No Index
 5668     scale(0x0);  // No Scale
 5669     disp($reg);  // Stack Offset
 5670   %}
 5671 %}
 5672 
 5673 operand stackSlotL(sRegL reg)
 5674 %{
 5675   constraint(ALLOC_IN_RC(stack_slots));
 5676   // No match rule because this operand is only generated in matching
 5677   // match(RegL);
 5678   format %{ &quot;[$reg]&quot; %}
 5679   interface(MEMORY_INTER) %{
 5680     base(0x1e);  // RSP
 5681     index(0x0);  // No Index
 5682     scale(0x0);  // No Scale
 5683     disp($reg);  // Stack Offset
 5684   %}
 5685 %}
 5686 
 5687 // Operands for expressing Control Flow
 5688 // NOTE: Label is a predefined operand which should not be redefined in
 5689 //       the AD file. It is generically handled within the ADLC.
 5690 
 5691 //----------Conditional Branch Operands----------------------------------------
 5692 // Comparison Op  - This is the operation of the comparison, and is limited to
 5693 //                  the following set of codes:
 5694 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5695 //
 5696 // Other attributes of the comparison, such as unsignedness, are specified
 5697 // by the comparison instruction that sets a condition code flags register.
 5698 // That result is represented by a flags operand whose subtype is appropriate
 5699 // to the unsignedness (etc.) of the comparison.
 5700 //
 5701 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5702 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5703 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5704 
 5705 // used for signed integral comparisons and fp comparisons
 5706 
 5707 operand cmpOp()
 5708 %{
 5709   match(Bool);
 5710 
 5711   format %{ &quot;&quot; %}
 5712   interface(COND_INTER) %{
 5713     equal(0x0, &quot;eq&quot;);
 5714     not_equal(0x1, &quot;ne&quot;);
 5715     less(0xb, &quot;lt&quot;);
 5716     greater_equal(0xa, &quot;ge&quot;);
 5717     less_equal(0xd, &quot;le&quot;);
 5718     greater(0xc, &quot;gt&quot;);
 5719     overflow(0x6, &quot;vs&quot;);
 5720     no_overflow(0x7, &quot;vc&quot;);
 5721   %}
 5722 %}
 5723 
 5724 // used for unsigned integral comparisons
 5725 
 5726 operand cmpOpU()
 5727 %{
 5728   match(Bool);
 5729 
 5730   format %{ &quot;&quot; %}
 5731   interface(COND_INTER) %{
 5732     equal(0x0, &quot;eq&quot;);
 5733     not_equal(0x1, &quot;ne&quot;);
 5734     less(0x3, &quot;lo&quot;);
 5735     greater_equal(0x2, &quot;hs&quot;);
 5736     less_equal(0x9, &quot;ls&quot;);
 5737     greater(0x8, &quot;hi&quot;);
 5738     overflow(0x6, &quot;vs&quot;);
 5739     no_overflow(0x7, &quot;vc&quot;);
 5740   %}
 5741 %}
 5742 
 5743 // used for certain integral comparisons which can be
 5744 // converted to cbxx or tbxx instructions
 5745 
 5746 operand cmpOpEqNe()
 5747 %{
 5748   match(Bool);
 5749   op_cost(0);
 5750   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5751             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5752 
 5753   format %{ &quot;&quot; %}
 5754   interface(COND_INTER) %{
 5755     equal(0x0, &quot;eq&quot;);
 5756     not_equal(0x1, &quot;ne&quot;);
 5757     less(0xb, &quot;lt&quot;);
 5758     greater_equal(0xa, &quot;ge&quot;);
 5759     less_equal(0xd, &quot;le&quot;);
 5760     greater(0xc, &quot;gt&quot;);
 5761     overflow(0x6, &quot;vs&quot;);
 5762     no_overflow(0x7, &quot;vc&quot;);
 5763   %}
 5764 %}
 5765 
 5766 // used for certain integral comparisons which can be
 5767 // converted to cbxx or tbxx instructions
 5768 
 5769 operand cmpOpLtGe()
 5770 %{
 5771   match(Bool);
 5772   op_cost(0);
 5773 
 5774   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5775             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5776 
 5777   format %{ &quot;&quot; %}
 5778   interface(COND_INTER) %{
 5779     equal(0x0, &quot;eq&quot;);
 5780     not_equal(0x1, &quot;ne&quot;);
 5781     less(0xb, &quot;lt&quot;);
 5782     greater_equal(0xa, &quot;ge&quot;);
 5783     less_equal(0xd, &quot;le&quot;);
 5784     greater(0xc, &quot;gt&quot;);
 5785     overflow(0x6, &quot;vs&quot;);
 5786     no_overflow(0x7, &quot;vc&quot;);
 5787   %}
 5788 %}
 5789 
 5790 // used for certain unsigned integral comparisons which can be
 5791 // converted to cbxx or tbxx instructions
 5792 
 5793 operand cmpOpUEqNeLtGe()
 5794 %{
 5795   match(Bool);
 5796   op_cost(0);
 5797 
 5798   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5799             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5800             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5801             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5802 
 5803   format %{ &quot;&quot; %}
 5804   interface(COND_INTER) %{
 5805     equal(0x0, &quot;eq&quot;);
 5806     not_equal(0x1, &quot;ne&quot;);
 5807     less(0xb, &quot;lt&quot;);
 5808     greater_equal(0xa, &quot;ge&quot;);
 5809     less_equal(0xd, &quot;le&quot;);
 5810     greater(0xc, &quot;gt&quot;);
 5811     overflow(0x6, &quot;vs&quot;);
 5812     no_overflow(0x7, &quot;vc&quot;);
 5813   %}
 5814 %}
 5815 
 5816 // Special operand allowing long args to int ops to be truncated for free
 5817 
 5818 operand iRegL2I(iRegL reg) %{
 5819 
 5820   op_cost(0);
 5821 
 5822   match(ConvL2I reg);
 5823 
 5824   format %{ &quot;l2i($reg)&quot; %}
 5825 
 5826   interface(REG_INTER)
 5827 %}
 5828 
 5829 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5830 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5831 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5832 
 5833 //----------OPERAND CLASSES----------------------------------------------------
 5834 // Operand Classes are groups of operands that are used as to simplify
 5835 // instruction definitions by not requiring the AD writer to specify
 5836 // separate instructions for every form of operand when the
 5837 // instruction accepts multiple operand types with the same basic
 5838 // encoding and format. The classic case of this is memory operands.
 5839 
 5840 // memory is used to define read/write location for load/store
 5841 // instruction defs. we can turn a memory op into an Address
 5842 
 5843 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5844                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5845 
 5846 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5847                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5848 
 5849 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5850                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5851 
 5852 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5853                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5854 
 5855 // All of the memory operands. For the pipeline description.
 5856 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5857                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5858                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5859 
 5860 
 5861 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5862 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5863 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5864 // can be elided because the 32-bit instruction will just employ the
 5865 // lower 32 bits anyway.
 5866 //
 5867 // n.b. this does not elide all L2I conversions. if the truncated
 5868 // value is consumed by more than one operation then the ConvL2I
 5869 // cannot be bundled into the consuming nodes so an l2i gets planted
 5870 // (actually a movw $dst $src) and the downstream instructions consume
 5871 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5872 // movw is actually redundant but its not too costly.
 5873 
 5874 opclass iRegIorL2I(iRegI, iRegL2I);
 5875 
 5876 //----------PIPELINE-----------------------------------------------------------
 5877 // Rules which define the behavior of the target architectures pipeline.
 5878 
 5879 // For specific pipelines, eg A53, define the stages of that pipeline
 5880 //pipe_desc(ISS, EX1, EX2, WR);
 5881 #define ISS S0
 5882 #define EX1 S1
 5883 #define EX2 S2
 5884 #define WR  S3
 5885 
 5886 // Integer ALU reg operation
 5887 pipeline %{
 5888 
 5889 attributes %{
 5890   // ARM instructions are of fixed length
 5891   fixed_size_instructions;        // Fixed size instructions TODO does
 5892   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5893   // ARM instructions come in 32-bit word units
 5894   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5895   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5896   instruction_fetch_units = 1;       // of 64 bytes
 5897 
 5898   // List of nop instructions
 5899   nops( MachNop );
 5900 %}
 5901 
 5902 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5903 // or description. we do use pipeline classes to introduce fixed
 5904 // latencies
 5905 
 5906 //----------RESOURCES----------------------------------------------------------
 5907 // Resources are the functional units available to the machine
 5908 
 5909 resources( INS0, INS1, INS01 = INS0 | INS1,
 5910            ALU0, ALU1, ALU = ALU0 | ALU1,
 5911            MAC,
 5912            DIV,
 5913            BRANCH,
 5914            LDST,
 5915            NEON_FP);
 5916 
 5917 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5918 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5919 
 5920 // Define the pipeline as a generic 6 stage pipeline
 5921 pipe_desc(S0, S1, S2, S3, S4, S5);
 5922 
 5923 //----------PIPELINE CLASSES---------------------------------------------------
 5924 // Pipeline Classes describe the stages in which input and output are
 5925 // referenced by the hardware pipeline.
 5926 
 5927 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5928 %{
 5929   single_instruction;
 5930   src1   : S1(read);
 5931   src2   : S2(read);
 5932   dst    : S5(write);
 5933   INS01  : ISS;
 5934   NEON_FP : S5;
 5935 %}
 5936 
 5937 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5938 %{
 5939   single_instruction;
 5940   src1   : S1(read);
 5941   src2   : S2(read);
 5942   dst    : S5(write);
 5943   INS01  : ISS;
 5944   NEON_FP : S5;
 5945 %}
 5946 
 5947 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5948 %{
 5949   single_instruction;
 5950   src    : S1(read);
 5951   dst    : S5(write);
 5952   INS01  : ISS;
 5953   NEON_FP : S5;
 5954 %}
 5955 
 5956 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5957 %{
 5958   single_instruction;
 5959   src    : S1(read);
 5960   dst    : S5(write);
 5961   INS01  : ISS;
 5962   NEON_FP : S5;
 5963 %}
 5964 
 5965 pipe_class fp_d2f(vRegF dst, vRegD src)
 5966 %{
 5967   single_instruction;
 5968   src    : S1(read);
 5969   dst    : S5(write);
 5970   INS01  : ISS;
 5971   NEON_FP : S5;
 5972 %}
 5973 
 5974 pipe_class fp_f2d(vRegD dst, vRegF src)
 5975 %{
 5976   single_instruction;
 5977   src    : S1(read);
 5978   dst    : S5(write);
 5979   INS01  : ISS;
 5980   NEON_FP : S5;
 5981 %}
 5982 
 5983 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 5984 %{
 5985   single_instruction;
 5986   src    : S1(read);
 5987   dst    : S5(write);
 5988   INS01  : ISS;
 5989   NEON_FP : S5;
 5990 %}
 5991 
 5992 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 5993 %{
 5994   single_instruction;
 5995   src    : S1(read);
 5996   dst    : S5(write);
 5997   INS01  : ISS;
 5998   NEON_FP : S5;
 5999 %}
 6000 
 6001 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 6002 %{
 6003   single_instruction;
 6004   src    : S1(read);
 6005   dst    : S5(write);
 6006   INS01  : ISS;
 6007   NEON_FP : S5;
 6008 %}
 6009 
 6010 pipe_class fp_l2f(vRegF dst, iRegL src)
 6011 %{
 6012   single_instruction;
 6013   src    : S1(read);
 6014   dst    : S5(write);
 6015   INS01  : ISS;
 6016   NEON_FP : S5;
 6017 %}
 6018 
 6019 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6020 %{
 6021   single_instruction;
 6022   src    : S1(read);
 6023   dst    : S5(write);
 6024   INS01  : ISS;
 6025   NEON_FP : S5;
 6026 %}
 6027 
 6028 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6029 %{
 6030   single_instruction;
 6031   src    : S1(read);
 6032   dst    : S5(write);
 6033   INS01  : ISS;
 6034   NEON_FP : S5;
 6035 %}
 6036 
 6037 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6038 %{
 6039   single_instruction;
 6040   src    : S1(read);
 6041   dst    : S5(write);
 6042   INS01  : ISS;
 6043   NEON_FP : S5;
 6044 %}
 6045 
 6046 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6047 %{
 6048   single_instruction;
 6049   src    : S1(read);
 6050   dst    : S5(write);
 6051   INS01  : ISS;
 6052   NEON_FP : S5;
 6053 %}
 6054 
 6055 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6056 %{
 6057   single_instruction;
 6058   src1   : S1(read);
 6059   src2   : S2(read);
 6060   dst    : S5(write);
 6061   INS0   : ISS;
 6062   NEON_FP : S5;
 6063 %}
 6064 
 6065 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6066 %{
 6067   single_instruction;
 6068   src1   : S1(read);
 6069   src2   : S2(read);
 6070   dst    : S5(write);
 6071   INS0   : ISS;
 6072   NEON_FP : S5;
 6073 %}
 6074 
 6075 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6076 %{
 6077   single_instruction;
 6078   cr     : S1(read);
 6079   src1   : S1(read);
 6080   src2   : S1(read);
 6081   dst    : S3(write);
 6082   INS01  : ISS;
 6083   NEON_FP : S3;
 6084 %}
 6085 
 6086 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6087 %{
 6088   single_instruction;
 6089   cr     : S1(read);
 6090   src1   : S1(read);
 6091   src2   : S1(read);
 6092   dst    : S3(write);
 6093   INS01  : ISS;
 6094   NEON_FP : S3;
 6095 %}
 6096 
 6097 pipe_class fp_imm_s(vRegF dst)
 6098 %{
 6099   single_instruction;
 6100   dst    : S3(write);
 6101   INS01  : ISS;
 6102   NEON_FP : S3;
 6103 %}
 6104 
 6105 pipe_class fp_imm_d(vRegD dst)
 6106 %{
 6107   single_instruction;
 6108   dst    : S3(write);
 6109   INS01  : ISS;
 6110   NEON_FP : S3;
 6111 %}
 6112 
 6113 pipe_class fp_load_constant_s(vRegF dst)
 6114 %{
 6115   single_instruction;
 6116   dst    : S4(write);
 6117   INS01  : ISS;
 6118   NEON_FP : S4;
 6119 %}
 6120 
 6121 pipe_class fp_load_constant_d(vRegD dst)
 6122 %{
 6123   single_instruction;
 6124   dst    : S4(write);
 6125   INS01  : ISS;
 6126   NEON_FP : S4;
 6127 %}
 6128 
 6129 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6130 %{
 6131   single_instruction;
 6132   dst    : S5(write);
 6133   src1   : S1(read);
 6134   src2   : S1(read);
 6135   INS01  : ISS;
 6136   NEON_FP : S5;
 6137 %}
 6138 
 6139 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6140 %{
 6141   single_instruction;
 6142   dst    : S5(write);
 6143   src1   : S1(read);
 6144   src2   : S1(read);
 6145   INS0   : ISS;
 6146   NEON_FP : S5;
 6147 %}
 6148 
 6149 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6150 %{
 6151   single_instruction;
 6152   dst    : S5(write);
 6153   src1   : S1(read);
 6154   src2   : S1(read);
 6155   dst    : S1(read);
 6156   INS01  : ISS;
 6157   NEON_FP : S5;
 6158 %}
 6159 
 6160 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6161 %{
 6162   single_instruction;
 6163   dst    : S5(write);
 6164   src1   : S1(read);
 6165   src2   : S1(read);
 6166   dst    : S1(read);
 6167   INS0   : ISS;
 6168   NEON_FP : S5;
 6169 %}
 6170 
 6171 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6172 %{
 6173   single_instruction;
 6174   dst    : S4(write);
 6175   src1   : S2(read);
 6176   src2   : S2(read);
 6177   INS01  : ISS;
 6178   NEON_FP : S4;
 6179 %}
 6180 
 6181 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6182 %{
 6183   single_instruction;
 6184   dst    : S4(write);
 6185   src1   : S2(read);
 6186   src2   : S2(read);
 6187   INS0   : ISS;
 6188   NEON_FP : S4;
 6189 %}
 6190 
 6191 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6192 %{
 6193   single_instruction;
 6194   dst    : S3(write);
 6195   src1   : S2(read);
 6196   src2   : S2(read);
 6197   INS01  : ISS;
 6198   NEON_FP : S3;
 6199 %}
 6200 
 6201 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6202 %{
 6203   single_instruction;
 6204   dst    : S3(write);
 6205   src1   : S2(read);
 6206   src2   : S2(read);
 6207   INS0   : ISS;
 6208   NEON_FP : S3;
 6209 %}
 6210 
 6211 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6212 %{
 6213   single_instruction;
 6214   dst    : S3(write);
 6215   src    : S1(read);
 6216   shift  : S1(read);
 6217   INS01  : ISS;
 6218   NEON_FP : S3;
 6219 %}
 6220 
 6221 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6222 %{
 6223   single_instruction;
 6224   dst    : S3(write);
 6225   src    : S1(read);
 6226   shift  : S1(read);
 6227   INS0   : ISS;
 6228   NEON_FP : S3;
 6229 %}
 6230 
 6231 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6232 %{
 6233   single_instruction;
 6234   dst    : S3(write);
 6235   src    : S1(read);
 6236   INS01  : ISS;
 6237   NEON_FP : S3;
 6238 %}
 6239 
 6240 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6241 %{
 6242   single_instruction;
 6243   dst    : S3(write);
 6244   src    : S1(read);
 6245   INS0   : ISS;
 6246   NEON_FP : S3;
 6247 %}
 6248 
 6249 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6250 %{
 6251   single_instruction;
 6252   dst    : S5(write);
 6253   src1   : S1(read);
 6254   src2   : S1(read);
 6255   INS01  : ISS;
 6256   NEON_FP : S5;
 6257 %}
 6258 
 6259 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6260 %{
 6261   single_instruction;
 6262   dst    : S5(write);
 6263   src1   : S1(read);
 6264   src2   : S1(read);
 6265   INS0   : ISS;
 6266   NEON_FP : S5;
 6267 %}
 6268 
 6269 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6270 %{
 6271   single_instruction;
 6272   dst    : S5(write);
 6273   src1   : S1(read);
 6274   src2   : S1(read);
 6275   INS0   : ISS;
 6276   NEON_FP : S5;
 6277 %}
 6278 
 6279 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6280 %{
 6281   single_instruction;
 6282   dst    : S5(write);
 6283   src1   : S1(read);
 6284   src2   : S1(read);
 6285   INS0   : ISS;
 6286   NEON_FP : S5;
 6287 %}
 6288 
 6289 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6290 %{
 6291   single_instruction;
 6292   dst    : S5(write);
 6293   src    : S1(read);
 6294   INS0   : ISS;
 6295   NEON_FP : S5;
 6296 %}
 6297 
 6298 pipe_class vunop_fp64(vecD dst, vecD src)
 6299 %{
 6300   single_instruction;
 6301   dst    : S5(write);
 6302   src    : S1(read);
 6303   INS01  : ISS;
 6304   NEON_FP : S5;
 6305 %}
 6306 
 6307 pipe_class vunop_fp128(vecX dst, vecX src)
 6308 %{
 6309   single_instruction;
 6310   dst    : S5(write);
 6311   src    : S1(read);
 6312   INS0   : ISS;
 6313   NEON_FP : S5;
 6314 %}
 6315 
 6316 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6317 %{
 6318   single_instruction;
 6319   dst    : S3(write);
 6320   src    : S1(read);
 6321   INS01  : ISS;
 6322   NEON_FP : S3;
 6323 %}
 6324 
 6325 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6326 %{
 6327   single_instruction;
 6328   dst    : S3(write);
 6329   src    : S1(read);
 6330   INS01  : ISS;
 6331   NEON_FP : S3;
 6332 %}
 6333 
 6334 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6335 %{
 6336   single_instruction;
 6337   dst    : S3(write);
 6338   src    : S1(read);
 6339   INS01  : ISS;
 6340   NEON_FP : S3;
 6341 %}
 6342 
 6343 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6344 %{
 6345   single_instruction;
 6346   dst    : S3(write);
 6347   src    : S1(read);
 6348   INS01  : ISS;
 6349   NEON_FP : S3;
 6350 %}
 6351 
 6352 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6353 %{
 6354   single_instruction;
 6355   dst    : S3(write);
 6356   src    : S1(read);
 6357   INS01  : ISS;
 6358   NEON_FP : S3;
 6359 %}
 6360 
 6361 pipe_class vmovi_reg_imm64(vecD dst)
 6362 %{
 6363   single_instruction;
 6364   dst    : S3(write);
 6365   INS01  : ISS;
 6366   NEON_FP : S3;
 6367 %}
 6368 
 6369 pipe_class vmovi_reg_imm128(vecX dst)
 6370 %{
 6371   single_instruction;
 6372   dst    : S3(write);
 6373   INS0   : ISS;
 6374   NEON_FP : S3;
 6375 %}
 6376 
 6377 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6378 %{
 6379   single_instruction;
 6380   dst    : S5(write);
 6381   mem    : ISS(read);
 6382   INS01  : ISS;
 6383   NEON_FP : S3;
 6384 %}
 6385 
 6386 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6387 %{
 6388   single_instruction;
 6389   dst    : S5(write);
 6390   mem    : ISS(read);
 6391   INS01  : ISS;
 6392   NEON_FP : S3;
 6393 %}
 6394 
 6395 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6396 %{
 6397   single_instruction;
 6398   mem    : ISS(read);
 6399   src    : S2(read);
 6400   INS01  : ISS;
 6401   NEON_FP : S3;
 6402 %}
 6403 
 6404 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6405 %{
 6406   single_instruction;
 6407   mem    : ISS(read);
 6408   src    : S2(read);
 6409   INS01  : ISS;
 6410   NEON_FP : S3;
 6411 %}
 6412 
 6413 //------- Integer ALU operations --------------------------
 6414 
 6415 // Integer ALU reg-reg operation
 6416 // Operands needed in EX1, result generated in EX2
 6417 // Eg.  ADD     x0, x1, x2
 6418 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6419 %{
 6420   single_instruction;
 6421   dst    : EX2(write);
 6422   src1   : EX1(read);
 6423   src2   : EX1(read);
 6424   INS01  : ISS; // Dual issue as instruction 0 or 1
 6425   ALU    : EX2;
 6426 %}
 6427 
 6428 // Integer ALU reg-reg operation with constant shift
 6429 // Shifted register must be available in LATE_ISS instead of EX1
 6430 // Eg.  ADD     x0, x1, x2, LSL #2
 6431 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6432 %{
 6433   single_instruction;
 6434   dst    : EX2(write);
 6435   src1   : EX1(read);
 6436   src2   : ISS(read);
 6437   INS01  : ISS;
 6438   ALU    : EX2;
 6439 %}
 6440 
 6441 // Integer ALU reg operation with constant shift
 6442 // Eg.  LSL     x0, x1, #shift
 6443 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6444 %{
 6445   single_instruction;
 6446   dst    : EX2(write);
 6447   src1   : ISS(read);
 6448   INS01  : ISS;
 6449   ALU    : EX2;
 6450 %}
 6451 
 6452 // Integer ALU reg-reg operation with variable shift
 6453 // Both operands must be available in LATE_ISS instead of EX1
 6454 // Result is available in EX1 instead of EX2
 6455 // Eg.  LSLV    x0, x1, x2
 6456 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6457 %{
 6458   single_instruction;
 6459   dst    : EX1(write);
 6460   src1   : ISS(read);
 6461   src2   : ISS(read);
 6462   INS01  : ISS;
 6463   ALU    : EX1;
 6464 %}
 6465 
 6466 // Integer ALU reg-reg operation with extract
 6467 // As for _vshift above, but result generated in EX2
 6468 // Eg.  EXTR    x0, x1, x2, #N
 6469 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6470 %{
 6471   single_instruction;
 6472   dst    : EX2(write);
 6473   src1   : ISS(read);
 6474   src2   : ISS(read);
 6475   INS1   : ISS; // Can only dual issue as Instruction 1
 6476   ALU    : EX1;
 6477 %}
 6478 
 6479 // Integer ALU reg operation
 6480 // Eg.  NEG     x0, x1
 6481 pipe_class ialu_reg(iRegI dst, iRegI src)
 6482 %{
 6483   single_instruction;
 6484   dst    : EX2(write);
 6485   src    : EX1(read);
 6486   INS01  : ISS;
 6487   ALU    : EX2;
 6488 %}
 6489 
 6490 // Integer ALU reg mmediate operation
 6491 // Eg.  ADD     x0, x1, #N
 6492 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6493 %{
 6494   single_instruction;
 6495   dst    : EX2(write);
 6496   src1   : EX1(read);
 6497   INS01  : ISS;
 6498   ALU    : EX2;
 6499 %}
 6500 
 6501 // Integer ALU immediate operation (no source operands)
 6502 // Eg.  MOV     x0, #N
 6503 pipe_class ialu_imm(iRegI dst)
 6504 %{
 6505   single_instruction;
 6506   dst    : EX1(write);
 6507   INS01  : ISS;
 6508   ALU    : EX1;
 6509 %}
 6510 
 6511 //------- Compare operation -------------------------------
 6512 
 6513 // Compare reg-reg
 6514 // Eg.  CMP     x0, x1
 6515 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6516 %{
 6517   single_instruction;
 6518 //  fixed_latency(16);
 6519   cr     : EX2(write);
 6520   op1    : EX1(read);
 6521   op2    : EX1(read);
 6522   INS01  : ISS;
 6523   ALU    : EX2;
 6524 %}
 6525 
 6526 // Compare reg-reg
 6527 // Eg.  CMP     x0, #N
 6528 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6529 %{
 6530   single_instruction;
 6531 //  fixed_latency(16);
 6532   cr     : EX2(write);
 6533   op1    : EX1(read);
 6534   INS01  : ISS;
 6535   ALU    : EX2;
 6536 %}
 6537 
 6538 //------- Conditional instructions ------------------------
 6539 
 6540 // Conditional no operands
 6541 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6542 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6543 %{
 6544   single_instruction;
 6545   cr     : EX1(read);
 6546   dst    : EX2(write);
 6547   INS01  : ISS;
 6548   ALU    : EX2;
 6549 %}
 6550 
 6551 // Conditional 2 operand
 6552 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6553 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6554 %{
 6555   single_instruction;
 6556   cr     : EX1(read);
 6557   src1   : EX1(read);
 6558   src2   : EX1(read);
 6559   dst    : EX2(write);
 6560   INS01  : ISS;
 6561   ALU    : EX2;
 6562 %}
 6563 
 6564 // Conditional 2 operand
 6565 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6566 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6567 %{
 6568   single_instruction;
 6569   cr     : EX1(read);
 6570   src    : EX1(read);
 6571   dst    : EX2(write);
 6572   INS01  : ISS;
 6573   ALU    : EX2;
 6574 %}
 6575 
 6576 //------- Multiply pipeline operations --------------------
 6577 
 6578 // Multiply reg-reg
 6579 // Eg.  MUL     w0, w1, w2
 6580 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6581 %{
 6582   single_instruction;
 6583   dst    : WR(write);
 6584   src1   : ISS(read);
 6585   src2   : ISS(read);
 6586   INS01  : ISS;
 6587   MAC    : WR;
 6588 %}
 6589 
 6590 // Multiply accumulate
 6591 // Eg.  MADD    w0, w1, w2, w3
 6592 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6593 %{
 6594   single_instruction;
 6595   dst    : WR(write);
 6596   src1   : ISS(read);
 6597   src2   : ISS(read);
 6598   src3   : ISS(read);
 6599   INS01  : ISS;
 6600   MAC    : WR;
 6601 %}
 6602 
 6603 // Eg.  MUL     w0, w1, w2
 6604 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6605 %{
 6606   single_instruction;
 6607   fixed_latency(3); // Maximum latency for 64 bit mul
 6608   dst    : WR(write);
 6609   src1   : ISS(read);
 6610   src2   : ISS(read);
 6611   INS01  : ISS;
 6612   MAC    : WR;
 6613 %}
 6614 
 6615 // Multiply accumulate
 6616 // Eg.  MADD    w0, w1, w2, w3
 6617 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6618 %{
 6619   single_instruction;
 6620   fixed_latency(3); // Maximum latency for 64 bit mul
 6621   dst    : WR(write);
 6622   src1   : ISS(read);
 6623   src2   : ISS(read);
 6624   src3   : ISS(read);
 6625   INS01  : ISS;
 6626   MAC    : WR;
 6627 %}
 6628 
 6629 //------- Divide pipeline operations --------------------
 6630 
 6631 // Eg.  SDIV    w0, w1, w2
 6632 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6633 %{
 6634   single_instruction;
 6635   fixed_latency(8); // Maximum latency for 32 bit divide
 6636   dst    : WR(write);
 6637   src1   : ISS(read);
 6638   src2   : ISS(read);
 6639   INS0   : ISS; // Can only dual issue as instruction 0
 6640   DIV    : WR;
 6641 %}
 6642 
 6643 // Eg.  SDIV    x0, x1, x2
 6644 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6645 %{
 6646   single_instruction;
 6647   fixed_latency(16); // Maximum latency for 64 bit divide
 6648   dst    : WR(write);
 6649   src1   : ISS(read);
 6650   src2   : ISS(read);
 6651   INS0   : ISS; // Can only dual issue as instruction 0
 6652   DIV    : WR;
 6653 %}
 6654 
 6655 //------- Load pipeline operations ------------------------
 6656 
 6657 // Load - prefetch
 6658 // Eg.  PFRM    &lt;mem&gt;
 6659 pipe_class iload_prefetch(memory mem)
 6660 %{
 6661   single_instruction;
 6662   mem    : ISS(read);
 6663   INS01  : ISS;
 6664   LDST   : WR;
 6665 %}
 6666 
 6667 // Load - reg, mem
 6668 // Eg.  LDR     x0, &lt;mem&gt;
 6669 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6670 %{
 6671   single_instruction;
 6672   dst    : WR(write);
 6673   mem    : ISS(read);
 6674   INS01  : ISS;
 6675   LDST   : WR;
 6676 %}
 6677 
 6678 // Load - reg, reg
 6679 // Eg.  LDR     x0, [sp, x1]
 6680 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6681 %{
 6682   single_instruction;
 6683   dst    : WR(write);
 6684   src    : ISS(read);
 6685   INS01  : ISS;
 6686   LDST   : WR;
 6687 %}
 6688 
 6689 //------- Store pipeline operations -----------------------
 6690 
 6691 // Store - zr, mem
 6692 // Eg.  STR     zr, &lt;mem&gt;
 6693 pipe_class istore_mem(memory mem)
 6694 %{
 6695   single_instruction;
 6696   mem    : ISS(read);
 6697   INS01  : ISS;
 6698   LDST   : WR;
 6699 %}
 6700 
 6701 // Store - reg, mem
 6702 // Eg.  STR     x0, &lt;mem&gt;
 6703 pipe_class istore_reg_mem(iRegI src, memory mem)
 6704 %{
 6705   single_instruction;
 6706   mem    : ISS(read);
 6707   src    : EX2(read);
 6708   INS01  : ISS;
 6709   LDST   : WR;
 6710 %}
 6711 
 6712 // Store - reg, reg
 6713 // Eg. STR      x0, [sp, x1]
 6714 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6715 %{
 6716   single_instruction;
 6717   dst    : ISS(read);
 6718   src    : EX2(read);
 6719   INS01  : ISS;
 6720   LDST   : WR;
 6721 %}
 6722 
 6723 //------- Store pipeline operations -----------------------
 6724 
 6725 // Branch
 6726 pipe_class pipe_branch()
 6727 %{
 6728   single_instruction;
 6729   INS01  : ISS;
 6730   BRANCH : EX1;
 6731 %}
 6732 
 6733 // Conditional branch
 6734 pipe_class pipe_branch_cond(rFlagsReg cr)
 6735 %{
 6736   single_instruction;
 6737   cr     : EX1(read);
 6738   INS01  : ISS;
 6739   BRANCH : EX1;
 6740 %}
 6741 
 6742 // Compare &amp; Branch
 6743 // EG.  CBZ/CBNZ
 6744 pipe_class pipe_cmp_branch(iRegI op1)
 6745 %{
 6746   single_instruction;
 6747   op1    : EX1(read);
 6748   INS01  : ISS;
 6749   BRANCH : EX1;
 6750 %}
 6751 
 6752 //------- Synchronisation operations ----------------------
 6753 
 6754 // Any operation requiring serialization.
 6755 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6756 pipe_class pipe_serial()
 6757 %{
 6758   single_instruction;
 6759   force_serialization;
 6760   fixed_latency(16);
 6761   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6762   LDST   : WR;
 6763 %}
 6764 
 6765 // Generic big/slow expanded idiom - also serialized
 6766 pipe_class pipe_slow()
 6767 %{
 6768   instruction_count(10);
 6769   multiple_bundles;
 6770   force_serialization;
 6771   fixed_latency(16);
 6772   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6773   LDST   : WR;
 6774 %}
 6775 
 6776 // Empty pipeline class
 6777 pipe_class pipe_class_empty()
 6778 %{
 6779   single_instruction;
 6780   fixed_latency(0);
 6781 %}
 6782 
 6783 // Default pipeline class.
 6784 pipe_class pipe_class_default()
 6785 %{
 6786   single_instruction;
 6787   fixed_latency(2);
 6788 %}
 6789 
 6790 // Pipeline class for compares.
 6791 pipe_class pipe_class_compare()
 6792 %{
 6793   single_instruction;
 6794   fixed_latency(16);
 6795 %}
 6796 
 6797 // Pipeline class for memory operations.
 6798 pipe_class pipe_class_memory()
 6799 %{
 6800   single_instruction;
 6801   fixed_latency(16);
 6802 %}
 6803 
 6804 // Pipeline class for call.
 6805 pipe_class pipe_class_call()
 6806 %{
 6807   single_instruction;
 6808   fixed_latency(100);
 6809 %}
 6810 
 6811 // Define the class for the Nop node.
 6812 define %{
 6813    MachNop = pipe_class_empty;
 6814 %}
 6815 
 6816 %}
 6817 //----------INSTRUCTIONS-------------------------------------------------------
 6818 //
 6819 // match      -- States which machine-independent subtree may be replaced
 6820 //               by this instruction.
 6821 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6822 //               selection to identify a minimum cost tree of machine
 6823 //               instructions that matches a tree of machine-independent
 6824 //               instructions.
 6825 // format     -- A string providing the disassembly for this instruction.
 6826 //               The value of an instruction&#39;s operand may be inserted
 6827 //               by referring to it with a &#39;$&#39; prefix.
 6828 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6829 //               to within an encode class as $primary, $secondary, and $tertiary
 6830 //               rrspectively.  The primary opcode is commonly used to
 6831 //               indicate the type of machine instruction, while secondary
 6832 //               and tertiary are often used for prefix options or addressing
 6833 //               modes.
 6834 // ins_encode -- A list of encode classes with parameters. The encode class
 6835 //               name must have been defined in an &#39;enc_class&#39; specification
 6836 //               in the encode section of the architecture description.
 6837 
 6838 // ============================================================================
 6839 // Memory (Load/Store) Instructions
 6840 
 6841 // Load Instructions
 6842 
 6843 // Load Byte (8 bit signed)
 6844 instruct loadB(iRegINoSp dst, memory1 mem)
 6845 %{
 6846   match(Set dst (LoadB mem));
 6847   predicate(!needs_acquiring_load(n));
 6848 
 6849   ins_cost(4 * INSN_COST);
 6850   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6851 
 6852   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6853 
 6854   ins_pipe(iload_reg_mem);
 6855 %}
 6856 
 6857 // Load Byte (8 bit signed) into long
 6858 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6859 %{
 6860   match(Set dst (ConvI2L (LoadB mem)));
 6861   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6862 
 6863   ins_cost(4 * INSN_COST);
 6864   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6865 
 6866   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6867 
 6868   ins_pipe(iload_reg_mem);
 6869 %}
 6870 
 6871 // Load Byte (8 bit unsigned)
 6872 instruct loadUB(iRegINoSp dst, memory1 mem)
 6873 %{
 6874   match(Set dst (LoadUB mem));
 6875   predicate(!needs_acquiring_load(n));
 6876 
 6877   ins_cost(4 * INSN_COST);
 6878   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6879 
 6880   ins_encode(aarch64_enc_ldrb(dst, mem));
 6881 
 6882   ins_pipe(iload_reg_mem);
 6883 %}
 6884 
 6885 // Load Byte (8 bit unsigned) into long
 6886 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6887 %{
 6888   match(Set dst (ConvI2L (LoadUB mem)));
 6889   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6890 
 6891   ins_cost(4 * INSN_COST);
 6892   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6893 
 6894   ins_encode(aarch64_enc_ldrb(dst, mem));
 6895 
 6896   ins_pipe(iload_reg_mem);
 6897 %}
 6898 
 6899 // Load Short (16 bit signed)
 6900 instruct loadS(iRegINoSp dst, memory2 mem)
 6901 %{
 6902   match(Set dst (LoadS mem));
 6903   predicate(!needs_acquiring_load(n));
 6904 
 6905   ins_cost(4 * INSN_COST);
 6906   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6907 
 6908   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6909 
 6910   ins_pipe(iload_reg_mem);
 6911 %}
 6912 
 6913 // Load Short (16 bit signed) into long
 6914 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6915 %{
 6916   match(Set dst (ConvI2L (LoadS mem)));
 6917   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6918 
 6919   ins_cost(4 * INSN_COST);
 6920   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6921 
 6922   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6923 
 6924   ins_pipe(iload_reg_mem);
 6925 %}
 6926 
 6927 // Load Char (16 bit unsigned)
 6928 instruct loadUS(iRegINoSp dst, memory2 mem)
 6929 %{
 6930   match(Set dst (LoadUS mem));
 6931   predicate(!needs_acquiring_load(n));
 6932 
 6933   ins_cost(4 * INSN_COST);
 6934   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6935 
 6936   ins_encode(aarch64_enc_ldrh(dst, mem));
 6937 
 6938   ins_pipe(iload_reg_mem);
 6939 %}
 6940 
 6941 // Load Short/Char (16 bit unsigned) into long
 6942 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6943 %{
 6944   match(Set dst (ConvI2L (LoadUS mem)));
 6945   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6946 
 6947   ins_cost(4 * INSN_COST);
 6948   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6949 
 6950   ins_encode(aarch64_enc_ldrh(dst, mem));
 6951 
 6952   ins_pipe(iload_reg_mem);
 6953 %}
 6954 
 6955 // Load Integer (32 bit signed)
 6956 instruct loadI(iRegINoSp dst, memory4 mem)
 6957 %{
 6958   match(Set dst (LoadI mem));
 6959   predicate(!needs_acquiring_load(n));
 6960 
 6961   ins_cost(4 * INSN_COST);
 6962   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6963 
 6964   ins_encode(aarch64_enc_ldrw(dst, mem));
 6965 
 6966   ins_pipe(iload_reg_mem);
 6967 %}
 6968 
 6969 // Load Integer (32 bit signed) into long
 6970 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6971 %{
 6972   match(Set dst (ConvI2L (LoadI mem)));
 6973   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6974 
 6975   ins_cost(4 * INSN_COST);
 6976   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 6977 
 6978   ins_encode(aarch64_enc_ldrsw(dst, mem));
 6979 
 6980   ins_pipe(iload_reg_mem);
 6981 %}
 6982 
 6983 // Load Integer (32 bit unsigned) into long
 6984 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 6985 %{
 6986   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 6987   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 6988 
 6989   ins_cost(4 * INSN_COST);
 6990   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6991 
 6992   ins_encode(aarch64_enc_ldrw(dst, mem));
 6993 
 6994   ins_pipe(iload_reg_mem);
 6995 %}
 6996 
 6997 // Load Long (64 bit signed)
 6998 instruct loadL(iRegLNoSp dst, memory8 mem)
 6999 %{
 7000   match(Set dst (LoadL mem));
 7001   predicate(!needs_acquiring_load(n));
 7002 
 7003   ins_cost(4 * INSN_COST);
 7004   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7005 
 7006   ins_encode(aarch64_enc_ldr(dst, mem));
 7007 
 7008   ins_pipe(iload_reg_mem);
 7009 %}
 7010 
 7011 // Load Range
 7012 instruct loadRange(iRegINoSp dst, memory4 mem)
 7013 %{
 7014   match(Set dst (LoadRange mem));
 7015 
 7016   ins_cost(4 * INSN_COST);
 7017   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7018 
 7019   ins_encode(aarch64_enc_ldrw(dst, mem));
 7020 
 7021   ins_pipe(iload_reg_mem);
 7022 %}
 7023 
 7024 // Load Pointer
 7025 instruct loadP(iRegPNoSp dst, memory8 mem)
 7026 %{
 7027   match(Set dst (LoadP mem));
 7028   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7029 
 7030   ins_cost(4 * INSN_COST);
 7031   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7032 
 7033   ins_encode(aarch64_enc_ldr(dst, mem));
 7034 
 7035   ins_pipe(iload_reg_mem);
 7036 %}
 7037 
 7038 // Load Compressed Pointer
 7039 instruct loadN(iRegNNoSp dst, memory4 mem)
 7040 %{
 7041   match(Set dst (LoadN mem));
 7042   predicate(!needs_acquiring_load(n));
 7043 
 7044   ins_cost(4 * INSN_COST);
 7045   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7046 
 7047   ins_encode(aarch64_enc_ldrw(dst, mem));
 7048 
 7049   ins_pipe(iload_reg_mem);
 7050 %}
 7051 
 7052 // Load Klass Pointer
 7053 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7054 %{
 7055   match(Set dst (LoadKlass mem));
 7056   predicate(!needs_acquiring_load(n));
 7057 
 7058   ins_cost(4 * INSN_COST);
 7059   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7060 
 7061   ins_encode(aarch64_enc_ldr(dst, mem));
 7062 
 7063   ins_pipe(iload_reg_mem);
 7064 %}
 7065 
 7066 // Load Narrow Klass Pointer
 7067 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7068 %{
 7069   match(Set dst (LoadNKlass mem));
 7070   predicate(!needs_acquiring_load(n));
 7071 
 7072   ins_cost(4 * INSN_COST);
 7073   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7074 
 7075   ins_encode(aarch64_enc_ldrw(dst, mem));
 7076 
 7077   ins_pipe(iload_reg_mem);
 7078 %}
 7079 
 7080 // Load Float
 7081 instruct loadF(vRegF dst, memory4 mem)
 7082 %{
 7083   match(Set dst (LoadF mem));
 7084   predicate(!needs_acquiring_load(n));
 7085 
 7086   ins_cost(4 * INSN_COST);
 7087   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7088 
 7089   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7090 
 7091   ins_pipe(pipe_class_memory);
 7092 %}
 7093 
 7094 // Load Double
 7095 instruct loadD(vRegD dst, memory8 mem)
 7096 %{
 7097   match(Set dst (LoadD mem));
 7098   predicate(!needs_acquiring_load(n));
 7099 
 7100   ins_cost(4 * INSN_COST);
 7101   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7102 
 7103   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7104 
 7105   ins_pipe(pipe_class_memory);
 7106 %}
 7107 
 7108 
 7109 // Load Int Constant
 7110 instruct loadConI(iRegINoSp dst, immI src)
 7111 %{
 7112   match(Set dst src);
 7113 
 7114   ins_cost(INSN_COST);
 7115   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7116 
 7117   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7118 
 7119   ins_pipe(ialu_imm);
 7120 %}
 7121 
 7122 // Load Long Constant
 7123 instruct loadConL(iRegLNoSp dst, immL src)
 7124 %{
 7125   match(Set dst src);
 7126 
 7127   ins_cost(INSN_COST);
 7128   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7129 
 7130   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7131 
 7132   ins_pipe(ialu_imm);
 7133 %}
 7134 
 7135 // Load Pointer Constant
 7136 
 7137 instruct loadConP(iRegPNoSp dst, immP con)
 7138 %{
 7139   match(Set dst con);
 7140 
 7141   ins_cost(INSN_COST * 4);
 7142   format %{
 7143     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7144   %}
 7145 
 7146   ins_encode(aarch64_enc_mov_p(dst, con));
 7147 
 7148   ins_pipe(ialu_imm);
 7149 %}
 7150 
 7151 // Load Null Pointer Constant
 7152 
 7153 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7154 %{
 7155   match(Set dst con);
 7156 
 7157   ins_cost(INSN_COST);
 7158   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7159 
 7160   ins_encode(aarch64_enc_mov_p0(dst, con));
 7161 
 7162   ins_pipe(ialu_imm);
 7163 %}
 7164 
 7165 // Load Pointer Constant One
 7166 
 7167 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7168 %{
 7169   match(Set dst con);
 7170 
 7171   ins_cost(INSN_COST);
 7172   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7173 
 7174   ins_encode(aarch64_enc_mov_p1(dst, con));
 7175 
 7176   ins_pipe(ialu_imm);
 7177 %}
 7178 
 7179 // Load Poll Page Constant
 7180 
 7181 instruct loadConPollPage(iRegPNoSp dst, immPollPage con)
 7182 %{
 7183   match(Set dst con);
 7184 
 7185   ins_cost(INSN_COST);
 7186   format %{ &quot;adr  $dst, $con\t# Poll Page Ptr&quot; %}
 7187 
 7188   ins_encode(aarch64_enc_mov_poll_page(dst, con));
 7189 
 7190   ins_pipe(ialu_imm);
 7191 %}
 7192 
 7193 // Load Byte Map Base Constant
 7194 
 7195 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7196 %{
 7197   match(Set dst con);
 7198 
 7199   ins_cost(INSN_COST);
 7200   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7201 
 7202   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7203 
 7204   ins_pipe(ialu_imm);
 7205 %}
 7206 
 7207 // Load Narrow Pointer Constant
 7208 
 7209 instruct loadConN(iRegNNoSp dst, immN con)
 7210 %{
 7211   match(Set dst con);
 7212 
 7213   ins_cost(INSN_COST * 4);
 7214   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7215 
 7216   ins_encode(aarch64_enc_mov_n(dst, con));
 7217 
 7218   ins_pipe(ialu_imm);
 7219 %}
 7220 
 7221 // Load Narrow Null Pointer Constant
 7222 
 7223 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7224 %{
 7225   match(Set dst con);
 7226 
 7227   ins_cost(INSN_COST);
 7228   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7229 
 7230   ins_encode(aarch64_enc_mov_n0(dst, con));
 7231 
 7232   ins_pipe(ialu_imm);
 7233 %}
 7234 
 7235 // Load Narrow Klass Constant
 7236 
 7237 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7238 %{
 7239   match(Set dst con);
 7240 
 7241   ins_cost(INSN_COST);
 7242   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7243 
 7244   ins_encode(aarch64_enc_mov_nk(dst, con));
 7245 
 7246   ins_pipe(ialu_imm);
 7247 %}
 7248 
 7249 // Load Packed Float Constant
 7250 
 7251 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7252   match(Set dst con);
 7253   ins_cost(INSN_COST * 4);
 7254   format %{ &quot;fmovs  $dst, $con&quot;%}
 7255   ins_encode %{
 7256     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7257   %}
 7258 
 7259   ins_pipe(fp_imm_s);
 7260 %}
 7261 
 7262 // Load Float Constant
 7263 
 7264 instruct loadConF(vRegF dst, immF con) %{
 7265   match(Set dst con);
 7266 
 7267   ins_cost(INSN_COST * 4);
 7268 
 7269   format %{
 7270     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7271   %}
 7272 
 7273   ins_encode %{
 7274     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7275   %}
 7276 
 7277   ins_pipe(fp_load_constant_s);
 7278 %}
 7279 
 7280 // Load Packed Double Constant
 7281 
 7282 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7283   match(Set dst con);
 7284   ins_cost(INSN_COST);
 7285   format %{ &quot;fmovd  $dst, $con&quot;%}
 7286   ins_encode %{
 7287     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7288   %}
 7289 
 7290   ins_pipe(fp_imm_d);
 7291 %}
 7292 
 7293 // Load Double Constant
 7294 
 7295 instruct loadConD(vRegD dst, immD con) %{
 7296   match(Set dst con);
 7297 
 7298   ins_cost(INSN_COST * 5);
 7299   format %{
 7300     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7301   %}
 7302 
 7303   ins_encode %{
 7304     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7305   %}
 7306 
 7307   ins_pipe(fp_load_constant_d);
 7308 %}
 7309 
 7310 // Store Instructions
 7311 
 7312 // Store CMS card-mark Immediate
 7313 instruct storeimmCM0(immI0 zero, memory1 mem)
 7314 %{
 7315   match(Set mem (StoreCM mem zero));
 7316 
 7317   ins_cost(INSN_COST);
 7318   format %{ &quot;storestore (elided)\n\t&quot;
 7319             &quot;strb zr, $mem\t# byte&quot; %}
 7320 
 7321   ins_encode(aarch64_enc_strb0(mem));
 7322 
 7323   ins_pipe(istore_mem);
 7324 %}
 7325 
 7326 // Store CMS card-mark Immediate with intervening StoreStore
 7327 // needed when using CMS with no conditional card marking
 7328 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7329 %{
 7330   match(Set mem (StoreCM mem zero));
 7331 
 7332   ins_cost(INSN_COST * 2);
 7333   format %{ &quot;storestore\n\t&quot;
 7334             &quot;dmb ishst&quot;
 7335             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7336 
 7337   ins_encode(aarch64_enc_strb0_ordered(mem));
 7338 
 7339   ins_pipe(istore_mem);
 7340 %}
 7341 
 7342 // Store Byte
 7343 instruct storeB(iRegIorL2I src, memory1 mem)
 7344 %{
 7345   match(Set mem (StoreB mem src));
 7346   predicate(!needs_releasing_store(n));
 7347 
 7348   ins_cost(INSN_COST);
 7349   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7350 
 7351   ins_encode(aarch64_enc_strb(src, mem));
 7352 
 7353   ins_pipe(istore_reg_mem);
 7354 %}
 7355 
 7356 
 7357 instruct storeimmB0(immI0 zero, memory1 mem)
 7358 %{
 7359   match(Set mem (StoreB mem zero));
 7360   predicate(!needs_releasing_store(n));
 7361 
 7362   ins_cost(INSN_COST);
 7363   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7364 
 7365   ins_encode(aarch64_enc_strb0(mem));
 7366 
 7367   ins_pipe(istore_mem);
 7368 %}
 7369 
 7370 // Store Char/Short
 7371 instruct storeC(iRegIorL2I src, memory2 mem)
 7372 %{
 7373   match(Set mem (StoreC mem src));
 7374   predicate(!needs_releasing_store(n));
 7375 
 7376   ins_cost(INSN_COST);
 7377   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7378 
 7379   ins_encode(aarch64_enc_strh(src, mem));
 7380 
 7381   ins_pipe(istore_reg_mem);
 7382 %}
 7383 
 7384 instruct storeimmC0(immI0 zero, memory2 mem)
 7385 %{
 7386   match(Set mem (StoreC mem zero));
 7387   predicate(!needs_releasing_store(n));
 7388 
 7389   ins_cost(INSN_COST);
 7390   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7391 
 7392   ins_encode(aarch64_enc_strh0(mem));
 7393 
 7394   ins_pipe(istore_mem);
 7395 %}
 7396 
 7397 // Store Integer
 7398 
 7399 instruct storeI(iRegIorL2I src, memory4 mem)
 7400 %{
 7401   match(Set mem(StoreI mem src));
 7402   predicate(!needs_releasing_store(n));
 7403 
 7404   ins_cost(INSN_COST);
 7405   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7406 
 7407   ins_encode(aarch64_enc_strw(src, mem));
 7408 
 7409   ins_pipe(istore_reg_mem);
 7410 %}
 7411 
 7412 instruct storeimmI0(immI0 zero, memory4 mem)
 7413 %{
 7414   match(Set mem(StoreI mem zero));
 7415   predicate(!needs_releasing_store(n));
 7416 
 7417   ins_cost(INSN_COST);
 7418   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7419 
 7420   ins_encode(aarch64_enc_strw0(mem));
 7421 
 7422   ins_pipe(istore_mem);
 7423 %}
 7424 
 7425 // Store Long (64 bit signed)
 7426 instruct storeL(iRegL src, memory8 mem)
 7427 %{
 7428   match(Set mem (StoreL mem src));
 7429   predicate(!needs_releasing_store(n));
 7430 
 7431   ins_cost(INSN_COST);
 7432   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7433 
 7434   ins_encode(aarch64_enc_str(src, mem));
 7435 
 7436   ins_pipe(istore_reg_mem);
 7437 %}
 7438 
 7439 // Store Long (64 bit signed)
 7440 instruct storeimmL0(immL0 zero, memory8 mem)
 7441 %{
 7442   match(Set mem (StoreL mem zero));
 7443   predicate(!needs_releasing_store(n));
 7444 
 7445   ins_cost(INSN_COST);
 7446   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7447 
 7448   ins_encode(aarch64_enc_str0(mem));
 7449 
 7450   ins_pipe(istore_mem);
 7451 %}
 7452 
 7453 // Store Pointer
 7454 instruct storeP(iRegP src, memory8 mem)
 7455 %{
 7456   match(Set mem (StoreP mem src));
 7457   predicate(!needs_releasing_store(n));
 7458 
 7459   ins_cost(INSN_COST);
 7460   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7461 
 7462   ins_encode(aarch64_enc_str(src, mem));
 7463 
 7464   ins_pipe(istore_reg_mem);
 7465 %}
 7466 
 7467 // Store Pointer
 7468 instruct storeimmP0(immP0 zero, memory8 mem)
 7469 %{
 7470   match(Set mem (StoreP mem zero));
 7471   predicate(!needs_releasing_store(n));
 7472 
 7473   ins_cost(INSN_COST);
 7474   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7475 
 7476   ins_encode(aarch64_enc_str0(mem));
 7477 
 7478   ins_pipe(istore_mem);
 7479 %}
 7480 
 7481 // Store Compressed Pointer
 7482 instruct storeN(iRegN src, memory4 mem)
 7483 %{
 7484   match(Set mem (StoreN mem src));
 7485   predicate(!needs_releasing_store(n));
 7486 
 7487   ins_cost(INSN_COST);
 7488   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7489 
 7490   ins_encode(aarch64_enc_strw(src, mem));
 7491 
 7492   ins_pipe(istore_reg_mem);
 7493 %}
 7494 
 7495 instruct storeImmN0(iRegIHeapbase heapbase, immN0 zero, memory4 mem)
 7496 %{
 7497   match(Set mem (StoreN mem zero));
 7498   predicate(CompressedOops::base() == NULL &amp;&amp;
 7499             CompressedKlassPointers::base() == NULL &amp;&amp;
 7500             (!needs_releasing_store(n)));
 7501 
 7502   ins_cost(INSN_COST);
 7503   format %{ &quot;strw  rheapbase, $mem\t# compressed ptr (rheapbase==0)&quot; %}
 7504 
 7505   ins_encode(aarch64_enc_strw(heapbase, mem));
 7506 
 7507   ins_pipe(istore_reg_mem);
 7508 %}
 7509 
 7510 // Store Float
 7511 instruct storeF(vRegF src, memory4 mem)
 7512 %{
 7513   match(Set mem (StoreF mem src));
 7514   predicate(!needs_releasing_store(n));
 7515 
 7516   ins_cost(INSN_COST);
 7517   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7518 
 7519   ins_encode( aarch64_enc_strs(src, mem) );
 7520 
 7521   ins_pipe(pipe_class_memory);
 7522 %}
 7523 
 7524 // TODO
 7525 // implement storeImmF0 and storeFImmPacked
 7526 
 7527 // Store Double
 7528 instruct storeD(vRegD src, memory8 mem)
 7529 %{
 7530   match(Set mem (StoreD mem src));
 7531   predicate(!needs_releasing_store(n));
 7532 
 7533   ins_cost(INSN_COST);
 7534   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7535 
 7536   ins_encode( aarch64_enc_strd(src, mem) );
 7537 
 7538   ins_pipe(pipe_class_memory);
 7539 %}
 7540 
 7541 // Store Compressed Klass Pointer
 7542 instruct storeNKlass(iRegN src, memory4 mem)
 7543 %{
 7544   predicate(!needs_releasing_store(n));
 7545   match(Set mem (StoreNKlass mem src));
 7546 
 7547   ins_cost(INSN_COST);
 7548   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7549 
 7550   ins_encode(aarch64_enc_strw(src, mem));
 7551 
 7552   ins_pipe(istore_reg_mem);
 7553 %}
 7554 
 7555 // TODO
 7556 // implement storeImmD0 and storeDImmPacked
 7557 
 7558 // prefetch instructions
 7559 // Must be safe to execute with invalid address (cannot fault).
 7560 
 7561 instruct prefetchalloc( memory8 mem ) %{
 7562   match(PrefetchAllocation mem);
 7563 
 7564   ins_cost(INSN_COST);
 7565   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7566 
 7567   ins_encode( aarch64_enc_prefetchw(mem) );
 7568 
 7569   ins_pipe(iload_prefetch);
 7570 %}
 7571 
 7572 //  ---------------- volatile loads and stores ----------------
 7573 
 7574 // Load Byte (8 bit signed)
 7575 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7576 %{
 7577   match(Set dst (LoadB mem));
 7578 
 7579   ins_cost(VOLATILE_REF_COST);
 7580   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7581 
 7582   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7583 
 7584   ins_pipe(pipe_serial);
 7585 %}
 7586 
 7587 // Load Byte (8 bit signed) into long
 7588 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7589 %{
 7590   match(Set dst (ConvI2L (LoadB mem)));
 7591 
 7592   ins_cost(VOLATILE_REF_COST);
 7593   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7594 
 7595   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7596 
 7597   ins_pipe(pipe_serial);
 7598 %}
 7599 
 7600 // Load Byte (8 bit unsigned)
 7601 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7602 %{
 7603   match(Set dst (LoadUB mem));
 7604 
 7605   ins_cost(VOLATILE_REF_COST);
 7606   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7607 
 7608   ins_encode(aarch64_enc_ldarb(dst, mem));
 7609 
 7610   ins_pipe(pipe_serial);
 7611 %}
 7612 
 7613 // Load Byte (8 bit unsigned) into long
 7614 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7615 %{
 7616   match(Set dst (ConvI2L (LoadUB mem)));
 7617 
 7618   ins_cost(VOLATILE_REF_COST);
 7619   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7620 
 7621   ins_encode(aarch64_enc_ldarb(dst, mem));
 7622 
 7623   ins_pipe(pipe_serial);
 7624 %}
 7625 
 7626 // Load Short (16 bit signed)
 7627 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7628 %{
 7629   match(Set dst (LoadS mem));
 7630 
 7631   ins_cost(VOLATILE_REF_COST);
 7632   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7633 
 7634   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7635 
 7636   ins_pipe(pipe_serial);
 7637 %}
 7638 
 7639 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7640 %{
 7641   match(Set dst (LoadUS mem));
 7642 
 7643   ins_cost(VOLATILE_REF_COST);
 7644   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7645 
 7646   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7647 
 7648   ins_pipe(pipe_serial);
 7649 %}
 7650 
 7651 // Load Short/Char (16 bit unsigned) into long
 7652 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7653 %{
 7654   match(Set dst (ConvI2L (LoadUS mem)));
 7655 
 7656   ins_cost(VOLATILE_REF_COST);
 7657   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7658 
 7659   ins_encode(aarch64_enc_ldarh(dst, mem));
 7660 
 7661   ins_pipe(pipe_serial);
 7662 %}
 7663 
 7664 // Load Short/Char (16 bit signed) into long
 7665 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7666 %{
 7667   match(Set dst (ConvI2L (LoadS mem)));
 7668 
 7669   ins_cost(VOLATILE_REF_COST);
 7670   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7671 
 7672   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7673 
 7674   ins_pipe(pipe_serial);
 7675 %}
 7676 
 7677 // Load Integer (32 bit signed)
 7678 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7679 %{
 7680   match(Set dst (LoadI mem));
 7681 
 7682   ins_cost(VOLATILE_REF_COST);
 7683   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7684 
 7685   ins_encode(aarch64_enc_ldarw(dst, mem));
 7686 
 7687   ins_pipe(pipe_serial);
 7688 %}
 7689 
 7690 // Load Integer (32 bit unsigned) into long
 7691 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7692 %{
 7693   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7694 
 7695   ins_cost(VOLATILE_REF_COST);
 7696   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7697 
 7698   ins_encode(aarch64_enc_ldarw(dst, mem));
 7699 
 7700   ins_pipe(pipe_serial);
 7701 %}
 7702 
 7703 // Load Long (64 bit signed)
 7704 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7705 %{
 7706   match(Set dst (LoadL mem));
 7707 
 7708   ins_cost(VOLATILE_REF_COST);
 7709   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7710 
 7711   ins_encode(aarch64_enc_ldar(dst, mem));
 7712 
 7713   ins_pipe(pipe_serial);
 7714 %}
 7715 
 7716 // Load Pointer
 7717 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7718 %{
 7719   match(Set dst (LoadP mem));
 7720   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7721 
 7722   ins_cost(VOLATILE_REF_COST);
 7723   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7724 
 7725   ins_encode(aarch64_enc_ldar(dst, mem));
 7726 
 7727   ins_pipe(pipe_serial);
 7728 %}
 7729 
 7730 // Load Compressed Pointer
 7731 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7732 %{
 7733   match(Set dst (LoadN mem));
 7734 
 7735   ins_cost(VOLATILE_REF_COST);
 7736   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7737 
 7738   ins_encode(aarch64_enc_ldarw(dst, mem));
 7739 
 7740   ins_pipe(pipe_serial);
 7741 %}
 7742 
 7743 // Load Float
 7744 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7745 %{
 7746   match(Set dst (LoadF mem));
 7747 
 7748   ins_cost(VOLATILE_REF_COST);
 7749   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7750 
 7751   ins_encode( aarch64_enc_fldars(dst, mem) );
 7752 
 7753   ins_pipe(pipe_serial);
 7754 %}
 7755 
 7756 // Load Double
 7757 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7758 %{
 7759   match(Set dst (LoadD mem));
 7760 
 7761   ins_cost(VOLATILE_REF_COST);
 7762   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7763 
 7764   ins_encode( aarch64_enc_fldard(dst, mem) );
 7765 
 7766   ins_pipe(pipe_serial);
 7767 %}
 7768 
 7769 // Store Byte
 7770 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7771 %{
 7772   match(Set mem (StoreB mem src));
 7773 
 7774   ins_cost(VOLATILE_REF_COST);
 7775   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7776 
 7777   ins_encode(aarch64_enc_stlrb(src, mem));
 7778 
 7779   ins_pipe(pipe_class_memory);
 7780 %}
 7781 
 7782 // Store Char/Short
 7783 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7784 %{
 7785   match(Set mem (StoreC mem src));
 7786 
 7787   ins_cost(VOLATILE_REF_COST);
 7788   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7789 
 7790   ins_encode(aarch64_enc_stlrh(src, mem));
 7791 
 7792   ins_pipe(pipe_class_memory);
 7793 %}
 7794 
 7795 // Store Integer
 7796 
 7797 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7798 %{
 7799   match(Set mem(StoreI mem src));
 7800 
 7801   ins_cost(VOLATILE_REF_COST);
 7802   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7803 
 7804   ins_encode(aarch64_enc_stlrw(src, mem));
 7805 
 7806   ins_pipe(pipe_class_memory);
 7807 %}
 7808 
 7809 // Store Long (64 bit signed)
 7810 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7811 %{
 7812   match(Set mem (StoreL mem src));
 7813 
 7814   ins_cost(VOLATILE_REF_COST);
 7815   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7816 
 7817   ins_encode(aarch64_enc_stlr(src, mem));
 7818 
 7819   ins_pipe(pipe_class_memory);
 7820 %}
 7821 
 7822 // Store Pointer
 7823 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7824 %{
 7825   match(Set mem (StoreP mem src));
 7826 
 7827   ins_cost(VOLATILE_REF_COST);
 7828   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7829 
 7830   ins_encode(aarch64_enc_stlr(src, mem));
 7831 
 7832   ins_pipe(pipe_class_memory);
 7833 %}
 7834 
 7835 // Store Compressed Pointer
 7836 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7837 %{
 7838   match(Set mem (StoreN mem src));
 7839 
 7840   ins_cost(VOLATILE_REF_COST);
 7841   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7842 
 7843   ins_encode(aarch64_enc_stlrw(src, mem));
 7844 
 7845   ins_pipe(pipe_class_memory);
 7846 %}
 7847 
 7848 // Store Float
 7849 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7850 %{
 7851   match(Set mem (StoreF mem src));
 7852 
 7853   ins_cost(VOLATILE_REF_COST);
 7854   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7855 
 7856   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7857 
 7858   ins_pipe(pipe_class_memory);
 7859 %}
 7860 
 7861 // TODO
 7862 // implement storeImmF0 and storeFImmPacked
 7863 
 7864 // Store Double
 7865 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7866 %{
 7867   match(Set mem (StoreD mem src));
 7868 
 7869   ins_cost(VOLATILE_REF_COST);
 7870   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7871 
 7872   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7873 
 7874   ins_pipe(pipe_class_memory);
 7875 %}
 7876 
 7877 //  ---------------- end of volatile loads and stores ----------------
 7878 
 7879 instruct cacheWB(indirect addr)
 7880 %{
 7881   predicate(VM_Version::supports_data_cache_line_flush());
 7882   match(CacheWB addr);
 7883 
 7884   ins_cost(100);
 7885   format %{&quot;cache wb $addr&quot; %}
 7886   ins_encode %{
 7887     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7888     assert($addr$$disp == 0, &quot;should be&quot;);
 7889     __ cache_wb(Address($addr$$base$$Register, 0));
 7890   %}
 7891   ins_pipe(pipe_slow); // XXX
 7892 %}
 7893 
 7894 instruct cacheWBPreSync()
 7895 %{
 7896   predicate(VM_Version::supports_data_cache_line_flush());
 7897   match(CacheWBPreSync);
 7898 
 7899   ins_cost(100);
 7900   format %{&quot;cache wb presync&quot; %}
 7901   ins_encode %{
 7902     __ cache_wbsync(true);
 7903   %}
 7904   ins_pipe(pipe_slow); // XXX
 7905 %}
 7906 
 7907 instruct cacheWBPostSync()
 7908 %{
 7909   predicate(VM_Version::supports_data_cache_line_flush());
 7910   match(CacheWBPostSync);
 7911 
 7912   ins_cost(100);
 7913   format %{&quot;cache wb postsync&quot; %}
 7914   ins_encode %{
 7915     __ cache_wbsync(false);
 7916   %}
 7917   ins_pipe(pipe_slow); // XXX
 7918 %}
 7919 
 7920 // ============================================================================
 7921 // BSWAP Instructions
 7922 
 7923 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7924   match(Set dst (ReverseBytesI src));
 7925 
 7926   ins_cost(INSN_COST);
 7927   format %{ &quot;revw  $dst, $src&quot; %}
 7928 
 7929   ins_encode %{
 7930     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7931   %}
 7932 
 7933   ins_pipe(ialu_reg);
 7934 %}
 7935 
 7936 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7937   match(Set dst (ReverseBytesL src));
 7938 
 7939   ins_cost(INSN_COST);
 7940   format %{ &quot;rev  $dst, $src&quot; %}
 7941 
 7942   ins_encode %{
 7943     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7944   %}
 7945 
 7946   ins_pipe(ialu_reg);
 7947 %}
 7948 
 7949 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7950   match(Set dst (ReverseBytesUS src));
 7951 
 7952   ins_cost(INSN_COST);
 7953   format %{ &quot;rev16w  $dst, $src&quot; %}
 7954 
 7955   ins_encode %{
 7956     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7957   %}
 7958 
 7959   ins_pipe(ialu_reg);
 7960 %}
 7961 
 7962 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7963   match(Set dst (ReverseBytesS src));
 7964 
 7965   ins_cost(INSN_COST);
 7966   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7967             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7968 
 7969   ins_encode %{
 7970     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7971     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7972   %}
 7973 
 7974   ins_pipe(ialu_reg);
 7975 %}
 7976 
 7977 // ============================================================================
 7978 // Zero Count Instructions
 7979 
 7980 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7981   match(Set dst (CountLeadingZerosI src));
 7982 
 7983   ins_cost(INSN_COST);
 7984   format %{ &quot;clzw  $dst, $src&quot; %}
 7985   ins_encode %{
 7986     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7987   %}
 7988 
 7989   ins_pipe(ialu_reg);
 7990 %}
 7991 
 7992 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 7993   match(Set dst (CountLeadingZerosL src));
 7994 
 7995   ins_cost(INSN_COST);
 7996   format %{ &quot;clz   $dst, $src&quot; %}
 7997   ins_encode %{
 7998     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 7999   %}
 8000 
 8001   ins_pipe(ialu_reg);
 8002 %}
 8003 
 8004 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 8005   match(Set dst (CountTrailingZerosI src));
 8006 
 8007   ins_cost(INSN_COST * 2);
 8008   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 8009             &quot;clzw   $dst, $dst&quot; %}
 8010   ins_encode %{
 8011     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 8012     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 8013   %}
 8014 
 8015   ins_pipe(ialu_reg);
 8016 %}
 8017 
 8018 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 8019   match(Set dst (CountTrailingZerosL src));
 8020 
 8021   ins_cost(INSN_COST * 2);
 8022   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8023             &quot;clz    $dst, $dst&quot; %}
 8024   ins_encode %{
 8025     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8026     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8027   %}
 8028 
 8029   ins_pipe(ialu_reg);
 8030 %}
 8031 
 8032 //---------- Population Count Instructions -------------------------------------
 8033 //
 8034 
 8035 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8036   predicate(UsePopCountInstruction);
 8037   match(Set dst (PopCountI src));
 8038   effect(TEMP tmp);
 8039   ins_cost(INSN_COST * 13);
 8040 
 8041   format %{ &quot;movw   $src, $src\n\t&quot;
 8042             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8043             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8044             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8045             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8046   ins_encode %{
 8047     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8048     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8049     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8050     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8051     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8052   %}
 8053 
 8054   ins_pipe(pipe_class_default);
 8055 %}
 8056 
 8057 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8058   predicate(UsePopCountInstruction);
 8059   match(Set dst (PopCountI (LoadI mem)));
 8060   effect(TEMP tmp);
 8061   ins_cost(INSN_COST * 13);
 8062 
 8063   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8064             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8065             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8066             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8067   ins_encode %{
 8068     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8069     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8070               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8071     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8072     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8073     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8074   %}
 8075 
 8076   ins_pipe(pipe_class_default);
 8077 %}
 8078 
 8079 // Note: Long.bitCount(long) returns an int.
 8080 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8081   predicate(UsePopCountInstruction);
 8082   match(Set dst (PopCountL src));
 8083   effect(TEMP tmp);
 8084   ins_cost(INSN_COST * 13);
 8085 
 8086   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8087             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8088             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8089             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8090   ins_encode %{
 8091     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8092     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8093     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8094     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8095   %}
 8096 
 8097   ins_pipe(pipe_class_default);
 8098 %}
 8099 
 8100 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8101   predicate(UsePopCountInstruction);
 8102   match(Set dst (PopCountL (LoadL mem)));
 8103   effect(TEMP tmp);
 8104   ins_cost(INSN_COST * 13);
 8105 
 8106   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8107             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8108             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8109             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8110   ins_encode %{
 8111     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8112     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8113               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8114     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8115     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8116     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8117   %}
 8118 
 8119   ins_pipe(pipe_class_default);
 8120 %}
 8121 
 8122 // ============================================================================
 8123 // MemBar Instruction
 8124 
 8125 instruct load_fence() %{
 8126   match(LoadFence);
 8127   ins_cost(VOLATILE_REF_COST);
 8128 
 8129   format %{ &quot;load_fence&quot; %}
 8130 
 8131   ins_encode %{
 8132     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8133   %}
 8134   ins_pipe(pipe_serial);
 8135 %}
 8136 
 8137 instruct unnecessary_membar_acquire() %{
 8138   predicate(unnecessary_acquire(n));
 8139   match(MemBarAcquire);
 8140   ins_cost(0);
 8141 
 8142   format %{ &quot;membar_acquire (elided)&quot; %}
 8143 
 8144   ins_encode %{
 8145     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8146   %}
 8147 
 8148   ins_pipe(pipe_class_empty);
 8149 %}
 8150 
 8151 instruct membar_acquire() %{
 8152   match(MemBarAcquire);
 8153   ins_cost(VOLATILE_REF_COST);
 8154 
 8155   format %{ &quot;membar_acquire\n\t&quot;
 8156             &quot;dmb ish&quot; %}
 8157 
 8158   ins_encode %{
 8159     __ block_comment(&quot;membar_acquire&quot;);
 8160     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8161   %}
 8162 
 8163   ins_pipe(pipe_serial);
 8164 %}
 8165 
 8166 
 8167 instruct membar_acquire_lock() %{
 8168   match(MemBarAcquireLock);
 8169   ins_cost(VOLATILE_REF_COST);
 8170 
 8171   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8172 
 8173   ins_encode %{
 8174     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8175   %}
 8176 
 8177   ins_pipe(pipe_serial);
 8178 %}
 8179 
 8180 instruct store_fence() %{
 8181   match(StoreFence);
 8182   ins_cost(VOLATILE_REF_COST);
 8183 
 8184   format %{ &quot;store_fence&quot; %}
 8185 
 8186   ins_encode %{
 8187     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8188   %}
 8189   ins_pipe(pipe_serial);
 8190 %}
 8191 
 8192 instruct unnecessary_membar_release() %{
 8193   predicate(unnecessary_release(n));
 8194   match(MemBarRelease);
 8195   ins_cost(0);
 8196 
 8197   format %{ &quot;membar_release (elided)&quot; %}
 8198 
 8199   ins_encode %{
 8200     __ block_comment(&quot;membar_release (elided)&quot;);
 8201   %}
 8202   ins_pipe(pipe_serial);
 8203 %}
 8204 
 8205 instruct membar_release() %{
 8206   match(MemBarRelease);
 8207   ins_cost(VOLATILE_REF_COST);
 8208 
 8209   format %{ &quot;membar_release\n\t&quot;
 8210             &quot;dmb ish&quot; %}
 8211 
 8212   ins_encode %{
 8213     __ block_comment(&quot;membar_release&quot;);
 8214     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8215   %}
 8216   ins_pipe(pipe_serial);
 8217 %}
 8218 
 8219 instruct membar_storestore() %{
 8220   match(MemBarStoreStore);
 8221   ins_cost(VOLATILE_REF_COST);
 8222 
 8223   format %{ &quot;MEMBAR-store-store&quot; %}
 8224 
 8225   ins_encode %{
 8226     __ membar(Assembler::StoreStore);
 8227   %}
 8228   ins_pipe(pipe_serial);
 8229 %}
 8230 
 8231 instruct membar_release_lock() %{
 8232   match(MemBarReleaseLock);
 8233   ins_cost(VOLATILE_REF_COST);
 8234 
 8235   format %{ &quot;membar_release_lock (elided)&quot; %}
 8236 
 8237   ins_encode %{
 8238     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8239   %}
 8240 
 8241   ins_pipe(pipe_serial);
 8242 %}
 8243 
 8244 instruct unnecessary_membar_volatile() %{
 8245   predicate(unnecessary_volatile(n));
 8246   match(MemBarVolatile);
 8247   ins_cost(0);
 8248 
 8249   format %{ &quot;membar_volatile (elided)&quot; %}
 8250 
 8251   ins_encode %{
 8252     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8253   %}
 8254 
 8255   ins_pipe(pipe_serial);
 8256 %}
 8257 
 8258 instruct membar_volatile() %{
 8259   match(MemBarVolatile);
 8260   ins_cost(VOLATILE_REF_COST*100);
 8261 
 8262   format %{ &quot;membar_volatile\n\t&quot;
 8263              &quot;dmb ish&quot;%}
 8264 
 8265   ins_encode %{
 8266     __ block_comment(&quot;membar_volatile&quot;);
 8267     __ membar(Assembler::StoreLoad);
 8268   %}
 8269 
 8270   ins_pipe(pipe_serial);
 8271 %}
 8272 
 8273 // ============================================================================
 8274 // Cast/Convert Instructions
 8275 
 8276 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8277   match(Set dst (CastX2P src));
 8278 
 8279   ins_cost(INSN_COST);
 8280   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8281 
 8282   ins_encode %{
 8283     if ($dst$$reg != $src$$reg) {
 8284       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8285     }
 8286   %}
 8287 
 8288   ins_pipe(ialu_reg);
 8289 %}
 8290 
 8291 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8292   match(Set dst (CastP2X src));
 8293 
 8294   ins_cost(INSN_COST);
 8295   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8296 
 8297   ins_encode %{
 8298     if ($dst$$reg != $src$$reg) {
 8299       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8300     }
 8301   %}
 8302 
 8303   ins_pipe(ialu_reg);
 8304 %}
 8305 
 8306 // Convert oop into int for vectors alignment masking
 8307 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8308   match(Set dst (ConvL2I (CastP2X src)));
 8309 
 8310   ins_cost(INSN_COST);
 8311   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8312   ins_encode %{
 8313     __ movw($dst$$Register, $src$$Register);
 8314   %}
 8315 
 8316   ins_pipe(ialu_reg);
 8317 %}
 8318 
 8319 // Convert compressed oop into int for vectors alignment masking
 8320 // in case of 32bit oops (heap &lt; 4Gb).
 8321 instruct convN2I(iRegINoSp dst, iRegN src)
 8322 %{
 8323   predicate(CompressedOops::shift() == 0);
 8324   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8325 
 8326   ins_cost(INSN_COST);
 8327   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8328   ins_encode %{
 8329     __ movw($dst$$Register, $src$$Register);
 8330   %}
 8331 
 8332   ins_pipe(ialu_reg);
 8333 %}
 8334 
 8335 
 8336 // Convert oop pointer into compressed form
 8337 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8338   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8339   match(Set dst (EncodeP src));
 8340   effect(KILL cr);
 8341   ins_cost(INSN_COST * 3);
 8342   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8343   ins_encode %{
 8344     Register s = $src$$Register;
 8345     Register d = $dst$$Register;
 8346     __ encode_heap_oop(d, s);
 8347   %}
 8348   ins_pipe(ialu_reg);
 8349 %}
 8350 
 8351 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8352   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8353   match(Set dst (EncodeP src));
 8354   ins_cost(INSN_COST * 3);
 8355   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8356   ins_encode %{
 8357     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8358   %}
 8359   ins_pipe(ialu_reg);
 8360 %}
 8361 
 8362 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8363   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8364             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8365   match(Set dst (DecodeN src));
 8366   ins_cost(INSN_COST * 3);
 8367   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8368   ins_encode %{
 8369     Register s = $src$$Register;
 8370     Register d = $dst$$Register;
 8371     __ decode_heap_oop(d, s);
 8372   %}
 8373   ins_pipe(ialu_reg);
 8374 %}
 8375 
 8376 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8377   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8378             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8379   match(Set dst (DecodeN src));
 8380   ins_cost(INSN_COST * 3);
 8381   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8382   ins_encode %{
 8383     Register s = $src$$Register;
 8384     Register d = $dst$$Register;
 8385     __ decode_heap_oop_not_null(d, s);
 8386   %}
 8387   ins_pipe(ialu_reg);
 8388 %}
 8389 
 8390 // n.b. AArch64 implementations of encode_klass_not_null and
 8391 // decode_klass_not_null do not modify the flags register so, unlike
 8392 // Intel, we don&#39;t kill CR as a side effect here
 8393 
 8394 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8395   match(Set dst (EncodePKlass src));
 8396 
 8397   ins_cost(INSN_COST * 3);
 8398   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8399 
 8400   ins_encode %{
 8401     Register src_reg = as_Register($src$$reg);
 8402     Register dst_reg = as_Register($dst$$reg);
 8403     __ encode_klass_not_null(dst_reg, src_reg);
 8404   %}
 8405 
 8406    ins_pipe(ialu_reg);
 8407 %}
 8408 
 8409 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8410   match(Set dst (DecodeNKlass src));
 8411 
 8412   ins_cost(INSN_COST * 3);
 8413   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8414 
 8415   ins_encode %{
 8416     Register src_reg = as_Register($src$$reg);
 8417     Register dst_reg = as_Register($dst$$reg);
 8418     if (dst_reg != src_reg) {
 8419       __ decode_klass_not_null(dst_reg, src_reg);
 8420     } else {
 8421       __ decode_klass_not_null(dst_reg);
 8422     }
 8423   %}
 8424 
 8425    ins_pipe(ialu_reg);
 8426 %}
 8427 
 8428 instruct checkCastPP(iRegPNoSp dst)
 8429 %{
 8430   match(Set dst (CheckCastPP dst));
 8431 
 8432   size(0);
 8433   format %{ &quot;# checkcastPP of $dst&quot; %}
 8434   ins_encode(/* empty encoding */);
 8435   ins_pipe(pipe_class_empty);
 8436 %}
 8437 
 8438 instruct castPP(iRegPNoSp dst)
 8439 %{
 8440   match(Set dst (CastPP dst));
 8441 
 8442   size(0);
 8443   format %{ &quot;# castPP of $dst&quot; %}
 8444   ins_encode(/* empty encoding */);
 8445   ins_pipe(pipe_class_empty);
 8446 %}
 8447 
 8448 instruct castII(iRegI dst)
 8449 %{
 8450   match(Set dst (CastII dst));
 8451 
 8452   size(0);
 8453   format %{ &quot;# castII of $dst&quot; %}
 8454   ins_encode(/* empty encoding */);
 8455   ins_cost(0);
 8456   ins_pipe(pipe_class_empty);
 8457 %}
 8458 
 8459 instruct castLL(iRegL dst)
 8460 %{
 8461   match(Set dst (CastLL dst));
 8462 
 8463   size(0);
 8464   format %{ &quot;# castLL of $dst&quot; %}
 8465   ins_encode(/* empty encoding */);
 8466   ins_cost(0);
 8467   ins_pipe(pipe_class_empty);
 8468 %}
 8469 
 8470 // ============================================================================
 8471 // Atomic operation instructions
 8472 //
 8473 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8474 // Store{PIL}Conditional instructions using a normal load for the
 8475 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8476 //
 8477 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8478 // pair to lock object allocations from Eden space when not using
 8479 // TLABs.
 8480 //
 8481 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8482 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8483 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8484 // only for 64-bit.
 8485 //
 8486 // We implement LoadPLocked and StorePLocked instructions using,
 8487 // respectively the AArch64 hw load-exclusive and store-conditional
 8488 // instructions. Whereas we must implement each of
 8489 // Store{IL}Conditional using a CAS which employs a pair of
 8490 // instructions comprising a load-exclusive followed by a
 8491 // store-conditional.
 8492 
 8493 
 8494 // Locked-load (linked load) of the current heap-top
 8495 // used when updating the eden heap top
 8496 // implemented using ldaxr on AArch64
 8497 
 8498 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8499 %{
 8500   match(Set dst (LoadPLocked mem));
 8501 
 8502   ins_cost(VOLATILE_REF_COST);
 8503 
 8504   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8505 
 8506   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8507 
 8508   ins_pipe(pipe_serial);
 8509 %}
 8510 
 8511 // Conditional-store of the updated heap-top.
 8512 // Used during allocation of the shared heap.
 8513 // Sets flag (EQ) on success.
 8514 // implemented using stlxr on AArch64.
 8515 
 8516 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8517 %{
 8518   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8519 
 8520   ins_cost(VOLATILE_REF_COST);
 8521 
 8522  // TODO
 8523  // do we need to do a store-conditional release or can we just use a
 8524  // plain store-conditional?
 8525 
 8526   format %{
 8527     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8528     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8529   %}
 8530 
 8531   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8532 
 8533   ins_pipe(pipe_serial);
 8534 %}
 8535 
 8536 
 8537 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8538 // when attempting to rebias a lock towards the current thread.  We
 8539 // must use the acquire form of cmpxchg in order to guarantee acquire
 8540 // semantics in this case.
 8541 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8542 %{
 8543   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8544 
 8545   ins_cost(VOLATILE_REF_COST);
 8546 
 8547   format %{
 8548     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8549     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8550   %}
 8551 
 8552   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8553 
 8554   ins_pipe(pipe_slow);
 8555 %}
 8556 
 8557 // storeIConditional also has acquire semantics, for no better reason
 8558 // than matching storeLConditional.  At the time of writing this
 8559 // comment storeIConditional was not used anywhere by AArch64.
 8560 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8561 %{
 8562   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8563 
 8564   ins_cost(VOLATILE_REF_COST);
 8565 
 8566   format %{
 8567     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8568     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8569   %}
 8570 
 8571   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8572 
 8573   ins_pipe(pipe_slow);
 8574 %}
 8575 
 8576 // standard CompareAndSwapX when we are using barriers
 8577 // these have higher priority than the rules selected by a predicate
 8578 
 8579 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8580 // can&#39;t match them
 8581 
 8582 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8583 
 8584   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8585   ins_cost(2 * VOLATILE_REF_COST);
 8586 
 8587   effect(KILL cr);
 8588 
 8589   format %{
 8590     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8591     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8592   %}
 8593 
 8594   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8595             aarch64_enc_cset_eq(res));
 8596 
 8597   ins_pipe(pipe_slow);
 8598 %}
 8599 
 8600 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8601 
 8602   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8603   ins_cost(2 * VOLATILE_REF_COST);
 8604 
 8605   effect(KILL cr);
 8606 
 8607   format %{
 8608     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8609     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8610   %}
 8611 
 8612   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8613             aarch64_enc_cset_eq(res));
 8614 
 8615   ins_pipe(pipe_slow);
 8616 %}
 8617 
 8618 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8619 
 8620   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8621   ins_cost(2 * VOLATILE_REF_COST);
 8622 
 8623   effect(KILL cr);
 8624 
 8625  format %{
 8626     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8627     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8628  %}
 8629 
 8630  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8631             aarch64_enc_cset_eq(res));
 8632 
 8633   ins_pipe(pipe_slow);
 8634 %}
 8635 
 8636 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8637 
 8638   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8639   ins_cost(2 * VOLATILE_REF_COST);
 8640 
 8641   effect(KILL cr);
 8642 
 8643  format %{
 8644     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8645     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8646  %}
 8647 
 8648  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8649             aarch64_enc_cset_eq(res));
 8650 
 8651   ins_pipe(pipe_slow);
 8652 %}
 8653 
 8654 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8655 
 8656   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8657   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8658   ins_cost(2 * VOLATILE_REF_COST);
 8659 
 8660   effect(KILL cr);
 8661 
 8662  format %{
 8663     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8664     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8665  %}
 8666 
 8667  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8668             aarch64_enc_cset_eq(res));
 8669 
 8670   ins_pipe(pipe_slow);
 8671 %}
 8672 
 8673 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8674 
 8675   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8676   ins_cost(2 * VOLATILE_REF_COST);
 8677 
 8678   effect(KILL cr);
 8679 
 8680  format %{
 8681     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8682     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8683  %}
 8684 
 8685  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8686             aarch64_enc_cset_eq(res));
 8687 
 8688   ins_pipe(pipe_slow);
 8689 %}
 8690 
 8691 // alternative CompareAndSwapX when we are eliding barriers
 8692 
 8693 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8694 
 8695   predicate(needs_acquiring_load_exclusive(n));
 8696   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8697   ins_cost(VOLATILE_REF_COST);
 8698 
 8699   effect(KILL cr);
 8700 
 8701   format %{
 8702     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8703     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8704   %}
 8705 
 8706   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8707             aarch64_enc_cset_eq(res));
 8708 
 8709   ins_pipe(pipe_slow);
 8710 %}
 8711 
 8712 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8713 
 8714   predicate(needs_acquiring_load_exclusive(n));
 8715   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8716   ins_cost(VOLATILE_REF_COST);
 8717 
 8718   effect(KILL cr);
 8719 
 8720   format %{
 8721     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8722     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8723   %}
 8724 
 8725   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8726             aarch64_enc_cset_eq(res));
 8727 
 8728   ins_pipe(pipe_slow);
 8729 %}
 8730 
 8731 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8732 
 8733   predicate(needs_acquiring_load_exclusive(n));
 8734   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8735   ins_cost(VOLATILE_REF_COST);
 8736 
 8737   effect(KILL cr);
 8738 
 8739  format %{
 8740     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8741     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8742  %}
 8743 
 8744  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8745             aarch64_enc_cset_eq(res));
 8746 
 8747   ins_pipe(pipe_slow);
 8748 %}
 8749 
 8750 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8751 
 8752   predicate(needs_acquiring_load_exclusive(n));
 8753   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8754   ins_cost(VOLATILE_REF_COST);
 8755 
 8756   effect(KILL cr);
 8757 
 8758  format %{
 8759     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8760     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8761  %}
 8762 
 8763  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8764             aarch64_enc_cset_eq(res));
 8765 
 8766   ins_pipe(pipe_slow);
 8767 %}
 8768 
 8769 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8770 
 8771   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8772   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8773   ins_cost(VOLATILE_REF_COST);
 8774 
 8775   effect(KILL cr);
 8776 
 8777  format %{
 8778     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8779     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8780  %}
 8781 
 8782  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8783             aarch64_enc_cset_eq(res));
 8784 
 8785   ins_pipe(pipe_slow);
 8786 %}
 8787 
 8788 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8789 
 8790   predicate(needs_acquiring_load_exclusive(n));
 8791   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8792   ins_cost(VOLATILE_REF_COST);
 8793 
 8794   effect(KILL cr);
 8795 
 8796  format %{
 8797     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8798     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8799  %}
 8800 
 8801  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8802             aarch64_enc_cset_eq(res));
 8803 
 8804   ins_pipe(pipe_slow);
 8805 %}
 8806 
 8807 
 8808 // ---------------------------------------------------------------------
 8809 
 8810 
 8811 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8812 
 8813 // Sundry CAS operations.  Note that release is always true,
 8814 // regardless of the memory ordering of the CAS.  This is because we
 8815 // need the volatile case to be sequentially consistent but there is
 8816 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8817 // can&#39;t check the type of memory ordering here, so we always emit a
 8818 // STLXR.
 8819 
 8820 // This section is generated from aarch64_ad_cas.m4
 8821 
 8822 
 8823 
 8824 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8825   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8826   ins_cost(2 * VOLATILE_REF_COST);
 8827   effect(TEMP_DEF res, KILL cr);
 8828   format %{
 8829     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8830   %}
 8831   ins_encode %{
 8832     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8833                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8834                /*weak*/ false, $res$$Register);
 8835     __ sxtbw($res$$Register, $res$$Register);
 8836   %}
 8837   ins_pipe(pipe_slow);
 8838 %}
 8839 
 8840 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8841   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8842   ins_cost(2 * VOLATILE_REF_COST);
 8843   effect(TEMP_DEF res, KILL cr);
 8844   format %{
 8845     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8846   %}
 8847   ins_encode %{
 8848     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8849                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8850                /*weak*/ false, $res$$Register);
 8851     __ sxthw($res$$Register, $res$$Register);
 8852   %}
 8853   ins_pipe(pipe_slow);
 8854 %}
 8855 
 8856 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8857   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8858   ins_cost(2 * VOLATILE_REF_COST);
 8859   effect(TEMP_DEF res, KILL cr);
 8860   format %{
 8861     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8862   %}
 8863   ins_encode %{
 8864     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8865                Assembler::word, /*acquire*/ false, /*release*/ true,
 8866                /*weak*/ false, $res$$Register);
 8867   %}
 8868   ins_pipe(pipe_slow);
 8869 %}
 8870 
 8871 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8872   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8873   ins_cost(2 * VOLATILE_REF_COST);
 8874   effect(TEMP_DEF res, KILL cr);
 8875   format %{
 8876     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8877   %}
 8878   ins_encode %{
 8879     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8880                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8881                /*weak*/ false, $res$$Register);
 8882   %}
 8883   ins_pipe(pipe_slow);
 8884 %}
 8885 
 8886 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8887   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8888   ins_cost(2 * VOLATILE_REF_COST);
 8889   effect(TEMP_DEF res, KILL cr);
 8890   format %{
 8891     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8892   %}
 8893   ins_encode %{
 8894     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8895                Assembler::word, /*acquire*/ false, /*release*/ true,
 8896                /*weak*/ false, $res$$Register);
 8897   %}
 8898   ins_pipe(pipe_slow);
 8899 %}
 8900 
 8901 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8902   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8903   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8904   ins_cost(2 * VOLATILE_REF_COST);
 8905   effect(TEMP_DEF res, KILL cr);
 8906   format %{
 8907     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8908   %}
 8909   ins_encode %{
 8910     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8911                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8912                /*weak*/ false, $res$$Register);
 8913   %}
 8914   ins_pipe(pipe_slow);
 8915 %}
 8916 
 8917 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8918   predicate(needs_acquiring_load_exclusive(n));
 8919   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8920   ins_cost(VOLATILE_REF_COST);
 8921   effect(TEMP_DEF res, KILL cr);
 8922   format %{
 8923     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8924   %}
 8925   ins_encode %{
 8926     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8927                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8928                /*weak*/ false, $res$$Register);
 8929     __ sxtbw($res$$Register, $res$$Register);
 8930   %}
 8931   ins_pipe(pipe_slow);
 8932 %}
 8933 
 8934 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8935   predicate(needs_acquiring_load_exclusive(n));
 8936   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8937   ins_cost(VOLATILE_REF_COST);
 8938   effect(TEMP_DEF res, KILL cr);
 8939   format %{
 8940     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8941   %}
 8942   ins_encode %{
 8943     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8944                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8945                /*weak*/ false, $res$$Register);
 8946     __ sxthw($res$$Register, $res$$Register);
 8947   %}
 8948   ins_pipe(pipe_slow);
 8949 %}
 8950 
 8951 
 8952 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8953   predicate(needs_acquiring_load_exclusive(n));
 8954   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8955   ins_cost(VOLATILE_REF_COST);
 8956   effect(TEMP_DEF res, KILL cr);
 8957   format %{
 8958     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8959   %}
 8960   ins_encode %{
 8961     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8962                Assembler::word, /*acquire*/ true, /*release*/ true,
 8963                /*weak*/ false, $res$$Register);
 8964   %}
 8965   ins_pipe(pipe_slow);
 8966 %}
 8967 
 8968 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8969   predicate(needs_acquiring_load_exclusive(n));
 8970   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8971   ins_cost(VOLATILE_REF_COST);
 8972   effect(TEMP_DEF res, KILL cr);
 8973   format %{
 8974     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8975   %}
 8976   ins_encode %{
 8977     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8978                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8979                /*weak*/ false, $res$$Register);
 8980   %}
 8981   ins_pipe(pipe_slow);
 8982 %}
 8983 
 8984 
 8985 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8986   predicate(needs_acquiring_load_exclusive(n));
 8987   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8988   ins_cost(VOLATILE_REF_COST);
 8989   effect(TEMP_DEF res, KILL cr);
 8990   format %{
 8991     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8992   %}
 8993   ins_encode %{
 8994     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8995                Assembler::word, /*acquire*/ true, /*release*/ true,
 8996                /*weak*/ false, $res$$Register);
 8997   %}
 8998   ins_pipe(pipe_slow);
 8999 %}
 9000 
 9001 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9002   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9003   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 9004   ins_cost(VOLATILE_REF_COST);
 9005   effect(TEMP_DEF res, KILL cr);
 9006   format %{
 9007     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9008   %}
 9009   ins_encode %{
 9010     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9011                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9012                /*weak*/ false, $res$$Register);
 9013   %}
 9014   ins_pipe(pipe_slow);
 9015 %}
 9016 
 9017 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9018   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9019   ins_cost(2 * VOLATILE_REF_COST);
 9020   effect(KILL cr);
 9021   format %{
 9022     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9023     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9024   %}
 9025   ins_encode %{
 9026     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9027                Assembler::byte, /*acquire*/ false, /*release*/ true,
 9028                /*weak*/ true, noreg);
 9029     __ csetw($res$$Register, Assembler::EQ);
 9030   %}
 9031   ins_pipe(pipe_slow);
 9032 %}
 9033 
 9034 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9035   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9036   ins_cost(2 * VOLATILE_REF_COST);
 9037   effect(KILL cr);
 9038   format %{
 9039     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9040     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9041   %}
 9042   ins_encode %{
 9043     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9044                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9045                /*weak*/ true, noreg);
 9046     __ csetw($res$$Register, Assembler::EQ);
 9047   %}
 9048   ins_pipe(pipe_slow);
 9049 %}
 9050 
 9051 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9052   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9053   ins_cost(2 * VOLATILE_REF_COST);
 9054   effect(KILL cr);
 9055   format %{
 9056     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9057     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9058   %}
 9059   ins_encode %{
 9060     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9061                Assembler::word, /*acquire*/ false, /*release*/ true,
 9062                /*weak*/ true, noreg);
 9063     __ csetw($res$$Register, Assembler::EQ);
 9064   %}
 9065   ins_pipe(pipe_slow);
 9066 %}
 9067 
 9068 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9069   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9070   ins_cost(2 * VOLATILE_REF_COST);
 9071   effect(KILL cr);
 9072   format %{
 9073     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9074     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9075   %}
 9076   ins_encode %{
 9077     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9078                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9079                /*weak*/ true, noreg);
 9080     __ csetw($res$$Register, Assembler::EQ);
 9081   %}
 9082   ins_pipe(pipe_slow);
 9083 %}
 9084 
 9085 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9086   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9087   ins_cost(2 * VOLATILE_REF_COST);
 9088   effect(KILL cr);
 9089   format %{
 9090     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9091     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9092   %}
 9093   ins_encode %{
 9094     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9095                Assembler::word, /*acquire*/ false, /*release*/ true,
 9096                /*weak*/ true, noreg);
 9097     __ csetw($res$$Register, Assembler::EQ);
 9098   %}
 9099   ins_pipe(pipe_slow);
 9100 %}
 9101 
 9102 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9103   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9104   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9105   ins_cost(2 * VOLATILE_REF_COST);
 9106   effect(KILL cr);
 9107   format %{
 9108     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9109     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9110   %}
 9111   ins_encode %{
 9112     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9113                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9114                /*weak*/ true, noreg);
 9115     __ csetw($res$$Register, Assembler::EQ);
 9116   %}
 9117   ins_pipe(pipe_slow);
 9118 %}
 9119 
 9120 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9121   predicate(needs_acquiring_load_exclusive(n));
 9122   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9123   ins_cost(VOLATILE_REF_COST);
 9124   effect(KILL cr);
 9125   format %{
 9126     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9127     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9128   %}
 9129   ins_encode %{
 9130     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9131                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9132                /*weak*/ true, noreg);
 9133     __ csetw($res$$Register, Assembler::EQ);
 9134   %}
 9135   ins_pipe(pipe_slow);
 9136 %}
 9137 
 9138 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9139   predicate(needs_acquiring_load_exclusive(n));
 9140   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9141   ins_cost(VOLATILE_REF_COST);
 9142   effect(KILL cr);
 9143   format %{
 9144     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9145     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9146   %}
 9147   ins_encode %{
 9148     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9149                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9150                /*weak*/ true, noreg);
 9151     __ csetw($res$$Register, Assembler::EQ);
 9152   %}
 9153   ins_pipe(pipe_slow);
 9154 %}
 9155 
 9156 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9157   predicate(needs_acquiring_load_exclusive(n));
 9158   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9159   ins_cost(VOLATILE_REF_COST);
 9160   effect(KILL cr);
 9161   format %{
 9162     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9163     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9164   %}
 9165   ins_encode %{
 9166     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9167                Assembler::word, /*acquire*/ true, /*release*/ true,
 9168                /*weak*/ true, noreg);
 9169     __ csetw($res$$Register, Assembler::EQ);
 9170   %}
 9171   ins_pipe(pipe_slow);
 9172 %}
 9173 
 9174 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9175   predicate(needs_acquiring_load_exclusive(n));
 9176   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9177   ins_cost(VOLATILE_REF_COST);
 9178   effect(KILL cr);
 9179   format %{
 9180     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9181     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9182   %}
 9183   ins_encode %{
 9184     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9185                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9186                /*weak*/ true, noreg);
 9187     __ csetw($res$$Register, Assembler::EQ);
 9188   %}
 9189   ins_pipe(pipe_slow);
 9190 %}
 9191 
 9192 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9193   predicate(needs_acquiring_load_exclusive(n));
 9194   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9195   ins_cost(VOLATILE_REF_COST);
 9196   effect(KILL cr);
 9197   format %{
 9198     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9199     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9200   %}
 9201   ins_encode %{
 9202     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9203                Assembler::word, /*acquire*/ true, /*release*/ true,
 9204                /*weak*/ true, noreg);
 9205     __ csetw($res$$Register, Assembler::EQ);
 9206   %}
 9207   ins_pipe(pipe_slow);
 9208 %}
 9209 
 9210 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9211   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9212   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9213   ins_cost(VOLATILE_REF_COST);
 9214   effect(KILL cr);
 9215   format %{
 9216     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9217     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9218   %}
 9219   ins_encode %{
 9220     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9221                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9222                /*weak*/ true, noreg);
 9223     __ csetw($res$$Register, Assembler::EQ);
 9224   %}
 9225   ins_pipe(pipe_slow);
 9226 %}
 9227 
 9228 // END This section of the file is automatically generated. Do not edit --------------
 9229 // ---------------------------------------------------------------------
 9230 
 9231 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9232   match(Set prev (GetAndSetI mem newv));
 9233   ins_cost(2 * VOLATILE_REF_COST);
 9234   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9235   ins_encode %{
 9236     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9237   %}
 9238   ins_pipe(pipe_serial);
 9239 %}
 9240 
 9241 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9242   match(Set prev (GetAndSetL mem newv));
 9243   ins_cost(2 * VOLATILE_REF_COST);
 9244   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9245   ins_encode %{
 9246     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9247   %}
 9248   ins_pipe(pipe_serial);
 9249 %}
 9250 
 9251 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9252   match(Set prev (GetAndSetN mem newv));
 9253   ins_cost(2 * VOLATILE_REF_COST);
 9254   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9255   ins_encode %{
 9256     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9257   %}
 9258   ins_pipe(pipe_serial);
 9259 %}
 9260 
 9261 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9262   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9263   match(Set prev (GetAndSetP mem newv));
 9264   ins_cost(2 * VOLATILE_REF_COST);
 9265   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9266   ins_encode %{
 9267     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9268   %}
 9269   ins_pipe(pipe_serial);
 9270 %}
 9271 
 9272 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9273   predicate(needs_acquiring_load_exclusive(n));
 9274   match(Set prev (GetAndSetI mem newv));
 9275   ins_cost(VOLATILE_REF_COST);
 9276   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9277   ins_encode %{
 9278     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9279   %}
 9280   ins_pipe(pipe_serial);
 9281 %}
 9282 
 9283 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9284   predicate(needs_acquiring_load_exclusive(n));
 9285   match(Set prev (GetAndSetL mem newv));
 9286   ins_cost(VOLATILE_REF_COST);
 9287   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9288   ins_encode %{
 9289     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9290   %}
 9291   ins_pipe(pipe_serial);
 9292 %}
 9293 
 9294 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9295   predicate(needs_acquiring_load_exclusive(n));
 9296   match(Set prev (GetAndSetN mem newv));
 9297   ins_cost(VOLATILE_REF_COST);
 9298   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9299   ins_encode %{
 9300     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9301   %}
 9302   ins_pipe(pipe_serial);
 9303 %}
 9304 
 9305 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9306   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9307   match(Set prev (GetAndSetP mem newv));
 9308   ins_cost(VOLATILE_REF_COST);
 9309   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9310   ins_encode %{
 9311     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9312   %}
 9313   ins_pipe(pipe_serial);
 9314 %}
 9315 
 9316 
 9317 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9318   match(Set newval (GetAndAddL mem incr));
 9319   ins_cost(2 * VOLATILE_REF_COST + 1);
 9320   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9321   ins_encode %{
 9322     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9323   %}
 9324   ins_pipe(pipe_serial);
 9325 %}
 9326 
 9327 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9328   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9329   match(Set dummy (GetAndAddL mem incr));
 9330   ins_cost(2 * VOLATILE_REF_COST);
 9331   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9332   ins_encode %{
 9333     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9334   %}
 9335   ins_pipe(pipe_serial);
 9336 %}
 9337 
 9338 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9339   match(Set newval (GetAndAddL mem incr));
 9340   ins_cost(2 * VOLATILE_REF_COST + 1);
 9341   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9342   ins_encode %{
 9343     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9344   %}
 9345   ins_pipe(pipe_serial);
 9346 %}
 9347 
 9348 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9349   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9350   match(Set dummy (GetAndAddL mem incr));
 9351   ins_cost(2 * VOLATILE_REF_COST);
 9352   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9353   ins_encode %{
 9354     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9355   %}
 9356   ins_pipe(pipe_serial);
 9357 %}
 9358 
 9359 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9360   match(Set newval (GetAndAddI mem incr));
 9361   ins_cost(2 * VOLATILE_REF_COST + 1);
 9362   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9363   ins_encode %{
 9364     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9365   %}
 9366   ins_pipe(pipe_serial);
 9367 %}
 9368 
 9369 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9370   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9371   match(Set dummy (GetAndAddI mem incr));
 9372   ins_cost(2 * VOLATILE_REF_COST);
 9373   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9374   ins_encode %{
 9375     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9376   %}
 9377   ins_pipe(pipe_serial);
 9378 %}
 9379 
 9380 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9381   match(Set newval (GetAndAddI mem incr));
 9382   ins_cost(2 * VOLATILE_REF_COST + 1);
 9383   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9384   ins_encode %{
 9385     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9386   %}
 9387   ins_pipe(pipe_serial);
 9388 %}
 9389 
 9390 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9391   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9392   match(Set dummy (GetAndAddI mem incr));
 9393   ins_cost(2 * VOLATILE_REF_COST);
 9394   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9395   ins_encode %{
 9396     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9397   %}
 9398   ins_pipe(pipe_serial);
 9399 %}
 9400 
 9401 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9402   predicate(needs_acquiring_load_exclusive(n));
 9403   match(Set newval (GetAndAddL mem incr));
 9404   ins_cost(VOLATILE_REF_COST + 1);
 9405   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9406   ins_encode %{
 9407     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9408   %}
 9409   ins_pipe(pipe_serial);
 9410 %}
 9411 
 9412 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9413   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9414   match(Set dummy (GetAndAddL mem incr));
 9415   ins_cost(VOLATILE_REF_COST);
 9416   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9417   ins_encode %{
 9418     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9419   %}
 9420   ins_pipe(pipe_serial);
 9421 %}
 9422 
 9423 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9424   predicate(needs_acquiring_load_exclusive(n));
 9425   match(Set newval (GetAndAddL mem incr));
 9426   ins_cost(VOLATILE_REF_COST + 1);
 9427   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9428   ins_encode %{
 9429     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9430   %}
 9431   ins_pipe(pipe_serial);
 9432 %}
 9433 
 9434 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9435   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9436   match(Set dummy (GetAndAddL mem incr));
 9437   ins_cost(VOLATILE_REF_COST);
 9438   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9439   ins_encode %{
 9440     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9441   %}
 9442   ins_pipe(pipe_serial);
 9443 %}
 9444 
 9445 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9446   predicate(needs_acquiring_load_exclusive(n));
 9447   match(Set newval (GetAndAddI mem incr));
 9448   ins_cost(VOLATILE_REF_COST + 1);
 9449   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9450   ins_encode %{
 9451     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9452   %}
 9453   ins_pipe(pipe_serial);
 9454 %}
 9455 
 9456 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9457   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9458   match(Set dummy (GetAndAddI mem incr));
 9459   ins_cost(VOLATILE_REF_COST);
 9460   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9461   ins_encode %{
 9462     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9463   %}
 9464   ins_pipe(pipe_serial);
 9465 %}
 9466 
 9467 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9468   predicate(needs_acquiring_load_exclusive(n));
 9469   match(Set newval (GetAndAddI mem incr));
 9470   ins_cost(VOLATILE_REF_COST + 1);
 9471   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9472   ins_encode %{
 9473     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9474   %}
 9475   ins_pipe(pipe_serial);
 9476 %}
 9477 
 9478 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9479   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9480   match(Set dummy (GetAndAddI mem incr));
 9481   ins_cost(VOLATILE_REF_COST);
 9482   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9483   ins_encode %{
 9484     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9485   %}
 9486   ins_pipe(pipe_serial);
 9487 %}
 9488 
 9489 // Manifest a CmpL result in an integer register.
 9490 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9491 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9492 %{
 9493   match(Set dst (CmpL3 src1 src2));
 9494   effect(KILL flags);
 9495 
 9496   ins_cost(INSN_COST * 6);
 9497   format %{
 9498       &quot;cmp $src1, $src2&quot;
 9499       &quot;csetw $dst, ne&quot;
 9500       &quot;cnegw $dst, lt&quot;
 9501   %}
 9502   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9503   ins_encode %{
 9504     __ cmp($src1$$Register, $src2$$Register);
 9505     __ csetw($dst$$Register, Assembler::NE);
 9506     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9507   %}
 9508 
 9509   ins_pipe(pipe_class_default);
 9510 %}
 9511 
 9512 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9513 %{
 9514   match(Set dst (CmpL3 src1 src2));
 9515   effect(KILL flags);
 9516 
 9517   ins_cost(INSN_COST * 6);
 9518   format %{
 9519       &quot;cmp $src1, $src2&quot;
 9520       &quot;csetw $dst, ne&quot;
 9521       &quot;cnegw $dst, lt&quot;
 9522   %}
 9523   ins_encode %{
 9524     int32_t con = (int32_t)$src2$$constant;
 9525      if (con &lt; 0) {
 9526       __ adds(zr, $src1$$Register, -con);
 9527     } else {
 9528       __ subs(zr, $src1$$Register, con);
 9529     }
 9530     __ csetw($dst$$Register, Assembler::NE);
 9531     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9532   %}
 9533 
 9534   ins_pipe(pipe_class_default);
 9535 %}
 9536 
 9537 // ============================================================================
 9538 // Conditional Move Instructions
 9539 
 9540 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9541 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9542 // define an op class which merged both inputs and use it to type the
 9543 // argument to a single rule. unfortunatelyt his fails because the
 9544 // opclass does not live up to the COND_INTER interface of its
 9545 // component operands. When the generic code tries to negate the
 9546 // operand it ends up running the generci Machoper::negate method
 9547 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9548 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9549 
 9550 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9551   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9552 
 9553   ins_cost(INSN_COST * 2);
 9554   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9555 
 9556   ins_encode %{
 9557     __ cselw(as_Register($dst$$reg),
 9558              as_Register($src2$$reg),
 9559              as_Register($src1$$reg),
 9560              (Assembler::Condition)$cmp$$cmpcode);
 9561   %}
 9562 
 9563   ins_pipe(icond_reg_reg);
 9564 %}
 9565 
 9566 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9567   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9568 
 9569   ins_cost(INSN_COST * 2);
 9570   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9571 
 9572   ins_encode %{
 9573     __ cselw(as_Register($dst$$reg),
 9574              as_Register($src2$$reg),
 9575              as_Register($src1$$reg),
 9576              (Assembler::Condition)$cmp$$cmpcode);
 9577   %}
 9578 
 9579   ins_pipe(icond_reg_reg);
 9580 %}
 9581 
 9582 // special cases where one arg is zero
 9583 
 9584 // n.b. this is selected in preference to the rule above because it
 9585 // avoids loading constant 0 into a source register
 9586 
 9587 // TODO
 9588 // we ought only to be able to cull one of these variants as the ideal
 9589 // transforms ought always to order the zero consistently (to left/right?)
 9590 
 9591 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9592   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9593 
 9594   ins_cost(INSN_COST * 2);
 9595   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9596 
 9597   ins_encode %{
 9598     __ cselw(as_Register($dst$$reg),
 9599              as_Register($src$$reg),
 9600              zr,
 9601              (Assembler::Condition)$cmp$$cmpcode);
 9602   %}
 9603 
 9604   ins_pipe(icond_reg);
 9605 %}
 9606 
 9607 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9608   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9609 
 9610   ins_cost(INSN_COST * 2);
 9611   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9612 
 9613   ins_encode %{
 9614     __ cselw(as_Register($dst$$reg),
 9615              as_Register($src$$reg),
 9616              zr,
 9617              (Assembler::Condition)$cmp$$cmpcode);
 9618   %}
 9619 
 9620   ins_pipe(icond_reg);
 9621 %}
 9622 
 9623 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9624   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9625 
 9626   ins_cost(INSN_COST * 2);
 9627   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9628 
 9629   ins_encode %{
 9630     __ cselw(as_Register($dst$$reg),
 9631              zr,
 9632              as_Register($src$$reg),
 9633              (Assembler::Condition)$cmp$$cmpcode);
 9634   %}
 9635 
 9636   ins_pipe(icond_reg);
 9637 %}
 9638 
 9639 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9640   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9641 
 9642   ins_cost(INSN_COST * 2);
 9643   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9644 
 9645   ins_encode %{
 9646     __ cselw(as_Register($dst$$reg),
 9647              zr,
 9648              as_Register($src$$reg),
 9649              (Assembler::Condition)$cmp$$cmpcode);
 9650   %}
 9651 
 9652   ins_pipe(icond_reg);
 9653 %}
 9654 
 9655 // special case for creating a boolean 0 or 1
 9656 
 9657 // n.b. this is selected in preference to the rule above because it
 9658 // avoids loading constants 0 and 1 into a source register
 9659 
 9660 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9661   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9662 
 9663   ins_cost(INSN_COST * 2);
 9664   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9665 
 9666   ins_encode %{
 9667     // equivalently
 9668     // cset(as_Register($dst$$reg),
 9669     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9670     __ csincw(as_Register($dst$$reg),
 9671              zr,
 9672              zr,
 9673              (Assembler::Condition)$cmp$$cmpcode);
 9674   %}
 9675 
 9676   ins_pipe(icond_none);
 9677 %}
 9678 
 9679 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9680   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9681 
 9682   ins_cost(INSN_COST * 2);
 9683   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9684 
 9685   ins_encode %{
 9686     // equivalently
 9687     // cset(as_Register($dst$$reg),
 9688     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9689     __ csincw(as_Register($dst$$reg),
 9690              zr,
 9691              zr,
 9692              (Assembler::Condition)$cmp$$cmpcode);
 9693   %}
 9694 
 9695   ins_pipe(icond_none);
 9696 %}
 9697 
 9698 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9699   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9700 
 9701   ins_cost(INSN_COST * 2);
 9702   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9703 
 9704   ins_encode %{
 9705     __ csel(as_Register($dst$$reg),
 9706             as_Register($src2$$reg),
 9707             as_Register($src1$$reg),
 9708             (Assembler::Condition)$cmp$$cmpcode);
 9709   %}
 9710 
 9711   ins_pipe(icond_reg_reg);
 9712 %}
 9713 
 9714 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9715   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9716 
 9717   ins_cost(INSN_COST * 2);
 9718   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9719 
 9720   ins_encode %{
 9721     __ csel(as_Register($dst$$reg),
 9722             as_Register($src2$$reg),
 9723             as_Register($src1$$reg),
 9724             (Assembler::Condition)$cmp$$cmpcode);
 9725   %}
 9726 
 9727   ins_pipe(icond_reg_reg);
 9728 %}
 9729 
 9730 // special cases where one arg is zero
 9731 
 9732 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9733   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9734 
 9735   ins_cost(INSN_COST * 2);
 9736   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9737 
 9738   ins_encode %{
 9739     __ csel(as_Register($dst$$reg),
 9740             zr,
 9741             as_Register($src$$reg),
 9742             (Assembler::Condition)$cmp$$cmpcode);
 9743   %}
 9744 
 9745   ins_pipe(icond_reg);
 9746 %}
 9747 
 9748 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9749   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9750 
 9751   ins_cost(INSN_COST * 2);
 9752   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9753 
 9754   ins_encode %{
 9755     __ csel(as_Register($dst$$reg),
 9756             zr,
 9757             as_Register($src$$reg),
 9758             (Assembler::Condition)$cmp$$cmpcode);
 9759   %}
 9760 
 9761   ins_pipe(icond_reg);
 9762 %}
 9763 
 9764 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9765   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9766 
 9767   ins_cost(INSN_COST * 2);
 9768   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9769 
 9770   ins_encode %{
 9771     __ csel(as_Register($dst$$reg),
 9772             as_Register($src$$reg),
 9773             zr,
 9774             (Assembler::Condition)$cmp$$cmpcode);
 9775   %}
 9776 
 9777   ins_pipe(icond_reg);
 9778 %}
 9779 
 9780 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9781   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9782 
 9783   ins_cost(INSN_COST * 2);
 9784   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9785 
 9786   ins_encode %{
 9787     __ csel(as_Register($dst$$reg),
 9788             as_Register($src$$reg),
 9789             zr,
 9790             (Assembler::Condition)$cmp$$cmpcode);
 9791   %}
 9792 
 9793   ins_pipe(icond_reg);
 9794 %}
 9795 
 9796 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9797   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9798 
 9799   ins_cost(INSN_COST * 2);
 9800   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9801 
 9802   ins_encode %{
 9803     __ csel(as_Register($dst$$reg),
 9804             as_Register($src2$$reg),
 9805             as_Register($src1$$reg),
 9806             (Assembler::Condition)$cmp$$cmpcode);
 9807   %}
 9808 
 9809   ins_pipe(icond_reg_reg);
 9810 %}
 9811 
 9812 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9813   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9814 
 9815   ins_cost(INSN_COST * 2);
 9816   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9817 
 9818   ins_encode %{
 9819     __ csel(as_Register($dst$$reg),
 9820             as_Register($src2$$reg),
 9821             as_Register($src1$$reg),
 9822             (Assembler::Condition)$cmp$$cmpcode);
 9823   %}
 9824 
 9825   ins_pipe(icond_reg_reg);
 9826 %}
 9827 
 9828 // special cases where one arg is zero
 9829 
 9830 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9831   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9832 
 9833   ins_cost(INSN_COST * 2);
 9834   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9835 
 9836   ins_encode %{
 9837     __ csel(as_Register($dst$$reg),
 9838             zr,
 9839             as_Register($src$$reg),
 9840             (Assembler::Condition)$cmp$$cmpcode);
 9841   %}
 9842 
 9843   ins_pipe(icond_reg);
 9844 %}
 9845 
 9846 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9847   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9848 
 9849   ins_cost(INSN_COST * 2);
 9850   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9851 
 9852   ins_encode %{
 9853     __ csel(as_Register($dst$$reg),
 9854             zr,
 9855             as_Register($src$$reg),
 9856             (Assembler::Condition)$cmp$$cmpcode);
 9857   %}
 9858 
 9859   ins_pipe(icond_reg);
 9860 %}
 9861 
 9862 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9863   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9864 
 9865   ins_cost(INSN_COST * 2);
 9866   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9867 
 9868   ins_encode %{
 9869     __ csel(as_Register($dst$$reg),
 9870             as_Register($src$$reg),
 9871             zr,
 9872             (Assembler::Condition)$cmp$$cmpcode);
 9873   %}
 9874 
 9875   ins_pipe(icond_reg);
 9876 %}
 9877 
 9878 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9879   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9880 
 9881   ins_cost(INSN_COST * 2);
 9882   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9883 
 9884   ins_encode %{
 9885     __ csel(as_Register($dst$$reg),
 9886             as_Register($src$$reg),
 9887             zr,
 9888             (Assembler::Condition)$cmp$$cmpcode);
 9889   %}
 9890 
 9891   ins_pipe(icond_reg);
 9892 %}
 9893 
 9894 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9895   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9896 
 9897   ins_cost(INSN_COST * 2);
 9898   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9899 
 9900   ins_encode %{
 9901     __ cselw(as_Register($dst$$reg),
 9902              as_Register($src2$$reg),
 9903              as_Register($src1$$reg),
 9904              (Assembler::Condition)$cmp$$cmpcode);
 9905   %}
 9906 
 9907   ins_pipe(icond_reg_reg);
 9908 %}
 9909 
 9910 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9911   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9912 
 9913   ins_cost(INSN_COST * 2);
 9914   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9915 
 9916   ins_encode %{
 9917     __ cselw(as_Register($dst$$reg),
 9918              as_Register($src2$$reg),
 9919              as_Register($src1$$reg),
 9920              (Assembler::Condition)$cmp$$cmpcode);
 9921   %}
 9922 
 9923   ins_pipe(icond_reg_reg);
 9924 %}
 9925 
 9926 // special cases where one arg is zero
 9927 
 9928 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9929   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9930 
 9931   ins_cost(INSN_COST * 2);
 9932   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9933 
 9934   ins_encode %{
 9935     __ cselw(as_Register($dst$$reg),
 9936              zr,
 9937              as_Register($src$$reg),
 9938              (Assembler::Condition)$cmp$$cmpcode);
 9939   %}
 9940 
 9941   ins_pipe(icond_reg);
 9942 %}
 9943 
 9944 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9945   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9946 
 9947   ins_cost(INSN_COST * 2);
 9948   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
 9949 
 9950   ins_encode %{
 9951     __ cselw(as_Register($dst$$reg),
 9952              zr,
 9953              as_Register($src$$reg),
 9954              (Assembler::Condition)$cmp$$cmpcode);
 9955   %}
 9956 
 9957   ins_pipe(icond_reg);
 9958 %}
 9959 
 9960 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9961   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9962 
 9963   ins_cost(INSN_COST * 2);
 9964   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
 9965 
 9966   ins_encode %{
 9967     __ cselw(as_Register($dst$$reg),
 9968              as_Register($src$$reg),
 9969              zr,
 9970              (Assembler::Condition)$cmp$$cmpcode);
 9971   %}
 9972 
 9973   ins_pipe(icond_reg);
 9974 %}
 9975 
 9976 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9977   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9978 
 9979   ins_cost(INSN_COST * 2);
 9980   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
 9981 
 9982   ins_encode %{
 9983     __ cselw(as_Register($dst$$reg),
 9984              as_Register($src$$reg),
 9985              zr,
 9986              (Assembler::Condition)$cmp$$cmpcode);
 9987   %}
 9988 
 9989   ins_pipe(icond_reg);
 9990 %}
 9991 
 9992 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
 9993 %{
 9994   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9995 
 9996   ins_cost(INSN_COST * 3);
 9997 
 9998   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
 9999   ins_encode %{
10000     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10001     __ fcsels(as_FloatRegister($dst$$reg),
10002               as_FloatRegister($src2$$reg),
10003               as_FloatRegister($src1$$reg),
10004               cond);
10005   %}
10006 
10007   ins_pipe(fp_cond_reg_reg_s);
10008 %}
10009 
10010 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
10011 %{
10012   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10013 
10014   ins_cost(INSN_COST * 3);
10015 
10016   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10017   ins_encode %{
10018     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10019     __ fcsels(as_FloatRegister($dst$$reg),
10020               as_FloatRegister($src2$$reg),
10021               as_FloatRegister($src1$$reg),
10022               cond);
10023   %}
10024 
10025   ins_pipe(fp_cond_reg_reg_s);
10026 %}
10027 
10028 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
10029 %{
10030   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10031 
10032   ins_cost(INSN_COST * 3);
10033 
10034   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10035   ins_encode %{
10036     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10037     __ fcseld(as_FloatRegister($dst$$reg),
10038               as_FloatRegister($src2$$reg),
10039               as_FloatRegister($src1$$reg),
10040               cond);
10041   %}
10042 
10043   ins_pipe(fp_cond_reg_reg_d);
10044 %}
10045 
10046 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10047 %{
10048   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10049 
10050   ins_cost(INSN_COST * 3);
10051 
10052   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10053   ins_encode %{
10054     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10055     __ fcseld(as_FloatRegister($dst$$reg),
10056               as_FloatRegister($src2$$reg),
10057               as_FloatRegister($src1$$reg),
10058               cond);
10059   %}
10060 
10061   ins_pipe(fp_cond_reg_reg_d);
10062 %}
10063 
10064 // ============================================================================
10065 // Arithmetic Instructions
10066 //
10067 
10068 // Integer Addition
10069 
10070 // TODO
10071 // these currently employ operations which do not set CR and hence are
10072 // not flagged as killing CR but we would like to isolate the cases
10073 // where we want to set flags from those where we don&#39;t. need to work
10074 // out how to do that.
10075 
10076 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10077   match(Set dst (AddI src1 src2));
10078 
10079   ins_cost(INSN_COST);
10080   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10081 
10082   ins_encode %{
10083     __ addw(as_Register($dst$$reg),
10084             as_Register($src1$$reg),
10085             as_Register($src2$$reg));
10086   %}
10087 
10088   ins_pipe(ialu_reg_reg);
10089 %}
10090 
10091 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10092   match(Set dst (AddI src1 src2));
10093 
10094   ins_cost(INSN_COST);
10095   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10096 
10097   // use opcode to indicate that this is an add not a sub
10098   opcode(0x0);
10099 
10100   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10101 
10102   ins_pipe(ialu_reg_imm);
10103 %}
10104 
10105 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10106   match(Set dst (AddI (ConvL2I src1) src2));
10107 
10108   ins_cost(INSN_COST);
10109   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10110 
10111   // use opcode to indicate that this is an add not a sub
10112   opcode(0x0);
10113 
10114   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10115 
10116   ins_pipe(ialu_reg_imm);
10117 %}
10118 
10119 // Pointer Addition
10120 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10121   match(Set dst (AddP src1 src2));
10122 
10123   ins_cost(INSN_COST);
10124   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10125 
10126   ins_encode %{
10127     __ add(as_Register($dst$$reg),
10128            as_Register($src1$$reg),
10129            as_Register($src2$$reg));
10130   %}
10131 
10132   ins_pipe(ialu_reg_reg);
10133 %}
10134 
10135 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10136   match(Set dst (AddP src1 (ConvI2L src2)));
10137 
10138   ins_cost(1.9 * INSN_COST);
10139   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10140 
10141   ins_encode %{
10142     __ add(as_Register($dst$$reg),
10143            as_Register($src1$$reg),
10144            as_Register($src2$$reg), ext::sxtw);
10145   %}
10146 
10147   ins_pipe(ialu_reg_reg);
10148 %}
10149 
10150 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10151   match(Set dst (AddP src1 (LShiftL src2 scale)));
10152 
10153   ins_cost(1.9 * INSN_COST);
10154   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10155 
10156   ins_encode %{
10157     __ lea(as_Register($dst$$reg),
10158            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10159                    Address::lsl($scale$$constant)));
10160   %}
10161 
10162   ins_pipe(ialu_reg_reg_shift);
10163 %}
10164 
10165 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10166   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10167 
10168   ins_cost(1.9 * INSN_COST);
10169   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10170 
10171   ins_encode %{
10172     __ lea(as_Register($dst$$reg),
10173            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10174                    Address::sxtw($scale$$constant)));
10175   %}
10176 
10177   ins_pipe(ialu_reg_reg_shift);
10178 %}
10179 
10180 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10181   match(Set dst (LShiftL (ConvI2L src) scale));
10182 
10183   ins_cost(INSN_COST);
10184   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10185 
10186   ins_encode %{
10187     __ sbfiz(as_Register($dst$$reg),
10188           as_Register($src$$reg),
10189           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10190   %}
10191 
10192   ins_pipe(ialu_reg_shift);
10193 %}
10194 
10195 // Pointer Immediate Addition
10196 // n.b. this needs to be more expensive than using an indirect memory
10197 // operand
10198 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10199   match(Set dst (AddP src1 src2));
10200 
10201   ins_cost(INSN_COST);
10202   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10203 
10204   // use opcode to indicate that this is an add not a sub
10205   opcode(0x0);
10206 
10207   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10208 
10209   ins_pipe(ialu_reg_imm);
10210 %}
10211 
10212 // Long Addition
10213 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10214 
10215   match(Set dst (AddL src1 src2));
10216 
10217   ins_cost(INSN_COST);
10218   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10219 
10220   ins_encode %{
10221     __ add(as_Register($dst$$reg),
10222            as_Register($src1$$reg),
10223            as_Register($src2$$reg));
10224   %}
10225 
10226   ins_pipe(ialu_reg_reg);
10227 %}
10228 
10229 // No constant pool entries requiredLong Immediate Addition.
10230 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10231   match(Set dst (AddL src1 src2));
10232 
10233   ins_cost(INSN_COST);
10234   format %{ &quot;add $dst, $src1, $src2&quot; %}
10235 
10236   // use opcode to indicate that this is an add not a sub
10237   opcode(0x0);
10238 
10239   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10240 
10241   ins_pipe(ialu_reg_imm);
10242 %}
10243 
10244 // Integer Subtraction
10245 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10246   match(Set dst (SubI src1 src2));
10247 
10248   ins_cost(INSN_COST);
10249   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10250 
10251   ins_encode %{
10252     __ subw(as_Register($dst$$reg),
10253             as_Register($src1$$reg),
10254             as_Register($src2$$reg));
10255   %}
10256 
10257   ins_pipe(ialu_reg_reg);
10258 %}
10259 
10260 // Immediate Subtraction
10261 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10262   match(Set dst (SubI src1 src2));
10263 
10264   ins_cost(INSN_COST);
10265   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10266 
10267   // use opcode to indicate that this is a sub not an add
10268   opcode(0x1);
10269 
10270   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10271 
10272   ins_pipe(ialu_reg_imm);
10273 %}
10274 
10275 // Long Subtraction
10276 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10277 
10278   match(Set dst (SubL src1 src2));
10279 
10280   ins_cost(INSN_COST);
10281   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10282 
10283   ins_encode %{
10284     __ sub(as_Register($dst$$reg),
10285            as_Register($src1$$reg),
10286            as_Register($src2$$reg));
10287   %}
10288 
10289   ins_pipe(ialu_reg_reg);
10290 %}
10291 
10292 // No constant pool entries requiredLong Immediate Subtraction.
10293 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10294   match(Set dst (SubL src1 src2));
10295 
10296   ins_cost(INSN_COST);
10297   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10298 
10299   // use opcode to indicate that this is a sub not an add
10300   opcode(0x1);
10301 
10302   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10303 
10304   ins_pipe(ialu_reg_imm);
10305 %}
10306 
10307 // Integer Negation (special case for sub)
10308 
10309 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10310   match(Set dst (SubI zero src));
10311 
10312   ins_cost(INSN_COST);
10313   format %{ &quot;negw $dst, $src\t# int&quot; %}
10314 
10315   ins_encode %{
10316     __ negw(as_Register($dst$$reg),
10317             as_Register($src$$reg));
10318   %}
10319 
10320   ins_pipe(ialu_reg);
10321 %}
10322 
10323 // Long Negation
10324 
10325 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10326   match(Set dst (SubL zero src));
10327 
10328   ins_cost(INSN_COST);
10329   format %{ &quot;neg $dst, $src\t# long&quot; %}
10330 
10331   ins_encode %{
10332     __ neg(as_Register($dst$$reg),
10333            as_Register($src$$reg));
10334   %}
10335 
10336   ins_pipe(ialu_reg);
10337 %}
10338 
10339 // Integer Multiply
10340 
10341 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10342   match(Set dst (MulI src1 src2));
10343 
10344   ins_cost(INSN_COST * 3);
10345   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10346 
10347   ins_encode %{
10348     __ mulw(as_Register($dst$$reg),
10349             as_Register($src1$$reg),
10350             as_Register($src2$$reg));
10351   %}
10352 
10353   ins_pipe(imul_reg_reg);
10354 %}
10355 
10356 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10357   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10358 
10359   ins_cost(INSN_COST * 3);
10360   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10361 
10362   ins_encode %{
10363     __ smull(as_Register($dst$$reg),
10364              as_Register($src1$$reg),
10365              as_Register($src2$$reg));
10366   %}
10367 
10368   ins_pipe(imul_reg_reg);
10369 %}
10370 
10371 // Long Multiply
10372 
10373 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10374   match(Set dst (MulL src1 src2));
10375 
10376   ins_cost(INSN_COST * 5);
10377   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10378 
10379   ins_encode %{
10380     __ mul(as_Register($dst$$reg),
10381            as_Register($src1$$reg),
10382            as_Register($src2$$reg));
10383   %}
10384 
10385   ins_pipe(lmul_reg_reg);
10386 %}
10387 
10388 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10389 %{
10390   match(Set dst (MulHiL src1 src2));
10391 
10392   ins_cost(INSN_COST * 7);
10393   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10394 
10395   ins_encode %{
10396     __ smulh(as_Register($dst$$reg),
10397              as_Register($src1$$reg),
10398              as_Register($src2$$reg));
10399   %}
10400 
10401   ins_pipe(lmul_reg_reg);
10402 %}
10403 
10404 // Combined Integer Multiply &amp; Add/Sub
10405 
10406 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10407   match(Set dst (AddI src3 (MulI src1 src2)));
10408 
10409   ins_cost(INSN_COST * 3);
10410   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10411 
10412   ins_encode %{
10413     __ maddw(as_Register($dst$$reg),
10414              as_Register($src1$$reg),
10415              as_Register($src2$$reg),
10416              as_Register($src3$$reg));
10417   %}
10418 
10419   ins_pipe(imac_reg_reg);
10420 %}
10421 
10422 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10423   match(Set dst (SubI src3 (MulI src1 src2)));
10424 
10425   ins_cost(INSN_COST * 3);
10426   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10427 
10428   ins_encode %{
10429     __ msubw(as_Register($dst$$reg),
10430              as_Register($src1$$reg),
10431              as_Register($src2$$reg),
10432              as_Register($src3$$reg));
10433   %}
10434 
10435   ins_pipe(imac_reg_reg);
10436 %}
10437 
10438 // Combined Integer Multiply &amp; Neg
10439 
10440 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10441   match(Set dst (MulI (SubI zero src1) src2));
10442   match(Set dst (MulI src1 (SubI zero src2)));
10443 
10444   ins_cost(INSN_COST * 3);
10445   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10446 
10447   ins_encode %{
10448     __ mnegw(as_Register($dst$$reg),
10449              as_Register($src1$$reg),
10450              as_Register($src2$$reg));
10451   %}
10452 
10453   ins_pipe(imac_reg_reg);
10454 %}
10455 
10456 // Combined Long Multiply &amp; Add/Sub
10457 
10458 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10459   match(Set dst (AddL src3 (MulL src1 src2)));
10460 
10461   ins_cost(INSN_COST * 5);
10462   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10463 
10464   ins_encode %{
10465     __ madd(as_Register($dst$$reg),
10466             as_Register($src1$$reg),
10467             as_Register($src2$$reg),
10468             as_Register($src3$$reg));
10469   %}
10470 
10471   ins_pipe(lmac_reg_reg);
10472 %}
10473 
10474 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10475   match(Set dst (SubL src3 (MulL src1 src2)));
10476 
10477   ins_cost(INSN_COST * 5);
10478   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10479 
10480   ins_encode %{
10481     __ msub(as_Register($dst$$reg),
10482             as_Register($src1$$reg),
10483             as_Register($src2$$reg),
10484             as_Register($src3$$reg));
10485   %}
10486 
10487   ins_pipe(lmac_reg_reg);
10488 %}
10489 
10490 // Combined Long Multiply &amp; Neg
10491 
10492 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10493   match(Set dst (MulL (SubL zero src1) src2));
10494   match(Set dst (MulL src1 (SubL zero src2)));
10495 
10496   ins_cost(INSN_COST * 5);
10497   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10498 
10499   ins_encode %{
10500     __ mneg(as_Register($dst$$reg),
10501             as_Register($src1$$reg),
10502             as_Register($src2$$reg));
10503   %}
10504 
10505   ins_pipe(lmac_reg_reg);
10506 %}
10507 
10508 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10509 
10510 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10511   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10512 
10513   ins_cost(INSN_COST * 3);
10514   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10515 
10516   ins_encode %{
10517     __ smaddl(as_Register($dst$$reg),
10518               as_Register($src1$$reg),
10519               as_Register($src2$$reg),
10520               as_Register($src3$$reg));
10521   %}
10522 
10523   ins_pipe(imac_reg_reg);
10524 %}
10525 
10526 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10527   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10528 
10529   ins_cost(INSN_COST * 3);
10530   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10531 
10532   ins_encode %{
10533     __ smsubl(as_Register($dst$$reg),
10534               as_Register($src1$$reg),
10535               as_Register($src2$$reg),
10536               as_Register($src3$$reg));
10537   %}
10538 
10539   ins_pipe(imac_reg_reg);
10540 %}
10541 
10542 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10543   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10544   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10545 
10546   ins_cost(INSN_COST * 3);
10547   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10548 
10549   ins_encode %{
10550     __ smnegl(as_Register($dst$$reg),
10551               as_Register($src1$$reg),
10552               as_Register($src2$$reg));
10553   %}
10554 
10555   ins_pipe(imac_reg_reg);
10556 %}
10557 
10558 // Integer Divide
10559 
10560 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10561   match(Set dst (DivI src1 src2));
10562 
10563   ins_cost(INSN_COST * 19);
10564   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10565 
10566   ins_encode(aarch64_enc_divw(dst, src1, src2));
10567   ins_pipe(idiv_reg_reg);
10568 %}
10569 
10570 instruct signExtract(iRegINoSp dst, iRegIorL2I src1, immI_31 div1, immI_31 div2) %{
10571   match(Set dst (URShiftI (RShiftI src1 div1) div2));
10572   ins_cost(INSN_COST);
10573   format %{ &quot;lsrw $dst, $src1, $div1&quot; %}
10574   ins_encode %{
10575     __ lsrw(as_Register($dst$$reg), as_Register($src1$$reg), 31);
10576   %}
10577   ins_pipe(ialu_reg_shift);
10578 %}
10579 
10580 instruct div2Round(iRegINoSp dst, iRegIorL2I src, immI_31 div1, immI_31 div2) %{
10581   match(Set dst (AddI src (URShiftI (RShiftI src div1) div2)));
10582   ins_cost(INSN_COST);
10583   format %{ &quot;addw $dst, $src, LSR $div1&quot; %}
10584 
10585   ins_encode %{
10586     __ addw(as_Register($dst$$reg),
10587               as_Register($src$$reg),
10588               as_Register($src$$reg),
10589               Assembler::LSR, 31);
10590   %}
10591   ins_pipe(ialu_reg);
10592 %}
10593 
10594 // Long Divide
10595 
10596 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10597   match(Set dst (DivL src1 src2));
10598 
10599   ins_cost(INSN_COST * 35);
10600   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10601 
10602   ins_encode(aarch64_enc_div(dst, src1, src2));
10603   ins_pipe(ldiv_reg_reg);
10604 %}
10605 
10606 instruct signExtractL(iRegLNoSp dst, iRegL src1, immI_63 div1, immI_63 div2) %{
10607   match(Set dst (URShiftL (RShiftL src1 div1) div2));
10608   ins_cost(INSN_COST);
10609   format %{ &quot;lsr $dst, $src1, $div1&quot; %}
10610   ins_encode %{
10611     __ lsr(as_Register($dst$$reg), as_Register($src1$$reg), 63);
10612   %}
10613   ins_pipe(ialu_reg_shift);
10614 %}
10615 
10616 instruct div2RoundL(iRegLNoSp dst, iRegL src, immI_63 div1, immI_63 div2) %{
10617   match(Set dst (AddL src (URShiftL (RShiftL src div1) div2)));
10618   ins_cost(INSN_COST);
10619   format %{ &quot;add $dst, $src, $div1&quot; %}
10620 
10621   ins_encode %{
10622     __ add(as_Register($dst$$reg),
10623               as_Register($src$$reg),
10624               as_Register($src$$reg),
10625               Assembler::LSR, 63);
10626   %}
10627   ins_pipe(ialu_reg);
10628 %}
10629 
10630 // Integer Remainder
10631 
10632 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10633   match(Set dst (ModI src1 src2));
10634 
10635   ins_cost(INSN_COST * 22);
10636   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10637             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10638 
10639   ins_encode(aarch64_enc_modw(dst, src1, src2));
10640   ins_pipe(idiv_reg_reg);
10641 %}
10642 
10643 // Long Remainder
10644 
10645 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10646   match(Set dst (ModL src1 src2));
10647 
10648   ins_cost(INSN_COST * 38);
10649   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10650             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10651 
10652   ins_encode(aarch64_enc_mod(dst, src1, src2));
10653   ins_pipe(ldiv_reg_reg);
10654 %}
10655 
10656 // Integer Shifts
10657 
10658 // Shift Left Register
10659 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10660   match(Set dst (LShiftI src1 src2));
10661 
10662   ins_cost(INSN_COST * 2);
10663   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10664 
10665   ins_encode %{
10666     __ lslvw(as_Register($dst$$reg),
10667              as_Register($src1$$reg),
10668              as_Register($src2$$reg));
10669   %}
10670 
10671   ins_pipe(ialu_reg_reg_vshift);
10672 %}
10673 
10674 // Shift Left Immediate
10675 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10676   match(Set dst (LShiftI src1 src2));
10677 
10678   ins_cost(INSN_COST);
10679   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10680 
10681   ins_encode %{
10682     __ lslw(as_Register($dst$$reg),
10683             as_Register($src1$$reg),
10684             $src2$$constant &amp; 0x1f);
10685   %}
10686 
10687   ins_pipe(ialu_reg_shift);
10688 %}
10689 
10690 // Shift Right Logical Register
10691 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10692   match(Set dst (URShiftI src1 src2));
10693 
10694   ins_cost(INSN_COST * 2);
10695   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10696 
10697   ins_encode %{
10698     __ lsrvw(as_Register($dst$$reg),
10699              as_Register($src1$$reg),
10700              as_Register($src2$$reg));
10701   %}
10702 
10703   ins_pipe(ialu_reg_reg_vshift);
10704 %}
10705 
10706 // Shift Right Logical Immediate
10707 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10708   match(Set dst (URShiftI src1 src2));
10709 
10710   ins_cost(INSN_COST);
10711   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10712 
10713   ins_encode %{
10714     __ lsrw(as_Register($dst$$reg),
10715             as_Register($src1$$reg),
10716             $src2$$constant &amp; 0x1f);
10717   %}
10718 
10719   ins_pipe(ialu_reg_shift);
10720 %}
10721 
10722 // Shift Right Arithmetic Register
10723 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10724   match(Set dst (RShiftI src1 src2));
10725 
10726   ins_cost(INSN_COST * 2);
10727   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10728 
10729   ins_encode %{
10730     __ asrvw(as_Register($dst$$reg),
10731              as_Register($src1$$reg),
10732              as_Register($src2$$reg));
10733   %}
10734 
10735   ins_pipe(ialu_reg_reg_vshift);
10736 %}
10737 
10738 // Shift Right Arithmetic Immediate
10739 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10740   match(Set dst (RShiftI src1 src2));
10741 
10742   ins_cost(INSN_COST);
10743   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10744 
10745   ins_encode %{
10746     __ asrw(as_Register($dst$$reg),
10747             as_Register($src1$$reg),
10748             $src2$$constant &amp; 0x1f);
10749   %}
10750 
10751   ins_pipe(ialu_reg_shift);
10752 %}
10753 
10754 // Combined Int Mask and Right Shift (using UBFM)
10755 // TODO
10756 
10757 // Long Shifts
10758 
10759 // Shift Left Register
10760 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10761   match(Set dst (LShiftL src1 src2));
10762 
10763   ins_cost(INSN_COST * 2);
10764   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10765 
10766   ins_encode %{
10767     __ lslv(as_Register($dst$$reg),
10768             as_Register($src1$$reg),
10769             as_Register($src2$$reg));
10770   %}
10771 
10772   ins_pipe(ialu_reg_reg_vshift);
10773 %}
10774 
10775 // Shift Left Immediate
10776 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10777   match(Set dst (LShiftL src1 src2));
10778 
10779   ins_cost(INSN_COST);
10780   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10781 
10782   ins_encode %{
10783     __ lsl(as_Register($dst$$reg),
10784             as_Register($src1$$reg),
10785             $src2$$constant &amp; 0x3f);
10786   %}
10787 
10788   ins_pipe(ialu_reg_shift);
10789 %}
10790 
10791 // Shift Right Logical Register
10792 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10793   match(Set dst (URShiftL src1 src2));
10794 
10795   ins_cost(INSN_COST * 2);
10796   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10797 
10798   ins_encode %{
10799     __ lsrv(as_Register($dst$$reg),
10800             as_Register($src1$$reg),
10801             as_Register($src2$$reg));
10802   %}
10803 
10804   ins_pipe(ialu_reg_reg_vshift);
10805 %}
10806 
10807 // Shift Right Logical Immediate
10808 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10809   match(Set dst (URShiftL src1 src2));
10810 
10811   ins_cost(INSN_COST);
10812   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10813 
10814   ins_encode %{
10815     __ lsr(as_Register($dst$$reg),
10816            as_Register($src1$$reg),
10817            $src2$$constant &amp; 0x3f);
10818   %}
10819 
10820   ins_pipe(ialu_reg_shift);
10821 %}
10822 
10823 // A special-case pattern for card table stores.
10824 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10825   match(Set dst (URShiftL (CastP2X src1) src2));
10826 
10827   ins_cost(INSN_COST);
10828   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10829 
10830   ins_encode %{
10831     __ lsr(as_Register($dst$$reg),
10832            as_Register($src1$$reg),
10833            $src2$$constant &amp; 0x3f);
10834   %}
10835 
10836   ins_pipe(ialu_reg_shift);
10837 %}
10838 
10839 // Shift Right Arithmetic Register
10840 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10841   match(Set dst (RShiftL src1 src2));
10842 
10843   ins_cost(INSN_COST * 2);
10844   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10845 
10846   ins_encode %{
10847     __ asrv(as_Register($dst$$reg),
10848             as_Register($src1$$reg),
10849             as_Register($src2$$reg));
10850   %}
10851 
10852   ins_pipe(ialu_reg_reg_vshift);
10853 %}
10854 
10855 // Shift Right Arithmetic Immediate
10856 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10857   match(Set dst (RShiftL src1 src2));
10858 
10859   ins_cost(INSN_COST);
10860   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10861 
10862   ins_encode %{
10863     __ asr(as_Register($dst$$reg),
10864            as_Register($src1$$reg),
10865            $src2$$constant &amp; 0x3f);
10866   %}
10867 
10868   ins_pipe(ialu_reg_shift);
10869 %}
10870 
10871 // BEGIN This section of the file is automatically generated. Do not edit --------------
10872 
10873 instruct regL_not_reg(iRegLNoSp dst,
10874                          iRegL src1, immL_M1 m1,
10875                          rFlagsReg cr) %{
10876   match(Set dst (XorL src1 m1));
10877   ins_cost(INSN_COST);
10878   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10879 
10880   ins_encode %{
10881     __ eon(as_Register($dst$$reg),
10882               as_Register($src1$$reg),
10883               zr,
10884               Assembler::LSL, 0);
10885   %}
10886 
10887   ins_pipe(ialu_reg);
10888 %}
10889 instruct regI_not_reg(iRegINoSp dst,
10890                          iRegIorL2I src1, immI_M1 m1,
10891                          rFlagsReg cr) %{
10892   match(Set dst (XorI src1 m1));
10893   ins_cost(INSN_COST);
10894   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10895 
10896   ins_encode %{
10897     __ eonw(as_Register($dst$$reg),
10898               as_Register($src1$$reg),
10899               zr,
10900               Assembler::LSL, 0);
10901   %}
10902 
10903   ins_pipe(ialu_reg);
10904 %}
10905 
10906 instruct AndI_reg_not_reg(iRegINoSp dst,
10907                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10908                          rFlagsReg cr) %{
10909   match(Set dst (AndI src1 (XorI src2 m1)));
10910   ins_cost(INSN_COST);
10911   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10912 
10913   ins_encode %{
10914     __ bicw(as_Register($dst$$reg),
10915               as_Register($src1$$reg),
10916               as_Register($src2$$reg),
10917               Assembler::LSL, 0);
10918   %}
10919 
10920   ins_pipe(ialu_reg_reg);
10921 %}
10922 
10923 instruct AndL_reg_not_reg(iRegLNoSp dst,
10924                          iRegL src1, iRegL src2, immL_M1 m1,
10925                          rFlagsReg cr) %{
10926   match(Set dst (AndL src1 (XorL src2 m1)));
10927   ins_cost(INSN_COST);
10928   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10929 
10930   ins_encode %{
10931     __ bic(as_Register($dst$$reg),
10932               as_Register($src1$$reg),
10933               as_Register($src2$$reg),
10934               Assembler::LSL, 0);
10935   %}
10936 
10937   ins_pipe(ialu_reg_reg);
10938 %}
10939 
10940 instruct OrI_reg_not_reg(iRegINoSp dst,
10941                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10942                          rFlagsReg cr) %{
10943   match(Set dst (OrI src1 (XorI src2 m1)));
10944   ins_cost(INSN_COST);
10945   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
10946 
10947   ins_encode %{
10948     __ ornw(as_Register($dst$$reg),
10949               as_Register($src1$$reg),
10950               as_Register($src2$$reg),
10951               Assembler::LSL, 0);
10952   %}
10953 
10954   ins_pipe(ialu_reg_reg);
10955 %}
10956 
10957 instruct OrL_reg_not_reg(iRegLNoSp dst,
10958                          iRegL src1, iRegL src2, immL_M1 m1,
10959                          rFlagsReg cr) %{
10960   match(Set dst (OrL src1 (XorL src2 m1)));
10961   ins_cost(INSN_COST);
10962   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
10963 
10964   ins_encode %{
10965     __ orn(as_Register($dst$$reg),
10966               as_Register($src1$$reg),
10967               as_Register($src2$$reg),
10968               Assembler::LSL, 0);
10969   %}
10970 
10971   ins_pipe(ialu_reg_reg);
10972 %}
10973 
10974 instruct XorI_reg_not_reg(iRegINoSp dst,
10975                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10976                          rFlagsReg cr) %{
10977   match(Set dst (XorI m1 (XorI src2 src1)));
10978   ins_cost(INSN_COST);
10979   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
10980 
10981   ins_encode %{
10982     __ eonw(as_Register($dst$$reg),
10983               as_Register($src1$$reg),
10984               as_Register($src2$$reg),
10985               Assembler::LSL, 0);
10986   %}
10987 
10988   ins_pipe(ialu_reg_reg);
10989 %}
10990 
10991 instruct XorL_reg_not_reg(iRegLNoSp dst,
10992                          iRegL src1, iRegL src2, immL_M1 m1,
10993                          rFlagsReg cr) %{
10994   match(Set dst (XorL m1 (XorL src2 src1)));
10995   ins_cost(INSN_COST);
10996   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
10997 
10998   ins_encode %{
10999     __ eon(as_Register($dst$$reg),
11000               as_Register($src1$$reg),
11001               as_Register($src2$$reg),
11002               Assembler::LSL, 0);
11003   %}
11004 
11005   ins_pipe(ialu_reg_reg);
11006 %}
11007 
11008 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
11009                          iRegIorL2I src1, iRegIorL2I src2,
11010                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11011   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
11012   ins_cost(1.9 * INSN_COST);
11013   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
11014 
11015   ins_encode %{
11016     __ bicw(as_Register($dst$$reg),
11017               as_Register($src1$$reg),
11018               as_Register($src2$$reg),
11019               Assembler::LSR,
11020               $src3$$constant &amp; 0x1f);
11021   %}
11022 
11023   ins_pipe(ialu_reg_reg_shift);
11024 %}
11025 
11026 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
11027                          iRegL src1, iRegL src2,
11028                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11029   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
11030   ins_cost(1.9 * INSN_COST);
11031   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
11032 
11033   ins_encode %{
11034     __ bic(as_Register($dst$$reg),
11035               as_Register($src1$$reg),
11036               as_Register($src2$$reg),
11037               Assembler::LSR,
11038               $src3$$constant &amp; 0x3f);
11039   %}
11040 
11041   ins_pipe(ialu_reg_reg_shift);
11042 %}
11043 
11044 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11045                          iRegIorL2I src1, iRegIorL2I src2,
11046                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11047   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11048   ins_cost(1.9 * INSN_COST);
11049   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11050 
11051   ins_encode %{
11052     __ bicw(as_Register($dst$$reg),
11053               as_Register($src1$$reg),
11054               as_Register($src2$$reg),
11055               Assembler::ASR,
11056               $src3$$constant &amp; 0x1f);
11057   %}
11058 
11059   ins_pipe(ialu_reg_reg_shift);
11060 %}
11061 
11062 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11063                          iRegL src1, iRegL src2,
11064                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11065   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11066   ins_cost(1.9 * INSN_COST);
11067   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11068 
11069   ins_encode %{
11070     __ bic(as_Register($dst$$reg),
11071               as_Register($src1$$reg),
11072               as_Register($src2$$reg),
11073               Assembler::ASR,
11074               $src3$$constant &amp; 0x3f);
11075   %}
11076 
11077   ins_pipe(ialu_reg_reg_shift);
11078 %}
11079 
11080 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11081                          iRegIorL2I src1, iRegIorL2I src2,
11082                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11083   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11084   ins_cost(1.9 * INSN_COST);
11085   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11086 
11087   ins_encode %{
11088     __ bicw(as_Register($dst$$reg),
11089               as_Register($src1$$reg),
11090               as_Register($src2$$reg),
11091               Assembler::LSL,
11092               $src3$$constant &amp; 0x1f);
11093   %}
11094 
11095   ins_pipe(ialu_reg_reg_shift);
11096 %}
11097 
11098 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11099                          iRegL src1, iRegL src2,
11100                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11101   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11102   ins_cost(1.9 * INSN_COST);
11103   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11104 
11105   ins_encode %{
11106     __ bic(as_Register($dst$$reg),
11107               as_Register($src1$$reg),
11108               as_Register($src2$$reg),
11109               Assembler::LSL,
11110               $src3$$constant &amp; 0x3f);
11111   %}
11112 
11113   ins_pipe(ialu_reg_reg_shift);
11114 %}
11115 
11116 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11117                          iRegIorL2I src1, iRegIorL2I src2,
11118                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11119   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11120   ins_cost(1.9 * INSN_COST);
11121   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11122 
11123   ins_encode %{
11124     __ eonw(as_Register($dst$$reg),
11125               as_Register($src1$$reg),
11126               as_Register($src2$$reg),
11127               Assembler::LSR,
11128               $src3$$constant &amp; 0x1f);
11129   %}
11130 
11131   ins_pipe(ialu_reg_reg_shift);
11132 %}
11133 
11134 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11135                          iRegL src1, iRegL src2,
11136                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11137   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11138   ins_cost(1.9 * INSN_COST);
11139   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11140 
11141   ins_encode %{
11142     __ eon(as_Register($dst$$reg),
11143               as_Register($src1$$reg),
11144               as_Register($src2$$reg),
11145               Assembler::LSR,
11146               $src3$$constant &amp; 0x3f);
11147   %}
11148 
11149   ins_pipe(ialu_reg_reg_shift);
11150 %}
11151 
11152 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11153                          iRegIorL2I src1, iRegIorL2I src2,
11154                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11155   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11156   ins_cost(1.9 * INSN_COST);
11157   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11158 
11159   ins_encode %{
11160     __ eonw(as_Register($dst$$reg),
11161               as_Register($src1$$reg),
11162               as_Register($src2$$reg),
11163               Assembler::ASR,
11164               $src3$$constant &amp; 0x1f);
11165   %}
11166 
11167   ins_pipe(ialu_reg_reg_shift);
11168 %}
11169 
11170 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11171                          iRegL src1, iRegL src2,
11172                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11173   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11174   ins_cost(1.9 * INSN_COST);
11175   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11176 
11177   ins_encode %{
11178     __ eon(as_Register($dst$$reg),
11179               as_Register($src1$$reg),
11180               as_Register($src2$$reg),
11181               Assembler::ASR,
11182               $src3$$constant &amp; 0x3f);
11183   %}
11184 
11185   ins_pipe(ialu_reg_reg_shift);
11186 %}
11187 
11188 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11189                          iRegIorL2I src1, iRegIorL2I src2,
11190                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11191   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11192   ins_cost(1.9 * INSN_COST);
11193   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11194 
11195   ins_encode %{
11196     __ eonw(as_Register($dst$$reg),
11197               as_Register($src1$$reg),
11198               as_Register($src2$$reg),
11199               Assembler::LSL,
11200               $src3$$constant &amp; 0x1f);
11201   %}
11202 
11203   ins_pipe(ialu_reg_reg_shift);
11204 %}
11205 
11206 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11207                          iRegL src1, iRegL src2,
11208                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11209   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11210   ins_cost(1.9 * INSN_COST);
11211   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11212 
11213   ins_encode %{
11214     __ eon(as_Register($dst$$reg),
11215               as_Register($src1$$reg),
11216               as_Register($src2$$reg),
11217               Assembler::LSL,
11218               $src3$$constant &amp; 0x3f);
11219   %}
11220 
11221   ins_pipe(ialu_reg_reg_shift);
11222 %}
11223 
11224 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11225                          iRegIorL2I src1, iRegIorL2I src2,
11226                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11227   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11228   ins_cost(1.9 * INSN_COST);
11229   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11230 
11231   ins_encode %{
11232     __ ornw(as_Register($dst$$reg),
11233               as_Register($src1$$reg),
11234               as_Register($src2$$reg),
11235               Assembler::LSR,
11236               $src3$$constant &amp; 0x1f);
11237   %}
11238 
11239   ins_pipe(ialu_reg_reg_shift);
11240 %}
11241 
11242 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11243                          iRegL src1, iRegL src2,
11244                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11245   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11246   ins_cost(1.9 * INSN_COST);
11247   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11248 
11249   ins_encode %{
11250     __ orn(as_Register($dst$$reg),
11251               as_Register($src1$$reg),
11252               as_Register($src2$$reg),
11253               Assembler::LSR,
11254               $src3$$constant &amp; 0x3f);
11255   %}
11256 
11257   ins_pipe(ialu_reg_reg_shift);
11258 %}
11259 
11260 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11261                          iRegIorL2I src1, iRegIorL2I src2,
11262                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11263   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11264   ins_cost(1.9 * INSN_COST);
11265   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11266 
11267   ins_encode %{
11268     __ ornw(as_Register($dst$$reg),
11269               as_Register($src1$$reg),
11270               as_Register($src2$$reg),
11271               Assembler::ASR,
11272               $src3$$constant &amp; 0x1f);
11273   %}
11274 
11275   ins_pipe(ialu_reg_reg_shift);
11276 %}
11277 
11278 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11279                          iRegL src1, iRegL src2,
11280                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11281   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11282   ins_cost(1.9 * INSN_COST);
11283   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11284 
11285   ins_encode %{
11286     __ orn(as_Register($dst$$reg),
11287               as_Register($src1$$reg),
11288               as_Register($src2$$reg),
11289               Assembler::ASR,
11290               $src3$$constant &amp; 0x3f);
11291   %}
11292 
11293   ins_pipe(ialu_reg_reg_shift);
11294 %}
11295 
11296 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11297                          iRegIorL2I src1, iRegIorL2I src2,
11298                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11299   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11300   ins_cost(1.9 * INSN_COST);
11301   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11302 
11303   ins_encode %{
11304     __ ornw(as_Register($dst$$reg),
11305               as_Register($src1$$reg),
11306               as_Register($src2$$reg),
11307               Assembler::LSL,
11308               $src3$$constant &amp; 0x1f);
11309   %}
11310 
11311   ins_pipe(ialu_reg_reg_shift);
11312 %}
11313 
11314 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11315                          iRegL src1, iRegL src2,
11316                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11317   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11318   ins_cost(1.9 * INSN_COST);
11319   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11320 
11321   ins_encode %{
11322     __ orn(as_Register($dst$$reg),
11323               as_Register($src1$$reg),
11324               as_Register($src2$$reg),
11325               Assembler::LSL,
11326               $src3$$constant &amp; 0x3f);
11327   %}
11328 
11329   ins_pipe(ialu_reg_reg_shift);
11330 %}
11331 
11332 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11333                          iRegIorL2I src1, iRegIorL2I src2,
11334                          immI src3, rFlagsReg cr) %{
11335   match(Set dst (AndI src1 (URShiftI src2 src3)));
11336 
11337   ins_cost(1.9 * INSN_COST);
11338   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11339 
11340   ins_encode %{
11341     __ andw(as_Register($dst$$reg),
11342               as_Register($src1$$reg),
11343               as_Register($src2$$reg),
11344               Assembler::LSR,
11345               $src3$$constant &amp; 0x1f);
11346   %}
11347 
11348   ins_pipe(ialu_reg_reg_shift);
11349 %}
11350 
11351 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11352                          iRegL src1, iRegL src2,
11353                          immI src3, rFlagsReg cr) %{
11354   match(Set dst (AndL src1 (URShiftL src2 src3)));
11355 
11356   ins_cost(1.9 * INSN_COST);
11357   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11358 
11359   ins_encode %{
11360     __ andr(as_Register($dst$$reg),
11361               as_Register($src1$$reg),
11362               as_Register($src2$$reg),
11363               Assembler::LSR,
11364               $src3$$constant &amp; 0x3f);
11365   %}
11366 
11367   ins_pipe(ialu_reg_reg_shift);
11368 %}
11369 
11370 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11371                          iRegIorL2I src1, iRegIorL2I src2,
11372                          immI src3, rFlagsReg cr) %{
11373   match(Set dst (AndI src1 (RShiftI src2 src3)));
11374 
11375   ins_cost(1.9 * INSN_COST);
11376   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11377 
11378   ins_encode %{
11379     __ andw(as_Register($dst$$reg),
11380               as_Register($src1$$reg),
11381               as_Register($src2$$reg),
11382               Assembler::ASR,
11383               $src3$$constant &amp; 0x1f);
11384   %}
11385 
11386   ins_pipe(ialu_reg_reg_shift);
11387 %}
11388 
11389 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11390                          iRegL src1, iRegL src2,
11391                          immI src3, rFlagsReg cr) %{
11392   match(Set dst (AndL src1 (RShiftL src2 src3)));
11393 
11394   ins_cost(1.9 * INSN_COST);
11395   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11396 
11397   ins_encode %{
11398     __ andr(as_Register($dst$$reg),
11399               as_Register($src1$$reg),
11400               as_Register($src2$$reg),
11401               Assembler::ASR,
11402               $src3$$constant &amp; 0x3f);
11403   %}
11404 
11405   ins_pipe(ialu_reg_reg_shift);
11406 %}
11407 
11408 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11409                          iRegIorL2I src1, iRegIorL2I src2,
11410                          immI src3, rFlagsReg cr) %{
11411   match(Set dst (AndI src1 (LShiftI src2 src3)));
11412 
11413   ins_cost(1.9 * INSN_COST);
11414   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11415 
11416   ins_encode %{
11417     __ andw(as_Register($dst$$reg),
11418               as_Register($src1$$reg),
11419               as_Register($src2$$reg),
11420               Assembler::LSL,
11421               $src3$$constant &amp; 0x1f);
11422   %}
11423 
11424   ins_pipe(ialu_reg_reg_shift);
11425 %}
11426 
11427 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11428                          iRegL src1, iRegL src2,
11429                          immI src3, rFlagsReg cr) %{
11430   match(Set dst (AndL src1 (LShiftL src2 src3)));
11431 
11432   ins_cost(1.9 * INSN_COST);
11433   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11434 
11435   ins_encode %{
11436     __ andr(as_Register($dst$$reg),
11437               as_Register($src1$$reg),
11438               as_Register($src2$$reg),
11439               Assembler::LSL,
11440               $src3$$constant &amp; 0x3f);
11441   %}
11442 
11443   ins_pipe(ialu_reg_reg_shift);
11444 %}
11445 
11446 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11447                          iRegIorL2I src1, iRegIorL2I src2,
11448                          immI src3, rFlagsReg cr) %{
11449   match(Set dst (XorI src1 (URShiftI src2 src3)));
11450 
11451   ins_cost(1.9 * INSN_COST);
11452   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11453 
11454   ins_encode %{
11455     __ eorw(as_Register($dst$$reg),
11456               as_Register($src1$$reg),
11457               as_Register($src2$$reg),
11458               Assembler::LSR,
11459               $src3$$constant &amp; 0x1f);
11460   %}
11461 
11462   ins_pipe(ialu_reg_reg_shift);
11463 %}
11464 
11465 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11466                          iRegL src1, iRegL src2,
11467                          immI src3, rFlagsReg cr) %{
11468   match(Set dst (XorL src1 (URShiftL src2 src3)));
11469 
11470   ins_cost(1.9 * INSN_COST);
11471   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11472 
11473   ins_encode %{
11474     __ eor(as_Register($dst$$reg),
11475               as_Register($src1$$reg),
11476               as_Register($src2$$reg),
11477               Assembler::LSR,
11478               $src3$$constant &amp; 0x3f);
11479   %}
11480 
11481   ins_pipe(ialu_reg_reg_shift);
11482 %}
11483 
11484 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11485                          iRegIorL2I src1, iRegIorL2I src2,
11486                          immI src3, rFlagsReg cr) %{
11487   match(Set dst (XorI src1 (RShiftI src2 src3)));
11488 
11489   ins_cost(1.9 * INSN_COST);
11490   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11491 
11492   ins_encode %{
11493     __ eorw(as_Register($dst$$reg),
11494               as_Register($src1$$reg),
11495               as_Register($src2$$reg),
11496               Assembler::ASR,
11497               $src3$$constant &amp; 0x1f);
11498   %}
11499 
11500   ins_pipe(ialu_reg_reg_shift);
11501 %}
11502 
11503 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11504                          iRegL src1, iRegL src2,
11505                          immI src3, rFlagsReg cr) %{
11506   match(Set dst (XorL src1 (RShiftL src2 src3)));
11507 
11508   ins_cost(1.9 * INSN_COST);
11509   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11510 
11511   ins_encode %{
11512     __ eor(as_Register($dst$$reg),
11513               as_Register($src1$$reg),
11514               as_Register($src2$$reg),
11515               Assembler::ASR,
11516               $src3$$constant &amp; 0x3f);
11517   %}
11518 
11519   ins_pipe(ialu_reg_reg_shift);
11520 %}
11521 
11522 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11523                          iRegIorL2I src1, iRegIorL2I src2,
11524                          immI src3, rFlagsReg cr) %{
11525   match(Set dst (XorI src1 (LShiftI src2 src3)));
11526 
11527   ins_cost(1.9 * INSN_COST);
11528   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11529 
11530   ins_encode %{
11531     __ eorw(as_Register($dst$$reg),
11532               as_Register($src1$$reg),
11533               as_Register($src2$$reg),
11534               Assembler::LSL,
11535               $src3$$constant &amp; 0x1f);
11536   %}
11537 
11538   ins_pipe(ialu_reg_reg_shift);
11539 %}
11540 
11541 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11542                          iRegL src1, iRegL src2,
11543                          immI src3, rFlagsReg cr) %{
11544   match(Set dst (XorL src1 (LShiftL src2 src3)));
11545 
11546   ins_cost(1.9 * INSN_COST);
11547   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11548 
11549   ins_encode %{
11550     __ eor(as_Register($dst$$reg),
11551               as_Register($src1$$reg),
11552               as_Register($src2$$reg),
11553               Assembler::LSL,
11554               $src3$$constant &amp; 0x3f);
11555   %}
11556 
11557   ins_pipe(ialu_reg_reg_shift);
11558 %}
11559 
11560 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11561                          iRegIorL2I src1, iRegIorL2I src2,
11562                          immI src3, rFlagsReg cr) %{
11563   match(Set dst (OrI src1 (URShiftI src2 src3)));
11564 
11565   ins_cost(1.9 * INSN_COST);
11566   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11567 
11568   ins_encode %{
11569     __ orrw(as_Register($dst$$reg),
11570               as_Register($src1$$reg),
11571               as_Register($src2$$reg),
11572               Assembler::LSR,
11573               $src3$$constant &amp; 0x1f);
11574   %}
11575 
11576   ins_pipe(ialu_reg_reg_shift);
11577 %}
11578 
11579 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11580                          iRegL src1, iRegL src2,
11581                          immI src3, rFlagsReg cr) %{
11582   match(Set dst (OrL src1 (URShiftL src2 src3)));
11583 
11584   ins_cost(1.9 * INSN_COST);
11585   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11586 
11587   ins_encode %{
11588     __ orr(as_Register($dst$$reg),
11589               as_Register($src1$$reg),
11590               as_Register($src2$$reg),
11591               Assembler::LSR,
11592               $src3$$constant &amp; 0x3f);
11593   %}
11594 
11595   ins_pipe(ialu_reg_reg_shift);
11596 %}
11597 
11598 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11599                          iRegIorL2I src1, iRegIorL2I src2,
11600                          immI src3, rFlagsReg cr) %{
11601   match(Set dst (OrI src1 (RShiftI src2 src3)));
11602 
11603   ins_cost(1.9 * INSN_COST);
11604   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11605 
11606   ins_encode %{
11607     __ orrw(as_Register($dst$$reg),
11608               as_Register($src1$$reg),
11609               as_Register($src2$$reg),
11610               Assembler::ASR,
11611               $src3$$constant &amp; 0x1f);
11612   %}
11613 
11614   ins_pipe(ialu_reg_reg_shift);
11615 %}
11616 
11617 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11618                          iRegL src1, iRegL src2,
11619                          immI src3, rFlagsReg cr) %{
11620   match(Set dst (OrL src1 (RShiftL src2 src3)));
11621 
11622   ins_cost(1.9 * INSN_COST);
11623   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11624 
11625   ins_encode %{
11626     __ orr(as_Register($dst$$reg),
11627               as_Register($src1$$reg),
11628               as_Register($src2$$reg),
11629               Assembler::ASR,
11630               $src3$$constant &amp; 0x3f);
11631   %}
11632 
11633   ins_pipe(ialu_reg_reg_shift);
11634 %}
11635 
11636 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11637                          iRegIorL2I src1, iRegIorL2I src2,
11638                          immI src3, rFlagsReg cr) %{
11639   match(Set dst (OrI src1 (LShiftI src2 src3)));
11640 
11641   ins_cost(1.9 * INSN_COST);
11642   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11643 
11644   ins_encode %{
11645     __ orrw(as_Register($dst$$reg),
11646               as_Register($src1$$reg),
11647               as_Register($src2$$reg),
11648               Assembler::LSL,
11649               $src3$$constant &amp; 0x1f);
11650   %}
11651 
11652   ins_pipe(ialu_reg_reg_shift);
11653 %}
11654 
11655 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11656                          iRegL src1, iRegL src2,
11657                          immI src3, rFlagsReg cr) %{
11658   match(Set dst (OrL src1 (LShiftL src2 src3)));
11659 
11660   ins_cost(1.9 * INSN_COST);
11661   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11662 
11663   ins_encode %{
11664     __ orr(as_Register($dst$$reg),
11665               as_Register($src1$$reg),
11666               as_Register($src2$$reg),
11667               Assembler::LSL,
11668               $src3$$constant &amp; 0x3f);
11669   %}
11670 
11671   ins_pipe(ialu_reg_reg_shift);
11672 %}
11673 
11674 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11675                          iRegIorL2I src1, iRegIorL2I src2,
11676                          immI src3, rFlagsReg cr) %{
11677   match(Set dst (AddI src1 (URShiftI src2 src3)));
11678 
11679   ins_cost(1.9 * INSN_COST);
11680   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11681 
11682   ins_encode %{
11683     __ addw(as_Register($dst$$reg),
11684               as_Register($src1$$reg),
11685               as_Register($src2$$reg),
11686               Assembler::LSR,
11687               $src3$$constant &amp; 0x1f);
11688   %}
11689 
11690   ins_pipe(ialu_reg_reg_shift);
11691 %}
11692 
11693 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11694                          iRegL src1, iRegL src2,
11695                          immI src3, rFlagsReg cr) %{
11696   match(Set dst (AddL src1 (URShiftL src2 src3)));
11697 
11698   ins_cost(1.9 * INSN_COST);
11699   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11700 
11701   ins_encode %{
11702     __ add(as_Register($dst$$reg),
11703               as_Register($src1$$reg),
11704               as_Register($src2$$reg),
11705               Assembler::LSR,
11706               $src3$$constant &amp; 0x3f);
11707   %}
11708 
11709   ins_pipe(ialu_reg_reg_shift);
11710 %}
11711 
11712 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11713                          iRegIorL2I src1, iRegIorL2I src2,
11714                          immI src3, rFlagsReg cr) %{
11715   match(Set dst (AddI src1 (RShiftI src2 src3)));
11716 
11717   ins_cost(1.9 * INSN_COST);
11718   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11719 
11720   ins_encode %{
11721     __ addw(as_Register($dst$$reg),
11722               as_Register($src1$$reg),
11723               as_Register($src2$$reg),
11724               Assembler::ASR,
11725               $src3$$constant &amp; 0x1f);
11726   %}
11727 
11728   ins_pipe(ialu_reg_reg_shift);
11729 %}
11730 
11731 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11732                          iRegL src1, iRegL src2,
11733                          immI src3, rFlagsReg cr) %{
11734   match(Set dst (AddL src1 (RShiftL src2 src3)));
11735 
11736   ins_cost(1.9 * INSN_COST);
11737   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11738 
11739   ins_encode %{
11740     __ add(as_Register($dst$$reg),
11741               as_Register($src1$$reg),
11742               as_Register($src2$$reg),
11743               Assembler::ASR,
11744               $src3$$constant &amp; 0x3f);
11745   %}
11746 
11747   ins_pipe(ialu_reg_reg_shift);
11748 %}
11749 
11750 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11751                          iRegIorL2I src1, iRegIorL2I src2,
11752                          immI src3, rFlagsReg cr) %{
11753   match(Set dst (AddI src1 (LShiftI src2 src3)));
11754 
11755   ins_cost(1.9 * INSN_COST);
11756   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11757 
11758   ins_encode %{
11759     __ addw(as_Register($dst$$reg),
11760               as_Register($src1$$reg),
11761               as_Register($src2$$reg),
11762               Assembler::LSL,
11763               $src3$$constant &amp; 0x1f);
11764   %}
11765 
11766   ins_pipe(ialu_reg_reg_shift);
11767 %}
11768 
11769 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11770                          iRegL src1, iRegL src2,
11771                          immI src3, rFlagsReg cr) %{
11772   match(Set dst (AddL src1 (LShiftL src2 src3)));
11773 
11774   ins_cost(1.9 * INSN_COST);
11775   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11776 
11777   ins_encode %{
11778     __ add(as_Register($dst$$reg),
11779               as_Register($src1$$reg),
11780               as_Register($src2$$reg),
11781               Assembler::LSL,
11782               $src3$$constant &amp; 0x3f);
11783   %}
11784 
11785   ins_pipe(ialu_reg_reg_shift);
11786 %}
11787 
11788 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11789                          iRegIorL2I src1, iRegIorL2I src2,
11790                          immI src3, rFlagsReg cr) %{
11791   match(Set dst (SubI src1 (URShiftI src2 src3)));
11792 
11793   ins_cost(1.9 * INSN_COST);
11794   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11795 
11796   ins_encode %{
11797     __ subw(as_Register($dst$$reg),
11798               as_Register($src1$$reg),
11799               as_Register($src2$$reg),
11800               Assembler::LSR,
11801               $src3$$constant &amp; 0x1f);
11802   %}
11803 
11804   ins_pipe(ialu_reg_reg_shift);
11805 %}
11806 
11807 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11808                          iRegL src1, iRegL src2,
11809                          immI src3, rFlagsReg cr) %{
11810   match(Set dst (SubL src1 (URShiftL src2 src3)));
11811 
11812   ins_cost(1.9 * INSN_COST);
11813   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11814 
11815   ins_encode %{
11816     __ sub(as_Register($dst$$reg),
11817               as_Register($src1$$reg),
11818               as_Register($src2$$reg),
11819               Assembler::LSR,
11820               $src3$$constant &amp; 0x3f);
11821   %}
11822 
11823   ins_pipe(ialu_reg_reg_shift);
11824 %}
11825 
11826 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11827                          iRegIorL2I src1, iRegIorL2I src2,
11828                          immI src3, rFlagsReg cr) %{
11829   match(Set dst (SubI src1 (RShiftI src2 src3)));
11830 
11831   ins_cost(1.9 * INSN_COST);
11832   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11833 
11834   ins_encode %{
11835     __ subw(as_Register($dst$$reg),
11836               as_Register($src1$$reg),
11837               as_Register($src2$$reg),
11838               Assembler::ASR,
11839               $src3$$constant &amp; 0x1f);
11840   %}
11841 
11842   ins_pipe(ialu_reg_reg_shift);
11843 %}
11844 
11845 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11846                          iRegL src1, iRegL src2,
11847                          immI src3, rFlagsReg cr) %{
11848   match(Set dst (SubL src1 (RShiftL src2 src3)));
11849 
11850   ins_cost(1.9 * INSN_COST);
11851   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11852 
11853   ins_encode %{
11854     __ sub(as_Register($dst$$reg),
11855               as_Register($src1$$reg),
11856               as_Register($src2$$reg),
11857               Assembler::ASR,
11858               $src3$$constant &amp; 0x3f);
11859   %}
11860 
11861   ins_pipe(ialu_reg_reg_shift);
11862 %}
11863 
11864 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11865                          iRegIorL2I src1, iRegIorL2I src2,
11866                          immI src3, rFlagsReg cr) %{
11867   match(Set dst (SubI src1 (LShiftI src2 src3)));
11868 
11869   ins_cost(1.9 * INSN_COST);
11870   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11871 
11872   ins_encode %{
11873     __ subw(as_Register($dst$$reg),
11874               as_Register($src1$$reg),
11875               as_Register($src2$$reg),
11876               Assembler::LSL,
11877               $src3$$constant &amp; 0x1f);
11878   %}
11879 
11880   ins_pipe(ialu_reg_reg_shift);
11881 %}
11882 
11883 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11884                          iRegL src1, iRegL src2,
11885                          immI src3, rFlagsReg cr) %{
11886   match(Set dst (SubL src1 (LShiftL src2 src3)));
11887 
11888   ins_cost(1.9 * INSN_COST);
11889   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11890 
11891   ins_encode %{
11892     __ sub(as_Register($dst$$reg),
11893               as_Register($src1$$reg),
11894               as_Register($src2$$reg),
11895               Assembler::LSL,
11896               $src3$$constant &amp; 0x3f);
11897   %}
11898 
11899   ins_pipe(ialu_reg_reg_shift);
11900 %}
11901 
11902 
11903 
11904 // Shift Left followed by Shift Right.
11905 // This idiom is used by the compiler for the i2b bytecode etc.
11906 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11907 %{
11908   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11909   ins_cost(INSN_COST * 2);
11910   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11911   ins_encode %{
11912     int lshift = $lshift_count$$constant &amp; 63;
11913     int rshift = $rshift_count$$constant &amp; 63;
11914     int s = 63 - lshift;
11915     int r = (rshift - lshift) &amp; 63;
11916     __ sbfm(as_Register($dst$$reg),
11917             as_Register($src$$reg),
11918             r, s);
11919   %}
11920 
11921   ins_pipe(ialu_reg_shift);
11922 %}
11923 
11924 // Shift Left followed by Shift Right.
11925 // This idiom is used by the compiler for the i2b bytecode etc.
11926 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11927 %{
11928   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11929   ins_cost(INSN_COST * 2);
11930   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11931   ins_encode %{
11932     int lshift = $lshift_count$$constant &amp; 31;
11933     int rshift = $rshift_count$$constant &amp; 31;
11934     int s = 31 - lshift;
11935     int r = (rshift - lshift) &amp; 31;
11936     __ sbfmw(as_Register($dst$$reg),
11937             as_Register($src$$reg),
11938             r, s);
11939   %}
11940 
11941   ins_pipe(ialu_reg_shift);
11942 %}
11943 
11944 // Shift Left followed by Shift Right.
11945 // This idiom is used by the compiler for the i2b bytecode etc.
11946 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11947 %{
11948   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
11949   ins_cost(INSN_COST * 2);
11950   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11951   ins_encode %{
11952     int lshift = $lshift_count$$constant &amp; 63;
11953     int rshift = $rshift_count$$constant &amp; 63;
11954     int s = 63 - lshift;
11955     int r = (rshift - lshift) &amp; 63;
11956     __ ubfm(as_Register($dst$$reg),
11957             as_Register($src$$reg),
11958             r, s);
11959   %}
11960 
11961   ins_pipe(ialu_reg_shift);
11962 %}
11963 
11964 // Shift Left followed by Shift Right.
11965 // This idiom is used by the compiler for the i2b bytecode etc.
11966 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11967 %{
11968   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
11969   ins_cost(INSN_COST * 2);
11970   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11971   ins_encode %{
11972     int lshift = $lshift_count$$constant &amp; 31;
11973     int rshift = $rshift_count$$constant &amp; 31;
11974     int s = 31 - lshift;
11975     int r = (rshift - lshift) &amp; 31;
11976     __ ubfmw(as_Register($dst$$reg),
11977             as_Register($src$$reg),
11978             r, s);
11979   %}
11980 
11981   ins_pipe(ialu_reg_shift);
11982 %}
11983 // Bitfield extract with shift &amp; mask
11984 
11985 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
11986 %{
11987   match(Set dst (AndI (URShiftI src rshift) mask));
11988   // Make sure we are not going to exceed what ubfxw can do.
11989   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
11990 
11991   ins_cost(INSN_COST);
11992   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
11993   ins_encode %{
11994     int rshift = $rshift$$constant &amp; 31;
11995     long mask = $mask$$constant;
11996     int width = exact_log2(mask+1);
11997     __ ubfxw(as_Register($dst$$reg),
11998             as_Register($src$$reg), rshift, width);
11999   %}
12000   ins_pipe(ialu_reg_shift);
12001 %}
12002 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
12003 %{
12004   match(Set dst (AndL (URShiftL src rshift) mask));
12005   // Make sure we are not going to exceed what ubfx can do.
12006   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12007 
12008   ins_cost(INSN_COST);
12009   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12010   ins_encode %{
12011     int rshift = $rshift$$constant &amp; 63;
12012     long mask = $mask$$constant;
12013     int width = exact_log2_long(mask+1);
12014     __ ubfx(as_Register($dst$$reg),
12015             as_Register($src$$reg), rshift, width);
12016   %}
12017   ins_pipe(ialu_reg_shift);
12018 %}
12019 
12020 // We can use ubfx when extending an And with a mask when we know mask
12021 // is positive.  We know that because immI_bitmask guarantees it.
12022 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12023 %{
12024   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12025   // Make sure we are not going to exceed what ubfxw can do.
12026   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12027 
12028   ins_cost(INSN_COST * 2);
12029   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12030   ins_encode %{
12031     int rshift = $rshift$$constant &amp; 31;
12032     long mask = $mask$$constant;
12033     int width = exact_log2(mask+1);
12034     __ ubfx(as_Register($dst$$reg),
12035             as_Register($src$$reg), rshift, width);
12036   %}
12037   ins_pipe(ialu_reg_shift);
12038 %}
12039 
12040 // We can use ubfiz when masking by a positive number and then left shifting the result.
12041 // We know that the mask is positive because immI_bitmask guarantees it.
12042 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12043 %{
12044   match(Set dst (LShiftI (AndI src mask) lshift));
12045   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12046 
12047   ins_cost(INSN_COST);
12048   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12049   ins_encode %{
12050     int lshift = $lshift$$constant &amp; 31;
12051     long mask = $mask$$constant;
12052     int width = exact_log2(mask+1);
12053     __ ubfizw(as_Register($dst$$reg),
12054           as_Register($src$$reg), lshift, width);
12055   %}
12056   ins_pipe(ialu_reg_shift);
12057 %}
12058 // We can use ubfiz when masking by a positive number and then left shifting the result.
12059 // We know that the mask is positive because immL_bitmask guarantees it.
12060 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12061 %{
12062   match(Set dst (LShiftL (AndL src mask) lshift));
12063   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12064 
12065   ins_cost(INSN_COST);
12066   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12067   ins_encode %{
12068     int lshift = $lshift$$constant &amp; 63;
12069     long mask = $mask$$constant;
12070     int width = exact_log2_long(mask+1);
12071     __ ubfiz(as_Register($dst$$reg),
12072           as_Register($src$$reg), lshift, width);
12073   %}
12074   ins_pipe(ialu_reg_shift);
12075 %}
12076 
12077 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12078 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12079 %{
12080   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12081   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12082 
12083   ins_cost(INSN_COST);
12084   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12085   ins_encode %{
12086     int lshift = $lshift$$constant &amp; 63;
12087     long mask = $mask$$constant;
12088     int width = exact_log2(mask+1);
12089     __ ubfiz(as_Register($dst$$reg),
12090              as_Register($src$$reg), lshift, width);
12091   %}
12092   ins_pipe(ialu_reg_shift);
12093 %}
12094 
12095 // Rotations
12096 
12097 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12098 %{
12099   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12100   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12101 
12102   ins_cost(INSN_COST);
12103   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12104 
12105   ins_encode %{
12106     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12107             $rshift$$constant &amp; 63);
12108   %}
12109   ins_pipe(ialu_reg_reg_extr);
12110 %}
12111 
12112 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12113 %{
12114   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12115   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12116 
12117   ins_cost(INSN_COST);
12118   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12119 
12120   ins_encode %{
12121     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12122             $rshift$$constant &amp; 31);
12123   %}
12124   ins_pipe(ialu_reg_reg_extr);
12125 %}
12126 
12127 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12128 %{
12129   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12130   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12131 
12132   ins_cost(INSN_COST);
12133   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12134 
12135   ins_encode %{
12136     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12137             $rshift$$constant &amp; 63);
12138   %}
12139   ins_pipe(ialu_reg_reg_extr);
12140 %}
12141 
12142 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12143 %{
12144   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12145   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12146 
12147   ins_cost(INSN_COST);
12148   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12149 
12150   ins_encode %{
12151     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12152             $rshift$$constant &amp; 31);
12153   %}
12154   ins_pipe(ialu_reg_reg_extr);
12155 %}
12156 
12157 
12158 // rol expander
12159 
12160 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12161 %{
12162   effect(DEF dst, USE src, USE shift);
12163 
12164   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12165   ins_cost(INSN_COST * 3);
12166   ins_encode %{
12167     __ subw(rscratch1, zr, as_Register($shift$$reg));
12168     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12169             rscratch1);
12170     %}
12171   ins_pipe(ialu_reg_reg_vshift);
12172 %}
12173 
12174 // rol expander
12175 
12176 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12177 %{
12178   effect(DEF dst, USE src, USE shift);
12179 
12180   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12181   ins_cost(INSN_COST * 3);
12182   ins_encode %{
12183     __ subw(rscratch1, zr, as_Register($shift$$reg));
12184     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12185             rscratch1);
12186     %}
12187   ins_pipe(ialu_reg_reg_vshift);
12188 %}
12189 
12190 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12191 %{
12192   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12193 
12194   expand %{
12195     rolL_rReg(dst, src, shift, cr);
12196   %}
12197 %}
12198 
12199 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12200 %{
12201   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12202 
12203   expand %{
12204     rolL_rReg(dst, src, shift, cr);
12205   %}
12206 %}
12207 
12208 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12209 %{
12210   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12211 
12212   expand %{
12213     rolI_rReg(dst, src, shift, cr);
12214   %}
12215 %}
12216 
12217 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12218 %{
12219   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12220 
12221   expand %{
12222     rolI_rReg(dst, src, shift, cr);
12223   %}
12224 %}
12225 
12226 // ror expander
12227 
12228 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12229 %{
12230   effect(DEF dst, USE src, USE shift);
12231 
12232   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12233   ins_cost(INSN_COST);
12234   ins_encode %{
12235     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12236             as_Register($shift$$reg));
12237     %}
12238   ins_pipe(ialu_reg_reg_vshift);
12239 %}
12240 
12241 // ror expander
12242 
12243 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12244 %{
12245   effect(DEF dst, USE src, USE shift);
12246 
12247   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12248   ins_cost(INSN_COST);
12249   ins_encode %{
12250     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12251             as_Register($shift$$reg));
12252     %}
12253   ins_pipe(ialu_reg_reg_vshift);
12254 %}
12255 
12256 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12257 %{
12258   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12259 
12260   expand %{
12261     rorL_rReg(dst, src, shift, cr);
12262   %}
12263 %}
12264 
12265 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12266 %{
12267   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12268 
12269   expand %{
12270     rorL_rReg(dst, src, shift, cr);
12271   %}
12272 %}
12273 
12274 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12275 %{
12276   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12277 
12278   expand %{
12279     rorI_rReg(dst, src, shift, cr);
12280   %}
12281 %}
12282 
12283 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12284 %{
12285   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12286 
12287   expand %{
12288     rorI_rReg(dst, src, shift, cr);
12289   %}
12290 %}
12291 
12292 // Add/subtract (extended)
12293 
12294 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12295 %{
12296   match(Set dst (AddL src1 (ConvI2L src2)));
12297   ins_cost(INSN_COST);
12298   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12299 
12300    ins_encode %{
12301      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12302             as_Register($src2$$reg), ext::sxtw);
12303    %}
12304   ins_pipe(ialu_reg_reg);
12305 %};
12306 
12307 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12308 %{
12309   match(Set dst (SubL src1 (ConvI2L src2)));
12310   ins_cost(INSN_COST);
12311   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12312 
12313    ins_encode %{
12314      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12315             as_Register($src2$$reg), ext::sxtw);
12316    %}
12317   ins_pipe(ialu_reg_reg);
12318 %};
12319 
12320 
12321 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12322 %{
12323   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12324   ins_cost(INSN_COST);
12325   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12326 
12327    ins_encode %{
12328      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12329             as_Register($src2$$reg), ext::sxth);
12330    %}
12331   ins_pipe(ialu_reg_reg);
12332 %}
12333 
12334 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12335 %{
12336   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12337   ins_cost(INSN_COST);
12338   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12339 
12340    ins_encode %{
12341      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12342             as_Register($src2$$reg), ext::sxtb);
12343    %}
12344   ins_pipe(ialu_reg_reg);
12345 %}
12346 
12347 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12348 %{
12349   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12350   ins_cost(INSN_COST);
12351   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12352 
12353    ins_encode %{
12354      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12355             as_Register($src2$$reg), ext::uxtb);
12356    %}
12357   ins_pipe(ialu_reg_reg);
12358 %}
12359 
12360 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12361 %{
12362   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12363   ins_cost(INSN_COST);
12364   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12365 
12366    ins_encode %{
12367      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12368             as_Register($src2$$reg), ext::sxth);
12369    %}
12370   ins_pipe(ialu_reg_reg);
12371 %}
12372 
12373 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12374 %{
12375   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12376   ins_cost(INSN_COST);
12377   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12378 
12379    ins_encode %{
12380      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12381             as_Register($src2$$reg), ext::sxtw);
12382    %}
12383   ins_pipe(ialu_reg_reg);
12384 %}
12385 
12386 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12387 %{
12388   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12389   ins_cost(INSN_COST);
12390   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12391 
12392    ins_encode %{
12393      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12394             as_Register($src2$$reg), ext::sxtb);
12395    %}
12396   ins_pipe(ialu_reg_reg);
12397 %}
12398 
12399 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12400 %{
12401   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12402   ins_cost(INSN_COST);
12403   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12404 
12405    ins_encode %{
12406      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12407             as_Register($src2$$reg), ext::uxtb);
12408    %}
12409   ins_pipe(ialu_reg_reg);
12410 %}
12411 
12412 
12413 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12414 %{
12415   match(Set dst (AddI src1 (AndI src2 mask)));
12416   ins_cost(INSN_COST);
12417   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12418 
12419    ins_encode %{
12420      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12421             as_Register($src2$$reg), ext::uxtb);
12422    %}
12423   ins_pipe(ialu_reg_reg);
12424 %}
12425 
12426 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12427 %{
12428   match(Set dst (AddI src1 (AndI src2 mask)));
12429   ins_cost(INSN_COST);
12430   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12431 
12432    ins_encode %{
12433      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12434             as_Register($src2$$reg), ext::uxth);
12435    %}
12436   ins_pipe(ialu_reg_reg);
12437 %}
12438 
12439 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12440 %{
12441   match(Set dst (AddL src1 (AndL src2 mask)));
12442   ins_cost(INSN_COST);
12443   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12444 
12445    ins_encode %{
12446      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12447             as_Register($src2$$reg), ext::uxtb);
12448    %}
12449   ins_pipe(ialu_reg_reg);
12450 %}
12451 
12452 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12453 %{
12454   match(Set dst (AddL src1 (AndL src2 mask)));
12455   ins_cost(INSN_COST);
12456   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12457 
12458    ins_encode %{
12459      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12460             as_Register($src2$$reg), ext::uxth);
12461    %}
12462   ins_pipe(ialu_reg_reg);
12463 %}
12464 
12465 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12466 %{
12467   match(Set dst (AddL src1 (AndL src2 mask)));
12468   ins_cost(INSN_COST);
12469   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12470 
12471    ins_encode %{
12472      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12473             as_Register($src2$$reg), ext::uxtw);
12474    %}
12475   ins_pipe(ialu_reg_reg);
12476 %}
12477 
12478 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12479 %{
12480   match(Set dst (SubI src1 (AndI src2 mask)));
12481   ins_cost(INSN_COST);
12482   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12483 
12484    ins_encode %{
12485      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12486             as_Register($src2$$reg), ext::uxtb);
12487    %}
12488   ins_pipe(ialu_reg_reg);
12489 %}
12490 
12491 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12492 %{
12493   match(Set dst (SubI src1 (AndI src2 mask)));
12494   ins_cost(INSN_COST);
12495   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12496 
12497    ins_encode %{
12498      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12499             as_Register($src2$$reg), ext::uxth);
12500    %}
12501   ins_pipe(ialu_reg_reg);
12502 %}
12503 
12504 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12505 %{
12506   match(Set dst (SubL src1 (AndL src2 mask)));
12507   ins_cost(INSN_COST);
12508   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12509 
12510    ins_encode %{
12511      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12512             as_Register($src2$$reg), ext::uxtb);
12513    %}
12514   ins_pipe(ialu_reg_reg);
12515 %}
12516 
12517 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12518 %{
12519   match(Set dst (SubL src1 (AndL src2 mask)));
12520   ins_cost(INSN_COST);
12521   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12522 
12523    ins_encode %{
12524      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12525             as_Register($src2$$reg), ext::uxth);
12526    %}
12527   ins_pipe(ialu_reg_reg);
12528 %}
12529 
12530 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12531 %{
12532   match(Set dst (SubL src1 (AndL src2 mask)));
12533   ins_cost(INSN_COST);
12534   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12535 
12536    ins_encode %{
12537      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12538             as_Register($src2$$reg), ext::uxtw);
12539    %}
12540   ins_pipe(ialu_reg_reg);
12541 %}
12542 
12543 
12544 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12545 %{
12546   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12547   ins_cost(1.9 * INSN_COST);
12548   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12549 
12550    ins_encode %{
12551      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12552             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12553    %}
12554   ins_pipe(ialu_reg_reg_shift);
12555 %}
12556 
12557 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12558 %{
12559   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12560   ins_cost(1.9 * INSN_COST);
12561   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12562 
12563    ins_encode %{
12564      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12565             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12566    %}
12567   ins_pipe(ialu_reg_reg_shift);
12568 %}
12569 
12570 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12571 %{
12572   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12573   ins_cost(1.9 * INSN_COST);
12574   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12575 
12576    ins_encode %{
12577      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12578             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12579    %}
12580   ins_pipe(ialu_reg_reg_shift);
12581 %}
12582 
12583 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12584 %{
12585   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12586   ins_cost(1.9 * INSN_COST);
12587   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12588 
12589    ins_encode %{
12590      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12591             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12592    %}
12593   ins_pipe(ialu_reg_reg_shift);
12594 %}
12595 
12596 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12597 %{
12598   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12599   ins_cost(1.9 * INSN_COST);
12600   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12601 
12602    ins_encode %{
12603      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12604             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12605    %}
12606   ins_pipe(ialu_reg_reg_shift);
12607 %}
12608 
12609 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12610 %{
12611   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12612   ins_cost(1.9 * INSN_COST);
12613   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12614 
12615    ins_encode %{
12616      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12617             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12618    %}
12619   ins_pipe(ialu_reg_reg_shift);
12620 %}
12621 
12622 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12623 %{
12624   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12625   ins_cost(1.9 * INSN_COST);
12626   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12627 
12628    ins_encode %{
12629      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12630             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12631    %}
12632   ins_pipe(ialu_reg_reg_shift);
12633 %}
12634 
12635 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12636 %{
12637   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12638   ins_cost(1.9 * INSN_COST);
12639   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12640 
12641    ins_encode %{
12642      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12643             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12644    %}
12645   ins_pipe(ialu_reg_reg_shift);
12646 %}
12647 
12648 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12649 %{
12650   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12651   ins_cost(1.9 * INSN_COST);
12652   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12653 
12654    ins_encode %{
12655      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12656             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12657    %}
12658   ins_pipe(ialu_reg_reg_shift);
12659 %}
12660 
12661 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12662 %{
12663   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12664   ins_cost(1.9 * INSN_COST);
12665   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12666 
12667    ins_encode %{
12668      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12669             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12670    %}
12671   ins_pipe(ialu_reg_reg_shift);
12672 %}
12673 
12674 
12675 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12676 %{
12677   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12678   ins_cost(1.9 * INSN_COST);
12679   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12680 
12681    ins_encode %{
12682      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12683             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12684    %}
12685   ins_pipe(ialu_reg_reg_shift);
12686 %};
12687 
12688 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12689 %{
12690   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12691   ins_cost(1.9 * INSN_COST);
12692   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12693 
12694    ins_encode %{
12695      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12696             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12697    %}
12698   ins_pipe(ialu_reg_reg_shift);
12699 %};
12700 
12701 
12702 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12703 %{
12704   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12705   ins_cost(1.9 * INSN_COST);
12706   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12707 
12708    ins_encode %{
12709      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12710             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12711    %}
12712   ins_pipe(ialu_reg_reg_shift);
12713 %}
12714 
12715 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12716 %{
12717   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12718   ins_cost(1.9 * INSN_COST);
12719   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12720 
12721    ins_encode %{
12722      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12723             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12724    %}
12725   ins_pipe(ialu_reg_reg_shift);
12726 %}
12727 
12728 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12729 %{
12730   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12731   ins_cost(1.9 * INSN_COST);
12732   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12733 
12734    ins_encode %{
12735      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12736             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12737    %}
12738   ins_pipe(ialu_reg_reg_shift);
12739 %}
12740 
12741 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12742 %{
12743   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12744   ins_cost(1.9 * INSN_COST);
12745   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12746 
12747    ins_encode %{
12748      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12749             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12750    %}
12751   ins_pipe(ialu_reg_reg_shift);
12752 %}
12753 
12754 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12755 %{
12756   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12757   ins_cost(1.9 * INSN_COST);
12758   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12759 
12760    ins_encode %{
12761      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12762             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12763    %}
12764   ins_pipe(ialu_reg_reg_shift);
12765 %}
12766 
12767 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12768 %{
12769   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12770   ins_cost(1.9 * INSN_COST);
12771   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12772 
12773    ins_encode %{
12774      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12775             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12776    %}
12777   ins_pipe(ialu_reg_reg_shift);
12778 %}
12779 
12780 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12781 %{
12782   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12783   ins_cost(1.9 * INSN_COST);
12784   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12785 
12786    ins_encode %{
12787      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12788             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12789    %}
12790   ins_pipe(ialu_reg_reg_shift);
12791 %}
12792 
12793 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12794 %{
12795   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12796   ins_cost(1.9 * INSN_COST);
12797   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12798 
12799    ins_encode %{
12800      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12801             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12802    %}
12803   ins_pipe(ialu_reg_reg_shift);
12804 %}
12805 
12806 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12807 %{
12808   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12809   ins_cost(1.9 * INSN_COST);
12810   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12811 
12812    ins_encode %{
12813      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12814             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12815    %}
12816   ins_pipe(ialu_reg_reg_shift);
12817 %}
12818 
12819 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12820 %{
12821   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12822   ins_cost(1.9 * INSN_COST);
12823   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12824 
12825    ins_encode %{
12826      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12827             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12828    %}
12829   ins_pipe(ialu_reg_reg_shift);
12830 %}
12831 // END This section of the file is automatically generated. Do not edit --------------
12832 
12833 // ============================================================================
12834 // Floating Point Arithmetic Instructions
12835 
12836 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12837   match(Set dst (AddF src1 src2));
12838 
12839   ins_cost(INSN_COST * 5);
12840   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12841 
12842   ins_encode %{
12843     __ fadds(as_FloatRegister($dst$$reg),
12844              as_FloatRegister($src1$$reg),
12845              as_FloatRegister($src2$$reg));
12846   %}
12847 
12848   ins_pipe(fp_dop_reg_reg_s);
12849 %}
12850 
12851 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12852   match(Set dst (AddD src1 src2));
12853 
12854   ins_cost(INSN_COST * 5);
12855   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12856 
12857   ins_encode %{
12858     __ faddd(as_FloatRegister($dst$$reg),
12859              as_FloatRegister($src1$$reg),
12860              as_FloatRegister($src2$$reg));
12861   %}
12862 
12863   ins_pipe(fp_dop_reg_reg_d);
12864 %}
12865 
12866 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12867   match(Set dst (SubF src1 src2));
12868 
12869   ins_cost(INSN_COST * 5);
12870   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12871 
12872   ins_encode %{
12873     __ fsubs(as_FloatRegister($dst$$reg),
12874              as_FloatRegister($src1$$reg),
12875              as_FloatRegister($src2$$reg));
12876   %}
12877 
12878   ins_pipe(fp_dop_reg_reg_s);
12879 %}
12880 
12881 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12882   match(Set dst (SubD src1 src2));
12883 
12884   ins_cost(INSN_COST * 5);
12885   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12886 
12887   ins_encode %{
12888     __ fsubd(as_FloatRegister($dst$$reg),
12889              as_FloatRegister($src1$$reg),
12890              as_FloatRegister($src2$$reg));
12891   %}
12892 
12893   ins_pipe(fp_dop_reg_reg_d);
12894 %}
12895 
12896 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12897   match(Set dst (MulF src1 src2));
12898 
12899   ins_cost(INSN_COST * 6);
12900   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12901 
12902   ins_encode %{
12903     __ fmuls(as_FloatRegister($dst$$reg),
12904              as_FloatRegister($src1$$reg),
12905              as_FloatRegister($src2$$reg));
12906   %}
12907 
12908   ins_pipe(fp_dop_reg_reg_s);
12909 %}
12910 
12911 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12912   match(Set dst (MulD src1 src2));
12913 
12914   ins_cost(INSN_COST * 6);
12915   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
12916 
12917   ins_encode %{
12918     __ fmuld(as_FloatRegister($dst$$reg),
12919              as_FloatRegister($src1$$reg),
12920              as_FloatRegister($src2$$reg));
12921   %}
12922 
12923   ins_pipe(fp_dop_reg_reg_d);
12924 %}
12925 
12926 // src1 * src2 + src3
12927 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12928   predicate(UseFMA);
12929   match(Set dst (FmaF src3 (Binary src1 src2)));
12930 
12931   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
12932 
12933   ins_encode %{
12934     __ fmadds(as_FloatRegister($dst$$reg),
12935              as_FloatRegister($src1$$reg),
12936              as_FloatRegister($src2$$reg),
12937              as_FloatRegister($src3$$reg));
12938   %}
12939 
12940   ins_pipe(pipe_class_default);
12941 %}
12942 
12943 // src1 * src2 + src3
12944 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12945   predicate(UseFMA);
12946   match(Set dst (FmaD src3 (Binary src1 src2)));
12947 
12948   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
12949 
12950   ins_encode %{
12951     __ fmaddd(as_FloatRegister($dst$$reg),
12952              as_FloatRegister($src1$$reg),
12953              as_FloatRegister($src2$$reg),
12954              as_FloatRegister($src3$$reg));
12955   %}
12956 
12957   ins_pipe(pipe_class_default);
12958 %}
12959 
12960 // -src1 * src2 + src3
12961 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12962   predicate(UseFMA);
12963   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
12964   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
12965 
12966   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
12967 
12968   ins_encode %{
12969     __ fmsubs(as_FloatRegister($dst$$reg),
12970               as_FloatRegister($src1$$reg),
12971               as_FloatRegister($src2$$reg),
12972               as_FloatRegister($src3$$reg));
12973   %}
12974 
12975   ins_pipe(pipe_class_default);
12976 %}
12977 
12978 // -src1 * src2 + src3
12979 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12980   predicate(UseFMA);
12981   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
12982   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
12983 
12984   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
12985 
12986   ins_encode %{
12987     __ fmsubd(as_FloatRegister($dst$$reg),
12988               as_FloatRegister($src1$$reg),
12989               as_FloatRegister($src2$$reg),
12990               as_FloatRegister($src3$$reg));
12991   %}
12992 
12993   ins_pipe(pipe_class_default);
12994 %}
12995 
12996 // -src1 * src2 - src3
12997 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12998   predicate(UseFMA);
12999   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
13000   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
13001 
13002   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
13003 
13004   ins_encode %{
13005     __ fnmadds(as_FloatRegister($dst$$reg),
13006                as_FloatRegister($src1$$reg),
13007                as_FloatRegister($src2$$reg),
13008                as_FloatRegister($src3$$reg));
13009   %}
13010 
13011   ins_pipe(pipe_class_default);
13012 %}
13013 
13014 // -src1 * src2 - src3
13015 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13016   predicate(UseFMA);
13017   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13018   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13019 
13020   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13021 
13022   ins_encode %{
13023     __ fnmaddd(as_FloatRegister($dst$$reg),
13024                as_FloatRegister($src1$$reg),
13025                as_FloatRegister($src2$$reg),
13026                as_FloatRegister($src3$$reg));
13027   %}
13028 
13029   ins_pipe(pipe_class_default);
13030 %}
13031 
13032 // src1 * src2 - src3
13033 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13034   predicate(UseFMA);
13035   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13036 
13037   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13038 
13039   ins_encode %{
13040     __ fnmsubs(as_FloatRegister($dst$$reg),
13041                as_FloatRegister($src1$$reg),
13042                as_FloatRegister($src2$$reg),
13043                as_FloatRegister($src3$$reg));
13044   %}
13045 
13046   ins_pipe(pipe_class_default);
13047 %}
13048 
13049 // src1 * src2 - src3
13050 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13051   predicate(UseFMA);
13052   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13053 
13054   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13055 
13056   ins_encode %{
13057   // n.b. insn name should be fnmsubd
13058     __ fnmsub(as_FloatRegister($dst$$reg),
13059               as_FloatRegister($src1$$reg),
13060               as_FloatRegister($src2$$reg),
13061               as_FloatRegister($src3$$reg));
13062   %}
13063 
13064   ins_pipe(pipe_class_default);
13065 %}
13066 
13067 
13068 // Math.max(FF)F
13069 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13070   match(Set dst (MaxF src1 src2));
13071 
13072   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13073   ins_encode %{
13074     __ fmaxs(as_FloatRegister($dst$$reg),
13075              as_FloatRegister($src1$$reg),
13076              as_FloatRegister($src2$$reg));
13077   %}
13078 
13079   ins_pipe(fp_dop_reg_reg_s);
13080 %}
13081 
13082 // Math.min(FF)F
13083 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13084   match(Set dst (MinF src1 src2));
13085 
13086   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13087   ins_encode %{
13088     __ fmins(as_FloatRegister($dst$$reg),
13089              as_FloatRegister($src1$$reg),
13090              as_FloatRegister($src2$$reg));
13091   %}
13092 
13093   ins_pipe(fp_dop_reg_reg_s);
13094 %}
13095 
13096 // Math.max(DD)D
13097 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13098   match(Set dst (MaxD src1 src2));
13099 
13100   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13101   ins_encode %{
13102     __ fmaxd(as_FloatRegister($dst$$reg),
13103              as_FloatRegister($src1$$reg),
13104              as_FloatRegister($src2$$reg));
13105   %}
13106 
13107   ins_pipe(fp_dop_reg_reg_d);
13108 %}
13109 
13110 // Math.min(DD)D
13111 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13112   match(Set dst (MinD src1 src2));
13113 
13114   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13115   ins_encode %{
13116     __ fmind(as_FloatRegister($dst$$reg),
13117              as_FloatRegister($src1$$reg),
13118              as_FloatRegister($src2$$reg));
13119   %}
13120 
13121   ins_pipe(fp_dop_reg_reg_d);
13122 %}
13123 
13124 
13125 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13126   match(Set dst (DivF src1  src2));
13127 
13128   ins_cost(INSN_COST * 18);
13129   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13130 
13131   ins_encode %{
13132     __ fdivs(as_FloatRegister($dst$$reg),
13133              as_FloatRegister($src1$$reg),
13134              as_FloatRegister($src2$$reg));
13135   %}
13136 
13137   ins_pipe(fp_div_s);
13138 %}
13139 
13140 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13141   match(Set dst (DivD src1  src2));
13142 
13143   ins_cost(INSN_COST * 32);
13144   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13145 
13146   ins_encode %{
13147     __ fdivd(as_FloatRegister($dst$$reg),
13148              as_FloatRegister($src1$$reg),
13149              as_FloatRegister($src2$$reg));
13150   %}
13151 
13152   ins_pipe(fp_div_d);
13153 %}
13154 
13155 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13156   match(Set dst (NegF src));
13157 
13158   ins_cost(INSN_COST * 3);
13159   format %{ &quot;fneg   $dst, $src&quot; %}
13160 
13161   ins_encode %{
13162     __ fnegs(as_FloatRegister($dst$$reg),
13163              as_FloatRegister($src$$reg));
13164   %}
13165 
13166   ins_pipe(fp_uop_s);
13167 %}
13168 
13169 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13170   match(Set dst (NegD src));
13171 
13172   ins_cost(INSN_COST * 3);
13173   format %{ &quot;fnegd   $dst, $src&quot; %}
13174 
13175   ins_encode %{
13176     __ fnegd(as_FloatRegister($dst$$reg),
13177              as_FloatRegister($src$$reg));
13178   %}
13179 
13180   ins_pipe(fp_uop_d);
13181 %}
13182 
13183 instruct absF_reg(vRegF dst, vRegF src) %{
13184   match(Set dst (AbsF src));
13185 
13186   ins_cost(INSN_COST * 3);
13187   format %{ &quot;fabss   $dst, $src&quot; %}
13188   ins_encode %{
13189     __ fabss(as_FloatRegister($dst$$reg),
13190              as_FloatRegister($src$$reg));
13191   %}
13192 
13193   ins_pipe(fp_uop_s);
13194 %}
13195 
13196 instruct absD_reg(vRegD dst, vRegD src) %{
13197   match(Set dst (AbsD src));
13198 
13199   ins_cost(INSN_COST * 3);
13200   format %{ &quot;fabsd   $dst, $src&quot; %}
13201   ins_encode %{
13202     __ fabsd(as_FloatRegister($dst$$reg),
13203              as_FloatRegister($src$$reg));
13204   %}
13205 
13206   ins_pipe(fp_uop_d);
13207 %}
13208 
13209 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13210   match(Set dst (SqrtD src));
13211 
13212   ins_cost(INSN_COST * 50);
13213   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13214   ins_encode %{
13215     __ fsqrtd(as_FloatRegister($dst$$reg),
13216              as_FloatRegister($src$$reg));
13217   %}
13218 
13219   ins_pipe(fp_div_s);
13220 %}
13221 
13222 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13223   match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
13224 
13225   ins_cost(INSN_COST * 50);
13226   format %{ &quot;fsqrts  $dst, $src&quot; %}
13227   ins_encode %{
13228     __ fsqrts(as_FloatRegister($dst$$reg),
13229              as_FloatRegister($src$$reg));
13230   %}
13231 
13232   ins_pipe(fp_div_d);
13233 %}
13234 
13235 // Math.rint, floor, ceil
13236 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13237   match(Set dst (RoundDoubleMode src rmode));
13238   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13239   ins_encode %{
13240     switch ($rmode$$constant) {
13241       case RoundDoubleModeNode::rmode_rint:
13242         __ frintnd(as_FloatRegister($dst$$reg),
13243                    as_FloatRegister($src$$reg));
13244         break;
13245       case RoundDoubleModeNode::rmode_floor:
13246         __ frintmd(as_FloatRegister($dst$$reg),
13247                    as_FloatRegister($src$$reg));
13248         break;
13249       case RoundDoubleModeNode::rmode_ceil:
13250         __ frintpd(as_FloatRegister($dst$$reg),
13251                    as_FloatRegister($src$$reg));
13252         break;
13253     }
13254   %}
13255   ins_pipe(fp_uop_d);
13256 %}
13257 
13258 // ============================================================================
13259 // Logical Instructions
13260 
13261 // Integer Logical Instructions
13262 
13263 // And Instructions
13264 
13265 
13266 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13267   match(Set dst (AndI src1 src2));
13268 
13269   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13270 
13271   ins_cost(INSN_COST);
13272   ins_encode %{
13273     __ andw(as_Register($dst$$reg),
13274             as_Register($src1$$reg),
13275             as_Register($src2$$reg));
13276   %}
13277 
13278   ins_pipe(ialu_reg_reg);
13279 %}
13280 
13281 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13282   match(Set dst (AndI src1 src2));
13283 
13284   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13285 
13286   ins_cost(INSN_COST);
13287   ins_encode %{
13288     __ andw(as_Register($dst$$reg),
13289             as_Register($src1$$reg),
13290             (unsigned long)($src2$$constant));
13291   %}
13292 
13293   ins_pipe(ialu_reg_imm);
13294 %}
13295 
13296 // Or Instructions
13297 
13298 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13299   match(Set dst (OrI src1 src2));
13300 
13301   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13302 
13303   ins_cost(INSN_COST);
13304   ins_encode %{
13305     __ orrw(as_Register($dst$$reg),
13306             as_Register($src1$$reg),
13307             as_Register($src2$$reg));
13308   %}
13309 
13310   ins_pipe(ialu_reg_reg);
13311 %}
13312 
13313 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13314   match(Set dst (OrI src1 src2));
13315 
13316   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13317 
13318   ins_cost(INSN_COST);
13319   ins_encode %{
13320     __ orrw(as_Register($dst$$reg),
13321             as_Register($src1$$reg),
13322             (unsigned long)($src2$$constant));
13323   %}
13324 
13325   ins_pipe(ialu_reg_imm);
13326 %}
13327 
13328 // Xor Instructions
13329 
13330 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13331   match(Set dst (XorI src1 src2));
13332 
13333   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13334 
13335   ins_cost(INSN_COST);
13336   ins_encode %{
13337     __ eorw(as_Register($dst$$reg),
13338             as_Register($src1$$reg),
13339             as_Register($src2$$reg));
13340   %}
13341 
13342   ins_pipe(ialu_reg_reg);
13343 %}
13344 
13345 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13346   match(Set dst (XorI src1 src2));
13347 
13348   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13349 
13350   ins_cost(INSN_COST);
13351   ins_encode %{
13352     __ eorw(as_Register($dst$$reg),
13353             as_Register($src1$$reg),
13354             (unsigned long)($src2$$constant));
13355   %}
13356 
13357   ins_pipe(ialu_reg_imm);
13358 %}
13359 
13360 // Long Logical Instructions
13361 // TODO
13362 
13363 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13364   match(Set dst (AndL src1 src2));
13365 
13366   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13367 
13368   ins_cost(INSN_COST);
13369   ins_encode %{
13370     __ andr(as_Register($dst$$reg),
13371             as_Register($src1$$reg),
13372             as_Register($src2$$reg));
13373   %}
13374 
13375   ins_pipe(ialu_reg_reg);
13376 %}
13377 
13378 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13379   match(Set dst (AndL src1 src2));
13380 
13381   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13382 
13383   ins_cost(INSN_COST);
13384   ins_encode %{
13385     __ andr(as_Register($dst$$reg),
13386             as_Register($src1$$reg),
13387             (unsigned long)($src2$$constant));
13388   %}
13389 
13390   ins_pipe(ialu_reg_imm);
13391 %}
13392 
13393 // Or Instructions
13394 
13395 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13396   match(Set dst (OrL src1 src2));
13397 
13398   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13399 
13400   ins_cost(INSN_COST);
13401   ins_encode %{
13402     __ orr(as_Register($dst$$reg),
13403            as_Register($src1$$reg),
13404            as_Register($src2$$reg));
13405   %}
13406 
13407   ins_pipe(ialu_reg_reg);
13408 %}
13409 
13410 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13411   match(Set dst (OrL src1 src2));
13412 
13413   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13414 
13415   ins_cost(INSN_COST);
13416   ins_encode %{
13417     __ orr(as_Register($dst$$reg),
13418            as_Register($src1$$reg),
13419            (unsigned long)($src2$$constant));
13420   %}
13421 
13422   ins_pipe(ialu_reg_imm);
13423 %}
13424 
13425 // Xor Instructions
13426 
13427 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13428   match(Set dst (XorL src1 src2));
13429 
13430   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13431 
13432   ins_cost(INSN_COST);
13433   ins_encode %{
13434     __ eor(as_Register($dst$$reg),
13435            as_Register($src1$$reg),
13436            as_Register($src2$$reg));
13437   %}
13438 
13439   ins_pipe(ialu_reg_reg);
13440 %}
13441 
13442 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13443   match(Set dst (XorL src1 src2));
13444 
13445   ins_cost(INSN_COST);
13446   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13447 
13448   ins_encode %{
13449     __ eor(as_Register($dst$$reg),
13450            as_Register($src1$$reg),
13451            (unsigned long)($src2$$constant));
13452   %}
13453 
13454   ins_pipe(ialu_reg_imm);
13455 %}
13456 
13457 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13458 %{
13459   match(Set dst (ConvI2L src));
13460 
13461   ins_cost(INSN_COST);
13462   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13463   ins_encode %{
13464     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13465   %}
13466   ins_pipe(ialu_reg_shift);
13467 %}
13468 
13469 // this pattern occurs in bigmath arithmetic
13470 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13471 %{
13472   match(Set dst (AndL (ConvI2L src) mask));
13473 
13474   ins_cost(INSN_COST);
13475   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13476   ins_encode %{
13477     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13478   %}
13479 
13480   ins_pipe(ialu_reg_shift);
13481 %}
13482 
13483 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13484   match(Set dst (ConvL2I src));
13485 
13486   ins_cost(INSN_COST);
13487   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13488 
13489   ins_encode %{
13490     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13491   %}
13492 
13493   ins_pipe(ialu_reg);
13494 %}
13495 
13496 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13497 %{
13498   match(Set dst (Conv2B src));
13499   effect(KILL cr);
13500 
13501   format %{
13502     &quot;cmpw $src, zr\n\t&quot;
13503     &quot;cset $dst, ne&quot;
13504   %}
13505 
13506   ins_encode %{
13507     __ cmpw(as_Register($src$$reg), zr);
13508     __ cset(as_Register($dst$$reg), Assembler::NE);
13509   %}
13510 
13511   ins_pipe(ialu_reg);
13512 %}
13513 
13514 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13515 %{
13516   match(Set dst (Conv2B src));
13517   effect(KILL cr);
13518 
13519   format %{
13520     &quot;cmp  $src, zr\n\t&quot;
13521     &quot;cset $dst, ne&quot;
13522   %}
13523 
13524   ins_encode %{
13525     __ cmp(as_Register($src$$reg), zr);
13526     __ cset(as_Register($dst$$reg), Assembler::NE);
13527   %}
13528 
13529   ins_pipe(ialu_reg);
13530 %}
13531 
13532 instruct convD2F_reg(vRegF dst, vRegD src) %{
13533   match(Set dst (ConvD2F src));
13534 
13535   ins_cost(INSN_COST * 5);
13536   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13537 
13538   ins_encode %{
13539     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13540   %}
13541 
13542   ins_pipe(fp_d2f);
13543 %}
13544 
13545 instruct convF2D_reg(vRegD dst, vRegF src) %{
13546   match(Set dst (ConvF2D src));
13547 
13548   ins_cost(INSN_COST * 5);
13549   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13550 
13551   ins_encode %{
13552     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13553   %}
13554 
13555   ins_pipe(fp_f2d);
13556 %}
13557 
13558 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13559   match(Set dst (ConvF2I src));
13560 
13561   ins_cost(INSN_COST * 5);
13562   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13563 
13564   ins_encode %{
13565     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13566   %}
13567 
13568   ins_pipe(fp_f2i);
13569 %}
13570 
13571 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13572   match(Set dst (ConvF2L src));
13573 
13574   ins_cost(INSN_COST * 5);
13575   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13576 
13577   ins_encode %{
13578     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13579   %}
13580 
13581   ins_pipe(fp_f2l);
13582 %}
13583 
13584 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13585   match(Set dst (ConvI2F src));
13586 
13587   ins_cost(INSN_COST * 5);
13588   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13589 
13590   ins_encode %{
13591     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13592   %}
13593 
13594   ins_pipe(fp_i2f);
13595 %}
13596 
13597 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13598   match(Set dst (ConvL2F src));
13599 
13600   ins_cost(INSN_COST * 5);
13601   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13602 
13603   ins_encode %{
13604     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13605   %}
13606 
13607   ins_pipe(fp_l2f);
13608 %}
13609 
13610 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13611   match(Set dst (ConvD2I src));
13612 
13613   ins_cost(INSN_COST * 5);
13614   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13615 
13616   ins_encode %{
13617     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13618   %}
13619 
13620   ins_pipe(fp_d2i);
13621 %}
13622 
13623 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13624   match(Set dst (ConvD2L src));
13625 
13626   ins_cost(INSN_COST * 5);
13627   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13628 
13629   ins_encode %{
13630     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13631   %}
13632 
13633   ins_pipe(fp_d2l);
13634 %}
13635 
13636 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13637   match(Set dst (ConvI2D src));
13638 
13639   ins_cost(INSN_COST * 5);
13640   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13641 
13642   ins_encode %{
13643     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13644   %}
13645 
13646   ins_pipe(fp_i2d);
13647 %}
13648 
13649 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13650   match(Set dst (ConvL2D src));
13651 
13652   ins_cost(INSN_COST * 5);
13653   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13654 
13655   ins_encode %{
13656     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13657   %}
13658 
13659   ins_pipe(fp_l2d);
13660 %}
13661 
13662 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13663 
13664 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13665 
13666   match(Set dst (MoveF2I src));
13667 
13668   effect(DEF dst, USE src);
13669 
13670   ins_cost(4 * INSN_COST);
13671 
13672   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13673 
13674   ins_encode %{
13675     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13676   %}
13677 
13678   ins_pipe(iload_reg_reg);
13679 
13680 %}
13681 
13682 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13683 
13684   match(Set dst (MoveI2F src));
13685 
13686   effect(DEF dst, USE src);
13687 
13688   ins_cost(4 * INSN_COST);
13689 
13690   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13691 
13692   ins_encode %{
13693     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13694   %}
13695 
13696   ins_pipe(pipe_class_memory);
13697 
13698 %}
13699 
13700 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13701 
13702   match(Set dst (MoveD2L src));
13703 
13704   effect(DEF dst, USE src);
13705 
13706   ins_cost(4 * INSN_COST);
13707 
13708   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13709 
13710   ins_encode %{
13711     __ ldr($dst$$Register, Address(sp, $src$$disp));
13712   %}
13713 
13714   ins_pipe(iload_reg_reg);
13715 
13716 %}
13717 
13718 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13719 
13720   match(Set dst (MoveL2D src));
13721 
13722   effect(DEF dst, USE src);
13723 
13724   ins_cost(4 * INSN_COST);
13725 
13726   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13727 
13728   ins_encode %{
13729     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13730   %}
13731 
13732   ins_pipe(pipe_class_memory);
13733 
13734 %}
13735 
13736 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13737 
13738   match(Set dst (MoveF2I src));
13739 
13740   effect(DEF dst, USE src);
13741 
13742   ins_cost(INSN_COST);
13743 
13744   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13745 
13746   ins_encode %{
13747     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13748   %}
13749 
13750   ins_pipe(pipe_class_memory);
13751 
13752 %}
13753 
13754 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13755 
13756   match(Set dst (MoveI2F src));
13757 
13758   effect(DEF dst, USE src);
13759 
13760   ins_cost(INSN_COST);
13761 
13762   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13763 
13764   ins_encode %{
13765     __ strw($src$$Register, Address(sp, $dst$$disp));
13766   %}
13767 
13768   ins_pipe(istore_reg_reg);
13769 
13770 %}
13771 
13772 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13773 
13774   match(Set dst (MoveD2L src));
13775 
13776   effect(DEF dst, USE src);
13777 
13778   ins_cost(INSN_COST);
13779 
13780   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13781 
13782   ins_encode %{
13783     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13784   %}
13785 
13786   ins_pipe(pipe_class_memory);
13787 
13788 %}
13789 
13790 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13791 
13792   match(Set dst (MoveL2D src));
13793 
13794   effect(DEF dst, USE src);
13795 
13796   ins_cost(INSN_COST);
13797 
13798   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13799 
13800   ins_encode %{
13801     __ str($src$$Register, Address(sp, $dst$$disp));
13802   %}
13803 
13804   ins_pipe(istore_reg_reg);
13805 
13806 %}
13807 
13808 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13809 
13810   match(Set dst (MoveF2I src));
13811 
13812   effect(DEF dst, USE src);
13813 
13814   ins_cost(INSN_COST);
13815 
13816   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13817 
13818   ins_encode %{
13819     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13820   %}
13821 
13822   ins_pipe(fp_f2i);
13823 
13824 %}
13825 
13826 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13827 
13828   match(Set dst (MoveI2F src));
13829 
13830   effect(DEF dst, USE src);
13831 
13832   ins_cost(INSN_COST);
13833 
13834   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13835 
13836   ins_encode %{
13837     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13838   %}
13839 
13840   ins_pipe(fp_i2f);
13841 
13842 %}
13843 
13844 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13845 
13846   match(Set dst (MoveD2L src));
13847 
13848   effect(DEF dst, USE src);
13849 
13850   ins_cost(INSN_COST);
13851 
13852   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13853 
13854   ins_encode %{
13855     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13856   %}
13857 
13858   ins_pipe(fp_d2l);
13859 
13860 %}
13861 
13862 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13863 
13864   match(Set dst (MoveL2D src));
13865 
13866   effect(DEF dst, USE src);
13867 
13868   ins_cost(INSN_COST);
13869 
13870   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13871 
13872   ins_encode %{
13873     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13874   %}
13875 
13876   ins_pipe(fp_l2d);
13877 
13878 %}
13879 
13880 // ============================================================================
13881 // clearing of an array
13882 
13883 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
13884 %{
13885   match(Set dummy (ClearArray cnt base));
13886   effect(USE_KILL cnt, USE_KILL base);
13887 
13888   ins_cost(4 * INSN_COST);
13889   format %{ &quot;ClearArray $cnt, $base&quot; %}
13890 
13891   ins_encode %{
13892     __ zero_words($base$$Register, $cnt$$Register);
13893   %}
13894 
13895   ins_pipe(pipe_class_memory);
13896 %}
13897 
13898 instruct clearArray_imm_reg(immL cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
13899 %{
13900   predicate((u_int64_t)n-&gt;in(2)-&gt;get_long()
13901             &lt; (u_int64_t)(BlockZeroingLowLimit &gt;&gt; LogBytesPerWord));
13902   match(Set dummy (ClearArray cnt base));
13903   effect(USE_KILL base);
13904 
13905   ins_cost(4 * INSN_COST);
13906   format %{ &quot;ClearArray $cnt, $base&quot; %}
13907 
13908   ins_encode %{
13909     __ zero_words($base$$Register, (u_int64_t)$cnt$$constant);
13910   %}
13911 
13912   ins_pipe(pipe_class_memory);
13913 %}
13914 
13915 // ============================================================================
13916 // Overflow Math Instructions
13917 
13918 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13919 %{
13920   match(Set cr (OverflowAddI op1 op2));
13921 
13922   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13923   ins_cost(INSN_COST);
13924   ins_encode %{
13925     __ cmnw($op1$$Register, $op2$$Register);
13926   %}
13927 
13928   ins_pipe(icmp_reg_reg);
13929 %}
13930 
13931 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13932 %{
13933   match(Set cr (OverflowAddI op1 op2));
13934 
13935   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13936   ins_cost(INSN_COST);
13937   ins_encode %{
13938     __ cmnw($op1$$Register, $op2$$constant);
13939   %}
13940 
13941   ins_pipe(icmp_reg_imm);
13942 %}
13943 
13944 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13945 %{
13946   match(Set cr (OverflowAddL op1 op2));
13947 
13948   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13949   ins_cost(INSN_COST);
13950   ins_encode %{
13951     __ cmn($op1$$Register, $op2$$Register);
13952   %}
13953 
13954   ins_pipe(icmp_reg_reg);
13955 %}
13956 
13957 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13958 %{
13959   match(Set cr (OverflowAddL op1 op2));
13960 
13961   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13962   ins_cost(INSN_COST);
13963   ins_encode %{
13964     __ cmn($op1$$Register, $op2$$constant);
13965   %}
13966 
13967   ins_pipe(icmp_reg_imm);
13968 %}
13969 
13970 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13971 %{
13972   match(Set cr (OverflowSubI op1 op2));
13973 
13974   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13975   ins_cost(INSN_COST);
13976   ins_encode %{
13977     __ cmpw($op1$$Register, $op2$$Register);
13978   %}
13979 
13980   ins_pipe(icmp_reg_reg);
13981 %}
13982 
13983 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13984 %{
13985   match(Set cr (OverflowSubI op1 op2));
13986 
13987   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13988   ins_cost(INSN_COST);
13989   ins_encode %{
13990     __ cmpw($op1$$Register, $op2$$constant);
13991   %}
13992 
13993   ins_pipe(icmp_reg_imm);
13994 %}
13995 
13996 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13997 %{
13998   match(Set cr (OverflowSubL op1 op2));
13999 
14000   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14001   ins_cost(INSN_COST);
14002   ins_encode %{
14003     __ cmp($op1$$Register, $op2$$Register);
14004   %}
14005 
14006   ins_pipe(icmp_reg_reg);
14007 %}
14008 
14009 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14010 %{
14011   match(Set cr (OverflowSubL op1 op2));
14012 
14013   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14014   ins_cost(INSN_COST);
14015   ins_encode %{
14016     __ subs(zr, $op1$$Register, $op2$$constant);
14017   %}
14018 
14019   ins_pipe(icmp_reg_imm);
14020 %}
14021 
14022 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14023 %{
14024   match(Set cr (OverflowSubI zero op1));
14025 
14026   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14027   ins_cost(INSN_COST);
14028   ins_encode %{
14029     __ cmpw(zr, $op1$$Register);
14030   %}
14031 
14032   ins_pipe(icmp_reg_imm);
14033 %}
14034 
14035 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14036 %{
14037   match(Set cr (OverflowSubL zero op1));
14038 
14039   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14040   ins_cost(INSN_COST);
14041   ins_encode %{
14042     __ cmp(zr, $op1$$Register);
14043   %}
14044 
14045   ins_pipe(icmp_reg_imm);
14046 %}
14047 
14048 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14049 %{
14050   match(Set cr (OverflowMulI op1 op2));
14051 
14052   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14053             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14054             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14055             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14056             &quot;cmpw  rscratch1, #1&quot; %}
14057   ins_cost(5 * INSN_COST);
14058   ins_encode %{
14059     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14060     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14061     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14062     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14063     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14064   %}
14065 
14066   ins_pipe(pipe_slow);
14067 %}
14068 
14069 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14070 %{
14071   match(If cmp (OverflowMulI op1 op2));
14072   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14073             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14074   effect(USE labl, KILL cr);
14075 
14076   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14077             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14078             &quot;b$cmp   $labl&quot; %}
14079   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14080   ins_encode %{
14081     Label* L = $labl$$label;
14082     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14083     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14084     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14085     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14086   %}
14087 
14088   ins_pipe(pipe_serial);
14089 %}
14090 
14091 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14092 %{
14093   match(Set cr (OverflowMulL op1 op2));
14094 
14095   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14096             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14097             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14098             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14099             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14100             &quot;cmpw  rscratch1, #1&quot; %}
14101   ins_cost(6 * INSN_COST);
14102   ins_encode %{
14103     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14104     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14105     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14106     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14107     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14108     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14109   %}
14110 
14111   ins_pipe(pipe_slow);
14112 %}
14113 
14114 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14115 %{
14116   match(If cmp (OverflowMulL op1 op2));
14117   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14118             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14119   effect(USE labl, KILL cr);
14120 
14121   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14122             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14123             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14124             &quot;b$cmp $labl&quot; %}
14125   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14126   ins_encode %{
14127     Label* L = $labl$$label;
14128     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14129     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14130     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14131     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14132     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14133   %}
14134 
14135   ins_pipe(pipe_serial);
14136 %}
14137 
14138 // ============================================================================
14139 // Compare Instructions
14140 
14141 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14142 %{
14143   match(Set cr (CmpI op1 op2));
14144 
14145   effect(DEF cr, USE op1, USE op2);
14146 
14147   ins_cost(INSN_COST);
14148   format %{ &quot;cmpw  $op1, $op2&quot; %}
14149 
14150   ins_encode(aarch64_enc_cmpw(op1, op2));
14151 
14152   ins_pipe(icmp_reg_reg);
14153 %}
14154 
14155 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14156 %{
14157   match(Set cr (CmpI op1 zero));
14158 
14159   effect(DEF cr, USE op1);
14160 
14161   ins_cost(INSN_COST);
14162   format %{ &quot;cmpw $op1, 0&quot; %}
14163 
14164   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14165 
14166   ins_pipe(icmp_reg_imm);
14167 %}
14168 
14169 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14170 %{
14171   match(Set cr (CmpI op1 op2));
14172 
14173   effect(DEF cr, USE op1);
14174 
14175   ins_cost(INSN_COST);
14176   format %{ &quot;cmpw  $op1, $op2&quot; %}
14177 
14178   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14179 
14180   ins_pipe(icmp_reg_imm);
14181 %}
14182 
14183 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14184 %{
14185   match(Set cr (CmpI op1 op2));
14186 
14187   effect(DEF cr, USE op1);
14188 
14189   ins_cost(INSN_COST * 2);
14190   format %{ &quot;cmpw  $op1, $op2&quot; %}
14191 
14192   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14193 
14194   ins_pipe(icmp_reg_imm);
14195 %}
14196 
14197 // Unsigned compare Instructions; really, same as signed compare
14198 // except it should only be used to feed an If or a CMovI which takes a
14199 // cmpOpU.
14200 
14201 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14202 %{
14203   match(Set cr (CmpU op1 op2));
14204 
14205   effect(DEF cr, USE op1, USE op2);
14206 
14207   ins_cost(INSN_COST);
14208   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14209 
14210   ins_encode(aarch64_enc_cmpw(op1, op2));
14211 
14212   ins_pipe(icmp_reg_reg);
14213 %}
14214 
14215 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14216 %{
14217   match(Set cr (CmpU op1 zero));
14218 
14219   effect(DEF cr, USE op1);
14220 
14221   ins_cost(INSN_COST);
14222   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14223 
14224   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14225 
14226   ins_pipe(icmp_reg_imm);
14227 %}
14228 
14229 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14230 %{
14231   match(Set cr (CmpU op1 op2));
14232 
14233   effect(DEF cr, USE op1);
14234 
14235   ins_cost(INSN_COST);
14236   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14237 
14238   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14239 
14240   ins_pipe(icmp_reg_imm);
14241 %}
14242 
14243 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14244 %{
14245   match(Set cr (CmpU op1 op2));
14246 
14247   effect(DEF cr, USE op1);
14248 
14249   ins_cost(INSN_COST * 2);
14250   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14251 
14252   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14253 
14254   ins_pipe(icmp_reg_imm);
14255 %}
14256 
14257 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14258 %{
14259   match(Set cr (CmpL op1 op2));
14260 
14261   effect(DEF cr, USE op1, USE op2);
14262 
14263   ins_cost(INSN_COST);
14264   format %{ &quot;cmp  $op1, $op2&quot; %}
14265 
14266   ins_encode(aarch64_enc_cmp(op1, op2));
14267 
14268   ins_pipe(icmp_reg_reg);
14269 %}
14270 
14271 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14272 %{
14273   match(Set cr (CmpL op1 zero));
14274 
14275   effect(DEF cr, USE op1);
14276 
14277   ins_cost(INSN_COST);
14278   format %{ &quot;tst  $op1&quot; %}
14279 
14280   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14281 
14282   ins_pipe(icmp_reg_imm);
14283 %}
14284 
14285 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14286 %{
14287   match(Set cr (CmpL op1 op2));
14288 
14289   effect(DEF cr, USE op1);
14290 
14291   ins_cost(INSN_COST);
14292   format %{ &quot;cmp  $op1, $op2&quot; %}
14293 
14294   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14295 
14296   ins_pipe(icmp_reg_imm);
14297 %}
14298 
14299 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14300 %{
14301   match(Set cr (CmpL op1 op2));
14302 
14303   effect(DEF cr, USE op1);
14304 
14305   ins_cost(INSN_COST * 2);
14306   format %{ &quot;cmp  $op1, $op2&quot; %}
14307 
14308   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14309 
14310   ins_pipe(icmp_reg_imm);
14311 %}
14312 
14313 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14314 %{
14315   match(Set cr (CmpUL op1 op2));
14316 
14317   effect(DEF cr, USE op1, USE op2);
14318 
14319   ins_cost(INSN_COST);
14320   format %{ &quot;cmp  $op1, $op2&quot; %}
14321 
14322   ins_encode(aarch64_enc_cmp(op1, op2));
14323 
14324   ins_pipe(icmp_reg_reg);
14325 %}
14326 
14327 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14328 %{
14329   match(Set cr (CmpUL op1 zero));
14330 
14331   effect(DEF cr, USE op1);
14332 
14333   ins_cost(INSN_COST);
14334   format %{ &quot;tst  $op1&quot; %}
14335 
14336   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14337 
14338   ins_pipe(icmp_reg_imm);
14339 %}
14340 
14341 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14342 %{
14343   match(Set cr (CmpUL op1 op2));
14344 
14345   effect(DEF cr, USE op1);
14346 
14347   ins_cost(INSN_COST);
14348   format %{ &quot;cmp  $op1, $op2&quot; %}
14349 
14350   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14351 
14352   ins_pipe(icmp_reg_imm);
14353 %}
14354 
14355 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14356 %{
14357   match(Set cr (CmpUL op1 op2));
14358 
14359   effect(DEF cr, USE op1);
14360 
14361   ins_cost(INSN_COST * 2);
14362   format %{ &quot;cmp  $op1, $op2&quot; %}
14363 
14364   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14365 
14366   ins_pipe(icmp_reg_imm);
14367 %}
14368 
14369 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14370 %{
14371   match(Set cr (CmpP op1 op2));
14372 
14373   effect(DEF cr, USE op1, USE op2);
14374 
14375   ins_cost(INSN_COST);
14376   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14377 
14378   ins_encode(aarch64_enc_cmpp(op1, op2));
14379 
14380   ins_pipe(icmp_reg_reg);
14381 %}
14382 
14383 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14384 %{
14385   match(Set cr (CmpN op1 op2));
14386 
14387   effect(DEF cr, USE op1, USE op2);
14388 
14389   ins_cost(INSN_COST);
14390   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14391 
14392   ins_encode(aarch64_enc_cmpn(op1, op2));
14393 
14394   ins_pipe(icmp_reg_reg);
14395 %}
14396 
14397 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14398 %{
14399   match(Set cr (CmpP op1 zero));
14400 
14401   effect(DEF cr, USE op1, USE zero);
14402 
14403   ins_cost(INSN_COST);
14404   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14405 
14406   ins_encode(aarch64_enc_testp(op1));
14407 
14408   ins_pipe(icmp_reg_imm);
14409 %}
14410 
14411 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14412 %{
14413   match(Set cr (CmpN op1 zero));
14414 
14415   effect(DEF cr, USE op1, USE zero);
14416 
14417   ins_cost(INSN_COST);
14418   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14419 
14420   ins_encode(aarch64_enc_testn(op1));
14421 
14422   ins_pipe(icmp_reg_imm);
14423 %}
14424 
14425 // FP comparisons
14426 //
14427 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14428 // using normal cmpOp. See declaration of rFlagsReg for details.
14429 
14430 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14431 %{
14432   match(Set cr (CmpF src1 src2));
14433 
14434   ins_cost(3 * INSN_COST);
14435   format %{ &quot;fcmps $src1, $src2&quot; %}
14436 
14437   ins_encode %{
14438     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14439   %}
14440 
14441   ins_pipe(pipe_class_compare);
14442 %}
14443 
14444 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14445 %{
14446   match(Set cr (CmpF src1 src2));
14447 
14448   ins_cost(3 * INSN_COST);
14449   format %{ &quot;fcmps $src1, 0.0&quot; %}
14450 
14451   ins_encode %{
14452     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14453   %}
14454 
14455   ins_pipe(pipe_class_compare);
14456 %}
14457 // FROM HERE
14458 
14459 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14460 %{
14461   match(Set cr (CmpD src1 src2));
14462 
14463   ins_cost(3 * INSN_COST);
14464   format %{ &quot;fcmpd $src1, $src2&quot; %}
14465 
14466   ins_encode %{
14467     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14468   %}
14469 
14470   ins_pipe(pipe_class_compare);
14471 %}
14472 
14473 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14474 %{
14475   match(Set cr (CmpD src1 src2));
14476 
14477   ins_cost(3 * INSN_COST);
14478   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14479 
14480   ins_encode %{
14481     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14482   %}
14483 
14484   ins_pipe(pipe_class_compare);
14485 %}
14486 
14487 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14488 %{
14489   match(Set dst (CmpF3 src1 src2));
14490   effect(KILL cr);
14491 
14492   ins_cost(5 * INSN_COST);
14493   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14494             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14495             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14496   %}
14497 
14498   ins_encode %{
14499     Label done;
14500     FloatRegister s1 = as_FloatRegister($src1$$reg);
14501     FloatRegister s2 = as_FloatRegister($src2$$reg);
14502     Register d = as_Register($dst$$reg);
14503     __ fcmps(s1, s2);
14504     // installs 0 if EQ else -1
14505     __ csinvw(d, zr, zr, Assembler::EQ);
14506     // keeps -1 if less or unordered else installs 1
14507     __ csnegw(d, d, d, Assembler::LT);
14508     __ bind(done);
14509   %}
14510 
14511   ins_pipe(pipe_class_default);
14512 
14513 %}
14514 
14515 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14516 %{
14517   match(Set dst (CmpD3 src1 src2));
14518   effect(KILL cr);
14519 
14520   ins_cost(5 * INSN_COST);
14521   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14522             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14523             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14524   %}
14525 
14526   ins_encode %{
14527     Label done;
14528     FloatRegister s1 = as_FloatRegister($src1$$reg);
14529     FloatRegister s2 = as_FloatRegister($src2$$reg);
14530     Register d = as_Register($dst$$reg);
14531     __ fcmpd(s1, s2);
14532     // installs 0 if EQ else -1
14533     __ csinvw(d, zr, zr, Assembler::EQ);
14534     // keeps -1 if less or unordered else installs 1
14535     __ csnegw(d, d, d, Assembler::LT);
14536     __ bind(done);
14537   %}
14538   ins_pipe(pipe_class_default);
14539 
14540 %}
14541 
14542 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14543 %{
14544   match(Set dst (CmpF3 src1 zero));
14545   effect(KILL cr);
14546 
14547   ins_cost(5 * INSN_COST);
14548   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14549             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14550             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14551   %}
14552 
14553   ins_encode %{
14554     Label done;
14555     FloatRegister s1 = as_FloatRegister($src1$$reg);
14556     Register d = as_Register($dst$$reg);
14557     __ fcmps(s1, 0.0);
14558     // installs 0 if EQ else -1
14559     __ csinvw(d, zr, zr, Assembler::EQ);
14560     // keeps -1 if less or unordered else installs 1
14561     __ csnegw(d, d, d, Assembler::LT);
14562     __ bind(done);
14563   %}
14564 
14565   ins_pipe(pipe_class_default);
14566 
14567 %}
14568 
14569 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14570 %{
14571   match(Set dst (CmpD3 src1 zero));
14572   effect(KILL cr);
14573 
14574   ins_cost(5 * INSN_COST);
14575   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14576             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14577             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14578   %}
14579 
14580   ins_encode %{
14581     Label done;
14582     FloatRegister s1 = as_FloatRegister($src1$$reg);
14583     Register d = as_Register($dst$$reg);
14584     __ fcmpd(s1, 0.0);
14585     // installs 0 if EQ else -1
14586     __ csinvw(d, zr, zr, Assembler::EQ);
14587     // keeps -1 if less or unordered else installs 1
14588     __ csnegw(d, d, d, Assembler::LT);
14589     __ bind(done);
14590   %}
14591   ins_pipe(pipe_class_default);
14592 
14593 %}
14594 
14595 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14596 %{
14597   match(Set dst (CmpLTMask p q));
14598   effect(KILL cr);
14599 
14600   ins_cost(3 * INSN_COST);
14601 
14602   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14603             &quot;csetw $dst, lt\n\t&quot;
14604             &quot;subw $dst, zr, $dst&quot;
14605   %}
14606 
14607   ins_encode %{
14608     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14609     __ csetw(as_Register($dst$$reg), Assembler::LT);
14610     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14611   %}
14612 
14613   ins_pipe(ialu_reg_reg);
14614 %}
14615 
14616 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14617 %{
14618   match(Set dst (CmpLTMask src zero));
14619   effect(KILL cr);
14620 
14621   ins_cost(INSN_COST);
14622 
14623   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14624 
14625   ins_encode %{
14626     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14627   %}
14628 
14629   ins_pipe(ialu_reg_shift);
14630 %}
14631 
14632 // ============================================================================
14633 // Max and Min
14634 
14635 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14636 %{
14637   effect( DEF dst, USE src1, USE src2, USE cr );
14638 
14639   ins_cost(INSN_COST * 2);
14640   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14641 
14642   ins_encode %{
14643     __ cselw(as_Register($dst$$reg),
14644              as_Register($src1$$reg),
14645              as_Register($src2$$reg),
14646              Assembler::LT);
14647   %}
14648 
14649   ins_pipe(icond_reg_reg);
14650 %}
14651 
14652 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14653 %{
14654   match(Set dst (MinI src1 src2));
14655   ins_cost(INSN_COST * 3);
14656 
14657   expand %{
14658     rFlagsReg cr;
14659     compI_reg_reg(cr, src1, src2);
14660     cmovI_reg_reg_lt(dst, src1, src2, cr);
14661   %}
14662 
14663 %}
14664 // FROM HERE
14665 
14666 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14667 %{
14668   effect( DEF dst, USE src1, USE src2, USE cr );
14669 
14670   ins_cost(INSN_COST * 2);
14671   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14672 
14673   ins_encode %{
14674     __ cselw(as_Register($dst$$reg),
14675              as_Register($src1$$reg),
14676              as_Register($src2$$reg),
14677              Assembler::GT);
14678   %}
14679 
14680   ins_pipe(icond_reg_reg);
14681 %}
14682 
14683 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14684 %{
14685   match(Set dst (MaxI src1 src2));
14686   ins_cost(INSN_COST * 3);
14687   expand %{
14688     rFlagsReg cr;
14689     compI_reg_reg(cr, src1, src2);
14690     cmovI_reg_reg_gt(dst, src1, src2, cr);
14691   %}
14692 %}
14693 
14694 // ============================================================================
14695 // Branch Instructions
14696 
14697 // Direct Branch.
14698 instruct branch(label lbl)
14699 %{
14700   match(Goto);
14701 
14702   effect(USE lbl);
14703 
14704   ins_cost(BRANCH_COST);
14705   format %{ &quot;b  $lbl&quot; %}
14706 
14707   ins_encode(aarch64_enc_b(lbl));
14708 
14709   ins_pipe(pipe_branch);
14710 %}
14711 
14712 // Conditional Near Branch
14713 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14714 %{
14715   // Same match rule as `branchConFar&#39;.
14716   match(If cmp cr);
14717 
14718   effect(USE lbl);
14719 
14720   ins_cost(BRANCH_COST);
14721   // If set to 1 this indicates that the current instruction is a
14722   // short variant of a long branch. This avoids using this
14723   // instruction in first-pass matching. It will then only be used in
14724   // the `Shorten_branches&#39; pass.
14725   // ins_short_branch(1);
14726   format %{ &quot;b$cmp  $lbl&quot; %}
14727 
14728   ins_encode(aarch64_enc_br_con(cmp, lbl));
14729 
14730   ins_pipe(pipe_branch_cond);
14731 %}
14732 
14733 // Conditional Near Branch Unsigned
14734 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14735 %{
14736   // Same match rule as `branchConFar&#39;.
14737   match(If cmp cr);
14738 
14739   effect(USE lbl);
14740 
14741   ins_cost(BRANCH_COST);
14742   // If set to 1 this indicates that the current instruction is a
14743   // short variant of a long branch. This avoids using this
14744   // instruction in first-pass matching. It will then only be used in
14745   // the `Shorten_branches&#39; pass.
14746   // ins_short_branch(1);
14747   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14748 
14749   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14750 
14751   ins_pipe(pipe_branch_cond);
14752 %}
14753 
14754 // Make use of CBZ and CBNZ.  These instructions, as well as being
14755 // shorter than (cmp; branch), have the additional benefit of not
14756 // killing the flags.
14757 
14758 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14759   match(If cmp (CmpI op1 op2));
14760   effect(USE labl);
14761 
14762   ins_cost(BRANCH_COST);
14763   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14764   ins_encode %{
14765     Label* L = $labl$$label;
14766     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14767     if (cond == Assembler::EQ)
14768       __ cbzw($op1$$Register, *L);
14769     else
14770       __ cbnzw($op1$$Register, *L);
14771   %}
14772   ins_pipe(pipe_cmp_branch);
14773 %}
14774 
14775 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14776   match(If cmp (CmpL op1 op2));
14777   effect(USE labl);
14778 
14779   ins_cost(BRANCH_COST);
14780   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14781   ins_encode %{
14782     Label* L = $labl$$label;
14783     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14784     if (cond == Assembler::EQ)
14785       __ cbz($op1$$Register, *L);
14786     else
14787       __ cbnz($op1$$Register, *L);
14788   %}
14789   ins_pipe(pipe_cmp_branch);
14790 %}
14791 
14792 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14793   match(If cmp (CmpP op1 op2));
14794   effect(USE labl);
14795 
14796   ins_cost(BRANCH_COST);
14797   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14798   ins_encode %{
14799     Label* L = $labl$$label;
14800     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14801     if (cond == Assembler::EQ)
14802       __ cbz($op1$$Register, *L);
14803     else
14804       __ cbnz($op1$$Register, *L);
14805   %}
14806   ins_pipe(pipe_cmp_branch);
14807 %}
14808 
14809 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14810   match(If cmp (CmpN op1 op2));
14811   effect(USE labl);
14812 
14813   ins_cost(BRANCH_COST);
14814   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14815   ins_encode %{
14816     Label* L = $labl$$label;
14817     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14818     if (cond == Assembler::EQ)
14819       __ cbzw($op1$$Register, *L);
14820     else
14821       __ cbnzw($op1$$Register, *L);
14822   %}
14823   ins_pipe(pipe_cmp_branch);
14824 %}
14825 
14826 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14827   match(If cmp (CmpP (DecodeN oop) zero));
14828   effect(USE labl);
14829 
14830   ins_cost(BRANCH_COST);
14831   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14832   ins_encode %{
14833     Label* L = $labl$$label;
14834     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14835     if (cond == Assembler::EQ)
14836       __ cbzw($oop$$Register, *L);
14837     else
14838       __ cbnzw($oop$$Register, *L);
14839   %}
14840   ins_pipe(pipe_cmp_branch);
14841 %}
14842 
14843 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14844   match(If cmp (CmpU op1 op2));
14845   effect(USE labl);
14846 
14847   ins_cost(BRANCH_COST);
14848   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14849   ins_encode %{
14850     Label* L = $labl$$label;
14851     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14852     if (cond == Assembler::EQ || cond == Assembler::LS)
14853       __ cbzw($op1$$Register, *L);
14854     else
14855       __ cbnzw($op1$$Register, *L);
14856   %}
14857   ins_pipe(pipe_cmp_branch);
14858 %}
14859 
14860 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14861   match(If cmp (CmpUL op1 op2));
14862   effect(USE labl);
14863 
14864   ins_cost(BRANCH_COST);
14865   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14866   ins_encode %{
14867     Label* L = $labl$$label;
14868     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14869     if (cond == Assembler::EQ || cond == Assembler::LS)
14870       __ cbz($op1$$Register, *L);
14871     else
14872       __ cbnz($op1$$Register, *L);
14873   %}
14874   ins_pipe(pipe_cmp_branch);
14875 %}
14876 
14877 // Test bit and Branch
14878 
14879 // Patterns for short (&lt; 32KiB) variants
14880 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14881   match(If cmp (CmpL op1 op2));
14882   effect(USE labl);
14883 
14884   ins_cost(BRANCH_COST);
14885   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14886   ins_encode %{
14887     Label* L = $labl$$label;
14888     Assembler::Condition cond =
14889       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14890     __ tbr(cond, $op1$$Register, 63, *L);
14891   %}
14892   ins_pipe(pipe_cmp_branch);
14893   ins_short_branch(1);
14894 %}
14895 
14896 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14897   match(If cmp (CmpI op1 op2));
14898   effect(USE labl);
14899 
14900   ins_cost(BRANCH_COST);
14901   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14902   ins_encode %{
14903     Label* L = $labl$$label;
14904     Assembler::Condition cond =
14905       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14906     __ tbr(cond, $op1$$Register, 31, *L);
14907   %}
14908   ins_pipe(pipe_cmp_branch);
14909   ins_short_branch(1);
14910 %}
14911 
14912 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14913   match(If cmp (CmpL (AndL op1 op2) op3));
14914   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14915   effect(USE labl);
14916 
14917   ins_cost(BRANCH_COST);
14918   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14919   ins_encode %{
14920     Label* L = $labl$$label;
14921     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14922     int bit = exact_log2($op2$$constant);
14923     __ tbr(cond, $op1$$Register, bit, *L);
14924   %}
14925   ins_pipe(pipe_cmp_branch);
14926   ins_short_branch(1);
14927 %}
14928 
14929 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14930   match(If cmp (CmpI (AndI op1 op2) op3));
14931   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14932   effect(USE labl);
14933 
14934   ins_cost(BRANCH_COST);
14935   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14936   ins_encode %{
14937     Label* L = $labl$$label;
14938     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14939     int bit = exact_log2($op2$$constant);
14940     __ tbr(cond, $op1$$Register, bit, *L);
14941   %}
14942   ins_pipe(pipe_cmp_branch);
14943   ins_short_branch(1);
14944 %}
14945 
14946 // And far variants
14947 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14948   match(If cmp (CmpL op1 op2));
14949   effect(USE labl);
14950 
14951   ins_cost(BRANCH_COST);
14952   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14953   ins_encode %{
14954     Label* L = $labl$$label;
14955     Assembler::Condition cond =
14956       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14957     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
14958   %}
14959   ins_pipe(pipe_cmp_branch);
14960 %}
14961 
14962 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14963   match(If cmp (CmpI op1 op2));
14964   effect(USE labl);
14965 
14966   ins_cost(BRANCH_COST);
14967   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14968   ins_encode %{
14969     Label* L = $labl$$label;
14970     Assembler::Condition cond =
14971       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14972     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
14973   %}
14974   ins_pipe(pipe_cmp_branch);
14975 %}
14976 
14977 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14978   match(If cmp (CmpL (AndL op1 op2) op3));
14979   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14980   effect(USE labl);
14981 
14982   ins_cost(BRANCH_COST);
14983   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14984   ins_encode %{
14985     Label* L = $labl$$label;
14986     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14987     int bit = exact_log2($op2$$constant);
14988     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
14989   %}
14990   ins_pipe(pipe_cmp_branch);
14991 %}
14992 
14993 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14994   match(If cmp (CmpI (AndI op1 op2) op3));
14995   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14996   effect(USE labl);
14997 
14998   ins_cost(BRANCH_COST);
14999   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15000   ins_encode %{
15001     Label* L = $labl$$label;
15002     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15003     int bit = exact_log2($op2$$constant);
15004     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15005   %}
15006   ins_pipe(pipe_cmp_branch);
15007 %}
15008 
15009 // Test bits
15010 
15011 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15012   match(Set cr (CmpL (AndL op1 op2) op3));
15013   predicate(Assembler::operand_valid_for_logical_immediate
15014             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15015 
15016   ins_cost(INSN_COST);
15017   format %{ &quot;tst $op1, $op2 # long&quot; %}
15018   ins_encode %{
15019     __ tst($op1$$Register, $op2$$constant);
15020   %}
15021   ins_pipe(ialu_reg_reg);
15022 %}
15023 
15024 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15025   match(Set cr (CmpI (AndI op1 op2) op3));
15026   predicate(Assembler::operand_valid_for_logical_immediate
15027             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15028 
15029   ins_cost(INSN_COST);
15030   format %{ &quot;tst $op1, $op2 # int&quot; %}
15031   ins_encode %{
15032     __ tstw($op1$$Register, $op2$$constant);
15033   %}
15034   ins_pipe(ialu_reg_reg);
15035 %}
15036 
15037 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15038   match(Set cr (CmpL (AndL op1 op2) op3));
15039 
15040   ins_cost(INSN_COST);
15041   format %{ &quot;tst $op1, $op2 # long&quot; %}
15042   ins_encode %{
15043     __ tst($op1$$Register, $op2$$Register);
15044   %}
15045   ins_pipe(ialu_reg_reg);
15046 %}
15047 
15048 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15049   match(Set cr (CmpI (AndI op1 op2) op3));
15050 
15051   ins_cost(INSN_COST);
15052   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15053   ins_encode %{
15054     __ tstw($op1$$Register, $op2$$Register);
15055   %}
15056   ins_pipe(ialu_reg_reg);
15057 %}
15058 
15059 
15060 // Conditional Far Branch
15061 // Conditional Far Branch Unsigned
15062 // TODO: fixme
15063 
15064 // counted loop end branch near
15065 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15066 %{
15067   match(CountedLoopEnd cmp cr);
15068 
15069   effect(USE lbl);
15070 
15071   ins_cost(BRANCH_COST);
15072   // short variant.
15073   // ins_short_branch(1);
15074   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15075 
15076   ins_encode(aarch64_enc_br_con(cmp, lbl));
15077 
15078   ins_pipe(pipe_branch);
15079 %}
15080 
15081 // counted loop end branch near Unsigned
15082 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15083 %{
15084   match(CountedLoopEnd cmp cr);
15085 
15086   effect(USE lbl);
15087 
15088   ins_cost(BRANCH_COST);
15089   // short variant.
15090   // ins_short_branch(1);
15091   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15092 
15093   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15094 
15095   ins_pipe(pipe_branch);
15096 %}
15097 
15098 // counted loop end branch far
15099 // counted loop end branch far unsigned
15100 // TODO: fixme
15101 
15102 // ============================================================================
15103 // inlined locking and unlocking
15104 
15105 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15106 %{
15107   match(Set cr (FastLock object box));
15108   effect(TEMP tmp, TEMP tmp2);
15109 
15110   // TODO
15111   // identify correct cost
15112   ins_cost(5 * INSN_COST);
15113   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15114 
15115   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15116 
15117   ins_pipe(pipe_serial);
15118 %}
15119 
15120 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15121 %{
15122   match(Set cr (FastUnlock object box));
15123   effect(TEMP tmp, TEMP tmp2);
15124 
15125   ins_cost(5 * INSN_COST);
15126   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15127 
15128   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15129 
15130   ins_pipe(pipe_serial);
15131 %}
15132 
15133 
15134 // ============================================================================
15135 // Safepoint Instructions
15136 
15137 // TODO
15138 // provide a near and far version of this code
15139 
15140 instruct safePoint(rFlagsReg cr, iRegP poll)
15141 %{
15142   match(SafePoint poll);
15143   effect(KILL cr);
15144 
15145   format %{
15146     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15147   %}
15148   ins_encode %{
15149     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15150   %}
15151   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15152 %}
15153 
15154 
15155 // ============================================================================
15156 // Procedure Call/Return Instructions
15157 
15158 // Call Java Static Instruction
15159 
15160 instruct CallStaticJavaDirect(method meth)
15161 %{
15162   match(CallStaticJava);
15163 
15164   effect(USE meth);
15165 
15166   ins_cost(CALL_COST);
15167 
15168   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15169 
15170   ins_encode( aarch64_enc_java_static_call(meth),
15171               aarch64_enc_call_epilog );
15172 
15173   ins_pipe(pipe_class_call);
15174 %}
15175 
15176 // TO HERE
15177 
15178 // Call Java Dynamic Instruction
15179 instruct CallDynamicJavaDirect(method meth)
15180 %{
15181   match(CallDynamicJava);
15182 
15183   effect(USE meth);
15184 
15185   ins_cost(CALL_COST);
15186 
15187   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15188 
15189   ins_encode( aarch64_enc_java_dynamic_call(meth),
15190                aarch64_enc_call_epilog );
15191 
15192   ins_pipe(pipe_class_call);
15193 %}
15194 
15195 // Call Runtime Instruction
15196 
15197 instruct CallRuntimeDirect(method meth)
15198 %{
15199   match(CallRuntime);
15200 
15201   effect(USE meth);
15202 
15203   ins_cost(CALL_COST);
15204 
15205   format %{ &quot;CALL, runtime $meth&quot; %}
15206 
15207   ins_encode( aarch64_enc_java_to_runtime(meth) );
15208 
15209   ins_pipe(pipe_class_call);
15210 %}
15211 
15212 // Call Runtime Instruction
15213 
15214 instruct CallLeafDirect(method meth)
15215 %{
15216   match(CallLeaf);
15217 
15218   effect(USE meth);
15219 
15220   ins_cost(CALL_COST);
15221 
15222   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15223 
15224   ins_encode( aarch64_enc_java_to_runtime(meth) );
15225 
15226   ins_pipe(pipe_class_call);
15227 %}
15228 
15229 // Call Runtime Instruction
15230 
15231 instruct CallLeafNoFPDirect(method meth)
15232 %{
15233   match(CallLeafNoFP);
15234 
15235   effect(USE meth);
15236 
15237   ins_cost(CALL_COST);
15238 
15239   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15240 
15241   ins_encode( aarch64_enc_java_to_runtime(meth) );
15242 
15243   ins_pipe(pipe_class_call);
15244 %}
15245 
15246 // Tail Call; Jump from runtime stub to Java code.
15247 // Also known as an &#39;interprocedural jump&#39;.
15248 // Target of jump will eventually return to caller.
15249 // TailJump below removes the return address.
15250 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15251 %{
15252   match(TailCall jump_target method_oop);
15253 
15254   ins_cost(CALL_COST);
15255 
15256   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15257 
15258   ins_encode(aarch64_enc_tail_call(jump_target));
15259 
15260   ins_pipe(pipe_class_call);
15261 %}
15262 
15263 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15264 %{
15265   match(TailJump jump_target ex_oop);
15266 
15267   ins_cost(CALL_COST);
15268 
15269   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15270 
15271   ins_encode(aarch64_enc_tail_jmp(jump_target));
15272 
15273   ins_pipe(pipe_class_call);
15274 %}
15275 
15276 // Create exception oop: created by stack-crawling runtime code.
15277 // Created exception is now available to this handler, and is setup
15278 // just prior to jumping to this handler. No code emitted.
15279 // TODO check
15280 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15281 instruct CreateException(iRegP_R0 ex_oop)
15282 %{
15283   match(Set ex_oop (CreateEx));
15284 
15285   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15286 
15287   size(0);
15288 
15289   ins_encode( /*empty*/ );
15290 
15291   ins_pipe(pipe_class_empty);
15292 %}
15293 
15294 // Rethrow exception: The exception oop will come in the first
15295 // argument position. Then JUMP (not call) to the rethrow stub code.
15296 instruct RethrowException() %{
15297   match(Rethrow);
15298   ins_cost(CALL_COST);
15299 
15300   format %{ &quot;b rethrow_stub&quot; %}
15301 
15302   ins_encode( aarch64_enc_rethrow() );
15303 
15304   ins_pipe(pipe_class_call);
15305 %}
15306 
15307 
15308 // Return Instruction
15309 // epilog node loads ret address into lr as part of frame pop
15310 instruct Ret()
15311 %{
15312   match(Return);
15313 
15314   format %{ &quot;ret\t// return register&quot; %}
15315 
15316   ins_encode( aarch64_enc_ret() );
15317 
15318   ins_pipe(pipe_branch);
15319 %}
15320 
15321 // Die now.
15322 instruct ShouldNotReachHere() %{
15323   match(Halt);
15324 
15325   ins_cost(CALL_COST);
15326   format %{ &quot;ShouldNotReachHere&quot; %}
15327 
15328   ins_encode %{
15329     // +1 so NativeInstruction::is_sigill_zombie_not_entrant() doesn&#39;t
15330     // return true
15331     __ dpcs1(0xdead + 1);
15332   %}
15333 
15334   ins_pipe(pipe_class_default);
15335 %}
15336 
15337 // ============================================================================
15338 // Partial Subtype Check
15339 //
15340 // superklass array for an instance of the superklass.  Set a hidden
15341 // internal cache on a hit (cache is checked with exposed code in
15342 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15343 // encoding ALSO sets flags.
15344 
15345 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15346 %{
15347   match(Set result (PartialSubtypeCheck sub super));
15348   effect(KILL cr, KILL temp);
15349 
15350   ins_cost(1100);  // slightly larger than the next version
15351   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15352 
15353   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15354 
15355   opcode(0x1); // Force zero of result reg on hit
15356 
15357   ins_pipe(pipe_class_memory);
15358 %}
15359 
15360 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15361 %{
15362   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15363   effect(KILL temp, KILL result);
15364 
15365   ins_cost(1100);  // slightly larger than the next version
15366   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15367 
15368   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15369 
15370   opcode(0x0); // Don&#39;t zero result reg on hit
15371 
15372   ins_pipe(pipe_class_memory);
15373 %}
15374 
15375 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15376                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15377 %{
15378   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15379   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15380   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15381 
15382   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15383   ins_encode %{
15384     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15385     __ string_compare($str1$$Register, $str2$$Register,
15386                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15387                       $tmp1$$Register, $tmp2$$Register,
15388                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15389   %}
15390   ins_pipe(pipe_class_memory);
15391 %}
15392 
15393 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15394                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15395 %{
15396   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15397   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15398   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15399 
15400   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15401   ins_encode %{
15402     __ string_compare($str1$$Register, $str2$$Register,
15403                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15404                       $tmp1$$Register, $tmp2$$Register,
15405                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15406   %}
15407   ins_pipe(pipe_class_memory);
15408 %}
15409 
15410 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15411                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15412                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15413 %{
15414   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15415   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15416   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15417          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15418 
15419   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15420   ins_encode %{
15421     __ string_compare($str1$$Register, $str2$$Register,
15422                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15423                       $tmp1$$Register, $tmp2$$Register,
15424                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15425                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15426   %}
15427   ins_pipe(pipe_class_memory);
15428 %}
15429 
15430 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15431                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15432                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15433 %{
15434   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15435   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15436   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15437          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15438 
15439   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15440   ins_encode %{
15441     __ string_compare($str1$$Register, $str2$$Register,
15442                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15443                       $tmp1$$Register, $tmp2$$Register,
15444                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15445                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15446   %}
15447   ins_pipe(pipe_class_memory);
15448 %}
15449 
15450 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15451        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15452        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15453 %{
15454   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15455   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15456   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15457          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15458   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15459 
15460   ins_encode %{
15461     __ string_indexof($str1$$Register, $str2$$Register,
15462                       $cnt1$$Register, $cnt2$$Register,
15463                       $tmp1$$Register, $tmp2$$Register,
15464                       $tmp3$$Register, $tmp4$$Register,
15465                       $tmp5$$Register, $tmp6$$Register,
15466                       -1, $result$$Register, StrIntrinsicNode::UU);
15467   %}
15468   ins_pipe(pipe_class_memory);
15469 %}
15470 
15471 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15472        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15473        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15474 %{
15475   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15476   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15477   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15478          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15479   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15480 
15481   ins_encode %{
15482     __ string_indexof($str1$$Register, $str2$$Register,
15483                       $cnt1$$Register, $cnt2$$Register,
15484                       $tmp1$$Register, $tmp2$$Register,
15485                       $tmp3$$Register, $tmp4$$Register,
15486                       $tmp5$$Register, $tmp6$$Register,
15487                       -1, $result$$Register, StrIntrinsicNode::LL);
15488   %}
15489   ins_pipe(pipe_class_memory);
15490 %}
15491 
15492 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15493        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15494        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15495 %{
15496   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15497   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15498   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15499          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15500   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15501 
15502   ins_encode %{
15503     __ string_indexof($str1$$Register, $str2$$Register,
15504                       $cnt1$$Register, $cnt2$$Register,
15505                       $tmp1$$Register, $tmp2$$Register,
15506                       $tmp3$$Register, $tmp4$$Register,
15507                       $tmp5$$Register, $tmp6$$Register,
15508                       -1, $result$$Register, StrIntrinsicNode::UL);
15509   %}
15510   ins_pipe(pipe_class_memory);
15511 %}
15512 
15513 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15514                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15515                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15516 %{
15517   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15518   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15519   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15520          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15521   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15522 
15523   ins_encode %{
15524     int icnt2 = (int)$int_cnt2$$constant;
15525     __ string_indexof($str1$$Register, $str2$$Register,
15526                       $cnt1$$Register, zr,
15527                       $tmp1$$Register, $tmp2$$Register,
15528                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15529                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15530   %}
15531   ins_pipe(pipe_class_memory);
15532 %}
15533 
15534 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15535                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15536                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15537 %{
15538   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15539   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15540   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15541          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15542   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15543 
15544   ins_encode %{
15545     int icnt2 = (int)$int_cnt2$$constant;
15546     __ string_indexof($str1$$Register, $str2$$Register,
15547                       $cnt1$$Register, zr,
15548                       $tmp1$$Register, $tmp2$$Register,
15549                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15550                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15551   %}
15552   ins_pipe(pipe_class_memory);
15553 %}
15554 
15555 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15556                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15557                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15558 %{
15559   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15560   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15561   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15562          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15563   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15564 
15565   ins_encode %{
15566     int icnt2 = (int)$int_cnt2$$constant;
15567     __ string_indexof($str1$$Register, $str2$$Register,
15568                       $cnt1$$Register, zr,
15569                       $tmp1$$Register, $tmp2$$Register,
15570                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15571                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15572   %}
15573   ins_pipe(pipe_class_memory);
15574 %}
15575 
15576 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15577                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15578                               iRegINoSp tmp3, rFlagsReg cr)
15579 %{
15580   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15581   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15582          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15583 
15584   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15585 
15586   ins_encode %{
15587     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15588                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15589                            $tmp3$$Register);
15590   %}
15591   ins_pipe(pipe_class_memory);
15592 %}
15593 
15594 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15595                         iRegI_R0 result, rFlagsReg cr)
15596 %{
15597   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15598   match(Set result (StrEquals (Binary str1 str2) cnt));
15599   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15600 
15601   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15602   ins_encode %{
15603     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15604     __ string_equals($str1$$Register, $str2$$Register,
15605                      $result$$Register, $cnt$$Register, 1);
15606   %}
15607   ins_pipe(pipe_class_memory);
15608 %}
15609 
15610 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15611                         iRegI_R0 result, rFlagsReg cr)
15612 %{
15613   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15614   match(Set result (StrEquals (Binary str1 str2) cnt));
15615   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15616 
15617   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15618   ins_encode %{
15619     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15620     __ string_equals($str1$$Register, $str2$$Register,
15621                      $result$$Register, $cnt$$Register, 2);
15622   %}
15623   ins_pipe(pipe_class_memory);
15624 %}
15625 
15626 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15627                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15628                        iRegP_R10 tmp, rFlagsReg cr)
15629 %{
15630   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15631   match(Set result (AryEq ary1 ary2));
15632   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15633 
15634   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15635   ins_encode %{
15636     __ arrays_equals($ary1$$Register, $ary2$$Register,
15637                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15638                      $result$$Register, $tmp$$Register, 1);
15639     %}
15640   ins_pipe(pipe_class_memory);
15641 %}
15642 
15643 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15644                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15645                        iRegP_R10 tmp, rFlagsReg cr)
15646 %{
15647   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15648   match(Set result (AryEq ary1 ary2));
15649   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15650 
15651   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15652   ins_encode %{
15653     __ arrays_equals($ary1$$Register, $ary2$$Register,
15654                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15655                      $result$$Register, $tmp$$Register, 2);
15656   %}
15657   ins_pipe(pipe_class_memory);
15658 %}
15659 
15660 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15661 %{
15662   match(Set result (HasNegatives ary1 len));
15663   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15664   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15665   ins_encode %{
15666     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15667   %}
15668   ins_pipe( pipe_slow );
15669 %}
15670 
15671 // fast char[] to byte[] compression
15672 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15673                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15674                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15675                          iRegI_R0 result, rFlagsReg cr)
15676 %{
15677   match(Set result (StrCompressedCopy src (Binary dst len)));
15678   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15679 
15680   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15681   ins_encode %{
15682     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15683                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15684                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15685                            $result$$Register);
15686   %}
15687   ins_pipe( pipe_slow );
15688 %}
15689 
15690 // fast byte[] to char[] inflation
15691 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15692                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15693 %{
15694   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15695   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15696 
15697   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15698   ins_encode %{
15699     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15700                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15701   %}
15702   ins_pipe(pipe_class_memory);
15703 %}
15704 
15705 // encode char[] to byte[] in ISO_8859_1
15706 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15707                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15708                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15709                           iRegI_R0 result, rFlagsReg cr)
15710 %{
15711   match(Set result (EncodeISOArray src (Binary dst len)));
15712   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15713          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15714 
15715   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15716   ins_encode %{
15717     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15718          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15719          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15720   %}
15721   ins_pipe( pipe_class_memory );
15722 %}
15723 
15724 // ============================================================================
15725 // This name is KNOWN by the ADLC and cannot be changed.
15726 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15727 // for this guy.
15728 instruct tlsLoadP(thread_RegP dst)
15729 %{
15730   match(Set dst (ThreadLocal));
15731 
15732   ins_cost(0);
15733 
15734   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15735 
15736   size(0);
15737 
15738   ins_encode( /*empty*/ );
15739 
15740   ins_pipe(pipe_class_empty);
15741 %}
15742 
15743 // ====================VECTOR INSTRUCTIONS=====================================
15744 
15745 // Load vector (32 bits)
15746 instruct loadV4(vecD dst, vmem4 mem)
15747 %{
15748   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15749   match(Set dst (LoadVector mem));
15750   ins_cost(4 * INSN_COST);
15751   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15752   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15753   ins_pipe(vload_reg_mem64);
15754 %}
15755 
15756 // Load vector (64 bits)
15757 instruct loadV8(vecD dst, vmem8 mem)
15758 %{
15759   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15760   match(Set dst (LoadVector mem));
15761   ins_cost(4 * INSN_COST);
15762   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15763   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15764   ins_pipe(vload_reg_mem64);
15765 %}
15766 
15767 // Load Vector (128 bits)
15768 instruct loadV16(vecX dst, vmem16 mem)
15769 %{
15770   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15771   match(Set dst (LoadVector mem));
15772   ins_cost(4 * INSN_COST);
15773   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15774   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15775   ins_pipe(vload_reg_mem128);
15776 %}
15777 
15778 // Store Vector (32 bits)
15779 instruct storeV4(vecD src, vmem4 mem)
15780 %{
15781   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15782   match(Set mem (StoreVector mem src));
15783   ins_cost(4 * INSN_COST);
15784   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15785   ins_encode( aarch64_enc_strvS(src, mem) );
15786   ins_pipe(vstore_reg_mem64);
15787 %}
15788 
15789 // Store Vector (64 bits)
15790 instruct storeV8(vecD src, vmem8 mem)
15791 %{
15792   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15793   match(Set mem (StoreVector mem src));
15794   ins_cost(4 * INSN_COST);
15795   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15796   ins_encode( aarch64_enc_strvD(src, mem) );
15797   ins_pipe(vstore_reg_mem64);
15798 %}
15799 
15800 // Store Vector (128 bits)
15801 instruct storeV16(vecX src, vmem16 mem)
15802 %{
15803   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15804   match(Set mem (StoreVector mem src));
15805   ins_cost(4 * INSN_COST);
15806   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15807   ins_encode( aarch64_enc_strvQ(src, mem) );
15808   ins_pipe(vstore_reg_mem128);
15809 %}
15810 
15811 instruct replicate8B(vecD dst, iRegIorL2I src)
15812 %{
15813   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15814             n-&gt;as_Vector()-&gt;length() == 8);
15815   match(Set dst (ReplicateB src));
15816   ins_cost(INSN_COST);
15817   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15818   ins_encode %{
15819     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15820   %}
15821   ins_pipe(vdup_reg_reg64);
15822 %}
15823 
15824 instruct replicate16B(vecX dst, iRegIorL2I src)
15825 %{
15826   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15827   match(Set dst (ReplicateB src));
15828   ins_cost(INSN_COST);
15829   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15830   ins_encode %{
15831     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15832   %}
15833   ins_pipe(vdup_reg_reg128);
15834 %}
15835 
15836 instruct replicate8B_imm(vecD dst, immI con)
15837 %{
15838   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15839             n-&gt;as_Vector()-&gt;length() == 8);
15840   match(Set dst (ReplicateB con));
15841   ins_cost(INSN_COST);
15842   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15843   ins_encode %{
15844     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15845   %}
15846   ins_pipe(vmovi_reg_imm64);
15847 %}
15848 
15849 instruct replicate16B_imm(vecX dst, immI con)
15850 %{
15851   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15852   match(Set dst (ReplicateB con));
15853   ins_cost(INSN_COST);
15854   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15855   ins_encode %{
15856     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15857   %}
15858   ins_pipe(vmovi_reg_imm128);
15859 %}
15860 
15861 instruct replicate4S(vecD dst, iRegIorL2I src)
15862 %{
15863   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15864             n-&gt;as_Vector()-&gt;length() == 4);
15865   match(Set dst (ReplicateS src));
15866   ins_cost(INSN_COST);
15867   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15868   ins_encode %{
15869     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15870   %}
15871   ins_pipe(vdup_reg_reg64);
15872 %}
15873 
15874 instruct replicate8S(vecX dst, iRegIorL2I src)
15875 %{
15876   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15877   match(Set dst (ReplicateS src));
15878   ins_cost(INSN_COST);
15879   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15880   ins_encode %{
15881     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15882   %}
15883   ins_pipe(vdup_reg_reg128);
15884 %}
15885 
15886 instruct replicate4S_imm(vecD dst, immI con)
15887 %{
15888   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15889             n-&gt;as_Vector()-&gt;length() == 4);
15890   match(Set dst (ReplicateS con));
15891   ins_cost(INSN_COST);
15892   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15893   ins_encode %{
15894     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15895   %}
15896   ins_pipe(vmovi_reg_imm64);
15897 %}
15898 
15899 instruct replicate8S_imm(vecX dst, immI con)
15900 %{
15901   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15902   match(Set dst (ReplicateS con));
15903   ins_cost(INSN_COST);
15904   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15905   ins_encode %{
15906     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15907   %}
15908   ins_pipe(vmovi_reg_imm128);
15909 %}
15910 
15911 instruct replicate2I(vecD dst, iRegIorL2I src)
15912 %{
15913   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15914   match(Set dst (ReplicateI src));
15915   ins_cost(INSN_COST);
15916   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15917   ins_encode %{
15918     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15919   %}
15920   ins_pipe(vdup_reg_reg64);
15921 %}
15922 
15923 instruct replicate4I(vecX dst, iRegIorL2I src)
15924 %{
15925   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15926   match(Set dst (ReplicateI src));
15927   ins_cost(INSN_COST);
15928   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15929   ins_encode %{
15930     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15931   %}
15932   ins_pipe(vdup_reg_reg128);
15933 %}
15934 
15935 instruct replicate2I_imm(vecD dst, immI con)
15936 %{
15937   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15938   match(Set dst (ReplicateI con));
15939   ins_cost(INSN_COST);
15940   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
15941   ins_encode %{
15942     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
15943   %}
15944   ins_pipe(vmovi_reg_imm64);
15945 %}
15946 
15947 instruct replicate4I_imm(vecX dst, immI con)
15948 %{
15949   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15950   match(Set dst (ReplicateI con));
15951   ins_cost(INSN_COST);
15952   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
15953   ins_encode %{
15954     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
15955   %}
15956   ins_pipe(vmovi_reg_imm128);
15957 %}
15958 
15959 instruct replicate2L(vecX dst, iRegL src)
15960 %{
15961   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15962   match(Set dst (ReplicateL src));
15963   ins_cost(INSN_COST);
15964   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
15965   ins_encode %{
15966     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
15967   %}
15968   ins_pipe(vdup_reg_reg128);
15969 %}
15970 
15971 instruct replicate2L_zero(vecX dst, immI0 zero)
15972 %{
15973   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15974   match(Set dst (ReplicateI zero));
15975   ins_cost(INSN_COST);
15976   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
15977   ins_encode %{
15978     __ eor(as_FloatRegister($dst$$reg), __ T16B,
15979            as_FloatRegister($dst$$reg),
15980            as_FloatRegister($dst$$reg));
15981   %}
15982   ins_pipe(vmovi_reg_imm128);
15983 %}
15984 
15985 instruct replicate2F(vecD dst, vRegF src)
15986 %{
15987   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15988   match(Set dst (ReplicateF src));
15989   ins_cost(INSN_COST);
15990   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
15991   ins_encode %{
15992     __ dup(as_FloatRegister($dst$$reg), __ T2S,
15993            as_FloatRegister($src$$reg));
15994   %}
15995   ins_pipe(vdup_reg_freg64);
15996 %}
15997 
15998 instruct replicate4F(vecX dst, vRegF src)
15999 %{
16000   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16001   match(Set dst (ReplicateF src));
16002   ins_cost(INSN_COST);
16003   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
16004   ins_encode %{
16005     __ dup(as_FloatRegister($dst$$reg), __ T4S,
16006            as_FloatRegister($src$$reg));
16007   %}
16008   ins_pipe(vdup_reg_freg128);
16009 %}
16010 
16011 instruct replicate2D(vecX dst, vRegD src)
16012 %{
16013   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16014   match(Set dst (ReplicateD src));
16015   ins_cost(INSN_COST);
16016   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16017   ins_encode %{
16018     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16019            as_FloatRegister($src$$reg));
16020   %}
16021   ins_pipe(vdup_reg_dreg128);
16022 %}
16023 
16024 // ====================REDUCTION ARITHMETIC====================================
16025 
16026 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp, iRegINoSp tmp2)
16027 %{
16028   match(Set dst (AddReductionVI src1 src2));
16029   ins_cost(INSN_COST);
16030   effect(TEMP tmp, TEMP tmp2);
16031   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16032             &quot;umov  $tmp2, $src2, S, 1\n\t&quot;
16033             &quot;addw  $dst, $src1, $tmp\n\t&quot;
16034             &quot;addw  $dst, $dst, $tmp2\t add reduction2i&quot;
16035   %}
16036   ins_encode %{
16037     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16038     __ umov($tmp2$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16039     __ addw($dst$$Register, $src1$$Register, $tmp$$Register);
16040     __ addw($dst$$Register, $dst$$Register, $tmp2$$Register);
16041   %}
16042   ins_pipe(pipe_class_default);
16043 %}
16044 
16045 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16046 %{
16047   match(Set dst (AddReductionVI src1 src2));
16048   ins_cost(INSN_COST);
16049   effect(TEMP tmp, TEMP tmp2);
16050   format %{ &quot;addv  $tmp, T4S, $src2\n\t&quot;
16051             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16052             &quot;addw  $dst, $tmp2, $src1\t add reduction4i&quot;
16053   %}
16054   ins_encode %{
16055     __ addv(as_FloatRegister($tmp$$reg), __ T4S,
16056             as_FloatRegister($src2$$reg));
16057     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16058     __ addw($dst$$Register, $tmp2$$Register, $src1$$Register);
16059   %}
16060   ins_pipe(pipe_class_default);
16061 %}
16062 
16063 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp)
16064 %{
16065   match(Set dst (MulReductionVI src1 src2));
16066   ins_cost(INSN_COST);
16067   effect(TEMP tmp, TEMP dst);
16068   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16069             &quot;mul   $dst, $tmp, $src1\n\t&quot;
16070             &quot;umov  $tmp, $src2, S, 1\n\t&quot;
16071             &quot;mul   $dst, $tmp, $dst\t mul reduction2i\n\t&quot;
16072   %}
16073   ins_encode %{
16074     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16075     __ mul($dst$$Register, $tmp$$Register, $src1$$Register);
16076     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16077     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16078   %}
16079   ins_pipe(pipe_class_default);
16080 %}
16081 
16082 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16083 %{
16084   match(Set dst (MulReductionVI src1 src2));
16085   ins_cost(INSN_COST);
16086   effect(TEMP tmp, TEMP tmp2, TEMP dst);
16087   format %{ &quot;ins   $tmp, $src2, 0, 1\n\t&quot;
16088             &quot;mul   $tmp, $tmp, $src2\n\t&quot;
16089             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16090             &quot;mul   $dst, $tmp2, $src1\n\t&quot;
16091             &quot;umov  $tmp2, $tmp, S, 1\n\t&quot;
16092             &quot;mul   $dst, $tmp2, $dst\t mul reduction4i\n\t&quot;
16093   %}
16094   ins_encode %{
16095     __ ins(as_FloatRegister($tmp$$reg), __ D,
16096            as_FloatRegister($src2$$reg), 0, 1);
16097     __ mulv(as_FloatRegister($tmp$$reg), __ T2S,
16098            as_FloatRegister($tmp$$reg), as_FloatRegister($src2$$reg));
16099     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16100     __ mul($dst$$Register, $tmp2$$Register, $src1$$Register);
16101     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 1);
16102     __ mul($dst$$Register, $tmp2$$Register, $dst$$Register);
16103   %}
16104   ins_pipe(pipe_class_default);
16105 %}
16106 
16107 instruct reduce_add2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16108 %{
16109   match(Set dst (AddReductionVF src1 src2));
16110   ins_cost(INSN_COST);
16111   effect(TEMP tmp, TEMP dst);
16112   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16113             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16114             &quot;fadds $dst, $dst, $tmp\t add reduction2f&quot;
16115   %}
16116   ins_encode %{
16117     __ fadds(as_FloatRegister($dst$$reg),
16118              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16119     __ ins(as_FloatRegister($tmp$$reg), __ S,
16120            as_FloatRegister($src2$$reg), 0, 1);
16121     __ fadds(as_FloatRegister($dst$$reg),
16122              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16123   %}
16124   ins_pipe(pipe_class_default);
16125 %}
16126 
16127 instruct reduce_add4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16128 %{
16129   match(Set dst (AddReductionVF src1 src2));
16130   ins_cost(INSN_COST);
16131   effect(TEMP tmp, TEMP dst);
16132   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16133             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16134             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16135             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16136             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16137             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
16138             &quot;fadds $dst, $dst, $tmp\t add reduction4f&quot;
16139   %}
16140   ins_encode %{
16141     __ fadds(as_FloatRegister($dst$$reg),
16142              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16143     __ ins(as_FloatRegister($tmp$$reg), __ S,
16144            as_FloatRegister($src2$$reg), 0, 1);
16145     __ fadds(as_FloatRegister($dst$$reg),
16146              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16147     __ ins(as_FloatRegister($tmp$$reg), __ S,
16148            as_FloatRegister($src2$$reg), 0, 2);
16149     __ fadds(as_FloatRegister($dst$$reg),
16150              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16151     __ ins(as_FloatRegister($tmp$$reg), __ S,
16152            as_FloatRegister($src2$$reg), 0, 3);
16153     __ fadds(as_FloatRegister($dst$$reg),
16154              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16155   %}
16156   ins_pipe(pipe_class_default);
16157 %}
16158 
16159 instruct reduce_mul2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16160 %{
16161   match(Set dst (MulReductionVF src1 src2));
16162   ins_cost(INSN_COST);
16163   effect(TEMP tmp, TEMP dst);
16164   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16165             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16166             &quot;fmuls $dst, $dst, $tmp\t add reduction4f&quot;
16167   %}
16168   ins_encode %{
16169     __ fmuls(as_FloatRegister($dst$$reg),
16170              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16171     __ ins(as_FloatRegister($tmp$$reg), __ S,
16172            as_FloatRegister($src2$$reg), 0, 1);
16173     __ fmuls(as_FloatRegister($dst$$reg),
16174              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16175   %}
16176   ins_pipe(pipe_class_default);
16177 %}
16178 
16179 instruct reduce_mul4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16180 %{
16181   match(Set dst (MulReductionVF src1 src2));
16182   ins_cost(INSN_COST);
16183   effect(TEMP tmp, TEMP dst);
16184   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16185             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16186             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16187             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16188             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16189             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
16190             &quot;fmuls $dst, $dst, $tmp\t add reduction4f&quot;
16191   %}
16192   ins_encode %{
16193     __ fmuls(as_FloatRegister($dst$$reg),
16194              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16195     __ ins(as_FloatRegister($tmp$$reg), __ S,
16196            as_FloatRegister($src2$$reg), 0, 1);
16197     __ fmuls(as_FloatRegister($dst$$reg),
16198              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16199     __ ins(as_FloatRegister($tmp$$reg), __ S,
16200            as_FloatRegister($src2$$reg), 0, 2);
16201     __ fmuls(as_FloatRegister($dst$$reg),
16202              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16203     __ ins(as_FloatRegister($tmp$$reg), __ S,
16204            as_FloatRegister($src2$$reg), 0, 3);
16205     __ fmuls(as_FloatRegister($dst$$reg),
16206              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16207   %}
16208   ins_pipe(pipe_class_default);
16209 %}
16210 
16211 instruct reduce_add2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16212 %{
16213   match(Set dst (AddReductionVD src1 src2));
16214   ins_cost(INSN_COST);
16215   effect(TEMP tmp, TEMP dst);
16216   format %{ &quot;faddd $dst, $src1, $src2\n\t&quot;
16217             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16218             &quot;faddd $dst, $dst, $tmp\t add reduction2d&quot;
16219   %}
16220   ins_encode %{
16221     __ faddd(as_FloatRegister($dst$$reg),
16222              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16223     __ ins(as_FloatRegister($tmp$$reg), __ D,
16224            as_FloatRegister($src2$$reg), 0, 1);
16225     __ faddd(as_FloatRegister($dst$$reg),
16226              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16227   %}
16228   ins_pipe(pipe_class_default);
16229 %}
16230 
16231 instruct reduce_mul2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16232 %{
16233   match(Set dst (MulReductionVD src1 src2));
16234   ins_cost(INSN_COST);
16235   effect(TEMP tmp, TEMP dst);
16236   format %{ &quot;fmuld $dst, $src1, $src2\n\t&quot;
16237             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16238             &quot;fmuld $dst, $dst, $tmp\t add reduction2d&quot;
16239   %}
16240   ins_encode %{
16241     __ fmuld(as_FloatRegister($dst$$reg),
16242              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16243     __ ins(as_FloatRegister($tmp$$reg), __ D,
16244            as_FloatRegister($src2$$reg), 0, 1);
16245     __ fmuld(as_FloatRegister($dst$$reg),
16246              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16247   %}
16248   ins_pipe(pipe_class_default);
16249 %}
16250 
16251 instruct reduce_max2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16252   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16253   match(Set dst (MaxReductionV src1 src2));
16254   ins_cost(INSN_COST);
16255   effect(TEMP_DEF dst, TEMP tmp);
16256   format %{ &quot;fmaxs $dst, $src1, $src2\n\t&quot;
16257             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16258             &quot;fmaxs $dst, $dst, $tmp\t max reduction2F&quot; %}
16259   ins_encode %{
16260     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16261     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16262     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16263   %}
16264   ins_pipe(pipe_class_default);
16265 %}
16266 
16267 instruct reduce_max4F(vRegF dst, vRegF src1, vecX src2) %{
16268   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16269   match(Set dst (MaxReductionV src1 src2));
16270   ins_cost(INSN_COST);
16271   effect(TEMP_DEF dst);
16272   format %{ &quot;fmaxv $dst, T4S, $src2\n\t&quot;
16273             &quot;fmaxs $dst, $dst, $src1\t max reduction4F&quot; %}
16274   ins_encode %{
16275     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16276     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16277   %}
16278   ins_pipe(pipe_class_default);
16279 %}
16280 
16281 instruct reduce_max2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16282   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16283   match(Set dst (MaxReductionV src1 src2));
16284   ins_cost(INSN_COST);
16285   effect(TEMP_DEF dst, TEMP tmp);
16286   format %{ &quot;fmaxd $dst, $src1, $src2\n\t&quot;
16287             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16288             &quot;fmaxd $dst, $dst, $tmp\t max reduction2D&quot; %}
16289   ins_encode %{
16290     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16291     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16292     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16293   %}
16294   ins_pipe(pipe_class_default);
16295 %}
16296 
16297 instruct reduce_min2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16298   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16299   match(Set dst (MinReductionV src1 src2));
16300   ins_cost(INSN_COST);
16301   effect(TEMP_DEF dst, TEMP tmp);
16302   format %{ &quot;fmins $dst, $src1, $src2\n\t&quot;
16303             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16304             &quot;fmins $dst, $dst, $tmp\t min reduction2F&quot; %}
16305   ins_encode %{
16306     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16307     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16308     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16309   %}
16310   ins_pipe(pipe_class_default);
16311 %}
16312 
16313 instruct reduce_min4F(vRegF dst, vRegF src1, vecX src2) %{
16314   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16315   match(Set dst (MinReductionV src1 src2));
16316   ins_cost(INSN_COST);
16317   effect(TEMP_DEF dst);
16318   format %{ &quot;fminv $dst, T4S, $src2\n\t&quot;
16319             &quot;fmins $dst, $dst, $src1\t min reduction4F&quot; %}
16320   ins_encode %{
16321     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16322     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16323   %}
16324   ins_pipe(pipe_class_default);
16325 %}
16326 
16327 instruct reduce_min2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16328   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16329   match(Set dst (MinReductionV src1 src2));
16330   ins_cost(INSN_COST);
16331   effect(TEMP_DEF dst, TEMP tmp);
16332   format %{ &quot;fmind $dst, $src1, $src2\n\t&quot;
16333             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16334             &quot;fmind $dst, $dst, $tmp\t min reduction2D&quot; %}
16335   ins_encode %{
16336     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16337     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16338     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16339   %}
16340   ins_pipe(pipe_class_default);
16341 %}
16342 
16343 // ====================VECTOR ARITHMETIC=======================================
16344 
16345 // --------------------------------- ADD --------------------------------------
16346 
16347 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16348 %{
16349   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16350             n-&gt;as_Vector()-&gt;length() == 8);
16351   match(Set dst (AddVB src1 src2));
16352   ins_cost(INSN_COST);
16353   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16354   ins_encode %{
16355     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16356             as_FloatRegister($src1$$reg),
16357             as_FloatRegister($src2$$reg));
16358   %}
16359   ins_pipe(vdop64);
16360 %}
16361 
16362 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16363 %{
16364   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16365   match(Set dst (AddVB src1 src2));
16366   ins_cost(INSN_COST);
16367   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16368   ins_encode %{
16369     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16370             as_FloatRegister($src1$$reg),
16371             as_FloatRegister($src2$$reg));
16372   %}
16373   ins_pipe(vdop128);
16374 %}
16375 
16376 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16377 %{
16378   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16379             n-&gt;as_Vector()-&gt;length() == 4);
16380   match(Set dst (AddVS src1 src2));
16381   ins_cost(INSN_COST);
16382   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16383   ins_encode %{
16384     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16385             as_FloatRegister($src1$$reg),
16386             as_FloatRegister($src2$$reg));
16387   %}
16388   ins_pipe(vdop64);
16389 %}
16390 
16391 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16392 %{
16393   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16394   match(Set dst (AddVS src1 src2));
16395   ins_cost(INSN_COST);
16396   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16397   ins_encode %{
16398     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16399             as_FloatRegister($src1$$reg),
16400             as_FloatRegister($src2$$reg));
16401   %}
16402   ins_pipe(vdop128);
16403 %}
16404 
16405 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16406 %{
16407   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16408   match(Set dst (AddVI src1 src2));
16409   ins_cost(INSN_COST);
16410   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16411   ins_encode %{
16412     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16413             as_FloatRegister($src1$$reg),
16414             as_FloatRegister($src2$$reg));
16415   %}
16416   ins_pipe(vdop64);
16417 %}
16418 
16419 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16420 %{
16421   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16422   match(Set dst (AddVI src1 src2));
16423   ins_cost(INSN_COST);
16424   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16425   ins_encode %{
16426     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16427             as_FloatRegister($src1$$reg),
16428             as_FloatRegister($src2$$reg));
16429   %}
16430   ins_pipe(vdop128);
16431 %}
16432 
16433 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16434 %{
16435   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16436   match(Set dst (AddVL src1 src2));
16437   ins_cost(INSN_COST);
16438   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16439   ins_encode %{
16440     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16441             as_FloatRegister($src1$$reg),
16442             as_FloatRegister($src2$$reg));
16443   %}
16444   ins_pipe(vdop128);
16445 %}
16446 
16447 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16448 %{
16449   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16450   match(Set dst (AddVF src1 src2));
16451   ins_cost(INSN_COST);
16452   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16453   ins_encode %{
16454     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16455             as_FloatRegister($src1$$reg),
16456             as_FloatRegister($src2$$reg));
16457   %}
16458   ins_pipe(vdop_fp64);
16459 %}
16460 
16461 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16462 %{
16463   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16464   match(Set dst (AddVF src1 src2));
16465   ins_cost(INSN_COST);
16466   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16467   ins_encode %{
16468     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16469             as_FloatRegister($src1$$reg),
16470             as_FloatRegister($src2$$reg));
16471   %}
16472   ins_pipe(vdop_fp128);
16473 %}
16474 
16475 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16476 %{
16477   match(Set dst (AddVD src1 src2));
16478   ins_cost(INSN_COST);
16479   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16480   ins_encode %{
16481     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16482             as_FloatRegister($src1$$reg),
16483             as_FloatRegister($src2$$reg));
16484   %}
16485   ins_pipe(vdop_fp128);
16486 %}
16487 
16488 // --------------------------------- SUB --------------------------------------
16489 
16490 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16491 %{
16492   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16493             n-&gt;as_Vector()-&gt;length() == 8);
16494   match(Set dst (SubVB src1 src2));
16495   ins_cost(INSN_COST);
16496   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16497   ins_encode %{
16498     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16499             as_FloatRegister($src1$$reg),
16500             as_FloatRegister($src2$$reg));
16501   %}
16502   ins_pipe(vdop64);
16503 %}
16504 
16505 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16506 %{
16507   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16508   match(Set dst (SubVB src1 src2));
16509   ins_cost(INSN_COST);
16510   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16511   ins_encode %{
16512     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16513             as_FloatRegister($src1$$reg),
16514             as_FloatRegister($src2$$reg));
16515   %}
16516   ins_pipe(vdop128);
16517 %}
16518 
16519 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16520 %{
16521   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16522             n-&gt;as_Vector()-&gt;length() == 4);
16523   match(Set dst (SubVS src1 src2));
16524   ins_cost(INSN_COST);
16525   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16526   ins_encode %{
16527     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16528             as_FloatRegister($src1$$reg),
16529             as_FloatRegister($src2$$reg));
16530   %}
16531   ins_pipe(vdop64);
16532 %}
16533 
16534 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16535 %{
16536   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16537   match(Set dst (SubVS src1 src2));
16538   ins_cost(INSN_COST);
16539   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16540   ins_encode %{
16541     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16542             as_FloatRegister($src1$$reg),
16543             as_FloatRegister($src2$$reg));
16544   %}
16545   ins_pipe(vdop128);
16546 %}
16547 
16548 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16549 %{
16550   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16551   match(Set dst (SubVI src1 src2));
16552   ins_cost(INSN_COST);
16553   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16554   ins_encode %{
16555     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16556             as_FloatRegister($src1$$reg),
16557             as_FloatRegister($src2$$reg));
16558   %}
16559   ins_pipe(vdop64);
16560 %}
16561 
16562 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16563 %{
16564   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16565   match(Set dst (SubVI src1 src2));
16566   ins_cost(INSN_COST);
16567   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16568   ins_encode %{
16569     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16570             as_FloatRegister($src1$$reg),
16571             as_FloatRegister($src2$$reg));
16572   %}
16573   ins_pipe(vdop128);
16574 %}
16575 
16576 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16577 %{
16578   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16579   match(Set dst (SubVL src1 src2));
16580   ins_cost(INSN_COST);
16581   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16582   ins_encode %{
16583     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16584             as_FloatRegister($src1$$reg),
16585             as_FloatRegister($src2$$reg));
16586   %}
16587   ins_pipe(vdop128);
16588 %}
16589 
16590 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16591 %{
16592   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16593   match(Set dst (SubVF src1 src2));
16594   ins_cost(INSN_COST);
16595   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16596   ins_encode %{
16597     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16598             as_FloatRegister($src1$$reg),
16599             as_FloatRegister($src2$$reg));
16600   %}
16601   ins_pipe(vdop_fp64);
16602 %}
16603 
16604 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16605 %{
16606   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16607   match(Set dst (SubVF src1 src2));
16608   ins_cost(INSN_COST);
16609   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16610   ins_encode %{
16611     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16612             as_FloatRegister($src1$$reg),
16613             as_FloatRegister($src2$$reg));
16614   %}
16615   ins_pipe(vdop_fp128);
16616 %}
16617 
16618 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16619 %{
16620   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16621   match(Set dst (SubVD src1 src2));
16622   ins_cost(INSN_COST);
16623   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16624   ins_encode %{
16625     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16626             as_FloatRegister($src1$$reg),
16627             as_FloatRegister($src2$$reg));
16628   %}
16629   ins_pipe(vdop_fp128);
16630 %}
16631 
16632 // --------------------------------- MUL --------------------------------------
16633 
16634 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16635 %{
16636   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16637             n-&gt;as_Vector()-&gt;length() == 4);
16638   match(Set dst (MulVS src1 src2));
16639   ins_cost(INSN_COST);
16640   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16641   ins_encode %{
16642     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16643             as_FloatRegister($src1$$reg),
16644             as_FloatRegister($src2$$reg));
16645   %}
16646   ins_pipe(vmul64);
16647 %}
16648 
16649 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16650 %{
16651   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16652   match(Set dst (MulVS src1 src2));
16653   ins_cost(INSN_COST);
16654   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16655   ins_encode %{
16656     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16657             as_FloatRegister($src1$$reg),
16658             as_FloatRegister($src2$$reg));
16659   %}
16660   ins_pipe(vmul128);
16661 %}
16662 
16663 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16664 %{
16665   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16666   match(Set dst (MulVI src1 src2));
16667   ins_cost(INSN_COST);
16668   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16669   ins_encode %{
16670     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16671             as_FloatRegister($src1$$reg),
16672             as_FloatRegister($src2$$reg));
16673   %}
16674   ins_pipe(vmul64);
16675 %}
16676 
16677 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16678 %{
16679   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16680   match(Set dst (MulVI src1 src2));
16681   ins_cost(INSN_COST);
16682   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16683   ins_encode %{
16684     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16685             as_FloatRegister($src1$$reg),
16686             as_FloatRegister($src2$$reg));
16687   %}
16688   ins_pipe(vmul128);
16689 %}
16690 
16691 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16692 %{
16693   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16694   match(Set dst (MulVF src1 src2));
16695   ins_cost(INSN_COST);
16696   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16697   ins_encode %{
16698     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16699             as_FloatRegister($src1$$reg),
16700             as_FloatRegister($src2$$reg));
16701   %}
16702   ins_pipe(vmuldiv_fp64);
16703 %}
16704 
16705 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16706 %{
16707   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16708   match(Set dst (MulVF src1 src2));
16709   ins_cost(INSN_COST);
16710   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16711   ins_encode %{
16712     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16713             as_FloatRegister($src1$$reg),
16714             as_FloatRegister($src2$$reg));
16715   %}
16716   ins_pipe(vmuldiv_fp128);
16717 %}
16718 
16719 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16720 %{
16721   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16722   match(Set dst (MulVD src1 src2));
16723   ins_cost(INSN_COST);
16724   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16725   ins_encode %{
16726     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16727             as_FloatRegister($src1$$reg),
16728             as_FloatRegister($src2$$reg));
16729   %}
16730   ins_pipe(vmuldiv_fp128);
16731 %}
16732 
16733 // --------------------------------- MLA --------------------------------------
16734 
16735 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16736 %{
16737   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16738             n-&gt;as_Vector()-&gt;length() == 4);
16739   match(Set dst (AddVS dst (MulVS src1 src2)));
16740   ins_cost(INSN_COST);
16741   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16742   ins_encode %{
16743     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16744             as_FloatRegister($src1$$reg),
16745             as_FloatRegister($src2$$reg));
16746   %}
16747   ins_pipe(vmla64);
16748 %}
16749 
16750 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16751 %{
16752   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16753   match(Set dst (AddVS dst (MulVS src1 src2)));
16754   ins_cost(INSN_COST);
16755   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16756   ins_encode %{
16757     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16758             as_FloatRegister($src1$$reg),
16759             as_FloatRegister($src2$$reg));
16760   %}
16761   ins_pipe(vmla128);
16762 %}
16763 
16764 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16765 %{
16766   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16767   match(Set dst (AddVI dst (MulVI src1 src2)));
16768   ins_cost(INSN_COST);
16769   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16770   ins_encode %{
16771     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16772             as_FloatRegister($src1$$reg),
16773             as_FloatRegister($src2$$reg));
16774   %}
16775   ins_pipe(vmla64);
16776 %}
16777 
16778 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16779 %{
16780   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16781   match(Set dst (AddVI dst (MulVI src1 src2)));
16782   ins_cost(INSN_COST);
16783   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16784   ins_encode %{
16785     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16786             as_FloatRegister($src1$$reg),
16787             as_FloatRegister($src2$$reg));
16788   %}
16789   ins_pipe(vmla128);
16790 %}
16791 
16792 // dst + src1 * src2
16793 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16794   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16795   match(Set dst (FmaVF  dst (Binary src1 src2)));
16796   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16797   ins_cost(INSN_COST);
16798   ins_encode %{
16799     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16800             as_FloatRegister($src1$$reg),
16801             as_FloatRegister($src2$$reg));
16802   %}
16803   ins_pipe(vmuldiv_fp64);
16804 %}
16805 
16806 // dst + src1 * src2
16807 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16808   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16809   match(Set dst (FmaVF  dst (Binary src1 src2)));
16810   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16811   ins_cost(INSN_COST);
16812   ins_encode %{
16813     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16814             as_FloatRegister($src1$$reg),
16815             as_FloatRegister($src2$$reg));
16816   %}
16817   ins_pipe(vmuldiv_fp128);
16818 %}
16819 
16820 // dst + src1 * src2
16821 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16822   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16823   match(Set dst (FmaVD  dst (Binary src1 src2)));
16824   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16825   ins_cost(INSN_COST);
16826   ins_encode %{
16827     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16828             as_FloatRegister($src1$$reg),
16829             as_FloatRegister($src2$$reg));
16830   %}
16831   ins_pipe(vmuldiv_fp128);
16832 %}
16833 
16834 // --------------------------------- MLS --------------------------------------
16835 
16836 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16837 %{
16838   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16839             n-&gt;as_Vector()-&gt;length() == 4);
16840   match(Set dst (SubVS dst (MulVS src1 src2)));
16841   ins_cost(INSN_COST);
16842   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16843   ins_encode %{
16844     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16845             as_FloatRegister($src1$$reg),
16846             as_FloatRegister($src2$$reg));
16847   %}
16848   ins_pipe(vmla64);
16849 %}
16850 
16851 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16852 %{
16853   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16854   match(Set dst (SubVS dst (MulVS src1 src2)));
16855   ins_cost(INSN_COST);
16856   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16857   ins_encode %{
16858     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16859             as_FloatRegister($src1$$reg),
16860             as_FloatRegister($src2$$reg));
16861   %}
16862   ins_pipe(vmla128);
16863 %}
16864 
16865 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16866 %{
16867   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16868   match(Set dst (SubVI dst (MulVI src1 src2)));
16869   ins_cost(INSN_COST);
16870   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16871   ins_encode %{
16872     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16873             as_FloatRegister($src1$$reg),
16874             as_FloatRegister($src2$$reg));
16875   %}
16876   ins_pipe(vmla64);
16877 %}
16878 
16879 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16880 %{
16881   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16882   match(Set dst (SubVI dst (MulVI src1 src2)));
16883   ins_cost(INSN_COST);
16884   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16885   ins_encode %{
16886     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16887             as_FloatRegister($src1$$reg),
16888             as_FloatRegister($src2$$reg));
16889   %}
16890   ins_pipe(vmla128);
16891 %}
16892 
16893 // dst - src1 * src2
16894 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16895   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16896   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16897   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16898   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16899   ins_cost(INSN_COST);
16900   ins_encode %{
16901     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16902             as_FloatRegister($src1$$reg),
16903             as_FloatRegister($src2$$reg));
16904   %}
16905   ins_pipe(vmuldiv_fp64);
16906 %}
16907 
16908 // dst - src1 * src2
16909 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16910   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16911   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16912   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16913   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16914   ins_cost(INSN_COST);
16915   ins_encode %{
16916     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16917             as_FloatRegister($src1$$reg),
16918             as_FloatRegister($src2$$reg));
16919   %}
16920   ins_pipe(vmuldiv_fp128);
16921 %}
16922 
16923 // dst - src1 * src2
16924 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16925   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16926   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16927   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16928   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16929   ins_cost(INSN_COST);
16930   ins_encode %{
16931     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16932             as_FloatRegister($src1$$reg),
16933             as_FloatRegister($src2$$reg));
16934   %}
16935   ins_pipe(vmuldiv_fp128);
16936 %}
16937 
16938 // --------------------------------- DIV --------------------------------------
16939 
16940 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
16941 %{
16942   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16943   match(Set dst (DivVF src1 src2));
16944   ins_cost(INSN_COST);
16945   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16946   ins_encode %{
16947     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
16948             as_FloatRegister($src1$$reg),
16949             as_FloatRegister($src2$$reg));
16950   %}
16951   ins_pipe(vmuldiv_fp64);
16952 %}
16953 
16954 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
16955 %{
16956   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16957   match(Set dst (DivVF src1 src2));
16958   ins_cost(INSN_COST);
16959   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16960   ins_encode %{
16961     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
16962             as_FloatRegister($src1$$reg),
16963             as_FloatRegister($src2$$reg));
16964   %}
16965   ins_pipe(vmuldiv_fp128);
16966 %}
16967 
16968 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
16969 %{
16970   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16971   match(Set dst (DivVD src1 src2));
16972   ins_cost(INSN_COST);
16973   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
16974   ins_encode %{
16975     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
16976             as_FloatRegister($src1$$reg),
16977             as_FloatRegister($src2$$reg));
16978   %}
16979   ins_pipe(vmuldiv_fp128);
16980 %}
16981 
16982 // --------------------------------- SQRT -------------------------------------
16983 
16984 instruct vsqrt2D(vecX dst, vecX src)
16985 %{
16986   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16987   match(Set dst (SqrtVD src));
16988   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
16989   ins_encode %{
16990     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
16991              as_FloatRegister($src$$reg));
16992   %}
16993   ins_pipe(vsqrt_fp128);
16994 %}
16995 
16996 // --------------------------------- ABS --------------------------------------
16997 
16998 instruct vabs2F(vecD dst, vecD src)
16999 %{
17000   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17001   match(Set dst (AbsVF src));
17002   ins_cost(INSN_COST * 3);
17003   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17004   ins_encode %{
17005     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17006             as_FloatRegister($src$$reg));
17007   %}
17008   ins_pipe(vunop_fp64);
17009 %}
17010 
17011 instruct vabs4F(vecX dst, vecX src)
17012 %{
17013   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17014   match(Set dst (AbsVF src));
17015   ins_cost(INSN_COST * 3);
17016   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17017   ins_encode %{
17018     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17019             as_FloatRegister($src$$reg));
17020   %}
17021   ins_pipe(vunop_fp128);
17022 %}
17023 
17024 instruct vabs2D(vecX dst, vecX src)
17025 %{
17026   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17027   match(Set dst (AbsVD src));
17028   ins_cost(INSN_COST * 3);
17029   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17030   ins_encode %{
17031     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17032             as_FloatRegister($src$$reg));
17033   %}
17034   ins_pipe(vunop_fp128);
17035 %}
17036 
17037 // --------------------------------- NEG --------------------------------------
17038 
17039 instruct vneg2F(vecD dst, vecD src)
17040 %{
17041   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17042   match(Set dst (NegVF src));
17043   ins_cost(INSN_COST * 3);
17044   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17045   ins_encode %{
17046     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17047             as_FloatRegister($src$$reg));
17048   %}
17049   ins_pipe(vunop_fp64);
17050 %}
17051 
17052 instruct vneg4F(vecX dst, vecX src)
17053 %{
17054   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17055   match(Set dst (NegVF src));
17056   ins_cost(INSN_COST * 3);
17057   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17058   ins_encode %{
17059     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17060             as_FloatRegister($src$$reg));
17061   %}
17062   ins_pipe(vunop_fp128);
17063 %}
17064 
17065 instruct vneg2D(vecX dst, vecX src)
17066 %{
17067   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17068   match(Set dst (NegVD src));
17069   ins_cost(INSN_COST * 3);
17070   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17071   ins_encode %{
17072     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17073             as_FloatRegister($src$$reg));
17074   %}
17075   ins_pipe(vunop_fp128);
17076 %}
17077 
17078 // --------------------------------- AND --------------------------------------
17079 
17080 instruct vand8B(vecD dst, vecD src1, vecD src2)
17081 %{
17082   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17083             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17084   match(Set dst (AndV src1 src2));
17085   ins_cost(INSN_COST);
17086   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17087   ins_encode %{
17088     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17089             as_FloatRegister($src1$$reg),
17090             as_FloatRegister($src2$$reg));
17091   %}
17092   ins_pipe(vlogical64);
17093 %}
17094 
17095 instruct vand16B(vecX dst, vecX src1, vecX src2)
17096 %{
17097   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17098   match(Set dst (AndV src1 src2));
17099   ins_cost(INSN_COST);
17100   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17101   ins_encode %{
17102     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17103             as_FloatRegister($src1$$reg),
17104             as_FloatRegister($src2$$reg));
17105   %}
17106   ins_pipe(vlogical128);
17107 %}
17108 
17109 // --------------------------------- OR ---------------------------------------
17110 
17111 instruct vor8B(vecD dst, vecD src1, vecD src2)
17112 %{
17113   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17114             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17115   match(Set dst (OrV src1 src2));
17116   ins_cost(INSN_COST);
17117   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17118   ins_encode %{
17119     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17120             as_FloatRegister($src1$$reg),
17121             as_FloatRegister($src2$$reg));
17122   %}
17123   ins_pipe(vlogical64);
17124 %}
17125 
17126 instruct vor16B(vecX dst, vecX src1, vecX src2)
17127 %{
17128   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17129   match(Set dst (OrV src1 src2));
17130   ins_cost(INSN_COST);
17131   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17132   ins_encode %{
17133     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17134             as_FloatRegister($src1$$reg),
17135             as_FloatRegister($src2$$reg));
17136   %}
17137   ins_pipe(vlogical128);
17138 %}
17139 
17140 // --------------------------------- XOR --------------------------------------
17141 
17142 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17143 %{
17144   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17145             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17146   match(Set dst (XorV src1 src2));
17147   ins_cost(INSN_COST);
17148   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17149   ins_encode %{
17150     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17151             as_FloatRegister($src1$$reg),
17152             as_FloatRegister($src2$$reg));
17153   %}
17154   ins_pipe(vlogical64);
17155 %}
17156 
17157 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17158 %{
17159   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17160   match(Set dst (XorV src1 src2));
17161   ins_cost(INSN_COST);
17162   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17163   ins_encode %{
17164     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17165             as_FloatRegister($src1$$reg),
17166             as_FloatRegister($src2$$reg));
17167   %}
17168   ins_pipe(vlogical128);
17169 %}
17170 
17171 // ------------------------------ Shift ---------------------------------------
17172 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17173   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17174   match(Set dst (LShiftCntV cnt));
17175   match(Set dst (RShiftCntV cnt));
17176   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17177   ins_encode %{
17178     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17179   %}
17180   ins_pipe(vdup_reg_reg64);
17181 %}
17182 
17183 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17184   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17185   match(Set dst (LShiftCntV cnt));
17186   match(Set dst (RShiftCntV cnt));
17187   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17188   ins_encode %{
17189     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17190   %}
17191   ins_pipe(vdup_reg_reg128);
17192 %}
17193 
17194 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17195   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17196             n-&gt;as_Vector()-&gt;length() == 8);
17197   match(Set dst (LShiftVB src shift));
17198   ins_cost(INSN_COST);
17199   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17200   ins_encode %{
17201     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17202             as_FloatRegister($src$$reg),
17203             as_FloatRegister($shift$$reg));
17204   %}
17205   ins_pipe(vshift64);
17206 %}
17207 
17208 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17209   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17210   match(Set dst (LShiftVB src shift));
17211   ins_cost(INSN_COST);
17212   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17213   ins_encode %{
17214     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17215             as_FloatRegister($src$$reg),
17216             as_FloatRegister($shift$$reg));
17217   %}
17218   ins_pipe(vshift128);
17219 %}
17220 
17221 // Right shifts with vector shift count on aarch64 SIMD are implemented
17222 // as left shift by negative shift count.
17223 // There are two cases for vector shift count.
17224 //
17225 // Case 1: The vector shift count is from replication.
17226 //        |            |
17227 //    LoadVector  RShiftCntV
17228 //        |       /
17229 //     RShiftVI
17230 // Note: In inner loop, multiple neg instructions are used, which can be
17231 // moved to outer loop and merge into one neg instruction.
17232 //
17233 // Case 2: The vector shift count is from loading.
17234 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17235 // panama/vectorIntrinsics(JEP 338: Vector API).
17236 //        |            |
17237 //    LoadVector  LoadVector
17238 //        |       /
17239 //     RShiftVI
17240 //
17241 
17242 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17243   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17244             n-&gt;as_Vector()-&gt;length() == 8);
17245   match(Set dst (RShiftVB src shift));
17246   ins_cost(INSN_COST);
17247   effect(TEMP tmp);
17248   format %{ &quot;negr  $tmp,$shift\t&quot;
17249             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17250   ins_encode %{
17251     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17252             as_FloatRegister($shift$$reg));
17253     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17254             as_FloatRegister($src$$reg),
17255             as_FloatRegister($tmp$$reg));
17256   %}
17257   ins_pipe(vshift64);
17258 %}
17259 
17260 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17261   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17262   match(Set dst (RShiftVB src shift));
17263   ins_cost(INSN_COST);
17264   effect(TEMP tmp);
17265   format %{ &quot;negr  $tmp,$shift\t&quot;
17266             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17267   ins_encode %{
17268     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17269             as_FloatRegister($shift$$reg));
17270     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17271             as_FloatRegister($src$$reg),
17272             as_FloatRegister($tmp$$reg));
17273   %}
17274   ins_pipe(vshift128);
17275 %}
17276 
17277 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17278   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17279             n-&gt;as_Vector()-&gt;length() == 8);
17280   match(Set dst (URShiftVB src shift));
17281   ins_cost(INSN_COST);
17282   effect(TEMP tmp);
17283   format %{ &quot;negr  $tmp,$shift\t&quot;
17284             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17285   ins_encode %{
17286     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17287             as_FloatRegister($shift$$reg));
17288     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17289             as_FloatRegister($src$$reg),
17290             as_FloatRegister($tmp$$reg));
17291   %}
17292   ins_pipe(vshift64);
17293 %}
17294 
17295 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17296   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17297   match(Set dst (URShiftVB src shift));
17298   ins_cost(INSN_COST);
17299   effect(TEMP tmp);
17300   format %{ &quot;negr  $tmp,$shift\t&quot;
17301             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17302   ins_encode %{
17303     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17304             as_FloatRegister($shift$$reg));
17305     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17306             as_FloatRegister($src$$reg),
17307             as_FloatRegister($tmp$$reg));
17308   %}
17309   ins_pipe(vshift128);
17310 %}
17311 
17312 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17313   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17314             n-&gt;as_Vector()-&gt;length() == 8);
17315   match(Set dst (LShiftVB src (LShiftCntV shift)));
17316   ins_cost(INSN_COST);
17317   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17318   ins_encode %{
17319     int sh = (int)$shift$$constant;
17320     if (sh &gt;= 8) {
17321       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17322              as_FloatRegister($src$$reg),
17323              as_FloatRegister($src$$reg));
17324     } else {
17325       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17326              as_FloatRegister($src$$reg), sh);
17327     }
17328   %}
17329   ins_pipe(vshift64_imm);
17330 %}
17331 
17332 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17333   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17334   match(Set dst (LShiftVB src (LShiftCntV shift)));
17335   ins_cost(INSN_COST);
17336   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17337   ins_encode %{
17338     int sh = (int)$shift$$constant;
17339     if (sh &gt;= 8) {
17340       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17341              as_FloatRegister($src$$reg),
17342              as_FloatRegister($src$$reg));
17343     } else {
17344       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17345              as_FloatRegister($src$$reg), sh);
17346     }
17347   %}
17348   ins_pipe(vshift128_imm);
17349 %}
17350 
17351 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17352   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17353             n-&gt;as_Vector()-&gt;length() == 8);
17354   match(Set dst (RShiftVB src (RShiftCntV shift)));
17355   ins_cost(INSN_COST);
17356   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17357   ins_encode %{
17358     int sh = (int)$shift$$constant;
17359     if (sh &gt;= 8) sh = 7;
17360     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17361            as_FloatRegister($src$$reg), sh);
17362   %}
17363   ins_pipe(vshift64_imm);
17364 %}
17365 
17366 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17367   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17368   match(Set dst (RShiftVB src (RShiftCntV shift)));
17369   ins_cost(INSN_COST);
17370   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17371   ins_encode %{
17372     int sh = (int)$shift$$constant;
17373     if (sh &gt;= 8) sh = 7;
17374     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17375            as_FloatRegister($src$$reg), sh);
17376   %}
17377   ins_pipe(vshift128_imm);
17378 %}
17379 
17380 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17381   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17382             n-&gt;as_Vector()-&gt;length() == 8);
17383   match(Set dst (URShiftVB src (RShiftCntV shift)));
17384   ins_cost(INSN_COST);
17385   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17386   ins_encode %{
17387     int sh = (int)$shift$$constant;
17388     if (sh &gt;= 8) {
17389       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17390              as_FloatRegister($src$$reg),
17391              as_FloatRegister($src$$reg));
17392     } else {
17393       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17394              as_FloatRegister($src$$reg), sh);
17395     }
17396   %}
17397   ins_pipe(vshift64_imm);
17398 %}
17399 
17400 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17401   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17402   match(Set dst (URShiftVB src (RShiftCntV shift)));
17403   ins_cost(INSN_COST);
17404   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17405   ins_encode %{
17406     int sh = (int)$shift$$constant;
17407     if (sh &gt;= 8) {
17408       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17409              as_FloatRegister($src$$reg),
17410              as_FloatRegister($src$$reg));
17411     } else {
17412       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17413              as_FloatRegister($src$$reg), sh);
17414     }
17415   %}
17416   ins_pipe(vshift128_imm);
17417 %}
17418 
17419 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17420   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17421             n-&gt;as_Vector()-&gt;length() == 4);
17422   match(Set dst (LShiftVS src shift));
17423   ins_cost(INSN_COST);
17424   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17425   ins_encode %{
17426     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17427             as_FloatRegister($src$$reg),
17428             as_FloatRegister($shift$$reg));
17429   %}
17430   ins_pipe(vshift64);
17431 %}
17432 
17433 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17434   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17435   match(Set dst (LShiftVS src shift));
17436   ins_cost(INSN_COST);
17437   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17438   ins_encode %{
17439     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17440             as_FloatRegister($src$$reg),
17441             as_FloatRegister($shift$$reg));
17442   %}
17443   ins_pipe(vshift128);
17444 %}
17445 
17446 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17447   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17448             n-&gt;as_Vector()-&gt;length() == 4);
17449   match(Set dst (RShiftVS src shift));
17450   ins_cost(INSN_COST);
17451   effect(TEMP tmp);
17452   format %{ &quot;negr  $tmp,$shift\t&quot;
17453             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17454   ins_encode %{
17455     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17456             as_FloatRegister($shift$$reg));
17457     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17458             as_FloatRegister($src$$reg),
17459             as_FloatRegister($tmp$$reg));
17460   %}
17461   ins_pipe(vshift64);
17462 %}
17463 
17464 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17465   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17466   match(Set dst (RShiftVS src shift));
17467   ins_cost(INSN_COST);
17468   effect(TEMP tmp);
17469   format %{ &quot;negr  $tmp,$shift\t&quot;
17470             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17471   ins_encode %{
17472     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17473             as_FloatRegister($shift$$reg));
17474     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17475             as_FloatRegister($src$$reg),
17476             as_FloatRegister($tmp$$reg));
17477   %}
17478   ins_pipe(vshift128);
17479 %}
17480 
17481 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17482   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17483             n-&gt;as_Vector()-&gt;length() == 4);
17484   match(Set dst (URShiftVS src shift));
17485   ins_cost(INSN_COST);
17486   effect(TEMP tmp);
17487   format %{ &quot;negr  $tmp,$shift\t&quot;
17488             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17489   ins_encode %{
17490     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17491             as_FloatRegister($shift$$reg));
17492     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17493             as_FloatRegister($src$$reg),
17494             as_FloatRegister($tmp$$reg));
17495   %}
17496   ins_pipe(vshift64);
17497 %}
17498 
17499 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17500   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17501   match(Set dst (URShiftVS src shift));
17502   ins_cost(INSN_COST);
17503   effect(TEMP tmp);
17504   format %{ &quot;negr  $tmp,$shift\t&quot;
17505             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17506   ins_encode %{
17507     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17508             as_FloatRegister($shift$$reg));
17509     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17510             as_FloatRegister($src$$reg),
17511             as_FloatRegister($tmp$$reg));
17512   %}
17513   ins_pipe(vshift128);
17514 %}
17515 
17516 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17517   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17518             n-&gt;as_Vector()-&gt;length() == 4);
17519   match(Set dst (LShiftVS src (LShiftCntV shift)));
17520   ins_cost(INSN_COST);
17521   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17522   ins_encode %{
17523     int sh = (int)$shift$$constant;
17524     if (sh &gt;= 16) {
17525       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17526              as_FloatRegister($src$$reg),
17527              as_FloatRegister($src$$reg));
17528     } else {
17529       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17530              as_FloatRegister($src$$reg), sh);
17531     }
17532   %}
17533   ins_pipe(vshift64_imm);
17534 %}
17535 
17536 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17537   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17538   match(Set dst (LShiftVS src (LShiftCntV shift)));
17539   ins_cost(INSN_COST);
17540   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17541   ins_encode %{
17542     int sh = (int)$shift$$constant;
17543     if (sh &gt;= 16) {
17544       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17545              as_FloatRegister($src$$reg),
17546              as_FloatRegister($src$$reg));
17547     } else {
17548       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17549              as_FloatRegister($src$$reg), sh);
17550     }
17551   %}
17552   ins_pipe(vshift128_imm);
17553 %}
17554 
17555 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17556   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17557             n-&gt;as_Vector()-&gt;length() == 4);
17558   match(Set dst (RShiftVS src (LShiftCntV shift)));
17559   ins_cost(INSN_COST);
17560   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17561   ins_encode %{
17562     int sh = (int)$shift$$constant;
17563     if (sh &gt;= 16) sh = 15;
17564     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17565            as_FloatRegister($src$$reg), sh);
17566   %}
17567   ins_pipe(vshift64_imm);
17568 %}
17569 
17570 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17571   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17572   match(Set dst (RShiftVS src (LShiftCntV shift)));
17573   ins_cost(INSN_COST);
17574   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17575   ins_encode %{
17576     int sh = (int)$shift$$constant;
17577     if (sh &gt;= 16) sh = 15;
17578     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17579            as_FloatRegister($src$$reg), sh);
17580   %}
17581   ins_pipe(vshift128_imm);
17582 %}
17583 
17584 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17585   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17586             n-&gt;as_Vector()-&gt;length() == 4);
17587   match(Set dst (URShiftVS src (RShiftCntV shift)));
17588   ins_cost(INSN_COST);
17589   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17590   ins_encode %{
17591     int sh = (int)$shift$$constant;
17592     if (sh &gt;= 16) {
17593       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17594              as_FloatRegister($src$$reg),
17595              as_FloatRegister($src$$reg));
17596     } else {
17597       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17598              as_FloatRegister($src$$reg), sh);
17599     }
17600   %}
17601   ins_pipe(vshift64_imm);
17602 %}
17603 
17604 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17605   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17606   match(Set dst (URShiftVS src (RShiftCntV shift)));
17607   ins_cost(INSN_COST);
17608   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17609   ins_encode %{
17610     int sh = (int)$shift$$constant;
17611     if (sh &gt;= 16) {
17612       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17613              as_FloatRegister($src$$reg),
17614              as_FloatRegister($src$$reg));
17615     } else {
17616       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17617              as_FloatRegister($src$$reg), sh);
17618     }
17619   %}
17620   ins_pipe(vshift128_imm);
17621 %}
17622 
17623 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17624   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17625   match(Set dst (LShiftVI src shift));
17626   ins_cost(INSN_COST);
17627   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17628   ins_encode %{
17629     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17630             as_FloatRegister($src$$reg),
17631             as_FloatRegister($shift$$reg));
17632   %}
17633   ins_pipe(vshift64);
17634 %}
17635 
17636 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17637   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17638   match(Set dst (LShiftVI src shift));
17639   ins_cost(INSN_COST);
17640   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17641   ins_encode %{
17642     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17643             as_FloatRegister($src$$reg),
17644             as_FloatRegister($shift$$reg));
17645   %}
17646   ins_pipe(vshift128);
17647 %}
17648 
17649 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17650   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17651   match(Set dst (RShiftVI src shift));
17652   ins_cost(INSN_COST);
17653   effect(TEMP tmp);
17654   format %{ &quot;negr  $tmp,$shift\t&quot;
17655             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17656   ins_encode %{
17657     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17658             as_FloatRegister($shift$$reg));
17659     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17660             as_FloatRegister($src$$reg),
17661             as_FloatRegister($tmp$$reg));
17662   %}
17663   ins_pipe(vshift64);
17664 %}
17665 
17666 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17667   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17668   match(Set dst (RShiftVI src shift));
17669   ins_cost(INSN_COST);
17670   effect(TEMP tmp);
17671   format %{ &quot;negr  $tmp,$shift\t&quot;
17672             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17673   ins_encode %{
17674     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17675             as_FloatRegister($shift$$reg));
17676     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17677             as_FloatRegister($src$$reg),
17678             as_FloatRegister($tmp$$reg));
17679   %}
17680   ins_pipe(vshift128);
17681 %}
17682 
17683 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17684   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17685   match(Set dst (URShiftVI src shift));
17686   ins_cost(INSN_COST);
17687   effect(TEMP tmp);
17688   format %{ &quot;negr  $tmp,$shift\t&quot;
17689             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17690   ins_encode %{
17691     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17692             as_FloatRegister($shift$$reg));
17693     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17694             as_FloatRegister($src$$reg),
17695             as_FloatRegister($tmp$$reg));
17696   %}
17697   ins_pipe(vshift64);
17698 %}
17699 
17700 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17701   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17702   match(Set dst (URShiftVI src shift));
17703   ins_cost(INSN_COST);
17704   effect(TEMP tmp);
17705   format %{ &quot;negr  $tmp,$shift\t&quot;
17706             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17707   ins_encode %{
17708     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17709             as_FloatRegister($shift$$reg));
17710     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17711             as_FloatRegister($src$$reg),
17712             as_FloatRegister($tmp$$reg));
17713   %}
17714   ins_pipe(vshift128);
17715 %}
17716 
17717 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17718   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17719   match(Set dst (LShiftVI src (LShiftCntV shift)));
17720   ins_cost(INSN_COST);
17721   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17722   ins_encode %{
17723     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17724            as_FloatRegister($src$$reg),
17725            (int)$shift$$constant);
17726   %}
17727   ins_pipe(vshift64_imm);
17728 %}
17729 
17730 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17731   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17732   match(Set dst (LShiftVI src (LShiftCntV shift)));
17733   ins_cost(INSN_COST);
17734   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17735   ins_encode %{
17736     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17737            as_FloatRegister($src$$reg),
17738            (int)$shift$$constant);
17739   %}
17740   ins_pipe(vshift128_imm);
17741 %}
17742 
17743 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17744   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17745   match(Set dst (RShiftVI src (RShiftCntV shift)));
17746   ins_cost(INSN_COST);
17747   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17748   ins_encode %{
17749     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17750             as_FloatRegister($src$$reg),
17751             (int)$shift$$constant);
17752   %}
17753   ins_pipe(vshift64_imm);
17754 %}
17755 
17756 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17757   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17758   match(Set dst (RShiftVI src (RShiftCntV shift)));
17759   ins_cost(INSN_COST);
17760   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17761   ins_encode %{
17762     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17763             as_FloatRegister($src$$reg),
17764             (int)$shift$$constant);
17765   %}
17766   ins_pipe(vshift128_imm);
17767 %}
17768 
17769 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17770   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17771   match(Set dst (URShiftVI src (RShiftCntV shift)));
17772   ins_cost(INSN_COST);
17773   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17774   ins_encode %{
17775     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17776             as_FloatRegister($src$$reg),
17777             (int)$shift$$constant);
17778   %}
17779   ins_pipe(vshift64_imm);
17780 %}
17781 
17782 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17783   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17784   match(Set dst (URShiftVI src (RShiftCntV shift)));
17785   ins_cost(INSN_COST);
17786   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17787   ins_encode %{
17788     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17789             as_FloatRegister($src$$reg),
17790             (int)$shift$$constant);
17791   %}
17792   ins_pipe(vshift128_imm);
17793 %}
17794 
17795 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17796   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17797   match(Set dst (LShiftVL src shift));
17798   ins_cost(INSN_COST);
17799   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17800   ins_encode %{
17801     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17802             as_FloatRegister($src$$reg),
17803             as_FloatRegister($shift$$reg));
17804   %}
17805   ins_pipe(vshift128);
17806 %}
17807 
17808 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17809   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17810   match(Set dst (RShiftVL src shift));
17811   ins_cost(INSN_COST);
17812   effect(TEMP tmp);
17813   format %{ &quot;negr  $tmp,$shift\t&quot;
17814             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17815   ins_encode %{
17816     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17817             as_FloatRegister($shift$$reg));
17818     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17819             as_FloatRegister($src$$reg),
17820             as_FloatRegister($tmp$$reg));
17821   %}
17822   ins_pipe(vshift128);
17823 %}
17824 
17825 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17826   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17827   match(Set dst (URShiftVL src shift));
17828   ins_cost(INSN_COST);
17829   effect(TEMP tmp);
17830   format %{ &quot;negr  $tmp,$shift\t&quot;
17831             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17832   ins_encode %{
17833     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17834             as_FloatRegister($shift$$reg));
17835     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
17836             as_FloatRegister($src$$reg),
17837             as_FloatRegister($tmp$$reg));
17838   %}
17839   ins_pipe(vshift128);
17840 %}
17841 
17842 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
17843   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17844   match(Set dst (LShiftVL src (LShiftCntV shift)));
17845   ins_cost(INSN_COST);
17846   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
17847   ins_encode %{
17848     __ shl(as_FloatRegister($dst$$reg), __ T2D,
17849            as_FloatRegister($src$$reg),
17850            (int)$shift$$constant);
17851   %}
17852   ins_pipe(vshift128_imm);
17853 %}
17854 
17855 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
17856   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17857   match(Set dst (RShiftVL src (RShiftCntV shift)));
17858   ins_cost(INSN_COST);
17859   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
17860   ins_encode %{
17861     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
17862             as_FloatRegister($src$$reg),
17863             (int)$shift$$constant);
17864   %}
17865   ins_pipe(vshift128_imm);
17866 %}
17867 
17868 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
17869   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17870   match(Set dst (URShiftVL src (RShiftCntV shift)));
17871   ins_cost(INSN_COST);
17872   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
17873   ins_encode %{
17874     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
17875             as_FloatRegister($src$$reg),
17876             (int)$shift$$constant);
17877   %}
17878   ins_pipe(vshift128_imm);
17879 %}
17880 
17881 instruct vmax2F(vecD dst, vecD src1, vecD src2)
17882 %{
17883   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17884   match(Set dst (MaxV src1 src2));
17885   ins_cost(INSN_COST);
17886   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
17887   ins_encode %{
17888     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
17889             as_FloatRegister($src1$$reg),
17890             as_FloatRegister($src2$$reg));
17891   %}
17892   ins_pipe(vdop_fp64);
17893 %}
17894 
17895 instruct vmax4F(vecX dst, vecX src1, vecX src2)
17896 %{
17897   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17898   match(Set dst (MaxV src1 src2));
17899   ins_cost(INSN_COST);
17900   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
17901   ins_encode %{
17902     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
17903             as_FloatRegister($src1$$reg),
17904             as_FloatRegister($src2$$reg));
17905   %}
17906   ins_pipe(vdop_fp128);
17907 %}
17908 
17909 instruct vmax2D(vecX dst, vecX src1, vecX src2)
17910 %{
17911   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17912   match(Set dst (MaxV src1 src2));
17913   ins_cost(INSN_COST);
17914   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
17915   ins_encode %{
17916     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
17917             as_FloatRegister($src1$$reg),
17918             as_FloatRegister($src2$$reg));
17919   %}
17920   ins_pipe(vdop_fp128);
17921 %}
17922 
17923 instruct vmin2F(vecD dst, vecD src1, vecD src2)
17924 %{
17925   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17926   match(Set dst (MinV src1 src2));
17927   ins_cost(INSN_COST);
17928   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
17929   ins_encode %{
17930     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
17931             as_FloatRegister($src1$$reg),
17932             as_FloatRegister($src2$$reg));
17933   %}
17934   ins_pipe(vdop_fp64);
17935 %}
17936 
17937 instruct vmin4F(vecX dst, vecX src1, vecX src2)
17938 %{
17939   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17940   match(Set dst (MinV src1 src2));
17941   ins_cost(INSN_COST);
17942   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
17943   ins_encode %{
17944     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
17945             as_FloatRegister($src1$$reg),
17946             as_FloatRegister($src2$$reg));
17947   %}
17948   ins_pipe(vdop_fp128);
17949 %}
17950 
17951 instruct vmin2D(vecX dst, vecX src1, vecX src2)
17952 %{
17953   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17954   match(Set dst (MinV src1 src2));
17955   ins_cost(INSN_COST);
17956   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
17957   ins_encode %{
17958     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
17959             as_FloatRegister($src1$$reg),
17960             as_FloatRegister($src2$$reg));
17961   %}
17962   ins_pipe(vdop_fp128);
17963 %}
17964 
17965 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
17966   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17967   match(Set dst (RoundDoubleModeV src rmode));
17968   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
17969   ins_encode %{
17970     switch ($rmode$$constant) {
17971       case RoundDoubleModeNode::rmode_rint:
17972         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
17973                   as_FloatRegister($src$$reg));
17974         break;
17975       case RoundDoubleModeNode::rmode_floor:
17976         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
17977                   as_FloatRegister($src$$reg));
17978         break;
17979       case RoundDoubleModeNode::rmode_ceil:
17980         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
17981                   as_FloatRegister($src$$reg));
17982         break;
17983     }
17984   %}
17985   ins_pipe(vdop_fp128);
17986 %}
17987 
17988 //----------PEEPHOLE RULES-----------------------------------------------------
17989 // These must follow all instruction definitions as they use the names
17990 // defined in the instructions definitions.
17991 //
17992 // peepmatch ( root_instr_name [preceding_instruction]* );
17993 //
17994 // peepconstraint %{
17995 // (instruction_number.operand_name relational_op instruction_number.operand_name
17996 //  [, ...] );
17997 // // instruction numbers are zero-based using left to right order in peepmatch
17998 //
17999 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18000 // // provide an instruction_number.operand_name for each operand that appears
18001 // // in the replacement instruction&#39;s match rule
18002 //
18003 // ---------VM FLAGS---------------------------------------------------------
18004 //
18005 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18006 //
18007 // Each peephole rule is given an identifying number starting with zero and
18008 // increasing by one in the order seen by the parser.  An individual peephole
18009 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18010 // on the command-line.
18011 //
18012 // ---------CURRENT LIMITATIONS----------------------------------------------
18013 //
18014 // Only match adjacent instructions in same basic block
18015 // Only equality constraints
18016 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18017 // Only one replacement instruction
18018 //
18019 // ---------EXAMPLE----------------------------------------------------------
18020 //
18021 // // pertinent parts of existing instructions in architecture description
18022 // instruct movI(iRegINoSp dst, iRegI src)
18023 // %{
18024 //   match(Set dst (CopyI src));
18025 // %}
18026 //
18027 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18028 // %{
18029 //   match(Set dst (AddI dst src));
18030 //   effect(KILL cr);
18031 // %}
18032 //
18033 // // Change (inc mov) to lea
18034 // peephole %{
18035 //   // increment preceeded by register-register move
18036 //   peepmatch ( incI_iReg movI );
18037 //   // require that the destination register of the increment
18038 //   // match the destination register of the move
18039 //   peepconstraint ( 0.dst == 1.dst );
18040 //   // construct a replacement instruction that sets
18041 //   // the destination to ( move&#39;s source register + one )
18042 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18043 // %}
18044 //
18045 
18046 // Implementation no longer uses movX instructions since
18047 // machine-independent system no longer uses CopyX nodes.
18048 //
18049 // peephole
18050 // %{
18051 //   peepmatch (incI_iReg movI);
18052 //   peepconstraint (0.dst == 1.dst);
18053 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18054 // %}
18055 
18056 // peephole
18057 // %{
18058 //   peepmatch (decI_iReg movI);
18059 //   peepconstraint (0.dst == 1.dst);
18060 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18061 // %}
18062 
18063 // peephole
18064 // %{
18065 //   peepmatch (addI_iReg_imm movI);
18066 //   peepconstraint (0.dst == 1.dst);
18067 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18068 // %}
18069 
18070 // peephole
18071 // %{
18072 //   peepmatch (incL_iReg movL);
18073 //   peepconstraint (0.dst == 1.dst);
18074 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18075 // %}
18076 
18077 // peephole
18078 // %{
18079 //   peepmatch (decL_iReg movL);
18080 //   peepconstraint (0.dst == 1.dst);
18081 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18082 // %}
18083 
18084 // peephole
18085 // %{
18086 //   peepmatch (addL_iReg_imm movL);
18087 //   peepconstraint (0.dst == 1.dst);
18088 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18089 // %}
18090 
18091 // peephole
18092 // %{
18093 //   peepmatch (addP_iReg_imm movP);
18094 //   peepconstraint (0.dst == 1.dst);
18095 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18096 // %}
18097 
18098 // // Change load of spilled value to only a spill
18099 // instruct storeI(memory mem, iRegI src)
18100 // %{
18101 //   match(Set mem (StoreI mem src));
18102 // %}
18103 //
18104 // instruct loadI(iRegINoSp dst, memory mem)
18105 // %{
18106 //   match(Set dst (LoadI mem));
18107 // %}
18108 //
18109 
18110 //----------SMARTSPILL RULES---------------------------------------------------
18111 // These must follow all instruction definitions as they use the names
18112 // defined in the instructions definitions.
18113 
18114 // Local Variables:
18115 // mode: c++
18116 // End:
    </pre>
  </body>
</html>