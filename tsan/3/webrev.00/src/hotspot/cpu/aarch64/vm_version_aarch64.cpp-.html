<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/cpu/aarch64/vm_version_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 1997, 2018, Oracle and/or its affiliates. All rights reserved.
  3  * Copyright (c) 2015, Red Hat Inc. All rights reserved.
  4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5  *
  6  * This code is free software; you can redistribute it and/or modify it
  7  * under the terms of the GNU General Public License version 2 only, as
  8  * published by the Free Software Foundation.
  9  *
 10  * This code is distributed in the hope that it will be useful, but WITHOUT
 11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13  * version 2 for more details (a copy is included in the LICENSE file that
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
 23  *
 24  */
 25 
 26 #include &quot;precompiled.hpp&quot;
 27 #include &quot;asm/macroAssembler.hpp&quot;
 28 #include &quot;asm/macroAssembler.inline.hpp&quot;
 29 #include &quot;memory/resourceArea.hpp&quot;
 30 #include &quot;runtime/java.hpp&quot;
 31 #include &quot;runtime/stubCodeGenerator.hpp&quot;
 32 #include &quot;utilities/macros.hpp&quot;
 33 #include &quot;vm_version_aarch64.hpp&quot;
 34 
 35 #include OS_HEADER_INLINE(os)
 36 
 37 #ifndef BUILTIN_SIM
 38 #include &lt;sys/auxv.h&gt;
 39 #include &lt;asm/hwcap.h&gt;
 40 #else
 41 #define getauxval(hwcap) 0
 42 #endif
 43 
 44 #ifndef HWCAP_AES
 45 #define HWCAP_AES   (1&lt;&lt;3)
 46 #endif
 47 
 48 #ifndef HWCAP_PMULL
 49 #define HWCAP_PMULL (1&lt;&lt;4)
 50 #endif
 51 
 52 #ifndef HWCAP_SHA1
 53 #define HWCAP_SHA1  (1&lt;&lt;5)
 54 #endif
 55 
 56 #ifndef HWCAP_SHA2
 57 #define HWCAP_SHA2  (1&lt;&lt;6)
 58 #endif
 59 
 60 #ifndef HWCAP_CRC32
 61 #define HWCAP_CRC32 (1&lt;&lt;7)
 62 #endif
 63 
 64 #ifndef HWCAP_ATOMICS
 65 #define HWCAP_ATOMICS (1&lt;&lt;8)
 66 #endif
 67 
 68 int VM_Version::_cpu;
 69 int VM_Version::_model;
 70 int VM_Version::_model2;
 71 int VM_Version::_variant;
 72 int VM_Version::_revision;
 73 int VM_Version::_stepping;
 74 VM_Version::PsrInfo VM_Version::_psr_info   = { 0, };
 75 
 76 static BufferBlob* stub_blob;
 77 static const int stub_size = 550;
 78 
 79 extern &quot;C&quot; {
 80   typedef void (*getPsrInfo_stub_t)(void*);
 81 }
 82 static getPsrInfo_stub_t getPsrInfo_stub = NULL;
 83 
 84 
 85 class VM_Version_StubGenerator: public StubCodeGenerator {
 86  public:
 87 
 88   VM_Version_StubGenerator(CodeBuffer *c) : StubCodeGenerator(c) {}
 89 
 90   address generate_getPsrInfo() {
 91     StubCodeMark mark(this, &quot;VM_Version&quot;, &quot;getPsrInfo_stub&quot;);
 92 #   define __ _masm-&gt;
 93     address start = __ pc();
 94 
 95 #ifdef BUILTIN_SIM
 96     __ c_stub_prolog(1, 0, MacroAssembler::ret_type_void);
 97 #endif
 98 
 99     // void getPsrInfo(VM_Version::PsrInfo* psr_info);
100 
101     address entry = __ pc();
102 
103     __ enter();
104 
105     __ get_dczid_el0(rscratch1);
106     __ strw(rscratch1, Address(c_rarg0, in_bytes(VM_Version::dczid_el0_offset())));
107 
108     __ get_ctr_el0(rscratch1);
109     __ strw(rscratch1, Address(c_rarg0, in_bytes(VM_Version::ctr_el0_offset())));
110 
111     __ leave();
112     __ ret(lr);
113 
114 #   undef __
115 
116     return start;
117   }
118 };
119 
120 
121 void VM_Version::get_processor_features() {
122   _supports_cx8 = true;
123   _supports_atomic_getset4 = true;
124   _supports_atomic_getadd4 = true;
125   _supports_atomic_getset8 = true;
126   _supports_atomic_getadd8 = true;
127 
128   getPsrInfo_stub(&amp;_psr_info);
129 
130   int dcache_line = VM_Version::dcache_line_size();
131 
132   if (FLAG_IS_DEFAULT(AllocatePrefetchDistance))
133     FLAG_SET_DEFAULT(AllocatePrefetchDistance, 3*dcache_line);
134   if (FLAG_IS_DEFAULT(AllocatePrefetchStepSize))
135     FLAG_SET_DEFAULT(AllocatePrefetchStepSize, dcache_line);
136   if (FLAG_IS_DEFAULT(PrefetchScanIntervalInBytes))
137     FLAG_SET_DEFAULT(PrefetchScanIntervalInBytes, 3*dcache_line);
138   if (FLAG_IS_DEFAULT(PrefetchCopyIntervalInBytes))
139     FLAG_SET_DEFAULT(PrefetchCopyIntervalInBytes, 3*dcache_line);
140   if (FLAG_IS_DEFAULT(SoftwarePrefetchHintDistance))
141     FLAG_SET_DEFAULT(SoftwarePrefetchHintDistance, 3*dcache_line);
142 
143   if (PrefetchCopyIntervalInBytes != -1 &amp;&amp;
144        ((PrefetchCopyIntervalInBytes &amp; 7) || (PrefetchCopyIntervalInBytes &gt;= 32768))) {
145     warning(&quot;PrefetchCopyIntervalInBytes must be -1, or a multiple of 8 and &lt; 32768&quot;);
146     PrefetchCopyIntervalInBytes &amp;= ~7;
147     if (PrefetchCopyIntervalInBytes &gt;= 32768)
148       PrefetchCopyIntervalInBytes = 32760;
149   }
150 
151   if (AllocatePrefetchDistance !=-1 &amp;&amp; (AllocatePrefetchDistance &amp; 7)) {
152     warning(&quot;AllocatePrefetchDistance must be multiple of 8&quot;);
153     AllocatePrefetchDistance &amp;= ~7;
154   }
155 
156   if (AllocatePrefetchStepSize &amp; 7) {
157     warning(&quot;AllocatePrefetchStepSize must be multiple of 8&quot;);
158     AllocatePrefetchStepSize &amp;= ~7;
159   }
160 
161   if (SoftwarePrefetchHintDistance != -1 &amp;&amp;
162        (SoftwarePrefetchHintDistance &amp; 7)) {
163     warning(&quot;SoftwarePrefetchHintDistance must be -1, or a multiple of 8&quot;);
164     SoftwarePrefetchHintDistance &amp;= ~7;
165   }
166 
167   unsigned long auxv = getauxval(AT_HWCAP);
168 
169   char buf[512];
170 
171   _features = auxv;
172 
173   int cpu_lines = 0;
174   if (FILE *f = fopen(&quot;/proc/cpuinfo&quot;, &quot;r&quot;)) {
175     char buf[128], *p;
176     while (fgets(buf, sizeof (buf), f) != NULL) {
177       if (p = strchr(buf, &#39;:&#39;)) {
178         long v = strtol(p+1, NULL, 0);
179         if (strncmp(buf, &quot;CPU implementer&quot;, sizeof &quot;CPU implementer&quot; - 1) == 0) {
180           _cpu = v;
181           cpu_lines++;
182         } else if (strncmp(buf, &quot;CPU variant&quot;, sizeof &quot;CPU variant&quot; - 1) == 0) {
183           _variant = v;
184         } else if (strncmp(buf, &quot;CPU part&quot;, sizeof &quot;CPU part&quot; - 1) == 0) {
185           if (_model != v)  _model2 = _model;
186           _model = v;
187         } else if (strncmp(buf, &quot;CPU revision&quot;, sizeof &quot;CPU revision&quot; - 1) == 0) {
188           _revision = v;
189         }
190       }
191     }
192     fclose(f);
193   }
194 
195   // Enable vendor specific features
196 
197   // Ampere eMAG
198   if (_cpu == CPU_AMCC &amp;&amp; (_model == 0) &amp;&amp; (_variant == 0x3)) {
199     if (FLAG_IS_DEFAULT(AvoidUnalignedAccesses)) {
200       FLAG_SET_DEFAULT(AvoidUnalignedAccesses, true);
201     }
202     if (FLAG_IS_DEFAULT(UseSIMDForMemoryOps)) {
203       FLAG_SET_DEFAULT(UseSIMDForMemoryOps, true);
204     }
205     if (FLAG_IS_DEFAULT(UseSIMDForArrayEquals)) {
206       FLAG_SET_DEFAULT(UseSIMDForArrayEquals, !(_revision == 1 || _revision == 2));
207     }
208   }
209 
210   // ThunderX
211   if (_cpu == CPU_CAVIUM &amp;&amp; (_model == 0xA1)) {
212     if (_variant == 0) _features |= CPU_DMB_ATOMICS;
213     if (FLAG_IS_DEFAULT(AvoidUnalignedAccesses)) {
214       FLAG_SET_DEFAULT(AvoidUnalignedAccesses, true);
215     }
216     if (FLAG_IS_DEFAULT(UseSIMDForMemoryOps)) {
217       FLAG_SET_DEFAULT(UseSIMDForMemoryOps, (_variant &gt; 0));
218     }
219     if (FLAG_IS_DEFAULT(UseSIMDForArrayEquals)) {
220       FLAG_SET_DEFAULT(UseSIMDForArrayEquals, false);
221     }
222   }
223 
224   // ThunderX2
225   if ((_cpu == CPU_CAVIUM &amp;&amp; (_model == 0xAF)) ||
226       (_cpu == CPU_BROADCOM &amp;&amp; (_model == 0x516))) {
227     if (FLAG_IS_DEFAULT(AvoidUnalignedAccesses)) {
228       FLAG_SET_DEFAULT(AvoidUnalignedAccesses, true);
229     }
230     if (FLAG_IS_DEFAULT(UseSIMDForMemoryOps)) {
231       FLAG_SET_DEFAULT(UseSIMDForMemoryOps, true);
232     }
233   }
234 
235   // HiSilicon TSV110
236   if (_cpu == CPU_HISILICON &amp;&amp; _model == 0xd01) {
237     if (FLAG_IS_DEFAULT(AvoidUnalignedAccesses)) {
238       FLAG_SET_DEFAULT(AvoidUnalignedAccesses, true);
239     }
240     if (FLAG_IS_DEFAULT(UseSIMDForMemoryOps)) {
241       FLAG_SET_DEFAULT(UseSIMDForMemoryOps, true);
242     }
243   }
244 
245   // Cortex A53
246   if (_cpu == CPU_ARM &amp;&amp; (_model == 0xd03 || _model2 == 0xd03)) {
247     _features |= CPU_A53MAC;
248     if (FLAG_IS_DEFAULT(UseSIMDForArrayEquals)) {
249       FLAG_SET_DEFAULT(UseSIMDForArrayEquals, false);
250     }
251   }
252 
253   // Cortex A73
254   if (_cpu == CPU_ARM &amp;&amp; (_model == 0xd09 || _model2 == 0xd09)) {
255     if (FLAG_IS_DEFAULT(SoftwarePrefetchHintDistance)) {
256       FLAG_SET_DEFAULT(SoftwarePrefetchHintDistance, -1);
257     }
258     // A73 is faster with short-and-easy-for-speculative-execution-loop
259     if (FLAG_IS_DEFAULT(UseSimpleArrayEquals)) {
260       FLAG_SET_DEFAULT(UseSimpleArrayEquals, true);
261     }
262   }
263 
264   if (_cpu == CPU_ARM &amp;&amp; (_model == 0xd07 || _model2 == 0xd07)) _features |= CPU_STXR_PREFETCH;
265   // If an olde style /proc/cpuinfo (cpu_lines == 1) then if _model is an A57 (0xd07)
266   // we assume the worst and assume we could be on a big little system and have
267   // undisclosed A53 cores which we could be swapped to at any stage
268   if (_cpu == CPU_ARM &amp;&amp; cpu_lines == 1 &amp;&amp; _model == 0xd07) _features |= CPU_A53MAC;
269 
270   sprintf(buf, &quot;0x%02x:0x%x:0x%03x:%d&quot;, _cpu, _variant, _model, _revision);
271   if (_model2) sprintf(buf+strlen(buf), &quot;(0x%03x)&quot;, _model2);
272   if (auxv &amp; HWCAP_ASIMD) strcat(buf, &quot;, simd&quot;);
273   if (auxv &amp; HWCAP_CRC32) strcat(buf, &quot;, crc&quot;);
274   if (auxv &amp; HWCAP_AES)   strcat(buf, &quot;, aes&quot;);
275   if (auxv &amp; HWCAP_SHA1)  strcat(buf, &quot;, sha1&quot;);
276   if (auxv &amp; HWCAP_SHA2)  strcat(buf, &quot;, sha256&quot;);
277   if (auxv &amp; HWCAP_ATOMICS) strcat(buf, &quot;, lse&quot;);
278 
279   _features_string = os::strdup(buf);
280 
281   if (FLAG_IS_DEFAULT(UseCRC32)) {
282     UseCRC32 = (auxv &amp; HWCAP_CRC32) != 0;
283   }
284 
285   if (UseCRC32 &amp;&amp; (auxv &amp; HWCAP_CRC32) == 0) {
286     warning(&quot;UseCRC32 specified, but not supported on this CPU&quot;);
287     FLAG_SET_DEFAULT(UseCRC32, false);
288   }
289 
290   if (FLAG_IS_DEFAULT(UseAdler32Intrinsics)) {
291     FLAG_SET_DEFAULT(UseAdler32Intrinsics, true);
292   }
293 
294   if (UseVectorizedMismatchIntrinsic) {
295     warning(&quot;UseVectorizedMismatchIntrinsic specified, but not available on this CPU.&quot;);
296     FLAG_SET_DEFAULT(UseVectorizedMismatchIntrinsic, false);
297   }
298 
299   if (auxv &amp; HWCAP_ATOMICS) {
300     if (FLAG_IS_DEFAULT(UseLSE))
301       FLAG_SET_DEFAULT(UseLSE, true);
302   } else {
303     if (UseLSE) {
304       warning(&quot;UseLSE specified, but not supported on this CPU&quot;);
305       FLAG_SET_DEFAULT(UseLSE, false);
306     }
307   }
308 
309   if (auxv &amp; HWCAP_AES) {
310     UseAES = UseAES || FLAG_IS_DEFAULT(UseAES);
311     UseAESIntrinsics =
312         UseAESIntrinsics || (UseAES &amp;&amp; FLAG_IS_DEFAULT(UseAESIntrinsics));
313     if (UseAESIntrinsics &amp;&amp; !UseAES) {
314       warning(&quot;UseAESIntrinsics enabled, but UseAES not, enabling&quot;);
315       UseAES = true;
316     }
317   } else {
318     if (UseAES) {
319       warning(&quot;UseAES specified, but not supported on this CPU&quot;);
320       FLAG_SET_DEFAULT(UseAES, false);
321     }
322     if (UseAESIntrinsics) {
323       warning(&quot;UseAESIntrinsics specified, but not supported on this CPU&quot;);
324       FLAG_SET_DEFAULT(UseAESIntrinsics, false);
325     }
326   }
327 
328   if (UseAESCTRIntrinsics) {
329     warning(&quot;AES/CTR intrinsics are not available on this CPU&quot;);
330     FLAG_SET_DEFAULT(UseAESCTRIntrinsics, false);
331   }
332 
333   if (FLAG_IS_DEFAULT(UseCRC32Intrinsics)) {
334     UseCRC32Intrinsics = true;
335   }
336 
337   if (auxv &amp; HWCAP_CRC32) {
338     if (FLAG_IS_DEFAULT(UseCRC32CIntrinsics)) {
339       FLAG_SET_DEFAULT(UseCRC32CIntrinsics, true);
340     }
341   } else if (UseCRC32CIntrinsics) {
342     warning(&quot;CRC32C is not available on the CPU&quot;);
343     FLAG_SET_DEFAULT(UseCRC32CIntrinsics, false);
344   }
345 
346   if (FLAG_IS_DEFAULT(UseFMA)) {
347     FLAG_SET_DEFAULT(UseFMA, true);
348   }
349 
350   if (auxv &amp; (HWCAP_SHA1 | HWCAP_SHA2)) {
351     if (FLAG_IS_DEFAULT(UseSHA)) {
352       FLAG_SET_DEFAULT(UseSHA, true);
353     }
354   } else if (UseSHA) {
355     warning(&quot;SHA instructions are not available on this CPU&quot;);
356     FLAG_SET_DEFAULT(UseSHA, false);
357   }
358 
359   if (UseSHA &amp;&amp; (auxv &amp; HWCAP_SHA1)) {
360     if (FLAG_IS_DEFAULT(UseSHA1Intrinsics)) {
361       FLAG_SET_DEFAULT(UseSHA1Intrinsics, true);
362     }
363   } else if (UseSHA1Intrinsics) {
364     warning(&quot;Intrinsics for SHA-1 crypto hash functions not available on this CPU.&quot;);
365     FLAG_SET_DEFAULT(UseSHA1Intrinsics, false);
366   }
367 
368   if (UseSHA &amp;&amp; (auxv &amp; HWCAP_SHA2)) {
369     if (FLAG_IS_DEFAULT(UseSHA256Intrinsics)) {
370       FLAG_SET_DEFAULT(UseSHA256Intrinsics, true);
371     }
372   } else if (UseSHA256Intrinsics) {
373     warning(&quot;Intrinsics for SHA-224 and SHA-256 crypto hash functions not available on this CPU.&quot;);
374     FLAG_SET_DEFAULT(UseSHA256Intrinsics, false);
375   }
376 
377   if (UseSHA512Intrinsics) {
378     warning(&quot;Intrinsics for SHA-384 and SHA-512 crypto hash functions not available on this CPU.&quot;);
379     FLAG_SET_DEFAULT(UseSHA512Intrinsics, false);
380   }
381 
382   if (!(UseSHA1Intrinsics || UseSHA256Intrinsics || UseSHA512Intrinsics)) {
383     FLAG_SET_DEFAULT(UseSHA, false);
384   }
385 
386   if (auxv &amp; HWCAP_PMULL) {
387     if (FLAG_IS_DEFAULT(UseGHASHIntrinsics)) {
388       FLAG_SET_DEFAULT(UseGHASHIntrinsics, true);
389     }
390   } else if (UseGHASHIntrinsics) {
391     warning(&quot;GHASH intrinsics are not available on this CPU&quot;);
392     FLAG_SET_DEFAULT(UseGHASHIntrinsics, false);
393   }
394 
395   if (is_zva_enabled()) {
396     if (FLAG_IS_DEFAULT(UseBlockZeroing)) {
397       FLAG_SET_DEFAULT(UseBlockZeroing, true);
398     }
399     if (FLAG_IS_DEFAULT(BlockZeroingLowLimit)) {
400       FLAG_SET_DEFAULT(BlockZeroingLowLimit, 4 * VM_Version::zva_length());
401     }
402   } else if (UseBlockZeroing) {
403     warning(&quot;DC ZVA is not available on this CPU&quot;);
404     FLAG_SET_DEFAULT(UseBlockZeroing, false);
405   }
406 
407   // This machine allows unaligned memory accesses
408   if (FLAG_IS_DEFAULT(UseUnalignedAccesses)) {
409     FLAG_SET_DEFAULT(UseUnalignedAccesses, true);
410   }
411 
412   if (FLAG_IS_DEFAULT(UseBarriersForVolatile)) {
413     UseBarriersForVolatile = (_features &amp; CPU_DMB_ATOMICS) != 0;
414   }
415 
416   if (FLAG_IS_DEFAULT(UsePopCountInstruction)) {
417     UsePopCountInstruction = true;
418   }
419 
420 #ifdef COMPILER2
421   if (FLAG_IS_DEFAULT(UseMultiplyToLenIntrinsic)) {
422     UseMultiplyToLenIntrinsic = true;
423   }
424 
425   if (FLAG_IS_DEFAULT(UseSquareToLenIntrinsic)) {
426     UseSquareToLenIntrinsic = true;
427   }
428 
429   if (FLAG_IS_DEFAULT(UseMulAddIntrinsic)) {
430     UseMulAddIntrinsic = true;
431   }
432 
433   if (FLAG_IS_DEFAULT(UseMontgomeryMultiplyIntrinsic)) {
434     UseMontgomeryMultiplyIntrinsic = true;
435   }
436   if (FLAG_IS_DEFAULT(UseMontgomerySquareIntrinsic)) {
437     UseMontgomerySquareIntrinsic = true;
438   }
439 
440   if (FLAG_IS_DEFAULT(OptoScheduling)) {
441     OptoScheduling = true;
442   }
443 #endif
444 }
445 
446 void VM_Version::initialize() {
447   ResourceMark rm;
448 
449   stub_blob = BufferBlob::create(&quot;getPsrInfo_stub&quot;, stub_size);
450   if (stub_blob == NULL) {
451     vm_exit_during_initialization(&quot;Unable to allocate getPsrInfo_stub&quot;);
452   }
453 
454   CodeBuffer c(stub_blob);
455   VM_Version_StubGenerator g(&amp;c);
456   getPsrInfo_stub = CAST_TO_FN_PTR(getPsrInfo_stub_t,
457                                    g.generate_getPsrInfo());
458 
459   get_processor_features();
460 
461   UNSUPPORTED_OPTION(CriticalJNINatives);
462 }
    </pre>
  </body>
</html>