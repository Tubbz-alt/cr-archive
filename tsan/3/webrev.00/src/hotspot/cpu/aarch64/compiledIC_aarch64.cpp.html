<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/cpu/aarch64/compiledIC_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * Copyright (c) 2014, 2018, Red Hat Inc. All rights reserved.
  4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5  *
  6  * This code is free software; you can redistribute it and/or modify it
  7  * under the terms of the GNU General Public License version 2 only, as
  8  * published by the Free Software Foundation.
  9  *
 10  * This code is distributed in the hope that it will be useful, but WITHOUT
 11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13  * version 2 for more details (a copy is included in the LICENSE file that
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
 23  *
 24  */
 25 
 26 #include &quot;precompiled.hpp&quot;
 27 #include &quot;asm/macroAssembler.inline.hpp&quot;
 28 #include &quot;code/compiledIC.hpp&quot;
 29 #include &quot;code/icBuffer.hpp&quot;
 30 #include &quot;code/nmethod.hpp&quot;
 31 #include &quot;memory/resourceArea.hpp&quot;
 32 #include &quot;runtime/mutexLocker.hpp&quot;
 33 #include &quot;runtime/safepoint.hpp&quot;
 34 
 35 // ----------------------------------------------------------------------------
 36 
 37 #define __ _masm.
 38 address CompiledStaticCall::emit_to_interp_stub(CodeBuffer &amp;cbuf, address mark) {
 39   // Stub is fixed up when the corresponding call is converted from
 40   // calling compiled code to calling interpreted code.
 41   // mov rmethod, 0
 42   // jmp -4 # to self
 43 
 44   if (mark == NULL) {
 45     mark = cbuf.insts_mark();  // Get mark within main instrs section.
 46   }
 47 
 48   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 49   // That&#39;s why we must use the macroassembler to generate a stub.
 50   MacroAssembler _masm(&amp;cbuf);
 51 
 52   address base = __ start_a_stub(to_interp_stub_size());
 53   int offset = __ offset();
 54   if (base == NULL) {
 55     return NULL;  // CodeBuffer::expand failed
 56   }
 57   // static stub relocation stores the instruction address of the call
 58   __ relocate(static_stub_Relocation::spec(mark));
 59 
 60 #if INCLUDE_AOT
 61   // Don&#39;t create a Metadata reloc if we&#39;re generating immutable PIC.
 62   if (cbuf.immutable_PIC()) {
 63     __ movptr(rmethod, 0);
 64     __ movptr(rscratch1, 0);
 65     __ br(rscratch1);
 66 
 67   } else
 68 #endif
 69   {
 70     __ emit_static_call_stub();
 71   }
 72 
 73   assert((__ offset() - offset) &lt;= (int)to_interp_stub_size(), &quot;stub too big&quot;);
 74   __ end_a_stub();
 75   return base;
 76 }
 77 #undef __
 78 
 79 int CompiledStaticCall::to_interp_stub_size() {
 80   // isb; movk; movz; movz; movk; movz; movz; br
 81   return 8 * NativeInstruction::instruction_size;
 82 }
 83 
 84 int CompiledStaticCall::to_trampoline_stub_size() {
 85   // Somewhat pessimistically, we count 3 instructions here (although
 86   // there are only two) because we sometimes emit an alignment nop.
 87   // Trampoline stubs are always word aligned.
 88   return 3 * NativeInstruction::instruction_size + wordSize;
 89 }
 90 
 91 // Relocation entries for call stub, compiled java to interpreter.
 92 int CompiledStaticCall::reloc_to_interp_stub() {
 93   return 4; // 3 in emit_to_interp_stub + 1 in emit_call
 94 }
 95 
 96 #if INCLUDE_AOT
 97 #define __ _masm.
 98 void CompiledStaticCall::emit_to_aot_stub(CodeBuffer &amp;cbuf, address mark) {
 99   if (!UseAOT) {
100     return;
101   }
102   // Stub is fixed up when the corresponding call is converted from
103   // calling compiled code to calling aot code.
104   // mov r, imm64_aot_code_address
105   // jmp r
106 
107   if (mark == NULL) {
108     mark = cbuf.insts_mark();  // Get mark within main instrs section.
109   }
110 
111   // Note that the code buffer&#39;s insts_mark is always relative to insts.
112   // That&#39;s why we must use the macroassembler to generate a stub.
113   MacroAssembler _masm(&amp;cbuf);
114 
115   address base =
116   __ start_a_stub(to_aot_stub_size());
117   guarantee(base != NULL, &quot;out of space&quot;);
118 
119   // Static stub relocation stores the instruction address of the call.
120   __ relocate(static_stub_Relocation::spec(mark, true /* is_aot */));
121   // Load destination AOT code address.
122   __ movptr(rscratch1, 0);  // address is zapped till fixup time.
123   // This is recognized as unresolved by relocs/nativeinst/ic code.
124   __ br(rscratch1);
125 
126   assert(__ pc() - base &lt;= to_aot_stub_size(), &quot;wrong stub size&quot;);
127 
128   // Update current stubs pointer and restore insts_end.
129   __ end_a_stub();
130 }
131 #undef __
132 
133 int CompiledStaticCall::to_aot_stub_size() {
134   if (UseAOT) {
135     return 5 * 4;  // movz; movk; movk; movk; br
136   } else {
137     return 0;
138   }
139 }
140 
141 // Relocation entries for call stub, compiled java to aot.
142 int CompiledStaticCall::reloc_to_aot_stub() {
143   if (UseAOT) {
144     return 5 * 4;  // movz; movk; movk; movk; br
145   } else {
146     return 0;
147   }
148 }
149 #endif // INCLUDE_AOT
150 
151 void CompiledDirectStaticCall::set_to_interpreted(const methodHandle&amp; callee, address entry) {
152   address stub = find_stub(false /* is_aot */);
153   guarantee(stub != NULL, &quot;stub not found&quot;);
154 
155   if (TraceICs) {
156     ResourceMark rm;
157     tty-&gt;print_cr(&quot;CompiledDirectStaticCall@&quot; INTPTR_FORMAT &quot;: set_to_interpreted %s&quot;,
158                   p2i(instruction_address()),
159                   callee-&gt;name_and_sig_as_C_string());
160   }
161 
162   // Creation also verifies the object.
163   NativeMovConstReg* method_holder
164     = nativeMovConstReg_at(stub + NativeInstruction::instruction_size);
165 
166 #ifdef ASSERT
167   NativeGeneralJump* jump = nativeGeneralJump_at(method_holder-&gt;next_instruction_address());
168   verify_mt_safe(callee, entry, method_holder, jump);
169 #endif
170 
171   // Update stub.
172   method_holder-&gt;set_data((intptr_t)callee());
173   NativeGeneralJump::insert_unconditional(method_holder-&gt;next_instruction_address(), entry);
174   ICache::invalidate_range(stub, to_interp_stub_size());
175   // Update jump to call.
176   set_destination_mt_safe(stub);
177 }
178 
179 void CompiledDirectStaticCall::set_stub_to_clean(static_stub_Relocation* static_stub) {
180   // Reset stub.
181   address stub = static_stub-&gt;addr();
182   assert(stub != NULL, &quot;stub not found&quot;);
183   assert(CompiledICLocker::is_safe(stub), &quot;mt unsafe call&quot;);
184   // Creation also verifies the object.
185   NativeMovConstReg* method_holder
186     = nativeMovConstReg_at(stub + NativeInstruction::instruction_size);
187   method_holder-&gt;set_data(0);
188   if (!static_stub-&gt;is_aot()) {
189     NativeJump* jump = nativeJump_at(method_holder-&gt;next_instruction_address());
190     jump-&gt;set_jump_destination((address)-1);
191   }
192 }
193 
194 //-----------------------------------------------------------------------------
195 // Non-product mode code
196 #ifndef PRODUCT
197 
198 void CompiledDirectStaticCall::verify() {
199   // Verify call.
200   _call-&gt;verify();
201   _call-&gt;verify_alignment();
202 
203   // Verify stub.
204   address stub = find_stub(false /* is_aot */);
205   assert(stub != NULL, &quot;no stub found for static call&quot;);
206   // Creation also verifies the object.
207   NativeMovConstReg* method_holder
208     = nativeMovConstReg_at(stub + NativeInstruction::instruction_size);
209   NativeJump* jump = nativeJump_at(method_holder-&gt;next_instruction_address());
210 
211   // Verify state.
212   assert(is_clean() || is_call_to_compiled() || is_call_to_interpreted(), &quot;sanity check&quot;);
213 }
214 
215 #endif // !PRODUCT
    </pre>
  </body>
</html>