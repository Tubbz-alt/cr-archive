<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/s390/sharedRuntime_s390.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="s390.ad.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_s390.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/s390/sharedRuntime_s390.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2016, 2018, Oracle and/or its affiliates. All rights reserved.</span>
<span class="line-modified">   3  * Copyright (c) 2016, 2018 SAP SE. All rights reserved.</span>
   4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   5  *
   6  * This code is free software; you can redistribute it and/or modify it
   7  * under the terms of the GNU General Public License version 2 only, as
   8  * published by the Free Software Foundation.
   9  *
  10  * This code is distributed in the hope that it will be useful, but WITHOUT
  11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;code/debugInfoRec.hpp&quot;
  29 #include &quot;code/icBuffer.hpp&quot;
  30 #include &quot;code/vtableStubs.hpp&quot;
  31 #include &quot;gc/shared/gcLocker.hpp&quot;
  32 #include &quot;interpreter/interpreter.hpp&quot;
  33 #include &quot;interpreter/interp_masm.hpp&quot;
  34 #include &quot;memory/resourceArea.hpp&quot;

  35 #include &quot;oops/compiledICHolder.hpp&quot;

  36 #include &quot;registerSaver_s390.hpp&quot;
  37 #include &quot;runtime/safepointMechanism.hpp&quot;
  38 #include &quot;runtime/sharedRuntime.hpp&quot;
  39 #include &quot;runtime/vframeArray.hpp&quot;
  40 #include &quot;utilities/align.hpp&quot;
  41 #include &quot;vmreg_s390.inline.hpp&quot;
  42 #ifdef COMPILER1
  43 #include &quot;c1/c1_Runtime1.hpp&quot;
  44 #endif
  45 #ifdef COMPILER2
  46 #include &quot;opto/ad.hpp&quot;
  47 #include &quot;opto/runtime.hpp&quot;
  48 #endif
  49 
  50 #ifdef PRODUCT
  51 #define __ masm-&gt;
  52 #else
  53 #define __ (Verbose ? (masm-&gt;block_comment(FILE_AND_LINE),masm):masm)-&gt;
  54 #endif
  55 
</pre>
<hr />
<pre>
 866 // The java_calling_convention describes stack locations as ideal slots on
 867 // a frame with no abi restrictions. Since we must observe abi restrictions
 868 // (like the placement of the register window) the slots must be biased by
 869 // the following value.
 870 //----------------------------------------------------------------------
 871 static int reg2slot(VMReg r) {
 872   return r-&gt;reg2stack() + SharedRuntime::out_preserve_stack_slots();
 873 }
 874 
 875 static int reg2offset(VMReg r) {
 876   return reg2slot(r) * VMRegImpl::stack_slot_size;
 877 }
 878 
 879 static void verify_oop_args(MacroAssembler *masm,
 880                             int total_args_passed,
 881                             const BasicType *sig_bt,
 882                             const VMRegPair *regs) {
 883   if (!VerifyOops) { return; }
 884 
 885   for (int i = 0; i &lt; total_args_passed; i++) {
<span class="line-modified"> 886     if (sig_bt[i] == T_OBJECT || sig_bt[i] == T_ARRAY) {</span>
 887       VMReg r = regs[i].first();
 888       assert(r-&gt;is_valid(), &quot;bad oop arg&quot;);
 889 
 890       if (r-&gt;is_stack()) {
 891         __ z_lg(Z_R0_scratch,
 892                 Address(Z_SP, r-&gt;reg2stack() * VMRegImpl::stack_slot_size + wordSize));
<span class="line-modified"> 893         __ verify_oop(Z_R0_scratch);</span>
 894       } else {
<span class="line-modified"> 895         __ verify_oop(r-&gt;as_Register());</span>
 896       }
 897     }
 898   }
 899 }
 900 
 901 static void gen_special_dispatch(MacroAssembler *masm,
 902                                  int total_args_passed,
 903                                  vmIntrinsics::ID special_dispatch,
 904                                  const BasicType *sig_bt,
 905                                  const VMRegPair *regs) {
 906   verify_oop_args(masm, total_args_passed, sig_bt, regs);
 907 
 908   // Now write the args into the outgoing interpreter space.
 909   bool     has_receiver   = false;
 910   Register receiver_reg   = noreg;
 911   int      member_arg_pos = -1;
 912   Register member_reg     = noreg;
 913   int      ref_kind       = MethodHandles::signature_polymorphic_intrinsic_ref_kind(special_dispatch);
 914 
 915   if (ref_kind != 0) {
</pre>
<hr />
<pre>
1501     __ clear_reg(tmp_reg, true, false);  // Don&#39;t set CC.
1502   }
1503   __ compare64_and_branch(first, (RegisterOrConstant)0L, Assembler::bcondEqual, set_out_args);
1504   __ z_lgf(tmp2_reg, Address(first, arrayOopDesc::length_offset_in_bytes()));
1505   __ add2reg(tmp_reg, arrayOopDesc::base_offset_in_bytes(in_elem_type), first);
1506 
1507   __ bind(set_out_args);
1508   move_ptr(masm, tmp, body_arg, framesize_in_slots);
1509   move32_64(masm, tmp2, length_arg, framesize_in_slots);
1510 }
1511 
1512 //----------------------------------------------------------------------
1513 // Wrap a JNI call.
1514 //----------------------------------------------------------------------
1515 #undef USE_RESIZE_FRAME
1516 nmethod *SharedRuntime::generate_native_wrapper(MacroAssembler *masm,
1517                                                 const methodHandle&amp; method,
1518                                                 int compile_id,
1519                                                 BasicType *in_sig_bt,
1520                                                 VMRegPair *in_regs,
<span class="line-modified">1521                                                 BasicType ret_type) {</span>
<span class="line-modified">1522 #ifdef COMPILER2</span>
1523   int total_in_args = method-&gt;size_of_parameters();
1524   if (method-&gt;is_method_handle_intrinsic()) {
1525     vmIntrinsics::ID iid = method-&gt;intrinsic_id();
1526     intptr_t start = (intptr_t) __ pc();
1527     int vep_offset = ((intptr_t) __ pc()) - start;
1528 
1529     gen_special_dispatch(masm, total_in_args,
1530                          method-&gt;intrinsic_id(), in_sig_bt, in_regs);
1531 
1532     int frame_complete = ((intptr_t)__ pc()) - start; // Not complete, period.
1533 
1534     __ flush();
1535 
1536     int stack_slots = SharedRuntime::out_preserve_stack_slots();  // No out slots at all, actually.
1537 
1538     return nmethod::new_native_nmethod(method,
1539                                        compile_id,
1540                                        masm-&gt;code(),
1541                                        vep_offset,
1542                                        frame_complete,
1543                                        stack_slots / VMRegImpl::slots_per_word,
1544                                        in_ByteSize(-1),
1545                                        in_ByteSize(-1),
1546                                        (OopMapSet *) NULL);
1547   }
1548 
1549 
1550   ///////////////////////////////////////////////////////////////////////
1551   //
1552   //  Precalculations before generating any code
1553   //
1554   ///////////////////////////////////////////////////////////////////////
1555 
1556   bool is_critical_native = true;
<span class="line-modified">1557   address native_func = method-&gt;critical_native_function();</span>
1558   if (native_func == NULL) {
1559     native_func = method-&gt;native_function();
1560     is_critical_native = false;
1561   }
1562   assert(native_func != NULL, &quot;must have function&quot;);
1563 
1564   //---------------------------------------------------------------------
1565   // We have received a description of where all the java args are located
1566   // on entry to the wrapper. We need to convert these args to where
1567   // the jni function will expect them. To figure out where they go
1568   // we convert the java signature to a C signature by inserting
1569   // the hidden arguments as arg[0] and possibly arg[1] (static method).
1570   //
1571   // The first hidden argument arg[0] is a pointer to the JNI environment.
1572   // It is generated for every call.
1573   // The second argument arg[1] to the JNI call, which is hidden for static
1574   // methods, is the boxed lock object. For static calls, the lock object
1575   // is the static method itself. The oop is constructed here. for instance
1576   // calls, the lock is performed on the object itself, the pointer of
1577   // which is passed as the first visible argument.
</pre>
<hr />
<pre>
1601   VMRegPair *out_regs   = NEW_RESOURCE_ARRAY(VMRegPair, total_c_args);
1602   BasicType* in_elem_bt = NULL;
1603 
1604   // Create the signature for the C call:
1605   //   1) add the JNIEnv*
1606   //   2) add the class if the method is static
1607   //   3) copy the rest of the incoming signature (shifted by the number of
1608   //      hidden arguments)
1609 
1610   int argc = 0;
1611   if (!is_critical_native) {
1612     out_sig_bt[argc++] = T_ADDRESS;
1613     if (method-&gt;is_static()) {
1614       out_sig_bt[argc++] = T_OBJECT;
1615     }
1616 
1617     for (int i = 0; i &lt; total_in_args; i++) {
1618       out_sig_bt[argc++] = in_sig_bt[i];
1619     }
1620   } else {
<span class="line-removed">1621     Thread* THREAD = Thread::current();</span>
1622     in_elem_bt = NEW_RESOURCE_ARRAY(BasicType, total_in_args);
1623     SignatureStream ss(method-&gt;signature());
1624     int o = 0;
1625     for (int i = 0; i &lt; total_in_args; i++, o++) {
1626       if (in_sig_bt[i] == T_ARRAY) {
1627         // Arrays are passed as tuples (int, elem*).
<span class="line-modified">1628         Symbol* atype = ss.as_symbol(CHECK_NULL);</span>
<span class="line-modified">1629         const char* at = atype-&gt;as_C_string();</span>
<span class="line-modified">1630         if (strlen(at) == 2) {</span>
<span class="line-removed">1631           assert(at[0] == &#39;[&#39;, &quot;must be&quot;);</span>
<span class="line-removed">1632           switch (at[1]) {</span>
<span class="line-removed">1633             case &#39;B&#39;: in_elem_bt[o]  = T_BYTE; break;</span>
<span class="line-removed">1634             case &#39;C&#39;: in_elem_bt[o]  = T_CHAR; break;</span>
<span class="line-removed">1635             case &#39;D&#39;: in_elem_bt[o]  = T_DOUBLE; break;</span>
<span class="line-removed">1636             case &#39;F&#39;: in_elem_bt[o]  = T_FLOAT; break;</span>
<span class="line-removed">1637             case &#39;I&#39;: in_elem_bt[o]  = T_INT; break;</span>
<span class="line-removed">1638             case &#39;J&#39;: in_elem_bt[o]  = T_LONG; break;</span>
<span class="line-removed">1639             case &#39;S&#39;: in_elem_bt[o]  = T_SHORT; break;</span>
<span class="line-removed">1640             case &#39;Z&#39;: in_elem_bt[o]  = T_BOOLEAN; break;</span>
<span class="line-removed">1641             default: ShouldNotReachHere();</span>
<span class="line-removed">1642           }</span>
<span class="line-removed">1643         }</span>
1644       } else {
1645         in_elem_bt[o] = T_VOID;
1646       }
1647       if (in_sig_bt[i] != T_VOID) {
<span class="line-modified">1648         assert(in_sig_bt[i] == ss.type(), &quot;must match&quot;);</span>

1649         ss.next();
1650       }
1651     }
1652     assert(total_in_args == o, &quot;must match&quot;);
1653 
1654     for (int i = 0; i &lt; total_in_args; i++) {
1655       if (in_sig_bt[i] == T_ARRAY) {
1656         // Arrays are passed as tuples (int, elem*).
1657         out_sig_bt[argc++] = T_INT;
1658         out_sig_bt[argc++] = T_ADDRESS;
1659       } else {
1660         out_sig_bt[argc++] = in_sig_bt[i];
1661       }
1662     }
1663   }
1664 
1665   ///////////////////////////////////////////////////////////////////////
1666   // Now figure out where the args must be stored and how much stack space
1667   // they require (neglecting out_preserve_stack_slots but providing space
1668   // for storing the first five register arguments).
</pre>
<hr />
<pre>
1816   unsigned int wrapper_FrameDone;
1817   unsigned int wrapper_CRegsSet;
1818   Label     handle_pending_exception;
1819   Label     ic_miss;
1820 
1821   //---------------------------------------------------------------------
1822   // Unverified entry point (UEP)
1823   //---------------------------------------------------------------------
1824   wrapper_UEPStart = __ offset();
1825 
1826   // check ic: object class &lt;-&gt; cached class
1827   if (!method_is_static) __ nmethod_UEP(ic_miss);
1828   // Fill with nops (alignment of verified entry point).
1829   __ align(CodeEntryAlignment);
1830 
1831   //---------------------------------------------------------------------
1832   // Verified entry point (VEP)
1833   //---------------------------------------------------------------------
1834   wrapper_VEPStart = __ offset();
1835 














1836   __ save_return_pc();
1837   __ generate_stack_overflow_check(frame_size_in_bytes);  // Check before creating frame.
1838 #ifndef USE_RESIZE_FRAME
1839   __ push_frame(frame_size_in_bytes);                     // Create a new frame for the wrapper.
1840 #else
1841   __ resize_frame(-frame_size_in_bytes, Z_R0_scratch);    // No new frame for the wrapper.
1842                                                           // Just resize the existing one.
1843 #endif
1844 
1845   wrapper_FrameDone = __ offset();
1846 
1847   __ verify_thread();
1848 
1849   // Native nmethod wrappers never take possession of the oop arguments.
1850   // So the caller will gc the arguments.
1851   // The only thing we need an oopMap for is if the call is static.
1852   //
1853   // An OopMap for lock (and class if static), and one for the VM call itself
1854   OopMapSet  *oop_maps        = new OopMapSet();
1855   OopMap     *map             = new OopMap(stack_slots * 2, 0 /* arg_slots*/);
</pre>
<hr />
<pre>
2287     // exception in pending_exception and not in a register. Kind of clumsy,
2288     // since all folks who branch to forward_exception must have tested
2289     // pending_exception first and hence have it in a register already.
2290     __ z_stg(R_exc, Address(Z_thread, Thread::pending_exception_offset()));
2291     restore_native_result(masm, ret_type, workspace_slot_offset);
2292     __ z_bru(done);
2293     __ z_illtrap(0x66);
2294 
2295     __ bind(done);
2296   }
2297 
2298 
2299   //--------------------------------------------------------------------
2300   // Clear &quot;last Java frame&quot; SP and PC.
2301   //--------------------------------------------------------------------
2302   __ verify_thread(); // Z_thread must be correct.
2303 
2304   __ reset_last_Java_frame();
2305 
2306   // Unpack oop result, e.g. JNIHandles::resolve result.
<span class="line-modified">2307   if (ret_type == T_OBJECT || ret_type == T_ARRAY) {</span>
2308     __ resolve_jobject(Z_RET, /* tmp1 */ Z_R13, /* tmp2 */ Z_R7);
2309   }
2310 
2311   if (CheckJNICalls) {
2312     // clear_pending_jni_exception_check
2313     __ clear_mem(Address(Z_thread, JavaThread::pending_jni_exception_check_fn_offset()), sizeof(oop));
2314   }
2315 
2316   // Reset handle block.
2317   if (!is_critical_native) {
2318     __ z_lg(Z_R1_scratch, Address(Z_thread, JavaThread::active_handles_offset()));
2319     __ clear_mem(Address(Z_R1_scratch, JNIHandleBlock::top_offset_in_bytes()), 4);
2320 
2321     // Check for pending exceptions.
2322     __ load_and_test_long(Z_R0, Address(Z_thread, Thread::pending_exception_offset()));
2323     __ z_brne(handle_pending_exception);
2324   }
2325 
2326 
2327   //////////////////////////////////////////////////////////////////////
</pre>
<hr />
<pre>
2369   //////////////////////////////////////////////////////////////////////
2370   // end of code generation
2371   //////////////////////////////////////////////////////////////////////
2372 
2373 
2374   nmethod *nm = nmethod::new_native_nmethod(method,
2375                                             compile_id,
2376                                             masm-&gt;code(),
2377                                             (int)(wrapper_VEPStart-wrapper_CodeStart),
2378                                             (int)(wrapper_FrameDone-wrapper_CodeStart),
2379                                             stack_slots / VMRegImpl::slots_per_word,
2380                                             (method_is_static ? in_ByteSize(klass_offset) : in_ByteSize(receiver_offset)),
2381                                             in_ByteSize(lock_offset),
2382                                             oop_maps);
2383 
2384   if (is_critical_native) {
2385     nm-&gt;set_lazy_critical_native(true);
2386   }
2387 
2388   return nm;
<span class="line-removed">2389 #else</span>
<span class="line-removed">2390   ShouldNotReachHere();</span>
<span class="line-removed">2391   return NULL;</span>
<span class="line-removed">2392 #endif // COMPILER2</span>
2393 }
2394 
2395 static address gen_c2i_adapter(MacroAssembler  *masm,
2396                                int total_args_passed,
2397                                int comp_args_on_stack,
2398                                const BasicType *sig_bt,
2399                                const VMRegPair *regs,
2400                                Label &amp;skip_fixup) {
2401   // Before we get into the guts of the C2I adapter, see if we should be here
2402   // at all. We&#39;ve come from compiled code and are attempting to jump to the
2403   // interpreter, which means the caller made a static call to get here
2404   // (vcalls always get a compiled target if there is one). Check for a
2405   // compiled target. If there is one, we need to patch the caller&#39;s call.
2406 
2407   // These two defs MUST MATCH code in gen_i2c2i_adapter!
2408   const Register ientry = Z_R11;
2409   const Register code   = Z_R11;
2410 
2411   address c2i_entrypoint;
2412   Label   patch_callsite;
</pre>
<hr />
<pre>
2590         ld_offset -= 2 * wordSize;
2591       }
2592     } else {
2593       if (r_1-&gt;is_stack()) {
2594         // Must do a memory to memory move.
2595         int st_off = (r_1-&gt;reg2stack() + SharedRuntime::out_preserve_stack_slots()) * VMRegImpl::stack_slot_size;
2596 
2597         if (!r_2-&gt;is_valid()) {
2598           __ z_mvc(Address(Z_SP, st_off), Address(ld_ptr, ld_offset), sizeof(void*));
2599         } else {
2600           // In 64bit, longs are given 2 64-bit slots in the interpreter, but the
2601           // data is passed in only 1 slot.
2602           if (sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {
2603             ld_offset -= wordSize;
2604           }
2605           __ z_mvc(Address(Z_SP, st_off), Address(ld_ptr, ld_offset), sizeof(void*));
2606         }
2607       } else {
2608         if (!r_2-&gt;is_valid()) {
2609           // Not sure we need to do this but it shouldn&#39;t hurt.
<span class="line-modified">2610           if (sig_bt[i] == T_OBJECT || sig_bt[i] == T_ADDRESS || sig_bt[i] == T_ARRAY) {</span>
2611             __ z_lg(r_1-&gt;as_Register(), ld_offset, ld_ptr);
2612           } else {
2613             __ z_l(r_1-&gt;as_Register(), ld_offset, ld_ptr);
2614           }
2615         } else {
2616           // In 64bit, longs are given 2 64-bit slots in the interpreter, but the
2617           // data is passed in only 1 slot.
2618           if (sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {
2619             ld_offset -= wordSize;
2620           }
2621           __ z_lg(r_1-&gt;as_Register(), ld_offset, ld_ptr);
2622         }
2623       }
2624       ld_offset -= wordSize;
2625     }
2626   }
2627 
2628   // Jump to the compiled code just as if compiled code was doing it.
2629   // load target address from method oop:
2630   __ z_lg(Z_R1_scratch, Address(Z_method, Method::from_compiled_offset()));
</pre>
<hr />
<pre>
2658 
2659   Label skip_fixup;
2660   {
2661     Label ic_miss;
2662     const int klass_offset           = oopDesc::klass_offset_in_bytes();
2663     const int holder_klass_offset    = CompiledICHolder::holder_klass_offset();
2664     const int holder_metadata_offset = CompiledICHolder::holder_metadata_offset();
2665 
2666     // Out-of-line call to ic_miss handler.
2667     __ call_ic_miss_handler(ic_miss, 0x11, 0, Z_R1_scratch);
2668 
2669     // Unverified Entry Point UEP
2670     __ align(CodeEntryAlignment);
2671     c2i_unverified_entry = __ pc();
2672 
2673     // Check the pointers.
2674     if (!ImplicitNullChecks || MacroAssembler::needs_explicit_null_check(klass_offset)) {
2675       __ z_ltgr(Z_ARG1, Z_ARG1);
2676       __ z_bre(ic_miss);
2677     }
<span class="line-modified">2678     __ verify_oop(Z_ARG1);</span>
2679 
2680     // Check ic: object class &lt;-&gt; cached class
2681     // Compress cached class for comparison. That&#39;s more efficient.
2682     if (UseCompressedClassPointers) {
2683       __ z_lg(Z_R11, holder_klass_offset, Z_method);             // Z_R11 is overwritten a few instructions down anyway.
2684       __ compare_klass_ptr(Z_R11, klass_offset, Z_ARG1, false); // Cached class can&#39;t be zero.
2685     } else {
2686       __ z_clc(klass_offset, sizeof(void *)-1, Z_ARG1, holder_klass_offset, Z_method);
2687     }
2688     __ z_brne(ic_miss);  // Cache miss: call runtime to handle this.
2689 
2690     // This def MUST MATCH code in gen_c2i_adapter!
2691     const Register code = Z_R11;
2692 
2693     __ z_lg(Z_method, holder_metadata_offset, Z_method);
2694     __ load_and_test_long(Z_R0, method_(code));
2695     __ z_brne(ic_miss);  // Cache miss: call runtime to handle this.
2696 
2697     // Fallthru to VEP. Duplicate LTG, but saved taken branch.
2698   }
2699 
<span class="line-modified">2700   address c2i_entry;</span>
<span class="line-modified">2701   c2i_entry = gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);</span>






















2702 
<span class="line-modified">2703   return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry);</span>
2704 }
2705 
2706 // This function returns the adjust size (in number of words) to a c2i adapter
2707 // activation for use during deoptimization.
2708 //
2709 // Actually only compiled frames need to be adjusted, but it
2710 // doesn&#39;t harm to adjust entry and interpreter frames, too.
2711 //
2712 int Deoptimization::last_frame_adjust(int callee_parameters, int callee_locals) {
2713   assert(callee_locals &gt;= callee_parameters,
2714           &quot;test and remove; got more parms than locals&quot;);
2715   // Handle the abi adjustment here instead of doing it in push_skeleton_frames.
2716   return (callee_locals - callee_parameters) * Interpreter::stackElementWords +
2717          frame::z_parent_ijava_frame_abi_size / BytesPerWord;
2718 }
2719 
2720 uint SharedRuntime::out_preserve_stack_slots() {
2721   return frame::z_jit_out_preserve_size/VMRegImpl::stack_slot_size;
2722 }
2723 
</pre>
<hr />
<pre>
2826   CodeBuffer buffer(&quot;deopt_blob&quot;, 2048, 1024);
2827   InterpreterMacroAssembler* masm = new InterpreterMacroAssembler(&amp;buffer);
2828   Label exec_mode_initialized;
2829   OopMap* map = NULL;
2830   OopMapSet *oop_maps = new OopMapSet();
2831 
2832   unsigned int start_off = __ offset();
2833   Label cont;
2834 
2835   // --------------------------------------------------------------------------
2836   // Normal entry (non-exception case)
2837   //
2838   // We have been called from the deopt handler of the deoptee.
2839   // Z_R14 points behind the call in the deopt handler. We adjust
2840   // it such that it points to the start of the deopt handler.
2841   // The return_pc has been stored in the frame of the deoptee and
2842   // will replace the address of the deopt_handler in the call
2843   // to Deoptimization::fetch_unroll_info below.
2844   // The (int) cast is necessary, because -((unsigned int)14)
2845   // is an unsigned int.
<span class="line-modified">2846   __ add2reg(Z_R14, -(int)HandlerImpl::size_deopt_handler());</span>
2847 
2848   const Register   exec_mode_reg = Z_tmp_1;
2849 
2850   // stack: (deoptee, caller of deoptee, ...)
2851 
2852   // pushes an &quot;unpack&quot; frame
2853   // R14 contains the return address pointing into the deoptimized
2854   // nmethod that was valid just before the nmethod was deoptimized.
2855   // save R14 into the deoptee frame.  the `fetch_unroll_info&#39;
2856   // procedure called below will read it from there.
2857   map = RegisterSaver::save_live_registers(masm, RegisterSaver::all_registers);
2858 
2859   // note the entry point.
2860   __ load_const_optimized(exec_mode_reg, Deoptimization::Unpack_deopt);
2861   __ z_bru(exec_mode_initialized);
2862 
2863 #ifndef COMPILER1
2864   int reexecute_offset = 1; // odd offset will produce odd pc, which triggers an hardware trap
2865 #else
2866   // --------------------------------------------------------------------------
</pre>
<hr />
<pre>
2905   // Exceptiop oop and throwing PC are passed in JavaThread
2906 
2907   // load throwing pc from JavaThread and us it as the return address of the current frame.
2908   __ z_lg(Z_R1_scratch, Address(Z_thread, JavaThread::exception_pc_offset()));
2909 
2910   // Save everything in sight.
2911   (void) RegisterSaver::save_live_registers(masm, RegisterSaver::all_registers, Z_R1_scratch);
2912 
2913   // Now it is safe to overwrite any register
2914 
2915   // Clear the exception pc field in JavaThread
2916   __ clear_mem(Address(Z_thread, JavaThread::exception_pc_offset()), 8);
2917 
2918   // Deopt during an exception.  Save exec mode for unpack_frames.
2919   __ load_const_optimized(exec_mode_reg, Deoptimization::Unpack_exception);
2920 
2921 
2922 #ifdef ASSERT
2923   // verify that there is really an exception oop in JavaThread
2924   __ z_lg(Z_ARG1, Address(Z_thread, JavaThread::exception_oop_offset()));
<span class="line-modified">2925   __ verify_oop(Z_ARG1);</span>
2926 
2927   // verify that there is no pending exception
2928   __ asm_assert_mem8_is_zero(in_bytes(Thread::pending_exception_offset()), Z_thread,
2929                              &quot;must not have pending exception here&quot;, __LINE__);
2930 #endif
2931 
2932   // --------------------------------------------------------------------------
2933   // At this point, the live registers are saved and
2934   // the exec_mode_reg has been set up correctly.
2935   __ bind(exec_mode_initialized);
2936 
2937   // stack: (&quot;unpack&quot; frame, deoptee, caller_of_deoptee, ...).
2938 
2939   {
2940   const Register unroll_block_reg  = Z_tmp_2;
2941 
2942   // we need to set `last_Java_frame&#39; because `fetch_unroll_info&#39; will
2943   // call `last_Java_frame()&#39;.  however we can&#39;t block and no gc will
2944   // occur so we don&#39;t need an oopmap. the value of the pc in the
2945   // frame is not particularly important.  it just needs to identify the blob.
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2016, 2020, Oracle and/or its affiliates. All rights reserved.</span>
<span class="line-modified">   3  * Copyright (c) 2016, 2019, SAP SE. All rights reserved.</span>
   4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   5  *
   6  * This code is free software; you can redistribute it and/or modify it
   7  * under the terms of the GNU General Public License version 2 only, as
   8  * published by the Free Software Foundation.
   9  *
  10  * This code is distributed in the hope that it will be useful, but WITHOUT
  11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;code/debugInfoRec.hpp&quot;
  29 #include &quot;code/icBuffer.hpp&quot;
  30 #include &quot;code/vtableStubs.hpp&quot;
  31 #include &quot;gc/shared/gcLocker.hpp&quot;
  32 #include &quot;interpreter/interpreter.hpp&quot;
  33 #include &quot;interpreter/interp_masm.hpp&quot;
  34 #include &quot;memory/resourceArea.hpp&quot;
<span class="line-added">  35 #include &quot;nativeInst_s390.hpp&quot;</span>
  36 #include &quot;oops/compiledICHolder.hpp&quot;
<span class="line-added">  37 #include &quot;oops/klass.inline.hpp&quot;</span>
  38 #include &quot;registerSaver_s390.hpp&quot;
  39 #include &quot;runtime/safepointMechanism.hpp&quot;
  40 #include &quot;runtime/sharedRuntime.hpp&quot;
  41 #include &quot;runtime/vframeArray.hpp&quot;
  42 #include &quot;utilities/align.hpp&quot;
  43 #include &quot;vmreg_s390.inline.hpp&quot;
  44 #ifdef COMPILER1
  45 #include &quot;c1/c1_Runtime1.hpp&quot;
  46 #endif
  47 #ifdef COMPILER2
  48 #include &quot;opto/ad.hpp&quot;
  49 #include &quot;opto/runtime.hpp&quot;
  50 #endif
  51 
  52 #ifdef PRODUCT
  53 #define __ masm-&gt;
  54 #else
  55 #define __ (Verbose ? (masm-&gt;block_comment(FILE_AND_LINE),masm):masm)-&gt;
  56 #endif
  57 
</pre>
<hr />
<pre>
 868 // The java_calling_convention describes stack locations as ideal slots on
 869 // a frame with no abi restrictions. Since we must observe abi restrictions
 870 // (like the placement of the register window) the slots must be biased by
 871 // the following value.
 872 //----------------------------------------------------------------------
 873 static int reg2slot(VMReg r) {
 874   return r-&gt;reg2stack() + SharedRuntime::out_preserve_stack_slots();
 875 }
 876 
 877 static int reg2offset(VMReg r) {
 878   return reg2slot(r) * VMRegImpl::stack_slot_size;
 879 }
 880 
 881 static void verify_oop_args(MacroAssembler *masm,
 882                             int total_args_passed,
 883                             const BasicType *sig_bt,
 884                             const VMRegPair *regs) {
 885   if (!VerifyOops) { return; }
 886 
 887   for (int i = 0; i &lt; total_args_passed; i++) {
<span class="line-modified"> 888     if (is_reference_type(sig_bt[i])) {</span>
 889       VMReg r = regs[i].first();
 890       assert(r-&gt;is_valid(), &quot;bad oop arg&quot;);
 891 
 892       if (r-&gt;is_stack()) {
 893         __ z_lg(Z_R0_scratch,
 894                 Address(Z_SP, r-&gt;reg2stack() * VMRegImpl::stack_slot_size + wordSize));
<span class="line-modified"> 895         __ verify_oop(Z_R0_scratch, FILE_AND_LINE);</span>
 896       } else {
<span class="line-modified"> 897         __ verify_oop(r-&gt;as_Register(), FILE_AND_LINE);</span>
 898       }
 899     }
 900   }
 901 }
 902 
 903 static void gen_special_dispatch(MacroAssembler *masm,
 904                                  int total_args_passed,
 905                                  vmIntrinsics::ID special_dispatch,
 906                                  const BasicType *sig_bt,
 907                                  const VMRegPair *regs) {
 908   verify_oop_args(masm, total_args_passed, sig_bt, regs);
 909 
 910   // Now write the args into the outgoing interpreter space.
 911   bool     has_receiver   = false;
 912   Register receiver_reg   = noreg;
 913   int      member_arg_pos = -1;
 914   Register member_reg     = noreg;
 915   int      ref_kind       = MethodHandles::signature_polymorphic_intrinsic_ref_kind(special_dispatch);
 916 
 917   if (ref_kind != 0) {
</pre>
<hr />
<pre>
1503     __ clear_reg(tmp_reg, true, false);  // Don&#39;t set CC.
1504   }
1505   __ compare64_and_branch(first, (RegisterOrConstant)0L, Assembler::bcondEqual, set_out_args);
1506   __ z_lgf(tmp2_reg, Address(first, arrayOopDesc::length_offset_in_bytes()));
1507   __ add2reg(tmp_reg, arrayOopDesc::base_offset_in_bytes(in_elem_type), first);
1508 
1509   __ bind(set_out_args);
1510   move_ptr(masm, tmp, body_arg, framesize_in_slots);
1511   move32_64(masm, tmp2, length_arg, framesize_in_slots);
1512 }
1513 
1514 //----------------------------------------------------------------------
1515 // Wrap a JNI call.
1516 //----------------------------------------------------------------------
1517 #undef USE_RESIZE_FRAME
1518 nmethod *SharedRuntime::generate_native_wrapper(MacroAssembler *masm,
1519                                                 const methodHandle&amp; method,
1520                                                 int compile_id,
1521                                                 BasicType *in_sig_bt,
1522                                                 VMRegPair *in_regs,
<span class="line-modified">1523                                                 BasicType ret_type,</span>
<span class="line-modified">1524                                                 address critical_entry) {</span>
1525   int total_in_args = method-&gt;size_of_parameters();
1526   if (method-&gt;is_method_handle_intrinsic()) {
1527     vmIntrinsics::ID iid = method-&gt;intrinsic_id();
1528     intptr_t start = (intptr_t) __ pc();
1529     int vep_offset = ((intptr_t) __ pc()) - start;
1530 
1531     gen_special_dispatch(masm, total_in_args,
1532                          method-&gt;intrinsic_id(), in_sig_bt, in_regs);
1533 
1534     int frame_complete = ((intptr_t)__ pc()) - start; // Not complete, period.
1535 
1536     __ flush();
1537 
1538     int stack_slots = SharedRuntime::out_preserve_stack_slots();  // No out slots at all, actually.
1539 
1540     return nmethod::new_native_nmethod(method,
1541                                        compile_id,
1542                                        masm-&gt;code(),
1543                                        vep_offset,
1544                                        frame_complete,
1545                                        stack_slots / VMRegImpl::slots_per_word,
1546                                        in_ByteSize(-1),
1547                                        in_ByteSize(-1),
1548                                        (OopMapSet *) NULL);
1549   }
1550 
1551 
1552   ///////////////////////////////////////////////////////////////////////
1553   //
1554   //  Precalculations before generating any code
1555   //
1556   ///////////////////////////////////////////////////////////////////////
1557 
1558   bool is_critical_native = true;
<span class="line-modified">1559   address native_func = critical_entry;</span>
1560   if (native_func == NULL) {
1561     native_func = method-&gt;native_function();
1562     is_critical_native = false;
1563   }
1564   assert(native_func != NULL, &quot;must have function&quot;);
1565 
1566   //---------------------------------------------------------------------
1567   // We have received a description of where all the java args are located
1568   // on entry to the wrapper. We need to convert these args to where
1569   // the jni function will expect them. To figure out where they go
1570   // we convert the java signature to a C signature by inserting
1571   // the hidden arguments as arg[0] and possibly arg[1] (static method).
1572   //
1573   // The first hidden argument arg[0] is a pointer to the JNI environment.
1574   // It is generated for every call.
1575   // The second argument arg[1] to the JNI call, which is hidden for static
1576   // methods, is the boxed lock object. For static calls, the lock object
1577   // is the static method itself. The oop is constructed here. for instance
1578   // calls, the lock is performed on the object itself, the pointer of
1579   // which is passed as the first visible argument.
</pre>
<hr />
<pre>
1603   VMRegPair *out_regs   = NEW_RESOURCE_ARRAY(VMRegPair, total_c_args);
1604   BasicType* in_elem_bt = NULL;
1605 
1606   // Create the signature for the C call:
1607   //   1) add the JNIEnv*
1608   //   2) add the class if the method is static
1609   //   3) copy the rest of the incoming signature (shifted by the number of
1610   //      hidden arguments)
1611 
1612   int argc = 0;
1613   if (!is_critical_native) {
1614     out_sig_bt[argc++] = T_ADDRESS;
1615     if (method-&gt;is_static()) {
1616       out_sig_bt[argc++] = T_OBJECT;
1617     }
1618 
1619     for (int i = 0; i &lt; total_in_args; i++) {
1620       out_sig_bt[argc++] = in_sig_bt[i];
1621     }
1622   } else {

1623     in_elem_bt = NEW_RESOURCE_ARRAY(BasicType, total_in_args);
1624     SignatureStream ss(method-&gt;signature());
1625     int o = 0;
1626     for (int i = 0; i &lt; total_in_args; i++, o++) {
1627       if (in_sig_bt[i] == T_ARRAY) {
1628         // Arrays are passed as tuples (int, elem*).
<span class="line-modified">1629         ss.skip_array_prefix(1);  // skip one &#39;[&#39;</span>
<span class="line-modified">1630         assert(ss.is_primitive(), &quot;primitive type expected&quot;);</span>
<span class="line-modified">1631         in_elem_bt[o] = ss.type();</span>













1632       } else {
1633         in_elem_bt[o] = T_VOID;
1634       }
1635       if (in_sig_bt[i] != T_VOID) {
<span class="line-modified">1636         assert(in_sig_bt[i] == ss.type() ||</span>
<span class="line-added">1637                in_sig_bt[i] == T_ARRAY, &quot;must match&quot;);</span>
1638         ss.next();
1639       }
1640     }
1641     assert(total_in_args == o, &quot;must match&quot;);
1642 
1643     for (int i = 0; i &lt; total_in_args; i++) {
1644       if (in_sig_bt[i] == T_ARRAY) {
1645         // Arrays are passed as tuples (int, elem*).
1646         out_sig_bt[argc++] = T_INT;
1647         out_sig_bt[argc++] = T_ADDRESS;
1648       } else {
1649         out_sig_bt[argc++] = in_sig_bt[i];
1650       }
1651     }
1652   }
1653 
1654   ///////////////////////////////////////////////////////////////////////
1655   // Now figure out where the args must be stored and how much stack space
1656   // they require (neglecting out_preserve_stack_slots but providing space
1657   // for storing the first five register arguments).
</pre>
<hr />
<pre>
1805   unsigned int wrapper_FrameDone;
1806   unsigned int wrapper_CRegsSet;
1807   Label     handle_pending_exception;
1808   Label     ic_miss;
1809 
1810   //---------------------------------------------------------------------
1811   // Unverified entry point (UEP)
1812   //---------------------------------------------------------------------
1813   wrapper_UEPStart = __ offset();
1814 
1815   // check ic: object class &lt;-&gt; cached class
1816   if (!method_is_static) __ nmethod_UEP(ic_miss);
1817   // Fill with nops (alignment of verified entry point).
1818   __ align(CodeEntryAlignment);
1819 
1820   //---------------------------------------------------------------------
1821   // Verified entry point (VEP)
1822   //---------------------------------------------------------------------
1823   wrapper_VEPStart = __ offset();
1824 
<span class="line-added">1825   if (VM_Version::supports_fast_class_init_checks() &amp;&amp; method-&gt;needs_clinit_barrier()) {</span>
<span class="line-added">1826     Label L_skip_barrier;</span>
<span class="line-added">1827     Register klass = Z_R1_scratch;</span>
<span class="line-added">1828     // Notify OOP recorder (don&#39;t need the relocation)</span>
<span class="line-added">1829     AddressLiteral md = __ constant_metadata_address(method-&gt;method_holder());</span>
<span class="line-added">1830     __ load_const_optimized(klass, md.value());</span>
<span class="line-added">1831     __ clinit_barrier(klass, Z_thread, &amp;L_skip_barrier /*L_fast_path*/);</span>
<span class="line-added">1832 </span>
<span class="line-added">1833     __ load_const_optimized(klass, SharedRuntime::get_handle_wrong_method_stub());</span>
<span class="line-added">1834     __ z_br(klass);</span>
<span class="line-added">1835 </span>
<span class="line-added">1836     __ bind(L_skip_barrier);</span>
<span class="line-added">1837   }</span>
<span class="line-added">1838 </span>
1839   __ save_return_pc();
1840   __ generate_stack_overflow_check(frame_size_in_bytes);  // Check before creating frame.
1841 #ifndef USE_RESIZE_FRAME
1842   __ push_frame(frame_size_in_bytes);                     // Create a new frame for the wrapper.
1843 #else
1844   __ resize_frame(-frame_size_in_bytes, Z_R0_scratch);    // No new frame for the wrapper.
1845                                                           // Just resize the existing one.
1846 #endif
1847 
1848   wrapper_FrameDone = __ offset();
1849 
1850   __ verify_thread();
1851 
1852   // Native nmethod wrappers never take possession of the oop arguments.
1853   // So the caller will gc the arguments.
1854   // The only thing we need an oopMap for is if the call is static.
1855   //
1856   // An OopMap for lock (and class if static), and one for the VM call itself
1857   OopMapSet  *oop_maps        = new OopMapSet();
1858   OopMap     *map             = new OopMap(stack_slots * 2, 0 /* arg_slots*/);
</pre>
<hr />
<pre>
2290     // exception in pending_exception and not in a register. Kind of clumsy,
2291     // since all folks who branch to forward_exception must have tested
2292     // pending_exception first and hence have it in a register already.
2293     __ z_stg(R_exc, Address(Z_thread, Thread::pending_exception_offset()));
2294     restore_native_result(masm, ret_type, workspace_slot_offset);
2295     __ z_bru(done);
2296     __ z_illtrap(0x66);
2297 
2298     __ bind(done);
2299   }
2300 
2301 
2302   //--------------------------------------------------------------------
2303   // Clear &quot;last Java frame&quot; SP and PC.
2304   //--------------------------------------------------------------------
2305   __ verify_thread(); // Z_thread must be correct.
2306 
2307   __ reset_last_Java_frame();
2308 
2309   // Unpack oop result, e.g. JNIHandles::resolve result.
<span class="line-modified">2310   if (is_reference_type(ret_type)) {</span>
2311     __ resolve_jobject(Z_RET, /* tmp1 */ Z_R13, /* tmp2 */ Z_R7);
2312   }
2313 
2314   if (CheckJNICalls) {
2315     // clear_pending_jni_exception_check
2316     __ clear_mem(Address(Z_thread, JavaThread::pending_jni_exception_check_fn_offset()), sizeof(oop));
2317   }
2318 
2319   // Reset handle block.
2320   if (!is_critical_native) {
2321     __ z_lg(Z_R1_scratch, Address(Z_thread, JavaThread::active_handles_offset()));
2322     __ clear_mem(Address(Z_R1_scratch, JNIHandleBlock::top_offset_in_bytes()), 4);
2323 
2324     // Check for pending exceptions.
2325     __ load_and_test_long(Z_R0, Address(Z_thread, Thread::pending_exception_offset()));
2326     __ z_brne(handle_pending_exception);
2327   }
2328 
2329 
2330   //////////////////////////////////////////////////////////////////////
</pre>
<hr />
<pre>
2372   //////////////////////////////////////////////////////////////////////
2373   // end of code generation
2374   //////////////////////////////////////////////////////////////////////
2375 
2376 
2377   nmethod *nm = nmethod::new_native_nmethod(method,
2378                                             compile_id,
2379                                             masm-&gt;code(),
2380                                             (int)(wrapper_VEPStart-wrapper_CodeStart),
2381                                             (int)(wrapper_FrameDone-wrapper_CodeStart),
2382                                             stack_slots / VMRegImpl::slots_per_word,
2383                                             (method_is_static ? in_ByteSize(klass_offset) : in_ByteSize(receiver_offset)),
2384                                             in_ByteSize(lock_offset),
2385                                             oop_maps);
2386 
2387   if (is_critical_native) {
2388     nm-&gt;set_lazy_critical_native(true);
2389   }
2390 
2391   return nm;




2392 }
2393 
2394 static address gen_c2i_adapter(MacroAssembler  *masm,
2395                                int total_args_passed,
2396                                int comp_args_on_stack,
2397                                const BasicType *sig_bt,
2398                                const VMRegPair *regs,
2399                                Label &amp;skip_fixup) {
2400   // Before we get into the guts of the C2I adapter, see if we should be here
2401   // at all. We&#39;ve come from compiled code and are attempting to jump to the
2402   // interpreter, which means the caller made a static call to get here
2403   // (vcalls always get a compiled target if there is one). Check for a
2404   // compiled target. If there is one, we need to patch the caller&#39;s call.
2405 
2406   // These two defs MUST MATCH code in gen_i2c2i_adapter!
2407   const Register ientry = Z_R11;
2408   const Register code   = Z_R11;
2409 
2410   address c2i_entrypoint;
2411   Label   patch_callsite;
</pre>
<hr />
<pre>
2589         ld_offset -= 2 * wordSize;
2590       }
2591     } else {
2592       if (r_1-&gt;is_stack()) {
2593         // Must do a memory to memory move.
2594         int st_off = (r_1-&gt;reg2stack() + SharedRuntime::out_preserve_stack_slots()) * VMRegImpl::stack_slot_size;
2595 
2596         if (!r_2-&gt;is_valid()) {
2597           __ z_mvc(Address(Z_SP, st_off), Address(ld_ptr, ld_offset), sizeof(void*));
2598         } else {
2599           // In 64bit, longs are given 2 64-bit slots in the interpreter, but the
2600           // data is passed in only 1 slot.
2601           if (sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {
2602             ld_offset -= wordSize;
2603           }
2604           __ z_mvc(Address(Z_SP, st_off), Address(ld_ptr, ld_offset), sizeof(void*));
2605         }
2606       } else {
2607         if (!r_2-&gt;is_valid()) {
2608           // Not sure we need to do this but it shouldn&#39;t hurt.
<span class="line-modified">2609           if (is_reference_type(sig_bt[i]) || sig_bt[i] == T_ADDRESS) {</span>
2610             __ z_lg(r_1-&gt;as_Register(), ld_offset, ld_ptr);
2611           } else {
2612             __ z_l(r_1-&gt;as_Register(), ld_offset, ld_ptr);
2613           }
2614         } else {
2615           // In 64bit, longs are given 2 64-bit slots in the interpreter, but the
2616           // data is passed in only 1 slot.
2617           if (sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {
2618             ld_offset -= wordSize;
2619           }
2620           __ z_lg(r_1-&gt;as_Register(), ld_offset, ld_ptr);
2621         }
2622       }
2623       ld_offset -= wordSize;
2624     }
2625   }
2626 
2627   // Jump to the compiled code just as if compiled code was doing it.
2628   // load target address from method oop:
2629   __ z_lg(Z_R1_scratch, Address(Z_method, Method::from_compiled_offset()));
</pre>
<hr />
<pre>
2657 
2658   Label skip_fixup;
2659   {
2660     Label ic_miss;
2661     const int klass_offset           = oopDesc::klass_offset_in_bytes();
2662     const int holder_klass_offset    = CompiledICHolder::holder_klass_offset();
2663     const int holder_metadata_offset = CompiledICHolder::holder_metadata_offset();
2664 
2665     // Out-of-line call to ic_miss handler.
2666     __ call_ic_miss_handler(ic_miss, 0x11, 0, Z_R1_scratch);
2667 
2668     // Unverified Entry Point UEP
2669     __ align(CodeEntryAlignment);
2670     c2i_unverified_entry = __ pc();
2671 
2672     // Check the pointers.
2673     if (!ImplicitNullChecks || MacroAssembler::needs_explicit_null_check(klass_offset)) {
2674       __ z_ltgr(Z_ARG1, Z_ARG1);
2675       __ z_bre(ic_miss);
2676     }
<span class="line-modified">2677     __ verify_oop(Z_ARG1, FILE_AND_LINE);</span>
2678 
2679     // Check ic: object class &lt;-&gt; cached class
2680     // Compress cached class for comparison. That&#39;s more efficient.
2681     if (UseCompressedClassPointers) {
2682       __ z_lg(Z_R11, holder_klass_offset, Z_method);             // Z_R11 is overwritten a few instructions down anyway.
2683       __ compare_klass_ptr(Z_R11, klass_offset, Z_ARG1, false); // Cached class can&#39;t be zero.
2684     } else {
2685       __ z_clc(klass_offset, sizeof(void *)-1, Z_ARG1, holder_klass_offset, Z_method);
2686     }
2687     __ z_brne(ic_miss);  // Cache miss: call runtime to handle this.
2688 
2689     // This def MUST MATCH code in gen_c2i_adapter!
2690     const Register code = Z_R11;
2691 
2692     __ z_lg(Z_method, holder_metadata_offset, Z_method);
2693     __ load_and_test_long(Z_R0, method_(code));
2694     __ z_brne(ic_miss);  // Cache miss: call runtime to handle this.
2695 
2696     // Fallthru to VEP. Duplicate LTG, but saved taken branch.
2697   }
2698 
<span class="line-modified">2699   address c2i_entry = __ pc();</span>
<span class="line-modified">2700 </span>
<span class="line-added">2701   // Class initialization barrier for static methods</span>
<span class="line-added">2702   address c2i_no_clinit_check_entry = NULL;</span>
<span class="line-added">2703   if (VM_Version::supports_fast_class_init_checks()) {</span>
<span class="line-added">2704     Label L_skip_barrier;</span>
<span class="line-added">2705 </span>
<span class="line-added">2706     { // Bypass the barrier for non-static methods</span>
<span class="line-added">2707       __ testbit(Address(Z_method, Method::access_flags_offset()), JVM_ACC_STATIC_BIT);</span>
<span class="line-added">2708       __ z_bfalse(L_skip_barrier); // non-static</span>
<span class="line-added">2709     }</span>
<span class="line-added">2710 </span>
<span class="line-added">2711     Register klass = Z_R11;</span>
<span class="line-added">2712     __ load_method_holder(klass, Z_method);</span>
<span class="line-added">2713     __ clinit_barrier(klass, Z_thread, &amp;L_skip_barrier /*L_fast_path*/);</span>
<span class="line-added">2714 </span>
<span class="line-added">2715     __ load_const_optimized(klass, SharedRuntime::get_handle_wrong_method_stub());</span>
<span class="line-added">2716     __ z_br(klass);</span>
<span class="line-added">2717 </span>
<span class="line-added">2718     __ bind(L_skip_barrier);</span>
<span class="line-added">2719     c2i_no_clinit_check_entry = __ pc();</span>
<span class="line-added">2720   }</span>
<span class="line-added">2721 </span>
<span class="line-added">2722   gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);</span>
2723 
<span class="line-modified">2724   return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);</span>
2725 }
2726 
2727 // This function returns the adjust size (in number of words) to a c2i adapter
2728 // activation for use during deoptimization.
2729 //
2730 // Actually only compiled frames need to be adjusted, but it
2731 // doesn&#39;t harm to adjust entry and interpreter frames, too.
2732 //
2733 int Deoptimization::last_frame_adjust(int callee_parameters, int callee_locals) {
2734   assert(callee_locals &gt;= callee_parameters,
2735           &quot;test and remove; got more parms than locals&quot;);
2736   // Handle the abi adjustment here instead of doing it in push_skeleton_frames.
2737   return (callee_locals - callee_parameters) * Interpreter::stackElementWords +
2738          frame::z_parent_ijava_frame_abi_size / BytesPerWord;
2739 }
2740 
2741 uint SharedRuntime::out_preserve_stack_slots() {
2742   return frame::z_jit_out_preserve_size/VMRegImpl::stack_slot_size;
2743 }
2744 
</pre>
<hr />
<pre>
2847   CodeBuffer buffer(&quot;deopt_blob&quot;, 2048, 1024);
2848   InterpreterMacroAssembler* masm = new InterpreterMacroAssembler(&amp;buffer);
2849   Label exec_mode_initialized;
2850   OopMap* map = NULL;
2851   OopMapSet *oop_maps = new OopMapSet();
2852 
2853   unsigned int start_off = __ offset();
2854   Label cont;
2855 
2856   // --------------------------------------------------------------------------
2857   // Normal entry (non-exception case)
2858   //
2859   // We have been called from the deopt handler of the deoptee.
2860   // Z_R14 points behind the call in the deopt handler. We adjust
2861   // it such that it points to the start of the deopt handler.
2862   // The return_pc has been stored in the frame of the deoptee and
2863   // will replace the address of the deopt_handler in the call
2864   // to Deoptimization::fetch_unroll_info below.
2865   // The (int) cast is necessary, because -((unsigned int)14)
2866   // is an unsigned int.
<span class="line-modified">2867   __ add2reg(Z_R14, -(int)NativeCall::max_instruction_size());</span>
2868 
2869   const Register   exec_mode_reg = Z_tmp_1;
2870 
2871   // stack: (deoptee, caller of deoptee, ...)
2872 
2873   // pushes an &quot;unpack&quot; frame
2874   // R14 contains the return address pointing into the deoptimized
2875   // nmethod that was valid just before the nmethod was deoptimized.
2876   // save R14 into the deoptee frame.  the `fetch_unroll_info&#39;
2877   // procedure called below will read it from there.
2878   map = RegisterSaver::save_live_registers(masm, RegisterSaver::all_registers);
2879 
2880   // note the entry point.
2881   __ load_const_optimized(exec_mode_reg, Deoptimization::Unpack_deopt);
2882   __ z_bru(exec_mode_initialized);
2883 
2884 #ifndef COMPILER1
2885   int reexecute_offset = 1; // odd offset will produce odd pc, which triggers an hardware trap
2886 #else
2887   // --------------------------------------------------------------------------
</pre>
<hr />
<pre>
2926   // Exceptiop oop and throwing PC are passed in JavaThread
2927 
2928   // load throwing pc from JavaThread and us it as the return address of the current frame.
2929   __ z_lg(Z_R1_scratch, Address(Z_thread, JavaThread::exception_pc_offset()));
2930 
2931   // Save everything in sight.
2932   (void) RegisterSaver::save_live_registers(masm, RegisterSaver::all_registers, Z_R1_scratch);
2933 
2934   // Now it is safe to overwrite any register
2935 
2936   // Clear the exception pc field in JavaThread
2937   __ clear_mem(Address(Z_thread, JavaThread::exception_pc_offset()), 8);
2938 
2939   // Deopt during an exception.  Save exec mode for unpack_frames.
2940   __ load_const_optimized(exec_mode_reg, Deoptimization::Unpack_exception);
2941 
2942 
2943 #ifdef ASSERT
2944   // verify that there is really an exception oop in JavaThread
2945   __ z_lg(Z_ARG1, Address(Z_thread, JavaThread::exception_oop_offset()));
<span class="line-modified">2946   __ MacroAssembler::verify_oop(Z_ARG1, FILE_AND_LINE);</span>
2947 
2948   // verify that there is no pending exception
2949   __ asm_assert_mem8_is_zero(in_bytes(Thread::pending_exception_offset()), Z_thread,
2950                              &quot;must not have pending exception here&quot;, __LINE__);
2951 #endif
2952 
2953   // --------------------------------------------------------------------------
2954   // At this point, the live registers are saved and
2955   // the exec_mode_reg has been set up correctly.
2956   __ bind(exec_mode_initialized);
2957 
2958   // stack: (&quot;unpack&quot; frame, deoptee, caller_of_deoptee, ...).
2959 
2960   {
2961   const Register unroll_block_reg  = Z_tmp_2;
2962 
2963   // we need to set `last_Java_frame&#39; because `fetch_unroll_info&#39; will
2964   // call `last_Java_frame()&#39;.  however we can&#39;t block and no gc will
2965   // occur so we don&#39;t need an oopmap. the value of the pc in the
2966   // frame is not particularly important.  it just needs to identify the blob.
</pre>
</td>
</tr>
</table>
<center><a href="s390.ad.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_s390.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>