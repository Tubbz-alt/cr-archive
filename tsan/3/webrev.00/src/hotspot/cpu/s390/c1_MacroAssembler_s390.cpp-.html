<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/cpu/s390/c1_MacroAssembler_s390.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2016, 2018, Oracle and/or its affiliates. All rights reserved.
  3  * Copyright (c) 2016 SAP SE. All rights reserved.
  4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5  *
  6  * This code is free software; you can redistribute it and/or modify it
  7  * under the terms of the GNU General Public License version 2 only, as
  8  * published by the Free Software Foundation.
  9  *
 10  * This code is distributed in the hope that it will be useful, but WITHOUT
 11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13  * version 2 for more details (a copy is included in the LICENSE file that
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
 23  *
 24  */
 25 
 26 #include &quot;precompiled.hpp&quot;
 27 #include &quot;asm/macroAssembler.inline.hpp&quot;
 28 #include &quot;c1/c1_MacroAssembler.hpp&quot;
 29 #include &quot;c1/c1_Runtime1.hpp&quot;
 30 #include &quot;classfile/systemDictionary.hpp&quot;
 31 #include &quot;gc/shared/collectedHeap.hpp&quot;
 32 #include &quot;interpreter/interpreter.hpp&quot;
 33 #include &quot;oops/arrayOop.hpp&quot;
 34 #include &quot;oops/markOop.hpp&quot;
 35 #include &quot;runtime/basicLock.hpp&quot;
 36 #include &quot;runtime/biasedLocking.hpp&quot;
 37 #include &quot;runtime/os.hpp&quot;
 38 #include &quot;runtime/sharedRuntime.hpp&quot;
 39 #include &quot;runtime/stubRoutines.hpp&quot;
 40 
 41 void C1_MacroAssembler::inline_cache_check(Register receiver, Register iCache) {
 42   Label ic_miss, ic_hit;
 43   verify_oop(receiver);
 44   int klass_offset = oopDesc::klass_offset_in_bytes();
 45 
 46   if (!ImplicitNullChecks || MacroAssembler::needs_explicit_null_check(klass_offset)) {
 47     if (VM_Version::has_CompareBranch()) {
 48       z_cgij(receiver, 0, Assembler::bcondEqual, ic_miss);
 49     } else {
 50       z_ltgr(receiver, receiver);
 51       z_bre(ic_miss);
 52     }
 53   }
 54 
 55   compare_klass_ptr(iCache, klass_offset, receiver, false);
 56   z_bre(ic_hit);
 57 
 58   // If icache check fails, then jump to runtime routine.
 59   // Note: RECEIVER must still contain the receiver!
 60   load_const_optimized(Z_R1_scratch, AddressLiteral(SharedRuntime::get_ic_miss_stub()));
 61   z_br(Z_R1_scratch);
 62   align(CodeEntryAlignment);
 63   bind(ic_hit);
 64 }
 65 
 66 void C1_MacroAssembler::explicit_null_check(Register base) {
 67   ShouldNotCallThis(); // unused
 68 }
 69 
 70 void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes) {
 71   assert(bang_size_in_bytes &gt;= frame_size_in_bytes, &quot;stack bang size incorrect&quot;);
 72   generate_stack_overflow_check(bang_size_in_bytes);
 73   save_return_pc();
 74   push_frame(frame_size_in_bytes);
 75 }
 76 
 77 void C1_MacroAssembler::verified_entry() {
 78   if (C1Breakpoint) z_illtrap(0xC1);
 79 }
 80 
 81 void C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Label&amp; slow_case) {
 82   const int hdr_offset = oopDesc::mark_offset_in_bytes();
 83   assert_different_registers(hdr, obj, disp_hdr);
 84   NearLabel done;
 85 
 86   verify_oop(obj);
 87 
 88   // Load object header.
 89   z_lg(hdr, Address(obj, hdr_offset));
 90 
 91   // Save object being locked into the BasicObjectLock...
 92   z_stg(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));
 93 
 94   if (UseBiasedLocking) {
 95     biased_locking_enter(obj, hdr, Z_R1_scratch, Z_R0_scratch, done, &amp;slow_case);
 96   }
 97 
 98   // and mark it as unlocked.
 99   z_oill(hdr, markOopDesc::unlocked_value);
100   // Save unlocked object header into the displaced header location on the stack.
101   z_stg(hdr, Address(disp_hdr, (intptr_t)0));
102   // Test if object header is still the same (i.e. unlocked), and if so, store the
103   // displaced header address in the object header. If it is not the same, get the
104   // object header instead.
105   z_csg(hdr, disp_hdr, hdr_offset, obj);
106   // If the object header was the same, we&#39;re done.
107   if (PrintBiasedLockingStatistics) {
108     Unimplemented();
109 #if 0
110     cond_inc32(Assembler::equal,
111                ExternalAddress((address)BiasedLocking::fast_path_entry_count_addr()));
112 #endif
113   }
114   branch_optimized(Assembler::bcondEqual, done);
115   // If the object header was not the same, it is now in the hdr register.
116   // =&gt; Test if it is a stack pointer into the same stack (recursive locking), i.e.:
117   //
118   // 1) (hdr &amp; markOopDesc::lock_mask_in_place) == 0
119   // 2) rsp &lt;= hdr
120   // 3) hdr &lt;= rsp + page_size
121   //
122   // These 3 tests can be done by evaluating the following expression:
123   //
124   // (hdr - Z_SP) &amp; (~(page_size-1) | markOopDesc::lock_mask_in_place)
125   //
126   // assuming both the stack pointer and page_size have their least
127   // significant 2 bits cleared and page_size is a power of 2
128   z_sgr(hdr, Z_SP);
129 
130   load_const_optimized(Z_R0_scratch, (~(os::vm_page_size()-1) | markOopDesc::lock_mask_in_place));
131   z_ngr(hdr, Z_R0_scratch); // AND sets CC (result eq/ne 0).
132   // For recursive locking, the result is zero. =&gt; Save it in the displaced header
133   // location (NULL in the displaced hdr location indicates recursive locking).
134   z_stg(hdr, Address(disp_hdr, (intptr_t)0));
135   // Otherwise we don&#39;t care about the result and handle locking via runtime call.
136   branch_optimized(Assembler::bcondNotZero, slow_case);
137   // done
138   bind(done);
139 }
140 
141 void C1_MacroAssembler::unlock_object(Register hdr, Register obj, Register disp_hdr, Label&amp; slow_case) {
142   const int aligned_mask = BytesPerWord -1;
143   const int hdr_offset = oopDesc::mark_offset_in_bytes();
144   assert_different_registers(hdr, obj, disp_hdr);
145   NearLabel done;
146 
147   if (UseBiasedLocking) {
148     // Load object.
149     z_lg(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));
150     biased_locking_exit(obj, hdr, done);
151   }
152 
153   // Load displaced header.
154   z_ltg(hdr, Address(disp_hdr, (intptr_t)0));
155   // If the loaded hdr is NULL we had recursive locking, and we are done.
156   z_bre(done);
157   if (!UseBiasedLocking) {
158     // Load object.
159     z_lg(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));
160   }
161   verify_oop(obj);
162   // Test if object header is pointing to the displaced header, and if so, restore
163   // the displaced header in the object. If the object header is not pointing to
164   // the displaced header, get the object header instead.
165   z_csg(disp_hdr, hdr, hdr_offset, obj);
166   // If the object header was not pointing to the displaced header,
167   // we do unlocking via runtime call.
168   branch_optimized(Assembler::bcondNotEqual, slow_case);
169   // done
170   bind(done);
171 }
172 
173 void C1_MacroAssembler::try_allocate(
174   Register obj,                        // result: Pointer to object after successful allocation.
175   Register var_size_in_bytes,          // Object size in bytes if unknown at compile time; invalid otherwise.
176   int      con_size_in_bytes,          // Object size in bytes if   known at compile time.
177   Register t1,                         // Temp register: Must be global register for incr_allocated_bytes.
178   Label&amp;   slow_case                   // Continuation point if fast allocation fails.
179 ) {
180   if (UseTLAB) {
181     tlab_allocate(obj, var_size_in_bytes, con_size_in_bytes, t1, slow_case);
182   } else {
183     // Allocation in shared Eden not implemented, because sapjvm allocation trace does not allow it.
184     z_brul(slow_case);
185   }
186 }
187 
188 void C1_MacroAssembler::initialize_header(Register obj, Register klass, Register len, Register Rzero, Register t1) {
189   assert_different_registers(obj, klass, len, t1, Rzero);
190   if (UseBiasedLocking &amp;&amp; !len-&gt;is_valid()) {
191     assert_different_registers(obj, klass, len, t1);
192     z_lg(t1, Address(klass, Klass::prototype_header_offset()));
193   } else {
194     // This assumes that all prototype bits fit in an int32_t.
195     load_const_optimized(t1, (intx)markOopDesc::prototype());
196   }
197   z_stg(t1, Address(obj, oopDesc::mark_offset_in_bytes()));
198 
199   if (len-&gt;is_valid()) {
200     // Length will be in the klass gap, if one exists.
201     z_st(len, Address(obj, arrayOopDesc::length_offset_in_bytes()));
202   } else if (UseCompressedClassPointers) {
203     store_klass_gap(Rzero, obj);  // Zero klass gap for compressed oops.
204   }
205   store_klass(klass, obj, t1);
206 }
207 
208 void C1_MacroAssembler::initialize_body(Register objectFields, Register len_in_bytes, Register Rzero) {
209   Label done;
210   assert_different_registers(objectFields, len_in_bytes, Rzero);
211 
212   // Initialize object fields.
213   // See documentation for MVCLE instruction!!!
214   assert(objectFields-&gt;encoding()%2==0, &quot;objectFields must be an even register&quot;);
215   assert(len_in_bytes-&gt;encoding() == (objectFields-&gt;encoding()+1), &quot;objectFields and len_in_bytes must be a register pair&quot;);
216   assert(Rzero-&gt;encoding()%2==1, &quot;Rzero must be an odd register&quot;);
217 
218   // Use Rzero as src length, then mvcle will copy nothing
219   // and fill the object with the padding value 0.
220   move_long_ext(objectFields, as_Register(Rzero-&gt;encoding()-1), 0);
221   bind(done);
222 }
223 
224 void C1_MacroAssembler::allocate_object(
225   Register obj,                        // Result: pointer to object after successful allocation.
226   Register t1,                         // temp register
227   Register t2,                         // temp register: Must be a global register for try_allocate.
228   int      hdr_size,                   // object header size in words
229   int      obj_size,                   // object size in words
230   Register klass,                      // object klass
231   Label&amp;   slow_case                   // Continuation point if fast allocation fails.
232 ) {
233   assert_different_registers(obj, t1, t2, klass);
234 
235   // Allocate space and initialize header.
236   try_allocate(obj, noreg, obj_size * wordSize, t1, slow_case);
237 
238   initialize_object(obj, klass, noreg, obj_size * HeapWordSize, t1, t2);
239 }
240 
241 void C1_MacroAssembler::initialize_object(
242   Register obj,                        // result: Pointer to object after successful allocation.
243   Register klass,                      // object klass
244   Register var_size_in_bytes,          // Object size in bytes if unknown at compile time; invalid otherwise.
245   int      con_size_in_bytes,          // Object size in bytes if   known at compile time.
246   Register t1,                         // temp register
247   Register t2                          // temp register
248  ) {
249   assert((con_size_in_bytes &amp; MinObjAlignmentInBytesMask) == 0,
250          &quot;con_size_in_bytes is not multiple of alignment&quot;);
251   assert(var_size_in_bytes == noreg, &quot;not implemented&quot;);
252   const int hdr_size_in_bytes = instanceOopDesc::header_size() * HeapWordSize;
253 
254   const Register Rzero = t2;
255 
256   z_xgr(Rzero, Rzero);
257   initialize_header(obj, klass, noreg, Rzero, t1);
258 
259   // Clear rest of allocated space.
260   const int threshold = 4 * BytesPerWord;
261   if (con_size_in_bytes &lt;= threshold) {
262     // Use explicit null stores.
263     // code size = 6*n bytes (n = number of fields to clear)
264     for (int i = hdr_size_in_bytes; i &lt; con_size_in_bytes; i += BytesPerWord)
265       z_stg(Rzero, Address(obj, i));
266   } else {
267     // Code size generated by initialize_body() is 16.
268     Register object_fields = Z_R0_scratch;
269     Register len_in_bytes  = Z_R1_scratch;
270     z_la(object_fields, hdr_size_in_bytes, obj);
271     load_const_optimized(len_in_bytes, con_size_in_bytes - hdr_size_in_bytes);
272     initialize_body(object_fields, len_in_bytes, Rzero);
273   }
274 
275   // Dtrace support is unimplemented.
276   //  if (CURRENT_ENV-&gt;dtrace_alloc_probes()) {
277   //    assert(obj == rax, &quot;must be&quot;);
278   //    call(RuntimeAddress(Runtime1::entry_for (Runtime1::dtrace_object_alloc_id)));
279   //  }
280 
281   verify_oop(obj);
282 }
283 
284 void C1_MacroAssembler::allocate_array(
285   Register obj,                        // result: Pointer to array after successful allocation.
286   Register len,                        // array length
287   Register t1,                         // temp register
288   Register t2,                         // temp register
289   int      hdr_size,                   // object header size in words
290   int      elt_size,                   // element size in bytes
291   Register klass,                      // object klass
292   Label&amp;   slow_case                   // Continuation point if fast allocation fails.
293 ) {
294   assert_different_registers(obj, len, t1, t2, klass);
295 
296   // Determine alignment mask.
297   assert(!(BytesPerWord &amp; 1), &quot;must be a multiple of 2 for masking code to work&quot;);
298 
299   // Check for negative or excessive length.
300   compareU64_and_branch(len, (int32_t)max_array_allocation_length, bcondHigh, slow_case);
301 
302   // Compute array size.
303   // Note: If 0 &lt;= len &lt;= max_length, len*elt_size + header + alignment is
304   // smaller or equal to the largest integer. Also, since top is always
305   // aligned, we can do the alignment here instead of at the end address
306   // computation.
307   const Register arr_size = t2;
308   switch (elt_size) {
309     case  1: lgr_if_needed(arr_size, len); break;
310     case  2: z_sllg(arr_size, len, 1); break;
311     case  4: z_sllg(arr_size, len, 2); break;
312     case  8: z_sllg(arr_size, len, 3); break;
313     default: ShouldNotReachHere();
314   }
315   add2reg(arr_size, hdr_size * wordSize + MinObjAlignmentInBytesMask); // Add space for header &amp; alignment.
316   z_nill(arr_size, (~MinObjAlignmentInBytesMask) &amp; 0xffff);            // Align array size.
317 
318   try_allocate(obj, arr_size, 0, t1, slow_case);
319 
320   initialize_header(obj, klass, len, noreg, t1);
321 
322   // Clear rest of allocated space.
323   Label done;
324   Register object_fields = t1;
325   Register Rzero = Z_R1_scratch;
326   z_aghi(arr_size, -(hdr_size * BytesPerWord));
327   z_bre(done); // Jump if size of fields is zero.
328   z_la(object_fields, hdr_size * BytesPerWord, obj);
329   z_xgr(Rzero, Rzero);
330   initialize_body(object_fields, arr_size, Rzero);
331   bind(done);
332 
333   // Dtrace support is unimplemented.
334   // if (CURRENT_ENV-&gt;dtrace_alloc_probes()) {
335   //   assert(obj == rax, &quot;must be&quot;);
336   //   call(RuntimeAddress(Runtime1::entry_for (Runtime1::dtrace_object_alloc_id)));
337   // }
338 
339   verify_oop(obj);
340 }
341 
342 
343 #ifndef PRODUCT
344 
345 void C1_MacroAssembler::verify_stack_oop(int stack_offset) {
346   Unimplemented();
347   // if (!VerifyOops) return;
348   // verify_oop_addr(Address(SP, stack_offset + STACK_BIAS));
349 }
350 
351 void C1_MacroAssembler::verify_not_null_oop(Register r) {
352   if (!VerifyOops) return;
353   NearLabel not_null;
354   compareU64_and_branch(r, (intptr_t)0, bcondNotEqual, not_null);
355   stop(&quot;non-null oop required&quot;);
356   bind(not_null);
357   verify_oop(r);
358 }
359 
360 void C1_MacroAssembler::invalidate_registers(Register preserve1,
361                                              Register preserve2,
362                                              Register preserve3) {
363   Register dead_value = noreg;
364   for (int i = 0; i &lt; FrameMap::nof_cpu_regs; i++) {
365     Register r = as_Register(i);
366     if (r != preserve1 &amp;&amp; r != preserve2 &amp;&amp; r != preserve3 &amp;&amp; r != Z_SP &amp;&amp; r != Z_thread) {
367       if (dead_value == noreg) {
368         load_const_optimized(r, 0xc1dead);
369         dead_value = r;
370       } else {
371         z_lgr(r, dead_value);
372       }
373     }
374   }
375 }
376 
377 #endif // !PRODUCT
    </pre>
  </body>
</html>