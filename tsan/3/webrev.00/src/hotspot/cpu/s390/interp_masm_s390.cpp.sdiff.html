<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/s390/interp_masm_s390.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="globals_s390.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="interp_masm_s390.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/s390/interp_masm_s390.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2016, 2018, Oracle and/or its affiliates. All rights reserved.</span>
<span class="line-modified">   3  * Copyright (c) 2016, 2018 SAP SE. All rights reserved.</span>
   4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   5  *
   6  * This code is free software; you can redistribute it and/or modify it
   7  * under the terms of the GNU General Public License version 2 only, as
   8  * published by the Free Software Foundation.
   9  *
  10  * This code is distributed in the hope that it will be useful, but WITHOUT
  11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 // Major contributions by AHa, AS, JL, ML.
  27 
  28 #include &quot;precompiled.hpp&quot;
  29 #include &quot;asm/macroAssembler.inline.hpp&quot;
  30 #include &quot;gc/shared/barrierSet.hpp&quot;
  31 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  32 #include &quot;interp_masm_s390.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  35 #include &quot;oops/arrayOop.hpp&quot;
<span class="line-modified">  36 #include &quot;oops/markOop.hpp&quot;</span>
  37 #include &quot;prims/jvmtiExport.hpp&quot;
  38 #include &quot;prims/jvmtiThreadState.hpp&quot;
  39 #include &quot;runtime/basicLock.hpp&quot;
  40 #include &quot;runtime/biasedLocking.hpp&quot;
  41 #include &quot;runtime/frame.inline.hpp&quot;
  42 #include &quot;runtime/safepointMechanism.hpp&quot;
  43 #include &quot;runtime/sharedRuntime.hpp&quot;
  44 #include &quot;runtime/thread.inline.hpp&quot;

  45 
  46 // Implementation of InterpreterMacroAssembler.
  47 // This file specializes the assembler with interpreter-specific macros.
  48 
  49 #ifdef PRODUCT
  50 #define BLOCK_COMMENT(str)
  51 #define BIND(label)        bind(label);
  52 #else
  53 #define BLOCK_COMMENT(str) block_comment(str)
  54 #define BIND(label)        bind(label); BLOCK_COMMENT(#label &quot;:&quot;)
  55 #endif
  56 
  57 void InterpreterMacroAssembler::jump_to_entry(address entry, Register Rscratch) {
  58   assert(entry != NULL, &quot;Entry must have been generated by now&quot;);
  59   assert(Rscratch != Z_R0, &quot;Can&#39;t use R0 for addressing&quot;);
  60   branch_optimized(Assembler::bcondAlways, entry);
  61 }
  62 
  63 void InterpreterMacroAssembler::empty_expression_stack(void) {
  64   get_monitors(Z_R1_scratch);
</pre>
<hr />
<pre>
 397 // load cpool-&gt;resolved_klass_at(index)
 398 void InterpreterMacroAssembler::load_resolved_klass_at_offset(Register cpool, Register offset, Register iklass) {
 399   // int value = *(Rcpool-&gt;int_at_addr(which));
 400   // int resolved_klass_index = extract_low_short_from_int(value);
 401   z_llgh(offset, Address(cpool, offset, sizeof(ConstantPool) + 2)); // offset = resolved_klass_index (s390 is big-endian)
 402   z_sllg(offset, offset, LogBytesPerWord);                          // Convert &#39;index&#39; to &#39;offset&#39;
 403   z_lg(iklass, Address(cpool, ConstantPool::resolved_klasses_offset_in_bytes())); // iklass = cpool-&gt;_resolved_klasses
 404   z_lg(iklass, Address(iklass, offset, Array&lt;Klass*&gt;::base_offset_in_bytes()));
 405 }
 406 
 407 void InterpreterMacroAssembler::get_cache_entry_pointer_at_bcp(Register cache,
 408                                                                Register tmp,
 409                                                                int bcp_offset,
 410                                                                size_t index_size) {
 411   BLOCK_COMMENT(&quot;get_cache_entry_pointer_at_bcp {&quot;);
 412     get_cache_and_index_at_bcp(cache, tmp, bcp_offset, index_size);
 413     add2reg_with_index(cache, in_bytes(ConstantPoolCache::base_offset()), tmp, cache);
 414   BLOCK_COMMENT(&quot;}&quot;);
 415 }
 416 













 417 // Generate a subtype check: branch to ok_is_subtype if sub_klass is
 418 // a subtype of super_klass. Blows registers Rsuper_klass, Rsub_klass, tmp1, tmp2.
 419 void InterpreterMacroAssembler::gen_subtype_check(Register Rsub_klass,
 420                                                   Register Rsuper_klass,
 421                                                   Register Rtmp1,
 422                                                   Register Rtmp2,
 423                                                   Label &amp;ok_is_subtype) {
 424   // Profile the not-null value&#39;s klass.
 425   profile_typecheck(Rtmp1, Rsub_klass, Rtmp2);
 426 
 427   // Do the check.
 428   check_klass_subtype(Rsub_klass, Rsuper_klass, Rtmp1, Rtmp2, ok_is_subtype);
 429 
 430   // Profile the failure of the check.
 431   profile_typecheck_failed(Rtmp1, Rtmp2);
 432 }
 433 
 434 // Pop topmost element from stack. It just disappears.
 435 // Useful if consumed previously by access via stackTop().
 436 void InterpreterMacroAssembler::popx(int len) {
</pre>
<hr />
<pre>
 944   pop_interpreter_frame(return_pc, Z_ARG2, Z_ARG3);
 945   BLOCK_COMMENT(&quot;} remove_activation&quot;);
 946 }
 947 
 948 // lock object
 949 //
 950 // Registers alive
 951 //   monitor - Address of the BasicObjectLock to be used for locking,
 952 //             which must be initialized with the object to lock.
 953 //   object  - Address of the object to be locked.
 954 void InterpreterMacroAssembler::lock_object(Register monitor, Register object) {
 955 
 956   if (UseHeavyMonitors) {
 957     call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),
 958             monitor, /*check_for_exceptions=*/false);
 959     return;
 960   }
 961 
 962   // template code:
 963   //
<span class="line-modified"> 964   // markOop displaced_header = obj-&gt;mark().set_unlocked();</span>
 965   // monitor-&gt;lock()-&gt;set_displaced_header(displaced_header);
<span class="line-modified"> 966   // if (Atomic::cmpxchg(/*ex=*/monitor, /*addr*/obj-&gt;mark_addr(), /*cmp*/displaced_header) == displaced_header) {</span>
 967   //   // We stored the monitor address into the object&#39;s mark word.
 968   // } else if (THREAD-&gt;is_lock_owned((address)displaced_header))
 969   //   // Simple recursive case.
 970   //   monitor-&gt;lock()-&gt;set_displaced_header(NULL);
 971   // } else {
 972   //   // Slow path.
 973   //   InterpreterRuntime::monitorenter(THREAD, monitor);
 974   // }
 975 
 976   const Register displaced_header = Z_ARG5;
 977   const Register object_mark_addr = Z_ARG4;
 978   const Register current_header   = Z_ARG5;
 979 
 980   NearLabel done;
 981   NearLabel slow_case;
 982 
<span class="line-modified"> 983   // markOop displaced_header = obj-&gt;mark().set_unlocked();</span>
 984 
<span class="line-modified"> 985   // Load markOop from object into displaced_header.</span>
 986   z_lg(displaced_header, oopDesc::mark_offset_in_bytes(), object);
 987 
 988   if (UseBiasedLocking) {
 989     biased_locking_enter(object, displaced_header, Z_R1, Z_R0, done, &amp;slow_case);
 990   }
 991 
<span class="line-modified"> 992   // Set displaced_header to be (markOop of object | UNLOCK_VALUE).</span>
<span class="line-modified"> 993   z_oill(displaced_header, markOopDesc::unlocked_value);</span>
 994 
 995   // monitor-&gt;lock()-&gt;set_displaced_header(displaced_header);
 996 
 997   // Initialize the box (Must happen before we update the object mark!).
 998   z_stg(displaced_header, BasicObjectLock::lock_offset_in_bytes() +
 999                           BasicLock::displaced_header_offset_in_bytes(), monitor);
1000 
<span class="line-modified">1001   // if (Atomic::cmpxchg(/*ex=*/monitor, /*addr*/obj-&gt;mark_addr(), /*cmp*/displaced_header) == displaced_header) {</span>
1002 
1003   // Store stack address of the BasicObjectLock (this is monitor) into object.
1004   add2reg(object_mark_addr, oopDesc::mark_offset_in_bytes(), object);
1005 
1006   z_csg(displaced_header, monitor, 0, object_mark_addr);
1007   assert(current_header==displaced_header, &quot;must be same register&quot;); // Identified two registers from z/Architecture.
1008 
1009   z_bre(done);
1010 
1011   // } else if (THREAD-&gt;is_lock_owned((address)displaced_header))
1012   //   // Simple recursive case.
1013   //   monitor-&gt;lock()-&gt;set_displaced_header(NULL);
1014 
1015   // We did not see an unlocked object so try the fast recursive case.
1016 
<span class="line-modified">1017   // Check if owner is self by comparing the value in the markOop of object</span>
1018   // (current_header) with the stack pointer.
1019   z_sgr(current_header, Z_SP);
1020 
1021   assert(os::vm_page_size() &gt; 0xfff, &quot;page size too small - change the constant&quot;);
1022 
1023   // The prior sequence &quot;LGR, NGR, LTGR&quot; can be done better
1024   // (Z_R1 is temp and not used after here).
<span class="line-modified">1025   load_const_optimized(Z_R0, (~(os::vm_page_size()-1) | markOopDesc::lock_mask_in_place));</span>
1026   z_ngr(Z_R0, current_header); // AND sets CC (result eq/ne 0)
1027 
1028   // If condition is true we are done and hence we can store 0 in the displaced
1029   // header indicating it is a recursive lock and be done.
1030   z_brne(slow_case);
1031   z_release();  // Membar unnecessary on zarch AND because the above csg does a sync before and after.
1032   z_stg(Z_R0/*==0!*/, BasicObjectLock::lock_offset_in_bytes() +
1033                       BasicLock::displaced_header_offset_in_bytes(), monitor);
1034   z_bru(done);
1035 
1036   // } else {
1037   //   // Slow path.
1038   //   InterpreterRuntime::monitorenter(THREAD, monitor);
1039 
1040   // None of the above fast optimizations worked so we have to get into the
1041   // slow case of monitor enter.
1042   bind(slow_case);
1043 
1044   call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),
1045           monitor, /*check_for_exceptions=*/false);
1046 
1047   // }
1048 
1049   bind(done);
1050 }
1051 
1052 // Unlocks an object. Used in monitorexit bytecode and remove_activation.
1053 //
1054 // Registers alive
1055 //   monitor - address of the BasicObjectLock to be used for locking,
1056 //             which must be initialized with the object to lock.
1057 //
1058 // Throw IllegalMonitorException if object is not locked by current thread.
1059 void InterpreterMacroAssembler::unlock_object(Register monitor, Register object) {
1060 
1061   if (UseHeavyMonitors) {
<span class="line-modified">1062     call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit),</span>
<span class="line-removed">1063             monitor, /*check_for_exceptions=*/ true);</span>
1064     return;
1065   }
1066 
1067 // else {
1068   // template code:
1069   //
1070   // if ((displaced_header = monitor-&gt;displaced_header()) == NULL) {
1071   //   // Recursive unlock. Mark the monitor unlocked by setting the object field to NULL.
1072   //   monitor-&gt;set_obj(NULL);
<span class="line-modified">1073   // } else if (Atomic::cmpxchg(displaced_header, obj-&gt;mark_addr(), monitor) == monitor) {</span>
1074   //   // We swapped the unlocked mark in displaced_header into the object&#39;s mark word.
1075   //   monitor-&gt;set_obj(NULL);
1076   // } else {
1077   //   // Slow path.
1078   //   InterpreterRuntime::monitorexit(THREAD, monitor);
1079   // }
1080 
1081   const Register displaced_header = Z_ARG4;
1082   const Register current_header   = Z_R1;
1083   Address obj_entry(monitor, BasicObjectLock::obj_offset_in_bytes());
1084   Label done;
1085 
1086   if (object == noreg) {
1087     // In the template interpreter, we must assure that the object
1088     // entry in the monitor is cleared on all paths. Thus we move
1089     // loading up to here, and clear the entry afterwards.
1090     object = Z_ARG3; // Use Z_ARG3 if caller didn&#39;t pass object.
1091     z_lg(object, obj_entry);
1092   }
1093 
1094   assert_different_registers(monitor, object, displaced_header, current_header);
1095 
1096   // if ((displaced_header = monitor-&gt;displaced_header()) == NULL) {
1097   //   // Recursive unlock. Mark the monitor unlocked by setting the object field to NULL.
1098   //   monitor-&gt;set_obj(NULL);
1099 
1100   clear_mem(obj_entry, sizeof(oop));
1101 
1102   if (UseBiasedLocking) {
1103     // The object address from the monitor is in object.
1104     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
1105     biased_locking_exit(object, displaced_header, done);
1106   }
1107 
1108   // Test first if we are in the fast recursive case.
1109   MacroAssembler::load_and_test_long(displaced_header,
1110                                      Address(monitor, BasicObjectLock::lock_offset_in_bytes() +
1111                                                       BasicLock::displaced_header_offset_in_bytes()));
1112   z_bre(done); // displaced_header == 0 -&gt; goto done
1113 
<span class="line-modified">1114   // } else if (Atomic::cmpxchg(displaced_header, obj-&gt;mark_addr(), monitor) == monitor) {</span>
1115   //   // We swapped the unlocked mark in displaced_header into the object&#39;s mark word.
1116   //   monitor-&gt;set_obj(NULL);
1117 
1118   // If we still have a lightweight lock, unlock the object and be done.
1119 
1120   // The markword is expected to be at offset 0.
1121   assert(oopDesc::mark_offset_in_bytes() == 0, &quot;unlock_object: review code below&quot;);
1122 
1123   // We have the displaced header in displaced_header. If the lock is still
1124   // lightweight, it will contain the monitor address and we&#39;ll store the
1125   // displaced header back into the object&#39;s mark word.
1126   z_lgr(current_header, monitor);
1127   z_csg(current_header, displaced_header, 0, object);
1128   z_bre(done);
1129 
1130   // } else {
1131   //   // Slow path.
1132   //   InterpreterRuntime::monitorexit(THREAD, monitor);
1133 
1134   // The lock has been converted into a heavy lock and hence
1135   // we need to get into the slow case.
1136   z_stg(object, obj_entry);   // Restore object entry, has been cleared above.
<span class="line-modified">1137   call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit),</span>
<span class="line-removed">1138           monitor,  /*check_for_exceptions=*/false);</span>
1139 
1140   // }
1141 
1142   bind(done);
1143 }
1144 
1145 void InterpreterMacroAssembler::test_method_data_pointer(Register mdp, Label&amp; zero_continue) {
1146   assert(ProfileInterpreter, &quot;must be profiling interpreter&quot;);
1147   load_and_test_long(mdp, Address(Z_fp, _z_ijava_state_neg(mdx)));
1148   z_brz(zero_continue);
1149 }
1150 
1151 // Set the method data pointer for the current bcp.
1152 void InterpreterMacroAssembler::set_method_data_pointer_for_bcp() {
1153   assert(ProfileInterpreter, &quot;must be profiling interpreter&quot;);
1154   Label    set_mdp;
1155   Register mdp    = Z_ARG4;
1156   Register method = Z_ARG5;
1157 
1158   get_method(method);
</pre>
<hr />
<pre>
1636     bind(profile_continue);
1637   }
1638 }
1639 
1640 // kills: R0, R1, flags, loads klass from obj (if not null)
1641 void InterpreterMacroAssembler::profile_obj_type(Register obj, Address mdo_addr, Register klass, bool cmp_done) {
1642   NearLabel null_seen, init_klass, do_nothing, do_update;
1643 
1644   // Klass = obj is allowed.
1645   const Register tmp = Z_R1;
1646   assert_different_registers(obj, mdo_addr.base(), tmp, Z_R0);
1647   assert_different_registers(klass, mdo_addr.base(), tmp, Z_R0);
1648 
1649   z_lg(tmp, mdo_addr);
1650   if (cmp_done) {
1651     z_brz(null_seen);
1652   } else {
1653     compareU64_and_branch(obj, (intptr_t)0, Assembler::bcondEqual, null_seen);
1654   }
1655 
<span class="line-modified">1656   verify_oop(obj);</span>
1657   load_klass(klass, obj);
1658 
1659   // Klass seen before, nothing to do (regardless of unknown bit).
1660   z_lgr(Z_R0, tmp);
1661   assert(Immediate::is_uimm(~TypeEntries::type_klass_mask, 16), &quot;or change following instruction&quot;);
1662   z_nill(Z_R0, TypeEntries::type_klass_mask &amp; 0xFFFF);
1663   compareU64_and_branch(Z_R0, klass, Assembler::bcondEqual, do_nothing);
1664 
1665   // Already unknown. Nothing to do anymore.
1666   z_tmll(tmp, TypeEntries::type_unknown);
1667   z_brc(Assembler::bcondAllOne, do_nothing);
1668 
1669   z_lgr(Z_R0, tmp);
1670   assert(Immediate::is_uimm(~TypeEntries::type_mask, 16), &quot;or change following instruction&quot;);
1671   z_nill(Z_R0, TypeEntries::type_mask &amp; 0xFFFF);
1672   compareU64_and_branch(Z_R0, (intptr_t)0, Assembler::bcondEqual, init_klass);
1673 
1674   // Different than before. Cannot keep accurate profile.
1675   z_oill(tmp, TypeEntries::type_unknown);
1676   z_bru(do_update);
</pre>
<hr />
<pre>
1884   }
1885   z_n(scratch, mask);
1886   if (where) { z_brc(cond, *where); }
1887 }
1888 
1889 // Get MethodCounters object for given method. Lazily allocated if necessary.
1890 //   method    - Ptr to Method object.
1891 //   Rcounters - Ptr to MethodCounters object associated with Method object.
1892 //   skip      - Exit point if MethodCounters object can&#39;t be created (OOM condition).
1893 void InterpreterMacroAssembler::get_method_counters(Register Rmethod,
1894                                                     Register Rcounters,
1895                                                     Label&amp; skip) {
1896   assert_different_registers(Rmethod, Rcounters);
1897 
1898   BLOCK_COMMENT(&quot;get MethodCounters object {&quot;);
1899 
1900   Label has_counters;
1901   load_and_test_long(Rcounters, Address(Rmethod, Method::method_counters_offset()));
1902   z_brnz(has_counters);
1903 
<span class="line-modified">1904   call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::build_method_counters), Rmethod, false);</span>
1905   z_ltgr(Rcounters, Z_RET); // Runtime call returns MethodCounters object.
1906   z_brz(skip); // No MethodCounters, out of memory.
1907 
1908   bind(has_counters);
1909 
1910   BLOCK_COMMENT(&quot;} get MethodCounters object&quot;);
1911 }
1912 
1913 // Increment invocation counter in MethodCounters object.
1914 // Return (invocation_counter+backedge_counter) as &quot;result&quot; in RctrSum.
1915 // Counter values are all unsigned.
1916 void InterpreterMacroAssembler::increment_invocation_counter(Register Rcounters, Register RctrSum) {
1917   assert(UseCompiler || LogTouchedMethods, &quot;incrementing must be useful&quot;);
1918   assert_different_registers(Rcounters, RctrSum);
1919 
1920   int increment          = InvocationCounter::count_increment;
1921   int inv_counter_offset = in_bytes(MethodCounters::invocation_counter_offset() + InvocationCounter::counter_offset());
1922   int be_counter_offset  = in_bytes(MethodCounters::backedge_counter_offset()   + InvocationCounter::counter_offset());
1923 
1924   BLOCK_COMMENT(&quot;Increment invocation counter {&quot;);
</pre>
<hr />
<pre>
2045     compareU64_and_branch(Rcurr_slot, Rlimit, bcondLow, next); // Are we done?
2046 
2047     bind(done);
2048     // Done copying stack.
2049   }
2050 
2051   // Adjust expression stack and monitor pointers.
2052   add2reg(Z_esp, delta);
2053   add2reg(Rlimit, delta);
2054   save_monitors(Rlimit);
2055 }
2056 
2057 // Note: Index holds the offset in bytes afterwards.
2058 // You can use this to store a new value (with Llocals as the base).
2059 void InterpreterMacroAssembler::access_local_int(Register index, Register dst) {
2060   z_sllg(index, index, LogBytesPerWord);
2061   mem2reg_opt(dst, Address(Z_locals, index), false);
2062 }
2063 
2064 void InterpreterMacroAssembler::verify_oop(Register reg, TosState state) {
<span class="line-modified">2065   if (state == atos) { MacroAssembler::verify_oop(reg); }</span>
2066 }
2067 
2068 // Inline assembly for:
2069 //
2070 // if (thread is in interp_only_mode) {
2071 //   InterpreterRuntime::post_method_entry();
2072 // }
2073 
2074 void InterpreterMacroAssembler::notify_method_entry() {
2075 
2076   // JVMTI
2077   // Whenever JVMTI puts a thread in interp_only_mode, method
2078   // entry/exit events are sent for that thread to track stack
2079   // depth. If it is possible to enter interp_only_mode we add
2080   // the code to check if the event should be sent.
2081   if (JvmtiExport::can_post_interpreter_events()) {
2082     Label jvmti_post_done;
2083     MacroAssembler::load_and_test_int(Z_R0, Address(Z_thread, JavaThread::interp_only_mode_offset()));
2084     z_bre(jvmti_post_done);
<span class="line-modified">2085     call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_method_entry), /*check_exceptions=*/false);</span>
2086     bind(jvmti_post_done);
2087   }
2088 }
2089 
2090 // Inline assembly for:
2091 //
2092 // if (thread is in interp_only_mode) {
2093 //   if (!native_method) save result
2094 //   InterpreterRuntime::post_method_exit();
2095 //   if (!native_method) restore result
2096 // }
2097 // if (DTraceMethodProbes) {
2098 //   SharedRuntime::dtrace_method_exit(thread, method);
2099 // }
2100 //
2101 // For native methods their result is stored in z_ijava_state.lresult
2102 // and z_ijava_state.fresult before coming here.
2103 // Java methods have their result stored in the expression stack.
2104 //
2105 // Notice the dependency to frame::interpreter_frame_result().
2106 void InterpreterMacroAssembler::notify_method_exit(bool native_method,
2107                                                    TosState state,
2108                                                    NotifyMethodExitMode mode) {
2109   // JVMTI
2110   // Whenever JVMTI puts a thread in interp_only_mode, method
2111   // entry/exit events are sent for that thread to track stack
2112   // depth. If it is possible to enter interp_only_mode we add
2113   // the code to check if the event should be sent.
2114   if (mode == NotifyJVMTI &amp;&amp; JvmtiExport::can_post_interpreter_events()) {
2115     Label jvmti_post_done;
2116     MacroAssembler::load_and_test_int(Z_R0, Address(Z_thread, JavaThread::interp_only_mode_offset()));
2117     z_bre(jvmti_post_done);
2118     if (!native_method) push(state); // see frame::interpreter_frame_result()
<span class="line-modified">2119     call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_method_exit), /*check_exceptions=*/false);</span>
2120     if (!native_method) pop(state);
2121     bind(jvmti_post_done);
2122   }
2123 
2124 #if 0
2125   // Dtrace currently not supported on z/Architecture.
2126   {
2127     SkipIfEqual skip(this, &amp;DTraceMethodProbes, false);
2128     push(state);
2129     get_method(c_rarg1);
2130     call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_method_exit),
2131                  r15_thread, c_rarg1);
2132     pop(state);
2133   }
2134 #endif
2135 }
2136 
2137 void InterpreterMacroAssembler::skip_if_jvmti_mode(Label &amp;Lskip, Register Rscratch) {
2138   if (!JvmtiExport::can_post_interpreter_events()) {
2139     return;
</pre>
<hr />
<pre>
2158   // F1  Z_fp -&gt; caller_sp (F2&#39;s)
2159   //             return_pc (Continuation after return from F0.)
2160   //             ...
2161   // F2          caller_sp
2162 
2163   // Remove F0&#39;s activation. Restoring Z_SP to sender_sp reverts modifications
2164   // (a) by a c2i adapter and (b) by generate_fixed_frame().
2165   // In case (a) the new top frame F1 is an unextended compiled frame.
2166   // In case (b) F1 is converted from PARENT_IJAVA_FRAME to TOP_IJAVA_FRAME.
2167 
2168   // Case (b) seems to be redundant when returning to a interpreted caller,
2169   // because then the caller&#39;s top_frame_sp is installed as sp (see
2170   // TemplateInterpreterGenerator::generate_return_entry_for ()). But
2171   // pop_interpreter_frame() is also used in exception handling and there the
2172   // frame type of the caller is unknown, therefore top_frame_sp cannot be used,
2173   // so it is important that sender_sp is the caller&#39;s sp as TOP_IJAVA_FRAME.
2174 
2175   Register R_f1_sender_sp = tmp1;
2176   Register R_f2_sp = tmp2;
2177 
<span class="line-modified">2178   // Tirst check the for the interpreter frame&#39;s magic.</span>
2179   asm_assert_ijava_state_magic(R_f2_sp/*tmp*/);
2180   z_lg(R_f2_sp, _z_parent_ijava_frame_abi(callers_sp), Z_fp);
2181   z_lg(R_f1_sender_sp, _z_ijava_state_neg(sender_sp), Z_fp);
2182   if (return_pc-&gt;is_valid())
2183     z_lg(return_pc, _z_parent_ijava_frame_abi(return_pc), Z_fp);
2184   // Pop F0 by resizing to R_f1_sender_sp and using R_f2_sp as fp.
2185   resize_frame_absolute(R_f1_sender_sp, R_f2_sp, false/*load fp*/);
2186 
2187 #ifdef ASSERT
2188   // The return_pc in the new top frame is dead... at least that&#39;s my
2189   // current understanding; to assert this I overwrite it.
2190   load_const_optimized(Z_ARG3, 0xb00b1);
2191   z_stg(Z_ARG3, _z_parent_ijava_frame_abi(return_pc), Z_SP);
2192 #endif
2193 }
2194 
2195 void InterpreterMacroAssembler::verify_FPU(int stack_depth, TosState state) {
2196   if (VerifyFPU) {
2197     unimplemented(&quot;verfiyFPU&quot;);
2198   }
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2016, 2019, Oracle and/or its affiliates. All rights reserved.</span>
<span class="line-modified">   3  * Copyright (c) 2016, 2019 SAP SE. All rights reserved.</span>
   4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   5  *
   6  * This code is free software; you can redistribute it and/or modify it
   7  * under the terms of the GNU General Public License version 2 only, as
   8  * published by the Free Software Foundation.
   9  *
  10  * This code is distributed in the hope that it will be useful, but WITHOUT
  11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 // Major contributions by AHa, AS, JL, ML.
  27 
  28 #include &quot;precompiled.hpp&quot;
  29 #include &quot;asm/macroAssembler.inline.hpp&quot;
  30 #include &quot;gc/shared/barrierSet.hpp&quot;
  31 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  32 #include &quot;interp_masm_s390.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  35 #include &quot;oops/arrayOop.hpp&quot;
<span class="line-modified">  36 #include &quot;oops/markWord.hpp&quot;</span>
  37 #include &quot;prims/jvmtiExport.hpp&quot;
  38 #include &quot;prims/jvmtiThreadState.hpp&quot;
  39 #include &quot;runtime/basicLock.hpp&quot;
  40 #include &quot;runtime/biasedLocking.hpp&quot;
  41 #include &quot;runtime/frame.inline.hpp&quot;
  42 #include &quot;runtime/safepointMechanism.hpp&quot;
  43 #include &quot;runtime/sharedRuntime.hpp&quot;
  44 #include &quot;runtime/thread.inline.hpp&quot;
<span class="line-added">  45 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  46 
  47 // Implementation of InterpreterMacroAssembler.
  48 // This file specializes the assembler with interpreter-specific macros.
  49 
  50 #ifdef PRODUCT
  51 #define BLOCK_COMMENT(str)
  52 #define BIND(label)        bind(label);
  53 #else
  54 #define BLOCK_COMMENT(str) block_comment(str)
  55 #define BIND(label)        bind(label); BLOCK_COMMENT(#label &quot;:&quot;)
  56 #endif
  57 
  58 void InterpreterMacroAssembler::jump_to_entry(address entry, Register Rscratch) {
  59   assert(entry != NULL, &quot;Entry must have been generated by now&quot;);
  60   assert(Rscratch != Z_R0, &quot;Can&#39;t use R0 for addressing&quot;);
  61   branch_optimized(Assembler::bcondAlways, entry);
  62 }
  63 
  64 void InterpreterMacroAssembler::empty_expression_stack(void) {
  65   get_monitors(Z_R1_scratch);
</pre>
<hr />
<pre>
 398 // load cpool-&gt;resolved_klass_at(index)
 399 void InterpreterMacroAssembler::load_resolved_klass_at_offset(Register cpool, Register offset, Register iklass) {
 400   // int value = *(Rcpool-&gt;int_at_addr(which));
 401   // int resolved_klass_index = extract_low_short_from_int(value);
 402   z_llgh(offset, Address(cpool, offset, sizeof(ConstantPool) + 2)); // offset = resolved_klass_index (s390 is big-endian)
 403   z_sllg(offset, offset, LogBytesPerWord);                          // Convert &#39;index&#39; to &#39;offset&#39;
 404   z_lg(iklass, Address(cpool, ConstantPool::resolved_klasses_offset_in_bytes())); // iklass = cpool-&gt;_resolved_klasses
 405   z_lg(iklass, Address(iklass, offset, Array&lt;Klass*&gt;::base_offset_in_bytes()));
 406 }
 407 
 408 void InterpreterMacroAssembler::get_cache_entry_pointer_at_bcp(Register cache,
 409                                                                Register tmp,
 410                                                                int bcp_offset,
 411                                                                size_t index_size) {
 412   BLOCK_COMMENT(&quot;get_cache_entry_pointer_at_bcp {&quot;);
 413     get_cache_and_index_at_bcp(cache, tmp, bcp_offset, index_size);
 414     add2reg_with_index(cache, in_bytes(ConstantPoolCache::base_offset()), tmp, cache);
 415   BLOCK_COMMENT(&quot;}&quot;);
 416 }
 417 
<span class="line-added"> 418 void InterpreterMacroAssembler::load_resolved_method_at_index(int byte_no,</span>
<span class="line-added"> 419                                                               Register cache,</span>
<span class="line-added"> 420                                                               Register cpe_offset,</span>
<span class="line-added"> 421                                                               Register method) {</span>
<span class="line-added"> 422   const int method_offset = in_bytes(</span>
<span class="line-added"> 423     ConstantPoolCache::base_offset() +</span>
<span class="line-added"> 424       ((byte_no == TemplateTable::f2_byte)</span>
<span class="line-added"> 425        ? ConstantPoolCacheEntry::f2_offset()</span>
<span class="line-added"> 426        : ConstantPoolCacheEntry::f1_offset()));</span>
<span class="line-added"> 427 </span>
<span class="line-added"> 428   z_lg(method, Address(cache, cpe_offset, method_offset)); // get f1 Method*</span>
<span class="line-added"> 429 }</span>
<span class="line-added"> 430 </span>
 431 // Generate a subtype check: branch to ok_is_subtype if sub_klass is
 432 // a subtype of super_klass. Blows registers Rsuper_klass, Rsub_klass, tmp1, tmp2.
 433 void InterpreterMacroAssembler::gen_subtype_check(Register Rsub_klass,
 434                                                   Register Rsuper_klass,
 435                                                   Register Rtmp1,
 436                                                   Register Rtmp2,
 437                                                   Label &amp;ok_is_subtype) {
 438   // Profile the not-null value&#39;s klass.
 439   profile_typecheck(Rtmp1, Rsub_klass, Rtmp2);
 440 
 441   // Do the check.
 442   check_klass_subtype(Rsub_klass, Rsuper_klass, Rtmp1, Rtmp2, ok_is_subtype);
 443 
 444   // Profile the failure of the check.
 445   profile_typecheck_failed(Rtmp1, Rtmp2);
 446 }
 447 
 448 // Pop topmost element from stack. It just disappears.
 449 // Useful if consumed previously by access via stackTop().
 450 void InterpreterMacroAssembler::popx(int len) {
</pre>
<hr />
<pre>
 958   pop_interpreter_frame(return_pc, Z_ARG2, Z_ARG3);
 959   BLOCK_COMMENT(&quot;} remove_activation&quot;);
 960 }
 961 
 962 // lock object
 963 //
 964 // Registers alive
 965 //   monitor - Address of the BasicObjectLock to be used for locking,
 966 //             which must be initialized with the object to lock.
 967 //   object  - Address of the object to be locked.
 968 void InterpreterMacroAssembler::lock_object(Register monitor, Register object) {
 969 
 970   if (UseHeavyMonitors) {
 971     call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),
 972             monitor, /*check_for_exceptions=*/false);
 973     return;
 974   }
 975 
 976   // template code:
 977   //
<span class="line-modified"> 978   // markWord displaced_header = obj-&gt;mark().set_unlocked();</span>
 979   // monitor-&gt;lock()-&gt;set_displaced_header(displaced_header);
<span class="line-modified"> 980   // if (Atomic::cmpxchg(/*addr*/obj-&gt;mark_addr(), /*cmp*/displaced_header, /*ex=*/monitor) == displaced_header) {</span>
 981   //   // We stored the monitor address into the object&#39;s mark word.
 982   // } else if (THREAD-&gt;is_lock_owned((address)displaced_header))
 983   //   // Simple recursive case.
 984   //   monitor-&gt;lock()-&gt;set_displaced_header(NULL);
 985   // } else {
 986   //   // Slow path.
 987   //   InterpreterRuntime::monitorenter(THREAD, monitor);
 988   // }
 989 
 990   const Register displaced_header = Z_ARG5;
 991   const Register object_mark_addr = Z_ARG4;
 992   const Register current_header   = Z_ARG5;
 993 
 994   NearLabel done;
 995   NearLabel slow_case;
 996 
<span class="line-modified"> 997   // markWord displaced_header = obj-&gt;mark().set_unlocked();</span>
 998 
<span class="line-modified"> 999   // Load markWord from object into displaced_header.</span>
1000   z_lg(displaced_header, oopDesc::mark_offset_in_bytes(), object);
1001 
1002   if (UseBiasedLocking) {
1003     biased_locking_enter(object, displaced_header, Z_R1, Z_R0, done, &amp;slow_case);
1004   }
1005 
<span class="line-modified">1006   // Set displaced_header to be (markWord of object | UNLOCK_VALUE).</span>
<span class="line-modified">1007   z_oill(displaced_header, markWord::unlocked_value);</span>
1008 
1009   // monitor-&gt;lock()-&gt;set_displaced_header(displaced_header);
1010 
1011   // Initialize the box (Must happen before we update the object mark!).
1012   z_stg(displaced_header, BasicObjectLock::lock_offset_in_bytes() +
1013                           BasicLock::displaced_header_offset_in_bytes(), monitor);
1014 
<span class="line-modified">1015   // if (Atomic::cmpxchg(/*addr*/obj-&gt;mark_addr(), /*cmp*/displaced_header, /*ex=*/monitor) == displaced_header) {</span>
1016 
1017   // Store stack address of the BasicObjectLock (this is monitor) into object.
1018   add2reg(object_mark_addr, oopDesc::mark_offset_in_bytes(), object);
1019 
1020   z_csg(displaced_header, monitor, 0, object_mark_addr);
1021   assert(current_header==displaced_header, &quot;must be same register&quot;); // Identified two registers from z/Architecture.
1022 
1023   z_bre(done);
1024 
1025   // } else if (THREAD-&gt;is_lock_owned((address)displaced_header))
1026   //   // Simple recursive case.
1027   //   monitor-&gt;lock()-&gt;set_displaced_header(NULL);
1028 
1029   // We did not see an unlocked object so try the fast recursive case.
1030 
<span class="line-modified">1031   // Check if owner is self by comparing the value in the markWord of object</span>
1032   // (current_header) with the stack pointer.
1033   z_sgr(current_header, Z_SP);
1034 
1035   assert(os::vm_page_size() &gt; 0xfff, &quot;page size too small - change the constant&quot;);
1036 
1037   // The prior sequence &quot;LGR, NGR, LTGR&quot; can be done better
1038   // (Z_R1 is temp and not used after here).
<span class="line-modified">1039   load_const_optimized(Z_R0, (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));</span>
1040   z_ngr(Z_R0, current_header); // AND sets CC (result eq/ne 0)
1041 
1042   // If condition is true we are done and hence we can store 0 in the displaced
1043   // header indicating it is a recursive lock and be done.
1044   z_brne(slow_case);
1045   z_release();  // Membar unnecessary on zarch AND because the above csg does a sync before and after.
1046   z_stg(Z_R0/*==0!*/, BasicObjectLock::lock_offset_in_bytes() +
1047                       BasicLock::displaced_header_offset_in_bytes(), monitor);
1048   z_bru(done);
1049 
1050   // } else {
1051   //   // Slow path.
1052   //   InterpreterRuntime::monitorenter(THREAD, monitor);
1053 
1054   // None of the above fast optimizations worked so we have to get into the
1055   // slow case of monitor enter.
1056   bind(slow_case);
1057 
1058   call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),
1059           monitor, /*check_for_exceptions=*/false);
1060 
1061   // }
1062 
1063   bind(done);
1064 }
1065 
1066 // Unlocks an object. Used in monitorexit bytecode and remove_activation.
1067 //
1068 // Registers alive
1069 //   monitor - address of the BasicObjectLock to be used for locking,
1070 //             which must be initialized with the object to lock.
1071 //
1072 // Throw IllegalMonitorException if object is not locked by current thread.
1073 void InterpreterMacroAssembler::unlock_object(Register monitor, Register object) {
1074 
1075   if (UseHeavyMonitors) {
<span class="line-modified">1076     call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), monitor);</span>

1077     return;
1078   }
1079 
1080 // else {
1081   // template code:
1082   //
1083   // if ((displaced_header = monitor-&gt;displaced_header()) == NULL) {
1084   //   // Recursive unlock. Mark the monitor unlocked by setting the object field to NULL.
1085   //   monitor-&gt;set_obj(NULL);
<span class="line-modified">1086   // } else if (Atomic::cmpxchg(obj-&gt;mark_addr(), monitor, displaced_header) == monitor) {</span>
1087   //   // We swapped the unlocked mark in displaced_header into the object&#39;s mark word.
1088   //   monitor-&gt;set_obj(NULL);
1089   // } else {
1090   //   // Slow path.
1091   //   InterpreterRuntime::monitorexit(THREAD, monitor);
1092   // }
1093 
1094   const Register displaced_header = Z_ARG4;
1095   const Register current_header   = Z_R1;
1096   Address obj_entry(monitor, BasicObjectLock::obj_offset_in_bytes());
1097   Label done;
1098 
1099   if (object == noreg) {
1100     // In the template interpreter, we must assure that the object
1101     // entry in the monitor is cleared on all paths. Thus we move
1102     // loading up to here, and clear the entry afterwards.
1103     object = Z_ARG3; // Use Z_ARG3 if caller didn&#39;t pass object.
1104     z_lg(object, obj_entry);
1105   }
1106 
1107   assert_different_registers(monitor, object, displaced_header, current_header);
1108 
1109   // if ((displaced_header = monitor-&gt;displaced_header()) == NULL) {
1110   //   // Recursive unlock. Mark the monitor unlocked by setting the object field to NULL.
1111   //   monitor-&gt;set_obj(NULL);
1112 
1113   clear_mem(obj_entry, sizeof(oop));
1114 
1115   if (UseBiasedLocking) {
1116     // The object address from the monitor is in object.
1117     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
1118     biased_locking_exit(object, displaced_header, done);
1119   }
1120 
1121   // Test first if we are in the fast recursive case.
1122   MacroAssembler::load_and_test_long(displaced_header,
1123                                      Address(monitor, BasicObjectLock::lock_offset_in_bytes() +
1124                                                       BasicLock::displaced_header_offset_in_bytes()));
1125   z_bre(done); // displaced_header == 0 -&gt; goto done
1126 
<span class="line-modified">1127   // } else if (Atomic::cmpxchg(obj-&gt;mark_addr(), monitor, displaced_header) == monitor) {</span>
1128   //   // We swapped the unlocked mark in displaced_header into the object&#39;s mark word.
1129   //   monitor-&gt;set_obj(NULL);
1130 
1131   // If we still have a lightweight lock, unlock the object and be done.
1132 
1133   // The markword is expected to be at offset 0.
1134   assert(oopDesc::mark_offset_in_bytes() == 0, &quot;unlock_object: review code below&quot;);
1135 
1136   // We have the displaced header in displaced_header. If the lock is still
1137   // lightweight, it will contain the monitor address and we&#39;ll store the
1138   // displaced header back into the object&#39;s mark word.
1139   z_lgr(current_header, monitor);
1140   z_csg(current_header, displaced_header, 0, object);
1141   z_bre(done);
1142 
1143   // } else {
1144   //   // Slow path.
1145   //   InterpreterRuntime::monitorexit(THREAD, monitor);
1146 
1147   // The lock has been converted into a heavy lock and hence
1148   // we need to get into the slow case.
1149   z_stg(object, obj_entry);   // Restore object entry, has been cleared above.
<span class="line-modified">1150   call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), monitor);</span>

1151 
1152   // }
1153 
1154   bind(done);
1155 }
1156 
1157 void InterpreterMacroAssembler::test_method_data_pointer(Register mdp, Label&amp; zero_continue) {
1158   assert(ProfileInterpreter, &quot;must be profiling interpreter&quot;);
1159   load_and_test_long(mdp, Address(Z_fp, _z_ijava_state_neg(mdx)));
1160   z_brz(zero_continue);
1161 }
1162 
1163 // Set the method data pointer for the current bcp.
1164 void InterpreterMacroAssembler::set_method_data_pointer_for_bcp() {
1165   assert(ProfileInterpreter, &quot;must be profiling interpreter&quot;);
1166   Label    set_mdp;
1167   Register mdp    = Z_ARG4;
1168   Register method = Z_ARG5;
1169 
1170   get_method(method);
</pre>
<hr />
<pre>
1648     bind(profile_continue);
1649   }
1650 }
1651 
1652 // kills: R0, R1, flags, loads klass from obj (if not null)
1653 void InterpreterMacroAssembler::profile_obj_type(Register obj, Address mdo_addr, Register klass, bool cmp_done) {
1654   NearLabel null_seen, init_klass, do_nothing, do_update;
1655 
1656   // Klass = obj is allowed.
1657   const Register tmp = Z_R1;
1658   assert_different_registers(obj, mdo_addr.base(), tmp, Z_R0);
1659   assert_different_registers(klass, mdo_addr.base(), tmp, Z_R0);
1660 
1661   z_lg(tmp, mdo_addr);
1662   if (cmp_done) {
1663     z_brz(null_seen);
1664   } else {
1665     compareU64_and_branch(obj, (intptr_t)0, Assembler::bcondEqual, null_seen);
1666   }
1667 
<span class="line-modified">1668   MacroAssembler::verify_oop(obj, FILE_AND_LINE);</span>
1669   load_klass(klass, obj);
1670 
1671   // Klass seen before, nothing to do (regardless of unknown bit).
1672   z_lgr(Z_R0, tmp);
1673   assert(Immediate::is_uimm(~TypeEntries::type_klass_mask, 16), &quot;or change following instruction&quot;);
1674   z_nill(Z_R0, TypeEntries::type_klass_mask &amp; 0xFFFF);
1675   compareU64_and_branch(Z_R0, klass, Assembler::bcondEqual, do_nothing);
1676 
1677   // Already unknown. Nothing to do anymore.
1678   z_tmll(tmp, TypeEntries::type_unknown);
1679   z_brc(Assembler::bcondAllOne, do_nothing);
1680 
1681   z_lgr(Z_R0, tmp);
1682   assert(Immediate::is_uimm(~TypeEntries::type_mask, 16), &quot;or change following instruction&quot;);
1683   z_nill(Z_R0, TypeEntries::type_mask &amp; 0xFFFF);
1684   compareU64_and_branch(Z_R0, (intptr_t)0, Assembler::bcondEqual, init_klass);
1685 
1686   // Different than before. Cannot keep accurate profile.
1687   z_oill(tmp, TypeEntries::type_unknown);
1688   z_bru(do_update);
</pre>
<hr />
<pre>
1896   }
1897   z_n(scratch, mask);
1898   if (where) { z_brc(cond, *where); }
1899 }
1900 
1901 // Get MethodCounters object for given method. Lazily allocated if necessary.
1902 //   method    - Ptr to Method object.
1903 //   Rcounters - Ptr to MethodCounters object associated with Method object.
1904 //   skip      - Exit point if MethodCounters object can&#39;t be created (OOM condition).
1905 void InterpreterMacroAssembler::get_method_counters(Register Rmethod,
1906                                                     Register Rcounters,
1907                                                     Label&amp; skip) {
1908   assert_different_registers(Rmethod, Rcounters);
1909 
1910   BLOCK_COMMENT(&quot;get MethodCounters object {&quot;);
1911 
1912   Label has_counters;
1913   load_and_test_long(Rcounters, Address(Rmethod, Method::method_counters_offset()));
1914   z_brnz(has_counters);
1915 
<span class="line-modified">1916   call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::build_method_counters), Rmethod);</span>
1917   z_ltgr(Rcounters, Z_RET); // Runtime call returns MethodCounters object.
1918   z_brz(skip); // No MethodCounters, out of memory.
1919 
1920   bind(has_counters);
1921 
1922   BLOCK_COMMENT(&quot;} get MethodCounters object&quot;);
1923 }
1924 
1925 // Increment invocation counter in MethodCounters object.
1926 // Return (invocation_counter+backedge_counter) as &quot;result&quot; in RctrSum.
1927 // Counter values are all unsigned.
1928 void InterpreterMacroAssembler::increment_invocation_counter(Register Rcounters, Register RctrSum) {
1929   assert(UseCompiler || LogTouchedMethods, &quot;incrementing must be useful&quot;);
1930   assert_different_registers(Rcounters, RctrSum);
1931 
1932   int increment          = InvocationCounter::count_increment;
1933   int inv_counter_offset = in_bytes(MethodCounters::invocation_counter_offset() + InvocationCounter::counter_offset());
1934   int be_counter_offset  = in_bytes(MethodCounters::backedge_counter_offset()   + InvocationCounter::counter_offset());
1935 
1936   BLOCK_COMMENT(&quot;Increment invocation counter {&quot;);
</pre>
<hr />
<pre>
2057     compareU64_and_branch(Rcurr_slot, Rlimit, bcondLow, next); // Are we done?
2058 
2059     bind(done);
2060     // Done copying stack.
2061   }
2062 
2063   // Adjust expression stack and monitor pointers.
2064   add2reg(Z_esp, delta);
2065   add2reg(Rlimit, delta);
2066   save_monitors(Rlimit);
2067 }
2068 
2069 // Note: Index holds the offset in bytes afterwards.
2070 // You can use this to store a new value (with Llocals as the base).
2071 void InterpreterMacroAssembler::access_local_int(Register index, Register dst) {
2072   z_sllg(index, index, LogBytesPerWord);
2073   mem2reg_opt(dst, Address(Z_locals, index), false);
2074 }
2075 
2076 void InterpreterMacroAssembler::verify_oop(Register reg, TosState state) {
<span class="line-modified">2077   if (state == atos) { MacroAssembler::verify_oop(reg, FILE_AND_LINE); }</span>
2078 }
2079 
2080 // Inline assembly for:
2081 //
2082 // if (thread is in interp_only_mode) {
2083 //   InterpreterRuntime::post_method_entry();
2084 // }
2085 
2086 void InterpreterMacroAssembler::notify_method_entry() {
2087 
2088   // JVMTI
2089   // Whenever JVMTI puts a thread in interp_only_mode, method
2090   // entry/exit events are sent for that thread to track stack
2091   // depth. If it is possible to enter interp_only_mode we add
2092   // the code to check if the event should be sent.
2093   if (JvmtiExport::can_post_interpreter_events()) {
2094     Label jvmti_post_done;
2095     MacroAssembler::load_and_test_int(Z_R0, Address(Z_thread, JavaThread::interp_only_mode_offset()));
2096     z_bre(jvmti_post_done);
<span class="line-modified">2097     call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_method_entry));</span>
2098     bind(jvmti_post_done);
2099   }
2100 }
2101 
2102 // Inline assembly for:
2103 //
2104 // if (thread is in interp_only_mode) {
2105 //   if (!native_method) save result
2106 //   InterpreterRuntime::post_method_exit();
2107 //   if (!native_method) restore result
2108 // }
2109 // if (DTraceMethodProbes) {
2110 //   SharedRuntime::dtrace_method_exit(thread, method);
2111 // }
2112 //
2113 // For native methods their result is stored in z_ijava_state.lresult
2114 // and z_ijava_state.fresult before coming here.
2115 // Java methods have their result stored in the expression stack.
2116 //
2117 // Notice the dependency to frame::interpreter_frame_result().
2118 void InterpreterMacroAssembler::notify_method_exit(bool native_method,
2119                                                    TosState state,
2120                                                    NotifyMethodExitMode mode) {
2121   // JVMTI
2122   // Whenever JVMTI puts a thread in interp_only_mode, method
2123   // entry/exit events are sent for that thread to track stack
2124   // depth. If it is possible to enter interp_only_mode we add
2125   // the code to check if the event should be sent.
2126   if (mode == NotifyJVMTI &amp;&amp; JvmtiExport::can_post_interpreter_events()) {
2127     Label jvmti_post_done;
2128     MacroAssembler::load_and_test_int(Z_R0, Address(Z_thread, JavaThread::interp_only_mode_offset()));
2129     z_bre(jvmti_post_done);
2130     if (!native_method) push(state); // see frame::interpreter_frame_result()
<span class="line-modified">2131     call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_method_exit));</span>
2132     if (!native_method) pop(state);
2133     bind(jvmti_post_done);
2134   }
2135 
2136 #if 0
2137   // Dtrace currently not supported on z/Architecture.
2138   {
2139     SkipIfEqual skip(this, &amp;DTraceMethodProbes, false);
2140     push(state);
2141     get_method(c_rarg1);
2142     call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_method_exit),
2143                  r15_thread, c_rarg1);
2144     pop(state);
2145   }
2146 #endif
2147 }
2148 
2149 void InterpreterMacroAssembler::skip_if_jvmti_mode(Label &amp;Lskip, Register Rscratch) {
2150   if (!JvmtiExport::can_post_interpreter_events()) {
2151     return;
</pre>
<hr />
<pre>
2170   // F1  Z_fp -&gt; caller_sp (F2&#39;s)
2171   //             return_pc (Continuation after return from F0.)
2172   //             ...
2173   // F2          caller_sp
2174 
2175   // Remove F0&#39;s activation. Restoring Z_SP to sender_sp reverts modifications
2176   // (a) by a c2i adapter and (b) by generate_fixed_frame().
2177   // In case (a) the new top frame F1 is an unextended compiled frame.
2178   // In case (b) F1 is converted from PARENT_IJAVA_FRAME to TOP_IJAVA_FRAME.
2179 
2180   // Case (b) seems to be redundant when returning to a interpreted caller,
2181   // because then the caller&#39;s top_frame_sp is installed as sp (see
2182   // TemplateInterpreterGenerator::generate_return_entry_for ()). But
2183   // pop_interpreter_frame() is also used in exception handling and there the
2184   // frame type of the caller is unknown, therefore top_frame_sp cannot be used,
2185   // so it is important that sender_sp is the caller&#39;s sp as TOP_IJAVA_FRAME.
2186 
2187   Register R_f1_sender_sp = tmp1;
2188   Register R_f2_sp = tmp2;
2189 
<span class="line-modified">2190   // First check for the interpreter frame&#39;s magic.</span>
2191   asm_assert_ijava_state_magic(R_f2_sp/*tmp*/);
2192   z_lg(R_f2_sp, _z_parent_ijava_frame_abi(callers_sp), Z_fp);
2193   z_lg(R_f1_sender_sp, _z_ijava_state_neg(sender_sp), Z_fp);
2194   if (return_pc-&gt;is_valid())
2195     z_lg(return_pc, _z_parent_ijava_frame_abi(return_pc), Z_fp);
2196   // Pop F0 by resizing to R_f1_sender_sp and using R_f2_sp as fp.
2197   resize_frame_absolute(R_f1_sender_sp, R_f2_sp, false/*load fp*/);
2198 
2199 #ifdef ASSERT
2200   // The return_pc in the new top frame is dead... at least that&#39;s my
2201   // current understanding; to assert this I overwrite it.
2202   load_const_optimized(Z_ARG3, 0xb00b1);
2203   z_stg(Z_ARG3, _z_parent_ijava_frame_abi(return_pc), Z_SP);
2204 #endif
2205 }
2206 
2207 void InterpreterMacroAssembler::verify_FPU(int stack_depth, TosState state) {
2208   if (VerifyFPU) {
2209     unimplemented(&quot;verfiyFPU&quot;);
2210   }
</pre>
</td>
</tr>
</table>
<center><a href="globals_s390.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="interp_masm_s390.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>