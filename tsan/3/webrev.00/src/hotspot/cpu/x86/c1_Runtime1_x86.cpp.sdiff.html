<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/c1_Runtime1_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_MacroAssembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_globals_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/c1_Runtime1_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/assembler.hpp&quot;
  27 #include &quot;c1/c1_Defs.hpp&quot;
  28 #include &quot;c1/c1_MacroAssembler.hpp&quot;
  29 #include &quot;c1/c1_Runtime1.hpp&quot;
  30 #include &quot;ci/ciUtilities.hpp&quot;
  31 #include &quot;gc/shared/cardTable.hpp&quot;
  32 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;

  34 #include &quot;nativeInst_x86.hpp&quot;
  35 #include &quot;oops/compiledICHolder.hpp&quot;
  36 #include &quot;oops/oop.inline.hpp&quot;
  37 #include &quot;prims/jvmtiExport.hpp&quot;
  38 #include &quot;register_x86.hpp&quot;
  39 #include &quot;runtime/sharedRuntime.hpp&quot;
  40 #include &quot;runtime/signature.hpp&quot;
  41 #include &quot;runtime/vframeArray.hpp&quot;
  42 #include &quot;utilities/macros.hpp&quot;
  43 #include &quot;vmreg_x86.inline.hpp&quot;
  44 
  45 // Implementation of StubAssembler
  46 
  47 int StubAssembler::call_RT(Register oop_result1, Register metadata_result, address entry, int args_size) {
  48   // setup registers
  49   const Register thread = NOT_LP64(rdi) LP64_ONLY(r15_thread); // is callee-saved register (Visual C++ calling conventions)
  50   assert(!(oop_result1-&gt;is_valid() || metadata_result-&gt;is_valid()) || oop_result1 != metadata_result, &quot;registers must be different&quot;);
  51   assert(oop_result1 != thread &amp;&amp; metadata_result != thread, &quot;registers must be different&quot;);
  52   assert(args_size &gt;= 0, &quot;illegal args_size&quot;);
  53   bool align_stack = false;
</pre>
<hr />
<pre>
 409   return map;
 410 }
 411 
 412 #define __ this-&gt;
 413 
 414 void C1_MacroAssembler::save_live_registers_no_oop_map(bool save_fpu_registers) {
 415   __ block_comment(&quot;save_live_registers&quot;);
 416 
 417   __ pusha();         // integer registers
 418 
 419   // assert(float_regs_as_doubles_off % 2 == 0, &quot;misaligned offset&quot;);
 420   // assert(xmm_regs_as_doubles_off % 2 == 0, &quot;misaligned offset&quot;);
 421 
 422   __ subptr(rsp, extra_space_offset * VMRegImpl::stack_slot_size);
 423 
 424 #ifdef ASSERT
 425   __ movptr(Address(rsp, marker * VMRegImpl::stack_slot_size), (int32_t)0xfeedbeef);
 426 #endif
 427 
 428   if (save_fpu_registers) {

 429     if (UseSSE &lt; 2) {
 430       // save FPU stack
 431       __ fnsave(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size));
 432       __ fwait();
 433 
 434 #ifdef ASSERT
 435       Label ok;
 436       __ cmpw(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size), StubRoutines::fpu_cntrl_wrd_std());
 437       __ jccb(Assembler::equal, ok);
 438       __ stop(&quot;corrupted control word detected&quot;);
 439       __ bind(ok);
 440 #endif
 441 
 442       // Reset the control word to guard against exceptions being unmasked
 443       // since fstp_d can cause FPU stack underflow exceptions.  Write it
 444       // into the on stack copy and then reload that to make sure that the
 445       // current and future values are correct.
 446       __ movw(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size), StubRoutines::fpu_cntrl_wrd_std());
 447       __ frstor(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size));
 448 
 449       // Save the FPU registers in de-opt-able form
 450       int offset = 0;
 451       for (int n = 0; n &lt; FrameMap::nof_fpu_regs; n++) {
 452         __ fstp_d(Address(rsp, float_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset));
 453         offset += 8;
 454       }
 455     }

 456 
 457     if (UseSSE &gt;= 2) {
 458       // save XMM registers
 459       // XMM registers can contain float or double values, but this is not known here,
 460       // so always save them as doubles.
 461       // note that float values are _not_ converted automatically, so for float values
 462       // the second word contains only garbage data.
 463       int xmm_bypass_limit = FrameMap::nof_xmm_regs;
 464       int offset = 0;
 465 #ifdef _LP64
 466       if (UseAVX &lt; 3) {
 467         xmm_bypass_limit = xmm_bypass_limit / 2;
 468       }
 469 #endif
 470       for (int n = 0; n &lt; xmm_bypass_limit; n++) {
 471         XMMRegister xmm_name = as_XMMRegister(n);
 472         __ movdbl(Address(rsp, xmm_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset), xmm_name);
 473         offset += 8;
 474       }

 475     } else if (UseSSE == 1) {
 476       // save XMM registers as float because double not supported without SSE2(num MMX == num fpu)
 477       int offset = 0;
 478       for (int n = 0; n &lt; FrameMap::nof_fpu_regs; n++) {
 479         XMMRegister xmm_name = as_XMMRegister(n);
 480         __ movflt(Address(rsp, xmm_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset), xmm_name);
 481         offset += 8;
 482       }

 483     }
 484   }
 485 
 486   // FPU stack must be empty now
<span class="line-modified"> 487   __ verify_FPU(0, &quot;save_live_registers&quot;);</span>
 488 }
 489 
 490 #undef __
 491 #define __ sasm-&gt;
 492 
 493 static void restore_fpu(C1_MacroAssembler* sasm, bool restore_fpu_registers) {















 494   if (restore_fpu_registers) {
 495     if (UseSSE &gt;= 2) {
 496       // restore XMM registers
 497       int xmm_bypass_limit = FrameMap::nof_xmm_regs;
<span class="line-removed"> 498 #ifdef _LP64</span>
<span class="line-removed"> 499       if (UseAVX &lt; 3) {</span>
<span class="line-removed"> 500         xmm_bypass_limit = xmm_bypass_limit / 2;</span>
<span class="line-removed"> 501       }</span>
<span class="line-removed"> 502 #endif</span>
 503       int offset = 0;
 504       for (int n = 0; n &lt; xmm_bypass_limit; n++) {
 505         XMMRegister xmm_name = as_XMMRegister(n);
 506         __ movdbl(xmm_name, Address(rsp, xmm_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset));
 507         offset += 8;
 508       }
 509     } else if (UseSSE == 1) {
 510       // restore XMM registers(num MMX == num fpu)
 511       int offset = 0;
 512       for (int n = 0; n &lt; FrameMap::nof_fpu_regs; n++) {
 513         XMMRegister xmm_name = as_XMMRegister(n);
 514         __ movflt(xmm_name, Address(rsp, xmm_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset));
 515         offset += 8;
 516       }
 517     }
 518 
 519     if (UseSSE &lt; 2) {
 520       __ frstor(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size));
 521     } else {
 522       // check that FPU stack is really empty
 523       __ verify_FPU(0, &quot;restore_live_registers&quot;);
 524     }
<span class="line-removed"> 525 </span>
 526   } else {
 527     // check that FPU stack is really empty
 528     __ verify_FPU(0, &quot;restore_live_registers&quot;);
 529   }

 530 
 531 #ifdef ASSERT
 532   {
 533     Label ok;
 534     __ cmpptr(Address(rsp, marker * VMRegImpl::stack_slot_size), (int32_t)0xfeedbeef);
 535     __ jcc(Assembler::equal, ok);
 536     __ stop(&quot;bad offsets in frame&quot;);
 537     __ bind(ok);
 538   }
 539 #endif // ASSERT
 540 
 541   __ addptr(rsp, extra_space_offset * VMRegImpl::stack_slot_size);
 542 }
 543 
 544 #undef __
 545 #define __ this-&gt;
 546 
 547 void C1_MacroAssembler::restore_live_registers(bool restore_fpu_registers) {
 548   __ block_comment(&quot;restore_live_registers&quot;);
 549 
</pre>
<hr />
<pre>
 681     __ movptr(Address(thread, JavaThread::vm_result_offset()),   NULL_WORD);
 682     __ movptr(Address(thread, JavaThread::vm_result_2_offset()), NULL_WORD);
 683     break;
 684   case handle_exception_nofpu_id:
 685   case handle_exception_id:
 686     // At this point all registers MAY be live.
 687     oop_map = save_live_registers(sasm, 1 /*thread*/, id != handle_exception_nofpu_id);
 688     break;
 689   case handle_exception_from_callee_id: {
 690     // At this point all registers except exception oop (RAX) and
 691     // exception pc (RDX) are dead.
 692     const int frame_size = 2 /*BP, return address*/ NOT_LP64(+ 1 /*thread*/) WIN64_ONLY(+ frame::arg_reg_save_area_bytes / BytesPerWord);
 693     oop_map = new OopMap(frame_size * VMRegImpl::slots_per_word, 0);
 694     sasm-&gt;set_frame_size(frame_size);
 695     WIN64_ONLY(__ subq(rsp, frame::arg_reg_save_area_bytes));
 696     break;
 697   }
 698   default:  ShouldNotReachHere();
 699   }
 700 
<span class="line-modified"> 701 #ifdef TIERED</span>
<span class="line-removed"> 702   // C2 can leave the fpu stack dirty</span>
 703   if (UseSSE &lt; 2) {

 704     __ empty_FPU_stack();
 705   }
<span class="line-modified"> 706 #endif // TIERED</span>
 707 
 708   // verify that only rax, and rdx is valid at this time
 709   __ invalidate_registers(false, true, true, false, true, true);
 710   // verify that rax, contains a valid exception
 711   __ verify_not_null_oop(exception_oop);
 712 
 713   // load address of JavaThread object for thread-local data
 714   NOT_LP64(__ get_thread(thread);)
 715 
 716 #ifdef ASSERT
 717   // check that fields in JavaThread for exception oop and issuing pc are
 718   // empty before writing to them
 719   Label oop_empty;
 720   __ cmpptr(Address(thread, JavaThread::exception_oop_offset()), (int32_t) NULL_WORD);
 721   __ jcc(Assembler::equal, oop_empty);
 722   __ stop(&quot;exception oop already set&quot;);
 723   __ bind(oop_empty);
 724 
 725   Label pc_empty;
 726   __ cmpptr(Address(thread, JavaThread::exception_pc_offset()), 0);
</pre>
<hr />
<pre>
 788   // verify that only rax, is valid at this time
 789   __ invalidate_registers(false, true, true, true, true, true);
 790 
 791 #ifdef ASSERT
 792   // check that fields in JavaThread for exception oop and issuing pc are empty
 793   NOT_LP64(__ get_thread(thread);)
 794   Label oop_empty;
 795   __ cmpptr(Address(thread, JavaThread::exception_oop_offset()), 0);
 796   __ jcc(Assembler::equal, oop_empty);
 797   __ stop(&quot;exception oop must be empty&quot;);
 798   __ bind(oop_empty);
 799 
 800   Label pc_empty;
 801   __ cmpptr(Address(thread, JavaThread::exception_pc_offset()), 0);
 802   __ jcc(Assembler::equal, pc_empty);
 803   __ stop(&quot;exception pc must be empty&quot;);
 804   __ bind(pc_empty);
 805 #endif
 806 
 807   // clear the FPU stack in case any FPU results are left behind
<span class="line-modified"> 808   __ empty_FPU_stack();</span>
 809 
 810   // save exception_oop in callee-saved register to preserve it during runtime calls
 811   __ verify_not_null_oop(exception_oop);
 812   __ movptr(exception_oop_callee_saved, exception_oop);
 813 
 814   NOT_LP64(__ get_thread(thread);)
 815   // Get return address (is on top of stack after leave).
 816   __ movptr(exception_pc, Address(rsp, 0));
 817 
 818   // search the exception handler address of the caller (using the return address)
 819   __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::exception_handler_for_return_address), thread, exception_pc);
 820   // rax: exception handler address of the caller
 821 
 822   // Only RAX and RSI are valid at this time, all other registers have been destroyed by the call.
 823   __ invalidate_registers(false, true, true, true, false, true);
 824 
 825   // move result of call into correct register
 826   __ movptr(handler_addr, rax);
 827 
 828   // Restore exception oop to RAX (required convention of exception handler).
</pre>
<hr />
<pre>
1459       }
1460       break;
1461 
1462     case dtrace_object_alloc_id:
1463       { // rax,: object
1464         StubFrame f(sasm, &quot;dtrace_object_alloc&quot;, dont_gc_arguments);
1465         // we can&#39;t gc here so skip the oopmap but make sure that all
1466         // the live registers get saved.
1467         save_live_registers(sasm, 1);
1468 
1469         __ NOT_LP64(push(rax)) LP64_ONLY(mov(c_rarg0, rax));
1470         __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc)));
1471         NOT_LP64(__ pop(rax));
1472 
1473         restore_live_registers(sasm);
1474       }
1475       break;
1476 
1477     case fpu2long_stub_id:
1478       {













1479         // rax, and rdx are destroyed, but should be free since the result is returned there
1480         // preserve rsi,ecx
1481         __ push(rsi);
1482         __ push(rcx);
<span class="line-removed">1483         LP64_ONLY(__ push(rdx);)</span>
1484 
1485         // check for NaN
1486         Label return0, do_return, return_min_jlong, do_convert;
1487 
1488         Address value_high_word(rsp, wordSize + 4);
1489         Address value_low_word(rsp, wordSize);
1490         Address result_high_word(rsp, 3*wordSize + 4);
1491         Address result_low_word(rsp, 3*wordSize);
1492 
1493         __ subptr(rsp, 32);                    // more than enough on 32bit
1494         __ fst_d(value_low_word);
1495         __ movl(rax, value_high_word);
1496         __ andl(rax, 0x7ff00000);
1497         __ cmpl(rax, 0x7ff00000);
1498         __ jcc(Assembler::notEqual, do_convert);
1499         __ movl(rax, value_high_word);
1500         __ andl(rax, 0xfffff);
1501         __ orl(rax, value_low_word);
1502         __ jcc(Assembler::notZero, return0);
1503 
</pre>
<hr />
<pre>
1508         __ movw(Address(rsp, 2), rax);
1509         __ fldcw(Address(rsp, 2));
1510         __ fwait();
1511         __ fistp_d(result_low_word);
1512         __ fldcw(Address(rsp, 0));
1513         __ fwait();
1514         // This gets the entire long in rax on 64bit
1515         __ movptr(rax, result_low_word);
1516         // testing of high bits
1517         __ movl(rdx, result_high_word);
1518         __ mov(rcx, rax);
1519         // What the heck is the point of the next instruction???
1520         __ xorl(rcx, 0x0);
1521         __ movl(rsi, 0x80000000);
1522         __ xorl(rsi, rdx);
1523         __ orl(rcx, rsi);
1524         __ jcc(Assembler::notEqual, do_return);
1525         __ fldz();
1526         __ fcomp_d(value_low_word);
1527         __ fnstsw_ax();
<span class="line-removed">1528 #ifdef _LP64</span>
<span class="line-removed">1529         __ testl(rax, 0x4100);  // ZF &amp; CF == 0</span>
<span class="line-removed">1530         __ jcc(Assembler::equal, return_min_jlong);</span>
<span class="line-removed">1531 #else</span>
1532         __ sahf();
1533         __ jcc(Assembler::above, return_min_jlong);
<span class="line-removed">1534 #endif // _LP64</span>
1535         // return max_jlong
<span class="line-removed">1536 #ifndef _LP64</span>
1537         __ movl(rdx, 0x7fffffff);
1538         __ movl(rax, 0xffffffff);
<span class="line-removed">1539 #else</span>
<span class="line-removed">1540         __ mov64(rax, CONST64(0x7fffffffffffffff));</span>
<span class="line-removed">1541 #endif // _LP64</span>
1542         __ jmp(do_return);
1543 
1544         __ bind(return_min_jlong);
<span class="line-removed">1545 #ifndef _LP64</span>
1546         __ movl(rdx, 0x80000000);
1547         __ xorl(rax, rax);
<span class="line-removed">1548 #else</span>
<span class="line-removed">1549         __ mov64(rax, UCONST64(0x8000000000000000));</span>
<span class="line-removed">1550 #endif // _LP64</span>
1551         __ jmp(do_return);
1552 
1553         __ bind(return0);
1554         __ fpop();
<span class="line-removed">1555 #ifndef _LP64</span>
1556         __ xorptr(rdx,rdx);
1557         __ xorptr(rax,rax);
<span class="line-removed">1558 #else</span>
<span class="line-removed">1559         __ xorptr(rax, rax);</span>
<span class="line-removed">1560 #endif // _LP64</span>
1561 
1562         __ bind(do_return);
1563         __ addptr(rsp, 32);
<span class="line-removed">1564         LP64_ONLY(__ pop(rdx);)</span>
1565         __ pop(rcx);
1566         __ pop(rsi);
1567         __ ret(0);

1568       }
1569       break;
1570 
1571     case predicate_failed_trap_id:
1572       {
1573         StubFrame f(sasm, &quot;predicate_failed_trap&quot;, dont_gc_arguments);
1574 
1575         OopMap* map = save_live_registers(sasm, 1);
1576 
1577         int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, predicate_failed_trap));
1578         oop_maps = new OopMapSet();
1579         oop_maps-&gt;add_gc_map(call_offset, map);
1580         restore_live_registers(sasm);
1581         __ leave();
1582         DeoptimizationBlob* deopt_blob = SharedRuntime::deopt_blob();
1583         assert(deopt_blob != NULL, &quot;deoptimization blob must have been created&quot;);
1584 
1585         __ jump(RuntimeAddress(deopt_blob-&gt;unpack_with_reexecution()));
1586       }
1587       break;
</pre>
</td>
<td>
<hr />
<pre>
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/assembler.hpp&quot;
  27 #include &quot;c1/c1_Defs.hpp&quot;
  28 #include &quot;c1/c1_MacroAssembler.hpp&quot;
  29 #include &quot;c1/c1_Runtime1.hpp&quot;
  30 #include &quot;ci/ciUtilities.hpp&quot;
  31 #include &quot;gc/shared/cardTable.hpp&quot;
  32 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;
<span class="line-added">  34 #include &quot;memory/universe.hpp&quot;</span>
  35 #include &quot;nativeInst_x86.hpp&quot;
  36 #include &quot;oops/compiledICHolder.hpp&quot;
  37 #include &quot;oops/oop.inline.hpp&quot;
  38 #include &quot;prims/jvmtiExport.hpp&quot;
  39 #include &quot;register_x86.hpp&quot;
  40 #include &quot;runtime/sharedRuntime.hpp&quot;
  41 #include &quot;runtime/signature.hpp&quot;
  42 #include &quot;runtime/vframeArray.hpp&quot;
  43 #include &quot;utilities/macros.hpp&quot;
  44 #include &quot;vmreg_x86.inline.hpp&quot;
  45 
  46 // Implementation of StubAssembler
  47 
  48 int StubAssembler::call_RT(Register oop_result1, Register metadata_result, address entry, int args_size) {
  49   // setup registers
  50   const Register thread = NOT_LP64(rdi) LP64_ONLY(r15_thread); // is callee-saved register (Visual C++ calling conventions)
  51   assert(!(oop_result1-&gt;is_valid() || metadata_result-&gt;is_valid()) || oop_result1 != metadata_result, &quot;registers must be different&quot;);
  52   assert(oop_result1 != thread &amp;&amp; metadata_result != thread, &quot;registers must be different&quot;);
  53   assert(args_size &gt;= 0, &quot;illegal args_size&quot;);
  54   bool align_stack = false;
</pre>
<hr />
<pre>
 410   return map;
 411 }
 412 
 413 #define __ this-&gt;
 414 
 415 void C1_MacroAssembler::save_live_registers_no_oop_map(bool save_fpu_registers) {
 416   __ block_comment(&quot;save_live_registers&quot;);
 417 
 418   __ pusha();         // integer registers
 419 
 420   // assert(float_regs_as_doubles_off % 2 == 0, &quot;misaligned offset&quot;);
 421   // assert(xmm_regs_as_doubles_off % 2 == 0, &quot;misaligned offset&quot;);
 422 
 423   __ subptr(rsp, extra_space_offset * VMRegImpl::stack_slot_size);
 424 
 425 #ifdef ASSERT
 426   __ movptr(Address(rsp, marker * VMRegImpl::stack_slot_size), (int32_t)0xfeedbeef);
 427 #endif
 428 
 429   if (save_fpu_registers) {
<span class="line-added"> 430 #ifndef _LP64</span>
 431     if (UseSSE &lt; 2) {
 432       // save FPU stack
 433       __ fnsave(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size));
 434       __ fwait();
 435 
 436 #ifdef ASSERT
 437       Label ok;
 438       __ cmpw(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size), StubRoutines::fpu_cntrl_wrd_std());
 439       __ jccb(Assembler::equal, ok);
 440       __ stop(&quot;corrupted control word detected&quot;);
 441       __ bind(ok);
 442 #endif
 443 
 444       // Reset the control word to guard against exceptions being unmasked
 445       // since fstp_d can cause FPU stack underflow exceptions.  Write it
 446       // into the on stack copy and then reload that to make sure that the
 447       // current and future values are correct.
 448       __ movw(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size), StubRoutines::fpu_cntrl_wrd_std());
 449       __ frstor(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size));
 450 
 451       // Save the FPU registers in de-opt-able form
 452       int offset = 0;
 453       for (int n = 0; n &lt; FrameMap::nof_fpu_regs; n++) {
 454         __ fstp_d(Address(rsp, float_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset));
 455         offset += 8;
 456       }
 457     }
<span class="line-added"> 458 #endif // !_LP64</span>
 459 
 460     if (UseSSE &gt;= 2) {
 461       // save XMM registers
 462       // XMM registers can contain float or double values, but this is not known here,
 463       // so always save them as doubles.
 464       // note that float values are _not_ converted automatically, so for float values
 465       // the second word contains only garbage data.
 466       int xmm_bypass_limit = FrameMap::nof_xmm_regs;
 467       int offset = 0;
 468 #ifdef _LP64
 469       if (UseAVX &lt; 3) {
 470         xmm_bypass_limit = xmm_bypass_limit / 2;
 471       }
 472 #endif
 473       for (int n = 0; n &lt; xmm_bypass_limit; n++) {
 474         XMMRegister xmm_name = as_XMMRegister(n);
 475         __ movdbl(Address(rsp, xmm_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset), xmm_name);
 476         offset += 8;
 477       }
<span class="line-added"> 478 #ifndef _LP64</span>
 479     } else if (UseSSE == 1) {
 480       // save XMM registers as float because double not supported without SSE2(num MMX == num fpu)
 481       int offset = 0;
 482       for (int n = 0; n &lt; FrameMap::nof_fpu_regs; n++) {
 483         XMMRegister xmm_name = as_XMMRegister(n);
 484         __ movflt(Address(rsp, xmm_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset), xmm_name);
 485         offset += 8;
 486       }
<span class="line-added"> 487 #endif // !_LP64</span>
 488     }
 489   }
 490 
 491   // FPU stack must be empty now
<span class="line-modified"> 492   NOT_LP64( __ verify_FPU(0, &quot;save_live_registers&quot;); )</span>
 493 }
 494 
 495 #undef __
 496 #define __ sasm-&gt;
 497 
 498 static void restore_fpu(C1_MacroAssembler* sasm, bool restore_fpu_registers) {
<span class="line-added"> 499 #ifdef _LP64</span>
<span class="line-added"> 500   if (restore_fpu_registers) {</span>
<span class="line-added"> 501     // restore XMM registers</span>
<span class="line-added"> 502     int xmm_bypass_limit = FrameMap::nof_xmm_regs;</span>
<span class="line-added"> 503     if (UseAVX &lt; 3) {</span>
<span class="line-added"> 504       xmm_bypass_limit = xmm_bypass_limit / 2;</span>
<span class="line-added"> 505     }</span>
<span class="line-added"> 506     int offset = 0;</span>
<span class="line-added"> 507     for (int n = 0; n &lt; xmm_bypass_limit; n++) {</span>
<span class="line-added"> 508       XMMRegister xmm_name = as_XMMRegister(n);</span>
<span class="line-added"> 509       __ movdbl(xmm_name, Address(rsp, xmm_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset));</span>
<span class="line-added"> 510       offset += 8;</span>
<span class="line-added"> 511     }</span>
<span class="line-added"> 512   }</span>
<span class="line-added"> 513 #else</span>
 514   if (restore_fpu_registers) {
 515     if (UseSSE &gt;= 2) {
 516       // restore XMM registers
 517       int xmm_bypass_limit = FrameMap::nof_xmm_regs;





 518       int offset = 0;
 519       for (int n = 0; n &lt; xmm_bypass_limit; n++) {
 520         XMMRegister xmm_name = as_XMMRegister(n);
 521         __ movdbl(xmm_name, Address(rsp, xmm_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset));
 522         offset += 8;
 523       }
 524     } else if (UseSSE == 1) {
 525       // restore XMM registers(num MMX == num fpu)
 526       int offset = 0;
 527       for (int n = 0; n &lt; FrameMap::nof_fpu_regs; n++) {
 528         XMMRegister xmm_name = as_XMMRegister(n);
 529         __ movflt(xmm_name, Address(rsp, xmm_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset));
 530         offset += 8;
 531       }
 532     }
 533 
 534     if (UseSSE &lt; 2) {
 535       __ frstor(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size));
 536     } else {
 537       // check that FPU stack is really empty
 538       __ verify_FPU(0, &quot;restore_live_registers&quot;);
 539     }

 540   } else {
 541     // check that FPU stack is really empty
 542     __ verify_FPU(0, &quot;restore_live_registers&quot;);
 543   }
<span class="line-added"> 544 #endif // _LP64</span>
 545 
 546 #ifdef ASSERT
 547   {
 548     Label ok;
 549     __ cmpptr(Address(rsp, marker * VMRegImpl::stack_slot_size), (int32_t)0xfeedbeef);
 550     __ jcc(Assembler::equal, ok);
 551     __ stop(&quot;bad offsets in frame&quot;);
 552     __ bind(ok);
 553   }
 554 #endif // ASSERT
 555 
 556   __ addptr(rsp, extra_space_offset * VMRegImpl::stack_slot_size);
 557 }
 558 
 559 #undef __
 560 #define __ this-&gt;
 561 
 562 void C1_MacroAssembler::restore_live_registers(bool restore_fpu_registers) {
 563   __ block_comment(&quot;restore_live_registers&quot;);
 564 
</pre>
<hr />
<pre>
 696     __ movptr(Address(thread, JavaThread::vm_result_offset()),   NULL_WORD);
 697     __ movptr(Address(thread, JavaThread::vm_result_2_offset()), NULL_WORD);
 698     break;
 699   case handle_exception_nofpu_id:
 700   case handle_exception_id:
 701     // At this point all registers MAY be live.
 702     oop_map = save_live_registers(sasm, 1 /*thread*/, id != handle_exception_nofpu_id);
 703     break;
 704   case handle_exception_from_callee_id: {
 705     // At this point all registers except exception oop (RAX) and
 706     // exception pc (RDX) are dead.
 707     const int frame_size = 2 /*BP, return address*/ NOT_LP64(+ 1 /*thread*/) WIN64_ONLY(+ frame::arg_reg_save_area_bytes / BytesPerWord);
 708     oop_map = new OopMap(frame_size * VMRegImpl::slots_per_word, 0);
 709     sasm-&gt;set_frame_size(frame_size);
 710     WIN64_ONLY(__ subq(rsp, frame::arg_reg_save_area_bytes));
 711     break;
 712   }
 713   default:  ShouldNotReachHere();
 714   }
 715 
<span class="line-modified"> 716 #if !defined(_LP64) &amp;&amp; defined(TIERED)</span>

 717   if (UseSSE &lt; 2) {
<span class="line-added"> 718     // C2 can leave the fpu stack dirty</span>
 719     __ empty_FPU_stack();
 720   }
<span class="line-modified"> 721 #endif // !_LP64 &amp;&amp; TIERED</span>
 722 
 723   // verify that only rax, and rdx is valid at this time
 724   __ invalidate_registers(false, true, true, false, true, true);
 725   // verify that rax, contains a valid exception
 726   __ verify_not_null_oop(exception_oop);
 727 
 728   // load address of JavaThread object for thread-local data
 729   NOT_LP64(__ get_thread(thread);)
 730 
 731 #ifdef ASSERT
 732   // check that fields in JavaThread for exception oop and issuing pc are
 733   // empty before writing to them
 734   Label oop_empty;
 735   __ cmpptr(Address(thread, JavaThread::exception_oop_offset()), (int32_t) NULL_WORD);
 736   __ jcc(Assembler::equal, oop_empty);
 737   __ stop(&quot;exception oop already set&quot;);
 738   __ bind(oop_empty);
 739 
 740   Label pc_empty;
 741   __ cmpptr(Address(thread, JavaThread::exception_pc_offset()), 0);
</pre>
<hr />
<pre>
 803   // verify that only rax, is valid at this time
 804   __ invalidate_registers(false, true, true, true, true, true);
 805 
 806 #ifdef ASSERT
 807   // check that fields in JavaThread for exception oop and issuing pc are empty
 808   NOT_LP64(__ get_thread(thread);)
 809   Label oop_empty;
 810   __ cmpptr(Address(thread, JavaThread::exception_oop_offset()), 0);
 811   __ jcc(Assembler::equal, oop_empty);
 812   __ stop(&quot;exception oop must be empty&quot;);
 813   __ bind(oop_empty);
 814 
 815   Label pc_empty;
 816   __ cmpptr(Address(thread, JavaThread::exception_pc_offset()), 0);
 817   __ jcc(Assembler::equal, pc_empty);
 818   __ stop(&quot;exception pc must be empty&quot;);
 819   __ bind(pc_empty);
 820 #endif
 821 
 822   // clear the FPU stack in case any FPU results are left behind
<span class="line-modified"> 823   NOT_LP64( __ empty_FPU_stack(); )</span>
 824 
 825   // save exception_oop in callee-saved register to preserve it during runtime calls
 826   __ verify_not_null_oop(exception_oop);
 827   __ movptr(exception_oop_callee_saved, exception_oop);
 828 
 829   NOT_LP64(__ get_thread(thread);)
 830   // Get return address (is on top of stack after leave).
 831   __ movptr(exception_pc, Address(rsp, 0));
 832 
 833   // search the exception handler address of the caller (using the return address)
 834   __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::exception_handler_for_return_address), thread, exception_pc);
 835   // rax: exception handler address of the caller
 836 
 837   // Only RAX and RSI are valid at this time, all other registers have been destroyed by the call.
 838   __ invalidate_registers(false, true, true, true, false, true);
 839 
 840   // move result of call into correct register
 841   __ movptr(handler_addr, rax);
 842 
 843   // Restore exception oop to RAX (required convention of exception handler).
</pre>
<hr />
<pre>
1474       }
1475       break;
1476 
1477     case dtrace_object_alloc_id:
1478       { // rax,: object
1479         StubFrame f(sasm, &quot;dtrace_object_alloc&quot;, dont_gc_arguments);
1480         // we can&#39;t gc here so skip the oopmap but make sure that all
1481         // the live registers get saved.
1482         save_live_registers(sasm, 1);
1483 
1484         __ NOT_LP64(push(rax)) LP64_ONLY(mov(c_rarg0, rax));
1485         __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc)));
1486         NOT_LP64(__ pop(rax));
1487 
1488         restore_live_registers(sasm);
1489       }
1490       break;
1491 
1492     case fpu2long_stub_id:
1493       {
<span class="line-added">1494 #ifdef _LP64</span>
<span class="line-added">1495         Label done;</span>
<span class="line-added">1496         __ cvttsd2siq(rax, Address(rsp, wordSize));</span>
<span class="line-added">1497         __ cmp64(rax, ExternalAddress((address) StubRoutines::x86::double_sign_flip()));</span>
<span class="line-added">1498         __ jccb(Assembler::notEqual, done);</span>
<span class="line-added">1499         __ movq(rax, Address(rsp, wordSize));</span>
<span class="line-added">1500         __ subptr(rsp, 8);</span>
<span class="line-added">1501         __ movq(Address(rsp, 0), rax);</span>
<span class="line-added">1502         __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::x86::d2l_fixup())));</span>
<span class="line-added">1503         __ pop(rax);</span>
<span class="line-added">1504         __ bind(done);</span>
<span class="line-added">1505         __ ret(0);</span>
<span class="line-added">1506 #else</span>
1507         // rax, and rdx are destroyed, but should be free since the result is returned there
1508         // preserve rsi,ecx
1509         __ push(rsi);
1510         __ push(rcx);

1511 
1512         // check for NaN
1513         Label return0, do_return, return_min_jlong, do_convert;
1514 
1515         Address value_high_word(rsp, wordSize + 4);
1516         Address value_low_word(rsp, wordSize);
1517         Address result_high_word(rsp, 3*wordSize + 4);
1518         Address result_low_word(rsp, 3*wordSize);
1519 
1520         __ subptr(rsp, 32);                    // more than enough on 32bit
1521         __ fst_d(value_low_word);
1522         __ movl(rax, value_high_word);
1523         __ andl(rax, 0x7ff00000);
1524         __ cmpl(rax, 0x7ff00000);
1525         __ jcc(Assembler::notEqual, do_convert);
1526         __ movl(rax, value_high_word);
1527         __ andl(rax, 0xfffff);
1528         __ orl(rax, value_low_word);
1529         __ jcc(Assembler::notZero, return0);
1530 
</pre>
<hr />
<pre>
1535         __ movw(Address(rsp, 2), rax);
1536         __ fldcw(Address(rsp, 2));
1537         __ fwait();
1538         __ fistp_d(result_low_word);
1539         __ fldcw(Address(rsp, 0));
1540         __ fwait();
1541         // This gets the entire long in rax on 64bit
1542         __ movptr(rax, result_low_word);
1543         // testing of high bits
1544         __ movl(rdx, result_high_word);
1545         __ mov(rcx, rax);
1546         // What the heck is the point of the next instruction???
1547         __ xorl(rcx, 0x0);
1548         __ movl(rsi, 0x80000000);
1549         __ xorl(rsi, rdx);
1550         __ orl(rcx, rsi);
1551         __ jcc(Assembler::notEqual, do_return);
1552         __ fldz();
1553         __ fcomp_d(value_low_word);
1554         __ fnstsw_ax();




1555         __ sahf();
1556         __ jcc(Assembler::above, return_min_jlong);

1557         // return max_jlong

1558         __ movl(rdx, 0x7fffffff);
1559         __ movl(rax, 0xffffffff);



1560         __ jmp(do_return);
1561 
1562         __ bind(return_min_jlong);

1563         __ movl(rdx, 0x80000000);
1564         __ xorl(rax, rax);



1565         __ jmp(do_return);
1566 
1567         __ bind(return0);
1568         __ fpop();

1569         __ xorptr(rdx,rdx);
1570         __ xorptr(rax,rax);



1571 
1572         __ bind(do_return);
1573         __ addptr(rsp, 32);

1574         __ pop(rcx);
1575         __ pop(rsi);
1576         __ ret(0);
<span class="line-added">1577 #endif // _LP64</span>
1578       }
1579       break;
1580 
1581     case predicate_failed_trap_id:
1582       {
1583         StubFrame f(sasm, &quot;predicate_failed_trap&quot;, dont_gc_arguments);
1584 
1585         OopMap* map = save_live_registers(sasm, 1);
1586 
1587         int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, predicate_failed_trap));
1588         oop_maps = new OopMapSet();
1589         oop_maps-&gt;add_gc_map(call_offset, map);
1590         restore_live_registers(sasm);
1591         __ leave();
1592         DeoptimizationBlob* deopt_blob = SharedRuntime::deopt_blob();
1593         assert(deopt_blob != NULL, &quot;deoptimization blob must have been created&quot;);
1594 
1595         __ jump(RuntimeAddress(deopt_blob-&gt;unpack_with_reexecution()));
1596       }
1597       break;
</pre>
</td>
</tr>
</table>
<center><a href="c1_MacroAssembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_globals_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>