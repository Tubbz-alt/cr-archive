<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/stubGenerator_x86_64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="stubGenerator_x86_32.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubRoutines_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/stubGenerator_x86_64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/macroAssembler.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;ci/ciUtilities.hpp&quot;
  29 #include &quot;gc/shared/barrierSet.hpp&quot;
  30 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  31 #include &quot;gc/shared/barrierSetNMethod.hpp&quot;
  32 #include &quot;interpreter/interpreter.hpp&quot;

  33 #include &quot;nativeInst_x86.hpp&quot;
  34 #include &quot;oops/instanceOop.hpp&quot;
  35 #include &quot;oops/method.hpp&quot;
  36 #include &quot;oops/objArrayKlass.hpp&quot;
  37 #include &quot;oops/oop.inline.hpp&quot;
  38 #include &quot;prims/methodHandles.hpp&quot;
  39 #include &quot;runtime/frame.inline.hpp&quot;
  40 #include &quot;runtime/handles.inline.hpp&quot;
  41 #include &quot;runtime/sharedRuntime.hpp&quot;
  42 #include &quot;runtime/stubCodeGenerator.hpp&quot;
  43 #include &quot;runtime/stubRoutines.hpp&quot;
  44 #include &quot;runtime/thread.inline.hpp&quot;
  45 #ifdef COMPILER2
  46 #include &quot;opto/runtime.hpp&quot;
  47 #endif
  48 #if INCLUDE_ZGC
  49 #include &quot;gc/z/zThreadLocalData.hpp&quot;
  50 #endif
  51 
  52 // Declaration and definition of StubGenerator (no .hpp file).
</pre>
<hr />
<pre>
 534     // make sure exception is set
 535     {
 536       Label L;
 537       __ testptr(rax, rax);
 538       __ jcc(Assembler::notEqual, L);
 539       __ stop(&quot;StubRoutines::forward exception: no pending exception (2)&quot;);
 540       __ bind(L);
 541     }
 542 #endif
 543 
 544     // continue at exception handler (return address removed)
 545     // rax: exception
 546     // rbx: exception handler
 547     // rdx: throwing pc
 548     __ verify_oop(rax);
 549     __ jmp(rbx);
 550 
 551     return start;
 552   }
 553 
<span class="line-modified"> 554   // Support for jint atomic::xchg(jint exchange_value, volatile jint* dest)</span>

 555   //
 556   // Arguments :
 557   //    c_rarg0: exchange_value
 558   //    c_rarg0: dest
 559   //
 560   // Result:
 561   //    *dest &lt;- ex, return (orig *dest)
 562   address generate_atomic_xchg() {
 563     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;atomic_xchg&quot;);
 564     address start = __ pc();
 565 
 566     __ movl(rax, c_rarg0); // Copy to eax we need a return value anyhow
 567     __ xchgl(rax, Address(c_rarg1, 0)); // automatic LOCK
 568     __ ret(0);
 569 
 570     return start;
 571   }
 572 
<span class="line-modified"> 573   // Support for intptr_t atomic::xchg_long(jlong exchange_value, volatile jlong* dest)</span>

 574   //
 575   // Arguments :
 576   //    c_rarg0: exchange_value
 577   //    c_rarg1: dest
 578   //
 579   // Result:
 580   //    *dest &lt;- ex, return (orig *dest)
 581   address generate_atomic_xchg_long() {
 582     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;atomic_xchg_long&quot;);
 583     address start = __ pc();
 584 
 585     __ movptr(rax, c_rarg0); // Copy to eax we need a return value anyhow
 586     __ xchgptr(rax, Address(c_rarg1, 0)); // automatic LOCK
 587     __ ret(0);
 588 
 589     return start;
 590   }
 591 
 592   // Support for jint atomic::atomic_cmpxchg(jint exchange_value, volatile jint* dest,
 593   //                                         jint compare_value)
</pre>
<hr />
<pre>
 650   //    c_rarg2: compare_value
 651   //
 652   // Result:
 653   //    if ( compare_value == *dest ) {
 654   //       *dest = exchange_value
 655   //       return compare_value;
 656   //    else
 657   //       return *dest;
 658   address generate_atomic_cmpxchg_long() {
 659     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;atomic_cmpxchg_long&quot;);
 660     address start = __ pc();
 661 
 662     __ movq(rax, c_rarg2);
 663     __ lock();
 664     __ cmpxchgq(c_rarg0, Address(c_rarg1, 0));
 665     __ ret(0);
 666 
 667     return start;
 668   }
 669 
<span class="line-modified"> 670   // Support for jint atomic::add(jint add_value, volatile jint* dest)</span>

 671   //
 672   // Arguments :
 673   //    c_rarg0: add_value
 674   //    c_rarg1: dest
 675   //
 676   // Result:
 677   //    *dest += add_value
 678   //    return *dest;
 679   address generate_atomic_add() {
 680     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;atomic_add&quot;);
 681     address start = __ pc();
 682 
 683     __ movl(rax, c_rarg0);
 684     __ lock();
 685     __ xaddl(Address(c_rarg1, 0), c_rarg0);
 686     __ addl(rax, c_rarg0);
 687     __ ret(0);
 688 
 689     return start;
 690   }
 691 
<span class="line-modified"> 692   // Support for intptr_t atomic::add_ptr(intptr_t add_value, volatile intptr_t* dest)</span>

 693   //
 694   // Arguments :
 695   //    c_rarg0: add_value
 696   //    c_rarg1: dest
 697   //
 698   // Result:
 699   //    *dest += add_value
 700   //    return *dest;
 701   address generate_atomic_add_long() {
 702     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;atomic_add_long&quot;);
 703     address start = __ pc();
 704 
 705     __ movptr(rax, c_rarg0); // Copy to eax we need a return value anyhow
 706     __ lock();
 707     __ xaddptr(Address(c_rarg1, 0), c_rarg0);
 708     __ addptr(rax, c_rarg0);
 709     __ ret(0);
 710 
 711     return start;
 712   }
</pre>
<hr />
<pre>
 962     __ pop(c_rarg2);
 963     __ pop(c_rarg3);
 964     __ pop(rax);
 965 
 966     __ ret(0);
 967 
 968     return start;
 969   }
 970 
 971   address generate_fp_mask(const char *stub_name, int64_t mask) {
 972     __ align(CodeEntryAlignment);
 973     StubCodeMark mark(this, &quot;StubRoutines&quot;, stub_name);
 974     address start = __ pc();
 975 
 976     __ emit_data64( mask, relocInfo::none );
 977     __ emit_data64( mask, relocInfo::none );
 978 
 979     return start;
 980   }
 981 


































 982   // Non-destructive plausibility checks for oops
 983   //
 984   // Arguments:
 985   //    all args on stack!
 986   //
 987   // Stack after saving c_rarg3:
 988   //    [tos + 0]: saved c_rarg3
 989   //    [tos + 1]: saved c_rarg2
 990   //    [tos + 2]: saved r12 (several TemplateTable methods use it)
 991   //    [tos + 3]: saved flags
 992   //    [tos + 4]: return address
 993   //  * [tos + 5]: error message (char*)
 994   //  * [tos + 6]: object to verify (oop)
 995   //  * [tos + 7]: saved rax - saved by caller and bashed
 996   //  * [tos + 8]: saved r10 (rscratch1) - saved by caller
 997   //  * = popped on exit
 998   address generate_verify_oop() {
 999     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;verify_oop&quot;);
1000     address start = __ pc();
1001 
</pre>
<hr />
<pre>
1077                                                  // already pushed)
1078     // debug(char* msg, int64_t pc, int64_t regs[])
1079     // We&#39;ve popped the registers we&#39;d saved (c_rarg3, c_rarg2 and flags), and
1080     // pushed all the registers, so now the stack looks like:
1081     //     [tos +  0] 16 saved registers
1082     //     [tos + 16] return address
1083     //   * [tos + 17] error message (char*)
1084     //   * [tos + 18] object to verify (oop)
1085     //   * [tos + 19] saved rax - saved by caller and bashed
1086     //   * [tos + 20] saved r10 (rscratch1) - saved by caller
1087     //   * = popped on exit
1088 
1089     __ movptr(c_rarg0, Address(rsp, error_msg));    // pass address of error message
1090     __ movptr(c_rarg1, Address(rsp, return_addr));  // pass return address
1091     __ movq(c_rarg2, rsp);                          // pass address of regs on stack
1092     __ mov(r12, rsp);                               // remember rsp
1093     __ subptr(rsp, frame::arg_reg_save_area_bytes); // windows
1094     __ andptr(rsp, -16);                            // align stack as required by ABI
1095     BLOCK_COMMENT(&quot;call MacroAssembler::debug&quot;);
1096     __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, MacroAssembler::debug64)));
<span class="line-modified">1097     __ mov(rsp, r12);                               // restore rsp</span>
<span class="line-removed">1098     __ popa();                                      // pop registers (includes r12)</span>
<span class="line-removed">1099     __ ret(4 * wordSize);                           // pop caller saved stuff</span>
<span class="line-removed">1100 </span>
1101     return start;
1102   }
1103 
1104   //
1105   // Verify that a register contains clean 32-bits positive value
1106   // (high 32-bits are 0) so it could be used in 64-bits shifts.
1107   //
1108   //  Input:
1109   //    Rint  -  32-bits value
1110   //    Rtmp  -  scratch
1111   //
1112   void assert_clean_int(Register Rint, Register Rtmp) {
1113 #ifdef ASSERT
1114     Label L;
1115     assert_different_registers(Rtmp, Rint);
1116     __ movslq(Rtmp, Rint);
1117     __ cmpq(Rtmp, Rint);
1118     __ jcc(Assembler::equal, L);
1119     __ stop(&quot;high 32-bits of int value are not 0&quot;);
1120     __ bind(L);
</pre>
<hr />
<pre>
1239 
1240   // Copy big chunks forward
1241   //
1242   // Inputs:
1243   //   end_from     - source arrays end address
1244   //   end_to       - destination array end address
1245   //   qword_count  - 64-bits element count, negative
1246   //   to           - scratch
1247   //   L_copy_bytes - entry label
1248   //   L_copy_8_bytes  - exit  label
1249   //
1250   void copy_bytes_forward(Register end_from, Register end_to,
1251                              Register qword_count, Register to,
1252                              Label&amp; L_copy_bytes, Label&amp; L_copy_8_bytes) {
1253     DEBUG_ONLY(__ stop(&quot;enter at entry label, not here&quot;));
1254     Label L_loop;
1255     __ align(OptoLoopAlignment);
1256     if (UseUnalignedLoadStores) {
1257       Label L_end;
1258       // Copy 64-bytes per iteration
<span class="line-removed">1259       __ BIND(L_loop);</span>
1260       if (UseAVX &gt; 2) {








1261         __ evmovdqul(xmm0, Address(end_from, qword_count, Address::times_8, -56), Assembler::AVX_512bit);
1262         __ evmovdqul(Address(end_to, qword_count, Address::times_8, -56), xmm0, Assembler::AVX_512bit);
<span class="line-modified">1263       } else if (UseAVX == 2) {</span>





1264         __ vmovdqu(xmm0, Address(end_from, qword_count, Address::times_8, -56));
1265         __ vmovdqu(Address(end_to, qword_count, Address::times_8, -56), xmm0);
1266         __ vmovdqu(xmm1, Address(end_from, qword_count, Address::times_8, -24));
1267         __ vmovdqu(Address(end_to, qword_count, Address::times_8, -24), xmm1);







1268       } else {
<span class="line-modified">1269         __ movdqu(xmm0, Address(end_from, qword_count, Address::times_8, -56));</span>
<span class="line-modified">1270         __ movdqu(Address(end_to, qword_count, Address::times_8, -56), xmm0);</span>
<span class="line-modified">1271         __ movdqu(xmm1, Address(end_from, qword_count, Address::times_8, -40));</span>
<span class="line-modified">1272         __ movdqu(Address(end_to, qword_count, Address::times_8, -40), xmm1);</span>
<span class="line-modified">1273         __ movdqu(xmm2, Address(end_from, qword_count, Address::times_8, -24));</span>
<span class="line-modified">1274         __ movdqu(Address(end_to, qword_count, Address::times_8, -24), xmm2);</span>
<span class="line-modified">1275         __ movdqu(xmm3, Address(end_from, qword_count, Address::times_8, - 8));</span>
<span class="line-modified">1276         __ movdqu(Address(end_to, qword_count, Address::times_8, - 8), xmm3);</span>














1277       }
<span class="line-removed">1278       __ BIND(L_copy_bytes);</span>
<span class="line-removed">1279       __ addptr(qword_count, 8);</span>
<span class="line-removed">1280       __ jcc(Assembler::lessEqual, L_loop);</span>
<span class="line-removed">1281       __ subptr(qword_count, 4);  // sub(8) and add(4)</span>
<span class="line-removed">1282       __ jccb(Assembler::greater, L_end);</span>
1283       // Copy trailing 32 bytes
1284       if (UseAVX &gt;= 2) {
1285         __ vmovdqu(xmm0, Address(end_from, qword_count, Address::times_8, -24));
1286         __ vmovdqu(Address(end_to, qword_count, Address::times_8, -24), xmm0);
1287       } else {
1288         __ movdqu(xmm0, Address(end_from, qword_count, Address::times_8, -24));
1289         __ movdqu(Address(end_to, qword_count, Address::times_8, -24), xmm0);
1290         __ movdqu(xmm1, Address(end_from, qword_count, Address::times_8, - 8));
1291         __ movdqu(Address(end_to, qword_count, Address::times_8, - 8), xmm1);
1292       }
1293       __ addptr(qword_count, 4);
1294       __ BIND(L_end);
1295       if (UseAVX &gt;= 2) {
1296         // clean upper bits of YMM registers
1297         __ vpxor(xmm0, xmm0);
1298         __ vpxor(xmm1, xmm1);
1299       }
1300     } else {
1301       // Copy 32-bytes per iteration
1302       __ BIND(L_loop);
</pre>
<hr />
<pre>
1319 
1320   // Copy big chunks backward
1321   //
1322   // Inputs:
1323   //   from         - source arrays address
1324   //   dest         - destination array address
1325   //   qword_count  - 64-bits element count
1326   //   to           - scratch
1327   //   L_copy_bytes - entry label
1328   //   L_copy_8_bytes  - exit  label
1329   //
1330   void copy_bytes_backward(Register from, Register dest,
1331                               Register qword_count, Register to,
1332                               Label&amp; L_copy_bytes, Label&amp; L_copy_8_bytes) {
1333     DEBUG_ONLY(__ stop(&quot;enter at entry label, not here&quot;));
1334     Label L_loop;
1335     __ align(OptoLoopAlignment);
1336     if (UseUnalignedLoadStores) {
1337       Label L_end;
1338       // Copy 64-bytes per iteration
<span class="line-removed">1339       __ BIND(L_loop);</span>
1340       if (UseAVX &gt; 2) {








1341         __ evmovdqul(xmm0, Address(from, qword_count, Address::times_8, 0), Assembler::AVX_512bit);
1342         __ evmovdqul(Address(dest, qword_count, Address::times_8, 0), xmm0, Assembler::AVX_512bit);
<span class="line-modified">1343       } else if (UseAVX == 2) {</span>





1344         __ vmovdqu(xmm0, Address(from, qword_count, Address::times_8, 32));
1345         __ vmovdqu(Address(dest, qword_count, Address::times_8, 32), xmm0);
<span class="line-modified">1346         __ vmovdqu(xmm1, Address(from, qword_count, Address::times_8,  0));</span>
<span class="line-modified">1347         __ vmovdqu(Address(dest, qword_count, Address::times_8,  0), xmm1);</span>







1348       } else {
<span class="line-modified">1349         __ movdqu(xmm0, Address(from, qword_count, Address::times_8, 48));</span>
<span class="line-modified">1350         __ movdqu(Address(dest, qword_count, Address::times_8, 48), xmm0);</span>
<span class="line-modified">1351         __ movdqu(xmm1, Address(from, qword_count, Address::times_8, 32));</span>
<span class="line-modified">1352         __ movdqu(Address(dest, qword_count, Address::times_8, 32), xmm1);</span>
<span class="line-modified">1353         __ movdqu(xmm2, Address(from, qword_count, Address::times_8, 16));</span>
<span class="line-modified">1354         __ movdqu(Address(dest, qword_count, Address::times_8, 16), xmm2);</span>
<span class="line-modified">1355         __ movdqu(xmm3, Address(from, qword_count, Address::times_8,  0));</span>
<span class="line-modified">1356         __ movdqu(Address(dest, qword_count, Address::times_8,  0), xmm3);</span>
<span class="line-modified">1357       }</span>
<span class="line-modified">1358       __ BIND(L_copy_bytes);</span>
<span class="line-modified">1359       __ subptr(qword_count, 8);</span>
<span class="line-modified">1360       __ jcc(Assembler::greaterEqual, L_loop);</span>




1361 
<span class="line-modified">1362       __ addptr(qword_count, 4);  // add(8) and sub(4)</span>
<span class="line-modified">1363       __ jccb(Assembler::less, L_end);</span>





1364       // Copy trailing 32 bytes
1365       if (UseAVX &gt;= 2) {
1366         __ vmovdqu(xmm0, Address(from, qword_count, Address::times_8, 0));
1367         __ vmovdqu(Address(dest, qword_count, Address::times_8, 0), xmm0);
1368       } else {
1369         __ movdqu(xmm0, Address(from, qword_count, Address::times_8, 16));
1370         __ movdqu(Address(dest, qword_count, Address::times_8, 16), xmm0);
1371         __ movdqu(xmm1, Address(from, qword_count, Address::times_8,  0));
1372         __ movdqu(Address(dest, qword_count, Address::times_8,  0), xmm1);
1373       }
1374       __ subptr(qword_count, 4);
1375       __ BIND(L_end);
1376       if (UseAVX &gt;= 2) {
1377         // clean upper bits of YMM registers
1378         __ vpxor(xmm0, xmm0);
1379         __ vpxor(xmm1, xmm1);
1380       }
1381     } else {
1382       // Copy 32-bytes per iteration
1383       __ BIND(L_loop);
1384       __ movq(to, Address(from, qword_count, Address::times_8, 24));
1385       __ movq(Address(dest, qword_count, Address::times_8, 24), to);
1386       __ movq(to, Address(from, qword_count, Address::times_8, 16));
1387       __ movq(Address(dest, qword_count, Address::times_8, 16), to);
1388       __ movq(to, Address(from, qword_count, Address::times_8,  8));
1389       __ movq(Address(dest, qword_count, Address::times_8,  8), to);
1390       __ movq(to, Address(from, qword_count, Address::times_8,  0));
1391       __ movq(Address(dest, qword_count, Address::times_8,  0), to);
1392 
1393       __ BIND(L_copy_bytes);
1394       __ subptr(qword_count, 4);
1395       __ jcc(Assembler::greaterEqual, L_loop);
1396     }
1397     __ addptr(qword_count, 4);
1398     __ jcc(Assembler::greater, L_copy_8_bytes); // Copy trailing qwords
1399   }
1400 
<span class="line-removed">1401 </span>
1402   // Arguments:
1403   //   aligned - true =&gt; Input and output aligned on a HeapWord == 8-byte boundary
1404   //             ignored
1405   //   name    - stub name string
1406   //
1407   // Inputs:
1408   //   c_rarg0   - source array address
1409   //   c_rarg1   - destination array address
1410   //   c_rarg2   - element count, treated as ssize_t, can be zero
1411   //
1412   // If &#39;from&#39; and/or &#39;to&#39; are aligned on 4-, 2-, or 1-byte boundaries,
1413   // we let the hardware handle it.  The one to eight bytes within words,
1414   // dwords or qwords that span cache line boundaries will still be loaded
1415   // and stored atomically.
1416   //
1417   // Side Effects:
1418   //   disjoint_byte_copy_entry is set to the no-overlap entry point
1419   //   used by generate_conjoint_byte_copy().
1420   //
1421   address generate_disjoint_byte_copy(bool aligned, address* entry, const char *name) {
</pre>
<hr />
<pre>
1430     const Register count       = rdx;  // elements count
1431     const Register byte_count  = rcx;
1432     const Register qword_count = count;
1433     const Register end_from    = from; // source array end address
1434     const Register end_to      = to;   // destination array end address
1435     // End pointers are inclusive, and if count is not zero they point
1436     // to the last unit copied:  end_to[0] := end_from[0]
1437 
1438     __ enter(); // required for proper stackwalking of RuntimeStub frame
1439     assert_clean_int(c_rarg2, rax);    // Make sure &#39;count&#39; is clean int.
1440 
1441     if (entry != NULL) {
1442       *entry = __ pc();
1443        // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
1444       BLOCK_COMMENT(&quot;Entry:&quot;);
1445     }
1446 
1447     setup_arg_regs(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
1448                       // r9 and r10 may be used to save non-volatile registers
1449 
<span class="line-modified">1450     // &#39;from&#39;, &#39;to&#39; and &#39;count&#39; are now valid</span>
<span class="line-modified">1451     __ movptr(byte_count, count);</span>
<span class="line-modified">1452     __ shrptr(count, 3); // count =&gt; qword_count</span>
<span class="line-modified">1453 </span>
<span class="line-modified">1454     // Copy from low to high addresses.  Use &#39;to&#39; as scratch.</span>
<span class="line-modified">1455     __ lea(end_from, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-modified">1456     __ lea(end_to,   Address(to,   qword_count, Address::times_8, -8));</span>
<span class="line-modified">1457     __ negptr(qword_count); // make the count negative</span>
<span class="line-modified">1458     __ jmp(L_copy_bytes);</span>
<span class="line-modified">1459 </span>
<span class="line-modified">1460     // Copy trailing qwords</span>
<span class="line-modified">1461   __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">1462     __ movq(rax, Address(end_from, qword_count, Address::times_8, 8));</span>
<span class="line-modified">1463     __ movq(Address(end_to, qword_count, Address::times_8, 8), rax);</span>
<span class="line-modified">1464     __ increment(qword_count);</span>
<span class="line-modified">1465     __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-modified">1466 </span>
<span class="line-modified">1467     // Check for and copy trailing dword</span>
<span class="line-modified">1468   __ BIND(L_copy_4_bytes);</span>
<span class="line-modified">1469     __ testl(byte_count, 4);</span>
<span class="line-modified">1470     __ jccb(Assembler::zero, L_copy_2_bytes);</span>
<span class="line-modified">1471     __ movl(rax, Address(end_from, 8));</span>
<span class="line-modified">1472     __ movl(Address(end_to, 8), rax);</span>
<span class="line-modified">1473 </span>
<span class="line-modified">1474     __ addptr(end_from, 4);</span>
<span class="line-modified">1475     __ addptr(end_to, 4);</span>
<span class="line-modified">1476 </span>
<span class="line-modified">1477     // Check for and copy trailing word</span>
<span class="line-modified">1478   __ BIND(L_copy_2_bytes);</span>
<span class="line-modified">1479     __ testl(byte_count, 2);</span>
<span class="line-modified">1480     __ jccb(Assembler::zero, L_copy_byte);</span>
<span class="line-modified">1481     __ movw(rax, Address(end_from, 8));</span>
<span class="line-modified">1482     __ movw(Address(end_to, 8), rax);</span>
<span class="line-modified">1483 </span>
<span class="line-modified">1484     __ addptr(end_from, 2);</span>
<span class="line-modified">1485     __ addptr(end_to, 2);</span>
<span class="line-modified">1486 </span>
<span class="line-modified">1487     // Check for and copy trailing byte</span>
<span class="line-modified">1488   __ BIND(L_copy_byte);</span>
<span class="line-modified">1489     __ testl(byte_count, 1);</span>
<span class="line-modified">1490     __ jccb(Assembler::zero, L_exit);</span>
<span class="line-modified">1491     __ movb(rax, Address(end_from, 8));</span>
<span class="line-modified">1492     __ movb(Address(end_to, 8), rax);</span>
<span class="line-modified">1493 </span>



1494   __ BIND(L_exit);

1495     restore_arg_regs();
1496     inc_counter_np(SharedRuntime::_jbyte_array_copy_ctr); // Update counter after rscratch1 is free
1497     __ xorptr(rax, rax); // return 0
1498     __ vzeroupper();
1499     __ leave(); // required for proper stackwalking of RuntimeStub frame
1500     __ ret(0);
1501 
<span class="line-modified">1502     // Copy in multi-bytes chunks</span>
<span class="line-modified">1503     copy_bytes_forward(end_from, end_to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>
<span class="line-modified">1504     __ jmp(L_copy_4_bytes);</span>
<span class="line-modified">1505 </span>


1506     return start;
1507   }
1508 
1509   // Arguments:
1510   //   aligned - true =&gt; Input and output aligned on a HeapWord == 8-byte boundary
1511   //             ignored
1512   //   name    - stub name string
1513   //
1514   // Inputs:
1515   //   c_rarg0   - source array address
1516   //   c_rarg1   - destination array address
1517   //   c_rarg2   - element count, treated as ssize_t, can be zero
1518   //
1519   // If &#39;from&#39; and/or &#39;to&#39; are aligned on 4-, 2-, or 1-byte boundaries,
1520   // we let the hardware handle it.  The one to eight bytes within words,
1521   // dwords or qwords that span cache line boundaries will still be loaded
1522   // and stored atomically.
1523   //
1524   address generate_conjoint_byte_copy(bool aligned, address nooverlap_target,
1525                                       address* entry, const char *name) {
</pre>
<hr />
<pre>
1530     Label L_copy_bytes, L_copy_8_bytes, L_copy_4_bytes, L_copy_2_bytes;
1531     const Register from        = rdi;  // source array address
1532     const Register to          = rsi;  // destination array address
1533     const Register count       = rdx;  // elements count
1534     const Register byte_count  = rcx;
1535     const Register qword_count = count;
1536 
1537     __ enter(); // required for proper stackwalking of RuntimeStub frame
1538     assert_clean_int(c_rarg2, rax);    // Make sure &#39;count&#39; is clean int.
1539 
1540     if (entry != NULL) {
1541       *entry = __ pc();
1542       // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
1543       BLOCK_COMMENT(&quot;Entry:&quot;);
1544     }
1545 
1546     array_overlap_test(nooverlap_target, Address::times_1);
1547     setup_arg_regs(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
1548                       // r9 and r10 may be used to save non-volatile registers
1549 
<span class="line-modified">1550     // &#39;from&#39;, &#39;to&#39; and &#39;count&#39; are now valid</span>
<span class="line-modified">1551     __ movptr(byte_count, count);</span>
<span class="line-modified">1552     __ shrptr(count, 3);   // count =&gt; qword_count</span>
<span class="line-modified">1553 </span>
<span class="line-modified">1554     // Copy from high to low addresses.</span>
<span class="line-modified">1555 </span>
<span class="line-modified">1556     // Check for and copy trailing byte</span>
<span class="line-modified">1557     __ testl(byte_count, 1);</span>
<span class="line-modified">1558     __ jcc(Assembler::zero, L_copy_2_bytes);</span>
<span class="line-modified">1559     __ movb(rax, Address(from, byte_count, Address::times_1, -1));</span>
<span class="line-modified">1560     __ movb(Address(to, byte_count, Address::times_1, -1), rax);</span>
<span class="line-modified">1561     __ decrement(byte_count); // Adjust for possible trailing word</span>
<span class="line-modified">1562 </span>
<span class="line-modified">1563     // Check for and copy trailing word</span>
<span class="line-modified">1564   __ BIND(L_copy_2_bytes);</span>
<span class="line-modified">1565     __ testl(byte_count, 2);</span>
<span class="line-modified">1566     __ jcc(Assembler::zero, L_copy_4_bytes);</span>
<span class="line-modified">1567     __ movw(rax, Address(from, byte_count, Address::times_1, -2));</span>
<span class="line-modified">1568     __ movw(Address(to, byte_count, Address::times_1, -2), rax);</span>
<span class="line-modified">1569 </span>
<span class="line-modified">1570     // Check for and copy trailing dword</span>
<span class="line-modified">1571   __ BIND(L_copy_4_bytes);</span>
<span class="line-modified">1572     __ testl(byte_count, 4);</span>
<span class="line-modified">1573     __ jcc(Assembler::zero, L_copy_bytes);</span>
<span class="line-modified">1574     __ movl(rax, Address(from, qword_count, Address::times_8));</span>
<span class="line-modified">1575     __ movl(Address(to, qword_count, Address::times_8), rax);</span>
<span class="line-modified">1576     __ jmp(L_copy_bytes);</span>
<span class="line-modified">1577 </span>
<span class="line-modified">1578     // Copy trailing qwords</span>
<span class="line-modified">1579   __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">1580     __ movq(rax, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-modified">1581     __ movq(Address(to, qword_count, Address::times_8, -8), rax);</span>
<span class="line-modified">1582     __ decrement(qword_count);</span>
<span class="line-modified">1583     __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-modified">1584 </span>



1585     restore_arg_regs();
1586     inc_counter_np(SharedRuntime::_jbyte_array_copy_ctr); // Update counter after rscratch1 is free
1587     __ xorptr(rax, rax); // return 0
1588     __ vzeroupper();
1589     __ leave(); // required for proper stackwalking of RuntimeStub frame
1590     __ ret(0);
1591 
<span class="line-modified">1592     // Copy in multi-bytes chunks</span>
<span class="line-modified">1593     copy_bytes_backward(from, to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>
<span class="line-modified">1594 </span>



1595     restore_arg_regs();
1596     inc_counter_np(SharedRuntime::_jbyte_array_copy_ctr); // Update counter after rscratch1 is free
1597     __ xorptr(rax, rax); // return 0
1598     __ vzeroupper();
1599     __ leave(); // required for proper stackwalking of RuntimeStub frame
1600     __ ret(0);
1601 
1602     return start;
1603   }
1604 
1605   // Arguments:
1606   //   aligned - true =&gt; Input and output aligned on a HeapWord == 8-byte boundary
1607   //             ignored
1608   //   name    - stub name string
1609   //
1610   // Inputs:
1611   //   c_rarg0   - source array address
1612   //   c_rarg1   - destination array address
1613   //   c_rarg2   - element count, treated as ssize_t, can be zero
1614   //
</pre>
<hr />
<pre>
1632     const Register count       = rdx;  // elements count
1633     const Register word_count  = rcx;
1634     const Register qword_count = count;
1635     const Register end_from    = from; // source array end address
1636     const Register end_to      = to;   // destination array end address
1637     // End pointers are inclusive, and if count is not zero they point
1638     // to the last unit copied:  end_to[0] := end_from[0]
1639 
1640     __ enter(); // required for proper stackwalking of RuntimeStub frame
1641     assert_clean_int(c_rarg2, rax);    // Make sure &#39;count&#39; is clean int.
1642 
1643     if (entry != NULL) {
1644       *entry = __ pc();
1645       // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
1646       BLOCK_COMMENT(&quot;Entry:&quot;);
1647     }
1648 
1649     setup_arg_regs(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
1650                       // r9 and r10 may be used to save non-volatile registers
1651 
<span class="line-modified">1652     // &#39;from&#39;, &#39;to&#39; and &#39;count&#39; are now valid</span>
<span class="line-modified">1653     __ movptr(word_count, count);</span>
<span class="line-modified">1654     __ shrptr(count, 2); // count =&gt; qword_count</span>
<span class="line-modified">1655 </span>
<span class="line-modified">1656     // Copy from low to high addresses.  Use &#39;to&#39; as scratch.</span>
<span class="line-modified">1657     __ lea(end_from, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-modified">1658     __ lea(end_to,   Address(to,   qword_count, Address::times_8, -8));</span>
<span class="line-modified">1659     __ negptr(qword_count);</span>
<span class="line-modified">1660     __ jmp(L_copy_bytes);</span>
<span class="line-modified">1661 </span>
<span class="line-modified">1662     // Copy trailing qwords</span>
<span class="line-modified">1663   __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">1664     __ movq(rax, Address(end_from, qword_count, Address::times_8, 8));</span>
<span class="line-modified">1665     __ movq(Address(end_to, qword_count, Address::times_8, 8), rax);</span>
<span class="line-modified">1666     __ increment(qword_count);</span>
<span class="line-modified">1667     __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-modified">1668 </span>
<span class="line-modified">1669     // Original &#39;dest&#39; is trashed, so we can&#39;t use it as a</span>
<span class="line-modified">1670     // base register for a possible trailing word copy</span>
<span class="line-modified">1671 </span>
<span class="line-modified">1672     // Check for and copy trailing dword</span>
<span class="line-modified">1673   __ BIND(L_copy_4_bytes);</span>
<span class="line-modified">1674     __ testl(word_count, 2);</span>
<span class="line-modified">1675     __ jccb(Assembler::zero, L_copy_2_bytes);</span>
<span class="line-modified">1676     __ movl(rax, Address(end_from, 8));</span>
<span class="line-modified">1677     __ movl(Address(end_to, 8), rax);</span>
<span class="line-modified">1678 </span>
<span class="line-modified">1679     __ addptr(end_from, 4);</span>
<span class="line-modified">1680     __ addptr(end_to, 4);</span>
<span class="line-modified">1681 </span>
<span class="line-modified">1682     // Check for and copy trailing word</span>
<span class="line-modified">1683   __ BIND(L_copy_2_bytes);</span>
<span class="line-modified">1684     __ testl(word_count, 1);</span>
<span class="line-modified">1685     __ jccb(Assembler::zero, L_exit);</span>
<span class="line-modified">1686     __ movw(rax, Address(end_from, 8));</span>
<span class="line-modified">1687     __ movw(Address(end_to, 8), rax);</span>
<span class="line-modified">1688 </span>



1689   __ BIND(L_exit);

1690     restore_arg_regs();
1691     inc_counter_np(SharedRuntime::_jshort_array_copy_ctr); // Update counter after rscratch1 is free
1692     __ xorptr(rax, rax); // return 0
1693     __ vzeroupper();
1694     __ leave(); // required for proper stackwalking of RuntimeStub frame
1695     __ ret(0);
1696 
<span class="line-modified">1697     // Copy in multi-bytes chunks</span>
<span class="line-modified">1698     copy_bytes_forward(end_from, end_to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>
<span class="line-modified">1699     __ jmp(L_copy_4_bytes);</span>



1700 
1701     return start;
1702   }
1703 
1704   address generate_fill(BasicType t, bool aligned, const char *name) {
1705     __ align(CodeEntryAlignment);
1706     StubCodeMark mark(this, &quot;StubRoutines&quot;, name);
1707     address start = __ pc();
1708 
1709     BLOCK_COMMENT(&quot;Entry:&quot;);
1710 
1711     const Register to       = c_rarg0;  // source array address
1712     const Register value    = c_rarg1;  // value
1713     const Register count    = c_rarg2;  // elements count
1714 
1715     __ enter(); // required for proper stackwalking of RuntimeStub frame
1716 
1717     __ generate_fill(t, aligned, to, value, count, rax, xmm0);
1718 
1719     __ vzeroupper();
</pre>
<hr />
<pre>
1746     Label L_copy_bytes, L_copy_8_bytes, L_copy_4_bytes;
1747     const Register from        = rdi;  // source array address
1748     const Register to          = rsi;  // destination array address
1749     const Register count       = rdx;  // elements count
1750     const Register word_count  = rcx;
1751     const Register qword_count = count;
1752 
1753     __ enter(); // required for proper stackwalking of RuntimeStub frame
1754     assert_clean_int(c_rarg2, rax);    // Make sure &#39;count&#39; is clean int.
1755 
1756     if (entry != NULL) {
1757       *entry = __ pc();
1758       // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
1759       BLOCK_COMMENT(&quot;Entry:&quot;);
1760     }
1761 
1762     array_overlap_test(nooverlap_target, Address::times_2);
1763     setup_arg_regs(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
1764                       // r9 and r10 may be used to save non-volatile registers
1765 
<span class="line-modified">1766     // &#39;from&#39;, &#39;to&#39; and &#39;count&#39; are now valid</span>
<span class="line-modified">1767     __ movptr(word_count, count);</span>
<span class="line-modified">1768     __ shrptr(count, 2); // count =&gt; qword_count</span>
<span class="line-modified">1769 </span>
<span class="line-modified">1770     // Copy from high to low addresses.  Use &#39;to&#39; as scratch.</span>
<span class="line-modified">1771 </span>
<span class="line-modified">1772     // Check for and copy trailing word</span>
<span class="line-modified">1773     __ testl(word_count, 1);</span>
<span class="line-modified">1774     __ jccb(Assembler::zero, L_copy_4_bytes);</span>
<span class="line-modified">1775     __ movw(rax, Address(from, word_count, Address::times_2, -2));</span>
<span class="line-modified">1776     __ movw(Address(to, word_count, Address::times_2, -2), rax);</span>
<span class="line-modified">1777 </span>
<span class="line-modified">1778     // Check for and copy trailing dword</span>
<span class="line-modified">1779   __ BIND(L_copy_4_bytes);</span>
<span class="line-modified">1780     __ testl(word_count, 2);</span>
<span class="line-modified">1781     __ jcc(Assembler::zero, L_copy_bytes);</span>
<span class="line-modified">1782     __ movl(rax, Address(from, qword_count, Address::times_8));</span>
<span class="line-modified">1783     __ movl(Address(to, qword_count, Address::times_8), rax);</span>
<span class="line-modified">1784     __ jmp(L_copy_bytes);</span>
<span class="line-modified">1785 </span>
<span class="line-modified">1786     // Copy trailing qwords</span>
<span class="line-modified">1787   __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">1788     __ movq(rax, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-modified">1789     __ movq(Address(to, qword_count, Address::times_8, -8), rax);</span>
<span class="line-modified">1790     __ decrement(qword_count);</span>
<span class="line-modified">1791     __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-modified">1792 </span>



1793     restore_arg_regs();
1794     inc_counter_np(SharedRuntime::_jshort_array_copy_ctr); // Update counter after rscratch1 is free
1795     __ xorptr(rax, rax); // return 0
1796     __ vzeroupper();
1797     __ leave(); // required for proper stackwalking of RuntimeStub frame
1798     __ ret(0);
1799 
<span class="line-modified">1800     // Copy in multi-bytes chunks</span>
<span class="line-modified">1801     copy_bytes_backward(from, to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>
<span class="line-modified">1802 </span>



1803     restore_arg_regs();
1804     inc_counter_np(SharedRuntime::_jshort_array_copy_ctr); // Update counter after rscratch1 is free
1805     __ xorptr(rax, rax); // return 0
1806     __ vzeroupper();
1807     __ leave(); // required for proper stackwalking of RuntimeStub frame
1808     __ ret(0);
1809 
1810     return start;
1811   }
1812 
1813   // Arguments:
1814   //   aligned - true =&gt; Input and output aligned on a HeapWord == 8-byte boundary
1815   //             ignored
1816   //   is_oop  - true =&gt; oop array, so generate store check code
1817   //   name    - stub name string
1818   //
1819   // Inputs:
1820   //   c_rarg0   - source array address
1821   //   c_rarg1   - destination array address
1822   //   c_rarg2   - element count, treated as ssize_t, can be zero
</pre>
<hr />
<pre>
1853       *entry = __ pc();
1854       // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
1855       BLOCK_COMMENT(&quot;Entry:&quot;);
1856     }
1857 
1858     setup_arg_regs_using_thread(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
1859                                    // r9 is used to save r15_thread
1860 
1861     DecoratorSet decorators = IN_HEAP | IS_ARRAY | ARRAYCOPY_DISJOINT;
1862     if (dest_uninitialized) {
1863       decorators |= IS_DEST_UNINITIALIZED;
1864     }
1865     if (aligned) {
1866       decorators |= ARRAYCOPY_ALIGNED;
1867     }
1868 
1869     BasicType type = is_oop ? T_OBJECT : T_INT;
1870     BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
1871     bs-&gt;arraycopy_prologue(_masm, decorators, type, from, to, count);
1872 
<span class="line-modified">1873     // &#39;from&#39;, &#39;to&#39; and &#39;count&#39; are now valid</span>
<span class="line-modified">1874     __ movptr(dword_count, count);</span>
<span class="line-modified">1875     __ shrptr(count, 1); // count =&gt; qword_count</span>
<span class="line-modified">1876 </span>
<span class="line-modified">1877     // Copy from low to high addresses.  Use &#39;to&#39; as scratch.</span>
<span class="line-modified">1878     __ lea(end_from, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-modified">1879     __ lea(end_to,   Address(to,   qword_count, Address::times_8, -8));</span>
<span class="line-modified">1880     __ negptr(qword_count);</span>
<span class="line-modified">1881     __ jmp(L_copy_bytes);</span>
<span class="line-modified">1882 </span>
<span class="line-modified">1883     // Copy trailing qwords</span>
<span class="line-modified">1884   __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">1885     __ movq(rax, Address(end_from, qword_count, Address::times_8, 8));</span>
<span class="line-modified">1886     __ movq(Address(end_to, qword_count, Address::times_8, 8), rax);</span>
<span class="line-modified">1887     __ increment(qword_count);</span>
<span class="line-modified">1888     __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-modified">1889 </span>
<span class="line-modified">1890     // Check for and copy trailing dword</span>
<span class="line-modified">1891   __ BIND(L_copy_4_bytes);</span>
<span class="line-modified">1892     __ testl(dword_count, 1); // Only byte test since the value is 0 or 1</span>
<span class="line-modified">1893     __ jccb(Assembler::zero, L_exit);</span>
<span class="line-modified">1894     __ movl(rax, Address(end_from, 8));</span>
<span class="line-modified">1895     __ movl(Address(end_to, 8), rax);</span>
<span class="line-modified">1896 </span>



1897   __ BIND(L_exit);

1898     bs-&gt;arraycopy_epilogue(_masm, decorators, type, from, to, dword_count);
1899     restore_arg_regs_using_thread();
1900     inc_counter_np(SharedRuntime::_jint_array_copy_ctr); // Update counter after rscratch1 is free
1901     __ vzeroupper();
1902     __ xorptr(rax, rax); // return 0
1903     __ leave(); // required for proper stackwalking of RuntimeStub frame
1904     __ ret(0);
1905 
<span class="line-modified">1906     // Copy in multi-bytes chunks</span>
<span class="line-modified">1907     copy_bytes_forward(end_from, end_to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>
<span class="line-modified">1908     __ jmp(L_copy_4_bytes);</span>



1909 
1910     return start;
1911   }
1912 
1913   // Arguments:
1914   //   aligned - true =&gt; Input and output aligned on a HeapWord == 8-byte boundary
1915   //             ignored
1916   //   is_oop  - true =&gt; oop array, so generate store check code
1917   //   name    - stub name string
1918   //
1919   // Inputs:
1920   //   c_rarg0   - source array address
1921   //   c_rarg1   - destination array address
1922   //   c_rarg2   - element count, treated as ssize_t, can be zero
1923   //
1924   // If &#39;from&#39; and/or &#39;to&#39; are aligned on 4-byte boundaries, we let
1925   // the hardware handle it.  The two dwords within qwords that span
1926   // cache line boundaries will still be loaded and stored atomicly.
1927   //
1928   address generate_conjoint_int_oop_copy(bool aligned, bool is_oop, address nooverlap_target,
</pre>
<hr />
<pre>
1949     }
1950 
1951     array_overlap_test(nooverlap_target, Address::times_4);
1952     setup_arg_regs_using_thread(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
1953                                    // r9 is used to save r15_thread
1954 
1955     DecoratorSet decorators = IN_HEAP | IS_ARRAY;
1956     if (dest_uninitialized) {
1957       decorators |= IS_DEST_UNINITIALIZED;
1958     }
1959     if (aligned) {
1960       decorators |= ARRAYCOPY_ALIGNED;
1961     }
1962 
1963     BasicType type = is_oop ? T_OBJECT : T_INT;
1964     BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
1965     // no registers are destroyed by this call
1966     bs-&gt;arraycopy_prologue(_masm, decorators, type, from, to, count);
1967 
1968     assert_clean_int(count, rax); // Make sure &#39;count&#39; is clean int.
<span class="line-modified">1969     // &#39;from&#39;, &#39;to&#39; and &#39;count&#39; are now valid</span>
<span class="line-modified">1970     __ movptr(dword_count, count);</span>
<span class="line-modified">1971     __ shrptr(count, 1); // count =&gt; qword_count</span>
<span class="line-modified">1972 </span>
<span class="line-modified">1973     // Copy from high to low addresses.  Use &#39;to&#39; as scratch.</span>
<span class="line-modified">1974 </span>
<span class="line-modified">1975     // Check for and copy trailing dword</span>
<span class="line-modified">1976     __ testl(dword_count, 1);</span>
<span class="line-modified">1977     __ jcc(Assembler::zero, L_copy_bytes);</span>
<span class="line-modified">1978     __ movl(rax, Address(from, dword_count, Address::times_4, -4));</span>
<span class="line-modified">1979     __ movl(Address(to, dword_count, Address::times_4, -4), rax);</span>
<span class="line-modified">1980     __ jmp(L_copy_bytes);</span>
<span class="line-modified">1981 </span>
<span class="line-modified">1982     // Copy trailing qwords</span>
<span class="line-modified">1983   __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">1984     __ movq(rax, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-modified">1985     __ movq(Address(to, qword_count, Address::times_8, -8), rax);</span>
<span class="line-modified">1986     __ decrement(qword_count);</span>
<span class="line-modified">1987     __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-modified">1988 </span>



1989     if (is_oop) {
1990       __ jmp(L_exit);
1991     }
1992     restore_arg_regs_using_thread();
1993     inc_counter_np(SharedRuntime::_jint_array_copy_ctr); // Update counter after rscratch1 is free
1994     __ xorptr(rax, rax); // return 0
1995     __ vzeroupper();
1996     __ leave(); // required for proper stackwalking of RuntimeStub frame
1997     __ ret(0);
1998 
<span class="line-modified">1999     // Copy in multi-bytes chunks</span>
<span class="line-modified">2000     copy_bytes_backward(from, to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>




2001 
2002   __ BIND(L_exit);
2003     bs-&gt;arraycopy_epilogue(_masm, decorators, type, from, to, dword_count);
2004     restore_arg_regs_using_thread();
2005     inc_counter_np(SharedRuntime::_jint_array_copy_ctr); // Update counter after rscratch1 is free
2006     __ xorptr(rax, rax); // return 0
2007     __ vzeroupper();
2008     __ leave(); // required for proper stackwalking of RuntimeStub frame
2009     __ ret(0);
2010 
2011     return start;
2012   }
2013 
2014   // Arguments:
2015   //   aligned - true =&gt; Input and output aligned on a HeapWord boundary == 8 bytes
2016   //             ignored
2017   //   is_oop  - true =&gt; oop array, so generate store check code
2018   //   name    - stub name string
2019   //
2020   // Inputs:
</pre>
<hr />
<pre>
2050       *entry = __ pc();
2051       // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
2052       BLOCK_COMMENT(&quot;Entry:&quot;);
2053     }
2054 
2055     setup_arg_regs_using_thread(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
2056                                      // r9 is used to save r15_thread
2057     // &#39;from&#39;, &#39;to&#39; and &#39;qword_count&#39; are now valid
2058 
2059     DecoratorSet decorators = IN_HEAP | IS_ARRAY | ARRAYCOPY_DISJOINT;
2060     if (dest_uninitialized) {
2061       decorators |= IS_DEST_UNINITIALIZED;
2062     }
2063     if (aligned) {
2064       decorators |= ARRAYCOPY_ALIGNED;
2065     }
2066 
2067     BasicType type = is_oop ? T_OBJECT : T_LONG;
2068     BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
2069     bs-&gt;arraycopy_prologue(_masm, decorators, type, from, to, qword_count);
<span class="line-modified">2070 </span>
<span class="line-modified">2071     // Copy from low to high addresses.  Use &#39;to&#39; as scratch.</span>
<span class="line-modified">2072     __ lea(end_from, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-modified">2073     __ lea(end_to,   Address(to,   qword_count, Address::times_8, -8));</span>
<span class="line-modified">2074     __ negptr(qword_count);</span>
<span class="line-modified">2075     __ jmp(L_copy_bytes);</span>
<span class="line-modified">2076 </span>
<span class="line-modified">2077     // Copy trailing qwords</span>
<span class="line-modified">2078   __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">2079     __ movq(rax, Address(end_from, qword_count, Address::times_8, 8));</span>
<span class="line-modified">2080     __ movq(Address(end_to, qword_count, Address::times_8, 8), rax);</span>
<span class="line-modified">2081     __ increment(qword_count);</span>
<span class="line-modified">2082     __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-modified">2083 </span>



2084     if (is_oop) {
2085       __ jmp(L_exit);
2086     } else {
2087       restore_arg_regs_using_thread();
2088       inc_counter_np(SharedRuntime::_jlong_array_copy_ctr); // Update counter after rscratch1 is free
2089       __ xorptr(rax, rax); // return 0
2090       __ vzeroupper();
2091       __ leave(); // required for proper stackwalking of RuntimeStub frame
2092       __ ret(0);
2093     }
2094 
<span class="line-modified">2095     // Copy in multi-bytes chunks</span>
<span class="line-modified">2096     copy_bytes_forward(end_from, end_to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>




2097 
2098     __ BIND(L_exit);
2099     bs-&gt;arraycopy_epilogue(_masm, decorators, type, from, to, qword_count);
2100     restore_arg_regs_using_thread();
2101     if (is_oop) {
2102       inc_counter_np(SharedRuntime::_oop_array_copy_ctr); // Update counter after rscratch1 is free
2103     } else {
2104       inc_counter_np(SharedRuntime::_jlong_array_copy_ctr); // Update counter after rscratch1 is free
2105     }
2106     __ vzeroupper();
2107     __ xorptr(rax, rax); // return 0
2108     __ leave(); // required for proper stackwalking of RuntimeStub frame
2109     __ ret(0);
2110 
2111     return start;
2112   }
2113 
2114   // Arguments:
2115   //   aligned - true =&gt; Input and output aligned on a HeapWord boundary == 8 bytes
2116   //             ignored
</pre>
<hr />
<pre>
2132     Label L_copy_bytes, L_copy_8_bytes, L_exit;
2133     const Register from        = rdi;  // source array address
2134     const Register to          = rsi;  // destination array address
2135     const Register qword_count = rdx;  // elements count
2136     const Register saved_count = rcx;
2137 
2138     __ enter(); // required for proper stackwalking of RuntimeStub frame
2139     assert_clean_int(c_rarg2, rax);    // Make sure &#39;count&#39; is clean int.
2140 
2141     if (entry != NULL) {
2142       *entry = __ pc();
2143       // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
2144       BLOCK_COMMENT(&quot;Entry:&quot;);
2145     }
2146 
2147     array_overlap_test(nooverlap_target, Address::times_8);
2148     setup_arg_regs_using_thread(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
2149                                    // r9 is used to save r15_thread
2150     // &#39;from&#39;, &#39;to&#39; and &#39;qword_count&#39; are now valid
2151 
<span class="line-modified">2152     DecoratorSet decorators = IN_HEAP | IS_ARRAY | ARRAYCOPY_DISJOINT;</span>
2153     if (dest_uninitialized) {
2154       decorators |= IS_DEST_UNINITIALIZED;
2155     }
2156     if (aligned) {
2157       decorators |= ARRAYCOPY_ALIGNED;
2158     }
2159 
2160     BasicType type = is_oop ? T_OBJECT : T_LONG;
2161     BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
2162     bs-&gt;arraycopy_prologue(_masm, decorators, type, from, to, qword_count);



2163 
<span class="line-modified">2164     __ jmp(L_copy_bytes);</span>
<span class="line-removed">2165 </span>
<span class="line-removed">2166     // Copy trailing qwords</span>
<span class="line-removed">2167   __ BIND(L_copy_8_bytes);</span>
<span class="line-removed">2168     __ movq(rax, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-removed">2169     __ movq(Address(to, qword_count, Address::times_8, -8), rax);</span>
<span class="line-removed">2170     __ decrement(qword_count);</span>
<span class="line-removed">2171     __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
2172 







2173     if (is_oop) {
2174       __ jmp(L_exit);
2175     } else {
2176       restore_arg_regs_using_thread();
2177       inc_counter_np(SharedRuntime::_jlong_array_copy_ctr); // Update counter after rscratch1 is free
2178       __ xorptr(rax, rax); // return 0
2179       __ vzeroupper();
2180       __ leave(); // required for proper stackwalking of RuntimeStub frame
2181       __ ret(0);
2182     }



2183 
<span class="line-modified">2184     // Copy in multi-bytes chunks</span>
<span class="line-modified">2185     copy_bytes_backward(from, to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>
<span class="line-modified">2186 </span>
2187     __ BIND(L_exit);
2188     bs-&gt;arraycopy_epilogue(_masm, decorators, type, from, to, qword_count);
2189     restore_arg_regs_using_thread();
2190     if (is_oop) {
2191       inc_counter_np(SharedRuntime::_oop_array_copy_ctr); // Update counter after rscratch1 is free
2192     } else {
2193       inc_counter_np(SharedRuntime::_jlong_array_copy_ctr); // Update counter after rscratch1 is free
2194     }
2195     __ vzeroupper();
2196     __ xorptr(rax, rax); // return 0
2197     __ leave(); // required for proper stackwalking of RuntimeStub frame
2198     __ ret(0);
2199 
2200     return start;
2201   }
2202 
2203 
2204   // Helper for generating a dynamic type check.
2205   // Smashes no registers.
2206   void generate_type_check(Register sub_klass,
</pre>
<hr />
<pre>
2326 #ifdef ASSERT
2327     BLOCK_COMMENT(&quot;assert consistent ckoff/ckval&quot;);
2328     // The ckoff and ckval must be mutually consistent,
2329     // even though caller generates both.
2330     { Label L;
2331       int sco_offset = in_bytes(Klass::super_check_offset_offset());
2332       __ cmpl(ckoff, Address(ckval, sco_offset));
2333       __ jcc(Assembler::equal, L);
2334       __ stop(&quot;super_check_offset inconsistent&quot;);
2335       __ bind(L);
2336     }
2337 #endif //ASSERT
2338 
2339     // Loop-invariant addresses.  They are exclusive end pointers.
2340     Address end_from_addr(from, length, TIMES_OOP, 0);
2341     Address   end_to_addr(to,   length, TIMES_OOP, 0);
2342     // Loop-variant addresses.  They assume post-incremented count &lt; 0.
2343     Address from_element_addr(end_from, count, TIMES_OOP, 0);
2344     Address   to_element_addr(end_to,   count, TIMES_OOP, 0);
2345 
<span class="line-modified">2346     DecoratorSet decorators = IN_HEAP | IS_ARRAY | ARRAYCOPY_CHECKCAST;</span>
2347     if (dest_uninitialized) {
2348       decorators |= IS_DEST_UNINITIALIZED;
2349     }
2350 
2351     BasicType type = T_OBJECT;
2352     BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
2353     bs-&gt;arraycopy_prologue(_masm, decorators, type, from, to, count);
2354 
2355     // Copy from low to high addresses, indexed from the end of each array.
2356     __ lea(end_from, end_from_addr);
2357     __ lea(end_to,   end_to_addr);
2358     __ movptr(r14_length, length);        // save a copy of the length
2359     assert(length == count, &quot;&quot;);          // else fix next line:
2360     __ negptr(count);                     // negate and test the length
2361     __ jcc(Assembler::notZero, L_load_element);
2362 
2363     // Empty array:  Nothing to do.
2364     __ xorptr(rax, rax);                  // return 0 on (trivial) success
2365     __ jmp(L_done);
2366 
</pre>
<hr />
<pre>
2806       __ movl(  sco_temp,      Address(r11_dst_klass, sco_offset));
2807       assert_clean_int(sco_temp, rax);
2808 
2809       // the checkcast_copy loop needs two extra arguments:
2810       assert(c_rarg3 == sco_temp, &quot;#3 already in place&quot;);
2811       // Set up arguments for checkcast_copy_entry.
2812       setup_arg_regs(4);
2813       __ movptr(r8, r11_dst_klass);  // dst.klass.element_klass, r8 is c_rarg4 on Linux/Solaris
2814       __ jump(RuntimeAddress(checkcast_copy_entry));
2815     }
2816 
2817   __ BIND(L_failed);
2818     __ xorptr(rax, rax);
2819     __ notptr(rax); // return -1
2820     __ leave();   // required for proper stackwalking of RuntimeStub frame
2821     __ ret(0);
2822 
2823     return start;
2824   }
2825 







































2826   void generate_arraycopy_stubs() {
2827     address entry;
2828     address entry_jbyte_arraycopy;
2829     address entry_jshort_arraycopy;
2830     address entry_jint_arraycopy;
2831     address entry_oop_arraycopy;
2832     address entry_jlong_arraycopy;
2833     address entry_checkcast_arraycopy;
2834 
2835     StubRoutines::_jbyte_disjoint_arraycopy  = generate_disjoint_byte_copy(false, &amp;entry,
2836                                                                            &quot;jbyte_disjoint_arraycopy&quot;);
2837     StubRoutines::_jbyte_arraycopy           = generate_conjoint_byte_copy(false, entry, &amp;entry_jbyte_arraycopy,
2838                                                                            &quot;jbyte_arraycopy&quot;);
2839 
2840     StubRoutines::_jshort_disjoint_arraycopy = generate_disjoint_short_copy(false, &amp;entry,
2841                                                                             &quot;jshort_disjoint_arraycopy&quot;);
2842     StubRoutines::_jshort_arraycopy          = generate_conjoint_short_copy(false, entry, &amp;entry_jshort_arraycopy,
2843                                                                             &quot;jshort_arraycopy&quot;);
2844 
2845     StubRoutines::_jint_disjoint_arraycopy   = generate_disjoint_int_oop_copy(false, false, &amp;entry,
</pre>
<hr />
<pre>
3582       __ subptr(len_reg, AESBlockSize);
3583       __ jcc(Assembler::notEqual, L_singleBlock_loopTop[k]);
3584       if (k != 2) {
3585         __ jmp(L_exit);
3586       }
3587     } //for 128/192/256
3588 
3589     __ BIND(L_exit);
3590     __ movdqu(Address(rvec, 0), xmm_prev_block_cipher);     // final value of r stored in rvec of CipherBlockChaining object
3591     __ pop(rbx);
3592 #ifdef _WIN64
3593     __ movl(rax, len_mem);
3594 #else
3595     __ pop(rax); // return length
3596 #endif
3597     __ leave(); // required for proper stackwalking of RuntimeStub frame
3598     __ ret(0);
3599     return start;
3600 }
3601 






























3602   address generate_upper_word_mask() {
3603     __ align(64);
3604     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;upper_word_mask&quot;);
3605     address start = __ pc();
3606     __ emit_data64(0x0000000000000000, relocInfo::none);
3607     __ emit_data64(0xFFFFFFFF00000000, relocInfo::none);
3608     return start;
3609   }
3610 
3611   address generate_shuffle_byte_flip_mask() {
3612     __ align(64);
3613     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;shuffle_byte_flip_mask&quot;);
3614     address start = __ pc();
3615     __ emit_data64(0x08090a0b0c0d0e0f, relocInfo::none);
3616     __ emit_data64(0x0001020304050607, relocInfo::none);
3617     return start;
3618   }
3619 
3620   // ofs and limit are use for multi-block byte array.
3621   // int com.sun.security.provider.DigestBase.implCompressMultiBlock(byte[] b, int ofs, int limit)
</pre>
<hr />
<pre>
3757     const XMMRegister state1 = xmm2;
3758     const XMMRegister msgtmp0 = xmm3;
3759     const XMMRegister msgtmp1 = xmm4;
3760     const XMMRegister msgtmp2 = xmm5;
3761     const XMMRegister msgtmp3 = xmm6;
3762     const XMMRegister msgtmp4 = xmm7;
3763 
3764     const XMMRegister shuf_mask = xmm8;
3765 
3766     __ enter();
3767 
3768     __ sha512_AVX2(msg, state0, state1, msgtmp0, msgtmp1, msgtmp2, msgtmp3, msgtmp4,
3769     buf, state, ofs, limit, rsp, multi_block, shuf_mask);
3770 
3771     __ vzeroupper();
3772     __ leave();
3773     __ ret(0);
3774     return start;
3775   }
3776 





















































































































3777   // This is a version of CTR/AES crypt which does 6 blocks in a loop at a time
3778   // to hide instruction latency
3779   //
3780   // Arguments:
3781   //
3782   // Inputs:
3783   //   c_rarg0   - source byte array address
3784   //   c_rarg1   - destination byte array address
3785   //   c_rarg2   - K (key) in little endian int array
3786   //   c_rarg3   - counter vector byte array address
3787   //   Linux
3788   //     c_rarg4   -          input length
3789   //     c_rarg5   -          saved encryptedCounter start
3790   //     rbp + 6 * wordSize - saved used length
3791   //   Windows
3792   //     rbp + 6 * wordSize - input length
3793   //     rbp + 7 * wordSize - saved encryptedCounter start
3794   //     rbp + 8 * wordSize - saved used length
3795   //
3796   // Output:
</pre>
<hr />
<pre>
5348     __ enter(); // required for proper stackwalking of RuntimeStub frame
5349 
5350     setup_arg_regs(4); // out =&gt; rdi, in =&gt; rsi, offset =&gt; rdx
5351                        // len =&gt; rcx, k =&gt; r8
5352                        // r9 and r10 may be used to save non-volatile registers
5353 #ifdef _WIN64
5354     // last argument is on stack on Win64
5355     __ movl(k, Address(rsp, 6 * wordSize));
5356 #endif
5357     __ movptr(r11, rdx);  // move offset in rdx to offset(r11)
5358     __ mul_add(out, in, offset, len, k, tmp1, tmp2, tmp3, tmp4, tmp5, rdx, rax);
5359 
5360     restore_arg_regs();
5361 
5362     __ leave(); // required for proper stackwalking of RuntimeStub frame
5363     __ ret(0);
5364 
5365     return start;
5366   }
5367 

















































































































































































































































5368   address generate_libmExp() {
5369     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;libmExp&quot;);
5370 
5371     address start = __ pc();
5372 
5373     const XMMRegister x0  = xmm0;
5374     const XMMRegister x1  = xmm1;
5375     const XMMRegister x2  = xmm2;
5376     const XMMRegister x3  = xmm3;
5377 
5378     const XMMRegister x4  = xmm4;
5379     const XMMRegister x5  = xmm5;
5380     const XMMRegister x6  = xmm6;
5381     const XMMRegister x7  = xmm7;
5382 
5383     const Register tmp   = r11;
5384 
5385     BLOCK_COMMENT(&quot;Entry:&quot;);
5386     __ enter(); // required for proper stackwalking of RuntimeStub frame
5387 
</pre>
<hr />
<pre>
5754 
5755     // is referenced by megamorphic call
5756     StubRoutines::_catch_exception_entry = generate_catch_exception();
5757 
5758     // atomic calls
5759     StubRoutines::_atomic_xchg_entry          = generate_atomic_xchg();
5760     StubRoutines::_atomic_xchg_long_entry     = generate_atomic_xchg_long();
5761     StubRoutines::_atomic_cmpxchg_entry       = generate_atomic_cmpxchg();
5762     StubRoutines::_atomic_cmpxchg_byte_entry  = generate_atomic_cmpxchg_byte();
5763     StubRoutines::_atomic_cmpxchg_long_entry  = generate_atomic_cmpxchg_long();
5764     StubRoutines::_atomic_add_entry           = generate_atomic_add();
5765     StubRoutines::_atomic_add_long_entry      = generate_atomic_add_long();
5766     StubRoutines::_fence_entry                = generate_orderaccess_fence();
5767 
5768     // platform dependent
5769     StubRoutines::x86::_get_previous_fp_entry = generate_get_previous_fp();
5770     StubRoutines::x86::_get_previous_sp_entry = generate_get_previous_sp();
5771 
5772     StubRoutines::x86::_verify_mxcsr_entry    = generate_verify_mxcsr();
5773 










5774     // Build this early so it&#39;s available for the interpreter.
5775     StubRoutines::_throw_StackOverflowError_entry =
5776       generate_throw_exception(&quot;StackOverflowError throw_exception&quot;,
5777                                CAST_FROM_FN_PTR(address,
5778                                                 SharedRuntime::
5779                                                 throw_StackOverflowError));
5780     StubRoutines::_throw_delayed_StackOverflowError_entry =
5781       generate_throw_exception(&quot;delayed StackOverflowError throw_exception&quot;,
5782                                CAST_FROM_FN_PTR(address,
5783                                                 SharedRuntime::
5784                                                 throw_delayed_StackOverflowError));
5785     if (UseCRC32Intrinsics) {
5786       // set table address before stub generation which use it
5787       StubRoutines::_crc_table_adr = (address)StubRoutines::x86::_crc_table;
5788       StubRoutines::_updateBytesCRC32 = generate_updateBytesCRC32();
5789     }
5790 
5791     if (UseCRC32CIntrinsics) {
5792       bool supports_clmul = VM_Version::supports_clmul();
5793       StubRoutines::x86::generate_CRC32C_table(supports_clmul);
5794       StubRoutines::_crc32c_table_addr = (address)StubRoutines::x86::_crc32c_table;
5795       StubRoutines::_updateBytesCRC32C = generate_updateBytesCRC32C(supports_clmul);
5796     }
<span class="line-modified">5797     if (VM_Version::supports_sse2() &amp;&amp; UseLibmIntrinsic &amp;&amp; InlineIntrinsics) {</span>
5798       if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dsin) ||
5799           vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dcos) ||
5800           vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dtan)) {
5801         StubRoutines::x86::_ONEHALF_adr = (address)StubRoutines::x86::_ONEHALF;
5802         StubRoutines::x86::_P_2_adr = (address)StubRoutines::x86::_P_2;
5803         StubRoutines::x86::_SC_4_adr = (address)StubRoutines::x86::_SC_4;
5804         StubRoutines::x86::_Ctable_adr = (address)StubRoutines::x86::_Ctable;
5805         StubRoutines::x86::_SC_2_adr = (address)StubRoutines::x86::_SC_2;
5806         StubRoutines::x86::_SC_3_adr = (address)StubRoutines::x86::_SC_3;
5807         StubRoutines::x86::_SC_1_adr = (address)StubRoutines::x86::_SC_1;
5808         StubRoutines::x86::_PI_INV_TABLE_adr = (address)StubRoutines::x86::_PI_INV_TABLE;
5809         StubRoutines::x86::_PI_4_adr = (address)StubRoutines::x86::_PI_4;
5810         StubRoutines::x86::_PI32INV_adr = (address)StubRoutines::x86::_PI32INV;
5811         StubRoutines::x86::_SIGN_MASK_adr = (address)StubRoutines::x86::_SIGN_MASK;
5812         StubRoutines::x86::_P_1_adr = (address)StubRoutines::x86::_P_1;
5813         StubRoutines::x86::_P_3_adr = (address)StubRoutines::x86::_P_3;
5814         StubRoutines::x86::_NEG_ZERO_adr = (address)StubRoutines::x86::_NEG_ZERO;
5815       }
5816       if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dexp)) {
5817         StubRoutines::_dexp = generate_libmExp();
</pre>
<hr />
<pre>
5845     // fabricate a RuntimeStub internally.
5846     StubRoutines::_throw_AbstractMethodError_entry =
5847       generate_throw_exception(&quot;AbstractMethodError throw_exception&quot;,
5848                                CAST_FROM_FN_PTR(address,
5849                                                 SharedRuntime::
5850                                                 throw_AbstractMethodError));
5851 
5852     StubRoutines::_throw_IncompatibleClassChangeError_entry =
5853       generate_throw_exception(&quot;IncompatibleClassChangeError throw_exception&quot;,
5854                                CAST_FROM_FN_PTR(address,
5855                                                 SharedRuntime::
5856                                                 throw_IncompatibleClassChangeError));
5857 
5858     StubRoutines::_throw_NullPointerException_at_call_entry =
5859       generate_throw_exception(&quot;NullPointerException at call throw_exception&quot;,
5860                                CAST_FROM_FN_PTR(address,
5861                                                 SharedRuntime::
5862                                                 throw_NullPointerException_at_call));
5863 
5864     // entry points that are platform specific
<span class="line-modified">5865     StubRoutines::x86::_f2i_fixup = generate_f2i_fixup();</span>
<span class="line-modified">5866     StubRoutines::x86::_f2l_fixup = generate_f2l_fixup();</span>
<span class="line-modified">5867     StubRoutines::x86::_d2i_fixup = generate_d2i_fixup();</span>
<span class="line-modified">5868     StubRoutines::x86::_d2l_fixup = generate_d2l_fixup();</span>
<span class="line-modified">5869 </span>
<span class="line-modified">5870     StubRoutines::x86::_float_sign_mask  = generate_fp_mask(&quot;float_sign_mask&quot;,  0x7FFFFFFF7FFFFFFF);</span>
<span class="line-modified">5871     StubRoutines::x86::_float_sign_flip  = generate_fp_mask(&quot;float_sign_flip&quot;,  0x8000000080000000);</span>
<span class="line-removed">5872     StubRoutines::x86::_double_sign_mask = generate_fp_mask(&quot;double_sign_mask&quot;, 0x7FFFFFFFFFFFFFFF);</span>
<span class="line-removed">5873     StubRoutines::x86::_double_sign_flip = generate_fp_mask(&quot;double_sign_flip&quot;, 0x8000000000000000);</span>
5874 
5875     // support for verify_oop (must happen after universe_init)
5876     StubRoutines::_verify_oop_subroutine_entry = generate_verify_oop();
5877 




5878     // arraycopy stubs used by compilers
5879     generate_arraycopy_stubs();
5880 
5881     // don&#39;t bother generating these AES intrinsic stubs unless global flag is set
5882     if (UseAESIntrinsics) {
5883       StubRoutines::x86::_key_shuffle_mask_addr = generate_key_shuffle_mask();  // needed by the others
5884       StubRoutines::_aescrypt_encryptBlock = generate_aescrypt_encryptBlock();
5885       StubRoutines::_aescrypt_decryptBlock = generate_aescrypt_decryptBlock();
5886       StubRoutines::_cipherBlockChaining_encryptAESCrypt = generate_cipherBlockChaining_encryptAESCrypt();
5887       if (VM_Version::supports_vaes() &amp;&amp;  VM_Version::supports_avx512vl() &amp;&amp; VM_Version::supports_avx512dq() ) {
5888         StubRoutines::_cipherBlockChaining_decryptAESCrypt = generate_cipherBlockChaining_decryptVectorAESCrypt();


5889       } else {
5890         StubRoutines::_cipherBlockChaining_decryptAESCrypt = generate_cipherBlockChaining_decryptAESCrypt_Parallel();
5891       }
5892     }
<span class="line-modified">5893     if (UseAESCTRIntrinsics){</span>
<span class="line-modified">5894       StubRoutines::x86::_counter_shuffle_mask_addr = generate_counter_shuffle_mask();</span>
<span class="line-modified">5895       StubRoutines::_counterMode_AESCrypt = generate_counterMode_AESCrypt_Parallel();</span>





5896     }
5897 
5898     if (UseSHA1Intrinsics) {
5899       StubRoutines::x86::_upper_word_mask_addr = generate_upper_word_mask();
5900       StubRoutines::x86::_shuffle_byte_flip_mask_addr = generate_shuffle_byte_flip_mask();
5901       StubRoutines::_sha1_implCompress = generate_sha1_implCompress(false, &quot;sha1_implCompress&quot;);
5902       StubRoutines::_sha1_implCompressMB = generate_sha1_implCompress(true, &quot;sha1_implCompressMB&quot;);
5903     }
5904     if (UseSHA256Intrinsics) {
5905       StubRoutines::x86::_k256_adr = (address)StubRoutines::x86::_k256;
5906       char* dst = (char*)StubRoutines::x86::_k256_W;
5907       char* src = (char*)StubRoutines::x86::_k256;
5908       for (int ii = 0; ii &lt; 16; ++ii) {
5909         memcpy(dst + 32 * ii,      src + 16 * ii, 16);
5910         memcpy(dst + 32 * ii + 16, src + 16 * ii, 16);
5911       }
5912       StubRoutines::x86::_k256_W_adr = (address)StubRoutines::x86::_k256_W;
5913       StubRoutines::x86::_pshuffle_byte_flip_mask_addr = generate_pshuffle_byte_flip_mask();
5914       StubRoutines::_sha256_implCompress = generate_sha256_implCompress(false, &quot;sha256_implCompress&quot;);
5915       StubRoutines::_sha256_implCompressMB = generate_sha256_implCompress(true, &quot;sha256_implCompressMB&quot;);
</pre>
<hr />
<pre>
5950                                                        &amp;StubRoutines::_safefetch32_fault_pc,
5951                                                        &amp;StubRoutines::_safefetch32_continuation_pc);
5952     generate_safefetch(&quot;SafeFetchN&quot;, sizeof(intptr_t), &amp;StubRoutines::_safefetchN_entry,
5953                                                        &amp;StubRoutines::_safefetchN_fault_pc,
5954                                                        &amp;StubRoutines::_safefetchN_continuation_pc);
5955 
5956     BarrierSetNMethod* bs_nm = BarrierSet::barrier_set()-&gt;barrier_set_nmethod();
5957     if (bs_nm != NULL) {
5958       StubRoutines::x86::_method_entry_barrier = generate_method_entry_barrier();
5959     }
5960 #ifdef COMPILER2
5961     if (UseMultiplyToLenIntrinsic) {
5962       StubRoutines::_multiplyToLen = generate_multiplyToLen();
5963     }
5964     if (UseSquareToLenIntrinsic) {
5965       StubRoutines::_squareToLen = generate_squareToLen();
5966     }
5967     if (UseMulAddIntrinsic) {
5968       StubRoutines::_mulAdd = generate_mulAdd();
5969     }




5970 #ifndef _WINDOWS
5971     if (UseMontgomeryMultiplyIntrinsic) {
5972       StubRoutines::_montgomeryMultiply
5973         = CAST_FROM_FN_PTR(address, SharedRuntime::montgomery_multiply);
5974     }
5975     if (UseMontgomerySquareIntrinsic) {
5976       StubRoutines::_montgomerySquare
5977         = CAST_FROM_FN_PTR(address, SharedRuntime::montgomery_square);
5978     }
5979 #endif // WINDOWS
5980 #endif // COMPILER2
5981 
5982     if (UseVectorizedMismatchIntrinsic) {
5983       StubRoutines::_vectorizedMismatch = generate_vectorizedMismatch();
5984     }
5985   }
5986 
5987  public:
5988   StubGenerator(CodeBuffer* code, bool all) : StubCodeGenerator(code) {
5989     if (all) {
5990       generate_all();
5991     } else {
5992       generate_initial();
5993     }
5994   }
5995 }; // end class declaration
5996 

5997 void StubGenerator_generate(CodeBuffer* code, bool all) {



5998   StubGenerator g(code, all);
5999 }
</pre>
</td>
<td>
<hr />
<pre>
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/macroAssembler.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;ci/ciUtilities.hpp&quot;
  29 #include &quot;gc/shared/barrierSet.hpp&quot;
  30 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  31 #include &quot;gc/shared/barrierSetNMethod.hpp&quot;
  32 #include &quot;interpreter/interpreter.hpp&quot;
<span class="line-added">  33 #include &quot;memory/universe.hpp&quot;</span>
  34 #include &quot;nativeInst_x86.hpp&quot;
  35 #include &quot;oops/instanceOop.hpp&quot;
  36 #include &quot;oops/method.hpp&quot;
  37 #include &quot;oops/objArrayKlass.hpp&quot;
  38 #include &quot;oops/oop.inline.hpp&quot;
  39 #include &quot;prims/methodHandles.hpp&quot;
  40 #include &quot;runtime/frame.inline.hpp&quot;
  41 #include &quot;runtime/handles.inline.hpp&quot;
  42 #include &quot;runtime/sharedRuntime.hpp&quot;
  43 #include &quot;runtime/stubCodeGenerator.hpp&quot;
  44 #include &quot;runtime/stubRoutines.hpp&quot;
  45 #include &quot;runtime/thread.inline.hpp&quot;
  46 #ifdef COMPILER2
  47 #include &quot;opto/runtime.hpp&quot;
  48 #endif
  49 #if INCLUDE_ZGC
  50 #include &quot;gc/z/zThreadLocalData.hpp&quot;
  51 #endif
  52 
  53 // Declaration and definition of StubGenerator (no .hpp file).
</pre>
<hr />
<pre>
 535     // make sure exception is set
 536     {
 537       Label L;
 538       __ testptr(rax, rax);
 539       __ jcc(Assembler::notEqual, L);
 540       __ stop(&quot;StubRoutines::forward exception: no pending exception (2)&quot;);
 541       __ bind(L);
 542     }
 543 #endif
 544 
 545     // continue at exception handler (return address removed)
 546     // rax: exception
 547     // rbx: exception handler
 548     // rdx: throwing pc
 549     __ verify_oop(rax);
 550     __ jmp(rbx);
 551 
 552     return start;
 553   }
 554 
<span class="line-modified"> 555   // Implementation of jint atomic_xchg(jint add_value, volatile jint* dest)</span>
<span class="line-added"> 556   // used by Atomic::xchg(volatile jint* dest, jint exchange_value)</span>
 557   //
 558   // Arguments :
 559   //    c_rarg0: exchange_value
 560   //    c_rarg0: dest
 561   //
 562   // Result:
 563   //    *dest &lt;- ex, return (orig *dest)
 564   address generate_atomic_xchg() {
 565     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;atomic_xchg&quot;);
 566     address start = __ pc();
 567 
 568     __ movl(rax, c_rarg0); // Copy to eax we need a return value anyhow
 569     __ xchgl(rax, Address(c_rarg1, 0)); // automatic LOCK
 570     __ ret(0);
 571 
 572     return start;
 573   }
 574 
<span class="line-modified"> 575   // Implementation of intptr_t atomic_xchg(jlong add_value, volatile jlong* dest)</span>
<span class="line-added"> 576   // used by Atomic::xchg(volatile jlong* dest, jlong exchange_value)</span>
 577   //
 578   // Arguments :
 579   //    c_rarg0: exchange_value
 580   //    c_rarg1: dest
 581   //
 582   // Result:
 583   //    *dest &lt;- ex, return (orig *dest)
 584   address generate_atomic_xchg_long() {
 585     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;atomic_xchg_long&quot;);
 586     address start = __ pc();
 587 
 588     __ movptr(rax, c_rarg0); // Copy to eax we need a return value anyhow
 589     __ xchgptr(rax, Address(c_rarg1, 0)); // automatic LOCK
 590     __ ret(0);
 591 
 592     return start;
 593   }
 594 
 595   // Support for jint atomic::atomic_cmpxchg(jint exchange_value, volatile jint* dest,
 596   //                                         jint compare_value)
</pre>
<hr />
<pre>
 653   //    c_rarg2: compare_value
 654   //
 655   // Result:
 656   //    if ( compare_value == *dest ) {
 657   //       *dest = exchange_value
 658   //       return compare_value;
 659   //    else
 660   //       return *dest;
 661   address generate_atomic_cmpxchg_long() {
 662     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;atomic_cmpxchg_long&quot;);
 663     address start = __ pc();
 664 
 665     __ movq(rax, c_rarg2);
 666     __ lock();
 667     __ cmpxchgq(c_rarg0, Address(c_rarg1, 0));
 668     __ ret(0);
 669 
 670     return start;
 671   }
 672 
<span class="line-modified"> 673   // Implementation of jint atomic_add(jint add_value, volatile jint* dest)</span>
<span class="line-added"> 674   // used by Atomic::add(volatile jint* dest, jint add_value)</span>
 675   //
 676   // Arguments :
 677   //    c_rarg0: add_value
 678   //    c_rarg1: dest
 679   //
 680   // Result:
 681   //    *dest += add_value
 682   //    return *dest;
 683   address generate_atomic_add() {
 684     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;atomic_add&quot;);
 685     address start = __ pc();
 686 
 687     __ movl(rax, c_rarg0);
 688     __ lock();
 689     __ xaddl(Address(c_rarg1, 0), c_rarg0);
 690     __ addl(rax, c_rarg0);
 691     __ ret(0);
 692 
 693     return start;
 694   }
 695 
<span class="line-modified"> 696   // Implementation of intptr_t atomic_add(intptr_t add_value, volatile intptr_t* dest)</span>
<span class="line-added"> 697   // used by Atomic::add(volatile intptr_t* dest, intptr_t add_value)</span>
 698   //
 699   // Arguments :
 700   //    c_rarg0: add_value
 701   //    c_rarg1: dest
 702   //
 703   // Result:
 704   //    *dest += add_value
 705   //    return *dest;
 706   address generate_atomic_add_long() {
 707     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;atomic_add_long&quot;);
 708     address start = __ pc();
 709 
 710     __ movptr(rax, c_rarg0); // Copy to eax we need a return value anyhow
 711     __ lock();
 712     __ xaddptr(Address(c_rarg1, 0), c_rarg0);
 713     __ addptr(rax, c_rarg0);
 714     __ ret(0);
 715 
 716     return start;
 717   }
</pre>
<hr />
<pre>
 967     __ pop(c_rarg2);
 968     __ pop(c_rarg3);
 969     __ pop(rax);
 970 
 971     __ ret(0);
 972 
 973     return start;
 974   }
 975 
 976   address generate_fp_mask(const char *stub_name, int64_t mask) {
 977     __ align(CodeEntryAlignment);
 978     StubCodeMark mark(this, &quot;StubRoutines&quot;, stub_name);
 979     address start = __ pc();
 980 
 981     __ emit_data64( mask, relocInfo::none );
 982     __ emit_data64( mask, relocInfo::none );
 983 
 984     return start;
 985   }
 986 
<span class="line-added"> 987   address generate_vector_mask(const char *stub_name, int64_t mask) {</span>
<span class="line-added"> 988     __ align(CodeEntryAlignment);</span>
<span class="line-added"> 989     StubCodeMark mark(this, &quot;StubRoutines&quot;, stub_name);</span>
<span class="line-added"> 990     address start = __ pc();</span>
<span class="line-added"> 991 </span>
<span class="line-added"> 992     __ emit_data64(mask, relocInfo::none);</span>
<span class="line-added"> 993     __ emit_data64(mask, relocInfo::none);</span>
<span class="line-added"> 994     __ emit_data64(mask, relocInfo::none);</span>
<span class="line-added"> 995     __ emit_data64(mask, relocInfo::none);</span>
<span class="line-added"> 996     __ emit_data64(mask, relocInfo::none);</span>
<span class="line-added"> 997     __ emit_data64(mask, relocInfo::none);</span>
<span class="line-added"> 998     __ emit_data64(mask, relocInfo::none);</span>
<span class="line-added"> 999     __ emit_data64(mask, relocInfo::none);</span>
<span class="line-added">1000 </span>
<span class="line-added">1001     return start;</span>
<span class="line-added">1002   }</span>
<span class="line-added">1003 </span>
<span class="line-added">1004   address generate_vector_byte_perm_mask(const char *stub_name) {</span>
<span class="line-added">1005     __ align(CodeEntryAlignment);</span>
<span class="line-added">1006     StubCodeMark mark(this, &quot;StubRoutines&quot;, stub_name);</span>
<span class="line-added">1007     address start = __ pc();</span>
<span class="line-added">1008 </span>
<span class="line-added">1009     __ emit_data64(0x0000000000000001, relocInfo::none);</span>
<span class="line-added">1010     __ emit_data64(0x0000000000000003, relocInfo::none);</span>
<span class="line-added">1011     __ emit_data64(0x0000000000000005, relocInfo::none);</span>
<span class="line-added">1012     __ emit_data64(0x0000000000000007, relocInfo::none);</span>
<span class="line-added">1013     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">1014     __ emit_data64(0x0000000000000002, relocInfo::none);</span>
<span class="line-added">1015     __ emit_data64(0x0000000000000004, relocInfo::none);</span>
<span class="line-added">1016     __ emit_data64(0x0000000000000006, relocInfo::none);</span>
<span class="line-added">1017 </span>
<span class="line-added">1018     return start;</span>
<span class="line-added">1019   }</span>
<span class="line-added">1020 </span>
1021   // Non-destructive plausibility checks for oops
1022   //
1023   // Arguments:
1024   //    all args on stack!
1025   //
1026   // Stack after saving c_rarg3:
1027   //    [tos + 0]: saved c_rarg3
1028   //    [tos + 1]: saved c_rarg2
1029   //    [tos + 2]: saved r12 (several TemplateTable methods use it)
1030   //    [tos + 3]: saved flags
1031   //    [tos + 4]: return address
1032   //  * [tos + 5]: error message (char*)
1033   //  * [tos + 6]: object to verify (oop)
1034   //  * [tos + 7]: saved rax - saved by caller and bashed
1035   //  * [tos + 8]: saved r10 (rscratch1) - saved by caller
1036   //  * = popped on exit
1037   address generate_verify_oop() {
1038     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;verify_oop&quot;);
1039     address start = __ pc();
1040 
</pre>
<hr />
<pre>
1116                                                  // already pushed)
1117     // debug(char* msg, int64_t pc, int64_t regs[])
1118     // We&#39;ve popped the registers we&#39;d saved (c_rarg3, c_rarg2 and flags), and
1119     // pushed all the registers, so now the stack looks like:
1120     //     [tos +  0] 16 saved registers
1121     //     [tos + 16] return address
1122     //   * [tos + 17] error message (char*)
1123     //   * [tos + 18] object to verify (oop)
1124     //   * [tos + 19] saved rax - saved by caller and bashed
1125     //   * [tos + 20] saved r10 (rscratch1) - saved by caller
1126     //   * = popped on exit
1127 
1128     __ movptr(c_rarg0, Address(rsp, error_msg));    // pass address of error message
1129     __ movptr(c_rarg1, Address(rsp, return_addr));  // pass return address
1130     __ movq(c_rarg2, rsp);                          // pass address of regs on stack
1131     __ mov(r12, rsp);                               // remember rsp
1132     __ subptr(rsp, frame::arg_reg_save_area_bytes); // windows
1133     __ andptr(rsp, -16);                            // align stack as required by ABI
1134     BLOCK_COMMENT(&quot;call MacroAssembler::debug&quot;);
1135     __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, MacroAssembler::debug64)));
<span class="line-modified">1136     __ hlt();</span>



1137     return start;
1138   }
1139 
1140   //
1141   // Verify that a register contains clean 32-bits positive value
1142   // (high 32-bits are 0) so it could be used in 64-bits shifts.
1143   //
1144   //  Input:
1145   //    Rint  -  32-bits value
1146   //    Rtmp  -  scratch
1147   //
1148   void assert_clean_int(Register Rint, Register Rtmp) {
1149 #ifdef ASSERT
1150     Label L;
1151     assert_different_registers(Rtmp, Rint);
1152     __ movslq(Rtmp, Rint);
1153     __ cmpq(Rtmp, Rint);
1154     __ jcc(Assembler::equal, L);
1155     __ stop(&quot;high 32-bits of int value are not 0&quot;);
1156     __ bind(L);
</pre>
<hr />
<pre>
1275 
1276   // Copy big chunks forward
1277   //
1278   // Inputs:
1279   //   end_from     - source arrays end address
1280   //   end_to       - destination array end address
1281   //   qword_count  - 64-bits element count, negative
1282   //   to           - scratch
1283   //   L_copy_bytes - entry label
1284   //   L_copy_8_bytes  - exit  label
1285   //
1286   void copy_bytes_forward(Register end_from, Register end_to,
1287                              Register qword_count, Register to,
1288                              Label&amp; L_copy_bytes, Label&amp; L_copy_8_bytes) {
1289     DEBUG_ONLY(__ stop(&quot;enter at entry label, not here&quot;));
1290     Label L_loop;
1291     __ align(OptoLoopAlignment);
1292     if (UseUnalignedLoadStores) {
1293       Label L_end;
1294       // Copy 64-bytes per iteration

1295       if (UseAVX &gt; 2) {
<span class="line-added">1296         Label L_loop_avx512, L_loop_avx2, L_32_byte_head, L_above_threshold, L_below_threshold;</span>
<span class="line-added">1297 </span>
<span class="line-added">1298         __ BIND(L_copy_bytes);</span>
<span class="line-added">1299         __ cmpptr(qword_count, (-1 * AVX3Threshold / 8));</span>
<span class="line-added">1300         __ jccb(Assembler::less, L_above_threshold);</span>
<span class="line-added">1301         __ jmpb(L_below_threshold);</span>
<span class="line-added">1302 </span>
<span class="line-added">1303         __ bind(L_loop_avx512);</span>
1304         __ evmovdqul(xmm0, Address(end_from, qword_count, Address::times_8, -56), Assembler::AVX_512bit);
1305         __ evmovdqul(Address(end_to, qword_count, Address::times_8, -56), xmm0, Assembler::AVX_512bit);
<span class="line-modified">1306         __ bind(L_above_threshold);</span>
<span class="line-added">1307         __ addptr(qword_count, 8);</span>
<span class="line-added">1308         __ jcc(Assembler::lessEqual, L_loop_avx512);</span>
<span class="line-added">1309         __ jmpb(L_32_byte_head);</span>
<span class="line-added">1310 </span>
<span class="line-added">1311         __ bind(L_loop_avx2);</span>
1312         __ vmovdqu(xmm0, Address(end_from, qword_count, Address::times_8, -56));
1313         __ vmovdqu(Address(end_to, qword_count, Address::times_8, -56), xmm0);
1314         __ vmovdqu(xmm1, Address(end_from, qword_count, Address::times_8, -24));
1315         __ vmovdqu(Address(end_to, qword_count, Address::times_8, -24), xmm1);
<span class="line-added">1316         __ bind(L_below_threshold);</span>
<span class="line-added">1317         __ addptr(qword_count, 8);</span>
<span class="line-added">1318         __ jcc(Assembler::lessEqual, L_loop_avx2);</span>
<span class="line-added">1319 </span>
<span class="line-added">1320         __ bind(L_32_byte_head);</span>
<span class="line-added">1321         __ subptr(qword_count, 4);  // sub(8) and add(4)</span>
<span class="line-added">1322         __ jccb(Assembler::greater, L_end);</span>
1323       } else {
<span class="line-modified">1324         __ BIND(L_loop);</span>
<span class="line-modified">1325         if (UseAVX == 2) {</span>
<span class="line-modified">1326           __ vmovdqu(xmm0, Address(end_from, qword_count, Address::times_8, -56));</span>
<span class="line-modified">1327           __ vmovdqu(Address(end_to, qword_count, Address::times_8, -56), xmm0);</span>
<span class="line-modified">1328           __ vmovdqu(xmm1, Address(end_from, qword_count, Address::times_8, -24));</span>
<span class="line-modified">1329           __ vmovdqu(Address(end_to, qword_count, Address::times_8, -24), xmm1);</span>
<span class="line-modified">1330         } else {</span>
<span class="line-modified">1331           __ movdqu(xmm0, Address(end_from, qword_count, Address::times_8, -56));</span>
<span class="line-added">1332           __ movdqu(Address(end_to, qword_count, Address::times_8, -56), xmm0);</span>
<span class="line-added">1333           __ movdqu(xmm1, Address(end_from, qword_count, Address::times_8, -40));</span>
<span class="line-added">1334           __ movdqu(Address(end_to, qword_count, Address::times_8, -40), xmm1);</span>
<span class="line-added">1335           __ movdqu(xmm2, Address(end_from, qword_count, Address::times_8, -24));</span>
<span class="line-added">1336           __ movdqu(Address(end_to, qword_count, Address::times_8, -24), xmm2);</span>
<span class="line-added">1337           __ movdqu(xmm3, Address(end_from, qword_count, Address::times_8, - 8));</span>
<span class="line-added">1338           __ movdqu(Address(end_to, qword_count, Address::times_8, - 8), xmm3);</span>
<span class="line-added">1339         }</span>
<span class="line-added">1340 </span>
<span class="line-added">1341         __ BIND(L_copy_bytes);</span>
<span class="line-added">1342         __ addptr(qword_count, 8);</span>
<span class="line-added">1343         __ jcc(Assembler::lessEqual, L_loop);</span>
<span class="line-added">1344         __ subptr(qword_count, 4);  // sub(8) and add(4)</span>
<span class="line-added">1345         __ jccb(Assembler::greater, L_end);</span>
1346       }





1347       // Copy trailing 32 bytes
1348       if (UseAVX &gt;= 2) {
1349         __ vmovdqu(xmm0, Address(end_from, qword_count, Address::times_8, -24));
1350         __ vmovdqu(Address(end_to, qword_count, Address::times_8, -24), xmm0);
1351       } else {
1352         __ movdqu(xmm0, Address(end_from, qword_count, Address::times_8, -24));
1353         __ movdqu(Address(end_to, qword_count, Address::times_8, -24), xmm0);
1354         __ movdqu(xmm1, Address(end_from, qword_count, Address::times_8, - 8));
1355         __ movdqu(Address(end_to, qword_count, Address::times_8, - 8), xmm1);
1356       }
1357       __ addptr(qword_count, 4);
1358       __ BIND(L_end);
1359       if (UseAVX &gt;= 2) {
1360         // clean upper bits of YMM registers
1361         __ vpxor(xmm0, xmm0);
1362         __ vpxor(xmm1, xmm1);
1363       }
1364     } else {
1365       // Copy 32-bytes per iteration
1366       __ BIND(L_loop);
</pre>
<hr />
<pre>
1383 
1384   // Copy big chunks backward
1385   //
1386   // Inputs:
1387   //   from         - source arrays address
1388   //   dest         - destination array address
1389   //   qword_count  - 64-bits element count
1390   //   to           - scratch
1391   //   L_copy_bytes - entry label
1392   //   L_copy_8_bytes  - exit  label
1393   //
1394   void copy_bytes_backward(Register from, Register dest,
1395                               Register qword_count, Register to,
1396                               Label&amp; L_copy_bytes, Label&amp; L_copy_8_bytes) {
1397     DEBUG_ONLY(__ stop(&quot;enter at entry label, not here&quot;));
1398     Label L_loop;
1399     __ align(OptoLoopAlignment);
1400     if (UseUnalignedLoadStores) {
1401       Label L_end;
1402       // Copy 64-bytes per iteration

1403       if (UseAVX &gt; 2) {
<span class="line-added">1404         Label L_loop_avx512, L_loop_avx2, L_32_byte_head, L_above_threshold, L_below_threshold;</span>
<span class="line-added">1405 </span>
<span class="line-added">1406         __ BIND(L_copy_bytes);</span>
<span class="line-added">1407         __ cmpptr(qword_count, (AVX3Threshold / 8));</span>
<span class="line-added">1408         __ jccb(Assembler::greater, L_above_threshold);</span>
<span class="line-added">1409         __ jmpb(L_below_threshold);</span>
<span class="line-added">1410 </span>
<span class="line-added">1411         __ BIND(L_loop_avx512);</span>
1412         __ evmovdqul(xmm0, Address(from, qword_count, Address::times_8, 0), Assembler::AVX_512bit);
1413         __ evmovdqul(Address(dest, qword_count, Address::times_8, 0), xmm0, Assembler::AVX_512bit);
<span class="line-modified">1414         __ bind(L_above_threshold);</span>
<span class="line-added">1415         __ subptr(qword_count, 8);</span>
<span class="line-added">1416         __ jcc(Assembler::greaterEqual, L_loop_avx512);</span>
<span class="line-added">1417         __ jmpb(L_32_byte_head);</span>
<span class="line-added">1418 </span>
<span class="line-added">1419         __ bind(L_loop_avx2);</span>
1420         __ vmovdqu(xmm0, Address(from, qword_count, Address::times_8, 32));
1421         __ vmovdqu(Address(dest, qword_count, Address::times_8, 32), xmm0);
<span class="line-modified">1422         __ vmovdqu(xmm1, Address(from, qword_count, Address::times_8, 0));</span>
<span class="line-modified">1423         __ vmovdqu(Address(dest, qword_count, Address::times_8, 0), xmm1);</span>
<span class="line-added">1424         __ bind(L_below_threshold);</span>
<span class="line-added">1425         __ subptr(qword_count, 8);</span>
<span class="line-added">1426         __ jcc(Assembler::greaterEqual, L_loop_avx2);</span>
<span class="line-added">1427 </span>
<span class="line-added">1428         __ bind(L_32_byte_head);</span>
<span class="line-added">1429         __ addptr(qword_count, 4);  // add(8) and sub(4)</span>
<span class="line-added">1430         __ jccb(Assembler::less, L_end);</span>
1431       } else {
<span class="line-modified">1432         __ BIND(L_loop);</span>
<span class="line-modified">1433         if (UseAVX == 2) {</span>
<span class="line-modified">1434           __ vmovdqu(xmm0, Address(from, qword_count, Address::times_8, 32));</span>
<span class="line-modified">1435           __ vmovdqu(Address(dest, qword_count, Address::times_8, 32), xmm0);</span>
<span class="line-modified">1436           __ vmovdqu(xmm1, Address(from, qword_count, Address::times_8,  0));</span>
<span class="line-modified">1437           __ vmovdqu(Address(dest, qword_count, Address::times_8,  0), xmm1);</span>
<span class="line-modified">1438         } else {</span>
<span class="line-modified">1439           __ movdqu(xmm0, Address(from, qword_count, Address::times_8, 48));</span>
<span class="line-modified">1440           __ movdqu(Address(dest, qword_count, Address::times_8, 48), xmm0);</span>
<span class="line-modified">1441           __ movdqu(xmm1, Address(from, qword_count, Address::times_8, 32));</span>
<span class="line-modified">1442           __ movdqu(Address(dest, qword_count, Address::times_8, 32), xmm1);</span>
<span class="line-modified">1443           __ movdqu(xmm2, Address(from, qword_count, Address::times_8, 16));</span>
<span class="line-added">1444           __ movdqu(Address(dest, qword_count, Address::times_8, 16), xmm2);</span>
<span class="line-added">1445           __ movdqu(xmm3, Address(from, qword_count, Address::times_8,  0));</span>
<span class="line-added">1446           __ movdqu(Address(dest, qword_count, Address::times_8,  0), xmm3);</span>
<span class="line-added">1447         }</span>
1448 
<span class="line-modified">1449         __ BIND(L_copy_bytes);</span>
<span class="line-modified">1450         __ subptr(qword_count, 8);</span>
<span class="line-added">1451         __ jcc(Assembler::greaterEqual, L_loop);</span>
<span class="line-added">1452 </span>
<span class="line-added">1453         __ addptr(qword_count, 4);  // add(8) and sub(4)</span>
<span class="line-added">1454         __ jccb(Assembler::less, L_end);</span>
<span class="line-added">1455       }</span>
1456       // Copy trailing 32 bytes
1457       if (UseAVX &gt;= 2) {
1458         __ vmovdqu(xmm0, Address(from, qword_count, Address::times_8, 0));
1459         __ vmovdqu(Address(dest, qword_count, Address::times_8, 0), xmm0);
1460       } else {
1461         __ movdqu(xmm0, Address(from, qword_count, Address::times_8, 16));
1462         __ movdqu(Address(dest, qword_count, Address::times_8, 16), xmm0);
1463         __ movdqu(xmm1, Address(from, qword_count, Address::times_8,  0));
1464         __ movdqu(Address(dest, qword_count, Address::times_8,  0), xmm1);
1465       }
1466       __ subptr(qword_count, 4);
1467       __ BIND(L_end);
1468       if (UseAVX &gt;= 2) {
1469         // clean upper bits of YMM registers
1470         __ vpxor(xmm0, xmm0);
1471         __ vpxor(xmm1, xmm1);
1472       }
1473     } else {
1474       // Copy 32-bytes per iteration
1475       __ BIND(L_loop);
1476       __ movq(to, Address(from, qword_count, Address::times_8, 24));
1477       __ movq(Address(dest, qword_count, Address::times_8, 24), to);
1478       __ movq(to, Address(from, qword_count, Address::times_8, 16));
1479       __ movq(Address(dest, qword_count, Address::times_8, 16), to);
1480       __ movq(to, Address(from, qword_count, Address::times_8,  8));
1481       __ movq(Address(dest, qword_count, Address::times_8,  8), to);
1482       __ movq(to, Address(from, qword_count, Address::times_8,  0));
1483       __ movq(Address(dest, qword_count, Address::times_8,  0), to);
1484 
1485       __ BIND(L_copy_bytes);
1486       __ subptr(qword_count, 4);
1487       __ jcc(Assembler::greaterEqual, L_loop);
1488     }
1489     __ addptr(qword_count, 4);
1490     __ jcc(Assembler::greater, L_copy_8_bytes); // Copy trailing qwords
1491   }
1492 

1493   // Arguments:
1494   //   aligned - true =&gt; Input and output aligned on a HeapWord == 8-byte boundary
1495   //             ignored
1496   //   name    - stub name string
1497   //
1498   // Inputs:
1499   //   c_rarg0   - source array address
1500   //   c_rarg1   - destination array address
1501   //   c_rarg2   - element count, treated as ssize_t, can be zero
1502   //
1503   // If &#39;from&#39; and/or &#39;to&#39; are aligned on 4-, 2-, or 1-byte boundaries,
1504   // we let the hardware handle it.  The one to eight bytes within words,
1505   // dwords or qwords that span cache line boundaries will still be loaded
1506   // and stored atomically.
1507   //
1508   // Side Effects:
1509   //   disjoint_byte_copy_entry is set to the no-overlap entry point
1510   //   used by generate_conjoint_byte_copy().
1511   //
1512   address generate_disjoint_byte_copy(bool aligned, address* entry, const char *name) {
</pre>
<hr />
<pre>
1521     const Register count       = rdx;  // elements count
1522     const Register byte_count  = rcx;
1523     const Register qword_count = count;
1524     const Register end_from    = from; // source array end address
1525     const Register end_to      = to;   // destination array end address
1526     // End pointers are inclusive, and if count is not zero they point
1527     // to the last unit copied:  end_to[0] := end_from[0]
1528 
1529     __ enter(); // required for proper stackwalking of RuntimeStub frame
1530     assert_clean_int(c_rarg2, rax);    // Make sure &#39;count&#39; is clean int.
1531 
1532     if (entry != NULL) {
1533       *entry = __ pc();
1534        // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
1535       BLOCK_COMMENT(&quot;Entry:&quot;);
1536     }
1537 
1538     setup_arg_regs(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
1539                       // r9 and r10 may be used to save non-volatile registers
1540 
<span class="line-modified">1541     {</span>
<span class="line-modified">1542       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-modified">1543       UnsafeCopyMemoryMark ucmm(this, !aligned, true);</span>
<span class="line-modified">1544       // &#39;from&#39;, &#39;to&#39; and &#39;count&#39; are now valid</span>
<span class="line-modified">1545       __ movptr(byte_count, count);</span>
<span class="line-modified">1546       __ shrptr(count, 3); // count =&gt; qword_count</span>
<span class="line-modified">1547 </span>
<span class="line-modified">1548       // Copy from low to high addresses.  Use &#39;to&#39; as scratch.</span>
<span class="line-modified">1549       __ lea(end_from, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-modified">1550       __ lea(end_to,   Address(to,   qword_count, Address::times_8, -8));</span>
<span class="line-modified">1551       __ negptr(qword_count); // make the count negative</span>
<span class="line-modified">1552       __ jmp(L_copy_bytes);</span>
<span class="line-modified">1553 </span>
<span class="line-modified">1554       // Copy trailing qwords</span>
<span class="line-modified">1555     __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">1556       __ movq(rax, Address(end_from, qword_count, Address::times_8, 8));</span>
<span class="line-modified">1557       __ movq(Address(end_to, qword_count, Address::times_8, 8), rax);</span>
<span class="line-modified">1558       __ increment(qword_count);</span>
<span class="line-modified">1559       __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-modified">1560 </span>
<span class="line-modified">1561       // Check for and copy trailing dword</span>
<span class="line-modified">1562     __ BIND(L_copy_4_bytes);</span>
<span class="line-modified">1563       __ testl(byte_count, 4);</span>
<span class="line-modified">1564       __ jccb(Assembler::zero, L_copy_2_bytes);</span>
<span class="line-modified">1565       __ movl(rax, Address(end_from, 8));</span>
<span class="line-modified">1566       __ movl(Address(end_to, 8), rax);</span>
<span class="line-modified">1567 </span>
<span class="line-modified">1568       __ addptr(end_from, 4);</span>
<span class="line-modified">1569       __ addptr(end_to, 4);</span>
<span class="line-modified">1570 </span>
<span class="line-modified">1571       // Check for and copy trailing word</span>
<span class="line-modified">1572     __ BIND(L_copy_2_bytes);</span>
<span class="line-modified">1573       __ testl(byte_count, 2);</span>
<span class="line-modified">1574       __ jccb(Assembler::zero, L_copy_byte);</span>
<span class="line-modified">1575       __ movw(rax, Address(end_from, 8));</span>
<span class="line-modified">1576       __ movw(Address(end_to, 8), rax);</span>
<span class="line-modified">1577 </span>
<span class="line-modified">1578       __ addptr(end_from, 2);</span>
<span class="line-modified">1579       __ addptr(end_to, 2);</span>
<span class="line-modified">1580 </span>
<span class="line-modified">1581       // Check for and copy trailing byte</span>
<span class="line-modified">1582     __ BIND(L_copy_byte);</span>
<span class="line-modified">1583       __ testl(byte_count, 1);</span>
<span class="line-modified">1584       __ jccb(Assembler::zero, L_exit);</span>
<span class="line-added">1585       __ movb(rax, Address(end_from, 8));</span>
<span class="line-added">1586       __ movb(Address(end_to, 8), rax);</span>
<span class="line-added">1587     }</span>
1588   __ BIND(L_exit);
<span class="line-added">1589     address ucme_exit_pc = __ pc();</span>
1590     restore_arg_regs();
1591     inc_counter_np(SharedRuntime::_jbyte_array_copy_ctr); // Update counter after rscratch1 is free
1592     __ xorptr(rax, rax); // return 0
1593     __ vzeroupper();
1594     __ leave(); // required for proper stackwalking of RuntimeStub frame
1595     __ ret(0);
1596 
<span class="line-modified">1597     {</span>
<span class="line-modified">1598       UnsafeCopyMemoryMark ucmm(this, !aligned, false, ucme_exit_pc);</span>
<span class="line-modified">1599       // Copy in multi-bytes chunks</span>
<span class="line-modified">1600       copy_bytes_forward(end_from, end_to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>
<span class="line-added">1601       __ jmp(L_copy_4_bytes);</span>
<span class="line-added">1602     }</span>
1603     return start;
1604   }
1605 
1606   // Arguments:
1607   //   aligned - true =&gt; Input and output aligned on a HeapWord == 8-byte boundary
1608   //             ignored
1609   //   name    - stub name string
1610   //
1611   // Inputs:
1612   //   c_rarg0   - source array address
1613   //   c_rarg1   - destination array address
1614   //   c_rarg2   - element count, treated as ssize_t, can be zero
1615   //
1616   // If &#39;from&#39; and/or &#39;to&#39; are aligned on 4-, 2-, or 1-byte boundaries,
1617   // we let the hardware handle it.  The one to eight bytes within words,
1618   // dwords or qwords that span cache line boundaries will still be loaded
1619   // and stored atomically.
1620   //
1621   address generate_conjoint_byte_copy(bool aligned, address nooverlap_target,
1622                                       address* entry, const char *name) {
</pre>
<hr />
<pre>
1627     Label L_copy_bytes, L_copy_8_bytes, L_copy_4_bytes, L_copy_2_bytes;
1628     const Register from        = rdi;  // source array address
1629     const Register to          = rsi;  // destination array address
1630     const Register count       = rdx;  // elements count
1631     const Register byte_count  = rcx;
1632     const Register qword_count = count;
1633 
1634     __ enter(); // required for proper stackwalking of RuntimeStub frame
1635     assert_clean_int(c_rarg2, rax);    // Make sure &#39;count&#39; is clean int.
1636 
1637     if (entry != NULL) {
1638       *entry = __ pc();
1639       // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
1640       BLOCK_COMMENT(&quot;Entry:&quot;);
1641     }
1642 
1643     array_overlap_test(nooverlap_target, Address::times_1);
1644     setup_arg_regs(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
1645                       // r9 and r10 may be used to save non-volatile registers
1646 
<span class="line-modified">1647     {</span>
<span class="line-modified">1648       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-modified">1649       UnsafeCopyMemoryMark ucmm(this, !aligned, true);</span>
<span class="line-modified">1650       // &#39;from&#39;, &#39;to&#39; and &#39;count&#39; are now valid</span>
<span class="line-modified">1651       __ movptr(byte_count, count);</span>
<span class="line-modified">1652       __ shrptr(count, 3);   // count =&gt; qword_count</span>
<span class="line-modified">1653 </span>
<span class="line-modified">1654       // Copy from high to low addresses.</span>
<span class="line-modified">1655 </span>
<span class="line-modified">1656       // Check for and copy trailing byte</span>
<span class="line-modified">1657       __ testl(byte_count, 1);</span>
<span class="line-modified">1658       __ jcc(Assembler::zero, L_copy_2_bytes);</span>
<span class="line-modified">1659       __ movb(rax, Address(from, byte_count, Address::times_1, -1));</span>
<span class="line-modified">1660       __ movb(Address(to, byte_count, Address::times_1, -1), rax);</span>
<span class="line-modified">1661       __ decrement(byte_count); // Adjust for possible trailing word</span>
<span class="line-modified">1662 </span>
<span class="line-modified">1663       // Check for and copy trailing word</span>
<span class="line-modified">1664     __ BIND(L_copy_2_bytes);</span>
<span class="line-modified">1665       __ testl(byte_count, 2);</span>
<span class="line-modified">1666       __ jcc(Assembler::zero, L_copy_4_bytes);</span>
<span class="line-modified">1667       __ movw(rax, Address(from, byte_count, Address::times_1, -2));</span>
<span class="line-modified">1668       __ movw(Address(to, byte_count, Address::times_1, -2), rax);</span>
<span class="line-modified">1669 </span>
<span class="line-modified">1670       // Check for and copy trailing dword</span>
<span class="line-modified">1671     __ BIND(L_copy_4_bytes);</span>
<span class="line-modified">1672       __ testl(byte_count, 4);</span>
<span class="line-modified">1673       __ jcc(Assembler::zero, L_copy_bytes);</span>
<span class="line-modified">1674       __ movl(rax, Address(from, qword_count, Address::times_8));</span>
<span class="line-modified">1675       __ movl(Address(to, qword_count, Address::times_8), rax);</span>
<span class="line-modified">1676       __ jmp(L_copy_bytes);</span>
<span class="line-modified">1677 </span>
<span class="line-modified">1678       // Copy trailing qwords</span>
<span class="line-modified">1679     __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">1680       __ movq(rax, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-modified">1681       __ movq(Address(to, qword_count, Address::times_8, -8), rax);</span>
<span class="line-added">1682       __ decrement(qword_count);</span>
<span class="line-added">1683       __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-added">1684     }</span>
1685     restore_arg_regs();
1686     inc_counter_np(SharedRuntime::_jbyte_array_copy_ctr); // Update counter after rscratch1 is free
1687     __ xorptr(rax, rax); // return 0
1688     __ vzeroupper();
1689     __ leave(); // required for proper stackwalking of RuntimeStub frame
1690     __ ret(0);
1691 
<span class="line-modified">1692     {</span>
<span class="line-modified">1693       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-modified">1694       UnsafeCopyMemoryMark ucmm(this, !aligned, true);</span>
<span class="line-added">1695       // Copy in multi-bytes chunks</span>
<span class="line-added">1696       copy_bytes_backward(from, to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>
<span class="line-added">1697     }</span>
1698     restore_arg_regs();
1699     inc_counter_np(SharedRuntime::_jbyte_array_copy_ctr); // Update counter after rscratch1 is free
1700     __ xorptr(rax, rax); // return 0
1701     __ vzeroupper();
1702     __ leave(); // required for proper stackwalking of RuntimeStub frame
1703     __ ret(0);
1704 
1705     return start;
1706   }
1707 
1708   // Arguments:
1709   //   aligned - true =&gt; Input and output aligned on a HeapWord == 8-byte boundary
1710   //             ignored
1711   //   name    - stub name string
1712   //
1713   // Inputs:
1714   //   c_rarg0   - source array address
1715   //   c_rarg1   - destination array address
1716   //   c_rarg2   - element count, treated as ssize_t, can be zero
1717   //
</pre>
<hr />
<pre>
1735     const Register count       = rdx;  // elements count
1736     const Register word_count  = rcx;
1737     const Register qword_count = count;
1738     const Register end_from    = from; // source array end address
1739     const Register end_to      = to;   // destination array end address
1740     // End pointers are inclusive, and if count is not zero they point
1741     // to the last unit copied:  end_to[0] := end_from[0]
1742 
1743     __ enter(); // required for proper stackwalking of RuntimeStub frame
1744     assert_clean_int(c_rarg2, rax);    // Make sure &#39;count&#39; is clean int.
1745 
1746     if (entry != NULL) {
1747       *entry = __ pc();
1748       // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
1749       BLOCK_COMMENT(&quot;Entry:&quot;);
1750     }
1751 
1752     setup_arg_regs(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
1753                       // r9 and r10 may be used to save non-volatile registers
1754 
<span class="line-modified">1755     {</span>
<span class="line-modified">1756       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-modified">1757       UnsafeCopyMemoryMark ucmm(this, !aligned, true);</span>
<span class="line-modified">1758       // &#39;from&#39;, &#39;to&#39; and &#39;count&#39; are now valid</span>
<span class="line-modified">1759       __ movptr(word_count, count);</span>
<span class="line-modified">1760       __ shrptr(count, 2); // count =&gt; qword_count</span>
<span class="line-modified">1761 </span>
<span class="line-modified">1762       // Copy from low to high addresses.  Use &#39;to&#39; as scratch.</span>
<span class="line-modified">1763       __ lea(end_from, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-modified">1764       __ lea(end_to,   Address(to,   qword_count, Address::times_8, -8));</span>
<span class="line-modified">1765       __ negptr(qword_count);</span>
<span class="line-modified">1766       __ jmp(L_copy_bytes);</span>
<span class="line-modified">1767 </span>
<span class="line-modified">1768       // Copy trailing qwords</span>
<span class="line-modified">1769     __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">1770       __ movq(rax, Address(end_from, qword_count, Address::times_8, 8));</span>
<span class="line-modified">1771       __ movq(Address(end_to, qword_count, Address::times_8, 8), rax);</span>
<span class="line-modified">1772       __ increment(qword_count);</span>
<span class="line-modified">1773       __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-modified">1774 </span>
<span class="line-modified">1775       // Original &#39;dest&#39; is trashed, so we can&#39;t use it as a</span>
<span class="line-modified">1776       // base register for a possible trailing word copy</span>
<span class="line-modified">1777 </span>
<span class="line-modified">1778       // Check for and copy trailing dword</span>
<span class="line-modified">1779     __ BIND(L_copy_4_bytes);</span>
<span class="line-modified">1780       __ testl(word_count, 2);</span>
<span class="line-modified">1781       __ jccb(Assembler::zero, L_copy_2_bytes);</span>
<span class="line-modified">1782       __ movl(rax, Address(end_from, 8));</span>
<span class="line-modified">1783       __ movl(Address(end_to, 8), rax);</span>
<span class="line-modified">1784 </span>
<span class="line-modified">1785       __ addptr(end_from, 4);</span>
<span class="line-modified">1786       __ addptr(end_to, 4);</span>
<span class="line-modified">1787 </span>
<span class="line-modified">1788       // Check for and copy trailing word</span>
<span class="line-modified">1789     __ BIND(L_copy_2_bytes);</span>
<span class="line-modified">1790       __ testl(word_count, 1);</span>
<span class="line-modified">1791       __ jccb(Assembler::zero, L_exit);</span>
<span class="line-added">1792       __ movw(rax, Address(end_from, 8));</span>
<span class="line-added">1793       __ movw(Address(end_to, 8), rax);</span>
<span class="line-added">1794     }</span>
1795   __ BIND(L_exit);
<span class="line-added">1796     address ucme_exit_pc = __ pc();</span>
1797     restore_arg_regs();
1798     inc_counter_np(SharedRuntime::_jshort_array_copy_ctr); // Update counter after rscratch1 is free
1799     __ xorptr(rax, rax); // return 0
1800     __ vzeroupper();
1801     __ leave(); // required for proper stackwalking of RuntimeStub frame
1802     __ ret(0);
1803 
<span class="line-modified">1804     {</span>
<span class="line-modified">1805       UnsafeCopyMemoryMark ucmm(this, !aligned, false, ucme_exit_pc);</span>
<span class="line-modified">1806       // Copy in multi-bytes chunks</span>
<span class="line-added">1807       copy_bytes_forward(end_from, end_to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>
<span class="line-added">1808       __ jmp(L_copy_4_bytes);</span>
<span class="line-added">1809     }</span>
1810 
1811     return start;
1812   }
1813 
1814   address generate_fill(BasicType t, bool aligned, const char *name) {
1815     __ align(CodeEntryAlignment);
1816     StubCodeMark mark(this, &quot;StubRoutines&quot;, name);
1817     address start = __ pc();
1818 
1819     BLOCK_COMMENT(&quot;Entry:&quot;);
1820 
1821     const Register to       = c_rarg0;  // source array address
1822     const Register value    = c_rarg1;  // value
1823     const Register count    = c_rarg2;  // elements count
1824 
1825     __ enter(); // required for proper stackwalking of RuntimeStub frame
1826 
1827     __ generate_fill(t, aligned, to, value, count, rax, xmm0);
1828 
1829     __ vzeroupper();
</pre>
<hr />
<pre>
1856     Label L_copy_bytes, L_copy_8_bytes, L_copy_4_bytes;
1857     const Register from        = rdi;  // source array address
1858     const Register to          = rsi;  // destination array address
1859     const Register count       = rdx;  // elements count
1860     const Register word_count  = rcx;
1861     const Register qword_count = count;
1862 
1863     __ enter(); // required for proper stackwalking of RuntimeStub frame
1864     assert_clean_int(c_rarg2, rax);    // Make sure &#39;count&#39; is clean int.
1865 
1866     if (entry != NULL) {
1867       *entry = __ pc();
1868       // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
1869       BLOCK_COMMENT(&quot;Entry:&quot;);
1870     }
1871 
1872     array_overlap_test(nooverlap_target, Address::times_2);
1873     setup_arg_regs(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
1874                       // r9 and r10 may be used to save non-volatile registers
1875 
<span class="line-modified">1876     {</span>
<span class="line-modified">1877       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-modified">1878       UnsafeCopyMemoryMark ucmm(this, !aligned, true);</span>
<span class="line-modified">1879       // &#39;from&#39;, &#39;to&#39; and &#39;count&#39; are now valid</span>
<span class="line-modified">1880       __ movptr(word_count, count);</span>
<span class="line-modified">1881       __ shrptr(count, 2); // count =&gt; qword_count</span>
<span class="line-modified">1882 </span>
<span class="line-modified">1883       // Copy from high to low addresses.  Use &#39;to&#39; as scratch.</span>
<span class="line-modified">1884 </span>
<span class="line-modified">1885       // Check for and copy trailing word</span>
<span class="line-modified">1886       __ testl(word_count, 1);</span>
<span class="line-modified">1887       __ jccb(Assembler::zero, L_copy_4_bytes);</span>
<span class="line-modified">1888       __ movw(rax, Address(from, word_count, Address::times_2, -2));</span>
<span class="line-modified">1889       __ movw(Address(to, word_count, Address::times_2, -2), rax);</span>
<span class="line-modified">1890 </span>
<span class="line-modified">1891      // Check for and copy trailing dword</span>
<span class="line-modified">1892     __ BIND(L_copy_4_bytes);</span>
<span class="line-modified">1893       __ testl(word_count, 2);</span>
<span class="line-modified">1894       __ jcc(Assembler::zero, L_copy_bytes);</span>
<span class="line-modified">1895       __ movl(rax, Address(from, qword_count, Address::times_8));</span>
<span class="line-modified">1896       __ movl(Address(to, qword_count, Address::times_8), rax);</span>
<span class="line-modified">1897       __ jmp(L_copy_bytes);</span>
<span class="line-modified">1898 </span>
<span class="line-modified">1899       // Copy trailing qwords</span>
<span class="line-modified">1900     __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">1901       __ movq(rax, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-modified">1902       __ movq(Address(to, qword_count, Address::times_8, -8), rax);</span>
<span class="line-added">1903       __ decrement(qword_count);</span>
<span class="line-added">1904       __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-added">1905     }</span>
1906     restore_arg_regs();
1907     inc_counter_np(SharedRuntime::_jshort_array_copy_ctr); // Update counter after rscratch1 is free
1908     __ xorptr(rax, rax); // return 0
1909     __ vzeroupper();
1910     __ leave(); // required for proper stackwalking of RuntimeStub frame
1911     __ ret(0);
1912 
<span class="line-modified">1913     {</span>
<span class="line-modified">1914       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-modified">1915       UnsafeCopyMemoryMark ucmm(this, !aligned, true);</span>
<span class="line-added">1916       // Copy in multi-bytes chunks</span>
<span class="line-added">1917       copy_bytes_backward(from, to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>
<span class="line-added">1918     }</span>
1919     restore_arg_regs();
1920     inc_counter_np(SharedRuntime::_jshort_array_copy_ctr); // Update counter after rscratch1 is free
1921     __ xorptr(rax, rax); // return 0
1922     __ vzeroupper();
1923     __ leave(); // required for proper stackwalking of RuntimeStub frame
1924     __ ret(0);
1925 
1926     return start;
1927   }
1928 
1929   // Arguments:
1930   //   aligned - true =&gt; Input and output aligned on a HeapWord == 8-byte boundary
1931   //             ignored
1932   //   is_oop  - true =&gt; oop array, so generate store check code
1933   //   name    - stub name string
1934   //
1935   // Inputs:
1936   //   c_rarg0   - source array address
1937   //   c_rarg1   - destination array address
1938   //   c_rarg2   - element count, treated as ssize_t, can be zero
</pre>
<hr />
<pre>
1969       *entry = __ pc();
1970       // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
1971       BLOCK_COMMENT(&quot;Entry:&quot;);
1972     }
1973 
1974     setup_arg_regs_using_thread(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
1975                                    // r9 is used to save r15_thread
1976 
1977     DecoratorSet decorators = IN_HEAP | IS_ARRAY | ARRAYCOPY_DISJOINT;
1978     if (dest_uninitialized) {
1979       decorators |= IS_DEST_UNINITIALIZED;
1980     }
1981     if (aligned) {
1982       decorators |= ARRAYCOPY_ALIGNED;
1983     }
1984 
1985     BasicType type = is_oop ? T_OBJECT : T_INT;
1986     BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
1987     bs-&gt;arraycopy_prologue(_masm, decorators, type, from, to, count);
1988 
<span class="line-modified">1989     {</span>
<span class="line-modified">1990       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-modified">1991       UnsafeCopyMemoryMark ucmm(this, !is_oop &amp;&amp; !aligned, true);</span>
<span class="line-modified">1992       // &#39;from&#39;, &#39;to&#39; and &#39;count&#39; are now valid</span>
<span class="line-modified">1993       __ movptr(dword_count, count);</span>
<span class="line-modified">1994       __ shrptr(count, 1); // count =&gt; qword_count</span>
<span class="line-modified">1995 </span>
<span class="line-modified">1996       // Copy from low to high addresses.  Use &#39;to&#39; as scratch.</span>
<span class="line-modified">1997       __ lea(end_from, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-modified">1998       __ lea(end_to,   Address(to,   qword_count, Address::times_8, -8));</span>
<span class="line-modified">1999       __ negptr(qword_count);</span>
<span class="line-modified">2000       __ jmp(L_copy_bytes);</span>
<span class="line-modified">2001 </span>
<span class="line-modified">2002       // Copy trailing qwords</span>
<span class="line-modified">2003     __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">2004       __ movq(rax, Address(end_from, qword_count, Address::times_8, 8));</span>
<span class="line-modified">2005       __ movq(Address(end_to, qword_count, Address::times_8, 8), rax);</span>
<span class="line-modified">2006       __ increment(qword_count);</span>
<span class="line-modified">2007       __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-modified">2008 </span>
<span class="line-modified">2009       // Check for and copy trailing dword</span>
<span class="line-modified">2010     __ BIND(L_copy_4_bytes);</span>
<span class="line-modified">2011       __ testl(dword_count, 1); // Only byte test since the value is 0 or 1</span>
<span class="line-modified">2012       __ jccb(Assembler::zero, L_exit);</span>
<span class="line-added">2013       __ movl(rax, Address(end_from, 8));</span>
<span class="line-added">2014       __ movl(Address(end_to, 8), rax);</span>
<span class="line-added">2015     }</span>
2016   __ BIND(L_exit);
<span class="line-added">2017     address ucme_exit_pc = __ pc();</span>
2018     bs-&gt;arraycopy_epilogue(_masm, decorators, type, from, to, dword_count);
2019     restore_arg_regs_using_thread();
2020     inc_counter_np(SharedRuntime::_jint_array_copy_ctr); // Update counter after rscratch1 is free
2021     __ vzeroupper();
2022     __ xorptr(rax, rax); // return 0
2023     __ leave(); // required for proper stackwalking of RuntimeStub frame
2024     __ ret(0);
2025 
<span class="line-modified">2026     {</span>
<span class="line-modified">2027       UnsafeCopyMemoryMark ucmm(this, !is_oop &amp;&amp; !aligned, false, ucme_exit_pc);</span>
<span class="line-modified">2028       // Copy in multi-bytes chunks</span>
<span class="line-added">2029       copy_bytes_forward(end_from, end_to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>
<span class="line-added">2030       __ jmp(L_copy_4_bytes);</span>
<span class="line-added">2031     }</span>
2032 
2033     return start;
2034   }
2035 
2036   // Arguments:
2037   //   aligned - true =&gt; Input and output aligned on a HeapWord == 8-byte boundary
2038   //             ignored
2039   //   is_oop  - true =&gt; oop array, so generate store check code
2040   //   name    - stub name string
2041   //
2042   // Inputs:
2043   //   c_rarg0   - source array address
2044   //   c_rarg1   - destination array address
2045   //   c_rarg2   - element count, treated as ssize_t, can be zero
2046   //
2047   // If &#39;from&#39; and/or &#39;to&#39; are aligned on 4-byte boundaries, we let
2048   // the hardware handle it.  The two dwords within qwords that span
2049   // cache line boundaries will still be loaded and stored atomicly.
2050   //
2051   address generate_conjoint_int_oop_copy(bool aligned, bool is_oop, address nooverlap_target,
</pre>
<hr />
<pre>
2072     }
2073 
2074     array_overlap_test(nooverlap_target, Address::times_4);
2075     setup_arg_regs_using_thread(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
2076                                    // r9 is used to save r15_thread
2077 
2078     DecoratorSet decorators = IN_HEAP | IS_ARRAY;
2079     if (dest_uninitialized) {
2080       decorators |= IS_DEST_UNINITIALIZED;
2081     }
2082     if (aligned) {
2083       decorators |= ARRAYCOPY_ALIGNED;
2084     }
2085 
2086     BasicType type = is_oop ? T_OBJECT : T_INT;
2087     BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
2088     // no registers are destroyed by this call
2089     bs-&gt;arraycopy_prologue(_masm, decorators, type, from, to, count);
2090 
2091     assert_clean_int(count, rax); // Make sure &#39;count&#39; is clean int.
<span class="line-modified">2092     {</span>
<span class="line-modified">2093       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-modified">2094       UnsafeCopyMemoryMark ucmm(this, !is_oop &amp;&amp; !aligned, true);</span>
<span class="line-modified">2095       // &#39;from&#39;, &#39;to&#39; and &#39;count&#39; are now valid</span>
<span class="line-modified">2096       __ movptr(dword_count, count);</span>
<span class="line-modified">2097       __ shrptr(count, 1); // count =&gt; qword_count</span>
<span class="line-modified">2098 </span>
<span class="line-modified">2099       // Copy from high to low addresses.  Use &#39;to&#39; as scratch.</span>
<span class="line-modified">2100 </span>
<span class="line-modified">2101       // Check for and copy trailing dword</span>
<span class="line-modified">2102       __ testl(dword_count, 1);</span>
<span class="line-modified">2103       __ jcc(Assembler::zero, L_copy_bytes);</span>
<span class="line-modified">2104       __ movl(rax, Address(from, dword_count, Address::times_4, -4));</span>
<span class="line-modified">2105       __ movl(Address(to, dword_count, Address::times_4, -4), rax);</span>
<span class="line-modified">2106       __ jmp(L_copy_bytes);</span>
<span class="line-modified">2107 </span>
<span class="line-modified">2108       // Copy trailing qwords</span>
<span class="line-modified">2109     __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">2110       __ movq(rax, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-modified">2111       __ movq(Address(to, qword_count, Address::times_8, -8), rax);</span>
<span class="line-added">2112       __ decrement(qword_count);</span>
<span class="line-added">2113       __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-added">2114     }</span>
2115     if (is_oop) {
2116       __ jmp(L_exit);
2117     }
2118     restore_arg_regs_using_thread();
2119     inc_counter_np(SharedRuntime::_jint_array_copy_ctr); // Update counter after rscratch1 is free
2120     __ xorptr(rax, rax); // return 0
2121     __ vzeroupper();
2122     __ leave(); // required for proper stackwalking of RuntimeStub frame
2123     __ ret(0);
2124 
<span class="line-modified">2125     {</span>
<span class="line-modified">2126       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-added">2127       UnsafeCopyMemoryMark ucmm(this, !is_oop &amp;&amp; !aligned, true);</span>
<span class="line-added">2128       // Copy in multi-bytes chunks</span>
<span class="line-added">2129       copy_bytes_backward(from, to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>
<span class="line-added">2130     }</span>
2131 
2132   __ BIND(L_exit);
2133     bs-&gt;arraycopy_epilogue(_masm, decorators, type, from, to, dword_count);
2134     restore_arg_regs_using_thread();
2135     inc_counter_np(SharedRuntime::_jint_array_copy_ctr); // Update counter after rscratch1 is free
2136     __ xorptr(rax, rax); // return 0
2137     __ vzeroupper();
2138     __ leave(); // required for proper stackwalking of RuntimeStub frame
2139     __ ret(0);
2140 
2141     return start;
2142   }
2143 
2144   // Arguments:
2145   //   aligned - true =&gt; Input and output aligned on a HeapWord boundary == 8 bytes
2146   //             ignored
2147   //   is_oop  - true =&gt; oop array, so generate store check code
2148   //   name    - stub name string
2149   //
2150   // Inputs:
</pre>
<hr />
<pre>
2180       *entry = __ pc();
2181       // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
2182       BLOCK_COMMENT(&quot;Entry:&quot;);
2183     }
2184 
2185     setup_arg_regs_using_thread(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
2186                                      // r9 is used to save r15_thread
2187     // &#39;from&#39;, &#39;to&#39; and &#39;qword_count&#39; are now valid
2188 
2189     DecoratorSet decorators = IN_HEAP | IS_ARRAY | ARRAYCOPY_DISJOINT;
2190     if (dest_uninitialized) {
2191       decorators |= IS_DEST_UNINITIALIZED;
2192     }
2193     if (aligned) {
2194       decorators |= ARRAYCOPY_ALIGNED;
2195     }
2196 
2197     BasicType type = is_oop ? T_OBJECT : T_LONG;
2198     BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
2199     bs-&gt;arraycopy_prologue(_masm, decorators, type, from, to, qword_count);
<span class="line-modified">2200     {</span>
<span class="line-modified">2201       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-modified">2202       UnsafeCopyMemoryMark ucmm(this, !is_oop &amp;&amp; !aligned, true);</span>
<span class="line-modified">2203 </span>
<span class="line-modified">2204       // Copy from low to high addresses.  Use &#39;to&#39; as scratch.</span>
<span class="line-modified">2205       __ lea(end_from, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-modified">2206       __ lea(end_to,   Address(to,   qword_count, Address::times_8, -8));</span>
<span class="line-modified">2207       __ negptr(qword_count);</span>
<span class="line-modified">2208       __ jmp(L_copy_bytes);</span>
<span class="line-modified">2209 </span>
<span class="line-modified">2210       // Copy trailing qwords</span>
<span class="line-modified">2211     __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">2212       __ movq(rax, Address(end_from, qword_count, Address::times_8, 8));</span>
<span class="line-modified">2213       __ movq(Address(end_to, qword_count, Address::times_8, 8), rax);</span>
<span class="line-added">2214       __ increment(qword_count);</span>
<span class="line-added">2215       __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-added">2216     }</span>
2217     if (is_oop) {
2218       __ jmp(L_exit);
2219     } else {
2220       restore_arg_regs_using_thread();
2221       inc_counter_np(SharedRuntime::_jlong_array_copy_ctr); // Update counter after rscratch1 is free
2222       __ xorptr(rax, rax); // return 0
2223       __ vzeroupper();
2224       __ leave(); // required for proper stackwalking of RuntimeStub frame
2225       __ ret(0);
2226     }
2227 
<span class="line-modified">2228     {</span>
<span class="line-modified">2229       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-added">2230       UnsafeCopyMemoryMark ucmm(this, !is_oop &amp;&amp; !aligned, true);</span>
<span class="line-added">2231       // Copy in multi-bytes chunks</span>
<span class="line-added">2232       copy_bytes_forward(end_from, end_to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>
<span class="line-added">2233     }</span>
2234 
2235     __ BIND(L_exit);
2236     bs-&gt;arraycopy_epilogue(_masm, decorators, type, from, to, qword_count);
2237     restore_arg_regs_using_thread();
2238     if (is_oop) {
2239       inc_counter_np(SharedRuntime::_oop_array_copy_ctr); // Update counter after rscratch1 is free
2240     } else {
2241       inc_counter_np(SharedRuntime::_jlong_array_copy_ctr); // Update counter after rscratch1 is free
2242     }
2243     __ vzeroupper();
2244     __ xorptr(rax, rax); // return 0
2245     __ leave(); // required for proper stackwalking of RuntimeStub frame
2246     __ ret(0);
2247 
2248     return start;
2249   }
2250 
2251   // Arguments:
2252   //   aligned - true =&gt; Input and output aligned on a HeapWord boundary == 8 bytes
2253   //             ignored
</pre>
<hr />
<pre>
2269     Label L_copy_bytes, L_copy_8_bytes, L_exit;
2270     const Register from        = rdi;  // source array address
2271     const Register to          = rsi;  // destination array address
2272     const Register qword_count = rdx;  // elements count
2273     const Register saved_count = rcx;
2274 
2275     __ enter(); // required for proper stackwalking of RuntimeStub frame
2276     assert_clean_int(c_rarg2, rax);    // Make sure &#39;count&#39; is clean int.
2277 
2278     if (entry != NULL) {
2279       *entry = __ pc();
2280       // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
2281       BLOCK_COMMENT(&quot;Entry:&quot;);
2282     }
2283 
2284     array_overlap_test(nooverlap_target, Address::times_8);
2285     setup_arg_regs_using_thread(); // from =&gt; rdi, to =&gt; rsi, count =&gt; rdx
2286                                    // r9 is used to save r15_thread
2287     // &#39;from&#39;, &#39;to&#39; and &#39;qword_count&#39; are now valid
2288 
<span class="line-modified">2289     DecoratorSet decorators = IN_HEAP | IS_ARRAY;</span>
2290     if (dest_uninitialized) {
2291       decorators |= IS_DEST_UNINITIALIZED;
2292     }
2293     if (aligned) {
2294       decorators |= ARRAYCOPY_ALIGNED;
2295     }
2296 
2297     BasicType type = is_oop ? T_OBJECT : T_LONG;
2298     BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
2299     bs-&gt;arraycopy_prologue(_masm, decorators, type, from, to, qword_count);
<span class="line-added">2300     {</span>
<span class="line-added">2301       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-added">2302       UnsafeCopyMemoryMark ucmm(this, !is_oop &amp;&amp; !aligned, true);</span>
2303 
<span class="line-modified">2304       __ jmp(L_copy_bytes);</span>







2305 
<span class="line-added">2306       // Copy trailing qwords</span>
<span class="line-added">2307     __ BIND(L_copy_8_bytes);</span>
<span class="line-added">2308       __ movq(rax, Address(from, qword_count, Address::times_8, -8));</span>
<span class="line-added">2309       __ movq(Address(to, qword_count, Address::times_8, -8), rax);</span>
<span class="line-added">2310       __ decrement(qword_count);</span>
<span class="line-added">2311       __ jcc(Assembler::notZero, L_copy_8_bytes);</span>
<span class="line-added">2312     }</span>
2313     if (is_oop) {
2314       __ jmp(L_exit);
2315     } else {
2316       restore_arg_regs_using_thread();
2317       inc_counter_np(SharedRuntime::_jlong_array_copy_ctr); // Update counter after rscratch1 is free
2318       __ xorptr(rax, rax); // return 0
2319       __ vzeroupper();
2320       __ leave(); // required for proper stackwalking of RuntimeStub frame
2321       __ ret(0);
2322     }
<span class="line-added">2323     {</span>
<span class="line-added">2324       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-added">2325       UnsafeCopyMemoryMark ucmm(this, !is_oop &amp;&amp; !aligned, true);</span>
2326 
<span class="line-modified">2327       // Copy in multi-bytes chunks</span>
<span class="line-modified">2328       copy_bytes_backward(from, to, qword_count, rax, L_copy_bytes, L_copy_8_bytes);</span>
<span class="line-modified">2329     }</span>
2330     __ BIND(L_exit);
2331     bs-&gt;arraycopy_epilogue(_masm, decorators, type, from, to, qword_count);
2332     restore_arg_regs_using_thread();
2333     if (is_oop) {
2334       inc_counter_np(SharedRuntime::_oop_array_copy_ctr); // Update counter after rscratch1 is free
2335     } else {
2336       inc_counter_np(SharedRuntime::_jlong_array_copy_ctr); // Update counter after rscratch1 is free
2337     }
2338     __ vzeroupper();
2339     __ xorptr(rax, rax); // return 0
2340     __ leave(); // required for proper stackwalking of RuntimeStub frame
2341     __ ret(0);
2342 
2343     return start;
2344   }
2345 
2346 
2347   // Helper for generating a dynamic type check.
2348   // Smashes no registers.
2349   void generate_type_check(Register sub_klass,
</pre>
<hr />
<pre>
2469 #ifdef ASSERT
2470     BLOCK_COMMENT(&quot;assert consistent ckoff/ckval&quot;);
2471     // The ckoff and ckval must be mutually consistent,
2472     // even though caller generates both.
2473     { Label L;
2474       int sco_offset = in_bytes(Klass::super_check_offset_offset());
2475       __ cmpl(ckoff, Address(ckval, sco_offset));
2476       __ jcc(Assembler::equal, L);
2477       __ stop(&quot;super_check_offset inconsistent&quot;);
2478       __ bind(L);
2479     }
2480 #endif //ASSERT
2481 
2482     // Loop-invariant addresses.  They are exclusive end pointers.
2483     Address end_from_addr(from, length, TIMES_OOP, 0);
2484     Address   end_to_addr(to,   length, TIMES_OOP, 0);
2485     // Loop-variant addresses.  They assume post-incremented count &lt; 0.
2486     Address from_element_addr(end_from, count, TIMES_OOP, 0);
2487     Address   to_element_addr(end_to,   count, TIMES_OOP, 0);
2488 
<span class="line-modified">2489     DecoratorSet decorators = IN_HEAP | IS_ARRAY | ARRAYCOPY_CHECKCAST | ARRAYCOPY_DISJOINT;</span>
2490     if (dest_uninitialized) {
2491       decorators |= IS_DEST_UNINITIALIZED;
2492     }
2493 
2494     BasicType type = T_OBJECT;
2495     BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
2496     bs-&gt;arraycopy_prologue(_masm, decorators, type, from, to, count);
2497 
2498     // Copy from low to high addresses, indexed from the end of each array.
2499     __ lea(end_from, end_from_addr);
2500     __ lea(end_to,   end_to_addr);
2501     __ movptr(r14_length, length);        // save a copy of the length
2502     assert(length == count, &quot;&quot;);          // else fix next line:
2503     __ negptr(count);                     // negate and test the length
2504     __ jcc(Assembler::notZero, L_load_element);
2505 
2506     // Empty array:  Nothing to do.
2507     __ xorptr(rax, rax);                  // return 0 on (trivial) success
2508     __ jmp(L_done);
2509 
</pre>
<hr />
<pre>
2949       __ movl(  sco_temp,      Address(r11_dst_klass, sco_offset));
2950       assert_clean_int(sco_temp, rax);
2951 
2952       // the checkcast_copy loop needs two extra arguments:
2953       assert(c_rarg3 == sco_temp, &quot;#3 already in place&quot;);
2954       // Set up arguments for checkcast_copy_entry.
2955       setup_arg_regs(4);
2956       __ movptr(r8, r11_dst_klass);  // dst.klass.element_klass, r8 is c_rarg4 on Linux/Solaris
2957       __ jump(RuntimeAddress(checkcast_copy_entry));
2958     }
2959 
2960   __ BIND(L_failed);
2961     __ xorptr(rax, rax);
2962     __ notptr(rax); // return -1
2963     __ leave();   // required for proper stackwalking of RuntimeStub frame
2964     __ ret(0);
2965 
2966     return start;
2967   }
2968 
<span class="line-added">2969   address generate_data_cache_writeback() {</span>
<span class="line-added">2970     const Register src        = c_rarg0;  // source address</span>
<span class="line-added">2971 </span>
<span class="line-added">2972     __ align(CodeEntryAlignment);</span>
<span class="line-added">2973 </span>
<span class="line-added">2974     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;_data_cache_writeback&quot;);</span>
<span class="line-added">2975 </span>
<span class="line-added">2976     address start = __ pc();</span>
<span class="line-added">2977     __ enter();</span>
<span class="line-added">2978     __ cache_wb(Address(src, 0));</span>
<span class="line-added">2979     __ leave();</span>
<span class="line-added">2980     __ ret(0);</span>
<span class="line-added">2981 </span>
<span class="line-added">2982     return start;</span>
<span class="line-added">2983   }</span>
<span class="line-added">2984 </span>
<span class="line-added">2985   address generate_data_cache_writeback_sync() {</span>
<span class="line-added">2986     const Register is_pre    = c_rarg0;  // pre or post sync</span>
<span class="line-added">2987 </span>
<span class="line-added">2988     __ align(CodeEntryAlignment);</span>
<span class="line-added">2989 </span>
<span class="line-added">2990     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;_data_cache_writeback_sync&quot;);</span>
<span class="line-added">2991 </span>
<span class="line-added">2992     // pre wbsync is a no-op</span>
<span class="line-added">2993     // post wbsync translates to an sfence</span>
<span class="line-added">2994 </span>
<span class="line-added">2995     Label skip;</span>
<span class="line-added">2996     address start = __ pc();</span>
<span class="line-added">2997     __ enter();</span>
<span class="line-added">2998     __ cmpl(is_pre, 0);</span>
<span class="line-added">2999     __ jcc(Assembler::notEqual, skip);</span>
<span class="line-added">3000     __ cache_wbsync(false);</span>
<span class="line-added">3001     __ bind(skip);</span>
<span class="line-added">3002     __ leave();</span>
<span class="line-added">3003     __ ret(0);</span>
<span class="line-added">3004 </span>
<span class="line-added">3005     return start;</span>
<span class="line-added">3006   }</span>
<span class="line-added">3007 </span>
3008   void generate_arraycopy_stubs() {
3009     address entry;
3010     address entry_jbyte_arraycopy;
3011     address entry_jshort_arraycopy;
3012     address entry_jint_arraycopy;
3013     address entry_oop_arraycopy;
3014     address entry_jlong_arraycopy;
3015     address entry_checkcast_arraycopy;
3016 
3017     StubRoutines::_jbyte_disjoint_arraycopy  = generate_disjoint_byte_copy(false, &amp;entry,
3018                                                                            &quot;jbyte_disjoint_arraycopy&quot;);
3019     StubRoutines::_jbyte_arraycopy           = generate_conjoint_byte_copy(false, entry, &amp;entry_jbyte_arraycopy,
3020                                                                            &quot;jbyte_arraycopy&quot;);
3021 
3022     StubRoutines::_jshort_disjoint_arraycopy = generate_disjoint_short_copy(false, &amp;entry,
3023                                                                             &quot;jshort_disjoint_arraycopy&quot;);
3024     StubRoutines::_jshort_arraycopy          = generate_conjoint_short_copy(false, entry, &amp;entry_jshort_arraycopy,
3025                                                                             &quot;jshort_arraycopy&quot;);
3026 
3027     StubRoutines::_jint_disjoint_arraycopy   = generate_disjoint_int_oop_copy(false, false, &amp;entry,
</pre>
<hr />
<pre>
3764       __ subptr(len_reg, AESBlockSize);
3765       __ jcc(Assembler::notEqual, L_singleBlock_loopTop[k]);
3766       if (k != 2) {
3767         __ jmp(L_exit);
3768       }
3769     } //for 128/192/256
3770 
3771     __ BIND(L_exit);
3772     __ movdqu(Address(rvec, 0), xmm_prev_block_cipher);     // final value of r stored in rvec of CipherBlockChaining object
3773     __ pop(rbx);
3774 #ifdef _WIN64
3775     __ movl(rax, len_mem);
3776 #else
3777     __ pop(rax); // return length
3778 #endif
3779     __ leave(); // required for proper stackwalking of RuntimeStub frame
3780     __ ret(0);
3781     return start;
3782 }
3783 
<span class="line-added">3784   address generate_electronicCodeBook_encryptAESCrypt() {</span>
<span class="line-added">3785     __ align(CodeEntryAlignment);</span>
<span class="line-added">3786     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;electronicCodeBook_encryptAESCrypt&quot;);</span>
<span class="line-added">3787     address start = __ pc();</span>
<span class="line-added">3788     const Register from = c_rarg0;  // source array address</span>
<span class="line-added">3789     const Register to = c_rarg1;  // destination array address</span>
<span class="line-added">3790     const Register key = c_rarg2;  // key array address</span>
<span class="line-added">3791     const Register len = c_rarg3;  // src len (must be multiple of blocksize 16)</span>
<span class="line-added">3792     __ enter(); // required for proper stackwalking of RuntimeStub frame</span>
<span class="line-added">3793     __ aesecb_encrypt(from, to, key, len);</span>
<span class="line-added">3794     __ leave(); // required for proper stackwalking of RuntimeStub frame</span>
<span class="line-added">3795     __ ret(0);</span>
<span class="line-added">3796     return start;</span>
<span class="line-added">3797  }</span>
<span class="line-added">3798 </span>
<span class="line-added">3799   address generate_electronicCodeBook_decryptAESCrypt() {</span>
<span class="line-added">3800     __ align(CodeEntryAlignment);</span>
<span class="line-added">3801     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;electronicCodeBook_decryptAESCrypt&quot;);</span>
<span class="line-added">3802     address start = __ pc();</span>
<span class="line-added">3803     const Register from = c_rarg0;  // source array address</span>
<span class="line-added">3804     const Register to = c_rarg1;  // destination array address</span>
<span class="line-added">3805     const Register key = c_rarg2;  // key array address</span>
<span class="line-added">3806     const Register len = c_rarg3;  // src len (must be multiple of blocksize 16)</span>
<span class="line-added">3807     __ enter(); // required for proper stackwalking of RuntimeStub frame</span>
<span class="line-added">3808     __ aesecb_decrypt(from, to, key, len);</span>
<span class="line-added">3809     __ leave(); // required for proper stackwalking of RuntimeStub frame</span>
<span class="line-added">3810     __ ret(0);</span>
<span class="line-added">3811     return start;</span>
<span class="line-added">3812   }</span>
<span class="line-added">3813 </span>
3814   address generate_upper_word_mask() {
3815     __ align(64);
3816     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;upper_word_mask&quot;);
3817     address start = __ pc();
3818     __ emit_data64(0x0000000000000000, relocInfo::none);
3819     __ emit_data64(0xFFFFFFFF00000000, relocInfo::none);
3820     return start;
3821   }
3822 
3823   address generate_shuffle_byte_flip_mask() {
3824     __ align(64);
3825     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;shuffle_byte_flip_mask&quot;);
3826     address start = __ pc();
3827     __ emit_data64(0x08090a0b0c0d0e0f, relocInfo::none);
3828     __ emit_data64(0x0001020304050607, relocInfo::none);
3829     return start;
3830   }
3831 
3832   // ofs and limit are use for multi-block byte array.
3833   // int com.sun.security.provider.DigestBase.implCompressMultiBlock(byte[] b, int ofs, int limit)
</pre>
<hr />
<pre>
3969     const XMMRegister state1 = xmm2;
3970     const XMMRegister msgtmp0 = xmm3;
3971     const XMMRegister msgtmp1 = xmm4;
3972     const XMMRegister msgtmp2 = xmm5;
3973     const XMMRegister msgtmp3 = xmm6;
3974     const XMMRegister msgtmp4 = xmm7;
3975 
3976     const XMMRegister shuf_mask = xmm8;
3977 
3978     __ enter();
3979 
3980     __ sha512_AVX2(msg, state0, state1, msgtmp0, msgtmp1, msgtmp2, msgtmp3, msgtmp4,
3981     buf, state, ofs, limit, rsp, multi_block, shuf_mask);
3982 
3983     __ vzeroupper();
3984     __ leave();
3985     __ ret(0);
3986     return start;
3987   }
3988 
<span class="line-added">3989   // This mask is used for incrementing counter value(linc0, linc4, etc.)</span>
<span class="line-added">3990   address counter_mask_addr() {</span>
<span class="line-added">3991     __ align(64);</span>
<span class="line-added">3992     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;counter_mask_addr&quot;);</span>
<span class="line-added">3993     address start = __ pc();</span>
<span class="line-added">3994     __ emit_data64(0x08090a0b0c0d0e0f, relocInfo::none);//lbswapmask</span>
<span class="line-added">3995     __ emit_data64(0x0001020304050607, relocInfo::none);</span>
<span class="line-added">3996     __ emit_data64(0x08090a0b0c0d0e0f, relocInfo::none);</span>
<span class="line-added">3997     __ emit_data64(0x0001020304050607, relocInfo::none);</span>
<span class="line-added">3998     __ emit_data64(0x08090a0b0c0d0e0f, relocInfo::none);</span>
<span class="line-added">3999     __ emit_data64(0x0001020304050607, relocInfo::none);</span>
<span class="line-added">4000     __ emit_data64(0x08090a0b0c0d0e0f, relocInfo::none);</span>
<span class="line-added">4001     __ emit_data64(0x0001020304050607, relocInfo::none);</span>
<span class="line-added">4002     __ emit_data64(0x0000000000000000, relocInfo::none);//linc0 = counter_mask_addr+64</span>
<span class="line-added">4003     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4004     __ emit_data64(0x0000000000000001, relocInfo::none);//counter_mask_addr() + 80</span>
<span class="line-added">4005     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4006     __ emit_data64(0x0000000000000002, relocInfo::none);</span>
<span class="line-added">4007     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4008     __ emit_data64(0x0000000000000003, relocInfo::none);</span>
<span class="line-added">4009     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4010     __ emit_data64(0x0000000000000004, relocInfo::none);//linc4 = counter_mask_addr() + 128</span>
<span class="line-added">4011     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4012     __ emit_data64(0x0000000000000004, relocInfo::none);</span>
<span class="line-added">4013     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4014     __ emit_data64(0x0000000000000004, relocInfo::none);</span>
<span class="line-added">4015     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4016     __ emit_data64(0x0000000000000004, relocInfo::none);</span>
<span class="line-added">4017     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4018     __ emit_data64(0x0000000000000008, relocInfo::none);//linc8 = counter_mask_addr() + 192</span>
<span class="line-added">4019     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4020     __ emit_data64(0x0000000000000008, relocInfo::none);</span>
<span class="line-added">4021     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4022     __ emit_data64(0x0000000000000008, relocInfo::none);</span>
<span class="line-added">4023     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4024     __ emit_data64(0x0000000000000008, relocInfo::none);</span>
<span class="line-added">4025     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4026     __ emit_data64(0x0000000000000020, relocInfo::none);//linc32 = counter_mask_addr() + 256</span>
<span class="line-added">4027     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4028     __ emit_data64(0x0000000000000020, relocInfo::none);</span>
<span class="line-added">4029     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4030     __ emit_data64(0x0000000000000020, relocInfo::none);</span>
<span class="line-added">4031     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4032     __ emit_data64(0x0000000000000020, relocInfo::none);</span>
<span class="line-added">4033     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4034     __ emit_data64(0x0000000000000010, relocInfo::none);//linc16 = counter_mask_addr() + 320</span>
<span class="line-added">4035     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4036     __ emit_data64(0x0000000000000010, relocInfo::none);</span>
<span class="line-added">4037     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4038     __ emit_data64(0x0000000000000010, relocInfo::none);</span>
<span class="line-added">4039     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4040     __ emit_data64(0x0000000000000010, relocInfo::none);</span>
<span class="line-added">4041     __ emit_data64(0x0000000000000000, relocInfo::none);</span>
<span class="line-added">4042     return start;</span>
<span class="line-added">4043   }</span>
<span class="line-added">4044 </span>
<span class="line-added">4045  // Vector AES Counter implementation</span>
<span class="line-added">4046   address generate_counterMode_VectorAESCrypt()  {</span>
<span class="line-added">4047     __ align(CodeEntryAlignment);</span>
<span class="line-added">4048     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;counterMode_AESCrypt&quot;);</span>
<span class="line-added">4049     address start = __ pc();</span>
<span class="line-added">4050     const Register from = c_rarg0; // source array address</span>
<span class="line-added">4051     const Register to = c_rarg1; // destination array address</span>
<span class="line-added">4052     const Register key = c_rarg2; // key array address r8</span>
<span class="line-added">4053     const Register counter = c_rarg3; // counter byte array initialized from counter array address</span>
<span class="line-added">4054     // and updated with the incremented counter in the end</span>
<span class="line-added">4055 #ifndef _WIN64</span>
<span class="line-added">4056     const Register len_reg = c_rarg4;</span>
<span class="line-added">4057     const Register saved_encCounter_start = c_rarg5;</span>
<span class="line-added">4058     const Register used_addr = r10;</span>
<span class="line-added">4059     const Address  used_mem(rbp, 2 * wordSize);</span>
<span class="line-added">4060     const Register used = r11;</span>
<span class="line-added">4061 #else</span>
<span class="line-added">4062     const Address len_mem(rbp, 6 * wordSize); // length is on stack on Win64</span>
<span class="line-added">4063     const Address saved_encCounter_mem(rbp, 7 * wordSize); // saved encrypted counter is on stack on Win64</span>
<span class="line-added">4064     const Address used_mem(rbp, 8 * wordSize); // used length is on stack on Win64</span>
<span class="line-added">4065     const Register len_reg = r10; // pick the first volatile windows register</span>
<span class="line-added">4066     const Register saved_encCounter_start = r11;</span>
<span class="line-added">4067     const Register used_addr = r13;</span>
<span class="line-added">4068     const Register used = r14;</span>
<span class="line-added">4069 #endif</span>
<span class="line-added">4070     __ enter();</span>
<span class="line-added">4071    // Save state before entering routine</span>
<span class="line-added">4072     __ push(r12);</span>
<span class="line-added">4073     __ push(r13);</span>
<span class="line-added">4074     __ push(r14);</span>
<span class="line-added">4075     __ push(r15);</span>
<span class="line-added">4076 #ifdef _WIN64</span>
<span class="line-added">4077     // on win64, fill len_reg from stack position</span>
<span class="line-added">4078     __ movl(len_reg, len_mem);</span>
<span class="line-added">4079     __ movptr(saved_encCounter_start, saved_encCounter_mem);</span>
<span class="line-added">4080     __ movptr(used_addr, used_mem);</span>
<span class="line-added">4081     __ movl(used, Address(used_addr, 0));</span>
<span class="line-added">4082 #else</span>
<span class="line-added">4083     __ push(len_reg); // Save</span>
<span class="line-added">4084     __ movptr(used_addr, used_mem);</span>
<span class="line-added">4085     __ movl(used, Address(used_addr, 0));</span>
<span class="line-added">4086 #endif</span>
<span class="line-added">4087     __ push(rbx);</span>
<span class="line-added">4088     __ aesctr_encrypt(from, to, key, counter, len_reg, used, used_addr, saved_encCounter_start);</span>
<span class="line-added">4089     // Restore state before leaving routine</span>
<span class="line-added">4090     __ pop(rbx);</span>
<span class="line-added">4091 #ifdef _WIN64</span>
<span class="line-added">4092     __ movl(rax, len_mem); // return length</span>
<span class="line-added">4093 #else</span>
<span class="line-added">4094     __ pop(rax); // return length</span>
<span class="line-added">4095 #endif</span>
<span class="line-added">4096     __ pop(r15);</span>
<span class="line-added">4097     __ pop(r14);</span>
<span class="line-added">4098     __ pop(r13);</span>
<span class="line-added">4099     __ pop(r12);</span>
<span class="line-added">4100 </span>
<span class="line-added">4101     __ leave(); // required for proper stackwalking of RuntimeStub frame</span>
<span class="line-added">4102     __ ret(0);</span>
<span class="line-added">4103     return start;</span>
<span class="line-added">4104   }</span>
<span class="line-added">4105 </span>
4106   // This is a version of CTR/AES crypt which does 6 blocks in a loop at a time
4107   // to hide instruction latency
4108   //
4109   // Arguments:
4110   //
4111   // Inputs:
4112   //   c_rarg0   - source byte array address
4113   //   c_rarg1   - destination byte array address
4114   //   c_rarg2   - K (key) in little endian int array
4115   //   c_rarg3   - counter vector byte array address
4116   //   Linux
4117   //     c_rarg4   -          input length
4118   //     c_rarg5   -          saved encryptedCounter start
4119   //     rbp + 6 * wordSize - saved used length
4120   //   Windows
4121   //     rbp + 6 * wordSize - input length
4122   //     rbp + 7 * wordSize - saved encryptedCounter start
4123   //     rbp + 8 * wordSize - saved used length
4124   //
4125   // Output:
</pre>
<hr />
<pre>
5677     __ enter(); // required for proper stackwalking of RuntimeStub frame
5678 
5679     setup_arg_regs(4); // out =&gt; rdi, in =&gt; rsi, offset =&gt; rdx
5680                        // len =&gt; rcx, k =&gt; r8
5681                        // r9 and r10 may be used to save non-volatile registers
5682 #ifdef _WIN64
5683     // last argument is on stack on Win64
5684     __ movl(k, Address(rsp, 6 * wordSize));
5685 #endif
5686     __ movptr(r11, rdx);  // move offset in rdx to offset(r11)
5687     __ mul_add(out, in, offset, len, k, tmp1, tmp2, tmp3, tmp4, tmp5, rdx, rax);
5688 
5689     restore_arg_regs();
5690 
5691     __ leave(); // required for proper stackwalking of RuntimeStub frame
5692     __ ret(0);
5693 
5694     return start;
5695   }
5696 
<span class="line-added">5697   address generate_bigIntegerRightShift() {</span>
<span class="line-added">5698     __ align(CodeEntryAlignment);</span>
<span class="line-added">5699     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;bigIntegerRightShiftWorker&quot;);</span>
<span class="line-added">5700 </span>
<span class="line-added">5701     address start = __ pc();</span>
<span class="line-added">5702     Label Shift512Loop, ShiftTwo, ShiftTwoLoop, ShiftOne, Exit;</span>
<span class="line-added">5703     // For Unix, the arguments are as follows: rdi, rsi, rdx, rcx, r8.</span>
<span class="line-added">5704     const Register newArr = rdi;</span>
<span class="line-added">5705     const Register oldArr = rsi;</span>
<span class="line-added">5706     const Register newIdx = rdx;</span>
<span class="line-added">5707     const Register shiftCount = rcx;  // It was intentional to have shiftCount in rcx since it is used implicitly for shift.</span>
<span class="line-added">5708     const Register totalNumIter = r8;</span>
<span class="line-added">5709 </span>
<span class="line-added">5710     // For windows, we use r9 and r10 as temps to save rdi and rsi. Thus we cannot allocate them for our temps.</span>
<span class="line-added">5711     // For everything else, we prefer using r9 and r10 since we do not have to save them before use.</span>
<span class="line-added">5712     const Register tmp1 = r11;                    // Caller save.</span>
<span class="line-added">5713     const Register tmp2 = rax;                    // Caller save.</span>
<span class="line-added">5714     const Register tmp3 = WINDOWS_ONLY(r12) NOT_WINDOWS(r9);   // Windows: Callee save. Linux: Caller save.</span>
<span class="line-added">5715     const Register tmp4 = WINDOWS_ONLY(r13) NOT_WINDOWS(r10);  // Windows: Callee save. Linux: Caller save.</span>
<span class="line-added">5716     const Register tmp5 = r14;                    // Callee save.</span>
<span class="line-added">5717     const Register tmp6 = r15;</span>
<span class="line-added">5718 </span>
<span class="line-added">5719     const XMMRegister x0 = xmm0;</span>
<span class="line-added">5720     const XMMRegister x1 = xmm1;</span>
<span class="line-added">5721     const XMMRegister x2 = xmm2;</span>
<span class="line-added">5722 </span>
<span class="line-added">5723     BLOCK_COMMENT(&quot;Entry:&quot;);</span>
<span class="line-added">5724     __ enter(); // required for proper stackwalking of RuntimeStub frame</span>
<span class="line-added">5725 </span>
<span class="line-added">5726 #ifdef _WINDOWS</span>
<span class="line-added">5727     setup_arg_regs(4);</span>
<span class="line-added">5728     // For windows, since last argument is on stack, we need to move it to the appropriate register.</span>
<span class="line-added">5729     __ movl(totalNumIter, Address(rsp, 6 * wordSize));</span>
<span class="line-added">5730     // Save callee save registers.</span>
<span class="line-added">5731     __ push(tmp3);</span>
<span class="line-added">5732     __ push(tmp4);</span>
<span class="line-added">5733 #endif</span>
<span class="line-added">5734     __ push(tmp5);</span>
<span class="line-added">5735 </span>
<span class="line-added">5736     // Rename temps used throughout the code.</span>
<span class="line-added">5737     const Register idx = tmp1;</span>
<span class="line-added">5738     const Register nIdx = tmp2;</span>
<span class="line-added">5739 </span>
<span class="line-added">5740     __ xorl(idx, idx);</span>
<span class="line-added">5741 </span>
<span class="line-added">5742     // Start right shift from end of the array.</span>
<span class="line-added">5743     // For example, if #iteration = 4 and newIdx = 1</span>
<span class="line-added">5744     // then dest[4] = src[4] &gt;&gt; shiftCount  | src[3] &lt;&lt;&lt; (shiftCount - 32)</span>
<span class="line-added">5745     // if #iteration = 4 and newIdx = 0</span>
<span class="line-added">5746     // then dest[3] = src[4] &gt;&gt; shiftCount  | src[3] &lt;&lt;&lt; (shiftCount - 32)</span>
<span class="line-added">5747     __ movl(idx, totalNumIter);</span>
<span class="line-added">5748     __ movl(nIdx, idx);</span>
<span class="line-added">5749     __ addl(nIdx, newIdx);</span>
<span class="line-added">5750 </span>
<span class="line-added">5751     // If vectorization is enabled, check if the number of iterations is at least 64</span>
<span class="line-added">5752     // If not, then go to ShifTwo processing 2 iterations</span>
<span class="line-added">5753     if (VM_Version::supports_vbmi2()) {</span>
<span class="line-added">5754       __ cmpptr(totalNumIter, (AVX3Threshold/64));</span>
<span class="line-added">5755       __ jcc(Assembler::less, ShiftTwo);</span>
<span class="line-added">5756 </span>
<span class="line-added">5757       if (AVX3Threshold &lt; 16 * 64) {</span>
<span class="line-added">5758         __ cmpl(totalNumIter, 16);</span>
<span class="line-added">5759         __ jcc(Assembler::less, ShiftTwo);</span>
<span class="line-added">5760       }</span>
<span class="line-added">5761       __ evpbroadcastd(x0, shiftCount, Assembler::AVX_512bit);</span>
<span class="line-added">5762       __ subl(idx, 16);</span>
<span class="line-added">5763       __ subl(nIdx, 16);</span>
<span class="line-added">5764       __ BIND(Shift512Loop);</span>
<span class="line-added">5765       __ evmovdqul(x2, Address(oldArr, idx, Address::times_4, 4), Assembler::AVX_512bit);</span>
<span class="line-added">5766       __ evmovdqul(x1, Address(oldArr, idx, Address::times_4), Assembler::AVX_512bit);</span>
<span class="line-added">5767       __ vpshrdvd(x2, x1, x0, Assembler::AVX_512bit);</span>
<span class="line-added">5768       __ evmovdqul(Address(newArr, nIdx, Address::times_4), x2, Assembler::AVX_512bit);</span>
<span class="line-added">5769       __ subl(nIdx, 16);</span>
<span class="line-added">5770       __ subl(idx, 16);</span>
<span class="line-added">5771       __ jcc(Assembler::greaterEqual, Shift512Loop);</span>
<span class="line-added">5772       __ addl(idx, 16);</span>
<span class="line-added">5773       __ addl(nIdx, 16);</span>
<span class="line-added">5774     }</span>
<span class="line-added">5775     __ BIND(ShiftTwo);</span>
<span class="line-added">5776     __ cmpl(idx, 2);</span>
<span class="line-added">5777     __ jcc(Assembler::less, ShiftOne);</span>
<span class="line-added">5778     __ subl(idx, 2);</span>
<span class="line-added">5779     __ subl(nIdx, 2);</span>
<span class="line-added">5780     __ BIND(ShiftTwoLoop);</span>
<span class="line-added">5781     __ movl(tmp5, Address(oldArr, idx, Address::times_4, 8));</span>
<span class="line-added">5782     __ movl(tmp4, Address(oldArr, idx, Address::times_4, 4));</span>
<span class="line-added">5783     __ movl(tmp3, Address(oldArr, idx, Address::times_4));</span>
<span class="line-added">5784     __ shrdl(tmp5, tmp4);</span>
<span class="line-added">5785     __ shrdl(tmp4, tmp3);</span>
<span class="line-added">5786     __ movl(Address(newArr, nIdx, Address::times_4, 4), tmp5);</span>
<span class="line-added">5787     __ movl(Address(newArr, nIdx, Address::times_4), tmp4);</span>
<span class="line-added">5788     __ subl(nIdx, 2);</span>
<span class="line-added">5789     __ subl(idx, 2);</span>
<span class="line-added">5790     __ jcc(Assembler::greaterEqual, ShiftTwoLoop);</span>
<span class="line-added">5791     __ addl(idx, 2);</span>
<span class="line-added">5792     __ addl(nIdx, 2);</span>
<span class="line-added">5793 </span>
<span class="line-added">5794     // Do the last iteration</span>
<span class="line-added">5795     __ BIND(ShiftOne);</span>
<span class="line-added">5796     __ cmpl(idx, 1);</span>
<span class="line-added">5797     __ jcc(Assembler::less, Exit);</span>
<span class="line-added">5798     __ subl(idx, 1);</span>
<span class="line-added">5799     __ subl(nIdx, 1);</span>
<span class="line-added">5800     __ movl(tmp4, Address(oldArr, idx, Address::times_4, 4));</span>
<span class="line-added">5801     __ movl(tmp3, Address(oldArr, idx, Address::times_4));</span>
<span class="line-added">5802     __ shrdl(tmp4, tmp3);</span>
<span class="line-added">5803     __ movl(Address(newArr, nIdx, Address::times_4), tmp4);</span>
<span class="line-added">5804     __ BIND(Exit);</span>
<span class="line-added">5805     // Restore callee save registers.</span>
<span class="line-added">5806     __ pop(tmp5);</span>
<span class="line-added">5807 #ifdef _WINDOWS</span>
<span class="line-added">5808     __ pop(tmp4);</span>
<span class="line-added">5809     __ pop(tmp3);</span>
<span class="line-added">5810     restore_arg_regs();</span>
<span class="line-added">5811 #endif</span>
<span class="line-added">5812     __ leave(); // required for proper stackwalking of RuntimeStub frame</span>
<span class="line-added">5813     __ ret(0);</span>
<span class="line-added">5814     return start;</span>
<span class="line-added">5815   }</span>
<span class="line-added">5816 </span>
<span class="line-added">5817    /**</span>
<span class="line-added">5818    *  Arguments:</span>
<span class="line-added">5819    *</span>
<span class="line-added">5820    *  Input:</span>
<span class="line-added">5821    *    c_rarg0   - newArr address</span>
<span class="line-added">5822    *    c_rarg1   - oldArr address</span>
<span class="line-added">5823    *    c_rarg2   - newIdx</span>
<span class="line-added">5824    *    c_rarg3   - shiftCount</span>
<span class="line-added">5825    * not Win64</span>
<span class="line-added">5826    *    c_rarg4   - numIter</span>
<span class="line-added">5827    * Win64</span>
<span class="line-added">5828    *    rsp40    - numIter</span>
<span class="line-added">5829    */</span>
<span class="line-added">5830   address generate_bigIntegerLeftShift() {</span>
<span class="line-added">5831     __ align(CodeEntryAlignment);</span>
<span class="line-added">5832     StubCodeMark mark(this,  &quot;StubRoutines&quot;, &quot;bigIntegerLeftShiftWorker&quot;);</span>
<span class="line-added">5833     address start = __ pc();</span>
<span class="line-added">5834     Label Shift512Loop, ShiftTwo, ShiftTwoLoop, ShiftOne, Exit;</span>
<span class="line-added">5835     // For Unix, the arguments are as follows: rdi, rsi, rdx, rcx, r8.</span>
<span class="line-added">5836     const Register newArr = rdi;</span>
<span class="line-added">5837     const Register oldArr = rsi;</span>
<span class="line-added">5838     const Register newIdx = rdx;</span>
<span class="line-added">5839     const Register shiftCount = rcx;  // It was intentional to have shiftCount in rcx since it is used implicitly for shift.</span>
<span class="line-added">5840     const Register totalNumIter = r8;</span>
<span class="line-added">5841     // For windows, we use r9 and r10 as temps to save rdi and rsi. Thus we cannot allocate them for our temps.</span>
<span class="line-added">5842     // For everything else, we prefer using r9 and r10 since we do not have to save them before use.</span>
<span class="line-added">5843     const Register tmp1 = r11;                    // Caller save.</span>
<span class="line-added">5844     const Register tmp2 = rax;                    // Caller save.</span>
<span class="line-added">5845     const Register tmp3 = WINDOWS_ONLY(r12) NOT_WINDOWS(r9);   // Windows: Callee save. Linux: Caller save.</span>
<span class="line-added">5846     const Register tmp4 = WINDOWS_ONLY(r13) NOT_WINDOWS(r10);  // Windows: Callee save. Linux: Caller save.</span>
<span class="line-added">5847     const Register tmp5 = r14;                    // Callee save.</span>
<span class="line-added">5848 </span>
<span class="line-added">5849     const XMMRegister x0 = xmm0;</span>
<span class="line-added">5850     const XMMRegister x1 = xmm1;</span>
<span class="line-added">5851     const XMMRegister x2 = xmm2;</span>
<span class="line-added">5852     BLOCK_COMMENT(&quot;Entry:&quot;);</span>
<span class="line-added">5853     __ enter(); // required for proper stackwalking of RuntimeStub frame</span>
<span class="line-added">5854 </span>
<span class="line-added">5855 #ifdef _WINDOWS</span>
<span class="line-added">5856     setup_arg_regs(4);</span>
<span class="line-added">5857     // For windows, since last argument is on stack, we need to move it to the appropriate register.</span>
<span class="line-added">5858     __ movl(totalNumIter, Address(rsp, 6 * wordSize));</span>
<span class="line-added">5859     // Save callee save registers.</span>
<span class="line-added">5860     __ push(tmp3);</span>
<span class="line-added">5861     __ push(tmp4);</span>
<span class="line-added">5862 #endif</span>
<span class="line-added">5863     __ push(tmp5);</span>
<span class="line-added">5864 </span>
<span class="line-added">5865     // Rename temps used throughout the code</span>
<span class="line-added">5866     const Register idx = tmp1;</span>
<span class="line-added">5867     const Register numIterTmp = tmp2;</span>
<span class="line-added">5868 </span>
<span class="line-added">5869     // Start idx from zero.</span>
<span class="line-added">5870     __ xorl(idx, idx);</span>
<span class="line-added">5871     // Compute interior pointer for new array. We do this so that we can use same index for both old and new arrays.</span>
<span class="line-added">5872     __ lea(newArr, Address(newArr, newIdx, Address::times_4));</span>
<span class="line-added">5873     __ movl(numIterTmp, totalNumIter);</span>
<span class="line-added">5874 </span>
<span class="line-added">5875     // If vectorization is enabled, check if the number of iterations is at least 64</span>
<span class="line-added">5876     // If not, then go to ShiftTwo shifting two numbers at a time</span>
<span class="line-added">5877     if (VM_Version::supports_vbmi2()) {</span>
<span class="line-added">5878       __ cmpl(totalNumIter, (AVX3Threshold/64));</span>
<span class="line-added">5879       __ jcc(Assembler::less, ShiftTwo);</span>
<span class="line-added">5880 </span>
<span class="line-added">5881       if (AVX3Threshold &lt; 16 * 64) {</span>
<span class="line-added">5882         __ cmpl(totalNumIter, 16);</span>
<span class="line-added">5883         __ jcc(Assembler::less, ShiftTwo);</span>
<span class="line-added">5884       }</span>
<span class="line-added">5885       __ evpbroadcastd(x0, shiftCount, Assembler::AVX_512bit);</span>
<span class="line-added">5886       __ subl(numIterTmp, 16);</span>
<span class="line-added">5887       __ BIND(Shift512Loop);</span>
<span class="line-added">5888       __ evmovdqul(x1, Address(oldArr, idx, Address::times_4), Assembler::AVX_512bit);</span>
<span class="line-added">5889       __ evmovdqul(x2, Address(oldArr, idx, Address::times_4, 0x4), Assembler::AVX_512bit);</span>
<span class="line-added">5890       __ vpshldvd(x1, x2, x0, Assembler::AVX_512bit);</span>
<span class="line-added">5891       __ evmovdqul(Address(newArr, idx, Address::times_4), x1, Assembler::AVX_512bit);</span>
<span class="line-added">5892       __ addl(idx, 16);</span>
<span class="line-added">5893       __ subl(numIterTmp, 16);</span>
<span class="line-added">5894       __ jcc(Assembler::greaterEqual, Shift512Loop);</span>
<span class="line-added">5895       __ addl(numIterTmp, 16);</span>
<span class="line-added">5896     }</span>
<span class="line-added">5897     __ BIND(ShiftTwo);</span>
<span class="line-added">5898     __ cmpl(totalNumIter, 1);</span>
<span class="line-added">5899     __ jcc(Assembler::less, Exit);</span>
<span class="line-added">5900     __ movl(tmp3, Address(oldArr, idx, Address::times_4));</span>
<span class="line-added">5901     __ subl(numIterTmp, 2);</span>
<span class="line-added">5902     __ jcc(Assembler::less, ShiftOne);</span>
<span class="line-added">5903 </span>
<span class="line-added">5904     __ BIND(ShiftTwoLoop);</span>
<span class="line-added">5905     __ movl(tmp4, Address(oldArr, idx, Address::times_4, 0x4));</span>
<span class="line-added">5906     __ movl(tmp5, Address(oldArr, idx, Address::times_4, 0x8));</span>
<span class="line-added">5907     __ shldl(tmp3, tmp4);</span>
<span class="line-added">5908     __ shldl(tmp4, tmp5);</span>
<span class="line-added">5909     __ movl(Address(newArr, idx, Address::times_4), tmp3);</span>
<span class="line-added">5910     __ movl(Address(newArr, idx, Address::times_4, 0x4), tmp4);</span>
<span class="line-added">5911     __ movl(tmp3, tmp5);</span>
<span class="line-added">5912     __ addl(idx, 2);</span>
<span class="line-added">5913     __ subl(numIterTmp, 2);</span>
<span class="line-added">5914     __ jcc(Assembler::greaterEqual, ShiftTwoLoop);</span>
<span class="line-added">5915 </span>
<span class="line-added">5916     // Do the last iteration</span>
<span class="line-added">5917     __ BIND(ShiftOne);</span>
<span class="line-added">5918     __ addl(numIterTmp, 2);</span>
<span class="line-added">5919     __ cmpl(numIterTmp, 1);</span>
<span class="line-added">5920     __ jcc(Assembler::less, Exit);</span>
<span class="line-added">5921     __ movl(tmp4, Address(oldArr, idx, Address::times_4, 0x4));</span>
<span class="line-added">5922     __ shldl(tmp3, tmp4);</span>
<span class="line-added">5923     __ movl(Address(newArr, idx, Address::times_4), tmp3);</span>
<span class="line-added">5924 </span>
<span class="line-added">5925     __ BIND(Exit);</span>
<span class="line-added">5926     // Restore callee save registers.</span>
<span class="line-added">5927     __ pop(tmp5);</span>
<span class="line-added">5928 #ifdef _WINDOWS</span>
<span class="line-added">5929     __ pop(tmp4);</span>
<span class="line-added">5930     __ pop(tmp3);</span>
<span class="line-added">5931     restore_arg_regs();</span>
<span class="line-added">5932 #endif</span>
<span class="line-added">5933     __ leave(); // required for proper stackwalking of RuntimeStub frame</span>
<span class="line-added">5934     __ ret(0);</span>
<span class="line-added">5935     return start;</span>
<span class="line-added">5936   }</span>
<span class="line-added">5937 </span>
5938   address generate_libmExp() {
5939     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;libmExp&quot;);
5940 
5941     address start = __ pc();
5942 
5943     const XMMRegister x0  = xmm0;
5944     const XMMRegister x1  = xmm1;
5945     const XMMRegister x2  = xmm2;
5946     const XMMRegister x3  = xmm3;
5947 
5948     const XMMRegister x4  = xmm4;
5949     const XMMRegister x5  = xmm5;
5950     const XMMRegister x6  = xmm6;
5951     const XMMRegister x7  = xmm7;
5952 
5953     const Register tmp   = r11;
5954 
5955     BLOCK_COMMENT(&quot;Entry:&quot;);
5956     __ enter(); // required for proper stackwalking of RuntimeStub frame
5957 
</pre>
<hr />
<pre>
6324 
6325     // is referenced by megamorphic call
6326     StubRoutines::_catch_exception_entry = generate_catch_exception();
6327 
6328     // atomic calls
6329     StubRoutines::_atomic_xchg_entry          = generate_atomic_xchg();
6330     StubRoutines::_atomic_xchg_long_entry     = generate_atomic_xchg_long();
6331     StubRoutines::_atomic_cmpxchg_entry       = generate_atomic_cmpxchg();
6332     StubRoutines::_atomic_cmpxchg_byte_entry  = generate_atomic_cmpxchg_byte();
6333     StubRoutines::_atomic_cmpxchg_long_entry  = generate_atomic_cmpxchg_long();
6334     StubRoutines::_atomic_add_entry           = generate_atomic_add();
6335     StubRoutines::_atomic_add_long_entry      = generate_atomic_add_long();
6336     StubRoutines::_fence_entry                = generate_orderaccess_fence();
6337 
6338     // platform dependent
6339     StubRoutines::x86::_get_previous_fp_entry = generate_get_previous_fp();
6340     StubRoutines::x86::_get_previous_sp_entry = generate_get_previous_sp();
6341 
6342     StubRoutines::x86::_verify_mxcsr_entry    = generate_verify_mxcsr();
6343 
<span class="line-added">6344     StubRoutines::x86::_f2i_fixup             = generate_f2i_fixup();</span>
<span class="line-added">6345     StubRoutines::x86::_f2l_fixup             = generate_f2l_fixup();</span>
<span class="line-added">6346     StubRoutines::x86::_d2i_fixup             = generate_d2i_fixup();</span>
<span class="line-added">6347     StubRoutines::x86::_d2l_fixup             = generate_d2l_fixup();</span>
<span class="line-added">6348 </span>
<span class="line-added">6349     StubRoutines::x86::_float_sign_mask       = generate_fp_mask(&quot;float_sign_mask&quot;,  0x7FFFFFFF7FFFFFFF);</span>
<span class="line-added">6350     StubRoutines::x86::_float_sign_flip       = generate_fp_mask(&quot;float_sign_flip&quot;,  0x8000000080000000);</span>
<span class="line-added">6351     StubRoutines::x86::_double_sign_mask      = generate_fp_mask(&quot;double_sign_mask&quot;, 0x7FFFFFFFFFFFFFFF);</span>
<span class="line-added">6352     StubRoutines::x86::_double_sign_flip      = generate_fp_mask(&quot;double_sign_flip&quot;, 0x8000000000000000);</span>
<span class="line-added">6353 </span>
6354     // Build this early so it&#39;s available for the interpreter.
6355     StubRoutines::_throw_StackOverflowError_entry =
6356       generate_throw_exception(&quot;StackOverflowError throw_exception&quot;,
6357                                CAST_FROM_FN_PTR(address,
6358                                                 SharedRuntime::
6359                                                 throw_StackOverflowError));
6360     StubRoutines::_throw_delayed_StackOverflowError_entry =
6361       generate_throw_exception(&quot;delayed StackOverflowError throw_exception&quot;,
6362                                CAST_FROM_FN_PTR(address,
6363                                                 SharedRuntime::
6364                                                 throw_delayed_StackOverflowError));
6365     if (UseCRC32Intrinsics) {
6366       // set table address before stub generation which use it
6367       StubRoutines::_crc_table_adr = (address)StubRoutines::x86::_crc_table;
6368       StubRoutines::_updateBytesCRC32 = generate_updateBytesCRC32();
6369     }
6370 
6371     if (UseCRC32CIntrinsics) {
6372       bool supports_clmul = VM_Version::supports_clmul();
6373       StubRoutines::x86::generate_CRC32C_table(supports_clmul);
6374       StubRoutines::_crc32c_table_addr = (address)StubRoutines::x86::_crc32c_table;
6375       StubRoutines::_updateBytesCRC32C = generate_updateBytesCRC32C(supports_clmul);
6376     }
<span class="line-modified">6377     if (UseLibmIntrinsic &amp;&amp; InlineIntrinsics) {</span>
6378       if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dsin) ||
6379           vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dcos) ||
6380           vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dtan)) {
6381         StubRoutines::x86::_ONEHALF_adr = (address)StubRoutines::x86::_ONEHALF;
6382         StubRoutines::x86::_P_2_adr = (address)StubRoutines::x86::_P_2;
6383         StubRoutines::x86::_SC_4_adr = (address)StubRoutines::x86::_SC_4;
6384         StubRoutines::x86::_Ctable_adr = (address)StubRoutines::x86::_Ctable;
6385         StubRoutines::x86::_SC_2_adr = (address)StubRoutines::x86::_SC_2;
6386         StubRoutines::x86::_SC_3_adr = (address)StubRoutines::x86::_SC_3;
6387         StubRoutines::x86::_SC_1_adr = (address)StubRoutines::x86::_SC_1;
6388         StubRoutines::x86::_PI_INV_TABLE_adr = (address)StubRoutines::x86::_PI_INV_TABLE;
6389         StubRoutines::x86::_PI_4_adr = (address)StubRoutines::x86::_PI_4;
6390         StubRoutines::x86::_PI32INV_adr = (address)StubRoutines::x86::_PI32INV;
6391         StubRoutines::x86::_SIGN_MASK_adr = (address)StubRoutines::x86::_SIGN_MASK;
6392         StubRoutines::x86::_P_1_adr = (address)StubRoutines::x86::_P_1;
6393         StubRoutines::x86::_P_3_adr = (address)StubRoutines::x86::_P_3;
6394         StubRoutines::x86::_NEG_ZERO_adr = (address)StubRoutines::x86::_NEG_ZERO;
6395       }
6396       if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dexp)) {
6397         StubRoutines::_dexp = generate_libmExp();
</pre>
<hr />
<pre>
6425     // fabricate a RuntimeStub internally.
6426     StubRoutines::_throw_AbstractMethodError_entry =
6427       generate_throw_exception(&quot;AbstractMethodError throw_exception&quot;,
6428                                CAST_FROM_FN_PTR(address,
6429                                                 SharedRuntime::
6430                                                 throw_AbstractMethodError));
6431 
6432     StubRoutines::_throw_IncompatibleClassChangeError_entry =
6433       generate_throw_exception(&quot;IncompatibleClassChangeError throw_exception&quot;,
6434                                CAST_FROM_FN_PTR(address,
6435                                                 SharedRuntime::
6436                                                 throw_IncompatibleClassChangeError));
6437 
6438     StubRoutines::_throw_NullPointerException_at_call_entry =
6439       generate_throw_exception(&quot;NullPointerException at call throw_exception&quot;,
6440                                CAST_FROM_FN_PTR(address,
6441                                                 SharedRuntime::
6442                                                 throw_NullPointerException_at_call));
6443 
6444     // entry points that are platform specific
<span class="line-modified">6445     StubRoutines::x86::_vector_float_sign_mask = generate_vector_mask(&quot;vector_float_sign_mask&quot;, 0x7FFFFFFF7FFFFFFF);</span>
<span class="line-modified">6446     StubRoutines::x86::_vector_float_sign_flip = generate_vector_mask(&quot;vector_float_sign_flip&quot;, 0x8000000080000000);</span>
<span class="line-modified">6447     StubRoutines::x86::_vector_double_sign_mask = generate_vector_mask(&quot;vector_double_sign_mask&quot;, 0x7FFFFFFFFFFFFFFF);</span>
<span class="line-modified">6448     StubRoutines::x86::_vector_double_sign_flip = generate_vector_mask(&quot;vector_double_sign_flip&quot;, 0x8000000000000000);</span>
<span class="line-modified">6449     StubRoutines::x86::_vector_short_to_byte_mask = generate_vector_mask(&quot;vector_short_to_byte_mask&quot;, 0x00ff00ff00ff00ff);</span>
<span class="line-modified">6450     StubRoutines::x86::_vector_byte_perm_mask = generate_vector_byte_perm_mask(&quot;vector_byte_perm_mask&quot;);</span>
<span class="line-modified">6451     StubRoutines::x86::_vector_long_sign_mask = generate_vector_mask(&quot;vector_long_sign_mask&quot;, 0x8000000000000000);</span>


6452 
6453     // support for verify_oop (must happen after universe_init)
6454     StubRoutines::_verify_oop_subroutine_entry = generate_verify_oop();
6455 
<span class="line-added">6456     // data cache line writeback</span>
<span class="line-added">6457     StubRoutines::_data_cache_writeback = generate_data_cache_writeback();</span>
<span class="line-added">6458     StubRoutines::_data_cache_writeback_sync = generate_data_cache_writeback_sync();</span>
<span class="line-added">6459 </span>
6460     // arraycopy stubs used by compilers
6461     generate_arraycopy_stubs();
6462 
6463     // don&#39;t bother generating these AES intrinsic stubs unless global flag is set
6464     if (UseAESIntrinsics) {
6465       StubRoutines::x86::_key_shuffle_mask_addr = generate_key_shuffle_mask();  // needed by the others
6466       StubRoutines::_aescrypt_encryptBlock = generate_aescrypt_encryptBlock();
6467       StubRoutines::_aescrypt_decryptBlock = generate_aescrypt_decryptBlock();
6468       StubRoutines::_cipherBlockChaining_encryptAESCrypt = generate_cipherBlockChaining_encryptAESCrypt();
6469       if (VM_Version::supports_vaes() &amp;&amp;  VM_Version::supports_avx512vl() &amp;&amp; VM_Version::supports_avx512dq() ) {
6470         StubRoutines::_cipherBlockChaining_decryptAESCrypt = generate_cipherBlockChaining_decryptVectorAESCrypt();
<span class="line-added">6471         StubRoutines::_electronicCodeBook_encryptAESCrypt = generate_electronicCodeBook_encryptAESCrypt();</span>
<span class="line-added">6472         StubRoutines::_electronicCodeBook_decryptAESCrypt = generate_electronicCodeBook_decryptAESCrypt();</span>
6473       } else {
6474         StubRoutines::_cipherBlockChaining_decryptAESCrypt = generate_cipherBlockChaining_decryptAESCrypt_Parallel();
6475       }
6476     }
<span class="line-modified">6477     if (UseAESCTRIntrinsics) {</span>
<span class="line-modified">6478       if (VM_Version::supports_vaes() &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; VM_Version::supports_avx512vl()) {</span>
<span class="line-modified">6479         StubRoutines::x86::_counter_mask_addr = counter_mask_addr();</span>
<span class="line-added">6480         StubRoutines::_counterMode_AESCrypt = generate_counterMode_VectorAESCrypt();</span>
<span class="line-added">6481       } else {</span>
<span class="line-added">6482         StubRoutines::x86::_counter_shuffle_mask_addr = generate_counter_shuffle_mask();</span>
<span class="line-added">6483         StubRoutines::_counterMode_AESCrypt = generate_counterMode_AESCrypt_Parallel();</span>
<span class="line-added">6484       }</span>
6485     }
6486 
6487     if (UseSHA1Intrinsics) {
6488       StubRoutines::x86::_upper_word_mask_addr = generate_upper_word_mask();
6489       StubRoutines::x86::_shuffle_byte_flip_mask_addr = generate_shuffle_byte_flip_mask();
6490       StubRoutines::_sha1_implCompress = generate_sha1_implCompress(false, &quot;sha1_implCompress&quot;);
6491       StubRoutines::_sha1_implCompressMB = generate_sha1_implCompress(true, &quot;sha1_implCompressMB&quot;);
6492     }
6493     if (UseSHA256Intrinsics) {
6494       StubRoutines::x86::_k256_adr = (address)StubRoutines::x86::_k256;
6495       char* dst = (char*)StubRoutines::x86::_k256_W;
6496       char* src = (char*)StubRoutines::x86::_k256;
6497       for (int ii = 0; ii &lt; 16; ++ii) {
6498         memcpy(dst + 32 * ii,      src + 16 * ii, 16);
6499         memcpy(dst + 32 * ii + 16, src + 16 * ii, 16);
6500       }
6501       StubRoutines::x86::_k256_W_adr = (address)StubRoutines::x86::_k256_W;
6502       StubRoutines::x86::_pshuffle_byte_flip_mask_addr = generate_pshuffle_byte_flip_mask();
6503       StubRoutines::_sha256_implCompress = generate_sha256_implCompress(false, &quot;sha256_implCompress&quot;);
6504       StubRoutines::_sha256_implCompressMB = generate_sha256_implCompress(true, &quot;sha256_implCompressMB&quot;);
</pre>
<hr />
<pre>
6539                                                        &amp;StubRoutines::_safefetch32_fault_pc,
6540                                                        &amp;StubRoutines::_safefetch32_continuation_pc);
6541     generate_safefetch(&quot;SafeFetchN&quot;, sizeof(intptr_t), &amp;StubRoutines::_safefetchN_entry,
6542                                                        &amp;StubRoutines::_safefetchN_fault_pc,
6543                                                        &amp;StubRoutines::_safefetchN_continuation_pc);
6544 
6545     BarrierSetNMethod* bs_nm = BarrierSet::barrier_set()-&gt;barrier_set_nmethod();
6546     if (bs_nm != NULL) {
6547       StubRoutines::x86::_method_entry_barrier = generate_method_entry_barrier();
6548     }
6549 #ifdef COMPILER2
6550     if (UseMultiplyToLenIntrinsic) {
6551       StubRoutines::_multiplyToLen = generate_multiplyToLen();
6552     }
6553     if (UseSquareToLenIntrinsic) {
6554       StubRoutines::_squareToLen = generate_squareToLen();
6555     }
6556     if (UseMulAddIntrinsic) {
6557       StubRoutines::_mulAdd = generate_mulAdd();
6558     }
<span class="line-added">6559     if (VM_Version::supports_vbmi2()) {</span>
<span class="line-added">6560       StubRoutines::_bigIntegerRightShiftWorker = generate_bigIntegerRightShift();</span>
<span class="line-added">6561       StubRoutines::_bigIntegerLeftShiftWorker = generate_bigIntegerLeftShift();</span>
<span class="line-added">6562     }</span>
6563 #ifndef _WINDOWS
6564     if (UseMontgomeryMultiplyIntrinsic) {
6565       StubRoutines::_montgomeryMultiply
6566         = CAST_FROM_FN_PTR(address, SharedRuntime::montgomery_multiply);
6567     }
6568     if (UseMontgomerySquareIntrinsic) {
6569       StubRoutines::_montgomerySquare
6570         = CAST_FROM_FN_PTR(address, SharedRuntime::montgomery_square);
6571     }
6572 #endif // WINDOWS
6573 #endif // COMPILER2
6574 
6575     if (UseVectorizedMismatchIntrinsic) {
6576       StubRoutines::_vectorizedMismatch = generate_vectorizedMismatch();
6577     }
6578   }
6579 
6580  public:
6581   StubGenerator(CodeBuffer* code, bool all) : StubCodeGenerator(code) {
6582     if (all) {
6583       generate_all();
6584     } else {
6585       generate_initial();
6586     }
6587   }
6588 }; // end class declaration
6589 
<span class="line-added">6590 #define UCM_TABLE_MAX_ENTRIES 16</span>
6591 void StubGenerator_generate(CodeBuffer* code, bool all) {
<span class="line-added">6592   if (UnsafeCopyMemory::_table == NULL) {</span>
<span class="line-added">6593     UnsafeCopyMemory::create_table(UCM_TABLE_MAX_ENTRIES);</span>
<span class="line-added">6594   }</span>
6595   StubGenerator g(code, all);
6596 }
</pre>
</td>
</tr>
</table>
<center><a href="stubGenerator_x86_32.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubRoutines_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>