<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/stubGenerator_x86_32.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="sharedRuntime_x86_64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_x86_64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/stubGenerator_x86_32.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/macroAssembler.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;gc/shared/barrierSet.hpp&quot;
  29 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;

  30 #include &quot;interpreter/interpreter.hpp&quot;

  31 #include &quot;nativeInst_x86.hpp&quot;
  32 #include &quot;oops/instanceOop.hpp&quot;
  33 #include &quot;oops/method.hpp&quot;
  34 #include &quot;oops/objArrayKlass.hpp&quot;
  35 #include &quot;oops/oop.inline.hpp&quot;
  36 #include &quot;prims/methodHandles.hpp&quot;
  37 #include &quot;runtime/frame.inline.hpp&quot;
  38 #include &quot;runtime/handles.inline.hpp&quot;
  39 #include &quot;runtime/sharedRuntime.hpp&quot;
  40 #include &quot;runtime/stubCodeGenerator.hpp&quot;
  41 #include &quot;runtime/stubRoutines.hpp&quot;
  42 #include &quot;runtime/thread.inline.hpp&quot;
  43 #ifdef COMPILER2
  44 #include &quot;opto/runtime.hpp&quot;
  45 #endif
  46 
  47 // Declaration and definition of StubGenerator (no .hpp file).
  48 // For a more detailed description of the stub routine structure
  49 // see the comment in stubRoutines.hpp
  50 
</pre>
<hr />
<pre>
 412       __ jcc(Assembler::notEqual, L);
 413       __ stop(&quot;StubRoutines::forward exception: no pending exception (2)&quot;);
 414       __ bind(L);
 415     }
 416 #endif
 417 
 418     // Verify that there is really a valid exception in RAX.
 419     __ verify_oop(exception_oop);
 420 
 421     // continue at exception handler (return address removed)
 422     // rax: exception
 423     // rbx: exception handler
 424     // rdx: throwing pc
 425     __ jmp(handler_addr);
 426 
 427     return start;
 428   }
 429 
 430 
 431   //----------------------------------------------------------------------------------------------------
<span class="line-modified"> 432   // Support for int32_t Atomic::xchg(int32_t exchange_value, volatile int32_t* dest)</span>

 433   //
 434   // xchg exists as far back as 8086, lock needed for MP only
 435   // Stack layout immediately after call:
 436   //
 437   // 0 [ret addr ] &lt;--- rsp
 438   // 1 [  ex     ]
 439   // 2 [  dest   ]
 440   //
 441   // Result:   *dest &lt;- ex, return (old *dest)
 442   //
 443   // Note: win32 does not currently use this code
 444 
 445   address generate_atomic_xchg() {
 446     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;atomic_xchg&quot;);
 447     address start = __ pc();
 448 
 449     __ push(rdx);
 450     Address exchange(rsp, 2 * wordSize);
 451     Address dest_addr(rsp, 3 * wordSize);
 452     __ movl(rax, exchange);
</pre>
<hr />
<pre>
 585     // Call the C code to massage the double.  Result in EAX
 586     if (t == T_INT)
 587       { BLOCK_COMMENT(&quot;SharedRuntime::d2i&quot;); }
 588     else if (t == T_LONG)
 589       { BLOCK_COMMENT(&quot;SharedRuntime::d2l&quot;); }
 590     __ call_VM_leaf( fcn, 2 );
 591 
 592     // Restore CPU &amp; FPU state
 593     __ pop_FPU_state();
 594     __ pop(rbp);
 595     __ pop(rdi);
 596     __ pop(rsi);
 597     __ pop(rcx);
 598     __ pop(rbx);
 599     __ addptr(rsp, wordSize * 2);
 600 
 601     __ ret(0);
 602 
 603     return start;
 604   }

 605 



















































 606 
 607   //----------------------------------------------------------------------------------------------------
 608   // Non-destructive plausibility checks for oops
 609 
 610   address generate_verify_oop() {
 611     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;verify_oop&quot;);
 612     address start = __ pc();
 613 
 614     // Incoming arguments on stack after saving rax,:
 615     //
 616     // [tos    ]: saved rdx
 617     // [tos + 1]: saved EFLAGS
 618     // [tos + 2]: return address
 619     // [tos + 3]: char* error message
 620     // [tos + 4]: oop   object to verify
 621     // [tos + 5]: saved rax, - saved by caller and bashed
 622 
 623     Label exit, error;
 624     __ pushf();
 625     __ incrementl(ExternalAddress((address) StubRoutines::verify_oop_count_addr()));
</pre>
<hr />
<pre>
 640     // make sure klass is &#39;reasonable&#39;, which is not zero.
 641     __ movptr(rax, Address(rax, oopDesc::klass_offset_in_bytes())); // get klass
 642     __ testptr(rax, rax);
 643     __ jcc(Assembler::zero, error);              // if klass is NULL it is broken
 644 
 645     // return if everything seems ok
 646     __ bind(exit);
 647     __ movptr(rax, Address(rsp, 5 * wordSize));  // get saved rax, back
 648     __ pop(rdx);                                 // restore rdx
 649     __ popf();                                   // restore EFLAGS
 650     __ ret(3 * wordSize);                        // pop arguments
 651 
 652     // handle errors
 653     __ bind(error);
 654     __ movptr(rax, Address(rsp, 5 * wordSize));  // get saved rax, back
 655     __ pop(rdx);                                 // get saved rdx back
 656     __ popf();                                   // get saved EFLAGS off stack -- will be ignored
 657     __ pusha();                                  // push registers (eip = return address &amp; msg are already pushed)
 658     BLOCK_COMMENT(&quot;call MacroAssembler::debug&quot;);
 659     __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, MacroAssembler::debug32)));
<span class="line-modified"> 660     __ popa();</span>
<span class="line-removed"> 661     __ ret(3 * wordSize);                        // pop arguments</span>
 662     return start;
 663   }
 664 
 665 
 666   // Copy 64 bytes chunks
 667   //
 668   // Inputs:
 669   //   from        - source array address
 670   //   to_from     - destination array address - from
 671   //   qword_count - 8-bytes element count, negative
 672   //
 673   void xmm_copy_forward(Register from, Register to_from, Register qword_count) {
 674     assert( UseSSE &gt;= 2, &quot;supported cpu only&quot; );
 675     Label L_copy_64_bytes_loop, L_copy_64_bytes, L_copy_8_bytes, L_exit;
 676 
 677     // Copy 64-byte chunks
 678     __ jmpb(L_copy_64_bytes);
 679     __ align(OptoLoopAlignment);
 680   __ BIND(L_copy_64_bytes_loop);
 681 
</pre>
<hr />
<pre>
 819     if (entry != NULL) {
 820       *entry = __ pc(); // Entry point from conjoint arraycopy stub.
 821       BLOCK_COMMENT(&quot;Entry:&quot;);
 822     }
 823 
 824     if (t == T_OBJECT) {
 825       __ testl(count, count);
 826       __ jcc(Assembler::zero, L_0_count);
 827     }
 828 
 829     DecoratorSet decorators = IN_HEAP | IS_ARRAY | ARRAYCOPY_DISJOINT;
 830     if (dest_uninitialized) {
 831       decorators |= IS_DEST_UNINITIALIZED;
 832     }
 833     if (aligned) {
 834       decorators |= ARRAYCOPY_ALIGNED;
 835     }
 836 
 837     BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
 838     bs-&gt;arraycopy_prologue(_masm, decorators, t, from, to, count);
<span class="line-modified"> 839 </span>
<span class="line-modified"> 840     __ subptr(to, from); // to --&gt; to_from</span>
<span class="line-modified"> 841     __ cmpl(count, 2&lt;&lt;shift); // Short arrays (&lt; 8 bytes) copy by element</span>
<span class="line-modified"> 842     __ jcc(Assembler::below, L_copy_4_bytes); // use unsigned cmp</span>
<span class="line-modified"> 843     if (!UseUnalignedLoadStores &amp;&amp; !aligned &amp;&amp; (t == T_BYTE || t == T_SHORT)) {</span>
<span class="line-modified"> 844       // align source address at 4 bytes address boundary</span>
<span class="line-modified"> 845       if (t == T_BYTE) {</span>
<span class="line-modified"> 846         // One byte misalignment happens only for byte arrays</span>
<span class="line-modified"> 847         __ testl(from, 1);</span>
<span class="line-modified"> 848         __ jccb(Assembler::zero, L_skip_align1);</span>
<span class="line-modified"> 849         __ movb(rax, Address(from, 0));</span>
<span class="line-modified"> 850         __ movb(Address(from, to_from, Address::times_1, 0), rax);</span>
<span class="line-modified"> 851         __ increment(from);</span>
<span class="line-modified"> 852         __ decrement(count);</span>
<span class="line-modified"> 853       __ BIND(L_skip_align1);</span>
<span class="line-modified"> 854       }</span>
<span class="line-modified"> 855       // Two bytes misalignment happens only for byte and short (char) arrays</span>
<span class="line-modified"> 856       __ testl(from, 2);</span>
<span class="line-modified"> 857       __ jccb(Assembler::zero, L_skip_align2);</span>
<span class="line-modified"> 858       __ movw(rax, Address(from, 0));</span>
<span class="line-modified"> 859       __ movw(Address(from, to_from, Address::times_1, 0), rax);</span>
<span class="line-modified"> 860       __ addptr(from, 2);</span>
<span class="line-modified"> 861       __ subl(count, 1&lt;&lt;(shift-1));</span>
<span class="line-modified"> 862     __ BIND(L_skip_align2);</span>
<span class="line-modified"> 863     }</span>
<span class="line-modified"> 864     if (!VM_Version::supports_mmx()) {</span>
<span class="line-modified"> 865       __ mov(rax, count);      // save &#39;count&#39;</span>
<span class="line-removed"> 866       __ shrl(count, shift); // bytes count</span>
<span class="line-removed"> 867       __ addptr(to_from, from);// restore &#39;to&#39;</span>
<span class="line-removed"> 868       __ rep_mov();</span>
<span class="line-removed"> 869       __ subptr(to_from, from);// restore &#39;to_from&#39;</span>
<span class="line-removed"> 870       __ mov(count, rax);      // restore &#39;count&#39;</span>
<span class="line-removed"> 871       __ jmpb(L_copy_2_bytes); // all dwords were copied</span>
<span class="line-removed"> 872     } else {</span>
<span class="line-removed"> 873       if (!UseUnalignedLoadStores) {</span>
<span class="line-removed"> 874         // align to 8 bytes, we know we are 4 byte aligned to start</span>
<span class="line-removed"> 875         __ testptr(from, 4);</span>
<span class="line-removed"> 876         __ jccb(Assembler::zero, L_copy_64_bytes);</span>
<span class="line-removed"> 877         __ movl(rax, Address(from, 0));</span>
<span class="line-removed"> 878         __ movl(Address(from, to_from, Address::times_1, 0), rax);</span>
<span class="line-removed"> 879         __ addptr(from, 4);</span>
<span class="line-removed"> 880         __ subl(count, 1&lt;&lt;shift);</span>
 881       }
<span class="line-modified"> 882     __ BIND(L_copy_64_bytes);</span>
<span class="line-modified"> 883       __ mov(rax, count);</span>
<span class="line-modified"> 884       __ shrl(rax, shift+1);  // 8 bytes chunk count</span>
<span class="line-modified"> 885       //</span>
<span class="line-modified"> 886       // Copy 8-byte chunks through MMX registers, 8 per iteration of the loop</span>
<span class="line-modified"> 887       //</span>
<span class="line-modified"> 888       if (UseXMMForArrayCopy) {</span>
<span class="line-modified"> 889         xmm_copy_forward(from, to_from, rax);</span>
 890       } else {
<span class="line-modified"> 891         mmx_copy_forward(from, to_from, rax);</span>



















 892       }
<span class="line-modified"> 893     }</span>
<span class="line-modified"> 894     // copy tailing dword</span>
<span class="line-modified"> 895   __ BIND(L_copy_4_bytes);</span>
<span class="line-modified"> 896     __ testl(count, 1&lt;&lt;shift);</span>
<span class="line-modified"> 897     __ jccb(Assembler::zero, L_copy_2_bytes);</span>
<span class="line-modified"> 898     __ movl(rax, Address(from, 0));</span>
<span class="line-modified"> 899     __ movl(Address(from, to_from, Address::times_1, 0), rax);</span>
<span class="line-modified"> 900     if (t == T_BYTE || t == T_SHORT) {</span>
<span class="line-modified"> 901       __ addptr(from, 4);</span>
<span class="line-modified"> 902     __ BIND(L_copy_2_bytes);</span>
<span class="line-modified"> 903       // copy tailing word</span>
<span class="line-modified"> 904       __ testl(count, 1&lt;&lt;(shift-1));</span>
<span class="line-modified"> 905       __ jccb(Assembler::zero, L_copy_byte);</span>
<span class="line-modified"> 906       __ movw(rax, Address(from, 0));</span>
<span class="line-modified"> 907       __ movw(Address(from, to_from, Address::times_1, 0), rax);</span>
<span class="line-modified"> 908       if (t == T_BYTE) {</span>
<span class="line-modified"> 909         __ addptr(from, 2);</span>
<span class="line-modified"> 910       __ BIND(L_copy_byte);</span>
<span class="line-modified"> 911         // copy tailing byte</span>
<span class="line-modified"> 912         __ testl(count, 1);</span>
<span class="line-modified"> 913         __ jccb(Assembler::zero, L_exit);</span>
<span class="line-modified"> 914         __ movb(rax, Address(from, 0));</span>
<span class="line-modified"> 915         __ movb(Address(from, to_from, Address::times_1, 0), rax);</span>
<span class="line-modified"> 916       __ BIND(L_exit);</span>


 917       } else {
<span class="line-modified"> 918       __ BIND(L_copy_byte);</span>
 919       }
<span class="line-removed"> 920     } else {</span>
<span class="line-removed"> 921     __ BIND(L_copy_2_bytes);</span>
 922     }
 923 



 924     __ movl(count, Address(rsp, 12+12)); // reread &#39;count&#39;
 925     bs-&gt;arraycopy_epilogue(_masm, decorators, t, from, to, count);
 926 
 927     if (t == T_OBJECT) {
 928     __ BIND(L_0_count);
 929     }
 930     inc_copy_counter_np(t);
 931     __ pop(rdi);
 932     __ pop(rsi);
 933     __ leave(); // required for proper stackwalking of RuntimeStub frame
 934     __ vzeroupper();
 935     __ xorptr(rax, rax); // return 0
 936     __ ret(0);
 937     return start;
 938   }
 939 
 940 
 941   address generate_fill(BasicType t, bool aligned, const char *name) {
 942     __ align(CodeEntryAlignment);
 943     StubCodeMark mark(this, &quot;StubRoutines&quot;, name);
</pre>
<hr />
<pre>
1009     __ jump_cc(Assembler::belowEqual, nooverlap);
1010     __ cmpptr(dst, end);
1011     __ jump_cc(Assembler::aboveEqual, nooverlap);
1012 
1013     if (t == T_OBJECT) {
1014       __ testl(count, count);
1015       __ jcc(Assembler::zero, L_0_count);
1016     }
1017 
1018     DecoratorSet decorators = IN_HEAP | IS_ARRAY;
1019     if (dest_uninitialized) {
1020       decorators |= IS_DEST_UNINITIALIZED;
1021     }
1022     if (aligned) {
1023       decorators |= ARRAYCOPY_ALIGNED;
1024     }
1025 
1026     BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
1027     bs-&gt;arraycopy_prologue(_masm, decorators, t, from, to, count);
1028 
<span class="line-modified">1029     // copy from high to low</span>
<span class="line-modified">1030     __ cmpl(count, 2&lt;&lt;shift); // Short arrays (&lt; 8 bytes) copy by element</span>
<span class="line-modified">1031     __ jcc(Assembler::below, L_copy_4_bytes); // use unsigned cmp</span>
<span class="line-modified">1032     if (t == T_BYTE || t == T_SHORT) {</span>
<span class="line-modified">1033       // Align the end of destination array at 4 bytes address boundary</span>
<span class="line-removed">1034       __ lea(end, Address(dst, count, sf, 0));</span>
<span class="line-removed">1035       if (t == T_BYTE) {</span>
<span class="line-removed">1036         // One byte misalignment happens only for byte arrays</span>
<span class="line-removed">1037         __ testl(end, 1);</span>
<span class="line-removed">1038         __ jccb(Assembler::zero, L_skip_align1);</span>
<span class="line-removed">1039         __ decrement(count);</span>
<span class="line-removed">1040         __ movb(rdx, Address(from, count, sf, 0));</span>
<span class="line-removed">1041         __ movb(Address(to, count, sf, 0), rdx);</span>
<span class="line-removed">1042       __ BIND(L_skip_align1);</span>
<span class="line-removed">1043       }</span>
<span class="line-removed">1044       // Two bytes misalignment happens only for byte and short (char) arrays</span>
<span class="line-removed">1045       __ testl(end, 2);</span>
<span class="line-removed">1046       __ jccb(Assembler::zero, L_skip_align2);</span>
<span class="line-removed">1047       __ subptr(count, 1&lt;&lt;(shift-1));</span>
<span class="line-removed">1048       __ movw(rdx, Address(from, count, sf, 0));</span>
<span class="line-removed">1049       __ movw(Address(to, count, sf, 0), rdx);</span>
<span class="line-removed">1050     __ BIND(L_skip_align2);</span>
1051       __ cmpl(count, 2&lt;&lt;shift); // Short arrays (&lt; 8 bytes) copy by element
<span class="line-modified">1052       __ jcc(Assembler::below, L_copy_4_bytes);</span>
<span class="line-modified">1053     }</span>
<span class="line-modified">1054 </span>
<span class="line-modified">1055     if (!VM_Version::supports_mmx()) {</span>
<span class="line-modified">1056       __ std();</span>
<span class="line-modified">1057       __ mov(rax, count); // Save &#39;count&#39;</span>
<span class="line-modified">1058       __ mov(rdx, to);    // Save &#39;to&#39;</span>
<span class="line-modified">1059       __ lea(rsi, Address(from, count, sf, -4));</span>
<span class="line-modified">1060       __ lea(rdi, Address(to  , count, sf, -4));</span>
<span class="line-modified">1061       __ shrptr(count, shift); // bytes count</span>
<span class="line-modified">1062       __ rep_mov();</span>
<span class="line-modified">1063       __ cld();</span>
<span class="line-modified">1064       __ mov(count, rax); // restore &#39;count&#39;</span>
<span class="line-modified">1065       __ andl(count, (1&lt;&lt;shift)-1);      // mask the number of rest elements</span>
<span class="line-modified">1066       __ movptr(from, Address(rsp, 12+4)); // reread &#39;from&#39;</span>
<span class="line-modified">1067       __ mov(to, rdx);   // restore &#39;to&#39;</span>
<span class="line-modified">1068       __ jmpb(L_copy_2_bytes); // all dword were copied</span>
<span class="line-modified">1069    } else {</span>
<span class="line-modified">1070       // Align to 8 bytes the end of array. It is aligned to 4 bytes already.</span>
<span class="line-modified">1071       __ testptr(end, 4);</span>
<span class="line-modified">1072       __ jccb(Assembler::zero, L_copy_8_bytes);</span>
<span class="line-modified">1073       __ subl(count, 1&lt;&lt;shift);</span>
<span class="line-modified">1074       __ movl(rdx, Address(from, count, sf, 0));</span>
<span class="line-removed">1075       __ movl(Address(to, count, sf, 0), rdx);</span>
<span class="line-removed">1076       __ jmpb(L_copy_8_bytes);</span>
1077 
<span class="line-modified">1078       __ align(OptoLoopAlignment);</span>
<span class="line-modified">1079       // Move 8 bytes</span>
<span class="line-modified">1080     __ BIND(L_copy_8_bytes_loop);</span>
<span class="line-modified">1081       if (UseXMMForArrayCopy) {</span>
<span class="line-modified">1082         __ movq(xmm0, Address(from, count, sf, 0));</span>
<span class="line-modified">1083         __ movq(Address(to, count, sf, 0), xmm0);</span>








1084       } else {
<span class="line-modified">1085         __ movq(mmx0, Address(from, count, sf, 0));</span>
<span class="line-modified">1086         __ movq(Address(to, count, sf, 0), mmx0);</span>























1087       }
<span class="line-modified">1088     __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">1089       __ subl(count, 2&lt;&lt;shift);</span>
<span class="line-modified">1090       __ jcc(Assembler::greaterEqual, L_copy_8_bytes_loop);</span>
<span class="line-modified">1091       __ addl(count, 2&lt;&lt;shift);</span>
<span class="line-modified">1092       if (!UseXMMForArrayCopy) {</span>
<span class="line-modified">1093         __ emms();</span>























1094       }
1095     }
<span class="line-removed">1096   __ BIND(L_copy_4_bytes);</span>
<span class="line-removed">1097     // copy prefix qword</span>
<span class="line-removed">1098     __ testl(count, 1&lt;&lt;shift);</span>
<span class="line-removed">1099     __ jccb(Assembler::zero, L_copy_2_bytes);</span>
<span class="line-removed">1100     __ movl(rdx, Address(from, count, sf, -4));</span>
<span class="line-removed">1101     __ movl(Address(to, count, sf, -4), rdx);</span>
1102 
<span class="line-modified">1103     if (t == T_BYTE || t == T_SHORT) {</span>
<span class="line-modified">1104         __ subl(count, (1&lt;&lt;shift));</span>
<span class="line-removed">1105       __ BIND(L_copy_2_bytes);</span>
<span class="line-removed">1106         // copy prefix dword</span>
<span class="line-removed">1107         __ testl(count, 1&lt;&lt;(shift-1));</span>
<span class="line-removed">1108         __ jccb(Assembler::zero, L_copy_byte);</span>
<span class="line-removed">1109         __ movw(rdx, Address(from, count, sf, -2));</span>
<span class="line-removed">1110         __ movw(Address(to, count, sf, -2), rdx);</span>
<span class="line-removed">1111         if (t == T_BYTE) {</span>
<span class="line-removed">1112           __ subl(count, 1&lt;&lt;(shift-1));</span>
<span class="line-removed">1113         __ BIND(L_copy_byte);</span>
<span class="line-removed">1114           // copy prefix byte</span>
<span class="line-removed">1115           __ testl(count, 1);</span>
<span class="line-removed">1116           __ jccb(Assembler::zero, L_exit);</span>
<span class="line-removed">1117           __ movb(rdx, Address(from, 0));</span>
<span class="line-removed">1118           __ movb(Address(to, 0), rdx);</span>
<span class="line-removed">1119         __ BIND(L_exit);</span>
<span class="line-removed">1120         } else {</span>
<span class="line-removed">1121         __ BIND(L_copy_byte);</span>
<span class="line-removed">1122         }</span>
<span class="line-removed">1123     } else {</span>
<span class="line-removed">1124     __ BIND(L_copy_2_bytes);</span>
1125     }
<span class="line-removed">1126 </span>
1127     __ movl2ptr(count, Address(rsp, 12+12)); // reread count
1128     bs-&gt;arraycopy_epilogue(_masm, decorators, t, from, to, count);
1129 
1130     if (t == T_OBJECT) {
1131     __ BIND(L_0_count);
1132     }
1133     inc_copy_counter_np(t);
1134     __ pop(rdi);
1135     __ pop(rsi);
1136     __ leave(); // required for proper stackwalking of RuntimeStub frame
1137     __ xorptr(rax, rax); // return 0
1138     __ ret(0);
1139     return start;
1140   }
1141 
1142 
1143   address generate_disjoint_long_copy(address* entry, const char *name) {
1144     __ align(CodeEntryAlignment);
1145     StubCodeMark mark(this, &quot;StubRoutines&quot;, name);
1146     address start = __ pc();
1147 
1148     Label L_copy_8_bytes, L_copy_8_bytes_loop;
1149     const Register from       = rax;  // source array address
1150     const Register to         = rdx;  // destination array address
1151     const Register count      = rcx;  // elements count
1152     const Register to_from    = rdx;  // (to - from)
1153 
1154     __ enter(); // required for proper stackwalking of RuntimeStub frame
1155     __ movptr(from , Address(rsp, 8+0));       // from
1156     __ movptr(to   , Address(rsp, 8+4));       // to
1157     __ movl2ptr(count, Address(rsp, 8+8));     // count
1158 
1159     *entry = __ pc(); // Entry point from conjoint arraycopy stub.
1160     BLOCK_COMMENT(&quot;Entry:&quot;);
1161 
<span class="line-modified">1162     __ subptr(to, from); // to --&gt; to_from</span>
<span class="line-modified">1163     if (VM_Version::supports_mmx()) {</span>
<span class="line-modified">1164       if (UseXMMForArrayCopy) {</span>
<span class="line-modified">1165         xmm_copy_forward(from, to_from, count);</span>






1166       } else {
<span class="line-modified">1167         mmx_copy_forward(from, to_from, count);</span>








1168       }
<span class="line-modified">1169     } else {</span>
<span class="line-modified">1170       __ jmpb(L_copy_8_bytes);</span>
<span class="line-modified">1171       __ align(OptoLoopAlignment);</span>
<span class="line-removed">1172     __ BIND(L_copy_8_bytes_loop);</span>
<span class="line-removed">1173       __ fild_d(Address(from, 0));</span>
<span class="line-removed">1174       __ fistp_d(Address(from, to_from, Address::times_1));</span>
<span class="line-removed">1175       __ addptr(from, 8);</span>
<span class="line-removed">1176     __ BIND(L_copy_8_bytes);</span>
<span class="line-removed">1177       __ decrement(count);</span>
<span class="line-removed">1178       __ jcc(Assembler::greaterEqual, L_copy_8_bytes_loop);</span>
1179     }
1180     inc_copy_counter_np(T_LONG);
1181     __ leave(); // required for proper stackwalking of RuntimeStub frame
1182     __ vzeroupper();
1183     __ xorptr(rax, rax); // return 0
1184     __ ret(0);
1185     return start;
1186   }
1187 
1188   address generate_conjoint_long_copy(address nooverlap_target,
1189                                       address* entry, const char *name) {
1190     __ align(CodeEntryAlignment);
1191     StubCodeMark mark(this, &quot;StubRoutines&quot;, name);
1192     address start = __ pc();
1193 
1194     Label L_copy_8_bytes, L_copy_8_bytes_loop;
1195     const Register from       = rax;  // source array address
1196     const Register to         = rdx;  // destination array address
1197     const Register count      = rcx;  // elements count
1198     const Register end_from   = rax;  // source array end address
1199 
1200     __ enter(); // required for proper stackwalking of RuntimeStub frame
1201     __ movptr(from , Address(rsp, 8+0));       // from
1202     __ movptr(to   , Address(rsp, 8+4));       // to
1203     __ movl2ptr(count, Address(rsp, 8+8));     // count
1204 
1205     *entry = __ pc(); // Entry point from generic arraycopy stub.
1206     BLOCK_COMMENT(&quot;Entry:&quot;);
1207 
1208     // arrays overlap test
1209     __ cmpptr(to, from);
1210     RuntimeAddress nooverlap(nooverlap_target);
1211     __ jump_cc(Assembler::belowEqual, nooverlap);
1212     __ lea(end_from, Address(from, count, Address::times_8, 0));
1213     __ cmpptr(to, end_from);
1214     __ movptr(from, Address(rsp, 8));  // from
1215     __ jump_cc(Assembler::aboveEqual, nooverlap);
1216 
<span class="line-modified">1217     __ jmpb(L_copy_8_bytes);</span>


1218 
<span class="line-modified">1219     __ align(OptoLoopAlignment);</span>
<span class="line-modified">1220   __ BIND(L_copy_8_bytes_loop);</span>
<span class="line-modified">1221     if (VM_Version::supports_mmx()) {</span>
<span class="line-modified">1222       if (UseXMMForArrayCopy) {</span>
<span class="line-modified">1223         __ movq(xmm0, Address(from, count, Address::times_8));</span>
<span class="line-modified">1224         __ movq(Address(to, count, Address::times_8), xmm0);</span>






1225       } else {
<span class="line-modified">1226         __ movq(mmx0, Address(from, count, Address::times_8));</span>
<span class="line-modified">1227         __ movq(Address(to, count, Address::times_8), mmx0);</span>
1228       }
<span class="line-modified">1229     } else {</span>
<span class="line-modified">1230       __ fild_d(Address(from, count, Address::times_8));</span>
<span class="line-modified">1231       __ fistp_d(Address(to, count, Address::times_8));</span>
<span class="line-removed">1232     }</span>
<span class="line-removed">1233   __ BIND(L_copy_8_bytes);</span>
<span class="line-removed">1234     __ decrement(count);</span>
<span class="line-removed">1235     __ jcc(Assembler::greaterEqual, L_copy_8_bytes_loop);</span>
1236 

1237     if (VM_Version::supports_mmx() &amp;&amp; !UseXMMForArrayCopy) {
1238       __ emms();
1239     }
1240     inc_copy_counter_np(T_LONG);
1241     __ leave(); // required for proper stackwalking of RuntimeStub frame
1242     __ xorptr(rax, rax); // return 0
1243     __ ret(0);
1244     return start;
1245   }
1246 
1247 
1248   // Helper for generating a dynamic type check.
1249   // The sub_klass must be one of {rbx, rdx, rsi}.
1250   // The temp is killed.
1251   void generate_type_check(Register sub_klass,
1252                            Address&amp; super_check_offset_addr,
1253                            Address&amp; super_klass_addr,
1254                            Register temp,
1255                            Label* L_success, Label* L_failure) {
1256     BLOCK_COMMENT(&quot;type_check:&quot;);
</pre>
<hr />
<pre>
2951     Register ofs   = rcx;
2952     Register limit = rdi;
2953 
2954     const Address  buf_param(rbp, 8 + 0);
2955     const Address  state_param(rbp, 8 + 4);
2956     const Address  ofs_param(rbp, 8 + 8);
2957     const Address  limit_param(rbp, 8 + 12);
2958 
2959     const XMMRegister abcd = xmm0;
2960     const XMMRegister e0 = xmm1;
2961     const XMMRegister e1 = xmm2;
2962     const XMMRegister msg0 = xmm3;
2963 
2964     const XMMRegister msg1 = xmm4;
2965     const XMMRegister msg2 = xmm5;
2966     const XMMRegister msg3 = xmm6;
2967     const XMMRegister shuf_mask = xmm7;
2968 
2969     __ enter();
2970     __ subptr(rsp, 8 * wordSize);
<span class="line-modified">2971     if (multi_block) {</span>
<span class="line-modified">2972       __ push(limit);</span>
<span class="line-removed">2973     }</span>
2974     __ movptr(buf, buf_param);
2975     __ movptr(state, state_param);
2976     if (multi_block) {
2977       __ movptr(ofs, ofs_param);
2978       __ movptr(limit, limit_param);
2979     }
2980 
2981     __ fast_sha1(abcd, e0, e1, msg0, msg1, msg2, msg3, shuf_mask,
2982       buf, state, ofs, limit, rsp, multi_block);
2983 
<span class="line-modified">2984     if (multi_block) {</span>
<span class="line-removed">2985       __ pop(limit);</span>
<span class="line-removed">2986     }</span>
2987     __ addptr(rsp, 8 * wordSize);
2988     __ leave();
2989     __ ret(0);
2990     return start;
2991   }
2992 
2993   address generate_pshuffle_byte_flip_mask() {
2994     __ align(64);
2995     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;pshuffle_byte_flip_mask&quot;);
2996     address start = __ pc();
2997     __ emit_data(0x00010203, relocInfo::none, 0);
2998     __ emit_data(0x04050607, relocInfo::none, 0);
2999     __ emit_data(0x08090a0b, relocInfo::none, 0);
3000     __ emit_data(0x0c0d0e0f, relocInfo::none, 0);
3001     return start;
3002   }
3003 
3004   // ofs and limit are use for multi-block byte array.
3005   // int com.sun.security.provider.DigestBase.implCompressMultiBlock(byte[] b, int ofs, int limit)
3006  address generate_sha256_implCompress(bool multi_block, const char *name) {
</pre>
<hr />
<pre>
3569     // Load *adr into eax, may fault.
3570     *fault_pc = __ pc();
3571     switch (size) {
3572       case 4:
3573         // int32_t
3574         __ movl(rax, Address(rcx, 0));
3575         break;
3576       case 8:
3577         // int64_t
3578         Unimplemented();
3579         break;
3580       default:
3581         ShouldNotReachHere();
3582     }
3583 
3584     // Return errValue or *adr.
3585     *continuation_pc = __ pc();
3586     __ ret(0);
3587   }
3588 






























































3589  public:
3590   // Information about frame layout at time of blocking runtime call.
3591   // Note that we only have to preserve callee-saved registers since
3592   // the compilers are responsible for supplying a continuation point
3593   // if they expect all registers to be preserved.
3594   enum layout {
3595     thread_off,    // last_java_sp
3596     arg1_off,
3597     arg2_off,
3598     rbp_off,       // callee saved register
3599     ret_pc,
3600     framesize
3601   };
3602 
3603  private:
3604 
3605 #undef  __
3606 #define __ masm-&gt;
3607 
3608   //------------------------------------------------------------------------------------------------------------------------
</pre>
<hr />
<pre>
3809       }
3810       if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dtan)) {
3811         StubRoutines::_dlibm_tan_cot_huge = generate_libm_tan_cot_huge();
3812         StubRoutines::_dtan = generate_libmTan();
3813       }
3814     }
3815   }
3816 
3817   void generate_all() {
3818     // Generates all stubs and initializes the entry points
3819 
3820     // These entry points require SharedInfo::stack0 to be set up in non-core builds
3821     // and need to be relocatable, so they each fabricate a RuntimeStub internally.
3822     StubRoutines::_throw_AbstractMethodError_entry         = generate_throw_exception(&quot;AbstractMethodError throw_exception&quot;,          CAST_FROM_FN_PTR(address, SharedRuntime::throw_AbstractMethodError));
3823     StubRoutines::_throw_IncompatibleClassChangeError_entry= generate_throw_exception(&quot;IncompatibleClassChangeError throw_exception&quot;, CAST_FROM_FN_PTR(address, SharedRuntime::throw_IncompatibleClassChangeError));
3824     StubRoutines::_throw_NullPointerException_at_call_entry= generate_throw_exception(&quot;NullPointerException at call throw_exception&quot;, CAST_FROM_FN_PTR(address, SharedRuntime::throw_NullPointerException_at_call));
3825 
3826     //------------------------------------------------------------------------------------------------------------------------
3827     // entry points that are platform specific
3828 








3829     // support for verify_oop (must happen after universe_init)
3830     StubRoutines::_verify_oop_subroutine_entry     = generate_verify_oop();
3831 
3832     // arraycopy stubs used by compilers
3833     generate_arraycopy_stubs();
3834 
3835     // don&#39;t bother generating these AES intrinsic stubs unless global flag is set
3836     if (UseAESIntrinsics) {
3837       StubRoutines::x86::_key_shuffle_mask_addr = generate_key_shuffle_mask();  // might be needed by the others
3838 
3839       StubRoutines::_aescrypt_encryptBlock = generate_aescrypt_encryptBlock();
3840       StubRoutines::_aescrypt_decryptBlock = generate_aescrypt_decryptBlock();
3841       StubRoutines::_cipherBlockChaining_encryptAESCrypt = generate_cipherBlockChaining_encryptAESCrypt();
3842       StubRoutines::_cipherBlockChaining_decryptAESCrypt = generate_cipherBlockChaining_decryptAESCrypt_Parallel();
3843     }
3844 
3845     if (UseAESCTRIntrinsics) {
3846       StubRoutines::x86::_counter_shuffle_mask_addr = generate_counter_shuffle_mask();
3847       StubRoutines::_counterMode_AESCrypt = generate_counterMode_AESCrypt_Parallel();
3848     }
</pre>
<hr />
<pre>
3857       StubRoutines::x86::_k256_adr = (address)StubRoutines::x86::_k256;
3858       StubRoutines::x86::_pshuffle_byte_flip_mask_addr = generate_pshuffle_byte_flip_mask();
3859       StubRoutines::_sha256_implCompress = generate_sha256_implCompress(false, &quot;sha256_implCompress&quot;);
3860       StubRoutines::_sha256_implCompressMB = generate_sha256_implCompress(true, &quot;sha256_implCompressMB&quot;);
3861     }
3862 
3863     // Generate GHASH intrinsics code
3864     if (UseGHASHIntrinsics) {
3865       StubRoutines::x86::_ghash_long_swap_mask_addr = generate_ghash_long_swap_mask();
3866       StubRoutines::x86::_ghash_byte_swap_mask_addr = generate_ghash_byte_swap_mask();
3867       StubRoutines::_ghash_processBlocks = generate_ghash_processBlocks();
3868     }
3869 
3870     // Safefetch stubs.
3871     generate_safefetch(&quot;SafeFetch32&quot;, sizeof(int), &amp;StubRoutines::_safefetch32_entry,
3872                                                    &amp;StubRoutines::_safefetch32_fault_pc,
3873                                                    &amp;StubRoutines::_safefetch32_continuation_pc);
3874     StubRoutines::_safefetchN_entry           = StubRoutines::_safefetch32_entry;
3875     StubRoutines::_safefetchN_fault_pc        = StubRoutines::_safefetch32_fault_pc;
3876     StubRoutines::_safefetchN_continuation_pc = StubRoutines::_safefetch32_continuation_pc;





3877   }
3878 
3879 
3880  public:
3881   StubGenerator(CodeBuffer* code, bool all) : StubCodeGenerator(code) {
3882     if (all) {
3883       generate_all();
3884     } else {
3885       generate_initial();
3886     }
3887   }
3888 }; // end class declaration
3889 
<span class="line-modified">3890 </span>
3891 void StubGenerator_generate(CodeBuffer* code, bool all) {



3892   StubGenerator g(code, all);
3893 }
</pre>
</td>
<td>
<hr />
<pre>
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/macroAssembler.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;gc/shared/barrierSet.hpp&quot;
  29 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
<span class="line-added">  30 #include &quot;gc/shared/barrierSetNMethod.hpp&quot;</span>
  31 #include &quot;interpreter/interpreter.hpp&quot;
<span class="line-added">  32 #include &quot;memory/universe.hpp&quot;</span>
  33 #include &quot;nativeInst_x86.hpp&quot;
  34 #include &quot;oops/instanceOop.hpp&quot;
  35 #include &quot;oops/method.hpp&quot;
  36 #include &quot;oops/objArrayKlass.hpp&quot;
  37 #include &quot;oops/oop.inline.hpp&quot;
  38 #include &quot;prims/methodHandles.hpp&quot;
  39 #include &quot;runtime/frame.inline.hpp&quot;
  40 #include &quot;runtime/handles.inline.hpp&quot;
  41 #include &quot;runtime/sharedRuntime.hpp&quot;
  42 #include &quot;runtime/stubCodeGenerator.hpp&quot;
  43 #include &quot;runtime/stubRoutines.hpp&quot;
  44 #include &quot;runtime/thread.inline.hpp&quot;
  45 #ifdef COMPILER2
  46 #include &quot;opto/runtime.hpp&quot;
  47 #endif
  48 
  49 // Declaration and definition of StubGenerator (no .hpp file).
  50 // For a more detailed description of the stub routine structure
  51 // see the comment in stubRoutines.hpp
  52 
</pre>
<hr />
<pre>
 414       __ jcc(Assembler::notEqual, L);
 415       __ stop(&quot;StubRoutines::forward exception: no pending exception (2)&quot;);
 416       __ bind(L);
 417     }
 418 #endif
 419 
 420     // Verify that there is really a valid exception in RAX.
 421     __ verify_oop(exception_oop);
 422 
 423     // continue at exception handler (return address removed)
 424     // rax: exception
 425     // rbx: exception handler
 426     // rdx: throwing pc
 427     __ jmp(handler_addr);
 428 
 429     return start;
 430   }
 431 
 432 
 433   //----------------------------------------------------------------------------------------------------
<span class="line-modified"> 434   // Implementation of int32_t atomic_xchg(int32_t exchange_value, volatile int32_t* dest)</span>
<span class="line-added"> 435   // used by Atomic::xchg(volatile int32_t* dest, int32_t exchange_value)</span>
 436   //
 437   // xchg exists as far back as 8086, lock needed for MP only
 438   // Stack layout immediately after call:
 439   //
 440   // 0 [ret addr ] &lt;--- rsp
 441   // 1 [  ex     ]
 442   // 2 [  dest   ]
 443   //
 444   // Result:   *dest &lt;- ex, return (old *dest)
 445   //
 446   // Note: win32 does not currently use this code
 447 
 448   address generate_atomic_xchg() {
 449     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;atomic_xchg&quot;);
 450     address start = __ pc();
 451 
 452     __ push(rdx);
 453     Address exchange(rsp, 2 * wordSize);
 454     Address dest_addr(rsp, 3 * wordSize);
 455     __ movl(rax, exchange);
</pre>
<hr />
<pre>
 588     // Call the C code to massage the double.  Result in EAX
 589     if (t == T_INT)
 590       { BLOCK_COMMENT(&quot;SharedRuntime::d2i&quot;); }
 591     else if (t == T_LONG)
 592       { BLOCK_COMMENT(&quot;SharedRuntime::d2l&quot;); }
 593     __ call_VM_leaf( fcn, 2 );
 594 
 595     // Restore CPU &amp; FPU state
 596     __ pop_FPU_state();
 597     __ pop(rbp);
 598     __ pop(rdi);
 599     __ pop(rsi);
 600     __ pop(rcx);
 601     __ pop(rbx);
 602     __ addptr(rsp, wordSize * 2);
 603 
 604     __ ret(0);
 605 
 606     return start;
 607   }
<span class="line-added"> 608   //---------------------------------------------------------------------------------------------------</span>
 609 
<span class="line-added"> 610   address generate_vector_mask(const char *stub_name, int32_t mask) {</span>
<span class="line-added"> 611     __ align(CodeEntryAlignment);</span>
<span class="line-added"> 612     StubCodeMark mark(this, &quot;StubRoutines&quot;, stub_name);</span>
<span class="line-added"> 613     address start = __ pc();</span>
<span class="line-added"> 614 </span>
<span class="line-added"> 615     for (int i = 0; i &lt; 16; i++) {</span>
<span class="line-added"> 616       __ emit_data(mask, relocInfo::none, 0);</span>
<span class="line-added"> 617     }</span>
<span class="line-added"> 618 </span>
<span class="line-added"> 619     return start;</span>
<span class="line-added"> 620   }</span>
<span class="line-added"> 621 </span>
<span class="line-added"> 622   address generate_vector_mask_long_double(const char *stub_name, int32_t maskhi, int32_t masklo) {</span>
<span class="line-added"> 623     __ align(CodeEntryAlignment);</span>
<span class="line-added"> 624     StubCodeMark mark(this, &quot;StubRoutines&quot;, stub_name);</span>
<span class="line-added"> 625     address start = __ pc();</span>
<span class="line-added"> 626 </span>
<span class="line-added"> 627     for (int i = 0; i &lt; 8; i++) {</span>
<span class="line-added"> 628       __ emit_data(masklo, relocInfo::none, 0);</span>
<span class="line-added"> 629       __ emit_data(maskhi, relocInfo::none, 0);</span>
<span class="line-added"> 630     }</span>
<span class="line-added"> 631 </span>
<span class="line-added"> 632     return start;</span>
<span class="line-added"> 633   }</span>
<span class="line-added"> 634 </span>
<span class="line-added"> 635   //----------------------------------------------------------------------------------------------------</span>
<span class="line-added"> 636 </span>
<span class="line-added"> 637   address generate_vector_byte_perm_mask(const char *stub_name) {</span>
<span class="line-added"> 638     __ align(CodeEntryAlignment);</span>
<span class="line-added"> 639     StubCodeMark mark(this, &quot;StubRoutines&quot;, stub_name);</span>
<span class="line-added"> 640     address start = __ pc();</span>
<span class="line-added"> 641 </span>
<span class="line-added"> 642     __ emit_data(0x00000001, relocInfo::none, 0);</span>
<span class="line-added"> 643     __ emit_data(0x00000000, relocInfo::none, 0);</span>
<span class="line-added"> 644     __ emit_data(0x00000003, relocInfo::none, 0);</span>
<span class="line-added"> 645     __ emit_data(0x00000000, relocInfo::none, 0);</span>
<span class="line-added"> 646     __ emit_data(0x00000005, relocInfo::none, 0);</span>
<span class="line-added"> 647     __ emit_data(0x00000000, relocInfo::none, 0);</span>
<span class="line-added"> 648     __ emit_data(0x00000007, relocInfo::none, 0);</span>
<span class="line-added"> 649     __ emit_data(0x00000000, relocInfo::none, 0);</span>
<span class="line-added"> 650     __ emit_data(0x00000000, relocInfo::none, 0);</span>
<span class="line-added"> 651     __ emit_data(0x00000000, relocInfo::none, 0);</span>
<span class="line-added"> 652     __ emit_data(0x00000002, relocInfo::none, 0);</span>
<span class="line-added"> 653     __ emit_data(0x00000000, relocInfo::none, 0);</span>
<span class="line-added"> 654     __ emit_data(0x00000004, relocInfo::none, 0);</span>
<span class="line-added"> 655     __ emit_data(0x00000000, relocInfo::none, 0);</span>
<span class="line-added"> 656     __ emit_data(0x00000006, relocInfo::none, 0);</span>
<span class="line-added"> 657     __ emit_data(0x00000000, relocInfo::none, 0);</span>
<span class="line-added"> 658 </span>
<span class="line-added"> 659     return start;</span>
<span class="line-added"> 660   }</span>
 661 
 662   //----------------------------------------------------------------------------------------------------
 663   // Non-destructive plausibility checks for oops
 664 
 665   address generate_verify_oop() {
 666     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;verify_oop&quot;);
 667     address start = __ pc();
 668 
 669     // Incoming arguments on stack after saving rax,:
 670     //
 671     // [tos    ]: saved rdx
 672     // [tos + 1]: saved EFLAGS
 673     // [tos + 2]: return address
 674     // [tos + 3]: char* error message
 675     // [tos + 4]: oop   object to verify
 676     // [tos + 5]: saved rax, - saved by caller and bashed
 677 
 678     Label exit, error;
 679     __ pushf();
 680     __ incrementl(ExternalAddress((address) StubRoutines::verify_oop_count_addr()));
</pre>
<hr />
<pre>
 695     // make sure klass is &#39;reasonable&#39;, which is not zero.
 696     __ movptr(rax, Address(rax, oopDesc::klass_offset_in_bytes())); // get klass
 697     __ testptr(rax, rax);
 698     __ jcc(Assembler::zero, error);              // if klass is NULL it is broken
 699 
 700     // return if everything seems ok
 701     __ bind(exit);
 702     __ movptr(rax, Address(rsp, 5 * wordSize));  // get saved rax, back
 703     __ pop(rdx);                                 // restore rdx
 704     __ popf();                                   // restore EFLAGS
 705     __ ret(3 * wordSize);                        // pop arguments
 706 
 707     // handle errors
 708     __ bind(error);
 709     __ movptr(rax, Address(rsp, 5 * wordSize));  // get saved rax, back
 710     __ pop(rdx);                                 // get saved rdx back
 711     __ popf();                                   // get saved EFLAGS off stack -- will be ignored
 712     __ pusha();                                  // push registers (eip = return address &amp; msg are already pushed)
 713     BLOCK_COMMENT(&quot;call MacroAssembler::debug&quot;);
 714     __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, MacroAssembler::debug32)));
<span class="line-modified"> 715     __ hlt();</span>

 716     return start;
 717   }
 718 
 719 
 720   // Copy 64 bytes chunks
 721   //
 722   // Inputs:
 723   //   from        - source array address
 724   //   to_from     - destination array address - from
 725   //   qword_count - 8-bytes element count, negative
 726   //
 727   void xmm_copy_forward(Register from, Register to_from, Register qword_count) {
 728     assert( UseSSE &gt;= 2, &quot;supported cpu only&quot; );
 729     Label L_copy_64_bytes_loop, L_copy_64_bytes, L_copy_8_bytes, L_exit;
 730 
 731     // Copy 64-byte chunks
 732     __ jmpb(L_copy_64_bytes);
 733     __ align(OptoLoopAlignment);
 734   __ BIND(L_copy_64_bytes_loop);
 735 
</pre>
<hr />
<pre>
 873     if (entry != NULL) {
 874       *entry = __ pc(); // Entry point from conjoint arraycopy stub.
 875       BLOCK_COMMENT(&quot;Entry:&quot;);
 876     }
 877 
 878     if (t == T_OBJECT) {
 879       __ testl(count, count);
 880       __ jcc(Assembler::zero, L_0_count);
 881     }
 882 
 883     DecoratorSet decorators = IN_HEAP | IS_ARRAY | ARRAYCOPY_DISJOINT;
 884     if (dest_uninitialized) {
 885       decorators |= IS_DEST_UNINITIALIZED;
 886     }
 887     if (aligned) {
 888       decorators |= ARRAYCOPY_ALIGNED;
 889     }
 890 
 891     BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
 892     bs-&gt;arraycopy_prologue(_masm, decorators, t, from, to, count);
<span class="line-modified"> 893     {</span>
<span class="line-modified"> 894       bool add_entry = (t != T_OBJECT &amp;&amp; (!aligned || t == T_INT));</span>
<span class="line-modified"> 895       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-modified"> 896       UnsafeCopyMemoryMark ucmm(this, add_entry, true);</span>
<span class="line-modified"> 897       __ subptr(to, from); // to --&gt; to_from</span>
<span class="line-modified"> 898       __ cmpl(count, 2&lt;&lt;shift); // Short arrays (&lt; 8 bytes) copy by element</span>
<span class="line-modified"> 899       __ jcc(Assembler::below, L_copy_4_bytes); // use unsigned cmp</span>
<span class="line-modified"> 900       if (!UseUnalignedLoadStores &amp;&amp; !aligned &amp;&amp; (t == T_BYTE || t == T_SHORT)) {</span>
<span class="line-modified"> 901         // align source address at 4 bytes address boundary</span>
<span class="line-modified"> 902         if (t == T_BYTE) {</span>
<span class="line-modified"> 903           // One byte misalignment happens only for byte arrays</span>
<span class="line-modified"> 904           __ testl(from, 1);</span>
<span class="line-modified"> 905           __ jccb(Assembler::zero, L_skip_align1);</span>
<span class="line-modified"> 906           __ movb(rax, Address(from, 0));</span>
<span class="line-modified"> 907           __ movb(Address(from, to_from, Address::times_1, 0), rax);</span>
<span class="line-modified"> 908           __ increment(from);</span>
<span class="line-modified"> 909           __ decrement(count);</span>
<span class="line-modified"> 910         __ BIND(L_skip_align1);</span>
<span class="line-modified"> 911         }</span>
<span class="line-modified"> 912         // Two bytes misalignment happens only for byte and short (char) arrays</span>
<span class="line-modified"> 913         __ testl(from, 2);</span>
<span class="line-modified"> 914         __ jccb(Assembler::zero, L_skip_align2);</span>
<span class="line-modified"> 915         __ movw(rax, Address(from, 0));</span>
<span class="line-modified"> 916         __ movw(Address(from, to_from, Address::times_1, 0), rax);</span>
<span class="line-modified"> 917         __ addptr(from, 2);</span>
<span class="line-modified"> 918         __ subl(count, 1&lt;&lt;(shift-1));</span>
<span class="line-modified"> 919       __ BIND(L_skip_align2);</span>















 920       }
<span class="line-modified"> 921       if (!VM_Version::supports_mmx()) {</span>
<span class="line-modified"> 922         __ mov(rax, count);      // save &#39;count&#39;</span>
<span class="line-modified"> 923         __ shrl(count, shift); // bytes count</span>
<span class="line-modified"> 924         __ addptr(to_from, from);// restore &#39;to&#39;</span>
<span class="line-modified"> 925         __ rep_mov();</span>
<span class="line-modified"> 926         __ subptr(to_from, from);// restore &#39;to_from&#39;</span>
<span class="line-modified"> 927         __ mov(count, rax);      // restore &#39;count&#39;</span>
<span class="line-modified"> 928         __ jmpb(L_copy_2_bytes); // all dwords were copied</span>
 929       } else {
<span class="line-modified"> 930         if (!UseUnalignedLoadStores) {</span>
<span class="line-added"> 931           // align to 8 bytes, we know we are 4 byte aligned to start</span>
<span class="line-added"> 932           __ testptr(from, 4);</span>
<span class="line-added"> 933           __ jccb(Assembler::zero, L_copy_64_bytes);</span>
<span class="line-added"> 934           __ movl(rax, Address(from, 0));</span>
<span class="line-added"> 935           __ movl(Address(from, to_from, Address::times_1, 0), rax);</span>
<span class="line-added"> 936           __ addptr(from, 4);</span>
<span class="line-added"> 937           __ subl(count, 1&lt;&lt;shift);</span>
<span class="line-added"> 938          }</span>
<span class="line-added"> 939       __ BIND(L_copy_64_bytes);</span>
<span class="line-added"> 940         __ mov(rax, count);</span>
<span class="line-added"> 941         __ shrl(rax, shift+1);  // 8 bytes chunk count</span>
<span class="line-added"> 942         //</span>
<span class="line-added"> 943         // Copy 8-byte chunks through MMX registers, 8 per iteration of the loop</span>
<span class="line-added"> 944         //</span>
<span class="line-added"> 945         if (UseXMMForArrayCopy) {</span>
<span class="line-added"> 946           xmm_copy_forward(from, to_from, rax);</span>
<span class="line-added"> 947         } else {</span>
<span class="line-added"> 948           mmx_copy_forward(from, to_from, rax);</span>
<span class="line-added"> 949         }</span>
 950       }
<span class="line-modified"> 951       // copy tailing dword</span>
<span class="line-modified"> 952     __ BIND(L_copy_4_bytes);</span>
<span class="line-modified"> 953       __ testl(count, 1&lt;&lt;shift);</span>
<span class="line-modified"> 954       __ jccb(Assembler::zero, L_copy_2_bytes);</span>
<span class="line-modified"> 955       __ movl(rax, Address(from, 0));</span>
<span class="line-modified"> 956       __ movl(Address(from, to_from, Address::times_1, 0), rax);</span>
<span class="line-modified"> 957       if (t == T_BYTE || t == T_SHORT) {</span>
<span class="line-modified"> 958         __ addptr(from, 4);</span>
<span class="line-modified"> 959       __ BIND(L_copy_2_bytes);</span>
<span class="line-modified"> 960         // copy tailing word</span>
<span class="line-modified"> 961         __ testl(count, 1&lt;&lt;(shift-1));</span>
<span class="line-modified"> 962         __ jccb(Assembler::zero, L_copy_byte);</span>
<span class="line-modified"> 963         __ movw(rax, Address(from, 0));</span>
<span class="line-modified"> 964         __ movw(Address(from, to_from, Address::times_1, 0), rax);</span>
<span class="line-modified"> 965         if (t == T_BYTE) {</span>
<span class="line-modified"> 966           __ addptr(from, 2);</span>
<span class="line-modified"> 967         __ BIND(L_copy_byte);</span>
<span class="line-modified"> 968           // copy tailing byte</span>
<span class="line-modified"> 969           __ testl(count, 1);</span>
<span class="line-modified"> 970           __ jccb(Assembler::zero, L_exit);</span>
<span class="line-modified"> 971           __ movb(rax, Address(from, 0));</span>
<span class="line-modified"> 972           __ movb(Address(from, to_from, Address::times_1, 0), rax);</span>
<span class="line-modified"> 973         __ BIND(L_exit);</span>
<span class="line-modified"> 974         } else {</span>
<span class="line-added"> 975         __ BIND(L_copy_byte);</span>
<span class="line-added"> 976         }</span>
 977       } else {
<span class="line-modified"> 978       __ BIND(L_copy_2_bytes);</span>
 979       }


 980     }
 981 
<span class="line-added"> 982     if (VM_Version::supports_mmx() &amp;&amp; !UseXMMForArrayCopy) {</span>
<span class="line-added"> 983       __ emms();</span>
<span class="line-added"> 984     }</span>
 985     __ movl(count, Address(rsp, 12+12)); // reread &#39;count&#39;
 986     bs-&gt;arraycopy_epilogue(_masm, decorators, t, from, to, count);
 987 
 988     if (t == T_OBJECT) {
 989     __ BIND(L_0_count);
 990     }
 991     inc_copy_counter_np(t);
 992     __ pop(rdi);
 993     __ pop(rsi);
 994     __ leave(); // required for proper stackwalking of RuntimeStub frame
 995     __ vzeroupper();
 996     __ xorptr(rax, rax); // return 0
 997     __ ret(0);
 998     return start;
 999   }
1000 
1001 
1002   address generate_fill(BasicType t, bool aligned, const char *name) {
1003     __ align(CodeEntryAlignment);
1004     StubCodeMark mark(this, &quot;StubRoutines&quot;, name);
</pre>
<hr />
<pre>
1070     __ jump_cc(Assembler::belowEqual, nooverlap);
1071     __ cmpptr(dst, end);
1072     __ jump_cc(Assembler::aboveEqual, nooverlap);
1073 
1074     if (t == T_OBJECT) {
1075       __ testl(count, count);
1076       __ jcc(Assembler::zero, L_0_count);
1077     }
1078 
1079     DecoratorSet decorators = IN_HEAP | IS_ARRAY;
1080     if (dest_uninitialized) {
1081       decorators |= IS_DEST_UNINITIALIZED;
1082     }
1083     if (aligned) {
1084       decorators |= ARRAYCOPY_ALIGNED;
1085     }
1086 
1087     BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
1088     bs-&gt;arraycopy_prologue(_masm, decorators, t, from, to, count);
1089 
<span class="line-modified">1090     {</span>
<span class="line-modified">1091       bool add_entry = (t != T_OBJECT &amp;&amp; (!aligned || t == T_INT));</span>
<span class="line-modified">1092       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-modified">1093       UnsafeCopyMemoryMark ucmm(this, add_entry, true);</span>
<span class="line-modified">1094       // copy from high to low</span>

















1095       __ cmpl(count, 2&lt;&lt;shift); // Short arrays (&lt; 8 bytes) copy by element
<span class="line-modified">1096       __ jcc(Assembler::below, L_copy_4_bytes); // use unsigned cmp</span>
<span class="line-modified">1097       if (t == T_BYTE || t == T_SHORT) {</span>
<span class="line-modified">1098         // Align the end of destination array at 4 bytes address boundary</span>
<span class="line-modified">1099         __ lea(end, Address(dst, count, sf, 0));</span>
<span class="line-modified">1100         if (t == T_BYTE) {</span>
<span class="line-modified">1101           // One byte misalignment happens only for byte arrays</span>
<span class="line-modified">1102           __ testl(end, 1);</span>
<span class="line-modified">1103           __ jccb(Assembler::zero, L_skip_align1);</span>
<span class="line-modified">1104           __ decrement(count);</span>
<span class="line-modified">1105           __ movb(rdx, Address(from, count, sf, 0));</span>
<span class="line-modified">1106           __ movb(Address(to, count, sf, 0), rdx);</span>
<span class="line-modified">1107         __ BIND(L_skip_align1);</span>
<span class="line-modified">1108         }</span>
<span class="line-modified">1109         // Two bytes misalignment happens only for byte and short (char) arrays</span>
<span class="line-modified">1110         __ testl(end, 2);</span>
<span class="line-modified">1111         __ jccb(Assembler::zero, L_skip_align2);</span>
<span class="line-modified">1112         __ subptr(count, 1&lt;&lt;(shift-1));</span>
<span class="line-modified">1113         __ movw(rdx, Address(from, count, sf, 0));</span>
<span class="line-modified">1114         __ movw(Address(to, count, sf, 0), rdx);</span>
<span class="line-modified">1115       __ BIND(L_skip_align2);</span>
<span class="line-modified">1116         __ cmpl(count, 2&lt;&lt;shift); // Short arrays (&lt; 8 bytes) copy by element</span>
<span class="line-modified">1117         __ jcc(Assembler::below, L_copy_4_bytes);</span>
<span class="line-modified">1118       }</span>


1119 
<span class="line-modified">1120       if (!VM_Version::supports_mmx()) {</span>
<span class="line-modified">1121         __ std();</span>
<span class="line-modified">1122         __ mov(rax, count); // Save &#39;count&#39;</span>
<span class="line-modified">1123         __ mov(rdx, to);    // Save &#39;to&#39;</span>
<span class="line-modified">1124         __ lea(rsi, Address(from, count, sf, -4));</span>
<span class="line-modified">1125         __ lea(rdi, Address(to  , count, sf, -4));</span>
<span class="line-added">1126         __ shrptr(count, shift); // bytes count</span>
<span class="line-added">1127         __ rep_mov();</span>
<span class="line-added">1128         __ cld();</span>
<span class="line-added">1129         __ mov(count, rax); // restore &#39;count&#39;</span>
<span class="line-added">1130         __ andl(count, (1&lt;&lt;shift)-1);      // mask the number of rest elements</span>
<span class="line-added">1131         __ movptr(from, Address(rsp, 12+4)); // reread &#39;from&#39;</span>
<span class="line-added">1132         __ mov(to, rdx);   // restore &#39;to&#39;</span>
<span class="line-added">1133         __ jmpb(L_copy_2_bytes); // all dword were copied</span>
1134       } else {
<span class="line-modified">1135         // Align to 8 bytes the end of array. It is aligned to 4 bytes already.</span>
<span class="line-modified">1136         __ testptr(end, 4);</span>
<span class="line-added">1137         __ jccb(Assembler::zero, L_copy_8_bytes);</span>
<span class="line-added">1138         __ subl(count, 1&lt;&lt;shift);</span>
<span class="line-added">1139         __ movl(rdx, Address(from, count, sf, 0));</span>
<span class="line-added">1140         __ movl(Address(to, count, sf, 0), rdx);</span>
<span class="line-added">1141         __ jmpb(L_copy_8_bytes);</span>
<span class="line-added">1142 </span>
<span class="line-added">1143         __ align(OptoLoopAlignment);</span>
<span class="line-added">1144         // Move 8 bytes</span>
<span class="line-added">1145       __ BIND(L_copy_8_bytes_loop);</span>
<span class="line-added">1146         if (UseXMMForArrayCopy) {</span>
<span class="line-added">1147           __ movq(xmm0, Address(from, count, sf, 0));</span>
<span class="line-added">1148           __ movq(Address(to, count, sf, 0), xmm0);</span>
<span class="line-added">1149         } else {</span>
<span class="line-added">1150           __ movq(mmx0, Address(from, count, sf, 0));</span>
<span class="line-added">1151           __ movq(Address(to, count, sf, 0), mmx0);</span>
<span class="line-added">1152         }</span>
<span class="line-added">1153       __ BIND(L_copy_8_bytes);</span>
<span class="line-added">1154         __ subl(count, 2&lt;&lt;shift);</span>
<span class="line-added">1155         __ jcc(Assembler::greaterEqual, L_copy_8_bytes_loop);</span>
<span class="line-added">1156         __ addl(count, 2&lt;&lt;shift);</span>
<span class="line-added">1157         if (!UseXMMForArrayCopy) {</span>
<span class="line-added">1158           __ emms();</span>
<span class="line-added">1159         }</span>
1160       }
<span class="line-modified">1161     __ BIND(L_copy_4_bytes);</span>
<span class="line-modified">1162       // copy prefix qword</span>
<span class="line-modified">1163       __ testl(count, 1&lt;&lt;shift);</span>
<span class="line-modified">1164       __ jccb(Assembler::zero, L_copy_2_bytes);</span>
<span class="line-modified">1165       __ movl(rdx, Address(from, count, sf, -4));</span>
<span class="line-modified">1166       __ movl(Address(to, count, sf, -4), rdx);</span>
<span class="line-added">1167 </span>
<span class="line-added">1168       if (t == T_BYTE || t == T_SHORT) {</span>
<span class="line-added">1169           __ subl(count, (1&lt;&lt;shift));</span>
<span class="line-added">1170         __ BIND(L_copy_2_bytes);</span>
<span class="line-added">1171           // copy prefix dword</span>
<span class="line-added">1172           __ testl(count, 1&lt;&lt;(shift-1));</span>
<span class="line-added">1173           __ jccb(Assembler::zero, L_copy_byte);</span>
<span class="line-added">1174           __ movw(rdx, Address(from, count, sf, -2));</span>
<span class="line-added">1175           __ movw(Address(to, count, sf, -2), rdx);</span>
<span class="line-added">1176           if (t == T_BYTE) {</span>
<span class="line-added">1177             __ subl(count, 1&lt;&lt;(shift-1));</span>
<span class="line-added">1178           __ BIND(L_copy_byte);</span>
<span class="line-added">1179             // copy prefix byte</span>
<span class="line-added">1180             __ testl(count, 1);</span>
<span class="line-added">1181             __ jccb(Assembler::zero, L_exit);</span>
<span class="line-added">1182             __ movb(rdx, Address(from, 0));</span>
<span class="line-added">1183             __ movb(Address(to, 0), rdx);</span>
<span class="line-added">1184           __ BIND(L_exit);</span>
<span class="line-added">1185           } else {</span>
<span class="line-added">1186           __ BIND(L_copy_byte);</span>
<span class="line-added">1187           }</span>
<span class="line-added">1188       } else {</span>
<span class="line-added">1189       __ BIND(L_copy_2_bytes);</span>
1190       }
1191     }






1192 
<span class="line-modified">1193     if (VM_Version::supports_mmx() &amp;&amp; !UseXMMForArrayCopy) {</span>
<span class="line-modified">1194       __ emms();</span>




















1195     }

1196     __ movl2ptr(count, Address(rsp, 12+12)); // reread count
1197     bs-&gt;arraycopy_epilogue(_masm, decorators, t, from, to, count);
1198 
1199     if (t == T_OBJECT) {
1200     __ BIND(L_0_count);
1201     }
1202     inc_copy_counter_np(t);
1203     __ pop(rdi);
1204     __ pop(rsi);
1205     __ leave(); // required for proper stackwalking of RuntimeStub frame
1206     __ xorptr(rax, rax); // return 0
1207     __ ret(0);
1208     return start;
1209   }
1210 
1211 
1212   address generate_disjoint_long_copy(address* entry, const char *name) {
1213     __ align(CodeEntryAlignment);
1214     StubCodeMark mark(this, &quot;StubRoutines&quot;, name);
1215     address start = __ pc();
1216 
1217     Label L_copy_8_bytes, L_copy_8_bytes_loop;
1218     const Register from       = rax;  // source array address
1219     const Register to         = rdx;  // destination array address
1220     const Register count      = rcx;  // elements count
1221     const Register to_from    = rdx;  // (to - from)
1222 
1223     __ enter(); // required for proper stackwalking of RuntimeStub frame
1224     __ movptr(from , Address(rsp, 8+0));       // from
1225     __ movptr(to   , Address(rsp, 8+4));       // to
1226     __ movl2ptr(count, Address(rsp, 8+8));     // count
1227 
1228     *entry = __ pc(); // Entry point from conjoint arraycopy stub.
1229     BLOCK_COMMENT(&quot;Entry:&quot;);
1230 
<span class="line-modified">1231     {</span>
<span class="line-modified">1232       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-modified">1233       UnsafeCopyMemoryMark ucmm(this, true, true);</span>
<span class="line-modified">1234       __ subptr(to, from); // to --&gt; to_from</span>
<span class="line-added">1235       if (VM_Version::supports_mmx()) {</span>
<span class="line-added">1236         if (UseXMMForArrayCopy) {</span>
<span class="line-added">1237           xmm_copy_forward(from, to_from, count);</span>
<span class="line-added">1238         } else {</span>
<span class="line-added">1239           mmx_copy_forward(from, to_from, count);</span>
<span class="line-added">1240         }</span>
1241       } else {
<span class="line-modified">1242         __ jmpb(L_copy_8_bytes);</span>
<span class="line-added">1243         __ align(OptoLoopAlignment);</span>
<span class="line-added">1244       __ BIND(L_copy_8_bytes_loop);</span>
<span class="line-added">1245         __ fild_d(Address(from, 0));</span>
<span class="line-added">1246         __ fistp_d(Address(from, to_from, Address::times_1));</span>
<span class="line-added">1247         __ addptr(from, 8);</span>
<span class="line-added">1248       __ BIND(L_copy_8_bytes);</span>
<span class="line-added">1249         __ decrement(count);</span>
<span class="line-added">1250         __ jcc(Assembler::greaterEqual, L_copy_8_bytes_loop);</span>
1251       }
<span class="line-modified">1252     }</span>
<span class="line-modified">1253     if (VM_Version::supports_mmx() &amp;&amp; !UseXMMForArrayCopy) {</span>
<span class="line-modified">1254       __ emms();</span>







1255     }
1256     inc_copy_counter_np(T_LONG);
1257     __ leave(); // required for proper stackwalking of RuntimeStub frame
1258     __ vzeroupper();
1259     __ xorptr(rax, rax); // return 0
1260     __ ret(0);
1261     return start;
1262   }
1263 
1264   address generate_conjoint_long_copy(address nooverlap_target,
1265                                       address* entry, const char *name) {
1266     __ align(CodeEntryAlignment);
1267     StubCodeMark mark(this, &quot;StubRoutines&quot;, name);
1268     address start = __ pc();
1269 
1270     Label L_copy_8_bytes, L_copy_8_bytes_loop;
1271     const Register from       = rax;  // source array address
1272     const Register to         = rdx;  // destination array address
1273     const Register count      = rcx;  // elements count
1274     const Register end_from   = rax;  // source array end address
1275 
1276     __ enter(); // required for proper stackwalking of RuntimeStub frame
1277     __ movptr(from , Address(rsp, 8+0));       // from
1278     __ movptr(to   , Address(rsp, 8+4));       // to
1279     __ movl2ptr(count, Address(rsp, 8+8));     // count
1280 
1281     *entry = __ pc(); // Entry point from generic arraycopy stub.
1282     BLOCK_COMMENT(&quot;Entry:&quot;);
1283 
1284     // arrays overlap test
1285     __ cmpptr(to, from);
1286     RuntimeAddress nooverlap(nooverlap_target);
1287     __ jump_cc(Assembler::belowEqual, nooverlap);
1288     __ lea(end_from, Address(from, count, Address::times_8, 0));
1289     __ cmpptr(to, end_from);
1290     __ movptr(from, Address(rsp, 8));  // from
1291     __ jump_cc(Assembler::aboveEqual, nooverlap);
1292 
<span class="line-modified">1293     {</span>
<span class="line-added">1294       // UnsafeCopyMemory page error: continue after ucm</span>
<span class="line-added">1295       UnsafeCopyMemoryMark ucmm(this, true, true);</span>
1296 
<span class="line-modified">1297       __ jmpb(L_copy_8_bytes);</span>
<span class="line-modified">1298 </span>
<span class="line-modified">1299       __ align(OptoLoopAlignment);</span>
<span class="line-modified">1300     __ BIND(L_copy_8_bytes_loop);</span>
<span class="line-modified">1301       if (VM_Version::supports_mmx()) {</span>
<span class="line-modified">1302         if (UseXMMForArrayCopy) {</span>
<span class="line-added">1303           __ movq(xmm0, Address(from, count, Address::times_8));</span>
<span class="line-added">1304           __ movq(Address(to, count, Address::times_8), xmm0);</span>
<span class="line-added">1305         } else {</span>
<span class="line-added">1306           __ movq(mmx0, Address(from, count, Address::times_8));</span>
<span class="line-added">1307           __ movq(Address(to, count, Address::times_8), mmx0);</span>
<span class="line-added">1308         }</span>
1309       } else {
<span class="line-modified">1310         __ fild_d(Address(from, count, Address::times_8));</span>
<span class="line-modified">1311         __ fistp_d(Address(to, count, Address::times_8));</span>
1312       }
<span class="line-modified">1313     __ BIND(L_copy_8_bytes);</span>
<span class="line-modified">1314       __ decrement(count);</span>
<span class="line-modified">1315       __ jcc(Assembler::greaterEqual, L_copy_8_bytes_loop);</span>




1316 
<span class="line-added">1317     }</span>
1318     if (VM_Version::supports_mmx() &amp;&amp; !UseXMMForArrayCopy) {
1319       __ emms();
1320     }
1321     inc_copy_counter_np(T_LONG);
1322     __ leave(); // required for proper stackwalking of RuntimeStub frame
1323     __ xorptr(rax, rax); // return 0
1324     __ ret(0);
1325     return start;
1326   }
1327 
1328 
1329   // Helper for generating a dynamic type check.
1330   // The sub_klass must be one of {rbx, rdx, rsi}.
1331   // The temp is killed.
1332   void generate_type_check(Register sub_klass,
1333                            Address&amp; super_check_offset_addr,
1334                            Address&amp; super_klass_addr,
1335                            Register temp,
1336                            Label* L_success, Label* L_failure) {
1337     BLOCK_COMMENT(&quot;type_check:&quot;);
</pre>
<hr />
<pre>
3032     Register ofs   = rcx;
3033     Register limit = rdi;
3034 
3035     const Address  buf_param(rbp, 8 + 0);
3036     const Address  state_param(rbp, 8 + 4);
3037     const Address  ofs_param(rbp, 8 + 8);
3038     const Address  limit_param(rbp, 8 + 12);
3039 
3040     const XMMRegister abcd = xmm0;
3041     const XMMRegister e0 = xmm1;
3042     const XMMRegister e1 = xmm2;
3043     const XMMRegister msg0 = xmm3;
3044 
3045     const XMMRegister msg1 = xmm4;
3046     const XMMRegister msg2 = xmm5;
3047     const XMMRegister msg3 = xmm6;
3048     const XMMRegister shuf_mask = xmm7;
3049 
3050     __ enter();
3051     __ subptr(rsp, 8 * wordSize);
<span class="line-modified">3052     handleSOERegisters(true /*saving*/);</span>
<span class="line-modified">3053 </span>

3054     __ movptr(buf, buf_param);
3055     __ movptr(state, state_param);
3056     if (multi_block) {
3057       __ movptr(ofs, ofs_param);
3058       __ movptr(limit, limit_param);
3059     }
3060 
3061     __ fast_sha1(abcd, e0, e1, msg0, msg1, msg2, msg3, shuf_mask,
3062       buf, state, ofs, limit, rsp, multi_block);
3063 
<span class="line-modified">3064     handleSOERegisters(false /*restoring*/);</span>


3065     __ addptr(rsp, 8 * wordSize);
3066     __ leave();
3067     __ ret(0);
3068     return start;
3069   }
3070 
3071   address generate_pshuffle_byte_flip_mask() {
3072     __ align(64);
3073     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;pshuffle_byte_flip_mask&quot;);
3074     address start = __ pc();
3075     __ emit_data(0x00010203, relocInfo::none, 0);
3076     __ emit_data(0x04050607, relocInfo::none, 0);
3077     __ emit_data(0x08090a0b, relocInfo::none, 0);
3078     __ emit_data(0x0c0d0e0f, relocInfo::none, 0);
3079     return start;
3080   }
3081 
3082   // ofs and limit are use for multi-block byte array.
3083   // int com.sun.security.provider.DigestBase.implCompressMultiBlock(byte[] b, int ofs, int limit)
3084  address generate_sha256_implCompress(bool multi_block, const char *name) {
</pre>
<hr />
<pre>
3647     // Load *adr into eax, may fault.
3648     *fault_pc = __ pc();
3649     switch (size) {
3650       case 4:
3651         // int32_t
3652         __ movl(rax, Address(rcx, 0));
3653         break;
3654       case 8:
3655         // int64_t
3656         Unimplemented();
3657         break;
3658       default:
3659         ShouldNotReachHere();
3660     }
3661 
3662     // Return errValue or *adr.
3663     *continuation_pc = __ pc();
3664     __ ret(0);
3665   }
3666 
<span class="line-added">3667   address generate_method_entry_barrier() {</span>
<span class="line-added">3668     __ align(CodeEntryAlignment);</span>
<span class="line-added">3669     StubCodeMark mark(this, &quot;StubRoutines&quot;, &quot;nmethod_entry_barrier&quot;);</span>
<span class="line-added">3670 </span>
<span class="line-added">3671     Label deoptimize_label;</span>
<span class="line-added">3672 </span>
<span class="line-added">3673     address start = __ pc();</span>
<span class="line-added">3674 </span>
<span class="line-added">3675     __ push(-1); // cookie, this is used for writing the new rsp when deoptimizing</span>
<span class="line-added">3676 </span>
<span class="line-added">3677     BLOCK_COMMENT(&quot;Entry:&quot;);</span>
<span class="line-added">3678     __ enter(); // save rbp</span>
<span class="line-added">3679 </span>
<span class="line-added">3680     // save rbx, because we want to use that value.</span>
<span class="line-added">3681     // We could do without it but then we depend on the number of slots used by pusha</span>
<span class="line-added">3682     __ push(rbx);</span>
<span class="line-added">3683 </span>
<span class="line-added">3684     __ lea(rbx, Address(rsp, wordSize * 3)); // 1 for cookie, 1 for rbp, 1 for rbx - this should be the return address</span>
<span class="line-added">3685 </span>
<span class="line-added">3686     __ pusha();</span>
<span class="line-added">3687 </span>
<span class="line-added">3688     // xmm0 and xmm1 may be used for passing float/double arguments</span>
<span class="line-added">3689     const int xmm_size = wordSize * 2;</span>
<span class="line-added">3690     const int xmm_spill_size = xmm_size * 2;</span>
<span class="line-added">3691     __ subptr(rsp, xmm_spill_size);</span>
<span class="line-added">3692     __ movdqu(Address(rsp, xmm_size * 1), xmm1);</span>
<span class="line-added">3693     __ movdqu(Address(rsp, xmm_size * 0), xmm0);</span>
<span class="line-added">3694 </span>
<span class="line-added">3695     __ call_VM_leaf(CAST_FROM_FN_PTR(address, static_cast&lt;int (*)(address*)&gt;(BarrierSetNMethod::nmethod_stub_entry_barrier)), rbx);</span>
<span class="line-added">3696 </span>
<span class="line-added">3697     __ movdqu(xmm0, Address(rsp, xmm_size * 0));</span>
<span class="line-added">3698     __ movdqu(xmm1, Address(rsp, xmm_size * 1));</span>
<span class="line-added">3699     __ addptr(rsp, xmm_spill_size);</span>
<span class="line-added">3700 </span>
<span class="line-added">3701     __ cmpl(rax, 1); // 1 means deoptimize</span>
<span class="line-added">3702     __ jcc(Assembler::equal, deoptimize_label);</span>
<span class="line-added">3703 </span>
<span class="line-added">3704     __ popa();</span>
<span class="line-added">3705     __ pop(rbx);</span>
<span class="line-added">3706 </span>
<span class="line-added">3707     __ leave();</span>
<span class="line-added">3708 </span>
<span class="line-added">3709     __ addptr(rsp, 1 * wordSize); // cookie</span>
<span class="line-added">3710     __ ret(0);</span>
<span class="line-added">3711 </span>
<span class="line-added">3712     __ BIND(deoptimize_label);</span>
<span class="line-added">3713 </span>
<span class="line-added">3714     __ popa();</span>
<span class="line-added">3715     __ pop(rbx);</span>
<span class="line-added">3716 </span>
<span class="line-added">3717     __ leave();</span>
<span class="line-added">3718 </span>
<span class="line-added">3719     // this can be taken out, but is good for verification purposes. getting a SIGSEGV</span>
<span class="line-added">3720     // here while still having a correct stack is valuable</span>
<span class="line-added">3721     __ testptr(rsp, Address(rsp, 0));</span>
<span class="line-added">3722 </span>
<span class="line-added">3723     __ movptr(rsp, Address(rsp, 0)); // new rsp was written in the barrier</span>
<span class="line-added">3724     __ jmp(Address(rsp, -1 * wordSize)); // jmp target should be callers verified_entry_point</span>
<span class="line-added">3725 </span>
<span class="line-added">3726     return start;</span>
<span class="line-added">3727   }</span>
<span class="line-added">3728 </span>
3729  public:
3730   // Information about frame layout at time of blocking runtime call.
3731   // Note that we only have to preserve callee-saved registers since
3732   // the compilers are responsible for supplying a continuation point
3733   // if they expect all registers to be preserved.
3734   enum layout {
3735     thread_off,    // last_java_sp
3736     arg1_off,
3737     arg2_off,
3738     rbp_off,       // callee saved register
3739     ret_pc,
3740     framesize
3741   };
3742 
3743  private:
3744 
3745 #undef  __
3746 #define __ masm-&gt;
3747 
3748   //------------------------------------------------------------------------------------------------------------------------
</pre>
<hr />
<pre>
3949       }
3950       if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dtan)) {
3951         StubRoutines::_dlibm_tan_cot_huge = generate_libm_tan_cot_huge();
3952         StubRoutines::_dtan = generate_libmTan();
3953       }
3954     }
3955   }
3956 
3957   void generate_all() {
3958     // Generates all stubs and initializes the entry points
3959 
3960     // These entry points require SharedInfo::stack0 to be set up in non-core builds
3961     // and need to be relocatable, so they each fabricate a RuntimeStub internally.
3962     StubRoutines::_throw_AbstractMethodError_entry         = generate_throw_exception(&quot;AbstractMethodError throw_exception&quot;,          CAST_FROM_FN_PTR(address, SharedRuntime::throw_AbstractMethodError));
3963     StubRoutines::_throw_IncompatibleClassChangeError_entry= generate_throw_exception(&quot;IncompatibleClassChangeError throw_exception&quot;, CAST_FROM_FN_PTR(address, SharedRuntime::throw_IncompatibleClassChangeError));
3964     StubRoutines::_throw_NullPointerException_at_call_entry= generate_throw_exception(&quot;NullPointerException at call throw_exception&quot;, CAST_FROM_FN_PTR(address, SharedRuntime::throw_NullPointerException_at_call));
3965 
3966     //------------------------------------------------------------------------------------------------------------------------
3967     // entry points that are platform specific
3968 
<span class="line-added">3969     StubRoutines::x86::_vector_float_sign_mask = generate_vector_mask(&quot;vector_float_sign_mask&quot;, 0x7FFFFFFF);</span>
<span class="line-added">3970     StubRoutines::x86::_vector_float_sign_flip = generate_vector_mask(&quot;vector_float_sign_flip&quot;, 0x80000000);</span>
<span class="line-added">3971     StubRoutines::x86::_vector_double_sign_mask = generate_vector_mask_long_double(&quot;vector_double_sign_mask&quot;, 0x7FFFFFFF, 0xFFFFFFFF);</span>
<span class="line-added">3972     StubRoutines::x86::_vector_double_sign_flip = generate_vector_mask_long_double(&quot;vector_double_sign_flip&quot;, 0x80000000, 0x00000000);</span>
<span class="line-added">3973     StubRoutines::x86::_vector_short_to_byte_mask = generate_vector_mask(&quot;vector_short_to_byte_mask&quot;, 0x00ff00ff);</span>
<span class="line-added">3974     StubRoutines::x86::_vector_byte_perm_mask = generate_vector_byte_perm_mask(&quot;vector_byte_perm_mask&quot;);</span>
<span class="line-added">3975     StubRoutines::x86::_vector_long_sign_mask = generate_vector_mask_long_double(&quot;vector_long_sign_mask&quot;, 0x80000000, 0x00000000);</span>
<span class="line-added">3976 </span>
3977     // support for verify_oop (must happen after universe_init)
3978     StubRoutines::_verify_oop_subroutine_entry     = generate_verify_oop();
3979 
3980     // arraycopy stubs used by compilers
3981     generate_arraycopy_stubs();
3982 
3983     // don&#39;t bother generating these AES intrinsic stubs unless global flag is set
3984     if (UseAESIntrinsics) {
3985       StubRoutines::x86::_key_shuffle_mask_addr = generate_key_shuffle_mask();  // might be needed by the others
3986 
3987       StubRoutines::_aescrypt_encryptBlock = generate_aescrypt_encryptBlock();
3988       StubRoutines::_aescrypt_decryptBlock = generate_aescrypt_decryptBlock();
3989       StubRoutines::_cipherBlockChaining_encryptAESCrypt = generate_cipherBlockChaining_encryptAESCrypt();
3990       StubRoutines::_cipherBlockChaining_decryptAESCrypt = generate_cipherBlockChaining_decryptAESCrypt_Parallel();
3991     }
3992 
3993     if (UseAESCTRIntrinsics) {
3994       StubRoutines::x86::_counter_shuffle_mask_addr = generate_counter_shuffle_mask();
3995       StubRoutines::_counterMode_AESCrypt = generate_counterMode_AESCrypt_Parallel();
3996     }
</pre>
<hr />
<pre>
4005       StubRoutines::x86::_k256_adr = (address)StubRoutines::x86::_k256;
4006       StubRoutines::x86::_pshuffle_byte_flip_mask_addr = generate_pshuffle_byte_flip_mask();
4007       StubRoutines::_sha256_implCompress = generate_sha256_implCompress(false, &quot;sha256_implCompress&quot;);
4008       StubRoutines::_sha256_implCompressMB = generate_sha256_implCompress(true, &quot;sha256_implCompressMB&quot;);
4009     }
4010 
4011     // Generate GHASH intrinsics code
4012     if (UseGHASHIntrinsics) {
4013       StubRoutines::x86::_ghash_long_swap_mask_addr = generate_ghash_long_swap_mask();
4014       StubRoutines::x86::_ghash_byte_swap_mask_addr = generate_ghash_byte_swap_mask();
4015       StubRoutines::_ghash_processBlocks = generate_ghash_processBlocks();
4016     }
4017 
4018     // Safefetch stubs.
4019     generate_safefetch(&quot;SafeFetch32&quot;, sizeof(int), &amp;StubRoutines::_safefetch32_entry,
4020                                                    &amp;StubRoutines::_safefetch32_fault_pc,
4021                                                    &amp;StubRoutines::_safefetch32_continuation_pc);
4022     StubRoutines::_safefetchN_entry           = StubRoutines::_safefetch32_entry;
4023     StubRoutines::_safefetchN_fault_pc        = StubRoutines::_safefetch32_fault_pc;
4024     StubRoutines::_safefetchN_continuation_pc = StubRoutines::_safefetch32_continuation_pc;
<span class="line-added">4025 </span>
<span class="line-added">4026     BarrierSetNMethod* bs_nm = BarrierSet::barrier_set()-&gt;barrier_set_nmethod();</span>
<span class="line-added">4027     if (bs_nm != NULL) {</span>
<span class="line-added">4028       StubRoutines::x86::_method_entry_barrier = generate_method_entry_barrier();</span>
<span class="line-added">4029     }</span>
4030   }
4031 
4032 
4033  public:
4034   StubGenerator(CodeBuffer* code, bool all) : StubCodeGenerator(code) {
4035     if (all) {
4036       generate_all();
4037     } else {
4038       generate_initial();
4039     }
4040   }
4041 }; // end class declaration
4042 
<span class="line-modified">4043 #define UCM_TABLE_MAX_ENTRIES 8</span>
4044 void StubGenerator_generate(CodeBuffer* code, bool all) {
<span class="line-added">4045   if (UnsafeCopyMemory::_table == NULL) {</span>
<span class="line-added">4046     UnsafeCopyMemory::create_table(UCM_TABLE_MAX_ENTRIES);</span>
<span class="line-added">4047   }</span>
4048   StubGenerator g(code, all);
4049 }
</pre>
</td>
</tr>
</table>
<center><a href="sharedRuntime_x86_64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_x86_64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>