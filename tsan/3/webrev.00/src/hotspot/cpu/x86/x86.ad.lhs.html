<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/x86/x86.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>    1 //
    2 // Copyright (c) 2011, 2019, Oracle and/or its affiliates. All rights reserved.
    3 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    4 //
    5 // This code is free software; you can redistribute it and/or modify it
    6 // under the terms of the GNU General Public License version 2 only, as
    7 // published by the Free Software Foundation.
    8 //
    9 // This code is distributed in the hope that it will be useful, but WITHOUT
   10 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   11 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   12 // version 2 for more details (a copy is included in the LICENSE file that
   13 // accompanied this code).
   14 //
   15 // You should have received a copy of the GNU General Public License version
   16 // 2 along with this work; if not, write to the Free Software Foundation,
   17 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   18 //
   19 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   20 // or visit www.oracle.com if you need additional information or have any
   21 // questions.
   22 //
   23 //
   24 
   25 // X86 Common Architecture Description File
   26 
   27 //----------REGISTER DEFINITION BLOCK------------------------------------------
   28 // This information is used by the matcher and the register allocator to
   29 // describe individual registers and classes of registers within the target
   30 // archtecture.
   31 
   32 register %{
   33 //----------Architecture Description Register Definitions----------------------
   34 // General Registers
   35 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   36 //                   ideal register type, encoding );
   37 // Register Save Types:
   38 //
   39 // NS  = No-Save:       The register allocator assumes that these registers
   40 //                      can be used without saving upon entry to the method, &amp;
   41 //                      that they do not need to be saved at call sites.
   42 //
   43 // SOC = Save-On-Call:  The register allocator assumes that these registers
   44 //                      can be used without saving upon entry to the method,
   45 //                      but that they must be saved at call sites.
   46 //
   47 // SOE = Save-On-Entry: The register allocator assumes that these registers
   48 //                      must be saved before using them upon entry to the
   49 //                      method, but they do not need to be saved at call
   50 //                      sites.
   51 //
   52 // AS  = Always-Save:   The register allocator assumes that these registers
   53 //                      must be saved before using them upon entry to the
   54 //                      method, &amp; that they must be saved at call sites.
   55 //
   56 // Ideal Register Type is used to determine how to save &amp; restore a
   57 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   58 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   59 //
   60 // The encoding number is the actual bit-pattern placed into the opcodes.
   61 
   62 // XMM registers.  512-bit registers or 8 words each, labeled (a)-p.
   63 // Word a in each register holds a Float, words ab hold a Double.
   64 // The whole registers are used in SSE4.2 version intrinsics,
   65 // array copy stubs and superword operations (see UseSSE42Intrinsics,
   66 // UseXMMForArrayCopy and UseSuperword flags).
   67 // For pre EVEX enabled architectures:
   68 //      XMM8-XMM15 must be encoded with REX (VEX for UseAVX)
   69 // For EVEX enabled architectures:
   70 //      XMM8-XMM31 must be encoded with REX (EVEX for UseAVX).
   71 //
   72 // Linux ABI:   No register preserved across function calls
   73 //              XMM0-XMM7 might hold parameters
   74 // Windows ABI: XMM6-XMM31 preserved across function calls
   75 //              XMM0-XMM3 might hold parameters
   76 
   77 reg_def XMM0 ( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg());
   78 reg_def XMM0b( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(1));
   79 reg_def XMM0c( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(2));
   80 reg_def XMM0d( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(3));
   81 reg_def XMM0e( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(4));
   82 reg_def XMM0f( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(5));
   83 reg_def XMM0g( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(6));
   84 reg_def XMM0h( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(7));
   85 reg_def XMM0i( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(8));
   86 reg_def XMM0j( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(9));
   87 reg_def XMM0k( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(10));
   88 reg_def XMM0l( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(11));
   89 reg_def XMM0m( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(12));
   90 reg_def XMM0n( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(13));
   91 reg_def XMM0o( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(14));
   92 reg_def XMM0p( SOC, SOC, Op_RegF, 0, xmm0-&gt;as_VMReg()-&gt;next(15));
   93 
   94 reg_def XMM1 ( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg());
   95 reg_def XMM1b( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(1));
   96 reg_def XMM1c( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(2));
   97 reg_def XMM1d( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(3));
   98 reg_def XMM1e( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(4));
   99 reg_def XMM1f( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(5));
  100 reg_def XMM1g( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(6));
  101 reg_def XMM1h( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(7));
  102 reg_def XMM1i( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(8));
  103 reg_def XMM1j( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(9));
  104 reg_def XMM1k( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(10));
  105 reg_def XMM1l( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(11));
  106 reg_def XMM1m( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(12));
  107 reg_def XMM1n( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(13));
  108 reg_def XMM1o( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(14));
  109 reg_def XMM1p( SOC, SOC, Op_RegF, 1, xmm1-&gt;as_VMReg()-&gt;next(15));
  110 
  111 reg_def XMM2 ( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg());
  112 reg_def XMM2b( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(1));
  113 reg_def XMM2c( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(2));
  114 reg_def XMM2d( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(3));
  115 reg_def XMM2e( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(4));
  116 reg_def XMM2f( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(5));
  117 reg_def XMM2g( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(6));
  118 reg_def XMM2h( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(7));
  119 reg_def XMM2i( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(8));
  120 reg_def XMM2j( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(9));
  121 reg_def XMM2k( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(10));
  122 reg_def XMM2l( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(11));
  123 reg_def XMM2m( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(12));
  124 reg_def XMM2n( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(13));
  125 reg_def XMM2o( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(14));
  126 reg_def XMM2p( SOC, SOC, Op_RegF, 2, xmm2-&gt;as_VMReg()-&gt;next(15));
  127 
  128 reg_def XMM3 ( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg());
  129 reg_def XMM3b( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(1));
  130 reg_def XMM3c( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(2));
  131 reg_def XMM3d( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(3));
  132 reg_def XMM3e( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(4));
  133 reg_def XMM3f( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(5));
  134 reg_def XMM3g( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(6));
  135 reg_def XMM3h( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(7));
  136 reg_def XMM3i( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(8));
  137 reg_def XMM3j( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(9));
  138 reg_def XMM3k( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(10));
  139 reg_def XMM3l( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(11));
  140 reg_def XMM3m( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(12));
  141 reg_def XMM3n( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(13));
  142 reg_def XMM3o( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(14));
  143 reg_def XMM3p( SOC, SOC, Op_RegF, 3, xmm3-&gt;as_VMReg()-&gt;next(15));
  144 
  145 reg_def XMM4 ( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg());
  146 reg_def XMM4b( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(1));
  147 reg_def XMM4c( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(2));
  148 reg_def XMM4d( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(3));
  149 reg_def XMM4e( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(4));
  150 reg_def XMM4f( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(5));
  151 reg_def XMM4g( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(6));
  152 reg_def XMM4h( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(7));
  153 reg_def XMM4i( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(8));
  154 reg_def XMM4j( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(9));
  155 reg_def XMM4k( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(10));
  156 reg_def XMM4l( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(11));
  157 reg_def XMM4m( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(12));
  158 reg_def XMM4n( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(13));
  159 reg_def XMM4o( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(14));
  160 reg_def XMM4p( SOC, SOC, Op_RegF, 4, xmm4-&gt;as_VMReg()-&gt;next(15));
  161 
  162 reg_def XMM5 ( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg());
  163 reg_def XMM5b( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(1));
  164 reg_def XMM5c( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(2));
  165 reg_def XMM5d( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(3));
  166 reg_def XMM5e( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(4));
  167 reg_def XMM5f( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(5));
  168 reg_def XMM5g( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(6));
  169 reg_def XMM5h( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(7));
  170 reg_def XMM5i( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(8));
  171 reg_def XMM5j( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(9));
  172 reg_def XMM5k( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(10));
  173 reg_def XMM5l( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(11));
  174 reg_def XMM5m( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(12));
  175 reg_def XMM5n( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(13));
  176 reg_def XMM5o( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(14));
  177 reg_def XMM5p( SOC, SOC, Op_RegF, 5, xmm5-&gt;as_VMReg()-&gt;next(15));
  178 
  179 reg_def XMM6 ( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg());
  180 reg_def XMM6b( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(1));
  181 reg_def XMM6c( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(2));
  182 reg_def XMM6d( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(3));
  183 reg_def XMM6e( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(4));
  184 reg_def XMM6f( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(5));
  185 reg_def XMM6g( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(6));
  186 reg_def XMM6h( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(7));
  187 reg_def XMM6i( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(8));
  188 reg_def XMM6j( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(9));
  189 reg_def XMM6k( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(10));
  190 reg_def XMM6l( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(11));
  191 reg_def XMM6m( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(12));
  192 reg_def XMM6n( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(13));
  193 reg_def XMM6o( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(14));
  194 reg_def XMM6p( SOC, SOC, Op_RegF, 6, xmm6-&gt;as_VMReg()-&gt;next(15));
  195 
  196 reg_def XMM7 ( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg());
  197 reg_def XMM7b( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(1));
  198 reg_def XMM7c( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(2));
  199 reg_def XMM7d( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(3));
  200 reg_def XMM7e( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(4));
  201 reg_def XMM7f( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(5));
  202 reg_def XMM7g( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(6));
  203 reg_def XMM7h( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(7));
  204 reg_def XMM7i( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(8));
  205 reg_def XMM7j( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(9));
  206 reg_def XMM7k( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(10));
  207 reg_def XMM7l( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(11));
  208 reg_def XMM7m( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(12));
  209 reg_def XMM7n( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(13));
  210 reg_def XMM7o( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(14));
  211 reg_def XMM7p( SOC, SOC, Op_RegF, 7, xmm7-&gt;as_VMReg()-&gt;next(15));
  212 
  213 #ifdef _LP64
  214 
  215 reg_def XMM8 ( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg());
  216 reg_def XMM8b( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(1));
  217 reg_def XMM8c( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(2));
  218 reg_def XMM8d( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(3));
  219 reg_def XMM8e( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(4));
  220 reg_def XMM8f( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(5));
  221 reg_def XMM8g( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(6));
  222 reg_def XMM8h( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(7));
  223 reg_def XMM8i( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(8));
  224 reg_def XMM8j( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(9));
  225 reg_def XMM8k( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(10));
  226 reg_def XMM8l( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(11));
  227 reg_def XMM8m( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(12));
  228 reg_def XMM8n( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(13));
  229 reg_def XMM8o( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(14));
  230 reg_def XMM8p( SOC, SOC, Op_RegF, 8, xmm8-&gt;as_VMReg()-&gt;next(15));
  231 
  232 reg_def XMM9 ( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg());
  233 reg_def XMM9b( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(1));
  234 reg_def XMM9c( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(2));
  235 reg_def XMM9d( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(3));
  236 reg_def XMM9e( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(4));
  237 reg_def XMM9f( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(5));
  238 reg_def XMM9g( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(6));
  239 reg_def XMM9h( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(7));
  240 reg_def XMM9i( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(8));
  241 reg_def XMM9j( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(9));
  242 reg_def XMM9k( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(10));
  243 reg_def XMM9l( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(11));
  244 reg_def XMM9m( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(12));
  245 reg_def XMM9n( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(13));
  246 reg_def XMM9o( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(14));
  247 reg_def XMM9p( SOC, SOC, Op_RegF, 9, xmm9-&gt;as_VMReg()-&gt;next(15));
  248 
  249 reg_def XMM10 ( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg());
  250 reg_def XMM10b( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(1));
  251 reg_def XMM10c( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(2));
  252 reg_def XMM10d( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(3));
  253 reg_def XMM10e( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(4));
  254 reg_def XMM10f( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(5));
  255 reg_def XMM10g( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(6));
  256 reg_def XMM10h( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(7));
  257 reg_def XMM10i( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(8));
  258 reg_def XMM10j( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(9));
  259 reg_def XMM10k( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(10));
  260 reg_def XMM10l( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(11));
  261 reg_def XMM10m( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(12));
  262 reg_def XMM10n( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(13));
  263 reg_def XMM10o( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(14));
  264 reg_def XMM10p( SOC, SOC, Op_RegF, 10, xmm10-&gt;as_VMReg()-&gt;next(15));
  265 
  266 reg_def XMM11 ( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg());
  267 reg_def XMM11b( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(1));
  268 reg_def XMM11c( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(2));
  269 reg_def XMM11d( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(3));
  270 reg_def XMM11e( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(4));
  271 reg_def XMM11f( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(5));
  272 reg_def XMM11g( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(6));
  273 reg_def XMM11h( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(7));
  274 reg_def XMM11i( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(8));
  275 reg_def XMM11j( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(9));
  276 reg_def XMM11k( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(10));
  277 reg_def XMM11l( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(11));
  278 reg_def XMM11m( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(12));
  279 reg_def XMM11n( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(13));
  280 reg_def XMM11o( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(14));
  281 reg_def XMM11p( SOC, SOC, Op_RegF, 11, xmm11-&gt;as_VMReg()-&gt;next(15));
  282 
  283 reg_def XMM12 ( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg());
  284 reg_def XMM12b( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(1));
  285 reg_def XMM12c( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(2));
  286 reg_def XMM12d( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(3));
  287 reg_def XMM12e( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(4));
  288 reg_def XMM12f( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(5));
  289 reg_def XMM12g( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(6));
  290 reg_def XMM12h( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(7));
  291 reg_def XMM12i( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(8));
  292 reg_def XMM12j( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(9));
  293 reg_def XMM12k( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(10));
  294 reg_def XMM12l( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(11));
  295 reg_def XMM12m( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(12));
  296 reg_def XMM12n( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(13));
  297 reg_def XMM12o( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(14));
  298 reg_def XMM12p( SOC, SOC, Op_RegF, 12, xmm12-&gt;as_VMReg()-&gt;next(15));
  299 
  300 reg_def XMM13 ( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg());
  301 reg_def XMM13b( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(1));
  302 reg_def XMM13c( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(2));
  303 reg_def XMM13d( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(3));
  304 reg_def XMM13e( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(4));
  305 reg_def XMM13f( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(5));
  306 reg_def XMM13g( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(6));
  307 reg_def XMM13h( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(7));
  308 reg_def XMM13i( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(8));
  309 reg_def XMM13j( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(9));
  310 reg_def XMM13k( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(10));
  311 reg_def XMM13l( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(11));
  312 reg_def XMM13m( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(12));
  313 reg_def XMM13n( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(13));
  314 reg_def XMM13o( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(14));
  315 reg_def XMM13p( SOC, SOC, Op_RegF, 13, xmm13-&gt;as_VMReg()-&gt;next(15));
  316 
  317 reg_def XMM14 ( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg());
  318 reg_def XMM14b( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(1));
  319 reg_def XMM14c( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(2));
  320 reg_def XMM14d( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(3));
  321 reg_def XMM14e( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(4));
  322 reg_def XMM14f( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(5));
  323 reg_def XMM14g( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(6));
  324 reg_def XMM14h( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(7));
  325 reg_def XMM14i( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(8));
  326 reg_def XMM14j( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(9));
  327 reg_def XMM14k( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(10));
  328 reg_def XMM14l( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(11));
  329 reg_def XMM14m( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(12));
  330 reg_def XMM14n( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(13));
  331 reg_def XMM14o( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(14));
  332 reg_def XMM14p( SOC, SOC, Op_RegF, 14, xmm14-&gt;as_VMReg()-&gt;next(15));
  333 
  334 reg_def XMM15 ( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg());
  335 reg_def XMM15b( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(1));
  336 reg_def XMM15c( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(2));
  337 reg_def XMM15d( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(3));
  338 reg_def XMM15e( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(4));
  339 reg_def XMM15f( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(5));
  340 reg_def XMM15g( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(6));
  341 reg_def XMM15h( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(7));
  342 reg_def XMM15i( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(8));
  343 reg_def XMM15j( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(9));
  344 reg_def XMM15k( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(10));
  345 reg_def XMM15l( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(11));
  346 reg_def XMM15m( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(12));
  347 reg_def XMM15n( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(13));
  348 reg_def XMM15o( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(14));
  349 reg_def XMM15p( SOC, SOC, Op_RegF, 15, xmm15-&gt;as_VMReg()-&gt;next(15));
  350 
  351 reg_def XMM16 ( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg());
  352 reg_def XMM16b( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(1));
  353 reg_def XMM16c( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(2));
  354 reg_def XMM16d( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(3));
  355 reg_def XMM16e( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(4));
  356 reg_def XMM16f( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(5));
  357 reg_def XMM16g( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(6));
  358 reg_def XMM16h( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(7));
  359 reg_def XMM16i( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(8));
  360 reg_def XMM16j( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(9));
  361 reg_def XMM16k( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(10));
  362 reg_def XMM16l( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(11));
  363 reg_def XMM16m( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(12));
  364 reg_def XMM16n( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(13));
  365 reg_def XMM16o( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(14));
  366 reg_def XMM16p( SOC, SOC, Op_RegF, 16, xmm16-&gt;as_VMReg()-&gt;next(15));
  367 
  368 reg_def XMM17 ( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg());
  369 reg_def XMM17b( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(1));
  370 reg_def XMM17c( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(2));
  371 reg_def XMM17d( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(3));
  372 reg_def XMM17e( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(4));
  373 reg_def XMM17f( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(5));
  374 reg_def XMM17g( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(6));
  375 reg_def XMM17h( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(7));
  376 reg_def XMM17i( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(8));
  377 reg_def XMM17j( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(9));
  378 reg_def XMM17k( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(10));
  379 reg_def XMM17l( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(11));
  380 reg_def XMM17m( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(12));
  381 reg_def XMM17n( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(13));
  382 reg_def XMM17o( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(14));
  383 reg_def XMM17p( SOC, SOC, Op_RegF, 17, xmm17-&gt;as_VMReg()-&gt;next(15));
  384 
  385 reg_def XMM18 ( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg());
  386 reg_def XMM18b( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(1));
  387 reg_def XMM18c( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(2));
  388 reg_def XMM18d( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(3));
  389 reg_def XMM18e( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(4));
  390 reg_def XMM18f( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(5));
  391 reg_def XMM18g( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(6));
  392 reg_def XMM18h( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(7));
  393 reg_def XMM18i( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(8));
  394 reg_def XMM18j( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(9));
  395 reg_def XMM18k( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(10));
  396 reg_def XMM18l( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(11));
  397 reg_def XMM18m( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(12));
  398 reg_def XMM18n( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(13));
  399 reg_def XMM18o( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(14));
  400 reg_def XMM18p( SOC, SOC, Op_RegF, 18, xmm18-&gt;as_VMReg()-&gt;next(15));
  401 
  402 reg_def XMM19 ( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg());
  403 reg_def XMM19b( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(1));
  404 reg_def XMM19c( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(2));
  405 reg_def XMM19d( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(3));
  406 reg_def XMM19e( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(4));
  407 reg_def XMM19f( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(5));
  408 reg_def XMM19g( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(6));
  409 reg_def XMM19h( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(7));
  410 reg_def XMM19i( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(8));
  411 reg_def XMM19j( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(9));
  412 reg_def XMM19k( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(10));
  413 reg_def XMM19l( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(11));
  414 reg_def XMM19m( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(12));
  415 reg_def XMM19n( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(13));
  416 reg_def XMM19o( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(14));
  417 reg_def XMM19p( SOC, SOC, Op_RegF, 19, xmm19-&gt;as_VMReg()-&gt;next(15));
  418 
  419 reg_def XMM20 ( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg());
  420 reg_def XMM20b( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(1));
  421 reg_def XMM20c( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(2));
  422 reg_def XMM20d( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(3));
  423 reg_def XMM20e( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(4));
  424 reg_def XMM20f( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(5));
  425 reg_def XMM20g( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(6));
  426 reg_def XMM20h( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(7));
  427 reg_def XMM20i( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(8));
  428 reg_def XMM20j( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(9));
  429 reg_def XMM20k( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(10));
  430 reg_def XMM20l( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(11));
  431 reg_def XMM20m( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(12));
  432 reg_def XMM20n( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(13));
  433 reg_def XMM20o( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(14));
  434 reg_def XMM20p( SOC, SOC, Op_RegF, 20, xmm20-&gt;as_VMReg()-&gt;next(15));
  435 
  436 reg_def XMM21 ( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg());
  437 reg_def XMM21b( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(1));
  438 reg_def XMM21c( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(2));
  439 reg_def XMM21d( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(3));
  440 reg_def XMM21e( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(4));
  441 reg_def XMM21f( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(5));
  442 reg_def XMM21g( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(6));
  443 reg_def XMM21h( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(7));
  444 reg_def XMM21i( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(8));
  445 reg_def XMM21j( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(9));
  446 reg_def XMM21k( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(10));
  447 reg_def XMM21l( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(11));
  448 reg_def XMM21m( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(12));
  449 reg_def XMM21n( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(13));
  450 reg_def XMM21o( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(14));
  451 reg_def XMM21p( SOC, SOC, Op_RegF, 21, xmm21-&gt;as_VMReg()-&gt;next(15));
  452 
  453 reg_def XMM22 ( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg());
  454 reg_def XMM22b( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(1));
  455 reg_def XMM22c( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(2));
  456 reg_def XMM22d( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(3));
  457 reg_def XMM22e( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(4));
  458 reg_def XMM22f( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(5));
  459 reg_def XMM22g( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(6));
  460 reg_def XMM22h( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(7));
  461 reg_def XMM22i( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(8));
  462 reg_def XMM22j( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(9));
  463 reg_def XMM22k( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(10));
  464 reg_def XMM22l( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(11));
  465 reg_def XMM22m( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(12));
  466 reg_def XMM22n( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(13));
  467 reg_def XMM22o( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(14));
  468 reg_def XMM22p( SOC, SOC, Op_RegF, 22, xmm22-&gt;as_VMReg()-&gt;next(15));
  469 
  470 reg_def XMM23 ( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg());
  471 reg_def XMM23b( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(1));
  472 reg_def XMM23c( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(2));
  473 reg_def XMM23d( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(3));
  474 reg_def XMM23e( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(4));
  475 reg_def XMM23f( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(5));
  476 reg_def XMM23g( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(6));
  477 reg_def XMM23h( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(7));
  478 reg_def XMM23i( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(8));
  479 reg_def XMM23j( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(9));
  480 reg_def XMM23k( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(10));
  481 reg_def XMM23l( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(11));
  482 reg_def XMM23m( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(12));
  483 reg_def XMM23n( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(13));
  484 reg_def XMM23o( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(14));
  485 reg_def XMM23p( SOC, SOC, Op_RegF, 23, xmm23-&gt;as_VMReg()-&gt;next(15));
  486 
  487 reg_def XMM24 ( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg());
  488 reg_def XMM24b( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(1));
  489 reg_def XMM24c( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(2));
  490 reg_def XMM24d( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(3));
  491 reg_def XMM24e( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(4));
  492 reg_def XMM24f( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(5));
  493 reg_def XMM24g( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(6));
  494 reg_def XMM24h( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(7));
  495 reg_def XMM24i( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(8));
  496 reg_def XMM24j( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(9));
  497 reg_def XMM24k( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(10));
  498 reg_def XMM24l( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(11));
  499 reg_def XMM24m( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(12));
  500 reg_def XMM24n( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(13));
  501 reg_def XMM24o( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(14));
  502 reg_def XMM24p( SOC, SOC, Op_RegF, 24, xmm24-&gt;as_VMReg()-&gt;next(15));
  503 
  504 reg_def XMM25 ( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg());
  505 reg_def XMM25b( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(1));
  506 reg_def XMM25c( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(2));
  507 reg_def XMM25d( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(3));
  508 reg_def XMM25e( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(4));
  509 reg_def XMM25f( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(5));
  510 reg_def XMM25g( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(6));
  511 reg_def XMM25h( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(7));
  512 reg_def XMM25i( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(8));
  513 reg_def XMM25j( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(9));
  514 reg_def XMM25k( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(10));
  515 reg_def XMM25l( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(11));
  516 reg_def XMM25m( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(12));
  517 reg_def XMM25n( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(13));
  518 reg_def XMM25o( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(14));
  519 reg_def XMM25p( SOC, SOC, Op_RegF, 25, xmm25-&gt;as_VMReg()-&gt;next(15));
  520 
  521 reg_def XMM26 ( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg());
  522 reg_def XMM26b( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(1));
  523 reg_def XMM26c( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(2));
  524 reg_def XMM26d( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(3));
  525 reg_def XMM26e( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(4));
  526 reg_def XMM26f( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(5));
  527 reg_def XMM26g( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(6));
  528 reg_def XMM26h( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(7));
  529 reg_def XMM26i( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(8));
  530 reg_def XMM26j( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(9));
  531 reg_def XMM26k( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(10));
  532 reg_def XMM26l( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(11));
  533 reg_def XMM26m( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(12));
  534 reg_def XMM26n( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(13));
  535 reg_def XMM26o( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(14));
  536 reg_def XMM26p( SOC, SOC, Op_RegF, 26, xmm26-&gt;as_VMReg()-&gt;next(15));
  537 
  538 reg_def XMM27 ( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg());
  539 reg_def XMM27b( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(1));
  540 reg_def XMM27c( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(2));
  541 reg_def XMM27d( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(3));
  542 reg_def XMM27e( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(4));
  543 reg_def XMM27f( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(5));
  544 reg_def XMM27g( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(6));
  545 reg_def XMM27h( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(7));
  546 reg_def XMM27i( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(8));
  547 reg_def XMM27j( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(9));
  548 reg_def XMM27k( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(10));
  549 reg_def XMM27l( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(11));
  550 reg_def XMM27m( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(12));
  551 reg_def XMM27n( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(13));
  552 reg_def XMM27o( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(14));
  553 reg_def XMM27p( SOC, SOC, Op_RegF, 27, xmm27-&gt;as_VMReg()-&gt;next(15));
  554 
  555 reg_def XMM28 ( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg());
  556 reg_def XMM28b( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(1));
  557 reg_def XMM28c( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(2));
  558 reg_def XMM28d( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(3));
  559 reg_def XMM28e( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(4));
  560 reg_def XMM28f( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(5));
  561 reg_def XMM28g( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(6));
  562 reg_def XMM28h( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(7));
  563 reg_def XMM28i( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(8));
  564 reg_def XMM28j( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(9));
  565 reg_def XMM28k( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(10));
  566 reg_def XMM28l( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(11));
  567 reg_def XMM28m( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(12));
  568 reg_def XMM28n( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(13));
  569 reg_def XMM28o( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(14));
  570 reg_def XMM28p( SOC, SOC, Op_RegF, 28, xmm28-&gt;as_VMReg()-&gt;next(15));
  571 
  572 reg_def XMM29 ( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg());
  573 reg_def XMM29b( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(1));
  574 reg_def XMM29c( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(2));
  575 reg_def XMM29d( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(3));
  576 reg_def XMM29e( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(4));
  577 reg_def XMM29f( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(5));
  578 reg_def XMM29g( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(6));
  579 reg_def XMM29h( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(7));
  580 reg_def XMM29i( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(8));
  581 reg_def XMM29j( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(9));
  582 reg_def XMM29k( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(10));
  583 reg_def XMM29l( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(11));
  584 reg_def XMM29m( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(12));
  585 reg_def XMM29n( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(13));
  586 reg_def XMM29o( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(14));
  587 reg_def XMM29p( SOC, SOC, Op_RegF, 29, xmm29-&gt;as_VMReg()-&gt;next(15));
  588 
  589 reg_def XMM30 ( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg());
  590 reg_def XMM30b( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(1));
  591 reg_def XMM30c( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(2));
  592 reg_def XMM30d( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(3));
  593 reg_def XMM30e( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(4));
  594 reg_def XMM30f( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(5));
  595 reg_def XMM30g( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(6));
  596 reg_def XMM30h( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(7));
  597 reg_def XMM30i( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(8));
  598 reg_def XMM30j( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(9));
  599 reg_def XMM30k( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(10));
  600 reg_def XMM30l( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(11));
  601 reg_def XMM30m( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(12));
  602 reg_def XMM30n( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(13));
  603 reg_def XMM30o( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(14));
  604 reg_def XMM30p( SOC, SOC, Op_RegF, 30, xmm30-&gt;as_VMReg()-&gt;next(15));
  605 
  606 reg_def XMM31 ( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg());
  607 reg_def XMM31b( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(1));
  608 reg_def XMM31c( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(2));
  609 reg_def XMM31d( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(3));
  610 reg_def XMM31e( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(4));
  611 reg_def XMM31f( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(5));
  612 reg_def XMM31g( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(6));
  613 reg_def XMM31h( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(7));
  614 reg_def XMM31i( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(8));
  615 reg_def XMM31j( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(9));
  616 reg_def XMM31k( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(10));
  617 reg_def XMM31l( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(11));
  618 reg_def XMM31m( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(12));
  619 reg_def XMM31n( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(13));
  620 reg_def XMM31o( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(14));
  621 reg_def XMM31p( SOC, SOC, Op_RegF, 31, xmm31-&gt;as_VMReg()-&gt;next(15));
  622 
  623 #endif // _LP64
  624 
  625 #ifdef _LP64
  626 reg_def RFLAGS(SOC, SOC, 0, 16, VMRegImpl::Bad());
  627 #else
  628 reg_def RFLAGS(SOC, SOC, 0, 8, VMRegImpl::Bad());
  629 #endif // _LP64
  630 
  631 alloc_class chunk1(XMM0,  XMM0b,  XMM0c,  XMM0d,  XMM0e,  XMM0f,  XMM0g,  XMM0h,  XMM0i,  XMM0j,  XMM0k,  XMM0l,  XMM0m,  XMM0n,  XMM0o,  XMM0p,
  632                    XMM1,  XMM1b,  XMM1c,  XMM1d,  XMM1e,  XMM1f,  XMM1g,  XMM1h,  XMM1i,  XMM1j,  XMM1k,  XMM1l,  XMM1m,  XMM1n,  XMM1o,  XMM1p,
  633                    XMM2,  XMM2b,  XMM2c,  XMM2d,  XMM2e,  XMM2f,  XMM2g,  XMM2h,  XMM2i,  XMM2j,  XMM2k,  XMM2l,  XMM2m,  XMM2n,  XMM2o,  XMM2p,
  634                    XMM3,  XMM3b,  XMM3c,  XMM3d,  XMM3e,  XMM3f,  XMM3g,  XMM3h,  XMM3i,  XMM3j,  XMM3k,  XMM3l,  XMM3m,  XMM3n,  XMM3o,  XMM3p,
  635                    XMM4,  XMM4b,  XMM4c,  XMM4d,  XMM4e,  XMM4f,  XMM4g,  XMM4h,  XMM4i,  XMM4j,  XMM4k,  XMM4l,  XMM4m,  XMM4n,  XMM4o,  XMM4p,
  636                    XMM5,  XMM5b,  XMM5c,  XMM5d,  XMM5e,  XMM5f,  XMM5g,  XMM5h,  XMM5i,  XMM5j,  XMM5k,  XMM5l,  XMM5m,  XMM5n,  XMM5o,  XMM5p,
  637                    XMM6,  XMM6b,  XMM6c,  XMM6d,  XMM6e,  XMM6f,  XMM6g,  XMM6h,  XMM6i,  XMM6j,  XMM6k,  XMM6l,  XMM6m,  XMM6n,  XMM6o,  XMM6p,
  638                    XMM7,  XMM7b,  XMM7c,  XMM7d,  XMM7e,  XMM7f,  XMM7g,  XMM7h,  XMM7i,  XMM7j,  XMM7k,  XMM7l,  XMM7m,  XMM7n,  XMM7o,  XMM7p
  639 #ifdef _LP64
  640                   ,XMM8,  XMM8b,  XMM8c,  XMM8d,  XMM8e,  XMM8f,  XMM8g,  XMM8h,  XMM8i,  XMM8j,  XMM8k,  XMM8l,  XMM8m,  XMM8n,  XMM8o,  XMM8p,
  641                    XMM9,  XMM9b,  XMM9c,  XMM9d,  XMM9e,  XMM9f,  XMM9g,  XMM9h,  XMM9i,  XMM9j,  XMM9k,  XMM9l,  XMM9m,  XMM9n,  XMM9o,  XMM9p,
  642                    XMM10, XMM10b, XMM10c, XMM10d, XMM10e, XMM10f, XMM10g, XMM10h, XMM10i, XMM10j, XMM10k, XMM10l, XMM10m, XMM10n, XMM10o, XMM10p,
  643                    XMM11, XMM11b, XMM11c, XMM11d, XMM11e, XMM11f, XMM11g, XMM11h, XMM11i, XMM11j, XMM11k, XMM11l, XMM11m, XMM11n, XMM11o, XMM11p,
  644                    XMM12, XMM12b, XMM12c, XMM12d, XMM12e, XMM12f, XMM12g, XMM12h, XMM12i, XMM12j, XMM12k, XMM12l, XMM12m, XMM12n, XMM12o, XMM12p,
  645                    XMM13, XMM13b, XMM13c, XMM13d, XMM13e, XMM13f, XMM13g, XMM13h, XMM13i, XMM13j, XMM13k, XMM13l, XMM13m, XMM13n, XMM13o, XMM13p,
  646                    XMM14, XMM14b, XMM14c, XMM14d, XMM14e, XMM14f, XMM14g, XMM14h, XMM14i, XMM14j, XMM14k, XMM14l, XMM14m, XMM14n, XMM14o, XMM14p,
  647                    XMM15, XMM15b, XMM15c, XMM15d, XMM15e, XMM15f, XMM15g, XMM15h, XMM15i, XMM15j, XMM15k, XMM15l, XMM15m, XMM15n, XMM15o, XMM15p
  648                   ,XMM16, XMM16b, XMM16c, XMM16d, XMM16e, XMM16f, XMM16g, XMM16h, XMM16i, XMM16j, XMM16k, XMM16l, XMM16m, XMM16n, XMM16o, XMM16p,
  649                    XMM17, XMM17b, XMM17c, XMM17d, XMM17e, XMM17f, XMM17g, XMM17h, XMM17i, XMM17j, XMM17k, XMM17l, XMM17m, XMM17n, XMM17o, XMM17p,
  650                    XMM18, XMM18b, XMM18c, XMM18d, XMM18e, XMM18f, XMM18g, XMM18h, XMM18i, XMM18j, XMM18k, XMM18l, XMM18m, XMM18n, XMM18o, XMM18p,
  651                    XMM19, XMM19b, XMM19c, XMM19d, XMM19e, XMM19f, XMM19g, XMM19h, XMM19i, XMM19j, XMM19k, XMM19l, XMM19m, XMM19n, XMM19o, XMM19p,
  652                    XMM20, XMM20b, XMM20c, XMM20d, XMM20e, XMM20f, XMM20g, XMM20h, XMM20i, XMM20j, XMM20k, XMM20l, XMM20m, XMM20n, XMM20o, XMM20p,
  653                    XMM21, XMM21b, XMM21c, XMM21d, XMM21e, XMM21f, XMM21g, XMM21h, XMM21i, XMM21j, XMM21k, XMM21l, XMM21m, XMM21n, XMM21o, XMM21p,
  654                    XMM22, XMM22b, XMM22c, XMM22d, XMM22e, XMM22f, XMM22g, XMM22h, XMM22i, XMM22j, XMM22k, XMM22l, XMM22m, XMM22n, XMM22o, XMM22p,
  655                    XMM23, XMM23b, XMM23c, XMM23d, XMM23e, XMM23f, XMM23g, XMM23h, XMM23i, XMM23j, XMM23k, XMM23l, XMM23m, XMM23n, XMM23o, XMM23p,
  656                    XMM24, XMM24b, XMM24c, XMM24d, XMM24e, XMM24f, XMM24g, XMM24h, XMM24i, XMM24j, XMM24k, XMM24l, XMM24m, XMM24n, XMM24o, XMM24p,
  657                    XMM25, XMM25b, XMM25c, XMM25d, XMM25e, XMM25f, XMM25g, XMM25h, XMM25i, XMM25j, XMM25k, XMM25l, XMM25m, XMM25n, XMM25o, XMM25p,
  658                    XMM26, XMM26b, XMM26c, XMM26d, XMM26e, XMM26f, XMM26g, XMM26h, XMM26i, XMM26j, XMM26k, XMM26l, XMM26m, XMM26n, XMM26o, XMM26p,
  659                    XMM27, XMM27b, XMM27c, XMM27d, XMM27e, XMM27f, XMM27g, XMM27h, XMM27i, XMM27j, XMM27k, XMM27l, XMM27m, XMM27n, XMM27o, XMM27p,
  660                    XMM28, XMM28b, XMM28c, XMM28d, XMM28e, XMM28f, XMM28g, XMM28h, XMM28i, XMM28j, XMM28k, XMM28l, XMM28m, XMM28n, XMM28o, XMM28p,
  661                    XMM29, XMM29b, XMM29c, XMM29d, XMM29e, XMM29f, XMM29g, XMM29h, XMM29i, XMM29j, XMM29k, XMM29l, XMM29m, XMM29n, XMM29o, XMM29p,
  662                    XMM30, XMM30b, XMM30c, XMM30d, XMM30e, XMM30f, XMM30g, XMM30h, XMM30i, XMM30j, XMM30k, XMM30l, XMM30m, XMM30n, XMM30o, XMM30p,
  663                    XMM31, XMM31b, XMM31c, XMM31d, XMM31e, XMM31f, XMM31g, XMM31h, XMM31i, XMM31j, XMM31k, XMM31l, XMM31m, XMM31n, XMM31o, XMM31p
  664 #endif
  665                       );
  666 
  667 // flags allocation class should be last.
  668 alloc_class chunk2(RFLAGS);
  669 
  670 // Singleton class for condition codes
  671 reg_class int_flags(RFLAGS);
  672 
  673 // Class for pre evex float registers
  674 reg_class float_reg_legacy(XMM0,
  675                     XMM1,
  676                     XMM2,
  677                     XMM3,
  678                     XMM4,
  679                     XMM5,
  680                     XMM6,
  681                     XMM7
  682 #ifdef _LP64
  683                    ,XMM8,
  684                     XMM9,
  685                     XMM10,
  686                     XMM11,
  687                     XMM12,
  688                     XMM13,
  689                     XMM14,
  690                     XMM15
  691 #endif
  692                     );
  693 
  694 // Class for evex float registers
  695 reg_class float_reg_evex(XMM0,
  696                     XMM1,
  697                     XMM2,
  698                     XMM3,
  699                     XMM4,
  700                     XMM5,
  701                     XMM6,
  702                     XMM7
  703 #ifdef _LP64
  704                    ,XMM8,
  705                     XMM9,
  706                     XMM10,
  707                     XMM11,
  708                     XMM12,
  709                     XMM13,
  710                     XMM14,
  711                     XMM15,
  712                     XMM16,
  713                     XMM17,
  714                     XMM18,
  715                     XMM19,
  716                     XMM20,
  717                     XMM21,
  718                     XMM22,
  719                     XMM23,
  720                     XMM24,
  721                     XMM25,
  722                     XMM26,
  723                     XMM27,
  724                     XMM28,
  725                     XMM29,
  726                     XMM30,
  727                     XMM31
  728 #endif
  729                     );
  730 
  731 reg_class_dynamic float_reg(float_reg_evex, float_reg_legacy, %{ VM_Version::supports_evex() %} );
  732 reg_class_dynamic float_reg_vl(float_reg_evex, float_reg_legacy, %{ VM_Version::supports_evex() &amp;&amp; VM_Version::supports_avx512vl() %} );
  733 
  734 // Class for pre evex double registers
  735 reg_class double_reg_legacy(XMM0,  XMM0b,
  736                      XMM1,  XMM1b,
  737                      XMM2,  XMM2b,
  738                      XMM3,  XMM3b,
  739                      XMM4,  XMM4b,
  740                      XMM5,  XMM5b,
  741                      XMM6,  XMM6b,
  742                      XMM7,  XMM7b
  743 #ifdef _LP64
  744                     ,XMM8,  XMM8b,
  745                      XMM9,  XMM9b,
  746                      XMM10, XMM10b,
  747                      XMM11, XMM11b,
  748                      XMM12, XMM12b,
  749                      XMM13, XMM13b,
  750                      XMM14, XMM14b,
  751                      XMM15, XMM15b
  752 #endif
  753                      );
  754 
  755 // Class for evex double registers
  756 reg_class double_reg_evex(XMM0,  XMM0b,
  757                      XMM1,  XMM1b,
  758                      XMM2,  XMM2b,
  759                      XMM3,  XMM3b,
  760                      XMM4,  XMM4b,
  761                      XMM5,  XMM5b,
  762                      XMM6,  XMM6b,
  763                      XMM7,  XMM7b
  764 #ifdef _LP64
  765                     ,XMM8,  XMM8b,
  766                      XMM9,  XMM9b,
  767                      XMM10, XMM10b,
  768                      XMM11, XMM11b,
  769                      XMM12, XMM12b,
  770                      XMM13, XMM13b,
  771                      XMM14, XMM14b,
  772                      XMM15, XMM15b,
  773                      XMM16, XMM16b,
  774                      XMM17, XMM17b,
  775                      XMM18, XMM18b,
  776                      XMM19, XMM19b,
  777                      XMM20, XMM20b,
  778                      XMM21, XMM21b,
  779                      XMM22, XMM22b,
  780                      XMM23, XMM23b,
  781                      XMM24, XMM24b,
  782                      XMM25, XMM25b,
  783                      XMM26, XMM26b,
  784                      XMM27, XMM27b,
  785                      XMM28, XMM28b,
  786                      XMM29, XMM29b,
  787                      XMM30, XMM30b,
  788                      XMM31, XMM31b
  789 #endif
  790                      );
  791 
  792 reg_class_dynamic double_reg(double_reg_evex, double_reg_legacy, %{ VM_Version::supports_evex() %} );
  793 reg_class_dynamic double_reg_vl(double_reg_evex, double_reg_legacy, %{ VM_Version::supports_evex() &amp;&amp; VM_Version::supports_avx512vl() %} );
  794 
  795 // Class for pre evex 32bit vector registers
  796 reg_class vectors_reg_legacy(XMM0,
  797                       XMM1,
  798                       XMM2,
  799                       XMM3,
  800                       XMM4,
  801                       XMM5,
  802                       XMM6,
  803                       XMM7
  804 #ifdef _LP64
  805                      ,XMM8,
  806                       XMM9,
  807                       XMM10,
  808                       XMM11,
  809                       XMM12,
  810                       XMM13,
  811                       XMM14,
  812                       XMM15
  813 #endif
  814                       );
  815 
  816 // Class for evex 32bit vector registers
  817 reg_class vectors_reg_evex(XMM0,
  818                       XMM1,
  819                       XMM2,
  820                       XMM3,
  821                       XMM4,
  822                       XMM5,
  823                       XMM6,
  824                       XMM7
  825 #ifdef _LP64
  826                      ,XMM8,
  827                       XMM9,
  828                       XMM10,
  829                       XMM11,
  830                       XMM12,
  831                       XMM13,
  832                       XMM14,
  833                       XMM15,
  834                       XMM16,
  835                       XMM17,
  836                       XMM18,
  837                       XMM19,
  838                       XMM20,
  839                       XMM21,
  840                       XMM22,
  841                       XMM23,
  842                       XMM24,
  843                       XMM25,
  844                       XMM26,
  845                       XMM27,
  846                       XMM28,
  847                       XMM29,
  848                       XMM30,
  849                       XMM31
  850 #endif
  851                       );
  852 
  853 reg_class_dynamic vectors_reg(vectors_reg_evex, vectors_reg_legacy, %{ VM_Version::supports_evex() %} );
  854 reg_class_dynamic vectors_reg_vlbwdq(vectors_reg_evex, vectors_reg_legacy, %{ VM_Version::supports_avx512vlbwdq() %} );
  855 
  856 // Class for all 64bit vector registers
  857 reg_class vectord_reg_legacy(XMM0,  XMM0b,
  858                       XMM1,  XMM1b,
  859                       XMM2,  XMM2b,
  860                       XMM3,  XMM3b,
  861                       XMM4,  XMM4b,
  862                       XMM5,  XMM5b,
  863                       XMM6,  XMM6b,
  864                       XMM7,  XMM7b
  865 #ifdef _LP64
  866                      ,XMM8,  XMM8b,
  867                       XMM9,  XMM9b,
  868                       XMM10, XMM10b,
  869                       XMM11, XMM11b,
  870                       XMM12, XMM12b,
  871                       XMM13, XMM13b,
  872                       XMM14, XMM14b,
  873                       XMM15, XMM15b
  874 #endif
  875                       );
  876 
  877 // Class for all 64bit vector registers
  878 reg_class vectord_reg_evex(XMM0,  XMM0b,
  879                       XMM1,  XMM1b,
  880                       XMM2,  XMM2b,
  881                       XMM3,  XMM3b,
  882                       XMM4,  XMM4b,
  883                       XMM5,  XMM5b,
  884                       XMM6,  XMM6b,
  885                       XMM7,  XMM7b
  886 #ifdef _LP64
  887                      ,XMM8,  XMM8b,
  888                       XMM9,  XMM9b,
  889                       XMM10, XMM10b,
  890                       XMM11, XMM11b,
  891                       XMM12, XMM12b,
  892                       XMM13, XMM13b,
  893                       XMM14, XMM14b,
  894                       XMM15, XMM15b,
  895                       XMM16, XMM16b,
  896                       XMM17, XMM17b,
  897                       XMM18, XMM18b,
  898                       XMM19, XMM19b,
  899                       XMM20, XMM20b,
  900                       XMM21, XMM21b,
  901                       XMM22, XMM22b,
  902                       XMM23, XMM23b,
  903                       XMM24, XMM24b,
  904                       XMM25, XMM25b,
  905                       XMM26, XMM26b,
  906                       XMM27, XMM27b,
  907                       XMM28, XMM28b,
  908                       XMM29, XMM29b,
  909                       XMM30, XMM30b,
  910                       XMM31, XMM31b
  911 #endif
  912                       );
  913 
  914 reg_class_dynamic vectord_reg(vectord_reg_evex, vectord_reg_legacy, %{ VM_Version::supports_evex() %} );
  915 reg_class_dynamic vectord_reg_vlbwdq(vectord_reg_evex, vectord_reg_legacy, %{ VM_Version::supports_avx512vlbwdq() %} );
  916 
  917 // Class for all 128bit vector registers
  918 reg_class vectorx_reg_legacy(XMM0,  XMM0b,  XMM0c,  XMM0d,
  919                       XMM1,  XMM1b,  XMM1c,  XMM1d,
  920                       XMM2,  XMM2b,  XMM2c,  XMM2d,
  921                       XMM3,  XMM3b,  XMM3c,  XMM3d,
  922                       XMM4,  XMM4b,  XMM4c,  XMM4d,
  923                       XMM5,  XMM5b,  XMM5c,  XMM5d,
  924                       XMM6,  XMM6b,  XMM6c,  XMM6d,
  925                       XMM7,  XMM7b,  XMM7c,  XMM7d
  926 #ifdef _LP64
  927                      ,XMM8,  XMM8b,  XMM8c,  XMM8d,
  928                       XMM9,  XMM9b,  XMM9c,  XMM9d,
  929                       XMM10, XMM10b, XMM10c, XMM10d,
  930                       XMM11, XMM11b, XMM11c, XMM11d,
  931                       XMM12, XMM12b, XMM12c, XMM12d,
  932                       XMM13, XMM13b, XMM13c, XMM13d,
  933                       XMM14, XMM14b, XMM14c, XMM14d,
  934                       XMM15, XMM15b, XMM15c, XMM15d
  935 #endif
  936                       );
  937 
  938 // Class for all 128bit vector registers
  939 reg_class vectorx_reg_evex(XMM0,  XMM0b,  XMM0c,  XMM0d,
  940                       XMM1,  XMM1b,  XMM1c,  XMM1d,
  941                       XMM2,  XMM2b,  XMM2c,  XMM2d,
  942                       XMM3,  XMM3b,  XMM3c,  XMM3d,
  943                       XMM4,  XMM4b,  XMM4c,  XMM4d,
  944                       XMM5,  XMM5b,  XMM5c,  XMM5d,
  945                       XMM6,  XMM6b,  XMM6c,  XMM6d,
  946                       XMM7,  XMM7b,  XMM7c,  XMM7d
  947 #ifdef _LP64
  948                      ,XMM8,  XMM8b,  XMM8c,  XMM8d,
  949                       XMM9,  XMM9b,  XMM9c,  XMM9d,
  950                       XMM10, XMM10b, XMM10c, XMM10d,
  951                       XMM11, XMM11b, XMM11c, XMM11d,
  952                       XMM12, XMM12b, XMM12c, XMM12d,
  953                       XMM13, XMM13b, XMM13c, XMM13d,
  954                       XMM14, XMM14b, XMM14c, XMM14d,
  955                       XMM15, XMM15b, XMM15c, XMM15d,
  956                       XMM16, XMM16b, XMM16c, XMM16d,
  957                       XMM17, XMM17b, XMM17c, XMM17d,
  958                       XMM18, XMM18b, XMM18c, XMM18d,
  959                       XMM19, XMM19b, XMM19c, XMM19d,
  960                       XMM20, XMM20b, XMM20c, XMM20d,
  961                       XMM21, XMM21b, XMM21c, XMM21d,
  962                       XMM22, XMM22b, XMM22c, XMM22d,
  963                       XMM23, XMM23b, XMM23c, XMM23d,
  964                       XMM24, XMM24b, XMM24c, XMM24d,
  965                       XMM25, XMM25b, XMM25c, XMM25d,
  966                       XMM26, XMM26b, XMM26c, XMM26d,
  967                       XMM27, XMM27b, XMM27c, XMM27d,
  968                       XMM28, XMM28b, XMM28c, XMM28d,
  969                       XMM29, XMM29b, XMM29c, XMM29d,
  970                       XMM30, XMM30b, XMM30c, XMM30d,
  971                       XMM31, XMM31b, XMM31c, XMM31d
  972 #endif
  973                       );
  974 
  975 reg_class_dynamic vectorx_reg(vectorx_reg_evex, vectorx_reg_legacy, %{ VM_Version::supports_evex() %} );
  976 reg_class_dynamic vectorx_reg_vlbwdq(vectorx_reg_evex, vectorx_reg_legacy, %{ VM_Version::supports_avx512vlbwdq() %} );
  977 
  978 // Class for all 256bit vector registers
  979 reg_class vectory_reg_legacy(XMM0,  XMM0b,  XMM0c,  XMM0d,  XMM0e,  XMM0f,  XMM0g,  XMM0h,
  980                       XMM1,  XMM1b,  XMM1c,  XMM1d,  XMM1e,  XMM1f,  XMM1g,  XMM1h,
  981                       XMM2,  XMM2b,  XMM2c,  XMM2d,  XMM2e,  XMM2f,  XMM2g,  XMM2h,
  982                       XMM3,  XMM3b,  XMM3c,  XMM3d,  XMM3e,  XMM3f,  XMM3g,  XMM3h,
  983                       XMM4,  XMM4b,  XMM4c,  XMM4d,  XMM4e,  XMM4f,  XMM4g,  XMM4h,
  984                       XMM5,  XMM5b,  XMM5c,  XMM5d,  XMM5e,  XMM5f,  XMM5g,  XMM5h,
  985                       XMM6,  XMM6b,  XMM6c,  XMM6d,  XMM6e,  XMM6f,  XMM6g,  XMM6h,
  986                       XMM7,  XMM7b,  XMM7c,  XMM7d,  XMM7e,  XMM7f,  XMM7g,  XMM7h
  987 #ifdef _LP64
  988                      ,XMM8,  XMM8b,  XMM8c,  XMM8d,  XMM8e,  XMM8f,  XMM8g,  XMM8h,
  989                       XMM9,  XMM9b,  XMM9c,  XMM9d,  XMM9e,  XMM9f,  XMM9g,  XMM9h,
  990                       XMM10, XMM10b, XMM10c, XMM10d, XMM10e, XMM10f, XMM10g, XMM10h,
  991                       XMM11, XMM11b, XMM11c, XMM11d, XMM11e, XMM11f, XMM11g, XMM11h,
  992                       XMM12, XMM12b, XMM12c, XMM12d, XMM12e, XMM12f, XMM12g, XMM12h,
  993                       XMM13, XMM13b, XMM13c, XMM13d, XMM13e, XMM13f, XMM13g, XMM13h,
  994                       XMM14, XMM14b, XMM14c, XMM14d, XMM14e, XMM14f, XMM14g, XMM14h,
  995                       XMM15, XMM15b, XMM15c, XMM15d, XMM15e, XMM15f, XMM15g, XMM15h
  996 #endif
  997                       );
  998 
  999 // Class for all 256bit vector registers
 1000 reg_class vectory_reg_evex(XMM0,  XMM0b,  XMM0c,  XMM0d,  XMM0e,  XMM0f,  XMM0g,  XMM0h,
 1001                       XMM1,  XMM1b,  XMM1c,  XMM1d,  XMM1e,  XMM1f,  XMM1g,  XMM1h,
 1002                       XMM2,  XMM2b,  XMM2c,  XMM2d,  XMM2e,  XMM2f,  XMM2g,  XMM2h,
 1003                       XMM3,  XMM3b,  XMM3c,  XMM3d,  XMM3e,  XMM3f,  XMM3g,  XMM3h,
 1004                       XMM4,  XMM4b,  XMM4c,  XMM4d,  XMM4e,  XMM4f,  XMM4g,  XMM4h,
 1005                       XMM5,  XMM5b,  XMM5c,  XMM5d,  XMM5e,  XMM5f,  XMM5g,  XMM5h,
 1006                       XMM6,  XMM6b,  XMM6c,  XMM6d,  XMM6e,  XMM6f,  XMM6g,  XMM6h,
 1007                       XMM7,  XMM7b,  XMM7c,  XMM7d,  XMM7e,  XMM7f,  XMM7g,  XMM7h
 1008 #ifdef _LP64
 1009                      ,XMM8,  XMM8b,  XMM8c,  XMM8d,  XMM8e,  XMM8f,  XMM8g,  XMM8h,
 1010                       XMM9,  XMM9b,  XMM9c,  XMM9d,  XMM9e,  XMM9f,  XMM9g,  XMM9h,
 1011                       XMM10, XMM10b, XMM10c, XMM10d, XMM10e, XMM10f, XMM10g, XMM10h,
 1012                       XMM11, XMM11b, XMM11c, XMM11d, XMM11e, XMM11f, XMM11g, XMM11h,
 1013                       XMM12, XMM12b, XMM12c, XMM12d, XMM12e, XMM12f, XMM12g, XMM12h,
 1014                       XMM13, XMM13b, XMM13c, XMM13d, XMM13e, XMM13f, XMM13g, XMM13h,
 1015                       XMM14, XMM14b, XMM14c, XMM14d, XMM14e, XMM14f, XMM14g, XMM14h,
 1016                       XMM15, XMM15b, XMM15c, XMM15d, XMM15e, XMM15f, XMM15g, XMM15h,
 1017                       XMM16, XMM16b, XMM16c, XMM16d, XMM16e, XMM16f, XMM16g, XMM16h,
 1018                       XMM17, XMM17b, XMM17c, XMM17d, XMM17e, XMM17f, XMM17g, XMM17h,
 1019                       XMM18, XMM18b, XMM18c, XMM18d, XMM18e, XMM18f, XMM18g, XMM18h,
 1020                       XMM19, XMM19b, XMM19c, XMM19d, XMM19e, XMM19f, XMM19g, XMM19h,
 1021                       XMM20, XMM20b, XMM20c, XMM20d, XMM20e, XMM20f, XMM20g, XMM20h,
 1022                       XMM21, XMM21b, XMM21c, XMM21d, XMM21e, XMM21f, XMM21g, XMM21h,
 1023                       XMM22, XMM22b, XMM22c, XMM22d, XMM22e, XMM22f, XMM22g, XMM22h,
 1024                       XMM23, XMM23b, XMM23c, XMM23d, XMM23e, XMM23f, XMM23g, XMM23h,
 1025                       XMM24, XMM24b, XMM24c, XMM24d, XMM24e, XMM24f, XMM24g, XMM24h,
 1026                       XMM25, XMM25b, XMM25c, XMM25d, XMM25e, XMM25f, XMM25g, XMM25h,
 1027                       XMM26, XMM26b, XMM26c, XMM26d, XMM26e, XMM26f, XMM26g, XMM26h,
 1028                       XMM27, XMM27b, XMM27c, XMM27d, XMM27e, XMM27f, XMM27g, XMM27h,
 1029                       XMM28, XMM28b, XMM28c, XMM28d, XMM28e, XMM28f, XMM28g, XMM28h,
 1030                       XMM29, XMM29b, XMM29c, XMM29d, XMM29e, XMM29f, XMM29g, XMM29h,
 1031                       XMM30, XMM30b, XMM30c, XMM30d, XMM30e, XMM30f, XMM30g, XMM30h,
 1032                       XMM31, XMM31b, XMM31c, XMM31d, XMM31e, XMM31f, XMM31g, XMM31h
 1033 #endif
 1034                       );
 1035 
 1036 reg_class_dynamic vectory_reg(vectory_reg_evex, vectory_reg_legacy, %{ VM_Version::supports_evex() %} );
 1037 reg_class_dynamic vectory_reg_vlbwdq(vectory_reg_evex, vectory_reg_legacy, %{ VM_Version::supports_avx512vlbwdq() %} );
 1038 
 1039 // Class for all 512bit vector registers
 1040 reg_class vectorz_reg_evex(XMM0,  XMM0b,  XMM0c,  XMM0d,  XMM0e,  XMM0f,  XMM0g,  XMM0h,  XMM0i,  XMM0j,  XMM0k,  XMM0l,  XMM0m,  XMM0n,  XMM0o,  XMM0p,
 1041                       XMM1,  XMM1b,  XMM1c,  XMM1d,  XMM1e,  XMM1f,  XMM1g,  XMM1h,  XMM1i,  XMM1j,  XMM1k,  XMM1l,  XMM1m,  XMM1n,  XMM1o,  XMM1p,
 1042                       XMM2,  XMM2b,  XMM2c,  XMM2d,  XMM2e,  XMM2f,  XMM2g,  XMM2h,  XMM2i,  XMM2j,  XMM2k,  XMM2l,  XMM2m,  XMM2n,  XMM2o,  XMM2p,
 1043                       XMM3,  XMM3b,  XMM3c,  XMM3d,  XMM3e,  XMM3f,  XMM3g,  XMM3h,  XMM3i,  XMM3j,  XMM3k,  XMM3l,  XMM3m,  XMM3n,  XMM3o,  XMM3p,
 1044                       XMM4,  XMM4b,  XMM4c,  XMM4d,  XMM4e,  XMM4f,  XMM4g,  XMM4h,  XMM4i,  XMM4j,  XMM4k,  XMM4l,  XMM4m,  XMM4n,  XMM4o,  XMM4p,
 1045                       XMM5,  XMM5b,  XMM5c,  XMM5d,  XMM5e,  XMM5f,  XMM5g,  XMM5h,  XMM5i,  XMM5j,  XMM5k,  XMM5l,  XMM5m,  XMM5n,  XMM5o,  XMM5p,
 1046                       XMM6,  XMM6b,  XMM6c,  XMM6d,  XMM6e,  XMM6f,  XMM6g,  XMM6h,  XMM6i,  XMM6j,  XMM6k,  XMM6l,  XMM6m,  XMM6n,  XMM6o,  XMM6p,
 1047                       XMM7,  XMM7b,  XMM7c,  XMM7d,  XMM7e,  XMM7f,  XMM7g,  XMM7h,  XMM7i,  XMM7j,  XMM7k,  XMM7l,  XMM7m,  XMM7n,  XMM7o,  XMM7p
 1048 #ifdef _LP64
 1049                      ,XMM8,  XMM8b,  XMM8c,  XMM8d,  XMM8e,  XMM8f,  XMM8g,  XMM8h,  XMM8i,  XMM8j,  XMM8k,  XMM8l,  XMM8m,  XMM8n,  XMM8o,  XMM8p,
 1050                       XMM9,  XMM9b,  XMM9c,  XMM9d,  XMM9e,  XMM9f,  XMM9g,  XMM9h,  XMM9i,  XMM9j,  XMM9k,  XMM9l,  XMM9m,  XMM9n,  XMM9o,  XMM9p,
 1051                       XMM10, XMM10b, XMM10c, XMM10d, XMM10e, XMM10f, XMM10g, XMM10h, XMM10i, XMM10j, XMM10k, XMM10l, XMM10m, XMM10n, XMM10o, XMM10p,
 1052                       XMM11, XMM11b, XMM11c, XMM11d, XMM11e, XMM11f, XMM11g, XMM11h, XMM11i, XMM11j, XMM11k, XMM11l, XMM11m, XMM11n, XMM11o, XMM11p,
 1053                       XMM12, XMM12b, XMM12c, XMM12d, XMM12e, XMM12f, XMM12g, XMM12h, XMM12i, XMM12j, XMM12k, XMM12l, XMM12m, XMM12n, XMM12o, XMM12p,
 1054                       XMM13, XMM13b, XMM13c, XMM13d, XMM13e, XMM13f, XMM13g, XMM13h, XMM13i, XMM13j, XMM13k, XMM13l, XMM13m, XMM13n, XMM13o, XMM13p,
 1055                       XMM14, XMM14b, XMM14c, XMM14d, XMM14e, XMM14f, XMM14g, XMM14h, XMM14i, XMM14j, XMM14k, XMM14l, XMM14m, XMM14n, XMM14o, XMM14p,
 1056                       XMM15, XMM15b, XMM15c, XMM15d, XMM15e, XMM15f, XMM15g, XMM15h, XMM15i, XMM15j, XMM15k, XMM15l, XMM15m, XMM15n, XMM15o, XMM15p
 1057                      ,XMM16, XMM16b, XMM16c, XMM16d, XMM16e, XMM16f, XMM16g, XMM16h, XMM16i, XMM16j, XMM16k, XMM16l, XMM16m, XMM16n, XMM16o, XMM16p,
 1058                       XMM17, XMM17b, XMM17c, XMM17d, XMM17e, XMM17f, XMM17g, XMM17h, XMM17i, XMM17j, XMM17k, XMM17l, XMM17m, XMM17n, XMM17o, XMM17p,
 1059                       XMM18, XMM18b, XMM18c, XMM18d, XMM18e, XMM18f, XMM18g, XMM18h, XMM18i, XMM18j, XMM18k, XMM18l, XMM18m, XMM18n, XMM18o, XMM18p,
 1060                       XMM19, XMM19b, XMM19c, XMM19d, XMM19e, XMM19f, XMM19g, XMM19h, XMM19i, XMM19j, XMM19k, XMM19l, XMM19m, XMM19n, XMM19o, XMM19p,
 1061                       XMM20, XMM20b, XMM20c, XMM20d, XMM20e, XMM20f, XMM20g, XMM20h, XMM20i, XMM20j, XMM20k, XMM20l, XMM20m, XMM20n, XMM20o, XMM20p,
 1062                       XMM21, XMM21b, XMM21c, XMM21d, XMM21e, XMM21f, XMM21g, XMM21h, XMM21i, XMM21j, XMM21k, XMM21l, XMM21m, XMM21n, XMM21o, XMM21p,
 1063                       XMM22, XMM22b, XMM22c, XMM22d, XMM22e, XMM22f, XMM22g, XMM22h, XMM22i, XMM22j, XMM22k, XMM22l, XMM22m, XMM22n, XMM22o, XMM22p,
 1064                       XMM23, XMM23b, XMM23c, XMM23d, XMM23e, XMM23f, XMM23g, XMM23h, XMM23i, XMM23j, XMM23k, XMM23l, XMM23m, XMM23n, XMM23o, XMM23p,
 1065                       XMM24, XMM24b, XMM24c, XMM24d, XMM24e, XMM24f, XMM24g, XMM24h, XMM24i, XMM24j, XMM24k, XMM24l, XMM24m, XMM24n, XMM24o, XMM24p,
 1066                       XMM25, XMM25b, XMM25c, XMM25d, XMM25e, XMM25f, XMM25g, XMM25h, XMM25i, XMM25j, XMM25k, XMM25l, XMM25m, XMM25n, XMM25o, XMM25p,
 1067                       XMM26, XMM26b, XMM26c, XMM26d, XMM26e, XMM26f, XMM26g, XMM26h, XMM26i, XMM26j, XMM26k, XMM26l, XMM26m, XMM26n, XMM26o, XMM26p,
 1068                       XMM27, XMM27b, XMM27c, XMM27d, XMM27e, XMM27f, XMM27g, XMM27h, XMM27i, XMM27j, XMM27k, XMM27l, XMM27m, XMM27n, XMM27o, XMM27p,
 1069                       XMM28, XMM28b, XMM28c, XMM28d, XMM28e, XMM28f, XMM28g, XMM28h, XMM28i, XMM28j, XMM28k, XMM28l, XMM28m, XMM28n, XMM28o, XMM28p,
 1070                       XMM29, XMM29b, XMM29c, XMM29d, XMM29e, XMM29f, XMM29g, XMM29h, XMM29i, XMM29j, XMM29k, XMM29l, XMM29m, XMM29n, XMM29o, XMM29p,
 1071                       XMM30, XMM30b, XMM30c, XMM30d, XMM30e, XMM30f, XMM30g, XMM30h, XMM30i, XMM30j, XMM30k, XMM30l, XMM30m, XMM30n, XMM30o, XMM30p,
 1072                       XMM31, XMM31b, XMM31c, XMM31d, XMM31e, XMM31f, XMM31g, XMM31h, XMM31i, XMM31j, XMM31k, XMM31l, XMM31m, XMM31n, XMM31o, XMM31p
 1073 #endif
 1074                       );
 1075 
 1076 // Class for restricted 512bit vector registers
 1077 reg_class vectorz_reg_legacy(XMM0,  XMM0b,  XMM0c,  XMM0d,  XMM0e,  XMM0f,  XMM0g,  XMM0h,  XMM0i,  XMM0j,  XMM0k,  XMM0l,  XMM0m,  XMM0n,  XMM0o,  XMM0p,
 1078                       XMM1,  XMM1b,  XMM1c,  XMM1d,  XMM1e,  XMM1f,  XMM1g,  XMM1h,  XMM1i,  XMM1j,  XMM1k,  XMM1l,  XMM1m,  XMM1n,  XMM1o,  XMM1p,
 1079                       XMM2,  XMM2b,  XMM2c,  XMM2d,  XMM2e,  XMM2f,  XMM2g,  XMM2h,  XMM2i,  XMM2j,  XMM2k,  XMM2l,  XMM2m,  XMM2n,  XMM2o,  XMM2p,
 1080                       XMM3,  XMM3b,  XMM3c,  XMM3d,  XMM3e,  XMM3f,  XMM3g,  XMM3h,  XMM3i,  XMM3j,  XMM3k,  XMM3l,  XMM3m,  XMM3n,  XMM3o,  XMM3p,
 1081                       XMM4,  XMM4b,  XMM4c,  XMM4d,  XMM4e,  XMM4f,  XMM4g,  XMM4h,  XMM4i,  XMM4j,  XMM4k,  XMM4l,  XMM4m,  XMM4n,  XMM4o,  XMM4p,
 1082                       XMM5,  XMM5b,  XMM5c,  XMM5d,  XMM5e,  XMM5f,  XMM5g,  XMM5h,  XMM5i,  XMM5j,  XMM5k,  XMM5l,  XMM5m,  XMM5n,  XMM5o,  XMM5p,
 1083                       XMM6,  XMM6b,  XMM6c,  XMM6d,  XMM6e,  XMM6f,  XMM6g,  XMM6h,  XMM6i,  XMM6j,  XMM6k,  XMM6l,  XMM6m,  XMM6n,  XMM6o,  XMM6p,
 1084                       XMM7,  XMM7b,  XMM7c,  XMM7d,  XMM7e,  XMM7f,  XMM7g,  XMM7h,  XMM7i,  XMM7j,  XMM7k,  XMM7l,  XMM7m,  XMM7n,  XMM7o,  XMM7p
 1085 #ifdef _LP64
 1086                      ,XMM8,  XMM8b,  XMM8c,  XMM8d,  XMM8e,  XMM8f,  XMM8g,  XMM8h,  XMM8i,  XMM8j,  XMM8k,  XMM8l,  XMM8m,  XMM8n,  XMM8o,  XMM8p,
 1087                       XMM9,  XMM9b,  XMM9c,  XMM9d,  XMM9e,  XMM9f,  XMM9g,  XMM9h,  XMM9i,  XMM9j,  XMM9k,  XMM9l,  XMM9m,  XMM9n,  XMM9o,  XMM9p,
 1088                       XMM10, XMM10b, XMM10c, XMM10d, XMM10e, XMM10f, XMM10g, XMM10h, XMM10i, XMM10j, XMM10k, XMM10l, XMM10m, XMM10n, XMM10o, XMM10p,
 1089                       XMM11, XMM11b, XMM11c, XMM11d, XMM11e, XMM11f, XMM11g, XMM11h, XMM11i, XMM11j, XMM11k, XMM11l, XMM11m, XMM11n, XMM11o, XMM11p,
 1090                       XMM12, XMM12b, XMM12c, XMM12d, XMM12e, XMM12f, XMM12g, XMM12h, XMM12i, XMM12j, XMM12k, XMM12l, XMM12m, XMM12n, XMM12o, XMM12p,
 1091                       XMM13, XMM13b, XMM13c, XMM13d, XMM13e, XMM13f, XMM13g, XMM13h, XMM13i, XMM13j, XMM13k, XMM13l, XMM13m, XMM13n, XMM13o, XMM13p,
 1092                       XMM14, XMM14b, XMM14c, XMM14d, XMM14e, XMM14f, XMM14g, XMM14h, XMM14i, XMM14j, XMM14k, XMM14l, XMM14m, XMM14n, XMM14o, XMM14p,
 1093                       XMM15, XMM15b, XMM15c, XMM15d, XMM15e, XMM15f, XMM15g, XMM15h, XMM15i, XMM15j, XMM15k, XMM15l, XMM15m, XMM15n, XMM15o, XMM15p
 1094 #endif
 1095                       );
 1096 
<a name="1" id="anc1"></a><span class="line-modified"> 1097 reg_class_dynamic vectorz_reg(vectorz_reg_evex, vectorz_reg_legacy, %{ VM_Version::supports_evex() %} );</span>
 1098 reg_class_dynamic vectorz_reg_vl(vectorz_reg_evex, vectorz_reg_legacy, %{ VM_Version::supports_evex() &amp;&amp; VM_Version::supports_avx512vl() %} );
 1099 
<a name="2" id="anc2"></a><span class="line-removed"> 1100 reg_class xmm0_reg(XMM0, XMM0b, XMM0c, XMM0d);</span>
<span class="line-removed"> 1101 reg_class ymm0_reg(XMM0, XMM0b, XMM0c, XMM0d, XMM0e, XMM0f, XMM0g, XMM0h);</span>
<span class="line-removed"> 1102 reg_class zmm0_reg(XMM0, XMM0b, XMM0c, XMM0d, XMM0e, XMM0f, XMM0g, XMM0h, XMM0i, XMM0j, XMM0k, XMM0l, XMM0m, XMM0n, XMM0o, XMM0p);</span>
<span class="line-removed"> 1103 </span>
<span class="line-removed"> 1104 reg_class xmm1_reg(XMM1, XMM1b, XMM1c, XMM1d);</span>
<span class="line-removed"> 1105 reg_class ymm1_reg(XMM1, XMM1b, XMM1c, XMM1d, XMM1e, XMM1f, XMM1g, XMM1h);</span>
<span class="line-removed"> 1106 reg_class zmm1_reg(XMM1, XMM1b, XMM1c, XMM1d, XMM1e, XMM1f, XMM1g, XMM1h, XMM1i, XMM1j, XMM1k, XMM1l, XMM1m, XMM1n, XMM1o, XMM1p);</span>
<span class="line-removed"> 1107 </span>
<span class="line-removed"> 1108 reg_class xmm2_reg(XMM2, XMM2b, XMM2c, XMM2d);</span>
<span class="line-removed"> 1109 reg_class ymm2_reg(XMM2, XMM2b, XMM2c, XMM2d, XMM2e, XMM2f, XMM2g, XMM2h);</span>
<span class="line-removed"> 1110 reg_class zmm2_reg(XMM2, XMM2b, XMM2c, XMM2d, XMM2e, XMM2f, XMM2g, XMM2h, XMM2i, XMM2j, XMM2k, XMM2l, XMM2m, XMM2n, XMM2o, XMM2p);</span>
<span class="line-removed"> 1111 </span>
<span class="line-removed"> 1112 reg_class xmm3_reg(XMM3, XMM3b, XMM3c, XMM3d);</span>
<span class="line-removed"> 1113 reg_class ymm3_reg(XMM3, XMM3b, XMM3c, XMM3d, XMM3e, XMM3f, XMM3g, XMM3h);</span>
<span class="line-removed"> 1114 reg_class zmm3_reg(XMM3, XMM3b, XMM3c, XMM3d, XMM3e, XMM3f, XMM3g, XMM3h, XMM3i, XMM3j, XMM3k, XMM3l, XMM3m, XMM3n, XMM3o, XMM3p);</span>
<span class="line-removed"> 1115 </span>
<span class="line-removed"> 1116 reg_class xmm4_reg(XMM4, XMM4b, XMM4c, XMM4d);</span>
<span class="line-removed"> 1117 reg_class ymm4_reg(XMM4, XMM4b, XMM4c, XMM4d, XMM4e, XMM4f, XMM4g, XMM4h);</span>
<span class="line-removed"> 1118 reg_class zmm4_reg(XMM4, XMM4b, XMM4c, XMM4d, XMM4e, XMM4f, XMM4g, XMM4h, XMM4i, XMM4j, XMM4k, XMM4l, XMM4m, XMM4n, XMM4o, XMM4p);</span>
<span class="line-removed"> 1119 </span>
<span class="line-removed"> 1120 reg_class xmm5_reg(XMM5, XMM5b, XMM5c, XMM5d);</span>
<span class="line-removed"> 1121 reg_class ymm5_reg(XMM5, XMM5b, XMM5c, XMM5d, XMM5e, XMM5f, XMM5g, XMM5h);</span>
<span class="line-removed"> 1122 reg_class zmm5_reg(XMM5, XMM5b, XMM5c, XMM5d, XMM5e, XMM5f, XMM5g, XMM5h, XMM5i, XMM5j, XMM5k, XMM5l, XMM5m, XMM5n, XMM5o, XMM5p);</span>
<span class="line-removed"> 1123 </span>
<span class="line-removed"> 1124 reg_class xmm6_reg(XMM6, XMM6b, XMM6c, XMM6d);</span>
<span class="line-removed"> 1125 reg_class ymm6_reg(XMM6, XMM6b, XMM6c, XMM6d, XMM6e, XMM6f, XMM6g, XMM6h);</span>
<span class="line-removed"> 1126 reg_class zmm6_reg(XMM6, XMM6b, XMM6c, XMM6d, XMM6e, XMM6f, XMM6g, XMM6h, XMM6i, XMM6j, XMM6k, XMM6l, XMM6m, XMM6n, XMM6o, XMM6p);</span>
<span class="line-removed"> 1127 </span>
<span class="line-removed"> 1128 reg_class xmm7_reg(XMM7, XMM7b, XMM7c, XMM7d);</span>
<span class="line-removed"> 1129 reg_class ymm7_reg(XMM7, XMM7b, XMM7c, XMM7d, XMM7e, XMM7f, XMM7g, XMM7h);</span>
<span class="line-removed"> 1130 reg_class zmm7_reg(XMM7, XMM7b, XMM7c, XMM7d, XMM7e, XMM7f, XMM7g, XMM7h, XMM7i, XMM7j, XMM7k, XMM7l, XMM7m, XMM7n, XMM7o, XMM7p);</span>
<span class="line-removed"> 1131 </span>
<span class="line-removed"> 1132 #ifdef _LP64</span>
<span class="line-removed"> 1133 </span>
<span class="line-removed"> 1134 reg_class xmm8_reg(XMM8, XMM8b, XMM8c, XMM8d);</span>
<span class="line-removed"> 1135 reg_class ymm8_reg(XMM8, XMM8b, XMM8c, XMM8d, XMM8e, XMM8f, XMM8g, XMM8h);</span>
<span class="line-removed"> 1136 reg_class zmm8_reg(XMM8, XMM8b, XMM8c, XMM8d, XMM8e, XMM8f, XMM8g, XMM8h, XMM8i, XMM8j, XMM8k, XMM8l, XMM8m, XMM8n, XMM8o, XMM8p);</span>
<span class="line-removed"> 1137 </span>
<span class="line-removed"> 1138 reg_class xmm9_reg(XMM9, XMM9b, XMM9c, XMM9d);</span>
<span class="line-removed"> 1139 reg_class ymm9_reg(XMM9, XMM9b, XMM9c, XMM9d, XMM9e, XMM9f, XMM9g, XMM9h);</span>
<span class="line-removed"> 1140 reg_class zmm9_reg(XMM9, XMM9b, XMM9c, XMM9d, XMM9e, XMM9f, XMM9g, XMM9h, XMM9i, XMM9j, XMM9k, XMM9l, XMM9m, XMM9n, XMM9o, XMM9p);</span>
<span class="line-removed"> 1141 </span>
<span class="line-removed"> 1142 reg_class xmm10_reg(XMM10, XMM10b, XMM10c, XMM10d);</span>
<span class="line-removed"> 1143 reg_class ymm10_reg(XMM10, XMM10b, XMM10c, XMM10d, XMM10e, XMM10f, XMM10g, XMM10h);</span>
<span class="line-removed"> 1144 reg_class zmm10_reg(XMM10, XMM10b, XMM10c, XMM10d, XMM10e, XMM10f, XMM10g, XMM10h, XMM10i, XMM10j, XMM10k, XMM10l, XMM10m, XMM10n, XMM10o, XMM10p);</span>
<span class="line-removed"> 1145 </span>
<span class="line-removed"> 1146 reg_class xmm11_reg(XMM11, XMM11b, XMM11c, XMM11d);</span>
<span class="line-removed"> 1147 reg_class ymm11_reg(XMM11, XMM11b, XMM11c, XMM11d, XMM11e, XMM11f, XMM11g, XMM11h);</span>
<span class="line-removed"> 1148 reg_class zmm11_reg(XMM11, XMM11b, XMM11c, XMM11d, XMM11e, XMM11f, XMM11g, XMM11h, XMM11i, XMM11j, XMM11k, XMM11l, XMM11m, XMM11n, XMM11o, XMM11p);</span>
<span class="line-removed"> 1149 </span>
<span class="line-removed"> 1150 reg_class xmm12_reg(XMM12, XMM12b, XMM12c, XMM12d);</span>
<span class="line-removed"> 1151 reg_class ymm12_reg(XMM12, XMM12b, XMM12c, XMM12d, XMM12e, XMM12f, XMM12g, XMM12h);</span>
<span class="line-removed"> 1152 reg_class zmm12_reg(XMM12, XMM12b, XMM12c, XMM12d, XMM12e, XMM12f, XMM12g, XMM12h, XMM12i, XMM12j, XMM12k, XMM12l, XMM12m, XMM12n, XMM12o, XMM12p);</span>
<span class="line-removed"> 1153 </span>
<span class="line-removed"> 1154 reg_class xmm13_reg(XMM13, XMM13b, XMM13c, XMM13d);</span>
<span class="line-removed"> 1155 reg_class ymm13_reg(XMM13, XMM13b, XMM13c, XMM13d, XMM13e, XMM13f, XMM13g, XMM13h);</span>
<span class="line-removed"> 1156 reg_class zmm13_reg(XMM13, XMM13b, XMM13c, XMM13d, XMM13e, XMM13f, XMM13g, XMM13h, XMM13i, XMM13j, XMM13k, XMM13l, XMM13m, XMM13n, XMM13o, XMM13p);</span>
<span class="line-removed"> 1157 </span>
<span class="line-removed"> 1158 reg_class xmm14_reg(XMM14, XMM14b, XMM14c, XMM14d);</span>
<span class="line-removed"> 1159 reg_class ymm14_reg(XMM14, XMM14b, XMM14c, XMM14d, XMM14e, XMM14f, XMM14g, XMM14h);</span>
<span class="line-removed"> 1160 reg_class zmm14_reg(XMM14, XMM14b, XMM14c, XMM14d, XMM14e, XMM14f, XMM14g, XMM14h, XMM14i, XMM14j, XMM14k, XMM14l, XMM14m, XMM14n, XMM14o, XMM14p);</span>
<span class="line-removed"> 1161 </span>
<span class="line-removed"> 1162 reg_class xmm15_reg(XMM15, XMM15b, XMM15c, XMM15d);</span>
<span class="line-removed"> 1163 reg_class ymm15_reg(XMM15, XMM15b, XMM15c, XMM15d, XMM15e, XMM15f, XMM15g, XMM15h);</span>
<span class="line-removed"> 1164 reg_class zmm15_reg(XMM15, XMM15b, XMM15c, XMM15d, XMM15e, XMM15f, XMM15g, XMM15h, XMM15i, XMM15j, XMM15k, XMM15l, XMM15m, XMM15n, XMM15o, XMM15p);</span>
<span class="line-removed"> 1165 </span>
<span class="line-removed"> 1166 reg_class xmm16_reg(XMM16, XMM16b, XMM16c, XMM16d);</span>
<span class="line-removed"> 1167 reg_class ymm16_reg(XMM16, XMM16b, XMM16c, XMM16d, XMM16e, XMM16f, XMM16g, XMM16h);</span>
<span class="line-removed"> 1168 reg_class zmm16_reg(XMM16, XMM16b, XMM16c, XMM16d, XMM16e, XMM16f, XMM16g, XMM16h, XMM16i, XMM16j, XMM16k, XMM16l, XMM16m, XMM16n, XMM16o, XMM16p);</span>
<span class="line-removed"> 1169 </span>
<span class="line-removed"> 1170 reg_class xmm17_reg(XMM17, XMM17b, XMM17c, XMM17d);</span>
<span class="line-removed"> 1171 reg_class ymm17_reg(XMM17, XMM17b, XMM17c, XMM17d, XMM17e, XMM17f, XMM17g, XMM17h);</span>
<span class="line-removed"> 1172 reg_class zmm17_reg(XMM17, XMM17b, XMM17c, XMM17d, XMM17e, XMM17f, XMM17g, XMM17h, XMM17i, XMM17j, XMM17k, XMM17l, XMM17m, XMM17n, XMM17o, XMM17p);</span>
<span class="line-removed"> 1173 </span>
<span class="line-removed"> 1174 reg_class xmm18_reg(XMM18, XMM18b, XMM18c, XMM18d);</span>
<span class="line-removed"> 1175 reg_class ymm18_reg(XMM18, XMM18b, XMM18c, XMM18d, XMM18e, XMM18f, XMM18g, XMM18h);</span>
<span class="line-removed"> 1176 reg_class zmm18_reg(XMM18, XMM18b, XMM18c, XMM18d, XMM18e, XMM18f, XMM18g, XMM18h, XMM18i, XMM18j, XMM18k, XMM18l, XMM18m, XMM18n, XMM18o, XMM18p);</span>
<span class="line-removed"> 1177 </span>
<span class="line-removed"> 1178 reg_class xmm19_reg(XMM19, XMM19b, XMM19c, XMM19d);</span>
<span class="line-removed"> 1179 reg_class ymm19_reg(XMM19, XMM19b, XMM19c, XMM19d, XMM19e, XMM19f, XMM19g, XMM19h);</span>
<span class="line-removed"> 1180 reg_class zmm19_reg(XMM19, XMM19b, XMM19c, XMM19d, XMM19e, XMM19f, XMM19g, XMM19h, XMM19i, XMM19j, XMM19k, XMM19l, XMM19m, XMM19n, XMM19o, XMM19p);</span>
<span class="line-removed"> 1181 </span>
<span class="line-removed"> 1182 reg_class xmm20_reg(XMM20, XMM20b, XMM20c, XMM20d);</span>
<span class="line-removed"> 1183 reg_class ymm20_reg(XMM20, XMM20b, XMM20c, XMM20d, XMM20e, XMM20f, XMM20g, XMM20h);</span>
<span class="line-removed"> 1184 reg_class zmm20_reg(XMM20, XMM20b, XMM20c, XMM20d, XMM20e, XMM20f, XMM20g, XMM20h, XMM20i, XMM20j, XMM20k, XMM20l, XMM20m, XMM20n, XMM20o, XMM20p);</span>
<span class="line-removed"> 1185 </span>
<span class="line-removed"> 1186 reg_class xmm21_reg(XMM21, XMM21b, XMM21c, XMM21d);</span>
<span class="line-removed"> 1187 reg_class ymm21_reg(XMM21, XMM21b, XMM21c, XMM21d, XMM21e, XMM21f, XMM21g, XMM21h);</span>
<span class="line-removed"> 1188 reg_class zmm21_reg(XMM21, XMM21b, XMM21c, XMM21d, XMM21e, XMM21f, XMM21g, XMM21h, XMM21i, XMM21j, XMM21k, XMM21l, XMM21m, XMM21n, XMM21o, XMM21p);</span>
<span class="line-removed"> 1189 </span>
<span class="line-removed"> 1190 reg_class xmm22_reg(XMM22, XMM22b, XMM22c, XMM22d);</span>
<span class="line-removed"> 1191 reg_class ymm22_reg(XMM22, XMM22b, XMM22c, XMM22d, XMM22e, XMM22f, XMM22g, XMM22h);</span>
<span class="line-removed"> 1192 reg_class zmm22_reg(XMM22, XMM22b, XMM22c, XMM22d, XMM22e, XMM22f, XMM22g, XMM22h, XMM22i, XMM22j, XMM22k, XMM22l, XMM22m, XMM22n, XMM22o, XMM22p);</span>
<span class="line-removed"> 1193 </span>
<span class="line-removed"> 1194 reg_class xmm23_reg(XMM23, XMM23b, XMM23c, XMM23d);</span>
<span class="line-removed"> 1195 reg_class ymm23_reg(XMM23, XMM23b, XMM23c, XMM23d, XMM23e, XMM23f, XMM23g, XMM23h);</span>
<span class="line-removed"> 1196 reg_class zmm23_reg(XMM23, XMM23b, XMM23c, XMM23d, XMM23e, XMM23f, XMM23g, XMM23h, XMM23i, XMM23j, XMM23k, XMM23l, XMM23m, XMM23n, XMM23o, XMM23p);</span>
<span class="line-removed"> 1197 </span>
<span class="line-removed"> 1198 reg_class xmm24_reg(XMM24, XMM24b, XMM24c, XMM24d);</span>
<span class="line-removed"> 1199 reg_class ymm24_reg(XMM24, XMM24b, XMM24c, XMM24d, XMM24e, XMM24f, XMM24g, XMM24h);</span>
<span class="line-removed"> 1200 reg_class zmm24_reg(XMM24, XMM24b, XMM24c, XMM24d, XMM24e, XMM24f, XMM24g, XMM24h, XMM24i, XMM24j, XMM24k, XMM24l, XMM24m, XMM24n, XMM24o, XMM24p);</span>
<span class="line-removed"> 1201 </span>
<span class="line-removed"> 1202 reg_class xmm25_reg(XMM25, XMM25b, XMM25c, XMM25d);</span>
<span class="line-removed"> 1203 reg_class ymm25_reg(XMM25, XMM25b, XMM25c, XMM25d, XMM25e, XMM25f, XMM25g, XMM25h);</span>
<span class="line-removed"> 1204 reg_class zmm25_reg(XMM25, XMM25b, XMM25c, XMM25d, XMM25e, XMM25f, XMM25g, XMM25h, XMM25i, XMM25j, XMM25k, XMM25l, XMM25m, XMM25n, XMM25o, XMM25p);</span>
<span class="line-removed"> 1205 </span>
<span class="line-removed"> 1206 reg_class xmm26_reg(XMM26, XMM26b, XMM26c, XMM26d);</span>
<span class="line-removed"> 1207 reg_class ymm26_reg(XMM26, XMM26b, XMM26c, XMM26d, XMM26e, XMM26f, XMM26g, XMM26h);</span>
<span class="line-removed"> 1208 reg_class zmm26_reg(XMM26, XMM26b, XMM26c, XMM26d, XMM26e, XMM26f, XMM26g, XMM26h, XMM26i, XMM26j, XMM26k, XMM26l, XMM26m, XMM26n, XMM26o, XMM26p);</span>
<span class="line-removed"> 1209 </span>
<span class="line-removed"> 1210 reg_class xmm27_reg(XMM27, XMM27b, XMM27c, XMM27d);</span>
<span class="line-removed"> 1211 reg_class ymm27_reg(XMM27, XMM27b, XMM27c, XMM27d, XMM27e, XMM27f, XMM27g, XMM27h);</span>
<span class="line-removed"> 1212 reg_class zmm27_reg(XMM27, XMM27b, XMM27c, XMM27d, XMM27e, XMM27f, XMM27g, XMM27h, XMM27i, XMM27j, XMM27k, XMM27l, XMM27m, XMM27n, XMM27o, XMM27p);</span>
<span class="line-removed"> 1213 </span>
<span class="line-removed"> 1214 reg_class xmm28_reg(XMM28, XMM28b, XMM28c, XMM28d);</span>
<span class="line-removed"> 1215 reg_class ymm28_reg(XMM28, XMM28b, XMM28c, XMM28d, XMM28e, XMM28f, XMM28g, XMM28h);</span>
<span class="line-removed"> 1216 reg_class zmm28_reg(XMM28, XMM28b, XMM28c, XMM28d, XMM28e, XMM28f, XMM28g, XMM28h, XMM28i, XMM28j, XMM28k, XMM28l, XMM28m, XMM28n, XMM28o, XMM28p);</span>
<span class="line-removed"> 1217 </span>
<span class="line-removed"> 1218 reg_class xmm29_reg(XMM29, XMM29b, XMM29c, XMM29d);</span>
<span class="line-removed"> 1219 reg_class ymm29_reg(XMM29, XMM29b, XMM29c, XMM29d, XMM29e, XMM29f, XMM29g, XMM29h);</span>
<span class="line-removed"> 1220 reg_class zmm29_reg(XMM29, XMM29b, XMM29c, XMM29d, XMM29e, XMM29f, XMM29g, XMM29h, XMM29i, XMM29j, XMM29k, XMM29l, XMM29m, XMM29n, XMM29o, XMM29p);</span>
<span class="line-removed"> 1221 </span>
<span class="line-removed"> 1222 reg_class xmm30_reg(XMM30, XMM30b, XMM30c, XMM30d);</span>
<span class="line-removed"> 1223 reg_class ymm30_reg(XMM30, XMM30b, XMM30c, XMM30d, XMM30e, XMM30f, XMM30g, XMM30h);</span>
<span class="line-removed"> 1224 reg_class zmm30_reg(XMM30, XMM30b, XMM30c, XMM30d, XMM30e, XMM30f, XMM30g, XMM30h, XMM30i, XMM30j, XMM30k, XMM30l, XMM30m, XMM30n, XMM30o, XMM30p);</span>
<span class="line-removed"> 1225 </span>
<span class="line-removed"> 1226 reg_class xmm31_reg(XMM31, XMM31b, XMM31c, XMM31d);</span>
<span class="line-removed"> 1227 reg_class ymm31_reg(XMM31, XMM31b, XMM31c, XMM31d, XMM31e, XMM31f, XMM31g, XMM31h);</span>
<span class="line-removed"> 1228 reg_class zmm31_reg(XMM31, XMM31b, XMM31c, XMM31d, XMM31e, XMM31f, XMM31g, XMM31h, XMM31i, XMM31j, XMM31k, XMM31l, XMM31m, XMM31n, XMM31o, XMM31p);</span>
<span class="line-removed"> 1229 </span>
<span class="line-removed"> 1230 #endif</span>
<span class="line-removed"> 1231 </span>
 1232 %}
 1233 
 1234 
 1235 //----------SOURCE BLOCK-------------------------------------------------------
 1236 // This is a block of C++ code which provides values, functions, and
 1237 // definitions necessary in the rest of the architecture description
 1238 
 1239 source_hpp %{
 1240 // Header information of the source block.
 1241 // Method declarations/definitions which are used outside
 1242 // the ad-scope can conveniently be defined here.
 1243 //
 1244 // To keep related declarations/definitions/uses close together,
 1245 // we switch between source %{ }% and source_hpp %{ }% freely as needed.
 1246 
 1247 class NativeJump;
 1248 
 1249 class CallStubImpl {
 1250 
 1251   //--------------------------------------------------------------
 1252   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
 1253   //--------------------------------------------------------------
 1254 
 1255  public:
 1256   // Size of call trampoline stub.
 1257   static uint size_call_trampoline() {
 1258     return 0; // no call trampolines on this platform
 1259   }
 1260 
 1261   // number of relocations needed by a call trampoline stub
 1262   static uint reloc_call_trampoline() {
 1263     return 0; // no call trampolines on this platform
 1264   }
 1265 };
 1266 
 1267 class HandlerImpl {
 1268 
 1269  public:
 1270 
 1271   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1272   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1273 
 1274   static uint size_exception_handler() {
 1275     // NativeCall instruction size is the same as NativeJump.
 1276     // exception handler starts out as jump and can be patched to
 1277     // a call be deoptimization.  (4932387)
 1278     // Note that this value is also credited (in output.cpp) to
 1279     // the size of the code section.
 1280     return NativeJump::instruction_size;
 1281   }
 1282 
 1283 #ifdef _LP64
 1284   static uint size_deopt_handler() {
 1285     // three 5 byte instructions plus one move for unreachable address.
 1286     return 15+3;
 1287   }
 1288 #else
 1289   static uint size_deopt_handler() {
 1290     // NativeCall instruction size is the same as NativeJump.
 1291     // exception handler starts out as jump and can be patched to
 1292     // a call be deoptimization.  (4932387)
 1293     // Note that this value is also credited (in output.cpp) to
 1294     // the size of the code section.
 1295     return 5 + NativeJump::instruction_size; // pushl(); jmp;
 1296   }
 1297 #endif
 1298 };
 1299 
 1300 %} // end source_hpp
 1301 
 1302 source %{
 1303 
 1304 #include &quot;opto/addnode.hpp&quot;
 1305 
 1306 // Emit exception handler code.
 1307 // Stuff framesize into a register and call a VM stub routine.
 1308 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf) {
 1309 
 1310   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 1311   // That&#39;s why we must use the macroassembler to generate a handler.
 1312   MacroAssembler _masm(&amp;cbuf);
 1313   address base = __ start_a_stub(size_exception_handler());
 1314   if (base == NULL) {
 1315     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 1316     return 0;  // CodeBuffer::expand failed
 1317   }
 1318   int offset = __ offset();
 1319   __ jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 1320   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 1321   __ end_a_stub();
 1322   return offset;
 1323 }
 1324 
 1325 // Emit deopt handler code.
 1326 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf) {
 1327 
 1328   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 1329   // That&#39;s why we must use the macroassembler to generate a handler.
 1330   MacroAssembler _masm(&amp;cbuf);
 1331   address base = __ start_a_stub(size_deopt_handler());
 1332   if (base == NULL) {
 1333     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 1334     return 0;  // CodeBuffer::expand failed
 1335   }
 1336   int offset = __ offset();
 1337 
 1338 #ifdef _LP64
 1339   address the_pc = (address) __ pc();
 1340   Label next;
 1341   // push a &quot;the_pc&quot; on the stack without destroying any registers
 1342   // as they all may be live.
 1343 
 1344   // push address of &quot;next&quot;
 1345   __ call(next, relocInfo::none); // reloc none is fine since it is a disp32
 1346   __ bind(next);
 1347   // adjust it so it matches &quot;the_pc&quot;
 1348   __ subptr(Address(rsp, 0), __ offset() - offset);
 1349 #else
 1350   InternalAddress here(__ pc());
 1351   __ pushptr(here.addr());
 1352 #endif
 1353 
 1354   __ jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 1355   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow %d&quot;, (__ offset() - offset));
 1356   __ end_a_stub();
 1357   return offset;
 1358 }
 1359 
 1360 
 1361 //=============================================================================
 1362 
 1363   // Float masks come from different places depending on platform.
 1364 #ifdef _LP64
 1365   static address float_signmask()  { return StubRoutines::x86::float_sign_mask(); }
 1366   static address float_signflip()  { return StubRoutines::x86::float_sign_flip(); }
 1367   static address double_signmask() { return StubRoutines::x86::double_sign_mask(); }
 1368   static address double_signflip() { return StubRoutines::x86::double_sign_flip(); }
 1369 #else
 1370   static address float_signmask()  { return (address)float_signmask_pool; }
 1371   static address float_signflip()  { return (address)float_signflip_pool; }
 1372   static address double_signmask() { return (address)double_signmask_pool; }
 1373   static address double_signflip() { return (address)double_signflip_pool; }
 1374 #endif
<a name="3" id="anc3"></a>


 1375 
<a name="4" id="anc4"></a><span class="line-modified"> 1376 </span>
 1377 const bool Matcher::match_rule_supported(int opcode) {
<a name="5" id="anc5"></a><span class="line-modified"> 1378   if (!has_match_rule(opcode))</span>
<span class="line-modified"> 1379     return false;</span>
<span class="line-modified"> 1380 </span>
<span class="line-removed"> 1381   bool ret_value = true;</span>
 1382   switch (opcode) {
<a name="6" id="anc6"></a>




 1383     case Op_PopCountI:
 1384     case Op_PopCountL:
<a name="7" id="anc7"></a><span class="line-modified"> 1385       if (!UsePopCountInstruction)</span>
<span class="line-modified"> 1386         ret_value = false;</span>

 1387       break;
 1388     case Op_PopCountVI:
<a name="8" id="anc8"></a><span class="line-modified"> 1389       if (!UsePopCountInstruction || !VM_Version::supports_vpopcntdq())</span>
<span class="line-modified"> 1390         ret_value = false;</span>

 1391       break;
 1392     case Op_MulVI:
<a name="9" id="anc9"></a><span class="line-modified"> 1393       if ((UseSSE &lt; 4) &amp;&amp; (UseAVX &lt; 1)) // only with SSE4_1 or AVX</span>
<span class="line-modified"> 1394         ret_value = false;</span>

 1395       break;
 1396     case Op_MulVL:
 1397     case Op_MulReductionVL:
<a name="10" id="anc10"></a><span class="line-modified"> 1398       if (VM_Version::supports_avx512dq() == false)</span>
<span class="line-modified"> 1399         ret_value = false;</span>

 1400       break;
 1401     case Op_AddReductionVL:
<a name="11" id="anc11"></a><span class="line-modified"> 1402       if (UseAVX &lt; 3) // only EVEX : vector connectivity becomes an issue here</span>
<span class="line-modified"> 1403         ret_value = false;</span>

 1404       break;
<a name="12" id="anc12"></a>


 1405     case Op_AddReductionVI:
<a name="13" id="anc13"></a><span class="line-modified"> 1406       if (UseSSE &lt; 3) // requires at least SSE3</span>
<span class="line-modified"> 1407         ret_value = false;</span>

 1408       break;
 1409     case Op_MulReductionVI:
<a name="14" id="anc14"></a><span class="line-modified"> 1410       if (UseSSE &lt; 4) // requires at least SSE4</span>
<span class="line-modified"> 1411         ret_value = false;</span>

 1412       break;
 1413     case Op_AddReductionVF:
 1414     case Op_AddReductionVD:
 1415     case Op_MulReductionVF:
 1416     case Op_MulReductionVD:
<a name="15" id="anc15"></a><span class="line-modified"> 1417       if (UseSSE &lt; 1) // requires at least SSE</span>
<span class="line-modified"> 1418         ret_value = false;</span>

 1419       break;
 1420     case Op_SqrtVD:
 1421     case Op_SqrtVF:
<a name="16" id="anc16"></a><span class="line-modified"> 1422       if (UseAVX &lt; 1) // enabled for AVX only</span>
<span class="line-modified"> 1423         ret_value = false;</span>

 1424       break;
 1425     case Op_CompareAndSwapL:
 1426 #ifdef _LP64
 1427     case Op_CompareAndSwapP:
 1428 #endif
<a name="17" id="anc17"></a><span class="line-modified"> 1429       if (!VM_Version::supports_cx8())</span>
<span class="line-modified"> 1430         ret_value = false;</span>

 1431       break;
 1432     case Op_CMoveVF:
 1433     case Op_CMoveVD:
<a name="18" id="anc18"></a><span class="line-modified"> 1434       if (UseAVX &lt; 1 || UseAVX &gt; 2)</span>
<span class="line-modified"> 1435         ret_value = false;</span>

 1436       break;
 1437     case Op_StrIndexOf:
<a name="19" id="anc19"></a><span class="line-modified"> 1438       if (!UseSSE42Intrinsics)</span>
<span class="line-modified"> 1439         ret_value = false;</span>

 1440       break;
 1441     case Op_StrIndexOfChar:
<a name="20" id="anc20"></a><span class="line-modified"> 1442       if (!UseSSE42Intrinsics)</span>
<span class="line-modified"> 1443         ret_value = false;</span>

 1444       break;
 1445     case Op_OnSpinWait:
<a name="21" id="anc21"></a><span class="line-modified"> 1446       if (VM_Version::supports_on_spin_wait() == false)</span>
<span class="line-modified"> 1447         ret_value = false;</span>

 1448       break;
 1449     case Op_MulAddVS2VI:
<a name="22" id="anc22"></a><span class="line-modified"> 1450       if (UseSSE &lt; 2)</span>
<span class="line-modified"> 1451         ret_value = false;</span>












 1452       break;
 1453 #ifdef _LP64
 1454     case Op_MaxD:
 1455     case Op_MaxF:
 1456     case Op_MinD:
 1457     case Op_MinF:
<a name="23" id="anc23"></a><span class="line-modified"> 1458       if (UseAVX &lt; 1) // enabled for AVX only</span>
<span class="line-modified"> 1459         ret_value = false;</span>

 1460       break;
 1461 #endif
<a name="24" id="anc24"></a>
















 1462   }
<a name="25" id="anc25"></a>

 1463 
<a name="26" id="anc26"></a><span class="line-modified"> 1464   return ret_value;  // Per default match rules are supported.</span>















































 1465 }
 1466 
<a name="27" id="anc27"></a><span class="line-modified"> 1467 const bool Matcher::match_rule_supported_vector(int opcode, int vlen) {</span>
<span class="line-modified"> 1468   // identify extra cases that we might want to provide match rules for</span>
<span class="line-modified"> 1469   // e.g. Op_ vector nodes and other intrinsics while guarding with vlen</span>
<span class="line-modified"> 1470   bool ret_value = match_rule_supported(opcode);</span>
<span class="line-modified"> 1471   if (ret_value) {</span>
<span class="line-modified"> 1472     switch (opcode) {</span>
<span class="line-modified"> 1473       case Op_AddVB:</span>
<span class="line-modified"> 1474       case Op_SubVB:</span>
<span class="line-modified"> 1475         if ((vlen == 64) &amp;&amp; (VM_Version::supports_avx512bw() == false))</span>
<span class="line-modified"> 1476           ret_value = false;</span>
<span class="line-modified"> 1477         break;</span>
<span class="line-modified"> 1478       case Op_URShiftVS:</span>
<span class="line-modified"> 1479       case Op_RShiftVS:</span>
<span class="line-modified"> 1480       case Op_LShiftVS:</span>
<span class="line-modified"> 1481       case Op_MulVS:</span>
<span class="line-modified"> 1482       case Op_AddVS:</span>
<span class="line-modified"> 1483       case Op_SubVS:</span>
<span class="line-modified"> 1484         if ((vlen == 32) &amp;&amp; (VM_Version::supports_avx512bw() == false))</span>
<span class="line-modified"> 1485           ret_value = false;</span>
<span class="line-modified"> 1486         break;</span>
<span class="line-modified"> 1487       case Op_CMoveVF:</span>
<span class="line-modified"> 1488         if (vlen != 8)</span>
<span class="line-modified"> 1489           ret_value  = false;</span>
<span class="line-modified"> 1490         break;</span>
<span class="line-modified"> 1491       case Op_CMoveVD:</span>
<span class="line-modified"> 1492         if (vlen != 4)</span>
<span class="line-removed"> 1493           ret_value  = false;</span>
<span class="line-removed"> 1494         break;</span>
 1495     }
 1496   }
<a name="28" id="anc28"></a>












 1497 
<a name="29" id="anc29"></a><span class="line-modified"> 1498   return ret_value;  // Per default match rules are supported.</span>







 1499 }
 1500 
<a name="30" id="anc30"></a>

 1501 const bool Matcher::has_predicated_vectors(void) {
 1502   bool ret_value = false;
 1503   if (UseAVX &gt; 2) {
 1504     ret_value = VM_Version::supports_avx512vl();
 1505   }
 1506 
 1507   return ret_value;
 1508 }
 1509 
 1510 const int Matcher::float_pressure(int default_pressure_threshold) {
 1511   int float_pressure_threshold = default_pressure_threshold;
 1512 #ifdef _LP64
 1513   if (UseAVX &gt; 2) {
 1514     // Increase pressure threshold on machines with AVX3 which have
 1515     // 2x more XMM registers.
 1516     float_pressure_threshold = default_pressure_threshold * 2;
 1517   }
 1518 #endif
 1519   return float_pressure_threshold;
 1520 }
 1521 
 1522 // Max vector size in bytes. 0 if not supported.
 1523 const int Matcher::vector_width_in_bytes(BasicType bt) {
 1524   assert(is_java_primitive(bt), &quot;only primitive type vectors&quot;);
 1525   if (UseSSE &lt; 2) return 0;
 1526   // SSE2 supports 128bit vectors for all types.
 1527   // AVX2 supports 256bit vectors for all types.
 1528   // AVX2/EVEX supports 512bit vectors for all types.
 1529   int size = (UseAVX &gt; 1) ? (1 &lt;&lt; UseAVX) * 8 : 16;
 1530   // AVX1 supports 256bit vectors only for FLOAT and DOUBLE.
 1531   if (UseAVX &gt; 0 &amp;&amp; (bt == T_FLOAT || bt == T_DOUBLE))
 1532     size = (UseAVX &gt; 2) ? 64 : 32;
 1533   if (UseAVX &gt; 2 &amp;&amp; (bt == T_BYTE || bt == T_SHORT || bt == T_CHAR))
 1534     size = (VM_Version::supports_avx512bw()) ? 64 : 32;
 1535   // Use flag to limit vector size.
 1536   size = MIN2(size,(int)MaxVectorSize);
 1537   // Minimum 2 values in vector (or 4 for bytes).
 1538   switch (bt) {
 1539   case T_DOUBLE:
 1540   case T_LONG:
 1541     if (size &lt; 16) return 0;
 1542     break;
 1543   case T_FLOAT:
 1544   case T_INT:
 1545     if (size &lt; 8) return 0;
 1546     break;
 1547   case T_BOOLEAN:
 1548     if (size &lt; 4) return 0;
 1549     break;
 1550   case T_CHAR:
 1551     if (size &lt; 4) return 0;
 1552     break;
 1553   case T_BYTE:
 1554     if (size &lt; 4) return 0;
 1555     break;
 1556   case T_SHORT:
 1557     if (size &lt; 4) return 0;
 1558     break;
 1559   default:
 1560     ShouldNotReachHere();
 1561   }
 1562   return size;
 1563 }
 1564 
 1565 // Limits on vector size (number of elements) loaded into vector.
 1566 const int Matcher::max_vector_size(const BasicType bt) {
 1567   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 1568 }
 1569 const int Matcher::min_vector_size(const BasicType bt) {
 1570   int max_size = max_vector_size(bt);
 1571   // Min size which can be loaded into vector is 4 bytes.
 1572   int size = (type2aelembytes(bt) == 1) ? 4 : 2;
 1573   return MIN2(size,max_size);
 1574 }
 1575 
 1576 // Vector ideal reg corresponding to specified size in bytes
 1577 const uint Matcher::vector_ideal_reg(int size) {
 1578   assert(MaxVectorSize &gt;= size, &quot;&quot;);
 1579   switch(size) {
 1580     case  4: return Op_VecS;
 1581     case  8: return Op_VecD;
 1582     case 16: return Op_VecX;
 1583     case 32: return Op_VecY;
 1584     case 64: return Op_VecZ;
 1585   }
 1586   ShouldNotReachHere();
 1587   return 0;
 1588 }
 1589 
 1590 // Only lowest bits of xmm reg are used for vector shift count.
 1591 const uint Matcher::vector_shift_count_ideal_reg(int size) {
 1592   return Op_VecS;
 1593 }
 1594 
 1595 // x86 supports misaligned vectors store/load.
 1596 const bool Matcher::misaligned_vectors_ok() {
 1597   return true;
 1598 }
 1599 
 1600 // x86 AES instructions are compatible with SunJCE expanded
 1601 // keys, hence we do not need to pass the original key to stubs
 1602 const bool Matcher::pass_original_key_for_aes() {
 1603   return false;
 1604 }
 1605 
 1606 
 1607 const bool Matcher::convi2l_type_required = true;
 1608 
 1609 // Check for shift by small constant as well
 1610 static bool clone_shift(Node* shift, Matcher* matcher, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 1611   if (shift-&gt;Opcode() == Op_LShiftX &amp;&amp; shift-&gt;in(2)-&gt;is_Con() &amp;&amp;
 1612       shift-&gt;in(2)-&gt;get_int() &lt;= 3 &amp;&amp;
 1613       // Are there other uses besides address expressions?
 1614       !matcher-&gt;is_visited(shift)) {
 1615     address_visited.set(shift-&gt;_idx); // Flag as address_visited
 1616     mstack.push(shift-&gt;in(2), Matcher::Visit);
 1617     Node *conv = shift-&gt;in(1);
 1618 #ifdef _LP64
 1619     // Allow Matcher to match the rule which bypass
 1620     // ConvI2L operation for an array index on LP64
 1621     // if the index value is positive.
 1622     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 1623         conv-&gt;as_Type()-&gt;type()-&gt;is_long()-&gt;_lo &gt;= 0 &amp;&amp;
 1624         // Are there other uses besides address expressions?
 1625         !matcher-&gt;is_visited(conv)) {
 1626       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 1627       mstack.push(conv-&gt;in(1), Matcher::Pre_Visit);
 1628     } else
 1629 #endif
 1630       mstack.push(conv, Matcher::Pre_Visit);
 1631     return true;
 1632   }
 1633   return false;
 1634 }
 1635 
 1636 // Should the Matcher clone shifts on addressing modes, expecting them
 1637 // to be subsumed into complex addressing expressions or compute them
 1638 // into registers?
 1639 bool Matcher::clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 1640   Node *off = m-&gt;in(AddPNode::Offset);
 1641   if (off-&gt;is_Con()) {
 1642     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 1643     Node *adr = m-&gt;in(AddPNode::Address);
 1644 
 1645     // Intel can handle 2 adds in addressing mode
 1646     // AtomicAdd is not an addressing expression.
 1647     // Cheap to find it by looking for screwy base.
 1648     if (adr-&gt;is_AddP() &amp;&amp;
 1649         !adr-&gt;in(AddPNode::Base)-&gt;is_top() &amp;&amp;
 1650         LP64_ONLY( off-&gt;get_long() == (int) (off-&gt;get_long()) &amp;&amp; ) // immL32
 1651         // Are there other uses besides address expressions?
 1652         !is_visited(adr)) {
 1653       address_visited.set(adr-&gt;_idx); // Flag as address_visited
 1654       Node *shift = adr-&gt;in(AddPNode::Offset);
 1655       if (!clone_shift(shift, this, mstack, address_visited)) {
 1656         mstack.push(shift, Pre_Visit);
 1657       }
 1658       mstack.push(adr-&gt;in(AddPNode::Address), Pre_Visit);
 1659       mstack.push(adr-&gt;in(AddPNode::Base), Pre_Visit);
 1660     } else {
 1661       mstack.push(adr, Pre_Visit);
 1662     }
 1663 
 1664     // Clone X+offset as it also folds into most addressing expressions
 1665     mstack.push(off, Visit);
 1666     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 1667     return true;
 1668   } else if (clone_shift(off, this, mstack, address_visited)) {
 1669     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 1670     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 1671     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 1672     return true;
 1673   }
 1674   return false;
 1675 }
 1676 
 1677 void Compile::reshape_address(AddPNode* addp) {
 1678 }
 1679 
<a name="31" id="anc31"></a>






























 1680 // Helper methods for MachSpillCopyNode::implementation().
 1681 static int vec_mov_helper(CodeBuffer *cbuf, bool do_size, int src_lo, int dst_lo,
 1682                           int src_hi, int dst_hi, uint ireg, outputStream* st) {
 1683   // In 64-bit VM size calculation is very complex. Emitting instructions
 1684   // into scratch buffer is used to get size in 64-bit VM.
 1685   LP64_ONLY( assert(!do_size, &quot;this method calculates size only for 32-bit VM&quot;); )
 1686   assert(ireg == Op_VecS || // 32bit vector
 1687          (src_lo &amp; 1) == 0 &amp;&amp; (src_lo + 1) == src_hi &amp;&amp;
 1688          (dst_lo &amp; 1) == 0 &amp;&amp; (dst_lo + 1) == dst_hi,
 1689          &quot;no non-adjacent vector moves&quot; );
 1690   if (cbuf) {
 1691     MacroAssembler _masm(cbuf);
 1692     int offset = __ offset();
 1693     switch (ireg) {
 1694     case Op_VecS: // copy whole register
 1695     case Op_VecD:
 1696     case Op_VecX:
 1697 #ifndef _LP64
 1698       __ movdqu(as_XMMRegister(Matcher::_regEncode[dst_lo]), as_XMMRegister(Matcher::_regEncode[src_lo]));
 1699 #else
 1700       if ((UseAVX &lt; 3) || VM_Version::supports_avx512vl()) {
 1701         __ movdqu(as_XMMRegister(Matcher::_regEncode[dst_lo]), as_XMMRegister(Matcher::_regEncode[src_lo]));
 1702       } else {
 1703         __ vextractf32x4(as_XMMRegister(Matcher::_regEncode[dst_lo]), as_XMMRegister(Matcher::_regEncode[src_lo]), 0x0);
 1704      }
 1705 #endif
 1706       break;
 1707     case Op_VecY:
 1708 #ifndef _LP64
 1709       __ vmovdqu(as_XMMRegister(Matcher::_regEncode[dst_lo]), as_XMMRegister(Matcher::_regEncode[src_lo]));
 1710 #else
 1711       if ((UseAVX &lt; 3) || VM_Version::supports_avx512vl()) {
 1712         __ vmovdqu(as_XMMRegister(Matcher::_regEncode[dst_lo]), as_XMMRegister(Matcher::_regEncode[src_lo]));
 1713       } else {
 1714         __ vextractf64x4(as_XMMRegister(Matcher::_regEncode[dst_lo]), as_XMMRegister(Matcher::_regEncode[src_lo]), 0x0);
 1715      }
 1716 #endif
 1717       break;
 1718     case Op_VecZ:
 1719       __ evmovdquq(as_XMMRegister(Matcher::_regEncode[dst_lo]), as_XMMRegister(Matcher::_regEncode[src_lo]), 2);
 1720       break;
 1721     default:
 1722       ShouldNotReachHere();
 1723     }
 1724     int size = __ offset() - offset;
 1725 #ifdef ASSERT
 1726     // VEX_2bytes prefix is used if UseAVX &gt; 0, so it takes the same 2 bytes as SIMD prefix.
 1727     assert(!do_size || size == 4, &quot;incorrect size calculattion&quot;);
 1728 #endif
 1729     return size;
 1730 #ifndef PRODUCT
 1731   } else if (!do_size) {
 1732     switch (ireg) {
 1733     case Op_VecS:
 1734     case Op_VecD:
 1735     case Op_VecX:
 1736       st-&gt;print(&quot;movdqu  %s,%s\t# spill&quot;,Matcher::regName[dst_lo],Matcher::regName[src_lo]);
 1737       break;
 1738     case Op_VecY:
 1739     case Op_VecZ:
 1740       st-&gt;print(&quot;vmovdqu %s,%s\t# spill&quot;,Matcher::regName[dst_lo],Matcher::regName[src_lo]);
 1741       break;
 1742     default:
 1743       ShouldNotReachHere();
 1744     }
 1745 #endif
 1746   }
 1747   // VEX_2bytes prefix is used if UseAVX &gt; 0, and it takes the same 2 bytes as SIMD prefix.
 1748   return (UseAVX &gt; 2) ? 6 : 4;
 1749 }
 1750 
<a name="32" id="anc32"></a><span class="line-modified"> 1751 static int vec_spill_helper(CodeBuffer *cbuf, bool do_size, bool is_load,</span>
<span class="line-modified"> 1752                             int stack_offset, int reg, uint ireg, outputStream* st) {</span>
 1753   // In 64-bit VM size calculation is very complex. Emitting instructions
 1754   // into scratch buffer is used to get size in 64-bit VM.
 1755   LP64_ONLY( assert(!do_size, &quot;this method calculates size only for 32-bit VM&quot;); )
 1756   if (cbuf) {
 1757     MacroAssembler _masm(cbuf);
 1758     int offset = __ offset();
 1759     if (is_load) {
 1760       switch (ireg) {
 1761       case Op_VecS:
 1762         __ movdl(as_XMMRegister(Matcher::_regEncode[reg]), Address(rsp, stack_offset));
 1763         break;
 1764       case Op_VecD:
 1765         __ movq(as_XMMRegister(Matcher::_regEncode[reg]), Address(rsp, stack_offset));
 1766         break;
 1767       case Op_VecX:
 1768 #ifndef _LP64
 1769         __ movdqu(as_XMMRegister(Matcher::_regEncode[reg]), Address(rsp, stack_offset));
 1770 #else
 1771         if ((UseAVX &lt; 3) || VM_Version::supports_avx512vl()) {
 1772           __ movdqu(as_XMMRegister(Matcher::_regEncode[reg]), Address(rsp, stack_offset));
 1773         } else {
 1774           __ vpxor(as_XMMRegister(Matcher::_regEncode[reg]), as_XMMRegister(Matcher::_regEncode[reg]), as_XMMRegister(Matcher::_regEncode[reg]), 2);
 1775           __ vinsertf32x4(as_XMMRegister(Matcher::_regEncode[reg]), as_XMMRegister(Matcher::_regEncode[reg]), Address(rsp, stack_offset),0x0);
 1776         }
 1777 #endif
 1778         break;
 1779       case Op_VecY:
 1780 #ifndef _LP64
 1781         __ vmovdqu(as_XMMRegister(Matcher::_regEncode[reg]), Address(rsp, stack_offset));
 1782 #else
 1783         if ((UseAVX &lt; 3) || VM_Version::supports_avx512vl()) {
 1784           __ vmovdqu(as_XMMRegister(Matcher::_regEncode[reg]), Address(rsp, stack_offset));
 1785         } else {
 1786           __ vpxor(as_XMMRegister(Matcher::_regEncode[reg]), as_XMMRegister(Matcher::_regEncode[reg]), as_XMMRegister(Matcher::_regEncode[reg]), 2);
 1787           __ vinsertf64x4(as_XMMRegister(Matcher::_regEncode[reg]), as_XMMRegister(Matcher::_regEncode[reg]), Address(rsp, stack_offset),0x0);
 1788         }
 1789 #endif
 1790         break;
 1791       case Op_VecZ:
 1792         __ evmovdquq(as_XMMRegister(Matcher::_regEncode[reg]), Address(rsp, stack_offset), 2);
 1793         break;
 1794       default:
 1795         ShouldNotReachHere();
 1796       }
 1797     } else { // store
 1798       switch (ireg) {
 1799       case Op_VecS:
 1800         __ movdl(Address(rsp, stack_offset), as_XMMRegister(Matcher::_regEncode[reg]));
 1801         break;
 1802       case Op_VecD:
 1803         __ movq(Address(rsp, stack_offset), as_XMMRegister(Matcher::_regEncode[reg]));
 1804         break;
 1805       case Op_VecX:
 1806 #ifndef _LP64
 1807         __ movdqu(Address(rsp, stack_offset), as_XMMRegister(Matcher::_regEncode[reg]));
 1808 #else
 1809         if ((UseAVX &lt; 3) || VM_Version::supports_avx512vl()) {
 1810           __ movdqu(Address(rsp, stack_offset), as_XMMRegister(Matcher::_regEncode[reg]));
 1811         }
 1812         else {
 1813           __ vextractf32x4(Address(rsp, stack_offset), as_XMMRegister(Matcher::_regEncode[reg]), 0x0);
 1814         }
 1815 #endif
 1816         break;
 1817       case Op_VecY:
 1818 #ifndef _LP64
 1819         __ vmovdqu(Address(rsp, stack_offset), as_XMMRegister(Matcher::_regEncode[reg]));
 1820 #else
 1821         if ((UseAVX &lt; 3) || VM_Version::supports_avx512vl()) {
 1822           __ vmovdqu(Address(rsp, stack_offset), as_XMMRegister(Matcher::_regEncode[reg]));
 1823         }
 1824         else {
 1825           __ vextractf64x4(Address(rsp, stack_offset), as_XMMRegister(Matcher::_regEncode[reg]), 0x0);
 1826         }
 1827 #endif
 1828         break;
 1829       case Op_VecZ:
 1830         __ evmovdquq(Address(rsp, stack_offset), as_XMMRegister(Matcher::_regEncode[reg]), 2);
 1831         break;
 1832       default:
 1833         ShouldNotReachHere();
 1834       }
 1835     }
 1836     int size = __ offset() - offset;
 1837 #ifdef ASSERT
 1838     int offset_size = (stack_offset == 0) ? 0 : ((stack_offset &lt; 0x80) ? 1 : (UseAVX &gt; 2) ? 6 : 4);
 1839     // VEX_2bytes prefix is used if UseAVX &gt; 0, so it takes the same 2 bytes as SIMD prefix.
 1840     assert(!do_size || size == (5+offset_size), &quot;incorrect size calculattion&quot;);
 1841 #endif
 1842     return size;
 1843 #ifndef PRODUCT
 1844   } else if (!do_size) {
 1845     if (is_load) {
 1846       switch (ireg) {
 1847       case Op_VecS:
 1848         st-&gt;print(&quot;movd    %s,[rsp + %d]\t# spill&quot;, Matcher::regName[reg], stack_offset);
 1849         break;
 1850       case Op_VecD:
 1851         st-&gt;print(&quot;movq    %s,[rsp + %d]\t# spill&quot;, Matcher::regName[reg], stack_offset);
 1852         break;
 1853        case Op_VecX:
 1854         st-&gt;print(&quot;movdqu  %s,[rsp + %d]\t# spill&quot;, Matcher::regName[reg], stack_offset);
 1855         break;
 1856       case Op_VecY:
 1857       case Op_VecZ:
 1858         st-&gt;print(&quot;vmovdqu %s,[rsp + %d]\t# spill&quot;, Matcher::regName[reg], stack_offset);
 1859         break;
 1860       default:
 1861         ShouldNotReachHere();
 1862       }
 1863     } else { // store
 1864       switch (ireg) {
 1865       case Op_VecS:
 1866         st-&gt;print(&quot;movd    [rsp + %d],%s\t# spill&quot;, stack_offset, Matcher::regName[reg]);
 1867         break;
 1868       case Op_VecD:
 1869         st-&gt;print(&quot;movq    [rsp + %d],%s\t# spill&quot;, stack_offset, Matcher::regName[reg]);
 1870         break;
 1871        case Op_VecX:
 1872         st-&gt;print(&quot;movdqu  [rsp + %d],%s\t# spill&quot;, stack_offset, Matcher::regName[reg]);
 1873         break;
 1874       case Op_VecY:
 1875       case Op_VecZ:
 1876         st-&gt;print(&quot;vmovdqu [rsp + %d],%s\t# spill&quot;, stack_offset, Matcher::regName[reg]);
 1877         break;
 1878       default:
 1879         ShouldNotReachHere();
 1880       }
 1881     }
 1882 #endif
 1883   }
 1884   bool is_single_byte = false;
 1885   int vec_len = 0;
 1886   if ((UseAVX &gt; 2) &amp;&amp; (stack_offset != 0)) {
 1887     int tuple_type = Assembler::EVEX_FVM;
 1888     int input_size = Assembler::EVEX_32bit;
 1889     switch (ireg) {
 1890     case Op_VecS:
 1891       tuple_type = Assembler::EVEX_T1S;
 1892       break;
 1893     case Op_VecD:
 1894       tuple_type = Assembler::EVEX_T1S;
 1895       input_size = Assembler::EVEX_64bit;
 1896       break;
 1897     case Op_VecX:
 1898       break;
 1899     case Op_VecY:
 1900       vec_len = 1;
 1901       break;
 1902     case Op_VecZ:
 1903       vec_len = 2;
 1904       break;
 1905     }
 1906     is_single_byte = Assembler::query_compressed_disp_byte(stack_offset, true, vec_len, tuple_type, input_size, 0);
 1907   }
 1908   int offset_size = 0;
 1909   int size = 5;
 1910   if (UseAVX &gt; 2 ) {
 1911     if (VM_Version::supports_avx512novl() &amp;&amp; (vec_len == 2)) {
 1912       offset_size = (stack_offset == 0) ? 0 : ((is_single_byte) ? 1 : 4);
 1913       size += 2; // Need an additional two bytes for EVEX encoding
 1914     } else if (VM_Version::supports_avx512novl() &amp;&amp; (vec_len &lt; 2)) {
 1915       offset_size = (stack_offset == 0) ? 0 : ((stack_offset &lt;= 127) ? 1 : 4);
 1916     } else {
 1917       offset_size = (stack_offset == 0) ? 0 : ((is_single_byte) ? 1 : 4);
 1918       size += 2; // Need an additional two bytes for EVEX encodding
 1919     }
 1920   } else {
 1921     offset_size = (stack_offset == 0) ? 0 : ((stack_offset &lt;= 127) ? 1 : 4);
 1922   }
 1923   // VEX_2bytes prefix is used if UseAVX &gt; 0, so it takes the same 2 bytes as SIMD prefix.
 1924   return size+offset_size;
 1925 }
 1926 
 1927 static inline jint replicate4_imm(int con, int width) {
 1928   // Load a constant of &quot;width&quot; (in bytes) and replicate it to fill 32bit.
 1929   assert(width == 1 || width == 2, &quot;only byte or short types here&quot;);
 1930   int bit_width = width * 8;
 1931   jint val = con;
 1932   val &amp;= (1 &lt;&lt; bit_width) - 1;  // mask off sign bits
 1933   while(bit_width &lt; 32) {
 1934     val |= (val &lt;&lt; bit_width);
 1935     bit_width &lt;&lt;= 1;
 1936   }
 1937   return val;
 1938 }
 1939 
 1940 static inline jlong replicate8_imm(int con, int width) {
 1941   // Load a constant of &quot;width&quot; (in bytes) and replicate it to fill 64bit.
 1942   assert(width == 1 || width == 2 || width == 4, &quot;only byte, short or int types here&quot;);
 1943   int bit_width = width * 8;
 1944   jlong val = con;
 1945   val &amp;= (((jlong) 1) &lt;&lt; bit_width) - 1;  // mask off sign bits
 1946   while(bit_width &lt; 64) {
 1947     val |= (val &lt;&lt; bit_width);
 1948     bit_width &lt;&lt;= 1;
 1949   }
 1950   return val;
 1951 }
 1952 
 1953 #ifndef PRODUCT
 1954   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1955     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1956   }
 1957 #endif
 1958 
 1959   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1960     MacroAssembler _masm(&amp;cbuf);
 1961     __ nop(_count);
 1962   }
 1963 
 1964   uint MachNopNode::size(PhaseRegAlloc*) const {
 1965     return _count;
 1966   }
 1967 
 1968 #ifndef PRODUCT
 1969   void MachBreakpointNode::format(PhaseRegAlloc*, outputStream* st) const {
 1970     st-&gt;print(&quot;# breakpoint&quot;);
 1971   }
 1972 #endif
 1973 
 1974   void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc* ra_) const {
 1975     MacroAssembler _masm(&amp;cbuf);
 1976     __ int3();
 1977   }
 1978 
 1979   uint MachBreakpointNode::size(PhaseRegAlloc* ra_) const {
 1980     return MachNode::size(ra_);
 1981   }
 1982 
 1983 %}
 1984 
 1985 encode %{
 1986 
 1987   enc_class call_epilog %{
 1988     if (VerifyStackAtCalls) {
 1989       // Check that stack depth is unchanged: find majik cookie on stack
 1990       int framesize = ra_-&gt;reg2offset_unchecked(OptoReg::add(ra_-&gt;_matcher._old_SP, -3*VMRegImpl::slots_per_word));
 1991       MacroAssembler _masm(&amp;cbuf);
 1992       Label L;
 1993       __ cmpptr(Address(rsp, framesize), (int32_t)0xbadb100d);
 1994       __ jccb(Assembler::equal, L);
 1995       // Die if stack mismatch
 1996       __ int3();
 1997       __ bind(L);
 1998     }
 1999   %}
 2000 
 2001 %}
 2002 
 2003 
 2004 //----------OPERANDS-----------------------------------------------------------
 2005 // Operand definitions must precede instruction definitions for correct parsing
 2006 // in the ADLC because operands constitute user defined types which are used in
 2007 // instruction definitions.
 2008 
<a name="33" id="anc33"></a>








































































































 2009 operand vecZ() %{
 2010   constraint(ALLOC_IN_RC(vectorz_reg));
 2011   match(VecZ);
 2012 
 2013   format %{ %}
 2014   interface(REG_INTER);
 2015 %}
 2016 
<a name="34" id="anc34"></a>
 2017 operand legVecZ() %{
<a name="35" id="anc35"></a><span class="line-modified"> 2018   constraint(ALLOC_IN_RC(vectorz_reg_vl));</span>
 2019   match(VecZ);
 2020 
 2021   format %{ %}
 2022   interface(REG_INTER);
 2023 %}
 2024 
 2025 // Comparison Code for FP conditional move
 2026 operand cmpOp_vcmppd() %{
 2027   match(Bool);
 2028 
 2029   predicate(n-&gt;as_Bool()-&gt;_test._test != BoolTest::overflow &amp;&amp;
 2030             n-&gt;as_Bool()-&gt;_test._test != BoolTest::no_overflow);
 2031   format %{ &quot;&quot; %}
 2032   interface(COND_INTER) %{
 2033     equal        (0x0, &quot;eq&quot;);
 2034     less         (0x1, &quot;lt&quot;);
 2035     less_equal   (0x2, &quot;le&quot;);
 2036     not_equal    (0xC, &quot;ne&quot;);
 2037     greater_equal(0xD, &quot;ge&quot;);
 2038     greater      (0xE, &quot;gt&quot;);
 2039     //TODO cannot compile (adlc breaks) without two next lines with error:
 2040     // x86_64.ad(13987) Syntax Error: :In operand cmpOp_vcmppd: Do not support this encode constant: &#39; %{
 2041     // equal&#39; for overflow.
 2042     overflow     (0x20, &quot;o&quot;);  // not really supported by the instruction
 2043     no_overflow  (0x21, &quot;no&quot;); // not really supported by the instruction
 2044   %}
 2045 %}
 2046 
 2047 
 2048 // INSTRUCTIONS -- Platform independent definitions (same for 32- and 64-bit)
 2049 
 2050 // ============================================================================
 2051 
 2052 instruct ShouldNotReachHere() %{
 2053   match(Halt);
 2054   format %{ &quot;ud2\t# ShouldNotReachHere&quot; %}
 2055   ins_encode %{
<a name="36" id="anc36"></a><span class="line-modified"> 2056     __ ud2();</span>
 2057   %}
 2058   ins_pipe(pipe_slow);
 2059 %}
 2060 
 2061 // =================================EVEX special===============================
 2062 
 2063 instruct setMask(rRegI dst, rRegI src) %{
 2064   predicate(Matcher::has_predicated_vectors());
 2065   match(Set dst (SetVectMaskI  src));
 2066   effect(TEMP dst);
 2067   format %{ &quot;setvectmask   $dst, $src&quot; %}
 2068   ins_encode %{
 2069     __ setvectmask($dst$$Register, $src$$Register);
 2070   %}
 2071   ins_pipe(pipe_slow);
 2072 %}
 2073 
 2074 // ============================================================================
 2075 
 2076 instruct addF_reg(regF dst, regF src) %{
 2077   predicate((UseSSE&gt;=1) &amp;&amp; (UseAVX == 0));
 2078   match(Set dst (AddF dst src));
 2079 
 2080   format %{ &quot;addss   $dst, $src&quot; %}
 2081   ins_cost(150);
 2082   ins_encode %{
 2083     __ addss($dst$$XMMRegister, $src$$XMMRegister);
 2084   %}
 2085   ins_pipe(pipe_slow);
 2086 %}
 2087 
 2088 instruct addF_mem(regF dst, memory src) %{
 2089   predicate((UseSSE&gt;=1) &amp;&amp; (UseAVX == 0));
 2090   match(Set dst (AddF dst (LoadF src)));
 2091 
 2092   format %{ &quot;addss   $dst, $src&quot; %}
 2093   ins_cost(150);
 2094   ins_encode %{
 2095     __ addss($dst$$XMMRegister, $src$$Address);
 2096   %}
 2097   ins_pipe(pipe_slow);
 2098 %}
 2099 
 2100 instruct addF_imm(regF dst, immF con) %{
 2101   predicate((UseSSE&gt;=1) &amp;&amp; (UseAVX == 0));
 2102   match(Set dst (AddF dst con));
 2103   format %{ &quot;addss   $dst, [$constantaddress]\t# load from constant table: float=$con&quot; %}
 2104   ins_cost(150);
 2105   ins_encode %{
 2106     __ addss($dst$$XMMRegister, $constantaddress($con));
 2107   %}
 2108   ins_pipe(pipe_slow);
 2109 %}
 2110 
 2111 instruct addF_reg_reg(regF dst, regF src1, regF src2) %{
 2112   predicate(UseAVX &gt; 0);
 2113   match(Set dst (AddF src1 src2));
 2114 
 2115   format %{ &quot;vaddss  $dst, $src1, $src2&quot; %}
 2116   ins_cost(150);
 2117   ins_encode %{
 2118     __ vaddss($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister);
 2119   %}
 2120   ins_pipe(pipe_slow);
 2121 %}
 2122 
 2123 instruct addF_reg_mem(regF dst, regF src1, memory src2) %{
 2124   predicate(UseAVX &gt; 0);
 2125   match(Set dst (AddF src1 (LoadF src2)));
 2126 
 2127   format %{ &quot;vaddss  $dst, $src1, $src2&quot; %}
 2128   ins_cost(150);
 2129   ins_encode %{
 2130     __ vaddss($dst$$XMMRegister, $src1$$XMMRegister, $src2$$Address);
 2131   %}
 2132   ins_pipe(pipe_slow);
 2133 %}
 2134 
 2135 instruct addF_reg_imm(regF dst, regF src, immF con) %{
 2136   predicate(UseAVX &gt; 0);
 2137   match(Set dst (AddF src con));
 2138 
 2139   format %{ &quot;vaddss  $dst, $src, [$constantaddress]\t# load from constant table: float=$con&quot; %}
 2140   ins_cost(150);
 2141   ins_encode %{
 2142     __ vaddss($dst$$XMMRegister, $src$$XMMRegister, $constantaddress($con));
 2143   %}
 2144   ins_pipe(pipe_slow);
 2145 %}
 2146 
 2147 instruct addD_reg(regD dst, regD src) %{
 2148   predicate((UseSSE&gt;=2) &amp;&amp; (UseAVX == 0));
 2149   match(Set dst (AddD dst src));
 2150 
 2151   format %{ &quot;addsd   $dst, $src&quot; %}
 2152   ins_cost(150);
 2153   ins_encode %{
 2154     __ addsd($dst$$XMMRegister, $src$$XMMRegister);
 2155   %}
 2156   ins_pipe(pipe_slow);
 2157 %}
 2158 
 2159 instruct addD_mem(regD dst, memory src) %{
 2160   predicate((UseSSE&gt;=2) &amp;&amp; (UseAVX == 0));
 2161   match(Set dst (AddD dst (LoadD src)));
 2162 
 2163   format %{ &quot;addsd   $dst, $src&quot; %}
 2164   ins_cost(150);
 2165   ins_encode %{
 2166     __ addsd($dst$$XMMRegister, $src$$Address);
 2167   %}
 2168   ins_pipe(pipe_slow);
 2169 %}
 2170 
 2171 instruct addD_imm(regD dst, immD con) %{
 2172   predicate((UseSSE&gt;=2) &amp;&amp; (UseAVX == 0));
 2173   match(Set dst (AddD dst con));
 2174   format %{ &quot;addsd   $dst, [$constantaddress]\t# load from constant table: double=$con&quot; %}
 2175   ins_cost(150);
 2176   ins_encode %{
 2177     __ addsd($dst$$XMMRegister, $constantaddress($con));
 2178   %}
 2179   ins_pipe(pipe_slow);
 2180 %}
 2181 
 2182 instruct addD_reg_reg(regD dst, regD src1, regD src2) %{
 2183   predicate(UseAVX &gt; 0);
 2184   match(Set dst (AddD src1 src2));
 2185 
 2186   format %{ &quot;vaddsd  $dst, $src1, $src2&quot; %}
 2187   ins_cost(150);
 2188   ins_encode %{
 2189     __ vaddsd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister);
 2190   %}
 2191   ins_pipe(pipe_slow);
 2192 %}
 2193 
 2194 instruct addD_reg_mem(regD dst, regD src1, memory src2) %{
 2195   predicate(UseAVX &gt; 0);
 2196   match(Set dst (AddD src1 (LoadD src2)));
 2197 
 2198   format %{ &quot;vaddsd  $dst, $src1, $src2&quot; %}
 2199   ins_cost(150);
 2200   ins_encode %{
 2201     __ vaddsd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$Address);
 2202   %}
 2203   ins_pipe(pipe_slow);
 2204 %}
 2205 
 2206 instruct addD_reg_imm(regD dst, regD src, immD con) %{
 2207   predicate(UseAVX &gt; 0);
 2208   match(Set dst (AddD src con));
 2209 
 2210   format %{ &quot;vaddsd  $dst, $src, [$constantaddress]\t# load from constant table: double=$con&quot; %}
 2211   ins_cost(150);
 2212   ins_encode %{
 2213     __ vaddsd($dst$$XMMRegister, $src$$XMMRegister, $constantaddress($con));
 2214   %}
 2215   ins_pipe(pipe_slow);
 2216 %}
 2217 
 2218 instruct subF_reg(regF dst, regF src) %{
 2219   predicate((UseSSE&gt;=1) &amp;&amp; (UseAVX == 0));
 2220   match(Set dst (SubF dst src));
 2221 
 2222   format %{ &quot;subss   $dst, $src&quot; %}
 2223   ins_cost(150);
 2224   ins_encode %{
 2225     __ subss($dst$$XMMRegister, $src$$XMMRegister);
 2226   %}
 2227   ins_pipe(pipe_slow);
 2228 %}
 2229 
 2230 instruct subF_mem(regF dst, memory src) %{
 2231   predicate((UseSSE&gt;=1) &amp;&amp; (UseAVX == 0));
 2232   match(Set dst (SubF dst (LoadF src)));
 2233 
 2234   format %{ &quot;subss   $dst, $src&quot; %}
 2235   ins_cost(150);
 2236   ins_encode %{
 2237     __ subss($dst$$XMMRegister, $src$$Address);
 2238   %}
 2239   ins_pipe(pipe_slow);
 2240 %}
 2241 
 2242 instruct subF_imm(regF dst, immF con) %{
 2243   predicate((UseSSE&gt;=1) &amp;&amp; (UseAVX == 0));
 2244   match(Set dst (SubF dst con));
 2245   format %{ &quot;subss   $dst, [$constantaddress]\t# load from constant table: float=$con&quot; %}
 2246   ins_cost(150);
 2247   ins_encode %{
 2248     __ subss($dst$$XMMRegister, $constantaddress($con));
 2249   %}
 2250   ins_pipe(pipe_slow);
 2251 %}
 2252 
 2253 instruct subF_reg_reg(regF dst, regF src1, regF src2) %{
 2254   predicate(UseAVX &gt; 0);
 2255   match(Set dst (SubF src1 src2));
 2256 
 2257   format %{ &quot;vsubss  $dst, $src1, $src2&quot; %}
 2258   ins_cost(150);
 2259   ins_encode %{
 2260     __ vsubss($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister);
 2261   %}
 2262   ins_pipe(pipe_slow);
 2263 %}
 2264 
 2265 instruct subF_reg_mem(regF dst, regF src1, memory src2) %{
 2266   predicate(UseAVX &gt; 0);
 2267   match(Set dst (SubF src1 (LoadF src2)));
 2268 
 2269   format %{ &quot;vsubss  $dst, $src1, $src2&quot; %}
 2270   ins_cost(150);
 2271   ins_encode %{
 2272     __ vsubss($dst$$XMMRegister, $src1$$XMMRegister, $src2$$Address);
 2273   %}
 2274   ins_pipe(pipe_slow);
 2275 %}
 2276 
 2277 instruct subF_reg_imm(regF dst, regF src, immF con) %{
 2278   predicate(UseAVX &gt; 0);
 2279   match(Set dst (SubF src con));
 2280 
 2281   format %{ &quot;vsubss  $dst, $src, [$constantaddress]\t# load from constant table: float=$con&quot; %}
 2282   ins_cost(150);
 2283   ins_encode %{
 2284     __ vsubss($dst$$XMMRegister, $src$$XMMRegister, $constantaddress($con));
 2285   %}
 2286   ins_pipe(pipe_slow);
 2287 %}
 2288 
 2289 instruct subD_reg(regD dst, regD src) %{
 2290   predicate((UseSSE&gt;=2) &amp;&amp; (UseAVX == 0));
 2291   match(Set dst (SubD dst src));
 2292 
 2293   format %{ &quot;subsd   $dst, $src&quot; %}
 2294   ins_cost(150);
 2295   ins_encode %{
 2296     __ subsd($dst$$XMMRegister, $src$$XMMRegister);
 2297   %}
 2298   ins_pipe(pipe_slow);
 2299 %}
 2300 
 2301 instruct subD_mem(regD dst, memory src) %{
 2302   predicate((UseSSE&gt;=2) &amp;&amp; (UseAVX == 0));
 2303   match(Set dst (SubD dst (LoadD src)));
 2304 
 2305   format %{ &quot;subsd   $dst, $src&quot; %}
 2306   ins_cost(150);
 2307   ins_encode %{
 2308     __ subsd($dst$$XMMRegister, $src$$Address);
 2309   %}
 2310   ins_pipe(pipe_slow);
 2311 %}
 2312 
 2313 instruct subD_imm(regD dst, immD con) %{
 2314   predicate((UseSSE&gt;=2) &amp;&amp; (UseAVX == 0));
 2315   match(Set dst (SubD dst con));
 2316   format %{ &quot;subsd   $dst, [$constantaddress]\t# load from constant table: double=$con&quot; %}
 2317   ins_cost(150);
 2318   ins_encode %{
 2319     __ subsd($dst$$XMMRegister, $constantaddress($con));
 2320   %}
 2321   ins_pipe(pipe_slow);
 2322 %}
 2323 
 2324 instruct subD_reg_reg(regD dst, regD src1, regD src2) %{
 2325   predicate(UseAVX &gt; 0);
 2326   match(Set dst (SubD src1 src2));
 2327 
 2328   format %{ &quot;vsubsd  $dst, $src1, $src2&quot; %}
 2329   ins_cost(150);
 2330   ins_encode %{
 2331     __ vsubsd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister);
 2332   %}
 2333   ins_pipe(pipe_slow);
 2334 %}
 2335 
 2336 instruct subD_reg_mem(regD dst, regD src1, memory src2) %{
 2337   predicate(UseAVX &gt; 0);
 2338   match(Set dst (SubD src1 (LoadD src2)));
 2339 
 2340   format %{ &quot;vsubsd  $dst, $src1, $src2&quot; %}
 2341   ins_cost(150);
 2342   ins_encode %{
 2343     __ vsubsd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$Address);
 2344   %}
 2345   ins_pipe(pipe_slow);
 2346 %}
 2347 
 2348 instruct subD_reg_imm(regD dst, regD src, immD con) %{
 2349   predicate(UseAVX &gt; 0);
 2350   match(Set dst (SubD src con));
 2351 
 2352   format %{ &quot;vsubsd  $dst, $src, [$constantaddress]\t# load from constant table: double=$con&quot; %}
 2353   ins_cost(150);
 2354   ins_encode %{
 2355     __ vsubsd($dst$$XMMRegister, $src$$XMMRegister, $constantaddress($con));
 2356   %}
 2357   ins_pipe(pipe_slow);
 2358 %}
 2359 
 2360 instruct mulF_reg(regF dst, regF src) %{
 2361   predicate((UseSSE&gt;=1) &amp;&amp; (UseAVX == 0));
 2362   match(Set dst (MulF dst src));
 2363 
 2364   format %{ &quot;mulss   $dst, $src&quot; %}
 2365   ins_cost(150);
 2366   ins_encode %{
 2367     __ mulss($dst$$XMMRegister, $src$$XMMRegister);
 2368   %}
 2369   ins_pipe(pipe_slow);
 2370 %}
 2371 
 2372 instruct mulF_mem(regF dst, memory src) %{
 2373   predicate((UseSSE&gt;=1) &amp;&amp; (UseAVX == 0));
 2374   match(Set dst (MulF dst (LoadF src)));
 2375 
 2376   format %{ &quot;mulss   $dst, $src&quot; %}
 2377   ins_cost(150);
 2378   ins_encode %{
 2379     __ mulss($dst$$XMMRegister, $src$$Address);
 2380   %}
 2381   ins_pipe(pipe_slow);
 2382 %}
 2383 
 2384 instruct mulF_imm(regF dst, immF con) %{
 2385   predicate((UseSSE&gt;=1) &amp;&amp; (UseAVX == 0));
 2386   match(Set dst (MulF dst con));
 2387   format %{ &quot;mulss   $dst, [$constantaddress]\t# load from constant table: float=$con&quot; %}
 2388   ins_cost(150);
 2389   ins_encode %{
 2390     __ mulss($dst$$XMMRegister, $constantaddress($con));
 2391   %}
 2392   ins_pipe(pipe_slow);
 2393 %}
 2394 
 2395 instruct mulF_reg_reg(regF dst, regF src1, regF src2) %{
 2396   predicate(UseAVX &gt; 0);
 2397   match(Set dst (MulF src1 src2));
 2398 
 2399   format %{ &quot;vmulss  $dst, $src1, $src2&quot; %}
 2400   ins_cost(150);
 2401   ins_encode %{
 2402     __ vmulss($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister);
 2403   %}
 2404   ins_pipe(pipe_slow);
 2405 %}
 2406 
 2407 instruct mulF_reg_mem(regF dst, regF src1, memory src2) %{
 2408   predicate(UseAVX &gt; 0);
 2409   match(Set dst (MulF src1 (LoadF src2)));
 2410 
 2411   format %{ &quot;vmulss  $dst, $src1, $src2&quot; %}
 2412   ins_cost(150);
 2413   ins_encode %{
 2414     __ vmulss($dst$$XMMRegister, $src1$$XMMRegister, $src2$$Address);
 2415   %}
 2416   ins_pipe(pipe_slow);
 2417 %}
 2418 
 2419 instruct mulF_reg_imm(regF dst, regF src, immF con) %{
 2420   predicate(UseAVX &gt; 0);
 2421   match(Set dst (MulF src con));
 2422 
 2423   format %{ &quot;vmulss  $dst, $src, [$constantaddress]\t# load from constant table: float=$con&quot; %}
 2424   ins_cost(150);
 2425   ins_encode %{
 2426     __ vmulss($dst$$XMMRegister, $src$$XMMRegister, $constantaddress($con));
 2427   %}
 2428   ins_pipe(pipe_slow);
 2429 %}
 2430 
 2431 instruct mulD_reg(regD dst, regD src) %{
 2432   predicate((UseSSE&gt;=2) &amp;&amp; (UseAVX == 0));
 2433   match(Set dst (MulD dst src));
 2434 
 2435   format %{ &quot;mulsd   $dst, $src&quot; %}
 2436   ins_cost(150);
 2437   ins_encode %{
 2438     __ mulsd($dst$$XMMRegister, $src$$XMMRegister);
 2439   %}
 2440   ins_pipe(pipe_slow);
 2441 %}
 2442 
 2443 instruct mulD_mem(regD dst, memory src) %{
 2444   predicate((UseSSE&gt;=2) &amp;&amp; (UseAVX == 0));
 2445   match(Set dst (MulD dst (LoadD src)));
 2446 
 2447   format %{ &quot;mulsd   $dst, $src&quot; %}
 2448   ins_cost(150);
 2449   ins_encode %{
 2450     __ mulsd($dst$$XMMRegister, $src$$Address);
 2451   %}
 2452   ins_pipe(pipe_slow);
 2453 %}
 2454 
 2455 instruct mulD_imm(regD dst, immD con) %{
 2456   predicate((UseSSE&gt;=2) &amp;&amp; (UseAVX == 0));
 2457   match(Set dst (MulD dst con));
 2458   format %{ &quot;mulsd   $dst, [$constantaddress]\t# load from constant table: double=$con&quot; %}
 2459   ins_cost(150);
 2460   ins_encode %{
 2461     __ mulsd($dst$$XMMRegister, $constantaddress($con));
 2462   %}
 2463   ins_pipe(pipe_slow);
 2464 %}
 2465 
 2466 instruct mulD_reg_reg(regD dst, regD src1, regD src2) %{
 2467   predicate(UseAVX &gt; 0);
 2468   match(Set dst (MulD src1 src2));
 2469 
 2470   format %{ &quot;vmulsd  $dst, $src1, $src2&quot; %}
 2471   ins_cost(150);
 2472   ins_encode %{
 2473     __ vmulsd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister);
 2474   %}
 2475   ins_pipe(pipe_slow);
 2476 %}
 2477 
 2478 instruct mulD_reg_mem(regD dst, regD src1, memory src2) %{
 2479   predicate(UseAVX &gt; 0);
 2480   match(Set dst (MulD src1 (LoadD src2)));
 2481 
 2482   format %{ &quot;vmulsd  $dst, $src1, $src2&quot; %}
 2483   ins_cost(150);
 2484   ins_encode %{
 2485     __ vmulsd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$Address);
 2486   %}
 2487   ins_pipe(pipe_slow);
 2488 %}
 2489 
 2490 instruct mulD_reg_imm(regD dst, regD src, immD con) %{
 2491   predicate(UseAVX &gt; 0);
 2492   match(Set dst (MulD src con));
 2493 
 2494   format %{ &quot;vmulsd  $dst, $src, [$constantaddress]\t# load from constant table: double=$con&quot; %}
 2495   ins_cost(150);
 2496   ins_encode %{
 2497     __ vmulsd($dst$$XMMRegister, $src$$XMMRegister, $constantaddress($con));
 2498   %}
 2499   ins_pipe(pipe_slow);
 2500 %}
 2501 
 2502 instruct divF_reg(regF dst, regF src) %{
 2503   predicate((UseSSE&gt;=1) &amp;&amp; (UseAVX == 0));
 2504   match(Set dst (DivF dst src));
 2505 
 2506   format %{ &quot;divss   $dst, $src&quot; %}
 2507   ins_cost(150);
 2508   ins_encode %{
 2509     __ divss($dst$$XMMRegister, $src$$XMMRegister);
 2510   %}
 2511   ins_pipe(pipe_slow);
 2512 %}
 2513 
 2514 instruct divF_mem(regF dst, memory src) %{
 2515   predicate((UseSSE&gt;=1) &amp;&amp; (UseAVX == 0));
 2516   match(Set dst (DivF dst (LoadF src)));
 2517 
 2518   format %{ &quot;divss   $dst, $src&quot; %}
 2519   ins_cost(150);
 2520   ins_encode %{
 2521     __ divss($dst$$XMMRegister, $src$$Address);
 2522   %}
 2523   ins_pipe(pipe_slow);
 2524 %}
 2525 
 2526 instruct divF_imm(regF dst, immF con) %{
 2527   predicate((UseSSE&gt;=1) &amp;&amp; (UseAVX == 0));
 2528   match(Set dst (DivF dst con));
 2529   format %{ &quot;divss   $dst, [$constantaddress]\t# load from constant table: float=$con&quot; %}
 2530   ins_cost(150);
 2531   ins_encode %{
 2532     __ divss($dst$$XMMRegister, $constantaddress($con));
 2533   %}
 2534   ins_pipe(pipe_slow);
 2535 %}
 2536 
 2537 instruct divF_reg_reg(regF dst, regF src1, regF src2) %{
 2538   predicate(UseAVX &gt; 0);
 2539   match(Set dst (DivF src1 src2));
 2540 
 2541   format %{ &quot;vdivss  $dst, $src1, $src2&quot; %}
 2542   ins_cost(150);
 2543   ins_encode %{
 2544     __ vdivss($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister);
 2545   %}
 2546   ins_pipe(pipe_slow);
 2547 %}
 2548 
 2549 instruct divF_reg_mem(regF dst, regF src1, memory src2) %{
 2550   predicate(UseAVX &gt; 0);
 2551   match(Set dst (DivF src1 (LoadF src2)));
 2552 
 2553   format %{ &quot;vdivss  $dst, $src1, $src2&quot; %}
 2554   ins_cost(150);
 2555   ins_encode %{
 2556     __ vdivss($dst$$XMMRegister, $src1$$XMMRegister, $src2$$Address);
 2557   %}
 2558   ins_pipe(pipe_slow);
 2559 %}
 2560 
 2561 instruct divF_reg_imm(regF dst, regF src, immF con) %{
 2562   predicate(UseAVX &gt; 0);
 2563   match(Set dst (DivF src con));
 2564 
 2565   format %{ &quot;vdivss  $dst, $src, [$constantaddress]\t# load from constant table: float=$con&quot; %}
 2566   ins_cost(150);
 2567   ins_encode %{
 2568     __ vdivss($dst$$XMMRegister, $src$$XMMRegister, $constantaddress($con));
 2569   %}
 2570   ins_pipe(pipe_slow);
 2571 %}
 2572 
 2573 instruct divD_reg(regD dst, regD src) %{
 2574   predicate((UseSSE&gt;=2) &amp;&amp; (UseAVX == 0));
 2575   match(Set dst (DivD dst src));
 2576 
 2577   format %{ &quot;divsd   $dst, $src&quot; %}
 2578   ins_cost(150);
 2579   ins_encode %{
 2580     __ divsd($dst$$XMMRegister, $src$$XMMRegister);
 2581   %}
 2582   ins_pipe(pipe_slow);
 2583 %}
 2584 
 2585 instruct divD_mem(regD dst, memory src) %{
 2586   predicate((UseSSE&gt;=2) &amp;&amp; (UseAVX == 0));
 2587   match(Set dst (DivD dst (LoadD src)));
 2588 
 2589   format %{ &quot;divsd   $dst, $src&quot; %}
 2590   ins_cost(150);
 2591   ins_encode %{
 2592     __ divsd($dst$$XMMRegister, $src$$Address);
 2593   %}
 2594   ins_pipe(pipe_slow);
 2595 %}
 2596 
 2597 instruct divD_imm(regD dst, immD con) %{
 2598   predicate((UseSSE&gt;=2) &amp;&amp; (UseAVX == 0));
 2599   match(Set dst (DivD dst con));
 2600   format %{ &quot;divsd   $dst, [$constantaddress]\t# load from constant table: double=$con&quot; %}
 2601   ins_cost(150);
 2602   ins_encode %{
 2603     __ divsd($dst$$XMMRegister, $constantaddress($con));
 2604   %}
 2605   ins_pipe(pipe_slow);
 2606 %}
 2607 
 2608 instruct divD_reg_reg(regD dst, regD src1, regD src2) %{
 2609   predicate(UseAVX &gt; 0);
 2610   match(Set dst (DivD src1 src2));
 2611 
 2612   format %{ &quot;vdivsd  $dst, $src1, $src2&quot; %}
 2613   ins_cost(150);
 2614   ins_encode %{
 2615     __ vdivsd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister);
 2616   %}
 2617   ins_pipe(pipe_slow);
 2618 %}
 2619 
 2620 instruct divD_reg_mem(regD dst, regD src1, memory src2) %{
 2621   predicate(UseAVX &gt; 0);
 2622   match(Set dst (DivD src1 (LoadD src2)));
 2623 
 2624   format %{ &quot;vdivsd  $dst, $src1, $src2&quot; %}
 2625   ins_cost(150);
 2626   ins_encode %{
 2627     __ vdivsd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$Address);
 2628   %}
 2629   ins_pipe(pipe_slow);
 2630 %}
 2631 
 2632 instruct divD_reg_imm(regD dst, regD src, immD con) %{
 2633   predicate(UseAVX &gt; 0);
 2634   match(Set dst (DivD src con));
 2635 
 2636   format %{ &quot;vdivsd  $dst, $src, [$constantaddress]\t# load from constant table: double=$con&quot; %}
 2637   ins_cost(150);
 2638   ins_encode %{
 2639     __ vdivsd($dst$$XMMRegister, $src$$XMMRegister, $constantaddress($con));
 2640   %}
 2641   ins_pipe(pipe_slow);
 2642 %}
 2643 
 2644 instruct absF_reg(regF dst) %{
 2645   predicate((UseSSE&gt;=1) &amp;&amp; (UseAVX == 0));
 2646   match(Set dst (AbsF dst));
 2647   ins_cost(150);
 2648   format %{ &quot;andps   $dst, [0x7fffffff]\t# abs float by sign masking&quot; %}
 2649   ins_encode %{
 2650     __ andps($dst$$XMMRegister, ExternalAddress(float_signmask()));
 2651   %}
 2652   ins_pipe(pipe_slow);
 2653 %}
 2654 
 2655 instruct absF_reg_reg(vlRegF dst, vlRegF src) %{
 2656   predicate(UseAVX &gt; 0);
 2657   match(Set dst (AbsF src));
 2658   ins_cost(150);
 2659   format %{ &quot;vandps  $dst, $src, [0x7fffffff]\t# abs float by sign masking&quot; %}
 2660   ins_encode %{
 2661     int vector_len = 0;
 2662     __ vandps($dst$$XMMRegister, $src$$XMMRegister,
 2663               ExternalAddress(float_signmask()), vector_len);
 2664   %}
 2665   ins_pipe(pipe_slow);
 2666 %}
 2667 
 2668 instruct absD_reg(regD dst) %{
 2669   predicate((UseSSE&gt;=2) &amp;&amp; (UseAVX == 0));
 2670   match(Set dst (AbsD dst));
 2671   ins_cost(150);
 2672   format %{ &quot;andpd   $dst, [0x7fffffffffffffff]\t&quot;
 2673             &quot;# abs double by sign masking&quot; %}
 2674   ins_encode %{
 2675     __ andpd($dst$$XMMRegister, ExternalAddress(double_signmask()));
 2676   %}
 2677   ins_pipe(pipe_slow);
 2678 %}
 2679 
 2680 instruct absD_reg_reg(vlRegD dst, vlRegD src) %{
 2681   predicate(UseAVX &gt; 0);
 2682   match(Set dst (AbsD src));
 2683   ins_cost(150);
 2684   format %{ &quot;vandpd  $dst, $src, [0x7fffffffffffffff]\t&quot;
 2685             &quot;# abs double by sign masking&quot; %}
 2686   ins_encode %{
 2687     int vector_len = 0;
 2688     __ vandpd($dst$$XMMRegister, $src$$XMMRegister,
 2689               ExternalAddress(double_signmask()), vector_len);
 2690   %}
 2691   ins_pipe(pipe_slow);
 2692 %}
 2693 
 2694 instruct negF_reg(regF dst) %{
 2695   predicate((UseSSE&gt;=1) &amp;&amp; (UseAVX == 0));
 2696   match(Set dst (NegF dst));
 2697   ins_cost(150);
 2698   format %{ &quot;xorps   $dst, [0x80000000]\t# neg float by sign flipping&quot; %}
 2699   ins_encode %{
 2700     __ xorps($dst$$XMMRegister, ExternalAddress(float_signflip()));
 2701   %}
 2702   ins_pipe(pipe_slow);
 2703 %}
 2704 
 2705 instruct negF_reg_reg(vlRegF dst, vlRegF src) %{
 2706   predicate(UseAVX &gt; 0);
 2707   match(Set dst (NegF src));
 2708   ins_cost(150);
 2709   format %{ &quot;vnegatess  $dst, $src, [0x80000000]\t# neg float by sign flipping&quot; %}
 2710   ins_encode %{
 2711     __ vnegatess($dst$$XMMRegister, $src$$XMMRegister,
 2712                  ExternalAddress(float_signflip()));
 2713   %}
 2714   ins_pipe(pipe_slow);
 2715 %}
 2716 
 2717 instruct negD_reg(regD dst) %{
 2718   predicate((UseSSE&gt;=2) &amp;&amp; (UseAVX == 0));
 2719   match(Set dst (NegD dst));
 2720   ins_cost(150);
 2721   format %{ &quot;xorpd   $dst, [0x8000000000000000]\t&quot;
 2722             &quot;# neg double by sign flipping&quot; %}
 2723   ins_encode %{
 2724     __ xorpd($dst$$XMMRegister, ExternalAddress(double_signflip()));
 2725   %}
 2726   ins_pipe(pipe_slow);
 2727 %}
 2728 
 2729 instruct negD_reg_reg(vlRegD dst, vlRegD src) %{
 2730   predicate(UseAVX &gt; 0);
 2731   match(Set dst (NegD src));
 2732   ins_cost(150);
 2733   format %{ &quot;vnegatesd  $dst, $src, [0x8000000000000000]\t&quot;
 2734             &quot;# neg double by sign flipping&quot; %}
 2735   ins_encode %{
 2736     __ vnegatesd($dst$$XMMRegister, $src$$XMMRegister,
 2737                  ExternalAddress(double_signflip()));
 2738   %}
 2739   ins_pipe(pipe_slow);
 2740 %}
 2741 
 2742 instruct sqrtF_reg(regF dst, regF src) %{
 2743   predicate(UseSSE&gt;=1);
 2744   match(Set dst (SqrtF src));
 2745 
 2746   format %{ &quot;sqrtss  $dst, $src&quot; %}
 2747   ins_cost(150);
 2748   ins_encode %{
 2749     __ sqrtss($dst$$XMMRegister, $src$$XMMRegister);
 2750   %}
 2751   ins_pipe(pipe_slow);
 2752 %}
 2753 
 2754 instruct sqrtF_mem(regF dst, memory src) %{
 2755   predicate(UseSSE&gt;=1);
 2756   match(Set dst (SqrtF (LoadF src)));
 2757 
 2758   format %{ &quot;sqrtss  $dst, $src&quot; %}
 2759   ins_cost(150);
 2760   ins_encode %{
 2761     __ sqrtss($dst$$XMMRegister, $src$$Address);
 2762   %}
 2763   ins_pipe(pipe_slow);
 2764 %}
 2765 
 2766 instruct sqrtF_imm(regF dst, immF con) %{
 2767   predicate(UseSSE&gt;=1);
 2768   match(Set dst (SqrtF con));
 2769 
 2770   format %{ &quot;sqrtss  $dst, [$constantaddress]\t# load from constant table: float=$con&quot; %}
 2771   ins_cost(150);
 2772   ins_encode %{
 2773     __ sqrtss($dst$$XMMRegister, $constantaddress($con));
 2774   %}
 2775   ins_pipe(pipe_slow);
 2776 %}
 2777 
 2778 instruct sqrtD_reg(regD dst, regD src) %{
 2779   predicate(UseSSE&gt;=2);
 2780   match(Set dst (SqrtD src));
 2781 
 2782   format %{ &quot;sqrtsd  $dst, $src&quot; %}
 2783   ins_cost(150);
 2784   ins_encode %{
 2785     __ sqrtsd($dst$$XMMRegister, $src$$XMMRegister);
 2786   %}
 2787   ins_pipe(pipe_slow);
 2788 %}
 2789 
 2790 instruct sqrtD_mem(regD dst, memory src) %{
 2791   predicate(UseSSE&gt;=2);
 2792   match(Set dst (SqrtD (LoadD src)));
 2793 
 2794   format %{ &quot;sqrtsd  $dst, $src&quot; %}
 2795   ins_cost(150);
 2796   ins_encode %{
 2797     __ sqrtsd($dst$$XMMRegister, $src$$Address);
 2798   %}
 2799   ins_pipe(pipe_slow);
 2800 %}
 2801 
 2802 instruct sqrtD_imm(regD dst, immD con) %{
 2803   predicate(UseSSE&gt;=2);
 2804   match(Set dst (SqrtD con));
 2805   format %{ &quot;sqrtsd  $dst, [$constantaddress]\t# load from constant table: double=$con&quot; %}
 2806   ins_cost(150);
 2807   ins_encode %{
 2808     __ sqrtsd($dst$$XMMRegister, $constantaddress($con));
 2809   %}
 2810   ins_pipe(pipe_slow);
 2811 %}
 2812 
<a name="37" id="anc37"></a>


















































































 2813 instruct onspinwait() %{
 2814   match(OnSpinWait);
 2815   ins_cost(200);
 2816 
 2817   format %{
 2818     $$template
 2819     $$emit$$&quot;pause\t! membar_onspinwait&quot;
 2820   %}
 2821   ins_encode %{
 2822     __ pause();
 2823   %}
 2824   ins_pipe(pipe_slow);
 2825 %}
 2826 
 2827 // a * b + c
 2828 instruct fmaD_reg(regD a, regD b, regD c) %{
 2829   predicate(UseFMA);
 2830   match(Set c (FmaD  c (Binary a b)));
 2831   format %{ &quot;fmasd $a,$b,$c\t# $c = $a * $b + $c&quot; %}
 2832   ins_cost(150);
 2833   ins_encode %{
 2834     __ fmad($c$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, $c$$XMMRegister);
 2835   %}
 2836   ins_pipe( pipe_slow );
 2837 %}
 2838 
 2839 // a * b + c
 2840 instruct fmaF_reg(regF a, regF b, regF c) %{
 2841   predicate(UseFMA);
 2842   match(Set c (FmaF  c (Binary a b)));
 2843   format %{ &quot;fmass $a,$b,$c\t# $c = $a * $b + $c&quot; %}
 2844   ins_cost(150);
 2845   ins_encode %{
 2846     __ fmaf($c$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, $c$$XMMRegister);
 2847   %}
 2848   ins_pipe( pipe_slow );
 2849 %}
 2850 
 2851 // ====================VECTOR INSTRUCTIONS=====================================
 2852 
<a name="38" id="anc38"></a><span class="line-modified"> 2853 </span>
<span class="line-modified"> 2854 // Load vectors (4 bytes long)</span>
<span class="line-removed"> 2855 instruct loadV4(vecS dst, memory mem) %{</span>
<span class="line-removed"> 2856   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);</span>
<span class="line-removed"> 2857   match(Set dst (LoadVector mem));</span>
<span class="line-removed"> 2858   ins_cost(125);</span>
<span class="line-removed"> 2859   format %{ &quot;movd    $dst,$mem\t! load vector (4 bytes)&quot; %}</span>
<span class="line-removed"> 2860   ins_encode %{</span>
<span class="line-removed"> 2861     __ movdl($dst$$XMMRegister, $mem$$Address);</span>
<span class="line-removed"> 2862   %}</span>
<span class="line-removed"> 2863   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 2864 %}</span>
<span class="line-removed"> 2865 </span>
<span class="line-removed"> 2866 // Load vectors (4 bytes long)</span>
<span class="line-removed"> 2867 instruct MoveVecS2Leg(legVecS dst, vecS src) %{</span>
 2868   match(Set dst src);
<a name="39" id="anc39"></a><span class="line-modified"> 2869   format %{ &quot;movss $dst,$src\t! load vector (4 bytes)&quot; %}</span>
 2870   ins_encode %{
<a name="40" id="anc40"></a><span class="line-modified"> 2871     __ movflt($dst$$XMMRegister, $src$$XMMRegister);</span>
 2872   %}
 2873   ins_pipe( fpu_reg_reg );
 2874 %}
 2875 
<a name="41" id="anc41"></a><span class="line-modified"> 2876 // Load vectors (4 bytes long)</span>
<span class="line-removed"> 2877 instruct MoveLeg2VecS(vecS dst, legVecS src) %{</span>
 2878   match(Set dst src);
<a name="42" id="anc42"></a><span class="line-modified"> 2879   format %{ &quot;movss $dst,$src\t! load vector (4 bytes)&quot; %}</span>
 2880   ins_encode %{
<a name="43" id="anc43"></a><span class="line-modified"> 2881     __ movflt($dst$$XMMRegister, $src$$XMMRegister);</span>
 2882   %}
 2883   ins_pipe( fpu_reg_reg );
 2884 %}
 2885 
<a name="44" id="anc44"></a><span class="line-modified"> 2886 // Load vectors (8 bytes long)</span>
<span class="line-modified"> 2887 instruct loadV8(vecD dst, memory mem) %{</span>
<span class="line-modified"> 2888   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);</span>

 2889   match(Set dst (LoadVector mem));
 2890   ins_cost(125);
<a name="45" id="anc45"></a><span class="line-modified"> 2891   format %{ &quot;movq    $dst,$mem\t! load vector (8 bytes)&quot; %}</span>
<span class="line-modified"> 2892   ins_encode %{</span>
<span class="line-modified"> 2893     __ movq($dst$$XMMRegister, $mem$$Address);</span>







 2894   %}
 2895   ins_pipe( pipe_slow );
 2896 %}
 2897 
<a name="46" id="anc46"></a><span class="line-modified"> 2898 // Load vectors (8 bytes long)</span>
<span class="line-modified"> 2899 instruct MoveVecD2Leg(legVecD dst, vecD src) %{</span>
<span class="line-modified"> 2900   match(Set dst src);</span>
<span class="line-modified"> 2901   format %{ &quot;movsd $dst,$src\t! load vector (8 bytes)&quot; %}</span>
<span class="line-modified"> 2902   ins_encode %{</span>
<span class="line-modified"> 2903     __ movdbl($dst$$XMMRegister, $src$$XMMRegister);</span>








 2904   %}
<a name="47" id="anc47"></a><span class="line-modified"> 2905   ins_pipe( fpu_reg_reg );</span>
 2906 %}
 2907 
<a name="48" id="anc48"></a><span class="line-modified"> 2908 // Load vectors (8 bytes long)</span>
<span class="line-modified"> 2909 instruct MoveLeg2VecD(vecD dst, legVecD src) %{</span>
<span class="line-modified"> 2910   match(Set dst src);</span>
<span class="line-modified"> 2911   format %{ &quot;movsd $dst,$src\t! load vector (8 bytes)&quot; %}</span>




 2912   ins_encode %{
<a name="49" id="anc49"></a><span class="line-modified"> 2913     __ movdbl($dst$$XMMRegister, $src$$XMMRegister);</span>
















 2914   %}
<a name="50" id="anc50"></a><span class="line-modified"> 2915   ins_pipe( fpu_reg_reg );</span>
 2916 %}
 2917 
<a name="51" id="anc51"></a><span class="line-modified"> 2918 // Load vectors (16 bytes long)</span>
<span class="line-modified"> 2919 instruct loadV16(vecX dst, memory mem) %{</span>
<span class="line-modified"> 2920   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);</span>
<span class="line-modified"> 2921   match(Set dst (LoadVector mem));</span>
<span class="line-removed"> 2922   ins_cost(125);</span>
<span class="line-removed"> 2923   format %{ &quot;movdqu  $dst,$mem\t! load vector (16 bytes)&quot; %}</span>
 2924   ins_encode %{
<a name="52" id="anc52"></a><span class="line-modified"> 2925     __ movdqu($dst$$XMMRegister, $mem$$Address);</span>






 2926   %}
 2927   ins_pipe( pipe_slow );
 2928 %}
 2929 
<a name="53" id="anc53"></a><span class="line-modified"> 2930 // Load vectors (16 bytes long)</span>
<span class="line-modified"> 2931 instruct MoveVecX2Leg(legVecX dst, vecX src) %{</span>
<span class="line-modified"> 2932   match(Set dst src);</span>
<span class="line-modified"> 2933   format %{ &quot;movdqu $dst,$src\t! load vector (16 bytes)&quot; %}</span>

 2934   ins_encode %{
<a name="54" id="anc54"></a><span class="line-modified"> 2935     if (UseAVX &gt; 2 &amp;&amp; !VM_Version::supports_avx512vl()) {</span>
<span class="line-modified"> 2936       int vector_len = 2;</span>
<span class="line-modified"> 2937       __ evmovdquq($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed"> 2938     } else {</span>
<span class="line-removed"> 2939       __ movdqu($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 2940     }</span>
 2941   %}
<a name="55" id="anc55"></a><span class="line-modified"> 2942   ins_pipe( fpu_reg_reg );</span>
 2943 %}
 2944 
<a name="56" id="anc56"></a><span class="line-modified"> 2945 // Load vectors (16 bytes long)</span>
<span class="line-modified"> 2946 instruct MoveLeg2VecX(vecX dst, legVecX src) %{</span>
<span class="line-modified"> 2947   match(Set dst src);</span>
<span class="line-modified"> 2948   format %{ &quot;movdqu $dst,$src\t! load vector (16 bytes)&quot; %}</span>

 2949   ins_encode %{
<a name="57" id="anc57"></a><span class="line-modified"> 2950     if (UseAVX &gt; 2 &amp;&amp; !VM_Version::supports_avx512vl()) {</span>
<span class="line-modified"> 2951       int vector_len = 2;</span>
<span class="line-modified"> 2952       __ evmovdquq($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>

 2953     } else {
<a name="58" id="anc58"></a><span class="line-modified"> 2954       __ movdqu($dst$$XMMRegister, $src$$XMMRegister);</span>












 2955     }
 2956   %}
<a name="59" id="anc59"></a><span class="line-modified"> 2957   ins_pipe( fpu_reg_reg );</span>
 2958 %}
 2959 
<a name="60" id="anc60"></a><span class="line-modified"> 2960 // Load vectors (32 bytes long)</span>
<span class="line-modified"> 2961 instruct loadV32(vecY dst, memory mem) %{</span>
<span class="line-modified"> 2962   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 32);</span>
<span class="line-modified"> 2963   match(Set dst (LoadVector mem));</span>
<span class="line-removed"> 2964   ins_cost(125);</span>
<span class="line-removed"> 2965   format %{ &quot;vmovdqu $dst,$mem\t! load vector (32 bytes)&quot; %}</span>
 2966   ins_encode %{
<a name="61" id="anc61"></a><span class="line-modified"> 2967     __ vmovdqu($dst$$XMMRegister, $mem$$Address);</span>



 2968   %}
 2969   ins_pipe( pipe_slow );
 2970 %}
 2971 
<a name="62" id="anc62"></a><span class="line-modified"> 2972 // Load vectors (32 bytes long)</span>
<span class="line-modified"> 2973 instruct MoveVecY2Leg(legVecY dst, vecY src) %{</span>
<span class="line-modified"> 2974   match(Set dst src);</span>
<span class="line-modified"> 2975   format %{ &quot;vmovdqu $dst,$src\t! load vector (32 bytes)&quot; %}</span>
 2976   ins_encode %{
<a name="63" id="anc63"></a><span class="line-modified"> 2977     if (UseAVX &gt; 2 &amp;&amp; !VM_Version::supports_avx512vl()) {</span>
<span class="line-modified"> 2978       int vector_len = 2;</span>
<span class="line-modified"> 2979       __ evmovdquq($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
 2980     } else {
<a name="64" id="anc64"></a><span class="line-modified"> 2981       __ vmovdqu($dst$$XMMRegister, $src$$XMMRegister);</span>


 2982     }
 2983   %}
 2984   ins_pipe( fpu_reg_reg );
 2985 %}
 2986 
<a name="65" id="anc65"></a><span class="line-modified"> 2987 // Load vectors (32 bytes long)</span>
<span class="line-modified"> 2988 instruct MoveLeg2VecY(vecY dst, legVecY src) %{</span>
<span class="line-modified"> 2989   match(Set dst src);</span>
<span class="line-modified"> 2990   format %{ &quot;vmovdqu $dst,$src\t! load vector (32 bytes)&quot; %}</span>



 2991   ins_encode %{
<a name="66" id="anc66"></a><span class="line-modified"> 2992     if (UseAVX &gt; 2 &amp;&amp; !VM_Version::supports_avx512vl()) {</span>
<span class="line-modified"> 2993       int vector_len = 2;</span>
<span class="line-modified"> 2994       __ evmovdquq($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>


 2995     } else {
<a name="67" id="anc67"></a><span class="line-modified"> 2996       __ vmovdqu($dst$$XMMRegister, $src$$XMMRegister);</span>








 2997     }
 2998   %}
<a name="68" id="anc68"></a><span class="line-modified"> 2999   ins_pipe( fpu_reg_reg );</span>
 3000 %}
 3001 
<a name="69" id="anc69"></a><span class="line-modified"> 3002 // Load vectors (64 bytes long)</span>
<span class="line-modified"> 3003 instruct loadV64_dword(vecZ dst, memory mem) %{</span>
<span class="line-modified"> 3004   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 64 &amp;&amp; n-&gt;as_LoadVector()-&gt;element_size() &lt;= 4);</span>
<span class="line-modified"> 3005   match(Set dst (LoadVector mem));</span>
<span class="line-removed"> 3006   ins_cost(125);</span>
<span class="line-removed"> 3007   format %{ &quot;vmovdqul $dst k0,$mem\t! load vector (64 bytes)&quot; %}</span>
 3008   ins_encode %{
<a name="70" id="anc70"></a><span class="line-modified"> 3009     int vector_len = 2;</span>
<span class="line-modified"> 3010     __ evmovdqul($dst$$XMMRegister, $mem$$Address, vector_len);</span>



 3011   %}
 3012   ins_pipe( pipe_slow );
 3013 %}
 3014 
<a name="71" id="anc71"></a><span class="line-modified"> 3015 // Load vectors (64 bytes long)</span>
<span class="line-modified"> 3016 instruct loadV64_qword(vecZ dst, memory mem) %{</span>
<span class="line-modified"> 3017   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 64 &amp;&amp; n-&gt;as_LoadVector()-&gt;element_size() &gt; 4);</span>
<span class="line-modified"> 3018   match(Set dst (LoadVector mem));</span>
<span class="line-modified"> 3019   ins_cost(125);</span>
<span class="line-modified"> 3020   format %{ &quot;vmovdquq $dst k0,$mem\t! load vector (64 bytes)&quot; %}</span>
 3021   ins_encode %{
<a name="72" id="anc72"></a><span class="line-modified"> 3022     int vector_len = 2;</span>
<span class="line-modified"> 3023     __ evmovdquq($dst$$XMMRegister, $mem$$Address, vector_len);</span>













 3024   %}
 3025   ins_pipe( pipe_slow );
 3026 %}
 3027 
<a name="73" id="anc73"></a><span class="line-modified"> 3028 instruct MoveVecZ2Leg(legVecZ dst, vecZ  src) %{</span>
<span class="line-modified"> 3029   match(Set dst src);</span>
<span class="line-modified"> 3030   format %{ &quot;vmovdquq $dst k0,$src\t! Move vector (64 bytes)&quot; %}</span>

 3031   ins_encode %{
<a name="74" id="anc74"></a><span class="line-modified"> 3032     int vector_len = 2;</span>
<span class="line-modified"> 3033     __ evmovdquq($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>


 3034   %}
<a name="75" id="anc75"></a><span class="line-modified"> 3035   ins_pipe( fpu_reg_reg );</span>
 3036 %}
 3037 
<a name="76" id="anc76"></a><span class="line-modified"> 3038 instruct MoveLeg2VecZ(vecZ dst, legVecZ  src) %{</span>
<span class="line-modified"> 3039   match(Set dst src);</span>
<span class="line-modified"> 3040   format %{ &quot;vmovdquq $dst k0,$src\t! Move vector (64 bytes)&quot; %}</span>


 3041   ins_encode %{
<a name="77" id="anc77"></a><span class="line-modified"> 3042     int vector_len = 2;</span>
<span class="line-modified"> 3043     __ evmovdquq($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>

















 3044   %}
 3045   ins_pipe( fpu_reg_reg );
 3046 %}
 3047 
<a name="78" id="anc78"></a><span class="line-modified"> 3048 // Store vectors</span>
<span class="line-modified"> 3049 instruct storeV4(memory mem, vecS src) %{</span>
<span class="line-modified"> 3050   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);</span>
<span class="line-modified"> 3051   match(Set mem (StoreVector mem src));</span>
<span class="line-removed"> 3052   ins_cost(145);</span>
<span class="line-removed"> 3053   format %{ &quot;movd    $mem,$src\t! store vector (4 bytes)&quot; %}</span>
 3054   ins_encode %{
<a name="79" id="anc79"></a><span class="line-modified"> 3055     __ movdl($mem$$Address, $src$$XMMRegister);</span>



 3056   %}
 3057   ins_pipe( pipe_slow );
 3058 %}
 3059 
<a name="80" id="anc80"></a><span class="line-modified"> 3060 instruct storeV8(memory mem, vecD src) %{</span>
<span class="line-modified"> 3061   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);</span>
<span class="line-modified"> 3062   match(Set mem (StoreVector mem src));</span>
<span class="line-removed"> 3063   ins_cost(145);</span>
<span class="line-removed"> 3064   format %{ &quot;movq    $mem,$src\t! store vector (8 bytes)&quot; %}</span>
 3065   ins_encode %{
<a name="81" id="anc81"></a><span class="line-modified"> 3066     __ movq($mem$$Address, $src$$XMMRegister);</span>






 3067   %}
<a name="82" id="anc82"></a><span class="line-modified"> 3068   ins_pipe( pipe_slow );</span>
 3069 %}
 3070 
<a name="83" id="anc83"></a><span class="line-modified"> 3071 instruct storeV16(memory mem, vecX src) %{</span>
<span class="line-modified"> 3072   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);</span>
<span class="line-modified"> 3073   match(Set mem (StoreVector mem src));</span>
<span class="line-modified"> 3074   ins_cost(145);</span>
<span class="line-modified"> 3075   format %{ &quot;movdqu  $mem,$src\t! store vector (16 bytes)&quot; %}</span>
 3076   ins_encode %{
<a name="84" id="anc84"></a><span class="line-modified"> 3077     __ movdqu($mem$$Address, $src$$XMMRegister);</span>











 3078   %}
 3079   ins_pipe( pipe_slow );
 3080 %}
 3081 
<a name="85" id="anc85"></a><span class="line-modified"> 3082 instruct storeV32(memory mem, vecY src) %{</span>
<span class="line-modified"> 3083   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 32);</span>
<span class="line-modified"> 3084   match(Set mem (StoreVector mem src));</span>
<span class="line-modified"> 3085   ins_cost(145);</span>
<span class="line-modified"> 3086   format %{ &quot;vmovdqu $mem,$src\t! store vector (32 bytes)&quot; %}</span>
<span class="line-modified"> 3087   ins_encode %{</span>
<span class="line-modified"> 3088     __ vmovdqu($mem$$Address, $src$$XMMRegister);</span>









 3089   %}
 3090   ins_pipe( pipe_slow );
 3091 %}
 3092 
<a name="86" id="anc86"></a><span class="line-modified"> 3093 instruct storeV64_dword(memory mem, vecZ src) %{</span>
<span class="line-modified"> 3094   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 64 &amp;&amp; n-&gt;as_StoreVector()-&gt;element_size() &lt;= 4);</span>
<span class="line-modified"> 3095   match(Set mem (StoreVector mem src));</span>
<span class="line-modified"> 3096   ins_cost(145);</span>
<span class="line-modified"> 3097   format %{ &quot;vmovdqul $mem k0,$src\t! store vector (64 bytes)&quot; %}</span>
<span class="line-modified"> 3098   ins_encode %{</span>
<span class="line-modified"> 3099     int vector_len = 2;</span>
<span class="line-modified"> 3100     __ evmovdqul($mem$$Address, $src$$XMMRegister, vector_len);</span>












 3101   %}
 3102   ins_pipe( pipe_slow );
 3103 %}
 3104 
<a name="87" id="anc87"></a><span class="line-modified"> 3105 instruct storeV64_qword(memory mem, vecZ src) %{</span>
<span class="line-modified"> 3106   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 64 &amp;&amp; n-&gt;as_StoreVector()-&gt;element_size() &gt; 4);</span>
<span class="line-modified"> 3107   match(Set mem (StoreVector mem src));</span>
<span class="line-modified"> 3108   ins_cost(145);</span>
<span class="line-removed"> 3109   format %{ &quot;vmovdquq $mem k0,$src\t! store vector (64 bytes)&quot; %}</span>
 3110   ins_encode %{
<a name="88" id="anc88"></a><span class="line-modified"> 3111     int vector_len = 2;</span>
<span class="line-modified"> 3112     __ evmovdquq($mem$$Address, $src$$XMMRegister, vector_len);</span>





 3113   %}
<a name="89" id="anc89"></a><span class="line-modified"> 3114   ins_pipe( pipe_slow );</span>
 3115 %}
 3116 
<a name="90" id="anc90"></a><span class="line-modified"> 3117 // ====================LEGACY REPLICATE=======================================</span>
 3118 
<a name="91" id="anc91"></a><span class="line-modified"> 3119 instruct Repl4B_mem(vecS dst, memory mem) %{</span>
<span class="line-modified"> 3120   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 0 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3121   match(Set dst (ReplicateB (LoadB mem)));</span>
<span class="line-modified"> 3122   format %{ &quot;punpcklbw $dst,$mem\n\t&quot;</span>
<span class="line-modified"> 3123             &quot;pshuflw $dst,$dst,0x00\t! replicate4B&quot; %}</span>
<span class="line-modified"> 3124   ins_encode %{</span>
<span class="line-modified"> 3125     __ punpcklbw($dst$$XMMRegister, $mem$$Address);</span>
<span class="line-modified"> 3126     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>











 3127   %}
 3128   ins_pipe( pipe_slow );
 3129 %}
<a name="92" id="anc92"></a><span class="line-modified"> 3130 </span>
<span class="line-modified"> 3131 instruct Repl8B_mem(vecD dst, memory mem) %{</span>
<span class="line-modified"> 3132   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 0 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3133   match(Set dst (ReplicateB (LoadB mem)));</span>
<span class="line-modified"> 3134   format %{ &quot;punpcklbw $dst,$mem\n\t&quot;</span>
<span class="line-modified"> 3135             &quot;pshuflw $dst,$dst,0x00\t! replicate8B&quot; %}</span>
<span class="line-modified"> 3136   ins_encode %{</span>
<span class="line-modified"> 3137     __ punpcklbw($dst$$XMMRegister, $mem$$Address);</span>
<span class="line-modified"> 3138     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>


















 3139   %}
 3140   ins_pipe( pipe_slow );
 3141 %}
 3142 
<a name="93" id="anc93"></a><span class="line-modified"> 3143 instruct Repl16B(vecX dst, rRegI src) %{</span>
<span class="line-modified"> 3144   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3145   match(Set dst (ReplicateB src));</span>
<span class="line-modified"> 3146   format %{ &quot;movd    $dst,$src\n\t&quot;</span>
<span class="line-modified"> 3147             &quot;punpcklbw $dst,$dst\n\t&quot;</span>
<span class="line-modified"> 3148             &quot;pshuflw $dst,$dst,0x00\n\t&quot;</span>
<span class="line-modified"> 3149             &quot;punpcklqdq $dst,$dst\t! replicate16B&quot; %}</span>
<span class="line-modified"> 3150   ins_encode %{</span>
<span class="line-modified"> 3151     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-modified"> 3152     __ punpcklbw($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-modified"> 3153     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-modified"> 3154     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>








 3155   %}
 3156   ins_pipe( pipe_slow );
 3157 %}
<a name="94" id="anc94"></a>
 3158 
<a name="95" id="anc95"></a><span class="line-modified"> 3159 instruct Repl16B_mem(vecX dst, memory mem) %{</span>
<span class="line-modified"> 3160   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 0 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3161   match(Set dst (ReplicateB (LoadB mem)));</span>
<span class="line-modified"> 3162   format %{ &quot;punpcklbw $dst,$mem\n\t&quot;</span>
<span class="line-modified"> 3163             &quot;pshuflw $dst,$dst,0x00\n\t&quot;</span>
<span class="line-modified"> 3164             &quot;punpcklqdq $dst,$dst\t! replicate16B&quot; %}</span>
<span class="line-modified"> 3165   ins_encode %{</span>
<span class="line-modified"> 3166     __ punpcklbw($dst$$XMMRegister, $mem$$Address);</span>
<span class="line-modified"> 3167     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-modified"> 3168     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>







 3169   %}
 3170   ins_pipe( pipe_slow );
 3171 %}
 3172 
<a name="96" id="anc96"></a><span class="line-modified"> 3173 instruct Repl32B(vecY dst, rRegI src) %{</span>
<span class="line-modified"> 3174   predicate(n-&gt;as_Vector()-&gt;length() == 32 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3175   match(Set dst (ReplicateB src));</span>
<span class="line-modified"> 3176   format %{ &quot;movd    $dst,$src\n\t&quot;</span>
<span class="line-modified"> 3177             &quot;punpcklbw $dst,$dst\n\t&quot;</span>
<span class="line-modified"> 3178             &quot;pshuflw $dst,$dst,0x00\n\t&quot;</span>
<span class="line-modified"> 3179             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-modified"> 3180             &quot;vinserti128_high $dst,$dst\t! replicate32B&quot; %}</span>
<span class="line-modified"> 3181   ins_encode %{</span>
<span class="line-modified"> 3182     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-modified"> 3183     __ punpcklbw($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-modified"> 3184     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-modified"> 3185     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-modified"> 3186     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>






 3187   %}
 3188   ins_pipe( pipe_slow );
 3189 %}
 3190 
<a name="97" id="anc97"></a><span class="line-modified"> 3191 instruct Repl32B_mem(vecY dst, memory mem) %{</span>
<span class="line-modified"> 3192   predicate(n-&gt;as_Vector()-&gt;length() == 32 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3193   match(Set dst (ReplicateB (LoadB mem)));</span>
<span class="line-removed"> 3194   format %{ &quot;punpcklbw $dst,$mem\n\t&quot;</span>
<span class="line-removed"> 3195             &quot;pshuflw $dst,$dst,0x00\n\t&quot;</span>
<span class="line-removed"> 3196             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3197             &quot;vinserti128_high $dst,$dst\t! replicate32B&quot; %}</span>
 3198   ins_encode %{
<a name="98" id="anc98"></a><span class="line-modified"> 3199     __ punpcklbw($dst$$XMMRegister, $mem$$Address);</span>
<span class="line-modified"> 3200     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-modified"> 3201     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-modified"> 3202     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>



 3203   %}
<a name="99" id="anc99"></a><span class="line-modified"> 3204   ins_pipe( pipe_slow );</span>
 3205 %}
 3206 
<a name="100" id="anc100"></a><span class="line-modified"> 3207 instruct Repl64B(legVecZ dst, rRegI src) %{</span>
<span class="line-removed"> 3208   predicate(n-&gt;as_Vector()-&gt;length() == 64 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 3209   match(Set dst (ReplicateB src));</span>
<span class="line-removed"> 3210   format %{ &quot;movd    $dst,$src\n\t&quot;</span>
<span class="line-removed"> 3211             &quot;punpcklbw $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3212             &quot;pshuflw $dst,$dst,0x00\n\t&quot;</span>
<span class="line-removed"> 3213             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3214             &quot;vinserti128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3215             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate64B&quot; %}</span>
<span class="line-removed"> 3216   ins_encode %{</span>
<span class="line-removed"> 3217     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 3218     __ punpcklbw($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3219     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-removed"> 3220     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3221     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3222     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3223   %}</span>
<span class="line-removed"> 3224   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3225 %}</span>
 3226 
<a name="101" id="anc101"></a><span class="line-modified"> 3227 instruct Repl64B_mem(legVecZ dst, memory mem) %{</span>
<span class="line-modified"> 3228   predicate(n-&gt;as_Vector()-&gt;length() == 64 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3229   match(Set dst (ReplicateB (LoadB mem)));</span>
<span class="line-modified"> 3230   format %{ &quot;punpcklbw $dst,$mem\n\t&quot;</span>
<span class="line-modified"> 3231             &quot;pshuflw $dst,$dst,0x00\n\t&quot;</span>
<span class="line-modified"> 3232             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-modified"> 3233             &quot;vinserti128_high $dst,$dst\t&quot;</span>
<span class="line-modified"> 3234             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate64B&quot; %}</span>
<span class="line-modified"> 3235   ins_encode %{</span>
<span class="line-modified"> 3236     __ punpcklbw($dst$$XMMRegister, $mem$$Address);</span>
<span class="line-modified"> 3237     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-modified"> 3238     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-modified"> 3239     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-modified"> 3240     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>

 3241   %}
 3242   ins_pipe( pipe_slow );
 3243 %}
 3244 
<a name="102" id="anc102"></a><span class="line-modified"> 3245 instruct Repl16B_imm(vecX dst, immI con) %{</span>
<span class="line-modified"> 3246   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3247   match(Set dst (ReplicateB con));</span>
<span class="line-modified"> 3248   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-modified"> 3249             &quot;punpcklqdq $dst,$dst\t! replicate16B($con)&quot; %}</span>
<span class="line-modified"> 3250   ins_encode %{</span>
<span class="line-modified"> 3251     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 1)));</span>
<span class="line-modified"> 3252     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>








 3253   %}
 3254   ins_pipe( pipe_slow );
 3255 %}
 3256 
<a name="103" id="anc103"></a><span class="line-modified"> 3257 instruct Repl32B_imm(vecY dst, immI con) %{</span>
<span class="line-modified"> 3258   predicate(n-&gt;as_Vector()-&gt;length() == 32 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3259   match(Set dst (ReplicateB con));</span>
<span class="line-removed"> 3260   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 3261             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3262             &quot;vinserti128_high $dst,$dst\t! lreplicate32B($con)&quot; %}</span>
 3263   ins_encode %{
<a name="104" id="anc104"></a><span class="line-modified"> 3264     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 1)));</span>
<span class="line-modified"> 3265     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-modified"> 3266     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>




 3267   %}
<a name="105" id="anc105"></a><span class="line-modified"> 3268   ins_pipe( pipe_slow );</span>
 3269 %}
 3270 
<a name="106" id="anc106"></a><span class="line-modified"> 3271 instruct Repl64B_imm(legVecZ dst, immI con) %{</span>
<span class="line-removed"> 3272   predicate(n-&gt;as_Vector()-&gt;length() == 64 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 3273   match(Set dst (ReplicateB con));</span>
<span class="line-removed"> 3274   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 3275             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3276             &quot;vinserti128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3277             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate64B($con)&quot; %}</span>
<span class="line-removed"> 3278   ins_encode %{</span>
<span class="line-removed"> 3279     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 1)));</span>
<span class="line-removed"> 3280     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3281     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3282     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3283   %}</span>
<span class="line-removed"> 3284   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3285 %}</span>
 3286 
<a name="107" id="anc107"></a><span class="line-modified"> 3287 instruct Repl4S(vecD dst, rRegI src) %{</span>
<span class="line-modified"> 3288   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3289   match(Set dst (ReplicateS src));</span>
<span class="line-modified"> 3290   format %{ &quot;movd    $dst,$src\n\t&quot;</span>
<span class="line-modified"> 3291             &quot;pshuflw $dst,$dst,0x00\t! replicate4S&quot; %}</span>
<span class="line-modified"> 3292   ins_encode %{</span>
<span class="line-modified"> 3293     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-modified"> 3294     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>








 3295   %}
 3296   ins_pipe( pipe_slow );
 3297 %}
 3298 
<a name="108" id="anc108"></a><span class="line-modified"> 3299 instruct Repl4S_mem(vecD dst, memory mem) %{</span>
<span class="line-modified"> 3300   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 0 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3301   match(Set dst (ReplicateS (LoadS mem)));</span>
<span class="line-modified"> 3302   format %{ &quot;pshuflw $dst,$mem,0x00\t! replicate4S&quot; %}</span>
<span class="line-modified"> 3303   ins_encode %{</span>
<span class="line-modified"> 3304     __ pshuflw($dst$$XMMRegister, $mem$$Address, 0x00);</span>










 3305   %}
 3306   ins_pipe( pipe_slow );
 3307 %}
 3308 
<a name="109" id="anc109"></a><span class="line-modified"> 3309 instruct Repl8S(vecX dst, rRegI src) %{</span>
<span class="line-modified"> 3310   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3311   match(Set dst (ReplicateS src));</span>
<span class="line-removed"> 3312   format %{ &quot;movd    $dst,$src\n\t&quot;</span>
<span class="line-removed"> 3313             &quot;pshuflw $dst,$dst,0x00\n\t&quot;</span>
<span class="line-removed"> 3314             &quot;punpcklqdq $dst,$dst\t! replicate8S&quot; %}</span>
 3315   ins_encode %{
<a name="110" id="anc110"></a><span class="line-modified"> 3316     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-modified"> 3317     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-modified"> 3318     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>




 3319   %}
<a name="111" id="anc111"></a><span class="line-modified"> 3320   ins_pipe( pipe_slow );</span>
 3321 %}
 3322 
<a name="112" id="anc112"></a><span class="line-modified"> 3323 instruct Repl8S_mem(vecX dst, memory mem) %{</span>
<span class="line-modified"> 3324   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 0 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3325   match(Set dst (ReplicateS (LoadS mem)));</span>
<span class="line-modified"> 3326   format %{ &quot;pshuflw $dst,$mem,0x00\n\t&quot;</span>
<span class="line-modified"> 3327             &quot;punpcklqdq $dst,$dst\t! replicate8S&quot; %}</span>
<span class="line-modified"> 3328   ins_encode %{</span>
<span class="line-modified"> 3329     __ pshuflw($dst$$XMMRegister, $mem$$Address, 0x00);</span>
<span class="line-modified"> 3330     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>























 3331   %}
 3332   ins_pipe( pipe_slow );
 3333 %}
 3334 
<a name="113" id="anc113"></a><span class="line-modified"> 3335 instruct Repl8S_imm(vecX dst, immI con) %{</span>
<span class="line-modified"> 3336   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3337   match(Set dst (ReplicateS con));</span>
<span class="line-modified"> 3338   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-modified"> 3339             &quot;punpcklqdq $dst,$dst\t! replicate8S($con)&quot; %}</span>
<span class="line-modified"> 3340   ins_encode %{</span>
<span class="line-modified"> 3341     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 2)));</span>
<span class="line-modified"> 3342     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>























 3343   %}
 3344   ins_pipe( pipe_slow );
 3345 %}
 3346 
<a name="114" id="anc114"></a><span class="line-modified"> 3347 instruct Repl16S(vecY dst, rRegI src) %{</span>
<span class="line-modified"> 3348   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3349   match(Set dst (ReplicateS src));</span>
<span class="line-modified"> 3350   format %{ &quot;movd    $dst,$src\n\t&quot;</span>
<span class="line-modified"> 3351             &quot;pshuflw $dst,$dst,0x00\n\t&quot;</span>
<span class="line-modified"> 3352             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-modified"> 3353             &quot;vinserti128_high $dst,$dst\t! replicate16S&quot; %}</span>
<span class="line-modified"> 3354   ins_encode %{</span>
<span class="line-modified"> 3355     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-modified"> 3356     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-modified"> 3357     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-modified"> 3358     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
















 3359   %}
 3360   ins_pipe( pipe_slow );
 3361 %}
 3362 
<a name="115" id="anc115"></a><span class="line-modified"> 3363 instruct Repl16S_mem(vecY dst, memory mem) %{</span>
<span class="line-modified"> 3364   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-modified"> 3365   match(Set dst (ReplicateS (LoadS mem)));</span>
<span class="line-modified"> 3366   format %{ &quot;pshuflw $dst,$mem,0x00\n\t&quot;</span>
<span class="line-modified"> 3367             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3368             &quot;vinserti128_high $dst,$dst\t! replicate16S&quot; %}</span>
<span class="line-removed"> 3369   ins_encode %{</span>
<span class="line-removed"> 3370     __ pshuflw($dst$$XMMRegister, $mem$$Address, 0x00);</span>
<span class="line-removed"> 3371     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3372     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3373   %}</span>
<span class="line-removed"> 3374   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3375 %}</span>
<span class="line-removed"> 3376 </span>
<span class="line-removed"> 3377 instruct Repl16S_imm(vecY dst, immI con) %{</span>
<span class="line-removed"> 3378   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 3379   match(Set dst (ReplicateS con));</span>
<span class="line-removed"> 3380   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 3381             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3382             &quot;vinserti128_high $dst,$dst\t! replicate16S($con)&quot; %}</span>
<span class="line-removed"> 3383   ins_encode %{</span>
<span class="line-removed"> 3384     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 2)));</span>
<span class="line-removed"> 3385     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3386     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3387   %}</span>
<span class="line-removed"> 3388   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3389 %}</span>
<span class="line-removed"> 3390 </span>
<span class="line-removed"> 3391 instruct Repl32S(legVecZ dst, rRegI src) %{</span>
<span class="line-removed"> 3392   predicate(n-&gt;as_Vector()-&gt;length() == 32 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 3393   match(Set dst (ReplicateS src));</span>
<span class="line-removed"> 3394   format %{ &quot;movd    $dst,$src\n\t&quot;</span>
<span class="line-removed"> 3395             &quot;pshuflw $dst,$dst,0x00\n\t&quot;</span>
<span class="line-removed"> 3396             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3397             &quot;vinserti128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3398             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate32S&quot; %}</span>
<span class="line-removed"> 3399   ins_encode %{</span>
<span class="line-removed"> 3400     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 3401     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-removed"> 3402     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3403     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3404     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3405   %}</span>
<span class="line-removed"> 3406   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3407 %}</span>
<span class="line-removed"> 3408 </span>
<span class="line-removed"> 3409 instruct Repl32S_mem(legVecZ dst, memory mem) %{</span>
<span class="line-removed"> 3410   predicate(n-&gt;as_Vector()-&gt;length() == 32 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 3411   match(Set dst (ReplicateS (LoadS mem)));</span>
<span class="line-removed"> 3412   format %{ &quot;pshuflw $dst,$mem,0x00\n\t&quot;</span>
<span class="line-removed"> 3413             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3414             &quot;vinserti128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3415             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate32S&quot; %}</span>
<span class="line-removed"> 3416   ins_encode %{</span>
<span class="line-removed"> 3417     __ pshuflw($dst$$XMMRegister, $mem$$Address, 0x00);</span>
<span class="line-removed"> 3418     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3419     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3420     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3421   %}</span>
<span class="line-removed"> 3422   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3423 %}</span>
<span class="line-removed"> 3424 </span>
<span class="line-removed"> 3425 instruct Repl32S_imm(legVecZ dst, immI con) %{</span>
<span class="line-removed"> 3426   predicate(n-&gt;as_Vector()-&gt;length() == 32 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 3427   match(Set dst (ReplicateS con));</span>
<span class="line-removed"> 3428   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 3429             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3430             &quot;vinserti128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3431             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate32S($con)&quot; %}</span>
<span class="line-removed"> 3432   ins_encode %{</span>
<span class="line-removed"> 3433     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 2)));</span>
<span class="line-removed"> 3434     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3435     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3436     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3437   %}</span>
<span class="line-removed"> 3438   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3439 %}</span>
<span class="line-removed"> 3440 </span>
<span class="line-removed"> 3441 instruct Repl4I(vecX dst, rRegI src) %{</span>
<span class="line-removed"> 3442   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3443   match(Set dst (ReplicateI src));</span>
<span class="line-removed"> 3444   format %{ &quot;movd    $dst,$src\n\t&quot;</span>
<span class="line-removed"> 3445             &quot;pshufd  $dst,$dst,0x00\t! replicate4I&quot; %}</span>
<span class="line-removed"> 3446   ins_encode %{</span>
<span class="line-removed"> 3447     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 3448     __ pshufd($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-removed"> 3449   %}</span>
<span class="line-removed"> 3450   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3451 %}</span>
<span class="line-removed"> 3452 </span>
<span class="line-removed"> 3453 instruct Repl4I_mem(vecX dst, memory mem) %{</span>
<span class="line-removed"> 3454   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 0 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3455   match(Set dst (ReplicateI (LoadI mem)));</span>
<span class="line-removed"> 3456   format %{ &quot;pshufd  $dst,$mem,0x00\t! replicate4I&quot; %}</span>
<span class="line-removed"> 3457   ins_encode %{</span>
<span class="line-removed"> 3458     __ pshufd($dst$$XMMRegister, $mem$$Address, 0x00);</span>
<span class="line-removed"> 3459   %}</span>
<span class="line-removed"> 3460   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3461 %}</span>
<span class="line-removed"> 3462 </span>
<span class="line-removed"> 3463 instruct Repl8I(vecY dst, rRegI src) %{</span>
<span class="line-removed"> 3464   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3465   match(Set dst (ReplicateI src));</span>
<span class="line-removed"> 3466   format %{ &quot;movd    $dst,$src\n\t&quot;</span>
<span class="line-removed"> 3467             &quot;pshufd  $dst,$dst,0x00\n\t&quot;</span>
<span class="line-removed"> 3468             &quot;vinserti128_high $dst,$dst\t! replicate8I&quot; %}</span>
<span class="line-removed"> 3469   ins_encode %{</span>
<span class="line-removed"> 3470     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 3471     __ pshufd($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-removed"> 3472     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3473   %}</span>
<span class="line-removed"> 3474   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3475 %}</span>
<span class="line-removed"> 3476 </span>
<span class="line-removed"> 3477 instruct Repl8I_mem(vecY dst, memory mem) %{</span>
<span class="line-removed"> 3478   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3479   match(Set dst (ReplicateI (LoadI mem)));</span>
<span class="line-removed"> 3480   format %{ &quot;pshufd  $dst,$mem,0x00\n\t&quot;</span>
<span class="line-removed"> 3481             &quot;vinserti128_high $dst,$dst\t! replicate8I&quot; %}</span>
<span class="line-removed"> 3482   ins_encode %{</span>
<span class="line-removed"> 3483     __ pshufd($dst$$XMMRegister, $mem$$Address, 0x00);</span>
<span class="line-removed"> 3484     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3485   %}</span>
<span class="line-removed"> 3486   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3487 %}</span>
<span class="line-removed"> 3488 </span>
<span class="line-removed"> 3489 instruct Repl16I(legVecZ dst, rRegI src) %{</span>
<span class="line-removed"> 3490   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3491   match(Set dst (ReplicateI src));</span>
<span class="line-removed"> 3492   format %{ &quot;movd    $dst,$src\n\t&quot;</span>
<span class="line-removed"> 3493             &quot;pshufd  $dst,$dst,0x00\n\t&quot;</span>
<span class="line-removed"> 3494             &quot;vinserti128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3495             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate16I&quot; %}</span>
<span class="line-removed"> 3496   ins_encode %{</span>
<span class="line-removed"> 3497     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 3498     __ pshufd($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-removed"> 3499     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3500     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3501   %}</span>
<span class="line-removed"> 3502   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3503 %}</span>
<span class="line-removed"> 3504 </span>
<span class="line-removed"> 3505 instruct Repl16I_mem(legVecZ dst, memory mem) %{</span>
<span class="line-removed"> 3506   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3507   match(Set dst (ReplicateI (LoadI mem)));</span>
<span class="line-removed"> 3508   format %{ &quot;pshufd  $dst,$mem,0x00\n\t&quot;</span>
<span class="line-removed"> 3509             &quot;vinserti128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3510             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate16I&quot; %}</span>
<span class="line-removed"> 3511   ins_encode %{</span>
<span class="line-removed"> 3512     __ pshufd($dst$$XMMRegister, $mem$$Address, 0x00);</span>
<span class="line-removed"> 3513     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3514     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3515   %}</span>
<span class="line-removed"> 3516   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3517 %}</span>
<span class="line-removed"> 3518 </span>
<span class="line-removed"> 3519 instruct Repl4I_imm(vecX dst, immI con) %{</span>
<span class="line-removed"> 3520   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3521   match(Set dst (ReplicateI con));</span>
<span class="line-removed"> 3522   format %{ &quot;movq    $dst,[$constantaddress]\t! replicate4I($con)\n\t&quot;</span>
<span class="line-removed"> 3523             &quot;punpcklqdq $dst,$dst&quot; %}</span>
<span class="line-removed"> 3524   ins_encode %{</span>
<span class="line-removed"> 3525     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 4)));</span>
<span class="line-removed"> 3526     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3527   %}</span>
<span class="line-removed"> 3528   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3529 %}</span>
<span class="line-removed"> 3530 </span>
<span class="line-removed"> 3531 instruct Repl8I_imm(vecY dst, immI con) %{</span>
<span class="line-removed"> 3532   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3533   match(Set dst (ReplicateI con));</span>
<span class="line-removed"> 3534   format %{ &quot;movq    $dst,[$constantaddress]\t! replicate8I($con)\n\t&quot;</span>
<span class="line-removed"> 3535             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3536             &quot;vinserti128_high $dst,$dst&quot; %}</span>
<span class="line-removed"> 3537   ins_encode %{</span>
<span class="line-removed"> 3538     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 4)));</span>
<span class="line-removed"> 3539     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3540     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3541   %}</span>
<span class="line-removed"> 3542   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3543 %}</span>
<span class="line-removed"> 3544 </span>
<span class="line-removed"> 3545 instruct Repl16I_imm(legVecZ dst, immI con) %{</span>
<span class="line-removed"> 3546   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3547   match(Set dst (ReplicateI con));</span>
<span class="line-removed"> 3548   format %{ &quot;movq    $dst,[$constantaddress]\t&quot;</span>
<span class="line-removed"> 3549             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3550             &quot;vinserti128_high $dst,$dst&quot;</span>
<span class="line-removed"> 3551             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate16I($con)&quot; %}</span>
<span class="line-removed"> 3552   ins_encode %{</span>
<span class="line-removed"> 3553     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 4)));</span>
<span class="line-removed"> 3554     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3555     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3556     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3557   %}</span>
<span class="line-removed"> 3558   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3559 %}</span>
<span class="line-removed"> 3560 </span>
<span class="line-removed"> 3561 // Long could be loaded into xmm register directly from memory.</span>
<span class="line-removed"> 3562 instruct Repl2L_mem(vecX dst, memory mem) %{</span>
<span class="line-removed"> 3563   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; !VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 3564   match(Set dst (ReplicateL (LoadL mem)));</span>
<span class="line-removed"> 3565   format %{ &quot;movq    $dst,$mem\n\t&quot;</span>
<span class="line-removed"> 3566             &quot;punpcklqdq $dst,$dst\t! replicate2L&quot; %}</span>
<span class="line-removed"> 3567   ins_encode %{</span>
<span class="line-removed"> 3568     __ movq($dst$$XMMRegister, $mem$$Address);</span>
<span class="line-removed"> 3569     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3570   %}</span>
<span class="line-removed"> 3571   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3572 %}</span>
<span class="line-removed"> 3573 </span>
<span class="line-removed"> 3574 // Replicate long (8 byte) scalar to be vector</span>
<span class="line-removed"> 3575 #ifdef _LP64</span>
<span class="line-removed"> 3576 instruct Repl4L(vecY dst, rRegL src) %{</span>
<span class="line-removed"> 3577   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3578   match(Set dst (ReplicateL src));</span>
<span class="line-removed"> 3579   format %{ &quot;movdq   $dst,$src\n\t&quot;</span>
<span class="line-removed"> 3580             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3581             &quot;vinserti128_high $dst,$dst\t! replicate4L&quot; %}</span>
<span class="line-removed"> 3582   ins_encode %{</span>
<span class="line-removed"> 3583     __ movdq($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 3584     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3585     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3586   %}</span>
<span class="line-removed"> 3587   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3588 %}</span>
<span class="line-removed"> 3589 </span>
<span class="line-removed"> 3590 instruct Repl8L(legVecZ dst, rRegL src) %{</span>
<span class="line-removed"> 3591   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3592   match(Set dst (ReplicateL src));</span>
<span class="line-removed"> 3593   format %{ &quot;movdq   $dst,$src\n\t&quot;</span>
<span class="line-removed"> 3594             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3595             &quot;vinserti128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3596             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate8L&quot; %}</span>
<span class="line-removed"> 3597   ins_encode %{</span>
<span class="line-removed"> 3598     __ movdq($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 3599     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3600     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3601     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3602   %}</span>
<span class="line-removed"> 3603   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3604 %}</span>
<span class="line-removed"> 3605 #else // _LP64</span>
<span class="line-removed"> 3606 instruct Repl4L(vecY dst, eRegL src, vecY tmp) %{</span>
<span class="line-removed"> 3607   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3608   match(Set dst (ReplicateL src));</span>
<span class="line-removed"> 3609   effect(TEMP dst, USE src, TEMP tmp);</span>
<span class="line-removed"> 3610   format %{ &quot;movdl   $dst,$src.lo\n\t&quot;</span>
<span class="line-removed"> 3611             &quot;movdl   $tmp,$src.hi\n\t&quot;</span>
<span class="line-removed"> 3612             &quot;punpckldq $dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 3613             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3614             &quot;vinserti128_high $dst,$dst\t! replicate4L&quot; %}</span>
<span class="line-removed"> 3615   ins_encode %{</span>
<span class="line-removed"> 3616     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 3617     __ movdl($tmp$$XMMRegister, HIGH_FROM_LOW($src$$Register));</span>
<span class="line-removed"> 3618     __ punpckldq($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 3619     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3620     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3621   %}</span>
<span class="line-removed"> 3622   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3623 %}</span>
<span class="line-removed"> 3624 </span>
<span class="line-removed"> 3625 instruct Repl8L(legVecZ dst, eRegL src, legVecZ tmp) %{</span>
<span class="line-removed"> 3626   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3627   match(Set dst (ReplicateL src));</span>
<span class="line-removed"> 3628   effect(TEMP dst, USE src, TEMP tmp);</span>
<span class="line-removed"> 3629   format %{ &quot;movdl   $dst,$src.lo\n\t&quot;</span>
<span class="line-removed"> 3630             &quot;movdl   $tmp,$src.hi\n\t&quot;</span>
<span class="line-removed"> 3631             &quot;punpckldq $dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 3632             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3633             &quot;vinserti128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3634             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate8L&quot; %}</span>
<span class="line-removed"> 3635   ins_encode %{</span>
<span class="line-removed"> 3636     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 3637     __ movdl($tmp$$XMMRegister, HIGH_FROM_LOW($src$$Register));</span>
<span class="line-removed"> 3638     __ punpckldq($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 3639     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3640     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3641     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3642   %}</span>
<span class="line-removed"> 3643   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3644 %}</span>
<span class="line-removed"> 3645 #endif // _LP64</span>
<span class="line-removed"> 3646 </span>
<span class="line-removed"> 3647 instruct Repl4L_imm(vecY dst, immL con) %{</span>
<span class="line-removed"> 3648   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3649   match(Set dst (ReplicateL con));</span>
<span class="line-removed"> 3650   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 3651             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3652             &quot;vinserti128_high $dst,$dst\t! replicate4L($con)&quot; %}</span>
<span class="line-removed"> 3653   ins_encode %{</span>
<span class="line-removed"> 3654     __ movq($dst$$XMMRegister, $constantaddress($con));</span>
<span class="line-removed"> 3655     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3656     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3657   %}</span>
<span class="line-removed"> 3658   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3659 %}</span>
<span class="line-removed"> 3660 </span>
<span class="line-removed"> 3661 instruct Repl8L_imm(legVecZ dst, immL con) %{</span>
<span class="line-removed"> 3662   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3663   match(Set dst (ReplicateL con));</span>
<span class="line-removed"> 3664   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 3665             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3666             &quot;vinserti128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3667             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate8L($con)&quot; %}</span>
<span class="line-removed"> 3668   ins_encode %{</span>
<span class="line-removed"> 3669     __ movq($dst$$XMMRegister, $constantaddress($con));</span>
<span class="line-removed"> 3670     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3671     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3672     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3673   %}</span>
<span class="line-removed"> 3674   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3675 %}</span>
<span class="line-removed"> 3676 </span>
<span class="line-removed"> 3677 instruct Repl4L_mem(vecY dst, memory mem) %{</span>
<span class="line-removed"> 3678   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3679   match(Set dst (ReplicateL (LoadL mem)));</span>
<span class="line-removed"> 3680   format %{ &quot;movq    $dst,$mem\n\t&quot;</span>
<span class="line-removed"> 3681             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3682             &quot;vinserti128_high $dst,$dst\t! replicate4L&quot; %}</span>
<span class="line-removed"> 3683   ins_encode %{</span>
<span class="line-removed"> 3684     __ movq($dst$$XMMRegister, $mem$$Address);</span>
<span class="line-removed"> 3685     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3686     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3687   %}</span>
<span class="line-removed"> 3688   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3689 %}</span>
<span class="line-removed"> 3690 </span>
<span class="line-removed"> 3691 instruct Repl8L_mem(legVecZ dst, memory mem) %{</span>
<span class="line-removed"> 3692   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3693   match(Set dst (ReplicateL (LoadL mem)));</span>
<span class="line-removed"> 3694   format %{ &quot;movq    $dst,$mem\n\t&quot;</span>
<span class="line-removed"> 3695             &quot;punpcklqdq $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3696             &quot;vinserti128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3697             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate8L&quot; %}</span>
<span class="line-removed"> 3698   ins_encode %{</span>
<span class="line-removed"> 3699     __ movq($dst$$XMMRegister, $mem$$Address);</span>
<span class="line-removed"> 3700     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3701     __ vinserti128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3702     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3703   %}</span>
<span class="line-removed"> 3704   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3705 %}</span>
<span class="line-removed"> 3706 </span>
<span class="line-removed"> 3707 instruct Repl2F_mem(vecD dst, memory mem) %{</span>
<span class="line-removed"> 3708   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; UseAVX &gt; 0 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3709   match(Set dst (ReplicateF (LoadF mem)));</span>
<span class="line-removed"> 3710   format %{ &quot;pshufd  $dst,$mem,0x00\t! replicate2F&quot; %}</span>
<span class="line-removed"> 3711   ins_encode %{</span>
<span class="line-removed"> 3712     __ pshufd($dst$$XMMRegister, $mem$$Address, 0x00);</span>
<span class="line-removed"> 3713   %}</span>
<span class="line-removed"> 3714   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3715 %}</span>
<span class="line-removed"> 3716 </span>
<span class="line-removed"> 3717 instruct Repl4F_mem(vecX dst, memory mem) %{</span>
<span class="line-removed"> 3718   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 0 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3719   match(Set dst (ReplicateF (LoadF mem)));</span>
<span class="line-removed"> 3720   format %{ &quot;pshufd  $dst,$mem,0x00\t! replicate4F&quot; %}</span>
<span class="line-removed"> 3721   ins_encode %{</span>
<span class="line-removed"> 3722     __ pshufd($dst$$XMMRegister, $mem$$Address, 0x00);</span>
<span class="line-removed"> 3723   %}</span>
<span class="line-removed"> 3724   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3725 %}</span>
<span class="line-removed"> 3726 </span>
<span class="line-removed"> 3727 instruct Repl8F(vecY dst, vlRegF src) %{</span>
<span class="line-removed"> 3728   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 0 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3729   match(Set dst (ReplicateF src));</span>
<span class="line-removed"> 3730   format %{ &quot;pshufd  $dst,$src,0x00\n\t&quot;</span>
<span class="line-removed"> 3731             &quot;vinsertf128_high $dst,$dst\t! replicate8F&quot; %}</span>
<span class="line-removed"> 3732   ins_encode %{</span>
<span class="line-removed"> 3733     __ pshufd($dst$$XMMRegister, $src$$XMMRegister, 0x00);</span>
<span class="line-removed"> 3734     __ vinsertf128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3735   %}</span>
<span class="line-removed"> 3736   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3737 %}</span>
<span class="line-removed"> 3738 </span>
<span class="line-removed"> 3739 instruct Repl8F_mem(vecY dst, memory mem) %{</span>
<span class="line-removed"> 3740   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3741   match(Set dst (ReplicateF (LoadF mem)));</span>
<span class="line-removed"> 3742   format %{ &quot;pshufd  $dst,$mem,0x00\n\t&quot;</span>
<span class="line-removed"> 3743             &quot;vinsertf128_high $dst,$dst\t! replicate8F&quot; %}</span>
<span class="line-removed"> 3744   ins_encode %{</span>
<span class="line-removed"> 3745     __ pshufd($dst$$XMMRegister, $mem$$Address, 0x00);</span>
<span class="line-removed"> 3746     __ vinsertf128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3747   %}</span>
<span class="line-removed"> 3748   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3749 %}</span>
<span class="line-removed"> 3750 </span>
<span class="line-removed"> 3751 instruct Repl16F(legVecZ dst, vlRegF src) %{</span>
<span class="line-removed"> 3752   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 0 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3753   match(Set dst (ReplicateF src));</span>
<span class="line-removed"> 3754   format %{ &quot;pshufd  $dst,$src,0x00\n\t&quot;</span>
<span class="line-removed"> 3755             &quot;vinsertf128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3756             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate16F&quot; %}</span>
<span class="line-removed"> 3757   ins_encode %{</span>
<span class="line-removed"> 3758     __ pshufd($dst$$XMMRegister, $src$$XMMRegister, 0x00);</span>
<span class="line-removed"> 3759     __ vinsertf128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3760     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3761   %}</span>
<span class="line-removed"> 3762   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3763 %}</span>
<span class="line-removed"> 3764 </span>
<span class="line-removed"> 3765 instruct Repl16F_mem(legVecZ dst, memory mem) %{</span>
<span class="line-removed"> 3766   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3767   match(Set dst (ReplicateF (LoadF mem)));</span>
<span class="line-removed"> 3768   format %{ &quot;pshufd  $dst,$mem,0x00\n\t&quot;</span>
<span class="line-removed"> 3769             &quot;vinsertf128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3770             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate16F&quot; %}</span>
<span class="line-removed"> 3771   ins_encode %{</span>
<span class="line-removed"> 3772     __ pshufd($dst$$XMMRegister, $mem$$Address, 0x00);</span>
<span class="line-removed"> 3773     __ vinsertf128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3774     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3775   %}</span>
<span class="line-removed"> 3776   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3777 %}</span>
<span class="line-removed"> 3778 </span>
<span class="line-removed"> 3779 instruct Repl2F_zero(vecD dst, immF0 zero) %{</span>
<span class="line-removed"> 3780   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; UseAVX &lt; 3);</span>
<span class="line-removed"> 3781   match(Set dst (ReplicateF zero));</span>
<span class="line-removed"> 3782   format %{ &quot;xorps   $dst,$dst\t! replicate2F zero&quot; %}</span>
<span class="line-removed"> 3783   ins_encode %{</span>
<span class="line-removed"> 3784     __ xorps($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3785   %}</span>
<span class="line-removed"> 3786   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 3787 %}</span>
<span class="line-removed"> 3788 </span>
<span class="line-removed"> 3789 instruct Repl4F_zero(vecX dst, immF0 zero) %{</span>
<span class="line-removed"> 3790   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &lt; 3);</span>
<span class="line-removed"> 3791   match(Set dst (ReplicateF zero));</span>
<span class="line-removed"> 3792   format %{ &quot;xorps   $dst,$dst\t! replicate4F zero&quot; %}</span>
<span class="line-removed"> 3793   ins_encode %{</span>
<span class="line-removed"> 3794     __ xorps($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3795   %}</span>
<span class="line-removed"> 3796   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 3797 %}</span>
<span class="line-removed"> 3798 </span>
<span class="line-removed"> 3799 instruct Repl8F_zero(vecY dst, immF0 zero) %{</span>
<span class="line-removed"> 3800   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &lt; 3);</span>
<span class="line-removed"> 3801   match(Set dst (ReplicateF zero));</span>
<span class="line-removed"> 3802   format %{ &quot;vxorps  $dst,$dst,$dst\t! replicate8F zero&quot; %}</span>
<span class="line-removed"> 3803   ins_encode %{</span>
<span class="line-removed"> 3804     int vector_len = 1;</span>
<span class="line-removed"> 3805     __ vxorps($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 3806   %}</span>
<span class="line-removed"> 3807   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 3808 %}</span>
<span class="line-removed"> 3809 </span>
<span class="line-removed"> 3810 instruct Repl2D_mem(vecX dst, memory mem) %{</span>
<span class="line-removed"> 3811   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; UseAVX &gt; 0 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3812   match(Set dst (ReplicateD (LoadD mem)));</span>
<span class="line-removed"> 3813   format %{ &quot;pshufd  $dst,$mem,0x44\t! replicate2D&quot; %}</span>
<span class="line-removed"> 3814   ins_encode %{</span>
<span class="line-removed"> 3815     __ pshufd($dst$$XMMRegister, $mem$$Address, 0x44);</span>
<span class="line-removed"> 3816   %}</span>
<span class="line-removed"> 3817   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3818 %}</span>
<span class="line-removed"> 3819 </span>
<span class="line-removed"> 3820 instruct Repl4D(vecY dst, vlRegD src) %{</span>
<span class="line-removed"> 3821   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 0 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3822   match(Set dst (ReplicateD src));</span>
<span class="line-removed"> 3823   format %{ &quot;pshufd  $dst,$src,0x44\n\t&quot;</span>
<span class="line-removed"> 3824             &quot;vinsertf128_high $dst,$dst\t! replicate4D&quot; %}</span>
<span class="line-removed"> 3825   ins_encode %{</span>
<span class="line-removed"> 3826     __ pshufd($dst$$XMMRegister, $src$$XMMRegister, 0x44);</span>
<span class="line-removed"> 3827     __ vinsertf128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3828   %}</span>
<span class="line-removed"> 3829   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3830 %}</span>
<span class="line-removed"> 3831 </span>
<span class="line-removed"> 3832 instruct Repl4D_mem(vecY dst, memory mem) %{</span>
<span class="line-removed"> 3833   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3834   match(Set dst (ReplicateD (LoadD mem)));</span>
<span class="line-removed"> 3835   format %{ &quot;pshufd  $dst,$mem,0x44\n\t&quot;</span>
<span class="line-removed"> 3836             &quot;vinsertf128_high $dst,$dst\t! replicate4D&quot; %}</span>
<span class="line-removed"> 3837   ins_encode %{</span>
<span class="line-removed"> 3838     __ pshufd($dst$$XMMRegister, $mem$$Address, 0x44);</span>
<span class="line-removed"> 3839     __ vinsertf128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3840   %}</span>
<span class="line-removed"> 3841   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3842 %}</span>
<span class="line-removed"> 3843 </span>
<span class="line-removed"> 3844 instruct Repl8D(legVecZ dst, vlRegD src) %{</span>
<span class="line-removed"> 3845   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 0 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3846   match(Set dst (ReplicateD src));</span>
<span class="line-removed"> 3847   format %{ &quot;pshufd  $dst,$src,0x44\n\t&quot;</span>
<span class="line-removed"> 3848             &quot;vinsertf128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3849             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate8D&quot; %}</span>
<span class="line-removed"> 3850   ins_encode %{</span>
<span class="line-removed"> 3851     __ pshufd($dst$$XMMRegister, $src$$XMMRegister, 0x44);</span>
<span class="line-removed"> 3852     __ vinsertf128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3853     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3854   %}</span>
<span class="line-removed"> 3855   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3856 %}</span>
<span class="line-removed"> 3857 </span>
<span class="line-removed"> 3858 instruct Repl8D_mem(legVecZ dst, memory mem) %{</span>
<span class="line-removed"> 3859   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; !VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 3860   match(Set dst (ReplicateD (LoadD mem)));</span>
<span class="line-removed"> 3861   format %{ &quot;pshufd  $dst,$mem,0x44\n\t&quot;</span>
<span class="line-removed"> 3862             &quot;vinsertf128_high $dst,$dst\t&quot;</span>
<span class="line-removed"> 3863             &quot;vinserti64x4 $dst,$dst,$dst,0x1\t! replicate8D&quot; %}</span>
<span class="line-removed"> 3864   ins_encode %{</span>
<span class="line-removed"> 3865     __ pshufd($dst$$XMMRegister, $mem$$Address, 0x44);</span>
<span class="line-removed"> 3866     __ vinsertf128_high($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3867     __ vinserti64x4($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, 0x1);</span>
<span class="line-removed"> 3868   %}</span>
<span class="line-removed"> 3869   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3870 %}</span>
<span class="line-removed"> 3871 </span>
<span class="line-removed"> 3872 // Replicate double (8 byte) scalar zero to be vector</span>
<span class="line-removed"> 3873 instruct Repl2D_zero(vecX dst, immD0 zero) %{</span>
<span class="line-removed"> 3874   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; UseAVX &lt; 3);</span>
<span class="line-removed"> 3875   match(Set dst (ReplicateD zero));</span>
<span class="line-removed"> 3876   format %{ &quot;xorpd   $dst,$dst\t! replicate2D zero&quot; %}</span>
<span class="line-removed"> 3877   ins_encode %{</span>
<span class="line-removed"> 3878     __ xorpd($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3879   %}</span>
<span class="line-removed"> 3880   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 3881 %}</span>
<span class="line-removed"> 3882 </span>
<span class="line-removed"> 3883 instruct Repl4D_zero(vecY dst, immD0 zero) %{</span>
<span class="line-removed"> 3884   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &lt; 3);</span>
<span class="line-removed"> 3885   match(Set dst (ReplicateD zero));</span>
<span class="line-removed"> 3886   format %{ &quot;vxorpd  $dst,$dst,$dst,vect256\t! replicate4D zero&quot; %}</span>
<span class="line-removed"> 3887   ins_encode %{</span>
<span class="line-removed"> 3888     int vector_len = 1;</span>
<span class="line-removed"> 3889     __ vxorpd($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 3890   %}</span>
<span class="line-removed"> 3891   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 3892 %}</span>
<span class="line-removed"> 3893 </span>
<span class="line-removed"> 3894 // ====================GENERIC REPLICATE==========================================</span>
<span class="line-removed"> 3895 </span>
<span class="line-removed"> 3896 // Replicate byte scalar to be vector</span>
<span class="line-removed"> 3897 instruct Repl4B(vecS dst, rRegI src) %{</span>
<span class="line-removed"> 3898   predicate(n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 3899   match(Set dst (ReplicateB src));</span>
<span class="line-removed"> 3900   format %{ &quot;movd    $dst,$src\n\t&quot;</span>
<span class="line-removed"> 3901             &quot;punpcklbw $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3902             &quot;pshuflw $dst,$dst,0x00\t! replicate4B&quot; %}</span>
<span class="line-removed"> 3903   ins_encode %{</span>
<span class="line-removed"> 3904     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 3905     __ punpcklbw($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3906     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-removed"> 3907   %}</span>
<span class="line-removed"> 3908   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3909 %}</span>
<span class="line-removed"> 3910 </span>
<span class="line-removed"> 3911 instruct Repl8B(vecD dst, rRegI src) %{</span>
<span class="line-removed"> 3912   predicate(n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 3913   match(Set dst (ReplicateB src));</span>
<span class="line-removed"> 3914   format %{ &quot;movd    $dst,$src\n\t&quot;</span>
<span class="line-removed"> 3915             &quot;punpcklbw $dst,$dst\n\t&quot;</span>
<span class="line-removed"> 3916             &quot;pshuflw $dst,$dst,0x00\t! replicate8B&quot; %}</span>
<span class="line-removed"> 3917   ins_encode %{</span>
<span class="line-removed"> 3918     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 3919     __ punpcklbw($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3920     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-removed"> 3921   %}</span>
<span class="line-removed"> 3922   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3923 %}</span>
<span class="line-removed"> 3924 </span>
<span class="line-removed"> 3925 // Replicate byte scalar immediate to be vector by loading from const table.</span>
<span class="line-removed"> 3926 instruct Repl4B_imm(vecS dst, immI con) %{</span>
<span class="line-removed"> 3927   predicate(n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 3928   match(Set dst (ReplicateB con));</span>
<span class="line-removed"> 3929   format %{ &quot;movdl   $dst,[$constantaddress]\t! replicate4B($con)&quot; %}</span>
<span class="line-removed"> 3930   ins_encode %{</span>
<span class="line-removed"> 3931     __ movdl($dst$$XMMRegister, $constantaddress(replicate4_imm($con$$constant, 1)));</span>
<span class="line-removed"> 3932   %}</span>
<span class="line-removed"> 3933   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3934 %}</span>
<span class="line-removed"> 3935 </span>
<span class="line-removed"> 3936 instruct Repl8B_imm(vecD dst, immI con) %{</span>
<span class="line-removed"> 3937   predicate(n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 3938   match(Set dst (ReplicateB con));</span>
<span class="line-removed"> 3939   format %{ &quot;movq    $dst,[$constantaddress]\t! replicate8B($con)&quot; %}</span>
<span class="line-removed"> 3940   ins_encode %{</span>
<span class="line-removed"> 3941     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 1)));</span>
<span class="line-removed"> 3942   %}</span>
<span class="line-removed"> 3943   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 3944 %}</span>
<span class="line-removed"> 3945 </span>
<span class="line-removed"> 3946 // Replicate byte scalar zero to be vector</span>
<span class="line-removed"> 3947 instruct Repl4B_zero(vecS dst, immI0 zero) %{</span>
<span class="line-removed"> 3948   predicate(n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 3949   match(Set dst (ReplicateB zero));</span>
<span class="line-removed"> 3950   format %{ &quot;pxor    $dst,$dst\t! replicate4B zero&quot; %}</span>
<span class="line-removed"> 3951   ins_encode %{</span>
<span class="line-removed"> 3952     __ pxor($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3953   %}</span>
<span class="line-removed"> 3954   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 3955 %}</span>
<span class="line-removed"> 3956 </span>
<span class="line-removed"> 3957 instruct Repl8B_zero(vecD dst, immI0 zero) %{</span>
<span class="line-removed"> 3958   predicate(n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 3959   match(Set dst (ReplicateB zero));</span>
<span class="line-removed"> 3960   format %{ &quot;pxor    $dst,$dst\t! replicate8B zero&quot; %}</span>
<span class="line-removed"> 3961   ins_encode %{</span>
<span class="line-removed"> 3962     __ pxor($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3963   %}</span>
<span class="line-removed"> 3964   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 3965 %}</span>
<span class="line-removed"> 3966 </span>
<span class="line-removed"> 3967 instruct Repl16B_zero(vecX dst, immI0 zero) %{</span>
<span class="line-removed"> 3968   predicate(n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 3969   match(Set dst (ReplicateB zero));</span>
<span class="line-removed"> 3970   format %{ &quot;pxor    $dst,$dst\t! replicate16B zero&quot; %}</span>
<span class="line-removed"> 3971   ins_encode %{</span>
<span class="line-removed"> 3972     __ pxor($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 3973   %}</span>
<span class="line-removed"> 3974   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 3975 %}</span>
<span class="line-removed"> 3976 </span>
<span class="line-removed"> 3977 instruct Repl32B_zero(vecY dst, immI0 zero) %{</span>
<span class="line-removed"> 3978   predicate(n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-removed"> 3979   match(Set dst (ReplicateB zero));</span>
<span class="line-removed"> 3980   format %{ &quot;vpxor   $dst,$dst,$dst\t! replicate32B zero&quot; %}</span>
<span class="line-removed"> 3981   ins_encode %{</span>
<span class="line-removed"> 3982     // Use vxorpd since AVX does not have vpxor for 256-bit (AVX2 will have it).</span>
<span class="line-removed"> 3983     int vector_len = 1;</span>
<span class="line-removed"> 3984     __ vpxor($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 3985   %}</span>
<span class="line-removed"> 3986   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 3987 %}</span>
<span class="line-removed"> 3988 </span>
<span class="line-removed"> 3989 // Replicate char/short (2 byte) scalar to be vector</span>
<span class="line-removed"> 3990 instruct Repl2S(vecS dst, rRegI src) %{</span>
<span class="line-removed"> 3991   predicate(n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 3992   match(Set dst (ReplicateS src));</span>
<span class="line-removed"> 3993   format %{ &quot;movd    $dst,$src\n\t&quot;</span>
<span class="line-removed"> 3994             &quot;pshuflw $dst,$dst,0x00\t! replicate2S&quot; %}</span>
<span class="line-removed"> 3995   ins_encode %{</span>
<span class="line-removed"> 3996     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 3997     __ pshuflw($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-removed"> 3998   %}</span>
<span class="line-removed"> 3999   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4000 %}</span>
<span class="line-removed"> 4001 </span>
<span class="line-removed"> 4002 // Replicate char/short (2 byte) scalar immediate to be vector by loading from const table.</span>
<span class="line-removed"> 4003 instruct Repl2S_imm(vecS dst, immI con) %{</span>
<span class="line-removed"> 4004   predicate(n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 4005   match(Set dst (ReplicateS con));</span>
<span class="line-removed"> 4006   format %{ &quot;movdl   $dst,[$constantaddress]\t! replicate2S($con)&quot; %}</span>
<span class="line-removed"> 4007   ins_encode %{</span>
<span class="line-removed"> 4008     __ movdl($dst$$XMMRegister, $constantaddress(replicate4_imm($con$$constant, 2)));</span>
<span class="line-removed"> 4009   %}</span>
<span class="line-removed"> 4010   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4011 %}</span>
<span class="line-removed"> 4012 </span>
<span class="line-removed"> 4013 instruct Repl4S_imm(vecD dst, immI con) %{</span>
<span class="line-removed"> 4014   predicate(n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 4015   match(Set dst (ReplicateS con));</span>
<span class="line-removed"> 4016   format %{ &quot;movq    $dst,[$constantaddress]\t! replicate4S($con)&quot; %}</span>
<span class="line-removed"> 4017   ins_encode %{</span>
<span class="line-removed"> 4018     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 2)));</span>
<span class="line-removed"> 4019   %}</span>
<span class="line-removed"> 4020   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4021 %}</span>
<span class="line-removed"> 4022 </span>
<span class="line-removed"> 4023 // Replicate char/short (2 byte) scalar zero to be vector</span>
<span class="line-removed"> 4024 instruct Repl2S_zero(vecS dst, immI0 zero) %{</span>
<span class="line-removed"> 4025   predicate(n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 4026   match(Set dst (ReplicateS zero));</span>
<span class="line-removed"> 4027   format %{ &quot;pxor    $dst,$dst\t! replicate2S zero&quot; %}</span>
<span class="line-removed"> 4028   ins_encode %{</span>
<span class="line-removed"> 4029     __ pxor($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 4030   %}</span>
<span class="line-removed"> 4031   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4032 %}</span>
<span class="line-removed"> 4033 </span>
<span class="line-removed"> 4034 instruct Repl4S_zero(vecD dst, immI0 zero) %{</span>
<span class="line-removed"> 4035   predicate(n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 4036   match(Set dst (ReplicateS zero));</span>
<span class="line-removed"> 4037   format %{ &quot;pxor    $dst,$dst\t! replicate4S zero&quot; %}</span>
<span class="line-removed"> 4038   ins_encode %{</span>
<span class="line-removed"> 4039     __ pxor($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 4040   %}</span>
<span class="line-removed"> 4041   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4042 %}</span>
<span class="line-removed"> 4043 </span>
<span class="line-removed"> 4044 instruct Repl8S_zero(vecX dst, immI0 zero) %{</span>
<span class="line-removed"> 4045   predicate(n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 4046   match(Set dst (ReplicateS zero));</span>
<span class="line-removed"> 4047   format %{ &quot;pxor    $dst,$dst\t! replicate8S zero&quot; %}</span>
<span class="line-removed"> 4048   ins_encode %{</span>
<span class="line-removed"> 4049     __ pxor($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 4050   %}</span>
<span class="line-removed"> 4051   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4052 %}</span>
<span class="line-removed"> 4053 </span>
<span class="line-removed"> 4054 instruct Repl16S_zero(vecY dst, immI0 zero) %{</span>
<span class="line-removed"> 4055   predicate(n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 4056   match(Set dst (ReplicateS zero));</span>
<span class="line-removed"> 4057   format %{ &quot;vpxor   $dst,$dst,$dst\t! replicate16S zero&quot; %}</span>
<span class="line-removed"> 4058   ins_encode %{</span>
<span class="line-removed"> 4059     // Use vxorpd since AVX does not have vpxor for 256-bit (AVX2 will have it).</span>
<span class="line-removed"> 4060     int vector_len = 1;</span>
<span class="line-removed"> 4061     __ vpxor($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4062   %}</span>
<span class="line-removed"> 4063   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4064 %}</span>
<span class="line-removed"> 4065 </span>
<span class="line-removed"> 4066 // Replicate integer (4 byte) scalar to be vector</span>
<span class="line-removed"> 4067 instruct Repl2I(vecD dst, rRegI src) %{</span>
<span class="line-removed"> 4068   predicate(n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 4069   match(Set dst (ReplicateI src));</span>
<span class="line-removed"> 4070   format %{ &quot;movd    $dst,$src\n\t&quot;</span>
<span class="line-removed"> 4071             &quot;pshufd  $dst,$dst,0x00\t! replicate2I&quot; %}</span>
<span class="line-removed"> 4072   ins_encode %{</span>
<span class="line-removed"> 4073     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 4074     __ pshufd($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-removed"> 4075   %}</span>
<span class="line-removed"> 4076   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4077 %}</span>
<span class="line-removed"> 4078 </span>
<span class="line-removed"> 4079 // Integer could be loaded into xmm register directly from memory.</span>
<span class="line-removed"> 4080 instruct Repl2I_mem(vecD dst, memory mem) %{</span>
<span class="line-removed"> 4081   predicate(n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 4082   match(Set dst (ReplicateI (LoadI mem)));</span>
<span class="line-removed"> 4083   format %{ &quot;movd    $dst,$mem\n\t&quot;</span>
<span class="line-removed"> 4084             &quot;pshufd  $dst,$dst,0x00\t! replicate2I&quot; %}</span>
<span class="line-removed"> 4085   ins_encode %{</span>
<span class="line-removed"> 4086     __ movdl($dst$$XMMRegister, $mem$$Address);</span>
<span class="line-removed"> 4087     __ pshufd($dst$$XMMRegister, $dst$$XMMRegister, 0x00);</span>
<span class="line-removed"> 4088   %}</span>
<span class="line-removed"> 4089   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4090 %}</span>
<span class="line-removed"> 4091 </span>
<span class="line-removed"> 4092 // Replicate integer (4 byte) scalar immediate to be vector by loading from const table.</span>
<span class="line-removed"> 4093 instruct Repl2I_imm(vecD dst, immI con) %{</span>
<span class="line-removed"> 4094   predicate(n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 4095   match(Set dst (ReplicateI con));</span>
<span class="line-removed"> 4096   format %{ &quot;movq    $dst,[$constantaddress]\t! replicate2I($con)&quot; %}</span>
<span class="line-removed"> 4097   ins_encode %{</span>
<span class="line-removed"> 4098     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 4)));</span>
<span class="line-removed"> 4099   %}</span>
<span class="line-removed"> 4100   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4101 %}</span>
<span class="line-removed"> 4102 </span>
<span class="line-removed"> 4103 // Replicate integer (4 byte) scalar zero to be vector</span>
<span class="line-removed"> 4104 instruct Repl2I_zero(vecD dst, immI0 zero) %{</span>
<span class="line-removed"> 4105   predicate(n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 4106   match(Set dst (ReplicateI zero));</span>
<span class="line-removed"> 4107   format %{ &quot;pxor    $dst,$dst\t! replicate2I&quot; %}</span>
<span class="line-removed"> 4108   ins_encode %{</span>
<span class="line-removed"> 4109     __ pxor($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 4110   %}</span>
<span class="line-removed"> 4111   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4112 %}</span>
<span class="line-removed"> 4113 </span>
<span class="line-removed"> 4114 instruct Repl4I_zero(vecX dst, immI0 zero) %{</span>
<span class="line-removed"> 4115   predicate(n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 4116   match(Set dst (ReplicateI zero));</span>
<span class="line-removed"> 4117   format %{ &quot;pxor    $dst,$dst\t! replicate4I zero)&quot; %}</span>
<span class="line-removed"> 4118   ins_encode %{</span>
<span class="line-removed"> 4119     __ pxor($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 4120   %}</span>
<span class="line-removed"> 4121   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4122 %}</span>
<span class="line-removed"> 4123 </span>
<span class="line-removed"> 4124 instruct Repl8I_zero(vecY dst, immI0 zero) %{</span>
<span class="line-removed"> 4125   predicate(n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 4126   match(Set dst (ReplicateI zero));</span>
<span class="line-removed"> 4127   format %{ &quot;vpxor   $dst,$dst,$dst\t! replicate8I zero&quot; %}</span>
<span class="line-removed"> 4128   ins_encode %{</span>
<span class="line-removed"> 4129     // Use vxorpd since AVX does not have vpxor for 256-bit (AVX2 will have it).</span>
<span class="line-removed"> 4130     int vector_len = 1;</span>
<span class="line-removed"> 4131     __ vpxor($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4132   %}</span>
<span class="line-removed"> 4133   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4134 %}</span>
<span class="line-removed"> 4135 </span>
<span class="line-removed"> 4136 // Replicate long (8 byte) scalar to be vector</span>
<span class="line-removed"> 4137 #ifdef _LP64</span>
<span class="line-removed"> 4138 instruct Repl2L(vecX dst, rRegL src) %{</span>
<span class="line-removed"> 4139   predicate(n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 4140   match(Set dst (ReplicateL src));</span>
<span class="line-removed"> 4141   format %{ &quot;movdq   $dst,$src\n\t&quot;</span>
<span class="line-removed"> 4142             &quot;punpcklqdq $dst,$dst\t! replicate2L&quot; %}</span>
<span class="line-removed"> 4143   ins_encode %{</span>
<span class="line-removed"> 4144     __ movdq($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 4145     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 4146   %}</span>
<span class="line-removed"> 4147   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4148 %}</span>
<span class="line-removed"> 4149 #else // _LP64</span>
<span class="line-removed"> 4150 instruct Repl2L(vecX dst, eRegL src, vecX tmp) %{</span>
<span class="line-removed"> 4151   predicate(n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 4152   match(Set dst (ReplicateL src));</span>
<span class="line-removed"> 4153   effect(TEMP dst, USE src, TEMP tmp);</span>
<span class="line-removed"> 4154   format %{ &quot;movdl   $dst,$src.lo\n\t&quot;</span>
<span class="line-removed"> 4155             &quot;movdl   $tmp,$src.hi\n\t&quot;</span>
<span class="line-removed"> 4156             &quot;punpckldq $dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 4157             &quot;punpcklqdq $dst,$dst\t! replicate2L&quot;%}</span>
<span class="line-removed"> 4158   ins_encode %{</span>
<span class="line-removed"> 4159     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 4160     __ movdl($tmp$$XMMRegister, HIGH_FROM_LOW($src$$Register));</span>
<span class="line-removed"> 4161     __ punpckldq($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 4162     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 4163   %}</span>
<span class="line-removed"> 4164   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4165 %}</span>
<span class="line-removed"> 4166 #endif // _LP64</span>
<span class="line-removed"> 4167 </span>
<span class="line-removed"> 4168 // Replicate long (8 byte) scalar immediate to be vector by loading from const table.</span>
<span class="line-removed"> 4169 instruct Repl2L_imm(vecX dst, immL con) %{</span>
<span class="line-removed"> 4170   predicate(n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 4171   match(Set dst (ReplicateL con));</span>
<span class="line-removed"> 4172   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 4173             &quot;punpcklqdq $dst,$dst\t! replicate2L($con)&quot; %}</span>
<span class="line-removed"> 4174   ins_encode %{</span>
<span class="line-removed"> 4175     __ movq($dst$$XMMRegister, $constantaddress($con));</span>
<span class="line-removed"> 4176     __ punpcklqdq($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 4177   %}</span>
<span class="line-removed"> 4178   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4179 %}</span>
<span class="line-removed"> 4180 </span>
<span class="line-removed"> 4181 // Replicate long (8 byte) scalar zero to be vector</span>
<span class="line-removed"> 4182 instruct Repl2L_zero(vecX dst, immL0 zero) %{</span>
<span class="line-removed"> 4183   predicate(n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 4184   match(Set dst (ReplicateL zero));</span>
<span class="line-removed"> 4185   format %{ &quot;pxor    $dst,$dst\t! replicate2L zero&quot; %}</span>
<span class="line-removed"> 4186   ins_encode %{</span>
<span class="line-removed"> 4187     __ pxor($dst$$XMMRegister, $dst$$XMMRegister);</span>
<span class="line-removed"> 4188   %}</span>
<span class="line-removed"> 4189   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4190 %}</span>
<span class="line-removed"> 4191 </span>
<span class="line-removed"> 4192 instruct Repl4L_zero(vecY dst, immL0 zero) %{</span>
<span class="line-removed"> 4193   predicate(n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 4194   match(Set dst (ReplicateL zero));</span>
<span class="line-removed"> 4195   format %{ &quot;vpxor   $dst,$dst,$dst\t! replicate4L zero&quot; %}</span>
<span class="line-removed"> 4196   ins_encode %{</span>
<span class="line-removed"> 4197     // Use vxorpd since AVX does not have vpxor for 256-bit (AVX2 will have it).</span>
<span class="line-removed"> 4198     int vector_len = 1;</span>
<span class="line-removed"> 4199     __ vpxor($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4200   %}</span>
<span class="line-removed"> 4201   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4202 %}</span>
<span class="line-removed"> 4203 </span>
<span class="line-removed"> 4204 // Replicate float (4 byte) scalar to be vector</span>
<span class="line-removed"> 4205 instruct Repl2F(vecD dst, vlRegF src) %{</span>
<span class="line-removed"> 4206   predicate(n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 4207   match(Set dst (ReplicateF src));</span>
<span class="line-removed"> 4208   format %{ &quot;pshufd  $dst,$dst,0x00\t! replicate2F&quot; %}</span>
<span class="line-removed"> 4209   ins_encode %{</span>
<span class="line-removed"> 4210     __ pshufd($dst$$XMMRegister, $src$$XMMRegister, 0x00);</span>
<span class="line-removed"> 4211   %}</span>
<span class="line-removed"> 4212   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4213 %}</span>
<span class="line-removed"> 4214 </span>
<span class="line-removed"> 4215 instruct Repl4F(vecX dst, vlRegF src) %{</span>
<span class="line-removed"> 4216   predicate(n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 4217   match(Set dst (ReplicateF src));</span>
<span class="line-removed"> 4218   format %{ &quot;pshufd  $dst,$dst,0x00\t! replicate4F&quot; %}</span>
<span class="line-removed"> 4219   ins_encode %{</span>
<span class="line-removed"> 4220     __ pshufd($dst$$XMMRegister, $src$$XMMRegister, 0x00);</span>
<span class="line-removed"> 4221   %}</span>
<span class="line-removed"> 4222   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4223 %}</span>
<span class="line-removed"> 4224 </span>
<span class="line-removed"> 4225 // Replicate double (8 bytes) scalar to be vector</span>
<span class="line-removed"> 4226 instruct Repl2D(vecX dst, vlRegD src) %{</span>
<span class="line-removed"> 4227   predicate(n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 4228   match(Set dst (ReplicateD src));</span>
<span class="line-removed"> 4229   format %{ &quot;pshufd  $dst,$src,0x44\t! replicate2D&quot; %}</span>
<span class="line-removed"> 4230   ins_encode %{</span>
<span class="line-removed"> 4231     __ pshufd($dst$$XMMRegister, $src$$XMMRegister, 0x44);</span>
<span class="line-removed"> 4232   %}</span>
<span class="line-removed"> 4233   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4234 %}</span>
<span class="line-removed"> 4235 </span>
<span class="line-removed"> 4236 // ====================EVEX REPLICATE=============================================</span>
<span class="line-removed"> 4237 </span>
<span class="line-removed"> 4238 instruct Repl4B_mem_evex(vecS dst, memory mem) %{</span>
<span class="line-removed"> 4239   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4240   match(Set dst (ReplicateB (LoadB mem)));</span>
<span class="line-removed"> 4241   format %{ &quot;vpbroadcastb  $dst,$mem\t! replicate4B&quot; %}</span>
<span class="line-removed"> 4242   ins_encode %{</span>
<span class="line-removed"> 4243     int vector_len = 0;</span>
<span class="line-removed"> 4244     __ vpbroadcastb($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4245   %}</span>
<span class="line-removed"> 4246   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4247 %}</span>
<span class="line-removed"> 4248 </span>
<span class="line-removed"> 4249 instruct Repl8B_mem_evex(vecD dst, memory mem) %{</span>
<span class="line-removed"> 4250   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4251   match(Set dst (ReplicateB (LoadB mem)));</span>
<span class="line-removed"> 4252   format %{ &quot;vpbroadcastb  $dst,$mem\t! replicate8B&quot; %}</span>
<span class="line-removed"> 4253   ins_encode %{</span>
<span class="line-removed"> 4254     int vector_len = 0;</span>
<span class="line-removed"> 4255     __ vpbroadcastb($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4256   %}</span>
<span class="line-removed"> 4257   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4258 %}</span>
<span class="line-removed"> 4259 </span>
<span class="line-removed"> 4260 instruct Repl16B_evex(vecX dst, rRegI src) %{</span>
<span class="line-removed"> 4261   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4262   match(Set dst (ReplicateB src));</span>
<span class="line-removed"> 4263   format %{ &quot;evpbroadcastb $dst,$src\t! replicate16B&quot; %}</span>
<span class="line-removed"> 4264   ins_encode %{</span>
<span class="line-removed"> 4265    int vector_len = 0;</span>
<span class="line-removed"> 4266     __ evpbroadcastb($dst$$XMMRegister, $src$$Register, vector_len);</span>
<span class="line-removed"> 4267   %}</span>
<span class="line-removed"> 4268   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4269 %}</span>
<span class="line-removed"> 4270 </span>
<span class="line-removed"> 4271 instruct Repl16B_mem_evex(vecX dst, memory mem) %{</span>
<span class="line-removed"> 4272   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4273   match(Set dst (ReplicateB (LoadB mem)));</span>
<span class="line-removed"> 4274   format %{ &quot;vpbroadcastb  $dst,$mem\t! replicate16B&quot; %}</span>
<span class="line-removed"> 4275   ins_encode %{</span>
<span class="line-removed"> 4276     int vector_len = 0;</span>
<span class="line-removed"> 4277     __ vpbroadcastb($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4278   %}</span>
<span class="line-removed"> 4279   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4280 %}</span>
<span class="line-removed"> 4281 </span>
<span class="line-removed"> 4282 instruct Repl32B_evex(vecY dst, rRegI src) %{</span>
<span class="line-removed"> 4283   predicate(n-&gt;as_Vector()-&gt;length() == 32 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4284   match(Set dst (ReplicateB src));</span>
<span class="line-removed"> 4285   format %{ &quot;evpbroadcastb $dst,$src\t! replicate32B&quot; %}</span>
<span class="line-removed"> 4286   ins_encode %{</span>
<span class="line-removed"> 4287    int vector_len = 1;</span>
<span class="line-removed"> 4288     __ evpbroadcastb($dst$$XMMRegister, $src$$Register, vector_len);</span>
<span class="line-removed"> 4289   %}</span>
<span class="line-removed"> 4290   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4291 %}</span>
<span class="line-removed"> 4292 </span>
<span class="line-removed"> 4293 instruct Repl32B_mem_evex(vecY dst, memory mem) %{</span>
<span class="line-removed"> 4294   predicate(n-&gt;as_Vector()-&gt;length() == 32 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4295   match(Set dst (ReplicateB (LoadB mem)));</span>
<span class="line-removed"> 4296   format %{ &quot;vpbroadcastb  $dst,$mem\t! replicate32B&quot; %}</span>
<span class="line-removed"> 4297   ins_encode %{</span>
<span class="line-removed"> 4298     int vector_len = 1;</span>
<span class="line-removed"> 4299     __ vpbroadcastb($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4300   %}</span>
<span class="line-removed"> 4301   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4302 %}</span>
<span class="line-removed"> 4303 </span>
<span class="line-removed"> 4304 instruct Repl64B_evex(vecZ dst, rRegI src) %{</span>
<span class="line-removed"> 4305   predicate(n-&gt;as_Vector()-&gt;length() == 64 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw());</span>
<span class="line-removed"> 4306   match(Set dst (ReplicateB src));</span>
<span class="line-removed"> 4307   format %{ &quot;evpbroadcastb $dst,$src\t! upper replicate64B&quot; %}</span>
<span class="line-removed"> 4308   ins_encode %{</span>
<span class="line-removed"> 4309    int vector_len = 2;</span>
<span class="line-removed"> 4310     __ evpbroadcastb($dst$$XMMRegister, $src$$Register, vector_len);</span>
<span class="line-removed"> 4311   %}</span>
<span class="line-removed"> 4312   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4313 %}</span>
<span class="line-removed"> 4314 </span>
<span class="line-removed"> 4315 instruct Repl64B_mem_evex(vecZ dst, memory mem) %{</span>
<span class="line-removed"> 4316   predicate(n-&gt;as_Vector()-&gt;length() == 64 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw());</span>
<span class="line-removed"> 4317   match(Set dst (ReplicateB (LoadB mem)));</span>
<span class="line-removed"> 4318   format %{ &quot;vpbroadcastb  $dst,$mem\t! replicate64B&quot; %}</span>
<span class="line-removed"> 4319   ins_encode %{</span>
<span class="line-removed"> 4320     int vector_len = 2;</span>
<span class="line-removed"> 4321     __ vpbroadcastb($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4322   %}</span>
<span class="line-removed"> 4323   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4324 %}</span>
<span class="line-removed"> 4325 </span>
<span class="line-removed"> 4326 instruct Repl16B_imm_evex(vecX dst, immI con) %{</span>
<span class="line-removed"> 4327   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4328   match(Set dst (ReplicateB con));</span>
<span class="line-removed"> 4329   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 4330             &quot;vpbroadcastb $dst,$dst\t! replicate16B&quot; %}</span>
<span class="line-removed"> 4331   ins_encode %{</span>
<span class="line-removed"> 4332    int vector_len = 0;</span>
<span class="line-removed"> 4333     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 1)));</span>
<span class="line-removed"> 4334     __ vpbroadcastb($dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4335   %}</span>
<span class="line-removed"> 4336   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4337 %}</span>
<span class="line-removed"> 4338 </span>
<span class="line-removed"> 4339 instruct Repl32B_imm_evex(vecY dst, immI con) %{</span>
<span class="line-removed"> 4340   predicate(n-&gt;as_Vector()-&gt;length() == 32 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4341   match(Set dst (ReplicateB con));</span>
<span class="line-removed"> 4342   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 4343             &quot;vpbroadcastb $dst,$dst\t! replicate32B&quot; %}</span>
<span class="line-removed"> 4344   ins_encode %{</span>
<span class="line-removed"> 4345    int vector_len = 1;</span>
<span class="line-removed"> 4346     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 1)));</span>
<span class="line-removed"> 4347     __ vpbroadcastb($dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4348   %}</span>
<span class="line-removed"> 4349   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4350 %}</span>
<span class="line-removed"> 4351 </span>
<span class="line-removed"> 4352 instruct Repl64B_imm_evex(vecZ dst, immI con) %{</span>
<span class="line-removed"> 4353   predicate(n-&gt;as_Vector()-&gt;length() == 64 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw());</span>
<span class="line-removed"> 4354   match(Set dst (ReplicateB con));</span>
<span class="line-removed"> 4355   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 4356             &quot;vpbroadcastb $dst,$dst\t! upper replicate64B&quot; %}</span>
<span class="line-removed"> 4357   ins_encode %{</span>
<span class="line-removed"> 4358    int vector_len = 2;</span>
<span class="line-removed"> 4359     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 1)));</span>
<span class="line-removed"> 4360     __ vpbroadcastb($dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4361   %}</span>
<span class="line-removed"> 4362   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4363 %}</span>
<span class="line-removed"> 4364 </span>
<span class="line-removed"> 4365 instruct Repl64B_zero_evex(vecZ dst, immI0 zero) %{</span>
<span class="line-removed"> 4366   predicate(n-&gt;as_Vector()-&gt;length() == 64 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4367   match(Set dst (ReplicateB zero));</span>
<span class="line-removed"> 4368   format %{ &quot;vpxor   $dst k0,$dst,$dst\t! replicate64B zero&quot; %}</span>
<span class="line-removed"> 4369   ins_encode %{</span>
<span class="line-removed"> 4370     // Use vxorpd since AVX does not have vpxor for 512-bit (EVEX will have it).</span>
<span class="line-removed"> 4371     int vector_len = 2;</span>
<span class="line-removed"> 4372     __ vpxor($dst$$XMMRegister,$dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4373   %}</span>
<span class="line-removed"> 4374   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4375 %}</span>
<span class="line-removed"> 4376 </span>
<span class="line-removed"> 4377 instruct Repl4S_evex(vecD dst, rRegI src) %{</span>
<span class="line-removed"> 4378   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4379   match(Set dst (ReplicateS src));</span>
<span class="line-removed"> 4380   format %{ &quot;evpbroadcastw $dst,$src\t! replicate4S&quot; %}</span>
<span class="line-removed"> 4381   ins_encode %{</span>
<span class="line-removed"> 4382    int vector_len = 0;</span>
<span class="line-removed"> 4383     __ evpbroadcastw($dst$$XMMRegister, $src$$Register, vector_len);</span>
<span class="line-removed"> 4384   %}</span>
<span class="line-removed"> 4385   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4386 %}</span>
<span class="line-removed"> 4387 </span>
<span class="line-removed"> 4388 instruct Repl4S_mem_evex(vecD dst, memory mem) %{</span>
<span class="line-removed"> 4389   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4390   match(Set dst (ReplicateS (LoadS mem)));</span>
<span class="line-removed"> 4391   format %{ &quot;vpbroadcastw  $dst,$mem\t! replicate4S&quot; %}</span>
<span class="line-removed"> 4392   ins_encode %{</span>
<span class="line-removed"> 4393     int vector_len = 0;</span>
<span class="line-removed"> 4394     __ vpbroadcastw($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4395   %}</span>
<span class="line-removed"> 4396   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4397 %}</span>
<span class="line-removed"> 4398 </span>
<span class="line-removed"> 4399 instruct Repl8S_evex(vecX dst, rRegI src) %{</span>
<span class="line-removed"> 4400   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4401   match(Set dst (ReplicateS src));</span>
<span class="line-removed"> 4402   format %{ &quot;evpbroadcastw $dst,$src\t! replicate8S&quot; %}</span>
<span class="line-removed"> 4403   ins_encode %{</span>
<span class="line-removed"> 4404    int vector_len = 0;</span>
<span class="line-removed"> 4405     __ evpbroadcastw($dst$$XMMRegister, $src$$Register, vector_len);</span>
<span class="line-removed"> 4406   %}</span>
<span class="line-removed"> 4407   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4408 %}</span>
<span class="line-removed"> 4409 </span>
<span class="line-removed"> 4410 instruct Repl8S_mem_evex(vecX dst, memory mem) %{</span>
<span class="line-removed"> 4411   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4412   match(Set dst (ReplicateS (LoadS mem)));</span>
<span class="line-removed"> 4413   format %{ &quot;vpbroadcastw  $dst,$mem\t! replicate8S&quot; %}</span>
<span class="line-removed"> 4414   ins_encode %{</span>
<span class="line-removed"> 4415     int vector_len = 0;</span>
<span class="line-removed"> 4416     __ vpbroadcastw($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4417   %}</span>
<span class="line-removed"> 4418   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4419 %}</span>
<span class="line-removed"> 4420 </span>
<span class="line-removed"> 4421 instruct Repl16S_evex(vecY dst, rRegI src) %{</span>
<span class="line-removed"> 4422   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4423   match(Set dst (ReplicateS src));</span>
<span class="line-removed"> 4424   format %{ &quot;evpbroadcastw $dst,$src\t! replicate16S&quot; %}</span>
<span class="line-removed"> 4425   ins_encode %{</span>
<span class="line-removed"> 4426    int vector_len = 1;</span>
<span class="line-removed"> 4427     __ evpbroadcastw($dst$$XMMRegister, $src$$Register, vector_len);</span>
<span class="line-removed"> 4428   %}</span>
<span class="line-removed"> 4429   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4430 %}</span>
<span class="line-removed"> 4431 </span>
<span class="line-removed"> 4432 instruct Repl16S_mem_evex(vecY dst, memory mem) %{</span>
<span class="line-removed"> 4433   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4434   match(Set dst (ReplicateS (LoadS mem)));</span>
<span class="line-removed"> 4435   format %{ &quot;vpbroadcastw  $dst,$mem\t! replicate16S&quot; %}</span>
<span class="line-removed"> 4436   ins_encode %{</span>
<span class="line-removed"> 4437     int vector_len = 1;</span>
<span class="line-removed"> 4438     __ vpbroadcastw($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4439   %}</span>
<span class="line-removed"> 4440   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4441 %}</span>
<span class="line-removed"> 4442 </span>
<span class="line-removed"> 4443 instruct Repl32S_evex(vecZ dst, rRegI src) %{</span>
<span class="line-removed"> 4444   predicate(n-&gt;as_Vector()-&gt;length() == 32 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw());</span>
<span class="line-removed"> 4445   match(Set dst (ReplicateS src));</span>
<span class="line-removed"> 4446   format %{ &quot;evpbroadcastw $dst,$src\t! replicate32S&quot; %}</span>
<span class="line-removed"> 4447   ins_encode %{</span>
<span class="line-removed"> 4448    int vector_len = 2;</span>
<span class="line-removed"> 4449     __ evpbroadcastw($dst$$XMMRegister, $src$$Register, vector_len);</span>
<span class="line-removed"> 4450   %}</span>
<span class="line-removed"> 4451   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4452 %}</span>
<span class="line-removed"> 4453 </span>
<span class="line-removed"> 4454 instruct Repl32S_mem_evex(vecZ dst, memory mem) %{</span>
<span class="line-removed"> 4455   predicate(n-&gt;as_Vector()-&gt;length() == 32 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw());</span>
<span class="line-removed"> 4456   match(Set dst (ReplicateS (LoadS mem)));</span>
<span class="line-removed"> 4457   format %{ &quot;vpbroadcastw  $dst,$mem\t! replicate32S&quot; %}</span>
<span class="line-removed"> 4458   ins_encode %{</span>
<span class="line-removed"> 4459     int vector_len = 2;</span>
<span class="line-removed"> 4460     __ vpbroadcastw($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4461   %}</span>
<span class="line-removed"> 4462   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4463 %}</span>
<span class="line-removed"> 4464 </span>
<span class="line-removed"> 4465 instruct Repl8S_imm_evex(vecX dst, immI con) %{</span>
<span class="line-removed"> 4466   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4467   match(Set dst (ReplicateS con));</span>
<span class="line-removed"> 4468   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 4469             &quot;vpbroadcastw $dst,$dst\t! replicate8S&quot; %}</span>
<span class="line-removed"> 4470   ins_encode %{</span>
<span class="line-removed"> 4471    int vector_len = 0;</span>
<span class="line-removed"> 4472     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 2)));</span>
<span class="line-removed"> 4473     __ vpbroadcastw($dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4474   %}</span>
<span class="line-removed"> 4475   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4476 %}</span>
<span class="line-removed"> 4477 </span>
<span class="line-removed"> 4478 instruct Repl16S_imm_evex(vecY dst, immI con) %{</span>
<span class="line-removed"> 4479   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vlbw());</span>
<span class="line-removed"> 4480   match(Set dst (ReplicateS con));</span>
<span class="line-removed"> 4481   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 4482             &quot;vpbroadcastw $dst,$dst\t! replicate16S&quot; %}</span>
<span class="line-removed"> 4483   ins_encode %{</span>
<span class="line-removed"> 4484    int vector_len = 1;</span>
<span class="line-removed"> 4485     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 2)));</span>
<span class="line-removed"> 4486     __ vpbroadcastw($dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4487   %}</span>
<span class="line-removed"> 4488   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4489 %}</span>
<span class="line-removed"> 4490 </span>
<span class="line-removed"> 4491 instruct Repl32S_imm_evex(vecZ dst, immI con) %{</span>
<span class="line-removed"> 4492   predicate(n-&gt;as_Vector()-&gt;length() == 32 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw());</span>
<span class="line-removed"> 4493   match(Set dst (ReplicateS con));</span>
<span class="line-removed"> 4494   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 4495             &quot;vpbroadcastw $dst,$dst\t! replicate32S&quot; %}</span>
<span class="line-removed"> 4496   ins_encode %{</span>
<span class="line-removed"> 4497    int vector_len = 2;</span>
<span class="line-removed"> 4498     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 2)));</span>
<span class="line-removed"> 4499     __ vpbroadcastw($dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4500   %}</span>
<span class="line-removed"> 4501   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4502 %}</span>
<span class="line-removed"> 4503 </span>
<span class="line-removed"> 4504 instruct Repl32S_zero_evex(vecZ dst, immI0 zero) %{</span>
<span class="line-removed"> 4505   predicate(n-&gt;as_Vector()-&gt;length() == 32 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4506   match(Set dst (ReplicateS zero));</span>
<span class="line-removed"> 4507   format %{ &quot;vpxor   $dst k0,$dst,$dst\t! replicate32S zero&quot; %}</span>
<span class="line-removed"> 4508   ins_encode %{</span>
<span class="line-removed"> 4509     // Use vxorpd since AVX does not have vpxor for 512-bit (EVEX will have it).</span>
<span class="line-removed"> 4510     int vector_len = 2;</span>
<span class="line-removed"> 4511     __ vpxor($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4512   %}</span>
<span class="line-removed"> 4513   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4514 %}</span>
<span class="line-removed"> 4515 </span>
<span class="line-removed"> 4516 instruct Repl4I_evex(vecX dst, rRegI src) %{</span>
<span class="line-removed"> 4517   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4518   match(Set dst (ReplicateI src));</span>
<span class="line-removed"> 4519   format %{ &quot;evpbroadcastd  $dst,$src\t! replicate4I&quot; %}</span>
<span class="line-removed"> 4520   ins_encode %{</span>
<span class="line-removed"> 4521     int vector_len = 0;</span>
<span class="line-removed"> 4522     __ evpbroadcastd($dst$$XMMRegister, $src$$Register, vector_len);</span>
<span class="line-removed"> 4523   %}</span>
<span class="line-removed"> 4524   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4525 %}</span>
<span class="line-removed"> 4526 </span>
<span class="line-removed"> 4527 instruct Repl4I_mem_evex(vecX dst, memory mem) %{</span>
<span class="line-removed"> 4528   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4529   match(Set dst (ReplicateI (LoadI mem)));</span>
<span class="line-removed"> 4530   format %{ &quot;vpbroadcastd  $dst,$mem\t! replicate4I&quot; %}</span>
<span class="line-removed"> 4531   ins_encode %{</span>
<span class="line-removed"> 4532     int vector_len = 0;</span>
<span class="line-removed"> 4533     __ vpbroadcastd($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4534   %}</span>
<span class="line-removed"> 4535   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4536 %}</span>
<span class="line-removed"> 4537 </span>
<span class="line-removed"> 4538 instruct Repl8I_evex(vecY dst, rRegI src) %{</span>
<span class="line-removed"> 4539   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4540   match(Set dst (ReplicateI src));</span>
<span class="line-removed"> 4541   format %{ &quot;evpbroadcastd  $dst,$src\t! replicate8I&quot; %}</span>
<span class="line-removed"> 4542   ins_encode %{</span>
<span class="line-removed"> 4543     int vector_len = 1;</span>
<span class="line-removed"> 4544     __ evpbroadcastd($dst$$XMMRegister, $src$$Register, vector_len);</span>
<span class="line-removed"> 4545   %}</span>
<span class="line-removed"> 4546   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4547 %}</span>
<span class="line-removed"> 4548 </span>
<span class="line-removed"> 4549 instruct Repl8I_mem_evex(vecY dst, memory mem) %{</span>
<span class="line-removed"> 4550   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4551   match(Set dst (ReplicateI (LoadI mem)));</span>
<span class="line-removed"> 4552   format %{ &quot;vpbroadcastd  $dst,$mem\t! replicate8I&quot; %}</span>
<span class="line-removed"> 4553   ins_encode %{</span>
<span class="line-removed"> 4554     int vector_len = 1;</span>
<span class="line-removed"> 4555     __ vpbroadcastd($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4556   %}</span>
<span class="line-removed"> 4557   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4558 %}</span>
<span class="line-removed"> 4559 </span>
<span class="line-removed"> 4560 instruct Repl16I_evex(vecZ dst, rRegI src) %{</span>
<span class="line-removed"> 4561   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4562   match(Set dst (ReplicateI src));</span>
<span class="line-removed"> 4563   format %{ &quot;evpbroadcastd  $dst,$src\t! replicate16I&quot; %}</span>
<span class="line-removed"> 4564   ins_encode %{</span>
<span class="line-removed"> 4565     int vector_len = 2;</span>
<span class="line-removed"> 4566     __ evpbroadcastd($dst$$XMMRegister, $src$$Register, vector_len);</span>
<span class="line-removed"> 4567   %}</span>
<span class="line-removed"> 4568   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4569 %}</span>
<span class="line-removed"> 4570 </span>
<span class="line-removed"> 4571 instruct Repl16I_mem_evex(vecZ dst, memory mem) %{</span>
<span class="line-removed"> 4572   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4573   match(Set dst (ReplicateI (LoadI mem)));</span>
<span class="line-removed"> 4574   format %{ &quot;vpbroadcastd  $dst,$mem\t! replicate16I&quot; %}</span>
<span class="line-removed"> 4575   ins_encode %{</span>
<span class="line-removed"> 4576     int vector_len = 2;</span>
<span class="line-removed"> 4577     __ vpbroadcastd($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4578   %}</span>
<span class="line-removed"> 4579   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4580 %}</span>
<span class="line-removed"> 4581 </span>
<span class="line-removed"> 4582 instruct Repl4I_imm_evex(vecX dst, immI con) %{</span>
<span class="line-removed"> 4583   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4584   match(Set dst (ReplicateI con));</span>
<span class="line-removed"> 4585   format %{ &quot;movq    $dst,[$constantaddress]\t! replicate8I($con)\n\t&quot;</span>
<span class="line-removed"> 4586             &quot;vpbroadcastd  $dst,$dst\t! replicate4I&quot; %}</span>
<span class="line-removed"> 4587   ins_encode %{</span>
<span class="line-removed"> 4588     int vector_len = 0;</span>
<span class="line-removed"> 4589     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 4)));</span>
<span class="line-removed"> 4590     __ vpbroadcastd($dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4591   %}</span>
<span class="line-removed"> 4592   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4593 %}</span>
<span class="line-removed"> 4594 </span>
<span class="line-removed"> 4595 instruct Repl8I_imm_evex(vecY dst, immI con) %{</span>
<span class="line-removed"> 4596   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4597   match(Set dst (ReplicateI con));</span>
<span class="line-removed"> 4598   format %{ &quot;movq    $dst,[$constantaddress]\t! replicate8I($con)\n\t&quot;</span>
<span class="line-removed"> 4599             &quot;vpbroadcastd  $dst,$dst\t! replicate8I&quot; %}</span>
<span class="line-removed"> 4600   ins_encode %{</span>
<span class="line-removed"> 4601     int vector_len = 1;</span>
<span class="line-removed"> 4602     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 4)));</span>
<span class="line-removed"> 4603     __ vpbroadcastd($dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4604   %}</span>
<span class="line-removed"> 4605   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4606 %}</span>
<span class="line-removed"> 4607 </span>
<span class="line-removed"> 4608 instruct Repl16I_imm_evex(vecZ dst, immI con) %{</span>
<span class="line-removed"> 4609   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4610   match(Set dst (ReplicateI con));</span>
<span class="line-removed"> 4611   format %{ &quot;movq    $dst,[$constantaddress]\t! replicate16I($con)\n\t&quot;</span>
<span class="line-removed"> 4612             &quot;vpbroadcastd  $dst,$dst\t! replicate16I&quot; %}</span>
<span class="line-removed"> 4613   ins_encode %{</span>
<span class="line-removed"> 4614     int vector_len = 2;</span>
<span class="line-removed"> 4615     __ movq($dst$$XMMRegister, $constantaddress(replicate8_imm($con$$constant, 4)));</span>
<span class="line-removed"> 4616     __ vpbroadcastd($dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4617   %}</span>
<span class="line-removed"> 4618   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4619 %}</span>
<span class="line-removed"> 4620 </span>
<span class="line-removed"> 4621 instruct Repl16I_zero_evex(vecZ dst, immI0 zero) %{</span>
<span class="line-removed"> 4622   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4623   match(Set dst (ReplicateI zero));</span>
<span class="line-removed"> 4624   format %{ &quot;vpxor   $dst k0,$dst,$dst\t! replicate16I zero&quot; %}</span>
<span class="line-removed"> 4625   ins_encode %{</span>
<span class="line-removed"> 4626     // Use vxorpd since AVX does not have vpxor for 512-bit (AVX2 will have it).</span>
<span class="line-removed"> 4627     int vector_len = 2;</span>
<span class="line-removed"> 4628     __ vpxor($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4629   %}</span>
<span class="line-removed"> 4630   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4631 %}</span>
<span class="line-removed"> 4632 </span>
<span class="line-removed"> 4633 // Replicate long (8 byte) scalar to be vector</span>
<span class="line-removed"> 4634 #ifdef _LP64</span>
<span class="line-removed"> 4635 instruct Repl4L_evex(vecY dst, rRegL src) %{</span>
<span class="line-removed"> 4636   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4637   match(Set dst (ReplicateL src));</span>
<span class="line-removed"> 4638   format %{ &quot;evpbroadcastq  $dst,$src\t! replicate4L&quot; %}</span>
<span class="line-removed"> 4639   ins_encode %{</span>
<span class="line-removed"> 4640     int vector_len = 1;</span>
<span class="line-removed"> 4641     __ evpbroadcastq($dst$$XMMRegister, $src$$Register, vector_len);</span>
<span class="line-removed"> 4642   %}</span>
<span class="line-removed"> 4643   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4644 %}</span>
<span class="line-removed"> 4645 </span>
<span class="line-removed"> 4646 instruct Repl8L_evex(vecZ dst, rRegL src) %{</span>
<span class="line-removed"> 4647   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4648   match(Set dst (ReplicateL src));</span>
<span class="line-removed"> 4649   format %{ &quot;evpbroadcastq  $dst,$src\t! replicate8L&quot; %}</span>
<span class="line-removed"> 4650   ins_encode %{</span>
<span class="line-removed"> 4651     int vector_len = 2;</span>
<span class="line-removed"> 4652     __ evpbroadcastq($dst$$XMMRegister, $src$$Register, vector_len);</span>
<span class="line-removed"> 4653   %}</span>
<span class="line-removed"> 4654   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4655 %}</span>
<span class="line-removed"> 4656 #else // _LP64</span>
<span class="line-removed"> 4657 instruct Repl4L_evex(vecY dst, eRegL src, regD tmp) %{</span>
<span class="line-removed"> 4658   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4659   match(Set dst (ReplicateL src));</span>
<span class="line-removed"> 4660   effect(TEMP dst, USE src, TEMP tmp);</span>
<span class="line-removed"> 4661   format %{ &quot;movdl   $dst,$src.lo\n\t&quot;</span>
<span class="line-removed"> 4662             &quot;movdl   $tmp,$src.hi\n\t&quot;</span>
<span class="line-removed"> 4663             &quot;punpckldq $dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 4664             &quot;vpbroadcastq  $dst,$dst\t! replicate4L&quot; %}</span>
<span class="line-removed"> 4665   ins_encode %{</span>
<span class="line-removed"> 4666     int vector_len = 1;</span>
<span class="line-removed"> 4667     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 4668     __ movdl($tmp$$XMMRegister, HIGH_FROM_LOW($src$$Register));</span>
<span class="line-removed"> 4669     __ punpckldq($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 4670     __ vpbroadcastq($dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4671   %}</span>
<span class="line-removed"> 4672   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4673 %}</span>
<span class="line-removed"> 4674 </span>
<span class="line-removed"> 4675 instruct Repl8L_evex(legVecZ dst, eRegL src, legVecZ tmp) %{</span>
<span class="line-removed"> 4676   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4677   match(Set dst (ReplicateL src));</span>
<span class="line-removed"> 4678   effect(TEMP dst, USE src, TEMP tmp);</span>
<span class="line-removed"> 4679   format %{ &quot;movdl   $dst,$src.lo\n\t&quot;</span>
<span class="line-removed"> 4680             &quot;movdl   $tmp,$src.hi\n\t&quot;</span>
<span class="line-removed"> 4681             &quot;punpckldq $dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 4682             &quot;vpbroadcastq  $dst,$dst\t! replicate8L&quot; %}</span>
<span class="line-removed"> 4683   ins_encode %{</span>
<span class="line-removed"> 4684     int vector_len = 2;</span>
<span class="line-removed"> 4685     __ movdl($dst$$XMMRegister, $src$$Register);</span>
<span class="line-removed"> 4686     __ movdl($tmp$$XMMRegister, HIGH_FROM_LOW($src$$Register));</span>
<span class="line-removed"> 4687     __ punpckldq($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 4688     __ vpbroadcastq($dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4689   %}</span>
<span class="line-removed"> 4690   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4691 %}</span>
<span class="line-removed"> 4692 #endif // _LP64</span>
<span class="line-removed"> 4693 </span>
<span class="line-removed"> 4694 instruct Repl4L_imm_evex(vecY dst, immL con) %{</span>
<span class="line-removed"> 4695   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4696   match(Set dst (ReplicateL con));</span>
<span class="line-removed"> 4697   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 4698             &quot;vpbroadcastq  $dst,$dst\t! replicate4L&quot; %}</span>
<span class="line-removed"> 4699   ins_encode %{</span>
<span class="line-removed"> 4700     int vector_len = 1;</span>
<span class="line-removed"> 4701     __ movq($dst$$XMMRegister, $constantaddress($con));</span>
<span class="line-removed"> 4702     __ vpbroadcastq($dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4703   %}</span>
<span class="line-removed"> 4704   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4705 %}</span>
<span class="line-removed"> 4706 </span>
<span class="line-removed"> 4707 instruct Repl8L_imm_evex(vecZ dst, immL con) %{</span>
<span class="line-removed"> 4708   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4709   match(Set dst (ReplicateL con));</span>
<span class="line-removed"> 4710   format %{ &quot;movq    $dst,[$constantaddress]\n\t&quot;</span>
<span class="line-removed"> 4711             &quot;vpbroadcastq  $dst,$dst\t! replicate8L&quot; %}</span>
<span class="line-removed"> 4712   ins_encode %{</span>
<span class="line-removed"> 4713     int vector_len = 2;</span>
<span class="line-removed"> 4714     __ movq($dst$$XMMRegister, $constantaddress($con));</span>
<span class="line-removed"> 4715     __ vpbroadcastq($dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4716   %}</span>
<span class="line-removed"> 4717   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4718 %}</span>
<span class="line-removed"> 4719 </span>
<span class="line-removed"> 4720 instruct Repl2L_mem_evex(vecX dst, memory mem) %{</span>
<span class="line-removed"> 4721   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4722   match(Set dst (ReplicateL (LoadL mem)));</span>
<span class="line-removed"> 4723   format %{ &quot;vpbroadcastd  $dst,$mem\t! replicate2L&quot; %}</span>
<span class="line-removed"> 4724   ins_encode %{</span>
<span class="line-removed"> 4725     int vector_len = 0;</span>
<span class="line-removed"> 4726     __ vpbroadcastq($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4727   %}</span>
<span class="line-removed"> 4728   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4729 %}</span>
<span class="line-removed"> 4730 </span>
<span class="line-removed"> 4731 instruct Repl4L_mem_evex(vecY dst, memory mem) %{</span>
<span class="line-removed"> 4732   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4733   match(Set dst (ReplicateL (LoadL mem)));</span>
<span class="line-removed"> 4734   format %{ &quot;vpbroadcastd  $dst,$mem\t! replicate4L&quot; %}</span>
<span class="line-removed"> 4735   ins_encode %{</span>
<span class="line-removed"> 4736     int vector_len = 1;</span>
<span class="line-removed"> 4737     __ vpbroadcastq($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4738   %}</span>
<span class="line-removed"> 4739   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4740 %}</span>
<span class="line-removed"> 4741 </span>
<span class="line-removed"> 4742 instruct Repl8L_mem_evex(vecZ dst, memory mem) %{</span>
<span class="line-removed"> 4743   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4744   match(Set dst (ReplicateL (LoadL mem)));</span>
<span class="line-removed"> 4745   format %{ &quot;vpbroadcastd  $dst,$mem\t! replicate8L&quot; %}</span>
<span class="line-removed"> 4746   ins_encode %{</span>
<span class="line-removed"> 4747     int vector_len = 2;</span>
<span class="line-removed"> 4748     __ vpbroadcastq($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4749   %}</span>
<span class="line-removed"> 4750   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4751 %}</span>
<span class="line-removed"> 4752 </span>
<span class="line-removed"> 4753 instruct Repl8L_zero_evex(vecZ dst, immL0 zero) %{</span>
<span class="line-removed"> 4754   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4755   match(Set dst (ReplicateL zero));</span>
<span class="line-removed"> 4756   format %{ &quot;vpxor   $dst k0,$dst,$dst\t! replicate8L zero&quot; %}</span>
<span class="line-removed"> 4757   ins_encode %{</span>
<span class="line-removed"> 4758     // Use vxorpd since AVX does not have vpxor for 512-bit (EVEX will have it).</span>
<span class="line-removed"> 4759     int vector_len = 2;</span>
<span class="line-removed"> 4760     __ vpxor($dst$$XMMRegister,$dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4761   %}</span>
<span class="line-removed"> 4762   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4763 %}</span>
<span class="line-removed"> 4764 </span>
<span class="line-removed"> 4765 instruct Repl8F_evex(vecY dst, regF src) %{</span>
<span class="line-removed"> 4766   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4767   match(Set dst (ReplicateF src));</span>
<span class="line-removed"> 4768   format %{ &quot;vpbroadcastss $dst,$src\t! replicate8F&quot; %}</span>
<span class="line-removed"> 4769   ins_encode %{</span>
<span class="line-removed"> 4770     int vector_len = 1;</span>
<span class="line-removed"> 4771     __ vpbroadcastss($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4772   %}</span>
<span class="line-removed"> 4773   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4774 %}</span>
<span class="line-removed"> 4775 </span>
<span class="line-removed"> 4776 instruct Repl8F_mem_evex(vecY dst, memory mem) %{</span>
<span class="line-removed"> 4777   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4778   match(Set dst (ReplicateF (LoadF mem)));</span>
<span class="line-removed"> 4779   format %{ &quot;vbroadcastss  $dst,$mem\t! replicate8F&quot; %}</span>
<span class="line-removed"> 4780   ins_encode %{</span>
<span class="line-removed"> 4781     int vector_len = 1;</span>
<span class="line-removed"> 4782     __ vpbroadcastss($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4783   %}</span>
<span class="line-removed"> 4784   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4785 %}</span>
<span class="line-removed"> 4786 </span>
<span class="line-removed"> 4787 instruct Repl16F_evex(vecZ dst, regF src) %{</span>
<span class="line-removed"> 4788   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4789   match(Set dst (ReplicateF src));</span>
<span class="line-removed"> 4790   format %{ &quot;vpbroadcastss $dst,$src\t! replicate16F&quot; %}</span>
<span class="line-removed"> 4791   ins_encode %{</span>
<span class="line-removed"> 4792     int vector_len = 2;</span>
<span class="line-removed"> 4793     __ vpbroadcastss($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4794   %}</span>
<span class="line-removed"> 4795   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4796 %}</span>
<span class="line-removed"> 4797 </span>
<span class="line-removed"> 4798 instruct Repl16F_mem_evex(vecZ dst, memory mem) %{</span>
<span class="line-removed"> 4799   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4800   match(Set dst (ReplicateF (LoadF mem)));</span>
<span class="line-removed"> 4801   format %{ &quot;vbroadcastss  $dst,$mem\t! replicate16F&quot; %}</span>
<span class="line-removed"> 4802   ins_encode %{</span>
<span class="line-removed"> 4803     int vector_len = 2;</span>
<span class="line-removed"> 4804     __ vpbroadcastss($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4805   %}</span>
<span class="line-removed"> 4806   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4807 %}</span>
<span class="line-removed"> 4808 </span>
<span class="line-removed"> 4809 instruct Repl2F_zero_evex(vecD dst, immF0 zero) %{</span>
<span class="line-removed"> 4810   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4811   match(Set dst (ReplicateF zero));</span>
<span class="line-removed"> 4812   format %{ &quot;vpxor  $dst k0,$dst,$dst\t! replicate2F zero&quot; %}</span>
<span class="line-removed"> 4813   ins_encode %{</span>
<span class="line-removed"> 4814     // Use vpxor in place of vxorps since EVEX has a constriant on dq for vxorps: this is a 512-bit operation</span>
<span class="line-removed"> 4815     int vector_len = 2;</span>
<span class="line-removed"> 4816     __ vpxor($dst$$XMMRegister,$dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4817   %}</span>
<span class="line-removed"> 4818   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4819 %}</span>
<span class="line-removed"> 4820 </span>
<span class="line-removed"> 4821 instruct Repl4F_zero_evex(vecX dst, immF0 zero) %{</span>
<span class="line-removed"> 4822   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4823   match(Set dst (ReplicateF zero));</span>
<span class="line-removed"> 4824   format %{ &quot;vpxor  $dst k0,$dst,$dst\t! replicate4F zero&quot; %}</span>
<span class="line-removed"> 4825   ins_encode %{</span>
<span class="line-removed"> 4826     // Use vpxor in place of vxorps since EVEX has a constriant on dq for vxorps: this is a 512-bit operation</span>
<span class="line-removed"> 4827     int vector_len = 2;</span>
<span class="line-removed"> 4828     __ vpxor($dst$$XMMRegister,$dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4829   %}</span>
<span class="line-removed"> 4830   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4831 %}</span>
<span class="line-removed"> 4832 </span>
<span class="line-removed"> 4833 instruct Repl8F_zero_evex(vecY dst, immF0 zero) %{</span>
<span class="line-removed"> 4834   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4835   match(Set dst (ReplicateF zero));</span>
<span class="line-removed"> 4836   format %{ &quot;vpxor  $dst k0,$dst,$dst\t! replicate8F zero&quot; %}</span>
<span class="line-removed"> 4837   ins_encode %{</span>
<span class="line-removed"> 4838     // Use vpxor in place of vxorps since EVEX has a constriant on dq for vxorps: this is a 512-bit operation</span>
<span class="line-removed"> 4839     int vector_len = 2;</span>
<span class="line-removed"> 4840     __ vpxor($dst$$XMMRegister,$dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4841   %}</span>
<span class="line-removed"> 4842   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4843 %}</span>
<span class="line-removed"> 4844 </span>
<span class="line-removed"> 4845 instruct Repl16F_zero_evex(vecZ dst, immF0 zero) %{</span>
<span class="line-removed"> 4846   predicate(n-&gt;as_Vector()-&gt;length() == 16 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4847   match(Set dst (ReplicateF zero));</span>
<span class="line-removed"> 4848   format %{ &quot;vpxor  $dst k0,$dst,$dst\t! replicate16F zero&quot; %}</span>
<span class="line-removed"> 4849   ins_encode %{</span>
<span class="line-removed"> 4850     // Use vpxor in place of vxorps since EVEX has a constriant on dq for vxorps: this is a 512-bit operation</span>
<span class="line-removed"> 4851     int vector_len = 2;</span>
<span class="line-removed"> 4852     __ vpxor($dst$$XMMRegister,$dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4853   %}</span>
<span class="line-removed"> 4854   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4855 %}</span>
<span class="line-removed"> 4856 </span>
<span class="line-removed"> 4857 instruct Repl4D_evex(vecY dst, regD src) %{</span>
<span class="line-removed"> 4858   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4859   match(Set dst (ReplicateD src));</span>
<span class="line-removed"> 4860   format %{ &quot;vpbroadcastsd $dst,$src\t! replicate4D&quot; %}</span>
<span class="line-removed"> 4861   ins_encode %{</span>
<span class="line-removed"> 4862     int vector_len = 1;</span>
<span class="line-removed"> 4863     __ vpbroadcastsd($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4864   %}</span>
<span class="line-removed"> 4865   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4866 %}</span>
<span class="line-removed"> 4867 </span>
<span class="line-removed"> 4868 instruct Repl4D_mem_evex(vecY dst, memory mem) %{</span>
<span class="line-removed"> 4869   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512vl());</span>
<span class="line-removed"> 4870   match(Set dst (ReplicateD (LoadD mem)));</span>
<span class="line-removed"> 4871   format %{ &quot;vbroadcastsd  $dst,$mem\t! replicate4D&quot; %}</span>
<span class="line-removed"> 4872   ins_encode %{</span>
<span class="line-removed"> 4873     int vector_len = 1;</span>
<span class="line-removed"> 4874     __ vpbroadcastsd($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4875   %}</span>
<span class="line-removed"> 4876   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4877 %}</span>
<span class="line-removed"> 4878 </span>
<span class="line-removed"> 4879 instruct Repl8D_evex(vecZ dst, regD src) %{</span>
<span class="line-removed"> 4880   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4881   match(Set dst (ReplicateD src));</span>
<span class="line-removed"> 4882   format %{ &quot;vpbroadcastsd $dst,$src\t! replicate8D&quot; %}</span>
<span class="line-removed"> 4883   ins_encode %{</span>
<span class="line-removed"> 4884     int vector_len = 2;</span>
<span class="line-removed"> 4885     __ vpbroadcastsd($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4886   %}</span>
<span class="line-removed"> 4887   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4888 %}</span>
<span class="line-removed"> 4889 </span>
<span class="line-removed"> 4890 instruct Repl8D_mem_evex(vecZ dst, memory mem) %{</span>
<span class="line-removed"> 4891   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4892   match(Set dst (ReplicateD (LoadD mem)));</span>
<span class="line-removed"> 4893   format %{ &quot;vbroadcastsd  $dst,$mem\t! replicate8D&quot; %}</span>
<span class="line-removed"> 4894   ins_encode %{</span>
<span class="line-removed"> 4895     int vector_len = 2;</span>
<span class="line-removed"> 4896     __ vpbroadcastsd($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 4897   %}</span>
<span class="line-removed"> 4898   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4899 %}</span>
<span class="line-removed"> 4900 </span>
<span class="line-removed"> 4901 instruct Repl2D_zero_evex(vecX dst, immD0 zero) %{</span>
<span class="line-removed"> 4902   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4903   match(Set dst (ReplicateD zero));</span>
<span class="line-removed"> 4904   format %{ &quot;vpxor  $dst k0,$dst,$dst\t! replicate2D zero&quot; %}</span>
<span class="line-removed"> 4905   ins_encode %{</span>
<span class="line-removed"> 4906     // Use vpxor in place of vxorpd since EVEX has a constriant on dq for vxorpd: this is a 512-bit operation</span>
<span class="line-removed"> 4907     int vector_len = 2;</span>
<span class="line-removed"> 4908     __ vpxor($dst$$XMMRegister,$dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4909   %}</span>
<span class="line-removed"> 4910   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4911 %}</span>
<span class="line-removed"> 4912 </span>
<span class="line-removed"> 4913 instruct Repl4D_zero_evex(vecY dst, immD0 zero) %{</span>
<span class="line-removed"> 4914   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4915   match(Set dst (ReplicateD zero));</span>
<span class="line-removed"> 4916   format %{ &quot;vpxor  $dst k0,$dst,$dst\t! replicate4D zero&quot; %}</span>
<span class="line-removed"> 4917   ins_encode %{</span>
<span class="line-removed"> 4918     // Use vpxor in place of vxorpd since EVEX has a constriant on dq for vxorpd: this is a 512-bit operation</span>
<span class="line-removed"> 4919     int vector_len = 2;</span>
<span class="line-removed"> 4920     __ vpxor($dst$$XMMRegister,$dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4921   %}</span>
<span class="line-removed"> 4922   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4923 %}</span>
<span class="line-removed"> 4924 </span>
<span class="line-removed"> 4925 instruct Repl8D_zero_evex(vecZ dst, immD0 zero) %{</span>
<span class="line-removed"> 4926   predicate(n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; UseAVX &gt; 2);</span>
<span class="line-removed"> 4927   match(Set dst (ReplicateD zero));</span>
<span class="line-removed"> 4928   format %{ &quot;vpxor  $dst k0,$dst,$dst,vect512\t! replicate8D zero&quot; %}</span>
<span class="line-removed"> 4929   ins_encode %{</span>
<span class="line-removed"> 4930     // Use vpxor in place of vxorpd since EVEX has a constriant on dq for vxorpd: this is a 512-bit operation</span>
<span class="line-removed"> 4931     int vector_len = 2;</span>
<span class="line-removed"> 4932     __ vpxor($dst$$XMMRegister,$dst$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4933   %}</span>
<span class="line-removed"> 4934   ins_pipe( fpu_reg_reg );</span>
<span class="line-removed"> 4935 %}</span>
<span class="line-removed"> 4936 </span>
<span class="line-removed"> 4937 // ====================REDUCTION ARITHMETIC=======================================</span>
<span class="line-removed"> 4938 </span>
<span class="line-removed"> 4939 instruct rsadd2I_reduction_reg(rRegI dst, rRegI src1, vecD src2, vecD tmp, vecD tmp2) %{</span>
<span class="line-removed"> 4940   predicate(UseSSE &gt; 2 &amp;&amp; UseAVX == 0);</span>
<span class="line-removed"> 4941   match(Set dst (AddReductionVI src1 src2));</span>
<span class="line-removed"> 4942   effect(TEMP tmp2, TEMP tmp);</span>
<span class="line-removed"> 4943   format %{ &quot;movdqu  $tmp2,$src2\n\t&quot;</span>
<span class="line-removed"> 4944             &quot;phaddd  $tmp2,$tmp2\n\t&quot;</span>
<span class="line-removed"> 4945             &quot;movd    $tmp,$src1\n\t&quot;</span>
<span class="line-removed"> 4946             &quot;paddd   $tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 4947             &quot;movd    $dst,$tmp\t! add reduction2I&quot; %}</span>
<span class="line-removed"> 4948   ins_encode %{</span>
<span class="line-removed"> 4949     __ movdqu($tmp2$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 4950     __ phaddd($tmp2$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 4951     __ movdl($tmp$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 4952     __ paddd($tmp$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 4953     __ movdl($dst$$Register, $tmp$$XMMRegister);</span>
<span class="line-removed"> 4954   %}</span>
<span class="line-removed"> 4955   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4956 %}</span>
<span class="line-removed"> 4957 </span>
<span class="line-removed"> 4958 instruct rvadd2I_reduction_reg(rRegI dst, rRegI src1, vecD src2, vecD tmp, vecD tmp2) %{</span>
<span class="line-removed"> 4959   predicate(VM_Version::supports_avxonly());</span>
<span class="line-removed"> 4960   match(Set dst (AddReductionVI src1 src2));</span>
<span class="line-removed"> 4961   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 4962   format %{ &quot;vphaddd  $tmp,$src2,$src2\n\t&quot;</span>
<span class="line-removed"> 4963             &quot;movd     $tmp2,$src1\n\t&quot;</span>
<span class="line-removed"> 4964             &quot;vpaddd   $tmp2,$tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 4965             &quot;movd     $dst,$tmp2\t! add reduction2I&quot; %}</span>
<span class="line-removed"> 4966   ins_encode %{</span>
<span class="line-removed"> 4967     int vector_len = 0;</span>
<span class="line-removed"> 4968     __ vphaddd($tmp$$XMMRegister, $src2$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4969     __ movdl($tmp2$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 4970     __ vpaddd($tmp2$$XMMRegister, $tmp2$$XMMRegister, $tmp$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4971     __ movdl($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 4972   %}</span>
<span class="line-removed"> 4973   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4974 %}</span>
<span class="line-removed"> 4975 </span>
<span class="line-removed"> 4976 instruct rvadd2I_reduction_reg_evex(rRegI dst, rRegI src1, vecD src2, vecD tmp, vecD tmp2) %{</span>
<span class="line-removed"> 4977   predicate(UseAVX &gt; 2);</span>
<span class="line-removed"> 4978   match(Set dst (AddReductionVI src1 src2));</span>
<span class="line-removed"> 4979   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 4980   format %{ &quot;pshufd  $tmp2,$src2,0x1\n\t&quot;</span>
<span class="line-removed"> 4981             &quot;vpaddd  $tmp,$src2,$tmp2\n\t&quot;</span>
<span class="line-removed"> 4982             &quot;movd    $tmp2,$src1\n\t&quot;</span>
<span class="line-removed"> 4983             &quot;vpaddd  $tmp2,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 4984             &quot;movd    $dst,$tmp2\t! add reduction2I&quot; %}</span>
<span class="line-removed"> 4985   ins_encode %{</span>
<span class="line-removed"> 4986     int vector_len = 0;</span>
<span class="line-removed"> 4987     __ pshufd($tmp2$$XMMRegister, $src2$$XMMRegister, 0x1);</span>
<span class="line-removed"> 4988     __ vpaddd($tmp$$XMMRegister, $src2$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4989     __ movdl($tmp2$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 4990     __ vpaddd($tmp2$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 4991     __ movdl($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 4992   %}</span>
<span class="line-removed"> 4993   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 4994 %}</span>
<span class="line-removed"> 4995 </span>
<span class="line-removed"> 4996 instruct rsadd4I_reduction_reg(rRegI dst, rRegI src1, vecX src2, vecX tmp, vecX tmp2) %{</span>
<span class="line-removed"> 4997   predicate(UseSSE &gt; 2 &amp;&amp; UseAVX == 0);</span>
<span class="line-removed"> 4998   match(Set dst (AddReductionVI src1 src2));</span>
<span class="line-removed"> 4999   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5000   format %{ &quot;movdqu  $tmp,$src2\n\t&quot;</span>
<span class="line-removed"> 5001             &quot;phaddd  $tmp,$tmp\n\t&quot;</span>
<span class="line-removed"> 5002             &quot;phaddd  $tmp,$tmp\n\t&quot;</span>
<span class="line-removed"> 5003             &quot;movd    $tmp2,$src1\n\t&quot;</span>
<span class="line-removed"> 5004             &quot;paddd   $tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5005             &quot;movd    $dst,$tmp2\t! add reduction4I&quot; %}</span>
<span class="line-removed"> 5006   ins_encode %{</span>
<span class="line-removed"> 5007     __ movdqu($tmp$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5008     __ phaddd($tmp$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5009     __ phaddd($tmp$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5010     __ movdl($tmp2$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5011     __ paddd($tmp2$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5012     __ movdl($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5013   %}</span>
<span class="line-removed"> 5014   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5015 %}</span>
<span class="line-removed"> 5016 </span>
<span class="line-removed"> 5017 instruct rvadd4I_reduction_reg(rRegI dst, rRegI src1, vecX src2, vecX tmp, vecX tmp2) %{</span>
<span class="line-removed"> 5018   predicate(VM_Version::supports_avxonly());</span>
<span class="line-removed"> 5019   match(Set dst (AddReductionVI src1 src2));</span>
<span class="line-removed"> 5020   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5021   format %{ &quot;vphaddd  $tmp,$src2,$src2\n\t&quot;</span>
<span class="line-removed"> 5022             &quot;vphaddd  $tmp,$tmp,$tmp\n\t&quot;</span>
<span class="line-removed"> 5023             &quot;movd     $tmp2,$src1\n\t&quot;</span>
<span class="line-removed"> 5024             &quot;vpaddd   $tmp2,$tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5025             &quot;movd     $dst,$tmp2\t! add reduction4I&quot; %}</span>
<span class="line-removed"> 5026   ins_encode %{</span>
<span class="line-removed"> 5027     int vector_len = 0;</span>
<span class="line-removed"> 5028     __ vphaddd($tmp$$XMMRegister, $src2$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5029     __ vphaddd($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5030     __ movdl($tmp2$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5031     __ vpaddd($tmp2$$XMMRegister, $tmp2$$XMMRegister, $tmp$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5032     __ movdl($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5033   %}</span>
<span class="line-removed"> 5034   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5035 %}</span>
<span class="line-removed"> 5036 </span>
<span class="line-removed"> 5037 instruct rvadd4I_reduction_reg_evex(rRegI dst, rRegI src1, vecX src2, vecX tmp, vecX tmp2) %{</span>
<span class="line-removed"> 5038   predicate(UseAVX &gt; 2);</span>
<span class="line-removed"> 5039   match(Set dst (AddReductionVI src1 src2));</span>
<span class="line-removed"> 5040   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5041   format %{ &quot;pshufd  $tmp2,$src2,0xE\n\t&quot;</span>
<span class="line-removed"> 5042             &quot;vpaddd  $tmp,$src2,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5043             &quot;pshufd  $tmp2,$tmp,0x1\n\t&quot;</span>
<span class="line-removed"> 5044             &quot;vpaddd  $tmp,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5045             &quot;movd    $tmp2,$src1\n\t&quot;</span>
<span class="line-removed"> 5046             &quot;vpaddd  $tmp2,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5047             &quot;movd    $dst,$tmp2\t! add reduction4I&quot; %}</span>
<span class="line-removed"> 5048   ins_encode %{</span>
<span class="line-removed"> 5049     int vector_len = 0;</span>
<span class="line-removed"> 5050     __ pshufd($tmp2$$XMMRegister, $src2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5051     __ vpaddd($tmp$$XMMRegister, $src2$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5052     __ pshufd($tmp2$$XMMRegister, $tmp$$XMMRegister, 0x1);</span>
<span class="line-removed"> 5053     __ vpaddd($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5054     __ movdl($tmp2$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5055     __ vpaddd($tmp2$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5056     __ movdl($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5057   %}</span>
<span class="line-removed"> 5058   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5059 %}</span>
<span class="line-removed"> 5060 </span>
<span class="line-removed"> 5061 instruct rvadd8I_reduction_reg(rRegI dst, rRegI src1, vecY src2, vecY tmp, vecY tmp2) %{</span>
<span class="line-removed"> 5062   predicate(VM_Version::supports_avxonly());</span>
<span class="line-removed"> 5063   match(Set dst (AddReductionVI src1 src2));</span>
<span class="line-removed"> 5064   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5065   format %{ &quot;vphaddd  $tmp,$src2,$src2\n\t&quot;</span>
<span class="line-removed"> 5066             &quot;vphaddd  $tmp,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5067             &quot;vextracti128_high  $tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5068             &quot;vpaddd   $tmp,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5069             &quot;movd     $tmp2,$src1\n\t&quot;</span>
<span class="line-removed"> 5070             &quot;vpaddd   $tmp2,$tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5071             &quot;movd     $dst,$tmp2\t! add reduction8I&quot; %}</span>
<span class="line-removed"> 5072   ins_encode %{</span>
<span class="line-removed"> 5073     int vector_len = 1;</span>
<span class="line-removed"> 5074     __ vphaddd($tmp$$XMMRegister, $src2$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5075     __ vphaddd($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5076     __ vextracti128_high($tmp2$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5077     __ vpaddd($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, 0);</span>
<span class="line-removed"> 5078     __ movdl($tmp2$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5079     __ vpaddd($tmp2$$XMMRegister, $tmp2$$XMMRegister, $tmp$$XMMRegister, 0);</span>
<span class="line-removed"> 5080     __ movdl($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5081   %}</span>
<span class="line-removed"> 5082   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5083 %}</span>
<span class="line-removed"> 5084 </span>
<span class="line-removed"> 5085 instruct rvadd8I_reduction_reg_evex(rRegI dst, rRegI src1, vecY src2, vecY tmp, vecY tmp2) %{</span>
<span class="line-removed"> 5086   predicate(UseAVX &gt; 2);</span>
<span class="line-removed"> 5087   match(Set dst (AddReductionVI src1 src2));</span>
<span class="line-removed"> 5088   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5089   format %{ &quot;vextracti128_high  $tmp,$src2\n\t&quot;</span>
<span class="line-removed"> 5090             &quot;vpaddd  $tmp,$tmp,$src2\n\t&quot;</span>
<span class="line-removed"> 5091             &quot;pshufd  $tmp2,$tmp,0xE\n\t&quot;</span>
<span class="line-removed"> 5092             &quot;vpaddd  $tmp,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5093             &quot;pshufd  $tmp2,$tmp,0x1\n\t&quot;</span>
<span class="line-removed"> 5094             &quot;vpaddd  $tmp,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5095             &quot;movd    $tmp2,$src1\n\t&quot;</span>
<span class="line-removed"> 5096             &quot;vpaddd  $tmp2,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5097             &quot;movd    $dst,$tmp2\t! add reduction8I&quot; %}</span>
<span class="line-removed"> 5098   ins_encode %{</span>
<span class="line-removed"> 5099     int vector_len = 0;</span>
<span class="line-removed"> 5100     __ vextracti128_high($tmp$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5101     __ vpaddd($tmp$$XMMRegister, $tmp$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5102     __ pshufd($tmp2$$XMMRegister, $tmp$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5103     __ vpaddd($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5104     __ pshufd($tmp2$$XMMRegister, $tmp$$XMMRegister, 0x1);</span>
<span class="line-removed"> 5105     __ vpaddd($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5106     __ movdl($tmp2$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5107     __ vpaddd($tmp2$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5108     __ movdl($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5109   %}</span>
<span class="line-removed"> 5110   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5111 %}</span>
<span class="line-removed"> 5112 </span>
<span class="line-removed"> 5113 instruct rvadd16I_reduction_reg_evex(rRegI dst, rRegI src1, legVecZ src2, legVecZ tmp, legVecZ tmp2, legVecZ tmp3) %{</span>
<span class="line-removed"> 5114   predicate(UseAVX &gt; 2);</span>
<span class="line-removed"> 5115   match(Set dst (AddReductionVI src1 src2));</span>
<span class="line-removed"> 5116   effect(TEMP tmp, TEMP tmp2, TEMP tmp3);</span>
<span class="line-removed"> 5117   format %{ &quot;vextracti64x4_high  $tmp3,$src2\n\t&quot;</span>
<span class="line-removed"> 5118             &quot;vpaddd  $tmp3,$tmp3,$src2\n\t&quot;</span>
<span class="line-removed"> 5119             &quot;vextracti128_high  $tmp,$tmp3\n\t&quot;</span>
<span class="line-removed"> 5120             &quot;vpaddd  $tmp,$tmp,$tmp3\n\t&quot;</span>
<span class="line-removed"> 5121             &quot;pshufd  $tmp2,$tmp,0xE\n\t&quot;</span>
<span class="line-removed"> 5122             &quot;vpaddd  $tmp,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5123             &quot;pshufd  $tmp2,$tmp,0x1\n\t&quot;</span>
<span class="line-removed"> 5124             &quot;vpaddd  $tmp,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5125             &quot;movd    $tmp2,$src1\n\t&quot;</span>
<span class="line-removed"> 5126             &quot;vpaddd  $tmp2,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5127             &quot;movd    $dst,$tmp2\t! mul reduction16I&quot; %}</span>
<span class="line-removed"> 5128   ins_encode %{</span>
<span class="line-removed"> 5129     __ vextracti64x4_high($tmp3$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5130     __ vpaddd($tmp3$$XMMRegister, $tmp3$$XMMRegister, $src2$$XMMRegister, 1);</span>
<span class="line-removed"> 5131     __ vextracti128_high($tmp$$XMMRegister, $tmp3$$XMMRegister);</span>
<span class="line-removed"> 5132     __ vpaddd($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp3$$XMMRegister, 0);</span>
<span class="line-removed"> 5133     __ pshufd($tmp2$$XMMRegister, $tmp$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5134     __ vpaddd($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, 0);</span>
<span class="line-removed"> 5135     __ pshufd($tmp2$$XMMRegister, $tmp$$XMMRegister, 0x1);</span>
<span class="line-removed"> 5136     __ vpaddd($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, 0);</span>
<span class="line-removed"> 5137     __ movdl($tmp2$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5138     __ vpaddd($tmp2$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, 0);</span>
<span class="line-removed"> 5139     __ movdl($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5140   %}</span>
<span class="line-removed"> 5141   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5142 %}</span>
<span class="line-removed"> 5143 </span>
<span class="line-removed"> 5144 #ifdef _LP64</span>
<span class="line-removed"> 5145 instruct rvadd2L_reduction_reg(rRegL dst, rRegL src1, vecX src2, vecX tmp, vecX tmp2) %{</span>
<span class="line-removed"> 5146   predicate(UseAVX &gt; 2);</span>
<span class="line-removed"> 5147   match(Set dst (AddReductionVL src1 src2));</span>
<span class="line-removed"> 5148   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5149   format %{ &quot;pshufd  $tmp2,$src2,0xE\n\t&quot;</span>
<span class="line-removed"> 5150             &quot;vpaddq  $tmp,$src2,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5151             &quot;movdq   $tmp2,$src1\n\t&quot;</span>
<span class="line-removed"> 5152             &quot;vpaddq  $tmp2,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5153             &quot;movdq   $dst,$tmp2\t! add reduction2L&quot; %}</span>
<span class="line-removed"> 5154   ins_encode %{</span>
<span class="line-removed"> 5155     __ pshufd($tmp2$$XMMRegister, $src2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5156     __ vpaddq($tmp$$XMMRegister, $src2$$XMMRegister, $tmp2$$XMMRegister, 0);</span>
<span class="line-removed"> 5157     __ movdq($tmp2$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5158     __ vpaddq($tmp2$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, 0);</span>
<span class="line-removed"> 5159     __ movdq($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5160   %}</span>
<span class="line-removed"> 5161   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5162 %}</span>
<span class="line-removed"> 5163 </span>
<span class="line-removed"> 5164 instruct rvadd4L_reduction_reg(rRegL dst, rRegL src1, vecY src2, vecY tmp, vecY tmp2) %{</span>
<span class="line-removed"> 5165   predicate(UseAVX &gt; 2);</span>
<span class="line-removed"> 5166   match(Set dst (AddReductionVL src1 src2));</span>
<span class="line-removed"> 5167   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5168   format %{ &quot;vextracti128_high  $tmp,$src2\n\t&quot;</span>
<span class="line-removed"> 5169             &quot;vpaddq  $tmp2,$tmp,$src2\n\t&quot;</span>
<span class="line-removed"> 5170             &quot;pshufd  $tmp,$tmp2,0xE\n\t&quot;</span>
<span class="line-removed"> 5171             &quot;vpaddq  $tmp2,$tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5172             &quot;movdq   $tmp,$src1\n\t&quot;</span>
<span class="line-removed"> 5173             &quot;vpaddq  $tmp2,$tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5174             &quot;movdq   $dst,$tmp2\t! add reduction4L&quot; %}</span>
<span class="line-removed"> 5175   ins_encode %{</span>
<span class="line-removed"> 5176     __ vextracti128_high($tmp$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5177     __ vpaddq($tmp2$$XMMRegister, $tmp$$XMMRegister, $src2$$XMMRegister, 0);</span>
<span class="line-removed"> 5178     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5179     __ vpaddq($tmp2$$XMMRegister, $tmp2$$XMMRegister, $tmp$$XMMRegister, 0);</span>
<span class="line-removed"> 5180     __ movdq($tmp$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5181     __ vpaddq($tmp2$$XMMRegister, $tmp2$$XMMRegister, $tmp$$XMMRegister, 0);</span>
<span class="line-removed"> 5182     __ movdq($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5183   %}</span>
<span class="line-removed"> 5184   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5185 %}</span>
<span class="line-removed"> 5186 </span>
<span class="line-removed"> 5187 instruct rvadd8L_reduction_reg(rRegL dst, rRegL src1, legVecZ src2, legVecZ tmp, legVecZ tmp2) %{</span>
<span class="line-removed"> 5188   predicate(UseAVX &gt; 2);</span>
<span class="line-removed"> 5189   match(Set dst (AddReductionVL src1 src2));</span>
<span class="line-removed"> 5190   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5191   format %{ &quot;vextracti64x4_high  $tmp2,$src2\n\t&quot;</span>
<span class="line-removed"> 5192             &quot;vpaddq  $tmp2,$tmp2,$src2\n\t&quot;</span>
<span class="line-removed"> 5193             &quot;vextracti128_high  $tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5194             &quot;vpaddq  $tmp2,$tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5195             &quot;pshufd  $tmp,$tmp2,0xE\n\t&quot;</span>
<span class="line-removed"> 5196             &quot;vpaddq  $tmp2,$tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5197             &quot;movdq   $tmp,$src1\n\t&quot;</span>
<span class="line-removed"> 5198             &quot;vpaddq  $tmp2,$tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5199             &quot;movdq   $dst,$tmp2\t! add reduction8L&quot; %}</span>
<span class="line-removed"> 5200   ins_encode %{</span>
<span class="line-removed"> 5201     __ vextracti64x4_high($tmp2$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5202     __ vpaddq($tmp2$$XMMRegister, $tmp2$$XMMRegister, $src2$$XMMRegister, 1);</span>
<span class="line-removed"> 5203     __ vextracti128_high($tmp$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5204     __ vpaddq($tmp2$$XMMRegister, $tmp2$$XMMRegister, $tmp$$XMMRegister, 0);</span>
<span class="line-removed"> 5205     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5206     __ vpaddq($tmp2$$XMMRegister, $tmp2$$XMMRegister, $tmp$$XMMRegister, 0);</span>
<span class="line-removed"> 5207     __ movdq($tmp$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5208     __ vpaddq($tmp2$$XMMRegister, $tmp2$$XMMRegister, $tmp$$XMMRegister, 0);</span>
<span class="line-removed"> 5209     __ movdq($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5210   %}</span>
<span class="line-removed"> 5211   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5212 %}</span>
<span class="line-removed"> 5213 #endif</span>
<span class="line-removed"> 5214 </span>
<span class="line-removed"> 5215 instruct rsadd2F_reduction_reg(regF dst, vecD src2, vecD tmp) %{</span>
<span class="line-removed"> 5216   predicate(UseSSE &gt;= 1 &amp;&amp; UseAVX == 0);</span>
<span class="line-removed"> 5217   match(Set dst (AddReductionVF dst src2));</span>
<span class="line-removed"> 5218   effect(TEMP dst, TEMP tmp);</span>
<span class="line-removed"> 5219   format %{ &quot;addss   $dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5220             &quot;pshufd  $tmp,$src2,0x01\n\t&quot;</span>
<span class="line-removed"> 5221             &quot;addss   $dst,$tmp\t! add reduction2F&quot; %}</span>
<span class="line-removed"> 5222   ins_encode %{</span>
<span class="line-removed"> 5223     __ addss($dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5224     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5225     __ addss($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5226   %}</span>
<span class="line-removed"> 5227   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5228 %}</span>
<span class="line-removed"> 5229 </span>
<span class="line-removed"> 5230 instruct rvadd2F_reduction_reg(regF dst, vecD src2, vecD tmp) %{</span>
<span class="line-removed"> 5231   predicate(UseAVX &gt; 0);</span>
<span class="line-removed"> 5232   match(Set dst (AddReductionVF dst src2));</span>
<span class="line-removed"> 5233   effect(TEMP dst, TEMP tmp);</span>
<span class="line-removed"> 5234   format %{ &quot;vaddss  $dst,$dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5235             &quot;pshufd  $tmp,$src2,0x01\n\t&quot;</span>
<span class="line-removed"> 5236             &quot;vaddss  $dst,$dst,$tmp\t! add reduction2F&quot; %}</span>
<span class="line-removed"> 5237   ins_encode %{</span>
<span class="line-removed"> 5238     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5239     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5240     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5241   %}</span>
<span class="line-removed"> 5242   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5243 %}</span>
<span class="line-removed"> 5244 </span>
<span class="line-removed"> 5245 instruct rsadd4F_reduction_reg(regF dst, vecX src2, vecX tmp) %{</span>
<span class="line-removed"> 5246   predicate(UseSSE &gt;= 1 &amp;&amp; UseAVX == 0);</span>
<span class="line-removed"> 5247   match(Set dst (AddReductionVF dst src2));</span>
<span class="line-removed"> 5248   effect(TEMP dst, TEMP tmp);</span>
<span class="line-removed"> 5249   format %{ &quot;addss   $dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5250             &quot;pshufd  $tmp,$src2,0x01\n\t&quot;</span>
<span class="line-removed"> 5251             &quot;addss   $dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5252             &quot;pshufd  $tmp,$src2,0x02\n\t&quot;</span>
<span class="line-removed"> 5253             &quot;addss   $dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5254             &quot;pshufd  $tmp,$src2,0x03\n\t&quot;</span>
<span class="line-removed"> 5255             &quot;addss   $dst,$tmp\t! add reduction4F&quot; %}</span>
<span class="line-removed"> 5256   ins_encode %{</span>
<span class="line-removed"> 5257     __ addss($dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5258     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5259     __ addss($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5260     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5261     __ addss($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5262     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5263     __ addss($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5264   %}</span>
<span class="line-removed"> 5265   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5266 %}</span>
<span class="line-removed"> 5267 </span>
<span class="line-removed"> 5268 instruct rvadd4F_reduction_reg(regF dst, vecX src2, vecX tmp) %{</span>
<span class="line-removed"> 5269   predicate(UseAVX &gt; 0);</span>
<span class="line-removed"> 5270   match(Set dst (AddReductionVF dst src2));</span>
<span class="line-removed"> 5271   effect(TEMP tmp, TEMP dst);</span>
<span class="line-removed"> 5272   format %{ &quot;vaddss  $dst,dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5273             &quot;pshufd  $tmp,$src2,0x01\n\t&quot;</span>
<span class="line-removed"> 5274             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5275             &quot;pshufd  $tmp,$src2,0x02\n\t&quot;</span>
<span class="line-removed"> 5276             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5277             &quot;pshufd  $tmp,$src2,0x03\n\t&quot;</span>
<span class="line-removed"> 5278             &quot;vaddss  $dst,$dst,$tmp\t! add reduction4F&quot; %}</span>
<span class="line-removed"> 5279   ins_encode %{</span>
<span class="line-removed"> 5280     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5281     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5282     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5283     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5284     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5285     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5286     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5287   %}</span>
<span class="line-removed"> 5288   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5289 %}</span>
<span class="line-removed"> 5290 </span>
<span class="line-removed"> 5291 instruct radd8F_reduction_reg(regF dst, vecY src2, vecY tmp, vecY tmp2) %{</span>
<span class="line-removed"> 5292   predicate(UseAVX &gt; 0);</span>
<span class="line-removed"> 5293   match(Set dst (AddReductionVF dst src2));</span>
<span class="line-removed"> 5294   effect(TEMP tmp, TEMP dst, TEMP tmp2);</span>
<span class="line-removed"> 5295   format %{ &quot;vaddss  $dst,$dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5296             &quot;pshufd  $tmp,$src2,0x01\n\t&quot;</span>
<span class="line-removed"> 5297             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5298             &quot;pshufd  $tmp,$src2,0x02\n\t&quot;</span>
<span class="line-removed"> 5299             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5300             &quot;pshufd  $tmp,$src2,0x03\n\t&quot;</span>
<span class="line-removed"> 5301             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5302             &quot;vextractf128_high  $tmp2,$src2\n\t&quot;</span>
<span class="line-removed"> 5303             &quot;vaddss  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5304             &quot;pshufd  $tmp,$tmp2,0x01\n\t&quot;</span>
<span class="line-removed"> 5305             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5306             &quot;pshufd  $tmp,$tmp2,0x02\n\t&quot;</span>
<span class="line-removed"> 5307             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5308             &quot;pshufd  $tmp,$tmp2,0x03\n\t&quot;</span>
<span class="line-removed"> 5309             &quot;vaddss  $dst,$dst,$tmp\t! add reduction8F&quot; %}</span>
<span class="line-removed"> 5310   ins_encode %{</span>
<span class="line-removed"> 5311     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5312     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5313     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5314     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5315     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5316     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5317     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5318     __ vextractf128_high($tmp2$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5319     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5320     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5321     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5322     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5323     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5324     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5325     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5326   %}</span>
<span class="line-removed"> 5327   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5328 %}</span>
<span class="line-removed"> 5329 </span>
<span class="line-removed"> 5330 instruct radd16F_reduction_reg(regF dst, legVecZ src2, legVecZ tmp, legVecZ tmp2) %{</span>
<span class="line-removed"> 5331   predicate(UseAVX &gt; 2);</span>
<span class="line-removed"> 5332   match(Set dst (AddReductionVF dst src2));</span>
<span class="line-removed"> 5333   effect(TEMP tmp, TEMP dst, TEMP tmp2);</span>
<span class="line-removed"> 5334   format %{ &quot;vaddss  $dst,$dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5335             &quot;pshufd  $tmp,$src2,0x01\n\t&quot;</span>
<span class="line-removed"> 5336             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5337             &quot;pshufd  $tmp,$src2,0x02\n\t&quot;</span>
<span class="line-removed"> 5338             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5339             &quot;pshufd  $tmp,$src2,0x03\n\t&quot;</span>
<span class="line-removed"> 5340             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5341             &quot;vextractf32x4  $tmp2,$src2,0x1\n\t&quot;</span>
<span class="line-removed"> 5342             &quot;vaddss  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5343             &quot;pshufd  $tmp,$tmp2,0x01\n\t&quot;</span>
<span class="line-removed"> 5344             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5345             &quot;pshufd  $tmp,$tmp2,0x02\n\t&quot;</span>
<span class="line-removed"> 5346             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5347             &quot;pshufd  $tmp,$tmp2,0x03\n\t&quot;</span>
<span class="line-removed"> 5348             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5349             &quot;vextractf32x4  $tmp2,$src2,0x2\n\t&quot;</span>
<span class="line-removed"> 5350             &quot;vaddss  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5351             &quot;pshufd  $tmp,$tmp2,0x01\n\t&quot;</span>
<span class="line-removed"> 5352             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5353             &quot;pshufd  $tmp,$tmp2,0x02\n\t&quot;</span>
<span class="line-removed"> 5354             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5355             &quot;pshufd  $tmp,$tmp2,0x03\n\t&quot;</span>
<span class="line-removed"> 5356             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5357             &quot;vextractf32x4  $tmp2,$src2,0x3\n\t&quot;</span>
<span class="line-removed"> 5358             &quot;vaddss  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5359             &quot;pshufd  $tmp,$tmp2,0x01\n\t&quot;</span>
<span class="line-removed"> 5360             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5361             &quot;pshufd  $tmp,$tmp2,0x02\n\t&quot;</span>
<span class="line-removed"> 5362             &quot;vaddss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5363             &quot;pshufd  $tmp,$tmp2,0x03\n\t&quot;</span>
<span class="line-removed"> 5364             &quot;vaddss  $dst,$dst,$tmp\t! add reduction16F&quot; %}</span>
<span class="line-removed"> 5365   ins_encode %{</span>
<span class="line-removed"> 5366     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5367     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5368     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5369     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5370     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5371     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5372     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5373     __ vextractf32x4($tmp2$$XMMRegister, $src2$$XMMRegister, 0x1);</span>
<span class="line-removed"> 5374     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5375     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5376     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5377     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5378     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5379     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5380     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5381     __ vextractf32x4($tmp2$$XMMRegister, $src2$$XMMRegister, 0x2);</span>
<span class="line-removed"> 5382     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5383     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5384     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5385     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5386     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5387     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5388     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5389     __ vextractf32x4($tmp2$$XMMRegister, $src2$$XMMRegister, 0x3);</span>
<span class="line-removed"> 5390     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5391     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5392     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5393     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5394     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5395     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5396     __ vaddss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5397   %}</span>
<span class="line-removed"> 5398   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5399 %}</span>
<span class="line-removed"> 5400 </span>
<span class="line-removed"> 5401 instruct rsadd2D_reduction_reg(regD dst, vecX src2, vecX tmp) %{</span>
<span class="line-removed"> 5402   predicate(UseSSE &gt;= 1 &amp;&amp; UseAVX == 0);</span>
<span class="line-removed"> 5403   match(Set dst (AddReductionVD dst src2));</span>
<span class="line-removed"> 5404   effect(TEMP tmp, TEMP dst);</span>
<span class="line-removed"> 5405   format %{ &quot;addsd   $dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5406             &quot;pshufd  $tmp,$src2,0xE\n\t&quot;</span>
<span class="line-removed"> 5407             &quot;addsd   $dst,$tmp\t! add reduction2D&quot; %}</span>
<span class="line-removed"> 5408   ins_encode %{</span>
<span class="line-removed"> 5409     __ addsd($dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5410     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5411     __ addsd($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5412   %}</span>
<span class="line-removed"> 5413   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5414 %}</span>
<span class="line-removed"> 5415 </span>
<span class="line-removed"> 5416 instruct rvadd2D_reduction_reg(regD dst, vecX src2, vecX tmp) %{</span>
<span class="line-removed"> 5417   predicate(UseAVX &gt; 0);</span>
<span class="line-removed"> 5418   match(Set dst (AddReductionVD dst src2));</span>
<span class="line-removed"> 5419   effect(TEMP tmp, TEMP dst);</span>
<span class="line-removed"> 5420   format %{ &quot;vaddsd  $dst,$dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5421             &quot;pshufd  $tmp,$src2,0xE\n\t&quot;</span>
<span class="line-removed"> 5422             &quot;vaddsd  $dst,$dst,$tmp\t! add reduction2D&quot; %}</span>
<span class="line-removed"> 5423   ins_encode %{</span>
<span class="line-removed"> 5424     __ vaddsd($dst$$XMMRegister, $dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5425     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5426     __ vaddsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5427   %}</span>
<span class="line-removed"> 5428   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5429 %}</span>
<span class="line-removed"> 5430 </span>
<span class="line-removed"> 5431 instruct rvadd4D_reduction_reg(regD dst, vecY src2, vecX tmp, vecX tmp2) %{</span>
<span class="line-removed"> 5432   predicate(UseAVX &gt; 0);</span>
<span class="line-removed"> 5433   match(Set dst (AddReductionVD dst src2));</span>
<span class="line-removed"> 5434   effect(TEMP tmp, TEMP dst, TEMP tmp2);</span>
<span class="line-removed"> 5435   format %{ &quot;vaddsd  $dst,$dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5436             &quot;pshufd  $tmp,$src2,0xE\n\t&quot;</span>
<span class="line-removed"> 5437             &quot;vaddsd  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5438             &quot;vextractf128  $tmp2,$src2,0x1\n\t&quot;</span>
<span class="line-removed"> 5439             &quot;vaddsd  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5440             &quot;pshufd  $tmp,$tmp2,0xE\n\t&quot;</span>
<span class="line-removed"> 5441             &quot;vaddsd  $dst,$dst,$tmp\t! add reduction4D&quot; %}</span>
<span class="line-removed"> 5442   ins_encode %{</span>
<span class="line-removed"> 5443     __ vaddsd($dst$$XMMRegister, $dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5444     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5445     __ vaddsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5446     __ vextractf128($tmp2$$XMMRegister, $src2$$XMMRegister, 0x1);</span>
<span class="line-removed"> 5447     __ vaddsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5448     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5449     __ vaddsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5450   %}</span>
<span class="line-removed"> 5451   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5452 %}</span>
<span class="line-removed"> 5453 </span>
<span class="line-removed"> 5454 instruct rvadd8D_reduction_reg(regD dst, legVecZ src2, legVecZ tmp, legVecZ tmp2) %{</span>
<span class="line-removed"> 5455   predicate(UseAVX &gt; 2);</span>
<span class="line-removed"> 5456   match(Set dst (AddReductionVD dst src2));</span>
<span class="line-removed"> 5457   effect(TEMP tmp, TEMP dst, TEMP tmp2);</span>
<span class="line-removed"> 5458   format %{ &quot;vaddsd  $dst,$dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5459             &quot;pshufd  $tmp,$src2,0xE\n\t&quot;</span>
<span class="line-removed"> 5460             &quot;vaddsd  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5461             &quot;vextractf32x4  $tmp2,$src2,0x1\n\t&quot;</span>
<span class="line-removed"> 5462             &quot;vaddsd  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5463             &quot;pshufd  $tmp,$tmp2,0xE\n\t&quot;</span>
<span class="line-removed"> 5464             &quot;vaddsd  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5465             &quot;vextractf32x4  $tmp2,$src2,0x2\n\t&quot;</span>
<span class="line-removed"> 5466             &quot;vaddsd  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5467             &quot;pshufd  $tmp,$tmp2,0xE\n\t&quot;</span>
<span class="line-removed"> 5468             &quot;vaddsd  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5469             &quot;vextractf32x4  $tmp2,$src2,0x3\n\t&quot;</span>
<span class="line-removed"> 5470             &quot;vaddsd  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5471             &quot;pshufd  $tmp,$tmp2,0xE\n\t&quot;</span>
<span class="line-removed"> 5472             &quot;vaddsd  $dst,$dst,$tmp\t! add reduction8D&quot; %}</span>
<span class="line-removed"> 5473   ins_encode %{</span>
<span class="line-removed"> 5474     __ vaddsd($dst$$XMMRegister, $dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5475     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5476     __ vaddsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5477     __ vextractf32x4($tmp2$$XMMRegister, $src2$$XMMRegister, 0x1);</span>
<span class="line-removed"> 5478     __ vaddsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5479     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5480     __ vaddsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5481     __ vextractf32x4($tmp2$$XMMRegister, $src2$$XMMRegister, 0x2);</span>
<span class="line-removed"> 5482     __ vaddsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5483     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5484     __ vaddsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5485     __ vextractf32x4($tmp2$$XMMRegister, $src2$$XMMRegister, 0x3);</span>
<span class="line-removed"> 5486     __ vaddsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5487     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5488     __ vaddsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5489   %}</span>
<span class="line-removed"> 5490   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5491 %}</span>
<span class="line-removed"> 5492 </span>
<span class="line-removed"> 5493 instruct rsmul2I_reduction_reg(rRegI dst, rRegI src1, vecD src2, vecD tmp, vecD tmp2) %{</span>
<span class="line-removed"> 5494   predicate(UseSSE &gt; 3 &amp;&amp; UseAVX == 0);</span>
<span class="line-removed"> 5495   match(Set dst (MulReductionVI src1 src2));</span>
<span class="line-removed"> 5496   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5497   format %{ &quot;pshufd  $tmp2,$src2,0x1\n\t&quot;</span>
<span class="line-removed"> 5498             &quot;pmulld  $tmp2,$src2\n\t&quot;</span>
<span class="line-removed"> 5499             &quot;movd    $tmp,$src1\n\t&quot;</span>
<span class="line-removed"> 5500             &quot;pmulld  $tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5501             &quot;movd    $dst,$tmp2\t! mul reduction2I&quot; %}</span>
<span class="line-removed"> 5502   ins_encode %{</span>
<span class="line-removed"> 5503     __ pshufd($tmp2$$XMMRegister, $src2$$XMMRegister, 0x1);</span>
<span class="line-removed"> 5504     __ pmulld($tmp2$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5505     __ movdl($tmp$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5506     __ pmulld($tmp2$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5507     __ movdl($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5508   %}</span>
<span class="line-removed"> 5509   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5510 %}</span>
<span class="line-removed"> 5511 </span>
<span class="line-removed"> 5512 instruct rvmul2I_reduction_reg(rRegI dst, rRegI src1, vecD src2, vecD tmp, vecD tmp2) %{</span>
<span class="line-removed"> 5513   predicate(UseAVX &gt; 0);</span>
<span class="line-removed"> 5514   match(Set dst (MulReductionVI src1 src2));</span>
<span class="line-removed"> 5515   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5516   format %{ &quot;pshufd   $tmp2,$src2,0x1\n\t&quot;</span>
<span class="line-removed"> 5517             &quot;vpmulld  $tmp,$src2,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5518             &quot;movd     $tmp2,$src1\n\t&quot;</span>
<span class="line-removed"> 5519             &quot;vpmulld  $tmp2,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5520             &quot;movd     $dst,$tmp2\t! mul reduction2I&quot; %}</span>
<span class="line-removed"> 5521   ins_encode %{</span>
<span class="line-removed"> 5522     int vector_len = 0;</span>
<span class="line-removed"> 5523     __ pshufd($tmp2$$XMMRegister, $src2$$XMMRegister, 0x1);</span>
<span class="line-removed"> 5524     __ vpmulld($tmp$$XMMRegister, $src2$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5525     __ movdl($tmp2$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5526     __ vpmulld($tmp2$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5527     __ movdl($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5528   %}</span>
<span class="line-removed"> 5529   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5530 %}</span>
<span class="line-removed"> 5531 </span>
<span class="line-removed"> 5532 instruct rsmul4I_reduction_reg(rRegI dst, rRegI src1, vecX src2, vecX tmp, vecX tmp2) %{</span>
<span class="line-removed"> 5533   predicate(UseSSE &gt; 3 &amp;&amp; UseAVX == 0);</span>
<span class="line-removed"> 5534   match(Set dst (MulReductionVI src1 src2));</span>
<span class="line-removed"> 5535   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5536   format %{ &quot;pshufd  $tmp2,$src2,0xE\n\t&quot;</span>
<span class="line-removed"> 5537             &quot;pmulld  $tmp2,$src2\n\t&quot;</span>
<span class="line-removed"> 5538             &quot;pshufd  $tmp,$tmp2,0x1\n\t&quot;</span>
<span class="line-removed"> 5539             &quot;pmulld  $tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5540             &quot;movd    $tmp,$src1\n\t&quot;</span>
<span class="line-removed"> 5541             &quot;pmulld  $tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5542             &quot;movd    $dst,$tmp2\t! mul reduction4I&quot; %}</span>
<span class="line-removed"> 5543   ins_encode %{</span>
<span class="line-removed"> 5544     __ pshufd($tmp2$$XMMRegister, $src2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5545     __ pmulld($tmp2$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5546     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x1);</span>
<span class="line-removed"> 5547     __ pmulld($tmp2$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5548     __ movdl($tmp$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5549     __ pmulld($tmp2$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5550     __ movdl($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5551   %}</span>
<span class="line-removed"> 5552   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5553 %}</span>
<span class="line-removed"> 5554 </span>
<span class="line-removed"> 5555 instruct rvmul4I_reduction_reg(rRegI dst, rRegI src1, vecX src2, vecX tmp, vecX tmp2) %{</span>
<span class="line-removed"> 5556   predicate(UseAVX &gt; 0);</span>
<span class="line-removed"> 5557   match(Set dst (MulReductionVI src1 src2));</span>
<span class="line-removed"> 5558   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5559   format %{ &quot;pshufd   $tmp2,$src2,0xE\n\t&quot;</span>
<span class="line-removed"> 5560             &quot;vpmulld  $tmp,$src2,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5561             &quot;pshufd   $tmp2,$tmp,0x1\n\t&quot;</span>
<span class="line-removed"> 5562             &quot;vpmulld  $tmp,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5563             &quot;movd     $tmp2,$src1\n\t&quot;</span>
<span class="line-removed"> 5564             &quot;vpmulld  $tmp2,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5565             &quot;movd     $dst,$tmp2\t! mul reduction4I&quot; %}</span>
<span class="line-removed"> 5566   ins_encode %{</span>
<span class="line-removed"> 5567     int vector_len = 0;</span>
<span class="line-removed"> 5568     __ pshufd($tmp2$$XMMRegister, $src2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5569     __ vpmulld($tmp$$XMMRegister, $src2$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5570     __ pshufd($tmp2$$XMMRegister, $tmp$$XMMRegister, 0x1);</span>
<span class="line-removed"> 5571     __ vpmulld($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5572     __ movdl($tmp2$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5573     __ vpmulld($tmp2$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5574     __ movdl($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5575   %}</span>
<span class="line-removed"> 5576   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5577 %}</span>
<span class="line-removed"> 5578 </span>
<span class="line-removed"> 5579 instruct rvmul8I_reduction_reg(rRegI dst, rRegI src1, vecY src2, vecY tmp, vecY tmp2) %{</span>
<span class="line-removed"> 5580   predicate(UseAVX &gt; 1);</span>
<span class="line-removed"> 5581   match(Set dst (MulReductionVI src1 src2));</span>
<span class="line-removed"> 5582   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5583   format %{ &quot;vextracti128_high  $tmp,$src2\n\t&quot;</span>
<span class="line-removed"> 5584             &quot;vpmulld  $tmp,$tmp,$src2\n\t&quot;</span>
<span class="line-removed"> 5585             &quot;pshufd   $tmp2,$tmp,0xE\n\t&quot;</span>
<span class="line-removed"> 5586             &quot;vpmulld  $tmp,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5587             &quot;pshufd   $tmp2,$tmp,0x1\n\t&quot;</span>
<span class="line-removed"> 5588             &quot;vpmulld  $tmp,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5589             &quot;movd     $tmp2,$src1\n\t&quot;</span>
<span class="line-removed"> 5590             &quot;vpmulld  $tmp2,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5591             &quot;movd     $dst,$tmp2\t! mul reduction8I&quot; %}</span>
<span class="line-removed"> 5592   ins_encode %{</span>
<span class="line-removed"> 5593     int vector_len = 0;</span>
<span class="line-removed"> 5594     __ vextracti128_high($tmp$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5595     __ vpmulld($tmp$$XMMRegister, $tmp$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5596     __ pshufd($tmp2$$XMMRegister, $tmp$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5597     __ vpmulld($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5598     __ pshufd($tmp2$$XMMRegister, $tmp$$XMMRegister, 0x1);</span>
<span class="line-removed"> 5599     __ vpmulld($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5600     __ movdl($tmp2$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5601     __ vpmulld($tmp2$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 5602     __ movdl($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5603   %}</span>
<span class="line-removed"> 5604   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5605 %}</span>
<span class="line-removed"> 5606 </span>
<span class="line-removed"> 5607 instruct rvmul16I_reduction_reg(rRegI dst, rRegI src1, legVecZ src2, legVecZ tmp, legVecZ tmp2, legVecZ tmp3) %{</span>
<span class="line-removed"> 5608   predicate(UseAVX &gt; 2);</span>
<span class="line-removed"> 5609   match(Set dst (MulReductionVI src1 src2));</span>
<span class="line-removed"> 5610   effect(TEMP tmp, TEMP tmp2, TEMP tmp3);</span>
<span class="line-removed"> 5611   format %{ &quot;vextracti64x4_high  $tmp3,$src2\n\t&quot;</span>
<span class="line-removed"> 5612             &quot;vpmulld  $tmp3,$tmp3,$src2\n\t&quot;</span>
<span class="line-removed"> 5613             &quot;vextracti128_high  $tmp,$tmp3\n\t&quot;</span>
<span class="line-removed"> 5614             &quot;vpmulld  $tmp,$tmp,$src2\n\t&quot;</span>
<span class="line-removed"> 5615             &quot;pshufd   $tmp2,$tmp,0xE\n\t&quot;</span>
<span class="line-removed"> 5616             &quot;vpmulld  $tmp,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5617             &quot;pshufd   $tmp2,$tmp,0x1\n\t&quot;</span>
<span class="line-removed"> 5618             &quot;vpmulld  $tmp,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5619             &quot;movd     $tmp2,$src1\n\t&quot;</span>
<span class="line-removed"> 5620             &quot;vpmulld  $tmp2,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5621             &quot;movd     $dst,$tmp2\t! mul reduction16I&quot; %}</span>
<span class="line-removed"> 5622   ins_encode %{</span>
<span class="line-removed"> 5623     __ vextracti64x4_high($tmp3$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5624     __ vpmulld($tmp3$$XMMRegister, $tmp3$$XMMRegister, $src2$$XMMRegister, 1);</span>
<span class="line-removed"> 5625     __ vextracti128_high($tmp$$XMMRegister, $tmp3$$XMMRegister);</span>
<span class="line-removed"> 5626     __ vpmulld($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp3$$XMMRegister, 0);</span>
<span class="line-removed"> 5627     __ pshufd($tmp2$$XMMRegister, $tmp$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5628     __ vpmulld($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, 0);</span>
<span class="line-removed"> 5629     __ pshufd($tmp2$$XMMRegister, $tmp$$XMMRegister, 0x1);</span>
<span class="line-removed"> 5630     __ vpmulld($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, 0);</span>
<span class="line-removed"> 5631     __ movdl($tmp2$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5632     __ vpmulld($tmp2$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, 0);</span>
<span class="line-removed"> 5633     __ movdl($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5634   %}</span>
<span class="line-removed"> 5635   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5636 %}</span>
<span class="line-removed"> 5637 </span>
<span class="line-removed"> 5638 #ifdef _LP64</span>
<span class="line-removed"> 5639 instruct rvmul2L_reduction_reg(rRegL dst, rRegL src1, vecX src2, vecX tmp, vecX tmp2) %{</span>
<span class="line-removed"> 5640   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512dq());</span>
<span class="line-removed"> 5641   match(Set dst (MulReductionVL src1 src2));</span>
<span class="line-removed"> 5642   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5643   format %{ &quot;pshufd   $tmp2,$src2,0xE\n\t&quot;</span>
<span class="line-removed"> 5644             &quot;vpmullq  $tmp,$src2,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5645             &quot;movdq    $tmp2,$src1\n\t&quot;</span>
<span class="line-removed"> 5646             &quot;vpmullq  $tmp2,$tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5647             &quot;movdq    $dst,$tmp2\t! mul reduction2L&quot; %}</span>
<span class="line-removed"> 5648   ins_encode %{</span>
<span class="line-removed"> 5649     __ pshufd($tmp2$$XMMRegister, $src2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5650     __ vpmullq($tmp$$XMMRegister, $src2$$XMMRegister, $tmp2$$XMMRegister, 0);</span>
<span class="line-removed"> 5651     __ movdq($tmp2$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5652     __ vpmullq($tmp2$$XMMRegister, $tmp$$XMMRegister, $tmp2$$XMMRegister, 0);</span>
<span class="line-removed"> 5653     __ movdq($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5654   %}</span>
<span class="line-removed"> 5655   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5656 %}</span>
<span class="line-removed"> 5657 </span>
<span class="line-removed"> 5658 instruct rvmul4L_reduction_reg(rRegL dst, rRegL src1, vecY src2, vecY tmp, vecY tmp2) %{</span>
<span class="line-removed"> 5659   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512dq());</span>
<span class="line-removed"> 5660   match(Set dst (MulReductionVL src1 src2));</span>
<span class="line-removed"> 5661   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5662   format %{ &quot;vextracti128_high  $tmp,$src2\n\t&quot;</span>
<span class="line-removed"> 5663             &quot;vpmullq  $tmp2,$tmp,$src2\n\t&quot;</span>
<span class="line-removed"> 5664             &quot;pshufd   $tmp,$tmp2,0xE\n\t&quot;</span>
<span class="line-removed"> 5665             &quot;vpmullq  $tmp2,$tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5666             &quot;movdq    $tmp,$src1\n\t&quot;</span>
<span class="line-removed"> 5667             &quot;vpmullq  $tmp2,$tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5668             &quot;movdq    $dst,$tmp2\t! mul reduction4L&quot; %}</span>
<span class="line-removed"> 5669   ins_encode %{</span>
<span class="line-removed"> 5670     __ vextracti128_high($tmp$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5671     __ vpmullq($tmp2$$XMMRegister, $tmp$$XMMRegister, $src2$$XMMRegister, 0);</span>
<span class="line-removed"> 5672     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5673     __ vpmullq($tmp2$$XMMRegister, $tmp2$$XMMRegister, $tmp$$XMMRegister, 0);</span>
<span class="line-removed"> 5674     __ movdq($tmp$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5675     __ vpmullq($tmp2$$XMMRegister, $tmp2$$XMMRegister, $tmp$$XMMRegister, 0);</span>
<span class="line-removed"> 5676     __ movdq($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5677   %}</span>
<span class="line-removed"> 5678   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5679 %}</span>
<span class="line-removed"> 5680 </span>
<span class="line-removed"> 5681 instruct rvmul8L_reduction_reg(rRegL dst, rRegL src1, legVecZ src2, legVecZ tmp, legVecZ tmp2) %{</span>
<span class="line-removed"> 5682   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512dq());</span>
<span class="line-removed"> 5683   match(Set dst (MulReductionVL src1 src2));</span>
<span class="line-removed"> 5684   effect(TEMP tmp, TEMP tmp2);</span>
<span class="line-removed"> 5685   format %{ &quot;vextracti64x4_high  $tmp2,$src2\n\t&quot;</span>
<span class="line-removed"> 5686             &quot;vpmullq  $tmp2,$tmp2,$src2\n\t&quot;</span>
<span class="line-removed"> 5687             &quot;vextracti128_high  $tmp,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5688             &quot;vpmullq  $tmp2,$tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5689             &quot;pshufd   $tmp,$tmp2,0xE\n\t&quot;</span>
<span class="line-removed"> 5690             &quot;vpmullq  $tmp2,$tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5691             &quot;movdq    $tmp,$src1\n\t&quot;</span>
<span class="line-removed"> 5692             &quot;vpmullq  $tmp2,$tmp2,$tmp\n\t&quot;</span>
<span class="line-removed"> 5693             &quot;movdq    $dst,$tmp2\t! mul reduction8L&quot; %}</span>
<span class="line-removed"> 5694   ins_encode %{</span>
<span class="line-removed"> 5695     __ vextracti64x4_high($tmp2$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5696     __ vpmullq($tmp2$$XMMRegister, $tmp2$$XMMRegister, $src2$$XMMRegister, 1);</span>
<span class="line-removed"> 5697     __ vextracti128_high($tmp$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5698     __ vpmullq($tmp2$$XMMRegister, $tmp2$$XMMRegister, $tmp$$XMMRegister, 0);</span>
<span class="line-removed"> 5699     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5700     __ vpmullq($tmp2$$XMMRegister, $tmp2$$XMMRegister, $tmp$$XMMRegister, 0);</span>
<span class="line-removed"> 5701     __ movdq($tmp$$XMMRegister, $src1$$Register);</span>
<span class="line-removed"> 5702     __ vpmullq($tmp2$$XMMRegister, $tmp2$$XMMRegister, $tmp$$XMMRegister, 0);</span>
<span class="line-removed"> 5703     __ movdq($dst$$Register, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5704   %}</span>
<span class="line-removed"> 5705   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5706 %}</span>
<span class="line-removed"> 5707 #endif</span>
<span class="line-removed"> 5708 </span>
<span class="line-removed"> 5709 instruct rsmul2F_reduction(regF dst, vecD src2, vecD tmp) %{</span>
<span class="line-removed"> 5710   predicate(UseSSE &gt;= 1 &amp;&amp; UseAVX == 0);</span>
<span class="line-removed"> 5711   match(Set dst (MulReductionVF dst src2));</span>
<span class="line-removed"> 5712   effect(TEMP dst, TEMP tmp);</span>
<span class="line-removed"> 5713   format %{ &quot;mulss   $dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5714             &quot;pshufd  $tmp,$src2,0x01\n\t&quot;</span>
<span class="line-removed"> 5715             &quot;mulss   $dst,$tmp\t! mul reduction2F&quot; %}</span>
<span class="line-removed"> 5716   ins_encode %{</span>
<span class="line-removed"> 5717     __ mulss($dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5718     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5719     __ mulss($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5720   %}</span>
<span class="line-removed"> 5721   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5722 %}</span>
<span class="line-removed"> 5723 </span>
<span class="line-removed"> 5724 instruct rvmul2F_reduction_reg(regF dst, vecD src2, vecD tmp) %{</span>
<span class="line-removed"> 5725   predicate(UseAVX &gt; 0);</span>
<span class="line-removed"> 5726   match(Set dst (MulReductionVF dst src2));</span>
<span class="line-removed"> 5727   effect(TEMP tmp, TEMP dst);</span>
<span class="line-removed"> 5728   format %{ &quot;vmulss  $dst,$dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5729             &quot;pshufd  $tmp,$src2,0x01\n\t&quot;</span>
<span class="line-removed"> 5730             &quot;vmulss  $dst,$dst,$tmp\t! mul reduction2F&quot; %}</span>
<span class="line-removed"> 5731   ins_encode %{</span>
<span class="line-removed"> 5732     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5733     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5734     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5735   %}</span>
<span class="line-removed"> 5736   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5737 %}</span>
<span class="line-removed"> 5738 </span>
<span class="line-removed"> 5739 instruct rsmul4F_reduction_reg(regF dst, vecX src2, vecX tmp) %{</span>
<span class="line-removed"> 5740   predicate(UseSSE &gt;= 1 &amp;&amp; UseAVX == 0);</span>
<span class="line-removed"> 5741   match(Set dst (MulReductionVF dst src2));</span>
<span class="line-removed"> 5742   effect(TEMP dst, TEMP tmp);</span>
<span class="line-removed"> 5743   format %{ &quot;mulss   $dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5744             &quot;pshufd  $tmp,$src2,0x01\n\t&quot;</span>
<span class="line-removed"> 5745             &quot;mulss   $dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5746             &quot;pshufd  $tmp,$src2,0x02\n\t&quot;</span>
<span class="line-removed"> 5747             &quot;mulss   $dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5748             &quot;pshufd  $tmp,$src2,0x03\n\t&quot;</span>
<span class="line-removed"> 5749             &quot;mulss   $dst,$tmp\t! mul reduction4F&quot; %}</span>
<span class="line-removed"> 5750   ins_encode %{</span>
<span class="line-removed"> 5751     __ mulss($dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5752     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5753     __ mulss($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5754     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5755     __ mulss($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5756     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5757     __ mulss($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5758   %}</span>
<span class="line-removed"> 5759   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5760 %}</span>
<span class="line-removed"> 5761 </span>
<span class="line-removed"> 5762 instruct rvmul4F_reduction_reg(regF dst, vecX src2, vecX tmp) %{</span>
<span class="line-removed"> 5763   predicate(UseAVX &gt; 0);</span>
<span class="line-removed"> 5764   match(Set dst (MulReductionVF dst src2));</span>
<span class="line-removed"> 5765   effect(TEMP tmp, TEMP dst);</span>
<span class="line-removed"> 5766   format %{ &quot;vmulss  $dst,$dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5767             &quot;pshufd  $tmp,$src2,0x01\n\t&quot;</span>
<span class="line-removed"> 5768             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5769             &quot;pshufd  $tmp,$src2,0x02\n\t&quot;</span>
<span class="line-removed"> 5770             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5771             &quot;pshufd  $tmp,$src2,0x03\n\t&quot;</span>
<span class="line-removed"> 5772             &quot;vmulss  $dst,$dst,$tmp\t! mul reduction4F&quot; %}</span>
<span class="line-removed"> 5773   ins_encode %{</span>
<span class="line-removed"> 5774     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5775     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5776     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5777     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5778     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5779     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5780     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5781   %}</span>
<span class="line-removed"> 5782   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5783 %}</span>
<span class="line-removed"> 5784 </span>
<span class="line-removed"> 5785 instruct rvmul8F_reduction_reg(regF dst, vecY src2, vecY tmp, vecY tmp2) %{</span>
<span class="line-removed"> 5786   predicate(UseAVX &gt; 0);</span>
<span class="line-removed"> 5787   match(Set dst (MulReductionVF dst src2));</span>
<span class="line-removed"> 5788   effect(TEMP tmp, TEMP dst, TEMP tmp2);</span>
<span class="line-removed"> 5789   format %{ &quot;vmulss  $dst,$dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5790             &quot;pshufd  $tmp,$src2,0x01\n\t&quot;</span>
<span class="line-removed"> 5791             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5792             &quot;pshufd  $tmp,$src2,0x02\n\t&quot;</span>
<span class="line-removed"> 5793             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5794             &quot;pshufd  $tmp,$src2,0x03\n\t&quot;</span>
<span class="line-removed"> 5795             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5796             &quot;vextractf128_high  $tmp2,$src2\n\t&quot;</span>
<span class="line-removed"> 5797             &quot;vmulss  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5798             &quot;pshufd  $tmp,$tmp2,0x01\n\t&quot;</span>
<span class="line-removed"> 5799             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5800             &quot;pshufd  $tmp,$tmp2,0x02\n\t&quot;</span>
<span class="line-removed"> 5801             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5802             &quot;pshufd  $tmp,$tmp2,0x03\n\t&quot;</span>
<span class="line-removed"> 5803             &quot;vmulss  $dst,$dst,$tmp\t! mul reduction8F&quot; %}</span>
<span class="line-removed"> 5804   ins_encode %{</span>
<span class="line-removed"> 5805     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5806     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5807     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5808     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5809     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5810     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5811     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5812     __ vextractf128_high($tmp2$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5813     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5814     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5815     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5816     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5817     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5818     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5819     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5820   %}</span>
<span class="line-removed"> 5821   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5822 %}</span>
<span class="line-removed"> 5823 </span>
<span class="line-removed"> 5824 instruct rvmul16F_reduction_reg(regF dst, legVecZ src2, legVecZ tmp, legVecZ tmp2) %{</span>
<span class="line-removed"> 5825   predicate(UseAVX &gt; 2);</span>
<span class="line-removed"> 5826   match(Set dst (MulReductionVF dst src2));</span>
<span class="line-removed"> 5827   effect(TEMP tmp, TEMP dst, TEMP tmp2);</span>
<span class="line-removed"> 5828   format %{ &quot;vmulss  $dst,$dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5829             &quot;pshufd  $tmp,$src2,0x01\n\t&quot;</span>
<span class="line-removed"> 5830             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5831             &quot;pshufd  $tmp,$src2,0x02\n\t&quot;</span>
<span class="line-removed"> 5832             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5833             &quot;pshufd  $tmp,$src2,0x03\n\t&quot;</span>
<span class="line-removed"> 5834             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5835             &quot;vextractf32x4  $tmp2,$src2,0x1\n\t&quot;</span>
<span class="line-removed"> 5836             &quot;vmulss  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5837             &quot;pshufd  $tmp,$tmp2,0x01\n\t&quot;</span>
<span class="line-removed"> 5838             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5839             &quot;pshufd  $tmp,$tmp2,0x02\n\t&quot;</span>
<span class="line-removed"> 5840             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5841             &quot;pshufd  $tmp,$tmp2,0x03\n\t&quot;</span>
<span class="line-removed"> 5842             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5843             &quot;vextractf32x4  $tmp2,$src2,0x2\n\t&quot;</span>
<span class="line-removed"> 5844             &quot;vmulss  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5845             &quot;pshufd  $tmp,$tmp2,0x01\n\t&quot;</span>
<span class="line-removed"> 5846             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5847             &quot;pshufd  $tmp,$tmp2,0x02\n\t&quot;</span>
<span class="line-removed"> 5848             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5849             &quot;pshufd  $tmp,$tmp2,0x03\n\t&quot;</span>
<span class="line-removed"> 5850             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5851             &quot;vextractf32x4  $tmp2,$src2,0x3\n\t&quot;</span>
<span class="line-removed"> 5852             &quot;vmulss  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5853             &quot;pshufd  $tmp,$tmp2,0x01\n\t&quot;</span>
<span class="line-removed"> 5854             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5855             &quot;pshufd  $tmp,$tmp2,0x02\n\t&quot;</span>
<span class="line-removed"> 5856             &quot;vmulss  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5857             &quot;pshufd  $tmp,$tmp2,0x03\n\t&quot;</span>
<span class="line-removed"> 5858             &quot;vmulss  $dst,$dst,$tmp\t! mul reduction16F&quot; %}</span>
<span class="line-removed"> 5859   ins_encode %{</span>
<span class="line-removed"> 5860     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5861     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5862     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5863     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5864     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5865     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5866     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5867     __ vextractf32x4($tmp2$$XMMRegister, $src2$$XMMRegister, 0x1);</span>
<span class="line-removed"> 5868     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5869     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5870     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5871     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5872     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5873     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5874     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5875     __ vextractf32x4($tmp2$$XMMRegister, $src2$$XMMRegister, 0x2);</span>
<span class="line-removed"> 5876     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5877     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5878     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5879     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5880     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5881     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5882     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5883     __ vextractf32x4($tmp2$$XMMRegister, $src2$$XMMRegister, 0x3);</span>
<span class="line-removed"> 5884     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5885     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x01);</span>
<span class="line-removed"> 5886     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5887     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x02);</span>
<span class="line-removed"> 5888     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5889     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0x03);</span>
<span class="line-removed"> 5890     __ vmulss($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5891   %}</span>
<span class="line-removed"> 5892   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5893 %}</span>
<span class="line-removed"> 5894 </span>
<span class="line-removed"> 5895 instruct rsmul2D_reduction_reg(regD dst, vecX src2, vecX tmp) %{</span>
<span class="line-removed"> 5896   predicate(UseSSE &gt;= 1 &amp;&amp; UseAVX == 0);</span>
<span class="line-removed"> 5897   match(Set dst (MulReductionVD dst src2));</span>
<span class="line-removed"> 5898   effect(TEMP dst, TEMP tmp);</span>
<span class="line-removed"> 5899   format %{ &quot;mulsd   $dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5900             &quot;pshufd  $tmp,$src2,0xE\n\t&quot;</span>
<span class="line-removed"> 5901             &quot;mulsd   $dst,$tmp\t! mul reduction2D&quot; %}</span>
<span class="line-removed"> 5902   ins_encode %{</span>
<span class="line-removed"> 5903     __ mulsd($dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5904     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5905     __ mulsd($dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5906   %}</span>
<span class="line-removed"> 5907   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5908 %}</span>
<span class="line-removed"> 5909 </span>
<span class="line-removed"> 5910 instruct rvmul2D_reduction_reg(regD dst, vecX src2, vecX tmp) %{</span>
<span class="line-removed"> 5911   predicate(UseAVX &gt; 0);</span>
<span class="line-removed"> 5912   match(Set dst (MulReductionVD dst src2));</span>
<span class="line-removed"> 5913   effect(TEMP tmp, TEMP dst);</span>
<span class="line-removed"> 5914   format %{ &quot;vmulsd  $dst,$dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5915             &quot;pshufd  $tmp,$src2,0xE\n\t&quot;</span>
<span class="line-removed"> 5916             &quot;vmulsd  $dst,$dst,$tmp\t! mul reduction2D&quot; %}</span>
<span class="line-removed"> 5917   ins_encode %{</span>
<span class="line-removed"> 5918     __ vmulsd($dst$$XMMRegister, $dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5919     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5920     __ vmulsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5921   %}</span>
<span class="line-removed"> 5922   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5923 %}</span>
<span class="line-removed"> 5924 </span>
<span class="line-removed"> 5925 instruct rvmul4D_reduction_reg(regD dst, vecY src2, vecY tmp, vecY tmp2) %{</span>
<span class="line-removed"> 5926   predicate(UseAVX &gt; 0);</span>
<span class="line-removed"> 5927   match(Set dst (MulReductionVD dst src2));</span>
<span class="line-removed"> 5928   effect(TEMP tmp, TEMP dst, TEMP tmp2);</span>
<span class="line-removed"> 5929   format %{ &quot;vmulsd  $dst,$dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5930             &quot;pshufd  $tmp,$src2,0xE\n\t&quot;</span>
<span class="line-removed"> 5931             &quot;vmulsd  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5932             &quot;vextractf128_high  $tmp2,$src2\n\t&quot;</span>
<span class="line-removed"> 5933             &quot;vmulsd  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5934             &quot;pshufd  $tmp,$tmp2,0xE\n\t&quot;</span>
<span class="line-removed"> 5935             &quot;vmulsd  $dst,$dst,$tmp\t! mul reduction4D&quot; %}</span>
<span class="line-removed"> 5936   ins_encode %{</span>
<span class="line-removed"> 5937     __ vmulsd($dst$$XMMRegister, $dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5938     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5939     __ vmulsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5940     __ vextractf128_high($tmp2$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5941     __ vmulsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5942     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5943     __ vmulsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5944   %}</span>
<span class="line-removed"> 5945   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5946 %}</span>
<span class="line-removed"> 5947 </span>
<span class="line-removed"> 5948 instruct rvmul8D_reduction_reg(regD dst, legVecZ src2, legVecZ tmp, legVecZ tmp2) %{</span>
<span class="line-removed"> 5949   predicate(UseAVX &gt; 2);</span>
<span class="line-removed"> 5950   match(Set dst (MulReductionVD dst src2));</span>
<span class="line-removed"> 5951   effect(TEMP tmp, TEMP dst, TEMP tmp2);</span>
<span class="line-removed"> 5952   format %{ &quot;vmulsd  $dst,$dst,$src2\n\t&quot;</span>
<span class="line-removed"> 5953             &quot;pshufd  $tmp,$src2,0xE\n\t&quot;</span>
<span class="line-removed"> 5954             &quot;vmulsd  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5955             &quot;vextractf32x4  $tmp2,$src2,0x1\n\t&quot;</span>
<span class="line-removed"> 5956             &quot;vmulsd  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5957             &quot;pshufd  $tmp,$src2,0xE\n\t&quot;</span>
<span class="line-removed"> 5958             &quot;vmulsd  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5959             &quot;vextractf32x4  $tmp2,$src2,0x2\n\t&quot;</span>
<span class="line-removed"> 5960             &quot;vmulsd  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5961             &quot;pshufd  $tmp,$tmp2,0xE\n\t&quot;</span>
<span class="line-removed"> 5962             &quot;vmulsd  $dst,$dst,$tmp\n\t&quot;</span>
<span class="line-removed"> 5963             &quot;vextractf32x4  $tmp2,$src2,0x3\n\t&quot;</span>
<span class="line-removed"> 5964             &quot;vmulsd  $dst,$dst,$tmp2\n\t&quot;</span>
<span class="line-removed"> 5965             &quot;pshufd  $tmp,$tmp2,0xE\n\t&quot;</span>
<span class="line-removed"> 5966             &quot;vmulsd  $dst,$dst,$tmp\t! mul reduction8D&quot; %}</span>
<span class="line-removed"> 5967   ins_encode %{</span>
<span class="line-removed"> 5968     __ vmulsd($dst$$XMMRegister, $dst$$XMMRegister, $src2$$XMMRegister);</span>
<span class="line-removed"> 5969     __ pshufd($tmp$$XMMRegister, $src2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5970     __ vmulsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5971     __ vextractf32x4($tmp2$$XMMRegister, $src2$$XMMRegister, 0x1);</span>
<span class="line-removed"> 5972     __ vmulsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5973     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5974     __ vmulsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5975     __ vextractf32x4($tmp2$$XMMRegister, $src2$$XMMRegister, 0x2);</span>
<span class="line-removed"> 5976     __ vmulsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5977     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5978     __ vmulsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5979     __ vextractf32x4($tmp2$$XMMRegister, $src2$$XMMRegister, 0x3);</span>
<span class="line-removed"> 5980     __ vmulsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp2$$XMMRegister);</span>
<span class="line-removed"> 5981     __ pshufd($tmp$$XMMRegister, $tmp2$$XMMRegister, 0xE);</span>
<span class="line-removed"> 5982     __ vmulsd($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister);</span>
<span class="line-removed"> 5983   %}</span>
<span class="line-removed"> 5984   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 5985 %}</span>
<span class="line-removed"> 5986 </span>
<span class="line-removed"> 5987 // ====================VECTOR ARITHMETIC=======================================</span>
<span class="line-removed"> 5988 </span>
<span class="line-removed"> 5989 // --------------------------------- ADD --------------------------------------</span>
<span class="line-removed"> 5990 </span>
<span class="line-removed"> 5991 // Bytes vector add</span>
<span class="line-removed"> 5992 instruct vadd4B(vecS dst, vecS src) %{</span>
<span class="line-removed"> 5993   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 5994   match(Set dst (AddVB dst src));</span>
<span class="line-removed"> 5995   format %{ &quot;paddb   $dst,$src\t! add packed4B&quot; %}</span>
<span class="line-removed"> 5996   ins_encode %{</span>
<span class="line-removed"> 5997     __ paddb($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 5998   %}</span>
<span class="line-removed"> 5999   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6000 %}</span>
<span class="line-removed"> 6001 </span>
<span class="line-removed"> 6002 instruct vadd4B_reg(vecS dst, vecS src1, vecS src2) %{</span>
<span class="line-removed"> 6003   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6004   match(Set dst (AddVB src1 src2));</span>
<span class="line-removed"> 6005   format %{ &quot;vpaddb  $dst,$src1,$src2\t! add packed4B&quot; %}</span>
<span class="line-removed"> 6006   ins_encode %{</span>
<span class="line-removed"> 6007     int vector_len = 0;</span>
<span class="line-removed"> 6008     __ vpaddb($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6009   %}</span>
<span class="line-removed"> 6010   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6011 %}</span>
<span class="line-removed"> 6012 </span>
<span class="line-removed"> 6013 </span>
<span class="line-removed"> 6014 instruct vadd4B_mem(vecS dst, vecS src, memory mem) %{</span>
<span class="line-removed"> 6015   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6016   match(Set dst (AddVB src (LoadVector mem)));</span>
<span class="line-removed"> 6017   format %{ &quot;vpaddb  $dst,$src,$mem\t! add packed4B&quot; %}</span>
<span class="line-removed"> 6018   ins_encode %{</span>
<span class="line-removed"> 6019     int vector_len = 0;</span>
<span class="line-removed"> 6020     __ vpaddb($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6021   %}</span>
<span class="line-removed"> 6022   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6023 %}</span>
<span class="line-removed"> 6024 </span>
<span class="line-removed"> 6025 instruct vadd8B(vecD dst, vecD src) %{</span>
<span class="line-removed"> 6026   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6027   match(Set dst (AddVB dst src));</span>
<span class="line-removed"> 6028   format %{ &quot;paddb   $dst,$src\t! add packed8B&quot; %}</span>
<span class="line-removed"> 6029   ins_encode %{</span>
<span class="line-removed"> 6030     __ paddb($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6031   %}</span>
<span class="line-removed"> 6032   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6033 %}</span>
<span class="line-removed"> 6034 </span>
<span class="line-removed"> 6035 instruct vadd8B_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-removed"> 6036   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6037   match(Set dst (AddVB src1 src2));</span>
<span class="line-removed"> 6038   format %{ &quot;vpaddb  $dst,$src1,$src2\t! add packed8B&quot; %}</span>
<span class="line-removed"> 6039   ins_encode %{</span>
<span class="line-removed"> 6040     int vector_len = 0;</span>
<span class="line-removed"> 6041     __ vpaddb($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6042   %}</span>
<span class="line-removed"> 6043   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6044 %}</span>
<span class="line-removed"> 6045 </span>
<span class="line-removed"> 6046 </span>
<span class="line-removed"> 6047 instruct vadd8B_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-removed"> 6048   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6049   match(Set dst (AddVB src (LoadVector mem)));</span>
<span class="line-removed"> 6050   format %{ &quot;vpaddb  $dst,$src,$mem\t! add packed8B&quot; %}</span>
<span class="line-removed"> 6051   ins_encode %{</span>
<span class="line-removed"> 6052     int vector_len = 0;</span>
<span class="line-removed"> 6053     __ vpaddb($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6054   %}</span>
<span class="line-removed"> 6055   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6056 %}</span>
<span class="line-removed"> 6057 </span>
<span class="line-removed"> 6058 instruct vadd16B(vecX dst, vecX src) %{</span>
<span class="line-removed"> 6059   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 6060   match(Set dst (AddVB dst src));</span>
<span class="line-removed"> 6061   format %{ &quot;paddb   $dst,$src\t! add packed16B&quot; %}</span>
<span class="line-removed"> 6062   ins_encode %{</span>
<span class="line-removed"> 6063     __ paddb($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6064   %}</span>
<span class="line-removed"> 6065   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6066 %}</span>
<span class="line-removed"> 6067 </span>
<span class="line-removed"> 6068 instruct vadd16B_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 6069   predicate(UseAVX &gt; 0  &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 6070   match(Set dst (AddVB src1 src2));</span>
<span class="line-removed"> 6071   format %{ &quot;vpaddb  $dst,$src1,$src2\t! add packed16B&quot; %}</span>
<span class="line-removed"> 6072   ins_encode %{</span>
<span class="line-removed"> 6073     int vector_len = 0;</span>
<span class="line-removed"> 6074     __ vpaddb($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6075   %}</span>
<span class="line-removed"> 6076   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6077 %}</span>
<span class="line-removed"> 6078 </span>
<span class="line-removed"> 6079 instruct vadd16B_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 6080   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 6081   match(Set dst (AddVB src (LoadVector mem)));</span>
<span class="line-removed"> 6082   format %{ &quot;vpaddb  $dst,$src,$mem\t! add packed16B&quot; %}</span>
<span class="line-removed"> 6083   ins_encode %{</span>
<span class="line-removed"> 6084     int vector_len = 0;</span>
<span class="line-removed"> 6085     __ vpaddb($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6086   %}</span>
<span class="line-removed"> 6087   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6088 %}</span>
<span class="line-removed"> 6089 </span>
<span class="line-removed"> 6090 instruct vadd32B_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 6091   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-removed"> 6092   match(Set dst (AddVB src1 src2));</span>
<span class="line-removed"> 6093   format %{ &quot;vpaddb  $dst,$src1,$src2\t! add packed32B&quot; %}</span>
<span class="line-removed"> 6094   ins_encode %{</span>
<span class="line-removed"> 6095     int vector_len = 1;</span>
<span class="line-removed"> 6096     __ vpaddb($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6097   %}</span>
<span class="line-removed"> 6098   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6099 %}</span>
<span class="line-removed"> 6100 </span>
<span class="line-removed"> 6101 instruct vadd32B_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 6102   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-removed"> 6103   match(Set dst (AddVB src (LoadVector mem)));</span>
<span class="line-removed"> 6104   format %{ &quot;vpaddb  $dst,$src,$mem\t! add packed32B&quot; %}</span>
<span class="line-removed"> 6105   ins_encode %{</span>
<span class="line-removed"> 6106     int vector_len = 1;</span>
<span class="line-removed"> 6107     __ vpaddb($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6108   %}</span>
<span class="line-removed"> 6109   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6110 %}</span>
<span class="line-removed"> 6111 </span>
<span class="line-removed"> 6112 instruct vadd64B_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 6113   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 64);</span>
<span class="line-removed"> 6114   match(Set dst (AddVB src1 src2));</span>
<span class="line-removed"> 6115   format %{ &quot;vpaddb  $dst,$src1,$src2\t! add packed64B&quot; %}</span>
<span class="line-removed"> 6116   ins_encode %{</span>
<span class="line-removed"> 6117     int vector_len = 2;</span>
<span class="line-removed"> 6118     __ vpaddb($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6119   %}</span>
<span class="line-removed"> 6120   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6121 %}</span>
<span class="line-removed"> 6122 </span>
<span class="line-removed"> 6123 instruct vadd64B_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 6124   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 64);</span>
<span class="line-removed"> 6125   match(Set dst (AddVB src (LoadVector mem)));</span>
<span class="line-removed"> 6126   format %{ &quot;vpaddb  $dst,$src,$mem\t! add packed64B&quot; %}</span>
<span class="line-removed"> 6127   ins_encode %{</span>
<span class="line-removed"> 6128     int vector_len = 2;</span>
<span class="line-removed"> 6129     __ vpaddb($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6130   %}</span>
<span class="line-removed"> 6131   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6132 %}</span>
<span class="line-removed"> 6133 </span>
<span class="line-removed"> 6134 // Shorts/Chars vector add</span>
<span class="line-removed"> 6135 instruct vadd2S(vecS dst, vecS src) %{</span>
<span class="line-removed"> 6136   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6137   match(Set dst (AddVS dst src));</span>
<span class="line-removed"> 6138   format %{ &quot;paddw   $dst,$src\t! add packed2S&quot; %}</span>
<span class="line-removed"> 6139   ins_encode %{</span>
<span class="line-removed"> 6140     __ paddw($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6141   %}</span>
<span class="line-removed"> 6142   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6143 %}</span>
<span class="line-removed"> 6144 </span>
<span class="line-removed"> 6145 instruct vadd2S_reg(vecS dst, vecS src1, vecS src2) %{</span>
<span class="line-removed"> 6146   predicate(UseAVX &gt; 0  &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6147   match(Set dst (AddVS src1 src2));</span>
<span class="line-removed"> 6148   format %{ &quot;vpaddw  $dst,$src1,$src2\t! add packed2S&quot; %}</span>
<span class="line-removed"> 6149   ins_encode %{</span>
<span class="line-removed"> 6150     int vector_len = 0;</span>
<span class="line-removed"> 6151     __ vpaddw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6152   %}</span>
<span class="line-removed"> 6153   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6154 %}</span>
<span class="line-removed"> 6155 </span>
<span class="line-removed"> 6156 instruct vadd2S_mem(vecS dst, vecS src, memory mem) %{</span>
<span class="line-removed"> 6157   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6158   match(Set dst (AddVS src (LoadVector mem)));</span>
<span class="line-removed"> 6159   format %{ &quot;vpaddw  $dst,$src,$mem\t! add packed2S&quot; %}</span>
<span class="line-removed"> 6160   ins_encode %{</span>
<span class="line-removed"> 6161     int vector_len = 0;</span>
<span class="line-removed"> 6162     __ vpaddw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6163   %}</span>
<span class="line-removed"> 6164   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6165 %}</span>
<span class="line-removed"> 6166 </span>
<span class="line-removed"> 6167 instruct vadd4S(vecD dst, vecD src) %{</span>
<span class="line-removed"> 6168   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6169   match(Set dst (AddVS dst src));</span>
<span class="line-removed"> 6170   format %{ &quot;paddw   $dst,$src\t! add packed4S&quot; %}</span>
<span class="line-removed"> 6171   ins_encode %{</span>
<span class="line-removed"> 6172     __ paddw($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6173   %}</span>
<span class="line-removed"> 6174   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6175 %}</span>
<span class="line-removed"> 6176 </span>
<span class="line-removed"> 6177 instruct vadd4S_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-removed"> 6178   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6179   match(Set dst (AddVS src1 src2));</span>
<span class="line-removed"> 6180   format %{ &quot;vpaddw  $dst,$src1,$src2\t! add packed4S&quot; %}</span>
<span class="line-removed"> 6181   ins_encode %{</span>
<span class="line-removed"> 6182     int vector_len = 0;</span>
<span class="line-removed"> 6183     __ vpaddw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6184   %}</span>
<span class="line-removed"> 6185   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6186 %}</span>
<span class="line-removed"> 6187 </span>
<span class="line-removed"> 6188 instruct vadd4S_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-removed"> 6189   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6190   match(Set dst (AddVS src (LoadVector mem)));</span>
<span class="line-removed"> 6191   format %{ &quot;vpaddw  $dst,$src,$mem\t! add packed4S&quot; %}</span>
<span class="line-removed"> 6192   ins_encode %{</span>
<span class="line-removed"> 6193     int vector_len = 0;</span>
<span class="line-removed"> 6194     __ vpaddw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6195   %}</span>
<span class="line-removed"> 6196   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6197 %}</span>
<span class="line-removed"> 6198 </span>
<span class="line-removed"> 6199 instruct vadd8S(vecX dst, vecX src) %{</span>
<span class="line-removed"> 6200   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6201   match(Set dst (AddVS dst src));</span>
<span class="line-removed"> 6202   format %{ &quot;paddw   $dst,$src\t! add packed8S&quot; %}</span>
<span class="line-removed"> 6203   ins_encode %{</span>
<span class="line-removed"> 6204     __ paddw($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6205   %}</span>
<span class="line-removed"> 6206   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6207 %}</span>
<span class="line-removed"> 6208 </span>
<span class="line-removed"> 6209 instruct vadd8S_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 6210   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6211   match(Set dst (AddVS src1 src2));</span>
<span class="line-removed"> 6212   format %{ &quot;vpaddw  $dst,$src1,$src2\t! add packed8S&quot; %}</span>
<span class="line-removed"> 6213   ins_encode %{</span>
<span class="line-removed"> 6214     int vector_len = 0;</span>
<span class="line-removed"> 6215     __ vpaddw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6216   %}</span>
<span class="line-removed"> 6217   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6218 %}</span>
<span class="line-removed"> 6219 </span>
<span class="line-removed"> 6220 instruct vadd8S_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 6221   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6222   match(Set dst (AddVS src (LoadVector mem)));</span>
<span class="line-removed"> 6223   format %{ &quot;vpaddw  $dst,$src,$mem\t! add packed8S&quot; %}</span>
<span class="line-removed"> 6224   ins_encode %{</span>
<span class="line-removed"> 6225     int vector_len = 0;</span>
<span class="line-removed"> 6226     __ vpaddw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6227   %}</span>
<span class="line-removed"> 6228   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6229 %}</span>
<span class="line-removed"> 6230 </span>
<span class="line-removed"> 6231 instruct vadd16S_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 6232   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 6233   match(Set dst (AddVS src1 src2));</span>
<span class="line-removed"> 6234   format %{ &quot;vpaddw  $dst,$src1,$src2\t! add packed16S&quot; %}</span>
<span class="line-removed"> 6235   ins_encode %{</span>
<span class="line-removed"> 6236     int vector_len = 1;</span>
<span class="line-removed"> 6237     __ vpaddw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6238   %}</span>
<span class="line-removed"> 6239   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6240 %}</span>
<span class="line-removed"> 6241 </span>
<span class="line-removed"> 6242 instruct vadd16S_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 6243   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 6244   match(Set dst (AddVS src (LoadVector mem)));</span>
<span class="line-removed"> 6245   format %{ &quot;vpaddw  $dst,$src,$mem\t! add packed16S&quot; %}</span>
<span class="line-removed"> 6246   ins_encode %{</span>
<span class="line-removed"> 6247     int vector_len = 1;</span>
<span class="line-removed"> 6248     __ vpaddw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6249   %}</span>
<span class="line-removed"> 6250   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6251 %}</span>
<span class="line-removed"> 6252 </span>
<span class="line-removed"> 6253 instruct vadd32S_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 6254   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-removed"> 6255   match(Set dst (AddVS src1 src2));</span>
<span class="line-removed"> 6256   format %{ &quot;vpaddw  $dst,$src1,$src2\t! add packed32S&quot; %}</span>
<span class="line-removed"> 6257   ins_encode %{</span>
<span class="line-removed"> 6258     int vector_len = 2;</span>
<span class="line-removed"> 6259     __ vpaddw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6260   %}</span>
<span class="line-removed"> 6261   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6262 %}</span>
<span class="line-removed"> 6263 </span>
<span class="line-removed"> 6264 instruct vadd32S_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 6265   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-removed"> 6266   match(Set dst (AddVS src (LoadVector mem)));</span>
<span class="line-removed"> 6267   format %{ &quot;vpaddw  $dst,$src,$mem\t! add packed32S&quot; %}</span>
<span class="line-removed"> 6268   ins_encode %{</span>
<span class="line-removed"> 6269     int vector_len = 2;</span>
<span class="line-removed"> 6270     __ vpaddw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6271   %}</span>
<span class="line-removed"> 6272   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6273 %}</span>
<span class="line-removed"> 6274 </span>
<span class="line-removed"> 6275 // Integers vector add</span>
<span class="line-removed"> 6276 instruct vadd2I(vecD dst, vecD src) %{</span>
<span class="line-removed"> 6277   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6278   match(Set dst (AddVI dst src));</span>
<span class="line-removed"> 6279   format %{ &quot;paddd   $dst,$src\t! add packed2I&quot; %}</span>
<span class="line-removed"> 6280   ins_encode %{</span>
<span class="line-removed"> 6281     __ paddd($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6282   %}</span>
<span class="line-removed"> 6283   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6284 %}</span>
<span class="line-removed"> 6285 </span>
<span class="line-removed"> 6286 instruct vadd2I_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-removed"> 6287   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6288   match(Set dst (AddVI src1 src2));</span>
<span class="line-removed"> 6289   format %{ &quot;vpaddd  $dst,$src1,$src2\t! add packed2I&quot; %}</span>
<span class="line-removed"> 6290   ins_encode %{</span>
<span class="line-removed"> 6291     int vector_len = 0;</span>
<span class="line-removed"> 6292     __ vpaddd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6293   %}</span>
<span class="line-removed"> 6294   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6295 %}</span>
<span class="line-removed"> 6296 </span>
<span class="line-removed"> 6297 instruct vadd2I_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-removed"> 6298   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6299   match(Set dst (AddVI src (LoadVector mem)));</span>
<span class="line-removed"> 6300   format %{ &quot;vpaddd  $dst,$src,$mem\t! add packed2I&quot; %}</span>
<span class="line-removed"> 6301   ins_encode %{</span>
<span class="line-removed"> 6302     int vector_len = 0;</span>
<span class="line-removed"> 6303     __ vpaddd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6304   %}</span>
<span class="line-removed"> 6305   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6306 %}</span>
<span class="line-removed"> 6307 </span>
<span class="line-removed"> 6308 instruct vadd4I(vecX dst, vecX src) %{</span>
<span class="line-removed"> 6309   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6310   match(Set dst (AddVI dst src));</span>
<span class="line-removed"> 6311   format %{ &quot;paddd   $dst,$src\t! add packed4I&quot; %}</span>
<span class="line-removed"> 6312   ins_encode %{</span>
<span class="line-removed"> 6313     __ paddd($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6314   %}</span>
<span class="line-removed"> 6315   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6316 %}</span>
<span class="line-removed"> 6317 </span>
<span class="line-removed"> 6318 instruct vadd4I_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 6319   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6320   match(Set dst (AddVI src1 src2));</span>
<span class="line-removed"> 6321   format %{ &quot;vpaddd  $dst,$src1,$src2\t! add packed4I&quot; %}</span>
<span class="line-removed"> 6322   ins_encode %{</span>
<span class="line-removed"> 6323     int vector_len = 0;</span>
<span class="line-removed"> 6324     __ vpaddd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6325   %}</span>
<span class="line-removed"> 6326   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6327 %}</span>
<span class="line-removed"> 6328 </span>
<span class="line-removed"> 6329 instruct vadd4I_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 6330   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6331   match(Set dst (AddVI src (LoadVector mem)));</span>
<span class="line-removed"> 6332   format %{ &quot;vpaddd  $dst,$src,$mem\t! add packed4I&quot; %}</span>
<span class="line-removed"> 6333   ins_encode %{</span>
<span class="line-removed"> 6334     int vector_len = 0;</span>
<span class="line-removed"> 6335     __ vpaddd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6336   %}</span>
<span class="line-removed"> 6337   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6338 %}</span>
<span class="line-removed"> 6339 </span>
<span class="line-removed"> 6340 instruct vadd8I_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 6341   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6342   match(Set dst (AddVI src1 src2));</span>
<span class="line-removed"> 6343   format %{ &quot;vpaddd  $dst,$src1,$src2\t! add packed8I&quot; %}</span>
<span class="line-removed"> 6344   ins_encode %{</span>
<span class="line-removed"> 6345     int vector_len = 1;</span>
<span class="line-removed"> 6346     __ vpaddd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6347   %}</span>
<span class="line-removed"> 6348   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6349 %}</span>
<span class="line-removed"> 6350 </span>
<span class="line-removed"> 6351 instruct vadd8I_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 6352   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6353   match(Set dst (AddVI src (LoadVector mem)));</span>
<span class="line-removed"> 6354   format %{ &quot;vpaddd  $dst,$src,$mem\t! add packed8I&quot; %}</span>
<span class="line-removed"> 6355   ins_encode %{</span>
<span class="line-removed"> 6356     int vector_len = 1;</span>
<span class="line-removed"> 6357     __ vpaddd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6358   %}</span>
<span class="line-removed"> 6359   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6360 %}</span>
<span class="line-removed"> 6361 </span>
<span class="line-removed"> 6362 instruct vadd16I_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 6363   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 6364   match(Set dst (AddVI src1 src2));</span>
<span class="line-removed"> 6365   format %{ &quot;vpaddd  $dst,$src1,$src2\t! add packed16I&quot; %}</span>
<span class="line-removed"> 6366   ins_encode %{</span>
<span class="line-removed"> 6367     int vector_len = 2;</span>
<span class="line-removed"> 6368     __ vpaddd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6369   %}</span>
<span class="line-removed"> 6370   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6371 %}</span>
<span class="line-removed"> 6372 </span>
<span class="line-removed"> 6373 instruct vadd16I_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 6374   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 6375   match(Set dst (AddVI src (LoadVector mem)));</span>
<span class="line-removed"> 6376   format %{ &quot;vpaddd  $dst,$src,$mem\t! add packed16I&quot; %}</span>
<span class="line-removed"> 6377   ins_encode %{</span>
<span class="line-removed"> 6378     int vector_len = 2;</span>
<span class="line-removed"> 6379     __ vpaddd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6380   %}</span>
<span class="line-removed"> 6381   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6382 %}</span>
<span class="line-removed"> 6383 </span>
<span class="line-removed"> 6384 // Longs vector add</span>
<span class="line-removed"> 6385 instruct vadd2L(vecX dst, vecX src) %{</span>
<span class="line-removed"> 6386   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6387   match(Set dst (AddVL dst src));</span>
<span class="line-removed"> 6388   format %{ &quot;paddq   $dst,$src\t! add packed2L&quot; %}</span>
<span class="line-removed"> 6389   ins_encode %{</span>
<span class="line-removed"> 6390     __ paddq($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6391   %}</span>
<span class="line-removed"> 6392   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6393 %}</span>
<span class="line-removed"> 6394 </span>
<span class="line-removed"> 6395 instruct vadd2L_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 6396   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6397   match(Set dst (AddVL src1 src2));</span>
<span class="line-removed"> 6398   format %{ &quot;vpaddq  $dst,$src1,$src2\t! add packed2L&quot; %}</span>
<span class="line-removed"> 6399   ins_encode %{</span>
<span class="line-removed"> 6400     int vector_len = 0;</span>
<span class="line-removed"> 6401     __ vpaddq($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6402   %}</span>
<span class="line-removed"> 6403   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6404 %}</span>
<span class="line-removed"> 6405 </span>
<span class="line-removed"> 6406 instruct vadd2L_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 6407   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6408   match(Set dst (AddVL src (LoadVector mem)));</span>
<span class="line-removed"> 6409   format %{ &quot;vpaddq  $dst,$src,$mem\t! add packed2L&quot; %}</span>
<span class="line-removed"> 6410   ins_encode %{</span>
<span class="line-removed"> 6411     int vector_len = 0;</span>
<span class="line-removed"> 6412     __ vpaddq($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6413   %}</span>
<span class="line-removed"> 6414   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6415 %}</span>
<span class="line-removed"> 6416 </span>
<span class="line-removed"> 6417 instruct vadd4L_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 6418   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6419   match(Set dst (AddVL src1 src2));</span>
<span class="line-removed"> 6420   format %{ &quot;vpaddq  $dst,$src1,$src2\t! add packed4L&quot; %}</span>
<span class="line-removed"> 6421   ins_encode %{</span>
<span class="line-removed"> 6422     int vector_len = 1;</span>
<span class="line-removed"> 6423     __ vpaddq($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6424   %}</span>
<span class="line-removed"> 6425   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6426 %}</span>
<span class="line-removed"> 6427 </span>
<span class="line-removed"> 6428 instruct vadd4L_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 6429   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6430   match(Set dst (AddVL src (LoadVector mem)));</span>
<span class="line-removed"> 6431   format %{ &quot;vpaddq  $dst,$src,$mem\t! add packed4L&quot; %}</span>
<span class="line-removed"> 6432   ins_encode %{</span>
<span class="line-removed"> 6433     int vector_len = 1;</span>
<span class="line-removed"> 6434     __ vpaddq($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6435   %}</span>
<span class="line-removed"> 6436   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6437 %}</span>
<span class="line-removed"> 6438 </span>
<span class="line-removed"> 6439 instruct vadd8L_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 6440   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6441   match(Set dst (AddVL src1 src2));</span>
<span class="line-removed"> 6442   format %{ &quot;vpaddq  $dst,$src1,$src2\t! add packed8L&quot; %}</span>
<span class="line-removed"> 6443   ins_encode %{</span>
<span class="line-removed"> 6444     int vector_len = 2;</span>
<span class="line-removed"> 6445     __ vpaddq($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6446   %}</span>
<span class="line-removed"> 6447   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6448 %}</span>
<span class="line-removed"> 6449 </span>
<span class="line-removed"> 6450 instruct vadd8L_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 6451   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6452   match(Set dst (AddVL src (LoadVector mem)));</span>
<span class="line-removed"> 6453   format %{ &quot;vpaddq  $dst,$src,$mem\t! add packed8L&quot; %}</span>
<span class="line-removed"> 6454   ins_encode %{</span>
<span class="line-removed"> 6455     int vector_len = 2;</span>
<span class="line-removed"> 6456     __ vpaddq($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6457   %}</span>
<span class="line-removed"> 6458   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6459 %}</span>
<span class="line-removed"> 6460 </span>
<span class="line-removed"> 6461 // Floats vector add</span>
<span class="line-removed"> 6462 instruct vadd2F(vecD dst, vecD src) %{</span>
<span class="line-removed"> 6463   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6464   match(Set dst (AddVF dst src));</span>
<span class="line-removed"> 6465   format %{ &quot;addps   $dst,$src\t! add packed2F&quot; %}</span>
<span class="line-removed"> 6466   ins_encode %{</span>
<span class="line-removed"> 6467     __ addps($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6468   %}</span>
<span class="line-removed"> 6469   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6470 %}</span>
<span class="line-removed"> 6471 </span>
<span class="line-removed"> 6472 instruct vadd2F_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-removed"> 6473   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6474   match(Set dst (AddVF src1 src2));</span>
<span class="line-removed"> 6475   format %{ &quot;vaddps  $dst,$src1,$src2\t! add packed2F&quot; %}</span>
<span class="line-removed"> 6476   ins_encode %{</span>
<span class="line-removed"> 6477     int vector_len = 0;</span>
<span class="line-removed"> 6478     __ vaddps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6479   %}</span>
<span class="line-removed"> 6480   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6481 %}</span>
<span class="line-removed"> 6482 </span>
<span class="line-removed"> 6483 instruct vadd2F_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-removed"> 6484   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6485   match(Set dst (AddVF src (LoadVector mem)));</span>
<span class="line-removed"> 6486   format %{ &quot;vaddps  $dst,$src,$mem\t! add packed2F&quot; %}</span>
<span class="line-removed"> 6487   ins_encode %{</span>
<span class="line-removed"> 6488     int vector_len = 0;</span>
<span class="line-removed"> 6489     __ vaddps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6490   %}</span>
<span class="line-removed"> 6491   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6492 %}</span>
<span class="line-removed"> 6493 </span>
<span class="line-removed"> 6494 instruct vadd4F(vecX dst, vecX src) %{</span>
<span class="line-removed"> 6495   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6496   match(Set dst (AddVF dst src));</span>
<span class="line-removed"> 6497   format %{ &quot;addps   $dst,$src\t! add packed4F&quot; %}</span>
<span class="line-removed"> 6498   ins_encode %{</span>
<span class="line-removed"> 6499     __ addps($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6500   %}</span>
<span class="line-removed"> 6501   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6502 %}</span>
<span class="line-removed"> 6503 </span>
<span class="line-removed"> 6504 instruct vadd4F_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 6505   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6506   match(Set dst (AddVF src1 src2));</span>
<span class="line-removed"> 6507   format %{ &quot;vaddps  $dst,$src1,$src2\t! add packed4F&quot; %}</span>
<span class="line-removed"> 6508   ins_encode %{</span>
<span class="line-removed"> 6509     int vector_len = 0;</span>
<span class="line-removed"> 6510     __ vaddps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6511   %}</span>
<span class="line-removed"> 6512   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6513 %}</span>
<span class="line-removed"> 6514 </span>
<span class="line-removed"> 6515 instruct vadd4F_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 6516   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6517   match(Set dst (AddVF src (LoadVector mem)));</span>
<span class="line-removed"> 6518   format %{ &quot;vaddps  $dst,$src,$mem\t! add packed4F&quot; %}</span>
<span class="line-removed"> 6519   ins_encode %{</span>
<span class="line-removed"> 6520     int vector_len = 0;</span>
<span class="line-removed"> 6521     __ vaddps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6522   %}</span>
<span class="line-removed"> 6523   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6524 %}</span>
<span class="line-removed"> 6525 </span>
<span class="line-removed"> 6526 instruct vadd8F_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 6527   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6528   match(Set dst (AddVF src1 src2));</span>
<span class="line-removed"> 6529   format %{ &quot;vaddps  $dst,$src1,$src2\t! add packed8F&quot; %}</span>
<span class="line-removed"> 6530   ins_encode %{</span>
<span class="line-removed"> 6531     int vector_len = 1;</span>
<span class="line-removed"> 6532     __ vaddps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6533   %}</span>
<span class="line-removed"> 6534   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6535 %}</span>
<span class="line-removed"> 6536 </span>
<span class="line-removed"> 6537 instruct vadd8F_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 6538   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6539   match(Set dst (AddVF src (LoadVector mem)));</span>
<span class="line-removed"> 6540   format %{ &quot;vaddps  $dst,$src,$mem\t! add packed8F&quot; %}</span>
<span class="line-removed"> 6541   ins_encode %{</span>
<span class="line-removed"> 6542     int vector_len = 1;</span>
<span class="line-removed"> 6543     __ vaddps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6544   %}</span>
<span class="line-removed"> 6545   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6546 %}</span>
<span class="line-removed"> 6547 </span>
<span class="line-removed"> 6548 instruct vadd16F_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 6549   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 6550   match(Set dst (AddVF src1 src2));</span>
<span class="line-removed"> 6551   format %{ &quot;vaddps  $dst,$src1,$src2\t! add packed16F&quot; %}</span>
<span class="line-removed"> 6552   ins_encode %{</span>
<span class="line-removed"> 6553     int vector_len = 2;</span>
<span class="line-removed"> 6554     __ vaddps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6555   %}</span>
<span class="line-removed"> 6556   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6557 %}</span>
<span class="line-removed"> 6558 </span>
<span class="line-removed"> 6559 instruct vadd16F_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 6560   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 6561   match(Set dst (AddVF src (LoadVector mem)));</span>
<span class="line-removed"> 6562   format %{ &quot;vaddps  $dst,$src,$mem\t! add packed16F&quot; %}</span>
<span class="line-removed"> 6563   ins_encode %{</span>
<span class="line-removed"> 6564     int vector_len = 2;</span>
<span class="line-removed"> 6565     __ vaddps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6566   %}</span>
<span class="line-removed"> 6567   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6568 %}</span>
<span class="line-removed"> 6569 </span>
<span class="line-removed"> 6570 // Doubles vector add</span>
<span class="line-removed"> 6571 instruct vadd2D(vecX dst, vecX src) %{</span>
<span class="line-removed"> 6572   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6573   match(Set dst (AddVD dst src));</span>
<span class="line-removed"> 6574   format %{ &quot;addpd   $dst,$src\t! add packed2D&quot; %}</span>
<span class="line-removed"> 6575   ins_encode %{</span>
<span class="line-removed"> 6576     __ addpd($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6577   %}</span>
<span class="line-removed"> 6578   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6579 %}</span>
<span class="line-removed"> 6580 </span>
<span class="line-removed"> 6581 instruct vadd2D_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 6582   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6583   match(Set dst (AddVD src1 src2));</span>
<span class="line-removed"> 6584   format %{ &quot;vaddpd  $dst,$src1,$src2\t! add packed2D&quot; %}</span>
<span class="line-removed"> 6585   ins_encode %{</span>
<span class="line-removed"> 6586     int vector_len = 0;</span>
<span class="line-removed"> 6587     __ vaddpd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6588   %}</span>
<span class="line-removed"> 6589   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6590 %}</span>
<span class="line-removed"> 6591 </span>
<span class="line-removed"> 6592 instruct vadd2D_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 6593   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6594   match(Set dst (AddVD src (LoadVector mem)));</span>
<span class="line-removed"> 6595   format %{ &quot;vaddpd  $dst,$src,$mem\t! add packed2D&quot; %}</span>
<span class="line-removed"> 6596   ins_encode %{</span>
<span class="line-removed"> 6597     int vector_len = 0;</span>
<span class="line-removed"> 6598     __ vaddpd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6599   %}</span>
<span class="line-removed"> 6600   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6601 %}</span>
<span class="line-removed"> 6602 </span>
<span class="line-removed"> 6603 instruct vadd4D_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 6604   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6605   match(Set dst (AddVD src1 src2));</span>
<span class="line-removed"> 6606   format %{ &quot;vaddpd  $dst,$src1,$src2\t! add packed4D&quot; %}</span>
<span class="line-removed"> 6607   ins_encode %{</span>
<span class="line-removed"> 6608     int vector_len = 1;</span>
<span class="line-removed"> 6609     __ vaddpd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6610   %}</span>
<span class="line-removed"> 6611   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6612 %}</span>
<span class="line-removed"> 6613 </span>
<span class="line-removed"> 6614 instruct vadd4D_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 6615   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6616   match(Set dst (AddVD src (LoadVector mem)));</span>
<span class="line-removed"> 6617   format %{ &quot;vaddpd  $dst,$src,$mem\t! add packed4D&quot; %}</span>
<span class="line-removed"> 6618   ins_encode %{</span>
<span class="line-removed"> 6619     int vector_len = 1;</span>
<span class="line-removed"> 6620     __ vaddpd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6621   %}</span>
<span class="line-removed"> 6622   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6623 %}</span>
<span class="line-removed"> 6624 </span>
<span class="line-removed"> 6625 instruct vadd8D_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 6626   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6627   match(Set dst (AddVD src1 src2));</span>
<span class="line-removed"> 6628   format %{ &quot;vaddpd  $dst,$src1,$src2\t! add packed8D&quot; %}</span>
<span class="line-removed"> 6629   ins_encode %{</span>
<span class="line-removed"> 6630     int vector_len = 2;</span>
<span class="line-removed"> 6631     __ vaddpd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6632   %}</span>
<span class="line-removed"> 6633   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6634 %}</span>
<span class="line-removed"> 6635 </span>
<span class="line-removed"> 6636 instruct vadd8D_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 6637   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6638   match(Set dst (AddVD src (LoadVector mem)));</span>
<span class="line-removed"> 6639   format %{ &quot;vaddpd  $dst,$src,$mem\t! add packed8D&quot; %}</span>
<span class="line-removed"> 6640   ins_encode %{</span>
<span class="line-removed"> 6641     int vector_len = 2;</span>
<span class="line-removed"> 6642     __ vaddpd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6643   %}</span>
<span class="line-removed"> 6644   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6645 %}</span>
<span class="line-removed"> 6646 </span>
<span class="line-removed"> 6647 // --------------------------------- SUB --------------------------------------</span>
<span class="line-removed"> 6648 </span>
<span class="line-removed"> 6649 // Bytes vector sub</span>
<span class="line-removed"> 6650 instruct vsub4B(vecS dst, vecS src) %{</span>
<span class="line-removed"> 6651   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6652   match(Set dst (SubVB dst src));</span>
<span class="line-removed"> 6653   format %{ &quot;psubb   $dst,$src\t! sub packed4B&quot; %}</span>
<span class="line-removed"> 6654   ins_encode %{</span>
<span class="line-removed"> 6655     __ psubb($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6656   %}</span>
<span class="line-removed"> 6657   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6658 %}</span>
<span class="line-removed"> 6659 </span>
<span class="line-removed"> 6660 instruct vsub4B_reg(vecS dst, vecS src1, vecS src2) %{</span>
<span class="line-removed"> 6661   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6662   match(Set dst (SubVB src1 src2));</span>
<span class="line-removed"> 6663   format %{ &quot;vpsubb  $dst,$src1,$src2\t! sub packed4B&quot; %}</span>
<span class="line-removed"> 6664   ins_encode %{</span>
<span class="line-removed"> 6665     int vector_len = 0;</span>
<span class="line-removed"> 6666     __ vpsubb($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6667   %}</span>
<span class="line-removed"> 6668   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6669 %}</span>
<span class="line-removed"> 6670 </span>
<span class="line-removed"> 6671 instruct vsub4B_mem(vecS dst, vecS src, memory mem) %{</span>
<span class="line-removed"> 6672   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6673   match(Set dst (SubVB src (LoadVector mem)));</span>
<span class="line-removed"> 6674   format %{ &quot;vpsubb  $dst,$src,$mem\t! sub packed4B&quot; %}</span>
<span class="line-removed"> 6675   ins_encode %{</span>
<span class="line-removed"> 6676     int vector_len = 0;</span>
<span class="line-removed"> 6677     __ vpsubb($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6678   %}</span>
<span class="line-removed"> 6679   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6680 %}</span>
<span class="line-removed"> 6681 </span>
<span class="line-removed"> 6682 instruct vsub8B(vecD dst, vecD src) %{</span>
<span class="line-removed"> 6683   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6684   match(Set dst (SubVB dst src));</span>
<span class="line-removed"> 6685   format %{ &quot;psubb   $dst,$src\t! sub packed8B&quot; %}</span>
<span class="line-removed"> 6686   ins_encode %{</span>
<span class="line-removed"> 6687     __ psubb($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6688   %}</span>
<span class="line-removed"> 6689   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6690 %}</span>
<span class="line-removed"> 6691 </span>
<span class="line-removed"> 6692 instruct vsub8B_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-removed"> 6693   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6694   match(Set dst (SubVB src1 src2));</span>
<span class="line-removed"> 6695   format %{ &quot;vpsubb  $dst,$src1,$src2\t! sub packed8B&quot; %}</span>
<span class="line-removed"> 6696   ins_encode %{</span>
<span class="line-removed"> 6697     int vector_len = 0;</span>
<span class="line-removed"> 6698     __ vpsubb($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6699   %}</span>
<span class="line-removed"> 6700   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6701 %}</span>
<span class="line-removed"> 6702 </span>
<span class="line-removed"> 6703 instruct vsub8B_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-removed"> 6704   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6705   match(Set dst (SubVB src (LoadVector mem)));</span>
<span class="line-removed"> 6706   format %{ &quot;vpsubb  $dst,$src,$mem\t! sub packed8B&quot; %}</span>
<span class="line-removed"> 6707   ins_encode %{</span>
<span class="line-removed"> 6708     int vector_len = 0;</span>
<span class="line-removed"> 6709     __ vpsubb($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6710   %}</span>
<span class="line-removed"> 6711   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6712 %}</span>
<span class="line-removed"> 6713 </span>
<span class="line-removed"> 6714 instruct vsub16B(vecX dst, vecX src) %{</span>
<span class="line-removed"> 6715   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 6716   match(Set dst (SubVB dst src));</span>
<span class="line-removed"> 6717   format %{ &quot;psubb   $dst,$src\t! sub packed16B&quot; %}</span>
<span class="line-removed"> 6718   ins_encode %{</span>
<span class="line-removed"> 6719     __ psubb($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6720   %}</span>
<span class="line-removed"> 6721   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6722 %}</span>
<span class="line-removed"> 6723 </span>
<span class="line-removed"> 6724 instruct vsub16B_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 6725   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 6726   match(Set dst (SubVB src1 src2));</span>
<span class="line-removed"> 6727   format %{ &quot;vpsubb  $dst,$src1,$src2\t! sub packed16B&quot; %}</span>
<span class="line-removed"> 6728   ins_encode %{</span>
<span class="line-removed"> 6729     int vector_len = 0;</span>
<span class="line-removed"> 6730     __ vpsubb($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6731   %}</span>
<span class="line-removed"> 6732   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6733 %}</span>
<span class="line-removed"> 6734 </span>
<span class="line-removed"> 6735 instruct vsub16B_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 6736   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 6737   match(Set dst (SubVB src (LoadVector mem)));</span>
<span class="line-removed"> 6738   format %{ &quot;vpsubb  $dst,$src,$mem\t! sub packed16B&quot; %}</span>
<span class="line-removed"> 6739   ins_encode %{</span>
<span class="line-removed"> 6740     int vector_len = 0;</span>
<span class="line-removed"> 6741     __ vpsubb($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6742   %}</span>
<span class="line-removed"> 6743   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6744 %}</span>
<span class="line-removed"> 6745 </span>
<span class="line-removed"> 6746 instruct vsub32B_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 6747   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-removed"> 6748   match(Set dst (SubVB src1 src2));</span>
<span class="line-removed"> 6749   format %{ &quot;vpsubb  $dst,$src1,$src2\t! sub packed32B&quot; %}</span>
<span class="line-removed"> 6750   ins_encode %{</span>
<span class="line-removed"> 6751     int vector_len = 1;</span>
<span class="line-removed"> 6752     __ vpsubb($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6753   %}</span>
<span class="line-removed"> 6754   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6755 %}</span>
<span class="line-removed"> 6756 </span>
<span class="line-removed"> 6757 instruct vsub32B_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 6758   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-removed"> 6759   match(Set dst (SubVB src (LoadVector mem)));</span>
<span class="line-removed"> 6760   format %{ &quot;vpsubb  $dst,$src,$mem\t! sub packed32B&quot; %}</span>
<span class="line-removed"> 6761   ins_encode %{</span>
<span class="line-removed"> 6762     int vector_len = 1;</span>
<span class="line-removed"> 6763     __ vpsubb($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6764   %}</span>
<span class="line-removed"> 6765   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6766 %}</span>
<span class="line-removed"> 6767 </span>
<span class="line-removed"> 6768 instruct vsub64B_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 6769   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 64);</span>
<span class="line-removed"> 6770   match(Set dst (SubVB src1 src2));</span>
<span class="line-removed"> 6771   format %{ &quot;vpsubb  $dst,$src1,$src2\t! sub packed64B&quot; %}</span>
<span class="line-removed"> 6772   ins_encode %{</span>
<span class="line-removed"> 6773     int vector_len = 2;</span>
<span class="line-removed"> 6774     __ vpsubb($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6775   %}</span>
<span class="line-removed"> 6776   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6777 %}</span>
<span class="line-removed"> 6778 </span>
<span class="line-removed"> 6779 instruct vsub64B_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 6780   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 64);</span>
<span class="line-removed"> 6781   match(Set dst (SubVB src (LoadVector mem)));</span>
<span class="line-removed"> 6782   format %{ &quot;vpsubb  $dst,$src,$mem\t! sub packed64B&quot; %}</span>
<span class="line-removed"> 6783   ins_encode %{</span>
<span class="line-removed"> 6784     int vector_len = 2;</span>
<span class="line-removed"> 6785     __ vpsubb($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6786   %}</span>
<span class="line-removed"> 6787   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6788 %}</span>
<span class="line-removed"> 6789 </span>
<span class="line-removed"> 6790 // Shorts/Chars vector sub</span>
<span class="line-removed"> 6791 instruct vsub2S(vecS dst, vecS src) %{</span>
<span class="line-removed"> 6792   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6793   match(Set dst (SubVS dst src));</span>
<span class="line-removed"> 6794   format %{ &quot;psubw   $dst,$src\t! sub packed2S&quot; %}</span>
<span class="line-removed"> 6795   ins_encode %{</span>
<span class="line-removed"> 6796     __ psubw($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6797   %}</span>
<span class="line-removed"> 6798   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6799 %}</span>
<span class="line-removed"> 6800 </span>
<span class="line-removed"> 6801 instruct vsub2S_reg(vecS dst, vecS src1, vecS src2) %{</span>
<span class="line-removed"> 6802   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6803   match(Set dst (SubVS src1 src2));</span>
<span class="line-removed"> 6804   format %{ &quot;vpsubw  $dst,$src1,$src2\t! sub packed2S&quot; %}</span>
<span class="line-removed"> 6805   ins_encode %{</span>
<span class="line-removed"> 6806     int vector_len = 0;</span>
<span class="line-removed"> 6807     __ vpsubw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6808   %}</span>
<span class="line-removed"> 6809   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6810 %}</span>
<span class="line-removed"> 6811 </span>
<span class="line-removed"> 6812 instruct vsub2S_mem(vecS dst, vecS src, memory mem) %{</span>
<span class="line-removed"> 6813   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6814   match(Set dst (SubVS src (LoadVector mem)));</span>
<span class="line-removed"> 6815   format %{ &quot;vpsubw  $dst,$src,$mem\t! sub packed2S&quot; %}</span>
<span class="line-removed"> 6816   ins_encode %{</span>
<span class="line-removed"> 6817     int vector_len = 0;</span>
<span class="line-removed"> 6818     __ vpsubw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6819   %}</span>
<span class="line-removed"> 6820   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6821 %}</span>
<span class="line-removed"> 6822 </span>
<span class="line-removed"> 6823 instruct vsub4S(vecD dst, vecD src) %{</span>
<span class="line-removed"> 6824   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6825   match(Set dst (SubVS dst src));</span>
<span class="line-removed"> 6826   format %{ &quot;psubw   $dst,$src\t! sub packed4S&quot; %}</span>
<span class="line-removed"> 6827   ins_encode %{</span>
<span class="line-removed"> 6828     __ psubw($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6829   %}</span>
<span class="line-removed"> 6830   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6831 %}</span>
<span class="line-removed"> 6832 </span>
<span class="line-removed"> 6833 instruct vsub4S_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-removed"> 6834   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6835   match(Set dst (SubVS src1 src2));</span>
<span class="line-removed"> 6836   format %{ &quot;vpsubw  $dst,$src1,$src2\t! sub packed4S&quot; %}</span>
<span class="line-removed"> 6837   ins_encode %{</span>
<span class="line-removed"> 6838     int vector_len = 0;</span>
<span class="line-removed"> 6839     __ vpsubw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6840   %}</span>
<span class="line-removed"> 6841   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6842 %}</span>
<span class="line-removed"> 6843 </span>
<span class="line-removed"> 6844 instruct vsub4S_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-removed"> 6845   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6846   match(Set dst (SubVS src (LoadVector mem)));</span>
<span class="line-removed"> 6847   format %{ &quot;vpsubw  $dst,$src,$mem\t! sub packed4S&quot; %}</span>
<span class="line-removed"> 6848   ins_encode %{</span>
<span class="line-removed"> 6849     int vector_len = 0;</span>
<span class="line-removed"> 6850     __ vpsubw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6851   %}</span>
<span class="line-removed"> 6852   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6853 %}</span>
<span class="line-removed"> 6854 </span>
<span class="line-removed"> 6855 instruct vsub8S(vecX dst, vecX src) %{</span>
<span class="line-removed"> 6856   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6857   match(Set dst (SubVS dst src));</span>
<span class="line-removed"> 6858   format %{ &quot;psubw   $dst,$src\t! sub packed8S&quot; %}</span>
<span class="line-removed"> 6859   ins_encode %{</span>
<span class="line-removed"> 6860     __ psubw($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6861   %}</span>
<span class="line-removed"> 6862   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6863 %}</span>
<span class="line-removed"> 6864 </span>
<span class="line-removed"> 6865 instruct vsub8S_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 6866   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6867   match(Set dst (SubVS src1 src2));</span>
<span class="line-removed"> 6868   format %{ &quot;vpsubw  $dst,$src1,$src2\t! sub packed8S&quot; %}</span>
<span class="line-removed"> 6869   ins_encode %{</span>
<span class="line-removed"> 6870     int vector_len = 0;</span>
<span class="line-removed"> 6871     __ vpsubw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6872   %}</span>
<span class="line-removed"> 6873   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6874 %}</span>
<span class="line-removed"> 6875 </span>
<span class="line-removed"> 6876 instruct vsub8S_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 6877   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6878   match(Set dst (SubVS src (LoadVector mem)));</span>
<span class="line-removed"> 6879   format %{ &quot;vpsubw  $dst,$src,$mem\t! sub packed8S&quot; %}</span>
<span class="line-removed"> 6880   ins_encode %{</span>
<span class="line-removed"> 6881     int vector_len = 0;</span>
<span class="line-removed"> 6882     __ vpsubw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6883   %}</span>
<span class="line-removed"> 6884   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6885 %}</span>
<span class="line-removed"> 6886 </span>
<span class="line-removed"> 6887 instruct vsub16S_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 6888   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 6889   match(Set dst (SubVS src1 src2));</span>
<span class="line-removed"> 6890   format %{ &quot;vpsubw  $dst,$src1,$src2\t! sub packed16S&quot; %}</span>
<span class="line-removed"> 6891   ins_encode %{</span>
<span class="line-removed"> 6892     int vector_len = 1;</span>
<span class="line-removed"> 6893     __ vpsubw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6894   %}</span>
<span class="line-removed"> 6895   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6896 %}</span>
<span class="line-removed"> 6897 </span>
<span class="line-removed"> 6898 instruct vsub16S_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 6899   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 6900   match(Set dst (SubVS src (LoadVector mem)));</span>
<span class="line-removed"> 6901   format %{ &quot;vpsubw  $dst,$src,$mem\t! sub packed16S&quot; %}</span>
<span class="line-removed"> 6902   ins_encode %{</span>
<span class="line-removed"> 6903     int vector_len = 1;</span>
<span class="line-removed"> 6904     __ vpsubw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6905   %}</span>
<span class="line-removed"> 6906   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6907 %}</span>
<span class="line-removed"> 6908 </span>
<span class="line-removed"> 6909 instruct vsub32S_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 6910   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-removed"> 6911   match(Set dst (SubVS src1 src2));</span>
<span class="line-removed"> 6912   format %{ &quot;vpsubw  $dst,$src1,$src2\t! sub packed32S&quot; %}</span>
<span class="line-removed"> 6913   ins_encode %{</span>
<span class="line-removed"> 6914     int vector_len = 2;</span>
<span class="line-removed"> 6915     __ vpsubw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6916   %}</span>
<span class="line-removed"> 6917   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6918 %}</span>
<span class="line-removed"> 6919 </span>
<span class="line-removed"> 6920 instruct vsub32S_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 6921   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-removed"> 6922   match(Set dst (SubVS src (LoadVector mem)));</span>
<span class="line-removed"> 6923   format %{ &quot;vpsubw  $dst,$src,$mem\t! sub packed32S&quot; %}</span>
<span class="line-removed"> 6924   ins_encode %{</span>
<span class="line-removed"> 6925     int vector_len = 2;</span>
<span class="line-removed"> 6926     __ vpsubw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6927   %}</span>
<span class="line-removed"> 6928   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6929 %}</span>
<span class="line-removed"> 6930 </span>
<span class="line-removed"> 6931 // Integers vector sub</span>
<span class="line-removed"> 6932 instruct vsub2I(vecD dst, vecD src) %{</span>
<span class="line-removed"> 6933   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6934   match(Set dst (SubVI dst src));</span>
<span class="line-removed"> 6935   format %{ &quot;psubd   $dst,$src\t! sub packed2I&quot; %}</span>
<span class="line-removed"> 6936   ins_encode %{</span>
<span class="line-removed"> 6937     __ psubd($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6938   %}</span>
<span class="line-removed"> 6939   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6940 %}</span>
<span class="line-removed"> 6941 </span>
<span class="line-removed"> 6942 instruct vsub2I_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-removed"> 6943   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6944   match(Set dst (SubVI src1 src2));</span>
<span class="line-removed"> 6945   format %{ &quot;vpsubd  $dst,$src1,$src2\t! sub packed2I&quot; %}</span>
<span class="line-removed"> 6946   ins_encode %{</span>
<span class="line-removed"> 6947     int vector_len = 0;</span>
<span class="line-removed"> 6948     __ vpsubd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6949   %}</span>
<span class="line-removed"> 6950   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6951 %}</span>
<span class="line-removed"> 6952 </span>
<span class="line-removed"> 6953 instruct vsub2I_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-removed"> 6954   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 6955   match(Set dst (SubVI src (LoadVector mem)));</span>
<span class="line-removed"> 6956   format %{ &quot;vpsubd  $dst,$src,$mem\t! sub packed2I&quot; %}</span>
<span class="line-removed"> 6957   ins_encode %{</span>
<span class="line-removed"> 6958     int vector_len = 0;</span>
<span class="line-removed"> 6959     __ vpsubd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6960   %}</span>
<span class="line-removed"> 6961   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6962 %}</span>
<span class="line-removed"> 6963 </span>
<span class="line-removed"> 6964 instruct vsub4I(vecX dst, vecX src) %{</span>
<span class="line-removed"> 6965   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6966   match(Set dst (SubVI dst src));</span>
<span class="line-removed"> 6967   format %{ &quot;psubd   $dst,$src\t! sub packed4I&quot; %}</span>
<span class="line-removed"> 6968   ins_encode %{</span>
<span class="line-removed"> 6969     __ psubd($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 6970   %}</span>
<span class="line-removed"> 6971   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6972 %}</span>
<span class="line-removed"> 6973 </span>
<span class="line-removed"> 6974 instruct vsub4I_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 6975   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6976   match(Set dst (SubVI src1 src2));</span>
<span class="line-removed"> 6977   format %{ &quot;vpsubd  $dst,$src1,$src2\t! sub packed4I&quot; %}</span>
<span class="line-removed"> 6978   ins_encode %{</span>
<span class="line-removed"> 6979     int vector_len = 0;</span>
<span class="line-removed"> 6980     __ vpsubd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 6981   %}</span>
<span class="line-removed"> 6982   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6983 %}</span>
<span class="line-removed"> 6984 </span>
<span class="line-removed"> 6985 instruct vsub4I_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 6986   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 6987   match(Set dst (SubVI src (LoadVector mem)));</span>
<span class="line-removed"> 6988   format %{ &quot;vpsubd  $dst,$src,$mem\t! sub packed4I&quot; %}</span>
<span class="line-removed"> 6989   ins_encode %{</span>
<span class="line-removed"> 6990     int vector_len = 0;</span>
<span class="line-removed"> 6991     __ vpsubd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 6992   %}</span>
<span class="line-removed"> 6993   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 6994 %}</span>
<span class="line-removed"> 6995 </span>
<span class="line-removed"> 6996 instruct vsub8I_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 6997   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 6998   match(Set dst (SubVI src1 src2));</span>
<span class="line-removed"> 6999   format %{ &quot;vpsubd  $dst,$src1,$src2\t! sub packed8I&quot; %}</span>
<span class="line-removed"> 7000   ins_encode %{</span>
<span class="line-removed"> 7001     int vector_len = 1;</span>
<span class="line-removed"> 7002     __ vpsubd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7003   %}</span>
<span class="line-removed"> 7004   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7005 %}</span>
<span class="line-removed"> 7006 </span>
<span class="line-removed"> 7007 instruct vsub8I_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 7008   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7009   match(Set dst (SubVI src (LoadVector mem)));</span>
<span class="line-removed"> 7010   format %{ &quot;vpsubd  $dst,$src,$mem\t! sub packed8I&quot; %}</span>
<span class="line-removed"> 7011   ins_encode %{</span>
<span class="line-removed"> 7012     int vector_len = 1;</span>
<span class="line-removed"> 7013     __ vpsubd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7014   %}</span>
<span class="line-removed"> 7015   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7016 %}</span>
<span class="line-removed"> 7017 </span>
<span class="line-removed"> 7018 instruct vsub16I_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 7019   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 7020   match(Set dst (SubVI src1 src2));</span>
<span class="line-removed"> 7021   format %{ &quot;vpsubd  $dst,$src1,$src2\t! sub packed16I&quot; %}</span>
<span class="line-removed"> 7022   ins_encode %{</span>
<span class="line-removed"> 7023     int vector_len = 2;</span>
<span class="line-removed"> 7024     __ vpsubd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7025   %}</span>
<span class="line-removed"> 7026   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7027 %}</span>
<span class="line-removed"> 7028 </span>
<span class="line-removed"> 7029 instruct vsub16I_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 7030   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 7031   match(Set dst (SubVI src (LoadVector mem)));</span>
<span class="line-removed"> 7032   format %{ &quot;vpsubd  $dst,$src,$mem\t! sub packed16I&quot; %}</span>
<span class="line-removed"> 7033   ins_encode %{</span>
<span class="line-removed"> 7034     int vector_len = 2;</span>
<span class="line-removed"> 7035     __ vpsubd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7036   %}</span>
<span class="line-removed"> 7037   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7038 %}</span>
<span class="line-removed"> 7039 </span>
<span class="line-removed"> 7040 // Longs vector sub</span>
<span class="line-removed"> 7041 instruct vsub2L(vecX dst, vecX src) %{</span>
<span class="line-removed"> 7042   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7043   match(Set dst (SubVL dst src));</span>
<span class="line-removed"> 7044   format %{ &quot;psubq   $dst,$src\t! sub packed2L&quot; %}</span>
<span class="line-removed"> 7045   ins_encode %{</span>
<span class="line-removed"> 7046     __ psubq($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7047   %}</span>
<span class="line-removed"> 7048   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7049 %}</span>
<span class="line-removed"> 7050 </span>
<span class="line-removed"> 7051 instruct vsub2L_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 7052   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7053   match(Set dst (SubVL src1 src2));</span>
<span class="line-removed"> 7054   format %{ &quot;vpsubq  $dst,$src1,$src2\t! sub packed2L&quot; %}</span>
<span class="line-removed"> 7055   ins_encode %{</span>
<span class="line-removed"> 7056     int vector_len = 0;</span>
<span class="line-removed"> 7057     __ vpsubq($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7058   %}</span>
<span class="line-removed"> 7059   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7060 %}</span>
<span class="line-removed"> 7061 </span>
<span class="line-removed"> 7062 instruct vsub2L_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 7063   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7064   match(Set dst (SubVL src (LoadVector mem)));</span>
<span class="line-removed"> 7065   format %{ &quot;vpsubq  $dst,$src,$mem\t! sub packed2L&quot; %}</span>
<span class="line-removed"> 7066   ins_encode %{</span>
<span class="line-removed"> 7067     int vector_len = 0;</span>
<span class="line-removed"> 7068     __ vpsubq($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7069   %}</span>
<span class="line-removed"> 7070   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7071 %}</span>
<span class="line-removed"> 7072 </span>
<span class="line-removed"> 7073 instruct vsub4L_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 7074   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7075   match(Set dst (SubVL src1 src2));</span>
<span class="line-removed"> 7076   format %{ &quot;vpsubq  $dst,$src1,$src2\t! sub packed4L&quot; %}</span>
<span class="line-removed"> 7077   ins_encode %{</span>
<span class="line-removed"> 7078     int vector_len = 1;</span>
<span class="line-removed"> 7079     __ vpsubq($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7080   %}</span>
<span class="line-removed"> 7081   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7082 %}</span>
<span class="line-removed"> 7083 </span>
<span class="line-removed"> 7084 instruct vsub4L_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 7085   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7086   match(Set dst (SubVL src (LoadVector mem)));</span>
<span class="line-removed"> 7087   format %{ &quot;vpsubq  $dst,$src,$mem\t! sub packed4L&quot; %}</span>
<span class="line-removed"> 7088   ins_encode %{</span>
<span class="line-removed"> 7089     int vector_len = 1;</span>
<span class="line-removed"> 7090     __ vpsubq($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7091   %}</span>
<span class="line-removed"> 7092   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7093 %}</span>
<span class="line-removed"> 7094 </span>
<span class="line-removed"> 7095 instruct vsub8L_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 7096   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7097   match(Set dst (SubVL src1 src2));</span>
<span class="line-removed"> 7098   format %{ &quot;vpsubq  $dst,$src1,$src2\t! sub packed8L&quot; %}</span>
<span class="line-removed"> 7099   ins_encode %{</span>
<span class="line-removed"> 7100     int vector_len = 2;</span>
<span class="line-removed"> 7101     __ vpsubq($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7102   %}</span>
<span class="line-removed"> 7103   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7104 %}</span>
<span class="line-removed"> 7105 </span>
<span class="line-removed"> 7106 instruct vsub8L_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 7107   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7108   match(Set dst (SubVL src (LoadVector mem)));</span>
<span class="line-removed"> 7109   format %{ &quot;vpsubq  $dst,$src,$mem\t! sub packed8L&quot; %}</span>
<span class="line-removed"> 7110   ins_encode %{</span>
<span class="line-removed"> 7111     int vector_len = 2;</span>
<span class="line-removed"> 7112     __ vpsubq($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7113   %}</span>
<span class="line-removed"> 7114   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7115 %}</span>
<span class="line-removed"> 7116 </span>
<span class="line-removed"> 7117 // Floats vector sub</span>
<span class="line-removed"> 7118 instruct vsub2F(vecD dst, vecD src) %{</span>
<span class="line-removed"> 7119   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7120   match(Set dst (SubVF dst src));</span>
<span class="line-removed"> 7121   format %{ &quot;subps   $dst,$src\t! sub packed2F&quot; %}</span>
<span class="line-removed"> 7122   ins_encode %{</span>
<span class="line-removed"> 7123     __ subps($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7124   %}</span>
<span class="line-removed"> 7125   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7126 %}</span>
<span class="line-removed"> 7127 </span>
<span class="line-removed"> 7128 instruct vsub2F_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-removed"> 7129   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7130   match(Set dst (SubVF src1 src2));</span>
<span class="line-removed"> 7131   format %{ &quot;vsubps  $dst,$src1,$src2\t! sub packed2F&quot; %}</span>
<span class="line-removed"> 7132   ins_encode %{</span>
<span class="line-removed"> 7133     int vector_len = 0;</span>
<span class="line-removed"> 7134     __ vsubps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7135   %}</span>
<span class="line-removed"> 7136   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7137 %}</span>
<span class="line-removed"> 7138 </span>
<span class="line-removed"> 7139 instruct vsub2F_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-removed"> 7140   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7141   match(Set dst (SubVF src (LoadVector mem)));</span>
<span class="line-removed"> 7142   format %{ &quot;vsubps  $dst,$src,$mem\t! sub packed2F&quot; %}</span>
<span class="line-removed"> 7143   ins_encode %{</span>
<span class="line-removed"> 7144     int vector_len = 0;</span>
<span class="line-removed"> 7145     __ vsubps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7146   %}</span>
<span class="line-removed"> 7147   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7148 %}</span>
<span class="line-removed"> 7149 </span>
<span class="line-removed"> 7150 instruct vsub4F(vecX dst, vecX src) %{</span>
<span class="line-removed"> 7151   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7152   match(Set dst (SubVF dst src));</span>
<span class="line-removed"> 7153   format %{ &quot;subps   $dst,$src\t! sub packed4F&quot; %}</span>
<span class="line-removed"> 7154   ins_encode %{</span>
<span class="line-removed"> 7155     __ subps($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7156   %}</span>
<span class="line-removed"> 7157   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7158 %}</span>
<span class="line-removed"> 7159 </span>
<span class="line-removed"> 7160 instruct vsub4F_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 7161   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7162   match(Set dst (SubVF src1 src2));</span>
<span class="line-removed"> 7163   format %{ &quot;vsubps  $dst,$src1,$src2\t! sub packed4F&quot; %}</span>
<span class="line-removed"> 7164   ins_encode %{</span>
<span class="line-removed"> 7165     int vector_len = 0;</span>
<span class="line-removed"> 7166     __ vsubps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7167   %}</span>
<span class="line-removed"> 7168   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7169 %}</span>
<span class="line-removed"> 7170 </span>
<span class="line-removed"> 7171 instruct vsub4F_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 7172   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7173   match(Set dst (SubVF src (LoadVector mem)));</span>
<span class="line-removed"> 7174   format %{ &quot;vsubps  $dst,$src,$mem\t! sub packed4F&quot; %}</span>
<span class="line-removed"> 7175   ins_encode %{</span>
<span class="line-removed"> 7176     int vector_len = 0;</span>
<span class="line-removed"> 7177     __ vsubps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7178   %}</span>
<span class="line-removed"> 7179   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7180 %}</span>
<span class="line-removed"> 7181 </span>
<span class="line-removed"> 7182 instruct vsub8F_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 7183   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7184   match(Set dst (SubVF src1 src2));</span>
<span class="line-removed"> 7185   format %{ &quot;vsubps  $dst,$src1,$src2\t! sub packed8F&quot; %}</span>
<span class="line-removed"> 7186   ins_encode %{</span>
<span class="line-removed"> 7187     int vector_len = 1;</span>
<span class="line-removed"> 7188     __ vsubps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7189   %}</span>
<span class="line-removed"> 7190   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7191 %}</span>
<span class="line-removed"> 7192 </span>
<span class="line-removed"> 7193 instruct vsub8F_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 7194   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7195   match(Set dst (SubVF src (LoadVector mem)));</span>
<span class="line-removed"> 7196   format %{ &quot;vsubps  $dst,$src,$mem\t! sub packed8F&quot; %}</span>
<span class="line-removed"> 7197   ins_encode %{</span>
<span class="line-removed"> 7198     int vector_len = 1;</span>
<span class="line-removed"> 7199     __ vsubps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7200   %}</span>
<span class="line-removed"> 7201   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7202 %}</span>
<span class="line-removed"> 7203 </span>
<span class="line-removed"> 7204 instruct vsub16F_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 7205   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 7206   match(Set dst (SubVF src1 src2));</span>
<span class="line-removed"> 7207   format %{ &quot;vsubps  $dst,$src1,$src2\t! sub packed16F&quot; %}</span>
<span class="line-removed"> 7208   ins_encode %{</span>
<span class="line-removed"> 7209     int vector_len = 2;</span>
<span class="line-removed"> 7210     __ vsubps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7211   %}</span>
<span class="line-removed"> 7212   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7213 %}</span>
<span class="line-removed"> 7214 </span>
<span class="line-removed"> 7215 instruct vsub16F_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 7216   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 7217   match(Set dst (SubVF src (LoadVector mem)));</span>
<span class="line-removed"> 7218   format %{ &quot;vsubps  $dst,$src,$mem\t! sub packed16F&quot; %}</span>
<span class="line-removed"> 7219   ins_encode %{</span>
<span class="line-removed"> 7220     int vector_len = 2;</span>
<span class="line-removed"> 7221     __ vsubps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7222   %}</span>
<span class="line-removed"> 7223   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7224 %}</span>
<span class="line-removed"> 7225 </span>
<span class="line-removed"> 7226 // Doubles vector sub</span>
<span class="line-removed"> 7227 instruct vsub2D(vecX dst, vecX src) %{</span>
<span class="line-removed"> 7228   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7229   match(Set dst (SubVD dst src));</span>
<span class="line-removed"> 7230   format %{ &quot;subpd   $dst,$src\t! sub packed2D&quot; %}</span>
<span class="line-removed"> 7231   ins_encode %{</span>
<span class="line-removed"> 7232     __ subpd($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7233   %}</span>
<span class="line-removed"> 7234   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7235 %}</span>
<span class="line-removed"> 7236 </span>
<span class="line-removed"> 7237 instruct vsub2D_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 7238   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7239   match(Set dst (SubVD src1 src2));</span>
<span class="line-removed"> 7240   format %{ &quot;vsubpd  $dst,$src1,$src2\t! sub packed2D&quot; %}</span>
<span class="line-removed"> 7241   ins_encode %{</span>
<span class="line-removed"> 7242     int vector_len = 0;</span>
<span class="line-removed"> 7243     __ vsubpd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7244   %}</span>
<span class="line-removed"> 7245   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7246 %}</span>
<span class="line-removed"> 7247 </span>
<span class="line-removed"> 7248 instruct vsub2D_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 7249   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7250   match(Set dst (SubVD src (LoadVector mem)));</span>
<span class="line-removed"> 7251   format %{ &quot;vsubpd  $dst,$src,$mem\t! sub packed2D&quot; %}</span>
<span class="line-removed"> 7252   ins_encode %{</span>
<span class="line-removed"> 7253     int vector_len = 0;</span>
<span class="line-removed"> 7254     __ vsubpd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7255   %}</span>
<span class="line-removed"> 7256   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7257 %}</span>
<span class="line-removed"> 7258 </span>
<span class="line-removed"> 7259 instruct vsub4D_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 7260   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7261   match(Set dst (SubVD src1 src2));</span>
<span class="line-removed"> 7262   format %{ &quot;vsubpd  $dst,$src1,$src2\t! sub packed4D&quot; %}</span>
<span class="line-removed"> 7263   ins_encode %{</span>
<span class="line-removed"> 7264     int vector_len = 1;</span>
<span class="line-removed"> 7265     __ vsubpd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7266   %}</span>
<span class="line-removed"> 7267   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7268 %}</span>
<span class="line-removed"> 7269 </span>
<span class="line-removed"> 7270 instruct vsub4D_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 7271   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7272   match(Set dst (SubVD src (LoadVector mem)));</span>
<span class="line-removed"> 7273   format %{ &quot;vsubpd  $dst,$src,$mem\t! sub packed4D&quot; %}</span>
<span class="line-removed"> 7274   ins_encode %{</span>
<span class="line-removed"> 7275     int vector_len = 1;</span>
<span class="line-removed"> 7276     __ vsubpd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7277   %}</span>
<span class="line-removed"> 7278   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7279 %}</span>
<span class="line-removed"> 7280 </span>
<span class="line-removed"> 7281 instruct vsub8D_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 7282   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7283   match(Set dst (SubVD src1 src2));</span>
<span class="line-removed"> 7284   format %{ &quot;vsubpd  $dst,$src1,$src2\t! sub packed8D&quot; %}</span>
<span class="line-removed"> 7285   ins_encode %{</span>
<span class="line-removed"> 7286     int vector_len = 2;</span>
<span class="line-removed"> 7287     __ vsubpd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7288   %}</span>
<span class="line-removed"> 7289   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7290 %}</span>
<span class="line-removed"> 7291 </span>
<span class="line-removed"> 7292 instruct vsub8D_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 7293   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7294   match(Set dst (SubVD src (LoadVector mem)));</span>
<span class="line-removed"> 7295   format %{ &quot;vsubpd  $dst,$src,$mem\t! sub packed8D&quot; %}</span>
<span class="line-removed"> 7296   ins_encode %{</span>
<span class="line-removed"> 7297     int vector_len = 2;</span>
<span class="line-removed"> 7298     __ vsubpd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7299   %}</span>
<span class="line-removed"> 7300   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7301 %}</span>
<span class="line-removed"> 7302 </span>
<span class="line-removed"> 7303 // --------------------------------- MUL --------------------------------------</span>
<span class="line-removed"> 7304 </span>
<span class="line-removed"> 7305 // Shorts/Chars vector mul</span>
<span class="line-removed"> 7306 instruct vmul2S(vecS dst, vecS src) %{</span>
<span class="line-removed"> 7307   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7308   match(Set dst (MulVS dst src));</span>
<span class="line-removed"> 7309   format %{ &quot;pmullw $dst,$src\t! mul packed2S&quot; %}</span>
<span class="line-removed"> 7310   ins_encode %{</span>
<span class="line-removed"> 7311     __ pmullw($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7312   %}</span>
<span class="line-removed"> 7313   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7314 %}</span>
<span class="line-removed"> 7315 </span>
<span class="line-removed"> 7316 instruct vmul2S_reg(vecS dst, vecS src1, vecS src2) %{</span>
<span class="line-removed"> 7317   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7318   match(Set dst (MulVS src1 src2));</span>
<span class="line-removed"> 7319   format %{ &quot;vpmullw $dst,$src1,$src2\t! mul packed2S&quot; %}</span>
<span class="line-removed"> 7320   ins_encode %{</span>
<span class="line-removed"> 7321     int vector_len = 0;</span>
<span class="line-removed"> 7322     __ vpmullw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7323   %}</span>
<span class="line-removed"> 7324   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7325 %}</span>
<span class="line-removed"> 7326 </span>
<span class="line-removed"> 7327 instruct vmul2S_mem(vecS dst, vecS src, memory mem) %{</span>
<span class="line-removed"> 7328   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7329   match(Set dst (MulVS src (LoadVector mem)));</span>
<span class="line-removed"> 7330   format %{ &quot;vpmullw $dst,$src,$mem\t! mul packed2S&quot; %}</span>
<span class="line-removed"> 7331   ins_encode %{</span>
<span class="line-removed"> 7332     int vector_len = 0;</span>
<span class="line-removed"> 7333     __ vpmullw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7334   %}</span>
<span class="line-removed"> 7335   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7336 %}</span>
<span class="line-removed"> 7337 </span>
<span class="line-removed"> 7338 instruct vmul4S(vecD dst, vecD src) %{</span>
<span class="line-removed"> 7339   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7340   match(Set dst (MulVS dst src));</span>
<span class="line-removed"> 7341   format %{ &quot;pmullw  $dst,$src\t! mul packed4S&quot; %}</span>
<span class="line-removed"> 7342   ins_encode %{</span>
<span class="line-removed"> 7343     __ pmullw($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7344   %}</span>
<span class="line-removed"> 7345   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7346 %}</span>
<span class="line-removed"> 7347 </span>
<span class="line-removed"> 7348 instruct vmul4S_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-removed"> 7349   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7350   match(Set dst (MulVS src1 src2));</span>
<span class="line-removed"> 7351   format %{ &quot;vpmullw $dst,$src1,$src2\t! mul packed4S&quot; %}</span>
<span class="line-removed"> 7352   ins_encode %{</span>
<span class="line-removed"> 7353     int vector_len = 0;</span>
<span class="line-removed"> 7354     __ vpmullw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7355   %}</span>
<span class="line-removed"> 7356   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7357 %}</span>
<span class="line-removed"> 7358 </span>
<span class="line-removed"> 7359 instruct vmul4S_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-removed"> 7360   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7361   match(Set dst (MulVS src (LoadVector mem)));</span>
<span class="line-removed"> 7362   format %{ &quot;vpmullw $dst,$src,$mem\t! mul packed4S&quot; %}</span>
<span class="line-removed"> 7363   ins_encode %{</span>
<span class="line-removed"> 7364     int vector_len = 0;</span>
<span class="line-removed"> 7365     __ vpmullw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7366   %}</span>
<span class="line-removed"> 7367   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7368 %}</span>
<span class="line-removed"> 7369 </span>
<span class="line-removed"> 7370 instruct vmul8S(vecX dst, vecX src) %{</span>
<span class="line-removed"> 7371   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7372   match(Set dst (MulVS dst src));</span>
<span class="line-removed"> 7373   format %{ &quot;pmullw  $dst,$src\t! mul packed8S&quot; %}</span>
<span class="line-removed"> 7374   ins_encode %{</span>
<span class="line-removed"> 7375     __ pmullw($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7376   %}</span>
<span class="line-removed"> 7377   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7378 %}</span>
<span class="line-removed"> 7379 </span>
<span class="line-removed"> 7380 instruct vmul8S_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 7381   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7382   match(Set dst (MulVS src1 src2));</span>
<span class="line-removed"> 7383   format %{ &quot;vpmullw $dst,$src1,$src2\t! mul packed8S&quot; %}</span>
<span class="line-removed"> 7384   ins_encode %{</span>
<span class="line-removed"> 7385     int vector_len = 0;</span>
<span class="line-removed"> 7386     __ vpmullw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7387   %}</span>
<span class="line-removed"> 7388   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7389 %}</span>
<span class="line-removed"> 7390 </span>
<span class="line-removed"> 7391 instruct vmul8S_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 7392   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7393   match(Set dst (MulVS src (LoadVector mem)));</span>
<span class="line-removed"> 7394   format %{ &quot;vpmullw $dst,$src,$mem\t! mul packed8S&quot; %}</span>
<span class="line-removed"> 7395   ins_encode %{</span>
<span class="line-removed"> 7396     int vector_len = 0;</span>
<span class="line-removed"> 7397     __ vpmullw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7398   %}</span>
<span class="line-removed"> 7399   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7400 %}</span>
<span class="line-removed"> 7401 </span>
<span class="line-removed"> 7402 instruct vmul16S_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 7403   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 7404   match(Set dst (MulVS src1 src2));</span>
<span class="line-removed"> 7405   format %{ &quot;vpmullw $dst,$src1,$src2\t! mul packed16S&quot; %}</span>
<span class="line-removed"> 7406   ins_encode %{</span>
<span class="line-removed"> 7407     int vector_len = 1;</span>
<span class="line-removed"> 7408     __ vpmullw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7409   %}</span>
<span class="line-removed"> 7410   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7411 %}</span>
<span class="line-removed"> 7412 </span>
<span class="line-removed"> 7413 instruct vmul16S_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 7414   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 7415   match(Set dst (MulVS src (LoadVector mem)));</span>
<span class="line-removed"> 7416   format %{ &quot;vpmullw $dst,$src,$mem\t! mul packed16S&quot; %}</span>
<span class="line-removed"> 7417   ins_encode %{</span>
<span class="line-removed"> 7418     int vector_len = 1;</span>
<span class="line-removed"> 7419     __ vpmullw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7420   %}</span>
<span class="line-removed"> 7421   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7422 %}</span>
<span class="line-removed"> 7423 </span>
<span class="line-removed"> 7424 instruct vmul32S_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 7425   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-removed"> 7426   match(Set dst (MulVS src1 src2));</span>
<span class="line-removed"> 7427   format %{ &quot;vpmullw $dst,$src1,$src2\t! mul packed32S&quot; %}</span>
<span class="line-removed"> 7428   ins_encode %{</span>
<span class="line-removed"> 7429     int vector_len = 2;</span>
<span class="line-removed"> 7430     __ vpmullw($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7431   %}</span>
<span class="line-removed"> 7432   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7433 %}</span>
<span class="line-removed"> 7434 </span>
<span class="line-removed"> 7435 instruct vmul32S_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 7436   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-removed"> 7437   match(Set dst (MulVS src (LoadVector mem)));</span>
<span class="line-removed"> 7438   format %{ &quot;vpmullw $dst,$src,$mem\t! mul packed32S&quot; %}</span>
<span class="line-removed"> 7439   ins_encode %{</span>
<span class="line-removed"> 7440     int vector_len = 2;</span>
<span class="line-removed"> 7441     __ vpmullw($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7442   %}</span>
<span class="line-removed"> 7443   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7444 %}</span>
<span class="line-removed"> 7445 </span>
<span class="line-removed"> 7446 // Integers vector mul (sse4_1)</span>
<span class="line-removed"> 7447 instruct vmul2I(vecD dst, vecD src) %{</span>
<span class="line-removed"> 7448   predicate(UseSSE &gt; 3 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7449   match(Set dst (MulVI dst src));</span>
<span class="line-removed"> 7450   format %{ &quot;pmulld  $dst,$src\t! mul packed2I&quot; %}</span>
<span class="line-removed"> 7451   ins_encode %{</span>
<span class="line-removed"> 7452     __ pmulld($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7453   %}</span>
<span class="line-removed"> 7454   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7455 %}</span>
<span class="line-removed"> 7456 </span>
<span class="line-removed"> 7457 instruct vmul2I_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-removed"> 7458   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7459   match(Set dst (MulVI src1 src2));</span>
<span class="line-removed"> 7460   format %{ &quot;vpmulld $dst,$src1,$src2\t! mul packed2I&quot; %}</span>
<span class="line-removed"> 7461   ins_encode %{</span>
<span class="line-removed"> 7462     int vector_len = 0;</span>
<span class="line-removed"> 7463     __ vpmulld($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7464   %}</span>
<span class="line-removed"> 7465   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7466 %}</span>
<span class="line-removed"> 7467 </span>
<span class="line-removed"> 7468 instruct vmul2I_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-removed"> 7469   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7470   match(Set dst (MulVI src (LoadVector mem)));</span>
<span class="line-removed"> 7471   format %{ &quot;vpmulld $dst,$src,$mem\t! mul packed2I&quot; %}</span>
<span class="line-removed"> 7472   ins_encode %{</span>
<span class="line-removed"> 7473     int vector_len = 0;</span>
<span class="line-removed"> 7474     __ vpmulld($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7475   %}</span>
<span class="line-removed"> 7476   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7477 %}</span>
<span class="line-removed"> 7478 </span>
<span class="line-removed"> 7479 instruct vmul4I(vecX dst, vecX src) %{</span>
<span class="line-removed"> 7480   predicate(UseSSE &gt; 3 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7481   match(Set dst (MulVI dst src));</span>
<span class="line-removed"> 7482   format %{ &quot;pmulld  $dst,$src\t! mul packed4I&quot; %}</span>
<span class="line-removed"> 7483   ins_encode %{</span>
<span class="line-removed"> 7484     __ pmulld($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7485   %}</span>
<span class="line-removed"> 7486   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7487 %}</span>
<span class="line-removed"> 7488 </span>
<span class="line-removed"> 7489 instruct vmul4I_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 7490   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7491   match(Set dst (MulVI src1 src2));</span>
<span class="line-removed"> 7492   format %{ &quot;vpmulld $dst,$src1,$src2\t! mul packed4I&quot; %}</span>
<span class="line-removed"> 7493   ins_encode %{</span>
<span class="line-removed"> 7494     int vector_len = 0;</span>
<span class="line-removed"> 7495     __ vpmulld($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7496   %}</span>
<span class="line-removed"> 7497   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7498 %}</span>
<span class="line-removed"> 7499 </span>
<span class="line-removed"> 7500 instruct vmul4I_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 7501   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7502   match(Set dst (MulVI src (LoadVector mem)));</span>
<span class="line-removed"> 7503   format %{ &quot;vpmulld $dst,$src,$mem\t! mul packed4I&quot; %}</span>
<span class="line-removed"> 7504   ins_encode %{</span>
<span class="line-removed"> 7505     int vector_len = 0;</span>
<span class="line-removed"> 7506     __ vpmulld($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7507   %}</span>
<span class="line-removed"> 7508   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7509 %}</span>
<span class="line-removed"> 7510 </span>
<span class="line-removed"> 7511 instruct vmul2L_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 7512   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::supports_avx512dq());</span>
<span class="line-removed"> 7513   match(Set dst (MulVL src1 src2));</span>
<span class="line-removed"> 7514   format %{ &quot;vpmullq $dst,$src1,$src2\t! mul packed2L&quot; %}</span>
<span class="line-removed"> 7515   ins_encode %{</span>
<span class="line-removed"> 7516     int vector_len = 0;</span>
<span class="line-removed"> 7517     __ vpmullq($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7518   %}</span>
<span class="line-removed"> 7519   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7520 %}</span>
<span class="line-removed"> 7521 </span>
<span class="line-removed"> 7522 instruct vmul2L_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 7523   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::supports_avx512dq());</span>
<span class="line-removed"> 7524   match(Set dst (MulVL src (LoadVector mem)));</span>
<span class="line-removed"> 7525   format %{ &quot;vpmullq $dst,$src,$mem\t! mul packed2L&quot; %}</span>
<span class="line-removed"> 7526   ins_encode %{</span>
<span class="line-removed"> 7527     int vector_len = 0;</span>
<span class="line-removed"> 7528     __ vpmullq($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7529   %}</span>
<span class="line-removed"> 7530   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7531 %}</span>
<span class="line-removed"> 7532 </span>
<span class="line-removed"> 7533 instruct vmul4L_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 7534   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::supports_avx512dq());</span>
<span class="line-removed"> 7535   match(Set dst (MulVL src1 src2));</span>
<span class="line-removed"> 7536   format %{ &quot;vpmullq $dst,$src1,$src2\t! mul packed4L&quot; %}</span>
<span class="line-removed"> 7537   ins_encode %{</span>
<span class="line-removed"> 7538     int vector_len = 1;</span>
<span class="line-removed"> 7539     __ vpmullq($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7540   %}</span>
<span class="line-removed"> 7541   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7542 %}</span>
<span class="line-removed"> 7543 </span>
<span class="line-removed"> 7544 instruct vmul4L_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 7545   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::supports_avx512dq());</span>
<span class="line-removed"> 7546   match(Set dst (MulVL src (LoadVector mem)));</span>
<span class="line-removed"> 7547   format %{ &quot;vpmullq $dst,$src,$mem\t! mul packed4L&quot; %}</span>
<span class="line-removed"> 7548   ins_encode %{</span>
<span class="line-removed"> 7549     int vector_len = 1;</span>
<span class="line-removed"> 7550     __ vpmullq($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7551   %}</span>
<span class="line-removed"> 7552   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7553 %}</span>
<span class="line-removed"> 7554 </span>
<span class="line-removed"> 7555 instruct vmul8L_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 7556   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; VM_Version::supports_avx512dq());</span>
<span class="line-removed"> 7557   match(Set dst (MulVL src1 src2));</span>
<span class="line-removed"> 7558   format %{ &quot;vpmullq $dst,$src1,$src2\t! mul packed8L&quot; %}</span>
<span class="line-removed"> 7559   ins_encode %{</span>
<span class="line-removed"> 7560     int vector_len = 2;</span>
<span class="line-removed"> 7561     __ vpmullq($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7562   %}</span>
<span class="line-removed"> 7563   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7564 %}</span>
<span class="line-removed"> 7565 </span>
<span class="line-removed"> 7566 instruct vmul8L_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 7567   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8 &amp;&amp; VM_Version::supports_avx512dq());</span>
<span class="line-removed"> 7568   match(Set dst (MulVL src (LoadVector mem)));</span>
<span class="line-removed"> 7569   format %{ &quot;vpmullq $dst,$src,$mem\t! mul packed8L&quot; %}</span>
<span class="line-removed"> 7570   ins_encode %{</span>
<span class="line-removed"> 7571     int vector_len = 2;</span>
<span class="line-removed"> 7572     __ vpmullq($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7573   %}</span>
<span class="line-removed"> 7574   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7575 %}</span>
<span class="line-removed"> 7576 </span>
<span class="line-removed"> 7577 instruct vmul8I_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 7578   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7579   match(Set dst (MulVI src1 src2));</span>
<span class="line-removed"> 7580   format %{ &quot;vpmulld $dst,$src1,$src2\t! mul packed8I&quot; %}</span>
<span class="line-removed"> 7581   ins_encode %{</span>
<span class="line-removed"> 7582     int vector_len = 1;</span>
<span class="line-removed"> 7583     __ vpmulld($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7584   %}</span>
<span class="line-removed"> 7585   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7586 %}</span>
<span class="line-removed"> 7587 </span>
<span class="line-removed"> 7588 instruct vmul8I_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 7589   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7590   match(Set dst (MulVI src (LoadVector mem)));</span>
<span class="line-removed"> 7591   format %{ &quot;vpmulld $dst,$src,$mem\t! mul packed8I&quot; %}</span>
<span class="line-removed"> 7592   ins_encode %{</span>
<span class="line-removed"> 7593     int vector_len = 1;</span>
<span class="line-removed"> 7594     __ vpmulld($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7595   %}</span>
<span class="line-removed"> 7596   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7597 %}</span>
<span class="line-removed"> 7598 </span>
<span class="line-removed"> 7599 instruct vmul16I_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 7600   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 7601   match(Set dst (MulVI src1 src2));</span>
<span class="line-removed"> 7602   format %{ &quot;vpmulld $dst,$src1,$src2\t! mul packed16I&quot; %}</span>
<span class="line-removed"> 7603   ins_encode %{</span>
<span class="line-removed"> 7604     int vector_len = 2;</span>
<span class="line-removed"> 7605     __ vpmulld($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7606   %}</span>
<span class="line-removed"> 7607   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7608 %}</span>
<span class="line-removed"> 7609 </span>
<span class="line-removed"> 7610 instruct vmul16I_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 7611   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 7612   match(Set dst (MulVI src (LoadVector mem)));</span>
<span class="line-removed"> 7613   format %{ &quot;vpmulld $dst,$src,$mem\t! mul packed16I&quot; %}</span>
<span class="line-removed"> 7614   ins_encode %{</span>
<span class="line-removed"> 7615     int vector_len = 2;</span>
<span class="line-removed"> 7616     __ vpmulld($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7617   %}</span>
<span class="line-removed"> 7618   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7619 %}</span>
<span class="line-removed"> 7620 </span>
<span class="line-removed"> 7621 // Floats vector mul</span>
<span class="line-removed"> 7622 instruct vmul2F(vecD dst, vecD src) %{</span>
<span class="line-removed"> 7623   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7624   match(Set dst (MulVF dst src));</span>
<span class="line-removed"> 7625   format %{ &quot;mulps   $dst,$src\t! mul packed2F&quot; %}</span>
<span class="line-removed"> 7626   ins_encode %{</span>
<span class="line-removed"> 7627     __ mulps($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7628   %}</span>
<span class="line-removed"> 7629   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7630 %}</span>
<span class="line-removed"> 7631 </span>
<span class="line-removed"> 7632 instruct vmul2F_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-removed"> 7633   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7634   match(Set dst (MulVF src1 src2));</span>
<span class="line-removed"> 7635   format %{ &quot;vmulps  $dst,$src1,$src2\t! mul packed2F&quot; %}</span>
<span class="line-removed"> 7636   ins_encode %{</span>
<span class="line-removed"> 7637     int vector_len = 0;</span>
<span class="line-removed"> 7638     __ vmulps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7639   %}</span>
<span class="line-removed"> 7640   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7641 %}</span>
<span class="line-removed"> 7642 </span>
<span class="line-removed"> 7643 instruct vmul2F_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-removed"> 7644   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7645   match(Set dst (MulVF src (LoadVector mem)));</span>
<span class="line-removed"> 7646   format %{ &quot;vmulps  $dst,$src,$mem\t! mul packed2F&quot; %}</span>
<span class="line-removed"> 7647   ins_encode %{</span>
<span class="line-removed"> 7648     int vector_len = 0;</span>
<span class="line-removed"> 7649     __ vmulps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7650   %}</span>
<span class="line-removed"> 7651   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7652 %}</span>
<span class="line-removed"> 7653 </span>
<span class="line-removed"> 7654 instruct vmul4F(vecX dst, vecX src) %{</span>
<span class="line-removed"> 7655   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7656   match(Set dst (MulVF dst src));</span>
<span class="line-removed"> 7657   format %{ &quot;mulps   $dst,$src\t! mul packed4F&quot; %}</span>
<span class="line-removed"> 7658   ins_encode %{</span>
<span class="line-removed"> 7659     __ mulps($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7660   %}</span>
<span class="line-removed"> 7661   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7662 %}</span>
<span class="line-removed"> 7663 </span>
<span class="line-removed"> 7664 instruct vmul4F_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 7665   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7666   match(Set dst (MulVF src1 src2));</span>
<span class="line-removed"> 7667   format %{ &quot;vmulps  $dst,$src1,$src2\t! mul packed4F&quot; %}</span>
<span class="line-removed"> 7668   ins_encode %{</span>
<span class="line-removed"> 7669     int vector_len = 0;</span>
<span class="line-removed"> 7670     __ vmulps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7671   %}</span>
<span class="line-removed"> 7672   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7673 %}</span>
<span class="line-removed"> 7674 </span>
<span class="line-removed"> 7675 instruct vmul4F_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 7676   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7677   match(Set dst (MulVF src (LoadVector mem)));</span>
<span class="line-removed"> 7678   format %{ &quot;vmulps  $dst,$src,$mem\t! mul packed4F&quot; %}</span>
<span class="line-removed"> 7679   ins_encode %{</span>
<span class="line-removed"> 7680     int vector_len = 0;</span>
<span class="line-removed"> 7681     __ vmulps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7682   %}</span>
<span class="line-removed"> 7683   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7684 %}</span>
<span class="line-removed"> 7685 </span>
<span class="line-removed"> 7686 instruct vmul8F_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 7687   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7688   match(Set dst (MulVF src1 src2));</span>
<span class="line-removed"> 7689   format %{ &quot;vmulps  $dst,$src1,$src2\t! mul packed8F&quot; %}</span>
<span class="line-removed"> 7690   ins_encode %{</span>
<span class="line-removed"> 7691     int vector_len = 1;</span>
<span class="line-removed"> 7692     __ vmulps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7693   %}</span>
<span class="line-removed"> 7694   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7695 %}</span>
<span class="line-removed"> 7696 </span>
<span class="line-removed"> 7697 instruct vmul8F_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 7698   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7699   match(Set dst (MulVF src (LoadVector mem)));</span>
<span class="line-removed"> 7700   format %{ &quot;vmulps  $dst,$src,$mem\t! mul packed8F&quot; %}</span>
<span class="line-removed"> 7701   ins_encode %{</span>
<span class="line-removed"> 7702     int vector_len = 1;</span>
<span class="line-removed"> 7703     __ vmulps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7704   %}</span>
<span class="line-removed"> 7705   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7706 %}</span>
<span class="line-removed"> 7707 </span>
<span class="line-removed"> 7708 instruct vmul16F_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 7709   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 7710   match(Set dst (MulVF src1 src2));</span>
<span class="line-removed"> 7711   format %{ &quot;vmulps  $dst,$src1,$src2\t! mul packed16F&quot; %}</span>
<span class="line-removed"> 7712   ins_encode %{</span>
<span class="line-removed"> 7713     int vector_len = 2;</span>
<span class="line-removed"> 7714     __ vmulps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7715   %}</span>
<span class="line-removed"> 7716   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7717 %}</span>
<span class="line-removed"> 7718 </span>
<span class="line-removed"> 7719 instruct vmul16F_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 7720   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 7721   match(Set dst (MulVF src (LoadVector mem)));</span>
<span class="line-removed"> 7722   format %{ &quot;vmulps  $dst,$src,$mem\t! mul packed16F&quot; %}</span>
<span class="line-removed"> 7723   ins_encode %{</span>
<span class="line-removed"> 7724     int vector_len = 2;</span>
<span class="line-removed"> 7725     __ vmulps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7726   %}</span>
<span class="line-removed"> 7727   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7728 %}</span>
<span class="line-removed"> 7729 </span>
<span class="line-removed"> 7730 // Doubles vector mul</span>
<span class="line-removed"> 7731 instruct vmul2D(vecX dst, vecX src) %{</span>
<span class="line-removed"> 7732   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7733   match(Set dst (MulVD dst src));</span>
<span class="line-removed"> 7734   format %{ &quot;mulpd   $dst,$src\t! mul packed2D&quot; %}</span>
<span class="line-removed"> 7735   ins_encode %{</span>
<span class="line-removed"> 7736     __ mulpd($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7737   %}</span>
<span class="line-removed"> 7738   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7739 %}</span>
<span class="line-removed"> 7740 </span>
<span class="line-removed"> 7741 instruct vmul2D_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 7742   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7743   match(Set dst (MulVD src1 src2));</span>
<span class="line-removed"> 7744   format %{ &quot;vmulpd  $dst,$src1,$src2\t! mul packed2D&quot; %}</span>
<span class="line-removed"> 7745   ins_encode %{</span>
<span class="line-removed"> 7746     int vector_len = 0;</span>
<span class="line-removed"> 7747     __ vmulpd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7748   %}</span>
<span class="line-removed"> 7749   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7750 %}</span>
<span class="line-removed"> 7751 </span>
<span class="line-removed"> 7752 instruct vmul2D_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 7753   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7754   match(Set dst (MulVD src (LoadVector mem)));</span>
<span class="line-removed"> 7755   format %{ &quot;vmulpd  $dst,$src,$mem\t! mul packed2D&quot; %}</span>
<span class="line-removed"> 7756   ins_encode %{</span>
<span class="line-removed"> 7757     int vector_len = 0;</span>
<span class="line-removed"> 7758     __ vmulpd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7759   %}</span>
<span class="line-removed"> 7760   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7761 %}</span>
<span class="line-removed"> 7762 </span>
<span class="line-removed"> 7763 instruct vmul4D_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 7764   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7765   match(Set dst (MulVD src1 src2));</span>
<span class="line-removed"> 7766   format %{ &quot;vmulpd  $dst,$src1,$src2\t! mul packed4D&quot; %}</span>
<span class="line-removed"> 7767   ins_encode %{</span>
<span class="line-removed"> 7768     int vector_len = 1;</span>
<span class="line-removed"> 7769     __ vmulpd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7770   %}</span>
<span class="line-removed"> 7771   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7772 %}</span>
<span class="line-removed"> 7773 </span>
<span class="line-removed"> 7774 instruct vmul4D_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 7775   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7776   match(Set dst (MulVD src (LoadVector mem)));</span>
<span class="line-removed"> 7777   format %{ &quot;vmulpd  $dst,$src,$mem\t! mul packed4D&quot; %}</span>
<span class="line-removed"> 7778   ins_encode %{</span>
<span class="line-removed"> 7779     int vector_len = 1;</span>
<span class="line-removed"> 7780     __ vmulpd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7781   %}</span>
<span class="line-removed"> 7782   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7783 %}</span>
<span class="line-removed"> 7784 </span>
<span class="line-removed"> 7785 instruct vmul8D_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 7786   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7787   match(Set dst (MulVD src1 src2));</span>
<span class="line-removed"> 7788   format %{ &quot;vmulpd  $dst k0,$src1,$src2\t! mul packed8D&quot; %}</span>
<span class="line-removed"> 7789   ins_encode %{</span>
<span class="line-removed"> 7790     int vector_len = 2;</span>
<span class="line-removed"> 7791     __ vmulpd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7792   %}</span>
<span class="line-removed"> 7793   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7794 %}</span>
<span class="line-removed"> 7795 </span>
<span class="line-removed"> 7796 instruct vmul8D_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 7797   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7798   match(Set dst (MulVD src (LoadVector mem)));</span>
<span class="line-removed"> 7799   format %{ &quot;vmulpd  $dst k0,$src,$mem\t! mul packed8D&quot; %}</span>
<span class="line-removed"> 7800   ins_encode %{</span>
<span class="line-removed"> 7801     int vector_len = 2;</span>
<span class="line-removed"> 7802     __ vmulpd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7803   %}</span>
<span class="line-removed"> 7804   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7805 %}</span>
<span class="line-removed"> 7806 </span>
<span class="line-removed"> 7807 instruct vcmov8F_reg(legVecY dst, legVecY src1, legVecY src2, immI8 cop, cmpOp_vcmppd copnd) %{</span>
<span class="line-removed"> 7808   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7809   match(Set dst (CMoveVF (Binary copnd cop) (Binary src1 src2)));</span>
<span class="line-removed"> 7810   effect(TEMP dst, USE src1, USE src2);</span>
<span class="line-removed"> 7811   format %{ &quot;cmpps.$copnd  $dst, $src1, $src2  ! vcmovevf, cond=$cop\n\t&quot;</span>
<span class="line-removed"> 7812             &quot;blendvps $dst,$src1,$src2,$dst ! vcmovevf\n\t&quot;</span>
<span class="line-removed"> 7813          %}</span>
<span class="line-removed"> 7814   ins_encode %{</span>
<span class="line-removed"> 7815     int vector_len = 1;</span>
<span class="line-removed"> 7816     int cond = (Assembler::Condition)($copnd$$cmpcode);</span>
<span class="line-removed"> 7817     __ cmpps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, cond, vector_len);</span>
<span class="line-removed"> 7818     __ blendvps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7819   %}</span>
<span class="line-removed"> 7820   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7821 %}</span>
<span class="line-removed"> 7822 </span>
<span class="line-removed"> 7823 instruct vcmov4D_reg(legVecY dst, legVecY src1, legVecY src2, immI8 cop, cmpOp_vcmppd copnd) %{</span>
<span class="line-removed"> 7824   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7825   match(Set dst (CMoveVD (Binary copnd cop) (Binary src1 src2)));</span>
<span class="line-removed"> 7826   effect(TEMP dst, USE src1, USE src2);</span>
<span class="line-removed"> 7827   format %{ &quot;cmppd.$copnd  $dst, $src1, $src2  ! vcmovevd, cond=$cop\n\t&quot;</span>
<span class="line-removed"> 7828             &quot;blendvpd $dst,$src1,$src2,$dst ! vcmovevd\n\t&quot;</span>
<span class="line-removed"> 7829          %}</span>
<span class="line-removed"> 7830   ins_encode %{</span>
<span class="line-removed"> 7831     int vector_len = 1;</span>
<span class="line-removed"> 7832     int cond = (Assembler::Condition)($copnd$$cmpcode);</span>
<span class="line-removed"> 7833     __ cmppd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, cond, vector_len);</span>
<span class="line-removed"> 7834     __ blendvpd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, $dst$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7835   %}</span>
<span class="line-removed"> 7836   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7837 %}</span>
<span class="line-removed"> 7838 </span>
<span class="line-removed"> 7839 // --------------------------------- DIV --------------------------------------</span>
<span class="line-removed"> 7840 </span>
<span class="line-removed"> 7841 // Floats vector div</span>
<span class="line-removed"> 7842 instruct vdiv2F(vecD dst, vecD src) %{</span>
<span class="line-removed"> 7843   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7844   match(Set dst (DivVF dst src));</span>
<span class="line-removed"> 7845   format %{ &quot;divps   $dst,$src\t! div packed2F&quot; %}</span>
<span class="line-removed"> 7846   ins_encode %{</span>
<span class="line-removed"> 7847     __ divps($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7848   %}</span>
<span class="line-removed"> 7849   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7850 %}</span>
<span class="line-removed"> 7851 </span>
<span class="line-removed"> 7852 instruct vdiv2F_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-removed"> 7853   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7854   match(Set dst (DivVF src1 src2));</span>
<span class="line-removed"> 7855   format %{ &quot;vdivps  $dst,$src1,$src2\t! div packed2F&quot; %}</span>
<span class="line-removed"> 7856   ins_encode %{</span>
<span class="line-removed"> 7857     int vector_len = 0;</span>
<span class="line-removed"> 7858     __ vdivps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7859   %}</span>
<span class="line-removed"> 7860   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7861 %}</span>
<span class="line-removed"> 7862 </span>
<span class="line-removed"> 7863 instruct vdiv2F_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-removed"> 7864   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7865   match(Set dst (DivVF src (LoadVector mem)));</span>
<span class="line-removed"> 7866   format %{ &quot;vdivps  $dst,$src,$mem\t! div packed2F&quot; %}</span>
<span class="line-removed"> 7867   ins_encode %{</span>
<span class="line-removed"> 7868     int vector_len = 0;</span>
<span class="line-removed"> 7869     __ vdivps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7870   %}</span>
<span class="line-removed"> 7871   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7872 %}</span>
<span class="line-removed"> 7873 </span>
<span class="line-removed"> 7874 instruct vdiv4F(vecX dst, vecX src) %{</span>
<span class="line-removed"> 7875   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7876   match(Set dst (DivVF dst src));</span>
<span class="line-removed"> 7877   format %{ &quot;divps   $dst,$src\t! div packed4F&quot; %}</span>
<span class="line-removed"> 7878   ins_encode %{</span>
<span class="line-removed"> 7879     __ divps($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7880   %}</span>
<span class="line-removed"> 7881   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7882 %}</span>
<span class="line-removed"> 7883 </span>
<span class="line-removed"> 7884 instruct vdiv4F_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 7885   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7886   match(Set dst (DivVF src1 src2));</span>
<span class="line-removed"> 7887   format %{ &quot;vdivps  $dst,$src1,$src2\t! div packed4F&quot; %}</span>
<span class="line-removed"> 7888   ins_encode %{</span>
<span class="line-removed"> 7889     int vector_len = 0;</span>
<span class="line-removed"> 7890     __ vdivps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7891   %}</span>
<span class="line-removed"> 7892   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7893 %}</span>
<span class="line-removed"> 7894 </span>
<span class="line-removed"> 7895 instruct vdiv4F_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 7896   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7897   match(Set dst (DivVF src (LoadVector mem)));</span>
<span class="line-removed"> 7898   format %{ &quot;vdivps  $dst,$src,$mem\t! div packed4F&quot; %}</span>
<span class="line-removed"> 7899   ins_encode %{</span>
<span class="line-removed"> 7900     int vector_len = 0;</span>
<span class="line-removed"> 7901     __ vdivps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7902   %}</span>
<span class="line-removed"> 7903   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7904 %}</span>
<span class="line-removed"> 7905 </span>
<span class="line-removed"> 7906 instruct vdiv8F_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 7907   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7908   match(Set dst (DivVF src1 src2));</span>
<span class="line-removed"> 7909   format %{ &quot;vdivps  $dst,$src1,$src2\t! div packed8F&quot; %}</span>
<span class="line-removed"> 7910   ins_encode %{</span>
<span class="line-removed"> 7911     int vector_len = 1;</span>
<span class="line-removed"> 7912     __ vdivps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7913   %}</span>
<span class="line-removed"> 7914   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7915 %}</span>
<span class="line-removed"> 7916 </span>
<span class="line-removed"> 7917 instruct vdiv8F_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 7918   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 7919   match(Set dst (DivVF src (LoadVector mem)));</span>
<span class="line-removed"> 7920   format %{ &quot;vdivps  $dst,$src,$mem\t! div packed8F&quot; %}</span>
<span class="line-removed"> 7921   ins_encode %{</span>
<span class="line-removed"> 7922     int vector_len = 1;</span>
<span class="line-removed"> 7923     __ vdivps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7924   %}</span>
<span class="line-removed"> 7925   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7926 %}</span>
<span class="line-removed"> 7927 </span>
<span class="line-removed"> 7928 instruct vdiv16F_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 7929   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 7930   match(Set dst (DivVF src1 src2));</span>
<span class="line-removed"> 7931   format %{ &quot;vdivps  $dst,$src1,$src2\t! div packed16F&quot; %}</span>
<span class="line-removed"> 7932   ins_encode %{</span>
<span class="line-removed"> 7933     int vector_len = 2;</span>
<span class="line-removed"> 7934     __ vdivps($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7935   %}</span>
<span class="line-removed"> 7936   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7937 %}</span>
<span class="line-removed"> 7938 </span>
<span class="line-removed"> 7939 instruct vdiv16F_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 7940   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 7941   match(Set dst (DivVF src (LoadVector mem)));</span>
<span class="line-removed"> 7942   format %{ &quot;vdivps  $dst,$src,$mem\t! div packed16F&quot; %}</span>
<span class="line-removed"> 7943   ins_encode %{</span>
<span class="line-removed"> 7944     int vector_len = 2;</span>
<span class="line-removed"> 7945     __ vdivps($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7946   %}</span>
<span class="line-removed"> 7947   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7948 %}</span>
<span class="line-removed"> 7949 </span>
<span class="line-removed"> 7950 // Doubles vector div</span>
<span class="line-removed"> 7951 instruct vdiv2D(vecX dst, vecX src) %{</span>
<span class="line-removed"> 7952   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7953   match(Set dst (DivVD dst src));</span>
<span class="line-removed"> 7954   format %{ &quot;divpd   $dst,$src\t! div packed2D&quot; %}</span>
<span class="line-removed"> 7955   ins_encode %{</span>
<span class="line-removed"> 7956     __ divpd($dst$$XMMRegister, $src$$XMMRegister);</span>
<span class="line-removed"> 7957   %}</span>
<span class="line-removed"> 7958   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7959 %}</span>
<span class="line-removed"> 7960 </span>
<span class="line-removed"> 7961 instruct vdiv2D_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 7962   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7963   match(Set dst (DivVD src1 src2));</span>
<span class="line-removed"> 7964   format %{ &quot;vdivpd  $dst,$src1,$src2\t! div packed2D&quot; %}</span>
<span class="line-removed"> 7965   ins_encode %{</span>
<span class="line-removed"> 7966     int vector_len = 0;</span>
<span class="line-removed"> 7967     __ vdivpd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7968   %}</span>
<span class="line-removed"> 7969   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7970 %}</span>
<span class="line-removed"> 7971 </span>
<span class="line-removed"> 7972 instruct vdiv2D_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-removed"> 7973   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 7974   match(Set dst (DivVD src (LoadVector mem)));</span>
<span class="line-removed"> 7975   format %{ &quot;vdivpd  $dst,$src,$mem\t! div packed2D&quot; %}</span>
<span class="line-removed"> 7976   ins_encode %{</span>
<span class="line-removed"> 7977     int vector_len = 0;</span>
<span class="line-removed"> 7978     __ vdivpd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 7979   %}</span>
<span class="line-removed"> 7980   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7981 %}</span>
<span class="line-removed"> 7982 </span>
<span class="line-removed"> 7983 instruct vdiv4D_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 7984   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7985   match(Set dst (DivVD src1 src2));</span>
<span class="line-removed"> 7986   format %{ &quot;vdivpd  $dst,$src1,$src2\t! div packed4D&quot; %}</span>
<span class="line-removed"> 7987   ins_encode %{</span>
<span class="line-removed"> 7988     int vector_len = 1;</span>
<span class="line-removed"> 7989     __ vdivpd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 7990   %}</span>
<span class="line-removed"> 7991   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 7992 %}</span>
<span class="line-removed"> 7993 </span>
<span class="line-removed"> 7994 instruct vdiv4D_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-removed"> 7995   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 7996   match(Set dst (DivVD src (LoadVector mem)));</span>
<span class="line-removed"> 7997   format %{ &quot;vdivpd  $dst,$src,$mem\t! div packed4D&quot; %}</span>
<span class="line-removed"> 7998   ins_encode %{</span>
<span class="line-removed"> 7999     int vector_len = 1;</span>
<span class="line-removed"> 8000     __ vdivpd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 8001   %}</span>
<span class="line-removed"> 8002   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8003 %}</span>
<span class="line-removed"> 8004 </span>
<span class="line-removed"> 8005 instruct vdiv8D_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 8006   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 8007   match(Set dst (DivVD src1 src2));</span>
<span class="line-removed"> 8008   format %{ &quot;vdivpd  $dst,$src1,$src2\t! div packed8D&quot; %}</span>
<span class="line-removed"> 8009   ins_encode %{</span>
<span class="line-removed"> 8010     int vector_len = 2;</span>
<span class="line-removed"> 8011     __ vdivpd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8012   %}</span>
<span class="line-removed"> 8013   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8014 %}</span>
<span class="line-removed"> 8015 </span>
<span class="line-removed"> 8016 instruct vdiv8D_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-removed"> 8017   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 8018   match(Set dst (DivVD src (LoadVector mem)));</span>
<span class="line-removed"> 8019   format %{ &quot;vdivpd  $dst,$src,$mem\t! div packed8D&quot; %}</span>
<span class="line-removed"> 8020   ins_encode %{</span>
<span class="line-removed"> 8021     int vector_len = 2;</span>
<span class="line-removed"> 8022     __ vdivpd($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 8023   %}</span>
<span class="line-removed"> 8024   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8025 %}</span>
<span class="line-removed"> 8026 </span>
<span class="line-removed"> 8027 // ------------------------------ Shift ---------------------------------------</span>
<span class="line-removed"> 8028 </span>
<span class="line-removed"> 8029 // Left and right shift count vectors are the same on x86</span>
<span class="line-removed"> 8030 // (only lowest bits of xmm reg are used for count).</span>
<span class="line-removed"> 8031 instruct vshiftcnt(vecS dst, rRegI cnt) %{</span>
<span class="line-removed"> 8032   match(Set dst (LShiftCntV cnt));</span>
<span class="line-removed"> 8033   match(Set dst (RShiftCntV cnt));</span>
<span class="line-removed"> 8034   format %{ &quot;movd    $dst,$cnt\t! load shift count&quot; %}</span>
<span class="line-removed"> 8035   ins_encode %{</span>
<span class="line-removed"> 8036     __ movdl($dst$$XMMRegister, $cnt$$Register);</span>
<span class="line-removed"> 8037   %}</span>
<span class="line-removed"> 8038   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8039 %}</span>
<span class="line-removed"> 8040 </span>
<span class="line-removed"> 8041 // --------------------------------- Sqrt --------------------------------------</span>
<span class="line-removed"> 8042 </span>
<span class="line-removed"> 8043 // Floating point vector sqrt</span>
<span class="line-removed"> 8044 instruct vsqrt2D_reg(vecX dst, vecX src) %{</span>
<span class="line-removed"> 8045   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 8046   match(Set dst (SqrtVD src));</span>
<span class="line-removed"> 8047   format %{ &quot;vsqrtpd  $dst,$src\t! sqrt packed2D&quot; %}</span>
<span class="line-removed"> 8048   ins_encode %{</span>
<span class="line-removed"> 8049     int vector_len = 0;</span>
<span class="line-removed"> 8050     __ vsqrtpd($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8051   %}</span>
<span class="line-removed"> 8052   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8053 %}</span>
<span class="line-removed"> 8054 </span>
<span class="line-removed"> 8055 instruct vsqrt2D_mem(vecX dst, memory mem) %{</span>
<span class="line-removed"> 8056   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 8057   match(Set dst (SqrtVD (LoadVector mem)));</span>
<span class="line-removed"> 8058   format %{ &quot;vsqrtpd  $dst,$mem\t! sqrt packed2D&quot; %}</span>
<span class="line-removed"> 8059   ins_encode %{</span>
<span class="line-removed"> 8060     int vector_len = 0;</span>
<span class="line-removed"> 8061     __ vsqrtpd($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 8062   %}</span>
<span class="line-removed"> 8063   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8064 %}</span>
<span class="line-removed"> 8065 </span>
<span class="line-removed"> 8066 instruct vsqrt4D_reg(vecY dst, vecY src) %{</span>
<span class="line-removed"> 8067   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 8068   match(Set dst (SqrtVD src));</span>
<span class="line-removed"> 8069   format %{ &quot;vsqrtpd  $dst,$src\t! sqrt packed4D&quot; %}</span>
<span class="line-removed"> 8070   ins_encode %{</span>
<span class="line-removed"> 8071     int vector_len = 1;</span>
<span class="line-removed"> 8072     __ vsqrtpd($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8073   %}</span>
<span class="line-removed"> 8074   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8075 %}</span>
<span class="line-removed"> 8076 </span>
<span class="line-removed"> 8077 instruct vsqrt4D_mem(vecY dst, memory mem) %{</span>
<span class="line-removed"> 8078   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 8079   match(Set dst (SqrtVD (LoadVector mem)));</span>
<span class="line-removed"> 8080   format %{ &quot;vsqrtpd  $dst,$mem\t! sqrt packed4D&quot; %}</span>
<span class="line-removed"> 8081   ins_encode %{</span>
<span class="line-removed"> 8082     int vector_len = 1;</span>
<span class="line-removed"> 8083     __ vsqrtpd($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 8084   %}</span>
<span class="line-removed"> 8085   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8086 %}</span>
<span class="line-removed"> 8087 </span>
<span class="line-removed"> 8088 instruct vsqrt8D_reg(vecZ dst, vecZ src) %{</span>
<span class="line-removed"> 8089   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 8090   match(Set dst (SqrtVD src));</span>
<span class="line-removed"> 8091   format %{ &quot;vsqrtpd  $dst,$src\t! sqrt packed8D&quot; %}</span>
<span class="line-removed"> 8092   ins_encode %{</span>
<span class="line-removed"> 8093     int vector_len = 2;</span>
<span class="line-removed"> 8094     __ vsqrtpd($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8095   %}</span>
<span class="line-removed"> 8096   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8097 %}</span>
<span class="line-removed"> 8098 </span>
<span class="line-removed"> 8099 instruct vsqrt8D_mem(vecZ dst, memory mem) %{</span>
<span class="line-removed"> 8100   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 8101   match(Set dst (SqrtVD (LoadVector mem)));</span>
<span class="line-removed"> 8102   format %{ &quot;vsqrtpd  $dst,$mem\t! sqrt packed8D&quot; %}</span>
<span class="line-removed"> 8103   ins_encode %{</span>
<span class="line-removed"> 8104     int vector_len = 2;</span>
<span class="line-removed"> 8105     __ vsqrtpd($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 8106   %}</span>
<span class="line-removed"> 8107   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8108 %}</span>
<span class="line-removed"> 8109 </span>
<span class="line-removed"> 8110 instruct vsqrt2F_reg(vecD dst, vecD src) %{</span>
<span class="line-removed"> 8111   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 8112   match(Set dst (SqrtVF src));</span>
<span class="line-removed"> 8113   format %{ &quot;vsqrtps  $dst,$src\t! sqrt packed2F&quot; %}</span>
<span class="line-removed"> 8114   ins_encode %{</span>
<span class="line-removed"> 8115     int vector_len = 0;</span>
<span class="line-removed"> 8116     __ vsqrtps($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8117   %}</span>
<span class="line-removed"> 8118   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8119 %}</span>
<span class="line-removed"> 8120 </span>
<span class="line-removed"> 8121 instruct vsqrt2F_mem(vecD dst, memory mem) %{</span>
<span class="line-removed"> 8122   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 8123   match(Set dst (SqrtVF (LoadVector mem)));</span>
<span class="line-removed"> 8124   format %{ &quot;vsqrtps  $dst,$mem\t! sqrt packed2F&quot; %}</span>
<span class="line-removed"> 8125   ins_encode %{</span>
<span class="line-removed"> 8126     int vector_len = 0;</span>
<span class="line-removed"> 8127     __ vsqrtps($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 8128   %}</span>
<span class="line-removed"> 8129   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8130 %}</span>
<span class="line-removed"> 8131 </span>
<span class="line-removed"> 8132 instruct vsqrt4F_reg(vecX dst, vecX src) %{</span>
<span class="line-removed"> 8133   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 8134   match(Set dst (SqrtVF src));</span>
<span class="line-removed"> 8135   format %{ &quot;vsqrtps  $dst,$src\t! sqrt packed4F&quot; %}</span>
<span class="line-removed"> 8136   ins_encode %{</span>
<span class="line-removed"> 8137     int vector_len = 0;</span>
<span class="line-removed"> 8138     __ vsqrtps($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8139   %}</span>
<span class="line-removed"> 8140   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8141 %}</span>
<span class="line-removed"> 8142 </span>
<span class="line-removed"> 8143 instruct vsqrt4F_mem(vecX dst, memory mem) %{</span>
<span class="line-removed"> 8144   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 8145   match(Set dst (SqrtVF (LoadVector mem)));</span>
<span class="line-removed"> 8146   format %{ &quot;vsqrtps  $dst,$mem\t! sqrt packed4F&quot; %}</span>
<span class="line-removed"> 8147   ins_encode %{</span>
<span class="line-removed"> 8148     int vector_len = 0;</span>
<span class="line-removed"> 8149     __ vsqrtps($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 8150   %}</span>
<span class="line-removed"> 8151   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8152 %}</span>
<span class="line-removed"> 8153 </span>
<span class="line-removed"> 8154 instruct vsqrt8F_reg(vecY dst, vecY src) %{</span>
<span class="line-removed"> 8155   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 8156   match(Set dst (SqrtVF src));</span>
<span class="line-removed"> 8157   format %{ &quot;vsqrtps  $dst,$src\t! sqrt packed8F&quot; %}</span>
<span class="line-removed"> 8158   ins_encode %{</span>
<span class="line-removed"> 8159     int vector_len = 1;</span>
<span class="line-removed"> 8160     __ vsqrtps($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8161   %}</span>
<span class="line-removed"> 8162   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8163 %}</span>
<span class="line-removed"> 8164 </span>
<span class="line-removed"> 8165 instruct vsqrt8F_mem(vecY dst, memory mem) %{</span>
<span class="line-removed"> 8166   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 8167   match(Set dst (SqrtVF (LoadVector mem)));</span>
<span class="line-removed"> 8168   format %{ &quot;vsqrtps  $dst,$mem\t! sqrt packed8F&quot; %}</span>
<span class="line-removed"> 8169   ins_encode %{</span>
<span class="line-removed"> 8170     int vector_len = 1;</span>
<span class="line-removed"> 8171     __ vsqrtps($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 8172   %}</span>
<span class="line-removed"> 8173   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8174 %}</span>
<span class="line-removed"> 8175 </span>
<span class="line-removed"> 8176 instruct vsqrt16F_reg(vecZ dst, vecZ src) %{</span>
<span class="line-removed"> 8177   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 8178   match(Set dst (SqrtVF src));</span>
<span class="line-removed"> 8179   format %{ &quot;vsqrtps  $dst,$src\t! sqrt packed16F&quot; %}</span>
<span class="line-removed"> 8180   ins_encode %{</span>
<span class="line-removed"> 8181     int vector_len = 2;</span>
<span class="line-removed"> 8182     __ vsqrtps($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8183   %}</span>
<span class="line-removed"> 8184   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8185 %}</span>
<span class="line-removed"> 8186 </span>
<span class="line-removed"> 8187 instruct vsqrt16F_mem(vecZ dst, memory mem) %{</span>
<span class="line-removed"> 8188   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 8189   match(Set dst (SqrtVF (LoadVector mem)));</span>
<span class="line-removed"> 8190   format %{ &quot;vsqrtps  $dst,$mem\t! sqrt packed16F&quot; %}</span>
<span class="line-removed"> 8191   ins_encode %{</span>
<span class="line-removed"> 8192     int vector_len = 2;</span>
<span class="line-removed"> 8193     __ vsqrtps($dst$$XMMRegister, $mem$$Address, vector_len);</span>
<span class="line-removed"> 8194   %}</span>
<span class="line-removed"> 8195   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8196 %}</span>
<span class="line-removed"> 8197 </span>
<span class="line-removed"> 8198 // ------------------------------ LeftShift -----------------------------------</span>
<span class="line-removed"> 8199 </span>
<span class="line-removed"> 8200 // Shorts/Chars vector left shift</span>
<span class="line-removed"> 8201 instruct vsll2S(vecS dst, vecS shift) %{</span>
<span class="line-removed"> 8202   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 8203   match(Set dst (LShiftVS dst shift));</span>
<span class="line-removed"> 8204   format %{ &quot;psllw   $dst,$shift\t! left shift packed2S&quot; %}</span>
<span class="line-removed"> 8205   ins_encode %{</span>
<span class="line-removed"> 8206     __ psllw($dst$$XMMRegister, $shift$$XMMRegister);</span>
<span class="line-removed"> 8207   %}</span>
<span class="line-removed"> 8208   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8209 %}</span>
<span class="line-removed"> 8210 </span>
<span class="line-removed"> 8211 instruct vsll2S_imm(vecS dst, immI8 shift) %{</span>
<span class="line-removed"> 8212   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 8213   match(Set dst (LShiftVS dst shift));</span>
<span class="line-removed"> 8214   format %{ &quot;psllw   $dst,$shift\t! left shift packed2S&quot; %}</span>
<span class="line-removed"> 8215   ins_encode %{</span>
<span class="line-removed"> 8216     __ psllw($dst$$XMMRegister, (int)$shift$$constant);</span>
<span class="line-removed"> 8217   %}</span>
<span class="line-removed"> 8218   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8219 %}</span>
<span class="line-removed"> 8220 </span>
<span class="line-removed"> 8221 instruct vsll2S_reg(vecS dst, vecS src, vecS shift) %{</span>
<span class="line-removed"> 8222   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 8223   match(Set dst (LShiftVS src shift));</span>
<span class="line-removed"> 8224   format %{ &quot;vpsllw  $dst,$src,$shift\t! left shift packed2S&quot; %}</span>
<span class="line-removed"> 8225   ins_encode %{</span>
<span class="line-removed"> 8226     int vector_len = 0;</span>
<span class="line-removed"> 8227     __ vpsllw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8228   %}</span>
<span class="line-removed"> 8229   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8230 %}</span>
<span class="line-removed"> 8231 </span>
<span class="line-removed"> 8232 instruct vsll2S_reg_imm(vecS dst, vecS src, immI8 shift) %{</span>
<span class="line-removed"> 8233   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 8234   match(Set dst (LShiftVS src shift));</span>
<span class="line-removed"> 8235   format %{ &quot;vpsllw  $dst,$src,$shift\t! left shift packed2S&quot; %}</span>
<span class="line-removed"> 8236   ins_encode %{</span>
<span class="line-removed"> 8237     int vector_len = 0;</span>
<span class="line-removed"> 8238     __ vpsllw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
<span class="line-removed"> 8239   %}</span>
<span class="line-removed"> 8240   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8241 %}</span>
<span class="line-removed"> 8242 </span>
<span class="line-removed"> 8243 instruct vsll4S(vecD dst, vecS shift) %{</span>
<span class="line-removed"> 8244   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 8245   match(Set dst (LShiftVS dst shift));</span>
<span class="line-removed"> 8246   format %{ &quot;psllw   $dst,$shift\t! left shift packed4S&quot; %}</span>
<span class="line-removed"> 8247   ins_encode %{</span>
<span class="line-removed"> 8248     __ psllw($dst$$XMMRegister, $shift$$XMMRegister);</span>
<span class="line-removed"> 8249   %}</span>
<span class="line-removed"> 8250   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8251 %}</span>
<span class="line-removed"> 8252 </span>
<span class="line-removed"> 8253 instruct vsll4S_imm(vecD dst, immI8 shift) %{</span>
<span class="line-removed"> 8254   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 8255   match(Set dst (LShiftVS dst shift));</span>
<span class="line-removed"> 8256   format %{ &quot;psllw   $dst,$shift\t! left shift packed4S&quot; %}</span>
<span class="line-removed"> 8257   ins_encode %{</span>
<span class="line-removed"> 8258     __ psllw($dst$$XMMRegister, (int)$shift$$constant);</span>
<span class="line-removed"> 8259   %}</span>
<span class="line-removed"> 8260   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8261 %}</span>
<span class="line-removed"> 8262 </span>
<span class="line-removed"> 8263 instruct vsll4S_reg(vecD dst, vecD src, vecS shift) %{</span>
<span class="line-removed"> 8264   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 8265   match(Set dst (LShiftVS src shift));</span>
<span class="line-removed"> 8266   format %{ &quot;vpsllw  $dst,$src,$shift\t! left shift packed4S&quot; %}</span>
<span class="line-removed"> 8267   ins_encode %{</span>
<span class="line-removed"> 8268     int vector_len = 0;</span>
<span class="line-removed"> 8269     __ vpsllw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8270   %}</span>
<span class="line-removed"> 8271   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8272 %}</span>
<span class="line-removed"> 8273 </span>
<span class="line-removed"> 8274 instruct vsll4S_reg_imm(vecD dst, vecD src, immI8 shift) %{</span>
<span class="line-removed"> 8275   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 8276   match(Set dst (LShiftVS src shift));</span>
<span class="line-removed"> 8277   format %{ &quot;vpsllw  $dst,$src,$shift\t! left shift packed4S&quot; %}</span>
<span class="line-removed"> 8278   ins_encode %{</span>
<span class="line-removed"> 8279     int vector_len = 0;</span>
<span class="line-removed"> 8280     __ vpsllw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
<span class="line-removed"> 8281   %}</span>
<span class="line-removed"> 8282   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8283 %}</span>
<span class="line-removed"> 8284 </span>
<span class="line-removed"> 8285 instruct vsll8S(vecX dst, vecS shift) %{</span>
<span class="line-removed"> 8286   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 8287   match(Set dst (LShiftVS dst shift));</span>
<span class="line-removed"> 8288   format %{ &quot;psllw   $dst,$shift\t! left shift packed8S&quot; %}</span>
<span class="line-removed"> 8289   ins_encode %{</span>
<span class="line-removed"> 8290     __ psllw($dst$$XMMRegister, $shift$$XMMRegister);</span>
<span class="line-removed"> 8291   %}</span>
<span class="line-removed"> 8292   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8293 %}</span>
<span class="line-removed"> 8294 </span>
<span class="line-removed"> 8295 instruct vsll8S_imm(vecX dst, immI8 shift) %{</span>
<span class="line-removed"> 8296   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 8297   match(Set dst (LShiftVS dst shift));</span>
<span class="line-removed"> 8298   format %{ &quot;psllw   $dst,$shift\t! left shift packed8S&quot; %}</span>
<span class="line-removed"> 8299   ins_encode %{</span>
<span class="line-removed"> 8300     __ psllw($dst$$XMMRegister, (int)$shift$$constant);</span>
<span class="line-removed"> 8301   %}</span>
<span class="line-removed"> 8302   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8303 %}</span>
<span class="line-removed"> 8304 </span>
<span class="line-removed"> 8305 instruct vsll8S_reg(vecX dst, vecX src, vecS shift) %{</span>
<span class="line-removed"> 8306   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 8307   match(Set dst (LShiftVS src shift));</span>
<span class="line-removed"> 8308   format %{ &quot;vpsllw  $dst,$src,$shift\t! left shift packed8S&quot; %}</span>
<span class="line-removed"> 8309   ins_encode %{</span>
<span class="line-removed"> 8310     int vector_len = 0;</span>
<span class="line-removed"> 8311     __ vpsllw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8312   %}</span>
<span class="line-removed"> 8313   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8314 %}</span>
<span class="line-removed"> 8315 </span>
<span class="line-removed"> 8316 instruct vsll8S_reg_imm(vecX dst, vecX src, immI8 shift) %{</span>
<span class="line-removed"> 8317   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 8318   match(Set dst (LShiftVS src shift));</span>
<span class="line-removed"> 8319   format %{ &quot;vpsllw  $dst,$src,$shift\t! left shift packed8S&quot; %}</span>
<span class="line-removed"> 8320   ins_encode %{</span>
<span class="line-removed"> 8321     int vector_len = 0;</span>
<span class="line-removed"> 8322     __ vpsllw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
<span class="line-removed"> 8323   %}</span>
<span class="line-removed"> 8324   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8325 %}</span>
<span class="line-removed"> 8326 </span>
<span class="line-removed"> 8327 instruct vsll16S_reg(vecY dst, vecY src, vecS shift) %{</span>
<span class="line-removed"> 8328   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 8329   match(Set dst (LShiftVS src shift));</span>
<span class="line-removed"> 8330   format %{ &quot;vpsllw  $dst,$src,$shift\t! left shift packed16S&quot; %}</span>
<span class="line-removed"> 8331   ins_encode %{</span>
<span class="line-removed"> 8332     int vector_len = 1;</span>
<span class="line-removed"> 8333     __ vpsllw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8334   %}</span>
<span class="line-removed"> 8335   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8336 %}</span>
<span class="line-removed"> 8337 </span>
<span class="line-removed"> 8338 instruct vsll16S_reg_imm(vecY dst, vecY src, immI8 shift) %{</span>
<span class="line-removed"> 8339   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 8340   match(Set dst (LShiftVS src shift));</span>
<span class="line-removed"> 8341   format %{ &quot;vpsllw  $dst,$src,$shift\t! left shift packed16S&quot; %}</span>
<span class="line-removed"> 8342   ins_encode %{</span>
<span class="line-removed"> 8343     int vector_len = 1;</span>
<span class="line-removed"> 8344     __ vpsllw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
<span class="line-removed"> 8345   %}</span>
<span class="line-removed"> 8346   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8347 %}</span>
<span class="line-removed"> 8348 </span>
<span class="line-removed"> 8349 instruct vsll32S_reg(vecZ dst, vecZ src, vecS shift) %{</span>
<span class="line-removed"> 8350   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-removed"> 8351   match(Set dst (LShiftVS src shift));</span>
<span class="line-removed"> 8352   format %{ &quot;vpsllw  $dst,$src,$shift\t! left shift packed32S&quot; %}</span>
<span class="line-removed"> 8353   ins_encode %{</span>
<span class="line-removed"> 8354     int vector_len = 2;</span>
<span class="line-removed"> 8355     __ vpsllw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8356   %}</span>
<span class="line-removed"> 8357   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8358 %}</span>
<span class="line-removed"> 8359 </span>
<span class="line-removed"> 8360 instruct vsll32S_reg_imm(vecZ dst, vecZ src, immI8 shift) %{</span>
<span class="line-removed"> 8361   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-removed"> 8362   match(Set dst (LShiftVS src shift));</span>
<span class="line-removed"> 8363   format %{ &quot;vpsllw  $dst,$src,$shift\t! left shift packed32S&quot; %}</span>
<span class="line-removed"> 8364   ins_encode %{</span>
<span class="line-removed"> 8365     int vector_len = 2;</span>
<span class="line-removed"> 8366     __ vpsllw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
<span class="line-removed"> 8367   %}</span>
<span class="line-removed"> 8368   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8369 %}</span>
<span class="line-removed"> 8370 </span>
<span class="line-removed"> 8371 // Integers vector left shift</span>
<span class="line-removed"> 8372 instruct vsll2I(vecD dst, vecS shift) %{</span>
<span class="line-removed"> 8373   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 8374   match(Set dst (LShiftVI dst shift));</span>
<span class="line-removed"> 8375   format %{ &quot;pslld   $dst,$shift\t! left shift packed2I&quot; %}</span>
<span class="line-removed"> 8376   ins_encode %{</span>
<span class="line-removed"> 8377     __ pslld($dst$$XMMRegister, $shift$$XMMRegister);</span>
<span class="line-removed"> 8378   %}</span>
<span class="line-removed"> 8379   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8380 %}</span>
<span class="line-removed"> 8381 </span>
<span class="line-removed"> 8382 instruct vsll2I_imm(vecD dst, immI8 shift) %{</span>
<span class="line-removed"> 8383   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 8384   match(Set dst (LShiftVI dst shift));</span>
<span class="line-removed"> 8385   format %{ &quot;pslld   $dst,$shift\t! left shift packed2I&quot; %}</span>
<span class="line-removed"> 8386   ins_encode %{</span>
<span class="line-removed"> 8387     __ pslld($dst$$XMMRegister, (int)$shift$$constant);</span>
<span class="line-removed"> 8388   %}</span>
<span class="line-removed"> 8389   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8390 %}</span>
<span class="line-removed"> 8391 </span>
<span class="line-removed"> 8392 instruct vsll2I_reg(vecD dst, vecD src, vecS shift) %{</span>
<span class="line-removed"> 8393   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 8394   match(Set dst (LShiftVI src shift));</span>
<span class="line-removed"> 8395   format %{ &quot;vpslld  $dst,$src,$shift\t! left shift packed2I&quot; %}</span>
<span class="line-removed"> 8396   ins_encode %{</span>
<span class="line-removed"> 8397     int vector_len = 0;</span>
<span class="line-removed"> 8398     __ vpslld($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8399   %}</span>
<span class="line-removed"> 8400   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8401 %}</span>
<span class="line-removed"> 8402 </span>
<span class="line-removed"> 8403 instruct vsll2I_reg_imm(vecD dst, vecD src, immI8 shift) %{</span>
<span class="line-removed"> 8404   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 8405   match(Set dst (LShiftVI src shift));</span>
<span class="line-removed"> 8406   format %{ &quot;vpslld  $dst,$src,$shift\t! left shift packed2I&quot; %}</span>
<span class="line-removed"> 8407   ins_encode %{</span>
<span class="line-removed"> 8408     int vector_len = 0;</span>
<span class="line-removed"> 8409     __ vpslld($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
<span class="line-removed"> 8410   %}</span>
<span class="line-removed"> 8411   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8412 %}</span>
<span class="line-removed"> 8413 </span>
<span class="line-removed"> 8414 instruct vsll4I(vecX dst, vecS shift) %{</span>
<span class="line-removed"> 8415   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 8416   match(Set dst (LShiftVI dst shift));</span>
<span class="line-removed"> 8417   format %{ &quot;pslld   $dst,$shift\t! left shift packed4I&quot; %}</span>
<span class="line-removed"> 8418   ins_encode %{</span>
<span class="line-removed"> 8419     __ pslld($dst$$XMMRegister, $shift$$XMMRegister);</span>
<span class="line-removed"> 8420   %}</span>
<span class="line-removed"> 8421   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8422 %}</span>
<span class="line-removed"> 8423 </span>
<span class="line-removed"> 8424 instruct vsll4I_imm(vecX dst, immI8 shift) %{</span>
<span class="line-removed"> 8425   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 8426   match(Set dst (LShiftVI dst shift));</span>
<span class="line-removed"> 8427   format %{ &quot;pslld   $dst,$shift\t! left shift packed4I&quot; %}</span>
<span class="line-removed"> 8428   ins_encode %{</span>
<span class="line-removed"> 8429     __ pslld($dst$$XMMRegister, (int)$shift$$constant);</span>
<span class="line-removed"> 8430   %}</span>
<span class="line-removed"> 8431   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8432 %}</span>
<span class="line-removed"> 8433 </span>
<span class="line-removed"> 8434 instruct vsll4I_reg(vecX dst, vecX src, vecS shift) %{</span>
<span class="line-removed"> 8435   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 8436   match(Set dst (LShiftVI src shift));</span>
<span class="line-removed"> 8437   format %{ &quot;vpslld  $dst,$src,$shift\t! left shift packed4I&quot; %}</span>
<span class="line-removed"> 8438   ins_encode %{</span>
<span class="line-removed"> 8439     int vector_len = 0;</span>
<span class="line-removed"> 8440     __ vpslld($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8441   %}</span>
<span class="line-removed"> 8442   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8443 %}</span>
<span class="line-removed"> 8444 </span>
<span class="line-removed"> 8445 instruct vsll4I_reg_imm(vecX dst, vecX src, immI8 shift) %{</span>
<span class="line-removed"> 8446   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 8447   match(Set dst (LShiftVI src shift));</span>
<span class="line-removed"> 8448   format %{ &quot;vpslld  $dst,$src,$shift\t! left shift packed4I&quot; %}</span>
<span class="line-removed"> 8449   ins_encode %{</span>
<span class="line-removed"> 8450     int vector_len = 0;</span>
<span class="line-removed"> 8451     __ vpslld($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
<span class="line-removed"> 8452   %}</span>
<span class="line-removed"> 8453   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8454 %}</span>
<span class="line-removed"> 8455 </span>
<span class="line-removed"> 8456 instruct vsll8I_reg(vecY dst, vecY src, vecS shift) %{</span>
<span class="line-removed"> 8457   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 8458   match(Set dst (LShiftVI src shift));</span>
<span class="line-removed"> 8459   format %{ &quot;vpslld  $dst,$src,$shift\t! left shift packed8I&quot; %}</span>
<span class="line-removed"> 8460   ins_encode %{</span>
<span class="line-removed"> 8461     int vector_len = 1;</span>
<span class="line-removed"> 8462     __ vpslld($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8463   %}</span>
<span class="line-removed"> 8464   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8465 %}</span>
<span class="line-removed"> 8466 </span>
<span class="line-removed"> 8467 instruct vsll8I_reg_imm(vecY dst, vecY src, immI8 shift) %{</span>
<span class="line-removed"> 8468   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 8469   match(Set dst (LShiftVI src shift));</span>
<span class="line-removed"> 8470   format %{ &quot;vpslld  $dst,$src,$shift\t! left shift packed8I&quot; %}</span>
 8471   ins_encode %{
<a name="116" id="anc116"></a><span class="line-modified"> 8472     int vector_len = 1;</span>
<span class="line-modified"> 8473     __ vpslld($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>









 8474   %}
 8475   ins_pipe( pipe_slow );
 8476 %}
 8477 
<a name="117" id="anc117"></a><span class="line-modified"> 8478 instruct vsll16I_reg(vecZ dst, vecZ src, vecS shift) %{</span>
<span class="line-removed"> 8479   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 8480   match(Set dst (LShiftVI src shift));</span>
<span class="line-removed"> 8481   format %{ &quot;vpslld  $dst,$src,$shift\t! left shift packed16I&quot; %}</span>
<span class="line-removed"> 8482   ins_encode %{</span>
<span class="line-removed"> 8483     int vector_len = 2;</span>
<span class="line-removed"> 8484     __ vpslld($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8485   %}</span>
<span class="line-removed"> 8486   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8487 %}</span>
 8488 
<a name="118" id="anc118"></a><span class="line-modified"> 8489 instruct vsll16I_reg_imm(vecZ dst, vecZ src, immI8 shift) %{</span>
<span class="line-modified"> 8490   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-modified"> 8491   match(Set dst (LShiftVI src shift));</span>
<span class="line-modified"> 8492   format %{ &quot;vpslld  $dst,$src,$shift\t! left shift packed16I&quot; %}</span>


 8493   ins_encode %{
<a name="119" id="anc119"></a><span class="line-modified"> 8494     int vector_len = 2;</span>
<span class="line-modified"> 8495     __ vpslld($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>




 8496   %}
 8497   ins_pipe( pipe_slow );
 8498 %}
 8499 
<a name="120" id="anc120"></a><span class="line-modified"> 8500 // Longs vector left shift</span>
<span class="line-modified"> 8501 instruct vsll2L(vecX dst, vecS shift) %{</span>
<span class="line-modified"> 8502   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8503   match(Set dst (LShiftVL dst shift));</span>
<span class="line-modified"> 8504   format %{ &quot;psllq   $dst,$shift\t! left shift packed2L&quot; %}</span>
 8505   ins_encode %{
<a name="121" id="anc121"></a><span class="line-modified"> 8506     __ psllq($dst$$XMMRegister, $shift$$XMMRegister);</span>







 8507   %}
 8508   ins_pipe( pipe_slow );
 8509 %}
 8510 
<a name="122" id="anc122"></a><span class="line-modified"> 8511 instruct vsll2L_imm(vecX dst, immI8 shift) %{</span>
<span class="line-modified"> 8512   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8513   match(Set dst (LShiftVL dst shift));</span>
<span class="line-modified"> 8514   format %{ &quot;psllq   $dst,$shift\t! left shift packed2L&quot; %}</span>

 8515   ins_encode %{
<a name="123" id="anc123"></a><span class="line-modified"> 8516     __ psllq($dst$$XMMRegister, (int)$shift$$constant);</span>









 8517   %}
 8518   ins_pipe( pipe_slow );
 8519 %}
<a name="124" id="anc124"></a>
 8520 
<a name="125" id="anc125"></a><span class="line-modified"> 8521 instruct vsll2L_reg(vecX dst, vecX src, vecS shift) %{</span>
<span class="line-removed"> 8522   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 8523   match(Set dst (LShiftVL src shift));</span>
<span class="line-removed"> 8524   format %{ &quot;vpsllq  $dst,$src,$shift\t! left shift packed2L&quot; %}</span>
<span class="line-removed"> 8525   ins_encode %{</span>
<span class="line-removed"> 8526     int vector_len = 0;</span>
<span class="line-removed"> 8527     __ vpsllq($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
<span class="line-removed"> 8528   %}</span>
<span class="line-removed"> 8529   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8530 %}</span>
 8531 
<a name="126" id="anc126"></a><span class="line-modified"> 8532 instruct vsll2L_reg_imm(vecX dst, vecX src, immI8 shift) %{</span>
<span class="line-modified"> 8533   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8534   match(Set dst (LShiftVL src shift));</span>
<span class="line-modified"> 8535   format %{ &quot;vpsllq  $dst,$src,$shift\t! left shift packed2L&quot; %}</span>

 8536   ins_encode %{
<a name="127" id="anc127"></a><span class="line-modified"> 8537     int vector_len = 0;</span>
<span class="line-modified"> 8538     __ vpsllq($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>








 8539   %}
 8540   ins_pipe( pipe_slow );
 8541 %}
 8542 
<a name="128" id="anc128"></a><span class="line-modified"> 8543 instruct vsll4L_reg(vecY dst, vecY src, vecS shift) %{</span>
<span class="line-modified"> 8544   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 8545   match(Set dst (LShiftVL src shift));</span>
<span class="line-modified"> 8546   format %{ &quot;vpsllq  $dst,$src,$shift\t! left shift packed4L&quot; %}</span>
<span class="line-modified"> 8547   ins_encode %{</span>
<span class="line-modified"> 8548     int vector_len = 1;</span>
<span class="line-modified"> 8549     __ vpsllq($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>

















 8550   %}
 8551   ins_pipe( pipe_slow );
 8552 %}
 8553 
<a name="129" id="anc129"></a><span class="line-removed"> 8554 instruct vsll4L_reg_imm(vecY dst, vecY src, immI8 shift) %{</span>
<span class="line-removed"> 8555   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 8556   match(Set dst (LShiftVL src shift));</span>
<span class="line-removed"> 8557   format %{ &quot;vpsllq  $dst,$src,$shift\t! left shift packed4L&quot; %}</span>
<span class="line-removed"> 8558   ins_encode %{</span>
<span class="line-removed"> 8559     int vector_len = 1;</span>
<span class="line-removed"> 8560     __ vpsllq($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
<span class="line-removed"> 8561   %}</span>
<span class="line-removed"> 8562   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8563 %}</span>
 8564 
<a name="130" id="anc130"></a><span class="line-modified"> 8565 instruct vsll8L_reg(vecZ dst, vecZ src, vecS shift) %{</span>
<span class="line-modified"> 8566   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 8567   match(Set dst (LShiftVL src shift));</span>
<span class="line-modified"> 8568   format %{ &quot;vpsllq  $dst,$src,$shift\t! left shift packed8L&quot; %}</span>

 8569   ins_encode %{
<a name="131" id="anc131"></a><span class="line-modified"> 8570     int vector_len = 2;</span>
<span class="line-modified"> 8571     __ vpsllq($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>














 8572   %}
 8573   ins_pipe( pipe_slow );
 8574 %}
 8575 
<a name="132" id="anc132"></a><span class="line-modified"> 8576 instruct vsll8L_reg_imm(vecZ dst, vecZ src, immI8 shift) %{</span>
<span class="line-modified"> 8577   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 8578   match(Set dst (LShiftVL src shift));</span>
<span class="line-modified"> 8579   format %{ &quot;vpsllq  $dst,$src,$shift\t! left shift packed8L&quot; %}</span>

 8580   ins_encode %{
<a name="133" id="anc133"></a><span class="line-modified"> 8581     int vector_len = 2;</span>
<span class="line-modified"> 8582     __ vpsllq($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>






























 8583   %}
 8584   ins_pipe( pipe_slow );
 8585 %}
 8586 
<a name="134" id="anc134"></a><span class="line-modified"> 8587 // ----------------------- LogicalRightShift -----------------------------------</span>
<span class="line-removed"> 8588 </span>
<span class="line-removed"> 8589 // Shorts vector logical right shift produces incorrect Java result</span>
<span class="line-removed"> 8590 // for negative data because java code convert short value into int with</span>
<span class="line-removed"> 8591 // sign extension before a shift. But char vectors are fine since chars are</span>
<span class="line-removed"> 8592 // unsigned values.</span>
 8593 
<a name="135" id="anc135"></a><span class="line-modified"> 8594 instruct vsrl2S(vecS dst, vecS shift) %{</span>
<span class="line-modified"> 8595   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8596   match(Set dst (URShiftVS dst shift));</span>
<span class="line-modified"> 8597   format %{ &quot;psrlw   $dst,$shift\t! logical right shift packed2S&quot; %}</span>

 8598   ins_encode %{
<a name="136" id="anc136"></a><span class="line-modified"> 8599     __ psrlw($dst$$XMMRegister, $shift$$XMMRegister);</span>









 8600   %}
 8601   ins_pipe( pipe_slow );
 8602 %}
 8603 
<a name="137" id="anc137"></a><span class="line-modified"> 8604 instruct vsrl2S_imm(vecS dst, immI8 shift) %{</span>
<span class="line-modified"> 8605   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8606   match(Set dst (URShiftVS dst shift));</span>
<span class="line-modified"> 8607   format %{ &quot;psrlw   $dst,$shift\t! logical right shift packed2S&quot; %}</span>

 8608   ins_encode %{
<a name="138" id="anc138"></a><span class="line-modified"> 8609     __ psrlw($dst$$XMMRegister, (int)$shift$$constant);</span>







 8610   %}
 8611   ins_pipe( pipe_slow );
 8612 %}
 8613 
<a name="139" id="anc139"></a><span class="line-modified"> 8614 instruct vsrl2S_reg(vecS dst, vecS src, vecS shift) %{</span>
<span class="line-modified"> 8615   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8616   match(Set dst (URShiftVS src shift));</span>
<span class="line-modified"> 8617   format %{ &quot;vpsrlw  $dst,$src,$shift\t! logical right shift packed2S&quot; %}</span>

 8618   ins_encode %{
<a name="140" id="anc140"></a><span class="line-modified"> 8619     int vector_len = 0;</span>
<span class="line-modified"> 8620     __ vpsrlw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>














 8621   %}
 8622   ins_pipe( pipe_slow );
 8623 %}
 8624 
<a name="141" id="anc141"></a><span class="line-modified"> 8625 instruct vsrl2S_reg_imm(vecS dst, vecS src, immI8 shift) %{</span>
<span class="line-removed"> 8626   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 8627   match(Set dst (URShiftVS src shift));</span>
<span class="line-removed"> 8628   format %{ &quot;vpsrlw  $dst,$src,$shift\t! logical right shift packed2S&quot; %}</span>
<span class="line-removed"> 8629   ins_encode %{</span>
<span class="line-removed"> 8630     int vector_len = 0;</span>
<span class="line-removed"> 8631     __ vpsrlw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
<span class="line-removed"> 8632   %}</span>
<span class="line-removed"> 8633   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 8634 %}</span>
 8635 
<a name="142" id="anc142"></a><span class="line-modified"> 8636 instruct vsrl4S(vecD dst, vecS shift) %{</span>
<span class="line-modified"> 8637   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 8638   match(Set dst (URShiftVS dst shift));</span>
<span class="line-modified"> 8639   format %{ &quot;psrlw   $dst,$shift\t! logical right shift packed4S&quot; %}</span>
<span class="line-modified"> 8640   ins_encode %{</span>
<span class="line-modified"> 8641     __ psrlw($dst$$XMMRegister, $shift$$XMMRegister);</span>















 8642   %}
 8643   ins_pipe( pipe_slow );
 8644 %}
 8645 
<a name="143" id="anc143"></a><span class="line-modified"> 8646 instruct vsrl4S_imm(vecD dst, immI8 shift) %{</span>
<span class="line-modified"> 8647   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 8648   match(Set dst (URShiftVS dst shift));</span>
<span class="line-modified"> 8649   format %{ &quot;psrlw   $dst,$shift\t! logical right shift packed4S&quot; %}</span>
<span class="line-modified"> 8650   ins_encode %{</span>
<span class="line-modified"> 8651     __ psrlw($dst$$XMMRegister, (int)$shift$$constant);</span>



















 8652   %}
 8653   ins_pipe( pipe_slow );
 8654 %}
 8655 
<a name="144" id="anc144"></a><span class="line-modified"> 8656 instruct vsrl4S_reg(vecD dst, vecD src, vecS shift) %{</span>
<span class="line-modified"> 8657   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 8658   match(Set dst (URShiftVS src shift));</span>
<span class="line-modified"> 8659   format %{ &quot;vpsrlw  $dst,$src,$shift\t! logical right shift packed4S&quot; %}</span>

 8660   ins_encode %{
<a name="145" id="anc145"></a><span class="line-modified"> 8661     int vector_len = 0;</span>
<span class="line-modified"> 8662     __ vpsrlw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>









 8663   %}
 8664   ins_pipe( pipe_slow );
 8665 %}
 8666 
<a name="146" id="anc146"></a><span class="line-modified"> 8667 instruct vsrl4S_reg_imm(vecD dst, vecD src, immI8 shift) %{</span>
<span class="line-modified"> 8668   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 8669   match(Set dst (URShiftVS src shift));</span>
<span class="line-modified"> 8670   format %{ &quot;vpsrlw  $dst,$src,$shift\t! logical right shift packed4S&quot; %}</span>

 8671   ins_encode %{
<a name="147" id="anc147"></a><span class="line-modified"> 8672     int vector_len = 0;</span>
<span class="line-modified"> 8673     __ vpsrlw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>










 8674   %}
 8675   ins_pipe( pipe_slow );
 8676 %}
 8677 
<a name="148" id="anc148"></a><span class="line-modified"> 8678 instruct vsrl8S(vecX dst, vecS shift) %{</span>
<span class="line-modified"> 8679   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 8680   match(Set dst (URShiftVS dst shift));</span>
<span class="line-modified"> 8681   format %{ &quot;psrlw   $dst,$shift\t! logical right shift packed8S&quot; %}</span>




 8682   ins_encode %{
<a name="149" id="anc149"></a><span class="line-modified"> 8683     __ psrlw($dst$$XMMRegister, $shift$$XMMRegister);</span>





 8684   %}
 8685   ins_pipe( pipe_slow );
 8686 %}
 8687 
<a name="150" id="anc150"></a><span class="line-modified"> 8688 instruct vsrl8S_imm(vecX dst, immI8 shift) %{</span>
<span class="line-modified"> 8689   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 8690   match(Set dst (URShiftVS dst shift));</span>
<span class="line-modified"> 8691   format %{ &quot;psrlw   $dst,$shift\t! logical right shift packed8S&quot; %}</span>

 8692   ins_encode %{
<a name="151" id="anc151"></a><span class="line-modified"> 8693     __ psrlw($dst$$XMMRegister, (int)$shift$$constant);</span>







 8694   %}
 8695   ins_pipe( pipe_slow );
 8696 %}
 8697 
<a name="152" id="anc152"></a><span class="line-modified"> 8698 instruct vsrl8S_reg(vecX dst, vecX src, vecS shift) %{</span>
<span class="line-modified"> 8699   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 8700   match(Set dst (URShiftVS src shift));</span>
<span class="line-modified"> 8701   format %{ &quot;vpsrlw  $dst,$src,$shift\t! logical right shift packed8S&quot; %}</span>

 8702   ins_encode %{
<a name="153" id="anc153"></a><span class="line-modified"> 8703     int vector_len = 0;</span>
<span class="line-modified"> 8704     __ vpsrlw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>








 8705   %}
 8706   ins_pipe( pipe_slow );
 8707 %}
<a name="154" id="anc154"></a>
 8708 
<a name="155" id="anc155"></a><span class="line-modified"> 8709 instruct vsrl8S_reg_imm(vecX dst, vecX src, immI8 shift) %{</span>
<span class="line-modified"> 8710   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 8711   match(Set dst (URShiftVS src shift));</span>
<span class="line-modified"> 8712   format %{ &quot;vpsrlw  $dst,$src,$shift\t! logical right shift packed8S&quot; %}</span>



 8713   ins_encode %{
<a name="156" id="anc156"></a><span class="line-modified"> 8714     int vector_len = 0;</span>
<span class="line-modified"> 8715     __ vpsrlw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>








 8716   %}
 8717   ins_pipe( pipe_slow );
 8718 %}
 8719 
<a name="157" id="anc157"></a><span class="line-modified"> 8720 instruct vsrl16S_reg(vecY dst, vecY src, vecS shift) %{</span>
<span class="line-modified"> 8721   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-modified"> 8722   match(Set dst (URShiftVS src shift));</span>
<span class="line-modified"> 8723   format %{ &quot;vpsrlw  $dst,$src,$shift\t! logical right shift packed16S&quot; %}</span>
<span class="line-modified"> 8724   ins_encode %{</span>
<span class="line-modified"> 8725     int vector_len = 1;</span>
<span class="line-modified"> 8726     __ vpsrlw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>

















 8727   %}
 8728   ins_pipe( pipe_slow );
 8729 %}
 8730 
<a name="158" id="anc158"></a><span class="line-modified"> 8731 instruct vsrl16S_reg_imm(vecY dst, vecY src, immI8 shift) %{</span>
<span class="line-modified"> 8732   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-modified"> 8733   match(Set dst (URShiftVS src shift));</span>
<span class="line-modified"> 8734   format %{ &quot;vpsrlw  $dst,$src,$shift\t! logical right shift packed16S&quot; %}</span>

 8735   ins_encode %{
<a name="159" id="anc159"></a><span class="line-modified"> 8736     int vector_len = 1;</span>
<span class="line-modified"> 8737     __ vpsrlw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>














 8738   %}
 8739   ins_pipe( pipe_slow );
 8740 %}
 8741 
<a name="160" id="anc160"></a><span class="line-modified"> 8742 instruct vsrl32S_reg(vecZ dst, vecZ src, vecS shift) %{</span>
<span class="line-modified"> 8743   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-modified"> 8744   match(Set dst (URShiftVS src shift));</span>
<span class="line-modified"> 8745   format %{ &quot;vpsrlw  $dst,$src,$shift\t! logical right shift packed32S&quot; %}</span>

 8746   ins_encode %{
<a name="161" id="anc161"></a><span class="line-modified"> 8747     int vector_len = 2;</span>
<span class="line-modified"> 8748     __ vpsrlw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>






























 8749   %}
 8750   ins_pipe( pipe_slow );
 8751 %}
 8752 
<a name="162" id="anc162"></a><span class="line-modified"> 8753 instruct vsrl32S_reg_imm(vecZ dst, vecZ src, immI8 shift) %{</span>
<span class="line-modified"> 8754   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-modified"> 8755   match(Set dst (URShiftVS src shift));</span>
<span class="line-modified"> 8756   format %{ &quot;vpsrlw  $dst,$src,$shift\t! logical right shift packed32S&quot; %}</span>



 8757   ins_encode %{
<a name="163" id="anc163"></a><span class="line-modified"> 8758     int vector_len = 2;</span>
<span class="line-modified"> 8759     __ vpsrlw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>








 8760   %}
 8761   ins_pipe( pipe_slow );
 8762 %}
 8763 
<a name="164" id="anc164"></a><span class="line-modified"> 8764 // Integers vector logical right shift</span>
<span class="line-modified"> 8765 instruct vsrl2I(vecD dst, vecS shift) %{</span>
<span class="line-modified"> 8766   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8767   match(Set dst (URShiftVI dst shift));</span>
<span class="line-modified"> 8768   format %{ &quot;psrld   $dst,$shift\t! logical right shift packed2I&quot; %}</span>

 8769   ins_encode %{
<a name="165" id="anc165"></a><span class="line-modified"> 8770     __ psrld($dst$$XMMRegister, $shift$$XMMRegister);</span>







 8771   %}
 8772   ins_pipe( pipe_slow );
 8773 %}
 8774 
<a name="166" id="anc166"></a><span class="line-modified"> 8775 instruct vsrl2I_imm(vecD dst, immI8 shift) %{</span>
<span class="line-modified"> 8776   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8777   match(Set dst (URShiftVI dst shift));</span>
<span class="line-modified"> 8778   format %{ &quot;psrld   $dst,$shift\t! logical right shift packed2I&quot; %}</span>

 8779   ins_encode %{
<a name="167" id="anc167"></a><span class="line-modified"> 8780     __ psrld($dst$$XMMRegister, (int)$shift$$constant);</span>















 8781   %}
 8782   ins_pipe( pipe_slow );
 8783 %}
 8784 
<a name="168" id="anc168"></a><span class="line-modified"> 8785 instruct vsrl2I_reg(vecD dst, vecD src, vecS shift) %{</span>
<span class="line-modified"> 8786   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8787   match(Set dst (URShiftVI src shift));</span>
<span class="line-modified"> 8788   format %{ &quot;vpsrld  $dst,$src,$shift\t! logical right shift packed2I&quot; %}</span>





 8789   ins_encode %{
<a name="169" id="anc169"></a><span class="line-modified"> 8790     int vector_len = 0;</span>
<span class="line-removed"> 8791     __ vpsrld($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 8792   %}
 8793   ins_pipe( pipe_slow );
 8794 %}
 8795 
<a name="170" id="anc170"></a><span class="line-modified"> 8796 instruct vsrl2I_reg_imm(vecD dst, vecD src, immI8 shift) %{</span>
<span class="line-modified"> 8797   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8798   match(Set dst (URShiftVI src shift));</span>
<span class="line-modified"> 8799   format %{ &quot;vpsrld  $dst,$src,$shift\t! logical right shift packed2I&quot; %}</span>
 8800   ins_encode %{
<a name="171" id="anc171"></a><span class="line-modified"> 8801     int vector_len = 0;</span>
<span class="line-modified"> 8802     __ vpsrld($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 8803   %}
 8804   ins_pipe( pipe_slow );
 8805 %}
 8806 
<a name="172" id="anc172"></a><span class="line-modified"> 8807 instruct vsrl4I(vecX dst, vecS shift) %{</span>
<span class="line-modified"> 8808   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 8809   match(Set dst (URShiftVI dst shift));</span>
<span class="line-modified"> 8810   format %{ &quot;psrld   $dst,$shift\t! logical right shift packed4I&quot; %}</span>
 8811   ins_encode %{
<a name="173" id="anc173"></a><span class="line-modified"> 8812     __ psrld($dst$$XMMRegister, $shift$$XMMRegister);</span>

 8813   %}
 8814   ins_pipe( pipe_slow );
 8815 %}
 8816 
<a name="174" id="anc174"></a><span class="line-modified"> 8817 instruct vsrl4I_imm(vecX dst, immI8 shift) %{</span>
<span class="line-modified"> 8818   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 8819   match(Set dst (URShiftVI dst shift));</span>
<span class="line-modified"> 8820   format %{ &quot;psrld   $dst,$shift\t! logical right shift packed4I&quot; %}</span>

 8821   ins_encode %{
<a name="175" id="anc175"></a><span class="line-modified"> 8822     __ psrld($dst$$XMMRegister, (int)$shift$$constant);</span>
 8823   %}
 8824   ins_pipe( pipe_slow );
 8825 %}
 8826 
<a name="176" id="anc176"></a><span class="line-modified"> 8827 instruct vsrl4I_reg(vecX dst, vecX src, vecS shift) %{</span>
<span class="line-modified"> 8828   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 8829   match(Set dst (URShiftVI src shift));</span>
<span class="line-modified"> 8830   format %{ &quot;vpsrld  $dst,$src,$shift\t! logical right shift packed4I&quot; %}</span>
 8831   ins_encode %{
<a name="177" id="anc177"></a><span class="line-modified"> 8832     int vector_len = 0;</span>
<span class="line-modified"> 8833     __ vpsrld($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 8834   %}
 8835   ins_pipe( pipe_slow );
 8836 %}
 8837 
<a name="178" id="anc178"></a><span class="line-modified"> 8838 instruct vsrl4I_reg_imm(vecX dst, vecX src, immI8 shift) %{</span>
<span class="line-modified"> 8839   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 8840   match(Set dst (URShiftVI src shift));</span>
<span class="line-modified"> 8841   format %{ &quot;vpsrld  $dst,$src,$shift\t! logical right shift packed4I&quot; %}</span>
 8842   ins_encode %{
<a name="179" id="anc179"></a><span class="line-modified"> 8843     int vector_len = 0;</span>
<span class="line-modified"> 8844     __ vpsrld($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 8845   %}
 8846   ins_pipe( pipe_slow );
 8847 %}
 8848 
<a name="180" id="anc180"></a><span class="line-modified"> 8849 instruct vsrl8I_reg(vecY dst, vecY src, vecS shift) %{</span>
<span class="line-modified"> 8850   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 8851   match(Set dst (URShiftVI src shift));</span>
<span class="line-modified"> 8852   format %{ &quot;vpsrld  $dst,$src,$shift\t! logical right shift packed8I&quot; %}</span>

 8853   ins_encode %{
<a name="181" id="anc181"></a><span class="line-modified"> 8854     int vector_len = 1;</span>
<span class="line-removed"> 8855     __ vpsrld($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 8856   %}
 8857   ins_pipe( pipe_slow );
 8858 %}
 8859 
<a name="182" id="anc182"></a><span class="line-modified"> 8860 instruct vsrl8I_reg_imm(vecY dst, vecY src, immI8 shift) %{</span>
<span class="line-modified"> 8861   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 8862   match(Set dst (URShiftVI src shift));</span>
<span class="line-modified"> 8863   format %{ &quot;vpsrld  $dst,$src,$shift\t! logical right shift packed8I&quot; %}</span>
 8864   ins_encode %{
<a name="183" id="anc183"></a><span class="line-modified"> 8865     int vector_len = 1;</span>
<span class="line-modified"> 8866     __ vpsrld($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 8867   %}
 8868   ins_pipe( pipe_slow );
 8869 %}
 8870 
<a name="184" id="anc184"></a><span class="line-modified"> 8871 instruct vsrl16I_reg(vecZ dst, vecZ src, vecS shift) %{</span>
<span class="line-modified"> 8872   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-modified"> 8873   match(Set dst (URShiftVI src shift));</span>
<span class="line-modified"> 8874   format %{ &quot;vpsrld  $dst,$src,$shift\t! logical right shift packed16I&quot; %}</span>

 8875   ins_encode %{
<a name="185" id="anc185"></a><span class="line-modified"> 8876     int vector_len = 2;</span>
<span class="line-modified"> 8877     __ vpsrld($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 8878   %}
 8879   ins_pipe( pipe_slow );
 8880 %}
 8881 
<a name="186" id="anc186"></a><span class="line-modified"> 8882 instruct vsrl16I_reg_imm(vecZ dst, vecZ src, immI8 shift) %{</span>
<span class="line-modified"> 8883   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-modified"> 8884   match(Set dst (URShiftVI src shift));</span>
<span class="line-modified"> 8885   format %{ &quot;vpsrld  $dst,$src,$shift\t! logical right shift packed16I&quot; %}</span>

 8886   ins_encode %{
<a name="187" id="anc187"></a><span class="line-modified"> 8887     int vector_len = 2;</span>
<span class="line-removed"> 8888     __ vpsrld($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 8889   %}
 8890   ins_pipe( pipe_slow );
 8891 %}
 8892 
<a name="188" id="anc188"></a><span class="line-modified"> 8893 // Longs vector logical right shift</span>
<span class="line-modified"> 8894 instruct vsrl2L(vecX dst, vecS shift) %{</span>
<span class="line-modified"> 8895   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8896   match(Set dst (URShiftVL dst shift));</span>
<span class="line-removed"> 8897   format %{ &quot;psrlq   $dst,$shift\t! logical right shift packed2L&quot; %}</span>
 8898   ins_encode %{
<a name="189" id="anc189"></a><span class="line-modified"> 8899     __ psrlq($dst$$XMMRegister, $shift$$XMMRegister);</span>

 8900   %}
 8901   ins_pipe( pipe_slow );
 8902 %}
 8903 
<a name="190" id="anc190"></a><span class="line-modified"> 8904 instruct vsrl2L_imm(vecX dst, immI8 shift) %{</span>
<span class="line-modified"> 8905   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8906   match(Set dst (URShiftVL dst shift));</span>
<span class="line-modified"> 8907   format %{ &quot;psrlq   $dst,$shift\t! logical right shift packed2L&quot; %}</span>
 8908   ins_encode %{
<a name="191" id="anc191"></a><span class="line-modified"> 8909     __ psrlq($dst$$XMMRegister, (int)$shift$$constant);</span>

 8910   %}
 8911   ins_pipe( pipe_slow );
 8912 %}
 8913 
<a name="192" id="anc192"></a><span class="line-modified"> 8914 instruct vsrl2L_reg(vecX dst, vecX src, vecS shift) %{</span>
<span class="line-modified"> 8915   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8916   match(Set dst (URShiftVL src shift));</span>
<span class="line-modified"> 8917   format %{ &quot;vpsrlq  $dst,$src,$shift\t! logical right shift packed2L&quot; %}</span>

 8918   ins_encode %{
<a name="193" id="anc193"></a><span class="line-modified"> 8919     int vector_len = 0;</span>
<span class="line-removed"> 8920     __ vpsrlq($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 8921   %}
 8922   ins_pipe( pipe_slow );
 8923 %}
 8924 
<a name="194" id="anc194"></a><span class="line-modified"> 8925 instruct vsrl2L_reg_imm(vecX dst, vecX src, immI8 shift) %{</span>
<span class="line-modified"> 8926   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8927   match(Set dst (URShiftVL src shift));</span>
<span class="line-modified"> 8928   format %{ &quot;vpsrlq  $dst,$src,$shift\t! logical right shift packed2L&quot; %}</span>
 8929   ins_encode %{
<a name="195" id="anc195"></a><span class="line-modified"> 8930     int vector_len = 0;</span>
<span class="line-modified"> 8931     __ vpsrlq($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 8932   %}
 8933   ins_pipe( pipe_slow );
 8934 %}
 8935 
<a name="196" id="anc196"></a><span class="line-modified"> 8936 instruct vsrl4L_reg(vecY dst, vecY src, vecS shift) %{</span>
<span class="line-modified"> 8937   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 8938   match(Set dst (URShiftVL src shift));</span>
<span class="line-modified"> 8939   format %{ &quot;vpsrlq  $dst,$src,$shift\t! logical right shift packed4L&quot; %}</span>
 8940   ins_encode %{
<a name="197" id="anc197"></a><span class="line-modified"> 8941     int vector_len = 1;</span>
<span class="line-modified"> 8942     __ vpsrlq($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 8943   %}
 8944   ins_pipe( pipe_slow );
 8945 %}
 8946 
<a name="198" id="anc198"></a><span class="line-modified"> 8947 instruct vsrl4L_reg_imm(vecY dst, vecY src, immI8 shift) %{</span>
<span class="line-modified"> 8948   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 8949   match(Set dst (URShiftVL src shift));</span>
<span class="line-modified"> 8950   format %{ &quot;vpsrlq  $dst,$src,$shift\t! logical right shift packed4L&quot; %}</span>

 8951   ins_encode %{
<a name="199" id="anc199"></a><span class="line-modified"> 8952     int vector_len = 1;</span>
<span class="line-removed"> 8953     __ vpsrlq($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 8954   %}
 8955   ins_pipe( pipe_slow );
 8956 %}
 8957 
<a name="200" id="anc200"></a><span class="line-modified"> 8958 instruct vsrl8L_reg(vecZ dst, vecZ src, vecS shift) %{</span>
<span class="line-modified"> 8959   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 8960   match(Set dst (URShiftVL src shift));</span>
<span class="line-modified"> 8961   format %{ &quot;vpsrlq  $dst,$src,$shift\t! logical right shift packed8L&quot; %}</span>
 8962   ins_encode %{
<a name="201" id="anc201"></a><span class="line-modified"> 8963     int vector_len = 2;</span>
<span class="line-modified"> 8964     __ vpsrlq($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 8965   %}
 8966   ins_pipe( pipe_slow );
 8967 %}
 8968 
<a name="202" id="anc202"></a><span class="line-modified"> 8969 instruct vsrl8L_reg_imm(vecZ dst, vecZ src, immI8 shift) %{</span>
<span class="line-modified"> 8970   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 8971   match(Set dst (URShiftVL src shift));</span>
<span class="line-modified"> 8972   format %{ &quot;vpsrlq  $dst,$src,$shift\t! logical right shift packed8L&quot; %}</span>
 8973   ins_encode %{
<a name="203" id="anc203"></a><span class="line-modified"> 8974     int vector_len = 2;</span>
<span class="line-modified"> 8975     __ vpsrlq($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 8976   %}
 8977   ins_pipe( pipe_slow );
 8978 %}
 8979 
<a name="204" id="anc204"></a><span class="line-modified"> 8980 // ------------------- ArithmeticRightShift -----------------------------------</span>
 8981 
<a name="205" id="anc205"></a><span class="line-modified"> 8982 // Shorts/Chars vector arithmetic right shift</span>
<span class="line-modified"> 8983 instruct vsra2S(vecS dst, vecS shift) %{</span>
<span class="line-modified"> 8984   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8985   match(Set dst (RShiftVS dst shift));</span>
<span class="line-modified"> 8986   format %{ &quot;psraw   $dst,$shift\t! arithmetic right shift packed2S&quot; %}</span>
 8987   ins_encode %{
<a name="206" id="anc206"></a><span class="line-modified"> 8988     __ psraw($dst$$XMMRegister, $shift$$XMMRegister);</span>
 8989   %}
 8990   ins_pipe( pipe_slow );
 8991 %}
 8992 
<a name="207" id="anc207"></a><span class="line-modified"> 8993 instruct vsra2S_imm(vecS dst, immI8 shift) %{</span>
<span class="line-modified"> 8994   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 8995   match(Set dst (RShiftVS dst shift));</span>
<span class="line-modified"> 8996   format %{ &quot;psraw   $dst,$shift\t! arithmetic right shift packed2S&quot; %}</span>
 8997   ins_encode %{
<a name="208" id="anc208"></a><span class="line-modified"> 8998     __ psraw($dst$$XMMRegister, (int)$shift$$constant);</span>

 8999   %}
 9000   ins_pipe( pipe_slow );
 9001 %}
 9002 
<a name="209" id="anc209"></a><span class="line-modified"> 9003 instruct vsra2S_reg(vecS dst, vecS src, vecS shift) %{</span>
<span class="line-modified"> 9004   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 9005   match(Set dst (RShiftVS src shift));</span>
<span class="line-modified"> 9006   format %{ &quot;vpsraw  $dst,$src,$shift\t! arithmetic right shift packed2S&quot; %}</span>
 9007   ins_encode %{
<a name="210" id="anc210"></a><span class="line-modified"> 9008     int vector_len = 0;</span>
<span class="line-modified"> 9009     __ vpsraw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 9010   %}
 9011   ins_pipe( pipe_slow );
 9012 %}
 9013 
<a name="211" id="anc211"></a><span class="line-modified"> 9014 instruct vsra2S_reg_imm(vecS dst, vecS src, immI8 shift) %{</span>
<span class="line-modified"> 9015   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 9016   match(Set dst (RShiftVS src shift));</span>
<span class="line-modified"> 9017   format %{ &quot;vpsraw  $dst,$src,$shift\t! arithmetic right shift packed2S&quot; %}</span>

 9018   ins_encode %{
<a name="212" id="anc212"></a><span class="line-modified"> 9019     int vector_len = 0;</span>
<span class="line-removed"> 9020     __ vpsraw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 9021   %}
 9022   ins_pipe( pipe_slow );
 9023 %}
 9024 
<a name="213" id="anc213"></a><span class="line-modified"> 9025 instruct vsra4S(vecD dst, vecS shift) %{</span>
<span class="line-modified"> 9026   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 9027   match(Set dst (RShiftVS dst shift));</span>
<span class="line-modified"> 9028   format %{ &quot;psraw   $dst,$shift\t! arithmetic right shift packed4S&quot; %}</span>

 9029   ins_encode %{
<a name="214" id="anc214"></a><span class="line-modified"> 9030     __ psraw($dst$$XMMRegister, $shift$$XMMRegister);</span>

 9031   %}
 9032   ins_pipe( pipe_slow );
 9033 %}
 9034 
<a name="215" id="anc215"></a><span class="line-modified"> 9035 instruct vsra4S_imm(vecD dst, immI8 shift) %{</span>
<span class="line-modified"> 9036   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 9037   match(Set dst (RShiftVS dst shift));</span>
<span class="line-modified"> 9038   format %{ &quot;psraw   $dst,$shift\t! arithmetic right shift packed4S&quot; %}</span>
 9039   ins_encode %{
<a name="216" id="anc216"></a><span class="line-modified"> 9040     __ psraw($dst$$XMMRegister, (int)$shift$$constant);</span>

 9041   %}
 9042   ins_pipe( pipe_slow );
 9043 %}
 9044 
<a name="217" id="anc217"></a><span class="line-modified"> 9045 instruct vsra4S_reg(vecD dst, vecD src, vecS shift) %{</span>
<span class="line-modified"> 9046   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 9047   match(Set dst (RShiftVS src shift));</span>
<span class="line-modified"> 9048   format %{ &quot;vpsraw  $dst,$src,$shift\t! arithmetic right shift packed4S&quot; %}</span>

 9049   ins_encode %{
<a name="218" id="anc218"></a><span class="line-modified"> 9050     int vector_len = 0;</span>
<span class="line-removed"> 9051     __ vpsraw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 9052   %}
 9053   ins_pipe( pipe_slow );
 9054 %}
 9055 
<a name="219" id="anc219"></a><span class="line-modified"> 9056 instruct vsra4S_reg_imm(vecD dst, vecD src, immI8 shift) %{</span>
<span class="line-modified"> 9057   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 9058   match(Set dst (RShiftVS src shift));</span>
<span class="line-modified"> 9059   format %{ &quot;vpsraw  $dst,$src,$shift\t! arithmetic right shift packed4S&quot; %}</span>
 9060   ins_encode %{
<a name="220" id="anc220"></a><span class="line-modified"> 9061     int vector_len = 0;</span>
<span class="line-modified"> 9062     __ vpsraw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 9063   %}
 9064   ins_pipe( pipe_slow );
 9065 %}
 9066 
<a name="221" id="anc221"></a><span class="line-modified"> 9067 instruct vsra8S(vecX dst, vecS shift) %{</span>
<span class="line-modified"> 9068   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 9069   match(Set dst (RShiftVS dst shift));</span>
<span class="line-modified"> 9070   format %{ &quot;psraw   $dst,$shift\t! arithmetic right shift packed8S&quot; %}</span>
 9071   ins_encode %{
<a name="222" id="anc222"></a><span class="line-modified"> 9072     __ psraw($dst$$XMMRegister, $shift$$XMMRegister);</span>

 9073   %}
 9074   ins_pipe( pipe_slow );
 9075 %}
 9076 
<a name="223" id="anc223"></a><span class="line-modified"> 9077 instruct vsra8S_imm(vecX dst, immI8 shift) %{</span>
<span class="line-modified"> 9078   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 9079   match(Set dst (RShiftVS dst shift));</span>
<span class="line-modified"> 9080   format %{ &quot;psraw   $dst,$shift\t! arithmetic right shift packed8S&quot; %}</span>

 9081   ins_encode %{
<a name="224" id="anc224"></a><span class="line-modified"> 9082     __ psraw($dst$$XMMRegister, (int)$shift$$constant);</span>
 9083   %}
 9084   ins_pipe( pipe_slow );
 9085 %}
 9086 
<a name="225" id="anc225"></a><span class="line-modified"> 9087 instruct vsra8S_reg(vecX dst, vecX src, vecS shift) %{</span>
<span class="line-modified"> 9088   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 9089   match(Set dst (RShiftVS src shift));</span>
<span class="line-modified"> 9090   format %{ &quot;vpsraw  $dst,$src,$shift\t! arithmetic right shift packed8S&quot; %}</span>
 9091   ins_encode %{
<a name="226" id="anc226"></a><span class="line-modified"> 9092     int vector_len = 0;</span>
<span class="line-modified"> 9093     __ vpsraw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 9094   %}
 9095   ins_pipe( pipe_slow );
 9096 %}
 9097 
<a name="227" id="anc227"></a><span class="line-modified"> 9098 instruct vsra8S_reg_imm(vecX dst, vecX src, immI8 shift) %{</span>
<span class="line-modified"> 9099   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 9100   match(Set dst (RShiftVS src shift));</span>
<span class="line-modified"> 9101   format %{ &quot;vpsraw  $dst,$src,$shift\t! arithmetic right shift packed8S&quot; %}</span>

 9102   ins_encode %{
<a name="228" id="anc228"></a><span class="line-modified"> 9103     int vector_len = 0;</span>
<span class="line-modified"> 9104     __ vpsraw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 9105   %}
 9106   ins_pipe( pipe_slow );
 9107 %}
 9108 
<a name="229" id="anc229"></a><span class="line-modified"> 9109 instruct vsra16S_reg(vecY dst, vecY src, vecS shift) %{</span>
<span class="line-modified"> 9110   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-modified"> 9111   match(Set dst (RShiftVS src shift));</span>
<span class="line-modified"> 9112   format %{ &quot;vpsraw  $dst,$src,$shift\t! arithmetic right shift packed16S&quot; %}</span>

 9113   ins_encode %{
<a name="230" id="anc230"></a><span class="line-modified"> 9114     int vector_len = 1;</span>
<span class="line-removed"> 9115     __ vpsraw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 9116   %}
 9117   ins_pipe( pipe_slow );
 9118 %}
 9119 
<a name="231" id="anc231"></a><span class="line-modified"> 9120 instruct vsra16S_reg_imm(vecY dst, vecY src, immI8 shift) %{</span>
<span class="line-modified"> 9121   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-modified"> 9122   match(Set dst (RShiftVS src shift));</span>
<span class="line-modified"> 9123   format %{ &quot;vpsraw  $dst,$src,$shift\t! arithmetic right shift packed16S&quot; %}</span>
 9124   ins_encode %{
<a name="232" id="anc232"></a><span class="line-modified"> 9125     int vector_len = 1;</span>
<span class="line-modified"> 9126     __ vpsraw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 9127   %}
 9128   ins_pipe( pipe_slow );
 9129 %}
 9130 
<a name="233" id="anc233"></a><span class="line-modified"> 9131 instruct vsra32S_reg(vecZ dst, vecZ src, vecS shift) %{</span>
<span class="line-modified"> 9132   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-modified"> 9133   match(Set dst (RShiftVS src shift));</span>
<span class="line-modified"> 9134   format %{ &quot;vpsraw  $dst,$src,$shift\t! arithmetic right shift packed32S&quot; %}</span>
 9135   ins_encode %{
<a name="234" id="anc234"></a><span class="line-modified"> 9136     int vector_len = 2;</span>
<span class="line-modified"> 9137     __ vpsraw($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 9138   %}
 9139   ins_pipe( pipe_slow );
 9140 %}
 9141 
<a name="235" id="anc235"></a><span class="line-modified"> 9142 instruct vsra32S_reg_imm(vecZ dst, vecZ src, immI8 shift) %{</span>
<span class="line-modified"> 9143   predicate(UseAVX &gt; 2 &amp;&amp; VM_Version::supports_avx512bw() &amp;&amp; n-&gt;as_Vector()-&gt;length() == 32);</span>
<span class="line-modified"> 9144   match(Set dst (RShiftVS src shift));</span>
<span class="line-modified"> 9145   format %{ &quot;vpsraw  $dst,$src,$shift\t! arithmetic right shift packed32S&quot; %}</span>

 9146   ins_encode %{
<a name="236" id="anc236"></a><span class="line-modified"> 9147     int vector_len = 2;</span>
<span class="line-removed"> 9148     __ vpsraw($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 9149   %}
 9150   ins_pipe( pipe_slow );
 9151 %}
 9152 
<a name="237" id="anc237"></a><span class="line-modified"> 9153 // Integers vector arithmetic right shift</span>
<span class="line-modified"> 9154 instruct vsra2I(vecD dst, vecS shift) %{</span>
<span class="line-modified"> 9155   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 9156   match(Set dst (RShiftVI dst shift));</span>
<span class="line-removed"> 9157   format %{ &quot;psrad   $dst,$shift\t! arithmetic right shift packed2I&quot; %}</span>
 9158   ins_encode %{
<a name="238" id="anc238"></a><span class="line-modified"> 9159     __ psrad($dst$$XMMRegister, $shift$$XMMRegister);</span>

 9160   %}
 9161   ins_pipe( pipe_slow );
 9162 %}
 9163 
<a name="239" id="anc239"></a><span class="line-modified"> 9164 instruct vsra2I_imm(vecD dst, immI8 shift) %{</span>
<span class="line-modified"> 9165   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 9166   match(Set dst (RShiftVI dst shift));</span>
<span class="line-modified"> 9167   format %{ &quot;psrad   $dst,$shift\t! arithmetic right shift packed2I&quot; %}</span>
 9168   ins_encode %{
<a name="240" id="anc240"></a><span class="line-modified"> 9169     __ psrad($dst$$XMMRegister, (int)$shift$$constant);</span>

 9170   %}
 9171   ins_pipe( pipe_slow );
 9172 %}
 9173 
<a name="241" id="anc241"></a><span class="line-modified"> 9174 instruct vsra2I_reg(vecD dst, vecD src, vecS shift) %{</span>
<span class="line-modified"> 9175   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 9176   match(Set dst (RShiftVI src shift));</span>
<span class="line-modified"> 9177   format %{ &quot;vpsrad  $dst,$src,$shift\t! arithmetic right shift packed2I&quot; %}</span>





 9178   ins_encode %{
<a name="242" id="anc242"></a><span class="line-modified"> 9179     int vector_len = 0;</span>
<span class="line-modified"> 9180     __ vpsrad($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>





 9181   %}
 9182   ins_pipe( pipe_slow );
 9183 %}
 9184 
<a name="243" id="anc243"></a><span class="line-modified"> 9185 instruct vsra2I_reg_imm(vecD dst, vecD src, immI8 shift) %{</span>
<span class="line-modified"> 9186   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-modified"> 9187   match(Set dst (RShiftVI src shift));</span>
<span class="line-modified"> 9188   format %{ &quot;vpsrad  $dst,$src,$shift\t! arithmetic right shift packed2I&quot; %}</span>

 9189   ins_encode %{
<a name="244" id="anc244"></a><span class="line-modified"> 9190     int vector_len = 0;</span>
<span class="line-modified"> 9191     __ vpsrad($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>











 9192   %}
 9193   ins_pipe( pipe_slow );
 9194 %}
 9195 
<a name="245" id="anc245"></a><span class="line-modified"> 9196 instruct vsra4I(vecX dst, vecS shift) %{</span>
<span class="line-modified"> 9197   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 9198   match(Set dst (RShiftVI dst shift));</span>
<span class="line-modified"> 9199   format %{ &quot;psrad   $dst,$shift\t! arithmetic right shift packed4I&quot; %}</span>

 9200   ins_encode %{
<a name="246" id="anc246"></a><span class="line-modified"> 9201     __ psrad($dst$$XMMRegister, $shift$$XMMRegister);</span>







 9202   %}
 9203   ins_pipe( pipe_slow );
 9204 %}
 9205 
<a name="247" id="anc247"></a><span class="line-modified"> 9206 instruct vsra4I_imm(vecX dst, immI8 shift) %{</span>
<span class="line-modified"> 9207   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 9208   match(Set dst (RShiftVI dst shift));</span>
<span class="line-modified"> 9209   format %{ &quot;psrad   $dst,$shift\t! arithmetic right shift packed4I&quot; %}</span>
<span class="line-modified"> 9210   ins_encode %{</span>
<span class="line-modified"> 9211     __ psrad($dst$$XMMRegister, (int)$shift$$constant);</span>











































 9212   %}
 9213   ins_pipe( pipe_slow );
 9214 %}
 9215 
<a name="248" id="anc248"></a><span class="line-modified"> 9216 instruct vsra4I_reg(vecX dst, vecX src, vecS shift) %{</span>
<span class="line-modified"> 9217   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 9218   match(Set dst (RShiftVI src shift));</span>
<span class="line-modified"> 9219   format %{ &quot;vpsrad  $dst,$src,$shift\t! arithmetic right shift packed4I&quot; %}</span>

 9220   ins_encode %{
<a name="249" id="anc249"></a><span class="line-modified"> 9221     int vector_len = 0;</span>
<span class="line-removed"> 9222     __ vpsrad($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 9223   %}
 9224   ins_pipe( pipe_slow );
 9225 %}
 9226 
<a name="250" id="anc250"></a><span class="line-modified"> 9227 instruct vsra4I_reg_imm(vecX dst, vecX src, immI8 shift) %{</span>
<span class="line-modified"> 9228   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 9229   match(Set dst (RShiftVI src shift));</span>
<span class="line-modified"> 9230   format %{ &quot;vpsrad  $dst,$src,$shift\t! arithmetic right shift packed4I&quot; %}</span>
 9231   ins_encode %{
<a name="251" id="anc251"></a><span class="line-modified"> 9232     int vector_len = 0;</span>
<span class="line-modified"> 9233     __ vpsrad($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 9234   %}
 9235   ins_pipe( pipe_slow );
 9236 %}
 9237 
<a name="252" id="anc252"></a><span class="line-modified"> 9238 instruct vsra8I_reg(vecY dst, vecY src, vecS shift) %{</span>
<span class="line-modified"> 9239   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 9240   match(Set dst (RShiftVI src shift));</span>
<span class="line-modified"> 9241   format %{ &quot;vpsrad  $dst,$src,$shift\t! arithmetic right shift packed8I&quot; %}</span>
 9242   ins_encode %{
<a name="253" id="anc253"></a><span class="line-modified"> 9243     int vector_len = 1;</span>
<span class="line-modified"> 9244     __ vpsrad($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 9245   %}
 9246   ins_pipe( pipe_slow );
 9247 %}
 9248 
<a name="254" id="anc254"></a><span class="line-modified"> 9249 instruct vsra8I_reg_imm(vecY dst, vecY src, immI8 shift) %{</span>
<span class="line-modified"> 9250   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 9251   match(Set dst (RShiftVI src shift));</span>
<span class="line-modified"> 9252   format %{ &quot;vpsrad  $dst,$src,$shift\t! arithmetic right shift packed8I&quot; %}</span>

 9253   ins_encode %{
<a name="255" id="anc255"></a><span class="line-modified"> 9254     int vector_len = 1;</span>
<span class="line-modified"> 9255     __ vpsrad($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 9256   %}
 9257   ins_pipe( pipe_slow );
 9258 %}
 9259 
<a name="256" id="anc256"></a><span class="line-modified"> 9260 instruct vsra16I_reg(vecZ dst, vecZ src, vecS shift) %{</span>
<span class="line-modified"> 9261   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-modified"> 9262   match(Set dst (RShiftVI src shift));</span>
<span class="line-modified"> 9263   format %{ &quot;vpsrad  $dst,$src,$shift\t! arithmetic right shift packed16I&quot; %}</span>
 9264   ins_encode %{
<a name="257" id="anc257"></a><span class="line-modified"> 9265     int vector_len = 2;</span>
<span class="line-modified"> 9266     __ vpsrad($dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vector_len);</span>
 9267   %}
 9268   ins_pipe( pipe_slow );
 9269 %}
 9270 
<a name="258" id="anc258"></a><span class="line-modified"> 9271 instruct vsra16I_reg_imm(vecZ dst, vecZ src, immI8 shift) %{</span>
<span class="line-modified"> 9272   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-modified"> 9273   match(Set dst (RShiftVI src shift));</span>
<span class="line-modified"> 9274   format %{ &quot;vpsrad  $dst,$src,$shift\t! arithmetic right shift packed16I&quot; %}</span>
 9275   ins_encode %{
<a name="259" id="anc259"></a><span class="line-modified"> 9276     int vector_len = 2;</span>
<span class="line-modified"> 9277     __ vpsrad($dst$$XMMRegister, $src$$XMMRegister, (int)$shift$$constant, vector_len);</span>
 9278   %}
 9279   ins_pipe( pipe_slow );
 9280 %}
 9281 
<a name="260" id="anc260"></a><span class="line-modified"> 9282 // There are no longs vector arithmetic right shift instructions.</span>
<span class="line-modified"> 9283 </span>
<span class="line-modified"> 9284 </span>
<span class="line-modified"> 9285 // --------------------------------- AND --------------------------------------</span>
<span class="line-removed"> 9286 </span>
<span class="line-removed"> 9287 instruct vand4B(vecS dst, vecS src) %{</span>
<span class="line-removed"> 9288   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 4);</span>
<span class="line-removed"> 9289   match(Set dst (AndV dst src));</span>
<span class="line-removed"> 9290   format %{ &quot;pand    $dst,$src\t! and vectors (4 bytes)&quot; %}</span>
 9291   ins_encode %{
<a name="261" id="anc261"></a><span class="line-modified"> 9292     __ pand($dst$$XMMRegister, $src$$XMMRegister);</span>


 9293   %}
 9294   ins_pipe( pipe_slow );
 9295 %}
 9296 
<a name="262" id="anc262"></a><span class="line-modified"> 9297 instruct vand4B_reg(vecS dst, vecS src1, vecS src2) %{</span>
<span class="line-modified"> 9298   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 4);</span>
<span class="line-modified"> 9299   match(Set dst (AndV src1 src2));</span>
<span class="line-removed"> 9300   format %{ &quot;vpand   $dst,$src1,$src2\t! and vectors (4 bytes)&quot; %}</span>
 9301   ins_encode %{
<a name="263" id="anc263"></a><span class="line-modified"> 9302     int vector_len = 0;</span>
<span class="line-modified"> 9303     __ vpand($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>

 9304   %}
 9305   ins_pipe( pipe_slow );
 9306 %}
 9307 
<a name="264" id="anc264"></a><span class="line-modified"> 9308 instruct vand4B_mem(vecS dst, vecS src, memory mem) %{</span>
<span class="line-modified"> 9309   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 4);</span>
<span class="line-modified"> 9310   match(Set dst (AndV src (LoadVector mem)));</span>
<span class="line-modified"> 9311   format %{ &quot;vpand   $dst,$src,$mem\t! and vectors (4 bytes)&quot; %}</span>

 9312   ins_encode %{
<a name="265" id="anc265"></a><span class="line-modified"> 9313     int vector_len = 0;</span>
<span class="line-removed"> 9314     __ vpand($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
 9315   %}
 9316   ins_pipe( pipe_slow );
 9317 %}
 9318 
<a name="266" id="anc266"></a><span class="line-modified"> 9319 instruct vand8B(vecD dst, vecD src) %{</span>
<span class="line-modified"> 9320   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 8);</span>
<span class="line-modified"> 9321   match(Set dst (AndV dst src));</span>
<span class="line-modified"> 9322   format %{ &quot;pand    $dst,$src\t! and vectors (8 bytes)&quot; %}</span>
 9323   ins_encode %{
<a name="267" id="anc267"></a><span class="line-modified"> 9324     __ pand($dst$$XMMRegister, $src$$XMMRegister);</span>

 9325   %}
 9326   ins_pipe( pipe_slow );
 9327 %}
 9328 
<a name="268" id="anc268"></a><span class="line-modified"> 9329 instruct vand8B_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-modified"> 9330   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 8);</span>
<span class="line-modified"> 9331   match(Set dst (AndV src1 src2));</span>
<span class="line-modified"> 9332   format %{ &quot;vpand   $dst,$src1,$src2\t! and vectors (8 bytes)&quot; %}</span>
 9333   ins_encode %{
<a name="269" id="anc269"></a><span class="line-modified"> 9334     int vector_len = 0;</span>
<span class="line-modified"> 9335     __ vpand($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
 9336   %}
 9337   ins_pipe( pipe_slow );
 9338 %}
 9339 
<a name="270" id="anc270"></a><span class="line-modified"> 9340 instruct vand8B_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-modified"> 9341   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 8);</span>
<span class="line-modified"> 9342   match(Set dst (AndV src (LoadVector mem)));</span>
<span class="line-modified"> 9343   format %{ &quot;vpand   $dst,$src,$mem\t! and vectors (8 bytes)&quot; %}</span>

 9344   ins_encode %{
<a name="271" id="anc271"></a><span class="line-modified"> 9345     int vector_len = 0;</span>
<span class="line-removed"> 9346     __ vpand($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
 9347   %}
 9348   ins_pipe( pipe_slow );
 9349 %}
 9350 
<a name="272" id="anc272"></a><span class="line-modified"> 9351 instruct vand16B(vecX dst, vecX src) %{</span>
<span class="line-modified"> 9352   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 16);</span>
<span class="line-modified"> 9353   match(Set dst (AndV dst src));</span>
<span class="line-modified"> 9354   format %{ &quot;pand    $dst,$src\t! and vectors (16 bytes)&quot; %}</span>
 9355   ins_encode %{
<a name="273" id="anc273"></a><span class="line-modified"> 9356     __ pand($dst$$XMMRegister, $src$$XMMRegister);</span>

 9357   %}
 9358   ins_pipe( pipe_slow );
 9359 %}
 9360 
<a name="274" id="anc274"></a><span class="line-modified"> 9361 instruct vand16B_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-modified"> 9362   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 16);</span>
<span class="line-modified"> 9363   match(Set dst (AndV src1 src2));</span>
<span class="line-modified"> 9364   format %{ &quot;vpand   $dst,$src1,$src2\t! and vectors (16 bytes)&quot; %}</span>
 9365   ins_encode %{
<a name="275" id="anc275"></a><span class="line-modified"> 9366     int vector_len = 0;</span>
<span class="line-modified"> 9367     __ vpand($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
 9368   %}
 9369   ins_pipe( pipe_slow );
 9370 %}
 9371 
<a name="276" id="anc276"></a><span class="line-modified"> 9372 instruct vand16B_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-modified"> 9373   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 16);</span>
<span class="line-modified"> 9374   match(Set dst (AndV src (LoadVector mem)));</span>
<span class="line-modified"> 9375   format %{ &quot;vpand   $dst,$src,$mem\t! and vectors (16 bytes)&quot; %}</span>



 9376   ins_encode %{
<a name="277" id="anc277"></a><span class="line-modified"> 9377     int vector_len = 0;</span>
<span class="line-modified"> 9378     __ vpand($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>


 9379   %}
 9380   ins_pipe( pipe_slow );
 9381 %}
 9382 
<a name="278" id="anc278"></a><span class="line-modified"> 9383 instruct vand32B_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-modified"> 9384   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 32);</span>
<span class="line-modified"> 9385   match(Set dst (AndV src1 src2));</span>
<span class="line-modified"> 9386   format %{ &quot;vpand   $dst,$src1,$src2\t! and vectors (32 bytes)&quot; %}</span>



 9387   ins_encode %{
 9388     int vector_len = 1;
<a name="279" id="anc279"></a><span class="line-modified"> 9389     __ vpand($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>


 9390   %}
 9391   ins_pipe( pipe_slow );
 9392 %}
 9393 
<a name="280" id="anc280"></a><span class="line-modified"> 9394 instruct vand32B_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-modified"> 9395   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 32);</span>
<span class="line-modified"> 9396   match(Set dst (AndV src (LoadVector mem)));</span>
<span class="line-modified"> 9397   format %{ &quot;vpand   $dst,$src,$mem\t! and vectors (32 bytes)&quot; %}</span>



 9398   ins_encode %{
<a name="281" id="anc281"></a><span class="line-modified"> 9399     int vector_len = 1;</span>
<span class="line-removed"> 9400     __ vpand($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
 9401   %}
 9402   ins_pipe( pipe_slow );
 9403 %}
 9404 
<a name="282" id="anc282"></a><span class="line-modified"> 9405 instruct vand64B_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-modified"> 9406   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 64);</span>
<span class="line-modified"> 9407   match(Set dst (AndV src1 src2));</span>
<span class="line-modified"> 9408   format %{ &quot;vpand   $dst,$src1,$src2\t! and vectors (64 bytes)&quot; %}</span>
 9409   ins_encode %{
<a name="283" id="anc283"></a><span class="line-modified"> 9410     int vector_len = 2;</span>
<span class="line-modified"> 9411     __ vpand($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
 9412   %}
 9413   ins_pipe( pipe_slow );
 9414 %}
 9415 
<a name="284" id="anc284"></a><span class="line-modified"> 9416 instruct vand64B_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-modified"> 9417   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 64);</span>
<span class="line-modified"> 9418   match(Set dst (AndV src (LoadVector mem)));</span>
<span class="line-modified"> 9419   format %{ &quot;vpand   $dst,$src,$mem\t! and vectors (64 bytes)&quot; %}</span>
 9420   ins_encode %{
<a name="285" id="anc285"></a><span class="line-modified"> 9421     int vector_len = 2;</span>
<span class="line-modified"> 9422     __ vpand($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
 9423   %}
 9424   ins_pipe( pipe_slow );
 9425 %}
 9426 
<a name="286" id="anc286"></a><span class="line-modified"> 9427 // --------------------------------- OR ---------------------------------------</span>
<span class="line-modified"> 9428 </span>
<span class="line-modified"> 9429 instruct vor4B(vecS dst, vecS src) %{</span>
<span class="line-modified"> 9430   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 4);</span>
<span class="line-modified"> 9431   match(Set dst (OrV dst src));</span>
<span class="line-removed"> 9432   format %{ &quot;por     $dst,$src\t! or vectors (4 bytes)&quot; %}</span>
 9433   ins_encode %{
<a name="287" id="anc287"></a><span class="line-modified"> 9434     __ por($dst$$XMMRegister, $src$$XMMRegister);</span>
 9435   %}
 9436   ins_pipe( pipe_slow );
 9437 %}
 9438 
<a name="288" id="anc288"></a><span class="line-modified"> 9439 instruct vor4B_reg(vecS dst, vecS src1, vecS src2) %{</span>
<span class="line-modified"> 9440   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 4);</span>
<span class="line-modified"> 9441   match(Set dst (OrV src1 src2));</span>
<span class="line-modified"> 9442   format %{ &quot;vpor    $dst,$src1,$src2\t! or vectors (4 bytes)&quot; %}</span>
 9443   ins_encode %{
<a name="289" id="anc289"></a><span class="line-modified"> 9444     int vector_len = 0;</span>
<span class="line-modified"> 9445     __ vpor($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
 9446   %}
 9447   ins_pipe( pipe_slow );
 9448 %}
 9449 
<a name="290" id="anc290"></a><span class="line-modified"> 9450 instruct vor4B_mem(vecS dst, vecS src, memory mem) %{</span>
<span class="line-modified"> 9451   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 4);</span>
<span class="line-modified"> 9452   match(Set dst (OrV src (LoadVector mem)));</span>
<span class="line-modified"> 9453   format %{ &quot;vpor    $dst,$src,$mem\t! or vectors (4 bytes)&quot; %}</span>
 9454   ins_encode %{
<a name="291" id="anc291"></a><span class="line-modified"> 9455     int vector_len = 0;</span>
<span class="line-modified"> 9456     __ vpor($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
 9457   %}
 9458   ins_pipe( pipe_slow );
 9459 %}
 9460 
<a name="292" id="anc292"></a><span class="line-modified"> 9461 instruct vor8B(vecD dst, vecD src) %{</span>
<span class="line-modified"> 9462   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 8);</span>
<span class="line-modified"> 9463   match(Set dst (OrV dst src));</span>
<span class="line-modified"> 9464   format %{ &quot;por     $dst,$src\t! or vectors (8 bytes)&quot; %}</span>

 9465   ins_encode %{
<a name="293" id="anc293"></a><span class="line-modified"> 9466     __ por($dst$$XMMRegister, $src$$XMMRegister);</span>


 9467   %}
 9468   ins_pipe( pipe_slow );
 9469 %}
 9470 
<a name="294" id="anc294"></a><span class="line-modified"> 9471 instruct vor8B_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-modified"> 9472   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 8);</span>
<span class="line-modified"> 9473   match(Set dst (OrV src1 src2));</span>
<span class="line-removed"> 9474   format %{ &quot;vpor    $dst,$src1,$src2\t! or vectors (8 bytes)&quot; %}</span>
 9475   ins_encode %{
<a name="295" id="anc295"></a><span class="line-modified"> 9476     int vector_len = 0;</span>
<span class="line-modified"> 9477     __ vpor($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>

 9478   %}
 9479   ins_pipe( pipe_slow );
 9480 %}
 9481 
<a name="296" id="anc296"></a><span class="line-modified"> 9482 instruct vor8B_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-modified"> 9483   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 4);</span>
<span class="line-modified"> 9484   match(Set dst (OrV src (LoadVector mem)));</span>
<span class="line-modified"> 9485   format %{ &quot;vpor    $dst,$src,$mem\t! or vectors (8 bytes)&quot; %}</span>
 9486   ins_encode %{
<a name="297" id="anc297"></a><span class="line-modified"> 9487     int vector_len = 0;</span>
<span class="line-modified"> 9488     __ vpor($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>

 9489   %}
 9490   ins_pipe( pipe_slow );
 9491 %}
 9492 
<a name="298" id="anc298"></a><span class="line-modified"> 9493 instruct vor16B(vecX dst, vecX src) %{</span>
<span class="line-modified"> 9494   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 16);</span>
<span class="line-modified"> 9495   match(Set dst (OrV dst src));</span>
<span class="line-removed"> 9496   format %{ &quot;por     $dst,$src\t! or vectors (16 bytes)&quot; %}</span>
 9497   ins_encode %{
<a name="299" id="anc299"></a><span class="line-modified"> 9498     __ por($dst$$XMMRegister, $src$$XMMRegister);</span>


 9499   %}
 9500   ins_pipe( pipe_slow );
 9501 %}
 9502 
<a name="300" id="anc300"></a><span class="line-modified"> 9503 instruct vor16B_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-modified"> 9504   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 16);</span>
<span class="line-modified"> 9505   match(Set dst (OrV src1 src2));</span>
<span class="line-modified"> 9506   format %{ &quot;vpor    $dst,$src1,$src2\t! or vectors (16 bytes)&quot; %}</span>




 9507   ins_encode %{
<a name="301" id="anc301"></a><span class="line-modified"> 9508     int vector_len = 0;</span>
<span class="line-removed"> 9509     __ vpor($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
 9510   %}
 9511   ins_pipe( pipe_slow );
 9512 %}
 9513 
<a name="302" id="anc302"></a><span class="line-modified"> 9514 instruct vor16B_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-modified"> 9515   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 16);</span>
<span class="line-modified"> 9516   match(Set dst (OrV src (LoadVector mem)));</span>
<span class="line-modified"> 9517   format %{ &quot;vpor    $dst,$src,$mem\t! or vectors (16 bytes)&quot; %}</span>




 9518   ins_encode %{
<a name="303" id="anc303"></a><span class="line-modified"> 9519     int vector_len = 0;</span>
<span class="line-modified"> 9520     __ vpor($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>





 9521   %}
 9522   ins_pipe( pipe_slow );
 9523 %}
 9524 
<a name="304" id="anc304"></a><span class="line-modified"> 9525 instruct vor32B_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-modified"> 9526   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 32);</span>
<span class="line-modified"> 9527   match(Set dst (OrV src1 src2));</span>
<span class="line-modified"> 9528   format %{ &quot;vpor    $dst,$src1,$src2\t! or vectors (32 bytes)&quot; %}</span>



 9529   ins_encode %{
<a name="305" id="anc305"></a><span class="line-modified"> 9530     int vector_len = 1;</span>
<span class="line-modified"> 9531     __ vpor($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>










 9532   %}
 9533   ins_pipe( pipe_slow );
 9534 %}
 9535 
<a name="306" id="anc306"></a><span class="line-modified"> 9536 instruct vor32B_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-modified"> 9537   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 32);</span>
<span class="line-modified"> 9538   match(Set dst (OrV src (LoadVector mem)));</span>
<span class="line-modified"> 9539   format %{ &quot;vpor    $dst,$src,$mem\t! or vectors (32 bytes)&quot; %}</span>



 9540   ins_encode %{
<a name="307" id="anc307"></a><span class="line-modified"> 9541     int vector_len = 1;</span>
<span class="line-modified"> 9542     __ vpor($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>





 9543   %}
 9544   ins_pipe( pipe_slow );
 9545 %}
 9546 
<a name="308" id="anc308"></a><span class="line-modified"> 9547 instruct vor64B_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-modified"> 9548   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 64);</span>
<span class="line-modified"> 9549   match(Set dst (OrV src1 src2));</span>
<span class="line-modified"> 9550   format %{ &quot;vpor    $dst,$src1,$src2\t! or vectors (64 bytes)&quot; %}</span>
<span class="line-modified"> 9551   ins_encode %{</span>
<span class="line-modified"> 9552     int vector_len = 2;</span>
<span class="line-modified"> 9553     __ vpor($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>








































 9554   %}
 9555   ins_pipe( pipe_slow );
 9556 %}
 9557 
<a name="309" id="anc309"></a><span class="line-modified"> 9558 instruct vor64B_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-modified"> 9559   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 64);</span>
<span class="line-modified"> 9560   match(Set dst (OrV src (LoadVector mem)));</span>
<span class="line-modified"> 9561   format %{ &quot;vpor    $dst,$src,$mem\t! or vectors (64 bytes)&quot; %}</span>







 9562   ins_encode %{
<a name="310" id="anc310"></a><span class="line-modified"> 9563     int vector_len = 2;</span>
<span class="line-modified"> 9564     __ vpor($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
















 9565   %}
 9566   ins_pipe( pipe_slow );
 9567 %}
 9568 
<a name="311" id="anc311"></a><span class="line-modified"> 9569 // --------------------------------- XOR --------------------------------------</span>
<span class="line-modified"> 9570 </span>
<span class="line-modified"> 9571 instruct vxor4B(vecS dst, vecS src) %{</span>
<span class="line-modified"> 9572   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 4);</span>
<span class="line-modified"> 9573   match(Set dst (XorV dst src));</span>
<span class="line-modified"> 9574   format %{ &quot;pxor    $dst,$src\t! xor vectors (4 bytes)&quot; %}</span>

 9575   ins_encode %{
<a name="312" id="anc312"></a><span class="line-modified"> 9576     __ pxor($dst$$XMMRegister, $src$$XMMRegister);</span>














 9577   %}
 9578   ins_pipe( pipe_slow );
 9579 %}
 9580 
<a name="313" id="anc313"></a><span class="line-modified"> 9581 instruct vxor4B_reg(vecS dst, vecS src1, vecS src2) %{</span>
<span class="line-modified"> 9582   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 4);</span>
<span class="line-modified"> 9583   match(Set dst (XorV src1 src2));</span>
<span class="line-modified"> 9584   format %{ &quot;vpxor   $dst,$src1,$src2\t! xor vectors (4 bytes)&quot; %}</span>


 9585   ins_encode %{
<a name="314" id="anc314"></a><span class="line-modified"> 9586     int vector_len = 0;</span>
<span class="line-modified"> 9587     __ vpxor($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>







 9588   %}
 9589   ins_pipe( pipe_slow );
 9590 %}
 9591 
<a name="315" id="anc315"></a><span class="line-modified"> 9592 instruct vxor4B_mem(vecS dst, vecS src, memory mem) %{</span>
<span class="line-modified"> 9593   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 4);</span>
<span class="line-modified"> 9594   match(Set dst (XorV src (LoadVector mem)));</span>
<span class="line-modified"> 9595   format %{ &quot;vpxor   $dst,$src,$mem\t! xor vectors (4 bytes)&quot; %}</span>



 9596   ins_encode %{
<a name="316" id="anc316"></a><span class="line-modified"> 9597     int vector_len = 0;</span>
<span class="line-modified"> 9598     __ vpxor($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>

















 9599   %}
 9600   ins_pipe( pipe_slow );
 9601 %}
 9602 
<a name="317" id="anc317"></a><span class="line-modified"> 9603 instruct vxor8B(vecD dst, vecD src) %{</span>
<span class="line-modified"> 9604   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 8);</span>
<span class="line-modified"> 9605   match(Set dst (XorV dst src));</span>
<span class="line-modified"> 9606   format %{ &quot;pxor    $dst,$src\t! xor vectors (8 bytes)&quot; %}</span>
 9607   ins_encode %{
<a name="318" id="anc318"></a><span class="line-modified"> 9608     __ pxor($dst$$XMMRegister, $src$$XMMRegister);</span>

 9609   %}
 9610   ins_pipe( pipe_slow );
 9611 %}
 9612 
<a name="319" id="anc319"></a><span class="line-modified"> 9613 instruct vxor8B_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-modified"> 9614   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 8);</span>
<span class="line-modified"> 9615   match(Set dst (XorV src1 src2));</span>
<span class="line-modified"> 9616   format %{ &quot;vpxor   $dst,$src1,$src2\t! xor vectors (8 bytes)&quot; %}</span>


 9617   ins_encode %{
<a name="320" id="anc320"></a><span class="line-modified"> 9618     int vector_len = 0;</span>
<span class="line-removed"> 9619     __ vpxor($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
 9620   %}
 9621   ins_pipe( pipe_slow );
 9622 %}
 9623 
<a name="321" id="anc321"></a><span class="line-modified"> 9624 instruct vxor8B_mem(vecD dst, vecD src, memory mem) %{</span>
<span class="line-modified"> 9625   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 8);</span>
<span class="line-modified"> 9626   match(Set dst (XorV src (LoadVector mem)));</span>
<span class="line-modified"> 9627   format %{ &quot;vpxor   $dst,$src,$mem\t! xor vectors (8 bytes)&quot; %}</span>
 9628   ins_encode %{
<a name="322" id="anc322"></a><span class="line-modified"> 9629     int vector_len = 0;</span>
<span class="line-modified"> 9630     __ vpxor($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
 9631   %}
 9632   ins_pipe( pipe_slow );
 9633 %}
 9634 
<a name="323" id="anc323"></a><span class="line-modified"> 9635 instruct vxor16B(vecX dst, vecX src) %{</span>
<span class="line-modified"> 9636   predicate(UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 16);</span>
<span class="line-modified"> 9637   match(Set dst (XorV dst src));</span>
<span class="line-modified"> 9638   format %{ &quot;pxor    $dst,$src\t! xor vectors (16 bytes)&quot; %}</span>
 9639   ins_encode %{
<a name="324" id="anc324"></a><span class="line-modified"> 9640     __ pxor($dst$$XMMRegister, $src$$XMMRegister);</span>

 9641   %}
 9642   ins_pipe( pipe_slow );
 9643 %}
 9644 
<a name="325" id="anc325"></a><span class="line-modified"> 9645 instruct vxor16B_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-modified"> 9646   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 16);</span>
<span class="line-modified"> 9647   match(Set dst (XorV src1 src2));</span>
<span class="line-modified"> 9648   format %{ &quot;vpxor   $dst,$src1,$src2\t! xor vectors (16 bytes)&quot; %}</span>


 9649   ins_encode %{
<a name="326" id="anc326"></a><span class="line-modified"> 9650     int vector_len = 0;</span>
<span class="line-removed"> 9651     __ vpxor($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
 9652   %}
 9653   ins_pipe( pipe_slow );
 9654 %}
 9655 
<a name="327" id="anc327"></a><span class="line-modified"> 9656 instruct vxor16B_mem(vecX dst, vecX src, memory mem) %{</span>
<span class="line-modified"> 9657   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 16);</span>
<span class="line-modified"> 9658   match(Set dst (XorV src (LoadVector mem)));</span>
<span class="line-modified"> 9659   format %{ &quot;vpxor   $dst,$src,$mem\t! xor vectors (16 bytes)&quot; %}</span>
 9660   ins_encode %{
<a name="328" id="anc328"></a><span class="line-modified"> 9661     int vector_len = 0;</span>
<span class="line-modified"> 9662     __ vpxor($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
 9663   %}
 9664   ins_pipe( pipe_slow );
 9665 %}
 9666 
<a name="329" id="anc329"></a><span class="line-modified"> 9667 instruct vxor32B_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-modified"> 9668   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 32);</span>
<span class="line-modified"> 9669   match(Set dst (XorV src1 src2));</span>
<span class="line-modified"> 9670   format %{ &quot;vpxor   $dst,$src1,$src2\t! xor vectors (32 bytes)&quot; %}</span>
 9671   ins_encode %{
<a name="330" id="anc330"></a><span class="line-modified"> 9672     int vector_len = 1;</span>
<span class="line-modified"> 9673     __ vpxor($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
 9674   %}
 9675   ins_pipe( pipe_slow );
 9676 %}
 9677 
<a name="331" id="anc331"></a><span class="line-modified"> 9678 instruct vxor32B_mem(vecY dst, vecY src, memory mem) %{</span>
<span class="line-modified"> 9679   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 32);</span>
<span class="line-modified"> 9680   match(Set dst (XorV src (LoadVector mem)));</span>
<span class="line-modified"> 9681   format %{ &quot;vpxor   $dst,$src,$mem\t! xor vectors (32 bytes)&quot; %}</span>


 9682   ins_encode %{
<a name="332" id="anc332"></a><span class="line-modified"> 9683     int vector_len = 1;</span>
<span class="line-removed"> 9684     __ vpxor($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);</span>
 9685   %}
 9686   ins_pipe( pipe_slow );
 9687 %}
 9688 
<a name="333" id="anc333"></a><span class="line-modified"> 9689 instruct vxor64B_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-modified"> 9690   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 64);</span>
 9691   match(Set dst (XorV src1 src2));
<a name="334" id="anc334"></a><span class="line-modified"> 9692   format %{ &quot;vpxor   $dst,$src1,$src2\t! xor vectors (64 bytes)&quot; %}</span>
 9693   ins_encode %{
<a name="335" id="anc335"></a><span class="line-modified"> 9694     int vector_len = 2;</span>
 9695     __ vpxor($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);
 9696   %}
 9697   ins_pipe( pipe_slow );
 9698 %}
 9699 
<a name="336" id="anc336"></a><span class="line-modified"> 9700 instruct vxor64B_mem(vecZ dst, vecZ src, memory mem) %{</span>
<span class="line-modified"> 9701   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length_in_bytes() == 64);</span>
 9702   match(Set dst (XorV src (LoadVector mem)));
<a name="337" id="anc337"></a><span class="line-modified"> 9703   format %{ &quot;vpxor   $dst,$src,$mem\t! xor vectors (64 bytes)&quot; %}</span>
 9704   ins_encode %{
<a name="338" id="anc338"></a><span class="line-modified"> 9705     int vector_len = 2;</span>
 9706     __ vpxor($dst$$XMMRegister, $src$$XMMRegister, $mem$$Address, vector_len);
 9707   %}
 9708   ins_pipe( pipe_slow );
 9709 %}
 9710 
<a name="339" id="anc339"></a><span class="line-modified"> 9711 // --------------------------------- FMA --------------------------------------</span>
<span class="line-modified"> 9712 </span>
<span class="line-modified"> 9713 // a * b + c</span>
<span class="line-modified"> 9714 instruct vfma2D_reg(vecX a, vecX b, vecX c) %{</span>
<span class="line-modified"> 9715   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 9716   match(Set c (FmaVD  c (Binary a b)));</span>
<span class="line-removed"> 9717   format %{ &quot;fmapd $a,$b,$c\t# $c = $a * $b + $c fma packed2D&quot; %}</span>
<span class="line-removed"> 9718   ins_cost(150);</span>
 9719   ins_encode %{
<a name="340" id="anc340"></a><span class="line-modified"> 9720     int vector_len = 0;</span>
<span class="line-modified"> 9721     __ vfmad($c$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, $c$$XMMRegister, vector_len);</span>





 9722   %}
 9723   ins_pipe( pipe_slow );
 9724 %}
 9725 
<a name="341" id="anc341"></a><span class="line-modified"> 9726 // a * b + c</span>
<span class="line-modified"> 9727 instruct vfma2D_mem(vecX a, memory b, vecX c) %{</span>
<span class="line-modified"> 9728   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 9729   match(Set c (FmaVD  c (Binary a (LoadVector b))));</span>
<span class="line-removed"> 9730   format %{ &quot;fmapd $a,$b,$c\t# $c = $a * $b + $c fma packed2D&quot; %}</span>
<span class="line-removed"> 9731   ins_cost(150);</span>
 9732   ins_encode %{
<a name="342" id="anc342"></a><span class="line-modified"> 9733     int vector_len = 0;</span>
<span class="line-modified"> 9734     __ vfmad($c$$XMMRegister, $a$$XMMRegister, $b$$Address, $c$$XMMRegister, vector_len);</span>





 9735   %}
 9736   ins_pipe( pipe_slow );
 9737 %}
 9738 
<a name="343" id="anc343"></a><span class="line-modified"> 9739 </span>
<span class="line-modified"> 9740 // a * b + c</span>
<span class="line-modified"> 9741 instruct vfma4D_reg(vecY a, vecY b, vecY c) %{</span>
<span class="line-removed"> 9742   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 9743   match(Set c (FmaVD  c (Binary a b)));</span>
<span class="line-removed"> 9744   format %{ &quot;fmapd $a,$b,$c\t# $c = $a * $b + $c fma packed4D&quot; %}</span>
<span class="line-removed"> 9745   ins_cost(150);</span>
 9746   ins_encode %{
<a name="344" id="anc344"></a><span class="line-modified"> 9747     int vector_len = 1;</span>
<span class="line-modified"> 9748     __ vfmad($c$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, $c$$XMMRegister, vector_len);</span>





 9749   %}
 9750   ins_pipe( pipe_slow );
 9751 %}
 9752 
<a name="345" id="anc345"></a><span class="line-modified"> 9753 // a * b + c</span>
<span class="line-modified"> 9754 instruct vfma4D_mem(vecY a, memory b, vecY c) %{</span>
<span class="line-modified"> 9755   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 9756   match(Set c (FmaVD  c (Binary a (LoadVector b))));</span>
<span class="line-removed"> 9757   format %{ &quot;fmapd $a,$b,$c\t# $c = $a * $b + $c fma packed4D&quot; %}</span>
<span class="line-removed"> 9758   ins_cost(150);</span>
 9759   ins_encode %{
<a name="346" id="anc346"></a><span class="line-modified"> 9760     int vector_len = 1;</span>
<span class="line-modified"> 9761     __ vfmad($c$$XMMRegister, $a$$XMMRegister, $b$$Address, $c$$XMMRegister, vector_len);</span>

 9762   %}
 9763   ins_pipe( pipe_slow );
 9764 %}
 9765 
<a name="347" id="anc347"></a><span class="line-modified"> 9766 // a * b + c</span>
<span class="line-removed"> 9767 instruct vfma8D_reg(vecZ a, vecZ b, vecZ c) %{</span>
<span class="line-removed"> 9768   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 9769   match(Set c (FmaVD  c (Binary a b)));</span>
<span class="line-removed"> 9770   format %{ &quot;fmapd $a,$b,$c\t# $c = $a * $b + $c fma packed8D&quot; %}</span>
<span class="line-removed"> 9771   ins_cost(150);</span>
<span class="line-removed"> 9772   ins_encode %{</span>
<span class="line-removed"> 9773     int vector_len = 2;</span>
<span class="line-removed"> 9774     __ vfmad($c$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, $c$$XMMRegister, vector_len);</span>
<span class="line-removed"> 9775   %}</span>
<span class="line-removed"> 9776   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 9777 %}</span>
 9778 
<a name="348" id="anc348"></a><span class="line-modified"> 9779 // a * b + c</span>
<span class="line-modified"> 9780 instruct vfma8D_mem(vecZ a, memory b, vecZ c) %{</span>
<span class="line-modified"> 9781   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-modified"> 9782   match(Set c (FmaVD  c (Binary a (LoadVector b))));</span>
<span class="line-modified"> 9783   format %{ &quot;fmapd $a,$b,$c\t# $c = $a * $b + $c fma packed8D&quot; %}</span>

 9784   ins_cost(150);
 9785   ins_encode %{
<a name="349" id="anc349"></a><span class="line-modified"> 9786     int vector_len = 2;</span>
<span class="line-modified"> 9787     __ vfmad($c$$XMMRegister, $a$$XMMRegister, $b$$Address, $c$$XMMRegister, vector_len);</span>







 9788   %}
 9789   ins_pipe( pipe_slow );
 9790 %}
 9791 
<a name="350" id="anc350"></a><span class="line-modified"> 9792 // a * b + c</span>
<span class="line-modified"> 9793 instruct vfma4F_reg(vecX a, vecX b, vecX c) %{</span>
<span class="line-modified"> 9794   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 9795   match(Set c (FmaVF  c (Binary a b)));</span>
<span class="line-modified"> 9796   format %{ &quot;fmaps $a,$b,$c\t# $c = $a * $b + $c fma packed4F&quot; %}</span>

 9797   ins_cost(150);
 9798   ins_encode %{
<a name="351" id="anc351"></a><span class="line-modified"> 9799     int vector_len = 0;</span>
<span class="line-modified"> 9800     __ vfmaf($c$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, $c$$XMMRegister, vector_len);</span>
 9801   %}
 9802   ins_pipe( pipe_slow );
 9803 %}
 9804 
<a name="352" id="anc352"></a><span class="line-modified"> 9805 // a * b + c</span>
<span class="line-modified"> 9806 instruct vfma4F_mem(vecX a, memory b, vecX c) %{</span>
<span class="line-modified"> 9807   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-modified"> 9808   match(Set c (FmaVF  c (Binary a (LoadVector b))));</span>
<span class="line-modified"> 9809   format %{ &quot;fmaps $a,$b,$c\t# $c = $a * $b + $c fma packed4F&quot; %}</span>
<span class="line-removed"> 9810   ins_cost(150);</span>
 9811   ins_encode %{
<a name="353" id="anc353"></a><span class="line-modified"> 9812     int vector_len = 0;</span>
<span class="line-modified"> 9813     __ vfmaf($c$$XMMRegister, $a$$XMMRegister, $b$$Address, $c$$XMMRegister, vector_len);</span>







 9814   %}
 9815   ins_pipe( pipe_slow );
 9816 %}
 9817 
<a name="354" id="anc354"></a>
 9818 // a * b + c
<a name="355" id="anc355"></a><span class="line-modified"> 9819 instruct vfma8F_reg(vecY a, vecY b, vecY c) %{</span>
<span class="line-modified"> 9820   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
 9821   match(Set c (FmaVF  c (Binary a b)));
<a name="356" id="anc356"></a><span class="line-modified"> 9822   format %{ &quot;fmaps $a,$b,$c\t# $c = $a * $b + $c fma packed8F&quot; %}</span>
 9823   ins_cost(150);
 9824   ins_encode %{
<a name="357" id="anc357"></a><span class="line-modified"> 9825     int vector_len = 1;</span>

 9826     __ vfmaf($c$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, $c$$XMMRegister, vector_len);
 9827   %}
 9828   ins_pipe( pipe_slow );
 9829 %}
 9830 
<a name="358" id="anc358"></a><span class="line-modified"> 9831 // a * b + c</span>
<span class="line-removed"> 9832 instruct vfma8F_mem(vecY a, memory b, vecY c) %{</span>
<span class="line-removed"> 9833   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
 9834   match(Set c (FmaVF  c (Binary a (LoadVector b))));
<a name="359" id="anc359"></a><span class="line-modified"> 9835   format %{ &quot;fmaps $a,$b,$c\t# $c = $a * $b + $c fma packed8F&quot; %}</span>
 9836   ins_cost(150);
 9837   ins_encode %{
<a name="360" id="anc360"></a><span class="line-modified"> 9838     int vector_len = 1;</span>

 9839     __ vfmaf($c$$XMMRegister, $a$$XMMRegister, $b$$Address, $c$$XMMRegister, vector_len);
 9840   %}
 9841   ins_pipe( pipe_slow );
 9842 %}
 9843 
<a name="361" id="anc361"></a><span class="line-modified"> 9844 // a * b + c</span>
<span class="line-modified"> 9845 instruct vfma16F_reg(vecZ a, vecZ b, vecZ c) %{</span>
<span class="line-modified"> 9846   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 9847   match(Set c (FmaVF  c (Binary a b)));</span>
<span class="line-removed"> 9848   format %{ &quot;fmaps $a,$b,$c\t# $c = $a * $b + $c fma packed16F&quot; %}</span>
 9849   ins_cost(150);
 9850   ins_encode %{
<a name="362" id="anc362"></a><span class="line-modified"> 9851     int vector_len = 2;</span>
<span class="line-modified"> 9852     __ vfmaf($c$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, $c$$XMMRegister, vector_len);</span>

 9853   %}
 9854   ins_pipe( pipe_slow );
 9855 %}
 9856 
<a name="363" id="anc363"></a><span class="line-modified"> 9857 // a * b + c</span>
<span class="line-modified"> 9858 instruct vfma16F_mem(vecZ a, memory b, vecZ c) %{</span>
<span class="line-modified"> 9859   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 9860   match(Set c (FmaVF  c (Binary a (LoadVector b))));</span>
<span class="line-removed"> 9861   format %{ &quot;fmaps $a,$b,$c\t# $c = $a * $b + $c fma packed16F&quot; %}</span>
 9862   ins_cost(150);
 9863   ins_encode %{
<a name="364" id="anc364"></a><span class="line-modified"> 9864     int vector_len = 2;</span>
<span class="line-modified"> 9865     __ vfmaf($c$$XMMRegister, $a$$XMMRegister, $b$$Address, $c$$XMMRegister, vector_len);</span>

 9866   %}
 9867   ins_pipe( pipe_slow );
 9868 %}
 9869 
 9870 // --------------------------------- Vector Multiply Add --------------------------------------
 9871 
<a name="365" id="anc365"></a><span class="line-modified"> 9872 instruct smuladd4S2I_reg(vecD dst, vecD src1) %{</span>
<span class="line-modified"> 9873   predicate(UseSSE &gt;= 2 &amp;&amp; UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 9874   match(Set dst (MulAddVS2VI dst src1));</span>
<span class="line-removed"> 9875   format %{ &quot;pmaddwd $dst,$dst,$src1\t! muladd packed4Sto2I&quot; %}</span>
<span class="line-removed"> 9876   ins_encode %{</span>
<span class="line-removed"> 9877     __ pmaddwd($dst$$XMMRegister, $src1$$XMMRegister);</span>
<span class="line-removed"> 9878   %}</span>
<span class="line-removed"> 9879   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 9880 %}</span>
<span class="line-removed"> 9881 </span>
<span class="line-removed"> 9882 instruct vmuladd4S2I_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-removed"> 9883   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 9884   match(Set dst (MulAddVS2VI src1 src2));</span>
<span class="line-removed"> 9885   format %{ &quot;vpmaddwd $dst,$src1,$src2\t! muladd packed4Sto2I&quot; %}</span>
<span class="line-removed"> 9886   ins_encode %{</span>
<span class="line-removed"> 9887     int vector_len = 0;</span>
<span class="line-removed"> 9888     __ vpmaddwd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 9889   %}</span>
<span class="line-removed"> 9890   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 9891 %}</span>
<span class="line-removed"> 9892 </span>
<span class="line-removed"> 9893 instruct smuladd8S4I_reg(vecX dst, vecX src1) %{</span>
<span class="line-removed"> 9894   predicate(UseSSE &gt;= 2 &amp;&amp; UseAVX == 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
 9895   match(Set dst (MulAddVS2VI dst src1));
<a name="366" id="anc366"></a><span class="line-modified"> 9896   format %{ &quot;pmaddwd $dst,$dst,$src1\t! muladd packed8Sto4I&quot; %}</span>
 9897   ins_encode %{
 9898     __ pmaddwd($dst$$XMMRegister, $src1$$XMMRegister);
 9899   %}
 9900   ins_pipe( pipe_slow );
 9901 %}
 9902 
<a name="367" id="anc367"></a><span class="line-modified"> 9903 instruct vmuladd8S4I_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-modified"> 9904   predicate(UseAVX &gt; 0 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 9905   match(Set dst (MulAddVS2VI src1 src2));</span>
<span class="line-removed"> 9906   format %{ &quot;vpmaddwd $dst,$src1,$src2\t! muladd packed8Sto4I&quot; %}</span>
<span class="line-removed"> 9907   ins_encode %{</span>
<span class="line-removed"> 9908     int vector_len = 0;</span>
<span class="line-removed"> 9909     __ vpmaddwd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 9910   %}</span>
<span class="line-removed"> 9911   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 9912 %}</span>
<span class="line-removed"> 9913 </span>
<span class="line-removed"> 9914 instruct vmuladd16S8I_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 9915   predicate(UseAVX &gt; 1 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-removed"> 9916   match(Set dst (MulAddVS2VI src1 src2));</span>
<span class="line-removed"> 9917   format %{ &quot;vpmaddwd $dst,$src1,$src2\t! muladd packed16Sto8I&quot; %}</span>
<span class="line-removed"> 9918   ins_encode %{</span>
<span class="line-removed"> 9919     int vector_len = 1;</span>
<span class="line-removed"> 9920     __ vpmaddwd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 9921   %}</span>
<span class="line-removed"> 9922   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 9923 %}</span>
<span class="line-removed"> 9924 </span>
<span class="line-removed"> 9925 instruct vmuladd32S16I_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 9926   predicate(UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
 9927   match(Set dst (MulAddVS2VI src1 src2));
<a name="368" id="anc368"></a><span class="line-modified"> 9928   format %{ &quot;vpmaddwd $dst,$src1,$src2\t! muladd packed32Sto16I&quot; %}</span>
 9929   ins_encode %{
<a name="369" id="anc369"></a><span class="line-modified"> 9930     int vector_len = 2;</span>
 9931     __ vpmaddwd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);
 9932   %}
 9933   ins_pipe( pipe_slow );
 9934 %}
 9935 
 9936 // --------------------------------- Vector Multiply Add Add ----------------------------------
 9937 
<a name="370" id="anc370"></a><span class="line-modified"> 9938 instruct vmuladdadd4S2I_reg(vecD dst, vecD src1, vecD src2) %{</span>
<span class="line-modified"> 9939   predicate(VM_Version::supports_vnni() &amp;&amp; UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 9940   match(Set dst (AddVI (MulAddVS2VI src1 src2) dst));</span>
<span class="line-removed"> 9941   format %{ &quot;evpdpwssd $dst,$src1,$src2\t! muladdadd packed4Sto2I&quot; %}</span>
<span class="line-removed"> 9942   ins_encode %{</span>
<span class="line-removed"> 9943     int vector_len = 0;</span>
<span class="line-removed"> 9944     __ evpdpwssd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 9945   %}</span>
<span class="line-removed"> 9946   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 9947   ins_cost(10);</span>
<span class="line-removed"> 9948 %}</span>
<span class="line-removed"> 9949 </span>
<span class="line-removed"> 9950 instruct vmuladdadd8S4I_reg(vecX dst, vecX src1, vecX src2) %{</span>
<span class="line-removed"> 9951   predicate(VM_Version::supports_vnni() &amp;&amp; UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed"> 9952   match(Set dst (AddVI (MulAddVS2VI src1 src2) dst));</span>
<span class="line-removed"> 9953   format %{ &quot;evpdpwssd $dst,$src1,$src2\t! muladdadd packed8Sto4I&quot; %}</span>
<span class="line-removed"> 9954   ins_encode %{</span>
<span class="line-removed"> 9955     int vector_len = 0;</span>
<span class="line-removed"> 9956     __ evpdpwssd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 9957   %}</span>
<span class="line-removed"> 9958   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 9959   ins_cost(10);</span>
<span class="line-removed"> 9960 %}</span>
<span class="line-removed"> 9961 </span>
<span class="line-removed"> 9962 instruct vmuladdadd16S8I_reg(vecY dst, vecY src1, vecY src2) %{</span>
<span class="line-removed"> 9963   predicate(VM_Version::supports_vnni() &amp;&amp; UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
 9964   match(Set dst (AddVI (MulAddVS2VI src1 src2) dst));
<a name="371" id="anc371"></a><span class="line-modified"> 9965   format %{ &quot;evpdpwssd $dst,$src1,$src2\t! muladdadd packed16Sto8I&quot; %}</span>
 9966   ins_encode %{
<a name="372" id="anc372"></a><span class="line-modified"> 9967     int vector_len = 1;</span>
<span class="line-modified"> 9968     __ evpdpwssd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);</span>
<span class="line-removed"> 9969   %}</span>
<span class="line-removed"> 9970   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 9971   ins_cost(10);</span>
<span class="line-removed"> 9972 %}</span>
<span class="line-removed"> 9973 </span>
<span class="line-removed"> 9974 instruct vmuladdadd32S16I_reg(vecZ dst, vecZ src1, vecZ src2) %{</span>
<span class="line-removed"> 9975   predicate(VM_Version::supports_vnni() &amp;&amp; UseAVX &gt; 2 &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed"> 9976   match(Set dst (AddVI (MulAddVS2VI src1 src2) dst));</span>
<span class="line-removed"> 9977   format %{ &quot;evpdpwssd $dst,$src1,$src2\t! muladdadd packed32Sto16I&quot; %}</span>
<span class="line-removed"> 9978   ins_encode %{</span>
<span class="line-removed"> 9979     int vector_len = 2;</span>
 9980     __ evpdpwssd($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, vector_len);
 9981   %}
 9982   ins_pipe( pipe_slow );
 9983   ins_cost(10);
 9984 %}
 9985 
 9986 // --------------------------------- PopCount --------------------------------------
 9987 
<a name="373" id="anc373"></a><span class="line-modified"> 9988 instruct vpopcount2I(vecD dst, vecD src) %{</span>
<span class="line-removed"> 9989   predicate(VM_Version::supports_vpopcntdq() &amp;&amp; UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);</span>
<span class="line-removed"> 9990   match(Set dst (PopCountVI src));</span>
<span class="line-removed"> 9991   format %{ &quot;vpopcntd  $dst,$src\t! vector popcount packed2I&quot; %}</span>
<span class="line-removed"> 9992   ins_encode %{</span>
<span class="line-removed"> 9993     int vector_len = 0;</span>
<span class="line-removed"> 9994     __ vpopcntd($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed"> 9995   %}</span>
<span class="line-removed"> 9996   ins_pipe( pipe_slow );</span>
<span class="line-removed"> 9997 %}</span>
<span class="line-removed"> 9998 </span>
<span class="line-removed"> 9999 instruct vpopcount4I(vecX dst, vecX src) %{</span>
<span class="line-removed">10000   predicate(VM_Version::supports_vpopcntdq() &amp;&amp; UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);</span>
<span class="line-removed">10001   match(Set dst (PopCountVI src));</span>
<span class="line-removed">10002   format %{ &quot;vpopcntd  $dst,$src\t! vector popcount packed4I&quot; %}</span>
<span class="line-removed">10003   ins_encode %{</span>
<span class="line-removed">10004     int vector_len = 0;</span>
<span class="line-removed">10005     __ vpopcntd($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed">10006   %}</span>
<span class="line-removed">10007   ins_pipe( pipe_slow );</span>
<span class="line-removed">10008 %}</span>
<span class="line-removed">10009 </span>
<span class="line-removed">10010 instruct vpopcount8I(vecY dst, vecY src) %{</span>
<span class="line-removed">10011   predicate(VM_Version::supports_vpopcntdq() &amp;&amp; UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 8);</span>
10012   match(Set dst (PopCountVI src));
<a name="374" id="anc374"></a><span class="line-modified">10013   format %{ &quot;vpopcntd  $dst,$src\t! vector popcount packed8I&quot; %}</span>
10014   ins_encode %{
<a name="375" id="anc375"></a><span class="line-modified">10015     int vector_len = 1;</span>
<span class="line-removed">10016     __ vpopcntd($dst$$XMMRegister, $src$$XMMRegister, vector_len);</span>
<span class="line-removed">10017   %}</span>
<span class="line-removed">10018   ins_pipe( pipe_slow );</span>
<span class="line-removed">10019 %}</span>
10020 
<a name="376" id="anc376"></a><span class="line-modified">10021 instruct vpopcount16I(vecZ dst, vecZ src) %{</span>
<span class="line-removed">10022   predicate(VM_Version::supports_vpopcntdq() &amp;&amp; UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-removed">10023   match(Set dst (PopCountVI src));</span>
<span class="line-removed">10024   format %{ &quot;vpopcntd  $dst,$src\t! vector popcount packed16I&quot; %}</span>
<span class="line-removed">10025   ins_encode %{</span>
<span class="line-removed">10026     int vector_len = 2;</span>
10027     __ vpopcntd($dst$$XMMRegister, $src$$XMMRegister, vector_len);
10028   %}
10029   ins_pipe( pipe_slow );
10030 %}
<a name="377" id="anc377"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="377" type="hidden" />
</body>
</html>