<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/assembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="abstractInterpreter_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="assembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/assembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 772       break;
 773 
 774     case 0x70: // pshufd r, r/a, #8
 775       debug_only(has_disp32 = true); // has both kinds of operands!
 776     case 0x73: // psrldq r, #8
 777       tail_size = 1;
 778       break;
 779 
 780     case 0x12: // movlps
 781     case 0x28: // movaps
 782     case 0x2E: // ucomiss
 783     case 0x2F: // comiss
 784     case 0x54: // andps
 785     case 0x55: // andnps
 786     case 0x56: // orps
 787     case 0x57: // xorps
 788     case 0x58: // addpd
 789     case 0x59: // mulpd
 790     case 0x6E: // movd
 791     case 0x7E: // movd


 792     case 0xAE: // ldmxcsr, stmxcsr, fxrstor, fxsave, clflush
 793     case 0xFE: // paddd
 794       debug_only(has_disp32 = true);
 795       break;
 796 
 797     case 0xAD: // shrd r, a, %cl
 798     case 0xAF: // imul r, a
 799     case 0xBE: // movsbl r, a (movsxb)
 800     case 0xBF: // movswl r, a (movsxw)
 801     case 0xB6: // movzbl r, a (movzxb)
 802     case 0xB7: // movzwl r, a (movzxw)
 803     case REP16(0x40): // cmovl cc, r, a
 804     case 0xB0: // cmpxchgb
 805     case 0xB1: // cmpxchg
 806     case 0xC1: // xaddl
 807     case 0xC7: // cmpxchg8
 808     case REP16(0x90): // setcc a
 809       debug_only(has_disp32 = true);
 810       // fall out of the switch to decode the address
 811       break;
</pre>
<hr />
<pre>
1361   emit_int8((unsigned char)(0xC0 | encode));
1362 }
1363 
1364 void Assembler::aesenc(XMMRegister dst, Address src) {
1365   assert(VM_Version::supports_aes(), &quot;&quot;);
1366   InstructionMark im(this);
1367   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1368   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1369   emit_int8((unsigned char)0xDC);
1370   emit_operand(dst, src);
1371 }
1372 
1373 void Assembler::aesenc(XMMRegister dst, XMMRegister src) {
1374   assert(VM_Version::supports_aes(), &quot;&quot;);
1375   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1376   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1377   emit_int8((unsigned char)0xDC);
1378   emit_int8(0xC0 | encode);
1379 }
1380 









1381 void Assembler::aesenclast(XMMRegister dst, Address src) {
1382   assert(VM_Version::supports_aes(), &quot;&quot;);
1383   InstructionMark im(this);
1384   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1385   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1386   emit_int8((unsigned char)0xDD);
1387   emit_operand(dst, src);
1388 }
1389 
1390 void Assembler::aesenclast(XMMRegister dst, XMMRegister src) {
1391   assert(VM_Version::supports_aes(), &quot;&quot;);
1392   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1393   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1394   emit_int8((unsigned char)0xDD);
1395   emit_int8((unsigned char)(0xC0 | encode));
1396 }
1397 









1398 void Assembler::andl(Address dst, int32_t imm32) {
1399   InstructionMark im(this);
1400   prefix(dst);
1401   emit_int8((unsigned char)0x81);
1402   emit_operand(rsp, dst, 4);
1403   emit_int32(imm32);
1404 }
1405 
1406 void Assembler::andl(Register dst, int32_t imm32) {
1407   prefix(dst);
1408   emit_arith(0x81, 0xE0, dst, imm32);
1409 }
1410 
1411 void Assembler::andl(Register dst, Address src) {
1412   InstructionMark im(this);
1413   prefix(src, dst);
1414   emit_int8(0x23);
1415   emit_operand(dst, src);
1416 }
1417 
</pre>
<hr />
<pre>
1877   emit_int8((unsigned char)(0xC0 | encode));
1878 }
1879 
1880 void Assembler::cvttss2sil(Register dst, XMMRegister src) {
1881   NOT_LP64(assert(VM_Version::supports_sse(), &quot;&quot;));
1882   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
1883   int encode = simd_prefix_and_encode(as_XMMRegister(dst-&gt;encoding()), xnoreg, src, VEX_SIMD_F3, VEX_OPCODE_0F, &amp;attributes);
1884   emit_int8(0x2C);
1885   emit_int8((unsigned char)(0xC0 | encode));
1886 }
1887 
1888 void Assembler::cvttpd2dq(XMMRegister dst, XMMRegister src) {
1889   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
1890   int vector_len = VM_Version::supports_avx512novl() ? AVX_512bit : AVX_128bit;
1891   InstructionAttr attributes(vector_len, /* rex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
1892   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
1893   emit_int8((unsigned char)0xE6);
1894   emit_int8((unsigned char)(0xC0 | encode));
1895 }
1896 































































1897 void Assembler::decl(Address dst) {
1898   // Don&#39;t use it directly. Use MacroAssembler::decrement() instead.
1899   InstructionMark im(this);
1900   prefix(dst);
1901   emit_int8((unsigned char)0xFF);
1902   emit_operand(rcx, dst);
1903 }
1904 
1905 void Assembler::divsd(XMMRegister dst, Address src) {
1906   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
1907   InstructionMark im(this);
1908   InstructionAttr attributes(AVX_128bit, /* rex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
1909   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_64bit);
1910   attributes.set_rex_vex_w_reverted();
1911   simd_prefix(dst, dst, src, VEX_SIMD_F2, VEX_OPCODE_0F, &amp;attributes);
1912   emit_int8(0x5E);
1913   emit_operand(dst, src);
1914 }
1915 
1916 void Assembler::divsd(XMMRegister dst, XMMRegister src) {
</pre>
<hr />
<pre>
2174   emit_int8((unsigned char)0xF0);
2175 }
2176 
2177 void Assembler::lzcntl(Register dst, Register src) {
2178   assert(VM_Version::supports_lzcnt(), &quot;encoding is treated as BSR&quot;);
2179   emit_int8((unsigned char)0xF3);
2180   int encode = prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding());
2181   emit_int8(0x0F);
2182   emit_int8((unsigned char)0xBD);
2183   emit_int8((unsigned char)(0xC0 | encode));
2184 }
2185 
2186 // Emit mfence instruction
2187 void Assembler::mfence() {
2188   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;unsupported&quot;);)
2189   emit_int8(0x0F);
2190   emit_int8((unsigned char)0xAE);
2191   emit_int8((unsigned char)0xF0);
2192 }
2193 








2194 void Assembler::mov(Register dst, Register src) {
2195   LP64_ONLY(movq(dst, src)) NOT_LP64(movl(dst, src));
2196 }
2197 
2198 void Assembler::movapd(XMMRegister dst, XMMRegister src) {
2199   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
2200   int vector_len = VM_Version::supports_avx512novl() ? AVX_512bit : AVX_128bit;
2201   InstructionAttr attributes(vector_len, /* rex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
2202   attributes.set_rex_vex_w_reverted();
2203   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
2204   emit_int8(0x28);
2205   emit_int8((unsigned char)(0xC0 | encode));
2206 }
2207 
2208 void Assembler::movaps(XMMRegister dst, XMMRegister src) {
2209   NOT_LP64(assert(VM_Version::supports_sse(), &quot;&quot;));
2210   int vector_len = VM_Version::supports_avx512novl() ? AVX_512bit : AVX_128bit;
2211   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
2212   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_NONE, VEX_OPCODE_0F, &amp;attributes);
2213   emit_int8(0x28);
</pre>
<hr />
<pre>
3082       case 5:
3083         addr_nop_5();
3084         break;
3085       case 4:
3086         addr_nop_4();
3087         break;
3088       case 3:
3089         // Don&#39;t use &quot;0x0F 0x1F 0x00&quot; - need patching safe padding
3090         emit_int8(0x66); // size prefix
3091       case 2:
3092         emit_int8(0x66); // size prefix
3093       case 1:
3094         emit_int8((unsigned char)0x90);
3095                          // nop
3096         break;
3097       default:
3098         assert(i == 0, &quot; &quot;);
3099     }
3100     return;
3101   }
<span class="line-modified">3102   if (UseAddressNop &amp;&amp; VM_Version::is_amd()) {</span>
3103     //
3104     // Using multi-bytes nops &quot;0x0F 0x1F [address]&quot; for AMD.
3105     //  1: 0x90
3106     //  2: 0x66 0x90
3107     //  3: 0x66 0x66 0x90 (don&#39;t use &quot;0x0F 0x1F 0x00&quot; - need patching safe padding)
3108     //  4: 0x0F 0x1F 0x40 0x00
3109     //  5: 0x0F 0x1F 0x44 0x00 0x00
3110     //  6: 0x66 0x0F 0x1F 0x44 0x00 0x00
3111     //  7: 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00
3112     //  8: 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00
3113     //  9: 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00
3114     // 10: 0x66 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00
3115     // 11: 0x66 0x66 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00
3116 
3117     // The rest coding is AMD specific - use consecutive address nops
3118 
3119     // 12: 0x66 0x0F 0x1F 0x44 0x00 0x00 0x66 0x0F 0x1F 0x44 0x00 0x00
3120     // 13: 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00 0x66 0x0F 0x1F 0x44 0x00 0x00
3121     // 14: 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00
3122     // 15: 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00
</pre>
<hr />
<pre>
3399   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
3400   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
3401   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
3402   emit_int8(0x67);
3403   emit_int8((unsigned char)(0xC0 | encode));
3404 }
3405 
3406 void Assembler::vpackuswb(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
3407   assert(UseAVX &gt; 0, &quot;some form of AVX must be enabled&quot;);
3408   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
3409   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
3410   emit_int8(0x67);
3411   emit_int8((unsigned char)(0xC0 | encode));
3412 }
3413 
3414 void Assembler::vpermq(XMMRegister dst, XMMRegister src, int imm8, int vector_len) {
3415   assert(VM_Version::supports_avx2(), &quot;&quot;);
3416   InstructionAttr attributes(vector_len, /* rex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
3417   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
3418   emit_int8(0x00);
<span class="line-modified">3419   emit_int8(0xC0 | encode);</span>
3420   emit_int8(imm8);
3421 }
3422 









3423 void Assembler::vperm2i128(XMMRegister dst,  XMMRegister nds, XMMRegister src, int imm8) {
3424   assert(VM_Version::supports_avx2(), &quot;&quot;);
3425   InstructionAttr attributes(AVX_256bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
3426   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
3427   emit_int8(0x46);
3428   emit_int8(0xC0 | encode);
3429   emit_int8(imm8);
3430 }
3431 
3432 void Assembler::vperm2f128(XMMRegister dst, XMMRegister nds, XMMRegister src, int imm8) {
3433   assert(VM_Version::supports_avx(), &quot;&quot;);
3434   InstructionAttr attributes(AVX_256bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
3435   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
3436   emit_int8(0x06);
3437   emit_int8(0xC0 | encode);
3438   emit_int8(imm8);
3439 }
3440 
3441 void Assembler::evpermi2q(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
3442   assert(VM_Version::supports_evex(), &quot;&quot;);
</pre>
<hr />
<pre>
3867 }
3868 
3869 void Assembler::pmovzxbw(XMMRegister dst, Address src) {
3870   assert(VM_Version::supports_sse4_1(), &quot;&quot;);
3871   InstructionMark im(this);
3872   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
3873   attributes.set_address_attributes(/* tuple_type */ EVEX_HVM, /* input_size_in_bits */ EVEX_NObit);
3874   simd_prefix(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
3875   emit_int8(0x30);
3876   emit_operand(dst, src);
3877 }
3878 
3879 void Assembler::pmovzxbw(XMMRegister dst, XMMRegister src) {
3880   assert(VM_Version::supports_sse4_1(), &quot;&quot;);
3881   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
3882   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
3883   emit_int8(0x30);
3884   emit_int8((unsigned char)(0xC0 | encode));
3885 }
3886 








3887 void Assembler::vpmovzxbw(XMMRegister dst, Address src, int vector_len) {
3888   assert(VM_Version::supports_avx(), &quot;&quot;);
3889   InstructionMark im(this);
3890   assert(dst != xnoreg, &quot;sanity&quot;);
3891   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
3892   attributes.set_address_attributes(/* tuple_type */ EVEX_HVM, /* input_size_in_bits */ EVEX_NObit);
3893   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
3894   emit_int8(0x30);
3895   emit_operand(dst, src);
3896 }
3897 
3898 void Assembler::vpmovzxbw(XMMRegister dst, XMMRegister src, int vector_len) {
3899   assert(vector_len == AVX_128bit? VM_Version::supports_avx() :
3900   vector_len == AVX_256bit? VM_Version::supports_avx2() :
3901   vector_len == AVX_512bit? VM_Version::supports_avx512bw() : 0, &quot;&quot;);
3902   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
3903   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
3904   emit_int8(0x30);
3905   emit_int8((unsigned char) (0xC0 | encode));
3906 }
3907 









3908 
3909 void Assembler::evpmovzxbw(XMMRegister dst, KRegister mask, Address src, int vector_len) {
3910   assert(VM_Version::supports_avx512vlbw(), &quot;&quot;);
3911   assert(dst != xnoreg, &quot;sanity&quot;);
3912   InstructionMark im(this);
3913   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ false, /* uses_vl */ true);
3914   attributes.set_address_attributes(/* tuple_type */ EVEX_HVM, /* input_size_in_bits */ EVEX_NObit);
3915   attributes.set_embedded_opmask_register_specifier(mask);
3916   attributes.set_is_evex_instruction();
3917   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
3918   emit_int8(0x30);
3919   emit_operand(dst, src);
3920 }
3921 void Assembler::evpmovwb(Address dst, XMMRegister src, int vector_len) {
3922   assert(VM_Version::supports_avx512vlbw(), &quot;&quot;);
3923   assert(src != xnoreg, &quot;sanity&quot;);
3924   InstructionMark im(this);
3925   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
3926   attributes.set_address_attributes(/* tuple_type */ EVEX_HVM, /* input_size_in_bits */ EVEX_NObit);
3927   attributes.set_is_evex_instruction();
</pre>
<hr />
<pre>
4093   prefetch_prefix(src);
4094   emit_int8(0x0D);
4095   emit_operand(rcx, src); // 1, src
4096 }
4097 
4098 void Assembler::prefix(Prefix p) {
4099   emit_int8(p);
4100 }
4101 
4102 void Assembler::pshufb(XMMRegister dst, XMMRegister src) {
4103   assert(VM_Version::supports_ssse3(), &quot;&quot;);
4104   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4105   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
4106   emit_int8(0x00);
4107   emit_int8((unsigned char)(0xC0 | encode));
4108 }
4109 
4110 void Assembler::vpshufb(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
4111   assert(vector_len == AVX_128bit? VM_Version::supports_avx() :
4112          vector_len == AVX_256bit? VM_Version::supports_avx2() :
<span class="line-modified">4113          0, &quot;&quot;);</span>
4114   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4115   int encode = simd_prefix_and_encode(dst, nds, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
4116   emit_int8(0x00);
4117   emit_int8((unsigned char)(0xC0 | encode));
4118 }
4119 
4120 void Assembler::pshufb(XMMRegister dst, Address src) {
4121   assert(VM_Version::supports_ssse3(), &quot;&quot;);
4122   InstructionMark im(this);
4123   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4124   attributes.set_address_attributes(/* tuple_type */ EVEX_FVM, /* input_size_in_bits */ EVEX_NObit);
4125   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
4126   emit_int8(0x00);
4127   emit_operand(dst, src);
4128 }
4129 
4130 void Assembler::pshufd(XMMRegister dst, XMMRegister src, int mode) {
4131   assert(isByte(mode), &quot;invalid value&quot;);
4132   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4133   int vector_len = VM_Version::supports_avx512novl() ? AVX_512bit : AVX_128bit;
4134   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
4135   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
4136   emit_int8(0x70);
4137   emit_int8((unsigned char)(0xC0 | encode));
4138   emit_int8(mode &amp; 0xFF);
4139 }
4140 
4141 void Assembler::vpshufd(XMMRegister dst, XMMRegister src, int mode, int vector_len) {
4142   assert(vector_len == AVX_128bit? VM_Version::supports_avx() :
<span class="line-modified">4143          vector_len == AVX_256bit? VM_Version::supports_avx2() :</span>
<span class="line-modified">4144          0, &quot;&quot;);</span>
4145   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4146   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
4147   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
4148   emit_int8(0x70);
4149   emit_int8((unsigned char)(0xC0 | encode));
4150   emit_int8(mode &amp; 0xFF);
4151 }
4152 
4153 void Assembler::pshufd(XMMRegister dst, Address src, int mode) {
4154   assert(isByte(mode), &quot;invalid value&quot;);
4155   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4156   assert((UseAVX &gt; 0), &quot;SSE mode requires address alignment 16 bytes&quot;);
4157   InstructionMark im(this);
4158   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
4159   attributes.set_address_attributes(/* tuple_type */ EVEX_FV, /* input_size_in_bits */ EVEX_32bit);
4160   simd_prefix(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
4161   emit_int8(0x70);
4162   emit_operand(dst, src);
4163   emit_int8(mode &amp; 0xFF);
4164 }
</pre>
<hr />
<pre>
4168   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4169   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4170   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_F2, VEX_OPCODE_0F, &amp;attributes);
4171   emit_int8(0x70);
4172   emit_int8((unsigned char)(0xC0 | encode));
4173   emit_int8(mode &amp; 0xFF);
4174 }
4175 
4176 void Assembler::pshuflw(XMMRegister dst, Address src, int mode) {
4177   assert(isByte(mode), &quot;invalid value&quot;);
4178   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4179   assert((UseAVX &gt; 0), &quot;SSE mode requires address alignment 16 bytes&quot;);
4180   InstructionMark im(this);
4181   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4182   attributes.set_address_attributes(/* tuple_type */ EVEX_FVM, /* input_size_in_bits */ EVEX_NObit);
4183   simd_prefix(dst, xnoreg, src, VEX_SIMD_F2, VEX_OPCODE_0F, &amp;attributes);
4184   emit_int8(0x70);
4185   emit_operand(dst, src);
4186   emit_int8(mode &amp; 0xFF);
4187 }

4188 void Assembler::evshufi64x2(XMMRegister dst, XMMRegister nds, XMMRegister src, int imm8, int vector_len) {
4189   assert(VM_Version::supports_evex(), &quot;requires EVEX support&quot;);
4190   assert(vector_len == Assembler::AVX_256bit || vector_len == Assembler::AVX_512bit, &quot;&quot;);
4191   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
4192   attributes.set_is_evex_instruction();
4193   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
4194   emit_int8(0x43);
4195   emit_int8((unsigned char)(0xC0 | encode));
4196   emit_int8(imm8 &amp; 0xFF);
4197 }
4198 
4199 void Assembler::psrldq(XMMRegister dst, int shift) {
4200   // Shift left 128 bit value in dst XMMRegister by shift number of bytes.
4201   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4202   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4203   int encode = simd_prefix_and_encode(xmm3, dst, dst, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
4204   emit_int8(0x73);
4205   emit_int8((unsigned char)(0xC0 | encode));
4206   emit_int8(shift);
4207 }
</pre>
<hr />
<pre>
4602 void Assembler::shll(Register dst) {
4603   int encode = prefix_and_encode(dst-&gt;encoding());
4604   emit_int8((unsigned char)0xD3);
4605   emit_int8((unsigned char)(0xE0 | encode));
4606 }
4607 
4608 void Assembler::shrl(Register dst, int imm8) {
4609   assert(isShiftCount(imm8), &quot;illegal shift count&quot;);
4610   int encode = prefix_and_encode(dst-&gt;encoding());
4611   emit_int8((unsigned char)0xC1);
4612   emit_int8((unsigned char)(0xE8 | encode));
4613   emit_int8(imm8);
4614 }
4615 
4616 void Assembler::shrl(Register dst) {
4617   int encode = prefix_and_encode(dst-&gt;encoding());
4618   emit_int8((unsigned char)0xD3);
4619   emit_int8((unsigned char)(0xE8 | encode));
4620 }
4621 






























4622 // copies a single word from [esi] to [edi]
4623 void Assembler::smovl() {
4624   emit_int8((unsigned char)0xA5);
4625 }
4626 



















4627 void Assembler::sqrtsd(XMMRegister dst, XMMRegister src) {
4628   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4629   InstructionAttr attributes(AVX_128bit, /* rex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
4630   attributes.set_rex_vex_w_reverted();
4631   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_F2, VEX_OPCODE_0F, &amp;attributes);
4632   emit_int8(0x51);
4633   emit_int8((unsigned char)(0xC0 | encode));
4634 }
4635 
4636 void Assembler::sqrtsd(XMMRegister dst, Address src) {
4637   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4638   InstructionMark im(this);
4639   InstructionAttr attributes(AVX_128bit, /* rex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
4640   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_64bit);
4641   attributes.set_rex_vex_w_reverted();
4642   simd_prefix(dst, dst, src, VEX_SIMD_F2, VEX_OPCODE_0F, &amp;attributes);
4643   emit_int8(0x51);
4644   emit_operand(dst, src);
4645 }
4646 
</pre>
<hr />
<pre>
5404   assert(VM_Version::supports_avx(), &quot;&quot;);
5405   InstructionMark im(this);
5406   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
5407   attributes.set_address_attributes(/* tuple_type */ EVEX_FV, /* input_size_in_bits */ EVEX_64bit);
5408   attributes.set_rex_vex_w_reverted();
5409   vex_prefix(src, nds-&gt;encoding(), dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
5410   emit_int8(0x5E);
5411   emit_operand(dst, src);
5412 }
5413 
5414 void Assembler::vdivps(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {
5415   assert(VM_Version::supports_avx(), &quot;&quot;);
5416   InstructionMark im(this);
5417   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
5418   attributes.set_address_attributes(/* tuple_type */ EVEX_FV, /* input_size_in_bits */ EVEX_32bit);
5419   vex_prefix(src, nds-&gt;encoding(), dst-&gt;encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F, &amp;attributes);
5420   emit_int8(0x5E);
5421   emit_operand(dst, src);
5422 }
5423 











































5424 void Assembler::vsqrtpd(XMMRegister dst, XMMRegister src, int vector_len) {
5425   assert(VM_Version::supports_avx(), &quot;&quot;);
5426   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
5427   attributes.set_rex_vex_w_reverted();
5428   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
5429   emit_int8(0x51);
5430   emit_int8((unsigned char)(0xC0 | encode));
5431 }
5432 
5433 void Assembler::vsqrtpd(XMMRegister dst, Address src, int vector_len) {
5434   assert(VM_Version::supports_avx(), &quot;&quot;);
5435   InstructionMark im(this);
5436   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
5437   attributes.set_address_attributes(/* tuple_type */ EVEX_FV, /* input_size_in_bits */ EVEX_64bit);
5438   attributes.set_rex_vex_w_reverted();
5439   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
5440   emit_int8(0x51);
5441   emit_operand(dst, src);
5442 }
5443 
</pre>
<hr />
<pre>
6260   emit_int8((unsigned char)(0xC0 | encode));
6261   emit_int8(shift &amp; 0xFF);
6262 }
6263 
6264 void Assembler::vpsraw(XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len) {
6265   assert(UseAVX &gt; 0, &quot;requires some form of AVX&quot;);
6266   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
6267   int encode = vex_prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding(), shift-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6268   emit_int8((unsigned char)0xE1);
6269   emit_int8((unsigned char)(0xC0 | encode));
6270 }
6271 
6272 void Assembler::vpsrad(XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len) {
6273   assert(UseAVX &gt; 0, &quot;requires some form of AVX&quot;);
6274   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6275   int encode = vex_prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding(), shift-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6276   emit_int8((unsigned char)0xE2);
6277   emit_int8((unsigned char)(0xC0 | encode));
6278 }
6279 




















6280 
6281 // logical operations packed integers
6282 void Assembler::pand(XMMRegister dst, XMMRegister src) {
6283   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
6284   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6285   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6286   emit_int8((unsigned char)0xDB);
6287   emit_int8((unsigned char)(0xC0 | encode));
6288 }
6289 
6290 void Assembler::vpand(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
6291   assert(UseAVX &gt; 0, &quot;requires some form of AVX&quot;);
6292   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6293   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6294   emit_int8((unsigned char)0xDB);
6295   emit_int8((unsigned char)(0xC0 | encode));
6296 }
6297 
6298 void Assembler::vpand(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {
6299   assert(UseAVX &gt; 0, &quot;requires some form of AVX&quot;);
6300   InstructionMark im(this);
6301   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6302   attributes.set_address_attributes(/* tuple_type */ EVEX_FV, /* input_size_in_bits */ EVEX_32bit);
6303   vex_prefix(src, nds-&gt;encoding(), dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6304   emit_int8((unsigned char)0xDB);
6305   emit_operand(dst, src);
6306 }
6307 
6308 void Assembler::vpandq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
6309   assert(VM_Version::supports_evex(), &quot;&quot;);
6310   InstructionAttr attributes(vector_len, /* vex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6311   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6312   emit_int8((unsigned char)0xDB);
6313   emit_int8((unsigned char)(0xC0 | encode));
6314 }
6315 

















6316 
6317 void Assembler::pandn(XMMRegister dst, XMMRegister src) {
6318   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
6319   InstructionAttr attributes(AVX_128bit, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6320   attributes.set_rex_vex_w_reverted();
6321   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6322   emit_int8((unsigned char)0xDF);
6323   emit_int8((unsigned char)(0xC0 | encode));
6324 }
6325 
6326 void Assembler::vpandn(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
6327   assert(UseAVX &gt; 0, &quot;requires some form of AVX&quot;);
6328   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6329   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6330   emit_int8((unsigned char)0xDF);
6331   emit_int8((unsigned char)(0xC0 | encode));
6332 }
6333 
6334 
6335 void Assembler::por(XMMRegister dst, XMMRegister src) {
</pre>
<hr />
<pre>
6895   emit_int8((unsigned char)(0xC0 | encode));
6896 }
6897 
6898 void Assembler::evbroadcasti64x2(XMMRegister dst, Address src, int vector_len) {
6899   assert(vector_len != Assembler::AVX_128bit, &quot;&quot;);
6900   assert(VM_Version::supports_avx512dq(), &quot;&quot;);
6901   assert(dst != xnoreg, &quot;sanity&quot;);
6902   InstructionMark im(this);
6903   InstructionAttr attributes(vector_len, /* vex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6904   attributes.set_rex_vex_w_reverted();
6905   attributes.set_address_attributes(/* tuple_type */ EVEX_T2, /* input_size_in_bits */ EVEX_64bit);
6906   // swap src&lt;-&gt;dst for encoding
6907   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
6908   emit_int8(0x5A);
6909   emit_operand(dst, src);
6910 }
6911 
6912 // scalar single/double precision replicate
6913 
6914 // duplicate single precision data from src into programmed locations in dest : requires AVX512VL
<span class="line-modified">6915 void Assembler::vpbroadcastss(XMMRegister dst, XMMRegister src, int vector_len) {</span>
6916   assert(VM_Version::supports_avx(), &quot;&quot;);
6917   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6918   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
6919   emit_int8(0x18);
6920   emit_int8((unsigned char)(0xC0 | encode));
6921 }
6922 
<span class="line-modified">6923 void Assembler::vpbroadcastss(XMMRegister dst, Address src, int vector_len) {</span>
6924   assert(VM_Version::supports_avx(), &quot;&quot;);
6925   assert(dst != xnoreg, &quot;sanity&quot;);
6926   InstructionMark im(this);
6927   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6928   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_32bit);
6929   // swap src&lt;-&gt;dst for encoding
6930   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
6931   emit_int8(0x18);
6932   emit_operand(dst, src);
6933 }
6934 
6935 // duplicate double precision data from src into programmed locations in dest : requires AVX512VL
<span class="line-modified">6936 void Assembler::vpbroadcastsd(XMMRegister dst, XMMRegister src, int vector_len) {</span>
6937   assert(VM_Version::supports_avx(), &quot;&quot;);
6938   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6939   attributes.set_rex_vex_w_reverted();
6940   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
6941   emit_int8(0x19);
6942   emit_int8((unsigned char)(0xC0 | encode));
6943 }
6944 
<span class="line-modified">6945 void Assembler::vpbroadcastsd(XMMRegister dst, Address src, int vector_len) {</span>
6946   assert(VM_Version::supports_avx(), &quot;&quot;);
6947   assert(dst != xnoreg, &quot;sanity&quot;);
6948   InstructionMark im(this);
6949   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6950   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_64bit);
6951   attributes.set_rex_vex_w_reverted();
6952   // swap src&lt;-&gt;dst for encoding
6953   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
6954   emit_int8(0x19);
6955   emit_operand(dst, src);
6956 }
6957 
6958 
6959 // gpr source broadcast forms
6960 
6961 // duplicate 1-byte integer data from src into programmed locations in dest : requires AVX512BW and AVX512VL
6962 void Assembler::evpbroadcastb(XMMRegister dst, Register src, int vector_len) {
6963   assert(VM_Version::supports_avx512bw(), &quot;&quot;);
6964   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
6965   attributes.set_is_evex_instruction();
</pre>
<hr />
<pre>
6980 
6981 // duplicate 4-byte integer data from src into programmed locations in dest : requires AVX512VL
6982 void Assembler::evpbroadcastd(XMMRegister dst, Register src, int vector_len) {
6983   assert(VM_Version::supports_evex(), &quot;&quot;);
6984   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6985   attributes.set_is_evex_instruction();
6986   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
6987   emit_int8(0x7C);
6988   emit_int8((unsigned char)(0xC0 | encode));
6989 }
6990 
6991 // duplicate 8-byte integer data from src into programmed locations in dest : requires AVX512VL
6992 void Assembler::evpbroadcastq(XMMRegister dst, Register src, int vector_len) {
6993   assert(VM_Version::supports_evex(), &quot;&quot;);
6994   InstructionAttr attributes(vector_len, /* vex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6995   attributes.set_is_evex_instruction();
6996   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
6997   emit_int8(0x7C);
6998   emit_int8((unsigned char)(0xC0 | encode));
6999 }
<span class="line-removed">7000 </span>
7001 void Assembler::evpgatherdd(XMMRegister dst, KRegister mask, Address src, int vector_len) {
7002   assert(VM_Version::supports_evex(), &quot;&quot;);
7003   assert(dst != xnoreg, &quot;sanity&quot;);
7004   InstructionMark im(this);
7005   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ false, /* uses_vl */ true);
7006   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_64bit);
7007   attributes.reset_is_clear_context();
7008   attributes.set_embedded_opmask_register_specifier(mask);
7009   attributes.set_is_evex_instruction();
7010   // swap src&lt;-&gt;dst for encoding
7011   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7012   emit_int8((unsigned char)0x90);
7013   emit_operand(dst, src);
7014 }
<span class="line-removed">7015 </span>
7016 // Carry-Less Multiplication Quadword
7017 void Assembler::pclmulqdq(XMMRegister dst, XMMRegister src, int mask) {
7018   assert(VM_Version::supports_clmul(), &quot;&quot;);
7019   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ true);
7020   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
7021   emit_int8(0x44);
7022   emit_int8((unsigned char)(0xC0 | encode));
7023   emit_int8((unsigned char)mask);
7024 }
7025 
7026 // Carry-Less Multiplication Quadword
7027 void Assembler::vpclmulqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int mask) {
7028   assert(VM_Version::supports_avx() &amp;&amp; VM_Version::supports_clmul(), &quot;&quot;);
7029   InstructionAttr attributes(AVX_128bit, /* vex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ true);
7030   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
7031   emit_int8(0x44);
7032   emit_int8((unsigned char)(0xC0 | encode));
7033   emit_int8((unsigned char)mask);
7034 }
7035 
7036 void Assembler::evpclmulqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int mask, int vector_len) {
<span class="line-modified">7037   assert(VM_Version::supports_vpclmulqdq(), &quot;Requires vector carryless multiplication support&quot;);</span>
7038   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7039   attributes.set_is_evex_instruction();
7040   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
7041   emit_int8(0x44);
7042   emit_int8((unsigned char)(0xC0 | encode));
7043   emit_int8((unsigned char)mask);
7044 }
7045 
7046 void Assembler::vzeroupper() {
7047   if (VM_Version::supports_vzeroupper()) {
7048     InstructionAttr attributes(AVX_128bit, /* vex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
7049     (void)vex_prefix_and_encode(0, 0, 0, VEX_SIMD_NONE, VEX_OPCODE_0F, &amp;attributes);
7050     emit_int8(0x77);
7051   }
7052 }
7053 
7054 #ifndef _LP64
7055 // 32bit only pieces of the assembler
7056 
7057 void Assembler::cmp_literal32(Register src1, int32_t imm32, RelocationHolder const&amp; rspec) {
</pre>
<hr />
<pre>
7068   emit_int8((unsigned char)0x81);
7069   emit_operand(rdi, src1);
7070   emit_data(imm32, rspec, 0);
7071 }
7072 
7073 // The 64-bit (32bit platform) cmpxchg compares the value at adr with the contents of rdx:rax,
7074 // and stores rcx:rbx into adr if so; otherwise, the value at adr is loaded
7075 // into rdx:rax.  The ZF is set if the compared values were equal, and cleared otherwise.
7076 void Assembler::cmpxchg8(Address adr) {
7077   InstructionMark im(this);
7078   emit_int8(0x0F);
7079   emit_int8((unsigned char)0xC7);
7080   emit_operand(rcx, adr);
7081 }
7082 
7083 void Assembler::decl(Register dst) {
7084   // Don&#39;t use it directly. Use MacroAssembler::decrementl() instead.
7085  emit_int8(0x48 | dst-&gt;encoding());
7086 }
7087 
<span class="line-modified">7088 #endif // _LP64</span>
<span class="line-removed">7089 </span>
<span class="line-removed">7090 // 64bit typically doesn&#39;t use the x87 but needs to for the trig funcs</span>
7091 
7092 void Assembler::fabs() {
7093   emit_int8((unsigned char)0xD9);
7094   emit_int8((unsigned char)0xE1);
7095 }
7096 
7097 void Assembler::fadd(int i) {
7098   emit_farith(0xD8, 0xC0, i);
7099 }
7100 
7101 void Assembler::fadd_d(Address src) {
7102   InstructionMark im(this);
7103   emit_int8((unsigned char)0xDC);
7104   emit_operand32(rax, src);
7105 }
7106 
7107 void Assembler::fadd_s(Address src) {
7108   InstructionMark im(this);
7109   emit_int8((unsigned char)0xD8);
7110   emit_operand32(rax, src);
</pre>
<hr />
<pre>
7505 
7506 void Assembler::fyl2x() {
7507   emit_int8((unsigned char)0xD9);
7508   emit_int8((unsigned char)0xF1);
7509 }
7510 
7511 void Assembler::frndint() {
7512   emit_int8((unsigned char)0xD9);
7513   emit_int8((unsigned char)0xFC);
7514 }
7515 
7516 void Assembler::f2xm1() {
7517   emit_int8((unsigned char)0xD9);
7518   emit_int8((unsigned char)0xF0);
7519 }
7520 
7521 void Assembler::fldl2e() {
7522   emit_int8((unsigned char)0xD9);
7523   emit_int8((unsigned char)0xEA);
7524 }

7525 
7526 // SSE SIMD prefix byte values corresponding to VexSimdPrefix encoding.
7527 static int simd_pre[4] = { 0, 0x66, 0xF3, 0xF2 };
7528 // SSE opcode second byte values (first is 0x0F) corresponding to VexOpcode encoding.
7529 static int simd_opc[4] = { 0,    0, 0x38, 0x3A };
7530 
7531 // Generate SSE legacy REX prefix and SIMD opcode based on VEX encoding.
7532 void Assembler::rex_prefix(Address adr, XMMRegister xreg, VexSimdPrefix pre, VexOpcode opc, bool rex_w) {
7533   if (pre &gt; 0) {
7534     emit_int8(simd_pre[pre]);
7535   }
7536   if (rex_w) {
7537     prefixq(adr, xreg);
7538   } else {
7539     prefix(adr, xreg);
7540   }
7541   if (opc &gt; 0) {
7542     emit_int8(0x0F);
7543     int opc2 = simd_opc[opc];
7544     if (opc2 &gt; 0) {
</pre>
<hr />
<pre>
7894 void Assembler::popa() { // 32bit
7895   emit_int8(0x61);
7896 }
7897 
7898 void Assembler::push_literal32(int32_t imm32, RelocationHolder const&amp; rspec) {
7899   InstructionMark im(this);
7900   emit_int8(0x68);
7901   emit_data(imm32, rspec, 0);
7902 }
7903 
7904 void Assembler::pusha() { // 32bit
7905   emit_int8(0x60);
7906 }
7907 
7908 void Assembler::set_byte_if_not_zero(Register dst) {
7909   emit_int8(0x0F);
7910   emit_int8((unsigned char)0x95);
7911   emit_int8((unsigned char)(0xE0 | dst-&gt;encoding()));
7912 }
7913 
<span class="line-removed">7914 void Assembler::shldl(Register dst, Register src) {</span>
<span class="line-removed">7915   emit_int8(0x0F);</span>
<span class="line-removed">7916   emit_int8((unsigned char)0xA5);</span>
<span class="line-removed">7917   emit_int8((unsigned char)(0xC0 | src-&gt;encoding() &lt;&lt; 3 | dst-&gt;encoding()));</span>
<span class="line-removed">7918 }</span>
<span class="line-removed">7919 </span>
<span class="line-removed">7920 // 0F A4 / r ib</span>
<span class="line-removed">7921 void Assembler::shldl(Register dst, Register src, int8_t imm8) {</span>
<span class="line-removed">7922   emit_int8(0x0F);</span>
<span class="line-removed">7923   emit_int8((unsigned char)0xA4);</span>
<span class="line-removed">7924   emit_int8((unsigned char)(0xC0 | src-&gt;encoding() &lt;&lt; 3 | dst-&gt;encoding()));</span>
<span class="line-removed">7925   emit_int8(imm8);</span>
<span class="line-removed">7926 }</span>
<span class="line-removed">7927 </span>
<span class="line-removed">7928 void Assembler::shrdl(Register dst, Register src) {</span>
<span class="line-removed">7929   emit_int8(0x0F);</span>
<span class="line-removed">7930   emit_int8((unsigned char)0xAD);</span>
<span class="line-removed">7931   emit_int8((unsigned char)(0xC0 | src-&gt;encoding() &lt;&lt; 3 | dst-&gt;encoding()));</span>
<span class="line-removed">7932 }</span>
<span class="line-removed">7933 </span>
7934 #else // LP64
7935 
7936 void Assembler::set_byte_if_not_zero(Register dst) {
7937   int enc = prefix_and_encode(dst-&gt;encoding(), true);
7938   emit_int8(0x0F);
7939   emit_int8((unsigned char)0x95);
7940   emit_int8((unsigned char)(0xE0 | enc));
7941 }
7942 
7943 // 64bit only pieces of the assembler
7944 // This should only be used by 64bit instructions that can use rip-relative
7945 // it cannot be used by instructions that want an immediate value.
7946 
7947 bool Assembler::reachable(AddressLiteral adr) {
7948   int64_t disp;
7949   // None will force a 64bit literal to the code stream. Likely a placeholder
7950   // for something that will be patched later and we need to certain it will
7951   // always be reachable.
7952   if (adr.reloc() == relocInfo::none) {
7953     return false;
</pre>
<hr />
<pre>
8470   int encode = vex_prefix_and_encode(rcx-&gt;encoding(), dst-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &amp;attributes);
8471   emit_int8((unsigned char)0xF3);
8472   emit_int8((unsigned char)(0xC0 | encode));
8473 }
8474 
8475 void Assembler::blsrq(Register dst, Address src) {
8476   assert(VM_Version::supports_bmi1(), &quot;bit manipulation instructions not supported&quot;);
8477   InstructionMark im(this);
8478   InstructionAttr attributes(AVX_128bit, /* vex_w */ true, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
8479   vex_prefix(src, dst-&gt;encoding(), rcx-&gt;encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &amp;attributes);
8480   emit_int8((unsigned char)0xF3);
8481   emit_operand(rcx, src);
8482 }
8483 
8484 void Assembler::cdqq() {
8485   prefix(REX_W);
8486   emit_int8((unsigned char)0x99);
8487 }
8488 
8489 void Assembler::clflush(Address adr) {















8490   prefix(adr);

8491   emit_int8(0x0F);
8492   emit_int8((unsigned char)0xAE);

8493   emit_operand(rdi, adr);
8494 }
8495 
















8496 void Assembler::cmovq(Condition cc, Register dst, Register src) {
8497   int encode = prefixq_and_encode(dst-&gt;encoding(), src-&gt;encoding());
8498   emit_int8(0x0F);
8499   emit_int8(0x40 | cc);
8500   emit_int8((unsigned char)(0xC0 | encode));
8501 }
8502 
8503 void Assembler::cmovq(Condition cc, Register dst, Address src) {
8504   InstructionMark im(this);
8505   prefixq(src, dst);
8506   emit_int8(0x0F);
8507   emit_int8(0x40 | cc);
8508   emit_operand(dst, src);
8509 }
8510 
8511 void Assembler::cmpq(Address dst, int32_t imm32) {
8512   InstructionMark im(this);
8513   prefixq(dst);
8514   emit_int8((unsigned char)0x81);
8515   emit_operand(rdi, dst, 4);
</pre>
<hr />
<pre>
8559 void Assembler::cvtsi2sdq(XMMRegister dst, Address src) {
8560   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
8561   InstructionMark im(this);
8562   InstructionAttr attributes(AVX_128bit, /* rex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
8563   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_64bit);
8564   simd_prefix(dst, dst, src, VEX_SIMD_F2, VEX_OPCODE_0F, &amp;attributes);
8565   emit_int8(0x2A);
8566   emit_operand(dst, src);
8567 }
8568 
8569 void Assembler::cvtsi2ssq(XMMRegister dst, Address src) {
8570   NOT_LP64(assert(VM_Version::supports_sse(), &quot;&quot;));
8571   InstructionMark im(this);
8572   InstructionAttr attributes(AVX_128bit, /* rex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
8573   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_64bit);
8574   simd_prefix(dst, dst, src, VEX_SIMD_F3, VEX_OPCODE_0F, &amp;attributes);
8575   emit_int8(0x2A);
8576   emit_operand(dst, src);
8577 }
8578 












8579 void Assembler::cvttsd2siq(Register dst, XMMRegister src) {
8580   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
8581   InstructionAttr attributes(AVX_128bit, /* rex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
8582   int encode = simd_prefix_and_encode(as_XMMRegister(dst-&gt;encoding()), xnoreg, src, VEX_SIMD_F2, VEX_OPCODE_0F, &amp;attributes);
8583   emit_int8(0x2C);
8584   emit_int8((unsigned char)(0xC0 | encode));
8585 }
8586 
8587 void Assembler::cvttss2siq(Register dst, XMMRegister src) {
8588   NOT_LP64(assert(VM_Version::supports_sse(), &quot;&quot;));
8589   InstructionAttr attributes(AVX_128bit, /* rex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
8590   int encode = simd_prefix_and_encode(as_XMMRegister(dst-&gt;encoding()), xnoreg, src, VEX_SIMD_F3, VEX_OPCODE_0F, &amp;attributes);
8591   emit_int8(0x2C);
8592   emit_int8((unsigned char)(0xC0 | encode));
8593 }
8594 
8595 void Assembler::decl(Register dst) {
8596   // Don&#39;t use it directly. Use MacroAssembler::decrementl() instead.
8597   // Use two-byte form (one-byte form is a REX prefix in 64-bit mode)
8598   int encode = prefix_and_encode(dst-&gt;encoding());
</pre>
<hr />
<pre>
8915 void Assembler::mulxq(Register dst1, Register dst2, Register src) {
8916   assert(VM_Version::supports_bmi2(), &quot;bit manipulation instructions not supported&quot;);
8917   InstructionAttr attributes(AVX_128bit, /* vex_w */ true, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
8918   int encode = vex_prefix_and_encode(dst1-&gt;encoding(), dst2-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &amp;attributes);
8919   emit_int8((unsigned char)0xF6);
8920   emit_int8((unsigned char)(0xC0 | encode));
8921 }
8922 
8923 void Assembler::negq(Register dst) {
8924   int encode = prefixq_and_encode(dst-&gt;encoding());
8925   emit_int8((unsigned char)0xF7);
8926   emit_int8((unsigned char)(0xD8 | encode));
8927 }
8928 
8929 void Assembler::notq(Register dst) {
8930   int encode = prefixq_and_encode(dst-&gt;encoding());
8931   emit_int8((unsigned char)0xF7);
8932   emit_int8((unsigned char)(0xD0 | encode));
8933 }
8934 




















8935 void Assembler::orq(Address dst, int32_t imm32) {
8936   InstructionMark im(this);
8937   prefixq(dst);
8938   emit_int8((unsigned char)0x81);
8939   emit_operand(rcx, dst, 4);
8940   emit_int32(imm32);
8941 }
8942 
8943 void Assembler::orq(Register dst, int32_t imm32) {
8944   (void) prefixq_and_encode(dst-&gt;encoding());
8945   emit_arith(0x81, 0xC8, dst, imm32);
8946 }
8947 
8948 void Assembler::orq(Register dst, Address src) {
8949   InstructionMark im(this);
8950   prefixq(src, dst);
8951   emit_int8(0x0B);
8952   emit_operand(dst, src);
8953 }
8954 
</pre>
</td>
<td>
<hr />
<pre>
 772       break;
 773 
 774     case 0x70: // pshufd r, r/a, #8
 775       debug_only(has_disp32 = true); // has both kinds of operands!
 776     case 0x73: // psrldq r, #8
 777       tail_size = 1;
 778       break;
 779 
 780     case 0x12: // movlps
 781     case 0x28: // movaps
 782     case 0x2E: // ucomiss
 783     case 0x2F: // comiss
 784     case 0x54: // andps
 785     case 0x55: // andnps
 786     case 0x56: // orps
 787     case 0x57: // xorps
 788     case 0x58: // addpd
 789     case 0x59: // mulpd
 790     case 0x6E: // movd
 791     case 0x7E: // movd
<span class="line-added"> 792     case 0x6F: // movdq</span>
<span class="line-added"> 793     case 0x7F: // movdq</span>
 794     case 0xAE: // ldmxcsr, stmxcsr, fxrstor, fxsave, clflush
 795     case 0xFE: // paddd
 796       debug_only(has_disp32 = true);
 797       break;
 798 
 799     case 0xAD: // shrd r, a, %cl
 800     case 0xAF: // imul r, a
 801     case 0xBE: // movsbl r, a (movsxb)
 802     case 0xBF: // movswl r, a (movsxw)
 803     case 0xB6: // movzbl r, a (movzxb)
 804     case 0xB7: // movzwl r, a (movzxw)
 805     case REP16(0x40): // cmovl cc, r, a
 806     case 0xB0: // cmpxchgb
 807     case 0xB1: // cmpxchg
 808     case 0xC1: // xaddl
 809     case 0xC7: // cmpxchg8
 810     case REP16(0x90): // setcc a
 811       debug_only(has_disp32 = true);
 812       // fall out of the switch to decode the address
 813       break;
</pre>
<hr />
<pre>
1363   emit_int8((unsigned char)(0xC0 | encode));
1364 }
1365 
1366 void Assembler::aesenc(XMMRegister dst, Address src) {
1367   assert(VM_Version::supports_aes(), &quot;&quot;);
1368   InstructionMark im(this);
1369   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1370   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1371   emit_int8((unsigned char)0xDC);
1372   emit_operand(dst, src);
1373 }
1374 
1375 void Assembler::aesenc(XMMRegister dst, XMMRegister src) {
1376   assert(VM_Version::supports_aes(), &quot;&quot;);
1377   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1378   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1379   emit_int8((unsigned char)0xDC);
1380   emit_int8(0xC0 | encode);
1381 }
1382 
<span class="line-added">1383 void Assembler::vaesenc(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {</span>
<span class="line-added">1384   assert(VM_Version::supports_vaes(), &quot;requires vaes support/enabling&quot;);</span>
<span class="line-added">1385   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">1386   attributes.set_is_evex_instruction();</span>
<span class="line-added">1387   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);</span>
<span class="line-added">1388   emit_int8((unsigned char)0xDC);</span>
<span class="line-added">1389   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">1390 }</span>
<span class="line-added">1391 </span>
1392 void Assembler::aesenclast(XMMRegister dst, Address src) {
1393   assert(VM_Version::supports_aes(), &quot;&quot;);
1394   InstructionMark im(this);
1395   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1396   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1397   emit_int8((unsigned char)0xDD);
1398   emit_operand(dst, src);
1399 }
1400 
1401 void Assembler::aesenclast(XMMRegister dst, XMMRegister src) {
1402   assert(VM_Version::supports_aes(), &quot;&quot;);
1403   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1404   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1405   emit_int8((unsigned char)0xDD);
1406   emit_int8((unsigned char)(0xC0 | encode));
1407 }
1408 
<span class="line-added">1409 void Assembler::vaesenclast(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {</span>
<span class="line-added">1410   assert(VM_Version::supports_vaes(), &quot;requires vaes support/enabling&quot;);</span>
<span class="line-added">1411   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">1412   attributes.set_is_evex_instruction();</span>
<span class="line-added">1413   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);</span>
<span class="line-added">1414   emit_int8((unsigned char)0xDD);</span>
<span class="line-added">1415   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">1416 }</span>
<span class="line-added">1417 </span>
1418 void Assembler::andl(Address dst, int32_t imm32) {
1419   InstructionMark im(this);
1420   prefix(dst);
1421   emit_int8((unsigned char)0x81);
1422   emit_operand(rsp, dst, 4);
1423   emit_int32(imm32);
1424 }
1425 
1426 void Assembler::andl(Register dst, int32_t imm32) {
1427   prefix(dst);
1428   emit_arith(0x81, 0xE0, dst, imm32);
1429 }
1430 
1431 void Assembler::andl(Register dst, Address src) {
1432   InstructionMark im(this);
1433   prefix(src, dst);
1434   emit_int8(0x23);
1435   emit_operand(dst, src);
1436 }
1437 
</pre>
<hr />
<pre>
1897   emit_int8((unsigned char)(0xC0 | encode));
1898 }
1899 
1900 void Assembler::cvttss2sil(Register dst, XMMRegister src) {
1901   NOT_LP64(assert(VM_Version::supports_sse(), &quot;&quot;));
1902   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
1903   int encode = simd_prefix_and_encode(as_XMMRegister(dst-&gt;encoding()), xnoreg, src, VEX_SIMD_F3, VEX_OPCODE_0F, &amp;attributes);
1904   emit_int8(0x2C);
1905   emit_int8((unsigned char)(0xC0 | encode));
1906 }
1907 
1908 void Assembler::cvttpd2dq(XMMRegister dst, XMMRegister src) {
1909   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
1910   int vector_len = VM_Version::supports_avx512novl() ? AVX_512bit : AVX_128bit;
1911   InstructionAttr attributes(vector_len, /* rex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
1912   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
1913   emit_int8((unsigned char)0xE6);
1914   emit_int8((unsigned char)(0xC0 | encode));
1915 }
1916 
<span class="line-added">1917 void Assembler::pabsb(XMMRegister dst, XMMRegister src) {</span>
<span class="line-added">1918   assert(VM_Version::supports_ssse3(), &quot;&quot;);</span>
<span class="line-added">1919   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">1920   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);</span>
<span class="line-added">1921   emit_int8(0x1C);</span>
<span class="line-added">1922   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">1923 }</span>
<span class="line-added">1924 </span>
<span class="line-added">1925 void Assembler::pabsw(XMMRegister dst, XMMRegister src) {</span>
<span class="line-added">1926   assert(VM_Version::supports_ssse3(), &quot;&quot;);</span>
<span class="line-added">1927   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">1928   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);</span>
<span class="line-added">1929   emit_int8(0x1D);</span>
<span class="line-added">1930   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">1931 }</span>
<span class="line-added">1932 </span>
<span class="line-added">1933 void Assembler::pabsd(XMMRegister dst, XMMRegister src) {</span>
<span class="line-added">1934   assert(VM_Version::supports_ssse3(), &quot;&quot;);</span>
<span class="line-added">1935   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">1936   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);</span>
<span class="line-added">1937   emit_int8(0x1E);</span>
<span class="line-added">1938   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">1939 }</span>
<span class="line-added">1940 </span>
<span class="line-added">1941 void Assembler::vpabsb(XMMRegister dst, XMMRegister src, int vector_len) {</span>
<span class="line-added">1942   assert(vector_len == AVX_128bit? VM_Version::supports_avx() :</span>
<span class="line-added">1943   vector_len == AVX_256bit? VM_Version::supports_avx2() :</span>
<span class="line-added">1944   vector_len == AVX_512bit? VM_Version::supports_avx512bw() : 0, &quot;&quot;);</span>
<span class="line-added">1945   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">1946   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);</span>
<span class="line-added">1947   emit_int8((unsigned char)0x1C);</span>
<span class="line-added">1948   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">1949 }</span>
<span class="line-added">1950 </span>
<span class="line-added">1951 void Assembler::vpabsw(XMMRegister dst, XMMRegister src, int vector_len) {</span>
<span class="line-added">1952   assert(vector_len == AVX_128bit? VM_Version::supports_avx() :</span>
<span class="line-added">1953   vector_len == AVX_256bit? VM_Version::supports_avx2() :</span>
<span class="line-added">1954   vector_len == AVX_512bit? VM_Version::supports_avx512bw() : 0, &quot;&quot;);</span>
<span class="line-added">1955   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">1956   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);</span>
<span class="line-added">1957   emit_int8((unsigned char)0x1D);</span>
<span class="line-added">1958   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">1959 }</span>
<span class="line-added">1960 </span>
<span class="line-added">1961 void Assembler::vpabsd(XMMRegister dst, XMMRegister src, int vector_len) {</span>
<span class="line-added">1962   assert(vector_len == AVX_128bit? VM_Version::supports_avx() :</span>
<span class="line-added">1963   vector_len == AVX_256bit? VM_Version::supports_avx2() :</span>
<span class="line-added">1964   vector_len == AVX_512bit? VM_Version::supports_evex() : 0, &quot;&quot;);</span>
<span class="line-added">1965   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">1966   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);</span>
<span class="line-added">1967   emit_int8((unsigned char)0x1E);</span>
<span class="line-added">1968   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">1969 }</span>
<span class="line-added">1970 </span>
<span class="line-added">1971 void Assembler::evpabsq(XMMRegister dst, XMMRegister src, int vector_len) {</span>
<span class="line-added">1972   assert(UseAVX &gt; 2, &quot;&quot;);</span>
<span class="line-added">1973   InstructionAttr attributes(vector_len, /* rex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">1974   attributes.set_is_evex_instruction();</span>
<span class="line-added">1975   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);</span>
<span class="line-added">1976   emit_int8((unsigned char)0x1F);</span>
<span class="line-added">1977   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">1978 }</span>
<span class="line-added">1979 </span>
1980 void Assembler::decl(Address dst) {
1981   // Don&#39;t use it directly. Use MacroAssembler::decrement() instead.
1982   InstructionMark im(this);
1983   prefix(dst);
1984   emit_int8((unsigned char)0xFF);
1985   emit_operand(rcx, dst);
1986 }
1987 
1988 void Assembler::divsd(XMMRegister dst, Address src) {
1989   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
1990   InstructionMark im(this);
1991   InstructionAttr attributes(AVX_128bit, /* rex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
1992   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_64bit);
1993   attributes.set_rex_vex_w_reverted();
1994   simd_prefix(dst, dst, src, VEX_SIMD_F2, VEX_OPCODE_0F, &amp;attributes);
1995   emit_int8(0x5E);
1996   emit_operand(dst, src);
1997 }
1998 
1999 void Assembler::divsd(XMMRegister dst, XMMRegister src) {
</pre>
<hr />
<pre>
2257   emit_int8((unsigned char)0xF0);
2258 }
2259 
2260 void Assembler::lzcntl(Register dst, Register src) {
2261   assert(VM_Version::supports_lzcnt(), &quot;encoding is treated as BSR&quot;);
2262   emit_int8((unsigned char)0xF3);
2263   int encode = prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding());
2264   emit_int8(0x0F);
2265   emit_int8((unsigned char)0xBD);
2266   emit_int8((unsigned char)(0xC0 | encode));
2267 }
2268 
2269 // Emit mfence instruction
2270 void Assembler::mfence() {
2271   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;unsupported&quot;);)
2272   emit_int8(0x0F);
2273   emit_int8((unsigned char)0xAE);
2274   emit_int8((unsigned char)0xF0);
2275 }
2276 
<span class="line-added">2277 // Emit sfence instruction</span>
<span class="line-added">2278 void Assembler::sfence() {</span>
<span class="line-added">2279   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;unsupported&quot;);)</span>
<span class="line-added">2280   emit_int8(0x0F);</span>
<span class="line-added">2281   emit_int8((unsigned char)0xAE);</span>
<span class="line-added">2282   emit_int8((unsigned char)0xF8);</span>
<span class="line-added">2283 }</span>
<span class="line-added">2284 </span>
2285 void Assembler::mov(Register dst, Register src) {
2286   LP64_ONLY(movq(dst, src)) NOT_LP64(movl(dst, src));
2287 }
2288 
2289 void Assembler::movapd(XMMRegister dst, XMMRegister src) {
2290   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
2291   int vector_len = VM_Version::supports_avx512novl() ? AVX_512bit : AVX_128bit;
2292   InstructionAttr attributes(vector_len, /* rex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
2293   attributes.set_rex_vex_w_reverted();
2294   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
2295   emit_int8(0x28);
2296   emit_int8((unsigned char)(0xC0 | encode));
2297 }
2298 
2299 void Assembler::movaps(XMMRegister dst, XMMRegister src) {
2300   NOT_LP64(assert(VM_Version::supports_sse(), &quot;&quot;));
2301   int vector_len = VM_Version::supports_avx512novl() ? AVX_512bit : AVX_128bit;
2302   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
2303   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_NONE, VEX_OPCODE_0F, &amp;attributes);
2304   emit_int8(0x28);
</pre>
<hr />
<pre>
3173       case 5:
3174         addr_nop_5();
3175         break;
3176       case 4:
3177         addr_nop_4();
3178         break;
3179       case 3:
3180         // Don&#39;t use &quot;0x0F 0x1F 0x00&quot; - need patching safe padding
3181         emit_int8(0x66); // size prefix
3182       case 2:
3183         emit_int8(0x66); // size prefix
3184       case 1:
3185         emit_int8((unsigned char)0x90);
3186                          // nop
3187         break;
3188       default:
3189         assert(i == 0, &quot; &quot;);
3190     }
3191     return;
3192   }
<span class="line-modified">3193   if (UseAddressNop &amp;&amp; VM_Version::is_amd_family()) {</span>
3194     //
3195     // Using multi-bytes nops &quot;0x0F 0x1F [address]&quot; for AMD.
3196     //  1: 0x90
3197     //  2: 0x66 0x90
3198     //  3: 0x66 0x66 0x90 (don&#39;t use &quot;0x0F 0x1F 0x00&quot; - need patching safe padding)
3199     //  4: 0x0F 0x1F 0x40 0x00
3200     //  5: 0x0F 0x1F 0x44 0x00 0x00
3201     //  6: 0x66 0x0F 0x1F 0x44 0x00 0x00
3202     //  7: 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00
3203     //  8: 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00
3204     //  9: 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00
3205     // 10: 0x66 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00
3206     // 11: 0x66 0x66 0x66 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00
3207 
3208     // The rest coding is AMD specific - use consecutive address nops
3209 
3210     // 12: 0x66 0x0F 0x1F 0x44 0x00 0x00 0x66 0x0F 0x1F 0x44 0x00 0x00
3211     // 13: 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00 0x66 0x0F 0x1F 0x44 0x00 0x00
3212     // 14: 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00
3213     // 15: 0x0F 0x1F 0x84 0x00 0x00 0x00 0x00 0x00 0x0F 0x1F 0x80 0x00 0x00 0x00 0x00
</pre>
<hr />
<pre>
3490   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
3491   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
3492   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
3493   emit_int8(0x67);
3494   emit_int8((unsigned char)(0xC0 | encode));
3495 }
3496 
3497 void Assembler::vpackuswb(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
3498   assert(UseAVX &gt; 0, &quot;some form of AVX must be enabled&quot;);
3499   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
3500   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
3501   emit_int8(0x67);
3502   emit_int8((unsigned char)(0xC0 | encode));
3503 }
3504 
3505 void Assembler::vpermq(XMMRegister dst, XMMRegister src, int imm8, int vector_len) {
3506   assert(VM_Version::supports_avx2(), &quot;&quot;);
3507   InstructionAttr attributes(vector_len, /* rex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
3508   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
3509   emit_int8(0x00);
<span class="line-modified">3510   emit_int8((unsigned char)(0xC0 | encode));</span>
3511   emit_int8(imm8);
3512 }
3513 
<span class="line-added">3514 void Assembler::vpermq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {</span>
<span class="line-added">3515   assert(UseAVX &gt; 2, &quot;requires AVX512F&quot;);</span>
<span class="line-added">3516   InstructionAttr attributes(vector_len, /* rex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">3517   attributes.set_is_evex_instruction();</span>
<span class="line-added">3518   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);</span>
<span class="line-added">3519   emit_int8((unsigned char)0x36);</span>
<span class="line-added">3520   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">3521 }</span>
<span class="line-added">3522 </span>
3523 void Assembler::vperm2i128(XMMRegister dst,  XMMRegister nds, XMMRegister src, int imm8) {
3524   assert(VM_Version::supports_avx2(), &quot;&quot;);
3525   InstructionAttr attributes(AVX_256bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
3526   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
3527   emit_int8(0x46);
3528   emit_int8(0xC0 | encode);
3529   emit_int8(imm8);
3530 }
3531 
3532 void Assembler::vperm2f128(XMMRegister dst, XMMRegister nds, XMMRegister src, int imm8) {
3533   assert(VM_Version::supports_avx(), &quot;&quot;);
3534   InstructionAttr attributes(AVX_256bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
3535   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
3536   emit_int8(0x06);
3537   emit_int8(0xC0 | encode);
3538   emit_int8(imm8);
3539 }
3540 
3541 void Assembler::evpermi2q(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
3542   assert(VM_Version::supports_evex(), &quot;&quot;);
</pre>
<hr />
<pre>
3967 }
3968 
3969 void Assembler::pmovzxbw(XMMRegister dst, Address src) {
3970   assert(VM_Version::supports_sse4_1(), &quot;&quot;);
3971   InstructionMark im(this);
3972   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
3973   attributes.set_address_attributes(/* tuple_type */ EVEX_HVM, /* input_size_in_bits */ EVEX_NObit);
3974   simd_prefix(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
3975   emit_int8(0x30);
3976   emit_operand(dst, src);
3977 }
3978 
3979 void Assembler::pmovzxbw(XMMRegister dst, XMMRegister src) {
3980   assert(VM_Version::supports_sse4_1(), &quot;&quot;);
3981   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
3982   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
3983   emit_int8(0x30);
3984   emit_int8((unsigned char)(0xC0 | encode));
3985 }
3986 
<span class="line-added">3987 void Assembler::pmovsxbw(XMMRegister dst, XMMRegister src) {</span>
<span class="line-added">3988   assert(VM_Version::supports_sse4_1(), &quot;&quot;);</span>
<span class="line-added">3989   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">3990   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);</span>
<span class="line-added">3991   emit_int8(0x20);</span>
<span class="line-added">3992   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">3993 }</span>
<span class="line-added">3994 </span>
3995 void Assembler::vpmovzxbw(XMMRegister dst, Address src, int vector_len) {
3996   assert(VM_Version::supports_avx(), &quot;&quot;);
3997   InstructionMark im(this);
3998   assert(dst != xnoreg, &quot;sanity&quot;);
3999   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4000   attributes.set_address_attributes(/* tuple_type */ EVEX_HVM, /* input_size_in_bits */ EVEX_NObit);
4001   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
4002   emit_int8(0x30);
4003   emit_operand(dst, src);
4004 }
4005 
4006 void Assembler::vpmovzxbw(XMMRegister dst, XMMRegister src, int vector_len) {
4007   assert(vector_len == AVX_128bit? VM_Version::supports_avx() :
4008   vector_len == AVX_256bit? VM_Version::supports_avx2() :
4009   vector_len == AVX_512bit? VM_Version::supports_avx512bw() : 0, &quot;&quot;);
4010   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4011   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
4012   emit_int8(0x30);
4013   emit_int8((unsigned char) (0xC0 | encode));
4014 }
4015 
<span class="line-added">4016 void Assembler::vpmovsxbw(XMMRegister dst, XMMRegister src, int vector_len) {</span>
<span class="line-added">4017   assert(vector_len == AVX_128bit? VM_Version::supports_avx() :</span>
<span class="line-added">4018   vector_len == AVX_256bit? VM_Version::supports_avx2() :</span>
<span class="line-added">4019   vector_len == AVX_512bit? VM_Version::supports_avx512bw() : 0, &quot;&quot;);</span>
<span class="line-added">4020   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">4021   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);</span>
<span class="line-added">4022   emit_int8(0x20);</span>
<span class="line-added">4023   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">4024 }</span>
4025 
4026 void Assembler::evpmovzxbw(XMMRegister dst, KRegister mask, Address src, int vector_len) {
4027   assert(VM_Version::supports_avx512vlbw(), &quot;&quot;);
4028   assert(dst != xnoreg, &quot;sanity&quot;);
4029   InstructionMark im(this);
4030   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ false, /* uses_vl */ true);
4031   attributes.set_address_attributes(/* tuple_type */ EVEX_HVM, /* input_size_in_bits */ EVEX_NObit);
4032   attributes.set_embedded_opmask_register_specifier(mask);
4033   attributes.set_is_evex_instruction();
4034   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
4035   emit_int8(0x30);
4036   emit_operand(dst, src);
4037 }
4038 void Assembler::evpmovwb(Address dst, XMMRegister src, int vector_len) {
4039   assert(VM_Version::supports_avx512vlbw(), &quot;&quot;);
4040   assert(src != xnoreg, &quot;sanity&quot;);
4041   InstructionMark im(this);
4042   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
4043   attributes.set_address_attributes(/* tuple_type */ EVEX_HVM, /* input_size_in_bits */ EVEX_NObit);
4044   attributes.set_is_evex_instruction();
</pre>
<hr />
<pre>
4210   prefetch_prefix(src);
4211   emit_int8(0x0D);
4212   emit_operand(rcx, src); // 1, src
4213 }
4214 
4215 void Assembler::prefix(Prefix p) {
4216   emit_int8(p);
4217 }
4218 
4219 void Assembler::pshufb(XMMRegister dst, XMMRegister src) {
4220   assert(VM_Version::supports_ssse3(), &quot;&quot;);
4221   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4222   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
4223   emit_int8(0x00);
4224   emit_int8((unsigned char)(0xC0 | encode));
4225 }
4226 
4227 void Assembler::vpshufb(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
4228   assert(vector_len == AVX_128bit? VM_Version::supports_avx() :
4229          vector_len == AVX_256bit? VM_Version::supports_avx2() :
<span class="line-modified">4230          vector_len == AVX_512bit? VM_Version::supports_avx512bw() : 0, &quot;&quot;);</span>
4231   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4232   int encode = simd_prefix_and_encode(dst, nds, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
4233   emit_int8(0x00);
4234   emit_int8((unsigned char)(0xC0 | encode));
4235 }
4236 
4237 void Assembler::pshufb(XMMRegister dst, Address src) {
4238   assert(VM_Version::supports_ssse3(), &quot;&quot;);
4239   InstructionMark im(this);
4240   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4241   attributes.set_address_attributes(/* tuple_type */ EVEX_FVM, /* input_size_in_bits */ EVEX_NObit);
4242   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
4243   emit_int8(0x00);
4244   emit_operand(dst, src);
4245 }
4246 
4247 void Assembler::pshufd(XMMRegister dst, XMMRegister src, int mode) {
4248   assert(isByte(mode), &quot;invalid value&quot;);
4249   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4250   int vector_len = VM_Version::supports_avx512novl() ? AVX_512bit : AVX_128bit;
4251   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
4252   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
4253   emit_int8(0x70);
4254   emit_int8((unsigned char)(0xC0 | encode));
4255   emit_int8(mode &amp; 0xFF);
4256 }
4257 
4258 void Assembler::vpshufd(XMMRegister dst, XMMRegister src, int mode, int vector_len) {
4259   assert(vector_len == AVX_128bit? VM_Version::supports_avx() :
<span class="line-modified">4260          (vector_len == AVX_256bit? VM_Version::supports_avx2() :</span>
<span class="line-modified">4261          (vector_len == AVX_512bit? VM_Version::supports_evex() : 0)), &quot;&quot;);</span>
4262   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4263   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
4264   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
4265   emit_int8(0x70);
4266   emit_int8((unsigned char)(0xC0 | encode));
4267   emit_int8(mode &amp; 0xFF);
4268 }
4269 
4270 void Assembler::pshufd(XMMRegister dst, Address src, int mode) {
4271   assert(isByte(mode), &quot;invalid value&quot;);
4272   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4273   assert((UseAVX &gt; 0), &quot;SSE mode requires address alignment 16 bytes&quot;);
4274   InstructionMark im(this);
4275   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
4276   attributes.set_address_attributes(/* tuple_type */ EVEX_FV, /* input_size_in_bits */ EVEX_32bit);
4277   simd_prefix(dst, xnoreg, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
4278   emit_int8(0x70);
4279   emit_operand(dst, src);
4280   emit_int8(mode &amp; 0xFF);
4281 }
</pre>
<hr />
<pre>
4285   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4286   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4287   int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_F2, VEX_OPCODE_0F, &amp;attributes);
4288   emit_int8(0x70);
4289   emit_int8((unsigned char)(0xC0 | encode));
4290   emit_int8(mode &amp; 0xFF);
4291 }
4292 
4293 void Assembler::pshuflw(XMMRegister dst, Address src, int mode) {
4294   assert(isByte(mode), &quot;invalid value&quot;);
4295   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4296   assert((UseAVX &gt; 0), &quot;SSE mode requires address alignment 16 bytes&quot;);
4297   InstructionMark im(this);
4298   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4299   attributes.set_address_attributes(/* tuple_type */ EVEX_FVM, /* input_size_in_bits */ EVEX_NObit);
4300   simd_prefix(dst, xnoreg, src, VEX_SIMD_F2, VEX_OPCODE_0F, &amp;attributes);
4301   emit_int8(0x70);
4302   emit_operand(dst, src);
4303   emit_int8(mode &amp; 0xFF);
4304 }
<span class="line-added">4305 </span>
4306 void Assembler::evshufi64x2(XMMRegister dst, XMMRegister nds, XMMRegister src, int imm8, int vector_len) {
4307   assert(VM_Version::supports_evex(), &quot;requires EVEX support&quot;);
4308   assert(vector_len == Assembler::AVX_256bit || vector_len == Assembler::AVX_512bit, &quot;&quot;);
4309   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
4310   attributes.set_is_evex_instruction();
4311   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
4312   emit_int8(0x43);
4313   emit_int8((unsigned char)(0xC0 | encode));
4314   emit_int8(imm8 &amp; 0xFF);
4315 }
4316 
4317 void Assembler::psrldq(XMMRegister dst, int shift) {
4318   // Shift left 128 bit value in dst XMMRegister by shift number of bytes.
4319   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4320   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4321   int encode = simd_prefix_and_encode(xmm3, dst, dst, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
4322   emit_int8(0x73);
4323   emit_int8((unsigned char)(0xC0 | encode));
4324   emit_int8(shift);
4325 }
</pre>
<hr />
<pre>
4720 void Assembler::shll(Register dst) {
4721   int encode = prefix_and_encode(dst-&gt;encoding());
4722   emit_int8((unsigned char)0xD3);
4723   emit_int8((unsigned char)(0xE0 | encode));
4724 }
4725 
4726 void Assembler::shrl(Register dst, int imm8) {
4727   assert(isShiftCount(imm8), &quot;illegal shift count&quot;);
4728   int encode = prefix_and_encode(dst-&gt;encoding());
4729   emit_int8((unsigned char)0xC1);
4730   emit_int8((unsigned char)(0xE8 | encode));
4731   emit_int8(imm8);
4732 }
4733 
4734 void Assembler::shrl(Register dst) {
4735   int encode = prefix_and_encode(dst-&gt;encoding());
4736   emit_int8((unsigned char)0xD3);
4737   emit_int8((unsigned char)(0xE8 | encode));
4738 }
4739 
<span class="line-added">4740 void Assembler::shldl(Register dst, Register src) {</span>
<span class="line-added">4741   int encode = prefix_and_encode(src-&gt;encoding(), dst-&gt;encoding());</span>
<span class="line-added">4742   emit_int8(0x0F);</span>
<span class="line-added">4743   emit_int8((unsigned char)0xA5);</span>
<span class="line-added">4744   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">4745 }</span>
<span class="line-added">4746 </span>
<span class="line-added">4747 void Assembler::shldl(Register dst, Register src, int8_t imm8) {</span>
<span class="line-added">4748   int encode = prefix_and_encode(src-&gt;encoding(), dst-&gt;encoding());</span>
<span class="line-added">4749   emit_int8(0x0F);</span>
<span class="line-added">4750   emit_int8((unsigned char)0xA4);</span>
<span class="line-added">4751   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">4752   emit_int8(imm8);</span>
<span class="line-added">4753 }</span>
<span class="line-added">4754 </span>
<span class="line-added">4755 void Assembler::shrdl(Register dst, Register src) {</span>
<span class="line-added">4756   int encode = prefix_and_encode(src-&gt;encoding(), dst-&gt;encoding());</span>
<span class="line-added">4757   emit_int8(0x0F);</span>
<span class="line-added">4758   emit_int8((unsigned char)0xAD);</span>
<span class="line-added">4759   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">4760 }</span>
<span class="line-added">4761 </span>
<span class="line-added">4762 void Assembler::shrdl(Register dst, Register src, int8_t imm8) {</span>
<span class="line-added">4763   int encode = prefix_and_encode(src-&gt;encoding(), dst-&gt;encoding());</span>
<span class="line-added">4764   emit_int8(0x0F);</span>
<span class="line-added">4765   emit_int8((unsigned char)0xAC);</span>
<span class="line-added">4766   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">4767   emit_int8(imm8);</span>
<span class="line-added">4768 }</span>
<span class="line-added">4769 </span>
4770 // copies a single word from [esi] to [edi]
4771 void Assembler::smovl() {
4772   emit_int8((unsigned char)0xA5);
4773 }
4774 
<span class="line-added">4775 void Assembler::roundsd(XMMRegister dst, XMMRegister src, int32_t rmode) {</span>
<span class="line-added">4776   assert(VM_Version::supports_sse4_1(), &quot;&quot;);</span>
<span class="line-added">4777   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);</span>
<span class="line-added">4778   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);</span>
<span class="line-added">4779   emit_int8(0x0B);</span>
<span class="line-added">4780   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">4781   emit_int8((unsigned char)rmode);</span>
<span class="line-added">4782 }</span>
<span class="line-added">4783 </span>
<span class="line-added">4784 void Assembler::roundsd(XMMRegister dst, Address src, int32_t rmode) {</span>
<span class="line-added">4785   assert(VM_Version::supports_sse4_1(), &quot;&quot;);</span>
<span class="line-added">4786   InstructionMark im(this);</span>
<span class="line-added">4787   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);</span>
<span class="line-added">4788   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);</span>
<span class="line-added">4789   emit_int8(0x0B);</span>
<span class="line-added">4790   emit_operand(dst, src);</span>
<span class="line-added">4791   emit_int8((unsigned char)rmode);</span>
<span class="line-added">4792 }</span>
<span class="line-added">4793 </span>
4794 void Assembler::sqrtsd(XMMRegister dst, XMMRegister src) {
4795   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4796   InstructionAttr attributes(AVX_128bit, /* rex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
4797   attributes.set_rex_vex_w_reverted();
4798   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_F2, VEX_OPCODE_0F, &amp;attributes);
4799   emit_int8(0x51);
4800   emit_int8((unsigned char)(0xC0 | encode));
4801 }
4802 
4803 void Assembler::sqrtsd(XMMRegister dst, Address src) {
4804   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4805   InstructionMark im(this);
4806   InstructionAttr attributes(AVX_128bit, /* rex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
4807   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_64bit);
4808   attributes.set_rex_vex_w_reverted();
4809   simd_prefix(dst, dst, src, VEX_SIMD_F2, VEX_OPCODE_0F, &amp;attributes);
4810   emit_int8(0x51);
4811   emit_operand(dst, src);
4812 }
4813 
</pre>
<hr />
<pre>
5571   assert(VM_Version::supports_avx(), &quot;&quot;);
5572   InstructionMark im(this);
5573   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
5574   attributes.set_address_attributes(/* tuple_type */ EVEX_FV, /* input_size_in_bits */ EVEX_64bit);
5575   attributes.set_rex_vex_w_reverted();
5576   vex_prefix(src, nds-&gt;encoding(), dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
5577   emit_int8(0x5E);
5578   emit_operand(dst, src);
5579 }
5580 
5581 void Assembler::vdivps(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {
5582   assert(VM_Version::supports_avx(), &quot;&quot;);
5583   InstructionMark im(this);
5584   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
5585   attributes.set_address_attributes(/* tuple_type */ EVEX_FV, /* input_size_in_bits */ EVEX_32bit);
5586   vex_prefix(src, nds-&gt;encoding(), dst-&gt;encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F, &amp;attributes);
5587   emit_int8(0x5E);
5588   emit_operand(dst, src);
5589 }
5590 
<span class="line-added">5591 void Assembler::vroundpd(XMMRegister dst, XMMRegister src, int32_t rmode, int vector_len) {</span>
<span class="line-added">5592   assert(VM_Version::supports_avx(), &quot;&quot;);</span>
<span class="line-added">5593   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);</span>
<span class="line-added">5594   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);</span>
<span class="line-added">5595   emit_int8(0x09);</span>
<span class="line-added">5596   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">5597   emit_int8((unsigned char)(rmode));</span>
<span class="line-added">5598 }</span>
<span class="line-added">5599 </span>
<span class="line-added">5600 void Assembler::vroundpd(XMMRegister dst, Address src, int32_t rmode,  int vector_len) {</span>
<span class="line-added">5601   assert(VM_Version::supports_avx(), &quot;&quot;);</span>
<span class="line-added">5602   InstructionMark im(this);</span>
<span class="line-added">5603   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);</span>
<span class="line-added">5604   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);</span>
<span class="line-added">5605   emit_int8(0x09);</span>
<span class="line-added">5606   emit_operand(dst, src);</span>
<span class="line-added">5607   emit_int8((unsigned char)(rmode));</span>
<span class="line-added">5608 }</span>
<span class="line-added">5609 </span>
<span class="line-added">5610 void Assembler::vrndscalepd(XMMRegister dst,  XMMRegister src,  int32_t rmode, int vector_len) {</span>
<span class="line-added">5611   assert(VM_Version::supports_evex(), &quot;requires EVEX support&quot;);</span>
<span class="line-added">5612   InstructionAttr attributes(vector_len, /* vex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">5613   attributes.set_is_evex_instruction();</span>
<span class="line-added">5614   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);</span>
<span class="line-added">5615   emit_int8((unsigned char)0x09);</span>
<span class="line-added">5616   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">5617   emit_int8((unsigned char)(rmode));</span>
<span class="line-added">5618 }</span>
<span class="line-added">5619 </span>
<span class="line-added">5620 void Assembler::vrndscalepd(XMMRegister dst, Address src, int32_t rmode, int vector_len) {</span>
<span class="line-added">5621   assert(VM_Version::supports_evex(), &quot;requires EVEX support&quot;);</span>
<span class="line-added">5622   assert(dst != xnoreg, &quot;sanity&quot;);</span>
<span class="line-added">5623   InstructionMark im(this);</span>
<span class="line-added">5624   InstructionAttr attributes(vector_len, /* vex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">5625   attributes.set_is_evex_instruction();</span>
<span class="line-added">5626   attributes.set_address_attributes(/* tuple_type */ EVEX_FV, /* input_size_in_bits */ EVEX_64bit);</span>
<span class="line-added">5627   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);</span>
<span class="line-added">5628   emit_int8((unsigned char)0x09);</span>
<span class="line-added">5629   emit_operand(dst, src);</span>
<span class="line-added">5630   emit_int8((unsigned char)(rmode));</span>
<span class="line-added">5631 }</span>
<span class="line-added">5632 </span>
<span class="line-added">5633 </span>
5634 void Assembler::vsqrtpd(XMMRegister dst, XMMRegister src, int vector_len) {
5635   assert(VM_Version::supports_avx(), &quot;&quot;);
5636   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
5637   attributes.set_rex_vex_w_reverted();
5638   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
5639   emit_int8(0x51);
5640   emit_int8((unsigned char)(0xC0 | encode));
5641 }
5642 
5643 void Assembler::vsqrtpd(XMMRegister dst, Address src, int vector_len) {
5644   assert(VM_Version::supports_avx(), &quot;&quot;);
5645   InstructionMark im(this);
5646   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
5647   attributes.set_address_attributes(/* tuple_type */ EVEX_FV, /* input_size_in_bits */ EVEX_64bit);
5648   attributes.set_rex_vex_w_reverted();
5649   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
5650   emit_int8(0x51);
5651   emit_operand(dst, src);
5652 }
5653 
</pre>
<hr />
<pre>
6470   emit_int8((unsigned char)(0xC0 | encode));
6471   emit_int8(shift &amp; 0xFF);
6472 }
6473 
6474 void Assembler::vpsraw(XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len) {
6475   assert(UseAVX &gt; 0, &quot;requires some form of AVX&quot;);
6476   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
6477   int encode = vex_prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding(), shift-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6478   emit_int8((unsigned char)0xE1);
6479   emit_int8((unsigned char)(0xC0 | encode));
6480 }
6481 
6482 void Assembler::vpsrad(XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len) {
6483   assert(UseAVX &gt; 0, &quot;requires some form of AVX&quot;);
6484   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6485   int encode = vex_prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding(), shift-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6486   emit_int8((unsigned char)0xE2);
6487   emit_int8((unsigned char)(0xC0 | encode));
6488 }
6489 
<span class="line-added">6490 void Assembler::evpsraq(XMMRegister dst, XMMRegister src, int shift, int vector_len) {</span>
<span class="line-added">6491   assert(UseAVX &gt; 2, &quot;requires AVX512&quot;);</span>
<span class="line-added">6492   assert ((VM_Version::supports_avx512vl() || vector_len == 2), &quot;requires AVX512vl&quot;);</span>
<span class="line-added">6493   InstructionAttr attributes(vector_len, /* vex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">6494   attributes.set_is_evex_instruction();</span>
<span class="line-added">6495   int encode = vex_prefix_and_encode(xmm4-&gt;encoding(), dst-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);</span>
<span class="line-added">6496   emit_int8((unsigned char)0x72);</span>
<span class="line-added">6497   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">6498   emit_int8(shift &amp; 0xFF);</span>
<span class="line-added">6499 }</span>
<span class="line-added">6500 </span>
<span class="line-added">6501 void Assembler::evpsraq(XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len) {</span>
<span class="line-added">6502   assert(UseAVX &gt; 2, &quot;requires AVX512&quot;);</span>
<span class="line-added">6503   assert ((VM_Version::supports_avx512vl() || vector_len == 2), &quot;requires AVX512vl&quot;);</span>
<span class="line-added">6504   InstructionAttr attributes(vector_len, /* vex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">6505   attributes.set_is_evex_instruction();</span>
<span class="line-added">6506   int encode = vex_prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding(), shift-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);</span>
<span class="line-added">6507   emit_int8((unsigned char)0xE2);</span>
<span class="line-added">6508   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">6509 }</span>
6510 
6511 // logical operations packed integers
6512 void Assembler::pand(XMMRegister dst, XMMRegister src) {
6513   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
6514   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6515   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6516   emit_int8((unsigned char)0xDB);
6517   emit_int8((unsigned char)(0xC0 | encode));
6518 }
6519 
6520 void Assembler::vpand(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
6521   assert(UseAVX &gt; 0, &quot;requires some form of AVX&quot;);
6522   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6523   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6524   emit_int8((unsigned char)0xDB);
6525   emit_int8((unsigned char)(0xC0 | encode));
6526 }
6527 
6528 void Assembler::vpand(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {
6529   assert(UseAVX &gt; 0, &quot;requires some form of AVX&quot;);
6530   InstructionMark im(this);
6531   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6532   attributes.set_address_attributes(/* tuple_type */ EVEX_FV, /* input_size_in_bits */ EVEX_32bit);
6533   vex_prefix(src, nds-&gt;encoding(), dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6534   emit_int8((unsigned char)0xDB);
6535   emit_operand(dst, src);
6536 }
6537 
6538 void Assembler::vpandq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
6539   assert(VM_Version::supports_evex(), &quot;&quot;);
6540   InstructionAttr attributes(vector_len, /* vex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6541   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6542   emit_int8((unsigned char)0xDB);
6543   emit_int8((unsigned char)(0xC0 | encode));
6544 }
6545 
<span class="line-added">6546 void Assembler::vpshldvd(XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len) {</span>
<span class="line-added">6547   assert(VM_Version::supports_vbmi2(), &quot;requires vbmi2&quot;);</span>
<span class="line-added">6548   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">6549   attributes.set_is_evex_instruction();</span>
<span class="line-added">6550   int encode = vex_prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding(), shift-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);</span>
<span class="line-added">6551   emit_int8(0x71);</span>
<span class="line-added">6552   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">6553 }</span>
<span class="line-added">6554 </span>
<span class="line-added">6555 void Assembler::vpshrdvd(XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len) {</span>
<span class="line-added">6556   assert(VM_Version::supports_vbmi2(), &quot;requires vbmi2&quot;);</span>
<span class="line-added">6557   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);</span>
<span class="line-added">6558   attributes.set_is_evex_instruction();</span>
<span class="line-added">6559   int encode = vex_prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding(), shift-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);</span>
<span class="line-added">6560   emit_int8(0x73);</span>
<span class="line-added">6561   emit_int8((unsigned char)(0xC0 | encode));</span>
<span class="line-added">6562 }</span>
6563 
6564 void Assembler::pandn(XMMRegister dst, XMMRegister src) {
6565   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
6566   InstructionAttr attributes(AVX_128bit, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6567   attributes.set_rex_vex_w_reverted();
6568   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6569   emit_int8((unsigned char)0xDF);
6570   emit_int8((unsigned char)(0xC0 | encode));
6571 }
6572 
6573 void Assembler::vpandn(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
6574   assert(UseAVX &gt; 0, &quot;requires some form of AVX&quot;);
6575   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6576   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6577   emit_int8((unsigned char)0xDF);
6578   emit_int8((unsigned char)(0xC0 | encode));
6579 }
6580 
6581 
6582 void Assembler::por(XMMRegister dst, XMMRegister src) {
</pre>
<hr />
<pre>
7142   emit_int8((unsigned char)(0xC0 | encode));
7143 }
7144 
7145 void Assembler::evbroadcasti64x2(XMMRegister dst, Address src, int vector_len) {
7146   assert(vector_len != Assembler::AVX_128bit, &quot;&quot;);
7147   assert(VM_Version::supports_avx512dq(), &quot;&quot;);
7148   assert(dst != xnoreg, &quot;sanity&quot;);
7149   InstructionMark im(this);
7150   InstructionAttr attributes(vector_len, /* vex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7151   attributes.set_rex_vex_w_reverted();
7152   attributes.set_address_attributes(/* tuple_type */ EVEX_T2, /* input_size_in_bits */ EVEX_64bit);
7153   // swap src&lt;-&gt;dst for encoding
7154   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7155   emit_int8(0x5A);
7156   emit_operand(dst, src);
7157 }
7158 
7159 // scalar single/double precision replicate
7160 
7161 // duplicate single precision data from src into programmed locations in dest : requires AVX512VL
<span class="line-modified">7162 void Assembler::vbroadcastss(XMMRegister dst, XMMRegister src, int vector_len) {</span>
7163   assert(VM_Version::supports_avx(), &quot;&quot;);
7164   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7165   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7166   emit_int8(0x18);
7167   emit_int8((unsigned char)(0xC0 | encode));
7168 }
7169 
<span class="line-modified">7170 void Assembler::vbroadcastss(XMMRegister dst, Address src, int vector_len) {</span>
7171   assert(VM_Version::supports_avx(), &quot;&quot;);
7172   assert(dst != xnoreg, &quot;sanity&quot;);
7173   InstructionMark im(this);
7174   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7175   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_32bit);
7176   // swap src&lt;-&gt;dst for encoding
7177   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7178   emit_int8(0x18);
7179   emit_operand(dst, src);
7180 }
7181 
7182 // duplicate double precision data from src into programmed locations in dest : requires AVX512VL
<span class="line-modified">7183 void Assembler::vbroadcastsd(XMMRegister dst, XMMRegister src, int vector_len) {</span>
7184   assert(VM_Version::supports_avx(), &quot;&quot;);
7185   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7186   attributes.set_rex_vex_w_reverted();
7187   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7188   emit_int8(0x19);
7189   emit_int8((unsigned char)(0xC0 | encode));
7190 }
7191 
<span class="line-modified">7192 void Assembler::vbroadcastsd(XMMRegister dst, Address src, int vector_len) {</span>
7193   assert(VM_Version::supports_avx(), &quot;&quot;);
7194   assert(dst != xnoreg, &quot;sanity&quot;);
7195   InstructionMark im(this);
7196   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7197   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_64bit);
7198   attributes.set_rex_vex_w_reverted();
7199   // swap src&lt;-&gt;dst for encoding
7200   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7201   emit_int8(0x19);
7202   emit_operand(dst, src);
7203 }
7204 
7205 
7206 // gpr source broadcast forms
7207 
7208 // duplicate 1-byte integer data from src into programmed locations in dest : requires AVX512BW and AVX512VL
7209 void Assembler::evpbroadcastb(XMMRegister dst, Register src, int vector_len) {
7210   assert(VM_Version::supports_avx512bw(), &quot;&quot;);
7211   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
7212   attributes.set_is_evex_instruction();
</pre>
<hr />
<pre>
7227 
7228 // duplicate 4-byte integer data from src into programmed locations in dest : requires AVX512VL
7229 void Assembler::evpbroadcastd(XMMRegister dst, Register src, int vector_len) {
7230   assert(VM_Version::supports_evex(), &quot;&quot;);
7231   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7232   attributes.set_is_evex_instruction();
7233   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7234   emit_int8(0x7C);
7235   emit_int8((unsigned char)(0xC0 | encode));
7236 }
7237 
7238 // duplicate 8-byte integer data from src into programmed locations in dest : requires AVX512VL
7239 void Assembler::evpbroadcastq(XMMRegister dst, Register src, int vector_len) {
7240   assert(VM_Version::supports_evex(), &quot;&quot;);
7241   InstructionAttr attributes(vector_len, /* vex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7242   attributes.set_is_evex_instruction();
7243   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7244   emit_int8(0x7C);
7245   emit_int8((unsigned char)(0xC0 | encode));
7246 }

7247 void Assembler::evpgatherdd(XMMRegister dst, KRegister mask, Address src, int vector_len) {
7248   assert(VM_Version::supports_evex(), &quot;&quot;);
7249   assert(dst != xnoreg, &quot;sanity&quot;);
7250   InstructionMark im(this);
7251   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ false, /* uses_vl */ true);
7252   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_64bit);
7253   attributes.reset_is_clear_context();
7254   attributes.set_embedded_opmask_register_specifier(mask);
7255   attributes.set_is_evex_instruction();
7256   // swap src&lt;-&gt;dst for encoding
7257   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7258   emit_int8((unsigned char)0x90);
7259   emit_operand(dst, src);
7260 }

7261 // Carry-Less Multiplication Quadword
7262 void Assembler::pclmulqdq(XMMRegister dst, XMMRegister src, int mask) {
7263   assert(VM_Version::supports_clmul(), &quot;&quot;);
7264   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ true);
7265   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
7266   emit_int8(0x44);
7267   emit_int8((unsigned char)(0xC0 | encode));
7268   emit_int8((unsigned char)mask);
7269 }
7270 
7271 // Carry-Less Multiplication Quadword
7272 void Assembler::vpclmulqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int mask) {
7273   assert(VM_Version::supports_avx() &amp;&amp; VM_Version::supports_clmul(), &quot;&quot;);
7274   InstructionAttr attributes(AVX_128bit, /* vex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ true);
7275   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
7276   emit_int8(0x44);
7277   emit_int8((unsigned char)(0xC0 | encode));
7278   emit_int8((unsigned char)mask);
7279 }
7280 
7281 void Assembler::evpclmulqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int mask, int vector_len) {
<span class="line-modified">7282   assert(VM_Version::supports_avx512_vpclmulqdq(), &quot;Requires vector carryless multiplication support&quot;);</span>
7283   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7284   attributes.set_is_evex_instruction();
7285   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
7286   emit_int8(0x44);
7287   emit_int8((unsigned char)(0xC0 | encode));
7288   emit_int8((unsigned char)mask);
7289 }
7290 
7291 void Assembler::vzeroupper() {
7292   if (VM_Version::supports_vzeroupper()) {
7293     InstructionAttr attributes(AVX_128bit, /* vex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
7294     (void)vex_prefix_and_encode(0, 0, 0, VEX_SIMD_NONE, VEX_OPCODE_0F, &amp;attributes);
7295     emit_int8(0x77);
7296   }
7297 }
7298 
7299 #ifndef _LP64
7300 // 32bit only pieces of the assembler
7301 
7302 void Assembler::cmp_literal32(Register src1, int32_t imm32, RelocationHolder const&amp; rspec) {
</pre>
<hr />
<pre>
7313   emit_int8((unsigned char)0x81);
7314   emit_operand(rdi, src1);
7315   emit_data(imm32, rspec, 0);
7316 }
7317 
7318 // The 64-bit (32bit platform) cmpxchg compares the value at adr with the contents of rdx:rax,
7319 // and stores rcx:rbx into adr if so; otherwise, the value at adr is loaded
7320 // into rdx:rax.  The ZF is set if the compared values were equal, and cleared otherwise.
7321 void Assembler::cmpxchg8(Address adr) {
7322   InstructionMark im(this);
7323   emit_int8(0x0F);
7324   emit_int8((unsigned char)0xC7);
7325   emit_operand(rcx, adr);
7326 }
7327 
7328 void Assembler::decl(Register dst) {
7329   // Don&#39;t use it directly. Use MacroAssembler::decrementl() instead.
7330  emit_int8(0x48 | dst-&gt;encoding());
7331 }
7332 
<span class="line-modified">7333 // 64bit doesn&#39;t use the x87</span>


7334 
7335 void Assembler::fabs() {
7336   emit_int8((unsigned char)0xD9);
7337   emit_int8((unsigned char)0xE1);
7338 }
7339 
7340 void Assembler::fadd(int i) {
7341   emit_farith(0xD8, 0xC0, i);
7342 }
7343 
7344 void Assembler::fadd_d(Address src) {
7345   InstructionMark im(this);
7346   emit_int8((unsigned char)0xDC);
7347   emit_operand32(rax, src);
7348 }
7349 
7350 void Assembler::fadd_s(Address src) {
7351   InstructionMark im(this);
7352   emit_int8((unsigned char)0xD8);
7353   emit_operand32(rax, src);
</pre>
<hr />
<pre>
7748 
7749 void Assembler::fyl2x() {
7750   emit_int8((unsigned char)0xD9);
7751   emit_int8((unsigned char)0xF1);
7752 }
7753 
7754 void Assembler::frndint() {
7755   emit_int8((unsigned char)0xD9);
7756   emit_int8((unsigned char)0xFC);
7757 }
7758 
7759 void Assembler::f2xm1() {
7760   emit_int8((unsigned char)0xD9);
7761   emit_int8((unsigned char)0xF0);
7762 }
7763 
7764 void Assembler::fldl2e() {
7765   emit_int8((unsigned char)0xD9);
7766   emit_int8((unsigned char)0xEA);
7767 }
<span class="line-added">7768 #endif // !_LP64</span>
7769 
7770 // SSE SIMD prefix byte values corresponding to VexSimdPrefix encoding.
7771 static int simd_pre[4] = { 0, 0x66, 0xF3, 0xF2 };
7772 // SSE opcode second byte values (first is 0x0F) corresponding to VexOpcode encoding.
7773 static int simd_opc[4] = { 0,    0, 0x38, 0x3A };
7774 
7775 // Generate SSE legacy REX prefix and SIMD opcode based on VEX encoding.
7776 void Assembler::rex_prefix(Address adr, XMMRegister xreg, VexSimdPrefix pre, VexOpcode opc, bool rex_w) {
7777   if (pre &gt; 0) {
7778     emit_int8(simd_pre[pre]);
7779   }
7780   if (rex_w) {
7781     prefixq(adr, xreg);
7782   } else {
7783     prefix(adr, xreg);
7784   }
7785   if (opc &gt; 0) {
7786     emit_int8(0x0F);
7787     int opc2 = simd_opc[opc];
7788     if (opc2 &gt; 0) {
</pre>
<hr />
<pre>
8138 void Assembler::popa() { // 32bit
8139   emit_int8(0x61);
8140 }
8141 
8142 void Assembler::push_literal32(int32_t imm32, RelocationHolder const&amp; rspec) {
8143   InstructionMark im(this);
8144   emit_int8(0x68);
8145   emit_data(imm32, rspec, 0);
8146 }
8147 
8148 void Assembler::pusha() { // 32bit
8149   emit_int8(0x60);
8150 }
8151 
8152 void Assembler::set_byte_if_not_zero(Register dst) {
8153   emit_int8(0x0F);
8154   emit_int8((unsigned char)0x95);
8155   emit_int8((unsigned char)(0xE0 | dst-&gt;encoding()));
8156 }
8157 




















8158 #else // LP64
8159 
8160 void Assembler::set_byte_if_not_zero(Register dst) {
8161   int enc = prefix_and_encode(dst-&gt;encoding(), true);
8162   emit_int8(0x0F);
8163   emit_int8((unsigned char)0x95);
8164   emit_int8((unsigned char)(0xE0 | enc));
8165 }
8166 
8167 // 64bit only pieces of the assembler
8168 // This should only be used by 64bit instructions that can use rip-relative
8169 // it cannot be used by instructions that want an immediate value.
8170 
8171 bool Assembler::reachable(AddressLiteral adr) {
8172   int64_t disp;
8173   // None will force a 64bit literal to the code stream. Likely a placeholder
8174   // for something that will be patched later and we need to certain it will
8175   // always be reachable.
8176   if (adr.reloc() == relocInfo::none) {
8177     return false;
</pre>
<hr />
<pre>
8694   int encode = vex_prefix_and_encode(rcx-&gt;encoding(), dst-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &amp;attributes);
8695   emit_int8((unsigned char)0xF3);
8696   emit_int8((unsigned char)(0xC0 | encode));
8697 }
8698 
8699 void Assembler::blsrq(Register dst, Address src) {
8700   assert(VM_Version::supports_bmi1(), &quot;bit manipulation instructions not supported&quot;);
8701   InstructionMark im(this);
8702   InstructionAttr attributes(AVX_128bit, /* vex_w */ true, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
8703   vex_prefix(src, dst-&gt;encoding(), rcx-&gt;encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &amp;attributes);
8704   emit_int8((unsigned char)0xF3);
8705   emit_operand(rcx, src);
8706 }
8707 
8708 void Assembler::cdqq() {
8709   prefix(REX_W);
8710   emit_int8((unsigned char)0x99);
8711 }
8712 
8713 void Assembler::clflush(Address adr) {
<span class="line-added">8714   assert(VM_Version::supports_clflush(), &quot;should do&quot;);</span>
<span class="line-added">8715   prefix(adr);</span>
<span class="line-added">8716   emit_int8(0x0F);</span>
<span class="line-added">8717   emit_int8((unsigned char)0xAE);</span>
<span class="line-added">8718   emit_operand(rdi, adr);</span>
<span class="line-added">8719 }</span>
<span class="line-added">8720 </span>
<span class="line-added">8721 void Assembler::clflushopt(Address adr) {</span>
<span class="line-added">8722   assert(VM_Version::supports_clflushopt(), &quot;should do!&quot;);</span>
<span class="line-added">8723   // adr should be base reg only with no index or offset</span>
<span class="line-added">8724   assert(adr.index() == noreg, &quot;index should be noreg&quot;);</span>
<span class="line-added">8725   assert(adr.scale() == Address::no_scale, &quot;scale should be no_scale&quot;);</span>
<span class="line-added">8726   assert(adr.disp() == 0, &quot;displacement should be 0&quot;);</span>
<span class="line-added">8727   // instruction prefix is 0x66</span>
<span class="line-added">8728   emit_int8(0x66);</span>
8729   prefix(adr);
<span class="line-added">8730   // opcode family is 0x0f 0xAE</span>
8731   emit_int8(0x0F);
8732   emit_int8((unsigned char)0xAE);
<span class="line-added">8733   // extended opcode byte is 7 == rdi</span>
8734   emit_operand(rdi, adr);
8735 }
8736 
<span class="line-added">8737 void Assembler::clwb(Address adr) {</span>
<span class="line-added">8738   assert(VM_Version::supports_clwb(), &quot;should do!&quot;);</span>
<span class="line-added">8739   // adr should be base reg only with no index or offset</span>
<span class="line-added">8740   assert(adr.index() == noreg, &quot;index should be noreg&quot;);</span>
<span class="line-added">8741   assert(adr.scale() == Address::no_scale, &quot;scale should be no_scale&quot;);</span>
<span class="line-added">8742   assert(adr.disp() == 0, &quot;displacement should be 0&quot;);</span>
<span class="line-added">8743   // instruction prefix is 0x66</span>
<span class="line-added">8744   emit_int8(0x66);</span>
<span class="line-added">8745   prefix(adr);</span>
<span class="line-added">8746   // opcode family is 0x0f 0xAE</span>
<span class="line-added">8747   emit_int8(0x0F);</span>
<span class="line-added">8748   emit_int8((unsigned char)0xAE);</span>
<span class="line-added">8749   // extended opcode byte is 6 == rsi</span>
<span class="line-added">8750   emit_operand(rsi, adr);</span>
<span class="line-added">8751 }</span>
<span class="line-added">8752 </span>
8753 void Assembler::cmovq(Condition cc, Register dst, Register src) {
8754   int encode = prefixq_and_encode(dst-&gt;encoding(), src-&gt;encoding());
8755   emit_int8(0x0F);
8756   emit_int8(0x40 | cc);
8757   emit_int8((unsigned char)(0xC0 | encode));
8758 }
8759 
8760 void Assembler::cmovq(Condition cc, Register dst, Address src) {
8761   InstructionMark im(this);
8762   prefixq(src, dst);
8763   emit_int8(0x0F);
8764   emit_int8(0x40 | cc);
8765   emit_operand(dst, src);
8766 }
8767 
8768 void Assembler::cmpq(Address dst, int32_t imm32) {
8769   InstructionMark im(this);
8770   prefixq(dst);
8771   emit_int8((unsigned char)0x81);
8772   emit_operand(rdi, dst, 4);
</pre>
<hr />
<pre>
8816 void Assembler::cvtsi2sdq(XMMRegister dst, Address src) {
8817   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
8818   InstructionMark im(this);
8819   InstructionAttr attributes(AVX_128bit, /* rex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
8820   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_64bit);
8821   simd_prefix(dst, dst, src, VEX_SIMD_F2, VEX_OPCODE_0F, &amp;attributes);
8822   emit_int8(0x2A);
8823   emit_operand(dst, src);
8824 }
8825 
8826 void Assembler::cvtsi2ssq(XMMRegister dst, Address src) {
8827   NOT_LP64(assert(VM_Version::supports_sse(), &quot;&quot;));
8828   InstructionMark im(this);
8829   InstructionAttr attributes(AVX_128bit, /* rex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
8830   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_64bit);
8831   simd_prefix(dst, dst, src, VEX_SIMD_F3, VEX_OPCODE_0F, &amp;attributes);
8832   emit_int8(0x2A);
8833   emit_operand(dst, src);
8834 }
8835 
<span class="line-added">8836 void Assembler::cvttsd2siq(Register dst, Address src) {</span>
<span class="line-added">8837   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));</span>
<span class="line-added">8838   // F2 REX.W 0F 2C /r</span>
<span class="line-added">8839   // CVTTSD2SI r64, xmm1/m64</span>
<span class="line-added">8840   InstructionMark im(this);</span>
<span class="line-added">8841   emit_int8((unsigned char)0xF2);</span>
<span class="line-added">8842   prefix(REX_W);</span>
<span class="line-added">8843   emit_int8(0x0F);</span>
<span class="line-added">8844   emit_int8(0x2C);</span>
<span class="line-added">8845   emit_operand(dst, src);</span>
<span class="line-added">8846 }</span>
<span class="line-added">8847 </span>
8848 void Assembler::cvttsd2siq(Register dst, XMMRegister src) {
8849   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
8850   InstructionAttr attributes(AVX_128bit, /* rex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
8851   int encode = simd_prefix_and_encode(as_XMMRegister(dst-&gt;encoding()), xnoreg, src, VEX_SIMD_F2, VEX_OPCODE_0F, &amp;attributes);
8852   emit_int8(0x2C);
8853   emit_int8((unsigned char)(0xC0 | encode));
8854 }
8855 
8856 void Assembler::cvttss2siq(Register dst, XMMRegister src) {
8857   NOT_LP64(assert(VM_Version::supports_sse(), &quot;&quot;));
8858   InstructionAttr attributes(AVX_128bit, /* rex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ false);
8859   int encode = simd_prefix_and_encode(as_XMMRegister(dst-&gt;encoding()), xnoreg, src, VEX_SIMD_F3, VEX_OPCODE_0F, &amp;attributes);
8860   emit_int8(0x2C);
8861   emit_int8((unsigned char)(0xC0 | encode));
8862 }
8863 
8864 void Assembler::decl(Register dst) {
8865   // Don&#39;t use it directly. Use MacroAssembler::decrementl() instead.
8866   // Use two-byte form (one-byte form is a REX prefix in 64-bit mode)
8867   int encode = prefix_and_encode(dst-&gt;encoding());
</pre>
<hr />
<pre>
9184 void Assembler::mulxq(Register dst1, Register dst2, Register src) {
9185   assert(VM_Version::supports_bmi2(), &quot;bit manipulation instructions not supported&quot;);
9186   InstructionAttr attributes(AVX_128bit, /* vex_w */ true, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
9187   int encode = vex_prefix_and_encode(dst1-&gt;encoding(), dst2-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &amp;attributes);
9188   emit_int8((unsigned char)0xF6);
9189   emit_int8((unsigned char)(0xC0 | encode));
9190 }
9191 
9192 void Assembler::negq(Register dst) {
9193   int encode = prefixq_and_encode(dst-&gt;encoding());
9194   emit_int8((unsigned char)0xF7);
9195   emit_int8((unsigned char)(0xD8 | encode));
9196 }
9197 
9198 void Assembler::notq(Register dst) {
9199   int encode = prefixq_and_encode(dst-&gt;encoding());
9200   emit_int8((unsigned char)0xF7);
9201   emit_int8((unsigned char)(0xD0 | encode));
9202 }
9203 
<span class="line-added">9204 void Assembler::btsq(Address dst, int imm8) {</span>
<span class="line-added">9205   assert(isByte(imm8), &quot;not a byte&quot;);</span>
<span class="line-added">9206   InstructionMark im(this);</span>
<span class="line-added">9207   prefixq(dst);</span>
<span class="line-added">9208   emit_int8((unsigned char)0x0F);</span>
<span class="line-added">9209   emit_int8((unsigned char)0xBA);</span>
<span class="line-added">9210   emit_operand(rbp /* 5 */, dst, 1);</span>
<span class="line-added">9211   emit_int8(imm8);</span>
<span class="line-added">9212 }</span>
<span class="line-added">9213 </span>
<span class="line-added">9214 void Assembler::btrq(Address dst, int imm8) {</span>
<span class="line-added">9215   assert(isByte(imm8), &quot;not a byte&quot;);</span>
<span class="line-added">9216   InstructionMark im(this);</span>
<span class="line-added">9217   prefixq(dst);</span>
<span class="line-added">9218   emit_int8((unsigned char)0x0F);</span>
<span class="line-added">9219   emit_int8((unsigned char)0xBA);</span>
<span class="line-added">9220   emit_operand(rsi /* 6 */, dst, 1);</span>
<span class="line-added">9221   emit_int8(imm8);</span>
<span class="line-added">9222 }</span>
<span class="line-added">9223 </span>
9224 void Assembler::orq(Address dst, int32_t imm32) {
9225   InstructionMark im(this);
9226   prefixq(dst);
9227   emit_int8((unsigned char)0x81);
9228   emit_operand(rcx, dst, 4);
9229   emit_int32(imm32);
9230 }
9231 
9232 void Assembler::orq(Register dst, int32_t imm32) {
9233   (void) prefixq_and_encode(dst-&gt;encoding());
9234   emit_arith(0x81, 0xC8, dst, imm32);
9235 }
9236 
9237 void Assembler::orq(Register dst, Address src) {
9238   InstructionMark im(this);
9239   prefixq(src, dst);
9240   emit_int8(0x0B);
9241   emit_operand(dst, src);
9242 }
9243 
</pre>
</td>
</tr>
</table>
<center><a href="abstractInterpreter_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="assembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>