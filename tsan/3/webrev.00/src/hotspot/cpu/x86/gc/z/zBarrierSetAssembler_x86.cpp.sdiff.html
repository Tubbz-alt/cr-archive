<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/gc/z/zBarrierSetAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../../../style.css" />
  </head>
<body>
<center><a href="../shenandoah/shenandoah_x86_64.ad.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../index.html" target="_top">index</a> <a href="zBarrierSetAssembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/gc/z/zBarrierSetAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 #include &quot;precompiled.hpp&quot;
 25 #include &quot;asm/macroAssembler.inline.hpp&quot;
 26 #include &quot;code/codeBlob.hpp&quot;

 27 #include &quot;gc/z/zBarrier.inline.hpp&quot;
 28 #include &quot;gc/z/zBarrierSet.hpp&quot;
 29 #include &quot;gc/z/zBarrierSetAssembler.hpp&quot;
 30 #include &quot;gc/z/zBarrierSetRuntime.hpp&quot;
 31 #include &quot;memory/resourceArea.hpp&quot;
<span class="line-modified"> 32 #include &quot;runtime/stubCodeGenerator.hpp&quot;</span>
 33 #include &quot;utilities/macros.hpp&quot;
 34 #ifdef COMPILER1
 35 #include &quot;c1/c1_LIRAssembler.hpp&quot;
 36 #include &quot;c1/c1_MacroAssembler.hpp&quot;
 37 #include &quot;gc/z/c1/zBarrierSetC1.hpp&quot;
 38 #endif // COMPILER1
<span class="line-modified"> 39 </span>
<span class="line-modified"> 40 ZBarrierSetAssembler::ZBarrierSetAssembler() :</span>
<span class="line-modified"> 41     _load_barrier_slow_stub(),</span>
<span class="line-removed"> 42     _load_barrier_weak_slow_stub() {}</span>
 43 
 44 #ifdef PRODUCT
 45 #define BLOCK_COMMENT(str) /* nothing */
 46 #else
 47 #define BLOCK_COMMENT(str) __ block_comment(str)
 48 #endif
 49 
 50 #undef __
 51 #define __ masm-&gt;
 52 
 53 static void call_vm(MacroAssembler* masm,
 54                     address entry_point,
 55                     Register arg0,
 56                     Register arg1) {
 57   // Setup arguments
 58   if (arg1 == c_rarg0) {
 59     if (arg0 == c_rarg1) {
 60       __ xchgptr(c_rarg1, c_rarg0);
 61     } else {
 62       __ movptr(c_rarg1, arg1);
</pre>
<hr />
<pre>
181   // Restore scratch register
182   if (tmp1 == noreg) {
183     __ pop(scratch);
184   }
185 
186   BLOCK_COMMENT(&quot;} ZBarrierSetAssembler::load_at&quot;);
187 }
188 
189 #ifdef ASSERT
190 
191 void ZBarrierSetAssembler::store_at(MacroAssembler* masm,
192                                     DecoratorSet decorators,
193                                     BasicType type,
194                                     Address dst,
195                                     Register src,
196                                     Register tmp1,
197                                     Register tmp2) {
198   BLOCK_COMMENT(&quot;ZBarrierSetAssembler::store_at {&quot;);
199 
200   // Verify oop store
<span class="line-modified">201   if (type == T_OBJECT || type == T_ARRAY) {</span>
202     // Note that src could be noreg, which means we
203     // are storing null and can skip verification.
204     if (src != noreg) {
205       Label done;
206       __ testptr(src, address_bad_mask_from_thread(r15_thread));
207       __ jcc(Assembler::zero, done);
208       __ stop(&quot;Verify oop store failed&quot;);
209       __ should_not_reach_here();
210       __ bind(done);
211     }
212   }
213 
214   // Store value
215   BarrierSetAssembler::store_at(masm, decorators, type, dst, src, tmp1, tmp2);
216 
217   BLOCK_COMMENT(&quot;} ZBarrierSetAssembler::store_at&quot;);
218 }
219 
220 #endif // ASSERT
221 
</pre>
<hr />
<pre>
327                                                                  DecoratorSet decorators) const {
328   // Enter and save registers
329   __ enter();
330   __ save_live_registers_no_oop_map(true /* save_fpu_registers */);
331 
332   // Setup arguments
333   __ load_parameter(1, c_rarg1);
334   __ load_parameter(0, c_rarg0);
335 
336   // Call VM
337   __ call_VM_leaf(ZBarrierSetRuntime::load_barrier_on_oop_field_preloaded_addr(decorators), c_rarg0, c_rarg1);
338 
339   // Restore registers and return
340   __ restore_live_registers_except_rax(true /* restore_fpu_registers */);
341   __ leave();
342   __ ret(0);
343 }
344 
345 #endif // COMPILER1
346 
<span class="line-modified">347 #undef __</span>
<span class="line-modified">348 #define __ cgen-&gt;assembler()-&gt;</span>
<span class="line-modified">349 </span>
<span class="line-modified">350 // Generates a register specific stub for calling</span>
<span class="line-modified">351 // ZBarrierSetRuntime::load_barrier_on_oop_field_preloaded() or</span>
<span class="line-modified">352 // ZBarrierSetRuntime::load_barrier_on_weak_oop_field_preloaded().</span>
<span class="line-modified">353 //</span>
<span class="line-modified">354 // The raddr register serves as both input and output for this stub. When the stub is</span>
<span class="line-modified">355 // called the raddr register contains the object field address (oop*) where the bad oop</span>
<span class="line-modified">356 // was loaded from, which caused the slow path to be taken. On return from the stub the</span>
<span class="line-modified">357 // raddr register contains the good/healed oop returned from</span>
<span class="line-modified">358 // ZBarrierSetRuntime::load_barrier_on_oop_field_preloaded() or</span>
<span class="line-modified">359 // ZBarrierSetRuntime::load_barrier_on_weak_oop_field_preloaded().</span>
<span class="line-modified">360 static address generate_load_barrier_stub(StubCodeGenerator* cgen, Register raddr, DecoratorSet decorators) {</span>
<span class="line-modified">361   // Don&#39;t generate stub for invalid registers</span>
<span class="line-modified">362   if (raddr == rsp || raddr == r15) {</span>
<span class="line-modified">363     return NULL;</span>







364   }
365 
<span class="line-modified">366   // Create stub name</span>
<span class="line-modified">367   char name[64];</span>
<span class="line-removed">368   const bool weak = (decorators &amp; ON_WEAK_OOP_REF) != 0;</span>
<span class="line-removed">369   os::snprintf(name, sizeof(name), &quot;zgc_load_barrier%s_stub_%s&quot;, weak ? &quot;_weak&quot; : &quot;&quot;, raddr-&gt;name());</span>
370 
<span class="line-modified">371   __ align(CodeEntryAlignment);</span>
<span class="line-modified">372   StubCodeMark mark(cgen, &quot;StubRoutines&quot;, os::strdup(name, mtCode));</span>
<span class="line-modified">373   address start = __ pc();</span>
374 
<span class="line-modified">375   // Save live registers</span>
<span class="line-modified">376   if (raddr != rax) {</span>
<span class="line-modified">377     __ push(rax);</span>
<span class="line-modified">378   }</span>
<span class="line-modified">379   if (raddr != rcx) {</span>
<span class="line-modified">380     __ push(rcx);</span>
<span class="line-modified">381   }</span>
<span class="line-modified">382   if (raddr != rdx) {</span>
<span class="line-modified">383     __ push(rdx);</span>


















384   }
<span class="line-modified">385   if (raddr != rsi) {</span>
<span class="line-modified">386     __ push(rsi);</span>


387   }
<span class="line-modified">388   if (raddr != rdi) {</span>
<span class="line-modified">389     __ push(rdi);</span>













390   }
<span class="line-modified">391   if (raddr != r8) {</span>
<span class="line-modified">392     __ push(r8);</span>

393   }
<span class="line-modified">394   if (raddr != r9) {</span>
<span class="line-modified">395     __ push(r9);</span>




396   }
<span class="line-modified">397   if (raddr != r10) {</span>
<span class="line-modified">398     __ push(r10);</span>




399   }
<span class="line-modified">400   if (raddr != r11) {</span>
<span class="line-modified">401     __ push(r11);</span>


402   }
403 
<span class="line-modified">404   // Setup arguments</span>
<span class="line-modified">405   if (raddr != c_rarg1) {</span>
<span class="line-modified">406     __ movq(c_rarg1, raddr);</span>
407   }
<span class="line-removed">408   __ movq(c_rarg0, Address(raddr, 0));</span>
409 
<span class="line-modified">410   // Call barrier function</span>
<span class="line-modified">411   __ call_VM_leaf(ZBarrierSetRuntime::load_barrier_on_oop_field_preloaded_addr(decorators), c_rarg0, c_rarg1);</span>












412 
<span class="line-modified">413   // Move result returned in rax to raddr, if needed</span>
<span class="line-modified">414   if (raddr != rax) {</span>
<span class="line-modified">415     __ movq(raddr, rax);</span>
<span class="line-modified">416   }</span>

417 
<span class="line-modified">418   // Restore saved registers</span>
<span class="line-modified">419   if (raddr != r11) {</span>
<span class="line-modified">420     __ pop(r11);</span>
<span class="line-modified">421   }</span>
<span class="line-modified">422   if (raddr != r10) {</span>
<span class="line-modified">423     __ pop(r10);</span>
<span class="line-modified">424   }</span>
<span class="line-modified">425   if (raddr != r9) {</span>
<span class="line-modified">426     __ pop(r9);</span>
<span class="line-modified">427   }</span>
<span class="line-modified">428   if (raddr != r8) {</span>
<span class="line-modified">429     __ pop(r8);</span>
<span class="line-modified">430   }</span>
<span class="line-modified">431   if (raddr != rdi) {</span>
<span class="line-modified">432     __ pop(rdi);</span>
<span class="line-modified">433   }</span>
<span class="line-modified">434   if (raddr != rsi) {</span>
<span class="line-modified">435     __ pop(rsi);</span>
<span class="line-modified">436   }</span>
<span class="line-modified">437   if (raddr != rdx) {</span>
<span class="line-modified">438     __ pop(rdx);</span>
















































































439   }
<span class="line-modified">440   if (raddr != rcx) {</span>
<span class="line-modified">441     __ pop(rcx);</span>
















442   }
<span class="line-modified">443   if (raddr != rax) {</span>
<span class="line-modified">444     __ pop(rax);</span>








































445   }
446 
<span class="line-modified">447   __ ret(0);</span>
<span class="line-modified">448 </span>
<span class="line-modified">449   return start;</span>
<span class="line-modified">450 }</span>



451 
452 #undef __

453 
<span class="line-modified">454 static void barrier_stubs_init_inner(const char* label, const DecoratorSet decorators, address* stub) {</span>
<span class="line-modified">455   const int nregs = RegisterImpl::number_of_registers;</span>
<span class="line-removed">456   const int code_size = nregs * 128; // Rough estimate of code size</span>
<span class="line-removed">457 </span>
<span class="line-removed">458   ResourceMark rm;</span>
459 
<span class="line-modified">460   CodeBuffer buf(BufferBlob::create(label, code_size));</span>
<span class="line-modified">461   StubCodeGenerator cgen(&amp;buf);</span>
462 
<span class="line-modified">463   for (int i = 0; i &lt; nregs; i++) {</span>
<span class="line-modified">464     const Register reg = as_Register(i);</span>
<span class="line-modified">465     stub[i] = generate_load_barrier_stub(&amp;cgen, reg, decorators);</span>

466   }
<span class="line-removed">467 }</span>
468 
<span class="line-modified">469 void ZBarrierSetAssembler::barrier_stubs_init() {</span>
<span class="line-modified">470   barrier_stubs_init_inner(&quot;zgc_load_barrier_stubs&quot;, ON_STRONG_OOP_REF, _load_barrier_slow_stub);</span>
<span class="line-removed">471   barrier_stubs_init_inner(&quot;zgc_load_barrier_weak_stubs&quot;, ON_WEAK_OOP_REF, _load_barrier_weak_slow_stub);</span>
472 }
473 
<span class="line-modified">474 address ZBarrierSetAssembler::load_barrier_slow_stub(Register reg) {</span>
<span class="line-removed">475   return _load_barrier_slow_stub[reg-&gt;encoding()];</span>
<span class="line-removed">476 }</span>
477 
<span class="line-modified">478 address ZBarrierSetAssembler::load_barrier_weak_slow_stub(Register reg) {</span>
<span class="line-removed">479   return _load_barrier_weak_slow_stub[reg-&gt;encoding()];</span>
<span class="line-removed">480 }</span>
</pre>
</td>
<td>
<hr />
<pre>
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 #include &quot;precompiled.hpp&quot;
 25 #include &quot;asm/macroAssembler.inline.hpp&quot;
 26 #include &quot;code/codeBlob.hpp&quot;
<span class="line-added"> 27 #include &quot;code/vmreg.inline.hpp&quot;</span>
 28 #include &quot;gc/z/zBarrier.inline.hpp&quot;
 29 #include &quot;gc/z/zBarrierSet.hpp&quot;
 30 #include &quot;gc/z/zBarrierSetAssembler.hpp&quot;
 31 #include &quot;gc/z/zBarrierSetRuntime.hpp&quot;
 32 #include &quot;memory/resourceArea.hpp&quot;
<span class="line-modified"> 33 #include &quot;runtime/sharedRuntime.hpp&quot;</span>
 34 #include &quot;utilities/macros.hpp&quot;
 35 #ifdef COMPILER1
 36 #include &quot;c1/c1_LIRAssembler.hpp&quot;
 37 #include &quot;c1/c1_MacroAssembler.hpp&quot;
 38 #include &quot;gc/z/c1/zBarrierSetC1.hpp&quot;
 39 #endif // COMPILER1
<span class="line-modified"> 40 #ifdef COMPILER2</span>
<span class="line-modified"> 41 #include &quot;gc/z/c2/zBarrierSetC2.hpp&quot;</span>
<span class="line-modified"> 42 #endif // COMPILER2</span>

 43 
 44 #ifdef PRODUCT
 45 #define BLOCK_COMMENT(str) /* nothing */
 46 #else
 47 #define BLOCK_COMMENT(str) __ block_comment(str)
 48 #endif
 49 
 50 #undef __
 51 #define __ masm-&gt;
 52 
 53 static void call_vm(MacroAssembler* masm,
 54                     address entry_point,
 55                     Register arg0,
 56                     Register arg1) {
 57   // Setup arguments
 58   if (arg1 == c_rarg0) {
 59     if (arg0 == c_rarg1) {
 60       __ xchgptr(c_rarg1, c_rarg0);
 61     } else {
 62       __ movptr(c_rarg1, arg1);
</pre>
<hr />
<pre>
181   // Restore scratch register
182   if (tmp1 == noreg) {
183     __ pop(scratch);
184   }
185 
186   BLOCK_COMMENT(&quot;} ZBarrierSetAssembler::load_at&quot;);
187 }
188 
189 #ifdef ASSERT
190 
191 void ZBarrierSetAssembler::store_at(MacroAssembler* masm,
192                                     DecoratorSet decorators,
193                                     BasicType type,
194                                     Address dst,
195                                     Register src,
196                                     Register tmp1,
197                                     Register tmp2) {
198   BLOCK_COMMENT(&quot;ZBarrierSetAssembler::store_at {&quot;);
199 
200   // Verify oop store
<span class="line-modified">201   if (is_reference_type(type)) {</span>
202     // Note that src could be noreg, which means we
203     // are storing null and can skip verification.
204     if (src != noreg) {
205       Label done;
206       __ testptr(src, address_bad_mask_from_thread(r15_thread));
207       __ jcc(Assembler::zero, done);
208       __ stop(&quot;Verify oop store failed&quot;);
209       __ should_not_reach_here();
210       __ bind(done);
211     }
212   }
213 
214   // Store value
215   BarrierSetAssembler::store_at(masm, decorators, type, dst, src, tmp1, tmp2);
216 
217   BLOCK_COMMENT(&quot;} ZBarrierSetAssembler::store_at&quot;);
218 }
219 
220 #endif // ASSERT
221 
</pre>
<hr />
<pre>
327                                                                  DecoratorSet decorators) const {
328   // Enter and save registers
329   __ enter();
330   __ save_live_registers_no_oop_map(true /* save_fpu_registers */);
331 
332   // Setup arguments
333   __ load_parameter(1, c_rarg1);
334   __ load_parameter(0, c_rarg0);
335 
336   // Call VM
337   __ call_VM_leaf(ZBarrierSetRuntime::load_barrier_on_oop_field_preloaded_addr(decorators), c_rarg0, c_rarg1);
338 
339   // Restore registers and return
340   __ restore_live_registers_except_rax(true /* restore_fpu_registers */);
341   __ leave();
342   __ ret(0);
343 }
344 
345 #endif // COMPILER1
346 
<span class="line-modified">347 #ifdef COMPILER2</span>
<span class="line-modified">348 </span>
<span class="line-modified">349 OptoReg::Name ZBarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) {</span>
<span class="line-modified">350   if (!OptoReg::is_reg(opto_reg)) {</span>
<span class="line-modified">351     return OptoReg::Bad;</span>
<span class="line-modified">352   }</span>
<span class="line-modified">353 </span>
<span class="line-modified">354   const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);</span>
<span class="line-modified">355   if (vm_reg-&gt;is_XMMRegister()) {</span>
<span class="line-modified">356     opto_reg &amp;= ~15;</span>
<span class="line-modified">357     switch (node-&gt;ideal_reg()) {</span>
<span class="line-modified">358       case Op_VecX:</span>
<span class="line-modified">359         opto_reg |= 2;</span>
<span class="line-modified">360         break;</span>
<span class="line-modified">361       case Op_VecY:</span>
<span class="line-modified">362         opto_reg |= 4;</span>
<span class="line-modified">363         break;</span>
<span class="line-added">364       case Op_VecZ:</span>
<span class="line-added">365         opto_reg |= 8;</span>
<span class="line-added">366         break;</span>
<span class="line-added">367       default:</span>
<span class="line-added">368         opto_reg |= 1;</span>
<span class="line-added">369         break;</span>
<span class="line-added">370     }</span>
371   }
372 
<span class="line-modified">373   return opto_reg;</span>
<span class="line-modified">374 }</span>


375 
<span class="line-modified">376 // We use the vec_spill_helper from the x86.ad file to avoid reinventing this wheel</span>
<span class="line-modified">377 extern int vec_spill_helper(CodeBuffer *cbuf, bool do_size, bool is_load,</span>
<span class="line-modified">378                             int stack_offset, int reg, uint ireg, outputStream* st);</span>
379 
<span class="line-modified">380 #undef __</span>
<span class="line-modified">381 #define __ _masm-&gt;</span>
<span class="line-modified">382 </span>
<span class="line-modified">383 class ZSaveLiveRegisters {</span>
<span class="line-modified">384 private:</span>
<span class="line-modified">385   struct XMMRegisterData {</span>
<span class="line-modified">386     XMMRegister _reg;</span>
<span class="line-modified">387     int         _size;</span>
<span class="line-modified">388 </span>
<span class="line-added">389     // Used by GrowableArray::find()</span>
<span class="line-added">390     bool operator == (const XMMRegisterData&amp; other) {</span>
<span class="line-added">391       return _reg == other._reg;</span>
<span class="line-added">392     }</span>
<span class="line-added">393   };</span>
<span class="line-added">394 </span>
<span class="line-added">395   MacroAssembler* const          _masm;</span>
<span class="line-added">396   GrowableArray&lt;Register&gt;        _gp_registers;</span>
<span class="line-added">397   GrowableArray&lt;XMMRegisterData&gt; _xmm_registers;</span>
<span class="line-added">398   int                            _spill_size;</span>
<span class="line-added">399   int                            _spill_offset;</span>
<span class="line-added">400 </span>
<span class="line-added">401   static int xmm_compare_register_size(XMMRegisterData* left, XMMRegisterData* right) {</span>
<span class="line-added">402     if (left-&gt;_size == right-&gt;_size) {</span>
<span class="line-added">403       return 0;</span>
<span class="line-added">404     }</span>
<span class="line-added">405 </span>
<span class="line-added">406     return (left-&gt;_size &lt; right-&gt;_size) ? -1 : 1;</span>
407   }
<span class="line-modified">408 </span>
<span class="line-modified">409   static int xmm_slot_size(OptoReg::Name opto_reg) {</span>
<span class="line-added">410     // The low order 4 bytes denote what size of the XMM register is live</span>
<span class="line-added">411     return (opto_reg &amp; 15) &lt;&lt; 3;</span>
412   }
<span class="line-modified">413 </span>
<span class="line-modified">414   static uint xmm_ideal_reg_for_size(int reg_size) {</span>
<span class="line-added">415     switch (reg_size) {</span>
<span class="line-added">416     case 8:</span>
<span class="line-added">417       return Op_VecD;</span>
<span class="line-added">418     case 16:</span>
<span class="line-added">419       return Op_VecX;</span>
<span class="line-added">420     case 32:</span>
<span class="line-added">421       return Op_VecY;</span>
<span class="line-added">422     case 64:</span>
<span class="line-added">423       return Op_VecZ;</span>
<span class="line-added">424     default:</span>
<span class="line-added">425       fatal(&quot;Invalid register size %d&quot;, reg_size);</span>
<span class="line-added">426       return 0;</span>
<span class="line-added">427     }</span>
428   }
<span class="line-modified">429 </span>
<span class="line-modified">430   bool xmm_needs_vzeroupper() const {</span>
<span class="line-added">431     return _xmm_registers.is_nonempty() &amp;&amp; _xmm_registers.at(0)._size &gt; 16;</span>
432   }
<span class="line-modified">433 </span>
<span class="line-modified">434   void xmm_register_save(const XMMRegisterData&amp; reg_data) {</span>
<span class="line-added">435     const OptoReg::Name opto_reg = OptoReg::as_OptoReg(reg_data._reg-&gt;as_VMReg());</span>
<span class="line-added">436     const uint ideal_reg = xmm_ideal_reg_for_size(reg_data._size);</span>
<span class="line-added">437     _spill_offset -= reg_data._size;</span>
<span class="line-added">438     vec_spill_helper(__ code(), false /* do_size */, false /* is_load */, _spill_offset, opto_reg, ideal_reg, tty);</span>
439   }
<span class="line-modified">440 </span>
<span class="line-modified">441   void xmm_register_restore(const XMMRegisterData&amp; reg_data) {</span>
<span class="line-added">442     const OptoReg::Name opto_reg = OptoReg::as_OptoReg(reg_data._reg-&gt;as_VMReg());</span>
<span class="line-added">443     const uint ideal_reg = xmm_ideal_reg_for_size(reg_data._size);</span>
<span class="line-added">444     vec_spill_helper(__ code(), false /* do_size */, true /* is_load */, _spill_offset, opto_reg, ideal_reg, tty);</span>
<span class="line-added">445     _spill_offset += reg_data._size;</span>
446   }
<span class="line-modified">447 </span>
<span class="line-modified">448   void gp_register_save(Register reg) {</span>
<span class="line-added">449     _spill_offset -= 8;</span>
<span class="line-added">450     __ movq(Address(rsp, _spill_offset), reg);</span>
451   }
452 
<span class="line-modified">453   void gp_register_restore(Register reg) {</span>
<span class="line-modified">454     __ movq(reg, Address(rsp, _spill_offset));</span>
<span class="line-modified">455     _spill_offset += 8;</span>
456   }

457 
<span class="line-modified">458   void initialize(ZLoadBarrierStubC2* stub) {</span>
<span class="line-modified">459     // Create mask of caller saved registers that need to</span>
<span class="line-added">460     // be saved/restored if live</span>
<span class="line-added">461     RegMask caller_saved;</span>
<span class="line-added">462     caller_saved.Insert(OptoReg::as_OptoReg(rax-&gt;as_VMReg()));</span>
<span class="line-added">463     caller_saved.Insert(OptoReg::as_OptoReg(rcx-&gt;as_VMReg()));</span>
<span class="line-added">464     caller_saved.Insert(OptoReg::as_OptoReg(rdx-&gt;as_VMReg()));</span>
<span class="line-added">465     caller_saved.Insert(OptoReg::as_OptoReg(rsi-&gt;as_VMReg()));</span>
<span class="line-added">466     caller_saved.Insert(OptoReg::as_OptoReg(rdi-&gt;as_VMReg()));</span>
<span class="line-added">467     caller_saved.Insert(OptoReg::as_OptoReg(r8-&gt;as_VMReg()));</span>
<span class="line-added">468     caller_saved.Insert(OptoReg::as_OptoReg(r9-&gt;as_VMReg()));</span>
<span class="line-added">469     caller_saved.Insert(OptoReg::as_OptoReg(r10-&gt;as_VMReg()));</span>
<span class="line-added">470     caller_saved.Insert(OptoReg::as_OptoReg(r11-&gt;as_VMReg()));</span>
<span class="line-added">471     caller_saved.Remove(OptoReg::as_OptoReg(stub-&gt;ref()-&gt;as_VMReg()));</span>
472 
<span class="line-modified">473     // Create mask of live registers</span>
<span class="line-modified">474     RegMask live = stub-&gt;live();</span>
<span class="line-modified">475     if (stub-&gt;tmp() != noreg) {</span>
<span class="line-modified">476       live.Insert(OptoReg::as_OptoReg(stub-&gt;tmp()-&gt;as_VMReg()));</span>
<span class="line-added">477     }</span>
478 
<span class="line-modified">479     int gp_spill_size = 0;</span>
<span class="line-modified">480     int xmm_spill_size = 0;</span>
<span class="line-modified">481 </span>
<span class="line-modified">482     // Record registers that needs to be saved/restored</span>
<span class="line-modified">483     while (live.is_NotEmpty()) {</span>
<span class="line-modified">484       const OptoReg::Name opto_reg = live.find_first_elem();</span>
<span class="line-modified">485       const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);</span>
<span class="line-modified">486 </span>
<span class="line-modified">487       live.Remove(opto_reg);</span>
<span class="line-modified">488 </span>
<span class="line-modified">489       if (vm_reg-&gt;is_Register()) {</span>
<span class="line-modified">490         if (caller_saved.Member(opto_reg)) {</span>
<span class="line-modified">491           _gp_registers.append(vm_reg-&gt;as_Register());</span>
<span class="line-modified">492           gp_spill_size += 8;</span>
<span class="line-modified">493         }</span>
<span class="line-modified">494       } else if (vm_reg-&gt;is_XMMRegister()) {</span>
<span class="line-modified">495         // We encode in the low order 4 bits of the opto_reg, how large part of the register is live</span>
<span class="line-modified">496         const VMReg vm_reg_base = OptoReg::as_VMReg(opto_reg &amp; ~15);</span>
<span class="line-modified">497         const int reg_size = xmm_slot_size(opto_reg);</span>
<span class="line-modified">498         const XMMRegisterData reg_data = { vm_reg_base-&gt;as_XMMRegister(), reg_size };</span>
<span class="line-modified">499         const int reg_index = _xmm_registers.find(reg_data);</span>
<span class="line-added">500         if (reg_index == -1) {</span>
<span class="line-added">501           // Not previously appended</span>
<span class="line-added">502           _xmm_registers.append(reg_data);</span>
<span class="line-added">503           xmm_spill_size += reg_size;</span>
<span class="line-added">504         } else {</span>
<span class="line-added">505           // Previously appended, update size</span>
<span class="line-added">506           const int reg_size_prev = _xmm_registers.at(reg_index)._size;</span>
<span class="line-added">507           if (reg_size &gt; reg_size_prev) {</span>
<span class="line-added">508             _xmm_registers.at_put(reg_index, reg_data);</span>
<span class="line-added">509             xmm_spill_size += reg_size - reg_size_prev;</span>
<span class="line-added">510           }</span>
<span class="line-added">511         }</span>
<span class="line-added">512       } else {</span>
<span class="line-added">513         fatal(&quot;Unexpected register type&quot;);</span>
<span class="line-added">514       }</span>
<span class="line-added">515     }</span>
<span class="line-added">516 </span>
<span class="line-added">517     // Sort by size, largest first</span>
<span class="line-added">518     _xmm_registers.sort(xmm_compare_register_size);</span>
<span class="line-added">519 </span>
<span class="line-added">520     // On Windows, the caller reserves stack space for spilling register arguments</span>
<span class="line-added">521     const int arg_spill_size = frame::arg_reg_save_area_bytes;</span>
<span class="line-added">522 </span>
<span class="line-added">523     // Stack pointer must be 16 bytes aligned for the call</span>
<span class="line-added">524     _spill_offset = _spill_size = align_up(xmm_spill_size + gp_spill_size + arg_spill_size, 16);</span>
<span class="line-added">525   }</span>
<span class="line-added">526 </span>
<span class="line-added">527 public:</span>
<span class="line-added">528   ZSaveLiveRegisters(MacroAssembler* masm, ZLoadBarrierStubC2* stub) :</span>
<span class="line-added">529       _masm(masm),</span>
<span class="line-added">530       _gp_registers(),</span>
<span class="line-added">531       _xmm_registers(),</span>
<span class="line-added">532       _spill_size(0),</span>
<span class="line-added">533       _spill_offset(0) {</span>
<span class="line-added">534 </span>
<span class="line-added">535     //</span>
<span class="line-added">536     // Stack layout after registers have been spilled:</span>
<span class="line-added">537     //</span>
<span class="line-added">538     // | ...            | original rsp, 16 bytes aligned</span>
<span class="line-added">539     // ------------------</span>
<span class="line-added">540     // | zmm0 high      |</span>
<span class="line-added">541     // | ...            |</span>
<span class="line-added">542     // | zmm0 low       | 16 bytes aligned</span>
<span class="line-added">543     // | ...            |</span>
<span class="line-added">544     // | ymm1 high      |</span>
<span class="line-added">545     // | ...            |</span>
<span class="line-added">546     // | ymm1 low       | 16 bytes aligned</span>
<span class="line-added">547     // | ...            |</span>
<span class="line-added">548     // | xmmN high      |</span>
<span class="line-added">549     // | ...            |</span>
<span class="line-added">550     // | xmmN low       | 8 bytes aligned</span>
<span class="line-added">551     // | reg0           | 8 bytes aligned</span>
<span class="line-added">552     // | reg1           |</span>
<span class="line-added">553     // | ...            |</span>
<span class="line-added">554     // | regN           | new rsp, if 16 bytes aligned</span>
<span class="line-added">555     // | &lt;padding&gt;      | else new rsp, 16 bytes aligned</span>
<span class="line-added">556     // ------------------</span>
<span class="line-added">557     //</span>
<span class="line-added">558 </span>
<span class="line-added">559     // Figure out what registers to save/restore</span>
<span class="line-added">560     initialize(stub);</span>
<span class="line-added">561 </span>
<span class="line-added">562     // Allocate stack space</span>
<span class="line-added">563     if (_spill_size &gt; 0) {</span>
<span class="line-added">564       __ subptr(rsp, _spill_size);</span>
<span class="line-added">565     }</span>
<span class="line-added">566 </span>
<span class="line-added">567     // Save XMM/YMM/ZMM registers</span>
<span class="line-added">568     for (int i = 0; i &lt; _xmm_registers.length(); i++) {</span>
<span class="line-added">569       xmm_register_save(_xmm_registers.at(i));</span>
<span class="line-added">570     }</span>
<span class="line-added">571 </span>
<span class="line-added">572     if (xmm_needs_vzeroupper()) {</span>
<span class="line-added">573       __ vzeroupper();</span>
<span class="line-added">574     }</span>
<span class="line-added">575 </span>
<span class="line-added">576     // Save general purpose registers</span>
<span class="line-added">577     for (int i = 0; i &lt; _gp_registers.length(); i++) {</span>
<span class="line-added">578       gp_register_save(_gp_registers.at(i));</span>
<span class="line-added">579     }</span>
580   }
<span class="line-modified">581 </span>
<span class="line-modified">582   ~ZSaveLiveRegisters() {</span>
<span class="line-added">583     // Restore general purpose registers</span>
<span class="line-added">584     for (int i = _gp_registers.length() - 1; i &gt;= 0; i--) {</span>
<span class="line-added">585       gp_register_restore(_gp_registers.at(i));</span>
<span class="line-added">586     }</span>
<span class="line-added">587 </span>
<span class="line-added">588     __ vzeroupper();</span>
<span class="line-added">589 </span>
<span class="line-added">590     // Restore XMM/YMM/ZMM registers</span>
<span class="line-added">591     for (int i = _xmm_registers.length() - 1; i &gt;= 0; i--) {</span>
<span class="line-added">592       xmm_register_restore(_xmm_registers.at(i));</span>
<span class="line-added">593     }</span>
<span class="line-added">594 </span>
<span class="line-added">595     // Free stack space</span>
<span class="line-added">596     if (_spill_size &gt; 0) {</span>
<span class="line-added">597       __ addptr(rsp, _spill_size);</span>
<span class="line-added">598     }</span>
599   }
<span class="line-modified">600 };</span>
<span class="line-modified">601 </span>
<span class="line-added">602 class ZSetupArguments {</span>
<span class="line-added">603 private:</span>
<span class="line-added">604   MacroAssembler* const _masm;</span>
<span class="line-added">605   const Register        _ref;</span>
<span class="line-added">606   const Address         _ref_addr;</span>
<span class="line-added">607 </span>
<span class="line-added">608 public:</span>
<span class="line-added">609   ZSetupArguments(MacroAssembler* masm, ZLoadBarrierStubC2* stub) :</span>
<span class="line-added">610       _masm(masm),</span>
<span class="line-added">611       _ref(stub-&gt;ref()),</span>
<span class="line-added">612       _ref_addr(stub-&gt;ref_addr()) {</span>
<span class="line-added">613 </span>
<span class="line-added">614     // Setup arguments</span>
<span class="line-added">615     if (_ref_addr.base() == noreg) {</span>
<span class="line-added">616       // No self healing</span>
<span class="line-added">617       if (_ref != c_rarg0) {</span>
<span class="line-added">618         __ movq(c_rarg0, _ref);</span>
<span class="line-added">619       }</span>
<span class="line-added">620       __ xorq(c_rarg1, c_rarg1);</span>
<span class="line-added">621     } else {</span>
<span class="line-added">622       // Self healing</span>
<span class="line-added">623       if (_ref == c_rarg0) {</span>
<span class="line-added">624         __ lea(c_rarg1, _ref_addr);</span>
<span class="line-added">625       } else if (_ref != c_rarg1) {</span>
<span class="line-added">626         __ lea(c_rarg1, _ref_addr);</span>
<span class="line-added">627         __ movq(c_rarg0, _ref);</span>
<span class="line-added">628       } else if (_ref_addr.base() != c_rarg0 &amp;&amp; _ref_addr.index() != c_rarg0) {</span>
<span class="line-added">629         __ movq(c_rarg0, _ref);</span>
<span class="line-added">630         __ lea(c_rarg1, _ref_addr);</span>
<span class="line-added">631       } else {</span>
<span class="line-added">632         __ xchgq(c_rarg0, c_rarg1);</span>
<span class="line-added">633         if (_ref_addr.base() == c_rarg0) {</span>
<span class="line-added">634           __ lea(c_rarg1, Address(c_rarg1, _ref_addr.index(), _ref_addr.scale(), _ref_addr.disp()));</span>
<span class="line-added">635         } else if (_ref_addr.index() == c_rarg0) {</span>
<span class="line-added">636           __ lea(c_rarg1, Address(_ref_addr.base(), c_rarg1, _ref_addr.scale(), _ref_addr.disp()));</span>
<span class="line-added">637         } else {</span>
<span class="line-added">638           ShouldNotReachHere();</span>
<span class="line-added">639         }</span>
<span class="line-added">640       }</span>
<span class="line-added">641     }</span>
642   }
643 
<span class="line-modified">644   ~ZSetupArguments() {</span>
<span class="line-modified">645     // Transfer result</span>
<span class="line-modified">646     if (_ref != rax) {</span>
<span class="line-modified">647       __ movq(_ref, rax);</span>
<span class="line-added">648     }</span>
<span class="line-added">649   }</span>
<span class="line-added">650 };</span>
651 
652 #undef __
<span class="line-added">653 #define __ masm-&gt;</span>
654 
<span class="line-modified">655 void ZBarrierSetAssembler::generate_c2_load_barrier_stub(MacroAssembler* masm, ZLoadBarrierStubC2* stub) const {</span>
<span class="line-modified">656   BLOCK_COMMENT(&quot;ZLoadBarrierStubC2&quot;);</span>



657 
<span class="line-modified">658   // Stub entry</span>
<span class="line-modified">659   __ bind(*stub-&gt;entry());</span>
660 
<span class="line-modified">661   {</span>
<span class="line-modified">662     ZSaveLiveRegisters save_live_registers(masm, stub);</span>
<span class="line-modified">663     ZSetupArguments setup_arguments(masm, stub);</span>
<span class="line-added">664     __ call(RuntimeAddress(stub-&gt;slow_path()));</span>
665   }

666 
<span class="line-modified">667   // Stub exit</span>
<span class="line-modified">668   __ jmp(*stub-&gt;continuation());</span>

669 }
670 
<span class="line-modified">671 #undef __</span>


672 
<span class="line-modified">673 #endif // COMPILER2</span>


</pre>
</td>
</tr>
</table>
<center><a href="../shenandoah/shenandoah_x86_64.ad.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../index.html" target="_top">index</a> <a href="zBarrierSetAssembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>