<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/x86/gc/shared/barrierSetAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
<a name="1" id="anc1"></a><span class="line-modified">  2  * Copyright (c) 2018, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;gc/shared/barrierSet.hpp&quot;
 27 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
 28 #include &quot;gc/shared/barrierSetNMethod.hpp&quot;
 29 #include &quot;gc/shared/collectedHeap.hpp&quot;
 30 #include &quot;interpreter/interp_masm.hpp&quot;
<a name="2" id="anc2"></a>
 31 #include &quot;runtime/jniHandles.hpp&quot;
<a name="3" id="anc3"></a>
 32 #include &quot;runtime/thread.hpp&quot;
 33 
 34 #define __ masm-&gt;
 35 
 36 void BarrierSetAssembler::load_at(MacroAssembler* masm, DecoratorSet decorators, BasicType type,
 37                                   Register dst, Address src, Register tmp1, Register tmp_thread) {
 38   bool in_heap = (decorators &amp; IN_HEAP) != 0;
 39   bool in_native = (decorators &amp; IN_NATIVE) != 0;
 40   bool is_not_null = (decorators &amp; IS_NOT_NULL) != 0;
 41   bool atomic = (decorators &amp; MO_RELAXED) != 0;
 42 
 43   switch (type) {
 44   case T_OBJECT:
 45   case T_ARRAY: {
 46     if (in_heap) {
 47 #ifdef _LP64
 48       if (UseCompressedOops) {
 49         __ movl(dst, src);
 50         if (is_not_null) {
 51           __ decode_heap_oop_not_null(dst);
 52         } else {
 53           __ decode_heap_oop(dst);
 54         }
 55       } else
 56 #endif
 57       {
 58         __ movptr(dst, src);
 59       }
 60     } else {
 61       assert(in_native, &quot;why else?&quot;);
 62       __ movptr(dst, src);
 63     }
 64     break;
 65   }
 66   case T_BOOLEAN: __ load_unsigned_byte(dst, src);  break;
 67   case T_BYTE:    __ load_signed_byte(dst, src);    break;
 68   case T_CHAR:    __ load_unsigned_short(dst, src); break;
 69   case T_SHORT:   __ load_signed_short(dst, src);   break;
 70   case T_INT:     __ movl  (dst, src);              break;
 71   case T_ADDRESS: __ movptr(dst, src);              break;
 72   case T_FLOAT:
 73     assert(dst == noreg, &quot;only to ftos&quot;);
 74     __ load_float(src);
 75     break;
 76   case T_DOUBLE:
 77     assert(dst == noreg, &quot;only to dtos&quot;);
 78     __ load_double(src);
 79     break;
 80   case T_LONG:
 81     assert(dst == noreg, &quot;only to ltos&quot;);
 82 #ifdef _LP64
 83     __ movq(rax, src);
 84 #else
 85     if (atomic) {
 86       __ fild_d(src);               // Must load atomically
 87       __ subptr(rsp,2*wordSize);    // Make space for store
 88       __ fistp_d(Address(rsp,0));
 89       __ pop(rax);
 90       __ pop(rdx);
 91     } else {
 92       __ movl(rax, src);
 93       __ movl(rdx, src.plus_disp(wordSize));
 94     }
 95 #endif
 96     break;
 97   default: Unimplemented();
 98   }
 99 }
100 
101 void BarrierSetAssembler::store_at(MacroAssembler* masm, DecoratorSet decorators, BasicType type,
102                                    Address dst, Register val, Register tmp1, Register tmp2) {
103   bool in_heap = (decorators &amp; IN_HEAP) != 0;
104   bool in_native = (decorators &amp; IN_NATIVE) != 0;
105   bool is_not_null = (decorators &amp; IS_NOT_NULL) != 0;
106   bool atomic = (decorators &amp; MO_RELAXED) != 0;
107 
108   switch (type) {
109   case T_OBJECT:
110   case T_ARRAY: {
111     if (in_heap) {
112       if (val == noreg) {
113         assert(!is_not_null, &quot;inconsistent access&quot;);
114 #ifdef _LP64
115         if (UseCompressedOops) {
116           __ movl(dst, (int32_t)NULL_WORD);
117         } else {
118           __ movslq(dst, (int32_t)NULL_WORD);
119         }
120 #else
121         __ movl(dst, (int32_t)NULL_WORD);
122 #endif
123       } else {
124 #ifdef _LP64
125         if (UseCompressedOops) {
126           assert(!dst.uses(val), &quot;not enough registers&quot;);
127           if (is_not_null) {
128             __ encode_heap_oop_not_null(val);
129           } else {
130             __ encode_heap_oop(val);
131           }
132           __ movl(dst, val);
133         } else
134 #endif
135         {
136           __ movptr(dst, val);
137         }
138       }
139     } else {
140       assert(in_native, &quot;why else?&quot;);
141       assert(val != noreg, &quot;not supported&quot;);
142       __ movptr(dst, val);
143     }
144     break;
145   }
146   case T_BOOLEAN:
147     __ andl(val, 0x1);  // boolean is true if LSB is 1
148     __ movb(dst, val);
149     break;
150   case T_BYTE:
151     __ movb(dst, val);
152     break;
153   case T_SHORT:
154     __ movw(dst, val);
155     break;
156   case T_CHAR:
157     __ movw(dst, val);
158     break;
159   case T_INT:
160     __ movl(dst, val);
161     break;
162   case T_LONG:
163     assert(val == noreg, &quot;only tos&quot;);
164 #ifdef _LP64
165     __ movq(dst, rax);
166 #else
167     if (atomic) {
168       __ push(rdx);
169       __ push(rax);                 // Must update atomically with FIST
170       __ fild_d(Address(rsp,0));    // So load into FPU register
171       __ fistp_d(dst);              // and put into memory atomically
172       __ addptr(rsp, 2*wordSize);
173     } else {
174       __ movptr(dst, rax);
175       __ movptr(dst.plus_disp(wordSize), rdx);
176     }
177 #endif
178     break;
179   case T_FLOAT:
180     assert(val == noreg, &quot;only tos&quot;);
181     __ store_float(dst);
182     break;
183   case T_DOUBLE:
184     assert(val == noreg, &quot;only tos&quot;);
185     __ store_double(dst);
186     break;
187   case T_ADDRESS:
188     __ movptr(dst, val);
189     break;
190   default: Unimplemented();
191   }
192 }
193 
194 #ifndef _LP64
195 void BarrierSetAssembler::obj_equals(MacroAssembler* masm,
196                                      Address obj1, jobject obj2) {
197   __ cmpoop_raw(obj1, obj2);
198 }
199 
200 void BarrierSetAssembler::obj_equals(MacroAssembler* masm,
201                                      Register obj1, jobject obj2) {
202   __ cmpoop_raw(obj1, obj2);
203 }
204 #endif
205 void BarrierSetAssembler::obj_equals(MacroAssembler* masm,
206                                      Register obj1, Address obj2) {
207   __ cmpptr(obj1, obj2);
208 }
209 
210 void BarrierSetAssembler::obj_equals(MacroAssembler* masm,
211                                      Register obj1, Register obj2) {
212   __ cmpptr(obj1, obj2);
213 }
214 
215 void BarrierSetAssembler::try_resolve_jobject_in_native(MacroAssembler* masm, Register jni_env,
216                                                         Register obj, Register tmp, Label&amp; slowpath) {
217   __ clear_jweak_tag(obj);
218   __ movptr(obj, Address(obj, 0));
219 }
220 
221 void BarrierSetAssembler::tlab_allocate(MacroAssembler* masm,
222                                         Register thread, Register obj,
223                                         Register var_size_in_bytes,
224                                         int con_size_in_bytes,
225                                         Register t1,
226                                         Register t2,
227                                         Label&amp; slow_case) {
228   assert_different_registers(obj, t1, t2);
229   assert_different_registers(obj, var_size_in_bytes, t1);
230   Register end = t2;
231   if (!thread-&gt;is_valid()) {
232 #ifdef _LP64
233     thread = r15_thread;
234 #else
235     assert(t1-&gt;is_valid(), &quot;need temp reg&quot;);
236     thread = t1;
237     __ get_thread(thread);
238 #endif
239   }
240 
241   __ verify_tlab();
242 
243   __ movptr(obj, Address(thread, JavaThread::tlab_top_offset()));
244   if (var_size_in_bytes == noreg) {
245     __ lea(end, Address(obj, con_size_in_bytes));
246   } else {
247     __ lea(end, Address(obj, var_size_in_bytes, Address::times_1));
248   }
249   __ cmpptr(end, Address(thread, JavaThread::tlab_end_offset()));
250   __ jcc(Assembler::above, slow_case);
251 
252   // update the tlab top pointer
253   __ movptr(Address(thread, JavaThread::tlab_top_offset()), end);
254 
255   // recover var_size_in_bytes if necessary
256   if (var_size_in_bytes == end) {
257     __ subptr(var_size_in_bytes, obj);
258   }
259   __ verify_tlab();
260 }
261 
262 // Defines obj, preserves var_size_in_bytes
263 void BarrierSetAssembler::eden_allocate(MacroAssembler* masm,
264                                         Register thread, Register obj,
265                                         Register var_size_in_bytes,
266                                         int con_size_in_bytes,
267                                         Register t1,
268                                         Label&amp; slow_case) {
269   assert(obj == rax, &quot;obj must be in rax, for cmpxchg&quot;);
270   assert_different_registers(obj, var_size_in_bytes, t1);
271   if (!Universe::heap()-&gt;supports_inline_contig_alloc()) {
272     __ jmp(slow_case);
273   } else {
274     Register end = t1;
275     Label retry;
276     __ bind(retry);
277     ExternalAddress heap_top((address) Universe::heap()-&gt;top_addr());
278     __ movptr(obj, heap_top);
279     if (var_size_in_bytes == noreg) {
280       __ lea(end, Address(obj, con_size_in_bytes));
281     } else {
282       __ lea(end, Address(obj, var_size_in_bytes, Address::times_1));
283     }
284     // if end &lt; obj then we wrapped around =&gt; object too long =&gt; slow case
285     __ cmpptr(end, obj);
286     __ jcc(Assembler::below, slow_case);
287     __ cmpptr(end, ExternalAddress((address) Universe::heap()-&gt;end_addr()));
288     __ jcc(Assembler::above, slow_case);
289     // Compare obj with the top addr, and if still equal, store the new top addr in
290     // end at the address of the top addr pointer. Sets ZF if was equal, and clears
291     // it otherwise. Use lock prefix for atomicity on MPs.
292     __ locked_cmpxchgptr(end, heap_top);
293     __ jcc(Assembler::notEqual, retry);
294     incr_allocated_bytes(masm, thread, var_size_in_bytes, con_size_in_bytes, thread-&gt;is_valid() ? noreg : t1);
295   }
296 }
297 
298 void BarrierSetAssembler::incr_allocated_bytes(MacroAssembler* masm, Register thread,
299                                                Register var_size_in_bytes,
300                                                int con_size_in_bytes,
301                                                Register t1) {
302   if (!thread-&gt;is_valid()) {
303 #ifdef _LP64
304     thread = r15_thread;
305 #else
306     assert(t1-&gt;is_valid(), &quot;need temp reg&quot;);
307     thread = t1;
308     __ get_thread(thread);
309 #endif
310   }
311 
312 #ifdef _LP64
313   if (var_size_in_bytes-&gt;is_valid()) {
314     __ addq(Address(thread, in_bytes(JavaThread::allocated_bytes_offset())), var_size_in_bytes);
315   } else {
316     __ addq(Address(thread, in_bytes(JavaThread::allocated_bytes_offset())), con_size_in_bytes);
317   }
318 #else
319   if (var_size_in_bytes-&gt;is_valid()) {
320     __ addl(Address(thread, in_bytes(JavaThread::allocated_bytes_offset())), var_size_in_bytes);
321   } else {
322     __ addl(Address(thread, in_bytes(JavaThread::allocated_bytes_offset())), con_size_in_bytes);
323   }
324   __ adcl(Address(thread, in_bytes(JavaThread::allocated_bytes_offset())+4), 0);
325 #endif
326 }
327 
<a name="4" id="anc4"></a>
328 void BarrierSetAssembler::nmethod_entry_barrier(MacroAssembler* masm) {
329   BarrierSetNMethod* bs_nm = BarrierSet::barrier_set()-&gt;barrier_set_nmethod();
330   if (bs_nm == NULL) {
331     return;
332   }
<a name="5" id="anc5"></a><span class="line-removed">333 #ifndef _LP64</span>
<span class="line-removed">334   ShouldNotReachHere();</span>
<span class="line-removed">335 #else</span>
336   Label continuation;
<a name="6" id="anc6"></a><span class="line-modified">337   Register thread = LP64_ONLY(r15_thread);</span>
338   Address disarmed_addr(thread, in_bytes(bs_nm-&gt;thread_disarmed_offset()));
339   __ align(8);
340   __ cmpl(disarmed_addr, 0);
341   __ jcc(Assembler::equal, continuation);
342   __ call(RuntimeAddress(StubRoutines::x86::method_entry_barrier()));
343   __ bind(continuation);
<a name="7" id="anc7"></a>




































































344 #endif
345 }
<a name="8" id="anc8"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="8" type="hidden" />
</body>
</html>