<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff src/hotspot/cpu/arm/sharedRuntime_arm.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="relocInfo_arm.cpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_arm.cpp.udiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/arm/sharedRuntime_arm.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -1,7 +1,7 @@</span>
  /*
<span class="udiff-line-modified-removed">-  * Copyright (c) 2008, 2018, Oracle and/or its affiliates. All rights reserved.</span>
<span class="udiff-line-modified-added">+  * Copyright (c) 2008, 2020, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -30,13 +30,16 @@</span>
  #include &quot;code/vtableStubs.hpp&quot;
  #include &quot;interpreter/interpreter.hpp&quot;
  #include &quot;logging/log.hpp&quot;
  #include &quot;memory/resourceArea.hpp&quot;
  #include &quot;oops/compiledICHolder.hpp&quot;
<span class="udiff-line-added">+ #include &quot;oops/klass.inline.hpp&quot;</span>
  #include &quot;runtime/sharedRuntime.hpp&quot;
<span class="udiff-line-added">+ #include &quot;runtime/safepointMechanism.hpp&quot;</span>
  #include &quot;runtime/vframeArray.hpp&quot;
  #include &quot;utilities/align.hpp&quot;
<span class="udiff-line-added">+ #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  #include &quot;vmreg_arm.inline.hpp&quot;
  #ifdef COMPILER1
  #include &quot;c1/c1_Runtime1.hpp&quot;
  #endif
  #ifdef COMPILER2
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -129,18 +132,18 @@</span>
      __ push(RegisterSet(FP) | RegisterSet(LR));
    }
    __ push(SAVED_BASE_REGS);
    if (HaveVFP) {
      if (VM_Version::has_vfp3_32()) {
<span class="udiff-line-modified-removed">-       __ fstmdbd(SP, FloatRegisterSet(D16, 16), writeback);</span>
<span class="udiff-line-modified-added">+       __ fpush(FloatRegisterSet(D16, 16));</span>
      } else {
        if (FloatRegisterImpl::number_of_registers &gt; 32) {
          assert(FloatRegisterImpl::number_of_registers == 64, &quot;nb fp registers should be 64&quot;);
          __ sub(SP, SP, 32 * wordSize);
        }
      }
<span class="udiff-line-modified-removed">-     __ fstmdbd(SP, FloatRegisterSet(D0, 16), writeback);</span>
<span class="udiff-line-modified-added">+     __ fpush(FloatRegisterSet(D0, 16));</span>
    } else {
      __ sub(SP, SP, fpu_save_size * wordSize);
    }
  
    int i;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -170,13 +173,13 @@</span>
    return map;
  }
  
  void RegisterSaver::restore_live_registers(MacroAssembler* masm, bool restore_lr) {
    if (HaveVFP) {
<span class="udiff-line-modified-removed">-     __ fldmiad(SP, FloatRegisterSet(D0, 16), writeback);</span>
<span class="udiff-line-modified-added">+     __ fpop(FloatRegisterSet(D0, 16));</span>
      if (VM_Version::has_vfp3_32()) {
<span class="udiff-line-modified-removed">-       __ fldmiad(SP, FloatRegisterSet(D16, 16), writeback);</span>
<span class="udiff-line-modified-added">+       __ fpop(FloatRegisterSet(D16, 16));</span>
      } else {
        if (FloatRegisterImpl::number_of_registers &gt; 32) {
          assert(FloatRegisterImpl::number_of_registers == 64, &quot;nb fp registers should be 64&quot;);
          __ add(SP, SP, 32 * wordSize);
        }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -217,30 +220,25 @@</span>
  
  static void push_param_registers(MacroAssembler* masm, int fp_regs_in_arguments) {
    // R1-R3 arguments need to be saved, but we push 4 registers for 8-byte alignment
    __ push(RegisterSet(R0, R3));
  
<span class="udiff-line-removed">- #ifdef __ABI_HARD__</span>
    // preserve arguments
    // Likely not needed as the locking code won&#39;t probably modify volatile FP registers,
    // but there is no way to guarantee that
    if (fp_regs_in_arguments) {
      // convert fp_regs_in_arguments to a number of double registers
      int double_regs_num = (fp_regs_in_arguments + 1) &gt;&gt; 1;
<span class="udiff-line-modified-removed">-     __ fstmdbd(SP, FloatRegisterSet(D0, double_regs_num), writeback);</span>
<span class="udiff-line-modified-added">+     __ fpush_hardfp(FloatRegisterSet(D0, double_regs_num));</span>
    }
<span class="udiff-line-removed">- #endif // __ ABI_HARD__</span>
  }
  
  static void pop_param_registers(MacroAssembler* masm, int fp_regs_in_arguments) {
<span class="udiff-line-removed">- #ifdef __ABI_HARD__</span>
    if (fp_regs_in_arguments) {
      int double_regs_num = (fp_regs_in_arguments + 1) &gt;&gt; 1;
<span class="udiff-line-modified-removed">-     __ fldmiad(SP, FloatRegisterSet(D0, double_regs_num), writeback);</span>
<span class="udiff-line-modified-added">+     __ fpop_hardfp(FloatRegisterSet(D0, double_regs_num));</span>
    }
<span class="udiff-line-removed">- #endif // __ABI_HARD__</span>
<span class="udiff-line-removed">- </span>
    __ pop(RegisterSet(R0, R3));
  }
  
  
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -458,15 +456,17 @@</span>
    __ cbz(Rtemp, skip);
  
    // Pushing an even number of registers for stack alignment.
    // Selecting R9, which had to be saved anyway for some platforms.
    __ push(RegisterSet(R0, R3) | R9 | LR);
<span class="udiff-line-added">+   __ fpush_hardfp(FloatRegisterSet(D0, 8));</span>
  
    __ mov(R0, Rmethod);
    __ mov(R1, LR);
    __ call(CAST_FROM_FN_PTR(address, SharedRuntime::fixup_callers_callsite));
  
<span class="udiff-line-added">+   __ fpop_hardfp(FloatRegisterSet(D0, 8));</span>
    __ pop(RegisterSet(R0, R3) | R9 | LR);
  
    __ bind(skip);
  }
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -750,11 +750,12 @@</span>
  nmethod* SharedRuntime::generate_native_wrapper(MacroAssembler* masm,
                                                  const methodHandle&amp; method,
                                                  int compile_id,
                                                  BasicType* in_sig_bt,
                                                  VMRegPair* in_regs,
<span class="udiff-line-modified-removed">-                                                 BasicType ret_type) {</span>
<span class="udiff-line-modified-added">+                                                 BasicType ret_type,</span>
<span class="udiff-line-added">+                                                 address critical_entry) {</span>
    if (method-&gt;is_method_handle_intrinsic()) {
      vmIntrinsics::ID iid = method-&gt;intrinsic_id();
      intptr_t start = (intptr_t)__ pc();
      int vep_offset = ((intptr_t)__ pc()) - start;
      gen_special_dispatch(masm,
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -858,20 +859,20 @@</span>
        __ bx(LR, eq);
      }
  
      __ ldr(Rtemp, Address(obj_reg, oopDesc::mark_offset_in_bytes()));
  
<span class="udiff-line-modified-removed">-     assert(markOopDesc::unlocked_value == 1, &quot;adjust this code&quot;);</span>
<span class="udiff-line-modified-removed">-     __ tbz(Rtemp, exact_log2(markOopDesc::unlocked_value), slow_case);</span>
<span class="udiff-line-modified-added">+     assert(markWord::unlocked_value == 1, &quot;adjust this code&quot;);</span>
<span class="udiff-line-modified-added">+     __ tbz(Rtemp, exact_log2(markWord::unlocked_value), slow_case);</span>
  
      if (UseBiasedLocking) {
<span class="udiff-line-modified-removed">-       assert(is_power_of_2(markOopDesc::biased_lock_bit_in_place), &quot;adjust this code&quot;);</span>
<span class="udiff-line-modified-removed">-       __ tbnz(Rtemp, exact_log2(markOopDesc::biased_lock_bit_in_place), slow_case);</span>
<span class="udiff-line-modified-added">+       assert(is_power_of_2(markWord::biased_lock_bit_in_place), &quot;adjust this code&quot;);</span>
<span class="udiff-line-modified-added">+       __ tbnz(Rtemp, exact_log2(markWord::biased_lock_bit_in_place), slow_case);</span>
      }
  
<span class="udiff-line-modified-removed">-     __ bics(Rtemp, Rtemp, ~markOopDesc::hash_mask_in_place);</span>
<span class="udiff-line-modified-removed">-     __ mov(R0, AsmOperand(Rtemp, lsr, markOopDesc::hash_shift), ne);</span>
<span class="udiff-line-modified-added">+     __ bics(Rtemp, Rtemp, ~markWord::hash_mask_in_place);</span>
<span class="udiff-line-modified-added">+     __ mov(R0, AsmOperand(Rtemp, lsr, markWord::hash_shift), ne);</span>
      __ bx(LR, ne);
  
      __ bind(slow_case);
    }
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1169,11 +1170,11 @@</span>
      // On MP platforms the next load could return a &#39;stale&#39; value if the memory location has been modified by another thread.
      // That would be acceptable as either CAS or slow case path is taken in that case
  
      __ ldr(mark, Address(sync_obj, oopDesc::mark_offset_in_bytes()));
      __ sub(disp_hdr, FP, lock_slot_fp_offset);
<span class="udiff-line-modified-removed">-     __ tst(mark, markOopDesc::unlocked_value);</span>
<span class="udiff-line-modified-added">+     __ tst(mark, markWord::unlocked_value);</span>
      __ b(fast_lock, ne);
  
      // Check for recursive lock
      // See comments in InterpreterMacroAssembler::lock_object for
      // explanations on the fast recursive locking check.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1215,24 +1216,22 @@</span>
    if (ret_type == T_BOOLEAN) {
      __ c2bool(R0);
    }
  
    // Do a safepoint check while thread is in transition state
<span class="udiff-line-removed">-   InlinedAddress safepoint_state(SafepointSynchronize::address_of_state());</span>
    Label call_safepoint_runtime, return_to_java;
    __ mov(Rtemp, _thread_in_native_trans);
<span class="udiff-line-removed">-   __ ldr_literal(R2, safepoint_state);</span>
    __ str_32(Rtemp, Address(Rthread, JavaThread::thread_state_offset()));
  
    // make sure the store is observed before reading the SafepointSynchronize state and further mem refs
    __ membar(MacroAssembler::Membar_mask_bits(MacroAssembler::StoreLoad | MacroAssembler::StoreStore), Rtemp);
  
<span class="udiff-line-modified-removed">-   __ ldr_s32(R2, Address(R2));</span>
<span class="udiff-line-modified-added">+   __ safepoint_poll(R2, call_safepoint_runtime);</span>
    __ ldr_u32(R3, Address(Rthread, JavaThread::suspend_flags_offset()));
<span class="udiff-line-modified-removed">-   __ cmp(R2, SafepointSynchronize::_not_synchronized);</span>
<span class="udiff-line-removed">-   __ cond_cmp(R3, 0, eq);</span>
<span class="udiff-line-modified-added">+   __ cmp(R3, 0);</span>
    __ b(call_safepoint_runtime, ne);
<span class="udiff-line-added">+ </span>
    __ bind(return_to_java);
  
    // Perform thread state transition and reguard stack yellow pages if needed
    Label reguard, reguard_done;
    __ mov(Rtemp, _thread_in_Java);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1299,12 +1298,10 @@</span>
    __ mov(R0, Rthread);
    __ call(CAST_FROM_FN_PTR(address, JavaThread::check_special_condition_for_native_trans));
    pop_result_registers(masm, ret_type);
    __ b(return_to_java);
  
<span class="udiff-line-removed">-   __ bind_literal(safepoint_state);</span>
<span class="udiff-line-removed">- </span>
    // Reguard stack pages. Save native results around a call to C runtime.
    __ bind(reguard);
    push_result_registers(masm, ret_type);
    __ call(CAST_FROM_FN_PTR(address, SharedRuntime::reguard_yellow_pages));
    pop_result_registers(masm, ret_type);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1802,19 +1799,33 @@</span>
      pc_offset = __ offset();
    }
    oop_maps-&gt;add_gc_map(pc_offset, map);
    __ reset_last_Java_frame(Rtemp); // Rtemp free since scratched by far call
  
<span class="udiff-line-removed">-   // Check for pending exception</span>
<span class="udiff-line-removed">-   __ ldr(Rtemp, Address(Rthread, Thread::pending_exception_offset()));</span>
<span class="udiff-line-removed">-   __ cmp(Rtemp, 0);</span>
<span class="udiff-line-removed">- </span>
    if (!cause_return) {
<span class="udiff-line-added">+     if (SafepointMechanism::uses_thread_local_poll()) {</span>
<span class="udiff-line-added">+       // If our stashed return pc was modified by the runtime we avoid touching it</span>
<span class="udiff-line-added">+       __ ldr(R3_tmp, Address(Rthread, JavaThread::saved_exception_pc_offset()));</span>
<span class="udiff-line-added">+       __ ldr(R2_tmp, Address(SP, RegisterSaver::LR_offset * wordSize));</span>
<span class="udiff-line-added">+       __ cmp(R2_tmp, R3_tmp);</span>
<span class="udiff-line-added">+       // Adjust return pc forward to step over the safepoint poll instruction</span>
<span class="udiff-line-added">+       __ add(R2_tmp, R2_tmp, 4, eq);</span>
<span class="udiff-line-added">+       __ str(R2_tmp, Address(SP, RegisterSaver::LR_offset * wordSize), eq);</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // Check for pending exception</span>
<span class="udiff-line-added">+     __ ldr(Rtemp, Address(Rthread, Thread::pending_exception_offset()));</span>
<span class="udiff-line-added">+     __ cmp(Rtemp, 0);</span>
<span class="udiff-line-added">+ </span>
      RegisterSaver::restore_live_registers(masm, false);
      __ pop(PC, eq);
      __ pop(Rexception_pc);
    } else {
<span class="udiff-line-added">+     // Check for pending exception</span>
<span class="udiff-line-added">+     __ ldr(Rtemp, Address(Rthread, Thread::pending_exception_offset()));</span>
<span class="udiff-line-added">+     __ cmp(Rtemp, 0);</span>
<span class="udiff-line-added">+ </span>
      RegisterSaver::restore_live_registers(masm);
      __ bx(LR, eq);
      __ mov(Rexception_pc, LR);
    }
  
</pre>
<center><a href="relocInfo_arm.cpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_arm.cpp.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>