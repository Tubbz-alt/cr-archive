diff a/src/hotspot/cpu/arm/macroAssembler_arm.cpp b/src/hotspot/cpu/arm/macroAssembler_arm.cpp
--- a/src/hotspot/cpu/arm/macroAssembler_arm.cpp
+++ b/src/hotspot/cpu/arm/macroAssembler_arm.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2008, 2018, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2008, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -44,10 +44,11 @@
 #include "runtime/objectMonitor.hpp"
 #include "runtime/os.hpp"
 #include "runtime/sharedRuntime.hpp"
 #include "runtime/stubRoutines.hpp"
 #include "utilities/macros.hpp"
+#include "utilities/powerOfTwo.hpp"
 
 // Implementation of AddressLiteral
 
 void AddressLiteral::set_rspec(relocInfo::relocType rtype) {
   switch (rtype) {
@@ -1343,11 +1344,11 @@
   if (PrintBiasedLockingStatistics && (counters == NULL)) {
     counters = BiasedLocking::counters();
   }
 #endif
 
-  assert(markOopDesc::age_shift == markOopDesc::lock_bits + markOopDesc::biased_lock_bits, "biased locking makes assumptions about bit layout");
+  assert(markWord::age_shift == markWord::lock_bits + markWord::biased_lock_bits, "biased locking makes assumptions about bit layout");
   Address mark_addr(obj_reg, oopDesc::mark_offset_in_bytes());
 
   // Biased locking
   // See whether the lock is currently biased toward our thread and
   // whether the epoch is still valid
@@ -1365,23 +1366,23 @@
   }
 
   // On MP platform loads could return 'stale' values in some cases.
   // That is acceptable since either CAS or slow case path is taken in the worst case.
 
-  andr(tmp_reg, swap_reg, (uintx)markOopDesc::biased_lock_mask_in_place);
-  cmp(tmp_reg, markOopDesc::biased_lock_pattern);
+  andr(tmp_reg, swap_reg, markWord::biased_lock_mask_in_place);
+  cmp(tmp_reg, markWord::biased_lock_pattern);
 
   b(cas_label, ne);
 
   // The bias pattern is present in the object's header. Need to check
   // whether the bias owner and the epoch are both still current.
   load_klass(tmp_reg, obj_reg);
   ldr(tmp_reg, Address(tmp_reg, Klass::prototype_header_offset()));
   orr(tmp_reg, tmp_reg, Rthread);
   eor(tmp_reg, tmp_reg, swap_reg);
 
-  bics(tmp_reg, tmp_reg, ((int) markOopDesc::age_mask_in_place));
+  bics(tmp_reg, tmp_reg, ((int) markWord::age_mask_in_place));
 
 #ifndef PRODUCT
   if (counters != NULL) {
     cond_atomic_inc32(eq, counters->biased_lock_entry_count_addr());
   }
@@ -1399,11 +1400,11 @@
   // header.
 
   // If the low three bits in the xor result aren't clear, that means
   // the prototype header is no longer biased and we have to revoke
   // the bias on this object.
-  tst(tmp_reg, (uintx)markOopDesc::biased_lock_mask_in_place);
+  tst(tmp_reg, markWord::biased_lock_mask_in_place);
   b(try_revoke_bias, ne);
 
   // Biasing is still enabled for this data type. See whether the
   // epoch of the current bias is still valid, meaning that the epoch
   // bits of the mark word are equal to the epoch bits of the
@@ -1411,11 +1412,11 @@
   // only change at a safepoint.) If not, attempt to rebias the object
   // toward the current thread. Note that we must be absolutely sure
   // that the current epoch is invalid in order to do this because
   // otherwise the manipulations it performs on the mark word are
   // illegal.
-  tst(tmp_reg, (uintx)markOopDesc::epoch_mask_in_place);
+  tst(tmp_reg, markWord::epoch_mask_in_place);
   b(try_rebias, ne);
 
   // tmp_reg has the age, epoch and pattern bits cleared
   // The remaining (owner) bits are (Thread ^ current_owner)
 
@@ -1429,14 +1430,14 @@
   // Note that we know the owner is not ourself. Hence, success can
   // only happen when the owner bits is 0
 
   // until the assembler can be made smarter, we need to make some assumptions about the values
   // so we can optimize this:
-  assert((markOopDesc::biased_lock_mask_in_place | markOopDesc::age_mask_in_place | markOopDesc::epoch_mask_in_place) == 0x1ff, "biased bitmasks changed");
+  assert((markWord::biased_lock_mask_in_place | markWord::age_mask_in_place | markWord::epoch_mask_in_place) == 0x1ff, "biased bitmasks changed");
 
   mov(swap_reg, AsmOperand(swap_reg, lsl, 23));
-  mov(swap_reg, AsmOperand(swap_reg, lsr, 23)); // markOop with thread bits cleared (for CAS)
+  mov(swap_reg, AsmOperand(swap_reg, lsr, 23)); // markWord with thread bits cleared (for CAS)
 
   orr(tmp_reg, swap_reg, Rthread); // new mark
 
   biased_locking_enter_with_cas(obj_reg, swap_reg, tmp_reg, tmp2, slow_case,
         (counters != NULL) ? counters->anonymously_biased_lock_entry_count_addr() : NULL);
@@ -1517,12 +1518,12 @@
   // a higher level. Second, if the bias was revoked while we held the
   // lock, the object could not be rebiased toward another thread, so
   // the bias bit would be clear.
   ldr(tmp_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));
 
-  andr(tmp_reg, tmp_reg, (uintx)markOopDesc::biased_lock_mask_in_place);
-  cmp(tmp_reg, markOopDesc::biased_lock_pattern);
+  andr(tmp_reg, tmp_reg, markWord::biased_lock_mask_in_place);
+  cmp(tmp_reg, markWord::biased_lock_pattern);
   b(done, eq);
 }
 
 
 void MacroAssembler::resolve_jobject(Register value,
@@ -1991,11 +1992,11 @@
   }
 
   // Invariant: Rmark loaded below does not contain biased lock pattern
 
   ldr(Rmark, Address(Roop, oopDesc::mark_offset_in_bytes()));
-  tst(Rmark, markOopDesc::unlocked_value);
+  tst(Rmark, markWord::unlocked_value);
   b(fast_lock, ne);
 
   // Check for recursive lock
   // See comments in InterpreterMacroAssembler::lock_object for
   // explanations on the fast recursive locking check.
@@ -2051,6 +2052,34 @@
   cas_for_lock_release(Rmark, Rbox, Roop, Rscratch, done, allow_fallthrough_on_failure, one_shot);
 
   bind(done);
 
 }
+
+void MacroAssembler::safepoint_poll(Register tmp1, Label& slow_path) {
+  if (SafepointMechanism::uses_thread_local_poll()) {
+    ldr_u32(tmp1, Address(Rthread, Thread::polling_page_offset()));
+    tst(tmp1, exact_log2(SafepointMechanism::poll_bit()));
+    b(slow_path, eq);
+  } else {
+    ldr_global_s32(tmp1, SafepointSynchronize::address_of_state());
+    cmp(tmp1, SafepointSynchronize::_not_synchronized);
+    b(slow_path, ne);
+  }
+}
+
+void MacroAssembler::get_polling_page(Register dest) {
+  if (SafepointMechanism::uses_thread_local_poll()) {
+    ldr(dest, Address(Rthread, Thread::polling_page_offset()));
+  } else {
+    mov_address(dest, os::get_polling_page());
+  }
+}
+
+void MacroAssembler::read_polling_page(Register dest, relocInfo::relocType rtype) {
+  get_polling_page(dest);
+  relocate(rtype);
+  ldr(dest, Address(dest));
+}
+
+
 #endif // COMPILER2
