<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/arm/vtableStubs_arm.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
<a name="1" id="anc1"></a><span class="line-modified">  2  * Copyright (c) 2008, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;asm/assembler.hpp&quot;
 27 #include &quot;asm/macroAssembler.inline.hpp&quot;
 28 #include &quot;assembler_arm.inline.hpp&quot;
 29 #include &quot;code/vtableStubs.hpp&quot;
 30 #include &quot;interp_masm_arm.hpp&quot;
 31 #include &quot;memory/resourceArea.hpp&quot;
 32 #include &quot;oops/compiledICHolder.hpp&quot;
 33 #include &quot;oops/instanceKlass.hpp&quot;
 34 #include &quot;oops/klassVtable.hpp&quot;
<a name="2" id="anc2"></a><span class="line-added"> 35 #include &quot;oops/klass.inline.hpp&quot;</span>
 36 #include &quot;runtime/sharedRuntime.hpp&quot;
 37 #include &quot;vmreg_arm.inline.hpp&quot;
 38 #ifdef COMPILER2
 39 #include &quot;opto/runtime.hpp&quot;
 40 #endif
 41 
 42 // machine-dependent part of VtableStubs: create VtableStub of correct size and
 43 // initialize its code
 44 
 45 #define __ masm-&gt;
 46 
 47 #ifndef PRODUCT
 48 extern &quot;C&quot; void bad_compiled_vtable_index(JavaThread* thread, oop receiver, int index);
 49 #endif
 50 
 51 VtableStub* VtableStubs::create_vtable_stub(int vtable_index) {
 52   // Read &quot;A word on VtableStub sizing&quot; in share/code/vtableStubs.hpp for details on stub sizing.
 53   const int stub_code_length = code_size_limit(true);
 54   VtableStub* s = new(stub_code_length) VtableStub(true, vtable_index);
 55   // Can be NULL if there is no free space in the code cache.
 56   if (s == NULL) {
 57     return NULL;
 58   }
 59 
 60   // Count unused bytes in instruction sequences of variable size.
 61   // We add them to the computed buffer size in order to avoid
 62   // overflow in subsequently generated stubs.
 63   address   start_pc;
 64   int       slop_bytes = 0;
 65   int       slop_delta = 0;
 66 
 67   ResourceMark    rm;
 68   CodeBuffer      cb(s-&gt;entry_point(), stub_code_length);
 69   MacroAssembler* masm = new MacroAssembler(&amp;cb);
 70 
 71 #if (!defined(PRODUCT) &amp;&amp; defined(COMPILER2))
 72   if (CountCompiledCalls) {
 73     // Implementation required?
 74   }
 75 #endif
 76 
 77   assert(VtableStub::receiver_location() == R0-&gt;as_VMReg(), &quot;receiver expected in R0&quot;);
 78 
 79   const Register tmp = Rtemp; // Rtemp OK, should be free at call sites
 80 
 81   address npe_addr = __ pc();
 82   __ load_klass(tmp, R0);
 83 
 84 #ifndef PRODUCT
 85   if (DebugVtables) {
 86     // Implementation required?
 87   }
 88 #endif
 89 
 90   start_pc = __ pc();
 91   { // lookup virtual method
 92     int entry_offset = in_bytes(Klass::vtable_start_offset()) + vtable_index * vtableEntry::size_in_bytes();
 93     int method_offset = vtableEntry::method_offset_in_bytes() + entry_offset;
 94 
 95     assert ((method_offset &amp; (wordSize - 1)) == 0, &quot;offset should be aligned&quot;);
 96     int offset_mask = 0xfff;
 97     if (method_offset &amp; ~offset_mask) {
 98       __ add(tmp, tmp, method_offset &amp; ~offset_mask);
 99     }
100     __ ldr(Rmethod, Address(tmp, method_offset &amp; offset_mask));
101   }
102   slop_delta  = 8 - (int)(__ pc() - start_pc);
103   slop_bytes += slop_delta;
104   assert(slop_delta &gt;= 0, &quot;negative slop(%d) encountered, adjust code size estimate!&quot;, slop_delta);
105 
106 #ifndef PRODUCT
107   if (DebugVtables) {
108     // Implementation required?
109   }
110 #endif
111 
112   address ame_addr = __ pc();
113   __ ldr(PC, Address(Rmethod, Method::from_compiled_offset()));
114 
115   masm-&gt;flush();
116   bookkeeping(masm, tty, s, npe_addr, ame_addr, true, vtable_index, slop_bytes, 0);
117 
118   return s;
119 }
120 
121 VtableStub* VtableStubs::create_itable_stub(int itable_index) {
122   // Read &quot;A word on VtableStub sizing&quot; in share/code/vtableStubs.hpp for details on stub sizing.
123   const int stub_code_length = code_size_limit(false);
124   VtableStub* s = new(stub_code_length) VtableStub(false, itable_index);
125   // Can be NULL if there is no free space in the code cache.
126   if (s == NULL) {
127     return NULL;
128   }
129   // Count unused bytes in instruction sequences of variable size.
130   // We add them to the computed buffer size in order to avoid
131   // overflow in subsequently generated stubs.
132   address   start_pc;
133   int       slop_bytes = 0;
134   int       slop_delta = 0;
135 
136   ResourceMark    rm;
137   CodeBuffer      cb(s-&gt;entry_point(), stub_code_length);
138   MacroAssembler* masm = new MacroAssembler(&amp;cb);
139 
140 #if (!defined(PRODUCT) &amp;&amp; defined(COMPILER2))
141   if (CountCompiledCalls) {
142     // Implementation required?
143   }
144 #endif
145 
146   assert(VtableStub::receiver_location() == R0-&gt;as_VMReg(), &quot;receiver expected in R0&quot;);
147 
148   // R0-R3 / R0-R7 registers hold the arguments and cannot be spoiled
149   const Register Rclass  = R4;
150   const Register Rintf   = R5;
151   const Register Rscan   = R6;
152 
153   Label L_no_such_interface;
154 
155   assert_different_registers(Ricklass, Rclass, Rintf, Rscan, Rtemp);
156 
157   start_pc = __ pc();
158 
159   // get receiver klass (also an implicit null-check)
160   address npe_addr = __ pc();
161   __ load_klass(Rclass, R0);
162 
163   // Receiver subtype check against REFC.
164   __ ldr(Rintf, Address(Ricklass, CompiledICHolder::holder_klass_offset()));
165   __ lookup_interface_method(// inputs: rec. class, interface, itable index
166                              Rclass, Rintf, noreg,
167                              // outputs: temp reg1, temp reg2
168                              noreg, Rscan, Rtemp,
169                              L_no_such_interface);
170 
171   const ptrdiff_t  typecheckSize = __ pc() - start_pc;
172   start_pc = __ pc();
173 
174   // Get Method* and entry point for compiler
175   __ ldr(Rintf, Address(Ricklass, CompiledICHolder::holder_metadata_offset()));
176   __ lookup_interface_method(// inputs: rec. class, interface, itable index
177                              Rclass, Rintf, itable_index,
178                              // outputs: temp reg1, temp reg2, temp reg3
179                              Rmethod, Rscan, Rtemp,
180                              L_no_such_interface);
181 
182   const ptrdiff_t lookupSize = __ pc() - start_pc;
183 
184   // Reduce &quot;estimate&quot; such that &quot;padding&quot; does not drop below 8.
185   const ptrdiff_t estimate = 140;
186   const ptrdiff_t codesize = typecheckSize + lookupSize;
187   slop_delta  = (int)(estimate - codesize);
188   slop_bytes += slop_delta;
189   assert(slop_delta &gt;= 0, &quot;itable #%d: Code size estimate (%d) for lookup_interface_method too small, required: %d&quot;, itable_index, (int)estimate, (int)codesize);
190 
191 #ifndef PRODUCT
192   if (DebugVtables) {
193     // Implementation required?
194   }
195 #endif
196 
197   address ame_addr = __ pc();
198 
199   __ ldr(PC, Address(Rmethod, Method::from_compiled_offset()));
200 
201   __ bind(L_no_such_interface);
202   // Handle IncompatibleClassChangeError in itable stubs.
203   // More detailed error message.
204   // We force resolving of the call site by jumping to the &quot;handle
205   // wrong method&quot; stub, and so let the interpreter runtime do all the
206   // dirty work.
207   assert(SharedRuntime::get_handle_wrong_method_stub() != NULL, &quot;check initialization order&quot;);
208   __ jump(SharedRuntime::get_handle_wrong_method_stub(), relocInfo::runtime_call_type, Rtemp);
209 
210   masm-&gt;flush();
211   bookkeeping(masm, tty, s, npe_addr, ame_addr, false, itable_index, slop_bytes, 0);
212 
213   return s;
214 }
215 
216 int VtableStub::pd_code_alignment() {
217   // ARM32 cache line size is not an architected constant. We just align on word size.
218   const unsigned int icache_line_size = wordSize;
219   return icache_line_size;
220 }
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="3" type="hidden" />
</body>
</html>