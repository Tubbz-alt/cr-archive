<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/arm/c1_LIRGenerator_arm.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_LIRAssembler_arm.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_MacroAssembler_arm.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/arm/c1_LIRGenerator_arm.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/macroAssembler.inline.hpp&quot;
  27 #include &quot;c1/c1_Compilation.hpp&quot;
  28 #include &quot;c1/c1_FrameMap.hpp&quot;
  29 #include &quot;c1/c1_Instruction.hpp&quot;
  30 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  31 #include &quot;c1/c1_LIRGenerator.hpp&quot;
  32 #include &quot;c1/c1_Runtime1.hpp&quot;
  33 #include &quot;c1/c1_ValueStack.hpp&quot;
  34 #include &quot;ci/ciArray.hpp&quot;
  35 #include &quot;ci/ciObjArrayKlass.hpp&quot;
  36 #include &quot;ci/ciTypeArrayKlass.hpp&quot;
  37 #include &quot;ci/ciUtilities.hpp&quot;
  38 #include &quot;gc/shared/c1/barrierSetC1.hpp&quot;
  39 #include &quot;gc/shared/cardTable.hpp&quot;
  40 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  41 #include &quot;runtime/sharedRuntime.hpp&quot;
  42 #include &quot;runtime/stubRoutines.hpp&quot;

  43 #include &quot;vmreg_arm.inline.hpp&quot;
  44 
  45 #ifdef ASSERT
  46 #define __ gen()-&gt;lir(__FILE__, __LINE__)-&gt;
  47 #else
  48 #define __ gen()-&gt;lir()-&gt;
  49 #endif
  50 
  51 void LIRItem::load_byte_item() {
  52   load_item();
  53 }
  54 
  55 void LIRItem::load_nonconstant() {
  56   LIR_Opr r = value()-&gt;operand();
  57   if (_gen-&gt;can_inline_as_constant(value())) {
  58     if (!r-&gt;is_constant()) {
  59       r = LIR_OprFact::value_type(value()-&gt;type());
  60     }
  61     _result = r;
  62   } else {
</pre>
<hr />
<pre>
 757   new_value.load_item();
 758   cmp_value.load_item();
 759   LIR_Opr result = new_register(T_INT);
 760   if (type == T_OBJECT || type == T_ARRAY) {
 761     __ cas_obj(addr, cmp_value.result(), new_value.result(), new_register(T_INT), new_register(T_INT), result);
 762   } else if (type == T_INT) {
 763     __ cas_int(addr-&gt;as_address_ptr()-&gt;base(), cmp_value.result(), new_value.result(), tmp1, tmp1, result);
 764   } else if (type == T_LONG) {
 765     tmp1 = new_register(T_LONG);
 766     __ cas_long(addr-&gt;as_address_ptr()-&gt;base(), cmp_value.result(), new_value.result(), tmp1, tmp2, result);
 767   } else {
 768     ShouldNotReachHere();
 769   }
 770   return result;
 771 }
 772 
 773 LIR_Opr LIRGenerator::atomic_xchg(BasicType type, LIR_Opr addr, LIRItem&amp; value) {
 774   bool is_oop = type == T_OBJECT || type == T_ARRAY;
 775   LIR_Opr result = new_register(type);
 776   value.load_item();
<span class="line-modified"> 777   assert(type == T_INT || is_oop LP64_ONLY( || type == T_LONG ), &quot;unexpected type&quot;);</span>
 778   LIR_Opr tmp = (UseCompressedOops &amp;&amp; is_oop) ? new_pointer_register() : LIR_OprFact::illegalOpr;
 779   __ xchg(addr, value.result(), result, tmp);
 780   return result;
 781 }
 782 
 783 LIR_Opr LIRGenerator::atomic_add(BasicType type, LIR_Opr addr, LIRItem&amp; value) {
 784   LIR_Opr result = new_register(type);
 785   value.load_item();
<span class="line-modified"> 786   assert(type == T_INT LP64_ONLY( || type == T_LONG), &quot;unexpected type&quot;);</span>
 787   LIR_Opr tmp = new_register(type);
 788   __ xadd(addr, value.result(), result, tmp);
 789   return result;
 790 }
 791 
 792 void LIRGenerator::do_MathIntrinsic(Intrinsic* x) {
 793   address runtime_func;
 794   switch (x-&gt;id()) {
 795     case vmIntrinsics::_dabs: {
 796 #ifdef __SOFTFP__
 797       runtime_func = CAST_FROM_FN_PTR(address, SharedRuntime::dabs);
 798       break;
 799 #else
 800       assert(x-&gt;number_of_arguments() == 1, &quot;wrong type&quot;);
 801       LIRItem value(x-&gt;argument_at(0), this);
 802       value.load_item();
 803       __ abs(value.result(), rlock_result(x), LIR_OprFact::illegalOpr);
 804       return;
 805 #endif // __SOFTFP__
 806     }
</pre>
<hr />
<pre>
1293 }
1294 
1295 
1296 LIR_Opr LIRGenerator::getThreadPointer() {
1297   return FrameMap::Rthread_opr;
1298 }
1299 
1300 void LIRGenerator::trace_block_entry(BlockBegin* block) {
1301   __ move(LIR_OprFact::intConst(block-&gt;block_id()), FrameMap::R0_opr);
1302   LIR_OprList* args = new LIR_OprList(1);
1303   args-&gt;append(FrameMap::R0_opr);
1304   address func = CAST_FROM_FN_PTR(address, Runtime1::trace_block_entry);
1305   __ call_runtime_leaf(func, getThreadTemp(), LIR_OprFact::illegalOpr, args);
1306 }
1307 
1308 
1309 void LIRGenerator::volatile_field_store(LIR_Opr value, LIR_Address* address,
1310                                         CodeEmitInfo* info) {
1311   if (value-&gt;is_double_cpu()) {
1312     assert(address-&gt;index()-&gt;is_illegal(), &quot;should have a constant displacement&quot;);
<span class="line-modified">1313     LIR_Opr tmp = new_pointer_register();</span>
<span class="line-modified">1314     add_large_constant(address-&gt;base(), address-&gt;disp(), tmp);</span>
<span class="line-modified">1315     __ volatile_store_mem_reg(value, new LIR_Address(tmp, (intx)0, address-&gt;type()), info);</span>







1316     return;
1317   }
1318   __ store(value, address, info, lir_patch_none);
1319 }
1320 
1321 void LIRGenerator::volatile_field_load(LIR_Address* address, LIR_Opr result,
1322                                        CodeEmitInfo* info) {
1323   if (result-&gt;is_double_cpu()) {
1324     assert(address-&gt;index()-&gt;is_illegal(), &quot;should have a constant displacement&quot;);
<span class="line-modified">1325     LIR_Opr tmp = new_pointer_register();</span>
<span class="line-modified">1326     add_large_constant(address-&gt;base(), address-&gt;disp(), tmp);</span>
<span class="line-modified">1327     __ volatile_load_mem_reg(new LIR_Address(tmp, (intx)0, address-&gt;type()), result, info);</span>







1328     return;
1329   }
1330   __ load(address, result, info, lir_patch_none);
1331 }
</pre>
</td>
<td>
<hr />
<pre>
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/macroAssembler.inline.hpp&quot;
  27 #include &quot;c1/c1_Compilation.hpp&quot;
  28 #include &quot;c1/c1_FrameMap.hpp&quot;
  29 #include &quot;c1/c1_Instruction.hpp&quot;
  30 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  31 #include &quot;c1/c1_LIRGenerator.hpp&quot;
  32 #include &quot;c1/c1_Runtime1.hpp&quot;
  33 #include &quot;c1/c1_ValueStack.hpp&quot;
  34 #include &quot;ci/ciArray.hpp&quot;
  35 #include &quot;ci/ciObjArrayKlass.hpp&quot;
  36 #include &quot;ci/ciTypeArrayKlass.hpp&quot;
  37 #include &quot;ci/ciUtilities.hpp&quot;
  38 #include &quot;gc/shared/c1/barrierSetC1.hpp&quot;
  39 #include &quot;gc/shared/cardTable.hpp&quot;
  40 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  41 #include &quot;runtime/sharedRuntime.hpp&quot;
  42 #include &quot;runtime/stubRoutines.hpp&quot;
<span class="line-added">  43 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  44 #include &quot;vmreg_arm.inline.hpp&quot;
  45 
  46 #ifdef ASSERT
  47 #define __ gen()-&gt;lir(__FILE__, __LINE__)-&gt;
  48 #else
  49 #define __ gen()-&gt;lir()-&gt;
  50 #endif
  51 
  52 void LIRItem::load_byte_item() {
  53   load_item();
  54 }
  55 
  56 void LIRItem::load_nonconstant() {
  57   LIR_Opr r = value()-&gt;operand();
  58   if (_gen-&gt;can_inline_as_constant(value())) {
  59     if (!r-&gt;is_constant()) {
  60       r = LIR_OprFact::value_type(value()-&gt;type());
  61     }
  62     _result = r;
  63   } else {
</pre>
<hr />
<pre>
 758   new_value.load_item();
 759   cmp_value.load_item();
 760   LIR_Opr result = new_register(T_INT);
 761   if (type == T_OBJECT || type == T_ARRAY) {
 762     __ cas_obj(addr, cmp_value.result(), new_value.result(), new_register(T_INT), new_register(T_INT), result);
 763   } else if (type == T_INT) {
 764     __ cas_int(addr-&gt;as_address_ptr()-&gt;base(), cmp_value.result(), new_value.result(), tmp1, tmp1, result);
 765   } else if (type == T_LONG) {
 766     tmp1 = new_register(T_LONG);
 767     __ cas_long(addr-&gt;as_address_ptr()-&gt;base(), cmp_value.result(), new_value.result(), tmp1, tmp2, result);
 768   } else {
 769     ShouldNotReachHere();
 770   }
 771   return result;
 772 }
 773 
 774 LIR_Opr LIRGenerator::atomic_xchg(BasicType type, LIR_Opr addr, LIRItem&amp; value) {
 775   bool is_oop = type == T_OBJECT || type == T_ARRAY;
 776   LIR_Opr result = new_register(type);
 777   value.load_item();
<span class="line-modified"> 778   assert(type == T_INT || is_oop || (type == T_LONG &amp;&amp; VM_Version::supports_ldrexd()), &quot;unexpected type&quot;);</span>
 779   LIR_Opr tmp = (UseCompressedOops &amp;&amp; is_oop) ? new_pointer_register() : LIR_OprFact::illegalOpr;
 780   __ xchg(addr, value.result(), result, tmp);
 781   return result;
 782 }
 783 
 784 LIR_Opr LIRGenerator::atomic_add(BasicType type, LIR_Opr addr, LIRItem&amp; value) {
 785   LIR_Opr result = new_register(type);
 786   value.load_item();
<span class="line-modified"> 787   assert(type == T_INT || (type == T_LONG &amp;&amp; VM_Version::supports_ldrexd ()), &quot;unexpected type&quot;);</span>
 788   LIR_Opr tmp = new_register(type);
 789   __ xadd(addr, value.result(), result, tmp);
 790   return result;
 791 }
 792 
 793 void LIRGenerator::do_MathIntrinsic(Intrinsic* x) {
 794   address runtime_func;
 795   switch (x-&gt;id()) {
 796     case vmIntrinsics::_dabs: {
 797 #ifdef __SOFTFP__
 798       runtime_func = CAST_FROM_FN_PTR(address, SharedRuntime::dabs);
 799       break;
 800 #else
 801       assert(x-&gt;number_of_arguments() == 1, &quot;wrong type&quot;);
 802       LIRItem value(x-&gt;argument_at(0), this);
 803       value.load_item();
 804       __ abs(value.result(), rlock_result(x), LIR_OprFact::illegalOpr);
 805       return;
 806 #endif // __SOFTFP__
 807     }
</pre>
<hr />
<pre>
1294 }
1295 
1296 
1297 LIR_Opr LIRGenerator::getThreadPointer() {
1298   return FrameMap::Rthread_opr;
1299 }
1300 
1301 void LIRGenerator::trace_block_entry(BlockBegin* block) {
1302   __ move(LIR_OprFact::intConst(block-&gt;block_id()), FrameMap::R0_opr);
1303   LIR_OprList* args = new LIR_OprList(1);
1304   args-&gt;append(FrameMap::R0_opr);
1305   address func = CAST_FROM_FN_PTR(address, Runtime1::trace_block_entry);
1306   __ call_runtime_leaf(func, getThreadTemp(), LIR_OprFact::illegalOpr, args);
1307 }
1308 
1309 
1310 void LIRGenerator::volatile_field_store(LIR_Opr value, LIR_Address* address,
1311                                         CodeEmitInfo* info) {
1312   if (value-&gt;is_double_cpu()) {
1313     assert(address-&gt;index()-&gt;is_illegal(), &quot;should have a constant displacement&quot;);
<span class="line-modified">1314     LIR_Address* store_addr = NULL;</span>
<span class="line-modified">1315     if (address-&gt;disp() != 0) {</span>
<span class="line-modified">1316       LIR_Opr tmp = new_pointer_register();</span>
<span class="line-added">1317       add_large_constant(address-&gt;base(), address-&gt;disp(), tmp);</span>
<span class="line-added">1318       store_addr = new LIR_Address(tmp, (intx)0, address-&gt;type());</span>
<span class="line-added">1319     } else {</span>
<span class="line-added">1320       // address-&gt;disp() can be 0, if the address is referenced using the unsafe intrinsic</span>
<span class="line-added">1321       store_addr = address;</span>
<span class="line-added">1322     }</span>
<span class="line-added">1323     __ volatile_store_mem_reg(value, store_addr, info);</span>
1324     return;
1325   }
1326   __ store(value, address, info, lir_patch_none);
1327 }
1328 
1329 void LIRGenerator::volatile_field_load(LIR_Address* address, LIR_Opr result,
1330                                        CodeEmitInfo* info) {
1331   if (result-&gt;is_double_cpu()) {
1332     assert(address-&gt;index()-&gt;is_illegal(), &quot;should have a constant displacement&quot;);
<span class="line-modified">1333     LIR_Address* load_addr = NULL;</span>
<span class="line-modified">1334     if (address-&gt;disp() != 0) {</span>
<span class="line-modified">1335       LIR_Opr tmp = new_pointer_register();</span>
<span class="line-added">1336       add_large_constant(address-&gt;base(), address-&gt;disp(), tmp);</span>
<span class="line-added">1337       load_addr = new LIR_Address(tmp, (intx)0, address-&gt;type());</span>
<span class="line-added">1338     } else {</span>
<span class="line-added">1339       // address-&gt;disp() can be 0, if the address is referenced using the unsafe intrinsic</span>
<span class="line-added">1340       load_addr = address;</span>
<span class="line-added">1341     }</span>
<span class="line-added">1342     __ volatile_load_mem_reg(load_addr, result, info);</span>
1343     return;
1344   }
1345   __ load(address, result, info, lir_patch_none);
1346 }
</pre>
</td>
</tr>
</table>
<center><a href="c1_LIRAssembler_arm.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_MacroAssembler_arm.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>