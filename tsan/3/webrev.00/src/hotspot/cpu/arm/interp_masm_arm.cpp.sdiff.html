<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/arm/interp_masm_arm.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="globals_arm.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="interp_masm_arm.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/arm/interp_masm_arm.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2008, 2018, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;jvm.h&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;gc/shared/barrierSet.hpp&quot;
  29 #include &quot;gc/shared/cardTable.hpp&quot;
  30 #include &quot;gc/shared/cardTableBarrierSet.inline.hpp&quot;
  31 #include &quot;gc/shared/collectedHeap.hpp&quot;
  32 #include &quot;interp_masm_arm.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  35 #include &quot;logging/log.hpp&quot;
  36 #include &quot;oops/arrayOop.hpp&quot;
<span class="line-modified">  37 #include &quot;oops/markOop.hpp&quot;</span>
  38 #include &quot;oops/method.hpp&quot;
  39 #include &quot;oops/methodData.hpp&quot;
  40 #include &quot;prims/jvmtiExport.hpp&quot;
  41 #include &quot;prims/jvmtiThreadState.hpp&quot;
  42 #include &quot;runtime/basicLock.hpp&quot;
  43 #include &quot;runtime/biasedLocking.hpp&quot;
  44 #include &quot;runtime/frame.inline.hpp&quot;

  45 #include &quot;runtime/sharedRuntime.hpp&quot;

  46 
  47 //--------------------------------------------------------------------
  48 // Implementation of InterpreterMacroAssembler
  49 
  50 
  51 
  52 
  53 InterpreterMacroAssembler::InterpreterMacroAssembler(CodeBuffer* code) : MacroAssembler(code) {
  54 }
  55 
  56 void InterpreterMacroAssembler::call_VM_helper(Register oop_result, address entry_point, int number_of_arguments, bool check_exceptions) {
  57 #ifdef ASSERT
  58   // Ensure that last_sp is not filled.
  59   { Label L;
  60     ldr(Rtemp, Address(FP, frame::interpreter_frame_last_sp_offset * wordSize));
  61     cbz(Rtemp, L);
  62     stop(&quot;InterpreterMacroAssembler::call_VM_helper: last_sp != NULL&quot;);
  63     bind(L);
  64   }
  65 #endif // ASSERT
</pre>
<hr />
<pre>
 539 }
 540 
 541 
 542 void InterpreterMacroAssembler::restore_dispatch() {
 543   mov_slow(RdispatchTable, (address)Interpreter::dispatch_table(vtos));
 544 }
 545 
 546 
 547 // The following two routines provide a hook so that an implementation
 548 // can schedule the dispatch in two parts.
 549 void InterpreterMacroAssembler::dispatch_prolog(TosState state, int step) {
 550   // Nothing ARM-specific to be done here.
 551 }
 552 
 553 void InterpreterMacroAssembler::dispatch_epilog(TosState state, int step) {
 554   dispatch_next(state, step);
 555 }
 556 
 557 void InterpreterMacroAssembler::dispatch_base(TosState state,
 558                                               DispatchTableMode table_mode,
<span class="line-modified"> 559                                               bool verifyoop) {</span>
 560   if (VerifyActivationFrameSize) {
 561     Label L;
 562     sub(Rtemp, FP, SP);
 563     int min_frame_size = (frame::link_offset - frame::interpreter_frame_initial_sp_offset) * wordSize;
 564     cmp(Rtemp, min_frame_size);
 565     b(L, ge);
 566     stop(&quot;broken stack frame&quot;);
 567     bind(L);
 568   }
 569 
 570   if (verifyoop) {
 571     interp_verify_oop(R0_tos, state, __FILE__, __LINE__);
 572   }
 573 












 574   if((state == itos) || (state == btos) || (state == ztos) || (state == ctos) || (state == stos)) {
 575     zap_high_non_significant_bits(R0_tos);
 576   }
 577 
 578 #ifdef ASSERT
 579   Label L;
 580   mov_slow(Rtemp, (address)Interpreter::dispatch_table(vtos));
 581   cmp(Rtemp, RdispatchTable);
 582   b(L, eq);
 583   stop(&quot;invalid RdispatchTable&quot;);
 584   bind(L);
 585 #endif
 586 
 587   if (table_mode == DispatchDefault) {
 588     if (state == vtos) {
 589       indirect_jump(Address::indexed_ptr(RdispatchTable, R3_bytecode), Rtemp);
 590     } else {
 591       // on 32-bit ARM this method is faster than the one above.
 592       sub(Rtemp, RdispatchTable, (Interpreter::distance_from_dispatch_table(vtos) -
 593                            Interpreter::distance_from_dispatch_table(state)) * wordSize);
 594       indirect_jump(Address::indexed_ptr(Rtemp, R3_bytecode), Rtemp);
 595     }
 596   } else {
 597     assert(table_mode == DispatchNormal, &quot;invalid dispatch table mode&quot;);
 598     address table = (address) Interpreter::normal_table(state);
 599     mov_slow(Rtemp, table);
 600     indirect_jump(Address::indexed_ptr(Rtemp, R3_bytecode), Rtemp);
 601   }
 602 






 603   nop(); // to avoid filling CPU pipeline with invalid instructions
 604   nop();
 605 }
 606 
<span class="line-modified"> 607 void InterpreterMacroAssembler::dispatch_only(TosState state) {</span>
<span class="line-modified"> 608   dispatch_base(state, DispatchDefault);</span>
 609 }
 610 
 611 
 612 void InterpreterMacroAssembler::dispatch_only_normal(TosState state) {
 613   dispatch_base(state, DispatchNormal);
 614 }
 615 
 616 void InterpreterMacroAssembler::dispatch_only_noverify(TosState state) {
 617   dispatch_base(state, DispatchNormal, false);
 618 }
 619 
<span class="line-modified"> 620 void InterpreterMacroAssembler::dispatch_next(TosState state, int step) {</span>
 621   // load next bytecode and advance Rbcp
 622   ldrb(R3_bytecode, Address(Rbcp, step, pre_indexed));
<span class="line-modified"> 623   dispatch_base(state, DispatchDefault);</span>
 624 }
 625 
 626 void InterpreterMacroAssembler::narrow(Register result) {
 627   // mask integer result to narrower return type.
 628   const Register Rtmp = R2;
 629 
 630   // get method type
 631   ldr(Rtmp, Address(Rmethod, Method::const_offset()));
 632   ldrb(Rtmp, Address(Rtmp, ConstMethod::result_type_offset()));
 633 
 634   Label notBool, notByte, notChar, done;
 635   cmp(Rtmp, T_INT);
 636   b(done, eq);
 637 
 638   cmp(Rtmp, T_BOOLEAN);
 639   b(notBool, ne);
 640   and_32(result, result, 1);
 641   b(done);
 642 
 643   bind(notBool);
</pre>
<hr />
<pre>
 861 
 862     Label already_locked, slow_case;
 863 
 864     // Load object pointer
 865     ldr(Robj, Address(Rlock, obj_offset));
 866 
 867     if (UseBiasedLocking) {
 868       biased_locking_enter(Robj, Rmark/*scratched*/, R0, false, Rtemp, done, slow_case);
 869     }
 870 
 871 
 872     // On MP platforms the next load could return a &#39;stale&#39; value if the memory location has been modified by another thread.
 873     // That would be acceptable as ether CAS or slow case path is taken in that case.
 874     // Exception to that is if the object is locked by the calling thread, then the recursive test will pass (guaranteed as
 875     // loads are satisfied from a store queue if performed on the same processor).
 876 
 877     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;must be&quot;);
 878     ldr(Rmark, Address(Robj, oopDesc::mark_offset_in_bytes()));
 879 
 880     // Test if object is already locked
<span class="line-modified"> 881     tst(Rmark, markOopDesc::unlocked_value);</span>
 882     b(already_locked, eq);
 883 
 884     // Save old object-&gt;mark() into BasicLock&#39;s displaced header
 885     str(Rmark, Address(Rlock, mark_offset));
 886 
 887     cas_for_lock_acquire(Rmark, Rlock, Robj, Rtemp, slow_case);
 888 
 889 #ifndef PRODUCT
 890     if (PrintBiasedLockingStatistics) {
 891       cond_atomic_inc32(al, BiasedLocking::fast_path_entry_count_addr());
 892     }
 893 #endif //!PRODUCT
 894 
 895     b(done);
 896 
 897     // If we got here that means the object is locked by ether calling thread or another thread.
 898     bind(already_locked);
 899     // Handling of locked objects: recursive locks and slow case.
 900 
 901     // Fast check for recursive lock.
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2008, 2020, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;jvm.h&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;gc/shared/barrierSet.hpp&quot;
  29 #include &quot;gc/shared/cardTable.hpp&quot;
  30 #include &quot;gc/shared/cardTableBarrierSet.inline.hpp&quot;
  31 #include &quot;gc/shared/collectedHeap.hpp&quot;
  32 #include &quot;interp_masm_arm.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  35 #include &quot;logging/log.hpp&quot;
  36 #include &quot;oops/arrayOop.hpp&quot;
<span class="line-modified">  37 #include &quot;oops/markWord.hpp&quot;</span>
  38 #include &quot;oops/method.hpp&quot;
  39 #include &quot;oops/methodData.hpp&quot;
  40 #include &quot;prims/jvmtiExport.hpp&quot;
  41 #include &quot;prims/jvmtiThreadState.hpp&quot;
  42 #include &quot;runtime/basicLock.hpp&quot;
  43 #include &quot;runtime/biasedLocking.hpp&quot;
  44 #include &quot;runtime/frame.inline.hpp&quot;
<span class="line-added">  45 #include &quot;runtime/safepointMechanism.hpp&quot;</span>
  46 #include &quot;runtime/sharedRuntime.hpp&quot;
<span class="line-added">  47 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  48 
  49 //--------------------------------------------------------------------
  50 // Implementation of InterpreterMacroAssembler
  51 
  52 
  53 
  54 
  55 InterpreterMacroAssembler::InterpreterMacroAssembler(CodeBuffer* code) : MacroAssembler(code) {
  56 }
  57 
  58 void InterpreterMacroAssembler::call_VM_helper(Register oop_result, address entry_point, int number_of_arguments, bool check_exceptions) {
  59 #ifdef ASSERT
  60   // Ensure that last_sp is not filled.
  61   { Label L;
  62     ldr(Rtemp, Address(FP, frame::interpreter_frame_last_sp_offset * wordSize));
  63     cbz(Rtemp, L);
  64     stop(&quot;InterpreterMacroAssembler::call_VM_helper: last_sp != NULL&quot;);
  65     bind(L);
  66   }
  67 #endif // ASSERT
</pre>
<hr />
<pre>
 541 }
 542 
 543 
 544 void InterpreterMacroAssembler::restore_dispatch() {
 545   mov_slow(RdispatchTable, (address)Interpreter::dispatch_table(vtos));
 546 }
 547 
 548 
 549 // The following two routines provide a hook so that an implementation
 550 // can schedule the dispatch in two parts.
 551 void InterpreterMacroAssembler::dispatch_prolog(TosState state, int step) {
 552   // Nothing ARM-specific to be done here.
 553 }
 554 
 555 void InterpreterMacroAssembler::dispatch_epilog(TosState state, int step) {
 556   dispatch_next(state, step);
 557 }
 558 
 559 void InterpreterMacroAssembler::dispatch_base(TosState state,
 560                                               DispatchTableMode table_mode,
<span class="line-modified"> 561                                               bool verifyoop, bool generate_poll) {</span>
 562   if (VerifyActivationFrameSize) {
 563     Label L;
 564     sub(Rtemp, FP, SP);
 565     int min_frame_size = (frame::link_offset - frame::interpreter_frame_initial_sp_offset) * wordSize;
 566     cmp(Rtemp, min_frame_size);
 567     b(L, ge);
 568     stop(&quot;broken stack frame&quot;);
 569     bind(L);
 570   }
 571 
 572   if (verifyoop) {
 573     interp_verify_oop(R0_tos, state, __FILE__, __LINE__);
 574   }
 575 
<span class="line-added"> 576   Label safepoint;</span>
<span class="line-added"> 577   address* const safepoint_table = Interpreter::safept_table(state);</span>
<span class="line-added"> 578   address* const table           = Interpreter::dispatch_table(state);</span>
<span class="line-added"> 579   bool needs_thread_local_poll = generate_poll &amp;&amp;</span>
<span class="line-added"> 580     SafepointMechanism::uses_thread_local_poll() &amp;&amp; table != safepoint_table;</span>
<span class="line-added"> 581 </span>
<span class="line-added"> 582   if (needs_thread_local_poll) {</span>
<span class="line-added"> 583     NOT_PRODUCT(block_comment(&quot;Thread-local Safepoint poll&quot;));</span>
<span class="line-added"> 584     ldr(Rtemp, Address(Rthread, Thread::polling_page_offset()));</span>
<span class="line-added"> 585     tbnz(Rtemp, exact_log2(SafepointMechanism::poll_bit()), safepoint);</span>
<span class="line-added"> 586   }</span>
<span class="line-added"> 587 </span>
 588   if((state == itos) || (state == btos) || (state == ztos) || (state == ctos) || (state == stos)) {
 589     zap_high_non_significant_bits(R0_tos);
 590   }
 591 
 592 #ifdef ASSERT
 593   Label L;
 594   mov_slow(Rtemp, (address)Interpreter::dispatch_table(vtos));
 595   cmp(Rtemp, RdispatchTable);
 596   b(L, eq);
 597   stop(&quot;invalid RdispatchTable&quot;);
 598   bind(L);
 599 #endif
 600 
 601   if (table_mode == DispatchDefault) {
 602     if (state == vtos) {
 603       indirect_jump(Address::indexed_ptr(RdispatchTable, R3_bytecode), Rtemp);
 604     } else {
 605       // on 32-bit ARM this method is faster than the one above.
 606       sub(Rtemp, RdispatchTable, (Interpreter::distance_from_dispatch_table(vtos) -
 607                            Interpreter::distance_from_dispatch_table(state)) * wordSize);
 608       indirect_jump(Address::indexed_ptr(Rtemp, R3_bytecode), Rtemp);
 609     }
 610   } else {
 611     assert(table_mode == DispatchNormal, &quot;invalid dispatch table mode&quot;);
 612     address table = (address) Interpreter::normal_table(state);
 613     mov_slow(Rtemp, table);
 614     indirect_jump(Address::indexed_ptr(Rtemp, R3_bytecode), Rtemp);
 615   }
 616 
<span class="line-added"> 617   if (needs_thread_local_poll) {</span>
<span class="line-added"> 618     bind(safepoint);</span>
<span class="line-added"> 619     lea(Rtemp, ExternalAddress((address)safepoint_table));</span>
<span class="line-added"> 620     indirect_jump(Address::indexed_ptr(Rtemp, R3_bytecode), Rtemp);</span>
<span class="line-added"> 621   }</span>
<span class="line-added"> 622 </span>
 623   nop(); // to avoid filling CPU pipeline with invalid instructions
 624   nop();
 625 }
 626 
<span class="line-modified"> 627 void InterpreterMacroAssembler::dispatch_only(TosState state, bool generate_poll) {</span>
<span class="line-modified"> 628   dispatch_base(state, DispatchDefault, true, generate_poll);</span>
 629 }
 630 
 631 
 632 void InterpreterMacroAssembler::dispatch_only_normal(TosState state) {
 633   dispatch_base(state, DispatchNormal);
 634 }
 635 
 636 void InterpreterMacroAssembler::dispatch_only_noverify(TosState state) {
 637   dispatch_base(state, DispatchNormal, false);
 638 }
 639 
<span class="line-modified"> 640 void InterpreterMacroAssembler::dispatch_next(TosState state, int step, bool generate_poll) {</span>
 641   // load next bytecode and advance Rbcp
 642   ldrb(R3_bytecode, Address(Rbcp, step, pre_indexed));
<span class="line-modified"> 643   dispatch_base(state, DispatchDefault, true, generate_poll);</span>
 644 }
 645 
 646 void InterpreterMacroAssembler::narrow(Register result) {
 647   // mask integer result to narrower return type.
 648   const Register Rtmp = R2;
 649 
 650   // get method type
 651   ldr(Rtmp, Address(Rmethod, Method::const_offset()));
 652   ldrb(Rtmp, Address(Rtmp, ConstMethod::result_type_offset()));
 653 
 654   Label notBool, notByte, notChar, done;
 655   cmp(Rtmp, T_INT);
 656   b(done, eq);
 657 
 658   cmp(Rtmp, T_BOOLEAN);
 659   b(notBool, ne);
 660   and_32(result, result, 1);
 661   b(done);
 662 
 663   bind(notBool);
</pre>
<hr />
<pre>
 881 
 882     Label already_locked, slow_case;
 883 
 884     // Load object pointer
 885     ldr(Robj, Address(Rlock, obj_offset));
 886 
 887     if (UseBiasedLocking) {
 888       biased_locking_enter(Robj, Rmark/*scratched*/, R0, false, Rtemp, done, slow_case);
 889     }
 890 
 891 
 892     // On MP platforms the next load could return a &#39;stale&#39; value if the memory location has been modified by another thread.
 893     // That would be acceptable as ether CAS or slow case path is taken in that case.
 894     // Exception to that is if the object is locked by the calling thread, then the recursive test will pass (guaranteed as
 895     // loads are satisfied from a store queue if performed on the same processor).
 896 
 897     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;must be&quot;);
 898     ldr(Rmark, Address(Robj, oopDesc::mark_offset_in_bytes()));
 899 
 900     // Test if object is already locked
<span class="line-modified"> 901     tst(Rmark, markWord::unlocked_value);</span>
 902     b(already_locked, eq);
 903 
 904     // Save old object-&gt;mark() into BasicLock&#39;s displaced header
 905     str(Rmark, Address(Rlock, mark_offset));
 906 
 907     cas_for_lock_acquire(Rmark, Rlock, Robj, Rtemp, slow_case);
 908 
 909 #ifndef PRODUCT
 910     if (PrintBiasedLockingStatistics) {
 911       cond_atomic_inc32(al, BiasedLocking::fast_path_entry_count_addr());
 912     }
 913 #endif //!PRODUCT
 914 
 915     b(done);
 916 
 917     // If we got here that means the object is locked by ether calling thread or another thread.
 918     bind(already_locked);
 919     // Handling of locked objects: recursive locks and slow case.
 920 
 921     // Fast check for recursive lock.
</pre>
</td>
</tr>
</table>
<center><a href="globals_arm.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="interp_masm_arm.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>