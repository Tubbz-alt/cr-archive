<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/arm/c1_MacroAssembler_arm.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_LIRGenerator_arm.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Runtime1_arm.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/arm/c1_MacroAssembler_arm.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;c1/c1_MacroAssembler.hpp&quot;
 27 #include &quot;c1/c1_Runtime1.hpp&quot;
 28 #include &quot;classfile/systemDictionary.hpp&quot;
 29 #include &quot;gc/shared/collectedHeap.hpp&quot;
 30 #include &quot;interpreter/interpreter.hpp&quot;
 31 #include &quot;oops/arrayOop.hpp&quot;
<span class="line-modified"> 32 #include &quot;oops/markOop.hpp&quot;</span>
 33 #include &quot;runtime/basicLock.hpp&quot;
 34 #include &quot;runtime/biasedLocking.hpp&quot;
 35 #include &quot;runtime/os.hpp&quot;
 36 #include &quot;runtime/sharedRuntime.hpp&quot;
 37 #include &quot;runtime/stubRoutines.hpp&quot;

 38 
 39 // Note: Rtemp usage is this file should not impact C2 and should be
 40 // correct as long as it is not implicitly used in lower layers (the
 41 // arm [macro]assembler) and used with care in the other C1 specific
 42 // files.
 43 
 44 void C1_MacroAssembler::inline_cache_check(Register receiver, Register iCache) {
 45   Label verified;
 46   load_klass(Rtemp, receiver);
 47   cmp(Rtemp, iCache);
 48   b(verified, eq); // jump over alignment no-ops
 49   jump(SharedRuntime::get_ic_miss_stub(), relocInfo::runtime_call_type);
 50   align(CodeEntryAlignment);
 51   bind(verified);
 52 }
 53 
 54 void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes) {
 55   assert(bang_size_in_bytes &gt;= frame_size_in_bytes, &quot;stack bang size incorrect&quot;);
 56   assert((frame_size_in_bytes % StackAlignmentInBytes) == 0, &quot;frame size should be aligned&quot;);
 57 
</pre>
<hr />
<pre>
 75   }
 76 }
 77 
 78 // Puts address of allocated object into register `obj` and end of allocated object into register `obj_end`.
 79 void C1_MacroAssembler::try_allocate(Register obj, Register obj_end, Register tmp1, Register tmp2,
 80                                      RegisterOrConstant size_expression, Label&amp; slow_case) {
 81   if (UseTLAB) {
 82     tlab_allocate(obj, obj_end, tmp1, size_expression, slow_case);
 83   } else {
 84     eden_allocate(obj, obj_end, tmp1, tmp2, size_expression, slow_case);
 85   }
 86 }
 87 
 88 
 89 void C1_MacroAssembler::initialize_header(Register obj, Register klass, Register len, Register tmp) {
 90   assert_different_registers(obj, klass, len, tmp);
 91 
 92   if(UseBiasedLocking &amp;&amp; !len-&gt;is_valid()) {
 93     ldr(tmp, Address(klass, Klass::prototype_header_offset()));
 94   } else {
<span class="line-modified"> 95     mov(tmp, (intptr_t)markOopDesc::prototype());</span>
 96   }
 97 
 98   str(tmp, Address(obj, oopDesc::mark_offset_in_bytes()));
 99   str(klass, Address(obj, oopDesc::klass_offset_in_bytes()));
100 
101   if (len-&gt;is_valid()) {
102     str_32(len, Address(obj, arrayOopDesc::length_offset_in_bytes()));
103   }
104 }
105 
106 
107 // Cleans object body [base..obj_end]. Clobbers `base` and `tmp` registers.
108 void C1_MacroAssembler::initialize_body(Register base, Register obj_end, Register tmp) {
109   zero_memory(base, obj_end, tmp);
110 }
111 
112 
113 void C1_MacroAssembler::initialize_object(Register obj, Register obj_end, Register klass,
114                                           Register len, Register tmp1, Register tmp2,
115                                           RegisterOrConstant header_size, int obj_size_in_bytes,
</pre>
<hr />
<pre>
202   if (UseBiasedLocking) {
203     // load object
204     str(obj, Address(disp_hdr, obj_offset));
205     null_check_offset = biased_locking_enter(obj, hdr/*scratched*/, tmp1, false, tmp2, done, slow_case);
206   }
207 
208   assert(oopDesc::mark_offset_in_bytes() == 0, &quot;Required by atomic instructions&quot;);
209 
210 
211   if (!UseBiasedLocking) {
212     null_check_offset = offset();
213   }
214 
215   // On MP platforms the next load could return a &#39;stale&#39; value if the memory location has been modified by another thread.
216   // That would be acceptable as ether CAS or slow case path is taken in that case.
217 
218   // Must be the first instruction here, because implicit null check relies on it
219   ldr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));
220 
221   str(obj, Address(disp_hdr, obj_offset));
<span class="line-modified">222   tst(hdr, markOopDesc::unlocked_value);</span>
223   b(fast_lock, ne);
224 
225   // Check for recursive locking
226   // See comments in InterpreterMacroAssembler::lock_object for
227   // explanations on the fast recursive locking check.
228   // -1- test low 2 bits
229   movs(tmp2, AsmOperand(hdr, lsl, 30));
230   // -2- test (hdr - SP) if the low two bits are 0
231   sub(tmp2, hdr, SP, eq);
232   movs(tmp2, AsmOperand(tmp2, lsr, exact_log2(os::vm_page_size())), eq);
233   // If &#39;eq&#39; then OK for recursive fast locking: store 0 into a lock record.
234   str(tmp2, Address(disp_hdr, mark_offset), eq);
235   b(fast_lock_done, eq);
236   // else need slow case
237   b(slow_case);
238 
239 
240   bind(fast_lock);
241   // Save previous object header in BasicLock structure and update the header
242   str(hdr, Address(disp_hdr, mark_offset));
</pre>
</td>
<td>
<hr />
<pre>
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;c1/c1_MacroAssembler.hpp&quot;
 27 #include &quot;c1/c1_Runtime1.hpp&quot;
 28 #include &quot;classfile/systemDictionary.hpp&quot;
 29 #include &quot;gc/shared/collectedHeap.hpp&quot;
 30 #include &quot;interpreter/interpreter.hpp&quot;
 31 #include &quot;oops/arrayOop.hpp&quot;
<span class="line-modified"> 32 #include &quot;oops/markWord.hpp&quot;</span>
 33 #include &quot;runtime/basicLock.hpp&quot;
 34 #include &quot;runtime/biasedLocking.hpp&quot;
 35 #include &quot;runtime/os.hpp&quot;
 36 #include &quot;runtime/sharedRuntime.hpp&quot;
 37 #include &quot;runtime/stubRoutines.hpp&quot;
<span class="line-added"> 38 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
 39 
 40 // Note: Rtemp usage is this file should not impact C2 and should be
 41 // correct as long as it is not implicitly used in lower layers (the
 42 // arm [macro]assembler) and used with care in the other C1 specific
 43 // files.
 44 
 45 void C1_MacroAssembler::inline_cache_check(Register receiver, Register iCache) {
 46   Label verified;
 47   load_klass(Rtemp, receiver);
 48   cmp(Rtemp, iCache);
 49   b(verified, eq); // jump over alignment no-ops
 50   jump(SharedRuntime::get_ic_miss_stub(), relocInfo::runtime_call_type);
 51   align(CodeEntryAlignment);
 52   bind(verified);
 53 }
 54 
 55 void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes) {
 56   assert(bang_size_in_bytes &gt;= frame_size_in_bytes, &quot;stack bang size incorrect&quot;);
 57   assert((frame_size_in_bytes % StackAlignmentInBytes) == 0, &quot;frame size should be aligned&quot;);
 58 
</pre>
<hr />
<pre>
 76   }
 77 }
 78 
 79 // Puts address of allocated object into register `obj` and end of allocated object into register `obj_end`.
 80 void C1_MacroAssembler::try_allocate(Register obj, Register obj_end, Register tmp1, Register tmp2,
 81                                      RegisterOrConstant size_expression, Label&amp; slow_case) {
 82   if (UseTLAB) {
 83     tlab_allocate(obj, obj_end, tmp1, size_expression, slow_case);
 84   } else {
 85     eden_allocate(obj, obj_end, tmp1, tmp2, size_expression, slow_case);
 86   }
 87 }
 88 
 89 
 90 void C1_MacroAssembler::initialize_header(Register obj, Register klass, Register len, Register tmp) {
 91   assert_different_registers(obj, klass, len, tmp);
 92 
 93   if(UseBiasedLocking &amp;&amp; !len-&gt;is_valid()) {
 94     ldr(tmp, Address(klass, Klass::prototype_header_offset()));
 95   } else {
<span class="line-modified"> 96     mov(tmp, (intptr_t)markWord::prototype().value());</span>
 97   }
 98 
 99   str(tmp, Address(obj, oopDesc::mark_offset_in_bytes()));
100   str(klass, Address(obj, oopDesc::klass_offset_in_bytes()));
101 
102   if (len-&gt;is_valid()) {
103     str_32(len, Address(obj, arrayOopDesc::length_offset_in_bytes()));
104   }
105 }
106 
107 
108 // Cleans object body [base..obj_end]. Clobbers `base` and `tmp` registers.
109 void C1_MacroAssembler::initialize_body(Register base, Register obj_end, Register tmp) {
110   zero_memory(base, obj_end, tmp);
111 }
112 
113 
114 void C1_MacroAssembler::initialize_object(Register obj, Register obj_end, Register klass,
115                                           Register len, Register tmp1, Register tmp2,
116                                           RegisterOrConstant header_size, int obj_size_in_bytes,
</pre>
<hr />
<pre>
203   if (UseBiasedLocking) {
204     // load object
205     str(obj, Address(disp_hdr, obj_offset));
206     null_check_offset = biased_locking_enter(obj, hdr/*scratched*/, tmp1, false, tmp2, done, slow_case);
207   }
208 
209   assert(oopDesc::mark_offset_in_bytes() == 0, &quot;Required by atomic instructions&quot;);
210 
211 
212   if (!UseBiasedLocking) {
213     null_check_offset = offset();
214   }
215 
216   // On MP platforms the next load could return a &#39;stale&#39; value if the memory location has been modified by another thread.
217   // That would be acceptable as ether CAS or slow case path is taken in that case.
218 
219   // Must be the first instruction here, because implicit null check relies on it
220   ldr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));
221 
222   str(obj, Address(disp_hdr, obj_offset));
<span class="line-modified">223   tst(hdr, markWord::unlocked_value);</span>
224   b(fast_lock, ne);
225 
226   // Check for recursive locking
227   // See comments in InterpreterMacroAssembler::lock_object for
228   // explanations on the fast recursive locking check.
229   // -1- test low 2 bits
230   movs(tmp2, AsmOperand(hdr, lsl, 30));
231   // -2- test (hdr - SP) if the low two bits are 0
232   sub(tmp2, hdr, SP, eq);
233   movs(tmp2, AsmOperand(tmp2, lsr, exact_log2(os::vm_page_size())), eq);
234   // If &#39;eq&#39; then OK for recursive fast locking: store 0 into a lock record.
235   str(tmp2, Address(disp_hdr, mark_offset), eq);
236   b(fast_lock_done, eq);
237   // else need slow case
238   b(slow_case);
239 
240 
241   bind(fast_lock);
242   // Save previous object header in BasicLock structure and update the header
243   str(hdr, Address(disp_hdr, mark_offset));
</pre>
</td>
</tr>
</table>
<center><a href="c1_LIRGenerator_arm.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Runtime1_arm.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>