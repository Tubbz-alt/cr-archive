<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/arm/arm.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="abstractInterpreter_arm.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="arm_32.ad.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/arm/arm.ad</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
    1 //
<span class="line-modified">    2 // Copyright (c) 2008, 2018, Oracle and/or its affiliates. All rights reserved.</span>
    3 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    4 //
    5 // This code is free software; you can redistribute it and/or modify it
    6 // under the terms of the GNU General Public License version 2 only, as
    7 // published by the Free Software Foundation.
    8 //
    9 // This code is distributed in the hope that it will be useful, but WITHOUT
   10 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   11 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   12 // version 2 for more details (a copy is included in the LICENSE file that
   13 // accompanied this code).
   14 //
   15 // You should have received a copy of the GNU General Public License version
   16 // 2 along with this work; if not, write to the Free Software Foundation,
   17 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   18 //
   19 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   20 // or visit www.oracle.com if you need additional information or have any
   21 // questions.
   22 //
</pre>
<hr />
<pre>
  334     st-&gt;print(&quot;\n\t&quot;);
  335     st-&gt;print(&quot;MOV    Rtemp, #PollAddr\t! Load Polling address\n\t&quot;);
  336     st-&gt;print(&quot;LDR    Rtemp,[Rtemp]\t!Poll for Safepointing&quot;);
  337   }
  338 }
  339 #endif
  340 
  341 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  342   MacroAssembler _masm(&amp;cbuf);
  343   Compile* C = ra_-&gt;C;
  344 
  345   size_t framesize = C-&gt;frame_size_in_bytes();
  346   framesize -= 2*wordSize;
  347   if (framesize != 0) {
  348     __ add_slow(SP, SP, framesize);
  349   }
  350   __ raw_pop(FP, LR);
  351 
  352   // If this does safepoint polling, then do it here
  353   if (do_polling() &amp;&amp; ra_-&gt;C-&gt;is_method_compilation()) {
<span class="line-modified">  354     // mov_slow here is usually one or two instruction</span>
<span class="line-removed">  355     __ mov_address(Rtemp, (address)os::get_polling_page());</span>
<span class="line-removed">  356     __ relocate(relocInfo::poll_return_type);</span>
<span class="line-removed">  357     __ ldr(Rtemp, Address(Rtemp));</span>
  358   }
  359 }
  360 
  361 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
  362   return MachNode::size(ra_);
  363 }
  364 
  365 int MachEpilogNode::reloc() const {
  366   return 16; // a large enough number
  367 }
  368 
  369 const Pipeline * MachEpilogNode::pipeline() const {
  370   return MachNode::pipeline_class();
  371 }
  372 
  373 int MachEpilogNode::safepoint_offset() const {
  374   assert( do_polling(), &quot;no return for this epilog node&quot;);
  375   //  return MacroAssembler::size_of_sethi(os::get_polling_page());
  376   Unimplemented();
  377   return 0;
</pre>
<hr />
<pre>
  954   case Op_OrV:
  955   case Op_XorV:
  956     return VM_Version::has_simd();
  957   case Op_LoadVector:
  958   case Op_StoreVector:
  959   case Op_AddVF:
  960   case Op_SubVF:
  961   case Op_MulVF:
  962     return VM_Version::has_vfp() || VM_Version::has_simd();
  963   case Op_AddVD:
  964   case Op_SubVD:
  965   case Op_MulVD:
  966   case Op_DivVF:
  967   case Op_DivVD:
  968     return VM_Version::has_vfp();
  969   }
  970 
  971   return true;  // Per default match rules are supported.
  972 }
  973 
<span class="line-modified">  974 const bool Matcher::match_rule_supported_vector(int opcode, int vlen) {</span>
  975 
  976   // TODO
  977   // identify extra cases that we might want to provide match rules for
  978   // e.g. Op_ vector nodes and other intrinsics while guarding with vlen
  979   bool ret_value = match_rule_supported(opcode);
  980   // Add rules here.
  981 
  982   return ret_value;  // Per default match rules are supported.
  983 }
  984 
  985 const bool Matcher::has_predicated_vectors(void) {
  986   return false;
  987 }
  988 
  989 const int Matcher::float_pressure(int default_pressure_threshold) {
  990   return default_pressure_threshold;
  991 }
  992 
  993 int Matcher::regnum_to_fpu_offset(int regnum) {
  994   return regnum - 32; // The FP registers are in the second chunk
</pre>
<hr />
<pre>
 1060 
 1061 // No scaling for the parameter the ClearArray node.
 1062 const bool Matcher::init_array_count_is_in_bytes = true;
 1063 
 1064 // Needs 2 CMOV&#39;s for longs.
 1065 const int Matcher::long_cmove_cost() { return 2; }
 1066 
 1067 // CMOVF/CMOVD are expensive on ARM.
 1068 const int Matcher::float_cmove_cost() { return ConditionalMoveLimit; }
 1069 
 1070 // Does the CPU require late expand (see block.cpp for description of late expand)?
 1071 const bool Matcher::require_postalloc_expand = false;
 1072 
 1073 // Do we need to mask the count passed to shift instructions or does
 1074 // the cpu only look at the lower 5/6 bits anyway?
 1075 // FIXME: does this handle vector shifts as well?
 1076 const bool Matcher::need_masked_shift_count = true;
 1077 
 1078 const bool Matcher::convi2l_type_required = true;
 1079 


















 1080 // Should the Matcher clone shifts on addressing modes, expecting them
 1081 // to be subsumed into complex addressing expressions or compute them
 1082 // into registers?
 1083 bool Matcher::clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 1084   return clone_base_plus_offset_address(m, mstack, address_visited);
 1085 }
 1086 
 1087 void Compile::reshape_address(AddPNode* addp) {
 1088 }
 1089 
 1090 bool Matcher::narrow_oop_use_complex_address() {
 1091   NOT_LP64(ShouldNotCallThis());
 1092   assert(UseCompressedOops, &quot;only for compressed oops code&quot;);
 1093   return false;
 1094 }
 1095 
 1096 bool Matcher::narrow_klass_use_complex_address() {
 1097   NOT_LP64(ShouldNotCallThis());
 1098   assert(UseCompressedClassPointers, &quot;only for compressed klass code&quot;);
 1099   return false;
</pre>
<hr />
<pre>
 1108   NOT_LP64(ShouldNotCallThis());
 1109   return true;
 1110 }
 1111 
 1112 // Is it better to copy float constants, or load them directly from memory?
 1113 // Intel can load a float constant from a direct address, requiring no
 1114 // extra registers.  Most RISCs will have to materialize an address into a
 1115 // register first, so they would do better to copy the constant from stack.
 1116 const bool Matcher::rematerialize_float_constants = false;
 1117 
 1118 // If CPU can load and store mis-aligned doubles directly then no fixup is
 1119 // needed.  Else we split the double into 2 integer pieces and move it
 1120 // piece-by-piece.  Only happens when passing doubles into C code as the
 1121 // Java calling convention forces doubles to be aligned.
 1122 const bool Matcher::misaligned_doubles_ok = false;
 1123 
 1124 // No-op on ARM.
 1125 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 1126 }
 1127 
<span class="line-modified"> 1128 // Advertise here if the CPU requires explicit rounding operations</span>
<span class="line-removed"> 1129 // to implement the UseStrictFP mode.</span>
 1130 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 1131 
 1132 // Are floats converted to double when stored to stack during deoptimization?
 1133 // ARM does not handle callee-save floats.
 1134 bool Matcher::float_in_double() {
 1135   return false;
 1136 }
 1137 
 1138 // Do ints take an entire long register or just half?
 1139 // Note that we if-def off of _LP64.
 1140 // The relevant question is how the int is callee-saved.  In _LP64
 1141 // the whole long is written but de-opt&#39;ing will have to extract
 1142 // the relevant 32 bits, in not-_LP64 only the low 32 bits is written.
 1143 #ifdef _LP64
 1144 const bool Matcher::int_in_long = true;
 1145 #else
 1146 const bool Matcher::int_in_long = false;
 1147 #endif
 1148 
 1149 // Return whether or not this register is ever used as an argument.  This
</pre>
<hr />
<pre>
 2187   interface(REG_INTER);
 2188 %}
 2189 
 2190 
 2191 operand R0RegP() %{
 2192   constraint(ALLOC_IN_RC(R0_regP));
 2193   match(iRegP);
 2194 
 2195   format %{ %}
 2196   interface(REG_INTER);
 2197 %}
 2198 
 2199 operand R1RegP() %{
 2200   constraint(ALLOC_IN_RC(R1_regP));
 2201   match(iRegP);
 2202 
 2203   format %{ %}
 2204   interface(REG_INTER);
 2205 %}
 2206 
























 2207 operand R2RegP() %{
 2208   constraint(ALLOC_IN_RC(R2_regP));
 2209   match(iRegP);
 2210 
 2211   format %{ %}
 2212   interface(REG_INTER);
 2213 %}
 2214 
 2215 operand RExceptionRegP() %{
 2216   constraint(ALLOC_IN_RC(Rexception_regP));
 2217   match(iRegP);
 2218 
 2219   format %{ %}
 2220   interface(REG_INTER);
 2221 %}
 2222 
 2223 operand RthreadRegP() %{
 2224   constraint(ALLOC_IN_RC(Rthread_regP));
 2225   match(iRegP);
 2226 
 2227   format %{ %}
 2228   interface(REG_INTER);
 2229 %}
 2230 
 2231 operand IPRegP() %{
 2232   constraint(ALLOC_IN_RC(IP_regP));
 2233   match(iRegP);
 2234 
 2235   format %{ %}
 2236   interface(REG_INTER);
 2237 %}
 2238 








 2239 operand LRRegP() %{
 2240   constraint(ALLOC_IN_RC(LR_regP));
 2241   match(iRegP);
 2242 
 2243   format %{ %}
 2244   interface(REG_INTER);
 2245 %}
 2246 
 2247 operand R0RegI() %{
 2248   constraint(ALLOC_IN_RC(R0_regI));
 2249   match(iRegI);
 2250 
 2251   format %{ %}
 2252   interface(REG_INTER);
 2253 %}
 2254 
 2255 operand R1RegI() %{
 2256   constraint(ALLOC_IN_RC(R1_regI));
 2257   match(iRegI);
 2258 
</pre>
<hr />
<pre>
 4331   ins_cost(MEMORY_REF_COST);
 4332   format %{ &quot;FLDD  $dst, [$constanttablebase + $constantoffset]\t! load from constant table: double=$src&quot; %}
 4333 
 4334   ins_encode %{
 4335     Register r = $constanttablebase;
 4336     int offset  = $constantoffset($src);
 4337     if (!is_memoryD(offset)) {                // can&#39;t use a predicate
 4338                                               // in load constant instructs
 4339       __ add_slow($tmp$$Register, r, offset);
 4340       r = $tmp$$Register;
 4341       offset = 0;
 4342     }
 4343     __ ldr_double($dst$$FloatRegister, Address(r, offset));
 4344   %}
 4345   ins_pipe(loadConFD);
 4346 %}
 4347 
 4348 // Prefetch instructions.
 4349 // Must be safe to execute with invalid address (cannot fault).
 4350 
<span class="line-modified"> 4351 instruct prefetchAlloc( memoryP mem ) %{</span>

 4352   match( PrefetchAllocation mem );
 4353   ins_cost(MEMORY_REF_COST);
 4354   size(4);
 4355 
 4356   format %{ &quot;PLDW $mem\t! Prefetch allocation&quot; %}
 4357   ins_encode %{
 4358     __ pldw($mem$$Address);
 4359   %}
 4360   ins_pipe(iload_mem);
 4361 %}
 4362 














 4363 //----------Store Instructions-------------------------------------------------
 4364 // Store Byte
 4365 instruct storeB(memoryB mem, store_RegI src) %{
 4366   match(Set mem (StoreB mem src));
 4367   ins_cost(MEMORY_REF_COST);
 4368 
 4369   size(4);
 4370   format %{ &quot;STRB    $src,$mem\t! byte&quot; %}
 4371   ins_encode %{
 4372     __ strb($src$$Register, $mem$$Address);
 4373   %}
 4374   ins_pipe(istore_mem_reg);
 4375 %}
 4376 
 4377 instruct storeCM(memoryB mem, store_RegI src) %{
 4378   match(Set mem (StoreCM mem src));
 4379   ins_cost(MEMORY_REF_COST);
 4380 
 4381   size(4);
 4382   format %{ &quot;STRB    $src,$mem\t! CMS card-mark byte&quot; %}
</pre>
<hr />
<pre>
 5244   ins_encode( /*empty encoding*/ );
 5245   ins_pipe(empty);
 5246 %}
 5247 
 5248 
 5249 instruct castPP( iRegP dst ) %{
 5250   match(Set dst (CastPP dst));
 5251   format %{ &quot;! castPP of $dst&quot; %}
 5252   ins_encode( /*empty encoding*/ );
 5253   ins_pipe(empty);
 5254 %}
 5255 
 5256 instruct castII( iRegI dst ) %{
 5257   match(Set dst (CastII dst));
 5258   format %{ &quot;! castII of $dst&quot; %}
 5259   ins_encode( /*empty encoding*/ );
 5260   ins_cost(0);
 5261   ins_pipe(empty);
 5262 %}
 5263 








 5264 //----------Arithmetic Instructions--------------------------------------------
 5265 // Addition Instructions
 5266 // Register Addition
 5267 instruct addI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 5268   match(Set dst (AddI src1 src2));
 5269 
 5270   size(4);
 5271   format %{ &quot;add_32 $dst,$src1,$src2\t! int&quot; %}
 5272   ins_encode %{
 5273     __ add_32($dst$$Register, $src1$$Register, $src2$$Register);
 5274   %}
 5275   ins_pipe(ialu_reg_reg);
 5276 %}
 5277 
 5278 instruct addshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5279   match(Set dst (AddI (LShiftI src1 src2) src3));
 5280 
 5281   size(4);
 5282   format %{ &quot;add_32 $dst,$src3,$src1&lt;&lt;$src2\t! int&quot; %}
 5283   ins_encode %{
</pre>
<hr />
<pre>
10532   match(Set dst (LShiftVB src shift));
10533   size(4*1);
10534   ins_cost(DEFAULT_COST*1); // FIXME
10535   expand %{
10536     vsh8B_reg(dst, src, shift);
10537   %}
10538 %}
10539 
10540 instruct vsl16B_reg(vecX dst, vecX src, vecX shift) %{
10541   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10542   match(Set dst (LShiftVB src shift));
10543   size(4*1);
10544   ins_cost(DEFAULT_COST*1); // FIXME
10545   expand %{
10546     vsh16B_reg(dst, src, shift);
10547   %}
10548 %}
10549 
10550 instruct vsl8B_immI(vecD dst, vecD src, immI shift) %{
10551   predicate(n-&gt;as_Vector()-&gt;length() == 8);
<span class="line-modified">10552   match(Set dst (LShiftVB src shift));</span>
10553   size(4);
10554   ins_cost(DEFAULT_COST); // FIXME
10555   format %{
10556     &quot;VSHL.I8 $dst.D,$src.D,$shift\t! logical left shift packed8B&quot;
10557   %}
10558   ins_encode %{
10559     bool quad = false;
10560     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
10561              quad);
10562   %}
10563   ins_pipe( ialu_reg_reg ); // FIXME
10564 %}
10565 
10566 instruct vsl16B_immI(vecX dst, vecX src, immI shift) %{
10567   predicate(n-&gt;as_Vector()-&gt;length() == 16);
<span class="line-modified">10568   match(Set dst (LShiftVB src shift));</span>
10569   size(4);
10570   ins_cost(DEFAULT_COST); // FIXME
10571   format %{
10572     &quot;VSHL.I8 $dst.Q,$src.Q,$shift\t! logical left shift packed16B&quot;
10573   %}
10574   ins_encode %{
10575     bool quad = true;
10576     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
10577              quad);
10578   %}
10579   ins_pipe( ialu_reg_reg ); // FIXME
10580 %}
10581 
10582 // Shorts/Chars vector logical left/right shift
10583 instruct vsl4S_reg(vecD dst, vecD src, vecD shift) %{
10584   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10585   match(Set dst (LShiftVS src shift));
10586   match(Set dst (URShiftVS src shift));
10587   size(4*1);
10588   ins_cost(DEFAULT_COST*1); // FIXME
10589   expand %{
10590     vsh4S_reg(dst, src, shift);
10591   %}
10592 %}
10593 
10594 instruct vsl8S_reg(vecX dst, vecX src, vecX shift) %{
10595   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10596   match(Set dst (LShiftVS src shift));
10597   match(Set dst (URShiftVS src shift));
10598   size(4*1);
10599   ins_cost(DEFAULT_COST*1); // FIXME
10600   expand %{
10601     vsh8S_reg(dst, src, shift);
10602   %}
10603 %}
10604 
10605 instruct vsl4S_immI(vecD dst, vecD src, immI shift) %{
10606   predicate(n-&gt;as_Vector()-&gt;length() == 4);
<span class="line-modified">10607   match(Set dst (LShiftVS src shift));</span>
10608   size(4);
10609   ins_cost(DEFAULT_COST); // FIXME
10610   format %{
10611     &quot;VSHL.I16 $dst.D,$src.D,$shift\t! logical left shift packed4S&quot;
10612   %}
10613   ins_encode %{
10614     bool quad = false;
10615     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10616              quad);
10617   %}
10618   ins_pipe( ialu_reg_reg ); // FIXME
10619 %}
10620 
10621 instruct vsl8S_immI(vecX dst, vecX src, immI shift) %{
10622   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10623   match(Set dst (LShiftVS src shift));
10624   size(4);
10625   ins_cost(DEFAULT_COST); // FIXME
10626   format %{
10627     &quot;VSHL.I16 $dst.Q,$src.Q,$shift\t! logical left shift packed8S&quot;
</pre>
<hr />
<pre>
10642   size(4*1);
10643   ins_cost(DEFAULT_COST*1); // FIXME
10644   expand %{
10645     vsh2I_reg(dst, src, shift);
10646   %}
10647 %}
10648 
10649 instruct vsl4I_reg(vecX dst, vecX src, vecX shift) %{
10650   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
10651   match(Set dst (LShiftVI src shift));
10652   match(Set dst (URShiftVI src shift));
10653   size(4*1);
10654   ins_cost(DEFAULT_COST*1); // FIXME
10655   expand %{
10656     vsh4I_reg(dst, src, shift);
10657   %}
10658 %}
10659 
10660 instruct vsl2I_immI(vecD dst, vecD src, immI shift) %{
10661   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10662   match(Set dst (LShiftVI src shift));</span>
10663   size(4);
10664   ins_cost(DEFAULT_COST); // FIXME
10665   format %{
10666     &quot;VSHL.I32 $dst.D,$src.D,$shift\t! logical left shift packed2I&quot;
10667   %}
10668   ins_encode %{
10669     bool quad = false;
10670     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10671              quad);
10672   %}
10673   ins_pipe( ialu_reg_reg ); // FIXME
10674 %}
10675 
10676 instruct vsl4I_immI(vecX dst, vecX src, immI shift) %{
10677   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10678   match(Set dst (LShiftVI src shift));</span>
10679   size(4);
10680   ins_cost(DEFAULT_COST); // FIXME
10681   format %{
10682     &quot;VSHL.I32 $dst.Q,$src.Q,$shift\t! logical left shift packed4I&quot;
10683   %}
10684   ins_encode %{
10685     bool quad = true;
10686     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10687              quad);
10688   %}
10689   ins_pipe( ialu_reg_reg ); // FIXME
10690 %}
10691 
10692 // Longs vector logical left/right shift
10693 instruct vsl2L_reg(vecX dst, vecX src, vecX shift) %{
10694   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10695   match(Set dst (LShiftVL src shift));
10696   match(Set dst (URShiftVL src shift));
10697   size(4*1);
10698   ins_cost(DEFAULT_COST*1); // FIXME
10699   expand %{
10700     vsh2L_reg(dst, src, shift);
10701   %}
10702 %}
10703 
10704 instruct vsl2L_immI(vecX dst, vecX src, immI shift) %{
10705   predicate(n-&gt;as_Vector()-&gt;length() == 2);
<span class="line-modified">10706   match(Set dst (LShiftVL src shift));</span>
10707   size(4);
10708   ins_cost(DEFAULT_COST); // FIXME
10709   format %{
10710     &quot;VSHL.I64 $dst.Q,$src.Q,$shift\t! logical left shift packed2L&quot;
10711   %}
10712   ins_encode %{
10713     bool quad = true;
10714     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
10715              quad);
10716   %}
10717   ins_pipe( ialu_reg_reg ); // FIXME
10718 %}
10719 
10720 // ----------------------- LogicalRightShift -----------------------------------
10721 
10722 // Bytes/Shorts vector logical right shift produces incorrect Java result
10723 // for negative data because java code convert short value into int with
10724 // sign extension before a shift.
10725 
10726 // Chars vector logical right shift
10727 instruct vsrl4S_immI(vecD dst, vecD src, immI shift) %{
10728   predicate(n-&gt;as_Vector()-&gt;length() == 4);
<span class="line-modified">10729   match(Set dst (URShiftVS src shift));</span>
10730   size(4);
10731   ins_cost(DEFAULT_COST); // FIXME
10732   format %{
10733     &quot;VSHR.U16 $dst.D,$src.D,$shift\t! logical right shift packed4S&quot;
10734   %}
10735   ins_encode %{
10736     bool quad = false;
10737     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10738              quad);
10739   %}
10740   ins_pipe( ialu_reg_reg ); // FIXME
10741 %}
10742 
10743 instruct vsrl8S_immI(vecX dst, vecX src, immI shift) %{
10744   predicate(n-&gt;as_Vector()-&gt;length() == 8);
<span class="line-modified">10745   match(Set dst (URShiftVS src shift));</span>
10746   size(4);
10747   ins_cost(DEFAULT_COST); // FIXME
10748   format %{
10749     &quot;VSHR.U16 $dst.Q,$src.Q,$shift\t! logical right shift packed8S&quot;
10750   %}
10751   ins_encode %{
10752     bool quad = true;
10753     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10754              quad);
10755   %}
10756   ins_pipe( ialu_reg_reg ); // FIXME
10757 %}
10758 
10759 // Integers vector logical right shift
10760 instruct vsrl2I_immI(vecD dst, vecD src, immI shift) %{
10761   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10762   match(Set dst (URShiftVI src shift));</span>
10763   size(4);
10764   ins_cost(DEFAULT_COST); // FIXME
10765   format %{
10766     &quot;VSHR.U32 $dst.D,$src.D,$shift\t! logical right shift packed2I&quot;
10767   %}
10768   ins_encode %{
10769     bool quad = false;
10770     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10771              quad);
10772   %}
10773   ins_pipe( ialu_reg_reg ); // FIXME
10774 %}
10775 
10776 instruct vsrl4I_immI(vecX dst, vecX src, immI shift) %{
10777   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10778   match(Set dst (URShiftVI src shift));</span>
10779   size(4);
10780   ins_cost(DEFAULT_COST); // FIXME
10781   format %{
10782     &quot;VSHR.U32 $dst.Q,$src.Q,$shift\t! logical right shift packed4I&quot;
10783   %}
10784   ins_encode %{
10785     bool quad = true;
10786     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10787              quad);
10788   %}
10789   ins_pipe( ialu_reg_reg ); // FIXME
10790 %}
10791 
10792 // Longs vector logical right shift
10793 instruct vsrl2L_immI(vecX dst, vecX src, immI shift) %{
10794   predicate(n-&gt;as_Vector()-&gt;length() == 2);
<span class="line-modified">10795   match(Set dst (URShiftVL src shift));</span>
10796   size(4);
10797   ins_cost(DEFAULT_COST); // FIXME
10798   format %{
10799     &quot;VSHR.U64 $dst.Q,$src.Q,$shift\t! logical right shift packed2L&quot;
10800   %}
10801   ins_encode %{
10802     bool quad = true;
10803     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
10804              quad);
10805   %}
10806   ins_pipe( ialu_reg_reg ); // FIXME
10807 %}
10808 
10809 // ------------------- ArithmeticRightShift -----------------------------------
10810 
10811 // Bytes vector arithmetic left/right shift based on sign
10812 instruct vsha8B_reg(vecD dst, vecD src, vecD shift) %{
10813   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10814   effect(DEF dst, USE src, USE shift);
10815   size(4);
</pre>
</td>
<td>
<hr />
<pre>
    1 //
<span class="line-modified">    2 // Copyright (c) 2008, 2020, Oracle and/or its affiliates. All rights reserved.</span>
    3 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    4 //
    5 // This code is free software; you can redistribute it and/or modify it
    6 // under the terms of the GNU General Public License version 2 only, as
    7 // published by the Free Software Foundation.
    8 //
    9 // This code is distributed in the hope that it will be useful, but WITHOUT
   10 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   11 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   12 // version 2 for more details (a copy is included in the LICENSE file that
   13 // accompanied this code).
   14 //
   15 // You should have received a copy of the GNU General Public License version
   16 // 2 along with this work; if not, write to the Free Software Foundation,
   17 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   18 //
   19 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   20 // or visit www.oracle.com if you need additional information or have any
   21 // questions.
   22 //
</pre>
<hr />
<pre>
  334     st-&gt;print(&quot;\n\t&quot;);
  335     st-&gt;print(&quot;MOV    Rtemp, #PollAddr\t! Load Polling address\n\t&quot;);
  336     st-&gt;print(&quot;LDR    Rtemp,[Rtemp]\t!Poll for Safepointing&quot;);
  337   }
  338 }
  339 #endif
  340 
  341 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  342   MacroAssembler _masm(&amp;cbuf);
  343   Compile* C = ra_-&gt;C;
  344 
  345   size_t framesize = C-&gt;frame_size_in_bytes();
  346   framesize -= 2*wordSize;
  347   if (framesize != 0) {
  348     __ add_slow(SP, SP, framesize);
  349   }
  350   __ raw_pop(FP, LR);
  351 
  352   // If this does safepoint polling, then do it here
  353   if (do_polling() &amp;&amp; ra_-&gt;C-&gt;is_method_compilation()) {
<span class="line-modified">  354     __ read_polling_page(Rtemp, relocInfo::poll_return_type);</span>



  355   }
  356 }
  357 
  358 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
  359   return MachNode::size(ra_);
  360 }
  361 
  362 int MachEpilogNode::reloc() const {
  363   return 16; // a large enough number
  364 }
  365 
  366 const Pipeline * MachEpilogNode::pipeline() const {
  367   return MachNode::pipeline_class();
  368 }
  369 
  370 int MachEpilogNode::safepoint_offset() const {
  371   assert( do_polling(), &quot;no return for this epilog node&quot;);
  372   //  return MacroAssembler::size_of_sethi(os::get_polling_page());
  373   Unimplemented();
  374   return 0;
</pre>
<hr />
<pre>
  951   case Op_OrV:
  952   case Op_XorV:
  953     return VM_Version::has_simd();
  954   case Op_LoadVector:
  955   case Op_StoreVector:
  956   case Op_AddVF:
  957   case Op_SubVF:
  958   case Op_MulVF:
  959     return VM_Version::has_vfp() || VM_Version::has_simd();
  960   case Op_AddVD:
  961   case Op_SubVD:
  962   case Op_MulVD:
  963   case Op_DivVF:
  964   case Op_DivVD:
  965     return VM_Version::has_vfp();
  966   }
  967 
  968   return true;  // Per default match rules are supported.
  969 }
  970 
<span class="line-modified">  971 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {</span>
  972 
  973   // TODO
  974   // identify extra cases that we might want to provide match rules for
  975   // e.g. Op_ vector nodes and other intrinsics while guarding with vlen
  976   bool ret_value = match_rule_supported(opcode);
  977   // Add rules here.
  978 
  979   return ret_value;  // Per default match rules are supported.
  980 }
  981 
  982 const bool Matcher::has_predicated_vectors(void) {
  983   return false;
  984 }
  985 
  986 const int Matcher::float_pressure(int default_pressure_threshold) {
  987   return default_pressure_threshold;
  988 }
  989 
  990 int Matcher::regnum_to_fpu_offset(int regnum) {
  991   return regnum - 32; // The FP registers are in the second chunk
</pre>
<hr />
<pre>
 1057 
 1058 // No scaling for the parameter the ClearArray node.
 1059 const bool Matcher::init_array_count_is_in_bytes = true;
 1060 
 1061 // Needs 2 CMOV&#39;s for longs.
 1062 const int Matcher::long_cmove_cost() { return 2; }
 1063 
 1064 // CMOVF/CMOVD are expensive on ARM.
 1065 const int Matcher::float_cmove_cost() { return ConditionalMoveLimit; }
 1066 
 1067 // Does the CPU require late expand (see block.cpp for description of late expand)?
 1068 const bool Matcher::require_postalloc_expand = false;
 1069 
 1070 // Do we need to mask the count passed to shift instructions or does
 1071 // the cpu only look at the lower 5/6 bits anyway?
 1072 // FIXME: does this handle vector shifts as well?
 1073 const bool Matcher::need_masked_shift_count = true;
 1074 
 1075 const bool Matcher::convi2l_type_required = true;
 1076 
<span class="line-added"> 1077 // No support for generic vector operands.</span>
<span class="line-added"> 1078 const bool Matcher::supports_generic_vector_operands  = false;</span>
<span class="line-added"> 1079 </span>
<span class="line-added"> 1080 MachOper* Matcher::specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {</span>
<span class="line-added"> 1081   ShouldNotReachHere(); // generic vector operands not supported</span>
<span class="line-added"> 1082   return NULL;</span>
<span class="line-added"> 1083 }</span>
<span class="line-added"> 1084 </span>
<span class="line-added"> 1085 bool Matcher::is_generic_reg2reg_move(MachNode* m) {</span>
<span class="line-added"> 1086   ShouldNotReachHere();  // generic vector operands not supported</span>
<span class="line-added"> 1087   return false;</span>
<span class="line-added"> 1088 }</span>
<span class="line-added"> 1089 </span>
<span class="line-added"> 1090 bool Matcher::is_generic_vector(MachOper* opnd)  {</span>
<span class="line-added"> 1091   ShouldNotReachHere();  // generic vector operands not supported</span>
<span class="line-added"> 1092   return false;</span>
<span class="line-added"> 1093 }</span>
<span class="line-added"> 1094 </span>
 1095 // Should the Matcher clone shifts on addressing modes, expecting them
 1096 // to be subsumed into complex addressing expressions or compute them
 1097 // into registers?
 1098 bool Matcher::clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 1099   return clone_base_plus_offset_address(m, mstack, address_visited);
 1100 }
 1101 
 1102 void Compile::reshape_address(AddPNode* addp) {
 1103 }
 1104 
 1105 bool Matcher::narrow_oop_use_complex_address() {
 1106   NOT_LP64(ShouldNotCallThis());
 1107   assert(UseCompressedOops, &quot;only for compressed oops code&quot;);
 1108   return false;
 1109 }
 1110 
 1111 bool Matcher::narrow_klass_use_complex_address() {
 1112   NOT_LP64(ShouldNotCallThis());
 1113   assert(UseCompressedClassPointers, &quot;only for compressed klass code&quot;);
 1114   return false;
</pre>
<hr />
<pre>
 1123   NOT_LP64(ShouldNotCallThis());
 1124   return true;
 1125 }
 1126 
 1127 // Is it better to copy float constants, or load them directly from memory?
 1128 // Intel can load a float constant from a direct address, requiring no
 1129 // extra registers.  Most RISCs will have to materialize an address into a
 1130 // register first, so they would do better to copy the constant from stack.
 1131 const bool Matcher::rematerialize_float_constants = false;
 1132 
 1133 // If CPU can load and store mis-aligned doubles directly then no fixup is
 1134 // needed.  Else we split the double into 2 integer pieces and move it
 1135 // piece-by-piece.  Only happens when passing doubles into C code as the
 1136 // Java calling convention forces doubles to be aligned.
 1137 const bool Matcher::misaligned_doubles_ok = false;
 1138 
 1139 // No-op on ARM.
 1140 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 1141 }
 1142 
<span class="line-modified"> 1143 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.</span>

 1144 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 1145 
 1146 // Are floats converted to double when stored to stack during deoptimization?
 1147 // ARM does not handle callee-save floats.
 1148 bool Matcher::float_in_double() {
 1149   return false;
 1150 }
 1151 
 1152 // Do ints take an entire long register or just half?
 1153 // Note that we if-def off of _LP64.
 1154 // The relevant question is how the int is callee-saved.  In _LP64
 1155 // the whole long is written but de-opt&#39;ing will have to extract
 1156 // the relevant 32 bits, in not-_LP64 only the low 32 bits is written.
 1157 #ifdef _LP64
 1158 const bool Matcher::int_in_long = true;
 1159 #else
 1160 const bool Matcher::int_in_long = false;
 1161 #endif
 1162 
 1163 // Return whether or not this register is ever used as an argument.  This
</pre>
<hr />
<pre>
 2201   interface(REG_INTER);
 2202 %}
 2203 
 2204 
 2205 operand R0RegP() %{
 2206   constraint(ALLOC_IN_RC(R0_regP));
 2207   match(iRegP);
 2208 
 2209   format %{ %}
 2210   interface(REG_INTER);
 2211 %}
 2212 
 2213 operand R1RegP() %{
 2214   constraint(ALLOC_IN_RC(R1_regP));
 2215   match(iRegP);
 2216 
 2217   format %{ %}
 2218   interface(REG_INTER);
 2219 %}
 2220 
<span class="line-added"> 2221 operand R8RegP() %{</span>
<span class="line-added"> 2222   constraint(ALLOC_IN_RC(R8_regP));</span>
<span class="line-added"> 2223   match(iRegP);</span>
<span class="line-added"> 2224 </span>
<span class="line-added"> 2225   format %{ %}</span>
<span class="line-added"> 2226   interface(REG_INTER);</span>
<span class="line-added"> 2227 %}</span>
<span class="line-added"> 2228 </span>
<span class="line-added"> 2229 operand R9RegP() %{</span>
<span class="line-added"> 2230   constraint(ALLOC_IN_RC(R9_regP));</span>
<span class="line-added"> 2231   match(iRegP);</span>
<span class="line-added"> 2232 </span>
<span class="line-added"> 2233   format %{ %}</span>
<span class="line-added"> 2234   interface(REG_INTER);</span>
<span class="line-added"> 2235 %}</span>
<span class="line-added"> 2236 </span>
<span class="line-added"> 2237 operand R12RegP() %{</span>
<span class="line-added"> 2238   constraint(ALLOC_IN_RC(R12_regP));</span>
<span class="line-added"> 2239   match(iRegP);</span>
<span class="line-added"> 2240 </span>
<span class="line-added"> 2241   format %{ %}</span>
<span class="line-added"> 2242   interface(REG_INTER);</span>
<span class="line-added"> 2243 %}</span>
<span class="line-added"> 2244 </span>
 2245 operand R2RegP() %{
 2246   constraint(ALLOC_IN_RC(R2_regP));
 2247   match(iRegP);
 2248 
 2249   format %{ %}
 2250   interface(REG_INTER);
 2251 %}
 2252 
 2253 operand RExceptionRegP() %{
 2254   constraint(ALLOC_IN_RC(Rexception_regP));
 2255   match(iRegP);
 2256 
 2257   format %{ %}
 2258   interface(REG_INTER);
 2259 %}
 2260 
 2261 operand RthreadRegP() %{
 2262   constraint(ALLOC_IN_RC(Rthread_regP));
 2263   match(iRegP);
 2264 
 2265   format %{ %}
 2266   interface(REG_INTER);
 2267 %}
 2268 
 2269 operand IPRegP() %{
 2270   constraint(ALLOC_IN_RC(IP_regP));
 2271   match(iRegP);
 2272 
 2273   format %{ %}
 2274   interface(REG_INTER);
 2275 %}
 2276 
<span class="line-added"> 2277 operand SPRegP() %{</span>
<span class="line-added"> 2278   constraint(ALLOC_IN_RC(SP_regP));</span>
<span class="line-added"> 2279   match(iRegP);</span>
<span class="line-added"> 2280 </span>
<span class="line-added"> 2281   format %{ %}</span>
<span class="line-added"> 2282   interface(REG_INTER);</span>
<span class="line-added"> 2283 %}</span>
<span class="line-added"> 2284 </span>
 2285 operand LRRegP() %{
 2286   constraint(ALLOC_IN_RC(LR_regP));
 2287   match(iRegP);
 2288 
 2289   format %{ %}
 2290   interface(REG_INTER);
 2291 %}
 2292 
 2293 operand R0RegI() %{
 2294   constraint(ALLOC_IN_RC(R0_regI));
 2295   match(iRegI);
 2296 
 2297   format %{ %}
 2298   interface(REG_INTER);
 2299 %}
 2300 
 2301 operand R1RegI() %{
 2302   constraint(ALLOC_IN_RC(R1_regI));
 2303   match(iRegI);
 2304 
</pre>
<hr />
<pre>
 4377   ins_cost(MEMORY_REF_COST);
 4378   format %{ &quot;FLDD  $dst, [$constanttablebase + $constantoffset]\t! load from constant table: double=$src&quot; %}
 4379 
 4380   ins_encode %{
 4381     Register r = $constanttablebase;
 4382     int offset  = $constantoffset($src);
 4383     if (!is_memoryD(offset)) {                // can&#39;t use a predicate
 4384                                               // in load constant instructs
 4385       __ add_slow($tmp$$Register, r, offset);
 4386       r = $tmp$$Register;
 4387       offset = 0;
 4388     }
 4389     __ ldr_double($dst$$FloatRegister, Address(r, offset));
 4390   %}
 4391   ins_pipe(loadConFD);
 4392 %}
 4393 
 4394 // Prefetch instructions.
 4395 // Must be safe to execute with invalid address (cannot fault).
 4396 
<span class="line-modified"> 4397 instruct prefetchAlloc_mp( memoryP mem ) %{</span>
<span class="line-added"> 4398   predicate(VM_Version::has_multiprocessing_extensions());</span>
 4399   match( PrefetchAllocation mem );
 4400   ins_cost(MEMORY_REF_COST);
 4401   size(4);
 4402 
 4403   format %{ &quot;PLDW $mem\t! Prefetch allocation&quot; %}
 4404   ins_encode %{
 4405     __ pldw($mem$$Address);
 4406   %}
 4407   ins_pipe(iload_mem);
 4408 %}
 4409 
<span class="line-added"> 4410 instruct prefetchAlloc_sp( memoryP mem ) %{</span>
<span class="line-added"> 4411   predicate(!VM_Version::has_multiprocessing_extensions());</span>
<span class="line-added"> 4412   match( PrefetchAllocation mem );</span>
<span class="line-added"> 4413   ins_cost(MEMORY_REF_COST);</span>
<span class="line-added"> 4414   size(4);</span>
<span class="line-added"> 4415 </span>
<span class="line-added"> 4416   format %{ &quot;PLD $mem\t! Prefetch allocation&quot; %}</span>
<span class="line-added"> 4417   ins_encode %{</span>
<span class="line-added"> 4418     __ pld($mem$$Address);</span>
<span class="line-added"> 4419   %}</span>
<span class="line-added"> 4420   ins_pipe(iload_mem);</span>
<span class="line-added"> 4421 %}</span>
<span class="line-added"> 4422 </span>
<span class="line-added"> 4423 </span>
 4424 //----------Store Instructions-------------------------------------------------
 4425 // Store Byte
 4426 instruct storeB(memoryB mem, store_RegI src) %{
 4427   match(Set mem (StoreB mem src));
 4428   ins_cost(MEMORY_REF_COST);
 4429 
 4430   size(4);
 4431   format %{ &quot;STRB    $src,$mem\t! byte&quot; %}
 4432   ins_encode %{
 4433     __ strb($src$$Register, $mem$$Address);
 4434   %}
 4435   ins_pipe(istore_mem_reg);
 4436 %}
 4437 
 4438 instruct storeCM(memoryB mem, store_RegI src) %{
 4439   match(Set mem (StoreCM mem src));
 4440   ins_cost(MEMORY_REF_COST);
 4441 
 4442   size(4);
 4443   format %{ &quot;STRB    $src,$mem\t! CMS card-mark byte&quot; %}
</pre>
<hr />
<pre>
 5305   ins_encode( /*empty encoding*/ );
 5306   ins_pipe(empty);
 5307 %}
 5308 
 5309 
 5310 instruct castPP( iRegP dst ) %{
 5311   match(Set dst (CastPP dst));
 5312   format %{ &quot;! castPP of $dst&quot; %}
 5313   ins_encode( /*empty encoding*/ );
 5314   ins_pipe(empty);
 5315 %}
 5316 
 5317 instruct castII( iRegI dst ) %{
 5318   match(Set dst (CastII dst));
 5319   format %{ &quot;! castII of $dst&quot; %}
 5320   ins_encode( /*empty encoding*/ );
 5321   ins_cost(0);
 5322   ins_pipe(empty);
 5323 %}
 5324 
<span class="line-added"> 5325 instruct castLL( iRegL dst ) %{</span>
<span class="line-added"> 5326   match(Set dst (CastLL dst));</span>
<span class="line-added"> 5327   format %{ &quot;! castLL of $dst&quot; %}</span>
<span class="line-added"> 5328   ins_encode( /*empty encoding*/ );</span>
<span class="line-added"> 5329   ins_cost(0);</span>
<span class="line-added"> 5330   ins_pipe(empty);</span>
<span class="line-added"> 5331 %}</span>
<span class="line-added"> 5332 </span>
 5333 //----------Arithmetic Instructions--------------------------------------------
 5334 // Addition Instructions
 5335 // Register Addition
 5336 instruct addI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 5337   match(Set dst (AddI src1 src2));
 5338 
 5339   size(4);
 5340   format %{ &quot;add_32 $dst,$src1,$src2\t! int&quot; %}
 5341   ins_encode %{
 5342     __ add_32($dst$$Register, $src1$$Register, $src2$$Register);
 5343   %}
 5344   ins_pipe(ialu_reg_reg);
 5345 %}
 5346 
 5347 instruct addshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5348   match(Set dst (AddI (LShiftI src1 src2) src3));
 5349 
 5350   size(4);
 5351   format %{ &quot;add_32 $dst,$src3,$src1&lt;&lt;$src2\t! int&quot; %}
 5352   ins_encode %{
</pre>
<hr />
<pre>
10601   match(Set dst (LShiftVB src shift));
10602   size(4*1);
10603   ins_cost(DEFAULT_COST*1); // FIXME
10604   expand %{
10605     vsh8B_reg(dst, src, shift);
10606   %}
10607 %}
10608 
10609 instruct vsl16B_reg(vecX dst, vecX src, vecX shift) %{
10610   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10611   match(Set dst (LShiftVB src shift));
10612   size(4*1);
10613   ins_cost(DEFAULT_COST*1); // FIXME
10614   expand %{
10615     vsh16B_reg(dst, src, shift);
10616   %}
10617 %}
10618 
10619 instruct vsl8B_immI(vecD dst, vecD src, immI shift) %{
10620   predicate(n-&gt;as_Vector()-&gt;length() == 8);
<span class="line-modified">10621   match(Set dst (LShiftVB src (LShiftCntV shift)));</span>
10622   size(4);
10623   ins_cost(DEFAULT_COST); // FIXME
10624   format %{
10625     &quot;VSHL.I8 $dst.D,$src.D,$shift\t! logical left shift packed8B&quot;
10626   %}
10627   ins_encode %{
10628     bool quad = false;
10629     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
10630              quad);
10631   %}
10632   ins_pipe( ialu_reg_reg ); // FIXME
10633 %}
10634 
10635 instruct vsl16B_immI(vecX dst, vecX src, immI shift) %{
10636   predicate(n-&gt;as_Vector()-&gt;length() == 16);
<span class="line-modified">10637   match(Set dst (LShiftVB src (LShiftCntV shift)));</span>
10638   size(4);
10639   ins_cost(DEFAULT_COST); // FIXME
10640   format %{
10641     &quot;VSHL.I8 $dst.Q,$src.Q,$shift\t! logical left shift packed16B&quot;
10642   %}
10643   ins_encode %{
10644     bool quad = true;
10645     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
10646              quad);
10647   %}
10648   ins_pipe( ialu_reg_reg ); // FIXME
10649 %}
10650 
10651 // Shorts/Chars vector logical left/right shift
10652 instruct vsl4S_reg(vecD dst, vecD src, vecD shift) %{
10653   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10654   match(Set dst (LShiftVS src shift));
10655   match(Set dst (URShiftVS src shift));
10656   size(4*1);
10657   ins_cost(DEFAULT_COST*1); // FIXME
10658   expand %{
10659     vsh4S_reg(dst, src, shift);
10660   %}
10661 %}
10662 
10663 instruct vsl8S_reg(vecX dst, vecX src, vecX shift) %{
10664   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10665   match(Set dst (LShiftVS src shift));
10666   match(Set dst (URShiftVS src shift));
10667   size(4*1);
10668   ins_cost(DEFAULT_COST*1); // FIXME
10669   expand %{
10670     vsh8S_reg(dst, src, shift);
10671   %}
10672 %}
10673 
10674 instruct vsl4S_immI(vecD dst, vecD src, immI shift) %{
10675   predicate(n-&gt;as_Vector()-&gt;length() == 4);
<span class="line-modified">10676   match(Set dst (LShiftVS src (LShiftCntV shift)));</span>
10677   size(4);
10678   ins_cost(DEFAULT_COST); // FIXME
10679   format %{
10680     &quot;VSHL.I16 $dst.D,$src.D,$shift\t! logical left shift packed4S&quot;
10681   %}
10682   ins_encode %{
10683     bool quad = false;
10684     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10685              quad);
10686   %}
10687   ins_pipe( ialu_reg_reg ); // FIXME
10688 %}
10689 
10690 instruct vsl8S_immI(vecX dst, vecX src, immI shift) %{
10691   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10692   match(Set dst (LShiftVS src shift));
10693   size(4);
10694   ins_cost(DEFAULT_COST); // FIXME
10695   format %{
10696     &quot;VSHL.I16 $dst.Q,$src.Q,$shift\t! logical left shift packed8S&quot;
</pre>
<hr />
<pre>
10711   size(4*1);
10712   ins_cost(DEFAULT_COST*1); // FIXME
10713   expand %{
10714     vsh2I_reg(dst, src, shift);
10715   %}
10716 %}
10717 
10718 instruct vsl4I_reg(vecX dst, vecX src, vecX shift) %{
10719   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
10720   match(Set dst (LShiftVI src shift));
10721   match(Set dst (URShiftVI src shift));
10722   size(4*1);
10723   ins_cost(DEFAULT_COST*1); // FIXME
10724   expand %{
10725     vsh4I_reg(dst, src, shift);
10726   %}
10727 %}
10728 
10729 instruct vsl2I_immI(vecD dst, vecD src, immI shift) %{
10730   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10731   match(Set dst (LShiftVI src (LShiftCntV shift)));</span>
10732   size(4);
10733   ins_cost(DEFAULT_COST); // FIXME
10734   format %{
10735     &quot;VSHL.I32 $dst.D,$src.D,$shift\t! logical left shift packed2I&quot;
10736   %}
10737   ins_encode %{
10738     bool quad = false;
10739     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10740              quad);
10741   %}
10742   ins_pipe( ialu_reg_reg ); // FIXME
10743 %}
10744 
10745 instruct vsl4I_immI(vecX dst, vecX src, immI shift) %{
10746   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10747   match(Set dst (LShiftVI src (LShiftCntV shift)));</span>
10748   size(4);
10749   ins_cost(DEFAULT_COST); // FIXME
10750   format %{
10751     &quot;VSHL.I32 $dst.Q,$src.Q,$shift\t! logical left shift packed4I&quot;
10752   %}
10753   ins_encode %{
10754     bool quad = true;
10755     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10756              quad);
10757   %}
10758   ins_pipe( ialu_reg_reg ); // FIXME
10759 %}
10760 
10761 // Longs vector logical left/right shift
10762 instruct vsl2L_reg(vecX dst, vecX src, vecX shift) %{
10763   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10764   match(Set dst (LShiftVL src shift));
10765   match(Set dst (URShiftVL src shift));
10766   size(4*1);
10767   ins_cost(DEFAULT_COST*1); // FIXME
10768   expand %{
10769     vsh2L_reg(dst, src, shift);
10770   %}
10771 %}
10772 
10773 instruct vsl2L_immI(vecX dst, vecX src, immI shift) %{
10774   predicate(n-&gt;as_Vector()-&gt;length() == 2);
<span class="line-modified">10775   match(Set dst (LShiftVL src (LShiftCntV shift)));</span>
10776   size(4);
10777   ins_cost(DEFAULT_COST); // FIXME
10778   format %{
10779     &quot;VSHL.I64 $dst.Q,$src.Q,$shift\t! logical left shift packed2L&quot;
10780   %}
10781   ins_encode %{
10782     bool quad = true;
10783     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
10784              quad);
10785   %}
10786   ins_pipe( ialu_reg_reg ); // FIXME
10787 %}
10788 
10789 // ----------------------- LogicalRightShift -----------------------------------
10790 
10791 // Bytes/Shorts vector logical right shift produces incorrect Java result
10792 // for negative data because java code convert short value into int with
10793 // sign extension before a shift.
10794 
10795 // Chars vector logical right shift
10796 instruct vsrl4S_immI(vecD dst, vecD src, immI shift) %{
10797   predicate(n-&gt;as_Vector()-&gt;length() == 4);
<span class="line-modified">10798   match(Set dst (URShiftVS src (RShiftCntV shift)));</span>
10799   size(4);
10800   ins_cost(DEFAULT_COST); // FIXME
10801   format %{
10802     &quot;VSHR.U16 $dst.D,$src.D,$shift\t! logical right shift packed4S&quot;
10803   %}
10804   ins_encode %{
10805     bool quad = false;
10806     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10807              quad);
10808   %}
10809   ins_pipe( ialu_reg_reg ); // FIXME
10810 %}
10811 
10812 instruct vsrl8S_immI(vecX dst, vecX src, immI shift) %{
10813   predicate(n-&gt;as_Vector()-&gt;length() == 8);
<span class="line-modified">10814   match(Set dst (URShiftVS src (RShiftCntV shift)));</span>
10815   size(4);
10816   ins_cost(DEFAULT_COST); // FIXME
10817   format %{
10818     &quot;VSHR.U16 $dst.Q,$src.Q,$shift\t! logical right shift packed8S&quot;
10819   %}
10820   ins_encode %{
10821     bool quad = true;
10822     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10823              quad);
10824   %}
10825   ins_pipe( ialu_reg_reg ); // FIXME
10826 %}
10827 
10828 // Integers vector logical right shift
10829 instruct vsrl2I_immI(vecD dst, vecD src, immI shift) %{
10830   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10831   match(Set dst (URShiftVI src (RShiftCntV shift)));</span>
10832   size(4);
10833   ins_cost(DEFAULT_COST); // FIXME
10834   format %{
10835     &quot;VSHR.U32 $dst.D,$src.D,$shift\t! logical right shift packed2I&quot;
10836   %}
10837   ins_encode %{
10838     bool quad = false;
10839     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10840              quad);
10841   %}
10842   ins_pipe( ialu_reg_reg ); // FIXME
10843 %}
10844 
10845 instruct vsrl4I_immI(vecX dst, vecX src, immI shift) %{
10846   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10847   match(Set dst (URShiftVI src (RShiftCntV shift)));</span>
10848   size(4);
10849   ins_cost(DEFAULT_COST); // FIXME
10850   format %{
10851     &quot;VSHR.U32 $dst.Q,$src.Q,$shift\t! logical right shift packed4I&quot;
10852   %}
10853   ins_encode %{
10854     bool quad = true;
10855     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10856              quad);
10857   %}
10858   ins_pipe( ialu_reg_reg ); // FIXME
10859 %}
10860 
10861 // Longs vector logical right shift
10862 instruct vsrl2L_immI(vecX dst, vecX src, immI shift) %{
10863   predicate(n-&gt;as_Vector()-&gt;length() == 2);
<span class="line-modified">10864   match(Set dst (URShiftVL src (RShiftCntV shift)));</span>
10865   size(4);
10866   ins_cost(DEFAULT_COST); // FIXME
10867   format %{
10868     &quot;VSHR.U64 $dst.Q,$src.Q,$shift\t! logical right shift packed2L&quot;
10869   %}
10870   ins_encode %{
10871     bool quad = true;
10872     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
10873              quad);
10874   %}
10875   ins_pipe( ialu_reg_reg ); // FIXME
10876 %}
10877 
10878 // ------------------- ArithmeticRightShift -----------------------------------
10879 
10880 // Bytes vector arithmetic left/right shift based on sign
10881 instruct vsha8B_reg(vecD dst, vecD src, vecD shift) %{
10882   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10883   effect(DEF dst, USE src, USE shift);
10884   size(4);
</pre>
</td>
</tr>
</table>
<center><a href="abstractInterpreter_arm.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="arm_32.ad.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>