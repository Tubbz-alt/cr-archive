<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/ppc/templateTable_ppc_64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="templateInterpreterGenerator_ppc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="vm_version_ext_ppc.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/ppc/templateTable_ppc_64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  29 #include &quot;interpreter/interpreter.hpp&quot;
  30 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  31 #include &quot;interpreter/interp_masm.hpp&quot;
  32 #include &quot;interpreter/templateInterpreter.hpp&quot;
  33 #include &quot;interpreter/templateTable.hpp&quot;
  34 #include &quot;memory/universe.hpp&quot;

  35 #include &quot;oops/objArrayKlass.hpp&quot;
  36 #include &quot;oops/oop.inline.hpp&quot;
  37 #include &quot;prims/methodHandles.hpp&quot;
  38 #include &quot;runtime/frame.inline.hpp&quot;
  39 #include &quot;runtime/safepointMechanism.hpp&quot;
  40 #include &quot;runtime/sharedRuntime.hpp&quot;
  41 #include &quot;runtime/stubRoutines.hpp&quot;
  42 #include &quot;runtime/synchronizer.hpp&quot;
  43 #include &quot;utilities/macros.hpp&quot;

  44 
  45 #undef __
  46 #define __ _masm-&gt;
  47 
  48 // ============================================================================
  49 // Misc helpers
  50 
  51 // Do an oop store like *(base + index) = val OR *(base + offset) = val
  52 // (only one of both variants is possible at the same time).
  53 // Index can be noreg.
  54 // Kills:
  55 //   Rbase, Rtmp
  56 static void do_oop_store(InterpreterMacroAssembler* _masm,
  57                          Register           base,
  58                          RegisterOrConstant offset,
  59                          Register           val,         // Noreg means always null.
  60                          Register           tmp1,
  61                          Register           tmp2,
  62                          Register           tmp3,
  63                          DecoratorSet       decorators) {
</pre>
<hr />
<pre>
2215 //   - _f12_oop
2216 // acquired, because these are asked if the cache is already resolved. We don&#39;t
2217 // want to float loads above this check.
2218 // See also comments in ConstantPoolCacheEntry::bytecode_1(),
2219 // ConstantPoolCacheEntry::bytecode_2() and ConstantPoolCacheEntry::f1();
2220 
2221 // Call into the VM if call site is not yet resolved
2222 //
2223 // Input regs:
2224 //   - None, all passed regs are outputs.
2225 //
2226 // Returns:
2227 //   - Rcache:  The const pool cache entry that contains the resolved result.
2228 //   - Rresult: Either noreg or output for f1/f2.
2229 //
2230 // Kills:
2231 //   - Rscratch
2232 void TemplateTable::resolve_cache_and_index(int byte_no, Register Rcache, Register Rscratch, size_t index_size) {
2233 
2234   __ get_cache_and_index_at_bcp(Rcache, 1, index_size);
<span class="line-modified">2235   Label Lresolved, Ldone;</span>
2236 
2237   Bytecodes::Code code = bytecode();
2238   switch (code) {
2239     case Bytecodes::_nofast_getfield: code = Bytecodes::_getfield; break;
2240     case Bytecodes::_nofast_putfield: code = Bytecodes::_putfield; break;
2241     default:
2242       break;
2243   }
2244 
2245   assert(byte_no == f1_byte || byte_no == f2_byte, &quot;byte_no out of range&quot;);
2246   // We are resolved if the indices offset contains the current bytecode.
2247 #if defined(VM_LITTLE_ENDIAN)
2248   __ lbz(Rscratch, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::indices_offset()) + byte_no + 1, Rcache);
2249 #else
2250   __ lbz(Rscratch, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::indices_offset()) + 7 - (byte_no + 1), Rcache);
2251 #endif
2252   // Acquire by cmp-br-isync (see below).
2253   __ cmpdi(CCR0, Rscratch, (int)code);
2254   __ beq(CCR0, Lresolved);
2255 



2256   address entry = CAST_FROM_FN_PTR(address, InterpreterRuntime::resolve_from_cache);
2257   __ li(R4_ARG2, code);
2258   __ call_VM(noreg, entry, R4_ARG2, true);
2259 
2260   // Update registers with resolved info.
2261   __ get_cache_and_index_at_bcp(Rcache, 1, index_size);
2262   __ b(Ldone);
2263 
2264   __ bind(Lresolved);
2265   __ isync(); // Order load wrt. succeeding loads.











2266   __ bind(Ldone);
2267 }
2268 
2269 // Load the constant pool cache entry at field accesses into registers.
2270 // The Rcache and Rindex registers must be set before call.
2271 // Input:
2272 //   - Rcache, Rindex
2273 // Output:
2274 //   - Robj, Roffset, Rflags
2275 void TemplateTable::load_field_cp_cache_entry(Register Robj,
2276                                               Register Rcache,
2277                                               Register Rindex /* unused on PPC64 */,
2278                                               Register Roffset,
2279                                               Register Rflags,
2280                                               bool is_static = false) {
2281   assert_different_registers(Rcache, Rflags, Roffset);
2282   // assert(Rindex == noreg, &quot;parameter not used on PPC64&quot;);
2283 
2284   ByteSize cp_base_offset = ConstantPoolCache::base_offset();
2285   __ ld(Rflags, in_bytes(cp_base_offset) + in_bytes(ConstantPoolCacheEntry::flags_offset()), Rcache);
</pre>
<hr />
<pre>
2312                                                Register Rflags,
2313                                                bool is_invokevirtual,
2314                                                bool is_invokevfinal,
2315                                                bool is_invokedynamic) {
2316 
2317   ByteSize cp_base_offset = ConstantPoolCache::base_offset();
2318   // Determine constant pool cache field offsets.
2319   assert(is_invokevirtual == (byte_no == f2_byte), &quot;is_invokevirtual flag redundant&quot;);
2320   const int method_offset = in_bytes(cp_base_offset + (is_invokevirtual ? ConstantPoolCacheEntry::f2_offset() : ConstantPoolCacheEntry::f1_offset()));
2321   const int flags_offset  = in_bytes(cp_base_offset + ConstantPoolCacheEntry::flags_offset());
2322   // Access constant pool cache fields.
2323   const int index_offset  = in_bytes(cp_base_offset + ConstantPoolCacheEntry::f2_offset());
2324 
2325   Register Rcache = R21_tmp1; // Note: same register as R21_sender_SP.
2326 
2327   if (is_invokevfinal) {
2328     assert(Ritable_index == noreg, &quot;register not used&quot;);
2329     // Already resolved.
2330     __ get_cache_and_index_at_bcp(Rcache, 1);
2331   } else {
<span class="line-modified">2332     resolve_cache_and_index(byte_no, Rcache, R0, is_invokedynamic ? sizeof(u4) : sizeof(u2));</span>
2333   }
2334 
2335   __ ld(Rmethod, method_offset, Rcache);
2336   __ ld(Rflags, flags_offset, Rcache);
2337 
2338   if (Ritable_index != noreg) {
2339     __ ld(Ritable_index, index_offset, Rcache);
2340   }
2341 }
2342 
2343 // ============================================================================
2344 // Field access
2345 
2346 // Volatile variables demand their effects be made known to all CPU&#39;s
2347 // in order. Store buffers on most chips allow reads &amp; writes to
2348 // reorder; the JMM&#39;s ReadAfterWrite.java test fails in -Xint mode
2349 // without some kind of memory barrier (i.e., it&#39;s not sufficient that
2350 // the interpreter does not reorder volatile references, the hardware
2351 // also must not reorder them).
2352 //
</pre>
<hr />
<pre>
3617 
3618   // do the call
3619 
3620   Register Rscratch = Rflags; // Rflags is dead now.
3621 
3622   __ profile_final_call(Rscratch1, Rscratch);
3623   __ profile_arguments_type(Rmethod, Rscratch, Rrecv_klass /* scratch */, true);
3624 
3625   __ call_from_interpreter(Rmethod, Rret_addr, Rscratch, Rrecv_klass /* scratch */);
3626 
3627   __ bind(LnotVFinal);
3628 
3629   __ lookup_interface_method(Rrecv_klass, Rinterface_klass, noreg, noreg, Rscratch1, Rscratch2,
3630                              L_no_such_interface, /*return_method=*/false);
3631 
3632   __ profile_virtual_call(Rrecv_klass, Rscratch1, Rscratch2, false);
3633 
3634   // Find entry point to call.
3635 
3636   // Get declaring interface class from method
<span class="line-modified">3637   __ ld(Rinterface_klass, in_bytes(Method::const_offset()), Rmethod);</span>
<span class="line-removed">3638   __ ld(Rinterface_klass, in_bytes(ConstMethod::constants_offset()), Rinterface_klass);</span>
<span class="line-removed">3639   __ ld(Rinterface_klass, ConstantPool::pool_holder_offset_in_bytes(), Rinterface_klass);</span>
3640 
3641   // Get itable index from method
3642   __ lwa(Rindex, in_bytes(Method::itable_index_offset()), Rmethod);
3643   __ subfic(Rindex, Rindex, Method::itable_index_max);
3644 
3645   __ lookup_interface_method(Rrecv_klass, Rinterface_klass, Rindex, Rmethod2, Rscratch1, Rscratch2,
3646                              L_no_such_interface);
3647 
3648   __ cmpdi(CCR0, Rmethod2, 0);
3649   __ beq(CCR0, Lthrow_ame);
3650   // Found entry. Jump off!
3651   // Argument and return type profiling.
3652   __ profile_arguments_type(Rmethod2, Rscratch1, Rscratch2, true);
3653   //__ profile_called_method(Rindex, Rscratch1);
3654   __ call_from_interpreter(Rmethod2, Rret_addr, Rscratch1, Rscratch2);
3655 
3656   // Vtable entry was NULL =&gt; Throw abstract method error.
3657   __ bind(Lthrow_ame);
3658   // Pass arguments for generating a verbose error message.
3659   call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::throw_AbstractMethodErrorVerbose),
</pre>
<hr />
<pre>
3791 
3792     if (!ZeroTLAB) {
3793       // --------------------------------------------------------------------------
3794       // Init1: Zero out newly allocated memory.
3795       // Initialize remaining object fields.
3796       Register Rbase = Rtags;
3797       __ addi(Rinstance_size, Rinstance_size, 7 - (int)sizeof(oopDesc));
3798       __ addi(Rbase, RallocatedObject, sizeof(oopDesc));
3799       __ srdi(Rinstance_size, Rinstance_size, 3);
3800 
3801       // Clear out object skipping header. Takes also care of the zero length case.
3802       __ clear_memory_doubleword(Rbase, Rinstance_size);
3803     }
3804 
3805     // --------------------------------------------------------------------------
3806     // Init2: Initialize the header: mark, klass
3807     // Init mark.
3808     if (UseBiasedLocking) {
3809       __ ld(Rscratch, in_bytes(Klass::prototype_header_offset()), RinstanceKlass);
3810     } else {
<span class="line-modified">3811       __ load_const_optimized(Rscratch, markOopDesc::prototype(), R0);</span>
3812     }
3813     __ std(Rscratch, oopDesc::mark_offset_in_bytes(), RallocatedObject);
3814 
3815     // Init klass.
3816     __ store_klass_gap(RallocatedObject);
3817     __ store_klass(RallocatedObject, RinstanceKlass, Rscratch); // klass (last for cms)
3818 
3819     // Check and trigger dtrace event.
3820     SkipIfEqualZero::skip_to_label_if_equal_zero(_masm, Rscratch, &amp;DTraceAllocProbes, Ldone);
3821     __ push(atos);
3822     __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc));
3823     __ pop(atos);
3824 
3825     __ b(Ldone);
3826   }
3827 
3828   // --------------------------------------------------------------------------
3829   // slow case
3830   __ bind(Lslow_case);
3831   call_VM(R17_tos, CAST_FROM_FN_PTR(address, InterpreterRuntime::_new), Rcpool, Rindex);
</pre>
</td>
<td>
<hr />
<pre>
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  29 #include &quot;interpreter/interpreter.hpp&quot;
  30 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  31 #include &quot;interpreter/interp_masm.hpp&quot;
  32 #include &quot;interpreter/templateInterpreter.hpp&quot;
  33 #include &quot;interpreter/templateTable.hpp&quot;
  34 #include &quot;memory/universe.hpp&quot;
<span class="line-added">  35 #include &quot;oops/klass.inline.hpp&quot;</span>
  36 #include &quot;oops/objArrayKlass.hpp&quot;
  37 #include &quot;oops/oop.inline.hpp&quot;
  38 #include &quot;prims/methodHandles.hpp&quot;
  39 #include &quot;runtime/frame.inline.hpp&quot;
  40 #include &quot;runtime/safepointMechanism.hpp&quot;
  41 #include &quot;runtime/sharedRuntime.hpp&quot;
  42 #include &quot;runtime/stubRoutines.hpp&quot;
  43 #include &quot;runtime/synchronizer.hpp&quot;
  44 #include &quot;utilities/macros.hpp&quot;
<span class="line-added">  45 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  46 
  47 #undef __
  48 #define __ _masm-&gt;
  49 
  50 // ============================================================================
  51 // Misc helpers
  52 
  53 // Do an oop store like *(base + index) = val OR *(base + offset) = val
  54 // (only one of both variants is possible at the same time).
  55 // Index can be noreg.
  56 // Kills:
  57 //   Rbase, Rtmp
  58 static void do_oop_store(InterpreterMacroAssembler* _masm,
  59                          Register           base,
  60                          RegisterOrConstant offset,
  61                          Register           val,         // Noreg means always null.
  62                          Register           tmp1,
  63                          Register           tmp2,
  64                          Register           tmp3,
  65                          DecoratorSet       decorators) {
</pre>
<hr />
<pre>
2217 //   - _f12_oop
2218 // acquired, because these are asked if the cache is already resolved. We don&#39;t
2219 // want to float loads above this check.
2220 // See also comments in ConstantPoolCacheEntry::bytecode_1(),
2221 // ConstantPoolCacheEntry::bytecode_2() and ConstantPoolCacheEntry::f1();
2222 
2223 // Call into the VM if call site is not yet resolved
2224 //
2225 // Input regs:
2226 //   - None, all passed regs are outputs.
2227 //
2228 // Returns:
2229 //   - Rcache:  The const pool cache entry that contains the resolved result.
2230 //   - Rresult: Either noreg or output for f1/f2.
2231 //
2232 // Kills:
2233 //   - Rscratch
2234 void TemplateTable::resolve_cache_and_index(int byte_no, Register Rcache, Register Rscratch, size_t index_size) {
2235 
2236   __ get_cache_and_index_at_bcp(Rcache, 1, index_size);
<span class="line-modified">2237   Label Lresolved, Ldone, L_clinit_barrier_slow;</span>
2238 
2239   Bytecodes::Code code = bytecode();
2240   switch (code) {
2241     case Bytecodes::_nofast_getfield: code = Bytecodes::_getfield; break;
2242     case Bytecodes::_nofast_putfield: code = Bytecodes::_putfield; break;
2243     default:
2244       break;
2245   }
2246 
2247   assert(byte_no == f1_byte || byte_no == f2_byte, &quot;byte_no out of range&quot;);
2248   // We are resolved if the indices offset contains the current bytecode.
2249 #if defined(VM_LITTLE_ENDIAN)
2250   __ lbz(Rscratch, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::indices_offset()) + byte_no + 1, Rcache);
2251 #else
2252   __ lbz(Rscratch, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::indices_offset()) + 7 - (byte_no + 1), Rcache);
2253 #endif
2254   // Acquire by cmp-br-isync (see below).
2255   __ cmpdi(CCR0, Rscratch, (int)code);
2256   __ beq(CCR0, Lresolved);
2257 
<span class="line-added">2258   // Class initialization barrier slow path lands here as well.</span>
<span class="line-added">2259   __ bind(L_clinit_barrier_slow);</span>
<span class="line-added">2260 </span>
2261   address entry = CAST_FROM_FN_PTR(address, InterpreterRuntime::resolve_from_cache);
2262   __ li(R4_ARG2, code);
2263   __ call_VM(noreg, entry, R4_ARG2, true);
2264 
2265   // Update registers with resolved info.
2266   __ get_cache_and_index_at_bcp(Rcache, 1, index_size);
2267   __ b(Ldone);
2268 
2269   __ bind(Lresolved);
2270   __ isync(); // Order load wrt. succeeding loads.
<span class="line-added">2271 </span>
<span class="line-added">2272   // Class initialization barrier for static methods</span>
<span class="line-added">2273   if (VM_Version::supports_fast_class_init_checks() &amp;&amp; bytecode() == Bytecodes::_invokestatic) {</span>
<span class="line-added">2274     const Register method = Rscratch;</span>
<span class="line-added">2275     const Register klass  = Rscratch;</span>
<span class="line-added">2276 </span>
<span class="line-added">2277     __ load_resolved_method_at_index(byte_no, Rcache, method);</span>
<span class="line-added">2278     __ load_method_holder(klass, method);</span>
<span class="line-added">2279     __ clinit_barrier(klass, R16_thread, NULL /*L_fast_path*/, &amp;L_clinit_barrier_slow);</span>
<span class="line-added">2280   }</span>
<span class="line-added">2281 </span>
2282   __ bind(Ldone);
2283 }
2284 
2285 // Load the constant pool cache entry at field accesses into registers.
2286 // The Rcache and Rindex registers must be set before call.
2287 // Input:
2288 //   - Rcache, Rindex
2289 // Output:
2290 //   - Robj, Roffset, Rflags
2291 void TemplateTable::load_field_cp_cache_entry(Register Robj,
2292                                               Register Rcache,
2293                                               Register Rindex /* unused on PPC64 */,
2294                                               Register Roffset,
2295                                               Register Rflags,
2296                                               bool is_static = false) {
2297   assert_different_registers(Rcache, Rflags, Roffset);
2298   // assert(Rindex == noreg, &quot;parameter not used on PPC64&quot;);
2299 
2300   ByteSize cp_base_offset = ConstantPoolCache::base_offset();
2301   __ ld(Rflags, in_bytes(cp_base_offset) + in_bytes(ConstantPoolCacheEntry::flags_offset()), Rcache);
</pre>
<hr />
<pre>
2328                                                Register Rflags,
2329                                                bool is_invokevirtual,
2330                                                bool is_invokevfinal,
2331                                                bool is_invokedynamic) {
2332 
2333   ByteSize cp_base_offset = ConstantPoolCache::base_offset();
2334   // Determine constant pool cache field offsets.
2335   assert(is_invokevirtual == (byte_no == f2_byte), &quot;is_invokevirtual flag redundant&quot;);
2336   const int method_offset = in_bytes(cp_base_offset + (is_invokevirtual ? ConstantPoolCacheEntry::f2_offset() : ConstantPoolCacheEntry::f1_offset()));
2337   const int flags_offset  = in_bytes(cp_base_offset + ConstantPoolCacheEntry::flags_offset());
2338   // Access constant pool cache fields.
2339   const int index_offset  = in_bytes(cp_base_offset + ConstantPoolCacheEntry::f2_offset());
2340 
2341   Register Rcache = R21_tmp1; // Note: same register as R21_sender_SP.
2342 
2343   if (is_invokevfinal) {
2344     assert(Ritable_index == noreg, &quot;register not used&quot;);
2345     // Already resolved.
2346     __ get_cache_and_index_at_bcp(Rcache, 1);
2347   } else {
<span class="line-modified">2348     resolve_cache_and_index(byte_no, Rcache, /* temp */ Rmethod, is_invokedynamic ? sizeof(u4) : sizeof(u2));</span>
2349   }
2350 
2351   __ ld(Rmethod, method_offset, Rcache);
2352   __ ld(Rflags, flags_offset, Rcache);
2353 
2354   if (Ritable_index != noreg) {
2355     __ ld(Ritable_index, index_offset, Rcache);
2356   }
2357 }
2358 
2359 // ============================================================================
2360 // Field access
2361 
2362 // Volatile variables demand their effects be made known to all CPU&#39;s
2363 // in order. Store buffers on most chips allow reads &amp; writes to
2364 // reorder; the JMM&#39;s ReadAfterWrite.java test fails in -Xint mode
2365 // without some kind of memory barrier (i.e., it&#39;s not sufficient that
2366 // the interpreter does not reorder volatile references, the hardware
2367 // also must not reorder them).
2368 //
</pre>
<hr />
<pre>
3633 
3634   // do the call
3635 
3636   Register Rscratch = Rflags; // Rflags is dead now.
3637 
3638   __ profile_final_call(Rscratch1, Rscratch);
3639   __ profile_arguments_type(Rmethod, Rscratch, Rrecv_klass /* scratch */, true);
3640 
3641   __ call_from_interpreter(Rmethod, Rret_addr, Rscratch, Rrecv_klass /* scratch */);
3642 
3643   __ bind(LnotVFinal);
3644 
3645   __ lookup_interface_method(Rrecv_klass, Rinterface_klass, noreg, noreg, Rscratch1, Rscratch2,
3646                              L_no_such_interface, /*return_method=*/false);
3647 
3648   __ profile_virtual_call(Rrecv_klass, Rscratch1, Rscratch2, false);
3649 
3650   // Find entry point to call.
3651 
3652   // Get declaring interface class from method
<span class="line-modified">3653   __ load_method_holder(Rinterface_klass, Rmethod);</span>


3654 
3655   // Get itable index from method
3656   __ lwa(Rindex, in_bytes(Method::itable_index_offset()), Rmethod);
3657   __ subfic(Rindex, Rindex, Method::itable_index_max);
3658 
3659   __ lookup_interface_method(Rrecv_klass, Rinterface_klass, Rindex, Rmethod2, Rscratch1, Rscratch2,
3660                              L_no_such_interface);
3661 
3662   __ cmpdi(CCR0, Rmethod2, 0);
3663   __ beq(CCR0, Lthrow_ame);
3664   // Found entry. Jump off!
3665   // Argument and return type profiling.
3666   __ profile_arguments_type(Rmethod2, Rscratch1, Rscratch2, true);
3667   //__ profile_called_method(Rindex, Rscratch1);
3668   __ call_from_interpreter(Rmethod2, Rret_addr, Rscratch1, Rscratch2);
3669 
3670   // Vtable entry was NULL =&gt; Throw abstract method error.
3671   __ bind(Lthrow_ame);
3672   // Pass arguments for generating a verbose error message.
3673   call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::throw_AbstractMethodErrorVerbose),
</pre>
<hr />
<pre>
3805 
3806     if (!ZeroTLAB) {
3807       // --------------------------------------------------------------------------
3808       // Init1: Zero out newly allocated memory.
3809       // Initialize remaining object fields.
3810       Register Rbase = Rtags;
3811       __ addi(Rinstance_size, Rinstance_size, 7 - (int)sizeof(oopDesc));
3812       __ addi(Rbase, RallocatedObject, sizeof(oopDesc));
3813       __ srdi(Rinstance_size, Rinstance_size, 3);
3814 
3815       // Clear out object skipping header. Takes also care of the zero length case.
3816       __ clear_memory_doubleword(Rbase, Rinstance_size);
3817     }
3818 
3819     // --------------------------------------------------------------------------
3820     // Init2: Initialize the header: mark, klass
3821     // Init mark.
3822     if (UseBiasedLocking) {
3823       __ ld(Rscratch, in_bytes(Klass::prototype_header_offset()), RinstanceKlass);
3824     } else {
<span class="line-modified">3825       __ load_const_optimized(Rscratch, markWord::prototype().value(), R0);</span>
3826     }
3827     __ std(Rscratch, oopDesc::mark_offset_in_bytes(), RallocatedObject);
3828 
3829     // Init klass.
3830     __ store_klass_gap(RallocatedObject);
3831     __ store_klass(RallocatedObject, RinstanceKlass, Rscratch); // klass (last for cms)
3832 
3833     // Check and trigger dtrace event.
3834     SkipIfEqualZero::skip_to_label_if_equal_zero(_masm, Rscratch, &amp;DTraceAllocProbes, Ldone);
3835     __ push(atos);
3836     __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc));
3837     __ pop(atos);
3838 
3839     __ b(Ldone);
3840   }
3841 
3842   // --------------------------------------------------------------------------
3843   // slow case
3844   __ bind(Lslow_case);
3845   call_VM(R17_tos, CAST_FROM_FN_PTR(address, InterpreterRuntime::_new), Rcpool, Rindex);
</pre>
</td>
</tr>
</table>
<center><a href="templateInterpreterGenerator_ppc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="vm_version_ext_ppc.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>