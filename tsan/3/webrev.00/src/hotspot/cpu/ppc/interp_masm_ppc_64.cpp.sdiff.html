<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/ppc/interp_masm_ppc_64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="interp_masm_ppc.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="interpreterRT_ppc.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/ppc/interp_masm_ppc_64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 
  27 #include &quot;precompiled.hpp&quot;
  28 #include &quot;asm/macroAssembler.inline.hpp&quot;
  29 #include &quot;gc/shared/barrierSet.hpp&quot;
  30 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  31 #include &quot;interp_masm_ppc.hpp&quot;
  32 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  33 #include &quot;prims/jvmtiThreadState.hpp&quot;
  34 #include &quot;runtime/frame.inline.hpp&quot;
  35 #include &quot;runtime/safepointMechanism.hpp&quot;
  36 #include &quot;runtime/sharedRuntime.hpp&quot;

  37 
  38 // Implementation of InterpreterMacroAssembler.
  39 
  40 // This file specializes the assembler with interpreter-specific macros.
  41 
  42 #ifdef PRODUCT
  43 #define BLOCK_COMMENT(str) // nothing
  44 #else
  45 #define BLOCK_COMMENT(str) block_comment(str)
  46 #endif
  47 
  48 void InterpreterMacroAssembler::null_check_throw(Register a, int offset, Register temp_reg) {
  49   address exception_entry = Interpreter::throw_NullPointerException_entry();
  50   MacroAssembler::null_check_throw(a, offset, temp_reg, exception_entry);
  51 }
  52 
  53 void InterpreterMacroAssembler::jump_to_entry(address entry, Register Rscratch) {
  54   assert(entry, &quot;Entry must have been generated by now&quot;);
  55   if (is_within_range_of_b(entry, pc())) {
  56     b(entry);
</pre>
<hr />
<pre>
 499 
 500 // load cpool-&gt;resolved_klass_at(index)
 501 void InterpreterMacroAssembler::load_resolved_klass_at_offset(Register Rcpool, Register Roffset, Register Rklass) {
 502   // int value = *(Rcpool-&gt;int_at_addr(which));
 503   // int resolved_klass_index = extract_low_short_from_int(value);
 504   add(Roffset, Rcpool, Roffset);
 505 #if defined(VM_LITTLE_ENDIAN)
 506   lhz(Roffset, sizeof(ConstantPool), Roffset);     // Roffset = resolved_klass_index
 507 #else
 508   lhz(Roffset, sizeof(ConstantPool) + 2, Roffset); // Roffset = resolved_klass_index
 509 #endif
 510 
 511   ld(Rklass, ConstantPool::resolved_klasses_offset_in_bytes(), Rcpool); // Rklass = Rcpool-&gt;_resolved_klasses
 512 
 513   sldi(Roffset, Roffset, LogBytesPerWord);
 514   addi(Roffset, Roffset, Array&lt;Klass*&gt;::base_offset_in_bytes());
 515   isync(); // Order load of instance Klass wrt. tags.
 516   ldx(Rklass, Rklass, Roffset);
 517 }
 518 












 519 // Generate a subtype check: branch to ok_is_subtype if sub_klass is
 520 // a subtype of super_klass. Blows registers Rsub_klass, tmp1, tmp2.
 521 void InterpreterMacroAssembler::gen_subtype_check(Register Rsub_klass, Register Rsuper_klass, Register Rtmp1,
 522                                                   Register Rtmp2, Register Rtmp3, Label &amp;ok_is_subtype) {
 523   // Profile the not-null value&#39;s klass.
 524   profile_typecheck(Rsub_klass, Rtmp1, Rtmp2);
 525   check_klass_subtype(Rsub_klass, Rsuper_klass, Rtmp1, Rtmp2, ok_is_subtype);
 526   profile_typecheck_failed(Rtmp1, Rtmp2);
 527 }
 528 
 529 // Separate these two to allow for delay slot in middle.
 530 // These are used to do a test and full jump to exception-throwing code.
 531 
 532 // Check that index is in range for array, then shift index by index_shift,
 533 // and put arrayOop + shifted_index into res.
 534 // Note: res is still shy of address by array offset into object.
 535 
 536 void InterpreterMacroAssembler::index_check_without_pop(Register Rarray, Register Rindex,
 537                                                         int index_shift, Register Rtmp, Register Rres) {
 538   // Check that index is in range for array, then shift index by index_shift,
</pre>
<hr />
<pre>
 739       unlock_object(Rmonitor_addr);
 740       if (install_monitor_exception) {
 741         call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::new_illegal_monitor_state_exception));
 742       }
 743       b(Lrestart);
 744     }
 745   }
 746 
 747   align(32, 12);
 748   bind(Lno_unlock);
 749   pop(state);
 750 }
 751 
 752 // Support function for remove_activation &amp; Co.
 753 void InterpreterMacroAssembler::merge_frames(Register Rsender_sp, Register return_pc,
 754                                              Register Rscratch1, Register Rscratch2) {
 755   // Pop interpreter frame.
 756   ld(Rscratch1, 0, R1_SP); // *SP
 757   ld(Rsender_sp, _ijava_state_neg(sender_sp), Rscratch1); // top_frame_sp
 758   ld(Rscratch2, 0, Rscratch1); // **SP
<span class="line-removed"> 759 #ifdef ASSERT</span>
<span class="line-removed"> 760   {</span>
<span class="line-removed"> 761     Label Lok;</span>
<span class="line-removed"> 762     ld(R0, _ijava_state_neg(ijava_reserved), Rscratch1);</span>
<span class="line-removed"> 763     cmpdi(CCR0, R0, 0x5afe);</span>
<span class="line-removed"> 764     beq(CCR0, Lok);</span>
<span class="line-removed"> 765     stop(&quot;frame corrupted (remove activation)&quot;, 0x5afe);</span>
<span class="line-removed"> 766     bind(Lok);</span>
<span class="line-removed"> 767   }</span>
<span class="line-removed"> 768 #endif</span>
 769   if (return_pc!=noreg) {
 770     ld(return_pc, _abi(lr), Rscratch1); // LR
 771   }
 772 
 773   // Merge top frames.
 774   subf(Rscratch1, R1_SP, Rsender_sp); // top_frame_sp - SP
 775   stdux(Rscratch2, R1_SP, Rscratch1); // atomically set *(SP = top_frame_sp) = **SP
 776 }
 777 
 778 void InterpreterMacroAssembler::narrow(Register result) {
 779   Register ret_type = R11_scratch1;
 780   ld(R11_scratch1, in_bytes(Method::const_offset()), R19_method);
 781   lbz(ret_type, in_bytes(ConstMethod::result_type_offset()), R11_scratch1);
 782 
 783   Label notBool, notByte, notChar, done;
 784 
 785   // common case first
 786   cmpwi(CCR0, ret_type, T_INT);
 787   beq(CCR0, done);
 788 
</pre>
<hr />
<pre>
 862 
 863   merge_frames(/*top_frame_sp*/ R21_sender_SP, /*return_pc*/ R0, R11_scratch1, R12_scratch2);
 864   mtlr(R0);
 865   BLOCK_COMMENT(&quot;} remove_activation&quot;);
 866 }
 867 
 868 // Lock object
 869 //
 870 // Registers alive
 871 //   monitor - Address of the BasicObjectLock to be used for locking,
 872 //             which must be initialized with the object to lock.
 873 //   object  - Address of the object to be locked.
 874 //
 875 void InterpreterMacroAssembler::lock_object(Register monitor, Register object) {
 876   if (UseHeavyMonitors) {
 877     call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),
 878             monitor, /*check_for_exceptions=*/true);
 879   } else {
 880     // template code:
 881     //
<span class="line-modified"> 882     // markOop displaced_header = obj-&gt;mark().set_unlocked();</span>
 883     // monitor-&gt;lock()-&gt;set_displaced_header(displaced_header);
<span class="line-modified"> 884     // if (Atomic::cmpxchg(/*ex=*/monitor, /*addr*/obj-&gt;mark_addr(), /*cmp*/displaced_header) == displaced_header) {</span>
 885     //   // We stored the monitor address into the object&#39;s mark word.
 886     // } else if (THREAD-&gt;is_lock_owned((address)displaced_header))
 887     //   // Simple recursive case.
 888     //   monitor-&gt;lock()-&gt;set_displaced_header(NULL);
 889     // } else {
 890     //   // Slow path.
 891     //   InterpreterRuntime::monitorenter(THREAD, monitor);
 892     // }
 893 
 894     const Register displaced_header = R7_ARG5;
 895     const Register object_mark_addr = R8_ARG6;
 896     const Register current_header   = R9_ARG7;
 897     const Register tmp              = R10_ARG8;
 898 
 899     Label done;
 900     Label cas_failed, slow_case;
 901 
 902     assert_different_registers(displaced_header, object_mark_addr, current_header, tmp);
 903 
<span class="line-modified"> 904     // markOop displaced_header = obj-&gt;mark().set_unlocked();</span>
 905 
<span class="line-modified"> 906     // Load markOop from object into displaced_header.</span>
 907     ld(displaced_header, oopDesc::mark_offset_in_bytes(), object);
 908 
 909     if (UseBiasedLocking) {
 910       biased_locking_enter(CCR0, object, displaced_header, tmp, current_header, done, &amp;slow_case);
 911     }
 912 
<span class="line-modified"> 913     // Set displaced_header to be (markOop of object | UNLOCK_VALUE).</span>
<span class="line-modified"> 914     ori(displaced_header, displaced_header, markOopDesc::unlocked_value);</span>
 915 
 916     // monitor-&gt;lock()-&gt;set_displaced_header(displaced_header);
 917 
 918     // Initialize the box (Must happen before we update the object mark!).
 919     std(displaced_header, BasicObjectLock::lock_offset_in_bytes() +
 920         BasicLock::displaced_header_offset_in_bytes(), monitor);
 921 
<span class="line-modified"> 922     // if (Atomic::cmpxchg(/*ex=*/monitor, /*addr*/obj-&gt;mark_addr(), /*cmp*/displaced_header) == displaced_header) {</span>
 923 
 924     // Store stack address of the BasicObjectLock (this is monitor) into object.
 925     addi(object_mark_addr, object, oopDesc::mark_offset_in_bytes());
 926 
 927     // Must fence, otherwise, preceding store(s) may float below cmpxchg.
 928     // CmpxchgX sets CCR0 to cmpX(current, displaced).
 929     cmpxchgd(/*flag=*/CCR0,
 930              /*current_value=*/current_header,
 931              /*compare_value=*/displaced_header, /*exchange_value=*/monitor,
 932              /*where=*/object_mark_addr,
 933              MacroAssembler::MemBarRel | MacroAssembler::MemBarAcq,
 934              MacroAssembler::cmpxchgx_hint_acquire_lock(),
 935              noreg,
 936              &amp;cas_failed,
 937              /*check without membar and ldarx first*/true);
 938 
 939     // If the compare-and-exchange succeeded, then we found an unlocked
 940     // object and we have now locked it.
 941     b(done);
 942     bind(cas_failed);
 943 
 944     // } else if (THREAD-&gt;is_lock_owned((address)displaced_header))
 945     //   // Simple recursive case.
 946     //   monitor-&gt;lock()-&gt;set_displaced_header(NULL);
 947 
 948     // We did not see an unlocked object so try the fast recursive case.
 949 
<span class="line-modified"> 950     // Check if owner is self by comparing the value in the markOop of object</span>
 951     // (current_header) with the stack pointer.
 952     sub(current_header, current_header, R1_SP);
 953 
 954     assert(os::vm_page_size() &gt; 0xfff, &quot;page size too small - change the constant&quot;);
<span class="line-modified"> 955     load_const_optimized(tmp, ~(os::vm_page_size()-1) | markOopDesc::lock_mask_in_place);</span>
 956 
 957     and_(R0/*==0?*/, current_header, tmp);
 958     // If condition is true we are done and hence we can store 0 in the displaced
 959     // header indicating it is a recursive lock.
 960     bne(CCR0, slow_case);
 961     std(R0/*==0!*/, BasicObjectLock::lock_offset_in_bytes() +
 962         BasicLock::displaced_header_offset_in_bytes(), monitor);
 963     b(done);
 964 
 965     // } else {
 966     //   // Slow path.
 967     //   InterpreterRuntime::monitorenter(THREAD, monitor);
 968 
 969     // None of the above fast optimizations worked so we have to get into the
 970     // slow case of monitor enter.
 971     bind(slow_case);
 972     call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),
 973             monitor, /*check_for_exceptions=*/true);
 974     // }
 975     align(32, 12);
</pre>
<hr />
<pre>
 978 }
 979 
 980 // Unlocks an object. Used in monitorexit bytecode and remove_activation.
 981 //
 982 // Registers alive
 983 //   monitor - Address of the BasicObjectLock to be used for locking,
 984 //             which must be initialized with the object to lock.
 985 //
 986 // Throw IllegalMonitorException if object is not locked by current thread.
 987 void InterpreterMacroAssembler::unlock_object(Register monitor, bool check_for_exceptions) {
 988   if (UseHeavyMonitors) {
 989     call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit),
 990             monitor, check_for_exceptions);
 991   } else {
 992 
 993     // template code:
 994     //
 995     // if ((displaced_header = monitor-&gt;displaced_header()) == NULL) {
 996     //   // Recursive unlock. Mark the monitor unlocked by setting the object field to NULL.
 997     //   monitor-&gt;set_obj(NULL);
<span class="line-modified"> 998     // } else if (Atomic::cmpxchg(displaced_header, obj-&gt;mark_addr(), monitor) == monitor) {</span>
 999     //   // We swapped the unlocked mark in displaced_header into the object&#39;s mark word.
1000     //   monitor-&gt;set_obj(NULL);
1001     // } else {
1002     //   // Slow path.
1003     //   InterpreterRuntime::monitorexit(THREAD, monitor);
1004     // }
1005 
1006     const Register object           = R7_ARG5;
1007     const Register displaced_header = R8_ARG6;
1008     const Register object_mark_addr = R9_ARG7;
1009     const Register current_header   = R10_ARG8;
1010 
1011     Label free_slot;
1012     Label slow_case;
1013 
1014     assert_different_registers(object, displaced_header, object_mark_addr, current_header);
1015 
1016     if (UseBiasedLocking) {
1017       // The object address from the monitor is in object.
1018       ld(object, BasicObjectLock::obj_offset_in_bytes(), monitor);
1019       assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
1020       biased_locking_exit(CCR0, object, displaced_header, free_slot);
1021     }
1022 
1023     // Test first if we are in the fast recursive case.
1024     ld(displaced_header, BasicObjectLock::lock_offset_in_bytes() +
1025            BasicLock::displaced_header_offset_in_bytes(), monitor);
1026 
1027     // If the displaced header is zero, we have a recursive unlock.
1028     cmpdi(CCR0, displaced_header, 0);
1029     beq(CCR0, free_slot); // recursive unlock
1030 
<span class="line-modified">1031     // } else if (Atomic::cmpxchg(displaced_header, obj-&gt;mark_addr(), monitor) == monitor) {</span>
1032     //   // We swapped the unlocked mark in displaced_header into the object&#39;s mark word.
1033     //   monitor-&gt;set_obj(NULL);
1034 
1035     // If we still have a lightweight lock, unlock the object and be done.
1036 
1037     // The object address from the monitor is in object.
1038     if (!UseBiasedLocking) { ld(object, BasicObjectLock::obj_offset_in_bytes(), monitor); }
1039     addi(object_mark_addr, object, oopDesc::mark_offset_in_bytes());
1040 
1041     // We have the displaced header in displaced_header. If the lock is still
1042     // lightweight, it will contain the monitor address and we&#39;ll store the
1043     // displaced header back into the object&#39;s mark word.
1044     // CmpxchgX sets CCR0 to cmpX(current, monitor).
1045     cmpxchgd(/*flag=*/CCR0,
1046              /*current_value=*/current_header,
1047              /*compare_value=*/monitor, /*exchange_value=*/displaced_header,
1048              /*where=*/object_mark_addr,
1049              MacroAssembler::MemBarRel,
1050              MacroAssembler::cmpxchgx_hint_release_lock(),
1051              noreg,
</pre>
<hr />
<pre>
2234   ld(R14_bcp, _ijava_state_neg(bcp), scratch); // Changed by VM code (exception).
2235   if (ProfileInterpreter) { ld(R28_mdx, _ijava_state_neg(mdx), scratch); } // Changed by VM code.
2236   if (!bcp_and_mdx_only) {
2237     // Following ones are Metadata.
2238     ld(R19_method, _ijava_state_neg(method), scratch);
2239     ld(R27_constPoolCache, _ijava_state_neg(cpoolCache), scratch);
2240     // Following ones are stack addresses and don&#39;t require reload.
2241     ld(R15_esp, _ijava_state_neg(esp), scratch);
2242     ld(R18_locals, _ijava_state_neg(locals), scratch);
2243     ld(R26_monitor, _ijava_state_neg(monitors), scratch);
2244   }
2245 #ifdef ASSERT
2246   {
2247     Label Lok;
2248     subf(R0, R1_SP, scratch);
2249     cmpdi(CCR0, R0, frame::abi_reg_args_size + frame::ijava_state_size);
2250     bge(CCR0, Lok);
2251     stop(&quot;frame too small (restore istate)&quot;, 0x5432);
2252     bind(Lok);
2253   }
<span class="line-removed">2254   {</span>
<span class="line-removed">2255     Label Lok;</span>
<span class="line-removed">2256     ld(R0, _ijava_state_neg(ijava_reserved), scratch);</span>
<span class="line-removed">2257     cmpdi(CCR0, R0, 0x5afe);</span>
<span class="line-removed">2258     beq(CCR0, Lok);</span>
<span class="line-removed">2259     stop(&quot;frame corrupted (restore istate)&quot;, 0x5afe);</span>
<span class="line-removed">2260     bind(Lok);</span>
<span class="line-removed">2261   }</span>
2262 #endif
2263 }
2264 
2265 void InterpreterMacroAssembler::get_method_counters(Register method,
2266                                                     Register Rcounters,
2267                                                     Label&amp; skip) {
2268   BLOCK_COMMENT(&quot;Load and ev. allocate counter object {&quot;);
2269   Label has_counters;
2270   ld(Rcounters, in_bytes(Method::method_counters_offset()), method);
2271   cmpdi(CCR0, Rcounters, 0);
2272   bne(CCR0, has_counters);
2273   call_VM(noreg, CAST_FROM_FN_PTR(address,
<span class="line-modified">2274                                   InterpreterRuntime::build_method_counters), method, false);</span>
2275   ld(Rcounters, in_bytes(Method::method_counters_offset()), method);
2276   cmpdi(CCR0, Rcounters, 0);
2277   beq(CCR0, skip); // No MethodCounters, OutOfMemory.
2278   BLOCK_COMMENT(&quot;} Load and ev. allocate counter object&quot;);
2279 
2280   bind(has_counters);
2281 }
2282 
2283 void InterpreterMacroAssembler::increment_invocation_counter(Register Rcounters,
2284                                                              Register iv_be_count,
2285                                                              Register Rtmp_r0) {
2286   assert(UseCompiler || LogTouchedMethods, &quot;incrementing must be useful&quot;);
2287   Register invocation_count = iv_be_count;
2288   Register backedge_count   = Rtmp_r0;
2289   int delta = InvocationCounter::count_increment;
2290 
2291   // Load each counter in a register.
2292   //  ld(inv_counter, Rtmp);
2293   //  ld(be_counter, Rtmp2);
2294   int inv_counter_offset = in_bytes(MethodCounters::invocation_counter_offset() +
</pre>
<hr />
<pre>
2302   lwz(backedge_count, be_counter_offset, Rcounters); // is unsigned int
2303   // Mask the backedge counter.
2304   andi(backedge_count, backedge_count, InvocationCounter::count_mask_value);
2305 
2306   // Load the invocation counter.
2307   lwz(invocation_count, inv_counter_offset, Rcounters); // is unsigned int
2308   // Add the delta to the invocation counter and store the result.
2309   addi(invocation_count, invocation_count, delta);
2310   // Store value.
2311   stw(invocation_count, inv_counter_offset, Rcounters);
2312 
2313   // Add invocation counter + backedge counter.
2314   add(iv_be_count, backedge_count, invocation_count);
2315 
2316   // Note that this macro must leave the backedge_count + invocation_count in
2317   // register iv_be_count!
2318   BLOCK_COMMENT(&quot;} Increment profiling counters&quot;);
2319 }
2320 
2321 void InterpreterMacroAssembler::verify_oop(Register reg, TosState state) {
<span class="line-modified">2322   if (state == atos) { MacroAssembler::verify_oop(reg); }</span>
2323 }
2324 
2325 // Local helper function for the verify_oop_or_return_address macro.
2326 static bool verify_return_address(Method* m, int bci) {
2327 #ifndef PRODUCT
2328   address pc = (address)(m-&gt;constMethod()) + in_bytes(ConstMethod::codes_offset()) + bci;
2329   // Assume it is a valid return address if it is inside m and is preceded by a jsr.
2330   if (!m-&gt;contains(pc))                                            return false;
2331   address jsr_pc;
2332   jsr_pc = pc - Bytecodes::length_for(Bytecodes::_jsr);
2333   if (*jsr_pc == Bytecodes::_jsr   &amp;&amp; jsr_pc &gt;= m-&gt;code_base())    return true;
2334   jsr_pc = pc - Bytecodes::length_for(Bytecodes::_jsr_w);
2335   if (*jsr_pc == Bytecodes::_jsr_w &amp;&amp; jsr_pc &gt;= m-&gt;code_base())    return true;
2336 #endif // PRODUCT
2337   return false;
2338 }
2339 
2340 void InterpreterMacroAssembler::verify_FPU(int stack_depth, TosState state) {
2341   if (VerifyFPU) {
2342     unimplemented(&quot;verfiyFPU&quot;);
</pre>
</td>
<td>
<hr />
<pre>
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 
  27 #include &quot;precompiled.hpp&quot;
  28 #include &quot;asm/macroAssembler.inline.hpp&quot;
  29 #include &quot;gc/shared/barrierSet.hpp&quot;
  30 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  31 #include &quot;interp_masm_ppc.hpp&quot;
  32 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  33 #include &quot;prims/jvmtiThreadState.hpp&quot;
  34 #include &quot;runtime/frame.inline.hpp&quot;
  35 #include &quot;runtime/safepointMechanism.hpp&quot;
  36 #include &quot;runtime/sharedRuntime.hpp&quot;
<span class="line-added">  37 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  38 
  39 // Implementation of InterpreterMacroAssembler.
  40 
  41 // This file specializes the assembler with interpreter-specific macros.
  42 
  43 #ifdef PRODUCT
  44 #define BLOCK_COMMENT(str) // nothing
  45 #else
  46 #define BLOCK_COMMENT(str) block_comment(str)
  47 #endif
  48 
  49 void InterpreterMacroAssembler::null_check_throw(Register a, int offset, Register temp_reg) {
  50   address exception_entry = Interpreter::throw_NullPointerException_entry();
  51   MacroAssembler::null_check_throw(a, offset, temp_reg, exception_entry);
  52 }
  53 
  54 void InterpreterMacroAssembler::jump_to_entry(address entry, Register Rscratch) {
  55   assert(entry, &quot;Entry must have been generated by now&quot;);
  56   if (is_within_range_of_b(entry, pc())) {
  57     b(entry);
</pre>
<hr />
<pre>
 500 
 501 // load cpool-&gt;resolved_klass_at(index)
 502 void InterpreterMacroAssembler::load_resolved_klass_at_offset(Register Rcpool, Register Roffset, Register Rklass) {
 503   // int value = *(Rcpool-&gt;int_at_addr(which));
 504   // int resolved_klass_index = extract_low_short_from_int(value);
 505   add(Roffset, Rcpool, Roffset);
 506 #if defined(VM_LITTLE_ENDIAN)
 507   lhz(Roffset, sizeof(ConstantPool), Roffset);     // Roffset = resolved_klass_index
 508 #else
 509   lhz(Roffset, sizeof(ConstantPool) + 2, Roffset); // Roffset = resolved_klass_index
 510 #endif
 511 
 512   ld(Rklass, ConstantPool::resolved_klasses_offset_in_bytes(), Rcpool); // Rklass = Rcpool-&gt;_resolved_klasses
 513 
 514   sldi(Roffset, Roffset, LogBytesPerWord);
 515   addi(Roffset, Roffset, Array&lt;Klass*&gt;::base_offset_in_bytes());
 516   isync(); // Order load of instance Klass wrt. tags.
 517   ldx(Rklass, Rklass, Roffset);
 518 }
 519 
<span class="line-added"> 520 void InterpreterMacroAssembler::load_resolved_method_at_index(int byte_no,</span>
<span class="line-added"> 521                                                               Register cache,</span>
<span class="line-added"> 522                                                               Register method) {</span>
<span class="line-added"> 523   const int method_offset = in_bytes(</span>
<span class="line-added"> 524     ConstantPoolCache::base_offset() +</span>
<span class="line-added"> 525       ((byte_no == TemplateTable::f2_byte)</span>
<span class="line-added"> 526        ? ConstantPoolCacheEntry::f2_offset()</span>
<span class="line-added"> 527        : ConstantPoolCacheEntry::f1_offset()));</span>
<span class="line-added"> 528 </span>
<span class="line-added"> 529   ld(method, method_offset, cache); // get f1 Method*</span>
<span class="line-added"> 530 }</span>
<span class="line-added"> 531 </span>
 532 // Generate a subtype check: branch to ok_is_subtype if sub_klass is
 533 // a subtype of super_klass. Blows registers Rsub_klass, tmp1, tmp2.
 534 void InterpreterMacroAssembler::gen_subtype_check(Register Rsub_klass, Register Rsuper_klass, Register Rtmp1,
 535                                                   Register Rtmp2, Register Rtmp3, Label &amp;ok_is_subtype) {
 536   // Profile the not-null value&#39;s klass.
 537   profile_typecheck(Rsub_klass, Rtmp1, Rtmp2);
 538   check_klass_subtype(Rsub_klass, Rsuper_klass, Rtmp1, Rtmp2, ok_is_subtype);
 539   profile_typecheck_failed(Rtmp1, Rtmp2);
 540 }
 541 
 542 // Separate these two to allow for delay slot in middle.
 543 // These are used to do a test and full jump to exception-throwing code.
 544 
 545 // Check that index is in range for array, then shift index by index_shift,
 546 // and put arrayOop + shifted_index into res.
 547 // Note: res is still shy of address by array offset into object.
 548 
 549 void InterpreterMacroAssembler::index_check_without_pop(Register Rarray, Register Rindex,
 550                                                         int index_shift, Register Rtmp, Register Rres) {
 551   // Check that index is in range for array, then shift index by index_shift,
</pre>
<hr />
<pre>
 752       unlock_object(Rmonitor_addr);
 753       if (install_monitor_exception) {
 754         call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::new_illegal_monitor_state_exception));
 755       }
 756       b(Lrestart);
 757     }
 758   }
 759 
 760   align(32, 12);
 761   bind(Lno_unlock);
 762   pop(state);
 763 }
 764 
 765 // Support function for remove_activation &amp; Co.
 766 void InterpreterMacroAssembler::merge_frames(Register Rsender_sp, Register return_pc,
 767                                              Register Rscratch1, Register Rscratch2) {
 768   // Pop interpreter frame.
 769   ld(Rscratch1, 0, R1_SP); // *SP
 770   ld(Rsender_sp, _ijava_state_neg(sender_sp), Rscratch1); // top_frame_sp
 771   ld(Rscratch2, 0, Rscratch1); // **SP










 772   if (return_pc!=noreg) {
 773     ld(return_pc, _abi(lr), Rscratch1); // LR
 774   }
 775 
 776   // Merge top frames.
 777   subf(Rscratch1, R1_SP, Rsender_sp); // top_frame_sp - SP
 778   stdux(Rscratch2, R1_SP, Rscratch1); // atomically set *(SP = top_frame_sp) = **SP
 779 }
 780 
 781 void InterpreterMacroAssembler::narrow(Register result) {
 782   Register ret_type = R11_scratch1;
 783   ld(R11_scratch1, in_bytes(Method::const_offset()), R19_method);
 784   lbz(ret_type, in_bytes(ConstMethod::result_type_offset()), R11_scratch1);
 785 
 786   Label notBool, notByte, notChar, done;
 787 
 788   // common case first
 789   cmpwi(CCR0, ret_type, T_INT);
 790   beq(CCR0, done);
 791 
</pre>
<hr />
<pre>
 865 
 866   merge_frames(/*top_frame_sp*/ R21_sender_SP, /*return_pc*/ R0, R11_scratch1, R12_scratch2);
 867   mtlr(R0);
 868   BLOCK_COMMENT(&quot;} remove_activation&quot;);
 869 }
 870 
 871 // Lock object
 872 //
 873 // Registers alive
 874 //   monitor - Address of the BasicObjectLock to be used for locking,
 875 //             which must be initialized with the object to lock.
 876 //   object  - Address of the object to be locked.
 877 //
 878 void InterpreterMacroAssembler::lock_object(Register monitor, Register object) {
 879   if (UseHeavyMonitors) {
 880     call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),
 881             monitor, /*check_for_exceptions=*/true);
 882   } else {
 883     // template code:
 884     //
<span class="line-modified"> 885     // markWord displaced_header = obj-&gt;mark().set_unlocked();</span>
 886     // monitor-&gt;lock()-&gt;set_displaced_header(displaced_header);
<span class="line-modified"> 887     // if (Atomic::cmpxchg(/*addr*/obj-&gt;mark_addr(), /*cmp*/displaced_header, /*ex=*/monitor) == displaced_header) {</span>
 888     //   // We stored the monitor address into the object&#39;s mark word.
 889     // } else if (THREAD-&gt;is_lock_owned((address)displaced_header))
 890     //   // Simple recursive case.
 891     //   monitor-&gt;lock()-&gt;set_displaced_header(NULL);
 892     // } else {
 893     //   // Slow path.
 894     //   InterpreterRuntime::monitorenter(THREAD, monitor);
 895     // }
 896 
 897     const Register displaced_header = R7_ARG5;
 898     const Register object_mark_addr = R8_ARG6;
 899     const Register current_header   = R9_ARG7;
 900     const Register tmp              = R10_ARG8;
 901 
 902     Label done;
 903     Label cas_failed, slow_case;
 904 
 905     assert_different_registers(displaced_header, object_mark_addr, current_header, tmp);
 906 
<span class="line-modified"> 907     // markWord displaced_header = obj-&gt;mark().set_unlocked();</span>
 908 
<span class="line-modified"> 909     // Load markWord from object into displaced_header.</span>
 910     ld(displaced_header, oopDesc::mark_offset_in_bytes(), object);
 911 
 912     if (UseBiasedLocking) {
 913       biased_locking_enter(CCR0, object, displaced_header, tmp, current_header, done, &amp;slow_case);
 914     }
 915 
<span class="line-modified"> 916     // Set displaced_header to be (markWord of object | UNLOCK_VALUE).</span>
<span class="line-modified"> 917     ori(displaced_header, displaced_header, markWord::unlocked_value);</span>
 918 
 919     // monitor-&gt;lock()-&gt;set_displaced_header(displaced_header);
 920 
 921     // Initialize the box (Must happen before we update the object mark!).
 922     std(displaced_header, BasicObjectLock::lock_offset_in_bytes() +
 923         BasicLock::displaced_header_offset_in_bytes(), monitor);
 924 
<span class="line-modified"> 925     // if (Atomic::cmpxchg(/*addr*/obj-&gt;mark_addr(), /*cmp*/displaced_header, /*ex=*/monitor) == displaced_header) {</span>
 926 
 927     // Store stack address of the BasicObjectLock (this is monitor) into object.
 928     addi(object_mark_addr, object, oopDesc::mark_offset_in_bytes());
 929 
 930     // Must fence, otherwise, preceding store(s) may float below cmpxchg.
 931     // CmpxchgX sets CCR0 to cmpX(current, displaced).
 932     cmpxchgd(/*flag=*/CCR0,
 933              /*current_value=*/current_header,
 934              /*compare_value=*/displaced_header, /*exchange_value=*/monitor,
 935              /*where=*/object_mark_addr,
 936              MacroAssembler::MemBarRel | MacroAssembler::MemBarAcq,
 937              MacroAssembler::cmpxchgx_hint_acquire_lock(),
 938              noreg,
 939              &amp;cas_failed,
 940              /*check without membar and ldarx first*/true);
 941 
 942     // If the compare-and-exchange succeeded, then we found an unlocked
 943     // object and we have now locked it.
 944     b(done);
 945     bind(cas_failed);
 946 
 947     // } else if (THREAD-&gt;is_lock_owned((address)displaced_header))
 948     //   // Simple recursive case.
 949     //   monitor-&gt;lock()-&gt;set_displaced_header(NULL);
 950 
 951     // We did not see an unlocked object so try the fast recursive case.
 952 
<span class="line-modified"> 953     // Check if owner is self by comparing the value in the markWord of object</span>
 954     // (current_header) with the stack pointer.
 955     sub(current_header, current_header, R1_SP);
 956 
 957     assert(os::vm_page_size() &gt; 0xfff, &quot;page size too small - change the constant&quot;);
<span class="line-modified"> 958     load_const_optimized(tmp, ~(os::vm_page_size()-1) | markWord::lock_mask_in_place);</span>
 959 
 960     and_(R0/*==0?*/, current_header, tmp);
 961     // If condition is true we are done and hence we can store 0 in the displaced
 962     // header indicating it is a recursive lock.
 963     bne(CCR0, slow_case);
 964     std(R0/*==0!*/, BasicObjectLock::lock_offset_in_bytes() +
 965         BasicLock::displaced_header_offset_in_bytes(), monitor);
 966     b(done);
 967 
 968     // } else {
 969     //   // Slow path.
 970     //   InterpreterRuntime::monitorenter(THREAD, monitor);
 971 
 972     // None of the above fast optimizations worked so we have to get into the
 973     // slow case of monitor enter.
 974     bind(slow_case);
 975     call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),
 976             monitor, /*check_for_exceptions=*/true);
 977     // }
 978     align(32, 12);
</pre>
<hr />
<pre>
 981 }
 982 
 983 // Unlocks an object. Used in monitorexit bytecode and remove_activation.
 984 //
 985 // Registers alive
 986 //   monitor - Address of the BasicObjectLock to be used for locking,
 987 //             which must be initialized with the object to lock.
 988 //
 989 // Throw IllegalMonitorException if object is not locked by current thread.
 990 void InterpreterMacroAssembler::unlock_object(Register monitor, bool check_for_exceptions) {
 991   if (UseHeavyMonitors) {
 992     call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit),
 993             monitor, check_for_exceptions);
 994   } else {
 995 
 996     // template code:
 997     //
 998     // if ((displaced_header = monitor-&gt;displaced_header()) == NULL) {
 999     //   // Recursive unlock. Mark the monitor unlocked by setting the object field to NULL.
1000     //   monitor-&gt;set_obj(NULL);
<span class="line-modified">1001     // } else if (Atomic::cmpxchg(obj-&gt;mark_addr(), monitor, displaced_header) == monitor) {</span>
1002     //   // We swapped the unlocked mark in displaced_header into the object&#39;s mark word.
1003     //   monitor-&gt;set_obj(NULL);
1004     // } else {
1005     //   // Slow path.
1006     //   InterpreterRuntime::monitorexit(THREAD, monitor);
1007     // }
1008 
1009     const Register object           = R7_ARG5;
1010     const Register displaced_header = R8_ARG6;
1011     const Register object_mark_addr = R9_ARG7;
1012     const Register current_header   = R10_ARG8;
1013 
1014     Label free_slot;
1015     Label slow_case;
1016 
1017     assert_different_registers(object, displaced_header, object_mark_addr, current_header);
1018 
1019     if (UseBiasedLocking) {
1020       // The object address from the monitor is in object.
1021       ld(object, BasicObjectLock::obj_offset_in_bytes(), monitor);
1022       assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
1023       biased_locking_exit(CCR0, object, displaced_header, free_slot);
1024     }
1025 
1026     // Test first if we are in the fast recursive case.
1027     ld(displaced_header, BasicObjectLock::lock_offset_in_bytes() +
1028            BasicLock::displaced_header_offset_in_bytes(), monitor);
1029 
1030     // If the displaced header is zero, we have a recursive unlock.
1031     cmpdi(CCR0, displaced_header, 0);
1032     beq(CCR0, free_slot); // recursive unlock
1033 
<span class="line-modified">1034     // } else if (Atomic::cmpxchg(obj-&gt;mark_addr(), monitor, displaced_header) == monitor) {</span>
1035     //   // We swapped the unlocked mark in displaced_header into the object&#39;s mark word.
1036     //   monitor-&gt;set_obj(NULL);
1037 
1038     // If we still have a lightweight lock, unlock the object and be done.
1039 
1040     // The object address from the monitor is in object.
1041     if (!UseBiasedLocking) { ld(object, BasicObjectLock::obj_offset_in_bytes(), monitor); }
1042     addi(object_mark_addr, object, oopDesc::mark_offset_in_bytes());
1043 
1044     // We have the displaced header in displaced_header. If the lock is still
1045     // lightweight, it will contain the monitor address and we&#39;ll store the
1046     // displaced header back into the object&#39;s mark word.
1047     // CmpxchgX sets CCR0 to cmpX(current, monitor).
1048     cmpxchgd(/*flag=*/CCR0,
1049              /*current_value=*/current_header,
1050              /*compare_value=*/monitor, /*exchange_value=*/displaced_header,
1051              /*where=*/object_mark_addr,
1052              MacroAssembler::MemBarRel,
1053              MacroAssembler::cmpxchgx_hint_release_lock(),
1054              noreg,
</pre>
<hr />
<pre>
2237   ld(R14_bcp, _ijava_state_neg(bcp), scratch); // Changed by VM code (exception).
2238   if (ProfileInterpreter) { ld(R28_mdx, _ijava_state_neg(mdx), scratch); } // Changed by VM code.
2239   if (!bcp_and_mdx_only) {
2240     // Following ones are Metadata.
2241     ld(R19_method, _ijava_state_neg(method), scratch);
2242     ld(R27_constPoolCache, _ijava_state_neg(cpoolCache), scratch);
2243     // Following ones are stack addresses and don&#39;t require reload.
2244     ld(R15_esp, _ijava_state_neg(esp), scratch);
2245     ld(R18_locals, _ijava_state_neg(locals), scratch);
2246     ld(R26_monitor, _ijava_state_neg(monitors), scratch);
2247   }
2248 #ifdef ASSERT
2249   {
2250     Label Lok;
2251     subf(R0, R1_SP, scratch);
2252     cmpdi(CCR0, R0, frame::abi_reg_args_size + frame::ijava_state_size);
2253     bge(CCR0, Lok);
2254     stop(&quot;frame too small (restore istate)&quot;, 0x5432);
2255     bind(Lok);
2256   }








2257 #endif
2258 }
2259 
2260 void InterpreterMacroAssembler::get_method_counters(Register method,
2261                                                     Register Rcounters,
2262                                                     Label&amp; skip) {
2263   BLOCK_COMMENT(&quot;Load and ev. allocate counter object {&quot;);
2264   Label has_counters;
2265   ld(Rcounters, in_bytes(Method::method_counters_offset()), method);
2266   cmpdi(CCR0, Rcounters, 0);
2267   bne(CCR0, has_counters);
2268   call_VM(noreg, CAST_FROM_FN_PTR(address,
<span class="line-modified">2269                                   InterpreterRuntime::build_method_counters), method);</span>
2270   ld(Rcounters, in_bytes(Method::method_counters_offset()), method);
2271   cmpdi(CCR0, Rcounters, 0);
2272   beq(CCR0, skip); // No MethodCounters, OutOfMemory.
2273   BLOCK_COMMENT(&quot;} Load and ev. allocate counter object&quot;);
2274 
2275   bind(has_counters);
2276 }
2277 
2278 void InterpreterMacroAssembler::increment_invocation_counter(Register Rcounters,
2279                                                              Register iv_be_count,
2280                                                              Register Rtmp_r0) {
2281   assert(UseCompiler || LogTouchedMethods, &quot;incrementing must be useful&quot;);
2282   Register invocation_count = iv_be_count;
2283   Register backedge_count   = Rtmp_r0;
2284   int delta = InvocationCounter::count_increment;
2285 
2286   // Load each counter in a register.
2287   //  ld(inv_counter, Rtmp);
2288   //  ld(be_counter, Rtmp2);
2289   int inv_counter_offset = in_bytes(MethodCounters::invocation_counter_offset() +
</pre>
<hr />
<pre>
2297   lwz(backedge_count, be_counter_offset, Rcounters); // is unsigned int
2298   // Mask the backedge counter.
2299   andi(backedge_count, backedge_count, InvocationCounter::count_mask_value);
2300 
2301   // Load the invocation counter.
2302   lwz(invocation_count, inv_counter_offset, Rcounters); // is unsigned int
2303   // Add the delta to the invocation counter and store the result.
2304   addi(invocation_count, invocation_count, delta);
2305   // Store value.
2306   stw(invocation_count, inv_counter_offset, Rcounters);
2307 
2308   // Add invocation counter + backedge counter.
2309   add(iv_be_count, backedge_count, invocation_count);
2310 
2311   // Note that this macro must leave the backedge_count + invocation_count in
2312   // register iv_be_count!
2313   BLOCK_COMMENT(&quot;} Increment profiling counters&quot;);
2314 }
2315 
2316 void InterpreterMacroAssembler::verify_oop(Register reg, TosState state) {
<span class="line-modified">2317   if (state == atos) { MacroAssembler::verify_oop(reg, FILE_AND_LINE); }</span>
2318 }
2319 
2320 // Local helper function for the verify_oop_or_return_address macro.
2321 static bool verify_return_address(Method* m, int bci) {
2322 #ifndef PRODUCT
2323   address pc = (address)(m-&gt;constMethod()) + in_bytes(ConstMethod::codes_offset()) + bci;
2324   // Assume it is a valid return address if it is inside m and is preceded by a jsr.
2325   if (!m-&gt;contains(pc))                                            return false;
2326   address jsr_pc;
2327   jsr_pc = pc - Bytecodes::length_for(Bytecodes::_jsr);
2328   if (*jsr_pc == Bytecodes::_jsr   &amp;&amp; jsr_pc &gt;= m-&gt;code_base())    return true;
2329   jsr_pc = pc - Bytecodes::length_for(Bytecodes::_jsr_w);
2330   if (*jsr_pc == Bytecodes::_jsr_w &amp;&amp; jsr_pc &gt;= m-&gt;code_base())    return true;
2331 #endif // PRODUCT
2332   return false;
2333 }
2334 
2335 void InterpreterMacroAssembler::verify_FPU(int stack_depth, TosState state) {
2336   if (VerifyFPU) {
2337     unimplemented(&quot;verfiyFPU&quot;);
</pre>
</td>
</tr>
</table>
<center><a href="interp_masm_ppc.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="interpreterRT_ppc.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>