<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff src/hotspot/cpu/ppc/macroAssembler_ppc.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="jniFastGetField_ppc.cpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_ppc.hpp.udiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/ppc/macroAssembler_ppc.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -30,10 +30,11 @@</span>
  #include &quot;gc/shared/barrierSet.hpp&quot;
  #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  #include &quot;interpreter/interpreter.hpp&quot;
  #include &quot;memory/resourceArea.hpp&quot;
  #include &quot;nativeInst_ppc.hpp&quot;
<span class="udiff-line-added">+ #include &quot;oops/klass.inline.hpp&quot;</span>
  #include &quot;prims/methodHandles.hpp&quot;
  #include &quot;runtime/biasedLocking.hpp&quot;
  #include &quot;runtime/icache.hpp&quot;
  #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  #include &quot;runtime/objectMonitor.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -41,10 +42,11 @@</span>
  #include &quot;runtime/safepoint.hpp&quot;
  #include &quot;runtime/safepointMechanism.hpp&quot;
  #include &quot;runtime/sharedRuntime.hpp&quot;
  #include &quot;runtime/stubRoutines.hpp&quot;
  #include &quot;utilities/macros.hpp&quot;
<span class="udiff-line-added">+ #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  #ifdef COMPILER2
  #include &quot;opto/intrinsicnode.hpp&quot;
  #endif
  
  #ifdef PRODUCT
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2009,19 +2011,37 @@</span>
    check_klass_subtype_fast_path(sub_klass, super_klass, temp1_reg, temp2_reg, &amp;L_success, &amp;L_failure);
    check_klass_subtype_slow_path(sub_klass, super_klass, temp1_reg, temp2_reg, &amp;L_success);
    bind(L_failure); // Fallthru if not successful.
  }
  
<span class="udiff-line-modified-removed">- void MacroAssembler::check_method_handle_type(Register mtype_reg, Register mh_reg,</span>
<span class="udiff-line-modified-removed">-                                               Register temp_reg,</span>
<span class="udiff-line-modified-removed">-                                               Label&amp; wrong_method_type) {</span>
<span class="udiff-line-modified-removed">-   assert_different_registers(mtype_reg, mh_reg, temp_reg);</span>
<span class="udiff-line-modified-removed">-   // Compare method type against that of the receiver.</span>
<span class="udiff-line-modified-removed">-   load_heap_oop(temp_reg, delayed_value(java_lang_invoke_MethodHandle::type_offset_in_bytes, temp_reg), mh_reg,</span>
<span class="udiff-line-modified-removed">-                 noreg, noreg, false, IS_NOT_NULL);</span>
<span class="udiff-line-modified-removed">-   cmpd(CCR0, temp_reg, mtype_reg);</span>
<span class="udiff-line-modified-removed">-   bne(CCR0, wrong_method_type);</span>
<span class="udiff-line-modified-added">+ void MacroAssembler::clinit_barrier(Register klass, Register thread, Label* L_fast_path, Label* L_slow_path) {</span>
<span class="udiff-line-modified-added">+   assert(L_fast_path != NULL || L_slow_path != NULL, &quot;at least one is required&quot;);</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+   Label L_fallthrough;</span>
<span class="udiff-line-modified-added">+   if (L_fast_path == NULL) {</span>
<span class="udiff-line-modified-added">+     L_fast_path = &amp;L_fallthrough;</span>
<span class="udiff-line-modified-added">+   } else if (L_slow_path == NULL) {</span>
<span class="udiff-line-modified-added">+     L_slow_path = &amp;L_fallthrough;</span>
<span class="udiff-line-modified-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Fast path check: class is fully initialized</span>
<span class="udiff-line-added">+   lbz(R0, in_bytes(InstanceKlass::init_state_offset()), klass);</span>
<span class="udiff-line-added">+   cmpwi(CCR0, R0, InstanceKlass::fully_initialized);</span>
<span class="udiff-line-added">+   beq(CCR0, *L_fast_path);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Fast path check: current thread is initializer thread</span>
<span class="udiff-line-added">+   ld(R0, in_bytes(InstanceKlass::init_thread_offset()), klass);</span>
<span class="udiff-line-added">+   cmpd(CCR0, thread, R0);</span>
<span class="udiff-line-added">+   if (L_slow_path == &amp;L_fallthrough) {</span>
<span class="udiff-line-added">+     beq(CCR0, *L_fast_path);</span>
<span class="udiff-line-added">+   } else if (L_fast_path == &amp;L_fallthrough) {</span>
<span class="udiff-line-added">+     bne(CCR0, *L_slow_path);</span>
<span class="udiff-line-added">+   } else {</span>
<span class="udiff-line-added">+     Unimplemented();</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   bind(L_fallthrough);</span>
  }
  
  RegisterOrConstant MacroAssembler::argument_offset(RegisterOrConstant arg_slot,
                                                     Register temp_reg,
                                                     int extra_slot_offset) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2058,27 +2078,27 @@</span>
    // Biased locking
    // See whether the lock is currently biased toward our thread and
    // whether the epoch is still valid
    // Note that the runtime guarantees sufficient alignment of JavaThread
    // pointers to allow age to be placed into low bits
<span class="udiff-line-modified-removed">-   assert(markOopDesc::age_shift == markOopDesc::lock_bits + markOopDesc::biased_lock_bits,</span>
<span class="udiff-line-modified-added">+   assert(markWord::age_shift == markWord::lock_bits + markWord::biased_lock_bits,</span>
           &quot;biased locking makes assumptions about bit layout&quot;);
  
    if (PrintBiasedLockingStatistics) {
      load_const(temp2_reg, (address) BiasedLocking::total_entry_count_addr(), temp_reg);
      lwzx(temp_reg, temp2_reg);
      addi(temp_reg, temp_reg, 1);
      stwx(temp_reg, temp2_reg);
    }
  
<span class="udiff-line-modified-removed">-   andi(temp_reg, mark_reg, markOopDesc::biased_lock_mask_in_place);</span>
<span class="udiff-line-modified-removed">-   cmpwi(cr_reg, temp_reg, markOopDesc::biased_lock_pattern);</span>
<span class="udiff-line-modified-added">+   andi(temp_reg, mark_reg, markWord::biased_lock_mask_in_place);</span>
<span class="udiff-line-modified-added">+   cmpwi(cr_reg, temp_reg, markWord::biased_lock_pattern);</span>
    bne(cr_reg, cas_label);
  
    load_klass(temp_reg, obj_reg);
  
<span class="udiff-line-modified-removed">-   load_const_optimized(temp2_reg, ~((int) markOopDesc::age_mask_in_place));</span>
<span class="udiff-line-modified-added">+   load_const_optimized(temp2_reg, ~((int) markWord::age_mask_in_place));</span>
    ld(temp_reg, in_bytes(Klass::prototype_header_offset()), temp_reg);
    orr(temp_reg, R16_thread, temp_reg);
    xorr(temp_reg, mark_reg, temp_reg);
    andr(temp_reg, temp_reg, temp2_reg);
    cmpdi(cr_reg, temp_reg, 0);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2105,11 +2125,11 @@</span>
    // header.
  
    // If the low three bits in the xor result aren&#39;t clear, that means
    // the prototype header is no longer biased and we have to revoke
    // the bias on this object.
<span class="udiff-line-modified-removed">-   andi(temp2_reg, temp_reg, markOopDesc::biased_lock_mask_in_place);</span>
<span class="udiff-line-modified-added">+   andi(temp2_reg, temp_reg, markWord::biased_lock_mask_in_place);</span>
    cmpwi(cr_reg, temp2_reg, 0);
    bne(cr_reg, try_revoke_bias);
  
    // Biasing is still enabled for this data type. See whether the
    // epoch of the current bias is still valid, meaning that the epoch
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2119,26 +2139,26 @@</span>
    // toward the current thread. Note that we must be absolutely sure
    // that the current epoch is invalid in order to do this because
    // otherwise the manipulations it performs on the mark word are
    // illegal.
  
<span class="udiff-line-modified-removed">-   int shift_amount = 64 - markOopDesc::epoch_shift;</span>
<span class="udiff-line-modified-added">+   int shift_amount = 64 - markWord::epoch_shift;</span>
    // rotate epoch bits to right (little) end and set other bits to 0
    // [ big part | epoch | little part ] -&gt; [ 0..0 | epoch ]
<span class="udiff-line-modified-removed">-   rldicl_(temp2_reg, temp_reg, shift_amount, 64 - markOopDesc::epoch_bits);</span>
<span class="udiff-line-modified-added">+   rldicl_(temp2_reg, temp_reg, shift_amount, 64 - markWord::epoch_bits);</span>
    // branch if epoch bits are != 0, i.e. they differ, because the epoch has been incremented
    bne(CCR0, try_rebias);
  
    // The epoch of the current bias is still valid but we know nothing
    // about the owner; it might be set or it might be clear. Try to
    // acquire the bias of the object using an atomic operation. If this
    // fails we will go in to the runtime to revoke the object&#39;s bias.
    // Note that we first construct the presumed unbiased header so we
    // don&#39;t accidentally blow away another thread&#39;s valid bias.
<span class="udiff-line-modified-removed">-   andi(mark_reg, mark_reg, (markOopDesc::biased_lock_mask_in_place |</span>
<span class="udiff-line-modified-removed">-                                 markOopDesc::age_mask_in_place |</span>
<span class="udiff-line-modified-removed">-                                 markOopDesc::epoch_mask_in_place));</span>
<span class="udiff-line-modified-added">+   andi(mark_reg, mark_reg, (markWord::biased_lock_mask_in_place |</span>
<span class="udiff-line-modified-added">+                                 markWord::age_mask_in_place |</span>
<span class="udiff-line-modified-added">+                                 markWord::epoch_mask_in_place));</span>
    orr(temp_reg, R16_thread, mark_reg);
  
    assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
  
    // CmpxchgX sets cr_reg to cmpX(temp2_reg, mark_reg).
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2167,11 +2187,11 @@</span>
    // circumstances _only_, we are allowed to use the current header&#39;s
    // value as the comparison value when doing the cas to acquire the
    // bias in the current epoch. In other words, we allow transfer of
    // the bias from one thread to another directly in this situation.
    load_klass(temp_reg, obj_reg);
<span class="udiff-line-modified-removed">-   andi(temp2_reg, mark_reg, markOopDesc::age_mask_in_place);</span>
<span class="udiff-line-modified-added">+   andi(temp2_reg, mark_reg, markWord::age_mask_in_place);</span>
    orr(temp2_reg, R16_thread, temp2_reg);
    ld(temp_reg, in_bytes(Klass::prototype_header_offset()), temp_reg);
    orr(temp_reg, temp2_reg, temp_reg);
  
    assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2204,11 +2224,11 @@</span>
    // that another thread raced us for the privilege of revoking the
    // bias of this particular object, so it&#39;s okay to continue in the
    // normal locking code.
    load_klass(temp_reg, obj_reg);
    ld(temp_reg, in_bytes(Klass::prototype_header_offset()), temp_reg);
<span class="udiff-line-modified-removed">-   andi(temp2_reg, mark_reg, markOopDesc::age_mask_in_place);</span>
<span class="udiff-line-modified-added">+   andi(temp2_reg, mark_reg, markWord::age_mask_in_place);</span>
    orr(temp_reg, temp_reg, temp2_reg);
  
    assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
  
    // CmpxchgX sets cr_reg to cmpX(temp2_reg, mark_reg).
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2216,11 +2236,11 @@</span>
                   /*compare_value=*/mark_reg, /*exchange_value=*/temp_reg,
                   /*where=*/obj_reg,
                   MacroAssembler::MemBarAcq,
                   MacroAssembler::cmpxchgx_hint_acquire_lock());
  
<span class="udiff-line-modified-removed">-   // reload markOop in mark_reg before continuing with lightweight locking</span>
<span class="udiff-line-modified-added">+   // reload markWord in mark_reg before continuing with lightweight locking</span>
    ld(mark_reg, oopDesc::mark_offset_in_bytes(), obj_reg);
  
    // Fall through to the normal CAS-based lock, because no matter what
    // the result of the above CAS, some thread must have succeeded in
    // removing the bias bit from the object&#39;s header.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2244,13 +2264,13 @@</span>
    // a higher level. Second, if the bias was revoked while we held the
    // lock, the object could not be rebiased toward another thread, so
    // the bias bit would be clear.
  
    ld(temp_reg, 0, mark_addr);
<span class="udiff-line-modified-removed">-   andi(temp_reg, temp_reg, markOopDesc::biased_lock_mask_in_place);</span>
<span class="udiff-line-modified-added">+   andi(temp_reg, temp_reg, markWord::biased_lock_mask_in_place);</span>
  
<span class="udiff-line-modified-removed">-   cmpwi(cr_reg, temp_reg, markOopDesc::biased_lock_pattern);</span>
<span class="udiff-line-modified-added">+   cmpwi(cr_reg, temp_reg, markWord::biased_lock_pattern);</span>
    beq(cr_reg, done);
  }
  
  // allocation (for C1)
  void MacroAssembler::eden_allocate(
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2667,11 +2687,11 @@</span>
  
    if (RTMRetryCount &gt; 0) {
      load_const_optimized(retry_on_abort_count_Reg, RTMRetryCount); // Retry on abort
      bind(L_rtm_retry);
    }
<span class="udiff-line-modified-removed">-   andi_(R0, mark_word, markOopDesc::monitor_value);  // inflated vs stack-locked|neutral|biased</span>
<span class="udiff-line-modified-added">+   andi_(R0, mark_word, markWord::monitor_value);  // inflated vs stack-locked|neutral|biased</span>
    bne(CCR0, IsInflated);
  
    if (PrintPreciseRTMLockingStatistics || profile_rtm) {
      Label L_noincrement;
      if (RTMTotalCountIncrRate &gt; 1) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2685,14 +2705,14 @@</span>
      stdx(mark_word, tmp);
      bind(L_noincrement);
    }
    tbegin_();
    beq(CCR0, L_on_abort);
<span class="udiff-line-modified-removed">-   ld(mark_word, oopDesc::mark_offset_in_bytes(), obj);         // Reload in transaction, conflicts need to be tracked.</span>
<span class="udiff-line-modified-removed">-   andi(R0, mark_word, markOopDesc::biased_lock_mask_in_place); // look at 3 lock bits</span>
<span class="udiff-line-modified-removed">-   cmpwi(flag, R0, markOopDesc::unlocked_value);                // bits = 001 unlocked</span>
<span class="udiff-line-modified-removed">-   beq(flag, DONE_LABEL);                                       // all done if unlocked</span>
<span class="udiff-line-modified-added">+   ld(mark_word, oopDesc::mark_offset_in_bytes(), obj);      // Reload in transaction, conflicts need to be tracked.</span>
<span class="udiff-line-modified-added">+   andi(R0, mark_word, markWord::biased_lock_mask_in_place); // look at 3 lock bits</span>
<span class="udiff-line-modified-added">+   cmpwi(flag, R0, markWord::unlocked_value);                // bits = 001 unlocked</span>
<span class="udiff-line-modified-added">+   beq(flag, DONE_LABEL);                                    // all done if unlocked</span>
  
    if (UseRTMXendForLockBusy) {
      tend_();
      b(L_decrement_retry);
    } else {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2724,13 +2744,13 @@</span>
                                            Metadata* method_data, bool profile_rtm,
                                            Label&amp; DONE_LABEL) {
    assert(UseRTMLocking, &quot;why call this otherwise?&quot;);
    Label L_rtm_retry, L_decrement_retry, L_on_abort;
    // Clean monitor_value bit to get valid pointer.
<span class="udiff-line-modified-removed">-   int owner_offset = ObjectMonitor::owner_offset_in_bytes() - markOopDesc::monitor_value;</span>
<span class="udiff-line-modified-added">+   int owner_offset = ObjectMonitor::owner_offset_in_bytes() - markWord::monitor_value;</span>
  
<span class="udiff-line-modified-removed">-   // Store non-null, using boxReg instead of (intptr_t)markOopDesc::unused_mark().</span>
<span class="udiff-line-modified-added">+   // Store non-null, using boxReg instead of (intptr_t)markWord::unused_mark().</span>
    std(boxReg, BasicLock::displaced_header_offset_in_bytes(), boxReg);
    const Register tmpReg = boxReg;
    const Register owner_addr_Reg = mark_word;
    addi(owner_addr_Reg, mark_word, owner_offset);
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2771,11 +2791,11 @@</span>
    if (PrintPreciseRTMLockingStatistics || profile_rtm) {
      rtm_profiling(abort_status_Reg, /*temp*/ owner_addr_Reg, rtm_counters, method_data, profile_rtm);
      // Restore owner_addr_Reg
      ld(mark_word, oopDesc::mark_offset_in_bytes(), obj);
  #ifdef ASSERT
<span class="udiff-line-modified-removed">-     andi_(R0, mark_word, markOopDesc::monitor_value);</span>
<span class="udiff-line-modified-added">+     andi_(R0, mark_word, markWord::monitor_value);</span>
      asm_assert_ne(&quot;must be inflated&quot;, 0xa754); // Deflating only allowed at safepoint.
  #endif
      addi(owner_addr_Reg, mark_word, owner_offset);
    }
    if (RTMRetryCount &gt; 0) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2813,11 +2833,11 @@</span>
    assert(flag != CCR0, &quot;bad condition register&quot;);
    Label cont;
    Label object_has_monitor;
    Label cas_failed;
  
<span class="udiff-line-modified-removed">-   // Load markOop from object into displaced_header.</span>
<span class="udiff-line-modified-added">+   // Load markWord from object into displaced_header.</span>
    ld(displaced_header, oopDesc::mark_offset_in_bytes(), oop);
  
  
    if (try_bias) {
      biased_locking_enter(flag, oop, displaced_header, temp, current_header, cont);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2831,23 +2851,23 @@</span>
    }
  #endif // INCLUDE_RTM_OPT
  
    // Handle existing monitor.
    // The object has an existing monitor iff (mark &amp; monitor_value) != 0.
<span class="udiff-line-modified-removed">-   andi_(temp, displaced_header, markOopDesc::monitor_value);</span>
<span class="udiff-line-modified-added">+   andi_(temp, displaced_header, markWord::monitor_value);</span>
    bne(CCR0, object_has_monitor);
  
<span class="udiff-line-modified-removed">-   // Set displaced_header to be (markOop of object | UNLOCK_VALUE).</span>
<span class="udiff-line-modified-removed">-   ori(displaced_header, displaced_header, markOopDesc::unlocked_value);</span>
<span class="udiff-line-modified-added">+   // Set displaced_header to be (markWord of object | UNLOCK_VALUE).</span>
<span class="udiff-line-modified-added">+   ori(displaced_header, displaced_header, markWord::unlocked_value);</span>
  
    // Load Compare Value application register.
  
    // Initialize the box. (Must happen before we update the object mark!)
    std(displaced_header, BasicLock::displaced_header_offset_in_bytes(), box);
  
    // Must fence, otherwise, preceding store(s) may float below cmpxchg.
<span class="udiff-line-modified-removed">-   // Compare object markOop with mark and if equal exchange scratch1 with object markOop.</span>
<span class="udiff-line-modified-added">+   // Compare object markWord with mark and if equal exchange scratch1 with object markWord.</span>
    cmpxchgd(/*flag=*/flag,
             /*current_value=*/current_header,
             /*compare_value=*/displaced_header,
             /*exchange_value=*/box,
             /*where=*/oop,
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2863,14 +2883,14 @@</span>
    b(cont);
  
    bind(cas_failed);
    // We did not see an unlocked object so try the fast recursive case.
  
<span class="udiff-line-modified-removed">-   // Check if the owner is self by comparing the value in the markOop of object</span>
<span class="udiff-line-modified-added">+   // Check if the owner is self by comparing the value in the markWord of object</span>
    // (current_header) with the stack pointer.
    sub(current_header, current_header, R1_SP);
<span class="udiff-line-modified-removed">-   load_const_optimized(temp, ~(os::vm_page_size()-1) | markOopDesc::lock_mask_in_place);</span>
<span class="udiff-line-modified-added">+   load_const_optimized(temp, ~(os::vm_page_size()-1) | markWord::lock_mask_in_place);</span>
  
    and_(R0/*==0?*/, current_header, temp);
    // If condition is true we are cont and hence we can store 0 as the
    // displaced header in the box, which indicates that it is a recursive lock.
    mcrf(flag,CCR0);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2890,11 +2910,11 @@</span>
                           rtm_counters, method_data, profile_rtm, cont);
    } else {
  #endif // INCLUDE_RTM_OPT
  
    // Try to CAS m-&gt;owner from NULL to current thread.
<span class="udiff-line-modified-removed">-   addi(temp, displaced_header, ObjectMonitor::owner_offset_in_bytes()-markOopDesc::monitor_value);</span>
<span class="udiff-line-modified-added">+   addi(temp, displaced_header, ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value);</span>
    cmpxchgd(/*flag=*/flag,
             /*current_value=*/current_header,
             /*compare_value=*/(intptr_t)0,
             /*exchange_value=*/R16_thread,
             /*where=*/temp,
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2937,16 +2957,16 @@</span>
  
  #if INCLUDE_RTM_OPT
    if (UseRTMForStackLocks &amp;&amp; use_rtm) {
      assert(!UseBiasedLocking, &quot;Biased locking is not supported with RTM locking&quot;);
      Label L_regular_unlock;
<span class="udiff-line-modified-removed">-     ld(current_header, oopDesc::mark_offset_in_bytes(), oop);         // fetch markword</span>
<span class="udiff-line-modified-removed">-     andi(R0, current_header, markOopDesc::biased_lock_mask_in_place); // look at 3 lock bits</span>
<span class="udiff-line-modified-removed">-     cmpwi(flag, R0, markOopDesc::unlocked_value);                     // bits = 001 unlocked</span>
<span class="udiff-line-modified-removed">-     bne(flag, L_regular_unlock);                                      // else RegularLock</span>
<span class="udiff-line-modified-removed">-     tend_();                                                          // otherwise end...</span>
<span class="udiff-line-modified-removed">-     b(cont);                                                          // ... and we&#39;re done</span>
<span class="udiff-line-modified-added">+     ld(current_header, oopDesc::mark_offset_in_bytes(), oop);      // fetch markword</span>
<span class="udiff-line-modified-added">+     andi(R0, current_header, markWord::biased_lock_mask_in_place); // look at 3 lock bits</span>
<span class="udiff-line-modified-added">+     cmpwi(flag, R0, markWord::unlocked_value);                     // bits = 001 unlocked</span>
<span class="udiff-line-modified-added">+     bne(flag, L_regular_unlock);                                   // else RegularLock</span>
<span class="udiff-line-modified-added">+     tend_();                                                       // otherwise end...</span>
<span class="udiff-line-modified-added">+     b(cont);                                                       // ... and we&#39;re done</span>
      bind(L_regular_unlock);
    }
  #endif
  
    // Find the lock address and load the displaced header from the stack.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2958,15 +2978,15 @@</span>
  
    // Handle existing monitor.
    // The object has an existing monitor iff (mark &amp; monitor_value) != 0.
    RTM_OPT_ONLY( if (!(UseRTMForStackLocks &amp;&amp; use_rtm)) ) // skip load if already done
    ld(current_header, oopDesc::mark_offset_in_bytes(), oop);
<span class="udiff-line-modified-removed">-   andi_(R0, current_header, markOopDesc::monitor_value);</span>
<span class="udiff-line-modified-added">+   andi_(R0, current_header, markWord::monitor_value);</span>
    bne(CCR0, object_has_monitor);
  
    // Check if it is still a light weight lock, this is is true if we see
<span class="udiff-line-modified-removed">-   // the stack address of the basicLock in the markOop of the object.</span>
<span class="udiff-line-modified-added">+   // the stack address of the basicLock in the markWord of the object.</span>
    // Cmpxchg sets flag to cmpd(current_header, box).
    cmpxchgd(/*flag=*/flag,
             /*current_value=*/current_header,
             /*compare_value=*/box,
             /*exchange_value=*/displaced_header,
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2980,11 +3000,12 @@</span>
  
    // Handle existing monitor.
    b(cont);
  
    bind(object_has_monitor);
<span class="udiff-line-modified-removed">-   addi(current_header, current_header, -markOopDesc::monitor_value); // monitor</span>
<span class="udiff-line-modified-added">+   STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);</span>
<span class="udiff-line-added">+   addi(current_header, current_header, -(int)markWord::monitor_value); // monitor</span>
    ld(temp,             ObjectMonitor::owner_offset_in_bytes(), current_header);
  
      // It&#39;s inflated.
  #if INCLUDE_RTM_OPT
    if (use_rtm) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -3098,11 +3119,11 @@</span>
  
    ld(oop_result, in_bytes(JavaThread::vm_result_offset()), R16_thread);
    li(R0, 0);
    std(R0, in_bytes(JavaThread::vm_result_offset()), R16_thread);
  
<span class="udiff-line-modified-removed">-   verify_oop(oop_result);</span>
<span class="udiff-line-modified-added">+   verify_oop(oop_result, FILE_AND_LINE);</span>
  }
  
  void MacroAssembler::get_vm_result_2(Register metadata_result) {
    // Read:
    //   R16_thread
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -3117,17 +3138,17 @@</span>
    std(R0, in_bytes(JavaThread::vm_result_2_offset()), R16_thread);
  }
  
  Register MacroAssembler::encode_klass_not_null(Register dst, Register src) {
    Register current = (src != noreg) ? src : dst; // Klass is in dst if no src provided.
<span class="udiff-line-modified-removed">-   if (Universe::narrow_klass_base() != 0) {</span>
<span class="udiff-line-modified-added">+   if (CompressedKlassPointers::base() != 0) {</span>
      // Use dst as temp if it is free.
<span class="udiff-line-modified-removed">-     sub_const_optimized(dst, current, Universe::narrow_klass_base(), R0);</span>
<span class="udiff-line-modified-added">+     sub_const_optimized(dst, current, CompressedKlassPointers::base(), R0);</span>
      current = dst;
    }
<span class="udiff-line-modified-removed">-   if (Universe::narrow_klass_shift() != 0) {</span>
<span class="udiff-line-modified-removed">-     srdi(dst, current, Universe::narrow_klass_shift());</span>
<span class="udiff-line-modified-added">+   if (CompressedKlassPointers::shift() != 0) {</span>
<span class="udiff-line-modified-added">+     srdi(dst, current, CompressedKlassPointers::shift());</span>
      current = dst;
    }
    return current;
  }
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -3151,25 +3172,25 @@</span>
  }
  
  int MacroAssembler::instr_size_for_decode_klass_not_null() {
    if (!UseCompressedClassPointers) return 0;
    int num_instrs = 1;  // shift or move
<span class="udiff-line-modified-removed">-   if (Universe::narrow_klass_base() != 0) num_instrs = 7;  // shift + load const + add</span>
<span class="udiff-line-modified-added">+   if (CompressedKlassPointers::base() != 0) num_instrs = 7;  // shift + load const + add</span>
    return num_instrs * BytesPerInstWord;
  }
  
  void MacroAssembler::decode_klass_not_null(Register dst, Register src) {
    assert(dst != R0, &quot;Dst reg may not be R0, as R0 is used here.&quot;);
    if (src == noreg) src = dst;
    Register shifted_src = src;
<span class="udiff-line-modified-removed">-   if (Universe::narrow_klass_shift() != 0 ||</span>
<span class="udiff-line-modified-removed">-       Universe::narrow_klass_base() == 0 &amp;&amp; src != dst) {  // Move required.</span>
<span class="udiff-line-modified-added">+   if (CompressedKlassPointers::shift() != 0 ||</span>
<span class="udiff-line-modified-added">+       CompressedKlassPointers::base() == 0 &amp;&amp; src != dst) {  // Move required.</span>
      shifted_src = dst;
<span class="udiff-line-modified-removed">-     sldi(shifted_src, src, Universe::narrow_klass_shift());</span>
<span class="udiff-line-modified-added">+     sldi(shifted_src, src, CompressedKlassPointers::shift());</span>
    }
<span class="udiff-line-modified-removed">-   if (Universe::narrow_klass_base() != 0) {</span>
<span class="udiff-line-modified-removed">-     add_const_optimized(dst, shifted_src, Universe::narrow_klass_base(), R0);</span>
<span class="udiff-line-modified-added">+   if (CompressedKlassPointers::base() != 0) {</span>
<span class="udiff-line-modified-added">+     add_const_optimized(dst, shifted_src, CompressedKlassPointers::base(), R0);</span>
    }
  }
  
  void MacroAssembler::load_klass(Register dst, Register src) {
    if (UseCompressedClassPointers) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -3192,10 +3213,16 @@</span>
    ld(mirror, ConstantPool::pool_holder_offset_in_bytes(), mirror);
    ld(mirror, in_bytes(Klass::java_mirror_offset()), mirror);
    resolve_oop_handle(mirror);
  }
  
<span class="udiff-line-added">+ void MacroAssembler::load_method_holder(Register holder, Register method) {</span>
<span class="udiff-line-added">+   ld(holder, in_bytes(Method::const_offset()), method);</span>
<span class="udiff-line-added">+   ld(holder, in_bytes(ConstMethod::constants_offset()), holder);</span>
<span class="udiff-line-added">+   ld(holder, ConstantPool::pool_holder_offset_in_bytes(), holder);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  // Clear Array
  // For very short arrays. tmp == R0 is allowed.
  void MacroAssembler::clear_memory_unrolled(Register base_ptr, int cnt_dwords, Register tmp, int offset) {
    if (cnt_dwords &gt; 0) { li(tmp, 0); }
    for (int i = 0; i &lt; cnt_dwords; ++i) { std(tmp, offset + i * 8, base_ptr); }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -4889,19 +4916,29 @@</span>
    if (VerifyThread) {
      unimplemented(&quot;&#39;VerifyThread&#39; currently not implemented on PPC&quot;);
    }
  }
  
<span class="udiff-line-added">+ void MacroAssembler::verify_coop(Register coop, const char* msg) {</span>
<span class="udiff-line-added">+   if (!VerifyOops) { return; }</span>
<span class="udiff-line-added">+   if (UseCompressedOops) { decode_heap_oop(coop); }</span>
<span class="udiff-line-added">+   verify_oop(coop, msg);</span>
<span class="udiff-line-added">+   if (UseCompressedOops) { encode_heap_oop(coop, coop); }</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  // READ: oop. KILL: R0. Volatile floats perhaps.
  void MacroAssembler::verify_oop(Register oop, const char* msg) {
    if (!VerifyOops) {
      return;
    }
  
    address/* FunctionDescriptor** */fd = StubRoutines::verify_oop_subroutine_entry_address();
    const Register tmp = R11; // Will be preserved.
    const int nbytes_save = MacroAssembler::num_volatile_regs * 8;
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   BLOCK_COMMENT(&quot;verify_oop {&quot;);</span>
<span class="udiff-line-added">+ </span>
    save_volatile_gprs(R1_SP, -nbytes_save); // except R0
  
    mr_if_needed(R4_ARG2, oop);
    save_LR_CR(tmp); // save in old frame
    push_frame_reg_args(nbytes_save, tmp);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -4914,10 +4951,12 @@</span>
    call_c(tmp);
  
    pop_frame();
    restore_LR_CR(tmp);
    restore_volatile_gprs(R1_SP, -nbytes_save); // except R0
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   BLOCK_COMMENT(&quot;} verify_oop&quot;);</span>
  }
  
  void MacroAssembler::verify_oop_addr(RegisterOrConstant offs, Register base, const char* msg) {
    if (!VerifyOops) {
      return;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -5023,5 +5062,24 @@</span>
  }
  
  SkipIfEqualZero::~SkipIfEqualZero() {
    _masm-&gt;bind(_label);
  }
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::cache_wb(Address line) {</span>
<span class="udiff-line-added">+   assert(line.index() == noreg, &quot;index should be noreg&quot;);</span>
<span class="udiff-line-added">+   assert(line.disp() == 0, &quot;displacement should be 0&quot;);</span>
<span class="udiff-line-added">+   assert(VM_Version::supports_data_cache_line_flush(), &quot;CPU or OS does not support flush to persistent memory&quot;);</span>
<span class="udiff-line-added">+   // Data Cache Store, not really a flush, so it works like a sync of cache</span>
<span class="udiff-line-added">+   // line and persistent mem, i.e. copying the cache line to persistent whilst</span>
<span class="udiff-line-added">+   // not invalidating the cache line.</span>
<span class="udiff-line-added">+   dcbst(line.base());</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::cache_wbsync(bool is_presync) {</span>
<span class="udiff-line-added">+   assert(VM_Version::supports_data_cache_line_flush(), &quot;CPU or OS does not support sync related to persistent memory&quot;);</span>
<span class="udiff-line-added">+   // We only need a post sync barrier. Post means _after_ a cache line flush or</span>
<span class="udiff-line-added">+   // store instruction, pre means a barrier emitted before such a instructions.</span>
<span class="udiff-line-added">+   if (!is_presync) {</span>
<span class="udiff-line-added">+     fence();</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ }</span>
</pre>
<center><a href="jniFastGetField_ppc.cpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_ppc.hpp.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>