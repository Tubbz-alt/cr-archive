<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/ppc/macroAssembler_ppc.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="macroAssembler_ppc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_ppc.inline.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/ppc/macroAssembler_ppc.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
542   // The rest of the type check; must be wired to a corresponding fast path.
543   // It does not repeat the fast path logic, so don&#39;t use it standalone.
544   // The temp_reg can be noreg, if no temps are available.
545   // It can also be sub_klass or super_klass, meaning it&#39;s OK to kill that one.
546   // Updates the sub&#39;s secondary super cache as necessary.
547   void check_klass_subtype_slow_path(Register sub_klass,
548                                      Register super_klass,
549                                      Register temp1_reg,
550                                      Register temp2_reg,
551                                      Label* L_success = NULL,
552                                      Register result_reg = noreg);
553 
554   // Simplified, combined version, good for typical uses.
555   // Falls through on failure.
556   void check_klass_subtype(Register sub_klass,
557                            Register super_klass,
558                            Register temp1_reg,
559                            Register temp2_reg,
560                            Label&amp; L_success);
561 
<span class="line-modified">562   // Method handle support (JSR 292).</span>
<span class="line-modified">563   void check_method_handle_type(Register mtype_reg, Register mh_reg, Register temp_reg, Label&amp; wrong_method_type);</span>


564 

565   RegisterOrConstant argument_offset(RegisterOrConstant arg_slot, Register temp_reg, int extra_slot_offset = 0);
566 
567   // Biased locking support
568   // Upon entry,obj_reg must contain the target object, and mark_reg
569   // must contain the target object&#39;s header.
570   // Destroys mark_reg if an attempt is made to bias an anonymously
571   // biased lock. In this case a failure will go either to the slow
572   // case or fall through with the notEqual condition code set with
573   // the expectation that the slow case in the runtime will be called.
574   // In the fall-through case where the CAS-based lock is done,
575   // mark_reg is not destroyed.
576   void biased_locking_enter(ConditionRegister cr_reg, Register obj_reg, Register mark_reg, Register temp_reg,
577                             Register temp2_reg, Label&amp; done, Label* slow_case = NULL);
578   // Upon entry, the base register of mark_addr must contain the oop.
579   // Destroys temp_reg.
580   // If allow_delay_slot_filling is set to true, the next instruction
581   // emitted after this one will go in an annulled delay slot if the
582   // biased locking exit case failed.
583   void biased_locking_exit(ConditionRegister cr_reg, Register mark_addr, Register temp_reg, Label&amp; done);
584 
</pre>
<hr />
<pre>
705   inline void store_heap_oop(Register d, RegisterOrConstant offs, Register s1,
706                              Register tmp1, Register tmp2, Register tmp3, bool needs_frame,
707                              DecoratorSet decorators = 0);
708 
709   // Encode/decode heap oop. Oop may not be null, else en/decoding goes wrong.
710   // src == d allowed.
711   inline Register encode_heap_oop_not_null(Register d, Register src = noreg);
712   inline Register decode_heap_oop_not_null(Register d, Register src = noreg);
713 
714   // Null allowed.
715   inline Register encode_heap_oop(Register d, Register src); // Prefer null check in GC barrier!
716   inline void decode_heap_oop(Register d);
717 
718   // Load/Store klass oop from klass field. Compress.
719   void load_klass(Register dst, Register src);
720   void store_klass(Register dst_oop, Register klass, Register tmp = R0);
721   void store_klass_gap(Register dst_oop, Register val = noreg); // Will store 0 if val not specified.
722 
723   void resolve_oop_handle(Register result);
724   void load_mirror_from_const_method(Register mirror, Register const_method);

725 
726   static int instr_size_for_decode_klass_not_null();
727   void decode_klass_not_null(Register dst, Register src = noreg);
728   Register encode_klass_not_null(Register dst, Register src = noreg);
729 
730   // SIGTRAP-based range checks for arrays.
731   inline void trap_range_check_l(Register a, Register b);
732   inline void trap_range_check_l(Register a, int si16);
733   static bool is_trap_range_check_l(int x) {
734     return (is_tw (x, traptoLessThanUnsigned, -1/*any reg*/, -1/*any reg*/) ||
735             is_twi(x, traptoLessThanUnsigned, -1/*any reg*/)                  );
736   }
737   inline void trap_range_check_le(Register a, int si16);
738   static bool is_trap_range_check_le(int x) {
739     return is_twi(x, traptoEqual | traptoLessThanUnsigned, -1/*any reg*/);
740   }
741   inline void trap_range_check_g(Register a, int si16);
742   static bool is_trap_range_check_g(int x) {
743     return is_twi(x, traptoGreaterThanUnsigned, -1/*any reg*/);
744   }
</pre>
<hr />
<pre>
867   void sha256_update_sha_state(const VectorRegister a, const VectorRegister b,
868       const VectorRegister c, const VectorRegister d, const VectorRegister e,
869       const VectorRegister f, const VectorRegister g, const VectorRegister h,
870       const Register hptr);
871 
872   void sha512_load_w_vec(const Register buf_in, const VectorRegister* ws, const int total_ws);
873   void sha512_update_sha_state(const Register state, const VectorRegister* hs, const int total_hs);
874   void sha512_round(const VectorRegister* hs, const int total_hs, int&amp; h_cnt, const VectorRegister kpw);
875   void sha512_load_h_vec(const Register state, const VectorRegister* hs, const int total_hs);
876   void sha512_calc_2w(const VectorRegister w0, const VectorRegister w1,
877       const VectorRegister w2, const VectorRegister w3,
878       const VectorRegister w4, const VectorRegister w5,
879       const VectorRegister w6, const VectorRegister w7,
880       const VectorRegister kpw0, const VectorRegister kpw1, const Register j,
881       const VectorRegister vRb, const Register k);
882 
883  public:
884   void sha256(bool multi_block);
885   void sha512(bool multi_block);
886 


887 
888   //
889   // Debugging
890   //
891 
892   // assert on cr0
893   void asm_assert(bool check_equal, const char* msg, int id);
894   void asm_assert_eq(const char* msg, int id) { asm_assert(true, msg, id); }
895   void asm_assert_ne(const char* msg, int id) { asm_assert(false, msg, id); }
896 
897  private:
898   void asm_assert_mems_zero(bool check_equal, int size, int mem_offset, Register mem_base,
899                             const char* msg, int id);
900 
901  public:
902 
903   void asm_assert_mem8_is_zero(int mem_offset, Register mem_base, const char* msg, int id) {
904     asm_assert_mems_zero(true,  8, mem_offset, mem_base, msg, id);
905   }
906   void asm_assert_mem8_isnot_zero(int mem_offset, Register mem_base, const char* msg, int id) {
907     asm_assert_mems_zero(false, 8, mem_offset, mem_base, msg, id);
908   }
909 
910   // Verify R16_thread contents.
911   void verify_thread();
912 



913   // Emit code to verify that reg contains a valid oop if +VerifyOops is set.
914   void verify_oop(Register reg, const char* s = &quot;broken oop&quot;);
915   void verify_oop_addr(RegisterOrConstant offs, Register base, const char* s = &quot;contains broken oop&quot;);
916 
917   // TODO: verify method and klass metadata (compare against vptr?)
918   void _verify_method_ptr(Register reg, const char * msg, const char * file, int line) {}
919   void _verify_klass_ptr(Register reg, const char * msg, const char * file, int line) {}
920 
921   // Convenience method returning function entry. For the ELFv1 case
922   // creates function descriptor at the current address and returs
923   // the pointer to it. For the ELFv2 case returns the current address.
924   inline address function_entry();
925 
926 #define verify_method_ptr(reg) _verify_method_ptr(reg, &quot;broken method &quot; #reg, __FILE__, __LINE__)
927 #define verify_klass_ptr(reg) _verify_klass_ptr(reg, &quot;broken klass &quot; #reg, __FILE__, __LINE__)
928 
929  private:
930 
931   enum {
932     stop_stop                = 0,
</pre>
</td>
<td>
<hr />
<pre>
542   // The rest of the type check; must be wired to a corresponding fast path.
543   // It does not repeat the fast path logic, so don&#39;t use it standalone.
544   // The temp_reg can be noreg, if no temps are available.
545   // It can also be sub_klass or super_klass, meaning it&#39;s OK to kill that one.
546   // Updates the sub&#39;s secondary super cache as necessary.
547   void check_klass_subtype_slow_path(Register sub_klass,
548                                      Register super_klass,
549                                      Register temp1_reg,
550                                      Register temp2_reg,
551                                      Label* L_success = NULL,
552                                      Register result_reg = noreg);
553 
554   // Simplified, combined version, good for typical uses.
555   // Falls through on failure.
556   void check_klass_subtype(Register sub_klass,
557                            Register super_klass,
558                            Register temp1_reg,
559                            Register temp2_reg,
560                            Label&amp; L_success);
561 
<span class="line-modified">562   void clinit_barrier(Register klass,</span>
<span class="line-modified">563                       Register thread,</span>
<span class="line-added">564                       Label* L_fast_path = NULL,</span>
<span class="line-added">565                       Label* L_slow_path = NULL);</span>
566 
<span class="line-added">567   // Method handle support (JSR 292).</span>
568   RegisterOrConstant argument_offset(RegisterOrConstant arg_slot, Register temp_reg, int extra_slot_offset = 0);
569 
570   // Biased locking support
571   // Upon entry,obj_reg must contain the target object, and mark_reg
572   // must contain the target object&#39;s header.
573   // Destroys mark_reg if an attempt is made to bias an anonymously
574   // biased lock. In this case a failure will go either to the slow
575   // case or fall through with the notEqual condition code set with
576   // the expectation that the slow case in the runtime will be called.
577   // In the fall-through case where the CAS-based lock is done,
578   // mark_reg is not destroyed.
579   void biased_locking_enter(ConditionRegister cr_reg, Register obj_reg, Register mark_reg, Register temp_reg,
580                             Register temp2_reg, Label&amp; done, Label* slow_case = NULL);
581   // Upon entry, the base register of mark_addr must contain the oop.
582   // Destroys temp_reg.
583   // If allow_delay_slot_filling is set to true, the next instruction
584   // emitted after this one will go in an annulled delay slot if the
585   // biased locking exit case failed.
586   void biased_locking_exit(ConditionRegister cr_reg, Register mark_addr, Register temp_reg, Label&amp; done);
587 
</pre>
<hr />
<pre>
708   inline void store_heap_oop(Register d, RegisterOrConstant offs, Register s1,
709                              Register tmp1, Register tmp2, Register tmp3, bool needs_frame,
710                              DecoratorSet decorators = 0);
711 
712   // Encode/decode heap oop. Oop may not be null, else en/decoding goes wrong.
713   // src == d allowed.
714   inline Register encode_heap_oop_not_null(Register d, Register src = noreg);
715   inline Register decode_heap_oop_not_null(Register d, Register src = noreg);
716 
717   // Null allowed.
718   inline Register encode_heap_oop(Register d, Register src); // Prefer null check in GC barrier!
719   inline void decode_heap_oop(Register d);
720 
721   // Load/Store klass oop from klass field. Compress.
722   void load_klass(Register dst, Register src);
723   void store_klass(Register dst_oop, Register klass, Register tmp = R0);
724   void store_klass_gap(Register dst_oop, Register val = noreg); // Will store 0 if val not specified.
725 
726   void resolve_oop_handle(Register result);
727   void load_mirror_from_const_method(Register mirror, Register const_method);
<span class="line-added">728   void load_method_holder(Register holder, Register method);</span>
729 
730   static int instr_size_for_decode_klass_not_null();
731   void decode_klass_not_null(Register dst, Register src = noreg);
732   Register encode_klass_not_null(Register dst, Register src = noreg);
733 
734   // SIGTRAP-based range checks for arrays.
735   inline void trap_range_check_l(Register a, Register b);
736   inline void trap_range_check_l(Register a, int si16);
737   static bool is_trap_range_check_l(int x) {
738     return (is_tw (x, traptoLessThanUnsigned, -1/*any reg*/, -1/*any reg*/) ||
739             is_twi(x, traptoLessThanUnsigned, -1/*any reg*/)                  );
740   }
741   inline void trap_range_check_le(Register a, int si16);
742   static bool is_trap_range_check_le(int x) {
743     return is_twi(x, traptoEqual | traptoLessThanUnsigned, -1/*any reg*/);
744   }
745   inline void trap_range_check_g(Register a, int si16);
746   static bool is_trap_range_check_g(int x) {
747     return is_twi(x, traptoGreaterThanUnsigned, -1/*any reg*/);
748   }
</pre>
<hr />
<pre>
871   void sha256_update_sha_state(const VectorRegister a, const VectorRegister b,
872       const VectorRegister c, const VectorRegister d, const VectorRegister e,
873       const VectorRegister f, const VectorRegister g, const VectorRegister h,
874       const Register hptr);
875 
876   void sha512_load_w_vec(const Register buf_in, const VectorRegister* ws, const int total_ws);
877   void sha512_update_sha_state(const Register state, const VectorRegister* hs, const int total_hs);
878   void sha512_round(const VectorRegister* hs, const int total_hs, int&amp; h_cnt, const VectorRegister kpw);
879   void sha512_load_h_vec(const Register state, const VectorRegister* hs, const int total_hs);
880   void sha512_calc_2w(const VectorRegister w0, const VectorRegister w1,
881       const VectorRegister w2, const VectorRegister w3,
882       const VectorRegister w4, const VectorRegister w5,
883       const VectorRegister w6, const VectorRegister w7,
884       const VectorRegister kpw0, const VectorRegister kpw1, const Register j,
885       const VectorRegister vRb, const Register k);
886 
887  public:
888   void sha256(bool multi_block);
889   void sha512(bool multi_block);
890 
<span class="line-added">891   void cache_wb(Address line);</span>
<span class="line-added">892   void cache_wbsync(bool is_presync);</span>
893 
894   //
895   // Debugging
896   //
897 
898   // assert on cr0
899   void asm_assert(bool check_equal, const char* msg, int id);
900   void asm_assert_eq(const char* msg, int id) { asm_assert(true, msg, id); }
901   void asm_assert_ne(const char* msg, int id) { asm_assert(false, msg, id); }
902 
903  private:
904   void asm_assert_mems_zero(bool check_equal, int size, int mem_offset, Register mem_base,
905                             const char* msg, int id);
906 
907  public:
908 
909   void asm_assert_mem8_is_zero(int mem_offset, Register mem_base, const char* msg, int id) {
910     asm_assert_mems_zero(true,  8, mem_offset, mem_base, msg, id);
911   }
912   void asm_assert_mem8_isnot_zero(int mem_offset, Register mem_base, const char* msg, int id) {
913     asm_assert_mems_zero(false, 8, mem_offset, mem_base, msg, id);
914   }
915 
916   // Verify R16_thread contents.
917   void verify_thread();
918 
<span class="line-added">919   // Calls verify_oop. If UseCompressedOops is on, decodes the oop.</span>
<span class="line-added">920   // Preserves reg.</span>
<span class="line-added">921   void verify_coop(Register reg, const char*);</span>
922   // Emit code to verify that reg contains a valid oop if +VerifyOops is set.
923   void verify_oop(Register reg, const char* s = &quot;broken oop&quot;);
924   void verify_oop_addr(RegisterOrConstant offs, Register base, const char* s = &quot;contains broken oop&quot;);
925 
926   // TODO: verify method and klass metadata (compare against vptr?)
927   void _verify_method_ptr(Register reg, const char * msg, const char * file, int line) {}
928   void _verify_klass_ptr(Register reg, const char * msg, const char * file, int line) {}
929 
930   // Convenience method returning function entry. For the ELFv1 case
931   // creates function descriptor at the current address and returs
932   // the pointer to it. For the ELFv2 case returns the current address.
933   inline address function_entry();
934 
935 #define verify_method_ptr(reg) _verify_method_ptr(reg, &quot;broken method &quot; #reg, __FILE__, __LINE__)
936 #define verify_klass_ptr(reg) _verify_klass_ptr(reg, &quot;broken klass &quot; #reg, __FILE__, __LINE__)
937 
938  private:
939 
940   enum {
941     stop_stop                = 0,
</pre>
</td>
</tr>
</table>
<center><a href="macroAssembler_ppc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_ppc.inline.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>