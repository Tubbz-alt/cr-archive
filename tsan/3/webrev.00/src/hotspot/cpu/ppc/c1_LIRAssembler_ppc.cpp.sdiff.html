<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/ppc/c1_LIRAssembler_ppc.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_FrameMap_ppc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRGenerator_ppc.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/ppc/c1_LIRAssembler_ppc.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;c1/c1_Compilation.hpp&quot;
  29 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  30 #include &quot;c1/c1_MacroAssembler.hpp&quot;
  31 #include &quot;c1/c1_Runtime1.hpp&quot;
  32 #include &quot;c1/c1_ValueStack.hpp&quot;
  33 #include &quot;ci/ciArrayKlass.hpp&quot;
  34 #include &quot;ci/ciInstance.hpp&quot;
  35 #include &quot;gc/shared/collectedHeap.hpp&quot;
<span class="line-modified">  36 #include &quot;gc/shared/barrierSet.hpp&quot;</span>
<span class="line-removed">  37 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;</span>
  38 #include &quot;nativeInst_ppc.hpp&quot;

  39 #include &quot;oops/objArrayKlass.hpp&quot;
  40 #include &quot;runtime/frame.inline.hpp&quot;
  41 #include &quot;runtime/safepointMechanism.inline.hpp&quot;
  42 #include &quot;runtime/sharedRuntime.hpp&quot;

  43 
  44 #define __ _masm-&gt;
  45 
  46 
  47 const ConditionRegister LIR_Assembler::BOOL_RESULT = CCR5;
  48 
  49 
  50 bool LIR_Assembler::is_small_constant(LIR_Opr opr) {
  51   Unimplemented(); return false; // Currently not used on this platform.
  52 }
  53 
  54 
  55 LIR_Opr LIR_Assembler::receiverOpr() {
  56   return FrameMap::R3_oop_opr;
  57 }
  58 
  59 
  60 LIR_Opr LIR_Assembler::osrBufferPointer() {
  61   return FrameMap::R3_opr;
  62 }
  63 
  64 
  65 // This specifies the stack pointer decrement needed to build the frame.
  66 int LIR_Assembler::initial_frame_size_in_bytes() const {
  67   return in_bytes(frame_map()-&gt;framesize_in_bytes());
  68 }
  69 
  70 
  71 // Inline cache check: the inline cached class is in inline_cache_reg;
  72 // we fetch the class of the receiver and compare it with the cached class.
  73 // If they do not match we jump to slow case.
  74 int LIR_Assembler::check_icache() {
  75   int offset = __ offset();
  76   __ inline_cache_check(R3_ARG1, R19_inline_cache_reg);
  77   return offset;
  78 }
  79 















  80 
  81 void LIR_Assembler::osr_entry() {
  82   // On-stack-replacement entry sequence:
  83   //
  84   //   1. Create a new compiled activation.
  85   //   2. Initialize local variables in the compiled activation. The expression
  86   //      stack must be empty at the osr_bci; it is not initialized.
  87   //   3. Jump to the continuation address in compiled code to resume execution.
  88 
  89   // OSR entry point
  90   offsets()-&gt;set_value(CodeOffsets::OSR_Entry, code_offset());
  91   BlockBegin* osr_entry = compilation()-&gt;hir()-&gt;osr_entry();
  92   ValueStack* entry_state = osr_entry-&gt;end()-&gt;state();
  93   int number_of_locks = entry_state-&gt;locks_size();
  94 
  95   // Create a frame for the compiled activation.
  96   __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());
  97 
  98   // OSR buffer is
  99   //
</pre>
<hr />
<pre>
 709     assert(wide &amp;&amp; !from_reg-&gt;is_same_register(FrameMap::R0_opr), &quot;large offset only supported in special case&quot;);
 710     __ load_const_optimized(R0, offset);
 711     store_offset = store(from_reg, base, R0, type, wide);
 712   } else {
 713     store_offset = code_offset();
 714     switch (type) {
 715       case T_BOOLEAN: // fall through
 716       case T_BYTE  : __ stb(from_reg-&gt;as_register(), offset, base); break;
 717       case T_CHAR  :
 718       case T_SHORT : __ sth(from_reg-&gt;as_register(), offset, base); break;
 719       case T_INT   : __ stw(from_reg-&gt;as_register(), offset, base); break;
 720       case T_LONG  : __ std(from_reg-&gt;as_register_lo(), offset, base); break;
 721       case T_ADDRESS:
 722       case T_METADATA: __ std(from_reg-&gt;as_register(), offset, base); break;
 723       case T_ARRAY : // fall through
 724       case T_OBJECT:
 725         {
 726           if (UseCompressedOops &amp;&amp; !wide) {
 727             // Encoding done in caller
 728             __ stw(from_reg-&gt;as_register(), offset, base);

 729           } else {
 730             __ std(from_reg-&gt;as_register(), offset, base);

 731           }
<span class="line-removed"> 732           __ verify_oop(from_reg-&gt;as_register());</span>
 733           break;
 734         }
 735       case T_FLOAT : __ stfs(from_reg-&gt;as_float_reg(), offset, base); break;
 736       case T_DOUBLE: __ stfd(from_reg-&gt;as_double_reg(), offset, base); break;
 737       default      : ShouldNotReachHere();
 738     }
 739   }
 740   return store_offset;
 741 }
 742 
 743 
 744 // Attention: caller must encode oop if needed
 745 int LIR_Assembler::store(LIR_Opr from_reg, Register base, Register disp, BasicType type, bool wide) {
 746   int store_offset = code_offset();
 747   switch (type) {
 748     case T_BOOLEAN: // fall through
 749     case T_BYTE  : __ stbx(from_reg-&gt;as_register(), base, disp); break;
 750     case T_CHAR  :
 751     case T_SHORT : __ sthx(from_reg-&gt;as_register(), base, disp); break;
 752     case T_INT   : __ stwx(from_reg-&gt;as_register(), base, disp); break;
 753     case T_LONG  :
 754 #ifdef _LP64
 755       __ stdx(from_reg-&gt;as_register_lo(), base, disp);
 756 #else
 757       Unimplemented();
 758 #endif
 759       break;
 760     case T_ADDRESS:
 761       __ stdx(from_reg-&gt;as_register(), base, disp);
 762       break;
 763     case T_ARRAY : // fall through
 764     case T_OBJECT:
 765       {
 766         if (UseCompressedOops &amp;&amp; !wide) {
 767           // Encoding done in caller.
 768           __ stwx(from_reg-&gt;as_register(), base, disp);

 769         } else {
 770           __ stdx(from_reg-&gt;as_register(), base, disp);

 771         }
<span class="line-removed"> 772         __ verify_oop(from_reg-&gt;as_register()); // kills R0</span>
 773         break;
 774       }
 775     case T_FLOAT : __ stfsx(from_reg-&gt;as_float_reg(), base, disp); break;
 776     case T_DOUBLE: __ stfdx(from_reg-&gt;as_double_reg(), base, disp); break;
 777     default      : ShouldNotReachHere();
 778   }
 779   return store_offset;
 780 }
 781 
 782 
 783 int LIR_Assembler::load(Register base, int offset, LIR_Opr to_reg, BasicType type, bool wide, bool unaligned) {
 784   int load_offset;
 785   if (!Assembler::is_simm16(offset)) {
 786     // For offsets larger than a simm16 we setup the offset.
 787     __ load_const_optimized(R0, offset);
 788     load_offset = load(base, R0, to_reg, type, wide);
 789   } else {
 790     load_offset = code_offset();
 791     switch(type) {
 792       case T_BOOLEAN: // fall through
</pre>
<hr />
<pre>
 797       case T_INT   :   __ lwa(to_reg-&gt;as_register(), offset, base); break;
 798       case T_LONG  :   __ ld(to_reg-&gt;as_register_lo(), offset, base); break;
 799       case T_METADATA: __ ld(to_reg-&gt;as_register(), offset, base); break;
 800       case T_ADDRESS:
 801         if (offset == oopDesc::klass_offset_in_bytes() &amp;&amp; UseCompressedClassPointers) {
 802           __ lwz(to_reg-&gt;as_register(), offset, base);
 803           __ decode_klass_not_null(to_reg-&gt;as_register());
 804         } else {
 805           __ ld(to_reg-&gt;as_register(), offset, base);
 806         }
 807         break;
 808       case T_ARRAY : // fall through
 809       case T_OBJECT:
 810         {
 811           if (UseCompressedOops &amp;&amp; !wide) {
 812             __ lwz(to_reg-&gt;as_register(), offset, base);
 813             __ decode_heap_oop(to_reg-&gt;as_register());
 814           } else {
 815             __ ld(to_reg-&gt;as_register(), offset, base);
 816           }
<span class="line-modified"> 817           __ verify_oop(to_reg-&gt;as_register());</span>
 818           break;
 819         }
 820       case T_FLOAT:  __ lfs(to_reg-&gt;as_float_reg(), offset, base); break;
 821       case T_DOUBLE: __ lfd(to_reg-&gt;as_double_reg(), offset, base); break;
 822       default      : ShouldNotReachHere();
 823     }
 824   }
 825   return load_offset;
 826 }
 827 
 828 
 829 int LIR_Assembler::load(Register base, Register disp, LIR_Opr to_reg, BasicType type, bool wide) {
 830   int load_offset = code_offset();
 831   switch(type) {
 832     case T_BOOLEAN: // fall through
 833     case T_BYTE  :  __ lbzx(to_reg-&gt;as_register(), base, disp);
 834                     __ extsb(to_reg-&gt;as_register(), to_reg-&gt;as_register()); break;
 835     case T_CHAR  :  __ lhzx(to_reg-&gt;as_register(), base, disp); break;
 836     case T_SHORT :  __ lhax(to_reg-&gt;as_register(), base, disp); break;
 837     case T_INT   :  __ lwax(to_reg-&gt;as_register(), base, disp); break;
 838     case T_ADDRESS: __ ldx(to_reg-&gt;as_register(), base, disp); break;
 839     case T_ARRAY : // fall through
 840     case T_OBJECT:
 841       {
 842         if (UseCompressedOops &amp;&amp; !wide) {
 843           __ lwzx(to_reg-&gt;as_register(), base, disp);
 844           __ decode_heap_oop(to_reg-&gt;as_register());
 845         } else {
 846           __ ldx(to_reg-&gt;as_register(), base, disp);
 847         }
<span class="line-modified"> 848         __ verify_oop(to_reg-&gt;as_register());</span>
 849         break;
 850       }
 851     case T_FLOAT:  __ lfsx(to_reg-&gt;as_float_reg() , base, disp); break;
 852     case T_DOUBLE: __ lfdx(to_reg-&gt;as_double_reg(), base, disp); break;
 853     case T_LONG  :
 854 #ifdef _LP64
 855       __ ldx(to_reg-&gt;as_register_lo(), base, disp);
 856 #else
 857       Unimplemented();
 858 #endif
 859       break;
 860     default      : ShouldNotReachHere();
 861   }
 862   return load_offset;
 863 }
 864 
 865 
 866 void LIR_Assembler::const2stack(LIR_Opr src, LIR_Opr dest) {
 867   LIR_Const* c = src-&gt;as_constant_ptr();
 868   Register src_reg = R0;
</pre>
<hr />
<pre>
1107 
1108 void LIR_Assembler::mem2reg(LIR_Opr src_opr, LIR_Opr dest, BasicType type,
1109                             LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool unaligned) {
1110 
1111   assert(type != T_METADATA, &quot;load of metadata ptr not supported&quot;);
1112   LIR_Address* addr = src_opr-&gt;as_address_ptr();
1113   LIR_Opr to_reg = dest;
1114 
1115   Register src = addr-&gt;base()-&gt;as_pointer_register();
1116   Register disp_reg = noreg;
1117   int disp_value = addr-&gt;disp();
1118   bool needs_patching = (patch_code != lir_patch_none);
1119   // null check for large offsets in LIRGenerator::do_LoadField
1120   bool needs_explicit_null_check = !os::zero_page_read_protected() || !ImplicitNullChecks;
1121 
1122   if (info != NULL &amp;&amp; needs_explicit_null_check) {
1123     explicit_null_check(src, info);
1124   }
1125 
1126   if (addr-&gt;base()-&gt;type() == T_OBJECT) {
<span class="line-modified">1127     __ verify_oop(src);</span>
1128   }
1129 
1130   PatchingStub* patch = NULL;
1131   if (needs_patching) {
1132     patch = new PatchingStub(_masm, PatchingStub::access_field_id);
1133     assert(!to_reg-&gt;is_double_cpu() ||
1134            patch_code == lir_patch_none ||
1135            patch_code == lir_patch_normal, &quot;patching doesn&#39;t match register&quot;);
1136   }
1137 
1138   if (addr-&gt;index()-&gt;is_illegal()) {
1139     if (!Assembler::is_simm16(disp_value)) {
1140       if (needs_patching) {
1141         __ load_const32(R0, 0); // patchable int
1142       } else {
1143         __ load_const_optimized(R0, disp_value);
1144       }
1145       disp_reg = R0;
1146     }
1147   } else {
</pre>
<hr />
<pre>
1203       assert(to_reg-&gt;is_double_fpu(), &quot;should match&quot;);
1204       __ fmr_if_needed(to_reg-&gt;as_double_reg(), from_reg-&gt;as_double_reg());
1205     } else {
1206       // float to float moves
1207       assert(to_reg-&gt;is_single_fpu(), &quot;should match&quot;);
1208       __ fmr_if_needed(to_reg-&gt;as_float_reg(), from_reg-&gt;as_float_reg());
1209     }
1210   } else if (!from_reg-&gt;is_float_kind() &amp;&amp; !to_reg-&gt;is_float_kind()) {
1211     if (from_reg-&gt;is_double_cpu()) {
1212       __ mr_if_needed(to_reg-&gt;as_pointer_register(), from_reg-&gt;as_pointer_register());
1213     } else if (to_reg-&gt;is_double_cpu()) {
1214       // int to int moves
1215       __ mr_if_needed(to_reg-&gt;as_register_lo(), from_reg-&gt;as_register());
1216     } else {
1217       // int to int moves
1218       __ mr_if_needed(to_reg-&gt;as_register(), from_reg-&gt;as_register());
1219     }
1220   } else {
1221     ShouldNotReachHere();
1222   }
<span class="line-modified">1223   if (to_reg-&gt;type() == T_OBJECT || to_reg-&gt;type() == T_ARRAY) {</span>
<span class="line-modified">1224     __ verify_oop(to_reg-&gt;as_register());</span>
1225   }
1226 }
1227 
1228 
1229 void LIR_Assembler::reg2mem(LIR_Opr from_reg, LIR_Opr dest, BasicType type,
1230                             LIR_PatchCode patch_code, CodeEmitInfo* info, bool pop_fpu_stack,
1231                             bool wide, bool unaligned) {
1232   assert(type != T_METADATA, &quot;store of metadata ptr not supported&quot;);
1233   LIR_Address* addr = dest-&gt;as_address_ptr();
1234 
1235   Register src = addr-&gt;base()-&gt;as_pointer_register();
1236   Register disp_reg = noreg;
1237   int disp_value = addr-&gt;disp();
1238   bool needs_patching = (patch_code != lir_patch_none);
<span class="line-modified">1239   bool compress_oop = (type == T_ARRAY || type == T_OBJECT) &amp;&amp; UseCompressedOops &amp;&amp; !wide &amp;&amp;</span>
<span class="line-modified">1240                       Universe::narrow_oop_mode() != Universe::UnscaledNarrowOop;</span>
1241   bool load_disp = addr-&gt;index()-&gt;is_illegal() &amp;&amp; !Assembler::is_simm16(disp_value);
1242   bool use_R29 = compress_oop &amp;&amp; load_disp; // Avoid register conflict, also do null check before killing R29.
1243   // Null check for large offsets in LIRGenerator::do_StoreField.
1244   bool needs_explicit_null_check = !ImplicitNullChecks || use_R29;
1245 
1246   if (info != NULL &amp;&amp; needs_explicit_null_check) {
1247     explicit_null_check(src, info);
1248   }
1249 
1250   if (addr-&gt;base()-&gt;is_oop_register()) {
<span class="line-modified">1251     __ verify_oop(src);</span>
1252   }
1253 
1254   PatchingStub* patch = NULL;
1255   if (needs_patching) {
1256     patch = new PatchingStub(_masm, PatchingStub::access_field_id);
1257     assert(!from_reg-&gt;is_double_cpu() ||
1258            patch_code == lir_patch_none ||
1259            patch_code == lir_patch_normal, &quot;patching doesn&#39;t match register&quot;);
1260   }
1261 
1262   if (addr-&gt;index()-&gt;is_illegal()) {
1263     if (load_disp) {
1264       disp_reg = use_R29 ? R29_TOC : R0;
1265       if (needs_patching) {
1266         __ load_const32(disp_reg, 0); // patchable int
1267       } else {
1268         __ load_const_optimized(disp_reg, disp_value);
1269       }
1270     }
1271   } else {
</pre>
<hr />
<pre>
1433                 __ cmpw(BOOL_RESULT, opr1-&gt;as_register(), R0);
1434               }
1435             }
1436           }
1437           break;
1438 
1439         case T_OBJECT:
1440           // There are only equal/notequal comparisons on objects.
1441           {
1442             assert(condition == lir_cond_equal || condition == lir_cond_notEqual, &quot;oops&quot;);
1443             jobject con = opr2-&gt;as_constant_ptr()-&gt;as_jobject();
1444             if (con == NULL) {
1445               __ cmpdi(BOOL_RESULT, opr1-&gt;as_register(), 0);
1446             } else {
1447               jobject2reg(con, R0);
1448               __ cmpd(BOOL_RESULT, opr1-&gt;as_register(), R0);
1449             }
1450           }
1451           break;
1452 













1453         default:
1454           ShouldNotReachHere();
1455           break;
1456       }
1457     } else {
<span class="line-modified">1458       if (opr2-&gt;is_address()) {</span>
<span class="line-modified">1459         DEBUG_ONLY( Unimplemented(); ) // Seems to be unused at the moment.</span>
<span class="line-modified">1460         LIR_Address *addr = opr2-&gt;as_address_ptr();</span>
<span class="line-modified">1461         BasicType type = addr-&gt;type();</span>
<span class="line-modified">1462         if (type == T_OBJECT) { __ ld(R0, index_or_disp(addr), addr-&gt;base()-&gt;as_register()); }</span>
<span class="line-removed">1463         else                  { __ lwa(R0, index_or_disp(addr), addr-&gt;base()-&gt;as_register()); }</span>
<span class="line-removed">1464         __ cmpd(BOOL_RESULT, opr1-&gt;as_register(), R0);</span>
1465       } else {
1466         if (unsigned_comp) {
1467           __ cmplw(BOOL_RESULT, opr1-&gt;as_register(), opr2-&gt;as_register());
1468         } else {
1469           __ cmpw(BOOL_RESULT, opr1-&gt;as_register(), opr2-&gt;as_register());
1470         }
1471       }
1472     }
1473   } else if (opr1-&gt;is_double_cpu()) {
1474     if (opr2-&gt;is_constant()) {
1475       jlong con = opr2-&gt;as_constant_ptr()-&gt;as_jlong();
1476       if (unsigned_comp) {
1477         if (Assembler::is_uimm(con, 16)) {
1478           __ cmpldi(BOOL_RESULT, opr1-&gt;as_register_lo(), con);
1479         } else {
1480           __ load_const_optimized(R0, con);
1481           __ cmpld(BOOL_RESULT, opr1-&gt;as_register_lo(), R0);
1482         }
1483       } else {
1484         if (Assembler::is_simm(con, 16)) {
1485           __ cmpdi(BOOL_RESULT, opr1-&gt;as_register_lo(), con);
1486         } else {
1487           __ load_const_optimized(R0, con);
1488           __ cmpd(BOOL_RESULT, opr1-&gt;as_register_lo(), R0);
1489         }
1490       }
1491     } else if (opr2-&gt;is_register()) {
1492       if (unsigned_comp) {
1493         __ cmpld(BOOL_RESULT, opr1-&gt;as_register_lo(), opr2-&gt;as_register_lo());
1494       } else {
1495         __ cmpd(BOOL_RESULT, opr1-&gt;as_register_lo(), opr2-&gt;as_register_lo());
1496       }
1497     } else {
1498       ShouldNotReachHere();
1499     }
<span class="line-removed">1500   } else if (opr1-&gt;is_address()) {</span>
<span class="line-removed">1501     DEBUG_ONLY( Unimplemented(); ) // Seems to be unused at the moment.</span>
<span class="line-removed">1502     LIR_Address * addr = opr1-&gt;as_address_ptr();</span>
<span class="line-removed">1503     BasicType type = addr-&gt;type();</span>
<span class="line-removed">1504     assert (opr2-&gt;is_constant(), &quot;Checking&quot;);</span>
<span class="line-removed">1505     if (type == T_OBJECT) { __ ld(R0, index_or_disp(addr), addr-&gt;base()-&gt;as_register()); }</span>
<span class="line-removed">1506     else                  { __ lwa(R0, index_or_disp(addr), addr-&gt;base()-&gt;as_register()); }</span>
<span class="line-removed">1507     __ cmpdi(BOOL_RESULT, R0, opr2-&gt;as_constant_ptr()-&gt;as_jint());</span>
1508   } else {
1509     ShouldNotReachHere();
1510   }
1511 }
1512 
1513 
1514 void LIR_Assembler::comp_fl2i(LIR_Code code, LIR_Opr left, LIR_Opr right, LIR_Opr dst, LIR_Op2* op){
1515   const Register Rdst = dst-&gt;as_register();
1516   Label done;
1517   if (code == lir_cmp_fd2i || code == lir_ucmp_fd2i) {
1518     bool is_unordered_less = (code == lir_ucmp_fd2i);
1519     if (left-&gt;is_single_fpu()) {
1520       __ fcmpu(CCR0, left-&gt;as_float_reg(), right-&gt;as_float_reg());
1521     } else if (left-&gt;is_double_fpu()) {
1522       __ fcmpu(CCR0, left-&gt;as_double_reg(), right-&gt;as_double_reg());
1523     } else {
1524       ShouldNotReachHere();
1525     }
1526     __ li(Rdst, is_unordered_less ? -1 : 1);
1527     __ bso(CCR0, done);
</pre>
<hr />
<pre>
1689     } else {
1690       Register lreg = left-&gt;as_pointer_register();
1691       Register res  = dest-&gt;as_register_lo();
1692       long con = right-&gt;as_constant_ptr()-&gt;as_jlong();
1693       assert(Assembler::is_simm16(con), &quot;must be simm16&quot;);
1694 
1695       switch (code) {
1696         case lir_sub:  assert(Assembler::is_simm16(-con), &quot;cannot encode&quot;);  // see do_ArithmeticOp_Long
1697                        con = -con;
1698         case lir_add:  if (res == lreg &amp;&amp; con == 0) break;
1699                        __ addi(res, lreg, (int)con); break;
1700         case lir_mul:  if (res == lreg &amp;&amp; con == 1) break;
1701                        __ mulli(res, lreg, (int)con); break;
1702         default: ShouldNotReachHere();
1703       }
1704     }
1705   }
1706 }
1707 
1708 
<span class="line-removed">1709 void LIR_Assembler::fpop() {</span>
<span class="line-removed">1710   Unimplemented();</span>
<span class="line-removed">1711   // do nothing</span>
<span class="line-removed">1712 }</span>
<span class="line-removed">1713 </span>
<span class="line-removed">1714 </span>
1715 void LIR_Assembler::intrinsic_op(LIR_Code code, LIR_Opr value, LIR_Opr thread, LIR_Opr dest, LIR_Op* op) {
1716   switch (code) {
1717     case lir_sqrt: {
1718       __ fsqrt(dest-&gt;as_double_reg(), value-&gt;as_double_reg());
1719       break;
1720     }
1721     case lir_abs: {
1722       __ fabs(dest-&gt;as_double_reg(), value-&gt;as_double_reg());
1723       break;
1724     }
1725     default: {
1726       ShouldNotReachHere();
1727       break;
1728     }
1729   }
1730 }
1731 
1732 
1733 void LIR_Assembler::logic_op(LIR_Code code, LIR_Opr left, LIR_Opr right, LIR_Opr dest) {
1734   if (right-&gt;is_constant()) { // see do_LogicOp
1735     long uimm;
1736     Register d, l;
1737     if (dest-&gt;is_single_cpu()) {
1738       uimm = right-&gt;as_constant_ptr()-&gt;as_jint();
1739       d = dest-&gt;as_register();
1740       l = left-&gt;as_register();
1741     } else {
1742       uimm = right-&gt;as_constant_ptr()-&gt;as_jlong();
1743       d = dest-&gt;as_register_lo();
1744       l = left-&gt;as_register_lo();
1745     }
1746     long uimms  = (unsigned long)uimm &gt;&gt; 16,
1747          uimmss = (unsigned long)uimm &gt;&gt; 32;
1748 
1749     switch (code) {
1750       case lir_logic_and:
<span class="line-modified">1751         if (uimmss != 0 || (uimms != 0 &amp;&amp; (uimm &amp; 0xFFFF) != 0) || is_power_of_2_long(uimm)) {</span>
1752           __ andi(d, l, uimm); // special cases
1753         } else if (uimms != 0) { __ andis_(d, l, uimms); }
1754         else { __ andi_(d, l, uimm); }
1755         break;
1756 
1757       case lir_logic_or:
1758         if (uimms != 0) { assert((uimm &amp; 0xFFFF) == 0, &quot;sanity&quot;); __ oris(d, l, uimms); }
1759         else { __ ori(d, l, uimm); }
1760         break;
1761 
1762       case lir_logic_xor:
1763         if (uimm == -1) { __ nand(d, l, l); } // special case
1764         else if (uimms != 0) { assert((uimm &amp; 0xFFFF) == 0, &quot;sanity&quot;); __ xoris(d, l, uimms); }
1765         else { __ xori(d, l, uimm); }
1766         break;
1767 
1768       default: ShouldNotReachHere();
1769     }
1770   } else {
1771     assert(right-&gt;is_register(), &quot;right should be in register&quot;);
</pre>
<hr />
<pre>
2284     if (!os::zero_page_read_protected() || !ImplicitNullChecks) {
2285       explicit_null_check(op-&gt;klass()-&gt;as_register(), op-&gt;stub()-&gt;info());
2286     } else {
2287       add_debug_info_for_null_check_here(op-&gt;stub()-&gt;info());
2288     }
2289     __ lbz(op-&gt;tmp1()-&gt;as_register(),
2290            in_bytes(InstanceKlass::init_state_offset()), op-&gt;klass()-&gt;as_register());
2291     __ cmpwi(CCR0, op-&gt;tmp1()-&gt;as_register(), InstanceKlass::fully_initialized);
2292     __ bc_far_optimized(Assembler::bcondCRbiIs0, __ bi0(CCR0, Assembler::equal), *op-&gt;stub()-&gt;entry());
2293   }
2294   __ allocate_object(op-&gt;obj()-&gt;as_register(),
2295                      op-&gt;tmp1()-&gt;as_register(),
2296                      op-&gt;tmp2()-&gt;as_register(),
2297                      op-&gt;tmp3()-&gt;as_register(),
2298                      op-&gt;header_size(),
2299                      op-&gt;object_size(),
2300                      op-&gt;klass()-&gt;as_register(),
2301                      *op-&gt;stub()-&gt;entry());
2302 
2303   __ bind(*op-&gt;stub()-&gt;continuation());
<span class="line-modified">2304   __ verify_oop(op-&gt;obj()-&gt;as_register());</span>
2305 }
2306 
2307 
2308 void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
2309   LP64_ONLY( __ extsw(op-&gt;len()-&gt;as_register(), op-&gt;len()-&gt;as_register()); )
2310   if (UseSlowPath ||
<span class="line-modified">2311       (!UseFastNewObjectArray &amp;&amp; (op-&gt;type() == T_OBJECT || op-&gt;type() == T_ARRAY)) ||</span>
<span class="line-modified">2312       (!UseFastNewTypeArray   &amp;&amp; (op-&gt;type() != T_OBJECT &amp;&amp; op-&gt;type() != T_ARRAY))) {</span>
2313     __ b(*op-&gt;stub()-&gt;entry());
2314   } else {
2315     __ allocate_array(op-&gt;obj()-&gt;as_register(),
2316                       op-&gt;len()-&gt;as_register(),
2317                       op-&gt;tmp1()-&gt;as_register(),
2318                       op-&gt;tmp2()-&gt;as_register(),
2319                       op-&gt;tmp3()-&gt;as_register(),
2320                       arrayOopDesc::header_size(op-&gt;type()),
2321                       type2aelembytes(op-&gt;type()),
2322                       op-&gt;klass()-&gt;as_register(),
2323                       *op-&gt;stub()-&gt;entry());
2324   }
2325   __ bind(*op-&gt;stub()-&gt;continuation());
2326 }
2327 
2328 
2329 void LIR_Assembler::type_profile_helper(Register mdo, int mdo_offset_bias,
2330                                         ciMethodData *md, ciProfileData *data,
2331                                         Register recv, Register tmp1, Label* update_done) {
2332   uint i;
</pre>
<hr />
<pre>
2509     __ add_const_optimized(mdo, mdo, mdo_offset_bias, R0);
2510     __ ld(Rtmp1, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()) - mdo_offset_bias, mdo);
2511     __ addi(Rtmp1, Rtmp1, -DataLayout::counter_increment);
2512     __ std(Rtmp1, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()) - mdo_offset_bias, mdo);
2513   }
2514 
2515   __ bind(*failure);
2516 }
2517 
2518 
2519 void LIR_Assembler::emit_opTypeCheck(LIR_OpTypeCheck* op) {
2520   LIR_Code code = op-&gt;code();
2521   if (code == lir_store_check) {
2522     Register value = op-&gt;object()-&gt;as_register();
2523     Register array = op-&gt;array()-&gt;as_register();
2524     Register k_RInfo = op-&gt;tmp1()-&gt;as_register();
2525     Register klass_RInfo = op-&gt;tmp2()-&gt;as_register();
2526     Register Rtmp1 = op-&gt;tmp3()-&gt;as_register();
2527     bool should_profile = op-&gt;should_profile();
2528 
<span class="line-modified">2529     __ verify_oop(value);</span>
2530     CodeStub* stub = op-&gt;stub();
2531     // Check if it needs to be profiled.
2532     ciMethodData* md = NULL;
2533     ciProfileData* data = NULL;
2534     int mdo_offset_bias = 0;
2535     if (should_profile) {
2536       ciMethod* method = op-&gt;profiled_method();
2537       assert(method != NULL, &quot;Should have method&quot;);
2538       setup_md_access(method, op-&gt;profiled_bci(), md, data, mdo_offset_bias);
2539     }
2540     Label profile_cast_success, failure, done;
2541     Label *success_target = should_profile ? &amp;profile_cast_success : &amp;done;
2542 
2543     __ cmpdi(CCR0, value, 0);
2544     if (should_profile) {
2545       Label not_null;
2546       __ bne(CCR0, not_null);
2547       Register mdo      = k_RInfo;
2548       Register data_val = Rtmp1;
2549       metadata2reg(md-&gt;constant_encoding(), mdo);
</pre>
<hr />
<pre>
2654 
2655   if (is_64bit) {
2656     __ cmpxchgd(BOOL_RESULT, /*current_value=*/R0, cmp_value, new_value, addr,
2657                 MacroAssembler::MemBarNone,
2658                 MacroAssembler::cmpxchgx_hint_atomic_update(),
2659                 noreg, NULL, /*check without ldarx first*/true);
2660   } else {
2661     __ cmpxchgw(BOOL_RESULT, /*current_value=*/R0, cmp_value, new_value, addr,
2662                 MacroAssembler::MemBarNone,
2663                 MacroAssembler::cmpxchgx_hint_atomic_update(),
2664                 noreg, /*check without ldarx first*/true);
2665   }
2666 
2667   if (support_IRIW_for_not_multiple_copy_atomic_cpu) {
2668     __ isync();
2669   } else {
2670     __ sync();
2671   }
2672 }
2673 
<span class="line-removed">2674 </span>
<span class="line-removed">2675 void LIR_Assembler::set_24bit_FPU() {</span>
<span class="line-removed">2676   Unimplemented();</span>
<span class="line-removed">2677 }</span>
<span class="line-removed">2678 </span>
<span class="line-removed">2679 void LIR_Assembler::reset_FPU() {</span>
<span class="line-removed">2680   Unimplemented();</span>
<span class="line-removed">2681 }</span>
<span class="line-removed">2682 </span>
<span class="line-removed">2683 </span>
2684 void LIR_Assembler::breakpoint() {
2685   __ illtrap();
2686 }
2687 
2688 
2689 void LIR_Assembler::push(LIR_Opr opr) {
2690   Unimplemented();
2691 }
2692 
2693 void LIR_Assembler::pop(LIR_Opr opr) {
2694   Unimplemented();
2695 }
2696 
2697 
2698 void LIR_Assembler::monitor_address(int monitor_no, LIR_Opr dst_opr) {
2699   Address mon_addr = frame_map()-&gt;address_for_monitor_lock(monitor_no);
2700   Register dst = dst_opr-&gt;as_register();
2701   Register reg = mon_addr.base();
2702   int offset = mon_addr.disp();
2703   // Compute pointer to BasicLock.
</pre>
<hr />
<pre>
2857 
2858 
2859 void LIR_Assembler::negate(LIR_Opr left, LIR_Opr dest, LIR_Opr tmp) {
2860   // tmp must be unused
2861   assert(tmp-&gt;is_illegal(), &quot;wasting a register if tmp is allocated&quot;);
2862   assert(left-&gt;is_register(), &quot;can only handle registers&quot;);
2863 
2864   if (left-&gt;is_single_cpu()) {
2865     __ neg(dest-&gt;as_register(), left-&gt;as_register());
2866   } else if (left-&gt;is_single_fpu()) {
2867     __ fneg(dest-&gt;as_float_reg(), left-&gt;as_float_reg());
2868   } else if (left-&gt;is_double_fpu()) {
2869     __ fneg(dest-&gt;as_double_reg(), left-&gt;as_double_reg());
2870   } else {
2871     assert (left-&gt;is_double_cpu(), &quot;Must be a long&quot;);
2872     __ neg(dest-&gt;as_register_lo(), left-&gt;as_register_lo());
2873   }
2874 }
2875 
2876 
<span class="line-removed">2877 void LIR_Assembler::fxch(int i) {</span>
<span class="line-removed">2878   Unimplemented();</span>
<span class="line-removed">2879 }</span>
<span class="line-removed">2880 </span>
<span class="line-removed">2881 void LIR_Assembler::fld(int i) {</span>
<span class="line-removed">2882   Unimplemented();</span>
<span class="line-removed">2883 }</span>
<span class="line-removed">2884 </span>
<span class="line-removed">2885 void LIR_Assembler::ffree(int i) {</span>
<span class="line-removed">2886   Unimplemented();</span>
<span class="line-removed">2887 }</span>
<span class="line-removed">2888 </span>
<span class="line-removed">2889 </span>
2890 void LIR_Assembler::rt_call(LIR_Opr result, address dest,
2891                             const LIR_OprList* args, LIR_Opr tmp, CodeEmitInfo* info) {
2892   // Stubs: Called via rt_call, but dest is a stub address (no function descriptor).
2893   if (dest == Runtime1::entry_for(Runtime1::register_finalizer_id) ||
2894       dest == Runtime1::entry_for(Runtime1::new_multi_array_id   )) {
2895     //__ load_const_optimized(R0, dest);
2896     __ add_const_optimized(R0, R29_TOC, MacroAssembler::offset_to_global_toc(dest));
2897     __ mtctr(R0);
2898     __ bctrl();
2899     assert(info != NULL, &quot;sanity&quot;);
2900     add_call_info_here(info);
2901     return;
2902   }
2903 
2904   __ call_c_with_frame_resize(dest, /*no resizing*/ 0);
2905   if (info != NULL) {
2906     add_call_info_here(info);
2907   }
2908 }
2909 
</pre>
<hr />
<pre>
3062 
3063 
3064 void LIR_Assembler::emit_profile_type(LIR_OpProfileType* op) {
3065   Register obj = op-&gt;obj()-&gt;as_register();
3066   Register tmp = op-&gt;tmp()-&gt;as_pointer_register();
3067   LIR_Address* mdo_addr = op-&gt;mdp()-&gt;as_address_ptr();
3068   ciKlass* exact_klass = op-&gt;exact_klass();
3069   intptr_t current_klass = op-&gt;current_klass();
3070   bool not_null = op-&gt;not_null();
3071   bool no_conflict = op-&gt;no_conflict();
3072 
3073   Label Lupdate, Ldo_update, Ldone;
3074 
3075   bool do_null = !not_null;
3076   bool exact_klass_set = exact_klass != NULL &amp;&amp; ciTypeEntries::valid_ciklass(current_klass) == exact_klass;
3077   bool do_update = !TypeEntries::is_type_unknown(current_klass) &amp;&amp; !exact_klass_set;
3078 
3079   assert(do_null || do_update, &quot;why are we here?&quot;);
3080   assert(!TypeEntries::was_null_seen(current_klass) || do_update, &quot;why are we here?&quot;);
3081 
<span class="line-modified">3082   __ verify_oop(obj);</span>
3083 
3084   if (do_null) {
3085     if (!TypeEntries::was_null_seen(current_klass)) {
3086       __ cmpdi(CCR0, obj, 0);
3087       __ bne(CCR0, Lupdate);
3088       __ ld(R0, index_or_disp(mdo_addr), mdo_addr-&gt;base()-&gt;as_pointer_register());
3089       __ ori(R0, R0, TypeEntries::null_seen);
3090       if (do_update) {
3091         __ b(Ldo_update);
3092       } else {
3093         __ std(R0, index_or_disp(mdo_addr), mdo_addr-&gt;base()-&gt;as_pointer_register());
3094       }
3095     } else {
3096       if (do_update) {
3097         __ cmpdi(CCR0, obj, 0);
3098         __ beq(CCR0, Ldone);
3099       }
3100     }
3101 #ifdef ASSERT
3102   } else {
</pre>
</td>
<td>
<hr />
<pre>
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;c1/c1_Compilation.hpp&quot;
  29 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  30 #include &quot;c1/c1_MacroAssembler.hpp&quot;
  31 #include &quot;c1/c1_Runtime1.hpp&quot;
  32 #include &quot;c1/c1_ValueStack.hpp&quot;
  33 #include &quot;ci/ciArrayKlass.hpp&quot;
  34 #include &quot;ci/ciInstance.hpp&quot;
  35 #include &quot;gc/shared/collectedHeap.hpp&quot;
<span class="line-modified">  36 #include &quot;memory/universe.hpp&quot;</span>

  37 #include &quot;nativeInst_ppc.hpp&quot;
<span class="line-added">  38 #include &quot;oops/compressedOops.hpp&quot;</span>
  39 #include &quot;oops/objArrayKlass.hpp&quot;
  40 #include &quot;runtime/frame.inline.hpp&quot;
  41 #include &quot;runtime/safepointMechanism.inline.hpp&quot;
  42 #include &quot;runtime/sharedRuntime.hpp&quot;
<span class="line-added">  43 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  44 
  45 #define __ _masm-&gt;
  46 
  47 
  48 const ConditionRegister LIR_Assembler::BOOL_RESULT = CCR5;
  49 
  50 
  51 bool LIR_Assembler::is_small_constant(LIR_Opr opr) {
  52   Unimplemented(); return false; // Currently not used on this platform.
  53 }
  54 
  55 
  56 LIR_Opr LIR_Assembler::receiverOpr() {
  57   return FrameMap::R3_oop_opr;
  58 }
  59 
  60 
  61 LIR_Opr LIR_Assembler::osrBufferPointer() {
  62   return FrameMap::R3_opr;
  63 }
  64 
  65 
  66 // This specifies the stack pointer decrement needed to build the frame.
  67 int LIR_Assembler::initial_frame_size_in_bytes() const {
  68   return in_bytes(frame_map()-&gt;framesize_in_bytes());
  69 }
  70 
  71 
  72 // Inline cache check: the inline cached class is in inline_cache_reg;
  73 // we fetch the class of the receiver and compare it with the cached class.
  74 // If they do not match we jump to slow case.
  75 int LIR_Assembler::check_icache() {
  76   int offset = __ offset();
  77   __ inline_cache_check(R3_ARG1, R19_inline_cache_reg);
  78   return offset;
  79 }
  80 
<span class="line-added">  81 void LIR_Assembler::clinit_barrier(ciMethod* method) {</span>
<span class="line-added">  82   assert(!method-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);</span>
<span class="line-added">  83 </span>
<span class="line-added">  84   Label L_skip_barrier;</span>
<span class="line-added">  85   Register klass = R20;</span>
<span class="line-added">  86 </span>
<span class="line-added">  87   metadata2reg(method-&gt;holder()-&gt;constant_encoding(), klass);</span>
<span class="line-added">  88   __ clinit_barrier(klass, R16_thread, &amp;L_skip_barrier /*L_fast_path*/);</span>
<span class="line-added">  89 </span>
<span class="line-added">  90   __ load_const_optimized(klass, SharedRuntime::get_handle_wrong_method_stub(), R0);</span>
<span class="line-added">  91   __ mtctr(klass);</span>
<span class="line-added">  92   __ bctr();</span>
<span class="line-added">  93 </span>
<span class="line-added">  94   __ bind(L_skip_barrier);</span>
<span class="line-added">  95 }</span>
  96 
  97 void LIR_Assembler::osr_entry() {
  98   // On-stack-replacement entry sequence:
  99   //
 100   //   1. Create a new compiled activation.
 101   //   2. Initialize local variables in the compiled activation. The expression
 102   //      stack must be empty at the osr_bci; it is not initialized.
 103   //   3. Jump to the continuation address in compiled code to resume execution.
 104 
 105   // OSR entry point
 106   offsets()-&gt;set_value(CodeOffsets::OSR_Entry, code_offset());
 107   BlockBegin* osr_entry = compilation()-&gt;hir()-&gt;osr_entry();
 108   ValueStack* entry_state = osr_entry-&gt;end()-&gt;state();
 109   int number_of_locks = entry_state-&gt;locks_size();
 110 
 111   // Create a frame for the compiled activation.
 112   __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());
 113 
 114   // OSR buffer is
 115   //
</pre>
<hr />
<pre>
 725     assert(wide &amp;&amp; !from_reg-&gt;is_same_register(FrameMap::R0_opr), &quot;large offset only supported in special case&quot;);
 726     __ load_const_optimized(R0, offset);
 727     store_offset = store(from_reg, base, R0, type, wide);
 728   } else {
 729     store_offset = code_offset();
 730     switch (type) {
 731       case T_BOOLEAN: // fall through
 732       case T_BYTE  : __ stb(from_reg-&gt;as_register(), offset, base); break;
 733       case T_CHAR  :
 734       case T_SHORT : __ sth(from_reg-&gt;as_register(), offset, base); break;
 735       case T_INT   : __ stw(from_reg-&gt;as_register(), offset, base); break;
 736       case T_LONG  : __ std(from_reg-&gt;as_register_lo(), offset, base); break;
 737       case T_ADDRESS:
 738       case T_METADATA: __ std(from_reg-&gt;as_register(), offset, base); break;
 739       case T_ARRAY : // fall through
 740       case T_OBJECT:
 741         {
 742           if (UseCompressedOops &amp;&amp; !wide) {
 743             // Encoding done in caller
 744             __ stw(from_reg-&gt;as_register(), offset, base);
<span class="line-added"> 745             __ verify_coop(from_reg-&gt;as_register(), FILE_AND_LINE);</span>
 746           } else {
 747             __ std(from_reg-&gt;as_register(), offset, base);
<span class="line-added"> 748             __ verify_oop(from_reg-&gt;as_register(), FILE_AND_LINE);</span>
 749           }

 750           break;
 751         }
 752       case T_FLOAT : __ stfs(from_reg-&gt;as_float_reg(), offset, base); break;
 753       case T_DOUBLE: __ stfd(from_reg-&gt;as_double_reg(), offset, base); break;
 754       default      : ShouldNotReachHere();
 755     }
 756   }
 757   return store_offset;
 758 }
 759 
 760 
 761 // Attention: caller must encode oop if needed
 762 int LIR_Assembler::store(LIR_Opr from_reg, Register base, Register disp, BasicType type, bool wide) {
 763   int store_offset = code_offset();
 764   switch (type) {
 765     case T_BOOLEAN: // fall through
 766     case T_BYTE  : __ stbx(from_reg-&gt;as_register(), base, disp); break;
 767     case T_CHAR  :
 768     case T_SHORT : __ sthx(from_reg-&gt;as_register(), base, disp); break;
 769     case T_INT   : __ stwx(from_reg-&gt;as_register(), base, disp); break;
 770     case T_LONG  :
 771 #ifdef _LP64
 772       __ stdx(from_reg-&gt;as_register_lo(), base, disp);
 773 #else
 774       Unimplemented();
 775 #endif
 776       break;
 777     case T_ADDRESS:
 778       __ stdx(from_reg-&gt;as_register(), base, disp);
 779       break;
 780     case T_ARRAY : // fall through
 781     case T_OBJECT:
 782       {
 783         if (UseCompressedOops &amp;&amp; !wide) {
 784           // Encoding done in caller.
 785           __ stwx(from_reg-&gt;as_register(), base, disp);
<span class="line-added"> 786           __ verify_coop(from_reg-&gt;as_register(), FILE_AND_LINE); // kills R0</span>
 787         } else {
 788           __ stdx(from_reg-&gt;as_register(), base, disp);
<span class="line-added"> 789           __ verify_oop(from_reg-&gt;as_register(), FILE_AND_LINE); // kills R0</span>
 790         }

 791         break;
 792       }
 793     case T_FLOAT : __ stfsx(from_reg-&gt;as_float_reg(), base, disp); break;
 794     case T_DOUBLE: __ stfdx(from_reg-&gt;as_double_reg(), base, disp); break;
 795     default      : ShouldNotReachHere();
 796   }
 797   return store_offset;
 798 }
 799 
 800 
 801 int LIR_Assembler::load(Register base, int offset, LIR_Opr to_reg, BasicType type, bool wide, bool unaligned) {
 802   int load_offset;
 803   if (!Assembler::is_simm16(offset)) {
 804     // For offsets larger than a simm16 we setup the offset.
 805     __ load_const_optimized(R0, offset);
 806     load_offset = load(base, R0, to_reg, type, wide);
 807   } else {
 808     load_offset = code_offset();
 809     switch(type) {
 810       case T_BOOLEAN: // fall through
</pre>
<hr />
<pre>
 815       case T_INT   :   __ lwa(to_reg-&gt;as_register(), offset, base); break;
 816       case T_LONG  :   __ ld(to_reg-&gt;as_register_lo(), offset, base); break;
 817       case T_METADATA: __ ld(to_reg-&gt;as_register(), offset, base); break;
 818       case T_ADDRESS:
 819         if (offset == oopDesc::klass_offset_in_bytes() &amp;&amp; UseCompressedClassPointers) {
 820           __ lwz(to_reg-&gt;as_register(), offset, base);
 821           __ decode_klass_not_null(to_reg-&gt;as_register());
 822         } else {
 823           __ ld(to_reg-&gt;as_register(), offset, base);
 824         }
 825         break;
 826       case T_ARRAY : // fall through
 827       case T_OBJECT:
 828         {
 829           if (UseCompressedOops &amp;&amp; !wide) {
 830             __ lwz(to_reg-&gt;as_register(), offset, base);
 831             __ decode_heap_oop(to_reg-&gt;as_register());
 832           } else {
 833             __ ld(to_reg-&gt;as_register(), offset, base);
 834           }
<span class="line-modified"> 835           __ verify_oop(to_reg-&gt;as_register(), FILE_AND_LINE);</span>
 836           break;
 837         }
 838       case T_FLOAT:  __ lfs(to_reg-&gt;as_float_reg(), offset, base); break;
 839       case T_DOUBLE: __ lfd(to_reg-&gt;as_double_reg(), offset, base); break;
 840       default      : ShouldNotReachHere();
 841     }
 842   }
 843   return load_offset;
 844 }
 845 
 846 
 847 int LIR_Assembler::load(Register base, Register disp, LIR_Opr to_reg, BasicType type, bool wide) {
 848   int load_offset = code_offset();
 849   switch(type) {
 850     case T_BOOLEAN: // fall through
 851     case T_BYTE  :  __ lbzx(to_reg-&gt;as_register(), base, disp);
 852                     __ extsb(to_reg-&gt;as_register(), to_reg-&gt;as_register()); break;
 853     case T_CHAR  :  __ lhzx(to_reg-&gt;as_register(), base, disp); break;
 854     case T_SHORT :  __ lhax(to_reg-&gt;as_register(), base, disp); break;
 855     case T_INT   :  __ lwax(to_reg-&gt;as_register(), base, disp); break;
 856     case T_ADDRESS: __ ldx(to_reg-&gt;as_register(), base, disp); break;
 857     case T_ARRAY : // fall through
 858     case T_OBJECT:
 859       {
 860         if (UseCompressedOops &amp;&amp; !wide) {
 861           __ lwzx(to_reg-&gt;as_register(), base, disp);
 862           __ decode_heap_oop(to_reg-&gt;as_register());
 863         } else {
 864           __ ldx(to_reg-&gt;as_register(), base, disp);
 865         }
<span class="line-modified"> 866         __ verify_oop(to_reg-&gt;as_register(), FILE_AND_LINE);</span>
 867         break;
 868       }
 869     case T_FLOAT:  __ lfsx(to_reg-&gt;as_float_reg() , base, disp); break;
 870     case T_DOUBLE: __ lfdx(to_reg-&gt;as_double_reg(), base, disp); break;
 871     case T_LONG  :
 872 #ifdef _LP64
 873       __ ldx(to_reg-&gt;as_register_lo(), base, disp);
 874 #else
 875       Unimplemented();
 876 #endif
 877       break;
 878     default      : ShouldNotReachHere();
 879   }
 880   return load_offset;
 881 }
 882 
 883 
 884 void LIR_Assembler::const2stack(LIR_Opr src, LIR_Opr dest) {
 885   LIR_Const* c = src-&gt;as_constant_ptr();
 886   Register src_reg = R0;
</pre>
<hr />
<pre>
1125 
1126 void LIR_Assembler::mem2reg(LIR_Opr src_opr, LIR_Opr dest, BasicType type,
1127                             LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool unaligned) {
1128 
1129   assert(type != T_METADATA, &quot;load of metadata ptr not supported&quot;);
1130   LIR_Address* addr = src_opr-&gt;as_address_ptr();
1131   LIR_Opr to_reg = dest;
1132 
1133   Register src = addr-&gt;base()-&gt;as_pointer_register();
1134   Register disp_reg = noreg;
1135   int disp_value = addr-&gt;disp();
1136   bool needs_patching = (patch_code != lir_patch_none);
1137   // null check for large offsets in LIRGenerator::do_LoadField
1138   bool needs_explicit_null_check = !os::zero_page_read_protected() || !ImplicitNullChecks;
1139 
1140   if (info != NULL &amp;&amp; needs_explicit_null_check) {
1141     explicit_null_check(src, info);
1142   }
1143 
1144   if (addr-&gt;base()-&gt;type() == T_OBJECT) {
<span class="line-modified">1145     __ verify_oop(src, FILE_AND_LINE);</span>
1146   }
1147 
1148   PatchingStub* patch = NULL;
1149   if (needs_patching) {
1150     patch = new PatchingStub(_masm, PatchingStub::access_field_id);
1151     assert(!to_reg-&gt;is_double_cpu() ||
1152            patch_code == lir_patch_none ||
1153            patch_code == lir_patch_normal, &quot;patching doesn&#39;t match register&quot;);
1154   }
1155 
1156   if (addr-&gt;index()-&gt;is_illegal()) {
1157     if (!Assembler::is_simm16(disp_value)) {
1158       if (needs_patching) {
1159         __ load_const32(R0, 0); // patchable int
1160       } else {
1161         __ load_const_optimized(R0, disp_value);
1162       }
1163       disp_reg = R0;
1164     }
1165   } else {
</pre>
<hr />
<pre>
1221       assert(to_reg-&gt;is_double_fpu(), &quot;should match&quot;);
1222       __ fmr_if_needed(to_reg-&gt;as_double_reg(), from_reg-&gt;as_double_reg());
1223     } else {
1224       // float to float moves
1225       assert(to_reg-&gt;is_single_fpu(), &quot;should match&quot;);
1226       __ fmr_if_needed(to_reg-&gt;as_float_reg(), from_reg-&gt;as_float_reg());
1227     }
1228   } else if (!from_reg-&gt;is_float_kind() &amp;&amp; !to_reg-&gt;is_float_kind()) {
1229     if (from_reg-&gt;is_double_cpu()) {
1230       __ mr_if_needed(to_reg-&gt;as_pointer_register(), from_reg-&gt;as_pointer_register());
1231     } else if (to_reg-&gt;is_double_cpu()) {
1232       // int to int moves
1233       __ mr_if_needed(to_reg-&gt;as_register_lo(), from_reg-&gt;as_register());
1234     } else {
1235       // int to int moves
1236       __ mr_if_needed(to_reg-&gt;as_register(), from_reg-&gt;as_register());
1237     }
1238   } else {
1239     ShouldNotReachHere();
1240   }
<span class="line-modified">1241   if (is_reference_type(to_reg-&gt;type())) {</span>
<span class="line-modified">1242     __ verify_oop(to_reg-&gt;as_register(), FILE_AND_LINE);</span>
1243   }
1244 }
1245 
1246 
1247 void LIR_Assembler::reg2mem(LIR_Opr from_reg, LIR_Opr dest, BasicType type,
1248                             LIR_PatchCode patch_code, CodeEmitInfo* info, bool pop_fpu_stack,
1249                             bool wide, bool unaligned) {
1250   assert(type != T_METADATA, &quot;store of metadata ptr not supported&quot;);
1251   LIR_Address* addr = dest-&gt;as_address_ptr();
1252 
1253   Register src = addr-&gt;base()-&gt;as_pointer_register();
1254   Register disp_reg = noreg;
1255   int disp_value = addr-&gt;disp();
1256   bool needs_patching = (patch_code != lir_patch_none);
<span class="line-modified">1257   bool compress_oop = (is_reference_type(type)) &amp;&amp; UseCompressedOops &amp;&amp; !wide &amp;&amp;</span>
<span class="line-modified">1258                       CompressedOops::mode() != CompressedOops::UnscaledNarrowOop;</span>
1259   bool load_disp = addr-&gt;index()-&gt;is_illegal() &amp;&amp; !Assembler::is_simm16(disp_value);
1260   bool use_R29 = compress_oop &amp;&amp; load_disp; // Avoid register conflict, also do null check before killing R29.
1261   // Null check for large offsets in LIRGenerator::do_StoreField.
1262   bool needs_explicit_null_check = !ImplicitNullChecks || use_R29;
1263 
1264   if (info != NULL &amp;&amp; needs_explicit_null_check) {
1265     explicit_null_check(src, info);
1266   }
1267 
1268   if (addr-&gt;base()-&gt;is_oop_register()) {
<span class="line-modified">1269     __ verify_oop(src, FILE_AND_LINE);</span>
1270   }
1271 
1272   PatchingStub* patch = NULL;
1273   if (needs_patching) {
1274     patch = new PatchingStub(_masm, PatchingStub::access_field_id);
1275     assert(!from_reg-&gt;is_double_cpu() ||
1276            patch_code == lir_patch_none ||
1277            patch_code == lir_patch_normal, &quot;patching doesn&#39;t match register&quot;);
1278   }
1279 
1280   if (addr-&gt;index()-&gt;is_illegal()) {
1281     if (load_disp) {
1282       disp_reg = use_R29 ? R29_TOC : R0;
1283       if (needs_patching) {
1284         __ load_const32(disp_reg, 0); // patchable int
1285       } else {
1286         __ load_const_optimized(disp_reg, disp_value);
1287       }
1288     }
1289   } else {
</pre>
<hr />
<pre>
1451                 __ cmpw(BOOL_RESULT, opr1-&gt;as_register(), R0);
1452               }
1453             }
1454           }
1455           break;
1456 
1457         case T_OBJECT:
1458           // There are only equal/notequal comparisons on objects.
1459           {
1460             assert(condition == lir_cond_equal || condition == lir_cond_notEqual, &quot;oops&quot;);
1461             jobject con = opr2-&gt;as_constant_ptr()-&gt;as_jobject();
1462             if (con == NULL) {
1463               __ cmpdi(BOOL_RESULT, opr1-&gt;as_register(), 0);
1464             } else {
1465               jobject2reg(con, R0);
1466               __ cmpd(BOOL_RESULT, opr1-&gt;as_register(), R0);
1467             }
1468           }
1469           break;
1470 
<span class="line-added">1471         case T_METADATA:</span>
<span class="line-added">1472           // We only need, for now, comparison with NULL for metadata.</span>
<span class="line-added">1473           {</span>
<span class="line-added">1474             assert(condition == lir_cond_equal || condition == lir_cond_notEqual, &quot;oops&quot;);</span>
<span class="line-added">1475             Metadata* p = opr2-&gt;as_constant_ptr()-&gt;as_metadata();</span>
<span class="line-added">1476             if (p == NULL) {</span>
<span class="line-added">1477               __ cmpdi(BOOL_RESULT, opr1-&gt;as_register(), 0);</span>
<span class="line-added">1478             } else {</span>
<span class="line-added">1479               ShouldNotReachHere();</span>
<span class="line-added">1480             }</span>
<span class="line-added">1481           }</span>
<span class="line-added">1482           break;</span>
<span class="line-added">1483 </span>
1484         default:
1485           ShouldNotReachHere();
1486           break;
1487       }
1488     } else {
<span class="line-modified">1489       assert(opr1-&gt;type() != T_ADDRESS &amp;&amp; opr2-&gt;type() != T_ADDRESS, &quot;currently unsupported&quot;);</span>
<span class="line-modified">1490       if (is_reference_type(opr1-&gt;type())) {</span>
<span class="line-modified">1491         // There are only equal/notequal comparisons on objects.</span>
<span class="line-modified">1492         assert(condition == lir_cond_equal || condition == lir_cond_notEqual, &quot;oops&quot;);</span>
<span class="line-modified">1493         __ cmpd(BOOL_RESULT, opr1-&gt;as_register(), opr2-&gt;as_register());</span>


1494       } else {
1495         if (unsigned_comp) {
1496           __ cmplw(BOOL_RESULT, opr1-&gt;as_register(), opr2-&gt;as_register());
1497         } else {
1498           __ cmpw(BOOL_RESULT, opr1-&gt;as_register(), opr2-&gt;as_register());
1499         }
1500       }
1501     }
1502   } else if (opr1-&gt;is_double_cpu()) {
1503     if (opr2-&gt;is_constant()) {
1504       jlong con = opr2-&gt;as_constant_ptr()-&gt;as_jlong();
1505       if (unsigned_comp) {
1506         if (Assembler::is_uimm(con, 16)) {
1507           __ cmpldi(BOOL_RESULT, opr1-&gt;as_register_lo(), con);
1508         } else {
1509           __ load_const_optimized(R0, con);
1510           __ cmpld(BOOL_RESULT, opr1-&gt;as_register_lo(), R0);
1511         }
1512       } else {
1513         if (Assembler::is_simm(con, 16)) {
1514           __ cmpdi(BOOL_RESULT, opr1-&gt;as_register_lo(), con);
1515         } else {
1516           __ load_const_optimized(R0, con);
1517           __ cmpd(BOOL_RESULT, opr1-&gt;as_register_lo(), R0);
1518         }
1519       }
1520     } else if (opr2-&gt;is_register()) {
1521       if (unsigned_comp) {
1522         __ cmpld(BOOL_RESULT, opr1-&gt;as_register_lo(), opr2-&gt;as_register_lo());
1523       } else {
1524         __ cmpd(BOOL_RESULT, opr1-&gt;as_register_lo(), opr2-&gt;as_register_lo());
1525       }
1526     } else {
1527       ShouldNotReachHere();
1528     }








1529   } else {
1530     ShouldNotReachHere();
1531   }
1532 }
1533 
1534 
1535 void LIR_Assembler::comp_fl2i(LIR_Code code, LIR_Opr left, LIR_Opr right, LIR_Opr dst, LIR_Op2* op){
1536   const Register Rdst = dst-&gt;as_register();
1537   Label done;
1538   if (code == lir_cmp_fd2i || code == lir_ucmp_fd2i) {
1539     bool is_unordered_less = (code == lir_ucmp_fd2i);
1540     if (left-&gt;is_single_fpu()) {
1541       __ fcmpu(CCR0, left-&gt;as_float_reg(), right-&gt;as_float_reg());
1542     } else if (left-&gt;is_double_fpu()) {
1543       __ fcmpu(CCR0, left-&gt;as_double_reg(), right-&gt;as_double_reg());
1544     } else {
1545       ShouldNotReachHere();
1546     }
1547     __ li(Rdst, is_unordered_less ? -1 : 1);
1548     __ bso(CCR0, done);
</pre>
<hr />
<pre>
1710     } else {
1711       Register lreg = left-&gt;as_pointer_register();
1712       Register res  = dest-&gt;as_register_lo();
1713       long con = right-&gt;as_constant_ptr()-&gt;as_jlong();
1714       assert(Assembler::is_simm16(con), &quot;must be simm16&quot;);
1715 
1716       switch (code) {
1717         case lir_sub:  assert(Assembler::is_simm16(-con), &quot;cannot encode&quot;);  // see do_ArithmeticOp_Long
1718                        con = -con;
1719         case lir_add:  if (res == lreg &amp;&amp; con == 0) break;
1720                        __ addi(res, lreg, (int)con); break;
1721         case lir_mul:  if (res == lreg &amp;&amp; con == 1) break;
1722                        __ mulli(res, lreg, (int)con); break;
1723         default: ShouldNotReachHere();
1724       }
1725     }
1726   }
1727 }
1728 
1729 






1730 void LIR_Assembler::intrinsic_op(LIR_Code code, LIR_Opr value, LIR_Opr thread, LIR_Opr dest, LIR_Op* op) {
1731   switch (code) {
1732     case lir_sqrt: {
1733       __ fsqrt(dest-&gt;as_double_reg(), value-&gt;as_double_reg());
1734       break;
1735     }
1736     case lir_abs: {
1737       __ fabs(dest-&gt;as_double_reg(), value-&gt;as_double_reg());
1738       break;
1739     }
1740     default: {
1741       ShouldNotReachHere();
1742       break;
1743     }
1744   }
1745 }
1746 
1747 
1748 void LIR_Assembler::logic_op(LIR_Code code, LIR_Opr left, LIR_Opr right, LIR_Opr dest) {
1749   if (right-&gt;is_constant()) { // see do_LogicOp
1750     long uimm;
1751     Register d, l;
1752     if (dest-&gt;is_single_cpu()) {
1753       uimm = right-&gt;as_constant_ptr()-&gt;as_jint();
1754       d = dest-&gt;as_register();
1755       l = left-&gt;as_register();
1756     } else {
1757       uimm = right-&gt;as_constant_ptr()-&gt;as_jlong();
1758       d = dest-&gt;as_register_lo();
1759       l = left-&gt;as_register_lo();
1760     }
1761     long uimms  = (unsigned long)uimm &gt;&gt; 16,
1762          uimmss = (unsigned long)uimm &gt;&gt; 32;
1763 
1764     switch (code) {
1765       case lir_logic_and:
<span class="line-modified">1766         if (uimmss != 0 || (uimms != 0 &amp;&amp; (uimm &amp; 0xFFFF) != 0) || is_power_of_2(uimm)) {</span>
1767           __ andi(d, l, uimm); // special cases
1768         } else if (uimms != 0) { __ andis_(d, l, uimms); }
1769         else { __ andi_(d, l, uimm); }
1770         break;
1771 
1772       case lir_logic_or:
1773         if (uimms != 0) { assert((uimm &amp; 0xFFFF) == 0, &quot;sanity&quot;); __ oris(d, l, uimms); }
1774         else { __ ori(d, l, uimm); }
1775         break;
1776 
1777       case lir_logic_xor:
1778         if (uimm == -1) { __ nand(d, l, l); } // special case
1779         else if (uimms != 0) { assert((uimm &amp; 0xFFFF) == 0, &quot;sanity&quot;); __ xoris(d, l, uimms); }
1780         else { __ xori(d, l, uimm); }
1781         break;
1782 
1783       default: ShouldNotReachHere();
1784     }
1785   } else {
1786     assert(right-&gt;is_register(), &quot;right should be in register&quot;);
</pre>
<hr />
<pre>
2299     if (!os::zero_page_read_protected() || !ImplicitNullChecks) {
2300       explicit_null_check(op-&gt;klass()-&gt;as_register(), op-&gt;stub()-&gt;info());
2301     } else {
2302       add_debug_info_for_null_check_here(op-&gt;stub()-&gt;info());
2303     }
2304     __ lbz(op-&gt;tmp1()-&gt;as_register(),
2305            in_bytes(InstanceKlass::init_state_offset()), op-&gt;klass()-&gt;as_register());
2306     __ cmpwi(CCR0, op-&gt;tmp1()-&gt;as_register(), InstanceKlass::fully_initialized);
2307     __ bc_far_optimized(Assembler::bcondCRbiIs0, __ bi0(CCR0, Assembler::equal), *op-&gt;stub()-&gt;entry());
2308   }
2309   __ allocate_object(op-&gt;obj()-&gt;as_register(),
2310                      op-&gt;tmp1()-&gt;as_register(),
2311                      op-&gt;tmp2()-&gt;as_register(),
2312                      op-&gt;tmp3()-&gt;as_register(),
2313                      op-&gt;header_size(),
2314                      op-&gt;object_size(),
2315                      op-&gt;klass()-&gt;as_register(),
2316                      *op-&gt;stub()-&gt;entry());
2317 
2318   __ bind(*op-&gt;stub()-&gt;continuation());
<span class="line-modified">2319   __ verify_oop(op-&gt;obj()-&gt;as_register(), FILE_AND_LINE);</span>
2320 }
2321 
2322 
2323 void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
2324   LP64_ONLY( __ extsw(op-&gt;len()-&gt;as_register(), op-&gt;len()-&gt;as_register()); )
2325   if (UseSlowPath ||
<span class="line-modified">2326       (!UseFastNewObjectArray &amp;&amp; (is_reference_type(op-&gt;type()))) ||</span>
<span class="line-modified">2327       (!UseFastNewTypeArray   &amp;&amp; (!is_reference_type(op-&gt;type())))) {</span>
2328     __ b(*op-&gt;stub()-&gt;entry());
2329   } else {
2330     __ allocate_array(op-&gt;obj()-&gt;as_register(),
2331                       op-&gt;len()-&gt;as_register(),
2332                       op-&gt;tmp1()-&gt;as_register(),
2333                       op-&gt;tmp2()-&gt;as_register(),
2334                       op-&gt;tmp3()-&gt;as_register(),
2335                       arrayOopDesc::header_size(op-&gt;type()),
2336                       type2aelembytes(op-&gt;type()),
2337                       op-&gt;klass()-&gt;as_register(),
2338                       *op-&gt;stub()-&gt;entry());
2339   }
2340   __ bind(*op-&gt;stub()-&gt;continuation());
2341 }
2342 
2343 
2344 void LIR_Assembler::type_profile_helper(Register mdo, int mdo_offset_bias,
2345                                         ciMethodData *md, ciProfileData *data,
2346                                         Register recv, Register tmp1, Label* update_done) {
2347   uint i;
</pre>
<hr />
<pre>
2524     __ add_const_optimized(mdo, mdo, mdo_offset_bias, R0);
2525     __ ld(Rtmp1, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()) - mdo_offset_bias, mdo);
2526     __ addi(Rtmp1, Rtmp1, -DataLayout::counter_increment);
2527     __ std(Rtmp1, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()) - mdo_offset_bias, mdo);
2528   }
2529 
2530   __ bind(*failure);
2531 }
2532 
2533 
2534 void LIR_Assembler::emit_opTypeCheck(LIR_OpTypeCheck* op) {
2535   LIR_Code code = op-&gt;code();
2536   if (code == lir_store_check) {
2537     Register value = op-&gt;object()-&gt;as_register();
2538     Register array = op-&gt;array()-&gt;as_register();
2539     Register k_RInfo = op-&gt;tmp1()-&gt;as_register();
2540     Register klass_RInfo = op-&gt;tmp2()-&gt;as_register();
2541     Register Rtmp1 = op-&gt;tmp3()-&gt;as_register();
2542     bool should_profile = op-&gt;should_profile();
2543 
<span class="line-modified">2544     __ verify_oop(value, FILE_AND_LINE);</span>
2545     CodeStub* stub = op-&gt;stub();
2546     // Check if it needs to be profiled.
2547     ciMethodData* md = NULL;
2548     ciProfileData* data = NULL;
2549     int mdo_offset_bias = 0;
2550     if (should_profile) {
2551       ciMethod* method = op-&gt;profiled_method();
2552       assert(method != NULL, &quot;Should have method&quot;);
2553       setup_md_access(method, op-&gt;profiled_bci(), md, data, mdo_offset_bias);
2554     }
2555     Label profile_cast_success, failure, done;
2556     Label *success_target = should_profile ? &amp;profile_cast_success : &amp;done;
2557 
2558     __ cmpdi(CCR0, value, 0);
2559     if (should_profile) {
2560       Label not_null;
2561       __ bne(CCR0, not_null);
2562       Register mdo      = k_RInfo;
2563       Register data_val = Rtmp1;
2564       metadata2reg(md-&gt;constant_encoding(), mdo);
</pre>
<hr />
<pre>
2669 
2670   if (is_64bit) {
2671     __ cmpxchgd(BOOL_RESULT, /*current_value=*/R0, cmp_value, new_value, addr,
2672                 MacroAssembler::MemBarNone,
2673                 MacroAssembler::cmpxchgx_hint_atomic_update(),
2674                 noreg, NULL, /*check without ldarx first*/true);
2675   } else {
2676     __ cmpxchgw(BOOL_RESULT, /*current_value=*/R0, cmp_value, new_value, addr,
2677                 MacroAssembler::MemBarNone,
2678                 MacroAssembler::cmpxchgx_hint_atomic_update(),
2679                 noreg, /*check without ldarx first*/true);
2680   }
2681 
2682   if (support_IRIW_for_not_multiple_copy_atomic_cpu) {
2683     __ isync();
2684   } else {
2685     __ sync();
2686   }
2687 }
2688 










2689 void LIR_Assembler::breakpoint() {
2690   __ illtrap();
2691 }
2692 
2693 
2694 void LIR_Assembler::push(LIR_Opr opr) {
2695   Unimplemented();
2696 }
2697 
2698 void LIR_Assembler::pop(LIR_Opr opr) {
2699   Unimplemented();
2700 }
2701 
2702 
2703 void LIR_Assembler::monitor_address(int monitor_no, LIR_Opr dst_opr) {
2704   Address mon_addr = frame_map()-&gt;address_for_monitor_lock(monitor_no);
2705   Register dst = dst_opr-&gt;as_register();
2706   Register reg = mon_addr.base();
2707   int offset = mon_addr.disp();
2708   // Compute pointer to BasicLock.
</pre>
<hr />
<pre>
2862 
2863 
2864 void LIR_Assembler::negate(LIR_Opr left, LIR_Opr dest, LIR_Opr tmp) {
2865   // tmp must be unused
2866   assert(tmp-&gt;is_illegal(), &quot;wasting a register if tmp is allocated&quot;);
2867   assert(left-&gt;is_register(), &quot;can only handle registers&quot;);
2868 
2869   if (left-&gt;is_single_cpu()) {
2870     __ neg(dest-&gt;as_register(), left-&gt;as_register());
2871   } else if (left-&gt;is_single_fpu()) {
2872     __ fneg(dest-&gt;as_float_reg(), left-&gt;as_float_reg());
2873   } else if (left-&gt;is_double_fpu()) {
2874     __ fneg(dest-&gt;as_double_reg(), left-&gt;as_double_reg());
2875   } else {
2876     assert (left-&gt;is_double_cpu(), &quot;Must be a long&quot;);
2877     __ neg(dest-&gt;as_register_lo(), left-&gt;as_register_lo());
2878   }
2879 }
2880 
2881 













2882 void LIR_Assembler::rt_call(LIR_Opr result, address dest,
2883                             const LIR_OprList* args, LIR_Opr tmp, CodeEmitInfo* info) {
2884   // Stubs: Called via rt_call, but dest is a stub address (no function descriptor).
2885   if (dest == Runtime1::entry_for(Runtime1::register_finalizer_id) ||
2886       dest == Runtime1::entry_for(Runtime1::new_multi_array_id   )) {
2887     //__ load_const_optimized(R0, dest);
2888     __ add_const_optimized(R0, R29_TOC, MacroAssembler::offset_to_global_toc(dest));
2889     __ mtctr(R0);
2890     __ bctrl();
2891     assert(info != NULL, &quot;sanity&quot;);
2892     add_call_info_here(info);
2893     return;
2894   }
2895 
2896   __ call_c_with_frame_resize(dest, /*no resizing*/ 0);
2897   if (info != NULL) {
2898     add_call_info_here(info);
2899   }
2900 }
2901 
</pre>
<hr />
<pre>
3054 
3055 
3056 void LIR_Assembler::emit_profile_type(LIR_OpProfileType* op) {
3057   Register obj = op-&gt;obj()-&gt;as_register();
3058   Register tmp = op-&gt;tmp()-&gt;as_pointer_register();
3059   LIR_Address* mdo_addr = op-&gt;mdp()-&gt;as_address_ptr();
3060   ciKlass* exact_klass = op-&gt;exact_klass();
3061   intptr_t current_klass = op-&gt;current_klass();
3062   bool not_null = op-&gt;not_null();
3063   bool no_conflict = op-&gt;no_conflict();
3064 
3065   Label Lupdate, Ldo_update, Ldone;
3066 
3067   bool do_null = !not_null;
3068   bool exact_klass_set = exact_klass != NULL &amp;&amp; ciTypeEntries::valid_ciklass(current_klass) == exact_klass;
3069   bool do_update = !TypeEntries::is_type_unknown(current_klass) &amp;&amp; !exact_klass_set;
3070 
3071   assert(do_null || do_update, &quot;why are we here?&quot;);
3072   assert(!TypeEntries::was_null_seen(current_klass) || do_update, &quot;why are we here?&quot;);
3073 
<span class="line-modified">3074   __ verify_oop(obj, FILE_AND_LINE);</span>
3075 
3076   if (do_null) {
3077     if (!TypeEntries::was_null_seen(current_klass)) {
3078       __ cmpdi(CCR0, obj, 0);
3079       __ bne(CCR0, Lupdate);
3080       __ ld(R0, index_or_disp(mdo_addr), mdo_addr-&gt;base()-&gt;as_pointer_register());
3081       __ ori(R0, R0, TypeEntries::null_seen);
3082       if (do_update) {
3083         __ b(Ldo_update);
3084       } else {
3085         __ std(R0, index_or_disp(mdo_addr), mdo_addr-&gt;base()-&gt;as_pointer_register());
3086       }
3087     } else {
3088       if (do_update) {
3089         __ cmpdi(CCR0, obj, 0);
3090         __ beq(CCR0, Ldone);
3091       }
3092     }
3093 #ifdef ASSERT
3094   } else {
</pre>
</td>
</tr>
</table>
<center><a href="c1_FrameMap_ppc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRGenerator_ppc.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>