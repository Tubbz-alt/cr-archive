<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/sparc/c1_LIRAssembler_sparc.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_FrameMap_sparc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRGenerator_sparc.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/sparc/c1_LIRAssembler_sparc.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/macroAssembler.inline.hpp&quot;
  27 #include &quot;c1/c1_Compilation.hpp&quot;
  28 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  29 #include &quot;c1/c1_MacroAssembler.hpp&quot;
  30 #include &quot;c1/c1_Runtime1.hpp&quot;
  31 #include &quot;c1/c1_ValueStack.hpp&quot;
  32 #include &quot;ci/ciArrayKlass.hpp&quot;
  33 #include &quot;ci/ciInstance.hpp&quot;
<span class="line-removed">  34 #include &quot;gc/shared/barrierSet.hpp&quot;</span>
<span class="line-removed">  35 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;</span>
  36 #include &quot;gc/shared/collectedHeap.hpp&quot;

  37 #include &quot;nativeInst_sparc.hpp&quot;
  38 #include &quot;oops/objArrayKlass.hpp&quot;
  39 #include &quot;runtime/frame.inline.hpp&quot;
  40 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  41 #include &quot;runtime/jniHandles.inline.hpp&quot;
  42 #include &quot;runtime/safepointMechanism.inline.hpp&quot;
  43 #include &quot;runtime/sharedRuntime.hpp&quot;

  44 
  45 #define __ _masm-&gt;
  46 
  47 
  48 //------------------------------------------------------------
  49 
  50 
  51 bool LIR_Assembler::is_small_constant(LIR_Opr opr) {
  52   if (opr-&gt;is_constant()) {
  53     LIR_Const* constant = opr-&gt;as_constant_ptr();
  54     switch (constant-&gt;type()) {
  55       case T_INT: {
  56         jint value = constant-&gt;as_jint();
  57         return Assembler::is_simm13(value);
  58       }
  59 
  60       default:
  61         return false;
  62     }
  63   }
</pre>
<hr />
<pre>
  89         // this works around a problem where moves with the same src and dst
  90         // end up in the delay slot and then the assembler swallows the mov
  91         // since it has no effect and then it complains because the delay slot
  92         // is empty.  returning false stops the optimizer from putting this in
  93         // the delay slot
  94         return false;
  95       }
  96 
  97       // don&#39;t put moves involving oops into the delay slot since the VerifyOops code
  98       // will make it much larger than a single instruction.
  99       if (VerifyOops) {
 100         return false;
 101       }
 102 
 103       if (src-&gt;is_double_cpu() || dst-&gt;is_double_cpu() || op1-&gt;patch_code() != lir_patch_none ||
 104           ((src-&gt;is_double_fpu() || dst-&gt;is_double_fpu()) &amp;&amp; op1-&gt;move_kind() != lir_move_normal)) {
 105         return false;
 106       }
 107 
 108       if (UseCompressedOops) {
<span class="line-modified"> 109         if (dst-&gt;is_address() &amp;&amp; !dst-&gt;is_stack() &amp;&amp; (dst-&gt;type() == T_OBJECT || dst-&gt;type() == T_ARRAY)) return false;</span>
<span class="line-modified"> 110         if (src-&gt;is_address() &amp;&amp; !src-&gt;is_stack() &amp;&amp; (src-&gt;type() == T_OBJECT || src-&gt;type() == T_ARRAY)) return false;</span>
 111       }
 112 
 113       if (UseCompressedClassPointers) {
 114         if (src-&gt;is_address() &amp;&amp; !src-&gt;is_stack() &amp;&amp; src-&gt;type() == T_ADDRESS &amp;&amp;
 115             src-&gt;as_address_ptr()-&gt;disp() == oopDesc::klass_offset_in_bytes()) return false;
 116       }
 117 
 118       if (dst-&gt;is_register()) {
 119         if (src-&gt;is_address() &amp;&amp; Assembler::is_simm13(src-&gt;as_address_ptr()-&gt;disp())) {
 120           return !PatchALot;
 121         } else if (src-&gt;is_single_stack()) {
 122           return true;
 123         }
 124       }
 125 
 126       if (src-&gt;is_register()) {
 127         if (dst-&gt;is_address() &amp;&amp; Assembler::is_simm13(dst-&gt;as_address_ptr()-&gt;disp())) {
 128           return !PatchALot;
 129         } else if (dst-&gt;is_single_stack()) {
 130           return true;
</pre>
<hr />
<pre>
 154 
 155 LIR_Opr LIR_Assembler::osrBufferPointer() {
 156   return FrameMap::I0_opr;
 157 }
 158 
 159 
 160 int LIR_Assembler::initial_frame_size_in_bytes() const {
 161   return in_bytes(frame_map()-&gt;framesize_in_bytes());
 162 }
 163 
 164 
 165 // inline cache check: the inline cached class is in G5_inline_cache_reg(G5);
 166 // we fetch the class of the receiver (O0) and compare it with the cached class.
 167 // If they do not match we jump to slow case.
 168 int LIR_Assembler::check_icache() {
 169   int offset = __ offset();
 170   __ inline_cache_check(O0, G5_inline_cache_reg);
 171   return offset;
 172 }
 173 



 174 
 175 void LIR_Assembler::osr_entry() {
 176   // On-stack-replacement entry sequence (interpreter frame layout described in interpreter_sparc.cpp):
 177   //
 178   //   1. Create a new compiled activation.
 179   //   2. Initialize local variables in the compiled activation.  The expression stack must be empty
 180   //      at the osr_bci; it is not initialized.
 181   //   3. Jump to the continuation address in compiled code to resume execution.
 182 
 183   // OSR entry point
 184   offsets()-&gt;set_value(CodeOffsets::OSR_Entry, code_offset());
 185   BlockBegin* osr_entry = compilation()-&gt;hir()-&gt;osr_entry();
 186   ValueStack* entry_state = osr_entry-&gt;end()-&gt;state();
 187   int number_of_locks = entry_state-&gt;locks_size();
 188 
 189   // Create a frame for the compiled activation.
 190   __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());
 191 
 192   // OSR buffer is
 193   //
</pre>
<hr />
<pre>
 388   }
 389 
 390   int offset = code_offset();
 391   AddressLiteral deopt_blob(SharedRuntime::deopt_blob()-&gt;unpack());
 392   __ JUMP(deopt_blob, G3_scratch, 0); // sethi;jmp
 393   __ delayed()-&gt;nop();
 394   guarantee(code_offset() - offset &lt;= deopt_handler_size(), &quot;overflow&quot;);
 395   __ end_a_stub();
 396 
 397   return offset;
 398 }
 399 
 400 
 401 void LIR_Assembler::jobject2reg(jobject o, Register reg) {
 402   if (o == NULL) {
 403     __ set(NULL_WORD, reg);
 404   } else {
 405 #ifdef ASSERT
 406     {
 407       ThreadInVMfromNative tiv(JavaThread::current());
<span class="line-modified"> 408       assert(Universe::heap()-&gt;is_in_reserved(JNIHandles::resolve(o)), &quot;should be real oop&quot;);</span>
 409     }
 410 #endif
 411     int oop_index = __ oop_recorder()-&gt;find_index(o);
 412     RelocationHolder rspec = oop_Relocation::spec(oop_index);
 413     __ set(NULL_WORD, reg, rspec); // Will be set when the nmethod is created
 414   }
 415 }
 416 
 417 
 418 void LIR_Assembler::jobject2reg_with_patching(Register reg, CodeEmitInfo *info) {
 419   // Allocate a new index in table to hold the object once it&#39;s been patched
 420   int oop_index = __ oop_recorder()-&gt;allocate_oop_index(NULL);
 421   PatchingStub* patch = new PatchingStub(_masm, patching_id(info), oop_index);
 422 
 423   AddressLiteral addrlit(NULL, oop_Relocation::spec(oop_index));
 424   assert(addrlit.rspec().type() == relocInfo::oop_type, &quot;must be an oop reloc&quot;);
 425   // It may not seem necessary to use a sethi/add pair to load a NULL into dest, but the
 426   // NULL will be dynamically patched later and the patched value may be large.  We must
 427   // therefore generate the sethi/add as a placeholders
 428   __ patchable_set(addrlit, reg);
</pre>
<hr />
<pre>
 707   } else {
 708     // This will generate 2 instructions
 709     __ set(op-&gt;vtable_offset(), G5_method);
 710     // ld_ptr, set_hi, set
 711     __ ld_ptr(G3_scratch, G5_method, G5_method);
 712   }
 713   __ ld_ptr(G5_method, Method::from_compiled_offset(), G3_scratch);
 714   __ callr(G3_scratch, G0);
 715   // the peephole pass fills the delay slot
 716 }
 717 
 718 int LIR_Assembler::store(LIR_Opr from_reg, Register base, int offset, BasicType type, bool wide, bool unaligned) {
 719   int store_offset;
 720   if (!Assembler::is_simm13(offset + (type == T_LONG) ? wordSize : 0)) {
 721     assert(base != O7, &quot;destroying register&quot;);
 722     assert(!unaligned, &quot;can&#39;t handle this&quot;);
 723     // for offsets larger than a simm13 we setup the offset in O7
 724     __ set(offset, O7);
 725     store_offset = store(from_reg, base, O7, type, wide);
 726   } else {
<span class="line-modified"> 727     if (type == T_ARRAY || type == T_OBJECT) {</span>
 728       __ verify_oop(from_reg-&gt;as_register());
 729     }
 730     store_offset = code_offset();
 731     switch (type) {
 732       case T_BOOLEAN: // fall through
 733       case T_BYTE  : __ stb(from_reg-&gt;as_register(), base, offset); break;
 734       case T_CHAR  : __ sth(from_reg-&gt;as_register(), base, offset); break;
 735       case T_SHORT : __ sth(from_reg-&gt;as_register(), base, offset); break;
 736       case T_INT   : __ stw(from_reg-&gt;as_register(), base, offset); break;
 737       case T_LONG  :
 738         if (unaligned || PatchALot) {
 739           // Don&#39;t use O7 here because it may be equal to &#39;base&#39; (see LIR_Assembler::reg2mem)
 740           assert(G3_scratch != base, &quot;can&#39;t handle this&quot;);
 741           assert(G3_scratch != from_reg-&gt;as_register_lo(), &quot;can&#39;t handle this&quot;);
 742           __ srax(from_reg-&gt;as_register_lo(), 32, G3_scratch);
 743           __ stw(from_reg-&gt;as_register_lo(), base, offset + lo_word_offset_in_bytes);
 744           __ stw(G3_scratch,                 base, offset + hi_word_offset_in_bytes);
 745         } else {
 746           __ stx(from_reg-&gt;as_register_lo(), base, offset);
 747         }
</pre>
<hr />
<pre>
 768         {
 769           FloatRegister reg = from_reg-&gt;as_double_reg();
 770           // split unaligned stores
 771           if (unaligned || PatchALot) {
 772             assert(Assembler::is_simm13(offset + 4), &quot;must be&quot;);
 773             __ stf(FloatRegisterImpl::S, reg-&gt;successor(), base, offset + 4);
 774             __ stf(FloatRegisterImpl::S, reg,              base, offset);
 775           } else {
 776             __ stf(FloatRegisterImpl::D, reg, base, offset);
 777           }
 778           break;
 779         }
 780       default      : ShouldNotReachHere();
 781     }
 782   }
 783   return store_offset;
 784 }
 785 
 786 
 787 int LIR_Assembler::store(LIR_Opr from_reg, Register base, Register disp, BasicType type, bool wide) {
<span class="line-modified"> 788   if (type == T_ARRAY || type == T_OBJECT) {</span>
 789     __ verify_oop(from_reg-&gt;as_register());
 790   }
 791   int store_offset = code_offset();
 792   switch (type) {
 793     case T_BOOLEAN: // fall through
 794     case T_BYTE  : __ stb(from_reg-&gt;as_register(), base, disp); break;
 795     case T_CHAR  : __ sth(from_reg-&gt;as_register(), base, disp); break;
 796     case T_SHORT : __ sth(from_reg-&gt;as_register(), base, disp); break;
 797     case T_INT   : __ stw(from_reg-&gt;as_register(), base, disp); break;
 798     case T_LONG  :
 799       __ stx(from_reg-&gt;as_register_lo(), base, disp);
 800       break;
 801     case T_ADDRESS:
 802       __ st_ptr(from_reg-&gt;as_register(), base, disp);
 803       break;
 804     case T_ARRAY : // fall through
 805     case T_OBJECT:
 806       {
 807         if (UseCompressedOops &amp;&amp; !wide) {
 808           __ encode_heap_oop(from_reg-&gt;as_register(), G3_scratch);
</pre>
<hr />
<pre>
 868           } else {
 869             __ ld_ptr(base, offset, to_reg-&gt;as_register());
 870           }
 871           break;
 872         }
 873       case T_FLOAT:  __ ldf(FloatRegisterImpl::S, base, offset, to_reg-&gt;as_float_reg()); break;
 874       case T_DOUBLE:
 875         {
 876           FloatRegister reg = to_reg-&gt;as_double_reg();
 877           // split unaligned loads
 878           if (unaligned || PatchALot) {
 879             __ ldf(FloatRegisterImpl::S, base, offset + 4, reg-&gt;successor());
 880             __ ldf(FloatRegisterImpl::S, base, offset,     reg);
 881           } else {
 882             __ ldf(FloatRegisterImpl::D, base, offset, to_reg-&gt;as_double_reg());
 883           }
 884           break;
 885         }
 886       default      : ShouldNotReachHere();
 887     }
<span class="line-modified"> 888     if (type == T_ARRAY || type == T_OBJECT) {</span>
 889       __ verify_oop(to_reg-&gt;as_register());
 890     }
 891   }
 892   return load_offset;
 893 }
 894 
 895 
 896 int LIR_Assembler::load(Register base, Register disp, LIR_Opr to_reg, BasicType type, bool wide) {
 897   int load_offset = code_offset();
 898   switch(type) {
 899     case T_BOOLEAN: // fall through
 900     case T_BYTE  :  __ ldsb(base, disp, to_reg-&gt;as_register()); break;
 901     case T_CHAR  :  __ lduh(base, disp, to_reg-&gt;as_register()); break;
 902     case T_SHORT :  __ ldsh(base, disp, to_reg-&gt;as_register()); break;
 903     case T_INT   :  __ ld(base, disp, to_reg-&gt;as_register()); break;
 904     case T_ADDRESS: __ ld_ptr(base, disp, to_reg-&gt;as_register()); break;
 905     case T_ARRAY : // fall through
 906     case T_OBJECT:
 907       {
 908           if (UseCompressedOops &amp;&amp; !wide) {
 909             __ lduw(base, disp, to_reg-&gt;as_register());
 910             __ decode_heap_oop(to_reg-&gt;as_register());
 911           } else {
 912             __ ld_ptr(base, disp, to_reg-&gt;as_register());
 913           }
 914           break;
 915       }
 916     case T_FLOAT:  __ ldf(FloatRegisterImpl::S, base, disp, to_reg-&gt;as_float_reg()); break;
 917     case T_DOUBLE: __ ldf(FloatRegisterImpl::D, base, disp, to_reg-&gt;as_double_reg()); break;
 918     case T_LONG  :
 919       __ ldx(base, disp, to_reg-&gt;as_register_lo());
 920       break;
 921     default      : ShouldNotReachHere();
 922   }
<span class="line-modified"> 923   if (type == T_ARRAY || type == T_OBJECT) {</span>
 924     __ verify_oop(to_reg-&gt;as_register());
 925   }
 926   return load_offset;
 927 }
 928 
 929 void LIR_Assembler::const2stack(LIR_Opr src, LIR_Opr dest) {
 930   LIR_Const* c = src-&gt;as_constant_ptr();
 931   switch (c-&gt;type()) {
 932     case T_INT:
 933     case T_FLOAT: {
 934       Register src_reg = O7;
 935       int value = c-&gt;as_jint_bits();
 936       if (value == 0) {
 937         src_reg = G0;
 938       } else {
 939         __ set(value, O7);
 940       }
 941       Address addr = frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix());
 942       __ stw(src_reg, addr.base(), addr.disp());
 943       break;
</pre>
<hr />
<pre>
1338       assert(to_reg-&gt;is_double_fpu(), &quot;should match&quot;);
1339       __ fmov(FloatRegisterImpl::D, from_reg-&gt;as_double_reg(), to_reg-&gt;as_double_reg());
1340     } else {
1341       // float to float moves
1342       assert(to_reg-&gt;is_single_fpu(), &quot;should match&quot;);
1343       __ fmov(FloatRegisterImpl::S, from_reg-&gt;as_float_reg(), to_reg-&gt;as_float_reg());
1344     }
1345   } else if (!from_reg-&gt;is_float_kind() &amp;&amp; !to_reg-&gt;is_float_kind()) {
1346     if (from_reg-&gt;is_double_cpu()) {
1347       __ mov(from_reg-&gt;as_pointer_register(), to_reg-&gt;as_pointer_register());
1348     } else if (to_reg-&gt;is_double_cpu()) {
1349       // int to int moves
1350       __ mov(from_reg-&gt;as_register(), to_reg-&gt;as_register_lo());
1351     } else {
1352       // int to int moves
1353       __ mov(from_reg-&gt;as_register(), to_reg-&gt;as_register());
1354     }
1355   } else {
1356     ShouldNotReachHere();
1357   }
<span class="line-modified">1358   if (to_reg-&gt;type() == T_OBJECT || to_reg-&gt;type() == T_ARRAY) {</span>
1359     __ verify_oop(to_reg-&gt;as_register());
1360   }
1361 }
1362 
1363 void LIR_Assembler::reg2mem(LIR_Opr from_reg, LIR_Opr dest, BasicType type,
1364                             LIR_PatchCode patch_code, CodeEmitInfo* info, bool pop_fpu_stack,
1365                             bool wide, bool unaligned) {
1366   assert(type != T_METADATA, &quot;store of metadata ptr not supported&quot;);
1367   LIR_Address* addr = dest-&gt;as_address_ptr();
1368 
1369   Register src = addr-&gt;base()-&gt;as_pointer_register();
1370   Register disp_reg = noreg;
1371   int disp_value = addr-&gt;disp();
1372   bool needs_patching = (patch_code != lir_patch_none);
1373 
1374   if (addr-&gt;base()-&gt;is_oop_register()) {
1375     __ verify_oop(src);
1376   }
1377 
1378   PatchingStub* patch = NULL;
</pre>
<hr />
<pre>
1490               __ cmp(opr1-&gt;as_register(), con);
1491             } else {
1492               __ set(con, O7);
1493               __ cmp(opr1-&gt;as_register(), O7);
1494             }
1495           }
1496           break;
1497 
1498         case T_OBJECT:
1499           // there are only equal/notequal comparisions on objects
1500           { jobject con = opr2-&gt;as_constant_ptr()-&gt;as_jobject();
1501             if (con == NULL) {
1502               __ cmp(opr1-&gt;as_register(), 0);
1503             } else {
1504               jobject2reg(con, O7);
1505               __ cmp(opr1-&gt;as_register(), O7);
1506             }
1507           }
1508           break;
1509 












1510         default:
1511           ShouldNotReachHere();
1512           break;
1513       }
1514     } else {
1515       if (opr2-&gt;is_address()) {
1516         LIR_Address * addr = opr2-&gt;as_address_ptr();
1517         BasicType type = addr-&gt;type();
1518         if ( type == T_OBJECT ) __ ld_ptr(as_Address(addr), O7);
1519         else                    __ ld(as_Address(addr), O7);
1520         __ cmp(opr1-&gt;as_register(), O7);
1521       } else {
1522         __ cmp(opr1-&gt;as_register(), opr2-&gt;as_register());
1523       }
1524     }
1525   } else if (opr1-&gt;is_double_cpu()) {
1526     Register xlo = opr1-&gt;as_register_lo();
1527     Register xhi = opr1-&gt;as_register_hi();
1528     if (opr2-&gt;is_constant() &amp;&amp; opr2-&gt;as_jlong() == 0) {
1529       assert(condition == lir_cond_equal || condition == lir_cond_notEqual, &quot;only handles these cases&quot;);
</pre>
<hr />
<pre>
1701         case lir_sub:  __ sub  (lreg, simm13, res); break;
1702         case lir_mul:  __ mulx (lreg, simm13, res); break;
1703         default: ShouldNotReachHere();
1704       }
1705     } else {
1706       Register lreg = left-&gt;as_pointer_register();
1707       Register res  = dest-&gt;as_register_lo();
1708       long con = right-&gt;as_constant_ptr()-&gt;as_jlong();
1709       assert(Assembler::is_simm13(con), &quot;must be simm13&quot;);
1710 
1711       switch (code) {
1712         case lir_add:  __ add  (lreg, (int)con, res); break;
1713         case lir_sub:  __ sub  (lreg, (int)con, res); break;
1714         case lir_mul:  __ mulx (lreg, (int)con, res); break;
1715         default: ShouldNotReachHere();
1716       }
1717     }
1718   }
1719 }
1720 
<span class="line-removed">1721 </span>
<span class="line-removed">1722 void LIR_Assembler::fpop() {</span>
<span class="line-removed">1723   // do nothing</span>
<span class="line-removed">1724 }</span>
<span class="line-removed">1725 </span>
<span class="line-removed">1726 </span>
1727 void LIR_Assembler::intrinsic_op(LIR_Code code, LIR_Opr value, LIR_Opr thread, LIR_Opr dest, LIR_Op* op) {
1728   switch (code) {
1729     case lir_tan: {
1730       assert(thread-&gt;is_valid(), &quot;preserve the thread object for performance reasons&quot;);
1731       assert(dest-&gt;as_double_reg() == F0, &quot;the result will be in f0/f1&quot;);
1732       break;
1733     }
1734     case lir_sqrt: {
1735       assert(!thread-&gt;is_valid(), &quot;there is no need for a thread_reg for dsqrt&quot;);
1736       FloatRegister src_reg = value-&gt;as_double_reg();
1737       FloatRegister dst_reg = dest-&gt;as_double_reg();
1738       __ fsqrt(FloatRegisterImpl::D, src_reg, dst_reg);
1739       break;
1740     }
1741     case lir_abs: {
1742       assert(!thread-&gt;is_valid(), &quot;there is no need for a thread_reg for fabs&quot;);
1743       FloatRegister src_reg = value-&gt;as_double_reg();
1744       FloatRegister dst_reg = dest-&gt;as_double_reg();
1745       __ fabs(FloatRegisterImpl::D, src_reg, dst_reg);
1746       break;
</pre>
<hr />
<pre>
2274                      op-&gt;tmp2()-&gt;as_register(),
2275                      op-&gt;tmp3()-&gt;as_register(),
2276                      op-&gt;header_size(),
2277                      op-&gt;object_size(),
2278                      op-&gt;klass()-&gt;as_register(),
2279                      *op-&gt;stub()-&gt;entry());
2280   __ bind(*op-&gt;stub()-&gt;continuation());
2281   __ verify_oop(op-&gt;obj()-&gt;as_register());
2282 }
2283 
2284 
2285 void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
2286   assert(op-&gt;tmp1()-&gt;as_register()  == G1 &amp;&amp;
2287          op-&gt;tmp2()-&gt;as_register()  == G3 &amp;&amp;
2288          op-&gt;tmp3()-&gt;as_register()  == G4 &amp;&amp;
2289          op-&gt;tmp4()-&gt;as_register()  == O1 &amp;&amp;
2290          op-&gt;klass()-&gt;as_register() == G5, &quot;must be&quot;);
2291 
2292   __ signx(op-&gt;len()-&gt;as_register());
2293   if (UseSlowPath ||
<span class="line-modified">2294       (!UseFastNewObjectArray &amp;&amp; (op-&gt;type() == T_OBJECT || op-&gt;type() == T_ARRAY)) ||</span>
<span class="line-modified">2295       (!UseFastNewTypeArray   &amp;&amp; (op-&gt;type() != T_OBJECT &amp;&amp; op-&gt;type() != T_ARRAY))) {</span>
2296     __ br(Assembler::always, false, Assembler::pt, *op-&gt;stub()-&gt;entry());
2297     __ delayed()-&gt;nop();
2298   } else {
2299     __ allocate_array(op-&gt;obj()-&gt;as_register(),
2300                       op-&gt;len()-&gt;as_register(),
2301                       op-&gt;tmp1()-&gt;as_register(),
2302                       op-&gt;tmp2()-&gt;as_register(),
2303                       op-&gt;tmp3()-&gt;as_register(),
2304                       arrayOopDesc::header_size(op-&gt;type()),
2305                       type2aelembytes(op-&gt;type()),
2306                       op-&gt;klass()-&gt;as_register(),
2307                       *op-&gt;stub()-&gt;entry());
2308   }
2309   __ bind(*op-&gt;stub()-&gt;continuation());
2310 }
2311 
2312 
2313 void LIR_Assembler::type_profile_helper(Register mdo, int mdo_offset_bias,
2314                                         ciMethodData *md, ciProfileData *data,
2315                                         Register recv, Register tmp1, Label* update_done) {
</pre>
<hr />
<pre>
2627     Register t2 = op-&gt;tmp2()-&gt;as_register();
2628     __ mov(cmp_value, t1);
2629     __ mov(new_value, t2);
2630     if (op-&gt;code() == lir_cas_obj) {
2631       if (UseCompressedOops) {
2632         __ encode_heap_oop(t1);
2633         __ encode_heap_oop(t2);
2634         __ cas(addr, t1, t2);
2635       } else {
2636         __ cas_ptr(addr, t1, t2);
2637       }
2638     } else {
2639       __ cas(addr, t1, t2);
2640     }
2641     __ cmp(t1, t2);
2642   } else {
2643     Unimplemented();
2644   }
2645 }
2646 
<span class="line-removed">2647 void LIR_Assembler::set_24bit_FPU() {</span>
<span class="line-removed">2648   Unimplemented();</span>
<span class="line-removed">2649 }</span>
<span class="line-removed">2650 </span>
<span class="line-removed">2651 </span>
<span class="line-removed">2652 void LIR_Assembler::reset_FPU() {</span>
<span class="line-removed">2653   Unimplemented();</span>
<span class="line-removed">2654 }</span>
<span class="line-removed">2655 </span>
<span class="line-removed">2656 </span>
2657 void LIR_Assembler::breakpoint() {
2658   __ breakpoint_trap();
2659 }
2660 
2661 
2662 void LIR_Assembler::push(LIR_Opr opr) {
2663   Unimplemented();
2664 }
2665 
2666 
2667 void LIR_Assembler::pop(LIR_Opr opr) {
2668   Unimplemented();
2669 }
2670 
2671 
2672 void LIR_Assembler::monitor_address(int monitor_no, LIR_Opr dst_opr) {
2673   Address mon_addr = frame_map()-&gt;address_for_monitor_lock(monitor_no);
2674   Register dst = dst_opr-&gt;as_register();
2675   Register reg = mon_addr.base();
2676   int offset = mon_addr.disp();
</pre>
<hr />
<pre>
3026 
3027 void LIR_Assembler::negate(LIR_Opr left, LIR_Opr dest, LIR_Opr tmp) {
3028   // tmp must be unused
3029   assert(tmp-&gt;is_illegal(), &quot;wasting a register if tmp is allocated&quot;);
3030   assert(left-&gt;is_register(), &quot;can only handle registers&quot;);
3031 
3032   if (left-&gt;is_single_cpu()) {
3033     __ neg(left-&gt;as_register(), dest-&gt;as_register());
3034   } else if (left-&gt;is_single_fpu()) {
3035     __ fneg(FloatRegisterImpl::S, left-&gt;as_float_reg(), dest-&gt;as_float_reg());
3036   } else if (left-&gt;is_double_fpu()) {
3037     __ fneg(FloatRegisterImpl::D, left-&gt;as_double_reg(), dest-&gt;as_double_reg());
3038   } else {
3039     assert (left-&gt;is_double_cpu(), &quot;Must be a long&quot;);
3040     Register Rlow = left-&gt;as_register_lo();
3041     Register Rhi = left-&gt;as_register_hi();
3042     __ sub(G0, Rlow, dest-&gt;as_register_lo());
3043   }
3044 }
3045 
<span class="line-removed">3046 </span>
<span class="line-removed">3047 void LIR_Assembler::fxch(int i) {</span>
<span class="line-removed">3048   Unimplemented();</span>
<span class="line-removed">3049 }</span>
<span class="line-removed">3050 </span>
<span class="line-removed">3051 void LIR_Assembler::fld(int i) {</span>
<span class="line-removed">3052   Unimplemented();</span>
<span class="line-removed">3053 }</span>
<span class="line-removed">3054 </span>
<span class="line-removed">3055 void LIR_Assembler::ffree(int i) {</span>
<span class="line-removed">3056   Unimplemented();</span>
<span class="line-removed">3057 }</span>
<span class="line-removed">3058 </span>
3059 void LIR_Assembler::rt_call(LIR_Opr result, address dest,
3060                             const LIR_OprList* args, LIR_Opr tmp, CodeEmitInfo* info) {
3061 
3062   // if tmp is invalid, then the function being called doesn&#39;t destroy the thread
3063   if (tmp-&gt;is_valid()) {
3064     __ save_thread(tmp-&gt;as_pointer_register());
3065   }
3066   __ call(dest, relocInfo::runtime_call_type);
3067   __ delayed()-&gt;nop();
3068   if (info != NULL) {
3069     add_call_info_here(info);
3070   }
3071   if (tmp-&gt;is_valid()) {
3072     __ restore_thread(tmp-&gt;as_pointer_register());
3073   }
3074 
3075 #ifdef ASSERT
3076   __ verify_thread();
3077 #endif // ASSERT
3078 }
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/macroAssembler.inline.hpp&quot;
  27 #include &quot;c1/c1_Compilation.hpp&quot;
  28 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  29 #include &quot;c1/c1_MacroAssembler.hpp&quot;
  30 #include &quot;c1/c1_Runtime1.hpp&quot;
  31 #include &quot;c1/c1_ValueStack.hpp&quot;
  32 #include &quot;ci/ciArrayKlass.hpp&quot;
  33 #include &quot;ci/ciInstance.hpp&quot;


  34 #include &quot;gc/shared/collectedHeap.hpp&quot;
<span class="line-added">  35 #include &quot;memory/universe.hpp&quot;</span>
  36 #include &quot;nativeInst_sparc.hpp&quot;
  37 #include &quot;oops/objArrayKlass.hpp&quot;
  38 #include &quot;runtime/frame.inline.hpp&quot;
  39 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  40 #include &quot;runtime/jniHandles.inline.hpp&quot;
  41 #include &quot;runtime/safepointMechanism.inline.hpp&quot;
  42 #include &quot;runtime/sharedRuntime.hpp&quot;
<span class="line-added">  43 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  44 
  45 #define __ _masm-&gt;
  46 
  47 
  48 //------------------------------------------------------------
  49 
  50 
  51 bool LIR_Assembler::is_small_constant(LIR_Opr opr) {
  52   if (opr-&gt;is_constant()) {
  53     LIR_Const* constant = opr-&gt;as_constant_ptr();
  54     switch (constant-&gt;type()) {
  55       case T_INT: {
  56         jint value = constant-&gt;as_jint();
  57         return Assembler::is_simm13(value);
  58       }
  59 
  60       default:
  61         return false;
  62     }
  63   }
</pre>
<hr />
<pre>
  89         // this works around a problem where moves with the same src and dst
  90         // end up in the delay slot and then the assembler swallows the mov
  91         // since it has no effect and then it complains because the delay slot
  92         // is empty.  returning false stops the optimizer from putting this in
  93         // the delay slot
  94         return false;
  95       }
  96 
  97       // don&#39;t put moves involving oops into the delay slot since the VerifyOops code
  98       // will make it much larger than a single instruction.
  99       if (VerifyOops) {
 100         return false;
 101       }
 102 
 103       if (src-&gt;is_double_cpu() || dst-&gt;is_double_cpu() || op1-&gt;patch_code() != lir_patch_none ||
 104           ((src-&gt;is_double_fpu() || dst-&gt;is_double_fpu()) &amp;&amp; op1-&gt;move_kind() != lir_move_normal)) {
 105         return false;
 106       }
 107 
 108       if (UseCompressedOops) {
<span class="line-modified"> 109         if (dst-&gt;is_address() &amp;&amp; !dst-&gt;is_stack() &amp;&amp; is_reference_type(dst-&gt;type())) return false;</span>
<span class="line-modified"> 110         if (src-&gt;is_address() &amp;&amp; !src-&gt;is_stack() &amp;&amp; is_reference_type(src-&gt;type())) return false;</span>
 111       }
 112 
 113       if (UseCompressedClassPointers) {
 114         if (src-&gt;is_address() &amp;&amp; !src-&gt;is_stack() &amp;&amp; src-&gt;type() == T_ADDRESS &amp;&amp;
 115             src-&gt;as_address_ptr()-&gt;disp() == oopDesc::klass_offset_in_bytes()) return false;
 116       }
 117 
 118       if (dst-&gt;is_register()) {
 119         if (src-&gt;is_address() &amp;&amp; Assembler::is_simm13(src-&gt;as_address_ptr()-&gt;disp())) {
 120           return !PatchALot;
 121         } else if (src-&gt;is_single_stack()) {
 122           return true;
 123         }
 124       }
 125 
 126       if (src-&gt;is_register()) {
 127         if (dst-&gt;is_address() &amp;&amp; Assembler::is_simm13(dst-&gt;as_address_ptr()-&gt;disp())) {
 128           return !PatchALot;
 129         } else if (dst-&gt;is_single_stack()) {
 130           return true;
</pre>
<hr />
<pre>
 154 
 155 LIR_Opr LIR_Assembler::osrBufferPointer() {
 156   return FrameMap::I0_opr;
 157 }
 158 
 159 
 160 int LIR_Assembler::initial_frame_size_in_bytes() const {
 161   return in_bytes(frame_map()-&gt;framesize_in_bytes());
 162 }
 163 
 164 
 165 // inline cache check: the inline cached class is in G5_inline_cache_reg(G5);
 166 // we fetch the class of the receiver (O0) and compare it with the cached class.
 167 // If they do not match we jump to slow case.
 168 int LIR_Assembler::check_icache() {
 169   int offset = __ offset();
 170   __ inline_cache_check(O0, G5_inline_cache_reg);
 171   return offset;
 172 }
 173 
<span class="line-added"> 174 void LIR_Assembler::clinit_barrier(ciMethod* method) {</span>
<span class="line-added"> 175   ShouldNotReachHere(); // not implemented</span>
<span class="line-added"> 176 }</span>
 177 
 178 void LIR_Assembler::osr_entry() {
 179   // On-stack-replacement entry sequence (interpreter frame layout described in interpreter_sparc.cpp):
 180   //
 181   //   1. Create a new compiled activation.
 182   //   2. Initialize local variables in the compiled activation.  The expression stack must be empty
 183   //      at the osr_bci; it is not initialized.
 184   //   3. Jump to the continuation address in compiled code to resume execution.
 185 
 186   // OSR entry point
 187   offsets()-&gt;set_value(CodeOffsets::OSR_Entry, code_offset());
 188   BlockBegin* osr_entry = compilation()-&gt;hir()-&gt;osr_entry();
 189   ValueStack* entry_state = osr_entry-&gt;end()-&gt;state();
 190   int number_of_locks = entry_state-&gt;locks_size();
 191 
 192   // Create a frame for the compiled activation.
 193   __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());
 194 
 195   // OSR buffer is
 196   //
</pre>
<hr />
<pre>
 391   }
 392 
 393   int offset = code_offset();
 394   AddressLiteral deopt_blob(SharedRuntime::deopt_blob()-&gt;unpack());
 395   __ JUMP(deopt_blob, G3_scratch, 0); // sethi;jmp
 396   __ delayed()-&gt;nop();
 397   guarantee(code_offset() - offset &lt;= deopt_handler_size(), &quot;overflow&quot;);
 398   __ end_a_stub();
 399 
 400   return offset;
 401 }
 402 
 403 
 404 void LIR_Assembler::jobject2reg(jobject o, Register reg) {
 405   if (o == NULL) {
 406     __ set(NULL_WORD, reg);
 407   } else {
 408 #ifdef ASSERT
 409     {
 410       ThreadInVMfromNative tiv(JavaThread::current());
<span class="line-modified"> 411       assert(Universe::heap()-&gt;is_in(JNIHandles::resolve(o)), &quot;should be real oop&quot;);</span>
 412     }
 413 #endif
 414     int oop_index = __ oop_recorder()-&gt;find_index(o);
 415     RelocationHolder rspec = oop_Relocation::spec(oop_index);
 416     __ set(NULL_WORD, reg, rspec); // Will be set when the nmethod is created
 417   }
 418 }
 419 
 420 
 421 void LIR_Assembler::jobject2reg_with_patching(Register reg, CodeEmitInfo *info) {
 422   // Allocate a new index in table to hold the object once it&#39;s been patched
 423   int oop_index = __ oop_recorder()-&gt;allocate_oop_index(NULL);
 424   PatchingStub* patch = new PatchingStub(_masm, patching_id(info), oop_index);
 425 
 426   AddressLiteral addrlit(NULL, oop_Relocation::spec(oop_index));
 427   assert(addrlit.rspec().type() == relocInfo::oop_type, &quot;must be an oop reloc&quot;);
 428   // It may not seem necessary to use a sethi/add pair to load a NULL into dest, but the
 429   // NULL will be dynamically patched later and the patched value may be large.  We must
 430   // therefore generate the sethi/add as a placeholders
 431   __ patchable_set(addrlit, reg);
</pre>
<hr />
<pre>
 710   } else {
 711     // This will generate 2 instructions
 712     __ set(op-&gt;vtable_offset(), G5_method);
 713     // ld_ptr, set_hi, set
 714     __ ld_ptr(G3_scratch, G5_method, G5_method);
 715   }
 716   __ ld_ptr(G5_method, Method::from_compiled_offset(), G3_scratch);
 717   __ callr(G3_scratch, G0);
 718   // the peephole pass fills the delay slot
 719 }
 720 
 721 int LIR_Assembler::store(LIR_Opr from_reg, Register base, int offset, BasicType type, bool wide, bool unaligned) {
 722   int store_offset;
 723   if (!Assembler::is_simm13(offset + (type == T_LONG) ? wordSize : 0)) {
 724     assert(base != O7, &quot;destroying register&quot;);
 725     assert(!unaligned, &quot;can&#39;t handle this&quot;);
 726     // for offsets larger than a simm13 we setup the offset in O7
 727     __ set(offset, O7);
 728     store_offset = store(from_reg, base, O7, type, wide);
 729   } else {
<span class="line-modified"> 730     if (is_reference_type(type)) {</span>
 731       __ verify_oop(from_reg-&gt;as_register());
 732     }
 733     store_offset = code_offset();
 734     switch (type) {
 735       case T_BOOLEAN: // fall through
 736       case T_BYTE  : __ stb(from_reg-&gt;as_register(), base, offset); break;
 737       case T_CHAR  : __ sth(from_reg-&gt;as_register(), base, offset); break;
 738       case T_SHORT : __ sth(from_reg-&gt;as_register(), base, offset); break;
 739       case T_INT   : __ stw(from_reg-&gt;as_register(), base, offset); break;
 740       case T_LONG  :
 741         if (unaligned || PatchALot) {
 742           // Don&#39;t use O7 here because it may be equal to &#39;base&#39; (see LIR_Assembler::reg2mem)
 743           assert(G3_scratch != base, &quot;can&#39;t handle this&quot;);
 744           assert(G3_scratch != from_reg-&gt;as_register_lo(), &quot;can&#39;t handle this&quot;);
 745           __ srax(from_reg-&gt;as_register_lo(), 32, G3_scratch);
 746           __ stw(from_reg-&gt;as_register_lo(), base, offset + lo_word_offset_in_bytes);
 747           __ stw(G3_scratch,                 base, offset + hi_word_offset_in_bytes);
 748         } else {
 749           __ stx(from_reg-&gt;as_register_lo(), base, offset);
 750         }
</pre>
<hr />
<pre>
 771         {
 772           FloatRegister reg = from_reg-&gt;as_double_reg();
 773           // split unaligned stores
 774           if (unaligned || PatchALot) {
 775             assert(Assembler::is_simm13(offset + 4), &quot;must be&quot;);
 776             __ stf(FloatRegisterImpl::S, reg-&gt;successor(), base, offset + 4);
 777             __ stf(FloatRegisterImpl::S, reg,              base, offset);
 778           } else {
 779             __ stf(FloatRegisterImpl::D, reg, base, offset);
 780           }
 781           break;
 782         }
 783       default      : ShouldNotReachHere();
 784     }
 785   }
 786   return store_offset;
 787 }
 788 
 789 
 790 int LIR_Assembler::store(LIR_Opr from_reg, Register base, Register disp, BasicType type, bool wide) {
<span class="line-modified"> 791   if (is_reference_type(type)) {</span>
 792     __ verify_oop(from_reg-&gt;as_register());
 793   }
 794   int store_offset = code_offset();
 795   switch (type) {
 796     case T_BOOLEAN: // fall through
 797     case T_BYTE  : __ stb(from_reg-&gt;as_register(), base, disp); break;
 798     case T_CHAR  : __ sth(from_reg-&gt;as_register(), base, disp); break;
 799     case T_SHORT : __ sth(from_reg-&gt;as_register(), base, disp); break;
 800     case T_INT   : __ stw(from_reg-&gt;as_register(), base, disp); break;
 801     case T_LONG  :
 802       __ stx(from_reg-&gt;as_register_lo(), base, disp);
 803       break;
 804     case T_ADDRESS:
 805       __ st_ptr(from_reg-&gt;as_register(), base, disp);
 806       break;
 807     case T_ARRAY : // fall through
 808     case T_OBJECT:
 809       {
 810         if (UseCompressedOops &amp;&amp; !wide) {
 811           __ encode_heap_oop(from_reg-&gt;as_register(), G3_scratch);
</pre>
<hr />
<pre>
 871           } else {
 872             __ ld_ptr(base, offset, to_reg-&gt;as_register());
 873           }
 874           break;
 875         }
 876       case T_FLOAT:  __ ldf(FloatRegisterImpl::S, base, offset, to_reg-&gt;as_float_reg()); break;
 877       case T_DOUBLE:
 878         {
 879           FloatRegister reg = to_reg-&gt;as_double_reg();
 880           // split unaligned loads
 881           if (unaligned || PatchALot) {
 882             __ ldf(FloatRegisterImpl::S, base, offset + 4, reg-&gt;successor());
 883             __ ldf(FloatRegisterImpl::S, base, offset,     reg);
 884           } else {
 885             __ ldf(FloatRegisterImpl::D, base, offset, to_reg-&gt;as_double_reg());
 886           }
 887           break;
 888         }
 889       default      : ShouldNotReachHere();
 890     }
<span class="line-modified"> 891     if (is_reference_type(type)) {</span>
 892       __ verify_oop(to_reg-&gt;as_register());
 893     }
 894   }
 895   return load_offset;
 896 }
 897 
 898 
 899 int LIR_Assembler::load(Register base, Register disp, LIR_Opr to_reg, BasicType type, bool wide) {
 900   int load_offset = code_offset();
 901   switch(type) {
 902     case T_BOOLEAN: // fall through
 903     case T_BYTE  :  __ ldsb(base, disp, to_reg-&gt;as_register()); break;
 904     case T_CHAR  :  __ lduh(base, disp, to_reg-&gt;as_register()); break;
 905     case T_SHORT :  __ ldsh(base, disp, to_reg-&gt;as_register()); break;
 906     case T_INT   :  __ ld(base, disp, to_reg-&gt;as_register()); break;
 907     case T_ADDRESS: __ ld_ptr(base, disp, to_reg-&gt;as_register()); break;
 908     case T_ARRAY : // fall through
 909     case T_OBJECT:
 910       {
 911           if (UseCompressedOops &amp;&amp; !wide) {
 912             __ lduw(base, disp, to_reg-&gt;as_register());
 913             __ decode_heap_oop(to_reg-&gt;as_register());
 914           } else {
 915             __ ld_ptr(base, disp, to_reg-&gt;as_register());
 916           }
 917           break;
 918       }
 919     case T_FLOAT:  __ ldf(FloatRegisterImpl::S, base, disp, to_reg-&gt;as_float_reg()); break;
 920     case T_DOUBLE: __ ldf(FloatRegisterImpl::D, base, disp, to_reg-&gt;as_double_reg()); break;
 921     case T_LONG  :
 922       __ ldx(base, disp, to_reg-&gt;as_register_lo());
 923       break;
 924     default      : ShouldNotReachHere();
 925   }
<span class="line-modified"> 926   if (is_reference_type(type)) {</span>
 927     __ verify_oop(to_reg-&gt;as_register());
 928   }
 929   return load_offset;
 930 }
 931 
 932 void LIR_Assembler::const2stack(LIR_Opr src, LIR_Opr dest) {
 933   LIR_Const* c = src-&gt;as_constant_ptr();
 934   switch (c-&gt;type()) {
 935     case T_INT:
 936     case T_FLOAT: {
 937       Register src_reg = O7;
 938       int value = c-&gt;as_jint_bits();
 939       if (value == 0) {
 940         src_reg = G0;
 941       } else {
 942         __ set(value, O7);
 943       }
 944       Address addr = frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix());
 945       __ stw(src_reg, addr.base(), addr.disp());
 946       break;
</pre>
<hr />
<pre>
1341       assert(to_reg-&gt;is_double_fpu(), &quot;should match&quot;);
1342       __ fmov(FloatRegisterImpl::D, from_reg-&gt;as_double_reg(), to_reg-&gt;as_double_reg());
1343     } else {
1344       // float to float moves
1345       assert(to_reg-&gt;is_single_fpu(), &quot;should match&quot;);
1346       __ fmov(FloatRegisterImpl::S, from_reg-&gt;as_float_reg(), to_reg-&gt;as_float_reg());
1347     }
1348   } else if (!from_reg-&gt;is_float_kind() &amp;&amp; !to_reg-&gt;is_float_kind()) {
1349     if (from_reg-&gt;is_double_cpu()) {
1350       __ mov(from_reg-&gt;as_pointer_register(), to_reg-&gt;as_pointer_register());
1351     } else if (to_reg-&gt;is_double_cpu()) {
1352       // int to int moves
1353       __ mov(from_reg-&gt;as_register(), to_reg-&gt;as_register_lo());
1354     } else {
1355       // int to int moves
1356       __ mov(from_reg-&gt;as_register(), to_reg-&gt;as_register());
1357     }
1358   } else {
1359     ShouldNotReachHere();
1360   }
<span class="line-modified">1361   if (is_reference_type(to_reg-&gt;type())) {</span>
1362     __ verify_oop(to_reg-&gt;as_register());
1363   }
1364 }
1365 
1366 void LIR_Assembler::reg2mem(LIR_Opr from_reg, LIR_Opr dest, BasicType type,
1367                             LIR_PatchCode patch_code, CodeEmitInfo* info, bool pop_fpu_stack,
1368                             bool wide, bool unaligned) {
1369   assert(type != T_METADATA, &quot;store of metadata ptr not supported&quot;);
1370   LIR_Address* addr = dest-&gt;as_address_ptr();
1371 
1372   Register src = addr-&gt;base()-&gt;as_pointer_register();
1373   Register disp_reg = noreg;
1374   int disp_value = addr-&gt;disp();
1375   bool needs_patching = (patch_code != lir_patch_none);
1376 
1377   if (addr-&gt;base()-&gt;is_oop_register()) {
1378     __ verify_oop(src);
1379   }
1380 
1381   PatchingStub* patch = NULL;
</pre>
<hr />
<pre>
1493               __ cmp(opr1-&gt;as_register(), con);
1494             } else {
1495               __ set(con, O7);
1496               __ cmp(opr1-&gt;as_register(), O7);
1497             }
1498           }
1499           break;
1500 
1501         case T_OBJECT:
1502           // there are only equal/notequal comparisions on objects
1503           { jobject con = opr2-&gt;as_constant_ptr()-&gt;as_jobject();
1504             if (con == NULL) {
1505               __ cmp(opr1-&gt;as_register(), 0);
1506             } else {
1507               jobject2reg(con, O7);
1508               __ cmp(opr1-&gt;as_register(), O7);
1509             }
1510           }
1511           break;
1512 
<span class="line-added">1513         case T_METADATA:</span>
<span class="line-added">1514           // We only need, for now, comparison with NULL for metadata.</span>
<span class="line-added">1515           { assert(condition == lir_cond_equal || condition == lir_cond_notEqual, &quot;oops&quot;);</span>
<span class="line-added">1516             Metadata* m = opr2-&gt;as_constant_ptr()-&gt;as_metadata();</span>
<span class="line-added">1517             if (m == NULL) {</span>
<span class="line-added">1518               __ cmp(opr1-&gt;as_register(), 0);</span>
<span class="line-added">1519             } else {</span>
<span class="line-added">1520               ShouldNotReachHere();</span>
<span class="line-added">1521             }</span>
<span class="line-added">1522           }</span>
<span class="line-added">1523           break;</span>
<span class="line-added">1524 </span>
1525         default:
1526           ShouldNotReachHere();
1527           break;
1528       }
1529     } else {
1530       if (opr2-&gt;is_address()) {
1531         LIR_Address * addr = opr2-&gt;as_address_ptr();
1532         BasicType type = addr-&gt;type();
1533         if ( type == T_OBJECT ) __ ld_ptr(as_Address(addr), O7);
1534         else                    __ ld(as_Address(addr), O7);
1535         __ cmp(opr1-&gt;as_register(), O7);
1536       } else {
1537         __ cmp(opr1-&gt;as_register(), opr2-&gt;as_register());
1538       }
1539     }
1540   } else if (opr1-&gt;is_double_cpu()) {
1541     Register xlo = opr1-&gt;as_register_lo();
1542     Register xhi = opr1-&gt;as_register_hi();
1543     if (opr2-&gt;is_constant() &amp;&amp; opr2-&gt;as_jlong() == 0) {
1544       assert(condition == lir_cond_equal || condition == lir_cond_notEqual, &quot;only handles these cases&quot;);
</pre>
<hr />
<pre>
1716         case lir_sub:  __ sub  (lreg, simm13, res); break;
1717         case lir_mul:  __ mulx (lreg, simm13, res); break;
1718         default: ShouldNotReachHere();
1719       }
1720     } else {
1721       Register lreg = left-&gt;as_pointer_register();
1722       Register res  = dest-&gt;as_register_lo();
1723       long con = right-&gt;as_constant_ptr()-&gt;as_jlong();
1724       assert(Assembler::is_simm13(con), &quot;must be simm13&quot;);
1725 
1726       switch (code) {
1727         case lir_add:  __ add  (lreg, (int)con, res); break;
1728         case lir_sub:  __ sub  (lreg, (int)con, res); break;
1729         case lir_mul:  __ mulx (lreg, (int)con, res); break;
1730         default: ShouldNotReachHere();
1731       }
1732     }
1733   }
1734 }
1735 






1736 void LIR_Assembler::intrinsic_op(LIR_Code code, LIR_Opr value, LIR_Opr thread, LIR_Opr dest, LIR_Op* op) {
1737   switch (code) {
1738     case lir_tan: {
1739       assert(thread-&gt;is_valid(), &quot;preserve the thread object for performance reasons&quot;);
1740       assert(dest-&gt;as_double_reg() == F0, &quot;the result will be in f0/f1&quot;);
1741       break;
1742     }
1743     case lir_sqrt: {
1744       assert(!thread-&gt;is_valid(), &quot;there is no need for a thread_reg for dsqrt&quot;);
1745       FloatRegister src_reg = value-&gt;as_double_reg();
1746       FloatRegister dst_reg = dest-&gt;as_double_reg();
1747       __ fsqrt(FloatRegisterImpl::D, src_reg, dst_reg);
1748       break;
1749     }
1750     case lir_abs: {
1751       assert(!thread-&gt;is_valid(), &quot;there is no need for a thread_reg for fabs&quot;);
1752       FloatRegister src_reg = value-&gt;as_double_reg();
1753       FloatRegister dst_reg = dest-&gt;as_double_reg();
1754       __ fabs(FloatRegisterImpl::D, src_reg, dst_reg);
1755       break;
</pre>
<hr />
<pre>
2283                      op-&gt;tmp2()-&gt;as_register(),
2284                      op-&gt;tmp3()-&gt;as_register(),
2285                      op-&gt;header_size(),
2286                      op-&gt;object_size(),
2287                      op-&gt;klass()-&gt;as_register(),
2288                      *op-&gt;stub()-&gt;entry());
2289   __ bind(*op-&gt;stub()-&gt;continuation());
2290   __ verify_oop(op-&gt;obj()-&gt;as_register());
2291 }
2292 
2293 
2294 void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
2295   assert(op-&gt;tmp1()-&gt;as_register()  == G1 &amp;&amp;
2296          op-&gt;tmp2()-&gt;as_register()  == G3 &amp;&amp;
2297          op-&gt;tmp3()-&gt;as_register()  == G4 &amp;&amp;
2298          op-&gt;tmp4()-&gt;as_register()  == O1 &amp;&amp;
2299          op-&gt;klass()-&gt;as_register() == G5, &quot;must be&quot;);
2300 
2301   __ signx(op-&gt;len()-&gt;as_register());
2302   if (UseSlowPath ||
<span class="line-modified">2303       (!UseFastNewObjectArray &amp;&amp; is_reference_type(op-&gt;type())) ||</span>
<span class="line-modified">2304       (!UseFastNewTypeArray   &amp;&amp; !is_reference_type(op-&gt;type()))) {</span>
2305     __ br(Assembler::always, false, Assembler::pt, *op-&gt;stub()-&gt;entry());
2306     __ delayed()-&gt;nop();
2307   } else {
2308     __ allocate_array(op-&gt;obj()-&gt;as_register(),
2309                       op-&gt;len()-&gt;as_register(),
2310                       op-&gt;tmp1()-&gt;as_register(),
2311                       op-&gt;tmp2()-&gt;as_register(),
2312                       op-&gt;tmp3()-&gt;as_register(),
2313                       arrayOopDesc::header_size(op-&gt;type()),
2314                       type2aelembytes(op-&gt;type()),
2315                       op-&gt;klass()-&gt;as_register(),
2316                       *op-&gt;stub()-&gt;entry());
2317   }
2318   __ bind(*op-&gt;stub()-&gt;continuation());
2319 }
2320 
2321 
2322 void LIR_Assembler::type_profile_helper(Register mdo, int mdo_offset_bias,
2323                                         ciMethodData *md, ciProfileData *data,
2324                                         Register recv, Register tmp1, Label* update_done) {
</pre>
<hr />
<pre>
2636     Register t2 = op-&gt;tmp2()-&gt;as_register();
2637     __ mov(cmp_value, t1);
2638     __ mov(new_value, t2);
2639     if (op-&gt;code() == lir_cas_obj) {
2640       if (UseCompressedOops) {
2641         __ encode_heap_oop(t1);
2642         __ encode_heap_oop(t2);
2643         __ cas(addr, t1, t2);
2644       } else {
2645         __ cas_ptr(addr, t1, t2);
2646       }
2647     } else {
2648       __ cas(addr, t1, t2);
2649     }
2650     __ cmp(t1, t2);
2651   } else {
2652     Unimplemented();
2653   }
2654 }
2655 










2656 void LIR_Assembler::breakpoint() {
2657   __ breakpoint_trap();
2658 }
2659 
2660 
2661 void LIR_Assembler::push(LIR_Opr opr) {
2662   Unimplemented();
2663 }
2664 
2665 
2666 void LIR_Assembler::pop(LIR_Opr opr) {
2667   Unimplemented();
2668 }
2669 
2670 
2671 void LIR_Assembler::monitor_address(int monitor_no, LIR_Opr dst_opr) {
2672   Address mon_addr = frame_map()-&gt;address_for_monitor_lock(monitor_no);
2673   Register dst = dst_opr-&gt;as_register();
2674   Register reg = mon_addr.base();
2675   int offset = mon_addr.disp();
</pre>
<hr />
<pre>
3025 
3026 void LIR_Assembler::negate(LIR_Opr left, LIR_Opr dest, LIR_Opr tmp) {
3027   // tmp must be unused
3028   assert(tmp-&gt;is_illegal(), &quot;wasting a register if tmp is allocated&quot;);
3029   assert(left-&gt;is_register(), &quot;can only handle registers&quot;);
3030 
3031   if (left-&gt;is_single_cpu()) {
3032     __ neg(left-&gt;as_register(), dest-&gt;as_register());
3033   } else if (left-&gt;is_single_fpu()) {
3034     __ fneg(FloatRegisterImpl::S, left-&gt;as_float_reg(), dest-&gt;as_float_reg());
3035   } else if (left-&gt;is_double_fpu()) {
3036     __ fneg(FloatRegisterImpl::D, left-&gt;as_double_reg(), dest-&gt;as_double_reg());
3037   } else {
3038     assert (left-&gt;is_double_cpu(), &quot;Must be a long&quot;);
3039     Register Rlow = left-&gt;as_register_lo();
3040     Register Rhi = left-&gt;as_register_hi();
3041     __ sub(G0, Rlow, dest-&gt;as_register_lo());
3042   }
3043 }
3044 













3045 void LIR_Assembler::rt_call(LIR_Opr result, address dest,
3046                             const LIR_OprList* args, LIR_Opr tmp, CodeEmitInfo* info) {
3047 
3048   // if tmp is invalid, then the function being called doesn&#39;t destroy the thread
3049   if (tmp-&gt;is_valid()) {
3050     __ save_thread(tmp-&gt;as_pointer_register());
3051   }
3052   __ call(dest, relocInfo::runtime_call_type);
3053   __ delayed()-&gt;nop();
3054   if (info != NULL) {
3055     add_call_info_here(info);
3056   }
3057   if (tmp-&gt;is_valid()) {
3058     __ restore_thread(tmp-&gt;as_pointer_register());
3059   }
3060 
3061 #ifdef ASSERT
3062   __ verify_thread();
3063 #endif // ASSERT
3064 }
</pre>
</td>
</tr>
</table>
<center><a href="c1_FrameMap_sparc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRGenerator_sparc.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>