<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff src/hotspot/cpu/sparc/stubGenerator_sparc.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="sparc.ad.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="templateTable_sparc.cpp.udiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/sparc/stubGenerator_sparc.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -583,11 +583,12 @@</span>
      // is flushed, and will stay flushed while the caller executes.
  
      return start;
    }
  
<span class="udiff-line-modified-removed">-   // Support for jint Atomic::xchg(jint exchange_value, volatile jint* dest).</span>
<span class="udiff-line-modified-added">+   // Implementation of jint atomic_xchg(jint exchange_value, volatile jint* dest)</span>
<span class="udiff-line-added">+   // used by Atomic::xchg(volatile jint* dest, jint exchange_value)</span>
    //
    // Arguments:
    //
    //      exchange_value: O0
    //      dest:           O1
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -620,11 +621,12 @@</span>
  
      return start;
    }
  
  
<span class="udiff-line-modified-removed">-   // Support for jint Atomic::cmpxchg(jint exchange_value, volatile jint* dest, jint compare_value)</span>
<span class="udiff-line-modified-added">+   // Implementation of jint atomic_cmpxchg(jint exchange_value, volatile jint* dest, jint compare_value)</span>
<span class="udiff-line-added">+   // used by Atomic::cmpxchg(volatile jint* dest, jint compare_value, jint exchange_value)</span>
    //
    // Arguments:
    //
    //      exchange_value: O0
    //      dest:           O1
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -644,11 +646,12 @@</span>
      __ delayed()-&gt;nop();
  
      return start;
    }
  
<span class="udiff-line-modified-removed">-   // Support for jlong Atomic::cmpxchg(jlong exchange_value, volatile jlong *dest, jlong compare_value)</span>
<span class="udiff-line-modified-added">+   // Implementation of jlong atomic_cmpxchg_long(jlong exchange_value, volatile jlong *dest, jlong compare_value)</span>
<span class="udiff-line-added">+   // used by Atomic::cmpxchg(volatile jlong *dest, jlong compare_value, jlong exchange_value)</span>
    //
    // Arguments:
    //
    //      exchange_value: O1:O0
    //      dest:           O2
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -677,11 +680,12 @@</span>
  
      return start;
    }
  
  
<span class="udiff-line-modified-removed">-   // Support for jint Atomic::add(jint add_value, volatile jint* dest).</span>
<span class="udiff-line-modified-added">+   // Implementation of jint atomic_add(jint add_value, volatile jint* dest)</span>
<span class="udiff-line-added">+   // used by Atomic::add(volatile jint* dest, jint add_value)</span>
    //
    // Arguments:
    //
    //      add_value: O0   (e.g., +1 or -1)
    //      dest:      O1
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1074,10 +1078,21 @@</span>
        __ srl(left_shift, LogBitsPerByte, left_shift);    // misaligned bytes
        __ br(Assembler::always, false, Assembler::pt, L_copy_bytes);
        __ delayed()-&gt;add(end_from, left_shift, end_from); // restore address
    }
  
<span class="udiff-line-added">+   address generate_unsafecopy_common_error_exit() {</span>
<span class="udiff-line-added">+     address start_pc = __ pc();</span>
<span class="udiff-line-added">+     if (UseBlockCopy) {</span>
<span class="udiff-line-added">+       __ wrasi(G0, Assembler::ASI_PRIMARY_NOFAULT);</span>
<span class="udiff-line-added">+       __ membar(Assembler::StoreLoad);</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     __ retl();</span>
<span class="udiff-line-added">+     __ delayed()-&gt;mov(G0, O0); // return 0</span>
<span class="udiff-line-added">+     return start_pc;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
    //
    //  Generate stub for disjoint byte copy.  If &quot;aligned&quot; is true, the
    //  &quot;from&quot; and &quot;to&quot; addresses are assumed to be heapword aligned.
    //
    // Arguments for generated stub:
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1105,65 +1120,70 @@</span>
        *entry = __ pc();
        // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
        BLOCK_COMMENT(&quot;Entry:&quot;);
      }
  
<span class="udiff-line-modified-removed">-     // for short arrays, just do single element copy</span>
<span class="udiff-line-modified-removed">-     __ cmp(count, 23); // 16 + 7</span>
<span class="udiff-line-modified-removed">-     __ brx(Assembler::less, false, Assembler::pn, L_copy_byte);</span>
<span class="udiff-line-removed">-     __ delayed()-&gt;mov(G0, offset);</span>
<span class="udiff-line-modified-added">+     {</span>
<span class="udiff-line-modified-added">+       // UnsafeCopyMemory page error: continue at UnsafeCopyMemory common_error_exit</span>
<span class="udiff-line-modified-added">+       UnsafeCopyMemoryMark ucmm(this, !aligned, false);</span>
  
<span class="udiff-line-modified-removed">-     if (aligned) {</span>
<span class="udiff-line-modified-removed">-       // &#39;aligned&#39; == true when it is known statically during compilation</span>
<span class="udiff-line-modified-removed">-       // of this arraycopy call site that both &#39;from&#39; and &#39;to&#39; addresses</span>
<span class="udiff-line-modified-removed">-       // are HeapWordSize aligned (see LibraryCallKit::basictype2arraycopy()).</span>
<span class="udiff-line-removed">-       //</span>
<span class="udiff-line-removed">-       // Aligned arrays have 4 bytes alignment in 32-bits VM</span>
<span class="udiff-line-removed">-       // and 8 bytes - in 64-bits VM. So we do it only for 32-bits VM</span>
<span class="udiff-line-removed">-       //</span>
<span class="udiff-line-removed">-     } else {</span>
<span class="udiff-line-removed">-       // copy bytes to align &#39;to&#39; on 8 byte boundary</span>
<span class="udiff-line-removed">-       __ andcc(to, 7, G1); // misaligned bytes</span>
<span class="udiff-line-removed">-       __ br(Assembler::zero, false, Assembler::pt, L_skip_alignment);</span>
<span class="udiff-line-removed">-       __ delayed()-&gt;neg(G1);</span>
<span class="udiff-line-removed">-       __ inc(G1, 8);       // bytes need to copy to next 8-bytes alignment</span>
<span class="udiff-line-removed">-       __ sub(count, G1, count);</span>
<span class="udiff-line-removed">-     __ BIND(L_align);</span>
<span class="udiff-line-removed">-       __ ldub(from, 0, O3);</span>
<span class="udiff-line-removed">-       __ deccc(G1);</span>
<span class="udiff-line-removed">-       __ inc(from);</span>
<span class="udiff-line-removed">-       __ stb(O3, to, 0);</span>
<span class="udiff-line-removed">-       __ br(Assembler::notZero, false, Assembler::pt, L_align);</span>
<span class="udiff-line-removed">-       __ delayed()-&gt;inc(to);</span>
<span class="udiff-line-removed">-     __ BIND(L_skip_alignment);</span>
<span class="udiff-line-removed">-     }</span>
<span class="udiff-line-removed">-     if (!aligned) {</span>
<span class="udiff-line-removed">-       // Copy with shift 16 bytes per iteration if arrays do not have</span>
<span class="udiff-line-removed">-       // the same alignment mod 8, otherwise fall through to the next</span>
<span class="udiff-line-removed">-       // code for aligned copy.</span>
<span class="udiff-line-removed">-       // The compare above (count &gt;= 23) guarantes &#39;count&#39; &gt;= 16 bytes.</span>
<span class="udiff-line-removed">-       // Also jump over aligned copy after the copy with shift completed.</span>
<span class="udiff-line-modified-added">+       // for short arrays, just do single element copy</span>
<span class="udiff-line-modified-added">+       __ cmp(count, 23); // 16 + 7</span>
<span class="udiff-line-modified-added">+       __ brx(Assembler::less, false, Assembler::pn, L_copy_byte);</span>
<span class="udiff-line-modified-added">+       __ delayed()-&gt;mov(G0, offset);</span>
  
<span class="udiff-line-modified-removed">-       copy_16_bytes_forward_with_shift(from, to, count, 0, L_copy_byte);</span>
<span class="udiff-line-modified-removed">-     }</span>
<span class="udiff-line-modified-added">+       if (aligned) {</span>
<span class="udiff-line-modified-added">+         // &#39;aligned&#39; == true when it is known statically during compilation</span>
<span class="udiff-line-added">+         // of this arraycopy call site that both &#39;from&#39; and &#39;to&#39; addresses</span>
<span class="udiff-line-added">+         // are HeapWordSize aligned (see LibraryCallKit::basictype2arraycopy()).</span>
<span class="udiff-line-added">+         //</span>
<span class="udiff-line-added">+         // Aligned arrays have 4 bytes alignment in 32-bits VM</span>
<span class="udiff-line-added">+         // and 8 bytes - in 64-bits VM. So we do it only for 32-bits VM</span>
<span class="udiff-line-added">+         //</span>
<span class="udiff-line-added">+       } else {</span>
<span class="udiff-line-added">+         // copy bytes to align &#39;to&#39; on 8 byte boundary</span>
<span class="udiff-line-added">+         __ andcc(to, 7, G1); // misaligned bytes</span>
<span class="udiff-line-added">+         __ br(Assembler::zero, false, Assembler::pt, L_skip_alignment);</span>
<span class="udiff-line-added">+         __ delayed()-&gt;neg(G1);</span>
<span class="udiff-line-added">+         __ inc(G1, 8);       // bytes need to copy to next 8-bytes alignment</span>
<span class="udiff-line-added">+         __ sub(count, G1, count);</span>
<span class="udiff-line-added">+       __ BIND(L_align);</span>
<span class="udiff-line-added">+         __ ldub(from, 0, O3);</span>
<span class="udiff-line-added">+         __ deccc(G1);</span>
<span class="udiff-line-added">+         __ inc(from);</span>
<span class="udiff-line-added">+         __ stb(O3, to, 0);</span>
<span class="udiff-line-added">+         __ br(Assembler::notZero, false, Assembler::pt, L_align);</span>
<span class="udiff-line-added">+         __ delayed()-&gt;inc(to);</span>
<span class="udiff-line-added">+       __ BIND(L_skip_alignment);</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       if (!aligned) {</span>
<span class="udiff-line-added">+         // Copy with shift 16 bytes per iteration if arrays do not have</span>
<span class="udiff-line-added">+         // the same alignment mod 8, otherwise fall through to the next</span>
<span class="udiff-line-added">+         // code for aligned copy.</span>
<span class="udiff-line-added">+         // The compare above (count &gt;= 23) guarantes &#39;count&#39; &gt;= 16 bytes.</span>
<span class="udiff-line-added">+         // Also jump over aligned copy after the copy with shift completed.</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         copy_16_bytes_forward_with_shift(from, to, count, 0, L_copy_byte);</span>
<span class="udiff-line-added">+       }</span>
  
<span class="udiff-line-modified-removed">-     // Both array are 8 bytes aligned, copy 16 bytes at a time</span>
<span class="udiff-line-modified-added">+       // Both array are 8 bytes aligned, copy 16 bytes at a time</span>
        __ and3(count, 7, G4); // Save count
        __ srl(count, 3, count);
<span class="udiff-line-modified-removed">-      generate_disjoint_long_copy_core(aligned);</span>
<span class="udiff-line-modified-added">+       generate_disjoint_long_copy_core(aligned);</span>
        __ mov(G4, count);     // Restore count
  
<span class="udiff-line-modified-removed">-     // copy tailing bytes</span>
<span class="udiff-line-modified-removed">-     __ BIND(L_copy_byte);</span>
<span class="udiff-line-modified-removed">-       __ cmp_and_br_short(count, 0, Assembler::equal, Assembler::pt, L_exit);</span>
<span class="udiff-line-modified-removed">-       __ align(OptoLoopAlignment);</span>
<span class="udiff-line-modified-removed">-     __ BIND(L_copy_byte_loop);</span>
<span class="udiff-line-modified-removed">-       __ ldub(from, offset, O3);</span>
<span class="udiff-line-modified-removed">-       __ deccc(count);</span>
<span class="udiff-line-modified-removed">-       __ stb(O3, to, offset);</span>
<span class="udiff-line-modified-removed">-       __ brx(Assembler::notZero, false, Assembler::pt, L_copy_byte_loop);</span>
<span class="udiff-line-modified-removed">-       __ delayed()-&gt;inc(offset);</span>
<span class="udiff-line-modified-added">+       // copy tailing bytes</span>
<span class="udiff-line-modified-added">+       __ BIND(L_copy_byte);</span>
<span class="udiff-line-modified-added">+         __ cmp_and_br_short(count, 0, Assembler::equal, Assembler::pt, L_exit);</span>
<span class="udiff-line-modified-added">+         __ align(OptoLoopAlignment);</span>
<span class="udiff-line-modified-added">+       __ BIND(L_copy_byte_loop);</span>
<span class="udiff-line-modified-added">+         __ ldub(from, offset, O3);</span>
<span class="udiff-line-modified-added">+         __ deccc(count);</span>
<span class="udiff-line-modified-added">+         __ stb(O3, to, offset);</span>
<span class="udiff-line-modified-added">+         __ brx(Assembler::notZero, false, Assembler::pt, L_copy_byte_loop);</span>
<span class="udiff-line-modified-added">+         __ delayed()-&gt;inc(offset);</span>
<span class="udiff-line-added">+     }</span>
  
      __ BIND(L_exit);
        // O3, O4 are used as temp registers
        inc_counter_np(SharedRuntime::_jbyte_array_copy_ctr, O3, O4);
        __ retl();
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1205,74 +1225,79 @@</span>
        BLOCK_COMMENT(&quot;Entry:&quot;);
      }
  
      array_overlap_test(nooverlap_target, 0);
  
<span class="udiff-line-modified-removed">-     __ add(to, count, end_to);       // offset after last copied element</span>
<span class="udiff-line-modified-added">+     {</span>
<span class="udiff-line-added">+       // UnsafeCopyMemory page error: continue at UnsafeCopyMemory common_error_exit</span>
<span class="udiff-line-added">+       UnsafeCopyMemoryMark ucmm(this, !aligned, false);</span>
  
<span class="udiff-line-modified-removed">-     // for short arrays, just do single element copy</span>
<span class="udiff-line-removed">-     __ cmp(count, 23); // 16 + 7</span>
<span class="udiff-line-removed">-     __ brx(Assembler::less, false, Assembler::pn, L_copy_byte);</span>
<span class="udiff-line-removed">-     __ delayed()-&gt;add(from, count, end_from);</span>
<span class="udiff-line-modified-added">+       __ add(to, count, end_to);       // offset after last copied element</span>
  
<span class="udiff-line-modified-removed">-     {</span>
<span class="udiff-line-modified-removed">-       // Align end of arrays since they could be not aligned even</span>
<span class="udiff-line-modified-removed">-       // when arrays itself are aligned.</span>
<span class="udiff-line-modified-added">+       // for short arrays, just do single element copy</span>
<span class="udiff-line-modified-added">+       __ cmp(count, 23); // 16 + 7</span>
<span class="udiff-line-modified-added">+       __ brx(Assembler::less, false, Assembler::pn, L_copy_byte);</span>
<span class="udiff-line-added">+       __ delayed()-&gt;add(from, count, end_from);</span>
  
<span class="udiff-line-modified-removed">-       // copy bytes to align &#39;end_to&#39; on 8 byte boundary</span>
<span class="udiff-line-modified-removed">-       __ andcc(end_to, 7, G1); // misaligned bytes</span>
<span class="udiff-line-modified-removed">-       __ br(Assembler::zero, false, Assembler::pt, L_skip_alignment);</span>
<span class="udiff-line-removed">-       __ delayed()-&gt;nop();</span>
<span class="udiff-line-removed">-       __ sub(count, G1, count);</span>
<span class="udiff-line-removed">-     __ BIND(L_align);</span>
<span class="udiff-line-removed">-       __ dec(end_from);</span>
<span class="udiff-line-removed">-       __ dec(end_to);</span>
<span class="udiff-line-removed">-       __ ldub(end_from, 0, O3);</span>
<span class="udiff-line-removed">-       __ deccc(G1);</span>
<span class="udiff-line-removed">-       __ brx(Assembler::notZero, false, Assembler::pt, L_align);</span>
<span class="udiff-line-removed">-       __ delayed()-&gt;stb(O3, end_to, 0);</span>
<span class="udiff-line-removed">-     __ BIND(L_skip_alignment);</span>
<span class="udiff-line-removed">-     }</span>
<span class="udiff-line-removed">-     if (aligned) {</span>
<span class="udiff-line-removed">-       // Both arrays are aligned to 8-bytes in 64-bits VM.</span>
<span class="udiff-line-removed">-       // The &#39;count&#39; is decremented in copy_16_bytes_backward_with_shift()</span>
<span class="udiff-line-removed">-       // in unaligned case.</span>
<span class="udiff-line-removed">-       __ dec(count, 16);</span>
<span class="udiff-line-removed">-     } else {</span>
<span class="udiff-line-removed">-       // Copy with shift 16 bytes per iteration if arrays do not have</span>
<span class="udiff-line-removed">-       // the same alignment mod 8, otherwise jump to the next</span>
<span class="udiff-line-removed">-       // code for aligned copy (and substracting 16 from &#39;count&#39; before jump).</span>
<span class="udiff-line-removed">-       // The compare above (count &gt;= 11) guarantes &#39;count&#39; &gt;= 16 bytes.</span>
<span class="udiff-line-removed">-       // Also jump over aligned copy after the copy with shift completed.</span>
<span class="udiff-line-modified-added">+       {</span>
<span class="udiff-line-modified-added">+         // Align end of arrays since they could be not aligned even</span>
<span class="udiff-line-modified-added">+         // when arrays itself are aligned.</span>
  
<span class="udiff-line-modified-removed">-       copy_16_bytes_backward_with_shift(end_from, end_to, count, 16,</span>
<span class="udiff-line-modified-removed">-                                         L_aligned_copy, L_copy_byte);</span>
<span class="udiff-line-modified-added">+         // copy bytes to align &#39;end_to&#39; on 8 byte boundary</span>
<span class="udiff-line-modified-added">+         __ andcc(end_to, 7, G1); // misaligned bytes</span>
<span class="udiff-line-added">+         __ br(Assembler::zero, false, Assembler::pt, L_skip_alignment);</span>
<span class="udiff-line-added">+         __ delayed()-&gt;nop();</span>
<span class="udiff-line-added">+         __ sub(count, G1, count);</span>
<span class="udiff-line-added">+       __ BIND(L_align);</span>
<span class="udiff-line-added">+         __ dec(end_from);</span>
<span class="udiff-line-added">+         __ dec(end_to);</span>
<span class="udiff-line-added">+         __ ldub(end_from, 0, O3);</span>
<span class="udiff-line-added">+         __ deccc(G1);</span>
<span class="udiff-line-added">+         __ brx(Assembler::notZero, false, Assembler::pt, L_align);</span>
<span class="udiff-line-added">+         __ delayed()-&gt;stb(O3, end_to, 0);</span>
<span class="udiff-line-added">+       __ BIND(L_skip_alignment);</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       if (aligned) {</span>
<span class="udiff-line-added">+         // Both arrays are aligned to 8-bytes in 64-bits VM.</span>
<span class="udiff-line-added">+         // The &#39;count&#39; is decremented in copy_16_bytes_backward_with_shift()</span>
<span class="udiff-line-added">+         // in unaligned case.</span>
<span class="udiff-line-added">+         __ dec(count, 16);</span>
<span class="udiff-line-added">+       } else {</span>
<span class="udiff-line-added">+         // Copy with shift 16 bytes per iteration if arrays do not have</span>
<span class="udiff-line-added">+         // the same alignment mod 8, otherwise jump to the next</span>
<span class="udiff-line-added">+         // code for aligned copy (and substracting 16 from &#39;count&#39; before jump).</span>
<span class="udiff-line-added">+         // The compare above (count &gt;= 11) guarantes &#39;count&#39; &gt;= 16 bytes.</span>
<span class="udiff-line-added">+         // Also jump over aligned copy after the copy with shift completed.</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+        copy_16_bytes_backward_with_shift(end_from, end_to, count, 16,</span>
<span class="udiff-line-added">+                                           L_aligned_copy, L_copy_byte);</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       // copy 4 elements (16 bytes) at a time</span>
<span class="udiff-line-added">+         __ align(OptoLoopAlignment);</span>
<span class="udiff-line-added">+       __ BIND(L_aligned_copy);</span>
<span class="udiff-line-added">+         __ dec(end_from, 16);</span>
<span class="udiff-line-added">+         __ ldx(end_from, 8, O3);</span>
<span class="udiff-line-added">+         __ ldx(end_from, 0, O4);</span>
<span class="udiff-line-added">+         __ dec(end_to, 16);</span>
<span class="udiff-line-added">+         __ deccc(count, 16);</span>
<span class="udiff-line-added">+         __ stx(O3, end_to, 8);</span>
<span class="udiff-line-added">+         __ brx(Assembler::greaterEqual, false, Assembler::pt, L_aligned_copy);</span>
<span class="udiff-line-added">+         __ delayed()-&gt;stx(O4, end_to, 0);</span>
<span class="udiff-line-added">+         __ inc(count, 16);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       // copy 1 element (2 bytes) at a time</span>
<span class="udiff-line-added">+       __ BIND(L_copy_byte);</span>
<span class="udiff-line-added">+         __ cmp_and_br_short(count, 0, Assembler::equal, Assembler::pt, L_exit);</span>
<span class="udiff-line-added">+         __ align(OptoLoopAlignment);</span>
<span class="udiff-line-added">+       __ BIND(L_copy_byte_loop);</span>
<span class="udiff-line-added">+         __ dec(end_from);</span>
<span class="udiff-line-added">+         __ dec(end_to);</span>
<span class="udiff-line-added">+         __ ldub(end_from, 0, O4);</span>
<span class="udiff-line-added">+         __ deccc(count);</span>
<span class="udiff-line-added">+         __ brx(Assembler::greater, false, Assembler::pt, L_copy_byte_loop);</span>
<span class="udiff-line-added">+         __ delayed()-&gt;stb(O4, end_to, 0);</span>
      }
<span class="udiff-line-removed">-     // copy 4 elements (16 bytes) at a time</span>
<span class="udiff-line-removed">-       __ align(OptoLoopAlignment);</span>
<span class="udiff-line-removed">-     __ BIND(L_aligned_copy);</span>
<span class="udiff-line-removed">-       __ dec(end_from, 16);</span>
<span class="udiff-line-removed">-       __ ldx(end_from, 8, O3);</span>
<span class="udiff-line-removed">-       __ ldx(end_from, 0, O4);</span>
<span class="udiff-line-removed">-       __ dec(end_to, 16);</span>
<span class="udiff-line-removed">-       __ deccc(count, 16);</span>
<span class="udiff-line-removed">-       __ stx(O3, end_to, 8);</span>
<span class="udiff-line-removed">-       __ brx(Assembler::greaterEqual, false, Assembler::pt, L_aligned_copy);</span>
<span class="udiff-line-removed">-       __ delayed()-&gt;stx(O4, end_to, 0);</span>
<span class="udiff-line-removed">-       __ inc(count, 16);</span>
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">-     // copy 1 element (2 bytes) at a time</span>
<span class="udiff-line-removed">-     __ BIND(L_copy_byte);</span>
<span class="udiff-line-removed">-       __ cmp_and_br_short(count, 0, Assembler::equal, Assembler::pt, L_exit);</span>
<span class="udiff-line-removed">-       __ align(OptoLoopAlignment);</span>
<span class="udiff-line-removed">-     __ BIND(L_copy_byte_loop);</span>
<span class="udiff-line-removed">-       __ dec(end_from);</span>
<span class="udiff-line-removed">-       __ dec(end_to);</span>
<span class="udiff-line-removed">-       __ ldub(end_from, 0, O4);</span>
<span class="udiff-line-removed">-       __ deccc(count);</span>
<span class="udiff-line-removed">-       __ brx(Assembler::greater, false, Assembler::pt, L_copy_byte_loop);</span>
<span class="udiff-line-removed">-       __ delayed()-&gt;stb(O4, end_to, 0);</span>
  
      __ BIND(L_exit);
      // O3, O4 are used as temp registers
      inc_counter_np(SharedRuntime::_jbyte_array_copy_ctr, O3, O4);
      __ retl();
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1309,73 +1334,77 @@</span>
        *entry = __ pc();
        // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
        BLOCK_COMMENT(&quot;Entry:&quot;);
      }
  
<span class="udiff-line-modified-removed">-     // for short arrays, just do single element copy</span>
<span class="udiff-line-modified-removed">-     __ cmp(count, 11); // 8 + 3  (22 bytes)</span>
<span class="udiff-line-modified-removed">-     __ brx(Assembler::less, false, Assembler::pn, L_copy_2_bytes);</span>
<span class="udiff-line-modified-removed">-     __ delayed()-&gt;mov(G0, offset);</span>
<span class="udiff-line-modified-added">+     {</span>
<span class="udiff-line-modified-added">+       // UnsafeCopyMemory page error: continue at UnsafeCopyMemory common_error_exit</span>
<span class="udiff-line-modified-added">+       UnsafeCopyMemoryMark ucmm(this, !aligned, false);</span>
<span class="udiff-line-modified-added">+       // for short arrays, just do single element copy</span>
<span class="udiff-line-added">+       __ cmp(count, 11); // 8 + 3  (22 bytes)</span>
<span class="udiff-line-added">+       __ brx(Assembler::less, false, Assembler::pn, L_copy_2_bytes);</span>
<span class="udiff-line-added">+       __ delayed()-&gt;mov(G0, offset);</span>
  
<span class="udiff-line-modified-removed">-     if (aligned) {</span>
<span class="udiff-line-modified-removed">-       // &#39;aligned&#39; == true when it is known statically during compilation</span>
<span class="udiff-line-modified-removed">-       // of this arraycopy call site that both &#39;from&#39; and &#39;to&#39; addresses</span>
<span class="udiff-line-modified-removed">-       // are HeapWordSize aligned (see LibraryCallKit::basictype2arraycopy()).</span>
<span class="udiff-line-modified-removed">-       //</span>
<span class="udiff-line-modified-removed">-       // Aligned arrays have 4 bytes alignment in 32-bits VM</span>
<span class="udiff-line-modified-removed">-       // and 8 bytes - in 64-bits VM.</span>
<span class="udiff-line-modified-removed">-       //</span>
<span class="udiff-line-modified-removed">-     } else {</span>
<span class="udiff-line-modified-removed">-       // copy 1 element if necessary to align &#39;to&#39; on an 4 bytes</span>
<span class="udiff-line-modified-removed">-       __ andcc(to, 3, G0);</span>
<span class="udiff-line-modified-removed">-       __ br(Assembler::zero, false, Assembler::pt, L_skip_alignment);</span>
<span class="udiff-line-modified-removed">-       __ delayed()-&gt;lduh(from, 0, O3);</span>
<span class="udiff-line-modified-removed">-       __ inc(from, 2);</span>
<span class="udiff-line-modified-removed">-       __ inc(to, 2);</span>
<span class="udiff-line-modified-removed">-       __ dec(count);</span>
<span class="udiff-line-modified-removed">-       __ sth(O3, to, -2);</span>
<span class="udiff-line-modified-removed">-     __ BIND(L_skip_alignment);</span>
<span class="udiff-line-modified-added">+       if (aligned) {</span>
<span class="udiff-line-modified-added">+         // &#39;aligned&#39; == true when it is known statically during compilation</span>
<span class="udiff-line-modified-added">+         // of this arraycopy call site that both &#39;from&#39; and &#39;to&#39; addresses</span>
<span class="udiff-line-modified-added">+         // are HeapWordSize aligned (see LibraryCallKit::basictype2arraycopy()).</span>
<span class="udiff-line-modified-added">+         //</span>
<span class="udiff-line-modified-added">+         // Aligned arrays have 4 bytes alignment in 32-bits VM</span>
<span class="udiff-line-modified-added">+         // and 8 bytes - in 64-bits VM.</span>
<span class="udiff-line-modified-added">+         //</span>
<span class="udiff-line-modified-added">+       } else {</span>
<span class="udiff-line-modified-added">+         // copy 1 element if necessary to align &#39;to&#39; on an 4 bytes</span>
<span class="udiff-line-modified-added">+         __ andcc(to, 3, G0);</span>
<span class="udiff-line-modified-added">+         __ br(Assembler::zero, false, Assembler::pt, L_skip_alignment);</span>
<span class="udiff-line-modified-added">+         __ delayed()-&gt;lduh(from, 0, O3);</span>
<span class="udiff-line-modified-added">+         __ inc(from, 2);</span>
<span class="udiff-line-modified-added">+         __ inc(to, 2);</span>
<span class="udiff-line-modified-added">+         __ dec(count);</span>
<span class="udiff-line-modified-added">+         __ sth(O3, to, -2);</span>
<span class="udiff-line-modified-added">+       __ BIND(L_skip_alignment);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         // copy 2 elements to align &#39;to&#39; on an 8 byte boundary</span>
<span class="udiff-line-added">+         __ andcc(to, 7, G0);</span>
<span class="udiff-line-added">+         __ br(Assembler::zero, false, Assembler::pn, L_skip_alignment2);</span>
<span class="udiff-line-added">+         __ delayed()-&gt;lduh(from, 0, O3);</span>
<span class="udiff-line-added">+         __ dec(count, 2);</span>
<span class="udiff-line-added">+         __ lduh(from, 2, O4);</span>
<span class="udiff-line-added">+         __ inc(from, 4);</span>
<span class="udiff-line-added">+         __ inc(to, 4);</span>
<span class="udiff-line-added">+         __ sth(O3, to, -4);</span>
<span class="udiff-line-added">+         __ sth(O4, to, -2);</span>
<span class="udiff-line-added">+       __ BIND(L_skip_alignment2);</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       if (!aligned) {</span>
<span class="udiff-line-added">+         // Copy with shift 16 bytes per iteration if arrays do not have</span>
<span class="udiff-line-added">+         // the same alignment mod 8, otherwise fall through to the next</span>
<span class="udiff-line-added">+         // code for aligned copy.</span>
<span class="udiff-line-added">+         // The compare above (count &gt;= 11) guarantes &#39;count&#39; &gt;= 16 bytes.</span>
<span class="udiff-line-added">+         // Also jump over aligned copy after the copy with shift completed.</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         copy_16_bytes_forward_with_shift(from, to, count, 1, L_copy_2_bytes);</span>
<span class="udiff-line-added">+       }</span>
  
<span class="udiff-line-modified-removed">-       // copy 2 elements to align &#39;to&#39; on an 8 byte boundary</span>
<span class="udiff-line-modified-removed">-       __ andcc(to, 7, G0);</span>
<span class="udiff-line-modified-removed">-       __ br(Assembler::zero, false, Assembler::pn, L_skip_alignment2);</span>
<span class="udiff-line-modified-removed">-       __ delayed()-&gt;lduh(from, 0, O3);</span>
<span class="udiff-line-modified-removed">-       __ dec(count, 2);</span>
<span class="udiff-line-removed">-       __ lduh(from, 2, O4);</span>
<span class="udiff-line-removed">-       __ inc(from, 4);</span>
<span class="udiff-line-removed">-       __ inc(to, 4);</span>
<span class="udiff-line-removed">-       __ sth(O3, to, -4);</span>
<span class="udiff-line-removed">-       __ sth(O4, to, -2);</span>
<span class="udiff-line-removed">-     __ BIND(L_skip_alignment2);</span>
<span class="udiff-line-removed">-     }</span>
<span class="udiff-line-removed">-     if (!aligned) {</span>
<span class="udiff-line-removed">-       // Copy with shift 16 bytes per iteration if arrays do not have</span>
<span class="udiff-line-removed">-       // the same alignment mod 8, otherwise fall through to the next</span>
<span class="udiff-line-removed">-       // code for aligned copy.</span>
<span class="udiff-line-removed">-       // The compare above (count &gt;= 11) guarantes &#39;count&#39; &gt;= 16 bytes.</span>
<span class="udiff-line-removed">-       // Also jump over aligned copy after the copy with shift completed.</span>
<span class="udiff-line-modified-added">+       // Both array are 8 bytes aligned, copy 16 bytes at a time</span>
<span class="udiff-line-modified-added">+         __ and3(count, 3, G4); // Save</span>
<span class="udiff-line-modified-added">+         __ srl(count, 2, count);</span>
<span class="udiff-line-modified-added">+        generate_disjoint_long_copy_core(aligned);</span>
<span class="udiff-line-modified-added">+         __ mov(G4, count); // restore</span>
  
<span class="udiff-line-modified-removed">-       copy_16_bytes_forward_with_shift(from, to, count, 1, L_copy_2_bytes);</span>
<span class="udiff-line-modified-added">+       // copy 1 element at a time</span>
<span class="udiff-line-added">+       __ BIND(L_copy_2_bytes);</span>
<span class="udiff-line-added">+         __ cmp_and_br_short(count, 0, Assembler::equal, Assembler::pt, L_exit);</span>
<span class="udiff-line-added">+         __ align(OptoLoopAlignment);</span>
<span class="udiff-line-added">+       __ BIND(L_copy_2_bytes_loop);</span>
<span class="udiff-line-added">+         __ lduh(from, offset, O3);</span>
<span class="udiff-line-added">+         __ deccc(count);</span>
<span class="udiff-line-added">+         __ sth(O3, to, offset);</span>
<span class="udiff-line-added">+         __ brx(Assembler::notZero, false, Assembler::pt, L_copy_2_bytes_loop);</span>
<span class="udiff-line-added">+         __ delayed()-&gt;inc(offset, 2);</span>
      }
  
<span class="udiff-line-removed">-     // Both array are 8 bytes aligned, copy 16 bytes at a time</span>
<span class="udiff-line-removed">-       __ and3(count, 3, G4); // Save</span>
<span class="udiff-line-removed">-       __ srl(count, 2, count);</span>
<span class="udiff-line-removed">-      generate_disjoint_long_copy_core(aligned);</span>
<span class="udiff-line-removed">-       __ mov(G4, count); // restore</span>
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">-     // copy 1 element at a time</span>
<span class="udiff-line-removed">-     __ BIND(L_copy_2_bytes);</span>
<span class="udiff-line-removed">-       __ cmp_and_br_short(count, 0, Assembler::equal, Assembler::pt, L_exit);</span>
<span class="udiff-line-removed">-       __ align(OptoLoopAlignment);</span>
<span class="udiff-line-removed">-     __ BIND(L_copy_2_bytes_loop);</span>
<span class="udiff-line-removed">-       __ lduh(from, offset, O3);</span>
<span class="udiff-line-removed">-       __ deccc(count);</span>
<span class="udiff-line-removed">-       __ sth(O3, to, offset);</span>
<span class="udiff-line-removed">-       __ brx(Assembler::notZero, false, Assembler::pt, L_copy_2_bytes_loop);</span>
<span class="udiff-line-removed">-       __ delayed()-&gt;inc(offset, 2);</span>
<span class="udiff-line-removed">- </span>
      __ BIND(L_exit);
        // O3, O4 are used as temp registers
        inc_counter_np(SharedRuntime::_jshort_array_copy_ctr, O3, O4);
        __ retl();
        __ delayed()-&gt;mov(G0, O0); // return 0
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1637,83 +1666,87 @@</span>
        BLOCK_COMMENT(&quot;Entry:&quot;);
      }
  
      array_overlap_test(nooverlap_target, 1);
  
<span class="udiff-line-removed">-     __ sllx(count, LogBytesPerShort, byte_count);</span>
<span class="udiff-line-removed">-     __ add(to, byte_count, end_to);  // offset after last copied element</span>
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">-     // for short arrays, just do single element copy</span>
<span class="udiff-line-removed">-     __ cmp(count, 11); // 8 + 3  (22 bytes)</span>
<span class="udiff-line-removed">-     __ brx(Assembler::less, false, Assembler::pn, L_copy_2_bytes);</span>
<span class="udiff-line-removed">-     __ delayed()-&gt;add(from, byte_count, end_from);</span>
<span class="udiff-line-removed">- </span>
      {
<span class="udiff-line-modified-removed">-       // Align end of arrays since they could be not aligned even</span>
<span class="udiff-line-modified-removed">-       // when arrays itself are aligned.</span>
<span class="udiff-line-modified-added">+       // UnsafeCopyMemory page error: continue at UnsafeCopyMemory common_error_exit</span>
<span class="udiff-line-modified-added">+       UnsafeCopyMemoryMark ucmm(this, !aligned, false);</span>
  
<span class="udiff-line-modified-removed">-       // copy 1 element if necessary to align &#39;end_to&#39; on an 4 bytes</span>
<span class="udiff-line-modified-removed">-       __ andcc(end_to, 3, G0);</span>
<span class="udiff-line-removed">-       __ br(Assembler::zero, false, Assembler::pt, L_skip_alignment);</span>
<span class="udiff-line-removed">-       __ delayed()-&gt;lduh(end_from, -2, O3);</span>
<span class="udiff-line-removed">-       __ dec(end_from, 2);</span>
<span class="udiff-line-removed">-       __ dec(end_to, 2);</span>
<span class="udiff-line-removed">-       __ dec(count);</span>
<span class="udiff-line-removed">-       __ sth(O3, end_to, 0);</span>
<span class="udiff-line-removed">-     __ BIND(L_skip_alignment);</span>
<span class="udiff-line-modified-added">+       __ sllx(count, LogBytesPerShort, byte_count);</span>
<span class="udiff-line-modified-added">+       __ add(to, byte_count, end_to);  // offset after last copied element</span>
  
<span class="udiff-line-modified-removed">-       // copy 2 elements to align &#39;end_to&#39; on an 8 byte boundary</span>
<span class="udiff-line-modified-removed">-       __ andcc(end_to, 7, G0);</span>
<span class="udiff-line-modified-removed">-       __ br(Assembler::zero, false, Assembler::pn, L_skip_alignment2);</span>
<span class="udiff-line-modified-removed">-       __ delayed()-&gt;lduh(end_from, -2, O3);</span>
<span class="udiff-line-modified-removed">-       __ dec(count, 2);</span>
<span class="udiff-line-modified-removed">-       __ lduh(end_from, -4, O4);</span>
<span class="udiff-line-modified-removed">-       __ dec(end_from, 4);</span>
<span class="udiff-line-modified-removed">-       __ dec(end_to, 4);</span>
<span class="udiff-line-modified-removed">-       __ sth(O3, end_to, 2);</span>
<span class="udiff-line-modified-removed">-       __ sth(O4, end_to, 0);</span>
<span class="udiff-line-modified-removed">-     __ BIND(L_skip_alignment2);</span>
<span class="udiff-line-modified-removed">-     }</span>
<span class="udiff-line-modified-removed">-     if (aligned) {</span>
<span class="udiff-line-modified-removed">-       // Both arrays are aligned to 8-bytes in 64-bits VM.</span>
<span class="udiff-line-modified-removed">-       // The &#39;count&#39; is decremented in copy_16_bytes_backward_with_shift()</span>
<span class="udiff-line-modified-removed">-       // in unaligned case.</span>
<span class="udiff-line-modified-removed">-       __ dec(count, 8);</span>
<span class="udiff-line-modified-removed">-     } else {</span>
<span class="udiff-line-modified-removed">-       // Copy with shift 16 bytes per iteration if arrays do not have</span>
<span class="udiff-line-modified-removed">-       // the same alignment mod 8, otherwise jump to the next</span>
<span class="udiff-line-modified-removed">-       // code for aligned copy (and substracting 8 from &#39;count&#39; before jump).</span>
<span class="udiff-line-modified-removed">-       // The compare above (count &gt;= 11) guarantes &#39;count&#39; &gt;= 16 bytes.</span>
<span class="udiff-line-modified-removed">-       // Also jump over aligned copy after the copy with shift completed.</span>
<span class="udiff-line-modified-added">+       // for short arrays, just do single element copy</span>
<span class="udiff-line-modified-added">+       __ cmp(count, 11); // 8 + 3  (22 bytes)</span>
<span class="udiff-line-modified-added">+       __ brx(Assembler::less, false, Assembler::pn, L_copy_2_bytes);</span>
<span class="udiff-line-modified-added">+       __ delayed()-&gt;add(from, byte_count, end_from);</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+       {</span>
<span class="udiff-line-modified-added">+         // Align end of arrays since they could be not aligned even</span>
<span class="udiff-line-modified-added">+         // when arrays itself are aligned.</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+         // copy 1 element if necessary to align &#39;end_to&#39; on an 4 bytes</span>
<span class="udiff-line-modified-added">+         __ andcc(end_to, 3, G0);</span>
<span class="udiff-line-modified-added">+         __ br(Assembler::zero, false, Assembler::pt, L_skip_alignment);</span>
<span class="udiff-line-modified-added">+         __ delayed()-&gt;lduh(end_from, -2, O3);</span>
<span class="udiff-line-modified-added">+         __ dec(end_from, 2);</span>
<span class="udiff-line-modified-added">+         __ dec(end_to, 2);</span>
<span class="udiff-line-modified-added">+         __ dec(count);</span>
<span class="udiff-line-modified-added">+         __ sth(O3, end_to, 0);</span>
<span class="udiff-line-modified-added">+       __ BIND(L_skip_alignment);</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+         // copy 2 elements to align &#39;end_to&#39; on an 8 byte boundary</span>
<span class="udiff-line-modified-added">+         __ andcc(end_to, 7, G0);</span>
<span class="udiff-line-modified-added">+         __ br(Assembler::zero, false, Assembler::pn, L_skip_alignment2);</span>
<span class="udiff-line-modified-added">+         __ delayed()-&gt;lduh(end_from, -2, O3);</span>
<span class="udiff-line-added">+         __ dec(count, 2);</span>
<span class="udiff-line-added">+         __ lduh(end_from, -4, O4);</span>
<span class="udiff-line-added">+         __ dec(end_from, 4);</span>
<span class="udiff-line-added">+         __ dec(end_to, 4);</span>
<span class="udiff-line-added">+         __ sth(O3, end_to, 2);</span>
<span class="udiff-line-added">+         __ sth(O4, end_to, 0);</span>
<span class="udiff-line-added">+       __ BIND(L_skip_alignment2);</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       if (aligned) {</span>
<span class="udiff-line-added">+         // Both arrays are aligned to 8-bytes in 64-bits VM.</span>
<span class="udiff-line-added">+         // The &#39;count&#39; is decremented in copy_16_bytes_backward_with_shift()</span>
<span class="udiff-line-added">+         // in unaligned case.</span>
<span class="udiff-line-added">+         __ dec(count, 8);</span>
<span class="udiff-line-added">+       } else {</span>
<span class="udiff-line-added">+         // Copy with shift 16 bytes per iteration if arrays do not have</span>
<span class="udiff-line-added">+         // the same alignment mod 8, otherwise jump to the next</span>
<span class="udiff-line-added">+         // code for aligned copy (and substracting 8 from &#39;count&#39; before jump).</span>
<span class="udiff-line-added">+         // The compare above (count &gt;= 11) guarantes &#39;count&#39; &gt;= 16 bytes.</span>
<span class="udiff-line-added">+         // Also jump over aligned copy after the copy with shift completed.</span>
  
<span class="udiff-line-modified-removed">-       copy_16_bytes_backward_with_shift(end_from, end_to, count, 8,</span>
<span class="udiff-line-modified-added">+         copy_16_bytes_backward_with_shift(end_from, end_to, count, 8,</span>
                                          L_aligned_copy, L_copy_2_bytes);
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       // copy 4 elements (16 bytes) at a time</span>
<span class="udiff-line-added">+         __ align(OptoLoopAlignment);</span>
<span class="udiff-line-added">+       __ BIND(L_aligned_copy);</span>
<span class="udiff-line-added">+         __ dec(end_from, 16);</span>
<span class="udiff-line-added">+         __ ldx(end_from, 8, O3);</span>
<span class="udiff-line-added">+         __ ldx(end_from, 0, O4);</span>
<span class="udiff-line-added">+         __ dec(end_to, 16);</span>
<span class="udiff-line-added">+         __ deccc(count, 8);</span>
<span class="udiff-line-added">+         __ stx(O3, end_to, 8);</span>
<span class="udiff-line-added">+         __ brx(Assembler::greaterEqual, false, Assembler::pt, L_aligned_copy);</span>
<span class="udiff-line-added">+         __ delayed()-&gt;stx(O4, end_to, 0);</span>
<span class="udiff-line-added">+         __ inc(count, 8);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       // copy 1 element (2 bytes) at a time</span>
<span class="udiff-line-added">+       __ BIND(L_copy_2_bytes);</span>
<span class="udiff-line-added">+         __ cmp_and_br_short(count, 0, Assembler::equal, Assembler::pt, L_exit);</span>
<span class="udiff-line-added">+       __ BIND(L_copy_2_bytes_loop);</span>
<span class="udiff-line-added">+         __ dec(end_from, 2);</span>
<span class="udiff-line-added">+         __ dec(end_to, 2);</span>
<span class="udiff-line-added">+         __ lduh(end_from, 0, O4);</span>
<span class="udiff-line-added">+         __ deccc(count);</span>
<span class="udiff-line-added">+         __ brx(Assembler::greater, false, Assembler::pt, L_copy_2_bytes_loop);</span>
<span class="udiff-line-added">+         __ delayed()-&gt;sth(O4, end_to, 0);</span>
      }
<span class="udiff-line-removed">-     // copy 4 elements (16 bytes) at a time</span>
<span class="udiff-line-removed">-       __ align(OptoLoopAlignment);</span>
<span class="udiff-line-removed">-     __ BIND(L_aligned_copy);</span>
<span class="udiff-line-removed">-       __ dec(end_from, 16);</span>
<span class="udiff-line-removed">-       __ ldx(end_from, 8, O3);</span>
<span class="udiff-line-removed">-       __ ldx(end_from, 0, O4);</span>
<span class="udiff-line-removed">-       __ dec(end_to, 16);</span>
<span class="udiff-line-removed">-       __ deccc(count, 8);</span>
<span class="udiff-line-removed">-       __ stx(O3, end_to, 8);</span>
<span class="udiff-line-removed">-       __ brx(Assembler::greaterEqual, false, Assembler::pt, L_aligned_copy);</span>
<span class="udiff-line-removed">-       __ delayed()-&gt;stx(O4, end_to, 0);</span>
<span class="udiff-line-removed">-       __ inc(count, 8);</span>
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">-     // copy 1 element (2 bytes) at a time</span>
<span class="udiff-line-removed">-     __ BIND(L_copy_2_bytes);</span>
<span class="udiff-line-removed">-       __ cmp_and_br_short(count, 0, Assembler::equal, Assembler::pt, L_exit);</span>
<span class="udiff-line-removed">-     __ BIND(L_copy_2_bytes_loop);</span>
<span class="udiff-line-removed">-       __ dec(end_from, 2);</span>
<span class="udiff-line-removed">-       __ dec(end_to, 2);</span>
<span class="udiff-line-removed">-       __ lduh(end_from, 0, O4);</span>
<span class="udiff-line-removed">-       __ deccc(count);</span>
<span class="udiff-line-removed">-       __ brx(Assembler::greater, false, Assembler::pt, L_copy_2_bytes_loop);</span>
<span class="udiff-line-removed">-       __ delayed()-&gt;sth(O4, end_to, 0);</span>
<span class="udiff-line-removed">- </span>
      __ BIND(L_exit);
      // O3, O4 are used as temp registers
      inc_counter_np(SharedRuntime::_jshort_array_copy_ctr, O3, O4);
      __ retl();
      __ delayed()-&gt;mov(G0, O0); // return 0
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1868,13 +1901,15 @@</span>
      if (entry != NULL) {
        *entry = __ pc();
        // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
        BLOCK_COMMENT(&quot;Entry:&quot;);
      }
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-removed">-     generate_disjoint_int_copy_core(aligned);</span>
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-added">+     {</span>
<span class="udiff-line-modified-added">+       // UnsafeCopyMemory page error: continue at UnsafeCopyMemory common_error_exit</span>
<span class="udiff-line-modified-added">+       UnsafeCopyMemoryMark ucmm(this, !aligned, false);</span>
<span class="udiff-line-added">+       generate_disjoint_int_copy_core(aligned);</span>
<span class="udiff-line-added">+     }</span>
      // O3, O4 are used as temp registers
      inc_counter_np(SharedRuntime::_jint_array_copy_ctr, O3, O4);
      __ retl();
      __ delayed()-&gt;mov(G0, O0); // return 0
      return start;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2003,13 +2038,15 @@</span>
        // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
        BLOCK_COMMENT(&quot;Entry:&quot;);
      }
  
      array_overlap_test(nooverlap_target, 2);
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-removed">-     generate_conjoint_int_copy_core(aligned);</span>
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-added">+     {</span>
<span class="udiff-line-modified-added">+       // UnsafeCopyMemory page error: continue at UnsafeCopyMemory common_error_exit</span>
<span class="udiff-line-modified-added">+       UnsafeCopyMemoryMark ucmm(this, !aligned, false);</span>
<span class="udiff-line-added">+       generate_conjoint_int_copy_core(aligned);</span>
<span class="udiff-line-added">+     }</span>
      // O3, O4 are used as temp registers
      inc_counter_np(SharedRuntime::_jint_array_copy_ctr, O3, O4);
      __ retl();
      __ delayed()-&gt;mov(G0, O0); // return 0
      return start;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2154,12 +2191,15 @@</span>
        *entry = __ pc();
        // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
        BLOCK_COMMENT(&quot;Entry:&quot;);
      }
  
<span class="udiff-line-modified-removed">-     generate_disjoint_long_copy_core(aligned);</span>
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-added">+     {</span>
<span class="udiff-line-modified-added">+       // UnsafeCopyMemory page error: continue at UnsafeCopyMemory common_error_exit</span>
<span class="udiff-line-added">+       UnsafeCopyMemoryMark ucmm(this, true, false);</span>
<span class="udiff-line-added">+       generate_disjoint_long_copy_core(aligned);</span>
<span class="udiff-line-added">+     }</span>
      // O3, O4 are used as temp registers
      inc_counter_np(SharedRuntime::_jlong_array_copy_ctr, O3, O4);
      __ retl();
      __ delayed()-&gt;mov(G0, O0); // return 0
      return start;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2230,13 +2270,15 @@</span>
        // caller can pass a 64-bit byte count here (from Unsafe.copyMemory)
        BLOCK_COMMENT(&quot;Entry:&quot;);
      }
  
      array_overlap_test(nooverlap_target, 3);
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-removed">-     generate_conjoint_long_copy_core(aligned);</span>
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-added">+     {</span>
<span class="udiff-line-modified-added">+       // UnsafeCopyMemory page error: continue at UnsafeCopyMemory common_error_exit</span>
<span class="udiff-line-modified-added">+       UnsafeCopyMemoryMark ucmm(this, true, false);</span>
<span class="udiff-line-added">+       generate_conjoint_long_copy_core(aligned);</span>
<span class="udiff-line-added">+     }</span>
      // O3, O4 are used as temp registers
      inc_counter_np(SharedRuntime::_jlong_array_copy_ctr, O3, O4);
      __ retl();
      __ delayed()-&gt;mov(G0, O0); // return 0
      return start;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2927,10 +2969,13 @@</span>
      address entry_jint_arraycopy;
      address entry_oop_arraycopy;
      address entry_jlong_arraycopy;
      address entry_checkcast_arraycopy;
  
<span class="udiff-line-added">+     address ucm_common_error_exit       =  generate_unsafecopy_common_error_exit();</span>
<span class="udiff-line-added">+     UnsafeCopyMemory::set_common_exit_stub_pc(ucm_common_error_exit);</span>
<span class="udiff-line-added">+ </span>
      //*** jbyte
      // Always need aligned and unaligned versions
      StubRoutines::_jbyte_disjoint_arraycopy         = generate_disjoint_byte_copy(false, &amp;entry,
                                                                                    &quot;jbyte_disjoint_arraycopy&quot;);
      StubRoutines::_jbyte_arraycopy                  = generate_conjoint_byte_copy(false, entry,
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -5819,8 +5864,12 @@</span>
      }
    }
  
  }; // end class declaration
  
<span class="udiff-line-added">+ #define UCM_TABLE_MAX_ENTRIES 8</span>
  void StubGenerator_generate(CodeBuffer* code, bool all) {
<span class="udiff-line-added">+   if (UnsafeCopyMemory::_table == NULL) {</span>
<span class="udiff-line-added">+     UnsafeCopyMemory::create_table(UCM_TABLE_MAX_ENTRIES);</span>
<span class="udiff-line-added">+   }</span>
    StubGenerator g(code, all);
  }
</pre>
<center><a href="sparc.ad.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="templateTable_sparc.cpp.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>