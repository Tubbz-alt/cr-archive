diff a/src/hotspot/cpu/sparc/sparc.ad b/src/hotspot/cpu/sparc/sparc.ad
--- a/src/hotspot/cpu/sparc/sparc.ad
+++ b/src/hotspot/cpu/sparc/sparc.ad
@@ -1,7 +1,7 @@
 //
-// Copyright (c) 1998, 2017, Oracle and/or its affiliates. All rights reserved.
+// Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.
 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
 //
 // This code is free software; you can redistribute it and/or modify it
 // under the terms of the GNU General Public License version 2 only, as
 // published by the Free Software Foundation.
@@ -1293,11 +1293,12 @@
 }
 
 #ifndef PRODUCT
 ATTRIBUTE_PRINTF(2, 3)
 static void print_helper(outputStream* st, const char* format, ...) {
-  if (st->position() > 0) {
+  const int tab_size = 8;
+  if (st->position() > tab_size) {
     st->cr();
     st->sp();
   }
   va_list ap;
   va_start(ap, format);
@@ -1577,19 +1578,19 @@
 void MachUEPNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
   st->print_cr("\nUEP:");
   if (UseCompressedClassPointers) {
     assert(Universe::heap() != NULL, "java heap should be initialized");
     st->print_cr("\tLDUW   [R_O0 + oopDesc::klass_offset_in_bytes],R_G5\t! Inline cache check - compressed klass");
-    if (Universe::narrow_klass_base() != 0) {
-      st->print_cr("\tSET    Universe::narrow_klass_base,R_G6_heap_base");
-      if (Universe::narrow_klass_shift() != 0) {
-        st->print_cr("\tSLL    R_G5,Universe::narrow_klass_shift,R_G5");
+    if (CompressedKlassPointers::base() != 0) {
+      st->print_cr("\tSET    CompressedKlassPointers::base,R_G6_heap_base");
+      if (CompressedKlassPointers::shift() != 0) {
+        st->print_cr("\tSLL    R_G5,CompressedKlassPointers::shift,R_G5");
       }
       st->print_cr("\tADD    R_G5,R_G6_heap_base,R_G5");
-      st->print_cr("\tSET    Universe::narrow_ptrs_base,R_G6_heap_base");
+      st->print_cr("\tSET    CompressedOops::ptrs_base,R_G6_heap_base");
     } else {
-      st->print_cr("\tSLL    R_G5,Universe::narrow_klass_shift,R_G5");
+      st->print_cr("\tSLL    R_G5,CompressedKlassPointers::shift,R_G5");
     }
   } else {
     st->print_cr("\tLDX    [R_O0 + oopDesc::klass_offset_in_bytes],R_G5\t! Inline cache check");
   }
   st->print_cr("\tCMP    R_G5,R_G3" );
@@ -1708,11 +1709,11 @@
   }
 
   return true;  // Per default match rules are supported.
 }
 
-const bool Matcher::match_rule_supported_vector(int opcode, int vlen) {
+const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 
   // TODO
   // identify extra cases that we might want to provide match rules for
   // e.g. Op_ vector nodes and other intrinsics while guarding with vlen
   bool ret_value = match_rule_supported(opcode);
@@ -1812,10 +1813,28 @@
 
 // Do we need to mask the count passed to shift instructions or does
 // the cpu only look at the lower 5/6 bits anyway?
 const bool Matcher::need_masked_shift_count = false;
 
+// No support for generic vector operands.
+const bool Matcher::supports_generic_vector_operands  = false;
+
+MachOper* Matcher::specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
+  ShouldNotReachHere(); // generic vector operands not supported
+  return NULL;
+}
+
+bool Matcher::is_generic_reg2reg_move(MachNode* m) {
+  ShouldNotReachHere();  // generic vector operands not supported
+  return false;
+}
+
+bool Matcher::is_generic_vector(MachOper* opnd)  {
+  ShouldNotReachHere();  // generic vector operands not supported
+  return false;
+}
+
 bool Matcher::narrow_oop_use_complex_address() {
   assert(UseCompressedOops, "only for compressed oops code");
   return false;
 }
 
@@ -1825,18 +1844,18 @@
 }
 
 bool Matcher::const_oop_prefer_decode() {
   // TODO: Check if loading ConP from TOC in heap-based mode is better:
   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
-  // return Universe::narrow_oop_base() == NULL;
+  // return CompressedOops::base() == NULL;
   return true;
 }
 
 bool Matcher::const_klass_prefer_decode() {
   // TODO: Check if loading ConP from TOC in heap-based mode is better:
   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
-  // return Universe::narrow_klass_base() == NULL;
+  // return CompressedKlassPointers::base() == NULL;
   return true;
 }
 
 // Is it better to copy float constants, or load them directly from memory?
 // Intel can load a float constant from a direct address, requiring no
@@ -1852,12 +1871,11 @@
 
 // No-op on SPARC.
 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 }
 
-// Advertise here if the CPU requires explicit rounding operations
-// to implement the UseStrictFP mode.
+// Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 
 // Are floats converted to double when stored to stack during deoptimization?
 // Sparc does not handle callee-save floats.
 bool Matcher::float_in_double() { return false; }
@@ -6249,11 +6267,11 @@
   match(Set dst (EncodeP src));
   format %{ "encode_heap_oop $src, $dst" %}
   ins_encode %{
     __ encode_heap_oop($src$$Register, $dst$$Register);
   %}
-  ins_avoid_back_to_back(Universe::narrow_oop_base() == NULL ? AVOID_NONE : AVOID_BEFORE);
+  ins_avoid_back_to_back(CompressedOops::base() == NULL ? AVOID_NONE : AVOID_BEFORE);
   ins_pipe(ialu_reg);
 %}
 
 instruct encodeHeapOop_not_null(iRegN dst, iRegP src) %{
   predicate(n->bottom_type()->make_ptr()->ptr() == TypePtr::NotNull);
@@ -6810,10 +6828,18 @@
   ins_encode( /*empty encoding*/ );
   ins_cost(0);
   ins_pipe(empty);
 %}
 
+instruct castLL( iRegL dst ) %{
+  match(Set dst (CastLL dst));
+  format %{ "# castLL of $dst" %}
+  ins_encode( /*empty encoding*/ );
+  ins_cost(0);
+  ins_pipe(empty);
+%}
+
 //----------Arithmetic Instructions--------------------------------------------
 // Addition Instructions
 // Register Addition
 instruct addI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
   match(Set dst (AddI src1 src2));
