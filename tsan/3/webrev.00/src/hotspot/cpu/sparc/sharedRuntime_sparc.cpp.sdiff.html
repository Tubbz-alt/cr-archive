<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/sparc/sharedRuntime_sparc.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="relocInfo_sparc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="sparc.ad.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/sparc/sharedRuntime_sparc.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2003, 2018, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/macroAssembler.inline.hpp&quot;
  27 #include &quot;code/debugInfoRec.hpp&quot;
  28 #include &quot;code/icBuffer.hpp&quot;
  29 #include &quot;code/vtableStubs.hpp&quot;
  30 #include &quot;gc/shared/gcLocker.hpp&quot;
  31 #include &quot;interpreter/interpreter.hpp&quot;
  32 #include &quot;logging/log.hpp&quot;
  33 #include &quot;memory/resourceArea.hpp&quot;
  34 #include &quot;oops/compiledICHolder.hpp&quot;

  35 #include &quot;runtime/safepointMechanism.hpp&quot;
  36 #include &quot;runtime/sharedRuntime.hpp&quot;
  37 #include &quot;runtime/vframeArray.hpp&quot;
  38 #include &quot;utilities/align.hpp&quot;
  39 #include &quot;vmreg_sparc.inline.hpp&quot;
  40 #ifdef COMPILER1
  41 #include &quot;c1/c1_Runtime1.hpp&quot;
  42 #endif
  43 #ifdef COMPILER2
  44 #include &quot;opto/runtime.hpp&quot;
  45 #endif
  46 #if INCLUDE_JVMCI
  47 #include &quot;jvmci/jvmciJavaClasses.hpp&quot;
  48 #endif
  49 
  50 #define __ masm-&gt;
  51 
  52 
  53 class RegisterSaver {
  54 
</pre>
<hr />
<pre>
 544 
 545   // Write the args into the outgoing interpreter space.
 546   for (int i = 0; i &lt; total_args_passed; i++) {
 547     const int st_off = interp_arg_offset - (i*Interpreter::stackElementSize) + bias;
 548     VMReg r_1 = regs[i].first();
 549     VMReg r_2 = regs[i].second();
 550     if (!r_1-&gt;is_valid()) {
 551       assert(!r_2-&gt;is_valid(), &quot;&quot;);
 552       continue;
 553     }
 554     if (r_1-&gt;is_stack()) {        // Pretend stack targets are loaded into G1
 555       RegisterOrConstant ld_off = reg2offset(r_1) + extraspace + bias;
 556       ld_off = __ ensure_simm13_or_reg(ld_off, Rdisp);
 557       r_1 = G1_scratch-&gt;as_VMReg();// as part of the load/store shuffle
 558       if (!r_2-&gt;is_valid()) __ ld (base, ld_off, G1_scratch);
 559       else                  __ ldx(base, ld_off, G1_scratch);
 560     }
 561 
 562     if (r_1-&gt;is_Register()) {
 563       Register r = r_1-&gt;as_Register()-&gt;after_restore();
<span class="line-modified"> 564       if (sig_bt[i] == T_OBJECT || sig_bt[i] == T_ARRAY) {</span>
 565         store_c2i_object(r, base, st_off);
 566       } else if (sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {
 567         store_c2i_long(r, base, st_off, r_2-&gt;is_stack());
 568       } else {
 569         store_c2i_int(r, base, st_off);
 570       }
 571     } else {
 572       assert(r_1-&gt;is_FloatRegister(), &quot;&quot;);
 573       if (sig_bt[i] == T_FLOAT) {
 574         store_c2i_float(r_1-&gt;as_FloatRegister(), base, st_off);
 575       } else {
 576         assert(sig_bt[i] == T_DOUBLE, &quot;wrong type&quot;);
 577         store_c2i_double(r_2, r_1, base, st_off);
 578       }
 579     }
 580   }
 581 
 582   // Load the interpreter entry point.
 583   __ ld_ptr(G5_method, in_bytes(Method::interpreter_entry_offset()), G3_scratch);
 584 
</pre>
<hr />
<pre>
1620   __ brx(Assembler::equal, false, Assembler::pt, is_null);
1621   __ delayed()-&gt;add(reg.first()-&gt;as_Register(), arrayOopDesc::base_offset_in_bytes(in_elem_type), L4);
1622   move_ptr(masm, reg64_to_VMRegPair(L4), body_arg);
1623   __ ld(reg.first()-&gt;as_Register(), arrayOopDesc::length_offset_in_bytes(), L4);
1624   move32_64(masm, reg64_to_VMRegPair(L4), length_arg);
1625   __ ba_short(done);
1626   __ bind(is_null);
1627   // Pass zeros
1628   move_ptr(masm, reg64_to_VMRegPair(G0), body_arg);
1629   move32_64(masm, reg64_to_VMRegPair(G0), length_arg);
1630   __ bind(done);
1631 }
1632 
1633 static void verify_oop_args(MacroAssembler* masm,
1634                             const methodHandle&amp; method,
1635                             const BasicType* sig_bt,
1636                             const VMRegPair* regs) {
1637   Register temp_reg = G5_method;  // not part of any compiled calling seq
1638   if (VerifyOops) {
1639     for (int i = 0; i &lt; method-&gt;size_of_parameters(); i++) {
<span class="line-modified">1640       if (sig_bt[i] == T_OBJECT ||</span>
<span class="line-removed">1641           sig_bt[i] == T_ARRAY) {</span>
1642         VMReg r = regs[i].first();
1643         assert(r-&gt;is_valid(), &quot;bad oop arg&quot;);
1644         if (r-&gt;is_stack()) {
1645           RegisterOrConstant ld_off = reg2offset(r) + STACK_BIAS;
1646           ld_off = __ ensure_simm13_or_reg(ld_off, temp_reg);
1647           __ ld_ptr(SP, ld_off, temp_reg);
1648           __ verify_oop(temp_reg);
1649         } else {
1650           __ verify_oop(r-&gt;as_Register());
1651         }
1652       }
1653     }
1654   }
1655 }
1656 
1657 static void gen_special_dispatch(MacroAssembler* masm,
1658                                  const methodHandle&amp; method,
1659                                  const BasicType* sig_bt,
1660                                  const VMRegPair* regs) {
1661   verify_oop_args(masm, method, sig_bt, regs);
</pre>
<hr />
<pre>
1734 // block and the check for pending exceptions it&#39;s impossible for them
1735 // to be thrown.
1736 //
1737 // They are roughly structured like this:
1738 //    if (GCLocker::needs_gc())
1739 //      SharedRuntime::block_for_jni_critical();
1740 //    tranistion to thread_in_native
1741 //    unpack arrray arguments and call native entry point
1742 //    check for safepoint in progress
1743 //    check if any thread suspend flags are set
1744 //      call into JVM and possible unlock the JNI critical
1745 //      if a GC was suppressed while in the critical native.
1746 //    transition back to thread_in_Java
1747 //    return to caller
1748 //
1749 nmethod* SharedRuntime::generate_native_wrapper(MacroAssembler* masm,
1750                                                 const methodHandle&amp; method,
1751                                                 int compile_id,
1752                                                 BasicType* in_sig_bt,
1753                                                 VMRegPair* in_regs,
<span class="line-modified">1754                                                 BasicType ret_type) {</span>

1755   if (method-&gt;is_method_handle_intrinsic()) {
1756     vmIntrinsics::ID iid = method-&gt;intrinsic_id();
1757     intptr_t start = (intptr_t)__ pc();
1758     int vep_offset = ((intptr_t)__ pc()) - start;
1759     gen_special_dispatch(masm,
1760                          method,
1761                          in_sig_bt,
1762                          in_regs);
1763     int frame_complete = ((intptr_t)__ pc()) - start;  // not complete, period
1764     __ flush();
1765     int stack_slots = SharedRuntime::out_preserve_stack_slots();  // no out slots at all, actually
1766     return nmethod::new_native_nmethod(method,
1767                                        compile_id,
1768                                        masm-&gt;code(),
1769                                        vep_offset,
1770                                        frame_complete,
1771                                        stack_slots / VMRegImpl::slots_per_word,
1772                                        in_ByteSize(-1),
1773                                        in_ByteSize(-1),
1774                                        (OopMapSet*)NULL);
1775   }
1776   bool is_critical_native = true;
<span class="line-modified">1777   address native_func = method-&gt;critical_native_function();</span>
1778   if (native_func == NULL) {
1779     native_func = method-&gt;native_function();
1780     is_critical_native = false;
1781   }
1782   assert(native_func != NULL, &quot;must have function&quot;);
1783 
1784   // Native nmethod wrappers never take possesion of the oop arguments.
1785   // So the caller will gc the arguments. The only thing we need an
1786   // oopMap for is if the call is static
1787   //
1788   // An OopMap for lock (and class if static), and one for the VM call itself
1789   OopMapSet *oop_maps = new OopMapSet();
1790   intptr_t start = (intptr_t)__ pc();
1791 
1792   // First thing make an ic check to see if we should even be here
1793   {
1794     Label L;
1795     const Register temp_reg = G3_scratch;
1796     AddressLiteral ic_miss(SharedRuntime::get_ic_miss_stub());
1797     __ verify_oop(O0);
</pre>
<hr />
<pre>
1815     Label slowCase;
1816     Label done;
1817     Register obj_reg              = O0;
1818     Register result               = O0;
1819     Register header               = G3_scratch;
1820     Register hash                 = G3_scratch; // overwrite header value with hash value
1821     Register mask                 = G1;         // to get hash field from header
1822 
1823     // Unlike for Object.hashCode, System.identityHashCode is static method and
1824     // gets object as argument instead of the receiver.
1825     if (method-&gt;intrinsic_id() == vmIntrinsics::_identityHashCode) {
1826       assert(method-&gt;is_static(), &quot;method should be static&quot;);
1827       // return 0 for null reference input
1828       __ br_null(obj_reg, false, Assembler::pn, done);
1829       __ delayed()-&gt;mov(obj_reg, hash);
1830     }
1831 
1832     // Read the header and build a mask to get its hash field.  Give up if the object is not unlocked.
1833     // We depend on hash_mask being at most 32 bits and avoid the use of
1834     // hash_mask_in_place because it could be larger than 32 bits in a 64-bit
<span class="line-modified">1835     // vm: see markOop.hpp.</span>
1836     __ ld_ptr(obj_reg, oopDesc::mark_offset_in_bytes(), header);
<span class="line-modified">1837     __ sethi(markOopDesc::hash_mask, mask);</span>
<span class="line-modified">1838     __ btst(markOopDesc::unlocked_value, header);</span>
1839     __ br(Assembler::zero, false, Assembler::pn, slowCase);
1840     if (UseBiasedLocking) {
1841       // Check if biased and fall through to runtime if so
1842       __ delayed()-&gt;nop();
<span class="line-modified">1843       __ btst(markOopDesc::biased_lock_bit_in_place, header);</span>
1844       __ br(Assembler::notZero, false, Assembler::pn, slowCase);
1845     }
<span class="line-modified">1846     __ delayed()-&gt;or3(mask, markOopDesc::hash_mask &amp; 0x3ff, mask);</span>
1847 
1848     // Check for a valid (non-zero) hash code and get its value.
<span class="line-modified">1849     __ srlx(header, markOopDesc::hash_shift, hash);</span>
1850     __ andcc(hash, mask, hash);
1851     __ br(Assembler::equal, false, Assembler::pn, slowCase);
1852     __ delayed()-&gt;nop();
1853 
1854     // leaf return.
1855     __ bind(done);
1856     __ retl();
1857     __ delayed()-&gt;mov(hash, result);
1858     __ bind(slowCase);
1859   }
1860 #endif // COMPILER1
1861 
1862 
1863   // We have received a description of where all the java arg are located
1864   // on entry to the wrapper. We need to convert these args to where
1865   // the jni function will expect them. To figure out where they go
1866   // we convert the java signature to a C signature by inserting
1867   // the hidden arguments as arg[0] and possibly arg[1] (static method)
1868 
1869   const int total_in_args = method-&gt;size_of_parameters();
</pre>
<hr />
<pre>
1889 
1890   int argc = 0;
1891   if (!is_critical_native) {
1892     out_sig_bt[argc++] = T_ADDRESS;
1893     if (method-&gt;is_static()) {
1894       out_sig_bt[argc++] = T_OBJECT;
1895     }
1896 
1897     for (int i = 0; i &lt; total_in_args ; i++ ) {
1898       out_sig_bt[argc++] = in_sig_bt[i];
1899     }
1900   } else {
1901     Thread* THREAD = Thread::current();
1902     in_elem_bt = NEW_RESOURCE_ARRAY(BasicType, total_in_args);
1903     SignatureStream ss(method-&gt;signature());
1904     for (int i = 0; i &lt; total_in_args ; i++ ) {
1905       if (in_sig_bt[i] == T_ARRAY) {
1906         // Arrays are passed as int, elem* pair
1907         out_sig_bt[argc++] = T_INT;
1908         out_sig_bt[argc++] = T_ADDRESS;
<span class="line-modified">1909         Symbol* atype = ss.as_symbol(CHECK_NULL);</span>
<span class="line-modified">1910         const char* at = atype-&gt;as_C_string();</span>
<span class="line-modified">1911         if (strlen(at) == 2) {</span>
<span class="line-removed">1912           assert(at[0] == &#39;[&#39;, &quot;must be&quot;);</span>
<span class="line-removed">1913           switch (at[1]) {</span>
<span class="line-removed">1914             case &#39;B&#39;: in_elem_bt[i]  = T_BYTE; break;</span>
<span class="line-removed">1915             case &#39;C&#39;: in_elem_bt[i]  = T_CHAR; break;</span>
<span class="line-removed">1916             case &#39;D&#39;: in_elem_bt[i]  = T_DOUBLE; break;</span>
<span class="line-removed">1917             case &#39;F&#39;: in_elem_bt[i]  = T_FLOAT; break;</span>
<span class="line-removed">1918             case &#39;I&#39;: in_elem_bt[i]  = T_INT; break;</span>
<span class="line-removed">1919             case &#39;J&#39;: in_elem_bt[i]  = T_LONG; break;</span>
<span class="line-removed">1920             case &#39;S&#39;: in_elem_bt[i]  = T_SHORT; break;</span>
<span class="line-removed">1921             case &#39;Z&#39;: in_elem_bt[i]  = T_BOOLEAN; break;</span>
<span class="line-removed">1922             default: ShouldNotReachHere();</span>
<span class="line-removed">1923           }</span>
<span class="line-removed">1924         }</span>
1925       } else {
1926         out_sig_bt[argc++] = in_sig_bt[i];
1927         in_elem_bt[i] = T_VOID;
1928       }
1929       if (in_sig_bt[i] != T_VOID) {
<span class="line-modified">1930         assert(in_sig_bt[i] == ss.type(), &quot;must match&quot;);</span>

1931         ss.next();
1932       }
1933     }
1934   }
1935 
1936   // Now figure out where the args must be stored and how much stack space
1937   // they require (neglecting out_preserve_stack_slots but space for storing
1938   // the 1st six register arguments). It&#39;s weird see int_stk_helper.
1939   //
1940   int out_arg_slots;
1941   out_arg_slots = c_calling_convention(out_sig_bt, out_regs, NULL, total_c_args);
1942 
1943   if (is_critical_native) {
1944     // Critical natives may have to call out so they need a save area
1945     // for register arguments.
1946     int double_slots = 0;
1947     int single_slots = 0;
1948     for ( int i = 0; i &lt; total_in_args; i++) {
1949       if (in_regs[i].first()-&gt;is_Register()) {
1950         const Register reg = in_regs[i].first()-&gt;as_Register();
</pre>
<hr />
<pre>
2489     __ bind(done);
2490   }
2491 
2492   // Tell dtrace about this method exit
2493   {
2494     SkipIfEqual skip_if(
2495       masm, G3_scratch, &amp;DTraceMethodProbes, Assembler::zero);
2496     save_native_result(masm, ret_type, stack_slots);
2497     __ set_metadata_constant(method(), O1);
2498     __ call_VM_leaf(L7_thread_cache,
2499        CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_method_exit),
2500        G2_thread, O1);
2501     restore_native_result(masm, ret_type, stack_slots);
2502   }
2503 
2504   // Clear &quot;last Java frame&quot; SP and PC.
2505   __ verify_thread(); // G2_thread must be correct
2506   __ reset_last_Java_frame();
2507 
2508   // Unbox oop result, e.g. JNIHandles::resolve value in I0.
<span class="line-modified">2509   if (ret_type == T_OBJECT || ret_type == T_ARRAY) {</span>
2510     __ resolve_jobject(I0, G3_scratch);
2511   }
2512 
2513   if (CheckJNICalls) {
2514     // clear_pending_jni_exception_check
2515     __ st_ptr(G0, G2_thread, JavaThread::pending_jni_exception_check_fn_offset());
2516   }
2517 
2518   if (!is_critical_native) {
2519     // reset handle block
2520     __ ld_ptr(G2_thread, in_bytes(JavaThread::active_handles_offset()), L5);
2521     __ st(G0, L5, JNIHandleBlock::top_offset_in_bytes());
2522 
2523     __ ld_ptr(G2_thread, in_bytes(Thread::pending_exception_offset()), G3_scratch);
2524     check_forward_pending_exception(masm, G3_scratch);
2525   }
2526 
2527 
2528   // Return
2529 
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/macroAssembler.inline.hpp&quot;
  27 #include &quot;code/debugInfoRec.hpp&quot;
  28 #include &quot;code/icBuffer.hpp&quot;
  29 #include &quot;code/vtableStubs.hpp&quot;
  30 #include &quot;gc/shared/gcLocker.hpp&quot;
  31 #include &quot;interpreter/interpreter.hpp&quot;
  32 #include &quot;logging/log.hpp&quot;
  33 #include &quot;memory/resourceArea.hpp&quot;
  34 #include &quot;oops/compiledICHolder.hpp&quot;
<span class="line-added">  35 #include &quot;oops/klass.inline.hpp&quot;</span>
  36 #include &quot;runtime/safepointMechanism.hpp&quot;
  37 #include &quot;runtime/sharedRuntime.hpp&quot;
  38 #include &quot;runtime/vframeArray.hpp&quot;
  39 #include &quot;utilities/align.hpp&quot;
  40 #include &quot;vmreg_sparc.inline.hpp&quot;
  41 #ifdef COMPILER1
  42 #include &quot;c1/c1_Runtime1.hpp&quot;
  43 #endif
  44 #ifdef COMPILER2
  45 #include &quot;opto/runtime.hpp&quot;
  46 #endif
  47 #if INCLUDE_JVMCI
  48 #include &quot;jvmci/jvmciJavaClasses.hpp&quot;
  49 #endif
  50 
  51 #define __ masm-&gt;
  52 
  53 
  54 class RegisterSaver {
  55 
</pre>
<hr />
<pre>
 545 
 546   // Write the args into the outgoing interpreter space.
 547   for (int i = 0; i &lt; total_args_passed; i++) {
 548     const int st_off = interp_arg_offset - (i*Interpreter::stackElementSize) + bias;
 549     VMReg r_1 = regs[i].first();
 550     VMReg r_2 = regs[i].second();
 551     if (!r_1-&gt;is_valid()) {
 552       assert(!r_2-&gt;is_valid(), &quot;&quot;);
 553       continue;
 554     }
 555     if (r_1-&gt;is_stack()) {        // Pretend stack targets are loaded into G1
 556       RegisterOrConstant ld_off = reg2offset(r_1) + extraspace + bias;
 557       ld_off = __ ensure_simm13_or_reg(ld_off, Rdisp);
 558       r_1 = G1_scratch-&gt;as_VMReg();// as part of the load/store shuffle
 559       if (!r_2-&gt;is_valid()) __ ld (base, ld_off, G1_scratch);
 560       else                  __ ldx(base, ld_off, G1_scratch);
 561     }
 562 
 563     if (r_1-&gt;is_Register()) {
 564       Register r = r_1-&gt;as_Register()-&gt;after_restore();
<span class="line-modified"> 565       if (is_reference_type(sig_bt[i])) {</span>
 566         store_c2i_object(r, base, st_off);
 567       } else if (sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {
 568         store_c2i_long(r, base, st_off, r_2-&gt;is_stack());
 569       } else {
 570         store_c2i_int(r, base, st_off);
 571       }
 572     } else {
 573       assert(r_1-&gt;is_FloatRegister(), &quot;&quot;);
 574       if (sig_bt[i] == T_FLOAT) {
 575         store_c2i_float(r_1-&gt;as_FloatRegister(), base, st_off);
 576       } else {
 577         assert(sig_bt[i] == T_DOUBLE, &quot;wrong type&quot;);
 578         store_c2i_double(r_2, r_1, base, st_off);
 579       }
 580     }
 581   }
 582 
 583   // Load the interpreter entry point.
 584   __ ld_ptr(G5_method, in_bytes(Method::interpreter_entry_offset()), G3_scratch);
 585 
</pre>
<hr />
<pre>
1621   __ brx(Assembler::equal, false, Assembler::pt, is_null);
1622   __ delayed()-&gt;add(reg.first()-&gt;as_Register(), arrayOopDesc::base_offset_in_bytes(in_elem_type), L4);
1623   move_ptr(masm, reg64_to_VMRegPair(L4), body_arg);
1624   __ ld(reg.first()-&gt;as_Register(), arrayOopDesc::length_offset_in_bytes(), L4);
1625   move32_64(masm, reg64_to_VMRegPair(L4), length_arg);
1626   __ ba_short(done);
1627   __ bind(is_null);
1628   // Pass zeros
1629   move_ptr(masm, reg64_to_VMRegPair(G0), body_arg);
1630   move32_64(masm, reg64_to_VMRegPair(G0), length_arg);
1631   __ bind(done);
1632 }
1633 
1634 static void verify_oop_args(MacroAssembler* masm,
1635                             const methodHandle&amp; method,
1636                             const BasicType* sig_bt,
1637                             const VMRegPair* regs) {
1638   Register temp_reg = G5_method;  // not part of any compiled calling seq
1639   if (VerifyOops) {
1640     for (int i = 0; i &lt; method-&gt;size_of_parameters(); i++) {
<span class="line-modified">1641       if (is_reference_type(sig_bt[i])) {</span>

1642         VMReg r = regs[i].first();
1643         assert(r-&gt;is_valid(), &quot;bad oop arg&quot;);
1644         if (r-&gt;is_stack()) {
1645           RegisterOrConstant ld_off = reg2offset(r) + STACK_BIAS;
1646           ld_off = __ ensure_simm13_or_reg(ld_off, temp_reg);
1647           __ ld_ptr(SP, ld_off, temp_reg);
1648           __ verify_oop(temp_reg);
1649         } else {
1650           __ verify_oop(r-&gt;as_Register());
1651         }
1652       }
1653     }
1654   }
1655 }
1656 
1657 static void gen_special_dispatch(MacroAssembler* masm,
1658                                  const methodHandle&amp; method,
1659                                  const BasicType* sig_bt,
1660                                  const VMRegPair* regs) {
1661   verify_oop_args(masm, method, sig_bt, regs);
</pre>
<hr />
<pre>
1734 // block and the check for pending exceptions it&#39;s impossible for them
1735 // to be thrown.
1736 //
1737 // They are roughly structured like this:
1738 //    if (GCLocker::needs_gc())
1739 //      SharedRuntime::block_for_jni_critical();
1740 //    tranistion to thread_in_native
1741 //    unpack arrray arguments and call native entry point
1742 //    check for safepoint in progress
1743 //    check if any thread suspend flags are set
1744 //      call into JVM and possible unlock the JNI critical
1745 //      if a GC was suppressed while in the critical native.
1746 //    transition back to thread_in_Java
1747 //    return to caller
1748 //
1749 nmethod* SharedRuntime::generate_native_wrapper(MacroAssembler* masm,
1750                                                 const methodHandle&amp; method,
1751                                                 int compile_id,
1752                                                 BasicType* in_sig_bt,
1753                                                 VMRegPair* in_regs,
<span class="line-modified">1754                                                 BasicType ret_type,</span>
<span class="line-added">1755                                                 address critical_entry) {</span>
1756   if (method-&gt;is_method_handle_intrinsic()) {
1757     vmIntrinsics::ID iid = method-&gt;intrinsic_id();
1758     intptr_t start = (intptr_t)__ pc();
1759     int vep_offset = ((intptr_t)__ pc()) - start;
1760     gen_special_dispatch(masm,
1761                          method,
1762                          in_sig_bt,
1763                          in_regs);
1764     int frame_complete = ((intptr_t)__ pc()) - start;  // not complete, period
1765     __ flush();
1766     int stack_slots = SharedRuntime::out_preserve_stack_slots();  // no out slots at all, actually
1767     return nmethod::new_native_nmethod(method,
1768                                        compile_id,
1769                                        masm-&gt;code(),
1770                                        vep_offset,
1771                                        frame_complete,
1772                                        stack_slots / VMRegImpl::slots_per_word,
1773                                        in_ByteSize(-1),
1774                                        in_ByteSize(-1),
1775                                        (OopMapSet*)NULL);
1776   }
1777   bool is_critical_native = true;
<span class="line-modified">1778   address native_func = critical_entry;</span>
1779   if (native_func == NULL) {
1780     native_func = method-&gt;native_function();
1781     is_critical_native = false;
1782   }
1783   assert(native_func != NULL, &quot;must have function&quot;);
1784 
1785   // Native nmethod wrappers never take possesion of the oop arguments.
1786   // So the caller will gc the arguments. The only thing we need an
1787   // oopMap for is if the call is static
1788   //
1789   // An OopMap for lock (and class if static), and one for the VM call itself
1790   OopMapSet *oop_maps = new OopMapSet();
1791   intptr_t start = (intptr_t)__ pc();
1792 
1793   // First thing make an ic check to see if we should even be here
1794   {
1795     Label L;
1796     const Register temp_reg = G3_scratch;
1797     AddressLiteral ic_miss(SharedRuntime::get_ic_miss_stub());
1798     __ verify_oop(O0);
</pre>
<hr />
<pre>
1816     Label slowCase;
1817     Label done;
1818     Register obj_reg              = O0;
1819     Register result               = O0;
1820     Register header               = G3_scratch;
1821     Register hash                 = G3_scratch; // overwrite header value with hash value
1822     Register mask                 = G1;         // to get hash field from header
1823 
1824     // Unlike for Object.hashCode, System.identityHashCode is static method and
1825     // gets object as argument instead of the receiver.
1826     if (method-&gt;intrinsic_id() == vmIntrinsics::_identityHashCode) {
1827       assert(method-&gt;is_static(), &quot;method should be static&quot;);
1828       // return 0 for null reference input
1829       __ br_null(obj_reg, false, Assembler::pn, done);
1830       __ delayed()-&gt;mov(obj_reg, hash);
1831     }
1832 
1833     // Read the header and build a mask to get its hash field.  Give up if the object is not unlocked.
1834     // We depend on hash_mask being at most 32 bits and avoid the use of
1835     // hash_mask_in_place because it could be larger than 32 bits in a 64-bit
<span class="line-modified">1836     // vm: see markWord.hpp.</span>
1837     __ ld_ptr(obj_reg, oopDesc::mark_offset_in_bytes(), header);
<span class="line-modified">1838     __ sethi(markWord::hash_mask, mask);</span>
<span class="line-modified">1839     __ btst(markWord::unlocked_value, header);</span>
1840     __ br(Assembler::zero, false, Assembler::pn, slowCase);
1841     if (UseBiasedLocking) {
1842       // Check if biased and fall through to runtime if so
1843       __ delayed()-&gt;nop();
<span class="line-modified">1844       __ btst(markWord::biased_lock_bit_in_place, header);</span>
1845       __ br(Assembler::notZero, false, Assembler::pn, slowCase);
1846     }
<span class="line-modified">1847     __ delayed()-&gt;or3(mask, markWord::hash_mask &amp; 0x3ff, mask);</span>
1848 
1849     // Check for a valid (non-zero) hash code and get its value.
<span class="line-modified">1850     __ srlx(header, markWord::hash_shift, hash);</span>
1851     __ andcc(hash, mask, hash);
1852     __ br(Assembler::equal, false, Assembler::pn, slowCase);
1853     __ delayed()-&gt;nop();
1854 
1855     // leaf return.
1856     __ bind(done);
1857     __ retl();
1858     __ delayed()-&gt;mov(hash, result);
1859     __ bind(slowCase);
1860   }
1861 #endif // COMPILER1
1862 
1863 
1864   // We have received a description of where all the java arg are located
1865   // on entry to the wrapper. We need to convert these args to where
1866   // the jni function will expect them. To figure out where they go
1867   // we convert the java signature to a C signature by inserting
1868   // the hidden arguments as arg[0] and possibly arg[1] (static method)
1869 
1870   const int total_in_args = method-&gt;size_of_parameters();
</pre>
<hr />
<pre>
1890 
1891   int argc = 0;
1892   if (!is_critical_native) {
1893     out_sig_bt[argc++] = T_ADDRESS;
1894     if (method-&gt;is_static()) {
1895       out_sig_bt[argc++] = T_OBJECT;
1896     }
1897 
1898     for (int i = 0; i &lt; total_in_args ; i++ ) {
1899       out_sig_bt[argc++] = in_sig_bt[i];
1900     }
1901   } else {
1902     Thread* THREAD = Thread::current();
1903     in_elem_bt = NEW_RESOURCE_ARRAY(BasicType, total_in_args);
1904     SignatureStream ss(method-&gt;signature());
1905     for (int i = 0; i &lt; total_in_args ; i++ ) {
1906       if (in_sig_bt[i] == T_ARRAY) {
1907         // Arrays are passed as int, elem* pair
1908         out_sig_bt[argc++] = T_INT;
1909         out_sig_bt[argc++] = T_ADDRESS;
<span class="line-modified">1910         ss.skip_array_prefix(1);  // skip one &#39;[&#39;</span>
<span class="line-modified">1911         assert(ss.is_primitive(), &quot;primitive type expected&quot;);</span>
<span class="line-modified">1912         in_elem_bt[i] = ss.type();</span>













1913       } else {
1914         out_sig_bt[argc++] = in_sig_bt[i];
1915         in_elem_bt[i] = T_VOID;
1916       }
1917       if (in_sig_bt[i] != T_VOID) {
<span class="line-modified">1918         assert(in_sig_bt[i] == ss.type() ||</span>
<span class="line-added">1919                in_sig_bt[i] == T_ARRAY, &quot;must match&quot;);</span>
1920         ss.next();
1921       }
1922     }
1923   }
1924 
1925   // Now figure out where the args must be stored and how much stack space
1926   // they require (neglecting out_preserve_stack_slots but space for storing
1927   // the 1st six register arguments). It&#39;s weird see int_stk_helper.
1928   //
1929   int out_arg_slots;
1930   out_arg_slots = c_calling_convention(out_sig_bt, out_regs, NULL, total_c_args);
1931 
1932   if (is_critical_native) {
1933     // Critical natives may have to call out so they need a save area
1934     // for register arguments.
1935     int double_slots = 0;
1936     int single_slots = 0;
1937     for ( int i = 0; i &lt; total_in_args; i++) {
1938       if (in_regs[i].first()-&gt;is_Register()) {
1939         const Register reg = in_regs[i].first()-&gt;as_Register();
</pre>
<hr />
<pre>
2478     __ bind(done);
2479   }
2480 
2481   // Tell dtrace about this method exit
2482   {
2483     SkipIfEqual skip_if(
2484       masm, G3_scratch, &amp;DTraceMethodProbes, Assembler::zero);
2485     save_native_result(masm, ret_type, stack_slots);
2486     __ set_metadata_constant(method(), O1);
2487     __ call_VM_leaf(L7_thread_cache,
2488        CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_method_exit),
2489        G2_thread, O1);
2490     restore_native_result(masm, ret_type, stack_slots);
2491   }
2492 
2493   // Clear &quot;last Java frame&quot; SP and PC.
2494   __ verify_thread(); // G2_thread must be correct
2495   __ reset_last_Java_frame();
2496 
2497   // Unbox oop result, e.g. JNIHandles::resolve value in I0.
<span class="line-modified">2498   if (is_reference_type(ret_type)) {</span>
2499     __ resolve_jobject(I0, G3_scratch);
2500   }
2501 
2502   if (CheckJNICalls) {
2503     // clear_pending_jni_exception_check
2504     __ st_ptr(G0, G2_thread, JavaThread::pending_jni_exception_check_fn_offset());
2505   }
2506 
2507   if (!is_critical_native) {
2508     // reset handle block
2509     __ ld_ptr(G2_thread, in_bytes(JavaThread::active_handles_offset()), L5);
2510     __ st(G0, L5, JNIHandleBlock::top_offset_in_bytes());
2511 
2512     __ ld_ptr(G2_thread, in_bytes(Thread::pending_exception_offset()), G3_scratch);
2513     check_forward_pending_exception(masm, G3_scratch);
2514   }
2515 
2516 
2517   // Return
2518 
</pre>
</td>
</tr>
</table>
<center><a href="relocInfo_sparc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="sparc.ad.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>