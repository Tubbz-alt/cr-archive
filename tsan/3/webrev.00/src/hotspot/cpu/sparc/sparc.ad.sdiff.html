<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/sparc/sparc.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="sharedRuntime_sparc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_sparc.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/sparc/sparc.ad</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
    1 //
<span class="line-modified">    2 // Copyright (c) 1998, 2017, Oracle and/or its affiliates. All rights reserved.</span>
    3 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    4 //
    5 // This code is free software; you can redistribute it and/or modify it
    6 // under the terms of the GNU General Public License version 2 only, as
    7 // published by the Free Software Foundation.
    8 //
    9 // This code is distributed in the hope that it will be useful, but WITHOUT
   10 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   11 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   12 // version 2 for more details (a copy is included in the LICENSE file that
   13 // accompanied this code).
   14 //
   15 // You should have received a copy of the GNU General Public License version
   16 // 2 along with this work; if not, write to the Free Software Foundation,
   17 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   18 //
   19 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   20 // or visit www.oracle.com if you need additional information or have any
   21 // questions.
   22 //
</pre>
<hr />
<pre>
 1278   assert( do_polling(), &quot;no return for this epilog node&quot;);
 1279   return MacroAssembler::insts_for_sethi(os::get_polling_page()) * BytesPerInstWord;
 1280 }
 1281 
 1282 //=============================================================================
 1283 
 1284 // Figure out which register class each belongs in: rc_int, rc_float, rc_stack
 1285 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1286 static enum RC rc_class( OptoReg::Name reg ) {
 1287   if (!OptoReg::is_valid(reg)) return rc_bad;
 1288   if (OptoReg::is_stack(reg)) return rc_stack;
 1289   VMReg r = OptoReg::as_VMReg(reg);
 1290   if (r-&gt;is_Register()) return rc_int;
 1291   assert(r-&gt;is_FloatRegister(), &quot;must be&quot;);
 1292   return rc_float;
 1293 }
 1294 
 1295 #ifndef PRODUCT
 1296 ATTRIBUTE_PRINTF(2, 3)
 1297 static void print_helper(outputStream* st, const char* format, ...) {
<span class="line-modified"> 1298   if (st-&gt;position() &gt; 0) {</span>

 1299     st-&gt;cr();
 1300     st-&gt;sp();
 1301   }
 1302   va_list ap;
 1303   va_start(ap, format);
 1304   st-&gt;vprint(format, ap);
 1305   va_end(ap);
 1306 }
 1307 #endif // !PRODUCT
 1308 
 1309 static void impl_helper(const MachNode* mach, CodeBuffer* cbuf, PhaseRegAlloc* ra, bool is_load, int offset, int reg, int opcode, const char *op_str, outputStream* st) {
 1310   if (cbuf) {
 1311     emit_form3_mem_reg(*cbuf, ra, mach, opcode, -1, R_SP_enc, offset, 0, Matcher::_regEncode[reg]);
 1312   }
 1313 #ifndef PRODUCT
 1314   else {
 1315     if (is_load) {
 1316       print_helper(st, &quot;%s   [R_SP + #%d],R_%s\t! spill&quot;, op_str, offset, OptoReg::regname(reg));
 1317     } else {
 1318       print_helper(st, &quot;%s   R_%s,[R_SP + #%d]\t! spill&quot;, op_str, OptoReg::regname(reg), offset);
</pre>
<hr />
<pre>
 1562      __ add(SP, offset, reg_to_register_object(reg));
 1563   } else {
 1564      __ set(offset, O7);
 1565      __ add(SP, O7, reg_to_register_object(reg));
 1566   }
 1567 }
 1568 
 1569 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1570   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_)
 1571   assert(ra_ == ra_-&gt;C-&gt;regalloc(), &quot;sanity&quot;);
 1572   return ra_-&gt;C-&gt;scratch_emit_size(this);
 1573 }
 1574 
 1575 //=============================================================================
 1576 #ifndef PRODUCT
 1577 void MachUEPNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
 1578   st-&gt;print_cr(&quot;\nUEP:&quot;);
 1579   if (UseCompressedClassPointers) {
 1580     assert(Universe::heap() != NULL, &quot;java heap should be initialized&quot;);
 1581     st-&gt;print_cr(&quot;\tLDUW   [R_O0 + oopDesc::klass_offset_in_bytes],R_G5\t! Inline cache check - compressed klass&quot;);
<span class="line-modified"> 1582     if (Universe::narrow_klass_base() != 0) {</span>
<span class="line-modified"> 1583       st-&gt;print_cr(&quot;\tSET    Universe::narrow_klass_base,R_G6_heap_base&quot;);</span>
<span class="line-modified"> 1584       if (Universe::narrow_klass_shift() != 0) {</span>
<span class="line-modified"> 1585         st-&gt;print_cr(&quot;\tSLL    R_G5,Universe::narrow_klass_shift,R_G5&quot;);</span>
 1586       }
 1587       st-&gt;print_cr(&quot;\tADD    R_G5,R_G6_heap_base,R_G5&quot;);
<span class="line-modified"> 1588       st-&gt;print_cr(&quot;\tSET    Universe::narrow_ptrs_base,R_G6_heap_base&quot;);</span>
 1589     } else {
<span class="line-modified"> 1590       st-&gt;print_cr(&quot;\tSLL    R_G5,Universe::narrow_klass_shift,R_G5&quot;);</span>
 1591     }
 1592   } else {
 1593     st-&gt;print_cr(&quot;\tLDX    [R_O0 + oopDesc::klass_offset_in_bytes],R_G5\t! Inline cache check&quot;);
 1594   }
 1595   st-&gt;print_cr(&quot;\tCMP    R_G5,R_G3&quot; );
 1596   st-&gt;print   (&quot;\tTne    xcc,R_G0+ST_RESERVED_FOR_USER_0+2&quot;);
 1597 }
 1598 #endif
 1599 
 1600 void MachUEPNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1601   MacroAssembler _masm(&amp;cbuf);
 1602   Register G5_ic_reg  = reg_to_register_object(Matcher::inline_cache_reg_encode());
 1603   Register temp_reg   = G3;
 1604   assert( G5_ic_reg != temp_reg, &quot;conflicting registers&quot; );
 1605 
 1606   // Load klass from receiver
 1607   __ load_klass(O0, temp_reg);
 1608   // Compare against expected klass
 1609   __ cmp(temp_reg, G5_ic_reg);
 1610   // Branch to miss code, checks xcc or icc depending
</pre>
<hr />
<pre>
 1693 
 1694   switch (opcode) {
 1695   case Op_CountLeadingZerosI:
 1696   case Op_CountLeadingZerosL:
 1697   case Op_CountTrailingZerosI:
 1698   case Op_CountTrailingZerosL:
 1699   case Op_PopCountI:
 1700   case Op_PopCountL:
 1701     if (!UsePopCountInstruction)
 1702       return false;
 1703   case Op_CompareAndSwapL:
 1704   case Op_CompareAndSwapP:
 1705     if (!VM_Version::supports_cx8())
 1706       return false;
 1707     break;
 1708   }
 1709 
 1710   return true;  // Per default match rules are supported.
 1711 }
 1712 
<span class="line-modified"> 1713 const bool Matcher::match_rule_supported_vector(int opcode, int vlen) {</span>
 1714 
 1715   // TODO
 1716   // identify extra cases that we might want to provide match rules for
 1717   // e.g. Op_ vector nodes and other intrinsics while guarding with vlen
 1718   bool ret_value = match_rule_supported(opcode);
 1719   // Add rules here.
 1720 
 1721   return ret_value;  // Per default match rules are supported.
 1722 }
 1723 
 1724 const bool Matcher::has_predicated_vectors(void) {
 1725   return false;
 1726 }
 1727 
 1728 const int Matcher::float_pressure(int default_pressure_threshold) {
 1729   return default_pressure_threshold;
 1730 }
 1731 
 1732 int Matcher::regnum_to_fpu_offset(int regnum) {
 1733   return regnum - 32; // The FP registers are in the second chunk
</pre>
<hr />
<pre>
 1797 }
 1798 
 1799 // No scaling for the parameter the ClearArray node.
 1800 const bool Matcher::init_array_count_is_in_bytes = true;
 1801 
 1802 // No additional cost for CMOVL.
 1803 const int Matcher::long_cmove_cost() { return 0; }
 1804 
 1805 // CMOVF/CMOVD are expensive on e.g., T4 and SPARC64.
 1806 const int Matcher::float_cmove_cost() {
 1807   return VM_Version::has_fast_cmove() ? 0 : ConditionalMoveLimit;
 1808 }
 1809 
 1810 // Does the CPU require late expand (see block.cpp for description of late expand)?
 1811 const bool Matcher::require_postalloc_expand = false;
 1812 
 1813 // Do we need to mask the count passed to shift instructions or does
 1814 // the cpu only look at the lower 5/6 bits anyway?
 1815 const bool Matcher::need_masked_shift_count = false;
 1816 


















 1817 bool Matcher::narrow_oop_use_complex_address() {
 1818   assert(UseCompressedOops, &quot;only for compressed oops code&quot;);
 1819   return false;
 1820 }
 1821 
 1822 bool Matcher::narrow_klass_use_complex_address() {
 1823   assert(UseCompressedClassPointers, &quot;only for compressed klass code&quot;);
 1824   return false;
 1825 }
 1826 
 1827 bool Matcher::const_oop_prefer_decode() {
 1828   // TODO: Check if loading ConP from TOC in heap-based mode is better:
 1829   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
<span class="line-modified"> 1830   // return Universe::narrow_oop_base() == NULL;</span>
 1831   return true;
 1832 }
 1833 
 1834 bool Matcher::const_klass_prefer_decode() {
 1835   // TODO: Check if loading ConP from TOC in heap-based mode is better:
 1836   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
<span class="line-modified"> 1837   // return Universe::narrow_klass_base() == NULL;</span>
 1838   return true;
 1839 }
 1840 
 1841 // Is it better to copy float constants, or load them directly from memory?
 1842 // Intel can load a float constant from a direct address, requiring no
 1843 // extra registers.  Most RISCs will have to materialize an address into a
 1844 // register first, so they would do better to copy the constant from stack.
 1845 const bool Matcher::rematerialize_float_constants = false;
 1846 
 1847 // If CPU can load and store mis-aligned doubles directly then no fixup is
 1848 // needed.  Else we split the double into 2 integer pieces and move it
 1849 // piece-by-piece.  Only happens when passing doubles into C code as the
 1850 // Java calling convention forces doubles to be aligned.
 1851 const bool Matcher::misaligned_doubles_ok = true;
 1852 
 1853 // No-op on SPARC.
 1854 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 1855 }
 1856 
<span class="line-modified"> 1857 // Advertise here if the CPU requires explicit rounding operations</span>
<span class="line-removed"> 1858 // to implement the UseStrictFP mode.</span>
 1859 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 1860 
 1861 // Are floats converted to double when stored to stack during deoptimization?
 1862 // Sparc does not handle callee-save floats.
 1863 bool Matcher::float_in_double() { return false; }
 1864 
 1865 // Do ints take an entire long register or just half?
 1866 // Note that we if-def off of _LP64.
 1867 // The relevant question is how the int is callee-saved.  In _LP64
 1868 // the whole long is written but de-opt&#39;ing will have to extract
 1869 // the relevant 32 bits, in not-_LP64 only the low 32 bits is written.
 1870 const bool Matcher::int_in_long = true;
 1871 
 1872 // Return whether or not this register is ever used as an argument.  This
 1873 // function is used on startup to build the trampoline stubs in generateOptoStub.
 1874 // Registers not mentioned will be killed by the VM call in the trampoline, and
 1875 // arguments in those registers not be available to the callee.
 1876 bool Matcher::can_be_java_arg( int reg ) {
 1877   // Standard sparc 6 args in registers
 1878   if( reg == R_I0_num ||
</pre>
<hr />
<pre>
 6234 %}
 6235 
 6236 instruct storeF0( memory mem, immF0 src) %{
 6237   match(Set mem (StoreF mem src));
 6238   ins_cost(MEMORY_REF_COST);
 6239 
 6240   format %{ &quot;STW    $src,$mem\t! storeF0&quot; %}
 6241   opcode(Assembler::stw_op3);
 6242   ins_encode(simple_form3_mem_reg( mem, R_G0 ) );
 6243   ins_pipe(fstoreF_mem_zero);
 6244 %}
 6245 
 6246 // Convert oop pointer into compressed form
 6247 instruct encodeHeapOop(iRegN dst, iRegP src) %{
 6248   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 6249   match(Set dst (EncodeP src));
 6250   format %{ &quot;encode_heap_oop $src, $dst&quot; %}
 6251   ins_encode %{
 6252     __ encode_heap_oop($src$$Register, $dst$$Register);
 6253   %}
<span class="line-modified"> 6254   ins_avoid_back_to_back(Universe::narrow_oop_base() == NULL ? AVOID_NONE : AVOID_BEFORE);</span>
 6255   ins_pipe(ialu_reg);
 6256 %}
 6257 
 6258 instruct encodeHeapOop_not_null(iRegN dst, iRegP src) %{
 6259   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 6260   match(Set dst (EncodeP src));
 6261   format %{ &quot;encode_heap_oop_not_null $src, $dst&quot; %}
 6262   ins_encode %{
 6263     __ encode_heap_oop_not_null($src$$Register, $dst$$Register);
 6264   %}
 6265   ins_pipe(ialu_reg);
 6266 %}
 6267 
 6268 instruct decodeHeapOop(iRegP dst, iRegN src) %{
 6269   predicate(n-&gt;bottom_type()-&gt;is_oopptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 6270             n-&gt;bottom_type()-&gt;is_oopptr()-&gt;ptr() != TypePtr::Constant);
 6271   match(Set dst (DecodeN src));
 6272   format %{ &quot;decode_heap_oop $src, $dst&quot; %}
 6273   ins_encode %{
 6274     __ decode_heap_oop($src$$Register, $dst$$Register);
</pre>
<hr />
<pre>
 6795   ins_encode( /*empty encoding*/ );
 6796   ins_pipe(empty);
 6797 %}
 6798 
 6799 
 6800 instruct castPP( iRegP dst ) %{
 6801   match(Set dst (CastPP dst));
 6802   format %{ &quot;# castPP of $dst&quot; %}
 6803   ins_encode( /*empty encoding*/ );
 6804   ins_pipe(empty);
 6805 %}
 6806 
 6807 instruct castII( iRegI dst ) %{
 6808   match(Set dst (CastII dst));
 6809   format %{ &quot;# castII of $dst&quot; %}
 6810   ins_encode( /*empty encoding*/ );
 6811   ins_cost(0);
 6812   ins_pipe(empty);
 6813 %}
 6814 








 6815 //----------Arithmetic Instructions--------------------------------------------
 6816 // Addition Instructions
 6817 // Register Addition
 6818 instruct addI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6819   match(Set dst (AddI src1 src2));
 6820 
 6821   size(4);
 6822   format %{ &quot;ADD    $src1,$src2,$dst&quot; %}
 6823   ins_encode %{
 6824     __ add($src1$$Register, $src2$$Register, $dst$$Register);
 6825   %}
 6826   ins_pipe(ialu_reg_reg);
 6827 %}
 6828 
 6829 // Immediate Addition
 6830 instruct addI_reg_imm13(iRegI dst, iRegI src1, immI13 src2) %{
 6831   match(Set dst (AddI src1 src2));
 6832 
 6833   size(4);
 6834   format %{ &quot;ADD    $src1,$src2,$dst&quot; %}
</pre>
</td>
<td>
<hr />
<pre>
    1 //
<span class="line-modified">    2 // Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.</span>
    3 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    4 //
    5 // This code is free software; you can redistribute it and/or modify it
    6 // under the terms of the GNU General Public License version 2 only, as
    7 // published by the Free Software Foundation.
    8 //
    9 // This code is distributed in the hope that it will be useful, but WITHOUT
   10 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   11 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   12 // version 2 for more details (a copy is included in the LICENSE file that
   13 // accompanied this code).
   14 //
   15 // You should have received a copy of the GNU General Public License version
   16 // 2 along with this work; if not, write to the Free Software Foundation,
   17 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   18 //
   19 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   20 // or visit www.oracle.com if you need additional information or have any
   21 // questions.
   22 //
</pre>
<hr />
<pre>
 1278   assert( do_polling(), &quot;no return for this epilog node&quot;);
 1279   return MacroAssembler::insts_for_sethi(os::get_polling_page()) * BytesPerInstWord;
 1280 }
 1281 
 1282 //=============================================================================
 1283 
 1284 // Figure out which register class each belongs in: rc_int, rc_float, rc_stack
 1285 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1286 static enum RC rc_class( OptoReg::Name reg ) {
 1287   if (!OptoReg::is_valid(reg)) return rc_bad;
 1288   if (OptoReg::is_stack(reg)) return rc_stack;
 1289   VMReg r = OptoReg::as_VMReg(reg);
 1290   if (r-&gt;is_Register()) return rc_int;
 1291   assert(r-&gt;is_FloatRegister(), &quot;must be&quot;);
 1292   return rc_float;
 1293 }
 1294 
 1295 #ifndef PRODUCT
 1296 ATTRIBUTE_PRINTF(2, 3)
 1297 static void print_helper(outputStream* st, const char* format, ...) {
<span class="line-modified"> 1298   const int tab_size = 8;</span>
<span class="line-added"> 1299   if (st-&gt;position() &gt; tab_size) {</span>
 1300     st-&gt;cr();
 1301     st-&gt;sp();
 1302   }
 1303   va_list ap;
 1304   va_start(ap, format);
 1305   st-&gt;vprint(format, ap);
 1306   va_end(ap);
 1307 }
 1308 #endif // !PRODUCT
 1309 
 1310 static void impl_helper(const MachNode* mach, CodeBuffer* cbuf, PhaseRegAlloc* ra, bool is_load, int offset, int reg, int opcode, const char *op_str, outputStream* st) {
 1311   if (cbuf) {
 1312     emit_form3_mem_reg(*cbuf, ra, mach, opcode, -1, R_SP_enc, offset, 0, Matcher::_regEncode[reg]);
 1313   }
 1314 #ifndef PRODUCT
 1315   else {
 1316     if (is_load) {
 1317       print_helper(st, &quot;%s   [R_SP + #%d],R_%s\t! spill&quot;, op_str, offset, OptoReg::regname(reg));
 1318     } else {
 1319       print_helper(st, &quot;%s   R_%s,[R_SP + #%d]\t! spill&quot;, op_str, OptoReg::regname(reg), offset);
</pre>
<hr />
<pre>
 1563      __ add(SP, offset, reg_to_register_object(reg));
 1564   } else {
 1565      __ set(offset, O7);
 1566      __ add(SP, O7, reg_to_register_object(reg));
 1567   }
 1568 }
 1569 
 1570 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1571   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_)
 1572   assert(ra_ == ra_-&gt;C-&gt;regalloc(), &quot;sanity&quot;);
 1573   return ra_-&gt;C-&gt;scratch_emit_size(this);
 1574 }
 1575 
 1576 //=============================================================================
 1577 #ifndef PRODUCT
 1578 void MachUEPNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
 1579   st-&gt;print_cr(&quot;\nUEP:&quot;);
 1580   if (UseCompressedClassPointers) {
 1581     assert(Universe::heap() != NULL, &quot;java heap should be initialized&quot;);
 1582     st-&gt;print_cr(&quot;\tLDUW   [R_O0 + oopDesc::klass_offset_in_bytes],R_G5\t! Inline cache check - compressed klass&quot;);
<span class="line-modified"> 1583     if (CompressedKlassPointers::base() != 0) {</span>
<span class="line-modified"> 1584       st-&gt;print_cr(&quot;\tSET    CompressedKlassPointers::base,R_G6_heap_base&quot;);</span>
<span class="line-modified"> 1585       if (CompressedKlassPointers::shift() != 0) {</span>
<span class="line-modified"> 1586         st-&gt;print_cr(&quot;\tSLL    R_G5,CompressedKlassPointers::shift,R_G5&quot;);</span>
 1587       }
 1588       st-&gt;print_cr(&quot;\tADD    R_G5,R_G6_heap_base,R_G5&quot;);
<span class="line-modified"> 1589       st-&gt;print_cr(&quot;\tSET    CompressedOops::ptrs_base,R_G6_heap_base&quot;);</span>
 1590     } else {
<span class="line-modified"> 1591       st-&gt;print_cr(&quot;\tSLL    R_G5,CompressedKlassPointers::shift,R_G5&quot;);</span>
 1592     }
 1593   } else {
 1594     st-&gt;print_cr(&quot;\tLDX    [R_O0 + oopDesc::klass_offset_in_bytes],R_G5\t! Inline cache check&quot;);
 1595   }
 1596   st-&gt;print_cr(&quot;\tCMP    R_G5,R_G3&quot; );
 1597   st-&gt;print   (&quot;\tTne    xcc,R_G0+ST_RESERVED_FOR_USER_0+2&quot;);
 1598 }
 1599 #endif
 1600 
 1601 void MachUEPNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1602   MacroAssembler _masm(&amp;cbuf);
 1603   Register G5_ic_reg  = reg_to_register_object(Matcher::inline_cache_reg_encode());
 1604   Register temp_reg   = G3;
 1605   assert( G5_ic_reg != temp_reg, &quot;conflicting registers&quot; );
 1606 
 1607   // Load klass from receiver
 1608   __ load_klass(O0, temp_reg);
 1609   // Compare against expected klass
 1610   __ cmp(temp_reg, G5_ic_reg);
 1611   // Branch to miss code, checks xcc or icc depending
</pre>
<hr />
<pre>
 1694 
 1695   switch (opcode) {
 1696   case Op_CountLeadingZerosI:
 1697   case Op_CountLeadingZerosL:
 1698   case Op_CountTrailingZerosI:
 1699   case Op_CountTrailingZerosL:
 1700   case Op_PopCountI:
 1701   case Op_PopCountL:
 1702     if (!UsePopCountInstruction)
 1703       return false;
 1704   case Op_CompareAndSwapL:
 1705   case Op_CompareAndSwapP:
 1706     if (!VM_Version::supports_cx8())
 1707       return false;
 1708     break;
 1709   }
 1710 
 1711   return true;  // Per default match rules are supported.
 1712 }
 1713 
<span class="line-modified"> 1714 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {</span>
 1715 
 1716   // TODO
 1717   // identify extra cases that we might want to provide match rules for
 1718   // e.g. Op_ vector nodes and other intrinsics while guarding with vlen
 1719   bool ret_value = match_rule_supported(opcode);
 1720   // Add rules here.
 1721 
 1722   return ret_value;  // Per default match rules are supported.
 1723 }
 1724 
 1725 const bool Matcher::has_predicated_vectors(void) {
 1726   return false;
 1727 }
 1728 
 1729 const int Matcher::float_pressure(int default_pressure_threshold) {
 1730   return default_pressure_threshold;
 1731 }
 1732 
 1733 int Matcher::regnum_to_fpu_offset(int regnum) {
 1734   return regnum - 32; // The FP registers are in the second chunk
</pre>
<hr />
<pre>
 1798 }
 1799 
 1800 // No scaling for the parameter the ClearArray node.
 1801 const bool Matcher::init_array_count_is_in_bytes = true;
 1802 
 1803 // No additional cost for CMOVL.
 1804 const int Matcher::long_cmove_cost() { return 0; }
 1805 
 1806 // CMOVF/CMOVD are expensive on e.g., T4 and SPARC64.
 1807 const int Matcher::float_cmove_cost() {
 1808   return VM_Version::has_fast_cmove() ? 0 : ConditionalMoveLimit;
 1809 }
 1810 
 1811 // Does the CPU require late expand (see block.cpp for description of late expand)?
 1812 const bool Matcher::require_postalloc_expand = false;
 1813 
 1814 // Do we need to mask the count passed to shift instructions or does
 1815 // the cpu only look at the lower 5/6 bits anyway?
 1816 const bool Matcher::need_masked_shift_count = false;
 1817 
<span class="line-added"> 1818 // No support for generic vector operands.</span>
<span class="line-added"> 1819 const bool Matcher::supports_generic_vector_operands  = false;</span>
<span class="line-added"> 1820 </span>
<span class="line-added"> 1821 MachOper* Matcher::specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {</span>
<span class="line-added"> 1822   ShouldNotReachHere(); // generic vector operands not supported</span>
<span class="line-added"> 1823   return NULL;</span>
<span class="line-added"> 1824 }</span>
<span class="line-added"> 1825 </span>
<span class="line-added"> 1826 bool Matcher::is_generic_reg2reg_move(MachNode* m) {</span>
<span class="line-added"> 1827   ShouldNotReachHere();  // generic vector operands not supported</span>
<span class="line-added"> 1828   return false;</span>
<span class="line-added"> 1829 }</span>
<span class="line-added"> 1830 </span>
<span class="line-added"> 1831 bool Matcher::is_generic_vector(MachOper* opnd)  {</span>
<span class="line-added"> 1832   ShouldNotReachHere();  // generic vector operands not supported</span>
<span class="line-added"> 1833   return false;</span>
<span class="line-added"> 1834 }</span>
<span class="line-added"> 1835 </span>
 1836 bool Matcher::narrow_oop_use_complex_address() {
 1837   assert(UseCompressedOops, &quot;only for compressed oops code&quot;);
 1838   return false;
 1839 }
 1840 
 1841 bool Matcher::narrow_klass_use_complex_address() {
 1842   assert(UseCompressedClassPointers, &quot;only for compressed klass code&quot;);
 1843   return false;
 1844 }
 1845 
 1846 bool Matcher::const_oop_prefer_decode() {
 1847   // TODO: Check if loading ConP from TOC in heap-based mode is better:
 1848   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
<span class="line-modified"> 1849   // return CompressedOops::base() == NULL;</span>
 1850   return true;
 1851 }
 1852 
 1853 bool Matcher::const_klass_prefer_decode() {
 1854   // TODO: Check if loading ConP from TOC in heap-based mode is better:
 1855   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
<span class="line-modified"> 1856   // return CompressedKlassPointers::base() == NULL;</span>
 1857   return true;
 1858 }
 1859 
 1860 // Is it better to copy float constants, or load them directly from memory?
 1861 // Intel can load a float constant from a direct address, requiring no
 1862 // extra registers.  Most RISCs will have to materialize an address into a
 1863 // register first, so they would do better to copy the constant from stack.
 1864 const bool Matcher::rematerialize_float_constants = false;
 1865 
 1866 // If CPU can load and store mis-aligned doubles directly then no fixup is
 1867 // needed.  Else we split the double into 2 integer pieces and move it
 1868 // piece-by-piece.  Only happens when passing doubles into C code as the
 1869 // Java calling convention forces doubles to be aligned.
 1870 const bool Matcher::misaligned_doubles_ok = true;
 1871 
 1872 // No-op on SPARC.
 1873 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 1874 }
 1875 
<span class="line-modified"> 1876 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.</span>

 1877 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 1878 
 1879 // Are floats converted to double when stored to stack during deoptimization?
 1880 // Sparc does not handle callee-save floats.
 1881 bool Matcher::float_in_double() { return false; }
 1882 
 1883 // Do ints take an entire long register or just half?
 1884 // Note that we if-def off of _LP64.
 1885 // The relevant question is how the int is callee-saved.  In _LP64
 1886 // the whole long is written but de-opt&#39;ing will have to extract
 1887 // the relevant 32 bits, in not-_LP64 only the low 32 bits is written.
 1888 const bool Matcher::int_in_long = true;
 1889 
 1890 // Return whether or not this register is ever used as an argument.  This
 1891 // function is used on startup to build the trampoline stubs in generateOptoStub.
 1892 // Registers not mentioned will be killed by the VM call in the trampoline, and
 1893 // arguments in those registers not be available to the callee.
 1894 bool Matcher::can_be_java_arg( int reg ) {
 1895   // Standard sparc 6 args in registers
 1896   if( reg == R_I0_num ||
</pre>
<hr />
<pre>
 6252 %}
 6253 
 6254 instruct storeF0( memory mem, immF0 src) %{
 6255   match(Set mem (StoreF mem src));
 6256   ins_cost(MEMORY_REF_COST);
 6257 
 6258   format %{ &quot;STW    $src,$mem\t! storeF0&quot; %}
 6259   opcode(Assembler::stw_op3);
 6260   ins_encode(simple_form3_mem_reg( mem, R_G0 ) );
 6261   ins_pipe(fstoreF_mem_zero);
 6262 %}
 6263 
 6264 // Convert oop pointer into compressed form
 6265 instruct encodeHeapOop(iRegN dst, iRegP src) %{
 6266   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 6267   match(Set dst (EncodeP src));
 6268   format %{ &quot;encode_heap_oop $src, $dst&quot; %}
 6269   ins_encode %{
 6270     __ encode_heap_oop($src$$Register, $dst$$Register);
 6271   %}
<span class="line-modified"> 6272   ins_avoid_back_to_back(CompressedOops::base() == NULL ? AVOID_NONE : AVOID_BEFORE);</span>
 6273   ins_pipe(ialu_reg);
 6274 %}
 6275 
 6276 instruct encodeHeapOop_not_null(iRegN dst, iRegP src) %{
 6277   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 6278   match(Set dst (EncodeP src));
 6279   format %{ &quot;encode_heap_oop_not_null $src, $dst&quot; %}
 6280   ins_encode %{
 6281     __ encode_heap_oop_not_null($src$$Register, $dst$$Register);
 6282   %}
 6283   ins_pipe(ialu_reg);
 6284 %}
 6285 
 6286 instruct decodeHeapOop(iRegP dst, iRegN src) %{
 6287   predicate(n-&gt;bottom_type()-&gt;is_oopptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 6288             n-&gt;bottom_type()-&gt;is_oopptr()-&gt;ptr() != TypePtr::Constant);
 6289   match(Set dst (DecodeN src));
 6290   format %{ &quot;decode_heap_oop $src, $dst&quot; %}
 6291   ins_encode %{
 6292     __ decode_heap_oop($src$$Register, $dst$$Register);
</pre>
<hr />
<pre>
 6813   ins_encode( /*empty encoding*/ );
 6814   ins_pipe(empty);
 6815 %}
 6816 
 6817 
 6818 instruct castPP( iRegP dst ) %{
 6819   match(Set dst (CastPP dst));
 6820   format %{ &quot;# castPP of $dst&quot; %}
 6821   ins_encode( /*empty encoding*/ );
 6822   ins_pipe(empty);
 6823 %}
 6824 
 6825 instruct castII( iRegI dst ) %{
 6826   match(Set dst (CastII dst));
 6827   format %{ &quot;# castII of $dst&quot; %}
 6828   ins_encode( /*empty encoding*/ );
 6829   ins_cost(0);
 6830   ins_pipe(empty);
 6831 %}
 6832 
<span class="line-added"> 6833 instruct castLL( iRegL dst ) %{</span>
<span class="line-added"> 6834   match(Set dst (CastLL dst));</span>
<span class="line-added"> 6835   format %{ &quot;# castLL of $dst&quot; %}</span>
<span class="line-added"> 6836   ins_encode( /*empty encoding*/ );</span>
<span class="line-added"> 6837   ins_cost(0);</span>
<span class="line-added"> 6838   ins_pipe(empty);</span>
<span class="line-added"> 6839 %}</span>
<span class="line-added"> 6840 </span>
 6841 //----------Arithmetic Instructions--------------------------------------------
 6842 // Addition Instructions
 6843 // Register Addition
 6844 instruct addI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6845   match(Set dst (AddI src1 src2));
 6846 
 6847   size(4);
 6848   format %{ &quot;ADD    $src1,$src2,$dst&quot; %}
 6849   ins_encode %{
 6850     __ add($src1$$Register, $src2$$Register, $dst$$Register);
 6851   %}
 6852   ins_pipe(ialu_reg_reg);
 6853 %}
 6854 
 6855 // Immediate Addition
 6856 instruct addI_reg_imm13(iRegI dst, iRegI src1, immI13 src2) %{
 6857   match(Set dst (AddI src1 src2));
 6858 
 6859   size(4);
 6860   format %{ &quot;ADD    $src1,$src2,$dst&quot; %}
</pre>
</td>
</tr>
</table>
<center><a href="sharedRuntime_sparc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_sparc.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>