diff a/src/hotspot/cpu/sparc/macroAssembler_sparc.cpp b/src/hotspot/cpu/sparc/macroAssembler_sparc.cpp
--- a/src/hotspot/cpu/sparc/macroAssembler_sparc.cpp
+++ b/src/hotspot/cpu/sparc/macroAssembler_sparc.cpp
@@ -31,10 +31,11 @@
 #include "gc/shared/barrierSetAssembler.hpp"
 #include "interpreter/interpreter.hpp"
 #include "memory/resourceArea.hpp"
 #include "memory/universe.hpp"
 #include "oops/accessDecorators.hpp"
+#include "oops/compressedOops.hpp"
 #include "oops/klass.inline.hpp"
 #include "prims/methodHandles.hpp"
 #include "runtime/biasedLocking.hpp"
 #include "runtime/flags/flagSetting.hpp"
 #include "runtime/interfaceSupport.inline.hpp"
@@ -45,10 +46,11 @@
 #include "runtime/safepointMechanism.hpp"
 #include "runtime/sharedRuntime.hpp"
 #include "runtime/stubRoutines.hpp"
 #include "utilities/align.hpp"
 #include "utilities/macros.hpp"
+#include "utilities/powerOfTwo.hpp"
 #ifdef COMPILER2
 #include "opto/intrinsicnode.hpp"
 #endif
 
 #ifdef PRODUCT
@@ -987,11 +989,11 @@
 AddressLiteral MacroAssembler::constant_oop_address(jobject obj) {
 #ifdef ASSERT
   {
     ThreadInVMfromUnknown tiv;
     assert(oop_recorder() != NULL, "this assembler needs an OopRecorder");
-    assert(Universe::heap()->is_in_reserved(JNIHandles::resolve(obj)), "not an oop");
+    assert(Universe::heap()->is_in(JNIHandles::resolve(obj)), "not an oop");
   }
 #endif
   int oop_index = oop_recorder()->find_index(obj);
   return AddressLiteral(obj, oop_Relocation::spec(oop_index));
 }
@@ -1013,11 +1015,11 @@
 
 void  MacroAssembler::set_narrow_klass(Klass* k, Register d) {
   assert(oop_recorder() != NULL, "this assembler needs an OopRecorder");
   int klass_index = oop_recorder()->find_index(k);
   RelocationHolder rspec = metadata_Relocation::spec(klass_index);
-  narrowOop encoded_k = Klass::encode_klass(k);
+  narrowOop encoded_k = CompressedKlassPointers::encode(k);
 
   assert_not_delayed();
   // Relocation with special format (see relocInfo_sparc.hpp).
   relocate(rspec, 1);
   // Assembler::sethi(encoded_k, d);
@@ -1127,25 +1129,10 @@
   for (int k = 0; k < 64; k += 2) {
     a->ldf(FloatRegisterImpl::D, O0, d_offset(k), as_FloatRegister(k));
   }
 }
 
-
-// pushes double TOS element of FPU stack on CPU stack; pops from FPU stack
-void MacroAssembler::push_fTOS() {
-  // %%%%%% need to implement this
-}
-
-// pops double TOS element from CPU stack and pushes on FPU stack
-void MacroAssembler::pop_fTOS() {
-  // %%%%%% need to implement this
-}
-
-void MacroAssembler::empty_FPU_stack() {
-  // %%%%%% need to implement this
-}
-
 void MacroAssembler::_verify_oop(Register reg, const char* msg, const char * file, int line) {
   // plausibility check for oops
   if (!VerifyOops) return;
 
   if (reg == G0)  return;       // always NULL, which is always an oop
@@ -2449,19 +2436,19 @@
   // Biased locking
   // See whether the lock is currently biased toward our thread and
   // whether the epoch is still valid
   // Note that the runtime guarantees sufficient alignment of JavaThread
   // pointers to allow age to be placed into low bits
-  assert(markOopDesc::age_shift == markOopDesc::lock_bits + markOopDesc::biased_lock_bits, "biased locking makes assumptions about bit layout");
-  and3(mark_reg, markOopDesc::biased_lock_mask_in_place, temp_reg);
-  cmp_and_brx_short(temp_reg, markOopDesc::biased_lock_pattern, Assembler::notEqual, Assembler::pn, cas_label);
+  assert(markWord::age_shift == markWord::lock_bits + markWord::biased_lock_bits, "biased locking makes assumptions about bit layout");
+  and3(mark_reg, markWord::biased_lock_mask_in_place, temp_reg);
+  cmp_and_brx_short(temp_reg, markWord::biased_lock_pattern, Assembler::notEqual, Assembler::pn, cas_label);
 
   load_klass(obj_reg, temp_reg);
   ld_ptr(Address(temp_reg, Klass::prototype_header_offset()), temp_reg);
   or3(G2_thread, temp_reg, temp_reg);
   xor3(mark_reg, temp_reg, temp_reg);
-  andcc(temp_reg, ~((int) markOopDesc::age_mask_in_place), temp_reg);
+  andcc(temp_reg, ~((int) markWord::age_mask_in_place), temp_reg);
   if (counters != NULL) {
     cond_inc(Assembler::equal, (address) counters->biased_lock_entry_count_addr(), mark_reg, temp_reg);
     // Reload mark_reg as we may need it later
     ld_ptr(Address(obj_reg, oopDesc::mark_offset_in_bytes()), mark_reg);
   }
@@ -2480,11 +2467,11 @@
   // header.
 
   // If the low three bits in the xor result aren't clear, that means
   // the prototype header is no longer biased and we have to revoke
   // the bias on this object.
-  btst(markOopDesc::biased_lock_mask_in_place, temp_reg);
+  btst(markWord::biased_lock_mask_in_place, temp_reg);
   brx(Assembler::notZero, false, Assembler::pn, try_revoke_bias);
 
   // Biasing is still enabled for this data type. See whether the
   // epoch of the current bias is still valid, meaning that the epoch
   // bits of the mark word are equal to the epoch bits of the
@@ -2492,21 +2479,21 @@
   // only change at a safepoint.) If not, attempt to rebias the object
   // toward the current thread. Note that we must be absolutely sure
   // that the current epoch is invalid in order to do this because
   // otherwise the manipulations it performs on the mark word are
   // illegal.
-  delayed()->btst(markOopDesc::epoch_mask_in_place, temp_reg);
+  delayed()->btst(markWord::epoch_mask_in_place, temp_reg);
   brx(Assembler::notZero, false, Assembler::pn, try_rebias);
 
   // The epoch of the current bias is still valid but we know nothing
   // about the owner; it might be set or it might be clear. Try to
   // acquire the bias of the object using an atomic operation. If this
   // fails we will go in to the runtime to revoke the object's bias.
   // Note that we first construct the presumed unbiased header so we
   // don't accidentally blow away another thread's valid bias.
   delayed()->and3(mark_reg,
-                  markOopDesc::biased_lock_mask_in_place | markOopDesc::age_mask_in_place | markOopDesc::epoch_mask_in_place,
+                  markWord::biased_lock_mask_in_place | markWord::age_mask_in_place | markWord::epoch_mask_in_place,
                   mark_reg);
   or3(G2_thread, mark_reg, temp_reg);
   cas_ptr(mark_addr.base(), mark_reg, temp_reg);
   // If the biasing toward our thread failed, this means that
   // another thread succeeded in biasing it toward itself and we
@@ -2583,12 +2570,12 @@
   // First, the interpreter checks for IllegalMonitorStateException at
   // a higher level. Second, if the bias was revoked while we held the
   // lock, the object could not be rebiased toward another thread, so
   // the bias bit would be clear.
   ld_ptr(mark_addr, temp_reg);
-  and3(temp_reg, markOopDesc::biased_lock_mask_in_place, temp_reg);
-  cmp(temp_reg, markOopDesc::biased_lock_pattern);
+  and3(temp_reg, markWord::biased_lock_mask_in_place, temp_reg);
+  cmp(temp_reg, markWord::biased_lock_pattern);
   brx(Assembler::equal, allow_delay_slot_filling, Assembler::pt, done);
   delayed();
   if (!allow_delay_slot_filling) {
     nop();
   }
@@ -2600,16 +2587,16 @@
 // The code could be tightened up considerably.
 //
 // box->dhw disposition - post-conditions at DONE_LABEL.
 // -   Successful inflated lock:  box->dhw != 0.
 //     Any non-zero value suffices.
-//     Consider G2_thread, rsp, boxReg, or markOopDesc::unused_mark()
+//     Consider G2_thread, rsp, boxReg, or markWord::unused_mark()
 // -   Successful Stack-lock: box->dhw == mark.
 //     box->dhw must contain the displaced mark word value
 // -   Failure -- icc.ZFlag == 0 and box->dhw is undefined.
-//     The slow-path fast_enter() and slow_enter() operators
-//     are responsible for setting box->dhw = NonZero (typically markOopDesc::unused_mark()).
+//     The slow-path enter() is responsible for setting
+//     box->dhw = NonZero (typically markWord::unused_mark()).
 // -   Biased: box->dhw is undefined
 //
 // SPARC refworkload performance - specifically jetstream and scimark - are
 // extremely sensitive to the size of the code emitted by compiler_lock_object
 // and compiler_unlock_object.  Critically, the key factor is code size, not path
@@ -2655,11 +2642,11 @@
    //   ST box->dhw  = mark   -- save fetched mark in on-stack basiclock box
    //   ST obj->mark = box    -- overwrite transient 0 value
    // This presumes TSO, of course.
 
    mov(0, Rscratch);
-   or3(Rmark, markOopDesc::unlocked_value, Rmark);
+   or3(Rmark, markWord::unlocked_value, Rmark);
    assert(mark_addr.disp() == 0, "cas must take a zero displacement");
    cas_ptr(mark_addr.base(), Rmark, Rscratch);
 // prefetch (mark_addr, Assembler::severalWritesAndPossiblyReads);
    cmp(Rscratch, Rmark);
    brx(Assembler::notZero, false, Assembler::pn, Recursive);
@@ -2709,11 +2696,11 @@
    cas_ptr(Rmark, G0, Rscratch);
    andcc(Rscratch, Rscratch, G0);             // set ICCs for done: icc.zf iff success
    // set icc.zf : 1=success 0=failure
    // ST box->displaced_header = NonZero.
    // Any non-zero value suffices:
-   //    markOopDesc::unused_mark(), G2_thread, RBox, RScratch, rsp, etc.
+   //    markWord::unused_mark(), G2_thread, RBox, RScratch, rsp, etc.
    st_ptr(Rbox, Rbox, BasicLock::displaced_header_offset_in_bytes());
    // Intentional fall-through into done
 
    bind   (done);
 }
@@ -2823,51 +2810,10 @@
    // Intentional fall through into done ...
 
    bind(done);
 }
 
-
-
-void MacroAssembler::print_CPU_state() {
-  // %%%%% need to implement this
-}
-
-void MacroAssembler::verify_FPU(int stack_depth, const char* s) {
-  // %%%%% need to implement this
-}
-
-void MacroAssembler::push_IU_state() {
-  // %%%%% need to implement this
-}
-
-
-void MacroAssembler::pop_IU_state() {
-  // %%%%% need to implement this
-}
-
-
-void MacroAssembler::push_FPU_state() {
-  // %%%%% need to implement this
-}
-
-
-void MacroAssembler::pop_FPU_state() {
-  // %%%%% need to implement this
-}
-
-
-void MacroAssembler::push_CPU_state() {
-  // %%%%% need to implement this
-}
-
-
-void MacroAssembler::pop_CPU_state() {
-  // %%%%% need to implement this
-}
-
-
-
 void MacroAssembler::verify_tlab() {
 #ifdef ASSERT
   if (UseTLAB && VerifyOops) {
     Label next, next2, ok;
     Register t1 = L0;
@@ -3293,13 +3239,13 @@
 
 
 void MacroAssembler::encode_heap_oop(Register src, Register dst) {
   assert (UseCompressedOops, "must be compressed");
   assert (Universe::heap() != NULL, "java heap should be initialized");
-  assert (LogMinObjAlignmentInBytes == Universe::narrow_oop_shift(), "decode alg wrong");
+  assert (LogMinObjAlignmentInBytes == CompressedOops::shift(), "decode alg wrong");
   verify_oop(src);
-  if (Universe::narrow_oop_base() == NULL) {
+  if (CompressedOops::base() == NULL) {
     srlx(src, LogMinObjAlignmentInBytes, dst);
     return;
   }
   Label done;
   if (src == dst) {
@@ -3321,23 +3267,23 @@
 
 
 void MacroAssembler::encode_heap_oop_not_null(Register r) {
   assert (UseCompressedOops, "must be compressed");
   assert (Universe::heap() != NULL, "java heap should be initialized");
-  assert (LogMinObjAlignmentInBytes == Universe::narrow_oop_shift(), "decode alg wrong");
+  assert (LogMinObjAlignmentInBytes == CompressedOops::shift(), "decode alg wrong");
   verify_oop(r);
-  if (Universe::narrow_oop_base() != NULL)
+  if (CompressedOops::base() != NULL)
     sub(r, G6_heapbase, r);
   srlx(r, LogMinObjAlignmentInBytes, r);
 }
 
 void MacroAssembler::encode_heap_oop_not_null(Register src, Register dst) {
   assert (UseCompressedOops, "must be compressed");
   assert (Universe::heap() != NULL, "java heap should be initialized");
-  assert (LogMinObjAlignmentInBytes == Universe::narrow_oop_shift(), "decode alg wrong");
+  assert (LogMinObjAlignmentInBytes == CompressedOops::shift(), "decode alg wrong");
   verify_oop(src);
-  if (Universe::narrow_oop_base() == NULL) {
+  if (CompressedOops::base() == NULL) {
     srlx(src, LogMinObjAlignmentInBytes, dst);
   } else {
     sub(src, G6_heapbase, dst);
     srlx(dst, LogMinObjAlignmentInBytes, dst);
   }
@@ -3345,13 +3291,13 @@
 
 // Same algorithm as oops.inline.hpp decode_heap_oop.
 void  MacroAssembler::decode_heap_oop(Register src, Register dst) {
   assert (UseCompressedOops, "must be compressed");
   assert (Universe::heap() != NULL, "java heap should be initialized");
-  assert (LogMinObjAlignmentInBytes == Universe::narrow_oop_shift(), "decode alg wrong");
+  assert (LogMinObjAlignmentInBytes == CompressedOops::shift(), "decode alg wrong");
   sllx(src, LogMinObjAlignmentInBytes, dst);
-  if (Universe::narrow_oop_base() != NULL) {
+  if (CompressedOops::base() != NULL) {
     Label done;
     bpr(rc_nz, true, Assembler::pt, dst, done);
     delayed() -> add(dst, G6_heapbase, dst); // annuled if not taken
     bind(done);
   }
@@ -3362,74 +3308,74 @@
   // Do not add assert code to this unless you change vtableStubs_sparc.cpp
   // pd_code_size_limit.
   // Also do not verify_oop as this is called by verify_oop.
   assert (UseCompressedOops, "must be compressed");
   assert (Universe::heap() != NULL, "java heap should be initialized");
-  assert (LogMinObjAlignmentInBytes == Universe::narrow_oop_shift(), "decode alg wrong");
+  assert (LogMinObjAlignmentInBytes == CompressedOops::shift(), "decode alg wrong");
   sllx(r, LogMinObjAlignmentInBytes, r);
-  if (Universe::narrow_oop_base() != NULL)
+  if (CompressedOops::base() != NULL)
     add(r, G6_heapbase, r);
 }
 
 void  MacroAssembler::decode_heap_oop_not_null(Register src, Register dst) {
   // Do not add assert code to this unless you change vtableStubs_sparc.cpp
   // pd_code_size_limit.
   // Also do not verify_oop as this is called by verify_oop.
   assert (UseCompressedOops, "must be compressed");
-  assert (LogMinObjAlignmentInBytes == Universe::narrow_oop_shift(), "decode alg wrong");
+  assert (LogMinObjAlignmentInBytes == CompressedOops::shift(), "decode alg wrong");
   sllx(src, LogMinObjAlignmentInBytes, dst);
-  if (Universe::narrow_oop_base() != NULL)
+  if (CompressedOops::base() != NULL)
     add(dst, G6_heapbase, dst);
 }
 
 void MacroAssembler::encode_klass_not_null(Register r) {
   assert (UseCompressedClassPointers, "must be compressed");
-  if (Universe::narrow_klass_base() != NULL) {
+  if (CompressedKlassPointers::base() != NULL) {
     assert(r != G6_heapbase, "bad register choice");
-    set((intptr_t)Universe::narrow_klass_base(), G6_heapbase);
+    set((intptr_t)CompressedKlassPointers::base(), G6_heapbase);
     sub(r, G6_heapbase, r);
-    if (Universe::narrow_klass_shift() != 0) {
-      assert (LogKlassAlignmentInBytes == Universe::narrow_klass_shift(), "decode alg wrong");
+    if (CompressedKlassPointers::shift() != 0) {
+      assert (LogKlassAlignmentInBytes == CompressedKlassPointers::shift(), "decode alg wrong");
       srlx(r, LogKlassAlignmentInBytes, r);
     }
     reinit_heapbase();
   } else {
-    assert (LogKlassAlignmentInBytes == Universe::narrow_klass_shift() || Universe::narrow_klass_shift() == 0, "decode alg wrong");
-    srlx(r, Universe::narrow_klass_shift(), r);
+    assert (LogKlassAlignmentInBytes == CompressedKlassPointers::shift() || CompressedKlassPointers::shift() == 0, "decode alg wrong");
+    srlx(r, CompressedKlassPointers::shift(), r);
   }
 }
 
 void MacroAssembler::encode_klass_not_null(Register src, Register dst) {
   if (src == dst) {
     encode_klass_not_null(src);
   } else {
     assert (UseCompressedClassPointers, "must be compressed");
-    if (Universe::narrow_klass_base() != NULL) {
-      set((intptr_t)Universe::narrow_klass_base(), dst);
+    if (CompressedKlassPointers::base() != NULL) {
+      set((intptr_t)CompressedKlassPointers::base(), dst);
       sub(src, dst, dst);
-      if (Universe::narrow_klass_shift() != 0) {
+      if (CompressedKlassPointers::shift() != 0) {
         srlx(dst, LogKlassAlignmentInBytes, dst);
       }
     } else {
       // shift src into dst
-      assert (LogKlassAlignmentInBytes == Universe::narrow_klass_shift() || Universe::narrow_klass_shift() == 0, "decode alg wrong");
-      srlx(src, Universe::narrow_klass_shift(), dst);
+      assert (LogKlassAlignmentInBytes == CompressedKlassPointers::shift() || CompressedKlassPointers::shift() == 0, "decode alg wrong");
+      srlx(src, CompressedKlassPointers::shift(), dst);
     }
   }
 }
 
 // Function instr_size_for_decode_klass_not_null() counts the instructions
 // generated by decode_klass_not_null() and reinit_heapbase().  Hence, if
 // the instructions they generate change, then this method needs to be updated.
 int MacroAssembler::instr_size_for_decode_klass_not_null() {
   assert (UseCompressedClassPointers, "only for compressed klass ptrs");
   int num_instrs = 1;  // shift src,dst or add
-  if (Universe::narrow_klass_base() != NULL) {
+  if (CompressedKlassPointers::base() != NULL) {
     // set + add + set
-    num_instrs += insts_for_internal_set((intptr_t)Universe::narrow_klass_base()) +
-                  insts_for_internal_set((intptr_t)Universe::narrow_ptrs_base());
-    if (Universe::narrow_klass_shift() != 0) {
+    num_instrs += insts_for_internal_set((intptr_t)CompressedKlassPointers::base()) +
+                  insts_for_internal_set((intptr_t)CompressedOops::ptrs_base());
+    if (CompressedKlassPointers::shift() != 0) {
       num_instrs += 1;  // sllx
     }
   }
   return num_instrs * BytesPerInstWord;
 }
@@ -3438,55 +3384,55 @@
 // instr_size_for_decode_klass_not_null() needs to get updated.
 void  MacroAssembler::decode_klass_not_null(Register r) {
   // Do not add assert code to this unless you change vtableStubs_sparc.cpp
   // pd_code_size_limit.
   assert (UseCompressedClassPointers, "must be compressed");
-  if (Universe::narrow_klass_base() != NULL) {
+  if (CompressedKlassPointers::base() != NULL) {
     assert(r != G6_heapbase, "bad register choice");
-    set((intptr_t)Universe::narrow_klass_base(), G6_heapbase);
-    if (Universe::narrow_klass_shift() != 0)
+    set((intptr_t)CompressedKlassPointers::base(), G6_heapbase);
+    if (CompressedKlassPointers::shift() != 0)
       sllx(r, LogKlassAlignmentInBytes, r);
     add(r, G6_heapbase, r);
     reinit_heapbase();
   } else {
-    assert (LogKlassAlignmentInBytes == Universe::narrow_klass_shift() || Universe::narrow_klass_shift() == 0, "decode alg wrong");
-    sllx(r, Universe::narrow_klass_shift(), r);
+    assert (LogKlassAlignmentInBytes == CompressedKlassPointers::shift() || CompressedKlassPointers::shift() == 0, "decode alg wrong");
+    sllx(r, CompressedKlassPointers::shift(), r);
   }
 }
 
 void  MacroAssembler::decode_klass_not_null(Register src, Register dst) {
   if (src == dst) {
     decode_klass_not_null(src);
   } else {
     // Do not add assert code to this unless you change vtableStubs_sparc.cpp
     // pd_code_size_limit.
     assert (UseCompressedClassPointers, "must be compressed");
-    if (Universe::narrow_klass_base() != NULL) {
-      if (Universe::narrow_klass_shift() != 0) {
+    if (CompressedKlassPointers::base() != NULL) {
+      if (CompressedKlassPointers::shift() != 0) {
         assert((src != G6_heapbase) && (dst != G6_heapbase), "bad register choice");
-        set((intptr_t)Universe::narrow_klass_base(), G6_heapbase);
+        set((intptr_t)CompressedKlassPointers::base(), G6_heapbase);
         sllx(src, LogKlassAlignmentInBytes, dst);
         add(dst, G6_heapbase, dst);
         reinit_heapbase();
       } else {
-        set((intptr_t)Universe::narrow_klass_base(), dst);
+        set((intptr_t)CompressedKlassPointers::base(), dst);
         add(src, dst, dst);
       }
     } else {
       // shift/mov src into dst.
-      assert (LogKlassAlignmentInBytes == Universe::narrow_klass_shift() || Universe::narrow_klass_shift() == 0, "decode alg wrong");
-      sllx(src, Universe::narrow_klass_shift(), dst);
+      assert (LogKlassAlignmentInBytes == CompressedKlassPointers::shift() || CompressedKlassPointers::shift() == 0, "decode alg wrong");
+      sllx(src, CompressedKlassPointers::shift(), dst);
     }
   }
 }
 
 void MacroAssembler::reinit_heapbase() {
   if (UseCompressedOops || UseCompressedClassPointers) {
     if (Universe::heap() != NULL) {
-      set((intptr_t)Universe::narrow_ptrs_base(), G6_heapbase);
+      set((intptr_t)CompressedOops::ptrs_base(), G6_heapbase);
     } else {
-      AddressLiteral base(Universe::narrow_ptrs_base_addr());
+      AddressLiteral base(CompressedOops::ptrs_base_addr());
       load_ptr_contents(base, G6_heapbase);
     }
   }
 }
 
