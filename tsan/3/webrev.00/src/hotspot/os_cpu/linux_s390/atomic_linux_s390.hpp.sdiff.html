<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/os_cpu/linux_s390/atomic_linux_s390.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../linux_ppc/thread_linux_ppc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="orderAccess_linux_s390.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/os_cpu/linux_s390/atomic_linux_s390.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
  2  * Copyright (c) 2016, 2019, Oracle and/or its affiliates. All rights reserved.
<span class="line-modified">  3  * Copyright (c) 2016, 2018 SAP SE. All rights reserved.</span>
  4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5  *
  6  * This code is free software; you can redistribute it and/or modify it
  7  * under the terms of the GNU General Public License version 2 only, as
  8  * published by the Free Software Foundation.
  9  *
 10  * This code is distributed in the hope that it will be useful, but WITHOUT
 11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13  * version 2 for more details (a copy is included in the LICENSE file that
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
 23  *
 24  */
 25 
 26 #ifndef OS_CPU_LINUX_S390_ATOMIC_LINUX_S390_HPP
 27 #define OS_CPU_LINUX_S390_ATOMIC_LINUX_S390_HPP
 28 
 29 #include &quot;runtime/atomic.hpp&quot;
 30 #include &quot;runtime/os.hpp&quot;
<span class="line-modified"> 31 #include &quot;vm_version_s390.hpp&quot;</span>
 32 
 33 // Note that the compare-and-swap instructions on System z perform
 34 // a serialization function before the storage operand is fetched
 35 // and again after the operation is completed.
 36 //
 37 // Used constraint modifiers:
 38 // = write-only access: Value on entry to inline-assembler code irrelevant.
 39 // + read/write access: Value on entry is used; on exit value is changed.
 40 //   read-only  access: Value on entry is used and never changed.
 41 // &amp; early-clobber access: Might be modified before all read-only operands
 42 //                         have been used.
 43 // a address register operand (not GR0).
 44 // d general register operand (including GR0)
 45 // Q memory operand w/o index register.
 46 // 0..9 operand reference (by operand position).
 47 //      Used for operands that fill multiple roles. One example would be a
 48 //      write-only operand receiving its initial value from a read-only operand.
 49 //      Refer to cmpxchg(..) operand #0 and variable cmp_val for a real-life example.
 50 //
 51 
</pre>
<hr />
<pre>
 58 // Atomic::add
 59 //------------
 60 // These methods force the value in memory to be augmented by the passed increment.
 61 // Both, memory value and increment, are treated as 32bit signed binary integers.
 62 // No overflow exceptions are recognized, and the condition code does not hold
 63 // information about the value in memory.
 64 //
 65 // The value in memory is updated by using a compare-and-swap instruction. The
 66 // instruction is retried as often as required.
 67 //
 68 // The return value of the method is the value that was successfully stored. At the
 69 // time the caller receives back control, the value in memory may have changed already.
 70 
 71 // New atomic operations only include specific-operand-serialization, not full
 72 // memory barriers. We can use the Fast-BCR-Serialization Facility for them.
 73 inline void z196_fast_sync() {
 74   __asm__ __volatile__ (&quot;bcr 14, 0&quot; : : : &quot;memory&quot;);
 75 }
 76 
 77 template&lt;size_t byte_size&gt;
<span class="line-modified"> 78 struct Atomic::PlatformAdd</span>
<span class="line-modified"> 79   : Atomic::AddAndFetch&lt;Atomic::PlatformAdd&lt;byte_size&gt; &gt;</span>
<span class="line-modified"> 80 {</span>
<span class="line-modified"> 81   template&lt;typename I, typename D&gt;</span>
<span class="line-modified"> 82   D add_and_fetch(I add_value, D volatile* dest, atomic_memory_order order) const;</span>



 83 };
 84 
 85 template&lt;&gt;
<span class="line-modified"> 86 template&lt;typename I, typename D&gt;</span>
<span class="line-modified"> 87 inline D Atomic::PlatformAdd&lt;4&gt;::add_and_fetch(I inc, D volatile* dest,</span>
 88                                                atomic_memory_order order) const {
 89   STATIC_ASSERT(4 == sizeof(I));
 90   STATIC_ASSERT(4 == sizeof(D));
 91 
 92   D old, upd;
 93 
 94   if (VM_Version::has_LoadAndALUAtomicV1()) {
 95     if (order == memory_order_conservative) { z196_fast_sync(); }
 96     __asm__ __volatile__ (
 97       &quot;   LGFR     0,%[inc]                \n\t&quot; // save increment
 98       &quot;   LA       3,%[mem]                \n\t&quot; // force data address into ARG2
 99 //    &quot;   LAA      %[upd],%[inc],%[mem]    \n\t&quot; // increment and get old value
100 //    &quot;   LAA      2,0,0(3)                \n\t&quot; // actually coded instruction
101       &quot;   .byte    0xeb                    \n\t&quot; // LAA main opcode
102       &quot;   .byte    0x20                    \n\t&quot; // R1,R3
103       &quot;   .byte    0x30                    \n\t&quot; // R2,disp1
104       &quot;   .byte    0x00                    \n\t&quot; // disp2,disp3
105       &quot;   .byte    0x00                    \n\t&quot; // disp4,disp5
106       &quot;   .byte    0xf8                    \n\t&quot; // LAA minor opcode
107       &quot;   AR       2,0                     \n\t&quot; // calc new value in register
</pre>
<hr />
<pre>
120       &quot;   LLGF     %[old],%[mem]           \n\t&quot; // get old value
121       &quot;0: LA       %[upd],0(%[inc],%[old]) \n\t&quot; // calc result
122       &quot;   CS       %[old],%[upd],%[mem]    \n\t&quot; // try to xchg res with mem
123       &quot;   JNE      0b                      \n\t&quot; // no success? -&gt; retry
124       //---&lt;  outputs  &gt;---
125       : [old] &quot;=&amp;a&quot; (old)    // write-only, old counter value
126       , [upd] &quot;=&amp;d&quot; (upd)    // write-only, updated counter value
127       , [mem] &quot;+Q&quot;  (*dest)  // read/write, memory to be updated atomically
128       //---&lt;  inputs  &gt;---
129       : [inc] &quot;a&quot;   (inc)    // read-only.
130       //---&lt;  clobbered  &gt;---
131       : &quot;cc&quot;, &quot;memory&quot;
132     );
133   }
134 
135   return upd;
136 }
137 
138 
139 template&lt;&gt;
<span class="line-modified">140 template&lt;typename I, typename D&gt;</span>
<span class="line-modified">141 inline D Atomic::PlatformAdd&lt;8&gt;::add_and_fetch(I inc, D volatile* dest,</span>
142                                                atomic_memory_order order) const {
143   STATIC_ASSERT(8 == sizeof(I));
144   STATIC_ASSERT(8 == sizeof(D));
145 
146   D old, upd;
147 
148   if (VM_Version::has_LoadAndALUAtomicV1()) {
149     if (order == memory_order_conservative) { z196_fast_sync(); }
150     __asm__ __volatile__ (
151       &quot;   LGR      0,%[inc]                \n\t&quot; // save increment
152       &quot;   LA       3,%[mem]                \n\t&quot; // force data address into ARG2
153 //    &quot;   LAAG     %[upd],%[inc],%[mem]    \n\t&quot; // increment and get old value
154 //    &quot;   LAAG     2,0,0(3)                \n\t&quot; // actually coded instruction
155       &quot;   .byte    0xeb                    \n\t&quot; // LAA main opcode
156       &quot;   .byte    0x20                    \n\t&quot; // R1,R3
157       &quot;   .byte    0x30                    \n\t&quot; // R2,disp1
158       &quot;   .byte    0x00                    \n\t&quot; // disp2,disp3
159       &quot;   .byte    0x00                    \n\t&quot; // disp4,disp5
160       &quot;   .byte    0xe8                    \n\t&quot; // LAA minor opcode
161       &quot;   AGR      2,0                     \n\t&quot; // calc new value in register
</pre>
<hr />
<pre>
191 
192 
193 //-------------
194 // Atomic::xchg
195 //-------------
196 // These methods force the value in memory to be replaced by the new value passed
197 // in as argument.
198 //
199 // The value in memory is replaced by using a compare-and-swap instruction. The
200 // instruction is retried as often as required. This makes sure that the new
201 // value can be seen, at least for a very short period of time, by other CPUs.
202 //
203 // If we would use a normal &quot;load(old value) store(new value)&quot; sequence,
204 // the new value could be lost unnoticed, due to a store(new value) from
205 // another thread.
206 //
207 // The return value is the (unchanged) value from memory as it was when the
208 // replacement succeeded.
209 template&lt;&gt;
210 template&lt;typename T&gt;
<span class="line-modified">211 inline T Atomic::PlatformXchg&lt;4&gt;::operator()(T exchange_value,</span>
<span class="line-modified">212                                              T volatile* dest,</span>
213                                              atomic_memory_order unused) const {
214   STATIC_ASSERT(4 == sizeof(T));
215   T old;
216 
217   __asm__ __volatile__ (
218     &quot;   LLGF     %[old],%[mem]           \n\t&quot; // get old value
219     &quot;0: CS       %[old],%[upd],%[mem]    \n\t&quot; // try to xchg upd with mem
220     &quot;   JNE      0b                      \n\t&quot; // no success? -&gt; retry
221     //---&lt;  outputs  &gt;---
222     : [old] &quot;=&amp;d&quot; (old)      // write-only, prev value irrelevant
223     , [mem] &quot;+Q&quot;  (*dest)    // read/write, memory to be updated atomically
224     //---&lt;  inputs  &gt;---
225     : [upd] &quot;d&quot;   (exchange_value) // read-only, value to be written to memory
226     //---&lt;  clobbered  &gt;---
227     : &quot;cc&quot;, &quot;memory&quot;
228   );
229 
230   return old;
231 }
232 
233 template&lt;&gt;
234 template&lt;typename T&gt;
<span class="line-modified">235 inline T Atomic::PlatformXchg&lt;8&gt;::operator()(T exchange_value,</span>
<span class="line-modified">236                                              T volatile* dest,</span>
237                                              atomic_memory_order unused) const {
238   STATIC_ASSERT(8 == sizeof(T));
239   T old;
240 
241   __asm__ __volatile__ (
242     &quot;   LG       %[old],%[mem]           \n\t&quot; // get old value
243     &quot;0: CSG      %[old],%[upd],%[mem]    \n\t&quot; // try to xchg upd with mem
244     &quot;   JNE      0b                      \n\t&quot; // no success? -&gt; retry
245     //---&lt;  outputs  &gt;---
246     : [old] &quot;=&amp;d&quot; (old)      // write-only, init from memory
247     , [mem] &quot;+Q&quot;  (*dest)    // read/write, memory to be updated atomically
248     //---&lt;  inputs  &gt;---
249     : [upd] &quot;d&quot;   (exchange_value) // read-only, value to be written to memory
250     //---&lt;  clobbered  &gt;---
251     : &quot;cc&quot;, &quot;memory&quot;
252   );
253 
254   return old;
255 }
256 
</pre>
<hr />
<pre>
272 //
273 // Inspecting the return value is the only way for the caller to determine
274 // if the compare-and-swap instruction was successful:
275 // - If return value and compare value compare equal, the compare-and-swap
276 //   instruction was successful and the value in memory was replaced by the
277 //   exchange value.
278 // - If return value and compare value compare unequal, the compare-and-swap
279 //   instruction was not successful. The value in memory was left unchanged.
280 //
281 // The s390 processors always fence before and after the csg instructions.
282 // Thus we ignore the memory ordering argument. The docu says: &quot;A serialization
283 // function is performed before the operand is fetched and again after the
284 // operation is completed.&quot;
285 
286 // No direct support for cmpxchg of bytes; emulate using int.
287 template&lt;&gt;
288 struct Atomic::PlatformCmpxchg&lt;1&gt; : Atomic::CmpxchgByteUsingInt {};
289 
290 template&lt;&gt;
291 template&lt;typename T&gt;
<span class="line-modified">292 inline T Atomic::PlatformCmpxchg&lt;4&gt;::operator()(T xchg_val,</span>
<span class="line-removed">293                                                 T volatile* dest,</span>
294                                                 T cmp_val,

295                                                 atomic_memory_order unused) const {
296   STATIC_ASSERT(4 == sizeof(T));
297   T old;
298 
299   __asm__ __volatile__ (
300     &quot;   CS       %[old],%[upd],%[mem]    \n\t&quot; // Try to xchg upd with mem.
301     // outputs
302     : [old] &quot;=&amp;d&quot; (old)      // Write-only, prev value irrelevant.
303     , [mem] &quot;+Q&quot;  (*dest)    // Read/write, memory to be updated atomically.
304     // inputs
305     : [upd] &quot;d&quot;   (xchg_val)
306     ,       &quot;0&quot;   (cmp_val)  // Read-only, initial value for [old] (operand #0).
307     // clobbered
308     : &quot;cc&quot;, &quot;memory&quot;
309   );
310 
311   return old;
312 }
313 
314 template&lt;&gt;
315 template&lt;typename T&gt;
<span class="line-modified">316 inline T Atomic::PlatformCmpxchg&lt;8&gt;::operator()(T xchg_val,</span>
<span class="line-removed">317                                                 T volatile* dest,</span>
318                                                 T cmp_val,

319                                                 atomic_memory_order unused) const {
320   STATIC_ASSERT(8 == sizeof(T));
321   T old;
322 
323   __asm__ __volatile__ (
324     &quot;   CSG      %[old],%[upd],%[mem]    \n\t&quot; // Try to xchg upd with mem.
325     // outputs
326     : [old] &quot;=&amp;d&quot; (old)      // Write-only, prev value irrelevant.
327     , [mem] &quot;+Q&quot;  (*dest)    // Read/write, memory to be updated atomically.
328     // inputs
329     : [upd] &quot;d&quot;   (xchg_val)
330     ,       &quot;0&quot;   (cmp_val)  // Read-only, initial value for [old] (operand #0).
331     // clobbered
332     : &quot;cc&quot;, &quot;memory&quot;
333   );
334 
335   return old;
336 }
337 







338 #endif // OS_CPU_LINUX_S390_ATOMIC_LINUX_S390_HPP
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
  2  * Copyright (c) 2016, 2019, Oracle and/or its affiliates. All rights reserved.
<span class="line-modified">  3  * Copyright (c) 2016, 2019 SAP SE. All rights reserved.</span>
  4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5  *
  6  * This code is free software; you can redistribute it and/or modify it
  7  * under the terms of the GNU General Public License version 2 only, as
  8  * published by the Free Software Foundation.
  9  *
 10  * This code is distributed in the hope that it will be useful, but WITHOUT
 11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13  * version 2 for more details (a copy is included in the LICENSE file that
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
 23  *
 24  */
 25 
 26 #ifndef OS_CPU_LINUX_S390_ATOMIC_LINUX_S390_HPP
 27 #define OS_CPU_LINUX_S390_ATOMIC_LINUX_S390_HPP
 28 
 29 #include &quot;runtime/atomic.hpp&quot;
 30 #include &quot;runtime/os.hpp&quot;
<span class="line-modified"> 31 #include &quot;runtime/vm_version.hpp&quot;</span>
 32 
 33 // Note that the compare-and-swap instructions on System z perform
 34 // a serialization function before the storage operand is fetched
 35 // and again after the operation is completed.
 36 //
 37 // Used constraint modifiers:
 38 // = write-only access: Value on entry to inline-assembler code irrelevant.
 39 // + read/write access: Value on entry is used; on exit value is changed.
 40 //   read-only  access: Value on entry is used and never changed.
 41 // &amp; early-clobber access: Might be modified before all read-only operands
 42 //                         have been used.
 43 // a address register operand (not GR0).
 44 // d general register operand (including GR0)
 45 // Q memory operand w/o index register.
 46 // 0..9 operand reference (by operand position).
 47 //      Used for operands that fill multiple roles. One example would be a
 48 //      write-only operand receiving its initial value from a read-only operand.
 49 //      Refer to cmpxchg(..) operand #0 and variable cmp_val for a real-life example.
 50 //
 51 
</pre>
<hr />
<pre>
 58 // Atomic::add
 59 //------------
 60 // These methods force the value in memory to be augmented by the passed increment.
 61 // Both, memory value and increment, are treated as 32bit signed binary integers.
 62 // No overflow exceptions are recognized, and the condition code does not hold
 63 // information about the value in memory.
 64 //
 65 // The value in memory is updated by using a compare-and-swap instruction. The
 66 // instruction is retried as often as required.
 67 //
 68 // The return value of the method is the value that was successfully stored. At the
 69 // time the caller receives back control, the value in memory may have changed already.
 70 
 71 // New atomic operations only include specific-operand-serialization, not full
 72 // memory barriers. We can use the Fast-BCR-Serialization Facility for them.
 73 inline void z196_fast_sync() {
 74   __asm__ __volatile__ (&quot;bcr 14, 0&quot; : : : &quot;memory&quot;);
 75 }
 76 
 77 template&lt;size_t byte_size&gt;
<span class="line-modified"> 78 struct Atomic::PlatformAdd {</span>
<span class="line-modified"> 79   template&lt;typename D, typename I&gt;</span>
<span class="line-modified"> 80   D add_and_fetch(D volatile* dest, I add_value, atomic_memory_order order) const;</span>
<span class="line-modified"> 81 </span>
<span class="line-modified"> 82   template&lt;typename D, typename I&gt;</span>
<span class="line-added"> 83   D fetch_and_add(D volatile* dest, I add_value, atomic_memory_order order) const {</span>
<span class="line-added"> 84     return add_and_fetch(dest, add_value, order) - add_value;</span>
<span class="line-added"> 85   }</span>
 86 };
 87 
 88 template&lt;&gt;
<span class="line-modified"> 89 template&lt;typename D, typename I&gt;</span>
<span class="line-modified"> 90 inline D Atomic::PlatformAdd&lt;4&gt;::add_and_fetch(D volatile* dest, I inc,</span>
 91                                                atomic_memory_order order) const {
 92   STATIC_ASSERT(4 == sizeof(I));
 93   STATIC_ASSERT(4 == sizeof(D));
 94 
 95   D old, upd;
 96 
 97   if (VM_Version::has_LoadAndALUAtomicV1()) {
 98     if (order == memory_order_conservative) { z196_fast_sync(); }
 99     __asm__ __volatile__ (
100       &quot;   LGFR     0,%[inc]                \n\t&quot; // save increment
101       &quot;   LA       3,%[mem]                \n\t&quot; // force data address into ARG2
102 //    &quot;   LAA      %[upd],%[inc],%[mem]    \n\t&quot; // increment and get old value
103 //    &quot;   LAA      2,0,0(3)                \n\t&quot; // actually coded instruction
104       &quot;   .byte    0xeb                    \n\t&quot; // LAA main opcode
105       &quot;   .byte    0x20                    \n\t&quot; // R1,R3
106       &quot;   .byte    0x30                    \n\t&quot; // R2,disp1
107       &quot;   .byte    0x00                    \n\t&quot; // disp2,disp3
108       &quot;   .byte    0x00                    \n\t&quot; // disp4,disp5
109       &quot;   .byte    0xf8                    \n\t&quot; // LAA minor opcode
110       &quot;   AR       2,0                     \n\t&quot; // calc new value in register
</pre>
<hr />
<pre>
123       &quot;   LLGF     %[old],%[mem]           \n\t&quot; // get old value
124       &quot;0: LA       %[upd],0(%[inc],%[old]) \n\t&quot; // calc result
125       &quot;   CS       %[old],%[upd],%[mem]    \n\t&quot; // try to xchg res with mem
126       &quot;   JNE      0b                      \n\t&quot; // no success? -&gt; retry
127       //---&lt;  outputs  &gt;---
128       : [old] &quot;=&amp;a&quot; (old)    // write-only, old counter value
129       , [upd] &quot;=&amp;d&quot; (upd)    // write-only, updated counter value
130       , [mem] &quot;+Q&quot;  (*dest)  // read/write, memory to be updated atomically
131       //---&lt;  inputs  &gt;---
132       : [inc] &quot;a&quot;   (inc)    // read-only.
133       //---&lt;  clobbered  &gt;---
134       : &quot;cc&quot;, &quot;memory&quot;
135     );
136   }
137 
138   return upd;
139 }
140 
141 
142 template&lt;&gt;
<span class="line-modified">143 template&lt;typename D, typename I&gt;</span>
<span class="line-modified">144 inline D Atomic::PlatformAdd&lt;8&gt;::add_and_fetch(D volatile* dest, I inc,</span>
145                                                atomic_memory_order order) const {
146   STATIC_ASSERT(8 == sizeof(I));
147   STATIC_ASSERT(8 == sizeof(D));
148 
149   D old, upd;
150 
151   if (VM_Version::has_LoadAndALUAtomicV1()) {
152     if (order == memory_order_conservative) { z196_fast_sync(); }
153     __asm__ __volatile__ (
154       &quot;   LGR      0,%[inc]                \n\t&quot; // save increment
155       &quot;   LA       3,%[mem]                \n\t&quot; // force data address into ARG2
156 //    &quot;   LAAG     %[upd],%[inc],%[mem]    \n\t&quot; // increment and get old value
157 //    &quot;   LAAG     2,0,0(3)                \n\t&quot; // actually coded instruction
158       &quot;   .byte    0xeb                    \n\t&quot; // LAA main opcode
159       &quot;   .byte    0x20                    \n\t&quot; // R1,R3
160       &quot;   .byte    0x30                    \n\t&quot; // R2,disp1
161       &quot;   .byte    0x00                    \n\t&quot; // disp2,disp3
162       &quot;   .byte    0x00                    \n\t&quot; // disp4,disp5
163       &quot;   .byte    0xe8                    \n\t&quot; // LAA minor opcode
164       &quot;   AGR      2,0                     \n\t&quot; // calc new value in register
</pre>
<hr />
<pre>
194 
195 
196 //-------------
197 // Atomic::xchg
198 //-------------
199 // These methods force the value in memory to be replaced by the new value passed
200 // in as argument.
201 //
202 // The value in memory is replaced by using a compare-and-swap instruction. The
203 // instruction is retried as often as required. This makes sure that the new
204 // value can be seen, at least for a very short period of time, by other CPUs.
205 //
206 // If we would use a normal &quot;load(old value) store(new value)&quot; sequence,
207 // the new value could be lost unnoticed, due to a store(new value) from
208 // another thread.
209 //
210 // The return value is the (unchanged) value from memory as it was when the
211 // replacement succeeded.
212 template&lt;&gt;
213 template&lt;typename T&gt;
<span class="line-modified">214 inline T Atomic::PlatformXchg&lt;4&gt;::operator()(T volatile* dest,</span>
<span class="line-modified">215                                              T exchange_value,</span>
216                                              atomic_memory_order unused) const {
217   STATIC_ASSERT(4 == sizeof(T));
218   T old;
219 
220   __asm__ __volatile__ (
221     &quot;   LLGF     %[old],%[mem]           \n\t&quot; // get old value
222     &quot;0: CS       %[old],%[upd],%[mem]    \n\t&quot; // try to xchg upd with mem
223     &quot;   JNE      0b                      \n\t&quot; // no success? -&gt; retry
224     //---&lt;  outputs  &gt;---
225     : [old] &quot;=&amp;d&quot; (old)      // write-only, prev value irrelevant
226     , [mem] &quot;+Q&quot;  (*dest)    // read/write, memory to be updated atomically
227     //---&lt;  inputs  &gt;---
228     : [upd] &quot;d&quot;   (exchange_value) // read-only, value to be written to memory
229     //---&lt;  clobbered  &gt;---
230     : &quot;cc&quot;, &quot;memory&quot;
231   );
232 
233   return old;
234 }
235 
236 template&lt;&gt;
237 template&lt;typename T&gt;
<span class="line-modified">238 inline T Atomic::PlatformXchg&lt;8&gt;::operator()(T volatile* dest,</span>
<span class="line-modified">239                                              T exchange_value,</span>
240                                              atomic_memory_order unused) const {
241   STATIC_ASSERT(8 == sizeof(T));
242   T old;
243 
244   __asm__ __volatile__ (
245     &quot;   LG       %[old],%[mem]           \n\t&quot; // get old value
246     &quot;0: CSG      %[old],%[upd],%[mem]    \n\t&quot; // try to xchg upd with mem
247     &quot;   JNE      0b                      \n\t&quot; // no success? -&gt; retry
248     //---&lt;  outputs  &gt;---
249     : [old] &quot;=&amp;d&quot; (old)      // write-only, init from memory
250     , [mem] &quot;+Q&quot;  (*dest)    // read/write, memory to be updated atomically
251     //---&lt;  inputs  &gt;---
252     : [upd] &quot;d&quot;   (exchange_value) // read-only, value to be written to memory
253     //---&lt;  clobbered  &gt;---
254     : &quot;cc&quot;, &quot;memory&quot;
255   );
256 
257   return old;
258 }
259 
</pre>
<hr />
<pre>
275 //
276 // Inspecting the return value is the only way for the caller to determine
277 // if the compare-and-swap instruction was successful:
278 // - If return value and compare value compare equal, the compare-and-swap
279 //   instruction was successful and the value in memory was replaced by the
280 //   exchange value.
281 // - If return value and compare value compare unequal, the compare-and-swap
282 //   instruction was not successful. The value in memory was left unchanged.
283 //
284 // The s390 processors always fence before and after the csg instructions.
285 // Thus we ignore the memory ordering argument. The docu says: &quot;A serialization
286 // function is performed before the operand is fetched and again after the
287 // operation is completed.&quot;
288 
289 // No direct support for cmpxchg of bytes; emulate using int.
290 template&lt;&gt;
291 struct Atomic::PlatformCmpxchg&lt;1&gt; : Atomic::CmpxchgByteUsingInt {};
292 
293 template&lt;&gt;
294 template&lt;typename T&gt;
<span class="line-modified">295 inline T Atomic::PlatformCmpxchg&lt;4&gt;::operator()(T volatile* dest,</span>

296                                                 T cmp_val,
<span class="line-added">297                                                 T xchg_val,</span>
298                                                 atomic_memory_order unused) const {
299   STATIC_ASSERT(4 == sizeof(T));
300   T old;
301 
302   __asm__ __volatile__ (
303     &quot;   CS       %[old],%[upd],%[mem]    \n\t&quot; // Try to xchg upd with mem.
304     // outputs
305     : [old] &quot;=&amp;d&quot; (old)      // Write-only, prev value irrelevant.
306     , [mem] &quot;+Q&quot;  (*dest)    // Read/write, memory to be updated atomically.
307     // inputs
308     : [upd] &quot;d&quot;   (xchg_val)
309     ,       &quot;0&quot;   (cmp_val)  // Read-only, initial value for [old] (operand #0).
310     // clobbered
311     : &quot;cc&quot;, &quot;memory&quot;
312   );
313 
314   return old;
315 }
316 
317 template&lt;&gt;
318 template&lt;typename T&gt;
<span class="line-modified">319 inline T Atomic::PlatformCmpxchg&lt;8&gt;::operator()(T volatile* dest,</span>

320                                                 T cmp_val,
<span class="line-added">321                                                 T xchg_val,</span>
322                                                 atomic_memory_order unused) const {
323   STATIC_ASSERT(8 == sizeof(T));
324   T old;
325 
326   __asm__ __volatile__ (
327     &quot;   CSG      %[old],%[upd],%[mem]    \n\t&quot; // Try to xchg upd with mem.
328     // outputs
329     : [old] &quot;=&amp;d&quot; (old)      // Write-only, prev value irrelevant.
330     , [mem] &quot;+Q&quot;  (*dest)    // Read/write, memory to be updated atomically.
331     // inputs
332     : [upd] &quot;d&quot;   (xchg_val)
333     ,       &quot;0&quot;   (cmp_val)  // Read-only, initial value for [old] (operand #0).
334     // clobbered
335     : &quot;cc&quot;, &quot;memory&quot;
336   );
337 
338   return old;
339 }
340 
<span class="line-added">341 template&lt;size_t byte_size&gt;</span>
<span class="line-added">342 struct Atomic::PlatformOrderedLoad&lt;byte_size, X_ACQUIRE&gt;</span>
<span class="line-added">343 {</span>
<span class="line-added">344   template &lt;typename T&gt;</span>
<span class="line-added">345   T operator()(const volatile T* p) const { T t = *p; OrderAccess::acquire(); return t; }</span>
<span class="line-added">346 };</span>
<span class="line-added">347 </span>
348 #endif // OS_CPU_LINUX_S390_ATOMIC_LINUX_S390_HPP
</pre>
</td>
</tr>
</table>
<center><a href="../linux_ppc/thread_linux_ppc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="orderAccess_linux_s390.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>