<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/os_cpu/linux_zero/atomic_linux_zero.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../linux_x86/vm_version_linux_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="orderAccess_linux_zero.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/os_cpu/linux_zero/atomic_linux_zero.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
 23  *
 24  */
 25 
 26 #ifndef OS_CPU_LINUX_ZERO_ATOMIC_LINUX_ZERO_HPP
 27 #define OS_CPU_LINUX_ZERO_ATOMIC_LINUX_ZERO_HPP
 28 
 29 #include &quot;runtime/os.hpp&quot;
 30 
 31 // Implementation of class atomic
 32 
 33 template&lt;size_t byte_size&gt;
<span class="line-modified"> 34 struct Atomic::PlatformAdd</span>
<span class="line-modified"> 35   : Atomic::AddAndFetch&lt;Atomic::PlatformAdd&lt;byte_size&gt; &gt;</span>
<span class="line-modified"> 36 {</span>
<span class="line-modified"> 37   template&lt;typename I, typename D&gt;</span>
<span class="line-modified"> 38   D add_and_fetch(I add_value, D volatile* dest, atomic_memory_order order) const;</span>



 39 };
 40 
 41 template&lt;&gt;
<span class="line-modified"> 42 template&lt;typename I, typename D&gt;</span>
<span class="line-modified"> 43 inline D Atomic::PlatformAdd&lt;4&gt;::add_and_fetch(I add_value, D volatile* dest,</span>
 44                                                atomic_memory_order order) const {
 45   STATIC_ASSERT(4 == sizeof(I));
 46   STATIC_ASSERT(4 == sizeof(D));
 47 
 48   return __sync_add_and_fetch(dest, add_value);
 49 }
 50 
 51 template&lt;&gt;
<span class="line-modified"> 52 template&lt;typename I, typename D&gt;</span>
<span class="line-modified"> 53 inline D Atomic::PlatformAdd&lt;8&gt;::add_and_fetch(I add_value, D volatile* dest,</span>
 54                                                atomic_memory_order order) const {
 55   STATIC_ASSERT(8 == sizeof(I));
 56   STATIC_ASSERT(8 == sizeof(D));
 57   return __sync_add_and_fetch(dest, add_value);
 58 }
 59 
 60 template&lt;&gt;
 61 template&lt;typename T&gt;
<span class="line-modified"> 62 inline T Atomic::PlatformXchg&lt;4&gt;::operator()(T exchange_value,</span>
<span class="line-modified"> 63                                              T volatile* dest,</span>
 64                                              atomic_memory_order order) const {
 65   STATIC_ASSERT(4 == sizeof(T));
 66   // __sync_lock_test_and_set is a bizarrely named atomic exchange
 67   // operation.  Note that some platforms only support this with the
 68   // limitation that the only valid value to store is the immediate
 69   // constant 1.  There is a test for this in JNI_CreateJavaVM().
 70   T result = __sync_lock_test_and_set (dest, exchange_value);
 71   // All atomic operations are expected to be full memory barriers
 72   // (see atomic.hpp). However, __sync_lock_test_and_set is not
 73   // a full memory barrier, but an acquire barrier. Hence, this added
 74   // barrier.
 75   __sync_synchronize();
 76   return result;
 77 }
 78 
 79 template&lt;&gt;
 80 template&lt;typename T&gt;
<span class="line-modified"> 81 inline T Atomic::PlatformXchg&lt;8&gt;::operator()(T exchange_value,</span>
<span class="line-modified"> 82                                              T volatile* dest,</span>
 83                                              atomic_memory_order order) const {
 84   STATIC_ASSERT(8 == sizeof(T));
 85   T result = __sync_lock_test_and_set (dest, exchange_value);
 86   __sync_synchronize();
 87   return result;
 88 }
 89 
 90 // No direct support for cmpxchg of bytes; emulate using int.
 91 template&lt;&gt;
 92 struct Atomic::PlatformCmpxchg&lt;1&gt; : Atomic::CmpxchgByteUsingInt {};
 93 
 94 template&lt;&gt;
 95 template&lt;typename T&gt;
<span class="line-modified"> 96 inline T Atomic::PlatformCmpxchg&lt;4&gt;::operator()(T exchange_value,</span>
<span class="line-removed"> 97                                                 T volatile* dest,</span>
 98                                                 T compare_value,

 99                                                 atomic_memory_order order) const {
100   STATIC_ASSERT(4 == sizeof(T));
101   return __sync_val_compare_and_swap(dest, compare_value, exchange_value);
102 }
103 
104 template&lt;&gt;
105 template&lt;typename T&gt;
<span class="line-modified">106 inline T Atomic::PlatformCmpxchg&lt;8&gt;::operator()(T exchange_value,</span>
<span class="line-removed">107                                                 T volatile* dest,</span>
108                                                 T compare_value,

109                                                 atomic_memory_order order) const {
110   STATIC_ASSERT(8 == sizeof(T));
111   return __sync_val_compare_and_swap(dest, compare_value, exchange_value);
112 }
113 
114 template&lt;&gt;
115 template&lt;typename T&gt;
116 inline T Atomic::PlatformLoad&lt;8&gt;::operator()(T const volatile* src) const {
117   STATIC_ASSERT(8 == sizeof(T));
118   volatile int64_t dest;
119   os::atomic_copy64(reinterpret_cast&lt;const volatile int64_t*&gt;(src), reinterpret_cast&lt;volatile int64_t*&gt;(&amp;dest));
120   return PrimitiveConversions::cast&lt;T&gt;(dest);
121 }
122 
123 template&lt;&gt;
124 template&lt;typename T&gt;
<span class="line-modified">125 inline void Atomic::PlatformStore&lt;8&gt;::operator()(T store_value,</span>
<span class="line-modified">126                                                  T volatile* dest) const {</span>
127   STATIC_ASSERT(8 == sizeof(T));
128   os::atomic_copy64(reinterpret_cast&lt;const volatile int64_t*&gt;(&amp;store_value), reinterpret_cast&lt;volatile int64_t*&gt;(dest));
129 }
130 
131 #endif // OS_CPU_LINUX_ZERO_ATOMIC_LINUX_ZERO_HPP
</pre>
</td>
<td>
<hr />
<pre>
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
 23  *
 24  */
 25 
 26 #ifndef OS_CPU_LINUX_ZERO_ATOMIC_LINUX_ZERO_HPP
 27 #define OS_CPU_LINUX_ZERO_ATOMIC_LINUX_ZERO_HPP
 28 
 29 #include &quot;runtime/os.hpp&quot;
 30 
 31 // Implementation of class atomic
 32 
 33 template&lt;size_t byte_size&gt;
<span class="line-modified"> 34 struct Atomic::PlatformAdd {</span>
<span class="line-modified"> 35   template&lt;typename D, typename I&gt;</span>
<span class="line-modified"> 36   D add_and_fetch(D volatile* dest, I add_value, atomic_memory_order order) const;</span>
<span class="line-modified"> 37 </span>
<span class="line-modified"> 38   template&lt;typename D, typename I&gt;</span>
<span class="line-added"> 39   D fetch_and_add(D volatile* dest, I add_value, atomic_memory_order order) const {</span>
<span class="line-added"> 40     return add_and_fetch(dest, add_value, order) - add_value;</span>
<span class="line-added"> 41   }</span>
 42 };
 43 
 44 template&lt;&gt;
<span class="line-modified"> 45 template&lt;typename D, typename I&gt;</span>
<span class="line-modified"> 46 inline D Atomic::PlatformAdd&lt;4&gt;::add_and_fetch(D volatile* dest, I add_value,</span>
 47                                                atomic_memory_order order) const {
 48   STATIC_ASSERT(4 == sizeof(I));
 49   STATIC_ASSERT(4 == sizeof(D));
 50 
 51   return __sync_add_and_fetch(dest, add_value);
 52 }
 53 
 54 template&lt;&gt;
<span class="line-modified"> 55 template&lt;typename D, typename I&gt;</span>
<span class="line-modified"> 56 inline D Atomic::PlatformAdd&lt;8&gt;::add_and_fetch(D volatile* dest, I add_value,</span>
 57                                                atomic_memory_order order) const {
 58   STATIC_ASSERT(8 == sizeof(I));
 59   STATIC_ASSERT(8 == sizeof(D));
 60   return __sync_add_and_fetch(dest, add_value);
 61 }
 62 
 63 template&lt;&gt;
 64 template&lt;typename T&gt;
<span class="line-modified"> 65 inline T Atomic::PlatformXchg&lt;4&gt;::operator()(T volatile* dest,</span>
<span class="line-modified"> 66                                              T exchange_value,</span>
 67                                              atomic_memory_order order) const {
 68   STATIC_ASSERT(4 == sizeof(T));
 69   // __sync_lock_test_and_set is a bizarrely named atomic exchange
 70   // operation.  Note that some platforms only support this with the
 71   // limitation that the only valid value to store is the immediate
 72   // constant 1.  There is a test for this in JNI_CreateJavaVM().
 73   T result = __sync_lock_test_and_set (dest, exchange_value);
 74   // All atomic operations are expected to be full memory barriers
 75   // (see atomic.hpp). However, __sync_lock_test_and_set is not
 76   // a full memory barrier, but an acquire barrier. Hence, this added
 77   // barrier.
 78   __sync_synchronize();
 79   return result;
 80 }
 81 
 82 template&lt;&gt;
 83 template&lt;typename T&gt;
<span class="line-modified"> 84 inline T Atomic::PlatformXchg&lt;8&gt;::operator()(T volatile* dest,</span>
<span class="line-modified"> 85                                              T exchange_value,</span>
 86                                              atomic_memory_order order) const {
 87   STATIC_ASSERT(8 == sizeof(T));
 88   T result = __sync_lock_test_and_set (dest, exchange_value);
 89   __sync_synchronize();
 90   return result;
 91 }
 92 
 93 // No direct support for cmpxchg of bytes; emulate using int.
 94 template&lt;&gt;
 95 struct Atomic::PlatformCmpxchg&lt;1&gt; : Atomic::CmpxchgByteUsingInt {};
 96 
 97 template&lt;&gt;
 98 template&lt;typename T&gt;
<span class="line-modified"> 99 inline T Atomic::PlatformCmpxchg&lt;4&gt;::operator()(T volatile* dest,</span>

100                                                 T compare_value,
<span class="line-added">101                                                 T exchange_value,</span>
102                                                 atomic_memory_order order) const {
103   STATIC_ASSERT(4 == sizeof(T));
104   return __sync_val_compare_and_swap(dest, compare_value, exchange_value);
105 }
106 
107 template&lt;&gt;
108 template&lt;typename T&gt;
<span class="line-modified">109 inline T Atomic::PlatformCmpxchg&lt;8&gt;::operator()(T volatile* dest,</span>

110                                                 T compare_value,
<span class="line-added">111                                                 T exchange_value,</span>
112                                                 atomic_memory_order order) const {
113   STATIC_ASSERT(8 == sizeof(T));
114   return __sync_val_compare_and_swap(dest, compare_value, exchange_value);
115 }
116 
117 template&lt;&gt;
118 template&lt;typename T&gt;
119 inline T Atomic::PlatformLoad&lt;8&gt;::operator()(T const volatile* src) const {
120   STATIC_ASSERT(8 == sizeof(T));
121   volatile int64_t dest;
122   os::atomic_copy64(reinterpret_cast&lt;const volatile int64_t*&gt;(src), reinterpret_cast&lt;volatile int64_t*&gt;(&amp;dest));
123   return PrimitiveConversions::cast&lt;T&gt;(dest);
124 }
125 
126 template&lt;&gt;
127 template&lt;typename T&gt;
<span class="line-modified">128 inline void Atomic::PlatformStore&lt;8&gt;::operator()(T volatile* dest,</span>
<span class="line-modified">129                                                  T store_value) const {</span>
130   STATIC_ASSERT(8 == sizeof(T));
131   os::atomic_copy64(reinterpret_cast&lt;const volatile int64_t*&gt;(&amp;store_value), reinterpret_cast&lt;volatile int64_t*&gt;(dest));
132 }
133 
134 #endif // OS_CPU_LINUX_ZERO_ATOMIC_LINUX_ZERO_HPP
</pre>
</td>
</tr>
</table>
<center><a href="../linux_x86/vm_version_linux_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="orderAccess_linux_zero.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>