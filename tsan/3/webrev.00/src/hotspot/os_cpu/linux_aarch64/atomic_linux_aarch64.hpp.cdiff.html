<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff src/hotspot/os_cpu/linux_aarch64/atomic_linux_aarch64.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../bsd_zero/vm_version_bsd_zero.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="copy_linux_aarch64.s.cdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/os_cpu/linux_aarch64/atomic_linux_aarch64.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 1,8 ***</span>
  /*
   * Copyright (c) 1999, 2019, Oracle and/or its affiliates. All rights reserved.
<span class="line-modified">!  * Copyright (c) 2014, Red Hat Inc. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
<span class="line-new-header">--- 1,8 ---</span>
  /*
   * Copyright (c) 1999, 2019, Oracle and/or its affiliates. All rights reserved.
<span class="line-modified">!  * Copyright (c) 2014, 2019, Red Hat Inc. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 24,52 ***</span>
   */
  
  #ifndef OS_CPU_LINUX_AARCH64_ATOMIC_LINUX_AARCH64_HPP
  #define OS_CPU_LINUX_AARCH64_ATOMIC_LINUX_AARCH64_HPP
  
<span class="line-modified">! #include &quot;vm_version_aarch64.hpp&quot;</span>
  
  // Implementation of class atomic
<span class="line-modified">! </span>
<span class="line-modified">! #define FULL_MEM_BARRIER  __sync_synchronize()</span>
<span class="line-removed">- #define READ_MEM_BARRIER  __atomic_thread_fence(__ATOMIC_ACQUIRE);</span>
<span class="line-removed">- #define WRITE_MEM_BARRIER __atomic_thread_fence(__ATOMIC_RELEASE);</span>
  
  template&lt;size_t byte_size&gt;
<span class="line-modified">! struct Atomic::PlatformAdd</span>
<span class="line-modified">!   : Atomic::AddAndFetch&lt;Atomic::PlatformAdd&lt;byte_size&gt; &gt;</span>
<span class="line-modified">! {</span>
<span class="line-modified">!   template&lt;typename I, typename D&gt;</span>
<span class="line-modified">!   D add_and_fetch(I add_value, D volatile* dest, atomic_memory_order order) const {</span>
<span class="line-modified">!     return __sync_add_and_fetch(dest, add_value);</span>
    }
  };
  
  template&lt;size_t byte_size&gt;
  template&lt;typename T&gt;
<span class="line-modified">! inline T Atomic::PlatformXchg&lt;byte_size&gt;::operator()(T exchange_value,</span>
<span class="line-modified">!                                                      T volatile* dest,</span>
                                                       atomic_memory_order order) const {
    STATIC_ASSERT(byte_size == sizeof(T));
<span class="line-modified">!   T res = __sync_lock_test_and_set(dest, exchange_value);</span>
    FULL_MEM_BARRIER;
    return res;
  }
  
  template&lt;size_t byte_size&gt;
  template&lt;typename T&gt;
<span class="line-modified">! inline T Atomic::PlatformCmpxchg&lt;byte_size&gt;::operator()(T exchange_value,</span>
<span class="line-removed">-                                                         T volatile* dest,</span>
                                                          T compare_value,
                                                          atomic_memory_order order) const {
    STATIC_ASSERT(byte_size == sizeof(T));
    if (order == memory_order_relaxed) {
      T value = compare_value;
      __atomic_compare_exchange(dest, &amp;value, &amp;exchange_value, /*weak*/false,
                                __ATOMIC_RELAXED, __ATOMIC_RELAXED);
      return value;
    } else {
<span class="line-modified">!     return __sync_val_compare_and_swap(dest, compare_value, exchange_value);</span>
    }
  }
  
  #endif // OS_CPU_LINUX_AARCH64_ATOMIC_LINUX_AARCH64_HPP
<span class="line-new-header">--- 24,82 ---</span>
   */
  
  #ifndef OS_CPU_LINUX_AARCH64_ATOMIC_LINUX_AARCH64_HPP
  #define OS_CPU_LINUX_AARCH64_ATOMIC_LINUX_AARCH64_HPP
  
<span class="line-modified">! #include &quot;runtime/vm_version.hpp&quot;</span>
  
  // Implementation of class atomic
<span class="line-modified">! // Note that memory_order_conservative requires a full barrier after atomic stores.</span>
<span class="line-modified">! // See https://patchwork.kernel.org/patch/3575821/</span>
  
  template&lt;size_t byte_size&gt;
<span class="line-modified">! struct Atomic::PlatformAdd {</span>
<span class="line-modified">!   template&lt;typename D, typename I&gt;</span>
<span class="line-modified">!   D add_and_fetch(D volatile* dest, I add_value, atomic_memory_order order) const {</span>
<span class="line-modified">!     D res = __atomic_add_fetch(dest, add_value, __ATOMIC_RELEASE);</span>
<span class="line-modified">!     FULL_MEM_BARRIER;</span>
<span class="line-modified">!     return res;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   template&lt;typename D, typename I&gt;</span>
<span class="line-added">+   D fetch_and_add(D volatile* dest, I add_value, atomic_memory_order order) const {</span>
<span class="line-added">+     return add_and_fetch(dest, add_value, order) - add_value;</span>
    }
  };
  
  template&lt;size_t byte_size&gt;
  template&lt;typename T&gt;
<span class="line-modified">! inline T Atomic::PlatformXchg&lt;byte_size&gt;::operator()(T volatile* dest,</span>
<span class="line-modified">!                                                      T exchange_value,</span>
                                                       atomic_memory_order order) const {
    STATIC_ASSERT(byte_size == sizeof(T));
<span class="line-modified">!   T res = __atomic_exchange_n(dest, exchange_value, __ATOMIC_RELEASE);</span>
    FULL_MEM_BARRIER;
    return res;
  }
  
<span class="line-added">+ // __attribute__((unused)) on dest is to get rid of spurious GCC warnings.</span>
  template&lt;size_t byte_size&gt;
  template&lt;typename T&gt;
<span class="line-modified">! inline T Atomic::PlatformCmpxchg&lt;byte_size&gt;::operator()(T volatile* dest __attribute__((unused)),</span>
                                                          T compare_value,
<span class="line-added">+                                                         T exchange_value,</span>
                                                          atomic_memory_order order) const {
    STATIC_ASSERT(byte_size == sizeof(T));
    if (order == memory_order_relaxed) {
      T value = compare_value;
      __atomic_compare_exchange(dest, &amp;value, &amp;exchange_value, /*weak*/false,
                                __ATOMIC_RELAXED, __ATOMIC_RELAXED);
      return value;
    } else {
<span class="line-modified">!     T value = compare_value;</span>
<span class="line-added">+     FULL_MEM_BARRIER;</span>
<span class="line-added">+     __atomic_compare_exchange(dest, &amp;value, &amp;exchange_value, /*weak*/false,</span>
<span class="line-added">+                               __ATOMIC_RELAXED, __ATOMIC_RELAXED);</span>
<span class="line-added">+     FULL_MEM_BARRIER;</span>
<span class="line-added">+     return value;</span>
    }
  }
  
<span class="line-added">+ template&lt;size_t byte_size&gt;</span>
<span class="line-added">+ struct Atomic::PlatformOrderedLoad&lt;byte_size, X_ACQUIRE&gt;</span>
<span class="line-added">+ {</span>
<span class="line-added">+   template &lt;typename T&gt;</span>
<span class="line-added">+   T operator()(const volatile T* p) const { T data; __atomic_load(const_cast&lt;T*&gt;(p), &amp;data, __ATOMIC_ACQUIRE); return data; }</span>
<span class="line-added">+ };</span>
<span class="line-added">+ </span>
<span class="line-added">+ template&lt;size_t byte_size&gt;</span>
<span class="line-added">+ struct Atomic::PlatformOrderedStore&lt;byte_size, RELEASE_X&gt;</span>
<span class="line-added">+ {</span>
<span class="line-added">+   template &lt;typename T&gt;</span>
<span class="line-added">+   void operator()(volatile T* p, T v) const { __atomic_store(const_cast&lt;T*&gt;(p), &amp;v, __ATOMIC_RELEASE); }</span>
<span class="line-added">+ };</span>
<span class="line-added">+ </span>
<span class="line-added">+ template&lt;size_t byte_size&gt;</span>
<span class="line-added">+ struct Atomic::PlatformOrderedStore&lt;byte_size, RELEASE_X_FENCE&gt;</span>
<span class="line-added">+ {</span>
<span class="line-added">+   template &lt;typename T&gt;</span>
<span class="line-added">+   void operator()(volatile T* p, T v) const { release_store(p, v); OrderAccess::fence(); }</span>
<span class="line-added">+ };</span>
<span class="line-added">+ </span>
  #endif // OS_CPU_LINUX_AARCH64_ATOMIC_LINUX_AARCH64_HPP
</pre>
<center><a href="../bsd_zero/vm_version_bsd_zero.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="copy_linux_aarch64.s.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>