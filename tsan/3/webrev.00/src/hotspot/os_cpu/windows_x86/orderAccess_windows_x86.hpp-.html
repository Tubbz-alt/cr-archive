<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/os_cpu/windows_x86/orderAccess_windows_x86.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2003, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef OS_CPU_WINDOWS_X86_ORDERACCESS_WINDOWS_X86_HPP
 26 #define OS_CPU_WINDOWS_X86_ORDERACCESS_WINDOWS_X86_HPP
 27 
 28 // Included in orderAccess.hpp header file.
 29 
 30 #include &lt;intrin.h&gt;
 31 
 32 // Compiler version last used for testing: Microsoft Visual Studio 2010
 33 // Please update this information when this file changes
 34 
 35 // Implementation of class OrderAccess.
 36 
 37 // A compiler barrier, forcing the C++ compiler to invalidate all memory assumptions
 38 inline void compiler_barrier() {
 39   _ReadWriteBarrier();
 40 }
 41 
 42 // Note that in MSVC, volatile memory accesses are explicitly
 43 // guaranteed to have acquire release semantics (w.r.t. compiler
 44 // reordering) and therefore does not even need a compiler barrier
 45 // for normal acquire release accesses. And all generalized
 46 // bound calls like release_store go through OrderAccess::load
 47 // and OrderAccess::store which do volatile memory accesses.
 48 template&lt;&gt; inline void ScopedFence&lt;X_ACQUIRE&gt;::postfix()       { }
 49 template&lt;&gt; inline void ScopedFence&lt;RELEASE_X&gt;::prefix()        { }
 50 template&lt;&gt; inline void ScopedFence&lt;RELEASE_X_FENCE&gt;::prefix()  { }
 51 template&lt;&gt; inline void ScopedFence&lt;RELEASE_X_FENCE&gt;::postfix() { OrderAccess::fence(); }
 52 
 53 inline void OrderAccess::loadload()   { compiler_barrier(); }
 54 inline void OrderAccess::storestore() { compiler_barrier(); }
 55 inline void OrderAccess::loadstore()  { compiler_barrier(); }
 56 inline void OrderAccess::storeload()  { fence(); }
 57 
 58 inline void OrderAccess::acquire()    { compiler_barrier(); }
 59 inline void OrderAccess::release()    { compiler_barrier(); }
 60 
 61 inline void OrderAccess::fence() {
 62 #ifdef AMD64
 63   StubRoutines_fence();
 64 #else
 65   __asm {
 66     lock add dword ptr [esp], 0;
 67   }
 68 #endif // AMD64
 69   compiler_barrier();
 70 }
 71 
 72 #ifndef AMD64
 73 template&lt;&gt;
 74 struct OrderAccess::PlatformOrderedStore&lt;1, RELEASE_X_FENCE&gt;
 75 {
 76   template &lt;typename T&gt;
 77   void operator()(T v, volatile T* p) const {
 78     __asm {
 79       mov edx, p;
 80       mov al, v;
 81       xchg al, byte ptr [edx];
 82     }
 83   }
 84 };
 85 
 86 template&lt;&gt;
 87 struct OrderAccess::PlatformOrderedStore&lt;2, RELEASE_X_FENCE&gt;
 88 {
 89   template &lt;typename T&gt;
 90   void operator()(T v, volatile T* p) const {
 91     __asm {
 92       mov edx, p;
 93       mov ax, v;
 94       xchg ax, word ptr [edx];
 95     }
 96   }
 97 };
 98 
 99 template&lt;&gt;
100 struct OrderAccess::PlatformOrderedStore&lt;4, RELEASE_X_FENCE&gt;
101 {
102   template &lt;typename T&gt;
103   void operator()(T v, volatile T* p) const {
104     __asm {
105       mov edx, p;
106       mov eax, v;
107       xchg eax, dword ptr [edx];
108     }
109   }
110 };
111 #endif // AMD64
112 
113 #endif // OS_CPU_WINDOWS_X86_ORDERACCESS_WINDOWS_X86_HPP
    </pre>
  </body>
</html>