<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/os_cpu/linux_x86/orderAccess_linux_x86.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="linux_x86_32.s.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="os_linux_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/os_cpu/linux_x86/orderAccess_linux_x86.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 38 }
 39 
 40 inline void OrderAccess::loadload()   { compiler_barrier(); }
 41 inline void OrderAccess::storestore() { compiler_barrier(); }
 42 inline void OrderAccess::loadstore()  { compiler_barrier(); }
 43 inline void OrderAccess::storeload()  { fence();            }
 44 
 45 inline void OrderAccess::acquire()    { compiler_barrier(); }
 46 inline void OrderAccess::release()    { compiler_barrier(); }
 47 
 48 inline void OrderAccess::fence() {
 49    // always use locked addl since mfence is sometimes expensive
 50 #ifdef AMD64
 51   __asm__ volatile (&quot;lock; addl $0,0(%%rsp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;);
 52 #else
 53   __asm__ volatile (&quot;lock; addl $0,0(%%esp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;);
 54 #endif
 55   compiler_barrier();
 56 }
 57 
<span class="line-modified"> 58 template&lt;&gt;</span>
<span class="line-modified"> 59 struct OrderAccess::PlatformOrderedStore&lt;1, RELEASE_X_FENCE&gt;</span>
<span class="line-removed"> 60 {</span>
<span class="line-removed"> 61   template &lt;typename T&gt;</span>
<span class="line-removed"> 62   void operator()(T v, volatile T* p) const {</span>
<span class="line-removed"> 63     __asm__ volatile (  &quot;xchgb (%2),%0&quot;</span>
<span class="line-removed"> 64                       : &quot;=q&quot; (v)</span>
<span class="line-removed"> 65                       : &quot;0&quot; (v), &quot;r&quot; (p)</span>
<span class="line-removed"> 66                       : &quot;memory&quot;);</span>
<span class="line-removed"> 67   }</span>
<span class="line-removed"> 68 };</span>
<span class="line-removed"> 69 </span>
<span class="line-removed"> 70 template&lt;&gt;</span>
<span class="line-removed"> 71 struct OrderAccess::PlatformOrderedStore&lt;2, RELEASE_X_FENCE&gt;</span>
<span class="line-removed"> 72 {</span>
<span class="line-removed"> 73   template &lt;typename T&gt;</span>
<span class="line-removed"> 74   void operator()(T v, volatile T* p) const {</span>
<span class="line-removed"> 75     __asm__ volatile (  &quot;xchgw (%2),%0&quot;</span>
<span class="line-removed"> 76                       : &quot;=r&quot; (v)</span>
<span class="line-removed"> 77                       : &quot;0&quot; (v), &quot;r&quot; (p)</span>
<span class="line-removed"> 78                       : &quot;memory&quot;);</span>
<span class="line-removed"> 79   }</span>
<span class="line-removed"> 80 };</span>
<span class="line-removed"> 81 </span>
<span class="line-removed"> 82 template&lt;&gt;</span>
<span class="line-removed"> 83 struct OrderAccess::PlatformOrderedStore&lt;4, RELEASE_X_FENCE&gt;</span>
<span class="line-removed"> 84 {</span>
<span class="line-removed"> 85   template &lt;typename T&gt;</span>
<span class="line-removed"> 86   void operator()(T v, volatile T* p) const {</span>
<span class="line-removed"> 87     __asm__ volatile (  &quot;xchgl (%2),%0&quot;</span>
<span class="line-removed"> 88                       : &quot;=r&quot; (v)</span>
<span class="line-removed"> 89                       : &quot;0&quot; (v), &quot;r&quot; (p)</span>
<span class="line-removed"> 90                       : &quot;memory&quot;);</span>
<span class="line-removed"> 91   }</span>
<span class="line-removed"> 92 };</span>
<span class="line-removed"> 93 </span>
 94 #ifdef AMD64
<span class="line-modified"> 95 template&lt;&gt;</span>
<span class="line-modified"> 96 struct OrderAccess::PlatformOrderedStore&lt;8, RELEASE_X_FENCE&gt;</span>
<span class="line-modified"> 97 {</span>
<span class="line-modified"> 98   template &lt;typename T&gt;</span>
<span class="line-modified"> 99   void operator()(T v, volatile T* p) const {</span>
<span class="line-modified">100     __asm__ volatile (  &quot;xchgq (%2), %0&quot;</span>
<span class="line-modified">101                       : &quot;=r&quot; (v)</span>
<span class="line-removed">102                       : &quot;0&quot; (v), &quot;r&quot; (p)</span>
<span class="line-removed">103                       : &quot;memory&quot;);</span>
<span class="line-removed">104   }</span>
<span class="line-removed">105 };</span>
<span class="line-removed">106 #endif // AMD64</span>
107 
108 #endif // OS_CPU_LINUX_X86_ORDERACCESS_LINUX_X86_HPP
</pre>
</td>
<td>
<hr />
<pre>
 38 }
 39 
 40 inline void OrderAccess::loadload()   { compiler_barrier(); }
 41 inline void OrderAccess::storestore() { compiler_barrier(); }
 42 inline void OrderAccess::loadstore()  { compiler_barrier(); }
 43 inline void OrderAccess::storeload()  { fence();            }
 44 
 45 inline void OrderAccess::acquire()    { compiler_barrier(); }
 46 inline void OrderAccess::release()    { compiler_barrier(); }
 47 
 48 inline void OrderAccess::fence() {
 49    // always use locked addl since mfence is sometimes expensive
 50 #ifdef AMD64
 51   __asm__ volatile (&quot;lock; addl $0,0(%%rsp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;);
 52 #else
 53   __asm__ volatile (&quot;lock; addl $0,0(%%esp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;);
 54 #endif
 55   compiler_barrier();
 56 }
 57 
<span class="line-modified"> 58 inline void OrderAccess::cross_modify_fence() {</span>
<span class="line-modified"> 59   int idx = 0;</span>


































 60 #ifdef AMD64
<span class="line-modified"> 61   __asm__ volatile (&quot;cpuid &quot; : &quot;+a&quot; (idx) : : &quot;ebx&quot;, &quot;ecx&quot;, &quot;edx&quot;, &quot;memory&quot;);</span>
<span class="line-modified"> 62 #else</span>
<span class="line-modified"> 63   // On some x86 systems EBX is a reserved register that cannot be</span>
<span class="line-modified"> 64   // clobbered, so we must protect it around the CPUID.</span>
<span class="line-modified"> 65   __asm__ volatile (&quot;xchg %%esi, %%ebx; cpuid; xchg %%esi, %%ebx &quot; : &quot;+a&quot; (idx) : : &quot;esi&quot;, &quot;ecx&quot;, &quot;edx&quot;, &quot;memory&quot;);</span>
<span class="line-modified"> 66 #endif</span>
<span class="line-modified"> 67 }</span>





 68 
 69 #endif // OS_CPU_LINUX_X86_ORDERACCESS_LINUX_X86_HPP
</pre>
</td>
</tr>
</table>
<center><a href="linux_x86_32.s.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="os_linux_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>