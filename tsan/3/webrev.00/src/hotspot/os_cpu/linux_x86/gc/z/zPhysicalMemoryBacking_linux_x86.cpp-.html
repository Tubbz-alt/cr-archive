<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/os_cpu/linux_x86/gc/z/zPhysicalMemoryBacking_linux_x86.cpp</title>
    <link rel="stylesheet" href="../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 #include &quot;precompiled.hpp&quot;
 25 #include &quot;gc/z/zAddress.inline.hpp&quot;
 26 #include &quot;gc/z/zBackingFile_linux_x86.hpp&quot;
 27 #include &quot;gc/z/zErrno.hpp&quot;
 28 #include &quot;gc/z/zGlobals.hpp&quot;
 29 #include &quot;gc/z/zLargePages.inline.hpp&quot;
 30 #include &quot;gc/z/zMemory.hpp&quot;
 31 #include &quot;gc/z/zNUMA.hpp&quot;
 32 #include &quot;gc/z/zPhysicalMemory.inline.hpp&quot;
 33 #include &quot;gc/z/zPhysicalMemoryBacking_linux_x86.hpp&quot;
 34 #include &quot;logging/log.hpp&quot;
 35 #include &quot;runtime/os.hpp&quot;
 36 #include &quot;utilities/align.hpp&quot;
 37 #include &quot;utilities/debug.hpp&quot;
 38 
 39 #include &lt;stdio.h&gt;
 40 #include &lt;sys/mman.h&gt;
 41 #include &lt;sys/types.h&gt;
 42 
 43 // Support for building on older Linux systems
 44 #ifndef MADV_HUGEPAGE
 45 #define MADV_HUGEPAGE                        14
 46 #endif
 47 
 48 // Proc file entry for max map mount
 49 #define ZFILENAME_PROC_MAX_MAP_COUNT         &quot;/proc/sys/vm/max_map_count&quot;
 50 
 51 ZPhysicalMemoryBacking::ZPhysicalMemoryBacking(size_t max_capacity) :
 52     _manager(),
 53     _file() {
 54 
 55   if (!_file.is_initialized()) {
 56     return;
 57   }
 58 
 59   // Check and warn if max map count is too low
 60   check_max_map_count(max_capacity);
 61 
 62   // Check and warn if available space on filesystem is too low
 63   check_available_space_on_filesystem(max_capacity);
 64 }
 65 
 66 void ZPhysicalMemoryBacking::check_max_map_count(size_t max_capacity) const {
 67   const char* const filename = ZFILENAME_PROC_MAX_MAP_COUNT;
 68   FILE* const file = fopen(filename, &quot;r&quot;);
 69   if (file == NULL) {
 70     // Failed to open file, skip check
 71     log_debug(gc, init)(&quot;Failed to open %s&quot;, filename);
 72     return;
 73   }
 74 
 75   size_t actual_max_map_count = 0;
 76   const int result = fscanf(file, SIZE_FORMAT, &amp;actual_max_map_count);
 77   fclose(file);
 78   if (result != 1) {
 79     // Failed to read file, skip check
 80     log_debug(gc, init)(&quot;Failed to read %s&quot;, filename);
 81     return;
 82   }
 83 
 84   // The required max map count is impossible to calculate exactly since subsystems
 85   // other than ZGC are also creating memory mappings, and we have no control over that.
 86   // However, ZGC tends to create the most mappings and dominate the total count.
 87   // In the worst cases, ZGC will map each granule three times, i.e. once per heap view.
 88   // We speculate that we need another 20% to allow for non-ZGC subsystems to map memory.
 89   const size_t required_max_map_count = (max_capacity / ZGranuleSize) * 3 * 1.2;
 90   if (actual_max_map_count &lt; required_max_map_count) {
 91     log_warning(gc, init)(&quot;***** WARNING! INCORRECT SYSTEM CONFIGURATION DETECTED! *****&quot;);
 92     log_warning(gc, init)(&quot;The system limit on number of memory mappings per process might be too low &quot;
 93                           &quot;for the given&quot;);
 94     log_warning(gc, init)(&quot;max Java heap size (&quot; SIZE_FORMAT &quot;M). Please adjust %s to allow for at&quot;,
 95                           max_capacity / M, filename);
 96     log_warning(gc, init)(&quot;least &quot; SIZE_FORMAT &quot; mappings (current limit is &quot; SIZE_FORMAT &quot;). Continuing &quot;
 97                           &quot;execution with the current&quot;, required_max_map_count, actual_max_map_count);
 98     log_warning(gc, init)(&quot;limit could lead to a fatal error, due to failure to map memory.&quot;);
 99   }
100 }
101 
102 void ZPhysicalMemoryBacking::check_available_space_on_filesystem(size_t max_capacity) const {
103   // Note that the available space on a tmpfs or a hugetlbfs filesystem
104   // will be zero if no size limit was specified when it was mounted.
105   const size_t available = _file.available();
106   if (available == 0) {
107     // No size limit set, skip check
108     log_info(gc, init)(&quot;Available space on backing filesystem: N/A&quot;);
109     return;
110   }
111 
112   log_info(gc, init)(&quot;Available space on backing filesystem: &quot; SIZE_FORMAT &quot;M&quot;,
113                      available / M);
114 
115   // Warn if the filesystem doesn&#39;t currently have enough space available to hold
116   // the max heap size. The max heap size will be capped if we later hit this limit
117   // when trying to expand the heap.
118   if (available &lt; max_capacity) {
119     log_warning(gc, init)(&quot;***** WARNING! INCORRECT SYSTEM CONFIGURATION DETECTED! *****&quot;);
120     log_warning(gc, init)(&quot;Not enough space available on the backing filesystem to hold the current &quot;
121                           &quot;max Java heap&quot;);
122     log_warning(gc, init)(&quot;size (&quot; SIZE_FORMAT &quot;M). Please adjust the size of the backing filesystem &quot;
123                           &quot;accordingly (available&quot;, max_capacity / M);
124     log_warning(gc, init)(&quot;space is currently &quot; SIZE_FORMAT &quot;M). Continuing execution with the current &quot;
125                           &quot;filesystem size could&quot;, available / M);
126     log_warning(gc, init)(&quot;lead to a premature OutOfMemoryError being thrown, due to failure to map &quot;
127                           &quot;memory.&quot;);
128   }
129 }
130 
131 bool ZPhysicalMemoryBacking::is_initialized() const {
132   return _file.is_initialized();
133 }
134 
135 size_t ZPhysicalMemoryBacking::try_expand(size_t old_capacity, size_t new_capacity) {
136   assert(old_capacity &lt; new_capacity, &quot;Invalid old/new capacity&quot;);
137 
138   const size_t capacity = _file.try_expand(old_capacity, new_capacity - old_capacity, ZGranuleSize);
139   if (capacity &gt; old_capacity) {
140     // Add expanded capacity to free list
141     _manager.free(old_capacity, capacity - old_capacity);
142   }
143 
144   return capacity;
145 }
146 
147 ZPhysicalMemory ZPhysicalMemoryBacking::alloc(size_t size) {
148   assert(is_aligned(size, ZGranuleSize), &quot;Invalid size&quot;);
149 
150   ZPhysicalMemory pmem;
151 
152   // Allocate segments
153   for (size_t allocated = 0; allocated &lt; size; allocated += ZGranuleSize) {
154     const uintptr_t start = _manager.alloc_from_front(ZGranuleSize);
155     assert(start != UINTPTR_MAX, &quot;Allocation should never fail&quot;);
156     pmem.add_segment(ZPhysicalMemorySegment(start, ZGranuleSize));
157   }
158 
159   return pmem;
160 }
161 
162 void ZPhysicalMemoryBacking::free(ZPhysicalMemory pmem) {
163   const size_t nsegments = pmem.nsegments();
164 
165   // Free segments
166   for (size_t i = 0; i &lt; nsegments; i++) {
167     const ZPhysicalMemorySegment segment = pmem.segment(i);
168     _manager.free(segment.start(), segment.size());
169   }
170 }
171 
172 void ZPhysicalMemoryBacking::map_failed(ZErrno err) const {
173   if (err == ENOMEM) {
174     fatal(&quot;Failed to map memory. Please check the system limit on number of &quot;
175           &quot;memory mappings allowed per process (see %s)&quot;, ZFILENAME_PROC_MAX_MAP_COUNT);
176   } else {
177     fatal(&quot;Failed to map memory (%s)&quot;, err.to_string());
178   }
179 }
180 
181 void ZPhysicalMemoryBacking::advise_view(uintptr_t addr, size_t size) const {
182   if (madvise((void*)addr, size, MADV_HUGEPAGE) == -1) {
183     ZErrno err;
184     log_error(gc)(&quot;Failed to advise use of transparent huge pages (%s)&quot;, err.to_string());
185   }
186 }
187 
188 void ZPhysicalMemoryBacking::pretouch_view(uintptr_t addr, size_t size) const {
189   const size_t page_size = ZLargePages::is_explicit() ? os::large_page_size() : os::vm_page_size();
190   os::pretouch_memory((void*)addr, (void*)(addr + size), page_size);
191 }
192 
193 void ZPhysicalMemoryBacking::map_view(ZPhysicalMemory pmem, uintptr_t addr, bool pretouch) const {
194   const size_t nsegments = pmem.nsegments();
195 
196   // Map segments
197   for (size_t i = 0; i &lt; nsegments; i++) {
198     const ZPhysicalMemorySegment segment = pmem.segment(i);
199     const size_t size = segment.size();
200     const void* const res = mmap((void*)addr, size, PROT_READ|PROT_WRITE, MAP_FIXED|MAP_SHARED, _file.fd(), segment.start());
201     if (res == MAP_FAILED) {
202       ZErrno err;
203       map_failed(err);
204     }
205 
206     // Advise on use of transparent huge pages before touching it
207     if (ZLargePages::is_transparent()) {
208       advise_view(addr, size);
209     }
210 
211     // NUMA interleave memory before touching it
212     ZNUMA::memory_interleave(addr, size);
213 
214     if (pretouch) {
215       pretouch_view(addr, size);
216     }
217 
218     addr += size;
219   }
220 }
221 
222 void ZPhysicalMemoryBacking::unmap_view(ZPhysicalMemory pmem, uintptr_t addr) const {
223   // Note that we must keep the address space reservation intact and just detach
224   // the backing memory. For this reason we map a new anonymous, non-accessible
225   // and non-reserved page over the mapping instead of actually unmapping.
226   const size_t size = pmem.size();
227   const void* const res = mmap((void*)addr, size, PROT_NONE, MAP_FIXED|MAP_ANONYMOUS|MAP_PRIVATE|MAP_NORESERVE, -1, 0);
228   if (res == MAP_FAILED) {
229     ZErrno err;
230     map_failed(err);
231   }
232 }
233 
234 uintptr_t ZPhysicalMemoryBacking::nmt_address(uintptr_t offset) const {
235   // From an NMT point of view we treat the first heap mapping (marked0) as committed
236   return ZAddress::marked0(offset);
237 }
238 
239 void ZPhysicalMemoryBacking::map(ZPhysicalMemory pmem, uintptr_t offset) const {
240   if (ZUnmapBadViews) {
241     // Only map the good view, for debugging only
242     map_view(pmem, ZAddress::good(offset), AlwaysPreTouch);
243   } else {
244     // Map all views
245     map_view(pmem, ZAddress::marked0(offset), AlwaysPreTouch);
246     map_view(pmem, ZAddress::marked1(offset), AlwaysPreTouch);
247     map_view(pmem, ZAddress::remapped(offset), AlwaysPreTouch);
248   }
249 }
250 
251 void ZPhysicalMemoryBacking::unmap(ZPhysicalMemory pmem, uintptr_t offset) const {
252   if (ZUnmapBadViews) {
253     // Only map the good view, for debugging only
254     unmap_view(pmem, ZAddress::good(offset));
255   } else {
256     // Unmap all views
257     unmap_view(pmem, ZAddress::marked0(offset));
258     unmap_view(pmem, ZAddress::marked1(offset));
259     unmap_view(pmem, ZAddress::remapped(offset));
260   }
261 }
262 
263 void ZPhysicalMemoryBacking::flip(ZPhysicalMemory pmem, uintptr_t offset) const {
264   assert(ZUnmapBadViews, &quot;Should be enabled&quot;);
265   const uintptr_t addr_good = ZAddress::good(offset);
266   const uintptr_t addr_bad = ZAddress::is_marked(ZAddressGoodMask) ? ZAddress::remapped(offset) : ZAddress::marked(offset);
267   // Map/Unmap views
268   map_view(pmem, addr_good, false /* pretouch */);
269   unmap_view(pmem, addr_bad);
270 }
    </pre>
  </body>
</html>