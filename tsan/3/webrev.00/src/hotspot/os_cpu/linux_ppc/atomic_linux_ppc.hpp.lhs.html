<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/os_cpu/linux_ppc/atomic_linux_ppc.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * Copyright (c) 2012, 2019 SAP SE. All rights reserved.
  4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5  *
  6  * This code is free software; you can redistribute it and/or modify it
  7  * under the terms of the GNU General Public License version 2 only, as
  8  * published by the Free Software Foundation.
  9  *
 10  * This code is distributed in the hope that it will be useful, but WITHOUT
 11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13  * version 2 for more details (a copy is included in the LICENSE file that
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
 23  *
 24  */
 25 
 26 #ifndef OS_CPU_LINUX_PPC_ATOMIC_LINUX_PPC_HPP
 27 #define OS_CPU_LINUX_PPC_ATOMIC_LINUX_PPC_HPP
 28 
 29 #ifndef PPC64
 30 #error &quot;Atomic currently only implemented for PPC64&quot;
 31 #endif
 32 
<a name="1" id="anc1"></a>
 33 #include &quot;utilities/debug.hpp&quot;
 34 
 35 // Implementation of class atomic
 36 
 37 //
 38 // machine barrier instructions:
 39 //
 40 // - sync            two-way memory barrier, aka fence
 41 // - lwsync          orders  Store|Store,
 42 //                            Load|Store,
 43 //                            Load|Load,
 44 //                   but not Store|Load
 45 // - eieio           orders memory accesses for device memory (only)
 46 // - isync           invalidates speculatively executed instructions
 47 //                   From the POWER ISA 2.06 documentation:
 48 //                    &quot;[...] an isync instruction prevents the execution of
 49 //                   instructions following the isync until instructions
 50 //                   preceding the isync have completed, [...]&quot;
 51 //                   From IBM&#39;s AIX assembler reference:
 52 //                    &quot;The isync [...] instructions causes the processor to
 53 //                   refetch any instructions that might have been fetched
 54 //                   prior to the isync instruction. The instruction isync
 55 //                   causes the processor to wait for all previous instructions
 56 //                   to complete. Then any instructions already fetched are
 57 //                   discarded and instruction processing continues in the
 58 //                   environment established by the previous instructions.&quot;
 59 //
 60 // semantic barrier instructions:
 61 // (as defined in orderAccess.hpp)
 62 //
 63 // - release         orders Store|Store,       (maps to lwsync)
 64 //                           Load|Store
 65 // - acquire         orders  Load|Store,       (maps to lwsync)
 66 //                           Load|Load
 67 // - fence           orders Store|Store,       (maps to sync)
 68 //                           Load|Store,
 69 //                           Load|Load,
 70 //                          Store|Load
 71 //
 72 
 73 inline void pre_membar(atomic_memory_order order) {
 74   switch (order) {
 75     case memory_order_relaxed:
 76     case memory_order_acquire: break;
 77     case memory_order_release:
 78     case memory_order_acq_rel: __asm__ __volatile__ (&quot;lwsync&quot; : : : &quot;memory&quot;); break;
 79     default /*conservative*/ : __asm__ __volatile__ (&quot;sync&quot;   : : : &quot;memory&quot;); break;
 80   }
 81 }
 82 
 83 inline void post_membar(atomic_memory_order order) {
 84   switch (order) {
 85     case memory_order_relaxed:
 86     case memory_order_release: break;
 87     case memory_order_acquire:
 88     case memory_order_acq_rel: __asm__ __volatile__ (&quot;isync&quot;  : : : &quot;memory&quot;); break;
 89     default /*conservative*/ : __asm__ __volatile__ (&quot;sync&quot;   : : : &quot;memory&quot;); break;
 90   }
 91 }
 92 
 93 
 94 template&lt;size_t byte_size&gt;
<a name="2" id="anc2"></a><span class="line-modified"> 95 struct Atomic::PlatformAdd</span>
<span class="line-modified"> 96   : Atomic::AddAndFetch&lt;Atomic::PlatformAdd&lt;byte_size&gt; &gt;</span>
<span class="line-modified"> 97 {</span>
<span class="line-modified"> 98   template&lt;typename I, typename D&gt;</span>
<span class="line-modified"> 99   D add_and_fetch(I add_value, D volatile* dest, atomic_memory_order order) const;</span>



100 };
101 
102 template&lt;&gt;
<a name="3" id="anc3"></a><span class="line-modified">103 template&lt;typename I, typename D&gt;</span>
<span class="line-modified">104 inline D Atomic::PlatformAdd&lt;4&gt;::add_and_fetch(I add_value, D volatile* dest,</span>
105                                                atomic_memory_order order) const {
106   STATIC_ASSERT(4 == sizeof(I));
107   STATIC_ASSERT(4 == sizeof(D));
108 
109   D result;
110 
111   pre_membar(order);
112 
113   __asm__ __volatile__ (
114     &quot;1: lwarx   %0,  0, %2    \n&quot;
115     &quot;   add     %0, %0, %1    \n&quot;
116     &quot;   stwcx.  %0,  0, %2    \n&quot;
117     &quot;   bne-    1b            \n&quot;
118     : /*%0*/&quot;=&amp;r&quot; (result)
119     : /*%1*/&quot;r&quot; (add_value), /*%2*/&quot;r&quot; (dest)
120     : &quot;cc&quot;, &quot;memory&quot; );
121 
122   post_membar(order);
123 
124   return result;
125 }
126 
127 
128 template&lt;&gt;
<a name="4" id="anc4"></a><span class="line-modified">129 template&lt;typename I, typename D&gt;</span>
<span class="line-modified">130 inline D Atomic::PlatformAdd&lt;8&gt;::add_and_fetch(I add_value, D volatile* dest,</span>
131                                                atomic_memory_order order) const {
132   STATIC_ASSERT(8 == sizeof(I));
133   STATIC_ASSERT(8 == sizeof(D));
134 
135   D result;
136 
137   pre_membar(order);
138 
139   __asm__ __volatile__ (
140     &quot;1: ldarx   %0,  0, %2    \n&quot;
141     &quot;   add     %0, %0, %1    \n&quot;
142     &quot;   stdcx.  %0,  0, %2    \n&quot;
143     &quot;   bne-    1b            \n&quot;
144     : /*%0*/&quot;=&amp;r&quot; (result)
145     : /*%1*/&quot;r&quot; (add_value), /*%2*/&quot;r&quot; (dest)
146     : &quot;cc&quot;, &quot;memory&quot; );
147 
148   post_membar(order);
149 
150   return result;
151 }
152 
153 template&lt;&gt;
154 template&lt;typename T&gt;
<a name="5" id="anc5"></a><span class="line-modified">155 inline T Atomic::PlatformXchg&lt;4&gt;::operator()(T exchange_value,</span>
<span class="line-modified">156                                              T volatile* dest,</span>
157                                              atomic_memory_order order) const {
158   // Note that xchg doesn&#39;t necessarily do an acquire
159   // (see synchronizer.cpp).
160 
161   T old_value;
162   const uint64_t zero = 0;
163 
164   pre_membar(order);
165 
166   __asm__ __volatile__ (
167     /* atomic loop */
168     &quot;1:                                                 \n&quot;
169     &quot;   lwarx   %[old_value], %[dest], %[zero]          \n&quot;
170     &quot;   stwcx.  %[exchange_value], %[dest], %[zero]     \n&quot;
171     &quot;   bne-    1b                                      \n&quot;
172     /* exit */
173     &quot;2:                                                 \n&quot;
174     /* out */
175     : [old_value]       &quot;=&amp;r&quot;   (old_value),
176                         &quot;=m&quot;    (*dest)
177     /* in */
178     : [dest]            &quot;b&quot;     (dest),
179       [zero]            &quot;r&quot;     (zero),
180       [exchange_value]  &quot;r&quot;     (exchange_value),
181                         &quot;m&quot;     (*dest)
182     /* clobber */
183     : &quot;cc&quot;,
184       &quot;memory&quot;
185     );
186 
187   post_membar(order);
188 
189   return old_value;
190 }
191 
192 template&lt;&gt;
193 template&lt;typename T&gt;
<a name="6" id="anc6"></a><span class="line-modified">194 inline T Atomic::PlatformXchg&lt;8&gt;::operator()(T exchange_value,</span>
<span class="line-modified">195                                              T volatile* dest,</span>
196                                              atomic_memory_order order) const {
197   STATIC_ASSERT(8 == sizeof(T));
198   // Note that xchg doesn&#39;t necessarily do an acquire
199   // (see synchronizer.cpp).
200 
201   T old_value;
202   const uint64_t zero = 0;
203 
204   pre_membar(order);
205 
206   __asm__ __volatile__ (
207     /* atomic loop */
208     &quot;1:                                                 \n&quot;
209     &quot;   ldarx   %[old_value], %[dest], %[zero]          \n&quot;
210     &quot;   stdcx.  %[exchange_value], %[dest], %[zero]     \n&quot;
211     &quot;   bne-    1b                                      \n&quot;
212     /* exit */
213     &quot;2:                                                 \n&quot;
214     /* out */
215     : [old_value]       &quot;=&amp;r&quot;   (old_value),
216                         &quot;=m&quot;    (*dest)
217     /* in */
218     : [dest]            &quot;b&quot;     (dest),
219       [zero]            &quot;r&quot;     (zero),
220       [exchange_value]  &quot;r&quot;     (exchange_value),
221                         &quot;m&quot;     (*dest)
222     /* clobber */
223     : &quot;cc&quot;,
224       &quot;memory&quot;
225     );
226 
227   post_membar(order);
228 
229   return old_value;
230 }
231 
232 template&lt;&gt;
233 template&lt;typename T&gt;
<a name="7" id="anc7"></a><span class="line-modified">234 inline T Atomic::PlatformCmpxchg&lt;1&gt;::operator()(T exchange_value,</span>
<span class="line-removed">235                                                 T volatile* dest,</span>
236                                                 T compare_value,
<a name="8" id="anc8"></a>
237                                                 atomic_memory_order order) const {
238   STATIC_ASSERT(1 == sizeof(T));
239 
240   // Note that cmpxchg guarantees a two-way memory barrier across
241   // the cmpxchg, so it&#39;s really a a &#39;fence_cmpxchg_fence&#39; if not
242   // specified otherwise (see atomic.hpp).
243 
244   // Using 32 bit internally.
245   volatile int *dest_base = (volatile int*)((uintptr_t)dest &amp; ~3);
246 
247 #ifdef VM_LITTLE_ENDIAN
248   const unsigned int shift_amount        = ((uintptr_t)dest &amp; 3) * 8;
249 #else
250   const unsigned int shift_amount        = ((~(uintptr_t)dest) &amp; 3) * 8;
251 #endif
252   const unsigned int masked_compare_val  = ((unsigned int)(unsigned char)compare_value),
253                      masked_exchange_val = ((unsigned int)(unsigned char)exchange_value),
254                      xor_value           = (masked_compare_val ^ masked_exchange_val) &lt;&lt; shift_amount;
255 
256   unsigned int old_value, value32;
257 
258   pre_membar(order);
259 
260   __asm__ __volatile__ (
261     /* simple guard */
262     &quot;   lbz     %[old_value], 0(%[dest])                  \n&quot;
263     &quot;   cmpw    %[masked_compare_val], %[old_value]       \n&quot;
264     &quot;   bne-    2f                                        \n&quot;
265     /* atomic loop */
266     &quot;1:                                                   \n&quot;
267     &quot;   lwarx   %[value32], 0, %[dest_base]               \n&quot;
268     /* extract byte and compare */
269     &quot;   srd     %[old_value], %[value32], %[shift_amount] \n&quot;
270     &quot;   clrldi  %[old_value], %[old_value], 56            \n&quot;
271     &quot;   cmpw    %[masked_compare_val], %[old_value]       \n&quot;
272     &quot;   bne-    2f                                        \n&quot;
273     /* replace byte and try to store */
274     &quot;   xor     %[value32], %[xor_value], %[value32]      \n&quot;
275     &quot;   stwcx.  %[value32], 0, %[dest_base]               \n&quot;
276     &quot;   bne-    1b                                        \n&quot;
277     /* exit */
278     &quot;2:                                                   \n&quot;
279     /* out */
280     : [old_value]           &quot;=&amp;r&quot;   (old_value),
281       [value32]             &quot;=&amp;r&quot;   (value32),
282                             &quot;=m&quot;    (*dest),
283                             &quot;=m&quot;    (*dest_base)
284     /* in */
285     : [dest]                &quot;b&quot;     (dest),
286       [dest_base]           &quot;b&quot;     (dest_base),
287       [shift_amount]        &quot;r&quot;     (shift_amount),
288       [masked_compare_val]  &quot;r&quot;     (masked_compare_val),
289       [xor_value]           &quot;r&quot;     (xor_value),
290                             &quot;m&quot;     (*dest),
291                             &quot;m&quot;     (*dest_base)
292     /* clobber */
293     : &quot;cc&quot;,
294       &quot;memory&quot;
295     );
296 
297   post_membar(order);
298 
299   return PrimitiveConversions::cast&lt;T&gt;((unsigned char)old_value);
300 }
301 
302 template&lt;&gt;
303 template&lt;typename T&gt;
<a name="9" id="anc9"></a><span class="line-modified">304 inline T Atomic::PlatformCmpxchg&lt;4&gt;::operator()(T exchange_value,</span>
<span class="line-removed">305                                                 T volatile* dest,</span>
306                                                 T compare_value,
<a name="10" id="anc10"></a>
307                                                 atomic_memory_order order) const {
308   STATIC_ASSERT(4 == sizeof(T));
309 
310   // Note that cmpxchg guarantees a two-way memory barrier across
311   // the cmpxchg, so it&#39;s really a a &#39;fence_cmpxchg_fence&#39; if not
312   // specified otherwise (see atomic.hpp).
313 
314   T old_value;
315   const uint64_t zero = 0;
316 
317   pre_membar(order);
318 
319   __asm__ __volatile__ (
320     /* simple guard */
321     &quot;   lwz     %[old_value], 0(%[dest])                \n&quot;
322     &quot;   cmpw    %[compare_value], %[old_value]          \n&quot;
323     &quot;   bne-    2f                                      \n&quot;
324     /* atomic loop */
325     &quot;1:                                                 \n&quot;
326     &quot;   lwarx   %[old_value], %[dest], %[zero]          \n&quot;
327     &quot;   cmpw    %[compare_value], %[old_value]          \n&quot;
328     &quot;   bne-    2f                                      \n&quot;
329     &quot;   stwcx.  %[exchange_value], %[dest], %[zero]     \n&quot;
330     &quot;   bne-    1b                                      \n&quot;
331     /* exit */
332     &quot;2:                                                 \n&quot;
333     /* out */
334     : [old_value]       &quot;=&amp;r&quot;   (old_value),
335                         &quot;=m&quot;    (*dest)
336     /* in */
337     : [dest]            &quot;b&quot;     (dest),
338       [zero]            &quot;r&quot;     (zero),
339       [compare_value]   &quot;r&quot;     (compare_value),
340       [exchange_value]  &quot;r&quot;     (exchange_value),
341                         &quot;m&quot;     (*dest)
342     /* clobber */
343     : &quot;cc&quot;,
344       &quot;memory&quot;
345     );
346 
347   post_membar(order);
348 
349   return old_value;
350 }
351 
352 template&lt;&gt;
353 template&lt;typename T&gt;
<a name="11" id="anc11"></a><span class="line-modified">354 inline T Atomic::PlatformCmpxchg&lt;8&gt;::operator()(T exchange_value,</span>
<span class="line-removed">355                                                 T volatile* dest,</span>
356                                                 T compare_value,
<a name="12" id="anc12"></a>
357                                                 atomic_memory_order order) const {
358   STATIC_ASSERT(8 == sizeof(T));
359 
360   // Note that cmpxchg guarantees a two-way memory barrier across
361   // the cmpxchg, so it&#39;s really a a &#39;fence_cmpxchg_fence&#39; if not
362   // specified otherwise (see atomic.hpp).
363 
364   T old_value;
365   const uint64_t zero = 0;
366 
367   pre_membar(order);
368 
369   __asm__ __volatile__ (
370     /* simple guard */
371     &quot;   ld      %[old_value], 0(%[dest])                \n&quot;
372     &quot;   cmpd    %[compare_value], %[old_value]          \n&quot;
373     &quot;   bne-    2f                                      \n&quot;
374     /* atomic loop */
375     &quot;1:                                                 \n&quot;
376     &quot;   ldarx   %[old_value], %[dest], %[zero]          \n&quot;
377     &quot;   cmpd    %[compare_value], %[old_value]          \n&quot;
378     &quot;   bne-    2f                                      \n&quot;
379     &quot;   stdcx.  %[exchange_value], %[dest], %[zero]     \n&quot;
380     &quot;   bne-    1b                                      \n&quot;
381     /* exit */
382     &quot;2:                                                 \n&quot;
383     /* out */
384     : [old_value]       &quot;=&amp;r&quot;   (old_value),
385                         &quot;=m&quot;    (*dest)
386     /* in */
387     : [dest]            &quot;b&quot;     (dest),
388       [zero]            &quot;r&quot;     (zero),
389       [compare_value]   &quot;r&quot;     (compare_value),
390       [exchange_value]  &quot;r&quot;     (exchange_value),
391                         &quot;m&quot;     (*dest)
392     /* clobber */
393     : &quot;cc&quot;,
394       &quot;memory&quot;
395     );
396 
397   post_membar(order);
398 
399   return old_value;
400 }
401 
<a name="13" id="anc13"></a>











402 #endif // OS_CPU_LINUX_PPC_ATOMIC_LINUX_PPC_HPP
<a name="14" id="anc14"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="14" type="hidden" />
</body>
</html>