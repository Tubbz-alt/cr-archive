<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff src/hotspot/share/utilities/concurrentHashTable.inline.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="concurrentHashTable.hpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="concurrentHashTableTasks.inline.hpp.udiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/utilities/concurrentHashTable.inline.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -51,64 +51,64 @@</span>
  static const void* POISON_PTR = (void*)0xffbadbac;
  #endif
  #endif
  
  // Node
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline typename ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::Node*</span>
<span class="udiff-line-modified-removed">- ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline typename ConcurrentHashTable&lt;CONFIG, F&gt;::Node*</span>
<span class="udiff-line-modified-added">+ ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    Node::next() const
  {
<span class="udiff-line-modified-removed">-   return OrderAccess::load_acquire(&amp;_next);</span>
<span class="udiff-line-modified-added">+   return Atomic::load_acquire(&amp;_next);</span>
  }
  
  // Bucket
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline typename ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::Node*</span>
<span class="udiff-line-modified-removed">- ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline typename ConcurrentHashTable&lt;CONFIG, F&gt;::Node*</span>
<span class="udiff-line-modified-added">+ ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    Bucket::first_raw() const
  {
<span class="udiff-line-modified-removed">-   return OrderAccess::load_acquire(&amp;_first);</span>
<span class="udiff-line-modified-added">+   return Atomic::load_acquire(&amp;_first);</span>
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    Bucket::release_assign_node_ptr(
<span class="udiff-line-modified-removed">-     typename ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::Node* const volatile * dst,</span>
<span class="udiff-line-modified-removed">-     typename ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::Node* node) const</span>
<span class="udiff-line-modified-added">+     typename ConcurrentHashTable&lt;CONFIG, F&gt;::Node* const volatile * dst,</span>
<span class="udiff-line-modified-added">+     typename ConcurrentHashTable&lt;CONFIG, F&gt;::Node* node) const</span>
  {
    // Due to this assert this methods is not static.
    assert(is_locked(), &quot;Must be locked.&quot;);
    Node** tmp = (Node**)dst;
<span class="udiff-line-modified-removed">-   OrderAccess::release_store(tmp, clear_set_state(node, *dst));</span>
<span class="udiff-line-modified-added">+   Atomic::release_store(tmp, clear_set_state(node, *dst));</span>
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline typename ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::Node*</span>
<span class="udiff-line-modified-removed">- ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline typename ConcurrentHashTable&lt;CONFIG, F&gt;::Node*</span>
<span class="udiff-line-modified-added">+ ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    Bucket::first() const
  {
    // We strip the states bit before returning the ptr.
<span class="udiff-line-modified-removed">-   return clear_state(OrderAccess::load_acquire(&amp;_first));</span>
<span class="udiff-line-modified-added">+   return clear_state(Atomic::load_acquire(&amp;_first));</span>
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    Bucket::have_redirect() const
  {
    return is_state(first_raw(), STATE_REDIRECT_BIT);
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    Bucket::is_locked() const
  {
    return is_state(first_raw(), STATE_LOCK_BIT);
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    Bucket::lock()
  {
    int i = 0;
    // SpinYield would be unfair here
    while (!this-&gt;trylock()) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -121,74 +121,74 @@</span>
        SpinPause();
      }
    }
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    Bucket::release_assign_last_node_next(
<span class="udiff-line-modified-removed">-      typename ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::Node* node)</span>
<span class="udiff-line-modified-added">+      typename ConcurrentHashTable&lt;CONFIG, F&gt;::Node* node)</span>
  {
    assert(is_locked(), &quot;Must be locked.&quot;);
    Node* const volatile * ret = first_ptr();
    while (clear_state(*ret) != NULL) {
      ret = clear_state(*ret)-&gt;next_ptr();
    }
    release_assign_node_ptr(ret, node);
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-removed">-   Bucket::cas_first(typename ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::Node* node,</span>
<span class="udiff-line-modified-removed">-                     typename ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::Node* expect</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+   Bucket::cas_first(typename ConcurrentHashTable&lt;CONFIG, F&gt;::Node* node,</span>
<span class="udiff-line-modified-added">+                     typename ConcurrentHashTable&lt;CONFIG, F&gt;::Node* expect</span>
                      )
  {
    if (is_locked()) {
      return false;
    }
<span class="udiff-line-modified-removed">-   if (Atomic::cmpxchg(node, &amp;_first, expect) == expect) {</span>
<span class="udiff-line-modified-added">+   if (Atomic::cmpxchg(&amp;_first, expect, node) == expect) {</span>
      return true;
    }
    return false;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    Bucket::trylock()
  {
    if (is_locked()) {
      return false;
    }
    // We will expect a clean first pointer.
    Node* tmp = first();
<span class="udiff-line-modified-removed">-   if (Atomic::cmpxchg(set_state(tmp, STATE_LOCK_BIT), &amp;_first, tmp) == tmp) {</span>
<span class="udiff-line-modified-added">+   if (Atomic::cmpxchg(&amp;_first, tmp, set_state(tmp, STATE_LOCK_BIT)) == tmp) {</span>
      return true;
    }
    return false;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    Bucket::unlock()
  {
    assert(is_locked(), &quot;Must be locked.&quot;);
    assert(!have_redirect(),
           &quot;Unlocking a bucket after it has reached terminal state.&quot;);
<span class="udiff-line-modified-removed">-   OrderAccess::release_store(&amp;_first, clear_state(first()));</span>
<span class="udiff-line-modified-added">+   Atomic::release_store(&amp;_first, clear_state(first()));</span>
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    Bucket::redirect()
  {
    assert(is_locked(), &quot;Must be locked.&quot;);
<span class="udiff-line-modified-removed">-   OrderAccess::release_store(&amp;_first, set_state(_first, STATE_REDIRECT_BIT));</span>
<span class="udiff-line-modified-added">+   Atomic::release_store(&amp;_first, set_state(_first, STATE_REDIRECT_BIT));</span>
  }
  
  // InternalTable
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    InternalTable::InternalTable(size_t log2_size)
      : _log2_size(log2_size), _size(((size_t)1ul) &lt;&lt; _log2_size),
        _hash_mask(~(~((size_t)0) &lt;&lt; _log2_size))
  {
    assert(_log2_size &gt;= SIZE_SMALL_LOG2 &amp;&amp; _log2_size &lt;= SIZE_BIG_LOG2,
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -199,65 +199,50 @@</span>
    for (size_t i = 0; i &lt; _size; ++i) {
      new (_buckets + i) Bucket();
    }
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    InternalTable::~InternalTable()
  {
    FREE_C_HEAP_ARRAY(Bucket, _buckets);
  }
  
  // ScopedCS
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-removed">-   ScopedCS::ScopedCS(Thread* thread, ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;* cht)</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+   ScopedCS::ScopedCS(Thread* thread, ConcurrentHashTable&lt;CONFIG, F&gt;* cht)</span>
      : _thread(thread),
        _cht(cht),
        _cs_context(GlobalCounter::critical_section_begin(_thread))
  {
    // This version is published now.
<span class="udiff-line-modified-removed">-   if (OrderAccess::load_acquire(&amp;_cht-&gt;_invisible_epoch) != NULL) {</span>
<span class="udiff-line-modified-removed">-     OrderAccess::release_store_fence(&amp;_cht-&gt;_invisible_epoch, (Thread*)NULL);</span>
<span class="udiff-line-modified-added">+   if (Atomic::load_acquire(&amp;_cht-&gt;_invisible_epoch) != NULL) {</span>
<span class="udiff-line-modified-added">+     Atomic::release_store_fence(&amp;_cht-&gt;_invisible_epoch, (Thread*)NULL);</span>
    }
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    ScopedCS::~ScopedCS()
  {
    GlobalCounter::critical_section_end(_thread, _cs_context);
  }
  
<span class="udiff-line-modified-removed">- // BaseConfig</span>
<span class="udiff-line-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-removed">- inline void* ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-removed">-   BaseConfig::allocate_node(size_t size, const VALUE&amp; value)</span>
<span class="udiff-line-removed">- {</span>
<span class="udiff-line-removed">-   return AllocateHeap(size, F);</span>
<span class="udiff-line-removed">- }</span>
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-removed">-   BaseConfig::free_node(void* memory, const VALUE&amp; value)</span>
<span class="udiff-line-removed">- {</span>
<span class="udiff-line-removed">-   FreeHeap(memory);</span>
<span class="udiff-line-removed">- }</span>
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename LOOKUP_FUNC&gt;
<span class="udiff-line-modified-removed">- inline VALUE* ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline typename CONFIG::Value* ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    MultiGetHandle::get(LOOKUP_FUNC&amp; lookup_f, bool* grow_hint)
  {
    return ScopedCS::_cht-&gt;internal_get(ScopedCS::_thread, lookup_f, grow_hint);
  }
  
  // HaveDeletables
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename EVALUATE_FUNC&gt;
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    HaveDeletables&lt;true, EVALUATE_FUNC&gt;::have_deletable(Bucket* bucket,
                                                        EVALUATE_FUNC&amp; eval_f,
                                                        Bucket* prefetch_bucket)
  {
    // Instantiated for pointer type (true), so we can use prefetch.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -279,13 +264,13 @@</span>
      }
    }
    return false;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;bool b, typename EVALUATE_FUNC&gt;
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    HaveDeletables&lt;b, EVALUATE_FUNC&gt;::have_deletable(Bucket* bucket,
                                                     EVALUATE_FUNC&amp; eval_f,
                                                     Bucket* preb)
  {
    for (Node* next = bucket-&gt;first(); next != NULL ; next = next-&gt;next()) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -295,29 +280,29 @@</span>
    }
    return false;
  }
  
  // ConcurrentHashTable
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    write_synchonize_on_visible_epoch(Thread* thread)
  {
    assert(_resize_lock_owner == thread, &quot;Re-size lock not held&quot;);
    OrderAccess::fence(); // Prevent below load from floating up.
    // If no reader saw this version we can skip write_synchronize.
<span class="udiff-line-modified-removed">-   if (OrderAccess::load_acquire(&amp;_invisible_epoch) == thread) {</span>
<span class="udiff-line-modified-added">+   if (Atomic::load_acquire(&amp;_invisible_epoch) == thread) {</span>
      return;
    }
    assert(_invisible_epoch == NULL, &quot;Two thread doing bulk operations&quot;);
    // We set this/next version that we are synchronizing for to not published.
    // A reader will zero this flag if it reads this/next version.
<span class="udiff-line-modified-removed">-   OrderAccess::release_store(&amp;_invisible_epoch, thread);</span>
<span class="udiff-line-modified-added">+   Atomic::release_store(&amp;_invisible_epoch, thread);</span>
    GlobalCounter::write_synchronize();
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    try_resize_lock(Thread* locker)
  {
    if (_resize_lock-&gt;try_lock()) {
      if (_resize_lock_owner != NULL) {
        assert(locker != _resize_lock_owner, &quot;Already own lock&quot;);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -331,12 +316,12 @@</span>
    _invisible_epoch = 0;
    _resize_lock_owner = locker;
    return true;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    lock_resize_lock(Thread* locker)
  {
    size_t i = 0;
    // If lock is hold by some other thread, the chances that it is return quick
    // is low. So we will prefer yielding.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -356,22 +341,22 @@</span>
    } while(true);
    _resize_lock_owner = locker;
    _invisible_epoch = 0;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    unlock_resize_lock(Thread* locker)
  {
    _invisible_epoch = 0;
    assert(locker == _resize_lock_owner, &quot;Not unlocked by locker.&quot;);
    _resize_lock_owner = NULL;
    _resize_lock-&gt;unlock();
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    free_nodes()
  {
    // We assume we are not MT during freeing.
    for (size_t node_it = 0; node_it &lt; _table-&gt;_size; node_it++) {
      Bucket* bucket = _table-&gt;get_buckets() + node_it;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -382,44 +367,44 @@</span>
        Node::destroy_node(free_node);
      }
    }
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline typename ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::InternalTable*</span>
<span class="udiff-line-modified-removed">- ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline typename ConcurrentHashTable&lt;CONFIG, F&gt;::InternalTable*</span>
<span class="udiff-line-modified-added">+ ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    get_table() const
  {
<span class="udiff-line-modified-removed">-   return OrderAccess::load_acquire(&amp;_table);</span>
<span class="udiff-line-modified-added">+   return Atomic::load_acquire(&amp;_table);</span>
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline typename ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::InternalTable*</span>
<span class="udiff-line-modified-removed">- ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline typename ConcurrentHashTable&lt;CONFIG, F&gt;::InternalTable*</span>
<span class="udiff-line-modified-added">+ ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    get_new_table() const
  {
<span class="udiff-line-modified-removed">-   return OrderAccess::load_acquire(&amp;_new_table);</span>
<span class="udiff-line-modified-added">+   return Atomic::load_acquire(&amp;_new_table);</span>
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline typename ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::InternalTable*</span>
<span class="udiff-line-modified-removed">- ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline typename ConcurrentHashTable&lt;CONFIG, F&gt;::InternalTable*</span>
<span class="udiff-line-modified-added">+ ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    set_table_from_new()
  {
    InternalTable* old_table = _table;
    // Publish the new table.
<span class="udiff-line-modified-removed">-   OrderAccess::release_store(&amp;_table, _new_table);</span>
<span class="udiff-line-modified-added">+   Atomic::release_store(&amp;_table, _new_table);</span>
    // All must see this.
    GlobalCounter::write_synchronize();
    // _new_table not read any more.
    _new_table = NULL;
    DEBUG_ONLY(_new_table = (InternalTable*)POISON_PTR;)
    return old_table;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    internal_grow_range(Thread* thread, size_t start, size_t stop)
  {
    assert(stop &lt;= _table-&gt;_size, &quot;Outside backing array&quot;);
    assert(_new_table != NULL, &quot;Grow not proper setup before start&quot;);
    // The state is also copied here. Hence all buckets in new table will be
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -454,13 +439,13 @@</span>
            _table-&gt;get_bucket(even_index)-&gt;first_ptr(), (Node*)POISON_PTR);
      )
    }
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename LOOKUP_FUNC, typename DELETE_FUNC&gt;
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    internal_remove(Thread* thread, LOOKUP_FUNC&amp; lookup_f, DELETE_FUNC&amp; delete_f)
  {
    Bucket* bucket = get_bucket_locked(thread, lookup_f.get_hash());
    assert(bucket-&gt;is_locked(), &quot;Must be locked.&quot;);
    Node* const volatile * rem_n_prev = bucket-&gt;first_ptr();
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -483,16 +468,17 @@</span>
    }
    // Publish the deletion.
    GlobalCounter::write_synchronize();
    delete_f(rem_n-&gt;value());
    Node::destroy_node(rem_n);
<span class="udiff-line-added">+   JFR_ONLY(_stats_rate.remove();)</span>
    return true;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename EVALUATE_FUNC, typename DELETE_FUNC&gt;
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    do_bulk_delete_locked_for(Thread* thread, size_t start_idx, size_t stop_idx,
                              EVALUATE_FUNC&amp; eval_f, DELETE_FUNC&amp; del_f, bool is_mt)
  {
    // Here we have resize lock so table is SMR safe, and there is no new
    // table. Can do this in parallel if we want.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -531,20 +517,21 @@</span>
        write_synchonize_on_visible_epoch(thread);
      }
      for (size_t node_it = 0; node_it &lt; nd; node_it++) {
        del_f(ndel[node_it]-&gt;value());
        Node::destroy_node(ndel[node_it]);
<span class="udiff-line-added">+       JFR_ONLY(_stats_rate.remove();)</span>
        DEBUG_ONLY(ndel[node_it] = (Node*)POISON_PTR;)
      }
      cs_context = GlobalCounter::critical_section_begin(thread);
    }
    GlobalCounter::critical_section_end(thread, cs_context);
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename LOOKUP_FUNC&gt;
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    delete_in_bucket(Thread* thread, Bucket* bucket, LOOKUP_FUNC&amp; lookup_f)
  {
    assert(bucket-&gt;is_locked(), &quot;Must be locked.&quot;);
  
    size_t dels = 0;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -569,18 +556,19 @@</span>
    }
    if (dels &gt; 0) {
      GlobalCounter::write_synchronize();
      for (size_t node_it = 0; node_it &lt; dels; node_it++) {
        Node::destroy_node(ndel[node_it]);
<span class="udiff-line-added">+       JFR_ONLY(_stats_rate.remove();)</span>
        DEBUG_ONLY(ndel[node_it] = (Node*)POISON_PTR;)
      }
    }
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline typename ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::Bucket*</span>
<span class="udiff-line-modified-removed">- ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline typename ConcurrentHashTable&lt;CONFIG, F&gt;::Bucket*</span>
<span class="udiff-line-modified-added">+ ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    get_bucket(uintx hash) const
  {
    InternalTable* table = get_table();
    Bucket* bucket = get_bucket_in(table, hash);
    if (bucket-&gt;have_redirect()) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -588,13 +576,13 @@</span>
      bucket = get_bucket_in(table, hash);
    }
    return bucket;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline typename ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::Bucket*</span>
<span class="udiff-line-modified-removed">- ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline typename ConcurrentHashTable&lt;CONFIG, F&gt;::Bucket*</span>
<span class="udiff-line-modified-added">+ ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    get_bucket_locked(Thread* thread, const uintx hash)
  {
    Bucket* bucket;
    int i = 0;
    // SpinYield would be unfair here
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -619,14 +607,14 @@</span>
    }
    return bucket;
  }
  
  // Always called within critical section
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename LOOKUP_FUNC&gt;
<span class="udiff-line-modified-removed">- typename ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::Node*</span>
<span class="udiff-line-modified-removed">- ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ typename ConcurrentHashTable&lt;CONFIG, F&gt;::Node*</span>
<span class="udiff-line-modified-added">+ ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    get_node(const Bucket* const bucket, LOOKUP_FUNC&amp; lookup_f,
             bool* have_dead, size_t* loops) const
  {
    size_t loop_count = 0;
    Node* node = bucket-&gt;first();
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -645,12 +633,12 @@</span>
      *loops = loop_count;
    }
    return node;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    unzip_bucket(Thread* thread, InternalTable* old_table,
                 InternalTable* new_table, size_t even_index, size_t odd_index)
  {
    Node* aux = old_table-&gt;get_bucket(even_index)-&gt;first();
    if (aux == NULL) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -703,12 +691,12 @@</span>
      }
    }
    return true;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    internal_shrink_prolog(Thread* thread, size_t log2_size)
  {
    if (!try_resize_lock(thread)) {
      return false;
    }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -720,12 +708,12 @@</span>
    }
    _new_table = new InternalTable(_table-&gt;_log2_size - 1);
    return true;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    internal_shrink_epilog(Thread* thread)
  {
    assert(_resize_lock_owner == thread, &quot;Re-size lock not held&quot;);
  
    InternalTable* old_table = set_table_from_new();
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -739,12 +727,12 @@</span>
  #endif
    // ABA safe, old_table not visible to any other threads.
    delete old_table;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    internal_shrink_range(Thread* thread, size_t start, size_t stop)
  {
    // The state is also copied here.
    // Hence all buckets in new table will be locked.
    for (size_t bucket_it = start; bucket_it &lt; stop; bucket_it++) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -776,12 +764,12 @@</span>
      DEBUG_ONLY(b_old_odd-&gt;release_assign_node_ptr(b_old_odd-&gt;first_ptr(),
                                                    (Node*)POISON_PTR);)
    }
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    internal_shrink(Thread* thread, size_t log2_size)
  {
    if (!internal_shrink_prolog(thread, log2_size)) {
      assert(_resize_lock_owner != thread, &quot;Re-size lock held&quot;);
      return false;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -791,12 +779,12 @@</span>
    internal_shrink_epilog(thread);
    assert(_resize_lock_owner != thread, &quot;Re-size lock held&quot;);
    return true;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    internal_grow_prolog(Thread* thread, size_t log2_size)
  {
    // This double checking of _size_limit_reached/is_max_size_reached()
    //  we only do in grow path, since grow means high load on table
    // while shrink means low load.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -820,12 +808,12 @@</span>
    }
  
    return true;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    internal_grow_epilog(Thread* thread)
  {
    assert(_resize_lock_owner == thread, &quot;Should be locked&quot;);
  
    InternalTable* old_table = set_table_from_new();
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -838,12 +826,12 @@</span>
  #endif
    // ABA safe, old_table not visible to any other threads.
    delete old_table;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    internal_grow(Thread* thread, size_t log2_size)
  {
    if (!internal_grow_prolog(thread, log2_size)) {
      assert(_resize_lock_owner != thread, &quot;Re-size lock held&quot;);
      return false;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -854,13 +842,13 @@</span>
    assert(_resize_lock_owner != thread, &quot;Re-size lock held&quot;);
    return true;
  }
  
  // Always called within critical section
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename LOOKUP_FUNC&gt;
<span class="udiff-line-modified-removed">- inline VALUE* ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline typename CONFIG::Value* ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    internal_get(Thread* thread, LOOKUP_FUNC&amp; lookup_f, bool* grow_hint)
  {
    bool clean = false;
    size_t loops = 0;
    VALUE* ret = NULL;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -875,13 +863,13 @@</span>
    }
  
    return ret;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename LOOKUP_FUNC&gt;
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    internal_insert(Thread* thread, LOOKUP_FUNC&amp; lookup_f, const VALUE&amp; value,
                    bool* grow_hint, bool* clean_hint)
  {
    bool ret = false;
    bool clean = false;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -898,10 +886,11 @@</span>
        Node* first_at_start = bucket-&gt;first();
        Node* old = get_node(bucket, lookup_f, &amp;clean, &amp;loops);
        if (old == NULL) {
          new_node-&gt;set_next(first_at_start);
          if (bucket-&gt;cas_first(new_node, first_at_start)) {
<span class="udiff-line-added">+           JFR_ONLY(_stats_rate.add();)</span>
            new_node = NULL;
            ret = true;
            break; /* leave critical section */
          }
          // CAS failed we must leave critical section and retry.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -939,13 +928,13 @@</span>
    }
  
    return ret;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename FUNC&gt;
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    visit_nodes(Bucket* bucket, FUNC&amp; visitor_f)
  {
    Node* current_node = bucket-&gt;first();
    while (current_node != NULL) {
      if (!visitor_f(current_node-&gt;value())) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -954,13 +943,13 @@</span>
      current_node = current_node-&gt;next();
    }
    return true;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename FUNC&gt;
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    do_scan_locked(Thread* thread, FUNC&amp; scan_f)
  {
    assert(_resize_lock_owner == thread, &quot;Re-size lock not held&quot;);
    // We can do a critical section over the entire loop but that would block
    // updates for a long time. Instead we choose to block resizes.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -971,13 +960,13 @@</span>
        break; /* ends critical section */
      }
    } /* ends critical section */
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename EVALUATE_FUNC&gt;
<span class="udiff-line-modified-removed">- inline size_t ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline size_t ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    delete_check_nodes(Bucket* bucket, EVALUATE_FUNC&amp; eval_f,
                       size_t num_del, Node** ndel)
  {
    size_t dels = 0;
    Node* const volatile * rem_n_prev = bucket-&gt;first_ptr();
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -998,63 +987,64 @@</span>
    }
    return dels;
  }
  
  // Constructor
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    ConcurrentHashTable(size_t log2size, size_t log2size_limit, size_t grow_hint)
      : _new_table(NULL), _log2_size_limit(log2size_limit),
         _log2_start_size(log2size), _grow_hint(grow_hint),
         _size_limit_reached(false), _resize_lock_owner(NULL),
         _invisible_epoch(0)
  {
<span class="udiff-line-added">+   _stats_rate = TableRateStatistics();</span>
    _resize_lock =
<span class="udiff-line-modified-removed">-     new Mutex(Mutex::leaf, &quot;ConcurrentHashTable&quot;, false,</span>
<span class="udiff-line-modified-removed">-               Monitor::_safepoint_check_never);</span>
<span class="udiff-line-modified-added">+     new Mutex(Mutex::leaf, &quot;ConcurrentHashTable&quot;, true,</span>
<span class="udiff-line-modified-added">+               Mutex::_safepoint_check_never);</span>
    _table = new InternalTable(log2size);
    assert(log2size_limit &gt;= log2size, &quot;bad ergo&quot;);
    _size_limit_reached = _table-&gt;_log2_size == _log2_size_limit;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    ~ConcurrentHashTable()
  {
    delete _resize_lock;
    free_nodes();
    delete _table;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline size_t ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline size_t ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    get_size_log2(Thread* thread)
  {
    ScopedCS cs(thread, this);
    return _table-&gt;_log2_size;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    shrink(Thread* thread, size_t size_limit_log2)
  {
    size_t tmp = size_limit_log2 == 0 ? _log2_start_size : size_limit_log2;
    bool ret = internal_shrink(thread, tmp);
    return ret;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    grow(Thread* thread, size_t size_limit_log2)
  {
    size_t tmp = size_limit_log2 == 0 ? _log2_size_limit : size_limit_log2;
    return internal_grow(thread, tmp);
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename LOOKUP_FUNC, typename FOUND_FUNC&gt;
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    get(Thread* thread, LOOKUP_FUNC&amp; lookup_f, FOUND_FUNC&amp; found_f, bool* grow_hint)
  {
    bool ret = false;
    ScopedCS cs(thread, this);
    VALUE* val = internal_get(thread, lookup_f, grow_hint);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1063,12 +1053,12 @@</span>
      ret = true;
    }
    return ret;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    unsafe_insert(const VALUE&amp; value) {
    bool dead_hash = false;
    size_t hash = CONFIG::get_hash(value, &amp;dead_hash);
    if (dead_hash) {
      return false;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1079,29 +1069,30 @@</span>
    assert(!bucket-&gt;have_redirect() &amp;&amp; !bucket-&gt;is_locked(), &quot;bad&quot;);
    Node* new_node = Node::create_node(value, bucket-&gt;first());
    if (!bucket-&gt;cas_first(new_node, bucket-&gt;first())) {
      assert(false, &quot;bad&quot;);
    }
<span class="udiff-line-added">+   JFR_ONLY(_stats_rate.add();)</span>
    return true;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename SCAN_FUNC&gt;
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    try_scan(Thread* thread, SCAN_FUNC&amp; scan_f)
  {
    if (!try_resize_lock(thread)) {
      return false;
    }
    do_scan_locked(thread, scan_f);
    unlock_resize_lock(thread);
    return true;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename SCAN_FUNC&gt;
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    do_scan(Thread* thread, SCAN_FUNC&amp; scan_f)
  {
    assert(!SafepointSynchronize::is_at_safepoint(),
           &quot;must be outside a safepoint&quot;);
    assert(_resize_lock_owner != thread, &quot;Re-size lock held&quot;);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1109,13 +1100,13 @@</span>
    do_scan_locked(thread, scan_f);
    unlock_resize_lock(thread);
    assert(_resize_lock_owner != thread, &quot;Re-size lock held&quot;);
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename SCAN_FUNC&gt;
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    do_safepoint_scan(SCAN_FUNC&amp; scan_f)
  {
    // We only allow this method to be used during a safepoint.
    assert(SafepointSynchronize::is_at_safepoint(),
           &quot;must only be called in a safepoint&quot;);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1152,13 +1143,13 @@</span>
        return;
      }
    }
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename EVALUATE_FUNC, typename DELETE_FUNC&gt;
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    try_bulk_delete(Thread* thread, EVALUATE_FUNC&amp; eval_f, DELETE_FUNC&amp; del_f)
  {
    if (!try_resize_lock(thread)) {
      return false;
    }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1166,88 +1157,84 @@</span>
    unlock_resize_lock(thread);
    assert(_resize_lock_owner != thread, &quot;Re-size lock held&quot;);
    return true;
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename EVALUATE_FUNC, typename DELETE_FUNC&gt;
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
    bulk_delete(Thread* thread, EVALUATE_FUNC&amp; eval_f, DELETE_FUNC&amp; del_f)
  {
    assert(!SafepointSynchronize::is_at_safepoint(),
           &quot;must be outside a safepoint&quot;);
    lock_resize_lock(thread);
    do_bulk_delete_locked(thread, eval_f, del_f);
    unlock_resize_lock(thread);
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
  template &lt;typename VALUE_SIZE_FUNC&gt;
<span class="udiff-line-modified-removed">- inline void ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-removed">-   statistics_to(Thread* thread, VALUE_SIZE_FUNC&amp; vs_f,</span>
<span class="udiff-line-removed">-                 outputStream* st, const char* table_name)</span>
<span class="udiff-line-modified-added">+ inline TableStatistics ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+   statistics_calculate(Thread* thread, VALUE_SIZE_FUNC&amp; vs_f)</span>
  {
    NumberSeq summary;
    size_t literal_bytes = 0;
<span class="udiff-line-removed">-   if (!try_resize_lock(thread)) {</span>
<span class="udiff-line-removed">-     st-&gt;print_cr(&quot;statistics unavailable at this moment&quot;);</span>
<span class="udiff-line-removed">-     return;</span>
<span class="udiff-line-removed">-   }</span>
<span class="udiff-line-removed">- </span>
    InternalTable* table = get_table();
    for (size_t bucket_it = 0; bucket_it &lt; table-&gt;_size; bucket_it++) {
      ScopedCS cs(thread, this);
      size_t count = 0;
      Bucket* bucket = table-&gt;get_bucket(bucket_it);
      if (bucket-&gt;have_redirect() || bucket-&gt;is_locked()) {
<span class="udiff-line-modified-removed">-         continue;</span>
<span class="udiff-line-modified-added">+       continue;</span>
      }
      Node* current_node = bucket-&gt;first();
      while (current_node != NULL) {
        ++count;
        literal_bytes += vs_f(current_node-&gt;value());
        current_node = current_node-&gt;next();
      }
      summary.add((double)count);
    }
  
<span class="udiff-line-modified-removed">-   double num_buckets = summary.num();</span>
<span class="udiff-line-modified-removed">-   double num_entries = summary.sum();</span>
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-removed">-   size_t bucket_bytes = num_buckets * sizeof(Bucket);</span>
<span class="udiff-line-modified-removed">-   size_t entry_bytes  = num_entries * sizeof(Node);</span>
<span class="udiff-line-modified-removed">-   size_t total_bytes = literal_bytes +  bucket_bytes + entry_bytes;</span>
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-removed">-   size_t bucket_size  = (num_buckets &lt;= 0) ? 0 : (bucket_bytes  / num_buckets);</span>
<span class="udiff-line-modified-removed">-   size_t entry_size   = (num_entries &lt;= 0) ? 0 : (entry_bytes   / num_entries);</span>
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-removed">-   st-&gt;print_cr(&quot;%s statistics:&quot;, table_name);</span>
<span class="udiff-line-modified-removed">-   st-&gt;print_cr(&quot;Number of buckets       : %9&quot; PRIuPTR &quot; = %9&quot; PRIuPTR</span>
<span class="udiff-line-modified-removed">-                &quot; bytes, each &quot; SIZE_FORMAT,</span>
<span class="udiff-line-modified-removed">-                (size_t)num_buckets, bucket_bytes,  bucket_size);</span>
<span class="udiff-line-modified-removed">-   st-&gt;print_cr(&quot;Number of entries       : %9&quot; PRIuPTR &quot; = %9&quot; PRIuPTR</span>
<span class="udiff-line-modified-removed">-                &quot; bytes, each &quot; SIZE_FORMAT,</span>
<span class="udiff-line-modified-removed">-                (size_t)num_entries, entry_bytes,   entry_size);</span>
<span class="udiff-line-modified-removed">-   if (literal_bytes != 0) {</span>
<span class="udiff-line-modified-removed">-     double literal_avg = (num_entries &lt;= 0) ? 0 : (literal_bytes / num_entries);</span>
<span class="udiff-line-modified-removed">-     st-&gt;print_cr(&quot;Number of literals      : %9&quot; PRIuPTR &quot; = %9&quot; PRIuPTR</span>
<span class="udiff-line-modified-removed">-                  &quot; bytes, avg %7.3f&quot;,</span>
<span class="udiff-line-modified-removed">-                  (size_t)num_entries, literal_bytes, literal_avg);</span>
<span class="udiff-line-modified-added">+   return TableStatistics(_stats_rate, summary, literal_bytes, sizeof(Bucket), sizeof(Node));</span>
<span class="udiff-line-modified-added">+ }</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename VALUE_SIZE_FUNC&gt;</span>
<span class="udiff-line-modified-added">+ inline TableStatistics ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+   statistics_get(Thread* thread, VALUE_SIZE_FUNC&amp; vs_f, TableStatistics old)</span>
<span class="udiff-line-modified-added">+ {</span>
<span class="udiff-line-modified-added">+   if (!try_resize_lock(thread)) {</span>
<span class="udiff-line-modified-added">+     return old;</span>
<span class="udiff-line-modified-added">+   }</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+   TableStatistics ts = statistics_calculate(thread, vs_f);</span>
<span class="udiff-line-modified-added">+   unlock_resize_lock(thread);</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+   return ts;</span>
<span class="udiff-line-modified-added">+ }</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ template &lt;typename VALUE_SIZE_FUNC&gt;</span>
<span class="udiff-line-modified-added">+ inline void ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+   statistics_to(Thread* thread, VALUE_SIZE_FUNC&amp; vs_f,</span>
<span class="udiff-line-added">+                 outputStream* st, const char* table_name)</span>
<span class="udiff-line-added">+ {</span>
<span class="udiff-line-added">+   if (!try_resize_lock(thread)) {</span>
<span class="udiff-line-added">+     st-&gt;print_cr(&quot;statistics unavailable at this moment&quot;);</span>
<span class="udiff-line-added">+     return;</span>
    }
<span class="udiff-line-modified-removed">-   st-&gt;print_cr(&quot;Total footprsize_t         : %9s = %9&quot; PRIuPTR &quot; bytes&quot;, &quot;&quot;</span>
<span class="udiff-line-modified-removed">-                , total_bytes);</span>
<span class="udiff-line-removed">-   st-&gt;print_cr(&quot;Average bucket size     : %9.3f&quot;, summary.avg());</span>
<span class="udiff-line-removed">-   st-&gt;print_cr(&quot;Variance of bucket size : %9.3f&quot;, summary.variance());</span>
<span class="udiff-line-removed">-   st-&gt;print_cr(&quot;Std. dev. of bucket size: %9.3f&quot;, summary.sd());</span>
<span class="udiff-line-removed">-   st-&gt;print_cr(&quot;Maximum bucket size     : %9&quot; PRIuPTR,</span>
<span class="udiff-line-removed">-                (size_t)summary.maximum());</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+   TableStatistics ts = statistics_calculate(thread, vs_f);</span>
    unlock_resize_lock(thread);
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   ts.print(st, table_name);</span>
  }
  
<span class="udiff-line-modified-removed">- template &lt;typename VALUE, typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-removed">- inline bool ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;::</span>
<span class="udiff-line-modified-removed">-   try_move_nodes_to(Thread* thread, ConcurrentHashTable&lt;VALUE, CONFIG, F&gt;* to_cht)</span>
<span class="udiff-line-modified-added">+ template &lt;typename CONFIG, MEMFLAGS F&gt;</span>
<span class="udiff-line-modified-added">+ inline bool ConcurrentHashTable&lt;CONFIG, F&gt;::</span>
<span class="udiff-line-modified-added">+   try_move_nodes_to(Thread* thread, ConcurrentHashTable&lt;CONFIG, F&gt;* to_cht)</span>
  {
    if (!try_resize_lock(thread)) {
      return false;
    }
    assert(_new_table == NULL || _new_table == POISON_PTR, &quot;Must be NULL&quot;);
</pre>
<center><a href="concurrentHashTable.hpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="concurrentHashTableTasks.inline.hpp.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>