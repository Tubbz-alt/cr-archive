diff a/src/hotspot/share/classfile/classLoaderData.cpp b/src/hotspot/share/classfile/classLoaderData.cpp
--- a/src/hotspot/share/classfile/classLoaderData.cpp
+++ b/src/hotspot/share/classfile/classLoaderData.cpp
@@ -1,7 +1,7 @@
  /*
- * Copyright (c) 2012, 2018, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2012, 2019, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -65,11 +65,10 @@
 #include "oops/oopHandle.inline.hpp"
 #include "oops/weakHandle.inline.hpp"
 #include "runtime/atomic.hpp"
 #include "runtime/handles.inline.hpp"
 #include "runtime/mutex.hpp"
-#include "runtime/orderAccess.hpp"
 #include "runtime/safepoint.hpp"
 #include "utilities/growableArray.hpp"
 #include "utilities/macros.hpp"
 #include "utilities/ostream.hpp"
 
@@ -106,12 +105,11 @@
   oop cl_name = java_lang_ClassLoader::name(class_loader());
   if (cl_name != NULL) {
     const char* cl_instance_name = java_lang_String::as_utf8_string(cl_name);
 
     if (cl_instance_name != NULL && cl_instance_name[0] != '\0') {
-      // Can't throw InternalError and SymbolTable doesn't throw OOM anymore.
-      _name = SymbolTable::new_symbol(cl_instance_name, CATCH);
+      _name = SymbolTable::new_symbol(cl_instance_name);
     }
   }
 
   // Obtain the class loader's name and identity hash.  If the class loader's
   // name was not explicitly set during construction, the class loader's name and id
@@ -123,18 +121,17 @@
   oop cl_name_and_id = java_lang_ClassLoader::nameAndId(class_loader());
   const char* cl_instance_name_and_id =
                   (cl_name_and_id == NULL) ? _class_loader_klass->external_name() :
                                              java_lang_String::as_utf8_string(cl_name_and_id);
   assert(cl_instance_name_and_id != NULL && cl_instance_name_and_id[0] != '\0', "class loader has no name and id");
-  // Can't throw InternalError and SymbolTable doesn't throw OOM anymore.
-  _name_and_id = SymbolTable::new_symbol(cl_instance_name_and_id, CATCH);
+  _name_and_id = SymbolTable::new_symbol(cl_instance_name_and_id);
 }
 
 ClassLoaderData::ClassLoaderData(Handle h_class_loader, bool is_unsafe_anonymous) :
   _metaspace(NULL),
-  _metaspace_lock(new Mutex(Monitor::leaf+1, "Metaspace allocation lock", true,
-                            Monitor::_safepoint_check_never)),
+  _metaspace_lock(new Mutex(Mutex::leaf+1, "Metaspace allocation lock", true,
+                            Mutex::_safepoint_check_never)),
   _unloading(false), _is_unsafe_anonymous(is_unsafe_anonymous),
   _modified_oops(true), _accumulated_modified_oops(false),
   // An unsafe anonymous class loader data doesn't have anything to keep
   // it from being unloaded during parsing of the unsafe anonymous class.
   // The null-class-loader should always be kept alive.
@@ -187,15 +184,15 @@
 }
 
 oop* ClassLoaderData::ChunkedHandleList::add(oop o) {
   if (_head == NULL || _head->_size == Chunk::CAPACITY) {
     Chunk* next = new Chunk(_head);
-    OrderAccess::release_store(&_head, next);
+    Atomic::release_store(&_head, next);
   }
   oop* handle = &_head->_data[_head->_size];
   NativeAccess<IS_DEST_UNINITIALIZED>::oop_store(handle, o);
-  OrderAccess::release_store(&_head->_size, _head->_size + 1);
+  Atomic::release_store(&_head->_size, _head->_size + 1);
   return handle;
 }
 
 int ClassLoaderData::ChunkedHandleList::count() const {
   int count = 0;
@@ -214,14 +211,14 @@
     }
   }
 }
 
 void ClassLoaderData::ChunkedHandleList::oops_do(OopClosure* f) {
-  Chunk* head = OrderAccess::load_acquire(&_head);
+  Chunk* head = Atomic::load_acquire(&_head);
   if (head != NULL) {
     // Must be careful when reading size of head
-    oops_do_chunk(f, head, OrderAccess::load_acquire(&head->_size));
+    oops_do_chunk(f, head, Atomic::load_acquire(&head->_size));
     for (Chunk* c = head->_next; c != NULL; c = c->_next) {
       oops_do_chunk(f, c, c->_size);
     }
   }
 }
@@ -232,11 +229,11 @@
 
  public:
   VerifyContainsOopClosure(oop target) : _target(target), _found(false) {}
 
   void do_oop(oop* p) {
-    if (p != NULL && oopDesc::equals(NativeAccess<AS_NO_KEEPALIVE>::oop_load(p), _target)) {
+    if (p != NULL && NativeAccess<AS_NO_KEEPALIVE>::oop_load(p) == _target) {
       _found = true;
     }
   }
 
   void do_oop(narrowOop* p) {
@@ -266,18 +263,31 @@
   }
   return false;
 }
 #endif // PRODUCT
 
+void ClassLoaderData::clear_claim(int claim) {
+  for (;;) {
+    int old_claim = Atomic::load(&_claim);
+    if ((old_claim & claim) == 0) {
+      return;
+    }
+    int new_claim = old_claim & ~claim;
+    if (Atomic::cmpxchg(&_claim, old_claim, new_claim) == old_claim) {
+      return;
+    }
+  }
+}
+
 bool ClassLoaderData::try_claim(int claim) {
   for (;;) {
     int old_claim = Atomic::load(&_claim);
     if ((old_claim & claim) == claim) {
       return false;
     }
     int new_claim = old_claim | claim;
-    if (Atomic::cmpxchg(new_claim, &_claim, old_claim) == old_claim) {
+    if (Atomic::cmpxchg(&_claim, old_claim, new_claim) == old_claim) {
       return true;
     }
   }
 }
 
@@ -286,11 +296,11 @@
 // Due to the uniqueness that no other class shares the unsafe anonymous class' name or
 // ClassLoaderData, no other non-GC thread has knowledge of the unsafe anonymous class while
 // it is being defined, therefore _keep_alive is not volatile or atomic.
 void ClassLoaderData::inc_keep_alive() {
   if (is_unsafe_anonymous()) {
-    assert(_keep_alive >= 0, "Invalid keep alive increment count");
+    assert(_keep_alive > 0, "Invalid keep alive increment count");
     _keep_alive++;
   }
 }
 
 void ClassLoaderData::dec_keep_alive() {
@@ -313,36 +323,36 @@
   _handles.oops_do(f);
 }
 
 void ClassLoaderData::classes_do(KlassClosure* klass_closure) {
   // Lock-free access requires load_acquire
-  for (Klass* k = OrderAccess::load_acquire(&_klasses); k != NULL; k = k->next_link()) {
+  for (Klass* k = Atomic::load_acquire(&_klasses); k != NULL; k = k->next_link()) {
     klass_closure->do_klass(k);
     assert(k != k->next_link(), "no loops!");
   }
 }
 
 void ClassLoaderData::classes_do(void f(Klass * const)) {
   // Lock-free access requires load_acquire
-  for (Klass* k = OrderAccess::load_acquire(&_klasses); k != NULL; k = k->next_link()) {
+  for (Klass* k = Atomic::load_acquire(&_klasses); k != NULL; k = k->next_link()) {
     f(k);
     assert(k != k->next_link(), "no loops!");
   }
 }
 
 void ClassLoaderData::methods_do(void f(Method*)) {
   // Lock-free access requires load_acquire
-  for (Klass* k = OrderAccess::load_acquire(&_klasses); k != NULL; k = k->next_link()) {
+  for (Klass* k = Atomic::load_acquire(&_klasses); k != NULL; k = k->next_link()) {
     if (k->is_instance_klass() && InstanceKlass::cast(k)->is_loaded()) {
       InstanceKlass::cast(k)->methods_do(f);
     }
   }
 }
 
 void ClassLoaderData::loaded_classes_do(KlassClosure* klass_closure) {
   // Lock-free access requires load_acquire
-  for (Klass* k = OrderAccess::load_acquire(&_klasses); k != NULL; k = k->next_link()) {
+  for (Klass* k = Atomic::load_acquire(&_klasses); k != NULL; k = k->next_link()) {
     // Do not filter ArrayKlass oops here...
     if (k->is_array_klass() || (k->is_instance_klass() && InstanceKlass::cast(k)->is_loaded())) {
 #ifdef ASSERT
       oop m = k->java_mirror();
       assert(m != NULL, "NULL mirror");
@@ -353,11 +363,11 @@
   }
 }
 
 void ClassLoaderData::classes_do(void f(InstanceKlass*)) {
   // Lock-free access requires load_acquire
-  for (Klass* k = OrderAccess::load_acquire(&_klasses); k != NULL; k = k->next_link()) {
+  for (Klass* k = Atomic::load_acquire(&_klasses); k != NULL; k = k->next_link()) {
     if (k->is_instance_klass()) {
       f(InstanceKlass::cast(k));
     }
     assert(k != k->next_link(), "no loops!");
   }
@@ -420,11 +430,11 @@
     to = to_cld->class_loader();
     oop from = from_cld->class_loader();
 
     // Just return if this dependency is to a class with the same or a parent
     // class_loader.
-    if (oopDesc::equals(from, to) || java_lang_ClassLoader::isAncestor(from, to)) {
+    if (from == to || java_lang_ClassLoader::isAncestor(from, to)) {
       return; // this class loader is in the parent list, no need to add it.
     }
   }
 
   // It's a dependency we won't find through GC, add it.
@@ -447,16 +457,16 @@
   }
 }
 
 void ClassLoaderData::add_class(Klass* k, bool publicize /* true */) {
   {
-    MutexLockerEx ml(metaspace_lock(), Mutex::_no_safepoint_check_flag);
+    MutexLocker ml(metaspace_lock(), Mutex::_no_safepoint_check_flag);
     Klass* old_value = _klasses;
     k->set_next_link(old_value);
     // Link the new item into the list, making sure the linked class is stable
     // since the list can be walked without a lock
-    OrderAccess::release_store(&_klasses, k);
+    Atomic::release_store(&_klasses, k);
     if (k->is_array_klass()) {
       ClassLoaderDataGraph::inc_array_classes(1);
     } else {
       ClassLoaderDataGraph::inc_instance_classes(1);
     }
@@ -539,21 +549,21 @@
 }
 
 ModuleEntryTable* ClassLoaderData::modules() {
   // Lazily create the module entry table at first request.
   // Lock-free access requires load_acquire.
-  ModuleEntryTable* modules = OrderAccess::load_acquire(&_modules);
+  ModuleEntryTable* modules = Atomic::load_acquire(&_modules);
   if (modules == NULL) {
     MutexLocker m1(Module_lock);
     // Check if _modules got allocated while we were waiting for this lock.
     if ((modules = _modules) == NULL) {
       modules = new ModuleEntryTable(ModuleEntryTable::_moduletable_entry_size);
 
       {
-        MutexLockerEx m1(metaspace_lock(), Mutex::_no_safepoint_check_flag);
+        MutexLocker m1(metaspace_lock(), Mutex::_no_safepoint_check_flag);
         // Ensure _modules is stable, since it is examined without a lock
-        OrderAccess::release_store(&_modules, modules);
+        Atomic::release_store(&_modules, modules);
       }
     }
   }
   return modules;
 }
@@ -739,13 +749,13 @@
   // If the metaspace has not been allocated, create a new one.  Might want
   // to create smaller arena for Reflection class loaders also.
   // The reason for the delayed allocation is because some class loaders are
   // simply for delegating with no metadata of their own.
   // Lock-free access requires load_acquire.
-  ClassLoaderMetaspace* metaspace = OrderAccess::load_acquire(&_metaspace);
+  ClassLoaderMetaspace* metaspace = Atomic::load_acquire(&_metaspace);
   if (metaspace == NULL) {
-    MutexLockerEx ml(_metaspace_lock,  Mutex::_no_safepoint_check_flag);
+    MutexLocker ml(_metaspace_lock,  Mutex::_no_safepoint_check_flag);
     // Check if _metaspace got allocated while we were waiting for this lock.
     if ((metaspace = _metaspace) == NULL) {
       if (this == the_null_class_loader_data()) {
         assert (class_loader() == NULL, "Must be");
         metaspace = new ClassLoaderMetaspace(_metaspace_lock, Metaspace::BootMetaspaceType);
@@ -755,18 +765,18 @@
         metaspace = new ClassLoaderMetaspace(_metaspace_lock, Metaspace::ReflectionMetaspaceType);
       } else {
         metaspace = new ClassLoaderMetaspace(_metaspace_lock, Metaspace::StandardMetaspaceType);
       }
       // Ensure _metaspace is stable, since it is examined without a lock
-      OrderAccess::release_store(&_metaspace, metaspace);
+      Atomic::release_store(&_metaspace, metaspace);
     }
   }
   return metaspace;
 }
 
 OopHandle ClassLoaderData::add_handle(Handle h) {
-  MutexLockerEx ml(metaspace_lock(),  Mutex::_no_safepoint_check_flag);
+  MutexLocker ml(metaspace_lock(),  Mutex::_no_safepoint_check_flag);
   record_modified_oops();
   return OopHandle(_handles.add(h()));
 }
 
 void ClassLoaderData::remove_handle(OopHandle h) {
@@ -777,11 +787,11 @@
     NativeAccess<>::oop_store(ptr, oop(NULL));
   }
 }
 
 void ClassLoaderData::init_handle_locked(OopHandle& dest, Handle h) {
-  MutexLockerEx ml(metaspace_lock(),  Mutex::_no_safepoint_check_flag);
+  MutexLocker ml(metaspace_lock(),  Mutex::_no_safepoint_check_flag);
   if (dest.resolve() != NULL) {
     return;
   } else {
     dest = _handles.add(h());
   }
@@ -790,11 +800,11 @@
 // Add this metadata pointer to be freed when it's safe.  This is only during
 // a safepoint which checks if handles point to this metadata field.
 void ClassLoaderData::add_to_deallocate_list(Metadata* m) {
   // Metadata in shared region isn't deleted.
   if (!m->is_shared()) {
-    MutexLockerEx ml(metaspace_lock(),  Mutex::_no_safepoint_check_flag);
+    MutexLocker ml(metaspace_lock(),  Mutex::_no_safepoint_check_flag);
     if (_deallocate_list == NULL) {
       _deallocate_list = new (ResourceObj::C_HEAP, mtClass) GrowableArray<Metadata*>(100, true);
     }
     _deallocate_list->append_if_missing(m);
     log_debug(class, loader, data)("deallocate added for %s", m->print_value_string());
@@ -913,10 +923,12 @@
   if (is_unsafe_anonymous()) {
     out->print(" unsafe anonymous");
   }
 }
 
+void ClassLoaderData::print_value() const { print_value_on(tty); }
+
 #ifndef PRODUCT
 void ClassLoaderData::print_on(outputStream* out) const {
   out->print("ClassLoaderData CLD: " PTR_FORMAT ", loader: " PTR_FORMAT ", loader_klass: %s {",
               p2i(this), p2i(_class_loader.ptr_raw()), loader_name_and_id());
   if (is_unsafe_anonymous()) out->print(" unsafe anonymous");
@@ -931,10 +943,12 @@
   out->print(" dependencies %d", _dependency_count);
   out->print_cr("}");
 }
 #endif // PRODUCT
 
+void ClassLoaderData::print() const { print_on(tty); }
+
 void ClassLoaderData::verify() {
   assert_locked_or_safepoint(_metaspace_lock);
   oop cl = class_loader();
 
   guarantee(this == class_loader_data(cl) || is_unsafe_anonymous(), "Must be the same");
@@ -952,10 +966,10 @@
   }
 }
 
 bool ClassLoaderData::contains_klass(Klass* klass) {
   // Lock-free access requires load_acquire
-  for (Klass* k = OrderAccess::load_acquire(&_klasses); k != NULL; k = k->next_link()) {
+  for (Klass* k = Atomic::load_acquire(&_klasses); k != NULL; k = k->next_link()) {
     if (k == klass) return true;
   }
   return false;
 }
