<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/interpreter/bytecodeInterpreter.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="bytecode.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="bytecodeStream.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/interpreter/bytecodeInterpreter.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2002, 2018, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 // no precompiled headers
  26 #include &quot;classfile/vmSymbols.hpp&quot;
  27 #include &quot;gc/shared/collectedHeap.hpp&quot;
  28 #include &quot;gc/shared/threadLocalAllocBuffer.inline.hpp&quot;
  29 #include &quot;interpreter/bytecodeHistogram.hpp&quot;
  30 #include &quot;interpreter/bytecodeInterpreter.hpp&quot;
  31 #include &quot;interpreter/bytecodeInterpreter.inline.hpp&quot;
  32 #include &quot;interpreter/bytecodeInterpreterProfiling.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  35 #include &quot;logging/log.hpp&quot;
  36 #include &quot;memory/resourceArea.hpp&quot;

  37 #include &quot;oops/constantPool.inline.hpp&quot;
  38 #include &quot;oops/cpCache.inline.hpp&quot;
  39 #include &quot;oops/method.inline.hpp&quot;
  40 #include &quot;oops/methodCounters.hpp&quot;
  41 #include &quot;oops/objArrayKlass.hpp&quot;
  42 #include &quot;oops/objArrayOop.inline.hpp&quot;
  43 #include &quot;oops/oop.inline.hpp&quot;
  44 #include &quot;oops/typeArrayOop.inline.hpp&quot;
  45 #include &quot;prims/jvmtiExport.hpp&quot;
  46 #include &quot;prims/jvmtiThreadState.hpp&quot;
  47 #include &quot;runtime/atomic.hpp&quot;
  48 #include &quot;runtime/biasedLocking.hpp&quot;
  49 #include &quot;runtime/frame.inline.hpp&quot;
  50 #include &quot;runtime/handles.inline.hpp&quot;
  51 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  52 #include &quot;runtime/orderAccess.hpp&quot;
  53 #include &quot;runtime/sharedRuntime.hpp&quot;
  54 #include &quot;runtime/threadCritical.hpp&quot;
  55 #include &quot;utilities/exceptions.hpp&quot;
  56 
</pre>
<hr />
<pre>
 648       if ((istate-&gt;_stack_base - istate-&gt;_stack_limit) != istate-&gt;method()-&gt;max_stack() + 1) {
 649         // initialize
 650         os::breakpoint();
 651       }
 652 
 653       // Lock method if synchronized.
 654       if (METHOD-&gt;is_synchronized()) {
 655         // oop rcvr = locals[0].j.r;
 656         oop rcvr;
 657         if (METHOD-&gt;is_static()) {
 658           rcvr = METHOD-&gt;constants()-&gt;pool_holder()-&gt;java_mirror();
 659         } else {
 660           rcvr = LOCALS_OBJECT(0);
 661           VERIFY_OOP(rcvr);
 662         }
 663         // The initial monitor is ours for the taking.
 664         // Monitor not filled in frame manager any longer as this caused race condition with biased locking.
 665         BasicObjectLock* mon = &amp;istate-&gt;monitor_base()[-1];
 666         mon-&gt;set_obj(rcvr);
 667         bool success = false;
<span class="line-modified"> 668         uintptr_t epoch_mask_in_place = (uintptr_t)markOopDesc::epoch_mask_in_place;</span>
<span class="line-modified"> 669         markOop mark = rcvr-&gt;mark();</span>
<span class="line-modified"> 670         intptr_t hash = (intptr_t) markOopDesc::no_hash;</span>
 671         // Implies UseBiasedLocking.
<span class="line-modified"> 672         if (mark-&gt;has_bias_pattern()) {</span>
 673           uintptr_t thread_ident;
 674           uintptr_t anticipated_bias_locking_value;
 675           thread_ident = (uintptr_t)istate-&gt;thread();
 676           anticipated_bias_locking_value =
<span class="line-modified"> 677             (((uintptr_t)rcvr-&gt;klass()-&gt;prototype_header() | thread_ident) ^ (uintptr_t)mark) &amp;</span>
<span class="line-modified"> 678             ~((uintptr_t) markOopDesc::age_mask_in_place);</span>
 679 
 680           if (anticipated_bias_locking_value == 0) {
 681             // Already biased towards this thread, nothing to do.
 682             if (PrintBiasedLockingStatistics) {
 683               (* BiasedLocking::biased_lock_entry_count_addr())++;
 684             }
 685             success = true;
<span class="line-modified"> 686           } else if ((anticipated_bias_locking_value &amp; markOopDesc::biased_lock_mask_in_place) != 0) {</span>
 687             // Try to revoke bias.
<span class="line-modified"> 688             markOop header = rcvr-&gt;klass()-&gt;prototype_header();</span>
<span class="line-modified"> 689             if (hash != markOopDesc::no_hash) {</span>
<span class="line-modified"> 690               header = header-&gt;copy_set_hash(hash);</span>
 691             }
 692             if (rcvr-&gt;cas_set_mark(header, mark) == mark) {
 693               if (PrintBiasedLockingStatistics)
 694                 (*BiasedLocking::revoked_lock_entry_count_addr())++;
 695             }
 696           } else if ((anticipated_bias_locking_value &amp; epoch_mask_in_place) != 0) {
 697             // Try to rebias.
<span class="line-modified"> 698             markOop new_header = (markOop) ( (intptr_t) rcvr-&gt;klass()-&gt;prototype_header() | thread_ident);</span>
<span class="line-modified"> 699             if (hash != markOopDesc::no_hash) {</span>
<span class="line-modified"> 700               new_header = new_header-&gt;copy_set_hash(hash);</span>
 701             }
 702             if (rcvr-&gt;cas_set_mark(new_header, mark) == mark) {
 703               if (PrintBiasedLockingStatistics) {
 704                 (* BiasedLocking::rebiased_lock_entry_count_addr())++;
 705               }
 706             } else {
 707               CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);
 708             }
 709             success = true;
 710           } else {
 711             // Try to bias towards thread in case object is anonymously biased.
<span class="line-modified"> 712             markOop header = (markOop) ((uintptr_t) mark &amp;</span>
<span class="line-modified"> 713                                         ((uintptr_t)markOopDesc::biased_lock_mask_in_place |</span>
<span class="line-modified"> 714                                          (uintptr_t)markOopDesc::age_mask_in_place | epoch_mask_in_place));</span>
<span class="line-modified"> 715             if (hash != markOopDesc::no_hash) {</span>
<span class="line-modified"> 716               header = header-&gt;copy_set_hash(hash);</span>
 717             }
<span class="line-modified"> 718             markOop new_header = (markOop) ((uintptr_t) header | thread_ident);</span>
 719             // Debugging hint.
<span class="line-modified"> 720             DEBUG_ONLY(mon-&gt;lock()-&gt;set_displaced_header((markOop) (uintptr_t) 0xdeaddead);)</span>
 721             if (rcvr-&gt;cas_set_mark(new_header, header) == header) {
 722               if (PrintBiasedLockingStatistics) {
 723                 (* BiasedLocking::anonymously_biased_lock_entry_count_addr())++;
 724               }
 725             } else {
 726               CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);
 727             }
 728             success = true;
 729           }
 730         }
 731 
 732         // Traditional lightweight locking.
 733         if (!success) {
<span class="line-modified"> 734           markOop displaced = rcvr-&gt;mark()-&gt;set_unlocked();</span>
 735           mon-&gt;lock()-&gt;set_displaced_header(displaced);
 736           bool call_vm = UseHeavyMonitors;
<span class="line-modified"> 737           if (call_vm || rcvr-&gt;cas_set_mark((markOop)mon, displaced) != displaced) {</span>
 738             // Is it simple recursive case?
<span class="line-modified"> 739             if (!call_vm &amp;&amp; THREAD-&gt;is_lock_owned((address) displaced-&gt;clear_lock_bits())) {</span>
<span class="line-modified"> 740               mon-&gt;lock()-&gt;set_displaced_header(NULL);</span>
 741             } else {
 742               CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);
 743             }
 744           }
 745         }
 746       }
 747       THREAD-&gt;clr_do_not_unlock();
 748 
 749       // Notify jvmti
 750 #ifdef VM_JVMTI
 751       if (_jvmti_interp_events) {
 752         // Whenever JVMTI puts a thread in interp_only_mode, method
 753         // entry/exit events are sent for that thread to track stack depth.
 754         if (THREAD-&gt;is_interp_only_mode()) {
 755           CALL_VM(InterpreterRuntime::post_method_entry(THREAD),
 756                   handle_exception);
 757         }
 758       }
 759 #endif /* VM_JVMTI */
 760 
</pre>
<hr />
<pre>
 833       UPDATE_PC(Bytecodes::length_at(METHOD, pc));
 834       if (THREAD-&gt;has_pending_exception()) goto handle_exception;
 835 
 836       if (_compiling) {
 837         // Get or create profile data. Check for pending (async) exceptions.
 838         BI_PROFILE_GET_OR_CREATE_METHOD_DATA(handle_exception);
 839       }
 840       goto run;
 841     }
 842     case got_monitors: {
 843       // continue locking now that we have a monitor to use
 844       // we expect to find newly allocated monitor at the &quot;top&quot; of the monitor stack.
 845       oop lockee = STACK_OBJECT(-1);
 846       VERIFY_OOP(lockee);
 847       // derefing&#39;s lockee ought to provoke implicit null check
 848       // find a free monitor
 849       BasicObjectLock* entry = (BasicObjectLock*) istate-&gt;stack_base();
 850       assert(entry-&gt;obj() == NULL, &quot;Frame manager didn&#39;t allocate the monitor&quot;);
 851       entry-&gt;set_obj(lockee);
 852       bool success = false;
<span class="line-modified"> 853       uintptr_t epoch_mask_in_place = (uintptr_t)markOopDesc::epoch_mask_in_place;</span>
 854 
<span class="line-modified"> 855       markOop mark = lockee-&gt;mark();</span>
<span class="line-modified"> 856       intptr_t hash = (intptr_t) markOopDesc::no_hash;</span>
 857       // implies UseBiasedLocking
<span class="line-modified"> 858       if (mark-&gt;has_bias_pattern()) {</span>
 859         uintptr_t thread_ident;
 860         uintptr_t anticipated_bias_locking_value;
 861         thread_ident = (uintptr_t)istate-&gt;thread();
 862         anticipated_bias_locking_value =
<span class="line-modified"> 863           (((uintptr_t)lockee-&gt;klass()-&gt;prototype_header() | thread_ident) ^ (uintptr_t)mark) &amp;</span>
<span class="line-modified"> 864           ~((uintptr_t) markOopDesc::age_mask_in_place);</span>
 865 
 866         if  (anticipated_bias_locking_value == 0) {
 867           // already biased towards this thread, nothing to do
 868           if (PrintBiasedLockingStatistics) {
 869             (* BiasedLocking::biased_lock_entry_count_addr())++;
 870           }
 871           success = true;
<span class="line-modified"> 872         } else if ((anticipated_bias_locking_value &amp; markOopDesc::biased_lock_mask_in_place) != 0) {</span>
 873           // try revoke bias
<span class="line-modified"> 874           markOop header = lockee-&gt;klass()-&gt;prototype_header();</span>
<span class="line-modified"> 875           if (hash != markOopDesc::no_hash) {</span>
<span class="line-modified"> 876             header = header-&gt;copy_set_hash(hash);</span>
 877           }
 878           if (lockee-&gt;cas_set_mark(header, mark) == mark) {
 879             if (PrintBiasedLockingStatistics) {
 880               (*BiasedLocking::revoked_lock_entry_count_addr())++;
 881             }
 882           }
 883         } else if ((anticipated_bias_locking_value &amp; epoch_mask_in_place) !=0) {
 884           // try rebias
<span class="line-modified"> 885           markOop new_header = (markOop) ( (intptr_t) lockee-&gt;klass()-&gt;prototype_header() | thread_ident);</span>
<span class="line-modified"> 886           if (hash != markOopDesc::no_hash) {</span>
<span class="line-modified"> 887                 new_header = new_header-&gt;copy_set_hash(hash);</span>
 888           }
 889           if (lockee-&gt;cas_set_mark(new_header, mark) == mark) {
 890             if (PrintBiasedLockingStatistics) {
 891               (* BiasedLocking::rebiased_lock_entry_count_addr())++;
 892             }
 893           } else {
 894             CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
 895           }
 896           success = true;
 897         } else {
 898           // try to bias towards thread in case object is anonymously biased
<span class="line-modified"> 899           markOop header = (markOop) ((uintptr_t) mark &amp; ((uintptr_t)markOopDesc::biased_lock_mask_in_place |</span>
<span class="line-modified"> 900                                                           (uintptr_t)markOopDesc::age_mask_in_place | epoch_mask_in_place));</span>
<span class="line-modified"> 901           if (hash != markOopDesc::no_hash) {</span>
<span class="line-modified"> 902             header = header-&gt;copy_set_hash(hash);</span>
 903           }
<span class="line-modified"> 904           markOop new_header = (markOop) ((uintptr_t) header | thread_ident);</span>
 905           // debugging hint
<span class="line-modified"> 906           DEBUG_ONLY(entry-&gt;lock()-&gt;set_displaced_header((markOop) (uintptr_t) 0xdeaddead);)</span>
 907           if (lockee-&gt;cas_set_mark(new_header, header) == header) {
 908             if (PrintBiasedLockingStatistics) {
 909               (* BiasedLocking::anonymously_biased_lock_entry_count_addr())++;
 910             }
 911           } else {
 912             CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
 913           }
 914           success = true;
 915         }
 916       }
 917 
 918       // traditional lightweight locking
 919       if (!success) {
<span class="line-modified"> 920         markOop displaced = lockee-&gt;mark()-&gt;set_unlocked();</span>
 921         entry-&gt;lock()-&gt;set_displaced_header(displaced);
 922         bool call_vm = UseHeavyMonitors;
<span class="line-modified"> 923         if (call_vm || lockee-&gt;cas_set_mark((markOop)entry, displaced) != displaced) {</span>
 924           // Is it simple recursive case?
<span class="line-modified"> 925           if (!call_vm &amp;&amp; THREAD-&gt;is_lock_owned((address) displaced-&gt;clear_lock_bits())) {</span>
<span class="line-modified"> 926             entry-&gt;lock()-&gt;set_displaced_header(NULL);</span>
 927           } else {
 928             CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
 929           }
 930         }
 931       }
 932       UPDATE_PC_AND_TOS(1, -1);
 933       goto run;
 934     }
 935     default: {
 936       fatal(&quot;Unexpected message from frame manager&quot;);
 937     }
 938   }
 939 
 940 run:
 941 
 942   DO_UPDATE_INSTRUCTION_COUNT(*pc)
 943   DEBUGGER_SINGLE_STEP_NOTIFY();
 944 #ifdef PREFETCH_OPCCODE
 945   opcode = *pc;  /* prefetch first opcode */
 946 #endif
</pre>
<hr />
<pre>
1773       /* monitorenter and monitorexit for locking/unlocking an object */
1774 
1775       CASE(_monitorenter): {
1776         oop lockee = STACK_OBJECT(-1);
1777         // derefing&#39;s lockee ought to provoke implicit null check
1778         CHECK_NULL(lockee);
1779         // find a free monitor or one already allocated for this object
1780         // if we find a matching object then we need a new monitor
1781         // since this is recursive enter
1782         BasicObjectLock* limit = istate-&gt;monitor_base();
1783         BasicObjectLock* most_recent = (BasicObjectLock*) istate-&gt;stack_base();
1784         BasicObjectLock* entry = NULL;
1785         while (most_recent != limit ) {
1786           if (most_recent-&gt;obj() == NULL) entry = most_recent;
1787           else if (most_recent-&gt;obj() == lockee) break;
1788           most_recent++;
1789         }
1790         if (entry != NULL) {
1791           entry-&gt;set_obj(lockee);
1792           int success = false;
<span class="line-modified">1793           uintptr_t epoch_mask_in_place = (uintptr_t)markOopDesc::epoch_mask_in_place;</span>
1794 
<span class="line-modified">1795           markOop mark = lockee-&gt;mark();</span>
<span class="line-modified">1796           intptr_t hash = (intptr_t) markOopDesc::no_hash;</span>
1797           // implies UseBiasedLocking
<span class="line-modified">1798           if (mark-&gt;has_bias_pattern()) {</span>
1799             uintptr_t thread_ident;
1800             uintptr_t anticipated_bias_locking_value;
1801             thread_ident = (uintptr_t)istate-&gt;thread();
1802             anticipated_bias_locking_value =
<span class="line-modified">1803               (((uintptr_t)lockee-&gt;klass()-&gt;prototype_header() | thread_ident) ^ (uintptr_t)mark) &amp;</span>
<span class="line-modified">1804               ~((uintptr_t) markOopDesc::age_mask_in_place);</span>
1805 
1806             if  (anticipated_bias_locking_value == 0) {
1807               // already biased towards this thread, nothing to do
1808               if (PrintBiasedLockingStatistics) {
1809                 (* BiasedLocking::biased_lock_entry_count_addr())++;
1810               }
1811               success = true;
1812             }
<span class="line-modified">1813             else if ((anticipated_bias_locking_value &amp; markOopDesc::biased_lock_mask_in_place) != 0) {</span>
1814               // try revoke bias
<span class="line-modified">1815               markOop header = lockee-&gt;klass()-&gt;prototype_header();</span>
<span class="line-modified">1816               if (hash != markOopDesc::no_hash) {</span>
<span class="line-modified">1817                 header = header-&gt;copy_set_hash(hash);</span>
1818               }
1819               if (lockee-&gt;cas_set_mark(header, mark) == mark) {
1820                 if (PrintBiasedLockingStatistics)
1821                   (*BiasedLocking::revoked_lock_entry_count_addr())++;
1822               }
1823             }
1824             else if ((anticipated_bias_locking_value &amp; epoch_mask_in_place) !=0) {
1825               // try rebias
<span class="line-modified">1826               markOop new_header = (markOop) ( (intptr_t) lockee-&gt;klass()-&gt;prototype_header() | thread_ident);</span>
<span class="line-modified">1827               if (hash != markOopDesc::no_hash) {</span>
<span class="line-modified">1828                 new_header = new_header-&gt;copy_set_hash(hash);</span>
1829               }
1830               if (lockee-&gt;cas_set_mark(new_header, mark) == mark) {
1831                 if (PrintBiasedLockingStatistics)
1832                   (* BiasedLocking::rebiased_lock_entry_count_addr())++;
1833               }
1834               else {
1835                 CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
1836               }
1837               success = true;
1838             }
1839             else {
1840               // try to bias towards thread in case object is anonymously biased
<span class="line-modified">1841               markOop header = (markOop) ((uintptr_t) mark &amp; ((uintptr_t)markOopDesc::biased_lock_mask_in_place |</span>
<span class="line-modified">1842                                                               (uintptr_t)markOopDesc::age_mask_in_place |</span>
<span class="line-modified">1843                                                               epoch_mask_in_place));</span>
<span class="line-modified">1844               if (hash != markOopDesc::no_hash) {</span>
<span class="line-modified">1845                 header = header-&gt;copy_set_hash(hash);</span>
1846               }
<span class="line-modified">1847               markOop new_header = (markOop) ((uintptr_t) header | thread_ident);</span>
1848               // debugging hint
<span class="line-modified">1849               DEBUG_ONLY(entry-&gt;lock()-&gt;set_displaced_header((markOop) (uintptr_t) 0xdeaddead);)</span>
1850               if (lockee-&gt;cas_set_mark(new_header, header) == header) {
1851                 if (PrintBiasedLockingStatistics)
1852                   (* BiasedLocking::anonymously_biased_lock_entry_count_addr())++;
1853               }
1854               else {
1855                 CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
1856               }
1857               success = true;
1858             }
1859           }
1860 
1861           // traditional lightweight locking
1862           if (!success) {
<span class="line-modified">1863             markOop displaced = lockee-&gt;mark()-&gt;set_unlocked();</span>
1864             entry-&gt;lock()-&gt;set_displaced_header(displaced);
1865             bool call_vm = UseHeavyMonitors;
<span class="line-modified">1866             if (call_vm || lockee-&gt;cas_set_mark((markOop)entry, displaced) != displaced) {</span>
1867               // Is it simple recursive case?
<span class="line-modified">1868               if (!call_vm &amp;&amp; THREAD-&gt;is_lock_owned((address) displaced-&gt;clear_lock_bits())) {</span>
<span class="line-modified">1869                 entry-&gt;lock()-&gt;set_displaced_header(NULL);</span>
1870               } else {
1871                 CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
1872               }
1873             }
1874           }
1875           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1876         } else {
1877           istate-&gt;set_msg(more_monitors);
1878           UPDATE_PC_AND_RETURN(0); // Re-execute
1879         }
1880       }
1881 
1882       CASE(_monitorexit): {
1883         oop lockee = STACK_OBJECT(-1);
1884         CHECK_NULL(lockee);
1885         // derefing&#39;s lockee ought to provoke implicit null check
1886         // find our monitor slot
1887         BasicObjectLock* limit = istate-&gt;monitor_base();
1888         BasicObjectLock* most_recent = (BasicObjectLock*) istate-&gt;stack_base();
1889         while (most_recent != limit ) {
1890           if ((most_recent)-&gt;obj() == lockee) {
1891             BasicLock* lock = most_recent-&gt;lock();
<span class="line-modified">1892             markOop header = lock-&gt;displaced_header();</span>
1893             most_recent-&gt;set_obj(NULL);
<span class="line-modified">1894             if (!lockee-&gt;mark()-&gt;has_bias_pattern()) {</span>
1895               bool call_vm = UseHeavyMonitors;
1896               // If it isn&#39;t recursive we either must swap old header or call the runtime
<span class="line-modified">1897               if (header != NULL || call_vm) {</span>
<span class="line-modified">1898                 markOop old_header = markOopDesc::encode(lock);</span>
1899                 if (call_vm || lockee-&gt;cas_set_mark(header, old_header) != old_header) {
1900                   // restore object for the slow case
1901                   most_recent-&gt;set_obj(lockee);
1902                   CALL_VM(InterpreterRuntime::monitorexit(THREAD, most_recent), handle_exception);
1903                 }
1904               }
1905             }
1906             UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1907           }
1908           most_recent++;
1909         }
1910         // Need to throw illegal monitor state exception
1911         CALL_VM(InterpreterRuntime::throw_illegal_monitor_state_exception(THREAD), handle_exception);
1912         ShouldNotReachHere();
1913       }
1914 
1915       /* All of the non-quick opcodes. */
1916 
1917       /* -Set clobbersCpIndex true if the quickened opcode clobbers the
1918        *  constant pool index in the instruction.
</pre>
<hr />
<pre>
2145           InstanceKlass* ik = InstanceKlass::cast(entry);
2146           if (ik-&gt;is_initialized() &amp;&amp; ik-&gt;can_be_fastpath_allocated() ) {
2147             size_t obj_size = ik-&gt;size_helper();
2148             oop result = NULL;
2149             // If the TLAB isn&#39;t pre-zeroed then we&#39;ll have to do it
2150             bool need_zero = !ZeroTLAB;
2151             if (UseTLAB) {
2152               result = (oop) THREAD-&gt;tlab().allocate(obj_size);
2153             }
2154             // Disable non-TLAB-based fast-path, because profiling requires that all
2155             // allocations go through InterpreterRuntime::_new() if THREAD-&gt;tlab().allocate
2156             // returns NULL.
2157 #ifndef CC_INTERP_PROFILE
2158             if (result == NULL) {
2159               need_zero = true;
2160               // Try allocate in shared eden
2161             retry:
2162               HeapWord* compare_to = *Universe::heap()-&gt;top_addr();
2163               HeapWord* new_top = compare_to + obj_size;
2164               if (new_top &lt;= *Universe::heap()-&gt;end_addr()) {
<span class="line-modified">2165                 if (Atomic::cmpxchg(new_top, Universe::heap()-&gt;top_addr(), compare_to) != compare_to) {</span>
2166                   goto retry;
2167                 }
2168                 result = (oop) compare_to;
2169               }
2170             }
2171 #endif
2172             if (result != NULL) {
2173               // Initialize object (if nonzero size and need) and then the header
2174               if (need_zero ) {
<span class="line-modified">2175                 HeapWord* to_zero = (HeapWord*) result + sizeof(oopDesc) / oopSize;</span>
2176                 obj_size -= sizeof(oopDesc) / oopSize;
2177                 if (obj_size &gt; 0 ) {
2178                   memset(to_zero, 0, obj_size * HeapWordSize);
2179                 }
2180               }
2181               if (UseBiasedLocking) {
2182                 result-&gt;set_mark(ik-&gt;prototype_header());
2183               } else {
<span class="line-modified">2184                 result-&gt;set_mark(markOopDesc::prototype());</span>
2185               }
2186               result-&gt;set_klass_gap(0);
2187               result-&gt;set_klass(ik);
2188               // Must prevent reordering of stores for object initialization
2189               // with stores that publish the new object.
2190               OrderAccess::storestore();
2191               SET_STACK_OBJECT(result, 0);
2192               UPDATE_PC_AND_TOS_AND_CONTINUE(3, 1);
2193             }
2194           }
2195         }
2196         // Slow case allocation
2197         CALL_VM(InterpreterRuntime::_new(THREAD, METHOD-&gt;constants(), index),
2198                 handle_exception);
2199         // Must prevent reordering of stores for object initialization
2200         // with stores that publish the new object.
2201         OrderAccess::storestore();
2202         SET_STACK_OBJECT(THREAD-&gt;vm_result(), 0);
2203         THREAD-&gt;set_vm_result(NULL);
2204         UPDATE_PC_AND_TOS_AND_CONTINUE(3, 1);
</pre>
<hr />
<pre>
2418         u2 index;
2419         int incr;
2420         if (opcode == Bytecodes::_fast_aldc) {
2421           index = pc[1];
2422           incr = 2;
2423         } else {
2424           index = Bytes::get_native_u2(pc+1);
2425           incr = 3;
2426         }
2427 
2428         // We are resolved if the resolved_references array contains a non-null object (CallSite, etc.)
2429         // This kind of CP cache entry does not need to match the flags byte, because
2430         // there is a 1-1 relation between bytecode type and CP entry type.
2431         ConstantPool* constants = METHOD-&gt;constants();
2432         oop result = constants-&gt;resolved_references()-&gt;obj_at(index);
2433         if (result == NULL) {
2434           CALL_VM(InterpreterRuntime::resolve_ldc(THREAD, (Bytecodes::Code) opcode),
2435                   handle_exception);
2436           result = THREAD-&gt;vm_result();
2437         }
<span class="line-modified">2438         if (oopDesc::equals(result, Universe::the_null_sentinel()))</span>
2439           result = NULL;
2440 
2441         VERIFY_OOP(result);
2442         SET_STACK_OBJECT(result, 0);
2443         UPDATE_PC_AND_TOS_AND_CONTINUE(incr, 1);
2444       }
2445 
2446       CASE(_invokedynamic): {
2447 
2448         u4 index = Bytes::get_native_u4(pc+1);
2449         ConstantPoolCacheEntry* cache = cp-&gt;constant_pool()-&gt;invokedynamic_cp_cache_entry_at(index);
2450 
2451         // We are resolved if the resolved_references array contains a non-null object (CallSite, etc.)
2452         // This kind of CP cache entry does not need to match the flags byte, because
2453         // there is a 1-1 relation between bytecode type and CP entry type.
2454         if (! cache-&gt;is_resolved((Bytecodes::Code) opcode)) {
2455           CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
2456                   handle_exception);
2457           cache = cp-&gt;constant_pool()-&gt;invokedynamic_cp_cache_entry_at(index);
2458         }
2459 
2460         Method* method = cache-&gt;f1_as_method();
2461         if (VerifyOops) method-&gt;verify();
2462 
2463         if (cache-&gt;has_appendix()) {
<span class="line-modified">2464           ConstantPool* constants = METHOD-&gt;constants();</span>
<span class="line-modified">2465           SET_STACK_OBJECT(cache-&gt;appendix_if_resolved(constants), 0);</span>
2466           MORE_STACK(1);
2467         }
2468 
2469         istate-&gt;set_msg(call_method);
2470         istate-&gt;set_callee(method);
2471         istate-&gt;set_callee_entry_point(method-&gt;from_interpreted_entry());
2472         istate-&gt;set_bcp_advance(5);
2473 
2474         // Invokedynamic has got a call counter, just like an invokestatic -&gt; increment!
2475         BI_PROFILE_UPDATE_CALL();
2476 
2477         UPDATE_PC_AND_RETURN(0); // I&#39;ll be back...
2478       }
2479 
2480       CASE(_invokehandle): {
2481 
2482         u2 index = Bytes::get_native_u2(pc+1);
2483         ConstantPoolCacheEntry* cache = cp-&gt;entry_at(index);
2484 
2485         if (! cache-&gt;is_resolved((Bytecodes::Code) opcode)) {
2486           CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
2487                   handle_exception);
2488           cache = cp-&gt;entry_at(index);
2489         }
2490 
2491         Method* method = cache-&gt;f1_as_method();
2492         if (VerifyOops) method-&gt;verify();
2493 
2494         if (cache-&gt;has_appendix()) {
<span class="line-modified">2495           ConstantPool* constants = METHOD-&gt;constants();</span>
<span class="line-modified">2496           SET_STACK_OBJECT(cache-&gt;appendix_if_resolved(constants), 0);</span>
2497           MORE_STACK(1);
2498         }
2499 
2500         istate-&gt;set_msg(call_method);
2501         istate-&gt;set_callee(method);
2502         istate-&gt;set_callee_entry_point(method-&gt;from_interpreted_entry());
2503         istate-&gt;set_bcp_advance(3);
2504 
2505         // Invokehandle has got a call counter, just like a final call -&gt; increment!
2506         BI_PROFILE_UPDATE_FINALCALL();
2507 
2508         UPDATE_PC_AND_RETURN(0); // I&#39;ll be back...
2509       }
2510 
2511       CASE(_invokeinterface): {
2512         u2 index = Bytes::get_native_u2(pc+1);
2513 
2514         // QQQ Need to make this as inlined as possible. Probably need to split all the bytecode cases
2515         // out so c++ compiler has a chance for constant prop to fold everything possible away.
2516 
</pre>
<hr />
<pre>
2853     // expression stack is emptied
2854     topOfStack = istate-&gt;stack_base() - Interpreter::stackElementWords;
2855     CALL_VM(continuation_bci = (intptr_t)InterpreterRuntime::exception_handler_for_exception(THREAD, except_oop()),
2856             handle_exception);
2857 
2858     except_oop = Handle(THREAD, THREAD-&gt;vm_result());
2859     THREAD-&gt;set_vm_result(NULL);
2860     if (continuation_bci &gt;= 0) {
2861       // Place exception on top of stack
2862       SET_STACK_OBJECT(except_oop(), 0);
2863       MORE_STACK(1);
2864       pc = METHOD-&gt;code_base() + continuation_bci;
2865       if (log_is_enabled(Info, exceptions)) {
2866         ResourceMark rm(THREAD);
2867         stringStream tempst;
2868         tempst.print(&quot;interpreter method &lt;%s&gt;\n&quot;
2869                      &quot; at bci %d, continuing at %d for thread &quot; INTPTR_FORMAT,
2870                      METHOD-&gt;print_value_string(),
2871                      (int)(istate-&gt;bcp() - METHOD-&gt;code_base()),
2872                      (int)continuation_bci, p2i(THREAD));
<span class="line-modified">2873         Exceptions::log_exception(except_oop, tempst);</span>
2874       }
2875       // for AbortVMOnException flag
2876       Exceptions::debug_check_abort(except_oop);
2877 
2878       // Update profiling data.
2879       BI_PROFILE_ALIGN_TO_CURRENT_BCI();
2880       goto run;
2881     }
2882     if (log_is_enabled(Info, exceptions)) {
2883       ResourceMark rm;
2884       stringStream tempst;
2885       tempst.print(&quot;interpreter method &lt;%s&gt;\n&quot;
2886              &quot; at bci %d, unwinding for thread &quot; INTPTR_FORMAT,
2887              METHOD-&gt;print_value_string(),
2888              (int)(istate-&gt;bcp() - METHOD-&gt;code_base()),
2889              p2i(THREAD));
<span class="line-modified">2890       Exceptions::log_exception(except_oop, tempst);</span>
2891     }
2892     // for AbortVMOnException flag
2893     Exceptions::debug_check_abort(except_oop);
2894 
2895     // No handler in this activation, unwind and try again
2896     THREAD-&gt;set_pending_exception(except_oop(), NULL, 0);
2897     goto handle_return;
2898   }  // handle_exception:
2899 
2900   // Return from an interpreter invocation with the result of the interpretation
2901   // on the top of the Java Stack (or a pending exception)
2902 
2903   handle_Pop_Frame: {
2904 
2905     // We don&#39;t really do anything special here except we must be aware
2906     // that we can get here without ever locking the method (if sync).
2907     // Also we skip the notification of the exit.
2908 
2909     istate-&gt;set_msg(popping_frame);
2910     // Clear pending so while the pop is in process
</pre>
<hr />
<pre>
3017       // Another weird thing to watch for is if the method was locked
3018       // recursively and then not exited properly. This means we must
3019       // examine all the entries in reverse time(and stack) order and
3020       // unlock as we find them. If we find the method monitor before
3021       // we are at the initial entry then we should throw an exception.
3022       // It is not clear the template based interpreter does this
3023       // correctly
3024 
3025       BasicObjectLock* base = istate-&gt;monitor_base();
3026       BasicObjectLock* end = (BasicObjectLock*) istate-&gt;stack_base();
3027       bool method_unlock_needed = METHOD-&gt;is_synchronized();
3028       // We know the initial monitor was used for the method don&#39;t check that
3029       // slot in the loop
3030       if (method_unlock_needed) base--;
3031 
3032       // Check all the monitors to see they are unlocked. Install exception if found to be locked.
3033       while (end &lt; base) {
3034         oop lockee = end-&gt;obj();
3035         if (lockee != NULL) {
3036           BasicLock* lock = end-&gt;lock();
<span class="line-modified">3037           markOop header = lock-&gt;displaced_header();</span>
3038           end-&gt;set_obj(NULL);
3039 
<span class="line-modified">3040           if (!lockee-&gt;mark()-&gt;has_bias_pattern()) {</span>
3041             // If it isn&#39;t recursive we either must swap old header or call the runtime
<span class="line-modified">3042             if (header != NULL) {</span>
<span class="line-modified">3043               markOop old_header = markOopDesc::encode(lock);</span>
3044               if (lockee-&gt;cas_set_mark(header, old_header) != old_header) {
3045                 // restore object for the slow case
3046                 end-&gt;set_obj(lockee);
3047                 {
3048                   // Prevent any HandleMarkCleaner from freeing our live handles
3049                   HandleMark __hm(THREAD);
3050                   CALL_VM_NOCHECK(InterpreterRuntime::monitorexit(THREAD, end));
3051                 }
3052               }
3053             }
3054           }
3055           // One error is plenty
3056           if (illegal_state_oop() == NULL &amp;&amp; !suppress_error) {
3057             {
3058               // Prevent any HandleMarkCleaner from freeing our live handles
3059               HandleMark __hm(THREAD);
3060               CALL_VM_NOCHECK(InterpreterRuntime::throw_illegal_monitor_state_exception(THREAD));
3061             }
3062             assert(THREAD-&gt;has_pending_exception(), &quot;Lost our exception!&quot;);
3063             illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
</pre>
<hr />
<pre>
3092           //
3093           oop rcvr = base-&gt;obj();
3094           if (rcvr == NULL) {
3095             if (!suppress_error) {
3096               VM_JAVA_ERROR_NO_JUMP(vmSymbols::java_lang_NullPointerException(), &quot;&quot;, note_nullCheck_trap);
3097               illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
3098               THREAD-&gt;clear_pending_exception();
3099             }
3100           } else if (UseHeavyMonitors) {
3101             {
3102               // Prevent any HandleMarkCleaner from freeing our live handles.
3103               HandleMark __hm(THREAD);
3104               CALL_VM_NOCHECK(InterpreterRuntime::monitorexit(THREAD, base));
3105             }
3106             if (THREAD-&gt;has_pending_exception()) {
3107               if (!suppress_error) illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
3108               THREAD-&gt;clear_pending_exception();
3109             }
3110           } else {
3111             BasicLock* lock = base-&gt;lock();
<span class="line-modified">3112             markOop header = lock-&gt;displaced_header();</span>
3113             base-&gt;set_obj(NULL);
3114 
<span class="line-modified">3115             if (!rcvr-&gt;mark()-&gt;has_bias_pattern()) {</span>
3116               base-&gt;set_obj(NULL);
3117               // If it isn&#39;t recursive we either must swap old header or call the runtime
<span class="line-modified">3118               if (header != NULL) {</span>
<span class="line-modified">3119                 markOop old_header = markOopDesc::encode(lock);</span>
3120                 if (rcvr-&gt;cas_set_mark(header, old_header) != old_header) {
3121                   // restore object for the slow case
3122                   base-&gt;set_obj(rcvr);
3123                   {
3124                     // Prevent any HandleMarkCleaner from freeing our live handles
3125                     HandleMark __hm(THREAD);
3126                     CALL_VM_NOCHECK(InterpreterRuntime::monitorexit(THREAD, base));
3127                   }
3128                   if (THREAD-&gt;has_pending_exception()) {
3129                     if (!suppress_error) illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
3130                     THREAD-&gt;clear_pending_exception();
3131                   }
3132                 }
3133               }
3134             }
3135           }
3136         }
3137       }
3138     }
3139     // Clear the do_not_unlock flag now.
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2002, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 // no precompiled headers
  26 #include &quot;classfile/vmSymbols.hpp&quot;
  27 #include &quot;gc/shared/collectedHeap.hpp&quot;
  28 #include &quot;gc/shared/threadLocalAllocBuffer.inline.hpp&quot;
  29 #include &quot;interpreter/bytecodeHistogram.hpp&quot;
  30 #include &quot;interpreter/bytecodeInterpreter.hpp&quot;
  31 #include &quot;interpreter/bytecodeInterpreter.inline.hpp&quot;
  32 #include &quot;interpreter/bytecodeInterpreterProfiling.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  35 #include &quot;logging/log.hpp&quot;
  36 #include &quot;memory/resourceArea.hpp&quot;
<span class="line-added">  37 #include &quot;memory/universe.hpp&quot;</span>
  38 #include &quot;oops/constantPool.inline.hpp&quot;
  39 #include &quot;oops/cpCache.inline.hpp&quot;
  40 #include &quot;oops/method.inline.hpp&quot;
  41 #include &quot;oops/methodCounters.hpp&quot;
  42 #include &quot;oops/objArrayKlass.hpp&quot;
  43 #include &quot;oops/objArrayOop.inline.hpp&quot;
  44 #include &quot;oops/oop.inline.hpp&quot;
  45 #include &quot;oops/typeArrayOop.inline.hpp&quot;
  46 #include &quot;prims/jvmtiExport.hpp&quot;
  47 #include &quot;prims/jvmtiThreadState.hpp&quot;
  48 #include &quot;runtime/atomic.hpp&quot;
  49 #include &quot;runtime/biasedLocking.hpp&quot;
  50 #include &quot;runtime/frame.inline.hpp&quot;
  51 #include &quot;runtime/handles.inline.hpp&quot;
  52 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  53 #include &quot;runtime/orderAccess.hpp&quot;
  54 #include &quot;runtime/sharedRuntime.hpp&quot;
  55 #include &quot;runtime/threadCritical.hpp&quot;
  56 #include &quot;utilities/exceptions.hpp&quot;
  57 
</pre>
<hr />
<pre>
 649       if ((istate-&gt;_stack_base - istate-&gt;_stack_limit) != istate-&gt;method()-&gt;max_stack() + 1) {
 650         // initialize
 651         os::breakpoint();
 652       }
 653 
 654       // Lock method if synchronized.
 655       if (METHOD-&gt;is_synchronized()) {
 656         // oop rcvr = locals[0].j.r;
 657         oop rcvr;
 658         if (METHOD-&gt;is_static()) {
 659           rcvr = METHOD-&gt;constants()-&gt;pool_holder()-&gt;java_mirror();
 660         } else {
 661           rcvr = LOCALS_OBJECT(0);
 662           VERIFY_OOP(rcvr);
 663         }
 664         // The initial monitor is ours for the taking.
 665         // Monitor not filled in frame manager any longer as this caused race condition with biased locking.
 666         BasicObjectLock* mon = &amp;istate-&gt;monitor_base()[-1];
 667         mon-&gt;set_obj(rcvr);
 668         bool success = false;
<span class="line-modified"> 669         uintptr_t epoch_mask_in_place = markWord::epoch_mask_in_place;</span>
<span class="line-modified"> 670         markWord mark = rcvr-&gt;mark();</span>
<span class="line-modified"> 671         intptr_t hash = (intptr_t) markWord::no_hash;</span>
 672         // Implies UseBiasedLocking.
<span class="line-modified"> 673         if (mark.has_bias_pattern()) {</span>
 674           uintptr_t thread_ident;
 675           uintptr_t anticipated_bias_locking_value;
 676           thread_ident = (uintptr_t)istate-&gt;thread();
 677           anticipated_bias_locking_value =
<span class="line-modified"> 678             ((rcvr-&gt;klass()-&gt;prototype_header().value() | thread_ident) ^ mark.value()) &amp;</span>
<span class="line-modified"> 679             ~(markWord::age_mask_in_place);</span>
 680 
 681           if (anticipated_bias_locking_value == 0) {
 682             // Already biased towards this thread, nothing to do.
 683             if (PrintBiasedLockingStatistics) {
 684               (* BiasedLocking::biased_lock_entry_count_addr())++;
 685             }
 686             success = true;
<span class="line-modified"> 687           } else if ((anticipated_bias_locking_value &amp; markWord::biased_lock_mask_in_place) != 0) {</span>
 688             // Try to revoke bias.
<span class="line-modified"> 689             markWord header = rcvr-&gt;klass()-&gt;prototype_header();</span>
<span class="line-modified"> 690             if (hash != markWord::no_hash) {</span>
<span class="line-modified"> 691               header = header.copy_set_hash(hash);</span>
 692             }
 693             if (rcvr-&gt;cas_set_mark(header, mark) == mark) {
 694               if (PrintBiasedLockingStatistics)
 695                 (*BiasedLocking::revoked_lock_entry_count_addr())++;
 696             }
 697           } else if ((anticipated_bias_locking_value &amp; epoch_mask_in_place) != 0) {
 698             // Try to rebias.
<span class="line-modified"> 699             markWord new_header( (intptr_t) rcvr-&gt;klass()-&gt;prototype_header().value() | thread_ident);</span>
<span class="line-modified"> 700             if (hash != markWord::no_hash) {</span>
<span class="line-modified"> 701               new_header = new_header.copy_set_hash(hash);</span>
 702             }
 703             if (rcvr-&gt;cas_set_mark(new_header, mark) == mark) {
 704               if (PrintBiasedLockingStatistics) {
 705                 (* BiasedLocking::rebiased_lock_entry_count_addr())++;
 706               }
 707             } else {
 708               CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);
 709             }
 710             success = true;
 711           } else {
 712             // Try to bias towards thread in case object is anonymously biased.
<span class="line-modified"> 713             markWord header(mark.value() &amp;</span>
<span class="line-modified"> 714                             (markWord::biased_lock_mask_in_place |</span>
<span class="line-modified"> 715                              markWord::age_mask_in_place | epoch_mask_in_place));</span>
<span class="line-modified"> 716             if (hash != markWord::no_hash) {</span>
<span class="line-modified"> 717               header = header.copy_set_hash(hash);</span>
 718             }
<span class="line-modified"> 719             markWord new_header(header.value() | thread_ident);</span>
 720             // Debugging hint.
<span class="line-modified"> 721             DEBUG_ONLY(mon-&gt;lock()-&gt;set_displaced_header(markWord((uintptr_t) 0xdeaddead));)</span>
 722             if (rcvr-&gt;cas_set_mark(new_header, header) == header) {
 723               if (PrintBiasedLockingStatistics) {
 724                 (* BiasedLocking::anonymously_biased_lock_entry_count_addr())++;
 725               }
 726             } else {
 727               CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);
 728             }
 729             success = true;
 730           }
 731         }
 732 
 733         // Traditional lightweight locking.
 734         if (!success) {
<span class="line-modified"> 735           markWord displaced = rcvr-&gt;mark().set_unlocked();</span>
 736           mon-&gt;lock()-&gt;set_displaced_header(displaced);
 737           bool call_vm = UseHeavyMonitors;
<span class="line-modified"> 738           if (call_vm || rcvr-&gt;cas_set_mark(markWord::from_pointer(mon), displaced) != displaced) {</span>
 739             // Is it simple recursive case?
<span class="line-modified"> 740             if (!call_vm &amp;&amp; THREAD-&gt;is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {</span>
<span class="line-modified"> 741               mon-&gt;lock()-&gt;set_displaced_header(markWord::from_pointer(NULL));</span>
 742             } else {
 743               CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);
 744             }
 745           }
 746         }
 747       }
 748       THREAD-&gt;clr_do_not_unlock();
 749 
 750       // Notify jvmti
 751 #ifdef VM_JVMTI
 752       if (_jvmti_interp_events) {
 753         // Whenever JVMTI puts a thread in interp_only_mode, method
 754         // entry/exit events are sent for that thread to track stack depth.
 755         if (THREAD-&gt;is_interp_only_mode()) {
 756           CALL_VM(InterpreterRuntime::post_method_entry(THREAD),
 757                   handle_exception);
 758         }
 759       }
 760 #endif /* VM_JVMTI */
 761 
</pre>
<hr />
<pre>
 834       UPDATE_PC(Bytecodes::length_at(METHOD, pc));
 835       if (THREAD-&gt;has_pending_exception()) goto handle_exception;
 836 
 837       if (_compiling) {
 838         // Get or create profile data. Check for pending (async) exceptions.
 839         BI_PROFILE_GET_OR_CREATE_METHOD_DATA(handle_exception);
 840       }
 841       goto run;
 842     }
 843     case got_monitors: {
 844       // continue locking now that we have a monitor to use
 845       // we expect to find newly allocated monitor at the &quot;top&quot; of the monitor stack.
 846       oop lockee = STACK_OBJECT(-1);
 847       VERIFY_OOP(lockee);
 848       // derefing&#39;s lockee ought to provoke implicit null check
 849       // find a free monitor
 850       BasicObjectLock* entry = (BasicObjectLock*) istate-&gt;stack_base();
 851       assert(entry-&gt;obj() == NULL, &quot;Frame manager didn&#39;t allocate the monitor&quot;);
 852       entry-&gt;set_obj(lockee);
 853       bool success = false;
<span class="line-modified"> 854       uintptr_t epoch_mask_in_place = markWord::epoch_mask_in_place;</span>
 855 
<span class="line-modified"> 856       markWord mark = lockee-&gt;mark();</span>
<span class="line-modified"> 857       intptr_t hash = (intptr_t) markWord::no_hash;</span>
 858       // implies UseBiasedLocking
<span class="line-modified"> 859       if (mark.has_bias_pattern()) {</span>
 860         uintptr_t thread_ident;
 861         uintptr_t anticipated_bias_locking_value;
 862         thread_ident = (uintptr_t)istate-&gt;thread();
 863         anticipated_bias_locking_value =
<span class="line-modified"> 864           ((lockee-&gt;klass()-&gt;prototype_header().value() | thread_ident) ^ mark.value()) &amp;</span>
<span class="line-modified"> 865           ~(markWord::age_mask_in_place);</span>
 866 
 867         if  (anticipated_bias_locking_value == 0) {
 868           // already biased towards this thread, nothing to do
 869           if (PrintBiasedLockingStatistics) {
 870             (* BiasedLocking::biased_lock_entry_count_addr())++;
 871           }
 872           success = true;
<span class="line-modified"> 873         } else if ((anticipated_bias_locking_value &amp; markWord::biased_lock_mask_in_place) != 0) {</span>
 874           // try revoke bias
<span class="line-modified"> 875           markWord header = lockee-&gt;klass()-&gt;prototype_header();</span>
<span class="line-modified"> 876           if (hash != markWord::no_hash) {</span>
<span class="line-modified"> 877             header = header.copy_set_hash(hash);</span>
 878           }
 879           if (lockee-&gt;cas_set_mark(header, mark) == mark) {
 880             if (PrintBiasedLockingStatistics) {
 881               (*BiasedLocking::revoked_lock_entry_count_addr())++;
 882             }
 883           }
 884         } else if ((anticipated_bias_locking_value &amp; epoch_mask_in_place) !=0) {
 885           // try rebias
<span class="line-modified"> 886           markWord new_header( (intptr_t) lockee-&gt;klass()-&gt;prototype_header().value() | thread_ident);</span>
<span class="line-modified"> 887           if (hash != markWord::no_hash) {</span>
<span class="line-modified"> 888             new_header = new_header.copy_set_hash(hash);</span>
 889           }
 890           if (lockee-&gt;cas_set_mark(new_header, mark) == mark) {
 891             if (PrintBiasedLockingStatistics) {
 892               (* BiasedLocking::rebiased_lock_entry_count_addr())++;
 893             }
 894           } else {
 895             CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
 896           }
 897           success = true;
 898         } else {
 899           // try to bias towards thread in case object is anonymously biased
<span class="line-modified"> 900           markWord header(mark.value() &amp; (markWord::biased_lock_mask_in_place |</span>
<span class="line-modified"> 901                                           markWord::age_mask_in_place | epoch_mask_in_place));</span>
<span class="line-modified"> 902           if (hash != markWord::no_hash) {</span>
<span class="line-modified"> 903             header = header.copy_set_hash(hash);</span>
 904           }
<span class="line-modified"> 905           markWord new_header(header.value() | thread_ident);</span>
 906           // debugging hint
<span class="line-modified"> 907           DEBUG_ONLY(entry-&gt;lock()-&gt;set_displaced_header(markWord((uintptr_t) 0xdeaddead));)</span>
 908           if (lockee-&gt;cas_set_mark(new_header, header) == header) {
 909             if (PrintBiasedLockingStatistics) {
 910               (* BiasedLocking::anonymously_biased_lock_entry_count_addr())++;
 911             }
 912           } else {
 913             CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
 914           }
 915           success = true;
 916         }
 917       }
 918 
 919       // traditional lightweight locking
 920       if (!success) {
<span class="line-modified"> 921         markWord displaced = lockee-&gt;mark().set_unlocked();</span>
 922         entry-&gt;lock()-&gt;set_displaced_header(displaced);
 923         bool call_vm = UseHeavyMonitors;
<span class="line-modified"> 924         if (call_vm || lockee-&gt;cas_set_mark(markWord::from_pointer(entry), displaced) != displaced) {</span>
 925           // Is it simple recursive case?
<span class="line-modified"> 926           if (!call_vm &amp;&amp; THREAD-&gt;is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {</span>
<span class="line-modified"> 927             entry-&gt;lock()-&gt;set_displaced_header(markWord::from_pointer(NULL));</span>
 928           } else {
 929             CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
 930           }
 931         }
 932       }
 933       UPDATE_PC_AND_TOS(1, -1);
 934       goto run;
 935     }
 936     default: {
 937       fatal(&quot;Unexpected message from frame manager&quot;);
 938     }
 939   }
 940 
 941 run:
 942 
 943   DO_UPDATE_INSTRUCTION_COUNT(*pc)
 944   DEBUGGER_SINGLE_STEP_NOTIFY();
 945 #ifdef PREFETCH_OPCCODE
 946   opcode = *pc;  /* prefetch first opcode */
 947 #endif
</pre>
<hr />
<pre>
1774       /* monitorenter and monitorexit for locking/unlocking an object */
1775 
1776       CASE(_monitorenter): {
1777         oop lockee = STACK_OBJECT(-1);
1778         // derefing&#39;s lockee ought to provoke implicit null check
1779         CHECK_NULL(lockee);
1780         // find a free monitor or one already allocated for this object
1781         // if we find a matching object then we need a new monitor
1782         // since this is recursive enter
1783         BasicObjectLock* limit = istate-&gt;monitor_base();
1784         BasicObjectLock* most_recent = (BasicObjectLock*) istate-&gt;stack_base();
1785         BasicObjectLock* entry = NULL;
1786         while (most_recent != limit ) {
1787           if (most_recent-&gt;obj() == NULL) entry = most_recent;
1788           else if (most_recent-&gt;obj() == lockee) break;
1789           most_recent++;
1790         }
1791         if (entry != NULL) {
1792           entry-&gt;set_obj(lockee);
1793           int success = false;
<span class="line-modified">1794           uintptr_t epoch_mask_in_place = markWord::epoch_mask_in_place;</span>
1795 
<span class="line-modified">1796           markWord mark = lockee-&gt;mark();</span>
<span class="line-modified">1797           intptr_t hash = (intptr_t) markWord::no_hash;</span>
1798           // implies UseBiasedLocking
<span class="line-modified">1799           if (mark.has_bias_pattern()) {</span>
1800             uintptr_t thread_ident;
1801             uintptr_t anticipated_bias_locking_value;
1802             thread_ident = (uintptr_t)istate-&gt;thread();
1803             anticipated_bias_locking_value =
<span class="line-modified">1804               ((lockee-&gt;klass()-&gt;prototype_header().value() | thread_ident) ^ mark.value()) &amp;</span>
<span class="line-modified">1805               ~(markWord::age_mask_in_place);</span>
1806 
1807             if  (anticipated_bias_locking_value == 0) {
1808               // already biased towards this thread, nothing to do
1809               if (PrintBiasedLockingStatistics) {
1810                 (* BiasedLocking::biased_lock_entry_count_addr())++;
1811               }
1812               success = true;
1813             }
<span class="line-modified">1814             else if ((anticipated_bias_locking_value &amp; markWord::biased_lock_mask_in_place) != 0) {</span>
1815               // try revoke bias
<span class="line-modified">1816               markWord header = lockee-&gt;klass()-&gt;prototype_header();</span>
<span class="line-modified">1817               if (hash != markWord::no_hash) {</span>
<span class="line-modified">1818                 header = header.copy_set_hash(hash);</span>
1819               }
1820               if (lockee-&gt;cas_set_mark(header, mark) == mark) {
1821                 if (PrintBiasedLockingStatistics)
1822                   (*BiasedLocking::revoked_lock_entry_count_addr())++;
1823               }
1824             }
1825             else if ((anticipated_bias_locking_value &amp; epoch_mask_in_place) !=0) {
1826               // try rebias
<span class="line-modified">1827               markWord new_header( (intptr_t) lockee-&gt;klass()-&gt;prototype_header().value() | thread_ident);</span>
<span class="line-modified">1828               if (hash != markWord::no_hash) {</span>
<span class="line-modified">1829                 new_header = new_header.copy_set_hash(hash);</span>
1830               }
1831               if (lockee-&gt;cas_set_mark(new_header, mark) == mark) {
1832                 if (PrintBiasedLockingStatistics)
1833                   (* BiasedLocking::rebiased_lock_entry_count_addr())++;
1834               }
1835               else {
1836                 CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
1837               }
1838               success = true;
1839             }
1840             else {
1841               // try to bias towards thread in case object is anonymously biased
<span class="line-modified">1842               markWord header(mark.value() &amp; (markWord::biased_lock_mask_in_place |</span>
<span class="line-modified">1843                                               markWord::age_mask_in_place |</span>
<span class="line-modified">1844                                               epoch_mask_in_place));</span>
<span class="line-modified">1845               if (hash != markWord::no_hash) {</span>
<span class="line-modified">1846                 header = header.copy_set_hash(hash);</span>
1847               }
<span class="line-modified">1848               markWord new_header(header.value() | thread_ident);</span>
1849               // debugging hint
<span class="line-modified">1850               DEBUG_ONLY(entry-&gt;lock()-&gt;set_displaced_header(markWord((uintptr_t) 0xdeaddead));)</span>
1851               if (lockee-&gt;cas_set_mark(new_header, header) == header) {
1852                 if (PrintBiasedLockingStatistics)
1853                   (* BiasedLocking::anonymously_biased_lock_entry_count_addr())++;
1854               }
1855               else {
1856                 CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
1857               }
1858               success = true;
1859             }
1860           }
1861 
1862           // traditional lightweight locking
1863           if (!success) {
<span class="line-modified">1864             markWord displaced = lockee-&gt;mark().set_unlocked();</span>
1865             entry-&gt;lock()-&gt;set_displaced_header(displaced);
1866             bool call_vm = UseHeavyMonitors;
<span class="line-modified">1867             if (call_vm || lockee-&gt;cas_set_mark(markWord::from_pointer(entry), displaced) != displaced) {</span>
1868               // Is it simple recursive case?
<span class="line-modified">1869               if (!call_vm &amp;&amp; THREAD-&gt;is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {</span>
<span class="line-modified">1870                 entry-&gt;lock()-&gt;set_displaced_header(markWord::from_pointer(NULL));</span>
1871               } else {
1872                 CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
1873               }
1874             }
1875           }
1876           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1877         } else {
1878           istate-&gt;set_msg(more_monitors);
1879           UPDATE_PC_AND_RETURN(0); // Re-execute
1880         }
1881       }
1882 
1883       CASE(_monitorexit): {
1884         oop lockee = STACK_OBJECT(-1);
1885         CHECK_NULL(lockee);
1886         // derefing&#39;s lockee ought to provoke implicit null check
1887         // find our monitor slot
1888         BasicObjectLock* limit = istate-&gt;monitor_base();
1889         BasicObjectLock* most_recent = (BasicObjectLock*) istate-&gt;stack_base();
1890         while (most_recent != limit ) {
1891           if ((most_recent)-&gt;obj() == lockee) {
1892             BasicLock* lock = most_recent-&gt;lock();
<span class="line-modified">1893             markWord header = lock-&gt;displaced_header();</span>
1894             most_recent-&gt;set_obj(NULL);
<span class="line-modified">1895             if (!lockee-&gt;mark().has_bias_pattern()) {</span>
1896               bool call_vm = UseHeavyMonitors;
1897               // If it isn&#39;t recursive we either must swap old header or call the runtime
<span class="line-modified">1898               if (header.to_pointer() != NULL || call_vm) {</span>
<span class="line-modified">1899                 markWord old_header = markWord::encode(lock);</span>
1900                 if (call_vm || lockee-&gt;cas_set_mark(header, old_header) != old_header) {
1901                   // restore object for the slow case
1902                   most_recent-&gt;set_obj(lockee);
1903                   CALL_VM(InterpreterRuntime::monitorexit(THREAD, most_recent), handle_exception);
1904                 }
1905               }
1906             }
1907             UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1908           }
1909           most_recent++;
1910         }
1911         // Need to throw illegal monitor state exception
1912         CALL_VM(InterpreterRuntime::throw_illegal_monitor_state_exception(THREAD), handle_exception);
1913         ShouldNotReachHere();
1914       }
1915 
1916       /* All of the non-quick opcodes. */
1917 
1918       /* -Set clobbersCpIndex true if the quickened opcode clobbers the
1919        *  constant pool index in the instruction.
</pre>
<hr />
<pre>
2146           InstanceKlass* ik = InstanceKlass::cast(entry);
2147           if (ik-&gt;is_initialized() &amp;&amp; ik-&gt;can_be_fastpath_allocated() ) {
2148             size_t obj_size = ik-&gt;size_helper();
2149             oop result = NULL;
2150             // If the TLAB isn&#39;t pre-zeroed then we&#39;ll have to do it
2151             bool need_zero = !ZeroTLAB;
2152             if (UseTLAB) {
2153               result = (oop) THREAD-&gt;tlab().allocate(obj_size);
2154             }
2155             // Disable non-TLAB-based fast-path, because profiling requires that all
2156             // allocations go through InterpreterRuntime::_new() if THREAD-&gt;tlab().allocate
2157             // returns NULL.
2158 #ifndef CC_INTERP_PROFILE
2159             if (result == NULL) {
2160               need_zero = true;
2161               // Try allocate in shared eden
2162             retry:
2163               HeapWord* compare_to = *Universe::heap()-&gt;top_addr();
2164               HeapWord* new_top = compare_to + obj_size;
2165               if (new_top &lt;= *Universe::heap()-&gt;end_addr()) {
<span class="line-modified">2166                 if (Atomic::cmpxchg(Universe::heap()-&gt;top_addr(), compare_to, new_top) != compare_to) {</span>
2167                   goto retry;
2168                 }
2169                 result = (oop) compare_to;
2170               }
2171             }
2172 #endif
2173             if (result != NULL) {
2174               // Initialize object (if nonzero size and need) and then the header
2175               if (need_zero ) {
<span class="line-modified">2176                 HeapWord* to_zero = cast_from_oop&lt;HeapWord*&gt;(result) + sizeof(oopDesc) / oopSize;</span>
2177                 obj_size -= sizeof(oopDesc) / oopSize;
2178                 if (obj_size &gt; 0 ) {
2179                   memset(to_zero, 0, obj_size * HeapWordSize);
2180                 }
2181               }
2182               if (UseBiasedLocking) {
2183                 result-&gt;set_mark(ik-&gt;prototype_header());
2184               } else {
<span class="line-modified">2185                 result-&gt;set_mark(markWord::prototype());</span>
2186               }
2187               result-&gt;set_klass_gap(0);
2188               result-&gt;set_klass(ik);
2189               // Must prevent reordering of stores for object initialization
2190               // with stores that publish the new object.
2191               OrderAccess::storestore();
2192               SET_STACK_OBJECT(result, 0);
2193               UPDATE_PC_AND_TOS_AND_CONTINUE(3, 1);
2194             }
2195           }
2196         }
2197         // Slow case allocation
2198         CALL_VM(InterpreterRuntime::_new(THREAD, METHOD-&gt;constants(), index),
2199                 handle_exception);
2200         // Must prevent reordering of stores for object initialization
2201         // with stores that publish the new object.
2202         OrderAccess::storestore();
2203         SET_STACK_OBJECT(THREAD-&gt;vm_result(), 0);
2204         THREAD-&gt;set_vm_result(NULL);
2205         UPDATE_PC_AND_TOS_AND_CONTINUE(3, 1);
</pre>
<hr />
<pre>
2419         u2 index;
2420         int incr;
2421         if (opcode == Bytecodes::_fast_aldc) {
2422           index = pc[1];
2423           incr = 2;
2424         } else {
2425           index = Bytes::get_native_u2(pc+1);
2426           incr = 3;
2427         }
2428 
2429         // We are resolved if the resolved_references array contains a non-null object (CallSite, etc.)
2430         // This kind of CP cache entry does not need to match the flags byte, because
2431         // there is a 1-1 relation between bytecode type and CP entry type.
2432         ConstantPool* constants = METHOD-&gt;constants();
2433         oop result = constants-&gt;resolved_references()-&gt;obj_at(index);
2434         if (result == NULL) {
2435           CALL_VM(InterpreterRuntime::resolve_ldc(THREAD, (Bytecodes::Code) opcode),
2436                   handle_exception);
2437           result = THREAD-&gt;vm_result();
2438         }
<span class="line-modified">2439         if (result == Universe::the_null_sentinel())</span>
2440           result = NULL;
2441 
2442         VERIFY_OOP(result);
2443         SET_STACK_OBJECT(result, 0);
2444         UPDATE_PC_AND_TOS_AND_CONTINUE(incr, 1);
2445       }
2446 
2447       CASE(_invokedynamic): {
2448 
2449         u4 index = Bytes::get_native_u4(pc+1);
2450         ConstantPoolCacheEntry* cache = cp-&gt;constant_pool()-&gt;invokedynamic_cp_cache_entry_at(index);
2451 
2452         // We are resolved if the resolved_references array contains a non-null object (CallSite, etc.)
2453         // This kind of CP cache entry does not need to match the flags byte, because
2454         // there is a 1-1 relation between bytecode type and CP entry type.
2455         if (! cache-&gt;is_resolved((Bytecodes::Code) opcode)) {
2456           CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
2457                   handle_exception);
2458           cache = cp-&gt;constant_pool()-&gt;invokedynamic_cp_cache_entry_at(index);
2459         }
2460 
2461         Method* method = cache-&gt;f1_as_method();
2462         if (VerifyOops) method-&gt;verify();
2463 
2464         if (cache-&gt;has_appendix()) {
<span class="line-modified">2465           constantPoolHandle cp(THREAD, METHOD-&gt;constants());</span>
<span class="line-modified">2466           SET_STACK_OBJECT(cache-&gt;appendix_if_resolved(cp), 0);</span>
2467           MORE_STACK(1);
2468         }
2469 
2470         istate-&gt;set_msg(call_method);
2471         istate-&gt;set_callee(method);
2472         istate-&gt;set_callee_entry_point(method-&gt;from_interpreted_entry());
2473         istate-&gt;set_bcp_advance(5);
2474 
2475         // Invokedynamic has got a call counter, just like an invokestatic -&gt; increment!
2476         BI_PROFILE_UPDATE_CALL();
2477 
2478         UPDATE_PC_AND_RETURN(0); // I&#39;ll be back...
2479       }
2480 
2481       CASE(_invokehandle): {
2482 
2483         u2 index = Bytes::get_native_u2(pc+1);
2484         ConstantPoolCacheEntry* cache = cp-&gt;entry_at(index);
2485 
2486         if (! cache-&gt;is_resolved((Bytecodes::Code) opcode)) {
2487           CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
2488                   handle_exception);
2489           cache = cp-&gt;entry_at(index);
2490         }
2491 
2492         Method* method = cache-&gt;f1_as_method();
2493         if (VerifyOops) method-&gt;verify();
2494 
2495         if (cache-&gt;has_appendix()) {
<span class="line-modified">2496           constantPoolHandle cp(THREAD, METHOD-&gt;constants());</span>
<span class="line-modified">2497           SET_STACK_OBJECT(cache-&gt;appendix_if_resolved(cp), 0);</span>
2498           MORE_STACK(1);
2499         }
2500 
2501         istate-&gt;set_msg(call_method);
2502         istate-&gt;set_callee(method);
2503         istate-&gt;set_callee_entry_point(method-&gt;from_interpreted_entry());
2504         istate-&gt;set_bcp_advance(3);
2505 
2506         // Invokehandle has got a call counter, just like a final call -&gt; increment!
2507         BI_PROFILE_UPDATE_FINALCALL();
2508 
2509         UPDATE_PC_AND_RETURN(0); // I&#39;ll be back...
2510       }
2511 
2512       CASE(_invokeinterface): {
2513         u2 index = Bytes::get_native_u2(pc+1);
2514 
2515         // QQQ Need to make this as inlined as possible. Probably need to split all the bytecode cases
2516         // out so c++ compiler has a chance for constant prop to fold everything possible away.
2517 
</pre>
<hr />
<pre>
2854     // expression stack is emptied
2855     topOfStack = istate-&gt;stack_base() - Interpreter::stackElementWords;
2856     CALL_VM(continuation_bci = (intptr_t)InterpreterRuntime::exception_handler_for_exception(THREAD, except_oop()),
2857             handle_exception);
2858 
2859     except_oop = Handle(THREAD, THREAD-&gt;vm_result());
2860     THREAD-&gt;set_vm_result(NULL);
2861     if (continuation_bci &gt;= 0) {
2862       // Place exception on top of stack
2863       SET_STACK_OBJECT(except_oop(), 0);
2864       MORE_STACK(1);
2865       pc = METHOD-&gt;code_base() + continuation_bci;
2866       if (log_is_enabled(Info, exceptions)) {
2867         ResourceMark rm(THREAD);
2868         stringStream tempst;
2869         tempst.print(&quot;interpreter method &lt;%s&gt;\n&quot;
2870                      &quot; at bci %d, continuing at %d for thread &quot; INTPTR_FORMAT,
2871                      METHOD-&gt;print_value_string(),
2872                      (int)(istate-&gt;bcp() - METHOD-&gt;code_base()),
2873                      (int)continuation_bci, p2i(THREAD));
<span class="line-modified">2874         Exceptions::log_exception(except_oop, tempst.as_string());</span>
2875       }
2876       // for AbortVMOnException flag
2877       Exceptions::debug_check_abort(except_oop);
2878 
2879       // Update profiling data.
2880       BI_PROFILE_ALIGN_TO_CURRENT_BCI();
2881       goto run;
2882     }
2883     if (log_is_enabled(Info, exceptions)) {
2884       ResourceMark rm;
2885       stringStream tempst;
2886       tempst.print(&quot;interpreter method &lt;%s&gt;\n&quot;
2887              &quot; at bci %d, unwinding for thread &quot; INTPTR_FORMAT,
2888              METHOD-&gt;print_value_string(),
2889              (int)(istate-&gt;bcp() - METHOD-&gt;code_base()),
2890              p2i(THREAD));
<span class="line-modified">2891       Exceptions::log_exception(except_oop, tempst.as_string());</span>
2892     }
2893     // for AbortVMOnException flag
2894     Exceptions::debug_check_abort(except_oop);
2895 
2896     // No handler in this activation, unwind and try again
2897     THREAD-&gt;set_pending_exception(except_oop(), NULL, 0);
2898     goto handle_return;
2899   }  // handle_exception:
2900 
2901   // Return from an interpreter invocation with the result of the interpretation
2902   // on the top of the Java Stack (or a pending exception)
2903 
2904   handle_Pop_Frame: {
2905 
2906     // We don&#39;t really do anything special here except we must be aware
2907     // that we can get here without ever locking the method (if sync).
2908     // Also we skip the notification of the exit.
2909 
2910     istate-&gt;set_msg(popping_frame);
2911     // Clear pending so while the pop is in process
</pre>
<hr />
<pre>
3018       // Another weird thing to watch for is if the method was locked
3019       // recursively and then not exited properly. This means we must
3020       // examine all the entries in reverse time(and stack) order and
3021       // unlock as we find them. If we find the method monitor before
3022       // we are at the initial entry then we should throw an exception.
3023       // It is not clear the template based interpreter does this
3024       // correctly
3025 
3026       BasicObjectLock* base = istate-&gt;monitor_base();
3027       BasicObjectLock* end = (BasicObjectLock*) istate-&gt;stack_base();
3028       bool method_unlock_needed = METHOD-&gt;is_synchronized();
3029       // We know the initial monitor was used for the method don&#39;t check that
3030       // slot in the loop
3031       if (method_unlock_needed) base--;
3032 
3033       // Check all the monitors to see they are unlocked. Install exception if found to be locked.
3034       while (end &lt; base) {
3035         oop lockee = end-&gt;obj();
3036         if (lockee != NULL) {
3037           BasicLock* lock = end-&gt;lock();
<span class="line-modified">3038           markWord header = lock-&gt;displaced_header();</span>
3039           end-&gt;set_obj(NULL);
3040 
<span class="line-modified">3041           if (!lockee-&gt;mark().has_bias_pattern()) {</span>
3042             // If it isn&#39;t recursive we either must swap old header or call the runtime
<span class="line-modified">3043             if (header.to_pointer() != NULL) {</span>
<span class="line-modified">3044               markWord old_header = markWord::encode(lock);</span>
3045               if (lockee-&gt;cas_set_mark(header, old_header) != old_header) {
3046                 // restore object for the slow case
3047                 end-&gt;set_obj(lockee);
3048                 {
3049                   // Prevent any HandleMarkCleaner from freeing our live handles
3050                   HandleMark __hm(THREAD);
3051                   CALL_VM_NOCHECK(InterpreterRuntime::monitorexit(THREAD, end));
3052                 }
3053               }
3054             }
3055           }
3056           // One error is plenty
3057           if (illegal_state_oop() == NULL &amp;&amp; !suppress_error) {
3058             {
3059               // Prevent any HandleMarkCleaner from freeing our live handles
3060               HandleMark __hm(THREAD);
3061               CALL_VM_NOCHECK(InterpreterRuntime::throw_illegal_monitor_state_exception(THREAD));
3062             }
3063             assert(THREAD-&gt;has_pending_exception(), &quot;Lost our exception!&quot;);
3064             illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
</pre>
<hr />
<pre>
3093           //
3094           oop rcvr = base-&gt;obj();
3095           if (rcvr == NULL) {
3096             if (!suppress_error) {
3097               VM_JAVA_ERROR_NO_JUMP(vmSymbols::java_lang_NullPointerException(), &quot;&quot;, note_nullCheck_trap);
3098               illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
3099               THREAD-&gt;clear_pending_exception();
3100             }
3101           } else if (UseHeavyMonitors) {
3102             {
3103               // Prevent any HandleMarkCleaner from freeing our live handles.
3104               HandleMark __hm(THREAD);
3105               CALL_VM_NOCHECK(InterpreterRuntime::monitorexit(THREAD, base));
3106             }
3107             if (THREAD-&gt;has_pending_exception()) {
3108               if (!suppress_error) illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
3109               THREAD-&gt;clear_pending_exception();
3110             }
3111           } else {
3112             BasicLock* lock = base-&gt;lock();
<span class="line-modified">3113             markWord header = lock-&gt;displaced_header();</span>
3114             base-&gt;set_obj(NULL);
3115 
<span class="line-modified">3116             if (!rcvr-&gt;mark().has_bias_pattern()) {</span>
3117               base-&gt;set_obj(NULL);
3118               // If it isn&#39;t recursive we either must swap old header or call the runtime
<span class="line-modified">3119               if (header.to_pointer() != NULL) {</span>
<span class="line-modified">3120                 markWord old_header = markWord::encode(lock);</span>
3121                 if (rcvr-&gt;cas_set_mark(header, old_header) != old_header) {
3122                   // restore object for the slow case
3123                   base-&gt;set_obj(rcvr);
3124                   {
3125                     // Prevent any HandleMarkCleaner from freeing our live handles
3126                     HandleMark __hm(THREAD);
3127                     CALL_VM_NOCHECK(InterpreterRuntime::monitorexit(THREAD, base));
3128                   }
3129                   if (THREAD-&gt;has_pending_exception()) {
3130                     if (!suppress_error) illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
3131                     THREAD-&gt;clear_pending_exception();
3132                   }
3133                 }
3134               }
3135             }
3136           }
3137         }
3138       }
3139     }
3140     // Clear the do_not_unlock flag now.
</pre>
</td>
</tr>
</table>
<center><a href="bytecode.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="bytecodeStream.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>