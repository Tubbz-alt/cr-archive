<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/code/dependencyContext.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="dependencies.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="dependencyContext.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/code/dependencyContext.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;code/nmethod.hpp&quot;
 27 #include &quot;code/dependencies.hpp&quot;
 28 #include &quot;code/dependencyContext.hpp&quot;
 29 #include &quot;memory/resourceArea.hpp&quot;
 30 #include &quot;runtime/atomic.hpp&quot;

 31 #include &quot;runtime/perfData.hpp&quot;
 32 #include &quot;utilities/exceptions.hpp&quot;
 33 
 34 PerfCounter* DependencyContext::_perf_total_buckets_allocated_count   = NULL;
 35 PerfCounter* DependencyContext::_perf_total_buckets_deallocated_count = NULL;
 36 PerfCounter* DependencyContext::_perf_total_buckets_stale_count       = NULL;
 37 PerfCounter* DependencyContext::_perf_total_buckets_stale_acc_count   = NULL;
 38 nmethodBucket* volatile DependencyContext::_purge_list                = NULL;
 39 volatile uint64_t DependencyContext::_cleaning_epoch                  = 0;
 40 uint64_t  DependencyContext::_cleaning_epoch_monotonic                = 0;
 41 
 42 void dependencyContext_init() {
 43   DependencyContext::init();
 44 }
 45 
 46 void DependencyContext::init() {
 47   if (UsePerfData) {
 48     EXCEPTION_MARK;
 49     _perf_total_buckets_allocated_count =
 50         PerfDataManager::create_counter(SUN_CI, &quot;nmethodBucketsAllocated&quot;, PerfData::U_Events, CHECK);
</pre>
<hr />
<pre>
 84 }
 85 
 86 //
 87 // Add an nmethod to the dependency context.
 88 // It&#39;s possible that an nmethod has multiple dependencies on a klass
 89 // so a count is kept for each bucket to guarantee that creation and
 90 // deletion of dependencies is consistent.
 91 //
 92 void DependencyContext::add_dependent_nmethod(nmethod* nm) {
 93   assert_lock_strong(CodeCache_lock);
 94   for (nmethodBucket* b = dependencies_not_unloading(); b != NULL; b = b-&gt;next_not_unloading()) {
 95     if (nm == b-&gt;get_nmethod()) {
 96       b-&gt;increment();
 97       return;
 98     }
 99   }
100   nmethodBucket* new_head = new nmethodBucket(nm, NULL);
101   for (;;) {
102     nmethodBucket* head = Atomic::load(_dependency_context_addr);
103     new_head-&gt;set_next(head);
<span class="line-modified">104     if (Atomic::cmpxchg(new_head, _dependency_context_addr, head) == head) {</span>
105       break;
106     }
107   }
108   if (UsePerfData) {
109     _perf_total_buckets_allocated_count-&gt;inc();
110   }
111 }
112 
113 void DependencyContext::release(nmethodBucket* b) {
114   bool expunge = Atomic::load(&amp;_cleaning_epoch) == 0;
115   if (expunge) {
116     assert_locked_or_safepoint(CodeCache_lock);
117     delete b;
118     if (UsePerfData) {
119       _perf_total_buckets_deallocated_count-&gt;inc();
120     }
121   } else {
122     // Mark the context as having stale entries, since it is not safe to
123     // expunge the list right now.
124     for (;;) {
125       nmethodBucket* purge_list_head = Atomic::load(&amp;_purge_list);
126       b-&gt;set_purge_list_next(purge_list_head);
<span class="line-modified">127       if (Atomic::cmpxchg(b, &amp;_purge_list, purge_list_head) == purge_list_head) {</span>
128         break;
129       }
130     }
131     if (UsePerfData) {
132       _perf_total_buckets_stale_count-&gt;inc();
133       _perf_total_buckets_stale_acc_count-&gt;inc();
134     }
135   }
136 }
137 
138 //
139 // Remove an nmethod dependency from the context.
140 // Decrement count of the nmethod in the dependency list and, optionally, remove
141 // the bucket completely when the count goes to 0.  This method must find
142 // a corresponding bucket otherwise there&#39;s a bug in the recording of dependencies.
143 // Can be called concurrently by parallel GC threads.
144 //
145 void DependencyContext::remove_dependent_nmethod(nmethod* nm) {
146   assert_locked_or_safepoint(CodeCache_lock);
147   nmethodBucket* first = dependencies_not_unloading();
</pre>
<hr />
<pre>
243     }
244   }
245 }
246 
247 bool DependencyContext::is_dependent_nmethod(nmethod* nm) {
248   for (nmethodBucket* b = dependencies_not_unloading(); b != NULL; b = b-&gt;next_not_unloading()) {
249     if (nm == b-&gt;get_nmethod()) {
250 #ifdef ASSERT
251       int count = b-&gt;count();
252       assert(count &gt;= 0, &quot;count shouldn&#39;t be negative: %d&quot;, count);
253 #endif
254       return true;
255     }
256   }
257   return false;
258 }
259 
260 #endif //PRODUCT
261 
262 int nmethodBucket::decrement() {
<span class="line-modified">263   return Atomic::sub(1, &amp;_count);</span>
264 }
265 
266 // We use a monotonically increasing epoch counter to track the last epoch a given
267 // dependency context was cleaned. GC threads claim cleanup tasks by performing
268 // a CAS on this value.
269 bool DependencyContext::claim_cleanup() {
270   uint64_t cleaning_epoch = Atomic::load(&amp;_cleaning_epoch);
271   uint64_t last_cleanup = Atomic::load(_last_cleanup_addr);
272   if (last_cleanup &gt;= cleaning_epoch) {
273     return false;
274   }
<span class="line-modified">275   return Atomic::cmpxchg(cleaning_epoch, _last_cleanup_addr, last_cleanup) == last_cleanup;</span>
276 }
277 
278 // Retrieve the first nmethodBucket that has a dependent that does not correspond to
279 // an is_unloading nmethod. Any nmethodBucket entries observed from the original head
280 // that is_unloading() will be unlinked and placed on the purge list.
281 nmethodBucket* DependencyContext::dependencies_not_unloading() {
282   for (;;) {
283     // Need acquire becase the read value could come from a concurrent insert.
<span class="line-modified">284     nmethodBucket* head = OrderAccess::load_acquire(_dependency_context_addr);</span>
285     if (head == NULL || !head-&gt;get_nmethod()-&gt;is_unloading()) {
286       return head;
287     }
288     nmethodBucket* head_next = head-&gt;next();
289     OrderAccess::loadload();
290     if (Atomic::load(_dependency_context_addr) != head) {
291       // Unstable load of head w.r.t. head-&gt;next
292       continue;
293     }
<span class="line-modified">294     if (Atomic::cmpxchg(head_next, _dependency_context_addr, head) == head) {</span>
295       // Release is_unloading entries if unlinking was claimed
296       DependencyContext::release(head);
297     }
298   }
299 }
300 
301 // Relaxed accessors
302 void DependencyContext::set_dependencies(nmethodBucket* b) {
<span class="line-modified">303   Atomic::store(b, _dependency_context_addr);</span>
304 }
305 
306 nmethodBucket* DependencyContext::dependencies() {
307   return Atomic::load(_dependency_context_addr);
308 }
309 
310 // After the gc_prologue, the dependency contexts may be claimed by the GC
311 // and releasing of nmethodBucket entries will be deferred and placed on
312 // a purge list to be deleted later.
313 void DependencyContext::cleaning_start() {
314   assert(SafepointSynchronize::is_at_safepoint(), &quot;must be&quot;);
315   uint64_t epoch = ++_cleaning_epoch_monotonic;
<span class="line-modified">316   Atomic::store(epoch, &amp;_cleaning_epoch);</span>
317 }
318 
319 // The epilogue marks the end of dependency context cleanup by the GC,
320 // and also makes subsequent releases of nmethodBuckets cause immediate
321 // deletion. It is okay to delay calling of cleaning_end() to a concurrent
322 // phase, subsequent to the safepoint operation in which cleaning_start()
323 // was called. That allows dependency contexts to be cleaned concurrently.
324 void DependencyContext::cleaning_end() {
325   uint64_t epoch = 0;
<span class="line-modified">326   Atomic::store(epoch, &amp;_cleaning_epoch);</span>
327 }
328 
329 // This function skips over nmethodBuckets in the list corresponding to
330 // nmethods that are is_unloading. This allows exposing a view of the
331 // dependents as-if they were already cleaned, despite being cleaned
332 // concurrently. Any entry observed that is_unloading() will be unlinked
333 // and placed on the purge list.
334 nmethodBucket* nmethodBucket::next_not_unloading() {
335   for (;;) {
336     // Do not need acquire because the loaded entry can never be
337     // concurrently inserted.
338     nmethodBucket* next = Atomic::load(&amp;_next);
339     if (next == NULL || !next-&gt;get_nmethod()-&gt;is_unloading()) {
340       return next;
341     }
342     nmethodBucket* next_next = Atomic::load(&amp;next-&gt;_next);
343     OrderAccess::loadload();
344     if (Atomic::load(&amp;_next) != next) {
345       // Unstable load of next w.r.t. next-&gt;next
346       continue;
347     }
<span class="line-modified">348     if (Atomic::cmpxchg(next_next, &amp;_next, next) == next) {</span>
349       // Release is_unloading entries if unlinking was claimed
350       DependencyContext::release(next);
351     }
352   }
353 }
354 
355 // Relaxed accessors
356 nmethodBucket* nmethodBucket::next() {
357   return Atomic::load(&amp;_next);
358 }
359 
360 void nmethodBucket::set_next(nmethodBucket* b) {
<span class="line-modified">361   Atomic::store(b, &amp;_next);</span>
362 }
363 
364 nmethodBucket* nmethodBucket::purge_list_next() {
365   return Atomic::load(&amp;_purge_list_next);
366 }
367 
368 void nmethodBucket::set_purge_list_next(nmethodBucket* b) {
<span class="line-modified">369   Atomic::store(b, &amp;_purge_list_next);</span>
370 }
</pre>
</td>
<td>
<hr />
<pre>
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;code/nmethod.hpp&quot;
 27 #include &quot;code/dependencies.hpp&quot;
 28 #include &quot;code/dependencyContext.hpp&quot;
 29 #include &quot;memory/resourceArea.hpp&quot;
 30 #include &quot;runtime/atomic.hpp&quot;
<span class="line-added"> 31 #include &quot;runtime/orderAccess.hpp&quot;</span>
 32 #include &quot;runtime/perfData.hpp&quot;
 33 #include &quot;utilities/exceptions.hpp&quot;
 34 
 35 PerfCounter* DependencyContext::_perf_total_buckets_allocated_count   = NULL;
 36 PerfCounter* DependencyContext::_perf_total_buckets_deallocated_count = NULL;
 37 PerfCounter* DependencyContext::_perf_total_buckets_stale_count       = NULL;
 38 PerfCounter* DependencyContext::_perf_total_buckets_stale_acc_count   = NULL;
 39 nmethodBucket* volatile DependencyContext::_purge_list                = NULL;
 40 volatile uint64_t DependencyContext::_cleaning_epoch                  = 0;
 41 uint64_t  DependencyContext::_cleaning_epoch_monotonic                = 0;
 42 
 43 void dependencyContext_init() {
 44   DependencyContext::init();
 45 }
 46 
 47 void DependencyContext::init() {
 48   if (UsePerfData) {
 49     EXCEPTION_MARK;
 50     _perf_total_buckets_allocated_count =
 51         PerfDataManager::create_counter(SUN_CI, &quot;nmethodBucketsAllocated&quot;, PerfData::U_Events, CHECK);
</pre>
<hr />
<pre>
 85 }
 86 
 87 //
 88 // Add an nmethod to the dependency context.
 89 // It&#39;s possible that an nmethod has multiple dependencies on a klass
 90 // so a count is kept for each bucket to guarantee that creation and
 91 // deletion of dependencies is consistent.
 92 //
 93 void DependencyContext::add_dependent_nmethod(nmethod* nm) {
 94   assert_lock_strong(CodeCache_lock);
 95   for (nmethodBucket* b = dependencies_not_unloading(); b != NULL; b = b-&gt;next_not_unloading()) {
 96     if (nm == b-&gt;get_nmethod()) {
 97       b-&gt;increment();
 98       return;
 99     }
100   }
101   nmethodBucket* new_head = new nmethodBucket(nm, NULL);
102   for (;;) {
103     nmethodBucket* head = Atomic::load(_dependency_context_addr);
104     new_head-&gt;set_next(head);
<span class="line-modified">105     if (Atomic::cmpxchg(_dependency_context_addr, head, new_head) == head) {</span>
106       break;
107     }
108   }
109   if (UsePerfData) {
110     _perf_total_buckets_allocated_count-&gt;inc();
111   }
112 }
113 
114 void DependencyContext::release(nmethodBucket* b) {
115   bool expunge = Atomic::load(&amp;_cleaning_epoch) == 0;
116   if (expunge) {
117     assert_locked_or_safepoint(CodeCache_lock);
118     delete b;
119     if (UsePerfData) {
120       _perf_total_buckets_deallocated_count-&gt;inc();
121     }
122   } else {
123     // Mark the context as having stale entries, since it is not safe to
124     // expunge the list right now.
125     for (;;) {
126       nmethodBucket* purge_list_head = Atomic::load(&amp;_purge_list);
127       b-&gt;set_purge_list_next(purge_list_head);
<span class="line-modified">128       if (Atomic::cmpxchg(&amp;_purge_list, purge_list_head, b) == purge_list_head) {</span>
129         break;
130       }
131     }
132     if (UsePerfData) {
133       _perf_total_buckets_stale_count-&gt;inc();
134       _perf_total_buckets_stale_acc_count-&gt;inc();
135     }
136   }
137 }
138 
139 //
140 // Remove an nmethod dependency from the context.
141 // Decrement count of the nmethod in the dependency list and, optionally, remove
142 // the bucket completely when the count goes to 0.  This method must find
143 // a corresponding bucket otherwise there&#39;s a bug in the recording of dependencies.
144 // Can be called concurrently by parallel GC threads.
145 //
146 void DependencyContext::remove_dependent_nmethod(nmethod* nm) {
147   assert_locked_or_safepoint(CodeCache_lock);
148   nmethodBucket* first = dependencies_not_unloading();
</pre>
<hr />
<pre>
244     }
245   }
246 }
247 
248 bool DependencyContext::is_dependent_nmethod(nmethod* nm) {
249   for (nmethodBucket* b = dependencies_not_unloading(); b != NULL; b = b-&gt;next_not_unloading()) {
250     if (nm == b-&gt;get_nmethod()) {
251 #ifdef ASSERT
252       int count = b-&gt;count();
253       assert(count &gt;= 0, &quot;count shouldn&#39;t be negative: %d&quot;, count);
254 #endif
255       return true;
256     }
257   }
258   return false;
259 }
260 
261 #endif //PRODUCT
262 
263 int nmethodBucket::decrement() {
<span class="line-modified">264   return Atomic::sub(&amp;_count, 1);</span>
265 }
266 
267 // We use a monotonically increasing epoch counter to track the last epoch a given
268 // dependency context was cleaned. GC threads claim cleanup tasks by performing
269 // a CAS on this value.
270 bool DependencyContext::claim_cleanup() {
271   uint64_t cleaning_epoch = Atomic::load(&amp;_cleaning_epoch);
272   uint64_t last_cleanup = Atomic::load(_last_cleanup_addr);
273   if (last_cleanup &gt;= cleaning_epoch) {
274     return false;
275   }
<span class="line-modified">276   return Atomic::cmpxchg(_last_cleanup_addr, last_cleanup, cleaning_epoch) == last_cleanup;</span>
277 }
278 
279 // Retrieve the first nmethodBucket that has a dependent that does not correspond to
280 // an is_unloading nmethod. Any nmethodBucket entries observed from the original head
281 // that is_unloading() will be unlinked and placed on the purge list.
282 nmethodBucket* DependencyContext::dependencies_not_unloading() {
283   for (;;) {
284     // Need acquire becase the read value could come from a concurrent insert.
<span class="line-modified">285     nmethodBucket* head = Atomic::load_acquire(_dependency_context_addr);</span>
286     if (head == NULL || !head-&gt;get_nmethod()-&gt;is_unloading()) {
287       return head;
288     }
289     nmethodBucket* head_next = head-&gt;next();
290     OrderAccess::loadload();
291     if (Atomic::load(_dependency_context_addr) != head) {
292       // Unstable load of head w.r.t. head-&gt;next
293       continue;
294     }
<span class="line-modified">295     if (Atomic::cmpxchg(_dependency_context_addr, head, head_next) == head) {</span>
296       // Release is_unloading entries if unlinking was claimed
297       DependencyContext::release(head);
298     }
299   }
300 }
301 
302 // Relaxed accessors
303 void DependencyContext::set_dependencies(nmethodBucket* b) {
<span class="line-modified">304   Atomic::store(_dependency_context_addr, b);</span>
305 }
306 
307 nmethodBucket* DependencyContext::dependencies() {
308   return Atomic::load(_dependency_context_addr);
309 }
310 
311 // After the gc_prologue, the dependency contexts may be claimed by the GC
312 // and releasing of nmethodBucket entries will be deferred and placed on
313 // a purge list to be deleted later.
314 void DependencyContext::cleaning_start() {
315   assert(SafepointSynchronize::is_at_safepoint(), &quot;must be&quot;);
316   uint64_t epoch = ++_cleaning_epoch_monotonic;
<span class="line-modified">317   Atomic::store(&amp;_cleaning_epoch, epoch);</span>
318 }
319 
320 // The epilogue marks the end of dependency context cleanup by the GC,
321 // and also makes subsequent releases of nmethodBuckets cause immediate
322 // deletion. It is okay to delay calling of cleaning_end() to a concurrent
323 // phase, subsequent to the safepoint operation in which cleaning_start()
324 // was called. That allows dependency contexts to be cleaned concurrently.
325 void DependencyContext::cleaning_end() {
326   uint64_t epoch = 0;
<span class="line-modified">327   Atomic::store(&amp;_cleaning_epoch, epoch);</span>
328 }
329 
330 // This function skips over nmethodBuckets in the list corresponding to
331 // nmethods that are is_unloading. This allows exposing a view of the
332 // dependents as-if they were already cleaned, despite being cleaned
333 // concurrently. Any entry observed that is_unloading() will be unlinked
334 // and placed on the purge list.
335 nmethodBucket* nmethodBucket::next_not_unloading() {
336   for (;;) {
337     // Do not need acquire because the loaded entry can never be
338     // concurrently inserted.
339     nmethodBucket* next = Atomic::load(&amp;_next);
340     if (next == NULL || !next-&gt;get_nmethod()-&gt;is_unloading()) {
341       return next;
342     }
343     nmethodBucket* next_next = Atomic::load(&amp;next-&gt;_next);
344     OrderAccess::loadload();
345     if (Atomic::load(&amp;_next) != next) {
346       // Unstable load of next w.r.t. next-&gt;next
347       continue;
348     }
<span class="line-modified">349     if (Atomic::cmpxchg(&amp;_next, next, next_next) == next) {</span>
350       // Release is_unloading entries if unlinking was claimed
351       DependencyContext::release(next);
352     }
353   }
354 }
355 
356 // Relaxed accessors
357 nmethodBucket* nmethodBucket::next() {
358   return Atomic::load(&amp;_next);
359 }
360 
361 void nmethodBucket::set_next(nmethodBucket* b) {
<span class="line-modified">362   Atomic::store(&amp;_next, b);</span>
363 }
364 
365 nmethodBucket* nmethodBucket::purge_list_next() {
366   return Atomic::load(&amp;_purge_list_next);
367 }
368 
369 void nmethodBucket::set_purge_list_next(nmethodBucket* b) {
<span class="line-modified">370   Atomic::store(&amp;_purge_list_next, b);</span>
371 }
</pre>
</td>
</tr>
</table>
<center><a href="dependencies.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="dependencyContext.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>