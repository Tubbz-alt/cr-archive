<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff src/hotspot/share/memory/metaspace.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="memRegion.hpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="metaspace.hpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/memory/metaspace.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 37,17 ***</span>
  #include &quot;memory/metaspace/spaceManager.hpp&quot;
  #include &quot;memory/metaspace/virtualSpaceList.hpp&quot;
  #include &quot;memory/metaspaceShared.hpp&quot;
  #include &quot;memory/metaspaceTracer.hpp&quot;
  #include &quot;memory/universe.hpp&quot;
  #include &quot;runtime/init.hpp&quot;
<span class="line-removed">- #include &quot;runtime/orderAccess.hpp&quot;</span>
  #include &quot;services/memTracker.hpp&quot;
  #include &quot;utilities/copy.hpp&quot;
  #include &quot;utilities/debug.hpp&quot;
  #include &quot;utilities/formatBuffer.hpp&quot;
  #include &quot;utilities/globalDefinitions.hpp&quot;
  
  
  using namespace metaspace;
  
  MetaWord* last_allocated = 0;
<span class="line-new-header">--- 37,19 ---</span>
  #include &quot;memory/metaspace/spaceManager.hpp&quot;
  #include &quot;memory/metaspace/virtualSpaceList.hpp&quot;
  #include &quot;memory/metaspaceShared.hpp&quot;
  #include &quot;memory/metaspaceTracer.hpp&quot;
  #include &quot;memory/universe.hpp&quot;
<span class="line-added">+ #include &quot;oops/compressedOops.hpp&quot;</span>
<span class="line-added">+ #include &quot;runtime/atomic.hpp&quot;</span>
  #include &quot;runtime/init.hpp&quot;
  #include &quot;services/memTracker.hpp&quot;
  #include &quot;utilities/copy.hpp&quot;
  #include &quot;utilities/debug.hpp&quot;
  #include &quot;utilities/formatBuffer.hpp&quot;
  #include &quot;utilities/globalDefinitions.hpp&quot;
<span class="line-added">+ #include &quot;utilities/vmError.hpp&quot;</span>
  
  
  using namespace metaspace;
  
  MetaWord* last_allocated = 0;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 69,11 ***</span>
    return s;
  }
  
  volatile size_t MetaspaceGC::_capacity_until_GC = 0;
  uint MetaspaceGC::_shrink_factor = 0;
<span class="line-removed">- bool MetaspaceGC::_should_concurrent_collect = false;</span>
  
  // BlockFreelist methods
  
  // VirtualSpaceNode methods
  
<span class="line-new-header">--- 71,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 125,11 ***</span>
  
    return delta;
  }
  
  size_t MetaspaceGC::capacity_until_GC() {
<span class="line-modified">!   size_t value = OrderAccess::load_acquire(&amp;_capacity_until_GC);</span>
    assert(value &gt;= MetaspaceSize, &quot;Not initialized properly?&quot;);
    return value;
  }
  
  // Try to increase the _capacity_until_GC limit counter by v bytes.
<span class="line-new-header">--- 126,11 ---</span>
  
    return delta;
  }
  
  size_t MetaspaceGC::capacity_until_GC() {
<span class="line-modified">!   size_t value = Atomic::load_acquire(&amp;_capacity_until_GC);</span>
    assert(value &gt;= MetaspaceSize, &quot;Not initialized properly?&quot;);
    return value;
  }
  
  // Try to increase the _capacity_until_GC limit counter by v bytes.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 159,11 ***</span>
    }
  
    if (can_retry != NULL) {
      *can_retry = true;
    }
<span class="line-modified">!   size_t prev_value = Atomic::cmpxchg(new_value, &amp;_capacity_until_GC, old_capacity_until_GC);</span>
  
    if (old_capacity_until_GC != prev_value) {
      return false;
    }
  
<span class="line-new-header">--- 160,11 ---</span>
    }
  
    if (can_retry != NULL) {
      *can_retry = true;
    }
<span class="line-modified">!   size_t prev_value = Atomic::cmpxchg(&amp;_capacity_until_GC, old_capacity_until_GC, new_value);</span>
  
    if (old_capacity_until_GC != prev_value) {
      return false;
    }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 177,11 ***</span>
  }
  
  size_t MetaspaceGC::dec_capacity_until_GC(size_t v) {
    assert_is_aligned(v, Metaspace::commit_alignment());
  
<span class="line-modified">!   return Atomic::sub(v, &amp;_capacity_until_GC);</span>
  }
  
  void MetaspaceGC::initialize() {
    // Set the high-water mark to MaxMetapaceSize during VM initializaton since
    // we can&#39;t do a GC during initialization.
<span class="line-new-header">--- 178,11 ---</span>
  }
  
  size_t MetaspaceGC::dec_capacity_until_GC(size_t v) {
    assert_is_aligned(v, Metaspace::commit_alignment());
  
<span class="line-modified">!   return Atomic::sub(&amp;_capacity_until_GC, v);</span>
  }
  
  void MetaspaceGC::initialize() {
    // Set the high-water mark to MaxMetapaceSize during VM initializaton since
    // we can&#39;t do a GC during initialization.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 391,19 ***</span>
           size_now, words);
    *pstat = size_now - words;
  }
  
  static void inc_stat_atomically(volatile size_t* pstat, size_t words) {
<span class="line-modified">!   Atomic::add(words, pstat);</span>
  }
  
  static void dec_stat_atomically(volatile size_t* pstat, size_t words) {
    const size_t size_now = *pstat;
    assert(size_now &gt;= words, &quot;About to decrement counter below zero &quot;
           &quot;(current value: &quot; SIZE_FORMAT &quot;, decrement value: &quot; SIZE_FORMAT &quot;.&quot;,
           size_now, words);
<span class="line-modified">!   Atomic::sub(words, pstat);</span>
  }
  
  void MetaspaceUtils::dec_capacity(Metaspace::MetadataType mdtype, size_t words) {
    dec_stat_nonatomically(&amp;_capacity_words[mdtype], words);
  }
<span class="line-new-header">--- 392,19 ---</span>
           size_now, words);
    *pstat = size_now - words;
  }
  
  static void inc_stat_atomically(volatile size_t* pstat, size_t words) {
<span class="line-modified">!   Atomic::add(pstat, words);</span>
  }
  
  static void dec_stat_atomically(volatile size_t* pstat, size_t words) {
    const size_t size_now = *pstat;
    assert(size_now &gt;= words, &quot;About to decrement counter below zero &quot;
           &quot;(current value: &quot; SIZE_FORMAT &quot;, decrement value: &quot; SIZE_FORMAT &quot;.&quot;,
           size_now, words);
<span class="line-modified">!   Atomic::sub(pstat, words);</span>
  }
  
  void MetaspaceUtils::dec_capacity(Metaspace::MetadataType mdtype, size_t words) {
    dec_stat_nonatomically(&amp;_capacity_words[mdtype], words);
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 467,13 ***</span>
  
    const ChunkManager* cm = Metaspace::get_chunk_manager(mdtype);
    return cm-&gt;chunk_free_list_summary();
  }
  
<span class="line-modified">! void MetaspaceUtils::print_metaspace_change(size_t prev_metadata_used) {</span>
<span class="line-modified">!   log_info(gc, metaspace)(&quot;Metaspace: &quot;  SIZE_FORMAT &quot;K-&gt;&quot; SIZE_FORMAT &quot;K(&quot;  SIZE_FORMAT &quot;K)&quot;,</span>
<span class="line-modified">!                           prev_metadata_used/K, used_bytes()/K, reserved_bytes()/K);</span>
  }
  
  void MetaspaceUtils::print_on(outputStream* out) {
    Metaspace::MetadataType nct = Metaspace::NonClassType;
  
<span class="line-new-header">--- 468,40 ---</span>
  
    const ChunkManager* cm = Metaspace::get_chunk_manager(mdtype);
    return cm-&gt;chunk_free_list_summary();
  }
  
<span class="line-modified">! void MetaspaceUtils::print_metaspace_change(const metaspace::MetaspaceSizesSnapshot&amp; pre_meta_values) {</span>
<span class="line-modified">!   const metaspace::MetaspaceSizesSnapshot meta_values;</span>
<span class="line-modified">! </span>
<span class="line-added">+   if (Metaspace::using_class_space()) {</span>
<span class="line-added">+     log_info(gc, metaspace)(HEAP_CHANGE_FORMAT&quot; &quot;</span>
<span class="line-added">+                             HEAP_CHANGE_FORMAT&quot; &quot;</span>
<span class="line-added">+                             HEAP_CHANGE_FORMAT,</span>
<span class="line-added">+                             HEAP_CHANGE_FORMAT_ARGS(&quot;Metaspace&quot;,</span>
<span class="line-added">+                                                     pre_meta_values.used(),</span>
<span class="line-added">+                                                     pre_meta_values.committed(),</span>
<span class="line-added">+                                                     meta_values.used(),</span>
<span class="line-added">+                                                     meta_values.committed()),</span>
<span class="line-added">+                             HEAP_CHANGE_FORMAT_ARGS(&quot;NonClass&quot;,</span>
<span class="line-added">+                                                     pre_meta_values.non_class_used(),</span>
<span class="line-added">+                                                     pre_meta_values.non_class_committed(),</span>
<span class="line-added">+                                                     meta_values.non_class_used(),</span>
<span class="line-added">+                                                     meta_values.non_class_committed()),</span>
<span class="line-added">+                             HEAP_CHANGE_FORMAT_ARGS(&quot;Class&quot;,</span>
<span class="line-added">+                                                     pre_meta_values.class_used(),</span>
<span class="line-added">+                                                     pre_meta_values.class_committed(),</span>
<span class="line-added">+                                                     meta_values.class_used(),</span>
<span class="line-added">+                                                     meta_values.class_committed()));</span>
<span class="line-added">+   } else {</span>
<span class="line-added">+     log_info(gc, metaspace)(HEAP_CHANGE_FORMAT,</span>
<span class="line-added">+                             HEAP_CHANGE_FORMAT_ARGS(&quot;Metaspace&quot;,</span>
<span class="line-added">+                                                     pre_meta_values.used(),</span>
<span class="line-added">+                                                     pre_meta_values.committed(),</span>
<span class="line-added">+                                                     meta_values.used(),</span>
<span class="line-added">+                                                     meta_values.committed()));</span>
<span class="line-added">+   }</span>
  }
  
  void MetaspaceUtils::print_on(outputStream* out) {
    Metaspace::MetadataType nct = Metaspace::NonClassType;
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 532,14 ***</span>
<span class="line-new-header">--- 560,36 ---</span>
        out-&gt;print_cr(&quot; committed &quot;);
      }
    }
  }
  
<span class="line-added">+ static void print_basic_switches(outputStream* out, size_t scale) {</span>
<span class="line-added">+   out-&gt;print(&quot;MaxMetaspaceSize: &quot;);</span>
<span class="line-added">+   if (MaxMetaspaceSize &gt;= (max_uintx) - (2 * os::vm_page_size())) {</span>
<span class="line-added">+     // aka &quot;very big&quot;. Default is max_uintx, but due to rounding in arg parsing the real</span>
<span class="line-added">+     // value is smaller.</span>
<span class="line-added">+     out-&gt;print(&quot;unlimited&quot;);</span>
<span class="line-added">+   } else {</span>
<span class="line-added">+     print_human_readable_size(out, MaxMetaspaceSize, scale);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   out-&gt;cr();</span>
<span class="line-added">+   if (Metaspace::using_class_space()) {</span>
<span class="line-added">+     out-&gt;print(&quot;CompressedClassSpaceSize: &quot;);</span>
<span class="line-added">+     print_human_readable_size(out, CompressedClassSpaceSize, scale);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   out-&gt;cr();</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  // This will print out a basic metaspace usage report but
  // unlike print_report() is guaranteed not to lock or to walk the CLDG.
  void MetaspaceUtils::print_basic_report(outputStream* out, size_t scale) {
  
<span class="line-added">+   if (!Metaspace::initialized()) {</span>
<span class="line-added">+     out-&gt;print_cr(&quot;Metaspace not yet initialized.&quot;);</span>
<span class="line-added">+     return;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    out-&gt;cr();
    out-&gt;print_cr(&quot;Usage:&quot;);
  
    if (Metaspace::using_class_space()) {
      out-&gt;print(&quot;  Non-class:  &quot;);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 612,16 ***</span>
<span class="line-new-header">--- 662,27 ---</span>
      out-&gt;print(&quot;        Both:  &quot;);
      print_human_readable_size(out, Metaspace::chunk_manager_class()-&gt;free_chunks_total_bytes() +
                                Metaspace::chunk_manager_metadata()-&gt;free_chunks_total_bytes(), scale);
      out-&gt;cr();
    }
<span class="line-added">+ </span>
<span class="line-added">+   out-&gt;cr();</span>
<span class="line-added">+ </span>
<span class="line-added">+   // Print basic settings</span>
<span class="line-added">+   print_basic_switches(out, scale);</span>
<span class="line-added">+ </span>
    out-&gt;cr();
  
  }
  
  void MetaspaceUtils::print_report(outputStream* out, size_t scale, int flags) {
  
<span class="line-added">+   if (!Metaspace::initialized()) {</span>
<span class="line-added">+     out-&gt;print_cr(&quot;Metaspace not yet initialized.&quot;);</span>
<span class="line-added">+     return;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    const bool print_loaders = (flags &amp; rf_show_loaders) &gt; 0;
    const bool print_classes = (flags &amp; rf_show_classes) &gt; 0;
    const bool print_by_chunktype = (flags &amp; rf_break_down_by_chunktype) &gt; 0;
    const bool print_by_spacetype = (flags &amp; rf_break_down_by_spacetype) &gt; 0;
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 641,27 ***</span>
      out-&gt;print_cr(&quot;Usage per space type:&quot;);
      out-&gt;cr();
      for (int space_type = (int)Metaspace::ZeroMetaspaceType;
           space_type &lt; (int)Metaspace::MetaspaceTypeCount; space_type ++)
      {
<span class="line-modified">!       uintx num = cl._num_loaders_by_spacetype[space_type];</span>
<span class="line-modified">!       out-&gt;print(&quot;%s (&quot; UINTX_FORMAT &quot; loader%s)%c&quot;,</span>
          space_type_name((Metaspace::MetaspaceType)space_type),
<span class="line-modified">!         num, (num == 1 ? &quot;&quot; : &quot;s&quot;), (num &gt; 0 ? &#39;:&#39; : &#39;.&#39;));</span>
<span class="line-modified">!       if (num &gt; 0) {</span>
          cl._stats_by_spacetype[space_type].print_on(out, scale, print_by_chunktype);
        }
        out-&gt;cr();
      }
    }
  
    // Print totals for in-use data:
    out-&gt;cr();
<span class="line-modified">!   out-&gt;print_cr(&quot;Total Usage ( &quot; UINTX_FORMAT &quot; loader%s)%c&quot;,</span>
<span class="line-modified">!       cl._num_loaders, (cl._num_loaders == 1 ? &quot;&quot; : &quot;s&quot;), (cl._num_loaders &gt; 0 ? &#39;:&#39; : &#39;.&#39;));</span>
<span class="line-modified">! </span>
<span class="line-modified">!   cl._stats_total.print_on(out, scale, print_by_chunktype);</span>
  
    // -- Print Virtual space.
    out-&gt;cr();
    out-&gt;print_cr(&quot;Virtual space:&quot;);
  
<span class="line-new-header">--- 702,39 ---</span>
      out-&gt;print_cr(&quot;Usage per space type:&quot;);
      out-&gt;cr();
      for (int space_type = (int)Metaspace::ZeroMetaspaceType;
           space_type &lt; (int)Metaspace::MetaspaceTypeCount; space_type ++)
      {
<span class="line-modified">!       uintx num_loaders = cl._num_loaders_by_spacetype[space_type];</span>
<span class="line-modified">!       uintx num_classes = cl._num_classes_by_spacetype[space_type];</span>
<span class="line-added">+       out-&gt;print(&quot;%s - &quot; UINTX_FORMAT &quot; %s&quot;,</span>
          space_type_name((Metaspace::MetaspaceType)space_type),
<span class="line-modified">!         num_loaders, loaders_plural(num_loaders));</span>
<span class="line-modified">!       if (num_classes &gt; 0) {</span>
<span class="line-added">+         out-&gt;print(&quot;, &quot;);</span>
<span class="line-added">+         print_number_of_classes(out, num_classes, cl._num_classes_shared_by_spacetype[space_type]);</span>
<span class="line-added">+         out-&gt;print(&quot;:&quot;);</span>
          cl._stats_by_spacetype[space_type].print_on(out, scale, print_by_chunktype);
<span class="line-added">+       } else {</span>
<span class="line-added">+         out-&gt;print(&quot;.&quot;);</span>
<span class="line-added">+         out-&gt;cr();</span>
        }
        out-&gt;cr();
      }
    }
  
    // Print totals for in-use data:
    out-&gt;cr();
<span class="line-modified">!   {</span>
<span class="line-modified">!     uintx num_loaders = cl._num_loaders;</span>
<span class="line-modified">!     out-&gt;print(&quot;Total Usage - &quot; UINTX_FORMAT &quot; %s, &quot;,</span>
<span class="line-modified">!       num_loaders, loaders_plural(num_loaders));</span>
<span class="line-added">+     print_number_of_classes(out, cl._num_classes, cl._num_classes_shared);</span>
<span class="line-added">+     out-&gt;print(&quot;:&quot;);</span>
<span class="line-added">+     cl._stats_total.print_on(out, scale, print_by_chunktype);</span>
<span class="line-added">+     out-&gt;cr();</span>
<span class="line-added">+   }</span>
  
    // -- Print Virtual space.
    out-&gt;cr();
    out-&gt;print_cr(&quot;Virtual space:&quot;);
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 803,32 ***</span>
  #endif
  
    // Print some interesting settings
    out-&gt;cr();
    out-&gt;cr();
<span class="line-modified">!   out-&gt;print(&quot;MaxMetaspaceSize: &quot;);</span>
<span class="line-modified">!   print_human_readable_size(out, MaxMetaspaceSize, scale);</span>
    out-&gt;cr();
    out-&gt;print(&quot;InitialBootClassLoaderMetaspaceSize: &quot;);
    print_human_readable_size(out, InitialBootClassLoaderMetaspaceSize, scale);
<span class="line-removed">-   out-&gt;cr();</span>
<span class="line-removed">- </span>
<span class="line-removed">-   out-&gt;print(&quot;UseCompressedClassPointers: %s&quot;, UseCompressedClassPointers ? &quot;true&quot; : &quot;false&quot;);</span>
<span class="line-removed">-   out-&gt;cr();</span>
<span class="line-removed">-   if (Metaspace::using_class_space()) {</span>
<span class="line-removed">-     out-&gt;print(&quot;CompressedClassSpaceSize: &quot;);</span>
<span class="line-removed">-     print_human_readable_size(out, CompressedClassSpaceSize, scale);</span>
<span class="line-removed">-   }</span>
  
    out-&gt;cr();
    out-&gt;cr();
  
  } // MetaspaceUtils::print_report()
  
  // Prints an ASCII representation of the given space.
  void MetaspaceUtils::print_metaspace_map(outputStream* out, Metaspace::MetadataType mdtype) {
<span class="line-modified">!   MutexLockerEx cl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);</span>
    const bool for_class = mdtype == Metaspace::ClassType ? true : false;
    VirtualSpaceList* const vsl = for_class ? Metaspace::class_space_list() : Metaspace::space_list();
    if (vsl != NULL) {
      if (for_class) {
        if (!Metaspace::using_class_space()) {
<span class="line-new-header">--- 876,24 ---</span>
  #endif
  
    // Print some interesting settings
    out-&gt;cr();
    out-&gt;cr();
<span class="line-modified">!   print_basic_switches(out, scale);</span>
<span class="line-modified">! </span>
    out-&gt;cr();
    out-&gt;print(&quot;InitialBootClassLoaderMetaspaceSize: &quot;);
    print_human_readable_size(out, InitialBootClassLoaderMetaspaceSize, scale);
  
    out-&gt;cr();
    out-&gt;cr();
  
  } // MetaspaceUtils::print_report()
  
  // Prints an ASCII representation of the given space.
  void MetaspaceUtils::print_metaspace_map(outputStream* out, Metaspace::MetadataType mdtype) {
<span class="line-modified">!   MutexLocker cl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);</span>
    const bool for_class = mdtype == Metaspace::ClassType ? true : false;
    VirtualSpaceList* const vsl = for_class ? Metaspace::class_space_list() : Metaspace::space_list();
    if (vsl != NULL) {
      if (for_class) {
        if (!Metaspace::using_class_space()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 887,35 ***</span>
    }
    assert(mismatch == false, &quot;MetaspaceUtils::verify_metrics: counter mismatch.&quot;);
  #endif
  }
  
<span class="line-removed">- // Utils to check if a pointer or range is part of a committed metaspace region.</span>
<span class="line-removed">- metaspace::VirtualSpaceNode* MetaspaceUtils::find_enclosing_virtual_space(const void* p) {</span>
<span class="line-removed">-   MutexLockerEx cl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);</span>
<span class="line-removed">-   VirtualSpaceNode* vsn = Metaspace::space_list()-&gt;find_enclosing_space(p);</span>
<span class="line-removed">-   if (Metaspace::using_class_space() &amp;&amp; vsn == NULL) {</span>
<span class="line-removed">-     vsn = Metaspace::class_space_list()-&gt;find_enclosing_space(p);</span>
<span class="line-removed">-   }</span>
<span class="line-removed">-   return vsn;</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- bool MetaspaceUtils::is_range_in_committed(const void* from, const void* to) {</span>
<span class="line-removed">- #if INCLUDE_CDS</span>
<span class="line-removed">-   if (UseSharedSpaces) {</span>
<span class="line-removed">-     for (int idx = MetaspaceShared::ro; idx &lt;= MetaspaceShared::mc; idx++) {</span>
<span class="line-removed">-       if (FileMapInfo::current_info()-&gt;is_in_shared_region(from, idx)) {</span>
<span class="line-removed">-         return FileMapInfo::current_info()-&gt;is_in_shared_region(to, idx);</span>
<span class="line-removed">-       }</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-   }</span>
<span class="line-removed">- #endif</span>
<span class="line-removed">-   VirtualSpaceNode* vsn = find_enclosing_virtual_space(from);</span>
<span class="line-removed">-   return (vsn != NULL) &amp;&amp; vsn-&gt;contains(to);</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- </span>
  // Metaspace methods
  
  size_t Metaspace::_first_chunk_word_size = 0;
  size_t Metaspace::_first_class_chunk_word_size = 0;
  
<span class="line-new-header">--- 952,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 926,185 ***</span>
  VirtualSpaceList* Metaspace::_class_space_list = NULL;
  
  ChunkManager* Metaspace::_chunk_manager_metadata = NULL;
  ChunkManager* Metaspace::_chunk_manager_class = NULL;
  
  #define VIRTUALSPACEMULTIPLIER 2
  
  #ifdef _LP64
  static const uint64_t UnscaledClassSpaceMax = (uint64_t(max_juint) + 1);
  
<span class="line-modified">! void Metaspace::set_narrow_klass_base_and_shift(address metaspace_base, address cds_base) {</span>
    assert(!DumpSharedSpaces, &quot;narrow_klass is set by MetaspaceShared class.&quot;);
    // Figure out the narrow_klass_base and the narrow_klass_shift.  The
    // narrow_klass_base is the lower of the metaspace base and the cds base
    // (if cds is enabled).  The narrow_klass_shift depends on the distance
    // between the lower base and higher address.
<span class="line-modified">!   address lower_base;</span>
<span class="line-modified">!   address higher_address;</span>
<span class="line-modified">! #if INCLUDE_CDS</span>
<span class="line-modified">!   if (UseSharedSpaces) {</span>
<span class="line-modified">!     higher_address = MAX2((address)(cds_base + MetaspaceShared::core_spaces_size()),</span>
<span class="line-modified">!                           (address)(metaspace_base + compressed_class_space_size()));</span>
<span class="line-removed">-     lower_base = MIN2(metaspace_base, cds_base);</span>
<span class="line-removed">-   } else</span>
<span class="line-removed">- #endif</span>
<span class="line-removed">-   {</span>
<span class="line-removed">-     higher_address = metaspace_base + compressed_class_space_size();</span>
<span class="line-removed">-     lower_base = metaspace_base;</span>
<span class="line-removed">- </span>
      uint64_t klass_encoding_max = UnscaledClassSpaceMax &lt;&lt; LogKlassAlignmentInBytes;
      // If compressed class space fits in lower 32G, we don&#39;t need a base.
      if (higher_address &lt;= (address)klass_encoding_max) {
        lower_base = 0; // Effectively lower base is zero.
      }
    }
  
<span class="line-modified">!   Universe::set_narrow_klass_base(lower_base);</span>
  
    // CDS uses LogKlassAlignmentInBytes for narrow_klass_shift. See
    // MetaspaceShared::initialize_dumptime_shared_and_meta_spaces() for
    // how dump time narrow_klass_shift is set. Although, CDS can work
    // with zero-shift mode also, to be consistent with AOT it uses
    // LogKlassAlignmentInBytes for klass shift so archived java heap objects
    // can be used at same time as AOT code.
    if (!UseSharedSpaces
        &amp;&amp; (uint64_t)(higher_address - lower_base) &lt;= UnscaledClassSpaceMax) {
<span class="line-modified">!     Universe::set_narrow_klass_shift(0);</span>
    } else {
<span class="line-modified">!     Universe::set_narrow_klass_shift(LogKlassAlignmentInBytes);</span>
    }
    AOTLoader::set_narrow_klass_shift();
  }
  
<span class="line-removed">- #if INCLUDE_CDS</span>
<span class="line-removed">- // Return TRUE if the specified metaspace_base and cds_base are close enough</span>
<span class="line-removed">- // to work with compressed klass pointers.</span>
<span class="line-removed">- bool Metaspace::can_use_cds_with_metaspace_addr(char* metaspace_base, address cds_base) {</span>
<span class="line-removed">-   assert(cds_base != 0 &amp;&amp; UseSharedSpaces, &quot;Only use with CDS&quot;);</span>
<span class="line-removed">-   assert(UseCompressedClassPointers, &quot;Only use with CompressedKlassPtrs&quot;);</span>
<span class="line-removed">-   address lower_base = MIN2((address)metaspace_base, cds_base);</span>
<span class="line-removed">-   address higher_address = MAX2((address)(cds_base + MetaspaceShared::core_spaces_size()),</span>
<span class="line-removed">-                                 (address)(metaspace_base + compressed_class_space_size()));</span>
<span class="line-removed">-   return ((uint64_t)(higher_address - lower_base) &lt;= UnscaledClassSpaceMax);</span>
<span class="line-removed">- }</span>
<span class="line-removed">- #endif</span>
<span class="line-removed">- </span>
  // Try to allocate the metaspace at the requested addr.
<span class="line-modified">! void Metaspace::allocate_metaspace_compressed_klass_ptrs(char* requested_addr, address cds_base) {</span>
    assert(!DumpSharedSpaces, &quot;compress klass space is allocated by MetaspaceShared class.&quot;);
    assert(using_class_space(), &quot;called improperly&quot;);
    assert(UseCompressedClassPointers, &quot;Only use with CompressedKlassPtrs&quot;);
    assert(compressed_class_space_size() &lt; KlassEncodingMetaspaceMax,
           &quot;Metaspace size is too big&quot;);
    assert_is_aligned(requested_addr, _reserve_alignment);
    assert_is_aligned(cds_base, _reserve_alignment);
    assert_is_aligned(compressed_class_space_size(), _reserve_alignment);
  
<span class="line-modified">!   // Don&#39;t use large pages for the class space.</span>
<span class="line-modified">!   bool large_pages = false;</span>
<span class="line-modified">! </span>
<span class="line-modified">! #if !(defined(AARCH64) || defined(AIX))</span>
<span class="line-modified">!   ReservedSpace metaspace_rs = ReservedSpace(compressed_class_space_size(),</span>
<span class="line-modified">!                                              _reserve_alignment,</span>
<span class="line-modified">!                                              large_pages,</span>
<span class="line-modified">!                                              requested_addr);</span>
<span class="line-modified">! #else // AARCH64</span>
<span class="line-removed">-   ReservedSpace metaspace_rs;</span>
<span class="line-removed">- </span>
<span class="line-removed">-   // Our compressed klass pointers may fit nicely into the lower 32</span>
<span class="line-removed">-   // bits.</span>
<span class="line-removed">-   if ((uint64_t)requested_addr + compressed_class_space_size() &lt; 4*G) {</span>
<span class="line-removed">-     metaspace_rs = ReservedSpace(compressed_class_space_size(),</span>
<span class="line-removed">-                                  _reserve_alignment,</span>
<span class="line-removed">-                                  large_pages,</span>
<span class="line-removed">-                                  requested_addr);</span>
<span class="line-removed">-   }</span>
<span class="line-removed">- </span>
<span class="line-removed">-   if (! metaspace_rs.is_reserved()) {</span>
<span class="line-removed">-     // Aarch64: Try to align metaspace so that we can decode a compressed</span>
<span class="line-removed">-     // klass with a single MOVK instruction.  We can do this iff the</span>
<span class="line-removed">-     // compressed class base is a multiple of 4G.</span>
<span class="line-removed">-     // Aix: Search for a place where we can find memory. If we need to load</span>
<span class="line-removed">-     // the base, 4G alignment is helpful, too.</span>
<span class="line-removed">-     size_t increment = AARCH64_ONLY(4*)G;</span>
<span class="line-removed">-     for (char *a = align_up(requested_addr, increment);</span>
<span class="line-removed">-          a &lt; (char*)(1024*G);</span>
<span class="line-removed">-          a += increment) {</span>
<span class="line-removed">-       if (a == (char *)(32*G)) {</span>
<span class="line-removed">-         // Go faster from here on. Zero-based is no longer possible.</span>
<span class="line-removed">-         increment = 4*G;</span>
<span class="line-removed">-       }</span>
<span class="line-removed">- </span>
<span class="line-removed">- #if INCLUDE_CDS</span>
<span class="line-removed">-       if (UseSharedSpaces</span>
<span class="line-removed">-           &amp;&amp; ! can_use_cds_with_metaspace_addr(a, cds_base)) {</span>
<span class="line-removed">-         // We failed to find an aligned base that will reach.  Fall</span>
<span class="line-removed">-         // back to using our requested addr.</span>
<span class="line-removed">-         metaspace_rs = ReservedSpace(compressed_class_space_size(),</span>
<span class="line-removed">-                                      _reserve_alignment,</span>
<span class="line-removed">-                                      large_pages,</span>
<span class="line-removed">-                                      requested_addr);</span>
<span class="line-removed">-         break;</span>
<span class="line-removed">-       }</span>
<span class="line-removed">- #endif</span>
<span class="line-removed">- </span>
<span class="line-removed">-       metaspace_rs = ReservedSpace(compressed_class_space_size(),</span>
<span class="line-removed">-                                    _reserve_alignment,</span>
<span class="line-removed">-                                    large_pages,</span>
<span class="line-removed">-                                    a);</span>
<span class="line-removed">-       if (metaspace_rs.is_reserved())</span>
<span class="line-removed">-         break;</span>
<span class="line-removed">-     }</span>
    }
  
<span class="line-removed">- #endif // AARCH64</span>
<span class="line-removed">- </span>
    if (!metaspace_rs.is_reserved()) {
<span class="line-modified">! #if INCLUDE_CDS</span>
<span class="line-removed">-     if (UseSharedSpaces) {</span>
<span class="line-removed">-       size_t increment = align_up(1*G, _reserve_alignment);</span>
<span class="line-removed">- </span>
<span class="line-removed">-       // Keep trying to allocate the metaspace, increasing the requested_addr</span>
<span class="line-removed">-       // by 1GB each time, until we reach an address that will no longer allow</span>
<span class="line-removed">-       // use of CDS with compressed klass pointers.</span>
<span class="line-removed">-       char *addr = requested_addr;</span>
<span class="line-removed">-       while (!metaspace_rs.is_reserved() &amp;&amp; (addr + increment &gt; addr) &amp;&amp;</span>
<span class="line-removed">-              can_use_cds_with_metaspace_addr(addr + increment, cds_base)) {</span>
<span class="line-removed">-         addr = addr + increment;</span>
<span class="line-removed">-         metaspace_rs = ReservedSpace(compressed_class_space_size(),</span>
<span class="line-removed">-                                      _reserve_alignment, large_pages, addr);</span>
<span class="line-removed">-       }</span>
<span class="line-removed">-     }</span>
<span class="line-removed">- #endif</span>
      // If no successful allocation then try to allocate the space anywhere.  If
      // that fails then OOM doom.  At this point we cannot try allocating the
      // metaspace as if UseCompressedClassPointers is off because too much
      // initialization has happened that depends on UseCompressedClassPointers.
      // So, UseCompressedClassPointers cannot be turned off at this point.
      if (!metaspace_rs.is_reserved()) {
<span class="line-modified">!       metaspace_rs = ReservedSpace(compressed_class_space_size(),</span>
<span class="line-modified">!                                    _reserve_alignment, large_pages);</span>
<span class="line-removed">-       if (!metaspace_rs.is_reserved()) {</span>
<span class="line-removed">-         vm_exit_during_initialization(err_msg(&quot;Could not allocate metaspace: &quot; SIZE_FORMAT &quot; bytes&quot;,</span>
<span class="line-removed">-                                               compressed_class_space_size()));</span>
<span class="line-removed">-       }</span>
      }
    }
  
<span class="line-modified">!   // If we got here then the metaspace got allocated.</span>
<span class="line-modified">!   MemTracker::record_virtual_memory_type((address)metaspace_rs.base(), mtClass);</span>
<span class="line-modified">! </span>
<span class="line-removed">- #if INCLUDE_CDS</span>
<span class="line-removed">-   // Verify that we can use shared spaces.  Otherwise, turn off CDS.</span>
<span class="line-removed">-   if (UseSharedSpaces &amp;&amp; !can_use_cds_with_metaspace_addr(metaspace_rs.base(), cds_base)) {</span>
<span class="line-removed">-     FileMapInfo::stop_sharing_and_unmap(</span>
<span class="line-removed">-         &quot;Could not allocate metaspace at a compatible address&quot;);</span>
    }
<span class="line-modified">! #endif</span>
<span class="line-modified">!   set_narrow_klass_base_and_shift((address)metaspace_rs.base(),</span>
<span class="line-removed">-                                   UseSharedSpaces ? (address)cds_base : 0);</span>
  
    initialize_class_space(metaspace_rs);
  
    LogTarget(Trace, gc, metaspace) lt;
    if (lt.is_enabled()) {
<span class="line-new-header">--- 966,96 ---</span>
  VirtualSpaceList* Metaspace::_class_space_list = NULL;
  
  ChunkManager* Metaspace::_chunk_manager_metadata = NULL;
  ChunkManager* Metaspace::_chunk_manager_class = NULL;
  
<span class="line-added">+ bool Metaspace::_initialized = false;</span>
<span class="line-added">+ </span>
  #define VIRTUALSPACEMULTIPLIER 2
  
  #ifdef _LP64
  static const uint64_t UnscaledClassSpaceMax = (uint64_t(max_juint) + 1);
  
<span class="line-modified">! void Metaspace::set_narrow_klass_base_and_shift(ReservedSpace metaspace_rs, address cds_base) {</span>
    assert(!DumpSharedSpaces, &quot;narrow_klass is set by MetaspaceShared class.&quot;);
    // Figure out the narrow_klass_base and the narrow_klass_shift.  The
    // narrow_klass_base is the lower of the metaspace base and the cds base
    // (if cds is enabled).  The narrow_klass_shift depends on the distance
    // between the lower base and higher address.
<span class="line-modified">!   address lower_base = (address)metaspace_rs.base();</span>
<span class="line-modified">!   address higher_address = (address)metaspace_rs.end();</span>
<span class="line-modified">!   if (cds_base != NULL) {</span>
<span class="line-modified">!     assert(UseSharedSpaces, &quot;must be&quot;);</span>
<span class="line-modified">!     lower_base = MIN2(lower_base, cds_base);</span>
<span class="line-modified">!   } else {</span>
      uint64_t klass_encoding_max = UnscaledClassSpaceMax &lt;&lt; LogKlassAlignmentInBytes;
      // If compressed class space fits in lower 32G, we don&#39;t need a base.
      if (higher_address &lt;= (address)klass_encoding_max) {
        lower_base = 0; // Effectively lower base is zero.
      }
    }
  
<span class="line-modified">!   CompressedKlassPointers::set_base(lower_base);</span>
  
    // CDS uses LogKlassAlignmentInBytes for narrow_klass_shift. See
    // MetaspaceShared::initialize_dumptime_shared_and_meta_spaces() for
    // how dump time narrow_klass_shift is set. Although, CDS can work
    // with zero-shift mode also, to be consistent with AOT it uses
    // LogKlassAlignmentInBytes for klass shift so archived java heap objects
    // can be used at same time as AOT code.
    if (!UseSharedSpaces
        &amp;&amp; (uint64_t)(higher_address - lower_base) &lt;= UnscaledClassSpaceMax) {
<span class="line-modified">!     CompressedKlassPointers::set_shift(0);</span>
    } else {
<span class="line-modified">!     CompressedKlassPointers::set_shift(LogKlassAlignmentInBytes);</span>
    }
    AOTLoader::set_narrow_klass_shift();
  }
  
  // Try to allocate the metaspace at the requested addr.
<span class="line-modified">! void Metaspace::allocate_metaspace_compressed_klass_ptrs(ReservedSpace metaspace_rs, char* requested_addr, address cds_base) {</span>
    assert(!DumpSharedSpaces, &quot;compress klass space is allocated by MetaspaceShared class.&quot;);
    assert(using_class_space(), &quot;called improperly&quot;);
    assert(UseCompressedClassPointers, &quot;Only use with CompressedKlassPtrs&quot;);
    assert(compressed_class_space_size() &lt; KlassEncodingMetaspaceMax,
           &quot;Metaspace size is too big&quot;);
    assert_is_aligned(requested_addr, _reserve_alignment);
    assert_is_aligned(cds_base, _reserve_alignment);
    assert_is_aligned(compressed_class_space_size(), _reserve_alignment);
  
<span class="line-modified">!   if (metaspace_rs.is_reserved()) {</span>
<span class="line-modified">!     // CDS should have already reserved the space.</span>
<span class="line-modified">!     assert(requested_addr == NULL, &quot;not used&quot;);</span>
<span class="line-modified">!     assert(cds_base != NULL, &quot;CDS should have already reserved the memory space&quot;);</span>
<span class="line-modified">!   } else {</span>
<span class="line-modified">!     assert(cds_base == NULL, &quot;must be&quot;);</span>
<span class="line-modified">!     metaspace_rs = reserve_space(compressed_class_space_size(),</span>
<span class="line-modified">!                                  _reserve_alignment, requested_addr,</span>
<span class="line-modified">!                                  false /* use_requested_addr */);</span>
    }
  
    if (!metaspace_rs.is_reserved()) {
<span class="line-modified">!     assert(cds_base == NULL, &quot;CDS should have already reserved the memory space&quot;);</span>
      // If no successful allocation then try to allocate the space anywhere.  If
      // that fails then OOM doom.  At this point we cannot try allocating the
      // metaspace as if UseCompressedClassPointers is off because too much
      // initialization has happened that depends on UseCompressedClassPointers.
      // So, UseCompressedClassPointers cannot be turned off at this point.
<span class="line-added">+     metaspace_rs = reserve_space(compressed_class_space_size(),</span>
<span class="line-added">+                                  _reserve_alignment, NULL, false);</span>
      if (!metaspace_rs.is_reserved()) {
<span class="line-modified">!       vm_exit_during_initialization(err_msg(&quot;Could not allocate metaspace: &quot; SIZE_FORMAT &quot; bytes&quot;,</span>
<span class="line-modified">!                                             compressed_class_space_size()));</span>
      }
    }
  
<span class="line-modified">!   if (cds_base == NULL) {</span>
<span class="line-modified">!     // If we got here then the metaspace got allocated.</span>
<span class="line-modified">!     MemTracker::record_virtual_memory_type((address)metaspace_rs.base(), mtClass);</span>
    }
<span class="line-modified">! </span>
<span class="line-modified">!   set_narrow_klass_base_and_shift(metaspace_rs, cds_base);</span>
  
    initialize_class_space(metaspace_rs);
  
    LogTarget(Trace, gc, metaspace) lt;
    if (lt.is_enabled()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1114,11 ***</span>
    }
  }
  
  void Metaspace::print_compressed_class_space(outputStream* st, const char* requested_addr) {
    st-&gt;print_cr(&quot;Narrow klass base: &quot; PTR_FORMAT &quot;, Narrow klass shift: %d&quot;,
<span class="line-modified">!                p2i(Universe::narrow_klass_base()), Universe::narrow_klass_shift());</span>
    if (_class_space_list != NULL) {
      address base = (address)_class_space_list-&gt;current_virtual_space()-&gt;bottom();
      st-&gt;print(&quot;Compressed class space size: &quot; SIZE_FORMAT &quot; Address: &quot; PTR_FORMAT,
                   compressed_class_space_size(), p2i(base));
      if (requested_addr != 0) {
<span class="line-new-header">--- 1065,11 ---</span>
    }
  }
  
  void Metaspace::print_compressed_class_space(outputStream* st, const char* requested_addr) {
    st-&gt;print_cr(&quot;Narrow klass base: &quot; PTR_FORMAT &quot;, Narrow klass shift: %d&quot;,
<span class="line-modified">!                p2i(CompressedKlassPointers::base()), CompressedKlassPointers::shift());</span>
    if (_class_space_list != NULL) {
      address base = (address)_class_space_list-&gt;current_virtual_space()-&gt;bottom();
      st-&gt;print(&quot;Compressed class space size: &quot; SIZE_FORMAT &quot; Address: &quot; PTR_FORMAT,
                   compressed_class_space_size(), p2i(base));
      if (requested_addr != 0) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1141,16 ***</span>
    if (!_class_space_list-&gt;initialization_succeeded()) {
      vm_exit_during_initialization(&quot;Failed to setup compressed class space virtual space list.&quot;);
    }
  }
  
  #endif
  
  void Metaspace::ergo_initialize() {
    if (DumpSharedSpaces) {
      // Using large pages when dumping the shared archive is currently not implemented.
<span class="line-modified">!     FLAG_SET_ERGO(bool, UseLargePagesInMetaspace, false);</span>
    }
  
    size_t page_size = os::vm_page_size();
    if (UseLargePages &amp;&amp; UseLargePagesInMetaspace) {
      page_size = os::large_page_size();
<span class="line-new-header">--- 1092,89 ---</span>
    if (!_class_space_list-&gt;initialization_succeeded()) {
      vm_exit_during_initialization(&quot;Failed to setup compressed class space virtual space list.&quot;);
    }
  }
  
<span class="line-added">+ #endif // _LP64</span>
<span class="line-added">+ </span>
<span class="line-added">+ #ifdef PREFERRED_METASPACE_ALIGNMENT</span>
<span class="line-added">+ ReservedSpace Metaspace::reserve_preferred_space(size_t size, size_t alignment,</span>
<span class="line-added">+                                                  bool large_pages, char *requested_addr,</span>
<span class="line-added">+                                                  bool use_requested_addr) {</span>
<span class="line-added">+   // Our compressed klass pointers may fit nicely into the lower 32 bits.</span>
<span class="line-added">+   if (requested_addr != NULL &amp;&amp; (uint64_t)requested_addr + size &lt; 4*G) {</span>
<span class="line-added">+     ReservedSpace rs(size, alignment, large_pages, requested_addr);</span>
<span class="line-added">+     if (rs.is_reserved() || use_requested_addr) {</span>
<span class="line-added">+       return rs;</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   struct SearchParams { uintptr_t limit; size_t increment; };</span>
<span class="line-added">+ </span>
<span class="line-added">+   // AArch64: Try to align metaspace so that we can decode a compressed</span>
<span class="line-added">+   // klass with a single MOVK instruction. We can do this iff the</span>
<span class="line-added">+   // compressed class base is a multiple of 4G.</span>
<span class="line-added">+   // Aix: Search for a place where we can find memory. If we need to load</span>
<span class="line-added">+   // the base, 4G alignment is helpful, too.</span>
<span class="line-added">+ </span>
<span class="line-added">+   // Go faster above 32G as it is no longer possible to use a zero base.</span>
<span class="line-added">+   // AArch64: Additionally, ensure the lower LogKlassAlignmentInBytes</span>
<span class="line-added">+   // bits of the upper 32-bits of the address are zero so we can handle</span>
<span class="line-added">+   // a shift when decoding.</span>
<span class="line-added">+ </span>
<span class="line-added">+   static const SearchParams search_params[] = {</span>
<span class="line-added">+     // Limit    Increment</span>
<span class="line-added">+     {  32*G,    AARCH64_ONLY(4*)G,                               },</span>
<span class="line-added">+     {  1024*G,  (4 AARCH64_ONLY(&lt;&lt; LogKlassAlignmentInBytes))*G  },</span>
<span class="line-added">+   };</span>
<span class="line-added">+ </span>
<span class="line-added">+   // Null requested_addr means allocate anywhere so ensure the search</span>
<span class="line-added">+   // begins from a non-null address.</span>
<span class="line-added">+   char *a = MAX2(requested_addr, (char *)search_params[0].increment);</span>
<span class="line-added">+ </span>
<span class="line-added">+   for (const SearchParams *p = search_params;</span>
<span class="line-added">+        p &lt; search_params + ARRAY_SIZE(search_params);</span>
<span class="line-added">+        ++p) {</span>
<span class="line-added">+     a = align_up(a, p-&gt;increment);</span>
<span class="line-added">+     if (use_requested_addr &amp;&amp; a != requested_addr)</span>
<span class="line-added">+       return ReservedSpace();</span>
<span class="line-added">+ </span>
<span class="line-added">+     for (; a &lt; (char *)p-&gt;limit; a += p-&gt;increment) {</span>
<span class="line-added">+       ReservedSpace rs(size, alignment, large_pages, a);</span>
<span class="line-added">+       if (rs.is_reserved() || use_requested_addr) {</span>
<span class="line-added">+         return rs;</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   return ReservedSpace();</span>
<span class="line-added">+ }</span>
<span class="line-added">+ #endif // PREFERRED_METASPACE_ALIGNMENT</span>
<span class="line-added">+ </span>
<span class="line-added">+ // Try to reserve a region for the metaspace at the requested address. Some</span>
<span class="line-added">+ // platforms have particular alignment requirements to allow efficient decode of</span>
<span class="line-added">+ // compressed class pointers in which case requested_addr is treated as hint for</span>
<span class="line-added">+ // where to start looking unless use_requested_addr is true.</span>
<span class="line-added">+ ReservedSpace Metaspace::reserve_space(size_t size, size_t alignment,</span>
<span class="line-added">+                                        char* requested_addr, bool use_requested_addr) {</span>
<span class="line-added">+   bool large_pages = false; // Don&#39;t use large pages for the class space.</span>
<span class="line-added">+   assert(is_aligned(requested_addr, alignment), &quot;must be&quot;);</span>
<span class="line-added">+   assert(requested_addr != NULL || !use_requested_addr,</span>
<span class="line-added">+          &quot;cannot set use_requested_addr with NULL address&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+ #ifdef PREFERRED_METASPACE_ALIGNMENT</span>
<span class="line-added">+   return reserve_preferred_space(size, alignment, large_pages,</span>
<span class="line-added">+                                  requested_addr, use_requested_addr);</span>
<span class="line-added">+ #else</span>
<span class="line-added">+   return ReservedSpace(size, alignment, large_pages, requested_addr);</span>
  #endif
<span class="line-added">+ }</span>
  
  void Metaspace::ergo_initialize() {
    if (DumpSharedSpaces) {
      // Using large pages when dumping the shared archive is currently not implemented.
<span class="line-modified">!     FLAG_SET_ERGO(UseLargePagesInMetaspace, false);</span>
    }
  
    size_t page_size = os::vm_page_size();
    if (UseLargePages &amp;&amp; UseLargePagesInMetaspace) {
      page_size = os::large_page_size();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1188,46 ***</span>
    if (UseCompressedClassPointers) {
      if ((min_metaspace_sz + CompressedClassSpaceSize) &gt;  MaxMetaspaceSize) {
        if (min_metaspace_sz &gt;= MaxMetaspaceSize) {
          vm_exit_during_initialization(&quot;MaxMetaspaceSize is too small.&quot;);
        } else {
<span class="line-modified">!         FLAG_SET_ERGO(size_t, CompressedClassSpaceSize,</span>
                        MaxMetaspaceSize - min_metaspace_sz);
        }
      }
    } else if (min_metaspace_sz &gt;= MaxMetaspaceSize) {
<span class="line-modified">!     FLAG_SET_ERGO(size_t, InitialBootClassLoaderMetaspaceSize,</span>
                    min_metaspace_sz);
    }
  
    set_compressed_class_space_size(CompressedClassSpaceSize);
  }
  
  void Metaspace::global_initialize() {
    MetaspaceGC::initialize();
  
  #if INCLUDE_CDS
    if (DumpSharedSpaces) {
      MetaspaceShared::initialize_dumptime_shared_and_meta_spaces();
    } else if (UseSharedSpaces) {
      // If any of the archived space fails to map, UseSharedSpaces
<span class="line-modified">!     // is reset to false. Fall through to the</span>
<span class="line-removed">-     // (!DumpSharedSpaces &amp;&amp; !UseSharedSpaces) case to set up class</span>
<span class="line-removed">-     // metaspace.</span>
      MetaspaceShared::initialize_runtime_shared_and_meta_spaces();
    }
  
<span class="line-modified">!   if (!DumpSharedSpaces &amp;&amp; !UseSharedSpaces)</span>
  #endif // INCLUDE_CDS
<span class="line-modified">!   {</span>
  #ifdef _LP64
<span class="line-modified">!     if (using_class_space()) {</span>
<span class="line-modified">!       char* base = (char*)align_up(Universe::heap()-&gt;reserved_region().end(), _reserve_alignment);</span>
<span class="line-modified">!       allocate_metaspace_compressed_klass_ptrs(base, 0);</span>
<span class="line-modified">!     }</span>
<span class="line-removed">- #endif // _LP64</span>
    }
  
    // Initialize these before initializing the VirtualSpaceList
    _first_chunk_word_size = InitialBootClassLoaderMetaspaceSize / BytesPerWord;
    _first_chunk_word_size = align_word_size_up(_first_chunk_word_size);
    // Make the first class chunk bigger than a medium chunk so it&#39;s not put
<span class="line-new-header">--- 1212,49 ---</span>
    if (UseCompressedClassPointers) {
      if ((min_metaspace_sz + CompressedClassSpaceSize) &gt;  MaxMetaspaceSize) {
        if (min_metaspace_sz &gt;= MaxMetaspaceSize) {
          vm_exit_during_initialization(&quot;MaxMetaspaceSize is too small.&quot;);
        } else {
<span class="line-modified">!         FLAG_SET_ERGO(CompressedClassSpaceSize,</span>
                        MaxMetaspaceSize - min_metaspace_sz);
        }
      }
    } else if (min_metaspace_sz &gt;= MaxMetaspaceSize) {
<span class="line-modified">!     FLAG_SET_ERGO(InitialBootClassLoaderMetaspaceSize,</span>
                    min_metaspace_sz);
    }
  
    set_compressed_class_space_size(CompressedClassSpaceSize);
  }
  
  void Metaspace::global_initialize() {
    MetaspaceGC::initialize();
  
<span class="line-added">+   bool class_space_inited = false;</span>
  #if INCLUDE_CDS
    if (DumpSharedSpaces) {
      MetaspaceShared::initialize_dumptime_shared_and_meta_spaces();
<span class="line-added">+     class_space_inited = true;</span>
    } else if (UseSharedSpaces) {
      // If any of the archived space fails to map, UseSharedSpaces
<span class="line-modified">!     // is reset to false.</span>
      MetaspaceShared::initialize_runtime_shared_and_meta_spaces();
<span class="line-added">+     class_space_inited = UseSharedSpaces;</span>
    }
  
<span class="line-modified">!   if (DynamicDumpSharedSpaces &amp;&amp; !UseSharedSpaces) {</span>
<span class="line-added">+     vm_exit_during_initialization(&quot;DynamicDumpSharedSpaces is unsupported when base CDS archive is not loaded&quot;, NULL);</span>
<span class="line-added">+   }</span>
  #endif // INCLUDE_CDS
<span class="line-modified">! </span>
  #ifdef _LP64
<span class="line-modified">!   if (using_class_space() &amp;&amp; !class_space_inited) {</span>
<span class="line-modified">!     char* base = (char*)align_up(CompressedOops::end(), _reserve_alignment);</span>
<span class="line-modified">!     ReservedSpace dummy;</span>
<span class="line-modified">!     allocate_metaspace_compressed_klass_ptrs(dummy, base, 0);</span>
    }
<span class="line-added">+ #endif</span>
  
    // Initialize these before initializing the VirtualSpaceList
    _first_chunk_word_size = InitialBootClassLoaderMetaspaceSize / BytesPerWord;
    _first_chunk_word_size = align_word_size_up(_first_chunk_word_size);
    // Make the first class chunk bigger than a medium chunk so it&#39;s not put
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1248,10 ***</span>
<span class="line-new-header">--- 1275,13 ---</span>
    if (!_space_list-&gt;initialization_succeeded()) {
      vm_exit_during_initialization(&quot;Unable to setup metadata virtual space list.&quot;, NULL);
    }
  
    _tracer = new MetaspaceTracer();
<span class="line-added">+ </span>
<span class="line-added">+   _initialized = true;</span>
<span class="line-added">+ </span>
  }
  
  void Metaspace::post_initialize() {
    MetaspaceGC::post_initialize();
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1385,12 ***</span>
  void Metaspace::purge(MetadataType mdtype) {
    get_space_list(mdtype)-&gt;purge(get_chunk_manager(mdtype));
  }
  
  void Metaspace::purge() {
<span class="line-modified">!   MutexLockerEx cl(MetaspaceExpand_lock,</span>
<span class="line-modified">!                    Mutex::_no_safepoint_check_flag);</span>
    purge(NonClassType);
    if (using_class_space()) {
      purge(ClassType);
    }
  }
<span class="line-new-header">--- 1415,12 ---</span>
  void Metaspace::purge(MetadataType mdtype) {
    get_space_list(mdtype)-&gt;purge(get_chunk_manager(mdtype));
  }
  
  void Metaspace::purge() {
<span class="line-modified">!   MutexLocker cl(MetaspaceExpand_lock,</span>
<span class="line-modified">!                  Mutex::_no_safepoint_check_flag);</span>
    purge(NonClassType);
    if (using_class_space()) {
      purge(ClassType);
    }
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1463,11 ***</span>
    if (Metaspace::using_class_space()) {
      // Allocate SpaceManager for classes.
      _class_vsm = new SpaceManager(Metaspace::ClassType, type, lock);
    }
  
<span class="line-modified">!   MutexLockerEx cl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);</span>
  
    // Allocate chunk for metadata objects
    initialize_first_chunk(type, Metaspace::NonClassType);
  
    // Allocate chunk for class metadata objects
<span class="line-new-header">--- 1493,11 ---</span>
    if (Metaspace::using_class_space()) {
      // Allocate SpaceManager for classes.
      _class_vsm = new SpaceManager(Metaspace::ClassType, type, lock);
    }
  
<span class="line-modified">!   MutexLocker cl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);</span>
  
    // Allocate chunk for metadata objects
    initialize_first_chunk(type, Metaspace::NonClassType);
  
    // Allocate chunk for class metadata objects
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1532,11 ***</span>
    assert(!SafepointSynchronize::is_at_safepoint()
           || Thread::current()-&gt;is_VM_thread(), &quot;should be the VM thread&quot;);
  
    DEBUG_ONLY(Atomic::inc(&amp;g_internal_statistics.num_external_deallocs));
  
<span class="line-modified">!   MutexLockerEx ml(vsm()-&gt;lock(), Mutex::_no_safepoint_check_flag);</span>
  
    if (is_class &amp;&amp; Metaspace::using_class_space()) {
      class_vsm()-&gt;deallocate(ptr, word_size);
    } else {
      vsm()-&gt;deallocate(ptr, word_size);
<span class="line-new-header">--- 1562,11 ---</span>
    assert(!SafepointSynchronize::is_at_safepoint()
           || Thread::current()-&gt;is_VM_thread(), &quot;should be the VM thread&quot;);
  
    DEBUG_ONLY(Atomic::inc(&amp;g_internal_statistics.num_external_deallocs));
  
<span class="line-modified">!   MutexLocker ml(vsm()-&gt;lock(), Mutex::_no_safepoint_check_flag);</span>
  
    if (is_class &amp;&amp; Metaspace::using_class_space()) {
      class_vsm()-&gt;deallocate(ptr, word_size);
    } else {
      vsm()-&gt;deallocate(ptr, word_size);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1572,81 ***</span>
      class_vsm()-&gt;add_to_statistics_locked(&amp;out-&gt;class_sm_stats());
    }
  }
  
  void ClassLoaderMetaspace::add_to_statistics(ClassLoaderMetaspaceStatistics* out) const {
<span class="line-modified">!   MutexLockerEx cl(lock(), Mutex::_no_safepoint_check_flag);</span>
    add_to_statistics_locked(out);
  }
  
  /////////////// Unit tests ///////////////
  
<span class="line-removed">- #ifndef PRODUCT</span>
<span class="line-removed">- </span>
<span class="line-removed">- class TestMetaspaceUtilsTest : AllStatic {</span>
<span class="line-removed">-  public:</span>
<span class="line-removed">-   static void test_reserved() {</span>
<span class="line-removed">-     size_t reserved = MetaspaceUtils::reserved_bytes();</span>
<span class="line-removed">- </span>
<span class="line-removed">-     assert(reserved &gt; 0, &quot;assert&quot;);</span>
<span class="line-removed">- </span>
<span class="line-removed">-     size_t committed  = MetaspaceUtils::committed_bytes();</span>
<span class="line-removed">-     assert(committed &lt;= reserved, &quot;assert&quot;);</span>
<span class="line-removed">- </span>
<span class="line-removed">-     size_t reserved_metadata = MetaspaceUtils::reserved_bytes(Metaspace::NonClassType);</span>
<span class="line-removed">-     assert(reserved_metadata &gt; 0, &quot;assert&quot;);</span>
<span class="line-removed">-     assert(reserved_metadata &lt;= reserved, &quot;assert&quot;);</span>
<span class="line-removed">- </span>
<span class="line-removed">-     if (UseCompressedClassPointers) {</span>
<span class="line-removed">-       size_t reserved_class    = MetaspaceUtils::reserved_bytes(Metaspace::ClassType);</span>
<span class="line-removed">-       assert(reserved_class &gt; 0, &quot;assert&quot;);</span>
<span class="line-removed">-       assert(reserved_class &lt; reserved, &quot;assert&quot;);</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-   }</span>
<span class="line-removed">- </span>
<span class="line-removed">-   static void test_committed() {</span>
<span class="line-removed">-     size_t committed = MetaspaceUtils::committed_bytes();</span>
<span class="line-removed">- </span>
<span class="line-removed">-     assert(committed &gt; 0, &quot;assert&quot;);</span>
<span class="line-removed">- </span>
<span class="line-removed">-     size_t reserved  = MetaspaceUtils::reserved_bytes();</span>
<span class="line-removed">-     assert(committed &lt;= reserved, &quot;assert&quot;);</span>
<span class="line-removed">- </span>
<span class="line-removed">-     size_t committed_metadata = MetaspaceUtils::committed_bytes(Metaspace::NonClassType);</span>
<span class="line-removed">-     assert(committed_metadata &gt; 0, &quot;assert&quot;);</span>
<span class="line-removed">-     assert(committed_metadata &lt;= committed, &quot;assert&quot;);</span>
<span class="line-removed">- </span>
<span class="line-removed">-     if (UseCompressedClassPointers) {</span>
<span class="line-removed">-       size_t committed_class    = MetaspaceUtils::committed_bytes(Metaspace::ClassType);</span>
<span class="line-removed">-       assert(committed_class &gt; 0, &quot;assert&quot;);</span>
<span class="line-removed">-       assert(committed_class &lt; committed, &quot;assert&quot;);</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-   }</span>
<span class="line-removed">- </span>
<span class="line-removed">-   static void test_virtual_space_list_large_chunk() {</span>
<span class="line-removed">-     VirtualSpaceList* vs_list = new VirtualSpaceList(os::vm_allocation_granularity());</span>
<span class="line-removed">-     MutexLockerEx cl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);</span>
<span class="line-removed">-     // A size larger than VirtualSpaceSize (256k) and add one page to make it _not_ be</span>
<span class="line-removed">-     // vm_allocation_granularity aligned on Windows.</span>
<span class="line-removed">-     size_t large_size = (size_t)(2*256*K + (os::vm_page_size()/BytesPerWord));</span>
<span class="line-removed">-     large_size += (os::vm_page_size()/BytesPerWord);</span>
<span class="line-removed">-     vs_list-&gt;get_new_chunk(large_size, 0);</span>
<span class="line-removed">-   }</span>
<span class="line-removed">- </span>
<span class="line-removed">-   static void test() {</span>
<span class="line-removed">-     test_reserved();</span>
<span class="line-removed">-     test_committed();</span>
<span class="line-removed">-     test_virtual_space_list_large_chunk();</span>
<span class="line-removed">-   }</span>
<span class="line-removed">- };</span>
<span class="line-removed">- </span>
<span class="line-removed">- void TestMetaspaceUtils_test() {</span>
<span class="line-removed">-   TestMetaspaceUtilsTest::test();</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- #endif // !PRODUCT</span>
<span class="line-removed">- </span>
  struct chunkmanager_statistics_t {
    int num_specialized_chunks;
    int num_small_chunks;
    int num_medium_chunks;
    int num_humongous_chunks;
<span class="line-new-header">--- 1602,16 ---</span>
      class_vsm()-&gt;add_to_statistics_locked(&amp;out-&gt;class_sm_stats());
    }
  }
  
  void ClassLoaderMetaspace::add_to_statistics(ClassLoaderMetaspaceStatistics* out) const {
<span class="line-modified">!   MutexLocker cl(lock(), Mutex::_no_safepoint_check_flag);</span>
    add_to_statistics_locked(out);
  }
  
  /////////////// Unit tests ///////////////
  
  struct chunkmanager_statistics_t {
    int num_specialized_chunks;
    int num_small_chunks;
    int num_medium_chunks;
    int num_humongous_chunks;
</pre>
<center><a href="memRegion.hpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="metaspace.hpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>