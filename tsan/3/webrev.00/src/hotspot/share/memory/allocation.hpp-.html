<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/memory/allocation.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_MEMORY_ALLOCATION_HPP
 26 #define SHARE_MEMORY_ALLOCATION_HPP
 27 
 28 #include &quot;runtime/globals.hpp&quot;
 29 #include &quot;utilities/globalDefinitions.hpp&quot;
 30 #include &quot;utilities/macros.hpp&quot;
 31 
 32 #include &lt;new&gt;
 33 
 34 class Thread;
 35 
 36 class AllocFailStrategy {
 37 public:
 38   enum AllocFailEnum { EXIT_OOM, RETURN_NULL };
 39 };
 40 typedef AllocFailStrategy::AllocFailEnum AllocFailType;
 41 
 42 // The virtual machine must never call one of the implicitly declared
 43 // global allocation or deletion functions.  (Such calls may result in
 44 // link-time or run-time errors.)  For convenience and documentation of
 45 // intended use, classes in the virtual machine may be derived from one
 46 // of the following allocation classes, some of which define allocation
 47 // and deletion functions.
 48 // Note: std::malloc and std::free should never called directly.
 49 
 50 //
 51 // For objects allocated in the resource area (see resourceArea.hpp).
 52 // - ResourceObj
 53 //
 54 // For objects allocated in the C-heap (managed by: free &amp; malloc and tracked with NMT)
 55 // - CHeapObj
 56 //
 57 // For objects allocated on the stack.
 58 // - StackObj
 59 //
 60 // For classes used as name spaces.
 61 // - AllStatic
 62 //
 63 // For classes in Metaspace (class data)
 64 // - MetaspaceObj
 65 //
 66 // The printable subclasses are used for debugging and define virtual
 67 // member functions for printing. Classes that avoid allocating the
 68 // vtbl entries in the objects should therefore not be the printable
 69 // subclasses.
 70 //
 71 // The following macros and function should be used to allocate memory
 72 // directly in the resource area or in the C-heap, The _OBJ variants
 73 // of the NEW/FREE_C_HEAP macros are used for alloc/dealloc simple
 74 // objects which are not inherited from CHeapObj, note constructor and
 75 // destructor are not called. The preferable way to allocate objects
 76 // is using the new operator.
 77 //
 78 // WARNING: The array variant must only be used for a homogenous array
 79 // where all objects are of the exact type specified. If subtypes are
 80 // stored in the array then must pay attention to calling destructors
 81 // at needed.
 82 //
 83 //   NEW_RESOURCE_ARRAY(type, size)
 84 //   NEW_RESOURCE_OBJ(type)
 85 //   NEW_C_HEAP_ARRAY(type, size)
 86 //   NEW_C_HEAP_OBJ(type, memflags)
 87 //   FREE_C_HEAP_ARRAY(type, old)
 88 //   FREE_C_HEAP_OBJ(objname, type, memflags)
 89 //   char* AllocateHeap(size_t size, const char* name);
 90 //   void  FreeHeap(void* p);
 91 //
 92 
 93 // In non product mode we introduce a super class for all allocation classes
 94 // that supports printing.
 95 // We avoid the superclass in product mode to save space.
 96 
 97 #ifdef PRODUCT
 98 #define ALLOCATION_SUPER_CLASS_SPEC
 99 #else
100 #define ALLOCATION_SUPER_CLASS_SPEC : public AllocatedObj
101 class AllocatedObj {
102  public:
103   // Printing support
104   void print() const;
105   void print_value() const;
106 
107   virtual void print_on(outputStream* st) const;
108   virtual void print_value_on(outputStream* st) const;
109 };
110 #endif
111 
112 #define MEMORY_TYPES_DO(f) \
113   /* Memory type by sub systems. It occupies lower byte. */  \
114   f(mtJavaHeap,      &quot;Java Heap&quot;)   /* Java heap                                 */ \
115   f(mtClass,         &quot;Class&quot;)       /* Java classes                              */ \
116   f(mtThread,        &quot;Thread&quot;)      /* thread objects                            */ \
117   f(mtThreadStack,   &quot;Thread Stack&quot;)                                                \
118   f(mtCode,          &quot;Code&quot;)        /* generated code                            */ \
119   f(mtGC,            &quot;GC&quot;)                                                          \
120   f(mtCompiler,      &quot;Compiler&quot;)                                                    \
121   f(mtInternal,      &quot;Internal&quot;)    /* memory used by VM, but does not belong to */ \
122                                     /* any of above categories, and not used by  */ \
123                                     /* NMT                                       */ \
124   f(mtOther,         &quot;Other&quot;)       /* memory not used by VM                     */ \
125   f(mtSymbol,        &quot;Symbol&quot;)                                                      \
126   f(mtNMT,           &quot;Native Memory Tracking&quot;)  /* memory used by NMT            */ \
127   f(mtClassShared,   &quot;Shared class space&quot;)      /* class data sharing            */ \
128   f(mtChunk,         &quot;Arena Chunk&quot;) /* chunk that holds content of arenas        */ \
129   f(mtTest,          &quot;Test&quot;)        /* Test type for verifying NMT               */ \
130   f(mtTracing,       &quot;Tracing&quot;)                                                     \
131   f(mtLogging,       &quot;Logging&quot;)                                                     \
132   f(mtArguments,     &quot;Arguments&quot;)                                                   \
133   f(mtModule,        &quot;Module&quot;)                                                      \
134   f(mtSafepoint,     &quot;Safepoint&quot;)                                                   \
135   f(mtSynchronizer,  &quot;Synchronization&quot;)                                             \
136   f(mtNone,          &quot;Unknown&quot;)                                                     \
137   //end
138 
139 #define MEMORY_TYPE_DECLARE_ENUM(type, human_readable) \
140   type,
141 
142 /*
143  * Memory types
144  */
145 enum MemoryType {
146   MEMORY_TYPES_DO(MEMORY_TYPE_DECLARE_ENUM)
147   mt_number_of_types   // number of memory types (mtDontTrack
148                        // is not included as validate type)
149 };
150 
151 typedef MemoryType MEMFLAGS;
152 
153 
154 #if INCLUDE_NMT
155 
156 extern bool NMT_track_callsite;
157 
158 #else
159 
160 const bool NMT_track_callsite = false;
161 
162 #endif // INCLUDE_NMT
163 
164 class NativeCallStack;
165 
166 
167 char* AllocateHeap(size_t size,
168                    MEMFLAGS flags,
169                    const NativeCallStack&amp; stack,
170                    AllocFailType alloc_failmode = AllocFailStrategy::EXIT_OOM);
171 char* AllocateHeap(size_t size,
172                    MEMFLAGS flags,
173                    AllocFailType alloc_failmode = AllocFailStrategy::EXIT_OOM);
174 
175 char* ReallocateHeap(char *old,
176                      size_t size,
177                      MEMFLAGS flag,
178                      AllocFailType alloc_failmode = AllocFailStrategy::EXIT_OOM);
179 
180 void FreeHeap(void* p);
181 
182 template &lt;MEMFLAGS F&gt; class CHeapObj ALLOCATION_SUPER_CLASS_SPEC {
183  public:
184   ALWAYSINLINE void* operator new(size_t size) throw() {
185     return (void*)AllocateHeap(size, F);
186   }
187 
188   ALWAYSINLINE void* operator new(size_t size,
189                                   const NativeCallStack&amp; stack) throw() {
190     return (void*)AllocateHeap(size, F, stack);
191   }
192 
193   ALWAYSINLINE void* operator new(size_t size, const std::nothrow_t&amp;,
194                                   const NativeCallStack&amp; stack) throw() {
195     return (void*)AllocateHeap(size, F, stack, AllocFailStrategy::RETURN_NULL);
196   }
197 
198   ALWAYSINLINE void* operator new(size_t size, const std::nothrow_t&amp;) throw() {
199     return (void*)AllocateHeap(size, F, AllocFailStrategy::RETURN_NULL);
200   }
201 
202   ALWAYSINLINE void* operator new[](size_t size) throw() {
203     return (void*)AllocateHeap(size, F);
204   }
205 
206   ALWAYSINLINE void* operator new[](size_t size,
207                                   const NativeCallStack&amp; stack) throw() {
208     return (void*)AllocateHeap(size, F, stack);
209   }
210 
211   ALWAYSINLINE void* operator new[](size_t size, const std::nothrow_t&amp;,
212                                     const NativeCallStack&amp; stack) throw() {
213     return (void*)AllocateHeap(size, F, stack, AllocFailStrategy::RETURN_NULL);
214   }
215 
216   ALWAYSINLINE void* operator new[](size_t size, const std::nothrow_t&amp;) throw() {
217     return (void*)AllocateHeap(size, F, AllocFailStrategy::RETURN_NULL);
218   }
219 
220   void  operator delete(void* p)     { FreeHeap(p); }
221   void  operator delete [] (void* p) { FreeHeap(p); }
222 };
223 
224 // Base class for objects allocated on the stack only.
225 // Calling new or delete will result in fatal error.
226 
227 class StackObj ALLOCATION_SUPER_CLASS_SPEC {
228  private:
229   void* operator new(size_t size) throw();
230   void* operator new [](size_t size) throw();
231 #ifdef __IBMCPP__
232  public:
233 #endif
234   void  operator delete(void* p);
235   void  operator delete [](void* p);
236 };
237 
238 // Base class for objects stored in Metaspace.
239 // Calling delete will result in fatal error.
240 //
241 // Do not inherit from something with a vptr because this class does
242 // not introduce one.  This class is used to allocate both shared read-only
243 // and shared read-write classes.
244 //
245 
246 class ClassLoaderData;
247 class MetaspaceClosure;
248 
249 class MetaspaceObj {
250   friend class VMStructs;
251   // When CDS is enabled, all shared metaspace objects are mapped
252   // into a single contiguous memory block, so we can use these
253   // two pointers to quickly determine if something is in the
254   // shared metaspace.
255   //
256   // When CDS is not enabled, both pointers are set to NULL.
257   static void* _shared_metaspace_base; // (inclusive) low address
258   static void* _shared_metaspace_top;  // (exclusive) high address
259 
260  public:
261   bool is_metaspace_object() const;
262   bool is_shared() const {
263     // If no shared metaspace regions are mapped, _shared_metaspace_{base,top} will
264     // both be NULL and all values of p will be rejected quickly.
265     return (((void*)this) &lt; _shared_metaspace_top &amp;&amp; ((void*)this) &gt;= _shared_metaspace_base);
266   }
267   void print_address_on(outputStream* st) const;  // nonvirtual address printing
268 
269   static void set_shared_metaspace_range(void* base, void* top) {
270     _shared_metaspace_base = base;
271     _shared_metaspace_top = top;
272   }
273   static void* shared_metaspace_base() { return _shared_metaspace_base; }
274   static void* shared_metaspace_top()  { return _shared_metaspace_top;  }
275 
276 #define METASPACE_OBJ_TYPES_DO(f) \
277   f(Class) \
278   f(Symbol) \
279   f(TypeArrayU1) \
280   f(TypeArrayU2) \
281   f(TypeArrayU4) \
282   f(TypeArrayU8) \
283   f(TypeArrayOther) \
284   f(Method) \
285   f(ConstMethod) \
286   f(MethodData) \
287   f(ConstantPool) \
288   f(ConstantPoolCache) \
289   f(Annotations) \
290   f(MethodCounters)
291 
292 #define METASPACE_OBJ_TYPE_DECLARE(name) name ## Type,
293 #define METASPACE_OBJ_TYPE_NAME_CASE(name) case name ## Type: return #name;
294 
295   enum Type {
296     // Types are MetaspaceObj::ClassType, MetaspaceObj::SymbolType, etc
297     METASPACE_OBJ_TYPES_DO(METASPACE_OBJ_TYPE_DECLARE)
298     _number_of_types
299   };
300 
301   static const char * type_name(Type type) {
302     switch(type) {
303     METASPACE_OBJ_TYPES_DO(METASPACE_OBJ_TYPE_NAME_CASE)
304     default:
305       ShouldNotReachHere();
306       return NULL;
307     }
308   }
309 
310   static MetaspaceObj::Type array_type(size_t elem_size) {
311     switch (elem_size) {
312     case 1: return TypeArrayU1Type;
313     case 2: return TypeArrayU2Type;
314     case 4: return TypeArrayU4Type;
315     case 8: return TypeArrayU8Type;
316     default:
317       return TypeArrayOtherType;
318     }
319   }
320 
321   void* operator new(size_t size, ClassLoaderData* loader_data,
322                      size_t word_size,
323                      Type type, Thread* thread) throw();
324                      // can&#39;t use TRAPS from this header file.
325   void operator delete(void* p) { ShouldNotCallThis(); }
326 
327   // Declare a *static* method with the same signature in any subclass of MetaspaceObj
328   // that should be read-only by default. See symbol.hpp for an example. This function
329   // is used by the templates in metaspaceClosure.hpp
330   static bool is_read_only_by_default() { return false; }
331 };
332 
333 // Base class for classes that constitute name spaces.
334 
335 class Arena;
336 
337 class AllStatic {
338  public:
339   AllStatic()  { ShouldNotCallThis(); }
340   ~AllStatic() { ShouldNotCallThis(); }
341 };
342 
343 
344 extern char* resource_allocate_bytes(size_t size,
345     AllocFailType alloc_failmode = AllocFailStrategy::EXIT_OOM);
346 extern char* resource_allocate_bytes(Thread* thread, size_t size,
347     AllocFailType alloc_failmode = AllocFailStrategy::EXIT_OOM);
348 extern char* resource_reallocate_bytes( char *old, size_t old_size, size_t new_size,
349     AllocFailType alloc_failmode = AllocFailStrategy::EXIT_OOM);
350 extern void resource_free_bytes( char *old, size_t size );
351 
352 //----------------------------------------------------------------------
353 // Base class for objects allocated in the resource area per default.
354 // Optionally, objects may be allocated on the C heap with
355 // new(ResourceObj::C_HEAP) Foo(...) or in an Arena with new (&amp;arena)
356 // ResourceObj&#39;s can be allocated within other objects, but don&#39;t use
357 // new or delete (allocation_type is unknown).  If new is used to allocate,
358 // use delete to deallocate.
359 class ResourceObj ALLOCATION_SUPER_CLASS_SPEC {
360  public:
361   enum allocation_type { STACK_OR_EMBEDDED = 0, RESOURCE_AREA, C_HEAP, ARENA, allocation_mask = 0x3 };
362   static void set_allocation_type(address res, allocation_type type) NOT_DEBUG_RETURN;
363 #ifdef ASSERT
364  private:
365   // When this object is allocated on stack the new() operator is not
366   // called but garbage on stack may look like a valid allocation_type.
367   // Store negated &#39;this&#39; pointer when new() is called to distinguish cases.
368   // Use second array&#39;s element for verification value to distinguish garbage.
369   uintptr_t _allocation_t[2];
370   bool is_type_set() const;
371   void initialize_allocation_info();
372  public:
373   allocation_type get_allocation_type() const;
374   bool allocated_on_stack()    const { return get_allocation_type() == STACK_OR_EMBEDDED; }
375   bool allocated_on_res_area() const { return get_allocation_type() == RESOURCE_AREA; }
376   bool allocated_on_C_heap()   const { return get_allocation_type() == C_HEAP; }
377   bool allocated_on_arena()    const { return get_allocation_type() == ARENA; }
378 protected:
379   ResourceObj(); // default constructor
380   ResourceObj(const ResourceObj&amp; r); // default copy constructor
381   ResourceObj&amp; operator=(const ResourceObj&amp; r); // default copy assignment
382   ~ResourceObj();
383 #endif // ASSERT
384 
385  public:
386   void* operator new(size_t size, allocation_type type, MEMFLAGS flags) throw();
387   void* operator new [](size_t size, allocation_type type, MEMFLAGS flags) throw();
388   void* operator new(size_t size, const std::nothrow_t&amp;  nothrow_constant,
389       allocation_type type, MEMFLAGS flags) throw();
390   void* operator new [](size_t size, const std::nothrow_t&amp;  nothrow_constant,
391       allocation_type type, MEMFLAGS flags) throw();
392 
393   void* operator new(size_t size, Arena *arena) throw();
394 
395   void* operator new [](size_t size, Arena *arena) throw();
396 
397   void* operator new(size_t size) throw() {
398       address res = (address)resource_allocate_bytes(size);
399       DEBUG_ONLY(set_allocation_type(res, RESOURCE_AREA);)
400       return res;
401   }
402 
403   void* operator new(size_t size, const std::nothrow_t&amp; nothrow_constant) throw() {
404       address res = (address)resource_allocate_bytes(size, AllocFailStrategy::RETURN_NULL);
405       DEBUG_ONLY(if (res != NULL) set_allocation_type(res, RESOURCE_AREA);)
406       return res;
407   }
408 
409   void* operator new [](size_t size) throw() {
410       address res = (address)resource_allocate_bytes(size);
411       DEBUG_ONLY(set_allocation_type(res, RESOURCE_AREA);)
412       return res;
413   }
414 
415   void* operator new [](size_t size, const std::nothrow_t&amp; nothrow_constant) throw() {
416       address res = (address)resource_allocate_bytes(size, AllocFailStrategy::RETURN_NULL);
417       DEBUG_ONLY(if (res != NULL) set_allocation_type(res, RESOURCE_AREA);)
418       return res;
419   }
420 
421   void  operator delete(void* p);
422   void  operator delete [](void* p);
423 };
424 
425 // One of the following macros must be used when allocating an array
426 // or object to determine whether it should reside in the C heap on in
427 // the resource area.
428 
429 #define NEW_RESOURCE_ARRAY(type, size)\
430   (type*) resource_allocate_bytes((size) * sizeof(type))
431 
432 #define NEW_RESOURCE_ARRAY_RETURN_NULL(type, size)\
433   (type*) resource_allocate_bytes((size) * sizeof(type), AllocFailStrategy::RETURN_NULL)
434 
435 #define NEW_RESOURCE_ARRAY_IN_THREAD(thread, type, size)\
436   (type*) resource_allocate_bytes(thread, (size) * sizeof(type))
437 
438 #define NEW_RESOURCE_ARRAY_IN_THREAD_RETURN_NULL(thread, type, size)\
439   (type*) resource_allocate_bytes(thread, (size) * sizeof(type), AllocFailStrategy::RETURN_NULL)
440 
441 #define REALLOC_RESOURCE_ARRAY(type, old, old_size, new_size)\
442   (type*) resource_reallocate_bytes((char*)(old), (old_size) * sizeof(type), (new_size) * sizeof(type))
443 
444 #define REALLOC_RESOURCE_ARRAY_RETURN_NULL(type, old, old_size, new_size)\
445   (type*) resource_reallocate_bytes((char*)(old), (old_size) * sizeof(type),\
446                                     (new_size) * sizeof(type), AllocFailStrategy::RETURN_NULL)
447 
448 #define FREE_RESOURCE_ARRAY(type, old, size)\
449   resource_free_bytes((char*)(old), (size) * sizeof(type))
450 
451 #define FREE_FAST(old)\
452     /* nop */
453 
454 #define NEW_RESOURCE_OBJ(type)\
455   NEW_RESOURCE_ARRAY(type, 1)
456 
457 #define NEW_RESOURCE_OBJ_RETURN_NULL(type)\
458   NEW_RESOURCE_ARRAY_RETURN_NULL(type, 1)
459 
460 #define NEW_C_HEAP_ARRAY3(type, size, memflags, pc, allocfail)\
461   (type*) AllocateHeap((size) * sizeof(type), memflags, pc, allocfail)
462 
463 #define NEW_C_HEAP_ARRAY2(type, size, memflags, pc)\
464   (type*) (AllocateHeap((size) * sizeof(type), memflags, pc))
465 
466 #define NEW_C_HEAP_ARRAY(type, size, memflags)\
467   (type*) (AllocateHeap((size) * sizeof(type), memflags))
468 
469 #define NEW_C_HEAP_ARRAY2_RETURN_NULL(type, size, memflags, pc)\
470   NEW_C_HEAP_ARRAY3(type, (size), memflags, pc, AllocFailStrategy::RETURN_NULL)
471 
472 #define NEW_C_HEAP_ARRAY_RETURN_NULL(type, size, memflags)\
473   NEW_C_HEAP_ARRAY3(type, (size), memflags, CURRENT_PC, AllocFailStrategy::RETURN_NULL)
474 
475 #define REALLOC_C_HEAP_ARRAY(type, old, size, memflags)\
476   (type*) (ReallocateHeap((char*)(old), (size) * sizeof(type), memflags))
477 
478 #define REALLOC_C_HEAP_ARRAY_RETURN_NULL(type, old, size, memflags)\
479   (type*) (ReallocateHeap((char*)(old), (size) * sizeof(type), memflags, AllocFailStrategy::RETURN_NULL))
480 
481 #define FREE_C_HEAP_ARRAY(type, old) \
482   FreeHeap((char*)(old))
483 
484 // allocate type in heap without calling ctor
485 #define NEW_C_HEAP_OBJ(type, memflags)\
486   NEW_C_HEAP_ARRAY(type, 1, memflags)
487 
488 #define NEW_C_HEAP_OBJ_RETURN_NULL(type, memflags)\
489   NEW_C_HEAP_ARRAY_RETURN_NULL(type, 1, memflags)
490 
491 // deallocate obj of type in heap without calling dtor
492 #define FREE_C_HEAP_OBJ(objname)\
493   FreeHeap((char*)objname);
494 
495 // for statistics
496 #ifndef PRODUCT
497 class AllocStats : StackObj {
498   julong start_mallocs, start_frees;
499   julong start_malloc_bytes, start_mfree_bytes, start_res_bytes;
500  public:
501   AllocStats();
502 
503   julong num_mallocs();    // since creation of receiver
504   julong alloc_bytes();
505   julong num_frees();
506   julong free_bytes();
507   julong resource_bytes();
508   void   print();
509 };
510 #endif
511 
512 
513 //------------------------------ReallocMark---------------------------------
514 // Code which uses REALLOC_RESOURCE_ARRAY should check an associated
515 // ReallocMark, which is declared in the same scope as the reallocated
516 // pointer.  Any operation that could __potentially__ cause a reallocation
517 // should check the ReallocMark.
518 class ReallocMark: public StackObj {
519 protected:
520   NOT_PRODUCT(int _nesting;)
521 
522 public:
523   ReallocMark()   PRODUCT_RETURN;
524   void check()    PRODUCT_RETURN;
525 };
526 
527 // Helper class to allocate arrays that may become large.
528 // Uses the OS malloc for allocations smaller than ArrayAllocatorMallocLimit
529 // and uses mapped memory for larger allocations.
530 // Most OS mallocs do something similar but Solaris malloc does not revert
531 // to mapped memory for large allocations. By default ArrayAllocatorMallocLimit
532 // is set so that we always use malloc except for Solaris where we set the
533 // limit to get mapped memory.
534 template &lt;class E&gt;
535 class ArrayAllocator : public AllStatic {
536  private:
537   static bool should_use_malloc(size_t length);
538 
539   static E* allocate_malloc(size_t length, MEMFLAGS flags);
540   static E* allocate_mmap(size_t length, MEMFLAGS flags);
541 
542   static void free_malloc(E* addr, size_t length);
543   static void free_mmap(E* addr, size_t length);
544 
545  public:
546   static E* allocate(size_t length, MEMFLAGS flags);
547   static E* reallocate(E* old_addr, size_t old_length, size_t new_length, MEMFLAGS flags);
548   static void free(E* addr, size_t length);
549 };
550 
551 // Uses mmaped memory for all allocations. All allocations are initially
552 // zero-filled. No pre-touching.
553 template &lt;class E&gt;
554 class MmapArrayAllocator : public AllStatic {
555  private:
556   static size_t size_for(size_t length);
557 
558  public:
559   static E* allocate_or_null(size_t length, MEMFLAGS flags);
560   static E* allocate(size_t length, MEMFLAGS flags);
561   static void free(E* addr, size_t length);
562 };
563 
564 // Uses malloc:ed memory for all allocations.
565 template &lt;class E&gt;
566 class MallocArrayAllocator : public AllStatic {
567  public:
568   static size_t size_for(size_t length);
569 
570   static E* allocate(size_t length, MEMFLAGS flags);
571   static void free(E* addr);
572 };
573 
574 #endif // SHARE_MEMORY_ALLOCATION_HPP
    </pre>
  </body>
</html>