<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/memory/allocation.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;memory/allocation.hpp&quot;
 27 #include &quot;memory/allocation.inline.hpp&quot;
 28 #include &quot;memory/arena.hpp&quot;
 29 #include &quot;memory/metaspaceShared.hpp&quot;
 30 #include &quot;memory/resourceArea.hpp&quot;
 31 #include &quot;memory/universe.hpp&quot;
 32 #include &quot;runtime/atomic.hpp&quot;
 33 #include &quot;runtime/os.hpp&quot;
 34 #include &quot;runtime/task.hpp&quot;
 35 #include &quot;runtime/threadCritical.hpp&quot;
 36 #include &quot;services/memTracker.hpp&quot;
 37 #include &quot;utilities/ostream.hpp&quot;
 38 
 39 // allocate using malloc; will fail if no memory available
 40 char* AllocateHeap(size_t size,
 41                    MEMFLAGS flags,
 42                    const NativeCallStack&amp; stack,
 43                    AllocFailType alloc_failmode /* = AllocFailStrategy::EXIT_OOM*/) {
 44   char* p = (char*) os::malloc(size, flags, stack);
 45   if (p == NULL &amp;&amp; alloc_failmode == AllocFailStrategy::EXIT_OOM) {
 46     vm_exit_out_of_memory(size, OOM_MALLOC_ERROR, &quot;AllocateHeap&quot;);
 47   }
 48   return p;
 49 }
 50 
 51 char* AllocateHeap(size_t size,
 52                    MEMFLAGS flags,
 53                    AllocFailType alloc_failmode /* = AllocFailStrategy::EXIT_OOM*/) {
 54   return AllocateHeap(size, flags, CALLER_PC);
 55 }
 56 
 57 char* ReallocateHeap(char *old,
 58                      size_t size,
 59                      MEMFLAGS flag,
 60                      AllocFailType alloc_failmode) {
 61   char* p = (char*) os::realloc(old, size, flag, CALLER_PC);
 62   if (p == NULL &amp;&amp; alloc_failmode == AllocFailStrategy::EXIT_OOM) {
 63     vm_exit_out_of_memory(size, OOM_MALLOC_ERROR, &quot;ReallocateHeap&quot;);
 64   }
 65   return p;
 66 }
 67 
 68 void FreeHeap(void* p) {
 69   os::free(p);
 70 }
 71 
 72 void* MetaspaceObj::_shared_metaspace_base = NULL;
 73 void* MetaspaceObj::_shared_metaspace_top  = NULL;
 74 
 75 void* StackObj::operator new(size_t size)     throw() { ShouldNotCallThis(); return 0; }
 76 void  StackObj::operator delete(void* p)              { ShouldNotCallThis(); }
 77 void* StackObj::operator new [](size_t size)  throw() { ShouldNotCallThis(); return 0; }
 78 void  StackObj::operator delete [](void* p)           { ShouldNotCallThis(); }
 79 
 80 void* MetaspaceObj::operator new(size_t size, ClassLoaderData* loader_data,
 81                                  size_t word_size,
 82                                  MetaspaceObj::Type type, TRAPS) throw() {
 83   // Klass has it&#39;s own operator new
 84   return Metaspace::allocate(loader_data, word_size, type, THREAD);
 85 }
 86 
 87 bool MetaspaceObj::is_metaspace_object() const {
 88   return Metaspace::contains((void*)this);
 89 }
 90 
 91 void MetaspaceObj::print_address_on(outputStream* st) const {
 92   st-&gt;print(&quot; {&quot; INTPTR_FORMAT &quot;}&quot;, p2i(this));
 93 }
 94 
 95 void* ResourceObj::operator new(size_t size, Arena *arena) throw() {
 96   address res = (address)arena-&gt;Amalloc(size);
 97   DEBUG_ONLY(set_allocation_type(res, ARENA);)
 98   return res;
 99 }
100 
101 void* ResourceObj::operator new [](size_t size, Arena *arena) throw() {
102   address res = (address)arena-&gt;Amalloc(size);
103   DEBUG_ONLY(set_allocation_type(res, ARENA);)
104   return res;
105 }
106 
107 void* ResourceObj::operator new(size_t size, allocation_type type, MEMFLAGS flags) throw() {
108   address res = NULL;
109   switch (type) {
110    case C_HEAP:
111     res = (address)AllocateHeap(size, flags, CALLER_PC);
112     DEBUG_ONLY(set_allocation_type(res, C_HEAP);)
113     break;
114    case RESOURCE_AREA:
115     // new(size) sets allocation type RESOURCE_AREA.
116     res = (address)operator new(size);
117     break;
118    default:
119     ShouldNotReachHere();
120   }
121   return res;
122 }
123 
124 void* ResourceObj::operator new [](size_t size, allocation_type type, MEMFLAGS flags) throw() {
125   return (address) operator new(size, type, flags);
126 }
127 
128 void* ResourceObj::operator new(size_t size, const std::nothrow_t&amp;  nothrow_constant,
129     allocation_type type, MEMFLAGS flags) throw() {
130   // should only call this with std::nothrow, use other operator new() otherwise
131   address res = NULL;
132   switch (type) {
133    case C_HEAP:
134     res = (address)AllocateHeap(size, flags, CALLER_PC, AllocFailStrategy::RETURN_NULL);
135     DEBUG_ONLY(if (res!= NULL) set_allocation_type(res, C_HEAP);)
136     break;
137    case RESOURCE_AREA:
138     // new(size) sets allocation type RESOURCE_AREA.
139     res = (address)operator new(size, std::nothrow);
140     break;
141    default:
142     ShouldNotReachHere();
143   }
144   return res;
145 }
146 
147 void* ResourceObj::operator new [](size_t size, const std::nothrow_t&amp;  nothrow_constant,
148     allocation_type type, MEMFLAGS flags) throw() {
149   return (address)operator new(size, nothrow_constant, type, flags);
150 }
151 
152 void ResourceObj::operator delete(void* p) {
153   assert(((ResourceObj *)p)-&gt;allocated_on_C_heap(),
154          &quot;delete only allowed for C_HEAP objects&quot;);
155   DEBUG_ONLY(((ResourceObj *)p)-&gt;_allocation_t[0] = (uintptr_t)badHeapOopVal;)
156   FreeHeap(p);
157 }
158 
159 void ResourceObj::operator delete [](void* p) {
160   operator delete(p);
161 }
162 
163 #ifdef ASSERT
164 void ResourceObj::set_allocation_type(address res, allocation_type type) {
165   // Set allocation type in the resource object
166   uintptr_t allocation = (uintptr_t)res;
167   assert((allocation &amp; allocation_mask) == 0, &quot;address should be aligned to 4 bytes at least: &quot; INTPTR_FORMAT, p2i(res));
168   assert(type &lt;= allocation_mask, &quot;incorrect allocation type&quot;);
169   ResourceObj* resobj = (ResourceObj *)res;
170   resobj-&gt;_allocation_t[0] = ~(allocation + type);
171   if (type != STACK_OR_EMBEDDED) {
172     // Called from operator new(), set verification value.
173     resobj-&gt;_allocation_t[1] = (uintptr_t)&amp;(resobj-&gt;_allocation_t[1]) + type;
174   }
175 }
176 
177 ResourceObj::allocation_type ResourceObj::get_allocation_type() const {
178   assert(~(_allocation_t[0] | allocation_mask) == (uintptr_t)this, &quot;lost resource object&quot;);
179   return (allocation_type)((~_allocation_t[0]) &amp; allocation_mask);
180 }
181 
182 bool ResourceObj::is_type_set() const {
183   allocation_type type = (allocation_type)(_allocation_t[1] &amp; allocation_mask);
184   return get_allocation_type()  == type &amp;&amp;
185          (_allocation_t[1] - type) == (uintptr_t)(&amp;_allocation_t[1]);
186 }
187 
188 // This whole business of passing information from ResourceObj::operator new
189 // to the ResourceObj constructor via fields in the &quot;object&quot; is technically UB.
190 // But it seems to work within the limitations of HotSpot usage (such as no
191 // multiple inheritance) with the compilers and compiler options we&#39;re using.
192 // And it gives some possibly useful checking for misuse of ResourceObj.
193 void ResourceObj::initialize_allocation_info() {
194   if (~(_allocation_t[0] | allocation_mask) != (uintptr_t)this) {
195     // Operator new() is not called for allocations
196     // on stack and for embedded objects.
197     set_allocation_type((address)this, STACK_OR_EMBEDDED);
198   } else if (allocated_on_stack()) { // STACK_OR_EMBEDDED
199     // For some reason we got a value which resembles
200     // an embedded or stack object (operator new() does not
201     // set such type). Keep it since it is valid value
202     // (even if it was garbage).
203     // Ignore garbage in other fields.
204   } else if (is_type_set()) {
205     // Operator new() was called and type was set.
206     assert(!allocated_on_stack(),
207            &quot;not embedded or stack, this(&quot; PTR_FORMAT &quot;) type %d a[0]=(&quot; PTR_FORMAT &quot;) a[1]=(&quot; PTR_FORMAT &quot;)&quot;,
208            p2i(this), get_allocation_type(), _allocation_t[0], _allocation_t[1]);
209   } else {
210     // Operator new() was not called.
211     // Assume that it is embedded or stack object.
212     set_allocation_type((address)this, STACK_OR_EMBEDDED);
213   }
214   _allocation_t[1] = 0; // Zap verification value
215 }
216 
217 ResourceObj::ResourceObj() {
218   initialize_allocation_info();
219 }
220 
221 ResourceObj::ResourceObj(const ResourceObj&amp;) {
222   // Initialize _allocation_t as a new object, ignoring object being copied.
223   initialize_allocation_info();
224 }
225 
226 ResourceObj&amp; ResourceObj::operator=(const ResourceObj&amp; r) {
227   assert(allocated_on_stack(),
228          &quot;copy only into local, this(&quot; PTR_FORMAT &quot;) type %d a[0]=(&quot; PTR_FORMAT &quot;) a[1]=(&quot; PTR_FORMAT &quot;)&quot;,
229          p2i(this), get_allocation_type(), _allocation_t[0], _allocation_t[1]);
230   // Keep current _allocation_t value;
231   return *this;
232 }
233 
234 ResourceObj::~ResourceObj() {
235   // allocated_on_C_heap() also checks that encoded (in _allocation) address == this.
236   if (!allocated_on_C_heap()) { // ResourceObj::delete() will zap _allocation for C_heap.
237     _allocation_t[0] = (uintptr_t)badHeapOopVal; // zap type
238   }
239 }
240 #endif // ASSERT
241 
242 //--------------------------------------------------------------------------------------
243 // Non-product code
244 
245 #ifndef PRODUCT
246 void AllocatedObj::print() const       { print_on(tty); }
247 void AllocatedObj::print_value() const { print_value_on(tty); }
248 
249 void AllocatedObj::print_on(outputStream* st) const {
250   st-&gt;print_cr(&quot;AllocatedObj(&quot; INTPTR_FORMAT &quot;)&quot;, p2i(this));
251 }
252 
253 void AllocatedObj::print_value_on(outputStream* st) const {
254   st-&gt;print(&quot;AllocatedObj(&quot; INTPTR_FORMAT &quot;)&quot;, p2i(this));
255 }
256 
257 AllocStats::AllocStats() {
258   start_mallocs      = os::num_mallocs;
259   start_frees        = os::num_frees;
260   start_malloc_bytes = os::alloc_bytes;
261   start_mfree_bytes  = os::free_bytes;
262   start_res_bytes    = Arena::_bytes_allocated;
263 }
264 
265 julong  AllocStats::num_mallocs() { return os::num_mallocs - start_mallocs; }
266 julong  AllocStats::alloc_bytes() { return os::alloc_bytes - start_malloc_bytes; }
267 julong  AllocStats::num_frees()   { return os::num_frees - start_frees; }
268 julong  AllocStats::free_bytes()  { return os::free_bytes - start_mfree_bytes; }
269 julong  AllocStats::resource_bytes() { return Arena::_bytes_allocated - start_res_bytes; }
270 void    AllocStats::print() {
271   tty-&gt;print_cr(UINT64_FORMAT &quot; mallocs (&quot; UINT64_FORMAT &quot;MB), &quot;
272                 UINT64_FORMAT &quot; frees (&quot; UINT64_FORMAT &quot;MB), &quot; UINT64_FORMAT &quot;MB resrc&quot;,
273                 num_mallocs(), alloc_bytes()/M, num_frees(), free_bytes()/M, resource_bytes()/M);
274 }
275 
276 ReallocMark::ReallocMark() {
277 #ifdef ASSERT
278   Thread *thread = Thread::current();
279   _nesting = thread-&gt;resource_area()-&gt;nesting();
280 #endif
281 }
282 
283 void ReallocMark::check() {
284 #ifdef ASSERT
285   if (_nesting != Thread::current()-&gt;resource_area()-&gt;nesting()) {
286     fatal(&quot;allocation bug: array could grow within nested ResourceMark&quot;);
287   }
288 #endif
289 }
290 
291 #endif // Non-product
    </pre>
  </body>
</html>