<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/prims/jvmtiTagMap.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="jvmtiRedefineClasses.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="jvmtiTagMap.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/prims/jvmtiTagMap.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2003, 2018, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;classfile/classLoaderDataGraph.hpp&quot;
  27 #include &quot;classfile/javaClasses.inline.hpp&quot;
  28 #include &quot;classfile/symbolTable.hpp&quot;
  29 #include &quot;classfile/systemDictionary.hpp&quot;
  30 #include &quot;classfile/vmSymbols.hpp&quot;
  31 #include &quot;jvmtifiles/jvmtiEnv.hpp&quot;
  32 #include &quot;logging/log.hpp&quot;
  33 #include &quot;memory/allocation.inline.hpp&quot;
  34 #include &quot;memory/resourceArea.hpp&quot;

  35 #include &quot;oops/access.inline.hpp&quot;
  36 #include &quot;oops/arrayOop.inline.hpp&quot;
  37 #include &quot;oops/constantPool.inline.hpp&quot;
  38 #include &quot;oops/instanceMirrorKlass.hpp&quot;
  39 #include &quot;oops/objArrayKlass.hpp&quot;
  40 #include &quot;oops/objArrayOop.inline.hpp&quot;
  41 #include &quot;oops/oop.inline.hpp&quot;
  42 #include &quot;oops/typeArrayOop.inline.hpp&quot;
  43 #include &quot;prims/jvmtiEventController.hpp&quot;
  44 #include &quot;prims/jvmtiEventController.inline.hpp&quot;
  45 #include &quot;prims/jvmtiExport.hpp&quot;
  46 #include &quot;prims/jvmtiImpl.hpp&quot;
  47 #include &quot;prims/jvmtiTagMap.hpp&quot;
  48 #include &quot;runtime/biasedLocking.hpp&quot;
  49 #include &quot;runtime/frame.inline.hpp&quot;
  50 #include &quot;runtime/handles.inline.hpp&quot;
  51 #include &quot;runtime/javaCalls.hpp&quot;
  52 #include &quot;runtime/jniHandles.inline.hpp&quot;
  53 #include &quot;runtime/mutex.hpp&quot;
  54 #include &quot;runtime/mutexLocker.hpp&quot;
</pre>
<hr />
<pre>
  82 
  83   inline void init(oop object, jlong tag) {
  84     _object = object;
  85     _tag = tag;
  86     _next = NULL;
  87   }
  88 
  89   // constructor
  90   JvmtiTagHashmapEntry(oop object, jlong tag) { init(object, tag); }
  91 
  92  public:
  93 
  94   // accessor methods
  95   inline oop* object_addr() { return &amp;_object; }
  96   inline oop object()       { return NativeAccess&lt;ON_PHANTOM_OOP_REF&gt;::oop_load(object_addr()); }
  97   // Peek at the object without keeping it alive. The returned object must be
  98   // kept alive using a normal access if it leaks out of a thread transition from VM.
  99   inline oop object_peek()  {
 100     return NativeAccess&lt;ON_PHANTOM_OOP_REF | AS_NO_KEEPALIVE&gt;::oop_load(object_addr());
 101   }





 102   inline jlong tag() const  { return _tag; }
 103 
 104   inline void set_tag(jlong tag) {
 105     assert(tag != 0, &quot;can&#39;t be zero&quot;);
 106     _tag = tag;
 107   }
 108 
 109   inline bool equals(oop object) {
<span class="line-modified"> 110     return oopDesc::equals(object, object_peek());</span>
 111   }
 112 
 113   inline JvmtiTagHashmapEntry* next() const        { return _next; }
 114   inline void set_next(JvmtiTagHashmapEntry* next) { _next = next; }
 115 };
 116 
 117 
 118 // JvmtiTagHashmap
 119 //
 120 // A hashmap is essentially a table of pointers to entries. Entries
 121 // are hashed to a location, or position in the table, and then
 122 // chained from that location. The &quot;key&quot; for hashing is address of
 123 // the object, or oop. The &quot;value&quot; is the tag value.
 124 //
 125 // A hashmap maintains a count of the number entries in the hashmap
 126 // and resizes if the number of entries exceeds a given threshold.
 127 // The threshold is specified as a percentage of the size - for
 128 // example a threshold of 0.75 will trigger the hashmap to resize
 129 // if the number of entries is &gt;75% of table size.
 130 //
</pre>
<hr />
<pre>
 167     _size_index = size_index;
 168     _size = initial_size;
 169     _entry_count = 0;
 170     _trace_threshold = initial_trace_threshold;
 171     _load_factor = load_factor;
 172     _resize_threshold = (int)(_load_factor * _size);
 173     _resizing_enabled = true;
 174     size_t s = initial_size * sizeof(JvmtiTagHashmapEntry*);
 175     _table = (JvmtiTagHashmapEntry**)os::malloc(s, mtInternal);
 176     if (_table == NULL) {
 177       vm_exit_out_of_memory(s, OOM_MALLOC_ERROR,
 178         &quot;unable to allocate initial hashtable for jvmti object tags&quot;);
 179     }
 180     for (int i=0; i&lt;initial_size; i++) {
 181       _table[i] = NULL;
 182     }
 183   }
 184 
 185   // hash a given key (oop) with the specified size
 186   static unsigned int hash(oop key, int size) {
<span class="line-modified"> 187     ZGC_ONLY(assert(ZAddressMetadataShift &gt;= sizeof(unsigned int) * BitsPerByte, &quot;cast removes the metadata bits&quot;);)</span>
<span class="line-modified"> 188 </span>
<span class="line-modified"> 189     // shift right to get better distribution (as these bits will be zero</span>
<span class="line-removed"> 190     // with aligned addresses)</span>
<span class="line-removed"> 191     key = Access&lt;&gt;::resolve(key);</span>
<span class="line-removed"> 192     unsigned int addr = (unsigned int)(cast_from_oop&lt;intptr_t&gt;(key));</span>
<span class="line-removed"> 193 #ifdef _LP64</span>
<span class="line-removed"> 194     return (addr &gt;&gt; 3) % size;</span>
<span class="line-removed"> 195 #else</span>
<span class="line-removed"> 196     return (addr &gt;&gt; 2) % size;</span>
<span class="line-removed"> 197 #endif</span>
 198   }
 199 
 200   // hash a given key (oop)
 201   unsigned int hash(oop key) {
 202     return hash(key, _size);
 203   }
 204 
 205   // resize the hashmap - allocates a large table and re-hashes
 206   // all entries into the new table.
 207   void resize() {
 208     int new_size_index = _size_index+1;
 209     int new_size = _sizes[new_size_index];
 210     if (new_size &lt; 0) {
 211       // hashmap already at maximum capacity
 212       return;
 213     }
 214 
 215     // allocate new table
 216     size_t s = new_size * sizeof(JvmtiTagHashmapEntry*);
 217     JvmtiTagHashmapEntry** new_table = (JvmtiTagHashmapEntry**)os::malloc(s, mtInternal);
</pre>
<hr />
<pre>
 368     while (entry != NULL) {
 369       if (entry-&gt;equals(key)) {
 370         break;
 371       }
 372       prev = entry;
 373       entry = entry-&gt;next();
 374     }
 375     if (entry != NULL) {
 376       remove(prev, h, entry);
 377     }
 378     return entry;
 379   }
 380 
 381   // iterate over all entries in the hashmap
 382   void entry_iterate(JvmtiTagHashmapEntryClosure* closure);
 383 };
 384 
 385 // Tsan should know that the JVMTI TagMap is protected by a mutex.
 386 class TsanMutexScope : public StackObj {
 387  private:
<span class="line-modified"> 388   Monitor *_lock;  // Keep my own reference, for destructor.</span>
 389 
 390  public:
 391   // Don&#39;t actually lock it, just tell tsan we did.
<span class="line-modified"> 392   TsanMutexScope(Monitor* mutex) : _lock(mutex) {</span>
 393     TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(_lock));
 394   }
 395 
 396   ~TsanMutexScope() {
 397     TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_RELEASED(_lock));
 398   }
 399 };
 400 
 401 // possible hashmap sizes - odd primes that roughly double in size.
 402 // To avoid excessive resizing the odd primes from 4801-76831 and
 403 // 76831-307261 have been removed. The list must be terminated by -1.
 404 int JvmtiTagHashmap::_sizes[] =  { 4801, 76831, 307261, 614563, 1228891,
 405     2457733, 4915219, 9830479, 19660831, 39321619, 78643219, -1 };
 406 
 407 
 408 // A supporting class for iterating over all entries in Hashmap
 409 class JvmtiTagHashmapEntryClosure {
 410  public:
 411   virtual void do_entry(JvmtiTagHashmapEntry* entry) = 0;
 412 };
</pre>
<hr />
<pre>
 470   // this being seen as racy though is not really.
 471   //
 472   // The JvmtiTagMap gets created by the first thread to call tag_map_for; which
 473   // uses a lock to create it if need be.
 474   //
 475   // This means that this lock is created under a mutex but then,
 476   // subsequent uses do not have a lock to protect it (because not
 477   // needed in this case), however TSAN sees it as being needed because:
 478   //  - Another thread can come and get the newly created JvmtiTagMap without a
 479   //  lock and acquire the lock.
 480   //  - This provokes a race for TSAN on the lock itself, though there is no
 481   //  real issue.
 482   //
 483   //  Not creating the lock or having a fence mechanism to tell TSAN this is
 484   //  safe (a fake lock around this lock for example) seem to be the only
 485   //  solutions.
 486 
 487   _hashmap = new JvmtiTagHashmap();
 488 
 489   // finally add us to the environment
<span class="line-modified"> 490   ((JvmtiEnvBase *)env)-&gt;set_tag_map(this);</span>
 491 }
 492 
 493 
 494 // destroy a JvmtiTagMap
 495 JvmtiTagMap::~JvmtiTagMap() {
 496   // no lock acquired as we assume the enclosing environment is
 497   // also being destroryed.
 498   ((JvmtiEnvBase *)_env)-&gt;set_tag_map(NULL);
 499 
 500   JvmtiTagHashmapEntry** table = _hashmap-&gt;table();
 501   for (int j = 0; j &lt; _hashmap-&gt;size(); j++) {
 502     JvmtiTagHashmapEntry* entry = table[j];
 503     while (entry != NULL) {
 504       JvmtiTagHashmapEntry* next = entry-&gt;next();
 505       delete entry;
 506       entry = next;
 507     }
 508   }
 509 
 510   // finally destroy the hashmap
 511   delete _hashmap;
 512   _hashmap = NULL;
 513 
 514   // remove any entries on the free list
 515   JvmtiTagHashmapEntry* entry = _free_entries;
 516   while (entry != NULL) {
 517     JvmtiTagHashmapEntry* next = entry-&gt;next();
 518     delete entry;
 519     entry = next;
 520   }
 521   _free_entries = NULL;
 522 
 523   // TSAN Note: see above for the Tsan creation note.
 524 }
 525 
 526 // create a hashmap entry
 527 // - if there&#39;s an entry on the (per-environment) free list then this
 528 // is returned. Otherwise an new entry is allocated.
 529 JvmtiTagHashmapEntry* JvmtiTagMap::create_entry(oop ref, jlong tag) {
 530   assert(Thread::current()-&gt;is_VM_thread() || is_locked(), &quot;checking&quot;);





 531   JvmtiTagHashmapEntry* entry;
 532   if (_free_entries == NULL) {
 533     entry = new JvmtiTagHashmapEntry(ref, tag);
 534   } else {
 535     assert(_free_entries_count &gt; 0, &quot;mismatched _free_entries_count&quot;);
 536     _free_entries_count--;
 537     entry = _free_entries;
 538     _free_entries = entry-&gt;next();
 539     entry-&gt;init(ref, tag);
 540   }
 541   return entry;
 542 }
 543 
 544 // destroy an entry by returning it to the free list
 545 void JvmtiTagMap::destroy_entry(JvmtiTagHashmapEntry* entry) {
 546   assert(SafepointSynchronize::is_at_safepoint() || is_locked(), &quot;checking&quot;);
 547   // limit the size of the free list
 548   if (_free_entries_count &gt;= max_free_entries) {
 549     delete entry;
 550   } else {
 551     entry-&gt;set_next(_free_entries);
 552     _free_entries = entry;
 553     _free_entries_count++;
 554   }
 555 }
 556 
 557 // returns the tag map for the given environments. If the tag map
 558 // doesn&#39;t exist then it is created.
 559 JvmtiTagMap* JvmtiTagMap::tag_map_for(JvmtiEnv* env) {
<span class="line-modified"> 560   JvmtiTagMap* tag_map = ((JvmtiEnvBase*)env)-&gt;tag_map();</span>
 561   if (tag_map == NULL) {
 562     MutexLocker mu(JvmtiThreadState_lock);
 563     tag_map = ((JvmtiEnvBase*)env)-&gt;tag_map();
 564     if (tag_map == NULL) {
 565       tag_map = new JvmtiTagMap(env);
 566     }
 567   } else {
<span class="line-modified"> 568     CHECK_UNHANDLED_OOPS_ONLY(Thread::current()-&gt;clear_unhandled_oops());</span>
 569   }
 570   return tag_map;
 571 }
 572 
 573 // iterate over all entries in the tag map.
 574 void JvmtiTagMap::entry_iterate(JvmtiTagHashmapEntryClosure* closure) {
 575   hashmap()-&gt;entry_iterate(closure);
 576 }
 577 
 578 // returns true if the hashmaps are empty
 579 bool JvmtiTagMap::is_empty() {
 580   assert(SafepointSynchronize::is_at_safepoint() || is_locked(), &quot;checking&quot;);
 581   return hashmap()-&gt;entry_count() == 0;
 582 }
 583 
 584 
 585 // Return the tag value for an object, or 0 if the object is
 586 // not tagged
 587 //
 588 static inline jlong tag_for(JvmtiTagMap* tag_map, oop o) {
</pre>
<hr />
<pre>
1062     if (heap_filter &amp; JVMTI_HEAP_FILTER_CLASS_TAGGED) return true;
1063   } else {
1064     // filter out objects with untagged classes.
1065     if (heap_filter &amp; JVMTI_HEAP_FILTER_CLASS_UNTAGGED) return true;
1066   }
1067   return false;
1068 }
1069 
1070 // helper function to indicate if an object is filtered by a klass filter
1071 static inline bool is_filtered_by_klass_filter(oop obj, Klass* klass_filter) {
1072   if (klass_filter != NULL) {
1073     if (obj-&gt;klass() != klass_filter) {
1074       return true;
1075     }
1076   }
1077   return false;
1078 }
1079 
1080 // helper function to tell if a field is a primitive field or not
1081 static inline bool is_primitive_field_type(char type) {
<span class="line-modified">1082   return (type != &#39;L&#39; &amp;&amp; type != &#39;[&#39;);</span>
1083 }
1084 
1085 // helper function to copy the value from location addr to jvalue.
1086 static inline void copy_to_jvalue(jvalue *v, address addr, jvmtiPrimitiveType value_type) {
1087   switch (value_type) {
1088     case JVMTI_PRIMITIVE_TYPE_BOOLEAN : { v-&gt;z = *(jboolean*)addr; break; }
1089     case JVMTI_PRIMITIVE_TYPE_BYTE    : { v-&gt;b = *(jbyte*)addr;    break; }
1090     case JVMTI_PRIMITIVE_TYPE_CHAR    : { v-&gt;c = *(jchar*)addr;    break; }
1091     case JVMTI_PRIMITIVE_TYPE_SHORT   : { v-&gt;s = *(jshort*)addr;   break; }
1092     case JVMTI_PRIMITIVE_TYPE_INT     : { v-&gt;i = *(jint*)addr;     break; }
1093     case JVMTI_PRIMITIVE_TYPE_LONG    : { v-&gt;j = *(jlong*)addr;    break; }
1094     case JVMTI_PRIMITIVE_TYPE_FLOAT   : { v-&gt;f = *(jfloat*)addr;   break; }
1095     case JVMTI_PRIMITIVE_TYPE_DOUBLE  : { v-&gt;d = *(jdouble*)addr;  break; }
1096     default: ShouldNotReachHere();
1097   }
1098 }
1099 
1100 // helper function to invoke string primitive value callback
1101 // returns visit control flags
1102 static jint invoke_string_value_callback(jvmtiStringPrimitiveValueCallback cb,
</pre>
<hr />
<pre>
1202     return 0;
1203   }
1204 
1205   // get the field map
1206   ClassFieldMap* field_map = ClassFieldMap::create_map_of_static_fields(klass);
1207 
1208   // invoke the callback for each static primitive field
1209   for (int i=0; i&lt;field_map-&gt;field_count(); i++) {
1210     ClassFieldDescriptor* field = field_map-&gt;field_at(i);
1211 
1212     // ignore non-primitive fields
1213     char type = field-&gt;field_type();
1214     if (!is_primitive_field_type(type)) {
1215       continue;
1216     }
1217     // one-to-one mapping
1218     jvmtiPrimitiveType value_type = (jvmtiPrimitiveType)type;
1219 
1220     // get offset and field value
1221     int offset = field-&gt;field_offset();
<span class="line-modified">1222     address addr = (address)klass-&gt;java_mirror() + offset;</span>
1223     jvalue value;
1224     copy_to_jvalue(&amp;value, addr, value_type);
1225 
1226     // field index
1227     reference_info.field.index = field-&gt;field_index();
1228 
1229     // invoke the callback
1230     jint res = (*cb)(JVMTI_HEAP_REFERENCE_STATIC_FIELD,
1231                      &amp;reference_info,
1232                      wrapper-&gt;klass_tag(),
1233                      wrapper-&gt;obj_tag_p(),
1234                      value,
1235                      value_type,
1236                      user_data);
1237     if (res &amp; JVMTI_VISIT_ABORT) {
1238       delete field_map;
1239       return res;
1240     }
1241   }
1242 
</pre>
<hr />
<pre>
1255   // for instance fields only the index will be set
1256   static jvmtiHeapReferenceInfo reference_info = { 0 };
1257 
1258   // get the map of the instance fields
1259   ClassFieldMap* fields = JvmtiCachedClassFieldMap::get_map_of_instance_fields(obj);
1260 
1261   // invoke the callback for each instance primitive field
1262   for (int i=0; i&lt;fields-&gt;field_count(); i++) {
1263     ClassFieldDescriptor* field = fields-&gt;field_at(i);
1264 
1265     // ignore non-primitive fields
1266     char type = field-&gt;field_type();
1267     if (!is_primitive_field_type(type)) {
1268       continue;
1269     }
1270     // one-to-one mapping
1271     jvmtiPrimitiveType value_type = (jvmtiPrimitiveType)type;
1272 
1273     // get offset and field value
1274     int offset = field-&gt;field_offset();
<span class="line-modified">1275     address addr = (address)obj + offset;</span>
1276     jvalue value;
1277     copy_to_jvalue(&amp;value, addr, value_type);
1278 
1279     // field index
1280     reference_info.field.index = field-&gt;field_index();
1281 
1282     // invoke the callback
1283     jint res = (*cb)(JVMTI_HEAP_REFERENCE_FIELD,
1284                      &amp;reference_info,
1285                      wrapper-&gt;klass_tag(),
1286                      wrapper-&gt;obj_tag_p(),
1287                      value,
1288                      value_type,
1289                      user_data);
1290     if (res &amp; JVMTI_VISIT_ABORT) {
1291       return res;
1292     }
1293   }
1294   return 0;
1295 }
</pre>
<hr />
<pre>
1312   void doit() {
1313     // Simulates barrier synchronization on safepoint.
1314     // This annotation is reasonably minimal in number of tsan callbacks.
1315     // By passing the lock directly, we are not actually locking it, just
1316     // telling TSAN we are to &quot;simulate&quot; the lock.
1317     TSAN_ONLY(TsanMutexScope tms(_tag_map-&gt;lock()));
1318 
1319     // allows class files maps to be cached during iteration
1320     ClassFieldMapCacheMark cm;
1321 
1322     // make sure that heap is parsable (fills TLABs with filler objects)
1323     Universe::heap()-&gt;ensure_parsability(false);  // no need to retire TLABs
1324 
1325     // Verify heap before iteration - if the heap gets corrupted then
1326     // JVMTI&#39;s IterateOverHeap will crash.
1327     if (VerifyBeforeIteration) {
1328       Universe::verify();
1329     }
1330 
1331     // do the iteration
<span class="line-removed">1332     // If this operation encounters a bad object when using CMS,</span>
<span class="line-removed">1333     // consider using safe_object_iterate() which avoids perm gen</span>
<span class="line-removed">1334     // objects that may contain bad references.</span>
1335     Universe::heap()-&gt;object_iterate(_blk);
1336   }
1337 
1338 };
1339 
1340 
1341 // An ObjectClosure used to support the deprecated IterateOverHeap and
1342 // IterateOverInstancesOfClass functions
1343 class IterateOverHeapObjectClosure: public ObjectClosure {
1344  private:
1345   JvmtiTagMap* _tag_map;
1346   Klass* _klass;
1347   jvmtiHeapObjectFilter _object_filter;
1348   jvmtiHeapObjectCallback _heap_object_callback;
1349   const void* _user_data;
1350 
1351   // accessors
1352   JvmtiTagMap* tag_map() const                    { return _tag_map; }
1353   jvmtiHeapObjectFilter object_filter() const     { return _object_filter; }
1354   jvmtiHeapObjectCallback object_callback() const { return _heap_object_callback; }
</pre>
<hr />
<pre>
1586     _tag_results = new (ResourceObj::C_HEAP, mtInternal) GrowableArray&lt;uint64_t&gt;(1,true);
1587   }
1588 
1589   ~TagObjectCollector() {
1590     delete _object_results;
1591     delete _tag_results;
1592   }
1593 
1594   // for each tagged object check if the tag value matches
1595   // - if it matches then we create a JNI local reference to the object
1596   // and record the reference and tag value.
1597   //
1598   void do_entry(JvmtiTagHashmapEntry* entry) {
1599     for (int i=0; i&lt;_tag_count; i++) {
1600       if (_tags[i] == entry-&gt;tag()) {
1601         // The reference in this tag map could be the only (implicitly weak)
1602         // reference to that object. If we hand it out, we need to keep it live wrt
1603         // SATB marking similar to other j.l.ref.Reference referents. This is
1604         // achieved by using a phantom load in the object() accessor.
1605         oop o = entry-&gt;object();
<span class="line-modified">1606         assert(o != NULL &amp;&amp; Universe::heap()-&gt;is_in_reserved(o), &quot;sanity check&quot;);</span>
1607         jobject ref = JNIHandles::make_local(JavaThread::current(), o);
1608         _object_results-&gt;append(ref);
1609         _tag_results-&gt;append((uint64_t)entry-&gt;tag());
1610       }
1611     }
1612   }
1613 
1614   // return the results from the collection
1615   //
1616   jvmtiError result(jint* count_ptr, jobject** object_result_ptr, jlong** tag_result_ptr) {
1617     jvmtiError error;
1618     int count = _object_results-&gt;length();
1619     assert(count &gt;= 0, &quot;sanity check&quot;);
1620 
1621     // if object_result_ptr is not NULL then allocate the result and copy
1622     // in the object references.
1623     if (object_result_ptr != NULL) {
1624       error = _env-&gt;Allocate(count * sizeof(jobject), (unsigned char**)object_result_ptr);
1625       if (error != JVMTI_ERROR_NONE) {
1626         return error;
</pre>
<hr />
<pre>
1670 //
1671 // This implementation uses the existing mark bits in an object for
1672 // marking. Objects that are marked must later have their headers restored.
1673 // As most objects are unlocked and don&#39;t have their identity hash computed
1674 // we don&#39;t have to save their headers. Instead we save the headers that
1675 // are &quot;interesting&quot;. Later when the headers are restored this implementation
1676 // restores all headers to their initial value and then restores the few
1677 // objects that had interesting headers.
1678 //
1679 // Future work: This implementation currently uses growable arrays to save
1680 // the oop and header of interesting objects. As an optimization we could
1681 // use the same technique as the GC and make use of the unused area
1682 // between top() and end().
1683 //
1684 
1685 // An ObjectClosure used to restore the mark bits of an object
1686 class RestoreMarksClosure : public ObjectClosure {
1687  public:
1688   void do_object(oop o) {
1689     if (o != NULL) {
<span class="line-modified">1690       markOop mark = o-&gt;mark();</span>
<span class="line-modified">1691       if (mark-&gt;is_marked()) {</span>
1692         o-&gt;init_mark();
1693       }
1694     }
1695   }
1696 };
1697 
1698 // ObjectMarker provides the mark and visited functions
1699 class ObjectMarker : AllStatic {
1700  private:
1701   // saved headers
1702   static GrowableArray&lt;oop&gt;* _saved_oop_stack;
<span class="line-modified">1703   static GrowableArray&lt;markOop&gt;* _saved_mark_stack;</span>
1704   static bool _needs_reset;                  // do we need to reset mark bits?
1705 
1706  public:
1707   static void init();                       // initialize
1708   static void done();                       // clean-up
1709 
1710   static inline void mark(oop o);           // mark an object
1711   static inline bool visited(oop o);        // check if object has been visited
1712 
1713   static inline bool needs_reset()            { return _needs_reset; }
1714   static inline void set_needs_reset(bool v)  { _needs_reset = v; }
1715 };
1716 
1717 GrowableArray&lt;oop&gt;* ObjectMarker::_saved_oop_stack = NULL;
<span class="line-modified">1718 GrowableArray&lt;markOop&gt;* ObjectMarker::_saved_mark_stack = NULL;</span>
1719 bool ObjectMarker::_needs_reset = true;  // need to reset mark bits by default
1720 
1721 // initialize ObjectMarker - prepares for object marking
1722 void ObjectMarker::init() {
1723   assert(Thread::current()-&gt;is_VM_thread(), &quot;must be VMThread&quot;);
1724 
1725   // prepare heap for iteration
1726   Universe::heap()-&gt;ensure_parsability(false);  // no need to retire TLABs
1727 
1728   // create stacks for interesting headers
<span class="line-modified">1729   _saved_mark_stack = new (ResourceObj::C_HEAP, mtInternal) GrowableArray&lt;markOop&gt;(4000, true);</span>
1730   _saved_oop_stack = new (ResourceObj::C_HEAP, mtInternal) GrowableArray&lt;oop&gt;(4000, true);
1731 
1732   if (UseBiasedLocking) {
1733     BiasedLocking::preserve_marks();
1734   }
1735 }
1736 
1737 // Object marking is done so restore object headers
1738 void ObjectMarker::done() {
1739   // iterate over all objects and restore the mark bits to
1740   // their initial value
1741   RestoreMarksClosure blk;
1742   if (needs_reset()) {
1743     Universe::heap()-&gt;object_iterate(&amp;blk);
1744   } else {
1745     // We don&#39;t need to reset mark bits on this call, but reset the
1746     // flag to the default for the next call.
1747     set_needs_reset(true);
1748   }
1749 
1750   // now restore the interesting headers
1751   for (int i = 0; i &lt; _saved_oop_stack-&gt;length(); i++) {
1752     oop o = _saved_oop_stack-&gt;at(i);
<span class="line-modified">1753     markOop mark = _saved_mark_stack-&gt;at(i);</span>
1754     o-&gt;set_mark(mark);
1755   }
1756 
1757   if (UseBiasedLocking) {
1758     BiasedLocking::restore_marks();
1759   }
1760 
1761   // free the stacks
1762   delete _saved_oop_stack;
1763   delete _saved_mark_stack;
1764 }
1765 
1766 // mark an object
1767 inline void ObjectMarker::mark(oop o) {
1768   assert(Universe::heap()-&gt;is_in(o), &quot;sanity check&quot;);
<span class="line-modified">1769   assert(!o-&gt;mark()-&gt;is_marked(), &quot;should only mark an object once&quot;);</span>
1770 
1771   // object&#39;s mark word
<span class="line-modified">1772   markOop mark = o-&gt;mark();</span>
1773 
<span class="line-modified">1774   if (mark-&gt;must_be_preserved(o)) {</span>
1775     _saved_mark_stack-&gt;push(mark);
1776     _saved_oop_stack-&gt;push(o);
1777   }
1778 
1779   // mark the object
<span class="line-modified">1780   o-&gt;set_mark(markOopDesc::prototype()-&gt;set_marked());</span>
1781 }
1782 
1783 // return true if object is marked
1784 inline bool ObjectMarker::visited(oop o) {
<span class="line-modified">1785   return o-&gt;mark()-&gt;is_marked();</span>
1786 }
1787 
1788 // Stack allocated class to help ensure that ObjectMarker is used
1789 // correctly. Constructor initializes ObjectMarker, destructor calls
1790 // ObjectMarker&#39;s done() function to restore object headers.
1791 class ObjectMarkerController : public StackObj {
1792  public:
1793   ObjectMarkerController() {
1794     ObjectMarker::init();
1795   }
1796   ~ObjectMarkerController() {
1797     ObjectMarker::done();
1798   }
1799 };
1800 
1801 
1802 // helper to map a jvmtiHeapReferenceKind to an old style jvmtiHeapRootKind
1803 // (not performance critical as only used for roots)
1804 static jvmtiHeapRootKind toJvmtiHeapRootKind(jvmtiHeapReferenceKind kind) {
1805   switch (kind) {
</pre>
<hr />
<pre>
2614     _kind = kind;
2615     _continue = true;
2616   }
2617 
2618   inline bool stopped() {
2619     return !_continue;
2620   }
2621 
2622   void do_oop(oop* obj_p) {
2623     // iteration has terminated
2624     if (stopped()) {
2625       return;
2626     }
2627 
2628     oop o = NativeAccess&lt;AS_NO_KEEPALIVE&gt;::oop_load(obj_p);
2629     // ignore null
2630     if (o == NULL) {
2631       return;
2632     }
2633 
<span class="line-modified">2634     assert(Universe::heap()-&gt;is_in_reserved(o), &quot;should be impossible&quot;);</span>
2635 
2636     jvmtiHeapReferenceKind kind = root_kind();
2637     if (kind == JVMTI_HEAP_REFERENCE_SYSTEM_CLASS) {
2638       // SystemDictionary::oops_do reports the application
2639       // class loader as a root. We want this root to be reported as
2640       // a root kind of &quot;OTHER&quot; rather than &quot;SYSTEM_CLASS&quot;.
2641       if (!o-&gt;is_instance() || !InstanceKlass::cast(o-&gt;klass())-&gt;is_mirror_instance_klass()) {
2642         kind = JVMTI_HEAP_REFERENCE_OTHER;
2643       }
2644     }
2645 
2646     // invoke the callback
2647     _continue = CallbackInvoker::report_simple_root(kind, o);
2648 
2649   }
2650   virtual void do_oop(narrowOop* obj_p) { ShouldNotReachHere(); }
2651 };
2652 
2653 // A supporting closure used to process JNI locals
2654 class JNILocalRootsClosure : public OopClosure {
</pre>
<hr />
<pre>
2843 inline bool VM_HeapWalkOperation::iterate_over_type_array(oop o) {
2844   Klass* k = o-&gt;klass();
2845   oop mirror = k-&gt;java_mirror();
2846   if (!CallbackInvoker::report_class_reference(o, mirror)) {
2847     return false;
2848   }
2849 
2850   // report the array contents if required
2851   if (is_reporting_primitive_array_values()) {
2852     if (!CallbackInvoker::report_primitive_array_values(o)) {
2853       return false;
2854     }
2855   }
2856   return true;
2857 }
2858 
2859 #ifdef ASSERT
2860 // verify that a static oop field is in range
2861 static inline bool verify_static_oop(InstanceKlass* ik,
2862                                      oop mirror, int offset) {
<span class="line-modified">2863   address obj_p = (address)mirror + offset;</span>
2864   address start = (address)InstanceMirrorKlass::start_of_static_fields(mirror);
2865   address end = start + (java_lang_Class::static_oop_field_count(mirror) * heapOopSize);
2866   assert(end &gt;= start, &quot;sanity check&quot;);
2867 
2868   if (obj_p &gt;= start &amp;&amp; obj_p &lt; end) {
2869     return true;
2870   } else {
2871     return false;
2872   }
2873 }
2874 #endif // #ifdef ASSERT
2875 
2876 // a class references its super class, interfaces, class loader, ...
2877 // and finally its static fields
2878 inline bool VM_HeapWalkOperation::iterate_over_class(oop java_class) {
2879   int i;
2880   Klass* klass = java_lang_Class::as_Klass(java_class);
2881 
2882   if (klass-&gt;is_instance_klass()) {
2883     InstanceKlass* ik = InstanceKlass::cast(klass);
</pre>
<hr />
<pre>
2971     }
2972 
2973     // iterate over the static fields
2974 
2975     ClassFieldMap* field_map = ClassFieldMap::create_map_of_static_fields(klass);
2976     for (i=0; i&lt;field_map-&gt;field_count(); i++) {
2977       ClassFieldDescriptor* field = field_map-&gt;field_at(i);
2978       char type = field-&gt;field_type();
2979       if (!is_primitive_field_type(type)) {
2980         oop fld_o = mirror-&gt;obj_field(field-&gt;field_offset());
2981         assert(verify_static_oop(ik, mirror, field-&gt;field_offset()), &quot;sanity check&quot;);
2982         if (fld_o != NULL) {
2983           int slot = field-&gt;field_index();
2984           if (!CallbackInvoker::report_static_field_reference(mirror, fld_o, slot)) {
2985             delete field_map;
2986             return false;
2987           }
2988         }
2989       } else {
2990          if (is_reporting_primitive_fields()) {
<span class="line-modified">2991            address addr = (address)mirror + field-&gt;field_offset();</span>
2992            int slot = field-&gt;field_index();
2993            if (!CallbackInvoker::report_primitive_static_field(mirror, slot, addr, type)) {
2994              delete field_map;
2995              return false;
2996           }
2997         }
2998       }
2999     }
3000     delete field_map;
3001 
3002     return true;
3003   }
3004 
3005   return true;
3006 }
3007 
3008 // an object references a class and its instance fields
3009 // (static fields are ignored here as we report these as
3010 // references from the class).
3011 inline bool VM_HeapWalkOperation::iterate_over_object(oop o) {
3012   // reference to the class
3013   if (!CallbackInvoker::report_class_reference(o, o-&gt;klass()-&gt;java_mirror())) {
3014     return false;
3015   }
3016 
3017   // iterate over instance fields
3018   ClassFieldMap* field_map = JvmtiCachedClassFieldMap::get_map_of_instance_fields(o);
3019   for (int i=0; i&lt;field_map-&gt;field_count(); i++) {
3020     ClassFieldDescriptor* field = field_map-&gt;field_at(i);
3021     char type = field-&gt;field_type();
3022     if (!is_primitive_field_type(type)) {
<span class="line-modified">3023       oop fld_o = o-&gt;obj_field(field-&gt;field_offset());</span>
3024       // ignore any objects that aren&#39;t visible to profiler
3025       if (fld_o != NULL) {
<span class="line-modified">3026         assert(Universe::heap()-&gt;is_in_reserved(fld_o), &quot;unsafe code should not &quot;</span>
3027                &quot;have references to Klass* anymore&quot;);
3028         int slot = field-&gt;field_index();
3029         if (!CallbackInvoker::report_field_reference(o, fld_o, slot)) {
3030           return false;
3031         }
3032       }
3033     } else {
3034       if (is_reporting_primitive_fields()) {
3035         // primitive instance field
<span class="line-modified">3036         address addr = (address)o + field-&gt;field_offset();</span>
3037         int slot = field-&gt;field_index();
3038         if (!CallbackInvoker::report_primitive_instance_field(o, slot, addr, type)) {
3039           return false;
3040         }
3041       }
3042     }
3043   }
3044 
3045   // if the object is a java.lang.String
3046   if (is_reporting_string_values() &amp;&amp;
3047       o-&gt;klass() == SystemDictionary::String_klass()) {
3048     if (!CallbackInvoker::report_string_value(o)) {
3049       return false;
3050     }
3051   }
3052   return true;
3053 }
3054 
3055 
3056 // Collects all simple (non-stack) roots except for threads;
</pre>
<hr />
<pre>
3077   CLDToOopClosure cld_closure(&amp;blk, false);
3078   ClassLoaderDataGraph::always_strong_cld_do(&amp;cld_closure);
3079   if (blk.stopped()) {
3080     return false;
3081   }
3082 
3083   // Inflated monitors
3084   blk.set_kind(JVMTI_HEAP_REFERENCE_MONITOR);
3085   ObjectSynchronizer::oops_do(&amp;blk);
3086   if (blk.stopped()) {
3087     return false;
3088   }
3089 
3090   // threads are now handled in collect_stack_roots()
3091 
3092   // Other kinds of roots maintained by HotSpot
3093   // Many of these won&#39;t be visible but others (such as instances of important
3094   // exceptions) will be visible.
3095   blk.set_kind(JVMTI_HEAP_REFERENCE_OTHER);
3096   Universe::oops_do(&amp;blk);



3097 
3098   return true;
3099 }
3100 
3101 // Walk the stack of a given thread and find all references (locals
3102 // and JNI calls) and report these as stack references
3103 inline bool VM_HeapWalkOperation::collect_stack_roots(JavaThread* java_thread,
3104                                                       JNILocalRootsClosure* blk)
3105 {
3106   oop threadObj = java_thread-&gt;threadObj();
3107   assert(threadObj != NULL, &quot;sanity check&quot;);
3108 
3109   // only need to get the thread&#39;s tag once per thread
3110   jlong thread_tag = tag_for(_tag_map, threadObj);
3111 
3112   // also need the thread id
3113   jlong tid = java_lang_Thread::thread_id(threadObj);
3114 
3115 
3116   if (java_thread-&gt;has_last_Java_frame()) {
</pre>
<hr />
<pre>
3352   oop obj = JNIHandles::resolve(object);
3353   Handle initial_object(Thread::current(), obj);
3354 
3355   MutexLocker ml(Heap_lock);
3356   AdvancedHeapWalkContext context(heap_filter, klass, callbacks);
3357   VM_HeapWalkOperation op(this, initial_object, context, user_data);
3358   VMThread::execute(&amp;op);
3359 }
3360 
3361 
3362 void JvmtiTagMap::weak_oops_do(BoolObjectClosure* is_alive, OopClosure* f) {
3363   // No locks during VM bring-up (0 threads) and no safepoints after main
3364   // thread creation and before VMThread creation (1 thread); initial GC
3365   // verification can happen in that window which gets to here.
3366   assert(Threads::number_of_threads() &lt;= 1 ||
3367          SafepointSynchronize::is_at_safepoint(),
3368          &quot;must be executed at a safepoint&quot;);
3369   if (JvmtiEnv::environments_might_exist()) {
3370     JvmtiEnvIterator it;
3371     for (JvmtiEnvBase* env = it.first(); env != NULL; env = it.next(env)) {
<span class="line-modified">3372       JvmtiTagMap* tag_map = env-&gt;tag_map();</span>
3373       if (tag_map != NULL &amp;&amp; !tag_map-&gt;is_empty()) {
3374         tag_map-&gt;do_weak_oops(is_alive, f);
3375       }
3376     }
3377   }
3378 }
3379 
3380 void JvmtiTagMap::do_weak_oops(BoolObjectClosure* is_alive, OopClosure* f) {
3381 
3382   // does this environment have the OBJECT_FREE event enabled
3383   bool post_object_free = env()-&gt;is_enabled(JVMTI_EVENT_OBJECT_FREE);
3384 
3385   // counters used for trace message
3386   int freed = 0;
3387   int moved = 0;
3388 
3389   JvmtiTagHashmap* hashmap = this-&gt;hashmap();
3390 
3391   // reenable sizing (if disabled)
3392   hashmap-&gt;set_resizing_enabled(true);
</pre>
<hr />
<pre>
3394   // if the hashmap is empty then we can skip it
3395   if (hashmap-&gt;_entry_count == 0) {
3396     return;
3397   }
3398 
3399   // now iterate through each entry in the table
3400 
3401   JvmtiTagHashmapEntry** table = hashmap-&gt;table();
3402   int size = hashmap-&gt;size();
3403 
3404   JvmtiTagHashmapEntry* delayed_add = NULL;
3405 
3406   for (int pos = 0; pos &lt; size; ++pos) {
3407     JvmtiTagHashmapEntry* entry = table[pos];
3408     JvmtiTagHashmapEntry* prev = NULL;
3409 
3410     while (entry != NULL) {
3411       JvmtiTagHashmapEntry* next = entry-&gt;next();
3412 
3413       // has object been GC&#39;ed
<span class="line-modified">3414       if (!is_alive-&gt;do_object_b(entry-&gt;object_peek())) {</span>
3415         // grab the tag
3416         jlong tag = entry-&gt;tag();
3417         guarantee(tag != 0, &quot;checking&quot;);
3418 
3419         // remove GC&#39;ed entry from hashmap and return the
3420         // entry to the free list
3421         hashmap-&gt;remove(prev, pos, entry);
3422         destroy_entry(entry);
3423 
3424         // post the event to the profiler
3425         if (post_object_free) {
3426           JvmtiExport::post_object_free(env(), tag);
3427         }
3428 
3429         ++freed;
3430       } else {
3431         f-&gt;do_oop(entry-&gt;object_addr());
<span class="line-modified">3432         oop new_oop = entry-&gt;object_peek();</span>
3433 
3434         // if the object has moved then re-hash it and move its
3435         // entry to its new location.
3436         unsigned int new_pos = JvmtiTagHashmap::hash(new_oop, size);
3437         if (new_pos != (unsigned int)pos) {
3438           if (prev == NULL) {
3439             table[pos] = next;
3440           } else {
3441             prev-&gt;set_next(next);
3442           }
3443           if (new_pos &lt; (unsigned int)pos) {
3444             entry-&gt;set_next(table[new_pos]);
3445             table[new_pos] = entry;
3446           } else {
3447             // Delay adding this entry to it&#39;s new position as we&#39;d end up
3448             // hitting it again during this iteration.
3449             entry-&gt;set_next(delayed_add);
3450             delayed_add = entry;
3451           }
3452           moved++;
3453         } else {
3454           // object didn&#39;t move
3455           prev = entry;
3456         }
3457       }
3458 
3459       entry = next;
3460     }
3461   }
3462 
3463   // Re-add all the entries which were kept aside
3464   while (delayed_add != NULL) {
3465     JvmtiTagHashmapEntry* next = delayed_add-&gt;next();
<span class="line-modified">3466     unsigned int pos = JvmtiTagHashmap::hash(delayed_add-&gt;object_peek(), size);</span>
3467     delayed_add-&gt;set_next(table[pos]);
3468     table[pos] = delayed_add;
3469     delayed_add = next;
3470   }
3471 
3472   log_debug(jvmti, objecttagging)(&quot;(%d-&gt;%d, %d freed, %d total moves)&quot;,
3473                                   hashmap-&gt;_entry_count + freed, hashmap-&gt;_entry_count, freed, moved);
3474 }
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;classfile/classLoaderDataGraph.hpp&quot;
  27 #include &quot;classfile/javaClasses.inline.hpp&quot;
  28 #include &quot;classfile/symbolTable.hpp&quot;
  29 #include &quot;classfile/systemDictionary.hpp&quot;
  30 #include &quot;classfile/vmSymbols.hpp&quot;
  31 #include &quot;jvmtifiles/jvmtiEnv.hpp&quot;
  32 #include &quot;logging/log.hpp&quot;
  33 #include &quot;memory/allocation.inline.hpp&quot;
  34 #include &quot;memory/resourceArea.hpp&quot;
<span class="line-added">  35 #include &quot;memory/universe.hpp&quot;</span>
  36 #include &quot;oops/access.inline.hpp&quot;
  37 #include &quot;oops/arrayOop.inline.hpp&quot;
  38 #include &quot;oops/constantPool.inline.hpp&quot;
  39 #include &quot;oops/instanceMirrorKlass.hpp&quot;
  40 #include &quot;oops/objArrayKlass.hpp&quot;
  41 #include &quot;oops/objArrayOop.inline.hpp&quot;
  42 #include &quot;oops/oop.inline.hpp&quot;
  43 #include &quot;oops/typeArrayOop.inline.hpp&quot;
  44 #include &quot;prims/jvmtiEventController.hpp&quot;
  45 #include &quot;prims/jvmtiEventController.inline.hpp&quot;
  46 #include &quot;prims/jvmtiExport.hpp&quot;
  47 #include &quot;prims/jvmtiImpl.hpp&quot;
  48 #include &quot;prims/jvmtiTagMap.hpp&quot;
  49 #include &quot;runtime/biasedLocking.hpp&quot;
  50 #include &quot;runtime/frame.inline.hpp&quot;
  51 #include &quot;runtime/handles.inline.hpp&quot;
  52 #include &quot;runtime/javaCalls.hpp&quot;
  53 #include &quot;runtime/jniHandles.inline.hpp&quot;
  54 #include &quot;runtime/mutex.hpp&quot;
  55 #include &quot;runtime/mutexLocker.hpp&quot;
</pre>
<hr />
<pre>
  83 
  84   inline void init(oop object, jlong tag) {
  85     _object = object;
  86     _tag = tag;
  87     _next = NULL;
  88   }
  89 
  90   // constructor
  91   JvmtiTagHashmapEntry(oop object, jlong tag) { init(object, tag); }
  92 
  93  public:
  94 
  95   // accessor methods
  96   inline oop* object_addr() { return &amp;_object; }
  97   inline oop object()       { return NativeAccess&lt;ON_PHANTOM_OOP_REF&gt;::oop_load(object_addr()); }
  98   // Peek at the object without keeping it alive. The returned object must be
  99   // kept alive using a normal access if it leaks out of a thread transition from VM.
 100   inline oop object_peek()  {
 101     return NativeAccess&lt;ON_PHANTOM_OOP_REF | AS_NO_KEEPALIVE&gt;::oop_load(object_addr());
 102   }
<span class="line-added"> 103 </span>
<span class="line-added"> 104   inline oop object_raw() {</span>
<span class="line-added"> 105     return RawAccess&lt;&gt;::oop_load(object_addr());</span>
<span class="line-added"> 106   }</span>
<span class="line-added"> 107 </span>
 108   inline jlong tag() const  { return _tag; }
 109 
 110   inline void set_tag(jlong tag) {
 111     assert(tag != 0, &quot;can&#39;t be zero&quot;);
 112     _tag = tag;
 113   }
 114 
 115   inline bool equals(oop object) {
<span class="line-modified"> 116     return object == object_peek();</span>
 117   }
 118 
 119   inline JvmtiTagHashmapEntry* next() const        { return _next; }
 120   inline void set_next(JvmtiTagHashmapEntry* next) { _next = next; }
 121 };
 122 
 123 
 124 // JvmtiTagHashmap
 125 //
 126 // A hashmap is essentially a table of pointers to entries. Entries
 127 // are hashed to a location, or position in the table, and then
 128 // chained from that location. The &quot;key&quot; for hashing is address of
 129 // the object, or oop. The &quot;value&quot; is the tag value.
 130 //
 131 // A hashmap maintains a count of the number entries in the hashmap
 132 // and resizes if the number of entries exceeds a given threshold.
 133 // The threshold is specified as a percentage of the size - for
 134 // example a threshold of 0.75 will trigger the hashmap to resize
 135 // if the number of entries is &gt;75% of table size.
 136 //
</pre>
<hr />
<pre>
 173     _size_index = size_index;
 174     _size = initial_size;
 175     _entry_count = 0;
 176     _trace_threshold = initial_trace_threshold;
 177     _load_factor = load_factor;
 178     _resize_threshold = (int)(_load_factor * _size);
 179     _resizing_enabled = true;
 180     size_t s = initial_size * sizeof(JvmtiTagHashmapEntry*);
 181     _table = (JvmtiTagHashmapEntry**)os::malloc(s, mtInternal);
 182     if (_table == NULL) {
 183       vm_exit_out_of_memory(s, OOM_MALLOC_ERROR,
 184         &quot;unable to allocate initial hashtable for jvmti object tags&quot;);
 185     }
 186     for (int i=0; i&lt;initial_size; i++) {
 187       _table[i] = NULL;
 188     }
 189   }
 190 
 191   // hash a given key (oop) with the specified size
 192   static unsigned int hash(oop key, int size) {
<span class="line-modified"> 193     const oop obj = Access&lt;&gt;::resolve(key);</span>
<span class="line-modified"> 194     const unsigned int hash = Universe::heap()-&gt;hash_oop(obj);</span>
<span class="line-modified"> 195     return hash % size;</span>








 196   }
 197 
 198   // hash a given key (oop)
 199   unsigned int hash(oop key) {
 200     return hash(key, _size);
 201   }
 202 
 203   // resize the hashmap - allocates a large table and re-hashes
 204   // all entries into the new table.
 205   void resize() {
 206     int new_size_index = _size_index+1;
 207     int new_size = _sizes[new_size_index];
 208     if (new_size &lt; 0) {
 209       // hashmap already at maximum capacity
 210       return;
 211     }
 212 
 213     // allocate new table
 214     size_t s = new_size * sizeof(JvmtiTagHashmapEntry*);
 215     JvmtiTagHashmapEntry** new_table = (JvmtiTagHashmapEntry**)os::malloc(s, mtInternal);
</pre>
<hr />
<pre>
 366     while (entry != NULL) {
 367       if (entry-&gt;equals(key)) {
 368         break;
 369       }
 370       prev = entry;
 371       entry = entry-&gt;next();
 372     }
 373     if (entry != NULL) {
 374       remove(prev, h, entry);
 375     }
 376     return entry;
 377   }
 378 
 379   // iterate over all entries in the hashmap
 380   void entry_iterate(JvmtiTagHashmapEntryClosure* closure);
 381 };
 382 
 383 // Tsan should know that the JVMTI TagMap is protected by a mutex.
 384 class TsanMutexScope : public StackObj {
 385  private:
<span class="line-modified"> 386   Mutex *_lock;  // Keep my own reference, for destructor.</span>
 387 
 388  public:
 389   // Don&#39;t actually lock it, just tell tsan we did.
<span class="line-modified"> 390   TsanMutexScope(Mutex* mutex) : _lock(mutex) {</span>
 391     TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_ACQUIRED(_lock));
 392   }
 393 
 394   ~TsanMutexScope() {
 395     TSAN_RUNTIME_ONLY(TSAN_RAW_LOCK_RELEASED(_lock));
 396   }
 397 };
 398 
 399 // possible hashmap sizes - odd primes that roughly double in size.
 400 // To avoid excessive resizing the odd primes from 4801-76831 and
 401 // 76831-307261 have been removed. The list must be terminated by -1.
 402 int JvmtiTagHashmap::_sizes[] =  { 4801, 76831, 307261, 614563, 1228891,
 403     2457733, 4915219, 9830479, 19660831, 39321619, 78643219, -1 };
 404 
 405 
 406 // A supporting class for iterating over all entries in Hashmap
 407 class JvmtiTagHashmapEntryClosure {
 408  public:
 409   virtual void do_entry(JvmtiTagHashmapEntry* entry) = 0;
 410 };
</pre>
<hr />
<pre>
 468   // this being seen as racy though is not really.
 469   //
 470   // The JvmtiTagMap gets created by the first thread to call tag_map_for; which
 471   // uses a lock to create it if need be.
 472   //
 473   // This means that this lock is created under a mutex but then,
 474   // subsequent uses do not have a lock to protect it (because not
 475   // needed in this case), however TSAN sees it as being needed because:
 476   //  - Another thread can come and get the newly created JvmtiTagMap without a
 477   //  lock and acquire the lock.
 478   //  - This provokes a race for TSAN on the lock itself, though there is no
 479   //  real issue.
 480   //
 481   //  Not creating the lock or having a fence mechanism to tell TSAN this is
 482   //  safe (a fake lock around this lock for example) seem to be the only
 483   //  solutions.
 484 
 485   _hashmap = new JvmtiTagHashmap();
 486 
 487   // finally add us to the environment
<span class="line-modified"> 488   ((JvmtiEnvBase *)env)-&gt;release_set_tag_map(this);</span>
 489 }
 490 
 491 
 492 // destroy a JvmtiTagMap
 493 JvmtiTagMap::~JvmtiTagMap() {
 494   // no lock acquired as we assume the enclosing environment is
 495   // also being destroryed.
 496   ((JvmtiEnvBase *)_env)-&gt;set_tag_map(NULL);
 497 
 498   JvmtiTagHashmapEntry** table = _hashmap-&gt;table();
 499   for (int j = 0; j &lt; _hashmap-&gt;size(); j++) {
 500     JvmtiTagHashmapEntry* entry = table[j];
 501     while (entry != NULL) {
 502       JvmtiTagHashmapEntry* next = entry-&gt;next();
 503       delete entry;
 504       entry = next;
 505     }
 506   }
 507 
 508   // finally destroy the hashmap
 509   delete _hashmap;
 510   _hashmap = NULL;
 511 
 512   // remove any entries on the free list
 513   JvmtiTagHashmapEntry* entry = _free_entries;
 514   while (entry != NULL) {
 515     JvmtiTagHashmapEntry* next = entry-&gt;next();
 516     delete entry;
 517     entry = next;
 518   }
 519   _free_entries = NULL;
 520 
 521   // TSAN Note: see above for the Tsan creation note.
 522 }
 523 
 524 // create a hashmap entry
 525 // - if there&#39;s an entry on the (per-environment) free list then this
 526 // is returned. Otherwise an new entry is allocated.
 527 JvmtiTagHashmapEntry* JvmtiTagMap::create_entry(oop ref, jlong tag) {
 528   assert(Thread::current()-&gt;is_VM_thread() || is_locked(), &quot;checking&quot;);
<span class="line-added"> 529 </span>
<span class="line-added"> 530   // ref was read with AS_NO_KEEPALIVE, or equivalent.</span>
<span class="line-added"> 531   // The object needs to be kept alive when it is published.</span>
<span class="line-added"> 532   Universe::heap()-&gt;keep_alive(ref);</span>
<span class="line-added"> 533 </span>
 534   JvmtiTagHashmapEntry* entry;
 535   if (_free_entries == NULL) {
 536     entry = new JvmtiTagHashmapEntry(ref, tag);
 537   } else {
 538     assert(_free_entries_count &gt; 0, &quot;mismatched _free_entries_count&quot;);
 539     _free_entries_count--;
 540     entry = _free_entries;
 541     _free_entries = entry-&gt;next();
 542     entry-&gt;init(ref, tag);
 543   }
 544   return entry;
 545 }
 546 
 547 // destroy an entry by returning it to the free list
 548 void JvmtiTagMap::destroy_entry(JvmtiTagHashmapEntry* entry) {
 549   assert(SafepointSynchronize::is_at_safepoint() || is_locked(), &quot;checking&quot;);
 550   // limit the size of the free list
 551   if (_free_entries_count &gt;= max_free_entries) {
 552     delete entry;
 553   } else {
 554     entry-&gt;set_next(_free_entries);
 555     _free_entries = entry;
 556     _free_entries_count++;
 557   }
 558 }
 559 
 560 // returns the tag map for the given environments. If the tag map
 561 // doesn&#39;t exist then it is created.
 562 JvmtiTagMap* JvmtiTagMap::tag_map_for(JvmtiEnv* env) {
<span class="line-modified"> 563   JvmtiTagMap* tag_map = ((JvmtiEnvBase*)env)-&gt;tag_map_acquire();</span>
 564   if (tag_map == NULL) {
 565     MutexLocker mu(JvmtiThreadState_lock);
 566     tag_map = ((JvmtiEnvBase*)env)-&gt;tag_map();
 567     if (tag_map == NULL) {
 568       tag_map = new JvmtiTagMap(env);
 569     }
 570   } else {
<span class="line-modified"> 571     DEBUG_ONLY(Thread::current()-&gt;check_possible_safepoint());</span>
 572   }
 573   return tag_map;
 574 }
 575 
 576 // iterate over all entries in the tag map.
 577 void JvmtiTagMap::entry_iterate(JvmtiTagHashmapEntryClosure* closure) {
 578   hashmap()-&gt;entry_iterate(closure);
 579 }
 580 
 581 // returns true if the hashmaps are empty
 582 bool JvmtiTagMap::is_empty() {
 583   assert(SafepointSynchronize::is_at_safepoint() || is_locked(), &quot;checking&quot;);
 584   return hashmap()-&gt;entry_count() == 0;
 585 }
 586 
 587 
 588 // Return the tag value for an object, or 0 if the object is
 589 // not tagged
 590 //
 591 static inline jlong tag_for(JvmtiTagMap* tag_map, oop o) {
</pre>
<hr />
<pre>
1065     if (heap_filter &amp; JVMTI_HEAP_FILTER_CLASS_TAGGED) return true;
1066   } else {
1067     // filter out objects with untagged classes.
1068     if (heap_filter &amp; JVMTI_HEAP_FILTER_CLASS_UNTAGGED) return true;
1069   }
1070   return false;
1071 }
1072 
1073 // helper function to indicate if an object is filtered by a klass filter
1074 static inline bool is_filtered_by_klass_filter(oop obj, Klass* klass_filter) {
1075   if (klass_filter != NULL) {
1076     if (obj-&gt;klass() != klass_filter) {
1077       return true;
1078     }
1079   }
1080   return false;
1081 }
1082 
1083 // helper function to tell if a field is a primitive field or not
1084 static inline bool is_primitive_field_type(char type) {
<span class="line-modified">1085   return (type != JVM_SIGNATURE_CLASS &amp;&amp; type != JVM_SIGNATURE_ARRAY);</span>
1086 }
1087 
1088 // helper function to copy the value from location addr to jvalue.
1089 static inline void copy_to_jvalue(jvalue *v, address addr, jvmtiPrimitiveType value_type) {
1090   switch (value_type) {
1091     case JVMTI_PRIMITIVE_TYPE_BOOLEAN : { v-&gt;z = *(jboolean*)addr; break; }
1092     case JVMTI_PRIMITIVE_TYPE_BYTE    : { v-&gt;b = *(jbyte*)addr;    break; }
1093     case JVMTI_PRIMITIVE_TYPE_CHAR    : { v-&gt;c = *(jchar*)addr;    break; }
1094     case JVMTI_PRIMITIVE_TYPE_SHORT   : { v-&gt;s = *(jshort*)addr;   break; }
1095     case JVMTI_PRIMITIVE_TYPE_INT     : { v-&gt;i = *(jint*)addr;     break; }
1096     case JVMTI_PRIMITIVE_TYPE_LONG    : { v-&gt;j = *(jlong*)addr;    break; }
1097     case JVMTI_PRIMITIVE_TYPE_FLOAT   : { v-&gt;f = *(jfloat*)addr;   break; }
1098     case JVMTI_PRIMITIVE_TYPE_DOUBLE  : { v-&gt;d = *(jdouble*)addr;  break; }
1099     default: ShouldNotReachHere();
1100   }
1101 }
1102 
1103 // helper function to invoke string primitive value callback
1104 // returns visit control flags
1105 static jint invoke_string_value_callback(jvmtiStringPrimitiveValueCallback cb,
</pre>
<hr />
<pre>
1205     return 0;
1206   }
1207 
1208   // get the field map
1209   ClassFieldMap* field_map = ClassFieldMap::create_map_of_static_fields(klass);
1210 
1211   // invoke the callback for each static primitive field
1212   for (int i=0; i&lt;field_map-&gt;field_count(); i++) {
1213     ClassFieldDescriptor* field = field_map-&gt;field_at(i);
1214 
1215     // ignore non-primitive fields
1216     char type = field-&gt;field_type();
1217     if (!is_primitive_field_type(type)) {
1218       continue;
1219     }
1220     // one-to-one mapping
1221     jvmtiPrimitiveType value_type = (jvmtiPrimitiveType)type;
1222 
1223     // get offset and field value
1224     int offset = field-&gt;field_offset();
<span class="line-modified">1225     address addr = cast_from_oop&lt;address&gt;(klass-&gt;java_mirror()) + offset;</span>
1226     jvalue value;
1227     copy_to_jvalue(&amp;value, addr, value_type);
1228 
1229     // field index
1230     reference_info.field.index = field-&gt;field_index();
1231 
1232     // invoke the callback
1233     jint res = (*cb)(JVMTI_HEAP_REFERENCE_STATIC_FIELD,
1234                      &amp;reference_info,
1235                      wrapper-&gt;klass_tag(),
1236                      wrapper-&gt;obj_tag_p(),
1237                      value,
1238                      value_type,
1239                      user_data);
1240     if (res &amp; JVMTI_VISIT_ABORT) {
1241       delete field_map;
1242       return res;
1243     }
1244   }
1245 
</pre>
<hr />
<pre>
1258   // for instance fields only the index will be set
1259   static jvmtiHeapReferenceInfo reference_info = { 0 };
1260 
1261   // get the map of the instance fields
1262   ClassFieldMap* fields = JvmtiCachedClassFieldMap::get_map_of_instance_fields(obj);
1263 
1264   // invoke the callback for each instance primitive field
1265   for (int i=0; i&lt;fields-&gt;field_count(); i++) {
1266     ClassFieldDescriptor* field = fields-&gt;field_at(i);
1267 
1268     // ignore non-primitive fields
1269     char type = field-&gt;field_type();
1270     if (!is_primitive_field_type(type)) {
1271       continue;
1272     }
1273     // one-to-one mapping
1274     jvmtiPrimitiveType value_type = (jvmtiPrimitiveType)type;
1275 
1276     // get offset and field value
1277     int offset = field-&gt;field_offset();
<span class="line-modified">1278     address addr = cast_from_oop&lt;address&gt;(obj) + offset;</span>
1279     jvalue value;
1280     copy_to_jvalue(&amp;value, addr, value_type);
1281 
1282     // field index
1283     reference_info.field.index = field-&gt;field_index();
1284 
1285     // invoke the callback
1286     jint res = (*cb)(JVMTI_HEAP_REFERENCE_FIELD,
1287                      &amp;reference_info,
1288                      wrapper-&gt;klass_tag(),
1289                      wrapper-&gt;obj_tag_p(),
1290                      value,
1291                      value_type,
1292                      user_data);
1293     if (res &amp; JVMTI_VISIT_ABORT) {
1294       return res;
1295     }
1296   }
1297   return 0;
1298 }
</pre>
<hr />
<pre>
1315   void doit() {
1316     // Simulates barrier synchronization on safepoint.
1317     // This annotation is reasonably minimal in number of tsan callbacks.
1318     // By passing the lock directly, we are not actually locking it, just
1319     // telling TSAN we are to &quot;simulate&quot; the lock.
1320     TSAN_ONLY(TsanMutexScope tms(_tag_map-&gt;lock()));
1321 
1322     // allows class files maps to be cached during iteration
1323     ClassFieldMapCacheMark cm;
1324 
1325     // make sure that heap is parsable (fills TLABs with filler objects)
1326     Universe::heap()-&gt;ensure_parsability(false);  // no need to retire TLABs
1327 
1328     // Verify heap before iteration - if the heap gets corrupted then
1329     // JVMTI&#39;s IterateOverHeap will crash.
1330     if (VerifyBeforeIteration) {
1331       Universe::verify();
1332     }
1333 
1334     // do the iteration



1335     Universe::heap()-&gt;object_iterate(_blk);
1336   }
1337 
1338 };
1339 
1340 
1341 // An ObjectClosure used to support the deprecated IterateOverHeap and
1342 // IterateOverInstancesOfClass functions
1343 class IterateOverHeapObjectClosure: public ObjectClosure {
1344  private:
1345   JvmtiTagMap* _tag_map;
1346   Klass* _klass;
1347   jvmtiHeapObjectFilter _object_filter;
1348   jvmtiHeapObjectCallback _heap_object_callback;
1349   const void* _user_data;
1350 
1351   // accessors
1352   JvmtiTagMap* tag_map() const                    { return _tag_map; }
1353   jvmtiHeapObjectFilter object_filter() const     { return _object_filter; }
1354   jvmtiHeapObjectCallback object_callback() const { return _heap_object_callback; }
</pre>
<hr />
<pre>
1586     _tag_results = new (ResourceObj::C_HEAP, mtInternal) GrowableArray&lt;uint64_t&gt;(1,true);
1587   }
1588 
1589   ~TagObjectCollector() {
1590     delete _object_results;
1591     delete _tag_results;
1592   }
1593 
1594   // for each tagged object check if the tag value matches
1595   // - if it matches then we create a JNI local reference to the object
1596   // and record the reference and tag value.
1597   //
1598   void do_entry(JvmtiTagHashmapEntry* entry) {
1599     for (int i=0; i&lt;_tag_count; i++) {
1600       if (_tags[i] == entry-&gt;tag()) {
1601         // The reference in this tag map could be the only (implicitly weak)
1602         // reference to that object. If we hand it out, we need to keep it live wrt
1603         // SATB marking similar to other j.l.ref.Reference referents. This is
1604         // achieved by using a phantom load in the object() accessor.
1605         oop o = entry-&gt;object();
<span class="line-modified">1606         assert(o != NULL &amp;&amp; Universe::heap()-&gt;is_in(o), &quot;sanity check&quot;);</span>
1607         jobject ref = JNIHandles::make_local(JavaThread::current(), o);
1608         _object_results-&gt;append(ref);
1609         _tag_results-&gt;append((uint64_t)entry-&gt;tag());
1610       }
1611     }
1612   }
1613 
1614   // return the results from the collection
1615   //
1616   jvmtiError result(jint* count_ptr, jobject** object_result_ptr, jlong** tag_result_ptr) {
1617     jvmtiError error;
1618     int count = _object_results-&gt;length();
1619     assert(count &gt;= 0, &quot;sanity check&quot;);
1620 
1621     // if object_result_ptr is not NULL then allocate the result and copy
1622     // in the object references.
1623     if (object_result_ptr != NULL) {
1624       error = _env-&gt;Allocate(count * sizeof(jobject), (unsigned char**)object_result_ptr);
1625       if (error != JVMTI_ERROR_NONE) {
1626         return error;
</pre>
<hr />
<pre>
1670 //
1671 // This implementation uses the existing mark bits in an object for
1672 // marking. Objects that are marked must later have their headers restored.
1673 // As most objects are unlocked and don&#39;t have their identity hash computed
1674 // we don&#39;t have to save their headers. Instead we save the headers that
1675 // are &quot;interesting&quot;. Later when the headers are restored this implementation
1676 // restores all headers to their initial value and then restores the few
1677 // objects that had interesting headers.
1678 //
1679 // Future work: This implementation currently uses growable arrays to save
1680 // the oop and header of interesting objects. As an optimization we could
1681 // use the same technique as the GC and make use of the unused area
1682 // between top() and end().
1683 //
1684 
1685 // An ObjectClosure used to restore the mark bits of an object
1686 class RestoreMarksClosure : public ObjectClosure {
1687  public:
1688   void do_object(oop o) {
1689     if (o != NULL) {
<span class="line-modified">1690       markWord mark = o-&gt;mark();</span>
<span class="line-modified">1691       if (mark.is_marked()) {</span>
1692         o-&gt;init_mark();
1693       }
1694     }
1695   }
1696 };
1697 
1698 // ObjectMarker provides the mark and visited functions
1699 class ObjectMarker : AllStatic {
1700  private:
1701   // saved headers
1702   static GrowableArray&lt;oop&gt;* _saved_oop_stack;
<span class="line-modified">1703   static GrowableArray&lt;markWord&gt;* _saved_mark_stack;</span>
1704   static bool _needs_reset;                  // do we need to reset mark bits?
1705 
1706  public:
1707   static void init();                       // initialize
1708   static void done();                       // clean-up
1709 
1710   static inline void mark(oop o);           // mark an object
1711   static inline bool visited(oop o);        // check if object has been visited
1712 
1713   static inline bool needs_reset()            { return _needs_reset; }
1714   static inline void set_needs_reset(bool v)  { _needs_reset = v; }
1715 };
1716 
1717 GrowableArray&lt;oop&gt;* ObjectMarker::_saved_oop_stack = NULL;
<span class="line-modified">1718 GrowableArray&lt;markWord&gt;* ObjectMarker::_saved_mark_stack = NULL;</span>
1719 bool ObjectMarker::_needs_reset = true;  // need to reset mark bits by default
1720 
1721 // initialize ObjectMarker - prepares for object marking
1722 void ObjectMarker::init() {
1723   assert(Thread::current()-&gt;is_VM_thread(), &quot;must be VMThread&quot;);
1724 
1725   // prepare heap for iteration
1726   Universe::heap()-&gt;ensure_parsability(false);  // no need to retire TLABs
1727 
1728   // create stacks for interesting headers
<span class="line-modified">1729   _saved_mark_stack = new (ResourceObj::C_HEAP, mtInternal) GrowableArray&lt;markWord&gt;(4000, true);</span>
1730   _saved_oop_stack = new (ResourceObj::C_HEAP, mtInternal) GrowableArray&lt;oop&gt;(4000, true);
1731 
1732   if (UseBiasedLocking) {
1733     BiasedLocking::preserve_marks();
1734   }
1735 }
1736 
1737 // Object marking is done so restore object headers
1738 void ObjectMarker::done() {
1739   // iterate over all objects and restore the mark bits to
1740   // their initial value
1741   RestoreMarksClosure blk;
1742   if (needs_reset()) {
1743     Universe::heap()-&gt;object_iterate(&amp;blk);
1744   } else {
1745     // We don&#39;t need to reset mark bits on this call, but reset the
1746     // flag to the default for the next call.
1747     set_needs_reset(true);
1748   }
1749 
1750   // now restore the interesting headers
1751   for (int i = 0; i &lt; _saved_oop_stack-&gt;length(); i++) {
1752     oop o = _saved_oop_stack-&gt;at(i);
<span class="line-modified">1753     markWord mark = _saved_mark_stack-&gt;at(i);</span>
1754     o-&gt;set_mark(mark);
1755   }
1756 
1757   if (UseBiasedLocking) {
1758     BiasedLocking::restore_marks();
1759   }
1760 
1761   // free the stacks
1762   delete _saved_oop_stack;
1763   delete _saved_mark_stack;
1764 }
1765 
1766 // mark an object
1767 inline void ObjectMarker::mark(oop o) {
1768   assert(Universe::heap()-&gt;is_in(o), &quot;sanity check&quot;);
<span class="line-modified">1769   assert(!o-&gt;mark().is_marked(), &quot;should only mark an object once&quot;);</span>
1770 
1771   // object&#39;s mark word
<span class="line-modified">1772   markWord mark = o-&gt;mark();</span>
1773 
<span class="line-modified">1774   if (o-&gt;mark_must_be_preserved(mark)) {</span>
1775     _saved_mark_stack-&gt;push(mark);
1776     _saved_oop_stack-&gt;push(o);
1777   }
1778 
1779   // mark the object
<span class="line-modified">1780   o-&gt;set_mark(markWord::prototype().set_marked());</span>
1781 }
1782 
1783 // return true if object is marked
1784 inline bool ObjectMarker::visited(oop o) {
<span class="line-modified">1785   return o-&gt;mark().is_marked();</span>
1786 }
1787 
1788 // Stack allocated class to help ensure that ObjectMarker is used
1789 // correctly. Constructor initializes ObjectMarker, destructor calls
1790 // ObjectMarker&#39;s done() function to restore object headers.
1791 class ObjectMarkerController : public StackObj {
1792  public:
1793   ObjectMarkerController() {
1794     ObjectMarker::init();
1795   }
1796   ~ObjectMarkerController() {
1797     ObjectMarker::done();
1798   }
1799 };
1800 
1801 
1802 // helper to map a jvmtiHeapReferenceKind to an old style jvmtiHeapRootKind
1803 // (not performance critical as only used for roots)
1804 static jvmtiHeapRootKind toJvmtiHeapRootKind(jvmtiHeapReferenceKind kind) {
1805   switch (kind) {
</pre>
<hr />
<pre>
2614     _kind = kind;
2615     _continue = true;
2616   }
2617 
2618   inline bool stopped() {
2619     return !_continue;
2620   }
2621 
2622   void do_oop(oop* obj_p) {
2623     // iteration has terminated
2624     if (stopped()) {
2625       return;
2626     }
2627 
2628     oop o = NativeAccess&lt;AS_NO_KEEPALIVE&gt;::oop_load(obj_p);
2629     // ignore null
2630     if (o == NULL) {
2631       return;
2632     }
2633 
<span class="line-modified">2634     assert(Universe::heap()-&gt;is_in(o), &quot;should be impossible&quot;);</span>
2635 
2636     jvmtiHeapReferenceKind kind = root_kind();
2637     if (kind == JVMTI_HEAP_REFERENCE_SYSTEM_CLASS) {
2638       // SystemDictionary::oops_do reports the application
2639       // class loader as a root. We want this root to be reported as
2640       // a root kind of &quot;OTHER&quot; rather than &quot;SYSTEM_CLASS&quot;.
2641       if (!o-&gt;is_instance() || !InstanceKlass::cast(o-&gt;klass())-&gt;is_mirror_instance_klass()) {
2642         kind = JVMTI_HEAP_REFERENCE_OTHER;
2643       }
2644     }
2645 
2646     // invoke the callback
2647     _continue = CallbackInvoker::report_simple_root(kind, o);
2648 
2649   }
2650   virtual void do_oop(narrowOop* obj_p) { ShouldNotReachHere(); }
2651 };
2652 
2653 // A supporting closure used to process JNI locals
2654 class JNILocalRootsClosure : public OopClosure {
</pre>
<hr />
<pre>
2843 inline bool VM_HeapWalkOperation::iterate_over_type_array(oop o) {
2844   Klass* k = o-&gt;klass();
2845   oop mirror = k-&gt;java_mirror();
2846   if (!CallbackInvoker::report_class_reference(o, mirror)) {
2847     return false;
2848   }
2849 
2850   // report the array contents if required
2851   if (is_reporting_primitive_array_values()) {
2852     if (!CallbackInvoker::report_primitive_array_values(o)) {
2853       return false;
2854     }
2855   }
2856   return true;
2857 }
2858 
2859 #ifdef ASSERT
2860 // verify that a static oop field is in range
2861 static inline bool verify_static_oop(InstanceKlass* ik,
2862                                      oop mirror, int offset) {
<span class="line-modified">2863   address obj_p = cast_from_oop&lt;address&gt;(mirror) + offset;</span>
2864   address start = (address)InstanceMirrorKlass::start_of_static_fields(mirror);
2865   address end = start + (java_lang_Class::static_oop_field_count(mirror) * heapOopSize);
2866   assert(end &gt;= start, &quot;sanity check&quot;);
2867 
2868   if (obj_p &gt;= start &amp;&amp; obj_p &lt; end) {
2869     return true;
2870   } else {
2871     return false;
2872   }
2873 }
2874 #endif // #ifdef ASSERT
2875 
2876 // a class references its super class, interfaces, class loader, ...
2877 // and finally its static fields
2878 inline bool VM_HeapWalkOperation::iterate_over_class(oop java_class) {
2879   int i;
2880   Klass* klass = java_lang_Class::as_Klass(java_class);
2881 
2882   if (klass-&gt;is_instance_klass()) {
2883     InstanceKlass* ik = InstanceKlass::cast(klass);
</pre>
<hr />
<pre>
2971     }
2972 
2973     // iterate over the static fields
2974 
2975     ClassFieldMap* field_map = ClassFieldMap::create_map_of_static_fields(klass);
2976     for (i=0; i&lt;field_map-&gt;field_count(); i++) {
2977       ClassFieldDescriptor* field = field_map-&gt;field_at(i);
2978       char type = field-&gt;field_type();
2979       if (!is_primitive_field_type(type)) {
2980         oop fld_o = mirror-&gt;obj_field(field-&gt;field_offset());
2981         assert(verify_static_oop(ik, mirror, field-&gt;field_offset()), &quot;sanity check&quot;);
2982         if (fld_o != NULL) {
2983           int slot = field-&gt;field_index();
2984           if (!CallbackInvoker::report_static_field_reference(mirror, fld_o, slot)) {
2985             delete field_map;
2986             return false;
2987           }
2988         }
2989       } else {
2990          if (is_reporting_primitive_fields()) {
<span class="line-modified">2991            address addr = cast_from_oop&lt;address&gt;(mirror) + field-&gt;field_offset();</span>
2992            int slot = field-&gt;field_index();
2993            if (!CallbackInvoker::report_primitive_static_field(mirror, slot, addr, type)) {
2994              delete field_map;
2995              return false;
2996           }
2997         }
2998       }
2999     }
3000     delete field_map;
3001 
3002     return true;
3003   }
3004 
3005   return true;
3006 }
3007 
3008 // an object references a class and its instance fields
3009 // (static fields are ignored here as we report these as
3010 // references from the class).
3011 inline bool VM_HeapWalkOperation::iterate_over_object(oop o) {
3012   // reference to the class
3013   if (!CallbackInvoker::report_class_reference(o, o-&gt;klass()-&gt;java_mirror())) {
3014     return false;
3015   }
3016 
3017   // iterate over instance fields
3018   ClassFieldMap* field_map = JvmtiCachedClassFieldMap::get_map_of_instance_fields(o);
3019   for (int i=0; i&lt;field_map-&gt;field_count(); i++) {
3020     ClassFieldDescriptor* field = field_map-&gt;field_at(i);
3021     char type = field-&gt;field_type();
3022     if (!is_primitive_field_type(type)) {
<span class="line-modified">3023       oop fld_o = o-&gt;obj_field_access&lt;AS_NO_KEEPALIVE | ON_UNKNOWN_OOP_REF&gt;(field-&gt;field_offset());</span>
3024       // ignore any objects that aren&#39;t visible to profiler
3025       if (fld_o != NULL) {
<span class="line-modified">3026         assert(Universe::heap()-&gt;is_in(fld_o), &quot;unsafe code should not &quot;</span>
3027                &quot;have references to Klass* anymore&quot;);
3028         int slot = field-&gt;field_index();
3029         if (!CallbackInvoker::report_field_reference(o, fld_o, slot)) {
3030           return false;
3031         }
3032       }
3033     } else {
3034       if (is_reporting_primitive_fields()) {
3035         // primitive instance field
<span class="line-modified">3036         address addr = cast_from_oop&lt;address&gt;(o) + field-&gt;field_offset();</span>
3037         int slot = field-&gt;field_index();
3038         if (!CallbackInvoker::report_primitive_instance_field(o, slot, addr, type)) {
3039           return false;
3040         }
3041       }
3042     }
3043   }
3044 
3045   // if the object is a java.lang.String
3046   if (is_reporting_string_values() &amp;&amp;
3047       o-&gt;klass() == SystemDictionary::String_klass()) {
3048     if (!CallbackInvoker::report_string_value(o)) {
3049       return false;
3050     }
3051   }
3052   return true;
3053 }
3054 
3055 
3056 // Collects all simple (non-stack) roots except for threads;
</pre>
<hr />
<pre>
3077   CLDToOopClosure cld_closure(&amp;blk, false);
3078   ClassLoaderDataGraph::always_strong_cld_do(&amp;cld_closure);
3079   if (blk.stopped()) {
3080     return false;
3081   }
3082 
3083   // Inflated monitors
3084   blk.set_kind(JVMTI_HEAP_REFERENCE_MONITOR);
3085   ObjectSynchronizer::oops_do(&amp;blk);
3086   if (blk.stopped()) {
3087     return false;
3088   }
3089 
3090   // threads are now handled in collect_stack_roots()
3091 
3092   // Other kinds of roots maintained by HotSpot
3093   // Many of these won&#39;t be visible but others (such as instances of important
3094   // exceptions) will be visible.
3095   blk.set_kind(JVMTI_HEAP_REFERENCE_OTHER);
3096   Universe::oops_do(&amp;blk);
<span class="line-added">3097   if (blk.stopped()) {</span>
<span class="line-added">3098     return false;</span>
<span class="line-added">3099   }</span>
3100 
3101   return true;
3102 }
3103 
3104 // Walk the stack of a given thread and find all references (locals
3105 // and JNI calls) and report these as stack references
3106 inline bool VM_HeapWalkOperation::collect_stack_roots(JavaThread* java_thread,
3107                                                       JNILocalRootsClosure* blk)
3108 {
3109   oop threadObj = java_thread-&gt;threadObj();
3110   assert(threadObj != NULL, &quot;sanity check&quot;);
3111 
3112   // only need to get the thread&#39;s tag once per thread
3113   jlong thread_tag = tag_for(_tag_map, threadObj);
3114 
3115   // also need the thread id
3116   jlong tid = java_lang_Thread::thread_id(threadObj);
3117 
3118 
3119   if (java_thread-&gt;has_last_Java_frame()) {
</pre>
<hr />
<pre>
3355   oop obj = JNIHandles::resolve(object);
3356   Handle initial_object(Thread::current(), obj);
3357 
3358   MutexLocker ml(Heap_lock);
3359   AdvancedHeapWalkContext context(heap_filter, klass, callbacks);
3360   VM_HeapWalkOperation op(this, initial_object, context, user_data);
3361   VMThread::execute(&amp;op);
3362 }
3363 
3364 
3365 void JvmtiTagMap::weak_oops_do(BoolObjectClosure* is_alive, OopClosure* f) {
3366   // No locks during VM bring-up (0 threads) and no safepoints after main
3367   // thread creation and before VMThread creation (1 thread); initial GC
3368   // verification can happen in that window which gets to here.
3369   assert(Threads::number_of_threads() &lt;= 1 ||
3370          SafepointSynchronize::is_at_safepoint(),
3371          &quot;must be executed at a safepoint&quot;);
3372   if (JvmtiEnv::environments_might_exist()) {
3373     JvmtiEnvIterator it;
3374     for (JvmtiEnvBase* env = it.first(); env != NULL; env = it.next(env)) {
<span class="line-modified">3375       JvmtiTagMap* tag_map = env-&gt;tag_map_acquire();</span>
3376       if (tag_map != NULL &amp;&amp; !tag_map-&gt;is_empty()) {
3377         tag_map-&gt;do_weak_oops(is_alive, f);
3378       }
3379     }
3380   }
3381 }
3382 
3383 void JvmtiTagMap::do_weak_oops(BoolObjectClosure* is_alive, OopClosure* f) {
3384 
3385   // does this environment have the OBJECT_FREE event enabled
3386   bool post_object_free = env()-&gt;is_enabled(JVMTI_EVENT_OBJECT_FREE);
3387 
3388   // counters used for trace message
3389   int freed = 0;
3390   int moved = 0;
3391 
3392   JvmtiTagHashmap* hashmap = this-&gt;hashmap();
3393 
3394   // reenable sizing (if disabled)
3395   hashmap-&gt;set_resizing_enabled(true);
</pre>
<hr />
<pre>
3397   // if the hashmap is empty then we can skip it
3398   if (hashmap-&gt;_entry_count == 0) {
3399     return;
3400   }
3401 
3402   // now iterate through each entry in the table
3403 
3404   JvmtiTagHashmapEntry** table = hashmap-&gt;table();
3405   int size = hashmap-&gt;size();
3406 
3407   JvmtiTagHashmapEntry* delayed_add = NULL;
3408 
3409   for (int pos = 0; pos &lt; size; ++pos) {
3410     JvmtiTagHashmapEntry* entry = table[pos];
3411     JvmtiTagHashmapEntry* prev = NULL;
3412 
3413     while (entry != NULL) {
3414       JvmtiTagHashmapEntry* next = entry-&gt;next();
3415 
3416       // has object been GC&#39;ed
<span class="line-modified">3417       if (!is_alive-&gt;do_object_b(entry-&gt;object_raw())) {</span>
3418         // grab the tag
3419         jlong tag = entry-&gt;tag();
3420         guarantee(tag != 0, &quot;checking&quot;);
3421 
3422         // remove GC&#39;ed entry from hashmap and return the
3423         // entry to the free list
3424         hashmap-&gt;remove(prev, pos, entry);
3425         destroy_entry(entry);
3426 
3427         // post the event to the profiler
3428         if (post_object_free) {
3429           JvmtiExport::post_object_free(env(), tag);
3430         }
3431 
3432         ++freed;
3433       } else {
3434         f-&gt;do_oop(entry-&gt;object_addr());
<span class="line-modified">3435         oop new_oop = entry-&gt;object_raw();</span>
3436 
3437         // if the object has moved then re-hash it and move its
3438         // entry to its new location.
3439         unsigned int new_pos = JvmtiTagHashmap::hash(new_oop, size);
3440         if (new_pos != (unsigned int)pos) {
3441           if (prev == NULL) {
3442             table[pos] = next;
3443           } else {
3444             prev-&gt;set_next(next);
3445           }
3446           if (new_pos &lt; (unsigned int)pos) {
3447             entry-&gt;set_next(table[new_pos]);
3448             table[new_pos] = entry;
3449           } else {
3450             // Delay adding this entry to it&#39;s new position as we&#39;d end up
3451             // hitting it again during this iteration.
3452             entry-&gt;set_next(delayed_add);
3453             delayed_add = entry;
3454           }
3455           moved++;
3456         } else {
3457           // object didn&#39;t move
3458           prev = entry;
3459         }
3460       }
3461 
3462       entry = next;
3463     }
3464   }
3465 
3466   // Re-add all the entries which were kept aside
3467   while (delayed_add != NULL) {
3468     JvmtiTagHashmapEntry* next = delayed_add-&gt;next();
<span class="line-modified">3469     unsigned int pos = JvmtiTagHashmap::hash(delayed_add-&gt;object_raw(), size);</span>
3470     delayed_add-&gt;set_next(table[pos]);
3471     table[pos] = delayed_add;
3472     delayed_add = next;
3473   }
3474 
3475   log_debug(jvmti, objecttagging)(&quot;(%d-&gt;%d, %d freed, %d total moves)&quot;,
3476                                   hashmap-&gt;_entry_count + freed, hashmap-&gt;_entry_count, freed, moved);
3477 }
</pre>
</td>
</tr>
</table>
<center><a href="jvmtiRedefineClasses.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="jvmtiTagMap.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>