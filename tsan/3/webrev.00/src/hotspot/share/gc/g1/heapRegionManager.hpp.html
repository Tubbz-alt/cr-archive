<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/gc/g1/heapRegionManager.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2001, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_GC_G1_HEAPREGIONMANAGER_HPP
 26 #define SHARE_GC_G1_HEAPREGIONMANAGER_HPP
 27 
 28 #include &quot;gc/g1/g1BiasedArray.hpp&quot;
 29 #include &quot;gc/g1/g1RegionToSpaceMapper.hpp&quot;
 30 #include &quot;gc/g1/heapRegionSet.hpp&quot;
 31 #include &quot;services/memoryUsage.hpp&quot;
 32 
 33 class HeapRegion;
 34 class HeapRegionClosure;
 35 class HeapRegionClaimer;
 36 class FreeRegionList;
 37 class WorkGang;
 38 
 39 class G1HeapRegionTable : public G1BiasedMappedArray&lt;HeapRegion*&gt; {
 40  protected:
 41   virtual HeapRegion* default_value() const { return NULL; }
 42 };
 43 
 44 // This class keeps track of the actual heap memory, auxiliary data
 45 // and its metadata (i.e., HeapRegion instances) and the list of free regions.
 46 //
 47 // This allows maximum flexibility for deciding what to commit or uncommit given
 48 // a request from outside.
 49 //
 50 // HeapRegions are kept in the _regions array in address order. A region&#39;s
 51 // index in the array corresponds to its index in the heap (i.e., 0 is the
 52 // region at the bottom of the heap, 1 is the one after it, etc.). Two
 53 // regions that are consecutive in the array should also be adjacent in the
 54 // address space (i.e., region(i).end() == region(i+1).bottom().
 55 //
 56 // We create a HeapRegion when we commit the region&#39;s address space
 57 // for the first time. When we uncommit the address space of a
 58 // region we retain the HeapRegion to be able to re-use it in the
 59 // future (in case we recommit it).
 60 //
 61 // We keep track of three lengths:
 62 //
 63 // * _num_committed (returned by length()) is the number of currently
 64 //   committed regions. These may not be contiguous.
 65 // * _allocated_heapregions_length (not exposed outside this class) is the
 66 //   number of regions+1 for which we have HeapRegions.
 67 // * max_length() returns the maximum number of regions the heap can have.
 68 //
 69 
 70 class HeapRegionManager: public CHeapObj&lt;mtGC&gt; {
 71   friend class VMStructs;
 72   friend class HeapRegionClaimer;
 73 
 74   G1RegionToSpaceMapper* _bot_mapper;
 75   G1RegionToSpaceMapper* _cardtable_mapper;
 76   G1RegionToSpaceMapper* _card_counts_mapper;
 77 
 78   // Each bit in this bitmap indicates that the corresponding region is available
 79   // for allocation.
 80   CHeapBitMap _available_map;
 81 
 82    // The number of regions committed in the heap.
 83   uint _num_committed;
 84 
 85   // Internal only. The highest heap region +1 we allocated a HeapRegion instance for.
 86   uint _allocated_heapregions_length;
 87 
 88   HeapWord* heap_bottom() const { return _regions.bottom_address_mapped(); }
 89   HeapWord* heap_end() const {return _regions.end_address_mapped(); }
 90 
 91   // Pass down commit calls to the VirtualSpace.
 92   void commit_regions(uint index, size_t num_regions = 1, WorkGang* pretouch_gang = NULL);
 93 
 94   // Notify other data structures about change in the heap layout.
 95   void update_committed_space(HeapWord* old_end, HeapWord* new_end);
 96 
 97   // Find a contiguous set of empty or uncommitted regions of length num and return
 98   // the index of the first region or G1_NO_HRM_INDEX if the search was unsuccessful.
 99   // If only_empty is true, only empty regions are considered.
100   // Searches from bottom to top of the heap, doing a first-fit.
101   uint find_contiguous(size_t num, bool only_empty);
102   // Finds the next sequence of unavailable regions starting from start_idx. Returns the
103   // length of the sequence found. If this result is zero, no such sequence could be found,
104   // otherwise res_idx indicates the start index of these regions.
105   uint find_unavailable_from_idx(uint start_idx, uint* res_idx) const;
106   // Finds the next sequence of empty regions starting from start_idx, going backwards in
107   // the heap. Returns the length of the sequence found. If this value is zero, no
108   // sequence could be found, otherwise res_idx contains the start index of this range.
109   uint find_empty_from_idx_reverse(uint start_idx, uint* res_idx) const;
110 
111   // Checks the G1MemoryNodeManager to see if this region is on the preferred node.
112   bool is_on_preferred_index(uint region_index, uint preferred_node_index);
113 
114 protected:
115   G1HeapRegionTable _regions;
116   G1RegionToSpaceMapper* _heap_mapper;
117   G1RegionToSpaceMapper* _prev_bitmap_mapper;
118   G1RegionToSpaceMapper* _next_bitmap_mapper;
119   FreeRegionList _free_list;
120 
121   void make_regions_available(uint index, uint num_regions = 1, WorkGang* pretouch_gang = NULL);
122   void uncommit_regions(uint index, size_t num_regions = 1);
123   // Allocate a new HeapRegion for the given index.
124   HeapRegion* new_heap_region(uint hrm_index);
125 #ifdef ASSERT
126 public:
127   bool is_free(HeapRegion* hr) const;
128 #endif
129 public:
130   // Empty constructor, we&#39;ll initialize it with the initialize() method.
131   HeapRegionManager();
132 
133   static HeapRegionManager* create_manager(G1CollectedHeap* heap);
134 
135   virtual void initialize(G1RegionToSpaceMapper* heap_storage,
136                           G1RegionToSpaceMapper* prev_bitmap,
137                           G1RegionToSpaceMapper* next_bitmap,
138                           G1RegionToSpaceMapper* bot,
139                           G1RegionToSpaceMapper* cardtable,
140                           G1RegionToSpaceMapper* card_counts);
141 
142   // Prepare heap regions before and after full collection.
143   // Nothing to be done in this class.
144   virtual void prepare_for_full_collection_start() {}
145   virtual void prepare_for_full_collection_end() {}
146 
147   // Return the &quot;dummy&quot; region used for G1AllocRegion. This is currently a hardwired
148   // new HeapRegion that owns HeapRegion at index 0. Since at the moment we commit
149   // the heap from the lowest address, this region (and its associated data
150   // structures) are available and we do not need to check further.
151   virtual HeapRegion* get_dummy_region() { return new_heap_region(0); }
152 
153   // Return the HeapRegion at the given index. Assume that the index
154   // is valid.
155   inline HeapRegion* at(uint index) const;
156 
157   // Return the HeapRegion at the given index, NULL if the index
158   // is for an unavailable region.
159   inline HeapRegion* at_or_null(uint index) const;
160 
161   // Returns whether the given region is available for allocation.
162   bool is_available(uint region) const;
163 
164   // Return the next region (by index) that is part of the same
165   // humongous object that hr is part of.
166   inline HeapRegion* next_region_in_humongous(HeapRegion* hr) const;
167 
168   // If addr is within the committed space return its corresponding
169   // HeapRegion, otherwise return NULL.
170   inline HeapRegion* addr_to_region(HeapWord* addr) const;
171 
172   // Insert the given region into the free region list.
173   inline void insert_into_free_list(HeapRegion* hr);
174 
175   // Rebuild the free region list from scratch.
176   void rebuild_free_list(WorkGang* workers);
177 
178   // Insert the given region list into the global free region list.
179   void insert_list_into_free_list(FreeRegionList* list) {
180     _free_list.add_ordered(list);
181   }
182 
183   // Allocate a free region with specific node index. If fails allocate with next node index.
184   virtual HeapRegion* allocate_free_region(HeapRegionType type, uint requested_node_index);
185 
186   inline void allocate_free_regions_starting_at(uint first, uint num_regions);
187 
188   // Remove all regions from the free list.
189   void remove_all_free_regions() {
190     _free_list.remove_all();
191   }
192 
193   // Return the number of committed free regions in the heap.
194   uint num_free_regions() const {
195     return _free_list.length();
196   }
197 
198   uint num_free_regions(uint node_index) const {
199     return _free_list.length(node_index);
200   }
201 
202   size_t total_free_bytes() const {
203     return num_free_regions() * HeapRegion::GrainBytes;
204   }
205 
206   // Return the number of available (uncommitted) regions.
207   uint available() const { return max_length() - length(); }
208 
209   // Return the number of regions that have been committed in the heap.
210   uint length() const { return _num_committed; }
211 
212   // Return the maximum number of regions in the heap.
213   uint max_length() const { return (uint)_regions.length(); }
214 
215   // Return maximum number of regions that heap can expand to.
216   virtual uint max_expandable_length() const { return (uint)_regions.length(); }
217 
218   MemoryUsage get_auxiliary_data_memory_usage() const;
219 
220   MemRegion reserved() const { return MemRegion(heap_bottom(), heap_end()); }
221 
222   // Expand the sequence to reflect that the heap has grown. Either create new
223   // HeapRegions, or re-use existing ones. Returns the number of regions the
224   // sequence was expanded by. If a HeapRegion allocation fails, the resulting
225   // number of regions might be smaller than what&#39;s desired.
226   virtual uint expand_by(uint num_regions, WorkGang* pretouch_workers);
227 
228   // Makes sure that the regions from start to start+num_regions-1 are available
229   // for allocation. Returns the number of regions that were committed to achieve
230   // this.
231   virtual uint expand_at(uint start, uint num_regions, WorkGang* pretouch_workers);
232 
233   // Try to expand on the given node index.
234   virtual uint expand_on_preferred_node(uint node_index);
235 
236   // Find a contiguous set of empty regions of length num. Returns the start index of
237   // that set, or G1_NO_HRM_INDEX.
238   virtual uint find_contiguous_only_empty(size_t num) { return find_contiguous(num, true); }
239   // Find a contiguous set of empty or unavailable regions of length num. Returns the
240   // start index of that set, or G1_NO_HRM_INDEX.
241   virtual uint find_contiguous_empty_or_unavailable(size_t num) { return find_contiguous(num, false); }
242 
243   HeapRegion* next_region_in_heap(const HeapRegion* r) const;
244 
245   // Find the highest free or uncommitted region in the reserved heap,
246   // and if uncommitted, commit it. If none are available, return G1_NO_HRM_INDEX.
247   // Set the &#39;expanded&#39; boolean true if a new region was committed.
248   virtual uint find_highest_free(bool* expanded);
249 
250   // Allocate the regions that contain the address range specified, committing the
251   // regions if necessary. Return false if any of the regions is already committed
252   // and not free, and return the number of regions newly committed in commit_count.
253   bool allocate_containing_regions(MemRegion range, size_t* commit_count, WorkGang* pretouch_workers);
254 
255   // Apply blk-&gt;do_heap_region() on all committed regions in address order,
256   // terminating the iteration early if do_heap_region() returns true.
257   void iterate(HeapRegionClosure* blk) const;
258 
259   void par_iterate(HeapRegionClosure* blk, HeapRegionClaimer* hrclaimer, const uint start_index) const;
260 
261   // Uncommit up to num_regions_to_remove regions that are completely free.
262   // Return the actual number of uncommitted regions.
263   virtual uint shrink_by(uint num_regions_to_remove);
264 
265   // Uncommit a number of regions starting at the specified index, which must be available,
266   // empty, and free.
267   void shrink_at(uint index, size_t num_regions);
268 
269   virtual void verify();
270 
271   // Do some sanity checking.
272   void verify_optional() PRODUCT_RETURN;
273 };
274 
275 // The HeapRegionClaimer is used during parallel iteration over heap regions,
276 // allowing workers to claim heap regions, gaining exclusive rights to these regions.
277 class HeapRegionClaimer : public StackObj {
278   uint           _n_workers;
279   uint           _n_regions;
280   volatile uint* _claims;
281 
282   static const uint Unclaimed = 0;
283   static const uint Claimed   = 1;
284 
285  public:
286   HeapRegionClaimer(uint n_workers);
287   ~HeapRegionClaimer();
288 
289   inline uint n_regions() const {
290     return _n_regions;
291   }
292 
293   // Return a start offset given a worker id.
294   uint offset_for_worker(uint worker_id) const;
295 
296   // Check if region has been claimed with this HRClaimer.
297   bool is_region_claimed(uint region_index) const;
298 
299   // Claim the given region, returns true if successfully claimed.
300   bool claim_region(uint region_index);
301 };
302 #endif // SHARE_GC_G1_HEAPREGIONMANAGER_HPP
    </pre>
  </body>
</html>