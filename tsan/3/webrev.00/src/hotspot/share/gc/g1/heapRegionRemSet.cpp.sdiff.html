<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/g1/heapRegionRemSet.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="heapRegionManager.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="heapRegionRemSet.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/g1/heapRegionRemSet.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2001, 2018, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;gc/g1/g1BlockOffsetTable.inline.hpp&quot;
 27 #include &quot;gc/g1/g1CollectedHeap.inline.hpp&quot;
 28 #include &quot;gc/g1/g1ConcurrentRefine.hpp&quot;
 29 #include &quot;gc/g1/heapRegionManager.inline.hpp&quot;
<span class="line-modified"> 30 #include &quot;gc/g1/heapRegionRemSet.hpp&quot;</span>
<span class="line-modified"> 31 #include &quot;gc/shared/space.inline.hpp&quot;</span>
 32 #include &quot;memory/allocation.hpp&quot;
 33 #include &quot;memory/padded.inline.hpp&quot;
 34 #include &quot;oops/oop.inline.hpp&quot;
 35 #include &quot;runtime/atomic.hpp&quot;
 36 #include &quot;utilities/bitMap.inline.hpp&quot;
 37 #include &quot;utilities/debug.hpp&quot;
 38 #include &quot;utilities/formatBuffer.hpp&quot;
 39 #include &quot;utilities/globalDefinitions.hpp&quot;
 40 #include &quot;utilities/growableArray.hpp&quot;
 41 
 42 const char* HeapRegionRemSet::_state_strings[] =  {&quot;Untracked&quot;, &quot;Updating&quot;, &quot;Complete&quot;};
 43 const char* HeapRegionRemSet::_short_state_strings[] =  {&quot;UNTRA&quot;, &quot;UPDAT&quot;, &quot;CMPLT&quot;};
 44 
<span class="line-modified"> 45 class PerRegionTable: public CHeapObj&lt;mtGC&gt; {</span>
<span class="line-modified"> 46   friend class OtherRegionsTable;</span>
<span class="line-modified"> 47   friend class HeapRegionRemSetIterator;</span>
<span class="line-modified"> 48 </span>
<span class="line-modified"> 49   HeapRegion*     _hr;</span>
<span class="line-modified"> 50   CHeapBitMap     _bm;</span>
<span class="line-modified"> 51   jint            _occupied;</span>
<span class="line-modified"> 52 </span>
<span class="line-modified"> 53   // next pointer for free/allocated &#39;all&#39; list</span>
<span class="line-modified"> 54   PerRegionTable* _next;</span>
<span class="line-removed"> 55 </span>
<span class="line-removed"> 56   // prev pointer for the allocated &#39;all&#39; list</span>
<span class="line-removed"> 57   PerRegionTable* _prev;</span>
<span class="line-removed"> 58 </span>
<span class="line-removed"> 59   // next pointer in collision list</span>
<span class="line-removed"> 60   PerRegionTable * _collision_list_next;</span>
<span class="line-removed"> 61 </span>
<span class="line-removed"> 62   // Global free list of PRTs</span>
<span class="line-removed"> 63   static PerRegionTable* volatile _free_list;</span>
<span class="line-removed"> 64 </span>
<span class="line-removed"> 65 protected:</span>
<span class="line-removed"> 66   // We need access in order to union things into the base table.</span>
<span class="line-removed"> 67   BitMap* bm() { return &amp;_bm; }</span>
<span class="line-removed"> 68 </span>
<span class="line-removed"> 69   PerRegionTable(HeapRegion* hr) :</span>
<span class="line-removed"> 70     _hr(hr),</span>
<span class="line-removed"> 71     _bm(HeapRegion::CardsPerRegion, mtGC),</span>
<span class="line-removed"> 72     _occupied(0),</span>
<span class="line-removed"> 73     _next(NULL), _prev(NULL),</span>
<span class="line-removed"> 74     _collision_list_next(NULL)</span>
<span class="line-removed"> 75   {}</span>
<span class="line-removed"> 76 </span>
<span class="line-removed"> 77   void add_card_work(CardIdx_t from_card, bool par) {</span>
<span class="line-removed"> 78     if (!_bm.at(from_card)) {</span>
<span class="line-removed"> 79       if (par) {</span>
<span class="line-removed"> 80         if (_bm.par_at_put(from_card, 1)) {</span>
<span class="line-removed"> 81           Atomic::inc(&amp;_occupied);</span>
<span class="line-removed"> 82         }</span>
<span class="line-removed"> 83       } else {</span>
<span class="line-removed"> 84         _bm.at_put(from_card, 1);</span>
<span class="line-removed"> 85         _occupied++;</span>
<span class="line-removed"> 86       }</span>
<span class="line-removed"> 87     }</span>
<span class="line-removed"> 88   }</span>
<span class="line-removed"> 89 </span>
<span class="line-removed"> 90   void add_reference_work(OopOrNarrowOopStar from, bool par) {</span>
<span class="line-removed"> 91     // Must make this robust in case &quot;from&quot; is not in &quot;_hr&quot;, because of</span>
<span class="line-removed"> 92     // concurrency.</span>
<span class="line-removed"> 93 </span>
<span class="line-removed"> 94     HeapRegion* loc_hr = hr();</span>
<span class="line-removed"> 95     // If the test below fails, then this table was reused concurrently</span>
<span class="line-removed"> 96     // with this operation.  This is OK, since the old table was coarsened,</span>
<span class="line-removed"> 97     // and adding a bit to the new table is never incorrect.</span>
<span class="line-removed"> 98     if (loc_hr-&gt;is_in_reserved(from)) {</span>
<span class="line-removed"> 99       CardIdx_t from_card = OtherRegionsTable::card_within_region(from, loc_hr);</span>
<span class="line-removed">100       add_card_work(from_card, par);</span>
<span class="line-removed">101     }</span>
<span class="line-removed">102   }</span>
<span class="line-removed">103 </span>
<span class="line-removed">104 public:</span>
<span class="line-removed">105 </span>
<span class="line-removed">106   HeapRegion* hr() const { return OrderAccess::load_acquire(&amp;_hr); }</span>
<span class="line-removed">107 </span>
<span class="line-removed">108   jint occupied() const {</span>
<span class="line-removed">109     // Overkill, but if we ever need it...</span>
<span class="line-removed">110     // guarantee(_occupied == _bm.count_one_bits(), &quot;Check&quot;);</span>
<span class="line-removed">111     return _occupied;</span>
<span class="line-removed">112   }</span>
<span class="line-removed">113 </span>
<span class="line-removed">114   void init(HeapRegion* hr, bool clear_links_to_all_list) {</span>
<span class="line-removed">115     if (clear_links_to_all_list) {</span>
<span class="line-removed">116       set_next(NULL);</span>
<span class="line-removed">117       set_prev(NULL);</span>
<span class="line-removed">118     }</span>
<span class="line-removed">119     _collision_list_next = NULL;</span>
<span class="line-removed">120     _occupied = 0;</span>
<span class="line-removed">121     _bm.clear();</span>
<span class="line-removed">122     // Make sure that the bitmap clearing above has been finished before publishing</span>
<span class="line-removed">123     // this PRT to concurrent threads.</span>
<span class="line-removed">124     OrderAccess::release_store(&amp;_hr, hr);</span>
<span class="line-removed">125   }</span>
<span class="line-removed">126 </span>
<span class="line-removed">127   void add_reference(OopOrNarrowOopStar from) {</span>
<span class="line-removed">128     add_reference_work(from, /*parallel*/ true);</span>
<span class="line-removed">129   }</span>
<span class="line-removed">130 </span>
<span class="line-removed">131   void seq_add_reference(OopOrNarrowOopStar from) {</span>
<span class="line-removed">132     add_reference_work(from, /*parallel*/ false);</span>
<span class="line-removed">133   }</span>
<span class="line-removed">134 </span>
<span class="line-removed">135   void add_card(CardIdx_t from_card_index) {</span>
<span class="line-removed">136     add_card_work(from_card_index, /*parallel*/ true);</span>
<span class="line-removed">137   }</span>
<span class="line-removed">138 </span>
<span class="line-removed">139   void seq_add_card(CardIdx_t from_card_index) {</span>
<span class="line-removed">140     add_card_work(from_card_index, /*parallel*/ false);</span>
<span class="line-removed">141   }</span>
<span class="line-removed">142 </span>
<span class="line-removed">143   // (Destructively) union the bitmap of the current table into the given</span>
<span class="line-removed">144   // bitmap (which is assumed to be of the same size.)</span>
<span class="line-removed">145   void union_bitmap_into(BitMap* bm) {</span>
<span class="line-removed">146     bm-&gt;set_union(_bm);</span>
<span class="line-removed">147   }</span>
<span class="line-removed">148 </span>
<span class="line-removed">149   // Mem size in bytes.</span>
<span class="line-removed">150   size_t mem_size() const {</span>
<span class="line-removed">151     return sizeof(PerRegionTable) + _bm.size_in_words() * HeapWordSize;</span>
<span class="line-removed">152   }</span>
<span class="line-removed">153 </span>
<span class="line-removed">154   // Requires &quot;from&quot; to be in &quot;hr()&quot;.</span>
<span class="line-removed">155   bool contains_reference(OopOrNarrowOopStar from) const {</span>
<span class="line-removed">156     assert(hr()-&gt;is_in_reserved(from), &quot;Precondition.&quot;);</span>
<span class="line-removed">157     size_t card_ind = pointer_delta(from, hr()-&gt;bottom(),</span>
<span class="line-removed">158                                     G1CardTable::card_size);</span>
<span class="line-removed">159     return _bm.at(card_ind);</span>
<span class="line-removed">160   }</span>
<span class="line-removed">161 </span>
<span class="line-removed">162   // Bulk-free the PRTs from prt to last, assumes that they are</span>
<span class="line-removed">163   // linked together using their _next field.</span>
<span class="line-removed">164   static void bulk_free(PerRegionTable* prt, PerRegionTable* last) {</span>
<span class="line-removed">165     while (true) {</span>
<span class="line-removed">166       PerRegionTable* fl = _free_list;</span>
<span class="line-removed">167       last-&gt;set_next(fl);</span>
<span class="line-removed">168       PerRegionTable* res = Atomic::cmpxchg(prt, &amp;_free_list, fl);</span>
<span class="line-removed">169       if (res == fl) {</span>
<span class="line-removed">170         return;</span>
<span class="line-removed">171       }</span>
<span class="line-removed">172     }</span>
<span class="line-removed">173     ShouldNotReachHere();</span>
<span class="line-removed">174   }</span>
<span class="line-removed">175 </span>
<span class="line-removed">176   static void free(PerRegionTable* prt) {</span>
<span class="line-removed">177     bulk_free(prt, prt);</span>
<span class="line-removed">178   }</span>
<span class="line-removed">179 </span>
<span class="line-removed">180   // Returns an initialized PerRegionTable instance.</span>
<span class="line-removed">181   static PerRegionTable* alloc(HeapRegion* hr) {</span>
<span class="line-removed">182     PerRegionTable* fl = _free_list;</span>
<span class="line-removed">183     while (fl != NULL) {</span>
<span class="line-removed">184       PerRegionTable* nxt = fl-&gt;next();</span>
<span class="line-removed">185       PerRegionTable* res = Atomic::cmpxchg(nxt, &amp;_free_list, fl);</span>
<span class="line-removed">186       if (res == fl) {</span>
<span class="line-removed">187         fl-&gt;init(hr, true);</span>
<span class="line-removed">188         return fl;</span>
<span class="line-removed">189       } else {</span>
<span class="line-removed">190         fl = _free_list;</span>
<span class="line-removed">191       }</span>
<span class="line-removed">192     }</span>
<span class="line-removed">193     assert(fl == NULL, &quot;Loop condition.&quot;);</span>
<span class="line-removed">194     return new PerRegionTable(hr);</span>
<span class="line-removed">195   }</span>
<span class="line-removed">196 </span>
<span class="line-removed">197   PerRegionTable* next() const { return _next; }</span>
<span class="line-removed">198   void set_next(PerRegionTable* next) { _next = next; }</span>
<span class="line-removed">199   PerRegionTable* prev() const { return _prev; }</span>
<span class="line-removed">200   void set_prev(PerRegionTable* prev) { _prev = prev; }</span>
<span class="line-removed">201 </span>
<span class="line-removed">202   // Accessor and Modification routines for the pointer for the</span>
<span class="line-removed">203   // singly linked collision list that links the PRTs within the</span>
<span class="line-removed">204   // OtherRegionsTable::_fine_grain_regions hash table.</span>
<span class="line-removed">205   //</span>
<span class="line-removed">206   // It might be useful to also make the collision list doubly linked</span>
<span class="line-removed">207   // to avoid iteration over the collisions list during scrubbing/deletion.</span>
<span class="line-removed">208   // OTOH there might not be many collisions.</span>
<span class="line-removed">209 </span>
<span class="line-removed">210   PerRegionTable* collision_list_next() const {</span>
<span class="line-removed">211     return _collision_list_next;</span>
<span class="line-removed">212   }</span>
<span class="line-removed">213 </span>
<span class="line-removed">214   void set_collision_list_next(PerRegionTable* next) {</span>
<span class="line-removed">215     _collision_list_next = next;</span>
<span class="line-removed">216   }</span>
<span class="line-removed">217 </span>
<span class="line-removed">218   PerRegionTable** collision_list_next_addr() {</span>
<span class="line-removed">219     return &amp;_collision_list_next;</span>
<span class="line-removed">220   }</span>
<span class="line-removed">221 </span>
<span class="line-removed">222   static size_t fl_mem_size() {</span>
<span class="line-removed">223     PerRegionTable* cur = _free_list;</span>
<span class="line-removed">224     size_t res = 0;</span>
<span class="line-removed">225     while (cur != NULL) {</span>
<span class="line-removed">226       res += cur-&gt;mem_size();</span>
<span class="line-removed">227       cur = cur-&gt;next();</span>
228     }
<span class="line-removed">229     return res;</span>
230   }
<span class="line-modified">231 </span>
<span class="line-modified">232   static void test_fl_mem_size();</span>
<span class="line-modified">233 };</span>
234 
235 PerRegionTable* volatile PerRegionTable::_free_list = NULL;
236 
237 size_t OtherRegionsTable::_max_fine_entries = 0;
238 size_t OtherRegionsTable::_mod_max_fine_entries_mask = 0;
239 size_t OtherRegionsTable::_fine_eviction_stride = 0;
240 size_t OtherRegionsTable::_fine_eviction_sample_size = 0;
241 
242 OtherRegionsTable::OtherRegionsTable(Mutex* m) :
243   _g1h(G1CollectedHeap::heap()),
244   _m(m),

245   _coarse_map(G1CollectedHeap::heap()-&gt;max_regions(), mtGC),
246   _n_coarse_entries(0),
247   _fine_grain_regions(NULL),
248   _n_fine_entries(0),
249   _first_all_fine_prts(NULL),
250   _last_all_fine_prts(NULL),
251   _fine_eviction_start(0),
252   _sparse_table()
253 {
254   typedef PerRegionTable* PerRegionTablePtr;
255 
256   if (_max_fine_entries == 0) {
257     assert(_mod_max_fine_entries_mask == 0, &quot;Both or none.&quot;);
258     size_t max_entries_log = (size_t)log2_long((jlong)G1RSetRegionEntries);
259     _max_fine_entries = (size_t)1 &lt;&lt; max_entries_log;
260     _mod_max_fine_entries_mask = _max_fine_entries - 1;
261 
262     assert(_fine_eviction_sample_size == 0
263            &amp;&amp; _fine_eviction_stride == 0, &quot;All init at same time.&quot;);
264     _fine_eviction_sample_size = MAX2((size_t)4, max_entries_log);
265     _fine_eviction_stride = _max_fine_entries / _fine_eviction_sample_size;
266   }
267 
<span class="line-modified">268   _fine_grain_regions = NEW_C_HEAP_ARRAY3(PerRegionTablePtr, _max_fine_entries,</span>
<span class="line-removed">269                         mtGC, CURRENT_PC, AllocFailStrategy::RETURN_NULL);</span>
<span class="line-removed">270 </span>
<span class="line-removed">271   if (_fine_grain_regions == NULL) {</span>
<span class="line-removed">272     vm_exit_out_of_memory(sizeof(void*)*_max_fine_entries, OOM_MALLOC_ERROR,</span>
<span class="line-removed">273                           &quot;Failed to allocate _fine_grain_entries.&quot;);</span>
<span class="line-removed">274   }</span>
<span class="line-removed">275 </span>
276   for (size_t i = 0; i &lt; _max_fine_entries; i++) {
277     _fine_grain_regions[i] = NULL;
278   }
279 }
280 
281 void OtherRegionsTable::link_to_all(PerRegionTable* prt) {
282   // We always append to the beginning of the list for convenience;
283   // the order of entries in this list does not matter.
284   if (_first_all_fine_prts != NULL) {
285     assert(_first_all_fine_prts-&gt;prev() == NULL, &quot;invariant&quot;);
286     _first_all_fine_prts-&gt;set_prev(prt);
287     prt-&gt;set_next(_first_all_fine_prts);
288   } else {
289     // this is the first element we insert. Adjust the &quot;last&quot; pointer
290     _last_all_fine_prts = prt;
291     assert(prt-&gt;next() == NULL, &quot;just checking&quot;);
292   }
293   // the new element is always the first element without a predecessor
294   prt-&gt;set_prev(NULL);
295   _first_all_fine_prts = prt;
</pre>
<hr />
<pre>
340 
341 CardIdx_t OtherRegionsTable::card_within_region(OopOrNarrowOopStar within_region, HeapRegion* hr) {
342   assert(hr-&gt;is_in_reserved(within_region),
343          &quot;HeapWord &quot; PTR_FORMAT &quot; is outside of region %u [&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT &quot;)&quot;,
344          p2i(within_region), hr-&gt;hrm_index(), p2i(hr-&gt;bottom()), p2i(hr-&gt;end()));
345   CardIdx_t result = (CardIdx_t)(pointer_delta((HeapWord*)within_region, hr-&gt;bottom()) &gt;&gt; (CardTable::card_shift - LogHeapWordSize));
346   return result;
347 }
348 
349 void OtherRegionsTable::add_reference(OopOrNarrowOopStar from, uint tid) {
350   // Note that this may be a continued H region.
351   HeapRegion* from_hr = _g1h-&gt;heap_region_containing(from);
352   RegionIdx_t from_hrm_ind = (RegionIdx_t) from_hr-&gt;hrm_index();
353 
354   // If the region is already coarsened, return.
355   if (_coarse_map.at(from_hrm_ind)) {
356     assert(contains_reference(from), &quot;We just found &quot; PTR_FORMAT &quot; in the Coarse table&quot;, p2i(from));
357     return;
358   }
359 

360   // Otherwise find a per-region table to add it to.
361   size_t ind = from_hrm_ind &amp; _mod_max_fine_entries_mask;
362   PerRegionTable* prt = find_region_table(ind, from_hr);
363   if (prt == NULL) {
<span class="line-modified">364     MutexLockerEx x(_m, Mutex::_no_safepoint_check_flag);</span>
365     // Confirm that it&#39;s really not there...
366     prt = find_region_table(ind, from_hr);
367     if (prt == NULL) {
368 
369       CardIdx_t card_index = card_within_region(from, from_hr);
370 
<span class="line-modified">371       if (_sparse_table.add_card(from_hrm_ind, card_index)) {</span>




372         assert(contains_reference_locked(from), &quot;We just added &quot; PTR_FORMAT &quot; to the Sparse table&quot;, p2i(from));
373         return;
374       }
375 
376       if (_n_fine_entries == _max_fine_entries) {
<span class="line-modified">377         prt = delete_region_table();</span>
378         // There is no need to clear the links to the &#39;all&#39; list here:
379         // prt will be reused immediately, i.e. remain in the &#39;all&#39; list.
380         prt-&gt;init(from_hr, false /* clear_links_to_all_list */);
381       } else {
382         prt = PerRegionTable::alloc(from_hr);
383         link_to_all(prt);
384       }
385 
386       PerRegionTable* first_prt = _fine_grain_regions[ind];
387       prt-&gt;set_collision_list_next(first_prt);
388       // The assignment into _fine_grain_regions allows the prt to
389       // start being used concurrently. In addition to
390       // collision_list_next which must be visible (else concurrent
391       // parsing of the list, if any, may fail to see other entries),
392       // the content of the prt must be visible (else for instance
393       // some mark bits may not yet seem cleared or a &#39;later&#39; update
394       // performed by a concurrent thread could be undone when the
395       // zeroing becomes visible). This requires store ordering.
<span class="line-modified">396       OrderAccess::release_store(&amp;_fine_grain_regions[ind], prt);</span>
397       _n_fine_entries++;
398 
<span class="line-modified">399       // Transfer from sparse to fine-grain.</span>

400       SparsePRTEntry *sprt_entry = _sparse_table.get_entry(from_hrm_ind);
401       assert(sprt_entry != NULL, &quot;There should have been an entry&quot;);
402       for (int i = 0; i &lt; sprt_entry-&gt;num_valid_cards(); i++) {
403         CardIdx_t c = sprt_entry-&gt;card(i);
404         prt-&gt;add_card(c);
405       }
406       // Now we can delete the sparse entry.
407       bool res = _sparse_table.delete_entry(from_hrm_ind);
408       assert(res, &quot;It should have been there.&quot;);
409     }
410     assert(prt != NULL &amp;&amp; prt-&gt;hr() == from_hr, &quot;consequence&quot;);
411   }
412   // Note that we can&#39;t assert &quot;prt-&gt;hr() == from_hr&quot;, because of the
413   // possibility of concurrent reuse.  But see head comment of
414   // OtherRegionsTable for why this is OK.
415   assert(prt != NULL, &quot;Inv&quot;);
416 
<span class="line-modified">417   prt-&gt;add_reference(from);</span>




418   assert(contains_reference(from), &quot;We just added &quot; PTR_FORMAT &quot; to the PRT (%d)&quot;, p2i(from), prt-&gt;contains_reference(from));
419 }
420 
421 PerRegionTable*
422 OtherRegionsTable::find_region_table(size_t ind, HeapRegion* hr) const {
423   assert(ind &lt; _max_fine_entries, &quot;Preconditions.&quot;);
424   PerRegionTable* prt = _fine_grain_regions[ind];
425   while (prt != NULL &amp;&amp; prt-&gt;hr() != hr) {
426     prt = prt-&gt;collision_list_next();
427   }
428   // Loop postcondition is the method postcondition.
429   return prt;
430 }
431 
432 jint OtherRegionsTable::_n_coarsenings = 0;
433 
<span class="line-modified">434 PerRegionTable* OtherRegionsTable::delete_region_table() {</span>
435   assert(_m-&gt;owned_by_self(), &quot;Precondition&quot;);
436   assert(_n_fine_entries == _max_fine_entries, &quot;Precondition&quot;);
437   PerRegionTable* max = NULL;
438   jint max_occ = 0;
439   PerRegionTable** max_prev = NULL;
440   size_t max_ind;
441 
442   size_t i = _fine_eviction_start;
443   for (size_t k = 0; k &lt; _fine_eviction_sample_size; k++) {
444     size_t ii = i;
445     // Make sure we get a non-NULL sample.
446     while (_fine_grain_regions[ii] == NULL) {
447       ii++;
448       if (ii == _max_fine_entries) ii = 0;
449       guarantee(ii != i, &quot;We must find one.&quot;);
450     }
451     PerRegionTable** prev = &amp;_fine_grain_regions[ii];
452     PerRegionTable* cur = *prev;
453     while (cur != NULL) {
454       jint cur_occ = cur-&gt;occupied();
</pre>
<hr />
<pre>
464     i = i + _fine_eviction_stride;
465     if (i &gt;= _n_fine_entries) i = i - _n_fine_entries;
466   }
467 
468   _fine_eviction_start++;
469 
470   if (_fine_eviction_start &gt;= _n_fine_entries) {
471     _fine_eviction_start -= _n_fine_entries;
472   }
473 
474   guarantee(max != NULL, &quot;Since _n_fine_entries &gt; 0&quot;);
475   guarantee(max_prev != NULL, &quot;Since max != NULL.&quot;);
476 
477   // Set the corresponding coarse bit.
478   size_t max_hrm_index = (size_t) max-&gt;hr()-&gt;hrm_index();
479   if (!_coarse_map.at(max_hrm_index)) {
480     _coarse_map.at_put(max_hrm_index, true);
481     _n_coarse_entries++;
482   }
483 

484   // Unsplice.
485   *max_prev = max-&gt;collision_list_next();
486   Atomic::inc(&amp;_n_coarsenings);
487   _n_fine_entries--;
488   return max;
489 }
490 
491 bool OtherRegionsTable::occupancy_less_or_equal_than(size_t limit) const {
<span class="line-modified">492   if (limit &lt;= (size_t)G1RSetSparseRegionEntries) {</span>
<span class="line-removed">493     return occ_coarse() == 0 &amp;&amp; _first_all_fine_prts == NULL &amp;&amp; occ_sparse() &lt;= limit;</span>
<span class="line-removed">494   } else {</span>
<span class="line-removed">495     // Current uses of this method may only use values less than G1RSetSparseRegionEntries</span>
<span class="line-removed">496     // for the limit. The solution, comparing against occupied() would be too slow</span>
<span class="line-removed">497     // at this time.</span>
<span class="line-removed">498     Unimplemented();</span>
<span class="line-removed">499     return false;</span>
<span class="line-removed">500   }</span>
501 }
502 
503 bool OtherRegionsTable::is_empty() const {
<span class="line-modified">504   return occ_sparse() == 0 &amp;&amp; occ_coarse() == 0 &amp;&amp; _first_all_fine_prts == NULL;</span>
505 }
506 
507 size_t OtherRegionsTable::occupied() const {
<span class="line-modified">508   size_t sum = occ_fine();</span>
<span class="line-removed">509   sum += occ_sparse();</span>
<span class="line-removed">510   sum += occ_coarse();</span>
<span class="line-removed">511   return sum;</span>
<span class="line-removed">512 }</span>
<span class="line-removed">513 </span>
<span class="line-removed">514 size_t OtherRegionsTable::occ_fine() const {</span>
<span class="line-removed">515   size_t sum = 0;</span>
<span class="line-removed">516 </span>
<span class="line-removed">517   size_t num = 0;</span>
<span class="line-removed">518   PerRegionTable * cur = _first_all_fine_prts;</span>
<span class="line-removed">519   while (cur != NULL) {</span>
<span class="line-removed">520     sum += cur-&gt;occupied();</span>
<span class="line-removed">521     cur = cur-&gt;next();</span>
<span class="line-removed">522     num++;</span>
<span class="line-removed">523   }</span>
<span class="line-removed">524   guarantee(num == _n_fine_entries, &quot;just checking&quot;);</span>
<span class="line-removed">525   return sum;</span>
<span class="line-removed">526 }</span>
<span class="line-removed">527 </span>
<span class="line-removed">528 size_t OtherRegionsTable::occ_coarse() const {</span>
<span class="line-removed">529   return (_n_coarse_entries * HeapRegion::CardsPerRegion);</span>
<span class="line-removed">530 }</span>
<span class="line-removed">531 </span>
<span class="line-removed">532 size_t OtherRegionsTable::occ_sparse() const {</span>
<span class="line-removed">533   return _sparse_table.occupied();</span>
534 }
535 
536 size_t OtherRegionsTable::mem_size() const {
537   size_t sum = 0;
538   // all PRTs are of the same size so it is sufficient to query only one of them.
539   if (_first_all_fine_prts != NULL) {
540     assert(_last_all_fine_prts != NULL &amp;&amp;
541       _first_all_fine_prts-&gt;mem_size() == _last_all_fine_prts-&gt;mem_size(), &quot;check that mem_size() is constant&quot;);
542     sum += _first_all_fine_prts-&gt;mem_size() * _n_fine_entries;
543   }
544   sum += (sizeof(PerRegionTable*) * _max_fine_entries);
545   sum += (_coarse_map.size_in_words() * HeapWordSize);
546   sum += (_sparse_table.mem_size());
547   sum += sizeof(OtherRegionsTable) - sizeof(_sparse_table); // Avoid double counting above.
548   return sum;
549 }
550 
551 size_t OtherRegionsTable::static_mem_size() {
552   return G1FromCardCache::static_mem_size();
553 }
</pre>
<hr />
<pre>
556   return PerRegionTable::fl_mem_size();
557 }
558 
559 void OtherRegionsTable::clear() {
560   // if there are no entries, skip this step
561   if (_first_all_fine_prts != NULL) {
562     guarantee(_first_all_fine_prts != NULL &amp;&amp; _last_all_fine_prts != NULL, &quot;just checking&quot;);
563     PerRegionTable::bulk_free(_first_all_fine_prts, _last_all_fine_prts);
564     memset(_fine_grain_regions, 0, _max_fine_entries * sizeof(_fine_grain_regions[0]));
565   } else {
566     guarantee(_first_all_fine_prts == NULL &amp;&amp; _last_all_fine_prts == NULL, &quot;just checking&quot;);
567   }
568 
569   _first_all_fine_prts = _last_all_fine_prts = NULL;
570   _sparse_table.clear();
571   if (_n_coarse_entries &gt; 0) {
572     _coarse_map.clear();
573   }
574   _n_fine_entries = 0;
575   _n_coarse_entries = 0;


576 }
577 
578 bool OtherRegionsTable::contains_reference(OopOrNarrowOopStar from) const {
579   // Cast away const in this case.
<span class="line-modified">580   MutexLockerEx x((Mutex*)_m, Mutex::_no_safepoint_check_flag);</span>
581   return contains_reference_locked(from);
582 }
583 
584 bool OtherRegionsTable::contains_reference_locked(OopOrNarrowOopStar from) const {
585   HeapRegion* hr = _g1h-&gt;heap_region_containing(from);
586   RegionIdx_t hr_ind = (RegionIdx_t) hr-&gt;hrm_index();
587   // Is this region in the coarse map?
588   if (_coarse_map.at(hr_ind)) return true;
589 
590   PerRegionTable* prt = find_region_table(hr_ind &amp; _mod_max_fine_entries_mask,
591                                           hr);
592   if (prt != NULL) {
593     return prt-&gt;contains_reference(from);
594 
595   } else {
596     CardIdx_t card_index = card_within_region(from, hr);
597     return _sparse_table.contains_card(hr_ind, card_index);
598   }
599 }
600 
601 HeapRegionRemSet::HeapRegionRemSet(G1BlockOffsetTable* bot,
602                                    HeapRegion* hr)
603   : _bot(bot),
604     _code_roots(),
<span class="line-modified">605     _m(Mutex::leaf, FormatBuffer&lt;128&gt;(&quot;HeapRegionRemSet lock #%u&quot;, hr-&gt;hrm_index()), true, Monitor::_safepoint_check_never),</span>
606     _other_regions(&amp;_m),
607     _hr(hr),
608     _state(Untracked)
609 {
610 }
611 
612 void HeapRegionRemSet::clear_fcc() {
613   G1FromCardCache::clear(_hr-&gt;hrm_index());
614 }
615 
616 void HeapRegionRemSet::setup_remset_size() {
<span class="line-removed">617   // Setup sparse and fine-grain tables sizes.</span>
<span class="line-removed">618   // table_size = base * (log(region_size / 1M) + 1)</span>
619   const int LOG_M = 20;
<span class="line-modified">620   int region_size_log_mb = MAX2(HeapRegion::LogOfHRGrainBytes - LOG_M, 0);</span>


621   if (FLAG_IS_DEFAULT(G1RSetSparseRegionEntries)) {
<span class="line-modified">622     G1RSetSparseRegionEntries = G1RSetSparseRegionEntriesBase * (region_size_log_mb + 1);</span>
623   }
624   if (FLAG_IS_DEFAULT(G1RSetRegionEntries)) {
625     G1RSetRegionEntries = G1RSetRegionEntriesBase * (region_size_log_mb + 1);
626   }
627   guarantee(G1RSetSparseRegionEntries &gt; 0 &amp;&amp; G1RSetRegionEntries &gt; 0 , &quot;Sanity&quot;);
628 }
629 
630 void HeapRegionRemSet::clear(bool only_cardset) {
<span class="line-modified">631   MutexLockerEx x(&amp;_m, Mutex::_no_safepoint_check_flag);</span>
632   clear_locked(only_cardset);
633 }
634 
635 void HeapRegionRemSet::clear_locked(bool only_cardset) {
636   if (!only_cardset) {
637     _code_roots.clear();
638   }
639   clear_fcc();
640   _other_regions.clear();
641   set_state_empty();
<span class="line-modified">642   assert(occupied_locked() == 0, &quot;Should be clear.&quot;);</span>
643 }
644 
645 // Code roots support
646 //
647 // The code root set is protected by two separate locking schemes
648 // When at safepoint the per-hrrs lock must be held during modifications
649 // except when doing a full gc.
650 // When not at safepoint the CodeCache_lock must be held during modifications.
651 // When concurrent readers access the contains() function
652 // (during the evacuation phase) no removals are allowed.
653 
654 void HeapRegionRemSet::add_strong_code_root(nmethod* nm) {
655   assert(nm != NULL, &quot;sanity&quot;);
656   assert((!CodeCache_lock-&gt;owned_by_self() || SafepointSynchronize::is_at_safepoint()),
657           &quot;should call add_strong_code_root_locked instead. CodeCache_lock-&gt;owned_by_self(): %s, is_at_safepoint(): %s&quot;,
658           BOOL_TO_STR(CodeCache_lock-&gt;owned_by_self()), BOOL_TO_STR(SafepointSynchronize::is_at_safepoint()));
659   // Optimistic unlocked contains-check
660   if (!_code_roots.contains(nm)) {
<span class="line-modified">661     MutexLockerEx ml(&amp;_m, Mutex::_no_safepoint_check_flag);</span>
662     add_strong_code_root_locked(nm);
663   }
664 }
665 
666 void HeapRegionRemSet::add_strong_code_root_locked(nmethod* nm) {
667   assert(nm != NULL, &quot;sanity&quot;);
668   assert((CodeCache_lock-&gt;owned_by_self() ||
669          (SafepointSynchronize::is_at_safepoint() &amp;&amp;
670           (_m.owned_by_self() || Thread::current()-&gt;is_VM_thread()))),
671           &quot;not safely locked. CodeCache_lock-&gt;owned_by_self(): %s, is_at_safepoint(): %s, _m.owned_by_self(): %s, Thread::current()-&gt;is_VM_thread(): %s&quot;,
672           BOOL_TO_STR(CodeCache_lock-&gt;owned_by_self()), BOOL_TO_STR(SafepointSynchronize::is_at_safepoint()),
673           BOOL_TO_STR(_m.owned_by_self()), BOOL_TO_STR(Thread::current()-&gt;is_VM_thread()));
674   _code_roots.add(nm);
675 }
676 
677 void HeapRegionRemSet::remove_strong_code_root(nmethod* nm) {
678   assert(nm != NULL, &quot;sanity&quot;);
679   assert_locked_or_safepoint(CodeCache_lock);
680 
<span class="line-modified">681   MutexLockerEx ml(CodeCache_lock-&gt;owned_by_self() ? NULL : &amp;_m, Mutex::_no_safepoint_check_flag);</span>
682   _code_roots.remove(nm);
683 
684   // Check that there were no duplicates
685   guarantee(!_code_roots.contains(nm), &quot;duplicate entry found&quot;);
686 }
687 
688 void HeapRegionRemSet::strong_code_roots_do(CodeBlobClosure* blk) const {
689   _code_roots.nmethods_do(blk);
690 }
691 
692 void HeapRegionRemSet::clean_strong_code_roots(HeapRegion* hr) {
693   _code_roots.clean(hr);
694 }
695 
696 size_t HeapRegionRemSet::strong_code_roots_mem_size() {
697   return _code_roots.mem_size();
698 }
<span class="line-removed">699 </span>
<span class="line-removed">700 HeapRegionRemSetIterator:: HeapRegionRemSetIterator(HeapRegionRemSet* hrrs) :</span>
<span class="line-removed">701   _hrrs(hrrs),</span>
<span class="line-removed">702   _coarse_map(&amp;hrrs-&gt;_other_regions._coarse_map),</span>
<span class="line-removed">703   _bot(hrrs-&gt;_bot),</span>
<span class="line-removed">704   _g1h(G1CollectedHeap::heap()),</span>
<span class="line-removed">705   _n_yielded_fine(0),</span>
<span class="line-removed">706   _n_yielded_coarse(0),</span>
<span class="line-removed">707   _n_yielded_sparse(0),</span>
<span class="line-removed">708   _is(Sparse),</span>
<span class="line-removed">709   _cur_region_card_offset(0),</span>
<span class="line-removed">710   // Set these values so that we increment to the first region.</span>
<span class="line-removed">711   _coarse_cur_region_index(-1),</span>
<span class="line-removed">712   _coarse_cur_region_cur_card(HeapRegion::CardsPerRegion-1),</span>
<span class="line-removed">713   _fine_cur_prt(NULL),</span>
<span class="line-removed">714   _cur_card_in_prt(HeapRegion::CardsPerRegion),</span>
<span class="line-removed">715   _sparse_iter(&amp;hrrs-&gt;_other_regions._sparse_table) {}</span>
<span class="line-removed">716 </span>
<span class="line-removed">717 bool HeapRegionRemSetIterator::coarse_has_next(size_t&amp; card_index) {</span>
<span class="line-removed">718   if (_hrrs-&gt;_other_regions._n_coarse_entries == 0) return false;</span>
<span class="line-removed">719   // Go to the next card.</span>
<span class="line-removed">720   _coarse_cur_region_cur_card++;</span>
<span class="line-removed">721   // Was the last the last card in the current region?</span>
<span class="line-removed">722   if (_coarse_cur_region_cur_card == HeapRegion::CardsPerRegion) {</span>
<span class="line-removed">723     // Yes: find the next region.  This may leave _coarse_cur_region_index</span>
<span class="line-removed">724     // Set to the last index, in which case there are no more coarse</span>
<span class="line-removed">725     // regions.</span>
<span class="line-removed">726     _coarse_cur_region_index =</span>
<span class="line-removed">727       (int) _coarse_map-&gt;get_next_one_offset(_coarse_cur_region_index + 1);</span>
<span class="line-removed">728     if ((size_t)_coarse_cur_region_index &lt; _coarse_map-&gt;size()) {</span>
<span class="line-removed">729       _coarse_cur_region_cur_card = 0;</span>
<span class="line-removed">730       HeapWord* r_bot =</span>
<span class="line-removed">731         _g1h-&gt;region_at((uint) _coarse_cur_region_index)-&gt;bottom();</span>
<span class="line-removed">732       _cur_region_card_offset = _bot-&gt;index_for_raw(r_bot);</span>
<span class="line-removed">733     } else {</span>
<span class="line-removed">734       return false;</span>
<span class="line-removed">735     }</span>
<span class="line-removed">736   }</span>
<span class="line-removed">737   // If we didn&#39;t return false above, then we can yield a card.</span>
<span class="line-removed">738   card_index = _cur_region_card_offset + _coarse_cur_region_cur_card;</span>
<span class="line-removed">739   return true;</span>
<span class="line-removed">740 }</span>
<span class="line-removed">741 </span>
<span class="line-removed">742 bool HeapRegionRemSetIterator::fine_has_next(size_t&amp; card_index) {</span>
<span class="line-removed">743   if (fine_has_next()) {</span>
<span class="line-removed">744     _cur_card_in_prt =</span>
<span class="line-removed">745       _fine_cur_prt-&gt;_bm.get_next_one_offset(_cur_card_in_prt + 1);</span>
<span class="line-removed">746   }</span>
<span class="line-removed">747   if (_cur_card_in_prt == HeapRegion::CardsPerRegion) {</span>
<span class="line-removed">748     // _fine_cur_prt may still be NULL in case if there are not PRTs at all for</span>
<span class="line-removed">749     // the remembered set.</span>
<span class="line-removed">750     if (_fine_cur_prt == NULL || _fine_cur_prt-&gt;next() == NULL) {</span>
<span class="line-removed">751       return false;</span>
<span class="line-removed">752     }</span>
<span class="line-removed">753     PerRegionTable* next_prt = _fine_cur_prt-&gt;next();</span>
<span class="line-removed">754     switch_to_prt(next_prt);</span>
<span class="line-removed">755     _cur_card_in_prt = _fine_cur_prt-&gt;_bm.get_next_one_offset(_cur_card_in_prt + 1);</span>
<span class="line-removed">756   }</span>
<span class="line-removed">757 </span>
<span class="line-removed">758   card_index = _cur_region_card_offset + _cur_card_in_prt;</span>
<span class="line-removed">759   guarantee(_cur_card_in_prt &lt; HeapRegion::CardsPerRegion,</span>
<span class="line-removed">760             &quot;Card index &quot; SIZE_FORMAT &quot; must be within the region&quot;, _cur_card_in_prt);</span>
<span class="line-removed">761   return true;</span>
<span class="line-removed">762 }</span>
<span class="line-removed">763 </span>
<span class="line-removed">764 bool HeapRegionRemSetIterator::fine_has_next() {</span>
<span class="line-removed">765   return _cur_card_in_prt != HeapRegion::CardsPerRegion;</span>
<span class="line-removed">766 }</span>
<span class="line-removed">767 </span>
<span class="line-removed">768 void HeapRegionRemSetIterator::switch_to_prt(PerRegionTable* prt) {</span>
<span class="line-removed">769   assert(prt != NULL, &quot;Cannot switch to NULL prt&quot;);</span>
<span class="line-removed">770   _fine_cur_prt = prt;</span>
<span class="line-removed">771 </span>
<span class="line-removed">772   HeapWord* r_bot = _fine_cur_prt-&gt;hr()-&gt;bottom();</span>
<span class="line-removed">773   _cur_region_card_offset = _bot-&gt;index_for_raw(r_bot);</span>
<span class="line-removed">774 </span>
<span class="line-removed">775   // The bitmap scan for the PRT always scans from _cur_region_cur_card + 1.</span>
<span class="line-removed">776   // To avoid special-casing this start case, and not miss the first bitmap</span>
<span class="line-removed">777   // entry, initialize _cur_region_cur_card with -1 instead of 0.</span>
<span class="line-removed">778   _cur_card_in_prt = (size_t)-1;</span>
<span class="line-removed">779 }</span>
<span class="line-removed">780 </span>
<span class="line-removed">781 bool HeapRegionRemSetIterator::has_next(size_t&amp; card_index) {</span>
<span class="line-removed">782   switch (_is) {</span>
<span class="line-removed">783   case Sparse: {</span>
<span class="line-removed">784     if (_sparse_iter.has_next(card_index)) {</span>
<span class="line-removed">785       _n_yielded_sparse++;</span>
<span class="line-removed">786       return true;</span>
<span class="line-removed">787     }</span>
<span class="line-removed">788     // Otherwise, deliberate fall-through</span>
<span class="line-removed">789     _is = Fine;</span>
<span class="line-removed">790     PerRegionTable* initial_fine_prt = _hrrs-&gt;_other_regions._first_all_fine_prts;</span>
<span class="line-removed">791     if (initial_fine_prt != NULL) {</span>
<span class="line-removed">792       switch_to_prt(_hrrs-&gt;_other_regions._first_all_fine_prts);</span>
<span class="line-removed">793     }</span>
<span class="line-removed">794   }</span>
<span class="line-removed">795   case Fine:</span>
<span class="line-removed">796     if (fine_has_next(card_index)) {</span>
<span class="line-removed">797       _n_yielded_fine++;</span>
<span class="line-removed">798       return true;</span>
<span class="line-removed">799     }</span>
<span class="line-removed">800     // Otherwise, deliberate fall-through</span>
<span class="line-removed">801     _is = Coarse;</span>
<span class="line-removed">802   case Coarse:</span>
<span class="line-removed">803     if (coarse_has_next(card_index)) {</span>
<span class="line-removed">804       _n_yielded_coarse++;</span>
<span class="line-removed">805       return true;</span>
<span class="line-removed">806     }</span>
<span class="line-removed">807     // Otherwise...</span>
<span class="line-removed">808     break;</span>
<span class="line-removed">809   }</span>
<span class="line-removed">810   return false;</span>
<span class="line-removed">811 }</span>
<span class="line-removed">812 </span>
<span class="line-removed">813 #ifndef PRODUCT</span>
<span class="line-removed">814 void HeapRegionRemSet::test() {</span>
<span class="line-removed">815   os::sleep(Thread::current(), (jlong)5000, false);</span>
<span class="line-removed">816   G1CollectedHeap* g1h = G1CollectedHeap::heap();</span>
<span class="line-removed">817 </span>
<span class="line-removed">818   // Run with &quot;-XX:G1LogRSetRegionEntries=2&quot;, so that 1 and 5 end up in same</span>
<span class="line-removed">819   // hash bucket.</span>
<span class="line-removed">820   HeapRegion* hr0 = g1h-&gt;region_at(0);</span>
<span class="line-removed">821   HeapRegion* hr1 = g1h-&gt;region_at(1);</span>
<span class="line-removed">822   HeapRegion* hr2 = g1h-&gt;region_at(5);</span>
<span class="line-removed">823   HeapRegion* hr3 = g1h-&gt;region_at(6);</span>
<span class="line-removed">824   HeapRegion* hr4 = g1h-&gt;region_at(7);</span>
<span class="line-removed">825   HeapRegion* hr5 = g1h-&gt;region_at(8);</span>
<span class="line-removed">826 </span>
<span class="line-removed">827   HeapWord* hr1_start = hr1-&gt;bottom();</span>
<span class="line-removed">828   HeapWord* hr1_mid = hr1_start + HeapRegion::GrainWords/2;</span>
<span class="line-removed">829   HeapWord* hr1_last = hr1-&gt;end() - 1;</span>
<span class="line-removed">830 </span>
<span class="line-removed">831   HeapWord* hr2_start = hr2-&gt;bottom();</span>
<span class="line-removed">832   HeapWord* hr2_mid = hr2_start + HeapRegion::GrainWords/2;</span>
<span class="line-removed">833   HeapWord* hr2_last = hr2-&gt;end() - 1;</span>
<span class="line-removed">834 </span>
<span class="line-removed">835   HeapWord* hr3_start = hr3-&gt;bottom();</span>
<span class="line-removed">836   HeapWord* hr3_mid = hr3_start + HeapRegion::GrainWords/2;</span>
<span class="line-removed">837   HeapWord* hr3_last = hr3-&gt;end() - 1;</span>
<span class="line-removed">838 </span>
<span class="line-removed">839   HeapRegionRemSet* hrrs = hr0-&gt;rem_set();</span>
<span class="line-removed">840 </span>
<span class="line-removed">841   // Make three references from region 0x101...</span>
<span class="line-removed">842   hrrs-&gt;add_reference((OopOrNarrowOopStar)hr1_start);</span>
<span class="line-removed">843   hrrs-&gt;add_reference((OopOrNarrowOopStar)hr1_mid);</span>
<span class="line-removed">844   hrrs-&gt;add_reference((OopOrNarrowOopStar)hr1_last);</span>
<span class="line-removed">845 </span>
<span class="line-removed">846   hrrs-&gt;add_reference((OopOrNarrowOopStar)hr2_start);</span>
<span class="line-removed">847   hrrs-&gt;add_reference((OopOrNarrowOopStar)hr2_mid);</span>
<span class="line-removed">848   hrrs-&gt;add_reference((OopOrNarrowOopStar)hr2_last);</span>
<span class="line-removed">849 </span>
<span class="line-removed">850   hrrs-&gt;add_reference((OopOrNarrowOopStar)hr3_start);</span>
<span class="line-removed">851   hrrs-&gt;add_reference((OopOrNarrowOopStar)hr3_mid);</span>
<span class="line-removed">852   hrrs-&gt;add_reference((OopOrNarrowOopStar)hr3_last);</span>
<span class="line-removed">853 </span>
<span class="line-removed">854   // Now cause a coarsening.</span>
<span class="line-removed">855   hrrs-&gt;add_reference((OopOrNarrowOopStar)hr4-&gt;bottom());</span>
<span class="line-removed">856   hrrs-&gt;add_reference((OopOrNarrowOopStar)hr5-&gt;bottom());</span>
<span class="line-removed">857 </span>
<span class="line-removed">858   // Now, does iteration yield these three?</span>
<span class="line-removed">859   HeapRegionRemSetIterator iter(hrrs);</span>
<span class="line-removed">860   size_t sum = 0;</span>
<span class="line-removed">861   size_t card_index;</span>
<span class="line-removed">862   while (iter.has_next(card_index)) {</span>
<span class="line-removed">863     HeapWord* card_start = g1h-&gt;bot()-&gt;address_for_index(card_index);</span>
<span class="line-removed">864     tty-&gt;print_cr(&quot;  Card &quot; PTR_FORMAT &quot;.&quot;, p2i(card_start));</span>
<span class="line-removed">865     sum++;</span>
<span class="line-removed">866   }</span>
<span class="line-removed">867   guarantee(sum == 11 - 3 + 2048, &quot;Failure&quot;);</span>
<span class="line-removed">868   guarantee(sum == hrrs-&gt;occupied(), &quot;Failure&quot;);</span>
<span class="line-removed">869 }</span>
<span class="line-removed">870 #endif</span>
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2001, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;gc/g1/g1BlockOffsetTable.inline.hpp&quot;
 27 #include &quot;gc/g1/g1CollectedHeap.inline.hpp&quot;
 28 #include &quot;gc/g1/g1ConcurrentRefine.hpp&quot;
 29 #include &quot;gc/g1/heapRegionManager.inline.hpp&quot;
<span class="line-modified"> 30 #include &quot;gc/g1/heapRegionRemSet.inline.hpp&quot;</span>
<span class="line-modified"> 31 #include &quot;gc/g1/sparsePRT.inline.hpp&quot;</span>
 32 #include &quot;memory/allocation.hpp&quot;
 33 #include &quot;memory/padded.inline.hpp&quot;
 34 #include &quot;oops/oop.inline.hpp&quot;
 35 #include &quot;runtime/atomic.hpp&quot;
 36 #include &quot;utilities/bitMap.inline.hpp&quot;
 37 #include &quot;utilities/debug.hpp&quot;
 38 #include &quot;utilities/formatBuffer.hpp&quot;
 39 #include &quot;utilities/globalDefinitions.hpp&quot;
 40 #include &quot;utilities/growableArray.hpp&quot;
 41 
 42 const char* HeapRegionRemSet::_state_strings[] =  {&quot;Untracked&quot;, &quot;Updating&quot;, &quot;Complete&quot;};
 43 const char* HeapRegionRemSet::_short_state_strings[] =  {&quot;UNTRA&quot;, &quot;UPDAT&quot;, &quot;CMPLT&quot;};
 44 
<span class="line-modified"> 45 PerRegionTable* PerRegionTable::alloc(HeapRegion* hr) {</span>
<span class="line-modified"> 46   PerRegionTable* fl = _free_list;</span>
<span class="line-modified"> 47   while (fl != NULL) {</span>
<span class="line-modified"> 48     PerRegionTable* nxt = fl-&gt;next();</span>
<span class="line-modified"> 49     PerRegionTable* res = Atomic::cmpxchg(&amp;_free_list, fl, nxt);</span>
<span class="line-modified"> 50     if (res == fl) {</span>
<span class="line-modified"> 51       fl-&gt;init(hr, true);</span>
<span class="line-modified"> 52       return fl;</span>
<span class="line-modified"> 53     } else {</span>
<span class="line-modified"> 54       fl = _free_list;</span>













































































































































































 55     }

 56   }
<span class="line-modified"> 57   assert(fl == NULL, &quot;Loop condition.&quot;);</span>
<span class="line-modified"> 58   return new PerRegionTable(hr);</span>
<span class="line-modified"> 59 }</span>
 60 
 61 PerRegionTable* volatile PerRegionTable::_free_list = NULL;
 62 
 63 size_t OtherRegionsTable::_max_fine_entries = 0;
 64 size_t OtherRegionsTable::_mod_max_fine_entries_mask = 0;
 65 size_t OtherRegionsTable::_fine_eviction_stride = 0;
 66 size_t OtherRegionsTable::_fine_eviction_sample_size = 0;
 67 
 68 OtherRegionsTable::OtherRegionsTable(Mutex* m) :
 69   _g1h(G1CollectedHeap::heap()),
 70   _m(m),
<span class="line-added"> 71   _num_occupied(0),</span>
 72   _coarse_map(G1CollectedHeap::heap()-&gt;max_regions(), mtGC),
 73   _n_coarse_entries(0),
 74   _fine_grain_regions(NULL),
 75   _n_fine_entries(0),
 76   _first_all_fine_prts(NULL),
 77   _last_all_fine_prts(NULL),
 78   _fine_eviction_start(0),
 79   _sparse_table()
 80 {
 81   typedef PerRegionTable* PerRegionTablePtr;
 82 
 83   if (_max_fine_entries == 0) {
 84     assert(_mod_max_fine_entries_mask == 0, &quot;Both or none.&quot;);
 85     size_t max_entries_log = (size_t)log2_long((jlong)G1RSetRegionEntries);
 86     _max_fine_entries = (size_t)1 &lt;&lt; max_entries_log;
 87     _mod_max_fine_entries_mask = _max_fine_entries - 1;
 88 
 89     assert(_fine_eviction_sample_size == 0
 90            &amp;&amp; _fine_eviction_stride == 0, &quot;All init at same time.&quot;);
 91     _fine_eviction_sample_size = MAX2((size_t)4, max_entries_log);
 92     _fine_eviction_stride = _max_fine_entries / _fine_eviction_sample_size;
 93   }
 94 
<span class="line-modified"> 95   _fine_grain_regions = NEW_C_HEAP_ARRAY(PerRegionTablePtr, _max_fine_entries, mtGC);</span>







 96   for (size_t i = 0; i &lt; _max_fine_entries; i++) {
 97     _fine_grain_regions[i] = NULL;
 98   }
 99 }
100 
101 void OtherRegionsTable::link_to_all(PerRegionTable* prt) {
102   // We always append to the beginning of the list for convenience;
103   // the order of entries in this list does not matter.
104   if (_first_all_fine_prts != NULL) {
105     assert(_first_all_fine_prts-&gt;prev() == NULL, &quot;invariant&quot;);
106     _first_all_fine_prts-&gt;set_prev(prt);
107     prt-&gt;set_next(_first_all_fine_prts);
108   } else {
109     // this is the first element we insert. Adjust the &quot;last&quot; pointer
110     _last_all_fine_prts = prt;
111     assert(prt-&gt;next() == NULL, &quot;just checking&quot;);
112   }
113   // the new element is always the first element without a predecessor
114   prt-&gt;set_prev(NULL);
115   _first_all_fine_prts = prt;
</pre>
<hr />
<pre>
160 
161 CardIdx_t OtherRegionsTable::card_within_region(OopOrNarrowOopStar within_region, HeapRegion* hr) {
162   assert(hr-&gt;is_in_reserved(within_region),
163          &quot;HeapWord &quot; PTR_FORMAT &quot; is outside of region %u [&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT &quot;)&quot;,
164          p2i(within_region), hr-&gt;hrm_index(), p2i(hr-&gt;bottom()), p2i(hr-&gt;end()));
165   CardIdx_t result = (CardIdx_t)(pointer_delta((HeapWord*)within_region, hr-&gt;bottom()) &gt;&gt; (CardTable::card_shift - LogHeapWordSize));
166   return result;
167 }
168 
169 void OtherRegionsTable::add_reference(OopOrNarrowOopStar from, uint tid) {
170   // Note that this may be a continued H region.
171   HeapRegion* from_hr = _g1h-&gt;heap_region_containing(from);
172   RegionIdx_t from_hrm_ind = (RegionIdx_t) from_hr-&gt;hrm_index();
173 
174   // If the region is already coarsened, return.
175   if (_coarse_map.at(from_hrm_ind)) {
176     assert(contains_reference(from), &quot;We just found &quot; PTR_FORMAT &quot; in the Coarse table&quot;, p2i(from));
177     return;
178   }
179 
<span class="line-added">180   size_t num_added_by_coarsening = 0;</span>
181   // Otherwise find a per-region table to add it to.
182   size_t ind = from_hrm_ind &amp; _mod_max_fine_entries_mask;
183   PerRegionTable* prt = find_region_table(ind, from_hr);
184   if (prt == NULL) {
<span class="line-modified">185     MutexLocker x(_m, Mutex::_no_safepoint_check_flag);</span>
186     // Confirm that it&#39;s really not there...
187     prt = find_region_table(ind, from_hr);
188     if (prt == NULL) {
189 
190       CardIdx_t card_index = card_within_region(from, from_hr);
191 
<span class="line-modified">192       SparsePRT::AddCardResult result = _sparse_table.add_card(from_hrm_ind, card_index);</span>
<span class="line-added">193       if (result != SparsePRT::overflow) {</span>
<span class="line-added">194         if (result == SparsePRT::added) {</span>
<span class="line-added">195           Atomic::inc(&amp;_num_occupied, memory_order_relaxed);</span>
<span class="line-added">196         }</span>
197         assert(contains_reference_locked(from), &quot;We just added &quot; PTR_FORMAT &quot; to the Sparse table&quot;, p2i(from));
198         return;
199       }
200 
201       if (_n_fine_entries == _max_fine_entries) {
<span class="line-modified">202         prt = delete_region_table(num_added_by_coarsening);</span>
203         // There is no need to clear the links to the &#39;all&#39; list here:
204         // prt will be reused immediately, i.e. remain in the &#39;all&#39; list.
205         prt-&gt;init(from_hr, false /* clear_links_to_all_list */);
206       } else {
207         prt = PerRegionTable::alloc(from_hr);
208         link_to_all(prt);
209       }
210 
211       PerRegionTable* first_prt = _fine_grain_regions[ind];
212       prt-&gt;set_collision_list_next(first_prt);
213       // The assignment into _fine_grain_regions allows the prt to
214       // start being used concurrently. In addition to
215       // collision_list_next which must be visible (else concurrent
216       // parsing of the list, if any, may fail to see other entries),
217       // the content of the prt must be visible (else for instance
218       // some mark bits may not yet seem cleared or a &#39;later&#39; update
219       // performed by a concurrent thread could be undone when the
220       // zeroing becomes visible). This requires store ordering.
<span class="line-modified">221       Atomic::release_store(&amp;_fine_grain_regions[ind], prt);</span>
222       _n_fine_entries++;
223 
<span class="line-modified">224       // Transfer from sparse to fine-grain. The cards from the sparse table</span>
<span class="line-added">225       // were already added to the total in _num_occupied.</span>
226       SparsePRTEntry *sprt_entry = _sparse_table.get_entry(from_hrm_ind);
227       assert(sprt_entry != NULL, &quot;There should have been an entry&quot;);
228       for (int i = 0; i &lt; sprt_entry-&gt;num_valid_cards(); i++) {
229         CardIdx_t c = sprt_entry-&gt;card(i);
230         prt-&gt;add_card(c);
231       }
232       // Now we can delete the sparse entry.
233       bool res = _sparse_table.delete_entry(from_hrm_ind);
234       assert(res, &quot;It should have been there.&quot;);
235     }
236     assert(prt != NULL &amp;&amp; prt-&gt;hr() == from_hr, &quot;consequence&quot;);
237   }
238   // Note that we can&#39;t assert &quot;prt-&gt;hr() == from_hr&quot;, because of the
239   // possibility of concurrent reuse.  But see head comment of
240   // OtherRegionsTable for why this is OK.
241   assert(prt != NULL, &quot;Inv&quot;);
242 
<span class="line-modified">243   bool added = prt-&gt;add_reference(from);</span>
<span class="line-added">244   if (prt-&gt;add_reference(from)) {</span>
<span class="line-added">245     num_added_by_coarsening++;</span>
<span class="line-added">246   }</span>
<span class="line-added">247   Atomic::add(&amp;_num_occupied, num_added_by_coarsening, memory_order_relaxed);</span>
248   assert(contains_reference(from), &quot;We just added &quot; PTR_FORMAT &quot; to the PRT (%d)&quot;, p2i(from), prt-&gt;contains_reference(from));
249 }
250 
251 PerRegionTable*
252 OtherRegionsTable::find_region_table(size_t ind, HeapRegion* hr) const {
253   assert(ind &lt; _max_fine_entries, &quot;Preconditions.&quot;);
254   PerRegionTable* prt = _fine_grain_regions[ind];
255   while (prt != NULL &amp;&amp; prt-&gt;hr() != hr) {
256     prt = prt-&gt;collision_list_next();
257   }
258   // Loop postcondition is the method postcondition.
259   return prt;
260 }
261 
262 jint OtherRegionsTable::_n_coarsenings = 0;
263 
<span class="line-modified">264 PerRegionTable* OtherRegionsTable::delete_region_table(size_t&amp; added_by_deleted) {</span>
265   assert(_m-&gt;owned_by_self(), &quot;Precondition&quot;);
266   assert(_n_fine_entries == _max_fine_entries, &quot;Precondition&quot;);
267   PerRegionTable* max = NULL;
268   jint max_occ = 0;
269   PerRegionTable** max_prev = NULL;
270   size_t max_ind;
271 
272   size_t i = _fine_eviction_start;
273   for (size_t k = 0; k &lt; _fine_eviction_sample_size; k++) {
274     size_t ii = i;
275     // Make sure we get a non-NULL sample.
276     while (_fine_grain_regions[ii] == NULL) {
277       ii++;
278       if (ii == _max_fine_entries) ii = 0;
279       guarantee(ii != i, &quot;We must find one.&quot;);
280     }
281     PerRegionTable** prev = &amp;_fine_grain_regions[ii];
282     PerRegionTable* cur = *prev;
283     while (cur != NULL) {
284       jint cur_occ = cur-&gt;occupied();
</pre>
<hr />
<pre>
294     i = i + _fine_eviction_stride;
295     if (i &gt;= _n_fine_entries) i = i - _n_fine_entries;
296   }
297 
298   _fine_eviction_start++;
299 
300   if (_fine_eviction_start &gt;= _n_fine_entries) {
301     _fine_eviction_start -= _n_fine_entries;
302   }
303 
304   guarantee(max != NULL, &quot;Since _n_fine_entries &gt; 0&quot;);
305   guarantee(max_prev != NULL, &quot;Since max != NULL.&quot;);
306 
307   // Set the corresponding coarse bit.
308   size_t max_hrm_index = (size_t) max-&gt;hr()-&gt;hrm_index();
309   if (!_coarse_map.at(max_hrm_index)) {
310     _coarse_map.at_put(max_hrm_index, true);
311     _n_coarse_entries++;
312   }
313 
<span class="line-added">314   added_by_deleted = HeapRegion::CardsPerRegion - max_occ;</span>
315   // Unsplice.
316   *max_prev = max-&gt;collision_list_next();
317   Atomic::inc(&amp;_n_coarsenings);
318   _n_fine_entries--;
319   return max;
320 }
321 
322 bool OtherRegionsTable::occupancy_less_or_equal_than(size_t limit) const {
<span class="line-modified">323   return occupied() &lt;= limit;</span>








324 }
325 
326 bool OtherRegionsTable::is_empty() const {
<span class="line-modified">327   return occupied() == 0;</span>
328 }
329 
330 size_t OtherRegionsTable::occupied() const {
<span class="line-modified">331   return _num_occupied;</span>

























332 }
333 
334 size_t OtherRegionsTable::mem_size() const {
335   size_t sum = 0;
336   // all PRTs are of the same size so it is sufficient to query only one of them.
337   if (_first_all_fine_prts != NULL) {
338     assert(_last_all_fine_prts != NULL &amp;&amp;
339       _first_all_fine_prts-&gt;mem_size() == _last_all_fine_prts-&gt;mem_size(), &quot;check that mem_size() is constant&quot;);
340     sum += _first_all_fine_prts-&gt;mem_size() * _n_fine_entries;
341   }
342   sum += (sizeof(PerRegionTable*) * _max_fine_entries);
343   sum += (_coarse_map.size_in_words() * HeapWordSize);
344   sum += (_sparse_table.mem_size());
345   sum += sizeof(OtherRegionsTable) - sizeof(_sparse_table); // Avoid double counting above.
346   return sum;
347 }
348 
349 size_t OtherRegionsTable::static_mem_size() {
350   return G1FromCardCache::static_mem_size();
351 }
</pre>
<hr />
<pre>
354   return PerRegionTable::fl_mem_size();
355 }
356 
357 void OtherRegionsTable::clear() {
358   // if there are no entries, skip this step
359   if (_first_all_fine_prts != NULL) {
360     guarantee(_first_all_fine_prts != NULL &amp;&amp; _last_all_fine_prts != NULL, &quot;just checking&quot;);
361     PerRegionTable::bulk_free(_first_all_fine_prts, _last_all_fine_prts);
362     memset(_fine_grain_regions, 0, _max_fine_entries * sizeof(_fine_grain_regions[0]));
363   } else {
364     guarantee(_first_all_fine_prts == NULL &amp;&amp; _last_all_fine_prts == NULL, &quot;just checking&quot;);
365   }
366 
367   _first_all_fine_prts = _last_all_fine_prts = NULL;
368   _sparse_table.clear();
369   if (_n_coarse_entries &gt; 0) {
370     _coarse_map.clear();
371   }
372   _n_fine_entries = 0;
373   _n_coarse_entries = 0;
<span class="line-added">374 </span>
<span class="line-added">375   _num_occupied = 0;</span>
376 }
377 
378 bool OtherRegionsTable::contains_reference(OopOrNarrowOopStar from) const {
379   // Cast away const in this case.
<span class="line-modified">380   MutexLocker x((Mutex*)_m, Mutex::_no_safepoint_check_flag);</span>
381   return contains_reference_locked(from);
382 }
383 
384 bool OtherRegionsTable::contains_reference_locked(OopOrNarrowOopStar from) const {
385   HeapRegion* hr = _g1h-&gt;heap_region_containing(from);
386   RegionIdx_t hr_ind = (RegionIdx_t) hr-&gt;hrm_index();
387   // Is this region in the coarse map?
388   if (_coarse_map.at(hr_ind)) return true;
389 
390   PerRegionTable* prt = find_region_table(hr_ind &amp; _mod_max_fine_entries_mask,
391                                           hr);
392   if (prt != NULL) {
393     return prt-&gt;contains_reference(from);
394 
395   } else {
396     CardIdx_t card_index = card_within_region(from, hr);
397     return _sparse_table.contains_card(hr_ind, card_index);
398   }
399 }
400 
401 HeapRegionRemSet::HeapRegionRemSet(G1BlockOffsetTable* bot,
402                                    HeapRegion* hr)
403   : _bot(bot),
404     _code_roots(),
<span class="line-modified">405     _m(Mutex::leaf, FormatBuffer&lt;128&gt;(&quot;HeapRegionRemSet lock #%u&quot;, hr-&gt;hrm_index()), true, Mutex::_safepoint_check_never),</span>
406     _other_regions(&amp;_m),
407     _hr(hr),
408     _state(Untracked)
409 {
410 }
411 
412 void HeapRegionRemSet::clear_fcc() {
413   G1FromCardCache::clear(_hr-&gt;hrm_index());
414 }
415 
416 void HeapRegionRemSet::setup_remset_size() {


417   const int LOG_M = 20;
<span class="line-modified">418   guarantee(HeapRegion::LogOfHRGrainBytes &gt;= LOG_M, &quot;Code assumes the region size &gt;= 1M, but is &quot; SIZE_FORMAT &quot;B&quot;, HeapRegion::GrainBytes);</span>
<span class="line-added">419 </span>
<span class="line-added">420   int region_size_log_mb = HeapRegion::LogOfHRGrainBytes - LOG_M;</span>
421   if (FLAG_IS_DEFAULT(G1RSetSparseRegionEntries)) {
<span class="line-modified">422     G1RSetSparseRegionEntries = G1RSetSparseRegionEntriesBase * ((size_t)1 &lt;&lt; (region_size_log_mb + 1));</span>
423   }
424   if (FLAG_IS_DEFAULT(G1RSetRegionEntries)) {
425     G1RSetRegionEntries = G1RSetRegionEntriesBase * (region_size_log_mb + 1);
426   }
427   guarantee(G1RSetSparseRegionEntries &gt; 0 &amp;&amp; G1RSetRegionEntries &gt; 0 , &quot;Sanity&quot;);
428 }
429 
430 void HeapRegionRemSet::clear(bool only_cardset) {
<span class="line-modified">431   MutexLocker x(&amp;_m, Mutex::_no_safepoint_check_flag);</span>
432   clear_locked(only_cardset);
433 }
434 
435 void HeapRegionRemSet::clear_locked(bool only_cardset) {
436   if (!only_cardset) {
437     _code_roots.clear();
438   }
439   clear_fcc();
440   _other_regions.clear();
441   set_state_empty();
<span class="line-modified">442   assert(occupied() == 0, &quot;Should be clear.&quot;);</span>
443 }
444 
445 // Code roots support
446 //
447 // The code root set is protected by two separate locking schemes
448 // When at safepoint the per-hrrs lock must be held during modifications
449 // except when doing a full gc.
450 // When not at safepoint the CodeCache_lock must be held during modifications.
451 // When concurrent readers access the contains() function
452 // (during the evacuation phase) no removals are allowed.
453 
454 void HeapRegionRemSet::add_strong_code_root(nmethod* nm) {
455   assert(nm != NULL, &quot;sanity&quot;);
456   assert((!CodeCache_lock-&gt;owned_by_self() || SafepointSynchronize::is_at_safepoint()),
457           &quot;should call add_strong_code_root_locked instead. CodeCache_lock-&gt;owned_by_self(): %s, is_at_safepoint(): %s&quot;,
458           BOOL_TO_STR(CodeCache_lock-&gt;owned_by_self()), BOOL_TO_STR(SafepointSynchronize::is_at_safepoint()));
459   // Optimistic unlocked contains-check
460   if (!_code_roots.contains(nm)) {
<span class="line-modified">461     MutexLocker ml(&amp;_m, Mutex::_no_safepoint_check_flag);</span>
462     add_strong_code_root_locked(nm);
463   }
464 }
465 
466 void HeapRegionRemSet::add_strong_code_root_locked(nmethod* nm) {
467   assert(nm != NULL, &quot;sanity&quot;);
468   assert((CodeCache_lock-&gt;owned_by_self() ||
469          (SafepointSynchronize::is_at_safepoint() &amp;&amp;
470           (_m.owned_by_self() || Thread::current()-&gt;is_VM_thread()))),
471           &quot;not safely locked. CodeCache_lock-&gt;owned_by_self(): %s, is_at_safepoint(): %s, _m.owned_by_self(): %s, Thread::current()-&gt;is_VM_thread(): %s&quot;,
472           BOOL_TO_STR(CodeCache_lock-&gt;owned_by_self()), BOOL_TO_STR(SafepointSynchronize::is_at_safepoint()),
473           BOOL_TO_STR(_m.owned_by_self()), BOOL_TO_STR(Thread::current()-&gt;is_VM_thread()));
474   _code_roots.add(nm);
475 }
476 
477 void HeapRegionRemSet::remove_strong_code_root(nmethod* nm) {
478   assert(nm != NULL, &quot;sanity&quot;);
479   assert_locked_or_safepoint(CodeCache_lock);
480 
<span class="line-modified">481   MutexLocker ml(CodeCache_lock-&gt;owned_by_self() ? NULL : &amp;_m, Mutex::_no_safepoint_check_flag);</span>
482   _code_roots.remove(nm);
483 
484   // Check that there were no duplicates
485   guarantee(!_code_roots.contains(nm), &quot;duplicate entry found&quot;);
486 }
487 
488 void HeapRegionRemSet::strong_code_roots_do(CodeBlobClosure* blk) const {
489   _code_roots.nmethods_do(blk);
490 }
491 
492 void HeapRegionRemSet::clean_strong_code_roots(HeapRegion* hr) {
493   _code_roots.clean(hr);
494 }
495 
496 size_t HeapRegionRemSet::strong_code_roots_mem_size() {
497   return _code_roots.mem_size();
498 }












































































































































































</pre>
</td>
</tr>
</table>
<center><a href="heapRegionManager.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="heapRegionRemSet.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>