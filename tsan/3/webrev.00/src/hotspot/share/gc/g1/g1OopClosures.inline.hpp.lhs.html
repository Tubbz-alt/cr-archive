<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/gc/g1/g1OopClosures.inline.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
    <script type="text/javascript" src="../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (c) 2001, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_GC_G1_G1OOPCLOSURES_INLINE_HPP
 26 #define SHARE_GC_G1_G1OOPCLOSURES_INLINE_HPP
 27 
 28 #include &quot;gc/g1/g1CollectedHeap.hpp&quot;
 29 #include &quot;gc/g1/g1ConcurrentMark.inline.hpp&quot;
 30 #include &quot;gc/g1/g1OopClosures.hpp&quot;
 31 #include &quot;gc/g1/g1ParScanThreadState.inline.hpp&quot;
 32 #include &quot;gc/g1/g1RemSet.hpp&quot;
 33 #include &quot;gc/g1/heapRegion.inline.hpp&quot;
 34 #include &quot;gc/g1/heapRegionRemSet.hpp&quot;
 35 #include &quot;memory/iterator.inline.hpp&quot;
 36 #include &quot;oops/access.inline.hpp&quot;
 37 #include &quot;oops/compressedOops.inline.hpp&quot;
 38 #include &quot;oops/oopsHierarchy.hpp&quot;
 39 #include &quot;oops/oop.inline.hpp&quot;
 40 #include &quot;runtime/prefetch.inline.hpp&quot;
<a name="1" id="anc1"></a>
 41 
 42 template &lt;class T&gt;
 43 inline void G1ScanClosureBase::prefetch_and_push(T* p, const oop obj) {
 44   // We&#39;re not going to even bother checking whether the object is
 45   // already forwarded or not, as this usually causes an immediate
 46   // stall. We&#39;ll try to prefetch the object (for write, given that
 47   // we might need to install the forwarding reference) and we&#39;ll
 48   // get back to it when pop it from the queue
 49   Prefetch::write(obj-&gt;mark_addr_raw(), 0);
 50   Prefetch::read(obj-&gt;mark_addr_raw(), (HeapWordSize*2));
 51 
 52   // slightly paranoid test; I&#39;m trying to catch potential
 53   // problems before we go into push_on_queue to know where the
 54   // problem is coming from
 55   assert((obj == RawAccess&lt;&gt;::oop_load(p)) ||
 56          (obj-&gt;is_forwarded() &amp;&amp;
 57          obj-&gt;forwardee() == RawAccess&lt;&gt;::oop_load(p)),
 58          &quot;p should still be pointing to obj or to its forwardee&quot;);
 59 
 60   _par_scan_state-&gt;push_on_queue(p);
 61 }
 62 
 63 template &lt;class T&gt;
<a name="2" id="anc2"></a><span class="line-modified"> 64 inline void G1ScanClosureBase::handle_non_cset_obj_common(InCSetState const state, T* p, oop const obj) {</span>
<span class="line-modified"> 65   if (state.is_humongous()) {</span>
 66     _g1h-&gt;set_humongous_is_live(obj);
<a name="3" id="anc3"></a><span class="line-modified"> 67   } else if (state.is_optional()) {</span>
 68     _par_scan_state-&gt;remember_reference_into_optional_region(p);
 69   }
 70 }
 71 
 72 inline void G1ScanClosureBase::trim_queue_partially() {
 73   _par_scan_state-&gt;trim_queue_partially();
 74 }
 75 
 76 template &lt;class T&gt;
 77 inline void G1ScanEvacuatedObjClosure::do_oop_work(T* p) {
 78   T heap_oop = RawAccess&lt;&gt;::oop_load(p);
 79 
 80   if (CompressedOops::is_null(heap_oop)) {
 81     return;
 82   }
 83   oop obj = CompressedOops::decode_not_null(heap_oop);
<a name="4" id="anc4"></a><span class="line-modified"> 84   const InCSetState state = _g1h-&gt;in_cset_state(obj);</span>
<span class="line-modified"> 85   if (state.is_in_cset()) {</span>
 86     prefetch_and_push(p, obj);
 87   } else if (!HeapRegion::is_in_same_region(p, obj)) {
<a name="5" id="anc5"></a><span class="line-modified"> 88     handle_non_cset_obj_common(state, p, obj);</span>
 89     assert(_scanning_in_young != Uninitialized, &quot;Scan location has not been initialized.&quot;);
 90     if (_scanning_in_young == True) {
 91       return;
 92     }
<a name="6" id="anc6"></a><span class="line-modified"> 93     _par_scan_state-&gt;enqueue_card_if_tracked(p, obj);</span>
 94   }
 95 }
 96 
 97 template &lt;class T&gt;
 98 inline void G1CMOopClosure::do_oop_work(T* p) {
 99   _task-&gt;deal_with_reference(p);
100 }
101 
102 template &lt;class T&gt;
103 inline void G1RootRegionScanClosure::do_oop_work(T* p) {
104   T heap_oop = RawAccess&lt;MO_VOLATILE&gt;::oop_load(p);
105   if (CompressedOops::is_null(heap_oop)) {
106     return;
107   }
108   oop obj = CompressedOops::decode_not_null(heap_oop);
109   _cm-&gt;mark_in_next_bitmap(_worker_id, obj);
110 }
111 
112 template &lt;class T&gt;
113 inline static void check_obj_during_refinement(T* p, oop const obj) {
114 #ifdef ASSERT
115   G1CollectedHeap* g1h = G1CollectedHeap::heap();
116   // can&#39;t do because of races
117   // assert(oopDesc::is_oop_or_null(obj), &quot;expected an oop&quot;);
<a name="7" id="anc7"></a><span class="line-modified">118   assert(check_obj_alignment(obj), &quot;not oop aligned&quot;);</span>
<span class="line-modified">119   assert(g1h-&gt;is_in_reserved(obj), &quot;must be in heap&quot;);</span>
120 
121   HeapRegion* from = g1h-&gt;heap_region_containing(p);
122 
123   assert(from != NULL, &quot;from region must be non-NULL&quot;);
124   assert(from-&gt;is_in_reserved(p) ||
125          (from-&gt;is_humongous() &amp;&amp;
126           g1h-&gt;heap_region_containing(p)-&gt;is_humongous() &amp;&amp;
127           from-&gt;humongous_start_region() == g1h-&gt;heap_region_containing(p)-&gt;humongous_start_region()),
128          &quot;p &quot; PTR_FORMAT &quot; is not in the same region %u or part of the correct humongous object starting at region %u.&quot;,
129          p2i(p), from-&gt;hrm_index(), from-&gt;humongous_start_region()-&gt;hrm_index());
130 #endif // ASSERT
131 }
132 
133 template &lt;class T&gt;
134 inline void G1ConcurrentRefineOopClosure::do_oop_work(T* p) {
135   T o = RawAccess&lt;MO_VOLATILE&gt;::oop_load(p);
136   if (CompressedOops::is_null(o)) {
137     return;
138   }
139   oop obj = CompressedOops::decode_not_null(o);
140 
141   check_obj_during_refinement(p, obj);
142 
143   if (HeapRegion::is_in_same_region(p, obj)) {
144     // Normally this closure should only be called with cross-region references.
145     // But since Java threads are manipulating the references concurrently and we
146     // reload the values things may have changed.
147     // Also this check lets slip through references from a humongous continues region
148     // to its humongous start region, as they are in different regions, and adds a
149     // remembered set entry. This is benign (apart from memory usage), as we never
150     // try to either evacuate or eager reclaim humonguous arrays of j.l.O.
151     return;
152   }
153 
154   HeapRegionRemSet* to_rem_set = _g1h-&gt;heap_region_containing(obj)-&gt;rem_set();
155 
156   assert(to_rem_set != NULL, &quot;Need per-region &#39;into&#39; remsets.&quot;);
157   if (to_rem_set-&gt;is_tracked()) {
<a name="8" id="anc8"></a><span class="line-modified">158     to_rem_set-&gt;add_reference(p, _worker_i);</span>
159   }
160 }
161 
162 template &lt;class T&gt;
<a name="9" id="anc9"></a><span class="line-modified">163 inline void G1ScanObjsDuringUpdateRSClosure::do_oop_work(T* p) {</span>
164   T o = RawAccess&lt;&gt;::oop_load(p);
165   if (CompressedOops::is_null(o)) {
166     return;
167   }
168   oop obj = CompressedOops::decode_not_null(o);
169 
170   check_obj_during_refinement(p, obj);
171 
<a name="10" id="anc10"></a><span class="line-modified">172   assert(!_g1h-&gt;is_in_cset((HeapWord*)p), &quot;Oop originates from &quot; PTR_FORMAT &quot; (region: %u) which is in the collection set.&quot;, p2i(p), _g1h-&gt;addr_to_region((HeapWord*)p));</span>
<span class="line-modified">173   const InCSetState state = _g1h-&gt;in_cset_state(obj);</span>
<span class="line-modified">174   if (state.is_in_cset()) {</span>



175     // Since the source is always from outside the collection set, here we implicitly know
176     // that this is a cross-region reference too.
177     prefetch_and_push(p, obj);
178   } else if (!HeapRegion::is_in_same_region(p, obj)) {
<a name="11" id="anc11"></a><span class="line-modified">179     handle_non_cset_obj_common(state, p, obj);</span>
<span class="line-modified">180     _par_scan_state-&gt;enqueue_card_if_tracked(p, obj);</span>
181   }
182 }
183 
184 template &lt;class T&gt;
<a name="12" id="anc12"></a><span class="line-modified">185 inline void G1ScanObjsDuringScanRSClosure::do_oop_work(T* p) {</span>
<span class="line-modified">186   T heap_oop = RawAccess&lt;&gt;::oop_load(p);</span>
<span class="line-modified">187   if (CompressedOops::is_null(heap_oop)) {</span>



188     return;
189   }
<a name="13" id="anc13"></a><span class="line-removed">190   oop obj = CompressedOops::decode_not_null(heap_oop);</span>
<span class="line-removed">191 </span>
<span class="line-removed">192   const InCSetState state = _g1h-&gt;in_cset_state(obj);</span>
<span class="line-removed">193   if (state.is_in_cset()) {</span>
<span class="line-removed">194     prefetch_and_push(p, obj);</span>
<span class="line-removed">195   } else if (!HeapRegion::is_in_same_region(p, obj)) {</span>
<span class="line-removed">196     handle_non_cset_obj_common(state, p, obj);</span>
<span class="line-removed">197   }</span>
<span class="line-removed">198 }</span>
<span class="line-removed">199 </span>
<span class="line-removed">200 template &lt;class T&gt;</span>
<span class="line-removed">201 inline void G1ScanRSForOptionalClosure::do_oop_work(T* p) {</span>
202   _scan_cl-&gt;do_oop_work(p);
203   _scan_cl-&gt;trim_queue_partially();
204 }
205 
206 void G1ParCopyHelper::do_cld_barrier(oop new_obj) {
207   if (_g1h-&gt;heap_region_containing(new_obj)-&gt;is_young()) {
208     _scanned_cld-&gt;record_modified_oops();
209   }
210 }
211 
212 void G1ParCopyHelper::mark_object(oop obj) {
213   assert(!_g1h-&gt;heap_region_containing(obj)-&gt;in_collection_set(), &quot;should not mark objects in the CSet&quot;);
214 
215   // We know that the object is not moving so it&#39;s safe to read its size.
216   _cm-&gt;mark_in_next_bitmap(_worker_id, obj);
217 }
218 
219 void G1ParCopyHelper::trim_queue_partially() {
220   _par_scan_state-&gt;trim_queue_partially();
221 }
222 
223 template &lt;G1Barrier barrier, G1Mark do_mark_object&gt;
224 template &lt;class T&gt;
225 void G1ParCopyClosure&lt;barrier, do_mark_object&gt;::do_oop_work(T* p) {
226   T heap_oop = RawAccess&lt;&gt;::oop_load(p);
227 
228   if (CompressedOops::is_null(heap_oop)) {
229     return;
230   }
231 
232   oop obj = CompressedOops::decode_not_null(heap_oop);
233 
234   assert(_worker_id == _par_scan_state-&gt;worker_id(), &quot;sanity&quot;);
235 
<a name="14" id="anc14"></a><span class="line-modified">236   const InCSetState state = _g1h-&gt;in_cset_state(obj);</span>
237   if (state.is_in_cset()) {
238     oop forwardee;
<a name="15" id="anc15"></a><span class="line-modified">239     markOop m = obj-&gt;mark_raw();</span>
<span class="line-modified">240     if (m-&gt;is_marked()) {</span>
<span class="line-modified">241       forwardee = (oop) m-&gt;decode_pointer();</span>
242     } else {
243       forwardee = _par_scan_state-&gt;copy_to_survivor_space(state, obj, m);
244     }
245     assert(forwardee != NULL, &quot;forwardee should not be NULL&quot;);
246     RawAccess&lt;IS_NOT_NULL&gt;::oop_store(p, forwardee);
247 
248     if (barrier == G1BarrierCLD) {
249       do_cld_barrier(forwardee);
250     }
251   } else {
252     if (state.is_humongous()) {
253       _g1h-&gt;set_humongous_is_live(obj);
<a name="16" id="anc16"></a><span class="line-modified">254     } else if (state.is_optional()) {</span>
255       _par_scan_state-&gt;remember_root_into_optional_region(p);
256     }
257 
258     // The object is not in collection set. If we&#39;re a root scanning
259     // closure during an initial mark pause then attempt to mark the object.
260     if (do_mark_object == G1MarkFromRoot) {
261       mark_object(obj);
262     }
263   }
264   trim_queue_partially();
265 }
266 
267 template &lt;class T&gt; void G1RebuildRemSetClosure::do_oop_work(T* p) {
268   oop const obj = RawAccess&lt;MO_VOLATILE&gt;::oop_load(p);
269   if (obj == NULL) {
270     return;
271   }
272 
273   if (HeapRegion::is_in_same_region(p, obj)) {
274     return;
275   }
276 
277   HeapRegion* to = _g1h-&gt;heap_region_containing(obj);
278   HeapRegionRemSet* rem_set = to-&gt;rem_set();
279   rem_set-&gt;add_reference(p, _worker_id);
280 }
281 
282 #endif // SHARE_GC_G1_G1OOPCLOSURES_INLINE_HPP
<a name="17" id="anc17"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="17" type="hidden" />
</body>
</html>