<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/g1/g1AllocRegion.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="g1AllocRegion.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1Allocator.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/g1/g1AllocRegion.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_GC_G1_G1ALLOCREGION_HPP
 26 #define SHARE_GC_G1_G1ALLOCREGION_HPP
 27 
 28 #include &quot;gc/g1/heapRegion.hpp&quot;
 29 #include &quot;gc/g1/g1EvacStats.hpp&quot;
<span class="line-modified"> 30 #include &quot;gc/g1/g1InCSetState.hpp&quot;</span>

 31 
 32 class G1CollectedHeap;
 33 
 34 // A class that holds a region that is active in satisfying allocation
 35 // requests, potentially issued in parallel. When the active region is
 36 // full it will be retired and replaced with a new one. The
 37 // implementation assumes that fast-path allocations will be lock-free
 38 // and a lock will need to be taken when the active region needs to be
 39 // replaced.
 40 
<span class="line-modified"> 41 class G1AllocRegion {</span>
 42 
 43 private:
 44   // The active allocating region we are currently allocating out
 45   // of. The invariant is that if this object is initialized (i.e.,
 46   // init() has been called and release() has not) then _alloc_region
 47   // is either an active allocating region or the dummy region (i.e.,
 48   // it can never be NULL) and this object can be used to satisfy
 49   // allocation requests. If this object is not initialized
 50   // (i.e. init() has not been called or release() has been called)
 51   // then _alloc_region is NULL and this object should not be used to
 52   // satisfy allocation requests (it was done this way to force the
 53   // correct use of init() and release()).
 54   HeapRegion* volatile _alloc_region;
 55 
 56   // It keeps track of the distinct number of regions that are used
 57   // for allocation in the active interval of this object, i.e.,
 58   // between a call to init() and a call to release(). The count
 59   // mostly includes regions that are freshly allocated, as well as
 60   // the region that is re-used using the set() method. This count can
 61   // be used in any heuristics that might want to bound how many
</pre>
<hr />
<pre>
 74   const char* _name;
 75 
 76   // A dummy region (i.e., it&#39;s been allocated specially for this
 77   // purpose and it is not part of the heap) that is full (i.e., top()
 78   // == end()). When we don&#39;t have a valid active region we make
 79   // _alloc_region point to this. This allows us to skip checking
 80   // whether the _alloc_region is NULL or not.
 81   static HeapRegion* _dummy_region;
 82 
 83   // After a region is allocated by alloc_new_region, this
 84   // method is used to set it as the active alloc_region
 85   void update_alloc_region(HeapRegion* alloc_region);
 86 
 87   // Allocate a new active region and use it to perform a word_size
 88   // allocation. The force parameter will be passed on to
 89   // G1CollectedHeap::allocate_new_alloc_region() and tells it to try
 90   // to allocate a new region even if the max has been reached.
 91   HeapWord* new_alloc_region_and_allocate(size_t word_size, bool force);
 92 
 93 protected:



 94   // Reset the alloc region to point a the dummy region.
 95   void reset_alloc_region();
 96 
 97   // Perform a non-MT-safe allocation out of the given region.
 98   inline HeapWord* allocate(HeapRegion* alloc_region,
 99                             size_t word_size);
100 
101   // Perform a MT-safe allocation out of the given region.
102   inline HeapWord* par_allocate(HeapRegion* alloc_region,
103                                 size_t word_size);
104   // Perform a MT-safe allocation out of the given region, with the given
105   // minimum and desired size. Returns the actual size allocated (between
106   // minimum and desired size) in actual_word_size if the allocation has been
107   // successful.
108   inline HeapWord* par_allocate(HeapRegion* alloc_region,
109                                 size_t min_word_size,
110                                 size_t desired_word_size,
111                                 size_t* actual_word_size);
112 
113   // Ensure that the region passed as a parameter has been filled up
114   // so that noone else can allocate out of it any more.
115   // Returns the number of bytes that have been wasted by filled up
116   // the space.
117   size_t fill_up_remaining_space(HeapRegion* alloc_region);
118 
119   // Retire the active allocating region. If fill_up is true then make
120   // sure that the region is full before we retire it so that no one
121   // else can allocate out of it.
122   // Returns the number of bytes that have been filled up during retire.
123   virtual size_t retire(bool fill_up);
124 
125   size_t retire_internal(HeapRegion* alloc_region, bool fill_up);
126 
127   // For convenience as subclasses use it.
128   static G1CollectedHeap* _g1h;
129 
130   virtual HeapRegion* allocate_new_region(size_t word_size, bool force) = 0;
131   virtual void retire_region(HeapRegion* alloc_region,
132                              size_t allocated_bytes) = 0;
133 
<span class="line-modified">134   G1AllocRegion(const char* name, bool bot_updates);</span>
135 
136 public:
137   static void setup(G1CollectedHeap* g1h, HeapRegion* dummy_region);
138 
139   HeapRegion* get() const {
140     HeapRegion * hr = _alloc_region;
141     // Make sure that the dummy region does not escape this class.
142     return (hr == _dummy_region) ? NULL : hr;
143   }
144 
145   uint count() { return _count; }
146 
147   // The following two are the building blocks for the allocation method.
148 
149   // First-level allocation: Should be called without holding a
150   // lock. It will try to allocate lock-free out of the active region,
151   // or return NULL if it was unable to.
152   inline HeapWord* attempt_allocation(size_t word_size);
153   // Perform an allocation out of the current allocation region, with the given
154   // minimum and desired size. Returns the actual size allocated (between
</pre>
<hr />
<pre>
203 
204 class MutatorAllocRegion : public G1AllocRegion {
205 private:
206   // Keeps track of the total waste generated during the current
207   // mutator phase.
208   size_t _wasted_bytes;
209 
210   // Retained allocation region. Used to lower the waste generated
211   // during mutation by having two active regions if the free space
212   // in a region about to be retired still could fit a TLAB.
213   HeapRegion* volatile _retained_alloc_region;
214 
215   // Decide if the region should be retained, based on the free size
216   // in it and the free size in the currently retained region, if any.
217   bool should_retain(HeapRegion* region);
218 protected:
219   virtual HeapRegion* allocate_new_region(size_t word_size, bool force);
220   virtual void retire_region(HeapRegion* alloc_region, size_t allocated_bytes);
221   virtual size_t retire(bool fill_up);
222 public:
<span class="line-modified">223   MutatorAllocRegion()</span>
<span class="line-modified">224     : G1AllocRegion(&quot;Mutator Alloc Region&quot;, false /* bot_updates */),</span>
225       _wasted_bytes(0),
226       _retained_alloc_region(NULL) { }
227 
228   // Returns the combined used memory in the current alloc region and
229   // the retained alloc region.
230   size_t used_in_alloc_regions();
231 
232   // Perform an allocation out of the retained allocation region, with the given
233   // minimum and desired size. Returns the actual size allocated (between
234   // minimum and desired size) in actual_word_size if the allocation has been
235   // successful.
236   // Should be called without holding a lock. It will try to allocate lock-free
237   // out of the retained region, or return NULL if it was unable to.
238   inline HeapWord* attempt_retained_allocation(size_t min_word_size,
239                                                size_t desired_word_size,
240                                                size_t* actual_word_size);
241 
242   // This specialization of release() makes sure that the retained alloc
243   // region is retired and set to NULL.
244   virtual HeapRegion* release();
245 
246   virtual void init();
247 };

248 // Common base class for allocation regions used during GC.
249 class G1GCAllocRegion : public G1AllocRegion {
250 protected:
251   G1EvacStats* _stats;
<span class="line-modified">252   InCSetState::in_cset_state_t _purpose;</span>
253 
254   virtual HeapRegion* allocate_new_region(size_t word_size, bool force);
255   virtual void retire_region(HeapRegion* alloc_region, size_t allocated_bytes);
256 
257   virtual size_t retire(bool fill_up);
258 
<span class="line-modified">259   G1GCAllocRegion(const char* name, bool bot_updates, G1EvacStats* stats, InCSetState::in_cset_state_t purpose)</span>
<span class="line-modified">260   : G1AllocRegion(name, bot_updates), _stats(stats), _purpose(purpose) {</span>

261     assert(stats != NULL, &quot;Must pass non-NULL PLAB statistics&quot;);
262   }
263 };
264 
265 class SurvivorGCAllocRegion : public G1GCAllocRegion {
266 public:
<span class="line-modified">267   SurvivorGCAllocRegion(G1EvacStats* stats)</span>
<span class="line-modified">268   : G1GCAllocRegion(&quot;Survivor GC Alloc Region&quot;, false /* bot_updates */, stats, InCSetState::Young) { }</span>
269 };
270 
271 class OldGCAllocRegion : public G1GCAllocRegion {
272 public:
273   OldGCAllocRegion(G1EvacStats* stats)
<span class="line-modified">274   : G1GCAllocRegion(&quot;Old GC Alloc Region&quot;, true /* bot_updates */, stats, InCSetState::Old) { }</span>
275 
276   // This specialization of release() makes sure that the last card that has
277   // been allocated into has been completely filled by a dummy object.  This
278   // avoids races when remembered set scanning wants to update the BOT of the
279   // last card in the retained old gc alloc region, and allocation threads
280   // allocating into that card at the same time.
281   virtual HeapRegion* release();
282 };
283 
284 #endif // SHARE_GC_G1_G1ALLOCREGION_HPP
</pre>
</td>
<td>
<hr />
<pre>
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_GC_G1_G1ALLOCREGION_HPP
 26 #define SHARE_GC_G1_G1ALLOCREGION_HPP
 27 
 28 #include &quot;gc/g1/heapRegion.hpp&quot;
 29 #include &quot;gc/g1/g1EvacStats.hpp&quot;
<span class="line-modified"> 30 #include &quot;gc/g1/g1HeapRegionAttr.hpp&quot;</span>
<span class="line-added"> 31 #include &quot;gc/g1/g1NUMA.hpp&quot;</span>
 32 
 33 class G1CollectedHeap;
 34 
 35 // A class that holds a region that is active in satisfying allocation
 36 // requests, potentially issued in parallel. When the active region is
 37 // full it will be retired and replaced with a new one. The
 38 // implementation assumes that fast-path allocations will be lock-free
 39 // and a lock will need to be taken when the active region needs to be
 40 // replaced.
 41 
<span class="line-modified"> 42 class G1AllocRegion : public CHeapObj&lt;mtGC&gt; {</span>
 43 
 44 private:
 45   // The active allocating region we are currently allocating out
 46   // of. The invariant is that if this object is initialized (i.e.,
 47   // init() has been called and release() has not) then _alloc_region
 48   // is either an active allocating region or the dummy region (i.e.,
 49   // it can never be NULL) and this object can be used to satisfy
 50   // allocation requests. If this object is not initialized
 51   // (i.e. init() has not been called or release() has been called)
 52   // then _alloc_region is NULL and this object should not be used to
 53   // satisfy allocation requests (it was done this way to force the
 54   // correct use of init() and release()).
 55   HeapRegion* volatile _alloc_region;
 56 
 57   // It keeps track of the distinct number of regions that are used
 58   // for allocation in the active interval of this object, i.e.,
 59   // between a call to init() and a call to release(). The count
 60   // mostly includes regions that are freshly allocated, as well as
 61   // the region that is re-used using the set() method. This count can
 62   // be used in any heuristics that might want to bound how many
</pre>
<hr />
<pre>
 75   const char* _name;
 76 
 77   // A dummy region (i.e., it&#39;s been allocated specially for this
 78   // purpose and it is not part of the heap) that is full (i.e., top()
 79   // == end()). When we don&#39;t have a valid active region we make
 80   // _alloc_region point to this. This allows us to skip checking
 81   // whether the _alloc_region is NULL or not.
 82   static HeapRegion* _dummy_region;
 83 
 84   // After a region is allocated by alloc_new_region, this
 85   // method is used to set it as the active alloc_region
 86   void update_alloc_region(HeapRegion* alloc_region);
 87 
 88   // Allocate a new active region and use it to perform a word_size
 89   // allocation. The force parameter will be passed on to
 90   // G1CollectedHeap::allocate_new_alloc_region() and tells it to try
 91   // to allocate a new region even if the max has been reached.
 92   HeapWord* new_alloc_region_and_allocate(size_t word_size, bool force);
 93 
 94 protected:
<span class="line-added"> 95   // The memory node index this allocation region belongs to.</span>
<span class="line-added"> 96   uint _node_index;</span>
<span class="line-added"> 97 </span>
 98   // Reset the alloc region to point a the dummy region.
 99   void reset_alloc_region();
100 
101   // Perform a non-MT-safe allocation out of the given region.
102   inline HeapWord* allocate(HeapRegion* alloc_region,
103                             size_t word_size);
104 
105   // Perform a MT-safe allocation out of the given region.
106   inline HeapWord* par_allocate(HeapRegion* alloc_region,
107                                 size_t word_size);
108   // Perform a MT-safe allocation out of the given region, with the given
109   // minimum and desired size. Returns the actual size allocated (between
110   // minimum and desired size) in actual_word_size if the allocation has been
111   // successful.
112   inline HeapWord* par_allocate(HeapRegion* alloc_region,
113                                 size_t min_word_size,
114                                 size_t desired_word_size,
115                                 size_t* actual_word_size);
116 
117   // Ensure that the region passed as a parameter has been filled up
118   // so that noone else can allocate out of it any more.
119   // Returns the number of bytes that have been wasted by filled up
120   // the space.
121   size_t fill_up_remaining_space(HeapRegion* alloc_region);
122 
123   // Retire the active allocating region. If fill_up is true then make
124   // sure that the region is full before we retire it so that no one
125   // else can allocate out of it.
126   // Returns the number of bytes that have been filled up during retire.
127   virtual size_t retire(bool fill_up);
128 
129   size_t retire_internal(HeapRegion* alloc_region, bool fill_up);
130 
131   // For convenience as subclasses use it.
132   static G1CollectedHeap* _g1h;
133 
134   virtual HeapRegion* allocate_new_region(size_t word_size, bool force) = 0;
135   virtual void retire_region(HeapRegion* alloc_region,
136                              size_t allocated_bytes) = 0;
137 
<span class="line-modified">138   G1AllocRegion(const char* name, bool bot_updates, uint node_index);</span>
139 
140 public:
141   static void setup(G1CollectedHeap* g1h, HeapRegion* dummy_region);
142 
143   HeapRegion* get() const {
144     HeapRegion * hr = _alloc_region;
145     // Make sure that the dummy region does not escape this class.
146     return (hr == _dummy_region) ? NULL : hr;
147   }
148 
149   uint count() { return _count; }
150 
151   // The following two are the building blocks for the allocation method.
152 
153   // First-level allocation: Should be called without holding a
154   // lock. It will try to allocate lock-free out of the active region,
155   // or return NULL if it was unable to.
156   inline HeapWord* attempt_allocation(size_t word_size);
157   // Perform an allocation out of the current allocation region, with the given
158   // minimum and desired size. Returns the actual size allocated (between
</pre>
<hr />
<pre>
207 
208 class MutatorAllocRegion : public G1AllocRegion {
209 private:
210   // Keeps track of the total waste generated during the current
211   // mutator phase.
212   size_t _wasted_bytes;
213 
214   // Retained allocation region. Used to lower the waste generated
215   // during mutation by having two active regions if the free space
216   // in a region about to be retired still could fit a TLAB.
217   HeapRegion* volatile _retained_alloc_region;
218 
219   // Decide if the region should be retained, based on the free size
220   // in it and the free size in the currently retained region, if any.
221   bool should_retain(HeapRegion* region);
222 protected:
223   virtual HeapRegion* allocate_new_region(size_t word_size, bool force);
224   virtual void retire_region(HeapRegion* alloc_region, size_t allocated_bytes);
225   virtual size_t retire(bool fill_up);
226 public:
<span class="line-modified">227   MutatorAllocRegion(uint node_index)</span>
<span class="line-modified">228     : G1AllocRegion(&quot;Mutator Alloc Region&quot;, false /* bot_updates */, node_index),</span>
229       _wasted_bytes(0),
230       _retained_alloc_region(NULL) { }
231 
232   // Returns the combined used memory in the current alloc region and
233   // the retained alloc region.
234   size_t used_in_alloc_regions();
235 
236   // Perform an allocation out of the retained allocation region, with the given
237   // minimum and desired size. Returns the actual size allocated (between
238   // minimum and desired size) in actual_word_size if the allocation has been
239   // successful.
240   // Should be called without holding a lock. It will try to allocate lock-free
241   // out of the retained region, or return NULL if it was unable to.
242   inline HeapWord* attempt_retained_allocation(size_t min_word_size,
243                                                size_t desired_word_size,
244                                                size_t* actual_word_size);
245 
246   // This specialization of release() makes sure that the retained alloc
247   // region is retired and set to NULL.
248   virtual HeapRegion* release();
249 
250   virtual void init();
251 };
<span class="line-added">252 </span>
253 // Common base class for allocation regions used during GC.
254 class G1GCAllocRegion : public G1AllocRegion {
255 protected:
256   G1EvacStats* _stats;
<span class="line-modified">257   G1HeapRegionAttr::region_type_t _purpose;</span>
258 
259   virtual HeapRegion* allocate_new_region(size_t word_size, bool force);
260   virtual void retire_region(HeapRegion* alloc_region, size_t allocated_bytes);
261 
262   virtual size_t retire(bool fill_up);
263 
<span class="line-modified">264   G1GCAllocRegion(const char* name, bool bot_updates, G1EvacStats* stats,</span>
<span class="line-modified">265                   G1HeapRegionAttr::region_type_t purpose, uint node_index = G1NUMA::AnyNodeIndex)</span>
<span class="line-added">266   : G1AllocRegion(name, bot_updates, node_index), _stats(stats), _purpose(purpose) {</span>
267     assert(stats != NULL, &quot;Must pass non-NULL PLAB statistics&quot;);
268   }
269 };
270 
271 class SurvivorGCAllocRegion : public G1GCAllocRegion {
272 public:
<span class="line-modified">273   SurvivorGCAllocRegion(G1EvacStats* stats, uint node_index)</span>
<span class="line-modified">274   : G1GCAllocRegion(&quot;Survivor GC Alloc Region&quot;, false /* bot_updates */, stats, G1HeapRegionAttr::Young, node_index) { }</span>
275 };
276 
277 class OldGCAllocRegion : public G1GCAllocRegion {
278 public:
279   OldGCAllocRegion(G1EvacStats* stats)
<span class="line-modified">280   : G1GCAllocRegion(&quot;Old GC Alloc Region&quot;, true /* bot_updates */, stats, G1HeapRegionAttr::Old) { }</span>
281 
282   // This specialization of release() makes sure that the last card that has
283   // been allocated into has been completely filled by a dummy object.  This
284   // avoids races when remembered set scanning wants to update the BOT of the
285   // last card in the retained old gc alloc region, and allocation threads
286   // allocating into that card at the same time.
287   virtual HeapRegion* release();
288 };
289 
290 #endif // SHARE_GC_G1_G1ALLOCREGION_HPP
</pre>
</td>
</tr>
</table>
<center><a href="g1AllocRegion.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1Allocator.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>