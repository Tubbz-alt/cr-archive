<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/gc/g1/g1OopClosures.inline.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
    <script type="text/javascript" src="../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (c) 2001, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_GC_G1_G1OOPCLOSURES_INLINE_HPP
 26 #define SHARE_GC_G1_G1OOPCLOSURES_INLINE_HPP
 27 
 28 #include &quot;gc/g1/g1CollectedHeap.hpp&quot;
 29 #include &quot;gc/g1/g1ConcurrentMark.inline.hpp&quot;
 30 #include &quot;gc/g1/g1OopClosures.hpp&quot;
 31 #include &quot;gc/g1/g1ParScanThreadState.inline.hpp&quot;
 32 #include &quot;gc/g1/g1RemSet.hpp&quot;
 33 #include &quot;gc/g1/heapRegion.inline.hpp&quot;
 34 #include &quot;gc/g1/heapRegionRemSet.hpp&quot;
 35 #include &quot;memory/iterator.inline.hpp&quot;
 36 #include &quot;oops/access.inline.hpp&quot;
 37 #include &quot;oops/compressedOops.inline.hpp&quot;
 38 #include &quot;oops/oopsHierarchy.hpp&quot;
 39 #include &quot;oops/oop.inline.hpp&quot;
 40 #include &quot;runtime/prefetch.inline.hpp&quot;
<a name="1" id="anc1"></a><span class="line-added"> 41 #include &quot;utilities/align.hpp&quot;</span>
 42 
 43 template &lt;class T&gt;
 44 inline void G1ScanClosureBase::prefetch_and_push(T* p, const oop obj) {
 45   // We&#39;re not going to even bother checking whether the object is
 46   // already forwarded or not, as this usually causes an immediate
 47   // stall. We&#39;ll try to prefetch the object (for write, given that
 48   // we might need to install the forwarding reference) and we&#39;ll
 49   // get back to it when pop it from the queue
 50   Prefetch::write(obj-&gt;mark_addr_raw(), 0);
 51   Prefetch::read(obj-&gt;mark_addr_raw(), (HeapWordSize*2));
 52 
 53   // slightly paranoid test; I&#39;m trying to catch potential
 54   // problems before we go into push_on_queue to know where the
 55   // problem is coming from
 56   assert((obj == RawAccess&lt;&gt;::oop_load(p)) ||
 57          (obj-&gt;is_forwarded() &amp;&amp;
 58          obj-&gt;forwardee() == RawAccess&lt;&gt;::oop_load(p)),
 59          &quot;p should still be pointing to obj or to its forwardee&quot;);
 60 
 61   _par_scan_state-&gt;push_on_queue(p);
 62 }
 63 
 64 template &lt;class T&gt;
<a name="2" id="anc2"></a><span class="line-modified"> 65 inline void G1ScanClosureBase::handle_non_cset_obj_common(G1HeapRegionAttr const region_attr, T* p, oop const obj) {</span>
<span class="line-modified"> 66   if (region_attr.is_humongous()) {</span>
 67     _g1h-&gt;set_humongous_is_live(obj);
<a name="3" id="anc3"></a><span class="line-modified"> 68   } else if (region_attr.is_optional()) {</span>
 69     _par_scan_state-&gt;remember_reference_into_optional_region(p);
 70   }
 71 }
 72 
 73 inline void G1ScanClosureBase::trim_queue_partially() {
 74   _par_scan_state-&gt;trim_queue_partially();
 75 }
 76 
 77 template &lt;class T&gt;
 78 inline void G1ScanEvacuatedObjClosure::do_oop_work(T* p) {
 79   T heap_oop = RawAccess&lt;&gt;::oop_load(p);
 80 
 81   if (CompressedOops::is_null(heap_oop)) {
 82     return;
 83   }
 84   oop obj = CompressedOops::decode_not_null(heap_oop);
<a name="4" id="anc4"></a><span class="line-modified"> 85   const G1HeapRegionAttr region_attr = _g1h-&gt;region_attr(obj);</span>
<span class="line-modified"> 86   if (region_attr.is_in_cset()) {</span>
 87     prefetch_and_push(p, obj);
 88   } else if (!HeapRegion::is_in_same_region(p, obj)) {
<a name="5" id="anc5"></a><span class="line-modified"> 89     handle_non_cset_obj_common(region_attr, p, obj);</span>
 90     assert(_scanning_in_young != Uninitialized, &quot;Scan location has not been initialized.&quot;);
 91     if (_scanning_in_young == True) {
 92       return;
 93     }
<a name="6" id="anc6"></a><span class="line-modified"> 94     _par_scan_state-&gt;enqueue_card_if_tracked(region_attr, p, obj);</span>
 95   }
 96 }
 97 
 98 template &lt;class T&gt;
 99 inline void G1CMOopClosure::do_oop_work(T* p) {
100   _task-&gt;deal_with_reference(p);
101 }
102 
103 template &lt;class T&gt;
104 inline void G1RootRegionScanClosure::do_oop_work(T* p) {
105   T heap_oop = RawAccess&lt;MO_VOLATILE&gt;::oop_load(p);
106   if (CompressedOops::is_null(heap_oop)) {
107     return;
108   }
109   oop obj = CompressedOops::decode_not_null(heap_oop);
110   _cm-&gt;mark_in_next_bitmap(_worker_id, obj);
111 }
112 
113 template &lt;class T&gt;
114 inline static void check_obj_during_refinement(T* p, oop const obj) {
115 #ifdef ASSERT
116   G1CollectedHeap* g1h = G1CollectedHeap::heap();
117   // can&#39;t do because of races
118   // assert(oopDesc::is_oop_or_null(obj), &quot;expected an oop&quot;);
<a name="7" id="anc7"></a><span class="line-modified">119   assert(is_object_aligned(obj), &quot;oop must be aligned&quot;);</span>
<span class="line-modified">120   assert(g1h-&gt;is_in_reserved(obj), &quot;oop must be in reserved&quot;);</span>
121 
122   HeapRegion* from = g1h-&gt;heap_region_containing(p);
123 
124   assert(from != NULL, &quot;from region must be non-NULL&quot;);
125   assert(from-&gt;is_in_reserved(p) ||
126          (from-&gt;is_humongous() &amp;&amp;
127           g1h-&gt;heap_region_containing(p)-&gt;is_humongous() &amp;&amp;
128           from-&gt;humongous_start_region() == g1h-&gt;heap_region_containing(p)-&gt;humongous_start_region()),
129          &quot;p &quot; PTR_FORMAT &quot; is not in the same region %u or part of the correct humongous object starting at region %u.&quot;,
130          p2i(p), from-&gt;hrm_index(), from-&gt;humongous_start_region()-&gt;hrm_index());
131 #endif // ASSERT
132 }
133 
134 template &lt;class T&gt;
135 inline void G1ConcurrentRefineOopClosure::do_oop_work(T* p) {
136   T o = RawAccess&lt;MO_VOLATILE&gt;::oop_load(p);
137   if (CompressedOops::is_null(o)) {
138     return;
139   }
140   oop obj = CompressedOops::decode_not_null(o);
141 
142   check_obj_during_refinement(p, obj);
143 
144   if (HeapRegion::is_in_same_region(p, obj)) {
145     // Normally this closure should only be called with cross-region references.
146     // But since Java threads are manipulating the references concurrently and we
147     // reload the values things may have changed.
148     // Also this check lets slip through references from a humongous continues region
149     // to its humongous start region, as they are in different regions, and adds a
150     // remembered set entry. This is benign (apart from memory usage), as we never
151     // try to either evacuate or eager reclaim humonguous arrays of j.l.O.
152     return;
153   }
154 
155   HeapRegionRemSet* to_rem_set = _g1h-&gt;heap_region_containing(obj)-&gt;rem_set();
156 
157   assert(to_rem_set != NULL, &quot;Need per-region &#39;into&#39; remsets.&quot;);
158   if (to_rem_set-&gt;is_tracked()) {
<a name="8" id="anc8"></a><span class="line-modified">159     to_rem_set-&gt;add_reference(p, _worker_id);</span>
160   }
161 }
162 
163 template &lt;class T&gt;
<a name="9" id="anc9"></a><span class="line-modified">164 inline void G1ScanCardClosure::do_oop_work(T* p) {</span>
165   T o = RawAccess&lt;&gt;::oop_load(p);
166   if (CompressedOops::is_null(o)) {
167     return;
168   }
169   oop obj = CompressedOops::decode_not_null(o);
170 
171   check_obj_during_refinement(p, obj);
172 
<a name="10" id="anc10"></a><span class="line-modified">173   assert(!_g1h-&gt;is_in_cset((HeapWord*)p),</span>
<span class="line-modified">174          &quot;Oop originates from &quot; PTR_FORMAT &quot; (region: %u) which is in the collection set.&quot;,</span>
<span class="line-modified">175          p2i(p), _g1h-&gt;addr_to_region((HeapWord*)p));</span>
<span class="line-added">176 </span>
<span class="line-added">177   const G1HeapRegionAttr region_attr = _g1h-&gt;region_attr(obj);</span>
<span class="line-added">178   if (region_attr.is_in_cset()) {</span>
179     // Since the source is always from outside the collection set, here we implicitly know
180     // that this is a cross-region reference too.
181     prefetch_and_push(p, obj);
182   } else if (!HeapRegion::is_in_same_region(p, obj)) {
<a name="11" id="anc11"></a><span class="line-modified">183     handle_non_cset_obj_common(region_attr, p, obj);</span>
<span class="line-modified">184     _par_scan_state-&gt;enqueue_card_if_tracked(region_attr, p, obj);</span>
185   }
186 }
187 
188 template &lt;class T&gt;
<a name="12" id="anc12"></a><span class="line-modified">189 inline void G1ScanRSForOptionalClosure::do_oop_work(T* p) {</span>
<span class="line-modified">190   const G1HeapRegionAttr region_attr = _g1h-&gt;region_attr(p);</span>
<span class="line-modified">191   // Entries in the optional collection set may start to originate from the collection</span>
<span class="line-added">192   // set after one or more increments. In this case, previously optional regions</span>
<span class="line-added">193   // became actual collection set regions. Filter them out here.</span>
<span class="line-added">194   if (region_attr.is_in_cset()) {</span>
195     return;
196   }
<a name="13" id="anc13"></a>











197   _scan_cl-&gt;do_oop_work(p);
198   _scan_cl-&gt;trim_queue_partially();
199 }
200 
201 void G1ParCopyHelper::do_cld_barrier(oop new_obj) {
202   if (_g1h-&gt;heap_region_containing(new_obj)-&gt;is_young()) {
203     _scanned_cld-&gt;record_modified_oops();
204   }
205 }
206 
207 void G1ParCopyHelper::mark_object(oop obj) {
208   assert(!_g1h-&gt;heap_region_containing(obj)-&gt;in_collection_set(), &quot;should not mark objects in the CSet&quot;);
209 
210   // We know that the object is not moving so it&#39;s safe to read its size.
211   _cm-&gt;mark_in_next_bitmap(_worker_id, obj);
212 }
213 
214 void G1ParCopyHelper::trim_queue_partially() {
215   _par_scan_state-&gt;trim_queue_partially();
216 }
217 
218 template &lt;G1Barrier barrier, G1Mark do_mark_object&gt;
219 template &lt;class T&gt;
220 void G1ParCopyClosure&lt;barrier, do_mark_object&gt;::do_oop_work(T* p) {
221   T heap_oop = RawAccess&lt;&gt;::oop_load(p);
222 
223   if (CompressedOops::is_null(heap_oop)) {
224     return;
225   }
226 
227   oop obj = CompressedOops::decode_not_null(heap_oop);
228 
229   assert(_worker_id == _par_scan_state-&gt;worker_id(), &quot;sanity&quot;);
230 
<a name="14" id="anc14"></a><span class="line-modified">231   const G1HeapRegionAttr state = _g1h-&gt;region_attr(obj);</span>
232   if (state.is_in_cset()) {
233     oop forwardee;
<a name="15" id="anc15"></a><span class="line-modified">234     markWord m = obj-&gt;mark_raw();</span>
<span class="line-modified">235     if (m.is_marked()) {</span>
<span class="line-modified">236       forwardee = (oop) m.decode_pointer();</span>
237     } else {
238       forwardee = _par_scan_state-&gt;copy_to_survivor_space(state, obj, m);
239     }
240     assert(forwardee != NULL, &quot;forwardee should not be NULL&quot;);
241     RawAccess&lt;IS_NOT_NULL&gt;::oop_store(p, forwardee);
242 
243     if (barrier == G1BarrierCLD) {
244       do_cld_barrier(forwardee);
245     }
246   } else {
247     if (state.is_humongous()) {
248       _g1h-&gt;set_humongous_is_live(obj);
<a name="16" id="anc16"></a><span class="line-modified">249     } else if ((barrier != G1BarrierNoOptRoots) &amp;&amp; state.is_optional()) {</span>
250       _par_scan_state-&gt;remember_root_into_optional_region(p);
251     }
252 
253     // The object is not in collection set. If we&#39;re a root scanning
254     // closure during an initial mark pause then attempt to mark the object.
255     if (do_mark_object == G1MarkFromRoot) {
256       mark_object(obj);
257     }
258   }
259   trim_queue_partially();
260 }
261 
262 template &lt;class T&gt; void G1RebuildRemSetClosure::do_oop_work(T* p) {
263   oop const obj = RawAccess&lt;MO_VOLATILE&gt;::oop_load(p);
264   if (obj == NULL) {
265     return;
266   }
267 
268   if (HeapRegion::is_in_same_region(p, obj)) {
269     return;
270   }
271 
272   HeapRegion* to = _g1h-&gt;heap_region_containing(obj);
273   HeapRegionRemSet* rem_set = to-&gt;rem_set();
274   rem_set-&gt;add_reference(p, _worker_id);
275 }
276 
277 #endif // SHARE_GC_G1_G1OOPCLOSURES_INLINE_HPP
<a name="17" id="anc17"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="17" type="hidden" />
</body>
</html>