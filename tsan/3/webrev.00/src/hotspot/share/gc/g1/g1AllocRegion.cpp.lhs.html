<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/gc/g1/g1AllocRegion.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
    <script type="text/javascript" src="../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
<a name="1" id="anc1"></a><span class="line-modified">  2  * Copyright (c) 2011, 2018, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;gc/g1/g1AllocRegion.inline.hpp&quot;
 27 #include &quot;gc/g1/g1EvacStats.inline.hpp&quot;
 28 #include &quot;gc/g1/g1CollectedHeap.inline.hpp&quot;
 29 #include &quot;logging/log.hpp&quot;
 30 #include &quot;logging/logStream.hpp&quot;
 31 #include &quot;memory/resourceArea.hpp&quot;
 32 #include &quot;runtime/orderAccess.hpp&quot;
 33 #include &quot;utilities/align.hpp&quot;
 34 
 35 G1CollectedHeap* G1AllocRegion::_g1h = NULL;
 36 HeapRegion* G1AllocRegion::_dummy_region = NULL;
 37 
 38 void G1AllocRegion::setup(G1CollectedHeap* g1h, HeapRegion* dummy_region) {
 39   assert(_dummy_region == NULL, &quot;should be set once&quot;);
 40   assert(dummy_region != NULL, &quot;pre-condition&quot;);
 41   assert(dummy_region-&gt;free() == 0, &quot;pre-condition&quot;);
 42 
 43   // Make sure that any allocation attempt on this region will fail
 44   // and will not trigger any asserts.
 45   assert(dummy_region-&gt;allocate_no_bot_updates(1) == NULL, &quot;should fail&quot;);
 46   assert(dummy_region-&gt;allocate(1) == NULL, &quot;should fail&quot;);
 47   DEBUG_ONLY(size_t assert_tmp);
 48   assert(dummy_region-&gt;par_allocate_no_bot_updates(1, 1, &amp;assert_tmp) == NULL, &quot;should fail&quot;);
 49   assert(dummy_region-&gt;par_allocate(1, 1, &amp;assert_tmp) == NULL, &quot;should fail&quot;);
 50 
 51   _g1h = g1h;
 52   _dummy_region = dummy_region;
 53 }
 54 
 55 size_t G1AllocRegion::fill_up_remaining_space(HeapRegion* alloc_region) {
 56   assert(alloc_region != NULL &amp;&amp; alloc_region != _dummy_region,
 57          &quot;pre-condition&quot;);
 58   size_t result = 0;
 59 
 60   // Other threads might still be trying to allocate using a CAS out
 61   // of the region we are trying to retire, as they can do so without
 62   // holding the lock. So, we first have to make sure that noone else
 63   // can allocate out of it by doing a maximal allocation. Even if our
 64   // CAS attempt fails a few times, we&#39;ll succeed sooner or later
 65   // given that failed CAS attempts mean that the region is getting
 66   // closed to being full.
 67   size_t free_word_size = alloc_region-&gt;free() / HeapWordSize;
 68 
 69   // This is the minimum free chunk we can turn into a dummy
 70   // object. If the free space falls below this, then noone can
 71   // allocate in this region anyway (all allocation requests will be
 72   // of a size larger than this) so we won&#39;t have to perform the dummy
 73   // allocation.
 74   size_t min_word_size_to_fill = CollectedHeap::min_fill_size();
 75 
 76   while (free_word_size &gt;= min_word_size_to_fill) {
 77     HeapWord* dummy = par_allocate(alloc_region, free_word_size);
 78     if (dummy != NULL) {
 79       // If the allocation was successful we should fill in the space.
 80       CollectedHeap::fill_with_object(dummy, free_word_size);
 81       alloc_region-&gt;set_pre_dummy_top(dummy);
 82       result += free_word_size * HeapWordSize;
 83       break;
 84     }
 85 
 86     free_word_size = alloc_region-&gt;free() / HeapWordSize;
 87     // It&#39;s also possible that someone else beats us to the
 88     // allocation and they fill up the region. In that case, we can
 89     // just get out of the loop.
 90   }
 91   result += alloc_region-&gt;free();
 92 
 93   assert(alloc_region-&gt;free() / HeapWordSize &lt; min_word_size_to_fill,
 94          &quot;post-condition&quot;);
 95   return result;
 96 }
 97 
 98 size_t G1AllocRegion::retire_internal(HeapRegion* alloc_region, bool fill_up) {
 99   // We never have to check whether the active region is empty or not,
100   // and potentially free it if it is, given that it&#39;s guaranteed that
101   // it will never be empty.
102   size_t waste = 0;
103   assert_alloc_region(!alloc_region-&gt;is_empty(),
104       &quot;the alloc region should never be empty&quot;);
105 
106   if (fill_up) {
107     waste = fill_up_remaining_space(alloc_region);
108   }
109 
110   assert_alloc_region(alloc_region-&gt;used() &gt;= _used_bytes_before, &quot;invariant&quot;);
111   size_t allocated_bytes = alloc_region-&gt;used() - _used_bytes_before;
112   retire_region(alloc_region, allocated_bytes);
113   _used_bytes_before = 0;
114 
115   return waste;
116 }
117 
118 size_t G1AllocRegion::retire(bool fill_up) {
119   assert_alloc_region(_alloc_region != NULL, &quot;not initialized properly&quot;);
120 
121   size_t waste = 0;
122 
123   trace(&quot;retiring&quot;);
124   HeapRegion* alloc_region = _alloc_region;
125   if (alloc_region != _dummy_region) {
126     waste = retire_internal(alloc_region, fill_up);
127     reset_alloc_region();
128   }
129   trace(&quot;retired&quot;);
130 
131   return waste;
132 }
133 
134 HeapWord* G1AllocRegion::new_alloc_region_and_allocate(size_t word_size,
135                                                        bool force) {
136   assert_alloc_region(_alloc_region == _dummy_region, &quot;pre-condition&quot;);
137   assert_alloc_region(_used_bytes_before == 0, &quot;pre-condition&quot;);
138 
139   trace(&quot;attempting region allocation&quot;);
140   HeapRegion* new_alloc_region = allocate_new_region(word_size, force);
141   if (new_alloc_region != NULL) {
142     new_alloc_region-&gt;reset_pre_dummy_top();
143     // Need to do this before the allocation
144     _used_bytes_before = new_alloc_region-&gt;used();
145     HeapWord* result = allocate(new_alloc_region, word_size);
146     assert_alloc_region(result != NULL, &quot;the allocation should succeeded&quot;);
147 
148     OrderAccess::storestore();
149     // Note that we first perform the allocation and then we store the
150     // region in _alloc_region. This is the reason why an active region
151     // can never be empty.
152     update_alloc_region(new_alloc_region);
153     trace(&quot;region allocation successful&quot;);
154     return result;
155   } else {
156     trace(&quot;region allocation failed&quot;);
157     return NULL;
158   }
159   ShouldNotReachHere();
160 }
161 
162 void G1AllocRegion::init() {
163   trace(&quot;initializing&quot;);
164   assert_alloc_region(_alloc_region == NULL &amp;&amp; _used_bytes_before == 0, &quot;pre-condition&quot;);
165   assert_alloc_region(_dummy_region != NULL, &quot;should have been set&quot;);
166   _alloc_region = _dummy_region;
167   _count = 0;
168   trace(&quot;initialized&quot;);
169 }
170 
171 void G1AllocRegion::set(HeapRegion* alloc_region) {
172   trace(&quot;setting&quot;);
173   // We explicitly check that the region is not empty to make sure we
174   // maintain the &quot;the alloc region cannot be empty&quot; invariant.
175   assert_alloc_region(alloc_region != NULL &amp;&amp; !alloc_region-&gt;is_empty(), &quot;pre-condition&quot;);
176   assert_alloc_region(_alloc_region == _dummy_region &amp;&amp;
177                          _used_bytes_before == 0 &amp;&amp; _count == 0,
178                          &quot;pre-condition&quot;);
179 
180   _used_bytes_before = alloc_region-&gt;used();
181   _alloc_region = alloc_region;
182   _count += 1;
183   trace(&quot;set&quot;);
184 }
185 
186 void G1AllocRegion::update_alloc_region(HeapRegion* alloc_region) {
187   trace(&quot;update&quot;);
188   // We explicitly check that the region is not empty to make sure we
189   // maintain the &quot;the alloc region cannot be empty&quot; invariant.
190   assert_alloc_region(alloc_region != NULL &amp;&amp; !alloc_region-&gt;is_empty(), &quot;pre-condition&quot;);
191 
192   _alloc_region = alloc_region;
193   _count += 1;
194   trace(&quot;updated&quot;);
195 }
196 
197 HeapRegion* G1AllocRegion::release() {
198   trace(&quot;releasing&quot;);
199   HeapRegion* alloc_region = _alloc_region;
200   retire(false /* fill_up */);
201   assert_alloc_region(_alloc_region == _dummy_region, &quot;post-condition of retire()&quot;);
202   _alloc_region = NULL;
203   trace(&quot;released&quot;);
204   return (alloc_region == _dummy_region) ? NULL : alloc_region;
205 }
206 
207 #ifndef PRODUCT
208 void G1AllocRegion::trace(const char* str, size_t min_word_size, size_t desired_word_size, size_t actual_word_size, HeapWord* result) {
209   // All the calls to trace that set either just the size or the size
210   // and the result are considered part of detailed tracing and are
211   // skipped during other tracing.
212 
213   Log(gc, alloc, region) log;
214 
215   if (!log.is_debug()) {
216     return;
217   }
218 
219   bool detailed_info = log.is_trace();
220 
221   if ((actual_word_size == 0 &amp;&amp; result == NULL) || detailed_info) {
222     ResourceMark rm;
223     LogStream ls_trace(log.trace());
224     LogStream ls_debug(log.debug());
225     outputStream* out = detailed_info ? &amp;ls_trace : &amp;ls_debug;
226 
227     out-&gt;print(&quot;%s: %u &quot;, _name, _count);
228 
229     if (_alloc_region == NULL) {
230       out-&gt;print(&quot;NULL&quot;);
231     } else if (_alloc_region == _dummy_region) {
232       out-&gt;print(&quot;DUMMY&quot;);
233     } else {
234       out-&gt;print(HR_FORMAT, HR_FORMAT_PARAMS(_alloc_region));
235     }
236 
237     out-&gt;print(&quot; : %s&quot;, str);
238 
239     if (detailed_info) {
240       if (result != NULL) {
241         out-&gt;print(&quot; min &quot; SIZE_FORMAT &quot; desired &quot; SIZE_FORMAT &quot; actual &quot; SIZE_FORMAT &quot; &quot; PTR_FORMAT,
242                      min_word_size, desired_word_size, actual_word_size, p2i(result));
243       } else if (min_word_size != 0) {
244         out-&gt;print(&quot; min &quot; SIZE_FORMAT &quot; desired &quot; SIZE_FORMAT, min_word_size, desired_word_size);
245       }
246     }
247     out-&gt;cr();
248   }
249 }
250 #endif // PRODUCT
251 
252 G1AllocRegion::G1AllocRegion(const char* name,
<a name="2" id="anc2"></a><span class="line-modified">253                              bool bot_updates)</span>

254   : _alloc_region(NULL),
255     _count(0),
256     _used_bytes_before(0),
257     _bot_updates(bot_updates),
<a name="3" id="anc3"></a><span class="line-modified">258     _name(name)</span>

259  { }
260 
261 HeapRegion* MutatorAllocRegion::allocate_new_region(size_t word_size,
262                                                     bool force) {
<a name="4" id="anc4"></a><span class="line-modified">263   return _g1h-&gt;new_mutator_alloc_region(word_size, force);</span>
264 }
265 
266 void MutatorAllocRegion::retire_region(HeapRegion* alloc_region,
267                                        size_t allocated_bytes) {
268   _g1h-&gt;retire_mutator_alloc_region(alloc_region, allocated_bytes);
269 }
270 
271 void MutatorAllocRegion::init() {
272   assert(_retained_alloc_region == NULL, &quot;Pre-condition&quot;);
273   G1AllocRegion::init();
274   _wasted_bytes = 0;
275 }
276 
277 bool MutatorAllocRegion::should_retain(HeapRegion* region) {
278   size_t free_bytes = region-&gt;free();
279   if (free_bytes &lt; MinTLABSize) {
280     return false;
281   }
282 
283   if (_retained_alloc_region != NULL &amp;&amp;
284       free_bytes &lt; _retained_alloc_region-&gt;free()) {
285     return false;
286   }
287 
288   return true;
289 }
290 
291 size_t MutatorAllocRegion::retire(bool fill_up) {
292   size_t waste = 0;
293   trace(&quot;retiring&quot;);
294   HeapRegion* current_region = get();
295   if (current_region != NULL) {
296     // Retain the current region if it fits a TLAB and has more
297     // free than the currently retained region.
298     if (should_retain(current_region)) {
299       trace(&quot;mutator retained&quot;);
300       if (_retained_alloc_region != NULL) {
301         waste = retire_internal(_retained_alloc_region, true);
302       }
303       _retained_alloc_region = current_region;
304     } else {
305       waste = retire_internal(current_region, fill_up);
306     }
307     reset_alloc_region();
308   }
309 
310   _wasted_bytes += waste;
311   trace(&quot;retired&quot;);
312   return waste;
313 }
314 
315 size_t MutatorAllocRegion::used_in_alloc_regions() {
316   size_t used = 0;
317   HeapRegion* hr = get();
318   if (hr != NULL) {
319     used += hr-&gt;used();
320   }
321 
322   hr = _retained_alloc_region;
323   if (hr != NULL) {
324     used += hr-&gt;used();
325   }
326   return used;
327 }
328 
329 HeapRegion* MutatorAllocRegion::release() {
330   HeapRegion* ret = G1AllocRegion::release();
331 
332   // The retained alloc region must be retired and this must be
333   // done after the above call to release the mutator alloc region,
334   // since it might update the _retained_alloc_region member.
335   if (_retained_alloc_region != NULL) {
336     _wasted_bytes += retire_internal(_retained_alloc_region, false);
337     _retained_alloc_region = NULL;
338   }
339   log_debug(gc, alloc, region)(&quot;Mutator Allocation stats, regions: %u, wasted size: &quot; SIZE_FORMAT &quot;%s (%4.1f%%)&quot;,
340                                count(),
341                                byte_size_in_proper_unit(_wasted_bytes),
342                                proper_unit_for_byte_size(_wasted_bytes),
343                                percent_of(_wasted_bytes, count() * HeapRegion::GrainBytes));
344   return ret;
345 }
346 
347 HeapRegion* G1GCAllocRegion::allocate_new_region(size_t word_size,
348                                                  bool force) {
349   assert(!force, &quot;not supported for GC alloc regions&quot;);
<a name="5" id="anc5"></a><span class="line-modified">350   return _g1h-&gt;new_gc_alloc_region(word_size, _purpose);</span>
351 }
352 
353 void G1GCAllocRegion::retire_region(HeapRegion* alloc_region,
354                                     size_t allocated_bytes) {
355   _g1h-&gt;retire_gc_alloc_region(alloc_region, allocated_bytes, _purpose);
356 }
357 
358 size_t G1GCAllocRegion::retire(bool fill_up) {
359   HeapRegion* retired = get();
360   size_t end_waste = G1AllocRegion::retire(fill_up);
361   // Do not count retirement of the dummy allocation region.
362   if (retired != NULL) {
363     _stats-&gt;add_region_end_waste(end_waste / HeapWordSize);
364   }
365   return end_waste;
366 }
367 
368 HeapRegion* OldGCAllocRegion::release() {
369   HeapRegion* cur = get();
370   if (cur != NULL) {
371     // Determine how far we are from the next card boundary. If it is smaller than
372     // the minimum object size we can allocate into, expand into the next card.
373     HeapWord* top = cur-&gt;top();
374     HeapWord* aligned_top = align_up(top, BOTConstants::N_bytes);
375 
376     size_t to_allocate_words = pointer_delta(aligned_top, top, HeapWordSize);
377 
378     if (to_allocate_words != 0) {
379       // We are not at a card boundary. Fill up, possibly into the next, taking the
380       // end of the region and the minimum object size into account.
381       to_allocate_words = MIN2(pointer_delta(cur-&gt;end(), cur-&gt;top(), HeapWordSize),
382                                MAX2(to_allocate_words, G1CollectedHeap::min_fill_size()));
383 
384       // Skip allocation if there is not enough space to allocate even the smallest
385       // possible object. In this case this region will not be retained, so the
386       // original problem cannot occur.
387       if (to_allocate_words &gt;= G1CollectedHeap::min_fill_size()) {
388         HeapWord* dummy = attempt_allocation(to_allocate_words);
389         CollectedHeap::fill_with_object(dummy, to_allocate_words);
390       }
391     }
392   }
393   return G1AllocRegion::release();
394 }
<a name="6" id="anc6"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="6" type="hidden" />
</body>
</html>