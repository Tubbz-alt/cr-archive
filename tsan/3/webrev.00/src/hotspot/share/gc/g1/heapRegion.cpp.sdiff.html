<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/g1/heapRegion.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="g1_globals.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="heapRegion.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/g1/heapRegion.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;code/nmethod.hpp&quot;
 27 #include &quot;gc/g1/g1BlockOffsetTable.inline.hpp&quot;
 28 #include &quot;gc/g1/g1CollectedHeap.inline.hpp&quot;
 29 #include &quot;gc/g1/g1CollectionSet.hpp&quot;
 30 #include &quot;gc/g1/g1HeapRegionTraceType.hpp&quot;

 31 #include &quot;gc/g1/g1OopClosures.inline.hpp&quot;
 32 #include &quot;gc/g1/heapRegion.inline.hpp&quot;
 33 #include &quot;gc/g1/heapRegionBounds.inline.hpp&quot;
 34 #include &quot;gc/g1/heapRegionManager.inline.hpp&quot;
 35 #include &quot;gc/g1/heapRegionRemSet.hpp&quot;
 36 #include &quot;gc/g1/heapRegionTracer.hpp&quot;
 37 #include &quot;gc/shared/genOopClosures.inline.hpp&quot;
<span class="line-removed"> 38 #include &quot;gc/shared/space.inline.hpp&quot;</span>
 39 #include &quot;logging/log.hpp&quot;
 40 #include &quot;logging/logStream.hpp&quot;
 41 #include &quot;memory/iterator.inline.hpp&quot;
 42 #include &quot;memory/resourceArea.hpp&quot;
 43 #include &quot;oops/access.inline.hpp&quot;
 44 #include &quot;oops/compressedOops.inline.hpp&quot;
 45 #include &quot;oops/oop.inline.hpp&quot;
<span class="line-removed"> 46 #include &quot;runtime/atomic.hpp&quot;</span>
<span class="line-removed"> 47 #include &quot;runtime/orderAccess.hpp&quot;</span>
<span class="line-removed"> 48 #include &quot;utilities/growableArray.hpp&quot;</span>
 49 
 50 int    HeapRegion::LogOfHRGrainBytes = 0;
 51 int    HeapRegion::LogOfHRGrainWords = 0;

 52 size_t HeapRegion::GrainBytes        = 0;
 53 size_t HeapRegion::GrainWords        = 0;
 54 size_t HeapRegion::CardsPerRegion    = 0;
 55 
 56 size_t HeapRegion::max_region_size() {
 57   return HeapRegionBounds::max_size();
 58 }
 59 
 60 size_t HeapRegion::min_region_size_in_words() {
 61   return HeapRegionBounds::min_size() &gt;&gt; LogHeapWordSize;
 62 }
 63 
 64 void HeapRegion::setup_heap_region_size(size_t initial_heap_size, size_t max_heap_size) {
 65   size_t region_size = G1HeapRegionSize;
 66   if (FLAG_IS_DEFAULT(G1HeapRegionSize)) {
 67     size_t average_heap_size = (initial_heap_size + max_heap_size) / 2;
 68     region_size = MAX2(average_heap_size / HeapRegionBounds::target_number(),
 69                        HeapRegionBounds::min_size());
 70   }
 71 
</pre>
<hr />
<pre>
 88   // Now, set up the globals.
 89   guarantee(LogOfHRGrainBytes == 0, &quot;we should only set it once&quot;);
 90   LogOfHRGrainBytes = region_size_log;
 91 
 92   guarantee(LogOfHRGrainWords == 0, &quot;we should only set it once&quot;);
 93   LogOfHRGrainWords = LogOfHRGrainBytes - LogHeapWordSize;
 94 
 95   guarantee(GrainBytes == 0, &quot;we should only set it once&quot;);
 96   // The cast to int is safe, given that we&#39;ve bounded region_size by
 97   // MIN_REGION_SIZE and MAX_REGION_SIZE.
 98   GrainBytes = region_size;
 99   log_info(gc, heap)(&quot;Heap region size: &quot; SIZE_FORMAT &quot;M&quot;, GrainBytes / M);
100 
101   guarantee(GrainWords == 0, &quot;we should only set it once&quot;);
102   GrainWords = GrainBytes &gt;&gt; LogHeapWordSize;
103   guarantee((size_t) 1 &lt;&lt; LogOfHRGrainWords == GrainWords, &quot;sanity&quot;);
104 
105   guarantee(CardsPerRegion == 0, &quot;we should only set it once&quot;);
106   CardsPerRegion = GrainBytes &gt;&gt; G1CardTable::card_shift;
107 


108   if (G1HeapRegionSize != GrainBytes) {
<span class="line-modified">109     FLAG_SET_ERGO(size_t, G1HeapRegionSize, GrainBytes);</span>
110   }
111 }
112 
<span class="line-modified">113 void HeapRegion::hr_clear(bool keep_remset, bool clear_space, bool locked) {</span>













114   assert(_humongous_start_region == NULL,
115          &quot;we should have already filtered out humongous regions&quot;);
116   assert(!in_collection_set(),
117          &quot;Should not clear heap region %u in the collection set&quot;, hrm_index());
118 
<span class="line-modified">119   set_young_index_in_cset(-1);</span>

120   uninstall_surv_rate_group();
121   set_free();
122   reset_pre_dummy_top();
123 
<span class="line-modified">124   if (!keep_remset) {</span>
<span class="line-removed">125     if (locked) {</span>
<span class="line-removed">126       rem_set()-&gt;clear_locked();</span>
<span class="line-removed">127     } else {</span>
<span class="line-removed">128       rem_set()-&gt;clear();</span>
<span class="line-removed">129     }</span>
<span class="line-removed">130   }</span>
131 
132   zero_marked_bytes();
133 
134   init_top_at_mark_start();
135   if (clear_space) clear(SpaceDecorator::Mangle);



136 }
137 
138 void HeapRegion::clear_cardtable() {
139   G1CardTable* ct = G1CollectedHeap::heap()-&gt;card_table();
140   ct-&gt;clear(MemRegion(bottom(), end()));
141 }
142 
143 void HeapRegion::calc_gc_efficiency() {
144   // GC efficiency is the ratio of how much space would be
145   // reclaimed over how long we predict it would take to reclaim it.
<span class="line-modified">146   G1CollectedHeap* g1h = G1CollectedHeap::heap();</span>
<span class="line-removed">147   G1Policy* policy = g1h-&gt;policy();</span>
148 
149   // Retrieve a prediction of the elapsed time for this region for
150   // a mixed gc because the region will only be evacuated during a
151   // mixed gc.
<span class="line-modified">152   double region_elapsed_time_ms =</span>
<span class="line-removed">153     policy-&gt;predict_region_elapsed_time_ms(this, false /* for_young_gc */);</span>
154   _gc_efficiency = (double) reclaimable_bytes() / region_elapsed_time_ms;
155 }
156 
157 void HeapRegion::set_free() {
158   report_region_type_change(G1HeapRegionTraceType::Free);
159   _type.set_free();
160 }
161 
162 void HeapRegion::set_eden() {
163   report_region_type_change(G1HeapRegionTraceType::Eden);
164   _type.set_eden();
165 }
166 
167 void HeapRegion::set_eden_pre_gc() {
168   report_region_type_change(G1HeapRegionTraceType::Eden);
169   _type.set_eden_pre_gc();
170 }
171 
172 void HeapRegion::set_survivor() {
173   report_region_type_change(G1HeapRegionTraceType::Survivor);
</pre>
<hr />
<pre>
213 
214   report_region_type_change(G1HeapRegionTraceType::ContinuesHumongous);
215   _type.set_continues_humongous();
216   _humongous_start_region = first_hr;
217 
218   _bot_part.set_object_can_span(true);
219 }
220 
221 void HeapRegion::clear_humongous() {
222   assert(is_humongous(), &quot;pre-condition&quot;);
223 
224   assert(capacity() == HeapRegion::GrainBytes, &quot;pre-condition&quot;);
225   _humongous_start_region = NULL;
226 
227   _bot_part.set_object_can_span(false);
228 }
229 
230 HeapRegion::HeapRegion(uint hrm_index,
231                        G1BlockOffsetTable* bot,
232                        MemRegion mr) :
<span class="line-modified">233     G1ContiguousSpace(bot),</span>
<span class="line-modified">234     _rem_set(NULL),</span>
<span class="line-modified">235     _hrm_index(hrm_index),</span>
<span class="line-modified">236     _type(),</span>
<span class="line-modified">237     _humongous_start_region(NULL),</span>
<span class="line-modified">238     _evacuation_failed(false),</span>
<span class="line-modified">239     _next(NULL), _prev(NULL),</span>







240 #ifdef ASSERT
<span class="line-modified">241     _containing_set(NULL),</span>
242 #endif
<span class="line-modified">243     _prev_marked_bytes(0), _next_marked_bytes(0), _gc_efficiency(0.0),</span>
<span class="line-modified">244     _index_in_opt_cset(G1OptionalCSet::InvalidCSetIndex), _young_index_in_cset(-1),</span>
<span class="line-modified">245     _surv_rate_group(NULL), _age_index(-1),</span>
<span class="line-modified">246     _prev_top_at_mark_start(NULL), _next_top_at_mark_start(NULL),</span>
<span class="line-modified">247     _recorded_rs_length(0), _predicted_elapsed_time_ms(0)</span>
248 {
<span class="line-modified">249   _rem_set = new HeapRegionRemSet(bot, this);</span>

250 
<span class="line-modified">251   initialize(mr);</span>

252 }
253 
<span class="line-modified">254 void HeapRegion::initialize(MemRegion mr, bool clear_space, bool mangle_space) {</span>
255   assert(_rem_set-&gt;is_empty(), &quot;Remembered set must be empty&quot;);
256 
<span class="line-modified">257   G1ContiguousSpace::initialize(mr, clear_space, mangle_space);</span>


258 
<span class="line-removed">259   hr_clear(false /*par*/, false /*clear_space*/);</span>
260   set_top(bottom());




261 }
262 
263 void HeapRegion::report_region_type_change(G1HeapRegionTraceType::Type to) {
264   HeapRegionTracer::send_region_type_change(_hrm_index,
265                                             get_trace_type(),
266                                             to,
267                                             (uintptr_t)bottom(),
268                                             used());
269 }
270 
271 void HeapRegion::note_self_forwarding_removal_start(bool during_initial_mark,
272                                                     bool during_conc_mark) {
273   // We always recreate the prev marking info and we&#39;ll explicitly
274   // mark all objects we find to be self-forwarded on the prev
275   // bitmap. So all objects need to be below PTAMS.
276   _prev_marked_bytes = 0;
277 
278   if (during_initial_mark) {
279     // During initial-mark, we&#39;ll also explicitly mark all objects
280     // we find to be self-forwarded on the next bitmap. So all
</pre>
<hr />
<pre>
317 
318 void HeapRegion::strong_code_roots_do(CodeBlobClosure* blk) const {
319   HeapRegionRemSet* hrrs = rem_set();
320   hrrs-&gt;strong_code_roots_do(blk);
321 }
322 
323 class VerifyStrongCodeRootOopClosure: public OopClosure {
324   const HeapRegion* _hr;
325   bool _failures;
326   bool _has_oops_in_region;
327 
328   template &lt;class T&gt; void do_oop_work(T* p) {
329     T heap_oop = RawAccess&lt;&gt;::oop_load(p);
330     if (!CompressedOops::is_null(heap_oop)) {
331       oop obj = CompressedOops::decode_not_null(heap_oop);
332 
333       // Note: not all the oops embedded in the nmethod are in the
334       // current region. We only look at those which are.
335       if (_hr-&gt;is_in(obj)) {
336         // Object is in the region. Check that its less than top
<span class="line-modified">337         if (_hr-&gt;top() &lt;= (HeapWord*)obj) {</span>
338           // Object is above top
339           log_error(gc, verify)(&quot;Object &quot; PTR_FORMAT &quot; in region &quot; HR_FORMAT &quot; is above top &quot;,
340                                 p2i(obj), HR_FORMAT_PARAMS(_hr));
341           _failures = true;
342           return;
343         }
344         // Nmethod has at least one oop in the current region
345         _has_oops_in_region = true;
346       }
347     }
348   }
349 
350 public:
351   VerifyStrongCodeRootOopClosure(const HeapRegion* hr):
352     _hr(hr), _failures(false), _has_oops_in_region(false) {}
353 
354   void do_oop(narrowOop* p) { do_oop_work(p); }
355   void do_oop(oop* p)       { do_oop_work(p); }
356 
357   bool failures()           { return _failures; }
</pre>
<hr />
<pre>
423   }
424 
425   if (is_continues_humongous()) {
426     if (strong_code_roots_length &gt; 0) {
427       log_error(gc, verify)(&quot;region &quot; HR_FORMAT &quot; is a continuation of a humongous region but has &quot; SIZE_FORMAT &quot; code root entries&quot;,
428                             HR_FORMAT_PARAMS(this), strong_code_roots_length);
429       *failures = true;
430     }
431     return;
432   }
433 
434   VerifyStrongCodeRootCodeBlobClosure cb_cl(this);
435   strong_code_roots_do(&amp;cb_cl);
436 
437   if (cb_cl.failures()) {
438     *failures = true;
439   }
440 }
441 
442 void HeapRegion::print() const { print_on(tty); }

443 void HeapRegion::print_on(outputStream* st) const {
444   st-&gt;print(&quot;|%4u&quot;, this-&gt;_hrm_index);
445   st-&gt;print(&quot;|&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT,
446             p2i(bottom()), p2i(top()), p2i(end()));
447   st-&gt;print(&quot;|%3d%%&quot;, (int) ((double) used() * 100 / capacity()));
448   st-&gt;print(&quot;|%2s&quot;, get_short_type_str());
449   if (in_collection_set()) {
450     st-&gt;print(&quot;|CS&quot;);
451   } else {
452     st-&gt;print(&quot;|  &quot;);
453   }
<span class="line-modified">454   st-&gt;print_cr(&quot;|TAMS &quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT &quot;| %s &quot;,</span>
455                p2i(prev_top_at_mark_start()), p2i(next_top_at_mark_start()), rem_set()-&gt;get_state_str());









456 }
457 
458 class G1VerificationClosure : public BasicOopIterateClosure {
459 protected:
460   G1CollectedHeap* _g1h;
461   G1CardTable *_ct;
462   oop _containing_obj;
463   bool _failures;
464   int _n_failures;
465   VerifyOption _vo;
466 public:
467   // _vo == UsePrevMarking -&gt; use &quot;prev&quot; marking information,
468   // _vo == UseNextMarking -&gt; use &quot;next&quot; marking information,
469   // _vo == UseFullMarking -&gt; use &quot;next&quot; marking bitmap but no TAMS.
470   G1VerificationClosure(G1CollectedHeap* g1h, VerifyOption vo) :
471     _g1h(g1h), _ct(g1h-&gt;card_table()),
472     _containing_obj(NULL), _failures(false), _n_failures(0), _vo(vo) {
473   }
474 
475   void set_containing_obj(oop obj) {
</pre>
<hr />
<pre>
497 public:
498   VerifyLiveClosure(G1CollectedHeap* g1h, VerifyOption vo) : G1VerificationClosure(g1h, vo) {}
499   virtual void do_oop(narrowOop* p) { do_oop_work(p); }
500   virtual void do_oop(oop* p) { do_oop_work(p); }
501 
502   template &lt;class T&gt;
503   void do_oop_work(T* p) {
504     assert(_containing_obj != NULL, &quot;Precondition&quot;);
505     assert(!_g1h-&gt;is_obj_dead_cond(_containing_obj, _vo),
506       &quot;Precondition&quot;);
507     verify_liveness(p);
508   }
509 
510   template &lt;class T&gt;
511   void verify_liveness(T* p) {
512     T heap_oop = RawAccess&lt;&gt;::oop_load(p);
513     Log(gc, verify) log;
514     if (!CompressedOops::is_null(heap_oop)) {
515       oop obj = CompressedOops::decode_not_null(heap_oop);
516       bool failed = false;
<span class="line-modified">517       if (!_g1h-&gt;is_in_closed_subset(obj) || _g1h-&gt;is_obj_dead_cond(obj, _vo)) {</span>
<span class="line-modified">518         MutexLockerEx x(ParGCRareEvent_lock,</span>
519           Mutex::_no_safepoint_check_flag);
520 
521         if (!_failures) {
522           log.error(&quot;----------&quot;);
523         }
524         ResourceMark rm;
<span class="line-modified">525         if (!_g1h-&gt;is_in_closed_subset(obj)) {</span>
526           HeapRegion* from = _g1h-&gt;heap_region_containing((HeapWord*)p);
527           log.error(&quot;Field &quot; PTR_FORMAT &quot; of live obj &quot; PTR_FORMAT &quot; in region &quot; HR_FORMAT,
528                     p2i(p), p2i(_containing_obj), HR_FORMAT_PARAMS(from));
529           LogStream ls(log.error());
530           print_object(&amp;ls, _containing_obj);
531           HeapRegion* const to = _g1h-&gt;heap_region_containing(obj);
532           log.error(&quot;points to obj &quot; PTR_FORMAT &quot; in region &quot; HR_FORMAT &quot; remset %s&quot;,
533                     p2i(obj), HR_FORMAT_PARAMS(to), to-&gt;rem_set()-&gt;get_state_str());
534         } else {
535           HeapRegion* from = _g1h-&gt;heap_region_containing((HeapWord*)p);
<span class="line-modified">536           HeapRegion* to = _g1h-&gt;heap_region_containing((HeapWord*)obj);</span>
537           log.error(&quot;Field &quot; PTR_FORMAT &quot; of live obj &quot; PTR_FORMAT &quot; in region &quot; HR_FORMAT,
538                     p2i(p), p2i(_containing_obj), HR_FORMAT_PARAMS(from));
539           LogStream ls(log.error());
540           print_object(&amp;ls, _containing_obj);
541           log.error(&quot;points to dead obj &quot; PTR_FORMAT &quot; in region &quot; HR_FORMAT,
542                     p2i(obj), HR_FORMAT_PARAMS(to));
543           print_object(&amp;ls, obj);
544         }
545         log.error(&quot;----------&quot;);
546         _failures = true;
547         failed = true;
548         _n_failures++;
549       }
550     }
551   }
552 };
553 
554 class VerifyRemSetClosure : public G1VerificationClosure {
555 public:
556   VerifyRemSetClosure(G1CollectedHeap* g1h, VerifyOption vo) : G1VerificationClosure(g1h, vo) {}
</pre>
<hr />
<pre>
570     T heap_oop = RawAccess&lt;&gt;::oop_load(p);
571     Log(gc, verify) log;
572     if (!CompressedOops::is_null(heap_oop)) {
573       oop obj = CompressedOops::decode_not_null(heap_oop);
574       HeapRegion* from = _g1h-&gt;heap_region_containing((HeapWord*)p);
575       HeapRegion* to = _g1h-&gt;heap_region_containing(obj);
576       if (from != NULL &amp;&amp; to != NULL &amp;&amp;
577         from != to &amp;&amp;
578         !to-&gt;is_pinned() &amp;&amp;
579         to-&gt;rem_set()-&gt;is_complete()) {
580         jbyte cv_obj = *_ct-&gt;byte_for_const(_containing_obj);
581         jbyte cv_field = *_ct-&gt;byte_for_const(p);
582         const jbyte dirty = G1CardTable::dirty_card_val();
583 
584         bool is_bad = !(from-&gt;is_young()
585           || to-&gt;rem_set()-&gt;contains_reference(p)
586           || (_containing_obj-&gt;is_objArray() ?
587                 cv_field == dirty :
588                 cv_obj == dirty || cv_field == dirty));
589         if (is_bad) {
<span class="line-modified">590           MutexLockerEx x(ParGCRareEvent_lock,</span>
591             Mutex::_no_safepoint_check_flag);
592 
593           if (!_failures) {
594             log.error(&quot;----------&quot;);
595           }
596           log.error(&quot;Missing rem set entry:&quot;);
597           log.error(&quot;Field &quot; PTR_FORMAT &quot; of obj &quot; PTR_FORMAT &quot; in region &quot; HR_FORMAT,
598                     p2i(p), p2i(_containing_obj), HR_FORMAT_PARAMS(from));
599           ResourceMark rm;
600           LogStream ls(log.error());
601           _containing_obj-&gt;print_on(&amp;ls);
602           log.error(&quot;points to obj &quot; PTR_FORMAT &quot; in region &quot; HR_FORMAT &quot; remset %s&quot;,
603                     p2i(obj), HR_FORMAT_PARAMS(to), to-&gt;rem_set()-&gt;get_state_str());
604           if (oopDesc::is_oop(obj)) {
605             obj-&gt;print_on(&amp;ls);
606           }
607           log.error(&quot;Obj head CTE = %d, field CTE = %d.&quot;, cv_obj, cv_field);
608           log.error(&quot;----------&quot;);
609           _failures = true;
610           _n_failures++;
</pre>
<hr />
<pre>
615 };
616 
617 // Closure that applies the given two closures in sequence.
618 class G1Mux2Closure : public BasicOopIterateClosure {
619   OopClosure* _c1;
620   OopClosure* _c2;
621 public:
622   G1Mux2Closure(OopClosure *c1, OopClosure *c2) { _c1 = c1; _c2 = c2; }
623   template &lt;class T&gt; inline void do_oop_work(T* p) {
624     // Apply first closure; then apply the second.
625     _c1-&gt;do_oop(p);
626     _c2-&gt;do_oop(p);
627   }
628   virtual inline void do_oop(oop* p) { do_oop_work(p); }
629   virtual inline void do_oop(narrowOop* p) { do_oop_work(p); }
630 
631   // This closure provides its own oop verification code.
632   debug_only(virtual bool should_verify_oops() { return false; })
633 };
634 
<span class="line-removed">635 // This really ought to be commoned up into OffsetTableContigSpace somehow.</span>
<span class="line-removed">636 // We would need a mechanism to make that code skip dead objects.</span>
<span class="line-removed">637 </span>
638 void HeapRegion::verify(VerifyOption vo,
639                         bool* failures) const {
640   G1CollectedHeap* g1h = G1CollectedHeap::heap();
641   *failures = false;
642   HeapWord* p = bottom();
643   HeapWord* prev_p = NULL;
644   VerifyLiveClosure vl_cl(g1h, vo);
645   VerifyRemSetClosure vr_cl(g1h, vo);
646   bool is_region_humongous = is_humongous();
647   size_t object_num = 0;
648   while (p &lt; top()) {
649     oop obj = oop(p);
650     size_t obj_size = block_size(p);
651     object_num += 1;
652 
653     if (!g1h-&gt;is_obj_dead_cond(obj, this, vo)) {
654       if (oopDesc::is_oop(obj)) {
655         Klass* klass = obj-&gt;klass();
656         bool is_metaspace_object = Metaspace::contains(klass);
657         if (!is_metaspace_object) {
</pre>
<hr />
<pre>
690               vl_cl.n_failures() &gt;= G1MaxVerifyFailures) {
691             return;
692           }
693         }
694       } else {
695         log_error(gc, verify)(PTR_FORMAT &quot; not an oop&quot;, p2i(obj));
696         *failures = true;
697         return;
698       }
699     }
700     prev_p = p;
701     p += obj_size;
702   }
703 
704   if (!is_young() &amp;&amp; !is_empty()) {
705     _bot_part.verify();
706   }
707 
708   if (is_region_humongous) {
709     oop obj = oop(this-&gt;humongous_start_region()-&gt;bottom());
<span class="line-modified">710     if ((HeapWord*)obj &gt; bottom() || (HeapWord*)obj + obj-&gt;size() &lt; bottom()) {</span>
711       log_error(gc, verify)(&quot;this humongous region is not part of its&#39; humongous object &quot; PTR_FORMAT, p2i(obj));
712       *failures = true;
713       return;
714     }
715   }
716 
717   if (!is_region_humongous &amp;&amp; p != top()) {
718     log_error(gc, verify)(&quot;end of last object &quot; PTR_FORMAT &quot; &quot;
719                           &quot;does not match top &quot; PTR_FORMAT, p2i(p), p2i(top()));
720     *failures = true;
721     return;
722   }
723 
724   HeapWord* the_end = end();
725   // Do some extra BOT consistency checking for addresses in the
726   // range [top, end). BOT look-ups in this range should yield
727   // top. No point in doing that if top == end (there&#39;s nothing there).
728   if (p &lt; the_end) {
729     // Look up top
730     HeapWord* addr_1 = p;
<span class="line-modified">731     HeapWord* b_start_1 = _bot_part.block_start_const(addr_1);</span>
732     if (b_start_1 != p) {
733       log_error(gc, verify)(&quot;BOT look up for top: &quot; PTR_FORMAT &quot; &quot;
734                             &quot; yielded &quot; PTR_FORMAT &quot;, expecting &quot; PTR_FORMAT,
735                             p2i(addr_1), p2i(b_start_1), p2i(p));
736       *failures = true;
737       return;
738     }
739 
740     // Look up top + 1
741     HeapWord* addr_2 = p + 1;
742     if (addr_2 &lt; the_end) {
<span class="line-modified">743       HeapWord* b_start_2 = _bot_part.block_start_const(addr_2);</span>
744       if (b_start_2 != p) {
745         log_error(gc, verify)(&quot;BOT look up for top + 1: &quot; PTR_FORMAT &quot; &quot;
746                               &quot; yielded &quot; PTR_FORMAT &quot;, expecting &quot; PTR_FORMAT,
747                               p2i(addr_2), p2i(b_start_2), p2i(p));
748         *failures = true;
749         return;
750       }
751     }
752 
753     // Look up an address between top and end
754     size_t diff = pointer_delta(the_end, p) / 2;
755     HeapWord* addr_3 = p + diff;
756     if (addr_3 &lt; the_end) {
<span class="line-modified">757       HeapWord* b_start_3 = _bot_part.block_start_const(addr_3);</span>
758       if (b_start_3 != p) {
759         log_error(gc, verify)(&quot;BOT look up for top + diff: &quot; PTR_FORMAT &quot; &quot;
760                               &quot; yielded &quot; PTR_FORMAT &quot;, expecting &quot; PTR_FORMAT,
761                               p2i(addr_3), p2i(b_start_3), p2i(p));
762         *failures = true;
763         return;
764       }
765     }
766 
767     // Look up end - 1
768     HeapWord* addr_4 = the_end - 1;
<span class="line-modified">769     HeapWord* b_start_4 = _bot_part.block_start_const(addr_4);</span>
770     if (b_start_4 != p) {
771       log_error(gc, verify)(&quot;BOT look up for end - 1: &quot; PTR_FORMAT &quot; &quot;
772                             &quot; yielded &quot; PTR_FORMAT &quot;, expecting &quot; PTR_FORMAT,
773                             p2i(addr_4), p2i(b_start_4), p2i(p));
774       *failures = true;
775       return;
776     }
777   }
778 
779   verify_strong_code_roots(vo, failures);
780 }
781 
782 void HeapRegion::verify() const {
783   bool dummy = false;
784   verify(VerifyOption_G1UsePrevMarking, /* failures */ &amp;dummy);
785 }
786 
787 void HeapRegion::verify_rem_set(VerifyOption vo, bool* failures) const {
788   G1CollectedHeap* g1h = G1CollectedHeap::heap();
789   *failures = false;
</pre>
<hr />
<pre>
807           return;
808         }
809       } else {
810         log_error(gc, verify)(PTR_FORMAT &quot; not an oop&quot;, p2i(obj));
811         *failures = true;
812         return;
813       }
814     }
815 
816     prev_p = p;
817     p += obj_size;
818   }
819 }
820 
821 void HeapRegion::verify_rem_set() const {
822   bool failures = false;
823   verify_rem_set(VerifyOption_G1UsePrevMarking, &amp;failures);
824   guarantee(!failures, &quot;HeapRegion RemSet verification failed&quot;);
825 }
826 
<span class="line-modified">827 void HeapRegion::prepare_for_compaction(CompactPoint* cp) {</span>
<span class="line-removed">828   // Not used for G1 anymore, but pure virtual in Space.</span>
<span class="line-removed">829   ShouldNotReachHere();</span>
<span class="line-removed">830 }</span>
<span class="line-removed">831 </span>
<span class="line-removed">832 // G1OffsetTableContigSpace code; copied from space.cpp.  Hope this can go</span>
<span class="line-removed">833 // away eventually.</span>
<span class="line-removed">834 </span>
<span class="line-removed">835 void G1ContiguousSpace::clear(bool mangle_space) {</span>
836   set_top(bottom());
<span class="line-modified">837   CompactibleSpace::clear(mangle_space);</span>




838   reset_bot();
839 }
<span class="line-removed">840 #ifndef PRODUCT</span>
<span class="line-removed">841 void G1ContiguousSpace::mangle_unused_area() {</span>
<span class="line-removed">842   mangle_unused_area_complete();</span>
<span class="line-removed">843 }</span>
844 
<span class="line-modified">845 void G1ContiguousSpace::mangle_unused_area_complete() {</span>

846   SpaceMangler::mangle_region(MemRegion(top(), end()));
847 }
848 #endif
849 
<span class="line-modified">850 void G1ContiguousSpace::print() const {</span>
<span class="line-removed">851   print_short();</span>
<span class="line-removed">852   tty-&gt;print_cr(&quot; [&quot; INTPTR_FORMAT &quot;, &quot; INTPTR_FORMAT &quot;, &quot;</span>
<span class="line-removed">853                 INTPTR_FORMAT &quot;, &quot; INTPTR_FORMAT &quot;)&quot;,</span>
<span class="line-removed">854                 p2i(bottom()), p2i(top()), p2i(_bot_part.threshold()), p2i(end()));</span>
<span class="line-removed">855 }</span>
<span class="line-removed">856 </span>
<span class="line-removed">857 HeapWord* G1ContiguousSpace::initialize_threshold() {</span>
858   return _bot_part.initialize_threshold();
859 }
860 
<span class="line-modified">861 HeapWord* G1ContiguousSpace::cross_threshold(HeapWord* start,</span>
<span class="line-removed">862                                                     HeapWord* end) {</span>
863   _bot_part.alloc_block(start, end);
864   return _bot_part.threshold();
865 }
866 
<span class="line-modified">867 void G1ContiguousSpace::safe_object_iterate(ObjectClosure* blk) {</span>
<span class="line-removed">868   object_iterate(blk);</span>
<span class="line-removed">869 }</span>
<span class="line-removed">870 </span>
<span class="line-removed">871 void G1ContiguousSpace::object_iterate(ObjectClosure* blk) {</span>
872   HeapWord* p = bottom();
873   while (p &lt; top()) {
874     if (block_is_obj(p)) {
875       blk-&gt;do_object(oop(p));
876     }
877     p += block_size(p);
878   }
879 }
<span class="line-removed">880 </span>
<span class="line-removed">881 G1ContiguousSpace::G1ContiguousSpace(G1BlockOffsetTable* bot) :</span>
<span class="line-removed">882   _top(NULL),</span>
<span class="line-removed">883   _bot_part(bot, this),</span>
<span class="line-removed">884   _par_alloc_lock(Mutex::leaf, &quot;OffsetTableContigSpace par alloc lock&quot;, true),</span>
<span class="line-removed">885   _pre_dummy_top(NULL)</span>
<span class="line-removed">886 {</span>
<span class="line-removed">887 }</span>
<span class="line-removed">888 </span>
<span class="line-removed">889 void G1ContiguousSpace::initialize(MemRegion mr, bool clear_space, bool mangle_space) {</span>
<span class="line-removed">890   CompactibleSpace::initialize(mr, clear_space, mangle_space);</span>
<span class="line-removed">891   _top = bottom();</span>
<span class="line-removed">892   set_saved_mark_word(NULL);</span>
<span class="line-removed">893   reset_bot();</span>
<span class="line-removed">894 }</span>
</pre>
</td>
<td>
<hr />
<pre>
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;code/nmethod.hpp&quot;
 27 #include &quot;gc/g1/g1BlockOffsetTable.inline.hpp&quot;
 28 #include &quot;gc/g1/g1CollectedHeap.inline.hpp&quot;
 29 #include &quot;gc/g1/g1CollectionSet.hpp&quot;
 30 #include &quot;gc/g1/g1HeapRegionTraceType.hpp&quot;
<span class="line-added"> 31 #include &quot;gc/g1/g1NUMA.hpp&quot;</span>
 32 #include &quot;gc/g1/g1OopClosures.inline.hpp&quot;
 33 #include &quot;gc/g1/heapRegion.inline.hpp&quot;
 34 #include &quot;gc/g1/heapRegionBounds.inline.hpp&quot;
 35 #include &quot;gc/g1/heapRegionManager.inline.hpp&quot;
 36 #include &quot;gc/g1/heapRegionRemSet.hpp&quot;
 37 #include &quot;gc/g1/heapRegionTracer.hpp&quot;
 38 #include &quot;gc/shared/genOopClosures.inline.hpp&quot;

 39 #include &quot;logging/log.hpp&quot;
 40 #include &quot;logging/logStream.hpp&quot;
 41 #include &quot;memory/iterator.inline.hpp&quot;
 42 #include &quot;memory/resourceArea.hpp&quot;
 43 #include &quot;oops/access.inline.hpp&quot;
 44 #include &quot;oops/compressedOops.inline.hpp&quot;
 45 #include &quot;oops/oop.inline.hpp&quot;



 46 
 47 int    HeapRegion::LogOfHRGrainBytes = 0;
 48 int    HeapRegion::LogOfHRGrainWords = 0;
<span class="line-added"> 49 int    HeapRegion::LogCardsPerRegion = 0;</span>
 50 size_t HeapRegion::GrainBytes        = 0;
 51 size_t HeapRegion::GrainWords        = 0;
 52 size_t HeapRegion::CardsPerRegion    = 0;
 53 
 54 size_t HeapRegion::max_region_size() {
 55   return HeapRegionBounds::max_size();
 56 }
 57 
 58 size_t HeapRegion::min_region_size_in_words() {
 59   return HeapRegionBounds::min_size() &gt;&gt; LogHeapWordSize;
 60 }
 61 
 62 void HeapRegion::setup_heap_region_size(size_t initial_heap_size, size_t max_heap_size) {
 63   size_t region_size = G1HeapRegionSize;
 64   if (FLAG_IS_DEFAULT(G1HeapRegionSize)) {
 65     size_t average_heap_size = (initial_heap_size + max_heap_size) / 2;
 66     region_size = MAX2(average_heap_size / HeapRegionBounds::target_number(),
 67                        HeapRegionBounds::min_size());
 68   }
 69 
</pre>
<hr />
<pre>
 86   // Now, set up the globals.
 87   guarantee(LogOfHRGrainBytes == 0, &quot;we should only set it once&quot;);
 88   LogOfHRGrainBytes = region_size_log;
 89 
 90   guarantee(LogOfHRGrainWords == 0, &quot;we should only set it once&quot;);
 91   LogOfHRGrainWords = LogOfHRGrainBytes - LogHeapWordSize;
 92 
 93   guarantee(GrainBytes == 0, &quot;we should only set it once&quot;);
 94   // The cast to int is safe, given that we&#39;ve bounded region_size by
 95   // MIN_REGION_SIZE and MAX_REGION_SIZE.
 96   GrainBytes = region_size;
 97   log_info(gc, heap)(&quot;Heap region size: &quot; SIZE_FORMAT &quot;M&quot;, GrainBytes / M);
 98 
 99   guarantee(GrainWords == 0, &quot;we should only set it once&quot;);
100   GrainWords = GrainBytes &gt;&gt; LogHeapWordSize;
101   guarantee((size_t) 1 &lt;&lt; LogOfHRGrainWords == GrainWords, &quot;sanity&quot;);
102 
103   guarantee(CardsPerRegion == 0, &quot;we should only set it once&quot;);
104   CardsPerRegion = GrainBytes &gt;&gt; G1CardTable::card_shift;
105 
<span class="line-added">106   LogCardsPerRegion = log2_long((jlong) CardsPerRegion);</span>
<span class="line-added">107 </span>
108   if (G1HeapRegionSize != GrainBytes) {
<span class="line-modified">109     FLAG_SET_ERGO(G1HeapRegionSize, GrainBytes);</span>
110   }
111 }
112 
<span class="line-modified">113 void HeapRegion::handle_evacuation_failure() {</span>
<span class="line-added">114   uninstall_surv_rate_group();</span>
<span class="line-added">115   clear_young_index_in_cset();</span>
<span class="line-added">116   set_evacuation_failed(false);</span>
<span class="line-added">117   set_old();</span>
<span class="line-added">118 }</span>
<span class="line-added">119 </span>
<span class="line-added">120 void HeapRegion::unlink_from_list() {</span>
<span class="line-added">121   set_next(NULL);</span>
<span class="line-added">122   set_prev(NULL);</span>
<span class="line-added">123   set_containing_set(NULL);</span>
<span class="line-added">124 }</span>
<span class="line-added">125 </span>
<span class="line-added">126 void HeapRegion::hr_clear(bool clear_space) {</span>
127   assert(_humongous_start_region == NULL,
128          &quot;we should have already filtered out humongous regions&quot;);
129   assert(!in_collection_set(),
130          &quot;Should not clear heap region %u in the collection set&quot;, hrm_index());
131 
<span class="line-modified">132   clear_young_index_in_cset();</span>
<span class="line-added">133   clear_index_in_opt_cset();</span>
134   uninstall_surv_rate_group();
135   set_free();
136   reset_pre_dummy_top();
137 
<span class="line-modified">138   rem_set()-&gt;clear_locked();</span>






139 
140   zero_marked_bytes();
141 
142   init_top_at_mark_start();
143   if (clear_space) clear(SpaceDecorator::Mangle);
<span class="line-added">144 </span>
<span class="line-added">145   _evacuation_failed = false;</span>
<span class="line-added">146   _gc_efficiency = 0.0;</span>
147 }
148 
149 void HeapRegion::clear_cardtable() {
150   G1CardTable* ct = G1CollectedHeap::heap()-&gt;card_table();
151   ct-&gt;clear(MemRegion(bottom(), end()));
152 }
153 
154 void HeapRegion::calc_gc_efficiency() {
155   // GC efficiency is the ratio of how much space would be
156   // reclaimed over how long we predict it would take to reclaim it.
<span class="line-modified">157   G1Policy* policy = G1CollectedHeap::heap()-&gt;policy();</span>

158 
159   // Retrieve a prediction of the elapsed time for this region for
160   // a mixed gc because the region will only be evacuated during a
161   // mixed gc.
<span class="line-modified">162   double region_elapsed_time_ms = policy-&gt;predict_region_total_time_ms(this, false /* for_young_gc */);</span>

163   _gc_efficiency = (double) reclaimable_bytes() / region_elapsed_time_ms;
164 }
165 
166 void HeapRegion::set_free() {
167   report_region_type_change(G1HeapRegionTraceType::Free);
168   _type.set_free();
169 }
170 
171 void HeapRegion::set_eden() {
172   report_region_type_change(G1HeapRegionTraceType::Eden);
173   _type.set_eden();
174 }
175 
176 void HeapRegion::set_eden_pre_gc() {
177   report_region_type_change(G1HeapRegionTraceType::Eden);
178   _type.set_eden_pre_gc();
179 }
180 
181 void HeapRegion::set_survivor() {
182   report_region_type_change(G1HeapRegionTraceType::Survivor);
</pre>
<hr />
<pre>
222 
223   report_region_type_change(G1HeapRegionTraceType::ContinuesHumongous);
224   _type.set_continues_humongous();
225   _humongous_start_region = first_hr;
226 
227   _bot_part.set_object_can_span(true);
228 }
229 
230 void HeapRegion::clear_humongous() {
231   assert(is_humongous(), &quot;pre-condition&quot;);
232 
233   assert(capacity() == HeapRegion::GrainBytes, &quot;pre-condition&quot;);
234   _humongous_start_region = NULL;
235 
236   _bot_part.set_object_can_span(false);
237 }
238 
239 HeapRegion::HeapRegion(uint hrm_index,
240                        G1BlockOffsetTable* bot,
241                        MemRegion mr) :
<span class="line-modified">242   _bottom(mr.start()),</span>
<span class="line-modified">243   _end(mr.end()),</span>
<span class="line-modified">244   _top(NULL),</span>
<span class="line-modified">245   _compaction_top(NULL),</span>
<span class="line-modified">246   _bot_part(bot, this),</span>
<span class="line-modified">247   _par_alloc_lock(Mutex::leaf, &quot;HeapRegion par alloc lock&quot;, true),</span>
<span class="line-modified">248   _pre_dummy_top(NULL),</span>
<span class="line-added">249   _rem_set(NULL),</span>
<span class="line-added">250   _hrm_index(hrm_index),</span>
<span class="line-added">251   _type(),</span>
<span class="line-added">252   _humongous_start_region(NULL),</span>
<span class="line-added">253   _evacuation_failed(false),</span>
<span class="line-added">254   _index_in_opt_cset(InvalidCSetIndex),</span>
<span class="line-added">255   _next(NULL), _prev(NULL),</span>
256 #ifdef ASSERT
<span class="line-modified">257   _containing_set(NULL),</span>
258 #endif
<span class="line-modified">259   _prev_top_at_mark_start(NULL), _next_top_at_mark_start(NULL),</span>
<span class="line-modified">260   _prev_marked_bytes(0), _next_marked_bytes(0),</span>
<span class="line-modified">261   _young_index_in_cset(-1),</span>
<span class="line-modified">262   _surv_rate_group(NULL), _age_index(G1SurvRateGroup::InvalidAgeIndex), _gc_efficiency(0.0),</span>
<span class="line-modified">263   _node_index(G1NUMA::UnknownNodeIndex)</span>
264 {
<span class="line-modified">265   assert(Universe::on_page_boundary(mr.start()) &amp;&amp; Universe::on_page_boundary(mr.end()),</span>
<span class="line-added">266          &quot;invalid space boundaries&quot;);</span>
267 
<span class="line-modified">268   _rem_set = new HeapRegionRemSet(bot, this);</span>
<span class="line-added">269   initialize();</span>
270 }
271 
<span class="line-modified">272 void HeapRegion::initialize(bool clear_space, bool mangle_space) {</span>
273   assert(_rem_set-&gt;is_empty(), &quot;Remembered set must be empty&quot;);
274 
<span class="line-modified">275   if (clear_space) {</span>
<span class="line-added">276     clear(mangle_space);</span>
<span class="line-added">277   }</span>
278 

279   set_top(bottom());
<span class="line-added">280   set_compaction_top(bottom());</span>
<span class="line-added">281   reset_bot();</span>
<span class="line-added">282 </span>
<span class="line-added">283   hr_clear(false /*clear_space*/);</span>
284 }
285 
286 void HeapRegion::report_region_type_change(G1HeapRegionTraceType::Type to) {
287   HeapRegionTracer::send_region_type_change(_hrm_index,
288                                             get_trace_type(),
289                                             to,
290                                             (uintptr_t)bottom(),
291                                             used());
292 }
293 
294 void HeapRegion::note_self_forwarding_removal_start(bool during_initial_mark,
295                                                     bool during_conc_mark) {
296   // We always recreate the prev marking info and we&#39;ll explicitly
297   // mark all objects we find to be self-forwarded on the prev
298   // bitmap. So all objects need to be below PTAMS.
299   _prev_marked_bytes = 0;
300 
301   if (during_initial_mark) {
302     // During initial-mark, we&#39;ll also explicitly mark all objects
303     // we find to be self-forwarded on the next bitmap. So all
</pre>
<hr />
<pre>
340 
341 void HeapRegion::strong_code_roots_do(CodeBlobClosure* blk) const {
342   HeapRegionRemSet* hrrs = rem_set();
343   hrrs-&gt;strong_code_roots_do(blk);
344 }
345 
346 class VerifyStrongCodeRootOopClosure: public OopClosure {
347   const HeapRegion* _hr;
348   bool _failures;
349   bool _has_oops_in_region;
350 
351   template &lt;class T&gt; void do_oop_work(T* p) {
352     T heap_oop = RawAccess&lt;&gt;::oop_load(p);
353     if (!CompressedOops::is_null(heap_oop)) {
354       oop obj = CompressedOops::decode_not_null(heap_oop);
355 
356       // Note: not all the oops embedded in the nmethod are in the
357       // current region. We only look at those which are.
358       if (_hr-&gt;is_in(obj)) {
359         // Object is in the region. Check that its less than top
<span class="line-modified">360         if (_hr-&gt;top() &lt;= cast_from_oop&lt;HeapWord*&gt;(obj)) {</span>
361           // Object is above top
362           log_error(gc, verify)(&quot;Object &quot; PTR_FORMAT &quot; in region &quot; HR_FORMAT &quot; is above top &quot;,
363                                 p2i(obj), HR_FORMAT_PARAMS(_hr));
364           _failures = true;
365           return;
366         }
367         // Nmethod has at least one oop in the current region
368         _has_oops_in_region = true;
369       }
370     }
371   }
372 
373 public:
374   VerifyStrongCodeRootOopClosure(const HeapRegion* hr):
375     _hr(hr), _failures(false), _has_oops_in_region(false) {}
376 
377   void do_oop(narrowOop* p) { do_oop_work(p); }
378   void do_oop(oop* p)       { do_oop_work(p); }
379 
380   bool failures()           { return _failures; }
</pre>
<hr />
<pre>
446   }
447 
448   if (is_continues_humongous()) {
449     if (strong_code_roots_length &gt; 0) {
450       log_error(gc, verify)(&quot;region &quot; HR_FORMAT &quot; is a continuation of a humongous region but has &quot; SIZE_FORMAT &quot; code root entries&quot;,
451                             HR_FORMAT_PARAMS(this), strong_code_roots_length);
452       *failures = true;
453     }
454     return;
455   }
456 
457   VerifyStrongCodeRootCodeBlobClosure cb_cl(this);
458   strong_code_roots_do(&amp;cb_cl);
459 
460   if (cb_cl.failures()) {
461     *failures = true;
462   }
463 }
464 
465 void HeapRegion::print() const { print_on(tty); }
<span class="line-added">466 </span>
467 void HeapRegion::print_on(outputStream* st) const {
468   st-&gt;print(&quot;|%4u&quot;, this-&gt;_hrm_index);
469   st-&gt;print(&quot;|&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT,
470             p2i(bottom()), p2i(top()), p2i(end()));
471   st-&gt;print(&quot;|%3d%%&quot;, (int) ((double) used() * 100 / capacity()));
472   st-&gt;print(&quot;|%2s&quot;, get_short_type_str());
473   if (in_collection_set()) {
474     st-&gt;print(&quot;|CS&quot;);
475   } else {
476     st-&gt;print(&quot;|  &quot;);
477   }
<span class="line-modified">478   st-&gt;print(&quot;|TAMS &quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT &quot;| %s &quot;,</span>
479                p2i(prev_top_at_mark_start()), p2i(next_top_at_mark_start()), rem_set()-&gt;get_state_str());
<span class="line-added">480   if (UseNUMA) {</span>
<span class="line-added">481     G1NUMA* numa = G1NUMA::numa();</span>
<span class="line-added">482     if (node_index() &lt; numa-&gt;num_active_nodes()) {</span>
<span class="line-added">483       st-&gt;print(&quot;|%d&quot;, numa-&gt;numa_id(node_index()));</span>
<span class="line-added">484     } else {</span>
<span class="line-added">485       st-&gt;print(&quot;|-&quot;);</span>
<span class="line-added">486     }</span>
<span class="line-added">487   }</span>
<span class="line-added">488   st-&gt;print_cr(&quot;&quot;);</span>
489 }
490 
491 class G1VerificationClosure : public BasicOopIterateClosure {
492 protected:
493   G1CollectedHeap* _g1h;
494   G1CardTable *_ct;
495   oop _containing_obj;
496   bool _failures;
497   int _n_failures;
498   VerifyOption _vo;
499 public:
500   // _vo == UsePrevMarking -&gt; use &quot;prev&quot; marking information,
501   // _vo == UseNextMarking -&gt; use &quot;next&quot; marking information,
502   // _vo == UseFullMarking -&gt; use &quot;next&quot; marking bitmap but no TAMS.
503   G1VerificationClosure(G1CollectedHeap* g1h, VerifyOption vo) :
504     _g1h(g1h), _ct(g1h-&gt;card_table()),
505     _containing_obj(NULL), _failures(false), _n_failures(0), _vo(vo) {
506   }
507 
508   void set_containing_obj(oop obj) {
</pre>
<hr />
<pre>
530 public:
531   VerifyLiveClosure(G1CollectedHeap* g1h, VerifyOption vo) : G1VerificationClosure(g1h, vo) {}
532   virtual void do_oop(narrowOop* p) { do_oop_work(p); }
533   virtual void do_oop(oop* p) { do_oop_work(p); }
534 
535   template &lt;class T&gt;
536   void do_oop_work(T* p) {
537     assert(_containing_obj != NULL, &quot;Precondition&quot;);
538     assert(!_g1h-&gt;is_obj_dead_cond(_containing_obj, _vo),
539       &quot;Precondition&quot;);
540     verify_liveness(p);
541   }
542 
543   template &lt;class T&gt;
544   void verify_liveness(T* p) {
545     T heap_oop = RawAccess&lt;&gt;::oop_load(p);
546     Log(gc, verify) log;
547     if (!CompressedOops::is_null(heap_oop)) {
548       oop obj = CompressedOops::decode_not_null(heap_oop);
549       bool failed = false;
<span class="line-modified">550       if (!_g1h-&gt;is_in(obj) || _g1h-&gt;is_obj_dead_cond(obj, _vo)) {</span>
<span class="line-modified">551         MutexLocker x(ParGCRareEvent_lock,</span>
552           Mutex::_no_safepoint_check_flag);
553 
554         if (!_failures) {
555           log.error(&quot;----------&quot;);
556         }
557         ResourceMark rm;
<span class="line-modified">558         if (!_g1h-&gt;is_in(obj)) {</span>
559           HeapRegion* from = _g1h-&gt;heap_region_containing((HeapWord*)p);
560           log.error(&quot;Field &quot; PTR_FORMAT &quot; of live obj &quot; PTR_FORMAT &quot; in region &quot; HR_FORMAT,
561                     p2i(p), p2i(_containing_obj), HR_FORMAT_PARAMS(from));
562           LogStream ls(log.error());
563           print_object(&amp;ls, _containing_obj);
564           HeapRegion* const to = _g1h-&gt;heap_region_containing(obj);
565           log.error(&quot;points to obj &quot; PTR_FORMAT &quot; in region &quot; HR_FORMAT &quot; remset %s&quot;,
566                     p2i(obj), HR_FORMAT_PARAMS(to), to-&gt;rem_set()-&gt;get_state_str());
567         } else {
568           HeapRegion* from = _g1h-&gt;heap_region_containing((HeapWord*)p);
<span class="line-modified">569           HeapRegion* to = _g1h-&gt;heap_region_containing(obj);</span>
570           log.error(&quot;Field &quot; PTR_FORMAT &quot; of live obj &quot; PTR_FORMAT &quot; in region &quot; HR_FORMAT,
571                     p2i(p), p2i(_containing_obj), HR_FORMAT_PARAMS(from));
572           LogStream ls(log.error());
573           print_object(&amp;ls, _containing_obj);
574           log.error(&quot;points to dead obj &quot; PTR_FORMAT &quot; in region &quot; HR_FORMAT,
575                     p2i(obj), HR_FORMAT_PARAMS(to));
576           print_object(&amp;ls, obj);
577         }
578         log.error(&quot;----------&quot;);
579         _failures = true;
580         failed = true;
581         _n_failures++;
582       }
583     }
584   }
585 };
586 
587 class VerifyRemSetClosure : public G1VerificationClosure {
588 public:
589   VerifyRemSetClosure(G1CollectedHeap* g1h, VerifyOption vo) : G1VerificationClosure(g1h, vo) {}
</pre>
<hr />
<pre>
603     T heap_oop = RawAccess&lt;&gt;::oop_load(p);
604     Log(gc, verify) log;
605     if (!CompressedOops::is_null(heap_oop)) {
606       oop obj = CompressedOops::decode_not_null(heap_oop);
607       HeapRegion* from = _g1h-&gt;heap_region_containing((HeapWord*)p);
608       HeapRegion* to = _g1h-&gt;heap_region_containing(obj);
609       if (from != NULL &amp;&amp; to != NULL &amp;&amp;
610         from != to &amp;&amp;
611         !to-&gt;is_pinned() &amp;&amp;
612         to-&gt;rem_set()-&gt;is_complete()) {
613         jbyte cv_obj = *_ct-&gt;byte_for_const(_containing_obj);
614         jbyte cv_field = *_ct-&gt;byte_for_const(p);
615         const jbyte dirty = G1CardTable::dirty_card_val();
616 
617         bool is_bad = !(from-&gt;is_young()
618           || to-&gt;rem_set()-&gt;contains_reference(p)
619           || (_containing_obj-&gt;is_objArray() ?
620                 cv_field == dirty :
621                 cv_obj == dirty || cv_field == dirty));
622         if (is_bad) {
<span class="line-modified">623           MutexLocker x(ParGCRareEvent_lock,</span>
624             Mutex::_no_safepoint_check_flag);
625 
626           if (!_failures) {
627             log.error(&quot;----------&quot;);
628           }
629           log.error(&quot;Missing rem set entry:&quot;);
630           log.error(&quot;Field &quot; PTR_FORMAT &quot; of obj &quot; PTR_FORMAT &quot; in region &quot; HR_FORMAT,
631                     p2i(p), p2i(_containing_obj), HR_FORMAT_PARAMS(from));
632           ResourceMark rm;
633           LogStream ls(log.error());
634           _containing_obj-&gt;print_on(&amp;ls);
635           log.error(&quot;points to obj &quot; PTR_FORMAT &quot; in region &quot; HR_FORMAT &quot; remset %s&quot;,
636                     p2i(obj), HR_FORMAT_PARAMS(to), to-&gt;rem_set()-&gt;get_state_str());
637           if (oopDesc::is_oop(obj)) {
638             obj-&gt;print_on(&amp;ls);
639           }
640           log.error(&quot;Obj head CTE = %d, field CTE = %d.&quot;, cv_obj, cv_field);
641           log.error(&quot;----------&quot;);
642           _failures = true;
643           _n_failures++;
</pre>
<hr />
<pre>
648 };
649 
650 // Closure that applies the given two closures in sequence.
651 class G1Mux2Closure : public BasicOopIterateClosure {
652   OopClosure* _c1;
653   OopClosure* _c2;
654 public:
655   G1Mux2Closure(OopClosure *c1, OopClosure *c2) { _c1 = c1; _c2 = c2; }
656   template &lt;class T&gt; inline void do_oop_work(T* p) {
657     // Apply first closure; then apply the second.
658     _c1-&gt;do_oop(p);
659     _c2-&gt;do_oop(p);
660   }
661   virtual inline void do_oop(oop* p) { do_oop_work(p); }
662   virtual inline void do_oop(narrowOop* p) { do_oop_work(p); }
663 
664   // This closure provides its own oop verification code.
665   debug_only(virtual bool should_verify_oops() { return false; })
666 };
667 



668 void HeapRegion::verify(VerifyOption vo,
669                         bool* failures) const {
670   G1CollectedHeap* g1h = G1CollectedHeap::heap();
671   *failures = false;
672   HeapWord* p = bottom();
673   HeapWord* prev_p = NULL;
674   VerifyLiveClosure vl_cl(g1h, vo);
675   VerifyRemSetClosure vr_cl(g1h, vo);
676   bool is_region_humongous = is_humongous();
677   size_t object_num = 0;
678   while (p &lt; top()) {
679     oop obj = oop(p);
680     size_t obj_size = block_size(p);
681     object_num += 1;
682 
683     if (!g1h-&gt;is_obj_dead_cond(obj, this, vo)) {
684       if (oopDesc::is_oop(obj)) {
685         Klass* klass = obj-&gt;klass();
686         bool is_metaspace_object = Metaspace::contains(klass);
687         if (!is_metaspace_object) {
</pre>
<hr />
<pre>
720               vl_cl.n_failures() &gt;= G1MaxVerifyFailures) {
721             return;
722           }
723         }
724       } else {
725         log_error(gc, verify)(PTR_FORMAT &quot; not an oop&quot;, p2i(obj));
726         *failures = true;
727         return;
728       }
729     }
730     prev_p = p;
731     p += obj_size;
732   }
733 
734   if (!is_young() &amp;&amp; !is_empty()) {
735     _bot_part.verify();
736   }
737 
738   if (is_region_humongous) {
739     oop obj = oop(this-&gt;humongous_start_region()-&gt;bottom());
<span class="line-modified">740     if (cast_from_oop&lt;HeapWord*&gt;(obj) &gt; bottom() || cast_from_oop&lt;HeapWord*&gt;(obj) + obj-&gt;size() &lt; bottom()) {</span>
741       log_error(gc, verify)(&quot;this humongous region is not part of its&#39; humongous object &quot; PTR_FORMAT, p2i(obj));
742       *failures = true;
743       return;
744     }
745   }
746 
747   if (!is_region_humongous &amp;&amp; p != top()) {
748     log_error(gc, verify)(&quot;end of last object &quot; PTR_FORMAT &quot; &quot;
749                           &quot;does not match top &quot; PTR_FORMAT, p2i(p), p2i(top()));
750     *failures = true;
751     return;
752   }
753 
754   HeapWord* the_end = end();
755   // Do some extra BOT consistency checking for addresses in the
756   // range [top, end). BOT look-ups in this range should yield
757   // top. No point in doing that if top == end (there&#39;s nothing there).
758   if (p &lt; the_end) {
759     // Look up top
760     HeapWord* addr_1 = p;
<span class="line-modified">761     HeapWord* b_start_1 = block_start_const(addr_1);</span>
762     if (b_start_1 != p) {
763       log_error(gc, verify)(&quot;BOT look up for top: &quot; PTR_FORMAT &quot; &quot;
764                             &quot; yielded &quot; PTR_FORMAT &quot;, expecting &quot; PTR_FORMAT,
765                             p2i(addr_1), p2i(b_start_1), p2i(p));
766       *failures = true;
767       return;
768     }
769 
770     // Look up top + 1
771     HeapWord* addr_2 = p + 1;
772     if (addr_2 &lt; the_end) {
<span class="line-modified">773       HeapWord* b_start_2 = block_start_const(addr_2);</span>
774       if (b_start_2 != p) {
775         log_error(gc, verify)(&quot;BOT look up for top + 1: &quot; PTR_FORMAT &quot; &quot;
776                               &quot; yielded &quot; PTR_FORMAT &quot;, expecting &quot; PTR_FORMAT,
777                               p2i(addr_2), p2i(b_start_2), p2i(p));
778         *failures = true;
779         return;
780       }
781     }
782 
783     // Look up an address between top and end
784     size_t diff = pointer_delta(the_end, p) / 2;
785     HeapWord* addr_3 = p + diff;
786     if (addr_3 &lt; the_end) {
<span class="line-modified">787       HeapWord* b_start_3 = block_start_const(addr_3);</span>
788       if (b_start_3 != p) {
789         log_error(gc, verify)(&quot;BOT look up for top + diff: &quot; PTR_FORMAT &quot; &quot;
790                               &quot; yielded &quot; PTR_FORMAT &quot;, expecting &quot; PTR_FORMAT,
791                               p2i(addr_3), p2i(b_start_3), p2i(p));
792         *failures = true;
793         return;
794       }
795     }
796 
797     // Look up end - 1
798     HeapWord* addr_4 = the_end - 1;
<span class="line-modified">799     HeapWord* b_start_4 = block_start_const(addr_4);</span>
800     if (b_start_4 != p) {
801       log_error(gc, verify)(&quot;BOT look up for end - 1: &quot; PTR_FORMAT &quot; &quot;
802                             &quot; yielded &quot; PTR_FORMAT &quot;, expecting &quot; PTR_FORMAT,
803                             p2i(addr_4), p2i(b_start_4), p2i(p));
804       *failures = true;
805       return;
806     }
807   }
808 
809   verify_strong_code_roots(vo, failures);
810 }
811 
812 void HeapRegion::verify() const {
813   bool dummy = false;
814   verify(VerifyOption_G1UsePrevMarking, /* failures */ &amp;dummy);
815 }
816 
817 void HeapRegion::verify_rem_set(VerifyOption vo, bool* failures) const {
818   G1CollectedHeap* g1h = G1CollectedHeap::heap();
819   *failures = false;
</pre>
<hr />
<pre>
837           return;
838         }
839       } else {
840         log_error(gc, verify)(PTR_FORMAT &quot; not an oop&quot;, p2i(obj));
841         *failures = true;
842         return;
843       }
844     }
845 
846     prev_p = p;
847     p += obj_size;
848   }
849 }
850 
851 void HeapRegion::verify_rem_set() const {
852   bool failures = false;
853   verify_rem_set(VerifyOption_G1UsePrevMarking, &amp;failures);
854   guarantee(!failures, &quot;HeapRegion RemSet verification failed&quot;);
855 }
856 
<span class="line-modified">857 void HeapRegion::clear(bool mangle_space) {</span>








858   set_top(bottom());
<span class="line-modified">859   set_compaction_top(bottom());</span>
<span class="line-added">860 </span>
<span class="line-added">861   if (ZapUnusedHeapArea &amp;&amp; mangle_space) {</span>
<span class="line-added">862     mangle_unused_area();</span>
<span class="line-added">863   }</span>
864   reset_bot();
865 }




866 
<span class="line-modified">867 #ifndef PRODUCT</span>
<span class="line-added">868 void HeapRegion::mangle_unused_area() {</span>
869   SpaceMangler::mangle_region(MemRegion(top(), end()));
870 }
871 #endif
872 
<span class="line-modified">873 HeapWord* HeapRegion::initialize_threshold() {</span>







874   return _bot_part.initialize_threshold();
875 }
876 
<span class="line-modified">877 HeapWord* HeapRegion::cross_threshold(HeapWord* start, HeapWord* end) {</span>

878   _bot_part.alloc_block(start, end);
879   return _bot_part.threshold();
880 }
881 
<span class="line-modified">882 void HeapRegion::object_iterate(ObjectClosure* blk) {</span>




883   HeapWord* p = bottom();
884   while (p &lt; top()) {
885     if (block_is_obj(p)) {
886       blk-&gt;do_object(oop(p));
887     }
888     p += block_size(p);
889   }
890 }















</pre>
</td>
</tr>
</table>
<center><a href="g1_globals.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="heapRegion.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>