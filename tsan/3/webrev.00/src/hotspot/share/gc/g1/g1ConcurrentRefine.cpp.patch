diff a/src/hotspot/share/gc/g1/g1ConcurrentRefine.cpp b/src/hotspot/share/gc/g1/g1ConcurrentRefine.cpp
--- a/src/hotspot/share/gc/g1/g1ConcurrentRefine.cpp
+++ b/src/hotspot/share/gc/g1/g1ConcurrentRefine.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2001, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2001, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -27,10 +27,11 @@
 #include "gc/g1/g1ConcurrentRefine.hpp"
 #include "gc/g1/g1ConcurrentRefineThread.hpp"
 #include "gc/g1/g1DirtyCardQueue.hpp"
 #include "logging/log.hpp"
 #include "memory/allocation.inline.hpp"
+#include "memory/iterator.hpp"
 #include "runtime/java.hpp"
 #include "runtime/thread.hpp"
 #include "utilities/debug.hpp"
 #include "utilities/globalDefinitions.hpp"
 #include "utilities/pair.hpp"
@@ -69,15 +70,11 @@
 jint G1ConcurrentRefineThreadControl::initialize(G1ConcurrentRefine* cr, uint num_max_threads) {
   assert(cr != NULL, "G1ConcurrentRefine must not be NULL");
   _cr = cr;
   _num_max_threads = num_max_threads;
 
-  _threads = NEW_C_HEAP_ARRAY_RETURN_NULL(G1ConcurrentRefineThread*, num_max_threads, mtGC);
-  if (_threads == NULL) {
-    vm_shutdown_during_initialization("Could not allocate thread holder array.");
-    return JNI_ENOMEM;
-  }
+  _threads = NEW_C_HEAP_ARRAY(G1ConcurrentRefineThread*, num_max_threads, mtGC);
 
   for (uint i = 0; i < num_max_threads; i++) {
     if (UseDynamicNumberOfGCThreads && i != 0 /* Always start first thread. */) {
       _threads[i] = NULL;
     } else {
@@ -86,10 +83,15 @@
         vm_shutdown_during_initialization("Could not allocate refinement threads.");
         return JNI_ENOMEM;
       }
     }
   }
+
+  if (num_max_threads > 0) {
+    G1BarrierSet::dirty_card_queue_set().set_primary_refinement_thread(_threads[0]);
+  }
+
   return JNI_OK;
 }
 
 void G1ConcurrentRefineThreadControl::maybe_activate_next(uint cur_worker_id) {
   assert(cur_worker_id < _num_max_threads,
@@ -105,11 +107,11 @@
   if (thread_to_activate == NULL) {
     // Still need to create the thread...
     _threads[worker_id] = create_refinement_thread(worker_id, false);
     thread_to_activate = _threads[worker_id];
   }
-  if (thread_to_activate != NULL && !thread_to_activate->is_active()) {
+  if (thread_to_activate != NULL) {
     thread_to_activate->activate();
   }
 }
 
 void G1ConcurrentRefineThreadControl::print_on(outputStream* st) const {
@@ -143,11 +145,11 @@
 // without needing to check for overflow in "x OP y", because the
 // ranges for x and y have been restricted.
 STATIC_ASSERT(sizeof(LP64_ONLY(jint) NOT_LP64(jshort)) <= (sizeof(size_t)/2));
 const size_t max_yellow_zone = LP64_ONLY(max_jint) NOT_LP64(max_jshort);
 const size_t max_green_zone = max_yellow_zone / 2;
-const size_t max_red_zone = INT_MAX; // For dcqs.set_max_completed_buffers.
+const size_t max_red_zone = INT_MAX; // For dcqs.set_max_cards.
 STATIC_ASSERT(max_yellow_zone <= max_red_zone);
 
 // Range check assertions for green zone values.
 #define assert_zone_constraints_g(green)                        \
   do {                                                          \
@@ -187,32 +189,37 @@
 #define CTRL_TAGS gc, ergo, refine
 
 // For logging zone values, ensuring consistency of level and tags.
 #define LOG_ZONES(...) log_debug( CTRL_TAGS )(__VA_ARGS__)
 
+static size_t buffers_to_cards(size_t value) {
+  return value * G1UpdateBufferSize;
+}
+
 // Package for pair of refinement thread activation and deactivation
 // thresholds.  The activation and deactivation levels are resp. the first
 // and second values of the pair.
 typedef Pair<size_t, size_t> Thresholds;
 inline size_t activation_level(const Thresholds& t) { return t.first; }
 inline size_t deactivation_level(const Thresholds& t) { return t.second; }
 
 static Thresholds calc_thresholds(size_t green_zone,
                                   size_t yellow_zone,
-                                  uint worker_i) {
+                                  uint worker_id) {
   double yellow_size = yellow_zone - green_zone;
   double step = yellow_size / G1ConcurrentRefine::max_num_threads();
-  if (worker_i == 0) {
+  if (worker_id == 0) {
     // Potentially activate worker 0 more aggressively, to keep
     // available buffers near green_zone value.  When yellow_size is
     // large we don't want to allow a full step to accumulate before
     // doing any processing, as that might lead to significantly more
-    // than green_zone buffers to be processed by update_rs.
-    step = MIN2(step, ParallelGCThreads / 2.0);
+    // than green_zone buffers to be processed during pause.  So limit
+    // to an extra half buffer per pause-time processing thread.
+    step = MIN2(step, buffers_to_cards(ParallelGCThreads) / 2.0);
   }
-  size_t activate_offset = static_cast<size_t>(ceil(step * (worker_i + 1)));
-  size_t deactivate_offset = static_cast<size_t>(floor(step * worker_i));
+  size_t activate_offset = static_cast<size_t>(ceil(step * (worker_id + 1)));
+  size_t deactivate_offset = static_cast<size_t>(floor(step * worker_id));
   return Thresholds(green_zone + activate_offset,
                     green_zone + deactivate_offset);
 }
 
 G1ConcurrentRefine::G1ConcurrentRefine(size_t green_zone,
@@ -231,11 +238,11 @@
 jint G1ConcurrentRefine::initialize() {
   return _thread_control.initialize(this, max_num_threads());
 }
 
 static size_t calc_min_yellow_zone_size() {
-  size_t step = G1ConcRefinementThresholdStep;
+  size_t step = buffers_to_cards(G1ConcRefinementThresholdStep);
   uint n_workers = G1ConcurrentRefine::max_num_threads();
   if ((max_yellow_zone / step) < n_workers) {
     return max_yellow_zone;
   } else {
     return step * n_workers;
@@ -245,15 +252,16 @@
 static size_t calc_init_green_zone() {
   size_t green = G1ConcRefinementGreenZone;
   if (FLAG_IS_DEFAULT(G1ConcRefinementGreenZone)) {
     green = ParallelGCThreads;
   }
+  green = buffers_to_cards(green);
   return MIN2(green, max_green_zone);
 }
 
 static size_t calc_init_yellow_zone(size_t green, size_t min_size) {
-  size_t config = G1ConcRefinementYellowZone;
+  size_t config = buffers_to_cards(G1ConcRefinementYellowZone);
   size_t size = 0;
   if (FLAG_IS_DEFAULT(G1ConcRefinementYellowZone)) {
     size = green * 2;
   } else if (green < config) {
     size = config - green;
@@ -264,11 +272,11 @@
 }
 
 static size_t calc_init_red_zone(size_t green, size_t yellow) {
   size_t size = yellow - green;
   if (!FLAG_IS_DEFAULT(G1ConcRefinementRedZone)) {
-    size_t config = G1ConcRefinementRedZone;
+    size_t config = buffers_to_cards(G1ConcRefinementRedZone);
     if (yellow < config) {
       size = MAX2(size, config - yellow);
     }
   }
   return MIN2(yellow + size, max_red_zone);
@@ -289,17 +297,10 @@
 
   G1ConcurrentRefine* cr = new G1ConcurrentRefine(green_zone,
                                                   yellow_zone,
                                                   red_zone,
                                                   min_yellow_zone_size);
-
-  if (cr == NULL) {
-    *ecode = JNI_ENOMEM;
-    vm_shutdown_during_initialization("Could not create G1ConcurrentRefine");
-    return NULL;
-  }
-
   *ecode = cr->initialize();
   return cr;
 }
 
 void G1ConcurrentRefine::stop() {
@@ -320,22 +321,22 @@
 void G1ConcurrentRefine::print_threads_on(outputStream* st) const {
   _thread_control.print_on(st);
 }
 
 static size_t calc_new_green_zone(size_t green,
-                                  double update_rs_time,
-                                  size_t update_rs_processed_buffers,
+                                  double logged_cards_scan_time,
+                                  size_t processed_logged_cards,
                                   double goal_ms) {
   // Adjust green zone based on whether we're meeting the time goal.
   // Limit to max_green_zone.
   const double inc_k = 1.1, dec_k = 0.9;
-  if (update_rs_time > goal_ms) {
+  if (logged_cards_scan_time > goal_ms) {
     if (green > 0) {
       green = static_cast<size_t>(green * dec_k);
     }
-  } else if (update_rs_time < goal_ms &&
-             update_rs_processed_buffers > green) {
+  } else if (logged_cards_scan_time < goal_ms &&
+             processed_logged_cards > green) {
     green = static_cast<size_t>(MAX2(green * inc_k, green + 1.0));
     green = MIN2(green, max_green_zone);
   }
   return green;
 }
@@ -348,24 +349,24 @@
 
 static size_t calc_new_red_zone(size_t green, size_t yellow) {
   return MIN2(yellow + (yellow - green), max_red_zone);
 }
 
-void G1ConcurrentRefine::update_zones(double update_rs_time,
-                                      size_t update_rs_processed_buffers,
+void G1ConcurrentRefine::update_zones(double logged_cards_scan_time,
+                                      size_t processed_logged_cards,
                                       double goal_ms) {
   log_trace( CTRL_TAGS )("Updating Refinement Zones: "
-                         "update_rs time: %.3fms, "
-                         "update_rs buffers: " SIZE_FORMAT ", "
-                         "update_rs goal time: %.3fms",
-                         update_rs_time,
-                         update_rs_processed_buffers,
+                         "logged cards scan time: %.3fms, "
+                         "processed cards: " SIZE_FORMAT ", "
+                         "goal time: %.3fms",
+                         logged_cards_scan_time,
+                         processed_logged_cards,
                          goal_ms);
 
   _green_zone = calc_new_green_zone(_green_zone,
-                                    update_rs_time,
-                                    update_rs_processed_buffers,
+                                    logged_cards_scan_time,
+                                    processed_logged_cards,
                                     goal_ms);
   _yellow_zone = calc_new_yellow_zone(_green_zone, _min_yellow_zone_size);
   _red_zone = calc_new_red_zone(_green_zone, _yellow_zone);
 
   assert_zone_constraints_gyr(_green_zone, _yellow_zone, _red_zone);
@@ -374,41 +375,57 @@
             "yellow: " SIZE_FORMAT ", "
             "red: " SIZE_FORMAT,
             _green_zone, _yellow_zone, _red_zone);
 }
 
-void G1ConcurrentRefine::adjust(double update_rs_time,
-                                size_t update_rs_processed_buffers,
+void G1ConcurrentRefine::adjust(double logged_cards_scan_time,
+                                size_t processed_logged_cards,
                                 double goal_ms) {
   G1DirtyCardQueueSet& dcqs = G1BarrierSet::dirty_card_queue_set();
 
   if (G1UseAdaptiveConcRefinement) {
-    update_zones(update_rs_time, update_rs_processed_buffers, goal_ms);
+    update_zones(logged_cards_scan_time, processed_logged_cards, goal_ms);
 
     // Change the barrier params
     if (max_num_threads() == 0) {
       // Disable dcqs notification when there are no threads to notify.
-      dcqs.set_process_completed_buffers_threshold(G1DirtyCardQueueSet::ProcessCompletedBuffersThresholdNever);
+      dcqs.set_process_cards_threshold(G1DirtyCardQueueSet::ProcessCardsThresholdNever);
     } else {
       // Worker 0 is the primary; wakeup is via dcqs notification.
       STATIC_ASSERT(max_yellow_zone <= INT_MAX);
       size_t activate = activation_threshold(0);
-      dcqs.set_process_completed_buffers_threshold(activate);
+      dcqs.set_process_cards_threshold(activate);
     }
-    dcqs.set_max_completed_buffers(red_zone());
+    dcqs.set_max_cards(red_zone());
   }
 
-  size_t curr_queue_size = dcqs.completed_buffers_num();
-  if ((dcqs.max_completed_buffers() > 0) &&
+  size_t curr_queue_size = dcqs.num_cards();
+  if ((dcqs.max_cards() > 0) &&
       (curr_queue_size >= yellow_zone())) {
-    dcqs.set_completed_buffers_padding(curr_queue_size);
+    dcqs.set_max_cards_padding(curr_queue_size);
   } else {
-    dcqs.set_completed_buffers_padding(0);
+    dcqs.set_max_cards_padding(0);
   }
   dcqs.notify_if_necessary();
 }
 
+G1ConcurrentRefine::RefinementStats G1ConcurrentRefine::total_refinement_stats() const {
+  struct CollectData : public ThreadClosure {
+    Tickspan _total_time;
+    size_t _total_cards;
+    CollectData() : _total_time(), _total_cards(0) {}
+    virtual void do_thread(Thread* t) {
+      G1ConcurrentRefineThread* crt = static_cast<G1ConcurrentRefineThread*>(t);
+      _total_time += crt->total_refinement_time();
+      _total_cards += crt->total_refined_cards();
+    }
+  } collector;
+  // Cast away const so we can call non-modifying closure on threads.
+  const_cast<G1ConcurrentRefine*>(this)->threads_do(&collector);
+  return RefinementStats(collector._total_time, collector._total_cards);
+}
+
 size_t G1ConcurrentRefine::activation_threshold(uint worker_id) const {
   Thresholds thresholds = calc_thresholds(_green_zone, _yellow_zone, worker_id);
   return activation_level(thresholds);
 }
 
@@ -419,29 +436,31 @@
 
 uint G1ConcurrentRefine::worker_id_offset() {
   return G1DirtyCardQueueSet::num_par_ids();
 }
 
-void G1ConcurrentRefine::maybe_activate_more_threads(uint worker_id, size_t num_cur_buffers) {
-  if (num_cur_buffers > activation_threshold(worker_id + 1)) {
+void G1ConcurrentRefine::maybe_activate_more_threads(uint worker_id, size_t num_cur_cards) {
+  if (num_cur_cards > activation_threshold(worker_id + 1)) {
     _thread_control.maybe_activate_next(worker_id);
   }
 }
 
-bool G1ConcurrentRefine::do_refinement_step(uint worker_id) {
+bool G1ConcurrentRefine::do_refinement_step(uint worker_id,
+                                            size_t* total_refined_cards) {
   G1DirtyCardQueueSet& dcqs = G1BarrierSet::dirty_card_queue_set();
 
-  size_t curr_buffer_num = dcqs.completed_buffers_num();
-  // If the number of the buffers falls down into the yellow zone,
+  size_t curr_cards = dcqs.num_cards();
+  // If the number of the cards falls down into the yellow zone,
   // that means that the transition period after the evacuation pause has ended.
   // Since the value written to the DCQS is the same for all threads, there is no
   // need to synchronize.
-  if (dcqs.completed_buffers_padding() > 0 && curr_buffer_num <= yellow_zone()) {
-    dcqs.set_completed_buffers_padding(0);
+  if (dcqs.max_cards_padding() > 0 && curr_cards <= yellow_zone()) {
+    dcqs.set_max_cards_padding(0);
   }
 
-  maybe_activate_more_threads(worker_id, curr_buffer_num);
+  maybe_activate_more_threads(worker_id, curr_cards);
 
   // Process the next buffer, if there are enough left.
   return dcqs.refine_completed_buffer_concurrently(worker_id + worker_id_offset(),
-                                                   deactivation_threshold(worker_id));
+                                                   deactivation_threshold(worker_id),
+                                                   total_refined_cards);
 }
