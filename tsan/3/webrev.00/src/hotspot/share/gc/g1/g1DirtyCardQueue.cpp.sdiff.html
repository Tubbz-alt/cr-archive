<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/g1/g1DirtyCardQueue.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="g1ConcurrentRefineThread.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1DirtyCardQueue.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/g1/g1DirtyCardQueue.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2001, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;


 26 #include &quot;gc/g1/g1CollectedHeap.inline.hpp&quot;

 27 #include &quot;gc/g1/g1DirtyCardQueue.hpp&quot;
 28 #include &quot;gc/g1/g1FreeIdSet.hpp&quot;

 29 #include &quot;gc/g1/g1RemSet.hpp&quot;
 30 #include &quot;gc/g1/g1ThreadLocalData.hpp&quot;
 31 #include &quot;gc/g1/heapRegionRemSet.hpp&quot;
 32 #include &quot;gc/shared/suspendibleThreadSet.hpp&quot;
<span class="line-modified"> 33 #include &quot;gc/shared/workgroup.hpp&quot;</span>
 34 #include &quot;runtime/atomic.hpp&quot;
<span class="line-modified"> 35 #include &quot;runtime/flags/flagSetting.hpp&quot;</span>
<span class="line-removed"> 36 #include &quot;runtime/mutexLocker.hpp&quot;</span>
 37 #include &quot;runtime/safepoint.hpp&quot;
 38 #include &quot;runtime/thread.inline.hpp&quot;
 39 #include &quot;runtime/threadSMR.hpp&quot;



 40 
<span class="line-modified"> 41 // Closure used for updating remembered sets and recording references that</span>
<span class="line-removed"> 42 // point into the collection set while the mutator is running.</span>
<span class="line-removed"> 43 // Assumed to be only executed concurrently with the mutator. Yields via</span>
<span class="line-removed"> 44 // SuspendibleThreadSet after every card.</span>
<span class="line-removed"> 45 class G1RefineCardConcurrentlyClosure: public G1CardTableEntryClosure {</span>
<span class="line-removed"> 46 public:</span>
<span class="line-removed"> 47   bool do_card_ptr(CardValue* card_ptr, uint worker_i) {</span>
<span class="line-removed"> 48     G1CollectedHeap::heap()-&gt;rem_set()-&gt;refine_card_concurrently(card_ptr, worker_i);</span>
<span class="line-removed"> 49 </span>
<span class="line-removed"> 50     if (SuspendibleThreadSet::should_yield()) {</span>
<span class="line-removed"> 51       // Caller will actually yield.</span>
<span class="line-removed"> 52       return false;</span>
<span class="line-removed"> 53     }</span>
<span class="line-removed"> 54     // Otherwise, we finished successfully; return true.</span>
<span class="line-removed"> 55     return true;</span>
<span class="line-removed"> 56   }</span>
<span class="line-removed"> 57 };</span>
<span class="line-removed"> 58 </span>
<span class="line-removed"> 59 G1DirtyCardQueue::G1DirtyCardQueue(G1DirtyCardQueueSet* qset, bool permanent) :</span>
 60   // Dirty card queues are always active, so we create them with their
 61   // active field set to true.
<span class="line-modified"> 62   PtrQueue(qset, permanent, true /* active */)</span>
 63 { }
 64 
 65 G1DirtyCardQueue::~G1DirtyCardQueue() {
<span class="line-modified"> 66   if (!is_permanent()) {</span>
<span class="line-modified"> 67     flush();</span>









 68   }
 69 }
 70 
<span class="line-modified"> 71 G1DirtyCardQueueSet::G1DirtyCardQueueSet(bool notify_when_complete) :</span>
<span class="line-modified"> 72   PtrQueueSet(notify_when_complete),</span>
<span class="line-modified"> 73   _shared_dirty_card_queue(this, true /* permanent */),</span>
<span class="line-modified"> 74   _free_ids(NULL),</span>
<span class="line-modified"> 75   _processed_buffers_mut(0),</span>
<span class="line-modified"> 76   _processed_buffers_rs_thread(0),</span>
<span class="line-modified"> 77   _cur_par_buffer_node(NULL)</span>







 78 {

 79   _all_active = true;
 80 }
 81 
 82 G1DirtyCardQueueSet::~G1DirtyCardQueueSet() {
<span class="line-modified"> 83   delete _free_ids;</span>

 84 }
 85 
 86 // Determines how many mutator threads can process the buffers in parallel.
 87 uint G1DirtyCardQueueSet::num_par_ids() {
 88   return (uint)os::initial_active_processor_count();
 89 }
 90 
<span class="line-modified"> 91 void G1DirtyCardQueueSet::initialize(Monitor* cbl_mon,</span>
<span class="line-modified"> 92                                      BufferNode::Allocator* allocator,</span>
<span class="line-modified"> 93                                      Mutex* lock,</span>
<span class="line-modified"> 94                                      bool init_free_ids) {</span>
<span class="line-removed"> 95   PtrQueueSet::initialize(cbl_mon, allocator);</span>
<span class="line-removed"> 96   _shared_dirty_card_queue.set_lock(lock);</span>
<span class="line-removed"> 97   if (init_free_ids) {</span>
<span class="line-removed"> 98     _free_ids = new G1FreeIdSet(0, num_par_ids());</span>
 99   }

100 }
101 
102 void G1DirtyCardQueueSet::handle_zero_index_for_thread(Thread* t) {
103   G1ThreadLocalData::dirty_card_queue(t).handle_zero_index();
104 }
105 
<span class="line-modified">106 bool G1DirtyCardQueueSet::apply_closure_to_buffer(G1CardTableEntryClosure* cl,</span>
<span class="line-modified">107                                                   BufferNode* node,</span>
<span class="line-modified">108                                                   bool consume,</span>
<span class="line-modified">109                                                   uint worker_i) {</span>
<span class="line-modified">110   if (cl == NULL) return true;</span>
<span class="line-modified">111   bool result = true;</span>
<span class="line-modified">112   void** buf = BufferNode::make_buffer_from_node(node);</span>
<span class="line-modified">113   size_t i = node-&gt;index();</span>
<span class="line-modified">114   size_t limit = buffer_size();</span>
<span class="line-modified">115   for ( ; i &lt; limit; ++i) {</span>
<span class="line-modified">116     CardTable::CardValue* card_ptr = static_cast&lt;CardTable::CardValue*&gt;(buf[i]);</span>
<span class="line-modified">117     assert(card_ptr != NULL, &quot;invariant&quot;);</span>
<span class="line-modified">118     if (!cl-&gt;do_card_ptr(card_ptr, worker_i)) {</span>
<span class="line-modified">119       result = false;           // Incomplete processing.</span>
<span class="line-modified">120       break;</span>


























































































































































































































121     }
122   }
<span class="line-modified">123   if (consume) {</span>
<span class="line-modified">124     assert(i &lt;= buffer_size(), &quot;invariant&quot;);</span>
<span class="line-modified">125     node-&gt;set_index(i);</span>















126   }
127   return result;
128 }
129 


















































































































































































































130 #ifndef ASSERT
131 #define assert_fully_consumed(node, buffer_size)
132 #else
133 #define assert_fully_consumed(node, buffer_size)                \
134   do {                                                          \
135     size_t _afc_index = (node)-&gt;index();                        \
136     size_t _afc_size = (buffer_size);                           \
137     assert(_afc_index == _afc_size,                             \
138            &quot;Buffer was not fully consumed as claimed: index: &quot;  \
139            SIZE_FORMAT &quot;, size: &quot; SIZE_FORMAT,                  \
140             _afc_index, _afc_size);                             \
141   } while (0)
142 #endif // ASSERT
143 
<span class="line-modified">144 bool G1DirtyCardQueueSet::mut_process_buffer(BufferNode* node) {</span>
<span class="line-modified">145   guarantee(_free_ids != NULL, &quot;must be&quot;);</span>




















146 
<span class="line-modified">147   uint worker_i = _free_ids-&gt;claim_par_id(); // temporarily claim an id</span>
<span class="line-modified">148   G1RefineCardConcurrentlyClosure cl;</span>
<span class="line-modified">149   bool result = apply_closure_to_buffer(&amp;cl, node, true, worker_i);</span>
<span class="line-modified">150   _free_ids-&gt;release_par_id(worker_i); // release the id</span>


151 
152   if (result) {
153     assert_fully_consumed(node, buffer_size());
<span class="line-removed">154     Atomic::inc(&amp;_processed_buffers_mut);</span>
155   }
156   return result;
157 }
158 
<span class="line-modified">159 bool G1DirtyCardQueueSet::refine_completed_buffer_concurrently(uint worker_i, size_t stop_at) {</span>
<span class="line-modified">160   G1RefineCardConcurrentlyClosure cl;</span>
<span class="line-modified">161   return apply_closure_to_completed_buffer(&amp;cl, worker_i, stop_at, false);</span>
<span class="line-modified">162 }</span>
<span class="line-modified">163 </span>
<span class="line-removed">164 bool G1DirtyCardQueueSet::apply_closure_during_gc(G1CardTableEntryClosure* cl, uint worker_i) {</span>
<span class="line-removed">165   assert_at_safepoint();</span>
<span class="line-removed">166   return apply_closure_to_completed_buffer(cl, worker_i, 0, true);</span>
<span class="line-removed">167 }</span>
<span class="line-removed">168 </span>
<span class="line-removed">169 bool G1DirtyCardQueueSet::apply_closure_to_completed_buffer(G1CardTableEntryClosure* cl,</span>
<span class="line-removed">170                                                             uint worker_i,</span>
<span class="line-removed">171                                                             size_t stop_at,</span>
<span class="line-removed">172                                                             bool during_pause) {</span>
<span class="line-removed">173   assert(!during_pause || stop_at == 0, &quot;Should not leave any completed buffers during a pause&quot;);</span>
<span class="line-removed">174   BufferNode* nd = get_completed_buffer(stop_at);</span>
<span class="line-removed">175   if (nd == NULL) {</span>
176     return false;





177   } else {
<span class="line-modified">178     if (apply_closure_to_buffer(cl, nd, true, worker_i)) {</span>
<span class="line-modified">179       assert_fully_consumed(nd, buffer_size());</span>
<span class="line-modified">180       // Done with fully processed buffer.</span>
<span class="line-removed">181       deallocate_buffer(nd);</span>
<span class="line-removed">182       Atomic::inc(&amp;_processed_buffers_rs_thread);</span>
<span class="line-removed">183     } else {</span>
<span class="line-removed">184       // Return partially processed buffer to the queue.</span>
<span class="line-removed">185       guarantee(!during_pause, &quot;Should never stop early&quot;);</span>
<span class="line-removed">186       enqueue_completed_buffer(nd);</span>
<span class="line-removed">187     }</span>
188     return true;
189   }
190 }
191 
<span class="line-removed">192 void G1DirtyCardQueueSet::par_apply_closure_to_all_completed_buffers(G1CardTableEntryClosure* cl) {</span>
<span class="line-removed">193   BufferNode* nd = _cur_par_buffer_node;</span>
<span class="line-removed">194   while (nd != NULL) {</span>
<span class="line-removed">195     BufferNode* next = nd-&gt;next();</span>
<span class="line-removed">196     BufferNode* actual = Atomic::cmpxchg(next, &amp;_cur_par_buffer_node, nd);</span>
<span class="line-removed">197     if (actual == nd) {</span>
<span class="line-removed">198       bool b = apply_closure_to_buffer(cl, nd, false);</span>
<span class="line-removed">199       guarantee(b, &quot;Should not stop early.&quot;);</span>
<span class="line-removed">200       nd = next;</span>
<span class="line-removed">201     } else {</span>
<span class="line-removed">202       nd = actual;</span>
<span class="line-removed">203     }</span>
<span class="line-removed">204   }</span>
<span class="line-removed">205 }</span>
<span class="line-removed">206 </span>
207 void G1DirtyCardQueueSet::abandon_logs() {
<span class="line-modified">208   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at safepoint.&quot;);</span>
209   abandon_completed_buffers();
210 
211   // Since abandon is done only at safepoints, we can safely manipulate
212   // these queues.
213   struct AbandonThreadLogClosure : public ThreadClosure {
214     virtual void do_thread(Thread* t) {
215       G1ThreadLocalData::dirty_card_queue(t).reset();
216     }
217   } closure;
218   Threads::threads_do(&amp;closure);
219 
<span class="line-modified">220   shared_dirty_card_queue()-&gt;reset();</span>
<span class="line-removed">221 }</span>
<span class="line-removed">222 </span>
<span class="line-removed">223 void G1DirtyCardQueueSet::concatenate_log(G1DirtyCardQueue&amp; dcq) {</span>
<span class="line-removed">224   if (!dcq.is_empty()) {</span>
<span class="line-removed">225     dcq.flush();</span>
<span class="line-removed">226   }</span>
227 }
228 
229 void G1DirtyCardQueueSet::concatenate_logs() {
230   // Iterate over all the threads, if we find a partial log add it to
231   // the global list of logs.  Temporarily turn off the limit on the number
232   // of outstanding buffers.
<span class="line-modified">233   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at safepoint.&quot;);</span>
<span class="line-modified">234   size_t old_limit = max_completed_buffers();</span>
<span class="line-modified">235   set_max_completed_buffers(MaxCompletedBuffersUnlimited);</span>
<span class="line-modified">236 </span>
<span class="line-modified">237   class ConcatenateThreadLogClosure : public ThreadClosure {</span>
<span class="line-removed">238     G1DirtyCardQueueSet* _qset;</span>
<span class="line-removed">239   public:</span>
<span class="line-removed">240     ConcatenateThreadLogClosure(G1DirtyCardQueueSet* qset) : _qset(qset) {}</span>
241     virtual void do_thread(Thread* t) {
<span class="line-modified">242       _qset-&gt;concatenate_log(G1ThreadLocalData::dirty_card_queue(t));</span>



243     }
<span class="line-modified">244   } closure(this);</span>
245   Threads::threads_do(&amp;closure);
246 
<span class="line-modified">247   concatenate_log(_shared_dirty_card_queue);</span>
<span class="line-modified">248   set_max_completed_buffers(old_limit);</span>


249 }
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2001, 2020, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
<span class="line-added"> 26 #include &quot;gc/g1/g1BufferNodeList.hpp&quot;</span>
<span class="line-added"> 27 #include &quot;gc/g1/g1CardTableEntryClosure.hpp&quot;</span>
 28 #include &quot;gc/g1/g1CollectedHeap.inline.hpp&quot;
<span class="line-added"> 29 #include &quot;gc/g1/g1ConcurrentRefineThread.hpp&quot;</span>
 30 #include &quot;gc/g1/g1DirtyCardQueue.hpp&quot;
 31 #include &quot;gc/g1/g1FreeIdSet.hpp&quot;
<span class="line-added"> 32 #include &quot;gc/g1/g1RedirtyCardsQueue.hpp&quot;</span>
 33 #include &quot;gc/g1/g1RemSet.hpp&quot;
 34 #include &quot;gc/g1/g1ThreadLocalData.hpp&quot;
 35 #include &quot;gc/g1/heapRegionRemSet.hpp&quot;
 36 #include &quot;gc/shared/suspendibleThreadSet.hpp&quot;
<span class="line-modified"> 37 #include &quot;memory/iterator.hpp&quot;</span>
 38 #include &quot;runtime/atomic.hpp&quot;
<span class="line-modified"> 39 #include &quot;runtime/os.hpp&quot;</span>

 40 #include &quot;runtime/safepoint.hpp&quot;
 41 #include &quot;runtime/thread.inline.hpp&quot;
 42 #include &quot;runtime/threadSMR.hpp&quot;
<span class="line-added"> 43 #include &quot;utilities/globalCounter.inline.hpp&quot;</span>
<span class="line-added"> 44 #include &quot;utilities/macros.hpp&quot;</span>
<span class="line-added"> 45 #include &quot;utilities/quickSort.hpp&quot;</span>
 46 
<span class="line-modified"> 47 G1DirtyCardQueue::G1DirtyCardQueue(G1DirtyCardQueueSet* qset) :</span>


















 48   // Dirty card queues are always active, so we create them with their
 49   // active field set to true.
<span class="line-modified"> 50   PtrQueue(qset, true /* active */)</span>
 51 { }
 52 
 53 G1DirtyCardQueue::~G1DirtyCardQueue() {
<span class="line-modified"> 54   flush();</span>
<span class="line-modified"> 55 }</span>
<span class="line-added"> 56 </span>
<span class="line-added"> 57 void G1DirtyCardQueue::handle_completed_buffer() {</span>
<span class="line-added"> 58   assert(_buf != NULL, &quot;precondition&quot;);</span>
<span class="line-added"> 59   BufferNode* node = BufferNode::make_node_from_buffer(_buf, index());</span>
<span class="line-added"> 60   G1DirtyCardQueueSet* dcqs = dirty_card_qset();</span>
<span class="line-added"> 61   if (dcqs-&gt;process_or_enqueue_completed_buffer(node)) {</span>
<span class="line-added"> 62     reset();                    // Buffer fully processed, reset index.</span>
<span class="line-added"> 63   } else {</span>
<span class="line-added"> 64     allocate_buffer();          // Buffer enqueued, get a new one.</span>
 65   }
 66 }
 67 
<span class="line-modified"> 68 // Assumed to be zero by concurrent threads.</span>
<span class="line-modified"> 69 static uint par_ids_start() { return 0; }</span>
<span class="line-modified"> 70 </span>
<span class="line-modified"> 71 G1DirtyCardQueueSet::G1DirtyCardQueueSet(BufferNode::Allocator* allocator) :</span>
<span class="line-modified"> 72   PtrQueueSet(allocator),</span>
<span class="line-modified"> 73   _primary_refinement_thread(NULL),</span>
<span class="line-modified"> 74   _num_cards(0),</span>
<span class="line-added"> 75   _completed(),</span>
<span class="line-added"> 76   _paused(),</span>
<span class="line-added"> 77   _free_ids(par_ids_start(), num_par_ids()),</span>
<span class="line-added"> 78   _process_cards_threshold(ProcessCardsThresholdNever),</span>
<span class="line-added"> 79   _max_cards(MaxCardsUnlimited),</span>
<span class="line-added"> 80   _max_cards_padding(0),</span>
<span class="line-added"> 81   _mutator_refined_cards_counters(NEW_C_HEAP_ARRAY(size_t, num_par_ids(), mtGC))</span>
 82 {
<span class="line-added"> 83   ::memset(_mutator_refined_cards_counters, 0, num_par_ids() * sizeof(size_t));</span>
 84   _all_active = true;
 85 }
 86 
 87 G1DirtyCardQueueSet::~G1DirtyCardQueueSet() {
<span class="line-modified"> 88   abandon_completed_buffers();</span>
<span class="line-added"> 89   FREE_C_HEAP_ARRAY(size_t, _mutator_refined_cards_counters);</span>
 90 }
 91 
 92 // Determines how many mutator threads can process the buffers in parallel.
 93 uint G1DirtyCardQueueSet::num_par_ids() {
 94   return (uint)os::initial_active_processor_count();
 95 }
 96 
<span class="line-modified"> 97 size_t G1DirtyCardQueueSet::total_mutator_refined_cards() const {</span>
<span class="line-modified"> 98   size_t sum = 0;</span>
<span class="line-modified"> 99   for (uint i = 0; i &lt; num_par_ids(); ++i) {</span>
<span class="line-modified">100     sum += _mutator_refined_cards_counters[i];</span>




101   }
<span class="line-added">102   return sum;</span>
103 }
104 
105 void G1DirtyCardQueueSet::handle_zero_index_for_thread(Thread* t) {
106   G1ThreadLocalData::dirty_card_queue(t).handle_zero_index();
107 }
108 
<span class="line-modified">109 #ifdef ASSERT</span>
<span class="line-modified">110 G1DirtyCardQueueSet::Queue::~Queue() {</span>
<span class="line-modified">111   assert(_head == NULL, &quot;precondition&quot;);</span>
<span class="line-modified">112   assert(_tail == NULL, &quot;precondition&quot;);</span>
<span class="line-modified">113 }</span>
<span class="line-modified">114 #endif // ASSERT</span>
<span class="line-modified">115 </span>
<span class="line-modified">116 BufferNode* G1DirtyCardQueueSet::Queue::top() const {</span>
<span class="line-modified">117   return Atomic::load(&amp;_head);</span>
<span class="line-modified">118 }</span>
<span class="line-modified">119 </span>
<span class="line-modified">120 // An append operation atomically exchanges the new tail with the queue tail.</span>
<span class="line-modified">121 // It then sets the &quot;next&quot; value of the old tail to the head of the list being</span>
<span class="line-modified">122 // appended; it is an invariant that the old tail&#39;s &quot;next&quot; value is NULL.</span>
<span class="line-modified">123 // But if the old tail is NULL then the queue was empty.  In this case the</span>
<span class="line-added">124 // head of the list being appended is instead stored in the queue head; it is</span>
<span class="line-added">125 // an invariant that the queue head is NULL in this case.</span>
<span class="line-added">126 //</span>
<span class="line-added">127 // This means there is a period between the exchange and the old tail update</span>
<span class="line-added">128 // where the queue sequence is split into two parts, the list from the queue</span>
<span class="line-added">129 // head to the old tail, and the list being appended.  If there are concurrent</span>
<span class="line-added">130 // push/append operations, each may introduce another such segment.  But they</span>
<span class="line-added">131 // all eventually get resolved by their respective updates of their old tail&#39;s</span>
<span class="line-added">132 // &quot;next&quot; value.  This also means that pop operations must handle a buffer</span>
<span class="line-added">133 // with a NULL &quot;next&quot; value specially.</span>
<span class="line-added">134 //</span>
<span class="line-added">135 // A push operation is just a degenerate append, where the buffer being pushed</span>
<span class="line-added">136 // is both the head and the tail of the list being appended.</span>
<span class="line-added">137 void G1DirtyCardQueueSet::Queue::append(BufferNode&amp; first, BufferNode&amp; last) {</span>
<span class="line-added">138   assert(last.next() == NULL, &quot;precondition&quot;);</span>
<span class="line-added">139   BufferNode* old_tail = Atomic::xchg(&amp;_tail, &amp;last);</span>
<span class="line-added">140   if (old_tail == NULL) {       // Was empty.</span>
<span class="line-added">141     Atomic::store(&amp;_head, &amp;first);</span>
<span class="line-added">142   } else {</span>
<span class="line-added">143     assert(old_tail-&gt;next() == NULL, &quot;invariant&quot;);</span>
<span class="line-added">144     old_tail-&gt;set_next(&amp;first);</span>
<span class="line-added">145   }</span>
<span class="line-added">146 }</span>
<span class="line-added">147 </span>
<span class="line-added">148 BufferNode* G1DirtyCardQueueSet::Queue::pop() {</span>
<span class="line-added">149   Thread* current_thread = Thread::current();</span>
<span class="line-added">150   while (true) {</span>
<span class="line-added">151     // Use a critical section per iteration, rather than over the whole</span>
<span class="line-added">152     // operation.  We&#39;re not guaranteed to make progress.  Lingering in one</span>
<span class="line-added">153     // CS could lead to excessive allocation of buffers, because the CS</span>
<span class="line-added">154     // blocks return of released buffers to the free list for reuse.</span>
<span class="line-added">155     GlobalCounter::CriticalSection cs(current_thread);</span>
<span class="line-added">156 </span>
<span class="line-added">157     BufferNode* result = Atomic::load_acquire(&amp;_head);</span>
<span class="line-added">158     if (result == NULL) return NULL; // Queue is empty.</span>
<span class="line-added">159 </span>
<span class="line-added">160     BufferNode* next = Atomic::load_acquire(BufferNode::next_ptr(*result));</span>
<span class="line-added">161     if (next != NULL) {</span>
<span class="line-added">162       // The &quot;usual&quot; lock-free pop from the head of a singly linked list.</span>
<span class="line-added">163       if (result == Atomic::cmpxchg(&amp;_head, result, next)) {</span>
<span class="line-added">164         // Former head successfully taken; it is not the last.</span>
<span class="line-added">165         assert(Atomic::load(&amp;_tail) != result, &quot;invariant&quot;);</span>
<span class="line-added">166         assert(result-&gt;next() != NULL, &quot;invariant&quot;);</span>
<span class="line-added">167         result-&gt;set_next(NULL);</span>
<span class="line-added">168         return result;</span>
<span class="line-added">169       }</span>
<span class="line-added">170       // Lost the race; try again.</span>
<span class="line-added">171       continue;</span>
<span class="line-added">172     }</span>
<span class="line-added">173 </span>
<span class="line-added">174     // next is NULL.  This case is handled differently from the &quot;usual&quot;</span>
<span class="line-added">175     // lock-free pop from the head of a singly linked list.</span>
<span class="line-added">176 </span>
<span class="line-added">177     // If _tail == result then result is the only element in the list. We can</span>
<span class="line-added">178     // remove it from the list by first setting _tail to NULL and then setting</span>
<span class="line-added">179     // _head to NULL, the order being important.  We set _tail with cmpxchg in</span>
<span class="line-added">180     // case of a concurrent push/append/pop also changing _tail.  If we win</span>
<span class="line-added">181     // then we&#39;ve claimed result.</span>
<span class="line-added">182     if (Atomic::cmpxchg(&amp;_tail, result, (BufferNode*)NULL) == result) {</span>
<span class="line-added">183       assert(result-&gt;next() == NULL, &quot;invariant&quot;);</span>
<span class="line-added">184       // Now that we&#39;ve claimed result, also set _head to NULL.  But we must</span>
<span class="line-added">185       // be careful of a concurrent push/append after we NULLed _tail, since</span>
<span class="line-added">186       // it may have already performed its list-was-empty update of _head,</span>
<span class="line-added">187       // which we must not overwrite.</span>
<span class="line-added">188       Atomic::cmpxchg(&amp;_head, result, (BufferNode*)NULL);</span>
<span class="line-added">189       return result;</span>
<span class="line-added">190     }</span>
<span class="line-added">191 </span>
<span class="line-added">192     // If _head != result then we lost the race to take result; try again.</span>
<span class="line-added">193     if (result != Atomic::load_acquire(&amp;_head)) {</span>
<span class="line-added">194       continue;</span>
<span class="line-added">195     }</span>
<span class="line-added">196 </span>
<span class="line-added">197     // An in-progress concurrent operation interfered with taking the head</span>
<span class="line-added">198     // element when it was the only element.  A concurrent pop may have won</span>
<span class="line-added">199     // the race to clear the tail but not yet cleared the head. Alternatively,</span>
<span class="line-added">200     // a concurrent push/append may have changed the tail but not yet linked</span>
<span class="line-added">201     // result-&gt;next().  We cannot take result in either case.  We don&#39;t just</span>
<span class="line-added">202     // try again, because we could spin for a long time waiting for that</span>
<span class="line-added">203     // concurrent operation to finish.  In the first case, returning NULL is</span>
<span class="line-added">204     // fine; we lost the race for the only element to another thread.  We</span>
<span class="line-added">205     // also return NULL for the second case, and let the caller cope.</span>
<span class="line-added">206     return NULL;</span>
<span class="line-added">207   }</span>
<span class="line-added">208 }</span>
<span class="line-added">209 </span>
<span class="line-added">210 G1DirtyCardQueueSet::HeadTail G1DirtyCardQueueSet::Queue::take_all() {</span>
<span class="line-added">211   assert_at_safepoint();</span>
<span class="line-added">212   HeadTail result(Atomic::load(&amp;_head), Atomic::load(&amp;_tail));</span>
<span class="line-added">213   Atomic::store(&amp;_head, (BufferNode*)NULL);</span>
<span class="line-added">214   Atomic::store(&amp;_tail, (BufferNode*)NULL);</span>
<span class="line-added">215   return result;</span>
<span class="line-added">216 }</span>
<span class="line-added">217 </span>
<span class="line-added">218 void G1DirtyCardQueueSet::enqueue_completed_buffer(BufferNode* cbn) {</span>
<span class="line-added">219   assert(cbn != NULL, &quot;precondition&quot;);</span>
<span class="line-added">220   // Increment _num_cards before adding to queue, so queue removal doesn&#39;t</span>
<span class="line-added">221   // need to deal with _num_cards possibly going negative.</span>
<span class="line-added">222   size_t new_num_cards = Atomic::add(&amp;_num_cards, buffer_size() - cbn-&gt;index());</span>
<span class="line-added">223   _completed.push(*cbn);</span>
<span class="line-added">224   if ((new_num_cards &gt; process_cards_threshold()) &amp;&amp;</span>
<span class="line-added">225       (_primary_refinement_thread != NULL)) {</span>
<span class="line-added">226     _primary_refinement_thread-&gt;activate();</span>
<span class="line-added">227   }</span>
<span class="line-added">228 }</span>
<span class="line-added">229 </span>
<span class="line-added">230 BufferNode* G1DirtyCardQueueSet::get_completed_buffer(size_t stop_at) {</span>
<span class="line-added">231   enqueue_previous_paused_buffers();</span>
<span class="line-added">232 </span>
<span class="line-added">233   // Check for insufficient cards to satisfy request.  We only do this once,</span>
<span class="line-added">234   // up front, rather than on each iteration below, since the test is racy</span>
<span class="line-added">235   // regardless of when we do it.</span>
<span class="line-added">236   if (Atomic::load_acquire(&amp;_num_cards) &lt;= stop_at) {</span>
<span class="line-added">237     return NULL;</span>
<span class="line-added">238   }</span>
<span class="line-added">239 </span>
<span class="line-added">240   BufferNode* result = _completed.pop();</span>
<span class="line-added">241   if (result != NULL) {</span>
<span class="line-added">242     Atomic::sub(&amp;_num_cards, buffer_size() - result-&gt;index());</span>
<span class="line-added">243   }</span>
<span class="line-added">244   return result;</span>
<span class="line-added">245 }</span>
<span class="line-added">246 </span>
<span class="line-added">247 #ifdef ASSERT</span>
<span class="line-added">248 void G1DirtyCardQueueSet::verify_num_cards() const {</span>
<span class="line-added">249   size_t actual = 0;</span>
<span class="line-added">250   BufferNode* cur = _completed.top();</span>
<span class="line-added">251   for ( ; cur != NULL; cur = cur-&gt;next()) {</span>
<span class="line-added">252     actual += buffer_size() - cur-&gt;index();</span>
<span class="line-added">253   }</span>
<span class="line-added">254   assert(actual == Atomic::load(&amp;_num_cards),</span>
<span class="line-added">255          &quot;Num entries in completed buffers should be &quot; SIZE_FORMAT &quot; but are &quot; SIZE_FORMAT,</span>
<span class="line-added">256          Atomic::load(&amp;_num_cards), actual);</span>
<span class="line-added">257 }</span>
<span class="line-added">258 #endif // ASSERT</span>
<span class="line-added">259 </span>
<span class="line-added">260 G1DirtyCardQueueSet::PausedBuffers::PausedList::PausedList() :</span>
<span class="line-added">261   _head(NULL), _tail(NULL),</span>
<span class="line-added">262   _safepoint_id(SafepointSynchronize::safepoint_id())</span>
<span class="line-added">263 {}</span>
<span class="line-added">264 </span>
<span class="line-added">265 #ifdef ASSERT</span>
<span class="line-added">266 G1DirtyCardQueueSet::PausedBuffers::PausedList::~PausedList() {</span>
<span class="line-added">267   assert(Atomic::load(&amp;_head) == NULL, &quot;precondition&quot;);</span>
<span class="line-added">268   assert(_tail == NULL, &quot;precondition&quot;);</span>
<span class="line-added">269 }</span>
<span class="line-added">270 #endif // ASSERT</span>
<span class="line-added">271 </span>
<span class="line-added">272 bool G1DirtyCardQueueSet::PausedBuffers::PausedList::is_next() const {</span>
<span class="line-added">273   assert_not_at_safepoint();</span>
<span class="line-added">274   return _safepoint_id == SafepointSynchronize::safepoint_id();</span>
<span class="line-added">275 }</span>
<span class="line-added">276 </span>
<span class="line-added">277 void G1DirtyCardQueueSet::PausedBuffers::PausedList::add(BufferNode* node) {</span>
<span class="line-added">278   assert_not_at_safepoint();</span>
<span class="line-added">279   assert(is_next(), &quot;precondition&quot;);</span>
<span class="line-added">280   BufferNode* old_head = Atomic::xchg(&amp;_head, node);</span>
<span class="line-added">281   if (old_head == NULL) {</span>
<span class="line-added">282     assert(_tail == NULL, &quot;invariant&quot;);</span>
<span class="line-added">283     _tail = node;</span>
<span class="line-added">284   } else {</span>
<span class="line-added">285     node-&gt;set_next(old_head);</span>
<span class="line-added">286   }</span>
<span class="line-added">287 }</span>
<span class="line-added">288 </span>
<span class="line-added">289 G1DirtyCardQueueSet::HeadTail G1DirtyCardQueueSet::PausedBuffers::PausedList::take() {</span>
<span class="line-added">290   BufferNode* head = Atomic::load(&amp;_head);</span>
<span class="line-added">291   BufferNode* tail = _tail;</span>
<span class="line-added">292   Atomic::store(&amp;_head, (BufferNode*)NULL);</span>
<span class="line-added">293   _tail = NULL;</span>
<span class="line-added">294   return HeadTail(head, tail);</span>
<span class="line-added">295 }</span>
<span class="line-added">296 </span>
<span class="line-added">297 G1DirtyCardQueueSet::PausedBuffers::PausedBuffers() : _plist(NULL) {}</span>
<span class="line-added">298 </span>
<span class="line-added">299 #ifdef ASSERT</span>
<span class="line-added">300 G1DirtyCardQueueSet::PausedBuffers::~PausedBuffers() {</span>
<span class="line-added">301   assert(is_empty(), &quot;invariant&quot;);</span>
<span class="line-added">302 }</span>
<span class="line-added">303 #endif // ASSERT</span>
<span class="line-added">304 </span>
<span class="line-added">305 bool G1DirtyCardQueueSet::PausedBuffers::is_empty() const {</span>
<span class="line-added">306   return Atomic::load(&amp;_plist) == NULL;</span>
<span class="line-added">307 }</span>
<span class="line-added">308 </span>
<span class="line-added">309 void G1DirtyCardQueueSet::PausedBuffers::add(BufferNode* node) {</span>
<span class="line-added">310   assert_not_at_safepoint();</span>
<span class="line-added">311   PausedList* plist = Atomic::load_acquire(&amp;_plist);</span>
<span class="line-added">312   if (plist != NULL) {</span>
<span class="line-added">313     // Already have a next list, so use it.  We know it&#39;s a next list because</span>
<span class="line-added">314     // of the precondition that take_previous() has already been called.</span>
<span class="line-added">315     assert(plist-&gt;is_next(), &quot;invariant&quot;);</span>
<span class="line-added">316   } else {</span>
<span class="line-added">317     // Try to install a new next list.</span>
<span class="line-added">318     plist = new PausedList();</span>
<span class="line-added">319     PausedList* old_plist = Atomic::cmpxchg(&amp;_plist, (PausedList*)NULL, plist);</span>
<span class="line-added">320     if (old_plist != NULL) {</span>
<span class="line-added">321       // Some other thread installed a new next list. Use it instead.</span>
<span class="line-added">322       delete plist;</span>
<span class="line-added">323       plist = old_plist;</span>
<span class="line-added">324     }</span>
<span class="line-added">325   }</span>
<span class="line-added">326   plist-&gt;add(node);</span>
<span class="line-added">327 }</span>
<span class="line-added">328 </span>
<span class="line-added">329 G1DirtyCardQueueSet::HeadTail G1DirtyCardQueueSet::PausedBuffers::take_previous() {</span>
<span class="line-added">330   assert_not_at_safepoint();</span>
<span class="line-added">331   PausedList* previous;</span>
<span class="line-added">332   {</span>
<span class="line-added">333     // Deal with plist in a critical section, to prevent it from being</span>
<span class="line-added">334     // deleted out from under us by a concurrent take_previous().</span>
<span class="line-added">335     GlobalCounter::CriticalSection cs(Thread::current());</span>
<span class="line-added">336     previous = Atomic::load_acquire(&amp;_plist);</span>
<span class="line-added">337     if ((previous == NULL) ||   // Nothing to take.</span>
<span class="line-added">338         previous-&gt;is_next() ||  // Not from a previous safepoint.</span>
<span class="line-added">339         // Some other thread stole it.</span>
<span class="line-added">340         (Atomic::cmpxchg(&amp;_plist, previous, (PausedList*)NULL) != previous)) {</span>
<span class="line-added">341       return HeadTail();</span>
342     }
343   }
<span class="line-modified">344   // We now own previous.</span>
<span class="line-modified">345   HeadTail result = previous-&gt;take();</span>
<span class="line-modified">346   // There might be other threads examining previous (in concurrent</span>
<span class="line-added">347   // take_previous()).  Synchronize to wait until any such threads are</span>
<span class="line-added">348   // done with such examination before deleting.</span>
<span class="line-added">349   GlobalCounter::write_synchronize();</span>
<span class="line-added">350   delete previous;</span>
<span class="line-added">351   return result;</span>
<span class="line-added">352 }</span>
<span class="line-added">353 </span>
<span class="line-added">354 G1DirtyCardQueueSet::HeadTail G1DirtyCardQueueSet::PausedBuffers::take_all() {</span>
<span class="line-added">355   assert_at_safepoint();</span>
<span class="line-added">356   HeadTail result;</span>
<span class="line-added">357   PausedList* plist = Atomic::load(&amp;_plist);</span>
<span class="line-added">358   if (plist != NULL) {</span>
<span class="line-added">359     Atomic::store(&amp;_plist, (PausedList*)NULL);</span>
<span class="line-added">360     result = plist-&gt;take();</span>
<span class="line-added">361     delete plist;</span>
362   }
363   return result;
364 }
365 
<span class="line-added">366 void G1DirtyCardQueueSet::record_paused_buffer(BufferNode* node) {</span>
<span class="line-added">367   assert_not_at_safepoint();</span>
<span class="line-added">368   assert(node-&gt;next() == NULL, &quot;precondition&quot;);</span>
<span class="line-added">369   // Cards for paused buffers are included in count, to contribute to</span>
<span class="line-added">370   // notification checking after the coming safepoint if it doesn&#39;t GC.</span>
<span class="line-added">371   // Note that this means the queue&#39;s _num_cards differs from the number</span>
<span class="line-added">372   // of cards in the queued buffers when there are paused buffers.</span>
<span class="line-added">373   Atomic::add(&amp;_num_cards, buffer_size() - node-&gt;index());</span>
<span class="line-added">374   _paused.add(node);</span>
<span class="line-added">375 }</span>
<span class="line-added">376 </span>
<span class="line-added">377 void G1DirtyCardQueueSet::enqueue_paused_buffers_aux(const HeadTail&amp; paused) {</span>
<span class="line-added">378   if (paused._head != NULL) {</span>
<span class="line-added">379     assert(paused._tail != NULL, &quot;invariant&quot;);</span>
<span class="line-added">380     // Cards from paused buffers are already recorded in the queue count.</span>
<span class="line-added">381     _completed.append(*paused._head, *paused._tail);</span>
<span class="line-added">382   }</span>
<span class="line-added">383 }</span>
<span class="line-added">384 </span>
<span class="line-added">385 void G1DirtyCardQueueSet::enqueue_previous_paused_buffers() {</span>
<span class="line-added">386   assert_not_at_safepoint();</span>
<span class="line-added">387   // The fast-path still satisfies the precondition for record_paused_buffer</span>
<span class="line-added">388   // and PausedBuffers::add, even with a racy test.  If there are paused</span>
<span class="line-added">389   // buffers from a previous safepoint, is_empty() will return false; there</span>
<span class="line-added">390   // will have been a safepoint between recording and test, so there can&#39;t be</span>
<span class="line-added">391   // a false negative (is_empty() returns true) while such buffers are present.</span>
<span class="line-added">392   // If is_empty() is false, there are two cases:</span>
<span class="line-added">393   //</span>
<span class="line-added">394   // (1) There were paused buffers from a previous safepoint.  A concurrent</span>
<span class="line-added">395   // caller may take and enqueue them first, but that&#39;s okay; the precondition</span>
<span class="line-added">396   // for a possible later record_paused_buffer by this thread will still hold.</span>
<span class="line-added">397   //</span>
<span class="line-added">398   // (2) There are paused buffers for a requested next safepoint.</span>
<span class="line-added">399   //</span>
<span class="line-added">400   // In each of those cases some effort may be spent detecting and dealing</span>
<span class="line-added">401   // with those circumstances; any wasted effort in such cases is expected to</span>
<span class="line-added">402   // be well compensated by the fast path.</span>
<span class="line-added">403   if (!_paused.is_empty()) {</span>
<span class="line-added">404     enqueue_paused_buffers_aux(_paused.take_previous());</span>
<span class="line-added">405   }</span>
<span class="line-added">406 }</span>
<span class="line-added">407 </span>
<span class="line-added">408 void G1DirtyCardQueueSet::enqueue_all_paused_buffers() {</span>
<span class="line-added">409   assert_at_safepoint();</span>
<span class="line-added">410   enqueue_paused_buffers_aux(_paused.take_all());</span>
<span class="line-added">411 }</span>
<span class="line-added">412 </span>
<span class="line-added">413 void G1DirtyCardQueueSet::abandon_completed_buffers() {</span>
<span class="line-added">414   enqueue_all_paused_buffers();</span>
<span class="line-added">415   verify_num_cards();</span>
<span class="line-added">416   G1BufferNodeList list = take_all_completed_buffers();</span>
<span class="line-added">417   BufferNode* buffers_to_delete = list._head;</span>
<span class="line-added">418   while (buffers_to_delete != NULL) {</span>
<span class="line-added">419     BufferNode* bn = buffers_to_delete;</span>
<span class="line-added">420     buffers_to_delete = bn-&gt;next();</span>
<span class="line-added">421     bn-&gt;set_next(NULL);</span>
<span class="line-added">422     deallocate_buffer(bn);</span>
<span class="line-added">423   }</span>
<span class="line-added">424 }</span>
<span class="line-added">425 </span>
<span class="line-added">426 void G1DirtyCardQueueSet::notify_if_necessary() {</span>
<span class="line-added">427   if ((_primary_refinement_thread != NULL) &amp;&amp;</span>
<span class="line-added">428       (num_cards() &gt; process_cards_threshold())) {</span>
<span class="line-added">429     _primary_refinement_thread-&gt;activate();</span>
<span class="line-added">430   }</span>
<span class="line-added">431 }</span>
<span class="line-added">432 </span>
<span class="line-added">433 // Merge lists of buffers. The source queue set is emptied as a</span>
<span class="line-added">434 // result. The queue sets must share the same allocator.</span>
<span class="line-added">435 void G1DirtyCardQueueSet::merge_bufferlists(G1RedirtyCardsQueueSet* src) {</span>
<span class="line-added">436   assert(allocator() == src-&gt;allocator(), &quot;precondition&quot;);</span>
<span class="line-added">437   const G1BufferNodeList from = src-&gt;take_all_completed_buffers();</span>
<span class="line-added">438   if (from._head != NULL) {</span>
<span class="line-added">439     Atomic::add(&amp;_num_cards, from._entry_count);</span>
<span class="line-added">440     _completed.append(*from._head, *from._tail);</span>
<span class="line-added">441   }</span>
<span class="line-added">442 }</span>
<span class="line-added">443 </span>
<span class="line-added">444 G1BufferNodeList G1DirtyCardQueueSet::take_all_completed_buffers() {</span>
<span class="line-added">445   enqueue_all_paused_buffers();</span>
<span class="line-added">446   verify_num_cards();</span>
<span class="line-added">447   HeadTail buffers = _completed.take_all();</span>
<span class="line-added">448   size_t num_cards = Atomic::load(&amp;_num_cards);</span>
<span class="line-added">449   Atomic::store(&amp;_num_cards, size_t(0));</span>
<span class="line-added">450   return G1BufferNodeList(buffers._head, buffers._tail, num_cards);</span>
<span class="line-added">451 }</span>
<span class="line-added">452 </span>
<span class="line-added">453 class G1RefineBufferedCards : public StackObj {</span>
<span class="line-added">454   BufferNode* const _node;</span>
<span class="line-added">455   CardTable::CardValue** const _node_buffer;</span>
<span class="line-added">456   const size_t _node_buffer_size;</span>
<span class="line-added">457   const uint _worker_id;</span>
<span class="line-added">458   size_t* _total_refined_cards;</span>
<span class="line-added">459   G1RemSet* const _g1rs;</span>
<span class="line-added">460 </span>
<span class="line-added">461   static inline int compare_card(const CardTable::CardValue* p1,</span>
<span class="line-added">462                                  const CardTable::CardValue* p2) {</span>
<span class="line-added">463     return p2 - p1;</span>
<span class="line-added">464   }</span>
<span class="line-added">465 </span>
<span class="line-added">466   // Sorts the cards from start_index to _node_buffer_size in *decreasing*</span>
<span class="line-added">467   // address order. Tests showed that this order is preferable to not sorting</span>
<span class="line-added">468   // or increasing address order.</span>
<span class="line-added">469   void sort_cards(size_t start_index) {</span>
<span class="line-added">470     QuickSort::sort(&amp;_node_buffer[start_index],</span>
<span class="line-added">471                     _node_buffer_size - start_index,</span>
<span class="line-added">472                     compare_card,</span>
<span class="line-added">473                     false);</span>
<span class="line-added">474   }</span>
<span class="line-added">475 </span>
<span class="line-added">476   // Returns the index to the first clean card in the buffer.</span>
<span class="line-added">477   size_t clean_cards() {</span>
<span class="line-added">478     const size_t start = _node-&gt;index();</span>
<span class="line-added">479     assert(start &lt;= _node_buffer_size, &quot;invariant&quot;);</span>
<span class="line-added">480 </span>
<span class="line-added">481     // Two-fingered compaction algorithm similar to the filtering mechanism in</span>
<span class="line-added">482     // SATBMarkQueue. The main difference is that clean_card_before_refine()</span>
<span class="line-added">483     // could change the buffer element in-place.</span>
<span class="line-added">484     // We don&#39;t check for SuspendibleThreadSet::should_yield(), because</span>
<span class="line-added">485     // cleaning and redirtying the cards is fast.</span>
<span class="line-added">486     CardTable::CardValue** src = &amp;_node_buffer[start];</span>
<span class="line-added">487     CardTable::CardValue** dst = &amp;_node_buffer[_node_buffer_size];</span>
<span class="line-added">488     assert(src &lt;= dst, &quot;invariant&quot;);</span>
<span class="line-added">489     for ( ; src &lt; dst; ++src) {</span>
<span class="line-added">490       // Search low to high for a card to keep.</span>
<span class="line-added">491       if (_g1rs-&gt;clean_card_before_refine(src)) {</span>
<span class="line-added">492         // Found keeper.  Search high to low for a card to discard.</span>
<span class="line-added">493         while (src &lt; --dst) {</span>
<span class="line-added">494           if (!_g1rs-&gt;clean_card_before_refine(dst)) {</span>
<span class="line-added">495             *dst = *src;         // Replace discard with keeper.</span>
<span class="line-added">496             break;</span>
<span class="line-added">497           }</span>
<span class="line-added">498         }</span>
<span class="line-added">499         // If discard search failed (src == dst), the outer loop will also end.</span>
<span class="line-added">500       }</span>
<span class="line-added">501     }</span>
<span class="line-added">502 </span>
<span class="line-added">503     // dst points to the first retained clean card, or the end of the buffer</span>
<span class="line-added">504     // if all the cards were discarded.</span>
<span class="line-added">505     const size_t first_clean = dst - _node_buffer;</span>
<span class="line-added">506     assert(first_clean &gt;= start &amp;&amp; first_clean &lt;= _node_buffer_size, &quot;invariant&quot;);</span>
<span class="line-added">507     // Discarded cards are considered as refined.</span>
<span class="line-added">508     *_total_refined_cards += first_clean - start;</span>
<span class="line-added">509     return first_clean;</span>
<span class="line-added">510   }</span>
<span class="line-added">511 </span>
<span class="line-added">512   bool refine_cleaned_cards(size_t start_index) {</span>
<span class="line-added">513     bool result = true;</span>
<span class="line-added">514     size_t i = start_index;</span>
<span class="line-added">515     for ( ; i &lt; _node_buffer_size; ++i) {</span>
<span class="line-added">516       if (SuspendibleThreadSet::should_yield()) {</span>
<span class="line-added">517         redirty_unrefined_cards(i);</span>
<span class="line-added">518         result = false;</span>
<span class="line-added">519         break;</span>
<span class="line-added">520       }</span>
<span class="line-added">521       _g1rs-&gt;refine_card_concurrently(_node_buffer[i], _worker_id);</span>
<span class="line-added">522     }</span>
<span class="line-added">523     _node-&gt;set_index(i);</span>
<span class="line-added">524     *_total_refined_cards += i - start_index;</span>
<span class="line-added">525     return result;</span>
<span class="line-added">526   }</span>
<span class="line-added">527 </span>
<span class="line-added">528   void redirty_unrefined_cards(size_t start) {</span>
<span class="line-added">529     for ( ; start &lt; _node_buffer_size; ++start) {</span>
<span class="line-added">530       *_node_buffer[start] = G1CardTable::dirty_card_val();</span>
<span class="line-added">531     }</span>
<span class="line-added">532   }</span>
<span class="line-added">533 </span>
<span class="line-added">534 public:</span>
<span class="line-added">535   G1RefineBufferedCards(BufferNode* node,</span>
<span class="line-added">536                         size_t node_buffer_size,</span>
<span class="line-added">537                         uint worker_id,</span>
<span class="line-added">538                         size_t* total_refined_cards) :</span>
<span class="line-added">539     _node(node),</span>
<span class="line-added">540     _node_buffer(reinterpret_cast&lt;CardTable::CardValue**&gt;(BufferNode::make_buffer_from_node(node))),</span>
<span class="line-added">541     _node_buffer_size(node_buffer_size),</span>
<span class="line-added">542     _worker_id(worker_id),</span>
<span class="line-added">543     _total_refined_cards(total_refined_cards),</span>
<span class="line-added">544     _g1rs(G1CollectedHeap::heap()-&gt;rem_set()) {}</span>
<span class="line-added">545 </span>
<span class="line-added">546   bool refine() {</span>
<span class="line-added">547     size_t first_clean_index = clean_cards();</span>
<span class="line-added">548     if (first_clean_index == _node_buffer_size) {</span>
<span class="line-added">549       _node-&gt;set_index(first_clean_index);</span>
<span class="line-added">550       return true;</span>
<span class="line-added">551     }</span>
<span class="line-added">552     // This fence serves two purposes. First, the cards must be cleaned</span>
<span class="line-added">553     // before processing the contents. Second, we can&#39;t proceed with</span>
<span class="line-added">554     // processing a region until after the read of the region&#39;s top in</span>
<span class="line-added">555     // collect_and_clean_cards(), for synchronization with possibly concurrent</span>
<span class="line-added">556     // humongous object allocation (see comment at the StoreStore fence before</span>
<span class="line-added">557     // setting the regions&#39; tops in humongous allocation path).</span>
<span class="line-added">558     // It&#39;s okay that reading region&#39;s top and reading region&#39;s type were racy</span>
<span class="line-added">559     // wrto each other. We need both set, in any order, to proceed.</span>
<span class="line-added">560     OrderAccess::fence();</span>
<span class="line-added">561     sort_cards(first_clean_index);</span>
<span class="line-added">562     return refine_cleaned_cards(first_clean_index);</span>
<span class="line-added">563   }</span>
<span class="line-added">564 };</span>
<span class="line-added">565 </span>
<span class="line-added">566 bool G1DirtyCardQueueSet::refine_buffer(BufferNode* node,</span>
<span class="line-added">567                                         uint worker_id,</span>
<span class="line-added">568                                         size_t* total_refined_cards) {</span>
<span class="line-added">569   G1RefineBufferedCards buffered_cards(node,</span>
<span class="line-added">570                                        buffer_size(),</span>
<span class="line-added">571                                        worker_id,</span>
<span class="line-added">572                                        total_refined_cards);</span>
<span class="line-added">573   return buffered_cards.refine();</span>
<span class="line-added">574 }</span>
<span class="line-added">575 </span>
576 #ifndef ASSERT
577 #define assert_fully_consumed(node, buffer_size)
578 #else
579 #define assert_fully_consumed(node, buffer_size)                \
580   do {                                                          \
581     size_t _afc_index = (node)-&gt;index();                        \
582     size_t _afc_size = (buffer_size);                           \
583     assert(_afc_index == _afc_size,                             \
584            &quot;Buffer was not fully consumed as claimed: index: &quot;  \
585            SIZE_FORMAT &quot;, size: &quot; SIZE_FORMAT,                  \
586             _afc_index, _afc_size);                             \
587   } while (0)
588 #endif // ASSERT
589 
<span class="line-modified">590 bool G1DirtyCardQueueSet::process_or_enqueue_completed_buffer(BufferNode* node) {</span>
<span class="line-modified">591   if (Thread::current()-&gt;is_Java_thread()) {</span>
<span class="line-added">592     // If the number of buffers exceeds the limit, make this Java</span>
<span class="line-added">593     // thread do the processing itself.  Calculation is racy but we</span>
<span class="line-added">594     // don&#39;t need precision here.  The add of padding could overflow,</span>
<span class="line-added">595     // which is treated as unlimited.</span>
<span class="line-added">596     size_t limit = max_cards() + max_cards_padding();</span>
<span class="line-added">597     if ((num_cards() &gt; limit) &amp;&amp; (limit &gt;= max_cards())) {</span>
<span class="line-added">598       if (mut_process_buffer(node)) {</span>
<span class="line-added">599         return true;</span>
<span class="line-added">600       }</span>
<span class="line-added">601       // Buffer was incompletely processed because of a pending safepoint</span>
<span class="line-added">602       // request.  Unlike with refinement thread processing, for mutator</span>
<span class="line-added">603       // processing the buffer did not come from the completed buffer queue,</span>
<span class="line-added">604       // so it is okay to add it to the queue rather than to the paused set.</span>
<span class="line-added">605       // Indeed, it can&#39;t be added to the paused set because we didn&#39;t pass</span>
<span class="line-added">606       // through enqueue_previous_paused_buffers.</span>
<span class="line-added">607     }</span>
<span class="line-added">608   }</span>
<span class="line-added">609   enqueue_completed_buffer(node);</span>
<span class="line-added">610   return false;</span>
<span class="line-added">611 }</span>
612 
<span class="line-modified">613 bool G1DirtyCardQueueSet::mut_process_buffer(BufferNode* node) {</span>
<span class="line-modified">614   uint worker_id = _free_ids.claim_par_id(); // temporarily claim an id</span>
<span class="line-modified">615   uint counter_index = worker_id - par_ids_start();</span>
<span class="line-modified">616   size_t* counter = &amp;_mutator_refined_cards_counters[counter_index];</span>
<span class="line-added">617   bool result = refine_buffer(node, worker_id, counter);</span>
<span class="line-added">618   _free_ids.release_par_id(worker_id); // release the id</span>
619 
620   if (result) {
621     assert_fully_consumed(node, buffer_size());

622   }
623   return result;
624 }
625 
<span class="line-modified">626 bool G1DirtyCardQueueSet::refine_completed_buffer_concurrently(uint worker_id,</span>
<span class="line-modified">627                                                                size_t stop_at,</span>
<span class="line-modified">628                                                                size_t* total_refined_cards) {</span>
<span class="line-modified">629   BufferNode* node = get_completed_buffer(stop_at);</span>
<span class="line-modified">630   if (node == NULL) {</span>












631     return false;
<span class="line-added">632   } else if (refine_buffer(node, worker_id, total_refined_cards)) {</span>
<span class="line-added">633     assert_fully_consumed(node, buffer_size());</span>
<span class="line-added">634     // Done with fully processed buffer.</span>
<span class="line-added">635     deallocate_buffer(node);</span>
<span class="line-added">636     return true;</span>
637   } else {
<span class="line-modified">638     // Buffer incompletely processed because there is a pending safepoint.</span>
<span class="line-modified">639     // Record partially processed buffer, to be finished later.</span>
<span class="line-modified">640     record_paused_buffer(node);</span>







641     return true;
642   }
643 }
644 















645 void G1DirtyCardQueueSet::abandon_logs() {
<span class="line-modified">646   assert_at_safepoint();</span>
647   abandon_completed_buffers();
648 
649   // Since abandon is done only at safepoints, we can safely manipulate
650   // these queues.
651   struct AbandonThreadLogClosure : public ThreadClosure {
652     virtual void do_thread(Thread* t) {
653       G1ThreadLocalData::dirty_card_queue(t).reset();
654     }
655   } closure;
656   Threads::threads_do(&amp;closure);
657 
<span class="line-modified">658   G1BarrierSet::shared_dirty_card_queue().reset();</span>






659 }
660 
661 void G1DirtyCardQueueSet::concatenate_logs() {
662   // Iterate over all the threads, if we find a partial log add it to
663   // the global list of logs.  Temporarily turn off the limit on the number
664   // of outstanding buffers.
<span class="line-modified">665   assert_at_safepoint();</span>
<span class="line-modified">666   size_t old_limit = max_cards();</span>
<span class="line-modified">667   set_max_cards(MaxCardsUnlimited);</span>
<span class="line-modified">668 </span>
<span class="line-modified">669   struct ConcatenateThreadLogClosure : public ThreadClosure {</span>



670     virtual void do_thread(Thread* t) {
<span class="line-modified">671       G1DirtyCardQueue&amp; dcq = G1ThreadLocalData::dirty_card_queue(t);</span>
<span class="line-added">672       if (!dcq.is_empty()) {</span>
<span class="line-added">673         dcq.flush();</span>
<span class="line-added">674       }</span>
675     }
<span class="line-modified">676   } closure;</span>
677   Threads::threads_do(&amp;closure);
678 
<span class="line-modified">679   G1BarrierSet::shared_dirty_card_queue().flush();</span>
<span class="line-modified">680   enqueue_all_paused_buffers();</span>
<span class="line-added">681   verify_num_cards();</span>
<span class="line-added">682   set_max_cards(old_limit);</span>
683 }
</pre>
</td>
</tr>
</table>
<center><a href="g1ConcurrentRefineThread.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1DirtyCardQueue.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>