<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/gc/g1/g1ParScanThreadState.inline.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
    <script type="text/javascript" src="../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (c) 2014, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_GC_G1_G1PARSCANTHREADSTATE_INLINE_HPP
 26 #define SHARE_GC_G1_G1PARSCANTHREADSTATE_INLINE_HPP
 27 
 28 #include &quot;gc/g1/g1CollectedHeap.inline.hpp&quot;
 29 #include &quot;gc/g1/g1OopStarChunkedList.inline.hpp&quot;
 30 #include &quot;gc/g1/g1ParScanThreadState.hpp&quot;
 31 #include &quot;gc/g1/g1RemSet.hpp&quot;
 32 #include &quot;oops/access.inline.hpp&quot;
 33 #include &quot;oops/oop.inline.hpp&quot;
 34 
 35 template &lt;class T&gt; void G1ParScanThreadState::do_oop_evac(T* p) {
 36   // Reference should not be NULL here as such are never pushed to the task queue.
 37   oop obj = RawAccess&lt;IS_NOT_NULL&gt;::oop_load(p);
 38 
 39   // Although we never intentionally push references outside of the collection
 40   // set, due to (benign) races in the claim mechanism during RSet scanning more
 41   // than one thread might claim the same card. So the same card may be
 42   // processed multiple times, and so we might get references into old gen here.
 43   // So we need to redo this check.
<a name="1" id="anc1"></a><span class="line-modified"> 44   const G1HeapRegionAttr region_attr = _g1h-&gt;region_attr(obj);</span>
 45   // References pushed onto the work stack should never point to a humongous region
 46   // as they are not added to the collection set due to above precondition.
<a name="2" id="anc2"></a><span class="line-modified"> 47   assert(!region_attr.is_humongous(),</span>
 48          &quot;Obj &quot; PTR_FORMAT &quot; should not refer to humongous region %u from &quot; PTR_FORMAT,
<a name="3" id="anc3"></a><span class="line-modified"> 49          p2i(obj), _g1h-&gt;addr_to_region(cast_from_oop&lt;HeapWord*&gt;(obj)), p2i(p));</span>
 50 
<a name="4" id="anc4"></a><span class="line-modified"> 51   if (!region_attr.is_in_cset()) {</span>
 52     // In this case somebody else already did all the work.
 53     return;
 54   }
 55 
<a name="5" id="anc5"></a><span class="line-modified"> 56   markWord m = obj-&gt;mark_raw();</span>
<span class="line-modified"> 57   if (m.is_marked()) {</span>
<span class="line-modified"> 58     obj = (oop) m.decode_pointer();</span>
 59   } else {
<a name="6" id="anc6"></a><span class="line-modified"> 60     obj = copy_to_survivor_space(region_attr, obj, m);</span>
 61   }
 62   RawAccess&lt;IS_NOT_NULL&gt;::oop_store(p, obj);
 63 
 64   assert(obj != NULL, &quot;Must be&quot;);
 65   if (HeapRegion::is_in_same_region(p, obj)) {
 66     return;
 67   }
 68   HeapRegion* from = _g1h-&gt;heap_region_containing(p);
 69   if (!from-&gt;is_young()) {
<a name="7" id="anc7"></a><span class="line-modified"> 70     enqueue_card_if_tracked(_g1h-&gt;region_attr(obj), p, obj);</span>
 71   }
 72 }
 73 
 74 template &lt;class T&gt; inline void G1ParScanThreadState::push_on_queue(T* ref) {
 75   assert(verify_ref(ref), &quot;sanity&quot;);
 76   _refs-&gt;push(ref);
 77 }
 78 
 79 inline void G1ParScanThreadState::do_oop_partial_array(oop* p) {
 80   assert(has_partial_array_mask(p), &quot;invariant&quot;);
 81   oop from_obj = clear_partial_array_mask(p);
 82 
 83   assert(_g1h-&gt;is_in_reserved(from_obj), &quot;must be in heap.&quot;);
 84   assert(from_obj-&gt;is_objArray(), &quot;must be obj array&quot;);
 85   objArrayOop from_obj_array = objArrayOop(from_obj);
 86   // The from-space object contains the real length.
 87   int length                 = from_obj_array-&gt;length();
 88 
 89   assert(from_obj-&gt;is_forwarded(), &quot;must be forwarded&quot;);
 90   oop to_obj                 = from_obj-&gt;forwardee();
 91   assert(from_obj != to_obj, &quot;should not be chunking self-forwarded objects&quot;);
 92   objArrayOop to_obj_array   = objArrayOop(to_obj);
 93   // We keep track of the next start index in the length field of the
 94   // to-space object.
 95   int next_index             = to_obj_array-&gt;length();
 96   assert(0 &lt;= next_index &amp;&amp; next_index &lt; length,
 97          &quot;invariant, next index: %d, length: %d&quot;, next_index, length);
 98 
 99   int start                  = next_index;
100   int end                    = length;
101   int remainder              = end - start;
102   // We&#39;ll try not to push a range that&#39;s smaller than ParGCArrayScanChunk.
103   if (remainder &gt; 2 * ParGCArrayScanChunk) {
104     end = start + ParGCArrayScanChunk;
105     to_obj_array-&gt;set_length(end);
106     // Push the remainder before we process the range in case another
107     // worker has run out of things to do and can steal it.
108     oop* from_obj_p = set_partial_array_mask(from_obj);
109     push_on_queue(from_obj_p);
110   } else {
111     assert(length == end, &quot;sanity&quot;);
112     // We&#39;ll process the final range for this object. Restore the length
113     // so that the heap remains parsable in case of evacuation failure.
114     to_obj_array-&gt;set_length(end);
115   }
116 
117   HeapRegion* hr = _g1h-&gt;heap_region_containing(to_obj);
118   G1ScanInYoungSetter x(&amp;_scanner, hr-&gt;is_young());
119   // Process indexes [start,end). It will also process the header
120   // along with the first chunk (i.e., the chunk with start == 0).
121   // Note that at this point the length field of to_obj_array is not
122   // correct given that we are using it to keep track of the next
123   // start index. oop_iterate_range() (thankfully!) ignores the length
124   // field and only relies on the start / end parameters.  It does
125   // however return the size of the object which will be incorrect. So
126   // we have to ignore it even if we wanted to use it.
127   to_obj_array-&gt;oop_iterate_range(&amp;_scanner, start, end);
128 }
129 
130 inline void G1ParScanThreadState::deal_with_reference(oop* ref_to_scan) {
131   if (!has_partial_array_mask(ref_to_scan)) {
132     do_oop_evac(ref_to_scan);
133   } else {
134     do_oop_partial_array(ref_to_scan);
135   }
136 }
137 
138 inline void G1ParScanThreadState::deal_with_reference(narrowOop* ref_to_scan) {
139   assert(!has_partial_array_mask(ref_to_scan), &quot;NarrowOop* elements should never be partial arrays.&quot;);
140   do_oop_evac(ref_to_scan);
141 }
142 
143 inline void G1ParScanThreadState::dispatch_reference(StarTask ref) {
144   assert(verify_task(ref), &quot;sanity&quot;);
145   if (ref.is_narrow()) {
146     deal_with_reference((narrowOop*)ref);
147   } else {
148     deal_with_reference((oop*)ref);
149   }
150 }
151 
152 void G1ParScanThreadState::steal_and_trim_queue(RefToScanQueueSet *task_queues) {
153   StarTask stolen_task;
154   while (task_queues-&gt;steal(_worker_id, stolen_task)) {
155     assert(verify_task(stolen_task), &quot;sanity&quot;);
156     dispatch_reference(stolen_task);
157 
158     // We&#39;ve just processed a reference and we might have made
159     // available new entries on the queues. So we have to make sure
160     // we drain the queues as necessary.
161     trim_queue();
162   }
163 }
164 
165 inline bool G1ParScanThreadState::needs_partial_trimming() const {
166   return !_refs-&gt;overflow_empty() || _refs-&gt;size() &gt; _stack_trim_upper_threshold;
167 }
168 
169 inline bool G1ParScanThreadState::is_partially_trimmed() const {
170   return _refs-&gt;overflow_empty() &amp;&amp; _refs-&gt;size() &lt;= _stack_trim_lower_threshold;
171 }
172 
173 inline void G1ParScanThreadState::trim_queue_to_threshold(uint threshold) {
174   StarTask ref;
175   // Drain the overflow stack first, so other threads can potentially steal.
176   while (_refs-&gt;pop_overflow(ref)) {
177     if (!_refs-&gt;try_push_to_taskqueue(ref)) {
178       dispatch_reference(ref);
179     }
180   }
181 
182   while (_refs-&gt;pop_local(ref, threshold)) {
183     dispatch_reference(ref);
184   }
185 }
186 
187 inline void G1ParScanThreadState::trim_queue_partially() {
188   if (!needs_partial_trimming()) {
189     return;
190   }
191 
192   const Ticks start = Ticks::now();
193   do {
194     trim_queue_to_threshold(_stack_trim_lower_threshold);
195   } while (!is_partially_trimmed());
196   _trim_ticks += Ticks::now() - start;
197 }
198 
199 inline Tickspan G1ParScanThreadState::trim_ticks() const {
200   return _trim_ticks;
201 }
202 
203 inline void G1ParScanThreadState::reset_trim_ticks() {
204   _trim_ticks = Tickspan();
205 }
206 
207 template &lt;typename T&gt;
208 inline void G1ParScanThreadState::remember_root_into_optional_region(T* p) {
209   oop o = RawAccess&lt;IS_NOT_NULL&gt;::oop_load(p);
210   uint index = _g1h-&gt;heap_region_containing(o)-&gt;index_in_opt_cset();
<a name="8" id="anc8"></a><span class="line-added">211   assert(index &lt; _num_optional_regions,</span>
<span class="line-added">212          &quot;Trying to access optional region idx %u beyond &quot; SIZE_FORMAT, index, _num_optional_regions);</span>
213   _oops_into_optional_regions[index].push_root(p);
214 }
215 
216 template &lt;typename T&gt;
217 inline void G1ParScanThreadState::remember_reference_into_optional_region(T* p) {
218   oop o = RawAccess&lt;IS_NOT_NULL&gt;::oop_load(p);
219   uint index = _g1h-&gt;heap_region_containing(o)-&gt;index_in_opt_cset();
<a name="9" id="anc9"></a><span class="line-added">220   assert(index &lt; _num_optional_regions,</span>
<span class="line-added">221          &quot;Trying to access optional region idx %u beyond &quot; SIZE_FORMAT, index, _num_optional_regions);</span>
222   _oops_into_optional_regions[index].push_oop(p);
223   DEBUG_ONLY(verify_ref(p);)
224 }
225 
226 G1OopStarChunkedList* G1ParScanThreadState::oops_into_optional_region(const HeapRegion* hr) {
<a name="10" id="anc10"></a><span class="line-added">227   assert(hr-&gt;index_in_opt_cset() &lt; _num_optional_regions,</span>
<span class="line-added">228          &quot;Trying to access optional region idx %u beyond &quot; SIZE_FORMAT &quot; &quot; HR_FORMAT,</span>
<span class="line-added">229          hr-&gt;index_in_opt_cset(), _num_optional_regions, HR_FORMAT_PARAMS(hr));</span>
230   return &amp;_oops_into_optional_regions[hr-&gt;index_in_opt_cset()];
231 }
232 
<a name="11" id="anc11"></a><span class="line-added">233 void G1ParScanThreadState::initialize_numa_stats() {</span>
<span class="line-added">234   if (_numa-&gt;is_enabled()) {</span>
<span class="line-added">235     LogTarget(Info, gc, heap, numa) lt;</span>
<span class="line-added">236 </span>
<span class="line-added">237     if (lt.is_enabled()) {</span>
<span class="line-added">238       uint num_nodes = _numa-&gt;num_active_nodes();</span>
<span class="line-added">239       // Record only if there are multiple active nodes.</span>
<span class="line-added">240       _obj_alloc_stat = NEW_C_HEAP_ARRAY(size_t, num_nodes, mtGC);</span>
<span class="line-added">241       memset(_obj_alloc_stat, 0, sizeof(size_t) * num_nodes);</span>
<span class="line-added">242     }</span>
<span class="line-added">243   }</span>
<span class="line-added">244 }</span>
<span class="line-added">245 </span>
<span class="line-added">246 void G1ParScanThreadState::flush_numa_stats() {</span>
<span class="line-added">247   if (_obj_alloc_stat != NULL) {</span>
<span class="line-added">248     uint node_index = _numa-&gt;index_of_current_thread();</span>
<span class="line-added">249     _numa-&gt;copy_statistics(G1NUMAStats::LocalObjProcessAtCopyToSurv, node_index, _obj_alloc_stat);</span>
<span class="line-added">250   }</span>
<span class="line-added">251 }</span>
<span class="line-added">252 </span>
<span class="line-added">253 void G1ParScanThreadState::update_numa_stats(uint node_index) {</span>
<span class="line-added">254   if (_obj_alloc_stat != NULL) {</span>
<span class="line-added">255     _obj_alloc_stat[node_index]++;</span>
<span class="line-added">256   }</span>
<span class="line-added">257 }</span>
<span class="line-added">258 </span>
259 #endif // SHARE_GC_G1_G1PARSCANTHREADSTATE_INLINE_HPP
<a name="12" id="anc12"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="12" type="hidden" />
</body>
</html>