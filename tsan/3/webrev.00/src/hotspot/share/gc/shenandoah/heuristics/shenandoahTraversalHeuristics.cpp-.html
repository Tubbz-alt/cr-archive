<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/gc/shenandoah/heuristics/shenandoahTraversalHeuristics.cpp</title>
    <link rel="stylesheet" href="../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2018, 2019, Red Hat, Inc. All rights reserved.
  3  *
  4  * This code is free software; you can redistribute it and/or modify it
  5  * under the terms of the GNU General Public License version 2 only, as
  6  * published by the Free Software Foundation.
  7  *
  8  * This code is distributed in the hope that it will be useful, but WITHOUT
  9  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 10  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 11  * version 2 for more details (a copy is included in the LICENSE file that
 12  * accompanied this code).
 13  *
 14  * You should have received a copy of the GNU General Public License version
 15  * 2 along with this work; if not, write to the Free Software Foundation,
 16  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 17  *
 18  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 19  * or visit www.oracle.com if you need additional information or have any
 20  * questions.
 21  *
 22  */
 23 
 24 #include &quot;precompiled.hpp&quot;
 25 
 26 #include &quot;gc/shenandoah/heuristics/shenandoahTraversalHeuristics.hpp&quot;
 27 #include &quot;gc/shenandoah/shenandoahCollectionSet.hpp&quot;
 28 #include &quot;gc/shenandoah/shenandoahFreeSet.hpp&quot;
 29 #include &quot;gc/shenandoah/shenandoahHeap.inline.hpp&quot;
 30 #include &quot;gc/shenandoah/shenandoahHeuristics.hpp&quot;
 31 #include &quot;gc/shenandoah/shenandoahTraversalGC.hpp&quot;
 32 #include &quot;logging/log.hpp&quot;
 33 #include &quot;logging/logTag.hpp&quot;
 34 #include &quot;utilities/quickSort.hpp&quot;
 35 
 36 ShenandoahTraversalHeuristics::ShenandoahTraversalHeuristics() : ShenandoahHeuristics(),
 37   _last_cset_select(0)
 38  {
 39   FLAG_SET_DEFAULT(ShenandoahSATBBarrier,            false);
 40   FLAG_SET_DEFAULT(ShenandoahStoreValReadBarrier,    false);
 41   FLAG_SET_DEFAULT(ShenandoahStoreValEnqueueBarrier, true);
 42   FLAG_SET_DEFAULT(ShenandoahKeepAliveBarrier,       false);
 43   FLAG_SET_DEFAULT(ShenandoahAllowMixedAllocs,       false);
 44 
 45   SHENANDOAH_ERGO_OVERRIDE_DEFAULT(ShenandoahRefProcFrequency, 1);
 46 
 47   // Adjust class unloading settings only if globally enabled.
 48   if (ClassUnloadingWithConcurrentMark) {
 49     SHENANDOAH_ERGO_OVERRIDE_DEFAULT(ShenandoahUnloadClassesFrequency, 1);
 50   }
 51 
 52   SHENANDOAH_ERGO_ENABLE_FLAG(ExplicitGCInvokesConcurrent);
 53   SHENANDOAH_ERGO_ENABLE_FLAG(ShenandoahImplicitGCInvokesConcurrent);
 54 
 55   // Final configuration checks
 56   SHENANDOAH_CHECK_FLAG_SET(ShenandoahReadBarrier);
 57   SHENANDOAH_CHECK_FLAG_SET(ShenandoahWriteBarrier);
 58   SHENANDOAH_CHECK_FLAG_SET(ShenandoahStoreValEnqueueBarrier);
 59   SHENANDOAH_CHECK_FLAG_SET(ShenandoahCASBarrier);
 60   SHENANDOAH_CHECK_FLAG_SET(ShenandoahAcmpBarrier);
 61   SHENANDOAH_CHECK_FLAG_SET(ShenandoahCloneBarrier);
 62 }
 63 
 64 bool ShenandoahTraversalHeuristics::should_start_normal_gc() const {
 65   return false;
 66 }
 67 
 68 bool ShenandoahTraversalHeuristics::is_experimental() {
 69   return true;
 70 }
 71 
 72 bool ShenandoahTraversalHeuristics::is_diagnostic() {
 73   return false;
 74 }
 75 
 76 bool ShenandoahTraversalHeuristics::can_do_traversal_gc() {
 77   return true;
 78 }
 79 
 80 const char* ShenandoahTraversalHeuristics::name() {
 81   return &quot;traversal&quot;;
 82 }
 83 
 84 void ShenandoahTraversalHeuristics::choose_collection_set(ShenandoahCollectionSet* collection_set) {
 85   ShenandoahHeap* heap = ShenandoahHeap::heap();
 86 
 87   ShenandoahTraversalGC* traversal_gc = heap-&gt;traversal_gc();
 88 
 89   ShenandoahHeapRegionSet* traversal_set = traversal_gc-&gt;traversal_set();
 90   traversal_set-&gt;clear();
 91 
 92   RegionData *data = get_region_data_cache(heap-&gt;num_regions());
 93   size_t cnt = 0;
 94 
 95   // Step 0. Prepare all regions
 96 
 97   for (size_t i = 0; i &lt; heap-&gt;num_regions(); i++) {
 98     ShenandoahHeapRegion* r = heap-&gt;get_region(i);
 99     if (r-&gt;used() &gt; 0) {
100       if (r-&gt;is_regular()) {
101         data[cnt]._region = r;
102         data[cnt]._garbage = r-&gt;garbage();
103         data[cnt]._seqnum_last_alloc = r-&gt;seqnum_last_alloc_mutator();
104         cnt++;
105       }
106       traversal_set-&gt;add_region(r);
107     }
108   }
109 
110   // The logic for cset selection is similar to that of adaptive:
111   //
112   //   1. We cannot get cset larger than available free space. Otherwise we guarantee OOME
113   //      during evacuation, and thus guarantee full GC. In practice, we also want to let
114   //      application to allocate something. This is why we limit CSet to some fraction of
115   //      available space. In non-overloaded heap, max_cset would contain all plausible candidates
116   //      over garbage threshold.
117   //
118   //   2. We should not get cset too low so that free threshold would not be met right
119   //      after the cycle. Otherwise we get back-to-back cycles for no reason if heap is
120   //      too fragmented. In non-overloaded non-fragmented heap min_garbage would be around zero.
121   //
122   // Therefore, we start by sorting the regions by garbage. Then we unconditionally add the best candidates
123   // before we meet min_garbage. Then we add all candidates that fit with a garbage threshold before
124   // we hit max_cset. When max_cset is hit, we terminate the cset selection. Note that in this scheme,
125   // ShenandoahGarbageThreshold is the soft threshold which would be ignored until min_garbage is hit.
126   //
127   // The significant complication is that liveness data was collected at the previous cycle, and only
128   // for those regions that were allocated before previous cycle started.
129 
130   size_t capacity    = heap-&gt;capacity();
131   size_t actual_free = heap-&gt;free_set()-&gt;available();
132   size_t free_target = ShenandoahMinFreeThreshold * capacity / 100;
133   size_t min_garbage = free_target &gt; actual_free ? (free_target - actual_free) : 0;
134   size_t max_cset    = (size_t)(1.0 * ShenandoahEvacReserve * capacity / 100 / ShenandoahEvacWaste);
135 
136   log_info(gc, ergo)(&quot;Adaptive CSet Selection. Target Free: &quot; SIZE_FORMAT &quot;M, Actual Free: &quot;
137                      SIZE_FORMAT &quot;M, Max CSet: &quot; SIZE_FORMAT &quot;M, Min Garbage: &quot; SIZE_FORMAT &quot;M&quot;,
138                      free_target / M, actual_free / M, max_cset / M, min_garbage / M);
139 
140   // Better select garbage-first regions, and then older ones
141   QuickSort::sort&lt;RegionData&gt;(data, (int) cnt, compare_by_garbage_then_alloc_seq_ascending, false);
142 
143   size_t cur_cset = 0;
144   size_t cur_garbage = 0;
145 
146   size_t garbage_threshold = ShenandoahHeapRegion::region_size_bytes() / 100 * ShenandoahGarbageThreshold;
147 
148   // Step 1. Add trustworthy regions to collection set.
149   //
150   // We can trust live/garbage data from regions that were fully traversed during
151   // previous cycle. Even if actual liveness is different now, we can only have _less_
152   // live objects, because dead objects are not resurrected. Which means we can undershoot
153   // the collection set, but not overshoot it.
154 
155   for (size_t i = 0; i &lt; cnt; i++) {
156     if (data[i]._seqnum_last_alloc &gt; _last_cset_select) continue;
157 
158     ShenandoahHeapRegion* r = data[i]._region;
159     assert (r-&gt;is_regular(), &quot;should have been filtered before&quot;);
160 
161     size_t new_garbage = cur_garbage + r-&gt;garbage();
162     size_t new_cset    = cur_cset    + r-&gt;get_live_data_bytes();
163 
164     if (new_cset &gt; max_cset) {
165       break;
166     }
167 
168     if ((new_garbage &lt; min_garbage) || (r-&gt;garbage() &gt; garbage_threshold)) {
169       assert(!collection_set-&gt;is_in(r), &quot;must not yet be in cset&quot;);
170       collection_set-&gt;add_region(r);
171       cur_cset = new_cset;
172       cur_garbage = new_garbage;
173     }
174   }
175 
176   // Step 2. Try to catch some recently allocated regions for evacuation ride.
177   //
178   // Pessimistically assume we are going to evacuate the entire region. While this
179   // is very pessimistic and in most cases undershoots the collection set when regions
180   // are mostly dead, it also provides more safety against running into allocation
181   // failure when newly allocated regions are fully live.
182 
183   for (size_t i = 0; i &lt; cnt; i++) {
184     if (data[i]._seqnum_last_alloc &lt;= _last_cset_select) continue;
185 
186     ShenandoahHeapRegion* r = data[i]._region;
187     assert (r-&gt;is_regular(), &quot;should have been filtered before&quot;);
188 
189     // size_t new_garbage = cur_garbage + 0; (implied)
190     size_t new_cset = cur_cset + r-&gt;used();
191 
192     if (new_cset &gt; max_cset) {
193       break;
194     }
195 
196     assert(!collection_set-&gt;is_in(r), &quot;must not yet be in cset&quot;);
197     collection_set-&gt;add_region(r);
198     cur_cset = new_cset;
199   }
200 
201   // Step 3. Clear liveness data
202   // TODO: Merge it with step 0, but save live data in RegionData before.
203   for (size_t i = 0; i &lt; heap-&gt;num_regions(); i++) {
204     ShenandoahHeapRegion* r = heap-&gt;get_region(i);
205     if (r-&gt;used() &gt; 0) {
206       r-&gt;clear_live_data();
207     }
208   }
209 
210   collection_set-&gt;update_region_status();
211 
212   _last_cset_select = ShenandoahHeapRegion::seqnum_current_alloc();
213 }
214 
215 bool ShenandoahTraversalHeuristics::should_start_traversal_gc() {
216   ShenandoahHeap* heap = ShenandoahHeap::heap();
217   assert(!heap-&gt;has_forwarded_objects(), &quot;no forwarded objects here&quot;);
218 
219   size_t capacity = heap-&gt;capacity();
220   size_t available = heap-&gt;free_set()-&gt;available();
221 
222   // Check if we are falling below the worst limit, time to trigger the GC, regardless of
223   // anything else.
224   size_t min_threshold = ShenandoahMinFreeThreshold * heap-&gt;capacity() / 100;
225   if (available &lt; min_threshold) {
226     log_info(gc)(&quot;Trigger: Free (&quot; SIZE_FORMAT &quot;M) is below minimum threshold (&quot; SIZE_FORMAT &quot;M)&quot;,
227                  available / M, min_threshold / M);
228     return true;
229   }
230 
231   // Check if are need to learn a bit about the application
232   const size_t max_learn = ShenandoahLearningSteps;
233   if (_gc_times_learned &lt; max_learn) {
234     size_t init_threshold = ShenandoahInitFreeThreshold * heap-&gt;capacity() / 100;
235     if (available &lt; init_threshold) {
236       log_info(gc)(&quot;Trigger: Learning &quot; SIZE_FORMAT &quot; of &quot; SIZE_FORMAT &quot;. Free (&quot; SIZE_FORMAT &quot;M) is below initial threshold (&quot; SIZE_FORMAT &quot;M)&quot;,
237                    _gc_times_learned + 1, max_learn, available / M, init_threshold / M);
238       return true;
239     }
240   }
241 
242   // Check if allocation headroom is still okay. This also factors in:
243   //   1. Some space to absorb allocation spikes
244   //   2. Accumulated penalties from Degenerated and Full GC
245 
246   size_t allocation_headroom = available;
247 
248   size_t spike_headroom = ShenandoahAllocSpikeFactor * capacity / 100;
249   size_t penalties      = _gc_time_penalties         * capacity / 100;
250 
251   allocation_headroom -= MIN2(allocation_headroom, spike_headroom);
252   allocation_headroom -= MIN2(allocation_headroom, penalties);
253 
254   double average_gc = _gc_time_history-&gt;avg();
255   double time_since_last = time_since_last_gc();
256   double allocation_rate = heap-&gt;bytes_allocated_since_gc_start() / time_since_last;
257 
258   if (average_gc &gt; allocation_headroom / allocation_rate) {
259     log_info(gc)(&quot;Trigger: Average GC time (%.2f ms) is above the time for allocation rate (%.2f MB/s) to deplete free headroom (&quot; SIZE_FORMAT &quot;M)&quot;,
260                  average_gc * 1000, allocation_rate / M, allocation_headroom / M);
261     log_info(gc, ergo)(&quot;Free headroom: &quot; SIZE_FORMAT &quot;M (free) - &quot; SIZE_FORMAT &quot;M (spike) - &quot; SIZE_FORMAT &quot;M (penalties) = &quot; SIZE_FORMAT &quot;M&quot;,
262                        available / M, spike_headroom / M, penalties / M, allocation_headroom / M);
263     return true;
264   } else if (ShenandoahHeuristics::should_start_normal_gc()) {
265     return true;
266   }
267 
268   return false;
269 }
270 
271 void ShenandoahTraversalHeuristics::choose_collection_set_from_regiondata(ShenandoahCollectionSet* set,
272                                                                           RegionData* data, size_t data_size,
273                                                                           size_t free) {
274   ShouldNotReachHere();
275 }
    </pre>
  </body>
</html>