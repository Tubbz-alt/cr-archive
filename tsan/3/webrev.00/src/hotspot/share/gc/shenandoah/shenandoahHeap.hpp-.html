<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/gc/shenandoah/shenandoahHeap.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2013, 2019, Red Hat, Inc. All rights reserved.
  3  *
  4  * This code is free software; you can redistribute it and/or modify it
  5  * under the terms of the GNU General Public License version 2 only, as
  6  * published by the Free Software Foundation.
  7  *
  8  * This code is distributed in the hope that it will be useful, but WITHOUT
  9  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 10  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 11  * version 2 for more details (a copy is included in the LICENSE file that
 12  * accompanied this code).
 13  *
 14  * You should have received a copy of the GNU General Public License version
 15  * 2 along with this work; if not, write to the Free Software Foundation,
 16  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 17  *
 18  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 19  * or visit www.oracle.com if you need additional information or have any
 20  * questions.
 21  *
 22  */
 23 
 24 #ifndef SHARE_GC_SHENANDOAH_SHENANDOAHHEAP_HPP
 25 #define SHARE_GC_SHENANDOAH_SHENANDOAHHEAP_HPP
 26 
 27 #include &quot;gc/shared/markBitMap.hpp&quot;
 28 #include &quot;gc/shared/softRefPolicy.hpp&quot;
 29 #include &quot;gc/shared/collectedHeap.hpp&quot;
 30 #include &quot;gc/shenandoah/shenandoahAsserts.hpp&quot;
 31 #include &quot;gc/shenandoah/shenandoahAllocRequest.hpp&quot;
 32 #include &quot;gc/shenandoah/shenandoahHeapLock.hpp&quot;
 33 #include &quot;gc/shenandoah/shenandoahEvacOOMHandler.hpp&quot;
 34 #include &quot;gc/shenandoah/shenandoahSharedVariables.hpp&quot;
 35 #include &quot;services/memoryManager.hpp&quot;
 36 
 37 class ConcurrentGCTimer;
 38 class ReferenceProcessor;
 39 class ShenandoahAllocTracker;
 40 class ShenandoahCollectorPolicy;
 41 class ShenandoahControlThread;
 42 class ShenandoahGCSession;
 43 class ShenandoahHeuristics;
 44 class ShenandoahMarkingContext;
 45 class ShenandoahPhaseTimings;
 46 class ShenandoahHeap;
 47 class ShenandoahHeapRegion;
 48 class ShenandoahHeapRegionClosure;
 49 class ShenandoahCollectionSet;
 50 class ShenandoahFreeSet;
 51 class ShenandoahConcurrentMark;
 52 class ShenandoahMarkCompact;
 53 class ShenandoahMonitoringSupport;
 54 class ShenandoahPacer;
 55 class ShenandoahTraversalGC;
 56 class ShenandoahVerifier;
 57 class ShenandoahWorkGang;
 58 class VMStructs;
 59 
 60 class ShenandoahRegionIterator : public StackObj {
 61 private:
 62   ShenandoahHeap* _heap;
 63 
 64   DEFINE_PAD_MINUS_SIZE(0, DEFAULT_CACHE_LINE_SIZE, sizeof(volatile size_t));
 65   volatile size_t _index;
 66   DEFINE_PAD_MINUS_SIZE(1, DEFAULT_CACHE_LINE_SIZE, 0);
 67 
 68   // No implicit copying: iterators should be passed by reference to capture the state
 69   ShenandoahRegionIterator(const ShenandoahRegionIterator&amp; that);
 70   ShenandoahRegionIterator&amp; operator=(const ShenandoahRegionIterator&amp; o);
 71 
 72 public:
 73   ShenandoahRegionIterator();
 74   ShenandoahRegionIterator(ShenandoahHeap* heap);
 75 
 76   // Reset iterator to default state
 77   void reset();
 78 
 79   // Returns next region, or NULL if there are no more regions.
 80   // This is multi-thread-safe.
 81   inline ShenandoahHeapRegion* next();
 82 
 83   // This is *not* MT safe. However, in the absence of multithreaded access, it
 84   // can be used to determine if there is more work to do.
 85   bool has_next() const;
 86 };
 87 
 88 class ShenandoahHeapRegionClosure : public StackObj {
 89 public:
 90   virtual void heap_region_do(ShenandoahHeapRegion* r) = 0;
 91   virtual bool is_thread_safe() { return false; }
 92 };
 93 
 94 class ShenandoahUpdateRefsClosure: public OopClosure {
 95 private:
 96   ShenandoahHeap* _heap;
 97 
 98   template &lt;class T&gt;
 99   inline void do_oop_work(T* p);
100 
101 public:
102   ShenandoahUpdateRefsClosure();
103   inline void do_oop(oop* p);
104   inline void do_oop(narrowOop* p);
105 };
106 
107 #ifdef ASSERT
108 class ShenandoahAssertToSpaceClosure : public OopClosure {
109 private:
110   template &lt;class T&gt;
111   void do_oop_work(T* p);
112 public:
113   void do_oop(narrowOop* p);
114   void do_oop(oop* p);
115 };
116 #endif
117 
118 class ShenandoahAlwaysTrueClosure : public BoolObjectClosure {
119 public:
120   bool do_object_b(oop p) { return true; }
121 };
122 
123 class ShenandoahForwardedIsAliveClosure: public BoolObjectClosure {
124 private:
125   ShenandoahMarkingContext* const _mark_context;
126 public:
127   ShenandoahForwardedIsAliveClosure();
128   bool do_object_b(oop obj);
129 };
130 
131 class ShenandoahIsAliveClosure: public BoolObjectClosure {
132 private:
133   ShenandoahMarkingContext* const _mark_context;
134 public:
135   ShenandoahIsAliveClosure();
136   bool do_object_b(oop obj);
137 };
138 
139 class ShenandoahIsAliveSelector : public StackObj {
140 private:
141   ShenandoahIsAliveClosure _alive_cl;
142   ShenandoahForwardedIsAliveClosure _fwd_alive_cl;
143 public:
144   BoolObjectClosure* is_alive_closure();
145 };
146 
147 // Shenandoah GC is low-pause concurrent GC that uses Brooks forwarding pointers
148 // to encode forwarding data. See BrooksPointer for details on forwarding data encoding.
149 // See ShenandoahControlThread for GC cycle structure.
150 //
151 class ShenandoahHeap : public CollectedHeap {
152   friend class ShenandoahAsserts;
153   friend class VMStructs;
154   friend class ShenandoahGCSession;
155 
156 // ---------- Locks that guard important data structures in Heap
157 //
158 private:
159   ShenandoahHeapLock _lock;
160 
161 public:
162   ShenandoahHeapLock* lock() {
163     return &amp;_lock;
164   }
165 
166   void assert_heaplock_owned_by_current_thread()     NOT_DEBUG_RETURN;
167   void assert_heaplock_not_owned_by_current_thread() NOT_DEBUG_RETURN;
168   void assert_heaplock_or_safepoint()                NOT_DEBUG_RETURN;
169 
170 // ---------- Initialization, termination, identification, printing routines
171 //
172 public:
173   static ShenandoahHeap* heap();
174   static ShenandoahHeap* heap_no_check();
175 
176   const char* name()          const { return &quot;Shenandoah&quot;; }
177   ShenandoahHeap::Name kind() const { return CollectedHeap::Shenandoah; }
178 
179   ShenandoahHeap(ShenandoahCollectorPolicy* policy);
180   jint initialize();
181   void post_initialize();
182   void initialize_heuristics();
183 
184   void initialize_serviceability();
185 
186   void print_on(outputStream* st)              const;
187   void print_extended_on(outputStream *st)     const;
188   void print_tracing_info()                    const;
189   void print_gc_threads_on(outputStream* st)   const;
190   void print_heap_regions_on(outputStream* st) const;
191 
192   void stop();
193 
194   void prepare_for_verify();
195   void verify(VerifyOption vo);
196 
197 // ---------- Heap counters and metrics
198 //
199 private:
200            size_t _initial_size;
201   DEFINE_PAD_MINUS_SIZE(0, DEFAULT_CACHE_LINE_SIZE, sizeof(volatile size_t));
202   volatile size_t _used;
203   volatile size_t _committed;
204   volatile size_t _bytes_allocated_since_gc_start;
205   DEFINE_PAD_MINUS_SIZE(1, DEFAULT_CACHE_LINE_SIZE, 0);
206 
207 public:
208   void increase_used(size_t bytes);
209   void decrease_used(size_t bytes);
210   void set_used(size_t bytes);
211 
212   void increase_committed(size_t bytes);
213   void decrease_committed(size_t bytes);
214   void increase_allocated(size_t bytes);
215 
216   size_t bytes_allocated_since_gc_start();
217   void reset_bytes_allocated_since_gc_start();
218 
219   size_t max_capacity()     const;
220   size_t initial_capacity() const;
221   size_t capacity()         const;
222   size_t used()             const;
223   size_t committed()        const;
224 
225 // ---------- Workers handling
226 //
227 private:
228   uint _max_workers;
229   ShenandoahWorkGang* _workers;
230   ShenandoahWorkGang* _safepoint_workers;
231 
232 public:
233   uint max_workers();
234   void assert_gc_workers(uint nworker) NOT_DEBUG_RETURN;
235 
236   WorkGang* workers() const;
237   WorkGang* get_safepoint_workers();
238 
239   void gc_threads_do(ThreadClosure* tcl) const;
240 
241 // ---------- Heap regions handling machinery
242 //
243 private:
244   MemRegion _heap_region;
245   bool      _heap_region_special;
246   size_t    _num_regions;
247   ShenandoahHeapRegion** _regions;
248   ShenandoahRegionIterator _update_refs_iterator;
249 
250 public:
251   inline size_t num_regions() const { return _num_regions; }
252   inline bool is_heap_region_special() { return _heap_region_special; }
253 
254   inline ShenandoahHeapRegion* const heap_region_containing(const void* addr) const;
255   inline size_t heap_region_index_containing(const void* addr) const;
256 
257   inline ShenandoahHeapRegion* const get_region(size_t region_idx) const;
258 
259   void heap_region_iterate(ShenandoahHeapRegionClosure* blk) const;
260   void parallel_heap_region_iterate(ShenandoahHeapRegionClosure* blk) const;
261 
262 // ---------- GC state machinery
263 //
264 // GC state describes the important parts of collector state, that may be
265 // used to make barrier selection decisions in the native and generated code.
266 // Multiple bits can be set at once.
267 //
268 // Important invariant: when GC state is zero, the heap is stable, and no barriers
269 // are required.
270 //
271 public:
272   enum GCStateBitPos {
273     // Heap has forwarded objects: need RB, ACMP, CAS barriers.
274     HAS_FORWARDED_BITPOS   = 0,
275 
276     // Heap is under marking: needs SATB barriers.
277     MARKING_BITPOS    = 1,
278 
279     // Heap is under evacuation: needs WB barriers. (Set together with UNSTABLE)
280     EVACUATION_BITPOS = 2,
281 
282     // Heap is under updating: needs SVRB/SVWB barriers.
283     UPDATEREFS_BITPOS = 3,
284 
285     // Heap is under traversal collection
286     TRAVERSAL_BITPOS  = 4,
287   };
288 
289   enum GCState {
290     STABLE        = 0,
291     HAS_FORWARDED = 1 &lt;&lt; HAS_FORWARDED_BITPOS,
292     MARKING       = 1 &lt;&lt; MARKING_BITPOS,
293     EVACUATION    = 1 &lt;&lt; EVACUATION_BITPOS,
294     UPDATEREFS    = 1 &lt;&lt; UPDATEREFS_BITPOS,
295     TRAVERSAL     = 1 &lt;&lt; TRAVERSAL_BITPOS,
296   };
297 
298 private:
299   ShenandoahSharedBitmap _gc_state;
300   ShenandoahSharedFlag   _degenerated_gc_in_progress;
301   ShenandoahSharedFlag   _full_gc_in_progress;
302   ShenandoahSharedFlag   _full_gc_move_in_progress;
303   ShenandoahSharedFlag   _progress_last_gc;
304 
305   void set_gc_state_all_threads(char state);
306   void set_gc_state_mask(uint mask, bool value);
307 
308 public:
309   char gc_state() const;
310   static address gc_state_addr();
311 
312   void set_concurrent_mark_in_progress(bool in_progress);
313   void set_evacuation_in_progress(bool in_progress);
314   void set_update_refs_in_progress(bool in_progress);
315   void set_degenerated_gc_in_progress(bool in_progress);
316   void set_full_gc_in_progress(bool in_progress);
317   void set_full_gc_move_in_progress(bool in_progress);
318   void set_concurrent_traversal_in_progress(bool in_progress);
319   void set_has_forwarded_objects(bool cond);
320 
321   inline bool is_stable() const;
322   inline bool is_idle() const;
323   inline bool is_concurrent_mark_in_progress() const;
324   inline bool is_update_refs_in_progress() const;
325   inline bool is_evacuation_in_progress() const;
326   inline bool is_degenerated_gc_in_progress() const;
327   inline bool is_full_gc_in_progress() const;
328   inline bool is_full_gc_move_in_progress() const;
329   inline bool is_concurrent_traversal_in_progress() const;
330   inline bool has_forwarded_objects() const;
331   inline bool is_gc_in_progress_mask(uint mask) const;
332 
333 // ---------- GC cancellation and degeneration machinery
334 //
335 // Cancelled GC flag is used to notify concurrent phases that they should terminate.
336 //
337 public:
338   enum ShenandoahDegenPoint {
339     _degenerated_unset,
340     _degenerated_traversal,
341     _degenerated_outside_cycle,
342     _degenerated_mark,
343     _degenerated_evac,
344     _degenerated_updaterefs,
345     _DEGENERATED_LIMIT,
346   };
347 
348   static const char* degen_point_to_string(ShenandoahDegenPoint point) {
349     switch (point) {
350       case _degenerated_unset:
351         return &quot;&lt;UNSET&gt;&quot;;
352       case _degenerated_traversal:
353         return &quot;Traversal&quot;;
354       case _degenerated_outside_cycle:
355         return &quot;Outside of Cycle&quot;;
356       case _degenerated_mark:
357         return &quot;Mark&quot;;
358       case _degenerated_evac:
359         return &quot;Evacuation&quot;;
360       case _degenerated_updaterefs:
361         return &quot;Update Refs&quot;;
362       default:
363         ShouldNotReachHere();
364         return &quot;ERROR&quot;;
365     }
366   };
367 
368 private:
369   enum CancelState {
370     // Normal state. GC has not been cancelled and is open for cancellation.
371     // Worker threads can suspend for safepoint.
372     CANCELLABLE,
373 
374     // GC has been cancelled. Worker threads can not suspend for
375     // safepoint but must finish their work as soon as possible.
376     CANCELLED,
377 
378     // GC has not been cancelled and must not be cancelled. At least
379     // one worker thread checks for pending safepoint and may suspend
380     // if a safepoint is pending.
381     NOT_CANCELLED
382   };
383 
384   ShenandoahSharedEnumFlag&lt;CancelState&gt; _cancelled_gc;
385   bool try_cancel_gc();
386 
387 public:
388   static address cancelled_gc_addr();
389 
390   inline bool cancelled_gc() const;
391   inline bool check_cancelled_gc_and_yield(bool sts_active = true);
392 
393   inline void clear_cancelled_gc();
394 
395   void cancel_gc(GCCause::Cause cause);
396 
397 // ---------- GC operations entry points
398 //
399 public:
400   // Entry points to STW GC operations, these cause a related safepoint, that then
401   // call the entry method below
402   void vmop_entry_init_mark();
403   void vmop_entry_final_mark();
404   void vmop_entry_final_evac();
405   void vmop_entry_init_updaterefs();
406   void vmop_entry_final_updaterefs();
407   void vmop_entry_init_traversal();
408   void vmop_entry_final_traversal();
409   void vmop_entry_full(GCCause::Cause cause);
410   void vmop_degenerated(ShenandoahDegenPoint point);
411 
412   // Entry methods to normally STW GC operations. These set up logging, monitoring
413   // and workers for net VM operation
414   void entry_init_mark();
415   void entry_final_mark();
416   void entry_final_evac();
417   void entry_init_updaterefs();
418   void entry_final_updaterefs();
419   void entry_init_traversal();
420   void entry_final_traversal();
421   void entry_full(GCCause::Cause cause);
422   void entry_degenerated(int point);
423 
424   // Entry methods to normally concurrent GC operations. These set up logging, monitoring
425   // for concurrent operation.
426   void entry_reset();
427   void entry_mark();
428   void entry_preclean();
429   void entry_cleanup();
430   void entry_evac();
431   void entry_updaterefs();
432   void entry_traversal();
433   void entry_uncommit(double shrink_before);
434 
435 private:
436   // Actual work for the phases
437   void op_init_mark();
438   void op_final_mark();
439   void op_final_evac();
440   void op_init_updaterefs();
441   void op_final_updaterefs();
442   void op_init_traversal();
443   void op_final_traversal();
444   void op_full(GCCause::Cause cause);
445   void op_degenerated(ShenandoahDegenPoint point);
446   void op_degenerated_fail();
447   void op_degenerated_futile();
448 
449   void op_reset();
450   void op_mark();
451   void op_preclean();
452   void op_cleanup();
453   void op_conc_evac();
454   void op_stw_evac();
455   void op_updaterefs();
456   void op_traversal();
457   void op_uncommit(double shrink_before);
458 
459   // Messages for GC trace events, they have to be immortal for
460   // passing around the logging/tracing systems
461   const char* init_mark_event_message() const;
462   const char* final_mark_event_message() const;
463   const char* conc_mark_event_message() const;
464   const char* degen_event_message(ShenandoahDegenPoint point) const;
465 
466 // ---------- GC subsystems
467 //
468 private:
469   ShenandoahControlThread*   _control_thread;
470   ShenandoahCollectorPolicy* _shenandoah_policy;
471   ShenandoahHeuristics*      _heuristics;
472   ShenandoahFreeSet*         _free_set;
473   ShenandoahConcurrentMark*  _scm;
474   ShenandoahTraversalGC*     _traversal_gc;
475   ShenandoahMarkCompact*     _full_gc;
476   ShenandoahPacer*           _pacer;
477   ShenandoahVerifier*        _verifier;
478 
479   ShenandoahAllocTracker*    _alloc_tracker;
480   ShenandoahPhaseTimings*    _phase_timings;
481 
482   ShenandoahControlThread*   control_thread()          { return _control_thread;    }
483   ShenandoahMarkCompact*     full_gc()                 { return _full_gc;           }
484 
485 public:
486   ShenandoahCollectorPolicy* shenandoah_policy() const { return _shenandoah_policy; }
487   ShenandoahHeuristics*      heuristics()        const { return _heuristics;        }
488   ShenandoahFreeSet*         free_set()          const { return _free_set;          }
489   ShenandoahConcurrentMark*  concurrent_mark()         { return _scm;               }
490   ShenandoahTraversalGC*     traversal_gc()            { return _traversal_gc;      }
491   ShenandoahPacer*           pacer()             const { return _pacer;             }
492 
493   ShenandoahPhaseTimings*    phase_timings()     const { return _phase_timings;     }
494   ShenandoahAllocTracker*    alloc_tracker()     const { return _alloc_tracker;     }
495 
496   ShenandoahVerifier*        verifier();
497 
498 // ---------- VM subsystem bindings
499 //
500 private:
501   ShenandoahMonitoringSupport* _monitoring_support;
502   MemoryPool*                  _memory_pool;
503   GCMemoryManager              _stw_memory_manager;
504   GCMemoryManager              _cycle_memory_manager;
505   ConcurrentGCTimer*           _gc_timer;
506   SoftRefPolicy                _soft_ref_policy;
507 
508 public:
509   ShenandoahMonitoringSupport* monitoring_support() { return _monitoring_support;    }
510   GCMemoryManager* cycle_memory_manager()           { return &amp;_cycle_memory_manager; }
511   GCMemoryManager* stw_memory_manager()             { return &amp;_stw_memory_manager;   }
512   SoftRefPolicy* soft_ref_policy()                  { return &amp;_soft_ref_policy;      }
513 
514   GrowableArray&lt;GCMemoryManager*&gt; memory_managers();
515   GrowableArray&lt;MemoryPool*&gt; memory_pools();
516   MemoryUsage memory_usage();
517   GCTracer* tracer();
518   GCTimer* gc_timer() const;
519   CollectorPolicy* collector_policy() const;
520 
521 // ---------- Reference processing
522 //
523 private:
524   AlwaysTrueClosure    _subject_to_discovery;
525   ReferenceProcessor*  _ref_processor;
526   ShenandoahSharedFlag _process_references;
527 
528   void ref_processing_init();
529 
530 public:
531   ReferenceProcessor* ref_processor() { return _ref_processor; }
532   void set_process_references(bool pr);
533   bool process_references() const;
534 
535 // ---------- Class Unloading
536 //
537 private:
538   ShenandoahSharedFlag _unload_classes;
539 
540 public:
541   void set_unload_classes(bool uc);
542   bool unload_classes() const;
543 
544   // Delete entries for dead interned string and clean up unreferenced symbols
545   // in symbol table, possibly in parallel.
546   void unload_classes_and_cleanup_tables(bool full_gc);
547 
548 // ---------- Generic interface hooks
549 // Minor things that super-interface expects us to implement to play nice with
550 // the rest of runtime. Some of the things here are not required to be implemented,
551 // and can be stubbed out.
552 //
553 public:
554   AdaptiveSizePolicy* size_policy() shenandoah_not_implemented_return(NULL);
555   bool is_maximal_no_gc() const shenandoah_not_implemented_return(false);
556 
557   bool is_in(const void* p) const;
558 
559   size_t obj_size(oop obj) const;
560   virtual ptrdiff_t cell_header_size() const;
561 
562   void collect(GCCause::Cause cause);
563   void do_full_collection(bool clear_all_soft_refs);
564 
565   // Used for parsing heap during error printing
566   HeapWord* block_start(const void* addr) const;
567   bool block_is_obj(const HeapWord* addr) const;
568 
569   // Used for native heap walkers: heap dumpers, mostly
570   void object_iterate(ObjectClosure* cl);
571   void safe_object_iterate(ObjectClosure* cl);
572 
573   // Used by RMI
574   jlong millis_since_last_gc();
575 
576 // ---------- Safepoint interface hooks
577 //
578 public:
579   void safepoint_synchronize_begin();
580   void safepoint_synchronize_end();
581 
582 // ---------- Code roots handling hooks
583 //
584 public:
585   void register_nmethod(nmethod* nm);
586   void unregister_nmethod(nmethod* nm);
587 
588 // ---------- Pinning hooks
589 //
590 public:
591   // Shenandoah supports per-object (per-region) pinning
592   bool supports_object_pinning() const { return true; }
593 
594   oop pin_object(JavaThread* thread, oop obj);
595   void unpin_object(JavaThread* thread, oop obj);
596 
597 // ---------- Allocation support
598 //
599 private:
600   HeapWord* allocate_memory_under_lock(ShenandoahAllocRequest&amp; request, bool&amp; in_new_region);
601   inline HeapWord* allocate_from_gclab(Thread* thread, size_t size);
602   HeapWord* allocate_from_gclab_slow(Thread* thread, size_t size);
603   HeapWord* allocate_new_gclab(size_t min_size, size_t word_size, size_t* actual_size);
604   void retire_and_reset_gclabs();
605 
606 public:
607   HeapWord* allocate_memory(ShenandoahAllocRequest&amp; request);
608   HeapWord* mem_allocate(size_t size, bool* what);
609   MetaWord* satisfy_failed_metadata_allocation(ClassLoaderData* loader_data,
610                                                size_t size,
611                                                Metaspace::MetadataType mdtype);
612 
613   oop obj_allocate(Klass* klass, int size, TRAPS);
614   oop array_allocate(Klass* klass, int size, int length, bool do_zero, TRAPS);
615   oop class_allocate(Klass* klass, int size, TRAPS);
616 
617   void notify_mutator_alloc_words(size_t words, bool waste);
618 
619   // Shenandoah supports TLAB allocation
620   bool supports_tlab_allocation() const { return true; }
621 
622   HeapWord* allocate_new_tlab(size_t min_size, size_t requested_size, size_t* actual_size);
623   size_t tlab_capacity(Thread *thr) const;
624   size_t unsafe_max_tlab_alloc(Thread *thread) const;
625   size_t max_tlab_size() const;
626   size_t tlab_used(Thread* ignored) const;
627 
628   HeapWord* tlab_post_allocation_setup(HeapWord* obj);
629   void fill_with_dummy_object(HeapWord* start, HeapWord* end, bool zap);
630   size_t min_dummy_object_size() const;
631 
632   void resize_tlabs();
633 
634   void ensure_parsability(bool retire_tlabs);
635   void make_parsable(bool retire_tlabs);
636 
637 // ---------- Marking support
638 //
639 private:
640   ShenandoahMarkingContext* _marking_context;
641   MemRegion  _bitmap_region;
642   MemRegion  _aux_bitmap_region;
643   MarkBitMap _verification_bit_map;
644   MarkBitMap _aux_bit_map;
645 
646   size_t _bitmap_size;
647   size_t _bitmap_regions_per_slice;
648   size_t _bitmap_bytes_per_slice;
649 
650   bool _bitmap_region_special;
651   bool _aux_bitmap_region_special;
652 
653   // Used for buffering per-region liveness data.
654   // Needed since ShenandoahHeapRegion uses atomics to update liveness.
655   //
656   // The array has max-workers elements, each of which is an array of
657   // jushort * max_regions. The choice of jushort is not accidental:
658   // there is a tradeoff between static/dynamic footprint that translates
659   // into cache pressure (which is already high during marking), and
660   // too many atomic updates. size_t/jint is too large, jbyte is too small.
661   jushort** _liveness_cache;
662 
663 public:
664   inline ShenandoahMarkingContext* complete_marking_context() const;
665   inline ShenandoahMarkingContext* marking_context() const;
666   inline void mark_complete_marking_context();
667   inline void mark_incomplete_marking_context();
668 
669   template&lt;class T&gt;
670   inline void marked_object_iterate(ShenandoahHeapRegion* region, T* cl);
671 
672   template&lt;class T&gt;
673   inline void marked_object_iterate(ShenandoahHeapRegion* region, T* cl, HeapWord* limit);
674 
675   template&lt;class T&gt;
676   inline void marked_object_oop_iterate(ShenandoahHeapRegion* region, T* cl, HeapWord* limit);
677 
678   void reset_mark_bitmap();
679 
680   // SATB barriers hooks
681   template&lt;bool RESOLVE&gt;
682   inline bool requires_marking(const void* entry) const;
683   void force_satb_flush_all_threads();
684 
685   // Support for bitmap uncommits
686   bool commit_bitmap_slice(ShenandoahHeapRegion *r);
687   bool uncommit_bitmap_slice(ShenandoahHeapRegion *r);
688   bool is_bitmap_slice_committed(ShenandoahHeapRegion* r, bool skip_self = false);
689 
690   // Liveness caching support
691   jushort* get_liveness_cache(uint worker_id);
692   void flush_liveness_cache(uint worker_id);
693 
694 // ---------- Evacuation support
695 //
696 private:
697   ShenandoahCollectionSet* _collection_set;
698   ShenandoahEvacOOMHandler _oom_evac_handler;
699 
700   void evacuate_and_update_roots();
701 
702 public:
703   static address in_cset_fast_test_addr();
704 
705   ShenandoahCollectionSet* collection_set() const { return _collection_set; }
706 
707   template &lt;class T&gt;
708   inline bool in_collection_set(T obj) const;
709 
710   // Avoid accidentally calling the method above with ShenandoahHeapRegion*, which would be *wrong*.
711   inline bool in_collection_set(ShenandoahHeapRegion* r) shenandoah_not_implemented_return(false);
712 
713   // Evacuates object src. Returns the evacuated object, either evacuated
714   // by this thread, or by some other thread.
715   inline oop evacuate_object(oop src, Thread* thread);
716 
717   // Call before/after evacuation.
718   void enter_evacuation();
719   void leave_evacuation();
720 
721 // ---------- Helper functions
722 //
723 public:
724   template &lt;class T&gt;
725   inline oop evac_update_with_forwarded(T* p);
726 
727   template &lt;class T&gt;
728   inline oop maybe_update_with_forwarded(T* p);
729 
730   template &lt;class T&gt;
731   inline oop maybe_update_with_forwarded_not_null(T* p, oop obj);
732 
733   template &lt;class T&gt;
734   inline oop update_with_forwarded_not_null(T* p, oop obj);
735 
736   inline oop atomic_compare_exchange_oop(oop n, narrowOop* addr, oop c);
737   inline oop atomic_compare_exchange_oop(oop n, oop* addr, oop c);
738 
739   void trash_humongous_region_at(ShenandoahHeapRegion *r);
740 
741   void deduplicate_string(oop str);
742 
743   void stop_concurrent_marking();
744 
745   void roots_iterate(OopClosure* cl);
746 
747 private:
748   void trash_cset_regions();
749   void update_heap_references(bool concurrent);
750 
751 // ---------- Testing helpers functions
752 //
753 private:
754   ShenandoahSharedFlag _inject_alloc_failure;
755 
756   void try_inject_alloc_failure();
757   bool should_inject_alloc_failure();
758 };
759 
760 #endif // SHARE_GC_SHENANDOAH_SHENANDOAHHEAP_HPP
    </pre>
  </body>
</html>