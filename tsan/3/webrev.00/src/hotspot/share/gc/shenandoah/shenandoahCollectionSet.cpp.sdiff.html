<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/shenandoah/shenandoahCollectionSet.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="shenandoahCodeRoots.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahCollectionSet.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shenandoah/shenandoahCollectionSet.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2016, 2018, Red Hat, Inc. All rights reserved.</span>

  3  *
  4  * This code is free software; you can redistribute it and/or modify it
  5  * under the terms of the GNU General Public License version 2 only, as
  6  * published by the Free Software Foundation.
  7  *
  8  * This code is distributed in the hope that it will be useful, but WITHOUT
  9  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 10  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 11  * version 2 for more details (a copy is included in the LICENSE file that
 12  * accompanied this code).
 13  *
 14  * You should have received a copy of the GNU General Public License version
 15  * 2 along with this work; if not, write to the Free Software Foundation,
 16  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 17  *
 18  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 19  * or visit www.oracle.com if you need additional information or have any
 20  * questions.
 21  *
 22  */
 23 
 24 #include &quot;precompiled.hpp&quot;
 25 
 26 #include &quot;gc/shenandoah/shenandoahCollectionSet.hpp&quot;
 27 #include &quot;gc/shenandoah/shenandoahHeap.inline.hpp&quot;
 28 #include &quot;gc/shenandoah/shenandoahHeapRegionSet.hpp&quot;
 29 #include &quot;gc/shenandoah/shenandoahUtils.hpp&quot;
 30 #include &quot;runtime/atomic.hpp&quot;

 31 #include &quot;utilities/copy.hpp&quot;
 32 
<span class="line-modified"> 33 ShenandoahCollectionSet::ShenandoahCollectionSet(ShenandoahHeap* heap, HeapWord* heap_base) :</span>
 34   _map_size(heap-&gt;num_regions()),
 35   _region_size_bytes_shift(ShenandoahHeapRegion::region_size_bytes_shift()),
<span class="line-modified"> 36   _cset_map(NEW_C_HEAP_ARRAY(jbyte, _map_size, mtGC)),</span>
<span class="line-modified"> 37   _biased_cset_map(_cset_map - ((uintx)heap_base &gt;&gt; _region_size_bytes_shift)),</span>

 38   _heap(heap),
 39   _garbage(0),
 40   _live_data(0),
 41   _used(0),
 42   _region_count(0),
 43   _current_index(0) {
<span class="line-removed"> 44   // Use 1-byte data type</span>
<span class="line-removed"> 45   STATIC_ASSERT(sizeof(jbyte) == 1);</span>
 46 
<span class="line-modified"> 47   // Initialize cset map</span>





























 48   Copy::zero_to_bytes(_cset_map, _map_size);

 49 }
 50 
 51 void ShenandoahCollectionSet::add_region(ShenandoahHeapRegion* r) {
 52   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Must be at a safepoint&quot;);
 53   assert(Thread::current()-&gt;is_VM_thread(), &quot;Must be VMThread&quot;);
 54   assert(!is_in(r), &quot;Already in collection set&quot;);
 55   _cset_map[r-&gt;region_number()] = 1;
 56   _region_count ++;
 57   _garbage += r-&gt;garbage();
 58   _live_data += r-&gt;get_live_data_bytes();
 59   _used += r-&gt;used();
 60 }
 61 
 62 bool ShenandoahCollectionSet::add_region_check_for_duplicates(ShenandoahHeapRegion* r) {
 63   if (!is_in(r)) {
 64     add_region(r);
 65     return true;
 66   } else {
 67     return false;
 68   }
</pre>
<hr />
<pre>
 99 
100   _garbage = 0;
101   _live_data = 0;
102   _used = 0;
103 
104   _region_count = 0;
105   _current_index = 0;
106 }
107 
108 ShenandoahHeapRegion* ShenandoahCollectionSet::claim_next() {
109   size_t num_regions = _heap-&gt;num_regions();
110   if (_current_index &gt;= (jint)num_regions) {
111     return NULL;
112   }
113 
114   jint saved_current = _current_index;
115   size_t index = (size_t)saved_current;
116 
117   while(index &lt; num_regions) {
118     if (is_in(index)) {
<span class="line-modified">119       jint cur = Atomic::cmpxchg((jint)(index + 1), &amp;_current_index, saved_current);</span>
120       assert(cur &gt;= (jint)saved_current, &quot;Must move forward&quot;);
121       if (cur == saved_current) {
122         assert(is_in(index), &quot;Invariant&quot;);
123         return _heap-&gt;get_region(index);
124       } else {
125         index = (size_t)cur;
126         saved_current = cur;
127       }
128     } else {
129       index ++;
130     }
131   }
132   return NULL;
133 }
134 
135 ShenandoahHeapRegion* ShenandoahCollectionSet::next() {
136   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Must be at a safepoint&quot;);
137   assert(Thread::current()-&gt;is_VM_thread(), &quot;Must be VMThread&quot;);
138   size_t num_regions = _heap-&gt;num_regions();
139   for (size_t index = (size_t)_current_index; index &lt; num_regions; index ++) {
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2016, 2019, Red Hat, Inc. All rights reserved.</span>
<span class="line-added">  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.</span>
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 
 27 #include &quot;gc/shenandoah/shenandoahCollectionSet.hpp&quot;
 28 #include &quot;gc/shenandoah/shenandoahHeap.inline.hpp&quot;
 29 #include &quot;gc/shenandoah/shenandoahHeapRegionSet.hpp&quot;
 30 #include &quot;gc/shenandoah/shenandoahUtils.hpp&quot;
 31 #include &quot;runtime/atomic.hpp&quot;
<span class="line-added"> 32 #include &quot;services/memTracker.hpp&quot;</span>
 33 #include &quot;utilities/copy.hpp&quot;
 34 
<span class="line-modified"> 35 ShenandoahCollectionSet::ShenandoahCollectionSet(ShenandoahHeap* heap, char* heap_base, size_t size) :</span>
 36   _map_size(heap-&gt;num_regions()),
 37   _region_size_bytes_shift(ShenandoahHeapRegion::region_size_bytes_shift()),
<span class="line-modified"> 38   _map_space(align_up(((uintx)heap_base + size) &gt;&gt; _region_size_bytes_shift, os::vm_allocation_granularity())),</span>
<span class="line-modified"> 39   _cset_map(_map_space.base() + ((uintx)heap_base &gt;&gt; _region_size_bytes_shift)),</span>
<span class="line-added"> 40   _biased_cset_map(_map_space.base()),</span>
 41   _heap(heap),
 42   _garbage(0),
 43   _live_data(0),
 44   _used(0),
 45   _region_count(0),
 46   _current_index(0) {


 47 
<span class="line-modified"> 48   // The collection set map is reserved to cover the entire heap *and* zero addresses.</span>
<span class="line-added"> 49   // This is needed to accept in-cset checks for both heap oops and NULLs, freeing</span>
<span class="line-added"> 50   // high-performance code from checking for NULL first.</span>
<span class="line-added"> 51   //</span>
<span class="line-added"> 52   // Since heap_base can be far away, committing the entire map would waste memory.</span>
<span class="line-added"> 53   // Therefore, we only commit the parts that are needed to operate: the heap view,</span>
<span class="line-added"> 54   // and the zero page.</span>
<span class="line-added"> 55   //</span>
<span class="line-added"> 56   // Note: we could instead commit the entire map, and piggyback on OS virtual memory</span>
<span class="line-added"> 57   // subsystem for mapping not-yet-written-to pages to a single physical backing page,</span>
<span class="line-added"> 58   // but this is not guaranteed, and would confuse NMT and other memory accounting tools.</span>
<span class="line-added"> 59 </span>
<span class="line-added"> 60   MemTracker::record_virtual_memory_type(_map_space.base(), mtGC);</span>
<span class="line-added"> 61 </span>
<span class="line-added"> 62   size_t page_size = (size_t)os::vm_page_size();</span>
<span class="line-added"> 63 </span>
<span class="line-added"> 64   if (!_map_space.special()) {</span>
<span class="line-added"> 65     // Commit entire pages that cover the heap cset map.</span>
<span class="line-added"> 66     char* bot_addr = align_down(_cset_map, page_size);</span>
<span class="line-added"> 67     char* top_addr = align_up(_cset_map + _map_size, page_size);</span>
<span class="line-added"> 68     os::commit_memory_or_exit(bot_addr, pointer_delta(top_addr, bot_addr, 1), false,</span>
<span class="line-added"> 69                               &quot;Unable to commit collection set bitmap: heap&quot;);</span>
<span class="line-added"> 70 </span>
<span class="line-added"> 71     // Commit the zero page, if not yet covered by heap cset map.</span>
<span class="line-added"> 72     if (bot_addr != _biased_cset_map) {</span>
<span class="line-added"> 73       os::commit_memory_or_exit(_biased_cset_map, page_size, false,</span>
<span class="line-added"> 74                                 &quot;Unable to commit collection set bitmap: zero page&quot;);</span>
<span class="line-added"> 75     }</span>
<span class="line-added"> 76   }</span>
<span class="line-added"> 77 </span>
 78   Copy::zero_to_bytes(_cset_map, _map_size);
<span class="line-added"> 79   Copy::zero_to_bytes(_biased_cset_map, page_size);</span>
 80 }
 81 
 82 void ShenandoahCollectionSet::add_region(ShenandoahHeapRegion* r) {
 83   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Must be at a safepoint&quot;);
 84   assert(Thread::current()-&gt;is_VM_thread(), &quot;Must be VMThread&quot;);
 85   assert(!is_in(r), &quot;Already in collection set&quot;);
 86   _cset_map[r-&gt;region_number()] = 1;
 87   _region_count ++;
 88   _garbage += r-&gt;garbage();
 89   _live_data += r-&gt;get_live_data_bytes();
 90   _used += r-&gt;used();
 91 }
 92 
 93 bool ShenandoahCollectionSet::add_region_check_for_duplicates(ShenandoahHeapRegion* r) {
 94   if (!is_in(r)) {
 95     add_region(r);
 96     return true;
 97   } else {
 98     return false;
 99   }
</pre>
<hr />
<pre>
130 
131   _garbage = 0;
132   _live_data = 0;
133   _used = 0;
134 
135   _region_count = 0;
136   _current_index = 0;
137 }
138 
139 ShenandoahHeapRegion* ShenandoahCollectionSet::claim_next() {
140   size_t num_regions = _heap-&gt;num_regions();
141   if (_current_index &gt;= (jint)num_regions) {
142     return NULL;
143   }
144 
145   jint saved_current = _current_index;
146   size_t index = (size_t)saved_current;
147 
148   while(index &lt; num_regions) {
149     if (is_in(index)) {
<span class="line-modified">150       jint cur = Atomic::cmpxchg(&amp;_current_index, saved_current, (jint)(index + 1));</span>
151       assert(cur &gt;= (jint)saved_current, &quot;Must move forward&quot;);
152       if (cur == saved_current) {
153         assert(is_in(index), &quot;Invariant&quot;);
154         return _heap-&gt;get_region(index);
155       } else {
156         index = (size_t)cur;
157         saved_current = cur;
158       }
159     } else {
160       index ++;
161     }
162   }
163   return NULL;
164 }
165 
166 ShenandoahHeapRegion* ShenandoahCollectionSet::next() {
167   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Must be at a safepoint&quot;);
168   assert(Thread::current()-&gt;is_VM_thread(), &quot;Must be VMThread&quot;);
169   size_t num_regions = _heap-&gt;num_regions();
170   for (size_t index = (size_t)_current_index; index &lt; num_regions; index ++) {
</pre>
</td>
</tr>
</table>
<center><a href="shenandoahCodeRoots.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahCollectionSet.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>