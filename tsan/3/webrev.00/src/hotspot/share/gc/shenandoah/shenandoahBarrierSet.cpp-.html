<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2013, 2019, Red Hat, Inc. All rights reserved.
  3  *
  4  * This code is free software; you can redistribute it and/or modify it
  5  * under the terms of the GNU General Public License version 2 only, as
  6  * published by the Free Software Foundation.
  7  *
  8  * This code is distributed in the hope that it will be useful, but WITHOUT
  9  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 10  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 11  * version 2 for more details (a copy is included in the LICENSE file that
 12  * accompanied this code).
 13  *
 14  * You should have received a copy of the GNU General Public License version
 15  * 2 along with this work; if not, write to the Free Software Foundation,
 16  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 17  *
 18  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 19  * or visit www.oracle.com if you need additional information or have any
 20  * questions.
 21  *
 22  */
 23 
 24 #include &quot;precompiled.hpp&quot;
 25 #include &quot;gc/shenandoah/shenandoahAsserts.hpp&quot;
 26 #include &quot;gc/shenandoah/shenandoahBarrierSet.hpp&quot;
 27 #include &quot;gc/shenandoah/shenandoahBarrierSetAssembler.hpp&quot;
 28 #include &quot;gc/shenandoah/shenandoahCollectorPolicy.hpp&quot;
 29 #include &quot;gc/shenandoah/shenandoahHeap.inline.hpp&quot;
 30 #include &quot;gc/shenandoah/shenandoahHeuristics.hpp&quot;
 31 #include &quot;gc/shenandoah/shenandoahTraversalGC.hpp&quot;
 32 #include &quot;memory/iterator.inline.hpp&quot;
 33 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
 34 #ifdef COMPILER1
 35 #include &quot;gc/shenandoah/c1/shenandoahBarrierSetC1.hpp&quot;
 36 #endif
 37 #ifdef COMPILER2
 38 #include &quot;gc/shenandoah/c2/shenandoahBarrierSetC2.hpp&quot;
 39 #endif
 40 
 41 class ShenandoahBarrierSetC1;
 42 class ShenandoahBarrierSetC2;
 43 
 44 template &lt;bool STOREVAL_WRITE_BARRIER&gt;
 45 class ShenandoahUpdateRefsForOopClosure: public BasicOopIterateClosure {
 46 private:
 47   ShenandoahHeap* _heap;
 48   ShenandoahBarrierSet* _bs;
 49 
 50   template &lt;class T&gt;
 51   inline void do_oop_work(T* p) {
 52     oop o;
 53     if (STOREVAL_WRITE_BARRIER) {
 54       o = _heap-&gt;evac_update_with_forwarded(p);
 55       if (!CompressedOops::is_null(o)) {
 56         _bs-&gt;enqueue(o);
 57       }
 58     } else {
 59       _heap-&gt;maybe_update_with_forwarded(p);
 60     }
 61   }
 62 public:
 63   ShenandoahUpdateRefsForOopClosure() : _heap(ShenandoahHeap::heap()), _bs(ShenandoahBarrierSet::barrier_set()) {
 64     assert(UseShenandoahGC &amp;&amp; ShenandoahCloneBarrier, &quot;should be enabled&quot;);
 65   }
 66 
 67   virtual void do_oop(oop* p)       { do_oop_work(p); }
 68   virtual void do_oop(narrowOop* p) { do_oop_work(p); }
 69 };
 70 
 71 ShenandoahBarrierSet::ShenandoahBarrierSet(ShenandoahHeap* heap) :
 72   BarrierSet(make_barrier_set_assembler&lt;ShenandoahBarrierSetAssembler&gt;(),
 73              make_barrier_set_c1&lt;ShenandoahBarrierSetC1&gt;(),
 74              make_barrier_set_c2&lt;ShenandoahBarrierSetC2&gt;(),
 75              NULL /* barrier_set_nmethod */,
 76              BarrierSet::FakeRtti(BarrierSet::ShenandoahBarrierSet)),
 77   _heap(heap),
 78   _satb_mark_queue_set()
 79 {
 80 }
 81 
 82 ShenandoahBarrierSetAssembler* ShenandoahBarrierSet::assembler() {
 83   BarrierSetAssembler* const bsa = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
 84   return reinterpret_cast&lt;ShenandoahBarrierSetAssembler*&gt;(bsa);
 85 }
 86 
 87 void ShenandoahBarrierSet::print_on(outputStream* st) const {
 88   st-&gt;print(&quot;ShenandoahBarrierSet&quot;);
 89 }
 90 
 91 bool ShenandoahBarrierSet::is_a(BarrierSet::Name bsn) {
 92   return bsn == BarrierSet::ShenandoahBarrierSet;
 93 }
 94 
 95 bool ShenandoahBarrierSet::is_aligned(HeapWord* hw) {
 96   return true;
 97 }
 98 
 99 template &lt;class T, bool STOREVAL_WRITE_BARRIER&gt;
100 void ShenandoahBarrierSet::write_ref_array_loop(HeapWord* start, size_t count) {
101   assert(UseShenandoahGC &amp;&amp; ShenandoahCloneBarrier, &quot;should be enabled&quot;);
102   ShenandoahUpdateRefsForOopClosure&lt;STOREVAL_WRITE_BARRIER&gt; cl;
103   T* dst = (T*) start;
104   for (size_t i = 0; i &lt; count; i++) {
105     cl.do_oop(dst++);
106   }
107 }
108 
109 void ShenandoahBarrierSet::write_ref_array(HeapWord* start, size_t count) {
110   assert(UseShenandoahGC, &quot;should be enabled&quot;);
111   if (count == 0) return;
112   if (!ShenandoahCloneBarrier) return;
113 
114   if (!need_update_refs_barrier()) return;
115 
116   if (_heap-&gt;is_concurrent_traversal_in_progress()) {
117     ShenandoahEvacOOMScope oom_evac_scope;
118     if (UseCompressedOops) {
119       write_ref_array_loop&lt;narrowOop, /* wb = */ true&gt;(start, count);
120     } else {
121       write_ref_array_loop&lt;oop,       /* wb = */ true&gt;(start, count);
122     }
123   } else {
124     if (UseCompressedOops) {
125       write_ref_array_loop&lt;narrowOop, /* wb = */ false&gt;(start, count);
126     } else {
127       write_ref_array_loop&lt;oop,       /* wb = */ false&gt;(start, count);
128     }
129   }
130 }
131 
132 template &lt;class T&gt;
133 void ShenandoahBarrierSet::write_ref_array_pre_work(T* dst, size_t count) {
134   shenandoah_assert_not_in_cset_loc_except(dst, _heap-&gt;cancelled_gc());
135   if (ShenandoahSATBBarrier &amp;&amp; _heap-&gt;is_concurrent_mark_in_progress()) {
136     T* elem_ptr = dst;
137     for (size_t i = 0; i &lt; count; i++, elem_ptr++) {
138       T heap_oop = RawAccess&lt;&gt;::oop_load(elem_ptr);
139       if (!CompressedOops::is_null(heap_oop)) {
140         enqueue(CompressedOops::decode_not_null(heap_oop));
141       }
142     }
143   }
144 }
145 
146 void ShenandoahBarrierSet::write_ref_array_pre(oop* dst, size_t count, bool dest_uninitialized) {
147   if (! dest_uninitialized) {
148     write_ref_array_pre_work(dst, count);
149   }
150 }
151 
152 void ShenandoahBarrierSet::write_ref_array_pre(narrowOop* dst, size_t count, bool dest_uninitialized) {
153   if (! dest_uninitialized) {
154     write_ref_array_pre_work(dst, count);
155   }
156 }
157 
158 template &lt;class T&gt;
159 inline void ShenandoahBarrierSet::inline_write_ref_field_pre(T* field, oop new_val) {
160   shenandoah_assert_not_in_cset_loc_except(field, _heap-&gt;cancelled_gc());
161   if (_heap-&gt;is_concurrent_mark_in_progress()) {
162     T heap_oop = RawAccess&lt;&gt;::oop_load(field);
163     if (!CompressedOops::is_null(heap_oop)) {
164       enqueue(CompressedOops::decode(heap_oop));
165     }
166   }
167 }
168 
169 // These are the more general virtual versions.
170 void ShenandoahBarrierSet::write_ref_field_pre_work(oop* field, oop new_val) {
171   inline_write_ref_field_pre(field, new_val);
172 }
173 
174 void ShenandoahBarrierSet::write_ref_field_pre_work(narrowOop* field, oop new_val) {
175   inline_write_ref_field_pre(field, new_val);
176 }
177 
178 void ShenandoahBarrierSet::write_ref_field_pre_work(void* field, oop new_val) {
179   guarantee(false, &quot;Not needed&quot;);
180 }
181 
182 void ShenandoahBarrierSet::write_ref_field_work(void* v, oop o, bool release) {
183   shenandoah_assert_not_in_cset_loc_except(v, _heap-&gt;cancelled_gc());
184   shenandoah_assert_not_forwarded_except  (v, o, o == NULL || _heap-&gt;cancelled_gc() || !_heap-&gt;is_concurrent_mark_in_progress());
185   shenandoah_assert_not_in_cset_except    (v, o, o == NULL || _heap-&gt;cancelled_gc() || !_heap-&gt;is_concurrent_mark_in_progress());
186 }
187 
188 void ShenandoahBarrierSet::write_region(MemRegion mr) {
189   assert(UseShenandoahGC, &quot;should be enabled&quot;);
190   if (!ShenandoahCloneBarrier) return;
191   if (! need_update_refs_barrier()) return;
192 
193   // This is called for cloning an object (see jvm.cpp) after the clone
194   // has been made. We are not interested in any &#39;previous value&#39; because
195   // it would be NULL in any case. But we *are* interested in any oop*
196   // that potentially need to be updated.
197 
198   oop obj = oop(mr.start());
199   shenandoah_assert_correct(NULL, obj);
200   if (_heap-&gt;is_concurrent_traversal_in_progress()) {
201     ShenandoahEvacOOMScope oom_evac_scope;
202     ShenandoahUpdateRefsForOopClosure&lt;/* wb = */ true&gt; cl;
203     obj-&gt;oop_iterate(&amp;cl);
204   } else {
205     ShenandoahUpdateRefsForOopClosure&lt;/* wb = */ false&gt; cl;
206     obj-&gt;oop_iterate(&amp;cl);
207   }
208 }
209 
210 oop ShenandoahBarrierSet::read_barrier(oop src) {
211   // Check for forwarded objects, because on Full GC path we might deal with
212   // non-trivial fwdptrs that contain Full GC specific metadata. We could check
213   // for is_full_gc_in_progress(), but this also covers the case of stable heap,
214   // which provides a bit of performance improvement.
215   if (ShenandoahReadBarrier &amp;&amp; _heap-&gt;has_forwarded_objects()) {
216     return ShenandoahBarrierSet::resolve_forwarded(src);
217   } else {
218     return src;
219   }
220 }
221 
222 bool ShenandoahBarrierSet::obj_equals(oop obj1, oop obj2) {
223   bool eq = oopDesc::equals_raw(obj1, obj2);
224   if (! eq &amp;&amp; ShenandoahAcmpBarrier) {
225     OrderAccess::loadload();
226     obj1 = resolve_forwarded(obj1);
227     obj2 = resolve_forwarded(obj2);
228     eq = oopDesc::equals_raw(obj1, obj2);
229   }
230   return eq;
231 }
232 
233 oop ShenandoahBarrierSet::write_barrier_mutator(oop obj) {
234   assert(UseShenandoahGC &amp;&amp; ShenandoahWriteBarrier, &quot;should be enabled&quot;);
235   assert(_heap-&gt;is_gc_in_progress_mask(ShenandoahHeap::EVACUATION | ShenandoahHeap::TRAVERSAL), &quot;evac should be in progress&quot;);
236   shenandoah_assert_in_cset(NULL, obj);
237 
238   oop fwd = resolve_forwarded_not_null(obj);
239   if (oopDesc::equals_raw(obj, fwd)) {
240     ShenandoahEvacOOMScope oom_evac_scope;
241 
242     Thread* thread = Thread::current();
243     oop res_oop = _heap-&gt;evacuate_object(obj, thread);
244 
245     // Since we are already here and paid the price of getting through runtime call adapters
246     // and acquiring oom-scope, it makes sense to try and evacuate more adjacent objects,
247     // thus amortizing the overhead. For sparsely live heaps, scan costs easily dominate
248     // total assist costs, and can introduce a lot of evacuation latency. This is why we
249     // only scan for _nearest_ N objects, regardless if they are eligible for evac or not.
250     // The scan itself should also avoid touching the non-marked objects below TAMS, because
251     // their metadata (notably, klasses) may be incorrect already.
252 
253     size_t max = ShenandoahEvacAssist;
254     if (max &gt; 0) {
255       // Traversal is special: it uses incomplete marking context, because it coalesces evac with mark.
256       // Other code uses complete marking context, because evac happens after the mark.
257       ShenandoahMarkingContext* ctx = _heap-&gt;is_concurrent_traversal_in_progress() ?
258                                       _heap-&gt;marking_context() : _heap-&gt;complete_marking_context();
259 
260       ShenandoahHeapRegion* r = _heap-&gt;heap_region_containing(obj);
261       assert(r-&gt;is_cset(), &quot;sanity&quot;);
262 
263       HeapWord* cur = (HeapWord*)obj + obj-&gt;size() + ShenandoahBrooksPointer::word_size();
264 
265       size_t count = 0;
266       while ((cur &lt; r-&gt;top()) &amp;&amp; ctx-&gt;is_marked(oop(cur)) &amp;&amp; (count++ &lt; max)) {
267         oop cur_oop = oop(cur);
268         if (oopDesc::equals_raw(cur_oop, resolve_forwarded_not_null(cur_oop))) {
269           _heap-&gt;evacuate_object(cur_oop, thread);
270         }
271         cur = cur + cur_oop-&gt;size() + ShenandoahBrooksPointer::word_size();
272       }
273     }
274 
275     return res_oop;
276   }
277   return fwd;
278 }
279 
280 oop ShenandoahBarrierSet::write_barrier_impl(oop obj) {
281   assert(UseShenandoahGC &amp;&amp; ShenandoahWriteBarrier, &quot;should be enabled&quot;);
282   if (!CompressedOops::is_null(obj)) {
283     bool evac_in_progress = _heap-&gt;is_gc_in_progress_mask(ShenandoahHeap::EVACUATION | ShenandoahHeap::TRAVERSAL);
284     oop fwd = resolve_forwarded_not_null(obj);
285     if (evac_in_progress &amp;&amp;
286         _heap-&gt;in_collection_set(obj) &amp;&amp;
287         oopDesc::equals_raw(obj, fwd)) {
288       Thread *t = Thread::current();
289       if (t-&gt;is_GC_task_thread()) {
290         return _heap-&gt;evacuate_object(obj, t);
291       } else {
292         ShenandoahEvacOOMScope oom_evac_scope;
293         return _heap-&gt;evacuate_object(obj, t);
294       }
295     } else {
296       return fwd;
297     }
298   } else {
299     return obj;
300   }
301 }
302 
303 oop ShenandoahBarrierSet::write_barrier(oop obj) {
304   if (ShenandoahWriteBarrier &amp;&amp; _heap-&gt;has_forwarded_objects()) {
305     return write_barrier_impl(obj);
306   } else {
307     return obj;
308   }
309 }
310 
311 oop ShenandoahBarrierSet::storeval_barrier(oop obj) {
312   if (ShenandoahStoreValEnqueueBarrier) {
313     if (!CompressedOops::is_null(obj)) {
314       obj = write_barrier(obj);
315       enqueue(obj);
316     }
317   }
318   if (ShenandoahStoreValReadBarrier) {
319     obj = resolve_forwarded(obj);
320   }
321   return obj;
322 }
323 
324 void ShenandoahBarrierSet::keep_alive_barrier(oop obj) {
325   if (ShenandoahKeepAliveBarrier &amp;&amp; _heap-&gt;is_concurrent_mark_in_progress()) {
326     enqueue(obj);
327   }
328 }
329 
330 void ShenandoahBarrierSet::enqueue(oop obj) {
331   shenandoah_assert_not_forwarded_if(NULL, obj, _heap-&gt;is_concurrent_traversal_in_progress());
332   if (!_satb_mark_queue_set.is_active()) return;
333 
334   // Filter marked objects before hitting the SATB queues. The same predicate would
335   // be used by SATBMQ::filter to eliminate already marked objects downstream, but
336   // filtering here helps to avoid wasteful SATB queueing work to begin with.
337   if (!_heap-&gt;requires_marking&lt;false&gt;(obj)) return;
338 
339   ShenandoahThreadLocalData::satb_mark_queue(Thread::current()).enqueue(obj);
340 }
341 
342 void ShenandoahBarrierSet::on_thread_create(Thread* thread) {
343   // Create thread local data
344   ShenandoahThreadLocalData::create(thread);
345 }
346 
347 void ShenandoahBarrierSet::on_thread_destroy(Thread* thread) {
348   // Destroy thread local data
349   ShenandoahThreadLocalData::destroy(thread);
350 }
351 
352 void ShenandoahBarrierSet::on_thread_attach(Thread *thread) {
353   assert(!thread-&gt;is_Java_thread() || !SafepointSynchronize::is_at_safepoint(),
354          &quot;We should not be at a safepoint&quot;);
355   SATBMarkQueue&amp; queue = ShenandoahThreadLocalData::satb_mark_queue(thread);
356   assert(!queue.is_active(), &quot;SATB queue should not be active&quot;);
357   assert( queue.is_empty(),  &quot;SATB queue should be empty&quot;);
358   queue.set_active(_satb_mark_queue_set.is_active());
359   if (thread-&gt;is_Java_thread()) {
360     ShenandoahThreadLocalData::set_gc_state(thread, _heap-&gt;gc_state());
361     ShenandoahThreadLocalData::initialize_gclab(thread);
362   }
363 }
364 
365 void ShenandoahBarrierSet::on_thread_detach(Thread *thread) {
366   SATBMarkQueue&amp; queue = ShenandoahThreadLocalData::satb_mark_queue(thread);
367   queue.flush();
368   if (thread-&gt;is_Java_thread()) {
369     PLAB* gclab = ShenandoahThreadLocalData::gclab(thread);
370     if (gclab != NULL) {
371       gclab-&gt;retire();
372     }
373   }
374 }
    </pre>
  </body>
</html>