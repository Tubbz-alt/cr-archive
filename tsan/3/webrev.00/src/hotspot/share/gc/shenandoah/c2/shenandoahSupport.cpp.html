<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp</title>
    <link rel="stylesheet" href="../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 2015, 2019, Red Hat, Inc. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 
  27 #include &quot;gc/shenandoah/c2/shenandoahSupport.hpp&quot;
  28 #include &quot;gc/shenandoah/c2/shenandoahBarrierSetC2.hpp&quot;
  29 #include &quot;gc/shenandoah/shenandoahBarrierSetAssembler.hpp&quot;
  30 #include &quot;gc/shenandoah/shenandoahForwarding.hpp&quot;
  31 #include &quot;gc/shenandoah/shenandoahHeap.hpp&quot;
  32 #include &quot;gc/shenandoah/shenandoahHeapRegion.hpp&quot;
  33 #include &quot;gc/shenandoah/shenandoahRuntime.hpp&quot;
  34 #include &quot;gc/shenandoah/shenandoahThreadLocalData.hpp&quot;
  35 #include &quot;opto/arraycopynode.hpp&quot;
  36 #include &quot;opto/block.hpp&quot;
  37 #include &quot;opto/callnode.hpp&quot;
  38 #include &quot;opto/castnode.hpp&quot;
  39 #include &quot;opto/movenode.hpp&quot;
  40 #include &quot;opto/phaseX.hpp&quot;
  41 #include &quot;opto/rootnode.hpp&quot;
  42 #include &quot;opto/runtime.hpp&quot;
  43 #include &quot;opto/subnode.hpp&quot;
  44 
  45 bool ShenandoahBarrierC2Support::expand(Compile* C, PhaseIterGVN&amp; igvn) {
  46   ShenandoahBarrierSetC2State* state = ShenandoahBarrierSetC2::bsc2()-&gt;state();
  47   if ((state-&gt;enqueue_barriers_count() +
  48        state-&gt;load_reference_barriers_count()) &gt; 0) {
  49     bool attempt_more_loopopts = ShenandoahLoopOptsAfterExpansion;
  50     C-&gt;clear_major_progress();
  51     PhaseIdealLoop ideal_loop(igvn, LoopOptsShenandoahExpand);
  52     if (C-&gt;failing()) return false;
  53     PhaseIdealLoop::verify(igvn);
  54     DEBUG_ONLY(verify_raw_mem(C-&gt;root());)
  55     if (attempt_more_loopopts) {
  56       C-&gt;set_major_progress();
  57       if (!C-&gt;optimize_loops(igvn, LoopOptsShenandoahPostExpand)) {
  58         return false;
  59       }
  60       C-&gt;clear_major_progress();
  61       if (C-&gt;range_check_cast_count() &gt; 0) {
  62         // No more loop optimizations. Remove all range check dependent CastIINodes.
  63         C-&gt;remove_range_check_casts(igvn);
  64         igvn.optimize();
  65       }
  66     }
  67   }
  68   return true;
  69 }
  70 
  71 bool ShenandoahBarrierC2Support::is_heap_state_test(Node* iff, int mask) {
  72   if (!UseShenandoahGC) {
  73     return false;
  74   }
  75   assert(iff-&gt;is_If(), &quot;bad input&quot;);
  76   if (iff-&gt;Opcode() != Op_If) {
  77     return false;
  78   }
  79   Node* bol = iff-&gt;in(1);
  80   if (!bol-&gt;is_Bool() || bol-&gt;as_Bool()-&gt;_test._test != BoolTest::ne) {
  81     return false;
  82   }
  83   Node* cmp = bol-&gt;in(1);
  84   if (cmp-&gt;Opcode() != Op_CmpI) {
  85     return false;
  86   }
  87   Node* in1 = cmp-&gt;in(1);
  88   Node* in2 = cmp-&gt;in(2);
  89   if (in2-&gt;find_int_con(-1) != 0) {
  90     return false;
  91   }
  92   if (in1-&gt;Opcode() != Op_AndI) {
  93     return false;
  94   }
  95   in2 = in1-&gt;in(2);
  96   if (in2-&gt;find_int_con(-1) != mask) {
  97     return false;
  98   }
  99   in1 = in1-&gt;in(1);
 100 
 101   return is_gc_state_load(in1);
 102 }
 103 
 104 bool ShenandoahBarrierC2Support::is_heap_stable_test(Node* iff) {
 105   return is_heap_state_test(iff, ShenandoahHeap::HAS_FORWARDED);
 106 }
 107 
 108 bool ShenandoahBarrierC2Support::is_gc_state_load(Node *n) {
 109   if (!UseShenandoahGC) {
 110     return false;
 111   }
 112   if (n-&gt;Opcode() != Op_LoadB &amp;&amp; n-&gt;Opcode() != Op_LoadUB) {
 113     return false;
 114   }
 115   Node* addp = n-&gt;in(MemNode::Address);
 116   if (!addp-&gt;is_AddP()) {
 117     return false;
 118   }
 119   Node* base = addp-&gt;in(AddPNode::Address);
 120   Node* off = addp-&gt;in(AddPNode::Offset);
 121   if (base-&gt;Opcode() != Op_ThreadLocal) {
 122     return false;
 123   }
 124   if (off-&gt;find_intptr_t_con(-1) != in_bytes(ShenandoahThreadLocalData::gc_state_offset())) {
 125     return false;
 126   }
 127   return true;
 128 }
 129 
 130 bool ShenandoahBarrierC2Support::has_safepoint_between(Node* start, Node* stop, PhaseIdealLoop *phase) {
 131   assert(phase-&gt;is_dominator(stop, start), &quot;bad inputs&quot;);
 132   ResourceMark rm;
 133   Unique_Node_List wq;
 134   wq.push(start);
 135   for (uint next = 0; next &lt; wq.size(); next++) {
 136     Node *m = wq.at(next);
 137     if (m == stop) {
 138       continue;
 139     }
 140     if (m-&gt;is_SafePoint() &amp;&amp; !m-&gt;is_CallLeaf()) {
 141       return true;
 142     }
 143     if (m-&gt;is_Region()) {
 144       for (uint i = 1; i &lt; m-&gt;req(); i++) {
 145         wq.push(m-&gt;in(i));
 146       }
 147     } else {
 148       wq.push(m-&gt;in(0));
 149     }
 150   }
 151   return false;
 152 }
 153 
 154 bool ShenandoahBarrierC2Support::try_common_gc_state_load(Node *n, PhaseIdealLoop *phase) {
 155   assert(is_gc_state_load(n), &quot;inconsistent&quot;);
 156   Node* addp = n-&gt;in(MemNode::Address);
 157   Node* dominator = NULL;
 158   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 159     Node* u = addp-&gt;fast_out(i);
 160     assert(is_gc_state_load(u), &quot;inconsistent&quot;);
 161     if (u != n &amp;&amp; phase-&gt;is_dominator(u-&gt;in(0), n-&gt;in(0))) {
 162       if (dominator == NULL) {
 163         dominator = u;
 164       } else {
 165         if (phase-&gt;dom_depth(u-&gt;in(0)) &lt; phase-&gt;dom_depth(dominator-&gt;in(0))) {
 166           dominator = u;
 167         }
 168       }
 169     }
 170   }
 171   if (dominator == NULL || has_safepoint_between(n-&gt;in(0), dominator-&gt;in(0), phase)) {
 172     return false;
 173   }
 174   phase-&gt;igvn().replace_node(n, dominator);
 175 
 176   return true;
 177 }
 178 
 179 #ifdef ASSERT
 180 bool ShenandoahBarrierC2Support::verify_helper(Node* in, Node_Stack&amp; phis, VectorSet&amp; visited, verify_type t, bool trace, Unique_Node_List&amp; barriers_used) {
 181   assert(phis.size() == 0, &quot;&quot;);
 182 
 183   while (true) {
 184     if (in-&gt;bottom_type() == TypePtr::NULL_PTR) {
 185       if (trace) {tty-&gt;print_cr(&quot;NULL&quot;);}
 186     } else if (!in-&gt;bottom_type()-&gt;make_ptr()-&gt;make_oopptr()) {
 187       if (trace) {tty-&gt;print_cr(&quot;Non oop&quot;);}
 188     } else {
 189       if (in-&gt;is_ConstraintCast()) {
 190         in = in-&gt;in(1);
 191         continue;
 192       } else if (in-&gt;is_AddP()) {
 193         assert(!in-&gt;in(AddPNode::Address)-&gt;is_top(), &quot;no raw memory access&quot;);
 194         in = in-&gt;in(AddPNode::Address);
 195         continue;
 196       } else if (in-&gt;is_Con()) {
 197         if (trace) {
 198           tty-&gt;print(&quot;Found constant&quot;);
 199           in-&gt;dump();
 200         }
 201       } else if (in-&gt;Opcode() == Op_Parm) {
 202         if (trace) {
 203           tty-&gt;print(&quot;Found argument&quot;);
 204         }
 205       } else if (in-&gt;Opcode() == Op_CreateEx) {
 206         if (trace) {
 207           tty-&gt;print(&quot;Found create-exception&quot;);
 208         }
 209       } else if (in-&gt;Opcode() == Op_LoadP &amp;&amp; in-&gt;adr_type() == TypeRawPtr::BOTTOM) {
 210         if (trace) {
 211           tty-&gt;print(&quot;Found raw LoadP (OSR argument?)&quot;);
 212         }
 213       } else if (in-&gt;Opcode() == Op_ShenandoahLoadReferenceBarrier) {
 214         if (t == ShenandoahOopStore) {
 215           uint i = 0;
 216           for (; i &lt; phis.size(); i++) {
 217             Node* n = phis.node_at(i);
 218             if (n-&gt;Opcode() == Op_ShenandoahEnqueueBarrier) {
 219               break;
 220             }
 221           }
 222           if (i == phis.size()) {
 223             return false;
 224           }
 225         }
 226         barriers_used.push(in);
 227         if (trace) {tty-&gt;print(&quot;Found barrier&quot;); in-&gt;dump();}
 228       } else if (in-&gt;Opcode() == Op_ShenandoahEnqueueBarrier) {
 229         if (t != ShenandoahOopStore) {
 230           in = in-&gt;in(1);
 231           continue;
 232         }
 233         if (trace) {tty-&gt;print(&quot;Found enqueue barrier&quot;); in-&gt;dump();}
 234         phis.push(in, in-&gt;req());
 235         in = in-&gt;in(1);
 236         continue;
 237       } else if (in-&gt;is_Proj() &amp;&amp; in-&gt;in(0)-&gt;is_Allocate()) {
 238         if (trace) {
 239           tty-&gt;print(&quot;Found alloc&quot;);
 240           in-&gt;in(0)-&gt;dump();
 241         }
 242       } else if (in-&gt;is_Proj() &amp;&amp; (in-&gt;in(0)-&gt;Opcode() == Op_CallStaticJava || in-&gt;in(0)-&gt;Opcode() == Op_CallDynamicJava)) {
 243         if (trace) {
 244           tty-&gt;print(&quot;Found Java call&quot;);
 245         }
 246       } else if (in-&gt;is_Phi()) {
 247         if (!visited.test_set(in-&gt;_idx)) {
 248           if (trace) {tty-&gt;print(&quot;Pushed phi:&quot;); in-&gt;dump();}
 249           phis.push(in, 2);
 250           in = in-&gt;in(1);
 251           continue;
 252         }
 253         if (trace) {tty-&gt;print(&quot;Already seen phi:&quot;); in-&gt;dump();}
 254       } else if (in-&gt;Opcode() == Op_CMoveP || in-&gt;Opcode() == Op_CMoveN) {
 255         if (!visited.test_set(in-&gt;_idx)) {
 256           if (trace) {tty-&gt;print(&quot;Pushed cmovep:&quot;); in-&gt;dump();}
 257           phis.push(in, CMoveNode::IfTrue);
 258           in = in-&gt;in(CMoveNode::IfFalse);
 259           continue;
 260         }
 261         if (trace) {tty-&gt;print(&quot;Already seen cmovep:&quot;); in-&gt;dump();}
 262       } else if (in-&gt;Opcode() == Op_EncodeP || in-&gt;Opcode() == Op_DecodeN) {
 263         in = in-&gt;in(1);
 264         continue;
 265       } else {
 266         return false;
 267       }
 268     }
 269     bool cont = false;
 270     while (phis.is_nonempty()) {
 271       uint idx = phis.index();
 272       Node* phi = phis.node();
 273       if (idx &gt;= phi-&gt;req()) {
 274         if (trace) {tty-&gt;print(&quot;Popped phi:&quot;); phi-&gt;dump();}
 275         phis.pop();
 276         continue;
 277       }
 278       if (trace) {tty-&gt;print(&quot;Next entry(%d) for phi:&quot;, idx); phi-&gt;dump();}
 279       in = phi-&gt;in(idx);
 280       phis.set_index(idx+1);
 281       cont = true;
 282       break;
 283     }
 284     if (!cont) {
 285       break;
 286     }
 287   }
 288   return true;
 289 }
 290 
 291 void ShenandoahBarrierC2Support::report_verify_failure(const char* msg, Node* n1, Node* n2) {
 292   if (n1 != NULL) {
 293     n1-&gt;dump(+10);
 294   }
 295   if (n2 != NULL) {
 296     n2-&gt;dump(+10);
 297   }
 298   fatal(&quot;%s&quot;, msg);
 299 }
 300 
 301 void ShenandoahBarrierC2Support::verify(RootNode* root) {
 302   ResourceMark rm;
 303   Unique_Node_List wq;
 304   GrowableArray&lt;Node*&gt; barriers;
 305   Unique_Node_List barriers_used;
 306   Node_Stack phis(0);
 307   VectorSet visited(Thread::current()-&gt;resource_area());
 308   const bool trace = false;
 309   const bool verify_no_useless_barrier = false;
 310 
 311   wq.push(root);
 312   for (uint next = 0; next &lt; wq.size(); next++) {
 313     Node *n = wq.at(next);
 314     if (n-&gt;is_Load()) {
 315       const bool trace = false;
 316       if (trace) {tty-&gt;print(&quot;Verifying&quot;); n-&gt;dump();}
 317       if (n-&gt;Opcode() == Op_LoadRange || n-&gt;Opcode() == Op_LoadKlass || n-&gt;Opcode() == Op_LoadNKlass) {
 318         if (trace) {tty-&gt;print_cr(&quot;Load range/klass&quot;);}
 319       } else {
 320         const TypePtr* adr_type = n-&gt;as_Load()-&gt;adr_type();
 321 
 322         if (adr_type-&gt;isa_oopptr() &amp;&amp; adr_type-&gt;is_oopptr()-&gt;offset() == oopDesc::mark_offset_in_bytes()) {
 323           if (trace) {tty-&gt;print_cr(&quot;Mark load&quot;);}
 324         } else if (adr_type-&gt;isa_instptr() &amp;&amp;
 325                    adr_type-&gt;is_instptr()-&gt;klass()-&gt;is_subtype_of(Compile::current()-&gt;env()-&gt;Reference_klass()) &amp;&amp;
 326                    adr_type-&gt;is_instptr()-&gt;offset() == java_lang_ref_Reference::referent_offset) {
 327           if (trace) {tty-&gt;print_cr(&quot;Reference.get()&quot;);}
 328         } else if (!verify_helper(n-&gt;in(MemNode::Address), phis, visited, ShenandoahLoad, trace, barriers_used)) {
 329           report_verify_failure(&quot;Shenandoah verification: Load should have barriers&quot;, n);
 330         }
 331       }
 332     } else if (n-&gt;is_Store()) {
 333       const bool trace = false;
 334 
 335       if (trace) {tty-&gt;print(&quot;Verifying&quot;); n-&gt;dump();}
 336       if (n-&gt;in(MemNode::ValueIn)-&gt;bottom_type()-&gt;make_oopptr()) {
 337         Node* adr = n-&gt;in(MemNode::Address);
 338         bool verify = true;
 339 
 340         if (adr-&gt;is_AddP() &amp;&amp; adr-&gt;in(AddPNode::Base)-&gt;is_top()) {
 341           adr = adr-&gt;in(AddPNode::Address);
 342           if (adr-&gt;is_AddP()) {
 343             assert(adr-&gt;in(AddPNode::Base)-&gt;is_top(), &quot;&quot;);
 344             adr = adr-&gt;in(AddPNode::Address);
 345             if (adr-&gt;Opcode() == Op_LoadP &amp;&amp;
 346                 adr-&gt;in(MemNode::Address)-&gt;in(AddPNode::Base)-&gt;is_top() &amp;&amp;
 347                 adr-&gt;in(MemNode::Address)-&gt;in(AddPNode::Address)-&gt;Opcode() == Op_ThreadLocal &amp;&amp;
 348                 adr-&gt;in(MemNode::Address)-&gt;in(AddPNode::Offset)-&gt;find_intptr_t_con(-1) == in_bytes(ShenandoahThreadLocalData::satb_mark_queue_buffer_offset())) {
 349               if (trace) {tty-&gt;print_cr(&quot;SATB prebarrier&quot;);}
 350               verify = false;
 351             }
 352           }
 353         }
 354 
 355         if (verify &amp;&amp; !verify_helper(n-&gt;in(MemNode::ValueIn), phis, visited, ShenandoahStoreValEnqueueBarrier ? ShenandoahOopStore : ShenandoahValue, trace, barriers_used)) {
 356           report_verify_failure(&quot;Shenandoah verification: Store should have barriers&quot;, n);
 357         }
 358       }
 359       if (!verify_helper(n-&gt;in(MemNode::Address), phis, visited, ShenandoahStore, trace, barriers_used)) {
 360         report_verify_failure(&quot;Shenandoah verification: Store (address) should have barriers&quot;, n);
 361       }
 362     } else if (n-&gt;Opcode() == Op_CmpP) {
 363       const bool trace = false;
 364 
 365       Node* in1 = n-&gt;in(1);
 366       Node* in2 = n-&gt;in(2);
 367       if (in1-&gt;bottom_type()-&gt;isa_oopptr()) {
 368         if (trace) {tty-&gt;print(&quot;Verifying&quot;); n-&gt;dump();}
 369 
 370         bool mark_inputs = false;
 371         if (in1-&gt;bottom_type() == TypePtr::NULL_PTR || in2-&gt;bottom_type() == TypePtr::NULL_PTR ||
 372             (in1-&gt;is_Con() || in2-&gt;is_Con())) {
 373           if (trace) {tty-&gt;print_cr(&quot;Comparison against a constant&quot;);}
 374           mark_inputs = true;
 375         } else if ((in1-&gt;is_CheckCastPP() &amp;&amp; in1-&gt;in(1)-&gt;is_Proj() &amp;&amp; in1-&gt;in(1)-&gt;in(0)-&gt;is_Allocate()) ||
 376                    (in2-&gt;is_CheckCastPP() &amp;&amp; in2-&gt;in(1)-&gt;is_Proj() &amp;&amp; in2-&gt;in(1)-&gt;in(0)-&gt;is_Allocate())) {
 377           if (trace) {tty-&gt;print_cr(&quot;Comparison with newly alloc&#39;ed object&quot;);}
 378           mark_inputs = true;
 379         } else {
 380           assert(in2-&gt;bottom_type()-&gt;isa_oopptr(), &quot;&quot;);
 381 
 382           if (!verify_helper(in1, phis, visited, ShenandoahStore, trace, barriers_used) ||
 383               !verify_helper(in2, phis, visited, ShenandoahStore, trace, barriers_used)) {
 384             report_verify_failure(&quot;Shenandoah verification: Cmp should have barriers&quot;, n);
 385           }
 386         }
 387         if (verify_no_useless_barrier &amp;&amp;
 388             mark_inputs &amp;&amp;
 389             (!verify_helper(in1, phis, visited, ShenandoahValue, trace, barriers_used) ||
 390              !verify_helper(in2, phis, visited, ShenandoahValue, trace, barriers_used))) {
 391           phis.clear();
 392           visited.reset();
 393         }
 394       }
 395     } else if (n-&gt;is_LoadStore()) {
 396       if (n-&gt;in(MemNode::ValueIn)-&gt;bottom_type()-&gt;make_ptr() &amp;&amp;
 397           !verify_helper(n-&gt;in(MemNode::ValueIn), phis, visited, ShenandoahStoreValEnqueueBarrier ? ShenandoahOopStore : ShenandoahValue, trace, barriers_used)) {
 398         report_verify_failure(&quot;Shenandoah verification: LoadStore (value) should have barriers&quot;, n);
 399       }
 400 
 401       if (n-&gt;in(MemNode::Address)-&gt;bottom_type()-&gt;make_oopptr() &amp;&amp; !verify_helper(n-&gt;in(MemNode::Address), phis, visited, ShenandoahStore, trace, barriers_used)) {
 402         report_verify_failure(&quot;Shenandoah verification: LoadStore (address) should have barriers&quot;, n);
 403       }
 404     } else if (n-&gt;Opcode() == Op_CallLeafNoFP || n-&gt;Opcode() == Op_CallLeaf) {
 405       CallNode* call = n-&gt;as_Call();
 406 
 407       static struct {
 408         const char* name;
 409         struct {
 410           int pos;
 411           verify_type t;
 412         } args[6];
 413       } calls[] = {
 414         &quot;aescrypt_encryptBlock&quot;,
 415         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahStore },  { TypeFunc::Parms+2, ShenandoahLoad },
 416           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 417         &quot;aescrypt_decryptBlock&quot;,
 418         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahStore },  { TypeFunc::Parms+2, ShenandoahLoad },
 419           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 420         &quot;multiplyToLen&quot;,
 421         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+2, ShenandoahLoad },   { TypeFunc::Parms+4, ShenandoahStore },
 422           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 423         &quot;squareToLen&quot;,
 424         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+2, ShenandoahLoad },   { -1,  ShenandoahNone},
 425           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 426         &quot;montgomery_multiply&quot;,
 427         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahLoad },   { TypeFunc::Parms+2, ShenandoahLoad },
 428           { TypeFunc::Parms+6, ShenandoahStore }, { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 429         &quot;montgomery_square&quot;,
 430         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahLoad },   { TypeFunc::Parms+5, ShenandoahStore },
 431           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 432         &quot;mulAdd&quot;,
 433         { { TypeFunc::Parms, ShenandoahStore },  { TypeFunc::Parms+1, ShenandoahLoad },   { -1,  ShenandoahNone},
 434           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 435         &quot;vectorizedMismatch&quot;,
 436         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahLoad },   { -1,  ShenandoahNone},
 437           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 438         &quot;updateBytesCRC32&quot;,
 439         { { TypeFunc::Parms+1, ShenandoahLoad }, { -1,  ShenandoahNone},                  { -1,  ShenandoahNone},
 440           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 441         &quot;updateBytesAdler32&quot;,
 442         { { TypeFunc::Parms+1, ShenandoahLoad }, { -1,  ShenandoahNone},                  { -1,  ShenandoahNone},
 443           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 444         &quot;updateBytesCRC32C&quot;,
 445         { { TypeFunc::Parms+1, ShenandoahLoad }, { TypeFunc::Parms+3, ShenandoahLoad},    { -1,  ShenandoahNone},
 446           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 447         &quot;counterMode_AESCrypt&quot;,
 448         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahStore },  { TypeFunc::Parms+2, ShenandoahLoad },
 449           { TypeFunc::Parms+3, ShenandoahStore }, { TypeFunc::Parms+5, ShenandoahStore }, { TypeFunc::Parms+6, ShenandoahStore } },
 450         &quot;cipherBlockChaining_encryptAESCrypt&quot;,
 451         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahStore },  { TypeFunc::Parms+2, ShenandoahLoad },
 452           { TypeFunc::Parms+3, ShenandoahLoad },  { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 453         &quot;cipherBlockChaining_decryptAESCrypt&quot;,
 454         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahStore },  { TypeFunc::Parms+2, ShenandoahLoad },
 455           { TypeFunc::Parms+3, ShenandoahLoad },  { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 456         &quot;shenandoah_clone_barrier&quot;,
 457         { { TypeFunc::Parms, ShenandoahLoad },   { -1,  ShenandoahNone},                  { -1,  ShenandoahNone},
 458           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 459         &quot;ghash_processBlocks&quot;,
 460         { { TypeFunc::Parms, ShenandoahStore },  { TypeFunc::Parms+1, ShenandoahLoad },   { TypeFunc::Parms+2, ShenandoahLoad },
 461           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 462         &quot;sha1_implCompress&quot;,
 463         { { TypeFunc::Parms, ShenandoahLoad },  { TypeFunc::Parms+1, ShenandoahStore },   { -1, ShenandoahNone },
 464           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 465         &quot;sha256_implCompress&quot;,
 466         { { TypeFunc::Parms, ShenandoahLoad },  { TypeFunc::Parms+1, ShenandoahStore },   { -1, ShenandoahNone },
 467           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 468         &quot;sha512_implCompress&quot;,
 469         { { TypeFunc::Parms, ShenandoahLoad },  { TypeFunc::Parms+1, ShenandoahStore },   { -1, ShenandoahNone },
 470           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 471         &quot;sha1_implCompressMB&quot;,
 472         { { TypeFunc::Parms, ShenandoahLoad },  { TypeFunc::Parms+1, ShenandoahStore },   { -1, ShenandoahNone },
 473           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 474         &quot;sha256_implCompressMB&quot;,
 475         { { TypeFunc::Parms, ShenandoahLoad },  { TypeFunc::Parms+1, ShenandoahStore },   { -1, ShenandoahNone },
 476           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 477         &quot;sha512_implCompressMB&quot;,
 478         { { TypeFunc::Parms, ShenandoahLoad },  { TypeFunc::Parms+1, ShenandoahStore },   { -1, ShenandoahNone },
 479           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 480         &quot;encodeBlock&quot;,
 481         { { TypeFunc::Parms, ShenandoahLoad },  { TypeFunc::Parms+3, ShenandoahStore },   { -1, ShenandoahNone },
 482           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 483       };
 484 
 485       if (call-&gt;is_call_to_arraycopystub()) {
 486         Node* dest = NULL;
 487         const TypeTuple* args = n-&gt;as_Call()-&gt;_tf-&gt;domain();
 488         for (uint i = TypeFunc::Parms, j = 0; i &lt; args-&gt;cnt(); i++) {
 489           if (args-&gt;field_at(i)-&gt;isa_ptr()) {
 490             j++;
 491             if (j == 2) {
 492               dest = n-&gt;in(i);
 493               break;
 494             }
 495           }
 496         }
 497         if (!verify_helper(n-&gt;in(TypeFunc::Parms), phis, visited, ShenandoahLoad, trace, barriers_used) ||
 498             !verify_helper(dest, phis, visited, ShenandoahStore, trace, barriers_used)) {
 499           report_verify_failure(&quot;Shenandoah verification: ArrayCopy should have barriers&quot;, n);
 500         }
 501       } else if (strlen(call-&gt;_name) &gt; 5 &amp;&amp;
 502                  !strcmp(call-&gt;_name + strlen(call-&gt;_name) - 5, &quot;_fill&quot;)) {
 503         if (!verify_helper(n-&gt;in(TypeFunc::Parms), phis, visited, ShenandoahStore, trace, barriers_used)) {
 504           report_verify_failure(&quot;Shenandoah verification: _fill should have barriers&quot;, n);
 505         }
 506       } else if (!strcmp(call-&gt;_name, &quot;shenandoah_wb_pre&quot;)) {
 507         // skip
 508       } else {
 509         const int calls_len = sizeof(calls) / sizeof(calls[0]);
 510         int i = 0;
 511         for (; i &lt; calls_len; i++) {
 512           if (!strcmp(calls[i].name, call-&gt;_name)) {
 513             break;
 514           }
 515         }
 516         if (i != calls_len) {
 517           const uint args_len = sizeof(calls[0].args) / sizeof(calls[0].args[0]);
 518           for (uint j = 0; j &lt; args_len; j++) {
 519             int pos = calls[i].args[j].pos;
 520             if (pos == -1) {
 521               break;
 522             }
 523             if (!verify_helper(call-&gt;in(pos), phis, visited, calls[i].args[j].t, trace, barriers_used)) {
 524               report_verify_failure(&quot;Shenandoah verification: intrinsic calls should have barriers&quot;, n);
 525             }
 526           }
 527           for (uint j = TypeFunc::Parms; j &lt; call-&gt;req(); j++) {
 528             if (call-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr() &amp;&amp;
 529                 call-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr()-&gt;isa_oopptr()) {
 530               uint k = 0;
 531               for (; k &lt; args_len &amp;&amp; calls[i].args[k].pos != (int)j; k++);
 532               if (k == args_len) {
 533                 fatal(&quot;arg %d for call %s not covered&quot;, j, call-&gt;_name);
 534               }
 535             }
 536           }
 537         } else {
 538           for (uint j = TypeFunc::Parms; j &lt; call-&gt;req(); j++) {
 539             if (call-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr() &amp;&amp;
 540                 call-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr()-&gt;isa_oopptr()) {
 541               fatal(&quot;%s not covered&quot;, call-&gt;_name);
 542             }
 543           }
 544         }
 545       }
 546     } else if (n-&gt;Opcode() == Op_ShenandoahEnqueueBarrier || n-&gt;Opcode() == Op_ShenandoahLoadReferenceBarrier) {
 547       // skip
 548     } else if (n-&gt;is_AddP()
 549                || n-&gt;is_Phi()
 550                || n-&gt;is_ConstraintCast()
 551                || n-&gt;Opcode() == Op_Return
 552                || n-&gt;Opcode() == Op_CMoveP
 553                || n-&gt;Opcode() == Op_CMoveN
 554                || n-&gt;Opcode() == Op_Rethrow
 555                || n-&gt;is_MemBar()
 556                || n-&gt;Opcode() == Op_Conv2B
 557                || n-&gt;Opcode() == Op_SafePoint
 558                || n-&gt;is_CallJava()
 559                || n-&gt;Opcode() == Op_Unlock
 560                || n-&gt;Opcode() == Op_EncodeP
 561                || n-&gt;Opcode() == Op_DecodeN) {
 562       // nothing to do
 563     } else {
 564       static struct {
 565         int opcode;
 566         struct {
 567           int pos;
 568           verify_type t;
 569         } inputs[2];
 570       } others[] = {
 571         Op_FastLock,
 572         { { 1, ShenandoahLoad },                  { -1, ShenandoahNone} },
 573         Op_Lock,
 574         { { TypeFunc::Parms, ShenandoahLoad },    { -1, ShenandoahNone} },
 575         Op_ArrayCopy,
 576         { { ArrayCopyNode::Src, ShenandoahLoad }, { ArrayCopyNode::Dest, ShenandoahStore } },
 577         Op_StrCompressedCopy,
 578         { { 2, ShenandoahLoad },                  { 3, ShenandoahStore } },
 579         Op_StrInflatedCopy,
 580         { { 2, ShenandoahLoad },                  { 3, ShenandoahStore } },
 581         Op_AryEq,
 582         { { 2, ShenandoahLoad },                  { 3, ShenandoahLoad } },
 583         Op_StrIndexOf,
 584         { { 2, ShenandoahLoad },                  { 4, ShenandoahLoad } },
 585         Op_StrComp,
 586         { { 2, ShenandoahLoad },                  { 4, ShenandoahLoad } },
 587         Op_StrEquals,
 588         { { 2, ShenandoahLoad },                  { 3, ShenandoahLoad } },
 589         Op_EncodeISOArray,
 590         { { 2, ShenandoahLoad },                  { 3, ShenandoahStore } },
 591         Op_HasNegatives,
 592         { { 2, ShenandoahLoad },                  { -1, ShenandoahNone} },
 593         Op_CastP2X,
 594         { { 1, ShenandoahLoad },                  { -1, ShenandoahNone} },
 595         Op_StrIndexOfChar,
 596         { { 2, ShenandoahLoad },                  { -1, ShenandoahNone } },
 597       };
 598 
 599       const int others_len = sizeof(others) / sizeof(others[0]);
 600       int i = 0;
 601       for (; i &lt; others_len; i++) {
 602         if (others[i].opcode == n-&gt;Opcode()) {
 603           break;
 604         }
 605       }
 606       uint stop = n-&gt;is_Call() ? n-&gt;as_Call()-&gt;tf()-&gt;domain()-&gt;cnt() : n-&gt;req();
 607       if (i != others_len) {
 608         const uint inputs_len = sizeof(others[0].inputs) / sizeof(others[0].inputs[0]);
 609         for (uint j = 0; j &lt; inputs_len; j++) {
 610           int pos = others[i].inputs[j].pos;
 611           if (pos == -1) {
 612             break;
 613           }
 614           if (!verify_helper(n-&gt;in(pos), phis, visited, others[i].inputs[j].t, trace, barriers_used)) {
 615             report_verify_failure(&quot;Shenandoah verification: intrinsic calls should have barriers&quot;, n);
 616           }
 617         }
 618         for (uint j = 1; j &lt; stop; j++) {
 619           if (n-&gt;in(j) != NULL &amp;&amp; n-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr() &amp;&amp;
 620               n-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr()-&gt;make_oopptr()) {
 621             uint k = 0;
 622             for (; k &lt; inputs_len &amp;&amp; others[i].inputs[k].pos != (int)j; k++);
 623             if (k == inputs_len) {
 624               fatal(&quot;arg %d for node %s not covered&quot;, j, n-&gt;Name());
 625             }
 626           }
 627         }
 628       } else {
 629         for (uint j = 1; j &lt; stop; j++) {
 630           if (n-&gt;in(j) != NULL &amp;&amp; n-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr() &amp;&amp;
 631               n-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr()-&gt;make_oopptr()) {
 632             fatal(&quot;%s not covered&quot;, n-&gt;Name());
 633           }
 634         }
 635       }
 636     }
 637 
 638     if (n-&gt;is_SafePoint()) {
 639       SafePointNode* sfpt = n-&gt;as_SafePoint();
 640       if (verify_no_useless_barrier &amp;&amp; sfpt-&gt;jvms() != NULL) {
 641         for (uint i = sfpt-&gt;jvms()-&gt;scloff(); i &lt; sfpt-&gt;jvms()-&gt;endoff(); i++) {
 642           if (!verify_helper(sfpt-&gt;in(i), phis, visited, ShenandoahLoad, trace, barriers_used)) {
 643             phis.clear();
 644             visited.reset();
 645           }
 646         }
 647       }
 648     }
 649   }
 650 
 651   if (verify_no_useless_barrier) {
 652     for (int i = 0; i &lt; barriers.length(); i++) {
 653       Node* n = barriers.at(i);
 654       if (!barriers_used.member(n)) {
 655         tty-&gt;print(&quot;XXX useless barrier&quot;); n-&gt;dump(-2);
 656         ShouldNotReachHere();
 657       }
 658     }
 659   }
 660 }
 661 #endif
 662 
 663 bool ShenandoahBarrierC2Support::is_dominator_same_ctrl(Node* c, Node* d, Node* n, PhaseIdealLoop* phase) {
 664   // That both nodes have the same control is not sufficient to prove
 665   // domination, verify that there&#39;s no path from d to n
 666   ResourceMark rm;
 667   Unique_Node_List wq;
 668   wq.push(d);
 669   for (uint next = 0; next &lt; wq.size(); next++) {
 670     Node *m = wq.at(next);
 671     if (m == n) {
 672       return false;
 673     }
 674     if (m-&gt;is_Phi() &amp;&amp; m-&gt;in(0)-&gt;is_Loop()) {
 675       assert(phase-&gt;ctrl_or_self(m-&gt;in(LoopNode::EntryControl)) != c, &quot;following loop entry should lead to new control&quot;);
 676     } else {
 677       if (m-&gt;is_Store() || m-&gt;is_LoadStore()) {
 678         // Take anti-dependencies into account
 679         Node* mem = m-&gt;in(MemNode::Memory);
 680         for (DUIterator_Fast imax, i = mem-&gt;fast_outs(imax); i &lt; imax; i++) {
 681           Node* u = mem-&gt;fast_out(i);
 682           if (u-&gt;is_Load() &amp;&amp; phase-&gt;C-&gt;can_alias(m-&gt;adr_type(), phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type())) &amp;&amp;
 683               phase-&gt;ctrl_or_self(u) == c) {
 684             wq.push(u);
 685           }
 686         }
 687       }
 688       for (uint i = 0; i &lt; m-&gt;req(); i++) {
 689         if (m-&gt;in(i) != NULL &amp;&amp; phase-&gt;ctrl_or_self(m-&gt;in(i)) == c) {
 690           wq.push(m-&gt;in(i));
 691         }
 692       }
 693     }
 694   }
 695   return true;
 696 }
 697 
 698 bool ShenandoahBarrierC2Support::is_dominator(Node* d_c, Node* n_c, Node* d, Node* n, PhaseIdealLoop* phase) {
 699   if (d_c != n_c) {
 700     return phase-&gt;is_dominator(d_c, n_c);
 701   }
 702   return is_dominator_same_ctrl(d_c, d, n, phase);
 703 }
 704 
 705 Node* next_mem(Node* mem, int alias) {
 706   Node* res = NULL;
 707   if (mem-&gt;is_Proj()) {
 708     res = mem-&gt;in(0);
 709   } else if (mem-&gt;is_SafePoint() || mem-&gt;is_MemBar()) {
 710     res = mem-&gt;in(TypeFunc::Memory);
 711   } else if (mem-&gt;is_Phi()) {
 712     res = mem-&gt;in(1);
 713   } else if (mem-&gt;is_MergeMem()) {
 714     res = mem-&gt;as_MergeMem()-&gt;memory_at(alias);
 715   } else if (mem-&gt;is_Store() || mem-&gt;is_LoadStore() || mem-&gt;is_ClearArray()) {
 716     assert(alias = Compile::AliasIdxRaw, &quot;following raw memory can&#39;t lead to a barrier&quot;);
 717     res = mem-&gt;in(MemNode::Memory);
 718   } else {
 719 #ifdef ASSERT
 720     mem-&gt;dump();
 721 #endif
 722     ShouldNotReachHere();
 723   }
 724   return res;
 725 }
 726 
 727 Node* ShenandoahBarrierC2Support::no_branches(Node* c, Node* dom, bool allow_one_proj, PhaseIdealLoop* phase) {
 728   Node* iffproj = NULL;
 729   while (c != dom) {
 730     Node* next = phase-&gt;idom(c);
 731     assert(next-&gt;unique_ctrl_out() == c || c-&gt;is_Proj() || c-&gt;is_Region(), &quot;multiple control flow out but no proj or region?&quot;);
 732     if (c-&gt;is_Region()) {
 733       ResourceMark rm;
 734       Unique_Node_List wq;
 735       wq.push(c);
 736       for (uint i = 0; i &lt; wq.size(); i++) {
 737         Node *n = wq.at(i);
 738         if (n == next) {
 739           continue;
 740         }
 741         if (n-&gt;is_Region()) {
 742           for (uint j = 1; j &lt; n-&gt;req(); j++) {
 743             wq.push(n-&gt;in(j));
 744           }
 745         } else {
 746           wq.push(n-&gt;in(0));
 747         }
 748       }
 749       for (uint i = 0; i &lt; wq.size(); i++) {
 750         Node *n = wq.at(i);
 751         assert(n-&gt;is_CFG(), &quot;&quot;);
 752         if (n-&gt;is_Multi()) {
 753           for (DUIterator_Fast jmax, j = n-&gt;fast_outs(jmax); j &lt; jmax; j++) {
 754             Node* u = n-&gt;fast_out(j);
 755             if (u-&gt;is_CFG()) {
 756               if (!wq.member(u) &amp;&amp; !u-&gt;as_Proj()-&gt;is_uncommon_trap_proj(Deoptimization::Reason_none)) {
 757                 return NodeSentinel;
 758               }
 759             }
 760           }
 761         }
 762       }
 763     } else  if (c-&gt;is_Proj()) {
 764       if (c-&gt;is_IfProj()) {
 765         if (c-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none) != NULL) {
 766           // continue;
 767         } else {
 768           if (!allow_one_proj) {
 769             return NodeSentinel;
 770           }
 771           if (iffproj == NULL) {
 772             iffproj = c;
 773           } else {
 774             return NodeSentinel;
 775           }
 776         }
 777       } else if (c-&gt;Opcode() == Op_JumpProj) {
 778         return NodeSentinel; // unsupported
 779       } else if (c-&gt;Opcode() == Op_CatchProj) {
 780         return NodeSentinel; // unsupported
 781       } else if (c-&gt;Opcode() == Op_CProj &amp;&amp; next-&gt;Opcode() == Op_NeverBranch) {
 782         return NodeSentinel; // unsupported
 783       } else {
 784         assert(next-&gt;unique_ctrl_out() == c, &quot;unsupported branch pattern&quot;);
 785       }
 786     }
 787     c = next;
 788   }
 789   return iffproj;
 790 }
 791 
 792 Node* ShenandoahBarrierC2Support::dom_mem(Node* mem, Node* ctrl, int alias, Node*&amp; mem_ctrl, PhaseIdealLoop* phase) {
 793   ResourceMark rm;
 794   VectorSet wq(Thread::current()-&gt;resource_area());
 795   wq.set(mem-&gt;_idx);
 796   mem_ctrl = phase-&gt;ctrl_or_self(mem);
 797   while (!phase-&gt;is_dominator(mem_ctrl, ctrl) || mem_ctrl == ctrl) {
 798     mem = next_mem(mem, alias);
 799     if (wq.test_set(mem-&gt;_idx)) {
 800       return NULL;
 801     }
 802     mem_ctrl = phase-&gt;ctrl_or_self(mem);
 803   }
 804   if (mem-&gt;is_MergeMem()) {
 805     mem = mem-&gt;as_MergeMem()-&gt;memory_at(alias);
 806     mem_ctrl = phase-&gt;ctrl_or_self(mem);
 807   }
 808   return mem;
 809 }
 810 
 811 Node* ShenandoahBarrierC2Support::find_bottom_mem(Node* ctrl, PhaseIdealLoop* phase) {
 812   Node* mem = NULL;
 813   Node* c = ctrl;
 814   do {
 815     if (c-&gt;is_Region()) {
 816       Node* phi_bottom = NULL;
 817       for (DUIterator_Fast imax, i = c-&gt;fast_outs(imax); i &lt; imax &amp;&amp; mem == NULL; i++) {
 818         Node* u = c-&gt;fast_out(i);
 819         if (u-&gt;is_Phi() &amp;&amp; u-&gt;bottom_type() == Type::MEMORY) {
 820           if (u-&gt;adr_type() == TypePtr::BOTTOM) {
 821             mem = u;
 822           }
 823         }
 824       }
 825     } else {
 826       if (c-&gt;is_Call() &amp;&amp; c-&gt;as_Call()-&gt;adr_type() != NULL) {
 827         CallProjections projs;
 828         c-&gt;as_Call()-&gt;extract_projections(&amp;projs, true, false);
 829         if (projs.fallthrough_memproj != NULL) {
 830           if (projs.fallthrough_memproj-&gt;adr_type() == TypePtr::BOTTOM) {
 831             if (projs.catchall_memproj == NULL) {
 832               mem = projs.fallthrough_memproj;
 833             } else {
 834               if (phase-&gt;is_dominator(projs.fallthrough_catchproj, ctrl)) {
 835                 mem = projs.fallthrough_memproj;
 836               } else {
 837                 assert(phase-&gt;is_dominator(projs.catchall_catchproj, ctrl), &quot;one proj must dominate barrier&quot;);
 838                 mem = projs.catchall_memproj;
 839               }
 840             }
 841           }
 842         } else {
 843           Node* proj = c-&gt;as_Call()-&gt;proj_out(TypeFunc::Memory);
 844           if (proj != NULL &amp;&amp;
 845               proj-&gt;adr_type() == TypePtr::BOTTOM) {
 846             mem = proj;
 847           }
 848         }
 849       } else {
 850         for (DUIterator_Fast imax, i = c-&gt;fast_outs(imax); i &lt; imax; i++) {
 851           Node* u = c-&gt;fast_out(i);
 852           if (u-&gt;is_Proj() &amp;&amp;
 853               u-&gt;bottom_type() == Type::MEMORY &amp;&amp;
 854               u-&gt;adr_type() == TypePtr::BOTTOM) {
 855               assert(c-&gt;is_SafePoint() || c-&gt;is_MemBar() || c-&gt;is_Start(), &quot;&quot;);
 856               assert(mem == NULL, &quot;only one proj&quot;);
 857               mem = u;
 858           }
 859         }
 860         assert(!c-&gt;is_Call() || c-&gt;as_Call()-&gt;adr_type() != NULL || mem == NULL, &quot;no mem projection expected&quot;);
 861       }
 862     }
 863     c = phase-&gt;idom(c);
 864   } while (mem == NULL);
 865   return mem;
 866 }
 867 
 868 void ShenandoahBarrierC2Support::follow_barrier_uses(Node* n, Node* ctrl, Unique_Node_List&amp; uses, PhaseIdealLoop* phase) {
 869   for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
 870     Node* u = n-&gt;fast_out(i);
 871     if (!u-&gt;is_CFG() &amp;&amp; phase-&gt;get_ctrl(u) == ctrl &amp;&amp; (!u-&gt;is_Phi() || !u-&gt;in(0)-&gt;is_Loop() || u-&gt;in(LoopNode::LoopBackControl) != n)) {
 872       uses.push(u);
 873     }
 874   }
 875 }
 876 
 877 static void hide_strip_mined_loop(OuterStripMinedLoopNode* outer, CountedLoopNode* inner, PhaseIdealLoop* phase) {
 878   OuterStripMinedLoopEndNode* le = inner-&gt;outer_loop_end();
 879   Node* new_outer = new LoopNode(outer-&gt;in(LoopNode::EntryControl), outer-&gt;in(LoopNode::LoopBackControl));
 880   phase-&gt;register_control(new_outer, phase-&gt;get_loop(outer), outer-&gt;in(LoopNode::EntryControl));
 881   Node* new_le = new IfNode(le-&gt;in(0), le-&gt;in(1), le-&gt;_prob, le-&gt;_fcnt);
 882   phase-&gt;register_control(new_le, phase-&gt;get_loop(le), le-&gt;in(0));
 883   phase-&gt;lazy_replace(outer, new_outer);
 884   phase-&gt;lazy_replace(le, new_le);
 885   inner-&gt;clear_strip_mined();
 886 }
 887 
 888 void ShenandoahBarrierC2Support::test_heap_stable(Node*&amp; ctrl, Node* raw_mem, Node*&amp; heap_stable_ctrl,
 889                                                   PhaseIdealLoop* phase) {
 890   IdealLoopTree* loop = phase-&gt;get_loop(ctrl);
 891   Node* thread = new ThreadLocalNode();
 892   phase-&gt;register_new_node(thread, ctrl);
 893   Node* offset = phase-&gt;igvn().MakeConX(in_bytes(ShenandoahThreadLocalData::gc_state_offset()));
 894   phase-&gt;set_ctrl(offset, phase-&gt;C-&gt;root());
 895   Node* gc_state_addr = new AddPNode(phase-&gt;C-&gt;top(), thread, offset);
 896   phase-&gt;register_new_node(gc_state_addr, ctrl);
 897   uint gc_state_idx = Compile::AliasIdxRaw;
 898   const TypePtr* gc_state_adr_type = NULL; // debug-mode-only argument
 899   debug_only(gc_state_adr_type = phase-&gt;C-&gt;get_adr_type(gc_state_idx));
 900 
 901   Node* gc_state = new LoadBNode(ctrl, raw_mem, gc_state_addr, gc_state_adr_type, TypeInt::BYTE, MemNode::unordered);
 902   phase-&gt;register_new_node(gc_state, ctrl);
 903   Node* heap_stable_and = new AndINode(gc_state, phase-&gt;igvn().intcon(ShenandoahHeap::HAS_FORWARDED));
 904   phase-&gt;register_new_node(heap_stable_and, ctrl);
 905   Node* heap_stable_cmp = new CmpINode(heap_stable_and, phase-&gt;igvn().zerocon(T_INT));
 906   phase-&gt;register_new_node(heap_stable_cmp, ctrl);
 907   Node* heap_stable_test = new BoolNode(heap_stable_cmp, BoolTest::ne);
 908   phase-&gt;register_new_node(heap_stable_test, ctrl);
 909   IfNode* heap_stable_iff = new IfNode(ctrl, heap_stable_test, PROB_UNLIKELY(0.999), COUNT_UNKNOWN);
 910   phase-&gt;register_control(heap_stable_iff, loop, ctrl);
 911 
 912   heap_stable_ctrl = new IfFalseNode(heap_stable_iff);
 913   phase-&gt;register_control(heap_stable_ctrl, loop, heap_stable_iff);
 914   ctrl = new IfTrueNode(heap_stable_iff);
 915   phase-&gt;register_control(ctrl, loop, heap_stable_iff);
 916 
 917   assert(is_heap_stable_test(heap_stable_iff), &quot;Should match the shape&quot;);
 918 }
 919 
 920 void ShenandoahBarrierC2Support::test_null(Node*&amp; ctrl, Node* val, Node*&amp; null_ctrl, PhaseIdealLoop* phase) {
 921   const Type* val_t = phase-&gt;igvn().type(val);
 922   if (val_t-&gt;meet(TypePtr::NULL_PTR) == val_t) {
 923     IdealLoopTree* loop = phase-&gt;get_loop(ctrl);
 924     Node* null_cmp = new CmpPNode(val, phase-&gt;igvn().zerocon(T_OBJECT));
 925     phase-&gt;register_new_node(null_cmp, ctrl);
 926     Node* null_test = new BoolNode(null_cmp, BoolTest::ne);
 927     phase-&gt;register_new_node(null_test, ctrl);
 928     IfNode* null_iff = new IfNode(ctrl, null_test, PROB_LIKELY(0.999), COUNT_UNKNOWN);
 929     phase-&gt;register_control(null_iff, loop, ctrl);
 930     ctrl = new IfTrueNode(null_iff);
 931     phase-&gt;register_control(ctrl, loop, null_iff);
 932     null_ctrl = new IfFalseNode(null_iff);
 933     phase-&gt;register_control(null_ctrl, loop, null_iff);
 934   }
 935 }
 936 
 937 Node* ShenandoahBarrierC2Support::clone_null_check(Node*&amp; c, Node* val, Node* unc_ctrl, PhaseIdealLoop* phase) {
 938   IdealLoopTree *loop = phase-&gt;get_loop(c);
 939   Node* iff = unc_ctrl-&gt;in(0);
 940   assert(iff-&gt;is_If(), &quot;broken&quot;);
 941   Node* new_iff = iff-&gt;clone();
 942   new_iff-&gt;set_req(0, c);
 943   phase-&gt;register_control(new_iff, loop, c);
 944   Node* iffalse = new IfFalseNode(new_iff-&gt;as_If());
 945   phase-&gt;register_control(iffalse, loop, new_iff);
 946   Node* iftrue = new IfTrueNode(new_iff-&gt;as_If());
 947   phase-&gt;register_control(iftrue, loop, new_iff);
 948   c = iftrue;
 949   const Type *t = phase-&gt;igvn().type(val);
 950   assert(val-&gt;Opcode() == Op_CastPP, &quot;expect cast to non null here&quot;);
 951   Node* uncasted_val = val-&gt;in(1);
 952   val = new CastPPNode(uncasted_val, t);
 953   val-&gt;init_req(0, c);
 954   phase-&gt;register_new_node(val, c);
 955   return val;
 956 }
 957 
 958 void ShenandoahBarrierC2Support::fix_null_check(Node* unc, Node* unc_ctrl, Node* new_unc_ctrl,
 959                                                 Unique_Node_List&amp; uses, PhaseIdealLoop* phase) {
 960   IfNode* iff = unc_ctrl-&gt;in(0)-&gt;as_If();
 961   Node* proj = iff-&gt;proj_out(0);
 962   assert(proj != unc_ctrl, &quot;bad projection&quot;);
 963   Node* use = proj-&gt;unique_ctrl_out();
 964 
 965   assert(use == unc || use-&gt;is_Region(), &quot;what else?&quot;);
 966 
 967   uses.clear();
 968   if (use == unc) {
 969     phase-&gt;set_idom(use, new_unc_ctrl, phase-&gt;dom_depth(use));
 970     for (uint i = 1; i &lt; unc-&gt;req(); i++) {
 971       Node* n = unc-&gt;in(i);
 972       if (phase-&gt;has_ctrl(n) &amp;&amp; phase-&gt;get_ctrl(n) == proj) {
 973         uses.push(n);
 974       }
 975     }
 976   } else {
 977     assert(use-&gt;is_Region(), &quot;what else?&quot;);
 978     uint idx = 1;
 979     for (; use-&gt;in(idx) != proj; idx++);
 980     for (DUIterator_Fast imax, i = use-&gt;fast_outs(imax); i &lt; imax; i++) {
 981       Node* u = use-&gt;fast_out(i);
 982       if (u-&gt;is_Phi() &amp;&amp; phase-&gt;get_ctrl(u-&gt;in(idx)) == proj) {
 983         uses.push(u-&gt;in(idx));
 984       }
 985     }
 986   }
 987   for(uint next = 0; next &lt; uses.size(); next++ ) {
 988     Node *n = uses.at(next);
 989     assert(phase-&gt;get_ctrl(n) == proj, &quot;bad control&quot;);
 990     phase-&gt;set_ctrl_and_loop(n, new_unc_ctrl);
 991     if (n-&gt;in(0) == proj) {
 992       phase-&gt;igvn().replace_input_of(n, 0, new_unc_ctrl);
 993     }
 994     for (uint i = 0; i &lt; n-&gt;req(); i++) {
 995       Node* m = n-&gt;in(i);
 996       if (m != NULL &amp;&amp; phase-&gt;has_ctrl(m) &amp;&amp; phase-&gt;get_ctrl(m) == proj) {
 997         uses.push(m);
 998       }
 999     }
1000   }
1001 
1002   phase-&gt;igvn().rehash_node_delayed(use);
1003   int nb = use-&gt;replace_edge(proj, new_unc_ctrl);
1004   assert(nb == 1, &quot;only use expected&quot;);
1005 }
1006 
1007 void ShenandoahBarrierC2Support::in_cset_fast_test(Node*&amp; ctrl, Node*&amp; not_cset_ctrl, Node* val, Node* raw_mem, PhaseIdealLoop* phase) {
1008   IdealLoopTree *loop = phase-&gt;get_loop(ctrl);
1009   Node* raw_rbtrue = new CastP2XNode(ctrl, val);
1010   phase-&gt;register_new_node(raw_rbtrue, ctrl);
1011   Node* cset_offset = new URShiftXNode(raw_rbtrue, phase-&gt;igvn().intcon(ShenandoahHeapRegion::region_size_bytes_shift_jint()));
1012   phase-&gt;register_new_node(cset_offset, ctrl);
1013   Node* in_cset_fast_test_base_addr = phase-&gt;igvn().makecon(TypeRawPtr::make(ShenandoahHeap::in_cset_fast_test_addr()));
1014   phase-&gt;set_ctrl(in_cset_fast_test_base_addr, phase-&gt;C-&gt;root());
1015   Node* in_cset_fast_test_adr = new AddPNode(phase-&gt;C-&gt;top(), in_cset_fast_test_base_addr, cset_offset);
1016   phase-&gt;register_new_node(in_cset_fast_test_adr, ctrl);
1017   uint in_cset_fast_test_idx = Compile::AliasIdxRaw;
1018   const TypePtr* in_cset_fast_test_adr_type = NULL; // debug-mode-only argument
1019   debug_only(in_cset_fast_test_adr_type = phase-&gt;C-&gt;get_adr_type(in_cset_fast_test_idx));
1020   Node* in_cset_fast_test_load = new LoadBNode(ctrl, raw_mem, in_cset_fast_test_adr, in_cset_fast_test_adr_type, TypeInt::BYTE, MemNode::unordered);
1021   phase-&gt;register_new_node(in_cset_fast_test_load, ctrl);
1022   Node* in_cset_fast_test_cmp = new CmpINode(in_cset_fast_test_load, phase-&gt;igvn().zerocon(T_INT));
1023   phase-&gt;register_new_node(in_cset_fast_test_cmp, ctrl);
1024   Node* in_cset_fast_test_test = new BoolNode(in_cset_fast_test_cmp, BoolTest::eq);
1025   phase-&gt;register_new_node(in_cset_fast_test_test, ctrl);
1026   IfNode* in_cset_fast_test_iff = new IfNode(ctrl, in_cset_fast_test_test, PROB_UNLIKELY(0.999), COUNT_UNKNOWN);
1027   phase-&gt;register_control(in_cset_fast_test_iff, loop, ctrl);
1028 
1029   not_cset_ctrl = new IfTrueNode(in_cset_fast_test_iff);
1030   phase-&gt;register_control(not_cset_ctrl, loop, in_cset_fast_test_iff);
1031 
1032   ctrl = new IfFalseNode(in_cset_fast_test_iff);
1033   phase-&gt;register_control(ctrl, loop, in_cset_fast_test_iff);
1034 }
1035 
1036 void ShenandoahBarrierC2Support::call_lrb_stub(Node*&amp; ctrl, Node*&amp; val, Node* load_addr, Node*&amp; result_mem, Node* raw_mem, bool is_native, PhaseIdealLoop* phase) {
1037   IdealLoopTree*loop = phase-&gt;get_loop(ctrl);
1038   const TypePtr* obj_type = phase-&gt;igvn().type(val)-&gt;is_oopptr();
1039 
1040   // The slow path stub consumes and produces raw memory in addition
1041   // to the existing memory edges
1042   Node* base = find_bottom_mem(ctrl, phase);
1043   MergeMemNode* mm = MergeMemNode::make(base);
1044   mm-&gt;set_memory_at(Compile::AliasIdxRaw, raw_mem);
1045   phase-&gt;register_new_node(mm, ctrl);
1046 
1047   address target = LP64_ONLY(UseCompressedOops) NOT_LP64(false) ?
1048           CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier_narrow) :
1049           CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier);
1050 
1051   address calladdr = is_native ? CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier_native)
1052                                : target;
1053   const char* name = is_native ? &quot;load_reference_barrier_native&quot; : &quot;load_reference_barrier&quot;;
1054   Node* call = new CallLeafNode(ShenandoahBarrierSetC2::shenandoah_load_reference_barrier_Type(), calladdr, name, TypeRawPtr::BOTTOM);
1055 
1056   call-&gt;init_req(TypeFunc::Control, ctrl);
1057   call-&gt;init_req(TypeFunc::I_O, phase-&gt;C-&gt;top());
1058   call-&gt;init_req(TypeFunc::Memory, mm);
1059   call-&gt;init_req(TypeFunc::FramePtr, phase-&gt;C-&gt;top());
1060   call-&gt;init_req(TypeFunc::ReturnAdr, phase-&gt;C-&gt;top());
1061   call-&gt;init_req(TypeFunc::Parms, val);
1062   call-&gt;init_req(TypeFunc::Parms+1, load_addr);
1063   phase-&gt;register_control(call, loop, ctrl);
1064   ctrl = new ProjNode(call, TypeFunc::Control);
1065   phase-&gt;register_control(ctrl, loop, call);
1066   result_mem = new ProjNode(call, TypeFunc::Memory);
1067   phase-&gt;register_new_node(result_mem, call);
1068   val = new ProjNode(call, TypeFunc::Parms);
1069   phase-&gt;register_new_node(val, call);
1070   val = new CheckCastPPNode(ctrl, val, obj_type);
1071   phase-&gt;register_new_node(val, ctrl);
1072 }
1073 
1074 void ShenandoahBarrierC2Support::fix_ctrl(Node* barrier, Node* region, const MemoryGraphFixer&amp; fixer, Unique_Node_List&amp; uses, Unique_Node_List&amp; uses_to_ignore, uint last, PhaseIdealLoop* phase) {
1075   Node* ctrl = phase-&gt;get_ctrl(barrier);
1076   Node* init_raw_mem = fixer.find_mem(ctrl, barrier);
1077 
1078   // Update the control of all nodes that should be after the
1079   // barrier control flow
1080   uses.clear();
1081   // Every node that is control dependent on the barrier&#39;s input
1082   // control will be after the expanded barrier. The raw memory (if
1083   // its memory is control dependent on the barrier&#39;s input control)
1084   // must stay above the barrier.
1085   uses_to_ignore.clear();
1086   if (phase-&gt;has_ctrl(init_raw_mem) &amp;&amp; phase-&gt;get_ctrl(init_raw_mem) == ctrl &amp;&amp; !init_raw_mem-&gt;is_Phi()) {
1087     uses_to_ignore.push(init_raw_mem);
1088   }
1089   for (uint next = 0; next &lt; uses_to_ignore.size(); next++) {
1090     Node *n = uses_to_ignore.at(next);
1091     for (uint i = 0; i &lt; n-&gt;req(); i++) {
1092       Node* in = n-&gt;in(i);
1093       if (in != NULL &amp;&amp; phase-&gt;has_ctrl(in) &amp;&amp; phase-&gt;get_ctrl(in) == ctrl) {
1094         uses_to_ignore.push(in);
1095       }
1096     }
1097   }
1098   for (DUIterator_Fast imax, i = ctrl-&gt;fast_outs(imax); i &lt; imax; i++) {
1099     Node* u = ctrl-&gt;fast_out(i);
1100     if (u-&gt;_idx &lt; last &amp;&amp;
1101         u != barrier &amp;&amp;
1102         !uses_to_ignore.member(u) &amp;&amp;
1103         (u-&gt;in(0) != ctrl || (!u-&gt;is_Region() &amp;&amp; !u-&gt;is_Phi())) &amp;&amp;
1104         (ctrl-&gt;Opcode() != Op_CatchProj || u-&gt;Opcode() != Op_CreateEx)) {
1105       Node* old_c = phase-&gt;ctrl_or_self(u);
1106       Node* c = old_c;
1107       if (c != ctrl ||
1108           is_dominator_same_ctrl(old_c, barrier, u, phase) ||
1109           ShenandoahBarrierSetC2::is_shenandoah_state_load(u)) {
1110         phase-&gt;igvn().rehash_node_delayed(u);
1111         int nb = u-&gt;replace_edge(ctrl, region);
1112         if (u-&gt;is_CFG()) {
1113           if (phase-&gt;idom(u) == ctrl) {
1114             phase-&gt;set_idom(u, region, phase-&gt;dom_depth(region));
1115           }
1116         } else if (phase-&gt;get_ctrl(u) == ctrl) {
1117           assert(u != init_raw_mem, &quot;should leave input raw mem above the barrier&quot;);
1118           uses.push(u);
1119         }
1120         assert(nb == 1, &quot;more than 1 ctrl input?&quot;);
1121         --i, imax -= nb;
1122       }
1123     }
1124   }
1125 }
1126 
1127 static Node* create_phis_on_call_return(Node* ctrl, Node* c, Node* n, Node* n_clone, const CallProjections&amp; projs, PhaseIdealLoop* phase) {
1128   Node* region = NULL;
1129   while (c != ctrl) {
1130     if (c-&gt;is_Region()) {
1131       region = c;
1132     }
1133     c = phase-&gt;idom(c);
1134   }
1135   assert(region != NULL, &quot;&quot;);
1136   Node* phi = new PhiNode(region, n-&gt;bottom_type());
1137   for (uint j = 1; j &lt; region-&gt;req(); j++) {
1138     Node* in = region-&gt;in(j);
1139     if (phase-&gt;is_dominator(projs.fallthrough_catchproj, in)) {
1140       phi-&gt;init_req(j, n);
1141     } else if (phase-&gt;is_dominator(projs.catchall_catchproj, in)) {
1142       phi-&gt;init_req(j, n_clone);
1143     } else {
1144       phi-&gt;init_req(j, create_phis_on_call_return(ctrl, in, n, n_clone, projs, phase));
1145     }
1146   }
1147   phase-&gt;register_new_node(phi, region);
1148   return phi;
1149 }
1150 
1151 void ShenandoahBarrierC2Support::pin_and_expand(PhaseIdealLoop* phase) {
1152   ShenandoahBarrierSetC2State* state = ShenandoahBarrierSetC2::bsc2()-&gt;state();
1153 
1154   Unique_Node_List uses;
1155   for (int i = 0; i &lt; state-&gt;enqueue_barriers_count(); i++) {
1156     Node* barrier = state-&gt;enqueue_barrier(i);
1157     Node* ctrl = phase-&gt;get_ctrl(barrier);
1158     IdealLoopTree* loop = phase-&gt;get_loop(ctrl);
1159     if (loop-&gt;_head-&gt;is_OuterStripMinedLoop()) {
1160       // Expanding a barrier here will break loop strip mining
1161       // verification. Transform the loop so the loop nest doesn&#39;t
1162       // appear as strip mined.
1163       OuterStripMinedLoopNode* outer = loop-&gt;_head-&gt;as_OuterStripMinedLoop();
1164       hide_strip_mined_loop(outer, outer-&gt;unique_ctrl_out()-&gt;as_CountedLoop(), phase);
1165     }
1166   }
1167 
1168   Node_Stack stack(0);
1169   Node_List clones;
1170   for (int i = state-&gt;load_reference_barriers_count() - 1; i &gt;= 0; i--) {
1171     ShenandoahLoadReferenceBarrierNode* lrb = state-&gt;load_reference_barrier(i);
1172     if (lrb-&gt;get_barrier_strength() == ShenandoahLoadReferenceBarrierNode::NONE) {
1173       continue;
1174     }
1175 
1176     Node* ctrl = phase-&gt;get_ctrl(lrb);
1177     Node* val = lrb-&gt;in(ShenandoahLoadReferenceBarrierNode::ValueIn);
1178 
1179     CallStaticJavaNode* unc = NULL;
1180     Node* unc_ctrl = NULL;
1181     Node* uncasted_val = val;
1182 
1183     for (DUIterator_Fast imax, i = lrb-&gt;fast_outs(imax); i &lt; imax; i++) {
1184       Node* u = lrb-&gt;fast_out(i);
1185       if (u-&gt;Opcode() == Op_CastPP &amp;&amp;
1186           u-&gt;in(0) != NULL &amp;&amp;
1187           phase-&gt;is_dominator(u-&gt;in(0), ctrl)) {
1188         const Type* u_t = phase-&gt;igvn().type(u);
1189 
1190         if (u_t-&gt;meet(TypePtr::NULL_PTR) != u_t &amp;&amp;
1191             u-&gt;in(0)-&gt;Opcode() == Op_IfTrue &amp;&amp;
1192             u-&gt;in(0)-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none) &amp;&amp;
1193             u-&gt;in(0)-&gt;in(0)-&gt;is_If() &amp;&amp;
1194             u-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;Opcode() == Op_Bool &amp;&amp;
1195             u-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::ne &amp;&amp;
1196             u-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;Opcode() == Op_CmpP &amp;&amp;
1197             u-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;in(1) == val &amp;&amp;
1198             u-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;bottom_type() == TypePtr::NULL_PTR) {
1199           IdealLoopTree* loop = phase-&gt;get_loop(ctrl);
1200           IdealLoopTree* unc_loop = phase-&gt;get_loop(u-&gt;in(0));
1201 
1202           if (!unc_loop-&gt;is_member(loop)) {
1203             continue;
1204           }
1205 
1206           Node* branch = no_branches(ctrl, u-&gt;in(0), false, phase);
1207           assert(branch == NULL || branch == NodeSentinel, &quot;was not looking for a branch&quot;);
1208           if (branch == NodeSentinel) {
1209             continue;
1210           }
1211 
1212           phase-&gt;igvn().replace_input_of(u, 1, val);
1213           phase-&gt;igvn().replace_input_of(lrb, ShenandoahLoadReferenceBarrierNode::ValueIn, u);
1214           phase-&gt;set_ctrl(u, u-&gt;in(0));
1215           phase-&gt;set_ctrl(lrb, u-&gt;in(0));
1216           unc = u-&gt;in(0)-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none);
1217           unc_ctrl = u-&gt;in(0);
1218           val = u;
1219 
1220           for (DUIterator_Fast jmax, j = val-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1221             Node* u = val-&gt;fast_out(j);
1222             if (u == lrb) continue;
1223             phase-&gt;igvn().rehash_node_delayed(u);
1224             int nb = u-&gt;replace_edge(val, lrb);
1225             --j; jmax -= nb;
1226           }
1227 
1228           RegionNode* r = new RegionNode(3);
1229           IfNode* iff = unc_ctrl-&gt;in(0)-&gt;as_If();
1230 
1231           Node* ctrl_use = unc_ctrl-&gt;unique_ctrl_out();
1232           Node* unc_ctrl_clone = unc_ctrl-&gt;clone();
1233           phase-&gt;register_control(unc_ctrl_clone, loop, iff);
1234           Node* c = unc_ctrl_clone;
1235           Node* new_cast = clone_null_check(c, val, unc_ctrl_clone, phase);
1236           r-&gt;init_req(1, new_cast-&gt;in(0)-&gt;in(0)-&gt;as_If()-&gt;proj_out(0));
1237 
1238           phase-&gt;igvn().replace_input_of(unc_ctrl, 0, c-&gt;in(0));
1239           phase-&gt;set_idom(unc_ctrl, c-&gt;in(0), phase-&gt;dom_depth(unc_ctrl));
1240           phase-&gt;lazy_replace(c, unc_ctrl);
1241           c = NULL;;
1242           phase-&gt;igvn().replace_input_of(val, 0, unc_ctrl_clone);
1243           phase-&gt;set_ctrl(val, unc_ctrl_clone);
1244 
1245           IfNode* new_iff = new_cast-&gt;in(0)-&gt;in(0)-&gt;as_If();
1246           fix_null_check(unc, unc_ctrl_clone, r, uses, phase);
1247           Node* iff_proj = iff-&gt;proj_out(0);
1248           r-&gt;init_req(2, iff_proj);
1249           phase-&gt;register_control(r, phase-&gt;ltree_root(), iff);
1250 
1251           Node* new_bol = new_iff-&gt;in(1)-&gt;clone();
1252           Node* new_cmp = new_bol-&gt;in(1)-&gt;clone();
1253           assert(new_cmp-&gt;Opcode() == Op_CmpP, &quot;broken&quot;);
1254           assert(new_cmp-&gt;in(1) == val-&gt;in(1), &quot;broken&quot;);
1255           new_bol-&gt;set_req(1, new_cmp);
1256           new_cmp-&gt;set_req(1, lrb);
1257           phase-&gt;register_new_node(new_bol, new_iff-&gt;in(0));
1258           phase-&gt;register_new_node(new_cmp, new_iff-&gt;in(0));
1259           phase-&gt;igvn().replace_input_of(new_iff, 1, new_bol);
1260           phase-&gt;igvn().replace_input_of(new_cast, 1, lrb);
1261 
1262           for (DUIterator_Fast imax, i = lrb-&gt;fast_outs(imax); i &lt; imax; i++) {
1263             Node* u = lrb-&gt;fast_out(i);
1264             if (u == new_cast || u == new_cmp) {
1265               continue;
1266             }
1267             phase-&gt;igvn().rehash_node_delayed(u);
1268             int nb = u-&gt;replace_edge(lrb, new_cast);
1269             assert(nb &gt; 0, &quot;no update?&quot;);
1270             --i; imax -= nb;
1271           }
1272 
1273           for (DUIterator_Fast imax, i = val-&gt;fast_outs(imax); i &lt; imax; i++) {
1274             Node* u = val-&gt;fast_out(i);
1275             if (u == lrb) {
1276               continue;
1277             }
1278             phase-&gt;igvn().rehash_node_delayed(u);
1279             int nb = u-&gt;replace_edge(val, new_cast);
1280             assert(nb &gt; 0, &quot;no update?&quot;);
1281             --i; imax -= nb;
1282           }
1283 
1284           ctrl = unc_ctrl_clone;
1285           phase-&gt;set_ctrl_and_loop(lrb, ctrl);
1286           break;
1287         }
1288       }
1289     }
1290     if ((ctrl-&gt;is_Proj() &amp;&amp; ctrl-&gt;in(0)-&gt;is_CallJava()) || ctrl-&gt;is_CallJava()) {
1291       CallNode* call = ctrl-&gt;is_Proj() ? ctrl-&gt;in(0)-&gt;as_CallJava() : ctrl-&gt;as_CallJava();
1292       if (call-&gt;entry_point() == OptoRuntime::rethrow_stub()) {
1293         // The rethrow call may have too many projections to be
1294         // properly handled here. Given there&#39;s no reason for a
1295         // barrier to depend on the call, move it above the call
1296         stack.push(lrb, 0);
1297         do {
1298           Node* n = stack.node();
1299           uint idx = stack.index();
1300           if (idx &lt; n-&gt;req()) {
1301             Node* in = n-&gt;in(idx);
1302             stack.set_index(idx+1);
1303             if (in != NULL) {
1304               if (phase-&gt;has_ctrl(in)) {
1305                 if (phase-&gt;is_dominator(call, phase-&gt;get_ctrl(in))) {
1306 #ifdef ASSERT
1307                   for (uint i = 0; i &lt; stack.size(); i++) {
1308                     assert(stack.node_at(i) != in, &quot;node shouldn&#39;t have been seen yet&quot;);
1309                   }
1310 #endif
1311                   stack.push(in, 0);
1312                 }
1313               } else {
1314                 assert(phase-&gt;is_dominator(in, call-&gt;in(0)), &quot;no dependency on the call&quot;);
1315               }
1316             }
1317           } else {
1318             phase-&gt;set_ctrl(n, call-&gt;in(0));
1319             stack.pop();
1320           }
1321         } while(stack.size() &gt; 0);
1322         continue;
1323       }
1324       CallProjections projs;
1325       call-&gt;extract_projections(&amp;projs, false, false);
1326 
1327       Node* lrb_clone = lrb-&gt;clone();
1328       phase-&gt;register_new_node(lrb_clone, projs.catchall_catchproj);
1329       phase-&gt;set_ctrl(lrb, projs.fallthrough_catchproj);
1330 
1331       stack.push(lrb, 0);
1332       clones.push(lrb_clone);
1333 
1334       do {
1335         assert(stack.size() == clones.size(), &quot;&quot;);
1336         Node* n = stack.node();
1337 #ifdef ASSERT
1338         if (n-&gt;is_Load()) {
1339           Node* mem = n-&gt;in(MemNode::Memory);
1340           for (DUIterator_Fast jmax, j = mem-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1341             Node* u = mem-&gt;fast_out(j);
1342             assert(!u-&gt;is_Store() || !u-&gt;is_LoadStore() || phase-&gt;get_ctrl(u) != ctrl, &quot;anti dependent store?&quot;);
1343           }
1344         }
1345 #endif
1346         uint idx = stack.index();
1347         Node* n_clone = clones.at(clones.size()-1);
1348         if (idx &lt; n-&gt;outcnt()) {
1349           Node* u = n-&gt;raw_out(idx);
1350           Node* c = phase-&gt;ctrl_or_self(u);
1351           if (phase-&gt;is_dominator(call, c) &amp;&amp; phase-&gt;is_dominator(c, projs.fallthrough_proj)) {
1352             stack.set_index(idx+1);
1353             assert(!u-&gt;is_CFG(), &quot;&quot;);
1354             stack.push(u, 0);
1355             Node* u_clone = u-&gt;clone();
1356             int nb = u_clone-&gt;replace_edge(n, n_clone);
1357             assert(nb &gt; 0, &quot;should have replaced some uses&quot;);
1358             phase-&gt;register_new_node(u_clone, projs.catchall_catchproj);
1359             clones.push(u_clone);
1360             phase-&gt;set_ctrl(u, projs.fallthrough_catchproj);
1361           } else {
1362             bool replaced = false;
1363             if (u-&gt;is_Phi()) {
1364               for (uint k = 1; k &lt; u-&gt;req(); k++) {
1365                 if (u-&gt;in(k) == n) {
1366                   if (phase-&gt;is_dominator(projs.catchall_catchproj, u-&gt;in(0)-&gt;in(k))) {
1367                     phase-&gt;igvn().replace_input_of(u, k, n_clone);
1368                     replaced = true;
1369                   } else if (!phase-&gt;is_dominator(projs.fallthrough_catchproj, u-&gt;in(0)-&gt;in(k))) {
1370                     phase-&gt;igvn().replace_input_of(u, k, create_phis_on_call_return(ctrl, u-&gt;in(0)-&gt;in(k), n, n_clone, projs, phase));
1371                     replaced = true;
1372                   }
1373                 }
1374               }
1375             } else {
1376               if (phase-&gt;is_dominator(projs.catchall_catchproj, c)) {
1377                 phase-&gt;igvn().rehash_node_delayed(u);
1378                 int nb = u-&gt;replace_edge(n, n_clone);
1379                 assert(nb &gt; 0, &quot;should have replaced some uses&quot;);
1380                 replaced = true;
1381               } else if (!phase-&gt;is_dominator(projs.fallthrough_catchproj, c)) {
1382                 phase-&gt;igvn().rehash_node_delayed(u);
1383                 int nb = u-&gt;replace_edge(n, create_phis_on_call_return(ctrl, c, n, n_clone, projs, phase));
1384                 assert(nb &gt; 0, &quot;should have replaced some uses&quot;);
1385                 replaced = true;
1386               }
1387             }
1388             if (!replaced) {
1389               stack.set_index(idx+1);
1390             }
1391           }
1392         } else {
1393           stack.pop();
1394           clones.pop();
1395         }
1396       } while (stack.size() &gt; 0);
1397       assert(stack.size() == 0 &amp;&amp; clones.size() == 0, &quot;&quot;);
1398     }
1399   }
1400 
1401   for (int i = 0; i &lt; state-&gt;load_reference_barriers_count(); i++) {
1402     ShenandoahLoadReferenceBarrierNode* lrb = state-&gt;load_reference_barrier(i);
1403     if (lrb-&gt;get_barrier_strength() == ShenandoahLoadReferenceBarrierNode::NONE) {
1404       continue;
1405     }
1406     Node* ctrl = phase-&gt;get_ctrl(lrb);
1407     IdealLoopTree* loop = phase-&gt;get_loop(ctrl);
1408     if (loop-&gt;_head-&gt;is_OuterStripMinedLoop()) {
1409       // Expanding a barrier here will break loop strip mining
1410       // verification. Transform the loop so the loop nest doesn&#39;t
1411       // appear as strip mined.
1412       OuterStripMinedLoopNode* outer = loop-&gt;_head-&gt;as_OuterStripMinedLoop();
1413       hide_strip_mined_loop(outer, outer-&gt;unique_ctrl_out()-&gt;as_CountedLoop(), phase);
1414     }
1415   }
1416 
1417   // Expand load-reference-barriers
1418   MemoryGraphFixer fixer(Compile::AliasIdxRaw, true, phase);
1419   Unique_Node_List uses_to_ignore;
1420   for (int i = state-&gt;load_reference_barriers_count() - 1; i &gt;= 0; i--) {
1421     ShenandoahLoadReferenceBarrierNode* lrb = state-&gt;load_reference_barrier(i);
1422     if (lrb-&gt;get_barrier_strength() == ShenandoahLoadReferenceBarrierNode::NONE) {
1423       phase-&gt;igvn().replace_node(lrb, lrb-&gt;in(ShenandoahLoadReferenceBarrierNode::ValueIn));
1424       continue;
1425     }
1426     uint last = phase-&gt;C-&gt;unique();
1427     Node* ctrl = phase-&gt;get_ctrl(lrb);
1428     Node* val = lrb-&gt;in(ShenandoahLoadReferenceBarrierNode::ValueIn);
1429 
1430 
1431     Node* orig_ctrl = ctrl;
1432 
1433     Node* raw_mem = fixer.find_mem(ctrl, lrb);
1434     Node* init_raw_mem = raw_mem;
1435     Node* raw_mem_for_ctrl = fixer.find_mem(ctrl, NULL);
1436 
1437     IdealLoopTree *loop = phase-&gt;get_loop(ctrl);
1438     CallStaticJavaNode* unc = lrb-&gt;pin_and_expand_null_check(phase-&gt;igvn());
1439     Node* unc_ctrl = NULL;
1440     if (unc != NULL) {
1441       if (val-&gt;in(ShenandoahLoadReferenceBarrierNode::Control) != ctrl) {
1442         unc = NULL;
1443       } else {
1444         unc_ctrl = val-&gt;in(ShenandoahLoadReferenceBarrierNode::Control);
1445       }
1446     }
1447 
1448     Node* uncasted_val = val;
1449     if (unc != NULL) {
1450       uncasted_val = val-&gt;in(1);
1451     }
1452 
1453     Node* heap_stable_ctrl = NULL;
1454     Node* null_ctrl = NULL;
1455 
1456     assert(val-&gt;bottom_type()-&gt;make_oopptr(), &quot;need oop&quot;);
1457     assert(val-&gt;bottom_type()-&gt;make_oopptr()-&gt;const_oop() == NULL, &quot;expect non-constant&quot;);
1458 
1459     enum { _heap_stable = 1, _not_cset, _evac_path, _null_path, PATH_LIMIT };
1460     Node* region = new RegionNode(PATH_LIMIT);
1461     Node* val_phi = new PhiNode(region, uncasted_val-&gt;bottom_type()-&gt;is_oopptr());
1462     Node* raw_mem_phi = PhiNode::make(region, raw_mem, Type::MEMORY, TypeRawPtr::BOTTOM);
1463 
1464     // Stable path.
1465     test_heap_stable(ctrl, raw_mem, heap_stable_ctrl, phase);
1466     IfNode* heap_stable_iff = heap_stable_ctrl-&gt;in(0)-&gt;as_If();
1467 
1468     // Heap stable case
1469     region-&gt;init_req(_heap_stable, heap_stable_ctrl);
1470     val_phi-&gt;init_req(_heap_stable, uncasted_val);
1471     raw_mem_phi-&gt;init_req(_heap_stable, raw_mem);
1472 
1473     Node* reg2_ctrl = NULL;
1474     // Null case
1475     test_null(ctrl, val, null_ctrl, phase);
1476     if (null_ctrl != NULL) {
1477       reg2_ctrl = null_ctrl-&gt;in(0);
1478       region-&gt;init_req(_null_path, null_ctrl);
1479       val_phi-&gt;init_req(_null_path, uncasted_val);
1480       raw_mem_phi-&gt;init_req(_null_path, raw_mem);
1481     } else {
1482       region-&gt;del_req(_null_path);
1483       val_phi-&gt;del_req(_null_path);
1484       raw_mem_phi-&gt;del_req(_null_path);
1485     }
1486 
1487     // Test for in-cset.
1488     // Wires !in_cset(obj) to slot 2 of region and phis
1489     Node* not_cset_ctrl = NULL;
1490     in_cset_fast_test(ctrl, not_cset_ctrl, uncasted_val, raw_mem, phase);
1491     if (not_cset_ctrl != NULL) {
1492       if (reg2_ctrl == NULL) reg2_ctrl = not_cset_ctrl-&gt;in(0);
1493       region-&gt;init_req(_not_cset, not_cset_ctrl);
1494       val_phi-&gt;init_req(_not_cset, uncasted_val);
1495       raw_mem_phi-&gt;init_req(_not_cset, raw_mem);
1496     }
1497 
1498     // Resolve object when orig-value is in cset.
1499     // Make the unconditional resolve for fwdptr.
1500     Node* new_val = uncasted_val;
1501     if (unc_ctrl != NULL) {
1502       // Clone the null check in this branch to allow implicit null check
1503       new_val = clone_null_check(ctrl, val, unc_ctrl, phase);
1504       fix_null_check(unc, unc_ctrl, ctrl-&gt;in(0)-&gt;as_If()-&gt;proj_out(0), uses, phase);
1505 
1506       IfNode* iff = unc_ctrl-&gt;in(0)-&gt;as_If();
1507       phase-&gt;igvn().replace_input_of(iff, 1, phase-&gt;igvn().intcon(1));
1508     }
1509 
1510     // Call lrb-stub and wire up that path in slots 4
1511     Node* result_mem = NULL;
1512 
1513     Node* fwd = new_val;
1514     Node* addr;
1515     if (ShenandoahSelfFixing) {
1516       VectorSet visited(Thread::current()-&gt;resource_area());
1517       addr = get_load_addr(phase, visited, lrb);
1518     } else {
1519       addr = phase-&gt;igvn().zerocon(T_OBJECT);
1520     }
1521     if (addr-&gt;Opcode() == Op_AddP) {
1522       Node* orig_base = addr-&gt;in(AddPNode::Base);
1523       Node* base = new CheckCastPPNode(ctrl, orig_base, orig_base-&gt;bottom_type(), true);
1524       phase-&gt;register_new_node(base, ctrl);
1525       if (addr-&gt;in(AddPNode::Base) == addr-&gt;in((AddPNode::Address))) {
1526         // Field access
1527         addr = addr-&gt;clone();
1528         addr-&gt;set_req(AddPNode::Base, base);
1529         addr-&gt;set_req(AddPNode::Address, base);
1530         phase-&gt;register_new_node(addr, ctrl);
1531       } else {
1532         Node* addr2 = addr-&gt;in(AddPNode::Address);
1533         if (addr2-&gt;Opcode() == Op_AddP &amp;&amp; addr2-&gt;in(AddPNode::Base) == addr2-&gt;in(AddPNode::Address) &amp;&amp;
1534               addr2-&gt;in(AddPNode::Base) == orig_base) {
1535           addr2 = addr2-&gt;clone();
1536           addr2-&gt;set_req(AddPNode::Base, base);
1537           addr2-&gt;set_req(AddPNode::Address, base);
1538           phase-&gt;register_new_node(addr2, ctrl);
1539           addr = addr-&gt;clone();
1540           addr-&gt;set_req(AddPNode::Base, base);
1541           addr-&gt;set_req(AddPNode::Address, addr2);
1542           phase-&gt;register_new_node(addr, ctrl);
1543         }
1544       }
1545     }
1546     call_lrb_stub(ctrl, fwd, addr, result_mem, raw_mem, lrb-&gt;is_native(), phase);
1547     region-&gt;init_req(_evac_path, ctrl);
1548     val_phi-&gt;init_req(_evac_path, fwd);
1549     raw_mem_phi-&gt;init_req(_evac_path, result_mem);
1550 
1551     phase-&gt;register_control(region, loop, heap_stable_iff);
1552     Node* out_val = val_phi;
1553     phase-&gt;register_new_node(val_phi, region);
1554     phase-&gt;register_new_node(raw_mem_phi, region);
1555 
1556     fix_ctrl(lrb, region, fixer, uses, uses_to_ignore, last, phase);
1557 
1558     ctrl = orig_ctrl;
1559 
1560     if (unc != NULL) {
1561       for (DUIterator_Fast imax, i = val-&gt;fast_outs(imax); i &lt; imax; i++) {
1562         Node* u = val-&gt;fast_out(i);
1563         Node* c = phase-&gt;ctrl_or_self(u);
1564         if (u != lrb &amp;&amp; (c != ctrl || is_dominator_same_ctrl(c, lrb, u, phase))) {
1565           phase-&gt;igvn().rehash_node_delayed(u);
1566           int nb = u-&gt;replace_edge(val, out_val);
1567           --i, imax -= nb;
1568         }
1569       }
1570       if (val-&gt;outcnt() == 0) {
1571         phase-&gt;igvn()._worklist.push(val);
1572       }
1573     }
1574     phase-&gt;igvn().replace_node(lrb, out_val);
1575 
1576     follow_barrier_uses(out_val, ctrl, uses, phase);
1577 
1578     for(uint next = 0; next &lt; uses.size(); next++ ) {
1579       Node *n = uses.at(next);
1580       assert(phase-&gt;get_ctrl(n) == ctrl, &quot;bad control&quot;);
1581       assert(n != init_raw_mem, &quot;should leave input raw mem above the barrier&quot;);
1582       phase-&gt;set_ctrl(n, region);
1583       follow_barrier_uses(n, ctrl, uses, phase);
1584     }
1585 
1586     // The slow path call produces memory: hook the raw memory phi
1587     // from the expanded load reference barrier with the rest of the graph
1588     // which may require adding memory phis at every post dominated
1589     // region and at enclosing loop heads. Use the memory state
1590     // collected in memory_nodes to fix the memory graph. Update that
1591     // memory state as we go.
1592     fixer.fix_mem(ctrl, region, init_raw_mem, raw_mem_for_ctrl, raw_mem_phi, uses);
1593   }
1594   // Done expanding load-reference-barriers.
1595   assert(ShenandoahBarrierSetC2::bsc2()-&gt;state()-&gt;load_reference_barriers_count() == 0, &quot;all load reference barrier nodes should have been replaced&quot;);
1596 
1597   for (int i = state-&gt;enqueue_barriers_count() - 1; i &gt;= 0; i--) {
1598     Node* barrier = state-&gt;enqueue_barrier(i);
1599     Node* pre_val = barrier-&gt;in(1);
1600 
1601     if (phase-&gt;igvn().type(pre_val)-&gt;higher_equal(TypePtr::NULL_PTR)) {
1602       ShouldNotReachHere();
1603       continue;
1604     }
1605 
1606     Node* ctrl = phase-&gt;get_ctrl(barrier);
1607 
1608     if (ctrl-&gt;is_Proj() &amp;&amp; ctrl-&gt;in(0)-&gt;is_CallJava()) {
1609       assert(is_dominator(phase-&gt;get_ctrl(pre_val), ctrl-&gt;in(0)-&gt;in(0), pre_val, ctrl-&gt;in(0), phase), &quot;can&#39;t move&quot;);
1610       ctrl = ctrl-&gt;in(0)-&gt;in(0);
1611       phase-&gt;set_ctrl(barrier, ctrl);
1612     } else if (ctrl-&gt;is_CallRuntime()) {
1613       assert(is_dominator(phase-&gt;get_ctrl(pre_val), ctrl-&gt;in(0), pre_val, ctrl, phase), &quot;can&#39;t move&quot;);
1614       ctrl = ctrl-&gt;in(0);
1615       phase-&gt;set_ctrl(barrier, ctrl);
1616     }
1617 
1618     Node* init_ctrl = ctrl;
1619     IdealLoopTree* loop = phase-&gt;get_loop(ctrl);
1620     Node* raw_mem = fixer.find_mem(ctrl, barrier);
1621     Node* init_raw_mem = raw_mem;
1622     Node* raw_mem_for_ctrl = fixer.find_mem(ctrl, NULL);
1623     Node* heap_stable_ctrl = NULL;
1624     Node* null_ctrl = NULL;
1625     uint last = phase-&gt;C-&gt;unique();
1626 
1627     enum { _heap_stable = 1, _heap_unstable, PATH_LIMIT };
1628     Node* region = new RegionNode(PATH_LIMIT);
1629     Node* phi = PhiNode::make(region, raw_mem, Type::MEMORY, TypeRawPtr::BOTTOM);
1630 
1631     enum { _fast_path = 1, _slow_path, _null_path, PATH_LIMIT2 };
1632     Node* region2 = new RegionNode(PATH_LIMIT2);
1633     Node* phi2 = PhiNode::make(region2, raw_mem, Type::MEMORY, TypeRawPtr::BOTTOM);
1634 
1635     // Stable path.
1636     test_heap_stable(ctrl, raw_mem, heap_stable_ctrl, phase);
1637     region-&gt;init_req(_heap_stable, heap_stable_ctrl);
1638     phi-&gt;init_req(_heap_stable, raw_mem);
1639 
1640     // Null path
1641     Node* reg2_ctrl = NULL;
1642     test_null(ctrl, pre_val, null_ctrl, phase);
1643     if (null_ctrl != NULL) {
1644       reg2_ctrl = null_ctrl-&gt;in(0);
1645       region2-&gt;init_req(_null_path, null_ctrl);
1646       phi2-&gt;init_req(_null_path, raw_mem);
1647     } else {
1648       region2-&gt;del_req(_null_path);
1649       phi2-&gt;del_req(_null_path);
1650     }
1651 
1652     const int index_offset = in_bytes(ShenandoahThreadLocalData::satb_mark_queue_index_offset());
1653     const int buffer_offset = in_bytes(ShenandoahThreadLocalData::satb_mark_queue_buffer_offset());
1654     Node* thread = new ThreadLocalNode();
1655     phase-&gt;register_new_node(thread, ctrl);
1656     Node* buffer_adr = new AddPNode(phase-&gt;C-&gt;top(), thread, phase-&gt;igvn().MakeConX(buffer_offset));
1657     phase-&gt;register_new_node(buffer_adr, ctrl);
1658     Node* index_adr = new AddPNode(phase-&gt;C-&gt;top(), thread, phase-&gt;igvn().MakeConX(index_offset));
1659     phase-&gt;register_new_node(index_adr, ctrl);
1660 
1661     BasicType index_bt = TypeX_X-&gt;basic_type();
1662     assert(sizeof(size_t) == type2aelembytes(index_bt), &quot;Loading G1 SATBMarkQueue::_index with wrong size.&quot;);
1663     const TypePtr* adr_type = TypeRawPtr::BOTTOM;
1664     Node* index = new LoadXNode(ctrl, raw_mem, index_adr, adr_type, TypeX_X, MemNode::unordered);
1665     phase-&gt;register_new_node(index, ctrl);
1666     Node* index_cmp = new CmpXNode(index, phase-&gt;igvn().MakeConX(0));
1667     phase-&gt;register_new_node(index_cmp, ctrl);
1668     Node* index_test = new BoolNode(index_cmp, BoolTest::ne);
1669     phase-&gt;register_new_node(index_test, ctrl);
1670     IfNode* queue_full_iff = new IfNode(ctrl, index_test, PROB_LIKELY(0.999), COUNT_UNKNOWN);
1671     if (reg2_ctrl == NULL) reg2_ctrl = queue_full_iff;
1672     phase-&gt;register_control(queue_full_iff, loop, ctrl);
1673     Node* not_full = new IfTrueNode(queue_full_iff);
1674     phase-&gt;register_control(not_full, loop, queue_full_iff);
1675     Node* full = new IfFalseNode(queue_full_iff);
1676     phase-&gt;register_control(full, loop, queue_full_iff);
1677 
1678     ctrl = not_full;
1679 
1680     Node* next_index = new SubXNode(index, phase-&gt;igvn().MakeConX(sizeof(intptr_t)));
1681     phase-&gt;register_new_node(next_index, ctrl);
1682 
1683     Node* buffer  = new LoadPNode(ctrl, raw_mem, buffer_adr, adr_type, TypeRawPtr::NOTNULL, MemNode::unordered);
1684     phase-&gt;register_new_node(buffer, ctrl);
1685     Node *log_addr = new AddPNode(phase-&gt;C-&gt;top(), buffer, next_index);
1686     phase-&gt;register_new_node(log_addr, ctrl);
1687     Node* log_store = new StorePNode(ctrl, raw_mem, log_addr, adr_type, pre_val, MemNode::unordered);
1688     phase-&gt;register_new_node(log_store, ctrl);
1689     // update the index
1690     Node* index_update = new StoreXNode(ctrl, log_store, index_adr, adr_type, next_index, MemNode::unordered);
1691     phase-&gt;register_new_node(index_update, ctrl);
1692 
1693     // Fast-path case
1694     region2-&gt;init_req(_fast_path, ctrl);
1695     phi2-&gt;init_req(_fast_path, index_update);
1696 
1697     ctrl = full;
1698 
1699     Node* base = find_bottom_mem(ctrl, phase);
1700 
1701     MergeMemNode* mm = MergeMemNode::make(base);
1702     mm-&gt;set_memory_at(Compile::AliasIdxRaw, raw_mem);
1703     phase-&gt;register_new_node(mm, ctrl);
1704 
1705     Node* call = new CallLeafNode(ShenandoahBarrierSetC2::write_ref_field_pre_entry_Type(), CAST_FROM_FN_PTR(address, ShenandoahRuntime::write_ref_field_pre_entry), &quot;shenandoah_wb_pre&quot;, TypeRawPtr::BOTTOM);
1706     call-&gt;init_req(TypeFunc::Control, ctrl);
1707     call-&gt;init_req(TypeFunc::I_O, phase-&gt;C-&gt;top());
1708     call-&gt;init_req(TypeFunc::Memory, mm);
1709     call-&gt;init_req(TypeFunc::FramePtr, phase-&gt;C-&gt;top());
1710     call-&gt;init_req(TypeFunc::ReturnAdr, phase-&gt;C-&gt;top());
1711     call-&gt;init_req(TypeFunc::Parms, pre_val);
1712     call-&gt;init_req(TypeFunc::Parms+1, thread);
1713     phase-&gt;register_control(call, loop, ctrl);
1714 
1715     Node* ctrl_proj = new ProjNode(call, TypeFunc::Control);
1716     phase-&gt;register_control(ctrl_proj, loop, call);
1717     Node* mem_proj = new ProjNode(call, TypeFunc::Memory);
1718     phase-&gt;register_new_node(mem_proj, call);
1719 
1720     // Slow-path case
1721     region2-&gt;init_req(_slow_path, ctrl_proj);
1722     phi2-&gt;init_req(_slow_path, mem_proj);
1723 
1724     phase-&gt;register_control(region2, loop, reg2_ctrl);
1725     phase-&gt;register_new_node(phi2, region2);
1726 
1727     region-&gt;init_req(_heap_unstable, region2);
1728     phi-&gt;init_req(_heap_unstable, phi2);
1729 
1730     phase-&gt;register_control(region, loop, heap_stable_ctrl-&gt;in(0));
1731     phase-&gt;register_new_node(phi, region);
1732 
1733     fix_ctrl(barrier, region, fixer, uses, uses_to_ignore, last, phase);
1734     for(uint next = 0; next &lt; uses.size(); next++ ) {
1735       Node *n = uses.at(next);
1736       assert(phase-&gt;get_ctrl(n) == init_ctrl, &quot;bad control&quot;);
1737       assert(n != init_raw_mem, &quot;should leave input raw mem above the barrier&quot;);
1738       phase-&gt;set_ctrl(n, region);
1739       follow_barrier_uses(n, init_ctrl, uses, phase);
1740     }
1741     fixer.fix_mem(init_ctrl, region, init_raw_mem, raw_mem_for_ctrl, phi, uses);
1742 
1743     phase-&gt;igvn().replace_node(barrier, pre_val);
1744   }
1745   assert(state-&gt;enqueue_barriers_count() == 0, &quot;all enqueue barrier nodes should have been replaced&quot;);
1746 
1747 }
1748 
1749 Node* ShenandoahBarrierC2Support::get_load_addr(PhaseIdealLoop* phase, VectorSet&amp; visited, Node* in) {
1750   if (visited.test_set(in-&gt;_idx)) {
1751     return NULL;
1752   }
1753   switch (in-&gt;Opcode()) {
1754     case Op_Proj:
1755       return get_load_addr(phase, visited, in-&gt;in(0));
1756     case Op_CastPP:
1757     case Op_CheckCastPP:
1758     case Op_DecodeN:
1759     case Op_EncodeP:
1760       return get_load_addr(phase, visited, in-&gt;in(1));
1761     case Op_LoadN:
1762     case Op_LoadP:
1763       return in-&gt;in(MemNode::Address);
1764     case Op_CompareAndExchangeN:
1765     case Op_CompareAndExchangeP:
1766     case Op_GetAndSetN:
1767     case Op_GetAndSetP:
1768     case Op_ShenandoahCompareAndExchangeP:
1769     case Op_ShenandoahCompareAndExchangeN:
1770       // Those instructions would just have stored a different
1771       // value into the field. No use to attempt to fix it at this point.
1772       return phase-&gt;igvn().zerocon(T_OBJECT);
1773     case Op_CMoveP:
1774     case Op_CMoveN: {
1775       Node* t = get_load_addr(phase, visited, in-&gt;in(CMoveNode::IfTrue));
1776       Node* f = get_load_addr(phase, visited, in-&gt;in(CMoveNode::IfFalse));
1777       // Handle unambiguous cases: single address reported on both branches.
1778       if (t != NULL &amp;&amp; f == NULL) return t;
1779       if (t == NULL &amp;&amp; f != NULL) return f;
1780       if (t != NULL &amp;&amp; t == f)    return t;
1781       // Ambiguity.
1782       return phase-&gt;igvn().zerocon(T_OBJECT);
1783     }
1784     case Op_Phi: {
1785       Node* addr = NULL;
1786       for (uint i = 1; i &lt; in-&gt;req(); i++) {
1787         Node* addr1 = get_load_addr(phase, visited, in-&gt;in(i));
1788         if (addr == NULL) {
1789           addr = addr1;
1790         }
1791         if (addr != addr1) {
1792           return phase-&gt;igvn().zerocon(T_OBJECT);
1793         }
1794       }
1795       return addr;
1796     }
1797     case Op_ShenandoahLoadReferenceBarrier:
1798       return get_load_addr(phase, visited, in-&gt;in(ShenandoahLoadReferenceBarrierNode::ValueIn));
1799     case Op_ShenandoahEnqueueBarrier:
1800       return get_load_addr(phase, visited, in-&gt;in(1));
1801     case Op_CallDynamicJava:
1802     case Op_CallLeaf:
1803     case Op_CallStaticJava:
1804     case Op_ConN:
1805     case Op_ConP:
1806     case Op_Parm:
1807     case Op_CreateEx:
1808       return phase-&gt;igvn().zerocon(T_OBJECT);
1809     default:
1810 #ifdef ASSERT
1811       fatal(&quot;Unknown node in get_load_addr: %s&quot;, NodeClassNames[in-&gt;Opcode()]);
1812 #endif
1813       return phase-&gt;igvn().zerocon(T_OBJECT);
1814   }
1815 
1816 }
1817 
1818 void ShenandoahBarrierC2Support::move_heap_stable_test_out_of_loop(IfNode* iff, PhaseIdealLoop* phase) {
1819   IdealLoopTree *loop = phase-&gt;get_loop(iff);
1820   Node* loop_head = loop-&gt;_head;
1821   Node* entry_c = loop_head-&gt;in(LoopNode::EntryControl);
1822 
1823   Node* bol = iff-&gt;in(1);
1824   Node* cmp = bol-&gt;in(1);
1825   Node* andi = cmp-&gt;in(1);
1826   Node* load = andi-&gt;in(1);
1827 
1828   assert(is_gc_state_load(load), &quot;broken&quot;);
1829   if (!phase-&gt;is_dominator(load-&gt;in(0), entry_c)) {
1830     Node* mem_ctrl = NULL;
1831     Node* mem = dom_mem(load-&gt;in(MemNode::Memory), loop_head, Compile::AliasIdxRaw, mem_ctrl, phase);
1832     load = load-&gt;clone();
1833     load-&gt;set_req(MemNode::Memory, mem);
1834     load-&gt;set_req(0, entry_c);
1835     phase-&gt;register_new_node(load, entry_c);
1836     andi = andi-&gt;clone();
1837     andi-&gt;set_req(1, load);
1838     phase-&gt;register_new_node(andi, entry_c);
1839     cmp = cmp-&gt;clone();
1840     cmp-&gt;set_req(1, andi);
1841     phase-&gt;register_new_node(cmp, entry_c);
1842     bol = bol-&gt;clone();
1843     bol-&gt;set_req(1, cmp);
1844     phase-&gt;register_new_node(bol, entry_c);
1845 
1846     Node* old_bol =iff-&gt;in(1);
1847     phase-&gt;igvn().replace_input_of(iff, 1, bol);
1848   }
1849 }
1850 
1851 bool ShenandoahBarrierC2Support::identical_backtoback_ifs(Node* n, PhaseIdealLoop* phase) {
1852   if (!n-&gt;is_If() || n-&gt;is_CountedLoopEnd()) {
1853     return false;
1854   }
1855   Node* region = n-&gt;in(0);
1856 
1857   if (!region-&gt;is_Region()) {
1858     return false;
1859   }
1860   Node* dom = phase-&gt;idom(region);
1861   if (!dom-&gt;is_If()) {
1862     return false;
1863   }
1864 
1865   if (!is_heap_stable_test(n) || !is_heap_stable_test(dom)) {
1866     return false;
1867   }
1868 
1869   IfNode* dom_if = dom-&gt;as_If();
1870   Node* proj_true = dom_if-&gt;proj_out(1);
1871   Node* proj_false = dom_if-&gt;proj_out(0);
1872 
1873   for (uint i = 1; i &lt; region-&gt;req(); i++) {
1874     if (phase-&gt;is_dominator(proj_true, region-&gt;in(i))) {
1875       continue;
1876     }
1877     if (phase-&gt;is_dominator(proj_false, region-&gt;in(i))) {
1878       continue;
1879     }
1880     return false;
1881   }
1882 
1883   return true;
1884 }
1885 
1886 void ShenandoahBarrierC2Support::merge_back_to_back_tests(Node* n, PhaseIdealLoop* phase) {
1887   assert(is_heap_stable_test(n), &quot;no other tests&quot;);
1888   if (identical_backtoback_ifs(n, phase)) {
1889     Node* n_ctrl = n-&gt;in(0);
1890     if (phase-&gt;can_split_if(n_ctrl)) {
1891       IfNode* dom_if = phase-&gt;idom(n_ctrl)-&gt;as_If();
1892       if (is_heap_stable_test(n)) {
1893         Node* gc_state_load = n-&gt;in(1)-&gt;in(1)-&gt;in(1)-&gt;in(1);
1894         assert(is_gc_state_load(gc_state_load), &quot;broken&quot;);
1895         Node* dom_gc_state_load = dom_if-&gt;in(1)-&gt;in(1)-&gt;in(1)-&gt;in(1);
1896         assert(is_gc_state_load(dom_gc_state_load), &quot;broken&quot;);
1897         if (gc_state_load != dom_gc_state_load) {
1898           phase-&gt;igvn().replace_node(gc_state_load, dom_gc_state_load);
1899         }
1900       }
1901       PhiNode* bolphi = PhiNode::make_blank(n_ctrl, n-&gt;in(1));
1902       Node* proj_true = dom_if-&gt;proj_out(1);
1903       Node* proj_false = dom_if-&gt;proj_out(0);
1904       Node* con_true = phase-&gt;igvn().makecon(TypeInt::ONE);
1905       Node* con_false = phase-&gt;igvn().makecon(TypeInt::ZERO);
1906 
1907       for (uint i = 1; i &lt; n_ctrl-&gt;req(); i++) {
1908         if (phase-&gt;is_dominator(proj_true, n_ctrl-&gt;in(i))) {
1909           bolphi-&gt;init_req(i, con_true);
1910         } else {
1911           assert(phase-&gt;is_dominator(proj_false, n_ctrl-&gt;in(i)), &quot;bad if&quot;);
1912           bolphi-&gt;init_req(i, con_false);
1913         }
1914       }
1915       phase-&gt;register_new_node(bolphi, n_ctrl);
1916       phase-&gt;igvn().replace_input_of(n, 1, bolphi);
1917       phase-&gt;do_split_if(n);
1918     }
1919   }
1920 }
1921 
1922 IfNode* ShenandoahBarrierC2Support::find_unswitching_candidate(const IdealLoopTree* loop, PhaseIdealLoop* phase) {
1923   // Find first invariant test that doesn&#39;t exit the loop
1924   LoopNode *head = loop-&gt;_head-&gt;as_Loop();
1925   IfNode* unswitch_iff = NULL;
1926   Node* n = head-&gt;in(LoopNode::LoopBackControl);
1927   int loop_has_sfpts = -1;
1928   while (n != head) {
1929     Node* n_dom = phase-&gt;idom(n);
1930     if (n-&gt;is_Region()) {
1931       if (n_dom-&gt;is_If()) {
1932         IfNode* iff = n_dom-&gt;as_If();
1933         if (iff-&gt;in(1)-&gt;is_Bool()) {
1934           BoolNode* bol = iff-&gt;in(1)-&gt;as_Bool();
1935           if (bol-&gt;in(1)-&gt;is_Cmp()) {
1936             // If condition is invariant and not a loop exit,
1937             // then found reason to unswitch.
1938             if (is_heap_stable_test(iff) &amp;&amp;
1939                 (loop_has_sfpts == -1 || loop_has_sfpts == 0)) {
1940               assert(!loop-&gt;is_loop_exit(iff), &quot;both branches should be in the loop&quot;);
1941               if (loop_has_sfpts == -1) {
1942                 for(uint i = 0; i &lt; loop-&gt;_body.size(); i++) {
1943                   Node *m = loop-&gt;_body[i];
1944                   if (m-&gt;is_SafePoint() &amp;&amp; !m-&gt;is_CallLeaf()) {
1945                     loop_has_sfpts = 1;
1946                     break;
1947                   }
1948                 }
1949                 if (loop_has_sfpts == -1) {
1950                   loop_has_sfpts = 0;
1951                 }
1952               }
1953               if (!loop_has_sfpts) {
1954                 unswitch_iff = iff;
1955               }
1956             }
1957           }
1958         }
1959       }
1960     }
1961     n = n_dom;
1962   }
1963   return unswitch_iff;
1964 }
1965 
1966 
1967 void ShenandoahBarrierC2Support::optimize_after_expansion(VectorSet &amp;visited, Node_Stack &amp;stack, Node_List &amp;old_new, PhaseIdealLoop* phase) {
1968   Node_List heap_stable_tests;
1969   Node_List gc_state_loads;
1970   stack.push(phase-&gt;C-&gt;start(), 0);
1971   do {
1972     Node* n = stack.node();
1973     uint i = stack.index();
1974 
1975     if (i &lt; n-&gt;outcnt()) {
1976       Node* u = n-&gt;raw_out(i);
1977       stack.set_index(i+1);
1978       if (!visited.test_set(u-&gt;_idx)) {
1979         stack.push(u, 0);
1980       }
1981     } else {
1982       stack.pop();
1983       if (ShenandoahCommonGCStateLoads &amp;&amp; is_gc_state_load(n)) {
1984         gc_state_loads.push(n);
1985       }
1986       if (n-&gt;is_If() &amp;&amp; is_heap_stable_test(n)) {
1987         heap_stable_tests.push(n);
1988       }
1989     }
1990   } while (stack.size() &gt; 0);
1991 
1992   bool progress;
1993   do {
1994     progress = false;
1995     for (uint i = 0; i &lt; gc_state_loads.size(); i++) {
1996       Node* n = gc_state_loads.at(i);
1997       if (n-&gt;outcnt() != 0) {
1998         progress |= try_common_gc_state_load(n, phase);
1999       }
2000     }
2001   } while (progress);
2002 
2003   for (uint i = 0; i &lt; heap_stable_tests.size(); i++) {
2004     Node* n = heap_stable_tests.at(i);
2005     assert(is_heap_stable_test(n), &quot;only evacuation test&quot;);
2006     merge_back_to_back_tests(n, phase);
2007   }
2008 
2009   if (!phase-&gt;C-&gt;major_progress()) {
2010     VectorSet seen(Thread::current()-&gt;resource_area());
2011     for (uint i = 0; i &lt; heap_stable_tests.size(); i++) {
2012       Node* n = heap_stable_tests.at(i);
2013       IdealLoopTree* loop = phase-&gt;get_loop(n);
2014       if (loop != phase-&gt;ltree_root() &amp;&amp;
2015           loop-&gt;_child == NULL &amp;&amp;
2016           !loop-&gt;_irreducible) {
2017         Node* head = loop-&gt;_head;
2018         if (head-&gt;is_Loop() &amp;&amp;
2019             (!head-&gt;is_CountedLoop() || head-&gt;as_CountedLoop()-&gt;is_main_loop() || head-&gt;as_CountedLoop()-&gt;is_normal_loop()) &amp;&amp;
2020             !seen.test_set(head-&gt;_idx)) {
2021           IfNode* iff = find_unswitching_candidate(loop, phase);
2022           if (iff != NULL) {
2023             Node* bol = iff-&gt;in(1);
2024             if (head-&gt;as_Loop()-&gt;is_strip_mined()) {
2025               head-&gt;as_Loop()-&gt;verify_strip_mined(0);
2026             }
2027             move_heap_stable_test_out_of_loop(iff, phase);
2028 
2029             AutoNodeBudget node_budget(phase);
2030 
2031             if (loop-&gt;policy_unswitching(phase)) {
2032               if (head-&gt;as_Loop()-&gt;is_strip_mined()) {
2033                 OuterStripMinedLoopNode* outer = head-&gt;as_CountedLoop()-&gt;outer_loop();
2034                 hide_strip_mined_loop(outer, head-&gt;as_CountedLoop(), phase);
2035               }
2036               phase-&gt;do_unswitching(loop, old_new);
2037             } else {
2038               // Not proceeding with unswitching. Move load back in
2039               // the loop.
2040               phase-&gt;igvn().replace_input_of(iff, 1, bol);
2041             }
2042           }
2043         }
2044       }
2045     }
2046   }
2047 }
2048 
2049 #ifdef ASSERT
2050 void ShenandoahBarrierC2Support::verify_raw_mem(RootNode* root) {
2051   const bool trace = false;
2052   ResourceMark rm;
2053   Unique_Node_List nodes;
2054   Unique_Node_List controls;
2055   Unique_Node_List memories;
2056 
2057   nodes.push(root);
2058   for (uint next = 0; next &lt; nodes.size(); next++) {
2059     Node *n  = nodes.at(next);
2060     if (ShenandoahBarrierSetC2::is_shenandoah_lrb_call(n)) {
2061       controls.push(n);
2062       if (trace) { tty-&gt;print(&quot;XXXXXX verifying&quot;); n-&gt;dump(); }
2063       for (uint next2 = 0; next2 &lt; controls.size(); next2++) {
2064         Node *m = controls.at(next2);
2065         for (DUIterator_Fast imax, i = m-&gt;fast_outs(imax); i &lt; imax; i++) {
2066           Node* u = m-&gt;fast_out(i);
2067           if (u-&gt;is_CFG() &amp;&amp; !u-&gt;is_Root() &amp;&amp;
2068               !(u-&gt;Opcode() == Op_CProj &amp;&amp; u-&gt;in(0)-&gt;Opcode() == Op_NeverBranch &amp;&amp; u-&gt;as_Proj()-&gt;_con == 1) &amp;&amp;
2069               !(u-&gt;is_Region() &amp;&amp; u-&gt;unique_ctrl_out()-&gt;Opcode() == Op_Halt)) {
2070             if (trace) { tty-&gt;print(&quot;XXXXXX pushing control&quot;); u-&gt;dump(); }
2071             controls.push(u);
2072           }
2073         }
2074       }
2075       memories.push(n-&gt;as_Call()-&gt;proj_out(TypeFunc::Memory));
2076       for (uint next2 = 0; next2 &lt; memories.size(); next2++) {
2077         Node *m = memories.at(next2);
2078         assert(m-&gt;bottom_type() == Type::MEMORY, &quot;&quot;);
2079         for (DUIterator_Fast imax, i = m-&gt;fast_outs(imax); i &lt; imax; i++) {
2080           Node* u = m-&gt;fast_out(i);
2081           if (u-&gt;bottom_type() == Type::MEMORY &amp;&amp; (u-&gt;is_Mem() || u-&gt;is_ClearArray())) {
2082             if (trace) { tty-&gt;print(&quot;XXXXXX pushing memory&quot;); u-&gt;dump(); }
2083             memories.push(u);
2084           } else if (u-&gt;is_LoadStore()) {
2085             if (trace) { tty-&gt;print(&quot;XXXXXX pushing memory&quot;); u-&gt;find_out_with(Op_SCMemProj)-&gt;dump(); }
2086             memories.push(u-&gt;find_out_with(Op_SCMemProj));
2087           } else if (u-&gt;is_MergeMem() &amp;&amp; u-&gt;as_MergeMem()-&gt;memory_at(Compile::AliasIdxRaw) == m) {
2088             if (trace) { tty-&gt;print(&quot;XXXXXX pushing memory&quot;); u-&gt;dump(); }
2089             memories.push(u);
2090           } else if (u-&gt;is_Phi()) {
2091             assert(u-&gt;bottom_type() == Type::MEMORY, &quot;&quot;);
2092             if (u-&gt;adr_type() == TypeRawPtr::BOTTOM || u-&gt;adr_type() == TypePtr::BOTTOM) {
2093               assert(controls.member(u-&gt;in(0)), &quot;&quot;);
2094               if (trace) { tty-&gt;print(&quot;XXXXXX pushing memory&quot;); u-&gt;dump(); }
2095               memories.push(u);
2096             }
2097           } else if (u-&gt;is_SafePoint() || u-&gt;is_MemBar()) {
2098             for (DUIterator_Fast jmax, j = u-&gt;fast_outs(jmax); j &lt; jmax; j++) {
2099               Node* uu = u-&gt;fast_out(j);
2100               if (uu-&gt;bottom_type() == Type::MEMORY) {
2101                 if (trace) { tty-&gt;print(&quot;XXXXXX pushing memory&quot;); uu-&gt;dump(); }
2102                 memories.push(uu);
2103               }
2104             }
2105           }
2106         }
2107       }
2108       for (uint next2 = 0; next2 &lt; controls.size(); next2++) {
2109         Node *m = controls.at(next2);
2110         if (m-&gt;is_Region()) {
2111           bool all_in = true;
2112           for (uint i = 1; i &lt; m-&gt;req(); i++) {
2113             if (!controls.member(m-&gt;in(i))) {
2114               all_in = false;
2115               break;
2116             }
2117           }
2118           if (trace) { tty-&gt;print(&quot;XXX verifying %s&quot;, all_in ? &quot;all in&quot; : &quot;&quot;); m-&gt;dump(); }
2119           bool found_phi = false;
2120           for (DUIterator_Fast jmax, j = m-&gt;fast_outs(jmax); j &lt; jmax &amp;&amp; !found_phi; j++) {
2121             Node* u = m-&gt;fast_out(j);
2122             if (u-&gt;is_Phi() &amp;&amp; memories.member(u)) {
2123               found_phi = true;
2124               for (uint i = 1; i &lt; u-&gt;req() &amp;&amp; found_phi; i++) {
2125                 Node* k = u-&gt;in(i);
2126                 if (memories.member(k) != controls.member(m-&gt;in(i))) {
2127                   found_phi = false;
2128                 }
2129               }
2130             }
2131           }
2132           assert(found_phi || all_in, &quot;&quot;);
2133         }
2134       }
2135       controls.clear();
2136       memories.clear();
2137     }
2138     for( uint i = 0; i &lt; n-&gt;len(); ++i ) {
2139       Node *m = n-&gt;in(i);
2140       if (m != NULL) {
2141         nodes.push(m);
2142       }
2143     }
2144   }
2145 }
2146 #endif
2147 
2148 ShenandoahEnqueueBarrierNode::ShenandoahEnqueueBarrierNode(Node* val) : Node(NULL, val) {
2149   ShenandoahBarrierSetC2::bsc2()-&gt;state()-&gt;add_enqueue_barrier(this);
2150 }
2151 
2152 const Type* ShenandoahEnqueueBarrierNode::bottom_type() const {
2153   if (in(1) == NULL || in(1)-&gt;is_top()) {
2154     return Type::TOP;
2155   }
2156   const Type* t = in(1)-&gt;bottom_type();
2157   if (t == TypePtr::NULL_PTR) {
2158     return t;
2159   }
2160   return t-&gt;is_oopptr();
2161 }
2162 
2163 const Type* ShenandoahEnqueueBarrierNode::Value(PhaseGVN* phase) const {
2164   if (in(1) == NULL) {
2165     return Type::TOP;
2166   }
2167   const Type* t = phase-&gt;type(in(1));
2168   if (t == Type::TOP) {
2169     return Type::TOP;
2170   }
2171   if (t == TypePtr::NULL_PTR) {
2172     return t;
2173   }
2174   return t-&gt;is_oopptr();
2175 }
2176 
2177 int ShenandoahEnqueueBarrierNode::needed(Node* n) {
2178   if (n == NULL ||
2179       n-&gt;is_Allocate() ||
2180       n-&gt;Opcode() == Op_ShenandoahEnqueueBarrier ||
2181       n-&gt;bottom_type() == TypePtr::NULL_PTR ||
2182       (n-&gt;bottom_type()-&gt;make_oopptr() != NULL &amp;&amp; n-&gt;bottom_type()-&gt;make_oopptr()-&gt;const_oop() != NULL)) {
2183     return NotNeeded;
2184   }
2185   if (n-&gt;is_Phi() ||
2186       n-&gt;is_CMove()) {
2187     return MaybeNeeded;
2188   }
2189   return Needed;
2190 }
2191 
2192 Node* ShenandoahEnqueueBarrierNode::next(Node* n) {
2193   for (;;) {
2194     if (n == NULL) {
2195       return n;
2196     } else if (n-&gt;bottom_type() == TypePtr::NULL_PTR) {
2197       return n;
2198     } else if (n-&gt;bottom_type()-&gt;make_oopptr() != NULL &amp;&amp; n-&gt;bottom_type()-&gt;make_oopptr()-&gt;const_oop() != NULL) {
2199       return n;
2200     } else if (n-&gt;is_ConstraintCast() ||
2201                n-&gt;Opcode() == Op_DecodeN ||
2202                n-&gt;Opcode() == Op_EncodeP) {
2203       n = n-&gt;in(1);
2204     } else if (n-&gt;is_Proj()) {
2205       n = n-&gt;in(0);
2206     } else {
2207       return n;
2208     }
2209   }
2210   ShouldNotReachHere();
2211   return NULL;
2212 }
2213 
2214 Node* ShenandoahEnqueueBarrierNode::Identity(PhaseGVN* phase) {
2215   PhaseIterGVN* igvn = phase-&gt;is_IterGVN();
2216 
2217   Node* n = next(in(1));
2218 
2219   int cont = needed(n);
2220 
2221   if (cont == NotNeeded) {
2222     return in(1);
2223   } else if (cont == MaybeNeeded) {
2224     if (igvn == NULL) {
2225       phase-&gt;record_for_igvn(this);
2226       return this;
2227     } else {
2228       ResourceMark rm;
2229       Unique_Node_List wq;
2230       uint wq_i = 0;
2231 
2232       for (;;) {
2233         if (n-&gt;is_Phi()) {
2234           for (uint i = 1; i &lt; n-&gt;req(); i++) {
2235             Node* m = n-&gt;in(i);
2236             if (m != NULL) {
2237               wq.push(m);
2238             }
2239           }
2240         } else {
2241           assert(n-&gt;is_CMove(), &quot;nothing else here&quot;);
2242           Node* m = n-&gt;in(CMoveNode::IfFalse);
2243           wq.push(m);
2244           m = n-&gt;in(CMoveNode::IfTrue);
2245           wq.push(m);
2246         }
2247         Node* orig_n = NULL;
2248         do {
2249           if (wq_i &gt;= wq.size()) {
2250             return in(1);
2251           }
2252           n = wq.at(wq_i);
2253           wq_i++;
2254           orig_n = n;
2255           n = next(n);
2256           cont = needed(n);
2257           if (cont == Needed) {
2258             return this;
2259           }
2260         } while (cont != MaybeNeeded || (orig_n != n &amp;&amp; wq.member(n)));
2261       }
2262     }
2263   }
2264 
2265   return this;
2266 }
2267 
2268 #ifdef ASSERT
2269 static bool has_never_branch(Node* root) {
2270   for (uint i = 1; i &lt; root-&gt;req(); i++) {
2271     Node* in = root-&gt;in(i);
2272     if (in != NULL &amp;&amp; in-&gt;Opcode() == Op_Halt &amp;&amp; in-&gt;in(0)-&gt;is_Proj() &amp;&amp; in-&gt;in(0)-&gt;in(0)-&gt;Opcode() == Op_NeverBranch) {
2273       return true;
2274     }
2275   }
2276   return false;
2277 }
2278 #endif
2279 
2280 void MemoryGraphFixer::collect_memory_nodes() {
2281   Node_Stack stack(0);
2282   VectorSet visited(Thread::current()-&gt;resource_area());
2283   Node_List regions;
2284 
2285   // Walk the raw memory graph and create a mapping from CFG node to
2286   // memory node. Exclude phis for now.
2287   stack.push(_phase-&gt;C-&gt;root(), 1);
2288   do {
2289     Node* n = stack.node();
2290     int opc = n-&gt;Opcode();
2291     uint i = stack.index();
2292     if (i &lt; n-&gt;req()) {
2293       Node* mem = NULL;
2294       if (opc == Op_Root) {
2295         Node* in = n-&gt;in(i);
2296         int in_opc = in-&gt;Opcode();
2297         if (in_opc == Op_Return || in_opc == Op_Rethrow) {
2298           mem = in-&gt;in(TypeFunc::Memory);
2299         } else if (in_opc == Op_Halt) {
2300           if (in-&gt;in(0)-&gt;is_Region()) {
2301             Node* r = in-&gt;in(0);
2302             for (uint j = 1; j &lt; r-&gt;req(); j++) {
2303               assert(r-&gt;in(j)-&gt;Opcode() != Op_NeverBranch, &quot;&quot;);
2304             }
2305           } else {
2306             Node* proj = in-&gt;in(0);
2307             assert(proj-&gt;is_Proj(), &quot;&quot;);
2308             Node* in = proj-&gt;in(0);
2309             assert(in-&gt;is_CallStaticJava() || in-&gt;Opcode() == Op_NeverBranch || in-&gt;Opcode() == Op_Catch || proj-&gt;is_IfProj(), &quot;&quot;);
2310             if (in-&gt;is_CallStaticJava()) {
2311               mem = in-&gt;in(TypeFunc::Memory);
2312             } else if (in-&gt;Opcode() == Op_Catch) {
2313               Node* call = in-&gt;in(0)-&gt;in(0);
2314               assert(call-&gt;is_Call(), &quot;&quot;);
2315               mem = call-&gt;in(TypeFunc::Memory);
2316             } else if (in-&gt;Opcode() == Op_NeverBranch) {
2317               Node* head = in-&gt;in(0);
2318               assert(head-&gt;is_Region() &amp;&amp; head-&gt;req() == 3, &quot;unexpected infinite loop graph shape&quot;);
2319               assert(_phase-&gt;is_dominator(head, head-&gt;in(1)) || _phase-&gt;is_dominator(head, head-&gt;in(2)), &quot;no back branch?&quot;);
2320               Node* tail = _phase-&gt;is_dominator(head, head-&gt;in(1)) ? head-&gt;in(1) : head-&gt;in(2);
2321               Node* c = tail;
2322               while (c != head) {
2323                 if (c-&gt;is_SafePoint() &amp;&amp; !c-&gt;is_CallLeaf()) {
2324                   mem = c-&gt;in(TypeFunc::Memory);
2325                 }
2326                 c = _phase-&gt;idom(c);
2327               }
2328               assert(mem != NULL, &quot;should have found safepoint&quot;);
2329 
2330               Node* phi_mem = NULL;
2331               for (DUIterator_Fast jmax, j = head-&gt;fast_outs(jmax); j &lt; jmax; j++) {
2332                 Node* u = head-&gt;fast_out(j);
2333                 if (u-&gt;is_Phi() &amp;&amp; u-&gt;bottom_type() == Type::MEMORY) {
2334                   if (_phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == _alias) {
2335                     assert(phi_mem == NULL || phi_mem-&gt;adr_type() == TypePtr::BOTTOM, &quot;&quot;);
2336                     phi_mem = u;
2337                   } else if (u-&gt;adr_type() == TypePtr::BOTTOM) {
2338                     assert(phi_mem == NULL || _phase-&gt;C-&gt;get_alias_index(phi_mem-&gt;adr_type()) == _alias, &quot;&quot;);
2339                     if (phi_mem == NULL) {
2340                       phi_mem = u;
2341                     }
2342                   }
2343                 }
2344               }
2345               if (phi_mem != NULL) {
2346                 mem = phi_mem;
2347               }
2348             }
2349           }
2350         } else {
2351 #ifdef ASSERT
2352           n-&gt;dump();
2353           in-&gt;dump();
2354 #endif
2355           ShouldNotReachHere();
2356         }
2357       } else {
2358         assert(n-&gt;is_Phi() &amp;&amp; n-&gt;bottom_type() == Type::MEMORY, &quot;&quot;);
2359         assert(n-&gt;adr_type() == TypePtr::BOTTOM || _phase-&gt;C-&gt;get_alias_index(n-&gt;adr_type()) == _alias, &quot;&quot;);
2360         mem = n-&gt;in(i);
2361       }
2362       i++;
2363       stack.set_index(i);
2364       if (mem == NULL) {
2365         continue;
2366       }
2367       for (;;) {
2368         if (visited.test_set(mem-&gt;_idx) || mem-&gt;is_Start()) {
2369           break;
2370         }
2371         if (mem-&gt;is_Phi()) {
2372           stack.push(mem, 2);
2373           mem = mem-&gt;in(1);
2374         } else if (mem-&gt;is_Proj()) {
2375           stack.push(mem, mem-&gt;req());
2376           mem = mem-&gt;in(0);
2377         } else if (mem-&gt;is_SafePoint() || mem-&gt;is_MemBar()) {
2378           mem = mem-&gt;in(TypeFunc::Memory);
2379         } else if (mem-&gt;is_MergeMem()) {
2380           MergeMemNode* mm = mem-&gt;as_MergeMem();
2381           mem = mm-&gt;memory_at(_alias);
2382         } else if (mem-&gt;is_Store() || mem-&gt;is_LoadStore() || mem-&gt;is_ClearArray()) {
2383           assert(_alias == Compile::AliasIdxRaw, &quot;&quot;);
2384           stack.push(mem, mem-&gt;req());
2385           mem = mem-&gt;in(MemNode::Memory);
2386         } else {
2387 #ifdef ASSERT
2388           mem-&gt;dump();
2389 #endif
2390           ShouldNotReachHere();
2391         }
2392       }
2393     } else {
2394       if (n-&gt;is_Phi()) {
2395         // Nothing
2396       } else if (!n-&gt;is_Root()) {
2397         Node* c = get_ctrl(n);
2398         _memory_nodes.map(c-&gt;_idx, n);
2399       }
2400       stack.pop();
2401     }
2402   } while(stack.is_nonempty());
2403 
2404   // Iterate over CFG nodes in rpo and propagate memory state to
2405   // compute memory state at regions, creating new phis if needed.
2406   Node_List rpo_list;
2407   visited.clear();
2408   _phase-&gt;rpo(_phase-&gt;C-&gt;root(), stack, visited, rpo_list);
2409   Node* root = rpo_list.pop();
2410   assert(root == _phase-&gt;C-&gt;root(), &quot;&quot;);
2411 
2412   const bool trace = false;
2413 #ifdef ASSERT
2414   if (trace) {
2415     for (int i = rpo_list.size() - 1; i &gt;= 0; i--) {
2416       Node* c = rpo_list.at(i);
2417       if (_memory_nodes[c-&gt;_idx] != NULL) {
2418         tty-&gt;print(&quot;X %d&quot;, c-&gt;_idx);  _memory_nodes[c-&gt;_idx]-&gt;dump();
2419       }
2420     }
2421   }
2422 #endif
2423   uint last = _phase-&gt;C-&gt;unique();
2424 
2425 #ifdef ASSERT
2426   uint8_t max_depth = 0;
2427   for (LoopTreeIterator iter(_phase-&gt;ltree_root()); !iter.done(); iter.next()) {
2428     IdealLoopTree* lpt = iter.current();
2429     max_depth = MAX2(max_depth, lpt-&gt;_nest);
2430   }
2431 #endif
2432 
2433   bool progress = true;
2434   int iteration = 0;
2435   Node_List dead_phis;
2436   while (progress) {
2437     progress = false;
2438     iteration++;
2439     assert(iteration &lt;= 2+max_depth || _phase-&gt;C-&gt;has_irreducible_loop() || has_never_branch(_phase-&gt;C-&gt;root()), &quot;&quot;);
2440     if (trace) { tty-&gt;print_cr(&quot;XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&quot;); }
2441     IdealLoopTree* last_updated_ilt = NULL;
2442     for (int i = rpo_list.size() - 1; i &gt;= 0; i--) {
2443       Node* c = rpo_list.at(i);
2444 
2445       Node* prev_mem = _memory_nodes[c-&gt;_idx];
2446       if (c-&gt;is_Region() &amp;&amp; (_include_lsm || !c-&gt;is_OuterStripMinedLoop())) {
2447         Node* prev_region = regions[c-&gt;_idx];
2448         Node* unique = NULL;
2449         for (uint j = 1; j &lt; c-&gt;req() &amp;&amp; unique != NodeSentinel; j++) {
2450           Node* m = _memory_nodes[c-&gt;in(j)-&gt;_idx];
2451           assert(m != NULL || (c-&gt;is_Loop() &amp;&amp; j == LoopNode::LoopBackControl &amp;&amp; iteration == 1) || _phase-&gt;C-&gt;has_irreducible_loop() || has_never_branch(_phase-&gt;C-&gt;root()), &quot;expect memory state&quot;);
2452           if (m != NULL) {
2453             if (m == prev_region &amp;&amp; ((c-&gt;is_Loop() &amp;&amp; j == LoopNode::LoopBackControl) || (prev_region-&gt;is_Phi() &amp;&amp; prev_region-&gt;in(0) == c))) {
2454               assert(c-&gt;is_Loop() &amp;&amp; j == LoopNode::LoopBackControl || _phase-&gt;C-&gt;has_irreducible_loop(), &quot;&quot;);
2455               // continue
2456             } else if (unique == NULL) {
2457               unique = m;
2458             } else if (m == unique) {
2459               // continue
2460             } else {
2461               unique = NodeSentinel;
2462             }
2463           }
2464         }
2465         assert(unique != NULL, &quot;empty phi???&quot;);
2466         if (unique != NodeSentinel) {
2467           if (prev_region != NULL &amp;&amp; prev_region-&gt;is_Phi() &amp;&amp; prev_region-&gt;in(0) == c) {
2468             dead_phis.push(prev_region);
2469           }
2470           regions.map(c-&gt;_idx, unique);
2471         } else {
2472           Node* phi = NULL;
2473           if (prev_region != NULL &amp;&amp; prev_region-&gt;is_Phi() &amp;&amp; prev_region-&gt;in(0) == c &amp;&amp; prev_region-&gt;_idx &gt;= last) {
2474             phi = prev_region;
2475             for (uint k = 1; k &lt; c-&gt;req(); k++) {
2476               Node* m = _memory_nodes[c-&gt;in(k)-&gt;_idx];
2477               assert(m != NULL, &quot;expect memory state&quot;);
2478               phi-&gt;set_req(k, m);
2479             }
2480           } else {
2481             for (DUIterator_Fast jmax, j = c-&gt;fast_outs(jmax); j &lt; jmax &amp;&amp; phi == NULL; j++) {
2482               Node* u = c-&gt;fast_out(j);
2483               if (u-&gt;is_Phi() &amp;&amp; u-&gt;bottom_type() == Type::MEMORY &amp;&amp;
2484                   (u-&gt;adr_type() == TypePtr::BOTTOM || _phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == _alias)) {
2485                 phi = u;
2486                 for (uint k = 1; k &lt; c-&gt;req() &amp;&amp; phi != NULL; k++) {
2487                   Node* m = _memory_nodes[c-&gt;in(k)-&gt;_idx];
2488                   assert(m != NULL, &quot;expect memory state&quot;);
2489                   if (u-&gt;in(k) != m) {
2490                     phi = NULL;
2491                   }
2492                 }
2493               }
2494             }
2495             if (phi == NULL) {
2496               phi = new PhiNode(c, Type::MEMORY, _phase-&gt;C-&gt;get_adr_type(_alias));
2497               for (uint k = 1; k &lt; c-&gt;req(); k++) {
2498                 Node* m = _memory_nodes[c-&gt;in(k)-&gt;_idx];
2499                 assert(m != NULL, &quot;expect memory state&quot;);
2500                 phi-&gt;init_req(k, m);
2501               }
2502             }
2503           }
2504           assert(phi != NULL, &quot;&quot;);
2505           regions.map(c-&gt;_idx, phi);
2506         }
2507         Node* current_region = regions[c-&gt;_idx];
2508         if (current_region != prev_region) {
2509           progress = true;
2510           if (prev_region == prev_mem) {
2511             _memory_nodes.map(c-&gt;_idx, current_region);
2512           }
2513         }
2514       } else if (prev_mem == NULL || prev_mem-&gt;is_Phi() || ctrl_or_self(prev_mem) != c) {
2515         Node* m = _memory_nodes[_phase-&gt;idom(c)-&gt;_idx];
2516         assert(m != NULL, &quot;expect memory state&quot;);
2517         if (m != prev_mem) {
2518           _memory_nodes.map(c-&gt;_idx, m);
2519           progress = true;
2520         }
2521       }
2522 #ifdef ASSERT
2523       if (trace) { tty-&gt;print(&quot;X %d&quot;, c-&gt;_idx);  _memory_nodes[c-&gt;_idx]-&gt;dump(); }
2524 #endif
2525     }
2526   }
2527 
2528   // Replace existing phi with computed memory state for that region
2529   // if different (could be a new phi or a dominating memory node if
2530   // that phi was found to be useless).
2531   while (dead_phis.size() &gt; 0) {
2532     Node* n = dead_phis.pop();
2533     n-&gt;replace_by(_phase-&gt;C-&gt;top());
2534     n-&gt;destruct();
2535   }
2536   for (int i = rpo_list.size() - 1; i &gt;= 0; i--) {
2537     Node* c = rpo_list.at(i);
2538     if (c-&gt;is_Region() &amp;&amp; (_include_lsm || !c-&gt;is_OuterStripMinedLoop())) {
2539       Node* n = regions[c-&gt;_idx];
2540       if (n-&gt;is_Phi() &amp;&amp; n-&gt;_idx &gt;= last &amp;&amp; n-&gt;in(0) == c) {
2541         _phase-&gt;register_new_node(n, c);
2542       }
2543     }
2544   }
2545   for (int i = rpo_list.size() - 1; i &gt;= 0; i--) {
2546     Node* c = rpo_list.at(i);
2547     if (c-&gt;is_Region() &amp;&amp; (_include_lsm || !c-&gt;is_OuterStripMinedLoop())) {
2548       Node* n = regions[c-&gt;_idx];
2549       for (DUIterator_Fast imax, i = c-&gt;fast_outs(imax); i &lt; imax; i++) {
2550         Node* u = c-&gt;fast_out(i);
2551         if (u-&gt;is_Phi() &amp;&amp; u-&gt;bottom_type() == Type::MEMORY &amp;&amp;
2552             u != n) {
2553           if (u-&gt;adr_type() == TypePtr::BOTTOM) {
2554             fix_memory_uses(u, n, n, c);
2555           } else if (_phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == _alias) {
2556             _phase-&gt;lazy_replace(u, n);
2557             --i; --imax;
2558           }
2559         }
2560       }
2561     }
2562   }
2563 }
2564 
2565 Node* MemoryGraphFixer::get_ctrl(Node* n) const {
2566   Node* c = _phase-&gt;get_ctrl(n);
2567   if (n-&gt;is_Proj() &amp;&amp; n-&gt;in(0) != NULL &amp;&amp; n-&gt;in(0)-&gt;is_Call()) {
2568     assert(c == n-&gt;in(0), &quot;&quot;);
2569     CallNode* call = c-&gt;as_Call();
2570     CallProjections projs;
2571     call-&gt;extract_projections(&amp;projs, true, false);
2572     if (projs.catchall_memproj != NULL) {
2573       if (projs.fallthrough_memproj == n) {
2574         c = projs.fallthrough_catchproj;
2575       } else {
2576         assert(projs.catchall_memproj == n, &quot;&quot;);
2577         c = projs.catchall_catchproj;
2578       }
2579     }
2580   }
2581   return c;
2582 }
2583 
2584 Node* MemoryGraphFixer::ctrl_or_self(Node* n) const {
2585   if (_phase-&gt;has_ctrl(n))
2586     return get_ctrl(n);
2587   else {
2588     assert (n-&gt;is_CFG(), &quot;must be a CFG node&quot;);
2589     return n;
2590   }
2591 }
2592 
2593 bool MemoryGraphFixer::mem_is_valid(Node* m, Node* c) const {
2594   return m != NULL &amp;&amp; get_ctrl(m) == c;
2595 }
2596 
2597 Node* MemoryGraphFixer::find_mem(Node* ctrl, Node* n) const {
2598   assert(n == NULL || _phase-&gt;ctrl_or_self(n) == ctrl, &quot;&quot;);
2599   Node* mem = _memory_nodes[ctrl-&gt;_idx];
2600   Node* c = ctrl;
2601   while (!mem_is_valid(mem, c) &amp;&amp;
2602          (!c-&gt;is_CatchProj() || mem == NULL || c-&gt;in(0)-&gt;in(0)-&gt;in(0) != get_ctrl(mem))) {
2603     c = _phase-&gt;idom(c);
2604     mem = _memory_nodes[c-&gt;_idx];
2605   }
2606   if (n != NULL &amp;&amp; mem_is_valid(mem, c)) {
2607     while (!ShenandoahBarrierC2Support::is_dominator_same_ctrl(c, mem, n, _phase) &amp;&amp; _phase-&gt;ctrl_or_self(mem) == ctrl) {
2608       mem = next_mem(mem, _alias);
2609     }
2610     if (mem-&gt;is_MergeMem()) {
2611       mem = mem-&gt;as_MergeMem()-&gt;memory_at(_alias);
2612     }
2613     if (!mem_is_valid(mem, c)) {
2614       do {
2615         c = _phase-&gt;idom(c);
2616         mem = _memory_nodes[c-&gt;_idx];
2617       } while (!mem_is_valid(mem, c) &amp;&amp;
2618                (!c-&gt;is_CatchProj() || mem == NULL || c-&gt;in(0)-&gt;in(0)-&gt;in(0) != get_ctrl(mem)));
2619     }
2620   }
2621   assert(mem-&gt;bottom_type() == Type::MEMORY, &quot;&quot;);
2622   return mem;
2623 }
2624 
2625 bool MemoryGraphFixer::has_mem_phi(Node* region) const {
2626   for (DUIterator_Fast imax, i = region-&gt;fast_outs(imax); i &lt; imax; i++) {
2627     Node* use = region-&gt;fast_out(i);
2628     if (use-&gt;is_Phi() &amp;&amp; use-&gt;bottom_type() == Type::MEMORY &amp;&amp;
2629         (_phase-&gt;C-&gt;get_alias_index(use-&gt;adr_type()) == _alias)) {
2630       return true;
2631     }
2632   }
2633   return false;
2634 }
2635 
2636 void MemoryGraphFixer::fix_mem(Node* ctrl, Node* new_ctrl, Node* mem, Node* mem_for_ctrl, Node* new_mem, Unique_Node_List&amp; uses) {
2637   assert(_phase-&gt;ctrl_or_self(new_mem) == new_ctrl, &quot;&quot;);
2638   const bool trace = false;
2639   DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ control is&quot;); ctrl-&gt;dump(); });
2640   DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ mem is&quot;); mem-&gt;dump(); });
2641   GrowableArray&lt;Node*&gt; phis;
2642   if (mem_for_ctrl != mem) {
2643     Node* old = mem_for_ctrl;
2644     Node* prev = NULL;
2645     while (old != mem) {
2646       prev = old;
2647       if (old-&gt;is_Store() || old-&gt;is_ClearArray() || old-&gt;is_LoadStore()) {
2648         assert(_alias == Compile::AliasIdxRaw, &quot;&quot;);
2649         old = old-&gt;in(MemNode::Memory);
2650       } else if (old-&gt;Opcode() == Op_SCMemProj) {
2651         assert(_alias == Compile::AliasIdxRaw, &quot;&quot;);
2652         old = old-&gt;in(0);
2653       } else {
2654         ShouldNotReachHere();
2655       }
2656     }
2657     assert(prev != NULL, &quot;&quot;);
2658     if (new_ctrl != ctrl) {
2659       _memory_nodes.map(ctrl-&gt;_idx, mem);
2660       _memory_nodes.map(new_ctrl-&gt;_idx, mem_for_ctrl);
2661     }
2662     uint input = (uint)MemNode::Memory;
2663     _phase-&gt;igvn().replace_input_of(prev, input, new_mem);
2664   } else {
2665     uses.clear();
2666     _memory_nodes.map(new_ctrl-&gt;_idx, new_mem);
2667     uses.push(new_ctrl);
2668     for(uint next = 0; next &lt; uses.size(); next++ ) {
2669       Node *n = uses.at(next);
2670       assert(n-&gt;is_CFG(), &quot;&quot;);
2671       DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ ctrl&quot;); n-&gt;dump(); });
2672       for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
2673         Node* u = n-&gt;fast_out(i);
2674         if (!u-&gt;is_Root() &amp;&amp; u-&gt;is_CFG() &amp;&amp; u != n) {
2675           Node* m = _memory_nodes[u-&gt;_idx];
2676           if (u-&gt;is_Region() &amp;&amp; (!u-&gt;is_OuterStripMinedLoop() || _include_lsm) &amp;&amp;
2677               !has_mem_phi(u) &amp;&amp;
2678               u-&gt;unique_ctrl_out()-&gt;Opcode() != Op_Halt) {
2679             DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ region&quot;); u-&gt;dump(); });
2680             DEBUG_ONLY(if (trace &amp;&amp; m != NULL) { tty-&gt;print(&quot;ZZZ mem&quot;); m-&gt;dump(); });
2681 
2682             if (!mem_is_valid(m, u) || !m-&gt;is_Phi()) {
2683               bool push = true;
2684               bool create_phi = true;
2685               if (_phase-&gt;is_dominator(new_ctrl, u)) {
2686                 create_phi = false;
2687               } else if (!_phase-&gt;C-&gt;has_irreducible_loop()) {
2688                 IdealLoopTree* loop = _phase-&gt;get_loop(ctrl);
2689                 bool do_check = true;
2690                 IdealLoopTree* l = loop;
2691                 create_phi = false;
2692                 while (l != _phase-&gt;ltree_root()) {
2693                   Node* head = l-&gt;_head;
2694                   if (head-&gt;in(0) == NULL) {
2695                     head = _phase-&gt;get_ctrl(head);
2696                   }
2697                   if (_phase-&gt;is_dominator(head, u) &amp;&amp; _phase-&gt;is_dominator(_phase-&gt;idom(u), head)) {
2698                     create_phi = true;
2699                     do_check = false;
2700                     break;
2701                   }
2702                   l = l-&gt;_parent;
2703                 }
2704 
2705                 if (do_check) {
2706                   assert(!create_phi, &quot;&quot;);
2707                   IdealLoopTree* u_loop = _phase-&gt;get_loop(u);
2708                   if (u_loop != _phase-&gt;ltree_root() &amp;&amp; u_loop-&gt;is_member(loop)) {
2709                     Node* c = ctrl;
2710                     while (!_phase-&gt;is_dominator(c, u_loop-&gt;tail())) {
2711                       c = _phase-&gt;idom(c);
2712                     }
2713                     if (!_phase-&gt;is_dominator(c, u)) {
2714                       do_check = false;
2715                     }
2716                   }
2717                 }
2718 
2719                 if (do_check &amp;&amp; _phase-&gt;is_dominator(_phase-&gt;idom(u), new_ctrl)) {
2720                   create_phi = true;
2721                 }
2722               }
2723               if (create_phi) {
2724                 Node* phi = new PhiNode(u, Type::MEMORY, _phase-&gt;C-&gt;get_adr_type(_alias));
2725                 _phase-&gt;register_new_node(phi, u);
2726                 phis.push(phi);
2727                 DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ new phi&quot;); phi-&gt;dump(); });
2728                 if (!mem_is_valid(m, u)) {
2729                   DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting mem&quot;); phi-&gt;dump(); });
2730                   _memory_nodes.map(u-&gt;_idx, phi);
2731                 } else {
2732                   DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ NOT setting mem&quot;); m-&gt;dump(); });
2733                   for (;;) {
2734                     assert(m-&gt;is_Mem() || m-&gt;is_LoadStore() || m-&gt;is_Proj(), &quot;&quot;);
2735                     Node* next = NULL;
2736                     if (m-&gt;is_Proj()) {
2737                       next = m-&gt;in(0);
2738                     } else {
2739                       assert(m-&gt;is_Mem() || m-&gt;is_LoadStore(), &quot;&quot;);
2740                       assert(_alias == Compile::AliasIdxRaw, &quot;&quot;);
2741                       next = m-&gt;in(MemNode::Memory);
2742                     }
2743                     if (_phase-&gt;get_ctrl(next) != u) {
2744                       break;
2745                     }
2746                     if (next-&gt;is_MergeMem()) {
2747                       assert(_phase-&gt;get_ctrl(next-&gt;as_MergeMem()-&gt;memory_at(_alias)) != u, &quot;&quot;);
2748                       break;
2749                     }
2750                     if (next-&gt;is_Phi()) {
2751                       assert(next-&gt;adr_type() == TypePtr::BOTTOM &amp;&amp; next-&gt;in(0) == u, &quot;&quot;);
2752                       break;
2753                     }
2754                     m = next;
2755                   }
2756 
2757                   DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting to phi&quot;); m-&gt;dump(); });
2758                   assert(m-&gt;is_Mem() || m-&gt;is_LoadStore(), &quot;&quot;);
2759                   uint input = (uint)MemNode::Memory;
2760                   _phase-&gt;igvn().replace_input_of(m, input, phi);
2761                   push = false;
2762                 }
2763               } else {
2764                 DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ skipping region&quot;); u-&gt;dump(); });
2765               }
2766               if (push) {
2767                 uses.push(u);
2768               }
2769             }
2770           } else if (!mem_is_valid(m, u) &amp;&amp;
2771                      !(u-&gt;Opcode() == Op_CProj &amp;&amp; u-&gt;in(0)-&gt;Opcode() == Op_NeverBranch &amp;&amp; u-&gt;as_Proj()-&gt;_con == 1)) {
2772             uses.push(u);
2773           }
2774         }
2775       }
2776     }
2777     for (int i = 0; i &lt; phis.length(); i++) {
2778       Node* n = phis.at(i);
2779       Node* r = n-&gt;in(0);
2780       DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ fixing new phi&quot;); n-&gt;dump(); });
2781       for (uint j = 1; j &lt; n-&gt;req(); j++) {
2782         Node* m = find_mem(r-&gt;in(j), NULL);
2783         _phase-&gt;igvn().replace_input_of(n, j, m);
2784         DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ fixing new phi: %d&quot;, j); m-&gt;dump(); });
2785       }
2786     }
2787   }
2788   uint last = _phase-&gt;C-&gt;unique();
2789   MergeMemNode* mm = NULL;
2790   int alias = _alias;
2791   DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ raw mem is&quot;); mem-&gt;dump(); });
2792   // Process loads first to not miss an anti-dependency: if the memory
2793   // edge of a store is updated before a load is processed then an
2794   // anti-dependency may be missed.
2795   for (DUIterator i = mem-&gt;outs(); mem-&gt;has_out(i); i++) {
2796     Node* u = mem-&gt;out(i);
2797     if (u-&gt;_idx &lt; last &amp;&amp; u-&gt;is_Load() &amp;&amp; _phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == alias) {
2798       Node* m = find_mem(_phase-&gt;get_ctrl(u), u);
2799       if (m != mem) {
2800         DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting memory of use&quot;); u-&gt;dump(); });
2801         _phase-&gt;igvn().replace_input_of(u, MemNode::Memory, m);
2802         --i;
2803       }
2804     }
2805   }
2806   for (DUIterator i = mem-&gt;outs(); mem-&gt;has_out(i); i++) {
2807     Node* u = mem-&gt;out(i);
2808     if (u-&gt;_idx &lt; last) {
2809       if (u-&gt;is_Mem()) {
2810         if (_phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == alias) {
2811           Node* m = find_mem(_phase-&gt;get_ctrl(u), u);
2812           if (m != mem) {
2813             DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting memory of use&quot;); u-&gt;dump(); });
2814             _phase-&gt;igvn().replace_input_of(u, MemNode::Memory, m);
2815             --i;
2816           }
2817         }
2818       } else if (u-&gt;is_MergeMem()) {
2819         MergeMemNode* u_mm = u-&gt;as_MergeMem();
2820         if (u_mm-&gt;memory_at(alias) == mem) {
2821           MergeMemNode* newmm = NULL;
2822           for (DUIterator_Fast jmax, j = u-&gt;fast_outs(jmax); j &lt; jmax; j++) {
2823             Node* uu = u-&gt;fast_out(j);
2824             assert(!uu-&gt;is_MergeMem(), &quot;chain of MergeMems?&quot;);
2825             if (uu-&gt;is_Phi()) {
2826               assert(uu-&gt;adr_type() == TypePtr::BOTTOM, &quot;&quot;);
2827               Node* region = uu-&gt;in(0);
2828               int nb = 0;
2829               for (uint k = 1; k &lt; uu-&gt;req(); k++) {
2830                 if (uu-&gt;in(k) == u) {
2831                   Node* m = find_mem(region-&gt;in(k), NULL);
2832                   if (m != mem) {
2833                     DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting memory of phi %d&quot;, k); uu-&gt;dump(); });
2834                     newmm = clone_merge_mem(u, mem, m, _phase-&gt;ctrl_or_self(m), i);
2835                     if (newmm != u) {
2836                       _phase-&gt;igvn().replace_input_of(uu, k, newmm);
2837                       nb++;
2838                       --jmax;
2839                     }
2840                   }
2841                 }
2842               }
2843               if (nb &gt; 0) {
2844                 --j;
2845               }
2846             } else {
2847               Node* m = find_mem(_phase-&gt;ctrl_or_self(uu), uu);
2848               if (m != mem) {
2849                 DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting memory of use&quot;); uu-&gt;dump(); });
2850                 newmm = clone_merge_mem(u, mem, m, _phase-&gt;ctrl_or_self(m), i);
2851                 if (newmm != u) {
2852                   _phase-&gt;igvn().replace_input_of(uu, uu-&gt;find_edge(u), newmm);
2853                   --j, --jmax;
2854                 }
2855               }
2856             }
2857           }
2858         }
2859       } else if (u-&gt;is_Phi()) {
2860         assert(u-&gt;bottom_type() == Type::MEMORY, &quot;what else?&quot;);
2861         if (_phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == alias || u-&gt;adr_type() == TypePtr::BOTTOM) {
2862           Node* region = u-&gt;in(0);
2863           bool replaced = false;
2864           for (uint j = 1; j &lt; u-&gt;req(); j++) {
2865             if (u-&gt;in(j) == mem) {
2866               Node* m = find_mem(region-&gt;in(j), NULL);
2867               Node* nnew = m;
2868               if (m != mem) {
2869                 if (u-&gt;adr_type() == TypePtr::BOTTOM) {
2870                   mm = allocate_merge_mem(mem, m, _phase-&gt;ctrl_or_self(m));
2871                   nnew = mm;
2872                 }
2873                 DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting memory of phi %d&quot;, j); u-&gt;dump(); });
2874                 _phase-&gt;igvn().replace_input_of(u, j, nnew);
2875                 replaced = true;
2876               }
2877             }
2878           }
2879           if (replaced) {
2880             --i;
2881           }
2882         }
2883       } else if ((u-&gt;adr_type() == TypePtr::BOTTOM &amp;&amp; u-&gt;Opcode() != Op_StrInflatedCopy) ||
2884                  u-&gt;adr_type() == NULL) {
2885         assert(u-&gt;adr_type() != NULL ||
2886                u-&gt;Opcode() == Op_Rethrow ||
2887                u-&gt;Opcode() == Op_Return ||
2888                u-&gt;Opcode() == Op_SafePoint ||
2889                (u-&gt;is_CallStaticJava() &amp;&amp; u-&gt;as_CallStaticJava()-&gt;uncommon_trap_request() != 0) ||
2890                (u-&gt;is_CallStaticJava() &amp;&amp; u-&gt;as_CallStaticJava()-&gt;_entry_point == OptoRuntime::rethrow_stub()) ||
2891                u-&gt;Opcode() == Op_CallLeaf, &quot;&quot;);
2892         Node* m = find_mem(_phase-&gt;ctrl_or_self(u), u);
2893         if (m != mem) {
2894           mm = allocate_merge_mem(mem, m, _phase-&gt;get_ctrl(m));
2895           _phase-&gt;igvn().replace_input_of(u, u-&gt;find_edge(mem), mm);
2896           --i;
2897         }
2898       } else if (_phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == alias) {
2899         Node* m = find_mem(_phase-&gt;ctrl_or_self(u), u);
2900         if (m != mem) {
2901           DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting memory of use&quot;); u-&gt;dump(); });
2902           _phase-&gt;igvn().replace_input_of(u, u-&gt;find_edge(mem), m);
2903           --i;
2904         }
2905       } else if (u-&gt;adr_type() != TypePtr::BOTTOM &amp;&amp;
2906                  _memory_nodes[_phase-&gt;ctrl_or_self(u)-&gt;_idx] == u) {
2907         Node* m = find_mem(_phase-&gt;ctrl_or_self(u), u);
2908         assert(m != mem, &quot;&quot;);
2909         // u is on the wrong slice...
2910         assert(u-&gt;is_ClearArray(), &quot;&quot;);
2911         DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting memory of use&quot;); u-&gt;dump(); });
2912         _phase-&gt;igvn().replace_input_of(u, u-&gt;find_edge(mem), m);
2913         --i;
2914       }
2915     }
2916   }
2917 #ifdef ASSERT
2918   assert(new_mem-&gt;outcnt() &gt; 0, &quot;&quot;);
2919   for (int i = 0; i &lt; phis.length(); i++) {
2920     Node* n = phis.at(i);
2921     assert(n-&gt;outcnt() &gt; 0, &quot;new phi must have uses now&quot;);
2922   }
2923 #endif
2924 }
2925 
2926 MergeMemNode* MemoryGraphFixer::allocate_merge_mem(Node* mem, Node* rep_proj, Node* rep_ctrl) const {
2927   MergeMemNode* mm = MergeMemNode::make(mem);
2928   mm-&gt;set_memory_at(_alias, rep_proj);
2929   _phase-&gt;register_new_node(mm, rep_ctrl);
2930   return mm;
2931 }
2932 
2933 MergeMemNode* MemoryGraphFixer::clone_merge_mem(Node* u, Node* mem, Node* rep_proj, Node* rep_ctrl, DUIterator&amp; i) const {
2934   MergeMemNode* newmm = NULL;
2935   MergeMemNode* u_mm = u-&gt;as_MergeMem();
2936   Node* c = _phase-&gt;get_ctrl(u);
2937   if (_phase-&gt;is_dominator(c, rep_ctrl)) {
2938     c = rep_ctrl;
2939   } else {
2940     assert(_phase-&gt;is_dominator(rep_ctrl, c), &quot;one must dominate the other&quot;);
2941   }
2942   if (u-&gt;outcnt() == 1) {
2943     if (u-&gt;req() &gt; (uint)_alias &amp;&amp; u-&gt;in(_alias) == mem) {
2944       _phase-&gt;igvn().replace_input_of(u, _alias, rep_proj);
2945       --i;
2946     } else {
2947       _phase-&gt;igvn().rehash_node_delayed(u);
2948       u_mm-&gt;set_memory_at(_alias, rep_proj);
2949     }
2950     newmm = u_mm;
2951     _phase-&gt;set_ctrl_and_loop(u, c);
2952   } else {
2953     // can&#39;t simply clone u and then change one of its input because
2954     // it adds and then removes an edge which messes with the
2955     // DUIterator
2956     newmm = MergeMemNode::make(u_mm-&gt;base_memory());
2957     for (uint j = 0; j &lt; u-&gt;req(); j++) {
2958       if (j &lt; newmm-&gt;req()) {
2959         if (j == (uint)_alias) {
2960           newmm-&gt;set_req(j, rep_proj);
2961         } else if (newmm-&gt;in(j) != u-&gt;in(j)) {
2962           newmm-&gt;set_req(j, u-&gt;in(j));
2963         }
2964       } else if (j == (uint)_alias) {
2965         newmm-&gt;add_req(rep_proj);
2966       } else {
2967         newmm-&gt;add_req(u-&gt;in(j));
2968       }
2969     }
2970     if ((uint)_alias &gt;= u-&gt;req()) {
2971       newmm-&gt;set_memory_at(_alias, rep_proj);
2972     }
2973     _phase-&gt;register_new_node(newmm, c);
2974   }
2975   return newmm;
2976 }
2977 
2978 bool MemoryGraphFixer::should_process_phi(Node* phi) const {
2979   if (phi-&gt;adr_type() == TypePtr::BOTTOM) {
2980     Node* region = phi-&gt;in(0);
2981     for (DUIterator_Fast jmax, j = region-&gt;fast_outs(jmax); j &lt; jmax; j++) {
2982       Node* uu = region-&gt;fast_out(j);
2983       if (uu-&gt;is_Phi() &amp;&amp; uu != phi &amp;&amp; uu-&gt;bottom_type() == Type::MEMORY &amp;&amp; _phase-&gt;C-&gt;get_alias_index(uu-&gt;adr_type()) == _alias) {
2984         return false;
2985       }
2986     }
2987     return true;
2988   }
2989   return _phase-&gt;C-&gt;get_alias_index(phi-&gt;adr_type()) == _alias;
2990 }
2991 
2992 void MemoryGraphFixer::fix_memory_uses(Node* mem, Node* replacement, Node* rep_proj, Node* rep_ctrl) const {
2993   uint last = _phase-&gt; C-&gt;unique();
2994   MergeMemNode* mm = NULL;
2995   assert(mem-&gt;bottom_type() == Type::MEMORY, &quot;&quot;);
2996   for (DUIterator i = mem-&gt;outs(); mem-&gt;has_out(i); i++) {
2997     Node* u = mem-&gt;out(i);
2998     if (u != replacement &amp;&amp; u-&gt;_idx &lt; last) {
2999       if (u-&gt;is_MergeMem()) {
3000         MergeMemNode* u_mm = u-&gt;as_MergeMem();
3001         if (u_mm-&gt;memory_at(_alias) == mem) {
3002           MergeMemNode* newmm = NULL;
3003           for (DUIterator_Fast jmax, j = u-&gt;fast_outs(jmax); j &lt; jmax; j++) {
3004             Node* uu = u-&gt;fast_out(j);
3005             assert(!uu-&gt;is_MergeMem(), &quot;chain of MergeMems?&quot;);
3006             if (uu-&gt;is_Phi()) {
3007               if (should_process_phi(uu)) {
3008                 Node* region = uu-&gt;in(0);
3009                 int nb = 0;
3010                 for (uint k = 1; k &lt; uu-&gt;req(); k++) {
3011                   if (uu-&gt;in(k) == u &amp;&amp; _phase-&gt;is_dominator(rep_ctrl, region-&gt;in(k))) {
3012                     if (newmm == NULL) {
3013                       newmm = clone_merge_mem(u, mem, rep_proj, rep_ctrl, i);
3014                     }
3015                     if (newmm != u) {
3016                       _phase-&gt;igvn().replace_input_of(uu, k, newmm);
3017                       nb++;
3018                       --jmax;
3019                     }
3020                   }
3021                 }
3022                 if (nb &gt; 0) {
3023                   --j;
3024                 }
3025               }
3026             } else {
3027               if (rep_ctrl != uu &amp;&amp; ShenandoahBarrierC2Support::is_dominator(rep_ctrl, _phase-&gt;ctrl_or_self(uu), replacement, uu, _phase)) {
3028                 if (newmm == NULL) {
3029                   newmm = clone_merge_mem(u, mem, rep_proj, rep_ctrl, i);
3030                 }
3031                 if (newmm != u) {
3032                   _phase-&gt;igvn().replace_input_of(uu, uu-&gt;find_edge(u), newmm);
3033                   --j, --jmax;
3034                 }
3035               }
3036             }
3037           }
3038         }
3039       } else if (u-&gt;is_Phi()) {
3040         assert(u-&gt;bottom_type() == Type::MEMORY, &quot;what else?&quot;);
3041         Node* region = u-&gt;in(0);
3042         if (should_process_phi(u)) {
3043           bool replaced = false;
3044           for (uint j = 1; j &lt; u-&gt;req(); j++) {
3045             if (u-&gt;in(j) == mem &amp;&amp; _phase-&gt;is_dominator(rep_ctrl, region-&gt;in(j))) {
3046               Node* nnew = rep_proj;
3047               if (u-&gt;adr_type() == TypePtr::BOTTOM) {
3048                 if (mm == NULL) {
3049                   mm = allocate_merge_mem(mem, rep_proj, rep_ctrl);
3050                 }
3051                 nnew = mm;
3052               }
3053               _phase-&gt;igvn().replace_input_of(u, j, nnew);
3054               replaced = true;
3055             }
3056           }
3057           if (replaced) {
3058             --i;
3059           }
3060 
3061         }
3062       } else if ((u-&gt;adr_type() == TypePtr::BOTTOM &amp;&amp; u-&gt;Opcode() != Op_StrInflatedCopy) ||
3063                  u-&gt;adr_type() == NULL) {
3064         assert(u-&gt;adr_type() != NULL ||
3065                u-&gt;Opcode() == Op_Rethrow ||
3066                u-&gt;Opcode() == Op_Return ||
3067                u-&gt;Opcode() == Op_SafePoint ||
3068                u-&gt;Opcode() == Op_StoreIConditional ||
3069                u-&gt;Opcode() == Op_StoreLConditional ||
3070                (u-&gt;is_CallStaticJava() &amp;&amp; u-&gt;as_CallStaticJava()-&gt;uncommon_trap_request() != 0) ||
3071                (u-&gt;is_CallStaticJava() &amp;&amp; u-&gt;as_CallStaticJava()-&gt;_entry_point == OptoRuntime::rethrow_stub()) ||
3072                u-&gt;Opcode() == Op_CallLeaf, &quot;%s&quot;, u-&gt;Name());
3073         if (ShenandoahBarrierC2Support::is_dominator(rep_ctrl, _phase-&gt;ctrl_or_self(u), replacement, u, _phase)) {
3074           if (mm == NULL) {
3075             mm = allocate_merge_mem(mem, rep_proj, rep_ctrl);
3076           }
3077           _phase-&gt;igvn().replace_input_of(u, u-&gt;find_edge(mem), mm);
3078           --i;
3079         }
3080       } else if (_phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == _alias) {
3081         if (ShenandoahBarrierC2Support::is_dominator(rep_ctrl, _phase-&gt;ctrl_or_self(u), replacement, u, _phase)) {
3082           _phase-&gt;igvn().replace_input_of(u, u-&gt;find_edge(mem), rep_proj);
3083           --i;
3084         }
3085       }
3086     }
3087   }
3088 }
3089 
3090 ShenandoahLoadReferenceBarrierNode::ShenandoahLoadReferenceBarrierNode(Node* ctrl, Node* obj, bool native)
3091 : Node(ctrl, obj), _native(native) {
3092   ShenandoahBarrierSetC2::bsc2()-&gt;state()-&gt;add_load_reference_barrier(this);
3093 }
3094 
3095 bool ShenandoahLoadReferenceBarrierNode::is_native() const {
3096   return _native;
3097 }
3098 
3099 uint ShenandoahLoadReferenceBarrierNode::size_of() const {
3100   return sizeof(*this);
3101 }
3102 
3103 uint ShenandoahLoadReferenceBarrierNode::hash() const {
3104   return Node::hash() + (_native ? 1 : 0);
3105 }
3106 
3107 bool ShenandoahLoadReferenceBarrierNode::cmp( const Node &amp;n ) const {
3108   return Node::cmp(n) &amp;&amp; n.Opcode() == Op_ShenandoahLoadReferenceBarrier &amp;&amp;
3109          _native == ((const ShenandoahLoadReferenceBarrierNode&amp;)n)._native;
3110 }
3111 
3112 const Type* ShenandoahLoadReferenceBarrierNode::bottom_type() const {
3113   if (in(ValueIn) == NULL || in(ValueIn)-&gt;is_top()) {
3114     return Type::TOP;
3115   }
3116   const Type* t = in(ValueIn)-&gt;bottom_type();
3117   if (t == TypePtr::NULL_PTR) {
3118     return t;
3119   }
3120   return t-&gt;is_oopptr();
3121 }
3122 
3123 const Type* ShenandoahLoadReferenceBarrierNode::Value(PhaseGVN* phase) const {
3124   // Either input is TOP ==&gt; the result is TOP
3125   const Type *t2 = phase-&gt;type(in(ValueIn));
3126   if( t2 == Type::TOP ) return Type::TOP;
3127 
3128   if (t2 == TypePtr::NULL_PTR) {
3129     return t2;
3130   }
3131 
3132   const Type* type = t2-&gt;is_oopptr();
3133   return type;
3134 }
3135 
3136 Node* ShenandoahLoadReferenceBarrierNode::Identity(PhaseGVN* phase) {
3137   Node* value = in(ValueIn);
3138   if (!needs_barrier(phase, value)) {
3139     return value;
3140   }
3141   return this;
3142 }
3143 
3144 bool ShenandoahLoadReferenceBarrierNode::needs_barrier(PhaseGVN* phase, Node* n) {
3145   Unique_Node_List visited;
3146   return needs_barrier_impl(phase, n, visited);
3147 }
3148 
3149 bool ShenandoahLoadReferenceBarrierNode::needs_barrier_impl(PhaseGVN* phase, Node* n, Unique_Node_List &amp;visited) {
3150   if (n == NULL) return false;
3151   if (visited.member(n)) {
3152     return false; // Been there.
3153   }
3154   visited.push(n);
3155 
3156   if (n-&gt;is_Allocate()) {
3157     // tty-&gt;print_cr(&quot;optimize barrier on alloc&quot;);
3158     return false;
3159   }
3160   if (n-&gt;is_Call()) {
3161     // tty-&gt;print_cr(&quot;optimize barrier on call&quot;);
3162     return false;
3163   }
3164 
3165   const Type* type = phase-&gt;type(n);
3166   if (type == Type::TOP) {
3167     return false;
3168   }
3169   if (type-&gt;make_ptr()-&gt;higher_equal(TypePtr::NULL_PTR)) {
3170     // tty-&gt;print_cr(&quot;optimize barrier on null&quot;);
3171     return false;
3172   }
3173   if (type-&gt;make_oopptr() &amp;&amp; type-&gt;make_oopptr()-&gt;const_oop() != NULL) {
3174     // tty-&gt;print_cr(&quot;optimize barrier on constant&quot;);
3175     return false;
3176   }
3177 
3178   switch (n-&gt;Opcode()) {
3179     case Op_AddP:
3180       return true; // TODO: Can refine?
3181     case Op_LoadP:
3182     case Op_ShenandoahCompareAndExchangeN:
3183     case Op_ShenandoahCompareAndExchangeP:
3184     case Op_CompareAndExchangeN:
3185     case Op_CompareAndExchangeP:
3186     case Op_GetAndSetN:
3187     case Op_GetAndSetP:
3188       return true;
3189     case Op_Phi: {
3190       for (uint i = 1; i &lt; n-&gt;req(); i++) {
3191         if (needs_barrier_impl(phase, n-&gt;in(i), visited)) return true;
3192       }
3193       return false;
3194     }
3195     case Op_CheckCastPP:
3196     case Op_CastPP:
3197       return needs_barrier_impl(phase, n-&gt;in(1), visited);
3198     case Op_Proj:
3199       return needs_barrier_impl(phase, n-&gt;in(0), visited);
3200     case Op_ShenandoahLoadReferenceBarrier:
3201       // tty-&gt;print_cr(&quot;optimize barrier on barrier&quot;);
3202       return false;
3203     case Op_Parm:
3204       // tty-&gt;print_cr(&quot;optimize barrier on input arg&quot;);
3205       return false;
3206     case Op_DecodeN:
3207     case Op_EncodeP:
3208       return needs_barrier_impl(phase, n-&gt;in(1), visited);
3209     case Op_LoadN:
3210       return true;
3211     case Op_CMoveN:
3212     case Op_CMoveP:
3213       return needs_barrier_impl(phase, n-&gt;in(2), visited) ||
3214              needs_barrier_impl(phase, n-&gt;in(3), visited);
3215     case Op_ShenandoahEnqueueBarrier:
3216       return needs_barrier_impl(phase, n-&gt;in(1), visited);
3217     case Op_CreateEx:
3218       return false;
3219     default:
3220       break;
3221   }
3222 #ifdef ASSERT
3223   tty-&gt;print(&quot;need barrier on?: &quot;);
3224   tty-&gt;print_cr(&quot;ins:&quot;);
3225   n-&gt;dump(2);
3226   tty-&gt;print_cr(&quot;outs:&quot;);
3227   n-&gt;dump(-2);
3228   ShouldNotReachHere();
3229 #endif
3230   return true;
3231 }
3232 
3233 ShenandoahLoadReferenceBarrierNode::Strength ShenandoahLoadReferenceBarrierNode::get_barrier_strength() {
3234   Unique_Node_List visited;
3235   Node_Stack stack(0);
3236   stack.push(this, 0);
3237 
3238   // Look for strongest strength: go over nodes looking for STRONG ones.
3239   // Stop once we encountered STRONG. Otherwise, walk until we ran out of nodes,
3240   // and then the overall strength is NONE.
3241   Strength strength = NONE;
3242   while (strength != STRONG &amp;&amp; stack.size() &gt; 0) {
3243     Node* n = stack.node();
3244     if (visited.member(n)) {
3245       stack.pop();
3246       continue;
3247     }
3248     visited.push(n);
3249     bool visit_users = false;
3250     switch (n-&gt;Opcode()) {
3251       case Op_CallStaticJava:
3252       case Op_CallDynamicJava:
3253       case Op_CallLeaf:
3254       case Op_CallLeafNoFP:
3255       case Op_CompareAndSwapL:
3256       case Op_CompareAndSwapI:
3257       case Op_CompareAndSwapB:
3258       case Op_CompareAndSwapS:
3259       case Op_CompareAndSwapN:
3260       case Op_CompareAndSwapP:
3261       case Op_CompareAndExchangeL:
3262       case Op_CompareAndExchangeI:
3263       case Op_CompareAndExchangeB:
3264       case Op_CompareAndExchangeS:
3265       case Op_CompareAndExchangeN:
3266       case Op_CompareAndExchangeP:
3267       case Op_WeakCompareAndSwapL:
3268       case Op_WeakCompareAndSwapI:
3269       case Op_WeakCompareAndSwapB:
3270       case Op_WeakCompareAndSwapS:
3271       case Op_WeakCompareAndSwapN:
3272       case Op_WeakCompareAndSwapP:
3273       case Op_ShenandoahCompareAndSwapN:
3274       case Op_ShenandoahCompareAndSwapP:
3275       case Op_ShenandoahWeakCompareAndSwapN:
3276       case Op_ShenandoahWeakCompareAndSwapP:
3277       case Op_ShenandoahCompareAndExchangeN:
3278       case Op_ShenandoahCompareAndExchangeP:
3279       case Op_GetAndSetL:
3280       case Op_GetAndSetI:
3281       case Op_GetAndSetB:
3282       case Op_GetAndSetS:
3283       case Op_GetAndSetP:
3284       case Op_GetAndSetN:
3285       case Op_GetAndAddL:
3286       case Op_GetAndAddI:
3287       case Op_GetAndAddB:
3288       case Op_GetAndAddS:
3289       case Op_ShenandoahEnqueueBarrier:
3290       case Op_FastLock:
3291       case Op_FastUnlock:
3292       case Op_Rethrow:
3293       case Op_Return:
3294       case Op_StoreB:
3295       case Op_StoreC:
3296       case Op_StoreD:
3297       case Op_StoreF:
3298       case Op_StoreL:
3299       case Op_StoreLConditional:
3300       case Op_StoreI:
3301       case Op_StoreIConditional:
3302       case Op_StoreN:
3303       case Op_StoreP:
3304       case Op_StoreVector:
3305       case Op_StrInflatedCopy:
3306       case Op_StrCompressedCopy:
3307       case Op_EncodeP:
3308       case Op_CastP2X:
3309       case Op_SafePoint:
3310       case Op_EncodeISOArray:
3311       case Op_AryEq:
3312       case Op_StrEquals:
3313       case Op_StrComp:
3314       case Op_StrIndexOf:
3315       case Op_StrIndexOfChar:
3316       case Op_HasNegatives:
3317         // Known to require barriers
3318         strength = STRONG;
3319         break;
3320       case Op_CmpP: {
3321         if (n-&gt;in(1)-&gt;bottom_type()-&gt;higher_equal(TypePtr::NULL_PTR) ||
3322             n-&gt;in(2)-&gt;bottom_type()-&gt;higher_equal(TypePtr::NULL_PTR)) {
3323           // One of the sides is known null, no need for barrier.
3324         } else {
3325           strength = STRONG;
3326         }
3327         break;
3328       }
3329       case Op_LoadB:
3330       case Op_LoadUB:
3331       case Op_LoadUS:
3332       case Op_LoadD:
3333       case Op_LoadF:
3334       case Op_LoadL:
3335       case Op_LoadI:
3336       case Op_LoadS:
3337       case Op_LoadN:
3338       case Op_LoadP:
3339       case Op_LoadVector: {
3340         const TypePtr* adr_type = n-&gt;adr_type();
3341         int alias_idx = Compile::current()-&gt;get_alias_index(adr_type);
3342         Compile::AliasType* alias_type = Compile::current()-&gt;alias_type(alias_idx);
3343         ciField* field = alias_type-&gt;field();
3344         bool is_static = field != NULL &amp;&amp; field-&gt;is_static();
3345         bool is_final = field != NULL &amp;&amp; field-&gt;is_final();
3346 
3347         if (ShenandoahOptimizeStaticFinals &amp;&amp; is_static &amp;&amp; is_final) {
3348           // Loading the constant does not require barriers: it should be handled
3349           // as part of GC roots already.
3350         } else {
3351           strength = STRONG;
3352         }
3353         break;
3354       }
3355       case Op_Conv2B:
3356       case Op_LoadRange:
3357       case Op_LoadKlass:
3358       case Op_LoadNKlass:
3359         // Do not require barriers
3360         break;
3361       case Op_AddP:
3362       case Op_CheckCastPP:
3363       case Op_CastPP:
3364       case Op_CMoveP:
3365       case Op_Phi:
3366       case Op_ShenandoahLoadReferenceBarrier:
3367         // Whether or not these need the barriers depends on their users
3368         visit_users = true;
3369         break;
3370       default: {
3371 #ifdef ASSERT
3372         fatal(&quot;Unknown node in get_barrier_strength: %s&quot;, NodeClassNames[n-&gt;Opcode()]);
3373 #else
3374         // Default to strong: better to have excess barriers, rather than miss some.
3375         strength = STRONG;
3376 #endif
3377       }
3378     }
3379 
3380     stack.pop();
3381     if (visit_users) {
3382       for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
3383         Node* user = n-&gt;fast_out(i);
3384         if (user != NULL) {
3385           stack.push(user, 0);
3386         }
3387       }
3388     }
3389   }
3390   return strength;
3391 }
3392 
3393 CallStaticJavaNode* ShenandoahLoadReferenceBarrierNode::pin_and_expand_null_check(PhaseIterGVN&amp; igvn) {
3394   Node* val = in(ValueIn);
3395 
3396   const Type* val_t = igvn.type(val);
3397 
3398   if (val_t-&gt;meet(TypePtr::NULL_PTR) != val_t &amp;&amp;
3399       val-&gt;Opcode() == Op_CastPP &amp;&amp;
3400       val-&gt;in(0) != NULL &amp;&amp;
3401       val-&gt;in(0)-&gt;Opcode() == Op_IfTrue &amp;&amp;
3402       val-&gt;in(0)-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none) &amp;&amp;
3403       val-&gt;in(0)-&gt;in(0)-&gt;is_If() &amp;&amp;
3404       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;Opcode() == Op_Bool &amp;&amp;
3405       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::ne &amp;&amp;
3406       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;Opcode() == Op_CmpP &amp;&amp;
3407       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;in(1) == val-&gt;in(1) &amp;&amp;
3408       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;bottom_type() == TypePtr::NULL_PTR) {
3409     assert(val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;in(1) == val-&gt;in(1), &quot;&quot;);
3410     CallStaticJavaNode* unc = val-&gt;in(0)-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none);
3411     return unc;
3412   }
3413   return NULL;
3414 }
    </pre>
  </body>
</html>