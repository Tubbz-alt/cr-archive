<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/shenandoah/shenandoahHeapRegion.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="shenandoahHeap.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahHeapRegion.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shenandoah/shenandoahHeapRegion.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
  2  * Copyright (c) 2013, 2019, Red Hat, Inc. All rights reserved.

  3  *
  4  * This code is free software; you can redistribute it and/or modify it
  5  * under the terms of the GNU General Public License version 2 only, as
  6  * published by the Free Software Foundation.
  7  *
  8  * This code is distributed in the hope that it will be useful, but WITHOUT
  9  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 10  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 11  * version 2 for more details (a copy is included in the LICENSE file that
 12  * accompanied this code).
 13  *
 14  * You should have received a copy of the GNU General Public License version
 15  * 2 along with this work; if not, write to the Free Software Foundation,
 16  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 17  *
 18  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 19  * or visit www.oracle.com if you need additional information or have any
 20  * questions.
 21  *
 22  */
 23 
 24 #include &quot;precompiled.hpp&quot;
 25 #include &quot;memory/allocation.hpp&quot;
<span class="line-removed"> 26 #include &quot;gc/shenandoah/shenandoahBrooksPointer.hpp&quot;</span>
 27 #include &quot;gc/shenandoah/shenandoahHeapRegionSet.inline.hpp&quot;
 28 #include &quot;gc/shenandoah/shenandoahHeap.inline.hpp&quot;
 29 #include &quot;gc/shenandoah/shenandoahHeapRegion.hpp&quot;
 30 #include &quot;gc/shenandoah/shenandoahMarkingContext.inline.hpp&quot;
 31 #include &quot;gc/shenandoah/shenandoahTraversalGC.hpp&quot;
 32 #include &quot;gc/shared/space.inline.hpp&quot;

 33 #include &quot;memory/iterator.inline.hpp&quot;
 34 #include &quot;memory/resourceArea.hpp&quot;
 35 #include &quot;memory/universe.hpp&quot;
 36 #include &quot;oops/oop.inline.hpp&quot;

 37 #include &quot;runtime/java.hpp&quot;
 38 #include &quot;runtime/mutexLocker.hpp&quot;
 39 #include &quot;runtime/os.hpp&quot;
 40 #include &quot;runtime/safepoint.hpp&quot;
 41 
 42 size_t ShenandoahHeapRegion::RegionCount = 0;
 43 size_t ShenandoahHeapRegion::RegionSizeBytes = 0;
 44 size_t ShenandoahHeapRegion::RegionSizeWords = 0;
 45 size_t ShenandoahHeapRegion::RegionSizeBytesShift = 0;
 46 size_t ShenandoahHeapRegion::RegionSizeWordsShift = 0;
 47 size_t ShenandoahHeapRegion::RegionSizeBytesMask = 0;
 48 size_t ShenandoahHeapRegion::RegionSizeWordsMask = 0;
 49 size_t ShenandoahHeapRegion::HumongousThresholdBytes = 0;
 50 size_t ShenandoahHeapRegion::HumongousThresholdWords = 0;
 51 size_t ShenandoahHeapRegion::MaxTLABSizeBytes = 0;
 52 size_t ShenandoahHeapRegion::MaxTLABSizeWords = 0;
 53 
 54 ShenandoahHeapRegion::PaddedAllocSeqNum ShenandoahHeapRegion::_alloc_seq_num;
 55 
 56 ShenandoahHeapRegion::ShenandoahHeapRegion(ShenandoahHeap* heap, HeapWord* start,
 57                                            size_t size_words, size_t index, bool committed) :
 58   _heap(heap),
 59   _reserved(MemRegion(start, size_words)),
 60   _region_number(index),
 61   _new_top(NULL),
<span class="line-removed"> 62   _critical_pins(0),</span>
 63   _empty_time(os::elapsedTime()),
 64   _state(committed ? _empty_committed : _empty_uncommitted),
 65   _tlab_allocs(0),
 66   _gclab_allocs(0),
 67   _shared_allocs(0),
 68   _seqnum_first_alloc_mutator(0),
 69   _seqnum_first_alloc_gc(0),
 70   _seqnum_last_alloc_mutator(0),
 71   _seqnum_last_alloc_gc(0),
<span class="line-modified"> 72   _live_data(0) {</span>

 73 
 74   ContiguousSpace::initialize(_reserved, true, committed);
 75 }
 76 
 77 size_t ShenandoahHeapRegion::region_number() const {
 78   return _region_number;
 79 }
 80 
 81 void ShenandoahHeapRegion::report_illegal_transition(const char *method) {
 82   ResourceMark rm;
 83   stringStream ss;
 84   ss.print(&quot;Illegal region state transition from \&quot;%s\&quot;, at %s\n  &quot;, region_state_to_string(_state), method);
 85   print_on(&amp;ss);
 86   fatal(&quot;%s&quot;, ss.as_string());
 87 }
 88 
 89 void ShenandoahHeapRegion::make_regular_allocation() {
 90   _heap-&gt;assert_heaplock_owned_by_current_thread();
 91 
 92   switch (_state) {
 93     case _empty_uncommitted:
 94       do_commit();
 95     case _empty_committed:
<span class="line-modified"> 96       _state = _regular;</span>
 97     case _regular:
 98     case _pinned:
 99       return;
100     default:
101       report_illegal_transition(&quot;regular allocation&quot;);
102   }
103 }
104 
105 void ShenandoahHeapRegion::make_regular_bypass() {
106   _heap-&gt;assert_heaplock_owned_by_current_thread();
107   assert (_heap-&gt;is_full_gc_in_progress() || _heap-&gt;is_degenerated_gc_in_progress(),
108           &quot;only for full or degen GC&quot;);
109 
110   switch (_state) {
111     case _empty_uncommitted:
112       do_commit();
113     case _empty_committed:
114     case _cset:
115     case _humongous_start:
116     case _humongous_cont:
<span class="line-modified">117       _state = _regular;</span>
118       return;
119     case _pinned_cset:
<span class="line-modified">120       _state = _pinned;</span>
121       return;
122     case _regular:
123     case _pinned:
124       return;
125     default:
126       report_illegal_transition(&quot;regular bypass&quot;);
127   }
128 }
129 
130 void ShenandoahHeapRegion::make_humongous_start() {
131   _heap-&gt;assert_heaplock_owned_by_current_thread();
132   switch (_state) {
133     case _empty_uncommitted:
134       do_commit();
135     case _empty_committed:
<span class="line-modified">136       _state = _humongous_start;</span>
137       return;
138     default:
139       report_illegal_transition(&quot;humongous start allocation&quot;);
140   }
141 }
142 
143 void ShenandoahHeapRegion::make_humongous_start_bypass() {
144   _heap-&gt;assert_heaplock_owned_by_current_thread();
145   assert (_heap-&gt;is_full_gc_in_progress(), &quot;only for full GC&quot;);
146 
147   switch (_state) {
148     case _empty_committed:
149     case _regular:
150     case _humongous_start:
151     case _humongous_cont:
<span class="line-modified">152       _state = _humongous_start;</span>
153       return;
154     default:
155       report_illegal_transition(&quot;humongous start bypass&quot;);
156   }
157 }
158 
159 void ShenandoahHeapRegion::make_humongous_cont() {
160   _heap-&gt;assert_heaplock_owned_by_current_thread();
161   switch (_state) {
162     case _empty_uncommitted:
163       do_commit();
164     case _empty_committed:
<span class="line-modified">165       _state = _humongous_cont;</span>
166       return;
167     default:
168       report_illegal_transition(&quot;humongous continuation allocation&quot;);
169   }
170 }
171 
172 void ShenandoahHeapRegion::make_humongous_cont_bypass() {
173   _heap-&gt;assert_heaplock_owned_by_current_thread();
174   assert (_heap-&gt;is_full_gc_in_progress(), &quot;only for full GC&quot;);
175 
176   switch (_state) {
177     case _empty_committed:
178     case _regular:
179     case _humongous_start:
180     case _humongous_cont:
<span class="line-modified">181       _state = _humongous_cont;</span>
182       return;
183     default:
184       report_illegal_transition(&quot;humongous continuation bypass&quot;);
185   }
186 }
187 
188 void ShenandoahHeapRegion::make_pinned() {
189   _heap-&gt;assert_heaplock_owned_by_current_thread();


190   switch (_state) {
191     case _regular:
<span class="line-modified">192       assert (_critical_pins == 0, &quot;sanity&quot;);</span>
<span class="line-removed">193       _state = _pinned;</span>
194     case _pinned_cset:
195     case _pinned:
<span class="line-removed">196       _critical_pins++;</span>
197       return;
198     case _humongous_start:
<span class="line-modified">199       assert (_critical_pins == 0, &quot;sanity&quot;);</span>
<span class="line-removed">200       _state = _pinned_humongous_start;</span>
201     case _pinned_humongous_start:
<span class="line-removed">202       _critical_pins++;</span>
203       return;
204     case _cset:
<span class="line-removed">205       guarantee(_heap-&gt;cancelled_gc(), &quot;only valid when evac has been cancelled&quot;);</span>
<span class="line-removed">206       assert (_critical_pins == 0, &quot;sanity&quot;);</span>
207       _state = _pinned_cset;
<span class="line-removed">208       _critical_pins++;</span>
209       return;
210     default:
211       report_illegal_transition(&quot;pinning&quot;);
212   }
213 }
214 
215 void ShenandoahHeapRegion::make_unpinned() {
216   _heap-&gt;assert_heaplock_owned_by_current_thread();


217   switch (_state) {
218     case _pinned:
<span class="line-modified">219       assert (_critical_pins &gt; 0, &quot;sanity&quot;);</span>
<span class="line-removed">220       _critical_pins--;</span>
<span class="line-removed">221       if (_critical_pins == 0) {</span>
<span class="line-removed">222         _state = _regular;</span>
<span class="line-removed">223       }</span>
224       return;
225     case _regular:
226     case _humongous_start:
<span class="line-removed">227       assert (_critical_pins == 0, &quot;sanity&quot;);</span>
228       return;
229     case _pinned_cset:
<span class="line-modified">230       guarantee(_heap-&gt;cancelled_gc(), &quot;only valid when evac has been cancelled&quot;);</span>
<span class="line-removed">231       assert (_critical_pins &gt; 0, &quot;sanity&quot;);</span>
<span class="line-removed">232       _critical_pins--;</span>
<span class="line-removed">233       if (_critical_pins == 0) {</span>
<span class="line-removed">234         _state = _cset;</span>
<span class="line-removed">235       }</span>
236       return;
237     case _pinned_humongous_start:
<span class="line-modified">238       assert (_critical_pins &gt; 0, &quot;sanity&quot;);</span>
<span class="line-removed">239       _critical_pins--;</span>
<span class="line-removed">240       if (_critical_pins == 0) {</span>
<span class="line-removed">241         _state = _humongous_start;</span>
<span class="line-removed">242       }</span>
243       return;
244     default:
245       report_illegal_transition(&quot;unpinning&quot;);
246   }
247 }
248 
249 void ShenandoahHeapRegion::make_cset() {
250   _heap-&gt;assert_heaplock_owned_by_current_thread();
251   switch (_state) {
252     case _regular:
<span class="line-modified">253       _state = _cset;</span>
254     case _cset:
255       return;
256     default:
257       report_illegal_transition(&quot;cset&quot;);
258   }
259 }
260 
261 void ShenandoahHeapRegion::make_trash() {
262   _heap-&gt;assert_heaplock_owned_by_current_thread();
263   switch (_state) {
264     case _cset:
265       // Reclaiming cset regions
266     case _humongous_start:
267     case _humongous_cont:
268       // Reclaiming humongous regions
269     case _regular:
270       // Immediate region reclaim
<span class="line-modified">271       _state = _trash;</span>
272       return;
273     default:
274       report_illegal_transition(&quot;trashing&quot;);
275   }
276 }
277 
278 void ShenandoahHeapRegion::make_trash_immediate() {
279   make_trash();
280 
281   // On this path, we know there are no marked objects in the region,
282   // tell marking context about it to bypass bitmap resets.
283   _heap-&gt;complete_marking_context()-&gt;reset_top_bitmap(this);
284 }
285 
286 void ShenandoahHeapRegion::make_empty() {
287   _heap-&gt;assert_heaplock_owned_by_current_thread();
288   switch (_state) {
289     case _trash:
<span class="line-modified">290       _state = _empty_committed;</span>
291       _empty_time = os::elapsedTime();
292       return;
293     default:
294       report_illegal_transition(&quot;emptying&quot;);
295   }
296 }
297 
298 void ShenandoahHeapRegion::make_uncommitted() {
299   _heap-&gt;assert_heaplock_owned_by_current_thread();
300   switch (_state) {
301     case _empty_committed:
302       do_uncommit();
<span class="line-modified">303       _state = _empty_uncommitted;</span>
304       return;
305     default:
306       report_illegal_transition(&quot;uncommiting&quot;);
307   }
308 }
309 
310 void ShenandoahHeapRegion::make_committed_bypass() {
311   _heap-&gt;assert_heaplock_owned_by_current_thread();
312   assert (_heap-&gt;is_full_gc_in_progress(), &quot;only for full GC&quot;);
313 
314   switch (_state) {
315     case _empty_uncommitted:
316       do_commit();
<span class="line-modified">317       _state = _empty_committed;</span>
318       return;
319     default:
320       report_illegal_transition(&quot;commit bypass&quot;);
321   }
322 }
323 
324 void ShenandoahHeapRegion::clear_live_data() {
<span class="line-modified">325   OrderAccess::release_store_fence&lt;size_t&gt;(&amp;_live_data, 0);</span>
326 }
327 
328 void ShenandoahHeapRegion::reset_alloc_metadata() {
329   _tlab_allocs = 0;
330   _gclab_allocs = 0;
331   _shared_allocs = 0;
332   _seqnum_first_alloc_mutator = 0;
333   _seqnum_last_alloc_mutator = 0;
334   _seqnum_first_alloc_gc = 0;
335   _seqnum_last_alloc_gc = 0;
336 }
337 
338 void ShenandoahHeapRegion::reset_alloc_metadata_to_shared() {
339   if (used() &gt; 0) {
340     _tlab_allocs = 0;
341     _gclab_allocs = 0;
342     _shared_allocs = used() &gt;&gt; LogHeapWordSize;
343     uint64_t next = _alloc_seq_num.value++;
344     _seqnum_first_alloc_mutator = next;
345     _seqnum_last_alloc_mutator = next;
</pre>
<hr />
<pre>
351 }
352 
353 size_t ShenandoahHeapRegion::get_shared_allocs() const {
354   return _shared_allocs * HeapWordSize;
355 }
356 
357 size_t ShenandoahHeapRegion::get_tlab_allocs() const {
358   return _tlab_allocs * HeapWordSize;
359 }
360 
361 size_t ShenandoahHeapRegion::get_gclab_allocs() const {
362   return _gclab_allocs * HeapWordSize;
363 }
364 
365 void ShenandoahHeapRegion::set_live_data(size_t s) {
366   assert(Thread::current()-&gt;is_VM_thread(), &quot;by VM thread&quot;);
367   _live_data = (s &gt;&gt; LogHeapWordSize);
368 }
369 
370 size_t ShenandoahHeapRegion::get_live_data_words() const {
<span class="line-modified">371   return OrderAccess::load_acquire(&amp;_live_data);</span>
372 }
373 
374 size_t ShenandoahHeapRegion::get_live_data_bytes() const {
375   return get_live_data_words() * HeapWordSize;
376 }
377 
378 bool ShenandoahHeapRegion::has_live() const {
379   return get_live_data_words() != 0;
380 }
381 
382 size_t ShenandoahHeapRegion::garbage() const {
383   assert(used() &gt;= get_live_data_bytes(), &quot;Live Data must be a subset of used() live: &quot; SIZE_FORMAT &quot; used: &quot; SIZE_FORMAT,
384          get_live_data_bytes(), used());
385 
386   size_t result = used() - get_live_data_bytes();
387   return result;
388 }
389 
390 void ShenandoahHeapRegion::print_on(outputStream* st) const {
391   st-&gt;print(&quot;|&quot;);
</pre>
<hr />
<pre>
417       st-&gt;print(&quot;|T  &quot;);
418       break;
419     case _pinned:
420       st-&gt;print(&quot;|P  &quot;);
421       break;
422     case _pinned_cset:
423       st-&gt;print(&quot;|CSP&quot;);
424       break;
425     default:
426       ShouldNotReachHere();
427   }
428   st-&gt;print(&quot;|BTE &quot; INTPTR_FORMAT_W(12) &quot;, &quot; INTPTR_FORMAT_W(12) &quot;, &quot; INTPTR_FORMAT_W(12),
429             p2i(bottom()), p2i(top()), p2i(end()));
430   st-&gt;print(&quot;|TAMS &quot; INTPTR_FORMAT_W(12),
431             p2i(_heap-&gt;marking_context()-&gt;top_at_mark_start(const_cast&lt;ShenandoahHeapRegion*&gt;(this))));
432   st-&gt;print(&quot;|U &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(used()),                proper_unit_for_byte_size(used()));
433   st-&gt;print(&quot;|T &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(get_tlab_allocs()),     proper_unit_for_byte_size(get_tlab_allocs()));
434   st-&gt;print(&quot;|G &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(get_gclab_allocs()),    proper_unit_for_byte_size(get_gclab_allocs()));
435   st-&gt;print(&quot;|S &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(get_shared_allocs()),   proper_unit_for_byte_size(get_shared_allocs()));
436   st-&gt;print(&quot;|L &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(get_live_data_bytes()), proper_unit_for_byte_size(get_live_data_bytes()));
<span class="line-modified">437   st-&gt;print(&quot;|CP &quot; SIZE_FORMAT_W(3), _critical_pins);</span>
438   st-&gt;print(&quot;|SN &quot; UINT64_FORMAT_X_W(12) &quot;, &quot; UINT64_FORMAT_X_W(8) &quot;, &quot; UINT64_FORMAT_X_W(8) &quot;, &quot; UINT64_FORMAT_X_W(8),
439             seqnum_first_alloc_mutator(), seqnum_last_alloc_mutator(),
440             seqnum_first_alloc_gc(), seqnum_last_alloc_gc());
441   st-&gt;cr();
442 }
443 
444 void ShenandoahHeapRegion::oop_iterate(OopIterateClosure* blk) {
445   if (!is_active()) return;
446   if (is_humongous()) {
447     oop_iterate_humongous(blk);
448   } else {
449     oop_iterate_objects(blk);
450   }
451 }
452 
453 void ShenandoahHeapRegion::oop_iterate_objects(OopIterateClosure* blk) {
454   assert(! is_humongous(), &quot;no humongous region here&quot;);
<span class="line-modified">455   HeapWord* obj_addr = bottom() + ShenandoahBrooksPointer::word_size();</span>
456   HeapWord* t = top();
457   // Could call objects iterate, but this is easier.
458   while (obj_addr &lt; t) {
459     oop obj = oop(obj_addr);
<span class="line-modified">460     obj_addr += obj-&gt;oop_iterate_size(blk) + ShenandoahBrooksPointer::word_size();</span>
461   }
462 }
463 
464 void ShenandoahHeapRegion::oop_iterate_humongous(OopIterateClosure* blk) {
465   assert(is_humongous(), &quot;only humongous region here&quot;);
466   // Find head.
467   ShenandoahHeapRegion* r = humongous_start_region();
468   assert(r-&gt;is_humongous_start(), &quot;need humongous head here&quot;);
<span class="line-modified">469   oop obj = oop(r-&gt;bottom() + ShenandoahBrooksPointer::word_size());</span>
470   obj-&gt;oop_iterate(blk, MemRegion(bottom(), top()));
471 }
472 
473 ShenandoahHeapRegion* ShenandoahHeapRegion::humongous_start_region() const {
474   assert(is_humongous(), &quot;Must be a part of the humongous region&quot;);
475   size_t reg_num = region_number();
476   ShenandoahHeapRegion* r = const_cast&lt;ShenandoahHeapRegion*&gt;(this);
477   while (!r-&gt;is_humongous_start()) {
478     assert(reg_num &gt; 0, &quot;Sanity&quot;);
479     reg_num --;
480     r = _heap-&gt;get_region(reg_num);
481     assert(r-&gt;is_humongous(), &quot;Must be a part of the humongous region&quot;);
482   }
483   assert(r-&gt;is_humongous_start(), &quot;Must be&quot;);
484   return r;
485 }
486 
487 void ShenandoahHeapRegion::recycle() {
488   ContiguousSpace::clear(false);
489   if (ZapUnusedHeapArea) {
490     ContiguousSpace::mangle_unused_area_complete();
491   }
492   clear_live_data();
493 
494   reset_alloc_metadata();
495 
496   _heap-&gt;marking_context()-&gt;reset_top_at_mark_start(this);
497 
498   make_empty();
499 }
500 
501 HeapWord* ShenandoahHeapRegion::block_start_const(const void* p) const {
502   assert(MemRegion(bottom(), end()).contains(p),
503          &quot;p (&quot; PTR_FORMAT &quot;) not in space [&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT &quot;)&quot;,
504          p2i(p), p2i(bottom()), p2i(end()));
505   if (p &gt;= top()) {
506     return top();
507   } else {
<span class="line-modified">508     HeapWord* last = bottom() + ShenandoahBrooksPointer::word_size();</span>
509     HeapWord* cur = last;
510     while (cur &lt;= p) {
511       last = cur;
<span class="line-modified">512       cur += oop(cur)-&gt;size() + ShenandoahBrooksPointer::word_size();</span>
513     }
514     shenandoah_assert_correct(NULL, oop(last));
515     return last;
516   }
517 }
518 
<span class="line-modified">519 void ShenandoahHeapRegion::setup_sizes(size_t initial_heap_size, size_t max_heap_size) {</span>
520   // Absolute minimums we should not ever break.
521   static const size_t MIN_REGION_SIZE = 256*K;
522 
523   if (FLAG_IS_DEFAULT(ShenandoahMinRegionSize)) {
524     FLAG_SET_DEFAULT(ShenandoahMinRegionSize, MIN_REGION_SIZE);
525   }
526 
527   size_t region_size;
528   if (FLAG_IS_DEFAULT(ShenandoahHeapRegionSize)) {
<span class="line-modified">529     if (ShenandoahMinRegionSize &gt; initial_heap_size / MIN_NUM_REGIONS) {</span>
<span class="line-modified">530       err_msg message(&quot;Initial heap size (&quot; SIZE_FORMAT &quot;K) is too low to afford the minimum number &quot;</span>
<span class="line-modified">531                       &quot;of regions (&quot; SIZE_FORMAT &quot;) of minimum region size (&quot; SIZE_FORMAT &quot;K).&quot;,</span>
<span class="line-modified">532                       initial_heap_size/K, MIN_NUM_REGIONS, ShenandoahMinRegionSize/K);</span>


533       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMinRegionSize option&quot;, message);
534     }
535     if (ShenandoahMinRegionSize &lt; MIN_REGION_SIZE) {
<span class="line-modified">536       err_msg message(&quot;&quot; SIZE_FORMAT &quot;K should not be lower than minimum region size (&quot; SIZE_FORMAT &quot;K).&quot;,</span>
<span class="line-modified">537                       ShenandoahMinRegionSize/K,  MIN_REGION_SIZE/K);</span>

538       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMinRegionSize option&quot;, message);
539     }
540     if (ShenandoahMinRegionSize &lt; MinTLABSize) {
<span class="line-modified">541       err_msg message(&quot;&quot; SIZE_FORMAT &quot;K should not be lower than TLAB size size (&quot; SIZE_FORMAT &quot;K).&quot;,</span>
<span class="line-modified">542                       ShenandoahMinRegionSize/K,  MinTLABSize/K);</span>

543       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMinRegionSize option&quot;, message);
544     }
545     if (ShenandoahMaxRegionSize &lt; MIN_REGION_SIZE) {
<span class="line-modified">546       err_msg message(&quot;&quot; SIZE_FORMAT &quot;K should not be lower than min region size (&quot; SIZE_FORMAT &quot;K).&quot;,</span>
<span class="line-modified">547                       ShenandoahMaxRegionSize/K,  MIN_REGION_SIZE/K);</span>

548       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMaxRegionSize option&quot;, message);
549     }
550     if (ShenandoahMinRegionSize &gt; ShenandoahMaxRegionSize) {
<span class="line-modified">551       err_msg message(&quot;Minimum (&quot; SIZE_FORMAT &quot;K) should be larger than maximum (&quot; SIZE_FORMAT &quot;K).&quot;,</span>
<span class="line-modified">552                       ShenandoahMinRegionSize/K, ShenandoahMaxRegionSize/K);</span>

553       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMinRegionSize or -XX:ShenandoahMaxRegionSize&quot;, message);
554     }
555 
556     // We rapidly expand to max_heap_size in most scenarios, so that is the measure
557     // for usual heap sizes. Do not depend on initial_heap_size here.
558     region_size = max_heap_size / ShenandoahTargetNumRegions;
559 
560     // Now make sure that we don&#39;t go over or under our limits.
561     region_size = MAX2(ShenandoahMinRegionSize, region_size);
562     region_size = MIN2(ShenandoahMaxRegionSize, region_size);
563 
564   } else {
<span class="line-modified">565     if (ShenandoahHeapRegionSize &gt; initial_heap_size / MIN_NUM_REGIONS) {</span>
<span class="line-modified">566       err_msg message(&quot;Initial heap size (&quot; SIZE_FORMAT &quot;K) is too low to afford the minimum number &quot;</span>
<span class="line-modified">567                               &quot;of regions (&quot; SIZE_FORMAT &quot;) of requested size (&quot; SIZE_FORMAT &quot;K).&quot;,</span>
<span class="line-modified">568                       initial_heap_size/K, MIN_NUM_REGIONS, ShenandoahHeapRegionSize/K);</span>


569       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahHeapRegionSize option&quot;, message);
570     }
571     if (ShenandoahHeapRegionSize &lt; ShenandoahMinRegionSize) {
<span class="line-modified">572       err_msg message(&quot;Heap region size (&quot; SIZE_FORMAT &quot;K) should be larger than min region size (&quot; SIZE_FORMAT &quot;K).&quot;,</span>
<span class="line-modified">573                       ShenandoahHeapRegionSize/K, ShenandoahMinRegionSize/K);</span>

574       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahHeapRegionSize option&quot;, message);
575     }
576     if (ShenandoahHeapRegionSize &gt; ShenandoahMaxRegionSize) {
<span class="line-modified">577       err_msg message(&quot;Heap region size (&quot; SIZE_FORMAT &quot;K) should be lower than max region size (&quot; SIZE_FORMAT &quot;K).&quot;,</span>
<span class="line-modified">578                       ShenandoahHeapRegionSize/K, ShenandoahMaxRegionSize/K);</span>

579       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahHeapRegionSize option&quot;, message);
580     }
581     region_size = ShenandoahHeapRegionSize;
582   }
583 
584   // Make sure region size is at least one large page, if enabled.
585   // Otherwise, uncommitting one region may falsely uncommit the adjacent
586   // regions too.
587   // Also see shenandoahArguments.cpp, where it handles UseLargePages.
588   if (UseLargePages &amp;&amp; ShenandoahUncommit) {
589     region_size = MAX2(region_size, os::large_page_size());
590   }
591 
592   int region_size_log = log2_long((jlong) region_size);
593   // Recalculate the region size to make sure it&#39;s a power of
594   // 2. This means that region_size is the largest power of 2 that&#39;s
595   // &lt;= what we&#39;ve calculated so far.
596   region_size = size_t(1) &lt;&lt; region_size_log;
597 
598   // Now, set up the globals.
</pre>
<hr />
<pre>
602   guarantee(RegionSizeWordsShift == 0, &quot;we should only set it once&quot;);
603   RegionSizeWordsShift = RegionSizeBytesShift - LogHeapWordSize;
604 
605   guarantee(RegionSizeBytes == 0, &quot;we should only set it once&quot;);
606   RegionSizeBytes = region_size;
607   RegionSizeWords = RegionSizeBytes &gt;&gt; LogHeapWordSize;
608   assert (RegionSizeWords*HeapWordSize == RegionSizeBytes, &quot;sanity&quot;);
609 
610   guarantee(RegionSizeWordsMask == 0, &quot;we should only set it once&quot;);
611   RegionSizeWordsMask = RegionSizeWords - 1;
612 
613   guarantee(RegionSizeBytesMask == 0, &quot;we should only set it once&quot;);
614   RegionSizeBytesMask = RegionSizeBytes - 1;
615 
616   guarantee(RegionCount == 0, &quot;we should only set it once&quot;);
617   RegionCount = max_heap_size / RegionSizeBytes;
618   guarantee(RegionCount &gt;= MIN_NUM_REGIONS, &quot;Should have at least minimum regions&quot;);
619 
620   guarantee(HumongousThresholdWords == 0, &quot;we should only set it once&quot;);
621   HumongousThresholdWords = RegionSizeWords * ShenandoahHumongousThreshold / 100;

622   assert (HumongousThresholdWords &lt;= RegionSizeWords, &quot;sanity&quot;);
623 
624   guarantee(HumongousThresholdBytes == 0, &quot;we should only set it once&quot;);
625   HumongousThresholdBytes = HumongousThresholdWords * HeapWordSize;
626   assert (HumongousThresholdBytes &lt;= RegionSizeBytes, &quot;sanity&quot;);
627 
628   // The rationale for trimming the TLAB sizes has to do with the raciness in
629   // TLAB allocation machinery. It may happen that TLAB sizing policy polls Shenandoah
630   // about next free size, gets the answer for region #N, goes away for a while, then
631   // tries to allocate in region #N, and fail because some other thread have claimed part
632   // of the region #N, and then the freeset allocation code has to retire the region #N,
633   // before moving the allocation to region #N+1.
634   //
635   // The worst case realizes when &quot;answer&quot; is &quot;region size&quot;, which means it could
636   // prematurely retire an entire region. Having smaller TLABs does not fix that
637   // completely, but reduces the probability of too wasteful region retirement.
638   // With current divisor, we will waste no more than 1/8 of region size in the worst
639   // case. This also has a secondary effect on collection set selection: even under
640   // the race, the regions would be at least 7/8 used, which allows relying on
641   // &quot;used&quot; - &quot;live&quot; for cset selection. Otherwise, we can get the fragmented region
642   // below the garbage threshold that would never be considered for collection.
643   //
644   // The whole thing is mitigated if Elastic TLABs are enabled.
645   //




646   guarantee(MaxTLABSizeBytes == 0, &quot;we should only set it once&quot;);
<span class="line-modified">647   MaxTLABSizeBytes = MIN2(ShenandoahElasticTLAB ? RegionSizeBytes : (RegionSizeBytes / 8), HumongousThresholdBytes);</span>
648   assert (MaxTLABSizeBytes &gt; MinTLABSize, &quot;should be larger&quot;);
649 
<span class="line-removed">650   guarantee(MaxTLABSizeWords == 0, &quot;we should only set it once&quot;);</span>
<span class="line-removed">651   MaxTLABSizeWords = MaxTLABSizeBytes / HeapWordSize;</span>
<span class="line-removed">652 </span>
653   log_info(gc, init)(&quot;Regions: &quot; SIZE_FORMAT &quot; x &quot; SIZE_FORMAT &quot;%s&quot;,
654                      RegionCount, byte_size_in_proper_unit(RegionSizeBytes), proper_unit_for_byte_size(RegionSizeBytes));
655   log_info(gc, init)(&quot;Humongous object threshold: &quot; SIZE_FORMAT &quot;%s&quot;,
656                      byte_size_in_proper_unit(HumongousThresholdBytes), proper_unit_for_byte_size(HumongousThresholdBytes));
657   log_info(gc, init)(&quot;Max TLAB size: &quot; SIZE_FORMAT &quot;%s&quot;,
658                      byte_size_in_proper_unit(MaxTLABSizeBytes), proper_unit_for_byte_size(MaxTLABSizeBytes));
659 }
660 
661 void ShenandoahHeapRegion::do_commit() {
662   if (!_heap-&gt;is_heap_region_special() &amp;&amp; !os::commit_memory((char *) _reserved.start(), _reserved.byte_size(), false)) {
663     report_java_out_of_memory(&quot;Unable to commit region&quot;);
664   }
665   if (!_heap-&gt;commit_bitmap_slice(this)) {
666     report_java_out_of_memory(&quot;Unable to commit bitmaps for region&quot;);
667   }
668   _heap-&gt;increase_committed(ShenandoahHeapRegion::region_size_bytes());
669 }
670 
671 void ShenandoahHeapRegion::do_uncommit() {
672   if (!_heap-&gt;is_heap_region_special() &amp;&amp; !os::uncommit_memory((char *) _reserved.start(), _reserved.byte_size())) {
673     report_java_out_of_memory(&quot;Unable to uncommit region&quot;);
674   }
675   if (!_heap-&gt;uncommit_bitmap_slice(this)) {
676     report_java_out_of_memory(&quot;Unable to uncommit bitmaps for region&quot;);
677   }
678   _heap-&gt;decrease_committed(ShenandoahHeapRegion::region_size_bytes());
679 }


























</pre>
</td>
<td>
<hr />
<pre>
  1 /*
  2  * Copyright (c) 2013, 2019, Red Hat, Inc. All rights reserved.
<span class="line-added">  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.</span>
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;memory/allocation.hpp&quot;

 27 #include &quot;gc/shenandoah/shenandoahHeapRegionSet.inline.hpp&quot;
 28 #include &quot;gc/shenandoah/shenandoahHeap.inline.hpp&quot;
 29 #include &quot;gc/shenandoah/shenandoahHeapRegion.hpp&quot;
 30 #include &quot;gc/shenandoah/shenandoahMarkingContext.inline.hpp&quot;
 31 #include &quot;gc/shenandoah/shenandoahTraversalGC.hpp&quot;
 32 #include &quot;gc/shared/space.inline.hpp&quot;
<span class="line-added"> 33 #include &quot;jfr/jfrEvents.hpp&quot;</span>
 34 #include &quot;memory/iterator.inline.hpp&quot;
 35 #include &quot;memory/resourceArea.hpp&quot;
 36 #include &quot;memory/universe.hpp&quot;
 37 #include &quot;oops/oop.inline.hpp&quot;
<span class="line-added"> 38 #include &quot;runtime/atomic.hpp&quot;</span>
 39 #include &quot;runtime/java.hpp&quot;
 40 #include &quot;runtime/mutexLocker.hpp&quot;
 41 #include &quot;runtime/os.hpp&quot;
 42 #include &quot;runtime/safepoint.hpp&quot;
 43 
 44 size_t ShenandoahHeapRegion::RegionCount = 0;
 45 size_t ShenandoahHeapRegion::RegionSizeBytes = 0;
 46 size_t ShenandoahHeapRegion::RegionSizeWords = 0;
 47 size_t ShenandoahHeapRegion::RegionSizeBytesShift = 0;
 48 size_t ShenandoahHeapRegion::RegionSizeWordsShift = 0;
 49 size_t ShenandoahHeapRegion::RegionSizeBytesMask = 0;
 50 size_t ShenandoahHeapRegion::RegionSizeWordsMask = 0;
 51 size_t ShenandoahHeapRegion::HumongousThresholdBytes = 0;
 52 size_t ShenandoahHeapRegion::HumongousThresholdWords = 0;
 53 size_t ShenandoahHeapRegion::MaxTLABSizeBytes = 0;
 54 size_t ShenandoahHeapRegion::MaxTLABSizeWords = 0;
 55 
 56 ShenandoahHeapRegion::PaddedAllocSeqNum ShenandoahHeapRegion::_alloc_seq_num;
 57 
 58 ShenandoahHeapRegion::ShenandoahHeapRegion(ShenandoahHeap* heap, HeapWord* start,
 59                                            size_t size_words, size_t index, bool committed) :
 60   _heap(heap),
 61   _reserved(MemRegion(start, size_words)),
 62   _region_number(index),
 63   _new_top(NULL),

 64   _empty_time(os::elapsedTime()),
 65   _state(committed ? _empty_committed : _empty_uncommitted),
 66   _tlab_allocs(0),
 67   _gclab_allocs(0),
 68   _shared_allocs(0),
 69   _seqnum_first_alloc_mutator(0),
 70   _seqnum_first_alloc_gc(0),
 71   _seqnum_last_alloc_mutator(0),
 72   _seqnum_last_alloc_gc(0),
<span class="line-modified"> 73   _live_data(0),</span>
<span class="line-added"> 74   _critical_pins(0) {</span>
 75 
 76   ContiguousSpace::initialize(_reserved, true, committed);
 77 }
 78 
 79 size_t ShenandoahHeapRegion::region_number() const {
 80   return _region_number;
 81 }
 82 
 83 void ShenandoahHeapRegion::report_illegal_transition(const char *method) {
 84   ResourceMark rm;
 85   stringStream ss;
 86   ss.print(&quot;Illegal region state transition from \&quot;%s\&quot;, at %s\n  &quot;, region_state_to_string(_state), method);
 87   print_on(&amp;ss);
 88   fatal(&quot;%s&quot;, ss.as_string());
 89 }
 90 
 91 void ShenandoahHeapRegion::make_regular_allocation() {
 92   _heap-&gt;assert_heaplock_owned_by_current_thread();
 93 
 94   switch (_state) {
 95     case _empty_uncommitted:
 96       do_commit();
 97     case _empty_committed:
<span class="line-modified"> 98       set_state(_regular);</span>
 99     case _regular:
100     case _pinned:
101       return;
102     default:
103       report_illegal_transition(&quot;regular allocation&quot;);
104   }
105 }
106 
107 void ShenandoahHeapRegion::make_regular_bypass() {
108   _heap-&gt;assert_heaplock_owned_by_current_thread();
109   assert (_heap-&gt;is_full_gc_in_progress() || _heap-&gt;is_degenerated_gc_in_progress(),
110           &quot;only for full or degen GC&quot;);
111 
112   switch (_state) {
113     case _empty_uncommitted:
114       do_commit();
115     case _empty_committed:
116     case _cset:
117     case _humongous_start:
118     case _humongous_cont:
<span class="line-modified">119       set_state(_regular);</span>
120       return;
121     case _pinned_cset:
<span class="line-modified">122       set_state(_pinned);</span>
123       return;
124     case _regular:
125     case _pinned:
126       return;
127     default:
128       report_illegal_transition(&quot;regular bypass&quot;);
129   }
130 }
131 
132 void ShenandoahHeapRegion::make_humongous_start() {
133   _heap-&gt;assert_heaplock_owned_by_current_thread();
134   switch (_state) {
135     case _empty_uncommitted:
136       do_commit();
137     case _empty_committed:
<span class="line-modified">138       set_state(_humongous_start);</span>
139       return;
140     default:
141       report_illegal_transition(&quot;humongous start allocation&quot;);
142   }
143 }
144 
145 void ShenandoahHeapRegion::make_humongous_start_bypass() {
146   _heap-&gt;assert_heaplock_owned_by_current_thread();
147   assert (_heap-&gt;is_full_gc_in_progress(), &quot;only for full GC&quot;);
148 
149   switch (_state) {
150     case _empty_committed:
151     case _regular:
152     case _humongous_start:
153     case _humongous_cont:
<span class="line-modified">154       set_state(_humongous_start);</span>
155       return;
156     default:
157       report_illegal_transition(&quot;humongous start bypass&quot;);
158   }
159 }
160 
161 void ShenandoahHeapRegion::make_humongous_cont() {
162   _heap-&gt;assert_heaplock_owned_by_current_thread();
163   switch (_state) {
164     case _empty_uncommitted:
165       do_commit();
166     case _empty_committed:
<span class="line-modified">167      set_state(_humongous_cont);</span>
168       return;
169     default:
170       report_illegal_transition(&quot;humongous continuation allocation&quot;);
171   }
172 }
173 
174 void ShenandoahHeapRegion::make_humongous_cont_bypass() {
175   _heap-&gt;assert_heaplock_owned_by_current_thread();
176   assert (_heap-&gt;is_full_gc_in_progress(), &quot;only for full GC&quot;);
177 
178   switch (_state) {
179     case _empty_committed:
180     case _regular:
181     case _humongous_start:
182     case _humongous_cont:
<span class="line-modified">183       set_state(_humongous_cont);</span>
184       return;
185     default:
186       report_illegal_transition(&quot;humongous continuation bypass&quot;);
187   }
188 }
189 
190 void ShenandoahHeapRegion::make_pinned() {
191   _heap-&gt;assert_heaplock_owned_by_current_thread();
<span class="line-added">192   assert(pin_count() &gt; 0, &quot;Should have pins: &quot; SIZE_FORMAT, pin_count());</span>
<span class="line-added">193 </span>
194   switch (_state) {
195     case _regular:
<span class="line-modified">196       set_state(_pinned);</span>

197     case _pinned_cset:
198     case _pinned:

199       return;
200     case _humongous_start:
<span class="line-modified">201       set_state(_pinned_humongous_start);</span>

202     case _pinned_humongous_start:

203       return;
204     case _cset:


205       _state = _pinned_cset;

206       return;
207     default:
208       report_illegal_transition(&quot;pinning&quot;);
209   }
210 }
211 
212 void ShenandoahHeapRegion::make_unpinned() {
213   _heap-&gt;assert_heaplock_owned_by_current_thread();
<span class="line-added">214   assert(pin_count() == 0, &quot;Should not have pins: &quot; SIZE_FORMAT, pin_count());</span>
<span class="line-added">215 </span>
216   switch (_state) {
217     case _pinned:
<span class="line-modified">218       set_state(_regular);</span>




219       return;
220     case _regular:
221     case _humongous_start:

222       return;
223     case _pinned_cset:
<span class="line-modified">224       set_state(_cset);</span>





225       return;
226     case _pinned_humongous_start:
<span class="line-modified">227       set_state(_humongous_start);</span>




228       return;
229     default:
230       report_illegal_transition(&quot;unpinning&quot;);
231   }
232 }
233 
234 void ShenandoahHeapRegion::make_cset() {
235   _heap-&gt;assert_heaplock_owned_by_current_thread();
236   switch (_state) {
237     case _regular:
<span class="line-modified">238       set_state(_cset);</span>
239     case _cset:
240       return;
241     default:
242       report_illegal_transition(&quot;cset&quot;);
243   }
244 }
245 
246 void ShenandoahHeapRegion::make_trash() {
247   _heap-&gt;assert_heaplock_owned_by_current_thread();
248   switch (_state) {
249     case _cset:
250       // Reclaiming cset regions
251     case _humongous_start:
252     case _humongous_cont:
253       // Reclaiming humongous regions
254     case _regular:
255       // Immediate region reclaim
<span class="line-modified">256       set_state(_trash);</span>
257       return;
258     default:
259       report_illegal_transition(&quot;trashing&quot;);
260   }
261 }
262 
263 void ShenandoahHeapRegion::make_trash_immediate() {
264   make_trash();
265 
266   // On this path, we know there are no marked objects in the region,
267   // tell marking context about it to bypass bitmap resets.
268   _heap-&gt;complete_marking_context()-&gt;reset_top_bitmap(this);
269 }
270 
271 void ShenandoahHeapRegion::make_empty() {
272   _heap-&gt;assert_heaplock_owned_by_current_thread();
273   switch (_state) {
274     case _trash:
<span class="line-modified">275       set_state(_empty_committed);</span>
276       _empty_time = os::elapsedTime();
277       return;
278     default:
279       report_illegal_transition(&quot;emptying&quot;);
280   }
281 }
282 
283 void ShenandoahHeapRegion::make_uncommitted() {
284   _heap-&gt;assert_heaplock_owned_by_current_thread();
285   switch (_state) {
286     case _empty_committed:
287       do_uncommit();
<span class="line-modified">288       set_state(_empty_uncommitted);</span>
289       return;
290     default:
291       report_illegal_transition(&quot;uncommiting&quot;);
292   }
293 }
294 
295 void ShenandoahHeapRegion::make_committed_bypass() {
296   _heap-&gt;assert_heaplock_owned_by_current_thread();
297   assert (_heap-&gt;is_full_gc_in_progress(), &quot;only for full GC&quot;);
298 
299   switch (_state) {
300     case _empty_uncommitted:
301       do_commit();
<span class="line-modified">302       set_state(_empty_committed);</span>
303       return;
304     default:
305       report_illegal_transition(&quot;commit bypass&quot;);
306   }
307 }
308 
309 void ShenandoahHeapRegion::clear_live_data() {
<span class="line-modified">310   Atomic::release_store_fence(&amp;_live_data, (size_t)0);</span>
311 }
312 
313 void ShenandoahHeapRegion::reset_alloc_metadata() {
314   _tlab_allocs = 0;
315   _gclab_allocs = 0;
316   _shared_allocs = 0;
317   _seqnum_first_alloc_mutator = 0;
318   _seqnum_last_alloc_mutator = 0;
319   _seqnum_first_alloc_gc = 0;
320   _seqnum_last_alloc_gc = 0;
321 }
322 
323 void ShenandoahHeapRegion::reset_alloc_metadata_to_shared() {
324   if (used() &gt; 0) {
325     _tlab_allocs = 0;
326     _gclab_allocs = 0;
327     _shared_allocs = used() &gt;&gt; LogHeapWordSize;
328     uint64_t next = _alloc_seq_num.value++;
329     _seqnum_first_alloc_mutator = next;
330     _seqnum_last_alloc_mutator = next;
</pre>
<hr />
<pre>
336 }
337 
338 size_t ShenandoahHeapRegion::get_shared_allocs() const {
339   return _shared_allocs * HeapWordSize;
340 }
341 
342 size_t ShenandoahHeapRegion::get_tlab_allocs() const {
343   return _tlab_allocs * HeapWordSize;
344 }
345 
346 size_t ShenandoahHeapRegion::get_gclab_allocs() const {
347   return _gclab_allocs * HeapWordSize;
348 }
349 
350 void ShenandoahHeapRegion::set_live_data(size_t s) {
351   assert(Thread::current()-&gt;is_VM_thread(), &quot;by VM thread&quot;);
352   _live_data = (s &gt;&gt; LogHeapWordSize);
353 }
354 
355 size_t ShenandoahHeapRegion::get_live_data_words() const {
<span class="line-modified">356   return Atomic::load_acquire(&amp;_live_data);</span>
357 }
358 
359 size_t ShenandoahHeapRegion::get_live_data_bytes() const {
360   return get_live_data_words() * HeapWordSize;
361 }
362 
363 bool ShenandoahHeapRegion::has_live() const {
364   return get_live_data_words() != 0;
365 }
366 
367 size_t ShenandoahHeapRegion::garbage() const {
368   assert(used() &gt;= get_live_data_bytes(), &quot;Live Data must be a subset of used() live: &quot; SIZE_FORMAT &quot; used: &quot; SIZE_FORMAT,
369          get_live_data_bytes(), used());
370 
371   size_t result = used() - get_live_data_bytes();
372   return result;
373 }
374 
375 void ShenandoahHeapRegion::print_on(outputStream* st) const {
376   st-&gt;print(&quot;|&quot;);
</pre>
<hr />
<pre>
402       st-&gt;print(&quot;|T  &quot;);
403       break;
404     case _pinned:
405       st-&gt;print(&quot;|P  &quot;);
406       break;
407     case _pinned_cset:
408       st-&gt;print(&quot;|CSP&quot;);
409       break;
410     default:
411       ShouldNotReachHere();
412   }
413   st-&gt;print(&quot;|BTE &quot; INTPTR_FORMAT_W(12) &quot;, &quot; INTPTR_FORMAT_W(12) &quot;, &quot; INTPTR_FORMAT_W(12),
414             p2i(bottom()), p2i(top()), p2i(end()));
415   st-&gt;print(&quot;|TAMS &quot; INTPTR_FORMAT_W(12),
416             p2i(_heap-&gt;marking_context()-&gt;top_at_mark_start(const_cast&lt;ShenandoahHeapRegion*&gt;(this))));
417   st-&gt;print(&quot;|U &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(used()),                proper_unit_for_byte_size(used()));
418   st-&gt;print(&quot;|T &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(get_tlab_allocs()),     proper_unit_for_byte_size(get_tlab_allocs()));
419   st-&gt;print(&quot;|G &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(get_gclab_allocs()),    proper_unit_for_byte_size(get_gclab_allocs()));
420   st-&gt;print(&quot;|S &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(get_shared_allocs()),   proper_unit_for_byte_size(get_shared_allocs()));
421   st-&gt;print(&quot;|L &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(get_live_data_bytes()), proper_unit_for_byte_size(get_live_data_bytes()));
<span class="line-modified">422   st-&gt;print(&quot;|CP &quot; SIZE_FORMAT_W(3), pin_count());</span>
423   st-&gt;print(&quot;|SN &quot; UINT64_FORMAT_X_W(12) &quot;, &quot; UINT64_FORMAT_X_W(8) &quot;, &quot; UINT64_FORMAT_X_W(8) &quot;, &quot; UINT64_FORMAT_X_W(8),
424             seqnum_first_alloc_mutator(), seqnum_last_alloc_mutator(),
425             seqnum_first_alloc_gc(), seqnum_last_alloc_gc());
426   st-&gt;cr();
427 }
428 
429 void ShenandoahHeapRegion::oop_iterate(OopIterateClosure* blk) {
430   if (!is_active()) return;
431   if (is_humongous()) {
432     oop_iterate_humongous(blk);
433   } else {
434     oop_iterate_objects(blk);
435   }
436 }
437 
438 void ShenandoahHeapRegion::oop_iterate_objects(OopIterateClosure* blk) {
439   assert(! is_humongous(), &quot;no humongous region here&quot;);
<span class="line-modified">440   HeapWord* obj_addr = bottom();</span>
441   HeapWord* t = top();
442   // Could call objects iterate, but this is easier.
443   while (obj_addr &lt; t) {
444     oop obj = oop(obj_addr);
<span class="line-modified">445     obj_addr += obj-&gt;oop_iterate_size(blk);</span>
446   }
447 }
448 
449 void ShenandoahHeapRegion::oop_iterate_humongous(OopIterateClosure* blk) {
450   assert(is_humongous(), &quot;only humongous region here&quot;);
451   // Find head.
452   ShenandoahHeapRegion* r = humongous_start_region();
453   assert(r-&gt;is_humongous_start(), &quot;need humongous head here&quot;);
<span class="line-modified">454   oop obj = oop(r-&gt;bottom());</span>
455   obj-&gt;oop_iterate(blk, MemRegion(bottom(), top()));
456 }
457 
458 ShenandoahHeapRegion* ShenandoahHeapRegion::humongous_start_region() const {
459   assert(is_humongous(), &quot;Must be a part of the humongous region&quot;);
460   size_t reg_num = region_number();
461   ShenandoahHeapRegion* r = const_cast&lt;ShenandoahHeapRegion*&gt;(this);
462   while (!r-&gt;is_humongous_start()) {
463     assert(reg_num &gt; 0, &quot;Sanity&quot;);
464     reg_num --;
465     r = _heap-&gt;get_region(reg_num);
466     assert(r-&gt;is_humongous(), &quot;Must be a part of the humongous region&quot;);
467   }
468   assert(r-&gt;is_humongous_start(), &quot;Must be&quot;);
469   return r;
470 }
471 
472 void ShenandoahHeapRegion::recycle() {
473   ContiguousSpace::clear(false);
474   if (ZapUnusedHeapArea) {
475     ContiguousSpace::mangle_unused_area_complete();
476   }
477   clear_live_data();
478 
479   reset_alloc_metadata();
480 
481   _heap-&gt;marking_context()-&gt;reset_top_at_mark_start(this);
482 
483   make_empty();
484 }
485 
486 HeapWord* ShenandoahHeapRegion::block_start_const(const void* p) const {
487   assert(MemRegion(bottom(), end()).contains(p),
488          &quot;p (&quot; PTR_FORMAT &quot;) not in space [&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT &quot;)&quot;,
489          p2i(p), p2i(bottom()), p2i(end()));
490   if (p &gt;= top()) {
491     return top();
492   } else {
<span class="line-modified">493     HeapWord* last = bottom();</span>
494     HeapWord* cur = last;
495     while (cur &lt;= p) {
496       last = cur;
<span class="line-modified">497       cur += oop(cur)-&gt;size();</span>
498     }
499     shenandoah_assert_correct(NULL, oop(last));
500     return last;
501   }
502 }
503 
<span class="line-modified">504 void ShenandoahHeapRegion::setup_sizes(size_t max_heap_size) {</span>
505   // Absolute minimums we should not ever break.
506   static const size_t MIN_REGION_SIZE = 256*K;
507 
508   if (FLAG_IS_DEFAULT(ShenandoahMinRegionSize)) {
509     FLAG_SET_DEFAULT(ShenandoahMinRegionSize, MIN_REGION_SIZE);
510   }
511 
512   size_t region_size;
513   if (FLAG_IS_DEFAULT(ShenandoahHeapRegionSize)) {
<span class="line-modified">514     if (ShenandoahMinRegionSize &gt; max_heap_size / MIN_NUM_REGIONS) {</span>
<span class="line-modified">515       err_msg message(&quot;Max heap size (&quot; SIZE_FORMAT &quot;%s) is too low to afford the minimum number &quot;</span>
<span class="line-modified">516                       &quot;of regions (&quot; SIZE_FORMAT &quot;) of minimum region size (&quot; SIZE_FORMAT &quot;%s).&quot;,</span>
<span class="line-modified">517                       byte_size_in_proper_unit(max_heap_size), proper_unit_for_byte_size(max_heap_size),</span>
<span class="line-added">518                       MIN_NUM_REGIONS,</span>
<span class="line-added">519                       byte_size_in_proper_unit(ShenandoahMinRegionSize), proper_unit_for_byte_size(ShenandoahMinRegionSize));</span>
520       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMinRegionSize option&quot;, message);
521     }
522     if (ShenandoahMinRegionSize &lt; MIN_REGION_SIZE) {
<span class="line-modified">523       err_msg message(&quot;&quot; SIZE_FORMAT &quot;%s should not be lower than minimum region size (&quot; SIZE_FORMAT &quot;%s).&quot;,</span>
<span class="line-modified">524                       byte_size_in_proper_unit(ShenandoahMinRegionSize), proper_unit_for_byte_size(ShenandoahMinRegionSize),</span>
<span class="line-added">525                       byte_size_in_proper_unit(MIN_REGION_SIZE),         proper_unit_for_byte_size(MIN_REGION_SIZE));</span>
526       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMinRegionSize option&quot;, message);
527     }
528     if (ShenandoahMinRegionSize &lt; MinTLABSize) {
<span class="line-modified">529       err_msg message(&quot;&quot; SIZE_FORMAT &quot;%s should not be lower than TLAB size size (&quot; SIZE_FORMAT &quot;%s).&quot;,</span>
<span class="line-modified">530                       byte_size_in_proper_unit(ShenandoahMinRegionSize), proper_unit_for_byte_size(ShenandoahMinRegionSize),</span>
<span class="line-added">531                       byte_size_in_proper_unit(MinTLABSize),             proper_unit_for_byte_size(MinTLABSize));</span>
532       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMinRegionSize option&quot;, message);
533     }
534     if (ShenandoahMaxRegionSize &lt; MIN_REGION_SIZE) {
<span class="line-modified">535       err_msg message(&quot;&quot; SIZE_FORMAT &quot;%s should not be lower than min region size (&quot; SIZE_FORMAT &quot;%s).&quot;,</span>
<span class="line-modified">536                       byte_size_in_proper_unit(ShenandoahMaxRegionSize), proper_unit_for_byte_size(ShenandoahMaxRegionSize),</span>
<span class="line-added">537                       byte_size_in_proper_unit(MIN_REGION_SIZE),         proper_unit_for_byte_size(MIN_REGION_SIZE));</span>
538       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMaxRegionSize option&quot;, message);
539     }
540     if (ShenandoahMinRegionSize &gt; ShenandoahMaxRegionSize) {
<span class="line-modified">541       err_msg message(&quot;Minimum (&quot; SIZE_FORMAT &quot;%s) should be larger than maximum (&quot; SIZE_FORMAT &quot;%s).&quot;,</span>
<span class="line-modified">542                       byte_size_in_proper_unit(ShenandoahMinRegionSize), proper_unit_for_byte_size(ShenandoahMinRegionSize),</span>
<span class="line-added">543                       byte_size_in_proper_unit(ShenandoahMaxRegionSize), proper_unit_for_byte_size(ShenandoahMaxRegionSize));</span>
544       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMinRegionSize or -XX:ShenandoahMaxRegionSize&quot;, message);
545     }
546 
547     // We rapidly expand to max_heap_size in most scenarios, so that is the measure
548     // for usual heap sizes. Do not depend on initial_heap_size here.
549     region_size = max_heap_size / ShenandoahTargetNumRegions;
550 
551     // Now make sure that we don&#39;t go over or under our limits.
552     region_size = MAX2(ShenandoahMinRegionSize, region_size);
553     region_size = MIN2(ShenandoahMaxRegionSize, region_size);
554 
555   } else {
<span class="line-modified">556     if (ShenandoahHeapRegionSize &gt; max_heap_size / MIN_NUM_REGIONS) {</span>
<span class="line-modified">557       err_msg message(&quot;Max heap size (&quot; SIZE_FORMAT &quot;%s) is too low to afford the minimum number &quot;</span>
<span class="line-modified">558                               &quot;of regions (&quot; SIZE_FORMAT &quot;) of requested size (&quot; SIZE_FORMAT &quot;%s).&quot;,</span>
<span class="line-modified">559                       byte_size_in_proper_unit(max_heap_size), proper_unit_for_byte_size(max_heap_size),</span>
<span class="line-added">560                       MIN_NUM_REGIONS,</span>
<span class="line-added">561                       byte_size_in_proper_unit(ShenandoahHeapRegionSize), proper_unit_for_byte_size(ShenandoahHeapRegionSize));</span>
562       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahHeapRegionSize option&quot;, message);
563     }
564     if (ShenandoahHeapRegionSize &lt; ShenandoahMinRegionSize) {
<span class="line-modified">565       err_msg message(&quot;Heap region size (&quot; SIZE_FORMAT &quot;%s) should be larger than min region size (&quot; SIZE_FORMAT &quot;%s).&quot;,</span>
<span class="line-modified">566                       byte_size_in_proper_unit(ShenandoahHeapRegionSize), proper_unit_for_byte_size(ShenandoahHeapRegionSize),</span>
<span class="line-added">567                       byte_size_in_proper_unit(ShenandoahMinRegionSize),  proper_unit_for_byte_size(ShenandoahMinRegionSize));</span>
568       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahHeapRegionSize option&quot;, message);
569     }
570     if (ShenandoahHeapRegionSize &gt; ShenandoahMaxRegionSize) {
<span class="line-modified">571       err_msg message(&quot;Heap region size (&quot; SIZE_FORMAT &quot;%s) should be lower than max region size (&quot; SIZE_FORMAT &quot;%s).&quot;,</span>
<span class="line-modified">572                       byte_size_in_proper_unit(ShenandoahHeapRegionSize), proper_unit_for_byte_size(ShenandoahHeapRegionSize),</span>
<span class="line-added">573                       byte_size_in_proper_unit(ShenandoahMaxRegionSize),  proper_unit_for_byte_size(ShenandoahMaxRegionSize));</span>
574       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahHeapRegionSize option&quot;, message);
575     }
576     region_size = ShenandoahHeapRegionSize;
577   }
578 
579   // Make sure region size is at least one large page, if enabled.
580   // Otherwise, uncommitting one region may falsely uncommit the adjacent
581   // regions too.
582   // Also see shenandoahArguments.cpp, where it handles UseLargePages.
583   if (UseLargePages &amp;&amp; ShenandoahUncommit) {
584     region_size = MAX2(region_size, os::large_page_size());
585   }
586 
587   int region_size_log = log2_long((jlong) region_size);
588   // Recalculate the region size to make sure it&#39;s a power of
589   // 2. This means that region_size is the largest power of 2 that&#39;s
590   // &lt;= what we&#39;ve calculated so far.
591   region_size = size_t(1) &lt;&lt; region_size_log;
592 
593   // Now, set up the globals.
</pre>
<hr />
<pre>
597   guarantee(RegionSizeWordsShift == 0, &quot;we should only set it once&quot;);
598   RegionSizeWordsShift = RegionSizeBytesShift - LogHeapWordSize;
599 
600   guarantee(RegionSizeBytes == 0, &quot;we should only set it once&quot;);
601   RegionSizeBytes = region_size;
602   RegionSizeWords = RegionSizeBytes &gt;&gt; LogHeapWordSize;
603   assert (RegionSizeWords*HeapWordSize == RegionSizeBytes, &quot;sanity&quot;);
604 
605   guarantee(RegionSizeWordsMask == 0, &quot;we should only set it once&quot;);
606   RegionSizeWordsMask = RegionSizeWords - 1;
607 
608   guarantee(RegionSizeBytesMask == 0, &quot;we should only set it once&quot;);
609   RegionSizeBytesMask = RegionSizeBytes - 1;
610 
611   guarantee(RegionCount == 0, &quot;we should only set it once&quot;);
612   RegionCount = max_heap_size / RegionSizeBytes;
613   guarantee(RegionCount &gt;= MIN_NUM_REGIONS, &quot;Should have at least minimum regions&quot;);
614 
615   guarantee(HumongousThresholdWords == 0, &quot;we should only set it once&quot;);
616   HumongousThresholdWords = RegionSizeWords * ShenandoahHumongousThreshold / 100;
<span class="line-added">617   HumongousThresholdWords = align_down(HumongousThresholdWords, MinObjAlignment);</span>
618   assert (HumongousThresholdWords &lt;= RegionSizeWords, &quot;sanity&quot;);
619 
620   guarantee(HumongousThresholdBytes == 0, &quot;we should only set it once&quot;);
621   HumongousThresholdBytes = HumongousThresholdWords * HeapWordSize;
622   assert (HumongousThresholdBytes &lt;= RegionSizeBytes, &quot;sanity&quot;);
623 
624   // The rationale for trimming the TLAB sizes has to do with the raciness in
625   // TLAB allocation machinery. It may happen that TLAB sizing policy polls Shenandoah
626   // about next free size, gets the answer for region #N, goes away for a while, then
627   // tries to allocate in region #N, and fail because some other thread have claimed part
628   // of the region #N, and then the freeset allocation code has to retire the region #N,
629   // before moving the allocation to region #N+1.
630   //
631   // The worst case realizes when &quot;answer&quot; is &quot;region size&quot;, which means it could
632   // prematurely retire an entire region. Having smaller TLABs does not fix that
633   // completely, but reduces the probability of too wasteful region retirement.
634   // With current divisor, we will waste no more than 1/8 of region size in the worst
635   // case. This also has a secondary effect on collection set selection: even under
636   // the race, the regions would be at least 7/8 used, which allows relying on
637   // &quot;used&quot; - &quot;live&quot; for cset selection. Otherwise, we can get the fragmented region
638   // below the garbage threshold that would never be considered for collection.
639   //
640   // The whole thing is mitigated if Elastic TLABs are enabled.
641   //
<span class="line-added">642   guarantee(MaxTLABSizeWords == 0, &quot;we should only set it once&quot;);</span>
<span class="line-added">643   MaxTLABSizeWords = MIN2(ShenandoahElasticTLAB ? RegionSizeWords : (RegionSizeWords / 8), HumongousThresholdWords);</span>
<span class="line-added">644   MaxTLABSizeWords = align_down(MaxTLABSizeWords, MinObjAlignment);</span>
<span class="line-added">645 </span>
646   guarantee(MaxTLABSizeBytes == 0, &quot;we should only set it once&quot;);
<span class="line-modified">647   MaxTLABSizeBytes = MaxTLABSizeWords * HeapWordSize;</span>
648   assert (MaxTLABSizeBytes &gt; MinTLABSize, &quot;should be larger&quot;);
649 



650   log_info(gc, init)(&quot;Regions: &quot; SIZE_FORMAT &quot; x &quot; SIZE_FORMAT &quot;%s&quot;,
651                      RegionCount, byte_size_in_proper_unit(RegionSizeBytes), proper_unit_for_byte_size(RegionSizeBytes));
652   log_info(gc, init)(&quot;Humongous object threshold: &quot; SIZE_FORMAT &quot;%s&quot;,
653                      byte_size_in_proper_unit(HumongousThresholdBytes), proper_unit_for_byte_size(HumongousThresholdBytes));
654   log_info(gc, init)(&quot;Max TLAB size: &quot; SIZE_FORMAT &quot;%s&quot;,
655                      byte_size_in_proper_unit(MaxTLABSizeBytes), proper_unit_for_byte_size(MaxTLABSizeBytes));
656 }
657 
658 void ShenandoahHeapRegion::do_commit() {
659   if (!_heap-&gt;is_heap_region_special() &amp;&amp; !os::commit_memory((char *) _reserved.start(), _reserved.byte_size(), false)) {
660     report_java_out_of_memory(&quot;Unable to commit region&quot;);
661   }
662   if (!_heap-&gt;commit_bitmap_slice(this)) {
663     report_java_out_of_memory(&quot;Unable to commit bitmaps for region&quot;);
664   }
665   _heap-&gt;increase_committed(ShenandoahHeapRegion::region_size_bytes());
666 }
667 
668 void ShenandoahHeapRegion::do_uncommit() {
669   if (!_heap-&gt;is_heap_region_special() &amp;&amp; !os::uncommit_memory((char *) _reserved.start(), _reserved.byte_size())) {
670     report_java_out_of_memory(&quot;Unable to uncommit region&quot;);
671   }
672   if (!_heap-&gt;uncommit_bitmap_slice(this)) {
673     report_java_out_of_memory(&quot;Unable to uncommit bitmaps for region&quot;);
674   }
675   _heap-&gt;decrease_committed(ShenandoahHeapRegion::region_size_bytes());
676 }
<span class="line-added">677 </span>
<span class="line-added">678 void ShenandoahHeapRegion::set_state(RegionState to) {</span>
<span class="line-added">679   EventShenandoahHeapRegionStateChange evt;</span>
<span class="line-added">680   if (evt.should_commit()){</span>
<span class="line-added">681     evt.set_index((unsigned)region_number());</span>
<span class="line-added">682     evt.set_start((uintptr_t)bottom());</span>
<span class="line-added">683     evt.set_used(used());</span>
<span class="line-added">684     evt.set_from(_state);</span>
<span class="line-added">685     evt.set_to(to);</span>
<span class="line-added">686     evt.commit();</span>
<span class="line-added">687   }</span>
<span class="line-added">688   _state = to;</span>
<span class="line-added">689 }</span>
<span class="line-added">690 </span>
<span class="line-added">691 void ShenandoahHeapRegion::record_pin() {</span>
<span class="line-added">692   Atomic::add(&amp;_critical_pins, (size_t)1);</span>
<span class="line-added">693 }</span>
<span class="line-added">694 </span>
<span class="line-added">695 void ShenandoahHeapRegion::record_unpin() {</span>
<span class="line-added">696   assert(pin_count() &gt; 0, &quot;Region &quot; SIZE_FORMAT &quot; should have non-zero pins&quot;, region_number());</span>
<span class="line-added">697   Atomic::sub(&amp;_critical_pins, (size_t)1);</span>
<span class="line-added">698 }</span>
<span class="line-added">699 </span>
<span class="line-added">700 size_t ShenandoahHeapRegion::pin_count() const {</span>
<span class="line-added">701   return Atomic::load(&amp;_critical_pins);</span>
<span class="line-added">702 }</span>
</pre>
</td>
</tr>
</table>
<center><a href="shenandoahHeap.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahHeapRegion.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>