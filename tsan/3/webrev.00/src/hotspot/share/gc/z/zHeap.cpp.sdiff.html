<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/z/zHeap.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="zGranuleMap.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="zHeap.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/z/zHeap.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 #include &quot;precompiled.hpp&quot;
<span class="line-modified"> 25 #include &quot;gc/shared/oopStorage.hpp&quot;</span>
<span class="line-modified"> 26 #include &quot;gc/z/zAddress.hpp&quot;</span>
 27 #include &quot;gc/z/zGlobals.hpp&quot;
 28 #include &quot;gc/z/zHeap.inline.hpp&quot;
 29 #include &quot;gc/z/zHeapIterator.hpp&quot;
<span class="line-removed"> 30 #include &quot;gc/z/zList.inline.hpp&quot;</span>
<span class="line-removed"> 31 #include &quot;gc/z/zLock.inline.hpp&quot;</span>
 32 #include &quot;gc/z/zMark.inline.hpp&quot;
<span class="line-removed"> 33 #include &quot;gc/z/zOopClosures.inline.hpp&quot;</span>
 34 #include &quot;gc/z/zPage.inline.hpp&quot;
 35 #include &quot;gc/z/zPageTable.inline.hpp&quot;
 36 #include &quot;gc/z/zRelocationSet.inline.hpp&quot;

 37 #include &quot;gc/z/zResurrection.hpp&quot;
<span class="line-removed"> 38 #include &quot;gc/z/zRootsIterator.hpp&quot;</span>
 39 #include &quot;gc/z/zStat.hpp&quot;
<span class="line-modified"> 40 #include &quot;gc/z/zTask.hpp&quot;</span>
<span class="line-modified"> 41 #include &quot;gc/z/zThread.hpp&quot;</span>
<span class="line-removed"> 42 #include &quot;gc/z/zTracer.inline.hpp&quot;</span>
<span class="line-removed"> 43 #include &quot;gc/z/zVirtualMemory.inline.hpp&quot;</span>
 44 #include &quot;gc/z/zWorkers.inline.hpp&quot;
 45 #include &quot;logging/log.hpp&quot;

 46 #include &quot;memory/resourceArea.hpp&quot;
<span class="line-modified"> 47 #include &quot;oops/oop.inline.hpp&quot;</span>
 48 #include &quot;runtime/safepoint.hpp&quot;
 49 #include &quot;runtime/thread.hpp&quot;
<span class="line-removed"> 50 #include &quot;utilities/align.hpp&quot;</span>
 51 #include &quot;utilities/debug.hpp&quot;
 52 
 53 static const ZStatSampler ZSamplerHeapUsedBeforeMark(&quot;Memory&quot;, &quot;Heap Used Before Mark&quot;, ZStatUnitBytes);
 54 static const ZStatSampler ZSamplerHeapUsedAfterMark(&quot;Memory&quot;, &quot;Heap Used After Mark&quot;, ZStatUnitBytes);
 55 static const ZStatSampler ZSamplerHeapUsedBeforeRelocation(&quot;Memory&quot;, &quot;Heap Used Before Relocation&quot;, ZStatUnitBytes);
 56 static const ZStatSampler ZSamplerHeapUsedAfterRelocation(&quot;Memory&quot;, &quot;Heap Used After Relocation&quot;, ZStatUnitBytes);
 57 static const ZStatCounter ZCounterUndoPageAllocation(&quot;Memory&quot;, &quot;Undo Page Allocation&quot;, ZStatUnitOpsPerSecond);
 58 static const ZStatCounter ZCounterOutOfMemory(&quot;Memory&quot;, &quot;Out Of Memory&quot;, ZStatUnitOpsPerSecond);
 59 
 60 ZHeap* ZHeap::_heap = NULL;
 61 
 62 ZHeap::ZHeap() :
 63     _workers(),
<span class="line-modified"> 64     _object_allocator(_workers.nworkers()),</span>
<span class="line-modified"> 65     _page_allocator(heap_min_size(), heap_max_size(), heap_max_reserve_size()),</span>
<span class="line-modified"> 66     _pagetable(),</span>
<span class="line-modified"> 67     _mark(&amp;_workers, &amp;_pagetable),</span>

 68     _reference_processor(&amp;_workers),
 69     _weak_roots_processor(&amp;_workers),
 70     _relocate(&amp;_workers),
 71     _relocation_set(),
 72     _unload(&amp;_workers),
 73     _serviceability(heap_min_size(), heap_max_size()) {
 74   // Install global heap instance
 75   assert(_heap == NULL, &quot;Already initialized&quot;);
 76   _heap = this;
 77 
 78   // Update statistics
<span class="line-modified"> 79   ZStatHeap::set_at_initialize(heap_max_size(), heap_max_reserve_size());</span>
 80 }
 81 
 82 size_t ZHeap::heap_min_size() const {
<span class="line-modified"> 83   const size_t aligned_min_size = align_up(InitialHeapSize, ZGranuleSize);</span>
<span class="line-modified"> 84   return MIN2(aligned_min_size, heap_max_size());</span>



 85 }
 86 
 87 size_t ZHeap::heap_max_size() const {
<span class="line-modified"> 88   const size_t aligned_max_size = align_up(MaxHeapSize, ZGranuleSize);</span>
<span class="line-removed"> 89   return MIN2(aligned_max_size, ZAddressOffsetMax);</span>
 90 }
 91 
 92 size_t ZHeap::heap_max_reserve_size() const {
 93   // Reserve one small page per worker plus one shared medium page. This is still just
 94   // an estimate and doesn&#39;t guarantee that we can&#39;t run out of memory during relocation.
 95   const size_t max_reserve_size = (_workers.nworkers() * ZPageSizeSmall) + ZPageSizeMedium;
 96   return MIN2(max_reserve_size, heap_max_size());
 97 }
 98 
 99 bool ZHeap::is_initialized() const {
100   return _page_allocator.is_initialized() &amp;&amp; _mark.is_initialized();
101 }
102 
103 size_t ZHeap::min_capacity() const {
<span class="line-modified">104   return heap_min_size();</span>
105 }
106 
107 size_t ZHeap::max_capacity() const {
108   return _page_allocator.max_capacity();
109 }
110 
<span class="line-modified">111 size_t ZHeap::current_max_capacity() const {</span>
<span class="line-modified">112   return _page_allocator.current_max_capacity();</span>
113 }
114 
115 size_t ZHeap::capacity() const {
116   return _page_allocator.capacity();
117 }
118 
119 size_t ZHeap::max_reserve() const {
120   return _page_allocator.max_reserve();
121 }
122 
123 size_t ZHeap::used_high() const {
124   return _page_allocator.used_high();
125 }
126 
127 size_t ZHeap::used_low() const {
128   return _page_allocator.used_low();
129 }
130 
131 size_t ZHeap::used() const {
132   return _page_allocator.used();
133 }
134 




135 size_t ZHeap::allocated() const {
136   return _page_allocator.allocated();
137 }
138 
139 size_t ZHeap::reclaimed() const {
140   return _page_allocator.reclaimed();
141 }
142 
143 size_t ZHeap::tlab_capacity() const {
144   return capacity();
145 }
146 
147 size_t ZHeap::tlab_used() const {
148   return _object_allocator.used();
149 }
150 
151 size_t ZHeap::max_tlab_size() const {
152   return ZObjectSizeLimitSmall;
153 }
154 
155 size_t ZHeap::unsafe_max_tlab_alloc() const {
156   size_t size = _object_allocator.remaining();
157 
158   if (size &lt; MinTLABSize) {
159     // The remaining space in the allocator is not enough to
160     // fit the smallest possible TLAB. This means that the next
161     // TLAB allocation will force the allocator to get a new
162     // backing page anyway, which in turn means that we can then
163     // fit the largest possible TLAB.
164     size = max_tlab_size();
165   }
166 
167   return MIN2(size, max_tlab_size());
168 }
169 
170 bool ZHeap::is_in(uintptr_t addr) const {
<span class="line-modified">171   if (addr &lt; ZAddressReservedStart() || addr &gt;= ZAddressReservedEnd()) {</span>
<span class="line-modified">172     return false;</span>
<span class="line-modified">173   }</span>
<span class="line-modified">174 </span>
<span class="line-modified">175   const ZPage* const page = _pagetable.get(addr);</span>
<span class="line-modified">176   if (page != NULL) {</span>
<span class="line-modified">177     return page-&gt;is_in(addr);</span>




178   }
179 
180   return false;
181 }
182 
<span class="line-removed">183 uintptr_t ZHeap::block_start(uintptr_t addr) const {</span>
<span class="line-removed">184   const ZPage* const page = _pagetable.get(addr);</span>
<span class="line-removed">185   return page-&gt;block_start(addr);</span>
<span class="line-removed">186 }</span>
<span class="line-removed">187 </span>
<span class="line-removed">188 bool ZHeap::block_is_obj(uintptr_t addr) const {</span>
<span class="line-removed">189   const ZPage* const page = _pagetable.get(addr);</span>
<span class="line-removed">190   return page-&gt;block_is_obj(addr);</span>
<span class="line-removed">191 }</span>
<span class="line-removed">192 </span>
193 uint ZHeap::nconcurrent_worker_threads() const {
194   return _workers.nconcurrent();
195 }
196 
197 uint ZHeap::nconcurrent_no_boost_worker_threads() const {
198   return _workers.nconcurrent_no_boost();
199 }
200 
201 void ZHeap::set_boost_worker_threads(bool boost) {
202   _workers.set_boost(boost);
203 }
204 
205 void ZHeap::worker_threads_do(ThreadClosure* tc) const {
206   _workers.threads_do(tc);
207 }
208 
209 void ZHeap::print_worker_threads_on(outputStream* st) const {
210   _workers.print_threads_on(st);
211 }
212 
213 void ZHeap::out_of_memory() {
214   ResourceMark rm;
215 
216   ZStatInc(ZCounterOutOfMemory);
217   log_info(gc)(&quot;Out Of Memory (%s)&quot;, Thread::current()-&gt;name());
218 }
219 
220 ZPage* ZHeap::alloc_page(uint8_t type, size_t size, ZAllocationFlags flags) {
221   ZPage* const page = _page_allocator.alloc_page(type, size, flags);
222   if (page != NULL) {
<span class="line-modified">223     // Update pagetable</span>
<span class="line-modified">224     _pagetable.insert(page);</span>
225   }
226 
227   return page;
228 }
229 
230 void ZHeap::undo_alloc_page(ZPage* page) {
231   assert(page-&gt;is_allocating(), &quot;Invalid page state&quot;);
232 
233   ZStatInc(ZCounterUndoPageAllocation);
234   log_trace(gc)(&quot;Undo page allocation, thread: &quot; PTR_FORMAT &quot; (%s), page: &quot; PTR_FORMAT &quot;, size: &quot; SIZE_FORMAT,
235                 ZThread::id(), ZThread::name(), p2i(page), page-&gt;size());
236 
<span class="line-modified">237   release_page(page, false /* reclaimed */);</span>
238 }
239 
<span class="line-modified">240 bool ZHeap::retain_page(ZPage* page) {</span>
<span class="line-modified">241   return page-&gt;inc_refcount();</span>




242 }
243 
<span class="line-modified">244 void ZHeap::release_page(ZPage* page, bool reclaimed) {</span>
<span class="line-modified">245   if (page-&gt;dec_refcount()) {</span>
<span class="line-removed">246     _page_allocator.free_page(page, reclaimed);</span>
<span class="line-removed">247   }</span>
248 }
249 
<span class="line-modified">250 void ZHeap::flip_views() {</span>
<span class="line-modified">251   // For debugging only</span>
<span class="line-modified">252   if (ZUnmapBadViews) {</span>
<span class="line-modified">253     // Flip pages</span>
<span class="line-removed">254     ZPageTableIterator iter(&amp;_pagetable);</span>
<span class="line-removed">255     for (ZPage* page; iter.next(&amp;page);) {</span>
<span class="line-removed">256       if (!page-&gt;is_detached()) {</span>
<span class="line-removed">257         _page_allocator.flip_page(page);</span>
<span class="line-removed">258       }</span>
<span class="line-removed">259     }</span>
260 
<span class="line-modified">261     // Flip pre-mapped memory</span>
<span class="line-modified">262     _page_allocator.flip_pre_mapped();</span>
<span class="line-modified">263   }</span>
264 }
265 
266 void ZHeap::mark_start() {
267   assert(SafepointSynchronize::is_at_safepoint(), &quot;Should be at safepoint&quot;);
268 
269   // Update statistics
270   ZStatSample(ZSamplerHeapUsedBeforeMark, used());
271 
272   // Flip address view
<span class="line-modified">273   ZAddressMasks::flip_to_marked();</span>
<span class="line-removed">274   flip_views();</span>
275 
276   // Retire allocating pages
277   _object_allocator.retire_pages();
278 
279   // Reset allocated/reclaimed/used statistics
280   _page_allocator.reset_statistics();
281 
282   // Reset encountered/dropped/enqueued statistics
283   _reference_processor.reset_statistics();
284 
285   // Enter mark phase
286   ZGlobalPhase = ZPhaseMark;
287 
288   // Reset marking information and mark roots
289   _mark.start();
290 
291   // Update statistics
<span class="line-modified">292   ZStatHeap::set_at_mark_start(capacity(), used());</span>
293 }
294 
295 void ZHeap::mark(bool initial) {
296   _mark.mark(initial);
297 }
298 
299 void ZHeap::mark_flush_and_free(Thread* thread) {
300   _mark.flush_and_free(thread);
301 }
302 
<span class="line-removed">303 class ZFixupPartialLoadsClosure : public ZRootsIteratorClosure {</span>
<span class="line-removed">304 public:</span>
<span class="line-removed">305   virtual void do_oop(oop* p) {</span>
<span class="line-removed">306     ZBarrier::mark_barrier_on_root_oop_field(p);</span>
<span class="line-removed">307   }</span>
<span class="line-removed">308 </span>
<span class="line-removed">309   virtual void do_oop(narrowOop* p) {</span>
<span class="line-removed">310     ShouldNotReachHere();</span>
<span class="line-removed">311   }</span>
<span class="line-removed">312 };</span>
<span class="line-removed">313 </span>
<span class="line-removed">314 class ZFixupPartialLoadsTask : public ZTask {</span>
<span class="line-removed">315 private:</span>
<span class="line-removed">316   ZThreadRootsIterator _thread_roots;</span>
<span class="line-removed">317 </span>
<span class="line-removed">318 public:</span>
<span class="line-removed">319   ZFixupPartialLoadsTask() :</span>
<span class="line-removed">320       ZTask(&quot;ZFixupPartialLoadsTask&quot;),</span>
<span class="line-removed">321       _thread_roots() {}</span>
<span class="line-removed">322 </span>
<span class="line-removed">323   virtual void work() {</span>
<span class="line-removed">324     ZFixupPartialLoadsClosure cl;</span>
<span class="line-removed">325     _thread_roots.oops_do(&amp;cl);</span>
<span class="line-removed">326   }</span>
<span class="line-removed">327 };</span>
<span class="line-removed">328 </span>
<span class="line-removed">329 void ZHeap::fixup_partial_loads() {</span>
<span class="line-removed">330   ZFixupPartialLoadsTask task;</span>
<span class="line-removed">331   _workers.run_parallel(&amp;task);</span>
<span class="line-removed">332 }</span>
<span class="line-removed">333 </span>
334 bool ZHeap::mark_end() {
335   assert(SafepointSynchronize::is_at_safepoint(), &quot;Should be at safepoint&quot;);
336 
<span class="line-removed">337   // C2 can generate code where a safepoint poll is inserted</span>
<span class="line-removed">338   // between a load and the associated load barrier. To handle</span>
<span class="line-removed">339   // this case we need to rescan the thread stack here to make</span>
<span class="line-removed">340   // sure such oops are marked.</span>
<span class="line-removed">341   fixup_partial_loads();</span>
<span class="line-removed">342 </span>
343   // Try end marking
344   if (!_mark.end()) {
345     // Marking not completed, continue concurrent mark
346     return false;
347   }
348 
349   // Enter mark completed phase
350   ZGlobalPhase = ZPhaseMarkCompleted;
351 



352   // Update statistics
353   ZStatSample(ZSamplerHeapUsedAfterMark, used());
354   ZStatHeap::set_at_mark_end(capacity(), allocated(), used());
355 
356   // Block resurrection of weak/phantom references
357   ZResurrection::block();
358 
359   // Process weak roots
360   _weak_roots_processor.process_weak_roots();
361 
<span class="line-modified">362   // Prepare to unload unused classes and code</span>
363   _unload.prepare();
364 
365   return true;
366 }
367 




368 void ZHeap::set_soft_reference_policy(bool clear) {
369   _reference_processor.set_soft_reference_policy(clear);
370 }
371 








372 void ZHeap::process_non_strong_references() {
373   // Process Soft/Weak/Final/PhantomReferences
374   _reference_processor.process_references();
375 
376   // Process concurrent weak roots
377   _weak_roots_processor.process_concurrent_weak_roots();
378 
<span class="line-modified">379   // Unload unused classes and code</span>
<span class="line-modified">380   _unload.unload();</span>











381 
382   // Unblock resurrection of weak/phantom references
383   ZResurrection::unblock();
384 



385   // Enqueue Soft/Weak/Final/PhantomReferences. Note that this
386   // must be done after unblocking resurrection. Otherwise the
387   // Finalizer thread could call Reference.get() on the Finalizers
388   // that were just enqueued, which would incorrectly return null
389   // during the resurrection block window, since such referents
390   // are only Finalizable marked.
391   _reference_processor.enqueue_references();
392 }
393 
<span class="line-removed">394 void ZHeap::destroy_detached_pages() {</span>
<span class="line-removed">395   ZList&lt;ZPage&gt; list;</span>
<span class="line-removed">396 </span>
<span class="line-removed">397   _page_allocator.flush_detached_pages(&amp;list);</span>
<span class="line-removed">398 </span>
<span class="line-removed">399   for (ZPage* page = list.remove_first(); page != NULL; page = list.remove_first()) {</span>
<span class="line-removed">400     // Remove pagetable entry</span>
<span class="line-removed">401     _pagetable.remove(page);</span>
<span class="line-removed">402 </span>
<span class="line-removed">403     // Delete the page</span>
<span class="line-removed">404     _page_allocator.destroy_page(page);</span>
<span class="line-removed">405   }</span>
<span class="line-removed">406 }</span>
<span class="line-removed">407 </span>
408 void ZHeap::select_relocation_set() {



409   // Register relocatable pages with selector
410   ZRelocationSetSelector selector;
<span class="line-modified">411   ZPageTableIterator iter(&amp;_pagetable);</span>
<span class="line-modified">412   for (ZPage* page; iter.next(&amp;page);) {</span>
413     if (!page-&gt;is_relocatable()) {
414       // Not relocatable, don&#39;t register
415       continue;
416     }
417 
418     if (page-&gt;is_marked()) {
419       // Register live page
420       selector.register_live_page(page);
421     } else {
422       // Register garbage page
423       selector.register_garbage_page(page);
424 
425       // Reclaim page immediately
<span class="line-modified">426       release_page(page, true /* reclaimed */);</span>
427     }
428   }
429 



430   // Select pages to relocate
431   selector.select(&amp;_relocation_set);
432 
<span class="line-modified">433   // Update statistics</span>
<span class="line-modified">434   ZStatRelocation::set_at_select_relocation_set(selector.relocating());</span>
<span class="line-modified">435   ZStatHeap::set_at_select_relocation_set(selector.live(),</span>
<span class="line-modified">436                                           selector.garbage(),</span>
<span class="line-removed">437                                           reclaimed());</span>
<span class="line-removed">438 }</span>
<span class="line-removed">439 </span>
<span class="line-removed">440 void ZHeap::prepare_relocation_set() {</span>
<span class="line-removed">441   ZRelocationSetIterator iter(&amp;_relocation_set);</span>
<span class="line-removed">442   for (ZPage* page; iter.next(&amp;page);) {</span>
<span class="line-removed">443     // Prepare for relocation</span>
<span class="line-removed">444     page-&gt;set_forwarding();</span>
<span class="line-removed">445 </span>
<span class="line-removed">446     // Update pagetable</span>
<span class="line-removed">447     _pagetable.set_relocating(page);</span>
448   }




449 }
450 
451 void ZHeap::reset_relocation_set() {

452   ZRelocationSetIterator iter(&amp;_relocation_set);
<span class="line-modified">453   for (ZPage* page; iter.next(&amp;page);) {</span>
<span class="line-modified">454     // Reset relocation information</span>
<span class="line-removed">455     page-&gt;reset_forwarding();</span>
<span class="line-removed">456 </span>
<span class="line-removed">457     // Update pagetable</span>
<span class="line-removed">458     _pagetable.clear_relocating(page);</span>
459   }



460 }
461 
462 void ZHeap::relocate_start() {
463   assert(SafepointSynchronize::is_at_safepoint(), &quot;Should be at safepoint&quot;);
464 
<span class="line-modified">465   // Finish unloading of classes and code</span>
466   _unload.finish();
467 
468   // Flip address view
<span class="line-modified">469   ZAddressMasks::flip_to_remapped();</span>
<span class="line-removed">470   flip_views();</span>
471 
472   // Enter relocate phase
473   ZGlobalPhase = ZPhaseRelocate;
474 
475   // Update statistics
476   ZStatSample(ZSamplerHeapUsedBeforeRelocation, used());
477   ZStatHeap::set_at_relocate_start(capacity(), allocated(), used());
478 
479   // Remap/Relocate roots
480   _relocate.start();
481 }
482 
<span class="line-removed">483 uintptr_t ZHeap::relocate_object(uintptr_t addr) {</span>
<span class="line-removed">484   assert(ZGlobalPhase == ZPhaseRelocate, &quot;Relocate not allowed&quot;);</span>
<span class="line-removed">485   ZPage* const page = _pagetable.get(addr);</span>
<span class="line-removed">486   const bool retained = retain_page(page);</span>
<span class="line-removed">487   const uintptr_t new_addr = page-&gt;relocate_object(addr);</span>
<span class="line-removed">488   if (retained) {</span>
<span class="line-removed">489     release_page(page, true /* reclaimed */);</span>
<span class="line-removed">490   }</span>
<span class="line-removed">491 </span>
<span class="line-removed">492   return new_addr;</span>
<span class="line-removed">493 }</span>
<span class="line-removed">494 </span>
<span class="line-removed">495 uintptr_t ZHeap::forward_object(uintptr_t addr) {</span>
<span class="line-removed">496   assert(ZGlobalPhase == ZPhaseMark ||</span>
<span class="line-removed">497          ZGlobalPhase == ZPhaseMarkCompleted, &quot;Forward not allowed&quot;);</span>
<span class="line-removed">498   ZPage* const page = _pagetable.get(addr);</span>
<span class="line-removed">499   return page-&gt;forward_object(addr);</span>
<span class="line-removed">500 }</span>
<span class="line-removed">501 </span>
502 void ZHeap::relocate() {
503   // Relocate relocation set
504   const bool success = _relocate.relocate(&amp;_relocation_set);
505 
506   // Update statistics
507   ZStatSample(ZSamplerHeapUsedAfterRelocation, used());
508   ZStatRelocation::set_at_relocate_end(success);
509   ZStatHeap::set_at_relocate_end(capacity(), allocated(), reclaimed(),
510                                  used(), used_high(), used_low());
511 }
512 
<span class="line-modified">513 void ZHeap::object_iterate(ObjectClosure* cl, bool visit_referents) {</span>
514   assert(SafepointSynchronize::is_at_safepoint(), &quot;Should be at safepoint&quot;);
515 
<span class="line-modified">516   ZHeapIterator iter(visit_referents);</span>
<span class="line-modified">517   iter.objects_do(cl);</span>








518 }
519 
520 void ZHeap::serviceability_initialize() {
521   _serviceability.initialize();
522 }
523 
524 GCMemoryManager* ZHeap::serviceability_memory_manager() {
525   return _serviceability.memory_manager();
526 }
527 
528 MemoryPool* ZHeap::serviceability_memory_pool() {
529   return _serviceability.memory_pool();
530 }
531 
532 ZServiceabilityCounters* ZHeap::serviceability_counters() {
533   return _serviceability.counters();
534 }
535 
536 void ZHeap::print_on(outputStream* st) const {
537   st-&gt;print_cr(&quot; ZHeap           used &quot; SIZE_FORMAT &quot;M, capacity &quot; SIZE_FORMAT &quot;M, max capacity &quot; SIZE_FORMAT &quot;M&quot;,
538                used() / M,
539                capacity() / M,
540                max_capacity() / M);
541   MetaspaceUtils::print_on(st);
542 }
543 
544 void ZHeap::print_extended_on(outputStream* st) const {
545   print_on(st);
546   st-&gt;cr();
547 
<span class="line-modified">548   ZPageTableIterator iter(&amp;_pagetable);</span>




549   for (ZPage* page; iter.next(&amp;page);) {
550     page-&gt;print_on(st);
551   }
552 



553   st-&gt;cr();
554 }
555 
<span class="line-modified">556 class ZVerifyRootsTask : public ZTask {</span>
<span class="line-modified">557 private:</span>
<span class="line-modified">558   ZRootsIterator     _strong_roots;</span>
<span class="line-modified">559   ZWeakRootsIterator _weak_roots;</span>
<span class="line-modified">560 </span>
<span class="line-removed">561 public:</span>
<span class="line-removed">562   ZVerifyRootsTask() :</span>
<span class="line-removed">563       ZTask(&quot;ZVerifyRootsTask&quot;),</span>
<span class="line-removed">564       _strong_roots(),</span>
<span class="line-removed">565       _weak_roots() {}</span>
<span class="line-removed">566 </span>
<span class="line-removed">567   virtual void work() {</span>
<span class="line-removed">568     ZVerifyOopClosure cl;</span>
<span class="line-removed">569     _strong_roots.oops_do(&amp;cl);</span>
<span class="line-removed">570     _weak_roots.oops_do(&amp;cl);</span>
571   }
<span class="line-modified">572 };</span>


573 
574 void ZHeap::verify() {
575   // Heap verification can only be done between mark end and
576   // relocate start. This is the only window where all oop are
577   // good and the whole heap is in a consistent state.
578   guarantee(ZGlobalPhase == ZPhaseMarkCompleted, &quot;Invalid phase&quot;);
579 
<span class="line-modified">580   {</span>
<span class="line-removed">581     ZVerifyRootsTask task;</span>
<span class="line-removed">582     _workers.run_parallel(&amp;task);</span>
<span class="line-removed">583   }</span>
<span class="line-removed">584 </span>
<span class="line-removed">585   {</span>
<span class="line-removed">586     ZVerifyObjectClosure cl;</span>
<span class="line-removed">587     object_iterate(&amp;cl, false /* visit_referents */);</span>
<span class="line-removed">588   }</span>
589 }
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2015, 2020, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 #include &quot;precompiled.hpp&quot;
<span class="line-modified"> 25 #include &quot;gc/shared/locationPrinter.hpp&quot;</span>
<span class="line-modified"> 26 #include &quot;gc/z/zAddress.inline.hpp&quot;</span>
 27 #include &quot;gc/z/zGlobals.hpp&quot;
 28 #include &quot;gc/z/zHeap.inline.hpp&quot;
 29 #include &quot;gc/z/zHeapIterator.hpp&quot;


 30 #include &quot;gc/z/zMark.inline.hpp&quot;

 31 #include &quot;gc/z/zPage.inline.hpp&quot;
 32 #include &quot;gc/z/zPageTable.inline.hpp&quot;
 33 #include &quot;gc/z/zRelocationSet.inline.hpp&quot;
<span class="line-added"> 34 #include &quot;gc/z/zRelocationSetSelector.inline.hpp&quot;</span>
 35 #include &quot;gc/z/zResurrection.hpp&quot;

 36 #include &quot;gc/z/zStat.hpp&quot;
<span class="line-modified"> 37 #include &quot;gc/z/zThread.inline.hpp&quot;</span>
<span class="line-modified"> 38 #include &quot;gc/z/zVerify.hpp&quot;</span>


 39 #include &quot;gc/z/zWorkers.inline.hpp&quot;
 40 #include &quot;logging/log.hpp&quot;
<span class="line-added"> 41 #include &quot;memory/iterator.hpp&quot;</span>
 42 #include &quot;memory/resourceArea.hpp&quot;
<span class="line-modified"> 43 #include &quot;runtime/handshake.hpp&quot;</span>
 44 #include &quot;runtime/safepoint.hpp&quot;
 45 #include &quot;runtime/thread.hpp&quot;

 46 #include &quot;utilities/debug.hpp&quot;
 47 
 48 static const ZStatSampler ZSamplerHeapUsedBeforeMark(&quot;Memory&quot;, &quot;Heap Used Before Mark&quot;, ZStatUnitBytes);
 49 static const ZStatSampler ZSamplerHeapUsedAfterMark(&quot;Memory&quot;, &quot;Heap Used After Mark&quot;, ZStatUnitBytes);
 50 static const ZStatSampler ZSamplerHeapUsedBeforeRelocation(&quot;Memory&quot;, &quot;Heap Used Before Relocation&quot;, ZStatUnitBytes);
 51 static const ZStatSampler ZSamplerHeapUsedAfterRelocation(&quot;Memory&quot;, &quot;Heap Used After Relocation&quot;, ZStatUnitBytes);
 52 static const ZStatCounter ZCounterUndoPageAllocation(&quot;Memory&quot;, &quot;Undo Page Allocation&quot;, ZStatUnitOpsPerSecond);
 53 static const ZStatCounter ZCounterOutOfMemory(&quot;Memory&quot;, &quot;Out Of Memory&quot;, ZStatUnitOpsPerSecond);
 54 
 55 ZHeap* ZHeap::_heap = NULL;
 56 
 57 ZHeap::ZHeap() :
 58     _workers(),
<span class="line-modified"> 59     _object_allocator(),</span>
<span class="line-modified"> 60     _page_allocator(&amp;_workers, heap_min_size(), heap_initial_size(), heap_max_size(), heap_max_reserve_size()),</span>
<span class="line-modified"> 61     _page_table(),</span>
<span class="line-modified"> 62     _forwarding_table(),</span>
<span class="line-added"> 63     _mark(&amp;_workers, &amp;_page_table),</span>
 64     _reference_processor(&amp;_workers),
 65     _weak_roots_processor(&amp;_workers),
 66     _relocate(&amp;_workers),
 67     _relocation_set(),
 68     _unload(&amp;_workers),
 69     _serviceability(heap_min_size(), heap_max_size()) {
 70   // Install global heap instance
 71   assert(_heap == NULL, &quot;Already initialized&quot;);
 72   _heap = this;
 73 
 74   // Update statistics
<span class="line-modified"> 75   ZStatHeap::set_at_initialize(heap_min_size(), heap_max_size(), heap_max_reserve_size());</span>
 76 }
 77 
 78 size_t ZHeap::heap_min_size() const {
<span class="line-modified"> 79   return MinHeapSize;</span>
<span class="line-modified"> 80 }</span>
<span class="line-added"> 81 </span>
<span class="line-added"> 82 size_t ZHeap::heap_initial_size() const {</span>
<span class="line-added"> 83   return InitialHeapSize;</span>
 84 }
 85 
 86 size_t ZHeap::heap_max_size() const {
<span class="line-modified"> 87   return MaxHeapSize;</span>

 88 }
 89 
 90 size_t ZHeap::heap_max_reserve_size() const {
 91   // Reserve one small page per worker plus one shared medium page. This is still just
 92   // an estimate and doesn&#39;t guarantee that we can&#39;t run out of memory during relocation.
 93   const size_t max_reserve_size = (_workers.nworkers() * ZPageSizeSmall) + ZPageSizeMedium;
 94   return MIN2(max_reserve_size, heap_max_size());
 95 }
 96 
 97 bool ZHeap::is_initialized() const {
 98   return _page_allocator.is_initialized() &amp;&amp; _mark.is_initialized();
 99 }
100 
101 size_t ZHeap::min_capacity() const {
<span class="line-modified">102   return _page_allocator.min_capacity();</span>
103 }
104 
105 size_t ZHeap::max_capacity() const {
106   return _page_allocator.max_capacity();
107 }
108 
<span class="line-modified">109 size_t ZHeap::soft_max_capacity() const {</span>
<span class="line-modified">110   return _page_allocator.soft_max_capacity();</span>
111 }
112 
113 size_t ZHeap::capacity() const {
114   return _page_allocator.capacity();
115 }
116 
117 size_t ZHeap::max_reserve() const {
118   return _page_allocator.max_reserve();
119 }
120 
121 size_t ZHeap::used_high() const {
122   return _page_allocator.used_high();
123 }
124 
125 size_t ZHeap::used_low() const {
126   return _page_allocator.used_low();
127 }
128 
129 size_t ZHeap::used() const {
130   return _page_allocator.used();
131 }
132 
<span class="line-added">133 size_t ZHeap::unused() const {</span>
<span class="line-added">134   return _page_allocator.unused();</span>
<span class="line-added">135 }</span>
<span class="line-added">136 </span>
137 size_t ZHeap::allocated() const {
138   return _page_allocator.allocated();
139 }
140 
141 size_t ZHeap::reclaimed() const {
142   return _page_allocator.reclaimed();
143 }
144 
145 size_t ZHeap::tlab_capacity() const {
146   return capacity();
147 }
148 
149 size_t ZHeap::tlab_used() const {
150   return _object_allocator.used();
151 }
152 
153 size_t ZHeap::max_tlab_size() const {
154   return ZObjectSizeLimitSmall;
155 }
156 
157 size_t ZHeap::unsafe_max_tlab_alloc() const {
158   size_t size = _object_allocator.remaining();
159 
160   if (size &lt; MinTLABSize) {
161     // The remaining space in the allocator is not enough to
162     // fit the smallest possible TLAB. This means that the next
163     // TLAB allocation will force the allocator to get a new
164     // backing page anyway, which in turn means that we can then
165     // fit the largest possible TLAB.
166     size = max_tlab_size();
167   }
168 
169   return MIN2(size, max_tlab_size());
170 }
171 
172 bool ZHeap::is_in(uintptr_t addr) const {
<span class="line-modified">173   // An address is considered to be &quot;in the heap&quot; if it points into</span>
<span class="line-modified">174   // the allocated part of a page, regardless of which heap view is</span>
<span class="line-modified">175   // used. Note that an address with the finalizable metadata bit set</span>
<span class="line-modified">176   // is not pointing into a heap view, and therefore not considered</span>
<span class="line-modified">177   // to be &quot;in the heap&quot;.</span>
<span class="line-modified">178 </span>
<span class="line-modified">179   if (ZAddress::is_in(addr)) {</span>
<span class="line-added">180     const ZPage* const page = _page_table.get(addr);</span>
<span class="line-added">181     if (page != NULL) {</span>
<span class="line-added">182       return page-&gt;is_in(addr);</span>
<span class="line-added">183     }</span>
184   }
185 
186   return false;
187 }
188 










189 uint ZHeap::nconcurrent_worker_threads() const {
190   return _workers.nconcurrent();
191 }
192 
193 uint ZHeap::nconcurrent_no_boost_worker_threads() const {
194   return _workers.nconcurrent_no_boost();
195 }
196 
197 void ZHeap::set_boost_worker_threads(bool boost) {
198   _workers.set_boost(boost);
199 }
200 
201 void ZHeap::worker_threads_do(ThreadClosure* tc) const {
202   _workers.threads_do(tc);
203 }
204 
205 void ZHeap::print_worker_threads_on(outputStream* st) const {
206   _workers.print_threads_on(st);
207 }
208 
209 void ZHeap::out_of_memory() {
210   ResourceMark rm;
211 
212   ZStatInc(ZCounterOutOfMemory);
213   log_info(gc)(&quot;Out Of Memory (%s)&quot;, Thread::current()-&gt;name());
214 }
215 
216 ZPage* ZHeap::alloc_page(uint8_t type, size_t size, ZAllocationFlags flags) {
217   ZPage* const page = _page_allocator.alloc_page(type, size, flags);
218   if (page != NULL) {
<span class="line-modified">219     // Insert page table entry</span>
<span class="line-modified">220     _page_table.insert(page);</span>
221   }
222 
223   return page;
224 }
225 
226 void ZHeap::undo_alloc_page(ZPage* page) {
227   assert(page-&gt;is_allocating(), &quot;Invalid page state&quot;);
228 
229   ZStatInc(ZCounterUndoPageAllocation);
230   log_trace(gc)(&quot;Undo page allocation, thread: &quot; PTR_FORMAT &quot; (%s), page: &quot; PTR_FORMAT &quot;, size: &quot; SIZE_FORMAT,
231                 ZThread::id(), ZThread::name(), p2i(page), page-&gt;size());
232 
<span class="line-modified">233   free_page(page, false /* reclaimed */);</span>
234 }
235 
<span class="line-modified">236 void ZHeap::free_page(ZPage* page, bool reclaimed) {</span>
<span class="line-modified">237   // Remove page table entry</span>
<span class="line-added">238   _page_table.remove(page);</span>
<span class="line-added">239 </span>
<span class="line-added">240   // Free page</span>
<span class="line-added">241   _page_allocator.free_page(page, reclaimed);</span>
242 }
243 
<span class="line-modified">244 uint64_t ZHeap::uncommit(uint64_t delay) {</span>
<span class="line-modified">245   return _page_allocator.uncommit(delay);</span>


246 }
247 
<span class="line-modified">248 void ZHeap::flip_to_marked() {</span>
<span class="line-modified">249   ZVerifyViewsFlip flip(&amp;_page_allocator);</span>
<span class="line-modified">250   ZAddress::flip_to_marked();</span>
<span class="line-modified">251 }</span>






252 
<span class="line-modified">253 void ZHeap::flip_to_remapped() {</span>
<span class="line-modified">254   ZVerifyViewsFlip flip(&amp;_page_allocator);</span>
<span class="line-modified">255   ZAddress::flip_to_remapped();</span>
256 }
257 
258 void ZHeap::mark_start() {
259   assert(SafepointSynchronize::is_at_safepoint(), &quot;Should be at safepoint&quot;);
260 
261   // Update statistics
262   ZStatSample(ZSamplerHeapUsedBeforeMark, used());
263 
264   // Flip address view
<span class="line-modified">265   flip_to_marked();</span>

266 
267   // Retire allocating pages
268   _object_allocator.retire_pages();
269 
270   // Reset allocated/reclaimed/used statistics
271   _page_allocator.reset_statistics();
272 
273   // Reset encountered/dropped/enqueued statistics
274   _reference_processor.reset_statistics();
275 
276   // Enter mark phase
277   ZGlobalPhase = ZPhaseMark;
278 
279   // Reset marking information and mark roots
280   _mark.start();
281 
282   // Update statistics
<span class="line-modified">283   ZStatHeap::set_at_mark_start(soft_max_capacity(), capacity(), used());</span>
284 }
285 
286 void ZHeap::mark(bool initial) {
287   _mark.mark(initial);
288 }
289 
290 void ZHeap::mark_flush_and_free(Thread* thread) {
291   _mark.flush_and_free(thread);
292 }
293 































294 bool ZHeap::mark_end() {
295   assert(SafepointSynchronize::is_at_safepoint(), &quot;Should be at safepoint&quot;);
296 






297   // Try end marking
298   if (!_mark.end()) {
299     // Marking not completed, continue concurrent mark
300     return false;
301   }
302 
303   // Enter mark completed phase
304   ZGlobalPhase = ZPhaseMarkCompleted;
305 
<span class="line-added">306   // Verify after mark</span>
<span class="line-added">307   ZVerify::after_mark();</span>
<span class="line-added">308 </span>
309   // Update statistics
310   ZStatSample(ZSamplerHeapUsedAfterMark, used());
311   ZStatHeap::set_at_mark_end(capacity(), allocated(), used());
312 
313   // Block resurrection of weak/phantom references
314   ZResurrection::block();
315 
316   // Process weak roots
317   _weak_roots_processor.process_weak_roots();
318 
<span class="line-modified">319   // Prepare to unload stale metadata and nmethods</span>
320   _unload.prepare();
321 
322   return true;
323 }
324 
<span class="line-added">325 void ZHeap::keep_alive(oop obj) {</span>
<span class="line-added">326   ZBarrier::keep_alive_barrier_on_oop(obj);</span>
<span class="line-added">327 }</span>
<span class="line-added">328 </span>
329 void ZHeap::set_soft_reference_policy(bool clear) {
330   _reference_processor.set_soft_reference_policy(clear);
331 }
332 
<span class="line-added">333 class ZRendezvousClosure : public HandshakeClosure {</span>
<span class="line-added">334 public:</span>
<span class="line-added">335   ZRendezvousClosure() :</span>
<span class="line-added">336       HandshakeClosure(&quot;ZRendezvous&quot;) {}</span>
<span class="line-added">337 </span>
<span class="line-added">338   void do_thread(Thread* thread) {}</span>
<span class="line-added">339 };</span>
<span class="line-added">340 </span>
341 void ZHeap::process_non_strong_references() {
342   // Process Soft/Weak/Final/PhantomReferences
343   _reference_processor.process_references();
344 
345   // Process concurrent weak roots
346   _weak_roots_processor.process_concurrent_weak_roots();
347 
<span class="line-modified">348   // Unlink stale metadata and nmethods</span>
<span class="line-modified">349   _unload.unlink();</span>
<span class="line-added">350 </span>
<span class="line-added">351   // Perform a handshake. This is needed 1) to make sure that stale</span>
<span class="line-added">352   // metadata and nmethods are no longer observable. And 2), to</span>
<span class="line-added">353   // prevent the race where a mutator first loads an oop, which is</span>
<span class="line-added">354   // logically null but not yet cleared. Then this oop gets cleared</span>
<span class="line-added">355   // by the reference processor and resurrection is unblocked. At</span>
<span class="line-added">356   // this point the mutator could see the unblocked state and pass</span>
<span class="line-added">357   // this invalid oop through the normal barrier path, which would</span>
<span class="line-added">358   // incorrectly try to mark the oop.</span>
<span class="line-added">359   ZRendezvousClosure cl;</span>
<span class="line-added">360   Handshake::execute(&amp;cl);</span>
361 
362   // Unblock resurrection of weak/phantom references
363   ZResurrection::unblock();
364 
<span class="line-added">365   // Purge stale metadata and nmethods that were unlinked</span>
<span class="line-added">366   _unload.purge();</span>
<span class="line-added">367 </span>
368   // Enqueue Soft/Weak/Final/PhantomReferences. Note that this
369   // must be done after unblocking resurrection. Otherwise the
370   // Finalizer thread could call Reference.get() on the Finalizers
371   // that were just enqueued, which would incorrectly return null
372   // during the resurrection block window, since such referents
373   // are only Finalizable marked.
374   _reference_processor.enqueue_references();
375 }
376 














377 void ZHeap::select_relocation_set() {
<span class="line-added">378   // Do not allow pages to be deleted</span>
<span class="line-added">379   _page_allocator.enable_deferred_delete();</span>
<span class="line-added">380 </span>
381   // Register relocatable pages with selector
382   ZRelocationSetSelector selector;
<span class="line-modified">383   ZPageTableIterator pt_iter(&amp;_page_table);</span>
<span class="line-modified">384   for (ZPage* page; pt_iter.next(&amp;page);) {</span>
385     if (!page-&gt;is_relocatable()) {
386       // Not relocatable, don&#39;t register
387       continue;
388     }
389 
390     if (page-&gt;is_marked()) {
391       // Register live page
392       selector.register_live_page(page);
393     } else {
394       // Register garbage page
395       selector.register_garbage_page(page);
396 
397       // Reclaim page immediately
<span class="line-modified">398       free_page(page, true /* reclaimed */);</span>
399     }
400   }
401 
<span class="line-added">402   // Allow pages to be deleted</span>
<span class="line-added">403   _page_allocator.disable_deferred_delete();</span>
<span class="line-added">404 </span>
405   // Select pages to relocate
406   selector.select(&amp;_relocation_set);
407 
<span class="line-modified">408   // Setup forwarding table</span>
<span class="line-modified">409   ZRelocationSetIterator rs_iter(&amp;_relocation_set);</span>
<span class="line-modified">410   for (ZForwarding* forwarding; rs_iter.next(&amp;forwarding);) {</span>
<span class="line-modified">411     _forwarding_table.insert(forwarding);</span>











412   }
<span class="line-added">413 </span>
<span class="line-added">414   // Update statistics</span>
<span class="line-added">415   ZStatRelocation::set_at_select_relocation_set(selector.stats());</span>
<span class="line-added">416   ZStatHeap::set_at_select_relocation_set(selector.stats(), reclaimed());</span>
417 }
418 
419 void ZHeap::reset_relocation_set() {
<span class="line-added">420   // Reset forwarding table</span>
421   ZRelocationSetIterator iter(&amp;_relocation_set);
<span class="line-modified">422   for (ZForwarding* forwarding; iter.next(&amp;forwarding);) {</span>
<span class="line-modified">423     _forwarding_table.remove(forwarding);</span>




424   }
<span class="line-added">425 </span>
<span class="line-added">426   // Reset relocation set</span>
<span class="line-added">427   _relocation_set.reset();</span>
428 }
429 
430 void ZHeap::relocate_start() {
431   assert(SafepointSynchronize::is_at_safepoint(), &quot;Should be at safepoint&quot;);
432 
<span class="line-modified">433   // Finish unloading stale metadata and nmethods</span>
434   _unload.finish();
435 
436   // Flip address view
<span class="line-modified">437   flip_to_remapped();</span>

438 
439   // Enter relocate phase
440   ZGlobalPhase = ZPhaseRelocate;
441 
442   // Update statistics
443   ZStatSample(ZSamplerHeapUsedBeforeRelocation, used());
444   ZStatHeap::set_at_relocate_start(capacity(), allocated(), used());
445 
446   // Remap/Relocate roots
447   _relocate.start();
448 }
449 



















450 void ZHeap::relocate() {
451   // Relocate relocation set
452   const bool success = _relocate.relocate(&amp;_relocation_set);
453 
454   // Update statistics
455   ZStatSample(ZSamplerHeapUsedAfterRelocation, used());
456   ZStatRelocation::set_at_relocate_end(success);
457   ZStatHeap::set_at_relocate_end(capacity(), allocated(), reclaimed(),
458                                  used(), used_high(), used_low());
459 }
460 
<span class="line-modified">461 void ZHeap::object_iterate(ObjectClosure* cl, bool visit_weaks) {</span>
462   assert(SafepointSynchronize::is_at_safepoint(), &quot;Should be at safepoint&quot;);
463 
<span class="line-modified">464   ZHeapIterator iter;</span>
<span class="line-modified">465   iter.objects_do(cl, visit_weaks);</span>
<span class="line-added">466 }</span>
<span class="line-added">467 </span>
<span class="line-added">468 void ZHeap::pages_do(ZPageClosure* cl) {</span>
<span class="line-added">469   ZPageTableIterator iter(&amp;_page_table);</span>
<span class="line-added">470   for (ZPage* page; iter.next(&amp;page);) {</span>
<span class="line-added">471     cl-&gt;do_page(page);</span>
<span class="line-added">472   }</span>
<span class="line-added">473   _page_allocator.pages_do(cl);</span>
474 }
475 
476 void ZHeap::serviceability_initialize() {
477   _serviceability.initialize();
478 }
479 
480 GCMemoryManager* ZHeap::serviceability_memory_manager() {
481   return _serviceability.memory_manager();
482 }
483 
484 MemoryPool* ZHeap::serviceability_memory_pool() {
485   return _serviceability.memory_pool();
486 }
487 
488 ZServiceabilityCounters* ZHeap::serviceability_counters() {
489   return _serviceability.counters();
490 }
491 
492 void ZHeap::print_on(outputStream* st) const {
493   st-&gt;print_cr(&quot; ZHeap           used &quot; SIZE_FORMAT &quot;M, capacity &quot; SIZE_FORMAT &quot;M, max capacity &quot; SIZE_FORMAT &quot;M&quot;,
494                used() / M,
495                capacity() / M,
496                max_capacity() / M);
497   MetaspaceUtils::print_on(st);
498 }
499 
500 void ZHeap::print_extended_on(outputStream* st) const {
501   print_on(st);
502   st-&gt;cr();
503 
<span class="line-modified">504   // Do not allow pages to be deleted</span>
<span class="line-added">505   _page_allocator.enable_deferred_delete();</span>
<span class="line-added">506 </span>
<span class="line-added">507   // Print all pages</span>
<span class="line-added">508   ZPageTableIterator iter(&amp;_page_table);</span>
509   for (ZPage* page; iter.next(&amp;page);) {
510     page-&gt;print_on(st);
511   }
512 
<span class="line-added">513   // Allow pages to be deleted</span>
<span class="line-added">514   _page_allocator.enable_deferred_delete();</span>
<span class="line-added">515 </span>
516   st-&gt;cr();
517 }
518 
<span class="line-modified">519 bool ZHeap::print_location(outputStream* st, uintptr_t addr) const {</span>
<span class="line-modified">520   if (LocationPrinter::is_valid_obj((void*)addr)) {</span>
<span class="line-modified">521     st-&gt;print(PTR_FORMAT &quot; is a %s oop: &quot;, addr, ZAddress::is_good(addr) ? &quot;good&quot; : &quot;bad&quot;);</span>
<span class="line-modified">522     ZOop::from_address(addr)-&gt;print_on(st);</span>
<span class="line-modified">523     return true;</span>










524   }
<span class="line-modified">525 </span>
<span class="line-added">526   return false;</span>
<span class="line-added">527 }</span>
528 
529 void ZHeap::verify() {
530   // Heap verification can only be done between mark end and
531   // relocate start. This is the only window where all oop are
532   // good and the whole heap is in a consistent state.
533   guarantee(ZGlobalPhase == ZPhaseMarkCompleted, &quot;Invalid phase&quot;);
534 
<span class="line-modified">535   ZVerify::after_weak_processing();</span>








536 }
</pre>
</td>
</tr>
</table>
<center><a href="zGranuleMap.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="zHeap.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>