diff a/src/hotspot/share/gc/z/zPage.inline.hpp b/src/hotspot/share/gc/z/zPage.inline.hpp
--- a/src/hotspot/share/gc/z/zPage.inline.hpp
+++ b/src/hotspot/share/gc/z/zPage.inline.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2015, 2017, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2015, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -23,23 +23,33 @@
 
 #ifndef SHARE_GC_Z_ZPAGE_INLINE_HPP
 #define SHARE_GC_Z_ZPAGE_INLINE_HPP
 
 #include "gc/z/zAddress.inline.hpp"
-#include "gc/z/zForwardingTable.inline.hpp"
 #include "gc/z/zGlobals.hpp"
 #include "gc/z/zLiveMap.inline.hpp"
 #include "gc/z/zMark.hpp"
 #include "gc/z/zNUMA.hpp"
 #include "gc/z/zPage.hpp"
 #include "gc/z/zPhysicalMemory.inline.hpp"
 #include "gc/z/zVirtualMemory.inline.hpp"
 #include "oops/oop.inline.hpp"
 #include "runtime/atomic.hpp"
+#include "runtime/os.hpp"
 #include "utilities/align.hpp"
 #include "utilities/debug.hpp"
 
+inline uint8_t ZPage::type_from_size(size_t size) const {
+  if (size == ZPageSizeSmall) {
+    return ZPageTypeSmall;
+  } else if (size == ZPageSizeMedium) {
+    return ZPageTypeMedium;
+  } else {
+    return ZPageTypeLarge;
+  }
+}
+
 inline const char* ZPage::type_to_string() const {
   switch (type()) {
   case ZPageTypeSmall:
     return "Small";
 
@@ -114,71 +124,32 @@
 
 inline size_t ZPage::remaining() const {
   return end() - top();
 }
 
-inline ZPhysicalMemory& ZPage::physical_memory() {
+inline const ZPhysicalMemory& ZPage::physical_memory() const {
   return _physical;
 }
 
 inline const ZVirtualMemory& ZPage::virtual_memory() const {
   return _virtual;
 }
 
 inline uint8_t ZPage::numa_id() {
   if (_numa_id == (uint8_t)-1) {
-    _numa_id = (uint8_t)ZNUMA::memory_id(ZAddress::good(start()));
+    _numa_id = ZNUMA::memory_id(ZAddress::good(start()));
   }
 
   return _numa_id;
 }
 
-inline bool ZPage::inc_refcount() {
-  for (uint32_t prev_refcount = _refcount; prev_refcount > 0; prev_refcount = _refcount) {
-    if (Atomic::cmpxchg(prev_refcount + 1, &_refcount, prev_refcount) == prev_refcount) {
-      return true;
-    }
-  }
-  return false;
-}
-
-inline bool ZPage::dec_refcount() {
-  assert(is_active(), "Should be active");
-  return Atomic::sub(1u, &_refcount) == 0;
-}
-
-inline bool ZPage::is_in(uintptr_t addr) const {
-  const uintptr_t offset = ZAddress::offset(addr);
-  return offset >= start() && offset < top();
-}
-
-inline uintptr_t ZPage::block_start(uintptr_t addr) const {
-  if (block_is_obj(addr)) {
-    return addr;
-  } else {
-    return ZAddress::good(top());
-  }
-}
-
-inline bool ZPage::block_is_obj(uintptr_t addr) const {
-  return ZAddress::offset(addr) < top();
-}
-
-inline bool ZPage::is_active() const {
-  return _refcount > 0;
-}
-
 inline bool ZPage::is_allocating() const {
-  return is_active() && _seqnum == ZGlobalSeqNum;
+  return _seqnum == ZGlobalSeqNum;
 }
 
 inline bool ZPage::is_relocatable() const {
-  return is_active() && _seqnum < ZGlobalSeqNum;
-}
-
-inline bool ZPage::is_detached() const {
-  return _physical.is_null();
+  return _seqnum < ZGlobalSeqNum;
 }
 
 inline bool ZPage::is_mapped() const {
   return _seqnum > 0;
 }
@@ -188,34 +159,21 @@
   // memory has been mapped. So, we need to set it to non-zero when the memory
   // has been pre-mapped.
   _seqnum = 1;
 }
 
-inline bool ZPage::is_pinned() const {
-  return _pinned;
-}
-
-inline void ZPage::set_pinned() {
-  _pinned = 1;
+inline uint64_t ZPage::last_used() const {
+  return _last_used;
 }
 
-inline bool ZPage::is_forwarding() const {
-  return !_forwarding.is_null();
+inline void ZPage::set_last_used() {
+  _last_used = os::elapsedTime();
 }
 
-inline void ZPage::set_forwarding() {
-  assert(is_marked(), "Should be marked");
-  _forwarding.setup(_livemap.live_objects());
-}
-
-inline void ZPage::reset_forwarding() {
-  _forwarding.reset();
-  _pinned = 0;
-}
-
-inline void ZPage::verify_forwarding() const {
-  _forwarding.verify(object_max_count(), _livemap.live_objects());
+inline bool ZPage::is_in(uintptr_t addr) const {
+  const uintptr_t offset = ZAddress::offset(addr);
+  return offset >= start() && offset < top();
 }
 
 inline bool ZPage::is_marked() const {
   assert(is_relocatable(), "Invalid page state");
   return _livemap.is_marked();
@@ -244,15 +202,20 @@
   assert(is_relocatable(), "Invalid page state");
   assert(is_in(addr), "Invalid address");
 
   // Set mark bit
   const size_t index = ((ZAddress::offset(addr) - start()) >> object_alignment_shift()) * 2;
-  return _livemap.set_atomic(index, finalizable, inc_live);
+  return _livemap.set(index, finalizable, inc_live);
+}
+
+inline void ZPage::inc_live(uint32_t objects, size_t bytes) {
+  _livemap.inc_live(objects, bytes);
 }
 
-inline void ZPage::inc_live_atomic(uint32_t objects, size_t bytes) {
-  _livemap.inc_live_atomic(objects, bytes);
+inline uint32_t ZPage::live_objects() const {
+  assert(is_marked(), "Should be marked");
+  return _livemap.live_objects();
 }
 
 inline size_t ZPage::live_bytes() const {
   assert(is_marked(), "Should be marked");
   return _livemap.live_bytes();
@@ -290,11 +253,11 @@
     if (new_top > end()) {
       // Not enough space left
       return 0;
     }
 
-    const uintptr_t prev_top = Atomic::cmpxchg(new_top, &_top, addr);
+    const uintptr_t prev_top = Atomic::cmpxchg(&_top, addr, new_top);
     if (prev_top == addr) {
       // Success
       return ZAddress::good(addr);
     }
 
@@ -334,11 +297,11 @@
     if (new_top != offset) {
       // Failed to undo allocation, not the last allocated object
       return false;
     }
 
-    const uintptr_t prev_top = Atomic::cmpxchg(new_top, &_top, old_top);
+    const uintptr_t prev_top = Atomic::cmpxchg(&_top, old_top, new_top);
     if (prev_top == old_top) {
       // Success
       return true;
     }
 
