<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/z/zPageAllocator.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="zPage.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="zPageAllocator.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/z/zPageAllocator.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 #include &quot;precompiled.hpp&quot;

 25 #include &quot;gc/z/zAddress.inline.hpp&quot;
 26 #include &quot;gc/z/zCollectedHeap.hpp&quot;
 27 #include &quot;gc/z/zFuture.inline.hpp&quot;
 28 #include &quot;gc/z/zGlobals.hpp&quot;
 29 #include &quot;gc/z/zLock.inline.hpp&quot;
 30 #include &quot;gc/z/zPage.inline.hpp&quot;
 31 #include &quot;gc/z/zPageAllocator.hpp&quot;
 32 #include &quot;gc/z/zPageCache.inline.hpp&quot;
<span class="line-modified"> 33 #include &quot;gc/z/zPreMappedMemory.inline.hpp&quot;</span>
 34 #include &quot;gc/z/zStat.hpp&quot;

 35 #include &quot;gc/z/zTracer.inline.hpp&quot;


 36 #include &quot;runtime/init.hpp&quot;


 37 
 38 static const ZStatCounter       ZCounterAllocationRate(&quot;Memory&quot;, &quot;Allocation Rate&quot;, ZStatUnitBytesPerSecond);


 39 static const ZStatCriticalPhase ZCriticalPhaseAllocationStall(&quot;Allocation Stall&quot;);
 40 
 41 class ZPageAllocRequest : public StackObj {
 42   friend class ZList&lt;ZPageAllocRequest&gt;;
 43 
 44 private:
 45   const uint8_t                _type;
 46   const size_t                 _size;
 47   const ZAllocationFlags       _flags;
 48   const unsigned int           _total_collections;
 49   ZListNode&lt;ZPageAllocRequest&gt; _node;
 50   ZFuture&lt;ZPage*&gt;              _result;
 51 
 52 public:
 53   ZPageAllocRequest(uint8_t type, size_t size, ZAllocationFlags flags, unsigned int total_collections) :
 54       _type(type),
 55       _size(size),
 56       _flags(flags),
<span class="line-modified"> 57       _total_collections(total_collections) {}</span>


 58 
 59   uint8_t type() const {
 60     return _type;
 61   }
 62 
 63   size_t size() const {
 64     return _size;
 65   }
 66 
 67   ZAllocationFlags flags() const {
 68     return _flags;
 69   }
 70 
 71   unsigned int total_collections() const {
 72     return _total_collections;
 73   }
 74 




 75   ZPage* wait() {
 76     return _result.get();
 77   }
 78 
 79   void satisfy(ZPage* page) {
 80     _result.set(page);
 81   }
 82 };
 83 
 84 ZPage* const ZPageAllocator::gc_marker = (ZPage*)-1;
 85 
<span class="line-modified"> 86 ZPageAllocator::ZPageAllocator(size_t min_capacity, size_t max_capacity, size_t max_reserve) :</span>




 87     _lock(),
<span class="line-modified"> 88     _virtual(),</span>
<span class="line-modified"> 89     _physical(max_capacity),</span>
 90     _cache(),


 91     _max_reserve(max_reserve),
<span class="line-modified"> 92     _pre_mapped(_virtual, _physical, try_ensure_unused_for_pre_mapped(min_capacity)),</span>

 93     _used_high(0),
 94     _used_low(0),
 95     _used(0),
 96     _allocated(0),
 97     _reclaimed(0),
 98     _queue(),
<span class="line-modified"> 99     _detached() {}</span>
































































































100 
101 bool ZPageAllocator::is_initialized() const {
<span class="line-modified">102   return _physical.is_initialized() &amp;&amp;</span>
<span class="line-modified">103          _virtual.is_initialized() &amp;&amp;</span>
<span class="line-modified">104          _pre_mapped.is_initialized();</span>


105 }
106 
107 size_t ZPageAllocator::max_capacity() const {
<span class="line-modified">108   return _physical.max_capacity();</span>
109 }
110 
<span class="line-modified">111 size_t ZPageAllocator::current_max_capacity() const {</span>
<span class="line-modified">112   return _physical.current_max_capacity();</span>

113 }
114 
115 size_t ZPageAllocator::capacity() const {
<span class="line-modified">116   return _physical.capacity();</span>
117 }
118 
119 size_t ZPageAllocator::max_reserve() const {
120   return _max_reserve;
121 }
122 
123 size_t ZPageAllocator::used_high() const {
124   return _used_high;
125 }
126 
127 size_t ZPageAllocator::used_low() const {
128   return _used_low;
129 }
130 
131 size_t ZPageAllocator::used() const {
132   return _used;
133 }
134 





135 size_t ZPageAllocator::allocated() const {
136   return _allocated;
137 }
138 
139 size_t ZPageAllocator::reclaimed() const {
140   return _reclaimed &gt; 0 ? (size_t)_reclaimed : 0;
141 }
142 
143 void ZPageAllocator::reset_statistics() {
144   assert(SafepointSynchronize::is_at_safepoint(), &quot;Should be at safepoint&quot;);
145   _allocated = 0;
146   _reclaimed = 0;
147   _used_high = _used_low = _used;
148 }
149 
150 void ZPageAllocator::increase_used(size_t size, bool relocation) {
151   if (relocation) {
152     // Allocating a page for the purpose of relocation has a
153     // negative contribution to the number of reclaimed bytes.
154     _reclaimed -= size;
</pre>
<hr />
<pre>
157   _used += size;
158   if (_used &gt; _used_high) {
159     _used_high = _used;
160   }
161 }
162 
163 void ZPageAllocator::decrease_used(size_t size, bool reclaimed) {
164   if (reclaimed) {
165     // Only pages explicitly released with the reclaimed flag set
166     // counts as reclaimed bytes. This flag is typically true when
167     // a worker releases a page after relocation, and is typically
168     // false when we release a page to undo an allocation.
169     _reclaimed += size;
170   }
171   _used -= size;
172   if (_used &lt; _used_low) {
173     _used_low = _used;
174   }
175 }
176 
<span class="line-removed">177 size_t ZPageAllocator::max_available(bool no_reserve) const {</span>
<span class="line-removed">178   size_t available = current_max_capacity() - used();</span>
<span class="line-removed">179 </span>
<span class="line-removed">180   if (no_reserve) {</span>
<span class="line-removed">181     // The reserve should not be considered available</span>
<span class="line-removed">182     available -= MIN2(available, max_reserve());</span>
<span class="line-removed">183   }</span>
<span class="line-removed">184 </span>
<span class="line-removed">185   return available;</span>
<span class="line-removed">186 }</span>
<span class="line-removed">187 </span>
<span class="line-removed">188 size_t ZPageAllocator::try_ensure_unused(size_t size, bool no_reserve) {</span>
<span class="line-removed">189   // Ensure that we always have space available for the reserve. This</span>
<span class="line-removed">190   // is needed to avoid losing the reserve because of failure to map</span>
<span class="line-removed">191   // more memory before reaching max capacity.</span>
<span class="line-removed">192   _physical.try_ensure_unused_capacity(size + max_reserve());</span>
<span class="line-removed">193 </span>
<span class="line-removed">194   size_t unused = _physical.unused_capacity();</span>
<span class="line-removed">195 </span>
<span class="line-removed">196   if (no_reserve) {</span>
<span class="line-removed">197     // The reserve should not be considered unused</span>
<span class="line-removed">198     unused -= MIN2(unused, max_reserve());</span>
<span class="line-removed">199   }</span>
<span class="line-removed">200 </span>
<span class="line-removed">201   return MIN2(size, unused);</span>
<span class="line-removed">202 }</span>
<span class="line-removed">203 </span>
<span class="line-removed">204 size_t ZPageAllocator::try_ensure_unused_for_pre_mapped(size_t size) {</span>
<span class="line-removed">205   // This function is called during construction, where the</span>
<span class="line-removed">206   // physical memory manager might have failed to initialied.</span>
<span class="line-removed">207   if (!_physical.is_initialized()) {</span>
<span class="line-removed">208     return 0;</span>
<span class="line-removed">209   }</span>
<span class="line-removed">210 </span>
<span class="line-removed">211   return try_ensure_unused(size, true /* no_reserve */);</span>
<span class="line-removed">212 }</span>
<span class="line-removed">213 </span>
214 ZPage* ZPageAllocator::create_page(uint8_t type, size_t size) {
<span class="line-removed">215   // Allocate physical memory</span>
<span class="line-removed">216   const ZPhysicalMemory pmem = _physical.alloc(size);</span>
<span class="line-removed">217   if (pmem.is_null()) {</span>
<span class="line-removed">218     // Out of memory</span>
<span class="line-removed">219     return NULL;</span>
<span class="line-removed">220   }</span>
<span class="line-removed">221 </span>
222   // Allocate virtual memory
223   const ZVirtualMemory vmem = _virtual.alloc(size);
224   if (vmem.is_null()) {
225     // Out of address space
<span class="line-removed">226     _physical.free(pmem);</span>
227     return NULL;
228   }
229 




230   // Allocate page
231   return new ZPage(type, vmem, pmem);
232 }
233 
<span class="line-modified">234 void ZPageAllocator::flush_pre_mapped() {</span>
<span class="line-modified">235   if (_pre_mapped.available() == 0) {</span>
<span class="line-modified">236     return;</span>
<span class="line-modified">237   }</span>





238 
<span class="line-modified">239   // Detach the memory mapping.</span>
<span class="line-modified">240   detach_memory(_pre_mapped.virtual_memory(), _pre_mapped.physical_memory());</span>
241 
<span class="line-modified">242   _pre_mapped.clear();</span>

243 }
244 
<span class="line-modified">245 void ZPageAllocator::map_page(ZPage* page) {</span>
246   // Map physical memory
247   _physical.map(page-&gt;physical_memory(), page-&gt;start());
248 }
249 
<span class="line-modified">250 void ZPageAllocator::detach_page(ZPage* page) {</span>
<span class="line-modified">251   // Detach the memory mapping.</span>
<span class="line-removed">252   detach_memory(page-&gt;virtual_memory(), page-&gt;physical_memory());</span>
<span class="line-removed">253 </span>
<span class="line-removed">254   // Add to list of detached pages</span>
<span class="line-removed">255   _detached.insert_last(page);</span>
<span class="line-removed">256 }</span>
<span class="line-removed">257 </span>
<span class="line-removed">258 void ZPageAllocator::destroy_page(ZPage* page) {</span>
<span class="line-removed">259   assert(page-&gt;is_detached(), &quot;Invalid page state&quot;);</span>
260 
<span class="line-modified">261   // Free virtual memory</span>
<span class="line-modified">262   {</span>
<span class="line-modified">263     ZLocker&lt;ZLock&gt; locker(&amp;_lock);</span>
<span class="line-removed">264     _virtual.free(page-&gt;virtual_memory());</span>
265   }
266 
<span class="line-modified">267   delete page;</span>
<span class="line-removed">268 }</span>
<span class="line-removed">269 </span>
<span class="line-removed">270 void ZPageAllocator::flush_detached_pages(ZList&lt;ZPage&gt;* list) {</span>
<span class="line-removed">271   ZLocker&lt;ZLock&gt; locker(&amp;_lock);</span>
<span class="line-removed">272   list-&gt;transfer(&amp;_detached);</span>
273 }
274 
<span class="line-modified">275 void ZPageAllocator::flush_cache(size_t size) {</span>
<span class="line-modified">276   ZList&lt;ZPage&gt; list;</span>
<span class="line-modified">277 </span>
<span class="line-modified">278   _cache.flush(&amp;list, size);</span>

































279 
<span class="line-modified">280   for (ZPage* page = list.remove_first(); page != NULL; page = list.remove_first()) {</span>
<span class="line-modified">281     detach_page(page);</span>
282   }



283 }
284 
<span class="line-modified">285 void ZPageAllocator::check_out_of_memory_during_initialization() {</span>
<span class="line-modified">286   if (!is_init_completed()) {</span>
<span class="line-modified">287     vm_exit_during_initialization(&quot;java.lang.OutOfMemoryError&quot;, &quot;Java heap too small&quot;);</span>


288   }
289 }
290 
<span class="line-modified">291 ZPage* ZPageAllocator::alloc_page_common_inner(uint8_t type, size_t size, ZAllocationFlags flags) {</span>
<span class="line-modified">292   const size_t max = max_available(flags.no_reserve());</span>
<span class="line-removed">293   if (max &lt; size) {</span>
294     // Not enough free memory
295     return NULL;
296   }
297 
<span class="line-modified">298   // Try allocating from the page cache</span>
<span class="line-modified">299   ZPage* const cached_page = _cache.alloc_page(type, size);</span>
<span class="line-modified">300   if (cached_page != NULL) {</span>
<span class="line-modified">301     return cached_page;</span>
<span class="line-removed">302   }</span>
<span class="line-removed">303 </span>
<span class="line-removed">304   // Try allocate from the pre-mapped memory</span>
<span class="line-removed">305   ZPage* const pre_mapped_page = _pre_mapped.alloc_page(type, size);</span>
<span class="line-removed">306   if (pre_mapped_page != NULL) {</span>
<span class="line-removed">307     return pre_mapped_page;</span>
308   }
309 
<span class="line-modified">310   // Flush any remaining pre-mapped memory so that</span>
<span class="line-modified">311   // subsequent allocations can use the physical memory.</span>
<span class="line-removed">312   flush_pre_mapped();</span>
<span class="line-removed">313 </span>
<span class="line-removed">314   // Try ensure that physical memory is available</span>
<span class="line-removed">315   const size_t unused = try_ensure_unused(size, flags.no_reserve());</span>
<span class="line-removed">316   if (unused &lt; size) {</span>
<span class="line-removed">317     // Flush cache to free up more physical memory</span>
<span class="line-removed">318     flush_cache(size - unused);</span>
<span class="line-removed">319   }</span>
320 
<span class="line-modified">321   // Create new page and allocate physical memory</span>
322   return create_page(type, size);
323 }
324 
325 ZPage* ZPageAllocator::alloc_page_common(uint8_t type, size_t size, ZAllocationFlags flags) {
<span class="line-modified">326   ZPage* const page = alloc_page_common_inner(type, size, flags);</span>
327   if (page == NULL) {
328     // Out of memory
329     return NULL;
330   }
331 
332   // Update used statistics
333   increase_used(size, flags.relocation());
334 
335   // Send trace event
<span class="line-modified">336   ZTracer::tracer()-&gt;report_page_alloc(size, used(), max_available(flags.no_reserve()), _cache.available(), flags);</span>
337 
338   return page;
339 }
340 






341 ZPage* ZPageAllocator::alloc_page_blocking(uint8_t type, size_t size, ZAllocationFlags flags) {
342   // Prepare to block
343   ZPageAllocRequest request(type, size, flags, ZCollectedHeap::heap()-&gt;total_collections());
344 
345   _lock.lock();
346 
347   // Try non-blocking allocation
348   ZPage* page = alloc_page_common(type, size, flags);
349   if (page == NULL) {
350     // Allocation failed, enqueue request
351     _queue.insert_last(&amp;request);
352   }
353 
354   _lock.unlock();
355 
356   if (page == NULL) {
357     // Allocation failed
358     ZStatTimer timer(ZCriticalPhaseAllocationStall);
359 
360     // We can only block if VM is fully initialized
361     check_out_of_memory_during_initialization();
362 
363     do {
364       // Start asynchronous GC
365       ZCollectedHeap::heap()-&gt;collect(GCCause::_z_allocation_stall);
366 
367       // Wait for allocation to complete or fail
368       page = request.wait();
369     } while (page == gc_marker);
370 
371     {
<span class="line-modified">372       // Guard deletion of underlying semaphore. This is a workaround for a</span>
<span class="line-modified">373       // bug in sem_post() in glibc &lt; 2.21, where it&#39;s not safe to destroy</span>



374       // the semaphore immediately after returning from sem_wait(). The
375       // reason is that sem_post() can touch the semaphore after a waiting
376       // thread have returned from sem_wait(). To avoid this race we are
377       // forcing the waiting thread to acquire/release the lock held by the
378       // posting thread. https://sourceware.org/bugzilla/show_bug.cgi?id=12674



379       ZLocker&lt;ZLock&gt; locker(&amp;_lock);

380     }
381   }
382 
383   return page;
384 }
385 
386 ZPage* ZPageAllocator::alloc_page_nonblocking(uint8_t type, size_t size, ZAllocationFlags flags) {
387   ZLocker&lt;ZLock&gt; locker(&amp;_lock);
388   return alloc_page_common(type, size, flags);
389 }
390 
391 ZPage* ZPageAllocator::alloc_page(uint8_t type, size_t size, ZAllocationFlags flags) {
392   ZPage* const page = flags.non_blocking()
393                       ? alloc_page_nonblocking(type, size, flags)
394                       : alloc_page_blocking(type, size, flags);
395   if (page == NULL) {
396     // Out of memory
397     return NULL;
398   }
399 
</pre>
<hr />
<pre>
421 }
422 
423 void ZPageAllocator::satisfy_alloc_queue() {
424   for (;;) {
425     ZPageAllocRequest* const request = _queue.first();
426     if (request == NULL) {
427       // Allocation queue is empty
428       return;
429     }
430 
431     ZPage* const page = alloc_page_common(request-&gt;type(), request-&gt;size(), request-&gt;flags());
432     if (page == NULL) {
433       // Allocation could not be satisfied, give up
434       return;
435     }
436 
437     // Allocation succeeded, dequeue and satisfy request. Note that
438     // the dequeue operation must happen first, since the request
439     // will immediately be deallocated once it has been satisfied.
440     _queue.remove(request);

441     request-&gt;satisfy(page);
442   }
443 }
444 
<span class="line-modified">445 void ZPageAllocator::detach_memory(const ZVirtualMemory&amp; vmem, ZPhysicalMemory&amp; pmem) {</span>
<span class="line-modified">446   const uintptr_t addr = vmem.start();</span>
447 
<span class="line-modified">448   // Unmap physical memory</span>
<span class="line-modified">449   _physical.unmap(pmem, addr);</span>
450 
<span class="line-modified">451   // Free physical memory</span>
<span class="line-modified">452   _physical.free(pmem);</span>
453 
<span class="line-modified">454   // Clear physical mapping</span>
<span class="line-modified">455   pmem.clear();</span>



456 }
457 
<span class="line-modified">458 void ZPageAllocator::flip_page(ZPage* page) {</span>
<span class="line-modified">459   const ZPhysicalMemory&amp; pmem = page-&gt;physical_memory();</span>
<span class="line-modified">460   const uintptr_t addr = page-&gt;start();</span>









461 
<span class="line-modified">462   // Flip physical mapping</span>
<span class="line-modified">463   _physical.flip(pmem, addr);</span>






464 }
465 
<span class="line-modified">466 void ZPageAllocator::flip_pre_mapped() {</span>
<span class="line-modified">467   if (_pre_mapped.available() == 0) {</span>
<span class="line-modified">468     // Nothing to flip</span>
<span class="line-modified">469     return;</span>










470   }

471 
<span class="line-modified">472   const ZPhysicalMemory&amp; pmem = _pre_mapped.physical_memory();</span>
<span class="line-modified">473   const ZVirtualMemory&amp; vmem = _pre_mapped.virtual_memory();</span>
474 
<span class="line-modified">475   // Flip physical mapping</span>
<span class="line-modified">476   _physical.flip(pmem, vmem.start());</span>















477 }
478 
<span class="line-modified">479 void ZPageAllocator::free_page(ZPage* page, bool reclaimed) {</span>
<span class="line-modified">480   ZLocker&lt;ZLock&gt; locker(&amp;_lock);</span>



481 
<span class="line-modified">482   // Update used statistics</span>
<span class="line-modified">483   decrease_used(page-&gt;size(), reclaimed);</span>














484 
<span class="line-modified">485   // Cache page</span>
<span class="line-modified">486   _cache.free_page(page);</span>
487 
<span class="line-modified">488   // Try satisfy blocked allocations</span>
<span class="line-modified">489   satisfy_alloc_queue();</span>



























































































490 }
491 
492 bool ZPageAllocator::is_alloc_stalled() const {
493   assert(SafepointSynchronize::is_at_safepoint(), &quot;Should be at safepoint&quot;);
494   return !_queue.is_empty();
495 }
496 
497 void ZPageAllocator::check_out_of_memory() {
498   ZLocker&lt;ZLock&gt; locker(&amp;_lock);
499 
500   // Fail allocation requests that were enqueued before the
501   // last GC cycle started, otherwise start a new GC cycle.
502   for (ZPageAllocRequest* request = _queue.first(); request != NULL; request = _queue.first()) {
503     if (request-&gt;total_collections() == ZCollectedHeap::heap()-&gt;total_collections()) {
504       // Start a new GC cycle, keep allocation requests enqueued
505       request-&gt;satisfy(gc_marker);
506       return;
507     }
508 
509     // Out of memory, fail allocation request
<span class="line-modified">510     _queue.remove_first();</span>

511     request-&gt;satisfy(NULL);
512   }
513 }
</pre>
</td>
<td>
<hr />
<pre>
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 #include &quot;precompiled.hpp&quot;
<span class="line-added"> 25 #include &quot;gc/shared/suspendibleThreadSet.hpp&quot;</span>
 26 #include &quot;gc/z/zAddress.inline.hpp&quot;
 27 #include &quot;gc/z/zCollectedHeap.hpp&quot;
 28 #include &quot;gc/z/zFuture.inline.hpp&quot;
 29 #include &quot;gc/z/zGlobals.hpp&quot;
 30 #include &quot;gc/z/zLock.inline.hpp&quot;
 31 #include &quot;gc/z/zPage.inline.hpp&quot;
 32 #include &quot;gc/z/zPageAllocator.hpp&quot;
 33 #include &quot;gc/z/zPageCache.inline.hpp&quot;
<span class="line-modified"> 34 #include &quot;gc/z/zSafeDelete.inline.hpp&quot;</span>
 35 #include &quot;gc/z/zStat.hpp&quot;
<span class="line-added"> 36 #include &quot;gc/z/zTask.hpp&quot;</span>
 37 #include &quot;gc/z/zTracer.inline.hpp&quot;
<span class="line-added"> 38 #include &quot;gc/z/zWorkers.hpp&quot;</span>
<span class="line-added"> 39 #include &quot;runtime/globals.hpp&quot;</span>
 40 #include &quot;runtime/init.hpp&quot;
<span class="line-added"> 41 #include &quot;runtime/java.hpp&quot;</span>
<span class="line-added"> 42 #include &quot;utilities/debug.hpp&quot;</span>
 43 
 44 static const ZStatCounter       ZCounterAllocationRate(&quot;Memory&quot;, &quot;Allocation Rate&quot;, ZStatUnitBytesPerSecond);
<span class="line-added"> 45 static const ZStatCounter       ZCounterPageCacheFlush(&quot;Memory&quot;, &quot;Page Cache Flush&quot;, ZStatUnitBytesPerSecond);</span>
<span class="line-added"> 46 static const ZStatCounter       ZCounterUncommit(&quot;Memory&quot;, &quot;Uncommit&quot;, ZStatUnitBytesPerSecond);</span>
 47 static const ZStatCriticalPhase ZCriticalPhaseAllocationStall(&quot;Allocation Stall&quot;);
 48 
 49 class ZPageAllocRequest : public StackObj {
 50   friend class ZList&lt;ZPageAllocRequest&gt;;
 51 
 52 private:
 53   const uint8_t                _type;
 54   const size_t                 _size;
 55   const ZAllocationFlags       _flags;
 56   const unsigned int           _total_collections;
 57   ZListNode&lt;ZPageAllocRequest&gt; _node;
 58   ZFuture&lt;ZPage*&gt;              _result;
 59 
 60 public:
 61   ZPageAllocRequest(uint8_t type, size_t size, ZAllocationFlags flags, unsigned int total_collections) :
 62       _type(type),
 63       _size(size),
 64       _flags(flags),
<span class="line-modified"> 65       _total_collections(total_collections),</span>
<span class="line-added"> 66       _node(),</span>
<span class="line-added"> 67       _result() {}</span>
 68 
 69   uint8_t type() const {
 70     return _type;
 71   }
 72 
 73   size_t size() const {
 74     return _size;
 75   }
 76 
 77   ZAllocationFlags flags() const {
 78     return _flags;
 79   }
 80 
 81   unsigned int total_collections() const {
 82     return _total_collections;
 83   }
 84 
<span class="line-added"> 85   ZPage* peek() {</span>
<span class="line-added"> 86     return _result.peek();</span>
<span class="line-added"> 87   }</span>
<span class="line-added"> 88 </span>
 89   ZPage* wait() {
 90     return _result.get();
 91   }
 92 
 93   void satisfy(ZPage* page) {
 94     _result.set(page);
 95   }
 96 };
 97 
 98 ZPage* const ZPageAllocator::gc_marker = (ZPage*)-1;
 99 
<span class="line-modified">100 ZPageAllocator::ZPageAllocator(ZWorkers* workers,</span>
<span class="line-added">101                                size_t min_capacity,</span>
<span class="line-added">102                                size_t initial_capacity,</span>
<span class="line-added">103                                size_t max_capacity,</span>
<span class="line-added">104                                size_t max_reserve) :</span>
105     _lock(),
<span class="line-modified">106     _virtual(max_capacity),</span>
<span class="line-modified">107     _physical(),</span>
108     _cache(),
<span class="line-added">109     _min_capacity(min_capacity),</span>
<span class="line-added">110     _max_capacity(max_capacity),</span>
111     _max_reserve(max_reserve),
<span class="line-modified">112     _current_max_capacity(max_capacity),</span>
<span class="line-added">113     _capacity(0),</span>
114     _used_high(0),
115     _used_low(0),
116     _used(0),
117     _allocated(0),
118     _reclaimed(0),
119     _queue(),
<span class="line-modified">120     _satisfied(),</span>
<span class="line-added">121     _safe_delete(),</span>
<span class="line-added">122     _uncommit(false),</span>
<span class="line-added">123     _initialized(false) {</span>
<span class="line-added">124 </span>
<span class="line-added">125   if (!_virtual.is_initialized() || !_physical.is_initialized()) {</span>
<span class="line-added">126     return;</span>
<span class="line-added">127   }</span>
<span class="line-added">128 </span>
<span class="line-added">129   log_info(gc, init)(&quot;Min Capacity: &quot; SIZE_FORMAT &quot;M&quot;, min_capacity / M);</span>
<span class="line-added">130   log_info(gc, init)(&quot;Initial Capacity: &quot; SIZE_FORMAT &quot;M&quot;, initial_capacity / M);</span>
<span class="line-added">131   log_info(gc, init)(&quot;Max Capacity: &quot; SIZE_FORMAT &quot;M&quot;, max_capacity / M);</span>
<span class="line-added">132   log_info(gc, init)(&quot;Max Reserve: &quot; SIZE_FORMAT &quot;M&quot;, max_reserve / M);</span>
<span class="line-added">133   log_info(gc, init)(&quot;Pre-touch: %s&quot;, AlwaysPreTouch ? &quot;Enabled&quot; : &quot;Disabled&quot;);</span>
<span class="line-added">134 </span>
<span class="line-added">135   // Warn if system limits could stop us from reaching max capacity</span>
<span class="line-added">136   _physical.warn_commit_limits(max_capacity);</span>
<span class="line-added">137 </span>
<span class="line-added">138   // Commit initial capacity</span>
<span class="line-added">139   _capacity = _physical.commit(initial_capacity);</span>
<span class="line-added">140   if (_capacity != initial_capacity) {</span>
<span class="line-added">141     log_error(gc)(&quot;Failed to allocate initial Java heap (&quot; SIZE_FORMAT &quot;M)&quot;, initial_capacity / M);</span>
<span class="line-added">142     return;</span>
<span class="line-added">143   }</span>
<span class="line-added">144 </span>
<span class="line-added">145   // If uncommit is not explicitly disabled, max capacity is greater than</span>
<span class="line-added">146   // min capacity, and uncommit is supported by the platform, then we will</span>
<span class="line-added">147   // try to uncommit unused memory.</span>
<span class="line-added">148   _uncommit = ZUncommit &amp;&amp; (max_capacity &gt; min_capacity) &amp;&amp; _physical.supports_uncommit();</span>
<span class="line-added">149   if (_uncommit) {</span>
<span class="line-added">150     log_info(gc, init)(&quot;Uncommit: Enabled, Delay: &quot; UINTX_FORMAT &quot;s&quot;, ZUncommitDelay);</span>
<span class="line-added">151   } else {</span>
<span class="line-added">152     log_info(gc, init)(&quot;Uncommit: Disabled&quot;);</span>
<span class="line-added">153   }</span>
<span class="line-added">154 </span>
<span class="line-added">155   // Pre-map initial capacity</span>
<span class="line-added">156   prime_cache(workers, initial_capacity);</span>
<span class="line-added">157 </span>
<span class="line-added">158   // Successfully initialized</span>
<span class="line-added">159   _initialized = true;</span>
<span class="line-added">160 }</span>
<span class="line-added">161 </span>
<span class="line-added">162 class ZPreTouchTask : public ZTask {</span>
<span class="line-added">163 private:</span>
<span class="line-added">164   const ZPhysicalMemoryManager* const _physical;</span>
<span class="line-added">165   volatile uintptr_t                  _start;</span>
<span class="line-added">166   const uintptr_t                     _end;</span>
<span class="line-added">167 </span>
<span class="line-added">168 public:</span>
<span class="line-added">169   ZPreTouchTask(const ZPhysicalMemoryManager* physical, uintptr_t start, uintptr_t end) :</span>
<span class="line-added">170       ZTask(&quot;ZPreTouchTask&quot;),</span>
<span class="line-added">171       _physical(physical),</span>
<span class="line-added">172       _start(start),</span>
<span class="line-added">173       _end(end) {}</span>
<span class="line-added">174 </span>
<span class="line-added">175   virtual void work() {</span>
<span class="line-added">176     for (;;) {</span>
<span class="line-added">177       // Get granule offset</span>
<span class="line-added">178       const size_t size = ZGranuleSize;</span>
<span class="line-added">179       const uintptr_t offset = Atomic::fetch_and_add(&amp;_start, size);</span>
<span class="line-added">180       if (offset &gt;= _end) {</span>
<span class="line-added">181         // Done</span>
<span class="line-added">182         break;</span>
<span class="line-added">183       }</span>
<span class="line-added">184 </span>
<span class="line-added">185       // Pre-touch granule</span>
<span class="line-added">186       _physical-&gt;pretouch(offset, size);</span>
<span class="line-added">187     }</span>
<span class="line-added">188   }</span>
<span class="line-added">189 };</span>
<span class="line-added">190 </span>
<span class="line-added">191 void ZPageAllocator::prime_cache(ZWorkers* workers, size_t size) {</span>
<span class="line-added">192   // Allocate physical memory</span>
<span class="line-added">193   const ZPhysicalMemory pmem = _physical.alloc(size);</span>
<span class="line-added">194   guarantee(!pmem.is_null(), &quot;Invalid size&quot;);</span>
<span class="line-added">195 </span>
<span class="line-added">196   // Allocate virtual memory</span>
<span class="line-added">197   const ZVirtualMemory vmem = _virtual.alloc(size, true /* alloc_from_front */);</span>
<span class="line-added">198   guarantee(!vmem.is_null(), &quot;Invalid size&quot;);</span>
<span class="line-added">199 </span>
<span class="line-added">200   // Allocate page</span>
<span class="line-added">201   ZPage* const page = new ZPage(vmem, pmem);</span>
<span class="line-added">202 </span>
<span class="line-added">203   // Map page</span>
<span class="line-added">204   map_page(page);</span>
<span class="line-added">205   page-&gt;set_pre_mapped();</span>
<span class="line-added">206 </span>
<span class="line-added">207   if (AlwaysPreTouch) {</span>
<span class="line-added">208     // Pre-touch page</span>
<span class="line-added">209     ZPreTouchTask task(&amp;_physical, page-&gt;start(), page-&gt;end());</span>
<span class="line-added">210     workers-&gt;run_parallel(&amp;task);</span>
<span class="line-added">211   }</span>
<span class="line-added">212 </span>
<span class="line-added">213   // Add page to cache</span>
<span class="line-added">214   page-&gt;set_last_used();</span>
<span class="line-added">215   _cache.free_page(page);</span>
<span class="line-added">216 }</span>
217 
218 bool ZPageAllocator::is_initialized() const {
<span class="line-modified">219   return _initialized;</span>
<span class="line-modified">220 }</span>
<span class="line-modified">221 </span>
<span class="line-added">222 size_t ZPageAllocator::min_capacity() const {</span>
<span class="line-added">223   return _min_capacity;</span>
224 }
225 
226 size_t ZPageAllocator::max_capacity() const {
<span class="line-modified">227   return _max_capacity;</span>
228 }
229 
<span class="line-modified">230 size_t ZPageAllocator::soft_max_capacity() const {</span>
<span class="line-modified">231   // Note that SoftMaxHeapSize is a manageable flag</span>
<span class="line-added">232   return MIN2(SoftMaxHeapSize, _current_max_capacity);</span>
233 }
234 
235 size_t ZPageAllocator::capacity() const {
<span class="line-modified">236   return _capacity;</span>
237 }
238 
239 size_t ZPageAllocator::max_reserve() const {
240   return _max_reserve;
241 }
242 
243 size_t ZPageAllocator::used_high() const {
244   return _used_high;
245 }
246 
247 size_t ZPageAllocator::used_low() const {
248   return _used_low;
249 }
250 
251 size_t ZPageAllocator::used() const {
252   return _used;
253 }
254 
<span class="line-added">255 size_t ZPageAllocator::unused() const {</span>
<span class="line-added">256   const ssize_t unused = (ssize_t)_capacity - (ssize_t)_used - (ssize_t)_max_reserve;</span>
<span class="line-added">257   return unused &gt; 0 ? (size_t)unused : 0;</span>
<span class="line-added">258 }</span>
<span class="line-added">259 </span>
260 size_t ZPageAllocator::allocated() const {
261   return _allocated;
262 }
263 
264 size_t ZPageAllocator::reclaimed() const {
265   return _reclaimed &gt; 0 ? (size_t)_reclaimed : 0;
266 }
267 
268 void ZPageAllocator::reset_statistics() {
269   assert(SafepointSynchronize::is_at_safepoint(), &quot;Should be at safepoint&quot;);
270   _allocated = 0;
271   _reclaimed = 0;
272   _used_high = _used_low = _used;
273 }
274 
275 void ZPageAllocator::increase_used(size_t size, bool relocation) {
276   if (relocation) {
277     // Allocating a page for the purpose of relocation has a
278     // negative contribution to the number of reclaimed bytes.
279     _reclaimed -= size;
</pre>
<hr />
<pre>
282   _used += size;
283   if (_used &gt; _used_high) {
284     _used_high = _used;
285   }
286 }
287 
288 void ZPageAllocator::decrease_used(size_t size, bool reclaimed) {
289   if (reclaimed) {
290     // Only pages explicitly released with the reclaimed flag set
291     // counts as reclaimed bytes. This flag is typically true when
292     // a worker releases a page after relocation, and is typically
293     // false when we release a page to undo an allocation.
294     _reclaimed += size;
295   }
296   _used -= size;
297   if (_used &lt; _used_low) {
298     _used_low = _used;
299   }
300 }
301 





































302 ZPage* ZPageAllocator::create_page(uint8_t type, size_t size) {







303   // Allocate virtual memory
304   const ZVirtualMemory vmem = _virtual.alloc(size);
305   if (vmem.is_null()) {
306     // Out of address space

307     return NULL;
308   }
309 
<span class="line-added">310   // Allocate physical memory</span>
<span class="line-added">311   const ZPhysicalMemory pmem = _physical.alloc(size);</span>
<span class="line-added">312   assert(!pmem.is_null(), &quot;Invalid size&quot;);</span>
<span class="line-added">313 </span>
314   // Allocate page
315   return new ZPage(type, vmem, pmem);
316 }
317 
<span class="line-modified">318 void ZPageAllocator::destroy_page(ZPage* page) {</span>
<span class="line-modified">319   const ZVirtualMemory&amp; vmem = page-&gt;virtual_memory();</span>
<span class="line-modified">320   const ZPhysicalMemory&amp; pmem = page-&gt;physical_memory();</span>
<span class="line-modified">321 </span>
<span class="line-added">322   // Unmap memory</span>
<span class="line-added">323   _physical.unmap(pmem, vmem.start());</span>
<span class="line-added">324 </span>
<span class="line-added">325   // Free physical memory</span>
<span class="line-added">326   _physical.free(pmem);</span>
327 
<span class="line-modified">328   // Free virtual memory</span>
<span class="line-modified">329   _virtual.free(vmem);</span>
330 
<span class="line-modified">331   // Delete page safely</span>
<span class="line-added">332   _safe_delete(page);</span>
333 }
334 
<span class="line-modified">335 void ZPageAllocator::map_page(const ZPage* page) const {</span>
336   // Map physical memory
337   _physical.map(page-&gt;physical_memory(), page-&gt;start());
338 }
339 
<span class="line-modified">340 size_t ZPageAllocator::max_available(bool no_reserve) const {</span>
<span class="line-modified">341   size_t available = _current_max_capacity - _used;</span>








342 
<span class="line-modified">343   if (no_reserve) {</span>
<span class="line-modified">344     // The reserve should not be considered available</span>
<span class="line-modified">345     available -= MIN2(available, _max_reserve);</span>

346   }
347 
<span class="line-modified">348   return available;</span>





349 }
350 
<span class="line-modified">351 bool ZPageAllocator::ensure_available(size_t size, bool no_reserve) {</span>
<span class="line-modified">352   if (max_available(no_reserve) &lt; size) {</span>
<span class="line-modified">353     // Not enough free memory</span>
<span class="line-modified">354     return false;</span>
<span class="line-added">355   }</span>
<span class="line-added">356 </span>
<span class="line-added">357   // We add the max_reserve to the requested size to avoid losing</span>
<span class="line-added">358   // the reserve because of failure to increase capacity before</span>
<span class="line-added">359   // reaching max capacity.</span>
<span class="line-added">360   size += _max_reserve;</span>
<span class="line-added">361 </span>
<span class="line-added">362   // Don&#39;t try to increase capacity if enough unused capacity</span>
<span class="line-added">363   // is available or if current max capacity has been reached.</span>
<span class="line-added">364   const size_t available = _capacity - _used;</span>
<span class="line-added">365   if (available &lt; size &amp;&amp; _capacity &lt; _current_max_capacity) {</span>
<span class="line-added">366     // Try to increase capacity</span>
<span class="line-added">367     const size_t commit = MIN2(size - available, _current_max_capacity - _capacity);</span>
<span class="line-added">368     const size_t committed = _physical.commit(commit);</span>
<span class="line-added">369     _capacity += committed;</span>
<span class="line-added">370 </span>
<span class="line-added">371     log_trace(gc, heap)(&quot;Make Available: Size: &quot; SIZE_FORMAT &quot;M, NoReserve: %s, &quot;</span>
<span class="line-added">372                         &quot;Available: &quot; SIZE_FORMAT &quot;M, Commit: &quot; SIZE_FORMAT &quot;M, &quot;</span>
<span class="line-added">373                         &quot;Committed: &quot; SIZE_FORMAT &quot;M, Capacity: &quot; SIZE_FORMAT &quot;M&quot;,</span>
<span class="line-added">374                         size / M, no_reserve ? &quot;True&quot; : &quot;False&quot;, available / M,</span>
<span class="line-added">375                         commit / M, committed / M, _capacity / M);</span>
<span class="line-added">376 </span>
<span class="line-added">377     if (committed != commit) {</span>
<span class="line-added">378       // Failed, or partly failed, to increase capacity. Adjust current</span>
<span class="line-added">379       // max capacity to avoid further attempts to increase capacity.</span>
<span class="line-added">380       log_error(gc)(&quot;Forced to lower max Java heap size from &quot;</span>
<span class="line-added">381                     SIZE_FORMAT &quot;M(%.0f%%) to &quot; SIZE_FORMAT &quot;M(%.0f%%)&quot;,</span>
<span class="line-added">382                     _current_max_capacity / M, percent_of(_current_max_capacity, _max_capacity),</span>
<span class="line-added">383                     _capacity / M, percent_of(_capacity, _max_capacity));</span>
<span class="line-added">384 </span>
<span class="line-added">385       _current_max_capacity = _capacity;</span>
<span class="line-added">386     }</span>
<span class="line-added">387   }</span>
388 
<span class="line-modified">389   if (!no_reserve) {</span>
<span class="line-modified">390     size -= _max_reserve;</span>
391   }
<span class="line-added">392 </span>
<span class="line-added">393   const size_t new_available = _capacity - _used;</span>
<span class="line-added">394   return new_available &gt;= size;</span>
395 }
396 
<span class="line-modified">397 void ZPageAllocator::ensure_uncached_available(size_t size) {</span>
<span class="line-modified">398   assert(_capacity - _used &gt;= size, &quot;Invalid size&quot;);</span>
<span class="line-modified">399   const size_t uncached_available = _capacity - _used - _cache.available();</span>
<span class="line-added">400   if (size &gt; uncached_available) {</span>
<span class="line-added">401     flush_cache_for_allocation(size - uncached_available);</span>
402   }
403 }
404 
<span class="line-modified">405 ZPage* ZPageAllocator::alloc_page_common_inner(uint8_t type, size_t size, bool no_reserve) {</span>
<span class="line-modified">406   if (!ensure_available(size, no_reserve)) {</span>

407     // Not enough free memory
408     return NULL;
409   }
410 
<span class="line-modified">411   // Try allocate page from the cache</span>
<span class="line-modified">412   ZPage* const page = _cache.alloc_page(type, size);</span>
<span class="line-modified">413   if (page != NULL) {</span>
<span class="line-modified">414     return page;</span>






415   }
416 
<span class="line-modified">417   // Try flush pages from the cache</span>
<span class="line-modified">418   ensure_uncached_available(size);</span>








419 
<span class="line-modified">420   // Create new page</span>
421   return create_page(type, size);
422 }
423 
424 ZPage* ZPageAllocator::alloc_page_common(uint8_t type, size_t size, ZAllocationFlags flags) {
<span class="line-modified">425   ZPage* const page = alloc_page_common_inner(type, size, flags.no_reserve());</span>
426   if (page == NULL) {
427     // Out of memory
428     return NULL;
429   }
430 
431   // Update used statistics
432   increase_used(size, flags.relocation());
433 
434   // Send trace event
<span class="line-modified">435   ZTracer::tracer()-&gt;report_page_alloc(size, _used, max_available(flags.no_reserve()), _cache.available(), flags);</span>
436 
437   return page;
438 }
439 
<span class="line-added">440 void ZPageAllocator::check_out_of_memory_during_initialization() {</span>
<span class="line-added">441   if (!is_init_completed()) {</span>
<span class="line-added">442     vm_exit_during_initialization(&quot;java.lang.OutOfMemoryError&quot;, &quot;Java heap too small&quot;);</span>
<span class="line-added">443   }</span>
<span class="line-added">444 }</span>
<span class="line-added">445 </span>
446 ZPage* ZPageAllocator::alloc_page_blocking(uint8_t type, size_t size, ZAllocationFlags flags) {
447   // Prepare to block
448   ZPageAllocRequest request(type, size, flags, ZCollectedHeap::heap()-&gt;total_collections());
449 
450   _lock.lock();
451 
452   // Try non-blocking allocation
453   ZPage* page = alloc_page_common(type, size, flags);
454   if (page == NULL) {
455     // Allocation failed, enqueue request
456     _queue.insert_last(&amp;request);
457   }
458 
459   _lock.unlock();
460 
461   if (page == NULL) {
462     // Allocation failed
463     ZStatTimer timer(ZCriticalPhaseAllocationStall);
464 
465     // We can only block if VM is fully initialized
466     check_out_of_memory_during_initialization();
467 
468     do {
469       // Start asynchronous GC
470       ZCollectedHeap::heap()-&gt;collect(GCCause::_z_allocation_stall);
471 
472       // Wait for allocation to complete or fail
473       page = request.wait();
474     } while (page == gc_marker);
475 
476     {
<span class="line-modified">477       //</span>
<span class="line-modified">478       // We grab the lock here for two different reasons:</span>
<span class="line-added">479       //</span>
<span class="line-added">480       // 1) Guard deletion of underlying semaphore. This is a workaround for</span>
<span class="line-added">481       // a bug in sem_post() in glibc &lt; 2.21, where it&#39;s not safe to destroy</span>
482       // the semaphore immediately after returning from sem_wait(). The
483       // reason is that sem_post() can touch the semaphore after a waiting
484       // thread have returned from sem_wait(). To avoid this race we are
485       // forcing the waiting thread to acquire/release the lock held by the
486       // posting thread. https://sourceware.org/bugzilla/show_bug.cgi?id=12674
<span class="line-added">487       //</span>
<span class="line-added">488       // 2) Guard the list of satisfied pages.</span>
<span class="line-added">489       //</span>
490       ZLocker&lt;ZLock&gt; locker(&amp;_lock);
<span class="line-added">491       _satisfied.remove(&amp;request);</span>
492     }
493   }
494 
495   return page;
496 }
497 
498 ZPage* ZPageAllocator::alloc_page_nonblocking(uint8_t type, size_t size, ZAllocationFlags flags) {
499   ZLocker&lt;ZLock&gt; locker(&amp;_lock);
500   return alloc_page_common(type, size, flags);
501 }
502 
503 ZPage* ZPageAllocator::alloc_page(uint8_t type, size_t size, ZAllocationFlags flags) {
504   ZPage* const page = flags.non_blocking()
505                       ? alloc_page_nonblocking(type, size, flags)
506                       : alloc_page_blocking(type, size, flags);
507   if (page == NULL) {
508     // Out of memory
509     return NULL;
510   }
511 
</pre>
<hr />
<pre>
533 }
534 
535 void ZPageAllocator::satisfy_alloc_queue() {
536   for (;;) {
537     ZPageAllocRequest* const request = _queue.first();
538     if (request == NULL) {
539       // Allocation queue is empty
540       return;
541     }
542 
543     ZPage* const page = alloc_page_common(request-&gt;type(), request-&gt;size(), request-&gt;flags());
544     if (page == NULL) {
545       // Allocation could not be satisfied, give up
546       return;
547     }
548 
549     // Allocation succeeded, dequeue and satisfy request. Note that
550     // the dequeue operation must happen first, since the request
551     // will immediately be deallocated once it has been satisfied.
552     _queue.remove(request);
<span class="line-added">553     _satisfied.insert_first(request);</span>
554     request-&gt;satisfy(page);
555   }
556 }
557 
<span class="line-modified">558 void ZPageAllocator::free_page(ZPage* page, bool reclaimed) {</span>
<span class="line-modified">559   ZLocker&lt;ZLock&gt; locker(&amp;_lock);</span>
560 
<span class="line-modified">561   // Update used statistics</span>
<span class="line-modified">562   decrease_used(page-&gt;size(), reclaimed);</span>
563 
<span class="line-modified">564   // Set time when last used</span>
<span class="line-modified">565   page-&gt;set_last_used();</span>
566 
<span class="line-modified">567   // Cache page</span>
<span class="line-modified">568   _cache.free_page(page);</span>
<span class="line-added">569 </span>
<span class="line-added">570   // Try satisfy blocked allocations</span>
<span class="line-added">571   satisfy_alloc_queue();</span>
572 }
573 
<span class="line-modified">574 size_t ZPageAllocator::flush_cache(ZPageCacheFlushClosure* cl) {</span>
<span class="line-modified">575   ZList&lt;ZPage&gt; list;</span>
<span class="line-modified">576 </span>
<span class="line-added">577   // Flush pages</span>
<span class="line-added">578   _cache.flush(cl, &amp;list);</span>
<span class="line-added">579 </span>
<span class="line-added">580   const size_t overflushed = cl-&gt;overflushed();</span>
<span class="line-added">581   if (overflushed &gt; 0) {</span>
<span class="line-added">582     // Overflushed, keep part of last page</span>
<span class="line-added">583     ZPage* const page = list.last()-&gt;split(overflushed);</span>
<span class="line-added">584     _cache.free_page(page);</span>
<span class="line-added">585   }</span>
586 
<span class="line-modified">587   // Destroy pages</span>
<span class="line-modified">588   size_t flushed = 0;</span>
<span class="line-added">589   for (ZPage* page = list.remove_first(); page != NULL; page = list.remove_first()) {</span>
<span class="line-added">590     flushed += page-&gt;size();</span>
<span class="line-added">591     destroy_page(page);</span>
<span class="line-added">592   }</span>
<span class="line-added">593 </span>
<span class="line-added">594   return flushed;</span>
595 }
596 
<span class="line-modified">597 class ZPageCacheFlushForAllocationClosure : public ZPageCacheFlushClosure {</span>
<span class="line-modified">598 public:</span>
<span class="line-modified">599   ZPageCacheFlushForAllocationClosure(size_t requested) :</span>
<span class="line-modified">600       ZPageCacheFlushClosure(requested) {}</span>
<span class="line-added">601 </span>
<span class="line-added">602   virtual bool do_page(const ZPage* page) {</span>
<span class="line-added">603     if (_flushed &lt; _requested) {</span>
<span class="line-added">604       // Flush page</span>
<span class="line-added">605       _flushed += page-&gt;size();</span>
<span class="line-added">606       return true;</span>
<span class="line-added">607     }</span>
<span class="line-added">608 </span>
<span class="line-added">609     // Don&#39;t flush page</span>
<span class="line-added">610     return false;</span>
611   }
<span class="line-added">612 };</span>
613 
<span class="line-modified">614 void ZPageAllocator::flush_cache_for_allocation(size_t requested) {</span>
<span class="line-modified">615   assert(requested &lt;= _cache.available(), &quot;Invalid request&quot;);</span>
616 
<span class="line-modified">617   // Flush pages</span>
<span class="line-modified">618   ZPageCacheFlushForAllocationClosure cl(requested);</span>
<span class="line-added">619   const size_t flushed = flush_cache(&amp;cl);</span>
<span class="line-added">620 </span>
<span class="line-added">621   assert(requested == flushed, &quot;Failed to flush&quot;);</span>
<span class="line-added">622 </span>
<span class="line-added">623   const size_t cached_after = _cache.available();</span>
<span class="line-added">624   const size_t cached_before = cached_after + flushed;</span>
<span class="line-added">625 </span>
<span class="line-added">626   log_info(gc, heap)(&quot;Page Cache: &quot; SIZE_FORMAT &quot;M(%.0f%%)-&gt;&quot; SIZE_FORMAT &quot;M(%.0f%%), &quot;</span>
<span class="line-added">627                      &quot;Flushed: &quot; SIZE_FORMAT &quot;M&quot;,</span>
<span class="line-added">628                      cached_before / M, percent_of(cached_before, max_capacity()),</span>
<span class="line-added">629                      cached_after / M, percent_of(cached_after, max_capacity()),</span>
<span class="line-added">630                      flushed / M);</span>
<span class="line-added">631 </span>
<span class="line-added">632   // Update statistics</span>
<span class="line-added">633   ZStatInc(ZCounterPageCacheFlush, flushed);</span>
634 }
635 
<span class="line-modified">636 class ZPageCacheFlushForUncommitClosure : public ZPageCacheFlushClosure {</span>
<span class="line-modified">637 private:</span>
<span class="line-added">638   const uint64_t _now;</span>
<span class="line-added">639   const uint64_t _delay;</span>
<span class="line-added">640   uint64_t       _timeout;</span>
641 
<span class="line-modified">642 public:</span>
<span class="line-modified">643   ZPageCacheFlushForUncommitClosure(size_t requested, uint64_t delay) :</span>
<span class="line-added">644       ZPageCacheFlushClosure(requested),</span>
<span class="line-added">645       _now(os::elapsedTime()),</span>
<span class="line-added">646       _delay(delay),</span>
<span class="line-added">647       _timeout(_delay) {}</span>
<span class="line-added">648 </span>
<span class="line-added">649   virtual bool do_page(const ZPage* page) {</span>
<span class="line-added">650     const uint64_t expires = page-&gt;last_used() + _delay;</span>
<span class="line-added">651     const uint64_t timeout = expires - MIN2(expires, _now);</span>
<span class="line-added">652 </span>
<span class="line-added">653     if (_flushed &lt; _requested &amp;&amp; timeout == 0) {</span>
<span class="line-added">654       // Flush page</span>
<span class="line-added">655       _flushed += page-&gt;size();</span>
<span class="line-added">656       return true;</span>
<span class="line-added">657     }</span>
658 
<span class="line-modified">659     // Record shortest non-expired timeout</span>
<span class="line-modified">660     _timeout = MIN2(_timeout, timeout);</span>
661 
<span class="line-modified">662     // Don&#39;t flush page</span>
<span class="line-modified">663     return false;</span>
<span class="line-added">664   }</span>
<span class="line-added">665 </span>
<span class="line-added">666   uint64_t timeout() const {</span>
<span class="line-added">667     return _timeout;</span>
<span class="line-added">668   }</span>
<span class="line-added">669 };</span>
<span class="line-added">670 </span>
<span class="line-added">671 uint64_t ZPageAllocator::uncommit(uint64_t delay) {</span>
<span class="line-added">672   // Set the default timeout, when no pages are found in the</span>
<span class="line-added">673   // cache or when uncommit is disabled, equal to the delay.</span>
<span class="line-added">674   uint64_t timeout = delay;</span>
<span class="line-added">675 </span>
<span class="line-added">676   if (!_uncommit) {</span>
<span class="line-added">677     // Disabled</span>
<span class="line-added">678     return timeout;</span>
<span class="line-added">679   }</span>
<span class="line-added">680 </span>
<span class="line-added">681   size_t capacity_before;</span>
<span class="line-added">682   size_t capacity_after;</span>
<span class="line-added">683   size_t uncommitted;</span>
<span class="line-added">684 </span>
<span class="line-added">685   {</span>
<span class="line-added">686     SuspendibleThreadSetJoiner joiner;</span>
<span class="line-added">687     ZLocker&lt;ZLock&gt; locker(&amp;_lock);</span>
<span class="line-added">688 </span>
<span class="line-added">689     // Don&#39;t flush more than we will uncommit. Never uncommit</span>
<span class="line-added">690     // the reserve, and never uncommit below min capacity.</span>
<span class="line-added">691     const size_t needed = MIN2(_used + _max_reserve, _current_max_capacity);</span>
<span class="line-added">692     const size_t guarded = MAX2(needed, _min_capacity);</span>
<span class="line-added">693     const size_t uncommittable = _capacity - guarded;</span>
<span class="line-added">694     const size_t uncached_available = _capacity - _used - _cache.available();</span>
<span class="line-added">695     size_t uncommit = MIN2(uncommittable, uncached_available);</span>
<span class="line-added">696     const size_t flush = uncommittable - uncommit;</span>
<span class="line-added">697 </span>
<span class="line-added">698     if (flush &gt; 0) {</span>
<span class="line-added">699       // Flush pages to uncommit</span>
<span class="line-added">700       ZPageCacheFlushForUncommitClosure cl(flush, delay);</span>
<span class="line-added">701       uncommit += flush_cache(&amp;cl);</span>
<span class="line-added">702       timeout = cl.timeout();</span>
<span class="line-added">703     }</span>
<span class="line-added">704 </span>
<span class="line-added">705     // Uncommit</span>
<span class="line-added">706     uncommitted = _physical.uncommit(uncommit);</span>
<span class="line-added">707     _capacity -= uncommitted;</span>
<span class="line-added">708 </span>
<span class="line-added">709     capacity_after = _capacity;</span>
<span class="line-added">710     capacity_before = capacity_after + uncommitted;</span>
<span class="line-added">711   }</span>
<span class="line-added">712 </span>
<span class="line-added">713   if (uncommitted &gt; 0) {</span>
<span class="line-added">714     log_info(gc, heap)(&quot;Capacity: &quot; SIZE_FORMAT &quot;M(%.0f%%)-&gt;&quot; SIZE_FORMAT &quot;M(%.0f%%), &quot;</span>
<span class="line-added">715                        &quot;Uncommitted: &quot; SIZE_FORMAT &quot;M&quot;,</span>
<span class="line-added">716                        capacity_before / M, percent_of(capacity_before, max_capacity()),</span>
<span class="line-added">717                        capacity_after / M, percent_of(capacity_after, max_capacity()),</span>
<span class="line-added">718                        uncommitted / M);</span>
<span class="line-added">719 </span>
<span class="line-added">720     // Update statistics</span>
<span class="line-added">721     ZStatInc(ZCounterUncommit, uncommitted);</span>
<span class="line-added">722   }</span>
<span class="line-added">723 </span>
<span class="line-added">724   return timeout;</span>
<span class="line-added">725 }</span>
<span class="line-added">726 </span>
<span class="line-added">727 void ZPageAllocator::enable_deferred_delete() const {</span>
<span class="line-added">728   _safe_delete.enable_deferred_delete();</span>
<span class="line-added">729 }</span>
<span class="line-added">730 </span>
<span class="line-added">731 void ZPageAllocator::disable_deferred_delete() const {</span>
<span class="line-added">732   _safe_delete.disable_deferred_delete();</span>
<span class="line-added">733 }</span>
<span class="line-added">734 </span>
<span class="line-added">735 void ZPageAllocator::debug_map_page(const ZPage* page) const {</span>
<span class="line-added">736   assert(SafepointSynchronize::is_at_safepoint(), &quot;Should be at safepoint&quot;);</span>
<span class="line-added">737   _physical.debug_map(page-&gt;physical_memory(), page-&gt;start());</span>
<span class="line-added">738 }</span>
<span class="line-added">739 </span>
<span class="line-added">740 void ZPageAllocator::debug_unmap_page(const ZPage* page) const {</span>
<span class="line-added">741   assert(SafepointSynchronize::is_at_safepoint(), &quot;Should be at safepoint&quot;);</span>
<span class="line-added">742   _physical.debug_unmap(page-&gt;physical_memory(), page-&gt;start());</span>
<span class="line-added">743 }</span>
<span class="line-added">744 </span>
<span class="line-added">745 void ZPageAllocator::pages_do(ZPageClosure* cl) const {</span>
<span class="line-added">746   ZListIterator&lt;ZPageAllocRequest&gt; iter(&amp;_satisfied);</span>
<span class="line-added">747   for (ZPageAllocRequest* request; iter.next(&amp;request);) {</span>
<span class="line-added">748     const ZPage* const page = request-&gt;peek();</span>
<span class="line-added">749     if (page != NULL) {</span>
<span class="line-added">750       cl-&gt;do_page(page);</span>
<span class="line-added">751     }</span>
<span class="line-added">752   }</span>
<span class="line-added">753 </span>
<span class="line-added">754   _cache.pages_do(cl);</span>
755 }
756 
757 bool ZPageAllocator::is_alloc_stalled() const {
758   assert(SafepointSynchronize::is_at_safepoint(), &quot;Should be at safepoint&quot;);
759   return !_queue.is_empty();
760 }
761 
762 void ZPageAllocator::check_out_of_memory() {
763   ZLocker&lt;ZLock&gt; locker(&amp;_lock);
764 
765   // Fail allocation requests that were enqueued before the
766   // last GC cycle started, otherwise start a new GC cycle.
767   for (ZPageAllocRequest* request = _queue.first(); request != NULL; request = _queue.first()) {
768     if (request-&gt;total_collections() == ZCollectedHeap::heap()-&gt;total_collections()) {
769       // Start a new GC cycle, keep allocation requests enqueued
770       request-&gt;satisfy(gc_marker);
771       return;
772     }
773 
774     // Out of memory, fail allocation request
<span class="line-modified">775     _queue.remove(request);</span>
<span class="line-added">776     _satisfied.insert_first(request);</span>
777     request-&gt;satisfy(NULL);
778   }
779 }
</pre>
</td>
</tr>
</table>
<center><a href="zPage.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="zPageAllocator.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>