<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/z/zBarrier.inline.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="zBarrier.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="zBarrierSet.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/z/zBarrier.inline.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2015, 2017, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 #ifndef SHARE_GC_Z_ZBARRIER_INLINE_HPP
 25 #define SHARE_GC_Z_ZBARRIER_INLINE_HPP
 26 

 27 #include &quot;gc/z/zAddress.inline.hpp&quot;
 28 #include &quot;gc/z/zBarrier.hpp&quot;
 29 #include &quot;gc/z/zOop.inline.hpp&quot;
 30 #include &quot;gc/z/zResurrection.inline.hpp&quot;

 31 #include &quot;runtime/atomic.hpp&quot;
 32 








































































































 33 template &lt;ZBarrierFastPath fast_path, ZBarrierSlowPath slow_path&gt;
 34 inline oop ZBarrier::barrier(volatile oop* p, oop o) {
<span class="line-modified"> 35   uintptr_t addr = ZOop::to_address(o);</span>
 36 
<span class="line-removed"> 37 retry:</span>
 38   // Fast path
 39   if (fast_path(addr)) {
<span class="line-modified"> 40     return ZOop::to_oop(addr);</span>
 41   }
 42 
 43   // Slow path
 44   const uintptr_t good_addr = slow_path(addr);
 45 
<span class="line-modified"> 46   // Self heal, but only if the address was actually updated by the slow path,</span>
<span class="line-modified"> 47   // which might not be the case, e.g. when marking through an already good oop.</span>
<span class="line-removed"> 48   if (p != NULL &amp;&amp; good_addr != addr) {</span>
<span class="line-removed"> 49     const uintptr_t prev_addr = Atomic::cmpxchg(good_addr, (volatile uintptr_t*)p, addr);</span>
<span class="line-removed"> 50     if (prev_addr != addr) {</span>
<span class="line-removed"> 51       // Some other thread overwrote the oop. If this oop was updated by a</span>
<span class="line-removed"> 52       // weak barrier the new oop might not be good, in which case we need</span>
<span class="line-removed"> 53       // to re-apply this barrier.</span>
<span class="line-removed"> 54       addr = prev_addr;</span>
<span class="line-removed"> 55       goto retry;</span>
<span class="line-removed"> 56     }</span>
 57   }
 58 
<span class="line-modified"> 59   return ZOop::to_oop(good_addr);</span>
 60 }
 61 
 62 template &lt;ZBarrierFastPath fast_path, ZBarrierSlowPath slow_path&gt;
 63 inline oop ZBarrier::weak_barrier(volatile oop* p, oop o) {
 64   const uintptr_t addr = ZOop::to_address(o);
 65 
 66   // Fast path
 67   if (fast_path(addr)) {
 68     // Return the good address instead of the weak good address
 69     // to ensure that the currently active heap view is used.
<span class="line-modified"> 70     return ZOop::to_oop(ZAddress::good_or_null(addr));</span>
 71   }
 72 
 73   // Slow path
<span class="line-modified"> 74   uintptr_t good_addr = slow_path(addr);</span>
<span class="line-modified"> 75 </span>
<span class="line-modified"> 76   // Self heal unless the address returned from the slow path is null,</span>
<span class="line-modified"> 77   // in which case resurrection was blocked and we must let the reference</span>
<span class="line-modified"> 78   // processor clear the oop. Mutators are not allowed to clear oops in</span>
<span class="line-modified"> 79   // these cases, since that would be similar to calling Reference.clear(),</span>
<span class="line-removed"> 80   // which would make the reference non-discoverable or silently dropped</span>
<span class="line-removed"> 81   // by the reference processor.</span>
<span class="line-removed"> 82   if (p != NULL &amp;&amp; good_addr != 0) {</span>
<span class="line-removed"> 83     // The slow path returns a good/marked address, but we never mark oops</span>
<span class="line-removed"> 84     // in a weak load barrier so we always self heal with the remapped address.</span>
<span class="line-removed"> 85     const uintptr_t weak_good_addr = ZAddress::remapped(good_addr);</span>
<span class="line-removed"> 86     const uintptr_t prev_addr = Atomic::cmpxchg(weak_good_addr, (volatile uintptr_t*)p, addr);</span>
<span class="line-removed"> 87     if (prev_addr != addr) {</span>
<span class="line-removed"> 88       // Some other thread overwrote the oop. The new</span>
<span class="line-removed"> 89       // oop is guaranteed to be weak good or null.</span>
<span class="line-removed"> 90       assert(ZAddress::is_weak_good_or_null(prev_addr), &quot;Bad weak overwrite&quot;);</span>
<span class="line-removed"> 91 </span>
<span class="line-removed"> 92       // Return the good address instead of the weak good address</span>
<span class="line-removed"> 93       // to ensure that the currently active heap view is used.</span>
<span class="line-removed"> 94       good_addr = ZAddress::good_or_null(prev_addr);</span>
<span class="line-removed"> 95     }</span>
 96   }
 97 
<span class="line-modified"> 98   return ZOop::to_oop(good_addr);</span>
 99 }
100 
101 template &lt;ZBarrierFastPath fast_path, ZBarrierSlowPath slow_path&gt;
102 inline void ZBarrier::root_barrier(oop* p, oop o) {
103   const uintptr_t addr = ZOop::to_address(o);
104 
105   // Fast path
106   if (fast_path(addr)) {
107     return;
108   }
109 
110   // Slow path
111   const uintptr_t good_addr = slow_path(addr);
112 
113   // Non-atomic healing helps speed up root scanning. This is safe to do
114   // since we are always healing roots in a safepoint, or under a lock,
115   // which ensures we are never racing with mutators modifying roots while
116   // we are healing them. It&#39;s also safe in case multiple GC threads try
117   // to heal the same root if it is aligned, since they would always heal
118   // the root in the same way and it does not matter in which order it
119   // happens. For misaligned oops, there needs to be mutual exclusion.
<span class="line-modified">120   *p = ZOop::to_oop(good_addr);</span>
<span class="line-removed">121 }</span>
<span class="line-removed">122 </span>
<span class="line-removed">123 inline bool ZBarrier::is_null_fast_path(uintptr_t addr) {</span>
<span class="line-removed">124   return ZAddress::is_null(addr);</span>
125 }
126 
127 inline bool ZBarrier::is_good_or_null_fast_path(uintptr_t addr) {
128   return ZAddress::is_good_or_null(addr);
129 }
130 
131 inline bool ZBarrier::is_weak_good_or_null_fast_path(uintptr_t addr) {
132   return ZAddress::is_weak_good_or_null(addr);
133 }
134 
<span class="line-modified">135 inline bool ZBarrier::is_resurrection_blocked(volatile oop* p, oop* o) {</span>
<span class="line-modified">136   const bool is_blocked = ZResurrection::is_blocked();</span>

137 
<span class="line-modified">138   // Reload oop after checking the resurrection blocked state. This is</span>
<span class="line-modified">139   // done to prevent a race where we first load an oop, which is logically</span>
<span class="line-modified">140   // null but not yet cleared, then this oop is cleared by the reference</span>
<span class="line-removed">141   // processor and resurrection is unblocked. At this point the mutator</span>
<span class="line-removed">142   // would see the unblocked state and pass this invalid oop through the</span>
<span class="line-removed">143   // normal barrier path, which would incorrectly try to mark this oop.</span>
<span class="line-removed">144   if (p != NULL) {</span>
<span class="line-removed">145     // First assign to reloaded_o to avoid compiler warning about</span>
<span class="line-removed">146     // implicit dereference of volatile oop.</span>
<span class="line-removed">147     const oop reloaded_o = *p;</span>
<span class="line-removed">148     *o = reloaded_o;</span>
<span class="line-removed">149   }</span>
150 
<span class="line-modified">151   return is_blocked;</span>

152 }
153 
154 //
155 // Load barrier
156 //
157 inline oop ZBarrier::load_barrier_on_oop(oop o) {
158   return load_barrier_on_oop_field_preloaded((oop*)NULL, o);
159 }
160 
161 inline oop ZBarrier::load_barrier_on_oop_field(volatile oop* p) {
162   const oop o = *p;
163   return load_barrier_on_oop_field_preloaded(p, o);
164 }
165 
166 inline oop ZBarrier::load_barrier_on_oop_field_preloaded(volatile oop* p, oop o) {
167   return barrier&lt;is_good_or_null_fast_path, load_barrier_on_oop_slow_path&gt;(p, o);
168 }
169 
170 inline void ZBarrier::load_barrier_on_oop_array(volatile oop* p, size_t length) {
171   for (volatile const oop* const end = p + length; p &lt; end; p++) {
172     load_barrier_on_oop_field(p);
173   }
174 }
175 












176 inline oop ZBarrier::load_barrier_on_weak_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">177   if (is_resurrection_blocked(p, &amp;o)) {</span>
<span class="line-modified">178     return weak_barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_weak_oop_slow_path&gt;(p, o);</span>


179   }
180 
181   return load_barrier_on_oop_field_preloaded(p, o);
182 }
183 
184 inline oop ZBarrier::load_barrier_on_phantom_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">185   if (is_resurrection_blocked(p, &amp;o)) {</span>
<span class="line-modified">186     return weak_barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_phantom_oop_slow_path&gt;(p, o);</span>
187   }
188 
189   return load_barrier_on_oop_field_preloaded(p, o);
190 }
191 
192 inline void ZBarrier::load_barrier_on_root_oop_field(oop* p) {
193   const oop o = *p;
194   root_barrier&lt;is_good_or_null_fast_path, load_barrier_on_oop_slow_path&gt;(p, o);
195 }
196 
197 //
198 // Weak load barrier
199 //
200 inline oop ZBarrier::weak_load_barrier_on_oop_field(volatile oop* p) {
201   assert(!ZResurrection::is_blocked(), &quot;Should not be called during resurrection blocked phase&quot;);
202   const oop o = *p;
203   return weak_load_barrier_on_oop_field_preloaded(p, o);
204 }
205 
206 inline oop ZBarrier::weak_load_barrier_on_oop_field_preloaded(volatile oop* p, oop o) {
207   return weak_barrier&lt;is_weak_good_or_null_fast_path, weak_load_barrier_on_oop_slow_path&gt;(p, o);
208 }
209 
210 inline oop ZBarrier::weak_load_barrier_on_weak_oop(oop o) {
211   return weak_load_barrier_on_weak_oop_field_preloaded((oop*)NULL, o);
212 }
213 
214 inline oop ZBarrier::weak_load_barrier_on_weak_oop_field(volatile oop* p) {
215   const oop o = *p;
216   return weak_load_barrier_on_weak_oop_field_preloaded(p, o);
217 }
218 
219 inline oop ZBarrier::weak_load_barrier_on_weak_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">220   if (is_resurrection_blocked(p, &amp;o)) {</span>
<span class="line-modified">221     return weak_barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_weak_oop_slow_path&gt;(p, o);</span>


222   }
223 
224   return weak_load_barrier_on_oop_field_preloaded(p, o);
225 }
226 
227 inline oop ZBarrier::weak_load_barrier_on_phantom_oop(oop o) {
228   return weak_load_barrier_on_phantom_oop_field_preloaded((oop*)NULL, o);
229 }
230 
231 inline oop ZBarrier::weak_load_barrier_on_phantom_oop_field(volatile oop* p) {
232   const oop o = *p;
233   return weak_load_barrier_on_phantom_oop_field_preloaded(p, o);
234 }
235 
236 inline oop ZBarrier::weak_load_barrier_on_phantom_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">237   if (is_resurrection_blocked(p, &amp;o)) {</span>
<span class="line-modified">238     return weak_barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_phantom_oop_slow_path&gt;(p, o);</span>
239   }
240 
241   return weak_load_barrier_on_oop_field_preloaded(p, o);
242 }
243 
244 //
245 // Is alive barrier
246 //
247 inline bool ZBarrier::is_alive_barrier_on_weak_oop(oop o) {
248   // Check if oop is logically non-null. This operation
249   // is only valid when resurrection is blocked.
250   assert(ZResurrection::is_blocked(), &quot;Invalid phase&quot;);
251   return weak_load_barrier_on_weak_oop(o) != NULL;
252 }
253 
254 inline bool ZBarrier::is_alive_barrier_on_phantom_oop(oop o) {
255   // Check if oop is logically non-null. This operation
256   // is only valid when resurrection is blocked.
257   assert(ZResurrection::is_blocked(), &quot;Invalid phase&quot;);
258   return weak_load_barrier_on_phantom_oop(o) != NULL;
</pre>
<hr />
<pre>
265   // This operation is only valid when resurrection is blocked.
266   assert(ZResurrection::is_blocked(), &quot;Invalid phase&quot;);
267   const oop o = *p;
268   barrier&lt;is_good_or_null_fast_path, keep_alive_barrier_on_weak_oop_slow_path&gt;(p, o);
269 }
270 
271 inline void ZBarrier::keep_alive_barrier_on_phantom_oop_field(volatile oop* p) {
272   // This operation is only valid when resurrection is blocked.
273   assert(ZResurrection::is_blocked(), &quot;Invalid phase&quot;);
274   const oop o = *p;
275   barrier&lt;is_good_or_null_fast_path, keep_alive_barrier_on_phantom_oop_slow_path&gt;(p, o);
276 }
277 
278 inline void ZBarrier::keep_alive_barrier_on_phantom_root_oop_field(oop* p) {
279   // This operation is only valid when resurrection is blocked.
280   assert(ZResurrection::is_blocked(), &quot;Invalid phase&quot;);
281   const oop o = *p;
282   root_barrier&lt;is_good_or_null_fast_path, keep_alive_barrier_on_phantom_oop_slow_path&gt;(p, o);
283 }
284 









285 //
286 // Mark barrier
287 //
288 inline void ZBarrier::mark_barrier_on_oop_field(volatile oop* p, bool finalizable) {
<span class="line-removed">289   // The fast path only checks for null since the GC worker</span>
<span class="line-removed">290   // threads doing marking wants to mark through good oops.</span>
291   const oop o = *p;
292 
293   if (finalizable) {
<span class="line-modified">294     barrier&lt;is_null_fast_path, mark_barrier_on_finalizable_oop_slow_path&gt;(p, o);</span>
295   } else {
<span class="line-modified">296     barrier&lt;is_null_fast_path, mark_barrier_on_oop_slow_path&gt;(p, o);</span>







297   }
298 }
299 
300 inline void ZBarrier::mark_barrier_on_oop_array(volatile oop* p, size_t length, bool finalizable) {
301   for (volatile const oop* const end = p + length; p &lt; end; p++) {
302     mark_barrier_on_oop_field(p, finalizable);
303   }
304 }
305 
306 inline void ZBarrier::mark_barrier_on_root_oop_field(oop* p) {
307   const oop o = *p;
308   root_barrier&lt;is_good_or_null_fast_path, mark_barrier_on_root_oop_slow_path&gt;(p, o);
309 }
310 





311 //
312 // Relocate barrier
313 //
314 inline void ZBarrier::relocate_barrier_on_root_oop_field(oop* p) {
315   const oop o = *p;
316   root_barrier&lt;is_good_or_null_fast_path, relocate_barrier_on_root_oop_slow_path&gt;(p, o);
317 }
318 
319 #endif // SHARE_GC_Z_ZBARRIER_INLINE_HPP
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 #ifndef SHARE_GC_Z_ZBARRIER_INLINE_HPP
 25 #define SHARE_GC_Z_ZBARRIER_INLINE_HPP
 26 
<span class="line-added"> 27 #include &quot;classfile/javaClasses.hpp&quot;</span>
 28 #include &quot;gc/z/zAddress.inline.hpp&quot;
 29 #include &quot;gc/z/zBarrier.hpp&quot;
 30 #include &quot;gc/z/zOop.inline.hpp&quot;
 31 #include &quot;gc/z/zResurrection.inline.hpp&quot;
<span class="line-added"> 32 #include &quot;oops/oop.hpp&quot;</span>
 33 #include &quot;runtime/atomic.hpp&quot;
 34 
<span class="line-added"> 35 // A self heal must always &quot;upgrade&quot; the address metadata bits in</span>
<span class="line-added"> 36 // accordance with the metadata bits state machine, which has the</span>
<span class="line-added"> 37 // valid state transitions as described below (where N is the GC</span>
<span class="line-added"> 38 // cycle).</span>
<span class="line-added"> 39 //</span>
<span class="line-added"> 40 // Note the subtleness of overlapping GC cycles. Specifically that</span>
<span class="line-added"> 41 // oops are colored Remapped(N) starting at relocation N and ending</span>
<span class="line-added"> 42 // at marking N + 1.</span>
<span class="line-added"> 43 //</span>
<span class="line-added"> 44 //              +--- Mark Start</span>
<span class="line-added"> 45 //              | +--- Mark End</span>
<span class="line-added"> 46 //              | | +--- Relocate Start</span>
<span class="line-added"> 47 //              | | | +--- Relocate End</span>
<span class="line-added"> 48 //              | | | |</span>
<span class="line-added"> 49 // Marked       |---N---|--N+1--|--N+2--|----</span>
<span class="line-added"> 50 // Finalizable  |---N---|--N+1--|--N+2--|----</span>
<span class="line-added"> 51 // Remapped     ----|---N---|--N+1--|--N+2--|</span>
<span class="line-added"> 52 //</span>
<span class="line-added"> 53 // VALID STATE TRANSITIONS</span>
<span class="line-added"> 54 //</span>
<span class="line-added"> 55 //   Marked(N)           -&gt; Remapped(N)</span>
<span class="line-added"> 56 //                       -&gt; Marked(N + 1)</span>
<span class="line-added"> 57 //                       -&gt; Finalizable(N + 1)</span>
<span class="line-added"> 58 //</span>
<span class="line-added"> 59 //   Finalizable(N)      -&gt; Marked(N)</span>
<span class="line-added"> 60 //                       -&gt; Remapped(N)</span>
<span class="line-added"> 61 //                       -&gt; Marked(N + 1)</span>
<span class="line-added"> 62 //                       -&gt; Finalizable(N + 1)</span>
<span class="line-added"> 63 //</span>
<span class="line-added"> 64 //   Remapped(N)         -&gt; Marked(N + 1)</span>
<span class="line-added"> 65 //                       -&gt; Finalizable(N + 1)</span>
<span class="line-added"> 66 //</span>
<span class="line-added"> 67 // PHASE VIEW</span>
<span class="line-added"> 68 //</span>
<span class="line-added"> 69 // ZPhaseMark</span>
<span class="line-added"> 70 //   Load &amp; Mark</span>
<span class="line-added"> 71 //     Marked(N)         &lt;- Marked(N - 1)</span>
<span class="line-added"> 72 //                       &lt;- Finalizable(N - 1)</span>
<span class="line-added"> 73 //                       &lt;- Remapped(N - 1)</span>
<span class="line-added"> 74 //                       &lt;- Finalizable(N)</span>
<span class="line-added"> 75 //</span>
<span class="line-added"> 76 //   Mark(Finalizable)</span>
<span class="line-added"> 77 //     Finalizable(N)    &lt;- Marked(N - 1)</span>
<span class="line-added"> 78 //                       &lt;- Finalizable(N - 1)</span>
<span class="line-added"> 79 //                       &lt;- Remapped(N - 1)</span>
<span class="line-added"> 80 //</span>
<span class="line-added"> 81 //   Load(AS_NO_KEEPALIVE)</span>
<span class="line-added"> 82 //     Remapped(N - 1)   &lt;- Marked(N - 1)</span>
<span class="line-added"> 83 //                       &lt;- Finalizable(N - 1)</span>
<span class="line-added"> 84 //</span>
<span class="line-added"> 85 // ZPhaseMarkCompleted (Resurrection blocked)</span>
<span class="line-added"> 86 //   Load &amp; Load(ON_WEAK/PHANTOM_OOP_REF | AS_NO_KEEPALIVE) &amp; KeepAlive</span>
<span class="line-added"> 87 //     Marked(N)         &lt;- Marked(N - 1)</span>
<span class="line-added"> 88 //                       &lt;- Finalizable(N - 1)</span>
<span class="line-added"> 89 //                       &lt;- Remapped(N - 1)</span>
<span class="line-added"> 90 //                       &lt;- Finalizable(N)</span>
<span class="line-added"> 91 //</span>
<span class="line-added"> 92 //   Load(ON_STRONG_OOP_REF | AS_NO_KEEPALIVE)</span>
<span class="line-added"> 93 //     Remapped(N - 1)   &lt;- Marked(N - 1)</span>
<span class="line-added"> 94 //                       &lt;- Finalizable(N - 1)</span>
<span class="line-added"> 95 //</span>
<span class="line-added"> 96 // ZPhaseMarkCompleted (Resurrection unblocked)</span>
<span class="line-added"> 97 //   Load</span>
<span class="line-added"> 98 //     Marked(N)         &lt;- Finalizable(N)</span>
<span class="line-added"> 99 //</span>
<span class="line-added">100 // ZPhaseRelocate</span>
<span class="line-added">101 //   Load &amp; Load(AS_NO_KEEPALIVE)</span>
<span class="line-added">102 //     Remapped(N)       &lt;- Marked(N)</span>
<span class="line-added">103 //                       &lt;- Finalizable(N)</span>
<span class="line-added">104 </span>
<span class="line-added">105 template &lt;ZBarrierFastPath fast_path&gt;</span>
<span class="line-added">106 inline void ZBarrier::self_heal(volatile oop* p, uintptr_t addr, uintptr_t heal_addr) {</span>
<span class="line-added">107   if (heal_addr == 0) {</span>
<span class="line-added">108     // Never heal with null since it interacts badly with reference processing.</span>
<span class="line-added">109     // A mutator clearing an oop would be similar to calling Reference.clear(),</span>
<span class="line-added">110     // which would make the reference non-discoverable or silently dropped</span>
<span class="line-added">111     // by the reference processor.</span>
<span class="line-added">112     return;</span>
<span class="line-added">113   }</span>
<span class="line-added">114 </span>
<span class="line-added">115   assert(!fast_path(addr), &quot;Invalid self heal&quot;);</span>
<span class="line-added">116   assert(fast_path(heal_addr), &quot;Invalid self heal&quot;);</span>
<span class="line-added">117 </span>
<span class="line-added">118   for (;;) {</span>
<span class="line-added">119     // Heal</span>
<span class="line-added">120     const uintptr_t prev_addr = Atomic::cmpxchg((volatile uintptr_t*)p, addr, heal_addr);</span>
<span class="line-added">121     if (prev_addr == addr) {</span>
<span class="line-added">122       // Success</span>
<span class="line-added">123       return;</span>
<span class="line-added">124     }</span>
<span class="line-added">125 </span>
<span class="line-added">126     if (fast_path(prev_addr)) {</span>
<span class="line-added">127       // Must not self heal</span>
<span class="line-added">128       return;</span>
<span class="line-added">129     }</span>
<span class="line-added">130 </span>
<span class="line-added">131     // The oop location was healed by another barrier, but still needs upgrading.</span>
<span class="line-added">132     // Re-apply healing to make sure the oop is not left with weaker (remapped or</span>
<span class="line-added">133     // finalizable) metadata bits than what this barrier tried to apply.</span>
<span class="line-added">134     assert(ZAddress::offset(prev_addr) == ZAddress::offset(heal_addr), &quot;Invalid offset&quot;);</span>
<span class="line-added">135     addr = prev_addr;</span>
<span class="line-added">136   }</span>
<span class="line-added">137 }</span>
<span class="line-added">138 </span>
139 template &lt;ZBarrierFastPath fast_path, ZBarrierSlowPath slow_path&gt;
140 inline oop ZBarrier::barrier(volatile oop* p, oop o) {
<span class="line-modified">141   const uintptr_t addr = ZOop::to_address(o);</span>
142 

143   // Fast path
144   if (fast_path(addr)) {
<span class="line-modified">145     return ZOop::from_address(addr);</span>
146   }
147 
148   // Slow path
149   const uintptr_t good_addr = slow_path(addr);
150 
<span class="line-modified">151   if (p != NULL) {</span>
<span class="line-modified">152     self_heal&lt;fast_path&gt;(p, addr, good_addr);</span>









153   }
154 
<span class="line-modified">155   return ZOop::from_address(good_addr);</span>
156 }
157 
158 template &lt;ZBarrierFastPath fast_path, ZBarrierSlowPath slow_path&gt;
159 inline oop ZBarrier::weak_barrier(volatile oop* p, oop o) {
160   const uintptr_t addr = ZOop::to_address(o);
161 
162   // Fast path
163   if (fast_path(addr)) {
164     // Return the good address instead of the weak good address
165     // to ensure that the currently active heap view is used.
<span class="line-modified">166     return ZOop::from_address(ZAddress::good_or_null(addr));</span>
167   }
168 
169   // Slow path
<span class="line-modified">170   const uintptr_t good_addr = slow_path(addr);</span>
<span class="line-modified">171 </span>
<span class="line-modified">172   if (p != NULL) {</span>
<span class="line-modified">173     // The slow path returns a good/marked address or null, but we never mark</span>
<span class="line-modified">174     // oops in a weak load barrier so we always heal with the remapped address.</span>
<span class="line-modified">175     self_heal&lt;fast_path&gt;(p, addr, ZAddress::remapped_or_null(good_addr));</span>
















176   }
177 
<span class="line-modified">178   return ZOop::from_address(good_addr);</span>
179 }
180 
181 template &lt;ZBarrierFastPath fast_path, ZBarrierSlowPath slow_path&gt;
182 inline void ZBarrier::root_barrier(oop* p, oop o) {
183   const uintptr_t addr = ZOop::to_address(o);
184 
185   // Fast path
186   if (fast_path(addr)) {
187     return;
188   }
189 
190   // Slow path
191   const uintptr_t good_addr = slow_path(addr);
192 
193   // Non-atomic healing helps speed up root scanning. This is safe to do
194   // since we are always healing roots in a safepoint, or under a lock,
195   // which ensures we are never racing with mutators modifying roots while
196   // we are healing them. It&#39;s also safe in case multiple GC threads try
197   // to heal the same root if it is aligned, since they would always heal
198   // the root in the same way and it does not matter in which order it
199   // happens. For misaligned oops, there needs to be mutual exclusion.
<span class="line-modified">200   *p = ZOop::from_address(good_addr);</span>




201 }
202 
203 inline bool ZBarrier::is_good_or_null_fast_path(uintptr_t addr) {
204   return ZAddress::is_good_or_null(addr);
205 }
206 
207 inline bool ZBarrier::is_weak_good_or_null_fast_path(uintptr_t addr) {
208   return ZAddress::is_weak_good_or_null(addr);
209 }
210 
<span class="line-modified">211 inline bool ZBarrier::is_marked_or_null_fast_path(uintptr_t addr) {</span>
<span class="line-modified">212   return ZAddress::is_marked_or_null(addr);</span>
<span class="line-added">213 }</span>
214 
<span class="line-modified">215 inline bool ZBarrier::during_mark() {</span>
<span class="line-modified">216   return ZGlobalPhase == ZPhaseMark;</span>
<span class="line-modified">217 }</span>









218 
<span class="line-modified">219 inline bool ZBarrier::during_relocate() {</span>
<span class="line-added">220   return ZGlobalPhase == ZPhaseRelocate;</span>
221 }
222 
223 //
224 // Load barrier
225 //
226 inline oop ZBarrier::load_barrier_on_oop(oop o) {
227   return load_barrier_on_oop_field_preloaded((oop*)NULL, o);
228 }
229 
230 inline oop ZBarrier::load_barrier_on_oop_field(volatile oop* p) {
231   const oop o = *p;
232   return load_barrier_on_oop_field_preloaded(p, o);
233 }
234 
235 inline oop ZBarrier::load_barrier_on_oop_field_preloaded(volatile oop* p, oop o) {
236   return barrier&lt;is_good_or_null_fast_path, load_barrier_on_oop_slow_path&gt;(p, o);
237 }
238 
239 inline void ZBarrier::load_barrier_on_oop_array(volatile oop* p, size_t length) {
240   for (volatile const oop* const end = p + length; p &lt; end; p++) {
241     load_barrier_on_oop_field(p);
242   }
243 }
244 
<span class="line-added">245 // ON_WEAK barriers should only ever be applied to j.l.r.Reference.referents.</span>
<span class="line-added">246 inline void verify_on_weak(volatile oop* referent_addr) {</span>
<span class="line-added">247 #ifdef ASSERT</span>
<span class="line-added">248   if (referent_addr != NULL) {</span>
<span class="line-added">249     uintptr_t base = (uintptr_t)referent_addr - java_lang_ref_Reference::referent_offset;</span>
<span class="line-added">250     oop obj = cast_to_oop(base);</span>
<span class="line-added">251     assert(oopDesc::is_oop(obj), &quot;Verification failed for: ref &quot; PTR_FORMAT &quot; obj: &quot; PTR_FORMAT, (uintptr_t)referent_addr, base);</span>
<span class="line-added">252     assert(java_lang_ref_Reference::is_referent_field(obj, java_lang_ref_Reference::referent_offset), &quot;Sanity&quot;);</span>
<span class="line-added">253   }</span>
<span class="line-added">254 #endif</span>
<span class="line-added">255 }</span>
<span class="line-added">256 </span>
257 inline oop ZBarrier::load_barrier_on_weak_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">258   verify_on_weak(p);</span>
<span class="line-modified">259 </span>
<span class="line-added">260   if (ZResurrection::is_blocked()) {</span>
<span class="line-added">261     return barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_weak_oop_slow_path&gt;(p, o);</span>
262   }
263 
264   return load_barrier_on_oop_field_preloaded(p, o);
265 }
266 
267 inline oop ZBarrier::load_barrier_on_phantom_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">268   if (ZResurrection::is_blocked()) {</span>
<span class="line-modified">269     return barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_phantom_oop_slow_path&gt;(p, o);</span>
270   }
271 
272   return load_barrier_on_oop_field_preloaded(p, o);
273 }
274 
275 inline void ZBarrier::load_barrier_on_root_oop_field(oop* p) {
276   const oop o = *p;
277   root_barrier&lt;is_good_or_null_fast_path, load_barrier_on_oop_slow_path&gt;(p, o);
278 }
279 
280 //
281 // Weak load barrier
282 //
283 inline oop ZBarrier::weak_load_barrier_on_oop_field(volatile oop* p) {
284   assert(!ZResurrection::is_blocked(), &quot;Should not be called during resurrection blocked phase&quot;);
285   const oop o = *p;
286   return weak_load_barrier_on_oop_field_preloaded(p, o);
287 }
288 
289 inline oop ZBarrier::weak_load_barrier_on_oop_field_preloaded(volatile oop* p, oop o) {
290   return weak_barrier&lt;is_weak_good_or_null_fast_path, weak_load_barrier_on_oop_slow_path&gt;(p, o);
291 }
292 
293 inline oop ZBarrier::weak_load_barrier_on_weak_oop(oop o) {
294   return weak_load_barrier_on_weak_oop_field_preloaded((oop*)NULL, o);
295 }
296 
297 inline oop ZBarrier::weak_load_barrier_on_weak_oop_field(volatile oop* p) {
298   const oop o = *p;
299   return weak_load_barrier_on_weak_oop_field_preloaded(p, o);
300 }
301 
302 inline oop ZBarrier::weak_load_barrier_on_weak_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">303   verify_on_weak(p);</span>
<span class="line-modified">304 </span>
<span class="line-added">305   if (ZResurrection::is_blocked()) {</span>
<span class="line-added">306     return barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_weak_oop_slow_path&gt;(p, o);</span>
307   }
308 
309   return weak_load_barrier_on_oop_field_preloaded(p, o);
310 }
311 
312 inline oop ZBarrier::weak_load_barrier_on_phantom_oop(oop o) {
313   return weak_load_barrier_on_phantom_oop_field_preloaded((oop*)NULL, o);
314 }
315 
316 inline oop ZBarrier::weak_load_barrier_on_phantom_oop_field(volatile oop* p) {
317   const oop o = *p;
318   return weak_load_barrier_on_phantom_oop_field_preloaded(p, o);
319 }
320 
321 inline oop ZBarrier::weak_load_barrier_on_phantom_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">322   if (ZResurrection::is_blocked()) {</span>
<span class="line-modified">323     return barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_phantom_oop_slow_path&gt;(p, o);</span>
324   }
325 
326   return weak_load_barrier_on_oop_field_preloaded(p, o);
327 }
328 
329 //
330 // Is alive barrier
331 //
332 inline bool ZBarrier::is_alive_barrier_on_weak_oop(oop o) {
333   // Check if oop is logically non-null. This operation
334   // is only valid when resurrection is blocked.
335   assert(ZResurrection::is_blocked(), &quot;Invalid phase&quot;);
336   return weak_load_barrier_on_weak_oop(o) != NULL;
337 }
338 
339 inline bool ZBarrier::is_alive_barrier_on_phantom_oop(oop o) {
340   // Check if oop is logically non-null. This operation
341   // is only valid when resurrection is blocked.
342   assert(ZResurrection::is_blocked(), &quot;Invalid phase&quot;);
343   return weak_load_barrier_on_phantom_oop(o) != NULL;
</pre>
<hr />
<pre>
350   // This operation is only valid when resurrection is blocked.
351   assert(ZResurrection::is_blocked(), &quot;Invalid phase&quot;);
352   const oop o = *p;
353   barrier&lt;is_good_or_null_fast_path, keep_alive_barrier_on_weak_oop_slow_path&gt;(p, o);
354 }
355 
356 inline void ZBarrier::keep_alive_barrier_on_phantom_oop_field(volatile oop* p) {
357   // This operation is only valid when resurrection is blocked.
358   assert(ZResurrection::is_blocked(), &quot;Invalid phase&quot;);
359   const oop o = *p;
360   barrier&lt;is_good_or_null_fast_path, keep_alive_barrier_on_phantom_oop_slow_path&gt;(p, o);
361 }
362 
363 inline void ZBarrier::keep_alive_barrier_on_phantom_root_oop_field(oop* p) {
364   // This operation is only valid when resurrection is blocked.
365   assert(ZResurrection::is_blocked(), &quot;Invalid phase&quot;);
366   const oop o = *p;
367   root_barrier&lt;is_good_or_null_fast_path, keep_alive_barrier_on_phantom_oop_slow_path&gt;(p, o);
368 }
369 
<span class="line-added">370 inline void ZBarrier::keep_alive_barrier_on_oop(oop o) {</span>
<span class="line-added">371   const uintptr_t addr = ZOop::to_address(o);</span>
<span class="line-added">372   assert(ZAddress::is_good(addr), &quot;Invalid address&quot;);</span>
<span class="line-added">373 </span>
<span class="line-added">374   if (during_mark()) {</span>
<span class="line-added">375     mark_barrier_on_oop_slow_path(addr);</span>
<span class="line-added">376   }</span>
<span class="line-added">377 }</span>
<span class="line-added">378 </span>
379 //
380 // Mark barrier
381 //
382 inline void ZBarrier::mark_barrier_on_oop_field(volatile oop* p, bool finalizable) {


383   const oop o = *p;
384 
385   if (finalizable) {
<span class="line-modified">386     barrier&lt;is_marked_or_null_fast_path, mark_barrier_on_finalizable_oop_slow_path&gt;(p, o);</span>
387   } else {
<span class="line-modified">388     const uintptr_t addr = ZOop::to_address(o);</span>
<span class="line-added">389     if (ZAddress::is_good(addr)) {</span>
<span class="line-added">390       // Mark through good oop</span>
<span class="line-added">391       mark_barrier_on_oop_slow_path(addr);</span>
<span class="line-added">392     } else {</span>
<span class="line-added">393       // Mark through bad oop</span>
<span class="line-added">394       barrier&lt;is_good_or_null_fast_path, mark_barrier_on_oop_slow_path&gt;(p, o);</span>
<span class="line-added">395     }</span>
396   }
397 }
398 
399 inline void ZBarrier::mark_barrier_on_oop_array(volatile oop* p, size_t length, bool finalizable) {
400   for (volatile const oop* const end = p + length; p &lt; end; p++) {
401     mark_barrier_on_oop_field(p, finalizable);
402   }
403 }
404 
405 inline void ZBarrier::mark_barrier_on_root_oop_field(oop* p) {
406   const oop o = *p;
407   root_barrier&lt;is_good_or_null_fast_path, mark_barrier_on_root_oop_slow_path&gt;(p, o);
408 }
409 
<span class="line-added">410 inline void ZBarrier::mark_barrier_on_invisible_root_oop_field(oop* p) {</span>
<span class="line-added">411   const oop o = *p;</span>
<span class="line-added">412   root_barrier&lt;is_good_or_null_fast_path, mark_barrier_on_invisible_root_oop_slow_path&gt;(p, o);</span>
<span class="line-added">413 }</span>
<span class="line-added">414 </span>
415 //
416 // Relocate barrier
417 //
418 inline void ZBarrier::relocate_barrier_on_root_oop_field(oop* p) {
419   const oop o = *p;
420   root_barrier&lt;is_good_or_null_fast_path, relocate_barrier_on_root_oop_slow_path&gt;(p, o);
421 }
422 
423 #endif // SHARE_GC_Z_ZBARRIER_INLINE_HPP
</pre>
</td>
</tr>
</table>
<center><a href="zBarrier.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="zBarrierSet.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>