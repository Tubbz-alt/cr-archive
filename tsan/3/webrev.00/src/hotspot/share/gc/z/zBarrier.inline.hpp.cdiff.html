<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff src/hotspot/share/gc/z/zBarrier.inline.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="zBarrier.hpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="zBarrierSet.cpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/z/zBarrier.inline.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 1,7 ***</span>
  /*
<span class="line-modified">!  * Copyright (c) 2015, 2017, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
<span class="line-new-header">--- 1,7 ---</span>
  /*
<span class="line-modified">!  * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 22,82 ***</span>
   */
  
  #ifndef SHARE_GC_Z_ZBARRIER_INLINE_HPP
  #define SHARE_GC_Z_ZBARRIER_INLINE_HPP
  
  #include &quot;gc/z/zAddress.inline.hpp&quot;
  #include &quot;gc/z/zBarrier.hpp&quot;
  #include &quot;gc/z/zOop.inline.hpp&quot;
  #include &quot;gc/z/zResurrection.inline.hpp&quot;
  #include &quot;runtime/atomic.hpp&quot;
  
  template &lt;ZBarrierFastPath fast_path, ZBarrierSlowPath slow_path&gt;
  inline oop ZBarrier::barrier(volatile oop* p, oop o) {
<span class="line-modified">!   uintptr_t addr = ZOop::to_address(o);</span>
  
<span class="line-removed">- retry:</span>
    // Fast path
    if (fast_path(addr)) {
<span class="line-modified">!     return ZOop::to_oop(addr);</span>
    }
  
    // Slow path
    const uintptr_t good_addr = slow_path(addr);
  
<span class="line-modified">!   // Self heal, but only if the address was actually updated by the slow path,</span>
<span class="line-modified">!   // which might not be the case, e.g. when marking through an already good oop.</span>
<span class="line-removed">-   if (p != NULL &amp;&amp; good_addr != addr) {</span>
<span class="line-removed">-     const uintptr_t prev_addr = Atomic::cmpxchg(good_addr, (volatile uintptr_t*)p, addr);</span>
<span class="line-removed">-     if (prev_addr != addr) {</span>
<span class="line-removed">-       // Some other thread overwrote the oop. If this oop was updated by a</span>
<span class="line-removed">-       // weak barrier the new oop might not be good, in which case we need</span>
<span class="line-removed">-       // to re-apply this barrier.</span>
<span class="line-removed">-       addr = prev_addr;</span>
<span class="line-removed">-       goto retry;</span>
<span class="line-removed">-     }</span>
    }
  
<span class="line-modified">!   return ZOop::to_oop(good_addr);</span>
  }
  
  template &lt;ZBarrierFastPath fast_path, ZBarrierSlowPath slow_path&gt;
  inline oop ZBarrier::weak_barrier(volatile oop* p, oop o) {
    const uintptr_t addr = ZOop::to_address(o);
  
    // Fast path
    if (fast_path(addr)) {
      // Return the good address instead of the weak good address
      // to ensure that the currently active heap view is used.
<span class="line-modified">!     return ZOop::to_oop(ZAddress::good_or_null(addr));</span>
    }
  
    // Slow path
<span class="line-modified">!   uintptr_t good_addr = slow_path(addr);</span>
<span class="line-modified">! </span>
<span class="line-modified">!   // Self heal unless the address returned from the slow path is null,</span>
<span class="line-modified">!   // in which case resurrection was blocked and we must let the reference</span>
<span class="line-modified">!   // processor clear the oop. Mutators are not allowed to clear oops in</span>
<span class="line-modified">!   // these cases, since that would be similar to calling Reference.clear(),</span>
<span class="line-removed">-   // which would make the reference non-discoverable or silently dropped</span>
<span class="line-removed">-   // by the reference processor.</span>
<span class="line-removed">-   if (p != NULL &amp;&amp; good_addr != 0) {</span>
<span class="line-removed">-     // The slow path returns a good/marked address, but we never mark oops</span>
<span class="line-removed">-     // in a weak load barrier so we always self heal with the remapped address.</span>
<span class="line-removed">-     const uintptr_t weak_good_addr = ZAddress::remapped(good_addr);</span>
<span class="line-removed">-     const uintptr_t prev_addr = Atomic::cmpxchg(weak_good_addr, (volatile uintptr_t*)p, addr);</span>
<span class="line-removed">-     if (prev_addr != addr) {</span>
<span class="line-removed">-       // Some other thread overwrote the oop. The new</span>
<span class="line-removed">-       // oop is guaranteed to be weak good or null.</span>
<span class="line-removed">-       assert(ZAddress::is_weak_good_or_null(prev_addr), &quot;Bad weak overwrite&quot;);</span>
<span class="line-removed">- </span>
<span class="line-removed">-       // Return the good address instead of the weak good address</span>
<span class="line-removed">-       // to ensure that the currently active heap view is used.</span>
<span class="line-removed">-       good_addr = ZAddress::good_or_null(prev_addr);</span>
<span class="line-removed">-     }</span>
    }
  
<span class="line-modified">!   return ZOop::to_oop(good_addr);</span>
  }
  
  template &lt;ZBarrierFastPath fast_path, ZBarrierSlowPath slow_path&gt;
  inline void ZBarrier::root_barrier(oop* p, oop o) {
    const uintptr_t addr = ZOop::to_address(o);
<span class="line-new-header">--- 22,162 ---</span>
   */
  
  #ifndef SHARE_GC_Z_ZBARRIER_INLINE_HPP
  #define SHARE_GC_Z_ZBARRIER_INLINE_HPP
  
<span class="line-added">+ #include &quot;classfile/javaClasses.hpp&quot;</span>
  #include &quot;gc/z/zAddress.inline.hpp&quot;
  #include &quot;gc/z/zBarrier.hpp&quot;
  #include &quot;gc/z/zOop.inline.hpp&quot;
  #include &quot;gc/z/zResurrection.inline.hpp&quot;
<span class="line-added">+ #include &quot;oops/oop.hpp&quot;</span>
  #include &quot;runtime/atomic.hpp&quot;
  
<span class="line-added">+ // A self heal must always &quot;upgrade&quot; the address metadata bits in</span>
<span class="line-added">+ // accordance with the metadata bits state machine, which has the</span>
<span class="line-added">+ // valid state transitions as described below (where N is the GC</span>
<span class="line-added">+ // cycle).</span>
<span class="line-added">+ //</span>
<span class="line-added">+ // Note the subtleness of overlapping GC cycles. Specifically that</span>
<span class="line-added">+ // oops are colored Remapped(N) starting at relocation N and ending</span>
<span class="line-added">+ // at marking N + 1.</span>
<span class="line-added">+ //</span>
<span class="line-added">+ //              +--- Mark Start</span>
<span class="line-added">+ //              | +--- Mark End</span>
<span class="line-added">+ //              | | +--- Relocate Start</span>
<span class="line-added">+ //              | | | +--- Relocate End</span>
<span class="line-added">+ //              | | | |</span>
<span class="line-added">+ // Marked       |---N---|--N+1--|--N+2--|----</span>
<span class="line-added">+ // Finalizable  |---N---|--N+1--|--N+2--|----</span>
<span class="line-added">+ // Remapped     ----|---N---|--N+1--|--N+2--|</span>
<span class="line-added">+ //</span>
<span class="line-added">+ // VALID STATE TRANSITIONS</span>
<span class="line-added">+ //</span>
<span class="line-added">+ //   Marked(N)           -&gt; Remapped(N)</span>
<span class="line-added">+ //                       -&gt; Marked(N + 1)</span>
<span class="line-added">+ //                       -&gt; Finalizable(N + 1)</span>
<span class="line-added">+ //</span>
<span class="line-added">+ //   Finalizable(N)      -&gt; Marked(N)</span>
<span class="line-added">+ //                       -&gt; Remapped(N)</span>
<span class="line-added">+ //                       -&gt; Marked(N + 1)</span>
<span class="line-added">+ //                       -&gt; Finalizable(N + 1)</span>
<span class="line-added">+ //</span>
<span class="line-added">+ //   Remapped(N)         -&gt; Marked(N + 1)</span>
<span class="line-added">+ //                       -&gt; Finalizable(N + 1)</span>
<span class="line-added">+ //</span>
<span class="line-added">+ // PHASE VIEW</span>
<span class="line-added">+ //</span>
<span class="line-added">+ // ZPhaseMark</span>
<span class="line-added">+ //   Load &amp; Mark</span>
<span class="line-added">+ //     Marked(N)         &lt;- Marked(N - 1)</span>
<span class="line-added">+ //                       &lt;- Finalizable(N - 1)</span>
<span class="line-added">+ //                       &lt;- Remapped(N - 1)</span>
<span class="line-added">+ //                       &lt;- Finalizable(N)</span>
<span class="line-added">+ //</span>
<span class="line-added">+ //   Mark(Finalizable)</span>
<span class="line-added">+ //     Finalizable(N)    &lt;- Marked(N - 1)</span>
<span class="line-added">+ //                       &lt;- Finalizable(N - 1)</span>
<span class="line-added">+ //                       &lt;- Remapped(N - 1)</span>
<span class="line-added">+ //</span>
<span class="line-added">+ //   Load(AS_NO_KEEPALIVE)</span>
<span class="line-added">+ //     Remapped(N - 1)   &lt;- Marked(N - 1)</span>
<span class="line-added">+ //                       &lt;- Finalizable(N - 1)</span>
<span class="line-added">+ //</span>
<span class="line-added">+ // ZPhaseMarkCompleted (Resurrection blocked)</span>
<span class="line-added">+ //   Load &amp; Load(ON_WEAK/PHANTOM_OOP_REF | AS_NO_KEEPALIVE) &amp; KeepAlive</span>
<span class="line-added">+ //     Marked(N)         &lt;- Marked(N - 1)</span>
<span class="line-added">+ //                       &lt;- Finalizable(N - 1)</span>
<span class="line-added">+ //                       &lt;- Remapped(N - 1)</span>
<span class="line-added">+ //                       &lt;- Finalizable(N)</span>
<span class="line-added">+ //</span>
<span class="line-added">+ //   Load(ON_STRONG_OOP_REF | AS_NO_KEEPALIVE)</span>
<span class="line-added">+ //     Remapped(N - 1)   &lt;- Marked(N - 1)</span>
<span class="line-added">+ //                       &lt;- Finalizable(N - 1)</span>
<span class="line-added">+ //</span>
<span class="line-added">+ // ZPhaseMarkCompleted (Resurrection unblocked)</span>
<span class="line-added">+ //   Load</span>
<span class="line-added">+ //     Marked(N)         &lt;- Finalizable(N)</span>
<span class="line-added">+ //</span>
<span class="line-added">+ // ZPhaseRelocate</span>
<span class="line-added">+ //   Load &amp; Load(AS_NO_KEEPALIVE)</span>
<span class="line-added">+ //     Remapped(N)       &lt;- Marked(N)</span>
<span class="line-added">+ //                       &lt;- Finalizable(N)</span>
<span class="line-added">+ </span>
<span class="line-added">+ template &lt;ZBarrierFastPath fast_path&gt;</span>
<span class="line-added">+ inline void ZBarrier::self_heal(volatile oop* p, uintptr_t addr, uintptr_t heal_addr) {</span>
<span class="line-added">+   if (heal_addr == 0) {</span>
<span class="line-added">+     // Never heal with null since it interacts badly with reference processing.</span>
<span class="line-added">+     // A mutator clearing an oop would be similar to calling Reference.clear(),</span>
<span class="line-added">+     // which would make the reference non-discoverable or silently dropped</span>
<span class="line-added">+     // by the reference processor.</span>
<span class="line-added">+     return;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   assert(!fast_path(addr), &quot;Invalid self heal&quot;);</span>
<span class="line-added">+   assert(fast_path(heal_addr), &quot;Invalid self heal&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+   for (;;) {</span>
<span class="line-added">+     // Heal</span>
<span class="line-added">+     const uintptr_t prev_addr = Atomic::cmpxchg((volatile uintptr_t*)p, addr, heal_addr);</span>
<span class="line-added">+     if (prev_addr == addr) {</span>
<span class="line-added">+       // Success</span>
<span class="line-added">+       return;</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
<span class="line-added">+     if (fast_path(prev_addr)) {</span>
<span class="line-added">+       // Must not self heal</span>
<span class="line-added">+       return;</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
<span class="line-added">+     // The oop location was healed by another barrier, but still needs upgrading.</span>
<span class="line-added">+     // Re-apply healing to make sure the oop is not left with weaker (remapped or</span>
<span class="line-added">+     // finalizable) metadata bits than what this barrier tried to apply.</span>
<span class="line-added">+     assert(ZAddress::offset(prev_addr) == ZAddress::offset(heal_addr), &quot;Invalid offset&quot;);</span>
<span class="line-added">+     addr = prev_addr;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  template &lt;ZBarrierFastPath fast_path, ZBarrierSlowPath slow_path&gt;
  inline oop ZBarrier::barrier(volatile oop* p, oop o) {
<span class="line-modified">!   const uintptr_t addr = ZOop::to_address(o);</span>
  
    // Fast path
    if (fast_path(addr)) {
<span class="line-modified">!     return ZOop::from_address(addr);</span>
    }
  
    // Slow path
    const uintptr_t good_addr = slow_path(addr);
  
<span class="line-modified">!   if (p != NULL) {</span>
<span class="line-modified">!     self_heal&lt;fast_path&gt;(p, addr, good_addr);</span>
    }
  
<span class="line-modified">!   return ZOop::from_address(good_addr);</span>
  }
  
  template &lt;ZBarrierFastPath fast_path, ZBarrierSlowPath slow_path&gt;
  inline oop ZBarrier::weak_barrier(volatile oop* p, oop o) {
    const uintptr_t addr = ZOop::to_address(o);
  
    // Fast path
    if (fast_path(addr)) {
      // Return the good address instead of the weak good address
      // to ensure that the currently active heap view is used.
<span class="line-modified">!     return ZOop::from_address(ZAddress::good_or_null(addr));</span>
    }
  
    // Slow path
<span class="line-modified">!   const uintptr_t good_addr = slow_path(addr);</span>
<span class="line-modified">! </span>
<span class="line-modified">!   if (p != NULL) {</span>
<span class="line-modified">!     // The slow path returns a good/marked address or null, but we never mark</span>
<span class="line-modified">!     // oops in a weak load barrier so we always heal with the remapped address.</span>
<span class="line-modified">!     self_heal&lt;fast_path&gt;(p, addr, ZAddress::remapped_or_null(good_addr));</span>
    }
  
<span class="line-modified">!   return ZOop::from_address(good_addr);</span>
  }
  
  template &lt;ZBarrierFastPath fast_path, ZBarrierSlowPath slow_path&gt;
  inline void ZBarrier::root_barrier(oop* p, oop o) {
    const uintptr_t addr = ZOop::to_address(o);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 115,42 ***</span>
    // which ensures we are never racing with mutators modifying roots while
    // we are healing them. It&#39;s also safe in case multiple GC threads try
    // to heal the same root if it is aligned, since they would always heal
    // the root in the same way and it does not matter in which order it
    // happens. For misaligned oops, there needs to be mutual exclusion.
<span class="line-modified">!   *p = ZOop::to_oop(good_addr);</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- inline bool ZBarrier::is_null_fast_path(uintptr_t addr) {</span>
<span class="line-removed">-   return ZAddress::is_null(addr);</span>
  }
  
  inline bool ZBarrier::is_good_or_null_fast_path(uintptr_t addr) {
    return ZAddress::is_good_or_null(addr);
  }
  
  inline bool ZBarrier::is_weak_good_or_null_fast_path(uintptr_t addr) {
    return ZAddress::is_weak_good_or_null(addr);
  }
  
<span class="line-modified">! inline bool ZBarrier::is_resurrection_blocked(volatile oop* p, oop* o) {</span>
<span class="line-modified">!   const bool is_blocked = ZResurrection::is_blocked();</span>
  
<span class="line-modified">!   // Reload oop after checking the resurrection blocked state. This is</span>
<span class="line-modified">!   // done to prevent a race where we first load an oop, which is logically</span>
<span class="line-modified">!   // null but not yet cleared, then this oop is cleared by the reference</span>
<span class="line-removed">-   // processor and resurrection is unblocked. At this point the mutator</span>
<span class="line-removed">-   // would see the unblocked state and pass this invalid oop through the</span>
<span class="line-removed">-   // normal barrier path, which would incorrectly try to mark this oop.</span>
<span class="line-removed">-   if (p != NULL) {</span>
<span class="line-removed">-     // First assign to reloaded_o to avoid compiler warning about</span>
<span class="line-removed">-     // implicit dereference of volatile oop.</span>
<span class="line-removed">-     const oop reloaded_o = *p;</span>
<span class="line-removed">-     *o = reloaded_o;</span>
<span class="line-removed">-   }</span>
  
<span class="line-modified">!   return is_blocked;</span>
  }
  
  //
  // Load barrier
  //
<span class="line-new-header">--- 195,31 ---</span>
    // which ensures we are never racing with mutators modifying roots while
    // we are healing them. It&#39;s also safe in case multiple GC threads try
    // to heal the same root if it is aligned, since they would always heal
    // the root in the same way and it does not matter in which order it
    // happens. For misaligned oops, there needs to be mutual exclusion.
<span class="line-modified">!   *p = ZOop::from_address(good_addr);</span>
  }
  
  inline bool ZBarrier::is_good_or_null_fast_path(uintptr_t addr) {
    return ZAddress::is_good_or_null(addr);
  }
  
  inline bool ZBarrier::is_weak_good_or_null_fast_path(uintptr_t addr) {
    return ZAddress::is_weak_good_or_null(addr);
  }
  
<span class="line-modified">! inline bool ZBarrier::is_marked_or_null_fast_path(uintptr_t addr) {</span>
<span class="line-modified">!   return ZAddress::is_marked_or_null(addr);</span>
<span class="line-added">+ }</span>
  
<span class="line-modified">! inline bool ZBarrier::during_mark() {</span>
<span class="line-modified">!   return ZGlobalPhase == ZPhaseMark;</span>
<span class="line-modified">! }</span>
  
<span class="line-modified">! inline bool ZBarrier::during_relocate() {</span>
<span class="line-added">+   return ZGlobalPhase == ZPhaseRelocate;</span>
  }
  
  //
  // Load barrier
  //
</pre>
<hr />
<pre>
<span class="line-old-header">*** 171,21 ***</span>
    for (volatile const oop* const end = p + length; p &lt; end; p++) {
      load_barrier_on_oop_field(p);
    }
  }
  
  inline oop ZBarrier::load_barrier_on_weak_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">!   if (is_resurrection_blocked(p, &amp;o)) {</span>
<span class="line-modified">!     return weak_barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_weak_oop_slow_path&gt;(p, o);</span>
    }
  
    return load_barrier_on_oop_field_preloaded(p, o);
  }
  
  inline oop ZBarrier::load_barrier_on_phantom_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">!   if (is_resurrection_blocked(p, &amp;o)) {</span>
<span class="line-modified">!     return weak_barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_phantom_oop_slow_path&gt;(p, o);</span>
    }
  
    return load_barrier_on_oop_field_preloaded(p, o);
  }
  
<span class="line-new-header">--- 240,35 ---</span>
    for (volatile const oop* const end = p + length; p &lt; end; p++) {
      load_barrier_on_oop_field(p);
    }
  }
  
<span class="line-added">+ // ON_WEAK barriers should only ever be applied to j.l.r.Reference.referents.</span>
<span class="line-added">+ inline void verify_on_weak(volatile oop* referent_addr) {</span>
<span class="line-added">+ #ifdef ASSERT</span>
<span class="line-added">+   if (referent_addr != NULL) {</span>
<span class="line-added">+     uintptr_t base = (uintptr_t)referent_addr - java_lang_ref_Reference::referent_offset;</span>
<span class="line-added">+     oop obj = cast_to_oop(base);</span>
<span class="line-added">+     assert(oopDesc::is_oop(obj), &quot;Verification failed for: ref &quot; PTR_FORMAT &quot; obj: &quot; PTR_FORMAT, (uintptr_t)referent_addr, base);</span>
<span class="line-added">+     assert(java_lang_ref_Reference::is_referent_field(obj, java_lang_ref_Reference::referent_offset), &quot;Sanity&quot;);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ #endif</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  inline oop ZBarrier::load_barrier_on_weak_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">!   verify_on_weak(p);</span>
<span class="line-modified">! </span>
<span class="line-added">+   if (ZResurrection::is_blocked()) {</span>
<span class="line-added">+     return barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_weak_oop_slow_path&gt;(p, o);</span>
    }
  
    return load_barrier_on_oop_field_preloaded(p, o);
  }
  
  inline oop ZBarrier::load_barrier_on_phantom_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">!   if (ZResurrection::is_blocked()) {</span>
<span class="line-modified">!     return barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_phantom_oop_slow_path&gt;(p, o);</span>
    }
  
    return load_barrier_on_oop_field_preloaded(p, o);
  }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 215,12 ***</span>
    const oop o = *p;
    return weak_load_barrier_on_weak_oop_field_preloaded(p, o);
  }
  
  inline oop ZBarrier::weak_load_barrier_on_weak_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">!   if (is_resurrection_blocked(p, &amp;o)) {</span>
<span class="line-modified">!     return weak_barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_weak_oop_slow_path&gt;(p, o);</span>
    }
  
    return weak_load_barrier_on_oop_field_preloaded(p, o);
  }
  
<span class="line-new-header">--- 298,14 ---</span>
    const oop o = *p;
    return weak_load_barrier_on_weak_oop_field_preloaded(p, o);
  }
  
  inline oop ZBarrier::weak_load_barrier_on_weak_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">!   verify_on_weak(p);</span>
<span class="line-modified">! </span>
<span class="line-added">+   if (ZResurrection::is_blocked()) {</span>
<span class="line-added">+     return barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_weak_oop_slow_path&gt;(p, o);</span>
    }
  
    return weak_load_barrier_on_oop_field_preloaded(p, o);
  }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 232,12 ***</span>
    const oop o = *p;
    return weak_load_barrier_on_phantom_oop_field_preloaded(p, o);
  }
  
  inline oop ZBarrier::weak_load_barrier_on_phantom_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">!   if (is_resurrection_blocked(p, &amp;o)) {</span>
<span class="line-modified">!     return weak_barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_phantom_oop_slow_path&gt;(p, o);</span>
    }
  
    return weak_load_barrier_on_oop_field_preloaded(p, o);
  }
  
<span class="line-new-header">--- 317,12 ---</span>
    const oop o = *p;
    return weak_load_barrier_on_phantom_oop_field_preloaded(p, o);
  }
  
  inline oop ZBarrier::weak_load_barrier_on_phantom_oop_field_preloaded(volatile oop* p, oop o) {
<span class="line-modified">!   if (ZResurrection::is_blocked()) {</span>
<span class="line-modified">!     return barrier&lt;is_good_or_null_fast_path, weak_load_barrier_on_phantom_oop_slow_path&gt;(p, o);</span>
    }
  
    return weak_load_barrier_on_oop_field_preloaded(p, o);
  }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 280,22 ***</span>
    assert(ZResurrection::is_blocked(), &quot;Invalid phase&quot;);
    const oop o = *p;
    root_barrier&lt;is_good_or_null_fast_path, keep_alive_barrier_on_phantom_oop_slow_path&gt;(p, o);
  }
  
  //
  // Mark barrier
  //
  inline void ZBarrier::mark_barrier_on_oop_field(volatile oop* p, bool finalizable) {
<span class="line-removed">-   // The fast path only checks for null since the GC worker</span>
<span class="line-removed">-   // threads doing marking wants to mark through good oops.</span>
    const oop o = *p;
  
    if (finalizable) {
<span class="line-modified">!     barrier&lt;is_null_fast_path, mark_barrier_on_finalizable_oop_slow_path&gt;(p, o);</span>
    } else {
<span class="line-modified">!     barrier&lt;is_null_fast_path, mark_barrier_on_oop_slow_path&gt;(p, o);</span>
    }
  }
  
  inline void ZBarrier::mark_barrier_on_oop_array(volatile oop* p, size_t length, bool finalizable) {
    for (volatile const oop* const end = p + length; p &lt; end; p++) {
<span class="line-new-header">--- 365,36 ---</span>
    assert(ZResurrection::is_blocked(), &quot;Invalid phase&quot;);
    const oop o = *p;
    root_barrier&lt;is_good_or_null_fast_path, keep_alive_barrier_on_phantom_oop_slow_path&gt;(p, o);
  }
  
<span class="line-added">+ inline void ZBarrier::keep_alive_barrier_on_oop(oop o) {</span>
<span class="line-added">+   const uintptr_t addr = ZOop::to_address(o);</span>
<span class="line-added">+   assert(ZAddress::is_good(addr), &quot;Invalid address&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (during_mark()) {</span>
<span class="line-added">+     mark_barrier_on_oop_slow_path(addr);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  //
  // Mark barrier
  //
  inline void ZBarrier::mark_barrier_on_oop_field(volatile oop* p, bool finalizable) {
    const oop o = *p;
  
    if (finalizable) {
<span class="line-modified">!     barrier&lt;is_marked_or_null_fast_path, mark_barrier_on_finalizable_oop_slow_path&gt;(p, o);</span>
    } else {
<span class="line-modified">!     const uintptr_t addr = ZOop::to_address(o);</span>
<span class="line-added">+     if (ZAddress::is_good(addr)) {</span>
<span class="line-added">+       // Mark through good oop</span>
<span class="line-added">+       mark_barrier_on_oop_slow_path(addr);</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       // Mark through bad oop</span>
<span class="line-added">+       barrier&lt;is_good_or_null_fast_path, mark_barrier_on_oop_slow_path&gt;(p, o);</span>
<span class="line-added">+     }</span>
    }
  }
  
  inline void ZBarrier::mark_barrier_on_oop_array(volatile oop* p, size_t length, bool finalizable) {
    for (volatile const oop* const end = p + length; p &lt; end; p++) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 306,10 ***</span>
<span class="line-new-header">--- 405,15 ---</span>
  inline void ZBarrier::mark_barrier_on_root_oop_field(oop* p) {
    const oop o = *p;
    root_barrier&lt;is_good_or_null_fast_path, mark_barrier_on_root_oop_slow_path&gt;(p, o);
  }
  
<span class="line-added">+ inline void ZBarrier::mark_barrier_on_invisible_root_oop_field(oop* p) {</span>
<span class="line-added">+   const oop o = *p;</span>
<span class="line-added">+   root_barrier&lt;is_good_or_null_fast_path, mark_barrier_on_invisible_root_oop_slow_path&gt;(p, o);</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  //
  // Relocate barrier
  //
  inline void ZBarrier::relocate_barrier_on_root_oop_field(oop* p) {
    const oop o = *p;
</pre>
<center><a href="zBarrier.hpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="zBarrierSet.cpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>