<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/gc/parallel/psScavenge.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
    <script type="text/javascript" src="../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
<a name="1" id="anc1"></a><span class="line-modified">  2  * Copyright (c) 2002, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
<a name="2" id="anc2"></a>

 26 #include &quot;classfile/stringTable.hpp&quot;
 27 #include &quot;code/codeCache.hpp&quot;
<a name="3" id="anc3"></a><span class="line-removed"> 28 #include &quot;gc/parallel/gcTaskManager.hpp&quot;</span>
 29 #include &quot;gc/parallel/parallelScavengeHeap.hpp&quot;
 30 #include &quot;gc/parallel/psAdaptiveSizePolicy.hpp&quot;
 31 #include &quot;gc/parallel/psClosure.inline.hpp&quot;
<a name="4" id="anc4"></a><span class="line-modified"> 32 #include &quot;gc/parallel/psMarkSweepProxy.hpp&quot;</span>
 33 #include &quot;gc/parallel/psParallelCompact.inline.hpp&quot;
 34 #include &quot;gc/parallel/psPromotionManager.inline.hpp&quot;
<a name="5" id="anc5"></a>
 35 #include &quot;gc/parallel/psScavenge.inline.hpp&quot;
<a name="6" id="anc6"></a><span class="line-removed"> 36 #include &quot;gc/parallel/psTasks.hpp&quot;</span>
<span class="line-removed"> 37 #include &quot;gc/shared/collectorPolicy.hpp&quot;</span>
 38 #include &quot;gc/shared/gcCause.hpp&quot;
 39 #include &quot;gc/shared/gcHeapSummary.hpp&quot;
 40 #include &quot;gc/shared/gcId.hpp&quot;
 41 #include &quot;gc/shared/gcLocker.hpp&quot;
 42 #include &quot;gc/shared/gcTimer.hpp&quot;
 43 #include &quot;gc/shared/gcTrace.hpp&quot;
 44 #include &quot;gc/shared/gcTraceTime.inline.hpp&quot;
 45 #include &quot;gc/shared/isGCActiveMark.hpp&quot;
 46 #include &quot;gc/shared/referencePolicy.hpp&quot;
 47 #include &quot;gc/shared/referenceProcessor.hpp&quot;
 48 #include &quot;gc/shared/referenceProcessorPhaseTimes.hpp&quot;
<a name="7" id="anc7"></a><span class="line-modified"> 49 #include &quot;gc/shared/spaceDecorator.hpp&quot;</span>


 50 #include &quot;gc/shared/weakProcessor.hpp&quot;
<a name="8" id="anc8"></a>


 51 #include &quot;memory/resourceArea.hpp&quot;
<a name="9" id="anc9"></a>
 52 #include &quot;logging/log.hpp&quot;
 53 #include &quot;oops/access.inline.hpp&quot;
 54 #include &quot;oops/compressedOops.inline.hpp&quot;
 55 #include &quot;oops/oop.inline.hpp&quot;
 56 #include &quot;runtime/biasedLocking.hpp&quot;
 57 #include &quot;runtime/handles.inline.hpp&quot;
 58 #include &quot;runtime/threadCritical.hpp&quot;
 59 #include &quot;runtime/vmThread.hpp&quot;
 60 #include &quot;runtime/vmOperations.hpp&quot;
<a name="10" id="anc10"></a>
 61 #include &quot;services/memoryService.hpp&quot;
 62 #include &quot;utilities/stack.inline.hpp&quot;
 63 
 64 HeapWord*                     PSScavenge::_to_space_top_before_gc = NULL;
 65 int                           PSScavenge::_consecutive_skipped_scavenges = 0;
 66 SpanSubjectToDiscoveryClosure PSScavenge::_span_based_discoverer;
 67 ReferenceProcessor*           PSScavenge::_ref_processor = NULL;
 68 PSCardTable*                  PSScavenge::_card_table = NULL;
 69 bool                          PSScavenge::_survivor_overflow = false;
 70 uint                          PSScavenge::_tenuring_threshold = 0;
 71 HeapWord*                     PSScavenge::_young_generation_boundary = NULL;
 72 uintptr_t                     PSScavenge::_young_generation_boundary_compressed = 0;
 73 elapsedTimer                  PSScavenge::_accumulated_time;
 74 STWGCTimer                    PSScavenge::_gc_timer;
 75 ParallelScavengeTracer        PSScavenge::_gc_tracer;
 76 CollectorCounters*            PSScavenge::_counters = NULL;
 77 
<a name="11" id="anc11"></a>
















































































 78 // Define before use
 79 class PSIsAliveClosure: public BoolObjectClosure {
 80 public:
 81   bool do_object_b(oop p) {
 82     return (!PSScavenge::is_obj_in_young(p)) || p-&gt;is_forwarded();
 83   }
 84 };
 85 
 86 PSIsAliveClosure PSScavenge::_is_alive_closure;
 87 
 88 class PSKeepAliveClosure: public OopClosure {
 89 protected:
 90   MutableSpace* _to_space;
 91   PSPromotionManager* _promotion_manager;
 92 
 93 public:
 94   PSKeepAliveClosure(PSPromotionManager* pm) : _promotion_manager(pm) {
 95     ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
 96     _to_space = heap-&gt;young_gen()-&gt;to_space();
 97 
 98     assert(_promotion_manager != NULL, &quot;Sanity&quot;);
 99   }
100 
101   template &lt;class T&gt; void do_oop_work(T* p) {
102     assert (oopDesc::is_oop(RawAccess&lt;IS_NOT_NULL&gt;::oop_load(p)),
103             &quot;expected an oop while scanning weak refs&quot;);
104 
105     // Weak refs may be visited more than once.
106     if (PSScavenge::should_scavenge(p, _to_space)) {
107       _promotion_manager-&gt;copy_and_push_safe_barrier&lt;T, /*promote_immediately=*/false&gt;(p);
108     }
109   }
110   virtual void do_oop(oop* p)       { PSKeepAliveClosure::do_oop_work(p); }
111   virtual void do_oop(narrowOop* p) { PSKeepAliveClosure::do_oop_work(p); }
112 };
113 
114 class PSEvacuateFollowersClosure: public VoidClosure {
115  private:
116   PSPromotionManager* _promotion_manager;
117  public:
118   PSEvacuateFollowersClosure(PSPromotionManager* pm) : _promotion_manager(pm) {}
119 
120   virtual void do_void() {
121     assert(_promotion_manager != NULL, &quot;Sanity&quot;);
122     _promotion_manager-&gt;drain_stacks(true);
123     guarantee(_promotion_manager-&gt;stacks_empty(),
124               &quot;stacks should be empty at this point&quot;);
125   }
126 };
127 
<a name="12" id="anc12"></a><span class="line-removed">128 class PSRefProcTaskProxy: public GCTask {</span>
<span class="line-removed">129   typedef AbstractRefProcTaskExecutor::ProcessTask ProcessTask;</span>
<span class="line-removed">130   ProcessTask &amp; _rp_task;</span>
<span class="line-removed">131   uint          _work_id;</span>
<span class="line-removed">132 public:</span>
<span class="line-removed">133   PSRefProcTaskProxy(ProcessTask &amp; rp_task, uint work_id)</span>
<span class="line-removed">134     : _rp_task(rp_task),</span>
<span class="line-removed">135       _work_id(work_id)</span>
<span class="line-removed">136   { }</span>
<span class="line-removed">137 </span>
<span class="line-removed">138 private:</span>
<span class="line-removed">139   virtual char* name() { return (char *)&quot;Process referents by policy in parallel&quot;; }</span>
<span class="line-removed">140   virtual void do_it(GCTaskManager* manager, uint which);</span>
<span class="line-removed">141 };</span>
<span class="line-removed">142 </span>
<span class="line-removed">143 void PSRefProcTaskProxy::do_it(GCTaskManager* manager, uint which)</span>
<span class="line-removed">144 {</span>
<span class="line-removed">145   PSPromotionManager* promotion_manager =</span>
<span class="line-removed">146     PSPromotionManager::gc_thread_promotion_manager(which);</span>
<span class="line-removed">147   assert(promotion_manager != NULL, &quot;sanity check&quot;);</span>
<span class="line-removed">148   PSKeepAliveClosure keep_alive(promotion_manager);</span>
<span class="line-removed">149   PSEvacuateFollowersClosure evac_followers(promotion_manager);</span>
<span class="line-removed">150   PSIsAliveClosure is_alive;</span>
<span class="line-removed">151   _rp_task.work(_work_id, is_alive, keep_alive, evac_followers);</span>
<span class="line-removed">152 }</span>
<span class="line-removed">153 </span>
154 class PSRefProcTaskExecutor: public AbstractRefProcTaskExecutor {
<a name="13" id="anc13"></a><span class="line-modified">155   virtual void execute(ProcessTask&amp; task, uint ergo_workers);</span>
156 };
157 
<a name="14" id="anc14"></a><span class="line-modified">158 void PSRefProcTaskExecutor::execute(ProcessTask&amp; task, uint ergo_workers)</span>
<span class="line-modified">159 {</span>
<span class="line-modified">160   GCTaskQueue* q = GCTaskQueue::create();</span>
<span class="line-modified">161   GCTaskManager* manager = ParallelScavengeHeap::gc_task_manager();</span>
<span class="line-modified">162   uint active_workers = manager-&gt;active_workers();</span>
<span class="line-removed">163 </span>
<span class="line-removed">164   assert(active_workers == ergo_workers,</span>
<span class="line-removed">165          &quot;Ergonomically chosen workers (%u) must be equal to active workers (%u)&quot;,</span>
<span class="line-removed">166          ergo_workers, active_workers);</span>
167 
<a name="15" id="anc15"></a><span class="line-modified">168   for(uint i=0; i &lt; active_workers; i++) {</span>
<span class="line-modified">169     q-&gt;enqueue(new PSRefProcTaskProxy(task, i));</span>




170   }
<a name="16" id="anc16"></a><span class="line-modified">171   TaskTerminator terminator(active_workers,</span>
<span class="line-modified">172                             (TaskQueueSetSuper*) PSPromotionManager::stack_array_depth());</span>
<span class="line-modified">173   if (task.marks_oops_alive() &amp;&amp; active_workers &gt; 1) {</span>
<span class="line-modified">174     for (uint j = 0; j &lt; active_workers; j++) {</span>
<span class="line-modified">175       q-&gt;enqueue(new StealTask(terminator.terminator()));</span>







176     }
177   }
<a name="17" id="anc17"></a><span class="line-modified">178   manager-&gt;execute_and_wait(q);</span>




179 }
180 
181 // This method contains all heap specific policy for invoking scavenge.
182 // PSScavenge::invoke_no_policy() will do nothing but attempt to
183 // scavenge. It will not clean up after failed promotions, bail out if
184 // we&#39;ve exceeded policy time limits, or any other special behavior.
185 // All such policy should be placed here.
186 //
187 // Note that this method should only be called from the vm_thread while
188 // at a safepoint!
189 bool PSScavenge::invoke() {
190   assert(SafepointSynchronize::is_at_safepoint(), &quot;should be at safepoint&quot;);
191   assert(Thread::current() == (Thread*)VMThread::vm_thread(), &quot;should be in vm thread&quot;);
192   assert(!ParallelScavengeHeap::heap()-&gt;is_gc_active(), &quot;not reentrant&quot;);
193 
194   ParallelScavengeHeap* const heap = ParallelScavengeHeap::heap();
195   PSAdaptiveSizePolicy* policy = heap-&gt;size_policy();
196   IsGCActiveMark mark;
197 
198   const bool scavenge_done = PSScavenge::invoke_no_policy();
199   const bool need_full_gc = !scavenge_done ||
200     policy-&gt;should_full_GC(heap-&gt;old_gen()-&gt;free_in_bytes());
201   bool full_gc_done = false;
202 
203   if (UsePerfData) {
204     PSGCAdaptivePolicyCounters* const counters = heap-&gt;gc_policy_counters();
205     const int ffs_val = need_full_gc ? full_follows_scavenge : not_skipped;
206     counters-&gt;update_full_follows_scavenge(ffs_val);
207   }
208 
209   if (need_full_gc) {
210     GCCauseSetter gccs(heap, GCCause::_adaptive_size_policy);
211     SoftRefPolicy* srp = heap-&gt;soft_ref_policy();
212     const bool clear_all_softrefs = srp-&gt;should_clear_all_soft_refs();
213 
<a name="18" id="anc18"></a><span class="line-modified">214     if (UseParallelOldGC) {</span>
<span class="line-removed">215       full_gc_done = PSParallelCompact::invoke_no_policy(clear_all_softrefs);</span>
<span class="line-removed">216     } else {</span>
<span class="line-removed">217       full_gc_done = PSMarkSweepProxy::invoke_no_policy(clear_all_softrefs);</span>
<span class="line-removed">218     }</span>
219   }
220 
221   return full_gc_done;
222 }
223 
<a name="19" id="anc19"></a><span class="line-modified">224 class PSAddThreadRootsTaskClosure : public ThreadClosure {</span>
<span class="line-modified">225 private:</span>
<span class="line-modified">226   GCTaskQueue* _q;</span>























227 
228 public:
<a name="20" id="anc20"></a><span class="line-modified">229   PSAddThreadRootsTaskClosure(GCTaskQueue* q) : _q(q) { }</span>
<span class="line-modified">230   void do_thread(Thread* t) {</span>
<span class="line-modified">231     _q-&gt;enqueue(new ThreadRootsTask(t));</span>



























































232   }
233 };
234 
235 // This method contains no policy. You should probably
236 // be calling invoke() instead.
237 bool PSScavenge::invoke_no_policy() {
238   assert(SafepointSynchronize::is_at_safepoint(), &quot;should be at safepoint&quot;);
239   assert(Thread::current() == (Thread*)VMThread::vm_thread(), &quot;should be in vm thread&quot;);
240 
241   _gc_timer.register_gc_start();
242 
243   TimeStamp scavenge_entry;
244   TimeStamp scavenge_midpoint;
245   TimeStamp scavenge_exit;
246 
247   scavenge_entry.update();
248 
249   if (GCLocker::check_active_before_gc()) {
250     return false;
251   }
252 
253   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
254   GCCause::Cause gc_cause = heap-&gt;gc_cause();
255 
256   // Check for potential problems.
257   if (!should_attempt_scavenge()) {
258     return false;
259   }
260 
261   GCIdMark gc_id_mark;
262   _gc_tracer.report_gc_start(heap-&gt;gc_cause(), _gc_timer.gc_start());
263 
264   bool promotion_failure_occurred = false;
265 
266   PSYoungGen* young_gen = heap-&gt;young_gen();
267   PSOldGen* old_gen = heap-&gt;old_gen();
268   PSAdaptiveSizePolicy* size_policy = heap-&gt;size_policy();
269 
270   heap-&gt;increment_total_collections();
271 
272   if (AdaptiveSizePolicy::should_update_eden_stats(gc_cause)) {
273     // Gather the feedback data for eden occupancy.
274     young_gen-&gt;eden_space()-&gt;accumulate_statistics();
275   }
276 
277   heap-&gt;print_heap_before_gc();
278   heap-&gt;trace_heap_before_gc(&amp;_gc_tracer);
279 
<a name="21" id="anc21"></a><span class="line-modified">280   assert(!NeverTenure || _tenuring_threshold == markOopDesc::max_age + 1, &quot;Sanity&quot;);</span>
281   assert(!AlwaysTenure || _tenuring_threshold == 0, &quot;Sanity&quot;);
282 
283   // Fill in TLABs
284   heap-&gt;ensure_parsability(true);  // retire TLABs
285 
286   if (VerifyBeforeGC &amp;&amp; heap-&gt;total_collections() &gt;= VerifyGCStartAt) {
287     HandleMark hm;  // Discard invalid handles created during verification
288     Universe::verify(&quot;Before GC&quot;);
289   }
290 
291   {
292     ResourceMark rm;
293     HandleMark hm;
294 
295     GCTraceCPUTime tcpu;
296     GCTraceTime(Info, gc) tm(&quot;Pause Young&quot;, NULL, gc_cause, true);
297     TraceCollectorStats tcs(counters());
298     TraceMemoryManagerStats tms(heap-&gt;young_gc_manager(), gc_cause);
299 
300     if (log_is_enabled(Debug, gc, heap, exit)) {
301       accumulated_time()-&gt;start();
302     }
303 
304     // Let the size policy know we&#39;re starting
305     size_policy-&gt;minor_collection_begin();
306 
307     // Verify the object start arrays.
308     if (VerifyObjectStartArray &amp;&amp;
309         VerifyBeforeGC) {
310       old_gen-&gt;verify_object_start_array();
311     }
312 
313     // Verify no unmarked old-&gt;young roots
314     if (VerifyRememberedSets) {
315       heap-&gt;card_table()-&gt;verify_all_young_refs_imprecise();
316     }
317 
318     assert(young_gen-&gt;to_space()-&gt;is_empty(),
319            &quot;Attempt to scavenge with live objects in to_space&quot;);
320     young_gen-&gt;to_space()-&gt;clear(SpaceDecorator::Mangle);
321 
322     save_to_space_top_before_gc();
323 
324 #if COMPILER2_OR_JVMCI
325     DerivedPointerTable::clear();
326 #endif
327 
328     reference_processor()-&gt;enable_discovery();
329     reference_processor()-&gt;setup_policy(false);
330 
<a name="22" id="anc22"></a><span class="line-modified">331     PreGCValues pre_gc_values(heap);</span>
332 
333     // Reset our survivor overflow.
334     set_survivor_overflow(false);
335 
336     // We need to save the old top values before
337     // creating the promotion_manager. We pass the top
338     // values to the card_table, to prevent it from
339     // straying into the promotion labs.
340     HeapWord* old_top = old_gen-&gt;object_space()-&gt;top();
341 
<a name="23" id="anc23"></a><span class="line-modified">342     // Release all previously held resources</span>
<span class="line-modified">343     gc_task_manager()-&gt;release_all_resources();</span>
<span class="line-modified">344 </span>
<span class="line-modified">345     // Set the number of GC threads to be used in this collection</span>
<span class="line-modified">346     gc_task_manager()-&gt;set_active_gang();</span>
<span class="line-removed">347     gc_task_manager()-&gt;task_idle_workers();</span>
<span class="line-removed">348     // Get the active number of workers here and use that value</span>
<span class="line-removed">349     // throughout the methods.</span>
<span class="line-removed">350     uint active_workers = gc_task_manager()-&gt;active_workers();</span>
351 
352     PSPromotionManager::pre_scavenge();
353 
354     // We&#39;ll use the promotion manager again later.
355     PSPromotionManager* promotion_manager = PSPromotionManager::vm_thread_promotion_manager();
356     {
357       GCTraceTime(Debug, gc, phases) tm(&quot;Scavenge&quot;, &amp;_gc_timer);
<a name="24" id="anc24"></a><span class="line-removed">358       ParallelScavengeHeap::ParStrongRootsScope psrs;</span>
<span class="line-removed">359 </span>
<span class="line-removed">360       GCTaskQueue* q = GCTaskQueue::create();</span>
361 
<a name="25" id="anc25"></a><span class="line-modified">362       if (!old_gen-&gt;object_space()-&gt;is_empty()) {</span>
<span class="line-modified">363         // There are only old-to-young pointers if there are objects</span>
<span class="line-removed">364         // in the old gen.</span>
<span class="line-removed">365         uint stripe_total = active_workers;</span>
<span class="line-removed">366         for(uint i=0; i &lt; stripe_total; i++) {</span>
<span class="line-removed">367           q-&gt;enqueue(new OldToYoungRootsTask(old_gen, old_top, i, stripe_total));</span>
<span class="line-removed">368         }</span>
<span class="line-removed">369       }</span>
<span class="line-removed">370 </span>
<span class="line-removed">371       q-&gt;enqueue(new ScavengeRootsTask(ScavengeRootsTask::universe));</span>
<span class="line-removed">372       q-&gt;enqueue(new ScavengeRootsTask(ScavengeRootsTask::jni_handles));</span>
<span class="line-removed">373       // We scan the thread roots in parallel</span>
<span class="line-removed">374       PSAddThreadRootsTaskClosure cl(q);</span>
<span class="line-removed">375       Threads::java_threads_and_vm_thread_do(&amp;cl);</span>
<span class="line-removed">376       q-&gt;enqueue(new ScavengeRootsTask(ScavengeRootsTask::object_synchronizer));</span>
<span class="line-removed">377       q-&gt;enqueue(new ScavengeRootsTask(ScavengeRootsTask::management));</span>
<span class="line-removed">378       q-&gt;enqueue(new ScavengeRootsTask(ScavengeRootsTask::system_dictionary));</span>
<span class="line-removed">379       q-&gt;enqueue(new ScavengeRootsTask(ScavengeRootsTask::class_loader_data));</span>
<span class="line-removed">380       q-&gt;enqueue(new ScavengeRootsTask(ScavengeRootsTask::jvmti));</span>
<span class="line-removed">381       q-&gt;enqueue(new ScavengeRootsTask(ScavengeRootsTask::code_cache));</span>
<span class="line-removed">382 </span>
<span class="line-removed">383       TaskTerminator terminator(active_workers,</span>
<span class="line-removed">384                                 (TaskQueueSetSuper*) promotion_manager-&gt;stack_array_depth());</span>
<span class="line-removed">385         // If active_workers can exceed 1, add a StrealTask.</span>
<span class="line-removed">386         // PSPromotionManager::drain_stacks_depth() does not fully drain its</span>
<span class="line-removed">387         // stacks and expects a StealTask to complete the draining if</span>
<span class="line-removed">388         // ParallelGCThreads is &gt; 1.</span>
<span class="line-removed">389         if (gc_task_manager()-&gt;workers() &gt; 1) {</span>
<span class="line-removed">390           for (uint j = 0; j &lt; active_workers; j++) {</span>
<span class="line-removed">391             q-&gt;enqueue(new StealTask(terminator.terminator()));</span>
<span class="line-removed">392           }</span>
<span class="line-removed">393         }</span>
<span class="line-removed">394 </span>
<span class="line-removed">395       gc_task_manager()-&gt;execute_and_wait(q);</span>
396     }
397 
398     scavenge_midpoint.update();
399 
400     // Process reference objects discovered during scavenge
401     {
402       GCTraceTime(Debug, gc, phases) tm(&quot;Reference Processing&quot;, &amp;_gc_timer);
403 
404       reference_processor()-&gt;setup_policy(false); // not always_clear
405       reference_processor()-&gt;set_active_mt_degree(active_workers);
406       PSKeepAliveClosure keep_alive(promotion_manager);
407       PSEvacuateFollowersClosure evac_followers(promotion_manager);
408       ReferenceProcessorStats stats;
409       ReferenceProcessorPhaseTimes pt(&amp;_gc_timer, reference_processor()-&gt;max_num_queues());
410       if (reference_processor()-&gt;processing_is_mt()) {
411         PSRefProcTaskExecutor task_executor;
412         stats = reference_processor()-&gt;process_discovered_references(
413           &amp;_is_alive_closure, &amp;keep_alive, &amp;evac_followers, &amp;task_executor,
414           &amp;pt);
415       } else {
416         stats = reference_processor()-&gt;process_discovered_references(
417           &amp;_is_alive_closure, &amp;keep_alive, &amp;evac_followers, NULL, &amp;pt);
418       }
419 
420       _gc_tracer.report_gc_reference_stats(stats);
421       pt.print_all_references();
422     }
423 
424     assert(promotion_manager-&gt;stacks_empty(),&quot;stacks should be empty at this point&quot;);
425 
426     PSScavengeRootsClosure root_closure(promotion_manager);
427 
428     {
429       GCTraceTime(Debug, gc, phases) tm(&quot;Weak Processing&quot;, &amp;_gc_timer);
430       WeakProcessor::weak_oops_do(&amp;_is_alive_closure, &amp;root_closure);
431     }
432 
433     // Verify that usage of root_closure didn&#39;t copy any objects.
434     assert(promotion_manager-&gt;stacks_empty(),&quot;stacks should be empty at this point&quot;);
435 
436     // Finally, flush the promotion_manager&#39;s labs, and deallocate its stacks.
437     promotion_failure_occurred = PSPromotionManager::post_scavenge(_gc_tracer);
438     if (promotion_failure_occurred) {
439       clean_up_failed_promotion();
440       log_info(gc, promotion)(&quot;Promotion failed&quot;);
441     }
442 
443     _gc_tracer.report_tenuring_threshold(tenuring_threshold());
444 
445     // Let the size policy know we&#39;re done.  Note that we count promotion
446     // failure cleanup time as part of the collection (otherwise, we&#39;re
447     // implicitly saying it&#39;s mutator time).
448     size_policy-&gt;minor_collection_end(gc_cause);
449 
450     if (!promotion_failure_occurred) {
451       // Swap the survivor spaces.
452       young_gen-&gt;eden_space()-&gt;clear(SpaceDecorator::Mangle);
453       young_gen-&gt;from_space()-&gt;clear(SpaceDecorator::Mangle);
454       young_gen-&gt;swap_spaces();
455 
456       size_t survived = young_gen-&gt;from_space()-&gt;used_in_bytes();
457       size_t promoted = old_gen-&gt;used_in_bytes() - pre_gc_values.old_gen_used();
458       size_policy-&gt;update_averages(_survivor_overflow, survived, promoted);
459 
460       // A successful scavenge should restart the GC time limit count which is
461       // for full GC&#39;s.
462       size_policy-&gt;reset_gc_overhead_limit_count();
463       if (UseAdaptiveSizePolicy) {
464         // Calculate the new survivor size and tenuring threshold
465 
466         log_debug(gc, ergo)(&quot;AdaptiveSizeStart:  collection: %d &quot;, heap-&gt;total_collections());
467         log_trace(gc, ergo)(&quot;old_gen_capacity: &quot; SIZE_FORMAT &quot; young_gen_capacity: &quot; SIZE_FORMAT,
468                             old_gen-&gt;capacity_in_bytes(), young_gen-&gt;capacity_in_bytes());
469 
470         if (UsePerfData) {
471           PSGCAdaptivePolicyCounters* counters = heap-&gt;gc_policy_counters();
472           counters-&gt;update_old_eden_size(
473             size_policy-&gt;calculated_eden_size_in_bytes());
474           counters-&gt;update_old_promo_size(
475             size_policy-&gt;calculated_promo_size_in_bytes());
476           counters-&gt;update_old_capacity(old_gen-&gt;capacity_in_bytes());
477           counters-&gt;update_young_capacity(young_gen-&gt;capacity_in_bytes());
478           counters-&gt;update_survived(survived);
479           counters-&gt;update_promoted(promoted);
480           counters-&gt;update_survivor_overflowed(_survivor_overflow);
481         }
482 
483         size_t max_young_size = young_gen-&gt;max_size();
484 
485         // Deciding a free ratio in the young generation is tricky, so if
486         // MinHeapFreeRatio or MaxHeapFreeRatio are in use (implicating
487         // that the old generation size may have been limited because of them) we
488         // should then limit our young generation size using NewRatio to have it
489         // follow the old generation size.
490         if (MinHeapFreeRatio != 0 || MaxHeapFreeRatio != 100) {
491           max_young_size = MIN2(old_gen-&gt;capacity_in_bytes() / NewRatio, young_gen-&gt;max_size());
492         }
493 
494         size_t survivor_limit =
495           size_policy-&gt;max_survivor_size(max_young_size);
496         _tenuring_threshold =
497           size_policy-&gt;compute_survivor_space_size_and_threshold(
498                                                            _survivor_overflow,
499                                                            _tenuring_threshold,
500                                                            survivor_limit);
501 
502        log_debug(gc, age)(&quot;Desired survivor size &quot; SIZE_FORMAT &quot; bytes, new threshold %u (max threshold &quot; UINTX_FORMAT &quot;)&quot;,
503                           size_policy-&gt;calculated_survivor_size_in_bytes(),
504                           _tenuring_threshold, MaxTenuringThreshold);
505 
506         if (UsePerfData) {
507           PSGCAdaptivePolicyCounters* counters = heap-&gt;gc_policy_counters();
508           counters-&gt;update_tenuring_threshold(_tenuring_threshold);
509           counters-&gt;update_survivor_size_counters();
510         }
511 
512         // Do call at minor collections?
513         // Don&#39;t check if the size_policy is ready at this
514         // level.  Let the size_policy check that internally.
515         if (UseAdaptiveGenerationSizePolicyAtMinorCollection &amp;&amp;
516             (AdaptiveSizePolicy::should_update_eden_stats(gc_cause))) {
517           // Calculate optimal free space amounts
518           assert(young_gen-&gt;max_size() &gt;
519             young_gen-&gt;from_space()-&gt;capacity_in_bytes() +
520             young_gen-&gt;to_space()-&gt;capacity_in_bytes(),
521             &quot;Sizes of space in young gen are out-of-bounds&quot;);
522 
523           size_t young_live = young_gen-&gt;used_in_bytes();
524           size_t eden_live = young_gen-&gt;eden_space()-&gt;used_in_bytes();
525           size_t cur_eden = young_gen-&gt;eden_space()-&gt;capacity_in_bytes();
526           size_t max_old_gen_size = old_gen-&gt;max_gen_size();
527           size_t max_eden_size = max_young_size -
528             young_gen-&gt;from_space()-&gt;capacity_in_bytes() -
529             young_gen-&gt;to_space()-&gt;capacity_in_bytes();
530 
531           // Used for diagnostics
532           size_policy-&gt;clear_generation_free_space_flags();
533 
534           size_policy-&gt;compute_eden_space_size(young_live,
535                                                eden_live,
536                                                cur_eden,
537                                                max_eden_size,
538                                                false /* not full gc*/);
539 
540           size_policy-&gt;check_gc_overhead_limit(eden_live,
541                                                max_old_gen_size,
542                                                max_eden_size,
543                                                false /* not full gc*/,
544                                                gc_cause,
545                                                heap-&gt;soft_ref_policy());
546 
547           size_policy-&gt;decay_supplemental_growth(false /* not full gc*/);
548         }
549         // Resize the young generation at every collection
550         // even if new sizes have not been calculated.  This is
551         // to allow resizes that may have been inhibited by the
552         // relative location of the &quot;to&quot; and &quot;from&quot; spaces.
553 
554         // Resizing the old gen at young collections can cause increases
555         // that don&#39;t feed back to the generation sizing policy until
556         // a full collection.  Don&#39;t resize the old gen here.
557 
558         heap-&gt;resize_young_gen(size_policy-&gt;calculated_eden_size_in_bytes(),
559                         size_policy-&gt;calculated_survivor_size_in_bytes());
560 
561         log_debug(gc, ergo)(&quot;AdaptiveSizeStop: collection: %d &quot;, heap-&gt;total_collections());
562       }
563 
564       // Update the structure of the eden. With NUMA-eden CPU hotplugging or offlining can
565       // cause the change of the heap layout. Make sure eden is reshaped if that&#39;s the case.
566       // Also update() will case adaptive NUMA chunk resizing.
567       assert(young_gen-&gt;eden_space()-&gt;is_empty(), &quot;eden space should be empty now&quot;);
568       young_gen-&gt;eden_space()-&gt;update();
569 
570       heap-&gt;gc_policy_counters()-&gt;update_counters();
571 
572       heap-&gt;resize_all_tlabs();
573 
574       assert(young_gen-&gt;to_space()-&gt;is_empty(), &quot;to space should be empty now&quot;);
575     }
576 
577 #if COMPILER2_OR_JVMCI
578     DerivedPointerTable::update_pointers();
579 #endif
580 
581     NOT_PRODUCT(reference_processor()-&gt;verify_no_references_recorded());
582 
583     // Re-verify object start arrays
584     if (VerifyObjectStartArray &amp;&amp;
585         VerifyAfterGC) {
586       old_gen-&gt;verify_object_start_array();
587     }
588 
589     // Verify all old -&gt; young cards are now precise
590     if (VerifyRememberedSets) {
591       // Precise verification will give false positives. Until this is fixed,
592       // use imprecise verification.
593       // heap-&gt;card_table()-&gt;verify_all_young_refs_precise();
594       heap-&gt;card_table()-&gt;verify_all_young_refs_imprecise();
595     }
596 
597     if (log_is_enabled(Debug, gc, heap, exit)) {
598       accumulated_time()-&gt;stop();
599     }
600 
<a name="26" id="anc26"></a><span class="line-modified">601     young_gen-&gt;print_used_change(pre_gc_values.young_gen_used());</span>
<span class="line-removed">602     old_gen-&gt;print_used_change(pre_gc_values.old_gen_used());</span>
<span class="line-removed">603     MetaspaceUtils::print_metaspace_change(pre_gc_values.metadata_used());</span>
604 
605     // Track memory usage and detect low memory
606     MemoryService::track_memory_usage();
607     heap-&gt;update_counters();
<a name="27" id="anc27"></a><span class="line-removed">608 </span>
<span class="line-removed">609     gc_task_manager()-&gt;release_idle_workers();</span>
610   }
611 
612   if (VerifyAfterGC &amp;&amp; heap-&gt;total_collections() &gt;= VerifyGCStartAt) {
613     HandleMark hm;  // Discard invalid handles created during verification
614     Universe::verify(&quot;After GC&quot;);
615   }
616 
617   heap-&gt;print_heap_after_gc();
618   heap-&gt;trace_heap_after_gc(&amp;_gc_tracer);
619 
620   scavenge_exit.update();
621 
622   log_debug(gc, task, time)(&quot;VM-Thread &quot; JLONG_FORMAT &quot; &quot; JLONG_FORMAT &quot; &quot; JLONG_FORMAT,
623                             scavenge_entry.ticks(), scavenge_midpoint.ticks(),
624                             scavenge_exit.ticks());
<a name="28" id="anc28"></a><span class="line-removed">625   gc_task_manager()-&gt;print_task_time_stamps();</span>
<span class="line-removed">626 </span>
<span class="line-removed">627 #ifdef TRACESPINNING</span>
<span class="line-removed">628   ParallelTaskTerminator::print_termination_counts();</span>
<span class="line-removed">629 #endif</span>
630 
631   AdaptiveSizePolicyOutput::print(size_policy, heap-&gt;total_collections());
632 
633   _gc_timer.register_gc_end();
634 
635   _gc_tracer.report_gc_end(_gc_timer.gc_end(), _gc_timer.time_partitions());
636 
637   return !promotion_failure_occurred;
638 }
639 
640 // This method iterates over all objects in the young generation,
641 // removing all forwarding references. It then restores any preserved marks.
642 void PSScavenge::clean_up_failed_promotion() {
643   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
644   PSYoungGen* young_gen = heap-&gt;young_gen();
645 
646   RemoveForwardedPointerClosure remove_fwd_ptr_closure;
647   young_gen-&gt;object_iterate(&amp;remove_fwd_ptr_closure);
648 
649   PSPromotionManager::restore_preserved_marks();
650 
651   // Reset the PromotionFailureALot counters.
652   NOT_PRODUCT(heap-&gt;reset_promotion_should_fail();)
653 }
654 
655 bool PSScavenge::should_attempt_scavenge() {
656   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
657   PSGCAdaptivePolicyCounters* counters = heap-&gt;gc_policy_counters();
658 
659   if (UsePerfData) {
660     counters-&gt;update_scavenge_skipped(not_skipped);
661   }
662 
663   PSYoungGen* young_gen = heap-&gt;young_gen();
664   PSOldGen* old_gen = heap-&gt;old_gen();
665 
666   // Do not attempt to promote unless to_space is empty
667   if (!young_gen-&gt;to_space()-&gt;is_empty()) {
668     _consecutive_skipped_scavenges++;
669     if (UsePerfData) {
670       counters-&gt;update_scavenge_skipped(to_space_not_empty);
671     }
672     return false;
673   }
674 
675   // Test to see if the scavenge will likely fail.
676   PSAdaptiveSizePolicy* policy = heap-&gt;size_policy();
677 
678   // A similar test is done in the policy&#39;s should_full_GC().  If this is
679   // changed, decide if that test should also be changed.
680   size_t avg_promoted = (size_t) policy-&gt;padded_average_promoted_in_bytes();
681   size_t promotion_estimate = MIN2(avg_promoted, young_gen-&gt;used_in_bytes());
682   bool result = promotion_estimate &lt; old_gen-&gt;free_in_bytes();
683 
684   log_trace(ergo)(&quot;%s scavenge: average_promoted &quot; SIZE_FORMAT &quot; padded_average_promoted &quot; SIZE_FORMAT &quot; free in old gen &quot; SIZE_FORMAT,
685                 result ? &quot;Do&quot; : &quot;Skip&quot;, (size_t) policy-&gt;average_promoted_in_bytes(),
686                 (size_t) policy-&gt;padded_average_promoted_in_bytes(),
687                 old_gen-&gt;free_in_bytes());
688   if (young_gen-&gt;used_in_bytes() &lt; (size_t) policy-&gt;padded_average_promoted_in_bytes()) {
689     log_trace(ergo)(&quot; padded_promoted_average is greater than maximum promotion = &quot; SIZE_FORMAT, young_gen-&gt;used_in_bytes());
690   }
691 
692   if (result) {
693     _consecutive_skipped_scavenges = 0;
694   } else {
695     _consecutive_skipped_scavenges++;
696     if (UsePerfData) {
697       counters-&gt;update_scavenge_skipped(promoted_too_large);
698     }
699   }
700   return result;
701 }
702 
<a name="29" id="anc29"></a><span class="line-removed">703   // Used to add tasks</span>
<span class="line-removed">704 GCTaskManager* const PSScavenge::gc_task_manager() {</span>
<span class="line-removed">705   assert(ParallelScavengeHeap::gc_task_manager() != NULL,</span>
<span class="line-removed">706    &quot;shouldn&#39;t return NULL&quot;);</span>
<span class="line-removed">707   return ParallelScavengeHeap::gc_task_manager();</span>
<span class="line-removed">708 }</span>
<span class="line-removed">709 </span>
710 // Adaptive size policy support.  When the young generation/old generation
711 // boundary moves, _young_generation_boundary must be reset
712 void PSScavenge::set_young_generation_boundary(HeapWord* v) {
713   _young_generation_boundary = v;
714   if (UseCompressedOops) {
715     _young_generation_boundary_compressed = (uintptr_t)CompressedOops::encode((oop)v);
716   }
717 }
718 
719 void PSScavenge::initialize() {
720   // Arguments must have been parsed
721 
722   if (AlwaysTenure || NeverTenure) {
<a name="30" id="anc30"></a><span class="line-modified">723     assert(MaxTenuringThreshold == 0 || MaxTenuringThreshold == markOopDesc::max_age + 1,</span>
<span class="line-modified">724            &quot;MaxTenuringThreshold should be 0 or markOopDesc::max_age + 1, but is %d&quot;, (int) MaxTenuringThreshold);</span>
725     _tenuring_threshold = MaxTenuringThreshold;
726   } else {
727     // We want to smooth out our startup times for the AdaptiveSizePolicy
728     _tenuring_threshold = (UseAdaptiveSizePolicy) ? InitialTenuringThreshold :
729                                                     MaxTenuringThreshold;
730   }
731 
732   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
733   PSYoungGen* young_gen = heap-&gt;young_gen();
734   PSOldGen* old_gen = heap-&gt;old_gen();
735 
736   // Set boundary between young_gen and old_gen
737   assert(old_gen-&gt;reserved().end() &lt;= young_gen-&gt;eden_space()-&gt;bottom(),
738          &quot;old above young&quot;);
739   set_young_generation_boundary(young_gen-&gt;eden_space()-&gt;bottom());
740 
741   // Initialize ref handling object for scavenging.
742   _span_based_discoverer.set_span(young_gen-&gt;reserved());
743   _ref_processor =
744     new ReferenceProcessor(&amp;_span_based_discoverer,
745                            ParallelRefProcEnabled &amp;&amp; (ParallelGCThreads &gt; 1), // mt processing
746                            ParallelGCThreads,          // mt processing degree
747                            true,                       // mt discovery
748                            ParallelGCThreads,          // mt discovery degree
749                            true,                       // atomic_discovery
750                            NULL,                       // header provides liveness info
751                            false);
752 
753   // Cache the cardtable
754   _card_table = heap-&gt;card_table();
755 
756   _counters = new CollectorCounters(&quot;Parallel young collection pauses&quot;, 0);
757 }
<a name="31" id="anc31"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="31" type="hidden" />
</body>
</html>