<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff src/hotspot/share/gc/parallel/psParallelCompact.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="psOldGen.hpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="psParallelCompact.hpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/parallel/psParallelCompact.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 1,7 ***</span>
  /*
<span class="line-modified">!  * Copyright (c) 2005, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
<span class="line-new-header">--- 1,7 ---</span>
  /*
<span class="line-modified">!  * Copyright (c) 2005, 2020, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 28,19 ***</span>
  #include &quot;classfile/javaClasses.inline.hpp&quot;
  #include &quot;classfile/stringTable.hpp&quot;
  #include &quot;classfile/symbolTable.hpp&quot;
  #include &quot;classfile/systemDictionary.hpp&quot;
  #include &quot;code/codeCache.hpp&quot;
<span class="line-modified">! #include &quot;gc/parallel/gcTaskManager.hpp&quot;</span>
  #include &quot;gc/parallel/parallelScavengeHeap.inline.hpp&quot;
  #include &quot;gc/parallel/parMarkBitMap.inline.hpp&quot;
<span class="line-removed">- #include &quot;gc/parallel/pcTasks.hpp&quot;</span>
  #include &quot;gc/parallel/psAdaptiveSizePolicy.hpp&quot;
  #include &quot;gc/parallel/psCompactionManager.inline.hpp&quot;
  #include &quot;gc/parallel/psOldGen.hpp&quot;
  #include &quot;gc/parallel/psParallelCompact.inline.hpp&quot;
  #include &quot;gc/parallel/psPromotionManager.inline.hpp&quot;
  #include &quot;gc/parallel/psScavenge.hpp&quot;
  #include &quot;gc/parallel/psYoungGen.hpp&quot;
  #include &quot;gc/shared/gcCause.hpp&quot;
  #include &quot;gc/shared/gcHeapSummary.hpp&quot;
  #include &quot;gc/shared/gcId.hpp&quot;
<span class="line-new-header">--- 28,19 ---</span>
  #include &quot;classfile/javaClasses.inline.hpp&quot;
  #include &quot;classfile/stringTable.hpp&quot;
  #include &quot;classfile/symbolTable.hpp&quot;
  #include &quot;classfile/systemDictionary.hpp&quot;
  #include &quot;code/codeCache.hpp&quot;
<span class="line-modified">! #include &quot;gc/parallel/parallelArguments.hpp&quot;</span>
  #include &quot;gc/parallel/parallelScavengeHeap.inline.hpp&quot;
  #include &quot;gc/parallel/parMarkBitMap.inline.hpp&quot;
  #include &quot;gc/parallel/psAdaptiveSizePolicy.hpp&quot;
  #include &quot;gc/parallel/psCompactionManager.inline.hpp&quot;
  #include &quot;gc/parallel/psOldGen.hpp&quot;
  #include &quot;gc/parallel/psParallelCompact.inline.hpp&quot;
  #include &quot;gc/parallel/psPromotionManager.inline.hpp&quot;
<span class="line-added">+ #include &quot;gc/parallel/psRootType.hpp&quot;</span>
  #include &quot;gc/parallel/psScavenge.hpp&quot;
  #include &quot;gc/parallel/psYoungGen.hpp&quot;
  #include &quot;gc/shared/gcCause.hpp&quot;
  #include &quot;gc/shared/gcHeapSummary.hpp&quot;
  #include &quot;gc/shared/gcId.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 50,15 ***</span>
  #include &quot;gc/shared/gcTraceTime.inline.hpp&quot;
  #include &quot;gc/shared/isGCActiveMark.hpp&quot;
  #include &quot;gc/shared/referencePolicy.hpp&quot;
  #include &quot;gc/shared/referenceProcessor.hpp&quot;
  #include &quot;gc/shared/referenceProcessorPhaseTimes.hpp&quot;
<span class="line-modified">! #include &quot;gc/shared/spaceDecorator.hpp&quot;</span>
  #include &quot;gc/shared/weakProcessor.hpp&quot;
  #include &quot;logging/log.hpp&quot;
  #include &quot;memory/iterator.inline.hpp&quot;
  #include &quot;memory/resourceArea.hpp&quot;
  #include &quot;oops/access.inline.hpp&quot;
  #include &quot;oops/instanceClassLoaderKlass.inline.hpp&quot;
  #include &quot;oops/instanceKlass.inline.hpp&quot;
  #include &quot;oops/instanceMirrorKlass.inline.hpp&quot;
  #include &quot;oops/methodData.hpp&quot;
<span class="line-new-header">--- 50,19 ---</span>
  #include &quot;gc/shared/gcTraceTime.inline.hpp&quot;
  #include &quot;gc/shared/isGCActiveMark.hpp&quot;
  #include &quot;gc/shared/referencePolicy.hpp&quot;
  #include &quot;gc/shared/referenceProcessor.hpp&quot;
  #include &quot;gc/shared/referenceProcessorPhaseTimes.hpp&quot;
<span class="line-modified">! #include &quot;gc/shared/spaceDecorator.inline.hpp&quot;</span>
<span class="line-added">+ #include &quot;gc/shared/taskTerminator.hpp&quot;</span>
  #include &quot;gc/shared/weakProcessor.hpp&quot;
<span class="line-added">+ #include &quot;gc/shared/workerPolicy.hpp&quot;</span>
<span class="line-added">+ #include &quot;gc/shared/workgroup.hpp&quot;</span>
  #include &quot;logging/log.hpp&quot;
  #include &quot;memory/iterator.inline.hpp&quot;
  #include &quot;memory/resourceArea.hpp&quot;
<span class="line-added">+ #include &quot;memory/universe.hpp&quot;</span>
  #include &quot;oops/access.inline.hpp&quot;
  #include &quot;oops/instanceClassLoaderKlass.inline.hpp&quot;
  #include &quot;oops/instanceKlass.inline.hpp&quot;
  #include &quot;oops/instanceMirrorKlass.inline.hpp&quot;
  #include &quot;oops/methodData.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 75,10 ***</span>
<span class="line-new-header">--- 79,13 ---</span>
  #include &quot;utilities/debug.hpp&quot;
  #include &quot;utilities/events.hpp&quot;
  #include &quot;utilities/formatBuffer.hpp&quot;
  #include &quot;utilities/macros.hpp&quot;
  #include &quot;utilities/stack.inline.hpp&quot;
<span class="line-added">+ #if INCLUDE_JVMCI</span>
<span class="line-added">+ #include &quot;jvmci/jvmci.hpp&quot;</span>
<span class="line-added">+ #endif</span>
  
  #include &lt;math.h&gt;
  
  // All sizes are in HeapWords.
  const size_t ParallelCompactData::Log2RegionSize  = 16; // 64K words
</pre>
<hr />
<pre>
<span class="line-old-header">*** 404,23 ***</span>
  size_t add_obj_size;
  size_t mark_bitmap_count;
  size_t mark_bitmap_size;
  #endif  // #ifdef ASSERT
  
<span class="line-modified">! ParallelCompactData::ParallelCompactData()</span>
<span class="line-modified">! {</span>
<span class="line-modified">!   _region_start = 0;</span>
<span class="line-modified">! </span>
<span class="line-modified">!   _region_vspace = 0;</span>
<span class="line-modified">!   _reserved_byte_size = 0;</span>
<span class="line-modified">!   _region_data = 0;</span>
<span class="line-modified">!   _region_count = 0;</span>
<span class="line-modified">! </span>
<span class="line-modified">!   _block_vspace = 0;</span>
<span class="line-removed">-   _block_data = 0;</span>
<span class="line-removed">-   _block_count = 0;</span>
<span class="line-removed">- }</span>
  
  bool ParallelCompactData::initialize(MemRegion covered_region)
  {
    _region_start = covered_region.start();
    const size_t region_size = covered_region.word_size();
<span class="line-new-header">--- 411,20 ---</span>
  size_t add_obj_size;
  size_t mark_bitmap_count;
  size_t mark_bitmap_size;
  #endif  // #ifdef ASSERT
  
<span class="line-modified">! ParallelCompactData::ParallelCompactData() :</span>
<span class="line-modified">!   _region_start(NULL),</span>
<span class="line-modified">!   DEBUG_ONLY(_region_end(NULL) COMMA)</span>
<span class="line-modified">!   _region_vspace(NULL),</span>
<span class="line-modified">!   _reserved_byte_size(0),</span>
<span class="line-modified">!   _region_data(NULL),</span>
<span class="line-modified">!   _region_count(0),</span>
<span class="line-modified">!   _block_vspace(NULL),</span>
<span class="line-modified">!   _block_data(NULL),</span>
<span class="line-modified">!   _block_count(0) {}</span>
  
  bool ParallelCompactData::initialize(MemRegion covered_region)
  {
    _region_start = covered_region.start();
    const size_t region_size = covered_region.word_size();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 527,11 ***</span>
    const size_t obj_ofs = pointer_delta(addr, _region_start);
    const size_t beg_region = obj_ofs &gt;&gt; Log2RegionSize;
    const size_t end_region = (obj_ofs + len - 1) &gt;&gt; Log2RegionSize;
  
    DEBUG_ONLY(Atomic::inc(&amp;add_obj_count);)
<span class="line-modified">!   DEBUG_ONLY(Atomic::add(len, &amp;add_obj_size);)</span>
  
    if (beg_region == end_region) {
      // All in one region.
      _region_data[beg_region].add_live_obj(len);
      return;
<span class="line-new-header">--- 531,11 ---</span>
    const size_t obj_ofs = pointer_delta(addr, _region_start);
    const size_t beg_region = obj_ofs &gt;&gt; Log2RegionSize;
    const size_t end_region = (obj_ofs + len - 1) &gt;&gt; Log2RegionSize;
  
    DEBUG_ONLY(Atomic::inc(&amp;add_obj_count);)
<span class="line-modified">!   DEBUG_ONLY(Atomic::add(&amp;add_obj_size, len);)</span>
  
    if (beg_region == end_region) {
      // All in one region.
      _region_data[beg_region].add_live_obj(len);
      return;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 956,11 ***</span>
    HeapWord* const bot = space-&gt;bottom();
    HeapWord* const top = space-&gt;top();
    HeapWord* const max_top = MAX2(top, _space_info[id].new_top());
  
    const idx_t beg_bit = _mark_bitmap.addr_to_bit(bot);
<span class="line-modified">!   const idx_t end_bit = BitMap::word_align_up(_mark_bitmap.addr_to_bit(top));</span>
    _mark_bitmap.clear_range(beg_bit, end_bit);
  
    const size_t beg_region = _summary_data.addr_to_region_idx(bot);
    const size_t end_region =
      _summary_data.addr_to_region_idx(_summary_data.region_align_up(max_top));
<span class="line-new-header">--- 960,11 ---</span>
    HeapWord* const bot = space-&gt;bottom();
    HeapWord* const top = space-&gt;top();
    HeapWord* const max_top = MAX2(top, _space_info[id].new_top());
  
    const idx_t beg_bit = _mark_bitmap.addr_to_bit(bot);
<span class="line-modified">!   const idx_t end_bit = _mark_bitmap.align_range_end(_mark_bitmap.addr_to_bit(top));</span>
    _mark_bitmap.clear_range(beg_bit, end_bit);
  
    const size_t beg_region = _summary_data.addr_to_region_idx(bot);
    const size_t end_region =
      _summary_data.addr_to_region_idx(_summary_data.region_align_up(max_top));
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1012,19 ***</span>
    }
  
    DEBUG_ONLY(mark_bitmap()-&gt;verify_clear();)
    DEBUG_ONLY(summary_data().verify_clear();)
  
<span class="line-removed">-   // Have worker threads release resources the next time they run a task.</span>
<span class="line-removed">-   gc_task_manager()-&gt;release_all_resources();</span>
<span class="line-removed">- </span>
    ParCompactionManager::reset_all_bitmap_query_caches();
  }
  
  void PSParallelCompact::post_compact()
  {
    GCTraceTime(Info, gc, phases) tm(&quot;Post Compact&quot;, &amp;_gc_timer);
  
    for (unsigned int id = old_space_id; id &lt; last_space_id; ++id) {
      // Clear the marking bitmap, summary data and split info.
      clear_data_covering_space(SpaceId(id));
      // Update top().  Must be done after clearing the bitmap and summary data.
<span class="line-new-header">--- 1016,17 ---</span>
    }
  
    DEBUG_ONLY(mark_bitmap()-&gt;verify_clear();)
    DEBUG_ONLY(summary_data().verify_clear();)
  
    ParCompactionManager::reset_all_bitmap_query_caches();
  }
  
  void PSParallelCompact::post_compact()
  {
    GCTraceTime(Info, gc, phases) tm(&quot;Post Compact&quot;, &amp;_gc_timer);
<span class="line-added">+   ParCompactionManager::remove_all_shadow_regions();</span>
  
    for (unsigned int id = old_space_id; id &lt; last_space_id; ++id) {
      // Clear the marking bitmap, summary data and split info.
      clear_data_covering_space(SpaceId(id));
      // Update top().  Must be done after clearing the bitmap and summary data.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1059,12 ***</span>
  
    // Delete metaspaces for unloaded class loaders and clean up loader_data graph
    ClassLoaderDataGraph::purge();
    MetaspaceUtils::verify_metrics();
  
<span class="line-modified">!   heap-&gt;prune_nmethods();</span>
<span class="line-removed">-   JvmtiExport::gc_epilogue();</span>
  
  #if COMPILER2_OR_JVMCI
    DerivedPointerTable::update_pointers();
  #endif
  
<span class="line-new-header">--- 1061,11 ---</span>
  
    // Delete metaspaces for unloaded class loaders and clean up loader_data graph
    ClassLoaderDataGraph::purge();
    MetaspaceUtils::verify_metrics();
  
<span class="line-modified">!   heap-&gt;prune_scavengable_nmethods();</span>
  
  #if COMPILER2_OR_JVMCI
    DerivedPointerTable::update_pointers();
  #endif
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1112,32 ***</span>
    const double cur_density = double(space_live) / space_capacity;
    const double deadwood_density =
      (1.0 - cur_density) * (1.0 - cur_density) * cur_density * cur_density;
    const size_t deadwood_goal = size_t(space_capacity * deadwood_density);
  
<span class="line-modified">!   if (TraceParallelOldGCDensePrefix) {</span>
<span class="line-modified">!     tty-&gt;print_cr(&quot;cur_dens=%5.3f dw_dens=%5.3f dw_goal=&quot; SIZE_FORMAT,</span>
<span class="line-modified">!                   cur_density, deadwood_density, deadwood_goal);</span>
<span class="line-modified">!     tty-&gt;print_cr(&quot;space_live=&quot; SIZE_FORMAT &quot; &quot; &quot;space_used=&quot; SIZE_FORMAT &quot; &quot;</span>
<span class="line-modified">!                   &quot;space_cap=&quot; SIZE_FORMAT,</span>
<span class="line-modified">!                   space_live, space_used,</span>
<span class="line-modified">!                   space_capacity);</span>
<span class="line-modified">!   }</span>
  
    // XXX - Use binary search?
    HeapWord* dense_prefix = sd.region_to_addr(cp);
    const RegionData* full_cp = cp;
    const RegionData* const top_cp = sd.addr_to_region_ptr(space-&gt;top() - 1);
    while (cp &lt; end_cp) {
      HeapWord* region_destination = cp-&gt;destination();
      const size_t cur_deadwood = pointer_delta(dense_prefix, region_destination);
<span class="line-modified">!     if (TraceParallelOldGCDensePrefix &amp;&amp; Verbose) {</span>
<span class="line-modified">!       tty-&gt;print_cr(&quot;c#=&quot; SIZE_FORMAT_W(4) &quot; dst=&quot; PTR_FORMAT &quot; &quot;</span>
<span class="line-modified">!                     &quot;dp=&quot; PTR_FORMAT &quot; &quot; &quot;cdw=&quot; SIZE_FORMAT_W(8),</span>
<span class="line-modified">!                     sd.region(cp), p2i(region_destination),</span>
<span class="line-modified">!                     p2i(dense_prefix), cur_deadwood);</span>
<span class="line-modified">!     }</span>
  
      if (cur_deadwood &gt;= deadwood_goal) {
        // Found the region that has the correct amount of deadwood to the left.
        // This typically occurs after crossing a fairly sparse set of regions, so
        // iterate backwards over those sparse regions, looking for the region
<span class="line-new-header">--- 1113,32 ---</span>
    const double cur_density = double(space_live) / space_capacity;
    const double deadwood_density =
      (1.0 - cur_density) * (1.0 - cur_density) * cur_density * cur_density;
    const size_t deadwood_goal = size_t(space_capacity * deadwood_density);
  
<span class="line-modified">!   log_develop_debug(gc, compaction)(</span>
<span class="line-modified">!       &quot;cur_dens=%5.3f dw_dens=%5.3f dw_goal=&quot; SIZE_FORMAT,</span>
<span class="line-modified">!       cur_density, deadwood_density, deadwood_goal);</span>
<span class="line-modified">!   log_develop_debug(gc, compaction)(</span>
<span class="line-modified">!       &quot;space_live=&quot; SIZE_FORMAT &quot; space_used=&quot; SIZE_FORMAT &quot; &quot;</span>
<span class="line-modified">!       &quot;space_cap=&quot; SIZE_FORMAT,</span>
<span class="line-modified">!       space_live, space_used,</span>
<span class="line-modified">!       space_capacity);</span>
  
    // XXX - Use binary search?
    HeapWord* dense_prefix = sd.region_to_addr(cp);
    const RegionData* full_cp = cp;
    const RegionData* const top_cp = sd.addr_to_region_ptr(space-&gt;top() - 1);
    while (cp &lt; end_cp) {
      HeapWord* region_destination = cp-&gt;destination();
      const size_t cur_deadwood = pointer_delta(dense_prefix, region_destination);
<span class="line-modified">! </span>
<span class="line-modified">!     log_develop_trace(gc, compaction)(</span>
<span class="line-modified">!         &quot;c#=&quot; SIZE_FORMAT_W(4) &quot; dst=&quot; PTR_FORMAT &quot; &quot;</span>
<span class="line-modified">!         &quot;dp=&quot; PTR_FORMAT &quot; cdw=&quot; SIZE_FORMAT_W(8),</span>
<span class="line-modified">!         sd.region(cp), p2i(region_destination),</span>
<span class="line-modified">!         p2i(dense_prefix), cur_deadwood);</span>
  
      if (cur_deadwood &gt;= deadwood_goal) {
        // Found the region that has the correct amount of deadwood to the left.
        // This typically occurs after crossing a fairly sparse set of regions, so
        // iterate backwards over those sparse regions, looking for the region
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1155,15 ***</span>
          double prev_region_density_to_right =
            double(prev_region_live_to_right) / prev_region_space_to_right;
          if (density_to_right &lt;= prev_region_density_to_right) {
            return dense_prefix;
          }
<span class="line-modified">!         if (TraceParallelOldGCDensePrefix &amp;&amp; Verbose) {</span>
<span class="line-modified">!           tty-&gt;print_cr(&quot;backing up from c=&quot; SIZE_FORMAT_W(4) &quot; d2r=%10.8f &quot;</span>
<span class="line-modified">!                         &quot;pc_d2r=%10.8f&quot;, sd.region(cp), density_to_right,</span>
<span class="line-modified">!                         prev_region_density_to_right);</span>
<span class="line-modified">!         }</span>
          dense_prefix -= region_size;
          live_to_right = prev_region_live_to_right;
          space_to_right = prev_region_space_to_right;
          density_to_right = prev_region_density_to_right;
        }
<span class="line-new-header">--- 1156,17 ---</span>
          double prev_region_density_to_right =
            double(prev_region_live_to_right) / prev_region_space_to_right;
          if (density_to_right &lt;= prev_region_density_to_right) {
            return dense_prefix;
          }
<span class="line-modified">! </span>
<span class="line-modified">!         log_develop_trace(gc, compaction)(</span>
<span class="line-modified">!             &quot;backing up from c=&quot; SIZE_FORMAT_W(4) &quot; d2r=%10.8f &quot;</span>
<span class="line-modified">!             &quot;pc_d2r=%10.8f&quot;,</span>
<span class="line-modified">!             sd.region(cp), density_to_right,</span>
<span class="line-added">+             prev_region_density_to_right);</span>
<span class="line-added">+ </span>
          dense_prefix -= region_size;
          live_to_right = prev_region_live_to_right;
          space_to_right = prev_region_space_to_right;
          density_to_right = prev_region_density_to_right;
        }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1193,20 ***</span>
    const size_t space_cap = space-&gt;capacity_in_words();
    const double dead_to_left_pct = double(dead_to_left) / space_cap;
    const size_t live_to_right = new_top - cp-&gt;destination();
    const size_t dead_to_right = space-&gt;top() - addr - live_to_right;
  
<span class="line-modified">!   tty-&gt;print_cr(&quot;%s=&quot; PTR_FORMAT &quot; dpc=&quot; SIZE_FORMAT_W(5) &quot; &quot;</span>
<span class="line-modified">!                 &quot;spl=&quot; SIZE_FORMAT &quot; &quot;</span>
<span class="line-modified">!                 &quot;d2l=&quot; SIZE_FORMAT &quot; d2l%%=%6.4f &quot;</span>
<span class="line-modified">!                 &quot;d2r=&quot; SIZE_FORMAT &quot; l2r=&quot; SIZE_FORMAT</span>
<span class="line-modified">!                 &quot; ratio=%10.8f&quot;,</span>
<span class="line-modified">!                 algorithm, p2i(addr), region_idx,</span>
<span class="line-modified">!                 space_live,</span>
<span class="line-modified">!                 dead_to_left, dead_to_left_pct,</span>
<span class="line-modified">!                 dead_to_right, live_to_right,</span>
<span class="line-modified">!                 double(dead_to_right) / live_to_right);</span>
  }
  #endif  // #ifndef PRODUCT
  
  // Return a fraction indicating how much of the generation can be treated as
  // &quot;dead wood&quot; (i.e., not reclaimed).  The function uses a normal distribution
<span class="line-new-header">--- 1196,21 ---</span>
    const size_t space_cap = space-&gt;capacity_in_words();
    const double dead_to_left_pct = double(dead_to_left) / space_cap;
    const size_t live_to_right = new_top - cp-&gt;destination();
    const size_t dead_to_right = space-&gt;top() - addr - live_to_right;
  
<span class="line-modified">!   log_develop_debug(gc, compaction)(</span>
<span class="line-modified">!       &quot;%s=&quot; PTR_FORMAT &quot; dpc=&quot; SIZE_FORMAT_W(5) &quot; &quot;</span>
<span class="line-modified">!       &quot;spl=&quot; SIZE_FORMAT &quot; &quot;</span>
<span class="line-modified">!       &quot;d2l=&quot; SIZE_FORMAT &quot; d2l%%=%6.4f &quot;</span>
<span class="line-modified">!       &quot;d2r=&quot; SIZE_FORMAT &quot; l2r=&quot; SIZE_FORMAT &quot; &quot;</span>
<span class="line-modified">!       &quot;ratio=%10.8f&quot;,</span>
<span class="line-modified">!       algorithm, p2i(addr), region_idx,</span>
<span class="line-modified">!       space_live,</span>
<span class="line-modified">!       dead_to_left, dead_to_left_pct,</span>
<span class="line-modified">!       dead_to_right, live_to_right,</span>
<span class="line-added">+       double(dead_to_right) / live_to_right);</span>
  }
  #endif  // #ifndef PRODUCT
  
  // Return a fraction indicating how much of the generation can be treated as
  // &quot;dead wood&quot; (i.e., not reclaimed).  The function uses a normal distribution
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1410,20 ***</span>
    const double limiter = dead_wood_limiter(density, min_percent_free);
    const size_t dead_wood_max = space_used - space_live;
    const size_t dead_wood_limit = MIN2(size_t(space_capacity * limiter),
                                        dead_wood_max);
  
<span class="line-modified">!   if (TraceParallelOldGCDensePrefix) {</span>
<span class="line-modified">!     tty-&gt;print_cr(&quot;space_live=&quot; SIZE_FORMAT &quot; &quot; &quot;space_used=&quot; SIZE_FORMAT &quot; &quot;</span>
<span class="line-modified">!                   &quot;space_cap=&quot; SIZE_FORMAT,</span>
<span class="line-modified">!                   space_live, space_used,</span>
<span class="line-modified">!                   space_capacity);</span>
<span class="line-modified">!     tty-&gt;print_cr(&quot;dead_wood_limiter(%6.4f, &quot; SIZE_FORMAT &quot;)=%6.4f &quot;</span>
<span class="line-modified">!                   &quot;dead_wood_max=&quot; SIZE_FORMAT &quot; dead_wood_limit=&quot; SIZE_FORMAT,</span>
<span class="line-modified">!                   density, min_percent_free, limiter,</span>
<span class="line-modified">!                   dead_wood_max, dead_wood_limit);</span>
<span class="line-modified">!   }</span>
  
    // Locate the region with the desired amount of dead space to the left.
    const RegionData* const limit_cp =
      dead_wood_limit_region(full_cp, top_cp, dead_wood_limit);
  
<span class="line-new-header">--- 1414,20 ---</span>
    const double limiter = dead_wood_limiter(density, min_percent_free);
    const size_t dead_wood_max = space_used - space_live;
    const size_t dead_wood_limit = MIN2(size_t(space_capacity * limiter),
                                        dead_wood_max);
  
<span class="line-modified">!   log_develop_debug(gc, compaction)(</span>
<span class="line-modified">!       &quot;space_live=&quot; SIZE_FORMAT &quot; space_used=&quot; SIZE_FORMAT &quot; &quot;</span>
<span class="line-modified">!       &quot;space_cap=&quot; SIZE_FORMAT,</span>
<span class="line-modified">!       space_live, space_used,</span>
<span class="line-modified">!       space_capacity);</span>
<span class="line-modified">!   log_develop_debug(gc, compaction)(</span>
<span class="line-modified">!       &quot;dead_wood_limiter(%6.4f, &quot; SIZE_FORMAT &quot;)=%6.4f &quot;</span>
<span class="line-modified">!       &quot;dead_wood_max=&quot; SIZE_FORMAT &quot; dead_wood_limit=&quot; SIZE_FORMAT,</span>
<span class="line-modified">!       density, min_percent_free, limiter,</span>
<span class="line-modified">!       dead_wood_max, dead_wood_limit);</span>
  
    // Locate the region with the desired amount of dead space to the left.
    const RegionData* const limit_cp =
      dead_wood_limit_region(full_cp, top_cp, dead_wood_limit);
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1533,11 ***</span>
    if (_space_info[id].new_top() != space-&gt;bottom()) {
      HeapWord* dense_prefix_end = compute_dense_prefix(id, maximum_compaction);
      _space_info[id].set_dense_prefix(dense_prefix_end);
  
  #ifndef PRODUCT
<span class="line-modified">!     if (TraceParallelOldGCDensePrefix) {</span>
        print_dense_prefix_stats(&quot;ratio&quot;, id, maximum_compaction,
                                 dense_prefix_end);
        HeapWord* addr = compute_dense_prefix_via_density(id, maximum_compaction);
        print_dense_prefix_stats(&quot;density&quot;, id, maximum_compaction, addr);
      }
<span class="line-new-header">--- 1537,11 ---</span>
    if (_space_info[id].new_top() != space-&gt;bottom()) {
      HeapWord* dense_prefix_end = compute_dense_prefix(id, maximum_compaction);
      _space_info[id].set_dense_prefix(dense_prefix_end);
  
  #ifndef PRODUCT
<span class="line-modified">!     if (log_is_enabled(Debug, gc, compaction)) {</span>
        print_dense_prefix_stats(&quot;ratio&quot;, id, maximum_compaction,
                                 dense_prefix_end);
        HeapWord* addr = compute_dense_prefix_via_density(id, maximum_compaction);
        print_dense_prefix_stats(&quot;density&quot;, id, maximum_compaction, addr);
      }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1607,20 ***</span>
  void PSParallelCompact::summary_phase(ParCompactionManager* cm,
                                        bool maximum_compaction)
  {
    GCTraceTime(Info, gc, phases) tm(&quot;Summary Phase&quot;, &amp;_gc_timer);
  
<span class="line-modified">! #ifdef  ASSERT</span>
<span class="line-modified">!   if (TraceParallelOldGCMarkingPhase) {</span>
<span class="line-modified">!     tty-&gt;print_cr(&quot;add_obj_count=&quot; SIZE_FORMAT &quot; &quot;</span>
<span class="line-modified">!                   &quot;add_obj_bytes=&quot; SIZE_FORMAT,</span>
<span class="line-modified">!                   add_obj_count, add_obj_size * HeapWordSize);</span>
<span class="line-modified">!     tty-&gt;print_cr(&quot;mark_bitmap_count=&quot; SIZE_FORMAT &quot; &quot;</span>
<span class="line-modified">!                   &quot;mark_bitmap_bytes=&quot; SIZE_FORMAT,</span>
<span class="line-modified">!                   mark_bitmap_count, mark_bitmap_size * HeapWordSize);</span>
<span class="line-modified">!   }</span>
<span class="line-modified">! #endif  // #ifdef ASSERT</span>
  
    // Quick summarization of each space into itself, to see how much is live.
    summarize_spaces_quick();
  
    log_develop_trace(gc, compaction)(&quot;summary phase:  after summarizing each space to self&quot;);
<span class="line-new-header">--- 1611,20 ---</span>
  void PSParallelCompact::summary_phase(ParCompactionManager* cm,
                                        bool maximum_compaction)
  {
    GCTraceTime(Info, gc, phases) tm(&quot;Summary Phase&quot;, &amp;_gc_timer);
  
<span class="line-modified">!   log_develop_debug(gc, marking)(</span>
<span class="line-modified">!       &quot;add_obj_count=&quot; SIZE_FORMAT &quot; &quot;</span>
<span class="line-modified">!       &quot;add_obj_bytes=&quot; SIZE_FORMAT,</span>
<span class="line-modified">!       add_obj_count,</span>
<span class="line-modified">!       add_obj_size * HeapWordSize);</span>
<span class="line-modified">!   log_develop_debug(gc, marking)(</span>
<span class="line-modified">!       &quot;mark_bitmap_count=&quot; SIZE_FORMAT &quot; &quot;</span>
<span class="line-modified">!       &quot;mark_bitmap_bytes=&quot; SIZE_FORMAT,</span>
<span class="line-modified">!       mark_bitmap_count,</span>
<span class="line-modified">!       mark_bitmap_size * HeapWordSize);</span>
  
    // Quick summarization of each space into itself, to see how much is live.
    summarize_spaces_quick();
  
    log_develop_trace(gc, compaction)(&quot;summary phase:  after summarizing each space to self&quot;);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1710,11 ***</span>
  // before full gc, or any other specialized behavior, it needs to be added here.
  //
  // Note that this method should only be called from the vm_thread while at a
  // safepoint.
  //
<span class="line-modified">! // Note that the all_soft_refs_clear flag in the collector policy</span>
  // may be true because this method can be called without intervening
  // activity.  For example when the heap space is tight and full measure
  // are being taken to free space.
  void PSParallelCompact::invoke(bool maximum_heap_compaction) {
    assert(SafepointSynchronize::is_at_safepoint(), &quot;should be at safepoint&quot;);
<span class="line-new-header">--- 1714,11 ---</span>
  // before full gc, or any other specialized behavior, it needs to be added here.
  //
  // Note that this method should only be called from the vm_thread while at a
  // safepoint.
  //
<span class="line-modified">! // Note that the all_soft_refs_clear flag in the soft ref policy</span>
  // may be true because this method can be called without intervening
  // activity.  For example when the heap space is tight and full measure
  // are being taken to free space.
  void PSParallelCompact::invoke(bool maximum_heap_compaction) {
    assert(SafepointSynchronize::is_at_safepoint(), &quot;should be at safepoint&quot;);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1763,11 ***</span>
    PSYoungGen* young_gen = heap-&gt;young_gen();
    PSOldGen* old_gen = heap-&gt;old_gen();
    PSAdaptiveSizePolicy* size_policy = heap-&gt;size_policy();
  
    // The scope of casr should end after code that can change
<span class="line-modified">!   // CollectorPolicy::_should_clear_all_soft_refs.</span>
    ClearedAllSoftRefs casr(maximum_heap_compaction,
                            heap-&gt;soft_ref_policy());
  
    if (ZapUnusedHeapArea) {
      // Save information needed to minimize mangling
<span class="line-new-header">--- 1767,11 ---</span>
    PSYoungGen* young_gen = heap-&gt;young_gen();
    PSOldGen* old_gen = heap-&gt;old_gen();
    PSAdaptiveSizePolicy* size_policy = heap-&gt;size_policy();
  
    // The scope of casr should end after code that can change
<span class="line-modified">!   // SoftRefPolicy::_should_clear_all_soft_refs.</span>
    ClearedAllSoftRefs casr(maximum_heap_compaction,
                            heap-&gt;soft_ref_policy());
  
    if (ZapUnusedHeapArea) {
      // Save information needed to minimize mangling
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1776,23 ***</span>
  
    // Make sure data structures are sane, make the heap parsable, and do other
    // miscellaneous bookkeeping.
    pre_compact();
  
<span class="line-modified">!   PreGCValues pre_gc_values(heap);</span>
  
    // Get the compaction manager reserved for the VM thread.
    ParCompactionManager* const vmthread_cm =
<span class="line-modified">!     ParCompactionManager::manager_array(gc_task_manager()-&gt;workers());</span>
  
    {
      ResourceMark rm;
      HandleMark hm;
  
<span class="line-modified">!     // Set the number of GC threads to be used in this collection</span>
<span class="line-modified">!     gc_task_manager()-&gt;set_active_gang();</span>
<span class="line-modified">!     gc_task_manager()-&gt;task_idle_workers();</span>
  
      GCTraceCPUTime tcpu;
      GCTraceTime(Info, gc) tm(&quot;Pause Full&quot;, NULL, gc_cause, true);
  
      heap-&gt;pre_full_gc_dump(&amp;_gc_timer);
<span class="line-new-header">--- 1780,25 ---</span>
  
    // Make sure data structures are sane, make the heap parsable, and do other
    // miscellaneous bookkeeping.
    pre_compact();
  
<span class="line-modified">!   const PreGenGCValues pre_gc_values = heap-&gt;get_pre_gc_values();</span>
  
    // Get the compaction manager reserved for the VM thread.
    ParCompactionManager* const vmthread_cm =
<span class="line-modified">!     ParCompactionManager::manager_array(ParallelScavengeHeap::heap()-&gt;workers().total_workers());</span>
  
    {
      ResourceMark rm;
      HandleMark hm;
  
<span class="line-modified">!     const uint active_workers =</span>
<span class="line-modified">!       WorkerPolicy::calc_active_workers(ParallelScavengeHeap::heap()-&gt;workers().total_workers(),</span>
<span class="line-modified">!                                         ParallelScavengeHeap::heap()-&gt;workers().active_workers(),</span>
<span class="line-added">+                                         Threads::number_of_non_daemon_threads());</span>
<span class="line-added">+     ParallelScavengeHeap::heap()-&gt;workers().update_active_workers(active_workers);</span>
  
      GCTraceCPUTime tcpu;
      GCTraceTime(Info, gc) tm(&quot;Pause Full&quot;, NULL, gc_cause, true);
  
      heap-&gt;pre_full_gc_dump(&amp;_gc_timer);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1920,18 ***</span>
  
      if (log_is_enabled(Debug, gc, heap, exit)) {
        accumulated_time()-&gt;stop();
      }
  
<span class="line-modified">!     young_gen-&gt;print_used_change(pre_gc_values.young_gen_used());</span>
<span class="line-removed">-     old_gen-&gt;print_used_change(pre_gc_values.old_gen_used());</span>
<span class="line-removed">-     MetaspaceUtils::print_metaspace_change(pre_gc_values.metadata_used());</span>
  
      // Track memory usage and detect low memory
      MemoryService::track_memory_usage();
      heap-&gt;update_counters();
<span class="line-removed">-     gc_task_manager()-&gt;release_idle_workers();</span>
  
      heap-&gt;post_full_gc_dump(&amp;_gc_timer);
    }
  
  #ifdef ASSERT
<span class="line-new-header">--- 1926,15 ---</span>
  
      if (log_is_enabled(Debug, gc, heap, exit)) {
        accumulated_time()-&gt;stop();
      }
  
<span class="line-modified">!     heap-&gt;print_heap_change(pre_gc_values);</span>
  
      // Track memory usage and detect low memory
      MemoryService::track_memory_usage();
      heap-&gt;update_counters();
  
      heap-&gt;post_full_gc_dump(&amp;_gc_timer);
    }
  
  #ifdef ASSERT
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1966,15 ***</span>
    heap-&gt;trace_heap_after_gc(&amp;_gc_tracer);
  
    log_debug(gc, task, time)(&quot;VM-Thread &quot; JLONG_FORMAT &quot; &quot; JLONG_FORMAT &quot; &quot; JLONG_FORMAT,
                           marking_start.ticks(), compaction_start.ticks(),
                           collection_exit.ticks());
<span class="line-removed">-   gc_task_manager()-&gt;print_task_time_stamps();</span>
<span class="line-removed">- </span>
<span class="line-removed">- #ifdef TRACESPINNING</span>
<span class="line-removed">-   ParallelTaskTerminator::print_termination_counts();</span>
<span class="line-removed">- #endif</span>
  
    AdaptiveSizePolicyOutput::print(size_policy, heap-&gt;total_collections());
  
    _gc_timer.register_gc_end();
  
<span class="line-new-header">--- 1969,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1990,14 ***</span>
    MutableSpace* const eden_space = young_gen-&gt;eden_space();
    assert(!eden_space-&gt;is_empty(), &quot;eden must be non-empty&quot;);
    assert(young_gen-&gt;virtual_space()-&gt;alignment() ==
           old_gen-&gt;virtual_space()-&gt;alignment(), &quot;alignments do not match&quot;);
  
<span class="line-modified">!   // We also return false when it&#39;s a heterogenous heap because old generation cannot absorb data from eden</span>
    // when it is allocated on different memory (example, nv-dimm) than young.
    if (!(UseAdaptiveSizePolicy &amp;&amp; UseAdaptiveGCBoundary) ||
<span class="line-modified">!       ParallelScavengeHeap::heap()-&gt;ps_collector_policy()-&gt;is_hetero_heap()) {</span>
      return false;
    }
  
    // Both generations must be completely committed.
    if (young_gen-&gt;virtual_space()-&gt;uncommitted_size() != 0) {
<span class="line-new-header">--- 1988,14 ---</span>
    MutableSpace* const eden_space = young_gen-&gt;eden_space();
    assert(!eden_space-&gt;is_empty(), &quot;eden must be non-empty&quot;);
    assert(young_gen-&gt;virtual_space()-&gt;alignment() ==
           old_gen-&gt;virtual_space()-&gt;alignment(), &quot;alignments do not match&quot;);
  
<span class="line-modified">!   // We also return false when it&#39;s a heterogeneous heap because old generation cannot absorb data from eden</span>
    // when it is allocated on different memory (example, nv-dimm) than young.
    if (!(UseAdaptiveSizePolicy &amp;&amp; UseAdaptiveGCBoundary) ||
<span class="line-modified">!       ParallelArguments::is_heterogeneous_heap()) {</span>
      return false;
    }
  
    // Both generations must be completely committed.
    if (young_gen-&gt;virtual_space()-&gt;uncommitted_size() != 0) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2071,71 ***</span>
  
    size_policy-&gt;set_bytes_absorbed_from_eden(absorb_size);
    return true;
  }
  
<span class="line-removed">- GCTaskManager* const PSParallelCompact::gc_task_manager() {</span>
<span class="line-removed">-   assert(ParallelScavengeHeap::gc_task_manager() != NULL,</span>
<span class="line-removed">-     &quot;shouldn&#39;t return NULL&quot;);</span>
<span class="line-removed">-   return ParallelScavengeHeap::gc_task_manager();</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
  class PCAddThreadRootsMarkingTaskClosure : public ThreadClosure {
  private:
<span class="line-modified">!   GCTaskQueue* _q;</span>
  
  public:
<span class="line-modified">!   PCAddThreadRootsMarkingTaskClosure(GCTaskQueue* q) : _q(q) { }</span>
<span class="line-modified">!   void do_thread(Thread* t) {</span>
<span class="line-modified">!     _q-&gt;enqueue(new ThreadRootsMarkingTask(t));</span>
    }
  };
  
  void PSParallelCompact::marking_phase(ParCompactionManager* cm,
                                        bool maximum_heap_compaction,
                                        ParallelOldTracer *gc_tracer) {
    // Recursively traverse all live objects and mark them
    GCTraceTime(Info, gc, phases) tm(&quot;Marking Phase&quot;, &amp;_gc_timer);
  
    ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
<span class="line-modified">!   uint parallel_gc_threads = heap-&gt;gc_task_manager()-&gt;workers();</span>
<span class="line-removed">-   uint active_gc_threads = heap-&gt;gc_task_manager()-&gt;active_workers();</span>
<span class="line-removed">-   TaskQueueSetSuper* qset = ParCompactionManager::stack_array();</span>
<span class="line-removed">-   TaskTerminator terminator(active_gc_threads, qset);</span>
  
    PCMarkAndPushClosure mark_and_push_closure(cm);
    ParCompactionManager::FollowStackClosure follow_stack_closure(cm);
  
    // Need new claim bits before marking starts.
    ClassLoaderDataGraph::clear_claimed_marks();
  
    {
      GCTraceTime(Debug, gc, phases) tm(&quot;Par Mark&quot;, &amp;_gc_timer);
  
<span class="line-modified">!     ParallelScavengeHeap::ParStrongRootsScope psrs;</span>
<span class="line-modified">! </span>
<span class="line-removed">-     GCTaskQueue* q = GCTaskQueue::create();</span>
<span class="line-removed">- </span>
<span class="line-removed">-     q-&gt;enqueue(new MarkFromRootsTask(MarkFromRootsTask::universe));</span>
<span class="line-removed">-     q-&gt;enqueue(new MarkFromRootsTask(MarkFromRootsTask::jni_handles));</span>
<span class="line-removed">-     // We scan the thread roots in parallel</span>
<span class="line-removed">-     PCAddThreadRootsMarkingTaskClosure cl(q);</span>
<span class="line-removed">-     Threads::java_threads_and_vm_thread_do(&amp;cl);</span>
<span class="line-removed">-     q-&gt;enqueue(new MarkFromRootsTask(MarkFromRootsTask::object_synchronizer));</span>
<span class="line-removed">-     q-&gt;enqueue(new MarkFromRootsTask(MarkFromRootsTask::management));</span>
<span class="line-removed">-     q-&gt;enqueue(new MarkFromRootsTask(MarkFromRootsTask::system_dictionary));</span>
<span class="line-removed">-     q-&gt;enqueue(new MarkFromRootsTask(MarkFromRootsTask::class_loader_data));</span>
<span class="line-removed">-     q-&gt;enqueue(new MarkFromRootsTask(MarkFromRootsTask::jvmti));</span>
<span class="line-removed">-     q-&gt;enqueue(new MarkFromRootsTask(MarkFromRootsTask::code_cache));</span>
<span class="line-removed">- </span>
<span class="line-removed">-     if (active_gc_threads &gt; 1) {</span>
<span class="line-removed">-       for (uint j = 0; j &lt; active_gc_threads; j++) {</span>
<span class="line-removed">-         q-&gt;enqueue(new StealMarkingTask(terminator.terminator()));</span>
<span class="line-removed">-       }</span>
<span class="line-removed">-     }</span>
<span class="line-removed">- </span>
<span class="line-removed">-     gc_task_manager()-&gt;execute_and_wait(q);</span>
    }
  
    // Process reference objects found during marking
    {
      GCTraceTime(Debug, gc, phases) tm(&quot;Reference Processing&quot;, &amp;_gc_timer);
<span class="line-new-header">--- 2069,201 ---</span>
  
    size_policy-&gt;set_bytes_absorbed_from_eden(absorb_size);
    return true;
  }
  
  class PCAddThreadRootsMarkingTaskClosure : public ThreadClosure {
  private:
<span class="line-modified">!   uint _worker_id;</span>
  
  public:
<span class="line-modified">!   PCAddThreadRootsMarkingTaskClosure(uint worker_id) : _worker_id(worker_id) { }</span>
<span class="line-modified">!   void do_thread(Thread* thread) {</span>
<span class="line-modified">!     assert(ParallelScavengeHeap::heap()-&gt;is_gc_active(), &quot;called outside gc&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+     ResourceMark rm;</span>
<span class="line-added">+ </span>
<span class="line-added">+     ParCompactionManager* cm = ParCompactionManager::gc_thread_compaction_manager(_worker_id);</span>
<span class="line-added">+ </span>
<span class="line-added">+     PCMarkAndPushClosure mark_and_push_closure(cm);</span>
<span class="line-added">+     MarkingCodeBlobClosure mark_and_push_in_blobs(&amp;mark_and_push_closure, !CodeBlobToOopClosure::FixRelocations);</span>
<span class="line-added">+ </span>
<span class="line-added">+     thread-&gt;oops_do(&amp;mark_and_push_closure, &amp;mark_and_push_in_blobs);</span>
<span class="line-added">+ </span>
<span class="line-added">+     // Do the real work</span>
<span class="line-added">+     cm-&gt;follow_marking_stacks();</span>
<span class="line-added">+   }</span>
<span class="line-added">+ };</span>
<span class="line-added">+ </span>
<span class="line-added">+ static void mark_from_roots_work(ParallelRootType::Value root_type, uint worker_id) {</span>
<span class="line-added">+   assert(ParallelScavengeHeap::heap()-&gt;is_gc_active(), &quot;called outside gc&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+   ParCompactionManager* cm =</span>
<span class="line-added">+     ParCompactionManager::gc_thread_compaction_manager(worker_id);</span>
<span class="line-added">+   PCMarkAndPushClosure mark_and_push_closure(cm);</span>
<span class="line-added">+ </span>
<span class="line-added">+   switch (root_type) {</span>
<span class="line-added">+     case ParallelRootType::universe:</span>
<span class="line-added">+       Universe::oops_do(&amp;mark_and_push_closure);</span>
<span class="line-added">+       break;</span>
<span class="line-added">+ </span>
<span class="line-added">+     case ParallelRootType::jni_handles:</span>
<span class="line-added">+       JNIHandles::oops_do(&amp;mark_and_push_closure);</span>
<span class="line-added">+       break;</span>
<span class="line-added">+ </span>
<span class="line-added">+     case ParallelRootType::object_synchronizer:</span>
<span class="line-added">+       ObjectSynchronizer::oops_do(&amp;mark_and_push_closure);</span>
<span class="line-added">+       break;</span>
<span class="line-added">+ </span>
<span class="line-added">+     case ParallelRootType::management:</span>
<span class="line-added">+       Management::oops_do(&amp;mark_and_push_closure);</span>
<span class="line-added">+       break;</span>
<span class="line-added">+ </span>
<span class="line-added">+     case ParallelRootType::jvmti:</span>
<span class="line-added">+       JvmtiExport::oops_do(&amp;mark_and_push_closure);</span>
<span class="line-added">+       break;</span>
<span class="line-added">+ </span>
<span class="line-added">+     case ParallelRootType::system_dictionary:</span>
<span class="line-added">+       SystemDictionary::oops_do(&amp;mark_and_push_closure);</span>
<span class="line-added">+       break;</span>
<span class="line-added">+ </span>
<span class="line-added">+     case ParallelRootType::class_loader_data:</span>
<span class="line-added">+       {</span>
<span class="line-added">+         CLDToOopClosure cld_closure(&amp;mark_and_push_closure, ClassLoaderData::_claim_strong);</span>
<span class="line-added">+         ClassLoaderDataGraph::always_strong_cld_do(&amp;cld_closure);</span>
<span class="line-added">+       }</span>
<span class="line-added">+       break;</span>
<span class="line-added">+ </span>
<span class="line-added">+     case ParallelRootType::code_cache:</span>
<span class="line-added">+       // Do not treat nmethods as strong roots for mark/sweep, since we can unload them.</span>
<span class="line-added">+       //ScavengableNMethods::scavengable_nmethods_do(CodeBlobToOopClosure(&amp;mark_and_push_closure));</span>
<span class="line-added">+       AOTLoader::oops_do(&amp;mark_and_push_closure);</span>
<span class="line-added">+       break;</span>
<span class="line-added">+ </span>
<span class="line-added">+     case ParallelRootType::sentinel:</span>
<span class="line-added">+     DEBUG_ONLY(default:) // DEBUG_ONLY hack will create compile error on release builds (-Wswitch) and runtime check on debug builds</span>
<span class="line-added">+       fatal(&quot;Bad enumeration value: %u&quot;, root_type);</span>
<span class="line-added">+       break;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   // Do the real work</span>
<span class="line-added">+   cm-&gt;follow_marking_stacks();</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ static void steal_marking_work(TaskTerminator&amp; terminator, uint worker_id) {</span>
<span class="line-added">+   assert(ParallelScavengeHeap::heap()-&gt;is_gc_active(), &quot;called outside gc&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+   ParCompactionManager* cm =</span>
<span class="line-added">+     ParCompactionManager::gc_thread_compaction_manager(worker_id);</span>
<span class="line-added">+ </span>
<span class="line-added">+   oop obj = NULL;</span>
<span class="line-added">+   ObjArrayTask task;</span>
<span class="line-added">+   do {</span>
<span class="line-added">+     while (ParCompactionManager::steal_objarray(worker_id,  task)) {</span>
<span class="line-added">+       cm-&gt;follow_array((objArrayOop)task.obj(), task.index());</span>
<span class="line-added">+       cm-&gt;follow_marking_stacks();</span>
<span class="line-added">+     }</span>
<span class="line-added">+     while (ParCompactionManager::steal(worker_id, obj)) {</span>
<span class="line-added">+       cm-&gt;follow_contents(obj);</span>
<span class="line-added">+       cm-&gt;follow_marking_stacks();</span>
<span class="line-added">+     }</span>
<span class="line-added">+   } while (!terminator.offer_termination());</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ class MarkFromRootsTask : public AbstractGangTask {</span>
<span class="line-added">+   typedef AbstractRefProcTaskExecutor::ProcessTask ProcessTask;</span>
<span class="line-added">+   StrongRootsScope _strong_roots_scope; // needed for Threads::possibly_parallel_threads_do</span>
<span class="line-added">+   SequentialSubTasksDone _subtasks;</span>
<span class="line-added">+   TaskTerminator _terminator;</span>
<span class="line-added">+   uint _active_workers;</span>
<span class="line-added">+ </span>
<span class="line-added">+ public:</span>
<span class="line-added">+   MarkFromRootsTask(uint active_workers) :</span>
<span class="line-added">+       AbstractGangTask(&quot;MarkFromRootsTask&quot;),</span>
<span class="line-added">+       _strong_roots_scope(active_workers),</span>
<span class="line-added">+       _subtasks(),</span>
<span class="line-added">+       _terminator(active_workers, ParCompactionManager::oop_task_queues()),</span>
<span class="line-added">+       _active_workers(active_workers) {</span>
<span class="line-added">+     _subtasks.set_n_threads(active_workers);</span>
<span class="line-added">+     _subtasks.set_n_tasks(ParallelRootType::sentinel);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   virtual void work(uint worker_id) {</span>
<span class="line-added">+     for (uint task = 0; _subtasks.try_claim_task(task); /*empty*/ ) {</span>
<span class="line-added">+       mark_from_roots_work(static_cast&lt;ParallelRootType::Value&gt;(task), worker_id);</span>
<span class="line-added">+     }</span>
<span class="line-added">+     _subtasks.all_tasks_completed();</span>
<span class="line-added">+ </span>
<span class="line-added">+     PCAddThreadRootsMarkingTaskClosure closure(worker_id);</span>
<span class="line-added">+     Threads::possibly_parallel_threads_do(true /*parallel */, &amp;closure);</span>
<span class="line-added">+ </span>
<span class="line-added">+     if (_active_workers &gt; 1) {</span>
<span class="line-added">+       steal_marking_work(_terminator, worker_id);</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ };</span>
<span class="line-added">+ </span>
<span class="line-added">+ class PCRefProcTask : public AbstractGangTask {</span>
<span class="line-added">+   typedef AbstractRefProcTaskExecutor::ProcessTask ProcessTask;</span>
<span class="line-added">+   ProcessTask&amp; _task;</span>
<span class="line-added">+   uint _ergo_workers;</span>
<span class="line-added">+   TaskTerminator _terminator;</span>
<span class="line-added">+ </span>
<span class="line-added">+ public:</span>
<span class="line-added">+   PCRefProcTask(ProcessTask&amp; task, uint ergo_workers) :</span>
<span class="line-added">+       AbstractGangTask(&quot;PCRefProcTask&quot;),</span>
<span class="line-added">+       _task(task),</span>
<span class="line-added">+       _ergo_workers(ergo_workers),</span>
<span class="line-added">+       _terminator(_ergo_workers, ParCompactionManager::oop_task_queues()) {</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   virtual void work(uint worker_id) {</span>
<span class="line-added">+     ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();</span>
<span class="line-added">+     assert(ParallelScavengeHeap::heap()-&gt;is_gc_active(), &quot;called outside gc&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+     ParCompactionManager* cm =</span>
<span class="line-added">+       ParCompactionManager::gc_thread_compaction_manager(worker_id);</span>
<span class="line-added">+     PCMarkAndPushClosure mark_and_push_closure(cm);</span>
<span class="line-added">+     ParCompactionManager::FollowStackClosure follow_stack_closure(cm);</span>
<span class="line-added">+     _task.work(worker_id, *PSParallelCompact::is_alive_closure(),</span>
<span class="line-added">+                mark_and_push_closure, follow_stack_closure);</span>
<span class="line-added">+ </span>
<span class="line-added">+     steal_marking_work(_terminator, worker_id);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ };</span>
<span class="line-added">+ </span>
<span class="line-added">+ class RefProcTaskExecutor: public AbstractRefProcTaskExecutor {</span>
<span class="line-added">+   void execute(ProcessTask&amp; process_task, uint ergo_workers) {</span>
<span class="line-added">+     assert(ParallelScavengeHeap::heap()-&gt;workers().active_workers() == ergo_workers,</span>
<span class="line-added">+            &quot;Ergonomically chosen workers (%u) must be equal to active workers (%u)&quot;,</span>
<span class="line-added">+            ergo_workers, ParallelScavengeHeap::heap()-&gt;workers().active_workers());</span>
<span class="line-added">+ </span>
<span class="line-added">+     PCRefProcTask task(process_task, ergo_workers);</span>
<span class="line-added">+     ParallelScavengeHeap::heap()-&gt;workers().run_task(&amp;task);</span>
    }
  };
  
  void PSParallelCompact::marking_phase(ParCompactionManager* cm,
                                        bool maximum_heap_compaction,
                                        ParallelOldTracer *gc_tracer) {
    // Recursively traverse all live objects and mark them
    GCTraceTime(Info, gc, phases) tm(&quot;Marking Phase&quot;, &amp;_gc_timer);
  
    ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
<span class="line-modified">!   uint active_gc_threads = ParallelScavengeHeap::heap()-&gt;workers().active_workers();</span>
  
    PCMarkAndPushClosure mark_and_push_closure(cm);
    ParCompactionManager::FollowStackClosure follow_stack_closure(cm);
  
    // Need new claim bits before marking starts.
    ClassLoaderDataGraph::clear_claimed_marks();
  
    {
      GCTraceTime(Debug, gc, phases) tm(&quot;Par Mark&quot;, &amp;_gc_timer);
  
<span class="line-modified">!     MarkFromRootsTask task(active_gc_threads);</span>
<span class="line-modified">!     ParallelScavengeHeap::heap()-&gt;workers().run_task(&amp;task);</span>
    }
  
    // Process reference objects found during marking
    {
      GCTraceTime(Debug, gc, phases) tm(&quot;Reference Processing&quot;, &amp;_gc_timer);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2177,10 ***</span>
<span class="line-new-header">--- 2305,13 ---</span>
      // Unload nmethods.
      CodeCache::do_unloading(is_alive_closure(), purged_class);
  
      // Prune dead klasses from subklass/sibling/implementor lists.
      Klass::clean_weak_klass_links(purged_class);
<span class="line-added">+ </span>
<span class="line-added">+     // Clean JVMCI metadata handles.</span>
<span class="line-added">+     JVMCI_ONLY(JVMCI::do_unloading(purged_class));</span>
    }
  
    _gc_tracer.report_object_count_after_gc(is_alive_closure());
  }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2208,11 ***</span>
    // have been cleared if they pointed to non-surviving objects.)
    WeakProcessor::oops_do(&amp;oop_closure);
  
    CodeBlobToOopClosure adjust_from_blobs(&amp;oop_closure, CodeBlobToOopClosure::FixRelocations);
    CodeCache::blobs_do(&amp;adjust_from_blobs);
<span class="line-modified">!   AOTLoader::oops_do(&amp;oop_closure);</span>
    ref_processor()-&gt;weak_oops_do(&amp;oop_closure);
    // Roots were visited so references into the young gen in roots
    // may have been scanned.  Process them also.
    // Should the reference processor have a span that excludes
    // young gen objects?
<span class="line-new-header">--- 2339,12 ---</span>
    // have been cleared if they pointed to non-surviving objects.)
    WeakProcessor::oops_do(&amp;oop_closure);
  
    CodeBlobToOopClosure adjust_from_blobs(&amp;oop_closure, CodeBlobToOopClosure::FixRelocations);
    CodeCache::blobs_do(&amp;adjust_from_blobs);
<span class="line-modified">!   AOT_ONLY(AOTLoader::oops_do(&amp;oop_closure);)</span>
<span class="line-added">+ </span>
    ref_processor()-&gt;weak_oops_do(&amp;oop_closure);
    // Roots were visited so references into the young gen in roots
    // may have been scanned.  Process them also.
    // Should the reference processor have a span that excludes
    // young gen objects?
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2256,25 ***</span>
      }
      _total_regions++;
    }
  };
  
<span class="line-modified">! void PSParallelCompact::prepare_region_draining_tasks(GCTaskQueue* q,</span>
<span class="line-removed">-                                                       uint parallel_gc_threads)</span>
  {
    GCTraceTime(Trace, gc, phases) tm(&quot;Drain Task Setup&quot;, &amp;_gc_timer);
  
    // Find the threads that are active
<span class="line-modified">!   unsigned int which = 0;</span>
  
    // Find all regions that are available (can be filled immediately) and
    // distribute them to the thread stacks.  The iteration is done in reverse
    // order (high to low) so the regions will be removed in ascending order.
  
    const ParallelCompactData&amp; sd = PSParallelCompact::summary_data();
  
<span class="line-removed">-   which = 0;</span>
    // id + 1 is used to test termination so unsigned  can
    // be used with an old_space_id == 0.
    FillableRegionLogger region_logger;
    for (unsigned int id = to_space_id; id + 1 &gt; old_space_id; --id) {
      SpaceInfo* const space_info = _space_info + id;
<span class="line-new-header">--- 2388,23 ---</span>
      }
      _total_regions++;
    }
  };
  
<span class="line-modified">! void PSParallelCompact::prepare_region_draining_tasks(uint parallel_gc_threads)</span>
  {
    GCTraceTime(Trace, gc, phases) tm(&quot;Drain Task Setup&quot;, &amp;_gc_timer);
  
    // Find the threads that are active
<span class="line-modified">!   uint worker_id = 0;</span>
  
    // Find all regions that are available (can be filled immediately) and
    // distribute them to the thread stacks.  The iteration is done in reverse
    // order (high to low) so the regions will be removed in ascending order.
  
    const ParallelCompactData&amp; sd = PSParallelCompact::summary_data();
  
    // id + 1 is used to test termination so unsigned  can
    // be used with an old_space_id == 0.
    FillableRegionLogger region_logger;
    for (unsigned int id = to_space_id; id + 1 &gt; old_space_id; --id) {
      SpaceInfo* const space_info = _space_info + id;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2285,27 ***</span>
      const size_t end_region =
        sd.addr_to_region_idx(sd.region_align_up(new_top));
  
      for (size_t cur = end_region - 1; cur + 1 &gt; beg_region; --cur) {
        if (sd.region(cur)-&gt;claim_unsafe()) {
<span class="line-modified">!         ParCompactionManager* cm = ParCompactionManager::manager_array(which);</span>
          cm-&gt;region_stack()-&gt;push(cur);
          region_logger.handle(cur);
          // Assign regions to tasks in round-robin fashion.
<span class="line-modified">!         if (++which == parallel_gc_threads) {</span>
<span class="line-modified">!           which = 0;</span>
          }
        }
      }
      region_logger.print_line();
    }
  }
  
  #define PAR_OLD_DENSE_PREFIX_OVER_PARTITIONING 4
  
<span class="line-modified">! void PSParallelCompact::enqueue_dense_prefix_tasks(GCTaskQueue* q,</span>
<span class="line-modified">!                                                     uint parallel_gc_threads) {</span>
    GCTraceTime(Trace, gc, phases) tm(&quot;Dense Prefix Task Setup&quot;, &amp;_gc_timer);
  
    ParallelCompactData&amp; sd = PSParallelCompact::summary_data();
  
    // Iterate over all the spaces adding tasks for updating
<span class="line-new-header">--- 2415,59 ---</span>
      const size_t end_region =
        sd.addr_to_region_idx(sd.region_align_up(new_top));
  
      for (size_t cur = end_region - 1; cur + 1 &gt; beg_region; --cur) {
        if (sd.region(cur)-&gt;claim_unsafe()) {
<span class="line-modified">!         ParCompactionManager* cm = ParCompactionManager::manager_array(worker_id);</span>
<span class="line-added">+         bool result = sd.region(cur)-&gt;mark_normal();</span>
<span class="line-added">+         assert(result, &quot;Must succeed at this point.&quot;);</span>
          cm-&gt;region_stack()-&gt;push(cur);
          region_logger.handle(cur);
          // Assign regions to tasks in round-robin fashion.
<span class="line-modified">!         if (++worker_id == parallel_gc_threads) {</span>
<span class="line-modified">!           worker_id = 0;</span>
          }
        }
      }
      region_logger.print_line();
    }
  }
  
<span class="line-added">+ class TaskQueue : StackObj {</span>
<span class="line-added">+   volatile uint _counter;</span>
<span class="line-added">+   uint _size;</span>
<span class="line-added">+   uint _insert_index;</span>
<span class="line-added">+   PSParallelCompact::UpdateDensePrefixTask* _backing_array;</span>
<span class="line-added">+ public:</span>
<span class="line-added">+   explicit TaskQueue(uint size) : _counter(0), _size(size), _insert_index(0), _backing_array(NULL) {</span>
<span class="line-added">+     _backing_array = NEW_C_HEAP_ARRAY(PSParallelCompact::UpdateDensePrefixTask, _size, mtGC);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   ~TaskQueue() {</span>
<span class="line-added">+     assert(_counter &gt;= _insert_index, &quot;not all queue elements were claimed&quot;);</span>
<span class="line-added">+     FREE_C_HEAP_ARRAY(T, _backing_array);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   void push(const PSParallelCompact::UpdateDensePrefixTask&amp; value) {</span>
<span class="line-added">+     assert(_insert_index &lt; _size, &quot;too small backing array&quot;);</span>
<span class="line-added">+     _backing_array[_insert_index++] = value;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   bool try_claim(PSParallelCompact::UpdateDensePrefixTask&amp; reference) {</span>
<span class="line-added">+     uint claimed = Atomic::fetch_and_add(&amp;_counter, 1u);</span>
<span class="line-added">+     if (claimed &lt; _insert_index) {</span>
<span class="line-added">+       reference = _backing_array[claimed];</span>
<span class="line-added">+       return true;</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       return false;</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ };</span>
<span class="line-added">+ </span>
  #define PAR_OLD_DENSE_PREFIX_OVER_PARTITIONING 4
  
<span class="line-modified">! void PSParallelCompact::enqueue_dense_prefix_tasks(TaskQueue&amp; task_queue,</span>
<span class="line-modified">!                                                    uint parallel_gc_threads) {</span>
    GCTraceTime(Trace, gc, phases) tm(&quot;Dense Prefix Task Setup&quot;, &amp;_gc_timer);
  
    ParallelCompactData&amp; sd = PSParallelCompact::summary_data();
  
    // Iterate over all the spaces adding tasks for updating
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2364,39 ***</span>
            break;
          }
          // region_index_end is not processed
          size_t region_index_end = MIN2(region_index_start + regions_per_thread,
                                         region_index_end_dense_prefix);
<span class="line-modified">!         q-&gt;enqueue(new UpdateDensePrefixTask(SpaceId(space_id),</span>
<span class="line-modified">!                                              region_index_start,</span>
<span class="line-modified">!                                              region_index_end));</span>
          region_index_start = region_index_end;
        }
      }
      // This gets any part of the dense prefix that did not
      // fit evenly.
      if (region_index_start &lt; region_index_end_dense_prefix) {
<span class="line-modified">!       q-&gt;enqueue(new UpdateDensePrefixTask(SpaceId(space_id),</span>
<span class="line-modified">!                                            region_index_start,</span>
<span class="line-modified">!                                            region_index_end_dense_prefix));</span>
      }
    }
  }
  
<span class="line-removed">- void PSParallelCompact::enqueue_region_stealing_tasks(</span>
<span class="line-removed">-                                      GCTaskQueue* q,</span>
<span class="line-removed">-                                      ParallelTaskTerminator* terminator_ptr,</span>
<span class="line-removed">-                                      uint parallel_gc_threads) {</span>
<span class="line-removed">-   GCTraceTime(Trace, gc, phases) tm(&quot;Steal Task Setup&quot;, &amp;_gc_timer);</span>
<span class="line-removed">- </span>
<span class="line-removed">-   // Once a thread has drained it&#39;s stack, it should try to steal regions from</span>
<span class="line-removed">-   // other threads.</span>
<span class="line-removed">-   for (uint j = 0; j &lt; parallel_gc_threads; j++) {</span>
<span class="line-removed">-     q-&gt;enqueue(new CompactionWithStealingTask(terminator_ptr));</span>
<span class="line-removed">-   }</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
  #ifdef ASSERT
  // Write a histogram of the number of times the block table was filled for a
  // region.
  void PSParallelCompact::write_block_fill_histogram()
  {
<span class="line-new-header">--- 2526,26 ---</span>
            break;
          }
          // region_index_end is not processed
          size_t region_index_end = MIN2(region_index_start + regions_per_thread,
                                         region_index_end_dense_prefix);
<span class="line-modified">!         task_queue.push(UpdateDensePrefixTask(SpaceId(space_id),</span>
<span class="line-modified">!                                               region_index_start,</span>
<span class="line-modified">!                                               region_index_end));</span>
          region_index_start = region_index_end;
        }
      }
      // This gets any part of the dense prefix that did not
      // fit evenly.
      if (region_index_start &lt; region_index_end_dense_prefix) {
<span class="line-modified">!       task_queue.push(UpdateDensePrefixTask(SpaceId(space_id),</span>
<span class="line-modified">!                                             region_index_start,</span>
<span class="line-modified">!                                             region_index_end_dense_prefix));</span>
      }
    }
  }
  
  #ifdef ASSERT
  // Write a histogram of the number of times the block table was filled for a
  // region.
  void PSParallelCompact::write_block_fill_histogram()
  {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2435,30 ***</span>
      }
    }
  }
  #endif // #ifdef ASSERT
  
  void PSParallelCompact::compact() {
    GCTraceTime(Info, gc, phases) tm(&quot;Compaction Phase&quot;, &amp;_gc_timer);
  
    ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
    PSOldGen* old_gen = heap-&gt;old_gen();
    old_gen-&gt;start_array()-&gt;reset();
<span class="line-modified">!   uint parallel_gc_threads = heap-&gt;gc_task_manager()-&gt;workers();</span>
<span class="line-removed">-   uint active_gc_threads = heap-&gt;gc_task_manager()-&gt;active_workers();</span>
<span class="line-removed">-   TaskQueueSetSuper* qset = ParCompactionManager::region_array();</span>
<span class="line-removed">-   TaskTerminator terminator(active_gc_threads, qset);</span>
  
<span class="line-modified">!   GCTaskQueue* q = GCTaskQueue::create();</span>
<span class="line-modified">!   prepare_region_draining_tasks(q, active_gc_threads);</span>
<span class="line-modified">!   enqueue_dense_prefix_tasks(q, active_gc_threads);</span>
<span class="line-modified">!   enqueue_region_stealing_tasks(q, terminator.terminator(), active_gc_threads);</span>
  
    {
      GCTraceTime(Trace, gc, phases) tm(&quot;Par Compact&quot;, &amp;_gc_timer);
  
<span class="line-modified">!     gc_task_manager()-&gt;execute_and_wait(q);</span>
  
  #ifdef  ASSERT
      // Verify that all regions have been processed before the deferred updates.
      for (unsigned int id = old_space_id; id &lt; last_space_id; ++id) {
        verify_complete(SpaceId(id));
<span class="line-new-header">--- 2584,96 ---</span>
      }
    }
  }
  #endif // #ifdef ASSERT
  
<span class="line-added">+ static void compaction_with_stealing_work(TaskTerminator* terminator, uint worker_id) {</span>
<span class="line-added">+   assert(ParallelScavengeHeap::heap()-&gt;is_gc_active(), &quot;called outside gc&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+   ParCompactionManager* cm =</span>
<span class="line-added">+     ParCompactionManager::gc_thread_compaction_manager(worker_id);</span>
<span class="line-added">+ </span>
<span class="line-added">+   // Drain the stacks that have been preloaded with regions</span>
<span class="line-added">+   // that are ready to fill.</span>
<span class="line-added">+ </span>
<span class="line-added">+   cm-&gt;drain_region_stacks();</span>
<span class="line-added">+ </span>
<span class="line-added">+   guarantee(cm-&gt;region_stack()-&gt;is_empty(), &quot;Not empty&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+   size_t region_index = 0;</span>
<span class="line-added">+ </span>
<span class="line-added">+   while (true) {</span>
<span class="line-added">+     if (ParCompactionManager::steal(worker_id, region_index)) {</span>
<span class="line-added">+       PSParallelCompact::fill_and_update_region(cm, region_index);</span>
<span class="line-added">+       cm-&gt;drain_region_stacks();</span>
<span class="line-added">+     } else if (PSParallelCompact::steal_unavailable_region(cm, region_index)) {</span>
<span class="line-added">+       // Fill and update an unavailable region with the help of a shadow region</span>
<span class="line-added">+       PSParallelCompact::fill_and_update_shadow_region(cm, region_index);</span>
<span class="line-added">+       cm-&gt;drain_region_stacks();</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       if (terminator-&gt;offer_termination()) {</span>
<span class="line-added">+         break;</span>
<span class="line-added">+       }</span>
<span class="line-added">+       // Go around again.</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+   return;</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ class UpdateDensePrefixAndCompactionTask: public AbstractGangTask {</span>
<span class="line-added">+   typedef AbstractRefProcTaskExecutor::ProcessTask ProcessTask;</span>
<span class="line-added">+   TaskQueue&amp; _tq;</span>
<span class="line-added">+   TaskTerminator _terminator;</span>
<span class="line-added">+   uint _active_workers;</span>
<span class="line-added">+ </span>
<span class="line-added">+ public:</span>
<span class="line-added">+   UpdateDensePrefixAndCompactionTask(TaskQueue&amp; tq, uint active_workers) :</span>
<span class="line-added">+       AbstractGangTask(&quot;UpdateDensePrefixAndCompactionTask&quot;),</span>
<span class="line-added">+       _tq(tq),</span>
<span class="line-added">+       _terminator(active_workers, ParCompactionManager::region_task_queues()),</span>
<span class="line-added">+       _active_workers(active_workers) {</span>
<span class="line-added">+   }</span>
<span class="line-added">+   virtual void work(uint worker_id) {</span>
<span class="line-added">+     ParCompactionManager* cm = ParCompactionManager::gc_thread_compaction_manager(worker_id);</span>
<span class="line-added">+ </span>
<span class="line-added">+     for (PSParallelCompact::UpdateDensePrefixTask task; _tq.try_claim(task); /* empty */) {</span>
<span class="line-added">+       PSParallelCompact::update_and_deadwood_in_dense_prefix(cm,</span>
<span class="line-added">+                                                              task._space_id,</span>
<span class="line-added">+                                                              task._region_index_start,</span>
<span class="line-added">+                                                              task._region_index_end);</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
<span class="line-added">+     // Once a thread has drained it&#39;s stack, it should try to steal regions from</span>
<span class="line-added">+     // other threads.</span>
<span class="line-added">+     compaction_with_stealing_work(&amp;_terminator, worker_id);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ };</span>
<span class="line-added">+ </span>
  void PSParallelCompact::compact() {
    GCTraceTime(Info, gc, phases) tm(&quot;Compaction Phase&quot;, &amp;_gc_timer);
  
    ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
    PSOldGen* old_gen = heap-&gt;old_gen();
    old_gen-&gt;start_array()-&gt;reset();
<span class="line-modified">!   uint active_gc_threads = ParallelScavengeHeap::heap()-&gt;workers().active_workers();</span>
  
<span class="line-modified">!   // for [0..last_space_id)</span>
<span class="line-modified">!   //     for [0..active_gc_threads * PAR_OLD_DENSE_PREFIX_OVER_PARTITIONING)</span>
<span class="line-modified">!   //         push</span>
<span class="line-modified">!   //     push</span>
<span class="line-added">+   //</span>
<span class="line-added">+   // max push count is thus: last_space_id * (active_gc_threads * PAR_OLD_DENSE_PREFIX_OVER_PARTITIONING + 1)</span>
<span class="line-added">+   TaskQueue task_queue(last_space_id * (active_gc_threads * PAR_OLD_DENSE_PREFIX_OVER_PARTITIONING + 1));</span>
<span class="line-added">+   initialize_shadow_regions(active_gc_threads);</span>
<span class="line-added">+   prepare_region_draining_tasks(active_gc_threads);</span>
<span class="line-added">+   enqueue_dense_prefix_tasks(task_queue, active_gc_threads);</span>
  
    {
      GCTraceTime(Trace, gc, phases) tm(&quot;Par Compact&quot;, &amp;_gc_timer);
  
<span class="line-modified">!     UpdateDensePrefixAndCompactionTask task(task_queue, active_gc_threads);</span>
<span class="line-added">+     ParallelScavengeHeap::heap()-&gt;workers().run_task(&amp;task);</span>
  
  #ifdef  ASSERT
      // Verify that all regions have been processed before the deferred updates.
      for (unsigned int id = old_space_id; id &lt; last_space_id; ++id) {
        verify_complete(SpaceId(id));
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2640,11 ***</span>
    assert(count &gt; 0, &quot;sanity&quot;);
  
    ParMarkBitMap* m = mark_bitmap();
    idx_t bits_to_skip = m-&gt;words_to_bits(count);
    idx_t cur_beg = m-&gt;addr_to_bit(beg);
<span class="line-modified">!   const idx_t search_end = BitMap::word_align_up(m-&gt;addr_to_bit(end));</span>
  
    do {
      cur_beg = m-&gt;find_obj_beg(cur_beg, search_end);
      idx_t cur_end = m-&gt;find_obj_end(cur_beg, search_end);
      const size_t obj_bits = cur_end - cur_beg + 1;
<span class="line-new-header">--- 2855,11 ---</span>
    assert(count &gt; 0, &quot;sanity&quot;);
  
    ParMarkBitMap* m = mark_bitmap();
    idx_t bits_to_skip = m-&gt;words_to_bits(count);
    idx_t cur_beg = m-&gt;addr_to_bit(beg);
<span class="line-modified">!   const idx_t search_end = m-&gt;align_range_end(m-&gt;addr_to_bit(end));</span>
  
    do {
      cur_beg = m-&gt;find_obj_beg(cur_beg, search_end);
      idx_t cur_end = m-&gt;find_obj_end(cur_beg, search_end);
      const size_t obj_bits = cur_end - cur_beg + 1;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2753,11 ***</span>
  
    for (RegionData* cur = beg; cur &lt; end; ++cur) {
      assert(cur-&gt;data_size() &gt; 0, &quot;region must have live data&quot;);
      cur-&gt;decrement_destination_count();
      if (cur &lt; enqueue_end &amp;&amp; cur-&gt;available() &amp;&amp; cur-&gt;claim()) {
<span class="line-modified">!       cm-&gt;push_region(sd.region(cur));</span>
      }
    }
  }
  
  size_t PSParallelCompact::next_src_region(MoveAndUpdateClosure&amp; closure,
<span class="line-new-header">--- 2968,21 ---</span>
  
    for (RegionData* cur = beg; cur &lt; end; ++cur) {
      assert(cur-&gt;data_size() &gt; 0, &quot;region must have live data&quot;);
      cur-&gt;decrement_destination_count();
      if (cur &lt; enqueue_end &amp;&amp; cur-&gt;available() &amp;&amp; cur-&gt;claim()) {
<span class="line-modified">!       if (cur-&gt;mark_normal()) {</span>
<span class="line-added">+         cm-&gt;push_region(sd.region(cur));</span>
<span class="line-added">+       } else if (cur-&gt;mark_copied()) {</span>
<span class="line-added">+         // Try to copy the content of the shadow region back to its corresponding</span>
<span class="line-added">+         // heap region if the shadow region is filled. Otherwise, the GC thread</span>
<span class="line-added">+         // fills the shadow region will copy the data back (see</span>
<span class="line-added">+         // MoveAndUpdateShadowClosure::complete_region).</span>
<span class="line-added">+         copy_back(sd.region_to_addr(cur-&gt;shadow_region()), sd.region_to_addr(cur));</span>
<span class="line-added">+         ParCompactionManager::push_shadow_region_mt_safe(cur-&gt;shadow_region());</span>
<span class="line-added">+         cur-&gt;set_completed();</span>
<span class="line-added">+       }</span>
      }
    }
  }
  
  size_t PSParallelCompact::next_src_region(MoveAndUpdateClosure&amp; closure,
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2831,32 ***</span>
  
    assert(false, &quot;no source region was found&quot;);
    return 0;
  }
  
<span class="line-modified">! void PSParallelCompact::fill_region(ParCompactionManager* cm, size_t region_idx)</span>
  {
    typedef ParMarkBitMap::IterationStatus IterationStatus;
<span class="line-removed">-   const size_t RegionSize = ParallelCompactData::RegionSize;</span>
    ParMarkBitMap* const bitmap = mark_bitmap();
    ParallelCompactData&amp; sd = summary_data();
    RegionData* const region_ptr = sd.region(region_idx);
  
<span class="line-removed">-   // Get the items needed to construct the closure.</span>
<span class="line-removed">-   HeapWord* dest_addr = sd.region_to_addr(region_idx);</span>
<span class="line-removed">-   SpaceId dest_space_id = space_id(dest_addr);</span>
<span class="line-removed">-   ObjectStartArray* start_array = _space_info[dest_space_id].start_array();</span>
<span class="line-removed">-   HeapWord* new_top = _space_info[dest_space_id].new_top();</span>
<span class="line-removed">-   assert(dest_addr &lt; new_top, &quot;sanity&quot;);</span>
<span class="line-removed">-   const size_t words = MIN2(pointer_delta(new_top, dest_addr), RegionSize);</span>
<span class="line-removed">- </span>
    // Get the source region and related info.
    size_t src_region_idx = region_ptr-&gt;source_region();
    SpaceId src_space_id = space_id(sd.region_to_addr(src_region_idx));
    HeapWord* src_space_top = _space_info[src_space_id].space()-&gt;top();
  
<span class="line-removed">-   MoveAndUpdateClosure closure(bitmap, cm, start_array, dest_addr, words);</span>
    closure.set_source(first_src_addr(dest_addr, src_space_id, src_region_idx));
  
    // Adjust src_region_idx to prepare for decrementing destination counts (the
    // destination count is not decremented when a region is copied to itself).
    if (src_region_idx == region_idx) {
<span class="line-new-header">--- 3056,23 ---</span>
  
    assert(false, &quot;no source region was found&quot;);
    return 0;
  }
  
<span class="line-modified">! void PSParallelCompact::fill_region(ParCompactionManager* cm, MoveAndUpdateClosure&amp; closure, size_t region_idx)</span>
  {
    typedef ParMarkBitMap::IterationStatus IterationStatus;
    ParMarkBitMap* const bitmap = mark_bitmap();
    ParallelCompactData&amp; sd = summary_data();
    RegionData* const region_ptr = sd.region(region_idx);
  
    // Get the source region and related info.
    size_t src_region_idx = region_ptr-&gt;source_region();
    SpaceId src_space_id = space_id(sd.region_to_addr(src_region_idx));
    HeapWord* src_space_top = _space_info[src_space_id].space()-&gt;top();
<span class="line-added">+   HeapWord* dest_addr = sd.region_to_addr(region_idx);</span>
  
    closure.set_source(first_src_addr(dest_addr, src_space_id, src_region_idx));
  
    // Adjust src_region_idx to prepare for decrementing destination counts (the
    // destination count is not decremented when a region is copied to itself).
    if (src_region_idx == region_idx) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2871,11 ***</span>
      closure.copy_partial_obj();
      if (closure.is_full()) {
        decrement_destination_counts(cm, src_space_id, src_region_idx,
                                     closure.source());
        region_ptr-&gt;set_deferred_obj_addr(NULL);
<span class="line-modified">!       region_ptr-&gt;set_completed();</span>
        return;
      }
  
      HeapWord* const end_addr = sd.region_align_down(closure.source());
      if (sd.region_align_down(old_src_addr) != end_addr) {
<span class="line-new-header">--- 3087,11 ---</span>
      closure.copy_partial_obj();
      if (closure.is_full()) {
        decrement_destination_counts(cm, src_space_id, src_region_idx,
                                     closure.source());
        region_ptr-&gt;set_deferred_obj_addr(NULL);
<span class="line-modified">!       closure.complete_region(cm, dest_addr, region_ptr);</span>
        return;
      }
  
      HeapWord* const end_addr = sd.region_align_down(closure.source());
      if (sd.region_align_down(old_src_addr) != end_addr) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2920,19 ***</span>
        region_ptr-&gt;set_deferred_obj_addr(closure.destination());
        status = closure.copy_until_full(); // copies from closure.source()
  
        decrement_destination_counts(cm, src_space_id, src_region_idx,
                                     closure.source());
<span class="line-modified">!       region_ptr-&gt;set_completed();</span>
        return;
      }
  
      if (status == ParMarkBitMap::full) {
        decrement_destination_counts(cm, src_space_id, src_region_idx,
                                     closure.source());
        region_ptr-&gt;set_deferred_obj_addr(NULL);
<span class="line-modified">!       region_ptr-&gt;set_completed();</span>
        return;
      }
  
      decrement_destination_counts(cm, src_space_id, src_region_idx, end_addr);
  
<span class="line-new-header">--- 3136,19 ---</span>
        region_ptr-&gt;set_deferred_obj_addr(closure.destination());
        status = closure.copy_until_full(); // copies from closure.source()
  
        decrement_destination_counts(cm, src_space_id, src_region_idx,
                                     closure.source());
<span class="line-modified">!       closure.complete_region(cm, dest_addr, region_ptr);</span>
        return;
      }
  
      if (status == ParMarkBitMap::full) {
        decrement_destination_counts(cm, src_space_id, src_region_idx,
                                     closure.source());
        region_ptr-&gt;set_deferred_obj_addr(NULL);
<span class="line-modified">!       closure.complete_region(cm, dest_addr, region_ptr);</span>
        return;
      }
  
      decrement_destination_counts(cm, src_space_id, src_region_idx, end_addr);
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2941,10 ***</span>
<span class="line-new-header">--- 3157,100 ---</span>
      src_region_idx = next_src_region(closure, src_space_id, src_space_top,
                                       end_addr);
    } while (true);
  }
  
<span class="line-added">+ void PSParallelCompact::fill_and_update_region(ParCompactionManager* cm, size_t region_idx)</span>
<span class="line-added">+ {</span>
<span class="line-added">+   MoveAndUpdateClosure cl(mark_bitmap(), cm, region_idx);</span>
<span class="line-added">+   fill_region(cm, cl, region_idx);</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ void PSParallelCompact::fill_and_update_shadow_region(ParCompactionManager* cm, size_t region_idx)</span>
<span class="line-added">+ {</span>
<span class="line-added">+   // Get a shadow region first</span>
<span class="line-added">+   ParallelCompactData&amp; sd = summary_data();</span>
<span class="line-added">+   RegionData* const region_ptr = sd.region(region_idx);</span>
<span class="line-added">+   size_t shadow_region = ParCompactionManager::pop_shadow_region_mt_safe(region_ptr);</span>
<span class="line-added">+   // The InvalidShadow return value indicates the corresponding heap region is available,</span>
<span class="line-added">+   // so use MoveAndUpdateClosure to fill the normal region. Otherwise, use</span>
<span class="line-added">+   // MoveAndUpdateShadowClosure to fill the acquired shadow region.</span>
<span class="line-added">+   if (shadow_region == ParCompactionManager::InvalidShadow) {</span>
<span class="line-added">+     MoveAndUpdateClosure cl(mark_bitmap(), cm, region_idx);</span>
<span class="line-added">+     region_ptr-&gt;shadow_to_normal();</span>
<span class="line-added">+     return fill_region(cm, cl, region_idx);</span>
<span class="line-added">+   } else {</span>
<span class="line-added">+     MoveAndUpdateShadowClosure cl(mark_bitmap(), cm, region_idx, shadow_region);</span>
<span class="line-added">+     return fill_region(cm, cl, region_idx);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ void PSParallelCompact::copy_back(HeapWord *shadow_addr, HeapWord *region_addr)</span>
<span class="line-added">+ {</span>
<span class="line-added">+   Copy::aligned_conjoint_words(shadow_addr, region_addr, _summary_data.RegionSize);</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ bool PSParallelCompact::steal_unavailable_region(ParCompactionManager* cm, size_t &amp;region_idx)</span>
<span class="line-added">+ {</span>
<span class="line-added">+   size_t next = cm-&gt;next_shadow_region();</span>
<span class="line-added">+   ParallelCompactData&amp; sd = summary_data();</span>
<span class="line-added">+   size_t old_new_top = sd.addr_to_region_idx(_space_info[old_space_id].new_top());</span>
<span class="line-added">+   uint active_gc_threads = ParallelScavengeHeap::heap()-&gt;workers().active_workers();</span>
<span class="line-added">+ </span>
<span class="line-added">+   while (next &lt; old_new_top) {</span>
<span class="line-added">+     if (sd.region(next)-&gt;mark_shadow()) {</span>
<span class="line-added">+       region_idx = next;</span>
<span class="line-added">+       return true;</span>
<span class="line-added">+     }</span>
<span class="line-added">+     next = cm-&gt;move_next_shadow_region_by(active_gc_threads);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   return false;</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ // The shadow region is an optimization to address region dependencies in full GC. The basic</span>
<span class="line-added">+ // idea is making more regions available by temporally storing their live objects in empty</span>
<span class="line-added">+ // shadow regions to resolve dependencies between them and the destination regions. Therefore,</span>
<span class="line-added">+ // GC threads need not wait destination regions to be available before processing sources.</span>
<span class="line-added">+ //</span>
<span class="line-added">+ // A typical workflow would be:</span>
<span class="line-added">+ // After draining its own stack and failing to steal from others, a GC worker would pick an</span>
<span class="line-added">+ // unavailable region (destination count &gt; 0) and get a shadow region. Then the worker fills</span>
<span class="line-added">+ // the shadow region by copying live objects from source regions of the unavailable one. Once</span>
<span class="line-added">+ // the unavailable region becomes available, the data in the shadow region will be copied back.</span>
<span class="line-added">+ // Shadow regions are empty regions in the to-space and regions between top and end of other spaces.</span>
<span class="line-added">+ //</span>
<span class="line-added">+ // For more details, please refer to §4.2 of the VEE&#39;19 paper:</span>
<span class="line-added">+ // Haoyu Li, Mingyu Wu, Binyu Zang, and Haibo Chen. 2019. ScissorGC: scalable and efficient</span>
<span class="line-added">+ // compaction for Java full garbage collection. In Proceedings of the 15th ACM SIGPLAN/SIGOPS</span>
<span class="line-added">+ // International Conference on Virtual Execution Environments (VEE 2019). ACM, New York, NY, USA,</span>
<span class="line-added">+ // 108-121. DOI: https://doi.org/10.1145/3313808.3313820</span>
<span class="line-added">+ void PSParallelCompact::initialize_shadow_regions(uint parallel_gc_threads)</span>
<span class="line-added">+ {</span>
<span class="line-added">+   const ParallelCompactData&amp; sd = PSParallelCompact::summary_data();</span>
<span class="line-added">+ </span>
<span class="line-added">+   for (unsigned int id = old_space_id; id &lt; last_space_id; ++id) {</span>
<span class="line-added">+     SpaceInfo* const space_info = _space_info + id;</span>
<span class="line-added">+     MutableSpace* const space = space_info-&gt;space();</span>
<span class="line-added">+ </span>
<span class="line-added">+     const size_t beg_region =</span>
<span class="line-added">+       sd.addr_to_region_idx(sd.region_align_up(MAX2(space_info-&gt;new_top(), space-&gt;top())));</span>
<span class="line-added">+     const size_t end_region =</span>
<span class="line-added">+       sd.addr_to_region_idx(sd.region_align_down(space-&gt;end()));</span>
<span class="line-added">+ </span>
<span class="line-added">+     for (size_t cur = beg_region; cur &lt; end_region; ++cur) {</span>
<span class="line-added">+       ParCompactionManager::push_shadow_region(cur);</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   size_t beg_region = sd.addr_to_region_idx(_space_info[old_space_id].dense_prefix());</span>
<span class="line-added">+   for (uint i = 0; i &lt; parallel_gc_threads; i++) {</span>
<span class="line-added">+     ParCompactionManager *cm = ParCompactionManager::manager_array(i);</span>
<span class="line-added">+     cm-&gt;set_next_shadow_region(beg_region + i);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  void PSParallelCompact::fill_blocks(size_t region_idx)
  {
    // Fill in the block table elements for the specified region.  Each block
    // table element holds the number of live words in the region that are to the
    // left of the first object that starts in the block.  Thus only blocks in
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2992,50 ***</span>
        return;
      }
    }
  }
  
<span class="line-removed">- void</span>
<span class="line-removed">- PSParallelCompact::move_and_update(ParCompactionManager* cm, SpaceId space_id) {</span>
<span class="line-removed">-   const MutableSpace* sp = space(space_id);</span>
<span class="line-removed">-   if (sp-&gt;is_empty()) {</span>
<span class="line-removed">-     return;</span>
<span class="line-removed">-   }</span>
<span class="line-removed">- </span>
<span class="line-removed">-   ParallelCompactData&amp; sd = PSParallelCompact::summary_data();</span>
<span class="line-removed">-   ParMarkBitMap* const bitmap = mark_bitmap();</span>
<span class="line-removed">-   HeapWord* const dp_addr = dense_prefix(space_id);</span>
<span class="line-removed">-   HeapWord* beg_addr = sp-&gt;bottom();</span>
<span class="line-removed">-   HeapWord* end_addr = sp-&gt;top();</span>
<span class="line-removed">- </span>
<span class="line-removed">-   assert(beg_addr &lt;= dp_addr &amp;&amp; dp_addr &lt;= end_addr, &quot;bad dense prefix&quot;);</span>
<span class="line-removed">- </span>
<span class="line-removed">-   const size_t beg_region = sd.addr_to_region_idx(beg_addr);</span>
<span class="line-removed">-   const size_t dp_region = sd.addr_to_region_idx(dp_addr);</span>
<span class="line-removed">-   if (beg_region &lt; dp_region) {</span>
<span class="line-removed">-     update_and_deadwood_in_dense_prefix(cm, space_id, beg_region, dp_region);</span>
<span class="line-removed">-   }</span>
<span class="line-removed">- </span>
<span class="line-removed">-   // The destination of the first live object that starts in the region is one</span>
<span class="line-removed">-   // past the end of the partial object entering the region (if any).</span>
<span class="line-removed">-   HeapWord* const dest_addr = sd.partial_obj_end(dp_region);</span>
<span class="line-removed">-   HeapWord* const new_top = _space_info[space_id].new_top();</span>
<span class="line-removed">-   assert(new_top &gt;= dest_addr, &quot;bad new_top value&quot;);</span>
<span class="line-removed">-   const size_t words = pointer_delta(new_top, dest_addr);</span>
<span class="line-removed">- </span>
<span class="line-removed">-   if (words &gt; 0) {</span>
<span class="line-removed">-     ObjectStartArray* start_array = _space_info[space_id].start_array();</span>
<span class="line-removed">-     MoveAndUpdateClosure closure(bitmap, cm, start_array, dest_addr, words);</span>
<span class="line-removed">- </span>
<span class="line-removed">-     ParMarkBitMap::IterationStatus status;</span>
<span class="line-removed">-     status = bitmap-&gt;iterate(&amp;closure, dest_addr, end_addr);</span>
<span class="line-removed">-     assert(status == ParMarkBitMap::full, &quot;iteration not complete&quot;);</span>
<span class="line-removed">-     assert(bitmap-&gt;find_obj_beg(closure.source(), end_addr) == end_addr,</span>
<span class="line-removed">-            &quot;live objects skipped because closure is full&quot;);</span>
<span class="line-removed">-   }</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
  jlong PSParallelCompact::millis_since_last_gc() {
    // We need a monotonically non-decreasing time in ms but
    // os::javaTimeMillis() does not guarantee monotonicity.
    jlong now = os::javaTimeNanos() / NANOSECS_PER_MILLISEC;
    jlong ret_val = now - _time_of_last_gc;
<span class="line-new-header">--- 3298,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3053,13 ***</span>
    _time_of_last_gc = os::javaTimeNanos() / NANOSECS_PER_MILLISEC;
  }
  
  ParMarkBitMap::IterationStatus MoveAndUpdateClosure::copy_until_full()
  {
<span class="line-modified">!   if (source() != destination()) {</span>
      DEBUG_ONLY(PSParallelCompact::check_new_location(source(), destination());)
<span class="line-modified">!     Copy::aligned_conjoint_words(source(), destination(), words_remaining());</span>
    }
    update_state(words_remaining());
    assert(is_full(), &quot;sanity&quot;);
    return ParMarkBitMap::full;
  }
<span class="line-new-header">--- 3319,13 ---</span>
    _time_of_last_gc = os::javaTimeNanos() / NANOSECS_PER_MILLISEC;
  }
  
  ParMarkBitMap::IterationStatus MoveAndUpdateClosure::copy_until_full()
  {
<span class="line-modified">!   if (source() != copy_destination()) {</span>
      DEBUG_ONLY(PSParallelCompact::check_new_location(source(), destination());)
<span class="line-modified">!     Copy::aligned_conjoint_words(source(), copy_destination(), words_remaining());</span>
    }
    update_state(words_remaining());
    assert(is_full(), &quot;sanity&quot;);
    return ParMarkBitMap::full;
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3074,17 ***</span>
      words = bitmap()-&gt;obj_size(source(), end_addr);
    }
  
    // This test is necessary; if omitted, the pointer updates to a partial object
    // that crosses the dense prefix boundary could be overwritten.
<span class="line-modified">!   if (source() != destination()) {</span>
      DEBUG_ONLY(PSParallelCompact::check_new_location(source(), destination());)
<span class="line-modified">!     Copy::aligned_conjoint_words(source(), destination(), words);</span>
    }
    update_state(words);
  }
  
  ParMarkBitMapClosure::IterationStatus
  MoveAndUpdateClosure::do_addr(HeapWord* addr, size_t words) {
    assert(destination() != NULL, &quot;sanity&quot;);
    assert(bitmap()-&gt;obj_size(addr) == words, &quot;bad size&quot;);
  
<span class="line-new-header">--- 3340,23 ---</span>
      words = bitmap()-&gt;obj_size(source(), end_addr);
    }
  
    // This test is necessary; if omitted, the pointer updates to a partial object
    // that crosses the dense prefix boundary could be overwritten.
<span class="line-modified">!   if (source() != copy_destination()) {</span>
      DEBUG_ONLY(PSParallelCompact::check_new_location(source(), destination());)
<span class="line-modified">!     Copy::aligned_conjoint_words(source(), copy_destination(), words);</span>
    }
    update_state(words);
  }
  
<span class="line-added">+ void MoveAndUpdateClosure::complete_region(ParCompactionManager *cm, HeapWord *dest_addr,</span>
<span class="line-added">+                                            PSParallelCompact::RegionData *region_ptr) {</span>
<span class="line-added">+   assert(region_ptr-&gt;shadow_state() == ParallelCompactData::RegionData::NormalRegion, &quot;Region should be finished&quot;);</span>
<span class="line-added">+   region_ptr-&gt;set_completed();</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  ParMarkBitMapClosure::IterationStatus
  MoveAndUpdateClosure::do_addr(HeapWord* addr, size_t words) {
    assert(destination() != NULL, &quot;sanity&quot;);
    assert(bitmap()-&gt;obj_size(addr) == words, &quot;bad size&quot;);
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3099,24 ***</span>
    // The start_array must be updated even if the object is not moving.
    if (_start_array != NULL) {
      _start_array-&gt;allocate_block(destination());
    }
  
<span class="line-modified">!   if (destination() != source()) {</span>
      DEBUG_ONLY(PSParallelCompact::check_new_location(source(), destination());)
<span class="line-modified">!     Copy::aligned_conjoint_words(source(), destination(), words);</span>
    }
  
<span class="line-modified">!   oop moved_oop = (oop) destination();</span>
    compaction_manager()-&gt;update_contents(moved_oop);
    assert(oopDesc::is_oop_or_null(moved_oop), &quot;Expected an oop or NULL at &quot; PTR_FORMAT, p2i(moved_oop));
  
    update_state(words);
<span class="line-modified">!   assert(destination() == (HeapWord*)moved_oop + moved_oop-&gt;size(), &quot;sanity&quot;);</span>
    return is_full() ? ParMarkBitMap::full : ParMarkBitMap::incomplete;
  }
  
  UpdateOnlyClosure::UpdateOnlyClosure(ParMarkBitMap* mbm,
                                       ParCompactionManager* cm,
                                       PSParallelCompact::SpaceId space_id) :
    ParMarkBitMapClosure(mbm, cm),
    _space_id(space_id),
<span class="line-new-header">--- 3371,43 ---</span>
    // The start_array must be updated even if the object is not moving.
    if (_start_array != NULL) {
      _start_array-&gt;allocate_block(destination());
    }
  
<span class="line-modified">!   if (copy_destination() != source()) {</span>
      DEBUG_ONLY(PSParallelCompact::check_new_location(source(), destination());)
<span class="line-modified">!     Copy::aligned_conjoint_words(source(), copy_destination(), words);</span>
    }
  
<span class="line-modified">!   oop moved_oop = (oop) copy_destination();</span>
    compaction_manager()-&gt;update_contents(moved_oop);
    assert(oopDesc::is_oop_or_null(moved_oop), &quot;Expected an oop or NULL at &quot; PTR_FORMAT, p2i(moved_oop));
  
    update_state(words);
<span class="line-modified">!   assert(copy_destination() == cast_from_oop&lt;HeapWord*&gt;(moved_oop) + moved_oop-&gt;size(), &quot;sanity&quot;);</span>
    return is_full() ? ParMarkBitMap::full : ParMarkBitMap::incomplete;
  }
  
<span class="line-added">+ void MoveAndUpdateShadowClosure::complete_region(ParCompactionManager *cm, HeapWord *dest_addr,</span>
<span class="line-added">+                                                  PSParallelCompact::RegionData *region_ptr) {</span>
<span class="line-added">+   assert(region_ptr-&gt;shadow_state() == ParallelCompactData::RegionData::ShadowRegion, &quot;Region should be shadow&quot;);</span>
<span class="line-added">+   // Record the shadow region index</span>
<span class="line-added">+   region_ptr-&gt;set_shadow_region(_shadow);</span>
<span class="line-added">+   // Mark the shadow region as filled to indicate the data is ready to be</span>
<span class="line-added">+   // copied back</span>
<span class="line-added">+   region_ptr-&gt;mark_filled();</span>
<span class="line-added">+   // Try to copy the content of the shadow region back to its corresponding</span>
<span class="line-added">+   // heap region if available; the GC thread that decreases the destination</span>
<span class="line-added">+   // count to zero will do the copying otherwise (see</span>
<span class="line-added">+   // PSParallelCompact::decrement_destination_counts).</span>
<span class="line-added">+   if (((region_ptr-&gt;available() &amp;&amp; region_ptr-&gt;claim()) || region_ptr-&gt;claimed()) &amp;&amp; region_ptr-&gt;mark_copied()) {</span>
<span class="line-added">+     region_ptr-&gt;set_completed();</span>
<span class="line-added">+     PSParallelCompact::copy_back(PSParallelCompact::summary_data().region_to_addr(_shadow), dest_addr);</span>
<span class="line-added">+     ParCompactionManager::push_shadow_region_mt_safe(_shadow);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  UpdateOnlyClosure::UpdateOnlyClosure(ParMarkBitMap* mbm,
                                       ParCompactionManager* cm,
                                       PSParallelCompact::SpaceId space_id) :
    ParMarkBitMapClosure(mbm, cm),
    _space_id(space_id),
</pre>
<center><a href="psOldGen.hpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="psParallelCompact.hpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>