diff a/src/hotspot/share/gc/parallel/asPSOldGen.cpp b/src/hotspot/share/gc/parallel/asPSOldGen.cpp
--- a/src/hotspot/share/gc/parallel/asPSOldGen.cpp
+++ b/src/hotspot/share/gc/parallel/asPSOldGen.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2003, 2015, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -24,12 +24,12 @@
 
 #include "precompiled.hpp"
 #include "gc/parallel/asPSOldGen.hpp"
 #include "gc/parallel/parallelScavengeHeap.hpp"
 #include "gc/parallel/psAdaptiveSizePolicy.hpp"
-#include "gc/parallel/psMarkSweepDecorator.hpp"
 #include "gc/shared/cardTableBarrierSet.hpp"
+#include "gc/shared/genArguments.hpp"
 #include "oops/oop.inline.hpp"
 #include "runtime/java.hpp"
 #include "utilities/align.hpp"
 
 // Whereas PSOldGen takes the maximum size of the generation
@@ -88,28 +88,26 @@
 
 size_t ASPSOldGen::available_for_expansion() {
   assert(virtual_space()->is_aligned(gen_size_limit()), "not aligned");
   assert(gen_size_limit() >= virtual_space()->committed_size(), "bad gen size");
 
-  ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
   size_t result =  gen_size_limit() - virtual_space()->committed_size();
-  size_t result_aligned = align_down(result, heap->generation_alignment());
+  size_t result_aligned = align_down(result, GenAlignment);
   return result_aligned;
 }
 
 size_t ASPSOldGen::available_for_contraction() {
   size_t uncommitted_bytes = virtual_space()->uncommitted_size();
   if (uncommitted_bytes != 0) {
     return uncommitted_bytes;
   }
 
   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
-  const size_t gen_alignment = heap->generation_alignment();
   PSAdaptiveSizePolicy* policy = heap->size_policy();
   const size_t working_size =
     used_in_bytes() + (size_t) policy->avg_promoted()->padded_average();
-  const size_t working_aligned = align_up(working_size, gen_alignment);
+  const size_t working_aligned = align_up(working_size, GenAlignment);
   const size_t working_or_min = MAX2(working_aligned, min_gen_size());
   if (working_or_min > reserved().byte_size()) {
     // If the used or minimum gen size (aligned up) is greater
     // than the total reserved size, then the space available
     // for contraction should (after proper alignment) be 0
@@ -123,11 +121,11 @@
   // "decrement" fraction is conservative because its intent is to
   // only reduce the footprint.
 
   size_t result = policy->promo_increment_aligned_down(max_contraction);
   // Also adjust for inter-generational alignment
-  size_t result_aligned = align_down(result, gen_alignment);
+  size_t result_aligned = align_down(result, GenAlignment);
 
   Log(gc, ergo) log;
   if (log.is_trace()) {
     size_t working_promoted = (size_t) policy->avg_promoted()->padded_average();
     size_t promo_increment = policy->promo_increment(max_contraction);
@@ -136,11 +134,11 @@
     log.trace(" padded promoted " SIZE_FORMAT " K / " SIZE_FORMAT_HEX, working_promoted/K, working_promoted);
     log.trace(" used " SIZE_FORMAT " K / " SIZE_FORMAT_HEX, used_in_bytes()/K, used_in_bytes());
     log.trace(" min_gen_size() " SIZE_FORMAT " K / " SIZE_FORMAT_HEX, min_gen_size()/K, min_gen_size());
     log.trace(" max_contraction " SIZE_FORMAT " K / " SIZE_FORMAT_HEX, max_contraction/K, max_contraction);
     log.trace("    without alignment " SIZE_FORMAT " K / " SIZE_FORMAT_HEX, promo_increment/K, promo_increment);
-    log.trace(" alignment " SIZE_FORMAT_HEX, gen_alignment);
+    log.trace(" alignment " SIZE_FORMAT_HEX, GenAlignment);
   }
 
   assert(result_aligned <= max_contraction, "arithmetic is wrong");
   return result_aligned;
 }
