<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/gc/parallel/mutableSpace.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2001, 2018, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;gc/parallel/mutableSpace.hpp&quot;
 27 #include &quot;gc/shared/spaceDecorator.hpp&quot;
 28 #include &quot;memory/iterator.inline.hpp&quot;
 29 #include &quot;oops/oop.inline.hpp&quot;
 30 #include &quot;runtime/atomic.hpp&quot;
 31 #include &quot;runtime/safepoint.hpp&quot;
 32 #include &quot;runtime/thread.hpp&quot;
 33 #include &quot;utilities/align.hpp&quot;
 34 #include &quot;utilities/macros.hpp&quot;
 35 
 36 MutableSpace::MutableSpace(size_t alignment): ImmutableSpace(), _alignment(alignment), _top(NULL) {
 37   assert(MutableSpace::alignment() % os::vm_page_size() == 0,
 38          &quot;Space should be aligned&quot;);
 39   _mangler = new MutableSpaceMangler(this);
 40 }
 41 
 42 MutableSpace::~MutableSpace() {
 43   delete _mangler;
 44 }
 45 
 46 void MutableSpace::numa_setup_pages(MemRegion mr, bool clear_space) {
 47   if (!mr.is_empty()) {
 48     size_t page_size = UseLargePages ? alignment() : os::vm_page_size();
 49     HeapWord *start = align_up(mr.start(), page_size);
 50     HeapWord *end =   align_down(mr.end(), page_size);
 51     if (end &gt; start) {
 52       size_t size = pointer_delta(end, start, sizeof(char));
 53       if (clear_space) {
 54         // Prefer page reallocation to migration.
 55         os::free_memory((char*)start, size, page_size);
 56       }
 57       os::numa_make_global((char*)start, size);
 58     }
 59   }
 60 }
 61 
 62 void MutableSpace::pretouch_pages(MemRegion mr) {
 63   os::pretouch_memory(mr.start(), mr.end());
 64 }
 65 
 66 void MutableSpace::initialize(MemRegion mr,
 67                               bool clear_space,
 68                               bool mangle_space,
 69                               bool setup_pages) {
 70 
 71   assert(Universe::on_page_boundary(mr.start()) &amp;&amp; Universe::on_page_boundary(mr.end()),
 72          &quot;invalid space boundaries&quot;);
 73 
 74   if (setup_pages &amp;&amp; (UseNUMA || AlwaysPreTouch)) {
 75     // The space may move left and right or expand/shrink.
 76     // We&#39;d like to enforce the desired page placement.
 77     MemRegion head, tail;
 78     if (last_setup_region().is_empty()) {
 79       // If it&#39;s the first initialization don&#39;t limit the amount of work.
 80       head = mr;
 81       tail = MemRegion(mr.end(), mr.end());
 82     } else {
 83       // Is there an intersection with the address space?
 84       MemRegion intersection = last_setup_region().intersection(mr);
 85       if (intersection.is_empty()) {
 86         intersection = MemRegion(mr.end(), mr.end());
 87       }
 88       // All the sizes below are in words.
 89       size_t head_size = 0, tail_size = 0;
 90       if (mr.start() &lt;= intersection.start()) {
 91         head_size = pointer_delta(intersection.start(), mr.start());
 92       }
 93       if(intersection.end() &lt;= mr.end()) {
 94         tail_size = pointer_delta(mr.end(), intersection.end());
 95       }
 96       // Limit the amount of page manipulation if necessary.
 97       if (NUMASpaceResizeRate &gt; 0 &amp;&amp; !AlwaysPreTouch) {
 98         const size_t change_size = head_size + tail_size;
 99         const float setup_rate_words = NUMASpaceResizeRate &gt;&gt; LogBytesPerWord;
100         head_size = MIN2((size_t)(setup_rate_words * head_size / change_size),
101                          head_size);
102         tail_size = MIN2((size_t)(setup_rate_words * tail_size / change_size),
103                          tail_size);
104       }
105       head = MemRegion(intersection.start() - head_size, intersection.start());
106       tail = MemRegion(intersection.end(), intersection.end() + tail_size);
107     }
108     assert(mr.contains(head) &amp;&amp; mr.contains(tail), &quot;Sanity&quot;);
109 
110     if (UseNUMA) {
111       numa_setup_pages(head, clear_space);
112       numa_setup_pages(tail, clear_space);
113     }
114 
115     if (AlwaysPreTouch) {
116       pretouch_pages(head);
117       pretouch_pages(tail);
118     }
119 
120     // Remember where we stopped so that we can continue later.
121     set_last_setup_region(MemRegion(head.start(), tail.end()));
122   }
123 
124   set_bottom(mr.start());
125   set_end(mr.end());
126 
127   if (clear_space) {
128     clear(mangle_space);
129   }
130 }
131 
132 void MutableSpace::clear(bool mangle_space) {
133   set_top(bottom());
134   if (ZapUnusedHeapArea &amp;&amp; mangle_space) {
135     mangle_unused_area();
136   }
137 }
138 
139 #ifndef PRODUCT
140 void MutableSpace::check_mangled_unused_area(HeapWord* limit) {
141   mangler()-&gt;check_mangled_unused_area(limit);
142 }
143 
144 void MutableSpace::check_mangled_unused_area_complete() {
145   mangler()-&gt;check_mangled_unused_area_complete();
146 }
147 
148 // Mangle only the unused space that has not previously
149 // been mangled and that has not been allocated since being
150 // mangled.
151 void MutableSpace::mangle_unused_area() {
152   mangler()-&gt;mangle_unused_area();
153 }
154 
155 void MutableSpace::mangle_unused_area_complete() {
156   mangler()-&gt;mangle_unused_area_complete();
157 }
158 
159 void MutableSpace::mangle_region(MemRegion mr) {
160   SpaceMangler::mangle_region(mr);
161 }
162 
163 void MutableSpace::set_top_for_allocations(HeapWord* v) {
164   mangler()-&gt;set_top_for_allocations(v);
165 }
166 
167 void MutableSpace::set_top_for_allocations() {
168   mangler()-&gt;set_top_for_allocations(top());
169 }
170 #endif
171 
172 // This version requires locking. */
173 HeapWord* MutableSpace::allocate(size_t size) {
174   assert(Heap_lock-&gt;owned_by_self() ||
175          (SafepointSynchronize::is_at_safepoint() &amp;&amp;
176           Thread::current()-&gt;is_VM_thread()),
177          &quot;not locked&quot;);
178   HeapWord* obj = top();
179   if (pointer_delta(end(), obj) &gt;= size) {
180     HeapWord* new_top = obj + size;
181     set_top(new_top);
182     assert(is_object_aligned(obj) &amp;&amp; is_object_aligned(new_top),
183            &quot;checking alignment&quot;);
184     return obj;
185   } else {
186     return NULL;
187   }
188 }
189 
190 // This version is lock-free.
191 HeapWord* MutableSpace::cas_allocate(size_t size) {
192   do {
193     HeapWord* obj = top();
194     if (pointer_delta(end(), obj) &gt;= size) {
195       HeapWord* new_top = obj + size;
196       HeapWord* result = Atomic::cmpxchg(new_top, top_addr(), obj);
197       // result can be one of two:
198       //  the old top value: the exchange succeeded
199       //  otherwise: the new value of the top is returned.
200       if (result != obj) {
201         continue; // another thread beat us to the allocation, try again
202       }
203       assert(is_object_aligned(obj) &amp;&amp; is_object_aligned(new_top),
204              &quot;checking alignment&quot;);
205       return obj;
206     } else {
207       return NULL;
208     }
209   } while (true);
210 }
211 
212 // Try to deallocate previous allocation. Returns true upon success.
213 bool MutableSpace::cas_deallocate(HeapWord *obj, size_t size) {
214   HeapWord* expected_top = obj + size;
215   return Atomic::cmpxchg(obj, top_addr(), expected_top) == expected_top;
216 }
217 
218 void MutableSpace::oop_iterate(OopIterateClosure* cl) {
219   HeapWord* obj_addr = bottom();
220   HeapWord* t = top();
221   // Could call objects iterate, but this is easier.
222   while (obj_addr &lt; t) {
223     obj_addr += oop(obj_addr)-&gt;oop_iterate_size(cl);
224   }
225 }
226 
227 void MutableSpace::object_iterate(ObjectClosure* cl) {
228   HeapWord* p = bottom();
229   while (p &lt; top()) {
230     cl-&gt;do_object(oop(p));
231     p += oop(p)-&gt;size();
232   }
233 }
234 
235 void MutableSpace::print_short() const { print_short_on(tty); }
236 void MutableSpace::print_short_on( outputStream* st) const {
237   st-&gt;print(&quot; space &quot; SIZE_FORMAT &quot;K, %d%% used&quot;, capacity_in_bytes() / K,
238             (int) ((double) used_in_bytes() * 100 / capacity_in_bytes()));
239 }
240 
241 void MutableSpace::print() const { print_on(tty); }
242 void MutableSpace::print_on(outputStream* st) const {
243   MutableSpace::print_short_on(st);
244   st-&gt;print_cr(&quot; [&quot; INTPTR_FORMAT &quot;,&quot; INTPTR_FORMAT &quot;,&quot; INTPTR_FORMAT &quot;)&quot;,
245                  p2i(bottom()), p2i(top()), p2i(end()));
246 }
247 
248 void MutableSpace::verify() {
249   HeapWord* p = bottom();
250   HeapWord* t = top();
251   HeapWord* prev_p = NULL;
252   while (p &lt; t) {
253     oopDesc::verify(oop(p));
254     prev_p = p;
255     p += oop(p)-&gt;size();
256   }
257   guarantee(p == top(), &quot;end of last object must match end of space&quot;);
258 }
    </pre>
  </body>
</html>