<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff src/hotspot/share/gc/parallel/psParallelCompact.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="psParallelCompact.cpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="psPromotionLAB.cpp.udiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/parallel/psParallelCompact.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -1,7 +1,7 @@</span>
  /*
<span class="udiff-line-modified-removed">-  * Copyright (c) 2005, 2019, Oracle and/or its affiliates. All rights reserved.</span>
<span class="udiff-line-modified-added">+  * Copyright (c) 2005, 2020, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -30,21 +30,19 @@</span>
  #include &quot;gc/parallel/parMarkBitMap.hpp&quot;
  #include &quot;gc/parallel/parallelScavengeHeap.hpp&quot;
  #include &quot;gc/shared/collectedHeap.hpp&quot;
  #include &quot;gc/shared/collectorCounters.hpp&quot;
  #include &quot;oops/oop.hpp&quot;
<span class="udiff-line-added">+ #include &quot;runtime/atomic.hpp&quot;</span>
<span class="udiff-line-added">+ #include &quot;runtime/orderAccess.hpp&quot;</span>
  
  class ParallelScavengeHeap;
  class PSAdaptiveSizePolicy;
  class PSYoungGen;
  class PSOldGen;
  class ParCompactionManager;
<span class="udiff-line-removed">- class ParallelTaskTerminator;</span>
  class PSParallelCompact;
<span class="udiff-line-removed">- class GCTaskManager;</span>
<span class="udiff-line-removed">- class GCTaskQueue;</span>
<span class="udiff-line-removed">- class PreGCValues;</span>
  class MoveAndUpdateClosure;
  class RefProcTaskExecutor;
  class ParallelOldTracer;
  class STWGCTimer;
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -239,10 +237,13 @@</span>
      HeapWord* destination() const { return _destination; }
  
      // The first region containing data destined for this region.
      size_t source_region() const { return _source_region; }
  
<span class="udiff-line-added">+     // Reuse _source_region to store the corresponding shadow region index</span>
<span class="udiff-line-added">+     size_t shadow_region() const { return _source_region; }</span>
<span class="udiff-line-added">+ </span>
      // The object (if any) starting in this region and ending in a different
      // region that could not be updated during the main (parallel) compaction
      // phase.  This is different from _partial_obj_addr, which is an object that
      // extends onto a source region.  However, the two uses do not overlap in
      // time, so the same field is used to save space.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -307,10 +308,11 @@</span>
      bool completed() const { return _dc_and_los &gt;= dc_completed; }
  
      // These are not atomic.
      void set_destination(HeapWord* addr)       { _destination = addr; }
      void set_source_region(size_t region)      { _source_region = region; }
<span class="udiff-line-added">+     void set_shadow_region(size_t region)      { _source_region = region; }</span>
      void set_deferred_obj_addr(HeapWord* addr) { _partial_obj_addr = addr; }
      void set_partial_obj_addr(HeapWord* addr)  { _partial_obj_addr = addr; }
      void set_partial_obj_size(size_t words)    {
        _partial_obj_size = (region_sz_t) words;
      }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -326,10 +328,36 @@</span>
      inline void add_live_obj(size_t words);
      inline void set_highest_ref(HeapWord* addr);
      inline void decrement_destination_count();
      inline bool claim();
  
<span class="udiff-line-added">+     // Possible values of _shadow_state, and transition is as follows</span>
<span class="udiff-line-added">+     // Normal Path:</span>
<span class="udiff-line-added">+     // UnusedRegion -&gt; mark_normal() -&gt; NormalRegion</span>
<span class="udiff-line-added">+     // Shadow Path:</span>
<span class="udiff-line-added">+     // UnusedRegion -&gt; mark_shadow() -&gt; ShadowRegion -&gt;</span>
<span class="udiff-line-added">+     // mark_filled() -&gt; FilledShadow -&gt; mark_copied() -&gt; CopiedShadow</span>
<span class="udiff-line-added">+     static const int UnusedRegion = 0; // The region is not collected yet</span>
<span class="udiff-line-added">+     static const int ShadowRegion = 1; // Stolen by an idle thread, and a shadow region is created for it</span>
<span class="udiff-line-added">+     static const int FilledShadow = 2; // Its shadow region has been filled and ready to be copied back</span>
<span class="udiff-line-added">+     static const int CopiedShadow = 3; // The data of the shadow region has been copied back</span>
<span class="udiff-line-added">+     static const int NormalRegion = 4; // The region will be collected by the original parallel algorithm</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // Mark the current region as normal or shadow to enter different processing paths</span>
<span class="udiff-line-added">+     inline bool mark_normal();</span>
<span class="udiff-line-added">+     inline bool mark_shadow();</span>
<span class="udiff-line-added">+     // Mark the shadow region as filled and ready to be copied back</span>
<span class="udiff-line-added">+     inline void mark_filled();</span>
<span class="udiff-line-added">+     // Mark the shadow region as copied back to avoid double copying.</span>
<span class="udiff-line-added">+     inline bool mark_copied();</span>
<span class="udiff-line-added">+     // Special case: see the comment in PSParallelCompact::fill_and_update_shadow_region.</span>
<span class="udiff-line-added">+     // Return to the normal path here</span>
<span class="udiff-line-added">+     inline void shadow_to_normal();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     int shadow_state() { return _shadow_state; }</span>
<span class="udiff-line-added">+ </span>
    private:
      // The type used to represent object sizes within a region.
      typedef uint region_sz_t;
  
      // Constants for manipulating the _dc_and_los field, which holds both the
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -346,10 +374,11 @@</span>
      size_t               _source_region;
      HeapWord*            _partial_obj_addr;
      region_sz_t          _partial_obj_size;
      region_sz_t volatile _dc_and_los;
      bool        volatile _blocks_filled;
<span class="udiff-line-added">+     int         volatile _shadow_state;</span>
  
  #ifdef ASSERT
      size_t               _blocks_filled_count;   // Number of block table fills.
  
      // These enable optimizations that are only partially implemented.  Use
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -394,11 +423,11 @@</span>
    size_t block_count() const { return _block_count; }
    inline BlockData* block(size_t block_idx) const;
    inline size_t     block(const BlockData* block_ptr) const;
  
    void add_obj(HeapWord* addr, size_t len);
<span class="udiff-line-modified-removed">-   void add_obj(oop p, size_t len) { add_obj((HeapWord*)p, len); }</span>
<span class="udiff-line-modified-added">+   void add_obj(oop p, size_t len) { add_obj(cast_from_oop&lt;HeapWord*&gt;(p), len); }</span>
  
    // Fill in the regions covering [beg, end) so that no data moves; i.e., the
    // destination of region n is simply the start of region n.  The argument beg
    // must be region-aligned; end need not be.
    void summarize_dense_prefix(HeapWord* beg, HeapWord* end);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -435,11 +464,11 @@</span>
  
    // Analogous to region_offset() for blocks.
    size_t     block_offset(const HeapWord* addr) const;
    size_t     addr_to_block_idx(const HeapWord* addr) const;
    size_t     addr_to_block_idx(const oop obj) const {
<span class="udiff-line-modified-removed">-     return addr_to_block_idx((HeapWord*) obj);</span>
<span class="udiff-line-modified-added">+     return addr_to_block_idx(cast_from_oop&lt;HeapWord*&gt;(obj));</span>
    }
    inline BlockData* addr_to_block_ptr(const HeapWord* addr) const;
    inline HeapWord*  block_to_addr(size_t block) const;
    inline size_t     region_to_block_idx(size_t region) const;
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -452,11 +481,11 @@</span>
  
    // Return the location of the object after compaction.
    HeapWord* calc_new_pointer(HeapWord* addr, ParCompactionManager* cm);
  
    HeapWord* calc_new_pointer(oop p, ParCompactionManager* cm) {
<span class="udiff-line-modified-removed">-     return calc_new_pointer((HeapWord*) p, cm);</span>
<span class="udiff-line-modified-added">+     return calc_new_pointer(cast_from_oop&lt;HeapWord*&gt;(p), cm);</span>
    }
  
  #ifdef  ASSERT
    void verify_clear(const PSVirtualSpace* vspace);
    void verify_clear();
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -536,11 +565,11 @@</span>
  
  inline void ParallelCompactData::RegionData::decrement_destination_count()
  {
    assert(_dc_and_los &lt; dc_claimed, &quot;already claimed&quot;);
    assert(_dc_and_los &gt;= dc_one, &quot;count would go negative&quot;);
<span class="udiff-line-modified-removed">-   Atomic::add(dc_mask, &amp;_dc_and_los);</span>
<span class="udiff-line-modified-added">+   Atomic::add(&amp;_dc_and_los, dc_mask);</span>
  }
  
  inline HeapWord* ParallelCompactData::RegionData::data_location() const
  {
    DEBUG_ONLY(return _data_location;)
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -576,30 +605,53 @@</span>
  }
  
  inline void ParallelCompactData::RegionData::add_live_obj(size_t words)
  {
    assert(words &lt;= (size_t)los_mask - live_obj_size(), &quot;overflow&quot;);
<span class="udiff-line-modified-removed">-   Atomic::add(static_cast&lt;region_sz_t&gt;(words), &amp;_dc_and_los);</span>
<span class="udiff-line-modified-added">+   Atomic::add(&amp;_dc_and_los, static_cast&lt;region_sz_t&gt;(words));</span>
  }
  
  inline void ParallelCompactData::RegionData::set_highest_ref(HeapWord* addr)
  {
  #ifdef ASSERT
    HeapWord* tmp = _highest_ref;
    while (addr &gt; tmp) {
<span class="udiff-line-modified-removed">-     tmp = Atomic::cmpxchg(addr, &amp;_highest_ref, tmp);</span>
<span class="udiff-line-modified-added">+     tmp = Atomic::cmpxchg(&amp;_highest_ref, tmp, addr);</span>
    }
  #endif  // #ifdef ASSERT
  }
  
  inline bool ParallelCompactData::RegionData::claim()
  {
    const region_sz_t los = static_cast&lt;region_sz_t&gt;(live_obj_size());
<span class="udiff-line-modified-removed">-   const region_sz_t old = Atomic::cmpxchg(dc_claimed | los, &amp;_dc_and_los, los);</span>
<span class="udiff-line-modified-added">+   const region_sz_t old = Atomic::cmpxchg(&amp;_dc_and_los, los, dc_claimed | los);</span>
    return old == los;
  }
  
<span class="udiff-line-added">+ inline bool ParallelCompactData::RegionData::mark_normal() {</span>
<span class="udiff-line-added">+   return Atomic::cmpxchg(&amp;_shadow_state, UnusedRegion, NormalRegion) == UnusedRegion;</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ inline bool ParallelCompactData::RegionData::mark_shadow() {</span>
<span class="udiff-line-added">+   if (_shadow_state != UnusedRegion) return false;</span>
<span class="udiff-line-added">+   return Atomic::cmpxchg(&amp;_shadow_state, UnusedRegion, ShadowRegion) == UnusedRegion;</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ inline void ParallelCompactData::RegionData::mark_filled() {</span>
<span class="udiff-line-added">+   int old = Atomic::cmpxchg(&amp;_shadow_state, ShadowRegion, FilledShadow);</span>
<span class="udiff-line-added">+   assert(old == ShadowRegion, &quot;Fail to mark the region as filled&quot;);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ inline bool ParallelCompactData::RegionData::mark_copied() {</span>
<span class="udiff-line-added">+   return Atomic::cmpxchg(&amp;_shadow_state, FilledShadow, CopiedShadow) == FilledShadow;</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void ParallelCompactData::RegionData::shadow_to_normal() {</span>
<span class="udiff-line-added">+   int old = Atomic::cmpxchg(&amp;_shadow_state, ShadowRegion, NormalRegion);</span>
<span class="udiff-line-added">+   assert(old == ShadowRegion, &quot;Fail to mark the region as finish&quot;);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  inline ParallelCompactData::RegionData*
  ParallelCompactData::region(size_t region_idx) const
  {
    assert(region_idx &lt;= region_count(), &quot;bad arg&quot;);
    return _region_data + region_idx;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -825,19 +877,13 @@</span>
  inline void ParMarkBitMapClosure::decrement_words_remaining(size_t words) {
    assert(_words_remaining &gt;= words, &quot;processed too many words&quot;);
    _words_remaining -= words;
  }
  
<span class="udiff-line-modified-removed">- // The UseParallelOldGC collector is a stop-the-world garbage collector that</span>
<span class="udiff-line-modified-added">+ // The Parallel collector is a stop-the-world garbage collector that</span>
  // does parts of the collection using parallel threads.  The collection includes
<span class="udiff-line-modified-removed">- // the tenured generation and the young generation.  The permanent generation is</span>
<span class="udiff-line-removed">- // collected at the same time as the other two generations but the permanent</span>
<span class="udiff-line-removed">- // generation is collect by a single GC thread.  The permanent generation is</span>
<span class="udiff-line-removed">- // collected serially because of the requirement that during the processing of a</span>
<span class="udiff-line-removed">- // klass AAA, any objects reference by AAA must already have been processed.</span>
<span class="udiff-line-removed">- // This requirement is enforced by a left (lower address) to right (higher</span>
<span class="udiff-line-removed">- // address) sliding compaction.</span>
<span class="udiff-line-modified-added">+ // the tenured generation and the young generation.</span>
  //
  // There are four phases of the collection.
  //
  //      - marking phase
  //      - summary phase
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -912,10 +958,12 @@</span>
  // also ready for filling.  The ready list is initially filled with empty
  // regions and regions compacting into themselves.  There is always at least 1
  // region that can be put on the ready list.  The regions are atomically added
  // and removed from the ready list.
  
<span class="udiff-line-added">+ class TaskQueue;</span>
<span class="udiff-line-added">+ </span>
  class PSParallelCompact : AllStatic {
   public:
    // Convenient access to type names.
    typedef ParMarkBitMap::idx_t idx_t;
    typedef ParallelCompactData::RegionData RegionData;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -924,10 +972,28 @@</span>
    typedef enum {
      old_space_id, eden_space_id,
      from_space_id, to_space_id, last_space_id
    } SpaceId;
  
<span class="udiff-line-added">+   struct UpdateDensePrefixTask : public CHeapObj&lt;mtGC&gt; {</span>
<span class="udiff-line-added">+     SpaceId _space_id;</span>
<span class="udiff-line-added">+     size_t _region_index_start;</span>
<span class="udiff-line-added">+     size_t _region_index_end;</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     UpdateDensePrefixTask() :</span>
<span class="udiff-line-added">+         _space_id(SpaceId(0)),</span>
<span class="udiff-line-added">+         _region_index_start(0),</span>
<span class="udiff-line-added">+         _region_index_end(0) {}</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     UpdateDensePrefixTask(SpaceId space_id,</span>
<span class="udiff-line-added">+                           size_t region_index_start,</span>
<span class="udiff-line-added">+                           size_t region_index_end) :</span>
<span class="udiff-line-added">+         _space_id(space_id),</span>
<span class="udiff-line-added">+         _region_index_start(region_index_start),</span>
<span class="udiff-line-added">+         _region_index_end(region_index_end) {}</span>
<span class="udiff-line-added">+   };</span>
<span class="udiff-line-added">+ </span>
   public:
    // Inline closure decls
    //
    class IsAliveClosure: public BoolObjectClosure {
     public:
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1049,23 +1115,16 @@</span>
    // Move objects to new locations.
    static void compact_perm(ParCompactionManager* cm);
    static void compact();
  
    // Add available regions to the stack and draining tasks to the task queue.
<span class="udiff-line-modified-removed">-   static void prepare_region_draining_tasks(GCTaskQueue* q,</span>
<span class="udiff-line-removed">-                                             uint parallel_gc_threads);</span>
<span class="udiff-line-modified-added">+   static void prepare_region_draining_tasks(uint parallel_gc_threads);</span>
  
    // Add dense prefix update tasks to the task queue.
<span class="udiff-line-modified-removed">-   static void enqueue_dense_prefix_tasks(GCTaskQueue* q,</span>
<span class="udiff-line-modified-added">+   static void enqueue_dense_prefix_tasks(TaskQueue&amp; task_queue,</span>
                                           uint parallel_gc_threads);
  
<span class="udiff-line-removed">-   // Add region stealing tasks to the task queue.</span>
<span class="udiff-line-removed">-   static void enqueue_region_stealing_tasks(</span>
<span class="udiff-line-removed">-                                        GCTaskQueue* q,</span>
<span class="udiff-line-removed">-                                        ParallelTaskTerminator* terminator_ptr,</span>
<span class="udiff-line-removed">-                                        uint parallel_gc_threads);</span>
<span class="udiff-line-removed">- </span>
    // If objects are left in eden after a collection, try to move the boundary
    // and absorb them into the old gen.  Returns true if eden was emptied.
    static bool absorb_live_data_from_eden(PSAdaptiveSizePolicy* size_policy,
                                           PSYoungGen* young_gen,
                                           PSOldGen* old_gen);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1100,13 +1159,10 @@</span>
    // Public accessors
    static elapsedTimer* accumulated_time() { return &amp;_accumulated_time; }
    static unsigned int total_invocations() { return _total_invocations; }
    static CollectorCounters* counters()    { return _counters; }
  
<span class="udiff-line-removed">-   // Used to add tasks</span>
<span class="udiff-line-removed">-   static GCTaskManager* const gc_task_manager();</span>
<span class="udiff-line-removed">- </span>
    // Marking support
    static inline bool mark_obj(oop obj);
    static inline bool is_marked(oop obj);
  
    template &lt;class T&gt; static inline void adjust_pointer(T* p, ParCompactionManager* cm);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1120,13 +1176,10 @@</span>
    static inline MutableSpace*     space(SpaceId space_id);
    static inline HeapWord*         new_top(SpaceId space_id);
    static inline HeapWord*         dense_prefix(SpaceId space_id);
    static inline ObjectStartArray* start_array(SpaceId space_id);
  
<span class="udiff-line-removed">-   // Move and update the live objects in the specified space.</span>
<span class="udiff-line-removed">-   static void move_and_update(ParCompactionManager* cm, SpaceId space_id);</span>
<span class="udiff-line-removed">- </span>
    // Process the end of the given region range in the dense prefix.
    // This includes saving any object not updated.
    static void dense_prefix_regions_epilogue(ParCompactionManager* cm,
                                              size_t region_start_index,
                                              size_t region_end_index,
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1172,15 +1225,20 @@</span>
    static void decrement_destination_counts(ParCompactionManager* cm,
                                             SpaceId src_space_id,
                                             size_t beg_region,
                                             HeapWord* end_addr);
  
<span class="udiff-line-modified-removed">-   // Fill a region, copying objects from one or more source regions.</span>
<span class="udiff-line-modified-removed">-   static void fill_region(ParCompactionManager* cm, size_t region_idx);</span>
<span class="udiff-line-modified-removed">-   static void fill_and_update_region(ParCompactionManager* cm, size_t region) {</span>
<span class="udiff-line-modified-removed">-     fill_region(cm, region);</span>
<span class="udiff-line-modified-removed">-   }</span>
<span class="udiff-line-modified-added">+   static void fill_region(ParCompactionManager* cm, MoveAndUpdateClosure&amp; closure, size_t region);</span>
<span class="udiff-line-modified-added">+   static void fill_and_update_region(ParCompactionManager* cm, size_t region);</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+   static bool steal_unavailable_region(ParCompactionManager* cm, size_t&amp; region_idx);</span>
<span class="udiff-line-modified-added">+   static void fill_and_update_shadow_region(ParCompactionManager* cm, size_t region);</span>
<span class="udiff-line-added">+   // Copy the content of a shadow region back to its corresponding heap region</span>
<span class="udiff-line-added">+   static void copy_back(HeapWord* shadow_addr, HeapWord* region_addr);</span>
<span class="udiff-line-added">+   // Collect empty regions as shadow regions and initialize the</span>
<span class="udiff-line-added">+   // _next_shadow_region filed for each compact manager</span>
<span class="udiff-line-added">+   static void initialize_shadow_regions(uint parallel_gc_threads);</span>
  
    // Fill in the block table for the specified region.
    static void fill_blocks(size_t region_idx);
  
    // Update the deferred objects in the space.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1223,60 +1281,103 @@</span>
    static void verify_complete(SpaceId space_id);
  #endif  // #ifdef ASSERT
  };
  
  class MoveAndUpdateClosure: public ParMarkBitMapClosure {
<span class="udiff-line-added">+   static inline size_t calculate_words_remaining(size_t region);</span>
   public:
    inline MoveAndUpdateClosure(ParMarkBitMap* bitmap, ParCompactionManager* cm,
<span class="udiff-line-modified-removed">-                               ObjectStartArray* start_array,</span>
<span class="udiff-line-removed">-                               HeapWord* destination, size_t words);</span>
<span class="udiff-line-modified-added">+                               size_t region);</span>
  
    // Accessors.
    HeapWord* destination() const         { return _destination; }
<span class="udiff-line-added">+   HeapWord* copy_destination() const    { return _destination + _offset; }</span>
  
    // If the object will fit (size &lt;= words_remaining()), copy it to the current
    // destination, update the interior oops and the start array and return either
    // full (if the closure is full) or incomplete.  If the object will not fit,
    // return would_overflow.
<span class="udiff-line-modified-removed">-   virtual IterationStatus do_addr(HeapWord* addr, size_t size);</span>
<span class="udiff-line-modified-added">+   IterationStatus do_addr(HeapWord* addr, size_t size);</span>
  
    // Copy enough words to fill this closure, starting at source().  Interior
    // oops and the start array are not updated.  Return full.
    IterationStatus copy_until_full();
  
    // Copy enough words to fill this closure or to the end of an object,
    // whichever is smaller, starting at source().  Interior oops and the start
    // array are not updated.
    void copy_partial_obj();
  
<span class="udiff-line-modified-removed">-  protected:</span>
<span class="udiff-line-modified-added">+   virtual void complete_region(ParCompactionManager* cm, HeapWord* dest_addr,</span>
<span class="udiff-line-added">+                                PSParallelCompact::RegionData* region_ptr);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ protected:</span>
    // Update variables to indicate that word_count words were processed.
    inline void update_state(size_t word_count);
  
   protected:
<span class="udiff-line-removed">-   ObjectStartArray* const _start_array;</span>
    HeapWord*               _destination;         // Next addr to be written.
<span class="udiff-line-added">+   ObjectStartArray* const _start_array;</span>
<span class="udiff-line-added">+   size_t                  _offset;</span>
  };
  
<span class="udiff-line-added">+ inline size_t MoveAndUpdateClosure::calculate_words_remaining(size_t region) {</span>
<span class="udiff-line-added">+   HeapWord* dest_addr = PSParallelCompact::summary_data().region_to_addr(region);</span>
<span class="udiff-line-added">+   PSParallelCompact::SpaceId dest_space_id = PSParallelCompact::space_id(dest_addr);</span>
<span class="udiff-line-added">+   HeapWord* new_top = PSParallelCompact::new_top(dest_space_id);</span>
<span class="udiff-line-added">+   assert(dest_addr &lt; new_top, &quot;sanity&quot;);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   return MIN2(pointer_delta(new_top, dest_addr), ParallelCompactData::RegionSize);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  inline
  MoveAndUpdateClosure::MoveAndUpdateClosure(ParMarkBitMap* bitmap,
                                             ParCompactionManager* cm,
<span class="udiff-line-modified-removed">-                                            ObjectStartArray* start_array,</span>
<span class="udiff-line-modified-removed">-                                            HeapWord* destination,</span>
<span class="udiff-line-modified-removed">-                                            size_t words) :</span>
<span class="udiff-line-modified-removed">-   ParMarkBitMapClosure(bitmap, cm, words), _start_array(start_array)</span>
<span class="udiff-line-modified-removed">- {</span>
<span class="udiff-line-modified-removed">-   _destination = destination;</span>
<span class="udiff-line-removed">- }</span>
<span class="udiff-line-modified-added">+                                            size_t region_idx) :</span>
<span class="udiff-line-modified-added">+   ParMarkBitMapClosure(bitmap, cm, calculate_words_remaining(region_idx)),</span>
<span class="udiff-line-modified-added">+   _destination(PSParallelCompact::summary_data().region_to_addr(region_idx)),</span>
<span class="udiff-line-modified-added">+   _start_array(PSParallelCompact::start_array(PSParallelCompact::space_id(_destination))),</span>
<span class="udiff-line-modified-added">+   _offset(0) { }</span>
<span class="udiff-line-modified-added">+ </span>
  
  inline void MoveAndUpdateClosure::update_state(size_t words)
  {
    decrement_words_remaining(words);
    _source += words;
    _destination += words;
  }
  
<span class="udiff-line-added">+ class MoveAndUpdateShadowClosure: public MoveAndUpdateClosure {</span>
<span class="udiff-line-added">+   inline size_t calculate_shadow_offset(size_t region_idx, size_t shadow_idx);</span>
<span class="udiff-line-added">+ public:</span>
<span class="udiff-line-added">+   inline MoveAndUpdateShadowClosure(ParMarkBitMap* bitmap, ParCompactionManager* cm,</span>
<span class="udiff-line-added">+                        size_t region, size_t shadow);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   virtual void complete_region(ParCompactionManager* cm, HeapWord* dest_addr,</span>
<span class="udiff-line-added">+                                PSParallelCompact::RegionData* region_ptr);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ private:</span>
<span class="udiff-line-added">+   size_t _shadow;</span>
<span class="udiff-line-added">+ };</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ inline size_t MoveAndUpdateShadowClosure::calculate_shadow_offset(size_t region_idx, size_t shadow_idx) {</span>
<span class="udiff-line-added">+   ParallelCompactData&amp; sd = PSParallelCompact::summary_data();</span>
<span class="udiff-line-added">+   HeapWord* dest_addr = sd.region_to_addr(region_idx);</span>
<span class="udiff-line-added">+   HeapWord* shadow_addr = sd.region_to_addr(shadow_idx);</span>
<span class="udiff-line-added">+   return pointer_delta(shadow_addr, dest_addr);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ inline</span>
<span class="udiff-line-added">+ MoveAndUpdateShadowClosure::MoveAndUpdateShadowClosure(ParMarkBitMap *bitmap,</span>
<span class="udiff-line-added">+                                                        ParCompactionManager *cm,</span>
<span class="udiff-line-added">+                                                        size_t region,</span>
<span class="udiff-line-added">+                                                        size_t shadow) :</span>
<span class="udiff-line-added">+   MoveAndUpdateClosure(bitmap, cm, region),</span>
<span class="udiff-line-added">+   _shadow(shadow) {</span>
<span class="udiff-line-added">+   _offset = calculate_shadow_offset(region, shadow);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  class UpdateOnlyClosure: public ParMarkBitMapClosure {
   private:
    const PSParallelCompact::SpaceId _space_id;
    ObjectStartArray* const          _start_array;
  
</pre>
<center><a href="psParallelCompact.cpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="psPromotionLAB.cpp.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>