<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/serial/genMarkSweep.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="defNewGeneration.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="markSweep.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/serial/genMarkSweep.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 29 #include &quot;classfile/symbolTable.hpp&quot;
 30 #include &quot;classfile/systemDictionary.hpp&quot;
 31 #include &quot;classfile/vmSymbols.hpp&quot;
 32 #include &quot;code/codeCache.hpp&quot;
 33 #include &quot;code/icBuffer.hpp&quot;
 34 #include &quot;gc/serial/genMarkSweep.hpp&quot;
 35 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
 36 #include &quot;gc/shared/gcHeapSummary.hpp&quot;
 37 #include &quot;gc/shared/gcTimer.hpp&quot;
 38 #include &quot;gc/shared/gcTrace.hpp&quot;
 39 #include &quot;gc/shared/gcTraceTime.inline.hpp&quot;
 40 #include &quot;gc/shared/genCollectedHeap.hpp&quot;
 41 #include &quot;gc/shared/generation.hpp&quot;
 42 #include &quot;gc/shared/genOopClosures.inline.hpp&quot;
 43 #include &quot;gc/shared/modRefBarrierSet.hpp&quot;
 44 #include &quot;gc/shared/referencePolicy.hpp&quot;
 45 #include &quot;gc/shared/referenceProcessorPhaseTimes.hpp&quot;
 46 #include &quot;gc/shared/space.hpp&quot;
 47 #include &quot;gc/shared/strongRootsScope.hpp&quot;
 48 #include &quot;gc/shared/weakProcessor.hpp&quot;

 49 #include &quot;oops/instanceRefKlass.hpp&quot;
 50 #include &quot;oops/oop.inline.hpp&quot;
 51 #include &quot;prims/jvmtiExport.hpp&quot;
 52 #include &quot;runtime/handles.inline.hpp&quot;
 53 #include &quot;runtime/synchronizer.hpp&quot;
 54 #include &quot;runtime/thread.inline.hpp&quot;
 55 #include &quot;runtime/vmThread.hpp&quot;
 56 #include &quot;utilities/copy.hpp&quot;
 57 #include &quot;utilities/events.hpp&quot;
 58 #include &quot;utilities/stack.inline.hpp&quot;



 59 
 60 void GenMarkSweep::invoke_at_safepoint(ReferenceProcessor* rp, bool clear_all_softrefs) {
 61   assert(SafepointSynchronize::is_at_safepoint(), &quot;must be at a safepoint&quot;);
 62 
 63   GenCollectedHeap* gch = GenCollectedHeap::heap();
 64 #ifdef ASSERT
 65   if (gch-&gt;soft_ref_policy()-&gt;should_clear_all_soft_refs()) {
 66     assert(clear_all_softrefs, &quot;Policy should have been checked earlier&quot;);
 67   }
 68 #endif
 69 
 70   // hook up weak ref data so it can be used during Mark-Sweep
 71   assert(ref_processor() == NULL, &quot;no stomping&quot;);
 72   assert(rp != NULL, &quot;should be non-NULL&quot;);
 73   set_ref_processor(rp);
 74   rp-&gt;setup_policy(clear_all_softrefs);
 75 
 76   gch-&gt;trace_heap_before_gc(_gc_tracer);
 77 
 78   // Increment the invocation count
</pre>
<hr />
<pre>
107 
108   deallocate_stacks();
109 
110   // If compaction completely evacuated the young generation then we
111   // can clear the card table.  Otherwise, we must invalidate
112   // it (consider all cards dirty).  In the future, we might consider doing
113   // compaction within generations only, and doing card-table sliding.
114   CardTableRS* rs = gch-&gt;rem_set();
115   Generation* old_gen = gch-&gt;old_gen();
116 
117   // Clear/invalidate below make use of the &quot;prev_used_regions&quot; saved earlier.
118   if (gch-&gt;young_gen()-&gt;used() == 0) {
119     // We&#39;ve evacuated the young generation.
120     rs-&gt;clear_into_younger(old_gen);
121   } else {
122     // Invalidate the cards corresponding to the currently used
123     // region and clear those corresponding to the evacuated region.
124     rs-&gt;invalidate_or_clear(old_gen);
125   }
126 
<span class="line-modified">127   gch-&gt;prune_nmethods();</span>
<span class="line-removed">128   JvmtiExport::gc_epilogue();</span>
129 
130   // refs processing: clean slate
131   set_ref_processor(NULL);
132 
133   // Update heap occupancy information which is used as
134   // input to soft ref clearing policy at the next gc.
135   Universe::update_heap_info_at_gc();
136 
137   // Update time of last gc for all generations we collected
138   // (which currently is all the generations in the heap).
139   // We need to use a monotonically non-decreasing time in ms
140   // or we will see time-warp warnings and os::javaTimeMillis()
141   // does not guarantee monotonicity.
142   jlong now = os::javaTimeNanos() / NANOSECS_PER_MILLISEC;
143   gch-&gt;update_time_of_last_gc(now);
144 
145   gch-&gt;trace_heap_after_gc(_gc_tracer);
146 }
147 
148 void GenMarkSweep::allocate_stacks() {
</pre>
<hr />
<pre>
216 
217   // This is the point where the entire marking should have completed.
218   assert(_marking_stack.is_empty(), &quot;Marking should have completed&quot;);
219 
220   {
221     GCTraceTime(Debug, gc, phases) tm_m(&quot;Weak Processing&quot;, gc_timer());
222     WeakProcessor::weak_oops_do(&amp;is_alive, &amp;do_nothing_cl);
223   }
224 
225   {
226     GCTraceTime(Debug, gc, phases) tm_m(&quot;Class Unloading&quot;, gc_timer());
227 
228     // Unload classes and purge the SystemDictionary.
229     bool purged_class = SystemDictionary::do_unloading(gc_timer());
230 
231     // Unload nmethods.
232     CodeCache::do_unloading(&amp;is_alive, purged_class);
233 
234     // Prune dead klasses from subklass/sibling/implementor lists.
235     Klass::clean_weak_klass_links(purged_class);



236   }
237 
238   gc_tracer()-&gt;report_object_count_after_gc(&amp;is_alive);
239 }
240 
241 
242 void GenMarkSweep::mark_sweep_phase2() {
243   // Now all live objects are marked, compute the new object addresses.
244 
245   // It is imperative that we traverse perm_gen LAST. If dead space is
246   // allowed a range of dead object may get overwritten by a dead int
247   // array. If perm_gen is not traversed last a Klass* may get
248   // overwritten. This is fine since it is dead, but if the class has dead
249   // instances we have to skip them, and in order to find their size we
250   // need the Klass*!
251   //
252   // It is not required that we traverse spaces in the same order in
253   // phase2, phase3 and phase4, but the ValidateMarkSweep live oops
254   // tracking expects us to do so. See comment under phase4.
255 
</pre>
</td>
<td>
<hr />
<pre>
 29 #include &quot;classfile/symbolTable.hpp&quot;
 30 #include &quot;classfile/systemDictionary.hpp&quot;
 31 #include &quot;classfile/vmSymbols.hpp&quot;
 32 #include &quot;code/codeCache.hpp&quot;
 33 #include &quot;code/icBuffer.hpp&quot;
 34 #include &quot;gc/serial/genMarkSweep.hpp&quot;
 35 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
 36 #include &quot;gc/shared/gcHeapSummary.hpp&quot;
 37 #include &quot;gc/shared/gcTimer.hpp&quot;
 38 #include &quot;gc/shared/gcTrace.hpp&quot;
 39 #include &quot;gc/shared/gcTraceTime.inline.hpp&quot;
 40 #include &quot;gc/shared/genCollectedHeap.hpp&quot;
 41 #include &quot;gc/shared/generation.hpp&quot;
 42 #include &quot;gc/shared/genOopClosures.inline.hpp&quot;
 43 #include &quot;gc/shared/modRefBarrierSet.hpp&quot;
 44 #include &quot;gc/shared/referencePolicy.hpp&quot;
 45 #include &quot;gc/shared/referenceProcessorPhaseTimes.hpp&quot;
 46 #include &quot;gc/shared/space.hpp&quot;
 47 #include &quot;gc/shared/strongRootsScope.hpp&quot;
 48 #include &quot;gc/shared/weakProcessor.hpp&quot;
<span class="line-added"> 49 #include &quot;memory/universe.hpp&quot;</span>
 50 #include &quot;oops/instanceRefKlass.hpp&quot;
 51 #include &quot;oops/oop.inline.hpp&quot;
 52 #include &quot;prims/jvmtiExport.hpp&quot;
 53 #include &quot;runtime/handles.inline.hpp&quot;
 54 #include &quot;runtime/synchronizer.hpp&quot;
 55 #include &quot;runtime/thread.inline.hpp&quot;
 56 #include &quot;runtime/vmThread.hpp&quot;
 57 #include &quot;utilities/copy.hpp&quot;
 58 #include &quot;utilities/events.hpp&quot;
 59 #include &quot;utilities/stack.inline.hpp&quot;
<span class="line-added"> 60 #if INCLUDE_JVMCI</span>
<span class="line-added"> 61 #include &quot;jvmci/jvmci.hpp&quot;</span>
<span class="line-added"> 62 #endif</span>
 63 
 64 void GenMarkSweep::invoke_at_safepoint(ReferenceProcessor* rp, bool clear_all_softrefs) {
 65   assert(SafepointSynchronize::is_at_safepoint(), &quot;must be at a safepoint&quot;);
 66 
 67   GenCollectedHeap* gch = GenCollectedHeap::heap();
 68 #ifdef ASSERT
 69   if (gch-&gt;soft_ref_policy()-&gt;should_clear_all_soft_refs()) {
 70     assert(clear_all_softrefs, &quot;Policy should have been checked earlier&quot;);
 71   }
 72 #endif
 73 
 74   // hook up weak ref data so it can be used during Mark-Sweep
 75   assert(ref_processor() == NULL, &quot;no stomping&quot;);
 76   assert(rp != NULL, &quot;should be non-NULL&quot;);
 77   set_ref_processor(rp);
 78   rp-&gt;setup_policy(clear_all_softrefs);
 79 
 80   gch-&gt;trace_heap_before_gc(_gc_tracer);
 81 
 82   // Increment the invocation count
</pre>
<hr />
<pre>
111 
112   deallocate_stacks();
113 
114   // If compaction completely evacuated the young generation then we
115   // can clear the card table.  Otherwise, we must invalidate
116   // it (consider all cards dirty).  In the future, we might consider doing
117   // compaction within generations only, and doing card-table sliding.
118   CardTableRS* rs = gch-&gt;rem_set();
119   Generation* old_gen = gch-&gt;old_gen();
120 
121   // Clear/invalidate below make use of the &quot;prev_used_regions&quot; saved earlier.
122   if (gch-&gt;young_gen()-&gt;used() == 0) {
123     // We&#39;ve evacuated the young generation.
124     rs-&gt;clear_into_younger(old_gen);
125   } else {
126     // Invalidate the cards corresponding to the currently used
127     // region and clear those corresponding to the evacuated region.
128     rs-&gt;invalidate_or_clear(old_gen);
129   }
130 
<span class="line-modified">131   gch-&gt;prune_scavengable_nmethods();</span>

132 
133   // refs processing: clean slate
134   set_ref_processor(NULL);
135 
136   // Update heap occupancy information which is used as
137   // input to soft ref clearing policy at the next gc.
138   Universe::update_heap_info_at_gc();
139 
140   // Update time of last gc for all generations we collected
141   // (which currently is all the generations in the heap).
142   // We need to use a monotonically non-decreasing time in ms
143   // or we will see time-warp warnings and os::javaTimeMillis()
144   // does not guarantee monotonicity.
145   jlong now = os::javaTimeNanos() / NANOSECS_PER_MILLISEC;
146   gch-&gt;update_time_of_last_gc(now);
147 
148   gch-&gt;trace_heap_after_gc(_gc_tracer);
149 }
150 
151 void GenMarkSweep::allocate_stacks() {
</pre>
<hr />
<pre>
219 
220   // This is the point where the entire marking should have completed.
221   assert(_marking_stack.is_empty(), &quot;Marking should have completed&quot;);
222 
223   {
224     GCTraceTime(Debug, gc, phases) tm_m(&quot;Weak Processing&quot;, gc_timer());
225     WeakProcessor::weak_oops_do(&amp;is_alive, &amp;do_nothing_cl);
226   }
227 
228   {
229     GCTraceTime(Debug, gc, phases) tm_m(&quot;Class Unloading&quot;, gc_timer());
230 
231     // Unload classes and purge the SystemDictionary.
232     bool purged_class = SystemDictionary::do_unloading(gc_timer());
233 
234     // Unload nmethods.
235     CodeCache::do_unloading(&amp;is_alive, purged_class);
236 
237     // Prune dead klasses from subklass/sibling/implementor lists.
238     Klass::clean_weak_klass_links(purged_class);
<span class="line-added">239 </span>
<span class="line-added">240     // Clean JVMCI metadata handles.</span>
<span class="line-added">241     JVMCI_ONLY(JVMCI::do_unloading(purged_class));</span>
242   }
243 
244   gc_tracer()-&gt;report_object_count_after_gc(&amp;is_alive);
245 }
246 
247 
248 void GenMarkSweep::mark_sweep_phase2() {
249   // Now all live objects are marked, compute the new object addresses.
250 
251   // It is imperative that we traverse perm_gen LAST. If dead space is
252   // allowed a range of dead object may get overwritten by a dead int
253   // array. If perm_gen is not traversed last a Klass* may get
254   // overwritten. This is fine since it is dead, but if the class has dead
255   // instances we have to skip them, and in order to find their size we
256   // need the Klass*!
257   //
258   // It is not required that we traverse spaces in the same order in
259   // phase2, phase3 and phase4, but the ValidateMarkSweep live oops
260   // tracking expects us to do so. See comment under phase4.
261 
</pre>
</td>
</tr>
</table>
<center><a href="defNewGeneration.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="markSweep.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>