<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/gc/serial/genMarkSweep.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
    <script type="text/javascript" src="../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (c) 2001, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;classfile/classLoaderDataGraph.hpp&quot;
 27 #include &quot;classfile/javaClasses.hpp&quot;
 28 #include &quot;classfile/stringTable.hpp&quot;
 29 #include &quot;classfile/symbolTable.hpp&quot;
 30 #include &quot;classfile/systemDictionary.hpp&quot;
 31 #include &quot;classfile/vmSymbols.hpp&quot;
 32 #include &quot;code/codeCache.hpp&quot;
 33 #include &quot;code/icBuffer.hpp&quot;
 34 #include &quot;gc/serial/genMarkSweep.hpp&quot;
 35 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
 36 #include &quot;gc/shared/gcHeapSummary.hpp&quot;
 37 #include &quot;gc/shared/gcTimer.hpp&quot;
 38 #include &quot;gc/shared/gcTrace.hpp&quot;
 39 #include &quot;gc/shared/gcTraceTime.inline.hpp&quot;
 40 #include &quot;gc/shared/genCollectedHeap.hpp&quot;
 41 #include &quot;gc/shared/generation.hpp&quot;
 42 #include &quot;gc/shared/genOopClosures.inline.hpp&quot;
 43 #include &quot;gc/shared/modRefBarrierSet.hpp&quot;
 44 #include &quot;gc/shared/referencePolicy.hpp&quot;
 45 #include &quot;gc/shared/referenceProcessorPhaseTimes.hpp&quot;
 46 #include &quot;gc/shared/space.hpp&quot;
 47 #include &quot;gc/shared/strongRootsScope.hpp&quot;
 48 #include &quot;gc/shared/weakProcessor.hpp&quot;
<a name="1" id="anc1"></a>
 49 #include &quot;oops/instanceRefKlass.hpp&quot;
 50 #include &quot;oops/oop.inline.hpp&quot;
 51 #include &quot;prims/jvmtiExport.hpp&quot;
 52 #include &quot;runtime/handles.inline.hpp&quot;
 53 #include &quot;runtime/synchronizer.hpp&quot;
 54 #include &quot;runtime/thread.inline.hpp&quot;
 55 #include &quot;runtime/vmThread.hpp&quot;
 56 #include &quot;utilities/copy.hpp&quot;
 57 #include &quot;utilities/events.hpp&quot;
 58 #include &quot;utilities/stack.inline.hpp&quot;
<a name="2" id="anc2"></a>


 59 
 60 void GenMarkSweep::invoke_at_safepoint(ReferenceProcessor* rp, bool clear_all_softrefs) {
 61   assert(SafepointSynchronize::is_at_safepoint(), &quot;must be at a safepoint&quot;);
 62 
 63   GenCollectedHeap* gch = GenCollectedHeap::heap();
 64 #ifdef ASSERT
 65   if (gch-&gt;soft_ref_policy()-&gt;should_clear_all_soft_refs()) {
 66     assert(clear_all_softrefs, &quot;Policy should have been checked earlier&quot;);
 67   }
 68 #endif
 69 
 70   // hook up weak ref data so it can be used during Mark-Sweep
 71   assert(ref_processor() == NULL, &quot;no stomping&quot;);
 72   assert(rp != NULL, &quot;should be non-NULL&quot;);
 73   set_ref_processor(rp);
 74   rp-&gt;setup_policy(clear_all_softrefs);
 75 
 76   gch-&gt;trace_heap_before_gc(_gc_tracer);
 77 
 78   // Increment the invocation count
 79   _total_invocations++;
 80 
 81   // Capture used regions for each generation that will be
 82   // subject to collection, so that card table adjustments can
 83   // be made intelligently (see clear / invalidate further below).
 84   gch-&gt;save_used_regions();
 85 
 86   allocate_stacks();
 87 
 88   mark_sweep_phase1(clear_all_softrefs);
 89 
 90   mark_sweep_phase2();
 91 
 92   // Don&#39;t add any more derived pointers during phase3
 93 #if COMPILER2_OR_JVMCI
 94   assert(DerivedPointerTable::is_active(), &quot;Sanity&quot;);
 95   DerivedPointerTable::set_active(false);
 96 #endif
 97 
 98   mark_sweep_phase3();
 99 
100   mark_sweep_phase4();
101 
102   restore_marks();
103 
104   // Set saved marks for allocation profiler (and other things? -- dld)
105   // (Should this be in general part?)
106   gch-&gt;save_marks();
107 
108   deallocate_stacks();
109 
110   // If compaction completely evacuated the young generation then we
111   // can clear the card table.  Otherwise, we must invalidate
112   // it (consider all cards dirty).  In the future, we might consider doing
113   // compaction within generations only, and doing card-table sliding.
114   CardTableRS* rs = gch-&gt;rem_set();
115   Generation* old_gen = gch-&gt;old_gen();
116 
117   // Clear/invalidate below make use of the &quot;prev_used_regions&quot; saved earlier.
118   if (gch-&gt;young_gen()-&gt;used() == 0) {
119     // We&#39;ve evacuated the young generation.
120     rs-&gt;clear_into_younger(old_gen);
121   } else {
122     // Invalidate the cards corresponding to the currently used
123     // region and clear those corresponding to the evacuated region.
124     rs-&gt;invalidate_or_clear(old_gen);
125   }
126 
<a name="3" id="anc3"></a><span class="line-modified">127   gch-&gt;prune_nmethods();</span>
<span class="line-removed">128   JvmtiExport::gc_epilogue();</span>
129 
130   // refs processing: clean slate
131   set_ref_processor(NULL);
132 
133   // Update heap occupancy information which is used as
134   // input to soft ref clearing policy at the next gc.
135   Universe::update_heap_info_at_gc();
136 
137   // Update time of last gc for all generations we collected
138   // (which currently is all the generations in the heap).
139   // We need to use a monotonically non-decreasing time in ms
140   // or we will see time-warp warnings and os::javaTimeMillis()
141   // does not guarantee monotonicity.
142   jlong now = os::javaTimeNanos() / NANOSECS_PER_MILLISEC;
143   gch-&gt;update_time_of_last_gc(now);
144 
145   gch-&gt;trace_heap_after_gc(_gc_tracer);
146 }
147 
148 void GenMarkSweep::allocate_stacks() {
149   GenCollectedHeap* gch = GenCollectedHeap::heap();
150   // Scratch request on behalf of old generation; will do no allocation.
151   ScratchBlock* scratch = gch-&gt;gather_scratch(gch-&gt;old_gen(), 0);
152 
153   // $$$ To cut a corner, we&#39;ll only use the first scratch block, and then
154   // revert to malloc.
155   if (scratch != NULL) {
156     _preserved_count_max =
157       scratch-&gt;num_words * HeapWordSize / sizeof(PreservedMark);
158   } else {
159     _preserved_count_max = 0;
160   }
161 
162   _preserved_marks = (PreservedMark*)scratch;
163   _preserved_count = 0;
164 }
165 
166 
167 void GenMarkSweep::deallocate_stacks() {
168   GenCollectedHeap* gch = GenCollectedHeap::heap();
169   gch-&gt;release_scratch();
170 
171   _preserved_mark_stack.clear(true);
172   _preserved_oop_stack.clear(true);
173   _marking_stack.clear();
174   _objarray_stack.clear(true);
175 }
176 
177 void GenMarkSweep::mark_sweep_phase1(bool clear_all_softrefs) {
178   // Recursively traverse all live objects and mark them
179   GCTraceTime(Info, gc, phases) tm(&quot;Phase 1: Mark live objects&quot;, _gc_timer);
180 
181   GenCollectedHeap* gch = GenCollectedHeap::heap();
182 
183   // Because follow_root_closure is created statically, cannot
184   // use OopsInGenClosure constructor which takes a generation,
185   // as the Universe has not been created when the static constructors
186   // are run.
187   follow_root_closure.set_orig_generation(gch-&gt;old_gen());
188 
189   // Need new claim bits before marking starts.
190   ClassLoaderDataGraph::clear_claimed_marks();
191 
192   {
193     StrongRootsScope srs(1);
194 
195     gch-&gt;full_process_roots(&amp;srs,
196                             false, // not the adjust phase
197                             GenCollectedHeap::SO_None,
198                             ClassUnloading, // only strong roots if ClassUnloading
199                                             // is enabled
200                             &amp;follow_root_closure,
201                             &amp;follow_cld_closure);
202   }
203 
204   // Process reference objects found during marking
205   {
206     GCTraceTime(Debug, gc, phases) tm_m(&quot;Reference Processing&quot;, gc_timer());
207 
208     ref_processor()-&gt;setup_policy(clear_all_softrefs);
209     ReferenceProcessorPhaseTimes pt(_gc_timer, ref_processor()-&gt;max_num_queues());
210     const ReferenceProcessorStats&amp; stats =
211       ref_processor()-&gt;process_discovered_references(
212         &amp;is_alive, &amp;keep_alive, &amp;follow_stack_closure, NULL, &amp;pt);
213     pt.print_all_references();
214     gc_tracer()-&gt;report_gc_reference_stats(stats);
215   }
216 
217   // This is the point where the entire marking should have completed.
218   assert(_marking_stack.is_empty(), &quot;Marking should have completed&quot;);
219 
220   {
221     GCTraceTime(Debug, gc, phases) tm_m(&quot;Weak Processing&quot;, gc_timer());
222     WeakProcessor::weak_oops_do(&amp;is_alive, &amp;do_nothing_cl);
223   }
224 
225   {
226     GCTraceTime(Debug, gc, phases) tm_m(&quot;Class Unloading&quot;, gc_timer());
227 
228     // Unload classes and purge the SystemDictionary.
229     bool purged_class = SystemDictionary::do_unloading(gc_timer());
230 
231     // Unload nmethods.
232     CodeCache::do_unloading(&amp;is_alive, purged_class);
233 
234     // Prune dead klasses from subklass/sibling/implementor lists.
235     Klass::clean_weak_klass_links(purged_class);
<a name="4" id="anc4"></a>


236   }
237 
238   gc_tracer()-&gt;report_object_count_after_gc(&amp;is_alive);
239 }
240 
241 
242 void GenMarkSweep::mark_sweep_phase2() {
243   // Now all live objects are marked, compute the new object addresses.
244 
245   // It is imperative that we traverse perm_gen LAST. If dead space is
246   // allowed a range of dead object may get overwritten by a dead int
247   // array. If perm_gen is not traversed last a Klass* may get
248   // overwritten. This is fine since it is dead, but if the class has dead
249   // instances we have to skip them, and in order to find their size we
250   // need the Klass*!
251   //
252   // It is not required that we traverse spaces in the same order in
253   // phase2, phase3 and phase4, but the ValidateMarkSweep live oops
254   // tracking expects us to do so. See comment under phase4.
255 
256   GenCollectedHeap* gch = GenCollectedHeap::heap();
257 
258   GCTraceTime(Info, gc, phases) tm(&quot;Phase 2: Compute new object addresses&quot;, _gc_timer);
259 
260   gch-&gt;prepare_for_compaction();
261 }
262 
263 class GenAdjustPointersClosure: public GenCollectedHeap::GenClosure {
264 public:
265   void do_generation(Generation* gen) {
266     gen-&gt;adjust_pointers();
267   }
268 };
269 
270 void GenMarkSweep::mark_sweep_phase3() {
271   GenCollectedHeap* gch = GenCollectedHeap::heap();
272 
273   // Adjust the pointers to reflect the new locations
274   GCTraceTime(Info, gc, phases) tm(&quot;Phase 3: Adjust pointers&quot;, gc_timer());
275 
276   // Need new claim bits for the pointer adjustment tracing.
277   ClassLoaderDataGraph::clear_claimed_marks();
278 
279   // Because the closure below is created statically, we cannot
280   // use OopsInGenClosure constructor which takes a generation,
281   // as the Universe has not been created when the static constructors
282   // are run.
283   adjust_pointer_closure.set_orig_generation(gch-&gt;old_gen());
284 
285   {
286     StrongRootsScope srs(1);
287 
288     gch-&gt;full_process_roots(&amp;srs,
289                             true,  // this is the adjust phase
290                             GenCollectedHeap::SO_AllCodeCache,
291                             false, // all roots
292                             &amp;adjust_pointer_closure,
293                             &amp;adjust_cld_closure);
294   }
295 
296   gch-&gt;gen_process_weak_roots(&amp;adjust_pointer_closure);
297 
298   adjust_marks();
299   GenAdjustPointersClosure blk;
300   gch-&gt;generation_iterate(&amp;blk, true);
301 }
302 
303 class GenCompactClosure: public GenCollectedHeap::GenClosure {
304 public:
305   void do_generation(Generation* gen) {
306     gen-&gt;compact();
307   }
308 };
309 
310 void GenMarkSweep::mark_sweep_phase4() {
311   // All pointers are now adjusted, move objects accordingly
312 
313   // It is imperative that we traverse perm_gen first in phase4. All
314   // classes must be allocated earlier than their instances, and traversing
315   // perm_gen first makes sure that all Klass*s have moved to their new
316   // location before any instance does a dispatch through it&#39;s klass!
317 
318   // The ValidateMarkSweep live oops tracking expects us to traverse spaces
319   // in the same order in phase2, phase3 and phase4. We don&#39;t quite do that
320   // here (perm_gen first rather than last), so we tell the validate code
321   // to use a higher index (saved from phase2) when verifying perm_gen.
322   GenCollectedHeap* gch = GenCollectedHeap::heap();
323 
324   GCTraceTime(Info, gc, phases) tm(&quot;Phase 4: Move objects&quot;, _gc_timer);
325 
326   GenCompactClosure blk;
327   gch-&gt;generation_iterate(&amp;blk, true);
328 }
<a name="5" id="anc5"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="5" type="hidden" />
</body>
</html>