<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/shared/space.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="space.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="space.inline.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shared/space.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_GC_SHARED_SPACE_HPP
 26 #define SHARE_GC_SHARED_SPACE_HPP
 27 
 28 #include &quot;gc/shared/blockOffsetTable.hpp&quot;
 29 #include &quot;gc/shared/cardTable.hpp&quot;
 30 #include &quot;gc/shared/workgroup.hpp&quot;
 31 #include &quot;memory/allocation.hpp&quot;
 32 #include &quot;memory/iterator.hpp&quot;
 33 #include &quot;memory/memRegion.hpp&quot;
<span class="line-modified"> 34 #include &quot;oops/markOop.hpp&quot;</span>
 35 #include &quot;runtime/mutexLocker.hpp&quot;
 36 #include &quot;utilities/align.hpp&quot;
 37 #include &quot;utilities/macros.hpp&quot;
 38 
 39 // A space is an abstraction for the &quot;storage units&quot; backing
 40 // up the generation abstraction. It includes specific
 41 // implementations for keeping track of free and used space,
 42 // for iterating over objects and free blocks, etc.
 43 
 44 // Forward decls.
 45 class Space;
 46 class BlockOffsetArray;
 47 class BlockOffsetArrayContigSpace;
 48 class Generation;
 49 class CompactibleSpace;
 50 class BlockOffsetTable;
 51 class CardTableRS;
 52 class DirtyCardToOopClosure;
 53 
 54 // A Space describes a heap area. Class Space is an abstract
 55 // base class.
 56 //
 57 // Space supports allocation, size computation and GC support is provided.
 58 //
 59 // Invariant: bottom() and end() are on page_size boundaries and
 60 // bottom() &lt;= top() &lt;= end()
 61 // top() is inclusive and end() is exclusive.
 62 
 63 class Space: public CHeapObj&lt;mtGC&gt; {
 64   friend class VMStructs;
 65  protected:
 66   HeapWord* _bottom;
 67   HeapWord* _end;
 68 
 69   // Used in support of save_marks()
 70   HeapWord* _saved_mark_word;
 71 
<span class="line-removed"> 72   // A sequential tasks done structure. This supports</span>
<span class="line-removed"> 73   // parallel GC, where we have threads dynamically</span>
<span class="line-removed"> 74   // claiming sub-tasks from a larger parallel task.</span>
<span class="line-removed"> 75   SequentialSubTasksDone _par_seq_tasks;</span>
<span class="line-removed"> 76 </span>
 77   Space():
 78     _bottom(NULL), _end(NULL) { }
 79 
 80  public:
 81   // Accessors
 82   HeapWord* bottom() const         { return _bottom; }
 83   HeapWord* end() const            { return _end;    }
 84   virtual void set_bottom(HeapWord* value) { _bottom = value; }
 85   virtual void set_end(HeapWord* value)    { _end = value; }
 86 
 87   virtual HeapWord* saved_mark_word() const  { return _saved_mark_word; }
 88 
 89   void set_saved_mark_word(HeapWord* p) { _saved_mark_word = p; }
 90 
 91   // Returns true if this object has been allocated since a
 92   // generation&#39;s &quot;save_marks&quot; call.
 93   virtual bool obj_allocated_since_save_marks(const oop obj) const {
<span class="line-modified"> 94     return (HeapWord*)obj &gt;= saved_mark_word();</span>
<span class="line-removed"> 95   }</span>
<span class="line-removed"> 96 </span>
<span class="line-removed"> 97   virtual MemRegionClosure* preconsumptionDirtyCardClosure() const {</span>
<span class="line-removed"> 98     return NULL;</span>
 99   }
100 
101   // Returns a subregion of the space containing only the allocated objects in
102   // the space.
103   virtual MemRegion used_region() const = 0;
104 
105   // Returns a region that is guaranteed to contain (at least) all objects
106   // allocated at the time of the last call to &quot;save_marks&quot;.  If the space
107   // initializes its DirtyCardToOopClosure&#39;s specifying the &quot;contig&quot; option
108   // (that is, if the space is contiguous), then this region must contain only
109   // such objects: the memregion will be from the bottom of the region to the
110   // saved mark.  Otherwise, the &quot;obj_allocated_since_save_marks&quot; method of
111   // the space must distinguish between objects in the region allocated before
112   // and after the call to save marks.
113   MemRegion used_region_at_save_marks() const {
114     return MemRegion(bottom(), saved_mark_word());
115   }
116 
117   // Initialization.
118   // &quot;initialize&quot; should be called once on a space, before it is used for
</pre>
<hr />
<pre>
158 
159   // Test whether p is double-aligned
160   static bool is_aligned(void* p) {
161     return ::is_aligned(p, sizeof(double));
162   }
163 
164   // Size computations.  Sizes are in bytes.
165   size_t capacity()     const { return byte_size(bottom(), end()); }
166   virtual size_t used() const = 0;
167   virtual size_t free() const = 0;
168 
169   // Iterate over all the ref-containing fields of all objects in the
170   // space, calling &quot;cl.do_oop&quot; on each.  Fields in objects allocated by
171   // applications of the closure are not included in the iteration.
172   virtual void oop_iterate(OopIterateClosure* cl);
173 
174   // Iterate over all objects in the space, calling &quot;cl.do_object&quot; on
175   // each.  Objects allocated by applications of the closure are not
176   // included in the iteration.
177   virtual void object_iterate(ObjectClosure* blk) = 0;
<span class="line-removed">178   // Similar to object_iterate() except only iterates over</span>
<span class="line-removed">179   // objects whose internal references point to objects in the space.</span>
<span class="line-removed">180   virtual void safe_object_iterate(ObjectClosure* blk) = 0;</span>
181 
182   // Create and return a new dirty card to oop closure. Can be
183   // overridden to return the appropriate type of closure
184   // depending on the type of space in which the closure will
185   // operate. ResourceArea allocated.
186   virtual DirtyCardToOopClosure* new_dcto_cl(OopIterateClosure* cl,
187                                              CardTable::PrecisionStyle precision,
188                                              HeapWord* boundary,
189                                              bool parallel);
190 
191   // If &quot;p&quot; is in the space, returns the address of the start of the
192   // &quot;block&quot; that contains &quot;p&quot;.  We say &quot;block&quot; instead of &quot;object&quot; since
193   // some heaps may not pack objects densely; a chunk may either be an
194   // object or a non-object.  If &quot;p&quot; is not in the space, return NULL.
195   virtual HeapWord* block_start_const(const void* p) const = 0;
196 
197   // The non-const version may have benevolent side effects on the data
198   // structure supporting these calls, possibly speeding up future calls.
199   // The default implementation, however, is simply to call the const
200   // version.
</pre>
<hr />
<pre>
215 
216   // Allocation (return NULL if full).  Assumes the caller has established
217   // mutually exclusive access to the space.
218   virtual HeapWord* allocate(size_t word_size) = 0;
219 
220   // Allocation (return NULL if full).  Enforces mutual exclusion internally.
221   virtual HeapWord* par_allocate(size_t word_size) = 0;
222 
223 #if INCLUDE_SERIALGC
224   // Mark-sweep-compact support: all spaces can update pointers to objects
225   // moving as a part of compaction.
226   virtual void adjust_pointers() = 0;
227 #endif
228 
229   virtual void print() const;
230   virtual void print_on(outputStream* st) const;
231   virtual void print_short() const;
232   virtual void print_short_on(outputStream* st) const;
233 
234 
<span class="line-removed">235   // Accessor for parallel sequential tasks.</span>
<span class="line-removed">236   SequentialSubTasksDone* par_seq_tasks() { return &amp;_par_seq_tasks; }</span>
<span class="line-removed">237 </span>
238   // IF &quot;this&quot; is a ContiguousSpace, return it, else return NULL.
239   virtual ContiguousSpace* toContiguousSpace() {
240     return NULL;
241   }
242 
243   // Debugging
244   virtual void verify() const = 0;
245 };
246 
247 // A MemRegionClosure (ResourceObj) whose &quot;do_MemRegion&quot; function applies an
248 // OopClosure to (the addresses of) all the ref-containing fields that could
249 // be modified by virtue of the given MemRegion being dirty. (Note that
250 // because of the imprecise nature of the write barrier, this may iterate
251 // over oops beyond the region.)
252 // This base type for dirty card to oop closures handles memory regions
253 // in non-contiguous spaces with no boundaries, and should be sub-classed
254 // to support other space types. See ContiguousDCTOC for a sub-class
255 // that works with ContiguousSpaces.
256 
257 class DirtyCardToOopClosure: public MemRegionClosureRO {
</pre>
<hr />
<pre>
339 // NOTE: Any subclasses to CompactibleSpace wanting to change/define the behavior
340 // in any of the auxiliary functions must also override the corresponding
341 // prepare_for_compaction/adjust_pointers/compact functions using them.
342 // If not, such changes will not be used or have no effect on the compaction operations.
343 //
344 // This translates to the following dependencies:
345 // Overrides/definitions of
346 //  - scan_limit
347 //  - scanned_block_is_obj
348 //  - scanned_block_size
349 // require override/definition of prepare_for_compaction().
350 // Similar dependencies exist between
351 //  - adjust_obj_size  and adjust_pointers()
352 //  - obj_size         and compact().
353 //
354 // Additionally, this also means that changes to block_size() or block_is_obj() that
355 // should be effective during the compaction operations must provide a corresponding
356 // definition of scanned_block_size/scanned_block_is_obj respectively.
357 class CompactibleSpace: public Space {
358   friend class VMStructs;
<span class="line-removed">359   friend class CompactibleFreeListSpace;</span>
360 private:
361   HeapWord* _compaction_top;
362   CompactibleSpace* _next_compaction_space;
363 
364   // Auxiliary functions for scan_and_{forward,adjust_pointers,compact} support.
365   inline size_t adjust_obj_size(size_t size) const {
366     return size;
367   }
368 
369   inline size_t obj_size(const HeapWord* addr) const;
370 
371   template &lt;class SpaceType&gt;
372   static inline void verify_up_to_first_dead(SpaceType* space) NOT_DEBUG_RETURN;
373 
374   template &lt;class SpaceType&gt;
375   static inline void clear_empty_region(SpaceType* space);
376 
377 public:
378   CompactibleSpace() :
379    _compaction_top(NULL), _next_compaction_space(NULL) {}
</pre>
<hr />
<pre>
445   // be one, since compaction must succeed -- we go to the first space of
446   // the previous generation if necessary, updating &quot;cp&quot;), reset compact_top
447   // and then forward.  In either case, returns the new value of &quot;compact_top&quot;.
448   // If the forwarding crosses &quot;cp-&gt;threshold&quot;, invokes the &quot;cross_threshold&quot;
449   // function of the then-current compaction space, and updates &quot;cp-&gt;threshold
450   // accordingly&quot;.
451   virtual HeapWord* forward(oop q, size_t size, CompactPoint* cp,
452                     HeapWord* compact_top);
453 
454   // Return a size with adjustments as required of the space.
455   virtual size_t adjust_object_size_v(size_t size) const { return size; }
456 
457   void set_first_dead(HeapWord* value) { _first_dead = value; }
458   void set_end_of_live(HeapWord* value) { _end_of_live = value; }
459 
460 protected:
461   // Used during compaction.
462   HeapWord* _first_dead;
463   HeapWord* _end_of_live;
464 
<span class="line-removed">465   // Minimum size of a free block.</span>
<span class="line-removed">466   virtual size_t minimum_free_block_size() const { return 0; }</span>
<span class="line-removed">467 </span>
468   // This the function is invoked when an allocation of an object covering
469   // &quot;start&quot; to &quot;end occurs crosses the threshold; returns the next
470   // threshold.  (The default implementation does nothing.)
471   virtual HeapWord* cross_threshold(HeapWord* start, HeapWord* the_end) {
472     return end();
473   }
474 
475   // Below are template functions for scan_and_* algorithms (avoiding virtual calls).
476   // The space argument should be a subclass of CompactibleSpace, implementing
477   // scan_limit(), scanned_block_is_obj(), and scanned_block_size(),
478   // and possibly also overriding obj_size(), and adjust_obj_size().
479   // These functions should avoid virtual calls whenever possible.
480 
481 #if INCLUDE_SERIALGC
482   // Frequently calls adjust_obj_size().
483   template &lt;class SpaceType&gt;
484   static inline void scan_and_adjust_pointers(SpaceType* space);
485 #endif
486 
487   // Frequently calls obj_size().
</pre>
<hr />
<pre>
567 
568   // Size computations: sizes in bytes.
569   size_t capacity() const        { return byte_size(bottom(), end()); }
570   size_t used() const            { return byte_size(bottom(), top()); }
571   size_t free() const            { return byte_size(top(),    end()); }
572 
573   virtual bool is_free_block(const HeapWord* p) const;
574 
575   // In a contiguous space we have a more obvious bound on what parts
576   // contain objects.
577   MemRegion used_region() const { return MemRegion(bottom(), top()); }
578 
579   // Allocation (return NULL if full)
580   virtual HeapWord* allocate(size_t word_size);
581   virtual HeapWord* par_allocate(size_t word_size);
582   HeapWord* allocate_aligned(size_t word_size);
583 
584   // Iteration
585   void oop_iterate(OopIterateClosure* cl);
586   void object_iterate(ObjectClosure* blk);
<span class="line-modified">587   // For contiguous spaces this method will iterate safely over objects</span>
<span class="line-removed">588   // in the space (i.e., between bottom and top) when at a safepoint.</span>
<span class="line-removed">589   void safe_object_iterate(ObjectClosure* blk);</span>
<span class="line-removed">590 </span>
<span class="line-removed">591   // Iterate over as many initialized objects in the space as possible,</span>
<span class="line-removed">592   // calling &quot;cl.do_object_careful&quot; on each. Return NULL if all objects</span>
<span class="line-removed">593   // in the space (at the start of the iteration) were iterated over.</span>
<span class="line-removed">594   // Return an address indicating the extent of the iteration in the</span>
<span class="line-removed">595   // event that the iteration had to return because of finding an</span>
<span class="line-removed">596   // uninitialized object in the space, or if the closure &quot;cl&quot;</span>
<span class="line-removed">597   // signaled early termination.</span>
<span class="line-removed">598   HeapWord* object_iterate_careful(ObjectClosureCareful* cl);</span>
599   HeapWord* concurrent_iteration_safe_limit() {
600     assert(_concurrent_iteration_safe_limit &lt;= top(),
601            &quot;_concurrent_iteration_safe_limit update missed&quot;);
602     return _concurrent_iteration_safe_limit;
603   }
604   // changes the safe limit, all objects from bottom() to the new
605   // limit should be properly initialized
606   void set_concurrent_iteration_safe_limit(HeapWord* new_limit) {
607     assert(new_limit &lt;= top(), &quot;uninitialized objects in the safe range&quot;);
608     _concurrent_iteration_safe_limit = new_limit;
609   }
610 
<span class="line-removed">611   // In support of parallel oop_iterate.</span>
<span class="line-removed">612   template &lt;typename OopClosureType&gt;</span>
<span class="line-removed">613   void par_oop_iterate(MemRegion mr, OopClosureType* blk);</span>
<span class="line-removed">614 </span>
615   // Compaction support
616   virtual void reset_after_compaction() {
617     assert(compaction_top() &gt;= bottom() &amp;&amp; compaction_top() &lt;= end(), &quot;should point inside space&quot;);
618     set_top(compaction_top());
619     // set new iteration safe limit
620     set_concurrent_iteration_safe_limit(compaction_top());
621   }
622 
623   // Override.
624   DirtyCardToOopClosure* new_dcto_cl(OopIterateClosure* cl,
625                                      CardTable::PrecisionStyle precision,
626                                      HeapWord* boundary,
627                                      bool parallel);
628 
629   // Apply &quot;blk-&gt;do_oop&quot; to the addresses of all reference fields in objects
630   // starting with the _saved_mark_word, which was noted during a generation&#39;s
631   // save_marks and is required to denote the head of an object.
632   // Fields in objects allocated by applications of the closure
633   // *are* included in the iteration.
634   // Updates _saved_mark_word to point to just after the last object
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_GC_SHARED_SPACE_HPP
 26 #define SHARE_GC_SHARED_SPACE_HPP
 27 
 28 #include &quot;gc/shared/blockOffsetTable.hpp&quot;
 29 #include &quot;gc/shared/cardTable.hpp&quot;
 30 #include &quot;gc/shared/workgroup.hpp&quot;
 31 #include &quot;memory/allocation.hpp&quot;
 32 #include &quot;memory/iterator.hpp&quot;
 33 #include &quot;memory/memRegion.hpp&quot;
<span class="line-modified"> 34 #include &quot;oops/markWord.hpp&quot;</span>
 35 #include &quot;runtime/mutexLocker.hpp&quot;
 36 #include &quot;utilities/align.hpp&quot;
 37 #include &quot;utilities/macros.hpp&quot;
 38 
 39 // A space is an abstraction for the &quot;storage units&quot; backing
 40 // up the generation abstraction. It includes specific
 41 // implementations for keeping track of free and used space,
 42 // for iterating over objects and free blocks, etc.
 43 
 44 // Forward decls.
 45 class Space;
 46 class BlockOffsetArray;
 47 class BlockOffsetArrayContigSpace;
 48 class Generation;
 49 class CompactibleSpace;
 50 class BlockOffsetTable;
 51 class CardTableRS;
 52 class DirtyCardToOopClosure;
 53 
 54 // A Space describes a heap area. Class Space is an abstract
 55 // base class.
 56 //
 57 // Space supports allocation, size computation and GC support is provided.
 58 //
 59 // Invariant: bottom() and end() are on page_size boundaries and
 60 // bottom() &lt;= top() &lt;= end()
 61 // top() is inclusive and end() is exclusive.
 62 
 63 class Space: public CHeapObj&lt;mtGC&gt; {
 64   friend class VMStructs;
 65  protected:
 66   HeapWord* _bottom;
 67   HeapWord* _end;
 68 
 69   // Used in support of save_marks()
 70   HeapWord* _saved_mark_word;
 71 





 72   Space():
 73     _bottom(NULL), _end(NULL) { }
 74 
 75  public:
 76   // Accessors
 77   HeapWord* bottom() const         { return _bottom; }
 78   HeapWord* end() const            { return _end;    }
 79   virtual void set_bottom(HeapWord* value) { _bottom = value; }
 80   virtual void set_end(HeapWord* value)    { _end = value; }
 81 
 82   virtual HeapWord* saved_mark_word() const  { return _saved_mark_word; }
 83 
 84   void set_saved_mark_word(HeapWord* p) { _saved_mark_word = p; }
 85 
 86   // Returns true if this object has been allocated since a
 87   // generation&#39;s &quot;save_marks&quot; call.
 88   virtual bool obj_allocated_since_save_marks(const oop obj) const {
<span class="line-modified"> 89     return cast_from_oop&lt;HeapWord*&gt;(obj) &gt;= saved_mark_word();</span>




 90   }
 91 
 92   // Returns a subregion of the space containing only the allocated objects in
 93   // the space.
 94   virtual MemRegion used_region() const = 0;
 95 
 96   // Returns a region that is guaranteed to contain (at least) all objects
 97   // allocated at the time of the last call to &quot;save_marks&quot;.  If the space
 98   // initializes its DirtyCardToOopClosure&#39;s specifying the &quot;contig&quot; option
 99   // (that is, if the space is contiguous), then this region must contain only
100   // such objects: the memregion will be from the bottom of the region to the
101   // saved mark.  Otherwise, the &quot;obj_allocated_since_save_marks&quot; method of
102   // the space must distinguish between objects in the region allocated before
103   // and after the call to save marks.
104   MemRegion used_region_at_save_marks() const {
105     return MemRegion(bottom(), saved_mark_word());
106   }
107 
108   // Initialization.
109   // &quot;initialize&quot; should be called once on a space, before it is used for
</pre>
<hr />
<pre>
149 
150   // Test whether p is double-aligned
151   static bool is_aligned(void* p) {
152     return ::is_aligned(p, sizeof(double));
153   }
154 
155   // Size computations.  Sizes are in bytes.
156   size_t capacity()     const { return byte_size(bottom(), end()); }
157   virtual size_t used() const = 0;
158   virtual size_t free() const = 0;
159 
160   // Iterate over all the ref-containing fields of all objects in the
161   // space, calling &quot;cl.do_oop&quot; on each.  Fields in objects allocated by
162   // applications of the closure are not included in the iteration.
163   virtual void oop_iterate(OopIterateClosure* cl);
164 
165   // Iterate over all objects in the space, calling &quot;cl.do_object&quot; on
166   // each.  Objects allocated by applications of the closure are not
167   // included in the iteration.
168   virtual void object_iterate(ObjectClosure* blk) = 0;



169 
170   // Create and return a new dirty card to oop closure. Can be
171   // overridden to return the appropriate type of closure
172   // depending on the type of space in which the closure will
173   // operate. ResourceArea allocated.
174   virtual DirtyCardToOopClosure* new_dcto_cl(OopIterateClosure* cl,
175                                              CardTable::PrecisionStyle precision,
176                                              HeapWord* boundary,
177                                              bool parallel);
178 
179   // If &quot;p&quot; is in the space, returns the address of the start of the
180   // &quot;block&quot; that contains &quot;p&quot;.  We say &quot;block&quot; instead of &quot;object&quot; since
181   // some heaps may not pack objects densely; a chunk may either be an
182   // object or a non-object.  If &quot;p&quot; is not in the space, return NULL.
183   virtual HeapWord* block_start_const(const void* p) const = 0;
184 
185   // The non-const version may have benevolent side effects on the data
186   // structure supporting these calls, possibly speeding up future calls.
187   // The default implementation, however, is simply to call the const
188   // version.
</pre>
<hr />
<pre>
203 
204   // Allocation (return NULL if full).  Assumes the caller has established
205   // mutually exclusive access to the space.
206   virtual HeapWord* allocate(size_t word_size) = 0;
207 
208   // Allocation (return NULL if full).  Enforces mutual exclusion internally.
209   virtual HeapWord* par_allocate(size_t word_size) = 0;
210 
211 #if INCLUDE_SERIALGC
212   // Mark-sweep-compact support: all spaces can update pointers to objects
213   // moving as a part of compaction.
214   virtual void adjust_pointers() = 0;
215 #endif
216 
217   virtual void print() const;
218   virtual void print_on(outputStream* st) const;
219   virtual void print_short() const;
220   virtual void print_short_on(outputStream* st) const;
221 
222 



223   // IF &quot;this&quot; is a ContiguousSpace, return it, else return NULL.
224   virtual ContiguousSpace* toContiguousSpace() {
225     return NULL;
226   }
227 
228   // Debugging
229   virtual void verify() const = 0;
230 };
231 
232 // A MemRegionClosure (ResourceObj) whose &quot;do_MemRegion&quot; function applies an
233 // OopClosure to (the addresses of) all the ref-containing fields that could
234 // be modified by virtue of the given MemRegion being dirty. (Note that
235 // because of the imprecise nature of the write barrier, this may iterate
236 // over oops beyond the region.)
237 // This base type for dirty card to oop closures handles memory regions
238 // in non-contiguous spaces with no boundaries, and should be sub-classed
239 // to support other space types. See ContiguousDCTOC for a sub-class
240 // that works with ContiguousSpaces.
241 
242 class DirtyCardToOopClosure: public MemRegionClosureRO {
</pre>
<hr />
<pre>
324 // NOTE: Any subclasses to CompactibleSpace wanting to change/define the behavior
325 // in any of the auxiliary functions must also override the corresponding
326 // prepare_for_compaction/adjust_pointers/compact functions using them.
327 // If not, such changes will not be used or have no effect on the compaction operations.
328 //
329 // This translates to the following dependencies:
330 // Overrides/definitions of
331 //  - scan_limit
332 //  - scanned_block_is_obj
333 //  - scanned_block_size
334 // require override/definition of prepare_for_compaction().
335 // Similar dependencies exist between
336 //  - adjust_obj_size  and adjust_pointers()
337 //  - obj_size         and compact().
338 //
339 // Additionally, this also means that changes to block_size() or block_is_obj() that
340 // should be effective during the compaction operations must provide a corresponding
341 // definition of scanned_block_size/scanned_block_is_obj respectively.
342 class CompactibleSpace: public Space {
343   friend class VMStructs;

344 private:
345   HeapWord* _compaction_top;
346   CompactibleSpace* _next_compaction_space;
347 
348   // Auxiliary functions for scan_and_{forward,adjust_pointers,compact} support.
349   inline size_t adjust_obj_size(size_t size) const {
350     return size;
351   }
352 
353   inline size_t obj_size(const HeapWord* addr) const;
354 
355   template &lt;class SpaceType&gt;
356   static inline void verify_up_to_first_dead(SpaceType* space) NOT_DEBUG_RETURN;
357 
358   template &lt;class SpaceType&gt;
359   static inline void clear_empty_region(SpaceType* space);
360 
361 public:
362   CompactibleSpace() :
363    _compaction_top(NULL), _next_compaction_space(NULL) {}
</pre>
<hr />
<pre>
429   // be one, since compaction must succeed -- we go to the first space of
430   // the previous generation if necessary, updating &quot;cp&quot;), reset compact_top
431   // and then forward.  In either case, returns the new value of &quot;compact_top&quot;.
432   // If the forwarding crosses &quot;cp-&gt;threshold&quot;, invokes the &quot;cross_threshold&quot;
433   // function of the then-current compaction space, and updates &quot;cp-&gt;threshold
434   // accordingly&quot;.
435   virtual HeapWord* forward(oop q, size_t size, CompactPoint* cp,
436                     HeapWord* compact_top);
437 
438   // Return a size with adjustments as required of the space.
439   virtual size_t adjust_object_size_v(size_t size) const { return size; }
440 
441   void set_first_dead(HeapWord* value) { _first_dead = value; }
442   void set_end_of_live(HeapWord* value) { _end_of_live = value; }
443 
444 protected:
445   // Used during compaction.
446   HeapWord* _first_dead;
447   HeapWord* _end_of_live;
448 



449   // This the function is invoked when an allocation of an object covering
450   // &quot;start&quot; to &quot;end occurs crosses the threshold; returns the next
451   // threshold.  (The default implementation does nothing.)
452   virtual HeapWord* cross_threshold(HeapWord* start, HeapWord* the_end) {
453     return end();
454   }
455 
456   // Below are template functions for scan_and_* algorithms (avoiding virtual calls).
457   // The space argument should be a subclass of CompactibleSpace, implementing
458   // scan_limit(), scanned_block_is_obj(), and scanned_block_size(),
459   // and possibly also overriding obj_size(), and adjust_obj_size().
460   // These functions should avoid virtual calls whenever possible.
461 
462 #if INCLUDE_SERIALGC
463   // Frequently calls adjust_obj_size().
464   template &lt;class SpaceType&gt;
465   static inline void scan_and_adjust_pointers(SpaceType* space);
466 #endif
467 
468   // Frequently calls obj_size().
</pre>
<hr />
<pre>
548 
549   // Size computations: sizes in bytes.
550   size_t capacity() const        { return byte_size(bottom(), end()); }
551   size_t used() const            { return byte_size(bottom(), top()); }
552   size_t free() const            { return byte_size(top(),    end()); }
553 
554   virtual bool is_free_block(const HeapWord* p) const;
555 
556   // In a contiguous space we have a more obvious bound on what parts
557   // contain objects.
558   MemRegion used_region() const { return MemRegion(bottom(), top()); }
559 
560   // Allocation (return NULL if full)
561   virtual HeapWord* allocate(size_t word_size);
562   virtual HeapWord* par_allocate(size_t word_size);
563   HeapWord* allocate_aligned(size_t word_size);
564 
565   // Iteration
566   void oop_iterate(OopIterateClosure* cl);
567   void object_iterate(ObjectClosure* blk);
<span class="line-modified">568 </span>











569   HeapWord* concurrent_iteration_safe_limit() {
570     assert(_concurrent_iteration_safe_limit &lt;= top(),
571            &quot;_concurrent_iteration_safe_limit update missed&quot;);
572     return _concurrent_iteration_safe_limit;
573   }
574   // changes the safe limit, all objects from bottom() to the new
575   // limit should be properly initialized
576   void set_concurrent_iteration_safe_limit(HeapWord* new_limit) {
577     assert(new_limit &lt;= top(), &quot;uninitialized objects in the safe range&quot;);
578     _concurrent_iteration_safe_limit = new_limit;
579   }
580 




581   // Compaction support
582   virtual void reset_after_compaction() {
583     assert(compaction_top() &gt;= bottom() &amp;&amp; compaction_top() &lt;= end(), &quot;should point inside space&quot;);
584     set_top(compaction_top());
585     // set new iteration safe limit
586     set_concurrent_iteration_safe_limit(compaction_top());
587   }
588 
589   // Override.
590   DirtyCardToOopClosure* new_dcto_cl(OopIterateClosure* cl,
591                                      CardTable::PrecisionStyle precision,
592                                      HeapWord* boundary,
593                                      bool parallel);
594 
595   // Apply &quot;blk-&gt;do_oop&quot; to the addresses of all reference fields in objects
596   // starting with the _saved_mark_word, which was noted during a generation&#39;s
597   // save_marks and is required to denote the head of an object.
598   // Fields in objects allocated by applications of the closure
599   // *are* included in the iteration.
600   // Updates _saved_mark_word to point to just after the last object
</pre>
</td>
</tr>
</table>
<center><a href="space.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="space.inline.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>