<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff src/hotspot/share/gc/shared/memAllocator.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="markBitMap.inline.hpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="memAllocator.hpp.udiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shared/memAllocator.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -1,7 +1,7 @@</span>
  /*
<span class="udiff-line-modified-removed">-  * Copyright (c) 2018, Oracle and/or its affiliates. All rights reserved.</span>
<span class="udiff-line-modified-added">+  * Copyright (c) 2018, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -141,11 +141,10 @@</span>
  
  void MemAllocator::Allocation::verify_before() {
    // Clear unhandled oops for memory allocation.  Memory allocation might
    // not take out a lock if from tlab, so clear here.
    Thread* THREAD = _thread;
<span class="udiff-line-removed">-   CHECK_UNHANDLED_OOPS_ONLY(THREAD-&gt;clear_unhandled_oops();)</span>
    assert(!HAS_PENDING_EXCEPTION, &quot;Should not allocate with exception pending&quot;);
    debug_only(check_for_valid_allocation_state());
    assert(!Universe::heap()-&gt;is_gc_active(), &quot;Allocation during gc not allowed&quot;);
  }
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -170,18 +169,12 @@</span>
    // How to choose between a pending exception and a potential
    // OutOfMemoryError?  Don&#39;t allow pending exceptions.
    // This is a VM policy failure, so how do we exhaustively test it?
    assert(!_thread-&gt;has_pending_exception(),
           &quot;shouldn&#39;t be allocating with pending exception&quot;);
<span class="udiff-line-modified-removed">-   if (StrictSafepointChecks) {</span>
<span class="udiff-line-modified-removed">-     assert(_thread-&gt;allow_allocation(),</span>
<span class="udiff-line-removed">-            &quot;Allocation done by thread for which allocation is blocked &quot;</span>
<span class="udiff-line-removed">-            &quot;by No_Allocation_Verifier!&quot;);</span>
<span class="udiff-line-removed">-     // Allocation of an oop can always invoke a safepoint,</span>
<span class="udiff-line-removed">-     // hence, the true argument</span>
<span class="udiff-line-removed">-     _thread-&gt;check_for_valid_safepoint_state(true);</span>
<span class="udiff-line-removed">-   }</span>
<span class="udiff-line-modified-added">+   // Allocation of an oop can always invoke a safepoint.</span>
<span class="udiff-line-modified-added">+   _thread-&gt;check_for_valid_safepoint_state();</span>
  }
  #endif
  
  void MemAllocator::Allocation::notify_allocation_jvmti_sampler() {
    // support for JVMTI VMObjectAlloc event (no-op if not enabled)
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -196,49 +189,56 @@</span>
      // Sample if it&#39;s a non-TLAB allocation, or a TLAB allocation that either refills the TLAB
      // or expands it due to taking a sampler induced slow path.
      return;
    }
  
<span class="udiff-line-modified-removed">-   if (JvmtiExport::should_post_sampled_object_alloc()) {</span>
<span class="udiff-line-modified-removed">-     // If we want to be sampling, protect the allocated object with a Handle</span>
<span class="udiff-line-modified-removed">-     // before doing the callback. The callback is done in the destructor of</span>
<span class="udiff-line-modified-removed">-     // the JvmtiSampledObjectAllocEventCollector.</span>
<span class="udiff-line-modified-added">+   // If we want to be sampling, protect the allocated object with a Handle</span>
<span class="udiff-line-modified-added">+   // before doing the callback. The callback is done in the destructor of</span>
<span class="udiff-line-modified-added">+   // the JvmtiSampledObjectAllocEventCollector.</span>
<span class="udiff-line-modified-added">+   size_t bytes_since_last = 0;</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   {</span>
      PreserveObj obj_h(_thread, _obj_ptr);
      JvmtiSampledObjectAllocEventCollector collector;
      size_t size_in_bytes = _allocator._word_size * HeapWordSize;
      ThreadLocalAllocBuffer&amp; tlab = _thread-&gt;tlab();
<span class="udiff-line-modified-removed">-     size_t bytes_since_last = _allocated_outside_tlab ? 0 : tlab.bytes_since_last_sample_point();</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-added">+     if (!_allocated_outside_tlab) {</span>
<span class="udiff-line-added">+       bytes_since_last = tlab.bytes_since_last_sample_point();</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+ </span>
      _thread-&gt;heap_sampler().check_for_sampling(obj_h(), size_in_bytes, bytes_since_last);
    }
  
    if (_tlab_end_reset_for_sample || _allocated_tlab_size != 0) {
<span class="udiff-line-modified-removed">-     _thread-&gt;tlab().set_sample_end();</span>
<span class="udiff-line-modified-added">+     // Tell tlab to forget bytes_since_last if we passed it to the heap sampler.</span>
<span class="udiff-line-added">+     _thread-&gt;tlab().set_sample_end(bytes_since_last != 0);</span>
    }
  }
  
  void MemAllocator::Allocation::notify_allocation_low_memory_detector() {
    // support low memory notifications (no-op if not enabled)
    LowMemoryDetector::detect_low_memory_for_collected_pools();
  }
  
  void MemAllocator::Allocation::notify_allocation_jfr_sampler() {
<span class="udiff-line-modified-removed">-   HeapWord* mem = (HeapWord*)obj();</span>
<span class="udiff-line-modified-added">+   HeapWord* mem = cast_from_oop&lt;HeapWord*&gt;(obj());</span>
    size_t size_in_bytes = _allocator._word_size * HeapWordSize;
  
    if (_allocated_outside_tlab) {
<span class="udiff-line-modified-removed">-     AllocTracer::send_allocation_outside_tlab(_allocator._klass, mem, size_in_bytes, _thread);</span>
<span class="udiff-line-modified-added">+     AllocTracer::send_allocation_outside_tlab(obj()-&gt;klass(), mem, size_in_bytes, _thread);</span>
    } else if (_allocated_tlab_size != 0) {
      // TLAB was refilled
<span class="udiff-line-modified-removed">-     AllocTracer::send_allocation_in_new_tlab(_allocator._klass, mem, _allocated_tlab_size * HeapWordSize,</span>
<span class="udiff-line-modified-added">+     AllocTracer::send_allocation_in_new_tlab(obj()-&gt;klass(), mem, _allocated_tlab_size * HeapWordSize,</span>
                                               size_in_bytes, _thread);
    }
  }
  
  void MemAllocator::Allocation::notify_allocation_dtrace_sampler() {
    if (DTraceAllocProbes) {
      // support for Dtrace object alloc event (no-op most of the time)
<span class="udiff-line-modified-removed">-     Klass* klass = _allocator._klass;</span>
<span class="udiff-line-modified-added">+     Klass* klass = obj()-&gt;klass();</span>
      size_t word_size = _allocator._word_size;
      if (klass != NULL &amp;&amp; klass-&gt;name() != NULL) {
        SharedRuntime::dtrace_object_alloc(obj(), (int)word_size);
      }
    }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -254,16 +254,16 @@</span>
    );
  }
  
  HeapWord* MemAllocator::allocate_outside_tlab(Allocation&amp; allocation) const {
    allocation._allocated_outside_tlab = true;
<span class="udiff-line-modified-removed">-   HeapWord* mem = _heap-&gt;mem_allocate(_word_size, &amp;allocation._overhead_limit_exceeded);</span>
<span class="udiff-line-modified-added">+   HeapWord* mem = Universe::heap()-&gt;mem_allocate(_word_size, &amp;allocation._overhead_limit_exceeded);</span>
    if (mem == NULL) {
      return mem;
    }
  
<span class="udiff-line-modified-removed">-   NOT_PRODUCT(_heap-&gt;check_for_non_bad_heap_word_value(mem, _word_size));</span>
<span class="udiff-line-modified-added">+   NOT_PRODUCT(Universe::heap()-&gt;check_for_non_bad_heap_word_value(mem, _word_size));</span>
    size_t size_in_bytes = _word_size * HeapWordSize;
    _thread-&gt;incr_allocated_bytes(size_in_bytes);
  
    return mem;
  }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -284,16 +284,18 @@</span>
  HeapWord* MemAllocator::allocate_inside_tlab_slow(Allocation&amp; allocation) const {
    HeapWord* mem = NULL;
    ThreadLocalAllocBuffer&amp; tlab = _thread-&gt;tlab();
  
    if (JvmtiExport::should_post_sampled_object_alloc()) {
<span class="udiff-line-removed">-     // Try to allocate the sampled object from TLAB, it is possible a sample</span>
<span class="udiff-line-removed">-     // point was put and the TLAB still has space.</span>
      tlab.set_back_allocation_end();
      mem = tlab.allocate(_word_size);
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // We set back the allocation sample point to try to allocate this, reset it</span>
<span class="udiff-line-added">+     // when done.</span>
<span class="udiff-line-added">+     allocation._tlab_end_reset_for_sample = true;</span>
<span class="udiff-line-added">+ </span>
      if (mem != NULL) {
<span class="udiff-line-removed">-       allocation._tlab_end_reset_for_sample = true;</span>
        return mem;
      }
    }
  
    // Retain tlab and allocate object in shared space if
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -314,11 +316,11 @@</span>
    }
  
    // Allocate a new TLAB requesting new_tlab_size. Any size
    // between minimal and new_tlab_size is accepted.
    size_t min_tlab_size = ThreadLocalAllocBuffer::compute_min_size(_word_size);
<span class="udiff-line-modified-removed">-   mem = _heap-&gt;allocate_new_tlab(min_tlab_size, new_tlab_size, &amp;allocation._allocated_tlab_size);</span>
<span class="udiff-line-modified-added">+   mem = Universe::heap()-&gt;allocate_new_tlab(min_tlab_size, new_tlab_size, &amp;allocation._allocated_tlab_size);</span>
    if (mem == NULL) {
      assert(allocation._allocated_tlab_size == 0,
             &quot;Allocation failed, but actual size was updated. min: &quot; SIZE_FORMAT
             &quot;, desired: &quot; SIZE_FORMAT &quot;, actual: &quot; SIZE_FORMAT,
             min_tlab_size, new_tlab_size, allocation._allocated_tlab_size);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -362,10 +364,14 @@</span>
    {
      Allocation allocation(*this, &amp;obj);
      HeapWord* mem = mem_allocate(allocation);
      if (mem != NULL) {
        obj = initialize(mem);
<span class="udiff-line-added">+     } else {</span>
<span class="udiff-line-added">+       // The unhandled oop detector will poison local variable obj,</span>
<span class="udiff-line-added">+       // so reset it to NULL if mem is NULL.</span>
<span class="udiff-line-added">+       obj = NULL;</span>
      }
    }
    return obj;
  }
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -381,11 +387,11 @@</span>
    assert(mem != NULL, &quot;NULL object pointer&quot;);
    if (UseBiasedLocking) {
      oopDesc::set_mark_raw(mem, _klass-&gt;prototype_header());
    } else {
      // May be bootstrapping
<span class="udiff-line-modified-removed">-     oopDesc::set_mark_raw(mem, markOopDesc::prototype());</span>
<span class="udiff-line-modified-added">+     oopDesc::set_mark_raw(mem, markWord::prototype());</span>
    }
    // Need a release store to ensure array/class length, mark word, and
    // object zeroing are visible before setting the klass non-NULL, for
    // concurrent collectors.
    oopDesc::release_set_klass(mem, _klass);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -401,11 +407,11 @@</span>
    if (_do_zero) {
      return MemAllocator::obj_memory_range(obj);
    }
    ArrayKlass* array_klass = ArrayKlass::cast(_klass);
    const size_t hs = arrayOopDesc::header_size(array_klass-&gt;element_type());
<span class="udiff-line-modified-removed">-   return MemRegion(((HeapWord*)obj) + hs, _word_size - hs);</span>
<span class="udiff-line-modified-added">+   return MemRegion(cast_from_oop&lt;HeapWord*&gt;(obj) + hs, _word_size - hs);</span>
  }
  
  oop ObjArrayAllocator::initialize(HeapWord* mem) const {
    // Set array length before setting the _klass field because a
    // non-NULL klass field indicates that the object is parsable by
</pre>
<center><a href="markBitMap.inline.hpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="memAllocator.hpp.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>