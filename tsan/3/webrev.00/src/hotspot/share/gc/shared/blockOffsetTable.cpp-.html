<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/gc/shared/blockOffsetTable.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;gc/shared/blockOffsetTable.inline.hpp&quot;
 27 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
 28 #include &quot;gc/shared/space.inline.hpp&quot;
 29 #include &quot;memory/iterator.hpp&quot;
 30 #include &quot;memory/universe.hpp&quot;
 31 #include &quot;logging/log.hpp&quot;
 32 #include &quot;oops/oop.inline.hpp&quot;
 33 #include &quot;runtime/java.hpp&quot;
 34 #include &quot;services/memTracker.hpp&quot;
 35 
 36 //////////////////////////////////////////////////////////////////////
 37 // BlockOffsetSharedArray
 38 //////////////////////////////////////////////////////////////////////
 39 
 40 BlockOffsetSharedArray::BlockOffsetSharedArray(MemRegion reserved,
 41                                                size_t init_word_size):
 42   _reserved(reserved), _end(NULL)
 43 {
 44   size_t size = compute_size(reserved.word_size());
 45   ReservedSpace rs(size);
 46   if (!rs.is_reserved()) {
 47     vm_exit_during_initialization(&quot;Could not reserve enough space for heap offset array&quot;);
 48   }
 49 
 50   MemTracker::record_virtual_memory_type((address)rs.base(), mtGC);
 51 
 52   if (!_vs.initialize(rs, 0)) {
 53     vm_exit_during_initialization(&quot;Could not reserve enough space for heap offset array&quot;);
 54   }
 55   _offset_array = (u_char*)_vs.low_boundary();
 56   resize(init_word_size);
 57   log_trace(gc, bot)(&quot;BlockOffsetSharedArray::BlockOffsetSharedArray: &quot;);
 58   log_trace(gc, bot)(&quot;   rs.base(): &quot; INTPTR_FORMAT &quot; rs.size(): &quot; INTPTR_FORMAT &quot; rs end(): &quot; INTPTR_FORMAT,
 59                      p2i(rs.base()), rs.size(), p2i(rs.base() + rs.size()));
 60   log_trace(gc, bot)(&quot;   _vs.low_boundary(): &quot; INTPTR_FORMAT &quot;  _vs.high_boundary(): &quot; INTPTR_FORMAT,
 61                      p2i(_vs.low_boundary()), p2i(_vs.high_boundary()));
 62 }
 63 
 64 void BlockOffsetSharedArray::resize(size_t new_word_size) {
 65   assert(new_word_size &lt;= _reserved.word_size(), &quot;Resize larger than reserved&quot;);
 66   size_t new_size = compute_size(new_word_size);
 67   size_t old_size = _vs.committed_size();
 68   size_t delta;
 69   char* high = _vs.high();
 70   _end = _reserved.start() + new_word_size;
 71   if (new_size &gt; old_size) {
 72     delta = ReservedSpace::page_align_size_up(new_size - old_size);
 73     assert(delta &gt; 0, &quot;just checking&quot;);
 74     if (!_vs.expand_by(delta)) {
 75       // Do better than this for Merlin
 76       vm_exit_out_of_memory(delta, OOM_MMAP_ERROR, &quot;offset table expansion&quot;);
 77     }
 78     assert(_vs.high() == high + delta, &quot;invalid expansion&quot;);
 79   } else {
 80     delta = ReservedSpace::page_align_size_down(old_size - new_size);
 81     if (delta == 0) return;
 82     _vs.shrink_by(delta);
 83     assert(_vs.high() == high - delta, &quot;invalid expansion&quot;);
 84   }
 85 }
 86 
 87 bool BlockOffsetSharedArray::is_card_boundary(HeapWord* p) const {
 88   assert(p &gt;= _reserved.start(), &quot;just checking&quot;);
 89   size_t delta = pointer_delta(p, _reserved.start());
 90   return (delta &amp; right_n_bits((int)BOTConstants::LogN_words)) == (size_t)NoBits;
 91 }
 92 
 93 
 94 //////////////////////////////////////////////////////////////////////
 95 // BlockOffsetArray
 96 //////////////////////////////////////////////////////////////////////
 97 
 98 BlockOffsetArray::BlockOffsetArray(BlockOffsetSharedArray* array,
 99                                    MemRegion mr, bool init_to_zero_) :
100   BlockOffsetTable(mr.start(), mr.end()),
101   _array(array)
102 {
103   assert(_bottom &lt;= _end, &quot;arguments out of order&quot;);
104   set_init_to_zero(init_to_zero_);
105   if (!init_to_zero_) {
106     // initialize cards to point back to mr.start()
107     set_remainder_to_point_to_start(mr.start() + BOTConstants::N_words, mr.end());
108     _array-&gt;set_offset_array(0, 0);  // set first card to 0
109   }
110 }
111 
112 
113 // The arguments follow the normal convention of denoting
114 // a right-open interval: [start, end)
115 void
116 BlockOffsetArray::
117 set_remainder_to_point_to_start(HeapWord* start, HeapWord* end, bool reducing) {
118 
119   check_reducing_assertion(reducing);
120   if (start &gt;= end) {
121     // The start address is equal to the end address (or to
122     // the right of the end address) so there are not cards
123     // that need to be updated..
124     return;
125   }
126 
127   // Write the backskip value for each region.
128   //
129   //    offset
130   //    card             2nd                       3rd
131   //     | +- 1st        |                         |
132   //     v v             v                         v
133   //    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+     +-+-+-+-+-+-+-+-+-+-+-
134   //    |x|0|0|0|0|0|0|0|1|1|1|1|1|1| ... |1|1|1|1|2|2|2|2|2|2| ...
135   //    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+     +-+-+-+-+-+-+-+-+-+-+-
136   //    11              19                        75
137   //      12
138   //
139   //    offset card is the card that points to the start of an object
140   //      x - offset value of offset card
141   //    1st - start of first logarithmic region
142   //      0 corresponds to logarithmic value N_words + 0 and 2**(3 * 0) = 1
143   //    2nd - start of second logarithmic region
144   //      1 corresponds to logarithmic value N_words + 1 and 2**(3 * 1) = 8
145   //    3rd - start of third logarithmic region
146   //      2 corresponds to logarithmic value N_words + 2 and 2**(3 * 2) = 64
147   //
148   //    integer below the block offset entry is an example of
149   //    the index of the entry
150   //
151   //    Given an address,
152   //      Find the index for the address
153   //      Find the block offset table entry
154   //      Convert the entry to a back slide
155   //        (e.g., with today&#39;s, offset = 0x81 =&gt;
156   //          back slip = 2**(3*(0x81 - N_words)) = 2**3) = 8
157   //      Move back N (e.g., 8) entries and repeat with the
158   //        value of the new entry
159   //
160   size_t start_card = _array-&gt;index_for(start);
161   size_t end_card = _array-&gt;index_for(end-1);
162   assert(start ==_array-&gt;address_for_index(start_card), &quot;Precondition&quot;);
163   assert(end ==_array-&gt;address_for_index(end_card)+BOTConstants::N_words, &quot;Precondition&quot;);
164   set_remainder_to_point_to_start_incl(start_card, end_card, reducing); // closed interval
165 }
166 
167 
168 // Unlike the normal convention in this code, the argument here denotes
169 // a closed, inclusive interval: [start_card, end_card], cf set_remainder_to_point_to_start()
170 // above.
171 void
172 BlockOffsetArray::set_remainder_to_point_to_start_incl(size_t start_card, size_t end_card, bool reducing) {
173 
174   check_reducing_assertion(reducing);
175   if (start_card &gt; end_card) {
176     return;
177   }
178   assert(start_card &gt; _array-&gt;index_for(_bottom), &quot;Cannot be first card&quot;);
179   assert(_array-&gt;offset_array(start_card-1) &lt;= BOTConstants::N_words,
180     &quot;Offset card has an unexpected value&quot;);
181   size_t start_card_for_region = start_card;
182   u_char offset = max_jubyte;
183   for (uint i = 0; i &lt; BOTConstants::N_powers; i++) {
184     // -1 so that the the card with the actual offset is counted.  Another -1
185     // so that the reach ends in this region and not at the start
186     // of the next.
187     size_t reach = start_card - 1 + (BOTConstants::power_to_cards_back(i+1) - 1);
188     offset = BOTConstants::N_words + i;
189     if (reach &gt;= end_card) {
190       _array-&gt;set_offset_array(start_card_for_region, end_card, offset, reducing);
191       start_card_for_region = reach + 1;
192       break;
193     }
194     _array-&gt;set_offset_array(start_card_for_region, reach, offset, reducing);
195     start_card_for_region = reach + 1;
196   }
197   assert(start_card_for_region &gt; end_card, &quot;Sanity check&quot;);
198   DEBUG_ONLY(check_all_cards(start_card, end_card);)
199 }
200 
201 // The card-interval [start_card, end_card] is a closed interval; this
202 // is an expensive check -- use with care and only under protection of
203 // suitable flag.
204 void BlockOffsetArray::check_all_cards(size_t start_card, size_t end_card) const {
205 
206   if (end_card &lt; start_card) {
207     return;
208   }
209   guarantee(_array-&gt;offset_array(start_card) == BOTConstants::N_words, &quot;Wrong value in second card&quot;);
210   u_char last_entry = BOTConstants::N_words;
211   for (size_t c = start_card + 1; c &lt;= end_card; c++ /* yeah! */) {
212     u_char entry = _array-&gt;offset_array(c);
213     guarantee(entry &gt;= last_entry, &quot;Monotonicity&quot;);
214     if (c - start_card &gt; BOTConstants::power_to_cards_back(1)) {
215       guarantee(entry &gt; BOTConstants::N_words, &quot;Should be in logarithmic region&quot;);
216     }
217     size_t backskip = BOTConstants::entry_to_cards_back(entry);
218     size_t landing_card = c - backskip;
219     guarantee(landing_card &gt;= (start_card - 1), &quot;Inv&quot;);
220     if (landing_card &gt;= start_card) {
221       guarantee(_array-&gt;offset_array(landing_card) &lt;= entry, &quot;Monotonicity&quot;);
222     } else {
223       guarantee(landing_card == (start_card - 1), &quot;Tautology&quot;);
224       // Note that N_words is the maximum offset value
225       guarantee(_array-&gt;offset_array(landing_card) &lt;= BOTConstants::N_words, &quot;Offset value&quot;);
226     }
227     last_entry = entry;  // remember for monotonicity test
228   }
229 }
230 
231 
232 void
233 BlockOffsetArray::alloc_block(HeapWord* blk_start, HeapWord* blk_end) {
234   assert(blk_start != NULL &amp;&amp; blk_end &gt; blk_start,
235          &quot;phantom block&quot;);
236   single_block(blk_start, blk_end);
237 }
238 
239 // Action_mark - update the BOT for the block [blk_start, blk_end).
240 //               Current typical use is for splitting a block.
241 // Action_single - udpate the BOT for an allocation.
242 // Action_verify - BOT verification.
243 void
244 BlockOffsetArray::do_block_internal(HeapWord* blk_start,
245                                     HeapWord* blk_end,
246                                     Action action, bool reducing) {
247   assert(Universe::heap()-&gt;is_in_reserved(blk_start),
248          &quot;reference must be into the heap&quot;);
249   assert(Universe::heap()-&gt;is_in_reserved(blk_end-1),
250          &quot;limit must be within the heap&quot;);
251   // This is optimized to make the test fast, assuming we only rarely
252   // cross boundaries.
253   uintptr_t end_ui = (uintptr_t)(blk_end - 1);
254   uintptr_t start_ui = (uintptr_t)blk_start;
255   // Calculate the last card boundary preceding end of blk
256   intptr_t boundary_before_end = (intptr_t)end_ui;
257   clear_bits(boundary_before_end, right_n_bits((int)BOTConstants::LogN));
258   if (start_ui &lt;= (uintptr_t)boundary_before_end) {
259     // blk starts at or crosses a boundary
260     // Calculate index of card on which blk begins
261     size_t    start_index = _array-&gt;index_for(blk_start);
262     // Index of card on which blk ends
263     size_t    end_index   = _array-&gt;index_for(blk_end - 1);
264     // Start address of card on which blk begins
265     HeapWord* boundary    = _array-&gt;address_for_index(start_index);
266     assert(boundary &lt;= blk_start, &quot;blk should start at or after boundary&quot;);
267     if (blk_start != boundary) {
268       // blk starts strictly after boundary
269       // adjust card boundary and start_index forward to next card
270       boundary += BOTConstants::N_words;
271       start_index++;
272     }
273     assert(start_index &lt;= end_index, &quot;monotonicity of index_for()&quot;);
274     assert(boundary &lt;= (HeapWord*)boundary_before_end, &quot;tautology&quot;);
275     switch (action) {
276       case Action_mark: {
277         if (init_to_zero()) {
278           _array-&gt;set_offset_array(start_index, boundary, blk_start, reducing);
279           break;
280         } // Else fall through to the next case
281       }
282       case Action_single: {
283         _array-&gt;set_offset_array(start_index, boundary, blk_start, reducing);
284         // We have finished marking the &quot;offset card&quot;. We need to now
285         // mark the subsequent cards that this blk spans.
286         if (start_index &lt; end_index) {
287           HeapWord* rem_st = _array-&gt;address_for_index(start_index) + BOTConstants::N_words;
288           HeapWord* rem_end = _array-&gt;address_for_index(end_index) + BOTConstants::N_words;
289           set_remainder_to_point_to_start(rem_st, rem_end, reducing);
290         }
291         break;
292       }
293       case Action_check: {
294         _array-&gt;check_offset_array(start_index, boundary, blk_start);
295         // We have finished checking the &quot;offset card&quot;. We need to now
296         // check the subsequent cards that this blk spans.
297         check_all_cards(start_index + 1, end_index);
298         break;
299       }
300       default:
301         ShouldNotReachHere();
302     }
303   }
304 }
305 
306 // The range [blk_start, blk_end) represents a single contiguous block
307 // of storage; modify the block offset table to represent this
308 // information; Right-open interval: [blk_start, blk_end)
309 // NOTE: this method does _not_ adjust _unallocated_block.
310 void
311 BlockOffsetArray::single_block(HeapWord* blk_start,
312                                HeapWord* blk_end) {
313   do_block_internal(blk_start, blk_end, Action_single);
314 }
315 
316 void BlockOffsetArray::verify() const {
317   // For each entry in the block offset table, verify that
318   // the entry correctly finds the start of an object at the
319   // first address covered by the block or to the left of that
320   // first address.
321 
322   size_t next_index = 1;
323   size_t last_index = last_active_index();
324 
325   // Use for debugging.  Initialize to NULL to distinguish the
326   // first iteration through the while loop.
327   HeapWord* last_p = NULL;
328   HeapWord* last_start = NULL;
329   oop last_o = NULL;
330 
331   while (next_index &lt;= last_index) {
332     // Use an address past the start of the address for
333     // the entry.
334     HeapWord* p = _array-&gt;address_for_index(next_index) + 1;
335     if (p &gt;= _end) {
336       // That&#39;s all of the allocated block table.
337       return;
338     }
339     // block_start() asserts that start &lt;= p.
340     HeapWord* start = block_start(p);
341     // First check if the start is an allocated block and only
342     // then if it is a valid object.
343     oop o = oop(start);
344     assert(!Universe::is_fully_initialized() ||
345            _sp-&gt;is_free_block(start) ||
346            oopDesc::is_oop_or_null(o), &quot;Bad object was found&quot;);
347     next_index++;
348     last_p = p;
349     last_start = start;
350     last_o = o;
351   }
352 }
353 
354 //////////////////////////////////////////////////////////////////////
355 // BlockOffsetArrayNonContigSpace
356 //////////////////////////////////////////////////////////////////////
357 
358 // The block [blk_start, blk_end) has been allocated;
359 // adjust the block offset table to represent this information;
360 // NOTE: Clients of BlockOffsetArrayNonContigSpace: consider using
361 // the somewhat more lightweight split_block() or
362 // (when init_to_zero()) mark_block() wherever possible.
363 // right-open interval: [blk_start, blk_end)
364 void
365 BlockOffsetArrayNonContigSpace::alloc_block(HeapWord* blk_start,
366                                             HeapWord* blk_end) {
367   assert(blk_start != NULL &amp;&amp; blk_end &gt; blk_start,
368          &quot;phantom block&quot;);
369   single_block(blk_start, blk_end);
370   allocated(blk_start, blk_end);
371 }
372 
373 // Adjust BOT to show that a previously whole block has been split
374 // into two.  We verify the BOT for the first part (prefix) and
375 // update the  BOT for the second part (suffix).
376 //      blk is the start of the block
377 //      blk_size is the size of the original block
378 //      left_blk_size is the size of the first part of the split
379 void BlockOffsetArrayNonContigSpace::split_block(HeapWord* blk,
380                                                  size_t blk_size,
381                                                  size_t left_blk_size) {
382   // Verify that the BOT shows [blk, blk + blk_size) to be one block.
383   verify_single_block(blk, blk_size);
384   // Update the BOT to indicate that [blk + left_blk_size, blk + blk_size)
385   // is one single block.
386   assert(blk_size &gt; 0, &quot;Should be positive&quot;);
387   assert(left_blk_size &gt; 0, &quot;Should be positive&quot;);
388   assert(left_blk_size &lt; blk_size, &quot;Not a split&quot;);
389 
390   // Start addresses of prefix block and suffix block.
391   HeapWord* pref_addr = blk;
392   HeapWord* suff_addr = blk + left_blk_size;
393   HeapWord* end_addr  = blk + blk_size;
394 
395   // Indices for starts of prefix block and suffix block.
396   size_t pref_index = _array-&gt;index_for(pref_addr);
397   if (_array-&gt;address_for_index(pref_index) != pref_addr) {
398     // pref_addr does not begin pref_index
399     pref_index++;
400   }
401 
402   size_t suff_index = _array-&gt;index_for(suff_addr);
403   if (_array-&gt;address_for_index(suff_index) != suff_addr) {
404     // suff_addr does not begin suff_index
405     suff_index++;
406   }
407 
408   // Definition: A block B, denoted [B_start, B_end) __starts__
409   //     a card C, denoted [C_start, C_end), where C_start and C_end
410   //     are the heap addresses that card C covers, iff
411   //     B_start &lt;= C_start &lt; B_end.
412   //
413   //     We say that a card C &quot;is started by&quot; a block B, iff
414   //     B &quot;starts&quot; C.
415   //
416   //     Note that the cardinality of the set of cards {C}
417   //     started by a block B can be 0, 1, or more.
418   //
419   // Below, pref_index and suff_index are, respectively, the
420   // first (least) card indices that the prefix and suffix of
421   // the split start; end_index is one more than the index of
422   // the last (greatest) card that blk starts.
423   size_t end_index  = _array-&gt;index_for(end_addr - 1) + 1;
424 
425   // Calculate the # cards that the prefix and suffix affect.
426   size_t num_pref_cards = suff_index - pref_index;
427 
428   size_t num_suff_cards = end_index  - suff_index;
429   // Change the cards that need changing
430   if (num_suff_cards &gt; 0) {
431     HeapWord* boundary = _array-&gt;address_for_index(suff_index);
432     // Set the offset card for suffix block
433     _array-&gt;set_offset_array(suff_index, boundary, suff_addr, true /* reducing */);
434     // Change any further cards that need changing in the suffix
435     if (num_pref_cards &gt; 0) {
436       if (num_pref_cards &gt;= num_suff_cards) {
437         // Unilaterally fix all of the suffix cards: closed card
438         // index interval in args below.
439         set_remainder_to_point_to_start_incl(suff_index + 1, end_index - 1, true /* reducing */);
440       } else {
441         // Unilaterally fix the first (num_pref_cards - 1) following
442         // the &quot;offset card&quot; in the suffix block.
443         const size_t right_most_fixed_index = suff_index + num_pref_cards - 1;
444         set_remainder_to_point_to_start_incl(suff_index + 1,
445           right_most_fixed_index, true /* reducing */);
446         // Fix the appropriate cards in the remainder of the
447         // suffix block -- these are the last num_pref_cards
448         // cards in each power block of the &quot;new&quot; range plumbed
449         // from suff_addr.
450         bool more = true;
451         uint i = 1;
452         // Fix the first power block with  back_by &gt; num_pref_cards.
453         while (more &amp;&amp; (i &lt; BOTConstants::N_powers)) {
454           size_t back_by = BOTConstants::power_to_cards_back(i);
455           size_t right_index = suff_index + back_by - 1;
456           size_t left_index  = right_index - num_pref_cards + 1;
457           if (right_index &gt;= end_index - 1) { // last iteration
458             right_index = end_index - 1;
459             more = false;
460           }
461           if (left_index &lt;= right_most_fixed_index) {
462                 left_index = right_most_fixed_index + 1;
463           }
464           if (back_by &gt; num_pref_cards) {
465             // Fill in the remainder of this &quot;power block&quot;, if it
466             // is non-null.
467             if (left_index &lt;= right_index) {
468               _array-&gt;set_offset_array(left_index, right_index,
469                                        BOTConstants::N_words + i - 1, true /* reducing */);
470             } else {
471               more = false; // we are done
472               assert((end_index - 1) == right_index, &quot;Must be at the end.&quot;);
473             }
474             i++;
475             break;
476           }
477           i++;
478         }
479         // Fix the rest of the power blocks.
480         while (more &amp;&amp; (i &lt; BOTConstants::N_powers)) {
481           size_t back_by = BOTConstants::power_to_cards_back(i);
482           size_t right_index = suff_index + back_by - 1;
483           size_t left_index  = right_index - num_pref_cards + 1;
484           if (right_index &gt;= end_index - 1) { // last iteration
485             right_index = end_index - 1;
486             if (left_index &gt; right_index) {
487               break;
488             }
489             more  = false;
490           }
491           assert(left_index &lt;= right_index, &quot;Error&quot;);
492           _array-&gt;set_offset_array(left_index, right_index, BOTConstants::N_words + i - 1, true /* reducing */);
493           i++;
494         }
495       }
496     } // else no more cards to fix in suffix
497   } // else nothing needs to be done
498   // Verify that we did the right thing
499   verify_single_block(pref_addr, left_blk_size);
500   verify_single_block(suff_addr, blk_size - left_blk_size);
501 }
502 
503 
504 // Mark the BOT such that if [blk_start, blk_end) straddles a card
505 // boundary, the card following the first such boundary is marked
506 // with the appropriate offset.
507 // NOTE: this method does _not_ adjust _unallocated_block or
508 // any cards subsequent to the first one.
509 void
510 BlockOffsetArrayNonContigSpace::mark_block(HeapWord* blk_start,
511                                            HeapWord* blk_end, bool reducing) {
512   do_block_internal(blk_start, blk_end, Action_mark, reducing);
513 }
514 
515 HeapWord* BlockOffsetArrayNonContigSpace::block_start_unsafe(
516   const void* addr) const {
517   assert(_array-&gt;offset_array(0) == 0, &quot;objects can&#39;t cross covered areas&quot;);
518   assert(_bottom &lt;= addr &amp;&amp; addr &lt; _end,
519          &quot;addr must be covered by this Array&quot;);
520   // Must read this exactly once because it can be modified by parallel
521   // allocation.
522   HeapWord* ub = _unallocated_block;
523   if (BlockOffsetArrayUseUnallocatedBlock &amp;&amp; addr &gt;= ub) {
524     assert(ub &lt; _end, &quot;tautology (see above)&quot;);
525     return ub;
526   }
527 
528   // Otherwise, find the block start using the table.
529   size_t index = _array-&gt;index_for(addr);
530   HeapWord* q = _array-&gt;address_for_index(index);
531 
532   uint offset = _array-&gt;offset_array(index);    // Extend u_char to uint.
533   while (offset &gt;= BOTConstants::N_words) {
534     // The excess of the offset from N_words indicates a power of Base
535     // to go back by.
536     size_t n_cards_back = BOTConstants::entry_to_cards_back(offset);
537     q -= (BOTConstants::N_words * n_cards_back);
538     assert(q &gt;= _sp-&gt;bottom(),
539            &quot;q = &quot; PTR_FORMAT &quot; crossed below bottom = &quot; PTR_FORMAT,
540            p2i(q), p2i(_sp-&gt;bottom()));
541     assert(q &lt; _sp-&gt;end(),
542            &quot;q = &quot; PTR_FORMAT &quot; crossed above end = &quot; PTR_FORMAT,
543            p2i(q), p2i(_sp-&gt;end()));
544     index -= n_cards_back;
545     offset = _array-&gt;offset_array(index);
546   }
547   assert(offset &lt; BOTConstants::N_words, &quot;offset too large&quot;);
548   index--;
549   q -= offset;
550   assert(q &gt;= _sp-&gt;bottom(),
551          &quot;q = &quot; PTR_FORMAT &quot; crossed below bottom = &quot; PTR_FORMAT,
552          p2i(q), p2i(_sp-&gt;bottom()));
553   assert(q &lt; _sp-&gt;end(),
554          &quot;q = &quot; PTR_FORMAT &quot; crossed above end = &quot; PTR_FORMAT,
555          p2i(q), p2i(_sp-&gt;end()));
556   HeapWord* n = q;
557 
558   while (n &lt;= addr) {
559     debug_only(HeapWord* last = q);   // for debugging
560     q = n;
561     n += _sp-&gt;block_size(n);
562     assert(n &gt; q,
563            &quot;Looping at n = &quot; PTR_FORMAT &quot; with last = &quot; PTR_FORMAT &quot;,&quot;
564            &quot; while querying blk_start(&quot; PTR_FORMAT &quot;)&quot;
565            &quot; on _sp = [&quot; PTR_FORMAT &quot;,&quot; PTR_FORMAT &quot;)&quot;,
566            p2i(n), p2i(last), p2i(addr), p2i(_sp-&gt;bottom()), p2i(_sp-&gt;end()));
567   }
568   assert(q &lt;= addr,
569          &quot;wrong order for current (&quot; INTPTR_FORMAT &quot;)&quot; &quot; &lt;= arg (&quot; INTPTR_FORMAT &quot;)&quot;,
570          p2i(q), p2i(addr));
571   assert(addr &lt;= n,
572          &quot;wrong order for arg (&quot; INTPTR_FORMAT &quot;) &lt;= next (&quot; INTPTR_FORMAT &quot;)&quot;,
573          p2i(addr), p2i(n));
574   return q;
575 }
576 
577 HeapWord* BlockOffsetArrayNonContigSpace::block_start_careful(
578   const void* addr) const {
579   assert(_array-&gt;offset_array(0) == 0, &quot;objects can&#39;t cross covered areas&quot;);
580 
581   assert(_bottom &lt;= addr &amp;&amp; addr &lt; _end,
582          &quot;addr must be covered by this Array&quot;);
583   // Must read this exactly once because it can be modified by parallel
584   // allocation.
585   HeapWord* ub = _unallocated_block;
586   if (BlockOffsetArrayUseUnallocatedBlock &amp;&amp; addr &gt;= ub) {
587     assert(ub &lt; _end, &quot;tautology (see above)&quot;);
588     return ub;
589   }
590 
591   // Otherwise, find the block start using the table, but taking
592   // care (cf block_start_unsafe() above) not to parse any objects/blocks
593   // on the cards themselves.
594   size_t index = _array-&gt;index_for(addr);
595   assert(_array-&gt;address_for_index(index) == addr,
596          &quot;arg should be start of card&quot;);
597 
598   HeapWord* q = (HeapWord*)addr;
599   uint offset;
600   do {
601     offset = _array-&gt;offset_array(index);
602     if (offset &lt; BOTConstants::N_words) {
603       q -= offset;
604     } else {
605       size_t n_cards_back = BOTConstants::entry_to_cards_back(offset);
606       q -= (n_cards_back * BOTConstants::N_words);
607       index -= n_cards_back;
608     }
609   } while (offset &gt;= BOTConstants::N_words);
610   assert(q &lt;= addr, &quot;block start should be to left of arg&quot;);
611   return q;
612 }
613 
614 #ifndef PRODUCT
615 // Verification &amp; debugging - ensure that the offset table reflects the fact
616 // that the block [blk_start, blk_end) or [blk, blk + size) is a
617 // single block of storage. NOTE: can&#39;t const this because of
618 // call to non-const do_block_internal() below.
619 void BlockOffsetArrayNonContigSpace::verify_single_block(
620   HeapWord* blk_start, HeapWord* blk_end) {
621   if (VerifyBlockOffsetArray) {
622     do_block_internal(blk_start, blk_end, Action_check);
623   }
624 }
625 
626 void BlockOffsetArrayNonContigSpace::verify_single_block(
627   HeapWord* blk, size_t size) {
628   verify_single_block(blk, blk + size);
629 }
630 
631 // Verify that the given block is before _unallocated_block
632 void BlockOffsetArrayNonContigSpace::verify_not_unallocated(
633   HeapWord* blk_start, HeapWord* blk_end) const {
634   if (BlockOffsetArrayUseUnallocatedBlock) {
635     assert(blk_start &lt; blk_end, &quot;Block inconsistency?&quot;);
636     assert(blk_end &lt;= _unallocated_block, &quot;_unallocated_block problem&quot;);
637   }
638 }
639 
640 void BlockOffsetArrayNonContigSpace::verify_not_unallocated(
641   HeapWord* blk, size_t size) const {
642   verify_not_unallocated(blk, blk + size);
643 }
644 #endif // PRODUCT
645 
646 size_t BlockOffsetArrayNonContigSpace::last_active_index() const {
647   if (_unallocated_block == _bottom) {
648     return 0;
649   } else {
650     return _array-&gt;index_for(_unallocated_block - 1);
651   }
652 }
653 
654 //////////////////////////////////////////////////////////////////////
655 // BlockOffsetArrayContigSpace
656 //////////////////////////////////////////////////////////////////////
657 
658 HeapWord* BlockOffsetArrayContigSpace::block_start_unsafe(const void* addr) const {
659   assert(_array-&gt;offset_array(0) == 0, &quot;objects can&#39;t cross covered areas&quot;);
660 
661   // Otherwise, find the block start using the table.
662   assert(_bottom &lt;= addr &amp;&amp; addr &lt; _end,
663          &quot;addr must be covered by this Array&quot;);
664   size_t index = _array-&gt;index_for(addr);
665   // We must make sure that the offset table entry we use is valid.  If
666   // &quot;addr&quot; is past the end, start at the last known one and go forward.
667   index = MIN2(index, _next_offset_index-1);
668   HeapWord* q = _array-&gt;address_for_index(index);
669 
670   uint offset = _array-&gt;offset_array(index);    // Extend u_char to uint.
671   while (offset &gt; BOTConstants::N_words) {
672     // The excess of the offset from N_words indicates a power of Base
673     // to go back by.
674     size_t n_cards_back = BOTConstants::entry_to_cards_back(offset);
675     q -= (BOTConstants::N_words * n_cards_back);
676     assert(q &gt;= _sp-&gt;bottom(), &quot;Went below bottom!&quot;);
677     index -= n_cards_back;
678     offset = _array-&gt;offset_array(index);
679   }
680   while (offset == BOTConstants::N_words) {
681     assert(q &gt;= _sp-&gt;bottom(), &quot;Went below bottom!&quot;);
682     q -= BOTConstants::N_words;
683     index--;
684     offset = _array-&gt;offset_array(index);
685   }
686   assert(offset &lt; BOTConstants::N_words, &quot;offset too large&quot;);
687   q -= offset;
688   HeapWord* n = q;
689 
690   while (n &lt;= addr) {
691     debug_only(HeapWord* last = q);   // for debugging
692     q = n;
693     n += _sp-&gt;block_size(n);
694   }
695   assert(q &lt;= addr, &quot;wrong order for current and arg&quot;);
696   assert(addr &lt;= n, &quot;wrong order for arg and next&quot;);
697   return q;
698 }
699 
700 //
701 //              _next_offset_threshold
702 //              |   _next_offset_index
703 //              v   v
704 //      +-------+-------+-------+-------+-------+
705 //      | i-1   |   i   | i+1   | i+2   | i+3   |
706 //      +-------+-------+-------+-------+-------+
707 //       ( ^    ]
708 //         block-start
709 //
710 
711 void BlockOffsetArrayContigSpace::alloc_block_work(HeapWord* blk_start,
712                                         HeapWord* blk_end) {
713   assert(blk_start != NULL &amp;&amp; blk_end &gt; blk_start,
714          &quot;phantom block&quot;);
715   assert(blk_end &gt; _next_offset_threshold,
716          &quot;should be past threshold&quot;);
717   assert(blk_start &lt;= _next_offset_threshold,
718          &quot;blk_start should be at or before threshold&quot;);
719   assert(pointer_delta(_next_offset_threshold, blk_start) &lt;= BOTConstants::N_words,
720          &quot;offset should be &lt;= BlockOffsetSharedArray::N&quot;);
721   assert(Universe::heap()-&gt;is_in_reserved(blk_start),
722          &quot;reference must be into the heap&quot;);
723   assert(Universe::heap()-&gt;is_in_reserved(blk_end-1),
724          &quot;limit must be within the heap&quot;);
725   assert(_next_offset_threshold ==
726          _array-&gt;_reserved.start() + _next_offset_index*BOTConstants::N_words,
727          &quot;index must agree with threshold&quot;);
728 
729   debug_only(size_t orig_next_offset_index = _next_offset_index;)
730 
731   // Mark the card that holds the offset into the block.  Note
732   // that _next_offset_index and _next_offset_threshold are not
733   // updated until the end of this method.
734   _array-&gt;set_offset_array(_next_offset_index,
735                            _next_offset_threshold,
736                            blk_start);
737 
738   // We need to now mark the subsequent cards that this blk spans.
739 
740   // Index of card on which blk ends.
741   size_t end_index   = _array-&gt;index_for(blk_end - 1);
742 
743   // Are there more cards left to be updated?
744   if (_next_offset_index + 1 &lt;= end_index) {
745     HeapWord* rem_st  = _array-&gt;address_for_index(_next_offset_index + 1);
746     // Calculate rem_end this way because end_index
747     // may be the last valid index in the covered region.
748     HeapWord* rem_end = _array-&gt;address_for_index(end_index) +  BOTConstants::N_words;
749     set_remainder_to_point_to_start(rem_st, rem_end);
750   }
751 
752   // _next_offset_index and _next_offset_threshold updated here.
753   _next_offset_index = end_index + 1;
754   // Calculate _next_offset_threshold this way because end_index
755   // may be the last valid index in the covered region.
756   _next_offset_threshold = _array-&gt;address_for_index(end_index) + BOTConstants::N_words;
757   assert(_next_offset_threshold &gt;= blk_end, &quot;Incorrect offset threshold&quot;);
758 
759 #ifdef ASSERT
760   // The offset can be 0 if the block starts on a boundary.  That
761   // is checked by an assertion above.
762   size_t start_index = _array-&gt;index_for(blk_start);
763   HeapWord* boundary    = _array-&gt;address_for_index(start_index);
764   assert((_array-&gt;offset_array(orig_next_offset_index) == 0 &amp;&amp;
765           blk_start == boundary) ||
766           (_array-&gt;offset_array(orig_next_offset_index) &gt; 0 &amp;&amp;
767          _array-&gt;offset_array(orig_next_offset_index) &lt;= BOTConstants::N_words),
768          &quot;offset array should have been set&quot;);
769   for (size_t j = orig_next_offset_index + 1; j &lt;= end_index; j++) {
770     assert(_array-&gt;offset_array(j) &gt; 0 &amp;&amp;
771            _array-&gt;offset_array(j) &lt;= (u_char) (BOTConstants::N_words+BOTConstants::N_powers-1),
772            &quot;offset array should have been set&quot;);
773   }
774 #endif
775 }
776 
777 HeapWord* BlockOffsetArrayContigSpace::initialize_threshold() {
778   assert(!Universe::heap()-&gt;is_in_reserved(_array-&gt;_offset_array),
779          &quot;just checking&quot;);
780   _next_offset_index = _array-&gt;index_for(_bottom);
781   _next_offset_index++;
782   _next_offset_threshold =
783     _array-&gt;address_for_index(_next_offset_index);
784   return _next_offset_threshold;
785 }
786 
787 void BlockOffsetArrayContigSpace::zero_bottom_entry() {
788   assert(!Universe::heap()-&gt;is_in_reserved(_array-&gt;_offset_array),
789          &quot;just checking&quot;);
790   size_t bottom_index = _array-&gt;index_for(_bottom);
791   _array-&gt;set_offset_array(bottom_index, 0);
792 }
793 
794 size_t BlockOffsetArrayContigSpace::last_active_index() const {
795   return _next_offset_index == 0 ? 0 : _next_offset_index - 1;
796 }
    </pre>
  </body>
</html>