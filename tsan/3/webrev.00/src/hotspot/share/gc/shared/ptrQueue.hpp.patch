diff a/src/hotspot/share/gc/shared/ptrQueue.hpp b/src/hotspot/share/gc/shared/ptrQueue.hpp
--- a/src/hotspot/share/gc/shared/ptrQueue.hpp
+++ b/src/hotspot/share/gc/shared/ptrQueue.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2001, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2001, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -26,10 +26,11 @@
 #define SHARE_GC_SHARED_PTRQUEUE_HPP
 
 #include "memory/padded.hpp"
 #include "utilities/align.hpp"
 #include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
 #include "utilities/lockFreeStack.hpp"
 #include "utilities/sizes.hpp"
 
 class Mutex;
 class Monitor;
@@ -42,25 +43,18 @@
 class BufferNode;
 class PtrQueueSet;
 class PtrQueue {
   friend class VMStructs;
 
-  // Noncopyable - not defined.
-  PtrQueue(const PtrQueue&);
-  PtrQueue& operator=(const PtrQueue&);
+  NONCOPYABLE(PtrQueue);
 
   // The ptr queue set to which this queue belongs.
   PtrQueueSet* const _qset;
 
   // Whether updates should be logged.
   bool _active;
 
-  // If true, the queue is permanent, and doesn't need to deallocate
-  // its buffer in the destructor (since that obtains a lock which may not
-  // be legally locked by then.
-  const bool _permanent;
-
   // The (byte) index at which an object was last enqueued.  Starts at
   // capacity_in_bytes (indicating an empty buffer) and goes towards zero.
   // Value is always pointer-size aligned.
   size_t _index;
 
@@ -74,18 +68,10 @@
   size_t capacity_in_bytes() const {
     assert(_capacity_in_bytes > 0, "capacity not set");
     return _capacity_in_bytes;
   }
 
-  void set_capacity(size_t entries) {
-    size_t byte_capacity = index_to_byte_index(entries);
-    assert(_capacity_in_bytes == 0 || _capacity_in_bytes == byte_capacity,
-           "changing capacity " SIZE_FORMAT " -> " SIZE_FORMAT,
-           _capacity_in_bytes, byte_capacity);
-    _capacity_in_bytes = byte_capacity;
-  }
-
   static size_t byte_index_to_index(size_t ind) {
     assert(is_aligned(ind, _element_size), "precondition");
     return ind / _element_size;
   }
 
@@ -109,31 +95,33 @@
 
   size_t capacity() const {
     return byte_index_to_index(capacity_in_bytes());
   }
 
-  // If there is a lock associated with this buffer, this is that lock.
-  Mutex* _lock;
-
-  PtrQueueSet* qset() { return _qset; }
-  bool is_permanent() const { return _permanent; }
+  PtrQueueSet* qset() const { return _qset; }
 
   // Process queue entries and release resources.
   void flush_impl();
 
+  // Process (some of) the buffer and leave it in place for further use,
+  // or enqueue the buffer and allocate a new one.
+  virtual void handle_completed_buffer() = 0;
+
+  void allocate_buffer();
+
+  // Enqueue the current buffer in the qset and allocate a new buffer.
+  void enqueue_completed_buffer();
+
   // Initialize this queue to contain a null buffer, and be part of the
   // given PtrQueueSet.
-  PtrQueue(PtrQueueSet* qset, bool permanent = false, bool active = false);
+  PtrQueue(PtrQueueSet* qset, bool active = false);
 
-  // Requires queue flushed or permanent.
+  // Requires queue flushed.
   ~PtrQueue();
 
 public:
 
-  // Associate a lock with a ptr queue.
-  void set_lock(Mutex* lock) { _lock = lock; }
-
   // Forcibly set empty.
   void reset() {
     if (_buf != NULL) {
       _index = capacity_in_bytes();
     }
@@ -147,18 +135,10 @@
   void enqueue(void* ptr) {
     if (!_active) return;
     else enqueue_known_active(ptr);
   }
 
-  // This method is called when we're doing the zero index handling
-  // and gives a chance to the queues to do any pre-enqueueing
-  // processing they might want to do on the buffer. It should return
-  // true if the buffer should be enqueued, or false if enough
-  // entries were cleared from it so that it can be re-used. It should
-  // not return false if the buffer is still full (otherwise we can
-  // get into an infinite loop).
-  virtual bool should_enqueue_buffer() { return true; }
   void handle_zero_index();
 
   void enqueue_known_active(void* ptr);
 
   // Return the size of the in-use region.
@@ -222,24 +202,24 @@
   void* _buffer[1];             // Pseudo flexible array member.
 
   BufferNode() : _index(0), _next(NULL) { }
   ~BufferNode() { }
 
+  NONCOPYABLE(BufferNode);
+
   static size_t buffer_offset() {
     return offset_of(BufferNode, _buffer);
   }
 
-  static BufferNode* volatile* next_ptr(BufferNode& bn) { return &bn._next; }
-
-AIX_ONLY(public:)               // xlC 12 on AIX doesn't implement C++ DR45.
   // Allocate a new BufferNode with the "buffer" having size elements.
   static BufferNode* allocate(size_t size);
 
   // Free a BufferNode.
   static void deallocate(BufferNode* node);
 
 public:
+  static BufferNode* volatile* next_ptr(BufferNode& bn) { return &bn._next; }
   typedef LockFreeStack<BufferNode, &next_ptr> Stack;
 
   BufferNode* next() const     { return _next;  }
   void set_next(BufferNode* n) { _next = n;     }
   size_t index() const         { return _index; }
@@ -291,10 +271,12 @@
 #undef DECLARE_PADDED_MEMBER
 
   void delete_list(BufferNode* list);
   bool try_transfer_pending();
 
+  NONCOPYABLE(Allocator);
+
 public:
   Allocator(const char* name, size_t buffer_size);
   ~Allocator();
 
   const char* name() const { return _name; }
@@ -313,55 +295,24 @@
 // In particular, the individual queues allocate buffers from this shared
 // set, and return completed buffers to the set.
 class PtrQueueSet {
   BufferNode::Allocator* _allocator;
 
-  Monitor* _cbl_mon;  // Protects the fields below.
-  BufferNode* _completed_buffers_head;
-  BufferNode* _completed_buffers_tail;
-  size_t _n_completed_buffers;
-
-  size_t _process_completed_buffers_threshold;
-  volatile bool _process_completed_buffers;
-
-  // If true, notify_all on _cbl_mon when the threshold is reached.
-  bool _notify_when_complete;
-
-  // Maximum number of elements allowed on completed queue: after that,
-  // enqueuer does the work itself.
-  size_t _max_completed_buffers;
-  size_t _completed_buffers_padding;
-
-  void assert_completed_buffers_list_len_correct_locked() NOT_DEBUG_RETURN;
+  NONCOPYABLE(PtrQueueSet);
 
 protected:
   bool _all_active;
 
-  // A mutator thread does the the work of processing a buffer.
-  // Returns "true" iff the work is complete (and the buffer may be
-  // deallocated).
-  virtual bool mut_process_buffer(BufferNode* node) {
-    ShouldNotReachHere();
-    return false;
-  }
-
   // Create an empty ptr queue set.
-  PtrQueueSet(bool notify_when_complete = false);
+  PtrQueueSet(BufferNode::Allocator* allocator);
   ~PtrQueueSet();
 
-  // Because of init-order concerns, we can't pass these as constructor
-  // arguments.
-  void initialize(Monitor* cbl_mon, BufferNode::Allocator* allocator);
-
-  // For (unlocked!) iteration over the completed buffers.
-  BufferNode* completed_buffers_head() const { return _completed_buffers_head; }
-
-  // Deallocate all of the completed buffers.
-  void abandon_completed_buffers();
-
 public:
 
+  // Return the associated BufferNode allocator.
+  BufferNode::Allocator* allocator() const { return _allocator; }
+
   // Return the buffer for a BufferNode of size buffer_size().
   void** allocate_buffer();
 
   // Return an empty buffer to the free list.  The node is required
   // to have been allocated with a size of buffer_size().
@@ -369,58 +320,15 @@
 
   // A completed buffer is a buffer the mutator is finished with, and
   // is ready to be processed by the collector.  It need not be full.
 
   // Adds node to the completed buffer list.
-  void enqueue_completed_buffer(BufferNode* node);
-
-  // If the number of completed buffers is > stop_at, then remove and
-  // return a completed buffer from the list.  Otherwise, return NULL.
-  BufferNode* get_completed_buffer(size_t stop_at = 0);
-
-  // To be invoked by the mutator.
-  bool process_or_enqueue_completed_buffer(BufferNode* node);
-
-  bool process_completed_buffers() { return _process_completed_buffers; }
-  void set_process_completed_buffers(bool x) { _process_completed_buffers = x; }
+  virtual void enqueue_completed_buffer(BufferNode* node) = 0;
 
   bool is_active() { return _all_active; }
 
   size_t buffer_size() const {
     return _allocator->buffer_size();
   }
-
-  // Get/Set the number of completed buffers that triggers log processing.
-  // Log processing should be done when the number of buffers exceeds the
-  // threshold.
-  void set_process_completed_buffers_threshold(size_t sz) {
-    _process_completed_buffers_threshold = sz;
-  }
-  size_t process_completed_buffers_threshold() const {
-    return _process_completed_buffers_threshold;
-  }
-  static const size_t ProcessCompletedBuffersThresholdNever = ~size_t(0);
-
-  size_t completed_buffers_num() const { return _n_completed_buffers; }
-
-  void merge_bufferlists(PtrQueueSet* src);
-
-  void set_max_completed_buffers(size_t m) {
-    _max_completed_buffers = m;
-  }
-  size_t max_completed_buffers() const {
-    return _max_completed_buffers;
-  }
-  static const size_t MaxCompletedBuffersUnlimited = ~size_t(0);
-
-  void set_completed_buffers_padding(size_t padding) {
-    _completed_buffers_padding = padding;
-  }
-  size_t completed_buffers_padding() const {
-    return _completed_buffers_padding;
-  }
-
-  // Notify the consumer if the number of buffers crossed the threshold
-  void notify_if_necessary();
 };
 
 #endif // SHARE_GC_SHARED_PTRQUEUE_HPP
