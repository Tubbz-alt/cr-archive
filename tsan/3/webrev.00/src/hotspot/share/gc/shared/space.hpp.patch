diff a/src/hotspot/share/gc/shared/space.hpp b/src/hotspot/share/gc/shared/space.hpp
--- a/src/hotspot/share/gc/shared/space.hpp
+++ b/src/hotspot/share/gc/shared/space.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -29,11 +29,11 @@
 #include "gc/shared/cardTable.hpp"
 #include "gc/shared/workgroup.hpp"
 #include "memory/allocation.hpp"
 #include "memory/iterator.hpp"
 #include "memory/memRegion.hpp"
-#include "oops/markOop.hpp"
+#include "oops/markWord.hpp"
 #include "runtime/mutexLocker.hpp"
 #include "utilities/align.hpp"
 #include "utilities/macros.hpp"
 
 // A space is an abstraction for the "storage units" backing
@@ -67,15 +67,10 @@
   HeapWord* _end;
 
   // Used in support of save_marks()
   HeapWord* _saved_mark_word;
 
-  // A sequential tasks done structure. This supports
-  // parallel GC, where we have threads dynamically
-  // claiming sub-tasks from a larger parallel task.
-  SequentialSubTasksDone _par_seq_tasks;
-
   Space():
     _bottom(NULL), _end(NULL) { }
 
  public:
   // Accessors
@@ -89,15 +84,11 @@
   void set_saved_mark_word(HeapWord* p) { _saved_mark_word = p; }
 
   // Returns true if this object has been allocated since a
   // generation's "save_marks" call.
   virtual bool obj_allocated_since_save_marks(const oop obj) const {
-    return (HeapWord*)obj >= saved_mark_word();
-  }
-
-  virtual MemRegionClosure* preconsumptionDirtyCardClosure() const {
-    return NULL;
+    return cast_from_oop<HeapWord*>(obj) >= saved_mark_word();
   }
 
   // Returns a subregion of the space containing only the allocated objects in
   // the space.
   virtual MemRegion used_region() const = 0;
@@ -173,13 +164,10 @@
 
   // Iterate over all objects in the space, calling "cl.do_object" on
   // each.  Objects allocated by applications of the closure are not
   // included in the iteration.
   virtual void object_iterate(ObjectClosure* blk) = 0;
-  // Similar to object_iterate() except only iterates over
-  // objects whose internal references point to objects in the space.
-  virtual void safe_object_iterate(ObjectClosure* blk) = 0;
 
   // Create and return a new dirty card to oop closure. Can be
   // overridden to return the appropriate type of closure
   // depending on the type of space in which the closure will
   // operate. ResourceArea allocated.
@@ -230,13 +218,10 @@
   virtual void print_on(outputStream* st) const;
   virtual void print_short() const;
   virtual void print_short_on(outputStream* st) const;
 
 
-  // Accessor for parallel sequential tasks.
-  SequentialSubTasksDone* par_seq_tasks() { return &_par_seq_tasks; }
-
   // IF "this" is a ContiguousSpace, return it, else return NULL.
   virtual ContiguousSpace* toContiguousSpace() {
     return NULL;
   }
 
@@ -354,11 +339,10 @@
 // Additionally, this also means that changes to block_size() or block_is_obj() that
 // should be effective during the compaction operations must provide a corresponding
 // definition of scanned_block_size/scanned_block_is_obj respectively.
 class CompactibleSpace: public Space {
   friend class VMStructs;
-  friend class CompactibleFreeListSpace;
 private:
   HeapWord* _compaction_top;
   CompactibleSpace* _next_compaction_space;
 
   // Auxiliary functions for scan_and_{forward,adjust_pointers,compact} support.
@@ -460,13 +444,10 @@
 protected:
   // Used during compaction.
   HeapWord* _first_dead;
   HeapWord* _end_of_live;
 
-  // Minimum size of a free block.
-  virtual size_t minimum_free_block_size() const { return 0; }
-
   // This the function is invoked when an allocation of an object covering
   // "start" to "end occurs crosses the threshold; returns the next
   // threshold.  (The default implementation does nothing.)
   virtual HeapWord* cross_threshold(HeapWord* start, HeapWord* the_end) {
     return end();
@@ -582,22 +563,11 @@
   HeapWord* allocate_aligned(size_t word_size);
 
   // Iteration
   void oop_iterate(OopIterateClosure* cl);
   void object_iterate(ObjectClosure* blk);
-  // For contiguous spaces this method will iterate safely over objects
-  // in the space (i.e., between bottom and top) when at a safepoint.
-  void safe_object_iterate(ObjectClosure* blk);
-
-  // Iterate over as many initialized objects in the space as possible,
-  // calling "cl.do_object_careful" on each. Return NULL if all objects
-  // in the space (at the start of the iteration) were iterated over.
-  // Return an address indicating the extent of the iteration in the
-  // event that the iteration had to return because of finding an
-  // uninitialized object in the space, or if the closure "cl"
-  // signaled early termination.
-  HeapWord* object_iterate_careful(ObjectClosureCareful* cl);
+
   HeapWord* concurrent_iteration_safe_limit() {
     assert(_concurrent_iteration_safe_limit <= top(),
            "_concurrent_iteration_safe_limit update missed");
     return _concurrent_iteration_safe_limit;
   }
@@ -606,14 +576,10 @@
   void set_concurrent_iteration_safe_limit(HeapWord* new_limit) {
     assert(new_limit <= top(), "uninitialized objects in the safe range");
     _concurrent_iteration_safe_limit = new_limit;
   }
 
-  // In support of parallel oop_iterate.
-  template <typename OopClosureType>
-  void par_oop_iterate(MemRegion mr, OopClosureType* blk);
-
   // Compaction support
   virtual void reset_after_compaction() {
     assert(compaction_top() >= bottom() && compaction_top() <= end(), "should point inside space");
     set_top(compaction_top());
     // set new iteration safe limit
