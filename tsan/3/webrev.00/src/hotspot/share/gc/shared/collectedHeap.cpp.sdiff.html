<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/shared/collectedHeap.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="cardTableRS.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="collectedHeap.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shared/collectedHeap.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;classfile/systemDictionary.hpp&quot;
 27 #include &quot;gc/shared/allocTracer.hpp&quot;
 28 #include &quot;gc/shared/barrierSet.hpp&quot;
 29 #include &quot;gc/shared/collectedHeap.hpp&quot;
 30 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
 31 #include &quot;gc/shared/gcLocker.inline.hpp&quot;
 32 #include &quot;gc/shared/gcHeapSummary.hpp&quot;
 33 #include &quot;gc/shared/gcTrace.hpp&quot;
 34 #include &quot;gc/shared/gcTraceTime.inline.hpp&quot;
 35 #include &quot;gc/shared/gcVMOperations.hpp&quot;
 36 #include &quot;gc/shared/gcWhen.hpp&quot;
 37 #include &quot;gc/shared/memAllocator.hpp&quot;
 38 #include &quot;logging/log.hpp&quot;
 39 #include &quot;memory/metaspace.hpp&quot;
 40 #include &quot;memory/resourceArea.hpp&quot;

 41 #include &quot;oops/instanceMirrorKlass.hpp&quot;
 42 #include &quot;oops/oop.inline.hpp&quot;
 43 #include &quot;runtime/handles.inline.hpp&quot;
 44 #include &quot;runtime/init.hpp&quot;
 45 #include &quot;runtime/thread.inline.hpp&quot;
 46 #include &quot;runtime/threadSMR.hpp&quot;
 47 #include &quot;runtime/vmThread.hpp&quot;
 48 #include &quot;services/heapDumper.hpp&quot;
 49 #include &quot;utilities/align.hpp&quot;
 50 #include &quot;utilities/copy.hpp&quot;
 51 
 52 class ClassLoaderData;
 53 
 54 size_t CollectedHeap::_filler_array_max_size = 0;
 55 
 56 template &lt;&gt;
 57 void EventLogBase&lt;GCMessage&gt;::print(outputStream* st, GCMessage&amp; m) {
 58   st-&gt;print_cr(&quot;GC heap %s&quot;, m.is_before ? &quot;before&quot; : &quot;after&quot;);
 59   st-&gt;print_raw(m);
 60 }
 61 
 62 void GCHeapLog::log_heap(CollectedHeap* heap, bool before) {
 63   if (!should_log()) {
 64     return;
 65   }
 66 
 67   double timestamp = fetch_timestamp();
<span class="line-modified"> 68   MutexLockerEx ml(&amp;_mutex, Mutex::_no_safepoint_check_flag);</span>
 69   int index = compute_log_index();
 70   _records[index].thread = NULL; // Its the GC thread so it&#39;s not that interesting.
 71   _records[index].timestamp = timestamp;
 72   _records[index].data.is_before = before;
 73   stringStream st(_records[index].data.buffer(), _records[index].data.size());
 74 
 75   st.print_cr(&quot;{Heap %s GC invocations=%u (full %u):&quot;,
 76                  before ? &quot;before&quot; : &quot;after&quot;,
 77                  heap-&gt;total_collections(),
 78                  heap-&gt;total_full_collections());
 79 
 80   heap-&gt;print_on(&amp;st);
 81   st.print_cr(&quot;}&quot;);
 82 }
 83 





 84 VirtualSpaceSummary CollectedHeap::create_heap_space_summary() {
 85   size_t capacity_in_words = capacity() / HeapWordSize;
 86 
 87   return VirtualSpaceSummary(
<span class="line-modified"> 88     reserved_region().start(), reserved_region().start() + capacity_in_words, reserved_region().end());</span>
 89 }
 90 
 91 GCHeapSummary CollectedHeap::create_heap_summary() {
 92   VirtualSpaceSummary heap_space = create_heap_space_summary();
 93   return GCHeapSummary(heap_space, used());
 94 }
 95 
 96 MetaspaceSummary CollectedHeap::create_metaspace_summary() {
 97   const MetaspaceSizes meta_space(
 98       MetaspaceUtils::committed_bytes(),
 99       MetaspaceUtils::used_bytes(),
100       MetaspaceUtils::reserved_bytes());
101   const MetaspaceSizes data_space(
102       MetaspaceUtils::committed_bytes(Metaspace::NonClassType),
103       MetaspaceUtils::used_bytes(Metaspace::NonClassType),
104       MetaspaceUtils::reserved_bytes(Metaspace::NonClassType));
105   const MetaspaceSizes class_space(
106       MetaspaceUtils::committed_bytes(Metaspace::ClassType),
107       MetaspaceUtils::used_bytes(Metaspace::ClassType),
108       MetaspaceUtils::reserved_bytes(Metaspace::ClassType));
</pre>
<hr />
<pre>
113     MetaspaceUtils::chunk_free_list_summary(Metaspace::ClassType);
114 
115   return MetaspaceSummary(MetaspaceGC::capacity_until_GC(), meta_space, data_space, class_space,
116                           ms_chunk_free_list_summary, class_chunk_free_list_summary);
117 }
118 
119 void CollectedHeap::print_heap_before_gc() {
120   Universe::print_heap_before_gc();
121   if (_gc_heap_log != NULL) {
122     _gc_heap_log-&gt;log_heap_before(this);
123   }
124 }
125 
126 void CollectedHeap::print_heap_after_gc() {
127   Universe::print_heap_after_gc();
128   if (_gc_heap_log != NULL) {
129     _gc_heap_log-&gt;log_heap_after(this);
130   }
131 }
132 


133 void CollectedHeap::print_on_error(outputStream* st) const {
134   st-&gt;print_cr(&quot;Heap:&quot;);
135   print_extended_on(st);
136   st-&gt;cr();
137 
138   BarrierSet::barrier_set()-&gt;print_on(st);
139 }
140 
141 void CollectedHeap::trace_heap(GCWhen::Type when, const GCTracer* gc_tracer) {
142   const GCHeapSummary&amp; heap_summary = create_heap_summary();
143   gc_tracer-&gt;report_gc_heap_summary(when, heap_summary);
144 
145   const MetaspaceSummary&amp; metaspace_summary = create_metaspace_summary();
146   gc_tracer-&gt;report_metaspace_summary(when, metaspace_summary);
147 }
148 
149 void CollectedHeap::trace_heap_before_gc(const GCTracer* gc_tracer) {
150   trace_heap(GCWhen::BeforeGC, gc_tracer);
151 }
152 
153 void CollectedHeap::trace_heap_after_gc(const GCTracer* gc_tracer) {
154   trace_heap(GCWhen::AfterGC, gc_tracer);
155 }
156 
157 // WhiteBox API support for concurrent collectors.  These are the
158 // default implementations, for collectors which don&#39;t support this
159 // feature.
160 bool CollectedHeap::supports_concurrent_phase_control() const {
161   return false;
162 }
163 
164 bool CollectedHeap::request_concurrent_phase(const char* phase) {
165   return false;
166 }
167 
168 bool CollectedHeap::is_oop(oop object) const {
<span class="line-modified">169   if (!check_obj_alignment(object)) {</span>
170     return false;
171   }
172 
<span class="line-modified">173   if (!is_in_reserved(object)) {</span>
174     return false;
175   }
176 
<span class="line-modified">177   if (is_in_reserved(object-&gt;klass_or_null())) {</span>
178     return false;
179   }
180 
181   return true;
182 }
183 
184 // Memory state functions.
185 
186 
187 CollectedHeap::CollectedHeap() :
188   _is_gc_active(false),
189   _total_collections(0),
190   _total_full_collections(0),
191   _gc_cause(GCCause::_no_gc),
192   _gc_lastcause(GCCause::_no_gc)
193 {
194   const size_t max_len = size_t(arrayOopDesc::max_array_length(T_INT));
195   const size_t elements_per_word = HeapWordSize / sizeof(jint);
196   _filler_array_max_size = align_object_size(filler_array_hdr_size() +
197                                              max_len / elements_per_word);
</pre>
<hr />
<pre>
310     if (op.prologue_succeeded()) {
311       return op.result();
312     }
313     loop_count++;
314     if ((QueuedAllocationWarningCount &gt; 0) &amp;&amp;
315         (loop_count % QueuedAllocationWarningCount == 0)) {
316       log_warning(gc, ergo)(&quot;satisfy_failed_metadata_allocation() retries %d times,&quot;
317                             &quot; size=&quot; SIZE_FORMAT, loop_count, word_size);
318     }
319   } while (true);  // Until a GC is done
320 }
321 
322 MemoryUsage CollectedHeap::memory_usage() {
323   return MemoryUsage(InitialHeapSize, used(), capacity(), max_capacity());
324 }
325 
326 
327 #ifndef PRODUCT
328 void CollectedHeap::check_for_non_bad_heap_word_value(HeapWord* addr, size_t size) {
329   if (CheckMemoryInitialization &amp;&amp; ZapUnusedHeapArea) {
<span class="line-modified">330     for (size_t slot = 0; slot &lt; size; slot += 1) {</span>
<span class="line-modified">331       assert((*(intptr_t*) (addr + slot)) == ((intptr_t) badHeapWordVal),</span>
<span class="line-modified">332              &quot;Found non badHeapWordValue in pre-allocation check&quot;);</span>
333     }
334   }
335 }
336 #endif // PRODUCT
337 
338 size_t CollectedHeap::max_tlab_size() const {
339   // TLABs can&#39;t be bigger than we can fill with a int[Integer.MAX_VALUE].
340   // This restriction could be removed by enabling filling with multiple arrays.
341   // If we compute that the reasonable way as
342   //    header_size + ((sizeof(jint) * max_jint) / HeapWordSize)
343   // we&#39;ll overflow on the multiply, so we do the divide first.
344   // We actually lose a little by dividing first,
345   // but that just makes the TLAB  somewhat smaller than the biggest array,
346   // which is fine, since we&#39;ll be able to fill that.
347   size_t max_int_size = typeArrayOopDesc::header_size(T_INT) +
348               sizeof(jint) *
349               ((juint) max_jint / (size_t) HeapWordSize);
350   return align_down(max_int_size, MinObjAlignment);
351 }
352 
353 size_t CollectedHeap::filler_array_hdr_size() {
354   return align_object_offset(arrayOopDesc::header_size(T_INT)); // align to Long
355 }
356 
357 size_t CollectedHeap::filler_array_min_size() {
358   return align_object_size(filler_array_hdr_size()); // align to MinObjAlignment
359 }
360 
361 #ifdef ASSERT
362 void CollectedHeap::fill_args_check(HeapWord* start, size_t words)
363 {
364   assert(words &gt;= min_fill_size(), &quot;too small to fill&quot;);
365   assert(is_object_aligned(words), &quot;unaligned size&quot;);
<span class="line-removed">366   assert(Universe::heap()-&gt;is_in_reserved(start), &quot;not in heap&quot;);</span>
<span class="line-removed">367   assert(Universe::heap()-&gt;is_in_reserved(start + words - 1), &quot;not in heap&quot;);</span>
368 }
369 
370 void CollectedHeap::zap_filler_array(HeapWord* start, size_t words, bool zap)
371 {
372   if (ZapFillerObjects &amp;&amp; zap) {
373     Copy::fill_to_words(start + filler_array_hdr_size(),
374                         words - filler_array_hdr_size(), 0XDEAFBABE);
375   }
376 }
377 #endif // ASSERT
378 
379 void
380 CollectedHeap::fill_with_array(HeapWord* start, size_t words, bool zap)
381 {
382   assert(words &gt;= filler_array_min_size(), &quot;too small for an array&quot;);
383   assert(words &lt;= filler_array_max_size(), &quot;too big for a single object&quot;);
384 
385   const size_t payload_size = words - filler_array_hdr_size();
386   const size_t len = payload_size * HeapWordSize / sizeof(jint);
387   assert((int)len &gt;= 0, &quot;size too large &quot; SIZE_FORMAT &quot; becomes %d&quot;, words, (int)len);
</pre>
<hr />
<pre>
491   }
492 
493   LogTarget(Trace, gc, classhisto) lt;
494   if (lt.is_enabled()) {
495     GCTraceTime(Trace, gc, classhisto) tm(before ? &quot;Class Histogram (before full gc)&quot; : &quot;Class Histogram (after full gc)&quot;, timer);
496     ResourceMark rm;
497     LogStream ls(lt);
498     VM_GC_HeapInspection inspector(&amp;ls, false /* ! full gc */);
499     inspector.doit();
500   }
501 }
502 
503 void CollectedHeap::pre_full_gc_dump(GCTimer* timer) {
504   full_gc_dump(timer, true);
505 }
506 
507 void CollectedHeap::post_full_gc_dump(GCTimer* timer) {
508   full_gc_dump(timer, false);
509 }
510 
<span class="line-modified">511 void CollectedHeap::initialize_reserved_region(HeapWord *start, HeapWord *end) {</span>
512   // It is important to do this in a way such that concurrent readers can&#39;t
513   // temporarily think something is in the heap.  (Seen this happen in asserts.)
514   _reserved.set_word_size(0);
<span class="line-modified">515   _reserved.set_start(start);</span>
<span class="line-modified">516   _reserved.set_end(end);</span>
517 }
518 
519 void CollectedHeap::post_initialize() {
520   initialize_serviceability();
521 }
522 
523 #ifndef PRODUCT
524 
525 bool CollectedHeap::promotion_should_fail(volatile size_t* count) {
526   // Access to count is not atomic; the value does not have to be exact.
527   if (PromotionFailureALot) {
528     const size_t gc_num = total_collections();
529     const size_t elapsed_gcs = gc_num - _promotion_failure_alot_gc_number;
530     if (elapsed_gcs &gt;= PromotionFailureALotInterval) {
531       // Test for unsigned arithmetic wrap-around.
532       if (++*count &gt;= PromotionFailureALotCount) {
533         *count = 0;
534         return true;
535       }
536     }
</pre>
<hr />
<pre>
558 bool CollectedHeap::supports_object_pinning() const {
559   return false;
560 }
561 
562 oop CollectedHeap::pin_object(JavaThread* thread, oop obj) {
563   ShouldNotReachHere();
564   return NULL;
565 }
566 
567 void CollectedHeap::unpin_object(JavaThread* thread, oop obj) {
568   ShouldNotReachHere();
569 }
570 
571 void CollectedHeap::deduplicate_string(oop str) {
572   // Do nothing, unless overridden in subclass.
573 }
574 
575 size_t CollectedHeap::obj_size(oop obj) const {
576   return obj-&gt;size();
577 }





</pre>
</td>
<td>
<hr />
<pre>
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;classfile/systemDictionary.hpp&quot;
 27 #include &quot;gc/shared/allocTracer.hpp&quot;
 28 #include &quot;gc/shared/barrierSet.hpp&quot;
 29 #include &quot;gc/shared/collectedHeap.hpp&quot;
 30 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
 31 #include &quot;gc/shared/gcLocker.inline.hpp&quot;
 32 #include &quot;gc/shared/gcHeapSummary.hpp&quot;
 33 #include &quot;gc/shared/gcTrace.hpp&quot;
 34 #include &quot;gc/shared/gcTraceTime.inline.hpp&quot;
 35 #include &quot;gc/shared/gcVMOperations.hpp&quot;
 36 #include &quot;gc/shared/gcWhen.hpp&quot;
 37 #include &quot;gc/shared/memAllocator.hpp&quot;
 38 #include &quot;logging/log.hpp&quot;
 39 #include &quot;memory/metaspace.hpp&quot;
 40 #include &quot;memory/resourceArea.hpp&quot;
<span class="line-added"> 41 #include &quot;memory/universe.hpp&quot;</span>
 42 #include &quot;oops/instanceMirrorKlass.hpp&quot;
 43 #include &quot;oops/oop.inline.hpp&quot;
 44 #include &quot;runtime/handles.inline.hpp&quot;
 45 #include &quot;runtime/init.hpp&quot;
 46 #include &quot;runtime/thread.inline.hpp&quot;
 47 #include &quot;runtime/threadSMR.hpp&quot;
 48 #include &quot;runtime/vmThread.hpp&quot;
 49 #include &quot;services/heapDumper.hpp&quot;
 50 #include &quot;utilities/align.hpp&quot;
 51 #include &quot;utilities/copy.hpp&quot;
 52 
 53 class ClassLoaderData;
 54 
 55 size_t CollectedHeap::_filler_array_max_size = 0;
 56 
 57 template &lt;&gt;
 58 void EventLogBase&lt;GCMessage&gt;::print(outputStream* st, GCMessage&amp; m) {
 59   st-&gt;print_cr(&quot;GC heap %s&quot;, m.is_before ? &quot;before&quot; : &quot;after&quot;);
 60   st-&gt;print_raw(m);
 61 }
 62 
 63 void GCHeapLog::log_heap(CollectedHeap* heap, bool before) {
 64   if (!should_log()) {
 65     return;
 66   }
 67 
 68   double timestamp = fetch_timestamp();
<span class="line-modified"> 69   MutexLocker ml(&amp;_mutex, Mutex::_no_safepoint_check_flag);</span>
 70   int index = compute_log_index();
 71   _records[index].thread = NULL; // Its the GC thread so it&#39;s not that interesting.
 72   _records[index].timestamp = timestamp;
 73   _records[index].data.is_before = before;
 74   stringStream st(_records[index].data.buffer(), _records[index].data.size());
 75 
 76   st.print_cr(&quot;{Heap %s GC invocations=%u (full %u):&quot;,
 77                  before ? &quot;before&quot; : &quot;after&quot;,
 78                  heap-&gt;total_collections(),
 79                  heap-&gt;total_full_collections());
 80 
 81   heap-&gt;print_on(&amp;st);
 82   st.print_cr(&quot;}&quot;);
 83 }
 84 
<span class="line-added"> 85 size_t CollectedHeap::unused() const {</span>
<span class="line-added"> 86   MutexLocker ml(Heap_lock);</span>
<span class="line-added"> 87   return capacity() - used();</span>
<span class="line-added"> 88 }</span>
<span class="line-added"> 89 </span>
 90 VirtualSpaceSummary CollectedHeap::create_heap_space_summary() {
 91   size_t capacity_in_words = capacity() / HeapWordSize;
 92 
 93   return VirtualSpaceSummary(
<span class="line-modified"> 94     _reserved.start(), _reserved.start() + capacity_in_words, _reserved.end());</span>
 95 }
 96 
 97 GCHeapSummary CollectedHeap::create_heap_summary() {
 98   VirtualSpaceSummary heap_space = create_heap_space_summary();
 99   return GCHeapSummary(heap_space, used());
100 }
101 
102 MetaspaceSummary CollectedHeap::create_metaspace_summary() {
103   const MetaspaceSizes meta_space(
104       MetaspaceUtils::committed_bytes(),
105       MetaspaceUtils::used_bytes(),
106       MetaspaceUtils::reserved_bytes());
107   const MetaspaceSizes data_space(
108       MetaspaceUtils::committed_bytes(Metaspace::NonClassType),
109       MetaspaceUtils::used_bytes(Metaspace::NonClassType),
110       MetaspaceUtils::reserved_bytes(Metaspace::NonClassType));
111   const MetaspaceSizes class_space(
112       MetaspaceUtils::committed_bytes(Metaspace::ClassType),
113       MetaspaceUtils::used_bytes(Metaspace::ClassType),
114       MetaspaceUtils::reserved_bytes(Metaspace::ClassType));
</pre>
<hr />
<pre>
119     MetaspaceUtils::chunk_free_list_summary(Metaspace::ClassType);
120 
121   return MetaspaceSummary(MetaspaceGC::capacity_until_GC(), meta_space, data_space, class_space,
122                           ms_chunk_free_list_summary, class_chunk_free_list_summary);
123 }
124 
125 void CollectedHeap::print_heap_before_gc() {
126   Universe::print_heap_before_gc();
127   if (_gc_heap_log != NULL) {
128     _gc_heap_log-&gt;log_heap_before(this);
129   }
130 }
131 
132 void CollectedHeap::print_heap_after_gc() {
133   Universe::print_heap_after_gc();
134   if (_gc_heap_log != NULL) {
135     _gc_heap_log-&gt;log_heap_after(this);
136   }
137 }
138 
<span class="line-added">139 void CollectedHeap::print() const { print_on(tty); }</span>
<span class="line-added">140 </span>
141 void CollectedHeap::print_on_error(outputStream* st) const {
142   st-&gt;print_cr(&quot;Heap:&quot;);
143   print_extended_on(st);
144   st-&gt;cr();
145 
146   BarrierSet::barrier_set()-&gt;print_on(st);
147 }
148 
149 void CollectedHeap::trace_heap(GCWhen::Type when, const GCTracer* gc_tracer) {
150   const GCHeapSummary&amp; heap_summary = create_heap_summary();
151   gc_tracer-&gt;report_gc_heap_summary(when, heap_summary);
152 
153   const MetaspaceSummary&amp; metaspace_summary = create_metaspace_summary();
154   gc_tracer-&gt;report_metaspace_summary(when, metaspace_summary);
155 }
156 
157 void CollectedHeap::trace_heap_before_gc(const GCTracer* gc_tracer) {
158   trace_heap(GCWhen::BeforeGC, gc_tracer);
159 }
160 
161 void CollectedHeap::trace_heap_after_gc(const GCTracer* gc_tracer) {
162   trace_heap(GCWhen::AfterGC, gc_tracer);
163 }
164 
165 // WhiteBox API support for concurrent collectors.  These are the
166 // default implementations, for collectors which don&#39;t support this
167 // feature.
168 bool CollectedHeap::supports_concurrent_phase_control() const {
169   return false;
170 }
171 
172 bool CollectedHeap::request_concurrent_phase(const char* phase) {
173   return false;
174 }
175 
176 bool CollectedHeap::is_oop(oop object) const {
<span class="line-modified">177   if (!is_object_aligned(object)) {</span>
178     return false;
179   }
180 
<span class="line-modified">181   if (!is_in(object)) {</span>
182     return false;
183   }
184 
<span class="line-modified">185   if (is_in(object-&gt;klass_or_null())) {</span>
186     return false;
187   }
188 
189   return true;
190 }
191 
192 // Memory state functions.
193 
194 
195 CollectedHeap::CollectedHeap() :
196   _is_gc_active(false),
197   _total_collections(0),
198   _total_full_collections(0),
199   _gc_cause(GCCause::_no_gc),
200   _gc_lastcause(GCCause::_no_gc)
201 {
202   const size_t max_len = size_t(arrayOopDesc::max_array_length(T_INT));
203   const size_t elements_per_word = HeapWordSize / sizeof(jint);
204   _filler_array_max_size = align_object_size(filler_array_hdr_size() +
205                                              max_len / elements_per_word);
</pre>
<hr />
<pre>
318     if (op.prologue_succeeded()) {
319       return op.result();
320     }
321     loop_count++;
322     if ((QueuedAllocationWarningCount &gt; 0) &amp;&amp;
323         (loop_count % QueuedAllocationWarningCount == 0)) {
324       log_warning(gc, ergo)(&quot;satisfy_failed_metadata_allocation() retries %d times,&quot;
325                             &quot; size=&quot; SIZE_FORMAT, loop_count, word_size);
326     }
327   } while (true);  // Until a GC is done
328 }
329 
330 MemoryUsage CollectedHeap::memory_usage() {
331   return MemoryUsage(InitialHeapSize, used(), capacity(), max_capacity());
332 }
333 
334 
335 #ifndef PRODUCT
336 void CollectedHeap::check_for_non_bad_heap_word_value(HeapWord* addr, size_t size) {
337   if (CheckMemoryInitialization &amp;&amp; ZapUnusedHeapArea) {
<span class="line-modified">338     // please note mismatch between size (in 32/64 bit words), and ju_addr that always point to a 32 bit word</span>
<span class="line-modified">339     for (juint* ju_addr = reinterpret_cast&lt;juint*&gt;(addr); ju_addr &lt; reinterpret_cast&lt;juint*&gt;(addr + size); ++ju_addr) {</span>
<span class="line-modified">340       assert(*ju_addr == badHeapWordVal, &quot;Found non badHeapWordValue in pre-allocation check&quot;);</span>
341     }
342   }
343 }
344 #endif // PRODUCT
345 
346 size_t CollectedHeap::max_tlab_size() const {
347   // TLABs can&#39;t be bigger than we can fill with a int[Integer.MAX_VALUE].
348   // This restriction could be removed by enabling filling with multiple arrays.
349   // If we compute that the reasonable way as
350   //    header_size + ((sizeof(jint) * max_jint) / HeapWordSize)
351   // we&#39;ll overflow on the multiply, so we do the divide first.
352   // We actually lose a little by dividing first,
353   // but that just makes the TLAB  somewhat smaller than the biggest array,
354   // which is fine, since we&#39;ll be able to fill that.
355   size_t max_int_size = typeArrayOopDesc::header_size(T_INT) +
356               sizeof(jint) *
357               ((juint) max_jint / (size_t) HeapWordSize);
358   return align_down(max_int_size, MinObjAlignment);
359 }
360 
361 size_t CollectedHeap::filler_array_hdr_size() {
362   return align_object_offset(arrayOopDesc::header_size(T_INT)); // align to Long
363 }
364 
365 size_t CollectedHeap::filler_array_min_size() {
366   return align_object_size(filler_array_hdr_size()); // align to MinObjAlignment
367 }
368 
369 #ifdef ASSERT
370 void CollectedHeap::fill_args_check(HeapWord* start, size_t words)
371 {
372   assert(words &gt;= min_fill_size(), &quot;too small to fill&quot;);
373   assert(is_object_aligned(words), &quot;unaligned size&quot;);


374 }
375 
376 void CollectedHeap::zap_filler_array(HeapWord* start, size_t words, bool zap)
377 {
378   if (ZapFillerObjects &amp;&amp; zap) {
379     Copy::fill_to_words(start + filler_array_hdr_size(),
380                         words - filler_array_hdr_size(), 0XDEAFBABE);
381   }
382 }
383 #endif // ASSERT
384 
385 void
386 CollectedHeap::fill_with_array(HeapWord* start, size_t words, bool zap)
387 {
388   assert(words &gt;= filler_array_min_size(), &quot;too small for an array&quot;);
389   assert(words &lt;= filler_array_max_size(), &quot;too big for a single object&quot;);
390 
391   const size_t payload_size = words - filler_array_hdr_size();
392   const size_t len = payload_size * HeapWordSize / sizeof(jint);
393   assert((int)len &gt;= 0, &quot;size too large &quot; SIZE_FORMAT &quot; becomes %d&quot;, words, (int)len);
</pre>
<hr />
<pre>
497   }
498 
499   LogTarget(Trace, gc, classhisto) lt;
500   if (lt.is_enabled()) {
501     GCTraceTime(Trace, gc, classhisto) tm(before ? &quot;Class Histogram (before full gc)&quot; : &quot;Class Histogram (after full gc)&quot;, timer);
502     ResourceMark rm;
503     LogStream ls(lt);
504     VM_GC_HeapInspection inspector(&amp;ls, false /* ! full gc */);
505     inspector.doit();
506   }
507 }
508 
509 void CollectedHeap::pre_full_gc_dump(GCTimer* timer) {
510   full_gc_dump(timer, true);
511 }
512 
513 void CollectedHeap::post_full_gc_dump(GCTimer* timer) {
514   full_gc_dump(timer, false);
515 }
516 
<span class="line-modified">517 void CollectedHeap::initialize_reserved_region(const ReservedHeapSpace&amp; rs) {</span>
518   // It is important to do this in a way such that concurrent readers can&#39;t
519   // temporarily think something is in the heap.  (Seen this happen in asserts.)
520   _reserved.set_word_size(0);
<span class="line-modified">521   _reserved.set_start((HeapWord*)rs.base());</span>
<span class="line-modified">522   _reserved.set_end((HeapWord*)rs.end());</span>
523 }
524 
525 void CollectedHeap::post_initialize() {
526   initialize_serviceability();
527 }
528 
529 #ifndef PRODUCT
530 
531 bool CollectedHeap::promotion_should_fail(volatile size_t* count) {
532   // Access to count is not atomic; the value does not have to be exact.
533   if (PromotionFailureALot) {
534     const size_t gc_num = total_collections();
535     const size_t elapsed_gcs = gc_num - _promotion_failure_alot_gc_number;
536     if (elapsed_gcs &gt;= PromotionFailureALotInterval) {
537       // Test for unsigned arithmetic wrap-around.
538       if (++*count &gt;= PromotionFailureALotCount) {
539         *count = 0;
540         return true;
541       }
542     }
</pre>
<hr />
<pre>
564 bool CollectedHeap::supports_object_pinning() const {
565   return false;
566 }
567 
568 oop CollectedHeap::pin_object(JavaThread* thread, oop obj) {
569   ShouldNotReachHere();
570   return NULL;
571 }
572 
573 void CollectedHeap::unpin_object(JavaThread* thread, oop obj) {
574   ShouldNotReachHere();
575 }
576 
577 void CollectedHeap::deduplicate_string(oop str) {
578   // Do nothing, unless overridden in subclass.
579 }
580 
581 size_t CollectedHeap::obj_size(oop obj) const {
582   return obj-&gt;size();
583 }
<span class="line-added">584 </span>
<span class="line-added">585 uint32_t CollectedHeap::hash_oop(oop obj) const {</span>
<span class="line-added">586   const uintptr_t addr = cast_from_oop&lt;uintptr_t&gt;(obj);</span>
<span class="line-added">587   return static_cast&lt;uint32_t&gt;(addr &gt;&gt; LogMinObjAlignment);</span>
<span class="line-added">588 }</span>
</pre>
</td>
</tr>
</table>
<center><a href="cardTableRS.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="collectedHeap.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>