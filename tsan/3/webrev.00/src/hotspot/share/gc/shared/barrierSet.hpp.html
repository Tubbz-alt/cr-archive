<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/gc/shared/barrierSet.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_GC_SHARED_BARRIERSET_HPP
 26 #define SHARE_GC_SHARED_BARRIERSET_HPP
 27 
 28 #include &quot;gc/shared/barrierSetConfig.hpp&quot;
 29 #include &quot;memory/memRegion.hpp&quot;
 30 #include &quot;oops/access.hpp&quot;
 31 #include &quot;oops/accessBackend.hpp&quot;
 32 #include &quot;oops/oopsHierarchy.hpp&quot;
 33 #include &quot;utilities/fakeRttiSupport.hpp&quot;
 34 #include &quot;utilities/macros.hpp&quot;
 35 
 36 class BarrierSetAssembler;
 37 class BarrierSetC1;
 38 class BarrierSetC2;
 39 class BarrierSetNMethod;
 40 class JavaThread;
 41 
 42 // This class provides the interface between a barrier implementation and
 43 // the rest of the system.
 44 
 45 class BarrierSet: public CHeapObj&lt;mtGC&gt; {
 46   friend class VMStructs;
 47 
 48   static BarrierSet* _barrier_set;
 49 
 50 public:
 51   enum Name {
 52 #define BARRIER_SET_DECLARE_BS_ENUM(bs_name) bs_name ,
 53     FOR_EACH_BARRIER_SET_DO(BARRIER_SET_DECLARE_BS_ENUM)
 54 #undef BARRIER_SET_DECLARE_BS_ENUM
 55     UnknownBS
 56   };
 57 
 58 protected:
 59   // Fake RTTI support.  For a derived class T to participate
 60   // - T must have a corresponding Name entry.
 61   // - GetName&lt;T&gt; must be specialized to return the corresponding Name
 62   //   entry.
 63   // - If T is a base class, the constructor must have a FakeRtti
 64   //   parameter and pass it up to its base class, with the tag set
 65   //   augmented with the corresponding Name entry.
 66   // - If T is a concrete class, the constructor must create a
 67   //   FakeRtti object whose tag set includes the corresponding Name
 68   //   entry, and pass it up to its base class.
 69   typedef FakeRttiSupport&lt;BarrierSet, Name&gt; FakeRtti;
 70 
 71 private:
 72   FakeRtti _fake_rtti;
 73   BarrierSetAssembler* _barrier_set_assembler;
 74   BarrierSetC1* _barrier_set_c1;
 75   BarrierSetC2* _barrier_set_c2;
 76   BarrierSetNMethod* _barrier_set_nmethod;
 77 
 78 public:
 79   // Metafunction mapping a class derived from BarrierSet to the
 80   // corresponding Name enum tag.
 81   template&lt;typename T&gt; struct GetName;
 82 
 83   // Metafunction mapping a Name enum type to the corresponding
 84   // lass derived from BarrierSet.
 85   template&lt;BarrierSet::Name T&gt; struct GetType;
 86 
 87   // Note: This is not presently the Name corresponding to the
 88   // concrete class of this object.
 89   BarrierSet::Name kind() const { return _fake_rtti.concrete_tag(); }
 90 
 91   // Test whether this object is of the type corresponding to bsn.
 92   bool is_a(BarrierSet::Name bsn) const { return _fake_rtti.has_tag(bsn); }
 93 
 94   // End of fake RTTI support.
 95 
 96 protected:
 97   BarrierSet(BarrierSetAssembler* barrier_set_assembler,
 98              BarrierSetC1* barrier_set_c1,
 99              BarrierSetC2* barrier_set_c2,
100              BarrierSetNMethod* barrier_set_nmethod,
101              const FakeRtti&amp; fake_rtti) :
102     _fake_rtti(fake_rtti),
103     _barrier_set_assembler(barrier_set_assembler),
104     _barrier_set_c1(barrier_set_c1),
105     _barrier_set_c2(barrier_set_c2),
106     _barrier_set_nmethod(barrier_set_nmethod) {}
107   ~BarrierSet() { }
108 
109   template &lt;class BarrierSetAssemblerT&gt;
110   static BarrierSetAssembler* make_barrier_set_assembler() {
111     return NOT_ZERO(new BarrierSetAssemblerT()) ZERO_ONLY(NULL);
112   }
113 
114   template &lt;class BarrierSetC1T&gt;
115   static BarrierSetC1* make_barrier_set_c1() {
116     return COMPILER1_PRESENT(new BarrierSetC1T()) NOT_COMPILER1(NULL);
117   }
118 
119   template &lt;class BarrierSetC2T&gt;
120   static BarrierSetC2* make_barrier_set_c2() {
121     return COMPILER2_PRESENT(new BarrierSetC2T()) NOT_COMPILER2(NULL);
122   }
123 
124 public:
125   // Support for optimizing compilers to call the barrier set on slow path allocations
126   // that did not enter a TLAB. Used for e.g. ReduceInitialCardMarks.
127   // The allocation is safe to use iff it returns true. If not, the slow-path allocation
128   // is redone until it succeeds. This can e.g. prevent allocations from the slow path
129   // to be in old.
130   virtual void on_slowpath_allocation_exit(JavaThread* thread, oop new_obj) {}
131   virtual void on_thread_create(Thread* thread) {}
132   virtual void on_thread_destroy(Thread* thread) {}
133 
134   // These perform BarrierSet-related initialization/cleanup before the thread
135   // is added to or removed from the corresponding set of threads. The
136   // argument thread is the current thread. These are called either holding
137   // the Threads_lock (for a JavaThread) and so not at a safepoint, or holding
138   // the NonJavaThreadsList_lock (for a NonJavaThread) locked by the
139   // caller. That locking ensures the operation is &quot;atomic&quot; with the list
140   // modification wrto operations that hold the NJTList_lock and either also
141   // hold the Threads_lock or are at a safepoint.
142   virtual void on_thread_attach(Thread* thread) {}
143   virtual void on_thread_detach(Thread* thread) {}
144 
145   virtual void make_parsable(JavaThread* thread) {}
146 
147 public:
148   // Print a description of the memory for the barrier set
149   virtual void print_on(outputStream* st) const = 0;
150 
151   static BarrierSet* barrier_set() { return _barrier_set; }
152   static void set_barrier_set(BarrierSet* barrier_set);
153 
154   BarrierSetAssembler* barrier_set_assembler() {
155     assert(_barrier_set_assembler != NULL, &quot;should be set&quot;);
156     return _barrier_set_assembler;
157   }
158 
159   BarrierSetC1* barrier_set_c1() {
160     assert(_barrier_set_c1 != NULL, &quot;should be set&quot;);
161     return _barrier_set_c1;
162   }
163 
164   BarrierSetC2* barrier_set_c2() {
165     assert(_barrier_set_c2 != NULL, &quot;should be set&quot;);
166     return _barrier_set_c2;
167   }
168 
169   BarrierSetNMethod* barrier_set_nmethod() {
170     return _barrier_set_nmethod;
171   }
172 
173   // The AccessBarrier of a BarrierSet subclass is called by the Access API
174   // (cf. oops/access.hpp) to perform decorated accesses. GC implementations
175   // may override these default access operations by declaring an
176   // AccessBarrier class in its BarrierSet. Its accessors will then be
177   // automatically resolved at runtime.
178   //
179   // In order to register a new FooBarrierSet::AccessBarrier with the Access API,
180   // the following steps should be taken:
181   // 1) Provide an enum &quot;name&quot; for the BarrierSet in barrierSetConfig.hpp
182   // 2) Make sure the barrier set headers are included from barrierSetConfig.inline.hpp
183   // 3) Provide specializations for BarrierSet::GetName and BarrierSet::GetType.
184   template &lt;DecoratorSet decorators, typename BarrierSetT&gt;
185   class AccessBarrier: protected RawAccessBarrier&lt;decorators&gt; {
186   private:
187     typedef RawAccessBarrier&lt;decorators&gt; Raw;
188 
189   public:
190     // Primitive heap accesses. These accessors get resolved when
191     // IN_HEAP is set (e.g. when using the HeapAccess API), it is
192     // not an oop_* overload, and the barrier strength is AS_NORMAL.
193     template &lt;typename T&gt;
194     static T load_in_heap(T* addr) {
195       return Raw::template load&lt;T&gt;(addr);
196     }
197 
198     template &lt;typename T&gt;
199     static T load_in_heap_at(oop base, ptrdiff_t offset) {
200       return Raw::template load_at&lt;T&gt;(base, offset);
201     }
202 
203     template &lt;typename T&gt;
204     static void store_in_heap(T* addr, T value) {
205       Raw::store(addr, value);
206     }
207 
208     template &lt;typename T&gt;
209     static void store_in_heap_at(oop base, ptrdiff_t offset, T value) {
210       Raw::store_at(base, offset, value);
211     }
212 
213     template &lt;typename T&gt;
214     static T atomic_cmpxchg_in_heap(T* addr, T compare_value, T new_value) {
215       return Raw::atomic_cmpxchg(addr, compare_value, new_value);
216     }
217 
218     template &lt;typename T&gt;
219     static T atomic_cmpxchg_in_heap_at(oop base, ptrdiff_t offset, T compare_value, T new_value) {
220       return Raw::atomic_cmpxchg_at(base, offset, compare_value, new_value);
221     }
222 
223     template &lt;typename T&gt;
224     static T atomic_xchg_in_heap(T* addr, T new_value) {
225       return Raw::atomic_xchg(addr, new_value);
226     }
227 
228     template &lt;typename T&gt;
229     static T atomic_xchg_in_heap_at(oop base, ptrdiff_t offset, T new_value) {
230       return Raw::atomic_xchg_at(base, offset, new_value);
231     }
232 
233     template &lt;typename T&gt;
234     static void arraycopy_in_heap(arrayOop src_obj, size_t src_offset_in_bytes, T* src_raw,
235                                   arrayOop dst_obj, size_t dst_offset_in_bytes, T* dst_raw,
236                                   size_t length) {
237       Raw::arraycopy(src_obj, src_offset_in_bytes, src_raw,
238                      dst_obj, dst_offset_in_bytes, dst_raw,
239                      length);
240     }
241 
242     // Heap oop accesses. These accessors get resolved when
243     // IN_HEAP is set (e.g. when using the HeapAccess API), it is
244     // an oop_* overload, and the barrier strength is AS_NORMAL.
245     template &lt;typename T&gt;
246     static oop oop_load_in_heap(T* addr) {
247       return Raw::template oop_load&lt;oop&gt;(addr);
248     }
249 
250     static oop oop_load_in_heap_at(oop base, ptrdiff_t offset) {
251       return Raw::template oop_load_at&lt;oop&gt;(base, offset);
252     }
253 
254     template &lt;typename T&gt;
255     static void oop_store_in_heap(T* addr, oop value) {
256       Raw::oop_store(addr, value);
257     }
258 
259     static void oop_store_in_heap_at(oop base, ptrdiff_t offset, oop value) {
260       Raw::oop_store_at(base, offset, value);
261     }
262 
263     template &lt;typename T&gt;
264     static oop oop_atomic_cmpxchg_in_heap(T* addr, oop compare_value, oop new_value) {
265       return Raw::oop_atomic_cmpxchg(addr, compare_value, new_value);
266     }
267 
268     static oop oop_atomic_cmpxchg_in_heap_at(oop base, ptrdiff_t offset, oop compare_value, oop new_value) {
269       return Raw::oop_atomic_cmpxchg_at(base, offset, compare_value, new_value);
270     }
271 
272     template &lt;typename T&gt;
273     static oop oop_atomic_xchg_in_heap(T* addr, oop new_value) {
274       return Raw::oop_atomic_xchg(addr, new_value);
275     }
276 
277     static oop oop_atomic_xchg_in_heap_at(oop base, ptrdiff_t offset, oop new_value) {
278       return Raw::oop_atomic_xchg_at(base, offset, new_value);
279     }
280 
281     template &lt;typename T&gt;
282     static bool oop_arraycopy_in_heap(arrayOop src_obj, size_t src_offset_in_bytes, T* src_raw,
283                                       arrayOop dst_obj, size_t dst_offset_in_bytes, T* dst_raw,
284                                       size_t length);
285 
286     // Off-heap oop accesses. These accessors get resolved when
287     // IN_HEAP is not set (e.g. when using the NativeAccess API), it is
288     // an oop* overload, and the barrier strength is AS_NORMAL.
289     template &lt;typename T&gt;
290     static oop oop_load_not_in_heap(T* addr) {
291       return Raw::template oop_load&lt;oop&gt;(addr);
292     }
293 
294     template &lt;typename T&gt;
295     static void oop_store_not_in_heap(T* addr, oop value) {
296       Raw::oop_store(addr, value);
297     }
298 
299     template &lt;typename T&gt;
300     static oop oop_atomic_cmpxchg_not_in_heap(T* addr, oop compare_value, oop new_value) {
301       return Raw::oop_atomic_cmpxchg(addr, compare_value, new_value);
302     }
303 
304     template &lt;typename T&gt;
305     static oop oop_atomic_xchg_not_in_heap(T* addr, oop new_value) {
306       return Raw::oop_atomic_xchg(addr, new_value);
307     }
308 
309     // Clone barrier support
310     static void clone_in_heap(oop src, oop dst, size_t size) {
311       Raw::clone(src, dst, size);
312     }
313 
314     static oop resolve(oop obj) {
315       return Raw::resolve(obj);
316     }
317   };
318 };
319 
320 template&lt;typename T&gt;
321 inline T* barrier_set_cast(BarrierSet* bs) {
322   assert(bs-&gt;is_a(BarrierSet::GetName&lt;T&gt;::value), &quot;wrong type of barrier set&quot;);
323   return static_cast&lt;T*&gt;(bs);
324 }
325 
326 #endif // SHARE_GC_SHARED_BARRIERSET_HPP
    </pre>
  </body>
</html>