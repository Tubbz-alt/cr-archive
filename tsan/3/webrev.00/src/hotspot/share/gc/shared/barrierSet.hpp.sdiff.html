<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/shared/barrierSet.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="ageTable.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="barrierSetNMethod.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shared/barrierSet.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
113 
114   template &lt;class BarrierSetC1T&gt;
115   static BarrierSetC1* make_barrier_set_c1() {
116     return COMPILER1_PRESENT(new BarrierSetC1T()) NOT_COMPILER1(NULL);
117   }
118 
119   template &lt;class BarrierSetC2T&gt;
120   static BarrierSetC2* make_barrier_set_c2() {
121     return COMPILER2_PRESENT(new BarrierSetC2T()) NOT_COMPILER2(NULL);
122   }
123 
124 public:
125   // Support for optimizing compilers to call the barrier set on slow path allocations
126   // that did not enter a TLAB. Used for e.g. ReduceInitialCardMarks.
127   // The allocation is safe to use iff it returns true. If not, the slow-path allocation
128   // is redone until it succeeds. This can e.g. prevent allocations from the slow path
129   // to be in old.
130   virtual void on_slowpath_allocation_exit(JavaThread* thread, oop new_obj) {}
131   virtual void on_thread_create(Thread* thread) {}
132   virtual void on_thread_destroy(Thread* thread) {}









133   virtual void on_thread_attach(Thread* thread) {}
134   virtual void on_thread_detach(Thread* thread) {}
<span class="line-removed">135   virtual void make_parsable(JavaThread* thread) {}</span>
136 
<span class="line-modified">137 #ifdef CHECK_UNHANDLED_OOPS</span>
<span class="line-removed">138   virtual bool oop_equals_operator_allowed() { return true; }</span>
<span class="line-removed">139 #endif</span>
140 
141 public:
142   // Print a description of the memory for the barrier set
143   virtual void print_on(outputStream* st) const = 0;
144 
145   static BarrierSet* barrier_set() { return _barrier_set; }
146   static void set_barrier_set(BarrierSet* barrier_set);
147 
148   BarrierSetAssembler* barrier_set_assembler() {
149     assert(_barrier_set_assembler != NULL, &quot;should be set&quot;);
150     return _barrier_set_assembler;
151   }
152 
153   BarrierSetC1* barrier_set_c1() {
154     assert(_barrier_set_c1 != NULL, &quot;should be set&quot;);
155     return _barrier_set_c1;
156   }
157 
158   BarrierSetC2* barrier_set_c2() {
159     assert(_barrier_set_c2 != NULL, &quot;should be set&quot;);
</pre>
<hr />
<pre>
188     static T load_in_heap(T* addr) {
189       return Raw::template load&lt;T&gt;(addr);
190     }
191 
192     template &lt;typename T&gt;
193     static T load_in_heap_at(oop base, ptrdiff_t offset) {
194       return Raw::template load_at&lt;T&gt;(base, offset);
195     }
196 
197     template &lt;typename T&gt;
198     static void store_in_heap(T* addr, T value) {
199       Raw::store(addr, value);
200     }
201 
202     template &lt;typename T&gt;
203     static void store_in_heap_at(oop base, ptrdiff_t offset, T value) {
204       Raw::store_at(base, offset, value);
205     }
206 
207     template &lt;typename T&gt;
<span class="line-modified">208     static T atomic_cmpxchg_in_heap(T new_value, T* addr, T compare_value) {</span>
<span class="line-modified">209       return Raw::atomic_cmpxchg(new_value, addr, compare_value);</span>
210     }
211 
212     template &lt;typename T&gt;
<span class="line-modified">213     static T atomic_cmpxchg_in_heap_at(T new_value, oop base, ptrdiff_t offset, T compare_value) {</span>
<span class="line-modified">214       return Raw::atomic_cmpxchg_at(new_value, base, offset, compare_value);</span>
215     }
216 
217     template &lt;typename T&gt;
<span class="line-modified">218     static T atomic_xchg_in_heap(T new_value, T* addr) {</span>
<span class="line-modified">219       return Raw::atomic_xchg(new_value, addr);</span>
220     }
221 
222     template &lt;typename T&gt;
<span class="line-modified">223     static T atomic_xchg_in_heap_at(T new_value, oop base, ptrdiff_t offset) {</span>
<span class="line-modified">224       return Raw::atomic_xchg_at(new_value, base, offset);</span>
225     }
226 
227     template &lt;typename T&gt;
228     static void arraycopy_in_heap(arrayOop src_obj, size_t src_offset_in_bytes, T* src_raw,
229                                   arrayOop dst_obj, size_t dst_offset_in_bytes, T* dst_raw,
230                                   size_t length) {
231       Raw::arraycopy(src_obj, src_offset_in_bytes, src_raw,
232                      dst_obj, dst_offset_in_bytes, dst_raw,
233                      length);
234     }
235 
236     // Heap oop accesses. These accessors get resolved when
237     // IN_HEAP is set (e.g. when using the HeapAccess API), it is
238     // an oop_* overload, and the barrier strength is AS_NORMAL.
239     template &lt;typename T&gt;
240     static oop oop_load_in_heap(T* addr) {
241       return Raw::template oop_load&lt;oop&gt;(addr);
242     }
243 
244     static oop oop_load_in_heap_at(oop base, ptrdiff_t offset) {
245       return Raw::template oop_load_at&lt;oop&gt;(base, offset);
246     }
247 
248     template &lt;typename T&gt;
249     static void oop_store_in_heap(T* addr, oop value) {
250       Raw::oop_store(addr, value);
251     }
252 
253     static void oop_store_in_heap_at(oop base, ptrdiff_t offset, oop value) {
254       Raw::oop_store_at(base, offset, value);
255     }
256 
257     template &lt;typename T&gt;
<span class="line-modified">258     static oop oop_atomic_cmpxchg_in_heap(oop new_value, T* addr, oop compare_value) {</span>
<span class="line-modified">259       return Raw::oop_atomic_cmpxchg(new_value, addr, compare_value);</span>
260     }
261 
<span class="line-modified">262     static oop oop_atomic_cmpxchg_in_heap_at(oop new_value, oop base, ptrdiff_t offset, oop compare_value) {</span>
<span class="line-modified">263       return Raw::oop_atomic_cmpxchg_at(new_value, base, offset, compare_value);</span>
264     }
265 
266     template &lt;typename T&gt;
<span class="line-modified">267     static oop oop_atomic_xchg_in_heap(oop new_value, T* addr) {</span>
<span class="line-modified">268       return Raw::oop_atomic_xchg(new_value, addr);</span>
269     }
270 
<span class="line-modified">271     static oop oop_atomic_xchg_in_heap_at(oop new_value, oop base, ptrdiff_t offset) {</span>
<span class="line-modified">272       return Raw::oop_atomic_xchg_at(new_value, base, offset);</span>
273     }
274 
275     template &lt;typename T&gt;
276     static bool oop_arraycopy_in_heap(arrayOop src_obj, size_t src_offset_in_bytes, T* src_raw,
277                                       arrayOop dst_obj, size_t dst_offset_in_bytes, T* dst_raw,
278                                       size_t length);
279 
280     // Off-heap oop accesses. These accessors get resolved when
281     // IN_HEAP is not set (e.g. when using the NativeAccess API), it is
282     // an oop* overload, and the barrier strength is AS_NORMAL.
283     template &lt;typename T&gt;
284     static oop oop_load_not_in_heap(T* addr) {
285       return Raw::template oop_load&lt;oop&gt;(addr);
286     }
287 
288     template &lt;typename T&gt;
289     static void oop_store_not_in_heap(T* addr, oop value) {
290       Raw::oop_store(addr, value);
291     }
292 
293     template &lt;typename T&gt;
<span class="line-modified">294     static oop oop_atomic_cmpxchg_not_in_heap(oop new_value, T* addr, oop compare_value) {</span>
<span class="line-modified">295       return Raw::oop_atomic_cmpxchg(new_value, addr, compare_value);</span>
296     }
297 
298     template &lt;typename T&gt;
<span class="line-modified">299     static oop oop_atomic_xchg_not_in_heap(oop new_value, T* addr) {</span>
<span class="line-modified">300       return Raw::oop_atomic_xchg(new_value, addr);</span>
301     }
302 
303     // Clone barrier support
304     static void clone_in_heap(oop src, oop dst, size_t size) {
305       Raw::clone(src, dst, size);
306     }
307 
308     static oop resolve(oop obj) {
309       return Raw::resolve(obj);
310     }
<span class="line-removed">311 </span>
<span class="line-removed">312     static bool equals(oop o1, oop o2) {</span>
<span class="line-removed">313       return Raw::equals(o1, o2);</span>
<span class="line-removed">314     }</span>
315   };
316 };
317 
318 template&lt;typename T&gt;
319 inline T* barrier_set_cast(BarrierSet* bs) {
320   assert(bs-&gt;is_a(BarrierSet::GetName&lt;T&gt;::value), &quot;wrong type of barrier set&quot;);
321   return static_cast&lt;T*&gt;(bs);
322 }
323 
324 #endif // SHARE_GC_SHARED_BARRIERSET_HPP
</pre>
</td>
<td>
<hr />
<pre>
113 
114   template &lt;class BarrierSetC1T&gt;
115   static BarrierSetC1* make_barrier_set_c1() {
116     return COMPILER1_PRESENT(new BarrierSetC1T()) NOT_COMPILER1(NULL);
117   }
118 
119   template &lt;class BarrierSetC2T&gt;
120   static BarrierSetC2* make_barrier_set_c2() {
121     return COMPILER2_PRESENT(new BarrierSetC2T()) NOT_COMPILER2(NULL);
122   }
123 
124 public:
125   // Support for optimizing compilers to call the barrier set on slow path allocations
126   // that did not enter a TLAB. Used for e.g. ReduceInitialCardMarks.
127   // The allocation is safe to use iff it returns true. If not, the slow-path allocation
128   // is redone until it succeeds. This can e.g. prevent allocations from the slow path
129   // to be in old.
130   virtual void on_slowpath_allocation_exit(JavaThread* thread, oop new_obj) {}
131   virtual void on_thread_create(Thread* thread) {}
132   virtual void on_thread_destroy(Thread* thread) {}
<span class="line-added">133 </span>
<span class="line-added">134   // These perform BarrierSet-related initialization/cleanup before the thread</span>
<span class="line-added">135   // is added to or removed from the corresponding set of threads. The</span>
<span class="line-added">136   // argument thread is the current thread. These are called either holding</span>
<span class="line-added">137   // the Threads_lock (for a JavaThread) and so not at a safepoint, or holding</span>
<span class="line-added">138   // the NonJavaThreadsList_lock (for a NonJavaThread) locked by the</span>
<span class="line-added">139   // caller. That locking ensures the operation is &quot;atomic&quot; with the list</span>
<span class="line-added">140   // modification wrto operations that hold the NJTList_lock and either also</span>
<span class="line-added">141   // hold the Threads_lock or are at a safepoint.</span>
142   virtual void on_thread_attach(Thread* thread) {}
143   virtual void on_thread_detach(Thread* thread) {}

144 
<span class="line-modified">145   virtual void make_parsable(JavaThread* thread) {}</span>


146 
147 public:
148   // Print a description of the memory for the barrier set
149   virtual void print_on(outputStream* st) const = 0;
150 
151   static BarrierSet* barrier_set() { return _barrier_set; }
152   static void set_barrier_set(BarrierSet* barrier_set);
153 
154   BarrierSetAssembler* barrier_set_assembler() {
155     assert(_barrier_set_assembler != NULL, &quot;should be set&quot;);
156     return _barrier_set_assembler;
157   }
158 
159   BarrierSetC1* barrier_set_c1() {
160     assert(_barrier_set_c1 != NULL, &quot;should be set&quot;);
161     return _barrier_set_c1;
162   }
163 
164   BarrierSetC2* barrier_set_c2() {
165     assert(_barrier_set_c2 != NULL, &quot;should be set&quot;);
</pre>
<hr />
<pre>
194     static T load_in_heap(T* addr) {
195       return Raw::template load&lt;T&gt;(addr);
196     }
197 
198     template &lt;typename T&gt;
199     static T load_in_heap_at(oop base, ptrdiff_t offset) {
200       return Raw::template load_at&lt;T&gt;(base, offset);
201     }
202 
203     template &lt;typename T&gt;
204     static void store_in_heap(T* addr, T value) {
205       Raw::store(addr, value);
206     }
207 
208     template &lt;typename T&gt;
209     static void store_in_heap_at(oop base, ptrdiff_t offset, T value) {
210       Raw::store_at(base, offset, value);
211     }
212 
213     template &lt;typename T&gt;
<span class="line-modified">214     static T atomic_cmpxchg_in_heap(T* addr, T compare_value, T new_value) {</span>
<span class="line-modified">215       return Raw::atomic_cmpxchg(addr, compare_value, new_value);</span>
216     }
217 
218     template &lt;typename T&gt;
<span class="line-modified">219     static T atomic_cmpxchg_in_heap_at(oop base, ptrdiff_t offset, T compare_value, T new_value) {</span>
<span class="line-modified">220       return Raw::atomic_cmpxchg_at(base, offset, compare_value, new_value);</span>
221     }
222 
223     template &lt;typename T&gt;
<span class="line-modified">224     static T atomic_xchg_in_heap(T* addr, T new_value) {</span>
<span class="line-modified">225       return Raw::atomic_xchg(addr, new_value);</span>
226     }
227 
228     template &lt;typename T&gt;
<span class="line-modified">229     static T atomic_xchg_in_heap_at(oop base, ptrdiff_t offset, T new_value) {</span>
<span class="line-modified">230       return Raw::atomic_xchg_at(base, offset, new_value);</span>
231     }
232 
233     template &lt;typename T&gt;
234     static void arraycopy_in_heap(arrayOop src_obj, size_t src_offset_in_bytes, T* src_raw,
235                                   arrayOop dst_obj, size_t dst_offset_in_bytes, T* dst_raw,
236                                   size_t length) {
237       Raw::arraycopy(src_obj, src_offset_in_bytes, src_raw,
238                      dst_obj, dst_offset_in_bytes, dst_raw,
239                      length);
240     }
241 
242     // Heap oop accesses. These accessors get resolved when
243     // IN_HEAP is set (e.g. when using the HeapAccess API), it is
244     // an oop_* overload, and the barrier strength is AS_NORMAL.
245     template &lt;typename T&gt;
246     static oop oop_load_in_heap(T* addr) {
247       return Raw::template oop_load&lt;oop&gt;(addr);
248     }
249 
250     static oop oop_load_in_heap_at(oop base, ptrdiff_t offset) {
251       return Raw::template oop_load_at&lt;oop&gt;(base, offset);
252     }
253 
254     template &lt;typename T&gt;
255     static void oop_store_in_heap(T* addr, oop value) {
256       Raw::oop_store(addr, value);
257     }
258 
259     static void oop_store_in_heap_at(oop base, ptrdiff_t offset, oop value) {
260       Raw::oop_store_at(base, offset, value);
261     }
262 
263     template &lt;typename T&gt;
<span class="line-modified">264     static oop oop_atomic_cmpxchg_in_heap(T* addr, oop compare_value, oop new_value) {</span>
<span class="line-modified">265       return Raw::oop_atomic_cmpxchg(addr, compare_value, new_value);</span>
266     }
267 
<span class="line-modified">268     static oop oop_atomic_cmpxchg_in_heap_at(oop base, ptrdiff_t offset, oop compare_value, oop new_value) {</span>
<span class="line-modified">269       return Raw::oop_atomic_cmpxchg_at(base, offset, compare_value, new_value);</span>
270     }
271 
272     template &lt;typename T&gt;
<span class="line-modified">273     static oop oop_atomic_xchg_in_heap(T* addr, oop new_value) {</span>
<span class="line-modified">274       return Raw::oop_atomic_xchg(addr, new_value);</span>
275     }
276 
<span class="line-modified">277     static oop oop_atomic_xchg_in_heap_at(oop base, ptrdiff_t offset, oop new_value) {</span>
<span class="line-modified">278       return Raw::oop_atomic_xchg_at(base, offset, new_value);</span>
279     }
280 
281     template &lt;typename T&gt;
282     static bool oop_arraycopy_in_heap(arrayOop src_obj, size_t src_offset_in_bytes, T* src_raw,
283                                       arrayOop dst_obj, size_t dst_offset_in_bytes, T* dst_raw,
284                                       size_t length);
285 
286     // Off-heap oop accesses. These accessors get resolved when
287     // IN_HEAP is not set (e.g. when using the NativeAccess API), it is
288     // an oop* overload, and the barrier strength is AS_NORMAL.
289     template &lt;typename T&gt;
290     static oop oop_load_not_in_heap(T* addr) {
291       return Raw::template oop_load&lt;oop&gt;(addr);
292     }
293 
294     template &lt;typename T&gt;
295     static void oop_store_not_in_heap(T* addr, oop value) {
296       Raw::oop_store(addr, value);
297     }
298 
299     template &lt;typename T&gt;
<span class="line-modified">300     static oop oop_atomic_cmpxchg_not_in_heap(T* addr, oop compare_value, oop new_value) {</span>
<span class="line-modified">301       return Raw::oop_atomic_cmpxchg(addr, compare_value, new_value);</span>
302     }
303 
304     template &lt;typename T&gt;
<span class="line-modified">305     static oop oop_atomic_xchg_not_in_heap(T* addr, oop new_value) {</span>
<span class="line-modified">306       return Raw::oop_atomic_xchg(addr, new_value);</span>
307     }
308 
309     // Clone barrier support
310     static void clone_in_heap(oop src, oop dst, size_t size) {
311       Raw::clone(src, dst, size);
312     }
313 
314     static oop resolve(oop obj) {
315       return Raw::resolve(obj);
316     }




317   };
318 };
319 
320 template&lt;typename T&gt;
321 inline T* barrier_set_cast(BarrierSet* bs) {
322   assert(bs-&gt;is_a(BarrierSet::GetName&lt;T&gt;::value), &quot;wrong type of barrier set&quot;);
323   return static_cast&lt;T*&gt;(bs);
324 }
325 
326 #endif // SHARE_GC_SHARED_BARRIERSET_HPP
</pre>
</td>
</tr>
</table>
<center><a href="ageTable.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="barrierSetNMethod.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>