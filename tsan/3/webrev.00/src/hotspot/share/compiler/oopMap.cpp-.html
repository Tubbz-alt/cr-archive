<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/compiler/oopMap.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 1998, 2018, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;code/codeBlob.hpp&quot;
 27 #include &quot;code/codeCache.hpp&quot;
 28 #include &quot;code/nmethod.hpp&quot;
 29 #include &quot;code/scopeDesc.hpp&quot;
 30 #include &quot;compiler/oopMap.hpp&quot;
 31 #include &quot;gc/shared/collectedHeap.hpp&quot;
 32 #include &quot;memory/allocation.inline.hpp&quot;
 33 #include &quot;memory/iterator.hpp&quot;
 34 #include &quot;memory/resourceArea.hpp&quot;
 35 #include &quot;runtime/frame.inline.hpp&quot;
 36 #include &quot;runtime/handles.inline.hpp&quot;
 37 #include &quot;runtime/signature.hpp&quot;
 38 #include &quot;utilities/align.hpp&quot;
 39 #ifdef COMPILER1
 40 #include &quot;c1/c1_Defs.hpp&quot;
 41 #endif
 42 #ifdef COMPILER2
 43 #include &quot;opto/optoreg.hpp&quot;
 44 #endif
 45 
 46 // OopMapStream
 47 
 48 OopMapStream::OopMapStream(OopMap* oop_map, int oop_types_mask) {
 49   _stream = new CompressedReadStream(oop_map-&gt;write_stream()-&gt;buffer());
 50   _mask = oop_types_mask;
 51   _size = oop_map-&gt;omv_count();
 52   _position = 0;
 53   _valid_omv = false;
 54 }
 55 
 56 OopMapStream::OopMapStream(const ImmutableOopMap* oop_map, int oop_types_mask) {
 57   _stream = new CompressedReadStream(oop_map-&gt;data_addr());
 58   _mask = oop_types_mask;
 59   _size = oop_map-&gt;count();
 60   _position = 0;
 61   _valid_omv = false;
 62 }
 63 
 64 void OopMapStream::find_next() {
 65   while(_position++ &lt; _size) {
 66     _omv.read_from(_stream);
 67     if(((int)_omv.type() &amp; _mask) &gt; 0) {
 68       _valid_omv = true;
 69       return;
 70     }
 71   }
 72   _valid_omv = false;
 73 }
 74 
 75 
 76 // OopMap
 77 
 78 // frame_size units are stack-slots (4 bytes) NOT intptr_t; we can name odd
 79 // slots to hold 4-byte values like ints and floats in the LP64 build.
 80 OopMap::OopMap(int frame_size, int arg_count) {
 81   // OopMaps are usually quite so small, so pick a small initial size
 82   set_write_stream(new CompressedWriteStream(32));
 83   set_omv_count(0);
 84 
 85 #ifdef ASSERT
 86   _locs_length = VMRegImpl::stack2reg(0)-&gt;value() + frame_size + arg_count;
 87   _locs_used   = NEW_RESOURCE_ARRAY(OopMapValue::oop_types, _locs_length);
 88   for(int i = 0; i &lt; _locs_length; i++) _locs_used[i] = OopMapValue::unused_value;
 89 #endif
 90 }
 91 
 92 
 93 OopMap::OopMap(OopMap::DeepCopyToken, OopMap* source) {
 94   // This constructor does a deep copy
 95   // of the source OopMap.
 96   set_write_stream(new CompressedWriteStream(source-&gt;omv_count() * 2));
 97   set_omv_count(0);
 98   set_offset(source-&gt;offset());
 99 
100 #ifdef ASSERT
101   _locs_length = source-&gt;_locs_length;
102   _locs_used = NEW_RESOURCE_ARRAY(OopMapValue::oop_types, _locs_length);
103   for(int i = 0; i &lt; _locs_length; i++) _locs_used[i] = OopMapValue::unused_value;
104 #endif
105 
106   // We need to copy the entries too.
107   for (OopMapStream oms(source); !oms.is_done(); oms.next()) {
108     OopMapValue omv = oms.current();
109     omv.write_on(write_stream());
110     increment_count();
111   }
112 }
113 
114 
115 OopMap* OopMap::deep_copy() {
116   return new OopMap(_deep_copy_token, this);
117 }
118 
119 void OopMap::copy_data_to(address addr) const {
120   memcpy(addr, write_stream()-&gt;buffer(), write_stream()-&gt;position());
121 }
122 
123 int OopMap::heap_size() const {
124   int size = sizeof(OopMap);
125   int align = sizeof(void *) - 1;
126   size += write_stream()-&gt;position();
127   // Align to a reasonable ending point
128   size = ((size+align) &amp; ~align);
129   return size;
130 }
131 
132 // frame_size units are stack-slots (4 bytes) NOT intptr_t; we can name odd
133 // slots to hold 4-byte values like ints and floats in the LP64 build.
134 void OopMap::set_xxx(VMReg reg, OopMapValue::oop_types x, VMReg optional) {
135 
136   assert(reg-&gt;value() &lt; _locs_length, &quot;too big reg value for stack size&quot;);
137   assert( _locs_used[reg-&gt;value()] == OopMapValue::unused_value, &quot;cannot insert twice&quot; );
138   debug_only( _locs_used[reg-&gt;value()] = x; )
139 
140   OopMapValue o(reg, x);
141 
142   if(x == OopMapValue::callee_saved_value) {
143     // This can never be a stack location, so we don&#39;t need to transform it.
144     assert(optional-&gt;is_reg(), &quot;Trying to callee save a stack location&quot;);
145     o.set_content_reg(optional);
146   } else if(x == OopMapValue::derived_oop_value) {
147     o.set_content_reg(optional);
148   }
149 
150   o.write_on(write_stream());
151   increment_count();
152 }
153 
154 
155 void OopMap::set_oop(VMReg reg) {
156   set_xxx(reg, OopMapValue::oop_value, VMRegImpl::Bad());
157 }
158 
159 
160 void OopMap::set_value(VMReg reg) {
161   // At this time, we don&#39;t need value entries in our OopMap.
162 }
163 
164 
165 void OopMap::set_narrowoop(VMReg reg) {
166   set_xxx(reg, OopMapValue::narrowoop_value, VMRegImpl::Bad());
167 }
168 
169 
170 void OopMap::set_callee_saved(VMReg reg, VMReg caller_machine_register ) {
171   set_xxx(reg, OopMapValue::callee_saved_value, caller_machine_register);
172 }
173 
174 
175 void OopMap::set_derived_oop(VMReg reg, VMReg derived_from_local_register ) {
176   if( reg == derived_from_local_register ) {
177     // Actually an oop, derived shares storage with base,
178     set_oop(reg);
179   } else {
180     set_xxx(reg, OopMapValue::derived_oop_value, derived_from_local_register);
181   }
182 }
183 
184 // OopMapSet
185 
186 OopMapSet::OopMapSet() {
187   set_om_size(MinOopMapAllocation);
188   set_om_count(0);
189   OopMap** temp = NEW_RESOURCE_ARRAY(OopMap*, om_size());
190   set_om_data(temp);
191 }
192 
193 
194 void OopMapSet::grow_om_data() {
195   int new_size = om_size() * 2;
196   OopMap** new_data = NEW_RESOURCE_ARRAY(OopMap*, new_size);
197   memcpy(new_data,om_data(),om_size() * sizeof(OopMap*));
198   set_om_size(new_size);
199   set_om_data(new_data);
200 }
201 
202 void OopMapSet::add_gc_map(int pc_offset, OopMap *map ) {
203   assert(om_size() != -1,&quot;Cannot grow a fixed OopMapSet&quot;);
204 
205   if(om_count() &gt;= om_size()) {
206     grow_om_data();
207   }
208   map-&gt;set_offset(pc_offset);
209 
210 #ifdef ASSERT
211   if(om_count() &gt; 0) {
212     OopMap* last = at(om_count()-1);
213     if (last-&gt;offset() == map-&gt;offset() ) {
214       fatal(&quot;OopMap inserted twice&quot;);
215     }
216     if(last-&gt;offset() &gt; map-&gt;offset()) {
217       tty-&gt;print_cr( &quot;WARNING, maps not sorted: pc[%d]=%d, pc[%d]=%d&quot;,
218                       om_count(),last-&gt;offset(),om_count()+1,map-&gt;offset());
219     }
220   }
221 #endif // ASSERT
222 
223   set(om_count(),map);
224   increment_count();
225 }
226 
227 
228 int OopMapSet::heap_size() const {
229   // The space we use
230   int size = sizeof(OopMap);
231   int align = sizeof(void *) - 1;
232   size = ((size+align) &amp; ~align);
233   size += om_count() * sizeof(OopMap*);
234 
235   // Now add in the space needed for the indivdiual OopMaps
236   for(int i=0; i &lt; om_count(); i++) {
237     size += at(i)-&gt;heap_size();
238   }
239   // We don&#39;t need to align this, it will be naturally pointer aligned
240   return size;
241 }
242 
243 
244 OopMap* OopMapSet::singular_oop_map() {
245   guarantee(om_count() == 1, &quot;Make sure we only have a single gc point&quot;);
246   return at(0);
247 }
248 
249 
250 OopMap* OopMapSet::find_map_at_offset(int pc_offset) const {
251   int i, len = om_count();
252   assert( len &gt; 0, &quot;must have pointer maps&quot; );
253 
254   // Scan through oopmaps. Stop when current offset is either equal or greater
255   // than the one we are looking for.
256   for( i = 0; i &lt; len; i++) {
257     if( at(i)-&gt;offset() &gt;= pc_offset )
258       break;
259   }
260 
261   assert( i &lt; len, &quot;oopmap not found&quot; );
262 
263   OopMap* m = at(i);
264   assert( m-&gt;offset() == pc_offset, &quot;oopmap not found&quot; );
265   return m;
266 }
267 
268 static void add_derived_oop(oop* base, oop* derived) {
269 #if !defined(TIERED) &amp;&amp; !INCLUDE_JVMCI
270   COMPILER1_PRESENT(ShouldNotReachHere();)
271 #endif // !defined(TIERED) &amp;&amp; !INCLUDE_JVMCI
272 #if COMPILER2_OR_JVMCI
273   DerivedPointerTable::add(derived, base);
274 #endif // COMPILER2_OR_JVMCI
275 }
276 
277 
278 #ifndef PRODUCT
279 static void trace_codeblob_maps(const frame *fr, const RegisterMap *reg_map) {
280   // Print oopmap and regmap
281   tty-&gt;print_cr(&quot;------ &quot;);
282   CodeBlob* cb = fr-&gt;cb();
283   const ImmutableOopMapSet* maps = cb-&gt;oop_maps();
284   const ImmutableOopMap* map = cb-&gt;oop_map_for_return_address(fr-&gt;pc());
285   map-&gt;print();
286   if( cb-&gt;is_nmethod() ) {
287     nmethod* nm = (nmethod*)cb;
288     // native wrappers have no scope data, it is implied
289     if (nm-&gt;is_native_method()) {
290       tty-&gt;print(&quot;bci: 0 (native)&quot;);
291     } else {
292       ScopeDesc* scope  = nm-&gt;scope_desc_at(fr-&gt;pc());
293       tty-&gt;print(&quot;bci: %d &quot;,scope-&gt;bci());
294     }
295   }
296   tty-&gt;cr();
297   fr-&gt;print_on(tty);
298   tty-&gt;print(&quot;     &quot;);
299   cb-&gt;print_value_on(tty);  tty-&gt;cr();
300   reg_map-&gt;print();
301   tty-&gt;print_cr(&quot;------ &quot;);
302 
303 }
304 #endif // PRODUCT
305 
306 void OopMapSet::oops_do(const frame *fr, const RegisterMap* reg_map, OopClosure* f) {
307   // add derived oops to a table
308   all_do(fr, reg_map, f, add_derived_oop, &amp;do_nothing_cl);
309 }
310 
311 
312 void OopMapSet::all_do(const frame *fr, const RegisterMap *reg_map,
313                        OopClosure* oop_fn, void derived_oop_fn(oop*, oop*),
314                        OopClosure* value_fn) {
315   CodeBlob* cb = fr-&gt;cb();
316   assert(cb != NULL, &quot;no codeblob&quot;);
317 
318   NOT_PRODUCT(if (TraceCodeBlobStacks) trace_codeblob_maps(fr, reg_map);)
319 
320   const ImmutableOopMapSet* maps = cb-&gt;oop_maps();
321   const ImmutableOopMap* map = cb-&gt;oop_map_for_return_address(fr-&gt;pc());
322   assert(map != NULL, &quot;no ptr map found&quot;);
323 
324   // handle derived pointers first (otherwise base pointer may be
325   // changed before derived pointer offset has been collected)
326   OopMapValue omv;
327   {
328     OopMapStream oms(map,OopMapValue::derived_oop_value);
329     if (!oms.is_done()) {
330 #ifndef TIERED
331       COMPILER1_PRESENT(ShouldNotReachHere();)
332 #if INCLUDE_JVMCI
333       if (UseJVMCICompiler) {
334         ShouldNotReachHere();
335       }
336 #endif
337 #endif // !TIERED
338       // Protect the operation on the derived pointers.  This
339       // protects the addition of derived pointers to the shared
340       // derived pointer table in DerivedPointerTable::add().
341       MutexLockerEx x(DerivedPointerTableGC_lock, Mutex::_no_safepoint_check_flag);
342       do {
343         omv = oms.current();
344         oop* loc = fr-&gt;oopmapreg_to_location(omv.reg(),reg_map);
345         guarantee(loc != NULL, &quot;missing saved register&quot;);
346         oop *derived_loc = loc;
347         oop *base_loc    = fr-&gt;oopmapreg_to_location(omv.content_reg(), reg_map);
348         // Ignore NULL oops and decoded NULL narrow oops which
349         // equal to Universe::narrow_oop_base when a narrow oop
350         // implicit null check is used in compiled code.
351         // The narrow_oop_base could be NULL or be the address
352         // of the page below heap depending on compressed oops mode.
353         if (base_loc != NULL &amp;&amp; *base_loc != NULL &amp;&amp; !Universe::is_narrow_oop_base(*base_loc)) {
354           derived_oop_fn(base_loc, derived_loc);
355         }
356         oms.next();
357       }  while (!oms.is_done());
358     }
359   }
360 
361   // We want coop and oop oop_types
362   int mask = OopMapValue::oop_value | OopMapValue::narrowoop_value;
363   {
364     for (OopMapStream oms(map,mask); !oms.is_done(); oms.next()) {
365       omv = oms.current();
366       oop* loc = fr-&gt;oopmapreg_to_location(omv.reg(),reg_map);
367       // It should be an error if no location can be found for a
368       // register mentioned as contained an oop of some kind.  Maybe
369       // this was allowed previously because value_value items might
370       // be missing?
371       guarantee(loc != NULL, &quot;missing saved register&quot;);
372       if ( omv.type() == OopMapValue::oop_value ) {
373         oop val = *loc;
374         if (val == NULL || Universe::is_narrow_oop_base(val)) {
375           // Ignore NULL oops and decoded NULL narrow oops which
376           // equal to Universe::narrow_oop_base when a narrow oop
377           // implicit null check is used in compiled code.
378           // The narrow_oop_base could be NULL or be the address
379           // of the page below heap depending on compressed oops mode.
380           continue;
381         }
382 #ifdef ASSERT
383         // We can not verify the oop here if we are using ZGC, the oop
384         // will be bad in case we had a safepoint between a load and a
385         // load barrier.
386         if (!UseZGC &amp;&amp;
387             ((((uintptr_t)loc &amp; (sizeof(*loc)-1)) != 0) ||
388              !Universe::heap()-&gt;is_in_or_null(*loc))) {
389           tty-&gt;print_cr(&quot;# Found non oop pointer.  Dumping state at failure&quot;);
390           // try to dump out some helpful debugging information
391           trace_codeblob_maps(fr, reg_map);
392           omv.print();
393           tty-&gt;print_cr(&quot;register r&quot;);
394           omv.reg()-&gt;print();
395           tty-&gt;print_cr(&quot;loc = %p *loc = %p\n&quot;, loc, (address)*loc);
396           // do the real assert.
397           assert(Universe::heap()-&gt;is_in_or_null(*loc), &quot;found non oop pointer&quot;);
398         }
399 #endif // ASSERT
400         oop_fn-&gt;do_oop(loc);
401       } else if ( omv.type() == OopMapValue::narrowoop_value ) {
402         narrowOop *nl = (narrowOop*)loc;
403 #ifndef VM_LITTLE_ENDIAN
404         VMReg vmReg = omv.reg();
405         // Don&#39;t do this on SPARC float registers as they can be individually addressed
406         if (!vmReg-&gt;is_stack() SPARC_ONLY(&amp;&amp; !vmReg-&gt;is_FloatRegister())) {
407           // compressed oops in registers only take up 4 bytes of an
408           // 8 byte register but they are in the wrong part of the
409           // word so adjust loc to point at the right place.
410           nl = (narrowOop*)((address)nl + 4);
411         }
412 #endif
413         oop_fn-&gt;do_oop(nl);
414       }
415     }
416   }
417 }
418 
419 
420 // Update callee-saved register info for the following frame
421 void OopMapSet::update_register_map(const frame *fr, RegisterMap *reg_map) {
422   ResourceMark rm;
423   CodeBlob* cb = fr-&gt;cb();
424   assert(cb != NULL, &quot;no codeblob&quot;);
425 
426   // Any reg might be saved by a safepoint handler (see generate_handler_blob).
427   assert( reg_map-&gt;_update_for_id == NULL || fr-&gt;is_older(reg_map-&gt;_update_for_id),
428          &quot;already updated this map; do not &#39;update&#39; it twice!&quot; );
429   debug_only(reg_map-&gt;_update_for_id = fr-&gt;id());
430 
431   // Check if caller must update oop argument
432   assert((reg_map-&gt;include_argument_oops() ||
433           !cb-&gt;caller_must_gc_arguments(reg_map-&gt;thread())),
434          &quot;include_argument_oops should already be set&quot;);
435 
436   // Scan through oopmap and find location of all callee-saved registers
437   // (we do not do update in place, since info could be overwritten)
438 
439   address pc = fr-&gt;pc();
440   const ImmutableOopMap* map  = cb-&gt;oop_map_for_return_address(pc);
441   assert(map != NULL, &quot;no ptr map found&quot;);
442   DEBUG_ONLY(int nof_callee = 0;)
443 
444   for (OopMapStream oms(map, OopMapValue::callee_saved_value); !oms.is_done(); oms.next()) {
445     OopMapValue omv = oms.current();
446     VMReg reg = omv.content_reg();
447     oop* loc = fr-&gt;oopmapreg_to_location(omv.reg(), reg_map);
448     reg_map-&gt;set_location(reg, (address) loc);
449     DEBUG_ONLY(nof_callee++;)
450   }
451 
452   // Check that runtime stubs save all callee-saved registers
453 #ifdef COMPILER2
454   assert(cb-&gt;is_compiled_by_c1() || cb-&gt;is_compiled_by_jvmci() || !cb-&gt;is_runtime_stub() ||
455          (nof_callee &gt;= SAVED_ON_ENTRY_REG_COUNT || nof_callee &gt;= C_SAVED_ON_ENTRY_REG_COUNT),
456          &quot;must save all&quot;);
457 #endif // COMPILER2
458 }
459 
460 //=============================================================================
461 // Non-Product code
462 
463 #ifndef PRODUCT
464 
465 bool ImmutableOopMap::has_derived_pointer() const {
466 #if !defined(TIERED) &amp;&amp; !INCLUDE_JVMCI
467   COMPILER1_PRESENT(return false);
468 #endif // !TIERED
469 #if COMPILER2_OR_JVMCI
470   OopMapStream oms(this,OopMapValue::derived_oop_value);
471   return oms.is_done();
472 #else
473   return false;
474 #endif // COMPILER2_OR_JVMCI
475 }
476 
477 #endif //PRODUCT
478 
479 // Printing code is present in product build for -XX:+PrintAssembly.
480 
481 static
482 void print_register_type(OopMapValue::oop_types x, VMReg optional,
483                          outputStream* st) {
484   switch( x ) {
485   case OopMapValue::oop_value:
486     st-&gt;print(&quot;Oop&quot;);
487     break;
488   case OopMapValue::narrowoop_value:
489     st-&gt;print(&quot;NarrowOop&quot;);
490     break;
491   case OopMapValue::callee_saved_value:
492     st-&gt;print(&quot;Callers_&quot;);
493     optional-&gt;print_on(st);
494     break;
495   case OopMapValue::derived_oop_value:
496     st-&gt;print(&quot;Derived_oop_&quot;);
497     optional-&gt;print_on(st);
498     break;
499   default:
500     ShouldNotReachHere();
501   }
502 }
503 
504 void OopMapValue::print_on(outputStream* st) const {
505   reg()-&gt;print_on(st);
506   st-&gt;print(&quot;=&quot;);
507   print_register_type(type(),content_reg(),st);
508   st-&gt;print(&quot; &quot;);
509 }
510 
511 void ImmutableOopMap::print_on(outputStream* st) const {
512   OopMapValue omv;
513   st-&gt;print(&quot;ImmutableOopMap{&quot;);
514   for(OopMapStream oms(this); !oms.is_done(); oms.next()) {
515     omv = oms.current();
516     omv.print_on(st);
517   }
518   st-&gt;print(&quot;}&quot;);
519 }
520 
521 void OopMap::print_on(outputStream* st) const {
522   OopMapValue omv;
523   st-&gt;print(&quot;OopMap{&quot;);
524   for(OopMapStream oms((OopMap*)this); !oms.is_done(); oms.next()) {
525     omv = oms.current();
526     omv.print_on(st);
527   }
528   st-&gt;print(&quot;off=%d}&quot;, (int) offset());
529 }
530 
531 void ImmutableOopMapSet::print_on(outputStream* st) const {
532   const ImmutableOopMap* last = NULL;
533   for (int i = 0; i &lt; _count; ++i) {
534     const ImmutableOopMapPair* pair = pair_at(i);
535     const ImmutableOopMap* map = pair-&gt;get_from(this);
536     if (map != last) {
537       st-&gt;cr();
538       map-&gt;print_on(st);
539       st-&gt;print(&quot;pc offsets: &quot;);
540     }
541     last = map;
542     st-&gt;print(&quot;%d &quot;, pair-&gt;pc_offset());
543   }
544 }
545 
546 void OopMapSet::print_on(outputStream* st) const {
547   int i, len = om_count();
548 
549   st-&gt;print_cr(&quot;OopMapSet contains %d OopMaps\n&quot;,len);
550 
551   for( i = 0; i &lt; len; i++) {
552     OopMap* m = at(i);
553     st-&gt;print_cr(&quot;#%d &quot;,i);
554     m-&gt;print_on(st);
555     st-&gt;cr();
556   }
557 }
558 
559 bool OopMap::equals(const OopMap* other) const {
560   if (other-&gt;_omv_count != _omv_count) {
561     return false;
562   }
563   if (other-&gt;write_stream()-&gt;position() != write_stream()-&gt;position()) {
564     return false;
565   }
566   if (memcmp(other-&gt;write_stream()-&gt;buffer(), write_stream()-&gt;buffer(), write_stream()-&gt;position()) != 0) {
567     return false;
568   }
569   return true;
570 }
571 
572 const ImmutableOopMap* ImmutableOopMapSet::find_map_at_offset(int pc_offset) const {
573   ImmutableOopMapPair* pairs = get_pairs();
574 
575   int i;
576   for (i = 0; i &lt; _count; ++i) {
577     if (pairs[i].pc_offset() &gt;= pc_offset) {
578       break;
579     }
580   }
581   ImmutableOopMapPair* last = &amp;pairs[i];
582 
583   assert(last-&gt;pc_offset() == pc_offset, &quot;oopmap not found&quot;);
584   return last-&gt;get_from(this);
585 }
586 
587 const ImmutableOopMap* ImmutableOopMapPair::get_from(const ImmutableOopMapSet* set) const {
588   return set-&gt;oopmap_at_offset(_oopmap_offset);
589 }
590 
591 ImmutableOopMap::ImmutableOopMap(const OopMap* oopmap) : _count(oopmap-&gt;count()) {
592   address addr = data_addr();
593   oopmap-&gt;copy_data_to(addr);
594 }
595 
596 #ifdef ASSERT
597 int ImmutableOopMap::nr_of_bytes() const {
598   OopMapStream oms(this);
599 
600   while (!oms.is_done()) {
601     oms.next();
602   }
603   return sizeof(ImmutableOopMap) + oms.stream_position();
604 }
605 #endif
606 
607 ImmutableOopMapBuilder::ImmutableOopMapBuilder(const OopMapSet* set) : _set(set), _empty(NULL), _last(NULL), _empty_offset(-1), _last_offset(-1), _offset(0), _required(-1), _new_set(NULL) {
608   _mapping = NEW_RESOURCE_ARRAY(Mapping, _set-&gt;size());
609 }
610 
611 int ImmutableOopMapBuilder::size_for(const OopMap* map) const {
612   return align_up((int)sizeof(ImmutableOopMap) + map-&gt;data_size(), 8);
613 }
614 
615 int ImmutableOopMapBuilder::heap_size() {
616   int base = sizeof(ImmutableOopMapSet);
617   base = align_up(base, 8);
618 
619   // all of ours pc / offset pairs
620   int pairs = _set-&gt;size() * sizeof(ImmutableOopMapPair);
621   pairs = align_up(pairs, 8);
622 
623   for (int i = 0; i &lt; _set-&gt;size(); ++i) {
624     int size = 0;
625     OopMap* map = _set-&gt;at(i);
626 
627     if (is_empty(map)) {
628       /* only keep a single empty map in the set */
629       if (has_empty()) {
630         _mapping[i].set(Mapping::OOPMAP_EMPTY, _empty_offset, 0, map, _empty);
631       } else {
632         _empty_offset = _offset;
633         _empty = map;
634         size = size_for(map);
635         _mapping[i].set(Mapping::OOPMAP_NEW, _offset, size, map);
636       }
637     } else if (is_last_duplicate(map)) {
638       /* if this entry is identical to the previous one, just point it there */
639       _mapping[i].set(Mapping::OOPMAP_DUPLICATE, _last_offset, 0, map, _last);
640     } else {
641       /* not empty, not an identical copy of the previous entry */
642       size = size_for(map);
643       _mapping[i].set(Mapping::OOPMAP_NEW, _offset, size, map);
644       _last_offset = _offset;
645       _last = map;
646     }
647 
648     assert(_mapping[i]._map == map, &quot;check&quot;);
649     _offset += size;
650   }
651 
652   int total = base + pairs + _offset;
653   DEBUG_ONLY(total += 8);
654   _required = total;
655   return total;
656 }
657 
658 void ImmutableOopMapBuilder::fill_pair(ImmutableOopMapPair* pair, const OopMap* map, int offset, const ImmutableOopMapSet* set) {
659   assert(offset &lt; set-&gt;nr_of_bytes(), &quot;check&quot;);
660   new ((address) pair) ImmutableOopMapPair(map-&gt;offset(), offset);
661 }
662 
663 int ImmutableOopMapBuilder::fill_map(ImmutableOopMapPair* pair, const OopMap* map, int offset, const ImmutableOopMapSet* set) {
664   fill_pair(pair, map, offset, set);
665   address addr = (address) pair-&gt;get_from(_new_set); // location of the ImmutableOopMap
666 
667   new (addr) ImmutableOopMap(map);
668   return size_for(map);
669 }
670 
671 void ImmutableOopMapBuilder::fill(ImmutableOopMapSet* set, int sz) {
672   ImmutableOopMapPair* pairs = set-&gt;get_pairs();
673 
674   for (int i = 0; i &lt; set-&gt;count(); ++i) {
675     const OopMap* map = _mapping[i]._map;
676     ImmutableOopMapPair* pair = NULL;
677     int size = 0;
678 
679     if (_mapping[i]._kind == Mapping::OOPMAP_NEW) {
680       size = fill_map(&amp;pairs[i], map, _mapping[i]._offset, set);
681     } else if (_mapping[i]._kind == Mapping::OOPMAP_DUPLICATE || _mapping[i]._kind == Mapping::OOPMAP_EMPTY) {
682       fill_pair(&amp;pairs[i], map, _mapping[i]._offset, set);
683     }
684 
685     const ImmutableOopMap* nv = set-&gt;find_map_at_offset(map-&gt;offset());
686     assert(memcmp(map-&gt;data(), nv-&gt;data_addr(), map-&gt;data_size()) == 0, &quot;check identity&quot;);
687   }
688 }
689 
690 #ifdef ASSERT
691 void ImmutableOopMapBuilder::verify(address buffer, int size, const ImmutableOopMapSet* set) {
692   for (int i = 0; i &lt; 8; ++i) {
693     assert(buffer[size - 8 + i] == (unsigned char) 0xff, &quot;overwritten memory check&quot;);
694   }
695 
696   for (int i = 0; i &lt; set-&gt;count(); ++i) {
697     const ImmutableOopMapPair* pair = set-&gt;pair_at(i);
698     assert(pair-&gt;oopmap_offset() &lt; set-&gt;nr_of_bytes(), &quot;check size&quot;);
699     const ImmutableOopMap* map = pair-&gt;get_from(set);
700     int nr_of_bytes = map-&gt;nr_of_bytes();
701     assert(pair-&gt;oopmap_offset() + nr_of_bytes &lt;= set-&gt;nr_of_bytes(), &quot;check size + size&quot;);
702   }
703 }
704 #endif
705 
706 ImmutableOopMapSet* ImmutableOopMapBuilder::generate_into(address buffer) {
707   DEBUG_ONLY(memset(&amp;buffer[_required-8], 0xff, 8));
708 
709   _new_set = new (buffer) ImmutableOopMapSet(_set, _required);
710   fill(_new_set, _required);
711 
712   DEBUG_ONLY(verify(buffer, _required, _new_set));
713 
714   return _new_set;
715 }
716 
717 ImmutableOopMapSet* ImmutableOopMapBuilder::build() {
718   _required = heap_size();
719 
720   // We need to allocate a chunk big enough to hold the ImmutableOopMapSet and all of its ImmutableOopMaps
721   address buffer = (address) NEW_C_HEAP_ARRAY(unsigned char, _required, mtCode);
722   return generate_into(buffer);
723 }
724 
725 ImmutableOopMapSet* ImmutableOopMapSet::build_from(const OopMapSet* oopmap_set) {
726   ResourceMark mark;
727   ImmutableOopMapBuilder builder(oopmap_set);
728   return builder.build();
729 }
730 
731 
732 //------------------------------DerivedPointerTable---------------------------
733 
734 #if COMPILER2_OR_JVMCI
735 
736 class DerivedPointerEntry : public CHeapObj&lt;mtCompiler&gt; {
737  private:
738   oop*     _location; // Location of derived pointer (also pointing to the base)
739   intptr_t _offset;   // Offset from base pointer
740  public:
741   DerivedPointerEntry(oop* location, intptr_t offset) { _location = location; _offset = offset; }
742   oop* location()    { return _location; }
743   intptr_t  offset() { return _offset; }
744 };
745 
746 
747 GrowableArray&lt;DerivedPointerEntry*&gt;* DerivedPointerTable::_list = NULL;
748 bool DerivedPointerTable::_active = false;
749 
750 
751 void DerivedPointerTable::clear() {
752   // The first time, we create the list.  Otherwise it should be
753   // empty.  If not, then we have probably forgotton to call
754   // update_pointers after last GC/Scavenge.
755   assert (!_active, &quot;should not be active&quot;);
756   assert(_list == NULL || _list-&gt;length() == 0, &quot;table not empty&quot;);
757   if (_list == NULL) {
758     _list = new (ResourceObj::C_HEAP, mtCompiler) GrowableArray&lt;DerivedPointerEntry*&gt;(10, true); // Allocated on C heap
759   }
760   _active = true;
761 }
762 
763 
764 // Returns value of location as an int
765 intptr_t value_of_loc(oop *pointer) { return cast_from_oop&lt;intptr_t&gt;((*pointer)); }
766 
767 
768 void DerivedPointerTable::add(oop *derived_loc, oop *base_loc) {
769   assert(Universe::heap()-&gt;is_in_or_null(*base_loc), &quot;not an oop&quot;);
770   assert(derived_loc != base_loc, &quot;Base and derived in same location&quot;);
771   if (_active) {
772     assert(*derived_loc != (void*)base_loc, &quot;location already added&quot;);
773     assert(_list != NULL, &quot;list must exist&quot;);
774     intptr_t offset = value_of_loc(derived_loc) - value_of_loc(base_loc);
775     // This assert is invalid because derived pointers can be
776     // arbitrarily far away from their base.
777     // assert(offset &gt;= -1000000, &quot;wrong derived pointer info&quot;);
778 
779     if (TraceDerivedPointers) {
780       tty-&gt;print_cr(
781         &quot;Add derived pointer@&quot; INTPTR_FORMAT
782         &quot; - Derived: &quot; INTPTR_FORMAT
783         &quot; Base: &quot; INTPTR_FORMAT &quot; (@&quot; INTPTR_FORMAT &quot;) (Offset: &quot; INTX_FORMAT &quot;)&quot;,
784         p2i(derived_loc), p2i((address)*derived_loc), p2i((address)*base_loc), p2i(base_loc), offset
785       );
786     }
787     // Set derived oop location to point to base.
788     *derived_loc = (oop)base_loc;
789     assert_lock_strong(DerivedPointerTableGC_lock);
790     DerivedPointerEntry *entry = new DerivedPointerEntry(derived_loc, offset);
791     _list-&gt;append(entry);
792   }
793 }
794 
795 
796 void DerivedPointerTable::update_pointers() {
797   assert(_list != NULL, &quot;list must exist&quot;);
798   for(int i = 0; i &lt; _list-&gt;length(); i++) {
799     DerivedPointerEntry* entry = _list-&gt;at(i);
800     oop* derived_loc = entry-&gt;location();
801     intptr_t offset  = entry-&gt;offset();
802     // The derived oop was setup to point to location of base
803     oop  base        = **(oop**)derived_loc;
804     assert(Universe::heap()-&gt;is_in_or_null(base), &quot;must be an oop&quot;);
805 
806     *derived_loc = (oop)(((address)base) + offset);
807     assert(value_of_loc(derived_loc) - value_of_loc(&amp;base) == offset, &quot;sanity check&quot;);
808 
809     if (TraceDerivedPointers) {
810       tty-&gt;print_cr(&quot;Updating derived pointer@&quot; INTPTR_FORMAT
811                     &quot; - Derived: &quot; INTPTR_FORMAT &quot;  Base: &quot; INTPTR_FORMAT &quot; (Offset: &quot; INTX_FORMAT &quot;)&quot;,
812           p2i(derived_loc), p2i((address)*derived_loc), p2i((address)base), offset);
813     }
814 
815     // Delete entry
816     delete entry;
817     _list-&gt;at_put(i, NULL);
818   }
819   // Clear list, so it is ready for next traversal (this is an invariant)
820   if (TraceDerivedPointers &amp;&amp; !_list-&gt;is_empty()) {
821     tty-&gt;print_cr(&quot;--------------------------&quot;);
822   }
823   _list-&gt;clear();
824   _active = false;
825 }
826 
827 #endif // COMPILER2_OR_JVMCI
    </pre>
  </body>
</html>