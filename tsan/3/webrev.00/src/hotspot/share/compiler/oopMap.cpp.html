<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/compiler/oopMap.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;code/codeBlob.hpp&quot;
 27 #include &quot;code/codeCache.hpp&quot;
 28 #include &quot;code/nmethod.hpp&quot;
 29 #include &quot;code/scopeDesc.hpp&quot;
 30 #include &quot;compiler/oopMap.hpp&quot;
 31 #include &quot;gc/shared/collectedHeap.hpp&quot;
 32 #include &quot;memory/allocation.inline.hpp&quot;
 33 #include &quot;memory/iterator.hpp&quot;
 34 #include &quot;memory/resourceArea.hpp&quot;
 35 #include &quot;memory/universe.hpp&quot;
 36 #include &quot;oops/compressedOops.hpp&quot;
 37 #include &quot;runtime/frame.inline.hpp&quot;
 38 #include &quot;runtime/handles.inline.hpp&quot;
 39 #include &quot;runtime/signature.hpp&quot;
 40 #include &quot;utilities/align.hpp&quot;
 41 #include &quot;utilities/lockFreeStack.hpp&quot;
 42 #ifdef COMPILER1
 43 #include &quot;c1/c1_Defs.hpp&quot;
 44 #endif
 45 #ifdef COMPILER2
 46 #include &quot;opto/optoreg.hpp&quot;
 47 #endif
 48 
 49 // OopMapStream
 50 
 51 OopMapStream::OopMapStream(OopMap* oop_map) {
 52   _stream = new CompressedReadStream(oop_map-&gt;write_stream()-&gt;buffer());
 53   _size = oop_map-&gt;omv_count();
 54   _position = 0;
 55   _valid_omv = false;
 56 }
 57 
 58 OopMapStream::OopMapStream(const ImmutableOopMap* oop_map) {
 59   _stream = new CompressedReadStream(oop_map-&gt;data_addr());
 60   _size = oop_map-&gt;count();
 61   _position = 0;
 62   _valid_omv = false;
 63 }
 64 
 65 void OopMapStream::find_next() {
 66   if (_position++ &lt; _size) {
 67     _omv.read_from(_stream);
 68     _valid_omv = true;
 69     return;
 70   }
 71   _valid_omv = false;
 72 }
 73 
 74 
 75 // OopMap
 76 
 77 // frame_size units are stack-slots (4 bytes) NOT intptr_t; we can name odd
 78 // slots to hold 4-byte values like ints and floats in the LP64 build.
 79 OopMap::OopMap(int frame_size, int arg_count) {
 80   // OopMaps are usually quite so small, so pick a small initial size
 81   set_write_stream(new CompressedWriteStream(32));
 82   set_omv_count(0);
 83 
 84 #ifdef ASSERT
 85   _locs_length = VMRegImpl::stack2reg(0)-&gt;value() + frame_size + arg_count;
 86   _locs_used   = NEW_RESOURCE_ARRAY(OopMapValue::oop_types, _locs_length);
 87   for(int i = 0; i &lt; _locs_length; i++) _locs_used[i] = OopMapValue::unused_value;
 88 #endif
 89 }
 90 
 91 
 92 OopMap::OopMap(OopMap::DeepCopyToken, OopMap* source) {
 93   // This constructor does a deep copy
 94   // of the source OopMap.
 95   set_write_stream(new CompressedWriteStream(source-&gt;omv_count() * 2));
 96   set_omv_count(0);
 97   set_offset(source-&gt;offset());
 98 
 99 #ifdef ASSERT
100   _locs_length = source-&gt;_locs_length;
101   _locs_used = NEW_RESOURCE_ARRAY(OopMapValue::oop_types, _locs_length);
102   for(int i = 0; i &lt; _locs_length; i++) _locs_used[i] = OopMapValue::unused_value;
103 #endif
104 
105   // We need to copy the entries too.
106   for (OopMapStream oms(source); !oms.is_done(); oms.next()) {
107     OopMapValue omv = oms.current();
108     omv.write_on(write_stream());
109     increment_count();
110   }
111 }
112 
113 
114 OopMap* OopMap::deep_copy() {
115   return new OopMap(_deep_copy_token, this);
116 }
117 
118 void OopMap::copy_data_to(address addr) const {
119   memcpy(addr, write_stream()-&gt;buffer(), write_stream()-&gt;position());
120 }
121 
122 int OopMap::heap_size() const {
123   int size = sizeof(OopMap);
124   int align = sizeof(void *) - 1;
125   size += write_stream()-&gt;position();
126   // Align to a reasonable ending point
127   size = ((size+align) &amp; ~align);
128   return size;
129 }
130 
131 // frame_size units are stack-slots (4 bytes) NOT intptr_t; we can name odd
132 // slots to hold 4-byte values like ints and floats in the LP64 build.
133 void OopMap::set_xxx(VMReg reg, OopMapValue::oop_types x, VMReg optional) {
134 
135   assert(reg-&gt;value() &lt; _locs_length, &quot;too big reg value for stack size&quot;);
136   assert( _locs_used[reg-&gt;value()] == OopMapValue::unused_value, &quot;cannot insert twice&quot; );
137   debug_only( _locs_used[reg-&gt;value()] = x; )
138 
139   OopMapValue o(reg, x, optional);
140   o.write_on(write_stream());
141   increment_count();
142 }
143 
144 
145 void OopMap::set_oop(VMReg reg) {
146   set_xxx(reg, OopMapValue::oop_value, VMRegImpl::Bad());
147 }
148 
149 
150 void OopMap::set_narrowoop(VMReg reg) {
151   set_xxx(reg, OopMapValue::narrowoop_value, VMRegImpl::Bad());
152 }
153 
154 
155 void OopMap::set_callee_saved(VMReg reg, VMReg caller_machine_register ) {
156   set_xxx(reg, OopMapValue::callee_saved_value, caller_machine_register);
157 }
158 
159 
160 void OopMap::set_derived_oop(VMReg reg, VMReg derived_from_local_register ) {
161   if( reg == derived_from_local_register ) {
162     // Actually an oop, derived shares storage with base,
163     set_oop(reg);
164   } else {
165     set_xxx(reg, OopMapValue::derived_oop_value, derived_from_local_register);
166   }
167 }
168 
169 // OopMapSet
170 
171 OopMapSet::OopMapSet() {
172   set_om_size(MinOopMapAllocation);
173   set_om_count(0);
174   OopMap** temp = NEW_RESOURCE_ARRAY(OopMap*, om_size());
175   set_om_data(temp);
176 }
177 
178 
179 void OopMapSet::grow_om_data() {
180   int new_size = om_size() * 2;
181   OopMap** new_data = NEW_RESOURCE_ARRAY(OopMap*, new_size);
182   memcpy(new_data,om_data(),om_size() * sizeof(OopMap*));
183   set_om_size(new_size);
184   set_om_data(new_data);
185 }
186 
187 void OopMapSet::add_gc_map(int pc_offset, OopMap *map ) {
188   assert(om_size() != -1,&quot;Cannot grow a fixed OopMapSet&quot;);
189 
190   if(om_count() &gt;= om_size()) {
191     grow_om_data();
192   }
193   map-&gt;set_offset(pc_offset);
194 
195 #ifdef ASSERT
196   if(om_count() &gt; 0) {
197     OopMap* last = at(om_count()-1);
198     if (last-&gt;offset() == map-&gt;offset() ) {
199       fatal(&quot;OopMap inserted twice&quot;);
200     }
201     if(last-&gt;offset() &gt; map-&gt;offset()) {
202       tty-&gt;print_cr( &quot;WARNING, maps not sorted: pc[%d]=%d, pc[%d]=%d&quot;,
203                       om_count(),last-&gt;offset(),om_count()+1,map-&gt;offset());
204     }
205   }
206 #endif // ASSERT
207 
208   set(om_count(),map);
209   increment_count();
210 }
211 
212 
213 int OopMapSet::heap_size() const {
214   // The space we use
215   int size = sizeof(OopMap);
216   int align = sizeof(void *) - 1;
217   size = ((size+align) &amp; ~align);
218   size += om_count() * sizeof(OopMap*);
219 
220   // Now add in the space needed for the indivdiual OopMaps
221   for(int i=0; i &lt; om_count(); i++) {
222     size += at(i)-&gt;heap_size();
223   }
224   // We don&#39;t need to align this, it will be naturally pointer aligned
225   return size;
226 }
227 
228 
229 OopMap* OopMapSet::singular_oop_map() {
230   guarantee(om_count() == 1, &quot;Make sure we only have a single gc point&quot;);
231   return at(0);
232 }
233 
234 
235 OopMap* OopMapSet::find_map_at_offset(int pc_offset) const {
236   int i, len = om_count();
237   assert( len &gt; 0, &quot;must have pointer maps&quot; );
238 
239   // Scan through oopmaps. Stop when current offset is either equal or greater
240   // than the one we are looking for.
241   for( i = 0; i &lt; len; i++) {
242     if( at(i)-&gt;offset() &gt;= pc_offset )
243       break;
244   }
245 
246   assert( i &lt; len, &quot;oopmap not found&quot; );
247 
248   OopMap* m = at(i);
249   assert( m-&gt;offset() == pc_offset, &quot;oopmap not found&quot; );
250   return m;
251 }
252 
253 static void add_derived_oop(oop* base, oop* derived) {
254 #if !defined(TIERED) &amp;&amp; !INCLUDE_JVMCI
255   COMPILER1_PRESENT(ShouldNotReachHere();)
256 #endif // !defined(TIERED) &amp;&amp; !INCLUDE_JVMCI
257 #if COMPILER2_OR_JVMCI
258   DerivedPointerTable::add(derived, base);
259 #endif // COMPILER2_OR_JVMCI
260 }
261 
262 
263 #ifndef PRODUCT
264 static void trace_codeblob_maps(const frame *fr, const RegisterMap *reg_map) {
265   // Print oopmap and regmap
266   tty-&gt;print_cr(&quot;------ &quot;);
267   CodeBlob* cb = fr-&gt;cb();
268   const ImmutableOopMapSet* maps = cb-&gt;oop_maps();
269   const ImmutableOopMap* map = cb-&gt;oop_map_for_return_address(fr-&gt;pc());
270   map-&gt;print();
271   if( cb-&gt;is_nmethod() ) {
272     nmethod* nm = (nmethod*)cb;
273     // native wrappers have no scope data, it is implied
274     if (nm-&gt;is_native_method()) {
275       tty-&gt;print(&quot;bci: 0 (native)&quot;);
276     } else {
277       ScopeDesc* scope  = nm-&gt;scope_desc_at(fr-&gt;pc());
278       tty-&gt;print(&quot;bci: %d &quot;,scope-&gt;bci());
279     }
280   }
281   tty-&gt;cr();
282   fr-&gt;print_on(tty);
283   tty-&gt;print(&quot;     &quot;);
284   cb-&gt;print_value_on(tty);  tty-&gt;cr();
285   reg_map-&gt;print();
286   tty-&gt;print_cr(&quot;------ &quot;);
287 
288 }
289 #endif // PRODUCT
290 
291 void OopMapSet::oops_do(const frame *fr, const RegisterMap* reg_map, OopClosure* f) {
292   // add derived oops to a table
293   all_do(fr, reg_map, f, add_derived_oop, &amp;do_nothing_cl);
294 }
295 
296 
297 void OopMapSet::all_do(const frame *fr, const RegisterMap *reg_map,
298                        OopClosure* oop_fn, void derived_oop_fn(oop*, oop*),
299                        OopClosure* value_fn) {
300   CodeBlob* cb = fr-&gt;cb();
301   assert(cb != NULL, &quot;no codeblob&quot;);
302 
303   NOT_PRODUCT(if (TraceCodeBlobStacks) trace_codeblob_maps(fr, reg_map);)
304 
305   const ImmutableOopMapSet* maps = cb-&gt;oop_maps();
306   const ImmutableOopMap* map = cb-&gt;oop_map_for_return_address(fr-&gt;pc());
307   assert(map != NULL, &quot;no ptr map found&quot;);
308 
309   // handle derived pointers first (otherwise base pointer may be
310   // changed before derived pointer offset has been collected)
311   {
312     for (OopMapStream oms(map); !oms.is_done(); oms.next()) {
313       OopMapValue omv = oms.current();
314       if (omv.type() != OopMapValue::derived_oop_value) {
315         continue;
316       }
317 
318 #ifndef TIERED
319       COMPILER1_PRESENT(ShouldNotReachHere();)
320 #if INCLUDE_JVMCI
321       if (UseJVMCICompiler) {
322         ShouldNotReachHere();
323       }
324 #endif
325 #endif // !TIERED
326       oop* loc = fr-&gt;oopmapreg_to_location(omv.reg(),reg_map);
327       guarantee(loc != NULL, &quot;missing saved register&quot;);
328       oop *derived_loc = loc;
329       oop *base_loc    = fr-&gt;oopmapreg_to_location(omv.content_reg(), reg_map);
330       // Ignore NULL oops and decoded NULL narrow oops which
331       // equal to CompressedOops::base() when a narrow oop
332       // implicit null check is used in compiled code.
333       // The narrow_oop_base could be NULL or be the address
334       // of the page below heap depending on compressed oops mode.
335       if (base_loc != NULL &amp;&amp; *base_loc != NULL &amp;&amp; !CompressedOops::is_base(*base_loc)) {
336         derived_oop_fn(base_loc, derived_loc);
337       }
338     }
339   }
340 
341   {
342     // We want coop and oop oop_types
343     for (OopMapStream oms(map); !oms.is_done(); oms.next()) {
344       OopMapValue omv = oms.current();
345       oop* loc = fr-&gt;oopmapreg_to_location(omv.reg(),reg_map);
346       // It should be an error if no location can be found for a
347       // register mentioned as contained an oop of some kind.  Maybe
348       // this was allowed previously because value_value items might
349       // be missing?
350       guarantee(loc != NULL, &quot;missing saved register&quot;);
351       if ( omv.type() == OopMapValue::oop_value ) {
352         oop val = *loc;
353         if (val == NULL || CompressedOops::is_base(val)) {
354           // Ignore NULL oops and decoded NULL narrow oops which
355           // equal to CompressedOops::base() when a narrow oop
356           // implicit null check is used in compiled code.
357           // The narrow_oop_base could be NULL or be the address
358           // of the page below heap depending on compressed oops mode.
359           continue;
360         }
361 #ifdef ASSERT
362         if ((((uintptr_t)loc &amp; (sizeof(*loc)-1)) != 0) ||
363             !Universe::heap()-&gt;is_in_or_null(*loc)) {
364           tty-&gt;print_cr(&quot;# Found non oop pointer.  Dumping state at failure&quot;);
365           // try to dump out some helpful debugging information
366           trace_codeblob_maps(fr, reg_map);
367           omv.print();
368           tty-&gt;print_cr(&quot;register r&quot;);
369           omv.reg()-&gt;print();
370           tty-&gt;print_cr(&quot;loc = %p *loc = %p\n&quot;, loc, cast_from_oop&lt;address&gt;(*loc));
371           // do the real assert.
372           assert(Universe::heap()-&gt;is_in_or_null(*loc), &quot;found non oop pointer&quot;);
373         }
374 #endif // ASSERT
375         oop_fn-&gt;do_oop(loc);
376       } else if ( omv.type() == OopMapValue::narrowoop_value ) {
377         narrowOop *nl = (narrowOop*)loc;
378 #ifndef VM_LITTLE_ENDIAN
379         VMReg vmReg = omv.reg();
380         // Don&#39;t do this on SPARC float registers as they can be individually addressed
381         if (!vmReg-&gt;is_stack() SPARC_ONLY(&amp;&amp; !vmReg-&gt;is_FloatRegister())) {
382           // compressed oops in registers only take up 4 bytes of an
383           // 8 byte register but they are in the wrong part of the
384           // word so adjust loc to point at the right place.
385           nl = (narrowOop*)((address)nl + 4);
386         }
387 #endif
388         oop_fn-&gt;do_oop(nl);
389       }
390     }
391   }
392 }
393 
394 
395 // Update callee-saved register info for the following frame
396 void OopMapSet::update_register_map(const frame *fr, RegisterMap *reg_map) {
397   ResourceMark rm;
398   CodeBlob* cb = fr-&gt;cb();
399   assert(cb != NULL, &quot;no codeblob&quot;);
400 
401   // Any reg might be saved by a safepoint handler (see generate_handler_blob).
402   assert( reg_map-&gt;_update_for_id == NULL || fr-&gt;is_older(reg_map-&gt;_update_for_id),
403          &quot;already updated this map; do not &#39;update&#39; it twice!&quot; );
404   debug_only(reg_map-&gt;_update_for_id = fr-&gt;id());
405 
406   // Check if caller must update oop argument
407   assert((reg_map-&gt;include_argument_oops() ||
408           !cb-&gt;caller_must_gc_arguments(reg_map-&gt;thread())),
409          &quot;include_argument_oops should already be set&quot;);
410 
411   // Scan through oopmap and find location of all callee-saved registers
412   // (we do not do update in place, since info could be overwritten)
413 
414   address pc = fr-&gt;pc();
415   const ImmutableOopMap* map  = cb-&gt;oop_map_for_return_address(pc);
416   assert(map != NULL, &quot;no ptr map found&quot;);
417   DEBUG_ONLY(int nof_callee = 0;)
418 
419   for (OopMapStream oms(map); !oms.is_done(); oms.next()) {
420     OopMapValue omv = oms.current();
421     if (omv.type() == OopMapValue::callee_saved_value) {
422       VMReg reg = omv.content_reg();
423       oop* loc = fr-&gt;oopmapreg_to_location(omv.reg(), reg_map);
424       reg_map-&gt;set_location(reg, (address) loc);
425       DEBUG_ONLY(nof_callee++;)
426     }
427   }
428 
429   // Check that runtime stubs save all callee-saved registers
430 #ifdef COMPILER2
431   assert(cb-&gt;is_compiled_by_c1() || cb-&gt;is_compiled_by_jvmci() || !cb-&gt;is_runtime_stub() ||
432          (nof_callee &gt;= SAVED_ON_ENTRY_REG_COUNT || nof_callee &gt;= C_SAVED_ON_ENTRY_REG_COUNT),
433          &quot;must save all&quot;);
434 #endif // COMPILER2
435 }
436 
437 // Printing code is present in product build for -XX:+PrintAssembly.
438 
439 static
440 void print_register_type(OopMapValue::oop_types x, VMReg optional,
441                          outputStream* st) {
442   switch( x ) {
443   case OopMapValue::oop_value:
444     st-&gt;print(&quot;Oop&quot;);
445     break;
446   case OopMapValue::narrowoop_value:
447     st-&gt;print(&quot;NarrowOop&quot;);
448     break;
449   case OopMapValue::callee_saved_value:
450     st-&gt;print(&quot;Callers_&quot;);
451     optional-&gt;print_on(st);
452     break;
453   case OopMapValue::derived_oop_value:
454     st-&gt;print(&quot;Derived_oop_&quot;);
455     optional-&gt;print_on(st);
456     break;
457   default:
458     ShouldNotReachHere();
459   }
460 }
461 
462 void OopMapValue::print_on(outputStream* st) const {
463   reg()-&gt;print_on(st);
464   st-&gt;print(&quot;=&quot;);
465   print_register_type(type(),content_reg(),st);
466   st-&gt;print(&quot; &quot;);
467 }
468 
469 void OopMapValue::print() const { print_on(tty); }
470 
471 void ImmutableOopMap::print_on(outputStream* st) const {
472   OopMapValue omv;
473   st-&gt;print(&quot;ImmutableOopMap {&quot;);
474   for(OopMapStream oms(this); !oms.is_done(); oms.next()) {
475     omv = oms.current();
476     omv.print_on(st);
477   }
478   st-&gt;print(&quot;}&quot;);
479 }
480 
481 void ImmutableOopMap::print() const { print_on(tty); }
482 
483 void OopMap::print_on(outputStream* st) const {
484   OopMapValue omv;
485   st-&gt;print(&quot;OopMap {&quot;);
486   for(OopMapStream oms((OopMap*)this); !oms.is_done(); oms.next()) {
487     omv = oms.current();
488     omv.print_on(st);
489   }
490   // Print hex offset in addition.
491   st-&gt;print(&quot;off=%d/0x%x}&quot;, (int) offset(), (int) offset());
492 }
493 
494 void OopMap::print() const { print_on(tty); }
495 
496 void ImmutableOopMapSet::print_on(outputStream* st) const {
497   const ImmutableOopMap* last = NULL;
498   const int len = count();
499 
500   st-&gt;print_cr(&quot;ImmutableOopMapSet contains %d OopMaps&quot;, len);
501 
502   for (int i = 0; i &lt; len; i++) {
503     const ImmutableOopMapPair* pair = pair_at(i);
504     const ImmutableOopMap* map = pair-&gt;get_from(this);
505     if (map != last) {
506       st-&gt;cr();
507       map-&gt;print_on(st);
508       st-&gt;print(&quot; pc offsets: &quot;);
509     }
510     last = map;
511     st-&gt;print(&quot;%d &quot;, pair-&gt;pc_offset());
512   }
513   st-&gt;cr();
514 }
515 
516 void ImmutableOopMapSet::print() const { print_on(tty); }
517 
518 void OopMapSet::print_on(outputStream* st) const {
519   const int len = om_count();
520 
521   st-&gt;print_cr(&quot;OopMapSet contains %d OopMaps&quot;, len);
522 
523   for( int i = 0; i &lt; len; i++) {
524     OopMap* m = at(i);
525     st-&gt;print_cr(&quot;#%d &quot;,i);
526     m-&gt;print_on(st);
527     st-&gt;cr();
528   }
529   st-&gt;cr();
530 }
531 
532 void OopMapSet::print() const { print_on(tty); }
533 
534 bool OopMap::equals(const OopMap* other) const {
535   if (other-&gt;_omv_count != _omv_count) {
536     return false;
537   }
538   if (other-&gt;write_stream()-&gt;position() != write_stream()-&gt;position()) {
539     return false;
540   }
541   if (memcmp(other-&gt;write_stream()-&gt;buffer(), write_stream()-&gt;buffer(), write_stream()-&gt;position()) != 0) {
542     return false;
543   }
544   return true;
545 }
546 
547 const ImmutableOopMap* ImmutableOopMapSet::find_map_at_offset(int pc_offset) const {
548   ImmutableOopMapPair* pairs = get_pairs();
549   ImmutableOopMapPair* last  = NULL;
550 
551   for (int i = 0; i &lt; _count; ++i) {
552     if (pairs[i].pc_offset() &gt;= pc_offset) {
553       last = &amp;pairs[i];
554       break;
555     }
556   }
557 
558   // Heal Coverity issue: potential index out of bounds access.
559   guarantee(last != NULL, &quot;last may not be null&quot;);
560   assert(last-&gt;pc_offset() == pc_offset, &quot;oopmap not found&quot;);
561   return last-&gt;get_from(this);
562 }
563 
564 const ImmutableOopMap* ImmutableOopMapPair::get_from(const ImmutableOopMapSet* set) const {
565   return set-&gt;oopmap_at_offset(_oopmap_offset);
566 }
567 
568 ImmutableOopMap::ImmutableOopMap(const OopMap* oopmap) : _count(oopmap-&gt;count()) {
569   address addr = data_addr();
570   oopmap-&gt;copy_data_to(addr);
571 }
572 
573 #ifdef ASSERT
574 int ImmutableOopMap::nr_of_bytes() const {
575   OopMapStream oms(this);
576 
577   while (!oms.is_done()) {
578     oms.next();
579   }
580   return sizeof(ImmutableOopMap) + oms.stream_position();
581 }
582 #endif
583 
584 ImmutableOopMapBuilder::ImmutableOopMapBuilder(const OopMapSet* set) : _set(set), _empty(NULL), _last(NULL), _empty_offset(-1), _last_offset(-1), _offset(0), _required(-1), _new_set(NULL) {
585   _mapping = NEW_RESOURCE_ARRAY(Mapping, _set-&gt;size());
586 }
587 
588 int ImmutableOopMapBuilder::size_for(const OopMap* map) const {
589   return align_up((int)sizeof(ImmutableOopMap) + map-&gt;data_size(), 8);
590 }
591 
592 int ImmutableOopMapBuilder::heap_size() {
593   int base = sizeof(ImmutableOopMapSet);
594   base = align_up(base, 8);
595 
596   // all of ours pc / offset pairs
597   int pairs = _set-&gt;size() * sizeof(ImmutableOopMapPair);
598   pairs = align_up(pairs, 8);
599 
600   for (int i = 0; i &lt; _set-&gt;size(); ++i) {
601     int size = 0;
602     OopMap* map = _set-&gt;at(i);
603 
604     if (is_empty(map)) {
605       /* only keep a single empty map in the set */
606       if (has_empty()) {
607         _mapping[i].set(Mapping::OOPMAP_EMPTY, _empty_offset, 0, map, _empty);
608       } else {
609         _empty_offset = _offset;
610         _empty = map;
611         size = size_for(map);
612         _mapping[i].set(Mapping::OOPMAP_NEW, _offset, size, map);
613       }
614     } else if (is_last_duplicate(map)) {
615       /* if this entry is identical to the previous one, just point it there */
616       _mapping[i].set(Mapping::OOPMAP_DUPLICATE, _last_offset, 0, map, _last);
617     } else {
618       /* not empty, not an identical copy of the previous entry */
619       size = size_for(map);
620       _mapping[i].set(Mapping::OOPMAP_NEW, _offset, size, map);
621       _last_offset = _offset;
622       _last = map;
623     }
624 
625     assert(_mapping[i]._map == map, &quot;check&quot;);
626     _offset += size;
627   }
628 
629   int total = base + pairs + _offset;
630   DEBUG_ONLY(total += 8);
631   _required = total;
632   return total;
633 }
634 
635 void ImmutableOopMapBuilder::fill_pair(ImmutableOopMapPair* pair, const OopMap* map, int offset, const ImmutableOopMapSet* set) {
636   assert(offset &lt; set-&gt;nr_of_bytes(), &quot;check&quot;);
637   new ((address) pair) ImmutableOopMapPair(map-&gt;offset(), offset);
638 }
639 
640 int ImmutableOopMapBuilder::fill_map(ImmutableOopMapPair* pair, const OopMap* map, int offset, const ImmutableOopMapSet* set) {
641   fill_pair(pair, map, offset, set);
642   address addr = (address) pair-&gt;get_from(_new_set); // location of the ImmutableOopMap
643 
644   new (addr) ImmutableOopMap(map);
645   return size_for(map);
646 }
647 
648 void ImmutableOopMapBuilder::fill(ImmutableOopMapSet* set, int sz) {
649   ImmutableOopMapPair* pairs = set-&gt;get_pairs();
650 
651   for (int i = 0; i &lt; set-&gt;count(); ++i) {
652     const OopMap* map = _mapping[i]._map;
653     ImmutableOopMapPair* pair = NULL;
654     int size = 0;
655 
656     if (_mapping[i]._kind == Mapping::OOPMAP_NEW) {
657       size = fill_map(&amp;pairs[i], map, _mapping[i]._offset, set);
658     } else if (_mapping[i]._kind == Mapping::OOPMAP_DUPLICATE || _mapping[i]._kind == Mapping::OOPMAP_EMPTY) {
659       fill_pair(&amp;pairs[i], map, _mapping[i]._offset, set);
660     }
661 
662     const ImmutableOopMap* nv = set-&gt;find_map_at_offset(map-&gt;offset());
663     assert(memcmp(map-&gt;data(), nv-&gt;data_addr(), map-&gt;data_size()) == 0, &quot;check identity&quot;);
664   }
665 }
666 
667 #ifdef ASSERT
668 void ImmutableOopMapBuilder::verify(address buffer, int size, const ImmutableOopMapSet* set) {
669   for (int i = 0; i &lt; 8; ++i) {
670     assert(buffer[size - 8 + i] == (unsigned char) 0xff, &quot;overwritten memory check&quot;);
671   }
672 
673   for (int i = 0; i &lt; set-&gt;count(); ++i) {
674     const ImmutableOopMapPair* pair = set-&gt;pair_at(i);
675     assert(pair-&gt;oopmap_offset() &lt; set-&gt;nr_of_bytes(), &quot;check size&quot;);
676     const ImmutableOopMap* map = pair-&gt;get_from(set);
677     int nr_of_bytes = map-&gt;nr_of_bytes();
678     assert(pair-&gt;oopmap_offset() + nr_of_bytes &lt;= set-&gt;nr_of_bytes(), &quot;check size + size&quot;);
679   }
680 }
681 #endif
682 
683 ImmutableOopMapSet* ImmutableOopMapBuilder::generate_into(address buffer) {
684   DEBUG_ONLY(memset(&amp;buffer[_required-8], 0xff, 8));
685 
686   _new_set = new (buffer) ImmutableOopMapSet(_set, _required);
687   fill(_new_set, _required);
688 
689   DEBUG_ONLY(verify(buffer, _required, _new_set));
690 
691   return _new_set;
692 }
693 
694 ImmutableOopMapSet* ImmutableOopMapBuilder::build() {
695   _required = heap_size();
696 
697   // We need to allocate a chunk big enough to hold the ImmutableOopMapSet and all of its ImmutableOopMaps
698   address buffer = NEW_C_HEAP_ARRAY(unsigned char, _required, mtCode);
699   return generate_into(buffer);
700 }
701 
702 ImmutableOopMapSet* ImmutableOopMapSet::build_from(const OopMapSet* oopmap_set) {
703   ResourceMark mark;
704   ImmutableOopMapBuilder builder(oopmap_set);
705   return builder.build();
706 }
707 
708 
709 //------------------------------DerivedPointerTable---------------------------
710 
711 #if COMPILER2_OR_JVMCI
712 
713 class DerivedPointerTable::Entry : public CHeapObj&lt;mtCompiler&gt; {
714   oop* _location;   // Location of derived pointer, also pointing to base
715   intptr_t _offset; // Offset from base pointer
716   Entry* volatile _next;
717 
718   static Entry* volatile* next_ptr(Entry&amp; entry) { return &amp;entry._next; }
719 
720 public:
721   Entry(oop* location, intptr_t offset) :
722     _location(location), _offset(offset), _next(NULL) {}
723 
724   oop* location() const { return _location; }
725   intptr_t offset() const { return _offset; }
726   Entry* next() const { return _next; }
727 
728   typedef LockFreeStack&lt;Entry, &amp;next_ptr&gt; List;
729   static List* _list;
730 };
731 
732 DerivedPointerTable::Entry::List* DerivedPointerTable::Entry::_list = NULL;
733 bool DerivedPointerTable::_active = false;
734 
735 bool DerivedPointerTable::is_empty() {
736   return Entry::_list == NULL || Entry::_list-&gt;empty();
737 }
738 
739 void DerivedPointerTable::clear() {
740   // The first time, we create the list.  Otherwise it should be
741   // empty.  If not, then we have probably forgotton to call
742   // update_pointers after last GC/Scavenge.
743   assert (!_active, &quot;should not be active&quot;);
744   assert(is_empty(), &quot;table not empty&quot;);
745   if (Entry::_list == NULL) {
746     void* mem = NEW_C_HEAP_OBJ(Entry::List, mtCompiler);
747     Entry::_list = ::new (mem) Entry::List();
748   }
749   _active = true;
750 }
751 
752 // Returns value of location as an int
753 inline intptr_t value_of_loc(oop *pointer) {
754   return cast_from_oop&lt;intptr_t&gt;((*pointer));
755 }
756 
757 void DerivedPointerTable::add(oop *derived_loc, oop *base_loc) {
758   assert(Universe::heap()-&gt;is_in_or_null(*base_loc), &quot;not an oop&quot;);
759   assert(derived_loc != base_loc, &quot;Base and derived in same location&quot;);
760   if (_active) {
761     assert(*derived_loc != (void*)base_loc, &quot;location already added&quot;);
762     assert(Entry::_list != NULL, &quot;list must exist&quot;);
763     intptr_t offset = value_of_loc(derived_loc) - value_of_loc(base_loc);
764     // This assert is invalid because derived pointers can be
765     // arbitrarily far away from their base.
766     // assert(offset &gt;= -1000000, &quot;wrong derived pointer info&quot;);
767 
768     if (TraceDerivedPointers) {
769       tty-&gt;print_cr(
770         &quot;Add derived pointer@&quot; INTPTR_FORMAT
771         &quot; - Derived: &quot; INTPTR_FORMAT
772         &quot; Base: &quot; INTPTR_FORMAT &quot; (@&quot; INTPTR_FORMAT &quot;) (Offset: &quot; INTX_FORMAT &quot;)&quot;,
773         p2i(derived_loc), p2i(*derived_loc), p2i(*base_loc), p2i(base_loc), offset
774       );
775     }
776     // Set derived oop location to point to base.
777     *derived_loc = (oop)base_loc;
778     Entry* entry = new Entry(derived_loc, offset);
779     Entry::_list-&gt;push(*entry);
780   }
781 }
782 
783 void DerivedPointerTable::update_pointers() {
784   assert(Entry::_list != NULL, &quot;list must exist&quot;);
785   Entry* entries = Entry::_list-&gt;pop_all();
786   while (entries != NULL) {
787     Entry* entry = entries;
788     entries = entry-&gt;next();
789     oop* derived_loc = entry-&gt;location();
790     intptr_t offset  = entry-&gt;offset();
791     // The derived oop was setup to point to location of base
792     oop base = **(oop**)derived_loc;
793     assert(Universe::heap()-&gt;is_in_or_null(base), &quot;must be an oop&quot;);
794 
795     *derived_loc = (oop)(cast_from_oop&lt;address&gt;(base) + offset);
796     assert(value_of_loc(derived_loc) - value_of_loc(&amp;base) == offset, &quot;sanity check&quot;);
797 
798     if (TraceDerivedPointers) {
799       tty-&gt;print_cr(&quot;Updating derived pointer@&quot; INTPTR_FORMAT
800                     &quot; - Derived: &quot; INTPTR_FORMAT &quot;  Base: &quot; INTPTR_FORMAT &quot; (Offset: &quot; INTX_FORMAT &quot;)&quot;,
801           p2i(derived_loc), p2i(*derived_loc), p2i(base), offset);
802     }
803 
804     // Delete entry
805     delete entry;
806   }
807   assert(Entry::_list-&gt;empty(), &quot;invariant&quot;);
808   _active = false;
809 }
810 
811 #endif // COMPILER2_OR_JVMCI
    </pre>
  </body>
</html>